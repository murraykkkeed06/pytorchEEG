{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d37b72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6c167c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional neural network (two convolutional layers)\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(BiLSTM, self).__init__()\n",
    "           \n",
    "        self.d1 = nn.Dropout(p=0.25)      \n",
    "        self.bn1 = nn.BatchNorm1d(64,affine=False)\n",
    "        self.ac1 = nn.Softplus()\n",
    "        #self.rnn = nn.RNN(64,256,dropout=0.25)\n",
    "        self.lstm = nn.LSTM(64,256,dropout=0.25,bidirectional=True)\n",
    "        self.fc1 = nn.Linear(512, 64)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def forward(self, x):      \n",
    "        x, _= self.lstm(x)\n",
    "        #print(x.shape)\n",
    "        x = x[:,-1,:]\n",
    "        #print(x.shape)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.ac1(x)\n",
    "        x = self.d1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d787f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 4])\n"
     ]
    }
   ],
   "source": [
    "rnn = BiLSTM(4)\n",
    "input = torch.randn(10, 64, 64)\n",
    "output= rnn(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81069b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c3bac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"data/final_format/train_set.csv\",header=None).to_numpy()\n",
    "train_label = pd.read_csv(\"data/final_format/train_label.csv\",header=None).to_numpy()\n",
    "test_set = pd.read_csv(\"data/final_format/test_set.csv\",header=None).to_numpy()\n",
    "test_label = pd.read_csv(\"data/final_format/test_label.csv\",header=None).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bf3f8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14392, 4096) (14392, 1) (3598, 4096) (3598, 1)\n"
     ]
    }
   ],
   "source": [
    "#delet first row data\n",
    "train_set = train_set[1:]\n",
    "train_label = train_label[1:]\n",
    "test_set = test_set[1:]\n",
    "test_label = test_label[1:]\n",
    "print(train_set.shape, train_label.shape, test_set.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "973e9154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14392, 4096) (14392,) (3598, 4096) (3598,)\n"
     ]
    }
   ],
   "source": [
    "train_label = train_label.reshape(-1)\n",
    "test_label = test_label.reshape(-1)\n",
    "print(train_set.shape, train_label.shape, test_set.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c01cf3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14392, 64, 64) (14392,) (3598, 64, 64) (3598,)\n"
     ]
    }
   ],
   "source": [
    "#transpose to set data in time sequence\n",
    "train_set = train_set.reshape(-1,64,64)\n",
    "train_set = np.transpose(train_set,[0,2,1])\n",
    "test_set = test_set.reshape(-1,64,64)\n",
    "test_set = np.transpose(test_set,[0,2,1])\n",
    "print(train_set.shape, train_label.shape, test_set.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfacc4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 300\n",
    "num_classes = 4\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd26b09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_tensor = Tensor(train_set) \n",
    "train_label_tensor = Tensor(train_label).type(torch.LongTensor)\n",
    "\n",
    "train_dataset = TensorDataset(train_set_tensor,train_label_tensor) \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size) \n",
    "\n",
    "test_set_tensor = Tensor(test_set) \n",
    "test_label_tensor = Tensor(test_label).type(torch.LongTensor)\n",
    "\n",
    "test_dataset = TensorDataset(test_set_tensor,test_label_tensor) \n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7079a997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14183dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM(num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6a63d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-3) \n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "milestones = [50,100,150,200,250]\n",
    "milestones = [a * len(train_loader) for a in milestones]\n",
    "scheduler = MultiStepLR(optimizer, milestones=milestones, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7297368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Step [1/225], Training Accuracy: 20.3125%, Training Loss: 1.5314%\n",
      "Epoch [1/300], Step [2/225], Training Accuracy: 23.4375%, Training Loss: 1.5104%\n",
      "Epoch [1/300], Step [3/225], Training Accuracy: 22.9167%, Training Loss: 1.5129%\n",
      "Epoch [1/300], Step [4/225], Training Accuracy: 25.3906%, Training Loss: 1.4929%\n",
      "Epoch [1/300], Step [5/225], Training Accuracy: 24.0625%, Training Loss: 1.5003%\n",
      "Epoch [1/300], Step [6/225], Training Accuracy: 23.1771%, Training Loss: 1.4946%\n",
      "Epoch [1/300], Step [7/225], Training Accuracy: 22.9911%, Training Loss: 1.4929%\n",
      "Epoch [1/300], Step [8/225], Training Accuracy: 25.0000%, Training Loss: 1.4821%\n",
      "Epoch [1/300], Step [9/225], Training Accuracy: 24.3056%, Training Loss: 1.4807%\n",
      "Epoch [1/300], Step [10/225], Training Accuracy: 23.9062%, Training Loss: 1.4759%\n",
      "Epoch [1/300], Step [11/225], Training Accuracy: 23.5795%, Training Loss: 1.4716%\n",
      "Epoch [1/300], Step [12/225], Training Accuracy: 24.2188%, Training Loss: 1.4677%\n",
      "Epoch [1/300], Step [13/225], Training Accuracy: 24.7596%, Training Loss: 1.4662%\n",
      "Epoch [1/300], Step [14/225], Training Accuracy: 25.0000%, Training Loss: 1.4616%\n",
      "Epoch [1/300], Step [15/225], Training Accuracy: 25.7292%, Training Loss: 1.4629%\n",
      "Epoch [1/300], Step [16/225], Training Accuracy: 26.0742%, Training Loss: 1.4624%\n",
      "Epoch [1/300], Step [17/225], Training Accuracy: 25.9191%, Training Loss: 1.4639%\n",
      "Epoch [1/300], Step [18/225], Training Accuracy: 26.2153%, Training Loss: 1.4618%\n",
      "Epoch [1/300], Step [19/225], Training Accuracy: 26.0691%, Training Loss: 1.4635%\n",
      "Epoch [1/300], Step [20/225], Training Accuracy: 26.1719%, Training Loss: 1.4628%\n",
      "Epoch [1/300], Step [21/225], Training Accuracy: 26.3393%, Training Loss: 1.4574%\n",
      "Epoch [1/300], Step [22/225], Training Accuracy: 26.5625%, Training Loss: 1.4564%\n",
      "Epoch [1/300], Step [23/225], Training Accuracy: 26.6304%, Training Loss: 1.4544%\n",
      "Epoch [1/300], Step [24/225], Training Accuracy: 26.6276%, Training Loss: 1.4528%\n",
      "Epoch [1/300], Step [25/225], Training Accuracy: 26.5000%, Training Loss: 1.4540%\n",
      "Epoch [1/300], Step [26/225], Training Accuracy: 26.5625%, Training Loss: 1.4521%\n",
      "Epoch [1/300], Step [27/225], Training Accuracy: 26.3889%, Training Loss: 1.4509%\n",
      "Epoch [1/300], Step [28/225], Training Accuracy: 26.3951%, Training Loss: 1.4497%\n",
      "Epoch [1/300], Step [29/225], Training Accuracy: 26.4547%, Training Loss: 1.4478%\n",
      "Epoch [1/300], Step [30/225], Training Accuracy: 26.4062%, Training Loss: 1.4469%\n",
      "Epoch [1/300], Step [31/225], Training Accuracy: 26.1593%, Training Loss: 1.4476%\n",
      "Epoch [1/300], Step [32/225], Training Accuracy: 26.0254%, Training Loss: 1.4462%\n",
      "Epoch [1/300], Step [33/225], Training Accuracy: 25.9470%, Training Loss: 1.4454%\n",
      "Epoch [1/300], Step [34/225], Training Accuracy: 26.0110%, Training Loss: 1.4446%\n",
      "Epoch [1/300], Step [35/225], Training Accuracy: 26.2054%, Training Loss: 1.4446%\n",
      "Epoch [1/300], Step [36/225], Training Accuracy: 26.3889%, Training Loss: 1.4451%\n",
      "Epoch [1/300], Step [37/225], Training Accuracy: 26.1402%, Training Loss: 1.4445%\n",
      "Epoch [1/300], Step [38/225], Training Accuracy: 26.0280%, Training Loss: 1.4439%\n",
      "Epoch [1/300], Step [39/225], Training Accuracy: 25.8814%, Training Loss: 1.4448%\n",
      "Epoch [1/300], Step [40/225], Training Accuracy: 25.6250%, Training Loss: 1.4461%\n",
      "Epoch [1/300], Step [41/225], Training Accuracy: 25.8765%, Training Loss: 1.4437%\n",
      "Epoch [1/300], Step [42/225], Training Accuracy: 25.9673%, Training Loss: 1.4437%\n",
      "Epoch [1/300], Step [43/225], Training Accuracy: 25.9084%, Training Loss: 1.4425%\n",
      "Epoch [1/300], Step [44/225], Training Accuracy: 25.9233%, Training Loss: 1.4415%\n",
      "Epoch [1/300], Step [45/225], Training Accuracy: 26.1111%, Training Loss: 1.4396%\n",
      "Epoch [1/300], Step [46/225], Training Accuracy: 25.9511%, Training Loss: 1.4397%\n",
      "Epoch [1/300], Step [47/225], Training Accuracy: 26.1303%, Training Loss: 1.4375%\n",
      "Epoch [1/300], Step [48/225], Training Accuracy: 26.2370%, Training Loss: 1.4362%\n",
      "Epoch [1/300], Step [49/225], Training Accuracy: 26.2117%, Training Loss: 1.4359%\n",
      "Epoch [1/300], Step [50/225], Training Accuracy: 26.2812%, Training Loss: 1.4349%\n",
      "Epoch [1/300], Step [51/225], Training Accuracy: 26.1642%, Training Loss: 1.4358%\n",
      "Epoch [1/300], Step [52/225], Training Accuracy: 26.1719%, Training Loss: 1.4357%\n",
      "Epoch [1/300], Step [53/225], Training Accuracy: 26.1792%, Training Loss: 1.4359%\n",
      "Epoch [1/300], Step [54/225], Training Accuracy: 26.1863%, Training Loss: 1.4351%\n",
      "Epoch [1/300], Step [55/225], Training Accuracy: 26.2784%, Training Loss: 1.4347%\n",
      "Epoch [1/300], Step [56/225], Training Accuracy: 26.1440%, Training Loss: 1.4352%\n",
      "Epoch [1/300], Step [57/225], Training Accuracy: 26.1513%, Training Loss: 1.4335%\n",
      "Epoch [1/300], Step [58/225], Training Accuracy: 26.2662%, Training Loss: 1.4331%\n",
      "Epoch [1/300], Step [59/225], Training Accuracy: 26.4036%, Training Loss: 1.4314%\n",
      "Epoch [1/300], Step [60/225], Training Accuracy: 26.5625%, Training Loss: 1.4301%\n",
      "Epoch [1/300], Step [61/225], Training Accuracy: 26.6650%, Training Loss: 1.4287%\n",
      "Epoch [1/300], Step [62/225], Training Accuracy: 26.6885%, Training Loss: 1.4286%\n",
      "Epoch [1/300], Step [63/225], Training Accuracy: 26.6865%, Training Loss: 1.4282%\n",
      "Epoch [1/300], Step [64/225], Training Accuracy: 26.8066%, Training Loss: 1.4274%\n",
      "Epoch [1/300], Step [65/225], Training Accuracy: 26.8750%, Training Loss: 1.4260%\n",
      "Epoch [1/300], Step [66/225], Training Accuracy: 27.0123%, Training Loss: 1.4252%\n",
      "Epoch [1/300], Step [67/225], Training Accuracy: 27.1222%, Training Loss: 1.4242%\n",
      "Epoch [1/300], Step [68/225], Training Accuracy: 27.1140%, Training Loss: 1.4244%\n",
      "Epoch [1/300], Step [69/225], Training Accuracy: 27.2192%, Training Loss: 1.4231%\n",
      "Epoch [1/300], Step [70/225], Training Accuracy: 27.2991%, Training Loss: 1.4224%\n",
      "Epoch [1/300], Step [71/225], Training Accuracy: 27.3107%, Training Loss: 1.4223%\n",
      "Epoch [1/300], Step [72/225], Training Accuracy: 27.4306%, Training Loss: 1.4222%\n",
      "Epoch [1/300], Step [73/225], Training Accuracy: 27.5685%, Training Loss: 1.4214%\n",
      "Epoch [1/300], Step [74/225], Training Accuracy: 27.7872%, Training Loss: 1.4198%\n",
      "Epoch [1/300], Step [75/225], Training Accuracy: 27.7292%, Training Loss: 1.4195%\n",
      "Epoch [1/300], Step [76/225], Training Accuracy: 27.7549%, Training Loss: 1.4190%\n",
      "Epoch [1/300], Step [77/225], Training Accuracy: 27.6989%, Training Loss: 1.4193%\n",
      "Epoch [1/300], Step [78/225], Training Accuracy: 27.7043%, Training Loss: 1.4195%\n",
      "Epoch [1/300], Step [79/225], Training Accuracy: 27.6503%, Training Loss: 1.4192%\n",
      "Epoch [1/300], Step [80/225], Training Accuracy: 27.5977%, Training Loss: 1.4191%\n",
      "Epoch [1/300], Step [81/225], Training Accuracy: 27.5463%, Training Loss: 1.4187%\n",
      "Epoch [1/300], Step [82/225], Training Accuracy: 27.5152%, Training Loss: 1.4187%\n",
      "Epoch [1/300], Step [83/225], Training Accuracy: 27.6167%, Training Loss: 1.4183%\n",
      "Epoch [1/300], Step [84/225], Training Accuracy: 27.4740%, Training Loss: 1.4186%\n",
      "Epoch [1/300], Step [85/225], Training Accuracy: 27.4081%, Training Loss: 1.4190%\n",
      "Epoch [1/300], Step [86/225], Training Accuracy: 27.3619%, Training Loss: 1.4193%\n",
      "Epoch [1/300], Step [87/225], Training Accuracy: 27.2989%, Training Loss: 1.4195%\n",
      "Epoch [1/300], Step [88/225], Training Accuracy: 27.2727%, Training Loss: 1.4195%\n",
      "Epoch [1/300], Step [89/225], Training Accuracy: 27.3350%, Training Loss: 1.4190%\n",
      "Epoch [1/300], Step [90/225], Training Accuracy: 27.3611%, Training Loss: 1.4178%\n",
      "Epoch [1/300], Step [91/225], Training Accuracy: 27.4210%, Training Loss: 1.4178%\n",
      "Epoch [1/300], Step [92/225], Training Accuracy: 27.3607%, Training Loss: 1.4175%\n",
      "Epoch [1/300], Step [93/225], Training Accuracy: 27.3353%, Training Loss: 1.4174%\n",
      "Epoch [1/300], Step [94/225], Training Accuracy: 27.3438%, Training Loss: 1.4166%\n",
      "Epoch [1/300], Step [95/225], Training Accuracy: 27.4178%, Training Loss: 1.4160%\n",
      "Epoch [1/300], Step [96/225], Training Accuracy: 27.3600%, Training Loss: 1.4164%\n",
      "Epoch [1/300], Step [97/225], Training Accuracy: 27.3035%, Training Loss: 1.4168%\n",
      "Epoch [1/300], Step [98/225], Training Accuracy: 27.2800%, Training Loss: 1.4163%\n",
      "Epoch [1/300], Step [99/225], Training Accuracy: 27.4306%, Training Loss: 1.4156%\n",
      "Epoch [1/300], Step [100/225], Training Accuracy: 27.4375%, Training Loss: 1.4157%\n",
      "Epoch [1/300], Step [101/225], Training Accuracy: 27.4752%, Training Loss: 1.4154%\n",
      "Epoch [1/300], Step [102/225], Training Accuracy: 27.3897%, Training Loss: 1.4157%\n",
      "Epoch [1/300], Step [103/225], Training Accuracy: 27.5334%, Training Loss: 1.4155%\n",
      "Epoch [1/300], Step [104/225], Training Accuracy: 27.4639%, Training Loss: 1.4152%\n",
      "Epoch [1/300], Step [105/225], Training Accuracy: 27.3810%, Training Loss: 1.4156%\n",
      "Epoch [1/300], Step [106/225], Training Accuracy: 27.4322%, Training Loss: 1.4148%\n",
      "Epoch [1/300], Step [107/225], Training Accuracy: 27.4679%, Training Loss: 1.4142%\n",
      "Epoch [1/300], Step [108/225], Training Accuracy: 27.5318%, Training Loss: 1.4137%\n",
      "Epoch [1/300], Step [109/225], Training Accuracy: 27.5229%, Training Loss: 1.4139%\n",
      "Epoch [1/300], Step [110/225], Training Accuracy: 27.5710%, Training Loss: 1.4135%\n",
      "Epoch [1/300], Step [111/225], Training Accuracy: 27.6323%, Training Loss: 1.4133%\n",
      "Epoch [1/300], Step [112/225], Training Accuracy: 27.6646%, Training Loss: 1.4124%\n",
      "Epoch [1/300], Step [113/225], Training Accuracy: 27.6825%, Training Loss: 1.4121%\n",
      "Epoch [1/300], Step [114/225], Training Accuracy: 27.7138%, Training Loss: 1.4119%\n",
      "Epoch [1/300], Step [115/225], Training Accuracy: 27.7038%, Training Loss: 1.4121%\n",
      "Epoch [1/300], Step [116/225], Training Accuracy: 27.6266%, Training Loss: 1.4122%\n",
      "Epoch [1/300], Step [117/225], Training Accuracy: 27.6709%, Training Loss: 1.4118%\n",
      "Epoch [1/300], Step [118/225], Training Accuracy: 27.6351%, Training Loss: 1.4118%\n",
      "Epoch [1/300], Step [119/225], Training Accuracy: 27.6523%, Training Loss: 1.4119%\n",
      "Epoch [1/300], Step [120/225], Training Accuracy: 27.7214%, Training Loss: 1.4115%\n",
      "Epoch [1/300], Step [121/225], Training Accuracy: 27.6730%, Training Loss: 1.4114%\n",
      "Epoch [1/300], Step [122/225], Training Accuracy: 27.6639%, Training Loss: 1.4112%\n",
      "Epoch [1/300], Step [123/225], Training Accuracy: 27.7439%, Training Loss: 1.4104%\n",
      "Epoch [1/300], Step [124/225], Training Accuracy: 27.7344%, Training Loss: 1.4103%\n",
      "Epoch [1/300], Step [125/225], Training Accuracy: 27.6875%, Training Loss: 1.4106%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Step [126/225], Training Accuracy: 27.6414%, Training Loss: 1.4108%\n",
      "Epoch [1/300], Step [127/225], Training Accuracy: 27.6329%, Training Loss: 1.4107%\n",
      "Epoch [1/300], Step [128/225], Training Accuracy: 27.7100%, Training Loss: 1.4103%\n",
      "Epoch [1/300], Step [129/225], Training Accuracy: 27.6405%, Training Loss: 1.4106%\n",
      "Epoch [1/300], Step [130/225], Training Accuracy: 27.6082%, Training Loss: 1.4106%\n",
      "Epoch [1/300], Step [131/225], Training Accuracy: 27.6837%, Training Loss: 1.4104%\n",
      "Epoch [1/300], Step [132/225], Training Accuracy: 27.6752%, Training Loss: 1.4099%\n",
      "Epoch [1/300], Step [133/225], Training Accuracy: 27.6903%, Training Loss: 1.4101%\n",
      "Epoch [1/300], Step [134/225], Training Accuracy: 27.6003%, Training Loss: 1.4105%\n",
      "Epoch [1/300], Step [135/225], Training Accuracy: 27.6389%, Training Loss: 1.4101%\n",
      "Epoch [1/300], Step [136/225], Training Accuracy: 27.6654%, Training Loss: 1.4100%\n",
      "Epoch [1/300], Step [137/225], Training Accuracy: 27.6688%, Training Loss: 1.4092%\n",
      "Epoch [1/300], Step [138/225], Training Accuracy: 27.6721%, Training Loss: 1.4089%\n",
      "Epoch [1/300], Step [139/225], Training Accuracy: 27.6529%, Training Loss: 1.4089%\n",
      "Epoch [1/300], Step [140/225], Training Accuracy: 27.7121%, Training Loss: 1.4087%\n",
      "Epoch [1/300], Step [141/225], Training Accuracy: 27.7593%, Training Loss: 1.4083%\n",
      "Epoch [1/300], Step [142/225], Training Accuracy: 27.8169%, Training Loss: 1.4076%\n",
      "Epoch [1/300], Step [143/225], Training Accuracy: 27.8409%, Training Loss: 1.4073%\n",
      "Epoch [1/300], Step [144/225], Training Accuracy: 27.8320%, Training Loss: 1.4070%\n",
      "Epoch [1/300], Step [145/225], Training Accuracy: 27.8772%, Training Loss: 1.4067%\n",
      "Epoch [1/300], Step [146/225], Training Accuracy: 27.8789%, Training Loss: 1.4065%\n",
      "Epoch [1/300], Step [147/225], Training Accuracy: 27.9230%, Training Loss: 1.4060%\n",
      "Epoch [1/300], Step [148/225], Training Accuracy: 27.9666%, Training Loss: 1.4059%\n",
      "Epoch [1/300], Step [149/225], Training Accuracy: 27.9782%, Training Loss: 1.4057%\n",
      "Epoch [1/300], Step [150/225], Training Accuracy: 28.0208%, Training Loss: 1.4052%\n",
      "Epoch [1/300], Step [151/225], Training Accuracy: 28.0112%, Training Loss: 1.4050%\n",
      "Epoch [1/300], Step [152/225], Training Accuracy: 28.0222%, Training Loss: 1.4046%\n",
      "Epoch [1/300], Step [153/225], Training Accuracy: 28.0331%, Training Loss: 1.4043%\n",
      "Epoch [1/300], Step [154/225], Training Accuracy: 27.9931%, Training Loss: 1.4047%\n",
      "Epoch [1/300], Step [155/225], Training Accuracy: 27.9839%, Training Loss: 1.4045%\n",
      "Epoch [1/300], Step [156/225], Training Accuracy: 27.9647%, Training Loss: 1.4045%\n",
      "Epoch [1/300], Step [157/225], Training Accuracy: 27.9459%, Training Loss: 1.4044%\n",
      "Epoch [1/300], Step [158/225], Training Accuracy: 27.9668%, Training Loss: 1.4040%\n",
      "Epoch [1/300], Step [159/225], Training Accuracy: 28.0169%, Training Loss: 1.4038%\n",
      "Epoch [1/300], Step [160/225], Training Accuracy: 28.0469%, Training Loss: 1.4034%\n",
      "Epoch [1/300], Step [161/225], Training Accuracy: 28.0474%, Training Loss: 1.4031%\n",
      "Epoch [1/300], Step [162/225], Training Accuracy: 28.0478%, Training Loss: 1.4029%\n",
      "Epoch [1/300], Step [163/225], Training Accuracy: 28.1250%, Training Loss: 1.4024%\n",
      "Epoch [1/300], Step [164/225], Training Accuracy: 28.0774%, Training Loss: 1.4025%\n",
      "Epoch [1/300], Step [165/225], Training Accuracy: 28.0019%, Training Loss: 1.4024%\n",
      "Epoch [1/300], Step [166/225], Training Accuracy: 28.0497%, Training Loss: 1.4018%\n",
      "Epoch [1/300], Step [167/225], Training Accuracy: 28.0782%, Training Loss: 1.4014%\n",
      "Epoch [1/300], Step [168/225], Training Accuracy: 28.0599%, Training Loss: 1.4013%\n",
      "Epoch [1/300], Step [169/225], Training Accuracy: 28.0325%, Training Loss: 1.4014%\n",
      "Epoch [1/300], Step [170/225], Training Accuracy: 28.0147%, Training Loss: 1.4015%\n",
      "Epoch [1/300], Step [171/225], Training Accuracy: 27.9971%, Training Loss: 1.4010%\n",
      "Epoch [1/300], Step [172/225], Training Accuracy: 28.0432%, Training Loss: 1.4008%\n",
      "Epoch [1/300], Step [173/225], Training Accuracy: 28.0166%, Training Loss: 1.4012%\n",
      "Epoch [1/300], Step [174/225], Training Accuracy: 28.0532%, Training Loss: 1.4008%\n",
      "Epoch [1/300], Step [175/225], Training Accuracy: 28.0446%, Training Loss: 1.4010%\n",
      "Epoch [1/300], Step [176/225], Training Accuracy: 28.0273%, Training Loss: 1.4012%\n",
      "Epoch [1/300], Step [177/225], Training Accuracy: 28.0809%, Training Loss: 1.4009%\n",
      "Epoch [1/300], Step [178/225], Training Accuracy: 28.1777%, Training Loss: 1.4002%\n",
      "Epoch [1/300], Step [179/225], Training Accuracy: 28.1948%, Training Loss: 1.4000%\n",
      "Epoch [1/300], Step [180/225], Training Accuracy: 28.2465%, Training Loss: 1.3995%\n",
      "Epoch [1/300], Step [181/225], Training Accuracy: 28.3322%, Training Loss: 1.3991%\n",
      "Epoch [1/300], Step [182/225], Training Accuracy: 28.3053%, Training Loss: 1.3989%\n",
      "Epoch [1/300], Step [183/225], Training Accuracy: 28.2787%, Training Loss: 1.3987%\n",
      "Epoch [1/300], Step [184/225], Training Accuracy: 28.2439%, Training Loss: 1.3988%\n",
      "Epoch [1/300], Step [185/225], Training Accuracy: 28.2770%, Training Loss: 1.3986%\n",
      "Epoch [1/300], Step [186/225], Training Accuracy: 28.3182%, Training Loss: 1.3983%\n",
      "Epoch [1/300], Step [187/225], Training Accuracy: 28.3172%, Training Loss: 1.3982%\n",
      "Epoch [1/300], Step [188/225], Training Accuracy: 28.3245%, Training Loss: 1.3980%\n",
      "Epoch [1/300], Step [189/225], Training Accuracy: 28.3730%, Training Loss: 1.3976%\n",
      "Epoch [1/300], Step [190/225], Training Accuracy: 28.3882%, Training Loss: 1.3972%\n",
      "Epoch [1/300], Step [191/225], Training Accuracy: 28.3704%, Training Loss: 1.3972%\n",
      "Epoch [1/300], Step [192/225], Training Accuracy: 28.3773%, Training Loss: 1.3973%\n",
      "Epoch [1/300], Step [193/225], Training Accuracy: 28.3679%, Training Loss: 1.3974%\n",
      "Epoch [1/300], Step [194/225], Training Accuracy: 28.4230%, Training Loss: 1.3966%\n",
      "Epoch [1/300], Step [195/225], Training Accuracy: 28.4375%, Training Loss: 1.3966%\n",
      "Epoch [1/300], Step [196/225], Training Accuracy: 28.4279%, Training Loss: 1.3965%\n",
      "Epoch [1/300], Step [197/225], Training Accuracy: 28.4661%, Training Loss: 1.3963%\n",
      "Epoch [1/300], Step [198/225], Training Accuracy: 28.5196%, Training Loss: 1.3959%\n",
      "Epoch [1/300], Step [199/225], Training Accuracy: 28.5411%, Training Loss: 1.3955%\n",
      "Epoch [1/300], Step [200/225], Training Accuracy: 28.5703%, Training Loss: 1.3953%\n",
      "Epoch [1/300], Step [201/225], Training Accuracy: 28.5759%, Training Loss: 1.3950%\n",
      "Epoch [1/300], Step [202/225], Training Accuracy: 28.5659%, Training Loss: 1.3948%\n",
      "Epoch [1/300], Step [203/225], Training Accuracy: 28.5406%, Training Loss: 1.3947%\n",
      "Epoch [1/300], Step [204/225], Training Accuracy: 28.5769%, Training Loss: 1.3944%\n",
      "Epoch [1/300], Step [205/225], Training Accuracy: 28.5823%, Training Loss: 1.3944%\n",
      "Epoch [1/300], Step [206/225], Training Accuracy: 28.6180%, Training Loss: 1.3941%\n",
      "Epoch [1/300], Step [207/225], Training Accuracy: 28.6232%, Training Loss: 1.3939%\n",
      "Epoch [1/300], Step [208/225], Training Accuracy: 28.6358%, Training Loss: 1.3935%\n",
      "Epoch [1/300], Step [209/225], Training Accuracy: 28.6558%, Training Loss: 1.3935%\n",
      "Epoch [1/300], Step [210/225], Training Accuracy: 28.6310%, Training Loss: 1.3935%\n",
      "Epoch [1/300], Step [211/225], Training Accuracy: 28.6582%, Training Loss: 1.3931%\n",
      "Epoch [1/300], Step [212/225], Training Accuracy: 28.6925%, Training Loss: 1.3927%\n",
      "Epoch [1/300], Step [213/225], Training Accuracy: 28.6972%, Training Loss: 1.3925%\n",
      "Epoch [1/300], Step [214/225], Training Accuracy: 28.7456%, Training Loss: 1.3920%\n",
      "Epoch [1/300], Step [215/225], Training Accuracy: 28.7355%, Training Loss: 1.3920%\n",
      "Epoch [1/300], Step [216/225], Training Accuracy: 28.7688%, Training Loss: 1.3916%\n",
      "Epoch [1/300], Step [217/225], Training Accuracy: 28.7802%, Training Loss: 1.3913%\n",
      "Epoch [1/300], Step [218/225], Training Accuracy: 28.7557%, Training Loss: 1.3915%\n",
      "Epoch [1/300], Step [219/225], Training Accuracy: 28.7814%, Training Loss: 1.3911%\n",
      "Epoch [1/300], Step [220/225], Training Accuracy: 28.8494%, Training Loss: 1.3904%\n",
      "Epoch [1/300], Step [221/225], Training Accuracy: 28.8532%, Training Loss: 1.3905%\n",
      "Epoch [1/300], Step [222/225], Training Accuracy: 28.8922%, Training Loss: 1.3904%\n",
      "Epoch [1/300], Step [223/225], Training Accuracy: 28.9168%, Training Loss: 1.3903%\n",
      "Epoch [1/300], Step [224/225], Training Accuracy: 28.9202%, Training Loss: 1.3902%\n",
      "Epoch [1/300], Step [225/225], Training Accuracy: 28.9119%, Training Loss: 1.3905%\n",
      "Epoch [2/300], Step [1/225], Training Accuracy: 35.9375%, Training Loss: 1.3050%\n",
      "Epoch [2/300], Step [2/225], Training Accuracy: 36.7188%, Training Loss: 1.3000%\n",
      "Epoch [2/300], Step [3/225], Training Accuracy: 32.8125%, Training Loss: 1.3332%\n",
      "Epoch [2/300], Step [4/225], Training Accuracy: 32.0312%, Training Loss: 1.3236%\n",
      "Epoch [2/300], Step [5/225], Training Accuracy: 30.6250%, Training Loss: 1.3446%\n",
      "Epoch [2/300], Step [6/225], Training Accuracy: 29.4271%, Training Loss: 1.3384%\n",
      "Epoch [2/300], Step [7/225], Training Accuracy: 28.7946%, Training Loss: 1.3440%\n",
      "Epoch [2/300], Step [8/225], Training Accuracy: 28.9062%, Training Loss: 1.3433%\n",
      "Epoch [2/300], Step [9/225], Training Accuracy: 29.3403%, Training Loss: 1.3458%\n",
      "Epoch [2/300], Step [10/225], Training Accuracy: 29.6875%, Training Loss: 1.3463%\n",
      "Epoch [2/300], Step [11/225], Training Accuracy: 29.2614%, Training Loss: 1.3446%\n",
      "Epoch [2/300], Step [12/225], Training Accuracy: 29.5573%, Training Loss: 1.3463%\n",
      "Epoch [2/300], Step [13/225], Training Accuracy: 30.1683%, Training Loss: 1.3451%\n",
      "Epoch [2/300], Step [14/225], Training Accuracy: 30.1339%, Training Loss: 1.3502%\n",
      "Epoch [2/300], Step [15/225], Training Accuracy: 30.0000%, Training Loss: 1.3523%\n",
      "Epoch [2/300], Step [16/225], Training Accuracy: 30.2734%, Training Loss: 1.3497%\n",
      "Epoch [2/300], Step [17/225], Training Accuracy: 30.6066%, Training Loss: 1.3490%\n",
      "Epoch [2/300], Step [18/225], Training Accuracy: 30.3819%, Training Loss: 1.3522%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/300], Step [19/225], Training Accuracy: 30.0164%, Training Loss: 1.3563%\n",
      "Epoch [2/300], Step [20/225], Training Accuracy: 30.3125%, Training Loss: 1.3554%\n",
      "Epoch [2/300], Step [21/225], Training Accuracy: 30.7292%, Training Loss: 1.3542%\n",
      "Epoch [2/300], Step [22/225], Training Accuracy: 31.1080%, Training Loss: 1.3531%\n",
      "Epoch [2/300], Step [23/225], Training Accuracy: 31.3859%, Training Loss: 1.3515%\n",
      "Epoch [2/300], Step [24/225], Training Accuracy: 31.4453%, Training Loss: 1.3497%\n",
      "Epoch [2/300], Step [25/225], Training Accuracy: 31.8750%, Training Loss: 1.3470%\n",
      "Epoch [2/300], Step [26/225], Training Accuracy: 31.9111%, Training Loss: 1.3454%\n",
      "Epoch [2/300], Step [27/225], Training Accuracy: 32.1181%, Training Loss: 1.3457%\n",
      "Epoch [2/300], Step [28/225], Training Accuracy: 32.3103%, Training Loss: 1.3440%\n",
      "Epoch [2/300], Step [29/225], Training Accuracy: 32.1659%, Training Loss: 1.3436%\n",
      "Epoch [2/300], Step [30/225], Training Accuracy: 32.2917%, Training Loss: 1.3428%\n",
      "Epoch [2/300], Step [31/225], Training Accuracy: 32.2077%, Training Loss: 1.3431%\n",
      "Epoch [2/300], Step [32/225], Training Accuracy: 32.2754%, Training Loss: 1.3423%\n",
      "Epoch [2/300], Step [33/225], Training Accuracy: 32.4337%, Training Loss: 1.3405%\n",
      "Epoch [2/300], Step [34/225], Training Accuracy: 32.4449%, Training Loss: 1.3416%\n",
      "Epoch [2/300], Step [35/225], Training Accuracy: 32.3661%, Training Loss: 1.3437%\n",
      "Epoch [2/300], Step [36/225], Training Accuracy: 32.1615%, Training Loss: 1.3463%\n",
      "Epoch [2/300], Step [37/225], Training Accuracy: 32.3057%, Training Loss: 1.3454%\n",
      "Epoch [2/300], Step [38/225], Training Accuracy: 32.1546%, Training Loss: 1.3456%\n",
      "Epoch [2/300], Step [39/225], Training Accuracy: 32.1314%, Training Loss: 1.3443%\n",
      "Epoch [2/300], Step [40/225], Training Accuracy: 32.1875%, Training Loss: 1.3449%\n",
      "Epoch [2/300], Step [41/225], Training Accuracy: 32.1265%, Training Loss: 1.3446%\n",
      "Epoch [2/300], Step [42/225], Training Accuracy: 32.0685%, Training Loss: 1.3461%\n",
      "Epoch [2/300], Step [43/225], Training Accuracy: 32.0858%, Training Loss: 1.3467%\n",
      "Epoch [2/300], Step [44/225], Training Accuracy: 32.2088%, Training Loss: 1.3450%\n",
      "Epoch [2/300], Step [45/225], Training Accuracy: 32.1875%, Training Loss: 1.3451%\n",
      "Epoch [2/300], Step [46/225], Training Accuracy: 32.2351%, Training Loss: 1.3450%\n",
      "Epoch [2/300], Step [47/225], Training Accuracy: 32.1476%, Training Loss: 1.3458%\n",
      "Epoch [2/300], Step [48/225], Training Accuracy: 32.1615%, Training Loss: 1.3449%\n",
      "Epoch [2/300], Step [49/225], Training Accuracy: 32.2704%, Training Loss: 1.3440%\n",
      "Epoch [2/300], Step [50/225], Training Accuracy: 32.2812%, Training Loss: 1.3441%\n",
      "Epoch [2/300], Step [51/225], Training Accuracy: 32.0772%, Training Loss: 1.3450%\n",
      "Epoch [2/300], Step [52/225], Training Accuracy: 32.1214%, Training Loss: 1.3439%\n",
      "Epoch [2/300], Step [53/225], Training Accuracy: 31.9870%, Training Loss: 1.3439%\n",
      "Epoch [2/300], Step [54/225], Training Accuracy: 32.0023%, Training Loss: 1.3444%\n",
      "Epoch [2/300], Step [55/225], Training Accuracy: 32.1591%, Training Loss: 1.3442%\n",
      "Epoch [2/300], Step [56/225], Training Accuracy: 32.1429%, Training Loss: 1.3442%\n",
      "Epoch [2/300], Step [57/225], Training Accuracy: 32.2094%, Training Loss: 1.3433%\n",
      "Epoch [2/300], Step [58/225], Training Accuracy: 32.1659%, Training Loss: 1.3430%\n",
      "Epoch [2/300], Step [59/225], Training Accuracy: 32.2828%, Training Loss: 1.3411%\n",
      "Epoch [2/300], Step [60/225], Training Accuracy: 32.2135%, Training Loss: 1.3406%\n",
      "Epoch [2/300], Step [61/225], Training Accuracy: 32.2490%, Training Loss: 1.3407%\n",
      "Epoch [2/300], Step [62/225], Training Accuracy: 32.2581%, Training Loss: 1.3417%\n",
      "Epoch [2/300], Step [63/225], Training Accuracy: 32.2669%, Training Loss: 1.3418%\n",
      "Epoch [2/300], Step [64/225], Training Accuracy: 32.3486%, Training Loss: 1.3418%\n",
      "Epoch [2/300], Step [65/225], Training Accuracy: 32.3317%, Training Loss: 1.3416%\n",
      "Epoch [2/300], Step [66/225], Training Accuracy: 32.5047%, Training Loss: 1.3404%\n",
      "Epoch [2/300], Step [67/225], Training Accuracy: 32.5326%, Training Loss: 1.3397%\n",
      "Epoch [2/300], Step [68/225], Training Accuracy: 32.3989%, Training Loss: 1.3401%\n",
      "Epoch [2/300], Step [69/225], Training Accuracy: 32.4955%, Training Loss: 1.3390%\n",
      "Epoch [2/300], Step [70/225], Training Accuracy: 32.4777%, Training Loss: 1.3396%\n",
      "Epoch [2/300], Step [71/225], Training Accuracy: 32.5484%, Training Loss: 1.3394%\n",
      "Epoch [2/300], Step [72/225], Training Accuracy: 32.4219%, Training Loss: 1.3404%\n",
      "Epoch [2/300], Step [73/225], Training Accuracy: 32.4486%, Training Loss: 1.3404%\n",
      "Epoch [2/300], Step [74/225], Training Accuracy: 32.6225%, Training Loss: 1.3386%\n",
      "Epoch [2/300], Step [75/225], Training Accuracy: 32.5625%, Training Loss: 1.3383%\n",
      "Epoch [2/300], Step [76/225], Training Accuracy: 32.6069%, Training Loss: 1.3378%\n",
      "Epoch [2/300], Step [77/225], Training Accuracy: 32.6299%, Training Loss: 1.3386%\n",
      "Epoch [2/300], Step [78/225], Training Accuracy: 32.5921%, Training Loss: 1.3385%\n",
      "Epoch [2/300], Step [79/225], Training Accuracy: 32.6543%, Training Loss: 1.3381%\n",
      "Epoch [2/300], Step [80/225], Training Accuracy: 32.5391%, Training Loss: 1.3385%\n",
      "Epoch [2/300], Step [81/225], Training Accuracy: 32.5039%, Training Loss: 1.3389%\n",
      "Epoch [2/300], Step [82/225], Training Accuracy: 32.6220%, Training Loss: 1.3388%\n",
      "Epoch [2/300], Step [83/225], Training Accuracy: 32.6431%, Training Loss: 1.3386%\n",
      "Epoch [2/300], Step [84/225], Training Accuracy: 32.6079%, Training Loss: 1.3383%\n",
      "Epoch [2/300], Step [85/225], Training Accuracy: 32.6471%, Training Loss: 1.3385%\n",
      "Epoch [2/300], Step [86/225], Training Accuracy: 32.5400%, Training Loss: 1.3390%\n",
      "Epoch [2/300], Step [87/225], Training Accuracy: 32.5251%, Training Loss: 1.3392%\n",
      "Epoch [2/300], Step [88/225], Training Accuracy: 32.4396%, Training Loss: 1.3394%\n",
      "Epoch [2/300], Step [89/225], Training Accuracy: 32.3385%, Training Loss: 1.3394%\n",
      "Epoch [2/300], Step [90/225], Training Accuracy: 32.4306%, Training Loss: 1.3384%\n",
      "Epoch [2/300], Step [91/225], Training Accuracy: 32.4348%, Training Loss: 1.3382%\n",
      "Epoch [2/300], Step [92/225], Training Accuracy: 32.4389%, Training Loss: 1.3388%\n",
      "Epoch [2/300], Step [93/225], Training Accuracy: 32.4429%, Training Loss: 1.3393%\n",
      "Epoch [2/300], Step [94/225], Training Accuracy: 32.4634%, Training Loss: 1.3391%\n",
      "Epoch [2/300], Step [95/225], Training Accuracy: 32.3849%, Training Loss: 1.3395%\n",
      "Epoch [2/300], Step [96/225], Training Accuracy: 32.3405%, Training Loss: 1.3396%\n",
      "Epoch [2/300], Step [97/225], Training Accuracy: 32.4420%, Training Loss: 1.3395%\n",
      "Epoch [2/300], Step [98/225], Training Accuracy: 32.4139%, Training Loss: 1.3392%\n",
      "Epoch [2/300], Step [99/225], Training Accuracy: 32.4968%, Training Loss: 1.3384%\n",
      "Epoch [2/300], Step [100/225], Training Accuracy: 32.5156%, Training Loss: 1.3378%\n",
      "Epoch [2/300], Step [101/225], Training Accuracy: 32.5650%, Training Loss: 1.3373%\n",
      "Epoch [2/300], Step [102/225], Training Accuracy: 32.5214%, Training Loss: 1.3377%\n",
      "Epoch [2/300], Step [103/225], Training Accuracy: 32.4939%, Training Loss: 1.3384%\n",
      "Epoch [2/300], Step [104/225], Training Accuracy: 32.4820%, Training Loss: 1.3382%\n",
      "Epoch [2/300], Step [105/225], Training Accuracy: 32.4256%, Training Loss: 1.3386%\n",
      "Epoch [2/300], Step [106/225], Training Accuracy: 32.4735%, Training Loss: 1.3380%\n",
      "Epoch [2/300], Step [107/225], Training Accuracy: 32.4766%, Training Loss: 1.3383%\n",
      "Epoch [2/300], Step [108/225], Training Accuracy: 32.4942%, Training Loss: 1.3384%\n",
      "Epoch [2/300], Step [109/225], Training Accuracy: 32.5401%, Training Loss: 1.3383%\n",
      "Epoch [2/300], Step [110/225], Training Accuracy: 32.5142%, Training Loss: 1.3385%\n",
      "Epoch [2/300], Step [111/225], Training Accuracy: 32.4887%, Training Loss: 1.3388%\n",
      "Epoch [2/300], Step [112/225], Training Accuracy: 32.5195%, Training Loss: 1.3384%\n",
      "Epoch [2/300], Step [113/225], Training Accuracy: 32.5636%, Training Loss: 1.3383%\n",
      "Epoch [2/300], Step [114/225], Training Accuracy: 32.5932%, Training Loss: 1.3377%\n",
      "Epoch [2/300], Step [115/225], Training Accuracy: 32.6223%, Training Loss: 1.3378%\n",
      "Epoch [2/300], Step [116/225], Training Accuracy: 32.6374%, Training Loss: 1.3378%\n",
      "Epoch [2/300], Step [117/225], Training Accuracy: 32.5588%, Training Loss: 1.3383%\n",
      "Epoch [2/300], Step [118/225], Training Accuracy: 32.4815%, Training Loss: 1.3388%\n",
      "Epoch [2/300], Step [119/225], Training Accuracy: 32.4580%, Training Loss: 1.3388%\n",
      "Epoch [2/300], Step [120/225], Training Accuracy: 32.4609%, Training Loss: 1.3386%\n",
      "Epoch [2/300], Step [121/225], Training Accuracy: 32.3864%, Training Loss: 1.3389%\n",
      "Epoch [2/300], Step [122/225], Training Accuracy: 32.3514%, Training Loss: 1.3394%\n",
      "Epoch [2/300], Step [123/225], Training Accuracy: 32.3933%, Training Loss: 1.3393%\n",
      "Epoch [2/300], Step [124/225], Training Accuracy: 32.3337%, Training Loss: 1.3397%\n",
      "Epoch [2/300], Step [125/225], Training Accuracy: 32.2625%, Training Loss: 1.3406%\n",
      "Epoch [2/300], Step [126/225], Training Accuracy: 32.1925%, Training Loss: 1.3411%\n",
      "Epoch [2/300], Step [127/225], Training Accuracy: 32.2096%, Training Loss: 1.3414%\n",
      "Epoch [2/300], Step [128/225], Training Accuracy: 32.2021%, Training Loss: 1.3413%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/300], Step [129/225], Training Accuracy: 32.1827%, Training Loss: 1.3415%\n",
      "Epoch [2/300], Step [130/225], Training Accuracy: 32.1274%, Training Loss: 1.3417%\n",
      "Epoch [2/300], Step [131/225], Training Accuracy: 32.1326%, Training Loss: 1.3418%\n",
      "Epoch [2/300], Step [132/225], Training Accuracy: 32.0786%, Training Loss: 1.3419%\n",
      "Epoch [2/300], Step [133/225], Training Accuracy: 32.1311%, Training Loss: 1.3420%\n",
      "Epoch [2/300], Step [134/225], Training Accuracy: 32.1129%, Training Loss: 1.3425%\n",
      "Epoch [2/300], Step [135/225], Training Accuracy: 32.1412%, Training Loss: 1.3423%\n",
      "Epoch [2/300], Step [136/225], Training Accuracy: 32.1806%, Training Loss: 1.3421%\n",
      "Epoch [2/300], Step [137/225], Training Accuracy: 32.1966%, Training Loss: 1.3419%\n",
      "Epoch [2/300], Step [138/225], Training Accuracy: 32.1671%, Training Loss: 1.3418%\n",
      "Epoch [2/300], Step [139/225], Training Accuracy: 32.1156%, Training Loss: 1.3421%\n",
      "Epoch [2/300], Step [140/225], Training Accuracy: 32.1987%, Training Loss: 1.3416%\n",
      "Epoch [2/300], Step [141/225], Training Accuracy: 32.2806%, Training Loss: 1.3414%\n",
      "Epoch [2/300], Step [142/225], Training Accuracy: 32.2733%, Training Loss: 1.3410%\n",
      "Epoch [2/300], Step [143/225], Training Accuracy: 32.3427%, Training Loss: 1.3408%\n",
      "Epoch [2/300], Step [144/225], Training Accuracy: 32.3351%, Training Loss: 1.3408%\n",
      "Epoch [2/300], Step [145/225], Training Accuracy: 32.3599%, Training Loss: 1.3407%\n",
      "Epoch [2/300], Step [146/225], Training Accuracy: 32.3844%, Training Loss: 1.3408%\n",
      "Epoch [2/300], Step [147/225], Training Accuracy: 32.3448%, Training Loss: 1.3406%\n",
      "Epoch [2/300], Step [148/225], Training Accuracy: 32.4113%, Training Loss: 1.3403%\n",
      "Epoch [2/300], Step [149/225], Training Accuracy: 32.4455%, Training Loss: 1.3403%\n",
      "Epoch [2/300], Step [150/225], Training Accuracy: 32.4792%, Training Loss: 1.3399%\n",
      "Epoch [2/300], Step [151/225], Training Accuracy: 32.5124%, Training Loss: 1.3397%\n",
      "Epoch [2/300], Step [152/225], Training Accuracy: 32.5452%, Training Loss: 1.3398%\n",
      "Epoch [2/300], Step [153/225], Training Accuracy: 32.5061%, Training Loss: 1.3399%\n",
      "Epoch [2/300], Step [154/225], Training Accuracy: 32.4878%, Training Loss: 1.3397%\n",
      "Epoch [2/300], Step [155/225], Training Accuracy: 32.4798%, Training Loss: 1.3397%\n",
      "Epoch [2/300], Step [156/225], Training Accuracy: 32.4920%, Training Loss: 1.3396%\n",
      "Epoch [2/300], Step [157/225], Training Accuracy: 32.4443%, Training Loss: 1.3396%\n",
      "Epoch [2/300], Step [158/225], Training Accuracy: 32.4664%, Training Loss: 1.3395%\n",
      "Epoch [2/300], Step [159/225], Training Accuracy: 32.5275%, Training Loss: 1.3390%\n",
      "Epoch [2/300], Step [160/225], Training Accuracy: 32.5000%, Training Loss: 1.3389%\n",
      "Epoch [2/300], Step [161/225], Training Accuracy: 32.5214%, Training Loss: 1.3385%\n",
      "Epoch [2/300], Step [162/225], Training Accuracy: 32.5617%, Training Loss: 1.3382%\n",
      "Epoch [2/300], Step [163/225], Training Accuracy: 32.5633%, Training Loss: 1.3378%\n",
      "Epoch [2/300], Step [164/225], Training Accuracy: 32.5743%, Training Loss: 1.3375%\n",
      "Epoch [2/300], Step [165/225], Training Accuracy: 32.5663%, Training Loss: 1.3378%\n",
      "Epoch [2/300], Step [166/225], Training Accuracy: 32.5960%, Training Loss: 1.3374%\n",
      "Epoch [2/300], Step [167/225], Training Accuracy: 32.6160%, Training Loss: 1.3373%\n",
      "Epoch [2/300], Step [168/225], Training Accuracy: 32.6265%, Training Loss: 1.3370%\n",
      "Epoch [2/300], Step [169/225], Training Accuracy: 32.5999%, Training Loss: 1.3372%\n",
      "Epoch [2/300], Step [170/225], Training Accuracy: 32.5460%, Training Loss: 1.3375%\n",
      "Epoch [2/300], Step [171/225], Training Accuracy: 32.5475%, Training Loss: 1.3373%\n",
      "Epoch [2/300], Step [172/225], Training Accuracy: 32.5763%, Training Loss: 1.3371%\n",
      "Epoch [2/300], Step [173/225], Training Accuracy: 32.5596%, Training Loss: 1.3373%\n",
      "Epoch [2/300], Step [174/225], Training Accuracy: 32.5700%, Training Loss: 1.3371%\n",
      "Epoch [2/300], Step [175/225], Training Accuracy: 32.5714%, Training Loss: 1.3369%\n",
      "Epoch [2/300], Step [176/225], Training Accuracy: 32.5728%, Training Loss: 1.3371%\n",
      "Epoch [2/300], Step [177/225], Training Accuracy: 32.6095%, Training Loss: 1.3368%\n",
      "Epoch [2/300], Step [178/225], Training Accuracy: 32.6633%, Training Loss: 1.3362%\n",
      "Epoch [2/300], Step [179/225], Training Accuracy: 32.6728%, Training Loss: 1.3359%\n",
      "Epoch [2/300], Step [180/225], Training Accuracy: 32.6823%, Training Loss: 1.3357%\n",
      "Epoch [2/300], Step [181/225], Training Accuracy: 32.7089%, Training Loss: 1.3356%\n",
      "Epoch [2/300], Step [182/225], Training Accuracy: 32.6923%, Training Loss: 1.3358%\n",
      "Epoch [2/300], Step [183/225], Training Accuracy: 32.7186%, Training Loss: 1.3355%\n",
      "Epoch [2/300], Step [184/225], Training Accuracy: 32.6512%, Training Loss: 1.3358%\n",
      "Epoch [2/300], Step [185/225], Training Accuracy: 32.6182%, Training Loss: 1.3362%\n",
      "Epoch [2/300], Step [186/225], Training Accuracy: 32.6613%, Training Loss: 1.3359%\n",
      "Epoch [2/300], Step [187/225], Training Accuracy: 32.6872%, Training Loss: 1.3359%\n",
      "Epoch [2/300], Step [188/225], Training Accuracy: 32.7128%, Training Loss: 1.3357%\n",
      "Epoch [2/300], Step [189/225], Training Accuracy: 32.7877%, Training Loss: 1.3353%\n",
      "Epoch [2/300], Step [190/225], Training Accuracy: 32.8454%, Training Loss: 1.3348%\n",
      "Epoch [2/300], Step [191/225], Training Accuracy: 32.8289%, Training Loss: 1.3349%\n",
      "Epoch [2/300], Step [192/225], Training Accuracy: 32.8125%, Training Loss: 1.3350%\n",
      "Epoch [2/300], Step [193/225], Training Accuracy: 32.7801%, Training Loss: 1.3351%\n",
      "Epoch [2/300], Step [194/225], Training Accuracy: 32.8206%, Training Loss: 1.3346%\n",
      "Epoch [2/300], Step [195/225], Training Accuracy: 32.7965%, Training Loss: 1.3346%\n",
      "Epoch [2/300], Step [196/225], Training Accuracy: 32.7806%, Training Loss: 1.3347%\n",
      "Epoch [2/300], Step [197/225], Training Accuracy: 32.8046%, Training Loss: 1.3347%\n",
      "Epoch [2/300], Step [198/225], Training Accuracy: 32.8520%, Training Loss: 1.3340%\n",
      "Epoch [2/300], Step [199/225], Training Accuracy: 32.9303%, Training Loss: 1.3337%\n",
      "Epoch [2/300], Step [200/225], Training Accuracy: 32.9609%, Training Loss: 1.3336%\n",
      "Epoch [2/300], Step [201/225], Training Accuracy: 32.9602%, Training Loss: 1.3334%\n",
      "Epoch [2/300], Step [202/225], Training Accuracy: 33.0213%, Training Loss: 1.3330%\n",
      "Epoch [2/300], Step [203/225], Training Accuracy: 32.9587%, Training Loss: 1.3332%\n",
      "Epoch [2/300], Step [204/225], Training Accuracy: 33.0116%, Training Loss: 1.3328%\n",
      "Epoch [2/300], Step [205/225], Training Accuracy: 33.0107%, Training Loss: 1.3330%\n",
      "Epoch [2/300], Step [206/225], Training Accuracy: 33.0097%, Training Loss: 1.3329%\n",
      "Epoch [2/300], Step [207/225], Training Accuracy: 33.0389%, Training Loss: 1.3326%\n",
      "Epoch [2/300], Step [208/225], Training Accuracy: 33.0303%, Training Loss: 1.3324%\n",
      "Epoch [2/300], Step [209/225], Training Accuracy: 33.0368%, Training Loss: 1.3322%\n",
      "Epoch [2/300], Step [210/225], Training Accuracy: 33.0729%, Training Loss: 1.3321%\n",
      "Epoch [2/300], Step [211/225], Training Accuracy: 33.1383%, Training Loss: 1.3316%\n",
      "Epoch [2/300], Step [212/225], Training Accuracy: 33.1073%, Training Loss: 1.3316%\n",
      "Epoch [2/300], Step [213/225], Training Accuracy: 33.1279%, Training Loss: 1.3315%\n",
      "Epoch [2/300], Step [214/225], Training Accuracy: 33.1338%, Training Loss: 1.3312%\n",
      "Epoch [2/300], Step [215/225], Training Accuracy: 33.1395%, Training Loss: 1.3310%\n",
      "Epoch [2/300], Step [216/225], Training Accuracy: 33.1670%, Training Loss: 1.3310%\n",
      "Epoch [2/300], Step [217/225], Training Accuracy: 33.1941%, Training Loss: 1.3306%\n",
      "Epoch [2/300], Step [218/225], Training Accuracy: 33.1637%, Training Loss: 1.3309%\n",
      "Epoch [2/300], Step [219/225], Training Accuracy: 33.2120%, Training Loss: 1.3306%\n",
      "Epoch [2/300], Step [220/225], Training Accuracy: 33.2670%, Training Loss: 1.3299%\n",
      "Epoch [2/300], Step [221/225], Training Accuracy: 33.2438%, Training Loss: 1.3302%\n",
      "Epoch [2/300], Step [222/225], Training Accuracy: 33.2278%, Training Loss: 1.3302%\n",
      "Epoch [2/300], Step [223/225], Training Accuracy: 33.2049%, Training Loss: 1.3301%\n",
      "Epoch [2/300], Step [224/225], Training Accuracy: 33.2450%, Training Loss: 1.3300%\n",
      "Epoch [2/300], Step [225/225], Training Accuracy: 33.2268%, Training Loss: 1.3300%\n",
      "Epoch [3/300], Step [1/225], Training Accuracy: 37.5000%, Training Loss: 1.3117%\n",
      "Epoch [3/300], Step [2/225], Training Accuracy: 39.8438%, Training Loss: 1.3055%\n",
      "Epoch [3/300], Step [3/225], Training Accuracy: 35.4167%, Training Loss: 1.3401%\n",
      "Epoch [3/300], Step [4/225], Training Accuracy: 32.0312%, Training Loss: 1.3385%\n",
      "Epoch [3/300], Step [5/225], Training Accuracy: 31.5625%, Training Loss: 1.3613%\n",
      "Epoch [3/300], Step [6/225], Training Accuracy: 32.2917%, Training Loss: 1.3533%\n",
      "Epoch [3/300], Step [7/225], Training Accuracy: 32.8125%, Training Loss: 1.3436%\n",
      "Epoch [3/300], Step [8/225], Training Accuracy: 33.5938%, Training Loss: 1.3328%\n",
      "Epoch [3/300], Step [9/225], Training Accuracy: 34.8958%, Training Loss: 1.3322%\n",
      "Epoch [3/300], Step [10/225], Training Accuracy: 35.0000%, Training Loss: 1.3303%\n",
      "Epoch [3/300], Step [11/225], Training Accuracy: 34.8011%, Training Loss: 1.3271%\n",
      "Epoch [3/300], Step [12/225], Training Accuracy: 35.2865%, Training Loss: 1.3287%\n",
      "Epoch [3/300], Step [13/225], Training Accuracy: 35.3365%, Training Loss: 1.3283%\n",
      "Epoch [3/300], Step [14/225], Training Accuracy: 35.3795%, Training Loss: 1.3337%\n",
      "Epoch [3/300], Step [15/225], Training Accuracy: 35.2083%, Training Loss: 1.3350%\n",
      "Epoch [3/300], Step [16/225], Training Accuracy: 35.7422%, Training Loss: 1.3307%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/300], Step [17/225], Training Accuracy: 36.0294%, Training Loss: 1.3291%\n",
      "Epoch [3/300], Step [18/225], Training Accuracy: 35.8507%, Training Loss: 1.3295%\n",
      "Epoch [3/300], Step [19/225], Training Accuracy: 35.4441%, Training Loss: 1.3330%\n",
      "Epoch [3/300], Step [20/225], Training Accuracy: 35.2344%, Training Loss: 1.3325%\n",
      "Epoch [3/300], Step [21/225], Training Accuracy: 36.0863%, Training Loss: 1.3276%\n",
      "Epoch [3/300], Step [22/225], Training Accuracy: 36.1506%, Training Loss: 1.3240%\n",
      "Epoch [3/300], Step [23/225], Training Accuracy: 36.0054%, Training Loss: 1.3236%\n",
      "Epoch [3/300], Step [24/225], Training Accuracy: 35.6120%, Training Loss: 1.3227%\n",
      "Epoch [3/300], Step [25/225], Training Accuracy: 35.5625%, Training Loss: 1.3227%\n",
      "Epoch [3/300], Step [26/225], Training Accuracy: 35.8774%, Training Loss: 1.3205%\n",
      "Epoch [3/300], Step [27/225], Training Accuracy: 35.7639%, Training Loss: 1.3191%\n",
      "Epoch [3/300], Step [28/225], Training Accuracy: 35.9375%, Training Loss: 1.3168%\n",
      "Epoch [3/300], Step [29/225], Training Accuracy: 36.0991%, Training Loss: 1.3138%\n",
      "Epoch [3/300], Step [30/225], Training Accuracy: 36.0417%, Training Loss: 1.3128%\n",
      "Epoch [3/300], Step [31/225], Training Accuracy: 35.7863%, Training Loss: 1.3133%\n",
      "Epoch [3/300], Step [32/225], Training Accuracy: 35.9375%, Training Loss: 1.3112%\n",
      "Epoch [3/300], Step [33/225], Training Accuracy: 36.0322%, Training Loss: 1.3093%\n",
      "Epoch [3/300], Step [34/225], Training Accuracy: 35.8456%, Training Loss: 1.3098%\n",
      "Epoch [3/300], Step [35/225], Training Accuracy: 35.7143%, Training Loss: 1.3123%\n",
      "Epoch [3/300], Step [36/225], Training Accuracy: 35.6337%, Training Loss: 1.3146%\n",
      "Epoch [3/300], Step [37/225], Training Accuracy: 35.8108%, Training Loss: 1.3144%\n",
      "Epoch [3/300], Step [38/225], Training Accuracy: 35.8553%, Training Loss: 1.3138%\n",
      "Epoch [3/300], Step [39/225], Training Accuracy: 35.9776%, Training Loss: 1.3126%\n",
      "Epoch [3/300], Step [40/225], Training Accuracy: 35.8203%, Training Loss: 1.3129%\n",
      "Epoch [3/300], Step [41/225], Training Accuracy: 35.8994%, Training Loss: 1.3122%\n",
      "Epoch [3/300], Step [42/225], Training Accuracy: 35.7887%, Training Loss: 1.3129%\n",
      "Epoch [3/300], Step [43/225], Training Accuracy: 35.7558%, Training Loss: 1.3119%\n",
      "Epoch [3/300], Step [44/225], Training Accuracy: 35.7599%, Training Loss: 1.3105%\n",
      "Epoch [3/300], Step [45/225], Training Accuracy: 35.7292%, Training Loss: 1.3099%\n",
      "Epoch [3/300], Step [46/225], Training Accuracy: 35.6997%, Training Loss: 1.3095%\n",
      "Epoch [3/300], Step [47/225], Training Accuracy: 35.6715%, Training Loss: 1.3096%\n",
      "Epoch [3/300], Step [48/225], Training Accuracy: 35.6120%, Training Loss: 1.3090%\n",
      "Epoch [3/300], Step [49/225], Training Accuracy: 35.6505%, Training Loss: 1.3080%\n",
      "Epoch [3/300], Step [50/225], Training Accuracy: 35.5000%, Training Loss: 1.3090%\n",
      "Epoch [3/300], Step [51/225], Training Accuracy: 35.2941%, Training Loss: 1.3096%\n",
      "Epoch [3/300], Step [52/225], Training Accuracy: 35.3966%, Training Loss: 1.3087%\n",
      "Epoch [3/300], Step [53/225], Training Accuracy: 35.1120%, Training Loss: 1.3098%\n",
      "Epoch [3/300], Step [54/225], Training Accuracy: 35.0694%, Training Loss: 1.3103%\n",
      "Epoch [3/300], Step [55/225], Training Accuracy: 35.1989%, Training Loss: 1.3102%\n",
      "Epoch [3/300], Step [56/225], Training Accuracy: 35.1562%, Training Loss: 1.3098%\n",
      "Epoch [3/300], Step [57/225], Training Accuracy: 35.1974%, Training Loss: 1.3084%\n",
      "Epoch [3/300], Step [58/225], Training Accuracy: 35.1024%, Training Loss: 1.3083%\n",
      "Epoch [3/300], Step [59/225], Training Accuracy: 35.1165%, Training Loss: 1.3068%\n",
      "Epoch [3/300], Step [60/225], Training Accuracy: 35.2344%, Training Loss: 1.3056%\n",
      "Epoch [3/300], Step [61/225], Training Accuracy: 35.2715%, Training Loss: 1.3058%\n",
      "Epoch [3/300], Step [62/225], Training Accuracy: 35.2319%, Training Loss: 1.3067%\n",
      "Epoch [3/300], Step [63/225], Training Accuracy: 35.1687%, Training Loss: 1.3076%\n",
      "Epoch [3/300], Step [64/225], Training Accuracy: 35.2539%, Training Loss: 1.3079%\n",
      "Epoch [3/300], Step [65/225], Training Accuracy: 35.2644%, Training Loss: 1.3074%\n",
      "Epoch [3/300], Step [66/225], Training Accuracy: 35.4640%, Training Loss: 1.3059%\n",
      "Epoch [3/300], Step [67/225], Training Accuracy: 35.5644%, Training Loss: 1.3051%\n",
      "Epoch [3/300], Step [68/225], Training Accuracy: 35.3401%, Training Loss: 1.3056%\n",
      "Epoch [3/300], Step [69/225], Training Accuracy: 35.3487%, Training Loss: 1.3044%\n",
      "Epoch [3/300], Step [70/225], Training Accuracy: 35.5134%, Training Loss: 1.3038%\n",
      "Epoch [3/300], Step [71/225], Training Accuracy: 35.4313%, Training Loss: 1.3040%\n",
      "Epoch [3/300], Step [72/225], Training Accuracy: 35.2648%, Training Loss: 1.3052%\n",
      "Epoch [3/300], Step [73/225], Training Accuracy: 35.3168%, Training Loss: 1.3056%\n",
      "Epoch [3/300], Step [74/225], Training Accuracy: 35.3885%, Training Loss: 1.3043%\n",
      "Epoch [3/300], Step [75/225], Training Accuracy: 35.4375%, Training Loss: 1.3036%\n",
      "Epoch [3/300], Step [76/225], Training Accuracy: 35.4441%, Training Loss: 1.3037%\n",
      "Epoch [3/300], Step [77/225], Training Accuracy: 35.2476%, Training Loss: 1.3043%\n",
      "Epoch [3/300], Step [78/225], Training Accuracy: 35.2364%, Training Loss: 1.3044%\n",
      "Epoch [3/300], Step [79/225], Training Accuracy: 35.2057%, Training Loss: 1.3044%\n",
      "Epoch [3/300], Step [80/225], Training Accuracy: 35.0977%, Training Loss: 1.3050%\n",
      "Epoch [3/300], Step [81/225], Training Accuracy: 35.0887%, Training Loss: 1.3054%\n",
      "Epoch [3/300], Step [82/225], Training Accuracy: 35.1753%, Training Loss: 1.3050%\n",
      "Epoch [3/300], Step [83/225], Training Accuracy: 35.1845%, Training Loss: 1.3051%\n",
      "Epoch [3/300], Step [84/225], Training Accuracy: 35.1935%, Training Loss: 1.3050%\n",
      "Epoch [3/300], Step [85/225], Training Accuracy: 35.2206%, Training Loss: 1.3052%\n",
      "Epoch [3/300], Step [86/225], Training Accuracy: 35.1562%, Training Loss: 1.3066%\n",
      "Epoch [3/300], Step [87/225], Training Accuracy: 35.2011%, Training Loss: 1.3064%\n",
      "Epoch [3/300], Step [88/225], Training Accuracy: 35.0852%, Training Loss: 1.3065%\n",
      "Epoch [3/300], Step [89/225], Training Accuracy: 34.9719%, Training Loss: 1.3066%\n",
      "Epoch [3/300], Step [90/225], Training Accuracy: 35.0347%, Training Loss: 1.3055%\n",
      "Epoch [3/300], Step [91/225], Training Accuracy: 35.1992%, Training Loss: 1.3045%\n",
      "Epoch [3/300], Step [92/225], Training Accuracy: 35.1902%, Training Loss: 1.3055%\n",
      "Epoch [3/300], Step [93/225], Training Accuracy: 35.1478%, Training Loss: 1.3059%\n",
      "Epoch [3/300], Step [94/225], Training Accuracy: 35.1064%, Training Loss: 1.3057%\n",
      "Epoch [3/300], Step [95/225], Training Accuracy: 35.0493%, Training Loss: 1.3062%\n",
      "Epoch [3/300], Step [96/225], Training Accuracy: 35.0098%, Training Loss: 1.3060%\n",
      "Epoch [3/300], Step [97/225], Training Accuracy: 35.0515%, Training Loss: 1.3060%\n",
      "Epoch [3/300], Step [98/225], Training Accuracy: 35.0287%, Training Loss: 1.3058%\n",
      "Epoch [3/300], Step [99/225], Training Accuracy: 35.0379%, Training Loss: 1.3052%\n",
      "Epoch [3/300], Step [100/225], Training Accuracy: 34.9844%, Training Loss: 1.3048%\n",
      "Epoch [3/300], Step [101/225], Training Accuracy: 35.0866%, Training Loss: 1.3041%\n",
      "Epoch [3/300], Step [102/225], Training Accuracy: 35.0337%, Training Loss: 1.3045%\n",
      "Epoch [3/300], Step [103/225], Training Accuracy: 35.0425%, Training Loss: 1.3051%\n",
      "Epoch [3/300], Step [104/225], Training Accuracy: 35.0511%, Training Loss: 1.3048%\n",
      "Epoch [3/300], Step [105/225], Training Accuracy: 34.9851%, Training Loss: 1.3051%\n",
      "Epoch [3/300], Step [106/225], Training Accuracy: 35.0825%, Training Loss: 1.3041%\n",
      "Epoch [3/300], Step [107/225], Training Accuracy: 35.0905%, Training Loss: 1.3043%\n",
      "Epoch [3/300], Step [108/225], Training Accuracy: 35.0839%, Training Loss: 1.3046%\n",
      "Epoch [3/300], Step [109/225], Training Accuracy: 35.0487%, Training Loss: 1.3048%\n",
      "Epoch [3/300], Step [110/225], Training Accuracy: 34.9290%, Training Loss: 1.3050%\n",
      "Epoch [3/300], Step [111/225], Training Accuracy: 34.9662%, Training Loss: 1.3053%\n",
      "Epoch [3/300], Step [112/225], Training Accuracy: 35.0167%, Training Loss: 1.3046%\n",
      "Epoch [3/300], Step [113/225], Training Accuracy: 35.0111%, Training Loss: 1.3052%\n",
      "Epoch [3/300], Step [114/225], Training Accuracy: 35.0603%, Training Loss: 1.3044%\n",
      "Epoch [3/300], Step [115/225], Training Accuracy: 34.9321%, Training Loss: 1.3050%\n",
      "Epoch [3/300], Step [116/225], Training Accuracy: 34.9407%, Training Loss: 1.3051%\n",
      "Epoch [3/300], Step [117/225], Training Accuracy: 34.8958%, Training Loss: 1.3056%\n",
      "Epoch [3/300], Step [118/225], Training Accuracy: 34.7987%, Training Loss: 1.3061%\n",
      "Epoch [3/300], Step [119/225], Training Accuracy: 34.7426%, Training Loss: 1.3061%\n",
      "Epoch [3/300], Step [120/225], Training Accuracy: 34.7656%, Training Loss: 1.3056%\n",
      "Epoch [3/300], Step [121/225], Training Accuracy: 34.7366%, Training Loss: 1.3059%\n",
      "Epoch [3/300], Step [122/225], Training Accuracy: 34.7848%, Training Loss: 1.3059%\n",
      "Epoch [3/300], Step [123/225], Training Accuracy: 34.7942%, Training Loss: 1.3061%\n",
      "Epoch [3/300], Step [124/225], Training Accuracy: 34.7656%, Training Loss: 1.3064%\n",
      "Epoch [3/300], Step [125/225], Training Accuracy: 34.7875%, Training Loss: 1.3068%\n",
      "Epoch [3/300], Step [126/225], Training Accuracy: 34.7346%, Training Loss: 1.3073%\n",
      "Epoch [3/300], Step [127/225], Training Accuracy: 34.7318%, Training Loss: 1.3073%\n",
      "Epoch [3/300], Step [128/225], Training Accuracy: 34.7290%, Training Loss: 1.3072%\n",
      "Epoch [3/300], Step [129/225], Training Accuracy: 34.6778%, Training Loss: 1.3076%\n",
      "Epoch [3/300], Step [130/225], Training Accuracy: 34.6034%, Training Loss: 1.3079%\n",
      "Epoch [3/300], Step [131/225], Training Accuracy: 34.5420%, Training Loss: 1.3085%\n",
      "Epoch [3/300], Step [132/225], Training Accuracy: 34.5289%, Training Loss: 1.3083%\n",
      "Epoch [3/300], Step [133/225], Training Accuracy: 34.5865%, Training Loss: 1.3082%\n",
      "Epoch [3/300], Step [134/225], Training Accuracy: 34.5732%, Training Loss: 1.3088%\n",
      "Epoch [3/300], Step [135/225], Training Accuracy: 34.6528%, Training Loss: 1.3086%\n",
      "Epoch [3/300], Step [136/225], Training Accuracy: 34.6507%, Training Loss: 1.3086%\n",
      "Epoch [3/300], Step [137/225], Training Accuracy: 34.6943%, Training Loss: 1.3082%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/300], Step [138/225], Training Accuracy: 34.7713%, Training Loss: 1.3077%\n",
      "Epoch [3/300], Step [139/225], Training Accuracy: 34.7460%, Training Loss: 1.3078%\n",
      "Epoch [3/300], Step [140/225], Training Accuracy: 34.7991%, Training Loss: 1.3078%\n",
      "Epoch [3/300], Step [141/225], Training Accuracy: 34.7961%, Training Loss: 1.3076%\n",
      "Epoch [3/300], Step [142/225], Training Accuracy: 34.8041%, Training Loss: 1.3073%\n",
      "Epoch [3/300], Step [143/225], Training Accuracy: 34.8448%, Training Loss: 1.3068%\n",
      "Epoch [3/300], Step [144/225], Training Accuracy: 34.7982%, Training Loss: 1.3077%\n",
      "Epoch [3/300], Step [145/225], Training Accuracy: 34.8276%, Training Loss: 1.3074%\n",
      "Epoch [3/300], Step [146/225], Training Accuracy: 34.8245%, Training Loss: 1.3073%\n",
      "Epoch [3/300], Step [147/225], Training Accuracy: 34.8533%, Training Loss: 1.3070%\n",
      "Epoch [3/300], Step [148/225], Training Accuracy: 34.8818%, Training Loss: 1.3064%\n",
      "Epoch [3/300], Step [149/225], Training Accuracy: 34.9308%, Training Loss: 1.3062%\n",
      "Epoch [3/300], Step [150/225], Training Accuracy: 34.9583%, Training Loss: 1.3060%\n",
      "Epoch [3/300], Step [151/225], Training Accuracy: 35.0269%, Training Loss: 1.3055%\n",
      "Epoch [3/300], Step [152/225], Training Accuracy: 35.0535%, Training Loss: 1.3053%\n",
      "Epoch [3/300], Step [153/225], Training Accuracy: 35.0388%, Training Loss: 1.3054%\n",
      "Epoch [3/300], Step [154/225], Training Accuracy: 35.0142%, Training Loss: 1.3056%\n",
      "Epoch [3/300], Step [155/225], Training Accuracy: 35.0504%, Training Loss: 1.3055%\n",
      "Epoch [3/300], Step [156/225], Training Accuracy: 35.0561%, Training Loss: 1.3054%\n",
      "Epoch [3/300], Step [157/225], Training Accuracy: 35.0318%, Training Loss: 1.3054%\n",
      "Epoch [3/300], Step [158/225], Training Accuracy: 35.0574%, Training Loss: 1.3054%\n",
      "Epoch [3/300], Step [159/225], Training Accuracy: 35.1317%, Training Loss: 1.3046%\n",
      "Epoch [3/300], Step [160/225], Training Accuracy: 35.1562%, Training Loss: 1.3045%\n",
      "Epoch [3/300], Step [161/225], Training Accuracy: 35.1708%, Training Loss: 1.3039%\n",
      "Epoch [3/300], Step [162/225], Training Accuracy: 35.1852%, Training Loss: 1.3039%\n",
      "Epoch [3/300], Step [163/225], Training Accuracy: 35.2569%, Training Loss: 1.3033%\n",
      "Epoch [3/300], Step [164/225], Training Accuracy: 35.3182%, Training Loss: 1.3031%\n",
      "Epoch [3/300], Step [165/225], Training Accuracy: 35.2936%, Training Loss: 1.3031%\n",
      "Epoch [3/300], Step [166/225], Training Accuracy: 35.3163%, Training Loss: 1.3027%\n",
      "Epoch [3/300], Step [167/225], Training Accuracy: 35.3574%, Training Loss: 1.3024%\n",
      "Epoch [3/300], Step [168/225], Training Accuracy: 35.3423%, Training Loss: 1.3024%\n",
      "Epoch [3/300], Step [169/225], Training Accuracy: 35.2996%, Training Loss: 1.3029%\n",
      "Epoch [3/300], Step [170/225], Training Accuracy: 35.2206%, Training Loss: 1.3031%\n",
      "Epoch [3/300], Step [171/225], Training Accuracy: 35.2248%, Training Loss: 1.3028%\n",
      "Epoch [3/300], Step [172/225], Training Accuracy: 35.2925%, Training Loss: 1.3022%\n",
      "Epoch [3/300], Step [173/225], Training Accuracy: 35.2330%, Training Loss: 1.3025%\n",
      "Epoch [3/300], Step [174/225], Training Accuracy: 35.2371%, Training Loss: 1.3023%\n",
      "Epoch [3/300], Step [175/225], Training Accuracy: 35.2589%, Training Loss: 1.3022%\n",
      "Epoch [3/300], Step [176/225], Training Accuracy: 35.2450%, Training Loss: 1.3025%\n",
      "Epoch [3/300], Step [177/225], Training Accuracy: 35.2313%, Training Loss: 1.3023%\n",
      "Epoch [3/300], Step [178/225], Training Accuracy: 35.2791%, Training Loss: 1.3018%\n",
      "Epoch [3/300], Step [179/225], Training Accuracy: 35.3090%, Training Loss: 1.3015%\n",
      "Epoch [3/300], Step [180/225], Training Accuracy: 35.3385%, Training Loss: 1.3015%\n",
      "Epoch [3/300], Step [181/225], Training Accuracy: 35.3332%, Training Loss: 1.3014%\n",
      "Epoch [3/300], Step [182/225], Training Accuracy: 35.2850%, Training Loss: 1.3015%\n",
      "Epoch [3/300], Step [183/225], Training Accuracy: 35.2715%, Training Loss: 1.3012%\n",
      "Epoch [3/300], Step [184/225], Training Accuracy: 35.2412%, Training Loss: 1.3014%\n",
      "Epoch [3/300], Step [185/225], Training Accuracy: 35.2280%, Training Loss: 1.3016%\n",
      "Epoch [3/300], Step [186/225], Training Accuracy: 35.2655%, Training Loss: 1.3015%\n",
      "Epoch [3/300], Step [187/225], Training Accuracy: 35.2941%, Training Loss: 1.3015%\n",
      "Epoch [3/300], Step [188/225], Training Accuracy: 35.3391%, Training Loss: 1.3013%\n",
      "Epoch [3/300], Step [189/225], Training Accuracy: 35.3423%, Training Loss: 1.3009%\n",
      "Epoch [3/300], Step [190/225], Training Accuracy: 35.3701%, Training Loss: 1.3006%\n",
      "Epoch [3/300], Step [191/225], Training Accuracy: 35.3649%, Training Loss: 1.3004%\n",
      "Epoch [3/300], Step [192/225], Training Accuracy: 35.3597%, Training Loss: 1.3006%\n",
      "Epoch [3/300], Step [193/225], Training Accuracy: 35.3141%, Training Loss: 1.3008%\n",
      "Epoch [3/300], Step [194/225], Training Accuracy: 35.3818%, Training Loss: 1.3000%\n",
      "Epoch [3/300], Step [195/225], Training Accuracy: 35.3686%, Training Loss: 1.3001%\n",
      "Epoch [3/300], Step [196/225], Training Accuracy: 35.3396%, Training Loss: 1.3001%\n",
      "Epoch [3/300], Step [197/225], Training Accuracy: 35.3347%, Training Loss: 1.3004%\n",
      "Epoch [3/300], Step [198/225], Training Accuracy: 35.3772%, Training Loss: 1.2999%\n",
      "Epoch [3/300], Step [199/225], Training Accuracy: 35.4193%, Training Loss: 1.2996%\n",
      "Epoch [3/300], Step [200/225], Training Accuracy: 35.4453%, Training Loss: 1.2997%\n",
      "Epoch [3/300], Step [201/225], Training Accuracy: 35.4633%, Training Loss: 1.2995%\n",
      "Epoch [3/300], Step [202/225], Training Accuracy: 35.5275%, Training Loss: 1.2991%\n",
      "Epoch [3/300], Step [203/225], Training Accuracy: 35.4911%, Training Loss: 1.2994%\n",
      "Epoch [3/300], Step [204/225], Training Accuracy: 35.5316%, Training Loss: 1.2992%\n",
      "Epoch [3/300], Step [205/225], Training Accuracy: 35.5412%, Training Loss: 1.2992%\n",
      "Epoch [3/300], Step [206/225], Training Accuracy: 35.5507%, Training Loss: 1.2993%\n",
      "Epoch [3/300], Step [207/225], Training Accuracy: 35.5827%, Training Loss: 1.2991%\n",
      "Epoch [3/300], Step [208/225], Training Accuracy: 35.5844%, Training Loss: 1.2988%\n",
      "Epoch [3/300], Step [209/225], Training Accuracy: 35.6011%, Training Loss: 1.2987%\n",
      "Epoch [3/300], Step [210/225], Training Accuracy: 35.5804%, Training Loss: 1.2987%\n",
      "Epoch [3/300], Step [211/225], Training Accuracy: 35.6117%, Training Loss: 1.2983%\n",
      "Epoch [3/300], Step [212/225], Training Accuracy: 35.6353%, Training Loss: 1.2980%\n",
      "Epoch [3/300], Step [213/225], Training Accuracy: 35.6514%, Training Loss: 1.2977%\n",
      "Epoch [3/300], Step [214/225], Training Accuracy: 35.6527%, Training Loss: 1.2975%\n",
      "Epoch [3/300], Step [215/225], Training Accuracy: 35.6686%, Training Loss: 1.2972%\n",
      "Epoch [3/300], Step [216/225], Training Accuracy: 35.6626%, Training Loss: 1.2972%\n",
      "Epoch [3/300], Step [217/225], Training Accuracy: 35.6855%, Training Loss: 1.2969%\n",
      "Epoch [3/300], Step [218/225], Training Accuracy: 35.6651%, Training Loss: 1.2970%\n",
      "Epoch [3/300], Step [219/225], Training Accuracy: 35.6592%, Training Loss: 1.2966%\n",
      "Epoch [3/300], Step [220/225], Training Accuracy: 35.7031%, Training Loss: 1.2961%\n",
      "Epoch [3/300], Step [221/225], Training Accuracy: 35.6759%, Training Loss: 1.2964%\n",
      "Epoch [3/300], Step [222/225], Training Accuracy: 35.6841%, Training Loss: 1.2966%\n",
      "Epoch [3/300], Step [223/225], Training Accuracy: 35.7273%, Training Loss: 1.2966%\n",
      "Epoch [3/300], Step [224/225], Training Accuracy: 35.7492%, Training Loss: 1.2962%\n",
      "Epoch [3/300], Step [225/225], Training Accuracy: 35.7421%, Training Loss: 1.2963%\n",
      "Epoch [4/300], Step [1/225], Training Accuracy: 39.0625%, Training Loss: 1.3039%\n",
      "Epoch [4/300], Step [2/225], Training Accuracy: 38.2812%, Training Loss: 1.2785%\n",
      "Epoch [4/300], Step [3/225], Training Accuracy: 36.4583%, Training Loss: 1.3214%\n",
      "Epoch [4/300], Step [4/225], Training Accuracy: 35.5469%, Training Loss: 1.3091%\n",
      "Epoch [4/300], Step [5/225], Training Accuracy: 34.6875%, Training Loss: 1.3185%\n",
      "Epoch [4/300], Step [6/225], Training Accuracy: 35.9375%, Training Loss: 1.3081%\n",
      "Epoch [4/300], Step [7/225], Training Accuracy: 35.4911%, Training Loss: 1.3112%\n",
      "Epoch [4/300], Step [8/225], Training Accuracy: 35.3516%, Training Loss: 1.3061%\n",
      "Epoch [4/300], Step [9/225], Training Accuracy: 34.8958%, Training Loss: 1.3105%\n",
      "Epoch [4/300], Step [10/225], Training Accuracy: 34.3750%, Training Loss: 1.3112%\n",
      "Epoch [4/300], Step [11/225], Training Accuracy: 34.6591%, Training Loss: 1.3045%\n",
      "Epoch [4/300], Step [12/225], Training Accuracy: 34.1146%, Training Loss: 1.3054%\n",
      "Epoch [4/300], Step [13/225], Training Accuracy: 34.3750%, Training Loss: 1.3062%\n",
      "Epoch [4/300], Step [14/225], Training Accuracy: 34.4866%, Training Loss: 1.3120%\n",
      "Epoch [4/300], Step [15/225], Training Accuracy: 34.6875%, Training Loss: 1.3130%\n",
      "Epoch [4/300], Step [16/225], Training Accuracy: 35.1562%, Training Loss: 1.3106%\n",
      "Epoch [4/300], Step [17/225], Training Accuracy: 35.2022%, Training Loss: 1.3078%\n",
      "Epoch [4/300], Step [18/225], Training Accuracy: 34.6354%, Training Loss: 1.3087%\n",
      "Epoch [4/300], Step [19/225], Training Accuracy: 34.6217%, Training Loss: 1.3091%\n",
      "Epoch [4/300], Step [20/225], Training Accuracy: 34.8438%, Training Loss: 1.3056%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/300], Step [21/225], Training Accuracy: 35.4167%, Training Loss: 1.3013%\n",
      "Epoch [4/300], Step [22/225], Training Accuracy: 35.9375%, Training Loss: 1.2985%\n",
      "Epoch [4/300], Step [23/225], Training Accuracy: 35.9375%, Training Loss: 1.2976%\n",
      "Epoch [4/300], Step [24/225], Training Accuracy: 35.8073%, Training Loss: 1.2962%\n",
      "Epoch [4/300], Step [25/225], Training Accuracy: 36.1875%, Training Loss: 1.2954%\n",
      "Epoch [4/300], Step [26/225], Training Accuracy: 36.2380%, Training Loss: 1.2950%\n",
      "Epoch [4/300], Step [27/225], Training Accuracy: 36.2269%, Training Loss: 1.2941%\n",
      "Epoch [4/300], Step [28/225], Training Accuracy: 36.3839%, Training Loss: 1.2906%\n",
      "Epoch [4/300], Step [29/225], Training Accuracy: 36.4224%, Training Loss: 1.2878%\n",
      "Epoch [4/300], Step [30/225], Training Accuracy: 36.4583%, Training Loss: 1.2859%\n",
      "Epoch [4/300], Step [31/225], Training Accuracy: 36.2903%, Training Loss: 1.2864%\n",
      "Epoch [4/300], Step [32/225], Training Accuracy: 36.5234%, Training Loss: 1.2839%\n",
      "Epoch [4/300], Step [33/225], Training Accuracy: 36.6951%, Training Loss: 1.2824%\n",
      "Epoch [4/300], Step [34/225], Training Accuracy: 36.7647%, Training Loss: 1.2834%\n",
      "Epoch [4/300], Step [35/225], Training Accuracy: 36.7411%, Training Loss: 1.2860%\n",
      "Epoch [4/300], Step [36/225], Training Accuracy: 36.6319%, Training Loss: 1.2883%\n",
      "Epoch [4/300], Step [37/225], Training Accuracy: 36.7821%, Training Loss: 1.2880%\n",
      "Epoch [4/300], Step [38/225], Training Accuracy: 36.9655%, Training Loss: 1.2863%\n",
      "Epoch [4/300], Step [39/225], Training Accuracy: 37.1795%, Training Loss: 1.2855%\n",
      "Epoch [4/300], Step [40/225], Training Accuracy: 37.3047%, Training Loss: 1.2856%\n",
      "Epoch [4/300], Step [41/225], Training Accuracy: 37.4238%, Training Loss: 1.2842%\n",
      "Epoch [4/300], Step [42/225], Training Accuracy: 37.5372%, Training Loss: 1.2850%\n",
      "Epoch [4/300], Step [43/225], Training Accuracy: 37.5727%, Training Loss: 1.2840%\n",
      "Epoch [4/300], Step [44/225], Training Accuracy: 37.7131%, Training Loss: 1.2824%\n",
      "Epoch [4/300], Step [45/225], Training Accuracy: 37.7778%, Training Loss: 1.2820%\n",
      "Epoch [4/300], Step [46/225], Training Accuracy: 37.9076%, Training Loss: 1.2806%\n",
      "Epoch [4/300], Step [47/225], Training Accuracy: 37.9322%, Training Loss: 1.2798%\n",
      "Epoch [4/300], Step [48/225], Training Accuracy: 37.9557%, Training Loss: 1.2797%\n",
      "Epoch [4/300], Step [49/225], Training Accuracy: 37.9464%, Training Loss: 1.2805%\n",
      "Epoch [4/300], Step [50/225], Training Accuracy: 37.8438%, Training Loss: 1.2802%\n",
      "Epoch [4/300], Step [51/225], Training Accuracy: 37.5613%, Training Loss: 1.2818%\n",
      "Epoch [4/300], Step [52/225], Training Accuracy: 37.5300%, Training Loss: 1.2811%\n",
      "Epoch [4/300], Step [53/225], Training Accuracy: 37.4410%, Training Loss: 1.2815%\n",
      "Epoch [4/300], Step [54/225], Training Accuracy: 37.4421%, Training Loss: 1.2822%\n",
      "Epoch [4/300], Step [55/225], Training Accuracy: 37.5000%, Training Loss: 1.2832%\n",
      "Epoch [4/300], Step [56/225], Training Accuracy: 37.6953%, Training Loss: 1.2819%\n",
      "Epoch [4/300], Step [57/225], Training Accuracy: 37.7193%, Training Loss: 1.2806%\n",
      "Epoch [4/300], Step [58/225], Training Accuracy: 37.7425%, Training Loss: 1.2803%\n",
      "Epoch [4/300], Step [59/225], Training Accuracy: 37.7913%, Training Loss: 1.2789%\n",
      "Epoch [4/300], Step [60/225], Training Accuracy: 37.9688%, Training Loss: 1.2771%\n",
      "Epoch [4/300], Step [61/225], Training Accuracy: 37.9355%, Training Loss: 1.2776%\n",
      "Epoch [4/300], Step [62/225], Training Accuracy: 37.8780%, Training Loss: 1.2782%\n",
      "Epoch [4/300], Step [63/225], Training Accuracy: 37.7232%, Training Loss: 1.2798%\n",
      "Epoch [4/300], Step [64/225], Training Accuracy: 37.6221%, Training Loss: 1.2811%\n",
      "Epoch [4/300], Step [65/225], Training Accuracy: 37.5481%, Training Loss: 1.2810%\n",
      "Epoch [4/300], Step [66/225], Training Accuracy: 37.5473%, Training Loss: 1.2801%\n",
      "Epoch [4/300], Step [67/225], Training Accuracy: 37.5466%, Training Loss: 1.2799%\n",
      "Epoch [4/300], Step [68/225], Training Accuracy: 37.5919%, Training Loss: 1.2798%\n",
      "Epoch [4/300], Step [69/225], Training Accuracy: 37.7038%, Training Loss: 1.2782%\n",
      "Epoch [4/300], Step [70/225], Training Accuracy: 37.7902%, Training Loss: 1.2773%\n",
      "Epoch [4/300], Step [71/225], Training Accuracy: 37.8081%, Training Loss: 1.2772%\n",
      "Epoch [4/300], Step [72/225], Training Accuracy: 37.7170%, Training Loss: 1.2779%\n",
      "Epoch [4/300], Step [73/225], Training Accuracy: 37.5642%, Training Loss: 1.2789%\n",
      "Epoch [4/300], Step [74/225], Training Accuracy: 37.7745%, Training Loss: 1.2770%\n",
      "Epoch [4/300], Step [75/225], Training Accuracy: 37.7292%, Training Loss: 1.2766%\n",
      "Epoch [4/300], Step [76/225], Training Accuracy: 37.7467%, Training Loss: 1.2769%\n",
      "Epoch [4/300], Step [77/225], Training Accuracy: 37.6623%, Training Loss: 1.2771%\n",
      "Epoch [4/300], Step [78/225], Training Accuracy: 37.5200%, Training Loss: 1.2774%\n",
      "Epoch [4/300], Step [79/225], Training Accuracy: 37.5198%, Training Loss: 1.2771%\n",
      "Epoch [4/300], Step [80/225], Training Accuracy: 37.3438%, Training Loss: 1.2781%\n",
      "Epoch [4/300], Step [81/225], Training Accuracy: 37.3264%, Training Loss: 1.2784%\n",
      "Epoch [4/300], Step [82/225], Training Accuracy: 37.3095%, Training Loss: 1.2784%\n",
      "Epoch [4/300], Step [83/225], Training Accuracy: 37.2741%, Training Loss: 1.2786%\n",
      "Epoch [4/300], Step [84/225], Training Accuracy: 37.2954%, Training Loss: 1.2788%\n",
      "Epoch [4/300], Step [85/225], Training Accuracy: 37.2794%, Training Loss: 1.2791%\n",
      "Epoch [4/300], Step [86/225], Training Accuracy: 37.2275%, Training Loss: 1.2799%\n",
      "Epoch [4/300], Step [87/225], Training Accuracy: 37.2845%, Training Loss: 1.2794%\n",
      "Epoch [4/300], Step [88/225], Training Accuracy: 37.2514%, Training Loss: 1.2793%\n",
      "Epoch [4/300], Step [89/225], Training Accuracy: 37.3069%, Training Loss: 1.2789%\n",
      "Epoch [4/300], Step [90/225], Training Accuracy: 37.3264%, Training Loss: 1.2778%\n",
      "Epoch [4/300], Step [91/225], Training Accuracy: 37.3283%, Training Loss: 1.2772%\n",
      "Epoch [4/300], Step [92/225], Training Accuracy: 37.2622%, Training Loss: 1.2779%\n",
      "Epoch [4/300], Step [93/225], Training Accuracy: 37.1640%, Training Loss: 1.2783%\n",
      "Epoch [4/300], Step [94/225], Training Accuracy: 37.1011%, Training Loss: 1.2780%\n",
      "Epoch [4/300], Step [95/225], Training Accuracy: 37.1217%, Training Loss: 1.2784%\n",
      "Epoch [4/300], Step [96/225], Training Accuracy: 37.0931%, Training Loss: 1.2783%\n",
      "Epoch [4/300], Step [97/225], Training Accuracy: 37.1295%, Training Loss: 1.2785%\n",
      "Epoch [4/300], Step [98/225], Training Accuracy: 37.2290%, Training Loss: 1.2778%\n",
      "Epoch [4/300], Step [99/225], Training Accuracy: 37.3422%, Training Loss: 1.2766%\n",
      "Epoch [4/300], Step [100/225], Training Accuracy: 37.3750%, Training Loss: 1.2763%\n",
      "Epoch [4/300], Step [101/225], Training Accuracy: 37.4536%, Training Loss: 1.2758%\n",
      "Epoch [4/300], Step [102/225], Training Accuracy: 37.4847%, Training Loss: 1.2760%\n",
      "Epoch [4/300], Step [103/225], Training Accuracy: 37.3938%, Training Loss: 1.2774%\n",
      "Epoch [4/300], Step [104/225], Training Accuracy: 37.4850%, Training Loss: 1.2771%\n",
      "Epoch [4/300], Step [105/225], Training Accuracy: 37.4702%, Training Loss: 1.2772%\n",
      "Epoch [4/300], Step [106/225], Training Accuracy: 37.5884%, Training Loss: 1.2763%\n",
      "Epoch [4/300], Step [107/225], Training Accuracy: 37.5146%, Training Loss: 1.2768%\n",
      "Epoch [4/300], Step [108/225], Training Accuracy: 37.5434%, Training Loss: 1.2772%\n",
      "Epoch [4/300], Step [109/225], Training Accuracy: 37.4857%, Training Loss: 1.2769%\n",
      "Epoch [4/300], Step [110/225], Training Accuracy: 37.4574%, Training Loss: 1.2766%\n",
      "Epoch [4/300], Step [111/225], Training Accuracy: 37.4859%, Training Loss: 1.2768%\n",
      "Epoch [4/300], Step [112/225], Training Accuracy: 37.5419%, Training Loss: 1.2763%\n",
      "Epoch [4/300], Step [113/225], Training Accuracy: 37.4723%, Training Loss: 1.2771%\n",
      "Epoch [4/300], Step [114/225], Training Accuracy: 37.5000%, Training Loss: 1.2763%\n",
      "Epoch [4/300], Step [115/225], Training Accuracy: 37.4185%, Training Loss: 1.2766%\n",
      "Epoch [4/300], Step [116/225], Training Accuracy: 37.4865%, Training Loss: 1.2766%\n",
      "Epoch [4/300], Step [117/225], Training Accuracy: 37.4599%, Training Loss: 1.2772%\n",
      "Epoch [4/300], Step [118/225], Training Accuracy: 37.3676%, Training Loss: 1.2782%\n",
      "Epoch [4/300], Step [119/225], Training Accuracy: 37.4212%, Training Loss: 1.2780%\n",
      "Epoch [4/300], Step [120/225], Training Accuracy: 37.4349%, Training Loss: 1.2779%\n",
      "Epoch [4/300], Step [121/225], Training Accuracy: 37.3709%, Training Loss: 1.2784%\n",
      "Epoch [4/300], Step [122/225], Training Accuracy: 37.3079%, Training Loss: 1.2788%\n",
      "Epoch [4/300], Step [123/225], Training Accuracy: 37.3222%, Training Loss: 1.2791%\n",
      "Epoch [4/300], Step [124/225], Training Accuracy: 37.3362%, Training Loss: 1.2795%\n",
      "Epoch [4/300], Step [125/225], Training Accuracy: 37.2875%, Training Loss: 1.2803%\n",
      "Epoch [4/300], Step [126/225], Training Accuracy: 37.2768%, Training Loss: 1.2808%\n",
      "Epoch [4/300], Step [127/225], Training Accuracy: 37.2416%, Training Loss: 1.2809%\n",
      "Epoch [4/300], Step [128/225], Training Accuracy: 37.2070%, Training Loss: 1.2809%\n",
      "Epoch [4/300], Step [129/225], Training Accuracy: 37.1851%, Training Loss: 1.2810%\n",
      "Epoch [4/300], Step [130/225], Training Accuracy: 37.1274%, Training Loss: 1.2812%\n",
      "Epoch [4/300], Step [131/225], Training Accuracy: 37.1064%, Training Loss: 1.2813%\n",
      "Epoch [4/300], Step [132/225], Training Accuracy: 37.1212%, Training Loss: 1.2813%\n",
      "Epoch [4/300], Step [133/225], Training Accuracy: 37.1476%, Training Loss: 1.2810%\n",
      "Epoch [4/300], Step [134/225], Training Accuracy: 37.1269%, Training Loss: 1.2812%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/300], Step [135/225], Training Accuracy: 37.1991%, Training Loss: 1.2807%\n",
      "Epoch [4/300], Step [136/225], Training Accuracy: 37.2702%, Training Loss: 1.2808%\n",
      "Epoch [4/300], Step [137/225], Training Accuracy: 37.3061%, Training Loss: 1.2803%\n",
      "Epoch [4/300], Step [138/225], Training Accuracy: 37.2622%, Training Loss: 1.2803%\n",
      "Epoch [4/300], Step [139/225], Training Accuracy: 37.2639%, Training Loss: 1.2804%\n",
      "Epoch [4/300], Step [140/225], Training Accuracy: 37.2768%, Training Loss: 1.2803%\n",
      "Epoch [4/300], Step [141/225], Training Accuracy: 37.2230%, Training Loss: 1.2802%\n",
      "Epoch [4/300], Step [142/225], Training Accuracy: 37.2359%, Training Loss: 1.2797%\n",
      "Epoch [4/300], Step [143/225], Training Accuracy: 37.2268%, Training Loss: 1.2793%\n",
      "Epoch [4/300], Step [144/225], Training Accuracy: 37.2179%, Training Loss: 1.2799%\n",
      "Epoch [4/300], Step [145/225], Training Accuracy: 37.2522%, Training Loss: 1.2797%\n",
      "Epoch [4/300], Step [146/225], Training Accuracy: 37.2967%, Training Loss: 1.2793%\n",
      "Epoch [4/300], Step [147/225], Training Accuracy: 37.3087%, Training Loss: 1.2792%\n",
      "Epoch [4/300], Step [148/225], Training Accuracy: 37.3733%, Training Loss: 1.2785%\n",
      "Epoch [4/300], Step [149/225], Training Accuracy: 37.3951%, Training Loss: 1.2788%\n",
      "Epoch [4/300], Step [150/225], Training Accuracy: 37.4271%, Training Loss: 1.2785%\n",
      "Epoch [4/300], Step [151/225], Training Accuracy: 37.4793%, Training Loss: 1.2781%\n",
      "Epoch [4/300], Step [152/225], Training Accuracy: 37.4692%, Training Loss: 1.2780%\n",
      "Epoch [4/300], Step [153/225], Training Accuracy: 37.5000%, Training Loss: 1.2780%\n",
      "Epoch [4/300], Step [154/225], Training Accuracy: 37.5101%, Training Loss: 1.2776%\n",
      "Epoch [4/300], Step [155/225], Training Accuracy: 37.4798%, Training Loss: 1.2776%\n",
      "Epoch [4/300], Step [156/225], Training Accuracy: 37.4900%, Training Loss: 1.2777%\n",
      "Epoch [4/300], Step [157/225], Training Accuracy: 37.4701%, Training Loss: 1.2774%\n",
      "Epoch [4/300], Step [158/225], Training Accuracy: 37.4802%, Training Loss: 1.2772%\n",
      "Epoch [4/300], Step [159/225], Training Accuracy: 37.5393%, Training Loss: 1.2766%\n",
      "Epoch [4/300], Step [160/225], Training Accuracy: 37.5098%, Training Loss: 1.2766%\n",
      "Epoch [4/300], Step [161/225], Training Accuracy: 37.5485%, Training Loss: 1.2760%\n",
      "Epoch [4/300], Step [162/225], Training Accuracy: 37.5193%, Training Loss: 1.2760%\n",
      "Epoch [4/300], Step [163/225], Training Accuracy: 37.6342%, Training Loss: 1.2753%\n",
      "Epoch [4/300], Step [164/225], Training Accuracy: 37.6143%, Training Loss: 1.2751%\n",
      "Epoch [4/300], Step [165/225], Training Accuracy: 37.5947%, Training Loss: 1.2753%\n",
      "Epoch [4/300], Step [166/225], Training Accuracy: 37.6224%, Training Loss: 1.2748%\n",
      "Epoch [4/300], Step [167/225], Training Accuracy: 37.6310%, Training Loss: 1.2749%\n",
      "Epoch [4/300], Step [168/225], Training Accuracy: 37.6395%, Training Loss: 1.2748%\n",
      "Epoch [4/300], Step [169/225], Training Accuracy: 37.5832%, Training Loss: 1.2751%\n",
      "Epoch [4/300], Step [170/225], Training Accuracy: 37.5827%, Training Loss: 1.2750%\n",
      "Epoch [4/300], Step [171/225], Training Accuracy: 37.5731%, Training Loss: 1.2746%\n",
      "Epoch [4/300], Step [172/225], Training Accuracy: 37.5818%, Training Loss: 1.2742%\n",
      "Epoch [4/300], Step [173/225], Training Accuracy: 37.5361%, Training Loss: 1.2746%\n",
      "Epoch [4/300], Step [174/225], Training Accuracy: 37.5449%, Training Loss: 1.2745%\n",
      "Epoch [4/300], Step [175/225], Training Accuracy: 37.5714%, Training Loss: 1.2742%\n",
      "Epoch [4/300], Step [176/225], Training Accuracy: 37.5178%, Training Loss: 1.2747%\n",
      "Epoch [4/300], Step [177/225], Training Accuracy: 37.5530%, Training Loss: 1.2742%\n",
      "Epoch [4/300], Step [178/225], Training Accuracy: 37.5966%, Training Loss: 1.2737%\n",
      "Epoch [4/300], Step [179/225], Training Accuracy: 37.5786%, Training Loss: 1.2739%\n",
      "Epoch [4/300], Step [180/225], Training Accuracy: 37.5694%, Training Loss: 1.2739%\n",
      "Epoch [4/300], Step [181/225], Training Accuracy: 37.5691%, Training Loss: 1.2741%\n",
      "Epoch [4/300], Step [182/225], Training Accuracy: 37.5515%, Training Loss: 1.2743%\n",
      "Epoch [4/300], Step [183/225], Training Accuracy: 37.5768%, Training Loss: 1.2739%\n",
      "Epoch [4/300], Step [184/225], Training Accuracy: 37.5425%, Training Loss: 1.2741%\n",
      "Epoch [4/300], Step [185/225], Training Accuracy: 37.5507%, Training Loss: 1.2743%\n",
      "Epoch [4/300], Step [186/225], Training Accuracy: 37.6092%, Training Loss: 1.2741%\n",
      "Epoch [4/300], Step [187/225], Training Accuracy: 37.6337%, Training Loss: 1.2742%\n",
      "Epoch [4/300], Step [188/225], Training Accuracy: 37.6662%, Training Loss: 1.2738%\n",
      "Epoch [4/300], Step [189/225], Training Accuracy: 37.7067%, Training Loss: 1.2733%\n",
      "Epoch [4/300], Step [190/225], Training Accuracy: 37.7220%, Training Loss: 1.2730%\n",
      "Epoch [4/300], Step [191/225], Training Accuracy: 37.7127%, Training Loss: 1.2730%\n",
      "Epoch [4/300], Step [192/225], Training Accuracy: 37.7197%, Training Loss: 1.2731%\n",
      "Epoch [4/300], Step [193/225], Training Accuracy: 37.6862%, Training Loss: 1.2733%\n",
      "Epoch [4/300], Step [194/225], Training Accuracy: 37.7255%, Training Loss: 1.2728%\n",
      "Epoch [4/300], Step [195/225], Training Accuracy: 37.7484%, Training Loss: 1.2725%\n",
      "Epoch [4/300], Step [196/225], Training Accuracy: 37.7471%, Training Loss: 1.2723%\n",
      "Epoch [4/300], Step [197/225], Training Accuracy: 37.7459%, Training Loss: 1.2725%\n",
      "Epoch [4/300], Step [198/225], Training Accuracy: 37.7525%, Training Loss: 1.2719%\n",
      "Epoch [4/300], Step [199/225], Training Accuracy: 37.7434%, Training Loss: 1.2719%\n",
      "Epoch [4/300], Step [200/225], Training Accuracy: 37.7500%, Training Loss: 1.2720%\n",
      "Epoch [4/300], Step [201/225], Training Accuracy: 37.7643%, Training Loss: 1.2719%\n",
      "Epoch [4/300], Step [202/225], Training Accuracy: 37.7785%, Training Loss: 1.2716%\n",
      "Epoch [4/300], Step [203/225], Training Accuracy: 37.7617%, Training Loss: 1.2719%\n",
      "Epoch [4/300], Step [204/225], Training Accuracy: 37.7528%, Training Loss: 1.2717%\n",
      "Epoch [4/300], Step [205/225], Training Accuracy: 37.7439%, Training Loss: 1.2720%\n",
      "Epoch [4/300], Step [206/225], Training Accuracy: 37.7882%, Training Loss: 1.2720%\n",
      "Epoch [4/300], Step [207/225], Training Accuracy: 37.8246%, Training Loss: 1.2716%\n",
      "Epoch [4/300], Step [208/225], Training Accuracy: 37.8305%, Training Loss: 1.2714%\n",
      "Epoch [4/300], Step [209/225], Training Accuracy: 37.8289%, Training Loss: 1.2712%\n",
      "Epoch [4/300], Step [210/225], Training Accuracy: 37.8199%, Training Loss: 1.2711%\n",
      "Epoch [4/300], Step [211/225], Training Accuracy: 37.8406%, Training Loss: 1.2707%\n",
      "Epoch [4/300], Step [212/225], Training Accuracy: 37.8611%, Training Loss: 1.2708%\n",
      "Epoch [4/300], Step [213/225], Training Accuracy: 37.8521%, Training Loss: 1.2707%\n",
      "Epoch [4/300], Step [214/225], Training Accuracy: 37.8067%, Training Loss: 1.2707%\n",
      "Epoch [4/300], Step [215/225], Training Accuracy: 37.8270%, Training Loss: 1.2707%\n",
      "Epoch [4/300], Step [216/225], Training Accuracy: 37.8472%, Training Loss: 1.2708%\n",
      "Epoch [4/300], Step [217/225], Training Accuracy: 37.8744%, Training Loss: 1.2703%\n",
      "Epoch [4/300], Step [218/225], Training Accuracy: 37.8440%, Training Loss: 1.2707%\n",
      "Epoch [4/300], Step [219/225], Training Accuracy: 37.9209%, Training Loss: 1.2702%\n",
      "Epoch [4/300], Step [220/225], Training Accuracy: 37.9545%, Training Loss: 1.2696%\n",
      "Epoch [4/300], Step [221/225], Training Accuracy: 37.9313%, Training Loss: 1.2697%\n",
      "Epoch [4/300], Step [222/225], Training Accuracy: 37.9082%, Training Loss: 1.2699%\n",
      "Epoch [4/300], Step [223/225], Training Accuracy: 37.9134%, Training Loss: 1.2700%\n",
      "Epoch [4/300], Step [224/225], Training Accuracy: 37.9325%, Training Loss: 1.2696%\n",
      "Epoch [4/300], Step [225/225], Training Accuracy: 37.9516%, Training Loss: 1.2694%\n",
      "Epoch [5/300], Step [1/225], Training Accuracy: 35.9375%, Training Loss: 1.2588%\n",
      "Epoch [5/300], Step [2/225], Training Accuracy: 35.9375%, Training Loss: 1.2666%\n",
      "Epoch [5/300], Step [3/225], Training Accuracy: 34.8958%, Training Loss: 1.2937%\n",
      "Epoch [5/300], Step [4/225], Training Accuracy: 36.3281%, Training Loss: 1.2776%\n",
      "Epoch [5/300], Step [5/225], Training Accuracy: 38.1250%, Training Loss: 1.2757%\n",
      "Epoch [5/300], Step [6/225], Training Accuracy: 38.0208%, Training Loss: 1.2816%\n",
      "Epoch [5/300], Step [7/225], Training Accuracy: 38.8393%, Training Loss: 1.2794%\n",
      "Epoch [5/300], Step [8/225], Training Accuracy: 39.4531%, Training Loss: 1.2740%\n",
      "Epoch [5/300], Step [9/225], Training Accuracy: 39.0625%, Training Loss: 1.2732%\n",
      "Epoch [5/300], Step [10/225], Training Accuracy: 39.0625%, Training Loss: 1.2684%\n",
      "Epoch [5/300], Step [11/225], Training Accuracy: 39.0625%, Training Loss: 1.2643%\n",
      "Epoch [5/300], Step [12/225], Training Accuracy: 38.1510%, Training Loss: 1.2700%\n",
      "Epoch [5/300], Step [13/225], Training Accuracy: 38.5817%, Training Loss: 1.2688%\n",
      "Epoch [5/300], Step [14/225], Training Accuracy: 38.1696%, Training Loss: 1.2773%\n",
      "Epoch [5/300], Step [15/225], Training Accuracy: 38.1250%, Training Loss: 1.2790%\n",
      "Epoch [5/300], Step [16/225], Training Accuracy: 38.1836%, Training Loss: 1.2803%\n",
      "Epoch [5/300], Step [17/225], Training Accuracy: 38.3272%, Training Loss: 1.2760%\n",
      "Epoch [5/300], Step [18/225], Training Accuracy: 38.0208%, Training Loss: 1.2780%\n",
      "Epoch [5/300], Step [19/225], Training Accuracy: 37.7467%, Training Loss: 1.2816%\n",
      "Epoch [5/300], Step [20/225], Training Accuracy: 37.8906%, Training Loss: 1.2792%\n",
      "Epoch [5/300], Step [21/225], Training Accuracy: 38.3929%, Training Loss: 1.2751%\n",
      "Epoch [5/300], Step [22/225], Training Accuracy: 38.4233%, Training Loss: 1.2740%\n",
      "Epoch [5/300], Step [23/225], Training Accuracy: 38.2473%, Training Loss: 1.2728%\n",
      "Epoch [5/300], Step [24/225], Training Accuracy: 38.3464%, Training Loss: 1.2701%\n",
      "Epoch [5/300], Step [25/225], Training Accuracy: 39.0000%, Training Loss: 1.2665%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/300], Step [26/225], Training Accuracy: 38.9423%, Training Loss: 1.2668%\n",
      "Epoch [5/300], Step [27/225], Training Accuracy: 38.8310%, Training Loss: 1.2659%\n",
      "Epoch [5/300], Step [28/225], Training Accuracy: 39.0067%, Training Loss: 1.2620%\n",
      "Epoch [5/300], Step [29/225], Training Accuracy: 39.1703%, Training Loss: 1.2593%\n",
      "Epoch [5/300], Step [30/225], Training Accuracy: 39.3229%, Training Loss: 1.2565%\n",
      "Epoch [5/300], Step [31/225], Training Accuracy: 39.1129%, Training Loss: 1.2559%\n",
      "Epoch [5/300], Step [32/225], Training Accuracy: 39.5020%, Training Loss: 1.2543%\n",
      "Epoch [5/300], Step [33/225], Training Accuracy: 39.6780%, Training Loss: 1.2526%\n",
      "Epoch [5/300], Step [34/225], Training Accuracy: 39.7059%, Training Loss: 1.2537%\n",
      "Epoch [5/300], Step [35/225], Training Accuracy: 39.5536%, Training Loss: 1.2565%\n",
      "Epoch [5/300], Step [36/225], Training Accuracy: 39.6267%, Training Loss: 1.2591%\n",
      "Epoch [5/300], Step [37/225], Training Accuracy: 39.6537%, Training Loss: 1.2583%\n",
      "Epoch [5/300], Step [38/225], Training Accuracy: 39.7204%, Training Loss: 1.2569%\n",
      "Epoch [5/300], Step [39/225], Training Accuracy: 39.7436%, Training Loss: 1.2575%\n",
      "Epoch [5/300], Step [40/225], Training Accuracy: 39.7656%, Training Loss: 1.2570%\n",
      "Epoch [5/300], Step [41/225], Training Accuracy: 39.9771%, Training Loss: 1.2554%\n",
      "Epoch [5/300], Step [42/225], Training Accuracy: 40.0298%, Training Loss: 1.2549%\n",
      "Epoch [5/300], Step [43/225], Training Accuracy: 39.9709%, Training Loss: 1.2550%\n",
      "Epoch [5/300], Step [44/225], Training Accuracy: 40.1278%, Training Loss: 1.2531%\n",
      "Epoch [5/300], Step [45/225], Training Accuracy: 40.1389%, Training Loss: 1.2522%\n",
      "Epoch [5/300], Step [46/225], Training Accuracy: 40.2174%, Training Loss: 1.2513%\n",
      "Epoch [5/300], Step [47/225], Training Accuracy: 40.4255%, Training Loss: 1.2499%\n",
      "Epoch [5/300], Step [48/225], Training Accuracy: 40.4948%, Training Loss: 1.2491%\n",
      "Epoch [5/300], Step [49/225], Training Accuracy: 40.4018%, Training Loss: 1.2488%\n",
      "Epoch [5/300], Step [50/225], Training Accuracy: 40.2812%, Training Loss: 1.2489%\n",
      "Epoch [5/300], Step [51/225], Training Accuracy: 40.1348%, Training Loss: 1.2505%\n",
      "Epoch [5/300], Step [52/225], Training Accuracy: 40.0841%, Training Loss: 1.2500%\n",
      "Epoch [5/300], Step [53/225], Training Accuracy: 39.8290%, Training Loss: 1.2509%\n",
      "Epoch [5/300], Step [54/225], Training Accuracy: 39.9016%, Training Loss: 1.2512%\n",
      "Epoch [5/300], Step [55/225], Training Accuracy: 39.8580%, Training Loss: 1.2517%\n",
      "Epoch [5/300], Step [56/225], Training Accuracy: 39.8158%, Training Loss: 1.2509%\n",
      "Epoch [5/300], Step [57/225], Training Accuracy: 39.9397%, Training Loss: 1.2493%\n",
      "Epoch [5/300], Step [58/225], Training Accuracy: 39.8976%, Training Loss: 1.2485%\n",
      "Epoch [5/300], Step [59/225], Training Accuracy: 39.8570%, Training Loss: 1.2476%\n",
      "Epoch [5/300], Step [60/225], Training Accuracy: 40.0260%, Training Loss: 1.2459%\n",
      "Epoch [5/300], Step [61/225], Training Accuracy: 39.9334%, Training Loss: 1.2470%\n",
      "Epoch [5/300], Step [62/225], Training Accuracy: 39.8185%, Training Loss: 1.2476%\n",
      "Epoch [5/300], Step [63/225], Training Accuracy: 39.6825%, Training Loss: 1.2493%\n",
      "Epoch [5/300], Step [64/225], Training Accuracy: 39.6973%, Training Loss: 1.2502%\n",
      "Epoch [5/300], Step [65/225], Training Accuracy: 39.5433%, Training Loss: 1.2502%\n",
      "Epoch [5/300], Step [66/225], Training Accuracy: 39.7727%, Training Loss: 1.2492%\n",
      "Epoch [5/300], Step [67/225], Training Accuracy: 39.7621%, Training Loss: 1.2490%\n",
      "Epoch [5/300], Step [68/225], Training Accuracy: 39.7978%, Training Loss: 1.2482%\n",
      "Epoch [5/300], Step [69/225], Training Accuracy: 39.7192%, Training Loss: 1.2472%\n",
      "Epoch [5/300], Step [70/225], Training Accuracy: 39.9330%, Training Loss: 1.2456%\n",
      "Epoch [5/300], Step [71/225], Training Accuracy: 39.8988%, Training Loss: 1.2459%\n",
      "Epoch [5/300], Step [72/225], Training Accuracy: 39.7352%, Training Loss: 1.2463%\n",
      "Epoch [5/300], Step [73/225], Training Accuracy: 39.5976%, Training Loss: 1.2472%\n",
      "Epoch [5/300], Step [74/225], Training Accuracy: 39.8015%, Training Loss: 1.2453%\n",
      "Epoch [5/300], Step [75/225], Training Accuracy: 39.7292%, Training Loss: 1.2452%\n",
      "Epoch [5/300], Step [76/225], Training Accuracy: 39.6998%, Training Loss: 1.2452%\n",
      "Epoch [5/300], Step [77/225], Training Accuracy: 39.7727%, Training Loss: 1.2447%\n",
      "Epoch [5/300], Step [78/225], Training Accuracy: 39.6635%, Training Loss: 1.2447%\n",
      "Epoch [5/300], Step [79/225], Training Accuracy: 39.7350%, Training Loss: 1.2447%\n",
      "Epoch [5/300], Step [80/225], Training Accuracy: 39.6875%, Training Loss: 1.2453%\n",
      "Epoch [5/300], Step [81/225], Training Accuracy: 39.6605%, Training Loss: 1.2455%\n",
      "Epoch [5/300], Step [82/225], Training Accuracy: 39.7294%, Training Loss: 1.2449%\n",
      "Epoch [5/300], Step [83/225], Training Accuracy: 39.7779%, Training Loss: 1.2449%\n",
      "Epoch [5/300], Step [84/225], Training Accuracy: 39.8065%, Training Loss: 1.2448%\n",
      "Epoch [5/300], Step [85/225], Training Accuracy: 39.8529%, Training Loss: 1.2452%\n",
      "Epoch [5/300], Step [86/225], Training Accuracy: 39.7892%, Training Loss: 1.2459%\n",
      "Epoch [5/300], Step [87/225], Training Accuracy: 39.7629%, Training Loss: 1.2465%\n",
      "Epoch [5/300], Step [88/225], Training Accuracy: 39.7372%, Training Loss: 1.2464%\n",
      "Epoch [5/300], Step [89/225], Training Accuracy: 39.6770%, Training Loss: 1.2467%\n",
      "Epoch [5/300], Step [90/225], Training Accuracy: 39.6875%, Training Loss: 1.2461%\n",
      "Epoch [5/300], Step [91/225], Training Accuracy: 39.7321%, Training Loss: 1.2457%\n",
      "Epoch [5/300], Step [92/225], Training Accuracy: 39.7079%, Training Loss: 1.2461%\n",
      "Epoch [5/300], Step [93/225], Training Accuracy: 39.6169%, Training Loss: 1.2465%\n",
      "Epoch [5/300], Step [94/225], Training Accuracy: 39.6110%, Training Loss: 1.2462%\n",
      "Epoch [5/300], Step [95/225], Training Accuracy: 39.6546%, Training Loss: 1.2464%\n",
      "Epoch [5/300], Step [96/225], Training Accuracy: 39.6810%, Training Loss: 1.2461%\n",
      "Epoch [5/300], Step [97/225], Training Accuracy: 39.7390%, Training Loss: 1.2456%\n",
      "Epoch [5/300], Step [98/225], Training Accuracy: 39.7800%, Training Loss: 1.2454%\n",
      "Epoch [5/300], Step [99/225], Training Accuracy: 39.8359%, Training Loss: 1.2446%\n",
      "Epoch [5/300], Step [100/225], Training Accuracy: 39.8594%, Training Loss: 1.2443%\n",
      "Epoch [5/300], Step [101/225], Training Accuracy: 39.8670%, Training Loss: 1.2439%\n",
      "Epoch [5/300], Step [102/225], Training Accuracy: 39.8591%, Training Loss: 1.2439%\n",
      "Epoch [5/300], Step [103/225], Training Accuracy: 39.7907%, Training Loss: 1.2450%\n",
      "Epoch [5/300], Step [104/225], Training Accuracy: 39.7837%, Training Loss: 1.2447%\n",
      "Epoch [5/300], Step [105/225], Training Accuracy: 39.7768%, Training Loss: 1.2449%\n",
      "Epoch [5/300], Step [106/225], Training Accuracy: 39.7848%, Training Loss: 1.2442%\n",
      "Epoch [5/300], Step [107/225], Training Accuracy: 39.6758%, Training Loss: 1.2445%\n",
      "Epoch [5/300], Step [108/225], Training Accuracy: 39.6846%, Training Loss: 1.2446%\n",
      "Epoch [5/300], Step [109/225], Training Accuracy: 39.6216%, Training Loss: 1.2449%\n",
      "Epoch [5/300], Step [110/225], Training Accuracy: 39.6307%, Training Loss: 1.2444%\n",
      "Epoch [5/300], Step [111/225], Training Accuracy: 39.6396%, Training Loss: 1.2444%\n",
      "Epoch [5/300], Step [112/225], Training Accuracy: 39.7321%, Training Loss: 1.2437%\n",
      "Epoch [5/300], Step [113/225], Training Accuracy: 39.7677%, Training Loss: 1.2439%\n",
      "Epoch [5/300], Step [114/225], Training Accuracy: 39.7889%, Training Loss: 1.2433%\n",
      "Epoch [5/300], Step [115/225], Training Accuracy: 39.7147%, Training Loss: 1.2439%\n",
      "Epoch [5/300], Step [116/225], Training Accuracy: 39.6956%, Training Loss: 1.2441%\n",
      "Epoch [5/300], Step [117/225], Training Accuracy: 39.6768%, Training Loss: 1.2444%\n",
      "Epoch [5/300], Step [118/225], Training Accuracy: 39.5789%, Training Loss: 1.2452%\n",
      "Epoch [5/300], Step [119/225], Training Accuracy: 39.5352%, Training Loss: 1.2452%\n",
      "Epoch [5/300], Step [120/225], Training Accuracy: 39.6354%, Training Loss: 1.2448%\n",
      "Epoch [5/300], Step [121/225], Training Accuracy: 39.5403%, Training Loss: 1.2453%\n",
      "Epoch [5/300], Step [122/225], Training Accuracy: 39.5364%, Training Loss: 1.2460%\n",
      "Epoch [5/300], Step [123/225], Training Accuracy: 39.5071%, Training Loss: 1.2462%\n",
      "Epoch [5/300], Step [124/225], Training Accuracy: 39.5161%, Training Loss: 1.2469%\n",
      "Epoch [5/300], Step [125/225], Training Accuracy: 39.4875%, Training Loss: 1.2473%\n",
      "Epoch [5/300], Step [126/225], Training Accuracy: 39.4717%, Training Loss: 1.2477%\n",
      "Epoch [5/300], Step [127/225], Training Accuracy: 39.4685%, Training Loss: 1.2476%\n",
      "Epoch [5/300], Step [128/225], Training Accuracy: 39.5020%, Training Loss: 1.2476%\n",
      "Epoch [5/300], Step [129/225], Training Accuracy: 39.4743%, Training Loss: 1.2479%\n",
      "Epoch [5/300], Step [130/225], Training Accuracy: 39.4351%, Training Loss: 1.2481%\n",
      "Epoch [5/300], Step [131/225], Training Accuracy: 39.4203%, Training Loss: 1.2477%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/300], Step [132/225], Training Accuracy: 39.3821%, Training Loss: 1.2479%\n",
      "Epoch [5/300], Step [133/225], Training Accuracy: 39.4032%, Training Loss: 1.2474%\n",
      "Epoch [5/300], Step [134/225], Training Accuracy: 39.4007%, Training Loss: 1.2476%\n",
      "Epoch [5/300], Step [135/225], Training Accuracy: 39.4792%, Training Loss: 1.2473%\n",
      "Epoch [5/300], Step [136/225], Training Accuracy: 39.4646%, Training Loss: 1.2478%\n",
      "Epoch [5/300], Step [137/225], Training Accuracy: 39.5529%, Training Loss: 1.2469%\n",
      "Epoch [5/300], Step [138/225], Training Accuracy: 39.5607%, Training Loss: 1.2468%\n",
      "Epoch [5/300], Step [139/225], Training Accuracy: 39.5796%, Training Loss: 1.2468%\n",
      "Epoch [5/300], Step [140/225], Training Accuracy: 39.5871%, Training Loss: 1.2468%\n",
      "Epoch [5/300], Step [141/225], Training Accuracy: 39.5501%, Training Loss: 1.2470%\n",
      "Epoch [5/300], Step [142/225], Training Accuracy: 39.5687%, Training Loss: 1.2467%\n",
      "Epoch [5/300], Step [143/225], Training Accuracy: 39.5323%, Training Loss: 1.2465%\n",
      "Epoch [5/300], Step [144/225], Training Accuracy: 39.4965%, Training Loss: 1.2469%\n",
      "Epoch [5/300], Step [145/225], Training Accuracy: 39.4612%, Training Loss: 1.2467%\n",
      "Epoch [5/300], Step [146/225], Training Accuracy: 39.4157%, Training Loss: 1.2465%\n",
      "Epoch [5/300], Step [147/225], Training Accuracy: 39.4133%, Training Loss: 1.2465%\n",
      "Epoch [5/300], Step [148/225], Training Accuracy: 39.4742%, Training Loss: 1.2458%\n",
      "Epoch [5/300], Step [149/225], Training Accuracy: 39.4610%, Training Loss: 1.2461%\n",
      "Epoch [5/300], Step [150/225], Training Accuracy: 39.5104%, Training Loss: 1.2457%\n",
      "Epoch [5/300], Step [151/225], Training Accuracy: 39.5799%, Training Loss: 1.2450%\n",
      "Epoch [5/300], Step [152/225], Training Accuracy: 39.6382%, Training Loss: 1.2449%\n",
      "Epoch [5/300], Step [153/225], Training Accuracy: 39.5935%, Training Loss: 1.2451%\n",
      "Epoch [5/300], Step [154/225], Training Accuracy: 39.6002%, Training Loss: 1.2449%\n",
      "Epoch [5/300], Step [155/225], Training Accuracy: 39.6169%, Training Loss: 1.2451%\n",
      "Epoch [5/300], Step [156/225], Training Accuracy: 39.5833%, Training Loss: 1.2455%\n",
      "Epoch [5/300], Step [157/225], Training Accuracy: 39.5701%, Training Loss: 1.2451%\n",
      "Epoch [5/300], Step [158/225], Training Accuracy: 39.5767%, Training Loss: 1.2450%\n",
      "Epoch [5/300], Step [159/225], Training Accuracy: 39.5932%, Training Loss: 1.2445%\n",
      "Epoch [5/300], Step [160/225], Training Accuracy: 39.5508%, Training Loss: 1.2447%\n",
      "Epoch [5/300], Step [161/225], Training Accuracy: 39.5672%, Training Loss: 1.2445%\n",
      "Epoch [5/300], Step [162/225], Training Accuracy: 39.5448%, Training Loss: 1.2445%\n",
      "Epoch [5/300], Step [163/225], Training Accuracy: 39.6089%, Training Loss: 1.2437%\n",
      "Epoch [5/300], Step [164/225], Training Accuracy: 39.6151%, Training Loss: 1.2437%\n",
      "Epoch [5/300], Step [165/225], Training Accuracy: 39.6023%, Training Loss: 1.2437%\n",
      "Epoch [5/300], Step [166/225], Training Accuracy: 39.6367%, Training Loss: 1.2431%\n",
      "Epoch [5/300], Step [167/225], Training Accuracy: 39.6894%, Training Loss: 1.2431%\n",
      "Epoch [5/300], Step [168/225], Training Accuracy: 39.7228%, Training Loss: 1.2431%\n",
      "Epoch [5/300], Step [169/225], Training Accuracy: 39.7004%, Training Loss: 1.2435%\n",
      "Epoch [5/300], Step [170/225], Training Accuracy: 39.6783%, Training Loss: 1.2436%\n",
      "Epoch [5/300], Step [171/225], Training Accuracy: 39.7295%, Training Loss: 1.2430%\n",
      "Epoch [5/300], Step [172/225], Training Accuracy: 39.7257%, Training Loss: 1.2427%\n",
      "Epoch [5/300], Step [173/225], Training Accuracy: 39.7489%, Training Loss: 1.2428%\n",
      "Epoch [5/300], Step [174/225], Training Accuracy: 39.7809%, Training Loss: 1.2422%\n",
      "Epoch [5/300], Step [175/225], Training Accuracy: 39.8125%, Training Loss: 1.2419%\n",
      "Epoch [5/300], Step [176/225], Training Accuracy: 39.7727%, Training Loss: 1.2423%\n",
      "Epoch [5/300], Step [177/225], Training Accuracy: 39.7775%, Training Loss: 1.2419%\n",
      "Epoch [5/300], Step [178/225], Training Accuracy: 39.7647%, Training Loss: 1.2416%\n",
      "Epoch [5/300], Step [179/225], Training Accuracy: 39.7957%, Training Loss: 1.2416%\n",
      "Epoch [5/300], Step [180/225], Training Accuracy: 39.7830%, Training Loss: 1.2418%\n",
      "Epoch [5/300], Step [181/225], Training Accuracy: 39.7790%, Training Loss: 1.2419%\n",
      "Epoch [5/300], Step [182/225], Training Accuracy: 39.7922%, Training Loss: 1.2420%\n",
      "Epoch [5/300], Step [183/225], Training Accuracy: 39.8053%, Training Loss: 1.2417%\n",
      "Epoch [5/300], Step [184/225], Training Accuracy: 39.7588%, Training Loss: 1.2420%\n",
      "Epoch [5/300], Step [185/225], Training Accuracy: 39.7720%, Training Loss: 1.2421%\n",
      "Epoch [5/300], Step [186/225], Training Accuracy: 39.8438%, Training Loss: 1.2419%\n",
      "Epoch [5/300], Step [187/225], Training Accuracy: 39.8814%, Training Loss: 1.2418%\n",
      "Epoch [5/300], Step [188/225], Training Accuracy: 39.9269%, Training Loss: 1.2417%\n",
      "Epoch [5/300], Step [189/225], Training Accuracy: 39.9636%, Training Loss: 1.2414%\n",
      "Epoch [5/300], Step [190/225], Training Accuracy: 39.9753%, Training Loss: 1.2411%\n",
      "Epoch [5/300], Step [191/225], Training Accuracy: 39.9133%, Training Loss: 1.2410%\n",
      "Epoch [5/300], Step [192/225], Training Accuracy: 39.9495%, Training Loss: 1.2413%\n",
      "Epoch [5/300], Step [193/225], Training Accuracy: 39.8964%, Training Loss: 1.2416%\n",
      "Epoch [5/300], Step [194/225], Training Accuracy: 39.9323%, Training Loss: 1.2411%\n",
      "Epoch [5/300], Step [195/225], Training Accuracy: 39.9119%, Training Loss: 1.2411%\n",
      "Epoch [5/300], Step [196/225], Training Accuracy: 39.9155%, Training Loss: 1.2412%\n",
      "Epoch [5/300], Step [197/225], Training Accuracy: 39.9032%, Training Loss: 1.2414%\n",
      "Epoch [5/300], Step [198/225], Training Accuracy: 39.9937%, Training Loss: 1.2407%\n",
      "Epoch [5/300], Step [199/225], Training Accuracy: 40.0283%, Training Loss: 1.2405%\n",
      "Epoch [5/300], Step [200/225], Training Accuracy: 40.0156%, Training Loss: 1.2407%\n",
      "Epoch [5/300], Step [201/225], Training Accuracy: 40.0264%, Training Loss: 1.2405%\n",
      "Epoch [5/300], Step [202/225], Training Accuracy: 40.0526%, Training Loss: 1.2403%\n",
      "Epoch [5/300], Step [203/225], Training Accuracy: 40.0323%, Training Loss: 1.2408%\n",
      "Epoch [5/300], Step [204/225], Training Accuracy: 40.0429%, Training Loss: 1.2407%\n",
      "Epoch [5/300], Step [205/225], Training Accuracy: 40.0686%, Training Loss: 1.2405%\n",
      "Epoch [5/300], Step [206/225], Training Accuracy: 40.0561%, Training Loss: 1.2410%\n",
      "Epoch [5/300], Step [207/225], Training Accuracy: 40.0966%, Training Loss: 1.2407%\n",
      "Epoch [5/300], Step [208/225], Training Accuracy: 40.1142%, Training Loss: 1.2403%\n",
      "Epoch [5/300], Step [209/225], Training Accuracy: 40.1092%, Training Loss: 1.2401%\n",
      "Epoch [5/300], Step [210/225], Training Accuracy: 40.1265%, Training Loss: 1.2400%\n",
      "Epoch [5/300], Step [211/225], Training Accuracy: 40.1585%, Training Loss: 1.2397%\n",
      "Epoch [5/300], Step [212/225], Training Accuracy: 40.1680%, Training Loss: 1.2397%\n",
      "Epoch [5/300], Step [213/225], Training Accuracy: 40.1995%, Training Loss: 1.2394%\n",
      "Epoch [5/300], Step [214/225], Training Accuracy: 40.1723%, Training Loss: 1.2396%\n",
      "Epoch [5/300], Step [215/225], Training Accuracy: 40.2253%, Training Loss: 1.2392%\n",
      "Epoch [5/300], Step [216/225], Training Accuracy: 40.2271%, Training Loss: 1.2396%\n",
      "Epoch [5/300], Step [217/225], Training Accuracy: 40.2650%, Training Loss: 1.2392%\n",
      "Epoch [5/300], Step [218/225], Training Accuracy: 40.2236%, Training Loss: 1.2397%\n",
      "Epoch [5/300], Step [219/225], Training Accuracy: 40.2825%, Training Loss: 1.2390%\n",
      "Epoch [5/300], Step [220/225], Training Accuracy: 40.3480%, Training Loss: 1.2385%\n",
      "Epoch [5/300], Step [221/225], Training Accuracy: 40.3139%, Training Loss: 1.2387%\n",
      "Epoch [5/300], Step [222/225], Training Accuracy: 40.3012%, Training Loss: 1.2388%\n",
      "Epoch [5/300], Step [223/225], Training Accuracy: 40.2747%, Training Loss: 1.2390%\n",
      "Epoch [5/300], Step [224/225], Training Accuracy: 40.3041%, Training Loss: 1.2387%\n",
      "Epoch [5/300], Step [225/225], Training Accuracy: 40.2932%, Training Loss: 1.2388%\n",
      "Epoch [6/300], Step [1/225], Training Accuracy: 32.8125%, Training Loss: 1.2883%\n",
      "Epoch [6/300], Step [2/225], Training Accuracy: 35.9375%, Training Loss: 1.2644%\n",
      "Epoch [6/300], Step [3/225], Training Accuracy: 33.8542%, Training Loss: 1.2861%\n",
      "Epoch [6/300], Step [4/225], Training Accuracy: 36.3281%, Training Loss: 1.2685%\n",
      "Epoch [6/300], Step [5/225], Training Accuracy: 38.7500%, Training Loss: 1.2594%\n",
      "Epoch [6/300], Step [6/225], Training Accuracy: 39.5833%, Training Loss: 1.2558%\n",
      "Epoch [6/300], Step [7/225], Training Accuracy: 40.4018%, Training Loss: 1.2564%\n",
      "Epoch [6/300], Step [8/225], Training Accuracy: 40.6250%, Training Loss: 1.2459%\n",
      "Epoch [6/300], Step [9/225], Training Accuracy: 39.9306%, Training Loss: 1.2527%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/300], Step [10/225], Training Accuracy: 40.0000%, Training Loss: 1.2528%\n",
      "Epoch [6/300], Step [11/225], Training Accuracy: 39.9148%, Training Loss: 1.2452%\n",
      "Epoch [6/300], Step [12/225], Training Accuracy: 39.1927%, Training Loss: 1.2524%\n",
      "Epoch [6/300], Step [13/225], Training Accuracy: 39.1827%, Training Loss: 1.2531%\n",
      "Epoch [6/300], Step [14/225], Training Accuracy: 39.3973%, Training Loss: 1.2580%\n",
      "Epoch [6/300], Step [15/225], Training Accuracy: 39.3750%, Training Loss: 1.2569%\n",
      "Epoch [6/300], Step [16/225], Training Accuracy: 40.0391%, Training Loss: 1.2506%\n",
      "Epoch [6/300], Step [17/225], Training Accuracy: 40.3493%, Training Loss: 1.2503%\n",
      "Epoch [6/300], Step [18/225], Training Accuracy: 40.0174%, Training Loss: 1.2516%\n",
      "Epoch [6/300], Step [19/225], Training Accuracy: 39.5559%, Training Loss: 1.2559%\n",
      "Epoch [6/300], Step [20/225], Training Accuracy: 40.1562%, Training Loss: 1.2517%\n",
      "Epoch [6/300], Step [21/225], Training Accuracy: 40.6250%, Training Loss: 1.2456%\n",
      "Epoch [6/300], Step [22/225], Training Accuracy: 40.5540%, Training Loss: 1.2435%\n",
      "Epoch [6/300], Step [23/225], Training Accuracy: 40.7609%, Training Loss: 1.2417%\n",
      "Epoch [6/300], Step [24/225], Training Accuracy: 40.3646%, Training Loss: 1.2409%\n",
      "Epoch [6/300], Step [25/225], Training Accuracy: 40.7500%, Training Loss: 1.2392%\n",
      "Epoch [6/300], Step [26/225], Training Accuracy: 40.9255%, Training Loss: 1.2375%\n",
      "Epoch [6/300], Step [27/225], Training Accuracy: 41.0880%, Training Loss: 1.2352%\n",
      "Epoch [6/300], Step [28/225], Training Accuracy: 41.4062%, Training Loss: 1.2311%\n",
      "Epoch [6/300], Step [29/225], Training Accuracy: 41.8642%, Training Loss: 1.2266%\n",
      "Epoch [6/300], Step [30/225], Training Accuracy: 41.8229%, Training Loss: 1.2261%\n",
      "Epoch [6/300], Step [31/225], Training Accuracy: 41.4819%, Training Loss: 1.2268%\n",
      "Epoch [6/300], Step [32/225], Training Accuracy: 41.8457%, Training Loss: 1.2247%\n",
      "Epoch [6/300], Step [33/225], Training Accuracy: 41.9034%, Training Loss: 1.2223%\n",
      "Epoch [6/300], Step [34/225], Training Accuracy: 41.7279%, Training Loss: 1.2232%\n",
      "Epoch [6/300], Step [35/225], Training Accuracy: 41.6964%, Training Loss: 1.2253%\n",
      "Epoch [6/300], Step [36/225], Training Accuracy: 41.6667%, Training Loss: 1.2278%\n",
      "Epoch [6/300], Step [37/225], Training Accuracy: 41.6807%, Training Loss: 1.2264%\n",
      "Epoch [6/300], Step [38/225], Training Accuracy: 41.8997%, Training Loss: 1.2238%\n",
      "Epoch [6/300], Step [39/225], Training Accuracy: 42.1074%, Training Loss: 1.2234%\n",
      "Epoch [6/300], Step [40/225], Training Accuracy: 42.1875%, Training Loss: 1.2230%\n",
      "Epoch [6/300], Step [41/225], Training Accuracy: 42.3780%, Training Loss: 1.2222%\n",
      "Epoch [6/300], Step [42/225], Training Accuracy: 42.4107%, Training Loss: 1.2223%\n",
      "Epoch [6/300], Step [43/225], Training Accuracy: 42.4419%, Training Loss: 1.2227%\n",
      "Epoch [6/300], Step [44/225], Training Accuracy: 42.4006%, Training Loss: 1.2222%\n",
      "Epoch [6/300], Step [45/225], Training Accuracy: 42.3611%, Training Loss: 1.2223%\n",
      "Epoch [6/300], Step [46/225], Training Accuracy: 42.5611%, Training Loss: 1.2211%\n",
      "Epoch [6/300], Step [47/225], Training Accuracy: 42.7194%, Training Loss: 1.2206%\n",
      "Epoch [6/300], Step [48/225], Training Accuracy: 42.7409%, Training Loss: 1.2200%\n",
      "Epoch [6/300], Step [49/225], Training Accuracy: 42.6658%, Training Loss: 1.2201%\n",
      "Epoch [6/300], Step [50/225], Training Accuracy: 42.6875%, Training Loss: 1.2194%\n",
      "Epoch [6/300], Step [51/225], Training Accuracy: 42.6164%, Training Loss: 1.2206%\n",
      "Epoch [6/300], Step [52/225], Training Accuracy: 42.5481%, Training Loss: 1.2208%\n",
      "Epoch [6/300], Step [53/225], Training Accuracy: 42.4233%, Training Loss: 1.2217%\n",
      "Epoch [6/300], Step [54/225], Training Accuracy: 42.3322%, Training Loss: 1.2222%\n",
      "Epoch [6/300], Step [55/225], Training Accuracy: 42.3011%, Training Loss: 1.2225%\n",
      "Epoch [6/300], Step [56/225], Training Accuracy: 42.1317%, Training Loss: 1.2226%\n",
      "Epoch [6/300], Step [57/225], Training Accuracy: 42.2149%, Training Loss: 1.2209%\n",
      "Epoch [6/300], Step [58/225], Training Accuracy: 42.2144%, Training Loss: 1.2208%\n",
      "Epoch [6/300], Step [59/225], Training Accuracy: 42.1081%, Training Loss: 1.2204%\n",
      "Epoch [6/300], Step [60/225], Training Accuracy: 42.2656%, Training Loss: 1.2180%\n",
      "Epoch [6/300], Step [61/225], Training Accuracy: 42.3156%, Training Loss: 1.2196%\n",
      "Epoch [6/300], Step [62/225], Training Accuracy: 42.2379%, Training Loss: 1.2193%\n",
      "Epoch [6/300], Step [63/225], Training Accuracy: 42.1379%, Training Loss: 1.2205%\n",
      "Epoch [6/300], Step [64/225], Training Accuracy: 42.1387%, Training Loss: 1.2213%\n",
      "Epoch [6/300], Step [65/225], Training Accuracy: 42.0433%, Training Loss: 1.2214%\n",
      "Epoch [6/300], Step [66/225], Training Accuracy: 42.0928%, Training Loss: 1.2212%\n",
      "Epoch [6/300], Step [67/225], Training Accuracy: 42.1642%, Training Loss: 1.2208%\n",
      "Epoch [6/300], Step [68/225], Training Accuracy: 42.0956%, Training Loss: 1.2205%\n",
      "Epoch [6/300], Step [69/225], Training Accuracy: 42.0969%, Training Loss: 1.2200%\n",
      "Epoch [6/300], Step [70/225], Training Accuracy: 42.2545%, Training Loss: 1.2182%\n",
      "Epoch [6/300], Step [71/225], Training Accuracy: 42.2315%, Training Loss: 1.2181%\n",
      "Epoch [6/300], Step [72/225], Training Accuracy: 42.0356%, Training Loss: 1.2192%\n",
      "Epoch [6/300], Step [73/225], Training Accuracy: 42.0591%, Training Loss: 1.2199%\n",
      "Epoch [6/300], Step [74/225], Training Accuracy: 42.2720%, Training Loss: 1.2176%\n",
      "Epoch [6/300], Step [75/225], Training Accuracy: 42.2708%, Training Loss: 1.2173%\n",
      "Epoch [6/300], Step [76/225], Training Accuracy: 42.2697%, Training Loss: 1.2179%\n",
      "Epoch [6/300], Step [77/225], Training Accuracy: 42.2281%, Training Loss: 1.2179%\n",
      "Epoch [6/300], Step [78/225], Training Accuracy: 42.2877%, Training Loss: 1.2182%\n",
      "Epoch [6/300], Step [79/225], Training Accuracy: 42.3853%, Training Loss: 1.2179%\n",
      "Epoch [6/300], Step [80/225], Training Accuracy: 42.2852%, Training Loss: 1.2187%\n",
      "Epoch [6/300], Step [81/225], Training Accuracy: 42.3611%, Training Loss: 1.2185%\n",
      "Epoch [6/300], Step [82/225], Training Accuracy: 42.3209%, Training Loss: 1.2188%\n",
      "Epoch [6/300], Step [83/225], Training Accuracy: 42.3569%, Training Loss: 1.2191%\n",
      "Epoch [6/300], Step [84/225], Training Accuracy: 42.2619%, Training Loss: 1.2193%\n",
      "Epoch [6/300], Step [85/225], Training Accuracy: 42.2794%, Training Loss: 1.2198%\n",
      "Epoch [6/300], Step [86/225], Training Accuracy: 42.2238%, Training Loss: 1.2203%\n",
      "Epoch [6/300], Step [87/225], Training Accuracy: 42.2773%, Training Loss: 1.2198%\n",
      "Epoch [6/300], Step [88/225], Training Accuracy: 42.1697%, Training Loss: 1.2204%\n",
      "Epoch [6/300], Step [89/225], Training Accuracy: 42.1875%, Training Loss: 1.2204%\n",
      "Epoch [6/300], Step [90/225], Training Accuracy: 42.2743%, Training Loss: 1.2194%\n",
      "Epoch [6/300], Step [91/225], Training Accuracy: 42.3420%, Training Loss: 1.2191%\n",
      "Epoch [6/300], Step [92/225], Training Accuracy: 42.1705%, Training Loss: 1.2201%\n",
      "Epoch [6/300], Step [93/225], Training Accuracy: 42.0867%, Training Loss: 1.2208%\n",
      "Epoch [6/300], Step [94/225], Training Accuracy: 42.1044%, Training Loss: 1.2202%\n",
      "Epoch [6/300], Step [95/225], Training Accuracy: 42.0888%, Training Loss: 1.2209%\n",
      "Epoch [6/300], Step [96/225], Training Accuracy: 42.1061%, Training Loss: 1.2207%\n",
      "Epoch [6/300], Step [97/225], Training Accuracy: 42.1875%, Training Loss: 1.2199%\n",
      "Epoch [6/300], Step [98/225], Training Accuracy: 42.2194%, Training Loss: 1.2192%\n",
      "Epoch [6/300], Step [99/225], Training Accuracy: 42.2506%, Training Loss: 1.2184%\n",
      "Epoch [6/300], Step [100/225], Training Accuracy: 42.2812%, Training Loss: 1.2181%\n",
      "Epoch [6/300], Step [101/225], Training Accuracy: 42.3422%, Training Loss: 1.2176%\n",
      "Epoch [6/300], Step [102/225], Training Accuracy: 42.3407%, Training Loss: 1.2172%\n",
      "Epoch [6/300], Step [103/225], Training Accuracy: 42.2633%, Training Loss: 1.2179%\n",
      "Epoch [6/300], Step [104/225], Training Accuracy: 42.2326%, Training Loss: 1.2173%\n",
      "Epoch [6/300], Step [105/225], Training Accuracy: 42.2024%, Training Loss: 1.2176%\n",
      "Epoch [6/300], Step [106/225], Training Accuracy: 42.2465%, Training Loss: 1.2165%\n",
      "Epoch [6/300], Step [107/225], Training Accuracy: 42.2313%, Training Loss: 1.2169%\n",
      "Epoch [6/300], Step [108/225], Training Accuracy: 42.2164%, Training Loss: 1.2173%\n",
      "Epoch [6/300], Step [109/225], Training Accuracy: 42.1445%, Training Loss: 1.2176%\n",
      "Epoch [6/300], Step [110/225], Training Accuracy: 42.1023%, Training Loss: 1.2172%\n",
      "Epoch [6/300], Step [111/225], Training Accuracy: 42.2157%, Training Loss: 1.2171%\n",
      "Epoch [6/300], Step [112/225], Training Accuracy: 42.2573%, Training Loss: 1.2166%\n",
      "Epoch [6/300], Step [113/225], Training Accuracy: 42.2152%, Training Loss: 1.2170%\n",
      "Epoch [6/300], Step [114/225], Training Accuracy: 42.2012%, Training Loss: 1.2164%\n",
      "Epoch [6/300], Step [115/225], Training Accuracy: 42.1196%, Training Loss: 1.2177%\n",
      "Epoch [6/300], Step [116/225], Training Accuracy: 42.1606%, Training Loss: 1.2171%\n",
      "Epoch [6/300], Step [117/225], Training Accuracy: 42.1341%, Training Loss: 1.2173%\n",
      "Epoch [6/300], Step [118/225], Training Accuracy: 42.0551%, Training Loss: 1.2181%\n",
      "Epoch [6/300], Step [119/225], Training Accuracy: 42.0825%, Training Loss: 1.2180%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/300], Step [120/225], Training Accuracy: 42.1354%, Training Loss: 1.2177%\n",
      "Epoch [6/300], Step [121/225], Training Accuracy: 42.1100%, Training Loss: 1.2180%\n",
      "Epoch [6/300], Step [122/225], Training Accuracy: 42.1107%, Training Loss: 1.2183%\n",
      "Epoch [6/300], Step [123/225], Training Accuracy: 42.0986%, Training Loss: 1.2183%\n",
      "Epoch [6/300], Step [124/225], Training Accuracy: 42.0993%, Training Loss: 1.2186%\n",
      "Epoch [6/300], Step [125/225], Training Accuracy: 42.0375%, Training Loss: 1.2191%\n",
      "Epoch [6/300], Step [126/225], Training Accuracy: 42.0139%, Training Loss: 1.2194%\n",
      "Epoch [6/300], Step [127/225], Training Accuracy: 42.0030%, Training Loss: 1.2195%\n",
      "Epoch [6/300], Step [128/225], Training Accuracy: 41.9800%, Training Loss: 1.2198%\n",
      "Epoch [6/300], Step [129/225], Training Accuracy: 41.9574%, Training Loss: 1.2197%\n",
      "Epoch [6/300], Step [130/225], Training Accuracy: 41.9351%, Training Loss: 1.2197%\n",
      "Epoch [6/300], Step [131/225], Training Accuracy: 41.9728%, Training Loss: 1.2194%\n",
      "Epoch [6/300], Step [132/225], Training Accuracy: 41.8797%, Training Loss: 1.2198%\n",
      "Epoch [6/300], Step [133/225], Training Accuracy: 41.9290%, Training Loss: 1.2192%\n",
      "Epoch [6/300], Step [134/225], Training Accuracy: 41.8843%, Training Loss: 1.2196%\n",
      "Epoch [6/300], Step [135/225], Training Accuracy: 41.9213%, Training Loss: 1.2194%\n",
      "Epoch [6/300], Step [136/225], Training Accuracy: 41.9003%, Training Loss: 1.2196%\n",
      "Epoch [6/300], Step [137/225], Training Accuracy: 41.9366%, Training Loss: 1.2191%\n",
      "Epoch [6/300], Step [138/225], Training Accuracy: 41.9384%, Training Loss: 1.2189%\n",
      "Epoch [6/300], Step [139/225], Training Accuracy: 41.9177%, Training Loss: 1.2192%\n",
      "Epoch [6/300], Step [140/225], Training Accuracy: 41.9866%, Training Loss: 1.2189%\n",
      "Epoch [6/300], Step [141/225], Training Accuracy: 41.9659%, Training Loss: 1.2188%\n",
      "Epoch [6/300], Step [142/225], Training Accuracy: 41.9894%, Training Loss: 1.2186%\n",
      "Epoch [6/300], Step [143/225], Training Accuracy: 41.9471%, Training Loss: 1.2185%\n",
      "Epoch [6/300], Step [144/225], Training Accuracy: 41.9162%, Training Loss: 1.2192%\n",
      "Epoch [6/300], Step [145/225], Training Accuracy: 41.9289%, Training Loss: 1.2188%\n",
      "Epoch [6/300], Step [146/225], Training Accuracy: 41.9199%, Training Loss: 1.2186%\n",
      "Epoch [6/300], Step [147/225], Training Accuracy: 41.8899%, Training Loss: 1.2189%\n",
      "Epoch [6/300], Step [148/225], Training Accuracy: 41.9236%, Training Loss: 1.2183%\n",
      "Epoch [6/300], Step [149/225], Training Accuracy: 41.9463%, Training Loss: 1.2179%\n",
      "Epoch [6/300], Step [150/225], Training Accuracy: 41.9688%, Training Loss: 1.2176%\n",
      "Epoch [6/300], Step [151/225], Training Accuracy: 42.0323%, Training Loss: 1.2167%\n",
      "Epoch [6/300], Step [152/225], Training Accuracy: 42.0127%, Training Loss: 1.2167%\n",
      "Epoch [6/300], Step [153/225], Training Accuracy: 42.0139%, Training Loss: 1.2168%\n",
      "Epoch [6/300], Step [154/225], Training Accuracy: 42.0049%, Training Loss: 1.2164%\n",
      "Epoch [6/300], Step [155/225], Training Accuracy: 42.0060%, Training Loss: 1.2165%\n",
      "Epoch [6/300], Step [156/225], Training Accuracy: 41.9872%, Training Loss: 1.2173%\n",
      "Epoch [6/300], Step [157/225], Training Accuracy: 41.9785%, Training Loss: 1.2167%\n",
      "Epoch [6/300], Step [158/225], Training Accuracy: 42.0392%, Training Loss: 1.2164%\n",
      "Epoch [6/300], Step [159/225], Training Accuracy: 42.0499%, Training Loss: 1.2159%\n",
      "Epoch [6/300], Step [160/225], Training Accuracy: 42.0215%, Training Loss: 1.2162%\n",
      "Epoch [6/300], Step [161/225], Training Accuracy: 41.9837%, Training Loss: 1.2160%\n",
      "Epoch [6/300], Step [162/225], Training Accuracy: 41.9850%, Training Loss: 1.2157%\n",
      "Epoch [6/300], Step [163/225], Training Accuracy: 42.0437%, Training Loss: 1.2152%\n",
      "Epoch [6/300], Step [164/225], Training Accuracy: 42.0732%, Training Loss: 1.2148%\n",
      "Epoch [6/300], Step [165/225], Training Accuracy: 42.0455%, Training Loss: 1.2148%\n",
      "Epoch [6/300], Step [166/225], Training Accuracy: 42.0463%, Training Loss: 1.2146%\n",
      "Epoch [6/300], Step [167/225], Training Accuracy: 42.0939%, Training Loss: 1.2146%\n",
      "Epoch [6/300], Step [168/225], Training Accuracy: 42.0759%, Training Loss: 1.2145%\n",
      "Epoch [6/300], Step [169/225], Training Accuracy: 42.0581%, Training Loss: 1.2146%\n",
      "Epoch [6/300], Step [170/225], Training Accuracy: 42.0588%, Training Loss: 1.2148%\n",
      "Epoch [6/300], Step [171/225], Training Accuracy: 42.0687%, Training Loss: 1.2144%\n",
      "Epoch [6/300], Step [172/225], Training Accuracy: 42.1148%, Training Loss: 1.2138%\n",
      "Epoch [6/300], Step [173/225], Training Accuracy: 42.0611%, Training Loss: 1.2140%\n",
      "Epoch [6/300], Step [174/225], Training Accuracy: 42.0618%, Training Loss: 1.2138%\n",
      "Epoch [6/300], Step [175/225], Training Accuracy: 42.1429%, Training Loss: 1.2134%\n",
      "Epoch [6/300], Step [176/225], Training Accuracy: 42.1076%, Training Loss: 1.2139%\n",
      "Epoch [6/300], Step [177/225], Training Accuracy: 42.1345%, Training Loss: 1.2134%\n",
      "Epoch [6/300], Step [178/225], Training Accuracy: 42.1699%, Training Loss: 1.2130%\n",
      "Epoch [6/300], Step [179/225], Training Accuracy: 42.1526%, Training Loss: 1.2132%\n",
      "Epoch [6/300], Step [180/225], Training Accuracy: 42.1788%, Training Loss: 1.2132%\n",
      "Epoch [6/300], Step [181/225], Training Accuracy: 42.1702%, Training Loss: 1.2133%\n",
      "Epoch [6/300], Step [182/225], Training Accuracy: 42.1961%, Training Loss: 1.2132%\n",
      "Epoch [6/300], Step [183/225], Training Accuracy: 42.1619%, Training Loss: 1.2128%\n",
      "Epoch [6/300], Step [184/225], Training Accuracy: 42.1196%, Training Loss: 1.2131%\n",
      "Epoch [6/300], Step [185/225], Training Accuracy: 42.1199%, Training Loss: 1.2132%\n",
      "Epoch [6/300], Step [186/225], Training Accuracy: 42.1707%, Training Loss: 1.2129%\n",
      "Epoch [6/300], Step [187/225], Training Accuracy: 42.1959%, Training Loss: 1.2131%\n",
      "Epoch [6/300], Step [188/225], Training Accuracy: 42.1792%, Training Loss: 1.2132%\n",
      "Epoch [6/300], Step [189/225], Training Accuracy: 42.1792%, Training Loss: 1.2131%\n",
      "Epoch [6/300], Step [190/225], Training Accuracy: 42.1875%, Training Loss: 1.2127%\n",
      "Epoch [6/300], Step [191/225], Training Accuracy: 42.1548%, Training Loss: 1.2127%\n",
      "Epoch [6/300], Step [192/225], Training Accuracy: 42.1631%, Training Loss: 1.2133%\n",
      "Epoch [6/300], Step [193/225], Training Accuracy: 42.1065%, Training Loss: 1.2138%\n",
      "Epoch [6/300], Step [194/225], Training Accuracy: 42.1633%, Training Loss: 1.2134%\n",
      "Epoch [6/300], Step [195/225], Training Accuracy: 42.1314%, Training Loss: 1.2133%\n",
      "Epoch [6/300], Step [196/225], Training Accuracy: 42.1556%, Training Loss: 1.2133%\n",
      "Epoch [6/300], Step [197/225], Training Accuracy: 42.1558%, Training Loss: 1.2135%\n",
      "Epoch [6/300], Step [198/225], Training Accuracy: 42.2112%, Training Loss: 1.2128%\n",
      "Epoch [6/300], Step [199/225], Training Accuracy: 42.2660%, Training Loss: 1.2126%\n",
      "Epoch [6/300], Step [200/225], Training Accuracy: 42.2734%, Training Loss: 1.2128%\n",
      "Epoch [6/300], Step [201/225], Training Accuracy: 42.2808%, Training Loss: 1.2127%\n",
      "Epoch [6/300], Step [202/225], Training Accuracy: 42.2726%, Training Loss: 1.2124%\n",
      "Epoch [6/300], Step [203/225], Training Accuracy: 42.2491%, Training Loss: 1.2129%\n",
      "Epoch [6/300], Step [204/225], Training Accuracy: 42.2411%, Training Loss: 1.2129%\n",
      "Epoch [6/300], Step [205/225], Training Accuracy: 42.2790%, Training Loss: 1.2127%\n",
      "Epoch [6/300], Step [206/225], Training Accuracy: 42.2937%, Training Loss: 1.2130%\n",
      "Epoch [6/300], Step [207/225], Training Accuracy: 42.3536%, Training Loss: 1.2127%\n",
      "Epoch [6/300], Step [208/225], Training Accuracy: 42.3678%, Training Loss: 1.2122%\n",
      "Epoch [6/300], Step [209/225], Training Accuracy: 42.3445%, Training Loss: 1.2121%\n",
      "Epoch [6/300], Step [210/225], Training Accuracy: 42.3438%, Training Loss: 1.2122%\n",
      "Epoch [6/300], Step [211/225], Training Accuracy: 42.3430%, Training Loss: 1.2118%\n",
      "Epoch [6/300], Step [212/225], Training Accuracy: 42.3275%, Training Loss: 1.2117%\n",
      "Epoch [6/300], Step [213/225], Training Accuracy: 42.3342%, Training Loss: 1.2115%\n",
      "Epoch [6/300], Step [214/225], Training Accuracy: 42.3043%, Training Loss: 1.2118%\n",
      "Epoch [6/300], Step [215/225], Training Accuracy: 42.2892%, Training Loss: 1.2117%\n",
      "Epoch [6/300], Step [216/225], Training Accuracy: 42.2671%, Training Loss: 1.2123%\n",
      "Epoch [6/300], Step [217/225], Training Accuracy: 42.3099%, Training Loss: 1.2120%\n",
      "Epoch [6/300], Step [218/225], Training Accuracy: 42.2592%, Training Loss: 1.2125%\n",
      "Epoch [6/300], Step [219/225], Training Accuracy: 42.3302%, Training Loss: 1.2119%\n",
      "Epoch [6/300], Step [220/225], Training Accuracy: 42.3935%, Training Loss: 1.2113%\n",
      "Epoch [6/300], Step [221/225], Training Accuracy: 42.3501%, Training Loss: 1.2114%\n",
      "Epoch [6/300], Step [222/225], Training Accuracy: 42.3423%, Training Loss: 1.2118%\n",
      "Epoch [6/300], Step [223/225], Training Accuracy: 42.3066%, Training Loss: 1.2122%\n",
      "Epoch [6/300], Step [224/225], Training Accuracy: 42.3340%, Training Loss: 1.2119%\n",
      "Epoch [6/300], Step [225/225], Training Accuracy: 42.3013%, Training Loss: 1.2122%\n",
      "Epoch [7/300], Step [1/225], Training Accuracy: 42.1875%, Training Loss: 1.2290%\n",
      "Epoch [7/300], Step [2/225], Training Accuracy: 41.4062%, Training Loss: 1.2137%\n",
      "Epoch [7/300], Step [3/225], Training Accuracy: 38.0208%, Training Loss: 1.2483%\n",
      "Epoch [7/300], Step [4/225], Training Accuracy: 39.8438%, Training Loss: 1.2235%\n",
      "Epoch [7/300], Step [5/225], Training Accuracy: 40.6250%, Training Loss: 1.2244%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/300], Step [6/225], Training Accuracy: 40.3646%, Training Loss: 1.2254%\n",
      "Epoch [7/300], Step [7/225], Training Accuracy: 40.4018%, Training Loss: 1.2312%\n",
      "Epoch [7/300], Step [8/225], Training Accuracy: 41.0156%, Training Loss: 1.2233%\n",
      "Epoch [7/300], Step [9/225], Training Accuracy: 41.6667%, Training Loss: 1.2267%\n",
      "Epoch [7/300], Step [10/225], Training Accuracy: 41.0938%, Training Loss: 1.2322%\n",
      "Epoch [7/300], Step [11/225], Training Accuracy: 41.1932%, Training Loss: 1.2247%\n",
      "Epoch [7/300], Step [12/225], Training Accuracy: 41.0156%, Training Loss: 1.2264%\n",
      "Epoch [7/300], Step [13/225], Training Accuracy: 41.3462%, Training Loss: 1.2245%\n",
      "Epoch [7/300], Step [14/225], Training Accuracy: 40.9598%, Training Loss: 1.2306%\n",
      "Epoch [7/300], Step [15/225], Training Accuracy: 40.8333%, Training Loss: 1.2292%\n",
      "Epoch [7/300], Step [16/225], Training Accuracy: 41.3086%, Training Loss: 1.2256%\n",
      "Epoch [7/300], Step [17/225], Training Accuracy: 41.5441%, Training Loss: 1.2217%\n",
      "Epoch [7/300], Step [18/225], Training Accuracy: 40.8854%, Training Loss: 1.2269%\n",
      "Epoch [7/300], Step [19/225], Training Accuracy: 40.2961%, Training Loss: 1.2296%\n",
      "Epoch [7/300], Step [20/225], Training Accuracy: 40.8594%, Training Loss: 1.2252%\n",
      "Epoch [7/300], Step [21/225], Training Accuracy: 41.5179%, Training Loss: 1.2198%\n",
      "Epoch [7/300], Step [22/225], Training Accuracy: 41.5483%, Training Loss: 1.2179%\n",
      "Epoch [7/300], Step [23/225], Training Accuracy: 41.9837%, Training Loss: 1.2172%\n",
      "Epoch [7/300], Step [24/225], Training Accuracy: 42.0573%, Training Loss: 1.2149%\n",
      "Epoch [7/300], Step [25/225], Training Accuracy: 42.1250%, Training Loss: 1.2130%\n",
      "Epoch [7/300], Step [26/225], Training Accuracy: 42.4279%, Training Loss: 1.2120%\n",
      "Epoch [7/300], Step [27/225], Training Accuracy: 42.4190%, Training Loss: 1.2121%\n",
      "Epoch [7/300], Step [28/225], Training Accuracy: 42.6339%, Training Loss: 1.2077%\n",
      "Epoch [7/300], Step [29/225], Training Accuracy: 43.1034%, Training Loss: 1.2025%\n",
      "Epoch [7/300], Step [30/225], Training Accuracy: 43.1771%, Training Loss: 1.2007%\n",
      "Epoch [7/300], Step [31/225], Training Accuracy: 43.0948%, Training Loss: 1.2017%\n",
      "Epoch [7/300], Step [32/225], Training Accuracy: 43.2617%, Training Loss: 1.1985%\n",
      "Epoch [7/300], Step [33/225], Training Accuracy: 43.4186%, Training Loss: 1.1967%\n",
      "Epoch [7/300], Step [34/225], Training Accuracy: 43.4743%, Training Loss: 1.1974%\n",
      "Epoch [7/300], Step [35/225], Training Accuracy: 43.5714%, Training Loss: 1.1988%\n",
      "Epoch [7/300], Step [36/225], Training Accuracy: 43.6198%, Training Loss: 1.1999%\n",
      "Epoch [7/300], Step [37/225], Training Accuracy: 43.4966%, Training Loss: 1.1996%\n",
      "Epoch [7/300], Step [38/225], Training Accuracy: 43.4211%, Training Loss: 1.1986%\n",
      "Epoch [7/300], Step [39/225], Training Accuracy: 43.4295%, Training Loss: 1.1998%\n",
      "Epoch [7/300], Step [40/225], Training Accuracy: 43.3594%, Training Loss: 1.2000%\n",
      "Epoch [7/300], Step [41/225], Training Accuracy: 43.4451%, Training Loss: 1.1982%\n",
      "Epoch [7/300], Step [42/225], Training Accuracy: 43.6384%, Training Loss: 1.1958%\n",
      "Epoch [7/300], Step [43/225], Training Accuracy: 43.6773%, Training Loss: 1.1958%\n",
      "Epoch [7/300], Step [44/225], Training Accuracy: 43.6435%, Training Loss: 1.1951%\n",
      "Epoch [7/300], Step [45/225], Training Accuracy: 43.6111%, Training Loss: 1.1949%\n",
      "Epoch [7/300], Step [46/225], Training Accuracy: 43.5802%, Training Loss: 1.1935%\n",
      "Epoch [7/300], Step [47/225], Training Accuracy: 43.6170%, Training Loss: 1.1930%\n",
      "Epoch [7/300], Step [48/225], Training Accuracy: 43.5872%, Training Loss: 1.1924%\n",
      "Epoch [7/300], Step [49/225], Training Accuracy: 43.4311%, Training Loss: 1.1928%\n",
      "Epoch [7/300], Step [50/225], Training Accuracy: 43.5312%, Training Loss: 1.1912%\n",
      "Epoch [7/300], Step [51/225], Training Accuracy: 43.3517%, Training Loss: 1.1921%\n",
      "Epoch [7/300], Step [52/225], Training Accuracy: 43.4495%, Training Loss: 1.1919%\n",
      "Epoch [7/300], Step [53/225], Training Accuracy: 43.3373%, Training Loss: 1.1925%\n",
      "Epoch [7/300], Step [54/225], Training Accuracy: 43.3738%, Training Loss: 1.1923%\n",
      "Epoch [7/300], Step [55/225], Training Accuracy: 43.4091%, Training Loss: 1.1928%\n",
      "Epoch [7/300], Step [56/225], Training Accuracy: 43.2757%, Training Loss: 1.1928%\n",
      "Epoch [7/300], Step [57/225], Training Accuracy: 43.4759%, Training Loss: 1.1907%\n",
      "Epoch [7/300], Step [58/225], Training Accuracy: 43.4267%, Training Loss: 1.1907%\n",
      "Epoch [7/300], Step [59/225], Training Accuracy: 43.4322%, Training Loss: 1.1900%\n",
      "Epoch [7/300], Step [60/225], Training Accuracy: 43.6458%, Training Loss: 1.1870%\n",
      "Epoch [7/300], Step [61/225], Training Accuracy: 43.4682%, Training Loss: 1.1888%\n",
      "Epoch [7/300], Step [62/225], Training Accuracy: 43.2460%, Training Loss: 1.1901%\n",
      "Epoch [7/300], Step [63/225], Training Accuracy: 43.1548%, Training Loss: 1.1918%\n",
      "Epoch [7/300], Step [64/225], Training Accuracy: 43.2129%, Training Loss: 1.1920%\n",
      "Epoch [7/300], Step [65/225], Training Accuracy: 43.1010%, Training Loss: 1.1923%\n",
      "Epoch [7/300], Step [66/225], Training Accuracy: 43.0871%, Training Loss: 1.1920%\n",
      "Epoch [7/300], Step [67/225], Training Accuracy: 43.1203%, Training Loss: 1.1918%\n",
      "Epoch [7/300], Step [68/225], Training Accuracy: 43.1066%, Training Loss: 1.1911%\n",
      "Epoch [7/300], Step [69/225], Training Accuracy: 43.0254%, Training Loss: 1.1906%\n",
      "Epoch [7/300], Step [70/225], Training Accuracy: 43.1250%, Training Loss: 1.1893%\n",
      "Epoch [7/300], Step [71/225], Training Accuracy: 43.1338%, Training Loss: 1.1888%\n",
      "Epoch [7/300], Step [72/225], Training Accuracy: 43.0339%, Training Loss: 1.1901%\n",
      "Epoch [7/300], Step [73/225], Training Accuracy: 42.9795%, Training Loss: 1.1917%\n",
      "Epoch [7/300], Step [74/225], Training Accuracy: 43.0321%, Training Loss: 1.1900%\n",
      "Epoch [7/300], Step [75/225], Training Accuracy: 43.0417%, Training Loss: 1.1899%\n",
      "Epoch [7/300], Step [76/225], Training Accuracy: 42.9893%, Training Loss: 1.1899%\n",
      "Epoch [7/300], Step [77/225], Training Accuracy: 43.0804%, Training Loss: 1.1893%\n",
      "Epoch [7/300], Step [78/225], Training Accuracy: 43.0288%, Training Loss: 1.1898%\n",
      "Epoch [7/300], Step [79/225], Training Accuracy: 43.1171%, Training Loss: 1.1897%\n",
      "Epoch [7/300], Step [80/225], Training Accuracy: 42.9883%, Training Loss: 1.1906%\n",
      "Epoch [7/300], Step [81/225], Training Accuracy: 43.0363%, Training Loss: 1.1903%\n",
      "Epoch [7/300], Step [82/225], Training Accuracy: 43.1021%, Training Loss: 1.1903%\n",
      "Epoch [7/300], Step [83/225], Training Accuracy: 43.1288%, Training Loss: 1.1903%\n",
      "Epoch [7/300], Step [84/225], Training Accuracy: 43.0246%, Training Loss: 1.1911%\n",
      "Epoch [7/300], Step [85/225], Training Accuracy: 43.0331%, Training Loss: 1.1918%\n",
      "Epoch [7/300], Step [86/225], Training Accuracy: 42.9506%, Training Loss: 1.1923%\n",
      "Epoch [7/300], Step [87/225], Training Accuracy: 42.8700%, Training Loss: 1.1925%\n",
      "Epoch [7/300], Step [88/225], Training Accuracy: 42.8800%, Training Loss: 1.1926%\n",
      "Epoch [7/300], Step [89/225], Training Accuracy: 42.9951%, Training Loss: 1.1919%\n",
      "Epoch [7/300], Step [90/225], Training Accuracy: 43.0729%, Training Loss: 1.1912%\n",
      "Epoch [7/300], Step [91/225], Training Accuracy: 43.2177%, Training Loss: 1.1903%\n",
      "Epoch [7/300], Step [92/225], Training Accuracy: 43.1046%, Training Loss: 1.1910%\n",
      "Epoch [7/300], Step [93/225], Training Accuracy: 43.0780%, Training Loss: 1.1916%\n",
      "Epoch [7/300], Step [94/225], Training Accuracy: 43.0851%, Training Loss: 1.1912%\n",
      "Epoch [7/300], Step [95/225], Training Accuracy: 42.9770%, Training Loss: 1.1916%\n",
      "Epoch [7/300], Step [96/225], Training Accuracy: 43.0176%, Training Loss: 1.1912%\n",
      "Epoch [7/300], Step [97/225], Training Accuracy: 43.0573%, Training Loss: 1.1907%\n",
      "Epoch [7/300], Step [98/225], Training Accuracy: 43.1122%, Training Loss: 1.1904%\n",
      "Epoch [7/300], Step [99/225], Training Accuracy: 43.2449%, Training Loss: 1.1890%\n",
      "Epoch [7/300], Step [100/225], Training Accuracy: 43.2031%, Training Loss: 1.1893%\n",
      "Epoch [7/300], Step [101/225], Training Accuracy: 43.1621%, Training Loss: 1.1893%\n",
      "Epoch [7/300], Step [102/225], Training Accuracy: 43.1832%, Training Loss: 1.1889%\n",
      "Epoch [7/300], Step [103/225], Training Accuracy: 43.1735%, Training Loss: 1.1895%\n",
      "Epoch [7/300], Step [104/225], Training Accuracy: 43.2091%, Training Loss: 1.1889%\n",
      "Epoch [7/300], Step [105/225], Training Accuracy: 43.1994%, Training Loss: 1.1891%\n",
      "Epoch [7/300], Step [106/225], Training Accuracy: 43.3225%, Training Loss: 1.1880%\n",
      "Epoch [7/300], Step [107/225], Training Accuracy: 43.3557%, Training Loss: 1.1883%\n",
      "Epoch [7/300], Step [108/225], Training Accuracy: 43.3594%, Training Loss: 1.1888%\n",
      "Epoch [7/300], Step [109/225], Training Accuracy: 43.2913%, Training Loss: 1.1893%\n",
      "Epoch [7/300], Step [110/225], Training Accuracy: 43.2528%, Training Loss: 1.1895%\n",
      "Epoch [7/300], Step [111/225], Training Accuracy: 43.2855%, Training Loss: 1.1899%\n",
      "Epoch [7/300], Step [112/225], Training Accuracy: 43.3454%, Training Loss: 1.1891%\n",
      "Epoch [7/300], Step [113/225], Training Accuracy: 43.2937%, Training Loss: 1.1899%\n",
      "Epoch [7/300], Step [114/225], Training Accuracy: 43.2840%, Training Loss: 1.1894%\n",
      "Epoch [7/300], Step [115/225], Training Accuracy: 43.3152%, Training Loss: 1.1901%\n",
      "Epoch [7/300], Step [116/225], Training Accuracy: 43.3190%, Training Loss: 1.1903%\n",
      "Epoch [7/300], Step [117/225], Training Accuracy: 43.3093%, Training Loss: 1.1901%\n",
      "Epoch [7/300], Step [118/225], Training Accuracy: 43.1806%, Training Loss: 1.1916%\n",
      "Epoch [7/300], Step [119/225], Training Accuracy: 43.2248%, Training Loss: 1.1914%\n",
      "Epoch [7/300], Step [120/225], Training Accuracy: 43.2552%, Training Loss: 1.1910%\n",
      "Epoch [7/300], Step [121/225], Training Accuracy: 43.1818%, Training Loss: 1.1917%\n",
      "Epoch [7/300], Step [122/225], Training Accuracy: 43.1865%, Training Loss: 1.1921%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/300], Step [123/225], Training Accuracy: 43.2038%, Training Loss: 1.1924%\n",
      "Epoch [7/300], Step [124/225], Training Accuracy: 43.2334%, Training Loss: 1.1923%\n",
      "Epoch [7/300], Step [125/225], Training Accuracy: 43.1750%, Training Loss: 1.1929%\n",
      "Epoch [7/300], Step [126/225], Training Accuracy: 43.1052%, Training Loss: 1.1932%\n",
      "Epoch [7/300], Step [127/225], Training Accuracy: 43.1102%, Training Loss: 1.1933%\n",
      "Epoch [7/300], Step [128/225], Training Accuracy: 43.0420%, Training Loss: 1.1935%\n",
      "Epoch [7/300], Step [129/225], Training Accuracy: 42.9990%, Training Loss: 1.1935%\n",
      "Epoch [7/300], Step [130/225], Training Accuracy: 43.0048%, Training Loss: 1.1932%\n",
      "Epoch [7/300], Step [131/225], Training Accuracy: 43.0463%, Training Loss: 1.1925%\n",
      "Epoch [7/300], Step [132/225], Training Accuracy: 42.9688%, Training Loss: 1.1926%\n",
      "Epoch [7/300], Step [133/225], Training Accuracy: 43.0216%, Training Loss: 1.1916%\n",
      "Epoch [7/300], Step [134/225], Training Accuracy: 43.0037%, Training Loss: 1.1920%\n",
      "Epoch [7/300], Step [135/225], Training Accuracy: 43.0787%, Training Loss: 1.1918%\n",
      "Epoch [7/300], Step [136/225], Training Accuracy: 43.1181%, Training Loss: 1.1920%\n",
      "Epoch [7/300], Step [137/225], Training Accuracy: 43.2254%, Training Loss: 1.1914%\n",
      "Epoch [7/300], Step [138/225], Training Accuracy: 43.2405%, Training Loss: 1.1910%\n",
      "Epoch [7/300], Step [139/225], Training Accuracy: 43.2554%, Training Loss: 1.1912%\n",
      "Epoch [7/300], Step [140/225], Training Accuracy: 43.3594%, Training Loss: 1.1903%\n",
      "Epoch [7/300], Step [141/225], Training Accuracy: 43.3511%, Training Loss: 1.1903%\n",
      "Epoch [7/300], Step [142/225], Training Accuracy: 43.3979%, Training Loss: 1.1898%\n",
      "Epoch [7/300], Step [143/225], Training Accuracy: 43.3894%, Training Loss: 1.1895%\n",
      "Epoch [7/300], Step [144/225], Training Accuracy: 43.3377%, Training Loss: 1.1899%\n",
      "Epoch [7/300], Step [145/225], Training Accuracy: 43.3190%, Training Loss: 1.1902%\n",
      "Epoch [7/300], Step [146/225], Training Accuracy: 43.2470%, Training Loss: 1.1901%\n",
      "Epoch [7/300], Step [147/225], Training Accuracy: 43.2929%, Training Loss: 1.1899%\n",
      "Epoch [7/300], Step [148/225], Training Accuracy: 43.3594%, Training Loss: 1.1892%\n",
      "Epoch [7/300], Step [149/225], Training Accuracy: 43.4249%, Training Loss: 1.1890%\n",
      "Epoch [7/300], Step [150/225], Training Accuracy: 43.4792%, Training Loss: 1.1884%\n",
      "Epoch [7/300], Step [151/225], Training Accuracy: 43.5430%, Training Loss: 1.1875%\n",
      "Epoch [7/300], Step [152/225], Training Accuracy: 43.5444%, Training Loss: 1.1874%\n",
      "Epoch [7/300], Step [153/225], Training Accuracy: 43.5253%, Training Loss: 1.1872%\n",
      "Epoch [7/300], Step [154/225], Training Accuracy: 43.5268%, Training Loss: 1.1868%\n",
      "Epoch [7/300], Step [155/225], Training Accuracy: 43.5685%, Training Loss: 1.1868%\n",
      "Epoch [7/300], Step [156/225], Training Accuracy: 43.5597%, Training Loss: 1.1871%\n",
      "Epoch [7/300], Step [157/225], Training Accuracy: 43.6007%, Training Loss: 1.1863%\n",
      "Epoch [7/300], Step [158/225], Training Accuracy: 43.6214%, Training Loss: 1.1861%\n",
      "Epoch [7/300], Step [159/225], Training Accuracy: 43.6321%, Training Loss: 1.1857%\n",
      "Epoch [7/300], Step [160/225], Training Accuracy: 43.6230%, Training Loss: 1.1859%\n",
      "Epoch [7/300], Step [161/225], Training Accuracy: 43.6627%, Training Loss: 1.1853%\n",
      "Epoch [7/300], Step [162/225], Training Accuracy: 43.6728%, Training Loss: 1.1849%\n",
      "Epoch [7/300], Step [163/225], Training Accuracy: 43.7692%, Training Loss: 1.1843%\n",
      "Epoch [7/300], Step [164/225], Training Accuracy: 43.8072%, Training Loss: 1.1838%\n",
      "Epoch [7/300], Step [165/225], Training Accuracy: 43.7595%, Training Loss: 1.1838%\n",
      "Epoch [7/300], Step [166/225], Training Accuracy: 43.7782%, Training Loss: 1.1836%\n",
      "Epoch [7/300], Step [167/225], Training Accuracy: 43.7968%, Training Loss: 1.1839%\n",
      "Epoch [7/300], Step [168/225], Training Accuracy: 43.7965%, Training Loss: 1.1836%\n",
      "Epoch [7/300], Step [169/225], Training Accuracy: 43.7592%, Training Loss: 1.1837%\n",
      "Epoch [7/300], Step [170/225], Training Accuracy: 43.7592%, Training Loss: 1.1838%\n",
      "Epoch [7/300], Step [171/225], Training Accuracy: 43.7774%, Training Loss: 1.1834%\n",
      "Epoch [7/300], Step [172/225], Training Accuracy: 43.7954%, Training Loss: 1.1832%\n",
      "Epoch [7/300], Step [173/225], Training Accuracy: 43.7681%, Training Loss: 1.1833%\n",
      "Epoch [7/300], Step [174/225], Training Accuracy: 43.7769%, Training Loss: 1.1834%\n",
      "Epoch [7/300], Step [175/225], Training Accuracy: 43.8304%, Training Loss: 1.1829%\n",
      "Epoch [7/300], Step [176/225], Training Accuracy: 43.7678%, Training Loss: 1.1834%\n",
      "Epoch [7/300], Step [177/225], Training Accuracy: 43.7765%, Training Loss: 1.1830%\n",
      "Epoch [7/300], Step [178/225], Training Accuracy: 43.7763%, Training Loss: 1.1828%\n",
      "Epoch [7/300], Step [179/225], Training Accuracy: 43.7325%, Training Loss: 1.1829%\n",
      "Epoch [7/300], Step [180/225], Training Accuracy: 43.7413%, Training Loss: 1.1830%\n",
      "Epoch [7/300], Step [181/225], Training Accuracy: 43.7500%, Training Loss: 1.1832%\n",
      "Epoch [7/300], Step [182/225], Training Accuracy: 43.7414%, Training Loss: 1.1833%\n",
      "Epoch [7/300], Step [183/225], Training Accuracy: 43.7415%, Training Loss: 1.1830%\n",
      "Epoch [7/300], Step [184/225], Training Accuracy: 43.6990%, Training Loss: 1.1833%\n",
      "Epoch [7/300], Step [185/225], Training Accuracy: 43.6993%, Training Loss: 1.1836%\n",
      "Epoch [7/300], Step [186/225], Training Accuracy: 43.7416%, Training Loss: 1.1832%\n",
      "Epoch [7/300], Step [187/225], Training Accuracy: 43.7834%, Training Loss: 1.1830%\n",
      "Epoch [7/300], Step [188/225], Training Accuracy: 43.7832%, Training Loss: 1.1830%\n",
      "Epoch [7/300], Step [189/225], Training Accuracy: 43.8327%, Training Loss: 1.1826%\n",
      "Epoch [7/300], Step [190/225], Training Accuracy: 43.8734%, Training Loss: 1.1822%\n",
      "Epoch [7/300], Step [191/225], Training Accuracy: 43.8645%, Training Loss: 1.1824%\n",
      "Epoch [7/300], Step [192/225], Training Accuracy: 43.8639%, Training Loss: 1.1828%\n",
      "Epoch [7/300], Step [193/225], Training Accuracy: 43.8310%, Training Loss: 1.1832%\n",
      "Epoch [7/300], Step [194/225], Training Accuracy: 43.8708%, Training Loss: 1.1827%\n",
      "Epoch [7/300], Step [195/225], Training Accuracy: 43.8061%, Training Loss: 1.1827%\n",
      "Epoch [7/300], Step [196/225], Training Accuracy: 43.8457%, Training Loss: 1.1827%\n",
      "Epoch [7/300], Step [197/225], Training Accuracy: 43.8293%, Training Loss: 1.1831%\n",
      "Epoch [7/300], Step [198/225], Training Accuracy: 43.8842%, Training Loss: 1.1825%\n",
      "Epoch [7/300], Step [199/225], Training Accuracy: 43.8913%, Training Loss: 1.1823%\n",
      "Epoch [7/300], Step [200/225], Training Accuracy: 43.9062%, Training Loss: 1.1824%\n",
      "Epoch [7/300], Step [201/225], Training Accuracy: 43.9599%, Training Loss: 1.1819%\n",
      "Epoch [7/300], Step [202/225], Training Accuracy: 43.9821%, Training Loss: 1.1815%\n",
      "Epoch [7/300], Step [203/225], Training Accuracy: 43.9886%, Training Loss: 1.1821%\n",
      "Epoch [7/300], Step [204/225], Training Accuracy: 44.0028%, Training Loss: 1.1821%\n",
      "Epoch [7/300], Step [205/225], Training Accuracy: 44.0549%, Training Loss: 1.1820%\n",
      "Epoch [7/300], Step [206/225], Training Accuracy: 44.0610%, Training Loss: 1.1826%\n",
      "Epoch [7/300], Step [207/225], Training Accuracy: 44.1350%, Training Loss: 1.1820%\n",
      "Epoch [7/300], Step [208/225], Training Accuracy: 44.1256%, Training Loss: 1.1818%\n",
      "Epoch [7/300], Step [209/225], Training Accuracy: 44.1089%, Training Loss: 1.1814%\n",
      "Epoch [7/300], Step [210/225], Training Accuracy: 44.0848%, Training Loss: 1.1816%\n",
      "Epoch [7/300], Step [211/225], Training Accuracy: 44.1277%, Training Loss: 1.1810%\n",
      "Epoch [7/300], Step [212/225], Training Accuracy: 44.1185%, Training Loss: 1.1811%\n",
      "Epoch [7/300], Step [213/225], Training Accuracy: 44.1388%, Training Loss: 1.1811%\n",
      "Epoch [7/300], Step [214/225], Training Accuracy: 44.0932%, Training Loss: 1.1813%\n",
      "Epoch [7/300], Step [215/225], Training Accuracy: 44.0988%, Training Loss: 1.1811%\n",
      "Epoch [7/300], Step [216/225], Training Accuracy: 44.0755%, Training Loss: 1.1816%\n",
      "Epoch [7/300], Step [217/225], Training Accuracy: 44.1100%, Training Loss: 1.1810%\n",
      "Epoch [7/300], Step [218/225], Training Accuracy: 44.0654%, Training Loss: 1.1815%\n",
      "Epoch [7/300], Step [219/225], Training Accuracy: 44.1139%, Training Loss: 1.1810%\n",
      "Epoch [7/300], Step [220/225], Training Accuracy: 44.1548%, Training Loss: 1.1804%\n",
      "Epoch [7/300], Step [221/225], Training Accuracy: 44.1318%, Training Loss: 1.1806%\n",
      "Epoch [7/300], Step [222/225], Training Accuracy: 44.1441%, Training Loss: 1.1807%\n",
      "Epoch [7/300], Step [223/225], Training Accuracy: 44.1214%, Training Loss: 1.1811%\n",
      "Epoch [7/300], Step [224/225], Training Accuracy: 44.1476%, Training Loss: 1.1807%\n",
      "Epoch [7/300], Step [225/225], Training Accuracy: 44.1217%, Training Loss: 1.1809%\n",
      "Epoch [8/300], Step [1/225], Training Accuracy: 42.1875%, Training Loss: 1.1813%\n",
      "Epoch [8/300], Step [2/225], Training Accuracy: 42.1875%, Training Loss: 1.1799%\n",
      "Epoch [8/300], Step [3/225], Training Accuracy: 40.6250%, Training Loss: 1.1887%\n",
      "Epoch [8/300], Step [4/225], Training Accuracy: 42.1875%, Training Loss: 1.1656%\n",
      "Epoch [8/300], Step [5/225], Training Accuracy: 43.1250%, Training Loss: 1.1563%\n",
      "Epoch [8/300], Step [6/225], Training Accuracy: 43.4896%, Training Loss: 1.1661%\n",
      "Epoch [8/300], Step [7/225], Training Accuracy: 43.5268%, Training Loss: 1.1794%\n",
      "Epoch [8/300], Step [8/225], Training Accuracy: 44.1406%, Training Loss: 1.1708%\n",
      "Epoch [8/300], Step [9/225], Training Accuracy: 44.2708%, Training Loss: 1.1738%\n",
      "Epoch [8/300], Step [10/225], Training Accuracy: 44.3750%, Training Loss: 1.1769%\n",
      "Epoch [8/300], Step [11/225], Training Accuracy: 44.6023%, Training Loss: 1.1706%\n",
      "Epoch [8/300], Step [12/225], Training Accuracy: 43.8802%, Training Loss: 1.1779%\n",
      "Epoch [8/300], Step [13/225], Training Accuracy: 44.4712%, Training Loss: 1.1762%\n",
      "Epoch [8/300], Step [14/225], Training Accuracy: 44.3080%, Training Loss: 1.1810%\n",
      "Epoch [8/300], Step [15/225], Training Accuracy: 44.2708%, Training Loss: 1.1810%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/300], Step [16/225], Training Accuracy: 44.0430%, Training Loss: 1.1770%\n",
      "Epoch [8/300], Step [17/225], Training Accuracy: 44.2096%, Training Loss: 1.1757%\n",
      "Epoch [8/300], Step [18/225], Training Accuracy: 43.5764%, Training Loss: 1.1819%\n",
      "Epoch [8/300], Step [19/225], Training Accuracy: 43.5033%, Training Loss: 1.1829%\n",
      "Epoch [8/300], Step [20/225], Training Accuracy: 43.9062%, Training Loss: 1.1775%\n",
      "Epoch [8/300], Step [21/225], Training Accuracy: 44.3452%, Training Loss: 1.1728%\n",
      "Epoch [8/300], Step [22/225], Training Accuracy: 44.6733%, Training Loss: 1.1708%\n",
      "Epoch [8/300], Step [23/225], Training Accuracy: 44.3614%, Training Loss: 1.1752%\n",
      "Epoch [8/300], Step [24/225], Training Accuracy: 44.0104%, Training Loss: 1.1769%\n",
      "Epoch [8/300], Step [25/225], Training Accuracy: 44.1250%, Training Loss: 1.1746%\n",
      "Epoch [8/300], Step [26/225], Training Accuracy: 44.1707%, Training Loss: 1.1746%\n",
      "Epoch [8/300], Step [27/225], Training Accuracy: 44.2708%, Training Loss: 1.1752%\n",
      "Epoch [8/300], Step [28/225], Training Accuracy: 44.5871%, Training Loss: 1.1712%\n",
      "Epoch [8/300], Step [29/225], Training Accuracy: 44.8276%, Training Loss: 1.1653%\n",
      "Epoch [8/300], Step [30/225], Training Accuracy: 44.7917%, Training Loss: 1.1663%\n",
      "Epoch [8/300], Step [31/225], Training Accuracy: 44.9093%, Training Loss: 1.1663%\n",
      "Epoch [8/300], Step [32/225], Training Accuracy: 45.3125%, Training Loss: 1.1621%\n",
      "Epoch [8/300], Step [33/225], Training Accuracy: 45.5966%, Training Loss: 1.1590%\n",
      "Epoch [8/300], Step [34/225], Training Accuracy: 45.4963%, Training Loss: 1.1614%\n",
      "Epoch [8/300], Step [35/225], Training Accuracy: 45.5357%, Training Loss: 1.1640%\n",
      "Epoch [8/300], Step [36/225], Training Accuracy: 45.4427%, Training Loss: 1.1672%\n",
      "Epoch [8/300], Step [37/225], Training Accuracy: 45.6081%, Training Loss: 1.1668%\n",
      "Epoch [8/300], Step [38/225], Training Accuracy: 45.7648%, Training Loss: 1.1650%\n",
      "Epoch [8/300], Step [39/225], Training Accuracy: 45.7532%, Training Loss: 1.1662%\n",
      "Epoch [8/300], Step [40/225], Training Accuracy: 45.7422%, Training Loss: 1.1663%\n",
      "Epoch [8/300], Step [41/225], Training Accuracy: 45.7698%, Training Loss: 1.1643%\n",
      "Epoch [8/300], Step [42/225], Training Accuracy: 45.7961%, Training Loss: 1.1633%\n",
      "Epoch [8/300], Step [43/225], Training Accuracy: 45.8939%, Training Loss: 1.1639%\n",
      "Epoch [8/300], Step [44/225], Training Accuracy: 45.9162%, Training Loss: 1.1633%\n",
      "Epoch [8/300], Step [45/225], Training Accuracy: 46.0069%, Training Loss: 1.1624%\n",
      "Epoch [8/300], Step [46/225], Training Accuracy: 46.0938%, Training Loss: 1.1614%\n",
      "Epoch [8/300], Step [47/225], Training Accuracy: 46.1769%, Training Loss: 1.1607%\n",
      "Epoch [8/300], Step [48/225], Training Accuracy: 46.2240%, Training Loss: 1.1602%\n",
      "Epoch [8/300], Step [49/225], Training Accuracy: 46.1416%, Training Loss: 1.1604%\n",
      "Epoch [8/300], Step [50/225], Training Accuracy: 46.2188%, Training Loss: 1.1599%\n",
      "Epoch [8/300], Step [51/225], Training Accuracy: 46.1397%, Training Loss: 1.1614%\n",
      "Epoch [8/300], Step [52/225], Training Accuracy: 46.0938%, Training Loss: 1.1619%\n",
      "Epoch [8/300], Step [53/225], Training Accuracy: 46.0200%, Training Loss: 1.1627%\n",
      "Epoch [8/300], Step [54/225], Training Accuracy: 45.8912%, Training Loss: 1.1625%\n",
      "Epoch [8/300], Step [55/225], Training Accuracy: 45.7670%, Training Loss: 1.1630%\n",
      "Epoch [8/300], Step [56/225], Training Accuracy: 45.8705%, Training Loss: 1.1617%\n",
      "Epoch [8/300], Step [57/225], Training Accuracy: 45.9430%, Training Loss: 1.1596%\n",
      "Epoch [8/300], Step [58/225], Training Accuracy: 45.9052%, Training Loss: 1.1601%\n",
      "Epoch [8/300], Step [59/225], Training Accuracy: 45.9216%, Training Loss: 1.1596%\n",
      "Epoch [8/300], Step [60/225], Training Accuracy: 46.0417%, Training Loss: 1.1583%\n",
      "Epoch [8/300], Step [61/225], Training Accuracy: 45.9529%, Training Loss: 1.1593%\n",
      "Epoch [8/300], Step [62/225], Training Accuracy: 45.7913%, Training Loss: 1.1598%\n",
      "Epoch [8/300], Step [63/225], Training Accuracy: 45.6845%, Training Loss: 1.1619%\n",
      "Epoch [8/300], Step [64/225], Training Accuracy: 45.6543%, Training Loss: 1.1625%\n",
      "Epoch [8/300], Step [65/225], Training Accuracy: 45.5048%, Training Loss: 1.1630%\n",
      "Epoch [8/300], Step [66/225], Training Accuracy: 45.5256%, Training Loss: 1.1622%\n",
      "Epoch [8/300], Step [67/225], Training Accuracy: 45.6856%, Training Loss: 1.1622%\n",
      "Epoch [8/300], Step [68/225], Training Accuracy: 45.6342%, Training Loss: 1.1619%\n",
      "Epoch [8/300], Step [69/225], Training Accuracy: 45.6295%, Training Loss: 1.1613%\n",
      "Epoch [8/300], Step [70/225], Training Accuracy: 45.6920%, Training Loss: 1.1603%\n",
      "Epoch [8/300], Step [71/225], Training Accuracy: 45.6646%, Training Loss: 1.1603%\n",
      "Epoch [8/300], Step [72/225], Training Accuracy: 45.5946%, Training Loss: 1.1612%\n",
      "Epoch [8/300], Step [73/225], Training Accuracy: 45.4623%, Training Loss: 1.1628%\n",
      "Epoch [8/300], Step [74/225], Training Accuracy: 45.5025%, Training Loss: 1.1612%\n",
      "Epoch [8/300], Step [75/225], Training Accuracy: 45.5417%, Training Loss: 1.1615%\n",
      "Epoch [8/300], Step [76/225], Training Accuracy: 45.5387%, Training Loss: 1.1616%\n",
      "Epoch [8/300], Step [77/225], Training Accuracy: 45.5357%, Training Loss: 1.1611%\n",
      "Epoch [8/300], Step [78/225], Training Accuracy: 45.5128%, Training Loss: 1.1610%\n",
      "Epoch [8/300], Step [79/225], Training Accuracy: 45.5894%, Training Loss: 1.1610%\n",
      "Epoch [8/300], Step [80/225], Training Accuracy: 45.4297%, Training Loss: 1.1618%\n",
      "Epoch [8/300], Step [81/225], Training Accuracy: 45.3897%, Training Loss: 1.1619%\n",
      "Epoch [8/300], Step [82/225], Training Accuracy: 45.3887%, Training Loss: 1.1618%\n",
      "Epoch [8/300], Step [83/225], Training Accuracy: 45.3690%, Training Loss: 1.1620%\n",
      "Epoch [8/300], Step [84/225], Training Accuracy: 45.2567%, Training Loss: 1.1633%\n",
      "Epoch [8/300], Step [85/225], Training Accuracy: 45.2206%, Training Loss: 1.1636%\n",
      "Epoch [8/300], Step [86/225], Training Accuracy: 45.1490%, Training Loss: 1.1640%\n",
      "Epoch [8/300], Step [87/225], Training Accuracy: 45.1149%, Training Loss: 1.1640%\n",
      "Epoch [8/300], Step [88/225], Training Accuracy: 45.0462%, Training Loss: 1.1641%\n",
      "Epoch [8/300], Step [89/225], Training Accuracy: 45.1194%, Training Loss: 1.1631%\n",
      "Epoch [8/300], Step [90/225], Training Accuracy: 45.1215%, Training Loss: 1.1625%\n",
      "Epoch [8/300], Step [91/225], Training Accuracy: 45.2438%, Training Loss: 1.1614%\n",
      "Epoch [8/300], Step [92/225], Training Accuracy: 45.1596%, Training Loss: 1.1627%\n",
      "Epoch [8/300], Step [93/225], Training Accuracy: 45.1445%, Training Loss: 1.1631%\n",
      "Epoch [8/300], Step [94/225], Training Accuracy: 45.1130%, Training Loss: 1.1629%\n",
      "Epoch [8/300], Step [95/225], Training Accuracy: 45.0493%, Training Loss: 1.1634%\n",
      "Epoch [8/300], Step [96/225], Training Accuracy: 45.1172%, Training Loss: 1.1629%\n",
      "Epoch [8/300], Step [97/225], Training Accuracy: 45.1353%, Training Loss: 1.1625%\n",
      "Epoch [8/300], Step [98/225], Training Accuracy: 45.2009%, Training Loss: 1.1617%\n",
      "Epoch [8/300], Step [99/225], Training Accuracy: 45.2336%, Training Loss: 1.1606%\n",
      "Epoch [8/300], Step [100/225], Training Accuracy: 45.0938%, Training Loss: 1.1613%\n",
      "Epoch [8/300], Step [101/225], Training Accuracy: 45.0495%, Training Loss: 1.1613%\n",
      "Epoch [8/300], Step [102/225], Training Accuracy: 45.0521%, Training Loss: 1.1613%\n",
      "Epoch [8/300], Step [103/225], Training Accuracy: 44.9939%, Training Loss: 1.1622%\n",
      "Epoch [8/300], Step [104/225], Training Accuracy: 45.0270%, Training Loss: 1.1616%\n",
      "Epoch [8/300], Step [105/225], Training Accuracy: 45.0000%, Training Loss: 1.1617%\n",
      "Epoch [8/300], Step [106/225], Training Accuracy: 45.0324%, Training Loss: 1.1611%\n",
      "Epoch [8/300], Step [107/225], Training Accuracy: 45.0058%, Training Loss: 1.1614%\n",
      "Epoch [8/300], Step [108/225], Training Accuracy: 44.9508%, Training Loss: 1.1621%\n",
      "Epoch [8/300], Step [109/225], Training Accuracy: 44.8968%, Training Loss: 1.1625%\n",
      "Epoch [8/300], Step [110/225], Training Accuracy: 44.8580%, Training Loss: 1.1622%\n",
      "Epoch [8/300], Step [111/225], Training Accuracy: 44.8620%, Training Loss: 1.1629%\n",
      "Epoch [8/300], Step [112/225], Training Accuracy: 44.9358%, Training Loss: 1.1617%\n",
      "Epoch [8/300], Step [113/225], Training Accuracy: 44.9392%, Training Loss: 1.1627%\n",
      "Epoch [8/300], Step [114/225], Training Accuracy: 44.9424%, Training Loss: 1.1627%\n",
      "Epoch [8/300], Step [115/225], Training Accuracy: 44.9321%, Training Loss: 1.1636%\n",
      "Epoch [8/300], Step [116/225], Training Accuracy: 44.9623%, Training Loss: 1.1637%\n",
      "Epoch [8/300], Step [117/225], Training Accuracy: 44.9920%, Training Loss: 1.1636%\n",
      "Epoch [8/300], Step [118/225], Training Accuracy: 44.8623%, Training Loss: 1.1652%\n",
      "Epoch [8/300], Step [119/225], Training Accuracy: 44.8923%, Training Loss: 1.1652%\n",
      "Epoch [8/300], Step [120/225], Training Accuracy: 44.9089%, Training Loss: 1.1651%\n",
      "Epoch [8/300], Step [121/225], Training Accuracy: 44.8735%, Training Loss: 1.1653%\n",
      "Epoch [8/300], Step [122/225], Training Accuracy: 44.9027%, Training Loss: 1.1654%\n",
      "Epoch [8/300], Step [123/225], Training Accuracy: 44.9695%, Training Loss: 1.1657%\n",
      "Epoch [8/300], Step [124/225], Training Accuracy: 45.0227%, Training Loss: 1.1657%\n",
      "Epoch [8/300], Step [125/225], Training Accuracy: 44.9625%, Training Loss: 1.1660%\n",
      "Epoch [8/300], Step [126/225], Training Accuracy: 44.9405%, Training Loss: 1.1661%\n",
      "Epoch [8/300], Step [127/225], Training Accuracy: 44.9311%, Training Loss: 1.1661%\n",
      "Epoch [8/300], Step [128/225], Training Accuracy: 44.9219%, Training Loss: 1.1662%\n",
      "Epoch [8/300], Step [129/225], Training Accuracy: 44.8886%, Training Loss: 1.1659%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/300], Step [130/225], Training Accuracy: 44.8918%, Training Loss: 1.1658%\n",
      "Epoch [8/300], Step [131/225], Training Accuracy: 44.9308%, Training Loss: 1.1653%\n",
      "Epoch [8/300], Step [132/225], Training Accuracy: 44.8982%, Training Loss: 1.1659%\n",
      "Epoch [8/300], Step [133/225], Training Accuracy: 45.0188%, Training Loss: 1.1650%\n",
      "Epoch [8/300], Step [134/225], Training Accuracy: 44.9394%, Training Loss: 1.1655%\n",
      "Epoch [8/300], Step [135/225], Training Accuracy: 44.9884%, Training Loss: 1.1653%\n",
      "Epoch [8/300], Step [136/225], Training Accuracy: 44.9793%, Training Loss: 1.1653%\n",
      "Epoch [8/300], Step [137/225], Training Accuracy: 44.9932%, Training Loss: 1.1650%\n",
      "Epoch [8/300], Step [138/225], Training Accuracy: 45.0181%, Training Loss: 1.1645%\n",
      "Epoch [8/300], Step [139/225], Training Accuracy: 45.0315%, Training Loss: 1.1649%\n",
      "Epoch [8/300], Step [140/225], Training Accuracy: 45.1116%, Training Loss: 1.1641%\n",
      "Epoch [8/300], Step [141/225], Training Accuracy: 45.0909%, Training Loss: 1.1642%\n",
      "Epoch [8/300], Step [142/225], Training Accuracy: 45.1474%, Training Loss: 1.1637%\n",
      "Epoch [8/300], Step [143/225], Training Accuracy: 45.1377%, Training Loss: 1.1639%\n",
      "Epoch [8/300], Step [144/225], Training Accuracy: 45.1389%, Training Loss: 1.1639%\n",
      "Epoch [8/300], Step [145/225], Training Accuracy: 45.0862%, Training Loss: 1.1642%\n",
      "Epoch [8/300], Step [146/225], Training Accuracy: 45.0985%, Training Loss: 1.1641%\n",
      "Epoch [8/300], Step [147/225], Training Accuracy: 45.0787%, Training Loss: 1.1645%\n",
      "Epoch [8/300], Step [148/225], Training Accuracy: 45.1647%, Training Loss: 1.1637%\n",
      "Epoch [8/300], Step [149/225], Training Accuracy: 45.2076%, Training Loss: 1.1636%\n",
      "Epoch [8/300], Step [150/225], Training Accuracy: 45.2396%, Training Loss: 1.1630%\n",
      "Epoch [8/300], Step [151/225], Training Accuracy: 45.2815%, Training Loss: 1.1620%\n",
      "Epoch [8/300], Step [152/225], Training Accuracy: 45.2919%, Training Loss: 1.1616%\n",
      "Epoch [8/300], Step [153/225], Training Accuracy: 45.3023%, Training Loss: 1.1615%\n",
      "Epoch [8/300], Step [154/225], Training Accuracy: 45.2922%, Training Loss: 1.1610%\n",
      "Epoch [8/300], Step [155/225], Training Accuracy: 45.2823%, Training Loss: 1.1610%\n",
      "Epoch [8/300], Step [156/225], Training Accuracy: 45.2424%, Training Loss: 1.1617%\n",
      "Epoch [8/300], Step [157/225], Training Accuracy: 45.3225%, Training Loss: 1.1609%\n",
      "Epoch [8/300], Step [158/225], Training Accuracy: 45.3422%, Training Loss: 1.1609%\n",
      "Epoch [8/300], Step [159/225], Training Accuracy: 45.3616%, Training Loss: 1.1606%\n",
      "Epoch [8/300], Step [160/225], Training Accuracy: 45.3613%, Training Loss: 1.1606%\n",
      "Epoch [8/300], Step [161/225], Training Accuracy: 45.3707%, Training Loss: 1.1599%\n",
      "Epoch [8/300], Step [162/225], Training Accuracy: 45.3704%, Training Loss: 1.1596%\n",
      "Epoch [8/300], Step [163/225], Training Accuracy: 45.4275%, Training Loss: 1.1589%\n",
      "Epoch [8/300], Step [164/225], Training Accuracy: 45.4459%, Training Loss: 1.1584%\n",
      "Epoch [8/300], Step [165/225], Training Accuracy: 45.4545%, Training Loss: 1.1582%\n",
      "Epoch [8/300], Step [166/225], Training Accuracy: 45.5102%, Training Loss: 1.1580%\n",
      "Epoch [8/300], Step [167/225], Training Accuracy: 45.5558%, Training Loss: 1.1578%\n",
      "Epoch [8/300], Step [168/225], Training Accuracy: 45.5822%, Training Loss: 1.1576%\n",
      "Epoch [8/300], Step [169/225], Training Accuracy: 45.5436%, Training Loss: 1.1578%\n",
      "Epoch [8/300], Step [170/225], Training Accuracy: 45.5882%, Training Loss: 1.1575%\n",
      "Epoch [8/300], Step [171/225], Training Accuracy: 45.6780%, Training Loss: 1.1567%\n",
      "Epoch [8/300], Step [172/225], Training Accuracy: 45.7395%, Training Loss: 1.1560%\n",
      "Epoch [8/300], Step [173/225], Training Accuracy: 45.7460%, Training Loss: 1.1562%\n",
      "Epoch [8/300], Step [174/225], Training Accuracy: 45.7705%, Training Loss: 1.1559%\n",
      "Epoch [8/300], Step [175/225], Training Accuracy: 45.7768%, Training Loss: 1.1554%\n",
      "Epoch [8/300], Step [176/225], Training Accuracy: 45.7298%, Training Loss: 1.1557%\n",
      "Epoch [8/300], Step [177/225], Training Accuracy: 45.7274%, Training Loss: 1.1553%\n",
      "Epoch [8/300], Step [178/225], Training Accuracy: 45.7338%, Training Loss: 1.1552%\n",
      "Epoch [8/300], Step [179/225], Training Accuracy: 45.7402%, Training Loss: 1.1555%\n",
      "Epoch [8/300], Step [180/225], Training Accuracy: 45.7205%, Training Loss: 1.1554%\n",
      "Epoch [8/300], Step [181/225], Training Accuracy: 45.7614%, Training Loss: 1.1554%\n",
      "Epoch [8/300], Step [182/225], Training Accuracy: 45.7332%, Training Loss: 1.1554%\n",
      "Epoch [8/300], Step [183/225], Training Accuracy: 45.7565%, Training Loss: 1.1549%\n",
      "Epoch [8/300], Step [184/225], Training Accuracy: 45.7116%, Training Loss: 1.1552%\n",
      "Epoch [8/300], Step [185/225], Training Accuracy: 45.6926%, Training Loss: 1.1555%\n",
      "Epoch [8/300], Step [186/225], Training Accuracy: 45.7745%, Training Loss: 1.1549%\n",
      "Epoch [8/300], Step [187/225], Training Accuracy: 45.7721%, Training Loss: 1.1549%\n",
      "Epoch [8/300], Step [188/225], Training Accuracy: 45.7779%, Training Loss: 1.1549%\n",
      "Epoch [8/300], Step [189/225], Training Accuracy: 45.8168%, Training Loss: 1.1546%\n",
      "Epoch [8/300], Step [190/225], Training Accuracy: 45.8224%, Training Loss: 1.1544%\n",
      "Epoch [8/300], Step [191/225], Training Accuracy: 45.7952%, Training Loss: 1.1549%\n",
      "Epoch [8/300], Step [192/225], Training Accuracy: 45.7845%, Training Loss: 1.1553%\n",
      "Epoch [8/300], Step [193/225], Training Accuracy: 45.7335%, Training Loss: 1.1557%\n",
      "Epoch [8/300], Step [194/225], Training Accuracy: 45.7796%, Training Loss: 1.1553%\n",
      "Epoch [8/300], Step [195/225], Training Accuracy: 45.7372%, Training Loss: 1.1552%\n",
      "Epoch [8/300], Step [196/225], Training Accuracy: 45.7749%, Training Loss: 1.1549%\n",
      "Epoch [8/300], Step [197/225], Training Accuracy: 45.7567%, Training Loss: 1.1554%\n",
      "Epoch [8/300], Step [198/225], Training Accuracy: 45.8176%, Training Loss: 1.1549%\n",
      "Epoch [8/300], Step [199/225], Training Accuracy: 45.8150%, Training Loss: 1.1547%\n",
      "Epoch [8/300], Step [200/225], Training Accuracy: 45.7969%, Training Loss: 1.1552%\n",
      "Epoch [8/300], Step [201/225], Training Accuracy: 45.8644%, Training Loss: 1.1546%\n",
      "Epoch [8/300], Step [202/225], Training Accuracy: 45.8694%, Training Loss: 1.1542%\n",
      "Epoch [8/300], Step [203/225], Training Accuracy: 45.8359%, Training Loss: 1.1548%\n",
      "Epoch [8/300], Step [204/225], Training Accuracy: 45.8793%, Training Loss: 1.1547%\n",
      "Epoch [8/300], Step [205/225], Training Accuracy: 45.9070%, Training Loss: 1.1549%\n",
      "Epoch [8/300], Step [206/225], Training Accuracy: 45.8965%, Training Loss: 1.1552%\n",
      "Epoch [8/300], Step [207/225], Training Accuracy: 45.9541%, Training Loss: 1.1547%\n",
      "Epoch [8/300], Step [208/225], Training Accuracy: 45.9510%, Training Loss: 1.1545%\n",
      "Epoch [8/300], Step [209/225], Training Accuracy: 45.9330%, Training Loss: 1.1542%\n",
      "Epoch [8/300], Step [210/225], Training Accuracy: 45.9449%, Training Loss: 1.1543%\n",
      "Epoch [8/300], Step [211/225], Training Accuracy: 46.0160%, Training Loss: 1.1538%\n",
      "Epoch [8/300], Step [212/225], Training Accuracy: 45.9979%, Training Loss: 1.1538%\n",
      "Epoch [8/300], Step [213/225], Training Accuracy: 46.0167%, Training Loss: 1.1533%\n",
      "Epoch [8/300], Step [214/225], Training Accuracy: 45.9550%, Training Loss: 1.1538%\n",
      "Epoch [8/300], Step [215/225], Training Accuracy: 45.9956%, Training Loss: 1.1534%\n",
      "Epoch [8/300], Step [216/225], Training Accuracy: 45.9708%, Training Loss: 1.1539%\n",
      "Epoch [8/300], Step [217/225], Training Accuracy: 46.0181%, Training Loss: 1.1534%\n",
      "Epoch [8/300], Step [218/225], Training Accuracy: 45.9647%, Training Loss: 1.1541%\n",
      "Epoch [8/300], Step [219/225], Training Accuracy: 45.9974%, Training Loss: 1.1535%\n",
      "Epoch [8/300], Step [220/225], Training Accuracy: 46.0440%, Training Loss: 1.1530%\n",
      "Epoch [8/300], Step [221/225], Training Accuracy: 46.0124%, Training Loss: 1.1534%\n",
      "Epoch [8/300], Step [222/225], Training Accuracy: 46.0304%, Training Loss: 1.1535%\n",
      "Epoch [8/300], Step [223/225], Training Accuracy: 46.0132%, Training Loss: 1.1540%\n",
      "Epoch [8/300], Step [224/225], Training Accuracy: 46.0589%, Training Loss: 1.1534%\n",
      "Epoch [8/300], Step [225/225], Training Accuracy: 46.0464%, Training Loss: 1.1535%\n",
      "Epoch [9/300], Step [1/225], Training Accuracy: 46.8750%, Training Loss: 1.1690%\n",
      "Epoch [9/300], Step [2/225], Training Accuracy: 50.7812%, Training Loss: 1.1245%\n",
      "Epoch [9/300], Step [3/225], Training Accuracy: 46.8750%, Training Loss: 1.1504%\n",
      "Epoch [9/300], Step [4/225], Training Accuracy: 46.0938%, Training Loss: 1.1238%\n",
      "Epoch [9/300], Step [5/225], Training Accuracy: 46.8750%, Training Loss: 1.1173%\n",
      "Epoch [9/300], Step [6/225], Training Accuracy: 45.8333%, Training Loss: 1.1265%\n",
      "Epoch [9/300], Step [7/225], Training Accuracy: 45.7589%, Training Loss: 1.1415%\n",
      "Epoch [9/300], Step [8/225], Training Accuracy: 46.8750%, Training Loss: 1.1293%\n",
      "Epoch [9/300], Step [9/225], Training Accuracy: 46.3542%, Training Loss: 1.1348%\n",
      "Epoch [9/300], Step [10/225], Training Accuracy: 46.4062%, Training Loss: 1.1434%\n",
      "Epoch [9/300], Step [11/225], Training Accuracy: 46.5909%, Training Loss: 1.1360%\n",
      "Epoch [9/300], Step [12/225], Training Accuracy: 45.7031%, Training Loss: 1.1433%\n",
      "Epoch [9/300], Step [13/225], Training Accuracy: 46.5144%, Training Loss: 1.1382%\n",
      "Epoch [9/300], Step [14/225], Training Accuracy: 46.5402%, Training Loss: 1.1419%\n",
      "Epoch [9/300], Step [15/225], Training Accuracy: 46.3542%, Training Loss: 1.1449%\n",
      "Epoch [9/300], Step [16/225], Training Accuracy: 46.4844%, Training Loss: 1.1433%\n",
      "Epoch [9/300], Step [17/225], Training Accuracy: 46.5074%, Training Loss: 1.1419%\n",
      "Epoch [9/300], Step [18/225], Training Accuracy: 46.8750%, Training Loss: 1.1396%\n",
      "Epoch [9/300], Step [19/225], Training Accuracy: 46.5461%, Training Loss: 1.1424%\n",
      "Epoch [9/300], Step [20/225], Training Accuracy: 47.1094%, Training Loss: 1.1395%\n",
      "Epoch [9/300], Step [21/225], Training Accuracy: 47.2470%, Training Loss: 1.1365%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/300], Step [22/225], Training Accuracy: 47.5852%, Training Loss: 1.1357%\n",
      "Epoch [9/300], Step [23/225], Training Accuracy: 47.5543%, Training Loss: 1.1370%\n",
      "Epoch [9/300], Step [24/225], Training Accuracy: 47.5260%, Training Loss: 1.1380%\n",
      "Epoch [9/300], Step [25/225], Training Accuracy: 47.5000%, Training Loss: 1.1383%\n",
      "Epoch [9/300], Step [26/225], Training Accuracy: 47.4159%, Training Loss: 1.1374%\n",
      "Epoch [9/300], Step [27/225], Training Accuracy: 47.5116%, Training Loss: 1.1378%\n",
      "Epoch [9/300], Step [28/225], Training Accuracy: 47.8237%, Training Loss: 1.1326%\n",
      "Epoch [9/300], Step [29/225], Training Accuracy: 48.0065%, Training Loss: 1.1276%\n",
      "Epoch [9/300], Step [30/225], Training Accuracy: 48.1771%, Training Loss: 1.1276%\n",
      "Epoch [9/300], Step [31/225], Training Accuracy: 48.1855%, Training Loss: 1.1274%\n",
      "Epoch [9/300], Step [32/225], Training Accuracy: 48.4863%, Training Loss: 1.1241%\n",
      "Epoch [9/300], Step [33/225], Training Accuracy: 48.4375%, Training Loss: 1.1219%\n",
      "Epoch [9/300], Step [34/225], Training Accuracy: 48.2537%, Training Loss: 1.1229%\n",
      "Epoch [9/300], Step [35/225], Training Accuracy: 48.1696%, Training Loss: 1.1260%\n",
      "Epoch [9/300], Step [36/225], Training Accuracy: 48.1771%, Training Loss: 1.1266%\n",
      "Epoch [9/300], Step [37/225], Training Accuracy: 48.2264%, Training Loss: 1.1258%\n",
      "Epoch [9/300], Step [38/225], Training Accuracy: 48.2730%, Training Loss: 1.1262%\n",
      "Epoch [9/300], Step [39/225], Training Accuracy: 48.1170%, Training Loss: 1.1274%\n",
      "Epoch [9/300], Step [40/225], Training Accuracy: 48.1641%, Training Loss: 1.1274%\n",
      "Epoch [9/300], Step [41/225], Training Accuracy: 48.2470%, Training Loss: 1.1253%\n",
      "Epoch [9/300], Step [42/225], Training Accuracy: 48.4003%, Training Loss: 1.1228%\n",
      "Epoch [9/300], Step [43/225], Training Accuracy: 48.5828%, Training Loss: 1.1226%\n",
      "Epoch [9/300], Step [44/225], Training Accuracy: 48.8636%, Training Loss: 1.1219%\n",
      "Epoch [9/300], Step [45/225], Training Accuracy: 48.9236%, Training Loss: 1.1211%\n",
      "Epoch [9/300], Step [46/225], Training Accuracy: 49.0829%, Training Loss: 1.1204%\n",
      "Epoch [9/300], Step [47/225], Training Accuracy: 49.0691%, Training Loss: 1.1206%\n",
      "Epoch [9/300], Step [48/225], Training Accuracy: 49.0234%, Training Loss: 1.1210%\n",
      "Epoch [9/300], Step [49/225], Training Accuracy: 48.9158%, Training Loss: 1.1223%\n",
      "Epoch [9/300], Step [50/225], Training Accuracy: 48.9375%, Training Loss: 1.1212%\n",
      "Epoch [9/300], Step [51/225], Training Accuracy: 48.8051%, Training Loss: 1.1231%\n",
      "Epoch [9/300], Step [52/225], Training Accuracy: 48.8281%, Training Loss: 1.1233%\n",
      "Epoch [9/300], Step [53/225], Training Accuracy: 48.6144%, Training Loss: 1.1245%\n",
      "Epoch [9/300], Step [54/225], Training Accuracy: 48.6400%, Training Loss: 1.1243%\n",
      "Epoch [9/300], Step [55/225], Training Accuracy: 48.6932%, Training Loss: 1.1247%\n",
      "Epoch [9/300], Step [56/225], Training Accuracy: 48.6886%, Training Loss: 1.1242%\n",
      "Epoch [9/300], Step [57/225], Training Accuracy: 48.8487%, Training Loss: 1.1219%\n",
      "Epoch [9/300], Step [58/225], Training Accuracy: 48.6800%, Training Loss: 1.1227%\n",
      "Epoch [9/300], Step [59/225], Training Accuracy: 48.7023%, Training Loss: 1.1220%\n",
      "Epoch [9/300], Step [60/225], Training Accuracy: 48.7760%, Training Loss: 1.1200%\n",
      "Epoch [9/300], Step [61/225], Training Accuracy: 48.6424%, Training Loss: 1.1216%\n",
      "Epoch [9/300], Step [62/225], Training Accuracy: 48.5383%, Training Loss: 1.1223%\n",
      "Epoch [9/300], Step [63/225], Training Accuracy: 48.3879%, Training Loss: 1.1242%\n",
      "Epoch [9/300], Step [64/225], Training Accuracy: 48.4375%, Training Loss: 1.1250%\n",
      "Epoch [9/300], Step [65/225], Training Accuracy: 48.3173%, Training Loss: 1.1261%\n",
      "Epoch [9/300], Step [66/225], Training Accuracy: 48.4848%, Training Loss: 1.1265%\n",
      "Epoch [9/300], Step [67/225], Training Accuracy: 48.5075%, Training Loss: 1.1263%\n",
      "Epoch [9/300], Step [68/225], Training Accuracy: 48.3456%, Training Loss: 1.1264%\n",
      "Epoch [9/300], Step [69/225], Training Accuracy: 48.4149%, Training Loss: 1.1254%\n",
      "Epoch [9/300], Step [70/225], Training Accuracy: 48.5938%, Training Loss: 1.1237%\n",
      "Epoch [9/300], Step [71/225], Training Accuracy: 48.5255%, Training Loss: 1.1239%\n",
      "Epoch [9/300], Step [72/225], Training Accuracy: 48.4158%, Training Loss: 1.1255%\n",
      "Epoch [9/300], Step [73/225], Training Accuracy: 48.4375%, Training Loss: 1.1264%\n",
      "Epoch [9/300], Step [74/225], Training Accuracy: 48.6064%, Training Loss: 1.1242%\n",
      "Epoch [9/300], Step [75/225], Training Accuracy: 48.6250%, Training Loss: 1.1238%\n",
      "Epoch [9/300], Step [76/225], Training Accuracy: 48.6842%, Training Loss: 1.1236%\n",
      "Epoch [9/300], Step [77/225], Training Accuracy: 48.6607%, Training Loss: 1.1237%\n",
      "Epoch [9/300], Step [78/225], Training Accuracy: 48.6579%, Training Loss: 1.1237%\n",
      "Epoch [9/300], Step [79/225], Training Accuracy: 48.6353%, Training Loss: 1.1241%\n",
      "Epoch [9/300], Step [80/225], Training Accuracy: 48.5156%, Training Loss: 1.1253%\n",
      "Epoch [9/300], Step [81/225], Training Accuracy: 48.4568%, Training Loss: 1.1257%\n",
      "Epoch [9/300], Step [82/225], Training Accuracy: 48.3613%, Training Loss: 1.1265%\n",
      "Epoch [9/300], Step [83/225], Training Accuracy: 48.3810%, Training Loss: 1.1270%\n",
      "Epoch [9/300], Step [84/225], Training Accuracy: 48.3445%, Training Loss: 1.1275%\n",
      "Epoch [9/300], Step [85/225], Training Accuracy: 48.3824%, Training Loss: 1.1274%\n",
      "Epoch [9/300], Step [86/225], Training Accuracy: 48.3103%, Training Loss: 1.1271%\n",
      "Epoch [9/300], Step [87/225], Training Accuracy: 48.3118%, Training Loss: 1.1268%\n",
      "Epoch [9/300], Step [88/225], Training Accuracy: 48.2599%, Training Loss: 1.1275%\n",
      "Epoch [9/300], Step [89/225], Training Accuracy: 48.2971%, Training Loss: 1.1270%\n",
      "Epoch [9/300], Step [90/225], Training Accuracy: 48.2292%, Training Loss: 1.1264%\n",
      "Epoch [9/300], Step [91/225], Training Accuracy: 48.2315%, Training Loss: 1.1256%\n",
      "Epoch [9/300], Step [92/225], Training Accuracy: 48.1148%, Training Loss: 1.1272%\n",
      "Epoch [9/300], Step [93/225], Training Accuracy: 48.0679%, Training Loss: 1.1277%\n",
      "Epoch [9/300], Step [94/225], Training Accuracy: 48.0718%, Training Loss: 1.1272%\n",
      "Epoch [9/300], Step [95/225], Training Accuracy: 48.0099%, Training Loss: 1.1281%\n",
      "Epoch [9/300], Step [96/225], Training Accuracy: 48.0957%, Training Loss: 1.1274%\n",
      "Epoch [9/300], Step [97/225], Training Accuracy: 48.0187%, Training Loss: 1.1272%\n",
      "Epoch [9/300], Step [98/225], Training Accuracy: 48.1027%, Training Loss: 1.1263%\n",
      "Epoch [9/300], Step [99/225], Training Accuracy: 48.1692%, Training Loss: 1.1255%\n",
      "Epoch [9/300], Step [100/225], Training Accuracy: 48.1875%, Training Loss: 1.1257%\n",
      "Epoch [9/300], Step [101/225], Training Accuracy: 48.2209%, Training Loss: 1.1254%\n",
      "Epoch [9/300], Step [102/225], Training Accuracy: 48.2230%, Training Loss: 1.1255%\n",
      "Epoch [9/300], Step [103/225], Training Accuracy: 48.1644%, Training Loss: 1.1264%\n",
      "Epoch [9/300], Step [104/225], Training Accuracy: 48.1971%, Training Loss: 1.1257%\n",
      "Epoch [9/300], Step [105/225], Training Accuracy: 48.2589%, Training Loss: 1.1261%\n",
      "Epoch [9/300], Step [106/225], Training Accuracy: 48.3196%, Training Loss: 1.1256%\n",
      "Epoch [9/300], Step [107/225], Training Accuracy: 48.3061%, Training Loss: 1.1257%\n",
      "Epoch [9/300], Step [108/225], Training Accuracy: 48.2639%, Training Loss: 1.1261%\n",
      "Epoch [9/300], Step [109/225], Training Accuracy: 48.2081%, Training Loss: 1.1268%\n",
      "Epoch [9/300], Step [110/225], Training Accuracy: 48.1392%, Training Loss: 1.1267%\n",
      "Epoch [9/300], Step [111/225], Training Accuracy: 48.1560%, Training Loss: 1.1268%\n",
      "Epoch [9/300], Step [112/225], Training Accuracy: 48.2003%, Training Loss: 1.1265%\n",
      "Epoch [9/300], Step [113/225], Training Accuracy: 48.2024%, Training Loss: 1.1271%\n",
      "Epoch [9/300], Step [114/225], Training Accuracy: 48.1634%, Training Loss: 1.1271%\n",
      "Epoch [9/300], Step [115/225], Training Accuracy: 48.1114%, Training Loss: 1.1286%\n",
      "Epoch [9/300], Step [116/225], Training Accuracy: 48.0873%, Training Loss: 1.1286%\n",
      "Epoch [9/300], Step [117/225], Training Accuracy: 48.0636%, Training Loss: 1.1287%\n",
      "Epoch [9/300], Step [118/225], Training Accuracy: 47.9873%, Training Loss: 1.1300%\n",
      "Epoch [9/300], Step [119/225], Training Accuracy: 48.0436%, Training Loss: 1.1297%\n",
      "Epoch [9/300], Step [120/225], Training Accuracy: 48.0339%, Training Loss: 1.1296%\n",
      "Epoch [9/300], Step [121/225], Training Accuracy: 47.9985%, Training Loss: 1.1295%\n",
      "Epoch [9/300], Step [122/225], Training Accuracy: 48.0020%, Training Loss: 1.1302%\n",
      "Epoch [9/300], Step [123/225], Training Accuracy: 48.0183%, Training Loss: 1.1302%\n",
      "Epoch [9/300], Step [124/225], Training Accuracy: 48.0973%, Training Loss: 1.1300%\n",
      "Epoch [9/300], Step [125/225], Training Accuracy: 48.0375%, Training Loss: 1.1301%\n",
      "Epoch [9/300], Step [126/225], Training Accuracy: 48.0283%, Training Loss: 1.1303%\n",
      "Epoch [9/300], Step [127/225], Training Accuracy: 48.0315%, Training Loss: 1.1301%\n",
      "Epoch [9/300], Step [128/225], Training Accuracy: 48.0225%, Training Loss: 1.1305%\n",
      "Epoch [9/300], Step [129/225], Training Accuracy: 48.0741%, Training Loss: 1.1303%\n",
      "Epoch [9/300], Step [130/225], Training Accuracy: 48.0529%, Training Loss: 1.1301%\n",
      "Epoch [9/300], Step [131/225], Training Accuracy: 48.1035%, Training Loss: 1.1295%\n",
      "Epoch [9/300], Step [132/225], Training Accuracy: 48.0705%, Training Loss: 1.1294%\n",
      "Epoch [9/300], Step [133/225], Training Accuracy: 48.1320%, Training Loss: 1.1285%\n",
      "Epoch [9/300], Step [134/225], Training Accuracy: 48.0760%, Training Loss: 1.1290%\n",
      "Epoch [9/300], Step [135/225], Training Accuracy: 48.1134%, Training Loss: 1.1287%\n",
      "Epoch [9/300], Step [136/225], Training Accuracy: 48.0813%, Training Loss: 1.1290%\n",
      "Epoch [9/300], Step [137/225], Training Accuracy: 48.0839%, Training Loss: 1.1288%\n",
      "Epoch [9/300], Step [138/225], Training Accuracy: 48.1431%, Training Loss: 1.1282%\n",
      "Epoch [9/300], Step [139/225], Training Accuracy: 48.1340%, Training Loss: 1.1283%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/300], Step [140/225], Training Accuracy: 48.2031%, Training Loss: 1.1276%\n",
      "Epoch [9/300], Step [141/225], Training Accuracy: 48.1161%, Training Loss: 1.1277%\n",
      "Epoch [9/300], Step [142/225], Training Accuracy: 48.1624%, Training Loss: 1.1275%\n",
      "Epoch [9/300], Step [143/225], Training Accuracy: 48.0878%, Training Loss: 1.1276%\n",
      "Epoch [9/300], Step [144/225], Training Accuracy: 48.0903%, Training Loss: 1.1274%\n",
      "Epoch [9/300], Step [145/225], Training Accuracy: 48.1034%, Training Loss: 1.1274%\n",
      "Epoch [9/300], Step [146/225], Training Accuracy: 48.0950%, Training Loss: 1.1272%\n",
      "Epoch [9/300], Step [147/225], Training Accuracy: 48.1293%, Training Loss: 1.1273%\n",
      "Epoch [9/300], Step [148/225], Training Accuracy: 48.1841%, Training Loss: 1.1265%\n",
      "Epoch [9/300], Step [149/225], Training Accuracy: 48.2173%, Training Loss: 1.1265%\n",
      "Epoch [9/300], Step [150/225], Training Accuracy: 48.2188%, Training Loss: 1.1259%\n",
      "Epoch [9/300], Step [151/225], Training Accuracy: 48.2823%, Training Loss: 1.1246%\n",
      "Epoch [9/300], Step [152/225], Training Accuracy: 48.3039%, Training Loss: 1.1245%\n",
      "Epoch [9/300], Step [153/225], Training Accuracy: 48.3456%, Training Loss: 1.1241%\n",
      "Epoch [9/300], Step [154/225], Training Accuracy: 48.3766%, Training Loss: 1.1238%\n",
      "Epoch [9/300], Step [155/225], Training Accuracy: 48.3770%, Training Loss: 1.1240%\n",
      "Epoch [9/300], Step [156/225], Training Accuracy: 48.3073%, Training Loss: 1.1248%\n",
      "Epoch [9/300], Step [157/225], Training Accuracy: 48.3380%, Training Loss: 1.1243%\n",
      "Epoch [9/300], Step [158/225], Training Accuracy: 48.3979%, Training Loss: 1.1240%\n",
      "Epoch [9/300], Step [159/225], Training Accuracy: 48.3884%, Training Loss: 1.1241%\n",
      "Epoch [9/300], Step [160/225], Training Accuracy: 48.3496%, Training Loss: 1.1243%\n",
      "Epoch [9/300], Step [161/225], Training Accuracy: 48.3696%, Training Loss: 1.1240%\n",
      "Epoch [9/300], Step [162/225], Training Accuracy: 48.3700%, Training Loss: 1.1238%\n",
      "Epoch [9/300], Step [163/225], Training Accuracy: 48.4183%, Training Loss: 1.1229%\n",
      "Epoch [9/300], Step [164/225], Training Accuracy: 48.4756%, Training Loss: 1.1221%\n",
      "Epoch [9/300], Step [165/225], Training Accuracy: 48.4659%, Training Loss: 1.1223%\n",
      "Epoch [9/300], Step [166/225], Training Accuracy: 48.4657%, Training Loss: 1.1221%\n",
      "Epoch [9/300], Step [167/225], Training Accuracy: 48.5217%, Training Loss: 1.1222%\n",
      "Epoch [9/300], Step [168/225], Training Accuracy: 48.4933%, Training Loss: 1.1219%\n",
      "Epoch [9/300], Step [169/225], Training Accuracy: 48.5022%, Training Loss: 1.1219%\n",
      "Epoch [9/300], Step [170/225], Training Accuracy: 48.5110%, Training Loss: 1.1215%\n",
      "Epoch [9/300], Step [171/225], Training Accuracy: 48.5471%, Training Loss: 1.1209%\n",
      "Epoch [9/300], Step [172/225], Training Accuracy: 48.5556%, Training Loss: 1.1206%\n",
      "Epoch [9/300], Step [173/225], Training Accuracy: 48.5098%, Training Loss: 1.1207%\n",
      "Epoch [9/300], Step [174/225], Training Accuracy: 48.5542%, Training Loss: 1.1203%\n",
      "Epoch [9/300], Step [175/225], Training Accuracy: 48.5982%, Training Loss: 1.1198%\n",
      "Epoch [9/300], Step [176/225], Training Accuracy: 48.6151%, Training Loss: 1.1198%\n",
      "Epoch [9/300], Step [177/225], Training Accuracy: 48.5964%, Training Loss: 1.1194%\n",
      "Epoch [9/300], Step [178/225], Training Accuracy: 48.6131%, Training Loss: 1.1196%\n",
      "Epoch [9/300], Step [179/225], Training Accuracy: 48.6034%, Training Loss: 1.1197%\n",
      "Epoch [9/300], Step [180/225], Training Accuracy: 48.6458%, Training Loss: 1.1190%\n",
      "Epoch [9/300], Step [181/225], Training Accuracy: 48.6619%, Training Loss: 1.1191%\n",
      "Epoch [9/300], Step [182/225], Training Accuracy: 48.6951%, Training Loss: 1.1187%\n",
      "Epoch [9/300], Step [183/225], Training Accuracy: 48.7193%, Training Loss: 1.1181%\n",
      "Epoch [9/300], Step [184/225], Training Accuracy: 48.6583%, Training Loss: 1.1184%\n",
      "Epoch [9/300], Step [185/225], Training Accuracy: 48.6318%, Training Loss: 1.1184%\n",
      "Epoch [9/300], Step [186/225], Training Accuracy: 48.6895%, Training Loss: 1.1176%\n",
      "Epoch [9/300], Step [187/225], Training Accuracy: 48.6715%, Training Loss: 1.1175%\n",
      "Epoch [9/300], Step [188/225], Training Accuracy: 48.6619%, Training Loss: 1.1174%\n",
      "Epoch [9/300], Step [189/225], Training Accuracy: 48.6607%, Training Loss: 1.1172%\n",
      "Epoch [9/300], Step [190/225], Training Accuracy: 48.6595%, Training Loss: 1.1168%\n",
      "Epoch [9/300], Step [191/225], Training Accuracy: 48.6257%, Training Loss: 1.1172%\n",
      "Epoch [9/300], Step [192/225], Training Accuracy: 48.6003%, Training Loss: 1.1176%\n",
      "Epoch [9/300], Step [193/225], Training Accuracy: 48.5508%, Training Loss: 1.1179%\n",
      "Epoch [9/300], Step [194/225], Training Accuracy: 48.6066%, Training Loss: 1.1174%\n",
      "Epoch [9/300], Step [195/225], Training Accuracy: 48.5577%, Training Loss: 1.1173%\n",
      "Epoch [9/300], Step [196/225], Training Accuracy: 48.5810%, Training Loss: 1.1171%\n",
      "Epoch [9/300], Step [197/225], Training Accuracy: 48.5485%, Training Loss: 1.1175%\n",
      "Epoch [9/300], Step [198/225], Training Accuracy: 48.6032%, Training Loss: 1.1172%\n",
      "Epoch [9/300], Step [199/225], Training Accuracy: 48.5788%, Training Loss: 1.1173%\n",
      "Epoch [9/300], Step [200/225], Training Accuracy: 48.6016%, Training Loss: 1.1177%\n",
      "Epoch [9/300], Step [201/225], Training Accuracy: 48.6629%, Training Loss: 1.1171%\n",
      "Epoch [9/300], Step [202/225], Training Accuracy: 48.6541%, Training Loss: 1.1169%\n",
      "Epoch [9/300], Step [203/225], Training Accuracy: 48.6453%, Training Loss: 1.1172%\n",
      "Epoch [9/300], Step [204/225], Training Accuracy: 48.6443%, Training Loss: 1.1171%\n",
      "Epoch [9/300], Step [205/225], Training Accuracy: 48.6509%, Training Loss: 1.1170%\n",
      "Epoch [9/300], Step [206/225], Training Accuracy: 48.6575%, Training Loss: 1.1173%\n",
      "Epoch [9/300], Step [207/225], Training Accuracy: 48.7168%, Training Loss: 1.1167%\n",
      "Epoch [9/300], Step [208/225], Training Accuracy: 48.7305%, Training Loss: 1.1163%\n",
      "Epoch [9/300], Step [209/225], Training Accuracy: 48.7515%, Training Loss: 1.1161%\n",
      "Epoch [9/300], Step [210/225], Training Accuracy: 48.7202%, Training Loss: 1.1164%\n",
      "Epoch [9/300], Step [211/225], Training Accuracy: 48.7411%, Training Loss: 1.1159%\n",
      "Epoch [9/300], Step [212/225], Training Accuracy: 48.7102%, Training Loss: 1.1162%\n",
      "Epoch [9/300], Step [213/225], Training Accuracy: 48.7383%, Training Loss: 1.1160%\n",
      "Epoch [9/300], Step [214/225], Training Accuracy: 48.7077%, Training Loss: 1.1164%\n",
      "Epoch [9/300], Step [215/225], Training Accuracy: 48.7427%, Training Loss: 1.1159%\n",
      "Epoch [9/300], Step [216/225], Training Accuracy: 48.7269%, Training Loss: 1.1165%\n",
      "Epoch [9/300], Step [217/225], Training Accuracy: 48.7543%, Training Loss: 1.1161%\n",
      "Epoch [9/300], Step [218/225], Training Accuracy: 48.7242%, Training Loss: 1.1167%\n",
      "Epoch [9/300], Step [219/225], Training Accuracy: 48.7158%, Training Loss: 1.1164%\n",
      "Epoch [9/300], Step [220/225], Training Accuracy: 48.7358%, Training Loss: 1.1161%\n",
      "Epoch [9/300], Step [221/225], Training Accuracy: 48.6920%, Training Loss: 1.1167%\n",
      "Epoch [9/300], Step [222/225], Training Accuracy: 48.6698%, Training Loss: 1.1170%\n",
      "Epoch [9/300], Step [223/225], Training Accuracy: 48.6197%, Training Loss: 1.1173%\n",
      "Epoch [9/300], Step [224/225], Training Accuracy: 48.6328%, Training Loss: 1.1170%\n",
      "Epoch [9/300], Step [225/225], Training Accuracy: 48.6451%, Training Loss: 1.1170%\n",
      "Epoch [10/300], Step [1/225], Training Accuracy: 45.3125%, Training Loss: 1.1065%\n",
      "Epoch [10/300], Step [2/225], Training Accuracy: 48.4375%, Training Loss: 1.0778%\n",
      "Epoch [10/300], Step [3/225], Training Accuracy: 45.3125%, Training Loss: 1.1272%\n",
      "Epoch [10/300], Step [4/225], Training Accuracy: 46.8750%, Training Loss: 1.1008%\n",
      "Epoch [10/300], Step [5/225], Training Accuracy: 47.5000%, Training Loss: 1.0923%\n",
      "Epoch [10/300], Step [6/225], Training Accuracy: 47.3958%, Training Loss: 1.1035%\n",
      "Epoch [10/300], Step [7/225], Training Accuracy: 47.0982%, Training Loss: 1.1218%\n",
      "Epoch [10/300], Step [8/225], Training Accuracy: 47.0703%, Training Loss: 1.1150%\n",
      "Epoch [10/300], Step [9/225], Training Accuracy: 47.5694%, Training Loss: 1.1129%\n",
      "Epoch [10/300], Step [10/225], Training Accuracy: 47.0312%, Training Loss: 1.1165%\n",
      "Epoch [10/300], Step [11/225], Training Accuracy: 48.0114%, Training Loss: 1.1065%\n",
      "Epoch [10/300], Step [12/225], Training Accuracy: 46.7448%, Training Loss: 1.1196%\n",
      "Epoch [10/300], Step [13/225], Training Accuracy: 46.8750%, Training Loss: 1.1164%\n",
      "Epoch [10/300], Step [14/225], Training Accuracy: 46.4286%, Training Loss: 1.1208%\n",
      "Epoch [10/300], Step [15/225], Training Accuracy: 46.2500%, Training Loss: 1.1253%\n",
      "Epoch [10/300], Step [16/225], Training Accuracy: 46.3867%, Training Loss: 1.1270%\n",
      "Epoch [10/300], Step [17/225], Training Accuracy: 46.4154%, Training Loss: 1.1277%\n",
      "Epoch [10/300], Step [18/225], Training Accuracy: 46.6146%, Training Loss: 1.1267%\n",
      "Epoch [10/300], Step [19/225], Training Accuracy: 46.0526%, Training Loss: 1.1261%\n",
      "Epoch [10/300], Step [20/225], Training Accuracy: 46.4062%, Training Loss: 1.1206%\n",
      "Epoch [10/300], Step [21/225], Training Accuracy: 46.8750%, Training Loss: 1.1158%\n",
      "Epoch [10/300], Step [22/225], Training Accuracy: 47.3011%, Training Loss: 1.1155%\n",
      "Epoch [10/300], Step [23/225], Training Accuracy: 47.1467%, Training Loss: 1.1177%\n",
      "Epoch [10/300], Step [24/225], Training Accuracy: 47.2005%, Training Loss: 1.1191%\n",
      "Epoch [10/300], Step [25/225], Training Accuracy: 47.1875%, Training Loss: 1.1163%\n",
      "Epoch [10/300], Step [26/225], Training Accuracy: 47.1755%, Training Loss: 1.1176%\n",
      "Epoch [10/300], Step [27/225], Training Accuracy: 47.3958%, Training Loss: 1.1160%\n",
      "Epoch [10/300], Step [28/225], Training Accuracy: 48.1027%, Training Loss: 1.1096%\n",
      "Epoch [10/300], Step [29/225], Training Accuracy: 48.3297%, Training Loss: 1.1046%\n",
      "Epoch [10/300], Step [30/225], Training Accuracy: 48.4896%, Training Loss: 1.1033%\n",
      "Epoch [10/300], Step [31/225], Training Accuracy: 48.5383%, Training Loss: 1.1028%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/300], Step [32/225], Training Accuracy: 48.7305%, Training Loss: 1.0990%\n",
      "Epoch [10/300], Step [33/225], Training Accuracy: 48.9583%, Training Loss: 1.0956%\n",
      "Epoch [10/300], Step [34/225], Training Accuracy: 49.0809%, Training Loss: 1.0961%\n",
      "Epoch [10/300], Step [35/225], Training Accuracy: 49.0625%, Training Loss: 1.0992%\n",
      "Epoch [10/300], Step [36/225], Training Accuracy: 48.9583%, Training Loss: 1.1017%\n",
      "Epoch [10/300], Step [37/225], Training Accuracy: 48.9443%, Training Loss: 1.1019%\n",
      "Epoch [10/300], Step [38/225], Training Accuracy: 49.0954%, Training Loss: 1.1007%\n",
      "Epoch [10/300], Step [39/225], Training Accuracy: 49.0785%, Training Loss: 1.1017%\n",
      "Epoch [10/300], Step [40/225], Training Accuracy: 48.8672%, Training Loss: 1.1034%\n",
      "Epoch [10/300], Step [41/225], Training Accuracy: 48.9329%, Training Loss: 1.1010%\n",
      "Epoch [10/300], Step [42/225], Training Accuracy: 49.1815%, Training Loss: 1.0991%\n",
      "Epoch [10/300], Step [43/225], Training Accuracy: 49.5276%, Training Loss: 1.0991%\n",
      "Epoch [10/300], Step [44/225], Training Accuracy: 49.6449%, Training Loss: 1.0989%\n",
      "Epoch [10/300], Step [45/225], Training Accuracy: 49.8264%, Training Loss: 1.0981%\n",
      "Epoch [10/300], Step [46/225], Training Accuracy: 49.9321%, Training Loss: 1.0957%\n",
      "Epoch [10/300], Step [47/225], Training Accuracy: 50.0332%, Training Loss: 1.0949%\n",
      "Epoch [10/300], Step [48/225], Training Accuracy: 49.9023%, Training Loss: 1.0951%\n",
      "Epoch [10/300], Step [49/225], Training Accuracy: 49.7449%, Training Loss: 1.0963%\n",
      "Epoch [10/300], Step [50/225], Training Accuracy: 49.9062%, Training Loss: 1.0947%\n",
      "Epoch [10/300], Step [51/225], Training Accuracy: 49.8162%, Training Loss: 1.0956%\n",
      "Epoch [10/300], Step [52/225], Training Accuracy: 49.8798%, Training Loss: 1.0942%\n",
      "Epoch [10/300], Step [53/225], Training Accuracy: 49.7347%, Training Loss: 1.0950%\n",
      "Epoch [10/300], Step [54/225], Training Accuracy: 49.5949%, Training Loss: 1.0948%\n",
      "Epoch [10/300], Step [55/225], Training Accuracy: 49.6875%, Training Loss: 1.0951%\n",
      "Epoch [10/300], Step [56/225], Training Accuracy: 49.6931%, Training Loss: 1.0933%\n",
      "Epoch [10/300], Step [57/225], Training Accuracy: 49.8081%, Training Loss: 1.0917%\n",
      "Epoch [10/300], Step [58/225], Training Accuracy: 49.5420%, Training Loss: 1.0925%\n",
      "Epoch [10/300], Step [59/225], Training Accuracy: 49.6292%, Training Loss: 1.0917%\n",
      "Epoch [10/300], Step [60/225], Training Accuracy: 49.6875%, Training Loss: 1.0899%\n",
      "Epoch [10/300], Step [61/225], Training Accuracy: 49.6926%, Training Loss: 1.0906%\n",
      "Epoch [10/300], Step [62/225], Training Accuracy: 49.6976%, Training Loss: 1.0907%\n",
      "Epoch [10/300], Step [63/225], Training Accuracy: 49.4544%, Training Loss: 1.0935%\n",
      "Epoch [10/300], Step [64/225], Training Accuracy: 49.5361%, Training Loss: 1.0936%\n",
      "Epoch [10/300], Step [65/225], Training Accuracy: 49.4952%, Training Loss: 1.0937%\n",
      "Epoch [10/300], Step [66/225], Training Accuracy: 49.5739%, Training Loss: 1.0934%\n",
      "Epoch [10/300], Step [67/225], Training Accuracy: 49.6502%, Training Loss: 1.0927%\n",
      "Epoch [10/300], Step [68/225], Training Accuracy: 49.6324%, Training Loss: 1.0921%\n",
      "Epoch [10/300], Step [69/225], Training Accuracy: 49.5924%, Training Loss: 1.0916%\n",
      "Epoch [10/300], Step [70/225], Training Accuracy: 49.7098%, Training Loss: 1.0906%\n",
      "Epoch [10/300], Step [71/225], Training Accuracy: 49.7799%, Training Loss: 1.0894%\n",
      "Epoch [10/300], Step [72/225], Training Accuracy: 49.5660%, Training Loss: 1.0913%\n",
      "Epoch [10/300], Step [73/225], Training Accuracy: 49.5505%, Training Loss: 1.0929%\n",
      "Epoch [10/300], Step [74/225], Training Accuracy: 49.6199%, Training Loss: 1.0918%\n",
      "Epoch [10/300], Step [75/225], Training Accuracy: 49.6458%, Training Loss: 1.0916%\n",
      "Epoch [10/300], Step [76/225], Training Accuracy: 49.5477%, Training Loss: 1.0917%\n",
      "Epoch [10/300], Step [77/225], Training Accuracy: 49.6144%, Training Loss: 1.0910%\n",
      "Epoch [10/300], Step [78/225], Training Accuracy: 49.6194%, Training Loss: 1.0911%\n",
      "Epoch [10/300], Step [79/225], Training Accuracy: 49.6044%, Training Loss: 1.0918%\n",
      "Epoch [10/300], Step [80/225], Training Accuracy: 49.3945%, Training Loss: 1.0934%\n",
      "Epoch [10/300], Step [81/225], Training Accuracy: 49.3634%, Training Loss: 1.0936%\n",
      "Epoch [10/300], Step [82/225], Training Accuracy: 49.4093%, Training Loss: 1.0937%\n",
      "Epoch [10/300], Step [83/225], Training Accuracy: 49.3976%, Training Loss: 1.0931%\n",
      "Epoch [10/300], Step [84/225], Training Accuracy: 49.3676%, Training Loss: 1.0942%\n",
      "Epoch [10/300], Step [85/225], Training Accuracy: 49.3566%, Training Loss: 1.0950%\n",
      "Epoch [10/300], Step [86/225], Training Accuracy: 49.3641%, Training Loss: 1.0948%\n",
      "Epoch [10/300], Step [87/225], Training Accuracy: 49.3534%, Training Loss: 1.0946%\n",
      "Epoch [10/300], Step [88/225], Training Accuracy: 49.3253%, Training Loss: 1.0951%\n",
      "Epoch [10/300], Step [89/225], Training Accuracy: 49.3855%, Training Loss: 1.0948%\n",
      "Epoch [10/300], Step [90/225], Training Accuracy: 49.3229%, Training Loss: 1.0951%\n",
      "Epoch [10/300], Step [91/225], Training Accuracy: 49.3475%, Training Loss: 1.0944%\n",
      "Epoch [10/300], Step [92/225], Training Accuracy: 49.2018%, Training Loss: 1.0960%\n",
      "Epoch [10/300], Step [93/225], Training Accuracy: 49.1935%, Training Loss: 1.0966%\n",
      "Epoch [10/300], Step [94/225], Training Accuracy: 49.1356%, Training Loss: 1.0966%\n",
      "Epoch [10/300], Step [95/225], Training Accuracy: 49.1118%, Training Loss: 1.0968%\n",
      "Epoch [10/300], Step [96/225], Training Accuracy: 49.1048%, Training Loss: 1.0967%\n",
      "Epoch [10/300], Step [97/225], Training Accuracy: 49.0496%, Training Loss: 1.0970%\n",
      "Epoch [10/300], Step [98/225], Training Accuracy: 49.1550%, Training Loss: 1.0963%\n",
      "Epoch [10/300], Step [99/225], Training Accuracy: 49.1162%, Training Loss: 1.0962%\n",
      "Epoch [10/300], Step [100/225], Training Accuracy: 49.0625%, Training Loss: 1.0971%\n",
      "Epoch [10/300], Step [101/225], Training Accuracy: 49.1337%, Training Loss: 1.0973%\n",
      "Epoch [10/300], Step [102/225], Training Accuracy: 49.1115%, Training Loss: 1.0973%\n",
      "Epoch [10/300], Step [103/225], Training Accuracy: 49.1353%, Training Loss: 1.0973%\n",
      "Epoch [10/300], Step [104/225], Training Accuracy: 49.1286%, Training Loss: 1.0971%\n",
      "Epoch [10/300], Step [105/225], Training Accuracy: 49.2113%, Training Loss: 1.0965%\n",
      "Epoch [10/300], Step [106/225], Training Accuracy: 49.2630%, Training Loss: 1.0955%\n",
      "Epoch [10/300], Step [107/225], Training Accuracy: 49.2553%, Training Loss: 1.0957%\n",
      "Epoch [10/300], Step [108/225], Training Accuracy: 49.1898%, Training Loss: 1.0960%\n",
      "Epoch [10/300], Step [109/225], Training Accuracy: 49.1686%, Training Loss: 1.0964%\n",
      "Epoch [10/300], Step [110/225], Training Accuracy: 49.1193%, Training Loss: 1.0959%\n",
      "Epoch [10/300], Step [111/225], Training Accuracy: 49.0991%, Training Loss: 1.0964%\n",
      "Epoch [10/300], Step [112/225], Training Accuracy: 49.1071%, Training Loss: 1.0956%\n",
      "Epoch [10/300], Step [113/225], Training Accuracy: 49.0597%, Training Loss: 1.0964%\n",
      "Epoch [10/300], Step [114/225], Training Accuracy: 49.0543%, Training Loss: 1.0964%\n",
      "Epoch [10/300], Step [115/225], Training Accuracy: 48.9946%, Training Loss: 1.0979%\n",
      "Epoch [10/300], Step [116/225], Training Accuracy: 48.9898%, Training Loss: 1.0977%\n",
      "Epoch [10/300], Step [117/225], Training Accuracy: 48.9717%, Training Loss: 1.0980%\n",
      "Epoch [10/300], Step [118/225], Training Accuracy: 48.8877%, Training Loss: 1.0990%\n",
      "Epoch [10/300], Step [119/225], Training Accuracy: 48.8708%, Training Loss: 1.0994%\n",
      "Epoch [10/300], Step [120/225], Training Accuracy: 48.9193%, Training Loss: 1.0988%\n",
      "Epoch [10/300], Step [121/225], Training Accuracy: 48.9282%, Training Loss: 1.0993%\n",
      "Epoch [10/300], Step [122/225], Training Accuracy: 48.8858%, Training Loss: 1.0998%\n",
      "Epoch [10/300], Step [123/225], Training Accuracy: 48.8948%, Training Loss: 1.0998%\n",
      "Epoch [10/300], Step [124/225], Training Accuracy: 48.9415%, Training Loss: 1.0998%\n",
      "Epoch [10/300], Step [125/225], Training Accuracy: 48.9250%, Training Loss: 1.0999%\n",
      "Epoch [10/300], Step [126/225], Training Accuracy: 48.9459%, Training Loss: 1.0997%\n",
      "Epoch [10/300], Step [127/225], Training Accuracy: 48.9542%, Training Loss: 1.0994%\n",
      "Epoch [10/300], Step [128/225], Training Accuracy: 48.8770%, Training Loss: 1.1004%\n",
      "Epoch [10/300], Step [129/225], Training Accuracy: 48.9220%, Training Loss: 1.0997%\n",
      "Epoch [10/300], Step [130/225], Training Accuracy: 48.9183%, Training Loss: 1.0999%\n",
      "Epoch [10/300], Step [131/225], Training Accuracy: 48.8669%, Training Loss: 1.1002%\n",
      "Epoch [10/300], Step [132/225], Training Accuracy: 48.8400%, Training Loss: 1.1004%\n",
      "Epoch [10/300], Step [133/225], Training Accuracy: 48.9074%, Training Loss: 1.0993%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/300], Step [134/225], Training Accuracy: 48.8340%, Training Loss: 1.1002%\n",
      "Epoch [10/300], Step [135/225], Training Accuracy: 48.8657%, Training Loss: 1.0999%\n",
      "Epoch [10/300], Step [136/225], Training Accuracy: 48.8396%, Training Loss: 1.1004%\n",
      "Epoch [10/300], Step [137/225], Training Accuracy: 48.8367%, Training Loss: 1.1002%\n",
      "Epoch [10/300], Step [138/225], Training Accuracy: 48.9357%, Training Loss: 1.0994%\n",
      "Epoch [10/300], Step [139/225], Training Accuracy: 48.9321%, Training Loss: 1.0992%\n",
      "Epoch [10/300], Step [140/225], Training Accuracy: 48.9621%, Training Loss: 1.0984%\n",
      "Epoch [10/300], Step [141/225], Training Accuracy: 48.9251%, Training Loss: 1.0989%\n",
      "Epoch [10/300], Step [142/225], Training Accuracy: 48.9327%, Training Loss: 1.0984%\n",
      "Epoch [10/300], Step [143/225], Training Accuracy: 48.9183%, Training Loss: 1.0986%\n",
      "Epoch [10/300], Step [144/225], Training Accuracy: 48.9149%, Training Loss: 1.0987%\n",
      "Epoch [10/300], Step [145/225], Training Accuracy: 48.8901%, Training Loss: 1.0991%\n",
      "Epoch [10/300], Step [146/225], Training Accuracy: 48.8549%, Training Loss: 1.0989%\n",
      "Epoch [10/300], Step [147/225], Training Accuracy: 48.9052%, Training Loss: 1.0988%\n",
      "Epoch [10/300], Step [148/225], Training Accuracy: 48.9337%, Training Loss: 1.0980%\n",
      "Epoch [10/300], Step [149/225], Training Accuracy: 48.9513%, Training Loss: 1.0977%\n",
      "Epoch [10/300], Step [150/225], Training Accuracy: 48.9896%, Training Loss: 1.0970%\n",
      "Epoch [10/300], Step [151/225], Training Accuracy: 49.0377%, Training Loss: 1.0961%\n",
      "Epoch [10/300], Step [152/225], Training Accuracy: 49.0440%, Training Loss: 1.0959%\n",
      "Epoch [10/300], Step [153/225], Training Accuracy: 49.0605%, Training Loss: 1.0953%\n",
      "Epoch [10/300], Step [154/225], Training Accuracy: 49.0666%, Training Loss: 1.0947%\n",
      "Epoch [10/300], Step [155/225], Training Accuracy: 49.0625%, Training Loss: 1.0949%\n",
      "Epoch [10/300], Step [156/225], Training Accuracy: 49.0585%, Training Loss: 1.0953%\n",
      "Epoch [10/300], Step [157/225], Training Accuracy: 49.1740%, Training Loss: 1.0943%\n",
      "Epoch [10/300], Step [158/225], Training Accuracy: 49.1891%, Training Loss: 1.0941%\n",
      "Epoch [10/300], Step [159/225], Training Accuracy: 49.1549%, Training Loss: 1.0942%\n",
      "Epoch [10/300], Step [160/225], Training Accuracy: 49.1406%, Training Loss: 1.0941%\n",
      "Epoch [10/300], Step [161/225], Training Accuracy: 49.1168%, Training Loss: 1.0937%\n",
      "Epoch [10/300], Step [162/225], Training Accuracy: 49.1030%, Training Loss: 1.0935%\n",
      "Epoch [10/300], Step [163/225], Training Accuracy: 49.1469%, Training Loss: 1.0922%\n",
      "Epoch [10/300], Step [164/225], Training Accuracy: 49.2092%, Training Loss: 1.0913%\n",
      "Epoch [10/300], Step [165/225], Training Accuracy: 49.2045%, Training Loss: 1.0915%\n",
      "Epoch [10/300], Step [166/225], Training Accuracy: 49.2093%, Training Loss: 1.0913%\n",
      "Epoch [10/300], Step [167/225], Training Accuracy: 49.2234%, Training Loss: 1.0913%\n",
      "Epoch [10/300], Step [168/225], Training Accuracy: 49.2001%, Training Loss: 1.0911%\n",
      "Epoch [10/300], Step [169/225], Training Accuracy: 49.2141%, Training Loss: 1.0911%\n",
      "Epoch [10/300], Step [170/225], Training Accuracy: 49.2188%, Training Loss: 1.0909%\n",
      "Epoch [10/300], Step [171/225], Training Accuracy: 49.2325%, Training Loss: 1.0903%\n",
      "Epoch [10/300], Step [172/225], Training Accuracy: 49.2369%, Training Loss: 1.0896%\n",
      "Epoch [10/300], Step [173/225], Training Accuracy: 49.1871%, Training Loss: 1.0902%\n",
      "Epoch [10/300], Step [174/225], Training Accuracy: 49.2188%, Training Loss: 1.0899%\n",
      "Epoch [10/300], Step [175/225], Training Accuracy: 49.2857%, Training Loss: 1.0893%\n",
      "Epoch [10/300], Step [176/225], Training Accuracy: 49.2809%, Training Loss: 1.0893%\n",
      "Epoch [10/300], Step [177/225], Training Accuracy: 49.2938%, Training Loss: 1.0891%\n",
      "Epoch [10/300], Step [178/225], Training Accuracy: 49.3065%, Training Loss: 1.0894%\n",
      "Epoch [10/300], Step [179/225], Training Accuracy: 49.3017%, Training Loss: 1.0894%\n",
      "Epoch [10/300], Step [180/225], Training Accuracy: 49.3056%, Training Loss: 1.0894%\n",
      "Epoch [10/300], Step [181/225], Training Accuracy: 49.3008%, Training Loss: 1.0893%\n",
      "Epoch [10/300], Step [182/225], Training Accuracy: 49.3389%, Training Loss: 1.0888%\n",
      "Epoch [10/300], Step [183/225], Training Accuracy: 49.3340%, Training Loss: 1.0888%\n",
      "Epoch [10/300], Step [184/225], Training Accuracy: 49.2697%, Training Loss: 1.0893%\n",
      "Epoch [10/300], Step [185/225], Training Accuracy: 49.2905%, Training Loss: 1.0897%\n",
      "Epoch [10/300], Step [186/225], Training Accuracy: 49.3364%, Training Loss: 1.0892%\n",
      "Epoch [10/300], Step [187/225], Training Accuracy: 49.3650%, Training Loss: 1.0889%\n",
      "Epoch [10/300], Step [188/225], Training Accuracy: 49.3351%, Training Loss: 1.0890%\n",
      "Epoch [10/300], Step [189/225], Training Accuracy: 49.3634%, Training Loss: 1.0886%\n",
      "Epoch [10/300], Step [190/225], Training Accuracy: 49.3750%, Training Loss: 1.0883%\n",
      "Epoch [10/300], Step [191/225], Training Accuracy: 49.3783%, Training Loss: 1.0886%\n",
      "Epoch [10/300], Step [192/225], Training Accuracy: 49.3571%, Training Loss: 1.0892%\n",
      "Epoch [10/300], Step [193/225], Training Accuracy: 49.3280%, Training Loss: 1.0897%\n",
      "Epoch [10/300], Step [194/225], Training Accuracy: 49.3637%, Training Loss: 1.0892%\n",
      "Epoch [10/300], Step [195/225], Training Accuracy: 49.3429%, Training Loss: 1.0894%\n",
      "Epoch [10/300], Step [196/225], Training Accuracy: 49.3941%, Training Loss: 1.0889%\n",
      "Epoch [10/300], Step [197/225], Training Accuracy: 49.3655%, Training Loss: 1.0893%\n",
      "Epoch [10/300], Step [198/225], Training Accuracy: 49.3845%, Training Loss: 1.0889%\n",
      "Epoch [10/300], Step [199/225], Training Accuracy: 49.3797%, Training Loss: 1.0891%\n",
      "Epoch [10/300], Step [200/225], Training Accuracy: 49.3750%, Training Loss: 1.0891%\n",
      "Epoch [10/300], Step [201/225], Training Accuracy: 49.4248%, Training Loss: 1.0885%\n",
      "Epoch [10/300], Step [202/225], Training Accuracy: 49.4585%, Training Loss: 1.0880%\n",
      "Epoch [10/300], Step [203/225], Training Accuracy: 49.4304%, Training Loss: 1.0885%\n",
      "Epoch [10/300], Step [204/225], Training Accuracy: 49.4485%, Training Loss: 1.0884%\n",
      "Epoch [10/300], Step [205/225], Training Accuracy: 49.4665%, Training Loss: 1.0882%\n",
      "Epoch [10/300], Step [206/225], Training Accuracy: 49.4842%, Training Loss: 1.0885%\n",
      "Epoch [10/300], Step [207/225], Training Accuracy: 49.5396%, Training Loss: 1.0878%\n",
      "Epoch [10/300], Step [208/225], Training Accuracy: 49.5568%, Training Loss: 1.0875%\n",
      "Epoch [10/300], Step [209/225], Training Accuracy: 49.5440%, Training Loss: 1.0875%\n",
      "Epoch [10/300], Step [210/225], Training Accuracy: 49.5461%, Training Loss: 1.0876%\n",
      "Epoch [10/300], Step [211/225], Training Accuracy: 49.5705%, Training Loss: 1.0870%\n",
      "Epoch [10/300], Step [212/225], Training Accuracy: 49.5578%, Training Loss: 1.0876%\n",
      "Epoch [10/300], Step [213/225], Training Accuracy: 49.5672%, Training Loss: 1.0877%\n",
      "Epoch [10/300], Step [214/225], Training Accuracy: 49.5546%, Training Loss: 1.0880%\n",
      "Epoch [10/300], Step [215/225], Training Accuracy: 49.6148%, Training Loss: 1.0874%\n",
      "Epoch [10/300], Step [216/225], Training Accuracy: 49.6094%, Training Loss: 1.0882%\n",
      "Epoch [10/300], Step [217/225], Training Accuracy: 49.6472%, Training Loss: 1.0878%\n",
      "Epoch [10/300], Step [218/225], Training Accuracy: 49.6201%, Training Loss: 1.0883%\n",
      "Epoch [10/300], Step [219/225], Training Accuracy: 49.6219%, Training Loss: 1.0879%\n",
      "Epoch [10/300], Step [220/225], Training Accuracy: 49.6733%, Training Loss: 1.0873%\n",
      "Epoch [10/300], Step [221/225], Training Accuracy: 49.6394%, Training Loss: 1.0879%\n",
      "Epoch [10/300], Step [222/225], Training Accuracy: 49.6762%, Training Loss: 1.0878%\n",
      "Epoch [10/300], Step [223/225], Training Accuracy: 49.6777%, Training Loss: 1.0879%\n",
      "Epoch [10/300], Step [224/225], Training Accuracy: 49.7140%, Training Loss: 1.0874%\n",
      "Epoch [10/300], Step [225/225], Training Accuracy: 49.6873%, Training Loss: 1.0876%\n",
      "Epoch [11/300], Step [1/225], Training Accuracy: 53.1250%, Training Loss: 1.1037%\n",
      "Epoch [11/300], Step [2/225], Training Accuracy: 52.3438%, Training Loss: 1.1104%\n",
      "Epoch [11/300], Step [3/225], Training Accuracy: 48.4375%, Training Loss: 1.1511%\n",
      "Epoch [11/300], Step [4/225], Training Accuracy: 51.5625%, Training Loss: 1.0920%\n",
      "Epoch [11/300], Step [5/225], Training Accuracy: 51.2500%, Training Loss: 1.0795%\n",
      "Epoch [11/300], Step [6/225], Training Accuracy: 50.5208%, Training Loss: 1.0819%\n",
      "Epoch [11/300], Step [7/225], Training Accuracy: 50.0000%, Training Loss: 1.1000%\n",
      "Epoch [11/300], Step [8/225], Training Accuracy: 50.0000%, Training Loss: 1.0893%\n",
      "Epoch [11/300], Step [9/225], Training Accuracy: 50.1736%, Training Loss: 1.0838%\n",
      "Epoch [11/300], Step [10/225], Training Accuracy: 50.3125%, Training Loss: 1.0923%\n",
      "Epoch [11/300], Step [11/225], Training Accuracy: 50.8523%, Training Loss: 1.0832%\n",
      "Epoch [11/300], Step [12/225], Training Accuracy: 50.3906%, Training Loss: 1.0904%\n",
      "Epoch [11/300], Step [13/225], Training Accuracy: 50.3606%, Training Loss: 1.0891%\n",
      "Epoch [11/300], Step [14/225], Training Accuracy: 50.1116%, Training Loss: 1.0933%\n",
      "Epoch [11/300], Step [15/225], Training Accuracy: 49.8958%, Training Loss: 1.0987%\n",
      "Epoch [11/300], Step [16/225], Training Accuracy: 49.8047%, Training Loss: 1.1011%\n",
      "Epoch [11/300], Step [17/225], Training Accuracy: 50.2757%, Training Loss: 1.0996%\n",
      "Epoch [11/300], Step [18/225], Training Accuracy: 50.0868%, Training Loss: 1.0995%\n",
      "Epoch [11/300], Step [19/225], Training Accuracy: 49.9178%, Training Loss: 1.0996%\n",
      "Epoch [11/300], Step [20/225], Training Accuracy: 50.4688%, Training Loss: 1.0956%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/300], Step [21/225], Training Accuracy: 50.8185%, Training Loss: 1.0900%\n",
      "Epoch [11/300], Step [22/225], Training Accuracy: 51.2074%, Training Loss: 1.0877%\n",
      "Epoch [11/300], Step [23/225], Training Accuracy: 51.2228%, Training Loss: 1.0883%\n",
      "Epoch [11/300], Step [24/225], Training Accuracy: 51.1068%, Training Loss: 1.0893%\n",
      "Epoch [11/300], Step [25/225], Training Accuracy: 51.0625%, Training Loss: 1.0861%\n",
      "Epoch [11/300], Step [26/225], Training Accuracy: 50.9014%, Training Loss: 1.0858%\n",
      "Epoch [11/300], Step [27/225], Training Accuracy: 50.8681%, Training Loss: 1.0845%\n",
      "Epoch [11/300], Step [28/225], Training Accuracy: 51.2277%, Training Loss: 1.0796%\n",
      "Epoch [11/300], Step [29/225], Training Accuracy: 51.6703%, Training Loss: 1.0732%\n",
      "Epoch [11/300], Step [30/225], Training Accuracy: 51.8750%, Training Loss: 1.0737%\n",
      "Epoch [11/300], Step [31/225], Training Accuracy: 51.6129%, Training Loss: 1.0758%\n",
      "Epoch [11/300], Step [32/225], Training Accuracy: 51.7578%, Training Loss: 1.0728%\n",
      "Epoch [11/300], Step [33/225], Training Accuracy: 51.9413%, Training Loss: 1.0692%\n",
      "Epoch [11/300], Step [34/225], Training Accuracy: 51.8842%, Training Loss: 1.0693%\n",
      "Epoch [11/300], Step [35/225], Training Accuracy: 51.8750%, Training Loss: 1.0718%\n",
      "Epoch [11/300], Step [36/225], Training Accuracy: 52.0399%, Training Loss: 1.0717%\n",
      "Epoch [11/300], Step [37/225], Training Accuracy: 52.1537%, Training Loss: 1.0708%\n",
      "Epoch [11/300], Step [38/225], Training Accuracy: 52.1382%, Training Loss: 1.0701%\n",
      "Epoch [11/300], Step [39/225], Training Accuracy: 52.2035%, Training Loss: 1.0692%\n",
      "Epoch [11/300], Step [40/225], Training Accuracy: 52.1484%, Training Loss: 1.0690%\n",
      "Epoch [11/300], Step [41/225], Training Accuracy: 52.1341%, Training Loss: 1.0664%\n",
      "Epoch [11/300], Step [42/225], Training Accuracy: 52.2693%, Training Loss: 1.0642%\n",
      "Epoch [11/300], Step [43/225], Training Accuracy: 52.3619%, Training Loss: 1.0644%\n",
      "Epoch [11/300], Step [44/225], Training Accuracy: 52.4503%, Training Loss: 1.0645%\n",
      "Epoch [11/300], Step [45/225], Training Accuracy: 52.5347%, Training Loss: 1.0647%\n",
      "Epoch [11/300], Step [46/225], Training Accuracy: 52.6155%, Training Loss: 1.0630%\n",
      "Epoch [11/300], Step [47/225], Training Accuracy: 52.5598%, Training Loss: 1.0634%\n",
      "Epoch [11/300], Step [48/225], Training Accuracy: 52.3763%, Training Loss: 1.0641%\n",
      "Epoch [11/300], Step [49/225], Training Accuracy: 52.3278%, Training Loss: 1.0643%\n",
      "Epoch [11/300], Step [50/225], Training Accuracy: 52.4688%, Training Loss: 1.0626%\n",
      "Epoch [11/300], Step [51/225], Training Accuracy: 52.3284%, Training Loss: 1.0638%\n",
      "Epoch [11/300], Step [52/225], Training Accuracy: 52.4038%, Training Loss: 1.0639%\n",
      "Epoch [11/300], Step [53/225], Training Accuracy: 52.3290%, Training Loss: 1.0645%\n",
      "Epoch [11/300], Step [54/225], Training Accuracy: 52.3438%, Training Loss: 1.0646%\n",
      "Epoch [11/300], Step [55/225], Training Accuracy: 52.5000%, Training Loss: 1.0646%\n",
      "Epoch [11/300], Step [56/225], Training Accuracy: 52.4554%, Training Loss: 1.0632%\n",
      "Epoch [11/300], Step [57/225], Training Accuracy: 52.4397%, Training Loss: 1.0635%\n",
      "Epoch [11/300], Step [58/225], Training Accuracy: 52.3438%, Training Loss: 1.0643%\n",
      "Epoch [11/300], Step [59/225], Training Accuracy: 52.2775%, Training Loss: 1.0637%\n",
      "Epoch [11/300], Step [60/225], Training Accuracy: 52.3438%, Training Loss: 1.0614%\n",
      "Epoch [11/300], Step [61/225], Training Accuracy: 52.3053%, Training Loss: 1.0624%\n",
      "Epoch [11/300], Step [62/225], Training Accuracy: 52.2429%, Training Loss: 1.0628%\n",
      "Epoch [11/300], Step [63/225], Training Accuracy: 52.0089%, Training Loss: 1.0654%\n",
      "Epoch [11/300], Step [64/225], Training Accuracy: 52.0264%, Training Loss: 1.0656%\n",
      "Epoch [11/300], Step [65/225], Training Accuracy: 52.0433%, Training Loss: 1.0652%\n",
      "Epoch [11/300], Step [66/225], Training Accuracy: 52.0833%, Training Loss: 1.0655%\n",
      "Epoch [11/300], Step [67/225], Training Accuracy: 51.9823%, Training Loss: 1.0660%\n",
      "Epoch [11/300], Step [68/225], Training Accuracy: 51.9531%, Training Loss: 1.0660%\n",
      "Epoch [11/300], Step [69/225], Training Accuracy: 51.9928%, Training Loss: 1.0653%\n",
      "Epoch [11/300], Step [70/225], Training Accuracy: 52.1429%, Training Loss: 1.0635%\n",
      "Epoch [11/300], Step [71/225], Training Accuracy: 52.1127%, Training Loss: 1.0636%\n",
      "Epoch [11/300], Step [72/225], Training Accuracy: 52.0833%, Training Loss: 1.0647%\n",
      "Epoch [11/300], Step [73/225], Training Accuracy: 51.9692%, Training Loss: 1.0668%\n",
      "Epoch [11/300], Step [74/225], Training Accuracy: 52.0270%, Training Loss: 1.0652%\n",
      "Epoch [11/300], Step [75/225], Training Accuracy: 51.9792%, Training Loss: 1.0646%\n",
      "Epoch [11/300], Step [76/225], Training Accuracy: 51.9120%, Training Loss: 1.0653%\n",
      "Epoch [11/300], Step [77/225], Training Accuracy: 51.9075%, Training Loss: 1.0649%\n",
      "Epoch [11/300], Step [78/225], Training Accuracy: 51.9030%, Training Loss: 1.0641%\n",
      "Epoch [11/300], Step [79/225], Training Accuracy: 51.8592%, Training Loss: 1.0646%\n",
      "Epoch [11/300], Step [80/225], Training Accuracy: 51.8164%, Training Loss: 1.0659%\n",
      "Epoch [11/300], Step [81/225], Training Accuracy: 51.8133%, Training Loss: 1.0659%\n",
      "Epoch [11/300], Step [82/225], Training Accuracy: 51.8293%, Training Loss: 1.0658%\n",
      "Epoch [11/300], Step [83/225], Training Accuracy: 51.8637%, Training Loss: 1.0653%\n",
      "Epoch [11/300], Step [84/225], Training Accuracy: 51.7671%, Training Loss: 1.0656%\n",
      "Epoch [11/300], Step [85/225], Training Accuracy: 51.6912%, Training Loss: 1.0667%\n",
      "Epoch [11/300], Step [86/225], Training Accuracy: 51.7805%, Training Loss: 1.0655%\n",
      "Epoch [11/300], Step [87/225], Training Accuracy: 51.7601%, Training Loss: 1.0653%\n",
      "Epoch [11/300], Step [88/225], Training Accuracy: 51.6335%, Training Loss: 1.0659%\n",
      "Epoch [11/300], Step [89/225], Training Accuracy: 51.6678%, Training Loss: 1.0646%\n",
      "Epoch [11/300], Step [90/225], Training Accuracy: 51.6493%, Training Loss: 1.0642%\n",
      "Epoch [11/300], Step [91/225], Training Accuracy: 51.6827%, Training Loss: 1.0633%\n",
      "Epoch [11/300], Step [92/225], Training Accuracy: 51.5795%, Training Loss: 1.0644%\n",
      "Epoch [11/300], Step [93/225], Training Accuracy: 51.5121%, Training Loss: 1.0649%\n",
      "Epoch [11/300], Step [94/225], Training Accuracy: 51.5126%, Training Loss: 1.0643%\n",
      "Epoch [11/300], Step [95/225], Training Accuracy: 51.4309%, Training Loss: 1.0648%\n",
      "Epoch [11/300], Step [96/225], Training Accuracy: 51.4811%, Training Loss: 1.0642%\n",
      "Epoch [11/300], Step [97/225], Training Accuracy: 51.4820%, Training Loss: 1.0640%\n",
      "Epoch [11/300], Step [98/225], Training Accuracy: 51.5466%, Training Loss: 1.0630%\n",
      "Epoch [11/300], Step [99/225], Training Accuracy: 51.4836%, Training Loss: 1.0631%\n",
      "Epoch [11/300], Step [100/225], Training Accuracy: 51.4062%, Training Loss: 1.0642%\n",
      "Epoch [11/300], Step [101/225], Training Accuracy: 51.3459%, Training Loss: 1.0640%\n",
      "Epoch [11/300], Step [102/225], Training Accuracy: 51.4400%, Training Loss: 1.0636%\n",
      "Epoch [11/300], Step [103/225], Training Accuracy: 51.4411%, Training Loss: 1.0644%\n",
      "Epoch [11/300], Step [104/225], Training Accuracy: 51.3672%, Training Loss: 1.0645%\n",
      "Epoch [11/300], Step [105/225], Training Accuracy: 51.3393%, Training Loss: 1.0647%\n",
      "Epoch [11/300], Step [106/225], Training Accuracy: 51.3856%, Training Loss: 1.0639%\n",
      "Epoch [11/300], Step [107/225], Training Accuracy: 51.3581%, Training Loss: 1.0635%\n",
      "Epoch [11/300], Step [108/225], Training Accuracy: 51.3166%, Training Loss: 1.0644%\n",
      "Epoch [11/300], Step [109/225], Training Accuracy: 51.3045%, Training Loss: 1.0647%\n",
      "Epoch [11/300], Step [110/225], Training Accuracy: 51.3636%, Training Loss: 1.0641%\n",
      "Epoch [11/300], Step [111/225], Training Accuracy: 51.3514%, Training Loss: 1.0644%\n",
      "Epoch [11/300], Step [112/225], Training Accuracy: 51.3811%, Training Loss: 1.0637%\n",
      "Epoch [11/300], Step [113/225], Training Accuracy: 51.3689%, Training Loss: 1.0641%\n",
      "Epoch [11/300], Step [114/225], Training Accuracy: 51.3295%, Training Loss: 1.0642%\n",
      "Epoch [11/300], Step [115/225], Training Accuracy: 51.3451%, Training Loss: 1.0655%\n",
      "Epoch [11/300], Step [116/225], Training Accuracy: 51.3874%, Training Loss: 1.0655%\n",
      "Epoch [11/300], Step [117/225], Training Accuracy: 51.4423%, Training Loss: 1.0655%\n",
      "Epoch [11/300], Step [118/225], Training Accuracy: 51.4036%, Training Loss: 1.0669%\n",
      "Epoch [11/300], Step [119/225], Training Accuracy: 51.3787%, Training Loss: 1.0672%\n",
      "Epoch [11/300], Step [120/225], Training Accuracy: 51.4453%, Training Loss: 1.0664%\n",
      "Epoch [11/300], Step [121/225], Training Accuracy: 51.3817%, Training Loss: 1.0669%\n",
      "Epoch [11/300], Step [122/225], Training Accuracy: 51.3192%, Training Loss: 1.0678%\n",
      "Epoch [11/300], Step [123/225], Training Accuracy: 51.3338%, Training Loss: 1.0678%\n",
      "Epoch [11/300], Step [124/225], Training Accuracy: 51.3987%, Training Loss: 1.0676%\n",
      "Epoch [11/300], Step [125/225], Training Accuracy: 51.4500%, Training Loss: 1.0672%\n",
      "Epoch [11/300], Step [126/225], Training Accuracy: 51.4261%, Training Loss: 1.0670%\n",
      "Epoch [11/300], Step [127/225], Training Accuracy: 51.3533%, Training Loss: 1.0674%\n",
      "Epoch [11/300], Step [128/225], Training Accuracy: 51.3062%, Training Loss: 1.0678%\n",
      "Epoch [11/300], Step [129/225], Training Accuracy: 51.3445%, Training Loss: 1.0676%\n",
      "Epoch [11/300], Step [130/225], Training Accuracy: 51.3582%, Training Loss: 1.0676%\n",
      "Epoch [11/300], Step [131/225], Training Accuracy: 51.3836%, Training Loss: 1.0679%\n",
      "Epoch [11/300], Step [132/225], Training Accuracy: 51.3494%, Training Loss: 1.0683%\n",
      "Epoch [11/300], Step [133/225], Training Accuracy: 51.4215%, Training Loss: 1.0672%\n",
      "Epoch [11/300], Step [134/225], Training Accuracy: 51.3526%, Training Loss: 1.0676%\n",
      "Epoch [11/300], Step [135/225], Training Accuracy: 51.3889%, Training Loss: 1.0668%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/300], Step [136/225], Training Accuracy: 51.3902%, Training Loss: 1.0672%\n",
      "Epoch [11/300], Step [137/225], Training Accuracy: 51.3800%, Training Loss: 1.0670%\n",
      "Epoch [11/300], Step [138/225], Training Accuracy: 51.3927%, Training Loss: 1.0668%\n",
      "Epoch [11/300], Step [139/225], Training Accuracy: 51.3714%, Training Loss: 1.0675%\n",
      "Epoch [11/300], Step [140/225], Training Accuracy: 51.4397%, Training Loss: 1.0666%\n",
      "Epoch [11/300], Step [141/225], Training Accuracy: 51.3852%, Training Loss: 1.0670%\n",
      "Epoch [11/300], Step [142/225], Training Accuracy: 51.4195%, Training Loss: 1.0666%\n",
      "Epoch [11/300], Step [143/225], Training Accuracy: 51.4205%, Training Loss: 1.0667%\n",
      "Epoch [11/300], Step [144/225], Training Accuracy: 51.4540%, Training Loss: 1.0663%\n",
      "Epoch [11/300], Step [145/225], Training Accuracy: 51.4978%, Training Loss: 1.0662%\n",
      "Epoch [11/300], Step [146/225], Training Accuracy: 51.5304%, Training Loss: 1.0657%\n",
      "Epoch [11/300], Step [147/225], Training Accuracy: 51.4881%, Training Loss: 1.0666%\n",
      "Epoch [11/300], Step [148/225], Training Accuracy: 51.5097%, Training Loss: 1.0661%\n",
      "Epoch [11/300], Step [149/225], Training Accuracy: 51.5206%, Training Loss: 1.0665%\n",
      "Epoch [11/300], Step [150/225], Training Accuracy: 51.5729%, Training Loss: 1.0654%\n",
      "Epoch [11/300], Step [151/225], Training Accuracy: 51.6660%, Training Loss: 1.0641%\n",
      "Epoch [11/300], Step [152/225], Training Accuracy: 51.6756%, Training Loss: 1.0638%\n",
      "Epoch [11/300], Step [153/225], Training Accuracy: 51.7157%, Training Loss: 1.0633%\n",
      "Epoch [11/300], Step [154/225], Training Accuracy: 51.7248%, Training Loss: 1.0628%\n",
      "Epoch [11/300], Step [155/225], Training Accuracy: 51.6935%, Training Loss: 1.0626%\n",
      "Epoch [11/300], Step [156/225], Training Accuracy: 51.6727%, Training Loss: 1.0629%\n",
      "Epoch [11/300], Step [157/225], Training Accuracy: 51.7715%, Training Loss: 1.0620%\n",
      "Epoch [11/300], Step [158/225], Training Accuracy: 51.7801%, Training Loss: 1.0616%\n",
      "Epoch [11/300], Step [159/225], Training Accuracy: 51.8180%, Training Loss: 1.0616%\n",
      "Epoch [11/300], Step [160/225], Training Accuracy: 51.7969%, Training Loss: 1.0615%\n",
      "Epoch [11/300], Step [161/225], Training Accuracy: 51.8148%, Training Loss: 1.0611%\n",
      "Epoch [11/300], Step [162/225], Training Accuracy: 51.8133%, Training Loss: 1.0613%\n",
      "Epoch [11/300], Step [163/225], Training Accuracy: 51.8597%, Training Loss: 1.0603%\n",
      "Epoch [11/300], Step [164/225], Training Accuracy: 51.9245%, Training Loss: 1.0596%\n",
      "Epoch [11/300], Step [165/225], Training Accuracy: 51.9413%, Training Loss: 1.0595%\n",
      "Epoch [11/300], Step [166/225], Training Accuracy: 51.9767%, Training Loss: 1.0589%\n",
      "Epoch [11/300], Step [167/225], Training Accuracy: 51.9742%, Training Loss: 1.0591%\n",
      "Epoch [11/300], Step [168/225], Training Accuracy: 51.9438%, Training Loss: 1.0590%\n",
      "Epoch [11/300], Step [169/225], Training Accuracy: 51.9231%, Training Loss: 1.0591%\n",
      "Epoch [11/300], Step [170/225], Training Accuracy: 51.9577%, Training Loss: 1.0588%\n",
      "Epoch [11/300], Step [171/225], Training Accuracy: 51.9920%, Training Loss: 1.0585%\n",
      "Epoch [11/300], Step [172/225], Training Accuracy: 52.0076%, Training Loss: 1.0579%\n",
      "Epoch [11/300], Step [173/225], Training Accuracy: 51.9599%, Training Loss: 1.0587%\n",
      "Epoch [11/300], Step [174/225], Training Accuracy: 51.9576%, Training Loss: 1.0590%\n",
      "Epoch [11/300], Step [175/225], Training Accuracy: 52.0089%, Training Loss: 1.0585%\n",
      "Epoch [11/300], Step [176/225], Training Accuracy: 51.9798%, Training Loss: 1.0588%\n",
      "Epoch [11/300], Step [177/225], Training Accuracy: 51.9597%, Training Loss: 1.0584%\n",
      "Epoch [11/300], Step [178/225], Training Accuracy: 51.9224%, Training Loss: 1.0591%\n",
      "Epoch [11/300], Step [179/225], Training Accuracy: 51.8942%, Training Loss: 1.0596%\n",
      "Epoch [11/300], Step [180/225], Training Accuracy: 51.8837%, Training Loss: 1.0597%\n",
      "Epoch [11/300], Step [181/225], Training Accuracy: 51.8992%, Training Loss: 1.0600%\n",
      "Epoch [11/300], Step [182/225], Training Accuracy: 51.9059%, Training Loss: 1.0596%\n",
      "Epoch [11/300], Step [183/225], Training Accuracy: 51.9382%, Training Loss: 1.0592%\n",
      "Epoch [11/300], Step [184/225], Training Accuracy: 51.8937%, Training Loss: 1.0597%\n",
      "Epoch [11/300], Step [185/225], Training Accuracy: 51.8666%, Training Loss: 1.0600%\n",
      "Epoch [11/300], Step [186/225], Training Accuracy: 51.8985%, Training Loss: 1.0595%\n",
      "Epoch [11/300], Step [187/225], Training Accuracy: 51.9385%, Training Loss: 1.0591%\n",
      "Epoch [11/300], Step [188/225], Training Accuracy: 51.8783%, Training Loss: 1.0591%\n",
      "Epoch [11/300], Step [189/225], Training Accuracy: 51.9015%, Training Loss: 1.0587%\n",
      "Epoch [11/300], Step [190/225], Training Accuracy: 51.9326%, Training Loss: 1.0584%\n",
      "Epoch [11/300], Step [191/225], Training Accuracy: 51.9388%, Training Loss: 1.0584%\n",
      "Epoch [11/300], Step [192/225], Training Accuracy: 51.9287%, Training Loss: 1.0588%\n",
      "Epoch [11/300], Step [193/225], Training Accuracy: 51.8620%, Training Loss: 1.0594%\n",
      "Epoch [11/300], Step [194/225], Training Accuracy: 51.9008%, Training Loss: 1.0589%\n",
      "Epoch [11/300], Step [195/225], Training Accuracy: 51.8590%, Training Loss: 1.0589%\n",
      "Epoch [11/300], Step [196/225], Training Accuracy: 51.8734%, Training Loss: 1.0585%\n",
      "Epoch [11/300], Step [197/225], Training Accuracy: 51.8560%, Training Loss: 1.0588%\n",
      "Epoch [11/300], Step [198/225], Training Accuracy: 51.8782%, Training Loss: 1.0587%\n",
      "Epoch [11/300], Step [199/225], Training Accuracy: 51.8923%, Training Loss: 1.0585%\n",
      "Epoch [11/300], Step [200/225], Training Accuracy: 51.9141%, Training Loss: 1.0587%\n",
      "Epoch [11/300], Step [201/225], Training Accuracy: 51.9512%, Training Loss: 1.0582%\n",
      "Epoch [11/300], Step [202/225], Training Accuracy: 51.9879%, Training Loss: 1.0577%\n",
      "Epoch [11/300], Step [203/225], Training Accuracy: 51.9474%, Training Loss: 1.0581%\n",
      "Epoch [11/300], Step [204/225], Training Accuracy: 51.9608%, Training Loss: 1.0577%\n",
      "Epoch [11/300], Step [205/225], Training Accuracy: 51.9665%, Training Loss: 1.0577%\n",
      "Epoch [11/300], Step [206/225], Training Accuracy: 51.9873%, Training Loss: 1.0578%\n",
      "Epoch [11/300], Step [207/225], Training Accuracy: 52.0003%, Training Loss: 1.0570%\n",
      "Epoch [11/300], Step [208/225], Training Accuracy: 52.0358%, Training Loss: 1.0566%\n",
      "Epoch [11/300], Step [209/225], Training Accuracy: 52.0260%, Training Loss: 1.0563%\n",
      "Epoch [11/300], Step [210/225], Training Accuracy: 52.0164%, Training Loss: 1.0567%\n",
      "Epoch [11/300], Step [211/225], Training Accuracy: 52.1031%, Training Loss: 1.0560%\n",
      "Epoch [11/300], Step [212/225], Training Accuracy: 52.0858%, Training Loss: 1.0561%\n",
      "Epoch [11/300], Step [213/225], Training Accuracy: 52.1053%, Training Loss: 1.0560%\n",
      "Epoch [11/300], Step [214/225], Training Accuracy: 52.0663%, Training Loss: 1.0566%\n",
      "Epoch [11/300], Step [215/225], Training Accuracy: 52.1148%, Training Loss: 1.0560%\n",
      "Epoch [11/300], Step [216/225], Training Accuracy: 52.0833%, Training Loss: 1.0566%\n",
      "Epoch [11/300], Step [217/225], Training Accuracy: 52.1313%, Training Loss: 1.0559%\n",
      "Epoch [11/300], Step [218/225], Training Accuracy: 52.0929%, Training Loss: 1.0564%\n",
      "Epoch [11/300], Step [219/225], Training Accuracy: 52.1333%, Training Loss: 1.0559%\n",
      "Epoch [11/300], Step [220/225], Training Accuracy: 52.1662%, Training Loss: 1.0553%\n",
      "Epoch [11/300], Step [221/225], Training Accuracy: 52.1352%, Training Loss: 1.0558%\n",
      "Epoch [11/300], Step [222/225], Training Accuracy: 52.1044%, Training Loss: 1.0563%\n",
      "Epoch [11/300], Step [223/225], Training Accuracy: 52.1160%, Training Loss: 1.0565%\n",
      "Epoch [11/300], Step [224/225], Training Accuracy: 52.1415%, Training Loss: 1.0560%\n",
      "Epoch [11/300], Step [225/225], Training Accuracy: 52.1470%, Training Loss: 1.0558%\n",
      "Epoch [12/300], Step [1/225], Training Accuracy: 53.1250%, Training Loss: 1.0581%\n",
      "Epoch [12/300], Step [2/225], Training Accuracy: 52.3438%, Training Loss: 1.0222%\n",
      "Epoch [12/300], Step [3/225], Training Accuracy: 51.0417%, Training Loss: 1.0861%\n",
      "Epoch [12/300], Step [4/225], Training Accuracy: 53.9062%, Training Loss: 1.0315%\n",
      "Epoch [12/300], Step [5/225], Training Accuracy: 54.6875%, Training Loss: 1.0202%\n",
      "Epoch [12/300], Step [6/225], Training Accuracy: 53.9062%, Training Loss: 1.0362%\n",
      "Epoch [12/300], Step [7/225], Training Accuracy: 52.2321%, Training Loss: 1.0541%\n",
      "Epoch [12/300], Step [8/225], Training Accuracy: 52.3438%, Training Loss: 1.0464%\n",
      "Epoch [12/300], Step [9/225], Training Accuracy: 51.9097%, Training Loss: 1.0500%\n",
      "Epoch [12/300], Step [10/225], Training Accuracy: 52.3438%, Training Loss: 1.0521%\n",
      "Epoch [12/300], Step [11/225], Training Accuracy: 53.1250%, Training Loss: 1.0416%\n",
      "Epoch [12/300], Step [12/225], Training Accuracy: 52.7344%, Training Loss: 1.0503%\n",
      "Epoch [12/300], Step [13/225], Training Accuracy: 53.1250%, Training Loss: 1.0512%\n",
      "Epoch [12/300], Step [14/225], Training Accuracy: 53.0134%, Training Loss: 1.0542%\n",
      "Epoch [12/300], Step [15/225], Training Accuracy: 52.6042%, Training Loss: 1.0597%\n",
      "Epoch [12/300], Step [16/225], Training Accuracy: 52.2461%, Training Loss: 1.0602%\n",
      "Epoch [12/300], Step [17/225], Training Accuracy: 52.1140%, Training Loss: 1.0586%\n",
      "Epoch [12/300], Step [18/225], Training Accuracy: 52.0833%, Training Loss: 1.0582%\n",
      "Epoch [12/300], Step [19/225], Training Accuracy: 52.2204%, Training Loss: 1.0563%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/300], Step [20/225], Training Accuracy: 52.4219%, Training Loss: 1.0546%\n",
      "Epoch [12/300], Step [21/225], Training Accuracy: 52.9018%, Training Loss: 1.0475%\n",
      "Epoch [12/300], Step [22/225], Training Accuracy: 53.0540%, Training Loss: 1.0478%\n",
      "Epoch [12/300], Step [23/225], Training Accuracy: 53.1929%, Training Loss: 1.0495%\n",
      "Epoch [12/300], Step [24/225], Training Accuracy: 53.1250%, Training Loss: 1.0499%\n",
      "Epoch [12/300], Step [25/225], Training Accuracy: 53.3125%, Training Loss: 1.0457%\n",
      "Epoch [12/300], Step [26/225], Training Accuracy: 53.0048%, Training Loss: 1.0483%\n",
      "Epoch [12/300], Step [27/225], Training Accuracy: 53.1250%, Training Loss: 1.0491%\n",
      "Epoch [12/300], Step [28/225], Training Accuracy: 53.4040%, Training Loss: 1.0439%\n",
      "Epoch [12/300], Step [29/225], Training Accuracy: 53.5560%, Training Loss: 1.0391%\n",
      "Epoch [12/300], Step [30/225], Training Accuracy: 53.5938%, Training Loss: 1.0379%\n",
      "Epoch [12/300], Step [31/225], Training Accuracy: 53.1754%, Training Loss: 1.0402%\n",
      "Epoch [12/300], Step [32/225], Training Accuracy: 53.5156%, Training Loss: 1.0370%\n",
      "Epoch [12/300], Step [33/225], Training Accuracy: 53.5038%, Training Loss: 1.0336%\n",
      "Epoch [12/300], Step [34/225], Training Accuracy: 53.4926%, Training Loss: 1.0341%\n",
      "Epoch [12/300], Step [35/225], Training Accuracy: 53.5268%, Training Loss: 1.0367%\n",
      "Epoch [12/300], Step [36/225], Training Accuracy: 53.5590%, Training Loss: 1.0380%\n",
      "Epoch [12/300], Step [37/225], Training Accuracy: 53.5895%, Training Loss: 1.0371%\n",
      "Epoch [12/300], Step [38/225], Training Accuracy: 53.7007%, Training Loss: 1.0362%\n",
      "Epoch [12/300], Step [39/225], Training Accuracy: 53.7260%, Training Loss: 1.0349%\n",
      "Epoch [12/300], Step [40/225], Training Accuracy: 53.7109%, Training Loss: 1.0364%\n",
      "Epoch [12/300], Step [41/225], Training Accuracy: 53.6966%, Training Loss: 1.0344%\n",
      "Epoch [12/300], Step [42/225], Training Accuracy: 53.9435%, Training Loss: 1.0323%\n",
      "Epoch [12/300], Step [43/225], Training Accuracy: 53.8881%, Training Loss: 1.0328%\n",
      "Epoch [12/300], Step [44/225], Training Accuracy: 53.9773%, Training Loss: 1.0325%\n",
      "Epoch [12/300], Step [45/225], Training Accuracy: 54.1319%, Training Loss: 1.0322%\n",
      "Epoch [12/300], Step [46/225], Training Accuracy: 54.1101%, Training Loss: 1.0312%\n",
      "Epoch [12/300], Step [47/225], Training Accuracy: 54.0226%, Training Loss: 1.0311%\n",
      "Epoch [12/300], Step [48/225], Training Accuracy: 53.8411%, Training Loss: 1.0331%\n",
      "Epoch [12/300], Step [49/225], Training Accuracy: 53.6990%, Training Loss: 1.0340%\n",
      "Epoch [12/300], Step [50/225], Training Accuracy: 53.6562%, Training Loss: 1.0331%\n",
      "Epoch [12/300], Step [51/225], Training Accuracy: 53.6765%, Training Loss: 1.0329%\n",
      "Epoch [12/300], Step [52/225], Training Accuracy: 53.6659%, Training Loss: 1.0324%\n",
      "Epoch [12/300], Step [53/225], Training Accuracy: 53.5672%, Training Loss: 1.0331%\n",
      "Epoch [12/300], Step [54/225], Training Accuracy: 53.5880%, Training Loss: 1.0333%\n",
      "Epoch [12/300], Step [55/225], Training Accuracy: 53.6932%, Training Loss: 1.0326%\n",
      "Epoch [12/300], Step [56/225], Training Accuracy: 53.7388%, Training Loss: 1.0313%\n",
      "Epoch [12/300], Step [57/225], Training Accuracy: 53.7829%, Training Loss: 1.0297%\n",
      "Epoch [12/300], Step [58/225], Training Accuracy: 53.5830%, Training Loss: 1.0314%\n",
      "Epoch [12/300], Step [59/225], Training Accuracy: 53.6547%, Training Loss: 1.0297%\n",
      "Epoch [12/300], Step [60/225], Training Accuracy: 53.6979%, Training Loss: 1.0286%\n",
      "Epoch [12/300], Step [61/225], Training Accuracy: 53.6885%, Training Loss: 1.0289%\n",
      "Epoch [12/300], Step [62/225], Training Accuracy: 53.5534%, Training Loss: 1.0302%\n",
      "Epoch [12/300], Step [63/225], Training Accuracy: 53.4226%, Training Loss: 1.0329%\n",
      "Epoch [12/300], Step [64/225], Training Accuracy: 53.4180%, Training Loss: 1.0338%\n",
      "Epoch [12/300], Step [65/225], Training Accuracy: 53.4135%, Training Loss: 1.0334%\n",
      "Epoch [12/300], Step [66/225], Training Accuracy: 53.5038%, Training Loss: 1.0332%\n",
      "Epoch [12/300], Step [67/225], Training Accuracy: 53.5215%, Training Loss: 1.0336%\n",
      "Epoch [12/300], Step [68/225], Training Accuracy: 53.4926%, Training Loss: 1.0331%\n",
      "Epoch [12/300], Step [69/225], Training Accuracy: 53.5779%, Training Loss: 1.0326%\n",
      "Epoch [12/300], Step [70/225], Training Accuracy: 53.7277%, Training Loss: 1.0312%\n",
      "Epoch [12/300], Step [71/225], Training Accuracy: 53.7632%, Training Loss: 1.0304%\n",
      "Epoch [12/300], Step [72/225], Training Accuracy: 53.6675%, Training Loss: 1.0313%\n",
      "Epoch [12/300], Step [73/225], Training Accuracy: 53.5959%, Training Loss: 1.0333%\n",
      "Epoch [12/300], Step [74/225], Training Accuracy: 53.7584%, Training Loss: 1.0317%\n",
      "Epoch [12/300], Step [75/225], Training Accuracy: 53.7500%, Training Loss: 1.0312%\n",
      "Epoch [12/300], Step [76/225], Training Accuracy: 53.6595%, Training Loss: 1.0321%\n",
      "Epoch [12/300], Step [77/225], Training Accuracy: 53.6323%, Training Loss: 1.0315%\n",
      "Epoch [12/300], Step [78/225], Training Accuracy: 53.6058%, Training Loss: 1.0309%\n",
      "Epoch [12/300], Step [79/225], Training Accuracy: 53.5997%, Training Loss: 1.0317%\n",
      "Epoch [12/300], Step [80/225], Training Accuracy: 53.5156%, Training Loss: 1.0333%\n",
      "Epoch [12/300], Step [81/225], Training Accuracy: 53.4915%, Training Loss: 1.0335%\n",
      "Epoch [12/300], Step [82/225], Training Accuracy: 53.5252%, Training Loss: 1.0342%\n",
      "Epoch [12/300], Step [83/225], Training Accuracy: 53.6521%, Training Loss: 1.0333%\n",
      "Epoch [12/300], Step [84/225], Training Accuracy: 53.6086%, Training Loss: 1.0341%\n",
      "Epoch [12/300], Step [85/225], Training Accuracy: 53.5846%, Training Loss: 1.0346%\n",
      "Epoch [12/300], Step [86/225], Training Accuracy: 53.6337%, Training Loss: 1.0340%\n",
      "Epoch [12/300], Step [87/225], Training Accuracy: 53.6099%, Training Loss: 1.0336%\n",
      "Epoch [12/300], Step [88/225], Training Accuracy: 53.4979%, Training Loss: 1.0344%\n",
      "Epoch [12/300], Step [89/225], Training Accuracy: 53.5639%, Training Loss: 1.0337%\n",
      "Epoch [12/300], Step [90/225], Training Accuracy: 53.5938%, Training Loss: 1.0335%\n",
      "Epoch [12/300], Step [91/225], Training Accuracy: 53.6401%, Training Loss: 1.0331%\n",
      "Epoch [12/300], Step [92/225], Training Accuracy: 53.4986%, Training Loss: 1.0345%\n",
      "Epoch [12/300], Step [93/225], Training Accuracy: 53.4106%, Training Loss: 1.0349%\n",
      "Epoch [12/300], Step [94/225], Training Accuracy: 53.4076%, Training Loss: 1.0344%\n",
      "Epoch [12/300], Step [95/225], Training Accuracy: 53.3224%, Training Loss: 1.0348%\n",
      "Epoch [12/300], Step [96/225], Training Accuracy: 53.4017%, Training Loss: 1.0337%\n",
      "Epoch [12/300], Step [97/225], Training Accuracy: 53.3505%, Training Loss: 1.0339%\n",
      "Epoch [12/300], Step [98/225], Training Accuracy: 53.4439%, Training Loss: 1.0328%\n",
      "Epoch [12/300], Step [99/225], Training Accuracy: 53.4249%, Training Loss: 1.0325%\n",
      "Epoch [12/300], Step [100/225], Training Accuracy: 53.3750%, Training Loss: 1.0333%\n",
      "Epoch [12/300], Step [101/225], Training Accuracy: 53.3571%, Training Loss: 1.0335%\n",
      "Epoch [12/300], Step [102/225], Training Accuracy: 53.3548%, Training Loss: 1.0333%\n",
      "Epoch [12/300], Step [103/225], Training Accuracy: 53.3222%, Training Loss: 1.0336%\n",
      "Epoch [12/300], Step [104/225], Training Accuracy: 53.2302%, Training Loss: 1.0337%\n",
      "Epoch [12/300], Step [105/225], Training Accuracy: 53.2738%, Training Loss: 1.0342%\n",
      "Epoch [12/300], Step [106/225], Training Accuracy: 53.3019%, Training Loss: 1.0339%\n",
      "Epoch [12/300], Step [107/225], Training Accuracy: 53.3148%, Training Loss: 1.0337%\n",
      "Epoch [12/300], Step [108/225], Training Accuracy: 53.2841%, Training Loss: 1.0335%\n",
      "Epoch [12/300], Step [109/225], Training Accuracy: 53.2970%, Training Loss: 1.0340%\n",
      "Epoch [12/300], Step [110/225], Training Accuracy: 53.3523%, Training Loss: 1.0332%\n",
      "Epoch [12/300], Step [111/225], Training Accuracy: 53.3925%, Training Loss: 1.0331%\n",
      "Epoch [12/300], Step [112/225], Training Accuracy: 53.4598%, Training Loss: 1.0325%\n",
      "Epoch [12/300], Step [113/225], Training Accuracy: 53.4015%, Training Loss: 1.0337%\n",
      "Epoch [12/300], Step [114/225], Training Accuracy: 53.3169%, Training Loss: 1.0343%\n",
      "Epoch [12/300], Step [115/225], Training Accuracy: 53.3152%, Training Loss: 1.0350%\n",
      "Epoch [12/300], Step [116/225], Training Accuracy: 53.3944%, Training Loss: 1.0345%\n",
      "Epoch [12/300], Step [117/225], Training Accuracy: 53.3253%, Training Loss: 1.0348%\n",
      "Epoch [12/300], Step [118/225], Training Accuracy: 53.2707%, Training Loss: 1.0358%\n",
      "Epoch [12/300], Step [119/225], Training Accuracy: 53.2957%, Training Loss: 1.0359%\n",
      "Epoch [12/300], Step [120/225], Training Accuracy: 53.3464%, Training Loss: 1.0354%\n",
      "Epoch [12/300], Step [121/225], Training Accuracy: 53.2541%, Training Loss: 1.0361%\n",
      "Epoch [12/300], Step [122/225], Training Accuracy: 53.2403%, Training Loss: 1.0365%\n",
      "Epoch [12/300], Step [123/225], Training Accuracy: 53.2266%, Training Loss: 1.0368%\n",
      "Epoch [12/300], Step [124/225], Training Accuracy: 53.3014%, Training Loss: 1.0362%\n",
      "Epoch [12/300], Step [125/225], Training Accuracy: 53.2625%, Training Loss: 1.0361%\n",
      "Epoch [12/300], Step [126/225], Training Accuracy: 53.2738%, Training Loss: 1.0363%\n",
      "Epoch [12/300], Step [127/225], Training Accuracy: 53.2972%, Training Loss: 1.0364%\n",
      "Epoch [12/300], Step [128/225], Training Accuracy: 53.2715%, Training Loss: 1.0366%\n",
      "Epoch [12/300], Step [129/225], Training Accuracy: 53.3430%, Training Loss: 1.0357%\n",
      "Epoch [12/300], Step [130/225], Training Accuracy: 53.3894%, Training Loss: 1.0356%\n",
      "Epoch [12/300], Step [131/225], Training Accuracy: 53.3874%, Training Loss: 1.0354%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/300], Step [132/225], Training Accuracy: 53.4091%, Training Loss: 1.0352%\n",
      "Epoch [12/300], Step [133/225], Training Accuracy: 53.4539%, Training Loss: 1.0342%\n",
      "Epoch [12/300], Step [134/225], Training Accuracy: 53.4049%, Training Loss: 1.0347%\n",
      "Epoch [12/300], Step [135/225], Training Accuracy: 53.4028%, Training Loss: 1.0343%\n",
      "Epoch [12/300], Step [136/225], Training Accuracy: 53.4237%, Training Loss: 1.0344%\n",
      "Epoch [12/300], Step [137/225], Training Accuracy: 53.3987%, Training Loss: 1.0344%\n",
      "Epoch [12/300], Step [138/225], Training Accuracy: 53.4647%, Training Loss: 1.0338%\n",
      "Epoch [12/300], Step [139/225], Training Accuracy: 53.4397%, Training Loss: 1.0344%\n",
      "Epoch [12/300], Step [140/225], Training Accuracy: 53.4598%, Training Loss: 1.0335%\n",
      "Epoch [12/300], Step [141/225], Training Accuracy: 53.3910%, Training Loss: 1.0345%\n",
      "Epoch [12/300], Step [142/225], Training Accuracy: 53.4001%, Training Loss: 1.0344%\n",
      "Epoch [12/300], Step [143/225], Training Accuracy: 53.3654%, Training Loss: 1.0349%\n",
      "Epoch [12/300], Step [144/225], Training Accuracy: 53.3854%, Training Loss: 1.0348%\n",
      "Epoch [12/300], Step [145/225], Training Accuracy: 53.3944%, Training Loss: 1.0349%\n",
      "Epoch [12/300], Step [146/225], Training Accuracy: 53.3711%, Training Loss: 1.0348%\n",
      "Epoch [12/300], Step [147/225], Training Accuracy: 53.3695%, Training Loss: 1.0349%\n",
      "Epoch [12/300], Step [148/225], Training Accuracy: 53.4206%, Training Loss: 1.0339%\n",
      "Epoch [12/300], Step [149/225], Training Accuracy: 53.4711%, Training Loss: 1.0337%\n",
      "Epoch [12/300], Step [150/225], Training Accuracy: 53.5312%, Training Loss: 1.0326%\n",
      "Epoch [12/300], Step [151/225], Training Accuracy: 53.6113%, Training Loss: 1.0314%\n",
      "Epoch [12/300], Step [152/225], Training Accuracy: 53.6081%, Training Loss: 1.0316%\n",
      "Epoch [12/300], Step [153/225], Training Accuracy: 53.6663%, Training Loss: 1.0308%\n",
      "Epoch [12/300], Step [154/225], Training Accuracy: 53.6627%, Training Loss: 1.0305%\n",
      "Epoch [12/300], Step [155/225], Training Accuracy: 53.6492%, Training Loss: 1.0301%\n",
      "Epoch [12/300], Step [156/225], Training Accuracy: 53.6959%, Training Loss: 1.0304%\n",
      "Epoch [12/300], Step [157/225], Training Accuracy: 53.7619%, Training Loss: 1.0293%\n",
      "Epoch [12/300], Step [158/225], Training Accuracy: 53.7975%, Training Loss: 1.0288%\n",
      "Epoch [12/300], Step [159/225], Training Accuracy: 53.8227%, Training Loss: 1.0284%\n",
      "Epoch [12/300], Step [160/225], Training Accuracy: 53.7891%, Training Loss: 1.0286%\n",
      "Epoch [12/300], Step [161/225], Training Accuracy: 53.7752%, Training Loss: 1.0285%\n",
      "Epoch [12/300], Step [162/225], Training Accuracy: 53.8098%, Training Loss: 1.0281%\n",
      "Epoch [12/300], Step [163/225], Training Accuracy: 53.8919%, Training Loss: 1.0270%\n",
      "Epoch [12/300], Step [164/225], Training Accuracy: 53.9920%, Training Loss: 1.0257%\n",
      "Epoch [12/300], Step [165/225], Training Accuracy: 54.0057%, Training Loss: 1.0258%\n",
      "Epoch [12/300], Step [166/225], Training Accuracy: 54.0098%, Training Loss: 1.0255%\n",
      "Epoch [12/300], Step [167/225], Training Accuracy: 53.9858%, Training Loss: 1.0256%\n",
      "Epoch [12/300], Step [168/225], Training Accuracy: 53.9900%, Training Loss: 1.0253%\n",
      "Epoch [12/300], Step [169/225], Training Accuracy: 54.0126%, Training Loss: 1.0253%\n",
      "Epoch [12/300], Step [170/225], Training Accuracy: 54.0074%, Training Loss: 1.0250%\n",
      "Epoch [12/300], Step [171/225], Training Accuracy: 54.0205%, Training Loss: 1.0245%\n",
      "Epoch [12/300], Step [172/225], Training Accuracy: 54.0334%, Training Loss: 1.0242%\n",
      "Epoch [12/300], Step [173/225], Training Accuracy: 54.0011%, Training Loss: 1.0246%\n",
      "Epoch [12/300], Step [174/225], Training Accuracy: 54.0140%, Training Loss: 1.0246%\n",
      "Epoch [12/300], Step [175/225], Training Accuracy: 54.0446%, Training Loss: 1.0238%\n",
      "Epoch [12/300], Step [176/225], Training Accuracy: 54.0128%, Training Loss: 1.0241%\n",
      "Epoch [12/300], Step [177/225], Training Accuracy: 54.0519%, Training Loss: 1.0235%\n",
      "Epoch [12/300], Step [178/225], Training Accuracy: 54.0379%, Training Loss: 1.0238%\n",
      "Epoch [12/300], Step [179/225], Training Accuracy: 54.0503%, Training Loss: 1.0238%\n",
      "Epoch [12/300], Step [180/225], Training Accuracy: 54.0191%, Training Loss: 1.0240%\n",
      "Epoch [12/300], Step [181/225], Training Accuracy: 54.0055%, Training Loss: 1.0241%\n",
      "Epoch [12/300], Step [182/225], Training Accuracy: 54.0350%, Training Loss: 1.0235%\n",
      "Epoch [12/300], Step [183/225], Training Accuracy: 54.0813%, Training Loss: 1.0231%\n",
      "Epoch [12/300], Step [184/225], Training Accuracy: 53.9827%, Training Loss: 1.0239%\n",
      "Epoch [12/300], Step [185/225], Training Accuracy: 54.0034%, Training Loss: 1.0240%\n",
      "Epoch [12/300], Step [186/225], Training Accuracy: 54.0407%, Training Loss: 1.0230%\n",
      "Epoch [12/300], Step [187/225], Training Accuracy: 54.0525%, Training Loss: 1.0229%\n",
      "Epoch [12/300], Step [188/225], Training Accuracy: 54.0475%, Training Loss: 1.0227%\n",
      "Epoch [12/300], Step [189/225], Training Accuracy: 54.0592%, Training Loss: 1.0224%\n",
      "Epoch [12/300], Step [190/225], Training Accuracy: 54.0461%, Training Loss: 1.0220%\n",
      "Epoch [12/300], Step [191/225], Training Accuracy: 54.0494%, Training Loss: 1.0224%\n",
      "Epoch [12/300], Step [192/225], Training Accuracy: 54.0283%, Training Loss: 1.0230%\n",
      "Epoch [12/300], Step [193/225], Training Accuracy: 53.9994%, Training Loss: 1.0233%\n",
      "Epoch [12/300], Step [194/225], Training Accuracy: 54.0351%, Training Loss: 1.0225%\n",
      "Epoch [12/300], Step [195/225], Training Accuracy: 54.0304%, Training Loss: 1.0224%\n",
      "Epoch [12/300], Step [196/225], Training Accuracy: 54.0896%, Training Loss: 1.0221%\n",
      "Epoch [12/300], Step [197/225], Training Accuracy: 54.0371%, Training Loss: 1.0225%\n",
      "Epoch [12/300], Step [198/225], Training Accuracy: 54.0483%, Training Loss: 1.0222%\n",
      "Epoch [12/300], Step [199/225], Training Accuracy: 54.0672%, Training Loss: 1.0222%\n",
      "Epoch [12/300], Step [200/225], Training Accuracy: 54.0703%, Training Loss: 1.0222%\n",
      "Epoch [12/300], Step [201/225], Training Accuracy: 54.1278%, Training Loss: 1.0214%\n",
      "Epoch [12/300], Step [202/225], Training Accuracy: 54.1770%, Training Loss: 1.0209%\n",
      "Epoch [12/300], Step [203/225], Training Accuracy: 54.1641%, Training Loss: 1.0213%\n",
      "Epoch [12/300], Step [204/225], Training Accuracy: 54.1437%, Training Loss: 1.0214%\n",
      "Epoch [12/300], Step [205/225], Training Accuracy: 54.1768%, Training Loss: 1.0213%\n",
      "Epoch [12/300], Step [206/225], Training Accuracy: 54.2096%, Training Loss: 1.0216%\n",
      "Epoch [12/300], Step [207/225], Training Accuracy: 54.2572%, Training Loss: 1.0207%\n",
      "Epoch [12/300], Step [208/225], Training Accuracy: 54.2668%, Training Loss: 1.0204%\n",
      "Epoch [12/300], Step [209/225], Training Accuracy: 54.2614%, Training Loss: 1.0202%\n",
      "Epoch [12/300], Step [210/225], Training Accuracy: 54.2411%, Training Loss: 1.0209%\n",
      "Epoch [12/300], Step [211/225], Training Accuracy: 54.2432%, Training Loss: 1.0207%\n",
      "Epoch [12/300], Step [212/225], Training Accuracy: 54.2232%, Training Loss: 1.0211%\n",
      "Epoch [12/300], Step [213/225], Training Accuracy: 54.2033%, Training Loss: 1.0212%\n",
      "Epoch [12/300], Step [214/225], Training Accuracy: 54.1545%, Training Loss: 1.0219%\n",
      "Epoch [12/300], Step [215/225], Training Accuracy: 54.2006%, Training Loss: 1.0215%\n",
      "Epoch [12/300], Step [216/225], Training Accuracy: 54.1594%, Training Loss: 1.0225%\n",
      "Epoch [12/300], Step [217/225], Training Accuracy: 54.1835%, Training Loss: 1.0220%\n",
      "Epoch [12/300], Step [218/225], Training Accuracy: 54.1428%, Training Loss: 1.0226%\n",
      "Epoch [12/300], Step [219/225], Training Accuracy: 54.1881%, Training Loss: 1.0219%\n",
      "Epoch [12/300], Step [220/225], Training Accuracy: 54.1761%, Training Loss: 1.0218%\n",
      "Epoch [12/300], Step [221/225], Training Accuracy: 54.1502%, Training Loss: 1.0222%\n",
      "Epoch [12/300], Step [222/225], Training Accuracy: 54.1737%, Training Loss: 1.0222%\n",
      "Epoch [12/300], Step [223/225], Training Accuracy: 54.1550%, Training Loss: 1.0224%\n",
      "Epoch [12/300], Step [224/225], Training Accuracy: 54.1783%, Training Loss: 1.0222%\n",
      "Epoch [12/300], Step [225/225], Training Accuracy: 54.1898%, Training Loss: 1.0222%\n",
      "Epoch [13/300], Step [1/225], Training Accuracy: 54.6875%, Training Loss: 1.0400%\n",
      "Epoch [13/300], Step [2/225], Training Accuracy: 50.0000%, Training Loss: 1.0535%\n",
      "Epoch [13/300], Step [3/225], Training Accuracy: 49.4792%, Training Loss: 1.0978%\n",
      "Epoch [13/300], Step [4/225], Training Accuracy: 51.9531%, Training Loss: 1.0377%\n",
      "Epoch [13/300], Step [5/225], Training Accuracy: 53.7500%, Training Loss: 1.0155%\n",
      "Epoch [13/300], Step [6/225], Training Accuracy: 53.6458%, Training Loss: 1.0245%\n",
      "Epoch [13/300], Step [7/225], Training Accuracy: 52.6786%, Training Loss: 1.0513%\n",
      "Epoch [13/300], Step [8/225], Training Accuracy: 53.5156%, Training Loss: 1.0332%\n",
      "Epoch [13/300], Step [9/225], Training Accuracy: 52.9514%, Training Loss: 1.0297%\n",
      "Epoch [13/300], Step [10/225], Training Accuracy: 53.4375%, Training Loss: 1.0326%\n",
      "Epoch [13/300], Step [11/225], Training Accuracy: 54.1193%, Training Loss: 1.0188%\n",
      "Epoch [13/300], Step [12/225], Training Accuracy: 53.3854%, Training Loss: 1.0329%\n",
      "Epoch [13/300], Step [13/225], Training Accuracy: 53.4856%, Training Loss: 1.0309%\n",
      "Epoch [13/300], Step [14/225], Training Accuracy: 53.3482%, Training Loss: 1.0321%\n",
      "Epoch [13/300], Step [15/225], Training Accuracy: 52.9167%, Training Loss: 1.0365%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/300], Step [16/225], Training Accuracy: 52.7344%, Training Loss: 1.0399%\n",
      "Epoch [13/300], Step [17/225], Training Accuracy: 53.1250%, Training Loss: 1.0385%\n",
      "Epoch [13/300], Step [18/225], Training Accuracy: 53.1250%, Training Loss: 1.0397%\n",
      "Epoch [13/300], Step [19/225], Training Accuracy: 52.9605%, Training Loss: 1.0372%\n",
      "Epoch [13/300], Step [20/225], Training Accuracy: 53.0469%, Training Loss: 1.0348%\n",
      "Epoch [13/300], Step [21/225], Training Accuracy: 53.4970%, Training Loss: 1.0294%\n",
      "Epoch [13/300], Step [22/225], Training Accuracy: 53.9062%, Training Loss: 1.0272%\n",
      "Epoch [13/300], Step [23/225], Training Accuracy: 53.9402%, Training Loss: 1.0302%\n",
      "Epoch [13/300], Step [24/225], Training Accuracy: 53.8411%, Training Loss: 1.0328%\n",
      "Epoch [13/300], Step [25/225], Training Accuracy: 53.9375%, Training Loss: 1.0280%\n",
      "Epoch [13/300], Step [26/225], Training Accuracy: 53.6659%, Training Loss: 1.0286%\n",
      "Epoch [13/300], Step [27/225], Training Accuracy: 53.9352%, Training Loss: 1.0273%\n",
      "Epoch [13/300], Step [28/225], Training Accuracy: 54.4643%, Training Loss: 1.0225%\n",
      "Epoch [13/300], Step [29/225], Training Accuracy: 54.7953%, Training Loss: 1.0156%\n",
      "Epoch [13/300], Step [30/225], Training Accuracy: 54.8438%, Training Loss: 1.0145%\n",
      "Epoch [13/300], Step [31/225], Training Accuracy: 54.6875%, Training Loss: 1.0158%\n",
      "Epoch [13/300], Step [32/225], Training Accuracy: 54.8828%, Training Loss: 1.0124%\n",
      "Epoch [13/300], Step [33/225], Training Accuracy: 55.2083%, Training Loss: 1.0076%\n",
      "Epoch [13/300], Step [34/225], Training Accuracy: 55.1011%, Training Loss: 1.0079%\n",
      "Epoch [13/300], Step [35/225], Training Accuracy: 55.1339%, Training Loss: 1.0086%\n",
      "Epoch [13/300], Step [36/225], Training Accuracy: 55.0347%, Training Loss: 1.0108%\n",
      "Epoch [13/300], Step [37/225], Training Accuracy: 55.0676%, Training Loss: 1.0104%\n",
      "Epoch [13/300], Step [38/225], Training Accuracy: 55.1809%, Training Loss: 1.0092%\n",
      "Epoch [13/300], Step [39/225], Training Accuracy: 55.3285%, Training Loss: 1.0069%\n",
      "Epoch [13/300], Step [40/225], Training Accuracy: 55.2344%, Training Loss: 1.0071%\n",
      "Epoch [13/300], Step [41/225], Training Accuracy: 55.3354%, Training Loss: 1.0038%\n",
      "Epoch [13/300], Step [42/225], Training Accuracy: 55.5060%, Training Loss: 1.0003%\n",
      "Epoch [13/300], Step [43/225], Training Accuracy: 55.4506%, Training Loss: 1.0009%\n",
      "Epoch [13/300], Step [44/225], Training Accuracy: 55.3267%, Training Loss: 1.0030%\n",
      "Epoch [13/300], Step [45/225], Training Accuracy: 55.3819%, Training Loss: 1.0023%\n",
      "Epoch [13/300], Step [46/225], Training Accuracy: 55.5367%, Training Loss: 0.9991%\n",
      "Epoch [13/300], Step [47/225], Training Accuracy: 55.6848%, Training Loss: 0.9976%\n",
      "Epoch [13/300], Step [48/225], Training Accuracy: 55.7292%, Training Loss: 0.9982%\n",
      "Epoch [13/300], Step [49/225], Training Accuracy: 55.7717%, Training Loss: 0.9989%\n",
      "Epoch [13/300], Step [50/225], Training Accuracy: 55.7812%, Training Loss: 0.9978%\n",
      "Epoch [13/300], Step [51/225], Training Accuracy: 55.6373%, Training Loss: 0.9989%\n",
      "Epoch [13/300], Step [52/225], Training Accuracy: 55.4688%, Training Loss: 0.9988%\n",
      "Epoch [13/300], Step [53/225], Training Accuracy: 55.3066%, Training Loss: 1.0010%\n",
      "Epoch [13/300], Step [54/225], Training Accuracy: 55.1505%, Training Loss: 1.0017%\n",
      "Epoch [13/300], Step [55/225], Training Accuracy: 55.3409%, Training Loss: 0.9995%\n",
      "Epoch [13/300], Step [56/225], Training Accuracy: 55.1897%, Training Loss: 0.9986%\n",
      "Epoch [13/300], Step [57/225], Training Accuracy: 55.2906%, Training Loss: 0.9981%\n",
      "Epoch [13/300], Step [58/225], Training Accuracy: 55.2532%, Training Loss: 0.9988%\n",
      "Epoch [13/300], Step [59/225], Training Accuracy: 55.2701%, Training Loss: 0.9973%\n",
      "Epoch [13/300], Step [60/225], Training Accuracy: 55.3906%, Training Loss: 0.9962%\n",
      "Epoch [13/300], Step [61/225], Training Accuracy: 55.3279%, Training Loss: 0.9977%\n",
      "Epoch [13/300], Step [62/225], Training Accuracy: 55.3931%, Training Loss: 0.9969%\n",
      "Epoch [13/300], Step [63/225], Training Accuracy: 55.2579%, Training Loss: 1.0005%\n",
      "Epoch [13/300], Step [64/225], Training Accuracy: 55.4199%, Training Loss: 0.9998%\n",
      "Epoch [13/300], Step [65/225], Training Accuracy: 55.4087%, Training Loss: 0.9991%\n",
      "Epoch [13/300], Step [66/225], Training Accuracy: 55.4451%, Training Loss: 0.9992%\n",
      "Epoch [13/300], Step [67/225], Training Accuracy: 55.3871%, Training Loss: 1.0001%\n",
      "Epoch [13/300], Step [68/225], Training Accuracy: 55.3079%, Training Loss: 0.9999%\n",
      "Epoch [13/300], Step [69/225], Training Accuracy: 55.3442%, Training Loss: 0.9994%\n",
      "Epoch [13/300], Step [70/225], Training Accuracy: 55.4464%, Training Loss: 0.9982%\n",
      "Epoch [13/300], Step [71/225], Training Accuracy: 55.5018%, Training Loss: 0.9977%\n",
      "Epoch [13/300], Step [72/225], Training Accuracy: 55.4253%, Training Loss: 0.9983%\n",
      "Epoch [13/300], Step [73/225], Training Accuracy: 55.3510%, Training Loss: 1.0010%\n",
      "Epoch [13/300], Step [74/225], Training Accuracy: 55.4476%, Training Loss: 0.9996%\n",
      "Epoch [13/300], Step [75/225], Training Accuracy: 55.4375%, Training Loss: 0.9988%\n",
      "Epoch [13/300], Step [76/225], Training Accuracy: 55.4276%, Training Loss: 0.9986%\n",
      "Epoch [13/300], Step [77/225], Training Accuracy: 55.4180%, Training Loss: 0.9980%\n",
      "Epoch [13/300], Step [78/225], Training Accuracy: 55.4688%, Training Loss: 0.9970%\n",
      "Epoch [13/300], Step [79/225], Training Accuracy: 55.3402%, Training Loss: 0.9983%\n",
      "Epoch [13/300], Step [80/225], Training Accuracy: 55.1758%, Training Loss: 0.9998%\n",
      "Epoch [13/300], Step [81/225], Training Accuracy: 55.2083%, Training Loss: 0.9993%\n",
      "Epoch [13/300], Step [82/225], Training Accuracy: 55.1258%, Training Loss: 1.0003%\n",
      "Epoch [13/300], Step [83/225], Training Accuracy: 55.1581%, Training Loss: 1.0001%\n",
      "Epoch [13/300], Step [84/225], Training Accuracy: 55.0781%, Training Loss: 1.0006%\n",
      "Epoch [13/300], Step [85/225], Training Accuracy: 54.9632%, Training Loss: 1.0020%\n",
      "Epoch [13/300], Step [86/225], Training Accuracy: 54.9237%, Training Loss: 1.0007%\n",
      "Epoch [13/300], Step [87/225], Training Accuracy: 54.8851%, Training Loss: 1.0002%\n",
      "Epoch [13/300], Step [88/225], Training Accuracy: 54.7940%, Training Loss: 1.0009%\n",
      "Epoch [13/300], Step [89/225], Training Accuracy: 54.8104%, Training Loss: 1.0000%\n",
      "Epoch [13/300], Step [90/225], Training Accuracy: 54.7569%, Training Loss: 1.0000%\n",
      "Epoch [13/300], Step [91/225], Training Accuracy: 54.7047%, Training Loss: 0.9995%\n",
      "Epoch [13/300], Step [92/225], Training Accuracy: 54.5856%, Training Loss: 1.0012%\n",
      "Epoch [13/300], Step [93/225], Training Accuracy: 54.5867%, Training Loss: 1.0014%\n",
      "Epoch [13/300], Step [94/225], Training Accuracy: 54.6543%, Training Loss: 1.0002%\n",
      "Epoch [13/300], Step [95/225], Training Accuracy: 54.6382%, Training Loss: 1.0000%\n",
      "Epoch [13/300], Step [96/225], Training Accuracy: 54.6875%, Training Loss: 0.9989%\n",
      "Epoch [13/300], Step [97/225], Training Accuracy: 54.6553%, Training Loss: 0.9988%\n",
      "Epoch [13/300], Step [98/225], Training Accuracy: 54.7353%, Training Loss: 0.9977%\n",
      "Epoch [13/300], Step [99/225], Training Accuracy: 54.6244%, Training Loss: 0.9982%\n",
      "Epoch [13/300], Step [100/225], Training Accuracy: 54.5312%, Training Loss: 0.9994%\n",
      "Epoch [13/300], Step [101/225], Training Accuracy: 54.5792%, Training Loss: 0.9994%\n",
      "Epoch [13/300], Step [102/225], Training Accuracy: 54.5956%, Training Loss: 0.9994%\n",
      "Epoch [13/300], Step [103/225], Training Accuracy: 54.5813%, Training Loss: 0.9999%\n",
      "Epoch [13/300], Step [104/225], Training Accuracy: 54.6575%, Training Loss: 0.9999%\n",
      "Epoch [13/300], Step [105/225], Training Accuracy: 54.6577%, Training Loss: 1.0002%\n",
      "Epoch [13/300], Step [106/225], Training Accuracy: 54.6433%, Training Loss: 1.0000%\n",
      "Epoch [13/300], Step [107/225], Training Accuracy: 54.6291%, Training Loss: 0.9999%\n",
      "Epoch [13/300], Step [108/225], Training Accuracy: 54.5284%, Training Loss: 1.0007%\n",
      "Epoch [13/300], Step [109/225], Training Accuracy: 54.4581%, Training Loss: 1.0015%\n",
      "Epoch [13/300], Step [110/225], Training Accuracy: 54.5455%, Training Loss: 1.0004%\n",
      "Epoch [13/300], Step [111/225], Training Accuracy: 54.5890%, Training Loss: 0.9999%\n",
      "Epoch [13/300], Step [112/225], Training Accuracy: 54.5898%, Training Loss: 0.9996%\n",
      "Epoch [13/300], Step [113/225], Training Accuracy: 54.5077%, Training Loss: 1.0006%\n",
      "Epoch [13/300], Step [114/225], Training Accuracy: 54.4682%, Training Loss: 1.0005%\n",
      "Epoch [13/300], Step [115/225], Training Accuracy: 54.4429%, Training Loss: 1.0017%\n",
      "Epoch [13/300], Step [116/225], Training Accuracy: 54.4720%, Training Loss: 1.0019%\n",
      "Epoch [13/300], Step [117/225], Training Accuracy: 54.4471%, Training Loss: 1.0023%\n",
      "Epoch [13/300], Step [118/225], Training Accuracy: 54.3697%, Training Loss: 1.0039%\n",
      "Epoch [13/300], Step [119/225], Training Accuracy: 54.4118%, Training Loss: 1.0042%\n",
      "Epoch [13/300], Step [120/225], Training Accuracy: 54.4141%, Training Loss: 1.0042%\n",
      "Epoch [13/300], Step [121/225], Training Accuracy: 54.4292%, Training Loss: 1.0046%\n",
      "Epoch [13/300], Step [122/225], Training Accuracy: 54.4314%, Training Loss: 1.0053%\n",
      "Epoch [13/300], Step [123/225], Training Accuracy: 54.3826%, Training Loss: 1.0054%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/300], Step [124/225], Training Accuracy: 54.4355%, Training Loss: 1.0050%\n",
      "Epoch [13/300], Step [125/225], Training Accuracy: 54.5125%, Training Loss: 1.0043%\n",
      "Epoch [13/300], Step [126/225], Training Accuracy: 54.5511%, Training Loss: 1.0045%\n",
      "Epoch [13/300], Step [127/225], Training Accuracy: 54.5891%, Training Loss: 1.0043%\n",
      "Epoch [13/300], Step [128/225], Training Accuracy: 54.5532%, Training Loss: 1.0052%\n",
      "Epoch [13/300], Step [129/225], Training Accuracy: 54.6391%, Training Loss: 1.0043%\n",
      "Epoch [13/300], Step [130/225], Training Accuracy: 54.6394%, Training Loss: 1.0045%\n",
      "Epoch [13/300], Step [131/225], Training Accuracy: 54.6875%, Training Loss: 1.0045%\n",
      "Epoch [13/300], Step [132/225], Training Accuracy: 54.6757%, Training Loss: 1.0047%\n",
      "Epoch [13/300], Step [133/225], Training Accuracy: 54.7462%, Training Loss: 1.0035%\n",
      "Epoch [13/300], Step [134/225], Training Accuracy: 54.7108%, Training Loss: 1.0041%\n",
      "Epoch [13/300], Step [135/225], Training Accuracy: 54.6875%, Training Loss: 1.0038%\n",
      "Epoch [13/300], Step [136/225], Training Accuracy: 54.6415%, Training Loss: 1.0042%\n",
      "Epoch [13/300], Step [137/225], Training Accuracy: 54.6191%, Training Loss: 1.0045%\n",
      "Epoch [13/300], Step [138/225], Training Accuracy: 54.6649%, Training Loss: 1.0036%\n",
      "Epoch [13/300], Step [139/225], Training Accuracy: 54.6538%, Training Loss: 1.0039%\n",
      "Epoch [13/300], Step [140/225], Training Accuracy: 54.7210%, Training Loss: 1.0031%\n",
      "Epoch [13/300], Step [141/225], Training Accuracy: 54.6764%, Training Loss: 1.0033%\n",
      "Epoch [13/300], Step [142/225], Training Accuracy: 54.6765%, Training Loss: 1.0034%\n",
      "Epoch [13/300], Step [143/225], Training Accuracy: 54.6438%, Training Loss: 1.0039%\n",
      "Epoch [13/300], Step [144/225], Training Accuracy: 54.6766%, Training Loss: 1.0038%\n",
      "Epoch [13/300], Step [145/225], Training Accuracy: 54.6336%, Training Loss: 1.0039%\n",
      "Epoch [13/300], Step [146/225], Training Accuracy: 54.6982%, Training Loss: 1.0032%\n",
      "Epoch [13/300], Step [147/225], Training Accuracy: 54.6662%, Training Loss: 1.0036%\n",
      "Epoch [13/300], Step [148/225], Training Accuracy: 54.7403%, Training Loss: 1.0028%\n",
      "Epoch [13/300], Step [149/225], Training Accuracy: 54.6980%, Training Loss: 1.0031%\n",
      "Epoch [13/300], Step [150/225], Training Accuracy: 54.7708%, Training Loss: 1.0020%\n",
      "Epoch [13/300], Step [151/225], Training Accuracy: 54.8220%, Training Loss: 1.0009%\n",
      "Epoch [13/300], Step [152/225], Training Accuracy: 54.7903%, Training Loss: 1.0006%\n",
      "Epoch [13/300], Step [153/225], Training Accuracy: 54.7998%, Training Loss: 0.9998%\n",
      "Epoch [13/300], Step [154/225], Training Accuracy: 54.7788%, Training Loss: 0.9997%\n",
      "Epoch [13/300], Step [155/225], Training Accuracy: 54.7480%, Training Loss: 0.9996%\n",
      "Epoch [13/300], Step [156/225], Training Accuracy: 54.7276%, Training Loss: 1.0002%\n",
      "Epoch [13/300], Step [157/225], Training Accuracy: 54.7472%, Training Loss: 0.9996%\n",
      "Epoch [13/300], Step [158/225], Training Accuracy: 54.7666%, Training Loss: 0.9993%\n",
      "Epoch [13/300], Step [159/225], Training Accuracy: 54.7465%, Training Loss: 0.9995%\n",
      "Epoch [13/300], Step [160/225], Training Accuracy: 54.6777%, Training Loss: 0.9999%\n",
      "Epoch [13/300], Step [161/225], Training Accuracy: 54.6875%, Training Loss: 0.9997%\n",
      "Epoch [13/300], Step [162/225], Training Accuracy: 54.7357%, Training Loss: 0.9995%\n",
      "Epoch [13/300], Step [163/225], Training Accuracy: 54.7929%, Training Loss: 0.9984%\n",
      "Epoch [13/300], Step [164/225], Training Accuracy: 54.8780%, Training Loss: 0.9971%\n",
      "Epoch [13/300], Step [165/225], Training Accuracy: 54.8958%, Training Loss: 0.9970%\n",
      "Epoch [13/300], Step [166/225], Training Accuracy: 54.9228%, Training Loss: 0.9964%\n",
      "Epoch [13/300], Step [167/225], Training Accuracy: 54.9214%, Training Loss: 0.9964%\n",
      "Epoch [13/300], Step [168/225], Training Accuracy: 54.9293%, Training Loss: 0.9963%\n",
      "Epoch [13/300], Step [169/225], Training Accuracy: 54.9186%, Training Loss: 0.9964%\n",
      "Epoch [13/300], Step [170/225], Training Accuracy: 54.9173%, Training Loss: 0.9962%\n",
      "Epoch [13/300], Step [171/225], Training Accuracy: 54.9525%, Training Loss: 0.9959%\n",
      "Epoch [13/300], Step [172/225], Training Accuracy: 55.0327%, Training Loss: 0.9950%\n",
      "Epoch [13/300], Step [173/225], Training Accuracy: 54.9855%, Training Loss: 0.9955%\n",
      "Epoch [13/300], Step [174/225], Training Accuracy: 55.0108%, Training Loss: 0.9951%\n",
      "Epoch [13/300], Step [175/225], Training Accuracy: 55.0357%, Training Loss: 0.9943%\n",
      "Epoch [13/300], Step [176/225], Training Accuracy: 55.0515%, Training Loss: 0.9944%\n",
      "Epoch [13/300], Step [177/225], Training Accuracy: 55.0583%, Training Loss: 0.9942%\n",
      "Epoch [13/300], Step [178/225], Training Accuracy: 55.0211%, Training Loss: 0.9945%\n",
      "Epoch [13/300], Step [179/225], Training Accuracy: 55.0367%, Training Loss: 0.9948%\n",
      "Epoch [13/300], Step [180/225], Training Accuracy: 55.0521%, Training Loss: 0.9945%\n",
      "Epoch [13/300], Step [181/225], Training Accuracy: 55.0760%, Training Loss: 0.9948%\n",
      "Epoch [13/300], Step [182/225], Training Accuracy: 55.0910%, Training Loss: 0.9944%\n",
      "Epoch [13/300], Step [183/225], Training Accuracy: 55.1144%, Training Loss: 0.9940%\n",
      "Epoch [13/300], Step [184/225], Training Accuracy: 55.0611%, Training Loss: 0.9948%\n",
      "Epoch [13/300], Step [185/225], Training Accuracy: 55.0591%, Training Loss: 0.9949%\n",
      "Epoch [13/300], Step [186/225], Training Accuracy: 55.1075%, Training Loss: 0.9941%\n",
      "Epoch [13/300], Step [187/225], Training Accuracy: 55.0886%, Training Loss: 0.9939%\n",
      "Epoch [13/300], Step [188/225], Training Accuracy: 55.1529%, Training Loss: 0.9934%\n",
      "Epoch [13/300], Step [189/225], Training Accuracy: 55.1753%, Training Loss: 0.9930%\n",
      "Epoch [13/300], Step [190/225], Training Accuracy: 55.1891%, Training Loss: 0.9924%\n",
      "Epoch [13/300], Step [191/225], Training Accuracy: 55.1947%, Training Loss: 0.9930%\n",
      "Epoch [13/300], Step [192/225], Training Accuracy: 55.1514%, Training Loss: 0.9936%\n",
      "Epoch [13/300], Step [193/225], Training Accuracy: 55.0923%, Training Loss: 0.9943%\n",
      "Epoch [13/300], Step [194/225], Training Accuracy: 55.1627%, Training Loss: 0.9936%\n",
      "Epoch [13/300], Step [195/225], Training Accuracy: 55.1362%, Training Loss: 0.9938%\n",
      "Epoch [13/300], Step [196/225], Training Accuracy: 55.1977%, Training Loss: 0.9931%\n",
      "Epoch [13/300], Step [197/225], Training Accuracy: 55.1475%, Training Loss: 0.9937%\n",
      "Epoch [13/300], Step [198/225], Training Accuracy: 55.1847%, Training Loss: 0.9933%\n",
      "Epoch [13/300], Step [199/225], Training Accuracy: 55.1743%, Training Loss: 0.9935%\n",
      "Epoch [13/300], Step [200/225], Training Accuracy: 55.1875%, Training Loss: 0.9935%\n",
      "Epoch [13/300], Step [201/225], Training Accuracy: 55.1850%, Training Loss: 0.9931%\n",
      "Epoch [13/300], Step [202/225], Training Accuracy: 55.2135%, Training Loss: 0.9926%\n",
      "Epoch [13/300], Step [203/225], Training Accuracy: 55.2340%, Training Loss: 0.9927%\n",
      "Epoch [13/300], Step [204/225], Training Accuracy: 55.2390%, Training Loss: 0.9927%\n",
      "Epoch [13/300], Step [205/225], Training Accuracy: 55.2439%, Training Loss: 0.9927%\n",
      "Epoch [13/300], Step [206/225], Training Accuracy: 55.2640%, Training Loss: 0.9930%\n",
      "Epoch [13/300], Step [207/225], Training Accuracy: 55.3065%, Training Loss: 0.9922%\n",
      "Epoch [13/300], Step [208/225], Training Accuracy: 55.3335%, Training Loss: 0.9918%\n",
      "Epoch [13/300], Step [209/225], Training Accuracy: 55.3603%, Training Loss: 0.9914%\n",
      "Epoch [13/300], Step [210/225], Training Accuracy: 55.3348%, Training Loss: 0.9918%\n",
      "Epoch [13/300], Step [211/225], Training Accuracy: 55.3614%, Training Loss: 0.9913%\n",
      "Epoch [13/300], Step [212/225], Training Accuracy: 55.3656%, Training Loss: 0.9916%\n",
      "Epoch [13/300], Step [213/225], Training Accuracy: 55.3917%, Training Loss: 0.9915%\n",
      "Epoch [13/300], Step [214/225], Training Accuracy: 55.3738%, Training Loss: 0.9922%\n",
      "Epoch [13/300], Step [215/225], Training Accuracy: 55.4288%, Training Loss: 0.9916%\n",
      "Epoch [13/300], Step [216/225], Training Accuracy: 55.3964%, Training Loss: 0.9929%\n",
      "Epoch [13/300], Step [217/225], Training Accuracy: 55.4435%, Training Loss: 0.9923%\n",
      "Epoch [13/300], Step [218/225], Training Accuracy: 55.3971%, Training Loss: 0.9925%\n",
      "Epoch [13/300], Step [219/225], Training Accuracy: 55.4081%, Training Loss: 0.9920%\n",
      "Epoch [13/300], Step [220/225], Training Accuracy: 55.3977%, Training Loss: 0.9916%\n",
      "Epoch [13/300], Step [221/225], Training Accuracy: 55.3874%, Training Loss: 0.9918%\n",
      "Epoch [13/300], Step [222/225], Training Accuracy: 55.3491%, Training Loss: 0.9924%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/300], Step [223/225], Training Accuracy: 55.3742%, Training Loss: 0.9921%\n",
      "Epoch [13/300], Step [224/225], Training Accuracy: 55.3711%, Training Loss: 0.9918%\n",
      "Epoch [13/300], Step [225/225], Training Accuracy: 55.3710%, Training Loss: 0.9918%\n",
      "Epoch [14/300], Step [1/225], Training Accuracy: 59.3750%, Training Loss: 0.9883%\n",
      "Epoch [14/300], Step [2/225], Training Accuracy: 62.5000%, Training Loss: 0.9683%\n",
      "Epoch [14/300], Step [3/225], Training Accuracy: 57.2917%, Training Loss: 1.0283%\n",
      "Epoch [14/300], Step [4/225], Training Accuracy: 60.5469%, Training Loss: 0.9704%\n",
      "Epoch [14/300], Step [5/225], Training Accuracy: 61.5625%, Training Loss: 0.9529%\n",
      "Epoch [14/300], Step [6/225], Training Accuracy: 59.6354%, Training Loss: 0.9838%\n",
      "Epoch [14/300], Step [7/225], Training Accuracy: 58.9286%, Training Loss: 1.0094%\n",
      "Epoch [14/300], Step [8/225], Training Accuracy: 58.7891%, Training Loss: 1.0006%\n",
      "Epoch [14/300], Step [9/225], Training Accuracy: 58.8542%, Training Loss: 0.9941%\n",
      "Epoch [14/300], Step [10/225], Training Accuracy: 58.9062%, Training Loss: 0.9946%\n",
      "Epoch [14/300], Step [11/225], Training Accuracy: 59.2330%, Training Loss: 0.9824%\n",
      "Epoch [14/300], Step [12/225], Training Accuracy: 58.3333%, Training Loss: 0.9923%\n",
      "Epoch [14/300], Step [13/225], Training Accuracy: 58.0529%, Training Loss: 0.9968%\n",
      "Epoch [14/300], Step [14/225], Training Accuracy: 57.9241%, Training Loss: 0.9997%\n",
      "Epoch [14/300], Step [15/225], Training Accuracy: 57.2917%, Training Loss: 1.0022%\n",
      "Epoch [14/300], Step [16/225], Training Accuracy: 57.0312%, Training Loss: 1.0033%\n",
      "Epoch [14/300], Step [17/225], Training Accuracy: 57.3529%, Training Loss: 1.0034%\n",
      "Epoch [14/300], Step [18/225], Training Accuracy: 57.4653%, Training Loss: 0.9999%\n",
      "Epoch [14/300], Step [19/225], Training Accuracy: 57.2368%, Training Loss: 0.9965%\n",
      "Epoch [14/300], Step [20/225], Training Accuracy: 56.8750%, Training Loss: 0.9958%\n",
      "Epoch [14/300], Step [21/225], Training Accuracy: 57.3661%, Training Loss: 0.9878%\n",
      "Epoch [14/300], Step [22/225], Training Accuracy: 57.3864%, Training Loss: 0.9868%\n",
      "Epoch [14/300], Step [23/225], Training Accuracy: 57.2690%, Training Loss: 0.9908%\n",
      "Epoch [14/300], Step [24/225], Training Accuracy: 56.8359%, Training Loss: 0.9946%\n",
      "Epoch [14/300], Step [25/225], Training Accuracy: 56.9375%, Training Loss: 0.9898%\n",
      "Epoch [14/300], Step [26/225], Training Accuracy: 56.7308%, Training Loss: 0.9889%\n",
      "Epoch [14/300], Step [27/225], Training Accuracy: 56.5394%, Training Loss: 0.9897%\n",
      "Epoch [14/300], Step [28/225], Training Accuracy: 56.9196%, Training Loss: 0.9831%\n",
      "Epoch [14/300], Step [29/225], Training Accuracy: 56.9504%, Training Loss: 0.9788%\n",
      "Epoch [14/300], Step [30/225], Training Accuracy: 56.8229%, Training Loss: 0.9804%\n",
      "Epoch [14/300], Step [31/225], Training Accuracy: 56.6532%, Training Loss: 0.9820%\n",
      "Epoch [14/300], Step [32/225], Training Accuracy: 56.9824%, Training Loss: 0.9782%\n",
      "Epoch [14/300], Step [33/225], Training Accuracy: 57.2917%, Training Loss: 0.9739%\n",
      "Epoch [14/300], Step [34/225], Training Accuracy: 57.0772%, Training Loss: 0.9746%\n",
      "Epoch [14/300], Step [35/225], Training Accuracy: 57.1875%, Training Loss: 0.9763%\n",
      "Epoch [14/300], Step [36/225], Training Accuracy: 57.0747%, Training Loss: 0.9788%\n",
      "Epoch [14/300], Step [37/225], Training Accuracy: 57.1368%, Training Loss: 0.9794%\n",
      "Epoch [14/300], Step [38/225], Training Accuracy: 57.2368%, Training Loss: 0.9788%\n",
      "Epoch [14/300], Step [39/225], Training Accuracy: 57.4519%, Training Loss: 0.9756%\n",
      "Epoch [14/300], Step [40/225], Training Accuracy: 57.4219%, Training Loss: 0.9746%\n",
      "Epoch [14/300], Step [41/225], Training Accuracy: 57.4314%, Training Loss: 0.9720%\n",
      "Epoch [14/300], Step [42/225], Training Accuracy: 57.5893%, Training Loss: 0.9690%\n",
      "Epoch [14/300], Step [43/225], Training Accuracy: 57.6308%, Training Loss: 0.9696%\n",
      "Epoch [14/300], Step [44/225], Training Accuracy: 57.5994%, Training Loss: 0.9697%\n",
      "Epoch [14/300], Step [45/225], Training Accuracy: 57.7431%, Training Loss: 0.9685%\n",
      "Epoch [14/300], Step [46/225], Training Accuracy: 57.8125%, Training Loss: 0.9667%\n",
      "Epoch [14/300], Step [47/225], Training Accuracy: 57.7793%, Training Loss: 0.9685%\n",
      "Epoch [14/300], Step [48/225], Training Accuracy: 57.6497%, Training Loss: 0.9698%\n",
      "Epoch [14/300], Step [49/225], Training Accuracy: 57.6531%, Training Loss: 0.9691%\n",
      "Epoch [14/300], Step [50/225], Training Accuracy: 57.7188%, Training Loss: 0.9676%\n",
      "Epoch [14/300], Step [51/225], Training Accuracy: 57.5061%, Training Loss: 0.9683%\n",
      "Epoch [14/300], Step [52/225], Training Accuracy: 57.5421%, Training Loss: 0.9670%\n",
      "Epoch [14/300], Step [53/225], Training Accuracy: 57.6356%, Training Loss: 0.9672%\n",
      "Epoch [14/300], Step [54/225], Training Accuracy: 57.7836%, Training Loss: 0.9668%\n",
      "Epoch [14/300], Step [55/225], Training Accuracy: 57.8693%, Training Loss: 0.9662%\n",
      "Epoch [14/300], Step [56/225], Training Accuracy: 57.8404%, Training Loss: 0.9650%\n",
      "Epoch [14/300], Step [57/225], Training Accuracy: 57.7851%, Training Loss: 0.9655%\n",
      "Epoch [14/300], Step [58/225], Training Accuracy: 57.6778%, Training Loss: 0.9677%\n",
      "Epoch [14/300], Step [59/225], Training Accuracy: 57.6801%, Training Loss: 0.9670%\n",
      "Epoch [14/300], Step [60/225], Training Accuracy: 57.6302%, Training Loss: 0.9665%\n",
      "Epoch [14/300], Step [61/225], Training Accuracy: 57.5820%, Training Loss: 0.9667%\n",
      "Epoch [14/300], Step [62/225], Training Accuracy: 57.6109%, Training Loss: 0.9671%\n",
      "Epoch [14/300], Step [63/225], Training Accuracy: 57.5149%, Training Loss: 0.9694%\n",
      "Epoch [14/300], Step [64/225], Training Accuracy: 57.5684%, Training Loss: 0.9697%\n",
      "Epoch [14/300], Step [65/225], Training Accuracy: 57.5962%, Training Loss: 0.9693%\n",
      "Epoch [14/300], Step [66/225], Training Accuracy: 57.6231%, Training Loss: 0.9701%\n",
      "Epoch [14/300], Step [67/225], Training Accuracy: 57.5793%, Training Loss: 0.9704%\n",
      "Epoch [14/300], Step [68/225], Training Accuracy: 57.6746%, Training Loss: 0.9691%\n",
      "Epoch [14/300], Step [69/225], Training Accuracy: 57.6993%, Training Loss: 0.9683%\n",
      "Epoch [14/300], Step [70/225], Training Accuracy: 57.7679%, Training Loss: 0.9664%\n",
      "Epoch [14/300], Step [71/225], Training Accuracy: 57.7465%, Training Loss: 0.9656%\n",
      "Epoch [14/300], Step [72/225], Training Accuracy: 57.7474%, Training Loss: 0.9665%\n",
      "Epoch [14/300], Step [73/225], Training Accuracy: 57.6627%, Training Loss: 0.9677%\n",
      "Epoch [14/300], Step [74/225], Training Accuracy: 57.6858%, Training Loss: 0.9663%\n",
      "Epoch [14/300], Step [75/225], Training Accuracy: 57.6875%, Training Loss: 0.9656%\n",
      "Epoch [14/300], Step [76/225], Training Accuracy: 57.7097%, Training Loss: 0.9658%\n",
      "Epoch [14/300], Step [77/225], Training Accuracy: 57.7110%, Training Loss: 0.9657%\n",
      "Epoch [14/300], Step [78/225], Training Accuracy: 57.7524%, Training Loss: 0.9647%\n",
      "Epoch [14/300], Step [79/225], Training Accuracy: 57.8323%, Training Loss: 0.9650%\n",
      "Epoch [14/300], Step [80/225], Training Accuracy: 57.6758%, Training Loss: 0.9671%\n",
      "Epoch [14/300], Step [81/225], Training Accuracy: 57.7353%, Training Loss: 0.9662%\n",
      "Epoch [14/300], Step [82/225], Training Accuracy: 57.7172%, Training Loss: 0.9667%\n",
      "Epoch [14/300], Step [83/225], Training Accuracy: 57.8313%, Training Loss: 0.9657%\n",
      "Epoch [14/300], Step [84/225], Training Accuracy: 57.8683%, Training Loss: 0.9655%\n",
      "Epoch [14/300], Step [85/225], Training Accuracy: 57.8125%, Training Loss: 0.9656%\n",
      "Epoch [14/300], Step [86/225], Training Accuracy: 57.8852%, Training Loss: 0.9643%\n",
      "Epoch [14/300], Step [87/225], Training Accuracy: 57.8843%, Training Loss: 0.9631%\n",
      "Epoch [14/300], Step [88/225], Training Accuracy: 57.9723%, Training Loss: 0.9623%\n",
      "Epoch [14/300], Step [89/225], Training Accuracy: 58.0583%, Training Loss: 0.9606%\n",
      "Epoch [14/300], Step [90/225], Training Accuracy: 58.0208%, Training Loss: 0.9604%\n",
      "Epoch [14/300], Step [91/225], Training Accuracy: 58.0185%, Training Loss: 0.9601%\n",
      "Epoch [14/300], Step [92/225], Training Accuracy: 57.8635%, Training Loss: 0.9616%\n",
      "Epoch [14/300], Step [93/225], Training Accuracy: 57.8293%, Training Loss: 0.9618%\n",
      "Epoch [14/300], Step [94/225], Training Accuracy: 57.8457%, Training Loss: 0.9616%\n",
      "Epoch [14/300], Step [95/225], Training Accuracy: 57.8289%, Training Loss: 0.9620%\n",
      "Epoch [14/300], Step [96/225], Training Accuracy: 57.9264%, Training Loss: 0.9606%\n",
      "Epoch [14/300], Step [97/225], Training Accuracy: 57.8447%, Training Loss: 0.9610%\n",
      "Epoch [14/300], Step [98/225], Training Accuracy: 57.9082%, Training Loss: 0.9594%\n",
      "Epoch [14/300], Step [99/225], Training Accuracy: 57.8598%, Training Loss: 0.9604%\n",
      "Epoch [14/300], Step [100/225], Training Accuracy: 57.7656%, Training Loss: 0.9618%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/300], Step [101/225], Training Accuracy: 57.7970%, Training Loss: 0.9614%\n",
      "Epoch [14/300], Step [102/225], Training Accuracy: 57.8125%, Training Loss: 0.9611%\n",
      "Epoch [14/300], Step [103/225], Training Accuracy: 57.7367%, Training Loss: 0.9614%\n",
      "Epoch [14/300], Step [104/225], Training Accuracy: 57.6923%, Training Loss: 0.9615%\n",
      "Epoch [14/300], Step [105/225], Training Accuracy: 57.7083%, Training Loss: 0.9615%\n",
      "Epoch [14/300], Step [106/225], Training Accuracy: 57.6946%, Training Loss: 0.9619%\n",
      "Epoch [14/300], Step [107/225], Training Accuracy: 57.6665%, Training Loss: 0.9622%\n",
      "Epoch [14/300], Step [108/225], Training Accuracy: 57.6534%, Training Loss: 0.9624%\n",
      "Epoch [14/300], Step [109/225], Training Accuracy: 57.6261%, Training Loss: 0.9632%\n",
      "Epoch [14/300], Step [110/225], Training Accuracy: 57.6847%, Training Loss: 0.9626%\n",
      "Epoch [14/300], Step [111/225], Training Accuracy: 57.7421%, Training Loss: 0.9620%\n",
      "Epoch [14/300], Step [112/225], Training Accuracy: 57.7846%, Training Loss: 0.9614%\n",
      "Epoch [14/300], Step [113/225], Training Accuracy: 57.7295%, Training Loss: 0.9622%\n",
      "Epoch [14/300], Step [114/225], Training Accuracy: 57.6617%, Training Loss: 0.9626%\n",
      "Epoch [14/300], Step [115/225], Training Accuracy: 57.6223%, Training Loss: 0.9638%\n",
      "Epoch [14/300], Step [116/225], Training Accuracy: 57.6509%, Training Loss: 0.9638%\n",
      "Epoch [14/300], Step [117/225], Training Accuracy: 57.7190%, Training Loss: 0.9637%\n",
      "Epoch [14/300], Step [118/225], Training Accuracy: 57.6668%, Training Loss: 0.9652%\n",
      "Epoch [14/300], Step [119/225], Training Accuracy: 57.6287%, Training Loss: 0.9655%\n",
      "Epoch [14/300], Step [120/225], Training Accuracy: 57.6562%, Training Loss: 0.9648%\n",
      "Epoch [14/300], Step [121/225], Training Accuracy: 57.6834%, Training Loss: 0.9647%\n",
      "Epoch [14/300], Step [122/225], Training Accuracy: 57.6588%, Training Loss: 0.9650%\n",
      "Epoch [14/300], Step [123/225], Training Accuracy: 57.6728%, Training Loss: 0.9647%\n",
      "Epoch [14/300], Step [124/225], Training Accuracy: 57.7117%, Training Loss: 0.9643%\n",
      "Epoch [14/300], Step [125/225], Training Accuracy: 57.7375%, Training Loss: 0.9636%\n",
      "Epoch [14/300], Step [126/225], Training Accuracy: 57.7009%, Training Loss: 0.9636%\n",
      "Epoch [14/300], Step [127/225], Training Accuracy: 57.6772%, Training Loss: 0.9641%\n",
      "Epoch [14/300], Step [128/225], Training Accuracy: 57.6416%, Training Loss: 0.9645%\n",
      "Epoch [14/300], Step [129/225], Training Accuracy: 57.7519%, Training Loss: 0.9637%\n",
      "Epoch [14/300], Step [130/225], Training Accuracy: 57.8245%, Training Loss: 0.9634%\n",
      "Epoch [14/300], Step [131/225], Training Accuracy: 57.8244%, Training Loss: 0.9634%\n",
      "Epoch [14/300], Step [132/225], Training Accuracy: 57.7296%, Training Loss: 0.9641%\n",
      "Epoch [14/300], Step [133/225], Training Accuracy: 57.7773%, Training Loss: 0.9629%\n",
      "Epoch [14/300], Step [134/225], Training Accuracy: 57.7192%, Training Loss: 0.9636%\n",
      "Epoch [14/300], Step [135/225], Training Accuracy: 57.7662%, Training Loss: 0.9626%\n",
      "Epoch [14/300], Step [136/225], Training Accuracy: 57.7551%, Training Loss: 0.9627%\n",
      "Epoch [14/300], Step [137/225], Training Accuracy: 57.7783%, Training Loss: 0.9624%\n",
      "Epoch [14/300], Step [138/225], Training Accuracy: 57.7785%, Training Loss: 0.9626%\n",
      "Epoch [14/300], Step [139/225], Training Accuracy: 57.7226%, Training Loss: 0.9629%\n",
      "Epoch [14/300], Step [140/225], Training Accuracy: 57.7790%, Training Loss: 0.9619%\n",
      "Epoch [14/300], Step [141/225], Training Accuracy: 57.8014%, Training Loss: 0.9622%\n",
      "Epoch [14/300], Step [142/225], Training Accuracy: 57.7795%, Training Loss: 0.9625%\n",
      "Epoch [14/300], Step [143/225], Training Accuracy: 57.7688%, Training Loss: 0.9630%\n",
      "Epoch [14/300], Step [144/225], Training Accuracy: 57.7799%, Training Loss: 0.9632%\n",
      "Epoch [14/300], Step [145/225], Training Accuracy: 57.7694%, Training Loss: 0.9635%\n",
      "Epoch [14/300], Step [146/225], Training Accuracy: 57.7483%, Training Loss: 0.9630%\n",
      "Epoch [14/300], Step [147/225], Training Accuracy: 57.7275%, Training Loss: 0.9639%\n",
      "Epoch [14/300], Step [148/225], Training Accuracy: 57.7492%, Training Loss: 0.9634%\n",
      "Epoch [14/300], Step [149/225], Training Accuracy: 57.8020%, Training Loss: 0.9634%\n",
      "Epoch [14/300], Step [150/225], Training Accuracy: 57.8438%, Training Loss: 0.9621%\n",
      "Epoch [14/300], Step [151/225], Training Accuracy: 57.9056%, Training Loss: 0.9613%\n",
      "Epoch [14/300], Step [152/225], Training Accuracy: 57.8845%, Training Loss: 0.9611%\n",
      "Epoch [14/300], Step [153/225], Training Accuracy: 57.9044%, Training Loss: 0.9606%\n",
      "Epoch [14/300], Step [154/225], Training Accuracy: 57.9038%, Training Loss: 0.9607%\n",
      "Epoch [14/300], Step [155/225], Training Accuracy: 57.9032%, Training Loss: 0.9609%\n",
      "Epoch [14/300], Step [156/225], Training Accuracy: 57.8826%, Training Loss: 0.9614%\n",
      "Epoch [14/300], Step [157/225], Training Accuracy: 57.9220%, Training Loss: 0.9607%\n",
      "Epoch [14/300], Step [158/225], Training Accuracy: 57.9312%, Training Loss: 0.9602%\n",
      "Epoch [14/300], Step [159/225], Training Accuracy: 57.9403%, Training Loss: 0.9603%\n",
      "Epoch [14/300], Step [160/225], Training Accuracy: 57.9199%, Training Loss: 0.9605%\n",
      "Epoch [14/300], Step [161/225], Training Accuracy: 57.8804%, Training Loss: 0.9606%\n",
      "Epoch [14/300], Step [162/225], Training Accuracy: 57.9282%, Training Loss: 0.9604%\n",
      "Epoch [14/300], Step [163/225], Training Accuracy: 57.9755%, Training Loss: 0.9594%\n",
      "Epoch [14/300], Step [164/225], Training Accuracy: 58.0316%, Training Loss: 0.9582%\n",
      "Epoch [14/300], Step [165/225], Training Accuracy: 58.0114%, Training Loss: 0.9585%\n",
      "Epoch [14/300], Step [166/225], Training Accuracy: 57.9725%, Training Loss: 0.9588%\n",
      "Epoch [14/300], Step [167/225], Training Accuracy: 58.0090%, Training Loss: 0.9584%\n",
      "Epoch [14/300], Step [168/225], Training Accuracy: 58.0078%, Training Loss: 0.9586%\n",
      "Epoch [14/300], Step [169/225], Training Accuracy: 58.0067%, Training Loss: 0.9586%\n",
      "Epoch [14/300], Step [170/225], Training Accuracy: 58.0055%, Training Loss: 0.9583%\n",
      "Epoch [14/300], Step [171/225], Training Accuracy: 57.9952%, Training Loss: 0.9581%\n",
      "Epoch [14/300], Step [172/225], Training Accuracy: 58.0305%, Training Loss: 0.9576%\n",
      "Epoch [14/300], Step [173/225], Training Accuracy: 57.9931%, Training Loss: 0.9581%\n",
      "Epoch [14/300], Step [174/225], Training Accuracy: 58.0280%, Training Loss: 0.9579%\n",
      "Epoch [14/300], Step [175/225], Training Accuracy: 58.0357%, Training Loss: 0.9573%\n",
      "Epoch [14/300], Step [176/225], Training Accuracy: 58.0611%, Training Loss: 0.9570%\n",
      "Epoch [14/300], Step [177/225], Training Accuracy: 58.0597%, Training Loss: 0.9567%\n",
      "Epoch [14/300], Step [178/225], Training Accuracy: 58.0056%, Training Loss: 0.9574%\n",
      "Epoch [14/300], Step [179/225], Training Accuracy: 57.9958%, Training Loss: 0.9574%\n",
      "Epoch [14/300], Step [180/225], Training Accuracy: 58.0295%, Training Loss: 0.9573%\n",
      "Epoch [14/300], Step [181/225], Training Accuracy: 58.0283%, Training Loss: 0.9577%\n",
      "Epoch [14/300], Step [182/225], Training Accuracy: 58.0185%, Training Loss: 0.9571%\n",
      "Epoch [14/300], Step [183/225], Training Accuracy: 58.0174%, Training Loss: 0.9570%\n",
      "Epoch [14/300], Step [184/225], Training Accuracy: 57.9399%, Training Loss: 0.9580%\n",
      "Epoch [14/300], Step [185/225], Training Accuracy: 57.9223%, Training Loss: 0.9582%\n",
      "Epoch [14/300], Step [186/225], Training Accuracy: 57.9301%, Training Loss: 0.9577%\n",
      "Epoch [14/300], Step [187/225], Training Accuracy: 57.9295%, Training Loss: 0.9576%\n",
      "Epoch [14/300], Step [188/225], Training Accuracy: 57.9205%, Training Loss: 0.9576%\n",
      "Epoch [14/300], Step [189/225], Training Accuracy: 57.9282%, Training Loss: 0.9570%\n",
      "Epoch [14/300], Step [190/225], Training Accuracy: 57.9523%, Training Loss: 0.9565%\n",
      "Epoch [14/300], Step [191/225], Training Accuracy: 57.9516%, Training Loss: 0.9569%\n",
      "Epoch [14/300], Step [192/225], Training Accuracy: 57.9102%, Training Loss: 0.9574%\n",
      "Epoch [14/300], Step [193/225], Training Accuracy: 57.8692%, Training Loss: 0.9579%\n",
      "Epoch [14/300], Step [194/225], Training Accuracy: 57.9333%, Training Loss: 0.9574%\n",
      "Epoch [14/300], Step [195/225], Training Accuracy: 57.8846%, Training Loss: 0.9576%\n",
      "Epoch [14/300], Step [196/225], Training Accuracy: 57.9799%, Training Loss: 0.9566%\n",
      "Epoch [14/300], Step [197/225], Training Accuracy: 57.9632%, Training Loss: 0.9572%\n",
      "Epoch [14/300], Step [198/225], Training Accuracy: 57.9467%, Training Loss: 0.9570%\n",
      "Epoch [14/300], Step [199/225], Training Accuracy: 57.9224%, Training Loss: 0.9574%\n",
      "Epoch [14/300], Step [200/225], Training Accuracy: 57.9297%, Training Loss: 0.9569%\n",
      "Epoch [14/300], Step [201/225], Training Accuracy: 57.9524%, Training Loss: 0.9561%\n",
      "Epoch [14/300], Step [202/225], Training Accuracy: 57.9595%, Training Loss: 0.9558%\n",
      "Epoch [14/300], Step [203/225], Training Accuracy: 57.9587%, Training Loss: 0.9556%\n",
      "Epoch [14/300], Step [204/225], Training Accuracy: 57.9810%, Training Loss: 0.9556%\n",
      "Epoch [14/300], Step [205/225], Training Accuracy: 58.0030%, Training Loss: 0.9555%\n",
      "Epoch [14/300], Step [206/225], Training Accuracy: 57.9718%, Training Loss: 0.9561%\n",
      "Epoch [14/300], Step [207/225], Training Accuracy: 58.0163%, Training Loss: 0.9550%\n",
      "Epoch [14/300], Step [208/225], Training Accuracy: 58.0454%, Training Loss: 0.9544%\n",
      "Epoch [14/300], Step [209/225], Training Accuracy: 58.0443%, Training Loss: 0.9540%\n",
      "Epoch [14/300], Step [210/225], Training Accuracy: 58.0208%, Training Loss: 0.9541%\n",
      "Epoch [14/300], Step [211/225], Training Accuracy: 58.0495%, Training Loss: 0.9534%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/300], Step [212/225], Training Accuracy: 58.0262%, Training Loss: 0.9538%\n",
      "Epoch [14/300], Step [213/225], Training Accuracy: 58.0179%, Training Loss: 0.9541%\n",
      "Epoch [14/300], Step [214/225], Training Accuracy: 57.9585%, Training Loss: 0.9546%\n",
      "Epoch [14/300], Step [215/225], Training Accuracy: 57.9869%, Training Loss: 0.9539%\n",
      "Epoch [14/300], Step [216/225], Training Accuracy: 57.9499%, Training Loss: 0.9545%\n",
      "Epoch [14/300], Step [217/225], Training Accuracy: 57.9565%, Training Loss: 0.9539%\n",
      "Epoch [14/300], Step [218/225], Training Accuracy: 57.9415%, Training Loss: 0.9546%\n",
      "Epoch [14/300], Step [219/225], Training Accuracy: 57.9623%, Training Loss: 0.9541%\n",
      "Epoch [14/300], Step [220/225], Training Accuracy: 58.0327%, Training Loss: 0.9533%\n",
      "Epoch [14/300], Step [221/225], Training Accuracy: 57.9893%, Training Loss: 0.9537%\n",
      "Epoch [14/300], Step [222/225], Training Accuracy: 57.9885%, Training Loss: 0.9539%\n",
      "Epoch [14/300], Step [223/225], Training Accuracy: 57.9877%, Training Loss: 0.9537%\n",
      "Epoch [14/300], Step [224/225], Training Accuracy: 58.0078%, Training Loss: 0.9532%\n",
      "Epoch [14/300], Step [225/225], Training Accuracy: 58.0253%, Training Loss: 0.9530%\n",
      "Epoch [15/300], Step [1/225], Training Accuracy: 60.9375%, Training Loss: 0.9462%\n",
      "Epoch [15/300], Step [2/225], Training Accuracy: 64.0625%, Training Loss: 0.9263%\n",
      "Epoch [15/300], Step [3/225], Training Accuracy: 61.4583%, Training Loss: 0.9524%\n",
      "Epoch [15/300], Step [4/225], Training Accuracy: 63.6719%, Training Loss: 0.9041%\n",
      "Epoch [15/300], Step [5/225], Training Accuracy: 64.0625%, Training Loss: 0.8994%\n",
      "Epoch [15/300], Step [6/225], Training Accuracy: 63.5417%, Training Loss: 0.9125%\n",
      "Epoch [15/300], Step [7/225], Training Accuracy: 62.0536%, Training Loss: 0.9355%\n",
      "Epoch [15/300], Step [8/225], Training Accuracy: 61.7188%, Training Loss: 0.9320%\n",
      "Epoch [15/300], Step [9/225], Training Accuracy: 61.1111%, Training Loss: 0.9313%\n",
      "Epoch [15/300], Step [10/225], Training Accuracy: 61.2500%, Training Loss: 0.9322%\n",
      "Epoch [15/300], Step [11/225], Training Accuracy: 61.6477%, Training Loss: 0.9198%\n",
      "Epoch [15/300], Step [12/225], Training Accuracy: 61.0677%, Training Loss: 0.9287%\n",
      "Epoch [15/300], Step [13/225], Training Accuracy: 60.6971%, Training Loss: 0.9283%\n",
      "Epoch [15/300], Step [14/225], Training Accuracy: 60.2679%, Training Loss: 0.9330%\n",
      "Epoch [15/300], Step [15/225], Training Accuracy: 59.5833%, Training Loss: 0.9388%\n",
      "Epoch [15/300], Step [16/225], Training Accuracy: 58.9844%, Training Loss: 0.9493%\n",
      "Epoch [15/300], Step [17/225], Training Accuracy: 59.0993%, Training Loss: 0.9492%\n",
      "Epoch [15/300], Step [18/225], Training Accuracy: 58.6806%, Training Loss: 0.9545%\n",
      "Epoch [15/300], Step [19/225], Training Accuracy: 58.7993%, Training Loss: 0.9488%\n",
      "Epoch [15/300], Step [20/225], Training Accuracy: 59.1406%, Training Loss: 0.9440%\n",
      "Epoch [15/300], Step [21/225], Training Accuracy: 59.3750%, Training Loss: 0.9389%\n",
      "Epoch [15/300], Step [22/225], Training Accuracy: 59.3750%, Training Loss: 0.9401%\n",
      "Epoch [15/300], Step [23/225], Training Accuracy: 59.1712%, Training Loss: 0.9446%\n",
      "Epoch [15/300], Step [24/225], Training Accuracy: 59.1146%, Training Loss: 0.9452%\n",
      "Epoch [15/300], Step [25/225], Training Accuracy: 59.4375%, Training Loss: 0.9396%\n",
      "Epoch [15/300], Step [26/225], Training Accuracy: 59.1947%, Training Loss: 0.9413%\n",
      "Epoch [15/300], Step [27/225], Training Accuracy: 59.2014%, Training Loss: 0.9433%\n",
      "Epoch [15/300], Step [28/225], Training Accuracy: 59.5982%, Training Loss: 0.9385%\n",
      "Epoch [15/300], Step [29/225], Training Accuracy: 59.6444%, Training Loss: 0.9336%\n",
      "Epoch [15/300], Step [30/225], Training Accuracy: 59.4792%, Training Loss: 0.9356%\n",
      "Epoch [15/300], Step [31/225], Training Accuracy: 59.3246%, Training Loss: 0.9372%\n",
      "Epoch [15/300], Step [32/225], Training Accuracy: 59.3750%, Training Loss: 0.9349%\n",
      "Epoch [15/300], Step [33/225], Training Accuracy: 59.5644%, Training Loss: 0.9305%\n",
      "Epoch [15/300], Step [34/225], Training Accuracy: 59.3750%, Training Loss: 0.9319%\n",
      "Epoch [15/300], Step [35/225], Training Accuracy: 59.2857%, Training Loss: 0.9330%\n",
      "Epoch [15/300], Step [36/225], Training Accuracy: 59.1580%, Training Loss: 0.9334%\n",
      "Epoch [15/300], Step [37/225], Training Accuracy: 59.2905%, Training Loss: 0.9334%\n",
      "Epoch [15/300], Step [38/225], Training Accuracy: 59.4572%, Training Loss: 0.9331%\n",
      "Epoch [15/300], Step [39/225], Training Accuracy: 59.5753%, Training Loss: 0.9310%\n",
      "Epoch [15/300], Step [40/225], Training Accuracy: 59.5312%, Training Loss: 0.9286%\n",
      "Epoch [15/300], Step [41/225], Training Accuracy: 59.4893%, Training Loss: 0.9266%\n",
      "Epoch [15/300], Step [42/225], Training Accuracy: 59.6726%, Training Loss: 0.9239%\n",
      "Epoch [15/300], Step [43/225], Training Accuracy: 59.6657%, Training Loss: 0.9244%\n",
      "Epoch [15/300], Step [44/225], Training Accuracy: 59.5170%, Training Loss: 0.9261%\n",
      "Epoch [15/300], Step [45/225], Training Accuracy: 59.5486%, Training Loss: 0.9252%\n",
      "Epoch [15/300], Step [46/225], Training Accuracy: 59.6467%, Training Loss: 0.9240%\n",
      "Epoch [15/300], Step [47/225], Training Accuracy: 59.7739%, Training Loss: 0.9231%\n",
      "Epoch [15/300], Step [48/225], Training Accuracy: 59.7005%, Training Loss: 0.9247%\n",
      "Epoch [15/300], Step [49/225], Training Accuracy: 59.5663%, Training Loss: 0.9251%\n",
      "Epoch [15/300], Step [50/225], Training Accuracy: 59.5938%, Training Loss: 0.9260%\n",
      "Epoch [15/300], Step [51/225], Training Accuracy: 59.5588%, Training Loss: 0.9266%\n",
      "Epoch [15/300], Step [52/225], Training Accuracy: 59.5553%, Training Loss: 0.9254%\n",
      "Epoch [15/300], Step [53/225], Training Accuracy: 59.4929%, Training Loss: 0.9265%\n",
      "Epoch [15/300], Step [54/225], Training Accuracy: 59.3750%, Training Loss: 0.9276%\n",
      "Epoch [15/300], Step [55/225], Training Accuracy: 59.5170%, Training Loss: 0.9268%\n",
      "Epoch [15/300], Step [56/225], Training Accuracy: 59.5982%, Training Loss: 0.9260%\n",
      "Epoch [15/300], Step [57/225], Training Accuracy: 59.6491%, Training Loss: 0.9252%\n",
      "Epoch [15/300], Step [58/225], Training Accuracy: 59.5636%, Training Loss: 0.9258%\n",
      "Epoch [15/300], Step [59/225], Training Accuracy: 59.5339%, Training Loss: 0.9259%\n",
      "Epoch [15/300], Step [60/225], Training Accuracy: 59.6094%, Training Loss: 0.9247%\n",
      "Epoch [15/300], Step [61/225], Training Accuracy: 59.6568%, Training Loss: 0.9248%\n",
      "Epoch [15/300], Step [62/225], Training Accuracy: 59.6522%, Training Loss: 0.9258%\n",
      "Epoch [15/300], Step [63/225], Training Accuracy: 59.5486%, Training Loss: 0.9279%\n",
      "Epoch [15/300], Step [64/225], Training Accuracy: 59.6191%, Training Loss: 0.9280%\n",
      "Epoch [15/300], Step [65/225], Training Accuracy: 59.5913%, Training Loss: 0.9276%\n",
      "Epoch [15/300], Step [66/225], Training Accuracy: 59.6354%, Training Loss: 0.9278%\n",
      "Epoch [15/300], Step [67/225], Training Accuracy: 59.6315%, Training Loss: 0.9286%\n",
      "Epoch [15/300], Step [68/225], Training Accuracy: 59.5818%, Training Loss: 0.9289%\n",
      "Epoch [15/300], Step [69/225], Training Accuracy: 59.6694%, Training Loss: 0.9286%\n",
      "Epoch [15/300], Step [70/225], Training Accuracy: 59.7545%, Training Loss: 0.9271%\n",
      "Epoch [15/300], Step [71/225], Training Accuracy: 59.6831%, Training Loss: 0.9273%\n",
      "Epoch [15/300], Step [72/225], Training Accuracy: 59.6137%, Training Loss: 0.9286%\n",
      "Epoch [15/300], Step [73/225], Training Accuracy: 59.4606%, Training Loss: 0.9314%\n",
      "Epoch [15/300], Step [74/225], Training Accuracy: 59.5017%, Training Loss: 0.9306%\n",
      "Epoch [15/300], Step [75/225], Training Accuracy: 59.6458%, Training Loss: 0.9295%\n",
      "Epoch [15/300], Step [76/225], Training Accuracy: 59.6012%, Training Loss: 0.9304%\n",
      "Epoch [15/300], Step [77/225], Training Accuracy: 59.5373%, Training Loss: 0.9317%\n",
      "Epoch [15/300], Step [78/225], Training Accuracy: 59.5553%, Training Loss: 0.9304%\n",
      "Epoch [15/300], Step [79/225], Training Accuracy: 59.5926%, Training Loss: 0.9313%\n",
      "Epoch [15/300], Step [80/225], Training Accuracy: 59.3945%, Training Loss: 0.9335%\n",
      "Epoch [15/300], Step [81/225], Training Accuracy: 59.4329%, Training Loss: 0.9331%\n",
      "Epoch [15/300], Step [82/225], Training Accuracy: 59.4512%, Training Loss: 0.9335%\n",
      "Epoch [15/300], Step [83/225], Training Accuracy: 59.5068%, Training Loss: 0.9327%\n",
      "Epoch [15/300], Step [84/225], Training Accuracy: 59.5238%, Training Loss: 0.9322%\n",
      "Epoch [15/300], Step [85/225], Training Accuracy: 59.5404%, Training Loss: 0.9327%\n",
      "Epoch [15/300], Step [86/225], Training Accuracy: 59.5567%, Training Loss: 0.9310%\n",
      "Epoch [15/300], Step [87/225], Training Accuracy: 59.6085%, Training Loss: 0.9302%\n",
      "Epoch [15/300], Step [88/225], Training Accuracy: 59.6413%, Training Loss: 0.9294%\n",
      "Epoch [15/300], Step [89/225], Training Accuracy: 59.7261%, Training Loss: 0.9276%\n",
      "Epoch [15/300], Step [90/225], Training Accuracy: 59.7049%, Training Loss: 0.9279%\n",
      "Epoch [15/300], Step [91/225], Training Accuracy: 59.7356%, Training Loss: 0.9271%\n",
      "Epoch [15/300], Step [92/225], Training Accuracy: 59.6637%, Training Loss: 0.9274%\n",
      "Epoch [15/300], Step [93/225], Training Accuracy: 59.6270%, Training Loss: 0.9277%\n",
      "Epoch [15/300], Step [94/225], Training Accuracy: 59.6576%, Training Loss: 0.9266%\n",
      "Epoch [15/300], Step [95/225], Training Accuracy: 59.6711%, Training Loss: 0.9263%\n",
      "Epoch [15/300], Step [96/225], Training Accuracy: 59.7819%, Training Loss: 0.9246%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/300], Step [97/225], Training Accuracy: 59.7777%, Training Loss: 0.9251%\n",
      "Epoch [15/300], Step [98/225], Training Accuracy: 59.8533%, Training Loss: 0.9239%\n",
      "Epoch [15/300], Step [99/225], Training Accuracy: 59.9432%, Training Loss: 0.9235%\n",
      "Epoch [15/300], Step [100/225], Training Accuracy: 59.9062%, Training Loss: 0.9242%\n",
      "Epoch [15/300], Step [101/225], Training Accuracy: 59.8546%, Training Loss: 0.9254%\n",
      "Epoch [15/300], Step [102/225], Training Accuracy: 59.7580%, Training Loss: 0.9262%\n",
      "Epoch [15/300], Step [103/225], Training Accuracy: 59.7694%, Training Loss: 0.9264%\n",
      "Epoch [15/300], Step [104/225], Training Accuracy: 59.6905%, Training Loss: 0.9268%\n",
      "Epoch [15/300], Step [105/225], Training Accuracy: 59.7173%, Training Loss: 0.9271%\n",
      "Epoch [15/300], Step [106/225], Training Accuracy: 59.7140%, Training Loss: 0.9273%\n",
      "Epoch [15/300], Step [107/225], Training Accuracy: 59.6963%, Training Loss: 0.9270%\n",
      "Epoch [15/300], Step [108/225], Training Accuracy: 59.6644%, Training Loss: 0.9275%\n",
      "Epoch [15/300], Step [109/225], Training Accuracy: 59.7047%, Training Loss: 0.9278%\n",
      "Epoch [15/300], Step [110/225], Training Accuracy: 59.6733%, Training Loss: 0.9269%\n",
      "Epoch [15/300], Step [111/225], Training Accuracy: 59.7410%, Training Loss: 0.9258%\n",
      "Epoch [15/300], Step [112/225], Training Accuracy: 59.8214%, Training Loss: 0.9251%\n",
      "Epoch [15/300], Step [113/225], Training Accuracy: 59.8175%, Training Loss: 0.9260%\n",
      "Epoch [15/300], Step [114/225], Training Accuracy: 59.8136%, Training Loss: 0.9258%\n",
      "Epoch [15/300], Step [115/225], Training Accuracy: 59.7554%, Training Loss: 0.9267%\n",
      "Epoch [15/300], Step [116/225], Training Accuracy: 59.7656%, Training Loss: 0.9267%\n",
      "Epoch [15/300], Step [117/225], Training Accuracy: 59.7489%, Training Loss: 0.9269%\n",
      "Epoch [15/300], Step [118/225], Training Accuracy: 59.6796%, Training Loss: 0.9276%\n",
      "Epoch [15/300], Step [119/225], Training Accuracy: 59.6901%, Training Loss: 0.9279%\n",
      "Epoch [15/300], Step [120/225], Training Accuracy: 59.7526%, Training Loss: 0.9274%\n",
      "Epoch [15/300], Step [121/225], Training Accuracy: 59.7366%, Training Loss: 0.9273%\n",
      "Epoch [15/300], Step [122/225], Training Accuracy: 59.7720%, Training Loss: 0.9271%\n",
      "Epoch [15/300], Step [123/225], Training Accuracy: 59.7561%, Training Loss: 0.9269%\n",
      "Epoch [15/300], Step [124/225], Training Accuracy: 59.8412%, Training Loss: 0.9260%\n",
      "Epoch [15/300], Step [125/225], Training Accuracy: 59.9000%, Training Loss: 0.9253%\n",
      "Epoch [15/300], Step [126/225], Training Accuracy: 59.9330%, Training Loss: 0.9251%\n",
      "Epoch [15/300], Step [127/225], Training Accuracy: 59.9656%, Training Loss: 0.9248%\n",
      "Epoch [15/300], Step [128/225], Training Accuracy: 59.8755%, Training Loss: 0.9262%\n",
      "Epoch [15/300], Step [129/225], Training Accuracy: 59.9443%, Training Loss: 0.9249%\n",
      "Epoch [15/300], Step [130/225], Training Accuracy: 59.9639%, Training Loss: 0.9250%\n",
      "Epoch [15/300], Step [131/225], Training Accuracy: 59.9714%, Training Loss: 0.9252%\n",
      "Epoch [15/300], Step [132/225], Training Accuracy: 59.8840%, Training Loss: 0.9268%\n",
      "Epoch [15/300], Step [133/225], Training Accuracy: 60.0094%, Training Loss: 0.9252%\n",
      "Epoch [15/300], Step [134/225], Training Accuracy: 59.9230%, Training Loss: 0.9261%\n",
      "Epoch [15/300], Step [135/225], Training Accuracy: 59.9653%, Training Loss: 0.9250%\n",
      "Epoch [15/300], Step [136/225], Training Accuracy: 59.9150%, Training Loss: 0.9255%\n",
      "Epoch [15/300], Step [137/225], Training Accuracy: 59.9339%, Training Loss: 0.9250%\n",
      "Epoch [15/300], Step [138/225], Training Accuracy: 59.9524%, Training Loss: 0.9245%\n",
      "Epoch [15/300], Step [139/225], Training Accuracy: 59.9371%, Training Loss: 0.9245%\n",
      "Epoch [15/300], Step [140/225], Training Accuracy: 60.0112%, Training Loss: 0.9240%\n",
      "Epoch [15/300], Step [141/225], Training Accuracy: 60.0066%, Training Loss: 0.9244%\n",
      "Epoch [15/300], Step [142/225], Training Accuracy: 60.0022%, Training Loss: 0.9239%\n",
      "Epoch [15/300], Step [143/225], Training Accuracy: 59.9869%, Training Loss: 0.9240%\n",
      "Epoch [15/300], Step [144/225], Training Accuracy: 60.0152%, Training Loss: 0.9233%\n",
      "Epoch [15/300], Step [145/225], Training Accuracy: 60.0539%, Training Loss: 0.9230%\n",
      "Epoch [15/300], Step [146/225], Training Accuracy: 60.0278%, Training Loss: 0.9227%\n",
      "Epoch [15/300], Step [147/225], Training Accuracy: 60.0128%, Training Loss: 0.9235%\n",
      "Epoch [15/300], Step [148/225], Training Accuracy: 60.0718%, Training Loss: 0.9228%\n",
      "Epoch [15/300], Step [149/225], Training Accuracy: 60.0776%, Training Loss: 0.9229%\n",
      "Epoch [15/300], Step [150/225], Training Accuracy: 60.1250%, Training Loss: 0.9218%\n",
      "Epoch [15/300], Step [151/225], Training Accuracy: 60.1614%, Training Loss: 0.9213%\n",
      "Epoch [15/300], Step [152/225], Training Accuracy: 60.1562%, Training Loss: 0.9211%\n",
      "Epoch [15/300], Step [153/225], Training Accuracy: 60.1920%, Training Loss: 0.9204%\n",
      "Epoch [15/300], Step [154/225], Training Accuracy: 60.2374%, Training Loss: 0.9201%\n",
      "Epoch [15/300], Step [155/225], Training Accuracy: 60.2621%, Training Loss: 0.9197%\n",
      "Epoch [15/300], Step [156/225], Training Accuracy: 60.2865%, Training Loss: 0.9197%\n",
      "Epoch [15/300], Step [157/225], Training Accuracy: 60.3105%, Training Loss: 0.9193%\n",
      "Epoch [15/300], Step [158/225], Training Accuracy: 60.2848%, Training Loss: 0.9192%\n",
      "Epoch [15/300], Step [159/225], Training Accuracy: 60.2987%, Training Loss: 0.9191%\n",
      "Epoch [15/300], Step [160/225], Training Accuracy: 60.2734%, Training Loss: 0.9193%\n",
      "Epoch [15/300], Step [161/225], Training Accuracy: 60.2679%, Training Loss: 0.9189%\n",
      "Epoch [15/300], Step [162/225], Training Accuracy: 60.2527%, Training Loss: 0.9188%\n",
      "Epoch [15/300], Step [163/225], Training Accuracy: 60.3240%, Training Loss: 0.9177%\n",
      "Epoch [15/300], Step [164/225], Training Accuracy: 60.3849%, Training Loss: 0.9167%\n",
      "Epoch [15/300], Step [165/225], Training Accuracy: 60.4167%, Training Loss: 0.9165%\n",
      "Epoch [15/300], Step [166/225], Training Accuracy: 60.4010%, Training Loss: 0.9162%\n",
      "Epoch [15/300], Step [167/225], Training Accuracy: 60.4042%, Training Loss: 0.9161%\n",
      "Epoch [15/300], Step [168/225], Training Accuracy: 60.4353%, Training Loss: 0.9160%\n",
      "Epoch [15/300], Step [169/225], Training Accuracy: 60.4105%, Training Loss: 0.9160%\n",
      "Epoch [15/300], Step [170/225], Training Accuracy: 60.3768%, Training Loss: 0.9160%\n",
      "Epoch [15/300], Step [171/225], Training Accuracy: 60.3801%, Training Loss: 0.9160%\n",
      "Epoch [15/300], Step [172/225], Training Accuracy: 60.3834%, Training Loss: 0.9157%\n",
      "Epoch [15/300], Step [173/225], Training Accuracy: 60.3595%, Training Loss: 0.9159%\n",
      "Epoch [15/300], Step [174/225], Training Accuracy: 60.3718%, Training Loss: 0.9157%\n",
      "Epoch [15/300], Step [175/225], Training Accuracy: 60.4196%, Training Loss: 0.9149%\n",
      "Epoch [15/300], Step [176/225], Training Accuracy: 60.4403%, Training Loss: 0.9146%\n",
      "Epoch [15/300], Step [177/225], Training Accuracy: 60.4520%, Training Loss: 0.9144%\n",
      "Epoch [15/300], Step [178/225], Training Accuracy: 60.4371%, Training Loss: 0.9146%\n",
      "Epoch [15/300], Step [179/225], Training Accuracy: 60.4312%, Training Loss: 0.9145%\n",
      "Epoch [15/300], Step [180/225], Training Accuracy: 60.4080%, Training Loss: 0.9145%\n",
      "Epoch [15/300], Step [181/225], Training Accuracy: 60.3591%, Training Loss: 0.9155%\n",
      "Epoch [15/300], Step [182/225], Training Accuracy: 60.3623%, Training Loss: 0.9155%\n",
      "Epoch [15/300], Step [183/225], Training Accuracy: 60.3654%, Training Loss: 0.9150%\n",
      "Epoch [15/300], Step [184/225], Training Accuracy: 60.3091%, Training Loss: 0.9154%\n",
      "Epoch [15/300], Step [185/225], Training Accuracy: 60.2703%, Training Loss: 0.9154%\n",
      "Epoch [15/300], Step [186/225], Training Accuracy: 60.3243%, Training Loss: 0.9149%\n",
      "Epoch [15/300], Step [187/225], Training Accuracy: 60.3275%, Training Loss: 0.9146%\n",
      "Epoch [15/300], Step [188/225], Training Accuracy: 60.3142%, Training Loss: 0.9148%\n",
      "Epoch [15/300], Step [189/225], Training Accuracy: 60.3423%, Training Loss: 0.9141%\n",
      "Epoch [15/300], Step [190/225], Training Accuracy: 60.3783%, Training Loss: 0.9137%\n",
      "Epoch [15/300], Step [191/225], Training Accuracy: 60.3812%, Training Loss: 0.9137%\n",
      "Epoch [15/300], Step [192/225], Training Accuracy: 60.2946%, Training Loss: 0.9145%\n",
      "Epoch [15/300], Step [193/225], Training Accuracy: 60.2494%, Training Loss: 0.9149%\n",
      "Epoch [15/300], Step [194/225], Training Accuracy: 60.2932%, Training Loss: 0.9143%\n",
      "Epoch [15/300], Step [195/225], Training Accuracy: 60.2564%, Training Loss: 0.9142%\n",
      "Epoch [15/300], Step [196/225], Training Accuracy: 60.3237%, Training Loss: 0.9134%\n",
      "Epoch [15/300], Step [197/225], Training Accuracy: 60.3188%, Training Loss: 0.9138%\n",
      "Epoch [15/300], Step [198/225], Training Accuracy: 60.3378%, Training Loss: 0.9133%\n",
      "Epoch [15/300], Step [199/225], Training Accuracy: 60.3172%, Training Loss: 0.9137%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/300], Step [200/225], Training Accuracy: 60.3516%, Training Loss: 0.9133%\n",
      "Epoch [15/300], Step [201/225], Training Accuracy: 60.3467%, Training Loss: 0.9127%\n",
      "Epoch [15/300], Step [202/225], Training Accuracy: 60.3419%, Training Loss: 0.9124%\n",
      "Epoch [15/300], Step [203/225], Training Accuracy: 60.3602%, Training Loss: 0.9123%\n",
      "Epoch [15/300], Step [204/225], Training Accuracy: 60.3707%, Training Loss: 0.9120%\n",
      "Epoch [15/300], Step [205/225], Training Accuracy: 60.3735%, Training Loss: 0.9120%\n",
      "Epoch [15/300], Step [206/225], Training Accuracy: 60.3762%, Training Loss: 0.9122%\n",
      "Epoch [15/300], Step [207/225], Training Accuracy: 60.4393%, Training Loss: 0.9111%\n",
      "Epoch [15/300], Step [208/225], Training Accuracy: 60.4793%, Training Loss: 0.9107%\n",
      "Epoch [15/300], Step [209/225], Training Accuracy: 60.4740%, Training Loss: 0.9106%\n",
      "Epoch [15/300], Step [210/225], Training Accuracy: 60.4167%, Training Loss: 0.9111%\n",
      "Epoch [15/300], Step [211/225], Training Accuracy: 60.4117%, Training Loss: 0.9109%\n",
      "Epoch [15/300], Step [212/225], Training Accuracy: 60.3921%, Training Loss: 0.9116%\n",
      "Epoch [15/300], Step [213/225], Training Accuracy: 60.3800%, Training Loss: 0.9117%\n",
      "Epoch [15/300], Step [214/225], Training Accuracy: 60.3753%, Training Loss: 0.9123%\n",
      "Epoch [15/300], Step [215/225], Training Accuracy: 60.4142%, Training Loss: 0.9117%\n",
      "Epoch [15/300], Step [216/225], Training Accuracy: 60.3805%, Training Loss: 0.9123%\n",
      "Epoch [15/300], Step [217/225], Training Accuracy: 60.4191%, Training Loss: 0.9115%\n",
      "Epoch [15/300], Step [218/225], Training Accuracy: 60.3856%, Training Loss: 0.9120%\n",
      "Epoch [15/300], Step [219/225], Training Accuracy: 60.3881%, Training Loss: 0.9115%\n",
      "Epoch [15/300], Step [220/225], Training Accuracy: 60.3977%, Training Loss: 0.9113%\n",
      "Epoch [15/300], Step [221/225], Training Accuracy: 60.4072%, Training Loss: 0.9116%\n",
      "Epoch [15/300], Step [222/225], Training Accuracy: 60.3885%, Training Loss: 0.9117%\n",
      "Epoch [15/300], Step [223/225], Training Accuracy: 60.3770%, Training Loss: 0.9116%\n",
      "Epoch [15/300], Step [224/225], Training Accuracy: 60.3725%, Training Loss: 0.9112%\n",
      "Epoch [15/300], Step [225/225], Training Accuracy: 60.3530%, Training Loss: 0.9112%\n",
      "Epoch [16/300], Step [1/225], Training Accuracy: 64.0625%, Training Loss: 0.9230%\n",
      "Epoch [16/300], Step [2/225], Training Accuracy: 67.1875%, Training Loss: 0.8650%\n",
      "Epoch [16/300], Step [3/225], Training Accuracy: 63.5417%, Training Loss: 0.9434%\n",
      "Epoch [16/300], Step [4/225], Training Accuracy: 67.1875%, Training Loss: 0.8746%\n",
      "Epoch [16/300], Step [5/225], Training Accuracy: 65.0000%, Training Loss: 0.8788%\n",
      "Epoch [16/300], Step [6/225], Training Accuracy: 63.2812%, Training Loss: 0.8947%\n",
      "Epoch [16/300], Step [7/225], Training Accuracy: 62.0536%, Training Loss: 0.9284%\n",
      "Epoch [16/300], Step [8/225], Training Accuracy: 62.3047%, Training Loss: 0.9134%\n",
      "Epoch [16/300], Step [9/225], Training Accuracy: 62.1528%, Training Loss: 0.9125%\n",
      "Epoch [16/300], Step [10/225], Training Accuracy: 62.1875%, Training Loss: 0.9202%\n",
      "Epoch [16/300], Step [11/225], Training Accuracy: 61.9318%, Training Loss: 0.9090%\n",
      "Epoch [16/300], Step [12/225], Training Accuracy: 61.8490%, Training Loss: 0.9124%\n",
      "Epoch [16/300], Step [13/225], Training Accuracy: 61.0577%, Training Loss: 0.9147%\n",
      "Epoch [16/300], Step [14/225], Training Accuracy: 60.4911%, Training Loss: 0.9208%\n",
      "Epoch [16/300], Step [15/225], Training Accuracy: 60.0000%, Training Loss: 0.9240%\n",
      "Epoch [16/300], Step [16/225], Training Accuracy: 59.2773%, Training Loss: 0.9287%\n",
      "Epoch [16/300], Step [17/225], Training Accuracy: 59.2831%, Training Loss: 0.9309%\n",
      "Epoch [16/300], Step [18/225], Training Accuracy: 59.4618%, Training Loss: 0.9303%\n",
      "Epoch [16/300], Step [19/225], Training Accuracy: 59.7039%, Training Loss: 0.9245%\n",
      "Epoch [16/300], Step [20/225], Training Accuracy: 59.8438%, Training Loss: 0.9212%\n",
      "Epoch [16/300], Step [21/225], Training Accuracy: 60.5655%, Training Loss: 0.9147%\n",
      "Epoch [16/300], Step [22/225], Training Accuracy: 60.3693%, Training Loss: 0.9147%\n",
      "Epoch [16/300], Step [23/225], Training Accuracy: 60.1902%, Training Loss: 0.9160%\n",
      "Epoch [16/300], Step [24/225], Training Accuracy: 59.5703%, Training Loss: 0.9234%\n",
      "Epoch [16/300], Step [25/225], Training Accuracy: 59.8750%, Training Loss: 0.9199%\n",
      "Epoch [16/300], Step [26/225], Training Accuracy: 59.9159%, Training Loss: 0.9197%\n",
      "Epoch [16/300], Step [27/225], Training Accuracy: 60.0694%, Training Loss: 0.9175%\n",
      "Epoch [16/300], Step [28/225], Training Accuracy: 60.1004%, Training Loss: 0.9129%\n",
      "Epoch [16/300], Step [29/225], Training Accuracy: 60.3448%, Training Loss: 0.9087%\n",
      "Epoch [16/300], Step [30/225], Training Accuracy: 60.3646%, Training Loss: 0.9082%\n",
      "Epoch [16/300], Step [31/225], Training Accuracy: 60.2319%, Training Loss: 0.9118%\n",
      "Epoch [16/300], Step [32/225], Training Accuracy: 60.5469%, Training Loss: 0.9090%\n",
      "Epoch [16/300], Step [33/225], Training Accuracy: 60.7481%, Training Loss: 0.9040%\n",
      "Epoch [16/300], Step [34/225], Training Accuracy: 60.5239%, Training Loss: 0.9060%\n",
      "Epoch [16/300], Step [35/225], Training Accuracy: 60.6250%, Training Loss: 0.9069%\n",
      "Epoch [16/300], Step [36/225], Training Accuracy: 60.4601%, Training Loss: 0.9082%\n",
      "Epoch [16/300], Step [37/225], Training Accuracy: 60.4307%, Training Loss: 0.9076%\n",
      "Epoch [16/300], Step [38/225], Training Accuracy: 60.5674%, Training Loss: 0.9061%\n",
      "Epoch [16/300], Step [39/225], Training Accuracy: 60.7372%, Training Loss: 0.9044%\n",
      "Epoch [16/300], Step [40/225], Training Accuracy: 60.6641%, Training Loss: 0.9046%\n",
      "Epoch [16/300], Step [41/225], Training Accuracy: 60.8613%, Training Loss: 0.9012%\n",
      "Epoch [16/300], Step [42/225], Training Accuracy: 60.9375%, Training Loss: 0.8985%\n",
      "Epoch [16/300], Step [43/225], Training Accuracy: 61.1192%, Training Loss: 0.8967%\n",
      "Epoch [16/300], Step [44/225], Training Accuracy: 60.9730%, Training Loss: 0.8986%\n",
      "Epoch [16/300], Step [45/225], Training Accuracy: 61.1111%, Training Loss: 0.8975%\n",
      "Epoch [16/300], Step [46/225], Training Accuracy: 61.2432%, Training Loss: 0.8953%\n",
      "Epoch [16/300], Step [47/225], Training Accuracy: 61.4029%, Training Loss: 0.8944%\n",
      "Epoch [16/300], Step [48/225], Training Accuracy: 61.2956%, Training Loss: 0.8969%\n",
      "Epoch [16/300], Step [49/225], Training Accuracy: 61.3520%, Training Loss: 0.8965%\n",
      "Epoch [16/300], Step [50/225], Training Accuracy: 61.4062%, Training Loss: 0.8962%\n",
      "Epoch [16/300], Step [51/225], Training Accuracy: 61.4583%, Training Loss: 0.8953%\n",
      "Epoch [16/300], Step [52/225], Training Accuracy: 61.5385%, Training Loss: 0.8937%\n",
      "Epoch [16/300], Step [53/225], Training Accuracy: 61.4682%, Training Loss: 0.8951%\n",
      "Epoch [16/300], Step [54/225], Training Accuracy: 61.3426%, Training Loss: 0.8964%\n",
      "Epoch [16/300], Step [55/225], Training Accuracy: 61.5341%, Training Loss: 0.8939%\n",
      "Epoch [16/300], Step [56/225], Training Accuracy: 61.5234%, Training Loss: 0.8931%\n",
      "Epoch [16/300], Step [57/225], Training Accuracy: 61.5132%, Training Loss: 0.8936%\n",
      "Epoch [16/300], Step [58/225], Training Accuracy: 61.3147%, Training Loss: 0.8957%\n",
      "Epoch [16/300], Step [59/225], Training Accuracy: 61.2288%, Training Loss: 0.8963%\n",
      "Epoch [16/300], Step [60/225], Training Accuracy: 61.2240%, Training Loss: 0.8951%\n",
      "Epoch [16/300], Step [61/225], Training Accuracy: 61.2961%, Training Loss: 0.8952%\n",
      "Epoch [16/300], Step [62/225], Training Accuracy: 61.1643%, Training Loss: 0.8968%\n",
      "Epoch [16/300], Step [63/225], Training Accuracy: 61.0119%, Training Loss: 0.8991%\n",
      "Epoch [16/300], Step [64/225], Training Accuracy: 61.1328%, Training Loss: 0.8980%\n",
      "Epoch [16/300], Step [65/225], Training Accuracy: 61.0577%, Training Loss: 0.8968%\n",
      "Epoch [16/300], Step [66/225], Training Accuracy: 61.0795%, Training Loss: 0.8960%\n",
      "Epoch [16/300], Step [67/225], Training Accuracy: 61.0774%, Training Loss: 0.8969%\n",
      "Epoch [16/300], Step [68/225], Training Accuracy: 61.0754%, Training Loss: 0.8965%\n",
      "Epoch [16/300], Step [69/225], Training Accuracy: 61.1413%, Training Loss: 0.8952%\n",
      "Epoch [16/300], Step [70/225], Training Accuracy: 61.2500%, Training Loss: 0.8946%\n",
      "Epoch [16/300], Step [71/225], Training Accuracy: 61.2016%, Training Loss: 0.8939%\n",
      "Epoch [16/300], Step [72/225], Training Accuracy: 61.1979%, Training Loss: 0.8942%\n",
      "Epoch [16/300], Step [73/225], Training Accuracy: 61.0873%, Training Loss: 0.8965%\n",
      "Epoch [16/300], Step [74/225], Training Accuracy: 61.0642%, Training Loss: 0.8956%\n",
      "Epoch [16/300], Step [75/225], Training Accuracy: 61.2083%, Training Loss: 0.8937%\n",
      "Epoch [16/300], Step [76/225], Training Accuracy: 61.2459%, Training Loss: 0.8932%\n",
      "Epoch [16/300], Step [77/225], Training Accuracy: 61.2419%, Training Loss: 0.8932%\n",
      "Epoch [16/300], Step [78/225], Training Accuracy: 61.2780%, Training Loss: 0.8923%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/300], Step [79/225], Training Accuracy: 61.2540%, Training Loss: 0.8931%\n",
      "Epoch [16/300], Step [80/225], Training Accuracy: 61.0547%, Training Loss: 0.8956%\n",
      "Epoch [16/300], Step [81/225], Training Accuracy: 61.1304%, Training Loss: 0.8942%\n",
      "Epoch [16/300], Step [82/225], Training Accuracy: 61.1662%, Training Loss: 0.8941%\n",
      "Epoch [16/300], Step [83/225], Training Accuracy: 61.2199%, Training Loss: 0.8938%\n",
      "Epoch [16/300], Step [84/225], Training Accuracy: 61.1793%, Training Loss: 0.8940%\n",
      "Epoch [16/300], Step [85/225], Training Accuracy: 61.1949%, Training Loss: 0.8946%\n",
      "Epoch [16/300], Step [86/225], Training Accuracy: 61.3009%, Training Loss: 0.8929%\n",
      "Epoch [16/300], Step [87/225], Training Accuracy: 61.3865%, Training Loss: 0.8917%\n",
      "Epoch [16/300], Step [88/225], Training Accuracy: 61.4169%, Training Loss: 0.8904%\n",
      "Epoch [16/300], Step [89/225], Training Accuracy: 61.4115%, Training Loss: 0.8890%\n",
      "Epoch [16/300], Step [90/225], Training Accuracy: 61.4062%, Training Loss: 0.8893%\n",
      "Epoch [16/300], Step [91/225], Training Accuracy: 61.4354%, Training Loss: 0.8884%\n",
      "Epoch [16/300], Step [92/225], Training Accuracy: 61.3451%, Training Loss: 0.8898%\n",
      "Epoch [16/300], Step [93/225], Training Accuracy: 61.2903%, Training Loss: 0.8906%\n",
      "Epoch [16/300], Step [94/225], Training Accuracy: 61.3531%, Training Loss: 0.8893%\n",
      "Epoch [16/300], Step [95/225], Training Accuracy: 61.3651%, Training Loss: 0.8892%\n",
      "Epoch [16/300], Step [96/225], Training Accuracy: 61.3932%, Training Loss: 0.8882%\n",
      "Epoch [16/300], Step [97/225], Training Accuracy: 61.3563%, Training Loss: 0.8884%\n",
      "Epoch [16/300], Step [98/225], Training Accuracy: 61.4318%, Training Loss: 0.8874%\n",
      "Epoch [16/300], Step [99/225], Training Accuracy: 61.3794%, Training Loss: 0.8879%\n",
      "Epoch [16/300], Step [100/225], Training Accuracy: 61.3750%, Training Loss: 0.8885%\n",
      "Epoch [16/300], Step [101/225], Training Accuracy: 61.3397%, Training Loss: 0.8890%\n",
      "Epoch [16/300], Step [102/225], Training Accuracy: 61.3205%, Training Loss: 0.8891%\n",
      "Epoch [16/300], Step [103/225], Training Accuracy: 61.2409%, Training Loss: 0.8897%\n",
      "Epoch [16/300], Step [104/225], Training Accuracy: 61.2230%, Training Loss: 0.8903%\n",
      "Epoch [16/300], Step [105/225], Training Accuracy: 61.2054%, Training Loss: 0.8906%\n",
      "Epoch [16/300], Step [106/225], Training Accuracy: 61.2323%, Training Loss: 0.8906%\n",
      "Epoch [16/300], Step [107/225], Training Accuracy: 61.2004%, Training Loss: 0.8902%\n",
      "Epoch [16/300], Step [108/225], Training Accuracy: 61.1690%, Training Loss: 0.8908%\n",
      "Epoch [16/300], Step [109/225], Training Accuracy: 61.0952%, Training Loss: 0.8916%\n",
      "Epoch [16/300], Step [110/225], Training Accuracy: 61.1222%, Training Loss: 0.8906%\n",
      "Epoch [16/300], Step [111/225], Training Accuracy: 61.1346%, Training Loss: 0.8903%\n",
      "Epoch [16/300], Step [112/225], Training Accuracy: 61.2584%, Training Loss: 0.8893%\n",
      "Epoch [16/300], Step [113/225], Training Accuracy: 61.1587%, Training Loss: 0.8906%\n",
      "Epoch [16/300], Step [114/225], Training Accuracy: 61.1842%, Training Loss: 0.8903%\n",
      "Epoch [16/300], Step [115/225], Training Accuracy: 61.1821%, Training Loss: 0.8911%\n",
      "Epoch [16/300], Step [116/225], Training Accuracy: 61.1800%, Training Loss: 0.8916%\n",
      "Epoch [16/300], Step [117/225], Training Accuracy: 61.1645%, Training Loss: 0.8915%\n",
      "Epoch [16/300], Step [118/225], Training Accuracy: 61.0964%, Training Loss: 0.8928%\n",
      "Epoch [16/300], Step [119/225], Training Accuracy: 61.0819%, Training Loss: 0.8934%\n",
      "Epoch [16/300], Step [120/225], Training Accuracy: 61.1068%, Training Loss: 0.8937%\n",
      "Epoch [16/300], Step [121/225], Training Accuracy: 61.1441%, Training Loss: 0.8938%\n",
      "Epoch [16/300], Step [122/225], Training Accuracy: 61.1040%, Training Loss: 0.8942%\n",
      "Epoch [16/300], Step [123/225], Training Accuracy: 61.0899%, Training Loss: 0.8944%\n",
      "Epoch [16/300], Step [124/225], Training Accuracy: 61.1265%, Training Loss: 0.8940%\n",
      "Epoch [16/300], Step [125/225], Training Accuracy: 61.1500%, Training Loss: 0.8934%\n",
      "Epoch [16/300], Step [126/225], Training Accuracy: 61.1359%, Training Loss: 0.8934%\n",
      "Epoch [16/300], Step [127/225], Training Accuracy: 61.1713%, Training Loss: 0.8933%\n",
      "Epoch [16/300], Step [128/225], Training Accuracy: 61.0840%, Training Loss: 0.8935%\n",
      "Epoch [16/300], Step [129/225], Training Accuracy: 61.1434%, Training Loss: 0.8927%\n",
      "Epoch [16/300], Step [130/225], Training Accuracy: 61.1178%, Training Loss: 0.8926%\n",
      "Epoch [16/300], Step [131/225], Training Accuracy: 61.1880%, Training Loss: 0.8927%\n",
      "Epoch [16/300], Step [132/225], Training Accuracy: 61.1861%, Training Loss: 0.8932%\n",
      "Epoch [16/300], Step [133/225], Training Accuracy: 61.2312%, Training Loss: 0.8918%\n",
      "Epoch [16/300], Step [134/225], Training Accuracy: 61.2640%, Training Loss: 0.8920%\n",
      "Epoch [16/300], Step [135/225], Training Accuracy: 61.2963%, Training Loss: 0.8909%\n",
      "Epoch [16/300], Step [136/225], Training Accuracy: 61.3626%, Training Loss: 0.8909%\n",
      "Epoch [16/300], Step [137/225], Training Accuracy: 61.3367%, Training Loss: 0.8908%\n",
      "Epoch [16/300], Step [138/225], Training Accuracy: 61.3791%, Training Loss: 0.8902%\n",
      "Epoch [16/300], Step [139/225], Training Accuracy: 61.3984%, Training Loss: 0.8901%\n",
      "Epoch [16/300], Step [140/225], Training Accuracy: 61.4732%, Training Loss: 0.8897%\n",
      "Epoch [16/300], Step [141/225], Training Accuracy: 61.5027%, Training Loss: 0.8899%\n",
      "Epoch [16/300], Step [142/225], Training Accuracy: 61.4657%, Training Loss: 0.8901%\n",
      "Epoch [16/300], Step [143/225], Training Accuracy: 61.4729%, Training Loss: 0.8901%\n",
      "Epoch [16/300], Step [144/225], Training Accuracy: 61.5234%, Training Loss: 0.8897%\n",
      "Epoch [16/300], Step [145/225], Training Accuracy: 61.5194%, Training Loss: 0.8897%\n",
      "Epoch [16/300], Step [146/225], Training Accuracy: 61.5154%, Training Loss: 0.8894%\n",
      "Epoch [16/300], Step [147/225], Training Accuracy: 61.4477%, Training Loss: 0.8906%\n",
      "Epoch [16/300], Step [148/225], Training Accuracy: 61.4759%, Training Loss: 0.8898%\n",
      "Epoch [16/300], Step [149/225], Training Accuracy: 61.5143%, Training Loss: 0.8896%\n",
      "Epoch [16/300], Step [150/225], Training Accuracy: 61.5417%, Training Loss: 0.8885%\n",
      "Epoch [16/300], Step [151/225], Training Accuracy: 61.5894%, Training Loss: 0.8874%\n",
      "Epoch [16/300], Step [152/225], Training Accuracy: 61.5748%, Training Loss: 0.8875%\n",
      "Epoch [16/300], Step [153/225], Training Accuracy: 61.6728%, Training Loss: 0.8864%\n",
      "Epoch [16/300], Step [154/225], Training Accuracy: 61.6680%, Training Loss: 0.8865%\n",
      "Epoch [16/300], Step [155/225], Training Accuracy: 61.6935%, Training Loss: 0.8859%\n",
      "Epoch [16/300], Step [156/225], Training Accuracy: 61.7087%, Training Loss: 0.8861%\n",
      "Epoch [16/300], Step [157/225], Training Accuracy: 61.7237%, Training Loss: 0.8855%\n",
      "Epoch [16/300], Step [158/225], Training Accuracy: 61.7583%, Training Loss: 0.8853%\n",
      "Epoch [16/300], Step [159/225], Training Accuracy: 61.8219%, Training Loss: 0.8846%\n",
      "Epoch [16/300], Step [160/225], Training Accuracy: 61.7773%, Training Loss: 0.8848%\n",
      "Epoch [16/300], Step [161/225], Training Accuracy: 61.7430%, Training Loss: 0.8852%\n",
      "Epoch [16/300], Step [162/225], Training Accuracy: 61.7380%, Training Loss: 0.8851%\n",
      "Epoch [16/300], Step [163/225], Training Accuracy: 61.7715%, Training Loss: 0.8842%\n",
      "Epoch [16/300], Step [164/225], Training Accuracy: 61.8140%, Training Loss: 0.8836%\n",
      "Epoch [16/300], Step [165/225], Training Accuracy: 61.8182%, Training Loss: 0.8834%\n",
      "Epoch [16/300], Step [166/225], Training Accuracy: 61.8317%, Training Loss: 0.8833%\n",
      "Epoch [16/300], Step [167/225], Training Accuracy: 61.8731%, Training Loss: 0.8824%\n",
      "Epoch [16/300], Step [168/225], Training Accuracy: 61.8676%, Training Loss: 0.8826%\n",
      "Epoch [16/300], Step [169/225], Training Accuracy: 61.8436%, Training Loss: 0.8832%\n",
      "Epoch [16/300], Step [170/225], Training Accuracy: 61.8658%, Training Loss: 0.8828%\n",
      "Epoch [16/300], Step [171/225], Training Accuracy: 61.9335%, Training Loss: 0.8822%\n",
      "Epoch [16/300], Step [172/225], Training Accuracy: 61.9640%, Training Loss: 0.8814%\n",
      "Epoch [16/300], Step [173/225], Training Accuracy: 61.9039%, Training Loss: 0.8821%\n",
      "Epoch [16/300], Step [174/225], Training Accuracy: 61.8983%, Training Loss: 0.8821%\n",
      "Epoch [16/300], Step [175/225], Training Accuracy: 61.9375%, Training Loss: 0.8814%\n",
      "Epoch [16/300], Step [176/225], Training Accuracy: 61.9585%, Training Loss: 0.8813%\n",
      "Epoch [16/300], Step [177/225], Training Accuracy: 61.9792%, Training Loss: 0.8808%\n",
      "Epoch [16/300], Step [178/225], Training Accuracy: 61.9558%, Training Loss: 0.8814%\n",
      "Epoch [16/300], Step [179/225], Training Accuracy: 61.9763%, Training Loss: 0.8815%\n",
      "Epoch [16/300], Step [180/225], Training Accuracy: 61.9531%, Training Loss: 0.8813%\n",
      "Epoch [16/300], Step [181/225], Training Accuracy: 61.9302%, Training Loss: 0.8823%\n",
      "Epoch [16/300], Step [182/225], Training Accuracy: 61.9677%, Training Loss: 0.8814%\n",
      "Epoch [16/300], Step [183/225], Training Accuracy: 61.9450%, Training Loss: 0.8814%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/300], Step [184/225], Training Accuracy: 61.8801%, Training Loss: 0.8821%\n",
      "Epoch [16/300], Step [185/225], Training Accuracy: 61.8666%, Training Loss: 0.8827%\n",
      "Epoch [16/300], Step [186/225], Training Accuracy: 61.8784%, Training Loss: 0.8822%\n",
      "Epoch [16/300], Step [187/225], Training Accuracy: 61.8650%, Training Loss: 0.8820%\n",
      "Epoch [16/300], Step [188/225], Training Accuracy: 61.8600%, Training Loss: 0.8821%\n",
      "Epoch [16/300], Step [189/225], Training Accuracy: 61.8634%, Training Loss: 0.8819%\n",
      "Epoch [16/300], Step [190/225], Training Accuracy: 61.9079%, Training Loss: 0.8813%\n",
      "Epoch [16/300], Step [191/225], Training Accuracy: 61.9355%, Training Loss: 0.8810%\n",
      "Epoch [16/300], Step [192/225], Training Accuracy: 61.9303%, Training Loss: 0.8810%\n",
      "Epoch [16/300], Step [193/225], Training Accuracy: 61.9009%, Training Loss: 0.8814%\n",
      "Epoch [16/300], Step [194/225], Training Accuracy: 61.9604%, Training Loss: 0.8807%\n",
      "Epoch [16/300], Step [195/225], Training Accuracy: 61.9792%, Training Loss: 0.8806%\n",
      "Epoch [16/300], Step [196/225], Training Accuracy: 62.0536%, Training Loss: 0.8794%\n",
      "Epoch [16/300], Step [197/225], Training Accuracy: 62.0241%, Training Loss: 0.8802%\n",
      "Epoch [16/300], Step [198/225], Training Accuracy: 62.0581%, Training Loss: 0.8796%\n",
      "Epoch [16/300], Step [199/225], Training Accuracy: 62.0132%, Training Loss: 0.8798%\n",
      "Epoch [16/300], Step [200/225], Training Accuracy: 62.0469%, Training Loss: 0.8791%\n",
      "Epoch [16/300], Step [201/225], Training Accuracy: 62.0647%, Training Loss: 0.8785%\n",
      "Epoch [16/300], Step [202/225], Training Accuracy: 62.0514%, Training Loss: 0.8785%\n",
      "Epoch [16/300], Step [203/225], Training Accuracy: 62.0921%, Training Loss: 0.8783%\n",
      "Epoch [16/300], Step [204/225], Training Accuracy: 62.0941%, Training Loss: 0.8785%\n",
      "Epoch [16/300], Step [205/225], Training Accuracy: 62.1037%, Training Loss: 0.8782%\n",
      "Epoch [16/300], Step [206/225], Training Accuracy: 62.1056%, Training Loss: 0.8784%\n",
      "Epoch [16/300], Step [207/225], Training Accuracy: 62.1754%, Training Loss: 0.8772%\n",
      "Epoch [16/300], Step [208/225], Training Accuracy: 62.1920%, Training Loss: 0.8768%\n",
      "Epoch [16/300], Step [209/225], Training Accuracy: 62.1711%, Training Loss: 0.8765%\n",
      "Epoch [16/300], Step [210/225], Training Accuracy: 62.1726%, Training Loss: 0.8764%\n",
      "Epoch [16/300], Step [211/225], Training Accuracy: 62.2112%, Training Loss: 0.8758%\n",
      "Epoch [16/300], Step [212/225], Training Accuracy: 62.1757%, Training Loss: 0.8763%\n",
      "Epoch [16/300], Step [213/225], Training Accuracy: 62.1552%, Training Loss: 0.8766%\n",
      "Epoch [16/300], Step [214/225], Training Accuracy: 62.1422%, Training Loss: 0.8769%\n",
      "Epoch [16/300], Step [215/225], Training Accuracy: 62.1802%, Training Loss: 0.8763%\n",
      "Epoch [16/300], Step [216/225], Training Accuracy: 62.1383%, Training Loss: 0.8772%\n",
      "Epoch [16/300], Step [217/225], Training Accuracy: 62.1544%, Training Loss: 0.8765%\n",
      "Epoch [16/300], Step [218/225], Training Accuracy: 62.1058%, Training Loss: 0.8771%\n",
      "Epoch [16/300], Step [219/225], Training Accuracy: 62.1147%, Training Loss: 0.8767%\n",
      "Epoch [16/300], Step [220/225], Training Accuracy: 62.1378%, Training Loss: 0.8765%\n",
      "Epoch [16/300], Step [221/225], Training Accuracy: 62.1253%, Training Loss: 0.8770%\n",
      "Epoch [16/300], Step [222/225], Training Accuracy: 62.1129%, Training Loss: 0.8770%\n",
      "Epoch [16/300], Step [223/225], Training Accuracy: 62.1006%, Training Loss: 0.8768%\n",
      "Epoch [16/300], Step [224/225], Training Accuracy: 62.1233%, Training Loss: 0.8765%\n",
      "Epoch [16/300], Step [225/225], Training Accuracy: 62.0692%, Training Loss: 0.8766%\n",
      "Epoch [17/300], Step [1/225], Training Accuracy: 60.9375%, Training Loss: 0.8248%\n",
      "Epoch [17/300], Step [2/225], Training Accuracy: 61.7188%, Training Loss: 0.8430%\n",
      "Epoch [17/300], Step [3/225], Training Accuracy: 58.8542%, Training Loss: 0.9174%\n",
      "Epoch [17/300], Step [4/225], Training Accuracy: 63.2812%, Training Loss: 0.8625%\n",
      "Epoch [17/300], Step [5/225], Training Accuracy: 64.3750%, Training Loss: 0.8393%\n",
      "Epoch [17/300], Step [6/225], Training Accuracy: 63.0208%, Training Loss: 0.8611%\n",
      "Epoch [17/300], Step [7/225], Training Accuracy: 61.3839%, Training Loss: 0.8940%\n",
      "Epoch [17/300], Step [8/225], Training Accuracy: 62.3047%, Training Loss: 0.8811%\n",
      "Epoch [17/300], Step [9/225], Training Accuracy: 61.8056%, Training Loss: 0.8841%\n",
      "Epoch [17/300], Step [10/225], Training Accuracy: 61.4062%, Training Loss: 0.8905%\n",
      "Epoch [17/300], Step [11/225], Training Accuracy: 61.3636%, Training Loss: 0.8839%\n",
      "Epoch [17/300], Step [12/225], Training Accuracy: 61.5885%, Training Loss: 0.8882%\n",
      "Epoch [17/300], Step [13/225], Training Accuracy: 61.7788%, Training Loss: 0.8845%\n",
      "Epoch [17/300], Step [14/225], Training Accuracy: 61.6071%, Training Loss: 0.8869%\n",
      "Epoch [17/300], Step [15/225], Training Accuracy: 61.1458%, Training Loss: 0.8870%\n",
      "Epoch [17/300], Step [16/225], Training Accuracy: 60.9375%, Training Loss: 0.8918%\n",
      "Epoch [17/300], Step [17/225], Training Accuracy: 60.9375%, Training Loss: 0.8958%\n",
      "Epoch [17/300], Step [18/225], Training Accuracy: 60.6771%, Training Loss: 0.8959%\n",
      "Epoch [17/300], Step [19/225], Training Accuracy: 60.9375%, Training Loss: 0.8903%\n",
      "Epoch [17/300], Step [20/225], Training Accuracy: 60.9375%, Training Loss: 0.8875%\n",
      "Epoch [17/300], Step [21/225], Training Accuracy: 61.4583%, Training Loss: 0.8811%\n",
      "Epoch [17/300], Step [22/225], Training Accuracy: 61.2926%, Training Loss: 0.8821%\n",
      "Epoch [17/300], Step [23/225], Training Accuracy: 61.2772%, Training Loss: 0.8862%\n",
      "Epoch [17/300], Step [24/225], Training Accuracy: 61.0026%, Training Loss: 0.8920%\n",
      "Epoch [17/300], Step [25/225], Training Accuracy: 61.0625%, Training Loss: 0.8884%\n",
      "Epoch [17/300], Step [26/225], Training Accuracy: 60.8774%, Training Loss: 0.8908%\n",
      "Epoch [17/300], Step [27/225], Training Accuracy: 61.0532%, Training Loss: 0.8904%\n",
      "Epoch [17/300], Step [28/225], Training Accuracy: 61.3839%, Training Loss: 0.8846%\n",
      "Epoch [17/300], Step [29/225], Training Accuracy: 61.5302%, Training Loss: 0.8803%\n",
      "Epoch [17/300], Step [30/225], Training Accuracy: 61.5625%, Training Loss: 0.8809%\n",
      "Epoch [17/300], Step [31/225], Training Accuracy: 61.5423%, Training Loss: 0.8821%\n",
      "Epoch [17/300], Step [32/225], Training Accuracy: 61.8164%, Training Loss: 0.8777%\n",
      "Epoch [17/300], Step [33/225], Training Accuracy: 62.0265%, Training Loss: 0.8743%\n",
      "Epoch [17/300], Step [34/225], Training Accuracy: 61.9485%, Training Loss: 0.8754%\n",
      "Epoch [17/300], Step [35/225], Training Accuracy: 62.0089%, Training Loss: 0.8771%\n",
      "Epoch [17/300], Step [36/225], Training Accuracy: 61.9792%, Training Loss: 0.8770%\n",
      "Epoch [17/300], Step [37/225], Training Accuracy: 62.0777%, Training Loss: 0.8767%\n",
      "Epoch [17/300], Step [38/225], Training Accuracy: 61.9655%, Training Loss: 0.8767%\n",
      "Epoch [17/300], Step [39/225], Training Accuracy: 62.1795%, Training Loss: 0.8739%\n",
      "Epoch [17/300], Step [40/225], Training Accuracy: 62.1094%, Training Loss: 0.8741%\n",
      "Epoch [17/300], Step [41/225], Training Accuracy: 62.2713%, Training Loss: 0.8706%\n",
      "Epoch [17/300], Step [42/225], Training Accuracy: 62.4628%, Training Loss: 0.8677%\n",
      "Epoch [17/300], Step [43/225], Training Accuracy: 62.5727%, Training Loss: 0.8676%\n",
      "Epoch [17/300], Step [44/225], Training Accuracy: 62.6420%, Training Loss: 0.8684%\n",
      "Epoch [17/300], Step [45/225], Training Accuracy: 62.6736%, Training Loss: 0.8672%\n",
      "Epoch [17/300], Step [46/225], Training Accuracy: 62.8057%, Training Loss: 0.8654%\n",
      "Epoch [17/300], Step [47/225], Training Accuracy: 62.7992%, Training Loss: 0.8658%\n",
      "Epoch [17/300], Step [48/225], Training Accuracy: 62.6302%, Training Loss: 0.8668%\n",
      "Epoch [17/300], Step [49/225], Training Accuracy: 62.5319%, Training Loss: 0.8674%\n",
      "Epoch [17/300], Step [50/225], Training Accuracy: 62.6250%, Training Loss: 0.8668%\n",
      "Epoch [17/300], Step [51/225], Training Accuracy: 62.5613%, Training Loss: 0.8673%\n",
      "Epoch [17/300], Step [52/225], Training Accuracy: 62.7704%, Training Loss: 0.8635%\n",
      "Epoch [17/300], Step [53/225], Training Accuracy: 62.6179%, Training Loss: 0.8632%\n",
      "Epoch [17/300], Step [54/225], Training Accuracy: 62.6157%, Training Loss: 0.8646%\n",
      "Epoch [17/300], Step [55/225], Training Accuracy: 62.7841%, Training Loss: 0.8632%\n",
      "Epoch [17/300], Step [56/225], Training Accuracy: 62.8069%, Training Loss: 0.8630%\n",
      "Epoch [17/300], Step [57/225], Training Accuracy: 62.7467%, Training Loss: 0.8637%\n",
      "Epoch [17/300], Step [58/225], Training Accuracy: 62.6616%, Training Loss: 0.8658%\n",
      "Epoch [17/300], Step [59/225], Training Accuracy: 62.5530%, Training Loss: 0.8667%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/300], Step [60/225], Training Accuracy: 62.6302%, Training Loss: 0.8655%\n",
      "Epoch [17/300], Step [61/225], Training Accuracy: 62.6537%, Training Loss: 0.8651%\n",
      "Epoch [17/300], Step [62/225], Training Accuracy: 62.6008%, Training Loss: 0.8670%\n",
      "Epoch [17/300], Step [63/225], Training Accuracy: 62.5248%, Training Loss: 0.8689%\n",
      "Epoch [17/300], Step [64/225], Training Accuracy: 62.5488%, Training Loss: 0.8681%\n",
      "Epoch [17/300], Step [65/225], Training Accuracy: 62.6683%, Training Loss: 0.8659%\n",
      "Epoch [17/300], Step [66/225], Training Accuracy: 62.6894%, Training Loss: 0.8659%\n",
      "Epoch [17/300], Step [67/225], Training Accuracy: 62.6632%, Training Loss: 0.8675%\n",
      "Epoch [17/300], Step [68/225], Training Accuracy: 62.6608%, Training Loss: 0.8674%\n",
      "Epoch [17/300], Step [69/225], Training Accuracy: 62.6132%, Training Loss: 0.8683%\n",
      "Epoch [17/300], Step [70/225], Training Accuracy: 62.5893%, Training Loss: 0.8668%\n",
      "Epoch [17/300], Step [71/225], Training Accuracy: 62.4560%, Training Loss: 0.8669%\n",
      "Epoch [17/300], Step [72/225], Training Accuracy: 62.3481%, Training Loss: 0.8680%\n",
      "Epoch [17/300], Step [73/225], Training Accuracy: 62.2003%, Training Loss: 0.8703%\n",
      "Epoch [17/300], Step [74/225], Training Accuracy: 62.2255%, Training Loss: 0.8688%\n",
      "Epoch [17/300], Step [75/225], Training Accuracy: 62.3333%, Training Loss: 0.8667%\n",
      "Epoch [17/300], Step [76/225], Training Accuracy: 62.3561%, Training Loss: 0.8669%\n",
      "Epoch [17/300], Step [77/225], Training Accuracy: 62.4188%, Training Loss: 0.8677%\n",
      "Epoch [17/300], Step [78/225], Training Accuracy: 62.5200%, Training Loss: 0.8669%\n",
      "Epoch [17/300], Step [79/225], Training Accuracy: 62.4604%, Training Loss: 0.8675%\n",
      "Epoch [17/300], Step [80/225], Training Accuracy: 62.3828%, Training Loss: 0.8692%\n",
      "Epoch [17/300], Step [81/225], Training Accuracy: 62.3650%, Training Loss: 0.8688%\n",
      "Epoch [17/300], Step [82/225], Training Accuracy: 62.3666%, Training Loss: 0.8694%\n",
      "Epoch [17/300], Step [83/225], Training Accuracy: 62.4059%, Training Loss: 0.8682%\n",
      "Epoch [17/300], Step [84/225], Training Accuracy: 62.2954%, Training Loss: 0.8688%\n",
      "Epoch [17/300], Step [85/225], Training Accuracy: 62.3346%, Training Loss: 0.8694%\n",
      "Epoch [17/300], Step [86/225], Training Accuracy: 62.4273%, Training Loss: 0.8684%\n",
      "Epoch [17/300], Step [87/225], Training Accuracy: 62.5180%, Training Loss: 0.8670%\n",
      "Epoch [17/300], Step [88/225], Training Accuracy: 62.5355%, Training Loss: 0.8662%\n",
      "Epoch [17/300], Step [89/225], Training Accuracy: 62.6404%, Training Loss: 0.8646%\n",
      "Epoch [17/300], Step [90/225], Training Accuracy: 62.7083%, Training Loss: 0.8641%\n",
      "Epoch [17/300], Step [91/225], Training Accuracy: 62.7404%, Training Loss: 0.8638%\n",
      "Epoch [17/300], Step [92/225], Training Accuracy: 62.6868%, Training Loss: 0.8645%\n",
      "Epoch [17/300], Step [93/225], Training Accuracy: 62.7184%, Training Loss: 0.8645%\n",
      "Epoch [17/300], Step [94/225], Training Accuracy: 62.8158%, Training Loss: 0.8635%\n",
      "Epoch [17/300], Step [95/225], Training Accuracy: 62.8618%, Training Loss: 0.8627%\n",
      "Epoch [17/300], Step [96/225], Training Accuracy: 62.9883%, Training Loss: 0.8603%\n",
      "Epoch [17/300], Step [97/225], Training Accuracy: 62.9027%, Training Loss: 0.8604%\n",
      "Epoch [17/300], Step [98/225], Training Accuracy: 63.0102%, Training Loss: 0.8591%\n",
      "Epoch [17/300], Step [99/225], Training Accuracy: 63.0840%, Training Loss: 0.8588%\n",
      "Epoch [17/300], Step [100/225], Training Accuracy: 63.0625%, Training Loss: 0.8594%\n",
      "Epoch [17/300], Step [101/225], Training Accuracy: 63.1188%, Training Loss: 0.8588%\n",
      "Epoch [17/300], Step [102/225], Training Accuracy: 63.1281%, Training Loss: 0.8592%\n",
      "Epoch [17/300], Step [103/225], Training Accuracy: 63.1068%, Training Loss: 0.8594%\n",
      "Epoch [17/300], Step [104/225], Training Accuracy: 63.0108%, Training Loss: 0.8600%\n",
      "Epoch [17/300], Step [105/225], Training Accuracy: 62.9762%, Training Loss: 0.8603%\n",
      "Epoch [17/300], Step [106/225], Training Accuracy: 63.0012%, Training Loss: 0.8605%\n",
      "Epoch [17/300], Step [107/225], Training Accuracy: 62.9965%, Training Loss: 0.8602%\n",
      "Epoch [17/300], Step [108/225], Training Accuracy: 62.9774%, Training Loss: 0.8606%\n",
      "Epoch [17/300], Step [109/225], Training Accuracy: 62.9014%, Training Loss: 0.8622%\n",
      "Epoch [17/300], Step [110/225], Training Accuracy: 62.9403%, Training Loss: 0.8610%\n",
      "Epoch [17/300], Step [111/225], Training Accuracy: 63.0068%, Training Loss: 0.8600%\n",
      "Epoch [17/300], Step [112/225], Training Accuracy: 63.0441%, Training Loss: 0.8597%\n",
      "Epoch [17/300], Step [113/225], Training Accuracy: 62.9840%, Training Loss: 0.8601%\n",
      "Epoch [17/300], Step [114/225], Training Accuracy: 62.9660%, Training Loss: 0.8603%\n",
      "Epoch [17/300], Step [115/225], Training Accuracy: 62.9348%, Training Loss: 0.8612%\n",
      "Epoch [17/300], Step [116/225], Training Accuracy: 62.9714%, Training Loss: 0.8618%\n",
      "Epoch [17/300], Step [117/225], Training Accuracy: 62.9808%, Training Loss: 0.8613%\n",
      "Epoch [17/300], Step [118/225], Training Accuracy: 62.8840%, Training Loss: 0.8627%\n",
      "Epoch [17/300], Step [119/225], Training Accuracy: 62.9070%, Training Loss: 0.8628%\n",
      "Epoch [17/300], Step [120/225], Training Accuracy: 63.0208%, Training Loss: 0.8624%\n",
      "Epoch [17/300], Step [121/225], Training Accuracy: 63.0165%, Training Loss: 0.8621%\n",
      "Epoch [17/300], Step [122/225], Training Accuracy: 63.0507%, Training Loss: 0.8624%\n",
      "Epoch [17/300], Step [123/225], Training Accuracy: 63.0971%, Training Loss: 0.8623%\n",
      "Epoch [17/300], Step [124/225], Training Accuracy: 63.1300%, Training Loss: 0.8614%\n",
      "Epoch [17/300], Step [125/225], Training Accuracy: 63.1875%, Training Loss: 0.8603%\n",
      "Epoch [17/300], Step [126/225], Training Accuracy: 63.1820%, Training Loss: 0.8601%\n",
      "Epoch [17/300], Step [127/225], Training Accuracy: 63.2382%, Training Loss: 0.8594%\n",
      "Epoch [17/300], Step [128/225], Training Accuracy: 63.1958%, Training Loss: 0.8602%\n",
      "Epoch [17/300], Step [129/225], Training Accuracy: 63.2389%, Training Loss: 0.8593%\n",
      "Epoch [17/300], Step [130/225], Training Accuracy: 63.1731%, Training Loss: 0.8596%\n",
      "Epoch [17/300], Step [131/225], Training Accuracy: 63.1441%, Training Loss: 0.8594%\n",
      "Epoch [17/300], Step [132/225], Training Accuracy: 63.1274%, Training Loss: 0.8595%\n",
      "Epoch [17/300], Step [133/225], Training Accuracy: 63.1696%, Training Loss: 0.8583%\n",
      "Epoch [17/300], Step [134/225], Training Accuracy: 63.0597%, Training Loss: 0.8598%\n",
      "Epoch [17/300], Step [135/225], Training Accuracy: 63.1481%, Training Loss: 0.8582%\n",
      "Epoch [17/300], Step [136/225], Training Accuracy: 63.1434%, Training Loss: 0.8585%\n",
      "Epoch [17/300], Step [137/225], Training Accuracy: 63.1159%, Training Loss: 0.8587%\n",
      "Epoch [17/300], Step [138/225], Training Accuracy: 63.1567%, Training Loss: 0.8583%\n",
      "Epoch [17/300], Step [139/225], Training Accuracy: 63.1183%, Training Loss: 0.8588%\n",
      "Epoch [17/300], Step [140/225], Training Accuracy: 63.1696%, Training Loss: 0.8583%\n",
      "Epoch [17/300], Step [141/225], Training Accuracy: 63.1981%, Training Loss: 0.8583%\n",
      "Epoch [17/300], Step [142/225], Training Accuracy: 63.2262%, Training Loss: 0.8579%\n",
      "Epoch [17/300], Step [143/225], Training Accuracy: 63.1993%, Training Loss: 0.8583%\n",
      "Epoch [17/300], Step [144/225], Training Accuracy: 63.2053%, Training Loss: 0.8578%\n",
      "Epoch [17/300], Step [145/225], Training Accuracy: 63.2004%, Training Loss: 0.8582%\n",
      "Epoch [17/300], Step [146/225], Training Accuracy: 63.1849%, Training Loss: 0.8582%\n",
      "Epoch [17/300], Step [147/225], Training Accuracy: 63.0952%, Training Loss: 0.8590%\n",
      "Epoch [17/300], Step [148/225], Training Accuracy: 63.1757%, Training Loss: 0.8580%\n",
      "Epoch [17/300], Step [149/225], Training Accuracy: 63.1711%, Training Loss: 0.8575%\n",
      "Epoch [17/300], Step [150/225], Training Accuracy: 63.3021%, Training Loss: 0.8561%\n",
      "Epoch [17/300], Step [151/225], Training Accuracy: 63.3382%, Training Loss: 0.8552%\n",
      "Epoch [17/300], Step [152/225], Training Accuracy: 63.3738%, Training Loss: 0.8547%\n",
      "Epoch [17/300], Step [153/225], Training Accuracy: 63.4498%, Training Loss: 0.8538%\n",
      "Epoch [17/300], Step [154/225], Training Accuracy: 63.4740%, Training Loss: 0.8533%\n",
      "Epoch [17/300], Step [155/225], Training Accuracy: 63.4677%, Training Loss: 0.8529%\n",
      "Epoch [17/300], Step [156/225], Training Accuracy: 63.4415%, Training Loss: 0.8534%\n",
      "Epoch [17/300], Step [157/225], Training Accuracy: 63.4853%, Training Loss: 0.8529%\n",
      "Epoch [17/300], Step [158/225], Training Accuracy: 63.5483%, Training Loss: 0.8522%\n",
      "Epoch [17/300], Step [159/225], Training Accuracy: 63.5908%, Training Loss: 0.8514%\n",
      "Epoch [17/300], Step [160/225], Training Accuracy: 63.5645%, Training Loss: 0.8517%\n",
      "Epoch [17/300], Step [161/225], Training Accuracy: 63.5093%, Training Loss: 0.8517%\n",
      "Epoch [17/300], Step [162/225], Training Accuracy: 63.5610%, Training Loss: 0.8507%\n",
      "Epoch [17/300], Step [163/225], Training Accuracy: 63.6215%, Training Loss: 0.8497%\n",
      "Epoch [17/300], Step [164/225], Training Accuracy: 63.6528%, Training Loss: 0.8492%\n",
      "Epoch [17/300], Step [165/225], Training Accuracy: 63.7027%, Training Loss: 0.8488%\n",
      "Epoch [17/300], Step [166/225], Training Accuracy: 63.6954%, Training Loss: 0.8488%\n",
      "Epoch [17/300], Step [167/225], Training Accuracy: 63.6882%, Training Loss: 0.8487%\n",
      "Epoch [17/300], Step [168/225], Training Accuracy: 63.6812%, Training Loss: 0.8486%\n",
      "Epoch [17/300], Step [169/225], Training Accuracy: 63.6557%, Training Loss: 0.8491%\n",
      "Epoch [17/300], Step [170/225], Training Accuracy: 63.6765%, Training Loss: 0.8491%\n",
      "Epoch [17/300], Step [171/225], Training Accuracy: 63.6787%, Training Loss: 0.8491%\n",
      "Epoch [17/300], Step [172/225], Training Accuracy: 63.7536%, Training Loss: 0.8483%\n",
      "Epoch [17/300], Step [173/225], Training Accuracy: 63.6832%, Training Loss: 0.8487%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/300], Step [174/225], Training Accuracy: 63.6853%, Training Loss: 0.8488%\n",
      "Epoch [17/300], Step [175/225], Training Accuracy: 63.6964%, Training Loss: 0.8483%\n",
      "Epoch [17/300], Step [176/225], Training Accuracy: 63.6808%, Training Loss: 0.8486%\n",
      "Epoch [17/300], Step [177/225], Training Accuracy: 63.7006%, Training Loss: 0.8484%\n",
      "Epoch [17/300], Step [178/225], Training Accuracy: 63.6850%, Training Loss: 0.8487%\n",
      "Epoch [17/300], Step [179/225], Training Accuracy: 63.7046%, Training Loss: 0.8485%\n",
      "Epoch [17/300], Step [180/225], Training Accuracy: 63.7153%, Training Loss: 0.8486%\n",
      "Epoch [17/300], Step [181/225], Training Accuracy: 63.6395%, Training Loss: 0.8496%\n",
      "Epoch [17/300], Step [182/225], Training Accuracy: 63.6590%, Training Loss: 0.8491%\n",
      "Epoch [17/300], Step [183/225], Training Accuracy: 63.6441%, Training Loss: 0.8487%\n",
      "Epoch [17/300], Step [184/225], Training Accuracy: 63.5954%, Training Loss: 0.8491%\n",
      "Epoch [17/300], Step [185/225], Training Accuracy: 63.6064%, Training Loss: 0.8487%\n",
      "Epoch [17/300], Step [186/225], Training Accuracy: 63.6257%, Training Loss: 0.8484%\n",
      "Epoch [17/300], Step [187/225], Training Accuracy: 63.6029%, Training Loss: 0.8488%\n",
      "Epoch [17/300], Step [188/225], Training Accuracy: 63.6054%, Training Loss: 0.8484%\n",
      "Epoch [17/300], Step [189/225], Training Accuracy: 63.6161%, Training Loss: 0.8477%\n",
      "Epoch [17/300], Step [190/225], Training Accuracy: 63.6349%, Training Loss: 0.8472%\n",
      "Epoch [17/300], Step [191/225], Training Accuracy: 63.6780%, Training Loss: 0.8466%\n",
      "Epoch [17/300], Step [192/225], Training Accuracy: 63.6475%, Training Loss: 0.8470%\n",
      "Epoch [17/300], Step [193/225], Training Accuracy: 63.6010%, Training Loss: 0.8472%\n",
      "Epoch [17/300], Step [194/225], Training Accuracy: 63.6517%, Training Loss: 0.8462%\n",
      "Epoch [17/300], Step [195/225], Training Accuracy: 63.6458%, Training Loss: 0.8465%\n",
      "Epoch [17/300], Step [196/225], Training Accuracy: 63.6719%, Training Loss: 0.8458%\n",
      "Epoch [17/300], Step [197/225], Training Accuracy: 63.6580%, Training Loss: 0.8462%\n",
      "Epoch [17/300], Step [198/225], Training Accuracy: 63.7074%, Training Loss: 0.8458%\n",
      "Epoch [17/300], Step [199/225], Training Accuracy: 63.6464%, Training Loss: 0.8467%\n",
      "Epoch [17/300], Step [200/225], Training Accuracy: 63.6406%, Training Loss: 0.8467%\n",
      "Epoch [17/300], Step [201/225], Training Accuracy: 63.6583%, Training Loss: 0.8463%\n",
      "Epoch [17/300], Step [202/225], Training Accuracy: 63.6216%, Training Loss: 0.8470%\n",
      "Epoch [17/300], Step [203/225], Training Accuracy: 63.6546%, Training Loss: 0.8472%\n",
      "Epoch [17/300], Step [204/225], Training Accuracy: 63.6489%, Training Loss: 0.8473%\n",
      "Epoch [17/300], Step [205/225], Training Accuracy: 63.6662%, Training Loss: 0.8473%\n",
      "Epoch [17/300], Step [206/225], Training Accuracy: 63.6605%, Training Loss: 0.8476%\n",
      "Epoch [17/300], Step [207/225], Training Accuracy: 63.6926%, Training Loss: 0.8468%\n",
      "Epoch [17/300], Step [208/225], Training Accuracy: 63.6719%, Training Loss: 0.8468%\n",
      "Epoch [17/300], Step [209/225], Training Accuracy: 63.6737%, Training Loss: 0.8467%\n",
      "Epoch [17/300], Step [210/225], Training Accuracy: 63.7128%, Training Loss: 0.8466%\n",
      "Epoch [17/300], Step [211/225], Training Accuracy: 63.6996%, Training Loss: 0.8465%\n",
      "Epoch [17/300], Step [212/225], Training Accuracy: 63.6645%, Training Loss: 0.8471%\n",
      "Epoch [17/300], Step [213/225], Training Accuracy: 63.6737%, Training Loss: 0.8471%\n",
      "Epoch [17/300], Step [214/225], Training Accuracy: 63.6390%, Training Loss: 0.8475%\n",
      "Epoch [17/300], Step [215/225], Training Accuracy: 63.6483%, Training Loss: 0.8470%\n",
      "Epoch [17/300], Step [216/225], Training Accuracy: 63.6212%, Training Loss: 0.8478%\n",
      "Epoch [17/300], Step [217/225], Training Accuracy: 63.6665%, Training Loss: 0.8472%\n",
      "Epoch [17/300], Step [218/225], Training Accuracy: 63.6611%, Training Loss: 0.8476%\n",
      "Epoch [17/300], Step [219/225], Training Accuracy: 63.6630%, Training Loss: 0.8472%\n",
      "Epoch [17/300], Step [220/225], Training Accuracy: 63.6861%, Training Loss: 0.8467%\n",
      "Epoch [17/300], Step [221/225], Training Accuracy: 63.6949%, Training Loss: 0.8471%\n",
      "Epoch [17/300], Step [222/225], Training Accuracy: 63.6895%, Training Loss: 0.8473%\n",
      "Epoch [17/300], Step [223/225], Training Accuracy: 63.7052%, Training Loss: 0.8471%\n",
      "Epoch [17/300], Step [224/225], Training Accuracy: 63.7207%, Training Loss: 0.8466%\n",
      "Epoch [17/300], Step [225/225], Training Accuracy: 63.7298%, Training Loss: 0.8467%\n",
      "Epoch [18/300], Step [1/225], Training Accuracy: 62.5000%, Training Loss: 0.8253%\n",
      "Epoch [18/300], Step [2/225], Training Accuracy: 64.8438%, Training Loss: 0.7994%\n",
      "Epoch [18/300], Step [3/225], Training Accuracy: 60.9375%, Training Loss: 0.8851%\n",
      "Epoch [18/300], Step [4/225], Training Accuracy: 63.6719%, Training Loss: 0.8302%\n",
      "Epoch [18/300], Step [5/225], Training Accuracy: 64.3750%, Training Loss: 0.8093%\n",
      "Epoch [18/300], Step [6/225], Training Accuracy: 64.8438%, Training Loss: 0.8205%\n",
      "Epoch [18/300], Step [7/225], Training Accuracy: 64.0625%, Training Loss: 0.8419%\n",
      "Epoch [18/300], Step [8/225], Training Accuracy: 64.0625%, Training Loss: 0.8358%\n",
      "Epoch [18/300], Step [9/225], Training Accuracy: 63.3681%, Training Loss: 0.8364%\n",
      "Epoch [18/300], Step [10/225], Training Accuracy: 63.2812%, Training Loss: 0.8394%\n",
      "Epoch [18/300], Step [11/225], Training Accuracy: 64.0625%, Training Loss: 0.8269%\n",
      "Epoch [18/300], Step [12/225], Training Accuracy: 64.1927%, Training Loss: 0.8303%\n",
      "Epoch [18/300], Step [13/225], Training Accuracy: 64.0625%, Training Loss: 0.8318%\n",
      "Epoch [18/300], Step [14/225], Training Accuracy: 63.9509%, Training Loss: 0.8346%\n",
      "Epoch [18/300], Step [15/225], Training Accuracy: 64.0625%, Training Loss: 0.8345%\n",
      "Epoch [18/300], Step [16/225], Training Accuracy: 63.1836%, Training Loss: 0.8442%\n",
      "Epoch [18/300], Step [17/225], Training Accuracy: 63.2353%, Training Loss: 0.8486%\n",
      "Epoch [18/300], Step [18/225], Training Accuracy: 63.2812%, Training Loss: 0.8489%\n",
      "Epoch [18/300], Step [19/225], Training Accuracy: 63.4868%, Training Loss: 0.8411%\n",
      "Epoch [18/300], Step [20/225], Training Accuracy: 63.7500%, Training Loss: 0.8356%\n",
      "Epoch [18/300], Step [21/225], Training Accuracy: 63.6905%, Training Loss: 0.8305%\n",
      "Epoch [18/300], Step [22/225], Training Accuracy: 63.5653%, Training Loss: 0.8338%\n",
      "Epoch [18/300], Step [23/225], Training Accuracy: 63.4511%, Training Loss: 0.8389%\n",
      "Epoch [18/300], Step [24/225], Training Accuracy: 63.4115%, Training Loss: 0.8441%\n",
      "Epoch [18/300], Step [25/225], Training Accuracy: 63.5000%, Training Loss: 0.8406%\n",
      "Epoch [18/300], Step [26/225], Training Accuracy: 63.4615%, Training Loss: 0.8425%\n",
      "Epoch [18/300], Step [27/225], Training Accuracy: 63.5995%, Training Loss: 0.8409%\n",
      "Epoch [18/300], Step [28/225], Training Accuracy: 63.9509%, Training Loss: 0.8332%\n",
      "Epoch [18/300], Step [29/225], Training Accuracy: 64.1703%, Training Loss: 0.8290%\n",
      "Epoch [18/300], Step [30/225], Training Accuracy: 64.0625%, Training Loss: 0.8306%\n",
      "Epoch [18/300], Step [31/225], Training Accuracy: 63.9617%, Training Loss: 0.8305%\n",
      "Epoch [18/300], Step [32/225], Training Accuracy: 64.1113%, Training Loss: 0.8272%\n",
      "Epoch [18/300], Step [33/225], Training Accuracy: 64.2519%, Training Loss: 0.8242%\n",
      "Epoch [18/300], Step [34/225], Training Accuracy: 64.3842%, Training Loss: 0.8227%\n",
      "Epoch [18/300], Step [35/225], Training Accuracy: 64.3750%, Training Loss: 0.8248%\n",
      "Epoch [18/300], Step [36/225], Training Accuracy: 64.4531%, Training Loss: 0.8241%\n",
      "Epoch [18/300], Step [37/225], Training Accuracy: 64.6115%, Training Loss: 0.8247%\n",
      "Epoch [18/300], Step [38/225], Training Accuracy: 64.7204%, Training Loss: 0.8222%\n",
      "Epoch [18/300], Step [39/225], Training Accuracy: 64.9038%, Training Loss: 0.8181%\n",
      "Epoch [18/300], Step [40/225], Training Accuracy: 64.6875%, Training Loss: 0.8184%\n",
      "Epoch [18/300], Step [41/225], Training Accuracy: 64.8628%, Training Loss: 0.8146%\n",
      "Epoch [18/300], Step [42/225], Training Accuracy: 65.0670%, Training Loss: 0.8127%\n",
      "Epoch [18/300], Step [43/225], Training Accuracy: 65.1163%, Training Loss: 0.8124%\n",
      "Epoch [18/300], Step [44/225], Training Accuracy: 64.9858%, Training Loss: 0.8147%\n",
      "Epoch [18/300], Step [45/225], Training Accuracy: 65.1736%, Training Loss: 0.8126%\n",
      "Epoch [18/300], Step [46/225], Training Accuracy: 65.3193%, Training Loss: 0.8115%\n",
      "Epoch [18/300], Step [47/225], Training Accuracy: 65.3590%, Training Loss: 0.8120%\n",
      "Epoch [18/300], Step [48/225], Training Accuracy: 65.3320%, Training Loss: 0.8142%\n",
      "Epoch [18/300], Step [49/225], Training Accuracy: 65.3061%, Training Loss: 0.8144%\n",
      "Epoch [18/300], Step [50/225], Training Accuracy: 65.2188%, Training Loss: 0.8143%\n",
      "Epoch [18/300], Step [51/225], Training Accuracy: 65.3186%, Training Loss: 0.8142%\n",
      "Epoch [18/300], Step [52/225], Training Accuracy: 65.4147%, Training Loss: 0.8126%\n",
      "Epoch [18/300], Step [53/225], Training Accuracy: 65.3597%, Training Loss: 0.8142%\n",
      "Epoch [18/300], Step [54/225], Training Accuracy: 65.3067%, Training Loss: 0.8164%\n",
      "Epoch [18/300], Step [55/225], Training Accuracy: 65.4261%, Training Loss: 0.8153%\n",
      "Epoch [18/300], Step [56/225], Training Accuracy: 65.5692%, Training Loss: 0.8143%\n",
      "Epoch [18/300], Step [57/225], Training Accuracy: 65.5976%, Training Loss: 0.8140%\n",
      "Epoch [18/300], Step [58/225], Training Accuracy: 65.5442%, Training Loss: 0.8167%\n",
      "Epoch [18/300], Step [59/225], Training Accuracy: 65.4396%, Training Loss: 0.8176%\n",
      "Epoch [18/300], Step [60/225], Training Accuracy: 65.4427%, Training Loss: 0.8166%\n",
      "Epoch [18/300], Step [61/225], Training Accuracy: 65.4457%, Training Loss: 0.8160%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/300], Step [62/225], Training Accuracy: 65.3982%, Training Loss: 0.8174%\n",
      "Epoch [18/300], Step [63/225], Training Accuracy: 65.3522%, Training Loss: 0.8198%\n",
      "Epoch [18/300], Step [64/225], Training Accuracy: 65.3564%, Training Loss: 0.8188%\n",
      "Epoch [18/300], Step [65/225], Training Accuracy: 65.4087%, Training Loss: 0.8176%\n",
      "Epoch [18/300], Step [66/225], Training Accuracy: 65.3883%, Training Loss: 0.8170%\n",
      "Epoch [18/300], Step [67/225], Training Accuracy: 65.3685%, Training Loss: 0.8173%\n",
      "Epoch [18/300], Step [68/225], Training Accuracy: 65.3722%, Training Loss: 0.8181%\n",
      "Epoch [18/300], Step [69/225], Training Accuracy: 65.3986%, Training Loss: 0.8172%\n",
      "Epoch [18/300], Step [70/225], Training Accuracy: 65.4911%, Training Loss: 0.8158%\n",
      "Epoch [18/300], Step [71/225], Training Accuracy: 65.4489%, Training Loss: 0.8154%\n",
      "Epoch [18/300], Step [72/225], Training Accuracy: 65.4514%, Training Loss: 0.8153%\n",
      "Epoch [18/300], Step [73/225], Training Accuracy: 65.2825%, Training Loss: 0.8183%\n",
      "Epoch [18/300], Step [74/225], Training Accuracy: 65.3294%, Training Loss: 0.8170%\n",
      "Epoch [18/300], Step [75/225], Training Accuracy: 65.3333%, Training Loss: 0.8162%\n",
      "Epoch [18/300], Step [76/225], Training Accuracy: 65.3166%, Training Loss: 0.8159%\n",
      "Epoch [18/300], Step [77/225], Training Accuracy: 65.2800%, Training Loss: 0.8167%\n",
      "Epoch [18/300], Step [78/225], Training Accuracy: 65.2644%, Training Loss: 0.8163%\n",
      "Epoch [18/300], Step [79/225], Training Accuracy: 65.2888%, Training Loss: 0.8168%\n",
      "Epoch [18/300], Step [80/225], Training Accuracy: 65.1562%, Training Loss: 0.8192%\n",
      "Epoch [18/300], Step [81/225], Training Accuracy: 65.1235%, Training Loss: 0.8193%\n",
      "Epoch [18/300], Step [82/225], Training Accuracy: 65.1677%, Training Loss: 0.8193%\n",
      "Epoch [18/300], Step [83/225], Training Accuracy: 65.1920%, Training Loss: 0.8190%\n",
      "Epoch [18/300], Step [84/225], Training Accuracy: 65.1228%, Training Loss: 0.8195%\n",
      "Epoch [18/300], Step [85/225], Training Accuracy: 65.0368%, Training Loss: 0.8198%\n",
      "Epoch [18/300], Step [86/225], Training Accuracy: 65.1163%, Training Loss: 0.8182%\n",
      "Epoch [18/300], Step [87/225], Training Accuracy: 65.1760%, Training Loss: 0.8175%\n",
      "Epoch [18/300], Step [88/225], Training Accuracy: 65.2699%, Training Loss: 0.8170%\n",
      "Epoch [18/300], Step [89/225], Training Accuracy: 65.3265%, Training Loss: 0.8159%\n",
      "Epoch [18/300], Step [90/225], Training Accuracy: 65.3646%, Training Loss: 0.8150%\n",
      "Epoch [18/300], Step [91/225], Training Accuracy: 65.4190%, Training Loss: 0.8140%\n",
      "Epoch [18/300], Step [92/225], Training Accuracy: 65.4042%, Training Loss: 0.8150%\n",
      "Epoch [18/300], Step [93/225], Training Accuracy: 65.4234%, Training Loss: 0.8148%\n",
      "Epoch [18/300], Step [94/225], Training Accuracy: 65.4754%, Training Loss: 0.8136%\n",
      "Epoch [18/300], Step [95/225], Training Accuracy: 65.4770%, Training Loss: 0.8138%\n",
      "Epoch [18/300], Step [96/225], Training Accuracy: 65.5273%, Training Loss: 0.8127%\n",
      "Epoch [18/300], Step [97/225], Training Accuracy: 65.4478%, Training Loss: 0.8131%\n",
      "Epoch [18/300], Step [98/225], Training Accuracy: 65.5293%, Training Loss: 0.8113%\n",
      "Epoch [18/300], Step [99/225], Training Accuracy: 65.5303%, Training Loss: 0.8114%\n",
      "Epoch [18/300], Step [100/225], Training Accuracy: 65.4531%, Training Loss: 0.8120%\n",
      "Epoch [18/300], Step [101/225], Training Accuracy: 65.4239%, Training Loss: 0.8128%\n",
      "Epoch [18/300], Step [102/225], Training Accuracy: 65.4412%, Training Loss: 0.8128%\n",
      "Epoch [18/300], Step [103/225], Training Accuracy: 65.4733%, Training Loss: 0.8130%\n",
      "Epoch [18/300], Step [104/225], Training Accuracy: 65.4147%, Training Loss: 0.8140%\n",
      "Epoch [18/300], Step [105/225], Training Accuracy: 65.3423%, Training Loss: 0.8144%\n",
      "Epoch [18/300], Step [106/225], Training Accuracy: 65.3154%, Training Loss: 0.8155%\n",
      "Epoch [18/300], Step [107/225], Training Accuracy: 65.3329%, Training Loss: 0.8153%\n",
      "Epoch [18/300], Step [108/225], Training Accuracy: 65.2922%, Training Loss: 0.8160%\n",
      "Epoch [18/300], Step [109/225], Training Accuracy: 65.2666%, Training Loss: 0.8178%\n",
      "Epoch [18/300], Step [110/225], Training Accuracy: 65.2983%, Training Loss: 0.8177%\n",
      "Epoch [18/300], Step [111/225], Training Accuracy: 65.3012%, Training Loss: 0.8173%\n",
      "Epoch [18/300], Step [112/225], Training Accuracy: 65.2902%, Training Loss: 0.8174%\n",
      "Epoch [18/300], Step [113/225], Training Accuracy: 65.3208%, Training Loss: 0.8176%\n",
      "Epoch [18/300], Step [114/225], Training Accuracy: 65.2961%, Training Loss: 0.8175%\n",
      "Epoch [18/300], Step [115/225], Training Accuracy: 65.2310%, Training Loss: 0.8194%\n",
      "Epoch [18/300], Step [116/225], Training Accuracy: 65.2344%, Training Loss: 0.8201%\n",
      "Epoch [18/300], Step [117/225], Training Accuracy: 65.2244%, Training Loss: 0.8198%\n",
      "Epoch [18/300], Step [118/225], Training Accuracy: 65.1615%, Training Loss: 0.8213%\n",
      "Epoch [18/300], Step [119/225], Training Accuracy: 65.0998%, Training Loss: 0.8218%\n",
      "Epoch [18/300], Step [120/225], Training Accuracy: 65.1042%, Training Loss: 0.8214%\n",
      "Epoch [18/300], Step [121/225], Training Accuracy: 65.0826%, Training Loss: 0.8215%\n",
      "Epoch [18/300], Step [122/225], Training Accuracy: 65.1127%, Training Loss: 0.8215%\n",
      "Epoch [18/300], Step [123/225], Training Accuracy: 65.1677%, Training Loss: 0.8211%\n",
      "Epoch [18/300], Step [124/225], Training Accuracy: 65.1840%, Training Loss: 0.8200%\n",
      "Epoch [18/300], Step [125/225], Training Accuracy: 65.2125%, Training Loss: 0.8187%\n",
      "Epoch [18/300], Step [126/225], Training Accuracy: 65.2158%, Training Loss: 0.8188%\n",
      "Epoch [18/300], Step [127/225], Training Accuracy: 65.2559%, Training Loss: 0.8186%\n",
      "Epoch [18/300], Step [128/225], Training Accuracy: 65.1733%, Training Loss: 0.8192%\n",
      "Epoch [18/300], Step [129/225], Training Accuracy: 65.2495%, Training Loss: 0.8187%\n",
      "Epoch [18/300], Step [130/225], Training Accuracy: 65.2524%, Training Loss: 0.8185%\n",
      "Epoch [18/300], Step [131/225], Training Accuracy: 65.2552%, Training Loss: 0.8185%\n",
      "Epoch [18/300], Step [132/225], Training Accuracy: 65.2107%, Training Loss: 0.8189%\n",
      "Epoch [18/300], Step [133/225], Training Accuracy: 65.2608%, Training Loss: 0.8175%\n",
      "Epoch [18/300], Step [134/225], Training Accuracy: 65.2635%, Training Loss: 0.8178%\n",
      "Epoch [18/300], Step [135/225], Training Accuracy: 65.3588%, Training Loss: 0.8162%\n",
      "Epoch [18/300], Step [136/225], Training Accuracy: 65.3952%, Training Loss: 0.8161%\n",
      "Epoch [18/300], Step [137/225], Training Accuracy: 65.3399%, Training Loss: 0.8161%\n",
      "Epoch [18/300], Step [138/225], Training Accuracy: 65.3759%, Training Loss: 0.8160%\n",
      "Epoch [18/300], Step [139/225], Training Accuracy: 65.3103%, Training Loss: 0.8166%\n",
      "Epoch [18/300], Step [140/225], Training Accuracy: 65.3125%, Training Loss: 0.8167%\n",
      "Epoch [18/300], Step [141/225], Training Accuracy: 65.3258%, Training Loss: 0.8164%\n",
      "Epoch [18/300], Step [142/225], Training Accuracy: 65.3389%, Training Loss: 0.8162%\n",
      "Epoch [18/300], Step [143/225], Training Accuracy: 65.2863%, Training Loss: 0.8166%\n",
      "Epoch [18/300], Step [144/225], Training Accuracy: 65.3103%, Training Loss: 0.8163%\n",
      "Epoch [18/300], Step [145/225], Training Accuracy: 65.3556%, Training Loss: 0.8161%\n",
      "Epoch [18/300], Step [146/225], Training Accuracy: 65.3467%, Training Loss: 0.8159%\n",
      "Epoch [18/300], Step [147/225], Training Accuracy: 65.2530%, Training Loss: 0.8166%\n",
      "Epoch [18/300], Step [148/225], Training Accuracy: 65.2660%, Training Loss: 0.8159%\n",
      "Epoch [18/300], Step [149/225], Training Accuracy: 65.2999%, Training Loss: 0.8153%\n",
      "Epoch [18/300], Step [150/225], Training Accuracy: 65.3750%, Training Loss: 0.8139%\n",
      "Epoch [18/300], Step [151/225], Training Accuracy: 65.4180%, Training Loss: 0.8127%\n",
      "Epoch [18/300], Step [152/225], Training Accuracy: 65.4400%, Training Loss: 0.8127%\n",
      "Epoch [18/300], Step [153/225], Training Accuracy: 65.4820%, Training Loss: 0.8116%\n",
      "Epoch [18/300], Step [154/225], Training Accuracy: 65.5134%, Training Loss: 0.8111%\n",
      "Epoch [18/300], Step [155/225], Training Accuracy: 65.5242%, Training Loss: 0.8113%\n",
      "Epoch [18/300], Step [156/225], Training Accuracy: 65.5349%, Training Loss: 0.8114%\n",
      "Epoch [18/300], Step [157/225], Training Accuracy: 65.5653%, Training Loss: 0.8112%\n",
      "Epoch [18/300], Step [158/225], Training Accuracy: 65.6151%, Training Loss: 0.8106%\n",
      "Epoch [18/300], Step [159/225], Training Accuracy: 65.6348%, Training Loss: 0.8099%\n",
      "Epoch [18/300], Step [160/225], Training Accuracy: 65.6348%, Training Loss: 0.8098%\n",
      "Epoch [18/300], Step [161/225], Training Accuracy: 65.6056%, Training Loss: 0.8097%\n",
      "Epoch [18/300], Step [162/225], Training Accuracy: 65.6732%, Training Loss: 0.8088%\n",
      "Epoch [18/300], Step [163/225], Training Accuracy: 65.7400%, Training Loss: 0.8078%\n",
      "Epoch [18/300], Step [164/225], Training Accuracy: 65.7584%, Training Loss: 0.8075%\n",
      "Epoch [18/300], Step [165/225], Training Accuracy: 65.7765%, Training Loss: 0.8071%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/300], Step [166/225], Training Accuracy: 65.7944%, Training Loss: 0.8071%\n",
      "Epoch [18/300], Step [167/225], Training Accuracy: 65.7841%, Training Loss: 0.8073%\n",
      "Epoch [18/300], Step [168/225], Training Accuracy: 65.8017%, Training Loss: 0.8068%\n",
      "Epoch [18/300], Step [169/225], Training Accuracy: 65.7822%, Training Loss: 0.8076%\n",
      "Epoch [18/300], Step [170/225], Training Accuracy: 65.7353%, Training Loss: 0.8078%\n",
      "Epoch [18/300], Step [171/225], Training Accuracy: 65.7255%, Training Loss: 0.8075%\n",
      "Epoch [18/300], Step [172/225], Training Accuracy: 65.7794%, Training Loss: 0.8073%\n",
      "Epoch [18/300], Step [173/225], Training Accuracy: 65.7243%, Training Loss: 0.8074%\n",
      "Epoch [18/300], Step [174/225], Training Accuracy: 65.7058%, Training Loss: 0.8076%\n",
      "Epoch [18/300], Step [175/225], Training Accuracy: 65.7232%, Training Loss: 0.8067%\n",
      "Epoch [18/300], Step [176/225], Training Accuracy: 65.7138%, Training Loss: 0.8067%\n",
      "Epoch [18/300], Step [177/225], Training Accuracy: 65.7309%, Training Loss: 0.8065%\n",
      "Epoch [18/300], Step [178/225], Training Accuracy: 65.6777%, Training Loss: 0.8073%\n",
      "Epoch [18/300], Step [179/225], Training Accuracy: 65.6774%, Training Loss: 0.8071%\n",
      "Epoch [18/300], Step [180/225], Training Accuracy: 65.6684%, Training Loss: 0.8069%\n",
      "Epoch [18/300], Step [181/225], Training Accuracy: 65.6768%, Training Loss: 0.8075%\n",
      "Epoch [18/300], Step [182/225], Training Accuracy: 65.6937%, Training Loss: 0.8070%\n",
      "Epoch [18/300], Step [183/225], Training Accuracy: 65.6848%, Training Loss: 0.8065%\n",
      "Epoch [18/300], Step [184/225], Training Accuracy: 65.6675%, Training Loss: 0.8066%\n",
      "Epoch [18/300], Step [185/225], Training Accuracy: 65.6841%, Training Loss: 0.8060%\n",
      "Epoch [18/300], Step [186/225], Training Accuracy: 65.6418%, Training Loss: 0.8063%\n",
      "Epoch [18/300], Step [187/225], Training Accuracy: 65.6501%, Training Loss: 0.8061%\n",
      "Epoch [18/300], Step [188/225], Training Accuracy: 65.6167%, Training Loss: 0.8060%\n",
      "Epoch [18/300], Step [189/225], Training Accuracy: 65.6415%, Training Loss: 0.8054%\n",
      "Epoch [18/300], Step [190/225], Training Accuracy: 65.6497%, Training Loss: 0.8050%\n",
      "Epoch [18/300], Step [191/225], Training Accuracy: 65.7232%, Training Loss: 0.8044%\n",
      "Epoch [18/300], Step [192/225], Training Accuracy: 65.6820%, Training Loss: 0.8048%\n",
      "Epoch [18/300], Step [193/225], Training Accuracy: 65.6655%, Training Loss: 0.8054%\n",
      "Epoch [18/300], Step [194/225], Training Accuracy: 65.7216%, Training Loss: 0.8049%\n",
      "Epoch [18/300], Step [195/225], Training Accuracy: 65.7051%, Training Loss: 0.8050%\n",
      "Epoch [18/300], Step [196/225], Training Accuracy: 65.7446%, Training Loss: 0.8042%\n",
      "Epoch [18/300], Step [197/225], Training Accuracy: 65.7202%, Training Loss: 0.8046%\n",
      "Epoch [18/300], Step [198/225], Training Accuracy: 65.6960%, Training Loss: 0.8049%\n",
      "Epoch [18/300], Step [199/225], Training Accuracy: 65.6878%, Training Loss: 0.8056%\n",
      "Epoch [18/300], Step [200/225], Training Accuracy: 65.7266%, Training Loss: 0.8055%\n",
      "Epoch [18/300], Step [201/225], Training Accuracy: 65.7572%, Training Loss: 0.8047%\n",
      "Epoch [18/300], Step [202/225], Training Accuracy: 65.7642%, Training Loss: 0.8046%\n",
      "Epoch [18/300], Step [203/225], Training Accuracy: 65.7635%, Training Loss: 0.8047%\n",
      "Epoch [18/300], Step [204/225], Training Accuracy: 65.7629%, Training Loss: 0.8047%\n",
      "Epoch [18/300], Step [205/225], Training Accuracy: 65.7927%, Training Loss: 0.8049%\n",
      "Epoch [18/300], Step [206/225], Training Accuracy: 65.7767%, Training Loss: 0.8048%\n",
      "Epoch [18/300], Step [207/225], Training Accuracy: 65.8439%, Training Loss: 0.8037%\n",
      "Epoch [18/300], Step [208/225], Training Accuracy: 65.8428%, Training Loss: 0.8033%\n",
      "Epoch [18/300], Step [209/225], Training Accuracy: 65.8493%, Training Loss: 0.8031%\n",
      "Epoch [18/300], Step [210/225], Training Accuracy: 65.8259%, Training Loss: 0.8034%\n",
      "Epoch [18/300], Step [211/225], Training Accuracy: 65.8249%, Training Loss: 0.8030%\n",
      "Epoch [18/300], Step [212/225], Training Accuracy: 65.8093%, Training Loss: 0.8038%\n",
      "Epoch [18/300], Step [213/225], Training Accuracy: 65.7864%, Training Loss: 0.8042%\n",
      "Epoch [18/300], Step [214/225], Training Accuracy: 65.7491%, Training Loss: 0.8045%\n",
      "Epoch [18/300], Step [215/225], Training Accuracy: 65.7413%, Training Loss: 0.8042%\n",
      "Epoch [18/300], Step [216/225], Training Accuracy: 65.7407%, Training Loss: 0.8049%\n",
      "Epoch [18/300], Step [217/225], Training Accuracy: 65.7330%, Training Loss: 0.8048%\n",
      "Epoch [18/300], Step [218/225], Training Accuracy: 65.7038%, Training Loss: 0.8051%\n",
      "Epoch [18/300], Step [219/225], Training Accuracy: 65.7035%, Training Loss: 0.8049%\n",
      "Epoch [18/300], Step [220/225], Training Accuracy: 65.7599%, Training Loss: 0.8043%\n",
      "Epoch [18/300], Step [221/225], Training Accuracy: 65.7523%, Training Loss: 0.8050%\n",
      "Epoch [18/300], Step [222/225], Training Accuracy: 65.6954%, Training Loss: 0.8054%\n",
      "Epoch [18/300], Step [223/225], Training Accuracy: 65.6740%, Training Loss: 0.8054%\n",
      "Epoch [18/300], Step [224/225], Training Accuracy: 65.6808%, Training Loss: 0.8052%\n",
      "Epoch [18/300], Step [225/225], Training Accuracy: 65.6545%, Training Loss: 0.8051%\n",
      "Epoch [19/300], Step [1/225], Training Accuracy: 62.5000%, Training Loss: 0.9248%\n",
      "Epoch [19/300], Step [2/225], Training Accuracy: 67.1875%, Training Loss: 0.8150%\n",
      "Epoch [19/300], Step [3/225], Training Accuracy: 63.5417%, Training Loss: 0.8547%\n",
      "Epoch [19/300], Step [4/225], Training Accuracy: 68.7500%, Training Loss: 0.7931%\n",
      "Epoch [19/300], Step [5/225], Training Accuracy: 69.6875%, Training Loss: 0.7764%\n",
      "Epoch [19/300], Step [6/225], Training Accuracy: 68.4896%, Training Loss: 0.7879%\n",
      "Epoch [19/300], Step [7/225], Training Accuracy: 67.8571%, Training Loss: 0.8057%\n",
      "Epoch [19/300], Step [8/225], Training Accuracy: 67.3828%, Training Loss: 0.8000%\n",
      "Epoch [19/300], Step [9/225], Training Accuracy: 67.0139%, Training Loss: 0.8001%\n",
      "Epoch [19/300], Step [10/225], Training Accuracy: 66.8750%, Training Loss: 0.8038%\n",
      "Epoch [19/300], Step [11/225], Training Accuracy: 67.3295%, Training Loss: 0.7937%\n",
      "Epoch [19/300], Step [12/225], Training Accuracy: 67.3177%, Training Loss: 0.7912%\n",
      "Epoch [19/300], Step [13/225], Training Accuracy: 67.3077%, Training Loss: 0.7920%\n",
      "Epoch [19/300], Step [14/225], Training Accuracy: 67.1875%, Training Loss: 0.7992%\n",
      "Epoch [19/300], Step [15/225], Training Accuracy: 66.8750%, Training Loss: 0.7967%\n",
      "Epoch [19/300], Step [16/225], Training Accuracy: 66.1133%, Training Loss: 0.8078%\n",
      "Epoch [19/300], Step [17/225], Training Accuracy: 66.4522%, Training Loss: 0.8079%\n",
      "Epoch [19/300], Step [18/225], Training Accuracy: 66.4931%, Training Loss: 0.8101%\n",
      "Epoch [19/300], Step [19/225], Training Accuracy: 66.6941%, Training Loss: 0.8050%\n",
      "Epoch [19/300], Step [20/225], Training Accuracy: 66.9531%, Training Loss: 0.8002%\n",
      "Epoch [19/300], Step [21/225], Training Accuracy: 67.4107%, Training Loss: 0.7946%\n",
      "Epoch [19/300], Step [22/225], Training Accuracy: 67.4006%, Training Loss: 0.7943%\n",
      "Epoch [19/300], Step [23/225], Training Accuracy: 67.1196%, Training Loss: 0.7981%\n",
      "Epoch [19/300], Step [24/225], Training Accuracy: 66.9271%, Training Loss: 0.8029%\n",
      "Epoch [19/300], Step [25/225], Training Accuracy: 67.1250%, Training Loss: 0.8004%\n",
      "Epoch [19/300], Step [26/225], Training Accuracy: 67.0072%, Training Loss: 0.8023%\n",
      "Epoch [19/300], Step [27/225], Training Accuracy: 66.9560%, Training Loss: 0.8034%\n",
      "Epoch [19/300], Step [28/225], Training Accuracy: 67.2991%, Training Loss: 0.7981%\n",
      "Epoch [19/300], Step [29/225], Training Accuracy: 67.0797%, Training Loss: 0.7969%\n",
      "Epoch [19/300], Step [30/225], Training Accuracy: 67.3438%, Training Loss: 0.7944%\n",
      "Epoch [19/300], Step [31/225], Training Accuracy: 67.4395%, Training Loss: 0.7959%\n",
      "Epoch [19/300], Step [32/225], Training Accuracy: 67.5781%, Training Loss: 0.7917%\n",
      "Epoch [19/300], Step [33/225], Training Accuracy: 67.6136%, Training Loss: 0.7884%\n",
      "Epoch [19/300], Step [34/225], Training Accuracy: 67.6011%, Training Loss: 0.7883%\n",
      "Epoch [19/300], Step [35/225], Training Accuracy: 67.6786%, Training Loss: 0.7889%\n",
      "Epoch [19/300], Step [36/225], Training Accuracy: 67.9253%, Training Loss: 0.7866%\n",
      "Epoch [19/300], Step [37/225], Training Accuracy: 67.8209%, Training Loss: 0.7887%\n",
      "Epoch [19/300], Step [38/225], Training Accuracy: 68.0099%, Training Loss: 0.7859%\n",
      "Epoch [19/300], Step [39/225], Training Accuracy: 68.2292%, Training Loss: 0.7824%\n",
      "Epoch [19/300], Step [40/225], Training Accuracy: 68.3203%, Training Loss: 0.7801%\n",
      "Epoch [19/300], Step [41/225], Training Accuracy: 68.1021%, Training Loss: 0.7797%\n",
      "Epoch [19/300], Step [42/225], Training Accuracy: 68.1176%, Training Loss: 0.7785%\n",
      "Epoch [19/300], Step [43/225], Training Accuracy: 68.1686%, Training Loss: 0.7775%\n",
      "Epoch [19/300], Step [44/225], Training Accuracy: 68.1108%, Training Loss: 0.7776%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/300], Step [45/225], Training Accuracy: 68.1597%, Training Loss: 0.7775%\n",
      "Epoch [19/300], Step [46/225], Training Accuracy: 68.2745%, Training Loss: 0.7760%\n",
      "Epoch [19/300], Step [47/225], Training Accuracy: 68.2846%, Training Loss: 0.7765%\n",
      "Epoch [19/300], Step [48/225], Training Accuracy: 68.1641%, Training Loss: 0.7785%\n",
      "Epoch [19/300], Step [49/225], Training Accuracy: 68.1122%, Training Loss: 0.7787%\n",
      "Epoch [19/300], Step [50/225], Training Accuracy: 68.0625%, Training Loss: 0.7795%\n",
      "Epoch [19/300], Step [51/225], Training Accuracy: 68.1679%, Training Loss: 0.7790%\n",
      "Epoch [19/300], Step [52/225], Training Accuracy: 68.1490%, Training Loss: 0.7769%\n",
      "Epoch [19/300], Step [53/225], Training Accuracy: 67.9540%, Training Loss: 0.7777%\n",
      "Epoch [19/300], Step [54/225], Training Accuracy: 67.8241%, Training Loss: 0.7811%\n",
      "Epoch [19/300], Step [55/225], Training Accuracy: 67.9545%, Training Loss: 0.7813%\n",
      "Epoch [19/300], Step [56/225], Training Accuracy: 67.9408%, Training Loss: 0.7813%\n",
      "Epoch [19/300], Step [57/225], Training Accuracy: 67.8180%, Training Loss: 0.7832%\n",
      "Epoch [19/300], Step [58/225], Training Accuracy: 67.6724%, Training Loss: 0.7856%\n",
      "Epoch [19/300], Step [59/225], Training Accuracy: 67.6642%, Training Loss: 0.7862%\n",
      "Epoch [19/300], Step [60/225], Training Accuracy: 67.7344%, Training Loss: 0.7845%\n",
      "Epoch [19/300], Step [61/225], Training Accuracy: 67.7510%, Training Loss: 0.7846%\n",
      "Epoch [19/300], Step [62/225], Training Accuracy: 67.6915%, Training Loss: 0.7868%\n",
      "Epoch [19/300], Step [63/225], Training Accuracy: 67.6091%, Training Loss: 0.7890%\n",
      "Epoch [19/300], Step [64/225], Training Accuracy: 67.6270%, Training Loss: 0.7888%\n",
      "Epoch [19/300], Step [65/225], Training Accuracy: 67.6442%, Training Loss: 0.7875%\n",
      "Epoch [19/300], Step [66/225], Training Accuracy: 67.5663%, Training Loss: 0.7883%\n",
      "Epoch [19/300], Step [67/225], Training Accuracy: 67.3741%, Training Loss: 0.7900%\n",
      "Epoch [19/300], Step [68/225], Training Accuracy: 67.3713%, Training Loss: 0.7905%\n",
      "Epoch [19/300], Step [69/225], Training Accuracy: 67.4366%, Training Loss: 0.7894%\n",
      "Epoch [19/300], Step [70/225], Training Accuracy: 67.4330%, Training Loss: 0.7879%\n",
      "Epoch [19/300], Step [71/225], Training Accuracy: 67.4296%, Training Loss: 0.7870%\n",
      "Epoch [19/300], Step [72/225], Training Accuracy: 67.3828%, Training Loss: 0.7878%\n",
      "Epoch [19/300], Step [73/225], Training Accuracy: 67.3159%, Training Loss: 0.7906%\n",
      "Epoch [19/300], Step [74/225], Training Accuracy: 67.3986%, Training Loss: 0.7893%\n",
      "Epoch [19/300], Step [75/225], Training Accuracy: 67.5000%, Training Loss: 0.7872%\n",
      "Epoch [19/300], Step [76/225], Training Accuracy: 67.4342%, Training Loss: 0.7882%\n",
      "Epoch [19/300], Step [77/225], Training Accuracy: 67.4310%, Training Loss: 0.7887%\n",
      "Epoch [19/300], Step [78/225], Training Accuracy: 67.5080%, Training Loss: 0.7876%\n",
      "Epoch [19/300], Step [79/225], Training Accuracy: 67.3853%, Training Loss: 0.7901%\n",
      "Epoch [19/300], Step [80/225], Training Accuracy: 67.2656%, Training Loss: 0.7925%\n",
      "Epoch [19/300], Step [81/225], Training Accuracy: 67.3032%, Training Loss: 0.7921%\n",
      "Epoch [19/300], Step [82/225], Training Accuracy: 67.2828%, Training Loss: 0.7915%\n",
      "Epoch [19/300], Step [83/225], Training Accuracy: 67.2628%, Training Loss: 0.7917%\n",
      "Epoch [19/300], Step [84/225], Training Accuracy: 67.1503%, Training Loss: 0.7927%\n",
      "Epoch [19/300], Step [85/225], Training Accuracy: 67.0588%, Training Loss: 0.7938%\n",
      "Epoch [19/300], Step [86/225], Training Accuracy: 67.0967%, Training Loss: 0.7924%\n",
      "Epoch [19/300], Step [87/225], Training Accuracy: 67.1516%, Training Loss: 0.7907%\n",
      "Epoch [19/300], Step [88/225], Training Accuracy: 67.1342%, Training Loss: 0.7904%\n",
      "Epoch [19/300], Step [89/225], Training Accuracy: 67.2226%, Training Loss: 0.7887%\n",
      "Epoch [19/300], Step [90/225], Training Accuracy: 67.2049%, Training Loss: 0.7878%\n",
      "Epoch [19/300], Step [91/225], Training Accuracy: 67.1875%, Training Loss: 0.7877%\n",
      "Epoch [19/300], Step [92/225], Training Accuracy: 67.1875%, Training Loss: 0.7884%\n",
      "Epoch [19/300], Step [93/225], Training Accuracy: 67.1875%, Training Loss: 0.7884%\n",
      "Epoch [19/300], Step [94/225], Training Accuracy: 67.2207%, Training Loss: 0.7870%\n",
      "Epoch [19/300], Step [95/225], Training Accuracy: 67.2039%, Training Loss: 0.7875%\n",
      "Epoch [19/300], Step [96/225], Training Accuracy: 67.3177%, Training Loss: 0.7859%\n",
      "Epoch [19/300], Step [97/225], Training Accuracy: 67.4130%, Training Loss: 0.7858%\n",
      "Epoch [19/300], Step [98/225], Training Accuracy: 67.5064%, Training Loss: 0.7845%\n",
      "Epoch [19/300], Step [99/225], Training Accuracy: 67.5663%, Training Loss: 0.7845%\n",
      "Epoch [19/300], Step [100/225], Training Accuracy: 67.4688%, Training Loss: 0.7847%\n",
      "Epoch [19/300], Step [101/225], Training Accuracy: 67.4505%, Training Loss: 0.7851%\n",
      "Epoch [19/300], Step [102/225], Training Accuracy: 67.4326%, Training Loss: 0.7856%\n",
      "Epoch [19/300], Step [103/225], Training Accuracy: 67.3240%, Training Loss: 0.7871%\n",
      "Epoch [19/300], Step [104/225], Training Accuracy: 67.2326%, Training Loss: 0.7882%\n",
      "Epoch [19/300], Step [105/225], Training Accuracy: 67.2768%, Training Loss: 0.7882%\n",
      "Epoch [19/300], Step [106/225], Training Accuracy: 67.2465%, Training Loss: 0.7886%\n",
      "Epoch [19/300], Step [107/225], Training Accuracy: 67.2605%, Training Loss: 0.7883%\n",
      "Epoch [19/300], Step [108/225], Training Accuracy: 67.2454%, Training Loss: 0.7885%\n",
      "Epoch [19/300], Step [109/225], Training Accuracy: 67.1732%, Training Loss: 0.7901%\n",
      "Epoch [19/300], Step [110/225], Training Accuracy: 67.2443%, Training Loss: 0.7887%\n",
      "Epoch [19/300], Step [111/225], Training Accuracy: 67.2720%, Training Loss: 0.7883%\n",
      "Epoch [19/300], Step [112/225], Training Accuracy: 67.3131%, Training Loss: 0.7874%\n",
      "Epoch [19/300], Step [113/225], Training Accuracy: 67.2428%, Training Loss: 0.7889%\n",
      "Epoch [19/300], Step [114/225], Training Accuracy: 67.2286%, Training Loss: 0.7885%\n",
      "Epoch [19/300], Step [115/225], Training Accuracy: 67.1875%, Training Loss: 0.7897%\n",
      "Epoch [19/300], Step [116/225], Training Accuracy: 67.1875%, Training Loss: 0.7899%\n",
      "Epoch [19/300], Step [117/225], Training Accuracy: 67.2409%, Training Loss: 0.7889%\n",
      "Epoch [19/300], Step [118/225], Training Accuracy: 67.1610%, Training Loss: 0.7904%\n",
      "Epoch [19/300], Step [119/225], Training Accuracy: 67.1350%, Training Loss: 0.7911%\n",
      "Epoch [19/300], Step [120/225], Training Accuracy: 67.1615%, Training Loss: 0.7907%\n",
      "Epoch [19/300], Step [121/225], Training Accuracy: 67.2133%, Training Loss: 0.7905%\n",
      "Epoch [19/300], Step [122/225], Training Accuracy: 67.2387%, Training Loss: 0.7904%\n",
      "Epoch [19/300], Step [123/225], Training Accuracy: 67.2129%, Training Loss: 0.7904%\n",
      "Epoch [19/300], Step [124/225], Training Accuracy: 67.2505%, Training Loss: 0.7894%\n",
      "Epoch [19/300], Step [125/225], Training Accuracy: 67.2875%, Training Loss: 0.7888%\n",
      "Epoch [19/300], Step [126/225], Training Accuracy: 67.3239%, Training Loss: 0.7884%\n",
      "Epoch [19/300], Step [127/225], Training Accuracy: 67.2859%, Training Loss: 0.7888%\n",
      "Epoch [19/300], Step [128/225], Training Accuracy: 67.2119%, Training Loss: 0.7894%\n",
      "Epoch [19/300], Step [129/225], Training Accuracy: 67.2844%, Training Loss: 0.7886%\n",
      "Epoch [19/300], Step [130/225], Training Accuracy: 67.2115%, Training Loss: 0.7889%\n",
      "Epoch [19/300], Step [131/225], Training Accuracy: 67.1994%, Training Loss: 0.7892%\n",
      "Epoch [19/300], Step [132/225], Training Accuracy: 67.2467%, Training Loss: 0.7888%\n",
      "Epoch [19/300], Step [133/225], Training Accuracy: 67.3167%, Training Loss: 0.7873%\n",
      "Epoch [19/300], Step [134/225], Training Accuracy: 67.2575%, Training Loss: 0.7882%\n",
      "Epoch [19/300], Step [135/225], Training Accuracy: 67.3032%, Training Loss: 0.7867%\n",
      "Epoch [19/300], Step [136/225], Training Accuracy: 67.3254%, Training Loss: 0.7864%\n",
      "Epoch [19/300], Step [137/225], Training Accuracy: 67.3358%, Training Loss: 0.7861%\n",
      "Epoch [19/300], Step [138/225], Training Accuracy: 67.3800%, Training Loss: 0.7858%\n",
      "Epoch [19/300], Step [139/225], Training Accuracy: 67.3336%, Training Loss: 0.7856%\n",
      "Epoch [19/300], Step [140/225], Training Accuracy: 67.3103%, Training Loss: 0.7855%\n",
      "Epoch [19/300], Step [141/225], Training Accuracy: 67.3205%, Training Loss: 0.7858%\n",
      "Epoch [19/300], Step [142/225], Training Accuracy: 67.3305%, Training Loss: 0.7854%\n",
      "Epoch [19/300], Step [143/225], Training Accuracy: 67.2858%, Training Loss: 0.7861%\n",
      "Epoch [19/300], Step [144/225], Training Accuracy: 67.3177%, Training Loss: 0.7854%\n",
      "Epoch [19/300], Step [145/225], Training Accuracy: 67.3168%, Training Loss: 0.7856%\n",
      "Epoch [19/300], Step [146/225], Training Accuracy: 67.2731%, Training Loss: 0.7859%\n",
      "Epoch [19/300], Step [147/225], Training Accuracy: 67.2088%, Training Loss: 0.7867%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/300], Step [148/225], Training Accuracy: 67.2403%, Training Loss: 0.7860%\n",
      "Epoch [19/300], Step [149/225], Training Accuracy: 67.2714%, Training Loss: 0.7855%\n",
      "Epoch [19/300], Step [150/225], Training Accuracy: 67.3333%, Training Loss: 0.7842%\n",
      "Epoch [19/300], Step [151/225], Training Accuracy: 67.3841%, Training Loss: 0.7833%\n",
      "Epoch [19/300], Step [152/225], Training Accuracy: 67.4239%, Training Loss: 0.7827%\n",
      "Epoch [19/300], Step [153/225], Training Accuracy: 67.4530%, Training Loss: 0.7819%\n",
      "Epoch [19/300], Step [154/225], Training Accuracy: 67.4817%, Training Loss: 0.7814%\n",
      "Epoch [19/300], Step [155/225], Training Accuracy: 67.5403%, Training Loss: 0.7810%\n",
      "Epoch [19/300], Step [156/225], Training Accuracy: 67.5381%, Training Loss: 0.7816%\n",
      "Epoch [19/300], Step [157/225], Training Accuracy: 67.5657%, Training Loss: 0.7812%\n",
      "Epoch [19/300], Step [158/225], Training Accuracy: 67.5930%, Training Loss: 0.7808%\n",
      "Epoch [19/300], Step [159/225], Training Accuracy: 67.6297%, Training Loss: 0.7800%\n",
      "Epoch [19/300], Step [160/225], Training Accuracy: 67.6270%, Training Loss: 0.7801%\n",
      "Epoch [19/300], Step [161/225], Training Accuracy: 67.6436%, Training Loss: 0.7795%\n",
      "Epoch [19/300], Step [162/225], Training Accuracy: 67.6794%, Training Loss: 0.7791%\n",
      "Epoch [19/300], Step [163/225], Training Accuracy: 67.7531%, Training Loss: 0.7781%\n",
      "Epoch [19/300], Step [164/225], Training Accuracy: 67.7877%, Training Loss: 0.7775%\n",
      "Epoch [19/300], Step [165/225], Training Accuracy: 67.8030%, Training Loss: 0.7776%\n",
      "Epoch [19/300], Step [166/225], Training Accuracy: 67.7899%, Training Loss: 0.7774%\n",
      "Epoch [19/300], Step [167/225], Training Accuracy: 67.7957%, Training Loss: 0.7771%\n",
      "Epoch [19/300], Step [168/225], Training Accuracy: 67.7641%, Training Loss: 0.7770%\n",
      "Epoch [19/300], Step [169/225], Training Accuracy: 67.7422%, Training Loss: 0.7773%\n",
      "Epoch [19/300], Step [170/225], Training Accuracy: 67.7390%, Training Loss: 0.7770%\n",
      "Epoch [19/300], Step [171/225], Training Accuracy: 67.7357%, Training Loss: 0.7771%\n",
      "Epoch [19/300], Step [172/225], Training Accuracy: 67.7326%, Training Loss: 0.7770%\n",
      "Epoch [19/300], Step [173/225], Training Accuracy: 67.6662%, Training Loss: 0.7775%\n",
      "Epoch [19/300], Step [174/225], Training Accuracy: 67.6634%, Training Loss: 0.7771%\n",
      "Epoch [19/300], Step [175/225], Training Accuracy: 67.7143%, Training Loss: 0.7759%\n",
      "Epoch [19/300], Step [176/225], Training Accuracy: 67.6847%, Training Loss: 0.7764%\n",
      "Epoch [19/300], Step [177/225], Training Accuracy: 67.7083%, Training Loss: 0.7760%\n",
      "Epoch [19/300], Step [178/225], Training Accuracy: 67.6791%, Training Loss: 0.7763%\n",
      "Epoch [19/300], Step [179/225], Training Accuracy: 67.6676%, Training Loss: 0.7765%\n",
      "Epoch [19/300], Step [180/225], Training Accuracy: 67.6562%, Training Loss: 0.7766%\n",
      "Epoch [19/300], Step [181/225], Training Accuracy: 67.6364%, Training Loss: 0.7774%\n",
      "Epoch [19/300], Step [182/225], Training Accuracy: 67.6597%, Training Loss: 0.7770%\n",
      "Epoch [19/300], Step [183/225], Training Accuracy: 67.6486%, Training Loss: 0.7766%\n",
      "Epoch [19/300], Step [184/225], Training Accuracy: 67.5696%, Training Loss: 0.7775%\n",
      "Epoch [19/300], Step [185/225], Training Accuracy: 67.6014%, Training Loss: 0.7775%\n",
      "Epoch [19/300], Step [186/225], Training Accuracy: 67.6159%, Training Loss: 0.7768%\n",
      "Epoch [19/300], Step [187/225], Training Accuracy: 67.6136%, Training Loss: 0.7767%\n",
      "Epoch [19/300], Step [188/225], Training Accuracy: 67.6114%, Training Loss: 0.7760%\n",
      "Epoch [19/300], Step [189/225], Training Accuracy: 67.6505%, Training Loss: 0.7755%\n",
      "Epoch [19/300], Step [190/225], Training Accuracy: 67.6562%, Training Loss: 0.7749%\n",
      "Epoch [19/300], Step [191/225], Training Accuracy: 67.6456%, Training Loss: 0.7744%\n",
      "Epoch [19/300], Step [192/225], Training Accuracy: 67.6270%, Training Loss: 0.7748%\n",
      "Epoch [19/300], Step [193/225], Training Accuracy: 67.6166%, Training Loss: 0.7750%\n",
      "Epoch [19/300], Step [194/225], Training Accuracy: 67.6788%, Training Loss: 0.7738%\n",
      "Epoch [19/300], Step [195/225], Training Accuracy: 67.6763%, Training Loss: 0.7738%\n",
      "Epoch [19/300], Step [196/225], Training Accuracy: 67.7296%, Training Loss: 0.7730%\n",
      "Epoch [19/300], Step [197/225], Training Accuracy: 67.7030%, Training Loss: 0.7740%\n",
      "Epoch [19/300], Step [198/225], Training Accuracy: 67.7004%, Training Loss: 0.7740%\n",
      "Epoch [19/300], Step [199/225], Training Accuracy: 67.6900%, Training Loss: 0.7745%\n",
      "Epoch [19/300], Step [200/225], Training Accuracy: 67.7109%, Training Loss: 0.7740%\n",
      "Epoch [19/300], Step [201/225], Training Accuracy: 67.7394%, Training Loss: 0.7737%\n",
      "Epoch [19/300], Step [202/225], Training Accuracy: 67.7135%, Training Loss: 0.7738%\n",
      "Epoch [19/300], Step [203/225], Training Accuracy: 67.7571%, Training Loss: 0.7734%\n",
      "Epoch [19/300], Step [204/225], Training Accuracy: 67.7619%, Training Loss: 0.7734%\n",
      "Epoch [19/300], Step [205/225], Training Accuracy: 67.7591%, Training Loss: 0.7735%\n",
      "Epoch [19/300], Step [206/225], Training Accuracy: 67.7564%, Training Loss: 0.7734%\n",
      "Epoch [19/300], Step [207/225], Training Accuracy: 67.8140%, Training Loss: 0.7723%\n",
      "Epoch [19/300], Step [208/225], Training Accuracy: 67.8410%, Training Loss: 0.7718%\n",
      "Epoch [19/300], Step [209/225], Training Accuracy: 67.8155%, Training Loss: 0.7719%\n",
      "Epoch [19/300], Step [210/225], Training Accuracy: 67.7753%, Training Loss: 0.7726%\n",
      "Epoch [19/300], Step [211/225], Training Accuracy: 67.7799%, Training Loss: 0.7724%\n",
      "Epoch [19/300], Step [212/225], Training Accuracy: 67.7476%, Training Loss: 0.7732%\n",
      "Epoch [19/300], Step [213/225], Training Accuracy: 67.7303%, Training Loss: 0.7735%\n",
      "Epoch [19/300], Step [214/225], Training Accuracy: 67.6986%, Training Loss: 0.7742%\n",
      "Epoch [19/300], Step [215/225], Training Accuracy: 67.7398%, Training Loss: 0.7737%\n",
      "Epoch [19/300], Step [216/225], Training Accuracy: 67.7011%, Training Loss: 0.7743%\n",
      "Epoch [19/300], Step [217/225], Training Accuracy: 67.7347%, Training Loss: 0.7738%\n",
      "Epoch [19/300], Step [218/225], Training Accuracy: 67.7107%, Training Loss: 0.7743%\n",
      "Epoch [19/300], Step [219/225], Training Accuracy: 67.7297%, Training Loss: 0.7741%\n",
      "Epoch [19/300], Step [220/225], Training Accuracy: 67.7486%, Training Loss: 0.7735%\n",
      "Epoch [19/300], Step [221/225], Training Accuracy: 67.7460%, Training Loss: 0.7737%\n",
      "Epoch [19/300], Step [222/225], Training Accuracy: 67.7435%, Training Loss: 0.7734%\n",
      "Epoch [19/300], Step [223/225], Training Accuracy: 67.7831%, Training Loss: 0.7734%\n",
      "Epoch [19/300], Step [224/225], Training Accuracy: 67.8013%, Training Loss: 0.7729%\n",
      "Epoch [19/300], Step [225/225], Training Accuracy: 67.8155%, Training Loss: 0.7727%\n",
      "Epoch [20/300], Step [1/225], Training Accuracy: 60.9375%, Training Loss: 0.8020%\n",
      "Epoch [20/300], Step [2/225], Training Accuracy: 61.7188%, Training Loss: 0.7736%\n",
      "Epoch [20/300], Step [3/225], Training Accuracy: 58.8542%, Training Loss: 0.8586%\n",
      "Epoch [20/300], Step [4/225], Training Accuracy: 64.0625%, Training Loss: 0.7898%\n",
      "Epoch [20/300], Step [5/225], Training Accuracy: 67.1875%, Training Loss: 0.7674%\n",
      "Epoch [20/300], Step [6/225], Training Accuracy: 65.1042%, Training Loss: 0.7932%\n",
      "Epoch [20/300], Step [7/225], Training Accuracy: 64.9554%, Training Loss: 0.8081%\n",
      "Epoch [20/300], Step [8/225], Training Accuracy: 65.0391%, Training Loss: 0.7985%\n",
      "Epoch [20/300], Step [9/225], Training Accuracy: 65.9722%, Training Loss: 0.7835%\n",
      "Epoch [20/300], Step [10/225], Training Accuracy: 66.5625%, Training Loss: 0.7864%\n",
      "Epoch [20/300], Step [11/225], Training Accuracy: 67.6136%, Training Loss: 0.7711%\n",
      "Epoch [20/300], Step [12/225], Training Accuracy: 67.1875%, Training Loss: 0.7760%\n",
      "Epoch [20/300], Step [13/225], Training Accuracy: 67.7885%, Training Loss: 0.7686%\n",
      "Epoch [20/300], Step [14/225], Training Accuracy: 66.9643%, Training Loss: 0.7825%\n",
      "Epoch [20/300], Step [15/225], Training Accuracy: 67.1875%, Training Loss: 0.7782%\n",
      "Epoch [20/300], Step [16/225], Training Accuracy: 66.4062%, Training Loss: 0.7889%\n",
      "Epoch [20/300], Step [17/225], Training Accuracy: 66.4522%, Training Loss: 0.7933%\n",
      "Epoch [20/300], Step [18/225], Training Accuracy: 66.3194%, Training Loss: 0.7936%\n",
      "Epoch [20/300], Step [19/225], Training Accuracy: 66.2007%, Training Loss: 0.7931%\n",
      "Epoch [20/300], Step [20/225], Training Accuracy: 66.0938%, Training Loss: 0.7918%\n",
      "Epoch [20/300], Step [21/225], Training Accuracy: 66.5923%, Training Loss: 0.7839%\n",
      "Epoch [20/300], Step [22/225], Training Accuracy: 66.6193%, Training Loss: 0.7857%\n",
      "Epoch [20/300], Step [23/225], Training Accuracy: 66.5761%, Training Loss: 0.7874%\n",
      "Epoch [20/300], Step [24/225], Training Accuracy: 66.4714%, Training Loss: 0.7953%\n",
      "Epoch [20/300], Step [25/225], Training Accuracy: 66.3750%, Training Loss: 0.7931%\n",
      "Epoch [20/300], Step [26/225], Training Accuracy: 66.3462%, Training Loss: 0.7930%\n",
      "Epoch [20/300], Step [27/225], Training Accuracy: 66.4931%, Training Loss: 0.7914%\n",
      "Epoch [20/300], Step [28/225], Training Accuracy: 66.5737%, Training Loss: 0.7869%\n",
      "Epoch [20/300], Step [29/225], Training Accuracy: 66.7026%, Training Loss: 0.7823%\n",
      "Epoch [20/300], Step [30/225], Training Accuracy: 66.5104%, Training Loss: 0.7847%\n",
      "Epoch [20/300], Step [31/225], Training Accuracy: 66.4819%, Training Loss: 0.7858%\n",
      "Epoch [20/300], Step [32/225], Training Accuracy: 66.6992%, Training Loss: 0.7818%\n",
      "Epoch [20/300], Step [33/225], Training Accuracy: 66.9034%, Training Loss: 0.7779%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/300], Step [34/225], Training Accuracy: 66.8199%, Training Loss: 0.7770%\n",
      "Epoch [20/300], Step [35/225], Training Accuracy: 67.0536%, Training Loss: 0.7737%\n",
      "Epoch [20/300], Step [36/225], Training Accuracy: 66.7969%, Training Loss: 0.7765%\n",
      "Epoch [20/300], Step [37/225], Training Accuracy: 66.9341%, Training Loss: 0.7766%\n",
      "Epoch [20/300], Step [38/225], Training Accuracy: 67.1464%, Training Loss: 0.7741%\n",
      "Epoch [20/300], Step [39/225], Training Accuracy: 67.1474%, Training Loss: 0.7716%\n",
      "Epoch [20/300], Step [40/225], Training Accuracy: 67.0312%, Training Loss: 0.7713%\n",
      "Epoch [20/300], Step [41/225], Training Accuracy: 67.1113%, Training Loss: 0.7682%\n",
      "Epoch [20/300], Step [42/225], Training Accuracy: 67.2991%, Training Loss: 0.7647%\n",
      "Epoch [20/300], Step [43/225], Training Accuracy: 67.3692%, Training Loss: 0.7645%\n",
      "Epoch [20/300], Step [44/225], Training Accuracy: 67.1165%, Training Loss: 0.7677%\n",
      "Epoch [20/300], Step [45/225], Training Accuracy: 67.2569%, Training Loss: 0.7666%\n",
      "Epoch [20/300], Step [46/225], Training Accuracy: 67.4253%, Training Loss: 0.7644%\n",
      "Epoch [20/300], Step [47/225], Training Accuracy: 67.6197%, Training Loss: 0.7621%\n",
      "Epoch [20/300], Step [48/225], Training Accuracy: 67.5130%, Training Loss: 0.7641%\n",
      "Epoch [20/300], Step [49/225], Training Accuracy: 67.6339%, Training Loss: 0.7635%\n",
      "Epoch [20/300], Step [50/225], Training Accuracy: 67.5312%, Training Loss: 0.7643%\n",
      "Epoch [20/300], Step [51/225], Training Accuracy: 67.6164%, Training Loss: 0.7631%\n",
      "Epoch [20/300], Step [52/225], Training Accuracy: 67.7584%, Training Loss: 0.7605%\n",
      "Epoch [20/300], Step [53/225], Training Accuracy: 67.7476%, Training Loss: 0.7606%\n",
      "Epoch [20/300], Step [54/225], Training Accuracy: 67.7373%, Training Loss: 0.7621%\n",
      "Epoch [20/300], Step [55/225], Training Accuracy: 67.8409%, Training Loss: 0.7602%\n",
      "Epoch [20/300], Step [56/225], Training Accuracy: 67.8013%, Training Loss: 0.7606%\n",
      "Epoch [20/300], Step [57/225], Training Accuracy: 67.8728%, Training Loss: 0.7599%\n",
      "Epoch [20/300], Step [58/225], Training Accuracy: 67.8071%, Training Loss: 0.7607%\n",
      "Epoch [20/300], Step [59/225], Training Accuracy: 67.8231%, Training Loss: 0.7612%\n",
      "Epoch [20/300], Step [60/225], Training Accuracy: 67.8646%, Training Loss: 0.7599%\n",
      "Epoch [20/300], Step [61/225], Training Accuracy: 67.7510%, Training Loss: 0.7596%\n",
      "Epoch [20/300], Step [62/225], Training Accuracy: 67.6915%, Training Loss: 0.7607%\n",
      "Epoch [20/300], Step [63/225], Training Accuracy: 67.6091%, Training Loss: 0.7635%\n",
      "Epoch [20/300], Step [64/225], Training Accuracy: 67.5781%, Training Loss: 0.7648%\n",
      "Epoch [20/300], Step [65/225], Training Accuracy: 67.5721%, Training Loss: 0.7640%\n",
      "Epoch [20/300], Step [66/225], Training Accuracy: 67.6610%, Training Loss: 0.7639%\n",
      "Epoch [20/300], Step [67/225], Training Accuracy: 67.6306%, Training Loss: 0.7645%\n",
      "Epoch [20/300], Step [68/225], Training Accuracy: 67.4862%, Training Loss: 0.7662%\n",
      "Epoch [20/300], Step [69/225], Training Accuracy: 67.5951%, Training Loss: 0.7651%\n",
      "Epoch [20/300], Step [70/225], Training Accuracy: 67.7009%, Training Loss: 0.7633%\n",
      "Epoch [20/300], Step [71/225], Training Accuracy: 67.6496%, Training Loss: 0.7621%\n",
      "Epoch [20/300], Step [72/225], Training Accuracy: 67.6649%, Training Loss: 0.7625%\n",
      "Epoch [20/300], Step [73/225], Training Accuracy: 67.5514%, Training Loss: 0.7651%\n",
      "Epoch [20/300], Step [74/225], Training Accuracy: 67.4620%, Training Loss: 0.7643%\n",
      "Epoch [20/300], Step [75/225], Training Accuracy: 67.5625%, Training Loss: 0.7622%\n",
      "Epoch [20/300], Step [76/225], Training Accuracy: 67.5987%, Training Loss: 0.7624%\n",
      "Epoch [20/300], Step [77/225], Training Accuracy: 67.7151%, Training Loss: 0.7623%\n",
      "Epoch [20/300], Step [78/225], Training Accuracy: 67.7083%, Training Loss: 0.7614%\n",
      "Epoch [20/300], Step [79/225], Training Accuracy: 67.5633%, Training Loss: 0.7636%\n",
      "Epoch [20/300], Step [80/225], Training Accuracy: 67.4609%, Training Loss: 0.7652%\n",
      "Epoch [20/300], Step [81/225], Training Accuracy: 67.3997%, Training Loss: 0.7655%\n",
      "Epoch [20/300], Step [82/225], Training Accuracy: 67.4162%, Training Loss: 0.7652%\n",
      "Epoch [20/300], Step [83/225], Training Accuracy: 67.4322%, Training Loss: 0.7646%\n",
      "Epoch [20/300], Step [84/225], Training Accuracy: 67.4479%, Training Loss: 0.7642%\n",
      "Epoch [20/300], Step [85/225], Training Accuracy: 67.4265%, Training Loss: 0.7644%\n",
      "Epoch [20/300], Step [86/225], Training Accuracy: 67.4782%, Training Loss: 0.7634%\n",
      "Epoch [20/300], Step [87/225], Training Accuracy: 67.5108%, Training Loss: 0.7626%\n",
      "Epoch [20/300], Step [88/225], Training Accuracy: 67.6136%, Training Loss: 0.7614%\n",
      "Epoch [20/300], Step [89/225], Training Accuracy: 67.6088%, Training Loss: 0.7608%\n",
      "Epoch [20/300], Step [90/225], Training Accuracy: 67.6389%, Training Loss: 0.7600%\n",
      "Epoch [20/300], Step [91/225], Training Accuracy: 67.6854%, Training Loss: 0.7590%\n",
      "Epoch [20/300], Step [92/225], Training Accuracy: 67.6461%, Training Loss: 0.7598%\n",
      "Epoch [20/300], Step [93/225], Training Accuracy: 67.6915%, Training Loss: 0.7594%\n",
      "Epoch [20/300], Step [94/225], Training Accuracy: 67.8191%, Training Loss: 0.7573%\n",
      "Epoch [20/300], Step [95/225], Training Accuracy: 67.7796%, Training Loss: 0.7574%\n",
      "Epoch [20/300], Step [96/225], Training Accuracy: 67.8711%, Training Loss: 0.7558%\n",
      "Epoch [20/300], Step [97/225], Training Accuracy: 67.8640%, Training Loss: 0.7555%\n",
      "Epoch [20/300], Step [98/225], Training Accuracy: 68.0166%, Training Loss: 0.7545%\n",
      "Epoch [20/300], Step [99/225], Training Accuracy: 67.9451%, Training Loss: 0.7559%\n",
      "Epoch [20/300], Step [100/225], Training Accuracy: 67.9688%, Training Loss: 0.7556%\n",
      "Epoch [20/300], Step [101/225], Training Accuracy: 68.0229%, Training Loss: 0.7554%\n",
      "Epoch [20/300], Step [102/225], Training Accuracy: 67.9534%, Training Loss: 0.7559%\n",
      "Epoch [20/300], Step [103/225], Training Accuracy: 67.9763%, Training Loss: 0.7564%\n",
      "Epoch [20/300], Step [104/225], Training Accuracy: 67.9387%, Training Loss: 0.7568%\n",
      "Epoch [20/300], Step [105/225], Training Accuracy: 67.9613%, Training Loss: 0.7563%\n",
      "Epoch [20/300], Step [106/225], Training Accuracy: 67.8213%, Training Loss: 0.7586%\n",
      "Epoch [20/300], Step [107/225], Training Accuracy: 67.8154%, Training Loss: 0.7590%\n",
      "Epoch [20/300], Step [108/225], Training Accuracy: 67.7951%, Training Loss: 0.7594%\n",
      "Epoch [20/300], Step [109/225], Training Accuracy: 67.7322%, Training Loss: 0.7604%\n",
      "Epoch [20/300], Step [110/225], Training Accuracy: 67.7699%, Training Loss: 0.7593%\n",
      "Epoch [20/300], Step [111/225], Training Accuracy: 67.8632%, Training Loss: 0.7583%\n",
      "Epoch [20/300], Step [112/225], Training Accuracy: 67.9129%, Training Loss: 0.7577%\n",
      "Epoch [20/300], Step [113/225], Training Accuracy: 67.8650%, Training Loss: 0.7581%\n",
      "Epoch [20/300], Step [114/225], Training Accuracy: 67.9276%, Training Loss: 0.7574%\n",
      "Epoch [20/300], Step [115/225], Training Accuracy: 67.8804%, Training Loss: 0.7579%\n",
      "Epoch [20/300], Step [116/225], Training Accuracy: 67.8879%, Training Loss: 0.7588%\n",
      "Epoch [20/300], Step [117/225], Training Accuracy: 67.8419%, Training Loss: 0.7593%\n",
      "Epoch [20/300], Step [118/225], Training Accuracy: 67.7701%, Training Loss: 0.7608%\n",
      "Epoch [20/300], Step [119/225], Training Accuracy: 67.7784%, Training Loss: 0.7615%\n",
      "Epoch [20/300], Step [120/225], Training Accuracy: 67.7734%, Training Loss: 0.7615%\n",
      "Epoch [20/300], Step [121/225], Training Accuracy: 67.8202%, Training Loss: 0.7616%\n",
      "Epoch [20/300], Step [122/225], Training Accuracy: 67.8023%, Training Loss: 0.7618%\n",
      "Epoch [20/300], Step [123/225], Training Accuracy: 67.8227%, Training Loss: 0.7625%\n",
      "Epoch [20/300], Step [124/225], Training Accuracy: 67.8679%, Training Loss: 0.7616%\n",
      "Epoch [20/300], Step [125/225], Training Accuracy: 67.9750%, Training Loss: 0.7607%\n",
      "Epoch [20/300], Step [126/225], Training Accuracy: 68.0184%, Training Loss: 0.7597%\n",
      "Epoch [20/300], Step [127/225], Training Accuracy: 67.9626%, Training Loss: 0.7596%\n",
      "Epoch [20/300], Step [128/225], Training Accuracy: 67.8589%, Training Loss: 0.7604%\n",
      "Epoch [20/300], Step [129/225], Training Accuracy: 67.9021%, Training Loss: 0.7594%\n",
      "Epoch [20/300], Step [130/225], Training Accuracy: 67.9688%, Training Loss: 0.7592%\n",
      "Epoch [20/300], Step [131/225], Training Accuracy: 67.9747%, Training Loss: 0.7589%\n",
      "Epoch [20/300], Step [132/225], Training Accuracy: 67.9569%, Training Loss: 0.7587%\n",
      "Epoch [20/300], Step [133/225], Training Accuracy: 68.0216%, Training Loss: 0.7575%\n",
      "Epoch [20/300], Step [134/225], Training Accuracy: 68.0737%, Training Loss: 0.7574%\n",
      "Epoch [20/300], Step [135/225], Training Accuracy: 68.1134%, Training Loss: 0.7564%\n",
      "Epoch [20/300], Step [136/225], Training Accuracy: 68.1641%, Training Loss: 0.7563%\n",
      "Epoch [20/300], Step [137/225], Training Accuracy: 68.2254%, Training Loss: 0.7550%\n",
      "Epoch [20/300], Step [138/225], Training Accuracy: 68.2405%, Training Loss: 0.7544%\n",
      "Epoch [20/300], Step [139/225], Training Accuracy: 68.2329%, Training Loss: 0.7549%\n",
      "Epoch [20/300], Step [140/225], Training Accuracy: 68.2143%, Training Loss: 0.7551%\n",
      "Epoch [20/300], Step [141/225], Training Accuracy: 68.1627%, Training Loss: 0.7560%\n",
      "Epoch [20/300], Step [142/225], Training Accuracy: 68.1008%, Training Loss: 0.7566%\n",
      "Epoch [20/300], Step [143/225], Training Accuracy: 68.0616%, Training Loss: 0.7577%\n",
      "Epoch [20/300], Step [144/225], Training Accuracy: 68.0773%, Training Loss: 0.7572%\n",
      "Epoch [20/300], Step [145/225], Training Accuracy: 68.1034%, Training Loss: 0.7573%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/300], Step [146/225], Training Accuracy: 68.0865%, Training Loss: 0.7577%\n",
      "Epoch [20/300], Step [147/225], Training Accuracy: 68.0591%, Training Loss: 0.7583%\n",
      "Epoch [20/300], Step [148/225], Training Accuracy: 68.0743%, Training Loss: 0.7578%\n",
      "Epoch [20/300], Step [149/225], Training Accuracy: 68.1208%, Training Loss: 0.7572%\n",
      "Epoch [20/300], Step [150/225], Training Accuracy: 68.1875%, Training Loss: 0.7558%\n",
      "Epoch [20/300], Step [151/225], Training Accuracy: 68.2016%, Training Loss: 0.7549%\n",
      "Epoch [20/300], Step [152/225], Training Accuracy: 68.2155%, Training Loss: 0.7548%\n",
      "Epoch [20/300], Step [153/225], Training Accuracy: 68.2598%, Training Loss: 0.7539%\n",
      "Epoch [20/300], Step [154/225], Training Accuracy: 68.2630%, Training Loss: 0.7537%\n",
      "Epoch [20/300], Step [155/225], Training Accuracy: 68.3165%, Training Loss: 0.7537%\n",
      "Epoch [20/300], Step [156/225], Training Accuracy: 68.3393%, Training Loss: 0.7537%\n",
      "Epoch [20/300], Step [157/225], Training Accuracy: 68.3718%, Training Loss: 0.7532%\n",
      "Epoch [20/300], Step [158/225], Training Accuracy: 68.4335%, Training Loss: 0.7520%\n",
      "Epoch [20/300], Step [159/225], Training Accuracy: 68.4748%, Training Loss: 0.7513%\n",
      "Epoch [20/300], Step [160/225], Training Accuracy: 68.4863%, Training Loss: 0.7513%\n",
      "Epoch [20/300], Step [161/225], Training Accuracy: 68.4686%, Training Loss: 0.7516%\n",
      "Epoch [20/300], Step [162/225], Training Accuracy: 68.4992%, Training Loss: 0.7510%\n",
      "Epoch [20/300], Step [163/225], Training Accuracy: 68.5391%, Training Loss: 0.7501%\n",
      "Epoch [20/300], Step [164/225], Training Accuracy: 68.5595%, Training Loss: 0.7498%\n",
      "Epoch [20/300], Step [165/225], Training Accuracy: 68.6174%, Training Loss: 0.7494%\n",
      "Epoch [20/300], Step [166/225], Training Accuracy: 68.6465%, Training Loss: 0.7489%\n",
      "Epoch [20/300], Step [167/225], Training Accuracy: 68.7032%, Training Loss: 0.7484%\n",
      "Epoch [20/300], Step [168/225], Training Accuracy: 68.6756%, Training Loss: 0.7482%\n",
      "Epoch [20/300], Step [169/225], Training Accuracy: 68.6391%, Training Loss: 0.7487%\n",
      "Epoch [20/300], Step [170/225], Training Accuracy: 68.6397%, Training Loss: 0.7484%\n",
      "Epoch [20/300], Step [171/225], Training Accuracy: 68.6586%, Training Loss: 0.7480%\n",
      "Epoch [20/300], Step [172/225], Training Accuracy: 68.6955%, Training Loss: 0.7473%\n",
      "Epoch [20/300], Step [173/225], Training Accuracy: 68.6236%, Training Loss: 0.7478%\n",
      "Epoch [20/300], Step [174/225], Training Accuracy: 68.6243%, Training Loss: 0.7477%\n",
      "Epoch [20/300], Step [175/225], Training Accuracy: 68.6518%, Training Loss: 0.7469%\n",
      "Epoch [20/300], Step [176/225], Training Accuracy: 68.5902%, Training Loss: 0.7478%\n",
      "Epoch [20/300], Step [177/225], Training Accuracy: 68.5999%, Training Loss: 0.7474%\n",
      "Epoch [20/300], Step [178/225], Training Accuracy: 68.5744%, Training Loss: 0.7475%\n",
      "Epoch [20/300], Step [179/225], Training Accuracy: 68.5580%, Training Loss: 0.7475%\n",
      "Epoch [20/300], Step [180/225], Training Accuracy: 68.5938%, Training Loss: 0.7476%\n",
      "Epoch [20/300], Step [181/225], Training Accuracy: 68.5860%, Training Loss: 0.7481%\n",
      "Epoch [20/300], Step [182/225], Training Accuracy: 68.5869%, Training Loss: 0.7478%\n",
      "Epoch [20/300], Step [183/225], Training Accuracy: 68.6048%, Training Loss: 0.7470%\n",
      "Epoch [20/300], Step [184/225], Training Accuracy: 68.5462%, Training Loss: 0.7473%\n",
      "Epoch [20/300], Step [185/225], Training Accuracy: 68.5557%, Training Loss: 0.7468%\n",
      "Epoch [20/300], Step [186/225], Training Accuracy: 68.5736%, Training Loss: 0.7465%\n",
      "Epoch [20/300], Step [187/225], Training Accuracy: 68.5578%, Training Loss: 0.7466%\n",
      "Epoch [20/300], Step [188/225], Training Accuracy: 68.5173%, Training Loss: 0.7469%\n",
      "Epoch [20/300], Step [189/225], Training Accuracy: 68.5847%, Training Loss: 0.7459%\n",
      "Epoch [20/300], Step [190/225], Training Accuracy: 68.5362%, Training Loss: 0.7463%\n",
      "Epoch [20/300], Step [191/225], Training Accuracy: 68.5618%, Training Loss: 0.7459%\n",
      "Epoch [20/300], Step [192/225], Training Accuracy: 68.5384%, Training Loss: 0.7460%\n",
      "Epoch [20/300], Step [193/225], Training Accuracy: 68.5800%, Training Loss: 0.7455%\n",
      "Epoch [20/300], Step [194/225], Training Accuracy: 68.5970%, Training Loss: 0.7449%\n",
      "Epoch [20/300], Step [195/225], Training Accuracy: 68.5978%, Training Loss: 0.7453%\n",
      "Epoch [20/300], Step [196/225], Training Accuracy: 68.6464%, Training Loss: 0.7444%\n",
      "Epoch [20/300], Step [197/225], Training Accuracy: 68.6152%, Training Loss: 0.7453%\n",
      "Epoch [20/300], Step [198/225], Training Accuracy: 68.6001%, Training Loss: 0.7455%\n",
      "Epoch [20/300], Step [199/225], Training Accuracy: 68.5773%, Training Loss: 0.7468%\n",
      "Epoch [20/300], Step [200/225], Training Accuracy: 68.5781%, Training Loss: 0.7467%\n",
      "Epoch [20/300], Step [201/225], Training Accuracy: 68.6334%, Training Loss: 0.7462%\n",
      "Epoch [20/300], Step [202/225], Training Accuracy: 68.6108%, Training Loss: 0.7466%\n",
      "Epoch [20/300], Step [203/225], Training Accuracy: 68.6576%, Training Loss: 0.7462%\n",
      "Epoch [20/300], Step [204/225], Training Accuracy: 68.6581%, Training Loss: 0.7461%\n",
      "Epoch [20/300], Step [205/225], Training Accuracy: 68.6966%, Training Loss: 0.7463%\n",
      "Epoch [20/300], Step [206/225], Training Accuracy: 68.6742%, Training Loss: 0.7464%\n",
      "Epoch [20/300], Step [207/225], Training Accuracy: 68.7274%, Training Loss: 0.7456%\n",
      "Epoch [20/300], Step [208/225], Training Accuracy: 68.7200%, Training Loss: 0.7453%\n",
      "Epoch [20/300], Step [209/225], Training Accuracy: 68.6827%, Training Loss: 0.7458%\n",
      "Epoch [20/300], Step [210/225], Training Accuracy: 68.7054%, Training Loss: 0.7457%\n",
      "Epoch [20/300], Step [211/225], Training Accuracy: 68.6982%, Training Loss: 0.7453%\n",
      "Epoch [20/300], Step [212/225], Training Accuracy: 68.7131%, Training Loss: 0.7459%\n",
      "Epoch [20/300], Step [213/225], Training Accuracy: 68.6913%, Training Loss: 0.7461%\n",
      "Epoch [20/300], Step [214/225], Training Accuracy: 68.6770%, Training Loss: 0.7468%\n",
      "Epoch [20/300], Step [215/225], Training Accuracy: 68.6628%, Training Loss: 0.7465%\n",
      "Epoch [20/300], Step [216/225], Training Accuracy: 68.6126%, Training Loss: 0.7478%\n",
      "Epoch [20/300], Step [217/225], Training Accuracy: 68.6204%, Training Loss: 0.7475%\n",
      "Epoch [20/300], Step [218/225], Training Accuracy: 68.5636%, Training Loss: 0.7483%\n",
      "Epoch [20/300], Step [219/225], Training Accuracy: 68.5574%, Training Loss: 0.7483%\n",
      "Epoch [20/300], Step [220/225], Training Accuracy: 68.5724%, Training Loss: 0.7479%\n",
      "Epoch [20/300], Step [221/225], Training Accuracy: 68.5308%, Training Loss: 0.7486%\n",
      "Epoch [20/300], Step [222/225], Training Accuracy: 68.5177%, Training Loss: 0.7489%\n",
      "Epoch [20/300], Step [223/225], Training Accuracy: 68.5608%, Training Loss: 0.7484%\n",
      "Epoch [20/300], Step [224/225], Training Accuracy: 68.5547%, Training Loss: 0.7482%\n",
      "Epoch [20/300], Step [225/225], Training Accuracy: 68.5798%, Training Loss: 0.7479%\n",
      "Epoch [21/300], Step [1/225], Training Accuracy: 73.4375%, Training Loss: 0.7383%\n",
      "Epoch [21/300], Step [2/225], Training Accuracy: 70.3125%, Training Loss: 0.7337%\n",
      "Epoch [21/300], Step [3/225], Training Accuracy: 67.1875%, Training Loss: 0.8045%\n",
      "Epoch [21/300], Step [4/225], Training Accuracy: 69.5312%, Training Loss: 0.7388%\n",
      "Epoch [21/300], Step [5/225], Training Accuracy: 70.3125%, Training Loss: 0.7147%\n",
      "Epoch [21/300], Step [6/225], Training Accuracy: 69.0104%, Training Loss: 0.7139%\n",
      "Epoch [21/300], Step [7/225], Training Accuracy: 68.0804%, Training Loss: 0.7463%\n",
      "Epoch [21/300], Step [8/225], Training Accuracy: 69.3359%, Training Loss: 0.7215%\n",
      "Epoch [21/300], Step [9/225], Training Accuracy: 70.1389%, Training Loss: 0.7160%\n",
      "Epoch [21/300], Step [10/225], Training Accuracy: 70.0000%, Training Loss: 0.7158%\n",
      "Epoch [21/300], Step [11/225], Training Accuracy: 70.1705%, Training Loss: 0.7072%\n",
      "Epoch [21/300], Step [12/225], Training Accuracy: 69.9219%, Training Loss: 0.7120%\n",
      "Epoch [21/300], Step [13/225], Training Accuracy: 69.9519%, Training Loss: 0.7107%\n",
      "Epoch [21/300], Step [14/225], Training Accuracy: 69.7545%, Training Loss: 0.7160%\n",
      "Epoch [21/300], Step [15/225], Training Accuracy: 69.2708%, Training Loss: 0.7195%\n",
      "Epoch [21/300], Step [16/225], Training Accuracy: 68.1641%, Training Loss: 0.7416%\n",
      "Epoch [21/300], Step [17/225], Training Accuracy: 68.0147%, Training Loss: 0.7448%\n",
      "Epoch [21/300], Step [18/225], Training Accuracy: 67.7083%, Training Loss: 0.7511%\n",
      "Epoch [21/300], Step [19/225], Training Accuracy: 68.0099%, Training Loss: 0.7463%\n",
      "Epoch [21/300], Step [20/225], Training Accuracy: 68.2812%, Training Loss: 0.7401%\n",
      "Epoch [21/300], Step [21/225], Training Accuracy: 68.4524%, Training Loss: 0.7358%\n",
      "Epoch [21/300], Step [22/225], Training Accuracy: 68.5369%, Training Loss: 0.7374%\n",
      "Epoch [21/300], Step [23/225], Training Accuracy: 68.3424%, Training Loss: 0.7435%\n",
      "Epoch [21/300], Step [24/225], Training Accuracy: 68.0990%, Training Loss: 0.7509%\n",
      "Epoch [21/300], Step [25/225], Training Accuracy: 68.4375%, Training Loss: 0.7487%\n",
      "Epoch [21/300], Step [26/225], Training Accuracy: 68.2692%, Training Loss: 0.7514%\n",
      "Epoch [21/300], Step [27/225], Training Accuracy: 68.6921%, Training Loss: 0.7477%\n",
      "Epoch [21/300], Step [28/225], Training Accuracy: 68.8616%, Training Loss: 0.7426%\n",
      "Epoch [21/300], Step [29/225], Training Accuracy: 68.8578%, Training Loss: 0.7401%\n",
      "Epoch [21/300], Step [30/225], Training Accuracy: 68.8021%, Training Loss: 0.7417%\n",
      "Epoch [21/300], Step [31/225], Training Accuracy: 68.6996%, Training Loss: 0.7425%\n",
      "Epoch [21/300], Step [32/225], Training Accuracy: 68.8965%, Training Loss: 0.7381%\n",
      "Epoch [21/300], Step [33/225], Training Accuracy: 69.1288%, Training Loss: 0.7333%\n",
      "Epoch [21/300], Step [34/225], Training Accuracy: 69.0717%, Training Loss: 0.7332%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/300], Step [35/225], Training Accuracy: 69.0179%, Training Loss: 0.7341%\n",
      "Epoch [21/300], Step [36/225], Training Accuracy: 68.8368%, Training Loss: 0.7357%\n",
      "Epoch [21/300], Step [37/225], Training Accuracy: 68.7500%, Training Loss: 0.7371%\n",
      "Epoch [21/300], Step [38/225], Training Accuracy: 69.1201%, Training Loss: 0.7318%\n",
      "Epoch [21/300], Step [39/225], Training Accuracy: 69.1907%, Training Loss: 0.7310%\n",
      "Epoch [21/300], Step [40/225], Training Accuracy: 69.1797%, Training Loss: 0.7296%\n",
      "Epoch [21/300], Step [41/225], Training Accuracy: 69.2454%, Training Loss: 0.7267%\n",
      "Epoch [21/300], Step [42/225], Training Accuracy: 69.3824%, Training Loss: 0.7255%\n",
      "Epoch [21/300], Step [43/225], Training Accuracy: 69.4041%, Training Loss: 0.7242%\n",
      "Epoch [21/300], Step [44/225], Training Accuracy: 69.3892%, Training Loss: 0.7250%\n",
      "Epoch [21/300], Step [45/225], Training Accuracy: 69.4097%, Training Loss: 0.7254%\n",
      "Epoch [21/300], Step [46/225], Training Accuracy: 69.5312%, Training Loss: 0.7230%\n",
      "Epoch [21/300], Step [47/225], Training Accuracy: 69.5811%, Training Loss: 0.7234%\n",
      "Epoch [21/300], Step [48/225], Training Accuracy: 69.4987%, Training Loss: 0.7255%\n",
      "Epoch [21/300], Step [49/225], Training Accuracy: 69.5153%, Training Loss: 0.7259%\n",
      "Epoch [21/300], Step [50/225], Training Accuracy: 69.5938%, Training Loss: 0.7250%\n",
      "Epoch [21/300], Step [51/225], Training Accuracy: 69.6691%, Training Loss: 0.7229%\n",
      "Epoch [21/300], Step [52/225], Training Accuracy: 69.7115%, Training Loss: 0.7219%\n",
      "Epoch [21/300], Step [53/225], Training Accuracy: 69.6639%, Training Loss: 0.7221%\n",
      "Epoch [21/300], Step [54/225], Training Accuracy: 69.5023%, Training Loss: 0.7247%\n",
      "Epoch [21/300], Step [55/225], Training Accuracy: 69.5739%, Training Loss: 0.7241%\n",
      "Epoch [21/300], Step [56/225], Training Accuracy: 69.6150%, Training Loss: 0.7237%\n",
      "Epoch [21/300], Step [57/225], Training Accuracy: 69.5175%, Training Loss: 0.7241%\n",
      "Epoch [21/300], Step [58/225], Training Accuracy: 69.3966%, Training Loss: 0.7268%\n",
      "Epoch [21/300], Step [59/225], Training Accuracy: 69.3591%, Training Loss: 0.7278%\n",
      "Epoch [21/300], Step [60/225], Training Accuracy: 69.3750%, Training Loss: 0.7279%\n",
      "Epoch [21/300], Step [61/225], Training Accuracy: 69.2367%, Training Loss: 0.7285%\n",
      "Epoch [21/300], Step [62/225], Training Accuracy: 69.1784%, Training Loss: 0.7294%\n",
      "Epoch [21/300], Step [63/225], Training Accuracy: 69.2212%, Training Loss: 0.7315%\n",
      "Epoch [21/300], Step [64/225], Training Accuracy: 69.2383%, Training Loss: 0.7310%\n",
      "Epoch [21/300], Step [65/225], Training Accuracy: 69.3510%, Training Loss: 0.7289%\n",
      "Epoch [21/300], Step [66/225], Training Accuracy: 69.2945%, Training Loss: 0.7290%\n",
      "Epoch [21/300], Step [67/225], Training Accuracy: 69.3330%, Training Loss: 0.7293%\n",
      "Epoch [21/300], Step [68/225], Training Accuracy: 69.3015%, Training Loss: 0.7297%\n",
      "Epoch [21/300], Step [69/225], Training Accuracy: 69.3388%, Training Loss: 0.7287%\n",
      "Epoch [21/300], Step [70/225], Training Accuracy: 69.4420%, Training Loss: 0.7276%\n",
      "Epoch [21/300], Step [71/225], Training Accuracy: 69.4982%, Training Loss: 0.7262%\n",
      "Epoch [21/300], Step [72/225], Training Accuracy: 69.4661%, Training Loss: 0.7270%\n",
      "Epoch [21/300], Step [73/225], Training Accuracy: 69.3707%, Training Loss: 0.7285%\n",
      "Epoch [21/300], Step [74/225], Training Accuracy: 69.2990%, Training Loss: 0.7285%\n",
      "Epoch [21/300], Step [75/225], Training Accuracy: 69.3958%, Training Loss: 0.7268%\n",
      "Epoch [21/300], Step [76/225], Training Accuracy: 69.3462%, Training Loss: 0.7264%\n",
      "Epoch [21/300], Step [77/225], Training Accuracy: 69.3791%, Training Loss: 0.7268%\n",
      "Epoch [21/300], Step [78/225], Training Accuracy: 69.3510%, Training Loss: 0.7266%\n",
      "Epoch [21/300], Step [79/225], Training Accuracy: 69.3038%, Training Loss: 0.7277%\n",
      "Epoch [21/300], Step [80/225], Training Accuracy: 69.2383%, Training Loss: 0.7295%\n",
      "Epoch [21/300], Step [81/225], Training Accuracy: 69.2515%, Training Loss: 0.7295%\n",
      "Epoch [21/300], Step [82/225], Training Accuracy: 69.2835%, Training Loss: 0.7294%\n",
      "Epoch [21/300], Step [83/225], Training Accuracy: 69.2959%, Training Loss: 0.7294%\n",
      "Epoch [21/300], Step [84/225], Training Accuracy: 69.2336%, Training Loss: 0.7294%\n",
      "Epoch [21/300], Step [85/225], Training Accuracy: 69.3199%, Training Loss: 0.7289%\n",
      "Epoch [21/300], Step [86/225], Training Accuracy: 69.3859%, Training Loss: 0.7270%\n",
      "Epoch [21/300], Step [87/225], Training Accuracy: 69.4864%, Training Loss: 0.7253%\n",
      "Epoch [21/300], Step [88/225], Training Accuracy: 69.5668%, Training Loss: 0.7245%\n",
      "Epoch [21/300], Step [89/225], Training Accuracy: 69.5576%, Training Loss: 0.7240%\n",
      "Epoch [21/300], Step [90/225], Training Accuracy: 69.5833%, Training Loss: 0.7230%\n",
      "Epoch [21/300], Step [91/225], Training Accuracy: 69.5913%, Training Loss: 0.7226%\n",
      "Epoch [21/300], Step [92/225], Training Accuracy: 69.6162%, Training Loss: 0.7226%\n",
      "Epoch [21/300], Step [93/225], Training Accuracy: 69.6237%, Training Loss: 0.7228%\n",
      "Epoch [21/300], Step [94/225], Training Accuracy: 69.6310%, Training Loss: 0.7224%\n",
      "Epoch [21/300], Step [95/225], Training Accuracy: 69.6217%, Training Loss: 0.7221%\n",
      "Epoch [21/300], Step [96/225], Training Accuracy: 69.7266%, Training Loss: 0.7200%\n",
      "Epoch [21/300], Step [97/225], Training Accuracy: 69.6843%, Training Loss: 0.7196%\n",
      "Epoch [21/300], Step [98/225], Training Accuracy: 69.7226%, Training Loss: 0.7191%\n",
      "Epoch [21/300], Step [99/225], Training Accuracy: 69.7759%, Training Loss: 0.7199%\n",
      "Epoch [21/300], Step [100/225], Training Accuracy: 69.7969%, Training Loss: 0.7200%\n",
      "Epoch [21/300], Step [101/225], Training Accuracy: 69.8175%, Training Loss: 0.7200%\n",
      "Epoch [21/300], Step [102/225], Training Accuracy: 69.8070%, Training Loss: 0.7207%\n",
      "Epoch [21/300], Step [103/225], Training Accuracy: 69.8574%, Training Loss: 0.7208%\n",
      "Epoch [21/300], Step [104/225], Training Accuracy: 69.8017%, Training Loss: 0.7213%\n",
      "Epoch [21/300], Step [105/225], Training Accuracy: 69.7470%, Training Loss: 0.7219%\n",
      "Epoch [21/300], Step [106/225], Training Accuracy: 69.7081%, Training Loss: 0.7225%\n",
      "Epoch [21/300], Step [107/225], Training Accuracy: 69.6554%, Training Loss: 0.7223%\n",
      "Epoch [21/300], Step [108/225], Training Accuracy: 69.6181%, Training Loss: 0.7237%\n",
      "Epoch [21/300], Step [109/225], Training Accuracy: 69.5671%, Training Loss: 0.7244%\n",
      "Epoch [21/300], Step [110/225], Training Accuracy: 69.6165%, Training Loss: 0.7238%\n",
      "Epoch [21/300], Step [111/225], Training Accuracy: 69.6931%, Training Loss: 0.7231%\n",
      "Epoch [21/300], Step [112/225], Training Accuracy: 69.7545%, Training Loss: 0.7227%\n",
      "Epoch [21/300], Step [113/225], Training Accuracy: 69.6764%, Training Loss: 0.7231%\n",
      "Epoch [21/300], Step [114/225], Training Accuracy: 69.6409%, Training Loss: 0.7231%\n",
      "Epoch [21/300], Step [115/225], Training Accuracy: 69.6196%, Training Loss: 0.7239%\n",
      "Epoch [21/300], Step [116/225], Training Accuracy: 69.6255%, Training Loss: 0.7248%\n",
      "Epoch [21/300], Step [117/225], Training Accuracy: 69.6047%, Training Loss: 0.7249%\n",
      "Epoch [21/300], Step [118/225], Training Accuracy: 69.5180%, Training Loss: 0.7265%\n",
      "Epoch [21/300], Step [119/225], Training Accuracy: 69.5509%, Training Loss: 0.7263%\n",
      "Epoch [21/300], Step [120/225], Training Accuracy: 69.5833%, Training Loss: 0.7256%\n",
      "Epoch [21/300], Step [121/225], Training Accuracy: 69.6152%, Training Loss: 0.7252%\n",
      "Epoch [21/300], Step [122/225], Training Accuracy: 69.6081%, Training Loss: 0.7253%\n",
      "Epoch [21/300], Step [123/225], Training Accuracy: 69.6392%, Training Loss: 0.7249%\n",
      "Epoch [21/300], Step [124/225], Training Accuracy: 69.6447%, Training Loss: 0.7244%\n",
      "Epoch [21/300], Step [125/225], Training Accuracy: 69.7250%, Training Loss: 0.7235%\n",
      "Epoch [21/300], Step [126/225], Training Accuracy: 69.7669%, Training Loss: 0.7231%\n",
      "Epoch [21/300], Step [127/225], Training Accuracy: 69.7835%, Training Loss: 0.7226%\n",
      "Epoch [21/300], Step [128/225], Training Accuracy: 69.7021%, Training Loss: 0.7242%\n",
      "Epoch [21/300], Step [129/225], Training Accuracy: 69.7432%, Training Loss: 0.7231%\n",
      "Epoch [21/300], Step [130/225], Training Accuracy: 69.7596%, Training Loss: 0.7231%\n",
      "Epoch [21/300], Step [131/225], Training Accuracy: 69.7519%, Training Loss: 0.7230%\n",
      "Epoch [21/300], Step [132/225], Training Accuracy: 69.7443%, Training Loss: 0.7232%\n",
      "Epoch [21/300], Step [133/225], Training Accuracy: 69.8308%, Training Loss: 0.7216%\n",
      "Epoch [21/300], Step [134/225], Training Accuracy: 69.8111%, Training Loss: 0.7218%\n",
      "Epoch [21/300], Step [135/225], Training Accuracy: 69.8843%, Training Loss: 0.7205%\n",
      "Epoch [21/300], Step [136/225], Training Accuracy: 69.8989%, Training Loss: 0.7203%\n",
      "Epoch [21/300], Step [137/225], Training Accuracy: 69.9475%, Training Loss: 0.7197%\n",
      "Epoch [21/300], Step [138/225], Training Accuracy: 69.9275%, Training Loss: 0.7197%\n",
      "Epoch [21/300], Step [139/225], Training Accuracy: 69.9191%, Training Loss: 0.7197%\n",
      "Epoch [21/300], Step [140/225], Training Accuracy: 69.9330%, Training Loss: 0.7201%\n",
      "Epoch [21/300], Step [141/225], Training Accuracy: 69.9246%, Training Loss: 0.7200%\n",
      "Epoch [21/300], Step [142/225], Training Accuracy: 69.9384%, Training Loss: 0.7195%\n",
      "Epoch [21/300], Step [143/225], Training Accuracy: 69.8864%, Training Loss: 0.7201%\n",
      "Epoch [21/300], Step [144/225], Training Accuracy: 69.8676%, Training Loss: 0.7200%\n",
      "Epoch [21/300], Step [145/225], Training Accuracy: 69.8707%, Training Loss: 0.7198%\n",
      "Epoch [21/300], Step [146/225], Training Accuracy: 69.8202%, Training Loss: 0.7203%\n",
      "Epoch [21/300], Step [147/225], Training Accuracy: 69.7385%, Training Loss: 0.7212%\n",
      "Epoch [21/300], Step [148/225], Training Accuracy: 69.7846%, Training Loss: 0.7206%\n",
      "Epoch [21/300], Step [149/225], Training Accuracy: 69.7777%, Training Loss: 0.7202%\n",
      "Epoch [21/300], Step [150/225], Training Accuracy: 69.8854%, Training Loss: 0.7186%\n",
      "Epoch [21/300], Step [151/225], Training Accuracy: 69.9089%, Training Loss: 0.7178%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/300], Step [152/225], Training Accuracy: 69.9424%, Training Loss: 0.7177%\n",
      "Epoch [21/300], Step [153/225], Training Accuracy: 69.9653%, Training Loss: 0.7171%\n",
      "Epoch [21/300], Step [154/225], Training Accuracy: 69.9675%, Training Loss: 0.7168%\n",
      "Epoch [21/300], Step [155/225], Training Accuracy: 69.9899%, Training Loss: 0.7164%\n",
      "Epoch [21/300], Step [156/225], Training Accuracy: 69.9619%, Training Loss: 0.7164%\n",
      "Epoch [21/300], Step [157/225], Training Accuracy: 70.0338%, Training Loss: 0.7155%\n",
      "Epoch [21/300], Step [158/225], Training Accuracy: 70.0850%, Training Loss: 0.7148%\n",
      "Epoch [21/300], Step [159/225], Training Accuracy: 70.1160%, Training Loss: 0.7142%\n",
      "Epoch [21/300], Step [160/225], Training Accuracy: 70.1855%, Training Loss: 0.7138%\n",
      "Epoch [21/300], Step [161/225], Training Accuracy: 70.1863%, Training Loss: 0.7134%\n",
      "Epoch [21/300], Step [162/225], Training Accuracy: 70.2546%, Training Loss: 0.7125%\n",
      "Epoch [21/300], Step [163/225], Training Accuracy: 70.2837%, Training Loss: 0.7114%\n",
      "Epoch [21/300], Step [164/225], Training Accuracy: 70.3125%, Training Loss: 0.7105%\n",
      "Epoch [21/300], Step [165/225], Training Accuracy: 70.3125%, Training Loss: 0.7102%\n",
      "Epoch [21/300], Step [166/225], Training Accuracy: 70.3313%, Training Loss: 0.7099%\n",
      "Epoch [21/300], Step [167/225], Training Accuracy: 70.3499%, Training Loss: 0.7096%\n",
      "Epoch [21/300], Step [168/225], Training Accuracy: 70.3962%, Training Loss: 0.7089%\n",
      "Epoch [21/300], Step [169/225], Training Accuracy: 70.3865%, Training Loss: 0.7097%\n",
      "Epoch [21/300], Step [170/225], Training Accuracy: 70.3952%, Training Loss: 0.7093%\n",
      "Epoch [21/300], Step [171/225], Training Accuracy: 70.4221%, Training Loss: 0.7091%\n",
      "Epoch [21/300], Step [172/225], Training Accuracy: 70.4578%, Training Loss: 0.7080%\n",
      "Epoch [21/300], Step [173/225], Training Accuracy: 70.4389%, Training Loss: 0.7081%\n",
      "Epoch [21/300], Step [174/225], Training Accuracy: 70.4203%, Training Loss: 0.7082%\n",
      "Epoch [21/300], Step [175/225], Training Accuracy: 70.4643%, Training Loss: 0.7073%\n",
      "Epoch [21/300], Step [176/225], Training Accuracy: 70.4545%, Training Loss: 0.7073%\n",
      "Epoch [21/300], Step [177/225], Training Accuracy: 70.4449%, Training Loss: 0.7073%\n",
      "Epoch [21/300], Step [178/225], Training Accuracy: 70.4003%, Training Loss: 0.7076%\n",
      "Epoch [21/300], Step [179/225], Training Accuracy: 70.4172%, Training Loss: 0.7071%\n",
      "Epoch [21/300], Step [180/225], Training Accuracy: 70.4167%, Training Loss: 0.7070%\n",
      "Epoch [21/300], Step [181/225], Training Accuracy: 70.4075%, Training Loss: 0.7073%\n",
      "Epoch [21/300], Step [182/225], Training Accuracy: 70.3726%, Training Loss: 0.7076%\n",
      "Epoch [21/300], Step [183/225], Training Accuracy: 70.3979%, Training Loss: 0.7069%\n",
      "Epoch [21/300], Step [184/225], Training Accuracy: 70.4059%, Training Loss: 0.7068%\n",
      "Epoch [21/300], Step [185/225], Training Accuracy: 70.4054%, Training Loss: 0.7066%\n",
      "Epoch [21/300], Step [186/225], Training Accuracy: 70.4217%, Training Loss: 0.7061%\n",
      "Epoch [21/300], Step [187/225], Training Accuracy: 70.4629%, Training Loss: 0.7058%\n",
      "Epoch [21/300], Step [188/225], Training Accuracy: 70.4455%, Training Loss: 0.7057%\n",
      "Epoch [21/300], Step [189/225], Training Accuracy: 70.4778%, Training Loss: 0.7049%\n",
      "Epoch [21/300], Step [190/225], Training Accuracy: 70.4605%, Training Loss: 0.7054%\n",
      "Epoch [21/300], Step [191/225], Training Accuracy: 70.5170%, Training Loss: 0.7047%\n",
      "Epoch [21/300], Step [192/225], Training Accuracy: 70.5322%, Training Loss: 0.7044%\n",
      "Epoch [21/300], Step [193/225], Training Accuracy: 70.5635%, Training Loss: 0.7042%\n",
      "Epoch [21/300], Step [194/225], Training Accuracy: 70.6266%, Training Loss: 0.7029%\n",
      "Epoch [21/300], Step [195/225], Training Accuracy: 70.6410%, Training Loss: 0.7026%\n",
      "Epoch [21/300], Step [196/225], Training Accuracy: 70.6712%, Training Loss: 0.7018%\n",
      "Epoch [21/300], Step [197/225], Training Accuracy: 70.6298%, Training Loss: 0.7030%\n",
      "Epoch [21/300], Step [198/225], Training Accuracy: 70.5650%, Training Loss: 0.7039%\n",
      "Epoch [21/300], Step [199/225], Training Accuracy: 70.5245%, Training Loss: 0.7047%\n",
      "Epoch [21/300], Step [200/225], Training Accuracy: 70.5469%, Training Loss: 0.7043%\n",
      "Epoch [21/300], Step [201/225], Training Accuracy: 70.6001%, Training Loss: 0.7033%\n",
      "Epoch [21/300], Step [202/225], Training Accuracy: 70.5910%, Training Loss: 0.7035%\n",
      "Epoch [21/300], Step [203/225], Training Accuracy: 70.6435%, Training Loss: 0.7029%\n",
      "Epoch [21/300], Step [204/225], Training Accuracy: 70.6419%, Training Loss: 0.7033%\n",
      "Epoch [21/300], Step [205/225], Training Accuracy: 70.6479%, Training Loss: 0.7035%\n",
      "Epoch [21/300], Step [206/225], Training Accuracy: 70.6159%, Training Loss: 0.7038%\n",
      "Epoch [21/300], Step [207/225], Training Accuracy: 70.6597%, Training Loss: 0.7028%\n",
      "Epoch [21/300], Step [208/225], Training Accuracy: 70.6731%, Training Loss: 0.7026%\n",
      "Epoch [21/300], Step [209/225], Training Accuracy: 70.6489%, Training Loss: 0.7030%\n",
      "Epoch [21/300], Step [210/225], Training Accuracy: 70.6548%, Training Loss: 0.7029%\n",
      "Epoch [21/300], Step [211/225], Training Accuracy: 70.6531%, Training Loss: 0.7027%\n",
      "Epoch [21/300], Step [212/225], Training Accuracy: 70.6663%, Training Loss: 0.7031%\n",
      "Epoch [21/300], Step [213/225], Training Accuracy: 70.6499%, Training Loss: 0.7034%\n",
      "Epoch [21/300], Step [214/225], Training Accuracy: 70.6411%, Training Loss: 0.7036%\n",
      "Epoch [21/300], Step [215/225], Training Accuracy: 70.6395%, Training Loss: 0.7033%\n",
      "Epoch [21/300], Step [216/225], Training Accuracy: 70.6019%, Training Loss: 0.7040%\n",
      "Epoch [21/300], Step [217/225], Training Accuracy: 70.6221%, Training Loss: 0.7039%\n",
      "Epoch [21/300], Step [218/225], Training Accuracy: 70.5992%, Training Loss: 0.7043%\n",
      "Epoch [21/300], Step [219/225], Training Accuracy: 70.6122%, Training Loss: 0.7041%\n",
      "Epoch [21/300], Step [220/225], Training Accuracy: 70.6534%, Training Loss: 0.7035%\n",
      "Epoch [21/300], Step [221/225], Training Accuracy: 70.6307%, Training Loss: 0.7039%\n",
      "Epoch [21/300], Step [222/225], Training Accuracy: 70.6081%, Training Loss: 0.7044%\n",
      "Epoch [21/300], Step [223/225], Training Accuracy: 70.6068%, Training Loss: 0.7042%\n",
      "Epoch [21/300], Step [224/225], Training Accuracy: 70.6055%, Training Loss: 0.7040%\n",
      "Epoch [21/300], Step [225/225], Training Accuracy: 70.6017%, Training Loss: 0.7037%\n",
      "Epoch [22/300], Step [1/225], Training Accuracy: 65.6250%, Training Loss: 0.7472%\n",
      "Epoch [22/300], Step [2/225], Training Accuracy: 64.8438%, Training Loss: 0.7413%\n",
      "Epoch [22/300], Step [3/225], Training Accuracy: 64.0625%, Training Loss: 0.8140%\n",
      "Epoch [22/300], Step [4/225], Training Accuracy: 67.9688%, Training Loss: 0.7270%\n",
      "Epoch [22/300], Step [5/225], Training Accuracy: 69.6875%, Training Loss: 0.7034%\n",
      "Epoch [22/300], Step [6/225], Training Accuracy: 69.0104%, Training Loss: 0.7183%\n",
      "Epoch [22/300], Step [7/225], Training Accuracy: 68.0804%, Training Loss: 0.7293%\n",
      "Epoch [22/300], Step [8/225], Training Accuracy: 69.5312%, Training Loss: 0.7073%\n",
      "Epoch [22/300], Step [9/225], Training Accuracy: 70.3125%, Training Loss: 0.6940%\n",
      "Epoch [22/300], Step [10/225], Training Accuracy: 70.6250%, Training Loss: 0.6975%\n",
      "Epoch [22/300], Step [11/225], Training Accuracy: 71.1648%, Training Loss: 0.6884%\n",
      "Epoch [22/300], Step [12/225], Training Accuracy: 71.3542%, Training Loss: 0.6819%\n",
      "Epoch [22/300], Step [13/225], Training Accuracy: 71.5144%, Training Loss: 0.6814%\n",
      "Epoch [22/300], Step [14/225], Training Accuracy: 71.3170%, Training Loss: 0.6938%\n",
      "Epoch [22/300], Step [15/225], Training Accuracy: 71.7708%, Training Loss: 0.6881%\n",
      "Epoch [22/300], Step [16/225], Training Accuracy: 70.5078%, Training Loss: 0.7084%\n",
      "Epoch [22/300], Step [17/225], Training Accuracy: 70.5882%, Training Loss: 0.7131%\n",
      "Epoch [22/300], Step [18/225], Training Accuracy: 70.3993%, Training Loss: 0.7188%\n",
      "Epoch [22/300], Step [19/225], Training Accuracy: 70.9704%, Training Loss: 0.7138%\n",
      "Epoch [22/300], Step [20/225], Training Accuracy: 71.4062%, Training Loss: 0.7059%\n",
      "Epoch [22/300], Step [21/225], Training Accuracy: 71.5774%, Training Loss: 0.7018%\n",
      "Epoch [22/300], Step [22/225], Training Accuracy: 71.3778%, Training Loss: 0.7042%\n",
      "Epoch [22/300], Step [23/225], Training Accuracy: 71.1957%, Training Loss: 0.7106%\n",
      "Epoch [22/300], Step [24/225], Training Accuracy: 70.6380%, Training Loss: 0.7195%\n",
      "Epoch [22/300], Step [25/225], Training Accuracy: 70.5625%, Training Loss: 0.7174%\n",
      "Epoch [22/300], Step [26/225], Training Accuracy: 70.2524%, Training Loss: 0.7201%\n",
      "Epoch [22/300], Step [27/225], Training Accuracy: 70.3125%, Training Loss: 0.7185%\n",
      "Epoch [22/300], Step [28/225], Training Accuracy: 70.4799%, Training Loss: 0.7141%\n",
      "Epoch [22/300], Step [29/225], Training Accuracy: 70.7435%, Training Loss: 0.7078%\n",
      "Epoch [22/300], Step [30/225], Training Accuracy: 70.8854%, Training Loss: 0.7088%\n",
      "Epoch [22/300], Step [31/225], Training Accuracy: 70.6653%, Training Loss: 0.7123%\n",
      "Epoch [22/300], Step [32/225], Training Accuracy: 70.9961%, Training Loss: 0.7073%\n",
      "Epoch [22/300], Step [33/225], Training Accuracy: 71.2595%, Training Loss: 0.7037%\n",
      "Epoch [22/300], Step [34/225], Training Accuracy: 71.4154%, Training Loss: 0.7013%\n",
      "Epoch [22/300], Step [35/225], Training Accuracy: 71.3839%, Training Loss: 0.6991%\n",
      "Epoch [22/300], Step [36/225], Training Accuracy: 71.5278%, Training Loss: 0.6983%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/300], Step [37/225], Training Accuracy: 71.6216%, Training Loss: 0.6971%\n",
      "Epoch [22/300], Step [38/225], Training Accuracy: 72.0806%, Training Loss: 0.6920%\n",
      "Epoch [22/300], Step [39/225], Training Accuracy: 72.1154%, Training Loss: 0.6892%\n",
      "Epoch [22/300], Step [40/225], Training Accuracy: 71.9531%, Training Loss: 0.6897%\n",
      "Epoch [22/300], Step [41/225], Training Accuracy: 71.9512%, Training Loss: 0.6875%\n",
      "Epoch [22/300], Step [42/225], Training Accuracy: 71.8006%, Training Loss: 0.6901%\n",
      "Epoch [22/300], Step [43/225], Training Accuracy: 71.7297%, Training Loss: 0.6899%\n",
      "Epoch [22/300], Step [44/225], Training Accuracy: 71.6619%, Training Loss: 0.6917%\n",
      "Epoch [22/300], Step [45/225], Training Accuracy: 71.7361%, Training Loss: 0.6916%\n",
      "Epoch [22/300], Step [46/225], Training Accuracy: 72.0109%, Training Loss: 0.6879%\n",
      "Epoch [22/300], Step [47/225], Training Accuracy: 72.1742%, Training Loss: 0.6867%\n",
      "Epoch [22/300], Step [48/225], Training Accuracy: 72.0703%, Training Loss: 0.6881%\n",
      "Epoch [22/300], Step [49/225], Training Accuracy: 72.1620%, Training Loss: 0.6881%\n",
      "Epoch [22/300], Step [50/225], Training Accuracy: 72.1562%, Training Loss: 0.6876%\n",
      "Epoch [22/300], Step [51/225], Training Accuracy: 72.3652%, Training Loss: 0.6853%\n",
      "Epoch [22/300], Step [52/225], Training Accuracy: 72.4459%, Training Loss: 0.6828%\n",
      "Epoch [22/300], Step [53/225], Training Accuracy: 72.3762%, Training Loss: 0.6845%\n",
      "Epoch [22/300], Step [54/225], Training Accuracy: 72.2222%, Training Loss: 0.6870%\n",
      "Epoch [22/300], Step [55/225], Training Accuracy: 72.3580%, Training Loss: 0.6846%\n",
      "Epoch [22/300], Step [56/225], Training Accuracy: 72.3214%, Training Loss: 0.6850%\n",
      "Epoch [22/300], Step [57/225], Training Accuracy: 72.2314%, Training Loss: 0.6862%\n",
      "Epoch [22/300], Step [58/225], Training Accuracy: 72.0905%, Training Loss: 0.6880%\n",
      "Epoch [22/300], Step [59/225], Training Accuracy: 72.0604%, Training Loss: 0.6884%\n",
      "Epoch [22/300], Step [60/225], Training Accuracy: 72.0833%, Training Loss: 0.6885%\n",
      "Epoch [22/300], Step [61/225], Training Accuracy: 72.1311%, Training Loss: 0.6872%\n",
      "Epoch [22/300], Step [62/225], Training Accuracy: 72.1018%, Training Loss: 0.6871%\n",
      "Epoch [22/300], Step [63/225], Training Accuracy: 71.9990%, Training Loss: 0.6881%\n",
      "Epoch [22/300], Step [64/225], Training Accuracy: 72.0215%, Training Loss: 0.6866%\n",
      "Epoch [22/300], Step [65/225], Training Accuracy: 72.0433%, Training Loss: 0.6852%\n",
      "Epoch [22/300], Step [66/225], Training Accuracy: 72.0407%, Training Loss: 0.6855%\n",
      "Epoch [22/300], Step [67/225], Training Accuracy: 71.9683%, Training Loss: 0.6860%\n",
      "Epoch [22/300], Step [68/225], Training Accuracy: 71.9439%, Training Loss: 0.6860%\n",
      "Epoch [22/300], Step [69/225], Training Accuracy: 71.9203%, Training Loss: 0.6857%\n",
      "Epoch [22/300], Step [70/225], Training Accuracy: 71.9643%, Training Loss: 0.6840%\n",
      "Epoch [22/300], Step [71/225], Training Accuracy: 72.0290%, Training Loss: 0.6824%\n",
      "Epoch [22/300], Step [72/225], Training Accuracy: 72.0269%, Training Loss: 0.6827%\n",
      "Epoch [22/300], Step [73/225], Training Accuracy: 71.8536%, Training Loss: 0.6859%\n",
      "Epoch [22/300], Step [74/225], Training Accuracy: 71.7483%, Training Loss: 0.6866%\n",
      "Epoch [22/300], Step [75/225], Training Accuracy: 71.8958%, Training Loss: 0.6846%\n",
      "Epoch [22/300], Step [76/225], Training Accuracy: 71.9367%, Training Loss: 0.6852%\n",
      "Epoch [22/300], Step [77/225], Training Accuracy: 71.9765%, Training Loss: 0.6846%\n",
      "Epoch [22/300], Step [78/225], Training Accuracy: 72.0553%, Training Loss: 0.6843%\n",
      "Epoch [22/300], Step [79/225], Training Accuracy: 72.0332%, Training Loss: 0.6845%\n",
      "Epoch [22/300], Step [80/225], Training Accuracy: 71.9141%, Training Loss: 0.6861%\n",
      "Epoch [22/300], Step [81/225], Training Accuracy: 71.9329%, Training Loss: 0.6854%\n",
      "Epoch [22/300], Step [82/225], Training Accuracy: 71.8941%, Training Loss: 0.6854%\n",
      "Epoch [22/300], Step [83/225], Training Accuracy: 71.9880%, Training Loss: 0.6841%\n",
      "Epoch [22/300], Step [84/225], Training Accuracy: 71.8750%, Training Loss: 0.6853%\n",
      "Epoch [22/300], Step [85/225], Training Accuracy: 71.8934%, Training Loss: 0.6841%\n",
      "Epoch [22/300], Step [86/225], Training Accuracy: 71.9658%, Training Loss: 0.6839%\n",
      "Epoch [22/300], Step [87/225], Training Accuracy: 72.0546%, Training Loss: 0.6825%\n",
      "Epoch [22/300], Step [88/225], Training Accuracy: 72.0348%, Training Loss: 0.6818%\n",
      "Epoch [22/300], Step [89/225], Training Accuracy: 72.1559%, Training Loss: 0.6800%\n",
      "Epoch [22/300], Step [90/225], Training Accuracy: 72.1701%, Training Loss: 0.6791%\n",
      "Epoch [22/300], Step [91/225], Training Accuracy: 72.2012%, Training Loss: 0.6790%\n",
      "Epoch [22/300], Step [92/225], Training Accuracy: 72.1807%, Training Loss: 0.6799%\n",
      "Epoch [22/300], Step [93/225], Training Accuracy: 72.2446%, Training Loss: 0.6797%\n",
      "Epoch [22/300], Step [94/225], Training Accuracy: 72.2906%, Training Loss: 0.6788%\n",
      "Epoch [22/300], Step [95/225], Training Accuracy: 72.2697%, Training Loss: 0.6790%\n",
      "Epoch [22/300], Step [96/225], Training Accuracy: 72.4121%, Training Loss: 0.6769%\n",
      "Epoch [22/300], Step [97/225], Training Accuracy: 72.4066%, Training Loss: 0.6769%\n",
      "Epoch [22/300], Step [98/225], Training Accuracy: 72.4968%, Training Loss: 0.6760%\n",
      "Epoch [22/300], Step [99/225], Training Accuracy: 72.4590%, Training Loss: 0.6763%\n",
      "Epoch [22/300], Step [100/225], Training Accuracy: 72.4531%, Training Loss: 0.6768%\n",
      "Epoch [22/300], Step [101/225], Training Accuracy: 72.4474%, Training Loss: 0.6772%\n",
      "Epoch [22/300], Step [102/225], Training Accuracy: 72.3958%, Training Loss: 0.6781%\n",
      "Epoch [22/300], Step [103/225], Training Accuracy: 72.4059%, Training Loss: 0.6787%\n",
      "Epoch [22/300], Step [104/225], Training Accuracy: 72.3858%, Training Loss: 0.6794%\n",
      "Epoch [22/300], Step [105/225], Training Accuracy: 72.3363%, Training Loss: 0.6793%\n",
      "Epoch [22/300], Step [106/225], Training Accuracy: 72.2583%, Training Loss: 0.6803%\n",
      "Epoch [22/300], Step [107/225], Training Accuracy: 72.2401%, Training Loss: 0.6800%\n",
      "Epoch [22/300], Step [108/225], Training Accuracy: 72.2222%, Training Loss: 0.6807%\n",
      "Epoch [22/300], Step [109/225], Training Accuracy: 72.1904%, Training Loss: 0.6817%\n",
      "Epoch [22/300], Step [110/225], Training Accuracy: 72.2869%, Training Loss: 0.6801%\n",
      "Epoch [22/300], Step [111/225], Training Accuracy: 72.2691%, Training Loss: 0.6793%\n",
      "Epoch [22/300], Step [112/225], Training Accuracy: 72.2238%, Training Loss: 0.6790%\n",
      "Epoch [22/300], Step [113/225], Training Accuracy: 72.2069%, Training Loss: 0.6794%\n",
      "Epoch [22/300], Step [114/225], Training Accuracy: 72.2177%, Training Loss: 0.6797%\n",
      "Epoch [22/300], Step [115/225], Training Accuracy: 72.2011%, Training Loss: 0.6800%\n",
      "Epoch [22/300], Step [116/225], Training Accuracy: 72.1579%, Training Loss: 0.6809%\n",
      "Epoch [22/300], Step [117/225], Training Accuracy: 72.1287%, Training Loss: 0.6815%\n",
      "Epoch [22/300], Step [118/225], Training Accuracy: 72.0339%, Training Loss: 0.6834%\n",
      "Epoch [22/300], Step [119/225], Training Accuracy: 72.0982%, Training Loss: 0.6834%\n",
      "Epoch [22/300], Step [120/225], Training Accuracy: 72.1354%, Training Loss: 0.6828%\n",
      "Epoch [22/300], Step [121/225], Training Accuracy: 72.1978%, Training Loss: 0.6822%\n",
      "Epoch [22/300], Step [122/225], Training Accuracy: 72.2080%, Training Loss: 0.6824%\n",
      "Epoch [22/300], Step [123/225], Training Accuracy: 72.2307%, Training Loss: 0.6826%\n",
      "Epoch [22/300], Step [124/225], Training Accuracy: 72.2404%, Training Loss: 0.6819%\n",
      "Epoch [22/300], Step [125/225], Training Accuracy: 72.2250%, Training Loss: 0.6823%\n",
      "Epoch [22/300], Step [126/225], Training Accuracy: 72.2842%, Training Loss: 0.6815%\n",
      "Epoch [22/300], Step [127/225], Training Accuracy: 72.3302%, Training Loss: 0.6809%\n",
      "Epoch [22/300], Step [128/225], Training Accuracy: 72.2778%, Training Loss: 0.6816%\n",
      "Epoch [22/300], Step [129/225], Training Accuracy: 72.3110%, Training Loss: 0.6810%\n",
      "Epoch [22/300], Step [130/225], Training Accuracy: 72.3077%, Training Loss: 0.6814%\n",
      "Epoch [22/300], Step [131/225], Training Accuracy: 72.2448%, Training Loss: 0.6821%\n",
      "Epoch [22/300], Step [132/225], Training Accuracy: 72.1709%, Training Loss: 0.6825%\n",
      "Epoch [22/300], Step [133/225], Training Accuracy: 72.2039%, Training Loss: 0.6815%\n",
      "Epoch [22/300], Step [134/225], Training Accuracy: 72.1665%, Training Loss: 0.6825%\n",
      "Epoch [22/300], Step [135/225], Training Accuracy: 72.2338%, Training Loss: 0.6813%\n",
      "Epoch [22/300], Step [136/225], Training Accuracy: 72.2771%, Training Loss: 0.6813%\n",
      "Epoch [22/300], Step [137/225], Training Accuracy: 72.3198%, Training Loss: 0.6805%\n",
      "Epoch [22/300], Step [138/225], Training Accuracy: 72.3053%, Training Loss: 0.6800%\n",
      "Epoch [22/300], Step [139/225], Training Accuracy: 72.2572%, Training Loss: 0.6810%\n",
      "Epoch [22/300], Step [140/225], Training Accuracy: 72.2656%, Training Loss: 0.6811%\n",
      "Epoch [22/300], Step [141/225], Training Accuracy: 72.2850%, Training Loss: 0.6811%\n",
      "Epoch [22/300], Step [142/225], Training Accuracy: 72.3041%, Training Loss: 0.6802%\n",
      "Epoch [22/300], Step [143/225], Training Accuracy: 72.2465%, Training Loss: 0.6811%\n",
      "Epoch [22/300], Step [144/225], Training Accuracy: 72.2765%, Training Loss: 0.6803%\n",
      "Epoch [22/300], Step [145/225], Training Accuracy: 72.2629%, Training Loss: 0.6806%\n",
      "Epoch [22/300], Step [146/225], Training Accuracy: 72.2175%, Training Loss: 0.6807%\n",
      "Epoch [22/300], Step [147/225], Training Accuracy: 72.1620%, Training Loss: 0.6823%\n",
      "Epoch [22/300], Step [148/225], Training Accuracy: 72.1706%, Training Loss: 0.6817%\n",
      "Epoch [22/300], Step [149/225], Training Accuracy: 72.1267%, Training Loss: 0.6819%\n",
      "Epoch [22/300], Step [150/225], Training Accuracy: 72.1667%, Training Loss: 0.6804%\n",
      "Epoch [22/300], Step [151/225], Training Accuracy: 72.1958%, Training Loss: 0.6797%\n",
      "Epoch [22/300], Step [152/225], Training Accuracy: 72.2245%, Training Loss: 0.6793%\n",
      "Epoch [22/300], Step [153/225], Training Accuracy: 72.2631%, Training Loss: 0.6786%\n",
      "Epoch [22/300], Step [154/225], Training Accuracy: 72.1997%, Training Loss: 0.6791%\n",
      "Epoch [22/300], Step [155/225], Training Accuracy: 72.2480%, Training Loss: 0.6784%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/300], Step [156/225], Training Accuracy: 72.2456%, Training Loss: 0.6787%\n",
      "Epoch [22/300], Step [157/225], Training Accuracy: 72.3129%, Training Loss: 0.6782%\n",
      "Epoch [22/300], Step [158/225], Training Accuracy: 72.3398%, Training Loss: 0.6778%\n",
      "Epoch [22/300], Step [159/225], Training Accuracy: 72.3467%, Training Loss: 0.6774%\n",
      "Epoch [22/300], Step [160/225], Training Accuracy: 72.3828%, Training Loss: 0.6774%\n",
      "Epoch [22/300], Step [161/225], Training Accuracy: 72.4379%, Training Loss: 0.6764%\n",
      "Epoch [22/300], Step [162/225], Training Accuracy: 72.4633%, Training Loss: 0.6761%\n",
      "Epoch [22/300], Step [163/225], Training Accuracy: 72.4789%, Training Loss: 0.6754%\n",
      "Epoch [22/300], Step [164/225], Training Accuracy: 72.4943%, Training Loss: 0.6750%\n",
      "Epoch [22/300], Step [165/225], Training Accuracy: 72.5189%, Training Loss: 0.6746%\n",
      "Epoch [22/300], Step [166/225], Training Accuracy: 72.5151%, Training Loss: 0.6748%\n",
      "Epoch [22/300], Step [167/225], Training Accuracy: 72.4925%, Training Loss: 0.6748%\n",
      "Epoch [22/300], Step [168/225], Training Accuracy: 72.5353%, Training Loss: 0.6743%\n",
      "Epoch [22/300], Step [169/225], Training Accuracy: 72.4852%, Training Loss: 0.6752%\n",
      "Epoch [22/300], Step [170/225], Training Accuracy: 72.4816%, Training Loss: 0.6751%\n",
      "Epoch [22/300], Step [171/225], Training Accuracy: 72.5146%, Training Loss: 0.6748%\n",
      "Epoch [22/300], Step [172/225], Training Accuracy: 72.5382%, Training Loss: 0.6747%\n",
      "Epoch [22/300], Step [173/225], Training Accuracy: 72.4892%, Training Loss: 0.6757%\n",
      "Epoch [22/300], Step [174/225], Training Accuracy: 72.4497%, Training Loss: 0.6763%\n",
      "Epoch [22/300], Step [175/225], Training Accuracy: 72.5089%, Training Loss: 0.6754%\n",
      "Epoch [22/300], Step [176/225], Training Accuracy: 72.4698%, Training Loss: 0.6758%\n",
      "Epoch [22/300], Step [177/225], Training Accuracy: 72.4841%, Training Loss: 0.6757%\n",
      "Epoch [22/300], Step [178/225], Training Accuracy: 72.4544%, Training Loss: 0.6761%\n",
      "Epoch [22/300], Step [179/225], Training Accuracy: 72.4162%, Training Loss: 0.6761%\n",
      "Epoch [22/300], Step [180/225], Training Accuracy: 72.4132%, Training Loss: 0.6761%\n",
      "Epoch [22/300], Step [181/225], Training Accuracy: 72.3843%, Training Loss: 0.6770%\n",
      "Epoch [22/300], Step [182/225], Training Accuracy: 72.3901%, Training Loss: 0.6768%\n",
      "Epoch [22/300], Step [183/225], Training Accuracy: 72.4044%, Training Loss: 0.6761%\n",
      "Epoch [22/300], Step [184/225], Training Accuracy: 72.3930%, Training Loss: 0.6763%\n",
      "Epoch [22/300], Step [185/225], Training Accuracy: 72.4409%, Training Loss: 0.6760%\n",
      "Epoch [22/300], Step [186/225], Training Accuracy: 72.4210%, Training Loss: 0.6763%\n",
      "Epoch [22/300], Step [187/225], Training Accuracy: 72.4014%, Training Loss: 0.6762%\n",
      "Epoch [22/300], Step [188/225], Training Accuracy: 72.3737%, Training Loss: 0.6764%\n",
      "Epoch [22/300], Step [189/225], Training Accuracy: 72.4206%, Training Loss: 0.6759%\n",
      "Epoch [22/300], Step [190/225], Training Accuracy: 72.4260%, Training Loss: 0.6755%\n",
      "Epoch [22/300], Step [191/225], Training Accuracy: 72.4558%, Training Loss: 0.6748%\n",
      "Epoch [22/300], Step [192/225], Training Accuracy: 72.3877%, Training Loss: 0.6752%\n",
      "Epoch [22/300], Step [193/225], Training Accuracy: 72.4012%, Training Loss: 0.6752%\n",
      "Epoch [22/300], Step [194/225], Training Accuracy: 72.4549%, Training Loss: 0.6743%\n",
      "Epoch [22/300], Step [195/225], Training Accuracy: 72.4439%, Training Loss: 0.6743%\n",
      "Epoch [22/300], Step [196/225], Training Accuracy: 72.4968%, Training Loss: 0.6732%\n",
      "Epoch [22/300], Step [197/225], Training Accuracy: 72.4778%, Training Loss: 0.6738%\n",
      "Epoch [22/300], Step [198/225], Training Accuracy: 72.4984%, Training Loss: 0.6737%\n",
      "Epoch [22/300], Step [199/225], Training Accuracy: 72.4560%, Training Loss: 0.6747%\n",
      "Epoch [22/300], Step [200/225], Training Accuracy: 72.4688%, Training Loss: 0.6740%\n",
      "Epoch [22/300], Step [201/225], Training Accuracy: 72.4969%, Training Loss: 0.6732%\n",
      "Epoch [22/300], Step [202/225], Training Accuracy: 72.4938%, Training Loss: 0.6733%\n",
      "Epoch [22/300], Step [203/225], Training Accuracy: 72.5062%, Training Loss: 0.6731%\n",
      "Epoch [22/300], Step [204/225], Training Accuracy: 72.5031%, Training Loss: 0.6730%\n",
      "Epoch [22/300], Step [205/225], Training Accuracy: 72.5229%, Training Loss: 0.6728%\n",
      "Epoch [22/300], Step [206/225], Training Accuracy: 72.5121%, Training Loss: 0.6730%\n",
      "Epoch [22/300], Step [207/225], Training Accuracy: 72.5694%, Training Loss: 0.6719%\n",
      "Epoch [22/300], Step [208/225], Training Accuracy: 72.6037%, Training Loss: 0.6713%\n",
      "Epoch [22/300], Step [209/225], Training Accuracy: 72.6226%, Training Loss: 0.6712%\n",
      "Epoch [22/300], Step [210/225], Training Accuracy: 72.6116%, Training Loss: 0.6713%\n",
      "Epoch [22/300], Step [211/225], Training Accuracy: 72.6451%, Training Loss: 0.6710%\n",
      "Epoch [22/300], Step [212/225], Training Accuracy: 72.6268%, Training Loss: 0.6717%\n",
      "Epoch [22/300], Step [213/225], Training Accuracy: 72.6086%, Training Loss: 0.6718%\n",
      "Epoch [22/300], Step [214/225], Training Accuracy: 72.6562%, Training Loss: 0.6713%\n",
      "Epoch [22/300], Step [215/225], Training Accuracy: 72.6672%, Training Loss: 0.6710%\n",
      "Epoch [22/300], Step [216/225], Training Accuracy: 72.6418%, Training Loss: 0.6718%\n",
      "Epoch [22/300], Step [217/225], Training Accuracy: 72.6454%, Training Loss: 0.6716%\n",
      "Epoch [22/300], Step [218/225], Training Accuracy: 72.6347%, Training Loss: 0.6718%\n",
      "Epoch [22/300], Step [219/225], Training Accuracy: 72.6384%, Training Loss: 0.6715%\n",
      "Epoch [22/300], Step [220/225], Training Accuracy: 72.6491%, Training Loss: 0.6714%\n",
      "Epoch [22/300], Step [221/225], Training Accuracy: 72.6244%, Training Loss: 0.6721%\n",
      "Epoch [22/300], Step [222/225], Training Accuracy: 72.6070%, Training Loss: 0.6722%\n",
      "Epoch [22/300], Step [223/225], Training Accuracy: 72.5897%, Training Loss: 0.6728%\n",
      "Epoch [22/300], Step [224/225], Training Accuracy: 72.6214%, Training Loss: 0.6723%\n",
      "Epoch [22/300], Step [225/225], Training Accuracy: 72.6028%, Training Loss: 0.6725%\n",
      "Epoch [23/300], Step [1/225], Training Accuracy: 78.1250%, Training Loss: 0.6126%\n",
      "Epoch [23/300], Step [2/225], Training Accuracy: 75.7812%, Training Loss: 0.6317%\n",
      "Epoch [23/300], Step [3/225], Training Accuracy: 72.9167%, Training Loss: 0.6907%\n",
      "Epoch [23/300], Step [4/225], Training Accuracy: 76.1719%, Training Loss: 0.6266%\n",
      "Epoch [23/300], Step [5/225], Training Accuracy: 76.5625%, Training Loss: 0.6088%\n",
      "Epoch [23/300], Step [6/225], Training Accuracy: 74.7396%, Training Loss: 0.6460%\n",
      "Epoch [23/300], Step [7/225], Training Accuracy: 73.6607%, Training Loss: 0.6674%\n",
      "Epoch [23/300], Step [8/225], Training Accuracy: 74.8047%, Training Loss: 0.6522%\n",
      "Epoch [23/300], Step [9/225], Training Accuracy: 75.1736%, Training Loss: 0.6492%\n",
      "Epoch [23/300], Step [10/225], Training Accuracy: 74.5312%, Training Loss: 0.6595%\n",
      "Epoch [23/300], Step [11/225], Training Accuracy: 75.4261%, Training Loss: 0.6429%\n",
      "Epoch [23/300], Step [12/225], Training Accuracy: 74.8698%, Training Loss: 0.6449%\n",
      "Epoch [23/300], Step [13/225], Training Accuracy: 74.1587%, Training Loss: 0.6509%\n",
      "Epoch [23/300], Step [14/225], Training Accuracy: 73.8839%, Training Loss: 0.6582%\n",
      "Epoch [23/300], Step [15/225], Training Accuracy: 74.0625%, Training Loss: 0.6557%\n",
      "Epoch [23/300], Step [16/225], Training Accuracy: 73.1445%, Training Loss: 0.6723%\n",
      "Epoch [23/300], Step [17/225], Training Accuracy: 72.9779%, Training Loss: 0.6803%\n",
      "Epoch [23/300], Step [18/225], Training Accuracy: 72.4826%, Training Loss: 0.6860%\n",
      "Epoch [23/300], Step [19/225], Training Accuracy: 72.7796%, Training Loss: 0.6779%\n",
      "Epoch [23/300], Step [20/225], Training Accuracy: 73.3594%, Training Loss: 0.6684%\n",
      "Epoch [23/300], Step [21/225], Training Accuracy: 73.4375%, Training Loss: 0.6630%\n",
      "Epoch [23/300], Step [22/225], Training Accuracy: 73.2244%, Training Loss: 0.6679%\n",
      "Epoch [23/300], Step [23/225], Training Accuracy: 72.8261%, Training Loss: 0.6736%\n",
      "Epoch [23/300], Step [24/225], Training Accuracy: 72.5911%, Training Loss: 0.6798%\n",
      "Epoch [23/300], Step [25/225], Training Accuracy: 72.4375%, Training Loss: 0.6779%\n",
      "Epoch [23/300], Step [26/225], Training Accuracy: 72.3558%, Training Loss: 0.6784%\n",
      "Epoch [23/300], Step [27/225], Training Accuracy: 72.1644%, Training Loss: 0.6811%\n",
      "Epoch [23/300], Step [28/225], Training Accuracy: 72.3772%, Training Loss: 0.6764%\n",
      "Epoch [23/300], Step [29/225], Training Accuracy: 72.4138%, Training Loss: 0.6748%\n",
      "Epoch [23/300], Step [30/225], Training Accuracy: 72.5521%, Training Loss: 0.6737%\n",
      "Epoch [23/300], Step [31/225], Training Accuracy: 72.4798%, Training Loss: 0.6776%\n",
      "Epoch [23/300], Step [32/225], Training Accuracy: 72.7051%, Training Loss: 0.6729%\n",
      "Epoch [23/300], Step [33/225], Training Accuracy: 72.8220%, Training Loss: 0.6692%\n",
      "Epoch [23/300], Step [34/225], Training Accuracy: 72.8401%, Training Loss: 0.6681%\n",
      "Epoch [23/300], Step [35/225], Training Accuracy: 72.9911%, Training Loss: 0.6668%\n",
      "Epoch [23/300], Step [36/225], Training Accuracy: 73.1337%, Training Loss: 0.6653%\n",
      "Epoch [23/300], Step [37/225], Training Accuracy: 72.9307%, Training Loss: 0.6698%\n",
      "Epoch [23/300], Step [38/225], Training Accuracy: 73.0674%, Training Loss: 0.6661%\n",
      "Epoch [23/300], Step [39/225], Training Accuracy: 73.2372%, Training Loss: 0.6637%\n",
      "Epoch [23/300], Step [40/225], Training Accuracy: 73.3984%, Training Loss: 0.6616%\n",
      "Epoch [23/300], Step [41/225], Training Accuracy: 73.5137%, Training Loss: 0.6579%\n",
      "Epoch [23/300], Step [42/225], Training Accuracy: 73.7351%, Training Loss: 0.6553%\n",
      "Epoch [23/300], Step [43/225], Training Accuracy: 73.6919%, Training Loss: 0.6561%\n",
      "Epoch [23/300], Step [44/225], Training Accuracy: 73.5085%, Training Loss: 0.6588%\n",
      "Epoch [23/300], Step [45/225], Training Accuracy: 73.5417%, Training Loss: 0.6580%\n",
      "Epoch [23/300], Step [46/225], Training Accuracy: 73.6073%, Training Loss: 0.6552%\n",
      "Epoch [23/300], Step [47/225], Training Accuracy: 73.6370%, Training Loss: 0.6555%\n",
      "Epoch [23/300], Step [48/225], Training Accuracy: 73.5026%, Training Loss: 0.6581%\n",
      "Epoch [23/300], Step [49/225], Training Accuracy: 73.5332%, Training Loss: 0.6607%\n",
      "Epoch [23/300], Step [50/225], Training Accuracy: 73.4688%, Training Loss: 0.6622%\n",
      "Epoch [23/300], Step [51/225], Training Accuracy: 73.5600%, Training Loss: 0.6600%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/300], Step [52/225], Training Accuracy: 73.7380%, Training Loss: 0.6561%\n",
      "Epoch [23/300], Step [53/225], Training Accuracy: 73.7618%, Training Loss: 0.6568%\n",
      "Epoch [23/300], Step [54/225], Training Accuracy: 73.5822%, Training Loss: 0.6595%\n",
      "Epoch [23/300], Step [55/225], Training Accuracy: 73.7216%, Training Loss: 0.6572%\n",
      "Epoch [23/300], Step [56/225], Training Accuracy: 73.7165%, Training Loss: 0.6567%\n",
      "Epoch [23/300], Step [57/225], Training Accuracy: 73.7664%, Training Loss: 0.6565%\n",
      "Epoch [23/300], Step [58/225], Training Accuracy: 73.5991%, Training Loss: 0.6592%\n",
      "Epoch [23/300], Step [59/225], Training Accuracy: 73.4640%, Training Loss: 0.6617%\n",
      "Epoch [23/300], Step [60/225], Training Accuracy: 73.5156%, Training Loss: 0.6622%\n",
      "Epoch [23/300], Step [61/225], Training Accuracy: 73.4375%, Training Loss: 0.6630%\n",
      "Epoch [23/300], Step [62/225], Training Accuracy: 73.3367%, Training Loss: 0.6635%\n",
      "Epoch [23/300], Step [63/225], Training Accuracy: 73.2639%, Training Loss: 0.6641%\n",
      "Epoch [23/300], Step [64/225], Training Accuracy: 73.2666%, Training Loss: 0.6646%\n",
      "Epoch [23/300], Step [65/225], Training Accuracy: 73.3894%, Training Loss: 0.6627%\n",
      "Epoch [23/300], Step [66/225], Training Accuracy: 73.3191%, Training Loss: 0.6631%\n",
      "Epoch [23/300], Step [67/225], Training Accuracy: 73.3442%, Training Loss: 0.6636%\n",
      "Epoch [23/300], Step [68/225], Training Accuracy: 73.2996%, Training Loss: 0.6650%\n",
      "Epoch [23/300], Step [69/225], Training Accuracy: 73.2563%, Training Loss: 0.6655%\n",
      "Epoch [23/300], Step [70/225], Training Accuracy: 73.2143%, Training Loss: 0.6648%\n",
      "Epoch [23/300], Step [71/225], Training Accuracy: 73.2174%, Training Loss: 0.6636%\n",
      "Epoch [23/300], Step [72/225], Training Accuracy: 73.3073%, Training Loss: 0.6621%\n",
      "Epoch [23/300], Step [73/225], Training Accuracy: 73.2449%, Training Loss: 0.6634%\n",
      "Epoch [23/300], Step [74/225], Training Accuracy: 73.2052%, Training Loss: 0.6637%\n",
      "Epoch [23/300], Step [75/225], Training Accuracy: 73.2708%, Training Loss: 0.6621%\n",
      "Epoch [23/300], Step [76/225], Training Accuracy: 73.2936%, Training Loss: 0.6616%\n",
      "Epoch [23/300], Step [77/225], Training Accuracy: 73.2752%, Training Loss: 0.6608%\n",
      "Epoch [23/300], Step [78/225], Training Accuracy: 73.2372%, Training Loss: 0.6609%\n",
      "Epoch [23/300], Step [79/225], Training Accuracy: 73.1804%, Training Loss: 0.6610%\n",
      "Epoch [23/300], Step [80/225], Training Accuracy: 73.1055%, Training Loss: 0.6633%\n",
      "Epoch [23/300], Step [81/225], Training Accuracy: 73.0903%, Training Loss: 0.6635%\n",
      "Epoch [23/300], Step [82/225], Training Accuracy: 73.1898%, Training Loss: 0.6623%\n",
      "Epoch [23/300], Step [83/225], Training Accuracy: 73.1739%, Training Loss: 0.6624%\n",
      "Epoch [23/300], Step [84/225], Training Accuracy: 73.2143%, Training Loss: 0.6612%\n",
      "Epoch [23/300], Step [85/225], Training Accuracy: 73.1618%, Training Loss: 0.6615%\n",
      "Epoch [23/300], Step [86/225], Training Accuracy: 73.1831%, Training Loss: 0.6612%\n",
      "Epoch [23/300], Step [87/225], Training Accuracy: 73.2040%, Training Loss: 0.6602%\n",
      "Epoch [23/300], Step [88/225], Training Accuracy: 73.2777%, Training Loss: 0.6592%\n",
      "Epoch [23/300], Step [89/225], Training Accuracy: 73.2795%, Training Loss: 0.6585%\n",
      "Epoch [23/300], Step [90/225], Training Accuracy: 73.2292%, Training Loss: 0.6578%\n",
      "Epoch [23/300], Step [91/225], Training Accuracy: 73.2486%, Training Loss: 0.6574%\n",
      "Epoch [23/300], Step [92/225], Training Accuracy: 73.2167%, Training Loss: 0.6581%\n",
      "Epoch [23/300], Step [93/225], Training Accuracy: 73.2695%, Training Loss: 0.6577%\n",
      "Epoch [23/300], Step [94/225], Training Accuracy: 73.3045%, Training Loss: 0.6570%\n",
      "Epoch [23/300], Step [95/225], Training Accuracy: 73.3059%, Training Loss: 0.6579%\n",
      "Epoch [23/300], Step [96/225], Training Accuracy: 73.3398%, Training Loss: 0.6567%\n",
      "Epoch [23/300], Step [97/225], Training Accuracy: 73.3409%, Training Loss: 0.6560%\n",
      "Epoch [23/300], Step [98/225], Training Accuracy: 73.4056%, Training Loss: 0.6550%\n",
      "Epoch [23/300], Step [99/225], Training Accuracy: 73.3744%, Training Loss: 0.6553%\n",
      "Epoch [23/300], Step [100/225], Training Accuracy: 73.2500%, Training Loss: 0.6574%\n",
      "Epoch [23/300], Step [101/225], Training Accuracy: 73.2054%, Training Loss: 0.6581%\n",
      "Epoch [23/300], Step [102/225], Training Accuracy: 73.1158%, Training Loss: 0.6601%\n",
      "Epoch [23/300], Step [103/225], Training Accuracy: 73.0734%, Training Loss: 0.6614%\n",
      "Epoch [23/300], Step [104/225], Training Accuracy: 73.0319%, Training Loss: 0.6618%\n",
      "Epoch [23/300], Step [105/225], Training Accuracy: 73.0804%, Training Loss: 0.6615%\n",
      "Epoch [23/300], Step [106/225], Training Accuracy: 72.9805%, Training Loss: 0.6630%\n",
      "Epoch [23/300], Step [107/225], Training Accuracy: 72.9264%, Training Loss: 0.6631%\n",
      "Epoch [23/300], Step [108/225], Training Accuracy: 72.8299%, Training Loss: 0.6642%\n",
      "Epoch [23/300], Step [109/225], Training Accuracy: 72.8211%, Training Loss: 0.6646%\n",
      "Epoch [23/300], Step [110/225], Training Accuracy: 72.9261%, Training Loss: 0.6628%\n",
      "Epoch [23/300], Step [111/225], Training Accuracy: 72.9730%, Training Loss: 0.6617%\n",
      "Epoch [23/300], Step [112/225], Training Accuracy: 72.9353%, Training Loss: 0.6619%\n",
      "Epoch [23/300], Step [113/225], Training Accuracy: 72.9950%, Training Loss: 0.6621%\n",
      "Epoch [23/300], Step [114/225], Training Accuracy: 73.0263%, Training Loss: 0.6613%\n",
      "Epoch [23/300], Step [115/225], Training Accuracy: 72.9755%, Training Loss: 0.6625%\n",
      "Epoch [23/300], Step [116/225], Training Accuracy: 72.8987%, Training Loss: 0.6635%\n",
      "Epoch [23/300], Step [117/225], Training Accuracy: 72.9167%, Training Loss: 0.6626%\n",
      "Epoch [23/300], Step [118/225], Training Accuracy: 72.7887%, Training Loss: 0.6642%\n",
      "Epoch [23/300], Step [119/225], Training Accuracy: 72.7941%, Training Loss: 0.6647%\n",
      "Epoch [23/300], Step [120/225], Training Accuracy: 72.8385%, Training Loss: 0.6641%\n",
      "Epoch [23/300], Step [121/225], Training Accuracy: 72.9339%, Training Loss: 0.6631%\n",
      "Epoch [23/300], Step [122/225], Training Accuracy: 72.9252%, Training Loss: 0.6623%\n",
      "Epoch [23/300], Step [123/225], Training Accuracy: 72.9167%, Training Loss: 0.6621%\n",
      "Epoch [23/300], Step [124/225], Training Accuracy: 72.9209%, Training Loss: 0.6617%\n",
      "Epoch [23/300], Step [125/225], Training Accuracy: 72.9000%, Training Loss: 0.6616%\n",
      "Epoch [23/300], Step [126/225], Training Accuracy: 72.8919%, Training Loss: 0.6614%\n",
      "Epoch [23/300], Step [127/225], Training Accuracy: 72.8962%, Training Loss: 0.6612%\n",
      "Epoch [23/300], Step [128/225], Training Accuracy: 72.8516%, Training Loss: 0.6626%\n",
      "Epoch [23/300], Step [129/225], Training Accuracy: 72.9167%, Training Loss: 0.6617%\n",
      "Epoch [23/300], Step [130/225], Training Accuracy: 72.9447%, Training Loss: 0.6617%\n",
      "Epoch [23/300], Step [131/225], Training Accuracy: 73.0081%, Training Loss: 0.6610%\n",
      "Epoch [23/300], Step [132/225], Training Accuracy: 73.0232%, Training Loss: 0.6603%\n",
      "Epoch [23/300], Step [133/225], Training Accuracy: 73.1555%, Training Loss: 0.6588%\n",
      "Epoch [23/300], Step [134/225], Training Accuracy: 73.1227%, Training Loss: 0.6593%\n",
      "Epoch [23/300], Step [135/225], Training Accuracy: 73.1944%, Training Loss: 0.6576%\n",
      "Epoch [23/300], Step [136/225], Training Accuracy: 73.1618%, Training Loss: 0.6575%\n",
      "Epoch [23/300], Step [137/225], Training Accuracy: 73.2094%, Training Loss: 0.6563%\n",
      "Epoch [23/300], Step [138/225], Training Accuracy: 73.2450%, Training Loss: 0.6554%\n",
      "Epoch [23/300], Step [139/225], Training Accuracy: 73.2352%, Training Loss: 0.6556%\n",
      "Epoch [23/300], Step [140/225], Training Accuracy: 73.2031%, Training Loss: 0.6562%\n",
      "Epoch [23/300], Step [141/225], Training Accuracy: 73.1715%, Training Loss: 0.6568%\n",
      "Epoch [23/300], Step [142/225], Training Accuracy: 73.1734%, Training Loss: 0.6566%\n",
      "Epoch [23/300], Step [143/225], Training Accuracy: 73.1206%, Training Loss: 0.6579%\n",
      "Epoch [23/300], Step [144/225], Training Accuracy: 73.1554%, Training Loss: 0.6570%\n",
      "Epoch [23/300], Step [145/225], Training Accuracy: 73.1573%, Training Loss: 0.6570%\n",
      "Epoch [23/300], Step [146/225], Training Accuracy: 73.1592%, Training Loss: 0.6570%\n",
      "Epoch [23/300], Step [147/225], Training Accuracy: 73.0655%, Training Loss: 0.6584%\n",
      "Epoch [23/300], Step [148/225], Training Accuracy: 73.0469%, Training Loss: 0.6585%\n",
      "Epoch [23/300], Step [149/225], Training Accuracy: 73.0705%, Training Loss: 0.6581%\n",
      "Epoch [23/300], Step [150/225], Training Accuracy: 73.1250%, Training Loss: 0.6567%\n",
      "Epoch [23/300], Step [151/225], Training Accuracy: 73.1581%, Training Loss: 0.6558%\n",
      "Epoch [23/300], Step [152/225], Training Accuracy: 73.1908%, Training Loss: 0.6552%\n",
      "Epoch [23/300], Step [153/225], Training Accuracy: 73.2230%, Training Loss: 0.6545%\n",
      "Epoch [23/300], Step [154/225], Training Accuracy: 73.2549%, Training Loss: 0.6541%\n",
      "Epoch [23/300], Step [155/225], Training Accuracy: 73.3165%, Training Loss: 0.6535%\n",
      "Epoch [23/300], Step [156/225], Training Accuracy: 73.3073%, Training Loss: 0.6536%\n",
      "Epoch [23/300], Step [157/225], Training Accuracy: 73.3579%, Training Loss: 0.6531%\n",
      "Epoch [23/300], Step [158/225], Training Accuracy: 73.4177%, Training Loss: 0.6522%\n",
      "Epoch [23/300], Step [159/225], Training Accuracy: 73.4178%, Training Loss: 0.6521%\n",
      "Epoch [23/300], Step [160/225], Training Accuracy: 73.4180%, Training Loss: 0.6527%\n",
      "Epoch [23/300], Step [161/225], Training Accuracy: 73.4181%, Training Loss: 0.6527%\n",
      "Epoch [23/300], Step [162/225], Training Accuracy: 73.4086%, Training Loss: 0.6521%\n",
      "Epoch [23/300], Step [163/225], Training Accuracy: 73.4567%, Training Loss: 0.6509%\n",
      "Epoch [23/300], Step [164/225], Training Accuracy: 73.4947%, Training Loss: 0.6503%\n",
      "Epoch [23/300], Step [165/225], Training Accuracy: 73.5511%, Training Loss: 0.6499%\n",
      "Epoch [23/300], Step [166/225], Training Accuracy: 73.5222%, Training Loss: 0.6501%\n",
      "Epoch [23/300], Step [167/225], Training Accuracy: 73.5966%, Training Loss: 0.6490%\n",
      "Epoch [23/300], Step [168/225], Training Accuracy: 73.6142%, Training Loss: 0.6484%\n",
      "Epoch [23/300], Step [169/225], Training Accuracy: 73.5762%, Training Loss: 0.6493%\n",
      "Epoch [23/300], Step [170/225], Training Accuracy: 73.5662%, Training Loss: 0.6494%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/300], Step [171/225], Training Accuracy: 73.5471%, Training Loss: 0.6496%\n",
      "Epoch [23/300], Step [172/225], Training Accuracy: 73.5647%, Training Loss: 0.6492%\n",
      "Epoch [23/300], Step [173/225], Training Accuracy: 73.5188%, Training Loss: 0.6495%\n",
      "Epoch [23/300], Step [174/225], Training Accuracy: 73.4914%, Training Loss: 0.6496%\n",
      "Epoch [23/300], Step [175/225], Training Accuracy: 73.5446%, Training Loss: 0.6486%\n",
      "Epoch [23/300], Step [176/225], Training Accuracy: 73.5529%, Training Loss: 0.6487%\n",
      "Epoch [23/300], Step [177/225], Training Accuracy: 73.5699%, Training Loss: 0.6480%\n",
      "Epoch [23/300], Step [178/225], Training Accuracy: 73.5253%, Training Loss: 0.6488%\n",
      "Epoch [23/300], Step [179/225], Training Accuracy: 73.5597%, Training Loss: 0.6485%\n",
      "Epoch [23/300], Step [180/225], Training Accuracy: 73.5851%, Training Loss: 0.6490%\n",
      "Epoch [23/300], Step [181/225], Training Accuracy: 73.5756%, Training Loss: 0.6495%\n",
      "Epoch [23/300], Step [182/225], Training Accuracy: 73.5834%, Training Loss: 0.6494%\n",
      "Epoch [23/300], Step [183/225], Training Accuracy: 73.6253%, Training Loss: 0.6485%\n",
      "Epoch [23/300], Step [184/225], Training Accuracy: 73.6158%, Training Loss: 0.6486%\n",
      "Epoch [23/300], Step [185/225], Training Accuracy: 73.5980%, Training Loss: 0.6484%\n",
      "Epoch [23/300], Step [186/225], Training Accuracy: 73.6559%, Training Loss: 0.6476%\n",
      "Epoch [23/300], Step [187/225], Training Accuracy: 73.6380%, Training Loss: 0.6481%\n",
      "Epoch [23/300], Step [188/225], Training Accuracy: 73.6453%, Training Loss: 0.6478%\n",
      "Epoch [23/300], Step [189/225], Training Accuracy: 73.6772%, Training Loss: 0.6474%\n",
      "Epoch [23/300], Step [190/225], Training Accuracy: 73.6513%, Training Loss: 0.6477%\n",
      "Epoch [23/300], Step [191/225], Training Accuracy: 73.6747%, Training Loss: 0.6473%\n",
      "Epoch [23/300], Step [192/225], Training Accuracy: 73.6898%, Training Loss: 0.6469%\n",
      "Epoch [23/300], Step [193/225], Training Accuracy: 73.6804%, Training Loss: 0.6472%\n",
      "Epoch [23/300], Step [194/225], Training Accuracy: 73.7274%, Training Loss: 0.6460%\n",
      "Epoch [23/300], Step [195/225], Training Accuracy: 73.7420%, Training Loss: 0.6456%\n",
      "Epoch [23/300], Step [196/225], Training Accuracy: 73.8042%, Training Loss: 0.6450%\n",
      "Epoch [23/300], Step [197/225], Training Accuracy: 73.7786%, Training Loss: 0.6461%\n",
      "Epoch [23/300], Step [198/225], Training Accuracy: 73.7610%, Training Loss: 0.6465%\n",
      "Epoch [23/300], Step [199/225], Training Accuracy: 73.7202%, Training Loss: 0.6480%\n",
      "Epoch [23/300], Step [200/225], Training Accuracy: 73.7109%, Training Loss: 0.6481%\n",
      "Epoch [23/300], Step [201/225], Training Accuracy: 73.7407%, Training Loss: 0.6475%\n",
      "Epoch [23/300], Step [202/225], Training Accuracy: 73.7005%, Training Loss: 0.6478%\n",
      "Epoch [23/300], Step [203/225], Training Accuracy: 73.7300%, Training Loss: 0.6475%\n",
      "Epoch [23/300], Step [204/225], Training Accuracy: 73.7286%, Training Loss: 0.6475%\n",
      "Epoch [23/300], Step [205/225], Training Accuracy: 73.7500%, Training Loss: 0.6473%\n",
      "Epoch [23/300], Step [206/225], Training Accuracy: 73.7409%, Training Loss: 0.6475%\n",
      "Epoch [23/300], Step [207/225], Training Accuracy: 73.7772%, Training Loss: 0.6470%\n",
      "Epoch [23/300], Step [208/225], Training Accuracy: 73.7605%, Training Loss: 0.6472%\n",
      "Epoch [23/300], Step [209/225], Training Accuracy: 73.7440%, Training Loss: 0.6475%\n",
      "Epoch [23/300], Step [210/225], Training Accuracy: 73.7500%, Training Loss: 0.6473%\n",
      "Epoch [23/300], Step [211/225], Training Accuracy: 73.7485%, Training Loss: 0.6471%\n",
      "Epoch [23/300], Step [212/225], Training Accuracy: 73.7544%, Training Loss: 0.6476%\n",
      "Epoch [23/300], Step [213/225], Training Accuracy: 73.7089%, Training Loss: 0.6480%\n",
      "Epoch [23/300], Step [214/225], Training Accuracy: 73.7442%, Training Loss: 0.6477%\n",
      "Epoch [23/300], Step [215/225], Training Accuracy: 73.7427%, Training Loss: 0.6472%\n",
      "Epoch [23/300], Step [216/225], Training Accuracy: 73.7052%, Training Loss: 0.6477%\n",
      "Epoch [23/300], Step [217/225], Training Accuracy: 73.7327%, Training Loss: 0.6474%\n",
      "Epoch [23/300], Step [218/225], Training Accuracy: 73.7170%, Training Loss: 0.6480%\n",
      "Epoch [23/300], Step [219/225], Training Accuracy: 73.7158%, Training Loss: 0.6479%\n",
      "Epoch [23/300], Step [220/225], Training Accuracy: 73.7500%, Training Loss: 0.6472%\n",
      "Epoch [23/300], Step [221/225], Training Accuracy: 73.7486%, Training Loss: 0.6476%\n",
      "Epoch [23/300], Step [222/225], Training Accuracy: 73.7401%, Training Loss: 0.6479%\n",
      "Epoch [23/300], Step [223/225], Training Accuracy: 73.7808%, Training Loss: 0.6473%\n",
      "Epoch [23/300], Step [224/225], Training Accuracy: 73.7723%, Training Loss: 0.6472%\n",
      "Epoch [23/300], Step [225/225], Training Accuracy: 73.7632%, Training Loss: 0.6471%\n",
      "Epoch [24/300], Step [1/225], Training Accuracy: 73.4375%, Training Loss: 0.7137%\n",
      "Epoch [24/300], Step [2/225], Training Accuracy: 75.0000%, Training Loss: 0.6257%\n",
      "Epoch [24/300], Step [3/225], Training Accuracy: 72.3958%, Training Loss: 0.6794%\n",
      "Epoch [24/300], Step [4/225], Training Accuracy: 73.4375%, Training Loss: 0.6465%\n",
      "Epoch [24/300], Step [5/225], Training Accuracy: 75.6250%, Training Loss: 0.6134%\n",
      "Epoch [24/300], Step [6/225], Training Accuracy: 74.7396%, Training Loss: 0.6194%\n",
      "Epoch [24/300], Step [7/225], Training Accuracy: 74.1071%, Training Loss: 0.6467%\n",
      "Epoch [24/300], Step [8/225], Training Accuracy: 75.0000%, Training Loss: 0.6239%\n",
      "Epoch [24/300], Step [9/225], Training Accuracy: 75.1736%, Training Loss: 0.6154%\n",
      "Epoch [24/300], Step [10/225], Training Accuracy: 74.5312%, Training Loss: 0.6221%\n",
      "Epoch [24/300], Step [11/225], Training Accuracy: 74.8580%, Training Loss: 0.6143%\n",
      "Epoch [24/300], Step [12/225], Training Accuracy: 75.0000%, Training Loss: 0.6131%\n",
      "Epoch [24/300], Step [13/225], Training Accuracy: 75.1202%, Training Loss: 0.6094%\n",
      "Epoch [24/300], Step [14/225], Training Accuracy: 74.5536%, Training Loss: 0.6157%\n",
      "Epoch [24/300], Step [15/225], Training Accuracy: 75.1042%, Training Loss: 0.6050%\n",
      "Epoch [24/300], Step [16/225], Training Accuracy: 73.6328%, Training Loss: 0.6250%\n",
      "Epoch [24/300], Step [17/225], Training Accuracy: 73.6213%, Training Loss: 0.6308%\n",
      "Epoch [24/300], Step [18/225], Training Accuracy: 73.0035%, Training Loss: 0.6443%\n",
      "Epoch [24/300], Step [19/225], Training Accuracy: 73.0263%, Training Loss: 0.6392%\n",
      "Epoch [24/300], Step [20/225], Training Accuracy: 73.3594%, Training Loss: 0.6322%\n",
      "Epoch [24/300], Step [21/225], Training Accuracy: 73.5119%, Training Loss: 0.6289%\n",
      "Epoch [24/300], Step [22/225], Training Accuracy: 73.4375%, Training Loss: 0.6371%\n",
      "Epoch [24/300], Step [23/225], Training Accuracy: 73.3696%, Training Loss: 0.6379%\n",
      "Epoch [24/300], Step [24/225], Training Accuracy: 72.8516%, Training Loss: 0.6472%\n",
      "Epoch [24/300], Step [25/225], Training Accuracy: 72.8125%, Training Loss: 0.6445%\n",
      "Epoch [24/300], Step [26/225], Training Accuracy: 73.0168%, Training Loss: 0.6435%\n",
      "Epoch [24/300], Step [27/225], Training Accuracy: 73.0324%, Training Loss: 0.6445%\n",
      "Epoch [24/300], Step [28/225], Training Accuracy: 73.2701%, Training Loss: 0.6402%\n",
      "Epoch [24/300], Step [29/225], Training Accuracy: 73.4375%, Training Loss: 0.6381%\n",
      "Epoch [24/300], Step [30/225], Training Accuracy: 73.4375%, Training Loss: 0.6439%\n",
      "Epoch [24/300], Step [31/225], Training Accuracy: 73.3871%, Training Loss: 0.6462%\n",
      "Epoch [24/300], Step [32/225], Training Accuracy: 73.4863%, Training Loss: 0.6424%\n",
      "Epoch [24/300], Step [33/225], Training Accuracy: 73.4375%, Training Loss: 0.6433%\n",
      "Epoch [24/300], Step [34/225], Training Accuracy: 73.8051%, Training Loss: 0.6391%\n",
      "Epoch [24/300], Step [35/225], Training Accuracy: 73.8839%, Training Loss: 0.6371%\n",
      "Epoch [24/300], Step [36/225], Training Accuracy: 74.0017%, Training Loss: 0.6351%\n",
      "Epoch [24/300], Step [37/225], Training Accuracy: 74.0287%, Training Loss: 0.6364%\n",
      "Epoch [24/300], Step [38/225], Training Accuracy: 74.1776%, Training Loss: 0.6333%\n",
      "Epoch [24/300], Step [39/225], Training Accuracy: 74.1987%, Training Loss: 0.6325%\n",
      "Epoch [24/300], Step [40/225], Training Accuracy: 74.1406%, Training Loss: 0.6328%\n",
      "Epoch [24/300], Step [41/225], Training Accuracy: 74.1616%, Training Loss: 0.6305%\n",
      "Epoch [24/300], Step [42/225], Training Accuracy: 74.2560%, Training Loss: 0.6306%\n",
      "Epoch [24/300], Step [43/225], Training Accuracy: 74.0916%, Training Loss: 0.6341%\n",
      "Epoch [24/300], Step [44/225], Training Accuracy: 74.0767%, Training Loss: 0.6351%\n",
      "Epoch [24/300], Step [45/225], Training Accuracy: 74.2014%, Training Loss: 0.6344%\n",
      "Epoch [24/300], Step [46/225], Training Accuracy: 74.2867%, Training Loss: 0.6321%\n",
      "Epoch [24/300], Step [47/225], Training Accuracy: 74.2686%, Training Loss: 0.6303%\n",
      "Epoch [24/300], Step [48/225], Training Accuracy: 74.3490%, Training Loss: 0.6305%\n",
      "Epoch [24/300], Step [49/225], Training Accuracy: 74.3941%, Training Loss: 0.6317%\n",
      "Epoch [24/300], Step [50/225], Training Accuracy: 74.3438%, Training Loss: 0.6323%\n",
      "Epoch [24/300], Step [51/225], Training Accuracy: 74.3873%, Training Loss: 0.6317%\n",
      "Epoch [24/300], Step [52/225], Training Accuracy: 74.6094%, Training Loss: 0.6287%\n",
      "Epoch [24/300], Step [53/225], Training Accuracy: 74.6757%, Training Loss: 0.6293%\n",
      "Epoch [24/300], Step [54/225], Training Accuracy: 74.5660%, Training Loss: 0.6329%\n",
      "Epoch [24/300], Step [55/225], Training Accuracy: 74.6875%, Training Loss: 0.6309%\n",
      "Epoch [24/300], Step [56/225], Training Accuracy: 74.6094%, Training Loss: 0.6322%\n",
      "Epoch [24/300], Step [57/225], Training Accuracy: 74.6711%, Training Loss: 0.6316%\n",
      "Epoch [24/300], Step [58/225], Training Accuracy: 74.6767%, Training Loss: 0.6311%\n",
      "Epoch [24/300], Step [59/225], Training Accuracy: 74.4703%, Training Loss: 0.6342%\n",
      "Epoch [24/300], Step [60/225], Training Accuracy: 74.4792%, Training Loss: 0.6334%\n",
      "Epoch [24/300], Step [61/225], Training Accuracy: 74.4365%, Training Loss: 0.6333%\n",
      "Epoch [24/300], Step [62/225], Training Accuracy: 74.3448%, Training Loss: 0.6344%\n",
      "Epoch [24/300], Step [63/225], Training Accuracy: 74.3056%, Training Loss: 0.6353%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/300], Step [64/225], Training Accuracy: 74.2920%, Training Loss: 0.6347%\n",
      "Epoch [24/300], Step [65/225], Training Accuracy: 74.4471%, Training Loss: 0.6334%\n",
      "Epoch [24/300], Step [66/225], Training Accuracy: 74.5028%, Training Loss: 0.6318%\n",
      "Epoch [24/300], Step [67/225], Training Accuracy: 74.3237%, Training Loss: 0.6332%\n",
      "Epoch [24/300], Step [68/225], Training Accuracy: 74.3336%, Training Loss: 0.6334%\n",
      "Epoch [24/300], Step [69/225], Training Accuracy: 74.2301%, Training Loss: 0.6341%\n",
      "Epoch [24/300], Step [70/225], Training Accuracy: 74.3304%, Training Loss: 0.6319%\n",
      "Epoch [24/300], Step [71/225], Training Accuracy: 74.3838%, Training Loss: 0.6312%\n",
      "Epoch [24/300], Step [72/225], Training Accuracy: 74.3924%, Training Loss: 0.6307%\n",
      "Epoch [24/300], Step [73/225], Training Accuracy: 74.3151%, Training Loss: 0.6321%\n",
      "Epoch [24/300], Step [74/225], Training Accuracy: 74.2188%, Training Loss: 0.6318%\n",
      "Epoch [24/300], Step [75/225], Training Accuracy: 74.2917%, Training Loss: 0.6299%\n",
      "Epoch [24/300], Step [76/225], Training Accuracy: 74.3010%, Training Loss: 0.6296%\n",
      "Epoch [24/300], Step [77/225], Training Accuracy: 74.3304%, Training Loss: 0.6287%\n",
      "Epoch [24/300], Step [78/225], Training Accuracy: 74.3389%, Training Loss: 0.6279%\n",
      "Epoch [24/300], Step [79/225], Training Accuracy: 74.2880%, Training Loss: 0.6285%\n",
      "Epoch [24/300], Step [80/225], Training Accuracy: 74.2578%, Training Loss: 0.6295%\n",
      "Epoch [24/300], Step [81/225], Training Accuracy: 74.3056%, Training Loss: 0.6290%\n",
      "Epoch [24/300], Step [82/225], Training Accuracy: 74.4093%, Training Loss: 0.6276%\n",
      "Epoch [24/300], Step [83/225], Training Accuracy: 74.4541%, Training Loss: 0.6276%\n",
      "Epoch [24/300], Step [84/225], Training Accuracy: 74.4048%, Training Loss: 0.6281%\n",
      "Epoch [24/300], Step [85/225], Training Accuracy: 74.5037%, Training Loss: 0.6278%\n",
      "Epoch [24/300], Step [86/225], Training Accuracy: 74.4913%, Training Loss: 0.6275%\n",
      "Epoch [24/300], Step [87/225], Training Accuracy: 74.4792%, Training Loss: 0.6273%\n",
      "Epoch [24/300], Step [88/225], Training Accuracy: 74.5206%, Training Loss: 0.6265%\n",
      "Epoch [24/300], Step [89/225], Training Accuracy: 74.6138%, Training Loss: 0.6257%\n",
      "Epoch [24/300], Step [90/225], Training Accuracy: 74.6528%, Training Loss: 0.6248%\n",
      "Epoch [24/300], Step [91/225], Training Accuracy: 74.5879%, Training Loss: 0.6259%\n",
      "Epoch [24/300], Step [92/225], Training Accuracy: 74.5075%, Training Loss: 0.6270%\n",
      "Epoch [24/300], Step [93/225], Training Accuracy: 74.6136%, Training Loss: 0.6259%\n",
      "Epoch [24/300], Step [94/225], Training Accuracy: 74.6676%, Training Loss: 0.6242%\n",
      "Epoch [24/300], Step [95/225], Training Accuracy: 74.6217%, Training Loss: 0.6240%\n",
      "Epoch [24/300], Step [96/225], Training Accuracy: 74.6257%, Training Loss: 0.6237%\n",
      "Epoch [24/300], Step [97/225], Training Accuracy: 74.6617%, Training Loss: 0.6228%\n",
      "Epoch [24/300], Step [98/225], Training Accuracy: 74.7290%, Training Loss: 0.6217%\n",
      "Epoch [24/300], Step [99/225], Training Accuracy: 74.7001%, Training Loss: 0.6219%\n",
      "Epoch [24/300], Step [100/225], Training Accuracy: 74.7031%, Training Loss: 0.6222%\n",
      "Epoch [24/300], Step [101/225], Training Accuracy: 74.7061%, Training Loss: 0.6227%\n",
      "Epoch [24/300], Step [102/225], Training Accuracy: 74.6783%, Training Loss: 0.6235%\n",
      "Epoch [24/300], Step [103/225], Training Accuracy: 74.6814%, Training Loss: 0.6240%\n",
      "Epoch [24/300], Step [104/225], Training Accuracy: 74.6244%, Training Loss: 0.6244%\n",
      "Epoch [24/300], Step [105/225], Training Accuracy: 74.6429%, Training Loss: 0.6249%\n",
      "Epoch [24/300], Step [106/225], Training Accuracy: 74.6462%, Training Loss: 0.6258%\n",
      "Epoch [24/300], Step [107/225], Training Accuracy: 74.5765%, Training Loss: 0.6258%\n",
      "Epoch [24/300], Step [108/225], Training Accuracy: 74.5515%, Training Loss: 0.6263%\n",
      "Epoch [24/300], Step [109/225], Training Accuracy: 74.5126%, Training Loss: 0.6273%\n",
      "Epoch [24/300], Step [110/225], Training Accuracy: 74.6023%, Training Loss: 0.6260%\n",
      "Epoch [24/300], Step [111/225], Training Accuracy: 74.5777%, Training Loss: 0.6254%\n",
      "Epoch [24/300], Step [112/225], Training Accuracy: 74.5675%, Training Loss: 0.6251%\n",
      "Epoch [24/300], Step [113/225], Training Accuracy: 74.5713%, Training Loss: 0.6246%\n",
      "Epoch [24/300], Step [114/225], Training Accuracy: 74.5751%, Training Loss: 0.6243%\n",
      "Epoch [24/300], Step [115/225], Training Accuracy: 74.5652%, Training Loss: 0.6249%\n",
      "Epoch [24/300], Step [116/225], Training Accuracy: 74.5286%, Training Loss: 0.6256%\n",
      "Epoch [24/300], Step [117/225], Training Accuracy: 74.4925%, Training Loss: 0.6256%\n",
      "Epoch [24/300], Step [118/225], Training Accuracy: 74.3909%, Training Loss: 0.6272%\n",
      "Epoch [24/300], Step [119/225], Training Accuracy: 74.3829%, Training Loss: 0.6281%\n",
      "Epoch [24/300], Step [120/225], Training Accuracy: 74.4141%, Training Loss: 0.6281%\n",
      "Epoch [24/300], Step [121/225], Training Accuracy: 74.4189%, Training Loss: 0.6280%\n",
      "Epoch [24/300], Step [122/225], Training Accuracy: 74.4109%, Training Loss: 0.6276%\n",
      "Epoch [24/300], Step [123/225], Training Accuracy: 74.4665%, Training Loss: 0.6275%\n",
      "Epoch [24/300], Step [124/225], Training Accuracy: 74.4834%, Training Loss: 0.6271%\n",
      "Epoch [24/300], Step [125/225], Training Accuracy: 74.5000%, Training Loss: 0.6265%\n",
      "Epoch [24/300], Step [126/225], Training Accuracy: 74.5288%, Training Loss: 0.6256%\n",
      "Epoch [24/300], Step [127/225], Training Accuracy: 74.5079%, Training Loss: 0.6250%\n",
      "Epoch [24/300], Step [128/225], Training Accuracy: 74.4385%, Training Loss: 0.6259%\n",
      "Epoch [24/300], Step [129/225], Training Accuracy: 74.4428%, Training Loss: 0.6256%\n",
      "Epoch [24/300], Step [130/225], Training Accuracy: 74.3510%, Training Loss: 0.6265%\n",
      "Epoch [24/300], Step [131/225], Training Accuracy: 74.3559%, Training Loss: 0.6267%\n",
      "Epoch [24/300], Step [132/225], Training Accuracy: 74.3371%, Training Loss: 0.6273%\n",
      "Epoch [24/300], Step [133/225], Training Accuracy: 74.4008%, Training Loss: 0.6257%\n",
      "Epoch [24/300], Step [134/225], Training Accuracy: 74.4053%, Training Loss: 0.6259%\n",
      "Epoch [24/300], Step [135/225], Training Accuracy: 74.4676%, Training Loss: 0.6245%\n",
      "Epoch [24/300], Step [136/225], Training Accuracy: 74.4945%, Training Loss: 0.6241%\n",
      "Epoch [24/300], Step [137/225], Training Accuracy: 74.5210%, Training Loss: 0.6237%\n",
      "Epoch [24/300], Step [138/225], Training Accuracy: 74.5245%, Training Loss: 0.6237%\n",
      "Epoch [24/300], Step [139/225], Training Accuracy: 74.4942%, Training Loss: 0.6245%\n",
      "Epoch [24/300], Step [140/225], Training Accuracy: 74.4866%, Training Loss: 0.6242%\n",
      "Epoch [24/300], Step [141/225], Training Accuracy: 74.4681%, Training Loss: 0.6243%\n",
      "Epoch [24/300], Step [142/225], Training Accuracy: 74.4498%, Training Loss: 0.6246%\n",
      "Epoch [24/300], Step [143/225], Training Accuracy: 74.4318%, Training Loss: 0.6249%\n",
      "Epoch [24/300], Step [144/225], Training Accuracy: 74.4358%, Training Loss: 0.6243%\n",
      "Epoch [24/300], Step [145/225], Training Accuracy: 74.5151%, Training Loss: 0.6236%\n",
      "Epoch [24/300], Step [146/225], Training Accuracy: 74.4970%, Training Loss: 0.6240%\n",
      "Epoch [24/300], Step [147/225], Training Accuracy: 74.4260%, Training Loss: 0.6251%\n",
      "Epoch [24/300], Step [148/225], Training Accuracy: 74.4088%, Training Loss: 0.6249%\n",
      "Epoch [24/300], Step [149/225], Training Accuracy: 74.4128%, Training Loss: 0.6245%\n",
      "Epoch [24/300], Step [150/225], Training Accuracy: 74.5417%, Training Loss: 0.6227%\n",
      "Epoch [24/300], Step [151/225], Training Accuracy: 74.5964%, Training Loss: 0.6219%\n",
      "Epoch [24/300], Step [152/225], Training Accuracy: 74.5888%, Training Loss: 0.6217%\n",
      "Epoch [24/300], Step [153/225], Training Accuracy: 74.6834%, Training Loss: 0.6208%\n",
      "Epoch [24/300], Step [154/225], Training Accuracy: 74.7159%, Training Loss: 0.6202%\n",
      "Epoch [24/300], Step [155/225], Training Accuracy: 74.7379%, Training Loss: 0.6202%\n",
      "Epoch [24/300], Step [156/225], Training Accuracy: 74.7296%, Training Loss: 0.6202%\n",
      "Epoch [24/300], Step [157/225], Training Accuracy: 74.7412%, Training Loss: 0.6201%\n",
      "Epoch [24/300], Step [158/225], Training Accuracy: 74.8022%, Training Loss: 0.6198%\n",
      "Epoch [24/300], Step [159/225], Training Accuracy: 74.8035%, Training Loss: 0.6194%\n",
      "Epoch [24/300], Step [160/225], Training Accuracy: 74.8340%, Training Loss: 0.6195%\n",
      "Epoch [24/300], Step [161/225], Training Accuracy: 74.8544%, Training Loss: 0.6192%\n",
      "Epoch [24/300], Step [162/225], Training Accuracy: 74.9035%, Training Loss: 0.6183%\n",
      "Epoch [24/300], Step [163/225], Training Accuracy: 74.9329%, Training Loss: 0.6175%\n",
      "Epoch [24/300], Step [164/225], Training Accuracy: 74.9524%, Training Loss: 0.6167%\n",
      "Epoch [24/300], Step [165/225], Training Accuracy: 75.0095%, Training Loss: 0.6160%\n",
      "Epoch [24/300], Step [166/225], Training Accuracy: 74.9529%, Training Loss: 0.6161%\n",
      "Epoch [24/300], Step [167/225], Training Accuracy: 74.9439%, Training Loss: 0.6163%\n",
      "Epoch [24/300], Step [168/225], Training Accuracy: 74.9535%, Training Loss: 0.6158%\n",
      "Epoch [24/300], Step [169/225], Training Accuracy: 74.8798%, Training Loss: 0.6172%\n",
      "Epoch [24/300], Step [170/225], Training Accuracy: 74.8897%, Training Loss: 0.6174%\n",
      "Epoch [24/300], Step [171/225], Training Accuracy: 74.8904%, Training Loss: 0.6178%\n",
      "Epoch [24/300], Step [172/225], Training Accuracy: 74.9273%, Training Loss: 0.6177%\n",
      "Epoch [24/300], Step [173/225], Training Accuracy: 74.9187%, Training Loss: 0.6176%\n",
      "Epoch [24/300], Step [174/225], Training Accuracy: 74.9012%, Training Loss: 0.6173%\n",
      "Epoch [24/300], Step [175/225], Training Accuracy: 74.9732%, Training Loss: 0.6160%\n",
      "Epoch [24/300], Step [176/225], Training Accuracy: 74.9379%, Training Loss: 0.6163%\n",
      "Epoch [24/300], Step [177/225], Training Accuracy: 74.9647%, Training Loss: 0.6157%\n",
      "Epoch [24/300], Step [178/225], Training Accuracy: 74.9473%, Training Loss: 0.6156%\n",
      "Epoch [24/300], Step [179/225], Training Accuracy: 74.9302%, Training Loss: 0.6158%\n",
      "Epoch [24/300], Step [180/225], Training Accuracy: 74.9392%, Training Loss: 0.6162%\n",
      "Epoch [24/300], Step [181/225], Training Accuracy: 74.9137%, Training Loss: 0.6164%\n",
      "Epoch [24/300], Step [182/225], Training Accuracy: 74.9056%, Training Loss: 0.6160%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/300], Step [183/225], Training Accuracy: 74.9402%, Training Loss: 0.6153%\n",
      "Epoch [24/300], Step [184/225], Training Accuracy: 74.9236%, Training Loss: 0.6158%\n",
      "Epoch [24/300], Step [185/225], Training Accuracy: 74.9747%, Training Loss: 0.6152%\n",
      "Epoch [24/300], Step [186/225], Training Accuracy: 74.9832%, Training Loss: 0.6149%\n",
      "Epoch [24/300], Step [187/225], Training Accuracy: 75.0000%, Training Loss: 0.6145%\n",
      "Epoch [24/300], Step [188/225], Training Accuracy: 75.0332%, Training Loss: 0.6140%\n",
      "Epoch [24/300], Step [189/225], Training Accuracy: 75.0579%, Training Loss: 0.6134%\n",
      "Epoch [24/300], Step [190/225], Training Accuracy: 75.0329%, Training Loss: 0.6138%\n",
      "Epoch [24/300], Step [191/225], Training Accuracy: 75.0736%, Training Loss: 0.6133%\n",
      "Epoch [24/300], Step [192/225], Training Accuracy: 75.0814%, Training Loss: 0.6133%\n",
      "Epoch [24/300], Step [193/225], Training Accuracy: 75.0972%, Training Loss: 0.6134%\n",
      "Epoch [24/300], Step [194/225], Training Accuracy: 75.1852%, Training Loss: 0.6117%\n",
      "Epoch [24/300], Step [195/225], Training Accuracy: 75.1763%, Training Loss: 0.6116%\n",
      "Epoch [24/300], Step [196/225], Training Accuracy: 75.1913%, Training Loss: 0.6111%\n",
      "Epoch [24/300], Step [197/225], Training Accuracy: 75.1586%, Training Loss: 0.6120%\n",
      "Epoch [24/300], Step [198/225], Training Accuracy: 75.1815%, Training Loss: 0.6121%\n",
      "Epoch [24/300], Step [199/225], Training Accuracy: 75.1335%, Training Loss: 0.6131%\n",
      "Epoch [24/300], Step [200/225], Training Accuracy: 75.1406%, Training Loss: 0.6128%\n",
      "Epoch [24/300], Step [201/225], Training Accuracy: 75.1632%, Training Loss: 0.6123%\n",
      "Epoch [24/300], Step [202/225], Training Accuracy: 75.1392%, Training Loss: 0.6131%\n",
      "Epoch [24/300], Step [203/225], Training Accuracy: 75.1462%, Training Loss: 0.6130%\n",
      "Epoch [24/300], Step [204/225], Training Accuracy: 75.1608%, Training Loss: 0.6126%\n",
      "Epoch [24/300], Step [205/225], Training Accuracy: 75.2058%, Training Loss: 0.6123%\n",
      "Epoch [24/300], Step [206/225], Training Accuracy: 75.1896%, Training Loss: 0.6124%\n",
      "Epoch [24/300], Step [207/225], Training Accuracy: 75.2415%, Training Loss: 0.6115%\n",
      "Epoch [24/300], Step [208/225], Training Accuracy: 75.2329%, Training Loss: 0.6113%\n",
      "Epoch [24/300], Step [209/225], Training Accuracy: 75.2318%, Training Loss: 0.6116%\n",
      "Epoch [24/300], Step [210/225], Training Accuracy: 75.2158%, Training Loss: 0.6120%\n",
      "Epoch [24/300], Step [211/225], Training Accuracy: 75.1925%, Training Loss: 0.6122%\n",
      "Epoch [24/300], Step [212/225], Training Accuracy: 75.1990%, Training Loss: 0.6125%\n",
      "Epoch [24/300], Step [213/225], Training Accuracy: 75.1834%, Training Loss: 0.6125%\n",
      "Epoch [24/300], Step [214/225], Training Accuracy: 75.2117%, Training Loss: 0.6124%\n",
      "Epoch [24/300], Step [215/225], Training Accuracy: 75.2326%, Training Loss: 0.6119%\n",
      "Epoch [24/300], Step [216/225], Training Accuracy: 75.1953%, Training Loss: 0.6124%\n",
      "Epoch [24/300], Step [217/225], Training Accuracy: 75.2016%, Training Loss: 0.6121%\n",
      "Epoch [24/300], Step [218/225], Training Accuracy: 75.1649%, Training Loss: 0.6126%\n",
      "Epoch [24/300], Step [219/225], Training Accuracy: 75.1570%, Training Loss: 0.6127%\n",
      "Epoch [24/300], Step [220/225], Training Accuracy: 75.1420%, Training Loss: 0.6129%\n",
      "Epoch [24/300], Step [221/225], Training Accuracy: 75.1343%, Training Loss: 0.6136%\n",
      "Epoch [24/300], Step [222/225], Training Accuracy: 75.0704%, Training Loss: 0.6140%\n",
      "Epoch [24/300], Step [223/225], Training Accuracy: 75.0841%, Training Loss: 0.6139%\n",
      "Epoch [24/300], Step [224/225], Training Accuracy: 75.0907%, Training Loss: 0.6135%\n",
      "Epoch [24/300], Step [225/225], Training Accuracy: 75.1042%, Training Loss: 0.6132%\n",
      "Epoch [25/300], Step [1/225], Training Accuracy: 78.1250%, Training Loss: 0.5769%\n",
      "Epoch [25/300], Step [2/225], Training Accuracy: 75.7812%, Training Loss: 0.5757%\n",
      "Epoch [25/300], Step [3/225], Training Accuracy: 77.0833%, Training Loss: 0.5777%\n",
      "Epoch [25/300], Step [4/225], Training Accuracy: 78.9062%, Training Loss: 0.5420%\n",
      "Epoch [25/300], Step [5/225], Training Accuracy: 78.7500%, Training Loss: 0.5438%\n",
      "Epoch [25/300], Step [6/225], Training Accuracy: 77.3438%, Training Loss: 0.5605%\n",
      "Epoch [25/300], Step [7/225], Training Accuracy: 75.6696%, Training Loss: 0.5943%\n",
      "Epoch [25/300], Step [8/225], Training Accuracy: 76.1719%, Training Loss: 0.5813%\n",
      "Epoch [25/300], Step [9/225], Training Accuracy: 75.8681%, Training Loss: 0.5897%\n",
      "Epoch [25/300], Step [10/225], Training Accuracy: 75.9375%, Training Loss: 0.5868%\n",
      "Epoch [25/300], Step [11/225], Training Accuracy: 75.9943%, Training Loss: 0.5789%\n",
      "Epoch [25/300], Step [12/225], Training Accuracy: 76.8229%, Training Loss: 0.5703%\n",
      "Epoch [25/300], Step [13/225], Training Accuracy: 76.8029%, Training Loss: 0.5719%\n",
      "Epoch [25/300], Step [14/225], Training Accuracy: 76.0045%, Training Loss: 0.5829%\n",
      "Epoch [25/300], Step [15/225], Training Accuracy: 76.2500%, Training Loss: 0.5750%\n",
      "Epoch [25/300], Step [16/225], Training Accuracy: 75.6836%, Training Loss: 0.5941%\n",
      "Epoch [25/300], Step [17/225], Training Accuracy: 75.6434%, Training Loss: 0.6008%\n",
      "Epoch [25/300], Step [18/225], Training Accuracy: 75.5208%, Training Loss: 0.6083%\n",
      "Epoch [25/300], Step [19/225], Training Accuracy: 75.9046%, Training Loss: 0.6002%\n",
      "Epoch [25/300], Step [20/225], Training Accuracy: 76.4844%, Training Loss: 0.5928%\n",
      "Epoch [25/300], Step [21/225], Training Accuracy: 76.5625%, Training Loss: 0.5905%\n",
      "Epoch [25/300], Step [22/225], Training Accuracy: 76.4915%, Training Loss: 0.5955%\n",
      "Epoch [25/300], Step [23/225], Training Accuracy: 76.2228%, Training Loss: 0.6026%\n",
      "Epoch [25/300], Step [24/225], Training Accuracy: 75.7812%, Training Loss: 0.6119%\n",
      "Epoch [25/300], Step [25/225], Training Accuracy: 75.6875%, Training Loss: 0.6097%\n",
      "Epoch [25/300], Step [26/225], Training Accuracy: 75.6611%, Training Loss: 0.6115%\n",
      "Epoch [25/300], Step [27/225], Training Accuracy: 75.5208%, Training Loss: 0.6145%\n",
      "Epoch [25/300], Step [28/225], Training Accuracy: 75.8371%, Training Loss: 0.6071%\n",
      "Epoch [25/300], Step [29/225], Training Accuracy: 75.9159%, Training Loss: 0.6022%\n",
      "Epoch [25/300], Step [30/225], Training Accuracy: 76.1458%, Training Loss: 0.6013%\n",
      "Epoch [25/300], Step [31/225], Training Accuracy: 76.0081%, Training Loss: 0.6050%\n",
      "Epoch [25/300], Step [32/225], Training Accuracy: 76.0254%, Training Loss: 0.6016%\n",
      "Epoch [25/300], Step [33/225], Training Accuracy: 76.2311%, Training Loss: 0.5980%\n",
      "Epoch [25/300], Step [34/225], Training Accuracy: 76.2408%, Training Loss: 0.5977%\n",
      "Epoch [25/300], Step [35/225], Training Accuracy: 76.2054%, Training Loss: 0.5977%\n",
      "Epoch [25/300], Step [36/225], Training Accuracy: 76.3889%, Training Loss: 0.5949%\n",
      "Epoch [25/300], Step [37/225], Training Accuracy: 76.5203%, Training Loss: 0.5930%\n",
      "Epoch [25/300], Step [38/225], Training Accuracy: 76.7681%, Training Loss: 0.5892%\n",
      "Epoch [25/300], Step [39/225], Training Accuracy: 76.8830%, Training Loss: 0.5864%\n",
      "Epoch [25/300], Step [40/225], Training Accuracy: 76.8359%, Training Loss: 0.5860%\n",
      "Epoch [25/300], Step [41/225], Training Accuracy: 76.9436%, Training Loss: 0.5852%\n",
      "Epoch [25/300], Step [42/225], Training Accuracy: 76.9717%, Training Loss: 0.5847%\n",
      "Epoch [25/300], Step [43/225], Training Accuracy: 76.9622%, Training Loss: 0.5847%\n",
      "Epoch [25/300], Step [44/225], Training Accuracy: 77.0597%, Training Loss: 0.5830%\n",
      "Epoch [25/300], Step [45/225], Training Accuracy: 77.0486%, Training Loss: 0.5817%\n",
      "Epoch [25/300], Step [46/225], Training Accuracy: 77.1399%, Training Loss: 0.5813%\n",
      "Epoch [25/300], Step [47/225], Training Accuracy: 77.1277%, Training Loss: 0.5821%\n",
      "Epoch [25/300], Step [48/225], Training Accuracy: 77.0182%, Training Loss: 0.5857%\n",
      "Epoch [25/300], Step [49/225], Training Accuracy: 76.9133%, Training Loss: 0.5868%\n",
      "Epoch [25/300], Step [50/225], Training Accuracy: 76.7812%, Training Loss: 0.5873%\n",
      "Epoch [25/300], Step [51/225], Training Accuracy: 76.8382%, Training Loss: 0.5860%\n",
      "Epoch [25/300], Step [52/225], Training Accuracy: 76.8930%, Training Loss: 0.5834%\n",
      "Epoch [25/300], Step [53/225], Training Accuracy: 76.8573%, Training Loss: 0.5845%\n",
      "Epoch [25/300], Step [54/225], Training Accuracy: 76.7650%, Training Loss: 0.5867%\n",
      "Epoch [25/300], Step [55/225], Training Accuracy: 76.8750%, Training Loss: 0.5855%\n",
      "Epoch [25/300], Step [56/225], Training Accuracy: 76.8694%, Training Loss: 0.5856%\n",
      "Epoch [25/300], Step [57/225], Training Accuracy: 76.8092%, Training Loss: 0.5857%\n",
      "Epoch [25/300], Step [58/225], Training Accuracy: 76.6433%, Training Loss: 0.5886%\n",
      "Epoch [25/300], Step [59/225], Training Accuracy: 76.5890%, Training Loss: 0.5896%\n",
      "Epoch [25/300], Step [60/225], Training Accuracy: 76.7188%, Training Loss: 0.5896%\n",
      "Epoch [25/300], Step [61/225], Training Accuracy: 76.6650%, Training Loss: 0.5901%\n",
      "Epoch [25/300], Step [62/225], Training Accuracy: 76.5121%, Training Loss: 0.5919%\n",
      "Epoch [25/300], Step [63/225], Training Accuracy: 76.4633%, Training Loss: 0.5929%\n",
      "Epoch [25/300], Step [64/225], Training Accuracy: 76.5869%, Training Loss: 0.5912%\n",
      "Epoch [25/300], Step [65/225], Training Accuracy: 76.6106%, Training Loss: 0.5901%\n",
      "Epoch [25/300], Step [66/225], Training Accuracy: 76.5625%, Training Loss: 0.5899%\n",
      "Epoch [25/300], Step [67/225], Training Accuracy: 76.5858%, Training Loss: 0.5907%\n",
      "Epoch [25/300], Step [68/225], Training Accuracy: 76.5625%, Training Loss: 0.5909%\n",
      "Epoch [25/300], Step [69/225], Training Accuracy: 76.5399%, Training Loss: 0.5910%\n",
      "Epoch [25/300], Step [70/225], Training Accuracy: 76.6071%, Training Loss: 0.5897%\n",
      "Epoch [25/300], Step [71/225], Training Accuracy: 76.6065%, Training Loss: 0.5898%\n",
      "Epoch [25/300], Step [72/225], Training Accuracy: 76.5625%, Training Loss: 0.5906%\n",
      "Epoch [25/300], Step [73/225], Training Accuracy: 76.5411%, Training Loss: 0.5916%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/300], Step [74/225], Training Accuracy: 76.4992%, Training Loss: 0.5912%\n",
      "Epoch [25/300], Step [75/225], Training Accuracy: 76.5625%, Training Loss: 0.5884%\n",
      "Epoch [25/300], Step [76/225], Training Accuracy: 76.4597%, Training Loss: 0.5889%\n",
      "Epoch [25/300], Step [77/225], Training Accuracy: 76.5219%, Training Loss: 0.5880%\n",
      "Epoch [25/300], Step [78/225], Training Accuracy: 76.5224%, Training Loss: 0.5871%\n",
      "Epoch [25/300], Step [79/225], Training Accuracy: 76.4834%, Training Loss: 0.5875%\n",
      "Epoch [25/300], Step [80/225], Training Accuracy: 76.4258%, Training Loss: 0.5887%\n",
      "Epoch [25/300], Step [81/225], Training Accuracy: 76.4275%, Training Loss: 0.5877%\n",
      "Epoch [25/300], Step [82/225], Training Accuracy: 76.4101%, Training Loss: 0.5874%\n",
      "Epoch [25/300], Step [83/225], Training Accuracy: 76.4119%, Training Loss: 0.5869%\n",
      "Epoch [25/300], Step [84/225], Training Accuracy: 76.3207%, Training Loss: 0.5878%\n",
      "Epoch [25/300], Step [85/225], Training Accuracy: 76.2316%, Training Loss: 0.5881%\n",
      "Epoch [25/300], Step [86/225], Training Accuracy: 76.1628%, Training Loss: 0.5882%\n",
      "Epoch [25/300], Step [87/225], Training Accuracy: 76.1853%, Training Loss: 0.5874%\n",
      "Epoch [25/300], Step [88/225], Training Accuracy: 76.2429%, Training Loss: 0.5860%\n",
      "Epoch [25/300], Step [89/225], Training Accuracy: 76.2640%, Training Loss: 0.5857%\n",
      "Epoch [25/300], Step [90/225], Training Accuracy: 76.2847%, Training Loss: 0.5855%\n",
      "Epoch [25/300], Step [91/225], Training Accuracy: 76.2363%, Training Loss: 0.5862%\n",
      "Epoch [25/300], Step [92/225], Training Accuracy: 76.1889%, Training Loss: 0.5865%\n",
      "Epoch [25/300], Step [93/225], Training Accuracy: 76.1425%, Training Loss: 0.5871%\n",
      "Epoch [25/300], Step [94/225], Training Accuracy: 76.2134%, Training Loss: 0.5857%\n",
      "Epoch [25/300], Step [95/225], Training Accuracy: 76.2336%, Training Loss: 0.5854%\n",
      "Epoch [25/300], Step [96/225], Training Accuracy: 76.3346%, Training Loss: 0.5836%\n",
      "Epoch [25/300], Step [97/225], Training Accuracy: 76.3692%, Training Loss: 0.5827%\n",
      "Epoch [25/300], Step [98/225], Training Accuracy: 76.3552%, Training Loss: 0.5832%\n",
      "Epoch [25/300], Step [99/225], Training Accuracy: 76.3258%, Training Loss: 0.5840%\n",
      "Epoch [25/300], Step [100/225], Training Accuracy: 76.2812%, Training Loss: 0.5850%\n",
      "Epoch [25/300], Step [101/225], Training Accuracy: 76.2686%, Training Loss: 0.5853%\n",
      "Epoch [25/300], Step [102/225], Training Accuracy: 76.1489%, Training Loss: 0.5875%\n",
      "Epoch [25/300], Step [103/225], Training Accuracy: 76.0771%, Training Loss: 0.5894%\n",
      "Epoch [25/300], Step [104/225], Training Accuracy: 76.0216%, Training Loss: 0.5893%\n",
      "Epoch [25/300], Step [105/225], Training Accuracy: 76.0268%, Training Loss: 0.5897%\n",
      "Epoch [25/300], Step [106/225], Training Accuracy: 75.9729%, Training Loss: 0.5911%\n",
      "Epoch [25/300], Step [107/225], Training Accuracy: 75.9638%, Training Loss: 0.5912%\n",
      "Epoch [25/300], Step [108/225], Training Accuracy: 75.9115%, Training Loss: 0.5920%\n",
      "Epoch [25/300], Step [109/225], Training Accuracy: 75.9318%, Training Loss: 0.5918%\n",
      "Epoch [25/300], Step [110/225], Training Accuracy: 76.0085%, Training Loss: 0.5907%\n",
      "Epoch [25/300], Step [111/225], Training Accuracy: 76.0698%, Training Loss: 0.5899%\n",
      "Epoch [25/300], Step [112/225], Training Accuracy: 76.0603%, Training Loss: 0.5896%\n",
      "Epoch [25/300], Step [113/225], Training Accuracy: 76.0509%, Training Loss: 0.5894%\n",
      "Epoch [25/300], Step [114/225], Training Accuracy: 76.0005%, Training Loss: 0.5891%\n",
      "Epoch [25/300], Step [115/225], Training Accuracy: 76.0190%, Training Loss: 0.5892%\n",
      "Epoch [25/300], Step [116/225], Training Accuracy: 75.9564%, Training Loss: 0.5907%\n",
      "Epoch [25/300], Step [117/225], Training Accuracy: 75.9749%, Training Loss: 0.5905%\n",
      "Epoch [25/300], Step [118/225], Training Accuracy: 75.9269%, Training Loss: 0.5925%\n",
      "Epoch [25/300], Step [119/225], Training Accuracy: 75.9585%, Training Loss: 0.5929%\n",
      "Epoch [25/300], Step [120/225], Training Accuracy: 75.9635%, Training Loss: 0.5927%\n",
      "Epoch [25/300], Step [121/225], Training Accuracy: 75.9814%, Training Loss: 0.5926%\n",
      "Epoch [25/300], Step [122/225], Training Accuracy: 75.9990%, Training Loss: 0.5925%\n",
      "Epoch [25/300], Step [123/225], Training Accuracy: 75.9782%, Training Loss: 0.5927%\n",
      "Epoch [25/300], Step [124/225], Training Accuracy: 76.0207%, Training Loss: 0.5920%\n",
      "Epoch [25/300], Step [125/225], Training Accuracy: 76.0750%, Training Loss: 0.5911%\n",
      "Epoch [25/300], Step [126/225], Training Accuracy: 76.1037%, Training Loss: 0.5905%\n",
      "Epoch [25/300], Step [127/225], Training Accuracy: 76.1073%, Training Loss: 0.5906%\n",
      "Epoch [25/300], Step [128/225], Training Accuracy: 76.0620%, Training Loss: 0.5908%\n",
      "Epoch [25/300], Step [129/225], Training Accuracy: 76.0538%, Training Loss: 0.5910%\n",
      "Epoch [25/300], Step [130/225], Training Accuracy: 76.0457%, Training Loss: 0.5912%\n",
      "Epoch [25/300], Step [131/225], Training Accuracy: 76.0496%, Training Loss: 0.5910%\n",
      "Epoch [25/300], Step [132/225], Training Accuracy: 76.0890%, Training Loss: 0.5908%\n",
      "Epoch [25/300], Step [133/225], Training Accuracy: 76.1396%, Training Loss: 0.5899%\n",
      "Epoch [25/300], Step [134/225], Training Accuracy: 76.1194%, Training Loss: 0.5901%\n",
      "Epoch [25/300], Step [135/225], Training Accuracy: 76.1458%, Training Loss: 0.5895%\n",
      "Epoch [25/300], Step [136/225], Training Accuracy: 76.1374%, Training Loss: 0.5892%\n",
      "Epoch [25/300], Step [137/225], Training Accuracy: 76.1747%, Training Loss: 0.5888%\n",
      "Epoch [25/300], Step [138/225], Training Accuracy: 76.2115%, Training Loss: 0.5884%\n",
      "Epoch [25/300], Step [139/225], Training Accuracy: 76.1691%, Training Loss: 0.5889%\n",
      "Epoch [25/300], Step [140/225], Training Accuracy: 76.1607%, Training Loss: 0.5893%\n",
      "Epoch [25/300], Step [141/225], Training Accuracy: 76.1857%, Training Loss: 0.5893%\n",
      "Epoch [25/300], Step [142/225], Training Accuracy: 76.1884%, Training Loss: 0.5891%\n",
      "Epoch [25/300], Step [143/225], Training Accuracy: 76.1582%, Training Loss: 0.5898%\n",
      "Epoch [25/300], Step [144/225], Training Accuracy: 76.1827%, Training Loss: 0.5891%\n",
      "Epoch [25/300], Step [145/225], Training Accuracy: 76.2069%, Training Loss: 0.5889%\n",
      "Epoch [25/300], Step [146/225], Training Accuracy: 76.2093%, Training Loss: 0.5887%\n",
      "Epoch [25/300], Step [147/225], Training Accuracy: 76.1905%, Training Loss: 0.5893%\n",
      "Epoch [25/300], Step [148/225], Training Accuracy: 76.1930%, Training Loss: 0.5890%\n",
      "Epoch [25/300], Step [149/225], Training Accuracy: 76.2164%, Training Loss: 0.5889%\n",
      "Epoch [25/300], Step [150/225], Training Accuracy: 76.2917%, Training Loss: 0.5874%\n",
      "Epoch [25/300], Step [151/225], Training Accuracy: 76.3038%, Training Loss: 0.5872%\n",
      "Epoch [25/300], Step [152/225], Training Accuracy: 76.3466%, Training Loss: 0.5864%\n",
      "Epoch [25/300], Step [153/225], Training Accuracy: 76.3787%, Training Loss: 0.5858%\n",
      "Epoch [25/300], Step [154/225], Training Accuracy: 76.3697%, Training Loss: 0.5865%\n",
      "Epoch [25/300], Step [155/225], Training Accuracy: 76.3911%, Training Loss: 0.5862%\n",
      "Epoch [25/300], Step [156/225], Training Accuracy: 76.4022%, Training Loss: 0.5859%\n",
      "Epoch [25/300], Step [157/225], Training Accuracy: 76.4232%, Training Loss: 0.5858%\n",
      "Epoch [25/300], Step [158/225], Training Accuracy: 76.4339%, Training Loss: 0.5850%\n",
      "Epoch [25/300], Step [159/225], Training Accuracy: 76.4347%, Training Loss: 0.5847%\n",
      "Epoch [25/300], Step [160/225], Training Accuracy: 76.4355%, Training Loss: 0.5848%\n",
      "Epoch [25/300], Step [161/225], Training Accuracy: 76.4557%, Training Loss: 0.5843%\n",
      "Epoch [25/300], Step [162/225], Training Accuracy: 76.4564%, Training Loss: 0.5839%\n",
      "Epoch [25/300], Step [163/225], Training Accuracy: 76.4858%, Training Loss: 0.5835%\n",
      "Epoch [25/300], Step [164/225], Training Accuracy: 76.5053%, Training Loss: 0.5826%\n",
      "Epoch [25/300], Step [165/225], Training Accuracy: 76.5341%, Training Loss: 0.5822%\n",
      "Epoch [25/300], Step [166/225], Training Accuracy: 76.5060%, Training Loss: 0.5824%\n",
      "Epoch [25/300], Step [167/225], Training Accuracy: 76.4876%, Training Loss: 0.5831%\n",
      "Epoch [25/300], Step [168/225], Training Accuracy: 76.4788%, Training Loss: 0.5825%\n",
      "Epoch [25/300], Step [169/225], Training Accuracy: 76.4238%, Training Loss: 0.5833%\n",
      "Epoch [25/300], Step [170/225], Training Accuracy: 76.3971%, Training Loss: 0.5835%\n",
      "Epoch [25/300], Step [171/225], Training Accuracy: 76.4072%, Training Loss: 0.5831%\n",
      "Epoch [25/300], Step [172/225], Training Accuracy: 76.4172%, Training Loss: 0.5826%\n",
      "Epoch [25/300], Step [173/225], Training Accuracy: 76.3909%, Training Loss: 0.5827%\n",
      "Epoch [25/300], Step [174/225], Training Accuracy: 76.3290%, Training Loss: 0.5830%\n",
      "Epoch [25/300], Step [175/225], Training Accuracy: 76.3393%, Training Loss: 0.5825%\n",
      "Epoch [25/300], Step [176/225], Training Accuracy: 76.3406%, Training Loss: 0.5834%\n",
      "Epoch [25/300], Step [177/225], Training Accuracy: 76.3683%, Training Loss: 0.5834%\n",
      "Epoch [25/300], Step [178/225], Training Accuracy: 76.3694%, Training Loss: 0.5838%\n",
      "Epoch [25/300], Step [179/225], Training Accuracy: 76.3879%, Training Loss: 0.5831%\n",
      "Epoch [25/300], Step [180/225], Training Accuracy: 76.3802%, Training Loss: 0.5832%\n",
      "Epoch [25/300], Step [181/225], Training Accuracy: 76.3294%, Training Loss: 0.5838%\n",
      "Epoch [25/300], Step [182/225], Training Accuracy: 76.3393%, Training Loss: 0.5836%\n",
      "Epoch [25/300], Step [183/225], Training Accuracy: 76.3490%, Training Loss: 0.5827%\n",
      "Epoch [25/300], Step [184/225], Training Accuracy: 76.3672%, Training Loss: 0.5828%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/300], Step [185/225], Training Accuracy: 76.3682%, Training Loss: 0.5823%\n",
      "Epoch [25/300], Step [186/225], Training Accuracy: 76.3861%, Training Loss: 0.5825%\n",
      "Epoch [25/300], Step [187/225], Training Accuracy: 76.3703%, Training Loss: 0.5825%\n",
      "Epoch [25/300], Step [188/225], Training Accuracy: 76.3797%, Training Loss: 0.5825%\n",
      "Epoch [25/300], Step [189/225], Training Accuracy: 76.4137%, Training Loss: 0.5819%\n",
      "Epoch [25/300], Step [190/225], Training Accuracy: 76.4309%, Training Loss: 0.5816%\n",
      "Epoch [25/300], Step [191/225], Training Accuracy: 76.4971%, Training Loss: 0.5806%\n",
      "Epoch [25/300], Step [192/225], Training Accuracy: 76.4974%, Training Loss: 0.5806%\n",
      "Epoch [25/300], Step [193/225], Training Accuracy: 76.4734%, Training Loss: 0.5811%\n",
      "Epoch [25/300], Step [194/225], Training Accuracy: 76.5303%, Training Loss: 0.5797%\n",
      "Epoch [25/300], Step [195/225], Training Accuracy: 76.5385%, Training Loss: 0.5798%\n",
      "Epoch [25/300], Step [196/225], Training Accuracy: 76.5466%, Training Loss: 0.5797%\n",
      "Epoch [25/300], Step [197/225], Training Accuracy: 76.4990%, Training Loss: 0.5807%\n",
      "Epoch [25/300], Step [198/225], Training Accuracy: 76.4915%, Training Loss: 0.5808%\n",
      "Epoch [25/300], Step [199/225], Training Accuracy: 76.4840%, Training Loss: 0.5813%\n",
      "Epoch [25/300], Step [200/225], Training Accuracy: 76.4922%, Training Loss: 0.5813%\n",
      "Epoch [25/300], Step [201/225], Training Accuracy: 76.5081%, Training Loss: 0.5809%\n",
      "Epoch [25/300], Step [202/225], Training Accuracy: 76.5006%, Training Loss: 0.5816%\n",
      "Epoch [25/300], Step [203/225], Training Accuracy: 76.5009%, Training Loss: 0.5814%\n",
      "Epoch [25/300], Step [204/225], Training Accuracy: 76.4706%, Training Loss: 0.5817%\n",
      "Epoch [25/300], Step [205/225], Training Accuracy: 76.5168%, Training Loss: 0.5814%\n",
      "Epoch [25/300], Step [206/225], Training Accuracy: 76.5018%, Training Loss: 0.5819%\n",
      "Epoch [25/300], Step [207/225], Training Accuracy: 76.5550%, Training Loss: 0.5810%\n",
      "Epoch [25/300], Step [208/225], Training Accuracy: 76.5550%, Training Loss: 0.5809%\n",
      "Epoch [25/300], Step [209/225], Training Accuracy: 76.5326%, Training Loss: 0.5812%\n",
      "Epoch [25/300], Step [210/225], Training Accuracy: 76.5551%, Training Loss: 0.5810%\n",
      "Epoch [25/300], Step [211/225], Training Accuracy: 76.5551%, Training Loss: 0.5808%\n",
      "Epoch [25/300], Step [212/225], Training Accuracy: 76.5625%, Training Loss: 0.5809%\n",
      "Epoch [25/300], Step [213/225], Training Accuracy: 76.5918%, Training Loss: 0.5806%\n",
      "Epoch [25/300], Step [214/225], Training Accuracy: 76.5990%, Training Loss: 0.5806%\n",
      "Epoch [25/300], Step [215/225], Training Accuracy: 76.6134%, Training Loss: 0.5801%\n",
      "Epoch [25/300], Step [216/225], Training Accuracy: 76.5842%, Training Loss: 0.5810%\n",
      "Epoch [25/300], Step [217/225], Training Accuracy: 76.6201%, Training Loss: 0.5806%\n",
      "Epoch [25/300], Step [218/225], Training Accuracy: 76.6127%, Training Loss: 0.5812%\n",
      "Epoch [25/300], Step [219/225], Training Accuracy: 76.6124%, Training Loss: 0.5811%\n",
      "Epoch [25/300], Step [220/225], Training Accuracy: 76.6477%, Training Loss: 0.5808%\n",
      "Epoch [25/300], Step [221/225], Training Accuracy: 76.6120%, Training Loss: 0.5814%\n",
      "Epoch [25/300], Step [222/225], Training Accuracy: 76.5907%, Training Loss: 0.5818%\n",
      "Epoch [25/300], Step [223/225], Training Accuracy: 76.6186%, Training Loss: 0.5816%\n",
      "Epoch [25/300], Step [224/225], Training Accuracy: 76.6462%, Training Loss: 0.5811%\n",
      "Epoch [25/300], Step [225/225], Training Accuracy: 76.6329%, Training Loss: 0.5811%\n",
      "Epoch [26/300], Step [1/225], Training Accuracy: 78.1250%, Training Loss: 0.6212%\n",
      "Epoch [26/300], Step [2/225], Training Accuracy: 80.4688%, Training Loss: 0.5492%\n",
      "Epoch [26/300], Step [3/225], Training Accuracy: 79.1667%, Training Loss: 0.5987%\n",
      "Epoch [26/300], Step [4/225], Training Accuracy: 79.6875%, Training Loss: 0.5807%\n",
      "Epoch [26/300], Step [5/225], Training Accuracy: 80.0000%, Training Loss: 0.5588%\n",
      "Epoch [26/300], Step [6/225], Training Accuracy: 79.4271%, Training Loss: 0.5625%\n",
      "Epoch [26/300], Step [7/225], Training Accuracy: 78.1250%, Training Loss: 0.5792%\n",
      "Epoch [26/300], Step [8/225], Training Accuracy: 79.1016%, Training Loss: 0.5559%\n",
      "Epoch [26/300], Step [9/225], Training Accuracy: 78.4722%, Training Loss: 0.5633%\n",
      "Epoch [26/300], Step [10/225], Training Accuracy: 77.8125%, Training Loss: 0.5755%\n",
      "Epoch [26/300], Step [11/225], Training Accuracy: 78.2670%, Training Loss: 0.5675%\n",
      "Epoch [26/300], Step [12/225], Training Accuracy: 78.7760%, Training Loss: 0.5647%\n",
      "Epoch [26/300], Step [13/225], Training Accuracy: 79.0865%, Training Loss: 0.5584%\n",
      "Epoch [26/300], Step [14/225], Training Accuracy: 78.4598%, Training Loss: 0.5628%\n",
      "Epoch [26/300], Step [15/225], Training Accuracy: 78.6458%, Training Loss: 0.5593%\n",
      "Epoch [26/300], Step [16/225], Training Accuracy: 78.0273%, Training Loss: 0.5731%\n",
      "Epoch [26/300], Step [17/225], Training Accuracy: 78.0331%, Training Loss: 0.5817%\n",
      "Epoch [26/300], Step [18/225], Training Accuracy: 77.9514%, Training Loss: 0.5837%\n",
      "Epoch [26/300], Step [19/225], Training Accuracy: 77.9605%, Training Loss: 0.5783%\n",
      "Epoch [26/300], Step [20/225], Training Accuracy: 78.2812%, Training Loss: 0.5704%\n",
      "Epoch [26/300], Step [21/225], Training Accuracy: 78.0506%, Training Loss: 0.5688%\n",
      "Epoch [26/300], Step [22/225], Training Accuracy: 77.6278%, Training Loss: 0.5768%\n",
      "Epoch [26/300], Step [23/225], Training Accuracy: 77.5136%, Training Loss: 0.5771%\n",
      "Epoch [26/300], Step [24/225], Training Accuracy: 77.4089%, Training Loss: 0.5822%\n",
      "Epoch [26/300], Step [25/225], Training Accuracy: 77.5000%, Training Loss: 0.5768%\n",
      "Epoch [26/300], Step [26/225], Training Accuracy: 77.1635%, Training Loss: 0.5811%\n",
      "Epoch [26/300], Step [27/225], Training Accuracy: 77.1991%, Training Loss: 0.5804%\n",
      "Epoch [26/300], Step [28/225], Training Accuracy: 77.2321%, Training Loss: 0.5790%\n",
      "Epoch [26/300], Step [29/225], Training Accuracy: 77.2629%, Training Loss: 0.5773%\n",
      "Epoch [26/300], Step [30/225], Training Accuracy: 77.5521%, Training Loss: 0.5767%\n",
      "Epoch [26/300], Step [31/225], Training Accuracy: 77.3185%, Training Loss: 0.5789%\n",
      "Epoch [26/300], Step [32/225], Training Accuracy: 77.4414%, Training Loss: 0.5784%\n",
      "Epoch [26/300], Step [33/225], Training Accuracy: 77.4621%, Training Loss: 0.5772%\n",
      "Epoch [26/300], Step [34/225], Training Accuracy: 77.6195%, Training Loss: 0.5750%\n",
      "Epoch [26/300], Step [35/225], Training Accuracy: 77.4554%, Training Loss: 0.5769%\n",
      "Epoch [26/300], Step [36/225], Training Accuracy: 77.3003%, Training Loss: 0.5792%\n",
      "Epoch [26/300], Step [37/225], Training Accuracy: 77.3226%, Training Loss: 0.5804%\n",
      "Epoch [26/300], Step [38/225], Training Accuracy: 77.6316%, Training Loss: 0.5760%\n",
      "Epoch [26/300], Step [39/225], Training Accuracy: 77.6042%, Training Loss: 0.5742%\n",
      "Epoch [26/300], Step [40/225], Training Accuracy: 77.5781%, Training Loss: 0.5730%\n",
      "Epoch [26/300], Step [41/225], Training Accuracy: 77.6677%, Training Loss: 0.5701%\n",
      "Epoch [26/300], Step [42/225], Training Accuracy: 77.7158%, Training Loss: 0.5700%\n",
      "Epoch [26/300], Step [43/225], Training Accuracy: 77.6163%, Training Loss: 0.5710%\n",
      "Epoch [26/300], Step [44/225], Training Accuracy: 77.6989%, Training Loss: 0.5715%\n",
      "Epoch [26/300], Step [45/225], Training Accuracy: 77.8819%, Training Loss: 0.5695%\n",
      "Epoch [26/300], Step [46/225], Training Accuracy: 78.0231%, Training Loss: 0.5687%\n",
      "Epoch [26/300], Step [47/225], Training Accuracy: 78.0585%, Training Loss: 0.5681%\n",
      "Epoch [26/300], Step [48/225], Training Accuracy: 78.0273%, Training Loss: 0.5684%\n",
      "Epoch [26/300], Step [49/225], Training Accuracy: 77.8380%, Training Loss: 0.5691%\n",
      "Epoch [26/300], Step [50/225], Training Accuracy: 77.7812%, Training Loss: 0.5703%\n",
      "Epoch [26/300], Step [51/225], Training Accuracy: 77.9412%, Training Loss: 0.5677%\n",
      "Epoch [26/300], Step [52/225], Training Accuracy: 78.0950%, Training Loss: 0.5642%\n",
      "Epoch [26/300], Step [53/225], Training Accuracy: 78.1545%, Training Loss: 0.5635%\n",
      "Epoch [26/300], Step [54/225], Training Accuracy: 77.9514%, Training Loss: 0.5682%\n",
      "Epoch [26/300], Step [55/225], Training Accuracy: 78.0966%, Training Loss: 0.5677%\n",
      "Epoch [26/300], Step [56/225], Training Accuracy: 78.0692%, Training Loss: 0.5678%\n",
      "Epoch [26/300], Step [57/225], Training Accuracy: 78.0154%, Training Loss: 0.5687%\n",
      "Epoch [26/300], Step [58/225], Training Accuracy: 77.9634%, Training Loss: 0.5701%\n",
      "Epoch [26/300], Step [59/225], Training Accuracy: 77.9131%, Training Loss: 0.5716%\n",
      "Epoch [26/300], Step [60/225], Training Accuracy: 77.9427%, Training Loss: 0.5707%\n",
      "Epoch [26/300], Step [61/225], Training Accuracy: 77.8432%, Training Loss: 0.5713%\n",
      "Epoch [26/300], Step [62/225], Training Accuracy: 77.7974%, Training Loss: 0.5726%\n",
      "Epoch [26/300], Step [63/225], Training Accuracy: 77.6042%, Training Loss: 0.5747%\n",
      "Epoch [26/300], Step [64/225], Training Accuracy: 77.7344%, Training Loss: 0.5732%\n",
      "Epoch [26/300], Step [65/225], Training Accuracy: 77.7885%, Training Loss: 0.5712%\n",
      "Epoch [26/300], Step [66/225], Training Accuracy: 77.8409%, Training Loss: 0.5711%\n",
      "Epoch [26/300], Step [67/225], Training Accuracy: 77.6586%, Training Loss: 0.5718%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/300], Step [68/225], Training Accuracy: 77.6425%, Training Loss: 0.5716%\n",
      "Epoch [26/300], Step [69/225], Training Accuracy: 77.5589%, Training Loss: 0.5724%\n",
      "Epoch [26/300], Step [70/225], Training Accuracy: 77.6116%, Training Loss: 0.5710%\n",
      "Epoch [26/300], Step [71/225], Training Accuracy: 77.5748%, Training Loss: 0.5699%\n",
      "Epoch [26/300], Step [72/225], Training Accuracy: 77.5825%, Training Loss: 0.5698%\n",
      "Epoch [26/300], Step [73/225], Training Accuracy: 77.5043%, Training Loss: 0.5730%\n",
      "Epoch [26/300], Step [74/225], Training Accuracy: 77.4282%, Training Loss: 0.5734%\n",
      "Epoch [26/300], Step [75/225], Training Accuracy: 77.5000%, Training Loss: 0.5724%\n",
      "Epoch [26/300], Step [76/225], Training Accuracy: 77.4054%, Training Loss: 0.5729%\n",
      "Epoch [26/300], Step [77/225], Training Accuracy: 77.4959%, Training Loss: 0.5714%\n",
      "Epoch [26/300], Step [78/225], Training Accuracy: 77.6042%, Training Loss: 0.5699%\n",
      "Epoch [26/300], Step [79/225], Training Accuracy: 77.5514%, Training Loss: 0.5698%\n",
      "Epoch [26/300], Step [80/225], Training Accuracy: 77.4609%, Training Loss: 0.5716%\n",
      "Epoch [26/300], Step [81/225], Training Accuracy: 77.5656%, Training Loss: 0.5699%\n",
      "Epoch [26/300], Step [82/225], Training Accuracy: 77.6677%, Training Loss: 0.5688%\n",
      "Epoch [26/300], Step [83/225], Training Accuracy: 77.7108%, Training Loss: 0.5685%\n",
      "Epoch [26/300], Step [84/225], Training Accuracy: 77.5856%, Training Loss: 0.5697%\n",
      "Epoch [26/300], Step [85/225], Training Accuracy: 77.5551%, Training Loss: 0.5694%\n",
      "Epoch [26/300], Step [86/225], Training Accuracy: 77.5799%, Training Loss: 0.5686%\n",
      "Epoch [26/300], Step [87/225], Training Accuracy: 77.6042%, Training Loss: 0.5683%\n",
      "Epoch [26/300], Step [88/225], Training Accuracy: 77.6101%, Training Loss: 0.5676%\n",
      "Epoch [26/300], Step [89/225], Training Accuracy: 77.6510%, Training Loss: 0.5667%\n",
      "Epoch [26/300], Step [90/225], Training Accuracy: 77.6389%, Training Loss: 0.5661%\n",
      "Epoch [26/300], Step [91/225], Training Accuracy: 77.7473%, Training Loss: 0.5648%\n",
      "Epoch [26/300], Step [92/225], Training Accuracy: 77.7004%, Training Loss: 0.5658%\n",
      "Epoch [26/300], Step [93/225], Training Accuracy: 77.7386%, Training Loss: 0.5653%\n",
      "Epoch [26/300], Step [94/225], Training Accuracy: 77.7593%, Training Loss: 0.5640%\n",
      "Epoch [26/300], Step [95/225], Training Accuracy: 77.6809%, Training Loss: 0.5651%\n",
      "Epoch [26/300], Step [96/225], Training Accuracy: 77.7344%, Training Loss: 0.5629%\n",
      "Epoch [26/300], Step [97/225], Training Accuracy: 77.6901%, Training Loss: 0.5629%\n",
      "Epoch [26/300], Step [98/225], Training Accuracy: 77.7423%, Training Loss: 0.5614%\n",
      "Epoch [26/300], Step [99/225], Training Accuracy: 77.7620%, Training Loss: 0.5614%\n",
      "Epoch [26/300], Step [100/225], Training Accuracy: 77.7344%, Training Loss: 0.5614%\n",
      "Epoch [26/300], Step [101/225], Training Accuracy: 77.7228%, Training Loss: 0.5616%\n",
      "Epoch [26/300], Step [102/225], Training Accuracy: 77.6808%, Training Loss: 0.5622%\n",
      "Epoch [26/300], Step [103/225], Training Accuracy: 77.7002%, Training Loss: 0.5626%\n",
      "Epoch [26/300], Step [104/225], Training Accuracy: 77.5841%, Training Loss: 0.5637%\n",
      "Epoch [26/300], Step [105/225], Training Accuracy: 77.5744%, Training Loss: 0.5637%\n",
      "Epoch [26/300], Step [106/225], Training Accuracy: 77.5354%, Training Loss: 0.5647%\n",
      "Epoch [26/300], Step [107/225], Training Accuracy: 77.5117%, Training Loss: 0.5648%\n",
      "Epoch [26/300], Step [108/225], Training Accuracy: 77.5174%, Training Loss: 0.5652%\n",
      "Epoch [26/300], Step [109/225], Training Accuracy: 77.3939%, Training Loss: 0.5669%\n",
      "Epoch [26/300], Step [110/225], Training Accuracy: 77.4716%, Training Loss: 0.5656%\n",
      "Epoch [26/300], Step [111/225], Training Accuracy: 77.5056%, Training Loss: 0.5647%\n",
      "Epoch [26/300], Step [112/225], Training Accuracy: 77.5391%, Training Loss: 0.5644%\n",
      "Epoch [26/300], Step [113/225], Training Accuracy: 77.5719%, Training Loss: 0.5638%\n",
      "Epoch [26/300], Step [114/225], Training Accuracy: 77.6042%, Training Loss: 0.5638%\n",
      "Epoch [26/300], Step [115/225], Training Accuracy: 77.5951%, Training Loss: 0.5637%\n",
      "Epoch [26/300], Step [116/225], Training Accuracy: 77.5458%, Training Loss: 0.5649%\n",
      "Epoch [26/300], Step [117/225], Training Accuracy: 77.5240%, Training Loss: 0.5648%\n",
      "Epoch [26/300], Step [118/225], Training Accuracy: 77.4497%, Training Loss: 0.5663%\n",
      "Epoch [26/300], Step [119/225], Training Accuracy: 77.4554%, Training Loss: 0.5664%\n",
      "Epoch [26/300], Step [120/225], Training Accuracy: 77.5000%, Training Loss: 0.5657%\n",
      "Epoch [26/300], Step [121/225], Training Accuracy: 77.5439%, Training Loss: 0.5651%\n",
      "Epoch [26/300], Step [122/225], Training Accuracy: 77.6127%, Training Loss: 0.5645%\n",
      "Epoch [26/300], Step [123/225], Training Accuracy: 77.6042%, Training Loss: 0.5645%\n",
      "Epoch [26/300], Step [124/225], Training Accuracy: 77.6588%, Training Loss: 0.5633%\n",
      "Epoch [26/300], Step [125/225], Training Accuracy: 77.6500%, Training Loss: 0.5630%\n",
      "Epoch [26/300], Step [126/225], Training Accuracy: 77.6910%, Training Loss: 0.5623%\n",
      "Epoch [26/300], Step [127/225], Training Accuracy: 77.7067%, Training Loss: 0.5616%\n",
      "Epoch [26/300], Step [128/225], Training Accuracy: 77.6611%, Training Loss: 0.5623%\n",
      "Epoch [26/300], Step [129/225], Training Accuracy: 77.6647%, Training Loss: 0.5616%\n",
      "Epoch [26/300], Step [130/225], Training Accuracy: 77.6322%, Training Loss: 0.5617%\n",
      "Epoch [26/300], Step [131/225], Training Accuracy: 77.6360%, Training Loss: 0.5613%\n",
      "Epoch [26/300], Step [132/225], Training Accuracy: 77.5923%, Training Loss: 0.5618%\n",
      "Epoch [26/300], Step [133/225], Training Accuracy: 77.6081%, Training Loss: 0.5613%\n",
      "Epoch [26/300], Step [134/225], Training Accuracy: 77.5886%, Training Loss: 0.5612%\n",
      "Epoch [26/300], Step [135/225], Training Accuracy: 77.6852%, Training Loss: 0.5595%\n",
      "Epoch [26/300], Step [136/225], Training Accuracy: 77.7114%, Training Loss: 0.5597%\n",
      "Epoch [26/300], Step [137/225], Training Accuracy: 77.7486%, Training Loss: 0.5584%\n",
      "Epoch [26/300], Step [138/225], Training Accuracy: 77.7400%, Training Loss: 0.5589%\n",
      "Epoch [26/300], Step [139/225], Training Accuracy: 77.7653%, Training Loss: 0.5588%\n",
      "Epoch [26/300], Step [140/225], Training Accuracy: 77.7232%, Training Loss: 0.5595%\n",
      "Epoch [26/300], Step [141/225], Training Accuracy: 77.6928%, Training Loss: 0.5597%\n",
      "Epoch [26/300], Step [142/225], Training Accuracy: 77.7179%, Training Loss: 0.5591%\n",
      "Epoch [26/300], Step [143/225], Training Accuracy: 77.6661%, Training Loss: 0.5598%\n",
      "Epoch [26/300], Step [144/225], Training Accuracy: 77.6693%, Training Loss: 0.5588%\n",
      "Epoch [26/300], Step [145/225], Training Accuracy: 77.6832%, Training Loss: 0.5588%\n",
      "Epoch [26/300], Step [146/225], Training Accuracy: 77.6755%, Training Loss: 0.5584%\n",
      "Epoch [26/300], Step [147/225], Training Accuracy: 77.6467%, Training Loss: 0.5598%\n",
      "Epoch [26/300], Step [148/225], Training Accuracy: 77.6394%, Training Loss: 0.5594%\n",
      "Epoch [26/300], Step [149/225], Training Accuracy: 77.6112%, Training Loss: 0.5598%\n",
      "Epoch [26/300], Step [150/225], Training Accuracy: 77.6667%, Training Loss: 0.5585%\n",
      "Epoch [26/300], Step [151/225], Training Accuracy: 77.7318%, Training Loss: 0.5573%\n",
      "Epoch [26/300], Step [152/225], Training Accuracy: 77.7344%, Training Loss: 0.5570%\n",
      "Epoch [26/300], Step [153/225], Training Accuracy: 77.7676%, Training Loss: 0.5566%\n",
      "Epoch [26/300], Step [154/225], Training Accuracy: 77.7597%, Training Loss: 0.5570%\n",
      "Epoch [26/300], Step [155/225], Training Accuracy: 77.8226%, Training Loss: 0.5565%\n",
      "Epoch [26/300], Step [156/225], Training Accuracy: 77.8245%, Training Loss: 0.5566%\n",
      "Epoch [26/300], Step [157/225], Training Accuracy: 77.8563%, Training Loss: 0.5564%\n",
      "Epoch [26/300], Step [158/225], Training Accuracy: 77.8975%, Training Loss: 0.5558%\n",
      "Epoch [26/300], Step [159/225], Training Accuracy: 77.9285%, Training Loss: 0.5551%\n",
      "Epoch [26/300], Step [160/225], Training Accuracy: 77.9199%, Training Loss: 0.5550%\n",
      "Epoch [26/300], Step [161/225], Training Accuracy: 77.9697%, Training Loss: 0.5541%\n",
      "Epoch [26/300], Step [162/225], Training Accuracy: 78.0285%, Training Loss: 0.5528%\n",
      "Epoch [26/300], Step [163/225], Training Accuracy: 78.0196%, Training Loss: 0.5526%\n",
      "Epoch [26/300], Step [164/225], Training Accuracy: 78.0107%, Training Loss: 0.5525%\n",
      "Epoch [26/300], Step [165/225], Training Accuracy: 77.9735%, Training Loss: 0.5533%\n",
      "Epoch [26/300], Step [166/225], Training Accuracy: 77.9462%, Training Loss: 0.5538%\n",
      "Epoch [26/300], Step [167/225], Training Accuracy: 77.9847%, Training Loss: 0.5539%\n",
      "Epoch [26/300], Step [168/225], Training Accuracy: 77.9948%, Training Loss: 0.5535%\n",
      "Epoch [26/300], Step [169/225], Training Accuracy: 77.9401%, Training Loss: 0.5544%\n",
      "Epoch [26/300], Step [170/225], Training Accuracy: 77.9504%, Training Loss: 0.5544%\n",
      "Epoch [26/300], Step [171/225], Training Accuracy: 77.9697%, Training Loss: 0.5538%\n",
      "Epoch [26/300], Step [172/225], Training Accuracy: 77.9978%, Training Loss: 0.5536%\n",
      "Epoch [26/300], Step [173/225], Training Accuracy: 77.9534%, Training Loss: 0.5540%\n",
      "Epoch [26/300], Step [174/225], Training Accuracy: 77.9454%, Training Loss: 0.5544%\n",
      "Epoch [26/300], Step [175/225], Training Accuracy: 77.9643%, Training Loss: 0.5534%\n",
      "Epoch [26/300], Step [176/225], Training Accuracy: 77.9208%, Training Loss: 0.5544%\n",
      "Epoch [26/300], Step [177/225], Training Accuracy: 77.9484%, Training Loss: 0.5544%\n",
      "Epoch [26/300], Step [178/225], Training Accuracy: 77.9231%, Training Loss: 0.5546%\n",
      "Epoch [26/300], Step [179/225], Training Accuracy: 77.9417%, Training Loss: 0.5544%\n",
      "Epoch [26/300], Step [180/225], Training Accuracy: 77.9688%, Training Loss: 0.5543%\n",
      "Epoch [26/300], Step [181/225], Training Accuracy: 77.9178%, Training Loss: 0.5549%\n",
      "Epoch [26/300], Step [182/225], Training Accuracy: 77.9361%, Training Loss: 0.5548%\n",
      "Epoch [26/300], Step [183/225], Training Accuracy: 77.9542%, Training Loss: 0.5542%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/300], Step [184/225], Training Accuracy: 77.9467%, Training Loss: 0.5538%\n",
      "Epoch [26/300], Step [185/225], Training Accuracy: 77.9392%, Training Loss: 0.5543%\n",
      "Epoch [26/300], Step [186/225], Training Accuracy: 77.9906%, Training Loss: 0.5534%\n",
      "Epoch [26/300], Step [187/225], Training Accuracy: 77.9662%, Training Loss: 0.5533%\n",
      "Epoch [26/300], Step [188/225], Training Accuracy: 77.9837%, Training Loss: 0.5532%\n",
      "Epoch [26/300], Step [189/225], Training Accuracy: 78.0258%, Training Loss: 0.5523%\n",
      "Epoch [26/300], Step [190/225], Training Accuracy: 78.0181%, Training Loss: 0.5525%\n",
      "Epoch [26/300], Step [191/225], Training Accuracy: 78.0432%, Training Loss: 0.5520%\n",
      "Epoch [26/300], Step [192/225], Training Accuracy: 78.0436%, Training Loss: 0.5521%\n",
      "Epoch [26/300], Step [193/225], Training Accuracy: 78.0521%, Training Loss: 0.5518%\n",
      "Epoch [26/300], Step [194/225], Training Accuracy: 78.1089%, Training Loss: 0.5505%\n",
      "Epoch [26/300], Step [195/225], Training Accuracy: 78.1090%, Training Loss: 0.5507%\n",
      "Epoch [26/300], Step [196/225], Training Accuracy: 78.1489%, Training Loss: 0.5504%\n",
      "Epoch [26/300], Step [197/225], Training Accuracy: 78.1488%, Training Loss: 0.5507%\n",
      "Epoch [26/300], Step [198/225], Training Accuracy: 78.1487%, Training Loss: 0.5508%\n",
      "Epoch [26/300], Step [199/225], Training Accuracy: 78.0857%, Training Loss: 0.5522%\n",
      "Epoch [26/300], Step [200/225], Training Accuracy: 78.0938%, Training Loss: 0.5520%\n",
      "Epoch [26/300], Step [201/225], Training Accuracy: 78.1172%, Training Loss: 0.5516%\n",
      "Epoch [26/300], Step [202/225], Training Accuracy: 78.1173%, Training Loss: 0.5519%\n",
      "Epoch [26/300], Step [203/225], Training Accuracy: 78.0942%, Training Loss: 0.5524%\n",
      "Epoch [26/300], Step [204/225], Training Accuracy: 78.0867%, Training Loss: 0.5526%\n",
      "Epoch [26/300], Step [205/225], Training Accuracy: 78.1174%, Training Loss: 0.5524%\n",
      "Epoch [26/300], Step [206/225], Training Accuracy: 78.0871%, Training Loss: 0.5529%\n",
      "Epoch [26/300], Step [207/225], Training Accuracy: 78.1175%, Training Loss: 0.5527%\n",
      "Epoch [26/300], Step [208/225], Training Accuracy: 78.1175%, Training Loss: 0.5521%\n",
      "Epoch [26/300], Step [209/225], Training Accuracy: 78.1175%, Training Loss: 0.5526%\n",
      "Epoch [26/300], Step [210/225], Training Accuracy: 78.1176%, Training Loss: 0.5524%\n",
      "Epoch [26/300], Step [211/225], Training Accuracy: 78.0954%, Training Loss: 0.5521%\n",
      "Epoch [26/300], Step [212/225], Training Accuracy: 78.0808%, Training Loss: 0.5528%\n",
      "Epoch [26/300], Step [213/225], Training Accuracy: 78.0737%, Training Loss: 0.5531%\n",
      "Epoch [26/300], Step [214/225], Training Accuracy: 78.0520%, Training Loss: 0.5532%\n",
      "Epoch [26/300], Step [215/225], Training Accuracy: 78.0887%, Training Loss: 0.5525%\n",
      "Epoch [26/300], Step [216/225], Training Accuracy: 78.0671%, Training Loss: 0.5531%\n",
      "Epoch [26/300], Step [217/225], Training Accuracy: 78.1106%, Training Loss: 0.5528%\n",
      "Epoch [26/300], Step [218/225], Training Accuracy: 78.1035%, Training Loss: 0.5530%\n",
      "Epoch [26/300], Step [219/225], Training Accuracy: 78.1321%, Training Loss: 0.5528%\n",
      "Epoch [26/300], Step [220/225], Training Accuracy: 78.1889%, Training Loss: 0.5522%\n",
      "Epoch [26/300], Step [221/225], Training Accuracy: 78.1533%, Training Loss: 0.5527%\n",
      "Epoch [26/300], Step [222/225], Training Accuracy: 78.1391%, Training Loss: 0.5530%\n",
      "Epoch [26/300], Step [223/225], Training Accuracy: 78.1670%, Training Loss: 0.5527%\n",
      "Epoch [26/300], Step [224/225], Training Accuracy: 78.1738%, Training Loss: 0.5523%\n",
      "Epoch [26/300], Step [225/225], Training Accuracy: 78.1545%, Training Loss: 0.5523%\n",
      "Epoch [27/300], Step [1/225], Training Accuracy: 82.8125%, Training Loss: 0.5309%\n",
      "Epoch [27/300], Step [2/225], Training Accuracy: 78.1250%, Training Loss: 0.5316%\n",
      "Epoch [27/300], Step [3/225], Training Accuracy: 75.5208%, Training Loss: 0.6021%\n",
      "Epoch [27/300], Step [4/225], Training Accuracy: 77.3438%, Training Loss: 0.5509%\n",
      "Epoch [27/300], Step [5/225], Training Accuracy: 77.1875%, Training Loss: 0.5517%\n",
      "Epoch [27/300], Step [6/225], Training Accuracy: 75.7812%, Training Loss: 0.5573%\n",
      "Epoch [27/300], Step [7/225], Training Accuracy: 76.1161%, Training Loss: 0.5642%\n",
      "Epoch [27/300], Step [8/225], Training Accuracy: 77.1484%, Training Loss: 0.5509%\n",
      "Epoch [27/300], Step [9/225], Training Accuracy: 77.4306%, Training Loss: 0.5437%\n",
      "Epoch [27/300], Step [10/225], Training Accuracy: 77.0312%, Training Loss: 0.5584%\n",
      "Epoch [27/300], Step [11/225], Training Accuracy: 76.7045%, Training Loss: 0.5598%\n",
      "Epoch [27/300], Step [12/225], Training Accuracy: 76.9531%, Training Loss: 0.5599%\n",
      "Epoch [27/300], Step [13/225], Training Accuracy: 76.8029%, Training Loss: 0.5646%\n",
      "Epoch [27/300], Step [14/225], Training Accuracy: 76.6741%, Training Loss: 0.5643%\n",
      "Epoch [27/300], Step [15/225], Training Accuracy: 76.9792%, Training Loss: 0.5535%\n",
      "Epoch [27/300], Step [16/225], Training Accuracy: 76.1719%, Training Loss: 0.5656%\n",
      "Epoch [27/300], Step [17/225], Training Accuracy: 76.1949%, Training Loss: 0.5726%\n",
      "Epoch [27/300], Step [18/225], Training Accuracy: 76.0417%, Training Loss: 0.5720%\n",
      "Epoch [27/300], Step [19/225], Training Accuracy: 76.5625%, Training Loss: 0.5651%\n",
      "Epoch [27/300], Step [20/225], Training Accuracy: 76.7969%, Training Loss: 0.5588%\n",
      "Epoch [27/300], Step [21/225], Training Accuracy: 76.9345%, Training Loss: 0.5553%\n",
      "Epoch [27/300], Step [22/225], Training Accuracy: 77.1307%, Training Loss: 0.5629%\n",
      "Epoch [27/300], Step [23/225], Training Accuracy: 76.9022%, Training Loss: 0.5686%\n",
      "Epoch [27/300], Step [24/225], Training Accuracy: 76.2370%, Training Loss: 0.5772%\n",
      "Epoch [27/300], Step [25/225], Training Accuracy: 76.1875%, Training Loss: 0.5731%\n",
      "Epoch [27/300], Step [26/225], Training Accuracy: 75.9615%, Training Loss: 0.5789%\n",
      "Epoch [27/300], Step [27/225], Training Accuracy: 75.6944%, Training Loss: 0.5814%\n",
      "Epoch [27/300], Step [28/225], Training Accuracy: 76.0045%, Training Loss: 0.5758%\n",
      "Epoch [27/300], Step [29/225], Training Accuracy: 76.2392%, Training Loss: 0.5694%\n",
      "Epoch [27/300], Step [30/225], Training Accuracy: 76.4583%, Training Loss: 0.5663%\n",
      "Epoch [27/300], Step [31/225], Training Accuracy: 76.4113%, Training Loss: 0.5693%\n",
      "Epoch [27/300], Step [32/225], Training Accuracy: 76.3672%, Training Loss: 0.5682%\n",
      "Epoch [27/300], Step [33/225], Training Accuracy: 76.2784%, Training Loss: 0.5677%\n",
      "Epoch [27/300], Step [34/225], Training Accuracy: 76.5165%, Training Loss: 0.5643%\n",
      "Epoch [27/300], Step [35/225], Training Accuracy: 76.2500%, Training Loss: 0.5676%\n",
      "Epoch [27/300], Step [36/225], Training Accuracy: 76.1719%, Training Loss: 0.5681%\n",
      "Epoch [27/300], Step [37/225], Training Accuracy: 76.0980%, Training Loss: 0.5724%\n",
      "Epoch [27/300], Step [38/225], Training Accuracy: 76.1924%, Training Loss: 0.5712%\n",
      "Epoch [27/300], Step [39/225], Training Accuracy: 76.2019%, Training Loss: 0.5686%\n",
      "Epoch [27/300], Step [40/225], Training Accuracy: 76.4062%, Training Loss: 0.5665%\n",
      "Epoch [27/300], Step [41/225], Training Accuracy: 76.4482%, Training Loss: 0.5638%\n",
      "Epoch [27/300], Step [42/225], Training Accuracy: 76.3393%, Training Loss: 0.5659%\n",
      "Epoch [27/300], Step [43/225], Training Accuracy: 76.4535%, Training Loss: 0.5647%\n",
      "Epoch [27/300], Step [44/225], Training Accuracy: 76.3849%, Training Loss: 0.5661%\n",
      "Epoch [27/300], Step [45/225], Training Accuracy: 76.5278%, Training Loss: 0.5661%\n",
      "Epoch [27/300], Step [46/225], Training Accuracy: 76.7323%, Training Loss: 0.5638%\n",
      "Epoch [27/300], Step [47/225], Training Accuracy: 76.8285%, Training Loss: 0.5617%\n",
      "Epoch [27/300], Step [48/225], Training Accuracy: 76.8229%, Training Loss: 0.5623%\n",
      "Epoch [27/300], Step [49/225], Training Accuracy: 76.7219%, Training Loss: 0.5626%\n",
      "Epoch [27/300], Step [50/225], Training Accuracy: 76.6250%, Training Loss: 0.5649%\n",
      "Epoch [27/300], Step [51/225], Training Accuracy: 76.5625%, Training Loss: 0.5635%\n",
      "Epoch [27/300], Step [52/225], Training Accuracy: 76.8630%, Training Loss: 0.5584%\n",
      "Epoch [27/300], Step [53/225], Training Accuracy: 76.8278%, Training Loss: 0.5602%\n",
      "Epoch [27/300], Step [54/225], Training Accuracy: 76.5625%, Training Loss: 0.5641%\n",
      "Epoch [27/300], Step [55/225], Training Accuracy: 76.6477%, Training Loss: 0.5615%\n",
      "Epoch [27/300], Step [56/225], Training Accuracy: 76.7020%, Training Loss: 0.5600%\n",
      "Epoch [27/300], Step [57/225], Training Accuracy: 76.6447%, Training Loss: 0.5608%\n",
      "Epoch [27/300], Step [58/225], Training Accuracy: 76.6164%, Training Loss: 0.5612%\n",
      "Epoch [27/300], Step [59/225], Training Accuracy: 76.5890%, Training Loss: 0.5607%\n",
      "Epoch [27/300], Step [60/225], Training Accuracy: 76.6406%, Training Loss: 0.5609%\n",
      "Epoch [27/300], Step [61/225], Training Accuracy: 76.3832%, Training Loss: 0.5632%\n",
      "Epoch [27/300], Step [62/225], Training Accuracy: 76.3861%, Training Loss: 0.5624%\n",
      "Epoch [27/300], Step [63/225], Training Accuracy: 76.3641%, Training Loss: 0.5628%\n",
      "Epoch [27/300], Step [64/225], Training Accuracy: 76.3428%, Training Loss: 0.5636%\n",
      "Epoch [27/300], Step [65/225], Training Accuracy: 76.4423%, Training Loss: 0.5616%\n",
      "Epoch [27/300], Step [66/225], Training Accuracy: 76.4441%, Training Loss: 0.5615%\n",
      "Epoch [27/300], Step [67/225], Training Accuracy: 76.3993%, Training Loss: 0.5618%\n",
      "Epoch [27/300], Step [68/225], Training Accuracy: 76.3787%, Training Loss: 0.5620%\n",
      "Epoch [27/300], Step [69/225], Training Accuracy: 76.3134%, Training Loss: 0.5630%\n",
      "Epoch [27/300], Step [70/225], Training Accuracy: 76.4062%, Training Loss: 0.5623%\n",
      "Epoch [27/300], Step [71/225], Training Accuracy: 76.4305%, Training Loss: 0.5611%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/300], Step [72/225], Training Accuracy: 76.4757%, Training Loss: 0.5597%\n",
      "Epoch [27/300], Step [73/225], Training Accuracy: 76.4127%, Training Loss: 0.5604%\n",
      "Epoch [27/300], Step [74/225], Training Accuracy: 76.4358%, Training Loss: 0.5607%\n",
      "Epoch [27/300], Step [75/225], Training Accuracy: 76.5833%, Training Loss: 0.5590%\n",
      "Epoch [27/300], Step [76/225], Training Accuracy: 76.6859%, Training Loss: 0.5579%\n",
      "Epoch [27/300], Step [77/225], Training Accuracy: 76.7248%, Training Loss: 0.5568%\n",
      "Epoch [27/300], Step [78/225], Training Accuracy: 76.7428%, Training Loss: 0.5570%\n",
      "Epoch [27/300], Step [79/225], Training Accuracy: 76.7603%, Training Loss: 0.5561%\n",
      "Epoch [27/300], Step [80/225], Training Accuracy: 76.7383%, Training Loss: 0.5568%\n",
      "Epoch [27/300], Step [81/225], Training Accuracy: 76.8133%, Training Loss: 0.5550%\n",
      "Epoch [27/300], Step [82/225], Training Accuracy: 76.7912%, Training Loss: 0.5556%\n",
      "Epoch [27/300], Step [83/225], Training Accuracy: 76.7696%, Training Loss: 0.5562%\n",
      "Epoch [27/300], Step [84/225], Training Accuracy: 76.8043%, Training Loss: 0.5567%\n",
      "Epoch [27/300], Step [85/225], Training Accuracy: 76.7463%, Training Loss: 0.5569%\n",
      "Epoch [27/300], Step [86/225], Training Accuracy: 76.7260%, Training Loss: 0.5570%\n",
      "Epoch [27/300], Step [87/225], Training Accuracy: 76.7960%, Training Loss: 0.5559%\n",
      "Epoch [27/300], Step [88/225], Training Accuracy: 76.7933%, Training Loss: 0.5557%\n",
      "Epoch [27/300], Step [89/225], Training Accuracy: 76.8610%, Training Loss: 0.5543%\n",
      "Epoch [27/300], Step [90/225], Training Accuracy: 76.8924%, Training Loss: 0.5544%\n",
      "Epoch [27/300], Step [91/225], Training Accuracy: 76.8887%, Training Loss: 0.5545%\n",
      "Epoch [27/300], Step [92/225], Training Accuracy: 76.9022%, Training Loss: 0.5545%\n",
      "Epoch [27/300], Step [93/225], Training Accuracy: 76.8817%, Training Loss: 0.5553%\n",
      "Epoch [27/300], Step [94/225], Training Accuracy: 76.9781%, Training Loss: 0.5537%\n",
      "Epoch [27/300], Step [95/225], Training Accuracy: 76.9737%, Training Loss: 0.5538%\n",
      "Epoch [27/300], Step [96/225], Training Accuracy: 77.0671%, Training Loss: 0.5520%\n",
      "Epoch [27/300], Step [97/225], Training Accuracy: 77.1102%, Training Loss: 0.5523%\n",
      "Epoch [27/300], Step [98/225], Training Accuracy: 77.0408%, Training Loss: 0.5532%\n",
      "Epoch [27/300], Step [99/225], Training Accuracy: 77.0833%, Training Loss: 0.5527%\n",
      "Epoch [27/300], Step [100/225], Training Accuracy: 77.0312%, Training Loss: 0.5531%\n",
      "Epoch [27/300], Step [101/225], Training Accuracy: 77.1504%, Training Loss: 0.5514%\n",
      "Epoch [27/300], Step [102/225], Training Accuracy: 77.0680%, Training Loss: 0.5524%\n",
      "Epoch [27/300], Step [103/225], Training Accuracy: 76.9873%, Training Loss: 0.5557%\n",
      "Epoch [27/300], Step [104/225], Training Accuracy: 76.9531%, Training Loss: 0.5565%\n",
      "Epoch [27/300], Step [105/225], Training Accuracy: 76.9048%, Training Loss: 0.5570%\n",
      "Epoch [27/300], Step [106/225], Training Accuracy: 76.8426%, Training Loss: 0.5586%\n",
      "Epoch [27/300], Step [107/225], Training Accuracy: 76.8692%, Training Loss: 0.5588%\n",
      "Epoch [27/300], Step [108/225], Training Accuracy: 76.8519%, Training Loss: 0.5586%\n",
      "Epoch [27/300], Step [109/225], Training Accuracy: 76.8205%, Training Loss: 0.5593%\n",
      "Epoch [27/300], Step [110/225], Training Accuracy: 76.8750%, Training Loss: 0.5582%\n",
      "Epoch [27/300], Step [111/225], Training Accuracy: 76.9989%, Training Loss: 0.5567%\n",
      "Epoch [27/300], Step [112/225], Training Accuracy: 76.9810%, Training Loss: 0.5565%\n",
      "Epoch [27/300], Step [113/225], Training Accuracy: 76.9912%, Training Loss: 0.5559%\n",
      "Epoch [27/300], Step [114/225], Training Accuracy: 77.0148%, Training Loss: 0.5549%\n",
      "Epoch [27/300], Step [115/225], Training Accuracy: 77.0109%, Training Loss: 0.5547%\n",
      "Epoch [27/300], Step [116/225], Training Accuracy: 76.9262%, Training Loss: 0.5560%\n",
      "Epoch [27/300], Step [117/225], Training Accuracy: 76.9498%, Training Loss: 0.5556%\n",
      "Epoch [27/300], Step [118/225], Training Accuracy: 76.8935%, Training Loss: 0.5566%\n",
      "Epoch [27/300], Step [119/225], Training Accuracy: 76.9170%, Training Loss: 0.5567%\n",
      "Epoch [27/300], Step [120/225], Training Accuracy: 76.9531%, Training Loss: 0.5562%\n",
      "Epoch [27/300], Step [121/225], Training Accuracy: 76.9112%, Training Loss: 0.5565%\n",
      "Epoch [27/300], Step [122/225], Training Accuracy: 76.9339%, Training Loss: 0.5562%\n",
      "Epoch [27/300], Step [123/225], Training Accuracy: 77.0071%, Training Loss: 0.5549%\n",
      "Epoch [27/300], Step [124/225], Training Accuracy: 77.0413%, Training Loss: 0.5547%\n",
      "Epoch [27/300], Step [125/225], Training Accuracy: 77.0500%, Training Loss: 0.5543%\n",
      "Epoch [27/300], Step [126/225], Training Accuracy: 77.1081%, Training Loss: 0.5535%\n",
      "Epoch [27/300], Step [127/225], Training Accuracy: 77.1531%, Training Loss: 0.5528%\n",
      "Epoch [27/300], Step [128/225], Training Accuracy: 77.0874%, Training Loss: 0.5535%\n",
      "Epoch [27/300], Step [129/225], Training Accuracy: 77.0712%, Training Loss: 0.5541%\n",
      "Epoch [27/300], Step [130/225], Training Accuracy: 77.0673%, Training Loss: 0.5543%\n",
      "Epoch [27/300], Step [131/225], Training Accuracy: 77.1231%, Training Loss: 0.5538%\n",
      "Epoch [27/300], Step [132/225], Training Accuracy: 77.1188%, Training Loss: 0.5540%\n",
      "Epoch [27/300], Step [133/225], Training Accuracy: 77.1734%, Training Loss: 0.5527%\n",
      "Epoch [27/300], Step [134/225], Training Accuracy: 77.2505%, Training Loss: 0.5518%\n",
      "Epoch [27/300], Step [135/225], Training Accuracy: 77.3495%, Training Loss: 0.5500%\n",
      "Epoch [27/300], Step [136/225], Training Accuracy: 77.2748%, Training Loss: 0.5510%\n",
      "Epoch [27/300], Step [137/225], Training Accuracy: 77.3266%, Training Loss: 0.5502%\n",
      "Epoch [27/300], Step [138/225], Training Accuracy: 77.3324%, Training Loss: 0.5504%\n",
      "Epoch [27/300], Step [139/225], Training Accuracy: 77.3381%, Training Loss: 0.5503%\n",
      "Epoch [27/300], Step [140/225], Training Accuracy: 77.3549%, Training Loss: 0.5498%\n",
      "Epoch [27/300], Step [141/225], Training Accuracy: 77.3382%, Training Loss: 0.5499%\n",
      "Epoch [27/300], Step [142/225], Training Accuracy: 77.3658%, Training Loss: 0.5495%\n",
      "Epoch [27/300], Step [143/225], Training Accuracy: 77.2946%, Training Loss: 0.5506%\n",
      "Epoch [27/300], Step [144/225], Training Accuracy: 77.3112%, Training Loss: 0.5503%\n",
      "Epoch [27/300], Step [145/225], Training Accuracy: 77.3060%, Training Loss: 0.5508%\n",
      "Epoch [27/300], Step [146/225], Training Accuracy: 77.3652%, Training Loss: 0.5502%\n",
      "Epoch [27/300], Step [147/225], Training Accuracy: 77.2640%, Training Loss: 0.5517%\n",
      "Epoch [27/300], Step [148/225], Training Accuracy: 77.2698%, Training Loss: 0.5511%\n",
      "Epoch [27/300], Step [149/225], Training Accuracy: 77.2966%, Training Loss: 0.5508%\n",
      "Epoch [27/300], Step [150/225], Training Accuracy: 77.3750%, Training Loss: 0.5496%\n",
      "Epoch [27/300], Step [151/225], Training Accuracy: 77.4007%, Training Loss: 0.5488%\n",
      "Epoch [27/300], Step [152/225], Training Accuracy: 77.4568%, Training Loss: 0.5478%\n",
      "Epoch [27/300], Step [153/225], Training Accuracy: 77.4918%, Training Loss: 0.5468%\n",
      "Epoch [27/300], Step [154/225], Training Accuracy: 77.4959%, Training Loss: 0.5467%\n",
      "Epoch [27/300], Step [155/225], Training Accuracy: 77.5302%, Training Loss: 0.5461%\n",
      "Epoch [27/300], Step [156/225], Training Accuracy: 77.5341%, Training Loss: 0.5458%\n",
      "Epoch [27/300], Step [157/225], Training Accuracy: 77.5279%, Training Loss: 0.5460%\n",
      "Epoch [27/300], Step [158/225], Training Accuracy: 77.5811%, Training Loss: 0.5454%\n",
      "Epoch [27/300], Step [159/225], Training Accuracy: 77.6140%, Training Loss: 0.5448%\n",
      "Epoch [27/300], Step [160/225], Training Accuracy: 77.5879%, Training Loss: 0.5452%\n",
      "Epoch [27/300], Step [161/225], Training Accuracy: 77.5912%, Training Loss: 0.5445%\n",
      "Epoch [27/300], Step [162/225], Training Accuracy: 77.6427%, Training Loss: 0.5437%\n",
      "Epoch [27/300], Step [163/225], Training Accuracy: 77.6649%, Training Loss: 0.5435%\n",
      "Epoch [27/300], Step [164/225], Training Accuracy: 77.6582%, Training Loss: 0.5429%\n",
      "Epoch [27/300], Step [165/225], Training Accuracy: 77.6705%, Training Loss: 0.5429%\n",
      "Epoch [27/300], Step [166/225], Training Accuracy: 77.6355%, Training Loss: 0.5430%\n",
      "Epoch [27/300], Step [167/225], Training Accuracy: 77.6478%, Training Loss: 0.5425%\n",
      "Epoch [27/300], Step [168/225], Training Accuracy: 77.6600%, Training Loss: 0.5423%\n",
      "Epoch [27/300], Step [169/225], Training Accuracy: 77.6627%, Training Loss: 0.5432%\n",
      "Epoch [27/300], Step [170/225], Training Accuracy: 77.6195%, Training Loss: 0.5439%\n",
      "Epoch [27/300], Step [171/225], Training Accuracy: 77.6407%, Training Loss: 0.5435%\n",
      "Epoch [27/300], Step [172/225], Training Accuracy: 77.6526%, Training Loss: 0.5438%\n",
      "Epoch [27/300], Step [173/225], Training Accuracy: 77.6283%, Training Loss: 0.5440%\n",
      "Epoch [27/300], Step [174/225], Training Accuracy: 77.6401%, Training Loss: 0.5440%\n",
      "Epoch [27/300], Step [175/225], Training Accuracy: 77.7054%, Training Loss: 0.5430%\n",
      "Epoch [27/300], Step [176/225], Training Accuracy: 77.7255%, Training Loss: 0.5426%\n",
      "Epoch [27/300], Step [177/225], Training Accuracy: 77.7189%, Training Loss: 0.5425%\n",
      "Epoch [27/300], Step [178/225], Training Accuracy: 77.6598%, Training Loss: 0.5431%\n",
      "Epoch [27/300], Step [179/225], Training Accuracy: 77.6973%, Training Loss: 0.5428%\n",
      "Epoch [27/300], Step [180/225], Training Accuracy: 77.7083%, Training Loss: 0.5428%\n",
      "Epoch [27/300], Step [181/225], Training Accuracy: 77.7193%, Training Loss: 0.5429%\n",
      "Epoch [27/300], Step [182/225], Training Accuracy: 77.7473%, Training Loss: 0.5422%\n",
      "Epoch [27/300], Step [183/225], Training Accuracy: 77.8005%, Training Loss: 0.5412%\n",
      "Epoch [27/300], Step [184/225], Training Accuracy: 77.8278%, Training Loss: 0.5409%\n",
      "Epoch [27/300], Step [185/225], Training Accuracy: 77.8463%, Training Loss: 0.5405%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/300], Step [186/225], Training Accuracy: 77.8814%, Training Loss: 0.5401%\n",
      "Epoch [27/300], Step [187/225], Training Accuracy: 77.9412%, Training Loss: 0.5393%\n",
      "Epoch [27/300], Step [188/225], Training Accuracy: 77.9754%, Training Loss: 0.5392%\n",
      "Epoch [27/300], Step [189/225], Training Accuracy: 78.0423%, Training Loss: 0.5382%\n",
      "Epoch [27/300], Step [190/225], Training Accuracy: 78.0099%, Training Loss: 0.5388%\n",
      "Epoch [27/300], Step [191/225], Training Accuracy: 78.0350%, Training Loss: 0.5384%\n",
      "Epoch [27/300], Step [192/225], Training Accuracy: 78.0436%, Training Loss: 0.5381%\n",
      "Epoch [27/300], Step [193/225], Training Accuracy: 78.0359%, Training Loss: 0.5385%\n",
      "Epoch [27/300], Step [194/225], Training Accuracy: 78.1169%, Training Loss: 0.5371%\n",
      "Epoch [27/300], Step [195/225], Training Accuracy: 78.0929%, Training Loss: 0.5373%\n",
      "Epoch [27/300], Step [196/225], Training Accuracy: 78.1091%, Training Loss: 0.5368%\n",
      "Epoch [27/300], Step [197/225], Training Accuracy: 78.1012%, Training Loss: 0.5372%\n",
      "Epoch [27/300], Step [198/225], Training Accuracy: 78.0619%, Training Loss: 0.5376%\n",
      "Epoch [27/300], Step [199/225], Training Accuracy: 78.0386%, Training Loss: 0.5384%\n",
      "Epoch [27/300], Step [200/225], Training Accuracy: 78.1094%, Training Loss: 0.5374%\n",
      "Epoch [27/300], Step [201/225], Training Accuracy: 78.1095%, Training Loss: 0.5371%\n",
      "Epoch [27/300], Step [202/225], Training Accuracy: 78.1095%, Training Loss: 0.5374%\n",
      "Epoch [27/300], Step [203/225], Training Accuracy: 78.1404%, Training Loss: 0.5370%\n",
      "Epoch [27/300], Step [204/225], Training Accuracy: 78.1020%, Training Loss: 0.5371%\n",
      "Epoch [27/300], Step [205/225], Training Accuracy: 78.1174%, Training Loss: 0.5371%\n",
      "Epoch [27/300], Step [206/225], Training Accuracy: 78.1022%, Training Loss: 0.5369%\n",
      "Epoch [27/300], Step [207/225], Training Accuracy: 78.1476%, Training Loss: 0.5362%\n",
      "Epoch [27/300], Step [208/225], Training Accuracy: 78.1400%, Training Loss: 0.5364%\n",
      "Epoch [27/300], Step [209/225], Training Accuracy: 78.1474%, Training Loss: 0.5363%\n",
      "Epoch [27/300], Step [210/225], Training Accuracy: 78.1622%, Training Loss: 0.5358%\n",
      "Epoch [27/300], Step [211/225], Training Accuracy: 78.1916%, Training Loss: 0.5355%\n",
      "Epoch [27/300], Step [212/225], Training Accuracy: 78.1840%, Training Loss: 0.5362%\n",
      "Epoch [27/300], Step [213/225], Training Accuracy: 78.1837%, Training Loss: 0.5363%\n",
      "Epoch [27/300], Step [214/225], Training Accuracy: 78.1469%, Training Loss: 0.5365%\n",
      "Epoch [27/300], Step [215/225], Training Accuracy: 78.1395%, Training Loss: 0.5359%\n",
      "Epoch [27/300], Step [216/225], Training Accuracy: 78.1033%, Training Loss: 0.5365%\n",
      "Epoch [27/300], Step [217/225], Training Accuracy: 78.1322%, Training Loss: 0.5359%\n",
      "Epoch [27/300], Step [218/225], Training Accuracy: 78.1608%, Training Loss: 0.5361%\n",
      "Epoch [27/300], Step [219/225], Training Accuracy: 78.1607%, Training Loss: 0.5363%\n",
      "Epoch [27/300], Step [220/225], Training Accuracy: 78.1818%, Training Loss: 0.5359%\n",
      "Epoch [27/300], Step [221/225], Training Accuracy: 78.1816%, Training Loss: 0.5361%\n",
      "Epoch [27/300], Step [222/225], Training Accuracy: 78.1532%, Training Loss: 0.5362%\n",
      "Epoch [27/300], Step [223/225], Training Accuracy: 78.1811%, Training Loss: 0.5358%\n",
      "Epoch [27/300], Step [224/225], Training Accuracy: 78.2017%, Training Loss: 0.5355%\n",
      "Epoch [27/300], Step [225/225], Training Accuracy: 78.2032%, Training Loss: 0.5352%\n",
      "Epoch [28/300], Step [1/225], Training Accuracy: 89.0625%, Training Loss: 0.4877%\n",
      "Epoch [28/300], Step [2/225], Training Accuracy: 86.7188%, Training Loss: 0.4888%\n",
      "Epoch [28/300], Step [3/225], Training Accuracy: 79.6875%, Training Loss: 0.5747%\n",
      "Epoch [28/300], Step [4/225], Training Accuracy: 79.2969%, Training Loss: 0.5750%\n",
      "Epoch [28/300], Step [5/225], Training Accuracy: 81.2500%, Training Loss: 0.5373%\n",
      "Epoch [28/300], Step [6/225], Training Accuracy: 80.7292%, Training Loss: 0.5328%\n",
      "Epoch [28/300], Step [7/225], Training Accuracy: 79.9107%, Training Loss: 0.5387%\n",
      "Epoch [28/300], Step [8/225], Training Accuracy: 80.2734%, Training Loss: 0.5244%\n",
      "Epoch [28/300], Step [9/225], Training Accuracy: 80.5556%, Training Loss: 0.5155%\n",
      "Epoch [28/300], Step [10/225], Training Accuracy: 80.7812%, Training Loss: 0.5192%\n",
      "Epoch [28/300], Step [11/225], Training Accuracy: 81.1080%, Training Loss: 0.5172%\n",
      "Epoch [28/300], Step [12/225], Training Accuracy: 80.5990%, Training Loss: 0.5154%\n",
      "Epoch [28/300], Step [13/225], Training Accuracy: 80.6490%, Training Loss: 0.5160%\n",
      "Epoch [28/300], Step [14/225], Training Accuracy: 80.2455%, Training Loss: 0.5208%\n",
      "Epoch [28/300], Step [15/225], Training Accuracy: 80.7292%, Training Loss: 0.5123%\n",
      "Epoch [28/300], Step [16/225], Training Accuracy: 79.6875%, Training Loss: 0.5258%\n",
      "Epoch [28/300], Step [17/225], Training Accuracy: 79.9632%, Training Loss: 0.5264%\n",
      "Epoch [28/300], Step [18/225], Training Accuracy: 79.7743%, Training Loss: 0.5308%\n",
      "Epoch [28/300], Step [19/225], Training Accuracy: 80.0987%, Training Loss: 0.5208%\n",
      "Epoch [28/300], Step [20/225], Training Accuracy: 80.2344%, Training Loss: 0.5147%\n",
      "Epoch [28/300], Step [21/225], Training Accuracy: 80.2827%, Training Loss: 0.5125%\n",
      "Epoch [28/300], Step [22/225], Training Accuracy: 80.1847%, Training Loss: 0.5165%\n",
      "Epoch [28/300], Step [23/225], Training Accuracy: 79.6875%, Training Loss: 0.5250%\n",
      "Epoch [28/300], Step [24/225], Training Accuracy: 78.9062%, Training Loss: 0.5406%\n",
      "Epoch [28/300], Step [25/225], Training Accuracy: 79.0625%, Training Loss: 0.5354%\n",
      "Epoch [28/300], Step [26/225], Training Accuracy: 78.9062%, Training Loss: 0.5369%\n",
      "Epoch [28/300], Step [27/225], Training Accuracy: 78.9352%, Training Loss: 0.5365%\n",
      "Epoch [28/300], Step [28/225], Training Accuracy: 79.1853%, Training Loss: 0.5309%\n",
      "Epoch [28/300], Step [29/225], Training Accuracy: 79.3642%, Training Loss: 0.5251%\n",
      "Epoch [28/300], Step [30/225], Training Accuracy: 79.4792%, Training Loss: 0.5245%\n",
      "Epoch [28/300], Step [31/225], Training Accuracy: 79.3851%, Training Loss: 0.5281%\n",
      "Epoch [28/300], Step [32/225], Training Accuracy: 79.2480%, Training Loss: 0.5279%\n",
      "Epoch [28/300], Step [33/225], Training Accuracy: 79.4034%, Training Loss: 0.5253%\n",
      "Epoch [28/300], Step [34/225], Training Accuracy: 79.5956%, Training Loss: 0.5205%\n",
      "Epoch [28/300], Step [35/225], Training Accuracy: 79.5536%, Training Loss: 0.5204%\n",
      "Epoch [28/300], Step [36/225], Training Accuracy: 79.5573%, Training Loss: 0.5179%\n",
      "Epoch [28/300], Step [37/225], Training Accuracy: 79.6453%, Training Loss: 0.5181%\n",
      "Epoch [28/300], Step [38/225], Training Accuracy: 79.6464%, Training Loss: 0.5191%\n",
      "Epoch [28/300], Step [39/225], Training Accuracy: 79.7276%, Training Loss: 0.5155%\n",
      "Epoch [28/300], Step [40/225], Training Accuracy: 79.8047%, Training Loss: 0.5155%\n",
      "Epoch [28/300], Step [41/225], Training Accuracy: 79.6113%, Training Loss: 0.5156%\n",
      "Epoch [28/300], Step [42/225], Training Accuracy: 79.5015%, Training Loss: 0.5173%\n",
      "Epoch [28/300], Step [43/225], Training Accuracy: 79.4695%, Training Loss: 0.5190%\n",
      "Epoch [28/300], Step [44/225], Training Accuracy: 79.4744%, Training Loss: 0.5198%\n",
      "Epoch [28/300], Step [45/225], Training Accuracy: 79.3403%, Training Loss: 0.5212%\n",
      "Epoch [28/300], Step [46/225], Training Accuracy: 79.6875%, Training Loss: 0.5171%\n",
      "Epoch [28/300], Step [47/225], Training Accuracy: 79.7872%, Training Loss: 0.5154%\n",
      "Epoch [28/300], Step [48/225], Training Accuracy: 79.7526%, Training Loss: 0.5163%\n",
      "Epoch [28/300], Step [49/225], Training Accuracy: 79.6875%, Training Loss: 0.5179%\n",
      "Epoch [28/300], Step [50/225], Training Accuracy: 79.7188%, Training Loss: 0.5171%\n",
      "Epoch [28/300], Step [51/225], Training Accuracy: 79.8100%, Training Loss: 0.5160%\n",
      "Epoch [28/300], Step [52/225], Training Accuracy: 79.8377%, Training Loss: 0.5140%\n",
      "Epoch [28/300], Step [53/225], Training Accuracy: 79.8644%, Training Loss: 0.5131%\n",
      "Epoch [28/300], Step [54/225], Training Accuracy: 79.7164%, Training Loss: 0.5153%\n",
      "Epoch [28/300], Step [55/225], Training Accuracy: 79.9148%, Training Loss: 0.5115%\n",
      "Epoch [28/300], Step [56/225], Training Accuracy: 79.8828%, Training Loss: 0.5124%\n",
      "Epoch [28/300], Step [57/225], Training Accuracy: 79.7971%, Training Loss: 0.5132%\n",
      "Epoch [28/300], Step [58/225], Training Accuracy: 79.8222%, Training Loss: 0.5122%\n",
      "Epoch [28/300], Step [59/225], Training Accuracy: 79.6875%, Training Loss: 0.5135%\n",
      "Epoch [28/300], Step [60/225], Training Accuracy: 79.7917%, Training Loss: 0.5110%\n",
      "Epoch [28/300], Step [61/225], Training Accuracy: 79.7387%, Training Loss: 0.5113%\n",
      "Epoch [28/300], Step [62/225], Training Accuracy: 79.6875%, Training Loss: 0.5134%\n",
      "Epoch [28/300], Step [63/225], Training Accuracy: 79.7371%, Training Loss: 0.5121%\n",
      "Epoch [28/300], Step [64/225], Training Accuracy: 79.8096%, Training Loss: 0.5115%\n",
      "Epoch [28/300], Step [65/225], Training Accuracy: 79.8798%, Training Loss: 0.5096%\n",
      "Epoch [28/300], Step [66/225], Training Accuracy: 79.7348%, Training Loss: 0.5112%\n",
      "Epoch [28/300], Step [67/225], Training Accuracy: 79.7108%, Training Loss: 0.5123%\n",
      "Epoch [28/300], Step [68/225], Training Accuracy: 79.7105%, Training Loss: 0.5140%\n",
      "Epoch [28/300], Step [69/225], Training Accuracy: 79.6649%, Training Loss: 0.5147%\n",
      "Epoch [28/300], Step [70/225], Training Accuracy: 79.7098%, Training Loss: 0.5133%\n",
      "Epoch [28/300], Step [71/225], Training Accuracy: 79.7755%, Training Loss: 0.5118%\n",
      "Epoch [28/300], Step [72/225], Training Accuracy: 79.6658%, Training Loss: 0.5122%\n",
      "Epoch [28/300], Step [73/225], Training Accuracy: 79.5377%, Training Loss: 0.5153%\n",
      "Epoch [28/300], Step [74/225], Training Accuracy: 79.5186%, Training Loss: 0.5154%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/300], Step [75/225], Training Accuracy: 79.5833%, Training Loss: 0.5148%\n",
      "Epoch [28/300], Step [76/225], Training Accuracy: 79.4613%, Training Loss: 0.5145%\n",
      "Epoch [28/300], Step [77/225], Training Accuracy: 79.4846%, Training Loss: 0.5146%\n",
      "Epoch [28/300], Step [78/225], Training Accuracy: 79.5072%, Training Loss: 0.5143%\n",
      "Epoch [28/300], Step [79/225], Training Accuracy: 79.5293%, Training Loss: 0.5129%\n",
      "Epoch [28/300], Step [80/225], Training Accuracy: 79.3750%, Training Loss: 0.5153%\n",
      "Epoch [28/300], Step [81/225], Training Accuracy: 79.3789%, Training Loss: 0.5151%\n",
      "Epoch [28/300], Step [82/225], Training Accuracy: 79.3826%, Training Loss: 0.5146%\n",
      "Epoch [28/300], Step [83/225], Training Accuracy: 79.3486%, Training Loss: 0.5148%\n",
      "Epoch [28/300], Step [84/225], Training Accuracy: 79.3155%, Training Loss: 0.5167%\n",
      "Epoch [28/300], Step [85/225], Training Accuracy: 79.2463%, Training Loss: 0.5173%\n",
      "Epoch [28/300], Step [86/225], Training Accuracy: 79.3241%, Training Loss: 0.5161%\n",
      "Epoch [28/300], Step [87/225], Training Accuracy: 79.2924%, Training Loss: 0.5162%\n",
      "Epoch [28/300], Step [88/225], Training Accuracy: 79.3324%, Training Loss: 0.5155%\n",
      "Epoch [28/300], Step [89/225], Training Accuracy: 79.3890%, Training Loss: 0.5148%\n",
      "Epoch [28/300], Step [90/225], Training Accuracy: 79.4444%, Training Loss: 0.5137%\n",
      "Epoch [28/300], Step [91/225], Training Accuracy: 79.5158%, Training Loss: 0.5126%\n",
      "Epoch [28/300], Step [92/225], Training Accuracy: 79.6026%, Training Loss: 0.5109%\n",
      "Epoch [28/300], Step [93/225], Training Accuracy: 79.6875%, Training Loss: 0.5097%\n",
      "Epoch [28/300], Step [94/225], Training Accuracy: 79.6709%, Training Loss: 0.5092%\n",
      "Epoch [28/300], Step [95/225], Training Accuracy: 79.6711%, Training Loss: 0.5100%\n",
      "Epoch [28/300], Step [96/225], Training Accuracy: 79.7526%, Training Loss: 0.5084%\n",
      "Epoch [28/300], Step [97/225], Training Accuracy: 79.7519%, Training Loss: 0.5079%\n",
      "Epoch [28/300], Step [98/225], Training Accuracy: 79.7832%, Training Loss: 0.5077%\n",
      "Epoch [28/300], Step [99/225], Training Accuracy: 79.7980%, Training Loss: 0.5067%\n",
      "Epoch [28/300], Step [100/225], Training Accuracy: 79.7031%, Training Loss: 0.5083%\n",
      "Epoch [28/300], Step [101/225], Training Accuracy: 79.6566%, Training Loss: 0.5086%\n",
      "Epoch [28/300], Step [102/225], Training Accuracy: 79.6109%, Training Loss: 0.5102%\n",
      "Epoch [28/300], Step [103/225], Training Accuracy: 79.5510%, Training Loss: 0.5105%\n",
      "Epoch [28/300], Step [104/225], Training Accuracy: 79.5222%, Training Loss: 0.5104%\n",
      "Epoch [28/300], Step [105/225], Training Accuracy: 79.4792%, Training Loss: 0.5103%\n",
      "Epoch [28/300], Step [106/225], Training Accuracy: 79.5401%, Training Loss: 0.5101%\n",
      "Epoch [28/300], Step [107/225], Training Accuracy: 79.4831%, Training Loss: 0.5105%\n",
      "Epoch [28/300], Step [108/225], Training Accuracy: 79.4705%, Training Loss: 0.5105%\n",
      "Epoch [28/300], Step [109/225], Training Accuracy: 79.4295%, Training Loss: 0.5118%\n",
      "Epoch [28/300], Step [110/225], Training Accuracy: 79.5028%, Training Loss: 0.5113%\n",
      "Epoch [28/300], Step [111/225], Training Accuracy: 79.5467%, Training Loss: 0.5107%\n",
      "Epoch [28/300], Step [112/225], Training Accuracy: 79.5201%, Training Loss: 0.5108%\n",
      "Epoch [28/300], Step [113/225], Training Accuracy: 79.5354%, Training Loss: 0.5103%\n",
      "Epoch [28/300], Step [114/225], Training Accuracy: 79.5504%, Training Loss: 0.5099%\n",
      "Epoch [28/300], Step [115/225], Training Accuracy: 79.5516%, Training Loss: 0.5100%\n",
      "Epoch [28/300], Step [116/225], Training Accuracy: 79.5124%, Training Loss: 0.5108%\n",
      "Epoch [28/300], Step [117/225], Training Accuracy: 79.5540%, Training Loss: 0.5097%\n",
      "Epoch [28/300], Step [118/225], Training Accuracy: 79.4624%, Training Loss: 0.5109%\n",
      "Epoch [28/300], Step [119/225], Training Accuracy: 79.4380%, Training Loss: 0.5112%\n",
      "Epoch [28/300], Step [120/225], Training Accuracy: 79.4401%, Training Loss: 0.5109%\n",
      "Epoch [28/300], Step [121/225], Training Accuracy: 79.4163%, Training Loss: 0.5106%\n",
      "Epoch [28/300], Step [122/225], Training Accuracy: 79.4442%, Training Loss: 0.5100%\n",
      "Epoch [28/300], Step [123/225], Training Accuracy: 79.5097%, Training Loss: 0.5089%\n",
      "Epoch [28/300], Step [124/225], Training Accuracy: 79.5489%, Training Loss: 0.5082%\n",
      "Epoch [28/300], Step [125/225], Training Accuracy: 79.5375%, Training Loss: 0.5082%\n",
      "Epoch [28/300], Step [126/225], Training Accuracy: 79.5387%, Training Loss: 0.5080%\n",
      "Epoch [28/300], Step [127/225], Training Accuracy: 79.5276%, Training Loss: 0.5073%\n",
      "Epoch [28/300], Step [128/225], Training Accuracy: 79.4678%, Training Loss: 0.5079%\n",
      "Epoch [28/300], Step [129/225], Training Accuracy: 79.4695%, Training Loss: 0.5076%\n",
      "Epoch [28/300], Step [130/225], Training Accuracy: 79.4832%, Training Loss: 0.5075%\n",
      "Epoch [28/300], Step [131/225], Training Accuracy: 79.4728%, Training Loss: 0.5072%\n",
      "Epoch [28/300], Step [132/225], Training Accuracy: 79.4626%, Training Loss: 0.5077%\n",
      "Epoch [28/300], Step [133/225], Training Accuracy: 79.5230%, Training Loss: 0.5069%\n",
      "Epoch [28/300], Step [134/225], Training Accuracy: 79.5009%, Training Loss: 0.5068%\n",
      "Epoch [28/300], Step [135/225], Training Accuracy: 79.5486%, Training Loss: 0.5054%\n",
      "Epoch [28/300], Step [136/225], Training Accuracy: 79.5381%, Training Loss: 0.5055%\n",
      "Epoch [28/300], Step [137/225], Training Accuracy: 79.5849%, Training Loss: 0.5048%\n",
      "Epoch [28/300], Step [138/225], Training Accuracy: 79.5969%, Training Loss: 0.5045%\n",
      "Epoch [28/300], Step [139/225], Training Accuracy: 79.5638%, Training Loss: 0.5055%\n",
      "Epoch [28/300], Step [140/225], Training Accuracy: 79.5647%, Training Loss: 0.5050%\n",
      "Epoch [28/300], Step [141/225], Training Accuracy: 79.5213%, Training Loss: 0.5058%\n",
      "Epoch [28/300], Step [142/225], Training Accuracy: 79.4894%, Training Loss: 0.5059%\n",
      "Epoch [28/300], Step [143/225], Training Accuracy: 79.4908%, Training Loss: 0.5065%\n",
      "Epoch [28/300], Step [144/225], Training Accuracy: 79.5247%, Training Loss: 0.5058%\n",
      "Epoch [28/300], Step [145/225], Training Accuracy: 79.5366%, Training Loss: 0.5062%\n",
      "Epoch [28/300], Step [146/225], Training Accuracy: 79.5484%, Training Loss: 0.5058%\n",
      "Epoch [28/300], Step [147/225], Training Accuracy: 79.5068%, Training Loss: 0.5069%\n",
      "Epoch [28/300], Step [148/225], Training Accuracy: 79.4869%, Training Loss: 0.5067%\n",
      "Epoch [28/300], Step [149/225], Training Accuracy: 79.4778%, Training Loss: 0.5069%\n",
      "Epoch [28/300], Step [150/225], Training Accuracy: 79.5000%, Training Loss: 0.5061%\n",
      "Epoch [28/300], Step [151/225], Training Accuracy: 79.5840%, Training Loss: 0.5047%\n",
      "Epoch [28/300], Step [152/225], Training Accuracy: 79.6053%, Training Loss: 0.5039%\n",
      "Epoch [28/300], Step [153/225], Training Accuracy: 79.6160%, Training Loss: 0.5039%\n",
      "Epoch [28/300], Step [154/225], Training Accuracy: 79.6266%, Training Loss: 0.5037%\n",
      "Epoch [28/300], Step [155/225], Training Accuracy: 79.6573%, Training Loss: 0.5034%\n",
      "Epoch [28/300], Step [156/225], Training Accuracy: 79.6474%, Training Loss: 0.5031%\n",
      "Epoch [28/300], Step [157/225], Training Accuracy: 79.6377%, Training Loss: 0.5032%\n",
      "Epoch [28/300], Step [158/225], Training Accuracy: 79.7369%, Training Loss: 0.5017%\n",
      "Epoch [28/300], Step [159/225], Training Accuracy: 79.7563%, Training Loss: 0.5012%\n",
      "Epoch [28/300], Step [160/225], Training Accuracy: 79.7754%, Training Loss: 0.5011%\n",
      "Epoch [28/300], Step [161/225], Training Accuracy: 79.7845%, Training Loss: 0.5009%\n",
      "Epoch [28/300], Step [162/225], Training Accuracy: 79.7647%, Training Loss: 0.5006%\n",
      "Epoch [28/300], Step [163/225], Training Accuracy: 79.8025%, Training Loss: 0.5000%\n",
      "Epoch [28/300], Step [164/225], Training Accuracy: 79.8209%, Training Loss: 0.4998%\n",
      "Epoch [28/300], Step [165/225], Training Accuracy: 79.8106%, Training Loss: 0.4995%\n",
      "Epoch [28/300], Step [166/225], Training Accuracy: 79.8287%, Training Loss: 0.4994%\n",
      "Epoch [28/300], Step [167/225], Training Accuracy: 79.7998%, Training Loss: 0.4992%\n",
      "Epoch [28/300], Step [168/225], Training Accuracy: 79.8270%, Training Loss: 0.4984%\n",
      "Epoch [28/300], Step [169/225], Training Accuracy: 79.7615%, Training Loss: 0.4998%\n",
      "Epoch [28/300], Step [170/225], Training Accuracy: 79.7335%, Training Loss: 0.5002%\n",
      "Epoch [28/300], Step [171/225], Training Accuracy: 79.7515%, Training Loss: 0.5002%\n",
      "Epoch [28/300], Step [172/225], Training Accuracy: 79.7783%, Training Loss: 0.4999%\n",
      "Epoch [28/300], Step [173/225], Training Accuracy: 79.7598%, Training Loss: 0.5003%\n",
      "Epoch [28/300], Step [174/225], Training Accuracy: 79.7324%, Training Loss: 0.5010%\n",
      "Epoch [28/300], Step [175/225], Training Accuracy: 79.7500%, Training Loss: 0.5006%\n",
      "Epoch [28/300], Step [176/225], Training Accuracy: 79.7408%, Training Loss: 0.5014%\n",
      "Epoch [28/300], Step [177/225], Training Accuracy: 79.7405%, Training Loss: 0.5013%\n",
      "Epoch [28/300], Step [178/225], Training Accuracy: 79.6875%, Training Loss: 0.5022%\n",
      "Epoch [28/300], Step [179/225], Training Accuracy: 79.7224%, Training Loss: 0.5016%\n",
      "Epoch [28/300], Step [180/225], Training Accuracy: 79.7309%, Training Loss: 0.5017%\n",
      "Epoch [28/300], Step [181/225], Training Accuracy: 79.7307%, Training Loss: 0.5019%\n",
      "Epoch [28/300], Step [182/225], Training Accuracy: 79.7734%, Training Loss: 0.5013%\n",
      "Epoch [28/300], Step [183/225], Training Accuracy: 79.7985%, Training Loss: 0.5005%\n",
      "Epoch [28/300], Step [184/225], Training Accuracy: 79.8064%, Training Loss: 0.5007%\n",
      "Epoch [28/300], Step [185/225], Training Accuracy: 79.8142%, Training Loss: 0.5010%\n",
      "Epoch [28/300], Step [186/225], Training Accuracy: 79.8219%, Training Loss: 0.5006%\n",
      "Epoch [28/300], Step [187/225], Training Accuracy: 79.7961%, Training Loss: 0.5014%\n",
      "Epoch [28/300], Step [188/225], Training Accuracy: 79.8122%, Training Loss: 0.5012%\n",
      "Epoch [28/300], Step [189/225], Training Accuracy: 79.8280%, Training Loss: 0.5008%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/300], Step [190/225], Training Accuracy: 79.8273%, Training Loss: 0.5005%\n",
      "Epoch [28/300], Step [191/225], Training Accuracy: 79.8838%, Training Loss: 0.4997%\n",
      "Epoch [28/300], Step [192/225], Training Accuracy: 79.8910%, Training Loss: 0.4996%\n",
      "Epoch [28/300], Step [193/225], Training Accuracy: 79.8251%, Training Loss: 0.5005%\n",
      "Epoch [28/300], Step [194/225], Training Accuracy: 79.8566%, Training Loss: 0.5000%\n",
      "Epoch [28/300], Step [195/225], Training Accuracy: 79.8478%, Training Loss: 0.5000%\n",
      "Epoch [28/300], Step [196/225], Training Accuracy: 79.8788%, Training Loss: 0.4994%\n",
      "Epoch [28/300], Step [197/225], Training Accuracy: 79.8620%, Training Loss: 0.5001%\n",
      "Epoch [28/300], Step [198/225], Training Accuracy: 79.8769%, Training Loss: 0.5002%\n",
      "Epoch [28/300], Step [199/225], Training Accuracy: 79.8759%, Training Loss: 0.5003%\n",
      "Epoch [28/300], Step [200/225], Training Accuracy: 79.8984%, Training Loss: 0.4998%\n",
      "Epoch [28/300], Step [201/225], Training Accuracy: 79.8896%, Training Loss: 0.4998%\n",
      "Epoch [28/300], Step [202/225], Training Accuracy: 79.9041%, Training Loss: 0.5000%\n",
      "Epoch [28/300], Step [203/225], Training Accuracy: 79.9107%, Training Loss: 0.5002%\n",
      "Epoch [28/300], Step [204/225], Training Accuracy: 79.9173%, Training Loss: 0.5001%\n",
      "Epoch [28/300], Step [205/225], Training Accuracy: 79.9314%, Training Loss: 0.4997%\n",
      "Epoch [28/300], Step [206/225], Training Accuracy: 79.9378%, Training Loss: 0.4996%\n",
      "Epoch [28/300], Step [207/225], Training Accuracy: 79.9743%, Training Loss: 0.4989%\n",
      "Epoch [28/300], Step [208/225], Training Accuracy: 79.9579%, Training Loss: 0.4994%\n",
      "Epoch [28/300], Step [209/225], Training Accuracy: 79.9492%, Training Loss: 0.5000%\n",
      "Epoch [28/300], Step [210/225], Training Accuracy: 79.9405%, Training Loss: 0.5002%\n",
      "Epoch [28/300], Step [211/225], Training Accuracy: 79.9615%, Training Loss: 0.4998%\n",
      "Epoch [28/300], Step [212/225], Training Accuracy: 79.9381%, Training Loss: 0.5002%\n",
      "Epoch [28/300], Step [213/225], Training Accuracy: 79.9442%, Training Loss: 0.5001%\n",
      "Epoch [28/300], Step [214/225], Training Accuracy: 79.9284%, Training Loss: 0.5002%\n",
      "Epoch [28/300], Step [215/225], Training Accuracy: 79.9564%, Training Loss: 0.4994%\n",
      "Epoch [28/300], Step [216/225], Training Accuracy: 79.9479%, Training Loss: 0.4998%\n",
      "Epoch [28/300], Step [217/225], Training Accuracy: 79.9467%, Training Loss: 0.4996%\n",
      "Epoch [28/300], Step [218/225], Training Accuracy: 79.9240%, Training Loss: 0.4999%\n",
      "Epoch [28/300], Step [219/225], Training Accuracy: 79.9015%, Training Loss: 0.5003%\n",
      "Epoch [28/300], Step [220/225], Training Accuracy: 79.9219%, Training Loss: 0.4998%\n",
      "Epoch [28/300], Step [221/225], Training Accuracy: 79.8996%, Training Loss: 0.5007%\n",
      "Epoch [28/300], Step [222/225], Training Accuracy: 79.8494%, Training Loss: 0.5017%\n",
      "Epoch [28/300], Step [223/225], Training Accuracy: 79.8557%, Training Loss: 0.5015%\n",
      "Epoch [28/300], Step [224/225], Training Accuracy: 79.8828%, Training Loss: 0.5008%\n",
      "Epoch [28/300], Step [225/225], Training Accuracy: 79.8916%, Training Loss: 0.5004%\n",
      "Epoch [29/300], Step [1/225], Training Accuracy: 78.1250%, Training Loss: 0.5698%\n",
      "Epoch [29/300], Step [2/225], Training Accuracy: 80.4688%, Training Loss: 0.4931%\n",
      "Epoch [29/300], Step [3/225], Training Accuracy: 78.6458%, Training Loss: 0.5441%\n",
      "Epoch [29/300], Step [4/225], Training Accuracy: 78.5156%, Training Loss: 0.5390%\n",
      "Epoch [29/300], Step [5/225], Training Accuracy: 80.3125%, Training Loss: 0.5135%\n",
      "Epoch [29/300], Step [6/225], Training Accuracy: 80.2083%, Training Loss: 0.5064%\n",
      "Epoch [29/300], Step [7/225], Training Accuracy: 79.9107%, Training Loss: 0.5201%\n",
      "Epoch [29/300], Step [8/225], Training Accuracy: 80.4688%, Training Loss: 0.5130%\n",
      "Epoch [29/300], Step [9/225], Training Accuracy: 80.5556%, Training Loss: 0.5000%\n",
      "Epoch [29/300], Step [10/225], Training Accuracy: 80.7812%, Training Loss: 0.5020%\n",
      "Epoch [29/300], Step [11/225], Training Accuracy: 80.6818%, Training Loss: 0.4973%\n",
      "Epoch [29/300], Step [12/225], Training Accuracy: 80.0781%, Training Loss: 0.5076%\n",
      "Epoch [29/300], Step [13/225], Training Accuracy: 80.2885%, Training Loss: 0.5181%\n",
      "Epoch [29/300], Step [14/225], Training Accuracy: 80.4688%, Training Loss: 0.5165%\n",
      "Epoch [29/300], Step [15/225], Training Accuracy: 80.8333%, Training Loss: 0.5080%\n",
      "Epoch [29/300], Step [16/225], Training Accuracy: 79.8828%, Training Loss: 0.5255%\n",
      "Epoch [29/300], Step [17/225], Training Accuracy: 80.0551%, Training Loss: 0.5260%\n",
      "Epoch [29/300], Step [18/225], Training Accuracy: 79.6875%, Training Loss: 0.5344%\n",
      "Epoch [29/300], Step [19/225], Training Accuracy: 79.9342%, Training Loss: 0.5263%\n",
      "Epoch [29/300], Step [20/225], Training Accuracy: 79.8438%, Training Loss: 0.5237%\n",
      "Epoch [29/300], Step [21/225], Training Accuracy: 80.1339%, Training Loss: 0.5184%\n",
      "Epoch [29/300], Step [22/225], Training Accuracy: 80.2557%, Training Loss: 0.5196%\n",
      "Epoch [29/300], Step [23/225], Training Accuracy: 80.0951%, Training Loss: 0.5201%\n",
      "Epoch [29/300], Step [24/225], Training Accuracy: 79.6875%, Training Loss: 0.5290%\n",
      "Epoch [29/300], Step [25/225], Training Accuracy: 80.0000%, Training Loss: 0.5206%\n",
      "Epoch [29/300], Step [26/225], Training Accuracy: 79.9880%, Training Loss: 0.5223%\n",
      "Epoch [29/300], Step [27/225], Training Accuracy: 80.1505%, Training Loss: 0.5220%\n",
      "Epoch [29/300], Step [28/225], Training Accuracy: 80.3571%, Training Loss: 0.5185%\n",
      "Epoch [29/300], Step [29/225], Training Accuracy: 80.4418%, Training Loss: 0.5150%\n",
      "Epoch [29/300], Step [30/225], Training Accuracy: 80.3646%, Training Loss: 0.5160%\n",
      "Epoch [29/300], Step [31/225], Training Accuracy: 80.0907%, Training Loss: 0.5169%\n",
      "Epoch [29/300], Step [32/225], Training Accuracy: 80.4688%, Training Loss: 0.5134%\n",
      "Epoch [29/300], Step [33/225], Training Accuracy: 80.6345%, Training Loss: 0.5088%\n",
      "Epoch [29/300], Step [34/225], Training Accuracy: 80.5147%, Training Loss: 0.5135%\n",
      "Epoch [29/300], Step [35/225], Training Accuracy: 80.3571%, Training Loss: 0.5152%\n",
      "Epoch [29/300], Step [36/225], Training Accuracy: 80.3819%, Training Loss: 0.5135%\n",
      "Epoch [29/300], Step [37/225], Training Accuracy: 80.1520%, Training Loss: 0.5170%\n",
      "Epoch [29/300], Step [38/225], Training Accuracy: 80.4276%, Training Loss: 0.5143%\n",
      "Epoch [29/300], Step [39/225], Training Accuracy: 80.4888%, Training Loss: 0.5112%\n",
      "Epoch [29/300], Step [40/225], Training Accuracy: 80.4688%, Training Loss: 0.5108%\n",
      "Epoch [29/300], Step [41/225], Training Accuracy: 80.5640%, Training Loss: 0.5099%\n",
      "Epoch [29/300], Step [42/225], Training Accuracy: 80.5804%, Training Loss: 0.5083%\n",
      "Epoch [29/300], Step [43/225], Training Accuracy: 80.5596%, Training Loss: 0.5084%\n",
      "Epoch [29/300], Step [44/225], Training Accuracy: 80.5753%, Training Loss: 0.5086%\n",
      "Epoch [29/300], Step [45/225], Training Accuracy: 80.5903%, Training Loss: 0.5090%\n",
      "Epoch [29/300], Step [46/225], Training Accuracy: 80.6386%, Training Loss: 0.5090%\n",
      "Epoch [29/300], Step [47/225], Training Accuracy: 80.5519%, Training Loss: 0.5100%\n",
      "Epoch [29/300], Step [48/225], Training Accuracy: 80.5339%, Training Loss: 0.5098%\n",
      "Epoch [29/300], Step [49/225], Training Accuracy: 80.4209%, Training Loss: 0.5117%\n",
      "Epoch [29/300], Step [50/225], Training Accuracy: 80.5312%, Training Loss: 0.5106%\n",
      "Epoch [29/300], Step [51/225], Training Accuracy: 80.7292%, Training Loss: 0.5069%\n",
      "Epoch [29/300], Step [52/225], Training Accuracy: 80.7993%, Training Loss: 0.5042%\n",
      "Epoch [29/300], Step [53/225], Training Accuracy: 80.8078%, Training Loss: 0.5038%\n",
      "Epoch [29/300], Step [54/225], Training Accuracy: 80.7581%, Training Loss: 0.5067%\n",
      "Epoch [29/300], Step [55/225], Training Accuracy: 80.9091%, Training Loss: 0.5033%\n",
      "Epoch [29/300], Step [56/225], Training Accuracy: 80.8873%, Training Loss: 0.5037%\n",
      "Epoch [29/300], Step [57/225], Training Accuracy: 80.8662%, Training Loss: 0.5029%\n",
      "Epoch [29/300], Step [58/225], Training Accuracy: 80.8459%, Training Loss: 0.5024%\n",
      "Epoch [29/300], Step [59/225], Training Accuracy: 80.8263%, Training Loss: 0.5026%\n",
      "Epoch [29/300], Step [60/225], Training Accuracy: 80.8073%, Training Loss: 0.5012%\n",
      "Epoch [29/300], Step [61/225], Training Accuracy: 80.7121%, Training Loss: 0.5034%\n",
      "Epoch [29/300], Step [62/225], Training Accuracy: 80.6200%, Training Loss: 0.5046%\n",
      "Epoch [29/300], Step [63/225], Training Accuracy: 80.5804%, Training Loss: 0.5060%\n",
      "Epoch [29/300], Step [64/225], Training Accuracy: 80.5664%, Training Loss: 0.5067%\n",
      "Epoch [29/300], Step [65/225], Training Accuracy: 80.6731%, Training Loss: 0.5049%\n",
      "Epoch [29/300], Step [66/225], Training Accuracy: 80.8239%, Training Loss: 0.5039%\n",
      "Epoch [29/300], Step [67/225], Training Accuracy: 80.7836%, Training Loss: 0.5039%\n",
      "Epoch [29/300], Step [68/225], Training Accuracy: 80.8134%, Training Loss: 0.5036%\n",
      "Epoch [29/300], Step [69/225], Training Accuracy: 80.7971%, Training Loss: 0.5038%\n",
      "Epoch [29/300], Step [70/225], Training Accuracy: 80.9152%, Training Loss: 0.5011%\n",
      "Epoch [29/300], Step [71/225], Training Accuracy: 80.9419%, Training Loss: 0.5006%\n",
      "Epoch [29/300], Step [72/225], Training Accuracy: 81.0113%, Training Loss: 0.4998%\n",
      "Epoch [29/300], Step [73/225], Training Accuracy: 80.9503%, Training Loss: 0.5000%\n",
      "Epoch [29/300], Step [74/225], Training Accuracy: 80.9544%, Training Loss: 0.5001%\n",
      "Epoch [29/300], Step [75/225], Training Accuracy: 80.9792%, Training Loss: 0.4985%\n",
      "Epoch [29/300], Step [76/225], Training Accuracy: 81.0033%, Training Loss: 0.4980%\n",
      "Epoch [29/300], Step [77/225], Training Accuracy: 81.0674%, Training Loss: 0.4966%\n",
      "Epoch [29/300], Step [78/225], Training Accuracy: 81.0897%, Training Loss: 0.4959%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/300], Step [79/225], Training Accuracy: 81.0522%, Training Loss: 0.4979%\n",
      "Epoch [29/300], Step [80/225], Training Accuracy: 81.0156%, Training Loss: 0.4984%\n",
      "Epoch [29/300], Step [81/225], Training Accuracy: 81.0764%, Training Loss: 0.4969%\n",
      "Epoch [29/300], Step [82/225], Training Accuracy: 81.0023%, Training Loss: 0.4972%\n",
      "Epoch [29/300], Step [83/225], Training Accuracy: 80.9864%, Training Loss: 0.4968%\n",
      "Epoch [29/300], Step [84/225], Training Accuracy: 80.9896%, Training Loss: 0.4964%\n",
      "Epoch [29/300], Step [85/225], Training Accuracy: 81.0846%, Training Loss: 0.4947%\n",
      "Epoch [29/300], Step [86/225], Training Accuracy: 81.1228%, Training Loss: 0.4949%\n",
      "Epoch [29/300], Step [87/225], Training Accuracy: 81.1422%, Training Loss: 0.4963%\n",
      "Epoch [29/300], Step [88/225], Training Accuracy: 81.0902%, Training Loss: 0.4963%\n",
      "Epoch [29/300], Step [89/225], Training Accuracy: 81.0393%, Training Loss: 0.4972%\n",
      "Epoch [29/300], Step [90/225], Training Accuracy: 81.0069%, Training Loss: 0.4978%\n",
      "Epoch [29/300], Step [91/225], Training Accuracy: 81.0096%, Training Loss: 0.4985%\n",
      "Epoch [29/300], Step [92/225], Training Accuracy: 81.0802%, Training Loss: 0.4973%\n",
      "Epoch [29/300], Step [93/225], Training Accuracy: 81.0484%, Training Loss: 0.4972%\n",
      "Epoch [29/300], Step [94/225], Training Accuracy: 81.1004%, Training Loss: 0.4956%\n",
      "Epoch [29/300], Step [95/225], Training Accuracy: 81.1020%, Training Loss: 0.4955%\n",
      "Epoch [29/300], Step [96/225], Training Accuracy: 81.2012%, Training Loss: 0.4931%\n",
      "Epoch [29/300], Step [97/225], Training Accuracy: 81.2339%, Training Loss: 0.4924%\n",
      "Epoch [29/300], Step [98/225], Training Accuracy: 81.2341%, Training Loss: 0.4922%\n",
      "Epoch [29/300], Step [99/225], Training Accuracy: 81.2184%, Training Loss: 0.4929%\n",
      "Epoch [29/300], Step [100/225], Training Accuracy: 81.2188%, Training Loss: 0.4929%\n",
      "Epoch [29/300], Step [101/225], Training Accuracy: 81.1881%, Training Loss: 0.4933%\n",
      "Epoch [29/300], Step [102/225], Training Accuracy: 81.1428%, Training Loss: 0.4941%\n",
      "Epoch [29/300], Step [103/225], Training Accuracy: 81.0528%, Training Loss: 0.4950%\n",
      "Epoch [29/300], Step [104/225], Training Accuracy: 81.0096%, Training Loss: 0.4956%\n",
      "Epoch [29/300], Step [105/225], Training Accuracy: 80.9673%, Training Loss: 0.4958%\n",
      "Epoch [29/300], Step [106/225], Training Accuracy: 80.8815%, Training Loss: 0.4970%\n",
      "Epoch [29/300], Step [107/225], Training Accuracy: 80.8557%, Training Loss: 0.4968%\n",
      "Epoch [29/300], Step [108/225], Training Accuracy: 80.8738%, Training Loss: 0.4966%\n",
      "Epoch [29/300], Step [109/225], Training Accuracy: 80.8343%, Training Loss: 0.4965%\n",
      "Epoch [29/300], Step [110/225], Training Accuracy: 80.8807%, Training Loss: 0.4961%\n",
      "Epoch [29/300], Step [111/225], Training Accuracy: 80.9122%, Training Loss: 0.4952%\n",
      "Epoch [29/300], Step [112/225], Training Accuracy: 80.9012%, Training Loss: 0.4948%\n",
      "Epoch [29/300], Step [113/225], Training Accuracy: 80.9596%, Training Loss: 0.4938%\n",
      "Epoch [29/300], Step [114/225], Training Accuracy: 80.9348%, Training Loss: 0.4939%\n",
      "Epoch [29/300], Step [115/225], Training Accuracy: 80.9239%, Training Loss: 0.4944%\n",
      "Epoch [29/300], Step [116/225], Training Accuracy: 80.8728%, Training Loss: 0.4954%\n",
      "Epoch [29/300], Step [117/225], Training Accuracy: 80.8494%, Training Loss: 0.4955%\n",
      "Epoch [29/300], Step [118/225], Training Accuracy: 80.8395%, Training Loss: 0.4957%\n",
      "Epoch [29/300], Step [119/225], Training Accuracy: 80.8561%, Training Loss: 0.4958%\n",
      "Epoch [29/300], Step [120/225], Training Accuracy: 80.9245%, Training Loss: 0.4942%\n",
      "Epoch [29/300], Step [121/225], Training Accuracy: 80.9659%, Training Loss: 0.4936%\n",
      "Epoch [29/300], Step [122/225], Training Accuracy: 80.9810%, Training Loss: 0.4927%\n",
      "Epoch [29/300], Step [123/225], Training Accuracy: 80.9832%, Training Loss: 0.4924%\n",
      "Epoch [29/300], Step [124/225], Training Accuracy: 80.9980%, Training Loss: 0.4918%\n",
      "Epoch [29/300], Step [125/225], Training Accuracy: 81.0375%, Training Loss: 0.4907%\n",
      "Epoch [29/300], Step [126/225], Training Accuracy: 81.0888%, Training Loss: 0.4898%\n",
      "Epoch [29/300], Step [127/225], Training Accuracy: 81.1024%, Training Loss: 0.4897%\n",
      "Epoch [29/300], Step [128/225], Training Accuracy: 81.1401%, Training Loss: 0.4895%\n",
      "Epoch [29/300], Step [129/225], Training Accuracy: 81.1289%, Training Loss: 0.4895%\n",
      "Epoch [29/300], Step [130/225], Training Accuracy: 81.0938%, Training Loss: 0.4898%\n",
      "Epoch [29/300], Step [131/225], Training Accuracy: 81.1546%, Training Loss: 0.4886%\n",
      "Epoch [29/300], Step [132/225], Training Accuracy: 81.2027%, Training Loss: 0.4881%\n",
      "Epoch [29/300], Step [133/225], Training Accuracy: 81.2617%, Training Loss: 0.4873%\n",
      "Epoch [29/300], Step [134/225], Training Accuracy: 81.2966%, Training Loss: 0.4865%\n",
      "Epoch [29/300], Step [135/225], Training Accuracy: 81.3426%, Training Loss: 0.4859%\n",
      "Epoch [29/300], Step [136/225], Training Accuracy: 81.3534%, Training Loss: 0.4860%\n",
      "Epoch [29/300], Step [137/225], Training Accuracy: 81.3184%, Training Loss: 0.4855%\n",
      "Epoch [29/300], Step [138/225], Training Accuracy: 81.3293%, Training Loss: 0.4855%\n",
      "Epoch [29/300], Step [139/225], Training Accuracy: 81.3624%, Training Loss: 0.4852%\n",
      "Epoch [29/300], Step [140/225], Training Accuracy: 81.3393%, Training Loss: 0.4855%\n",
      "Epoch [29/300], Step [141/225], Training Accuracy: 81.3387%, Training Loss: 0.4858%\n",
      "Epoch [29/300], Step [142/225], Training Accuracy: 81.3600%, Training Loss: 0.4855%\n",
      "Epoch [29/300], Step [143/225], Training Accuracy: 81.3702%, Training Loss: 0.4854%\n",
      "Epoch [29/300], Step [144/225], Training Accuracy: 81.3585%, Training Loss: 0.4849%\n",
      "Epoch [29/300], Step [145/225], Training Accuracy: 81.3685%, Training Loss: 0.4848%\n",
      "Epoch [29/300], Step [146/225], Training Accuracy: 81.3998%, Training Loss: 0.4838%\n",
      "Epoch [29/300], Step [147/225], Training Accuracy: 81.3776%, Training Loss: 0.4840%\n",
      "Epoch [29/300], Step [148/225], Training Accuracy: 81.3556%, Training Loss: 0.4837%\n",
      "Epoch [29/300], Step [149/225], Training Accuracy: 81.3339%, Training Loss: 0.4839%\n",
      "Epoch [29/300], Step [150/225], Training Accuracy: 81.3854%, Training Loss: 0.4827%\n",
      "Epoch [29/300], Step [151/225], Training Accuracy: 81.4466%, Training Loss: 0.4819%\n",
      "Epoch [29/300], Step [152/225], Training Accuracy: 81.4556%, Training Loss: 0.4812%\n",
      "Epoch [29/300], Step [153/225], Training Accuracy: 81.5155%, Training Loss: 0.4803%\n",
      "Epoch [29/300], Step [154/225], Training Accuracy: 81.5239%, Training Loss: 0.4801%\n",
      "Epoch [29/300], Step [155/225], Training Accuracy: 81.5827%, Training Loss: 0.4798%\n",
      "Epoch [29/300], Step [156/225], Training Accuracy: 81.5805%, Training Loss: 0.4794%\n",
      "Epoch [29/300], Step [157/225], Training Accuracy: 81.5983%, Training Loss: 0.4789%\n",
      "Epoch [29/300], Step [158/225], Training Accuracy: 81.6258%, Training Loss: 0.4782%\n",
      "Epoch [29/300], Step [159/225], Training Accuracy: 81.6627%, Training Loss: 0.4776%\n",
      "Epoch [29/300], Step [160/225], Training Accuracy: 81.6895%, Training Loss: 0.4774%\n",
      "Epoch [29/300], Step [161/225], Training Accuracy: 81.7644%, Training Loss: 0.4761%\n",
      "Epoch [29/300], Step [162/225], Training Accuracy: 81.8094%, Training Loss: 0.4750%\n",
      "Epoch [29/300], Step [163/225], Training Accuracy: 81.8156%, Training Loss: 0.4746%\n",
      "Epoch [29/300], Step [164/225], Training Accuracy: 81.8121%, Training Loss: 0.4743%\n",
      "Epoch [29/300], Step [165/225], Training Accuracy: 81.8087%, Training Loss: 0.4745%\n",
      "Epoch [29/300], Step [166/225], Training Accuracy: 81.7959%, Training Loss: 0.4747%\n",
      "Epoch [29/300], Step [167/225], Training Accuracy: 81.8207%, Training Loss: 0.4749%\n",
      "Epoch [29/300], Step [168/225], Training Accuracy: 81.7987%, Training Loss: 0.4746%\n",
      "Epoch [29/300], Step [169/225], Training Accuracy: 81.7308%, Training Loss: 0.4759%\n",
      "Epoch [29/300], Step [170/225], Training Accuracy: 81.7188%, Training Loss: 0.4762%\n",
      "Epoch [29/300], Step [171/225], Training Accuracy: 81.7160%, Training Loss: 0.4763%\n",
      "Epoch [29/300], Step [172/225], Training Accuracy: 81.7224%, Training Loss: 0.4758%\n",
      "Epoch [29/300], Step [173/225], Training Accuracy: 81.7197%, Training Loss: 0.4759%\n",
      "Epoch [29/300], Step [174/225], Training Accuracy: 81.7259%, Training Loss: 0.4756%\n",
      "Epoch [29/300], Step [175/225], Training Accuracy: 81.7679%, Training Loss: 0.4746%\n",
      "Epoch [29/300], Step [176/225], Training Accuracy: 81.7560%, Training Loss: 0.4753%\n",
      "Epoch [29/300], Step [177/225], Training Accuracy: 81.7973%, Training Loss: 0.4747%\n",
      "Epoch [29/300], Step [178/225], Training Accuracy: 81.7942%, Training Loss: 0.4749%\n",
      "Epoch [29/300], Step [179/225], Training Accuracy: 81.7825%, Training Loss: 0.4752%\n",
      "Epoch [29/300], Step [180/225], Training Accuracy: 81.7535%, Training Loss: 0.4753%\n",
      "Epoch [29/300], Step [181/225], Training Accuracy: 81.7421%, Training Loss: 0.4755%\n",
      "Epoch [29/300], Step [182/225], Training Accuracy: 81.7308%, Training Loss: 0.4753%\n",
      "Epoch [29/300], Step [183/225], Training Accuracy: 81.7794%, Training Loss: 0.4741%\n",
      "Epoch [29/300], Step [184/225], Training Accuracy: 81.8020%, Training Loss: 0.4737%\n",
      "Epoch [29/300], Step [185/225], Training Accuracy: 81.8243%, Training Loss: 0.4733%\n",
      "Epoch [29/300], Step [186/225], Training Accuracy: 81.8632%, Training Loss: 0.4726%\n",
      "Epoch [29/300], Step [187/225], Training Accuracy: 81.8683%, Training Loss: 0.4721%\n",
      "Epoch [29/300], Step [188/225], Training Accuracy: 81.8900%, Training Loss: 0.4715%\n",
      "Epoch [29/300], Step [189/225], Training Accuracy: 81.9279%, Training Loss: 0.4706%\n",
      "Epoch [29/300], Step [190/225], Training Accuracy: 81.9161%, Training Loss: 0.4709%\n",
      "Epoch [29/300], Step [191/225], Training Accuracy: 81.9454%, Training Loss: 0.4700%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/300], Step [192/225], Training Accuracy: 81.9336%, Training Loss: 0.4704%\n",
      "Epoch [29/300], Step [193/225], Training Accuracy: 81.9139%, Training Loss: 0.4706%\n",
      "Epoch [29/300], Step [194/225], Training Accuracy: 81.9507%, Training Loss: 0.4695%\n",
      "Epoch [29/300], Step [195/225], Training Accuracy: 81.9471%, Training Loss: 0.4694%\n",
      "Epoch [29/300], Step [196/225], Training Accuracy: 81.9515%, Training Loss: 0.4695%\n",
      "Epoch [29/300], Step [197/225], Training Accuracy: 81.9162%, Training Loss: 0.4704%\n",
      "Epoch [29/300], Step [198/225], Training Accuracy: 81.8971%, Training Loss: 0.4707%\n",
      "Epoch [29/300], Step [199/225], Training Accuracy: 81.8546%, Training Loss: 0.4709%\n",
      "Epoch [29/300], Step [200/225], Training Accuracy: 81.8672%, Training Loss: 0.4705%\n",
      "Epoch [29/300], Step [201/225], Training Accuracy: 81.8563%, Training Loss: 0.4704%\n",
      "Epoch [29/300], Step [202/225], Training Accuracy: 81.8147%, Training Loss: 0.4712%\n",
      "Epoch [29/300], Step [203/225], Training Accuracy: 81.8196%, Training Loss: 0.4709%\n",
      "Epoch [29/300], Step [204/225], Training Accuracy: 81.7862%, Training Loss: 0.4710%\n",
      "Epoch [29/300], Step [205/225], Training Accuracy: 81.7912%, Training Loss: 0.4711%\n",
      "Epoch [29/300], Step [206/225], Training Accuracy: 81.7734%, Training Loss: 0.4710%\n",
      "Epoch [29/300], Step [207/225], Training Accuracy: 81.7935%, Training Loss: 0.4706%\n",
      "Epoch [29/300], Step [208/225], Training Accuracy: 81.7758%, Training Loss: 0.4709%\n",
      "Epoch [29/300], Step [209/225], Training Accuracy: 81.7584%, Training Loss: 0.4715%\n",
      "Epoch [29/300], Step [210/225], Training Accuracy: 81.7411%, Training Loss: 0.4715%\n",
      "Epoch [29/300], Step [211/225], Training Accuracy: 81.7239%, Training Loss: 0.4715%\n",
      "Epoch [29/300], Step [212/225], Training Accuracy: 81.7291%, Training Loss: 0.4720%\n",
      "Epoch [29/300], Step [213/225], Training Accuracy: 81.7268%, Training Loss: 0.4719%\n",
      "Epoch [29/300], Step [214/225], Training Accuracy: 81.7538%, Training Loss: 0.4715%\n",
      "Epoch [29/300], Step [215/225], Training Accuracy: 81.7878%, Training Loss: 0.4710%\n",
      "Epoch [29/300], Step [216/225], Training Accuracy: 81.7636%, Training Loss: 0.4715%\n",
      "Epoch [29/300], Step [217/225], Training Accuracy: 81.7540%, Training Loss: 0.4714%\n",
      "Epoch [29/300], Step [218/225], Training Accuracy: 81.7159%, Training Loss: 0.4723%\n",
      "Epoch [29/300], Step [219/225], Training Accuracy: 81.6924%, Training Loss: 0.4725%\n",
      "Epoch [29/300], Step [220/225], Training Accuracy: 81.6974%, Training Loss: 0.4722%\n",
      "Epoch [29/300], Step [221/225], Training Accuracy: 81.6742%, Training Loss: 0.4724%\n",
      "Epoch [29/300], Step [222/225], Training Accuracy: 81.6723%, Training Loss: 0.4728%\n",
      "Epoch [29/300], Step [223/225], Training Accuracy: 81.6914%, Training Loss: 0.4724%\n",
      "Epoch [29/300], Step [224/225], Training Accuracy: 81.7174%, Training Loss: 0.4721%\n",
      "Epoch [29/300], Step [225/225], Training Accuracy: 81.7190%, Training Loss: 0.4722%\n",
      "Epoch [30/300], Step [1/225], Training Accuracy: 81.2500%, Training Loss: 0.5407%\n",
      "Epoch [30/300], Step [2/225], Training Accuracy: 84.3750%, Training Loss: 0.4983%\n",
      "Epoch [30/300], Step [3/225], Training Accuracy: 82.8125%, Training Loss: 0.5108%\n",
      "Epoch [30/300], Step [4/225], Training Accuracy: 84.3750%, Training Loss: 0.4711%\n",
      "Epoch [30/300], Step [5/225], Training Accuracy: 85.9375%, Training Loss: 0.4392%\n",
      "Epoch [30/300], Step [6/225], Training Accuracy: 84.1146%, Training Loss: 0.4677%\n",
      "Epoch [30/300], Step [7/225], Training Accuracy: 83.0357%, Training Loss: 0.4868%\n",
      "Epoch [30/300], Step [8/225], Training Accuracy: 82.4219%, Training Loss: 0.4843%\n",
      "Epoch [30/300], Step [9/225], Training Accuracy: 82.4653%, Training Loss: 0.4795%\n",
      "Epoch [30/300], Step [10/225], Training Accuracy: 82.6562%, Training Loss: 0.4757%\n",
      "Epoch [30/300], Step [11/225], Training Accuracy: 83.2386%, Training Loss: 0.4648%\n",
      "Epoch [30/300], Step [12/225], Training Accuracy: 83.3333%, Training Loss: 0.4619%\n",
      "Epoch [30/300], Step [13/225], Training Accuracy: 83.8942%, Training Loss: 0.4501%\n",
      "Epoch [30/300], Step [14/225], Training Accuracy: 83.5938%, Training Loss: 0.4512%\n",
      "Epoch [30/300], Step [15/225], Training Accuracy: 83.8542%, Training Loss: 0.4439%\n",
      "Epoch [30/300], Step [16/225], Training Accuracy: 82.9102%, Training Loss: 0.4619%\n",
      "Epoch [30/300], Step [17/225], Training Accuracy: 82.9963%, Training Loss: 0.4664%\n",
      "Epoch [30/300], Step [18/225], Training Accuracy: 82.8993%, Training Loss: 0.4674%\n",
      "Epoch [30/300], Step [19/225], Training Accuracy: 82.9770%, Training Loss: 0.4603%\n",
      "Epoch [30/300], Step [20/225], Training Accuracy: 83.2031%, Training Loss: 0.4567%\n",
      "Epoch [30/300], Step [21/225], Training Accuracy: 83.3333%, Training Loss: 0.4530%\n",
      "Epoch [30/300], Step [22/225], Training Accuracy: 83.1676%, Training Loss: 0.4562%\n",
      "Epoch [30/300], Step [23/225], Training Accuracy: 83.2880%, Training Loss: 0.4550%\n",
      "Epoch [30/300], Step [24/225], Training Accuracy: 83.0078%, Training Loss: 0.4595%\n",
      "Epoch [30/300], Step [25/225], Training Accuracy: 83.1875%, Training Loss: 0.4548%\n",
      "Epoch [30/300], Step [26/225], Training Accuracy: 82.8726%, Training Loss: 0.4596%\n",
      "Epoch [30/300], Step [27/225], Training Accuracy: 82.9282%, Training Loss: 0.4589%\n",
      "Epoch [30/300], Step [28/225], Training Accuracy: 83.3705%, Training Loss: 0.4517%\n",
      "Epoch [30/300], Step [29/225], Training Accuracy: 83.4052%, Training Loss: 0.4509%\n",
      "Epoch [30/300], Step [30/225], Training Accuracy: 83.3854%, Training Loss: 0.4516%\n",
      "Epoch [30/300], Step [31/225], Training Accuracy: 83.3165%, Training Loss: 0.4529%\n",
      "Epoch [30/300], Step [32/225], Training Accuracy: 83.3008%, Training Loss: 0.4509%\n",
      "Epoch [30/300], Step [33/225], Training Accuracy: 83.4280%, Training Loss: 0.4480%\n",
      "Epoch [30/300], Step [34/225], Training Accuracy: 83.5018%, Training Loss: 0.4476%\n",
      "Epoch [30/300], Step [35/225], Training Accuracy: 83.2589%, Training Loss: 0.4504%\n",
      "Epoch [30/300], Step [36/225], Training Accuracy: 83.1163%, Training Loss: 0.4521%\n",
      "Epoch [30/300], Step [37/225], Training Accuracy: 82.8970%, Training Loss: 0.4558%\n",
      "Epoch [30/300], Step [38/225], Training Accuracy: 83.0181%, Training Loss: 0.4543%\n",
      "Epoch [30/300], Step [39/225], Training Accuracy: 83.1330%, Training Loss: 0.4533%\n",
      "Epoch [30/300], Step [40/225], Training Accuracy: 83.1641%, Training Loss: 0.4521%\n",
      "Epoch [30/300], Step [41/225], Training Accuracy: 83.1936%, Training Loss: 0.4517%\n",
      "Epoch [30/300], Step [42/225], Training Accuracy: 83.1473%, Training Loss: 0.4516%\n",
      "Epoch [30/300], Step [43/225], Training Accuracy: 83.0305%, Training Loss: 0.4544%\n",
      "Epoch [30/300], Step [44/225], Training Accuracy: 83.0611%, Training Loss: 0.4527%\n",
      "Epoch [30/300], Step [45/225], Training Accuracy: 83.1944%, Training Loss: 0.4513%\n",
      "Epoch [30/300], Step [46/225], Training Accuracy: 83.3899%, Training Loss: 0.4482%\n",
      "Epoch [30/300], Step [47/225], Training Accuracy: 83.3777%, Training Loss: 0.4473%\n",
      "Epoch [30/300], Step [48/225], Training Accuracy: 83.3659%, Training Loss: 0.4474%\n",
      "Epoch [30/300], Step [49/225], Training Accuracy: 83.1633%, Training Loss: 0.4509%\n",
      "Epoch [30/300], Step [50/225], Training Accuracy: 83.1562%, Training Loss: 0.4513%\n",
      "Epoch [30/300], Step [51/225], Training Accuracy: 83.2414%, Training Loss: 0.4491%\n",
      "Epoch [30/300], Step [52/225], Training Accuracy: 83.3534%, Training Loss: 0.4467%\n",
      "Epoch [30/300], Step [53/225], Training Accuracy: 83.2252%, Training Loss: 0.4489%\n",
      "Epoch [30/300], Step [54/225], Training Accuracy: 83.0440%, Training Loss: 0.4513%\n",
      "Epoch [30/300], Step [55/225], Training Accuracy: 83.0682%, Training Loss: 0.4494%\n",
      "Epoch [30/300], Step [56/225], Training Accuracy: 83.0636%, Training Loss: 0.4499%\n",
      "Epoch [30/300], Step [57/225], Training Accuracy: 82.9496%, Training Loss: 0.4522%\n",
      "Epoch [30/300], Step [58/225], Training Accuracy: 82.8933%, Training Loss: 0.4541%\n",
      "Epoch [30/300], Step [59/225], Training Accuracy: 82.7331%, Training Loss: 0.4561%\n",
      "Epoch [30/300], Step [60/225], Training Accuracy: 82.8385%, Training Loss: 0.4549%\n",
      "Epoch [30/300], Step [61/225], Training Accuracy: 82.7869%, Training Loss: 0.4560%\n",
      "Epoch [30/300], Step [62/225], Training Accuracy: 82.7369%, Training Loss: 0.4579%\n",
      "Epoch [30/300], Step [63/225], Training Accuracy: 82.6885%, Training Loss: 0.4598%\n",
      "Epoch [30/300], Step [64/225], Training Accuracy: 82.6172%, Training Loss: 0.4598%\n",
      "Epoch [30/300], Step [65/225], Training Accuracy: 82.6442%, Training Loss: 0.4578%\n",
      "Epoch [30/300], Step [66/225], Training Accuracy: 82.6705%, Training Loss: 0.4577%\n",
      "Epoch [30/300], Step [67/225], Training Accuracy: 82.6259%, Training Loss: 0.4583%\n",
      "Epoch [30/300], Step [68/225], Training Accuracy: 82.5827%, Training Loss: 0.4582%\n",
      "Epoch [30/300], Step [69/225], Training Accuracy: 82.6087%, Training Loss: 0.4579%\n",
      "Epoch [30/300], Step [70/225], Training Accuracy: 82.5670%, Training Loss: 0.4585%\n",
      "Epoch [30/300], Step [71/225], Training Accuracy: 82.5484%, Training Loss: 0.4579%\n",
      "Epoch [30/300], Step [72/225], Training Accuracy: 82.6606%, Training Loss: 0.4572%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/300], Step [73/225], Training Accuracy: 82.6627%, Training Loss: 0.4584%\n",
      "Epoch [30/300], Step [74/225], Training Accuracy: 82.6436%, Training Loss: 0.4593%\n",
      "Epoch [30/300], Step [75/225], Training Accuracy: 82.7083%, Training Loss: 0.4581%\n",
      "Epoch [30/300], Step [76/225], Training Accuracy: 82.6480%, Training Loss: 0.4583%\n",
      "Epoch [30/300], Step [77/225], Training Accuracy: 82.6705%, Training Loss: 0.4575%\n",
      "Epoch [30/300], Step [78/225], Training Accuracy: 82.6723%, Training Loss: 0.4569%\n",
      "Epoch [30/300], Step [79/225], Training Accuracy: 82.6543%, Training Loss: 0.4576%\n",
      "Epoch [30/300], Step [80/225], Training Accuracy: 82.7148%, Training Loss: 0.4568%\n",
      "Epoch [30/300], Step [81/225], Training Accuracy: 82.7160%, Training Loss: 0.4571%\n",
      "Epoch [30/300], Step [82/225], Training Accuracy: 82.6791%, Training Loss: 0.4577%\n",
      "Epoch [30/300], Step [83/225], Training Accuracy: 82.6431%, Training Loss: 0.4576%\n",
      "Epoch [30/300], Step [84/225], Training Accuracy: 82.6451%, Training Loss: 0.4580%\n",
      "Epoch [30/300], Step [85/225], Training Accuracy: 82.6654%, Training Loss: 0.4575%\n",
      "Epoch [30/300], Step [86/225], Training Accuracy: 82.6672%, Training Loss: 0.4574%\n",
      "Epoch [30/300], Step [87/225], Training Accuracy: 82.5072%, Training Loss: 0.4601%\n",
      "Epoch [30/300], Step [88/225], Training Accuracy: 82.4396%, Training Loss: 0.4605%\n",
      "Epoch [30/300], Step [89/225], Training Accuracy: 82.4789%, Training Loss: 0.4595%\n",
      "Epoch [30/300], Step [90/225], Training Accuracy: 82.4653%, Training Loss: 0.4592%\n",
      "Epoch [30/300], Step [91/225], Training Accuracy: 82.4863%, Training Loss: 0.4587%\n",
      "Epoch [30/300], Step [92/225], Training Accuracy: 82.4389%, Training Loss: 0.4596%\n",
      "Epoch [30/300], Step [93/225], Training Accuracy: 82.4093%, Training Loss: 0.4600%\n",
      "Epoch [30/300], Step [94/225], Training Accuracy: 82.4136%, Training Loss: 0.4603%\n",
      "Epoch [30/300], Step [95/225], Training Accuracy: 82.3355%, Training Loss: 0.4612%\n",
      "Epoch [30/300], Step [96/225], Training Accuracy: 82.3730%, Training Loss: 0.4601%\n",
      "Epoch [30/300], Step [97/225], Training Accuracy: 82.3293%, Training Loss: 0.4603%\n",
      "Epoch [30/300], Step [98/225], Training Accuracy: 82.2864%, Training Loss: 0.4601%\n",
      "Epoch [30/300], Step [99/225], Training Accuracy: 82.2285%, Training Loss: 0.4602%\n",
      "Epoch [30/300], Step [100/225], Training Accuracy: 82.1562%, Training Loss: 0.4605%\n",
      "Epoch [30/300], Step [101/225], Training Accuracy: 82.1473%, Training Loss: 0.4612%\n",
      "Epoch [30/300], Step [102/225], Training Accuracy: 81.9547%, Training Loss: 0.4631%\n",
      "Epoch [30/300], Step [103/225], Training Accuracy: 81.9175%, Training Loss: 0.4642%\n",
      "Epoch [30/300], Step [104/225], Training Accuracy: 81.9411%, Training Loss: 0.4643%\n",
      "Epoch [30/300], Step [105/225], Training Accuracy: 81.9345%, Training Loss: 0.4640%\n",
      "Epoch [30/300], Step [106/225], Training Accuracy: 81.8396%, Training Loss: 0.4653%\n",
      "Epoch [30/300], Step [107/225], Training Accuracy: 81.7903%, Training Loss: 0.4661%\n",
      "Epoch [30/300], Step [108/225], Training Accuracy: 81.8142%, Training Loss: 0.4659%\n",
      "Epoch [30/300], Step [109/225], Training Accuracy: 81.7804%, Training Loss: 0.4665%\n",
      "Epoch [30/300], Step [110/225], Training Accuracy: 81.8608%, Training Loss: 0.4656%\n",
      "Epoch [30/300], Step [111/225], Training Accuracy: 81.8131%, Training Loss: 0.4659%\n",
      "Epoch [30/300], Step [112/225], Training Accuracy: 81.7801%, Training Loss: 0.4664%\n",
      "Epoch [30/300], Step [113/225], Training Accuracy: 81.8308%, Training Loss: 0.4657%\n",
      "Epoch [30/300], Step [114/225], Training Accuracy: 81.8531%, Training Loss: 0.4650%\n",
      "Epoch [30/300], Step [115/225], Training Accuracy: 81.7799%, Training Loss: 0.4654%\n",
      "Epoch [30/300], Step [116/225], Training Accuracy: 81.7753%, Training Loss: 0.4651%\n",
      "Epoch [30/300], Step [117/225], Training Accuracy: 81.7575%, Training Loss: 0.4660%\n",
      "Epoch [30/300], Step [118/225], Training Accuracy: 81.6870%, Training Loss: 0.4680%\n",
      "Epoch [30/300], Step [119/225], Training Accuracy: 81.6702%, Training Loss: 0.4685%\n",
      "Epoch [30/300], Step [120/225], Training Accuracy: 81.7578%, Training Loss: 0.4678%\n",
      "Epoch [30/300], Step [121/225], Training Accuracy: 81.7924%, Training Loss: 0.4673%\n",
      "Epoch [30/300], Step [122/225], Training Accuracy: 81.8648%, Training Loss: 0.4661%\n",
      "Epoch [30/300], Step [123/225], Training Accuracy: 81.8343%, Training Loss: 0.4664%\n",
      "Epoch [30/300], Step [124/225], Training Accuracy: 81.7792%, Training Loss: 0.4670%\n",
      "Epoch [30/300], Step [125/225], Training Accuracy: 81.7750%, Training Loss: 0.4672%\n",
      "Epoch [30/300], Step [126/225], Training Accuracy: 81.8328%, Training Loss: 0.4667%\n",
      "Epoch [30/300], Step [127/225], Training Accuracy: 81.8406%, Training Loss: 0.4668%\n",
      "Epoch [30/300], Step [128/225], Training Accuracy: 81.7993%, Training Loss: 0.4687%\n",
      "Epoch [30/300], Step [129/225], Training Accuracy: 81.7708%, Training Loss: 0.4684%\n",
      "Epoch [30/300], Step [130/225], Training Accuracy: 81.7308%, Training Loss: 0.4687%\n",
      "Epoch [30/300], Step [131/225], Training Accuracy: 81.7748%, Training Loss: 0.4675%\n",
      "Epoch [30/300], Step [132/225], Training Accuracy: 81.7827%, Training Loss: 0.4681%\n",
      "Epoch [30/300], Step [133/225], Training Accuracy: 81.8257%, Training Loss: 0.4676%\n",
      "Epoch [30/300], Step [134/225], Training Accuracy: 81.8214%, Training Loss: 0.4685%\n",
      "Epoch [30/300], Step [135/225], Training Accuracy: 81.8171%, Training Loss: 0.4675%\n",
      "Epoch [30/300], Step [136/225], Training Accuracy: 81.8130%, Training Loss: 0.4682%\n",
      "Epoch [30/300], Step [137/225], Training Accuracy: 81.8203%, Training Loss: 0.4677%\n",
      "Epoch [30/300], Step [138/225], Training Accuracy: 81.8501%, Training Loss: 0.4671%\n",
      "Epoch [30/300], Step [139/225], Training Accuracy: 81.8907%, Training Loss: 0.4665%\n",
      "Epoch [30/300], Step [140/225], Training Accuracy: 81.8415%, Training Loss: 0.4676%\n",
      "Epoch [30/300], Step [141/225], Training Accuracy: 81.8595%, Training Loss: 0.4674%\n",
      "Epoch [30/300], Step [142/225], Training Accuracy: 81.8552%, Training Loss: 0.4672%\n",
      "Epoch [30/300], Step [143/225], Training Accuracy: 81.7635%, Training Loss: 0.4684%\n",
      "Epoch [30/300], Step [144/225], Training Accuracy: 81.7708%, Training Loss: 0.4678%\n",
      "Epoch [30/300], Step [145/225], Training Accuracy: 81.8211%, Training Loss: 0.4673%\n",
      "Epoch [30/300], Step [146/225], Training Accuracy: 81.8493%, Training Loss: 0.4666%\n",
      "Epoch [30/300], Step [147/225], Training Accuracy: 81.8134%, Training Loss: 0.4670%\n",
      "Epoch [30/300], Step [148/225], Training Accuracy: 81.8623%, Training Loss: 0.4662%\n",
      "Epoch [30/300], Step [149/225], Training Accuracy: 81.8268%, Training Loss: 0.4667%\n",
      "Epoch [30/300], Step [150/225], Training Accuracy: 81.8333%, Training Loss: 0.4660%\n",
      "Epoch [30/300], Step [151/225], Training Accuracy: 81.8605%, Training Loss: 0.4655%\n",
      "Epoch [30/300], Step [152/225], Training Accuracy: 81.8976%, Training Loss: 0.4647%\n",
      "Epoch [30/300], Step [153/225], Training Accuracy: 81.9240%, Training Loss: 0.4642%\n",
      "Epoch [30/300], Step [154/225], Training Accuracy: 81.8892%, Training Loss: 0.4655%\n",
      "Epoch [30/300], Step [155/225], Training Accuracy: 81.8851%, Training Loss: 0.4654%\n",
      "Epoch [30/300], Step [156/225], Training Accuracy: 81.9411%, Training Loss: 0.4646%\n",
      "Epoch [30/300], Step [157/225], Training Accuracy: 81.9666%, Training Loss: 0.4646%\n",
      "Epoch [30/300], Step [158/225], Training Accuracy: 82.0115%, Training Loss: 0.4634%\n",
      "Epoch [30/300], Step [159/225], Training Accuracy: 82.0067%, Training Loss: 0.4631%\n",
      "Epoch [30/300], Step [160/225], Training Accuracy: 82.0020%, Training Loss: 0.4629%\n",
      "Epoch [30/300], Step [161/225], Training Accuracy: 82.0361%, Training Loss: 0.4619%\n",
      "Epoch [30/300], Step [162/225], Training Accuracy: 82.0602%, Training Loss: 0.4613%\n",
      "Epoch [30/300], Step [163/225], Training Accuracy: 82.0456%, Training Loss: 0.4610%\n",
      "Epoch [30/300], Step [164/225], Training Accuracy: 82.0694%, Training Loss: 0.4608%\n",
      "Epoch [30/300], Step [165/225], Training Accuracy: 82.1212%, Training Loss: 0.4604%\n",
      "Epoch [30/300], Step [166/225], Training Accuracy: 82.1066%, Training Loss: 0.4606%\n",
      "Epoch [30/300], Step [167/225], Training Accuracy: 82.1108%, Training Loss: 0.4605%\n",
      "Epoch [30/300], Step [168/225], Training Accuracy: 82.1429%, Training Loss: 0.4600%\n",
      "Epoch [30/300], Step [169/225], Training Accuracy: 82.1098%, Training Loss: 0.4601%\n",
      "Epoch [30/300], Step [170/225], Training Accuracy: 82.0680%, Training Loss: 0.4604%\n",
      "Epoch [30/300], Step [171/225], Training Accuracy: 82.0632%, Training Loss: 0.4600%\n",
      "Epoch [30/300], Step [172/225], Training Accuracy: 82.0676%, Training Loss: 0.4597%\n",
      "Epoch [30/300], Step [173/225], Training Accuracy: 82.0809%, Training Loss: 0.4595%\n",
      "Epoch [30/300], Step [174/225], Training Accuracy: 82.0941%, Training Loss: 0.4592%\n",
      "Epoch [30/300], Step [175/225], Training Accuracy: 82.0714%, Training Loss: 0.4590%\n",
      "Epoch [30/300], Step [176/225], Training Accuracy: 82.0668%, Training Loss: 0.4593%\n",
      "Epoch [30/300], Step [177/225], Training Accuracy: 82.1239%, Training Loss: 0.4585%\n",
      "Epoch [30/300], Step [178/225], Training Accuracy: 82.1103%, Training Loss: 0.4592%\n",
      "Epoch [30/300], Step [179/225], Training Accuracy: 82.1054%, Training Loss: 0.4590%\n",
      "Epoch [30/300], Step [180/225], Training Accuracy: 82.1267%, Training Loss: 0.4592%\n",
      "Epoch [30/300], Step [181/225], Training Accuracy: 82.1219%, Training Loss: 0.4595%\n",
      "Epoch [30/300], Step [182/225], Training Accuracy: 82.1257%, Training Loss: 0.4592%\n",
      "Epoch [30/300], Step [183/225], Training Accuracy: 82.1551%, Training Loss: 0.4581%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/300], Step [184/225], Training Accuracy: 82.1162%, Training Loss: 0.4588%\n",
      "Epoch [30/300], Step [185/225], Training Accuracy: 82.1199%, Training Loss: 0.4584%\n",
      "Epoch [30/300], Step [186/225], Training Accuracy: 82.1741%, Training Loss: 0.4574%\n",
      "Epoch [30/300], Step [187/225], Training Accuracy: 82.1691%, Training Loss: 0.4571%\n",
      "Epoch [30/300], Step [188/225], Training Accuracy: 82.1642%, Training Loss: 0.4571%\n",
      "Epoch [30/300], Step [189/225], Training Accuracy: 82.2007%, Training Loss: 0.4564%\n",
      "Epoch [30/300], Step [190/225], Training Accuracy: 82.1793%, Training Loss: 0.4564%\n",
      "Epoch [30/300], Step [191/225], Training Accuracy: 82.2235%, Training Loss: 0.4555%\n",
      "Epoch [30/300], Step [192/225], Training Accuracy: 82.2184%, Training Loss: 0.4557%\n",
      "Epoch [30/300], Step [193/225], Training Accuracy: 82.1972%, Training Loss: 0.4565%\n",
      "Epoch [30/300], Step [194/225], Training Accuracy: 82.2326%, Training Loss: 0.4558%\n",
      "Epoch [30/300], Step [195/225], Training Accuracy: 82.2115%, Training Loss: 0.4558%\n",
      "Epoch [30/300], Step [196/225], Training Accuracy: 82.2385%, Training Loss: 0.4555%\n",
      "Epoch [30/300], Step [197/225], Training Accuracy: 82.2176%, Training Loss: 0.4560%\n",
      "Epoch [30/300], Step [198/225], Training Accuracy: 82.2206%, Training Loss: 0.4561%\n",
      "Epoch [30/300], Step [199/225], Training Accuracy: 82.1765%, Training Loss: 0.4571%\n",
      "Epoch [30/300], Step [200/225], Training Accuracy: 82.2109%, Training Loss: 0.4562%\n",
      "Epoch [30/300], Step [201/225], Training Accuracy: 82.2139%, Training Loss: 0.4558%\n",
      "Epoch [30/300], Step [202/225], Training Accuracy: 82.1860%, Training Loss: 0.4567%\n",
      "Epoch [30/300], Step [203/225], Training Accuracy: 82.2044%, Training Loss: 0.4566%\n",
      "Epoch [30/300], Step [204/225], Training Accuracy: 82.2074%, Training Loss: 0.4564%\n",
      "Epoch [30/300], Step [205/225], Training Accuracy: 82.2027%, Training Loss: 0.4564%\n",
      "Epoch [30/300], Step [206/225], Training Accuracy: 82.2133%, Training Loss: 0.4562%\n",
      "Epoch [30/300], Step [207/225], Training Accuracy: 82.2464%, Training Loss: 0.4555%\n",
      "Epoch [30/300], Step [208/225], Training Accuracy: 82.2341%, Training Loss: 0.4557%\n",
      "Epoch [30/300], Step [209/225], Training Accuracy: 82.1995%, Training Loss: 0.4563%\n",
      "Epoch [30/300], Step [210/225], Training Accuracy: 82.2247%, Training Loss: 0.4564%\n",
      "Epoch [30/300], Step [211/225], Training Accuracy: 82.2127%, Training Loss: 0.4566%\n",
      "Epoch [30/300], Step [212/225], Training Accuracy: 82.2155%, Training Loss: 0.4566%\n",
      "Epoch [30/300], Step [213/225], Training Accuracy: 82.2036%, Training Loss: 0.4566%\n",
      "Epoch [30/300], Step [214/225], Training Accuracy: 82.1992%, Training Loss: 0.4567%\n",
      "Epoch [30/300], Step [215/225], Training Accuracy: 82.2238%, Training Loss: 0.4563%\n",
      "Epoch [30/300], Step [216/225], Training Accuracy: 82.2049%, Training Loss: 0.4566%\n",
      "Epoch [30/300], Step [217/225], Training Accuracy: 82.2293%, Training Loss: 0.4559%\n",
      "Epoch [30/300], Step [218/225], Training Accuracy: 82.2033%, Training Loss: 0.4564%\n",
      "Epoch [30/300], Step [219/225], Training Accuracy: 82.2061%, Training Loss: 0.4562%\n",
      "Epoch [30/300], Step [220/225], Training Accuracy: 82.2372%, Training Loss: 0.4557%\n",
      "Epoch [30/300], Step [221/225], Training Accuracy: 82.2257%, Training Loss: 0.4561%\n",
      "Epoch [30/300], Step [222/225], Training Accuracy: 82.2072%, Training Loss: 0.4562%\n",
      "Epoch [30/300], Step [223/225], Training Accuracy: 82.1959%, Training Loss: 0.4561%\n",
      "Epoch [30/300], Step [224/225], Training Accuracy: 82.2056%, Training Loss: 0.4558%\n",
      "Epoch [30/300], Step [225/225], Training Accuracy: 82.2123%, Training Loss: 0.4558%\n",
      "Epoch [31/300], Step [1/225], Training Accuracy: 81.2500%, Training Loss: 0.5105%\n",
      "Epoch [31/300], Step [2/225], Training Accuracy: 82.8125%, Training Loss: 0.4570%\n",
      "Epoch [31/300], Step [3/225], Training Accuracy: 79.6875%, Training Loss: 0.4966%\n",
      "Epoch [31/300], Step [4/225], Training Accuracy: 80.8594%, Training Loss: 0.4535%\n",
      "Epoch [31/300], Step [5/225], Training Accuracy: 80.6250%, Training Loss: 0.4625%\n",
      "Epoch [31/300], Step [6/225], Training Accuracy: 81.5104%, Training Loss: 0.4682%\n",
      "Epoch [31/300], Step [7/225], Training Accuracy: 80.1339%, Training Loss: 0.4915%\n",
      "Epoch [31/300], Step [8/225], Training Accuracy: 80.8594%, Training Loss: 0.4767%\n",
      "Epoch [31/300], Step [9/225], Training Accuracy: 80.7292%, Training Loss: 0.4860%\n",
      "Epoch [31/300], Step [10/225], Training Accuracy: 80.4688%, Training Loss: 0.4954%\n",
      "Epoch [31/300], Step [11/225], Training Accuracy: 80.5398%, Training Loss: 0.4909%\n",
      "Epoch [31/300], Step [12/225], Training Accuracy: 81.1198%, Training Loss: 0.4867%\n",
      "Epoch [31/300], Step [13/225], Training Accuracy: 81.3702%, Training Loss: 0.4772%\n",
      "Epoch [31/300], Step [14/225], Training Accuracy: 80.5804%, Training Loss: 0.4926%\n",
      "Epoch [31/300], Step [15/225], Training Accuracy: 80.9375%, Training Loss: 0.4840%\n",
      "Epoch [31/300], Step [16/225], Training Accuracy: 80.4688%, Training Loss: 0.4903%\n",
      "Epoch [31/300], Step [17/225], Training Accuracy: 80.2390%, Training Loss: 0.4976%\n",
      "Epoch [31/300], Step [18/225], Training Accuracy: 79.8611%, Training Loss: 0.5044%\n",
      "Epoch [31/300], Step [19/225], Training Accuracy: 80.2632%, Training Loss: 0.4956%\n",
      "Epoch [31/300], Step [20/225], Training Accuracy: 80.7812%, Training Loss: 0.4866%\n",
      "Epoch [31/300], Step [21/225], Training Accuracy: 81.0268%, Training Loss: 0.4785%\n",
      "Epoch [31/300], Step [22/225], Training Accuracy: 80.7528%, Training Loss: 0.4824%\n",
      "Epoch [31/300], Step [23/225], Training Accuracy: 80.5027%, Training Loss: 0.4841%\n",
      "Epoch [31/300], Step [24/225], Training Accuracy: 80.3385%, Training Loss: 0.4856%\n",
      "Epoch [31/300], Step [25/225], Training Accuracy: 80.6250%, Training Loss: 0.4797%\n",
      "Epoch [31/300], Step [26/225], Training Accuracy: 80.7692%, Training Loss: 0.4784%\n",
      "Epoch [31/300], Step [27/225], Training Accuracy: 80.9606%, Training Loss: 0.4769%\n",
      "Epoch [31/300], Step [28/225], Training Accuracy: 81.1942%, Training Loss: 0.4697%\n",
      "Epoch [31/300], Step [29/225], Training Accuracy: 81.5194%, Training Loss: 0.4629%\n",
      "Epoch [31/300], Step [30/225], Training Accuracy: 81.6146%, Training Loss: 0.4631%\n",
      "Epoch [31/300], Step [31/225], Training Accuracy: 81.5020%, Training Loss: 0.4662%\n",
      "Epoch [31/300], Step [32/225], Training Accuracy: 81.6895%, Training Loss: 0.4634%\n",
      "Epoch [31/300], Step [33/225], Training Accuracy: 81.7708%, Training Loss: 0.4612%\n",
      "Epoch [31/300], Step [34/225], Training Accuracy: 81.8474%, Training Loss: 0.4593%\n",
      "Epoch [31/300], Step [35/225], Training Accuracy: 81.9643%, Training Loss: 0.4578%\n",
      "Epoch [31/300], Step [36/225], Training Accuracy: 81.9010%, Training Loss: 0.4574%\n",
      "Epoch [31/300], Step [37/225], Training Accuracy: 82.0524%, Training Loss: 0.4557%\n",
      "Epoch [31/300], Step [38/225], Training Accuracy: 82.2780%, Training Loss: 0.4540%\n",
      "Epoch [31/300], Step [39/225], Training Accuracy: 82.4119%, Training Loss: 0.4511%\n",
      "Epoch [31/300], Step [40/225], Training Accuracy: 82.3438%, Training Loss: 0.4507%\n",
      "Epoch [31/300], Step [41/225], Training Accuracy: 82.3933%, Training Loss: 0.4498%\n",
      "Epoch [31/300], Step [42/225], Training Accuracy: 82.4033%, Training Loss: 0.4498%\n",
      "Epoch [31/300], Step [43/225], Training Accuracy: 82.1584%, Training Loss: 0.4540%\n",
      "Epoch [31/300], Step [44/225], Training Accuracy: 82.2443%, Training Loss: 0.4533%\n",
      "Epoch [31/300], Step [45/225], Training Accuracy: 82.5000%, Training Loss: 0.4507%\n",
      "Epoch [31/300], Step [46/225], Training Accuracy: 82.6427%, Training Loss: 0.4497%\n",
      "Epoch [31/300], Step [47/225], Training Accuracy: 82.7460%, Training Loss: 0.4501%\n",
      "Epoch [31/300], Step [48/225], Training Accuracy: 82.6172%, Training Loss: 0.4516%\n",
      "Epoch [31/300], Step [49/225], Training Accuracy: 82.5893%, Training Loss: 0.4520%\n",
      "Epoch [31/300], Step [50/225], Training Accuracy: 82.5312%, Training Loss: 0.4533%\n",
      "Epoch [31/300], Step [51/225], Training Accuracy: 82.5368%, Training Loss: 0.4521%\n",
      "Epoch [31/300], Step [52/225], Training Accuracy: 82.6923%, Training Loss: 0.4495%\n",
      "Epoch [31/300], Step [53/225], Training Accuracy: 82.9304%, Training Loss: 0.4468%\n",
      "Epoch [31/300], Step [54/225], Training Accuracy: 82.6968%, Training Loss: 0.4504%\n",
      "Epoch [31/300], Step [55/225], Training Accuracy: 82.7557%, Training Loss: 0.4491%\n",
      "Epoch [31/300], Step [56/225], Training Accuracy: 82.7846%, Training Loss: 0.4489%\n",
      "Epoch [31/300], Step [57/225], Training Accuracy: 82.7577%, Training Loss: 0.4485%\n",
      "Epoch [31/300], Step [58/225], Training Accuracy: 82.7317%, Training Loss: 0.4484%\n",
      "Epoch [31/300], Step [59/225], Training Accuracy: 82.8390%, Training Loss: 0.4480%\n",
      "Epoch [31/300], Step [60/225], Training Accuracy: 82.8646%, Training Loss: 0.4474%\n",
      "Epoch [31/300], Step [61/225], Training Accuracy: 82.8893%, Training Loss: 0.4469%\n",
      "Epoch [31/300], Step [62/225], Training Accuracy: 82.7621%, Training Loss: 0.4486%\n",
      "Epoch [31/300], Step [63/225], Training Accuracy: 82.6885%, Training Loss: 0.4501%\n",
      "Epoch [31/300], Step [64/225], Training Accuracy: 82.5928%, Training Loss: 0.4525%\n",
      "Epoch [31/300], Step [65/225], Training Accuracy: 82.5240%, Training Loss: 0.4520%\n",
      "Epoch [31/300], Step [66/225], Training Accuracy: 82.5521%, Training Loss: 0.4519%\n",
      "Epoch [31/300], Step [67/225], Training Accuracy: 82.5793%, Training Loss: 0.4513%\n",
      "Epoch [31/300], Step [68/225], Training Accuracy: 82.5138%, Training Loss: 0.4532%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/300], Step [69/225], Training Accuracy: 82.5634%, Training Loss: 0.4526%\n",
      "Epoch [31/300], Step [70/225], Training Accuracy: 82.7009%, Training Loss: 0.4513%\n",
      "Epoch [31/300], Step [71/225], Training Accuracy: 82.7905%, Training Loss: 0.4496%\n",
      "Epoch [31/300], Step [72/225], Training Accuracy: 82.7691%, Training Loss: 0.4488%\n",
      "Epoch [31/300], Step [73/225], Training Accuracy: 82.7269%, Training Loss: 0.4500%\n",
      "Epoch [31/300], Step [74/225], Training Accuracy: 82.6647%, Training Loss: 0.4518%\n",
      "Epoch [31/300], Step [75/225], Training Accuracy: 82.6875%, Training Loss: 0.4501%\n",
      "Epoch [31/300], Step [76/225], Training Accuracy: 82.6480%, Training Loss: 0.4507%\n",
      "Epoch [31/300], Step [77/225], Training Accuracy: 82.7719%, Training Loss: 0.4490%\n",
      "Epoch [31/300], Step [78/225], Training Accuracy: 82.8325%, Training Loss: 0.4488%\n",
      "Epoch [31/300], Step [79/225], Training Accuracy: 82.8718%, Training Loss: 0.4485%\n",
      "Epoch [31/300], Step [80/225], Training Accuracy: 82.7930%, Training Loss: 0.4501%\n",
      "Epoch [31/300], Step [81/225], Training Accuracy: 82.8511%, Training Loss: 0.4495%\n",
      "Epoch [31/300], Step [82/225], Training Accuracy: 82.8125%, Training Loss: 0.4494%\n",
      "Epoch [31/300], Step [83/225], Training Accuracy: 82.8313%, Training Loss: 0.4491%\n",
      "Epoch [31/300], Step [84/225], Training Accuracy: 82.9055%, Training Loss: 0.4479%\n",
      "Epoch [31/300], Step [85/225], Training Accuracy: 82.9228%, Training Loss: 0.4480%\n",
      "Epoch [31/300], Step [86/225], Training Accuracy: 82.9760%, Training Loss: 0.4479%\n",
      "Epoch [31/300], Step [87/225], Training Accuracy: 82.9023%, Training Loss: 0.4491%\n",
      "Epoch [31/300], Step [88/225], Training Accuracy: 82.8835%, Training Loss: 0.4484%\n",
      "Epoch [31/300], Step [89/225], Training Accuracy: 82.9705%, Training Loss: 0.4472%\n",
      "Epoch [31/300], Step [90/225], Training Accuracy: 83.0035%, Training Loss: 0.4467%\n",
      "Epoch [31/300], Step [91/225], Training Accuracy: 83.0357%, Training Loss: 0.4466%\n",
      "Epoch [31/300], Step [92/225], Training Accuracy: 82.9484%, Training Loss: 0.4466%\n",
      "Epoch [31/300], Step [93/225], Training Accuracy: 82.9805%, Training Loss: 0.4461%\n",
      "Epoch [31/300], Step [94/225], Training Accuracy: 82.9787%, Training Loss: 0.4457%\n",
      "Epoch [31/300], Step [95/225], Training Accuracy: 82.9605%, Training Loss: 0.4458%\n",
      "Epoch [31/300], Step [96/225], Training Accuracy: 83.0729%, Training Loss: 0.4437%\n",
      "Epoch [31/300], Step [97/225], Training Accuracy: 83.0702%, Training Loss: 0.4439%\n",
      "Epoch [31/300], Step [98/225], Training Accuracy: 83.0357%, Training Loss: 0.4439%\n",
      "Epoch [31/300], Step [99/225], Training Accuracy: 83.0177%, Training Loss: 0.4439%\n",
      "Epoch [31/300], Step [100/225], Training Accuracy: 82.9688%, Training Loss: 0.4444%\n",
      "Epoch [31/300], Step [101/225], Training Accuracy: 83.0446%, Training Loss: 0.4435%\n",
      "Epoch [31/300], Step [102/225], Training Accuracy: 83.0116%, Training Loss: 0.4443%\n",
      "Epoch [31/300], Step [103/225], Training Accuracy: 83.0097%, Training Loss: 0.4449%\n",
      "Epoch [31/300], Step [104/225], Training Accuracy: 83.0228%, Training Loss: 0.4446%\n",
      "Epoch [31/300], Step [105/225], Training Accuracy: 82.9911%, Training Loss: 0.4449%\n",
      "Epoch [31/300], Step [106/225], Training Accuracy: 82.9452%, Training Loss: 0.4451%\n",
      "Epoch [31/300], Step [107/225], Training Accuracy: 82.9293%, Training Loss: 0.4452%\n",
      "Epoch [31/300], Step [108/225], Training Accuracy: 82.8559%, Training Loss: 0.4458%\n",
      "Epoch [31/300], Step [109/225], Training Accuracy: 82.8555%, Training Loss: 0.4452%\n",
      "Epoch [31/300], Step [110/225], Training Accuracy: 82.9119%, Training Loss: 0.4442%\n",
      "Epoch [31/300], Step [111/225], Training Accuracy: 82.8688%, Training Loss: 0.4436%\n",
      "Epoch [31/300], Step [112/225], Training Accuracy: 82.8404%, Training Loss: 0.4437%\n",
      "Epoch [31/300], Step [113/225], Training Accuracy: 82.8678%, Training Loss: 0.4429%\n",
      "Epoch [31/300], Step [114/225], Training Accuracy: 82.8947%, Training Loss: 0.4422%\n",
      "Epoch [31/300], Step [115/225], Training Accuracy: 82.8668%, Training Loss: 0.4430%\n",
      "Epoch [31/300], Step [116/225], Training Accuracy: 82.8260%, Training Loss: 0.4437%\n",
      "Epoch [31/300], Step [117/225], Training Accuracy: 82.8125%, Training Loss: 0.4439%\n",
      "Epoch [31/300], Step [118/225], Training Accuracy: 82.8655%, Training Loss: 0.4431%\n",
      "Epoch [31/300], Step [119/225], Training Accuracy: 82.8256%, Training Loss: 0.4434%\n",
      "Epoch [31/300], Step [120/225], Training Accuracy: 82.8776%, Training Loss: 0.4423%\n",
      "Epoch [31/300], Step [121/225], Training Accuracy: 82.8254%, Training Loss: 0.4427%\n",
      "Epoch [31/300], Step [122/225], Training Accuracy: 82.7997%, Training Loss: 0.4428%\n",
      "Epoch [31/300], Step [123/225], Training Accuracy: 82.8252%, Training Loss: 0.4420%\n",
      "Epoch [31/300], Step [124/225], Training Accuracy: 82.7999%, Training Loss: 0.4427%\n",
      "Epoch [31/300], Step [125/225], Training Accuracy: 82.8125%, Training Loss: 0.4428%\n",
      "Epoch [31/300], Step [126/225], Training Accuracy: 82.8621%, Training Loss: 0.4424%\n",
      "Epoch [31/300], Step [127/225], Training Accuracy: 82.8740%, Training Loss: 0.4423%\n",
      "Epoch [31/300], Step [128/225], Training Accuracy: 82.8857%, Training Loss: 0.4425%\n",
      "Epoch [31/300], Step [129/225], Training Accuracy: 82.9336%, Training Loss: 0.4416%\n",
      "Epoch [31/300], Step [130/225], Training Accuracy: 82.9087%, Training Loss: 0.4418%\n",
      "Epoch [31/300], Step [131/225], Training Accuracy: 82.9556%, Training Loss: 0.4409%\n",
      "Epoch [31/300], Step [132/225], Training Accuracy: 82.9664%, Training Loss: 0.4409%\n",
      "Epoch [31/300], Step [133/225], Training Accuracy: 83.0240%, Training Loss: 0.4398%\n",
      "Epoch [31/300], Step [134/225], Training Accuracy: 83.0224%, Training Loss: 0.4398%\n",
      "Epoch [31/300], Step [135/225], Training Accuracy: 83.0208%, Training Loss: 0.4391%\n",
      "Epoch [31/300], Step [136/225], Training Accuracy: 83.0193%, Training Loss: 0.4396%\n",
      "Epoch [31/300], Step [137/225], Training Accuracy: 83.0634%, Training Loss: 0.4386%\n",
      "Epoch [31/300], Step [138/225], Training Accuracy: 83.0503%, Training Loss: 0.4387%\n",
      "Epoch [31/300], Step [139/225], Training Accuracy: 83.0710%, Training Loss: 0.4388%\n",
      "Epoch [31/300], Step [140/225], Training Accuracy: 83.0915%, Training Loss: 0.4388%\n",
      "Epoch [31/300], Step [141/225], Training Accuracy: 83.0674%, Training Loss: 0.4388%\n",
      "Epoch [31/300], Step [142/225], Training Accuracy: 83.0326%, Training Loss: 0.4393%\n",
      "Epoch [31/300], Step [143/225], Training Accuracy: 82.9764%, Training Loss: 0.4401%\n",
      "Epoch [31/300], Step [144/225], Training Accuracy: 83.0187%, Training Loss: 0.4393%\n",
      "Epoch [31/300], Step [145/225], Training Accuracy: 83.0711%, Training Loss: 0.4394%\n",
      "Epoch [31/300], Step [146/225], Training Accuracy: 83.0908%, Training Loss: 0.4390%\n",
      "Epoch [31/300], Step [147/225], Training Accuracy: 83.1101%, Training Loss: 0.4391%\n",
      "Epoch [31/300], Step [148/225], Training Accuracy: 83.0870%, Training Loss: 0.4391%\n",
      "Epoch [31/300], Step [149/225], Training Accuracy: 83.0852%, Training Loss: 0.4392%\n",
      "Epoch [31/300], Step [150/225], Training Accuracy: 83.1146%, Training Loss: 0.4380%\n",
      "Epoch [31/300], Step [151/225], Training Accuracy: 83.1229%, Training Loss: 0.4379%\n",
      "Epoch [31/300], Step [152/225], Training Accuracy: 83.1517%, Training Loss: 0.4373%\n",
      "Epoch [31/300], Step [153/225], Training Accuracy: 83.1597%, Training Loss: 0.4366%\n",
      "Epoch [31/300], Step [154/225], Training Accuracy: 83.1879%, Training Loss: 0.4363%\n",
      "Epoch [31/300], Step [155/225], Training Accuracy: 83.1855%, Training Loss: 0.4360%\n",
      "Epoch [31/300], Step [156/225], Training Accuracy: 83.2031%, Training Loss: 0.4360%\n",
      "Epoch [31/300], Step [157/225], Training Accuracy: 83.2006%, Training Loss: 0.4359%\n",
      "Epoch [31/300], Step [158/225], Training Accuracy: 83.2180%, Training Loss: 0.4354%\n",
      "Epoch [31/300], Step [159/225], Training Accuracy: 83.2252%, Training Loss: 0.4354%\n",
      "Epoch [31/300], Step [160/225], Training Accuracy: 83.2324%, Training Loss: 0.4354%\n",
      "Epoch [31/300], Step [161/225], Training Accuracy: 83.2589%, Training Loss: 0.4346%\n",
      "Epoch [31/300], Step [162/225], Training Accuracy: 83.2755%, Training Loss: 0.4340%\n",
      "Epoch [31/300], Step [163/225], Training Accuracy: 83.2535%, Training Loss: 0.4338%\n",
      "Epoch [31/300], Step [164/225], Training Accuracy: 83.2698%, Training Loss: 0.4335%\n",
      "Epoch [31/300], Step [165/225], Training Accuracy: 83.3049%, Training Loss: 0.4330%\n",
      "Epoch [31/300], Step [166/225], Training Accuracy: 83.2737%, Training Loss: 0.4333%\n",
      "Epoch [31/300], Step [167/225], Training Accuracy: 83.2616%, Training Loss: 0.4331%\n",
      "Epoch [31/300], Step [168/225], Training Accuracy: 83.2682%, Training Loss: 0.4328%\n",
      "Epoch [31/300], Step [169/225], Training Accuracy: 83.2193%, Training Loss: 0.4331%\n",
      "Epoch [31/300], Step [170/225], Training Accuracy: 83.2169%, Training Loss: 0.4333%\n",
      "Epoch [31/300], Step [171/225], Training Accuracy: 83.2602%, Training Loss: 0.4326%\n",
      "Epoch [31/300], Step [172/225], Training Accuracy: 83.2667%, Training Loss: 0.4323%\n",
      "Epoch [31/300], Step [173/225], Training Accuracy: 83.2280%, Training Loss: 0.4324%\n",
      "Epoch [31/300], Step [174/225], Training Accuracy: 83.2256%, Training Loss: 0.4325%\n",
      "Epoch [31/300], Step [175/225], Training Accuracy: 83.2500%, Training Loss: 0.4320%\n",
      "Epoch [31/300], Step [176/225], Training Accuracy: 83.2475%, Training Loss: 0.4320%\n",
      "Epoch [31/300], Step [177/225], Training Accuracy: 83.2627%, Training Loss: 0.4315%\n",
      "Epoch [31/300], Step [178/225], Training Accuracy: 83.2163%, Training Loss: 0.4321%\n",
      "Epoch [31/300], Step [179/225], Training Accuracy: 83.2490%, Training Loss: 0.4323%\n",
      "Epoch [31/300], Step [180/225], Training Accuracy: 83.2465%, Training Loss: 0.4326%\n",
      "Epoch [31/300], Step [181/225], Training Accuracy: 83.2096%, Training Loss: 0.4335%\n",
      "Epoch [31/300], Step [182/225], Training Accuracy: 83.2418%, Training Loss: 0.4332%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/300], Step [183/225], Training Accuracy: 83.2736%, Training Loss: 0.4328%\n",
      "Epoch [31/300], Step [184/225], Training Accuracy: 83.2541%, Training Loss: 0.4331%\n",
      "Epoch [31/300], Step [185/225], Training Accuracy: 83.3024%, Training Loss: 0.4325%\n",
      "Epoch [31/300], Step [186/225], Training Accuracy: 83.3333%, Training Loss: 0.4320%\n",
      "Epoch [31/300], Step [187/225], Training Accuracy: 83.3138%, Training Loss: 0.4322%\n",
      "Epoch [31/300], Step [188/225], Training Accuracy: 83.3278%, Training Loss: 0.4318%\n",
      "Epoch [31/300], Step [189/225], Training Accuracy: 83.3581%, Training Loss: 0.4312%\n",
      "Epoch [31/300], Step [190/225], Training Accuracy: 83.3470%, Training Loss: 0.4317%\n",
      "Epoch [31/300], Step [191/225], Training Accuracy: 83.3770%, Training Loss: 0.4309%\n",
      "Epoch [31/300], Step [192/225], Training Accuracy: 83.3740%, Training Loss: 0.4313%\n",
      "Epoch [31/300], Step [193/225], Training Accuracy: 83.3468%, Training Loss: 0.4316%\n",
      "Epoch [31/300], Step [194/225], Training Accuracy: 83.4085%, Training Loss: 0.4302%\n",
      "Epoch [31/300], Step [195/225], Training Accuracy: 83.4215%, Training Loss: 0.4303%\n",
      "Epoch [31/300], Step [196/225], Training Accuracy: 83.4503%, Training Loss: 0.4298%\n",
      "Epoch [31/300], Step [197/225], Training Accuracy: 83.4549%, Training Loss: 0.4302%\n",
      "Epoch [31/300], Step [198/225], Training Accuracy: 83.4517%, Training Loss: 0.4298%\n",
      "Epoch [31/300], Step [199/225], Training Accuracy: 83.4485%, Training Loss: 0.4303%\n",
      "Epoch [31/300], Step [200/225], Training Accuracy: 83.4531%, Training Loss: 0.4301%\n",
      "Epoch [31/300], Step [201/225], Training Accuracy: 83.4810%, Training Loss: 0.4295%\n",
      "Epoch [31/300], Step [202/225], Training Accuracy: 83.4468%, Training Loss: 0.4300%\n",
      "Epoch [31/300], Step [203/225], Training Accuracy: 83.4437%, Training Loss: 0.4298%\n",
      "Epoch [31/300], Step [204/225], Training Accuracy: 83.4559%, Training Loss: 0.4297%\n",
      "Epoch [31/300], Step [205/225], Training Accuracy: 83.4909%, Training Loss: 0.4290%\n",
      "Epoch [31/300], Step [206/225], Training Accuracy: 83.5027%, Training Loss: 0.4287%\n",
      "Epoch [31/300], Step [207/225], Training Accuracy: 83.5296%, Training Loss: 0.4279%\n",
      "Epoch [31/300], Step [208/225], Training Accuracy: 83.5111%, Training Loss: 0.4276%\n",
      "Epoch [31/300], Step [209/225], Training Accuracy: 83.5227%, Training Loss: 0.4278%\n",
      "Epoch [31/300], Step [210/225], Training Accuracy: 83.5342%, Training Loss: 0.4278%\n",
      "Epoch [31/300], Step [211/225], Training Accuracy: 83.5086%, Training Loss: 0.4281%\n",
      "Epoch [31/300], Step [212/225], Training Accuracy: 83.4906%, Training Loss: 0.4289%\n",
      "Epoch [31/300], Step [213/225], Training Accuracy: 83.5167%, Training Loss: 0.4286%\n",
      "Epoch [31/300], Step [214/225], Training Accuracy: 83.5426%, Training Loss: 0.4282%\n",
      "Epoch [31/300], Step [215/225], Training Accuracy: 83.5392%, Training Loss: 0.4277%\n",
      "Epoch [31/300], Step [216/225], Training Accuracy: 83.4852%, Training Loss: 0.4285%\n",
      "Epoch [31/300], Step [217/225], Training Accuracy: 83.5037%, Training Loss: 0.4283%\n",
      "Epoch [31/300], Step [218/225], Training Accuracy: 83.5077%, Training Loss: 0.4285%\n",
      "Epoch [31/300], Step [219/225], Training Accuracy: 83.5331%, Training Loss: 0.4281%\n",
      "Epoch [31/300], Step [220/225], Training Accuracy: 83.5582%, Training Loss: 0.4277%\n",
      "Epoch [31/300], Step [221/225], Training Accuracy: 83.5549%, Training Loss: 0.4277%\n",
      "Epoch [31/300], Step [222/225], Training Accuracy: 83.5234%, Training Loss: 0.4280%\n",
      "Epoch [31/300], Step [223/225], Training Accuracy: 83.5412%, Training Loss: 0.4279%\n",
      "Epoch [31/300], Step [224/225], Training Accuracy: 83.5519%, Training Loss: 0.4274%\n",
      "Epoch [31/300], Step [225/225], Training Accuracy: 83.5534%, Training Loss: 0.4272%\n",
      "Epoch [32/300], Step [1/225], Training Accuracy: 81.2500%, Training Loss: 0.4934%\n",
      "Epoch [32/300], Step [2/225], Training Accuracy: 82.0312%, Training Loss: 0.4210%\n",
      "Epoch [32/300], Step [3/225], Training Accuracy: 81.2500%, Training Loss: 0.4434%\n",
      "Epoch [32/300], Step [4/225], Training Accuracy: 83.9844%, Training Loss: 0.3950%\n",
      "Epoch [32/300], Step [5/225], Training Accuracy: 85.0000%, Training Loss: 0.3803%\n",
      "Epoch [32/300], Step [6/225], Training Accuracy: 85.1562%, Training Loss: 0.3831%\n",
      "Epoch [32/300], Step [7/225], Training Accuracy: 84.3750%, Training Loss: 0.4011%\n",
      "Epoch [32/300], Step [8/225], Training Accuracy: 85.1562%, Training Loss: 0.3895%\n",
      "Epoch [32/300], Step [9/225], Training Accuracy: 84.8958%, Training Loss: 0.3952%\n",
      "Epoch [32/300], Step [10/225], Training Accuracy: 85.0000%, Training Loss: 0.3986%\n",
      "Epoch [32/300], Step [11/225], Training Accuracy: 84.9432%, Training Loss: 0.3995%\n",
      "Epoch [32/300], Step [12/225], Training Accuracy: 85.2865%, Training Loss: 0.3982%\n",
      "Epoch [32/300], Step [13/225], Training Accuracy: 85.5769%, Training Loss: 0.3915%\n",
      "Epoch [32/300], Step [14/225], Training Accuracy: 85.4911%, Training Loss: 0.3976%\n",
      "Epoch [32/300], Step [15/225], Training Accuracy: 85.8333%, Training Loss: 0.3894%\n",
      "Epoch [32/300], Step [16/225], Training Accuracy: 84.9609%, Training Loss: 0.4020%\n",
      "Epoch [32/300], Step [17/225], Training Accuracy: 84.7426%, Training Loss: 0.4147%\n",
      "Epoch [32/300], Step [18/225], Training Accuracy: 84.6354%, Training Loss: 0.4175%\n",
      "Epoch [32/300], Step [19/225], Training Accuracy: 84.7862%, Training Loss: 0.4127%\n",
      "Epoch [32/300], Step [20/225], Training Accuracy: 85.2344%, Training Loss: 0.4065%\n",
      "Epoch [32/300], Step [21/225], Training Accuracy: 85.2679%, Training Loss: 0.4021%\n",
      "Epoch [32/300], Step [22/225], Training Accuracy: 85.0852%, Training Loss: 0.4035%\n",
      "Epoch [32/300], Step [23/225], Training Accuracy: 84.5109%, Training Loss: 0.4120%\n",
      "Epoch [32/300], Step [24/225], Training Accuracy: 84.1797%, Training Loss: 0.4191%\n",
      "Epoch [32/300], Step [25/225], Training Accuracy: 84.3125%, Training Loss: 0.4151%\n",
      "Epoch [32/300], Step [26/225], Training Accuracy: 83.8942%, Training Loss: 0.4183%\n",
      "Epoch [32/300], Step [27/225], Training Accuracy: 83.6227%, Training Loss: 0.4211%\n",
      "Epoch [32/300], Step [28/225], Training Accuracy: 83.8170%, Training Loss: 0.4146%\n",
      "Epoch [32/300], Step [29/225], Training Accuracy: 84.1595%, Training Loss: 0.4107%\n",
      "Epoch [32/300], Step [30/225], Training Accuracy: 83.9583%, Training Loss: 0.4138%\n",
      "Epoch [32/300], Step [31/225], Training Accuracy: 83.9718%, Training Loss: 0.4133%\n",
      "Epoch [32/300], Step [32/225], Training Accuracy: 84.0820%, Training Loss: 0.4102%\n",
      "Epoch [32/300], Step [33/225], Training Accuracy: 83.9962%, Training Loss: 0.4094%\n",
      "Epoch [32/300], Step [34/225], Training Accuracy: 84.1452%, Training Loss: 0.4071%\n",
      "Epoch [32/300], Step [35/225], Training Accuracy: 84.2857%, Training Loss: 0.4051%\n",
      "Epoch [32/300], Step [36/225], Training Accuracy: 84.1146%, Training Loss: 0.4049%\n",
      "Epoch [32/300], Step [37/225], Training Accuracy: 84.0794%, Training Loss: 0.4069%\n",
      "Epoch [32/300], Step [38/225], Training Accuracy: 84.1694%, Training Loss: 0.4056%\n",
      "Epoch [32/300], Step [39/225], Training Accuracy: 84.1346%, Training Loss: 0.4050%\n",
      "Epoch [32/300], Step [40/225], Training Accuracy: 84.1406%, Training Loss: 0.4039%\n",
      "Epoch [32/300], Step [41/225], Training Accuracy: 84.0320%, Training Loss: 0.4043%\n",
      "Epoch [32/300], Step [42/225], Training Accuracy: 84.1146%, Training Loss: 0.4031%\n",
      "Epoch [32/300], Step [43/225], Training Accuracy: 83.8663%, Training Loss: 0.4077%\n",
      "Epoch [32/300], Step [44/225], Training Accuracy: 83.9844%, Training Loss: 0.4051%\n",
      "Epoch [32/300], Step [45/225], Training Accuracy: 83.8889%, Training Loss: 0.4054%\n",
      "Epoch [32/300], Step [46/225], Training Accuracy: 83.9674%, Training Loss: 0.4057%\n",
      "Epoch [32/300], Step [47/225], Training Accuracy: 83.8098%, Training Loss: 0.4065%\n",
      "Epoch [32/300], Step [48/225], Training Accuracy: 83.6914%, Training Loss: 0.4080%\n",
      "Epoch [32/300], Step [49/225], Training Accuracy: 83.7054%, Training Loss: 0.4078%\n",
      "Epoch [32/300], Step [50/225], Training Accuracy: 83.7812%, Training Loss: 0.4063%\n",
      "Epoch [32/300], Step [51/225], Training Accuracy: 83.7316%, Training Loss: 0.4069%\n",
      "Epoch [32/300], Step [52/225], Training Accuracy: 83.8041%, Training Loss: 0.4043%\n",
      "Epoch [32/300], Step [53/225], Training Accuracy: 83.8149%, Training Loss: 0.4043%\n",
      "Epoch [32/300], Step [54/225], Training Accuracy: 83.6806%, Training Loss: 0.4081%\n",
      "Epoch [32/300], Step [55/225], Training Accuracy: 83.6080%, Training Loss: 0.4083%\n",
      "Epoch [32/300], Step [56/225], Training Accuracy: 83.5658%, Training Loss: 0.4092%\n",
      "Epoch [32/300], Step [57/225], Training Accuracy: 83.6623%, Training Loss: 0.4079%\n",
      "Epoch [32/300], Step [58/225], Training Accuracy: 83.7554%, Training Loss: 0.4073%\n",
      "Epoch [32/300], Step [59/225], Training Accuracy: 83.7129%, Training Loss: 0.4084%\n",
      "Epoch [32/300], Step [60/225], Training Accuracy: 83.8021%, Training Loss: 0.4081%\n",
      "Epoch [32/300], Step [61/225], Training Accuracy: 83.7859%, Training Loss: 0.4091%\n",
      "Epoch [32/300], Step [62/225], Training Accuracy: 83.6946%, Training Loss: 0.4108%\n",
      "Epoch [32/300], Step [63/225], Training Accuracy: 83.8046%, Training Loss: 0.4105%\n",
      "Epoch [32/300], Step [64/225], Training Accuracy: 83.7646%, Training Loss: 0.4124%\n",
      "Epoch [32/300], Step [65/225], Training Accuracy: 83.9423%, Training Loss: 0.4093%\n",
      "Epoch [32/300], Step [66/225], Training Accuracy: 83.9962%, Training Loss: 0.4096%\n",
      "Epoch [32/300], Step [67/225], Training Accuracy: 83.9552%, Training Loss: 0.4104%\n",
      "Epoch [32/300], Step [68/225], Training Accuracy: 83.7776%, Training Loss: 0.4129%\n",
      "Epoch [32/300], Step [69/225], Training Accuracy: 83.8315%, Training Loss: 0.4122%\n",
      "Epoch [32/300], Step [70/225], Training Accuracy: 83.9732%, Training Loss: 0.4097%\n",
      "Epoch [32/300], Step [71/225], Training Accuracy: 83.9129%, Training Loss: 0.4097%\n",
      "Epoch [32/300], Step [72/225], Training Accuracy: 83.9410%, Training Loss: 0.4097%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/300], Step [73/225], Training Accuracy: 83.9255%, Training Loss: 0.4099%\n",
      "Epoch [32/300], Step [74/225], Training Accuracy: 83.9316%, Training Loss: 0.4107%\n",
      "Epoch [32/300], Step [75/225], Training Accuracy: 83.9375%, Training Loss: 0.4101%\n",
      "Epoch [32/300], Step [76/225], Training Accuracy: 83.9227%, Training Loss: 0.4112%\n",
      "Epoch [32/300], Step [77/225], Training Accuracy: 84.0097%, Training Loss: 0.4099%\n",
      "Epoch [32/300], Step [78/225], Training Accuracy: 84.0345%, Training Loss: 0.4099%\n",
      "Epoch [32/300], Step [79/225], Training Accuracy: 84.0190%, Training Loss: 0.4099%\n",
      "Epoch [32/300], Step [80/225], Training Accuracy: 83.9844%, Training Loss: 0.4094%\n",
      "Epoch [32/300], Step [81/225], Training Accuracy: 84.0856%, Training Loss: 0.4081%\n",
      "Epoch [32/300], Step [82/225], Training Accuracy: 84.0320%, Training Loss: 0.4094%\n",
      "Epoch [32/300], Step [83/225], Training Accuracy: 84.0550%, Training Loss: 0.4085%\n",
      "Epoch [32/300], Step [84/225], Training Accuracy: 84.0216%, Training Loss: 0.4088%\n",
      "Epoch [32/300], Step [85/225], Training Accuracy: 83.9706%, Training Loss: 0.4086%\n",
      "Epoch [32/300], Step [86/225], Training Accuracy: 83.9026%, Training Loss: 0.4095%\n",
      "Epoch [32/300], Step [87/225], Training Accuracy: 83.8901%, Training Loss: 0.4109%\n",
      "Epoch [32/300], Step [88/225], Training Accuracy: 83.8778%, Training Loss: 0.4107%\n",
      "Epoch [32/300], Step [89/225], Training Accuracy: 83.8659%, Training Loss: 0.4102%\n",
      "Epoch [32/300], Step [90/225], Training Accuracy: 83.8715%, Training Loss: 0.4109%\n",
      "Epoch [32/300], Step [91/225], Training Accuracy: 83.9629%, Training Loss: 0.4101%\n",
      "Epoch [32/300], Step [92/225], Training Accuracy: 83.9674%, Training Loss: 0.4096%\n",
      "Epoch [32/300], Step [93/225], Training Accuracy: 84.0222%, Training Loss: 0.4088%\n",
      "Epoch [32/300], Step [94/225], Training Accuracy: 84.1257%, Training Loss: 0.4070%\n",
      "Epoch [32/300], Step [95/225], Training Accuracy: 84.0789%, Training Loss: 0.4073%\n",
      "Epoch [32/300], Step [96/225], Training Accuracy: 84.1797%, Training Loss: 0.4059%\n",
      "Epoch [32/300], Step [97/225], Training Accuracy: 84.2300%, Training Loss: 0.4048%\n",
      "Epoch [32/300], Step [98/225], Training Accuracy: 84.1996%, Training Loss: 0.4050%\n",
      "Epoch [32/300], Step [99/225], Training Accuracy: 84.1856%, Training Loss: 0.4048%\n",
      "Epoch [32/300], Step [100/225], Training Accuracy: 84.1250%, Training Loss: 0.4060%\n",
      "Epoch [32/300], Step [101/225], Training Accuracy: 84.1584%, Training Loss: 0.4054%\n",
      "Epoch [32/300], Step [102/225], Training Accuracy: 84.1146%, Training Loss: 0.4058%\n",
      "Epoch [32/300], Step [103/225], Training Accuracy: 84.0716%, Training Loss: 0.4068%\n",
      "Epoch [32/300], Step [104/225], Training Accuracy: 84.0895%, Training Loss: 0.4065%\n",
      "Epoch [32/300], Step [105/225], Training Accuracy: 84.0923%, Training Loss: 0.4058%\n",
      "Epoch [32/300], Step [106/225], Training Accuracy: 84.0212%, Training Loss: 0.4070%\n",
      "Epoch [32/300], Step [107/225], Training Accuracy: 84.0245%, Training Loss: 0.4072%\n",
      "Epoch [32/300], Step [108/225], Training Accuracy: 84.0278%, Training Loss: 0.4074%\n",
      "Epoch [32/300], Step [109/225], Training Accuracy: 84.0883%, Training Loss: 0.4066%\n",
      "Epoch [32/300], Step [110/225], Training Accuracy: 84.1193%, Training Loss: 0.4066%\n",
      "Epoch [32/300], Step [111/225], Training Accuracy: 84.1920%, Training Loss: 0.4054%\n",
      "Epoch [32/300], Step [112/225], Training Accuracy: 84.1797%, Training Loss: 0.4052%\n",
      "Epoch [32/300], Step [113/225], Training Accuracy: 84.2091%, Training Loss: 0.4052%\n",
      "Epoch [32/300], Step [114/225], Training Accuracy: 84.2379%, Training Loss: 0.4046%\n",
      "Epoch [32/300], Step [115/225], Training Accuracy: 84.1848%, Training Loss: 0.4052%\n",
      "Epoch [32/300], Step [116/225], Training Accuracy: 84.1730%, Training Loss: 0.4056%\n",
      "Epoch [32/300], Step [117/225], Training Accuracy: 84.2281%, Training Loss: 0.4049%\n",
      "Epoch [32/300], Step [118/225], Training Accuracy: 84.2558%, Training Loss: 0.4048%\n",
      "Epoch [32/300], Step [119/225], Training Accuracy: 84.2437%, Training Loss: 0.4057%\n",
      "Epoch [32/300], Step [120/225], Training Accuracy: 84.2839%, Training Loss: 0.4050%\n",
      "Epoch [32/300], Step [121/225], Training Accuracy: 84.2975%, Training Loss: 0.4051%\n",
      "Epoch [32/300], Step [122/225], Training Accuracy: 84.2853%, Training Loss: 0.4053%\n",
      "Epoch [32/300], Step [123/225], Training Accuracy: 84.3496%, Training Loss: 0.4045%\n",
      "Epoch [32/300], Step [124/225], Training Accuracy: 84.3372%, Training Loss: 0.4051%\n",
      "Epoch [32/300], Step [125/225], Training Accuracy: 84.3750%, Training Loss: 0.4047%\n",
      "Epoch [32/300], Step [126/225], Training Accuracy: 84.3626%, Training Loss: 0.4050%\n",
      "Epoch [32/300], Step [127/225], Training Accuracy: 84.3381%, Training Loss: 0.4053%\n",
      "Epoch [32/300], Step [128/225], Training Accuracy: 84.2896%, Training Loss: 0.4056%\n",
      "Epoch [32/300], Step [129/225], Training Accuracy: 84.3266%, Training Loss: 0.4054%\n",
      "Epoch [32/300], Step [130/225], Training Accuracy: 84.3029%, Training Loss: 0.4069%\n",
      "Epoch [32/300], Step [131/225], Training Accuracy: 84.3989%, Training Loss: 0.4059%\n",
      "Epoch [32/300], Step [132/225], Training Accuracy: 84.3868%, Training Loss: 0.4061%\n",
      "Epoch [32/300], Step [133/225], Training Accuracy: 84.4102%, Training Loss: 0.4053%\n",
      "Epoch [32/300], Step [134/225], Training Accuracy: 84.3750%, Training Loss: 0.4058%\n",
      "Epoch [32/300], Step [135/225], Training Accuracy: 84.4097%, Training Loss: 0.4049%\n",
      "Epoch [32/300], Step [136/225], Training Accuracy: 84.3750%, Training Loss: 0.4055%\n",
      "Epoch [32/300], Step [137/225], Training Accuracy: 84.3408%, Training Loss: 0.4053%\n",
      "Epoch [32/300], Step [138/225], Training Accuracy: 84.3863%, Training Loss: 0.4042%\n",
      "Epoch [32/300], Step [139/225], Training Accuracy: 84.3750%, Training Loss: 0.4048%\n",
      "Epoch [32/300], Step [140/225], Training Accuracy: 84.3638%, Training Loss: 0.4053%\n",
      "Epoch [32/300], Step [141/225], Training Accuracy: 84.3750%, Training Loss: 0.4054%\n",
      "Epoch [32/300], Step [142/225], Training Accuracy: 84.3970%, Training Loss: 0.4054%\n",
      "Epoch [32/300], Step [143/225], Training Accuracy: 84.3859%, Training Loss: 0.4052%\n",
      "Epoch [32/300], Step [144/225], Training Accuracy: 84.3967%, Training Loss: 0.4047%\n",
      "Epoch [32/300], Step [145/225], Training Accuracy: 84.3966%, Training Loss: 0.4050%\n",
      "Epoch [32/300], Step [146/225], Training Accuracy: 84.3964%, Training Loss: 0.4046%\n",
      "Epoch [32/300], Step [147/225], Training Accuracy: 84.3219%, Training Loss: 0.4053%\n",
      "Epoch [32/300], Step [148/225], Training Accuracy: 84.3539%, Training Loss: 0.4050%\n",
      "Epoch [32/300], Step [149/225], Training Accuracy: 84.3435%, Training Loss: 0.4052%\n",
      "Epoch [32/300], Step [150/225], Training Accuracy: 84.3646%, Training Loss: 0.4048%\n",
      "Epoch [32/300], Step [151/225], Training Accuracy: 84.4164%, Training Loss: 0.4042%\n",
      "Epoch [32/300], Step [152/225], Training Accuracy: 84.4572%, Training Loss: 0.4036%\n",
      "Epoch [32/300], Step [153/225], Training Accuracy: 84.3852%, Training Loss: 0.4045%\n",
      "Epoch [32/300], Step [154/225], Training Accuracy: 84.3851%, Training Loss: 0.4043%\n",
      "Epoch [32/300], Step [155/225], Training Accuracy: 84.4052%, Training Loss: 0.4042%\n",
      "Epoch [32/300], Step [156/225], Training Accuracy: 84.3850%, Training Loss: 0.4044%\n",
      "Epoch [32/300], Step [157/225], Training Accuracy: 84.3650%, Training Loss: 0.4047%\n",
      "Epoch [32/300], Step [158/225], Training Accuracy: 84.3552%, Training Loss: 0.4045%\n",
      "Epoch [32/300], Step [159/225], Training Accuracy: 84.3750%, Training Loss: 0.4040%\n",
      "Epoch [32/300], Step [160/225], Training Accuracy: 84.4141%, Training Loss: 0.4039%\n",
      "Epoch [32/300], Step [161/225], Training Accuracy: 84.4526%, Training Loss: 0.4029%\n",
      "Epoch [32/300], Step [162/225], Training Accuracy: 84.4425%, Training Loss: 0.4026%\n",
      "Epoch [32/300], Step [163/225], Training Accuracy: 84.4709%, Training Loss: 0.4019%\n",
      "Epoch [32/300], Step [164/225], Training Accuracy: 84.4512%, Training Loss: 0.4021%\n",
      "Epoch [32/300], Step [165/225], Training Accuracy: 84.4318%, Training Loss: 0.4028%\n",
      "Epoch [32/300], Step [166/225], Training Accuracy: 84.4127%, Training Loss: 0.4031%\n",
      "Epoch [32/300], Step [167/225], Training Accuracy: 84.4124%, Training Loss: 0.4037%\n",
      "Epoch [32/300], Step [168/225], Training Accuracy: 84.4122%, Training Loss: 0.4034%\n",
      "Epoch [32/300], Step [169/225], Training Accuracy: 84.3842%, Training Loss: 0.4041%\n",
      "Epoch [32/300], Step [170/225], Training Accuracy: 84.3934%, Training Loss: 0.4038%\n",
      "Epoch [32/300], Step [171/225], Training Accuracy: 84.4207%, Training Loss: 0.4038%\n",
      "Epoch [32/300], Step [172/225], Training Accuracy: 84.4204%, Training Loss: 0.4033%\n",
      "Epoch [32/300], Step [173/225], Training Accuracy: 84.4111%, Training Loss: 0.4036%\n",
      "Epoch [32/300], Step [174/225], Training Accuracy: 84.4109%, Training Loss: 0.4039%\n",
      "Epoch [32/300], Step [175/225], Training Accuracy: 84.4554%, Training Loss: 0.4027%\n",
      "Epoch [32/300], Step [176/225], Training Accuracy: 84.4371%, Training Loss: 0.4027%\n",
      "Epoch [32/300], Step [177/225], Training Accuracy: 84.5074%, Training Loss: 0.4020%\n",
      "Epoch [32/300], Step [178/225], Training Accuracy: 84.4891%, Training Loss: 0.4024%\n",
      "Epoch [32/300], Step [179/225], Training Accuracy: 84.5234%, Training Loss: 0.4022%\n",
      "Epoch [32/300], Step [180/225], Training Accuracy: 84.5226%, Training Loss: 0.4021%\n",
      "Epoch [32/300], Step [181/225], Training Accuracy: 84.5045%, Training Loss: 0.4024%\n",
      "Epoch [32/300], Step [182/225], Training Accuracy: 84.5038%, Training Loss: 0.4023%\n",
      "Epoch [32/300], Step [183/225], Training Accuracy: 84.5116%, Training Loss: 0.4017%\n",
      "Epoch [32/300], Step [184/225], Training Accuracy: 84.5194%, Training Loss: 0.4014%\n",
      "Epoch [32/300], Step [185/225], Training Accuracy: 84.5439%, Training Loss: 0.4011%\n",
      "Epoch [32/300], Step [186/225], Training Accuracy: 84.5598%, Training Loss: 0.4007%\n",
      "Epoch [32/300], Step [187/225], Training Accuracy: 84.5672%, Training Loss: 0.4007%\n",
      "Epoch [32/300], Step [188/225], Training Accuracy: 84.5578%, Training Loss: 0.4012%\n",
      "Epoch [32/300], Step [189/225], Training Accuracy: 84.5569%, Training Loss: 0.4009%\n",
      "Epoch [32/300], Step [190/225], Training Accuracy: 84.5395%, Training Loss: 0.4018%\n",
      "Epoch [32/300], Step [191/225], Training Accuracy: 84.5713%, Training Loss: 0.4010%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/300], Step [192/225], Training Accuracy: 84.5866%, Training Loss: 0.4012%\n",
      "Epoch [32/300], Step [193/225], Training Accuracy: 84.5693%, Training Loss: 0.4014%\n",
      "Epoch [32/300], Step [194/225], Training Accuracy: 84.5602%, Training Loss: 0.4010%\n",
      "Epoch [32/300], Step [195/225], Training Accuracy: 84.5673%, Training Loss: 0.4013%\n",
      "Epoch [32/300], Step [196/225], Training Accuracy: 84.5823%, Training Loss: 0.4007%\n",
      "Epoch [32/300], Step [197/225], Training Accuracy: 84.5971%, Training Loss: 0.4004%\n",
      "Epoch [32/300], Step [198/225], Training Accuracy: 84.6275%, Training Loss: 0.3998%\n",
      "Epoch [32/300], Step [199/225], Training Accuracy: 84.6184%, Training Loss: 0.3999%\n",
      "Epoch [32/300], Step [200/225], Training Accuracy: 84.6484%, Training Loss: 0.3991%\n",
      "Epoch [32/300], Step [201/225], Training Accuracy: 84.6626%, Training Loss: 0.3990%\n",
      "Epoch [32/300], Step [202/225], Training Accuracy: 84.6380%, Training Loss: 0.3992%\n",
      "Epoch [32/300], Step [203/225], Training Accuracy: 84.6598%, Training Loss: 0.3989%\n",
      "Epoch [32/300], Step [204/225], Training Accuracy: 84.6584%, Training Loss: 0.3988%\n",
      "Epoch [32/300], Step [205/225], Training Accuracy: 84.6875%, Training Loss: 0.3983%\n",
      "Epoch [32/300], Step [206/225], Training Accuracy: 84.6784%, Training Loss: 0.3986%\n",
      "Epoch [32/300], Step [207/225], Training Accuracy: 84.6920%, Training Loss: 0.3982%\n",
      "Epoch [32/300], Step [208/225], Training Accuracy: 84.7130%, Training Loss: 0.3981%\n",
      "Epoch [32/300], Step [209/225], Training Accuracy: 84.7114%, Training Loss: 0.3980%\n",
      "Epoch [32/300], Step [210/225], Training Accuracy: 84.7098%, Training Loss: 0.3980%\n",
      "Epoch [32/300], Step [211/225], Training Accuracy: 84.7082%, Training Loss: 0.3983%\n",
      "Epoch [32/300], Step [212/225], Training Accuracy: 84.6919%, Training Loss: 0.3992%\n",
      "Epoch [32/300], Step [213/225], Training Accuracy: 84.6978%, Training Loss: 0.3992%\n",
      "Epoch [32/300], Step [214/225], Training Accuracy: 84.7036%, Training Loss: 0.3991%\n",
      "Epoch [32/300], Step [215/225], Training Accuracy: 84.7238%, Training Loss: 0.3988%\n",
      "Epoch [32/300], Step [216/225], Training Accuracy: 84.7150%, Training Loss: 0.3989%\n",
      "Epoch [32/300], Step [217/225], Training Accuracy: 84.7206%, Training Loss: 0.3987%\n",
      "Epoch [32/300], Step [218/225], Training Accuracy: 84.7262%, Training Loss: 0.3986%\n",
      "Epoch [32/300], Step [219/225], Training Accuracy: 84.7317%, Training Loss: 0.3985%\n",
      "Epoch [32/300], Step [220/225], Training Accuracy: 84.7585%, Training Loss: 0.3981%\n",
      "Epoch [32/300], Step [221/225], Training Accuracy: 84.7426%, Training Loss: 0.3988%\n",
      "Epoch [32/300], Step [222/225], Training Accuracy: 84.6706%, Training Loss: 0.3998%\n",
      "Epoch [32/300], Step [223/225], Training Accuracy: 84.6623%, Training Loss: 0.3994%\n",
      "Epoch [32/300], Step [224/225], Training Accuracy: 84.6610%, Training Loss: 0.3988%\n",
      "Epoch [32/300], Step [225/225], Training Accuracy: 84.6512%, Training Loss: 0.3986%\n",
      "Epoch [33/300], Step [1/225], Training Accuracy: 85.9375%, Training Loss: 0.4582%\n",
      "Epoch [33/300], Step [2/225], Training Accuracy: 86.7188%, Training Loss: 0.4162%\n",
      "Epoch [33/300], Step [3/225], Training Accuracy: 83.8542%, Training Loss: 0.4727%\n",
      "Epoch [33/300], Step [4/225], Training Accuracy: 85.5469%, Training Loss: 0.4184%\n",
      "Epoch [33/300], Step [5/225], Training Accuracy: 85.6250%, Training Loss: 0.4144%\n",
      "Epoch [33/300], Step [6/225], Training Accuracy: 85.4167%, Training Loss: 0.4222%\n",
      "Epoch [33/300], Step [7/225], Training Accuracy: 85.2679%, Training Loss: 0.4320%\n",
      "Epoch [33/300], Step [8/225], Training Accuracy: 85.9375%, Training Loss: 0.4117%\n",
      "Epoch [33/300], Step [9/225], Training Accuracy: 86.1111%, Training Loss: 0.4094%\n",
      "Epoch [33/300], Step [10/225], Training Accuracy: 85.9375%, Training Loss: 0.4144%\n",
      "Epoch [33/300], Step [11/225], Training Accuracy: 86.5057%, Training Loss: 0.4018%\n",
      "Epoch [33/300], Step [12/225], Training Accuracy: 86.3281%, Training Loss: 0.3989%\n",
      "Epoch [33/300], Step [13/225], Training Accuracy: 86.4183%, Training Loss: 0.3935%\n",
      "Epoch [33/300], Step [14/225], Training Accuracy: 86.4955%, Training Loss: 0.3953%\n",
      "Epoch [33/300], Step [15/225], Training Accuracy: 86.7708%, Training Loss: 0.3863%\n",
      "Epoch [33/300], Step [16/225], Training Accuracy: 86.2305%, Training Loss: 0.3994%\n",
      "Epoch [33/300], Step [17/225], Training Accuracy: 86.3051%, Training Loss: 0.4045%\n",
      "Epoch [33/300], Step [18/225], Training Accuracy: 86.2847%, Training Loss: 0.4032%\n",
      "Epoch [33/300], Step [19/225], Training Accuracy: 86.2664%, Training Loss: 0.4006%\n",
      "Epoch [33/300], Step [20/225], Training Accuracy: 86.2500%, Training Loss: 0.3949%\n",
      "Epoch [33/300], Step [21/225], Training Accuracy: 86.3839%, Training Loss: 0.3893%\n",
      "Epoch [33/300], Step [22/225], Training Accuracy: 86.1506%, Training Loss: 0.3941%\n",
      "Epoch [33/300], Step [23/225], Training Accuracy: 85.8696%, Training Loss: 0.3971%\n",
      "Epoch [33/300], Step [24/225], Training Accuracy: 85.6120%, Training Loss: 0.4049%\n",
      "Epoch [33/300], Step [25/225], Training Accuracy: 85.5625%, Training Loss: 0.4044%\n",
      "Epoch [33/300], Step [26/225], Training Accuracy: 85.3365%, Training Loss: 0.4078%\n",
      "Epoch [33/300], Step [27/225], Training Accuracy: 85.3009%, Training Loss: 0.4047%\n",
      "Epoch [33/300], Step [28/225], Training Accuracy: 85.3237%, Training Loss: 0.4031%\n",
      "Epoch [33/300], Step [29/225], Training Accuracy: 85.3987%, Training Loss: 0.3984%\n",
      "Epoch [33/300], Step [30/225], Training Accuracy: 85.2083%, Training Loss: 0.4003%\n",
      "Epoch [33/300], Step [31/225], Training Accuracy: 85.0302%, Training Loss: 0.3998%\n",
      "Epoch [33/300], Step [32/225], Training Accuracy: 84.9609%, Training Loss: 0.3980%\n",
      "Epoch [33/300], Step [33/225], Training Accuracy: 84.8485%, Training Loss: 0.3986%\n",
      "Epoch [33/300], Step [34/225], Training Accuracy: 84.8346%, Training Loss: 0.3966%\n",
      "Epoch [33/300], Step [35/225], Training Accuracy: 84.8661%, Training Loss: 0.3954%\n",
      "Epoch [33/300], Step [36/225], Training Accuracy: 85.1562%, Training Loss: 0.3918%\n",
      "Epoch [33/300], Step [37/225], Training Accuracy: 85.1774%, Training Loss: 0.3921%\n",
      "Epoch [33/300], Step [38/225], Training Accuracy: 85.2385%, Training Loss: 0.3932%\n",
      "Epoch [33/300], Step [39/225], Training Accuracy: 85.3365%, Training Loss: 0.3921%\n",
      "Epoch [33/300], Step [40/225], Training Accuracy: 85.5859%, Training Loss: 0.3886%\n",
      "Epoch [33/300], Step [41/225], Training Accuracy: 85.5564%, Training Loss: 0.3885%\n",
      "Epoch [33/300], Step [42/225], Training Accuracy: 85.4911%, Training Loss: 0.3888%\n",
      "Epoch [33/300], Step [43/225], Training Accuracy: 85.6105%, Training Loss: 0.3869%\n",
      "Epoch [33/300], Step [44/225], Training Accuracy: 85.7955%, Training Loss: 0.3840%\n",
      "Epoch [33/300], Step [45/225], Training Accuracy: 85.8333%, Training Loss: 0.3828%\n",
      "Epoch [33/300], Step [46/225], Training Accuracy: 85.9035%, Training Loss: 0.3816%\n",
      "Epoch [33/300], Step [47/225], Training Accuracy: 85.9043%, Training Loss: 0.3816%\n",
      "Epoch [33/300], Step [48/225], Training Accuracy: 85.9049%, Training Loss: 0.3826%\n",
      "Epoch [33/300], Step [49/225], Training Accuracy: 85.7462%, Training Loss: 0.3848%\n",
      "Epoch [33/300], Step [50/225], Training Accuracy: 85.8125%, Training Loss: 0.3832%\n",
      "Epoch [33/300], Step [51/225], Training Accuracy: 85.7537%, Training Loss: 0.3834%\n",
      "Epoch [33/300], Step [52/225], Training Accuracy: 85.7572%, Training Loss: 0.3829%\n",
      "Epoch [33/300], Step [53/225], Training Accuracy: 85.7017%, Training Loss: 0.3838%\n",
      "Epoch [33/300], Step [54/225], Training Accuracy: 85.3299%, Training Loss: 0.3899%\n",
      "Epoch [33/300], Step [55/225], Training Accuracy: 85.2841%, Training Loss: 0.3906%\n",
      "Epoch [33/300], Step [56/225], Training Accuracy: 85.3795%, Training Loss: 0.3902%\n",
      "Epoch [33/300], Step [57/225], Training Accuracy: 85.2796%, Training Loss: 0.3912%\n",
      "Epoch [33/300], Step [58/225], Training Accuracy: 85.2909%, Training Loss: 0.3908%\n",
      "Epoch [33/300], Step [59/225], Training Accuracy: 85.2489%, Training Loss: 0.3923%\n",
      "Epoch [33/300], Step [60/225], Training Accuracy: 85.3125%, Training Loss: 0.3909%\n",
      "Epoch [33/300], Step [61/225], Training Accuracy: 85.2971%, Training Loss: 0.3923%\n",
      "Epoch [33/300], Step [62/225], Training Accuracy: 85.1310%, Training Loss: 0.3940%\n",
      "Epoch [33/300], Step [63/225], Training Accuracy: 85.0694%, Training Loss: 0.3959%\n",
      "Epoch [33/300], Step [64/225], Training Accuracy: 84.9854%, Training Loss: 0.3972%\n",
      "Epoch [33/300], Step [65/225], Training Accuracy: 84.9519%, Training Loss: 0.3960%\n",
      "Epoch [33/300], Step [66/225], Training Accuracy: 84.9195%, Training Loss: 0.3960%\n",
      "Epoch [33/300], Step [67/225], Training Accuracy: 84.8647%, Training Loss: 0.3956%\n",
      "Epoch [33/300], Step [68/225], Training Accuracy: 84.7656%, Training Loss: 0.3965%\n",
      "Epoch [33/300], Step [69/225], Training Accuracy: 84.7373%, Training Loss: 0.3975%\n",
      "Epoch [33/300], Step [70/225], Training Accuracy: 84.8214%, Training Loss: 0.3965%\n",
      "Epoch [33/300], Step [71/225], Training Accuracy: 84.9032%, Training Loss: 0.3954%\n",
      "Epoch [33/300], Step [72/225], Training Accuracy: 84.9826%, Training Loss: 0.3942%\n",
      "Epoch [33/300], Step [73/225], Training Accuracy: 84.9315%, Training Loss: 0.3953%\n",
      "Epoch [33/300], Step [74/225], Training Accuracy: 84.8606%, Training Loss: 0.3963%\n",
      "Epoch [33/300], Step [75/225], Training Accuracy: 84.8750%, Training Loss: 0.3957%\n",
      "Epoch [33/300], Step [76/225], Training Accuracy: 84.9095%, Training Loss: 0.3951%\n",
      "Epoch [33/300], Step [77/225], Training Accuracy: 85.0041%, Training Loss: 0.3934%\n",
      "Epoch [33/300], Step [78/225], Training Accuracy: 84.9760%, Training Loss: 0.3935%\n",
      "Epoch [33/300], Step [79/225], Training Accuracy: 84.8892%, Training Loss: 0.3939%\n",
      "Epoch [33/300], Step [80/225], Training Accuracy: 84.7656%, Training Loss: 0.3957%\n",
      "Epoch [33/300], Step [81/225], Training Accuracy: 84.8187%, Training Loss: 0.3934%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/300], Step [82/225], Training Accuracy: 84.7370%, Training Loss: 0.3940%\n",
      "Epoch [33/300], Step [83/225], Training Accuracy: 84.6762%, Training Loss: 0.3949%\n",
      "Epoch [33/300], Step [84/225], Training Accuracy: 84.7470%, Training Loss: 0.3938%\n",
      "Epoch [33/300], Step [85/225], Training Accuracy: 84.7610%, Training Loss: 0.3940%\n",
      "Epoch [33/300], Step [86/225], Training Accuracy: 84.6839%, Training Loss: 0.3946%\n",
      "Epoch [33/300], Step [87/225], Training Accuracy: 84.6624%, Training Loss: 0.3955%\n",
      "Epoch [33/300], Step [88/225], Training Accuracy: 84.6591%, Training Loss: 0.3949%\n",
      "Epoch [33/300], Step [89/225], Training Accuracy: 84.6032%, Training Loss: 0.3952%\n",
      "Epoch [33/300], Step [90/225], Training Accuracy: 84.5312%, Training Loss: 0.3962%\n",
      "Epoch [33/300], Step [91/225], Training Accuracy: 84.5467%, Training Loss: 0.3957%\n",
      "Epoch [33/300], Step [92/225], Training Accuracy: 84.5958%, Training Loss: 0.3947%\n",
      "Epoch [33/300], Step [93/225], Training Accuracy: 84.6270%, Training Loss: 0.3936%\n",
      "Epoch [33/300], Step [94/225], Training Accuracy: 84.6410%, Training Loss: 0.3931%\n",
      "Epoch [33/300], Step [95/225], Training Accuracy: 84.6875%, Training Loss: 0.3927%\n",
      "Epoch [33/300], Step [96/225], Training Accuracy: 84.7331%, Training Loss: 0.3916%\n",
      "Epoch [33/300], Step [97/225], Training Accuracy: 84.7777%, Training Loss: 0.3905%\n",
      "Epoch [33/300], Step [98/225], Training Accuracy: 84.8214%, Training Loss: 0.3905%\n",
      "Epoch [33/300], Step [99/225], Training Accuracy: 84.7854%, Training Loss: 0.3919%\n",
      "Epoch [33/300], Step [100/225], Training Accuracy: 84.7188%, Training Loss: 0.3932%\n",
      "Epoch [33/300], Step [101/225], Training Accuracy: 84.7308%, Training Loss: 0.3924%\n",
      "Epoch [33/300], Step [102/225], Training Accuracy: 84.6967%, Training Loss: 0.3930%\n",
      "Epoch [33/300], Step [103/225], Training Accuracy: 84.6481%, Training Loss: 0.3938%\n",
      "Epoch [33/300], Step [104/225], Training Accuracy: 84.6304%, Training Loss: 0.3938%\n",
      "Epoch [33/300], Step [105/225], Training Accuracy: 84.5685%, Training Loss: 0.3951%\n",
      "Epoch [33/300], Step [106/225], Training Accuracy: 84.5371%, Training Loss: 0.3956%\n",
      "Epoch [33/300], Step [107/225], Training Accuracy: 84.5356%, Training Loss: 0.3957%\n",
      "Epoch [33/300], Step [108/225], Training Accuracy: 84.4907%, Training Loss: 0.3963%\n",
      "Epoch [33/300], Step [109/225], Training Accuracy: 84.5614%, Training Loss: 0.3956%\n",
      "Epoch [33/300], Step [110/225], Training Accuracy: 84.5881%, Training Loss: 0.3950%\n",
      "Epoch [33/300], Step [111/225], Training Accuracy: 84.5721%, Training Loss: 0.3948%\n",
      "Epoch [33/300], Step [112/225], Training Accuracy: 84.5564%, Training Loss: 0.3952%\n",
      "Epoch [33/300], Step [113/225], Training Accuracy: 84.5686%, Training Loss: 0.3949%\n",
      "Epoch [33/300], Step [114/225], Training Accuracy: 84.6217%, Training Loss: 0.3940%\n",
      "Epoch [33/300], Step [115/225], Training Accuracy: 84.5652%, Training Loss: 0.3948%\n",
      "Epoch [33/300], Step [116/225], Training Accuracy: 84.5232%, Training Loss: 0.3953%\n",
      "Epoch [33/300], Step [117/225], Training Accuracy: 84.5219%, Training Loss: 0.3953%\n",
      "Epoch [33/300], Step [118/225], Training Accuracy: 84.4544%, Training Loss: 0.3970%\n",
      "Epoch [33/300], Step [119/225], Training Accuracy: 84.5194%, Training Loss: 0.3963%\n",
      "Epoch [33/300], Step [120/225], Training Accuracy: 84.5703%, Training Loss: 0.3960%\n",
      "Epoch [33/300], Step [121/225], Training Accuracy: 84.5945%, Training Loss: 0.3950%\n",
      "Epoch [33/300], Step [122/225], Training Accuracy: 84.6311%, Training Loss: 0.3957%\n",
      "Epoch [33/300], Step [123/225], Training Accuracy: 84.6545%, Training Loss: 0.3948%\n",
      "Epoch [33/300], Step [124/225], Training Accuracy: 84.6270%, Training Loss: 0.3951%\n",
      "Epoch [33/300], Step [125/225], Training Accuracy: 84.6625%, Training Loss: 0.3949%\n",
      "Epoch [33/300], Step [126/225], Training Accuracy: 84.6850%, Training Loss: 0.3947%\n",
      "Epoch [33/300], Step [127/225], Training Accuracy: 84.6949%, Training Loss: 0.3950%\n",
      "Epoch [33/300], Step [128/225], Training Accuracy: 84.6680%, Training Loss: 0.3959%\n",
      "Epoch [33/300], Step [129/225], Training Accuracy: 84.6778%, Training Loss: 0.3959%\n",
      "Epoch [33/300], Step [130/225], Training Accuracy: 84.7115%, Training Loss: 0.3959%\n",
      "Epoch [33/300], Step [131/225], Training Accuracy: 84.7567%, Training Loss: 0.3949%\n",
      "Epoch [33/300], Step [132/225], Training Accuracy: 84.7064%, Training Loss: 0.3957%\n",
      "Epoch [33/300], Step [133/225], Training Accuracy: 84.7509%, Training Loss: 0.3945%\n",
      "Epoch [33/300], Step [134/225], Training Accuracy: 84.7481%, Training Loss: 0.3948%\n",
      "Epoch [33/300], Step [135/225], Training Accuracy: 84.7685%, Training Loss: 0.3939%\n",
      "Epoch [33/300], Step [136/225], Training Accuracy: 84.7771%, Training Loss: 0.3946%\n",
      "Epoch [33/300], Step [137/225], Training Accuracy: 84.7970%, Training Loss: 0.3946%\n",
      "Epoch [33/300], Step [138/225], Training Accuracy: 84.8279%, Training Loss: 0.3943%\n",
      "Epoch [33/300], Step [139/225], Training Accuracy: 84.8359%, Training Loss: 0.3943%\n",
      "Epoch [33/300], Step [140/225], Training Accuracy: 84.8214%, Training Loss: 0.3948%\n",
      "Epoch [33/300], Step [141/225], Training Accuracy: 84.8183%, Training Loss: 0.3953%\n",
      "Epoch [33/300], Step [142/225], Training Accuracy: 84.8371%, Training Loss: 0.3950%\n",
      "Epoch [33/300], Step [143/225], Training Accuracy: 84.7793%, Training Loss: 0.3960%\n",
      "Epoch [33/300], Step [144/225], Training Accuracy: 84.8090%, Training Loss: 0.3956%\n",
      "Epoch [33/300], Step [145/225], Training Accuracy: 84.8060%, Training Loss: 0.3955%\n",
      "Epoch [33/300], Step [146/225], Training Accuracy: 84.8352%, Training Loss: 0.3953%\n",
      "Epoch [33/300], Step [147/225], Training Accuracy: 84.8214%, Training Loss: 0.3954%\n",
      "Epoch [33/300], Step [148/225], Training Accuracy: 84.8079%, Training Loss: 0.3952%\n",
      "Epoch [33/300], Step [149/225], Training Accuracy: 84.8049%, Training Loss: 0.3956%\n",
      "Epoch [33/300], Step [150/225], Training Accuracy: 84.8229%, Training Loss: 0.3951%\n",
      "Epoch [33/300], Step [151/225], Training Accuracy: 84.8820%, Training Loss: 0.3942%\n",
      "Epoch [33/300], Step [152/225], Training Accuracy: 84.8787%, Training Loss: 0.3949%\n",
      "Epoch [33/300], Step [153/225], Training Accuracy: 84.9469%, Training Loss: 0.3934%\n",
      "Epoch [33/300], Step [154/225], Training Accuracy: 84.9838%, Training Loss: 0.3930%\n",
      "Epoch [33/300], Step [155/225], Training Accuracy: 84.9899%, Training Loss: 0.3930%\n",
      "Epoch [33/300], Step [156/225], Training Accuracy: 85.0160%, Training Loss: 0.3926%\n",
      "Epoch [33/300], Step [157/225], Training Accuracy: 85.0020%, Training Loss: 0.3926%\n",
      "Epoch [33/300], Step [158/225], Training Accuracy: 85.0475%, Training Loss: 0.3915%\n",
      "Epoch [33/300], Step [159/225], Training Accuracy: 85.0727%, Training Loss: 0.3910%\n",
      "Epoch [33/300], Step [160/225], Training Accuracy: 85.0684%, Training Loss: 0.3914%\n",
      "Epoch [33/300], Step [161/225], Training Accuracy: 85.0932%, Training Loss: 0.3909%\n",
      "Epoch [33/300], Step [162/225], Training Accuracy: 85.1370%, Training Loss: 0.3898%\n",
      "Epoch [33/300], Step [163/225], Training Accuracy: 85.1515%, Training Loss: 0.3892%\n",
      "Epoch [33/300], Step [164/225], Training Accuracy: 85.1562%, Training Loss: 0.3889%\n",
      "Epoch [33/300], Step [165/225], Training Accuracy: 85.1989%, Training Loss: 0.3882%\n",
      "Epoch [33/300], Step [166/225], Training Accuracy: 85.2033%, Training Loss: 0.3884%\n",
      "Epoch [33/300], Step [167/225], Training Accuracy: 85.2077%, Training Loss: 0.3883%\n",
      "Epoch [33/300], Step [168/225], Training Accuracy: 85.2121%, Training Loss: 0.3882%\n",
      "Epoch [33/300], Step [169/225], Training Accuracy: 85.1794%, Training Loss: 0.3888%\n",
      "Epoch [33/300], Step [170/225], Training Accuracy: 85.1471%, Training Loss: 0.3894%\n",
      "Epoch [33/300], Step [171/225], Training Accuracy: 85.1608%, Training Loss: 0.3893%\n",
      "Epoch [33/300], Step [172/225], Training Accuracy: 85.1472%, Training Loss: 0.3891%\n",
      "Epoch [33/300], Step [173/225], Training Accuracy: 85.0975%, Training Loss: 0.3902%\n",
      "Epoch [33/300], Step [174/225], Training Accuracy: 85.0395%, Training Loss: 0.3907%\n",
      "Epoch [33/300], Step [175/225], Training Accuracy: 85.0625%, Training Loss: 0.3902%\n",
      "Epoch [33/300], Step [176/225], Training Accuracy: 84.9876%, Training Loss: 0.3915%\n",
      "Epoch [33/300], Step [177/225], Training Accuracy: 85.0194%, Training Loss: 0.3908%\n",
      "Epoch [33/300], Step [178/225], Training Accuracy: 85.0158%, Training Loss: 0.3909%\n",
      "Epoch [33/300], Step [179/225], Training Accuracy: 85.0209%, Training Loss: 0.3906%\n",
      "Epoch [33/300], Step [180/225], Training Accuracy: 85.0174%, Training Loss: 0.3907%\n",
      "Epoch [33/300], Step [181/225], Training Accuracy: 84.9879%, Training Loss: 0.3908%\n",
      "Epoch [33/300], Step [182/225], Training Accuracy: 85.0361%, Training Loss: 0.3902%\n",
      "Epoch [33/300], Step [183/225], Training Accuracy: 85.0581%, Training Loss: 0.3898%\n",
      "Epoch [33/300], Step [184/225], Training Accuracy: 85.0289%, Training Loss: 0.3904%\n",
      "Epoch [33/300], Step [185/225], Training Accuracy: 85.0338%, Training Loss: 0.3902%\n",
      "Epoch [33/300], Step [186/225], Training Accuracy: 85.0134%, Training Loss: 0.3903%\n",
      "Epoch [33/300], Step [187/225], Training Accuracy: 84.9933%, Training Loss: 0.3906%\n",
      "Epoch [33/300], Step [188/225], Training Accuracy: 84.9817%, Training Loss: 0.3909%\n",
      "Epoch [33/300], Step [189/225], Training Accuracy: 85.0116%, Training Loss: 0.3903%\n",
      "Epoch [33/300], Step [190/225], Training Accuracy: 85.0000%, Training Loss: 0.3906%\n",
      "Epoch [33/300], Step [191/225], Training Accuracy: 85.0049%, Training Loss: 0.3902%\n",
      "Epoch [33/300], Step [192/225], Training Accuracy: 85.0098%, Training Loss: 0.3903%\n",
      "Epoch [33/300], Step [193/225], Training Accuracy: 85.0065%, Training Loss: 0.3903%\n",
      "Epoch [33/300], Step [194/225], Training Accuracy: 85.0435%, Training Loss: 0.3894%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/300], Step [195/225], Training Accuracy: 85.0401%, Training Loss: 0.3893%\n",
      "Epoch [33/300], Step [196/225], Training Accuracy: 85.0686%, Training Loss: 0.3888%\n",
      "Epoch [33/300], Step [197/225], Training Accuracy: 85.0412%, Training Loss: 0.3892%\n",
      "Epoch [33/300], Step [198/225], Training Accuracy: 85.0616%, Training Loss: 0.3889%\n",
      "Epoch [33/300], Step [199/225], Training Accuracy: 85.0581%, Training Loss: 0.3896%\n",
      "Epoch [33/300], Step [200/225], Training Accuracy: 85.0781%, Training Loss: 0.3894%\n",
      "Epoch [33/300], Step [201/225], Training Accuracy: 85.0824%, Training Loss: 0.3887%\n",
      "Epoch [33/300], Step [202/225], Training Accuracy: 85.1253%, Training Loss: 0.3882%\n",
      "Epoch [33/300], Step [203/225], Training Accuracy: 85.1293%, Training Loss: 0.3885%\n",
      "Epoch [33/300], Step [204/225], Training Accuracy: 85.1103%, Training Loss: 0.3888%\n",
      "Epoch [33/300], Step [205/225], Training Accuracy: 85.1143%, Training Loss: 0.3886%\n",
      "Epoch [33/300], Step [206/225], Training Accuracy: 85.1335%, Training Loss: 0.3881%\n",
      "Epoch [33/300], Step [207/225], Training Accuracy: 85.1525%, Training Loss: 0.3875%\n",
      "Epoch [33/300], Step [208/225], Training Accuracy: 85.1638%, Training Loss: 0.3872%\n",
      "Epoch [33/300], Step [209/225], Training Accuracy: 85.1749%, Training Loss: 0.3873%\n",
      "Epoch [33/300], Step [210/225], Training Accuracy: 85.1786%, Training Loss: 0.3870%\n",
      "Epoch [33/300], Step [211/225], Training Accuracy: 85.1822%, Training Loss: 0.3873%\n",
      "Epoch [33/300], Step [212/225], Training Accuracy: 85.1784%, Training Loss: 0.3877%\n",
      "Epoch [33/300], Step [213/225], Training Accuracy: 85.1452%, Training Loss: 0.3877%\n",
      "Epoch [33/300], Step [214/225], Training Accuracy: 85.1709%, Training Loss: 0.3875%\n",
      "Epoch [33/300], Step [215/225], Training Accuracy: 85.2035%, Training Loss: 0.3867%\n",
      "Epoch [33/300], Step [216/225], Training Accuracy: 85.1707%, Training Loss: 0.3870%\n",
      "Epoch [33/300], Step [217/225], Training Accuracy: 85.1743%, Training Loss: 0.3868%\n",
      "Epoch [33/300], Step [218/225], Training Accuracy: 85.1562%, Training Loss: 0.3870%\n",
      "Epoch [33/300], Step [219/225], Training Accuracy: 85.1527%, Training Loss: 0.3872%\n",
      "Epoch [33/300], Step [220/225], Training Accuracy: 85.1420%, Training Loss: 0.3870%\n",
      "Epoch [33/300], Step [221/225], Training Accuracy: 85.1032%, Training Loss: 0.3879%\n",
      "Epoch [33/300], Step [222/225], Training Accuracy: 85.1070%, Training Loss: 0.3880%\n",
      "Epoch [33/300], Step [223/225], Training Accuracy: 85.1177%, Training Loss: 0.3880%\n",
      "Epoch [33/300], Step [224/225], Training Accuracy: 85.1283%, Training Loss: 0.3875%\n",
      "Epoch [33/300], Step [225/225], Training Accuracy: 85.1167%, Training Loss: 0.3872%\n",
      "Epoch [34/300], Step [1/225], Training Accuracy: 87.5000%, Training Loss: 0.3531%\n",
      "Epoch [34/300], Step [2/225], Training Accuracy: 85.9375%, Training Loss: 0.3526%\n",
      "Epoch [34/300], Step [3/225], Training Accuracy: 84.8958%, Training Loss: 0.4315%\n",
      "Epoch [34/300], Step [4/225], Training Accuracy: 85.9375%, Training Loss: 0.3920%\n",
      "Epoch [34/300], Step [5/225], Training Accuracy: 85.6250%, Training Loss: 0.3867%\n",
      "Epoch [34/300], Step [6/225], Training Accuracy: 85.1562%, Training Loss: 0.4021%\n",
      "Epoch [34/300], Step [7/225], Training Accuracy: 84.5982%, Training Loss: 0.4042%\n",
      "Epoch [34/300], Step [8/225], Training Accuracy: 84.7656%, Training Loss: 0.3948%\n",
      "Epoch [34/300], Step [9/225], Training Accuracy: 84.8958%, Training Loss: 0.3835%\n",
      "Epoch [34/300], Step [10/225], Training Accuracy: 84.3750%, Training Loss: 0.3917%\n",
      "Epoch [34/300], Step [11/225], Training Accuracy: 83.9489%, Training Loss: 0.3946%\n",
      "Epoch [34/300], Step [12/225], Training Accuracy: 84.2448%, Training Loss: 0.3901%\n",
      "Epoch [34/300], Step [13/225], Training Accuracy: 84.7356%, Training Loss: 0.3844%\n",
      "Epoch [34/300], Step [14/225], Training Accuracy: 84.7098%, Training Loss: 0.3927%\n",
      "Epoch [34/300], Step [15/225], Training Accuracy: 85.4167%, Training Loss: 0.3814%\n",
      "Epoch [34/300], Step [16/225], Training Accuracy: 84.9609%, Training Loss: 0.3914%\n",
      "Epoch [34/300], Step [17/225], Training Accuracy: 84.7426%, Training Loss: 0.3955%\n",
      "Epoch [34/300], Step [18/225], Training Accuracy: 84.3750%, Training Loss: 0.4072%\n",
      "Epoch [34/300], Step [19/225], Training Accuracy: 84.7039%, Training Loss: 0.3984%\n",
      "Epoch [34/300], Step [20/225], Training Accuracy: 84.9219%, Training Loss: 0.3945%\n",
      "Epoch [34/300], Step [21/225], Training Accuracy: 85.0446%, Training Loss: 0.3966%\n",
      "Epoch [34/300], Step [22/225], Training Accuracy: 84.8722%, Training Loss: 0.4004%\n",
      "Epoch [34/300], Step [23/225], Training Accuracy: 84.6467%, Training Loss: 0.4041%\n",
      "Epoch [34/300], Step [24/225], Training Accuracy: 84.4401%, Training Loss: 0.4055%\n",
      "Epoch [34/300], Step [25/225], Training Accuracy: 84.5000%, Training Loss: 0.4016%\n",
      "Epoch [34/300], Step [26/225], Training Accuracy: 84.4351%, Training Loss: 0.4011%\n",
      "Epoch [34/300], Step [27/225], Training Accuracy: 84.4907%, Training Loss: 0.3974%\n",
      "Epoch [34/300], Step [28/225], Training Accuracy: 84.6540%, Training Loss: 0.3953%\n",
      "Epoch [34/300], Step [29/225], Training Accuracy: 84.5905%, Training Loss: 0.3929%\n",
      "Epoch [34/300], Step [30/225], Training Accuracy: 84.3750%, Training Loss: 0.3941%\n",
      "Epoch [34/300], Step [31/225], Training Accuracy: 84.3246%, Training Loss: 0.3954%\n",
      "Epoch [34/300], Step [32/225], Training Accuracy: 84.4727%, Training Loss: 0.3917%\n",
      "Epoch [34/300], Step [33/225], Training Accuracy: 84.7064%, Training Loss: 0.3902%\n",
      "Epoch [34/300], Step [34/225], Training Accuracy: 84.9265%, Training Loss: 0.3873%\n",
      "Epoch [34/300], Step [35/225], Training Accuracy: 85.0446%, Training Loss: 0.3857%\n",
      "Epoch [34/300], Step [36/225], Training Accuracy: 85.2431%, Training Loss: 0.3833%\n",
      "Epoch [34/300], Step [37/225], Training Accuracy: 85.0507%, Training Loss: 0.3868%\n",
      "Epoch [34/300], Step [38/225], Training Accuracy: 85.1151%, Training Loss: 0.3862%\n",
      "Epoch [34/300], Step [39/225], Training Accuracy: 85.0962%, Training Loss: 0.3860%\n",
      "Epoch [34/300], Step [40/225], Training Accuracy: 85.2734%, Training Loss: 0.3840%\n",
      "Epoch [34/300], Step [41/225], Training Accuracy: 85.3277%, Training Loss: 0.3833%\n",
      "Epoch [34/300], Step [42/225], Training Accuracy: 85.2307%, Training Loss: 0.3842%\n",
      "Epoch [34/300], Step [43/225], Training Accuracy: 85.0654%, Training Loss: 0.3886%\n",
      "Epoch [34/300], Step [44/225], Training Accuracy: 85.0497%, Training Loss: 0.3883%\n",
      "Epoch [34/300], Step [45/225], Training Accuracy: 84.9306%, Training Loss: 0.3900%\n",
      "Epoch [34/300], Step [46/225], Training Accuracy: 84.8845%, Training Loss: 0.3921%\n",
      "Epoch [34/300], Step [47/225], Training Accuracy: 84.7739%, Training Loss: 0.3929%\n",
      "Epoch [34/300], Step [48/225], Training Accuracy: 84.7331%, Training Loss: 0.3946%\n",
      "Epoch [34/300], Step [49/225], Training Accuracy: 84.6301%, Training Loss: 0.3958%\n",
      "Epoch [34/300], Step [50/225], Training Accuracy: 84.5938%, Training Loss: 0.3952%\n",
      "Epoch [34/300], Step [51/225], Training Accuracy: 84.6201%, Training Loss: 0.3944%\n",
      "Epoch [34/300], Step [52/225], Training Accuracy: 84.5553%, Training Loss: 0.3936%\n",
      "Epoch [34/300], Step [53/225], Training Accuracy: 84.3160%, Training Loss: 0.3988%\n",
      "Epoch [34/300], Step [54/225], Training Accuracy: 84.1435%, Training Loss: 0.4011%\n",
      "Epoch [34/300], Step [55/225], Training Accuracy: 84.1477%, Training Loss: 0.3996%\n",
      "Epoch [34/300], Step [56/225], Training Accuracy: 84.1797%, Training Loss: 0.3988%\n",
      "Epoch [34/300], Step [57/225], Training Accuracy: 84.0735%, Training Loss: 0.4008%\n",
      "Epoch [34/300], Step [58/225], Training Accuracy: 84.0517%, Training Loss: 0.4008%\n",
      "Epoch [34/300], Step [59/225], Training Accuracy: 83.9778%, Training Loss: 0.4031%\n",
      "Epoch [34/300], Step [60/225], Training Accuracy: 84.0625%, Training Loss: 0.4021%\n",
      "Epoch [34/300], Step [61/225], Training Accuracy: 84.0164%, Training Loss: 0.4024%\n",
      "Epoch [34/300], Step [62/225], Training Accuracy: 84.1230%, Training Loss: 0.4003%\n",
      "Epoch [34/300], Step [63/225], Training Accuracy: 84.1766%, Training Loss: 0.4004%\n",
      "Epoch [34/300], Step [64/225], Training Accuracy: 84.1553%, Training Loss: 0.4004%\n",
      "Epoch [34/300], Step [65/225], Training Accuracy: 84.3029%, Training Loss: 0.3975%\n",
      "Epoch [34/300], Step [66/225], Training Accuracy: 84.3277%, Training Loss: 0.3971%\n",
      "Epoch [34/300], Step [67/225], Training Accuracy: 84.3050%, Training Loss: 0.3974%\n",
      "Epoch [34/300], Step [68/225], Training Accuracy: 84.3750%, Training Loss: 0.3968%\n",
      "Epoch [34/300], Step [69/225], Training Accuracy: 84.3750%, Training Loss: 0.3955%\n",
      "Epoch [34/300], Step [70/225], Training Accuracy: 84.3750%, Training Loss: 0.3964%\n",
      "Epoch [34/300], Step [71/225], Training Accuracy: 84.4190%, Training Loss: 0.3953%\n",
      "Epoch [34/300], Step [72/225], Training Accuracy: 84.3750%, Training Loss: 0.3956%\n",
      "Epoch [34/300], Step [73/225], Training Accuracy: 84.3108%, Training Loss: 0.3974%\n",
      "Epoch [34/300], Step [74/225], Training Accuracy: 84.2694%, Training Loss: 0.3989%\n",
      "Epoch [34/300], Step [75/225], Training Accuracy: 84.3542%, Training Loss: 0.3976%\n",
      "Epoch [34/300], Step [76/225], Training Accuracy: 84.3339%, Training Loss: 0.3982%\n",
      "Epoch [34/300], Step [77/225], Training Accuracy: 84.3547%, Training Loss: 0.3976%\n",
      "Epoch [34/300], Step [78/225], Training Accuracy: 84.3750%, Training Loss: 0.3979%\n",
      "Epoch [34/300], Step [79/225], Training Accuracy: 84.3354%, Training Loss: 0.3985%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/300], Step [80/225], Training Accuracy: 84.2773%, Training Loss: 0.3995%\n",
      "Epoch [34/300], Step [81/225], Training Accuracy: 84.2400%, Training Loss: 0.3995%\n",
      "Epoch [34/300], Step [82/225], Training Accuracy: 84.2416%, Training Loss: 0.4005%\n",
      "Epoch [34/300], Step [83/225], Training Accuracy: 84.2244%, Training Loss: 0.4004%\n",
      "Epoch [34/300], Step [84/225], Training Accuracy: 84.1704%, Training Loss: 0.4010%\n",
      "Epoch [34/300], Step [85/225], Training Accuracy: 84.1912%, Training Loss: 0.4006%\n",
      "Epoch [34/300], Step [86/225], Training Accuracy: 84.1751%, Training Loss: 0.4009%\n",
      "Epoch [34/300], Step [87/225], Training Accuracy: 84.1774%, Training Loss: 0.4007%\n",
      "Epoch [34/300], Step [88/225], Training Accuracy: 84.2152%, Training Loss: 0.3999%\n",
      "Epoch [34/300], Step [89/225], Training Accuracy: 84.3223%, Training Loss: 0.3986%\n",
      "Epoch [34/300], Step [90/225], Training Accuracy: 84.3229%, Training Loss: 0.3984%\n",
      "Epoch [34/300], Step [91/225], Training Accuracy: 84.3063%, Training Loss: 0.3989%\n",
      "Epoch [34/300], Step [92/225], Training Accuracy: 84.3240%, Training Loss: 0.3989%\n",
      "Epoch [34/300], Step [93/225], Training Accuracy: 84.2742%, Training Loss: 0.3998%\n",
      "Epoch [34/300], Step [94/225], Training Accuracy: 84.2586%, Training Loss: 0.3994%\n",
      "Epoch [34/300], Step [95/225], Training Accuracy: 84.2270%, Training Loss: 0.4002%\n",
      "Epoch [34/300], Step [96/225], Training Accuracy: 84.3099%, Training Loss: 0.3987%\n",
      "Epoch [34/300], Step [97/225], Training Accuracy: 84.2945%, Training Loss: 0.3987%\n",
      "Epoch [34/300], Step [98/225], Training Accuracy: 84.2793%, Training Loss: 0.3991%\n",
      "Epoch [34/300], Step [99/225], Training Accuracy: 84.3277%, Training Loss: 0.3985%\n",
      "Epoch [34/300], Step [100/225], Training Accuracy: 84.3438%, Training Loss: 0.3979%\n",
      "Epoch [34/300], Step [101/225], Training Accuracy: 84.4214%, Training Loss: 0.3965%\n",
      "Epoch [34/300], Step [102/225], Training Accuracy: 84.3903%, Training Loss: 0.3981%\n",
      "Epoch [34/300], Step [103/225], Training Accuracy: 84.3598%, Training Loss: 0.4000%\n",
      "Epoch [34/300], Step [104/225], Training Accuracy: 84.4351%, Training Loss: 0.3990%\n",
      "Epoch [34/300], Step [105/225], Training Accuracy: 84.4940%, Training Loss: 0.3977%\n",
      "Epoch [34/300], Step [106/225], Training Accuracy: 84.4782%, Training Loss: 0.3976%\n",
      "Epoch [34/300], Step [107/225], Training Accuracy: 84.4188%, Training Loss: 0.3982%\n",
      "Epoch [34/300], Step [108/225], Training Accuracy: 84.4184%, Training Loss: 0.3976%\n",
      "Epoch [34/300], Step [109/225], Training Accuracy: 84.4897%, Training Loss: 0.3964%\n",
      "Epoch [34/300], Step [110/225], Training Accuracy: 84.5597%, Training Loss: 0.3951%\n",
      "Epoch [34/300], Step [111/225], Training Accuracy: 84.5861%, Training Loss: 0.3949%\n",
      "Epoch [34/300], Step [112/225], Training Accuracy: 84.6122%, Training Loss: 0.3946%\n",
      "Epoch [34/300], Step [113/225], Training Accuracy: 84.6930%, Training Loss: 0.3933%\n",
      "Epoch [34/300], Step [114/225], Training Accuracy: 84.6902%, Training Loss: 0.3932%\n",
      "Epoch [34/300], Step [115/225], Training Accuracy: 84.6332%, Training Loss: 0.3934%\n",
      "Epoch [34/300], Step [116/225], Training Accuracy: 84.6579%, Training Loss: 0.3928%\n",
      "Epoch [34/300], Step [117/225], Training Accuracy: 84.6822%, Training Loss: 0.3925%\n",
      "Epoch [34/300], Step [118/225], Training Accuracy: 84.6531%, Training Loss: 0.3941%\n",
      "Epoch [34/300], Step [119/225], Training Accuracy: 84.6245%, Training Loss: 0.3944%\n",
      "Epoch [34/300], Step [120/225], Training Accuracy: 84.7005%, Training Loss: 0.3929%\n",
      "Epoch [34/300], Step [121/225], Training Accuracy: 84.7237%, Training Loss: 0.3927%\n",
      "Epoch [34/300], Step [122/225], Training Accuracy: 84.7720%, Training Loss: 0.3917%\n",
      "Epoch [34/300], Step [123/225], Training Accuracy: 84.8577%, Training Loss: 0.3907%\n",
      "Epoch [34/300], Step [124/225], Training Accuracy: 84.8286%, Training Loss: 0.3907%\n",
      "Epoch [34/300], Step [125/225], Training Accuracy: 84.8625%, Training Loss: 0.3900%\n",
      "Epoch [34/300], Step [126/225], Training Accuracy: 84.9082%, Training Loss: 0.3890%\n",
      "Epoch [34/300], Step [127/225], Training Accuracy: 84.9163%, Training Loss: 0.3891%\n",
      "Epoch [34/300], Step [128/225], Training Accuracy: 84.9121%, Training Loss: 0.3889%\n",
      "Epoch [34/300], Step [129/225], Training Accuracy: 84.9443%, Training Loss: 0.3880%\n",
      "Epoch [34/300], Step [130/225], Training Accuracy: 84.9038%, Training Loss: 0.3880%\n",
      "Epoch [34/300], Step [131/225], Training Accuracy: 84.9117%, Training Loss: 0.3880%\n",
      "Epoch [34/300], Step [132/225], Training Accuracy: 84.9432%, Training Loss: 0.3876%\n",
      "Epoch [34/300], Step [133/225], Training Accuracy: 84.9742%, Training Loss: 0.3868%\n",
      "Epoch [34/300], Step [134/225], Training Accuracy: 84.9813%, Training Loss: 0.3870%\n",
      "Epoch [34/300], Step [135/225], Training Accuracy: 85.0347%, Training Loss: 0.3858%\n",
      "Epoch [34/300], Step [136/225], Training Accuracy: 85.0414%, Training Loss: 0.3859%\n",
      "Epoch [34/300], Step [137/225], Training Accuracy: 85.0593%, Training Loss: 0.3854%\n",
      "Epoch [34/300], Step [138/225], Training Accuracy: 85.0883%, Training Loss: 0.3848%\n",
      "Epoch [34/300], Step [139/225], Training Accuracy: 85.1057%, Training Loss: 0.3846%\n",
      "Epoch [34/300], Step [140/225], Training Accuracy: 85.1004%, Training Loss: 0.3842%\n",
      "Epoch [34/300], Step [141/225], Training Accuracy: 85.0953%, Training Loss: 0.3850%\n",
      "Epoch [34/300], Step [142/225], Training Accuracy: 85.0902%, Training Loss: 0.3848%\n",
      "Epoch [34/300], Step [143/225], Training Accuracy: 85.0634%, Training Loss: 0.3860%\n",
      "Epoch [34/300], Step [144/225], Training Accuracy: 85.0477%, Training Loss: 0.3860%\n",
      "Epoch [34/300], Step [145/225], Training Accuracy: 85.0647%, Training Loss: 0.3852%\n",
      "Epoch [34/300], Step [146/225], Training Accuracy: 85.1027%, Training Loss: 0.3848%\n",
      "Epoch [34/300], Step [147/225], Training Accuracy: 85.0872%, Training Loss: 0.3853%\n",
      "Epoch [34/300], Step [148/225], Training Accuracy: 85.1246%, Training Loss: 0.3850%\n",
      "Epoch [34/300], Step [149/225], Training Accuracy: 85.1091%, Training Loss: 0.3852%\n",
      "Epoch [34/300], Step [150/225], Training Accuracy: 85.1354%, Training Loss: 0.3845%\n",
      "Epoch [34/300], Step [151/225], Training Accuracy: 85.1718%, Training Loss: 0.3837%\n",
      "Epoch [34/300], Step [152/225], Training Accuracy: 85.2076%, Training Loss: 0.3827%\n",
      "Epoch [34/300], Step [153/225], Training Accuracy: 85.2226%, Training Loss: 0.3823%\n",
      "Epoch [34/300], Step [154/225], Training Accuracy: 85.2171%, Training Loss: 0.3819%\n",
      "Epoch [34/300], Step [155/225], Training Accuracy: 85.2722%, Training Loss: 0.3812%\n",
      "Epoch [34/300], Step [156/225], Training Accuracy: 85.2965%, Training Loss: 0.3806%\n",
      "Epoch [34/300], Step [157/225], Training Accuracy: 85.2807%, Training Loss: 0.3807%\n",
      "Epoch [34/300], Step [158/225], Training Accuracy: 85.2848%, Training Loss: 0.3798%\n",
      "Epoch [34/300], Step [159/225], Training Accuracy: 85.2693%, Training Loss: 0.3794%\n",
      "Epoch [34/300], Step [160/225], Training Accuracy: 85.2832%, Training Loss: 0.3793%\n",
      "Epoch [34/300], Step [161/225], Training Accuracy: 85.3261%, Training Loss: 0.3788%\n",
      "Epoch [34/300], Step [162/225], Training Accuracy: 85.3395%, Training Loss: 0.3782%\n",
      "Epoch [34/300], Step [163/225], Training Accuracy: 85.3336%, Training Loss: 0.3779%\n",
      "Epoch [34/300], Step [164/225], Training Accuracy: 85.3754%, Training Loss: 0.3770%\n",
      "Epoch [34/300], Step [165/225], Training Accuracy: 85.3977%, Training Loss: 0.3770%\n",
      "Epoch [34/300], Step [166/225], Training Accuracy: 85.4104%, Training Loss: 0.3769%\n",
      "Epoch [34/300], Step [167/225], Training Accuracy: 85.4042%, Training Loss: 0.3766%\n",
      "Epoch [34/300], Step [168/225], Training Accuracy: 85.4353%, Training Loss: 0.3759%\n",
      "Epoch [34/300], Step [169/225], Training Accuracy: 85.4197%, Training Loss: 0.3757%\n",
      "Epoch [34/300], Step [170/225], Training Accuracy: 85.4136%, Training Loss: 0.3757%\n",
      "Epoch [34/300], Step [171/225], Training Accuracy: 85.3984%, Training Loss: 0.3759%\n",
      "Epoch [34/300], Step [172/225], Training Accuracy: 85.4106%, Training Loss: 0.3753%\n",
      "Epoch [34/300], Step [173/225], Training Accuracy: 85.4137%, Training Loss: 0.3757%\n",
      "Epoch [34/300], Step [174/225], Training Accuracy: 85.4077%, Training Loss: 0.3755%\n",
      "Epoch [34/300], Step [175/225], Training Accuracy: 85.4375%, Training Loss: 0.3749%\n",
      "Epoch [34/300], Step [176/225], Training Accuracy: 85.4581%, Training Loss: 0.3750%\n",
      "Epoch [34/300], Step [177/225], Training Accuracy: 85.4696%, Training Loss: 0.3746%\n",
      "Epoch [34/300], Step [178/225], Training Accuracy: 85.4459%, Training Loss: 0.3748%\n",
      "Epoch [34/300], Step [179/225], Training Accuracy: 85.4749%, Training Loss: 0.3745%\n",
      "Epoch [34/300], Step [180/225], Training Accuracy: 85.4601%, Training Loss: 0.3749%\n",
      "Epoch [34/300], Step [181/225], Training Accuracy: 85.4195%, Training Loss: 0.3754%\n",
      "Epoch [34/300], Step [182/225], Training Accuracy: 85.4310%, Training Loss: 0.3746%\n",
      "Epoch [34/300], Step [183/225], Training Accuracy: 85.4167%, Training Loss: 0.3749%\n",
      "Epoch [34/300], Step [184/225], Training Accuracy: 85.4195%, Training Loss: 0.3751%\n",
      "Epoch [34/300], Step [185/225], Training Accuracy: 85.4054%, Training Loss: 0.3748%\n",
      "Epoch [34/300], Step [186/225], Training Accuracy: 85.4251%, Training Loss: 0.3743%\n",
      "Epoch [34/300], Step [187/225], Training Accuracy: 85.4779%, Training Loss: 0.3737%\n",
      "Epoch [34/300], Step [188/225], Training Accuracy: 85.5053%, Training Loss: 0.3730%\n",
      "Epoch [34/300], Step [189/225], Training Accuracy: 85.5241%, Training Loss: 0.3727%\n",
      "Epoch [34/300], Step [190/225], Training Accuracy: 85.5099%, Training Loss: 0.3733%\n",
      "Epoch [34/300], Step [191/225], Training Accuracy: 85.5448%, Training Loss: 0.3725%\n",
      "Epoch [34/300], Step [192/225], Training Accuracy: 85.5143%, Training Loss: 0.3728%\n",
      "Epoch [34/300], Step [193/225], Training Accuracy: 85.5084%, Training Loss: 0.3732%\n",
      "Epoch [34/300], Step [194/225], Training Accuracy: 85.5751%, Training Loss: 0.3720%\n",
      "Epoch [34/300], Step [195/225], Training Accuracy: 85.5609%, Training Loss: 0.3724%\n",
      "Epoch [34/300], Step [196/225], Training Accuracy: 85.5788%, Training Loss: 0.3718%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/300], Step [197/225], Training Accuracy: 85.5727%, Training Loss: 0.3718%\n",
      "Epoch [34/300], Step [198/225], Training Accuracy: 85.6061%, Training Loss: 0.3716%\n",
      "Epoch [34/300], Step [199/225], Training Accuracy: 85.6234%, Training Loss: 0.3715%\n",
      "Epoch [34/300], Step [200/225], Training Accuracy: 85.6328%, Training Loss: 0.3712%\n",
      "Epoch [34/300], Step [201/225], Training Accuracy: 85.6576%, Training Loss: 0.3707%\n",
      "Epoch [34/300], Step [202/225], Training Accuracy: 85.6745%, Training Loss: 0.3703%\n",
      "Epoch [34/300], Step [203/225], Training Accuracy: 85.7066%, Training Loss: 0.3698%\n",
      "Epoch [34/300], Step [204/225], Training Accuracy: 85.7001%, Training Loss: 0.3703%\n",
      "Epoch [34/300], Step [205/225], Training Accuracy: 85.6631%, Training Loss: 0.3706%\n",
      "Epoch [34/300], Step [206/225], Training Accuracy: 85.6796%, Training Loss: 0.3704%\n",
      "Epoch [34/300], Step [207/225], Training Accuracy: 85.6960%, Training Loss: 0.3703%\n",
      "Epoch [34/300], Step [208/225], Training Accuracy: 85.7121%, Training Loss: 0.3700%\n",
      "Epoch [34/300], Step [209/225], Training Accuracy: 85.7132%, Training Loss: 0.3701%\n",
      "Epoch [34/300], Step [210/225], Training Accuracy: 85.7143%, Training Loss: 0.3702%\n",
      "Epoch [34/300], Step [211/225], Training Accuracy: 85.6931%, Training Loss: 0.3705%\n",
      "Epoch [34/300], Step [212/225], Training Accuracy: 85.7017%, Training Loss: 0.3707%\n",
      "Epoch [34/300], Step [213/225], Training Accuracy: 85.7321%, Training Loss: 0.3705%\n",
      "Epoch [34/300], Step [214/225], Training Accuracy: 85.7404%, Training Loss: 0.3701%\n",
      "Epoch [34/300], Step [215/225], Training Accuracy: 85.7340%, Training Loss: 0.3701%\n",
      "Epoch [34/300], Step [216/225], Training Accuracy: 85.7277%, Training Loss: 0.3703%\n",
      "Epoch [34/300], Step [217/225], Training Accuracy: 85.7647%, Training Loss: 0.3696%\n",
      "Epoch [34/300], Step [218/225], Training Accuracy: 85.7583%, Training Loss: 0.3699%\n",
      "Epoch [34/300], Step [219/225], Training Accuracy: 85.7449%, Training Loss: 0.3702%\n",
      "Epoch [34/300], Step [220/225], Training Accuracy: 85.7599%, Training Loss: 0.3696%\n",
      "Epoch [34/300], Step [221/225], Training Accuracy: 85.7466%, Training Loss: 0.3700%\n",
      "Epoch [34/300], Step [222/225], Training Accuracy: 85.7123%, Training Loss: 0.3705%\n",
      "Epoch [34/300], Step [223/225], Training Accuracy: 85.7483%, Training Loss: 0.3696%\n",
      "Epoch [34/300], Step [224/225], Training Accuracy: 85.7701%, Training Loss: 0.3691%\n",
      "Epoch [34/300], Step [225/225], Training Accuracy: 85.7768%, Training Loss: 0.3687%\n",
      "Epoch [35/300], Step [1/225], Training Accuracy: 78.1250%, Training Loss: 0.5065%\n",
      "Epoch [35/300], Step [2/225], Training Accuracy: 85.1562%, Training Loss: 0.3769%\n",
      "Epoch [35/300], Step [3/225], Training Accuracy: 82.8125%, Training Loss: 0.4401%\n",
      "Epoch [35/300], Step [4/225], Training Accuracy: 82.0312%, Training Loss: 0.4240%\n",
      "Epoch [35/300], Step [5/225], Training Accuracy: 82.8125%, Training Loss: 0.4037%\n",
      "Epoch [35/300], Step [6/225], Training Accuracy: 83.5938%, Training Loss: 0.4020%\n",
      "Epoch [35/300], Step [7/225], Training Accuracy: 82.5893%, Training Loss: 0.4077%\n",
      "Epoch [35/300], Step [8/225], Training Accuracy: 83.0078%, Training Loss: 0.4055%\n",
      "Epoch [35/300], Step [9/225], Training Accuracy: 83.3333%, Training Loss: 0.3893%\n",
      "Epoch [35/300], Step [10/225], Training Accuracy: 83.9062%, Training Loss: 0.3796%\n",
      "Epoch [35/300], Step [11/225], Training Accuracy: 84.9432%, Training Loss: 0.3670%\n",
      "Epoch [35/300], Step [12/225], Training Accuracy: 85.2865%, Training Loss: 0.3618%\n",
      "Epoch [35/300], Step [13/225], Training Accuracy: 85.0962%, Training Loss: 0.3608%\n",
      "Epoch [35/300], Step [14/225], Training Accuracy: 84.9330%, Training Loss: 0.3643%\n",
      "Epoch [35/300], Step [15/225], Training Accuracy: 85.0000%, Training Loss: 0.3629%\n",
      "Epoch [35/300], Step [16/225], Training Accuracy: 84.8633%, Training Loss: 0.3650%\n",
      "Epoch [35/300], Step [17/225], Training Accuracy: 84.7426%, Training Loss: 0.3712%\n",
      "Epoch [35/300], Step [18/225], Training Accuracy: 84.8958%, Training Loss: 0.3709%\n",
      "Epoch [35/300], Step [19/225], Training Accuracy: 85.2796%, Training Loss: 0.3641%\n",
      "Epoch [35/300], Step [20/225], Training Accuracy: 85.3906%, Training Loss: 0.3586%\n",
      "Epoch [35/300], Step [21/225], Training Accuracy: 85.4167%, Training Loss: 0.3558%\n",
      "Epoch [35/300], Step [22/225], Training Accuracy: 85.3693%, Training Loss: 0.3659%\n",
      "Epoch [35/300], Step [23/225], Training Accuracy: 85.0543%, Training Loss: 0.3696%\n",
      "Epoch [35/300], Step [24/225], Training Accuracy: 84.7656%, Training Loss: 0.3739%\n",
      "Epoch [35/300], Step [25/225], Training Accuracy: 85.1250%, Training Loss: 0.3658%\n",
      "Epoch [35/300], Step [26/225], Training Accuracy: 85.2764%, Training Loss: 0.3622%\n",
      "Epoch [35/300], Step [27/225], Training Accuracy: 85.1852%, Training Loss: 0.3627%\n",
      "Epoch [35/300], Step [28/225], Training Accuracy: 85.4911%, Training Loss: 0.3571%\n",
      "Epoch [35/300], Step [29/225], Training Accuracy: 85.6142%, Training Loss: 0.3550%\n",
      "Epoch [35/300], Step [30/225], Training Accuracy: 85.3125%, Training Loss: 0.3599%\n",
      "Epoch [35/300], Step [31/225], Training Accuracy: 85.3327%, Training Loss: 0.3604%\n",
      "Epoch [35/300], Step [32/225], Training Accuracy: 85.3027%, Training Loss: 0.3611%\n",
      "Epoch [35/300], Step [33/225], Training Accuracy: 85.2746%, Training Loss: 0.3621%\n",
      "Epoch [35/300], Step [34/225], Training Accuracy: 85.4320%, Training Loss: 0.3590%\n",
      "Epoch [35/300], Step [35/225], Training Accuracy: 85.4464%, Training Loss: 0.3580%\n",
      "Epoch [35/300], Step [36/225], Training Accuracy: 85.5469%, Training Loss: 0.3558%\n",
      "Epoch [35/300], Step [37/225], Training Accuracy: 85.5997%, Training Loss: 0.3576%\n",
      "Epoch [35/300], Step [38/225], Training Accuracy: 85.4852%, Training Loss: 0.3581%\n",
      "Epoch [35/300], Step [39/225], Training Accuracy: 85.4968%, Training Loss: 0.3591%\n",
      "Epoch [35/300], Step [40/225], Training Accuracy: 85.4688%, Training Loss: 0.3598%\n",
      "Epoch [35/300], Step [41/225], Training Accuracy: 85.4802%, Training Loss: 0.3592%\n",
      "Epoch [35/300], Step [42/225], Training Accuracy: 85.5283%, Training Loss: 0.3593%\n",
      "Epoch [35/300], Step [43/225], Training Accuracy: 85.4651%, Training Loss: 0.3597%\n",
      "Epoch [35/300], Step [44/225], Training Accuracy: 85.5824%, Training Loss: 0.3583%\n",
      "Epoch [35/300], Step [45/225], Training Accuracy: 85.6944%, Training Loss: 0.3558%\n",
      "Epoch [35/300], Step [46/225], Training Accuracy: 85.8696%, Training Loss: 0.3526%\n",
      "Epoch [35/300], Step [47/225], Training Accuracy: 85.8045%, Training Loss: 0.3537%\n",
      "Epoch [35/300], Step [48/225], Training Accuracy: 85.9375%, Training Loss: 0.3527%\n",
      "Epoch [35/300], Step [49/225], Training Accuracy: 86.1288%, Training Loss: 0.3505%\n",
      "Epoch [35/300], Step [50/225], Training Accuracy: 86.0312%, Training Loss: 0.3526%\n",
      "Epoch [35/300], Step [51/225], Training Accuracy: 86.0907%, Training Loss: 0.3504%\n",
      "Epoch [35/300], Step [52/225], Training Accuracy: 86.2380%, Training Loss: 0.3477%\n",
      "Epoch [35/300], Step [53/225], Training Accuracy: 86.2618%, Training Loss: 0.3477%\n",
      "Epoch [35/300], Step [54/225], Training Accuracy: 86.2269%, Training Loss: 0.3495%\n",
      "Epoch [35/300], Step [55/225], Training Accuracy: 86.2784%, Training Loss: 0.3486%\n",
      "Epoch [35/300], Step [56/225], Training Accuracy: 86.2444%, Training Loss: 0.3484%\n",
      "Epoch [35/300], Step [57/225], Training Accuracy: 86.2664%, Training Loss: 0.3479%\n",
      "Epoch [35/300], Step [58/225], Training Accuracy: 86.2069%, Training Loss: 0.3488%\n",
      "Epoch [35/300], Step [59/225], Training Accuracy: 86.1494%, Training Loss: 0.3506%\n",
      "Epoch [35/300], Step [60/225], Training Accuracy: 86.1198%, Training Loss: 0.3504%\n",
      "Epoch [35/300], Step [61/225], Training Accuracy: 86.1680%, Training Loss: 0.3504%\n",
      "Epoch [35/300], Step [62/225], Training Accuracy: 86.1895%, Training Loss: 0.3510%\n",
      "Epoch [35/300], Step [63/225], Training Accuracy: 86.1855%, Training Loss: 0.3512%\n",
      "Epoch [35/300], Step [64/225], Training Accuracy: 86.1328%, Training Loss: 0.3512%\n",
      "Epoch [35/300], Step [65/225], Training Accuracy: 86.1779%, Training Loss: 0.3497%\n",
      "Epoch [35/300], Step [66/225], Training Accuracy: 86.2216%, Training Loss: 0.3497%\n",
      "Epoch [35/300], Step [67/225], Training Accuracy: 86.1241%, Training Loss: 0.3508%\n",
      "Epoch [35/300], Step [68/225], Training Accuracy: 86.0754%, Training Loss: 0.3523%\n",
      "Epoch [35/300], Step [69/225], Training Accuracy: 86.1413%, Training Loss: 0.3521%\n",
      "Epoch [35/300], Step [70/225], Training Accuracy: 86.2054%, Training Loss: 0.3507%\n",
      "Epoch [35/300], Step [71/225], Training Accuracy: 86.2676%, Training Loss: 0.3496%\n",
      "Epoch [35/300], Step [72/225], Training Accuracy: 86.2847%, Training Loss: 0.3493%\n",
      "Epoch [35/300], Step [73/225], Training Accuracy: 86.3228%, Training Loss: 0.3495%\n",
      "Epoch [35/300], Step [74/225], Training Accuracy: 86.1909%, Training Loss: 0.3514%\n",
      "Epoch [35/300], Step [75/225], Training Accuracy: 86.2500%, Training Loss: 0.3502%\n",
      "Epoch [35/300], Step [76/225], Training Accuracy: 86.2870%, Training Loss: 0.3503%\n",
      "Epoch [35/300], Step [77/225], Training Accuracy: 86.3028%, Training Loss: 0.3492%\n",
      "Epoch [35/300], Step [78/225], Training Accuracy: 86.3582%, Training Loss: 0.3478%\n",
      "Epoch [35/300], Step [79/225], Training Accuracy: 86.3924%, Training Loss: 0.3471%\n",
      "Epoch [35/300], Step [80/225], Training Accuracy: 86.3477%, Training Loss: 0.3482%\n",
      "Epoch [35/300], Step [81/225], Training Accuracy: 86.3812%, Training Loss: 0.3471%\n",
      "Epoch [35/300], Step [82/225], Training Accuracy: 86.3948%, Training Loss: 0.3469%\n",
      "Epoch [35/300], Step [83/225], Training Accuracy: 86.3893%, Training Loss: 0.3471%\n",
      "Epoch [35/300], Step [84/225], Training Accuracy: 86.4955%, Training Loss: 0.3457%\n",
      "Epoch [35/300], Step [85/225], Training Accuracy: 86.5257%, Training Loss: 0.3461%\n",
      "Epoch [35/300], Step [86/225], Training Accuracy: 86.4826%, Training Loss: 0.3473%\n",
      "Epoch [35/300], Step [87/225], Training Accuracy: 86.4763%, Training Loss: 0.3477%\n",
      "Epoch [35/300], Step [88/225], Training Accuracy: 86.5057%, Training Loss: 0.3474%\n",
      "Epoch [35/300], Step [89/225], Training Accuracy: 86.4817%, Training Loss: 0.3471%\n",
      "Epoch [35/300], Step [90/225], Training Accuracy: 86.4931%, Training Loss: 0.3479%\n",
      "Epoch [35/300], Step [91/225], Training Accuracy: 86.5041%, Training Loss: 0.3470%\n",
      "Epoch [35/300], Step [92/225], Training Accuracy: 86.5659%, Training Loss: 0.3458%\n",
      "Epoch [35/300], Step [93/225], Training Accuracy: 86.5759%, Training Loss: 0.3460%\n",
      "Epoch [35/300], Step [94/225], Training Accuracy: 86.6190%, Training Loss: 0.3450%\n",
      "Epoch [35/300], Step [95/225], Training Accuracy: 86.6447%, Training Loss: 0.3458%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/300], Step [96/225], Training Accuracy: 86.6862%, Training Loss: 0.3448%\n",
      "Epoch [35/300], Step [97/225], Training Accuracy: 86.6463%, Training Loss: 0.3454%\n",
      "Epoch [35/300], Step [98/225], Training Accuracy: 86.6390%, Training Loss: 0.3459%\n",
      "Epoch [35/300], Step [99/225], Training Accuracy: 86.6477%, Training Loss: 0.3456%\n",
      "Epoch [35/300], Step [100/225], Training Accuracy: 86.6719%, Training Loss: 0.3450%\n",
      "Epoch [35/300], Step [101/225], Training Accuracy: 86.6337%, Training Loss: 0.3452%\n",
      "Epoch [35/300], Step [102/225], Training Accuracy: 86.5962%, Training Loss: 0.3460%\n",
      "Epoch [35/300], Step [103/225], Training Accuracy: 86.6353%, Training Loss: 0.3455%\n",
      "Epoch [35/300], Step [104/225], Training Accuracy: 86.5835%, Training Loss: 0.3458%\n",
      "Epoch [35/300], Step [105/225], Training Accuracy: 86.5625%, Training Loss: 0.3461%\n",
      "Epoch [35/300], Step [106/225], Training Accuracy: 86.5419%, Training Loss: 0.3473%\n",
      "Epoch [35/300], Step [107/225], Training Accuracy: 86.5070%, Training Loss: 0.3474%\n",
      "Epoch [35/300], Step [108/225], Training Accuracy: 86.4728%, Training Loss: 0.3478%\n",
      "Epoch [35/300], Step [109/225], Training Accuracy: 86.4679%, Training Loss: 0.3482%\n",
      "Epoch [35/300], Step [110/225], Training Accuracy: 86.4489%, Training Loss: 0.3483%\n",
      "Epoch [35/300], Step [111/225], Training Accuracy: 86.5146%, Training Loss: 0.3481%\n",
      "Epoch [35/300], Step [112/225], Training Accuracy: 86.5653%, Training Loss: 0.3474%\n",
      "Epoch [35/300], Step [113/225], Training Accuracy: 86.5321%, Training Loss: 0.3479%\n",
      "Epoch [35/300], Step [114/225], Training Accuracy: 86.5543%, Training Loss: 0.3478%\n",
      "Epoch [35/300], Step [115/225], Training Accuracy: 86.5625%, Training Loss: 0.3475%\n",
      "Epoch [35/300], Step [116/225], Training Accuracy: 86.5706%, Training Loss: 0.3484%\n",
      "Epoch [35/300], Step [117/225], Training Accuracy: 86.5385%, Training Loss: 0.3486%\n",
      "Epoch [35/300], Step [118/225], Training Accuracy: 86.5069%, Training Loss: 0.3485%\n",
      "Epoch [35/300], Step [119/225], Training Accuracy: 86.4890%, Training Loss: 0.3493%\n",
      "Epoch [35/300], Step [120/225], Training Accuracy: 86.5495%, Training Loss: 0.3485%\n",
      "Epoch [35/300], Step [121/225], Training Accuracy: 86.5315%, Training Loss: 0.3484%\n",
      "Epoch [35/300], Step [122/225], Training Accuracy: 86.5651%, Training Loss: 0.3479%\n",
      "Epoch [35/300], Step [123/225], Training Accuracy: 86.5981%, Training Loss: 0.3472%\n",
      "Epoch [35/300], Step [124/225], Training Accuracy: 86.6305%, Training Loss: 0.3471%\n",
      "Epoch [35/300], Step [125/225], Training Accuracy: 86.6250%, Training Loss: 0.3470%\n",
      "Epoch [35/300], Step [126/225], Training Accuracy: 86.5947%, Training Loss: 0.3469%\n",
      "Epoch [35/300], Step [127/225], Training Accuracy: 86.6142%, Training Loss: 0.3468%\n",
      "Epoch [35/300], Step [128/225], Training Accuracy: 86.5845%, Training Loss: 0.3475%\n",
      "Epoch [35/300], Step [129/225], Training Accuracy: 86.6279%, Training Loss: 0.3478%\n",
      "Epoch [35/300], Step [130/225], Training Accuracy: 86.5625%, Training Loss: 0.3484%\n",
      "Epoch [35/300], Step [131/225], Training Accuracy: 86.6054%, Training Loss: 0.3477%\n",
      "Epoch [35/300], Step [132/225], Training Accuracy: 86.6122%, Training Loss: 0.3475%\n",
      "Epoch [35/300], Step [133/225], Training Accuracy: 86.6306%, Training Loss: 0.3469%\n",
      "Epoch [35/300], Step [134/225], Training Accuracy: 86.6138%, Training Loss: 0.3466%\n",
      "Epoch [35/300], Step [135/225], Training Accuracy: 86.6667%, Training Loss: 0.3457%\n",
      "Epoch [35/300], Step [136/225], Training Accuracy: 86.6153%, Training Loss: 0.3473%\n",
      "Epoch [35/300], Step [137/225], Training Accuracy: 86.5876%, Training Loss: 0.3467%\n",
      "Epoch [35/300], Step [138/225], Training Accuracy: 86.6168%, Training Loss: 0.3465%\n",
      "Epoch [35/300], Step [139/225], Training Accuracy: 86.6120%, Training Loss: 0.3462%\n",
      "Epoch [35/300], Step [140/225], Training Accuracy: 86.6071%, Training Loss: 0.3466%\n",
      "Epoch [35/300], Step [141/225], Training Accuracy: 86.5581%, Training Loss: 0.3477%\n",
      "Epoch [35/300], Step [142/225], Training Accuracy: 86.5867%, Training Loss: 0.3472%\n",
      "Epoch [35/300], Step [143/225], Training Accuracy: 86.5822%, Training Loss: 0.3469%\n",
      "Epoch [35/300], Step [144/225], Training Accuracy: 86.5668%, Training Loss: 0.3469%\n",
      "Epoch [35/300], Step [145/225], Training Accuracy: 86.6056%, Training Loss: 0.3467%\n",
      "Epoch [35/300], Step [146/225], Training Accuracy: 86.6438%, Training Loss: 0.3463%\n",
      "Epoch [35/300], Step [147/225], Training Accuracy: 86.6178%, Training Loss: 0.3470%\n",
      "Epoch [35/300], Step [148/225], Training Accuracy: 86.6343%, Training Loss: 0.3469%\n",
      "Epoch [35/300], Step [149/225], Training Accuracy: 86.6611%, Training Loss: 0.3468%\n",
      "Epoch [35/300], Step [150/225], Training Accuracy: 86.6875%, Training Loss: 0.3463%\n",
      "Epoch [35/300], Step [151/225], Training Accuracy: 86.7343%, Training Loss: 0.3462%\n",
      "Epoch [35/300], Step [152/225], Training Accuracy: 86.7907%, Training Loss: 0.3453%\n",
      "Epoch [35/300], Step [153/225], Training Accuracy: 86.8056%, Training Loss: 0.3450%\n",
      "Epoch [35/300], Step [154/225], Training Accuracy: 86.7390%, Training Loss: 0.3456%\n",
      "Epoch [35/300], Step [155/225], Training Accuracy: 86.7440%, Training Loss: 0.3454%\n",
      "Epoch [35/300], Step [156/225], Training Accuracy: 86.7288%, Training Loss: 0.3457%\n",
      "Epoch [35/300], Step [157/225], Training Accuracy: 86.7436%, Training Loss: 0.3457%\n",
      "Epoch [35/300], Step [158/225], Training Accuracy: 86.7979%, Training Loss: 0.3447%\n",
      "Epoch [35/300], Step [159/225], Training Accuracy: 86.8318%, Training Loss: 0.3440%\n",
      "Epoch [35/300], Step [160/225], Training Accuracy: 86.8750%, Training Loss: 0.3431%\n",
      "Epoch [35/300], Step [161/225], Training Accuracy: 86.9177%, Training Loss: 0.3424%\n",
      "Epoch [35/300], Step [162/225], Training Accuracy: 86.9213%, Training Loss: 0.3424%\n",
      "Epoch [35/300], Step [163/225], Training Accuracy: 86.8865%, Training Loss: 0.3427%\n",
      "Epoch [35/300], Step [164/225], Training Accuracy: 86.8998%, Training Loss: 0.3422%\n",
      "Epoch [35/300], Step [165/225], Training Accuracy: 86.9318%, Training Loss: 0.3422%\n",
      "Epoch [35/300], Step [166/225], Training Accuracy: 86.9070%, Training Loss: 0.3422%\n",
      "Epoch [35/300], Step [167/225], Training Accuracy: 86.8731%, Training Loss: 0.3431%\n",
      "Epoch [35/300], Step [168/225], Training Accuracy: 86.8676%, Training Loss: 0.3430%\n",
      "Epoch [35/300], Step [169/225], Training Accuracy: 86.8713%, Training Loss: 0.3433%\n",
      "Epoch [35/300], Step [170/225], Training Accuracy: 86.8842%, Training Loss: 0.3433%\n",
      "Epoch [35/300], Step [171/225], Training Accuracy: 86.8787%, Training Loss: 0.3433%\n",
      "Epoch [35/300], Step [172/225], Training Accuracy: 86.8914%, Training Loss: 0.3432%\n",
      "Epoch [35/300], Step [173/225], Training Accuracy: 86.9039%, Training Loss: 0.3433%\n",
      "Epoch [35/300], Step [174/225], Training Accuracy: 86.8983%, Training Loss: 0.3431%\n",
      "Epoch [35/300], Step [175/225], Training Accuracy: 86.9286%, Training Loss: 0.3425%\n",
      "Epoch [35/300], Step [176/225], Training Accuracy: 86.9496%, Training Loss: 0.3420%\n",
      "Epoch [35/300], Step [177/225], Training Accuracy: 86.9968%, Training Loss: 0.3413%\n",
      "Epoch [35/300], Step [178/225], Training Accuracy: 86.9821%, Training Loss: 0.3415%\n",
      "Epoch [35/300], Step [179/225], Training Accuracy: 87.0024%, Training Loss: 0.3413%\n",
      "Epoch [35/300], Step [180/225], Training Accuracy: 87.0052%, Training Loss: 0.3412%\n",
      "Epoch [35/300], Step [181/225], Training Accuracy: 87.0166%, Training Loss: 0.3408%\n",
      "Epoch [35/300], Step [182/225], Training Accuracy: 87.0021%, Training Loss: 0.3408%\n",
      "Epoch [35/300], Step [183/225], Training Accuracy: 87.0389%, Training Loss: 0.3402%\n",
      "Epoch [35/300], Step [184/225], Training Accuracy: 87.0160%, Training Loss: 0.3403%\n",
      "Epoch [35/300], Step [185/225], Training Accuracy: 87.0524%, Training Loss: 0.3396%\n",
      "Epoch [35/300], Step [186/225], Training Accuracy: 87.0632%, Training Loss: 0.3392%\n",
      "Epoch [35/300], Step [187/225], Training Accuracy: 87.0822%, Training Loss: 0.3390%\n",
      "Epoch [35/300], Step [188/225], Training Accuracy: 87.0678%, Training Loss: 0.3392%\n",
      "Epoch [35/300], Step [189/225], Training Accuracy: 87.0618%, Training Loss: 0.3394%\n",
      "Epoch [35/300], Step [190/225], Training Accuracy: 87.0312%, Training Loss: 0.3400%\n",
      "Epoch [35/300], Step [191/225], Training Accuracy: 87.0501%, Training Loss: 0.3395%\n",
      "Epoch [35/300], Step [192/225], Training Accuracy: 87.0605%, Training Loss: 0.3393%\n",
      "Epoch [35/300], Step [193/225], Training Accuracy: 87.0628%, Training Loss: 0.3397%\n",
      "Epoch [35/300], Step [194/225], Training Accuracy: 87.1053%, Training Loss: 0.3390%\n",
      "Epoch [35/300], Step [195/225], Training Accuracy: 87.0513%, Training Loss: 0.3395%\n",
      "Epoch [35/300], Step [196/225], Training Accuracy: 87.0297%, Training Loss: 0.3398%\n",
      "Epoch [35/300], Step [197/225], Training Accuracy: 86.9924%, Training Loss: 0.3400%\n",
      "Epoch [35/300], Step [198/225], Training Accuracy: 86.9949%, Training Loss: 0.3402%\n",
      "Epoch [35/300], Step [199/225], Training Accuracy: 86.9818%, Training Loss: 0.3405%\n",
      "Epoch [35/300], Step [200/225], Training Accuracy: 86.9922%, Training Loss: 0.3401%\n",
      "Epoch [35/300], Step [201/225], Training Accuracy: 87.0025%, Training Loss: 0.3396%\n",
      "Epoch [35/300], Step [202/225], Training Accuracy: 86.9663%, Training Loss: 0.3404%\n",
      "Epoch [35/300], Step [203/225], Training Accuracy: 86.9766%, Training Loss: 0.3404%\n",
      "Epoch [35/300], Step [204/225], Training Accuracy: 86.9256%, Training Loss: 0.3406%\n",
      "Epoch [35/300], Step [205/225], Training Accuracy: 86.9436%, Training Loss: 0.3400%\n",
      "Epoch [35/300], Step [206/225], Training Accuracy: 86.9084%, Training Loss: 0.3404%\n",
      "Epoch [35/300], Step [207/225], Training Accuracy: 86.9490%, Training Loss: 0.3396%\n",
      "Epoch [35/300], Step [208/225], Training Accuracy: 86.9817%, Training Loss: 0.3391%\n",
      "Epoch [35/300], Step [209/225], Training Accuracy: 86.9767%, Training Loss: 0.3395%\n",
      "Epoch [35/300], Step [210/225], Training Accuracy: 86.9420%, Training Loss: 0.3399%\n",
      "Epoch [35/300], Step [211/225], Training Accuracy: 86.9594%, Training Loss: 0.3398%\n",
      "Epoch [35/300], Step [212/225], Training Accuracy: 86.9325%, Training Loss: 0.3407%\n",
      "Epoch [35/300], Step [213/225], Training Accuracy: 86.9205%, Training Loss: 0.3411%\n",
      "Epoch [35/300], Step [214/225], Training Accuracy: 86.9013%, Training Loss: 0.3416%\n",
      "Epoch [35/300], Step [215/225], Training Accuracy: 86.8895%, Training Loss: 0.3415%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/300], Step [216/225], Training Accuracy: 86.8490%, Training Loss: 0.3422%\n",
      "Epoch [35/300], Step [217/225], Training Accuracy: 86.8664%, Training Loss: 0.3416%\n",
      "Epoch [35/300], Step [218/225], Training Accuracy: 86.8263%, Training Loss: 0.3424%\n",
      "Epoch [35/300], Step [219/225], Training Accuracy: 86.8151%, Training Loss: 0.3425%\n",
      "Epoch [35/300], Step [220/225], Training Accuracy: 86.8253%, Training Loss: 0.3422%\n",
      "Epoch [35/300], Step [221/225], Training Accuracy: 86.8354%, Training Loss: 0.3425%\n",
      "Epoch [35/300], Step [222/225], Training Accuracy: 86.7962%, Training Loss: 0.3434%\n",
      "Epoch [35/300], Step [223/225], Training Accuracy: 86.8344%, Training Loss: 0.3426%\n",
      "Epoch [35/300], Step [224/225], Training Accuracy: 86.8304%, Training Loss: 0.3428%\n",
      "Epoch [35/300], Step [225/225], Training Accuracy: 86.7843%, Training Loss: 0.3433%\n",
      "Epoch [36/300], Step [1/225], Training Accuracy: 85.9375%, Training Loss: 0.4143%\n",
      "Epoch [36/300], Step [2/225], Training Accuracy: 87.5000%, Training Loss: 0.3676%\n",
      "Epoch [36/300], Step [3/225], Training Accuracy: 86.9792%, Training Loss: 0.3658%\n",
      "Epoch [36/300], Step [4/225], Training Accuracy: 87.5000%, Training Loss: 0.3432%\n",
      "Epoch [36/300], Step [5/225], Training Accuracy: 87.8125%, Training Loss: 0.3252%\n",
      "Epoch [36/300], Step [6/225], Training Accuracy: 88.0208%, Training Loss: 0.3216%\n",
      "Epoch [36/300], Step [7/225], Training Accuracy: 87.0536%, Training Loss: 0.3350%\n",
      "Epoch [36/300], Step [8/225], Training Accuracy: 87.3047%, Training Loss: 0.3256%\n",
      "Epoch [36/300], Step [9/225], Training Accuracy: 87.1528%, Training Loss: 0.3277%\n",
      "Epoch [36/300], Step [10/225], Training Accuracy: 87.1875%, Training Loss: 0.3274%\n",
      "Epoch [36/300], Step [11/225], Training Accuracy: 87.2159%, Training Loss: 0.3252%\n",
      "Epoch [36/300], Step [12/225], Training Accuracy: 87.2396%, Training Loss: 0.3238%\n",
      "Epoch [36/300], Step [13/225], Training Accuracy: 87.1394%, Training Loss: 0.3243%\n",
      "Epoch [36/300], Step [14/225], Training Accuracy: 87.0536%, Training Loss: 0.3263%\n",
      "Epoch [36/300], Step [15/225], Training Accuracy: 87.3958%, Training Loss: 0.3182%\n",
      "Epoch [36/300], Step [16/225], Training Accuracy: 87.0117%, Training Loss: 0.3277%\n",
      "Epoch [36/300], Step [17/225], Training Accuracy: 86.9485%, Training Loss: 0.3321%\n",
      "Epoch [36/300], Step [18/225], Training Accuracy: 87.0660%, Training Loss: 0.3314%\n",
      "Epoch [36/300], Step [19/225], Training Accuracy: 87.0888%, Training Loss: 0.3293%\n",
      "Epoch [36/300], Step [20/225], Training Accuracy: 86.8750%, Training Loss: 0.3287%\n",
      "Epoch [36/300], Step [21/225], Training Accuracy: 87.1280%, Training Loss: 0.3248%\n",
      "Epoch [36/300], Step [22/225], Training Accuracy: 87.2869%, Training Loss: 0.3236%\n",
      "Epoch [36/300], Step [23/225], Training Accuracy: 87.0245%, Training Loss: 0.3256%\n",
      "Epoch [36/300], Step [24/225], Training Accuracy: 86.7188%, Training Loss: 0.3311%\n",
      "Epoch [36/300], Step [25/225], Training Accuracy: 86.8125%, Training Loss: 0.3303%\n",
      "Epoch [36/300], Step [26/225], Training Accuracy: 86.8389%, Training Loss: 0.3336%\n",
      "Epoch [36/300], Step [27/225], Training Accuracy: 86.9213%, Training Loss: 0.3316%\n",
      "Epoch [36/300], Step [28/225], Training Accuracy: 87.2210%, Training Loss: 0.3263%\n",
      "Epoch [36/300], Step [29/225], Training Accuracy: 87.5000%, Training Loss: 0.3216%\n",
      "Epoch [36/300], Step [30/225], Training Accuracy: 87.4479%, Training Loss: 0.3217%\n",
      "Epoch [36/300], Step [31/225], Training Accuracy: 87.2480%, Training Loss: 0.3233%\n",
      "Epoch [36/300], Step [32/225], Training Accuracy: 87.0605%, Training Loss: 0.3266%\n",
      "Epoch [36/300], Step [33/225], Training Accuracy: 87.1212%, Training Loss: 0.3265%\n",
      "Epoch [36/300], Step [34/225], Training Accuracy: 87.1324%, Training Loss: 0.3266%\n",
      "Epoch [36/300], Step [35/225], Training Accuracy: 87.3214%, Training Loss: 0.3239%\n",
      "Epoch [36/300], Step [36/225], Training Accuracy: 87.5868%, Training Loss: 0.3221%\n",
      "Epoch [36/300], Step [37/225], Training Accuracy: 87.5845%, Training Loss: 0.3228%\n",
      "Epoch [36/300], Step [38/225], Training Accuracy: 87.3355%, Training Loss: 0.3266%\n",
      "Epoch [36/300], Step [39/225], Training Accuracy: 87.2997%, Training Loss: 0.3266%\n",
      "Epoch [36/300], Step [40/225], Training Accuracy: 87.3438%, Training Loss: 0.3264%\n",
      "Epoch [36/300], Step [41/225], Training Accuracy: 87.3476%, Training Loss: 0.3259%\n",
      "Epoch [36/300], Step [42/225], Training Accuracy: 87.5000%, Training Loss: 0.3237%\n",
      "Epoch [36/300], Step [43/225], Training Accuracy: 87.5000%, Training Loss: 0.3225%\n",
      "Epoch [36/300], Step [44/225], Training Accuracy: 87.5710%, Training Loss: 0.3219%\n",
      "Epoch [36/300], Step [45/225], Training Accuracy: 87.5000%, Training Loss: 0.3240%\n",
      "Epoch [36/300], Step [46/225], Training Accuracy: 87.6019%, Training Loss: 0.3231%\n",
      "Epoch [36/300], Step [47/225], Training Accuracy: 87.5000%, Training Loss: 0.3253%\n",
      "Epoch [36/300], Step [48/225], Training Accuracy: 87.4674%, Training Loss: 0.3258%\n",
      "Epoch [36/300], Step [49/225], Training Accuracy: 87.3087%, Training Loss: 0.3289%\n",
      "Epoch [36/300], Step [50/225], Training Accuracy: 87.2188%, Training Loss: 0.3311%\n",
      "Epoch [36/300], Step [51/225], Training Accuracy: 87.1936%, Training Loss: 0.3316%\n",
      "Epoch [36/300], Step [52/225], Training Accuracy: 87.2897%, Training Loss: 0.3289%\n",
      "Epoch [36/300], Step [53/225], Training Accuracy: 87.2642%, Training Loss: 0.3298%\n",
      "Epoch [36/300], Step [54/225], Training Accuracy: 87.2396%, Training Loss: 0.3311%\n",
      "Epoch [36/300], Step [55/225], Training Accuracy: 87.1875%, Training Loss: 0.3317%\n",
      "Epoch [36/300], Step [56/225], Training Accuracy: 87.1373%, Training Loss: 0.3329%\n",
      "Epoch [36/300], Step [57/225], Training Accuracy: 87.1436%, Training Loss: 0.3332%\n",
      "Epoch [36/300], Step [58/225], Training Accuracy: 87.0151%, Training Loss: 0.3350%\n",
      "Epoch [36/300], Step [59/225], Training Accuracy: 87.0233%, Training Loss: 0.3358%\n",
      "Epoch [36/300], Step [60/225], Training Accuracy: 87.0052%, Training Loss: 0.3354%\n",
      "Epoch [36/300], Step [61/225], Training Accuracy: 87.0645%, Training Loss: 0.3363%\n",
      "Epoch [36/300], Step [62/225], Training Accuracy: 86.9960%, Training Loss: 0.3384%\n",
      "Epoch [36/300], Step [63/225], Training Accuracy: 86.9048%, Training Loss: 0.3407%\n",
      "Epoch [36/300], Step [64/225], Training Accuracy: 86.9141%, Training Loss: 0.3412%\n",
      "Epoch [36/300], Step [65/225], Training Accuracy: 86.9712%, Training Loss: 0.3400%\n",
      "Epoch [36/300], Step [66/225], Training Accuracy: 86.9081%, Training Loss: 0.3414%\n",
      "Epoch [36/300], Step [67/225], Training Accuracy: 86.8937%, Training Loss: 0.3416%\n",
      "Epoch [36/300], Step [68/225], Training Accuracy: 86.7647%, Training Loss: 0.3423%\n",
      "Epoch [36/300], Step [69/225], Training Accuracy: 86.8433%, Training Loss: 0.3406%\n",
      "Epoch [36/300], Step [70/225], Training Accuracy: 86.8527%, Training Loss: 0.3398%\n",
      "Epoch [36/300], Step [71/225], Training Accuracy: 86.7738%, Training Loss: 0.3406%\n",
      "Epoch [36/300], Step [72/225], Training Accuracy: 86.8273%, Training Loss: 0.3401%\n",
      "Epoch [36/300], Step [73/225], Training Accuracy: 86.7723%, Training Loss: 0.3416%\n",
      "Epoch [36/300], Step [74/225], Training Accuracy: 86.7188%, Training Loss: 0.3422%\n",
      "Epoch [36/300], Step [75/225], Training Accuracy: 86.6875%, Training Loss: 0.3421%\n",
      "Epoch [36/300], Step [76/225], Training Accuracy: 86.6365%, Training Loss: 0.3443%\n",
      "Epoch [36/300], Step [77/225], Training Accuracy: 86.7289%, Training Loss: 0.3432%\n",
      "Epoch [36/300], Step [78/225], Training Accuracy: 86.6787%, Training Loss: 0.3430%\n",
      "Epoch [36/300], Step [79/225], Training Accuracy: 86.5902%, Training Loss: 0.3441%\n",
      "Epoch [36/300], Step [80/225], Training Accuracy: 86.4844%, Training Loss: 0.3458%\n",
      "Epoch [36/300], Step [81/225], Training Accuracy: 86.4969%, Training Loss: 0.3452%\n",
      "Epoch [36/300], Step [82/225], Training Accuracy: 86.4901%, Training Loss: 0.3463%\n",
      "Epoch [36/300], Step [83/225], Training Accuracy: 86.5211%, Training Loss: 0.3476%\n",
      "Epoch [36/300], Step [84/225], Training Accuracy: 86.5327%, Training Loss: 0.3481%\n",
      "Epoch [36/300], Step [85/225], Training Accuracy: 86.5257%, Training Loss: 0.3477%\n",
      "Epoch [36/300], Step [86/225], Training Accuracy: 86.5189%, Training Loss: 0.3475%\n",
      "Epoch [36/300], Step [87/225], Training Accuracy: 86.5122%, Training Loss: 0.3478%\n",
      "Epoch [36/300], Step [88/225], Training Accuracy: 86.4879%, Training Loss: 0.3492%\n",
      "Epoch [36/300], Step [89/225], Training Accuracy: 86.4993%, Training Loss: 0.3487%\n",
      "Epoch [36/300], Step [90/225], Training Accuracy: 86.4583%, Training Loss: 0.3494%\n",
      "Epoch [36/300], Step [91/225], Training Accuracy: 86.4354%, Training Loss: 0.3498%\n",
      "Epoch [36/300], Step [92/225], Training Accuracy: 86.4130%, Training Loss: 0.3503%\n",
      "Epoch [36/300], Step [93/225], Training Accuracy: 86.4079%, Training Loss: 0.3508%\n",
      "Epoch [36/300], Step [94/225], Training Accuracy: 86.3697%, Training Loss: 0.3513%\n",
      "Epoch [36/300], Step [95/225], Training Accuracy: 86.3322%, Training Loss: 0.3528%\n",
      "Epoch [36/300], Step [96/225], Training Accuracy: 86.3444%, Training Loss: 0.3526%\n",
      "Epoch [36/300], Step [97/225], Training Accuracy: 86.3724%, Training Loss: 0.3523%\n",
      "Epoch [36/300], Step [98/225], Training Accuracy: 86.3202%, Training Loss: 0.3530%\n",
      "Epoch [36/300], Step [99/225], Training Accuracy: 86.3636%, Training Loss: 0.3523%\n",
      "Epoch [36/300], Step [100/225], Training Accuracy: 86.3750%, Training Loss: 0.3521%\n",
      "Epoch [36/300], Step [101/225], Training Accuracy: 86.4325%, Training Loss: 0.3512%\n",
      "Epoch [36/300], Step [102/225], Training Accuracy: 86.4124%, Training Loss: 0.3515%\n",
      "Epoch [36/300], Step [103/225], Training Accuracy: 86.4078%, Training Loss: 0.3522%\n",
      "Epoch [36/300], Step [104/225], Training Accuracy: 86.4032%, Training Loss: 0.3519%\n",
      "Epoch [36/300], Step [105/225], Training Accuracy: 86.3839%, Training Loss: 0.3524%\n",
      "Epoch [36/300], Step [106/225], Training Accuracy: 86.3797%, Training Loss: 0.3528%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/300], Step [107/225], Training Accuracy: 86.3172%, Training Loss: 0.3539%\n",
      "Epoch [36/300], Step [108/225], Training Accuracy: 86.3137%, Training Loss: 0.3540%\n",
      "Epoch [36/300], Step [109/225], Training Accuracy: 86.3245%, Training Loss: 0.3536%\n",
      "Epoch [36/300], Step [110/225], Training Accuracy: 86.3778%, Training Loss: 0.3524%\n",
      "Epoch [36/300], Step [111/225], Training Accuracy: 86.4020%, Training Loss: 0.3517%\n",
      "Epoch [36/300], Step [112/225], Training Accuracy: 86.3700%, Training Loss: 0.3518%\n",
      "Epoch [36/300], Step [113/225], Training Accuracy: 86.4076%, Training Loss: 0.3516%\n",
      "Epoch [36/300], Step [114/225], Training Accuracy: 86.4309%, Training Loss: 0.3511%\n",
      "Epoch [36/300], Step [115/225], Training Accuracy: 86.4538%, Training Loss: 0.3508%\n",
      "Epoch [36/300], Step [116/225], Training Accuracy: 86.3955%, Training Loss: 0.3513%\n",
      "Epoch [36/300], Step [117/225], Training Accuracy: 86.4316%, Training Loss: 0.3505%\n",
      "Epoch [36/300], Step [118/225], Training Accuracy: 86.4407%, Training Loss: 0.3503%\n",
      "Epoch [36/300], Step [119/225], Training Accuracy: 86.5021%, Training Loss: 0.3495%\n",
      "Epoch [36/300], Step [120/225], Training Accuracy: 86.5234%, Training Loss: 0.3484%\n",
      "Epoch [36/300], Step [121/225], Training Accuracy: 86.5057%, Training Loss: 0.3489%\n",
      "Epoch [36/300], Step [122/225], Training Accuracy: 86.5010%, Training Loss: 0.3486%\n",
      "Epoch [36/300], Step [123/225], Training Accuracy: 86.4710%, Training Loss: 0.3490%\n",
      "Epoch [36/300], Step [124/225], Training Accuracy: 86.4667%, Training Loss: 0.3493%\n",
      "Epoch [36/300], Step [125/225], Training Accuracy: 86.4875%, Training Loss: 0.3488%\n",
      "Epoch [36/300], Step [126/225], Training Accuracy: 86.4955%, Training Loss: 0.3482%\n",
      "Epoch [36/300], Step [127/225], Training Accuracy: 86.4788%, Training Loss: 0.3487%\n",
      "Epoch [36/300], Step [128/225], Training Accuracy: 86.4502%, Training Loss: 0.3492%\n",
      "Epoch [36/300], Step [129/225], Training Accuracy: 86.4583%, Training Loss: 0.3485%\n",
      "Epoch [36/300], Step [130/225], Training Accuracy: 86.3582%, Training Loss: 0.3502%\n",
      "Epoch [36/300], Step [131/225], Training Accuracy: 86.4027%, Training Loss: 0.3496%\n",
      "Epoch [36/300], Step [132/225], Training Accuracy: 86.4110%, Training Loss: 0.3491%\n",
      "Epoch [36/300], Step [133/225], Training Accuracy: 86.3722%, Training Loss: 0.3494%\n",
      "Epoch [36/300], Step [134/225], Training Accuracy: 86.3456%, Training Loss: 0.3500%\n",
      "Epoch [36/300], Step [135/225], Training Accuracy: 86.3773%, Training Loss: 0.3491%\n",
      "Epoch [36/300], Step [136/225], Training Accuracy: 86.3741%, Training Loss: 0.3495%\n",
      "Epoch [36/300], Step [137/225], Training Accuracy: 86.4051%, Training Loss: 0.3490%\n",
      "Epoch [36/300], Step [138/225], Training Accuracy: 86.3904%, Training Loss: 0.3493%\n",
      "Epoch [36/300], Step [139/225], Training Accuracy: 86.3422%, Training Loss: 0.3493%\n",
      "Epoch [36/300], Step [140/225], Training Accuracy: 86.3616%, Training Loss: 0.3492%\n",
      "Epoch [36/300], Step [141/225], Training Accuracy: 86.3586%, Training Loss: 0.3492%\n",
      "Epoch [36/300], Step [142/225], Training Accuracy: 86.3776%, Training Loss: 0.3486%\n",
      "Epoch [36/300], Step [143/225], Training Accuracy: 86.3746%, Training Loss: 0.3490%\n",
      "Epoch [36/300], Step [144/225], Training Accuracy: 86.4258%, Training Loss: 0.3479%\n",
      "Epoch [36/300], Step [145/225], Training Accuracy: 86.4224%, Training Loss: 0.3481%\n",
      "Epoch [36/300], Step [146/225], Training Accuracy: 86.4191%, Training Loss: 0.3478%\n",
      "Epoch [36/300], Step [147/225], Training Accuracy: 86.4264%, Training Loss: 0.3479%\n",
      "Epoch [36/300], Step [148/225], Training Accuracy: 86.4126%, Training Loss: 0.3484%\n",
      "Epoch [36/300], Step [149/225], Training Accuracy: 86.3779%, Training Loss: 0.3487%\n",
      "Epoch [36/300], Step [150/225], Training Accuracy: 86.3854%, Training Loss: 0.3480%\n",
      "Epoch [36/300], Step [151/225], Training Accuracy: 86.3928%, Training Loss: 0.3477%\n",
      "Epoch [36/300], Step [152/225], Training Accuracy: 86.4104%, Training Loss: 0.3473%\n",
      "Epoch [36/300], Step [153/225], Training Accuracy: 86.4685%, Training Loss: 0.3465%\n",
      "Epoch [36/300], Step [154/225], Training Accuracy: 86.5361%, Training Loss: 0.3453%\n",
      "Epoch [36/300], Step [155/225], Training Accuracy: 86.5625%, Training Loss: 0.3448%\n",
      "Epoch [36/300], Step [156/225], Training Accuracy: 86.5685%, Training Loss: 0.3452%\n",
      "Epoch [36/300], Step [157/225], Training Accuracy: 86.5446%, Training Loss: 0.3455%\n",
      "Epoch [36/300], Step [158/225], Training Accuracy: 86.6001%, Training Loss: 0.3446%\n",
      "Epoch [36/300], Step [159/225], Training Accuracy: 86.6254%, Training Loss: 0.3443%\n",
      "Epoch [36/300], Step [160/225], Training Accuracy: 86.6309%, Training Loss: 0.3440%\n",
      "Epoch [36/300], Step [161/225], Training Accuracy: 86.6557%, Training Loss: 0.3435%\n",
      "Epoch [36/300], Step [162/225], Training Accuracy: 86.7091%, Training Loss: 0.3430%\n",
      "Epoch [36/300], Step [163/225], Training Accuracy: 86.7235%, Training Loss: 0.3428%\n",
      "Epoch [36/300], Step [164/225], Training Accuracy: 86.7188%, Training Loss: 0.3424%\n",
      "Epoch [36/300], Step [165/225], Training Accuracy: 86.7519%, Training Loss: 0.3419%\n",
      "Epoch [36/300], Step [166/225], Training Accuracy: 86.7564%, Training Loss: 0.3419%\n",
      "Epoch [36/300], Step [167/225], Training Accuracy: 86.7702%, Training Loss: 0.3417%\n",
      "Epoch [36/300], Step [168/225], Training Accuracy: 86.7932%, Training Loss: 0.3410%\n",
      "Epoch [36/300], Step [169/225], Training Accuracy: 86.8066%, Training Loss: 0.3408%\n",
      "Epoch [36/300], Step [170/225], Training Accuracy: 86.8290%, Training Loss: 0.3402%\n",
      "Epoch [36/300], Step [171/225], Training Accuracy: 86.7964%, Training Loss: 0.3405%\n",
      "Epoch [36/300], Step [172/225], Training Accuracy: 86.8550%, Training Loss: 0.3397%\n",
      "Epoch [36/300], Step [173/225], Training Accuracy: 86.8678%, Training Loss: 0.3399%\n",
      "Epoch [36/300], Step [174/225], Training Accuracy: 86.8804%, Training Loss: 0.3394%\n",
      "Epoch [36/300], Step [175/225], Training Accuracy: 86.9107%, Training Loss: 0.3387%\n",
      "Epoch [36/300], Step [176/225], Training Accuracy: 86.9052%, Training Loss: 0.3388%\n",
      "Epoch [36/300], Step [177/225], Training Accuracy: 86.9439%, Training Loss: 0.3382%\n",
      "Epoch [36/300], Step [178/225], Training Accuracy: 86.9294%, Training Loss: 0.3385%\n",
      "Epoch [36/300], Step [179/225], Training Accuracy: 86.9413%, Training Loss: 0.3381%\n",
      "Epoch [36/300], Step [180/225], Training Accuracy: 86.9184%, Training Loss: 0.3380%\n",
      "Epoch [36/300], Step [181/225], Training Accuracy: 86.9389%, Training Loss: 0.3380%\n",
      "Epoch [36/300], Step [182/225], Training Accuracy: 86.9334%, Training Loss: 0.3377%\n",
      "Epoch [36/300], Step [183/225], Training Accuracy: 86.9450%, Training Loss: 0.3372%\n",
      "Epoch [36/300], Step [184/225], Training Accuracy: 86.9650%, Training Loss: 0.3366%\n",
      "Epoch [36/300], Step [185/225], Training Accuracy: 86.9848%, Training Loss: 0.3363%\n",
      "Epoch [36/300], Step [186/225], Training Accuracy: 86.9792%, Training Loss: 0.3365%\n",
      "Epoch [36/300], Step [187/225], Training Accuracy: 86.9820%, Training Loss: 0.3362%\n",
      "Epoch [36/300], Step [188/225], Training Accuracy: 87.0013%, Training Loss: 0.3356%\n",
      "Epoch [36/300], Step [189/225], Training Accuracy: 87.0536%, Training Loss: 0.3347%\n",
      "Epoch [36/300], Step [190/225], Training Accuracy: 86.9984%, Training Loss: 0.3351%\n",
      "Epoch [36/300], Step [191/225], Training Accuracy: 87.0337%, Training Loss: 0.3347%\n",
      "Epoch [36/300], Step [192/225], Training Accuracy: 87.0361%, Training Loss: 0.3348%\n",
      "Epoch [36/300], Step [193/225], Training Accuracy: 87.0304%, Training Loss: 0.3350%\n",
      "Epoch [36/300], Step [194/225], Training Accuracy: 87.0651%, Training Loss: 0.3343%\n",
      "Epoch [36/300], Step [195/225], Training Accuracy: 87.0673%, Training Loss: 0.3344%\n",
      "Epoch [36/300], Step [196/225], Training Accuracy: 87.0695%, Training Loss: 0.3343%\n",
      "Epoch [36/300], Step [197/225], Training Accuracy: 87.0717%, Training Loss: 0.3345%\n",
      "Epoch [36/300], Step [198/225], Training Accuracy: 87.0818%, Training Loss: 0.3343%\n",
      "Epoch [36/300], Step [199/225], Training Accuracy: 87.1153%, Training Loss: 0.3339%\n",
      "Epoch [36/300], Step [200/225], Training Accuracy: 87.1562%, Training Loss: 0.3335%\n",
      "Epoch [36/300], Step [201/225], Training Accuracy: 87.1813%, Training Loss: 0.3333%\n",
      "Epoch [36/300], Step [202/225], Training Accuracy: 87.1829%, Training Loss: 0.3335%\n",
      "Epoch [36/300], Step [203/225], Training Accuracy: 87.1844%, Training Loss: 0.3334%\n",
      "Epoch [36/300], Step [204/225], Training Accuracy: 87.1630%, Training Loss: 0.3338%\n",
      "Epoch [36/300], Step [205/225], Training Accuracy: 87.1799%, Training Loss: 0.3337%\n",
      "Epoch [36/300], Step [206/225], Training Accuracy: 87.1663%, Training Loss: 0.3343%\n",
      "Epoch [36/300], Step [207/225], Training Accuracy: 87.1603%, Training Loss: 0.3340%\n",
      "Epoch [36/300], Step [208/225], Training Accuracy: 87.1845%, Training Loss: 0.3337%\n",
      "Epoch [36/300], Step [209/225], Training Accuracy: 87.1935%, Training Loss: 0.3334%\n",
      "Epoch [36/300], Step [210/225], Training Accuracy: 87.1875%, Training Loss: 0.3336%\n",
      "Epoch [36/300], Step [211/225], Training Accuracy: 87.1520%, Training Loss: 0.3342%\n",
      "Epoch [36/300], Step [212/225], Training Accuracy: 87.1536%, Training Loss: 0.3342%\n",
      "Epoch [36/300], Step [213/225], Training Accuracy: 87.1479%, Training Loss: 0.3343%\n",
      "Epoch [36/300], Step [214/225], Training Accuracy: 87.1860%, Training Loss: 0.3337%\n",
      "Epoch [36/300], Step [215/225], Training Accuracy: 87.2020%, Training Loss: 0.3337%\n",
      "Epoch [36/300], Step [216/225], Training Accuracy: 87.1455%, Training Loss: 0.3347%\n",
      "Epoch [36/300], Step [217/225], Training Accuracy: 87.1472%, Training Loss: 0.3350%\n",
      "Epoch [36/300], Step [218/225], Training Accuracy: 87.1703%, Training Loss: 0.3347%\n",
      "Epoch [36/300], Step [219/225], Training Accuracy: 87.1789%, Training Loss: 0.3342%\n",
      "Epoch [36/300], Step [220/225], Training Accuracy: 87.2088%, Training Loss: 0.3335%\n",
      "Epoch [36/300], Step [221/225], Training Accuracy: 87.1889%, Training Loss: 0.3336%\n",
      "Epoch [36/300], Step [222/225], Training Accuracy: 87.1692%, Training Loss: 0.3340%\n",
      "Epoch [36/300], Step [223/225], Training Accuracy: 87.1777%, Training Loss: 0.3336%\n",
      "Epoch [36/300], Step [224/225], Training Accuracy: 87.1791%, Training Loss: 0.3335%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/300], Step [225/225], Training Accuracy: 87.1943%, Training Loss: 0.3332%\n",
      "Epoch [37/300], Step [1/225], Training Accuracy: 92.1875%, Training Loss: 0.2519%\n",
      "Epoch [37/300], Step [2/225], Training Accuracy: 92.1875%, Training Loss: 0.2848%\n",
      "Epoch [37/300], Step [3/225], Training Accuracy: 89.5833%, Training Loss: 0.3361%\n",
      "Epoch [37/300], Step [4/225], Training Accuracy: 89.0625%, Training Loss: 0.3315%\n",
      "Epoch [37/300], Step [5/225], Training Accuracy: 89.6875%, Training Loss: 0.3045%\n",
      "Epoch [37/300], Step [6/225], Training Accuracy: 88.8021%, Training Loss: 0.3203%\n",
      "Epoch [37/300], Step [7/225], Training Accuracy: 88.8393%, Training Loss: 0.3200%\n",
      "Epoch [37/300], Step [8/225], Training Accuracy: 88.2812%, Training Loss: 0.3335%\n",
      "Epoch [37/300], Step [9/225], Training Accuracy: 88.7153%, Training Loss: 0.3195%\n",
      "Epoch [37/300], Step [10/225], Training Accuracy: 88.2812%, Training Loss: 0.3286%\n",
      "Epoch [37/300], Step [11/225], Training Accuracy: 88.0682%, Training Loss: 0.3269%\n",
      "Epoch [37/300], Step [12/225], Training Accuracy: 88.1510%, Training Loss: 0.3247%\n",
      "Epoch [37/300], Step [13/225], Training Accuracy: 87.9808%, Training Loss: 0.3225%\n",
      "Epoch [37/300], Step [14/225], Training Accuracy: 87.5000%, Training Loss: 0.3312%\n",
      "Epoch [37/300], Step [15/225], Training Accuracy: 87.3958%, Training Loss: 0.3336%\n",
      "Epoch [37/300], Step [16/225], Training Accuracy: 87.3047%, Training Loss: 0.3336%\n",
      "Epoch [37/300], Step [17/225], Training Accuracy: 87.0404%, Training Loss: 0.3411%\n",
      "Epoch [37/300], Step [18/225], Training Accuracy: 86.8056%, Training Loss: 0.3437%\n",
      "Epoch [37/300], Step [19/225], Training Accuracy: 87.0888%, Training Loss: 0.3402%\n",
      "Epoch [37/300], Step [20/225], Training Accuracy: 87.5000%, Training Loss: 0.3332%\n",
      "Epoch [37/300], Step [21/225], Training Accuracy: 87.7976%, Training Loss: 0.3260%\n",
      "Epoch [37/300], Step [22/225], Training Accuracy: 87.5000%, Training Loss: 0.3295%\n",
      "Epoch [37/300], Step [23/225], Training Accuracy: 87.2283%, Training Loss: 0.3359%\n",
      "Epoch [37/300], Step [24/225], Training Accuracy: 87.3047%, Training Loss: 0.3371%\n",
      "Epoch [37/300], Step [25/225], Training Accuracy: 87.6250%, Training Loss: 0.3318%\n",
      "Epoch [37/300], Step [26/225], Training Accuracy: 87.5000%, Training Loss: 0.3304%\n",
      "Epoch [37/300], Step [27/225], Training Accuracy: 87.5579%, Training Loss: 0.3268%\n",
      "Epoch [37/300], Step [28/225], Training Accuracy: 87.8906%, Training Loss: 0.3208%\n",
      "Epoch [37/300], Step [29/225], Training Accuracy: 88.2004%, Training Loss: 0.3164%\n",
      "Epoch [37/300], Step [30/225], Training Accuracy: 88.0208%, Training Loss: 0.3202%\n",
      "Epoch [37/300], Step [31/225], Training Accuracy: 87.9032%, Training Loss: 0.3238%\n",
      "Epoch [37/300], Step [32/225], Training Accuracy: 87.9395%, Training Loss: 0.3263%\n",
      "Epoch [37/300], Step [33/225], Training Accuracy: 88.0682%, Training Loss: 0.3236%\n",
      "Epoch [37/300], Step [34/225], Training Accuracy: 88.0055%, Training Loss: 0.3232%\n",
      "Epoch [37/300], Step [35/225], Training Accuracy: 87.9464%, Training Loss: 0.3258%\n",
      "Epoch [37/300], Step [36/225], Training Accuracy: 88.0208%, Training Loss: 0.3257%\n",
      "Epoch [37/300], Step [37/225], Training Accuracy: 88.1334%, Training Loss: 0.3244%\n",
      "Epoch [37/300], Step [38/225], Training Accuracy: 88.1168%, Training Loss: 0.3250%\n",
      "Epoch [37/300], Step [39/225], Training Accuracy: 88.0609%, Training Loss: 0.3263%\n",
      "Epoch [37/300], Step [40/225], Training Accuracy: 88.0078%, Training Loss: 0.3259%\n",
      "Epoch [37/300], Step [41/225], Training Accuracy: 87.7668%, Training Loss: 0.3294%\n",
      "Epoch [37/300], Step [42/225], Training Accuracy: 87.6860%, Training Loss: 0.3295%\n",
      "Epoch [37/300], Step [43/225], Training Accuracy: 87.5363%, Training Loss: 0.3302%\n",
      "Epoch [37/300], Step [44/225], Training Accuracy: 87.4645%, Training Loss: 0.3313%\n",
      "Epoch [37/300], Step [45/225], Training Accuracy: 87.4306%, Training Loss: 0.3306%\n",
      "Epoch [37/300], Step [46/225], Training Accuracy: 87.5340%, Training Loss: 0.3285%\n",
      "Epoch [37/300], Step [47/225], Training Accuracy: 87.6995%, Training Loss: 0.3255%\n",
      "Epoch [37/300], Step [48/225], Training Accuracy: 87.6628%, Training Loss: 0.3252%\n",
      "Epoch [37/300], Step [49/225], Training Accuracy: 87.5957%, Training Loss: 0.3262%\n",
      "Epoch [37/300], Step [50/225], Training Accuracy: 87.6250%, Training Loss: 0.3253%\n",
      "Epoch [37/300], Step [51/225], Training Accuracy: 87.6838%, Training Loss: 0.3239%\n",
      "Epoch [37/300], Step [52/225], Training Accuracy: 87.8606%, Training Loss: 0.3203%\n",
      "Epoch [37/300], Step [53/225], Training Accuracy: 87.7653%, Training Loss: 0.3235%\n",
      "Epoch [37/300], Step [54/225], Training Accuracy: 87.5000%, Training Loss: 0.3290%\n",
      "Epoch [37/300], Step [55/225], Training Accuracy: 87.5000%, Training Loss: 0.3283%\n",
      "Epoch [37/300], Step [56/225], Training Accuracy: 87.4721%, Training Loss: 0.3271%\n",
      "Epoch [37/300], Step [57/225], Training Accuracy: 87.5274%, Training Loss: 0.3257%\n",
      "Epoch [37/300], Step [58/225], Training Accuracy: 87.5539%, Training Loss: 0.3249%\n",
      "Epoch [37/300], Step [59/225], Training Accuracy: 87.4206%, Training Loss: 0.3271%\n",
      "Epoch [37/300], Step [60/225], Training Accuracy: 87.4479%, Training Loss: 0.3265%\n",
      "Epoch [37/300], Step [61/225], Training Accuracy: 87.4744%, Training Loss: 0.3284%\n",
      "Epoch [37/300], Step [62/225], Training Accuracy: 87.4496%, Training Loss: 0.3281%\n",
      "Epoch [37/300], Step [63/225], Training Accuracy: 87.5248%, Training Loss: 0.3271%\n",
      "Epoch [37/300], Step [64/225], Training Accuracy: 87.2803%, Training Loss: 0.3313%\n",
      "Epoch [37/300], Step [65/225], Training Accuracy: 87.3077%, Training Loss: 0.3300%\n",
      "Epoch [37/300], Step [66/225], Training Accuracy: 87.2633%, Training Loss: 0.3322%\n",
      "Epoch [37/300], Step [67/225], Training Accuracy: 87.2668%, Training Loss: 0.3330%\n",
      "Epoch [37/300], Step [68/225], Training Accuracy: 87.2243%, Training Loss: 0.3339%\n",
      "Epoch [37/300], Step [69/225], Training Accuracy: 87.2509%, Training Loss: 0.3335%\n",
      "Epoch [37/300], Step [70/225], Training Accuracy: 87.1652%, Training Loss: 0.3350%\n",
      "Epoch [37/300], Step [71/225], Training Accuracy: 87.1259%, Training Loss: 0.3350%\n",
      "Epoch [37/300], Step [72/225], Training Accuracy: 87.0877%, Training Loss: 0.3350%\n",
      "Epoch [37/300], Step [73/225], Training Accuracy: 86.9863%, Training Loss: 0.3369%\n",
      "Epoch [37/300], Step [74/225], Training Accuracy: 86.9721%, Training Loss: 0.3371%\n",
      "Epoch [37/300], Step [75/225], Training Accuracy: 87.0000%, Training Loss: 0.3359%\n",
      "Epoch [37/300], Step [76/225], Training Accuracy: 87.0477%, Training Loss: 0.3356%\n",
      "Epoch [37/300], Step [77/225], Training Accuracy: 87.1144%, Training Loss: 0.3342%\n",
      "Epoch [37/300], Step [78/225], Training Accuracy: 87.1394%, Training Loss: 0.3331%\n",
      "Epoch [37/300], Step [79/225], Training Accuracy: 87.0451%, Training Loss: 0.3340%\n",
      "Epoch [37/300], Step [80/225], Training Accuracy: 86.9922%, Training Loss: 0.3344%\n",
      "Epoch [37/300], Step [81/225], Training Accuracy: 87.0370%, Training Loss: 0.3335%\n",
      "Epoch [37/300], Step [82/225], Training Accuracy: 86.9855%, Training Loss: 0.3340%\n",
      "Epoch [37/300], Step [83/225], Training Accuracy: 87.0105%, Training Loss: 0.3345%\n",
      "Epoch [37/300], Step [84/225], Training Accuracy: 86.9978%, Training Loss: 0.3340%\n",
      "Epoch [37/300], Step [85/225], Training Accuracy: 86.9853%, Training Loss: 0.3337%\n",
      "Epoch [37/300], Step [86/225], Training Accuracy: 86.9731%, Training Loss: 0.3345%\n",
      "Epoch [37/300], Step [87/225], Training Accuracy: 87.0330%, Training Loss: 0.3336%\n",
      "Epoch [37/300], Step [88/225], Training Accuracy: 87.0028%, Training Loss: 0.3335%\n",
      "Epoch [37/300], Step [89/225], Training Accuracy: 87.0435%, Training Loss: 0.3323%\n",
      "Epoch [37/300], Step [90/225], Training Accuracy: 87.0139%, Training Loss: 0.3330%\n",
      "Epoch [37/300], Step [91/225], Training Accuracy: 87.0021%, Training Loss: 0.3328%\n",
      "Epoch [37/300], Step [92/225], Training Accuracy: 87.0414%, Training Loss: 0.3322%\n",
      "Epoch [37/300], Step [93/225], Training Accuracy: 87.0800%, Training Loss: 0.3313%\n",
      "Epoch [37/300], Step [94/225], Training Accuracy: 87.0512%, Training Loss: 0.3322%\n",
      "Epoch [37/300], Step [95/225], Training Accuracy: 87.0888%, Training Loss: 0.3322%\n",
      "Epoch [37/300], Step [96/225], Training Accuracy: 87.1094%, Training Loss: 0.3313%\n",
      "Epoch [37/300], Step [97/225], Training Accuracy: 87.1295%, Training Loss: 0.3310%\n",
      "Epoch [37/300], Step [98/225], Training Accuracy: 87.0855%, Training Loss: 0.3313%\n",
      "Epoch [37/300], Step [99/225], Training Accuracy: 87.0896%, Training Loss: 0.3310%\n",
      "Epoch [37/300], Step [100/225], Training Accuracy: 86.9844%, Training Loss: 0.3329%\n",
      "Epoch [37/300], Step [101/225], Training Accuracy: 87.0359%, Training Loss: 0.3320%\n",
      "Epoch [37/300], Step [102/225], Training Accuracy: 87.0251%, Training Loss: 0.3322%\n",
      "Epoch [37/300], Step [103/225], Training Accuracy: 86.9994%, Training Loss: 0.3333%\n",
      "Epoch [37/300], Step [104/225], Training Accuracy: 87.0192%, Training Loss: 0.3330%\n",
      "Epoch [37/300], Step [105/225], Training Accuracy: 87.0238%, Training Loss: 0.3327%\n",
      "Epoch [37/300], Step [106/225], Training Accuracy: 87.0430%, Training Loss: 0.3323%\n",
      "Epoch [37/300], Step [107/225], Training Accuracy: 87.0035%, Training Loss: 0.3328%\n",
      "Epoch [37/300], Step [108/225], Training Accuracy: 86.9647%, Training Loss: 0.3325%\n",
      "Epoch [37/300], Step [109/225], Training Accuracy: 86.9553%, Training Loss: 0.3321%\n",
      "Epoch [37/300], Step [110/225], Training Accuracy: 86.9886%, Training Loss: 0.3314%\n",
      "Epoch [37/300], Step [111/225], Training Accuracy: 86.9510%, Training Loss: 0.3312%\n",
      "Epoch [37/300], Step [112/225], Training Accuracy: 86.9699%, Training Loss: 0.3306%\n",
      "Epoch [37/300], Step [113/225], Training Accuracy: 87.0160%, Training Loss: 0.3302%\n",
      "Epoch [37/300], Step [114/225], Training Accuracy: 87.0066%, Training Loss: 0.3299%\n",
      "Epoch [37/300], Step [115/225], Training Accuracy: 87.0516%, Training Loss: 0.3291%\n",
      "Epoch [37/300], Step [116/225], Training Accuracy: 87.0286%, Training Loss: 0.3299%\n",
      "Epoch [37/300], Step [117/225], Training Accuracy: 87.0192%, Training Loss: 0.3299%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/300], Step [118/225], Training Accuracy: 87.0101%, Training Loss: 0.3301%\n",
      "Epoch [37/300], Step [119/225], Training Accuracy: 86.9879%, Training Loss: 0.3303%\n",
      "Epoch [37/300], Step [120/225], Training Accuracy: 87.0312%, Training Loss: 0.3290%\n",
      "Epoch [37/300], Step [121/225], Training Accuracy: 87.0222%, Training Loss: 0.3287%\n",
      "Epoch [37/300], Step [122/225], Training Accuracy: 87.0645%, Training Loss: 0.3276%\n",
      "Epoch [37/300], Step [123/225], Training Accuracy: 87.0427%, Training Loss: 0.3279%\n",
      "Epoch [37/300], Step [124/225], Training Accuracy: 87.0464%, Training Loss: 0.3277%\n",
      "Epoch [37/300], Step [125/225], Training Accuracy: 87.0500%, Training Loss: 0.3272%\n",
      "Epoch [37/300], Step [126/225], Training Accuracy: 87.0660%, Training Loss: 0.3268%\n",
      "Epoch [37/300], Step [127/225], Training Accuracy: 87.0448%, Training Loss: 0.3271%\n",
      "Epoch [37/300], Step [128/225], Training Accuracy: 87.0239%, Training Loss: 0.3275%\n",
      "Epoch [37/300], Step [129/225], Training Accuracy: 87.0155%, Training Loss: 0.3274%\n",
      "Epoch [37/300], Step [130/225], Training Accuracy: 86.9591%, Training Loss: 0.3279%\n",
      "Epoch [37/300], Step [131/225], Training Accuracy: 86.9871%, Training Loss: 0.3276%\n",
      "Epoch [37/300], Step [132/225], Training Accuracy: 86.9673%, Training Loss: 0.3279%\n",
      "Epoch [37/300], Step [133/225], Training Accuracy: 86.9948%, Training Loss: 0.3271%\n",
      "Epoch [37/300], Step [134/225], Training Accuracy: 87.0219%, Training Loss: 0.3267%\n",
      "Epoch [37/300], Step [135/225], Training Accuracy: 87.0255%, Training Loss: 0.3263%\n",
      "Epoch [37/300], Step [136/225], Training Accuracy: 87.0175%, Training Loss: 0.3276%\n",
      "Epoch [37/300], Step [137/225], Training Accuracy: 87.0210%, Training Loss: 0.3271%\n",
      "Epoch [37/300], Step [138/225], Training Accuracy: 87.0245%, Training Loss: 0.3267%\n",
      "Epoch [37/300], Step [139/225], Training Accuracy: 86.9717%, Training Loss: 0.3275%\n",
      "Epoch [37/300], Step [140/225], Training Accuracy: 86.9866%, Training Loss: 0.3270%\n",
      "Epoch [37/300], Step [141/225], Training Accuracy: 86.9681%, Training Loss: 0.3278%\n",
      "Epoch [37/300], Step [142/225], Training Accuracy: 86.9278%, Training Loss: 0.3282%\n",
      "Epoch [37/300], Step [143/225], Training Accuracy: 86.8881%, Training Loss: 0.3291%\n",
      "Epoch [37/300], Step [144/225], Training Accuracy: 86.9141%, Training Loss: 0.3287%\n",
      "Epoch [37/300], Step [145/225], Training Accuracy: 86.9289%, Training Loss: 0.3284%\n",
      "Epoch [37/300], Step [146/225], Training Accuracy: 86.9114%, Training Loss: 0.3288%\n",
      "Epoch [37/300], Step [147/225], Training Accuracy: 86.8941%, Training Loss: 0.3293%\n",
      "Epoch [37/300], Step [148/225], Training Accuracy: 86.9088%, Training Loss: 0.3290%\n",
      "Epoch [37/300], Step [149/225], Training Accuracy: 86.9023%, Training Loss: 0.3290%\n",
      "Epoch [37/300], Step [150/225], Training Accuracy: 86.9271%, Training Loss: 0.3281%\n",
      "Epoch [37/300], Step [151/225], Training Accuracy: 86.9619%, Training Loss: 0.3278%\n",
      "Epoch [37/300], Step [152/225], Training Accuracy: 87.0066%, Training Loss: 0.3273%\n",
      "Epoch [37/300], Step [153/225], Training Accuracy: 86.9996%, Training Loss: 0.3273%\n",
      "Epoch [37/300], Step [154/225], Training Accuracy: 86.9927%, Training Loss: 0.3272%\n",
      "Epoch [37/300], Step [155/225], Training Accuracy: 86.9657%, Training Loss: 0.3270%\n",
      "Epoch [37/300], Step [156/225], Training Accuracy: 86.9892%, Training Loss: 0.3270%\n",
      "Epoch [37/300], Step [157/225], Training Accuracy: 86.9725%, Training Loss: 0.3269%\n",
      "Epoch [37/300], Step [158/225], Training Accuracy: 87.0154%, Training Loss: 0.3261%\n",
      "Epoch [37/300], Step [159/225], Training Accuracy: 87.0185%, Training Loss: 0.3257%\n",
      "Epoch [37/300], Step [160/225], Training Accuracy: 87.0215%, Training Loss: 0.3258%\n",
      "Epoch [37/300], Step [161/225], Training Accuracy: 87.0245%, Training Loss: 0.3260%\n",
      "Epoch [37/300], Step [162/225], Training Accuracy: 87.0274%, Training Loss: 0.3258%\n",
      "Epoch [37/300], Step [163/225], Training Accuracy: 87.0111%, Training Loss: 0.3257%\n",
      "Epoch [37/300], Step [164/225], Training Accuracy: 87.0332%, Training Loss: 0.3253%\n",
      "Epoch [37/300], Step [165/225], Training Accuracy: 87.0644%, Training Loss: 0.3248%\n",
      "Epoch [37/300], Step [166/225], Training Accuracy: 87.0670%, Training Loss: 0.3247%\n",
      "Epoch [37/300], Step [167/225], Training Accuracy: 87.0603%, Training Loss: 0.3249%\n",
      "Epoch [37/300], Step [168/225], Training Accuracy: 87.0815%, Training Loss: 0.3246%\n",
      "Epoch [37/300], Step [169/225], Training Accuracy: 87.0470%, Training Loss: 0.3250%\n",
      "Epoch [37/300], Step [170/225], Training Accuracy: 87.0221%, Training Loss: 0.3255%\n",
      "Epoch [37/300], Step [171/225], Training Accuracy: 87.0066%, Training Loss: 0.3257%\n",
      "Epoch [37/300], Step [172/225], Training Accuracy: 87.0004%, Training Loss: 0.3257%\n",
      "Epoch [37/300], Step [173/225], Training Accuracy: 86.9852%, Training Loss: 0.3258%\n",
      "Epoch [37/300], Step [174/225], Training Accuracy: 86.9792%, Training Loss: 0.3261%\n",
      "Epoch [37/300], Step [175/225], Training Accuracy: 86.9911%, Training Loss: 0.3256%\n",
      "Epoch [37/300], Step [176/225], Training Accuracy: 86.9673%, Training Loss: 0.3259%\n",
      "Epoch [37/300], Step [177/225], Training Accuracy: 87.0233%, Training Loss: 0.3250%\n",
      "Epoch [37/300], Step [178/225], Training Accuracy: 86.9996%, Training Loss: 0.3254%\n",
      "Epoch [37/300], Step [179/225], Training Accuracy: 87.0112%, Training Loss: 0.3256%\n",
      "Epoch [37/300], Step [180/225], Training Accuracy: 87.0139%, Training Loss: 0.3258%\n",
      "Epoch [37/300], Step [181/225], Training Accuracy: 87.0079%, Training Loss: 0.3265%\n",
      "Epoch [37/300], Step [182/225], Training Accuracy: 87.0106%, Training Loss: 0.3263%\n",
      "Epoch [37/300], Step [183/225], Training Accuracy: 87.0219%, Training Loss: 0.3259%\n",
      "Epoch [37/300], Step [184/225], Training Accuracy: 87.0329%, Training Loss: 0.3262%\n",
      "Epoch [37/300], Step [185/225], Training Accuracy: 87.0439%, Training Loss: 0.3264%\n",
      "Epoch [37/300], Step [186/225], Training Accuracy: 87.0968%, Training Loss: 0.3257%\n",
      "Epoch [37/300], Step [187/225], Training Accuracy: 87.1324%, Training Loss: 0.3252%\n",
      "Epoch [37/300], Step [188/225], Training Accuracy: 87.1426%, Training Loss: 0.3252%\n",
      "Epoch [37/300], Step [189/225], Training Accuracy: 87.1528%, Training Loss: 0.3248%\n",
      "Epoch [37/300], Step [190/225], Training Accuracy: 87.1464%, Training Loss: 0.3249%\n",
      "Epoch [37/300], Step [191/225], Training Accuracy: 87.1891%, Training Loss: 0.3243%\n",
      "Epoch [37/300], Step [192/225], Training Accuracy: 87.1745%, Training Loss: 0.3248%\n",
      "Epoch [37/300], Step [193/225], Training Accuracy: 87.1762%, Training Loss: 0.3249%\n",
      "Epoch [37/300], Step [194/225], Training Accuracy: 87.2262%, Training Loss: 0.3241%\n",
      "Epoch [37/300], Step [195/225], Training Accuracy: 87.2516%, Training Loss: 0.3237%\n",
      "Epoch [37/300], Step [196/225], Training Accuracy: 87.2210%, Training Loss: 0.3238%\n",
      "Epoch [37/300], Step [197/225], Training Accuracy: 87.2065%, Training Loss: 0.3243%\n",
      "Epoch [37/300], Step [198/225], Training Accuracy: 87.2317%, Training Loss: 0.3240%\n",
      "Epoch [37/300], Step [199/225], Training Accuracy: 87.2173%, Training Loss: 0.3247%\n",
      "Epoch [37/300], Step [200/225], Training Accuracy: 87.2500%, Training Loss: 0.3244%\n",
      "Epoch [37/300], Step [201/225], Training Accuracy: 87.2357%, Training Loss: 0.3247%\n",
      "Epoch [37/300], Step [202/225], Training Accuracy: 87.2447%, Training Loss: 0.3244%\n",
      "Epoch [37/300], Step [203/225], Training Accuracy: 87.2306%, Training Loss: 0.3250%\n",
      "Epoch [37/300], Step [204/225], Training Accuracy: 87.2626%, Training Loss: 0.3246%\n",
      "Epoch [37/300], Step [205/225], Training Accuracy: 87.2485%, Training Loss: 0.3247%\n",
      "Epoch [37/300], Step [206/225], Training Accuracy: 87.2194%, Training Loss: 0.3247%\n",
      "Epoch [37/300], Step [207/225], Training Accuracy: 87.2509%, Training Loss: 0.3240%\n",
      "Epoch [37/300], Step [208/225], Training Accuracy: 87.2671%, Training Loss: 0.3240%\n",
      "Epoch [37/300], Step [209/225], Training Accuracy: 87.2981%, Training Loss: 0.3238%\n",
      "Epoch [37/300], Step [210/225], Training Accuracy: 87.3140%, Training Loss: 0.3235%\n",
      "Epoch [37/300], Step [211/225], Training Accuracy: 87.3149%, Training Loss: 0.3234%\n",
      "Epoch [37/300], Step [212/225], Training Accuracy: 87.3231%, Training Loss: 0.3239%\n",
      "Epoch [37/300], Step [213/225], Training Accuracy: 87.3386%, Training Loss: 0.3237%\n",
      "Epoch [37/300], Step [214/225], Training Accuracy: 87.3394%, Training Loss: 0.3235%\n",
      "Epoch [37/300], Step [215/225], Training Accuracy: 87.3547%, Training Loss: 0.3232%\n",
      "Epoch [37/300], Step [216/225], Training Accuracy: 87.3336%, Training Loss: 0.3237%\n",
      "Epoch [37/300], Step [217/225], Training Accuracy: 87.3416%, Training Loss: 0.3236%\n",
      "Epoch [37/300], Step [218/225], Training Accuracy: 87.3710%, Training Loss: 0.3230%\n",
      "Epoch [37/300], Step [219/225], Training Accuracy: 87.4001%, Training Loss: 0.3223%\n",
      "Epoch [37/300], Step [220/225], Training Accuracy: 87.4077%, Training Loss: 0.3220%\n",
      "Epoch [37/300], Step [221/225], Training Accuracy: 87.3939%, Training Loss: 0.3225%\n",
      "Epoch [37/300], Step [222/225], Training Accuracy: 87.4015%, Training Loss: 0.3224%\n",
      "Epoch [37/300], Step [223/225], Training Accuracy: 87.3879%, Training Loss: 0.3223%\n",
      "Epoch [37/300], Step [224/225], Training Accuracy: 87.4023%, Training Loss: 0.3219%\n",
      "Epoch [37/300], Step [225/225], Training Accuracy: 87.4166%, Training Loss: 0.3213%\n",
      "Epoch [38/300], Step [1/225], Training Accuracy: 90.6250%, Training Loss: 0.3481%\n",
      "Epoch [38/300], Step [2/225], Training Accuracy: 90.6250%, Training Loss: 0.3360%\n",
      "Epoch [38/300], Step [3/225], Training Accuracy: 87.5000%, Training Loss: 0.3978%\n",
      "Epoch [38/300], Step [4/225], Training Accuracy: 88.2812%, Training Loss: 0.3816%\n",
      "Epoch [38/300], Step [5/225], Training Accuracy: 88.7500%, Training Loss: 0.3679%\n",
      "Epoch [38/300], Step [6/225], Training Accuracy: 88.2812%, Training Loss: 0.3607%\n",
      "Epoch [38/300], Step [7/225], Training Accuracy: 87.7232%, Training Loss: 0.3731%\n",
      "Epoch [38/300], Step [8/225], Training Accuracy: 87.8906%, Training Loss: 0.3581%\n",
      "Epoch [38/300], Step [9/225], Training Accuracy: 88.3681%, Training Loss: 0.3421%\n",
      "Epoch [38/300], Step [10/225], Training Accuracy: 88.5938%, Training Loss: 0.3452%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/300], Step [11/225], Training Accuracy: 88.4943%, Training Loss: 0.3402%\n",
      "Epoch [38/300], Step [12/225], Training Accuracy: 88.8021%, Training Loss: 0.3338%\n",
      "Epoch [38/300], Step [13/225], Training Accuracy: 89.3029%, Training Loss: 0.3210%\n",
      "Epoch [38/300], Step [14/225], Training Accuracy: 89.3973%, Training Loss: 0.3228%\n",
      "Epoch [38/300], Step [15/225], Training Accuracy: 89.5833%, Training Loss: 0.3199%\n",
      "Epoch [38/300], Step [16/225], Training Accuracy: 89.5508%, Training Loss: 0.3178%\n",
      "Epoch [38/300], Step [17/225], Training Accuracy: 89.1544%, Training Loss: 0.3249%\n",
      "Epoch [38/300], Step [18/225], Training Accuracy: 88.8889%, Training Loss: 0.3263%\n",
      "Epoch [38/300], Step [19/225], Training Accuracy: 88.7336%, Training Loss: 0.3271%\n",
      "Epoch [38/300], Step [20/225], Training Accuracy: 88.7500%, Training Loss: 0.3238%\n",
      "Epoch [38/300], Step [21/225], Training Accuracy: 89.0625%, Training Loss: 0.3169%\n",
      "Epoch [38/300], Step [22/225], Training Accuracy: 89.1335%, Training Loss: 0.3174%\n",
      "Epoch [38/300], Step [23/225], Training Accuracy: 89.1984%, Training Loss: 0.3182%\n",
      "Epoch [38/300], Step [24/225], Training Accuracy: 89.0625%, Training Loss: 0.3229%\n",
      "Epoch [38/300], Step [25/225], Training Accuracy: 89.0625%, Training Loss: 0.3204%\n",
      "Epoch [38/300], Step [26/225], Training Accuracy: 88.8221%, Training Loss: 0.3230%\n",
      "Epoch [38/300], Step [27/225], Training Accuracy: 88.7153%, Training Loss: 0.3259%\n",
      "Epoch [38/300], Step [28/225], Training Accuracy: 88.7835%, Training Loss: 0.3215%\n",
      "Epoch [38/300], Step [29/225], Training Accuracy: 88.9547%, Training Loss: 0.3192%\n",
      "Epoch [38/300], Step [30/225], Training Accuracy: 88.9583%, Training Loss: 0.3184%\n",
      "Epoch [38/300], Step [31/225], Training Accuracy: 88.7097%, Training Loss: 0.3214%\n",
      "Epoch [38/300], Step [32/225], Training Accuracy: 88.9648%, Training Loss: 0.3169%\n",
      "Epoch [38/300], Step [33/225], Training Accuracy: 89.0625%, Training Loss: 0.3150%\n",
      "Epoch [38/300], Step [34/225], Training Accuracy: 89.1544%, Training Loss: 0.3111%\n",
      "Epoch [38/300], Step [35/225], Training Accuracy: 89.0625%, Training Loss: 0.3115%\n",
      "Epoch [38/300], Step [36/225], Training Accuracy: 89.1493%, Training Loss: 0.3088%\n",
      "Epoch [38/300], Step [37/225], Training Accuracy: 89.1892%, Training Loss: 0.3087%\n",
      "Epoch [38/300], Step [38/225], Training Accuracy: 89.2270%, Training Loss: 0.3081%\n",
      "Epoch [38/300], Step [39/225], Training Accuracy: 89.2628%, Training Loss: 0.3075%\n",
      "Epoch [38/300], Step [40/225], Training Accuracy: 89.2969%, Training Loss: 0.3089%\n",
      "Epoch [38/300], Step [41/225], Training Accuracy: 89.1387%, Training Loss: 0.3108%\n",
      "Epoch [38/300], Step [42/225], Training Accuracy: 89.1369%, Training Loss: 0.3098%\n",
      "Epoch [38/300], Step [43/225], Training Accuracy: 89.1715%, Training Loss: 0.3084%\n",
      "Epoch [38/300], Step [44/225], Training Accuracy: 89.1335%, Training Loss: 0.3074%\n",
      "Epoch [38/300], Step [45/225], Training Accuracy: 89.1319%, Training Loss: 0.3058%\n",
      "Epoch [38/300], Step [46/225], Training Accuracy: 89.0965%, Training Loss: 0.3051%\n",
      "Epoch [38/300], Step [47/225], Training Accuracy: 89.1290%, Training Loss: 0.3048%\n",
      "Epoch [38/300], Step [48/225], Training Accuracy: 88.9974%, Training Loss: 0.3062%\n",
      "Epoch [38/300], Step [49/225], Training Accuracy: 89.0625%, Training Loss: 0.3042%\n",
      "Epoch [38/300], Step [50/225], Training Accuracy: 89.0625%, Training Loss: 0.3042%\n",
      "Epoch [38/300], Step [51/225], Training Accuracy: 89.0319%, Training Loss: 0.3054%\n",
      "Epoch [38/300], Step [52/225], Training Accuracy: 89.0925%, Training Loss: 0.3055%\n",
      "Epoch [38/300], Step [53/225], Training Accuracy: 89.0920%, Training Loss: 0.3053%\n",
      "Epoch [38/300], Step [54/225], Training Accuracy: 88.9178%, Training Loss: 0.3086%\n",
      "Epoch [38/300], Step [55/225], Training Accuracy: 88.8636%, Training Loss: 0.3096%\n",
      "Epoch [38/300], Step [56/225], Training Accuracy: 88.9230%, Training Loss: 0.3077%\n",
      "Epoch [38/300], Step [57/225], Training Accuracy: 88.8432%, Training Loss: 0.3089%\n",
      "Epoch [38/300], Step [58/225], Training Accuracy: 88.8200%, Training Loss: 0.3076%\n",
      "Epoch [38/300], Step [59/225], Training Accuracy: 88.7712%, Training Loss: 0.3082%\n",
      "Epoch [38/300], Step [60/225], Training Accuracy: 88.7500%, Training Loss: 0.3084%\n",
      "Epoch [38/300], Step [61/225], Training Accuracy: 88.7039%, Training Loss: 0.3100%\n",
      "Epoch [38/300], Step [62/225], Training Accuracy: 88.6593%, Training Loss: 0.3100%\n",
      "Epoch [38/300], Step [63/225], Training Accuracy: 88.6161%, Training Loss: 0.3104%\n",
      "Epoch [38/300], Step [64/225], Training Accuracy: 88.5986%, Training Loss: 0.3117%\n",
      "Epoch [38/300], Step [65/225], Training Accuracy: 88.6779%, Training Loss: 0.3098%\n",
      "Epoch [38/300], Step [66/225], Training Accuracy: 88.6837%, Training Loss: 0.3100%\n",
      "Epoch [38/300], Step [67/225], Training Accuracy: 88.7127%, Training Loss: 0.3098%\n",
      "Epoch [38/300], Step [68/225], Training Accuracy: 88.6029%, Training Loss: 0.3129%\n",
      "Epoch [38/300], Step [69/225], Training Accuracy: 88.6096%, Training Loss: 0.3133%\n",
      "Epoch [38/300], Step [70/225], Training Accuracy: 88.6161%, Training Loss: 0.3134%\n",
      "Epoch [38/300], Step [71/225], Training Accuracy: 88.6444%, Training Loss: 0.3132%\n",
      "Epoch [38/300], Step [72/225], Training Accuracy: 88.5417%, Training Loss: 0.3136%\n",
      "Epoch [38/300], Step [73/225], Training Accuracy: 88.5060%, Training Loss: 0.3138%\n",
      "Epoch [38/300], Step [74/225], Training Accuracy: 88.5557%, Training Loss: 0.3133%\n",
      "Epoch [38/300], Step [75/225], Training Accuracy: 88.5208%, Training Loss: 0.3134%\n",
      "Epoch [38/300], Step [76/225], Training Accuracy: 88.4663%, Training Loss: 0.3141%\n",
      "Epoch [38/300], Step [77/225], Training Accuracy: 88.5146%, Training Loss: 0.3128%\n",
      "Epoch [38/300], Step [78/225], Training Accuracy: 88.6218%, Training Loss: 0.3108%\n",
      "Epoch [38/300], Step [79/225], Training Accuracy: 88.7065%, Training Loss: 0.3099%\n",
      "Epoch [38/300], Step [80/225], Training Accuracy: 88.7305%, Training Loss: 0.3093%\n",
      "Epoch [38/300], Step [81/225], Training Accuracy: 88.7153%, Training Loss: 0.3089%\n",
      "Epoch [38/300], Step [82/225], Training Accuracy: 88.6623%, Training Loss: 0.3092%\n",
      "Epoch [38/300], Step [83/225], Training Accuracy: 88.6483%, Training Loss: 0.3097%\n",
      "Epoch [38/300], Step [84/225], Training Accuracy: 88.5603%, Training Loss: 0.3109%\n",
      "Epoch [38/300], Step [85/225], Training Accuracy: 88.5662%, Training Loss: 0.3111%\n",
      "Epoch [38/300], Step [86/225], Training Accuracy: 88.5719%, Training Loss: 0.3118%\n",
      "Epoch [38/300], Step [87/225], Training Accuracy: 88.4878%, Training Loss: 0.3135%\n",
      "Epoch [38/300], Step [88/225], Training Accuracy: 88.4233%, Training Loss: 0.3149%\n",
      "Epoch [38/300], Step [89/225], Training Accuracy: 88.3778%, Training Loss: 0.3163%\n",
      "Epoch [38/300], Step [90/225], Training Accuracy: 88.3507%, Training Loss: 0.3165%\n",
      "Epoch [38/300], Step [91/225], Training Accuracy: 88.3757%, Training Loss: 0.3160%\n",
      "Epoch [38/300], Step [92/225], Training Accuracy: 88.3492%, Training Loss: 0.3159%\n",
      "Epoch [38/300], Step [93/225], Training Accuracy: 88.3737%, Training Loss: 0.3161%\n",
      "Epoch [38/300], Step [94/225], Training Accuracy: 88.3477%, Training Loss: 0.3158%\n",
      "Epoch [38/300], Step [95/225], Training Accuracy: 88.3553%, Training Loss: 0.3154%\n",
      "Epoch [38/300], Step [96/225], Training Accuracy: 88.4115%, Training Loss: 0.3141%\n",
      "Epoch [38/300], Step [97/225], Training Accuracy: 88.3860%, Training Loss: 0.3147%\n",
      "Epoch [38/300], Step [98/225], Training Accuracy: 88.3610%, Training Loss: 0.3159%\n",
      "Epoch [38/300], Step [99/225], Training Accuracy: 88.3838%, Training Loss: 0.3158%\n",
      "Epoch [38/300], Step [100/225], Training Accuracy: 88.3906%, Training Loss: 0.3155%\n",
      "Epoch [38/300], Step [101/225], Training Accuracy: 88.4282%, Training Loss: 0.3148%\n",
      "Epoch [38/300], Step [102/225], Training Accuracy: 88.4191%, Training Loss: 0.3148%\n",
      "Epoch [38/300], Step [103/225], Training Accuracy: 88.3495%, Training Loss: 0.3167%\n",
      "Epoch [38/300], Step [104/225], Training Accuracy: 88.3263%, Training Loss: 0.3167%\n",
      "Epoch [38/300], Step [105/225], Training Accuracy: 88.2589%, Training Loss: 0.3185%\n",
      "Epoch [38/300], Step [106/225], Training Accuracy: 88.2370%, Training Loss: 0.3184%\n",
      "Epoch [38/300], Step [107/225], Training Accuracy: 88.2301%, Training Loss: 0.3180%\n",
      "Epoch [38/300], Step [108/225], Training Accuracy: 88.2234%, Training Loss: 0.3180%\n",
      "Epoch [38/300], Step [109/225], Training Accuracy: 88.2454%, Training Loss: 0.3168%\n",
      "Epoch [38/300], Step [110/225], Training Accuracy: 88.2528%, Training Loss: 0.3163%\n",
      "Epoch [38/300], Step [111/225], Training Accuracy: 88.2461%, Training Loss: 0.3167%\n",
      "Epoch [38/300], Step [112/225], Training Accuracy: 88.2533%, Training Loss: 0.3165%\n",
      "Epoch [38/300], Step [113/225], Training Accuracy: 88.2052%, Training Loss: 0.3172%\n",
      "Epoch [38/300], Step [114/225], Training Accuracy: 88.2401%, Training Loss: 0.3168%\n",
      "Epoch [38/300], Step [115/225], Training Accuracy: 88.2201%, Training Loss: 0.3168%\n",
      "Epoch [38/300], Step [116/225], Training Accuracy: 88.1870%, Training Loss: 0.3172%\n",
      "Epoch [38/300], Step [117/225], Training Accuracy: 88.1811%, Training Loss: 0.3167%\n",
      "Epoch [38/300], Step [118/225], Training Accuracy: 88.1488%, Training Loss: 0.3170%\n",
      "Epoch [38/300], Step [119/225], Training Accuracy: 88.1040%, Training Loss: 0.3179%\n",
      "Epoch [38/300], Step [120/225], Training Accuracy: 88.1120%, Training Loss: 0.3182%\n",
      "Epoch [38/300], Step [121/225], Training Accuracy: 88.1457%, Training Loss: 0.3179%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/300], Step [122/225], Training Accuracy: 88.1532%, Training Loss: 0.3177%\n",
      "Epoch [38/300], Step [123/225], Training Accuracy: 88.1479%, Training Loss: 0.3175%\n",
      "Epoch [38/300], Step [124/225], Training Accuracy: 88.1300%, Training Loss: 0.3176%\n",
      "Epoch [38/300], Step [125/225], Training Accuracy: 88.1250%, Training Loss: 0.3174%\n",
      "Epoch [38/300], Step [126/225], Training Accuracy: 88.0952%, Training Loss: 0.3180%\n",
      "Epoch [38/300], Step [127/225], Training Accuracy: 88.1275%, Training Loss: 0.3173%\n",
      "Epoch [38/300], Step [128/225], Training Accuracy: 88.0859%, Training Loss: 0.3193%\n",
      "Epoch [38/300], Step [129/225], Training Accuracy: 88.1420%, Training Loss: 0.3182%\n",
      "Epoch [38/300], Step [130/225], Training Accuracy: 88.1370%, Training Loss: 0.3180%\n",
      "Epoch [38/300], Step [131/225], Training Accuracy: 88.1202%, Training Loss: 0.3184%\n",
      "Epoch [38/300], Step [132/225], Training Accuracy: 88.1392%, Training Loss: 0.3184%\n",
      "Epoch [38/300], Step [133/225], Training Accuracy: 88.1344%, Training Loss: 0.3181%\n",
      "Epoch [38/300], Step [134/225], Training Accuracy: 88.1880%, Training Loss: 0.3172%\n",
      "Epoch [38/300], Step [135/225], Training Accuracy: 88.2060%, Training Loss: 0.3163%\n",
      "Epoch [38/300], Step [136/225], Training Accuracy: 88.2353%, Training Loss: 0.3166%\n",
      "Epoch [38/300], Step [137/225], Training Accuracy: 88.2413%, Training Loss: 0.3162%\n",
      "Epoch [38/300], Step [138/225], Training Accuracy: 88.2360%, Training Loss: 0.3164%\n",
      "Epoch [38/300], Step [139/225], Training Accuracy: 88.1857%, Training Loss: 0.3171%\n",
      "Epoch [38/300], Step [140/225], Training Accuracy: 88.1696%, Training Loss: 0.3171%\n",
      "Epoch [38/300], Step [141/225], Training Accuracy: 88.0984%, Training Loss: 0.3181%\n",
      "Epoch [38/300], Step [142/225], Training Accuracy: 88.0942%, Training Loss: 0.3182%\n",
      "Epoch [38/300], Step [143/225], Training Accuracy: 88.0682%, Training Loss: 0.3196%\n",
      "Epoch [38/300], Step [144/225], Training Accuracy: 88.0968%, Training Loss: 0.3190%\n",
      "Epoch [38/300], Step [145/225], Training Accuracy: 88.1142%, Training Loss: 0.3187%\n",
      "Epoch [38/300], Step [146/225], Training Accuracy: 88.1528%, Training Loss: 0.3179%\n",
      "Epoch [38/300], Step [147/225], Training Accuracy: 88.1378%, Training Loss: 0.3184%\n",
      "Epoch [38/300], Step [148/225], Training Accuracy: 88.1440%, Training Loss: 0.3188%\n",
      "Epoch [38/300], Step [149/225], Training Accuracy: 88.1397%, Training Loss: 0.3191%\n",
      "Epoch [38/300], Step [150/225], Training Accuracy: 88.1771%, Training Loss: 0.3183%\n",
      "Epoch [38/300], Step [151/225], Training Accuracy: 88.2036%, Training Loss: 0.3177%\n",
      "Epoch [38/300], Step [152/225], Training Accuracy: 88.1887%, Training Loss: 0.3174%\n",
      "Epoch [38/300], Step [153/225], Training Accuracy: 88.2149%, Training Loss: 0.3169%\n",
      "Epoch [38/300], Step [154/225], Training Accuracy: 88.2204%, Training Loss: 0.3166%\n",
      "Epoch [38/300], Step [155/225], Training Accuracy: 88.2157%, Training Loss: 0.3168%\n",
      "Epoch [38/300], Step [156/225], Training Accuracy: 88.2111%, Training Loss: 0.3168%\n",
      "Epoch [38/300], Step [157/225], Training Accuracy: 88.2166%, Training Loss: 0.3168%\n",
      "Epoch [38/300], Step [158/225], Training Accuracy: 88.2219%, Training Loss: 0.3161%\n",
      "Epoch [38/300], Step [159/225], Training Accuracy: 88.1977%, Training Loss: 0.3163%\n",
      "Epoch [38/300], Step [160/225], Training Accuracy: 88.1934%, Training Loss: 0.3167%\n",
      "Epoch [38/300], Step [161/225], Training Accuracy: 88.1891%, Training Loss: 0.3164%\n",
      "Epoch [38/300], Step [162/225], Training Accuracy: 88.1944%, Training Loss: 0.3163%\n",
      "Epoch [38/300], Step [163/225], Training Accuracy: 88.1902%, Training Loss: 0.3164%\n",
      "Epoch [38/300], Step [164/225], Training Accuracy: 88.2336%, Training Loss: 0.3157%\n",
      "Epoch [38/300], Step [165/225], Training Accuracy: 88.2765%, Training Loss: 0.3150%\n",
      "Epoch [38/300], Step [166/225], Training Accuracy: 88.2436%, Training Loss: 0.3151%\n",
      "Epoch [38/300], Step [167/225], Training Accuracy: 88.2391%, Training Loss: 0.3149%\n",
      "Epoch [38/300], Step [168/225], Training Accuracy: 88.2254%, Training Loss: 0.3149%\n",
      "Epoch [38/300], Step [169/225], Training Accuracy: 88.2489%, Training Loss: 0.3152%\n",
      "Epoch [38/300], Step [170/225], Training Accuracy: 88.2537%, Training Loss: 0.3152%\n",
      "Epoch [38/300], Step [171/225], Training Accuracy: 88.2675%, Training Loss: 0.3150%\n",
      "Epoch [38/300], Step [172/225], Training Accuracy: 88.2994%, Training Loss: 0.3142%\n",
      "Epoch [38/300], Step [173/225], Training Accuracy: 88.2858%, Training Loss: 0.3143%\n",
      "Epoch [38/300], Step [174/225], Training Accuracy: 88.2633%, Training Loss: 0.3143%\n",
      "Epoch [38/300], Step [175/225], Training Accuracy: 88.2589%, Training Loss: 0.3144%\n",
      "Epoch [38/300], Step [176/225], Training Accuracy: 88.2546%, Training Loss: 0.3145%\n",
      "Epoch [38/300], Step [177/225], Training Accuracy: 88.2592%, Training Loss: 0.3142%\n",
      "Epoch [38/300], Step [178/225], Training Accuracy: 88.2812%, Training Loss: 0.3144%\n",
      "Epoch [38/300], Step [179/225], Training Accuracy: 88.3031%, Training Loss: 0.3145%\n",
      "Epoch [38/300], Step [180/225], Training Accuracy: 88.3247%, Training Loss: 0.3140%\n",
      "Epoch [38/300], Step [181/225], Training Accuracy: 88.2856%, Training Loss: 0.3144%\n",
      "Epoch [38/300], Step [182/225], Training Accuracy: 88.2898%, Training Loss: 0.3141%\n",
      "Epoch [38/300], Step [183/225], Training Accuracy: 88.2770%, Training Loss: 0.3137%\n",
      "Epoch [38/300], Step [184/225], Training Accuracy: 88.3067%, Training Loss: 0.3135%\n",
      "Epoch [38/300], Step [185/225], Training Accuracy: 88.3193%, Training Loss: 0.3134%\n",
      "Epoch [38/300], Step [186/225], Training Accuracy: 88.3401%, Training Loss: 0.3129%\n",
      "Epoch [38/300], Step [187/225], Training Accuracy: 88.3606%, Training Loss: 0.3124%\n",
      "Epoch [38/300], Step [188/225], Training Accuracy: 88.3477%, Training Loss: 0.3130%\n",
      "Epoch [38/300], Step [189/225], Training Accuracy: 88.3763%, Training Loss: 0.3127%\n",
      "Epoch [38/300], Step [190/225], Training Accuracy: 88.3306%, Training Loss: 0.3135%\n",
      "Epoch [38/300], Step [191/225], Training Accuracy: 88.3508%, Training Loss: 0.3129%\n",
      "Epoch [38/300], Step [192/225], Training Accuracy: 88.3219%, Training Loss: 0.3137%\n",
      "Epoch [38/300], Step [193/225], Training Accuracy: 88.3339%, Training Loss: 0.3136%\n",
      "Epoch [38/300], Step [194/225], Training Accuracy: 88.3537%, Training Loss: 0.3134%\n",
      "Epoch [38/300], Step [195/225], Training Accuracy: 88.3574%, Training Loss: 0.3135%\n",
      "Epoch [38/300], Step [196/225], Training Accuracy: 88.3610%, Training Loss: 0.3135%\n",
      "Epoch [38/300], Step [197/225], Training Accuracy: 88.3645%, Training Loss: 0.3139%\n",
      "Epoch [38/300], Step [198/225], Training Accuracy: 88.3838%, Training Loss: 0.3134%\n",
      "Epoch [38/300], Step [199/225], Training Accuracy: 88.3715%, Training Loss: 0.3136%\n",
      "Epoch [38/300], Step [200/225], Training Accuracy: 88.3750%, Training Loss: 0.3132%\n",
      "Epoch [38/300], Step [201/225], Training Accuracy: 88.3629%, Training Loss: 0.3133%\n",
      "Epoch [38/300], Step [202/225], Training Accuracy: 88.3741%, Training Loss: 0.3134%\n",
      "Epoch [38/300], Step [203/225], Training Accuracy: 88.3775%, Training Loss: 0.3136%\n",
      "Epoch [38/300], Step [204/225], Training Accuracy: 88.3732%, Training Loss: 0.3133%\n",
      "Epoch [38/300], Step [205/225], Training Accuracy: 88.3918%, Training Loss: 0.3131%\n",
      "Epoch [38/300], Step [206/225], Training Accuracy: 88.3950%, Training Loss: 0.3130%\n",
      "Epoch [38/300], Step [207/225], Training Accuracy: 88.4133%, Training Loss: 0.3126%\n",
      "Epoch [38/300], Step [208/225], Training Accuracy: 88.4315%, Training Loss: 0.3124%\n",
      "Epoch [38/300], Step [209/225], Training Accuracy: 88.4345%, Training Loss: 0.3124%\n",
      "Epoch [38/300], Step [210/225], Training Accuracy: 88.4301%, Training Loss: 0.3121%\n",
      "Epoch [38/300], Step [211/225], Training Accuracy: 88.4108%, Training Loss: 0.3122%\n",
      "Epoch [38/300], Step [212/225], Training Accuracy: 88.3771%, Training Loss: 0.3125%\n",
      "Epoch [38/300], Step [213/225], Training Accuracy: 88.3803%, Training Loss: 0.3122%\n",
      "Epoch [38/300], Step [214/225], Training Accuracy: 88.3762%, Training Loss: 0.3120%\n",
      "Epoch [38/300], Step [215/225], Training Accuracy: 88.3939%, Training Loss: 0.3118%\n",
      "Epoch [38/300], Step [216/225], Training Accuracy: 88.3898%, Training Loss: 0.3121%\n",
      "Epoch [38/300], Step [217/225], Training Accuracy: 88.4001%, Training Loss: 0.3117%\n",
      "Epoch [38/300], Step [218/225], Training Accuracy: 88.3816%, Training Loss: 0.3120%\n",
      "Epoch [38/300], Step [219/225], Training Accuracy: 88.3847%, Training Loss: 0.3119%\n",
      "Epoch [38/300], Step [220/225], Training Accuracy: 88.3949%, Training Loss: 0.3116%\n",
      "Epoch [38/300], Step [221/225], Training Accuracy: 88.3979%, Training Loss: 0.3114%\n",
      "Epoch [38/300], Step [222/225], Training Accuracy: 88.3727%, Training Loss: 0.3118%\n",
      "Epoch [38/300], Step [223/225], Training Accuracy: 88.4039%, Training Loss: 0.3113%\n",
      "Epoch [38/300], Step [224/225], Training Accuracy: 88.4347%, Training Loss: 0.3106%\n",
      "Epoch [38/300], Step [225/225], Training Accuracy: 88.4450%, Training Loss: 0.3103%\n",
      "Epoch [39/300], Step [1/225], Training Accuracy: 89.0625%, Training Loss: 0.3499%\n",
      "Epoch [39/300], Step [2/225], Training Accuracy: 90.6250%, Training Loss: 0.2879%\n",
      "Epoch [39/300], Step [3/225], Training Accuracy: 89.0625%, Training Loss: 0.3220%\n",
      "Epoch [39/300], Step [4/225], Training Accuracy: 91.0156%, Training Loss: 0.2834%\n",
      "Epoch [39/300], Step [5/225], Training Accuracy: 90.0000%, Training Loss: 0.2917%\n",
      "Epoch [39/300], Step [6/225], Training Accuracy: 89.0625%, Training Loss: 0.3118%\n",
      "Epoch [39/300], Step [7/225], Training Accuracy: 88.1696%, Training Loss: 0.3422%\n",
      "Epoch [39/300], Step [8/225], Training Accuracy: 88.6719%, Training Loss: 0.3392%\n",
      "Epoch [39/300], Step [9/225], Training Accuracy: 88.5417%, Training Loss: 0.3369%\n",
      "Epoch [39/300], Step [10/225], Training Accuracy: 88.9062%, Training Loss: 0.3287%\n",
      "Epoch [39/300], Step [11/225], Training Accuracy: 89.2045%, Training Loss: 0.3227%\n",
      "Epoch [39/300], Step [12/225], Training Accuracy: 88.8021%, Training Loss: 0.3282%\n",
      "Epoch [39/300], Step [13/225], Training Accuracy: 88.5817%, Training Loss: 0.3291%\n",
      "Epoch [39/300], Step [14/225], Training Accuracy: 88.6161%, Training Loss: 0.3234%\n",
      "Epoch [39/300], Step [15/225], Training Accuracy: 88.9583%, Training Loss: 0.3204%\n",
      "Epoch [39/300], Step [16/225], Training Accuracy: 88.7695%, Training Loss: 0.3255%\n",
      "Epoch [39/300], Step [17/225], Training Accuracy: 88.7868%, Training Loss: 0.3253%\n",
      "Epoch [39/300], Step [18/225], Training Accuracy: 88.5417%, Training Loss: 0.3285%\n",
      "Epoch [39/300], Step [19/225], Training Accuracy: 88.3224%, Training Loss: 0.3292%\n",
      "Epoch [39/300], Step [20/225], Training Accuracy: 88.5156%, Training Loss: 0.3250%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/300], Step [21/225], Training Accuracy: 88.6905%, Training Loss: 0.3172%\n",
      "Epoch [39/300], Step [22/225], Training Accuracy: 88.7784%, Training Loss: 0.3188%\n",
      "Epoch [39/300], Step [23/225], Training Accuracy: 88.7228%, Training Loss: 0.3221%\n",
      "Epoch [39/300], Step [24/225], Training Accuracy: 88.4115%, Training Loss: 0.3302%\n",
      "Epoch [39/300], Step [25/225], Training Accuracy: 88.6250%, Training Loss: 0.3252%\n",
      "Epoch [39/300], Step [26/225], Training Accuracy: 88.7620%, Training Loss: 0.3261%\n",
      "Epoch [39/300], Step [27/225], Training Accuracy: 88.8889%, Training Loss: 0.3255%\n",
      "Epoch [39/300], Step [28/225], Training Accuracy: 89.0625%, Training Loss: 0.3188%\n",
      "Epoch [39/300], Step [29/225], Training Accuracy: 89.0625%, Training Loss: 0.3156%\n",
      "Epoch [39/300], Step [30/225], Training Accuracy: 88.9583%, Training Loss: 0.3175%\n",
      "Epoch [39/300], Step [31/225], Training Accuracy: 88.9617%, Training Loss: 0.3160%\n",
      "Epoch [39/300], Step [32/225], Training Accuracy: 89.0137%, Training Loss: 0.3134%\n",
      "Epoch [39/300], Step [33/225], Training Accuracy: 88.9678%, Training Loss: 0.3175%\n",
      "Epoch [39/300], Step [34/225], Training Accuracy: 88.8327%, Training Loss: 0.3239%\n",
      "Epoch [39/300], Step [35/225], Training Accuracy: 88.7946%, Training Loss: 0.3228%\n",
      "Epoch [39/300], Step [36/225], Training Accuracy: 88.7587%, Training Loss: 0.3230%\n",
      "Epoch [39/300], Step [37/225], Training Accuracy: 88.7669%, Training Loss: 0.3212%\n",
      "Epoch [39/300], Step [38/225], Training Accuracy: 88.8158%, Training Loss: 0.3186%\n",
      "Epoch [39/300], Step [39/225], Training Accuracy: 88.7420%, Training Loss: 0.3195%\n",
      "Epoch [39/300], Step [40/225], Training Accuracy: 88.6719%, Training Loss: 0.3175%\n",
      "Epoch [39/300], Step [41/225], Training Accuracy: 88.6433%, Training Loss: 0.3186%\n",
      "Epoch [39/300], Step [42/225], Training Accuracy: 88.5789%, Training Loss: 0.3221%\n",
      "Epoch [39/300], Step [43/225], Training Accuracy: 88.4811%, Training Loss: 0.3229%\n",
      "Epoch [39/300], Step [44/225], Training Accuracy: 88.4588%, Training Loss: 0.3225%\n",
      "Epoch [39/300], Step [45/225], Training Accuracy: 88.5417%, Training Loss: 0.3194%\n",
      "Epoch [39/300], Step [46/225], Training Accuracy: 88.6209%, Training Loss: 0.3165%\n",
      "Epoch [39/300], Step [47/225], Training Accuracy: 88.5971%, Training Loss: 0.3157%\n",
      "Epoch [39/300], Step [48/225], Training Accuracy: 88.5091%, Training Loss: 0.3180%\n",
      "Epoch [39/300], Step [49/225], Training Accuracy: 88.3929%, Training Loss: 0.3204%\n",
      "Epoch [39/300], Step [50/225], Training Accuracy: 88.4375%, Training Loss: 0.3213%\n",
      "Epoch [39/300], Step [51/225], Training Accuracy: 88.4804%, Training Loss: 0.3200%\n",
      "Epoch [39/300], Step [52/225], Training Accuracy: 88.5817%, Training Loss: 0.3166%\n",
      "Epoch [39/300], Step [53/225], Training Accuracy: 88.5318%, Training Loss: 0.3170%\n",
      "Epoch [39/300], Step [54/225], Training Accuracy: 88.2812%, Training Loss: 0.3196%\n",
      "Epoch [39/300], Step [55/225], Training Accuracy: 88.2955%, Training Loss: 0.3182%\n",
      "Epoch [39/300], Step [56/225], Training Accuracy: 88.3929%, Training Loss: 0.3164%\n",
      "Epoch [39/300], Step [57/225], Training Accuracy: 88.3772%, Training Loss: 0.3178%\n",
      "Epoch [39/300], Step [58/225], Training Accuracy: 88.3621%, Training Loss: 0.3179%\n",
      "Epoch [39/300], Step [59/225], Training Accuracy: 88.3210%, Training Loss: 0.3202%\n",
      "Epoch [39/300], Step [60/225], Training Accuracy: 88.3073%, Training Loss: 0.3202%\n",
      "Epoch [39/300], Step [61/225], Training Accuracy: 88.2684%, Training Loss: 0.3202%\n",
      "Epoch [39/300], Step [62/225], Training Accuracy: 88.2560%, Training Loss: 0.3209%\n",
      "Epoch [39/300], Step [63/225], Training Accuracy: 88.2937%, Training Loss: 0.3203%\n",
      "Epoch [39/300], Step [64/225], Training Accuracy: 88.2568%, Training Loss: 0.3207%\n",
      "Epoch [39/300], Step [65/225], Training Accuracy: 88.2692%, Training Loss: 0.3203%\n",
      "Epoch [39/300], Step [66/225], Training Accuracy: 88.3286%, Training Loss: 0.3191%\n",
      "Epoch [39/300], Step [67/225], Training Accuracy: 88.3862%, Training Loss: 0.3190%\n",
      "Epoch [39/300], Step [68/225], Training Accuracy: 88.3732%, Training Loss: 0.3195%\n",
      "Epoch [39/300], Step [69/225], Training Accuracy: 88.4284%, Training Loss: 0.3177%\n",
      "Epoch [39/300], Step [70/225], Training Accuracy: 88.4821%, Training Loss: 0.3172%\n",
      "Epoch [39/300], Step [71/225], Training Accuracy: 88.5123%, Training Loss: 0.3165%\n",
      "Epoch [39/300], Step [72/225], Training Accuracy: 88.5634%, Training Loss: 0.3150%\n",
      "Epoch [39/300], Step [73/225], Training Accuracy: 88.4846%, Training Loss: 0.3164%\n",
      "Epoch [39/300], Step [74/225], Training Accuracy: 88.4713%, Training Loss: 0.3169%\n",
      "Epoch [39/300], Step [75/225], Training Accuracy: 88.5208%, Training Loss: 0.3155%\n",
      "Epoch [39/300], Step [76/225], Training Accuracy: 88.4046%, Training Loss: 0.3175%\n",
      "Epoch [39/300], Step [77/225], Training Accuracy: 88.4537%, Training Loss: 0.3156%\n",
      "Epoch [39/300], Step [78/225], Training Accuracy: 88.4816%, Training Loss: 0.3153%\n",
      "Epoch [39/300], Step [79/225], Training Accuracy: 88.4889%, Training Loss: 0.3149%\n",
      "Epoch [39/300], Step [80/225], Training Accuracy: 88.4570%, Training Loss: 0.3160%\n",
      "Epoch [39/300], Step [81/225], Training Accuracy: 88.5031%, Training Loss: 0.3153%\n",
      "Epoch [39/300], Step [82/225], Training Accuracy: 88.5099%, Training Loss: 0.3157%\n",
      "Epoch [39/300], Step [83/225], Training Accuracy: 88.4789%, Training Loss: 0.3165%\n",
      "Epoch [39/300], Step [84/225], Training Accuracy: 88.4673%, Training Loss: 0.3157%\n",
      "Epoch [39/300], Step [85/225], Training Accuracy: 88.4559%, Training Loss: 0.3163%\n",
      "Epoch [39/300], Step [86/225], Training Accuracy: 88.4266%, Training Loss: 0.3163%\n",
      "Epoch [39/300], Step [87/225], Training Accuracy: 88.3980%, Training Loss: 0.3168%\n",
      "Epoch [39/300], Step [88/225], Training Accuracy: 88.4233%, Training Loss: 0.3158%\n",
      "Epoch [39/300], Step [89/225], Training Accuracy: 88.4129%, Training Loss: 0.3156%\n",
      "Epoch [39/300], Step [90/225], Training Accuracy: 88.3333%, Training Loss: 0.3162%\n",
      "Epoch [39/300], Step [91/225], Training Accuracy: 88.3413%, Training Loss: 0.3153%\n",
      "Epoch [39/300], Step [92/225], Training Accuracy: 88.3492%, Training Loss: 0.3148%\n",
      "Epoch [39/300], Step [93/225], Training Accuracy: 88.3233%, Training Loss: 0.3143%\n",
      "Epoch [39/300], Step [94/225], Training Accuracy: 88.3810%, Training Loss: 0.3133%\n",
      "Epoch [39/300], Step [95/225], Training Accuracy: 88.4211%, Training Loss: 0.3124%\n",
      "Epoch [39/300], Step [96/225], Training Accuracy: 88.4440%, Training Loss: 0.3117%\n",
      "Epoch [39/300], Step [97/225], Training Accuracy: 88.4987%, Training Loss: 0.3112%\n",
      "Epoch [39/300], Step [98/225], Training Accuracy: 88.5045%, Training Loss: 0.3111%\n",
      "Epoch [39/300], Step [99/225], Training Accuracy: 88.4785%, Training Loss: 0.3114%\n",
      "Epoch [39/300], Step [100/225], Training Accuracy: 88.4062%, Training Loss: 0.3120%\n",
      "Epoch [39/300], Step [101/225], Training Accuracy: 88.4437%, Training Loss: 0.3122%\n",
      "Epoch [39/300], Step [102/225], Training Accuracy: 88.4498%, Training Loss: 0.3117%\n",
      "Epoch [39/300], Step [103/225], Training Accuracy: 88.4254%, Training Loss: 0.3114%\n",
      "Epoch [39/300], Step [104/225], Training Accuracy: 88.3714%, Training Loss: 0.3122%\n",
      "Epoch [39/300], Step [105/225], Training Accuracy: 88.3929%, Training Loss: 0.3118%\n",
      "Epoch [39/300], Step [106/225], Training Accuracy: 88.3402%, Training Loss: 0.3120%\n",
      "Epoch [39/300], Step [107/225], Training Accuracy: 88.3324%, Training Loss: 0.3117%\n",
      "Epoch [39/300], Step [108/225], Training Accuracy: 88.3536%, Training Loss: 0.3118%\n",
      "Epoch [39/300], Step [109/225], Training Accuracy: 88.3314%, Training Loss: 0.3114%\n",
      "Epoch [39/300], Step [110/225], Training Accuracy: 88.3239%, Training Loss: 0.3108%\n",
      "Epoch [39/300], Step [111/225], Training Accuracy: 88.3727%, Training Loss: 0.3100%\n",
      "Epoch [39/300], Step [112/225], Training Accuracy: 88.3650%, Training Loss: 0.3096%\n",
      "Epoch [39/300], Step [113/225], Training Accuracy: 88.3573%, Training Loss: 0.3095%\n",
      "Epoch [39/300], Step [114/225], Training Accuracy: 88.3498%, Training Loss: 0.3099%\n",
      "Epoch [39/300], Step [115/225], Training Accuracy: 88.3424%, Training Loss: 0.3095%\n",
      "Epoch [39/300], Step [116/225], Training Accuracy: 88.3755%, Training Loss: 0.3090%\n",
      "Epoch [39/300], Step [117/225], Training Accuracy: 88.4081%, Training Loss: 0.3087%\n",
      "Epoch [39/300], Step [118/225], Training Accuracy: 88.4269%, Training Loss: 0.3086%\n",
      "Epoch [39/300], Step [119/225], Training Accuracy: 88.4060%, Training Loss: 0.3088%\n",
      "Epoch [39/300], Step [120/225], Training Accuracy: 88.4505%, Training Loss: 0.3076%\n",
      "Epoch [39/300], Step [121/225], Training Accuracy: 88.4427%, Training Loss: 0.3072%\n",
      "Epoch [39/300], Step [122/225], Training Accuracy: 88.4477%, Training Loss: 0.3066%\n",
      "Epoch [39/300], Step [123/225], Training Accuracy: 88.4654%, Training Loss: 0.3063%\n",
      "Epoch [39/300], Step [124/225], Training Accuracy: 88.4955%, Training Loss: 0.3064%\n",
      "Epoch [39/300], Step [125/225], Training Accuracy: 88.4500%, Training Loss: 0.3076%\n",
      "Epoch [39/300], Step [126/225], Training Accuracy: 88.4301%, Training Loss: 0.3079%\n",
      "Epoch [39/300], Step [127/225], Training Accuracy: 88.4473%, Training Loss: 0.3078%\n",
      "Epoch [39/300], Step [128/225], Training Accuracy: 88.4155%, Training Loss: 0.3083%\n",
      "Epoch [39/300], Step [129/225], Training Accuracy: 88.3842%, Training Loss: 0.3084%\n",
      "Epoch [39/300], Step [130/225], Training Accuracy: 88.3293%, Training Loss: 0.3091%\n",
      "Epoch [39/300], Step [131/225], Training Accuracy: 88.2991%, Training Loss: 0.3091%\n",
      "Epoch [39/300], Step [132/225], Training Accuracy: 88.2931%, Training Loss: 0.3094%\n",
      "Epoch [39/300], Step [133/225], Training Accuracy: 88.3341%, Training Loss: 0.3088%\n",
      "Epoch [39/300], Step [134/225], Training Accuracy: 88.3862%, Training Loss: 0.3078%\n",
      "Epoch [39/300], Step [135/225], Training Accuracy: 88.4028%, Training Loss: 0.3069%\n",
      "Epoch [39/300], Step [136/225], Training Accuracy: 88.3732%, Training Loss: 0.3080%\n",
      "Epoch [39/300], Step [137/225], Training Accuracy: 88.3896%, Training Loss: 0.3076%\n",
      "Epoch [39/300], Step [138/225], Training Accuracy: 88.4058%, Training Loss: 0.3070%\n",
      "Epoch [39/300], Step [139/225], Training Accuracy: 88.4218%, Training Loss: 0.3067%\n",
      "Epoch [39/300], Step [140/225], Training Accuracy: 88.3817%, Training Loss: 0.3069%\n",
      "Epoch [39/300], Step [141/225], Training Accuracy: 88.3533%, Training Loss: 0.3077%\n",
      "Epoch [39/300], Step [142/225], Training Accuracy: 88.3693%, Training Loss: 0.3074%\n",
      "Epoch [39/300], Step [143/225], Training Accuracy: 88.3741%, Training Loss: 0.3077%\n",
      "Epoch [39/300], Step [144/225], Training Accuracy: 88.3355%, Training Loss: 0.3079%\n",
      "Epoch [39/300], Step [145/225], Training Accuracy: 88.3513%, Training Loss: 0.3077%\n",
      "Epoch [39/300], Step [146/225], Training Accuracy: 88.3669%, Training Loss: 0.3073%\n",
      "Epoch [39/300], Step [147/225], Training Accuracy: 88.3716%, Training Loss: 0.3071%\n",
      "Epoch [39/300], Step [148/225], Training Accuracy: 88.3657%, Training Loss: 0.3071%\n",
      "Epoch [39/300], Step [149/225], Training Accuracy: 88.3075%, Training Loss: 0.3079%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/300], Step [150/225], Training Accuracy: 88.3333%, Training Loss: 0.3073%\n",
      "Epoch [39/300], Step [151/225], Training Accuracy: 88.3382%, Training Loss: 0.3071%\n",
      "Epoch [39/300], Step [152/225], Training Accuracy: 88.3635%, Training Loss: 0.3065%\n",
      "Epoch [39/300], Step [153/225], Training Accuracy: 88.3578%, Training Loss: 0.3063%\n",
      "Epoch [39/300], Step [154/225], Training Accuracy: 88.3624%, Training Loss: 0.3067%\n",
      "Epoch [39/300], Step [155/225], Training Accuracy: 88.3468%, Training Loss: 0.3067%\n",
      "Epoch [39/300], Step [156/225], Training Accuracy: 88.3514%, Training Loss: 0.3065%\n",
      "Epoch [39/300], Step [157/225], Training Accuracy: 88.3658%, Training Loss: 0.3066%\n",
      "Epoch [39/300], Step [158/225], Training Accuracy: 88.3801%, Training Loss: 0.3061%\n",
      "Epoch [39/300], Step [159/225], Training Accuracy: 88.3648%, Training Loss: 0.3060%\n",
      "Epoch [39/300], Step [160/225], Training Accuracy: 88.3496%, Training Loss: 0.3068%\n",
      "Epoch [39/300], Step [161/225], Training Accuracy: 88.3637%, Training Loss: 0.3061%\n",
      "Epoch [39/300], Step [162/225], Training Accuracy: 88.3681%, Training Loss: 0.3067%\n",
      "Epoch [39/300], Step [163/225], Training Accuracy: 88.3531%, Training Loss: 0.3066%\n",
      "Epoch [39/300], Step [164/225], Training Accuracy: 88.3765%, Training Loss: 0.3060%\n",
      "Epoch [39/300], Step [165/225], Training Accuracy: 88.3902%, Training Loss: 0.3057%\n",
      "Epoch [39/300], Step [166/225], Training Accuracy: 88.3754%, Training Loss: 0.3058%\n",
      "Epoch [39/300], Step [167/225], Training Accuracy: 88.3421%, Training Loss: 0.3068%\n",
      "Epoch [39/300], Step [168/225], Training Accuracy: 88.3464%, Training Loss: 0.3063%\n",
      "Epoch [39/300], Step [169/225], Training Accuracy: 88.3691%, Training Loss: 0.3058%\n",
      "Epoch [39/300], Step [170/225], Training Accuracy: 88.3548%, Training Loss: 0.3057%\n",
      "Epoch [39/300], Step [171/225], Training Accuracy: 88.3589%, Training Loss: 0.3060%\n",
      "Epoch [39/300], Step [172/225], Training Accuracy: 88.3630%, Training Loss: 0.3055%\n",
      "Epoch [39/300], Step [173/225], Training Accuracy: 88.3400%, Training Loss: 0.3056%\n",
      "Epoch [39/300], Step [174/225], Training Accuracy: 88.3531%, Training Loss: 0.3052%\n",
      "Epoch [39/300], Step [175/225], Training Accuracy: 88.3482%, Training Loss: 0.3049%\n",
      "Epoch [39/300], Step [176/225], Training Accuracy: 88.3700%, Training Loss: 0.3047%\n",
      "Epoch [39/300], Step [177/225], Training Accuracy: 88.3651%, Training Loss: 0.3044%\n",
      "Epoch [39/300], Step [178/225], Training Accuracy: 88.3427%, Training Loss: 0.3050%\n",
      "Epoch [39/300], Step [179/225], Training Accuracy: 88.3380%, Training Loss: 0.3053%\n",
      "Epoch [39/300], Step [180/225], Training Accuracy: 88.3247%, Training Loss: 0.3058%\n",
      "Epoch [39/300], Step [181/225], Training Accuracy: 88.3201%, Training Loss: 0.3060%\n",
      "Epoch [39/300], Step [182/225], Training Accuracy: 88.3070%, Training Loss: 0.3061%\n",
      "Epoch [39/300], Step [183/225], Training Accuracy: 88.3538%, Training Loss: 0.3052%\n",
      "Epoch [39/300], Step [184/225], Training Accuracy: 88.3322%, Training Loss: 0.3055%\n",
      "Epoch [39/300], Step [185/225], Training Accuracy: 88.3446%, Training Loss: 0.3054%\n",
      "Epoch [39/300], Step [186/225], Training Accuracy: 88.3737%, Training Loss: 0.3048%\n",
      "Epoch [39/300], Step [187/225], Training Accuracy: 88.3857%, Training Loss: 0.3045%\n",
      "Epoch [39/300], Step [188/225], Training Accuracy: 88.3893%, Training Loss: 0.3044%\n",
      "Epoch [39/300], Step [189/225], Training Accuracy: 88.3681%, Training Loss: 0.3046%\n",
      "Epoch [39/300], Step [190/225], Training Accuracy: 88.3306%, Training Loss: 0.3047%\n",
      "Epoch [39/300], Step [191/225], Training Accuracy: 88.3671%, Training Loss: 0.3041%\n",
      "Epoch [39/300], Step [192/225], Training Accuracy: 88.3545%, Training Loss: 0.3049%\n",
      "Epoch [39/300], Step [193/225], Training Accuracy: 88.3663%, Training Loss: 0.3046%\n",
      "Epoch [39/300], Step [194/225], Training Accuracy: 88.4021%, Training Loss: 0.3038%\n",
      "Epoch [39/300], Step [195/225], Training Accuracy: 88.3814%, Training Loss: 0.3040%\n",
      "Epoch [39/300], Step [196/225], Training Accuracy: 88.4088%, Training Loss: 0.3034%\n",
      "Epoch [39/300], Step [197/225], Training Accuracy: 88.4280%, Training Loss: 0.3030%\n",
      "Epoch [39/300], Step [198/225], Training Accuracy: 88.4628%, Training Loss: 0.3025%\n",
      "Epoch [39/300], Step [199/225], Training Accuracy: 88.4736%, Training Loss: 0.3022%\n",
      "Epoch [39/300], Step [200/225], Training Accuracy: 88.4766%, Training Loss: 0.3022%\n",
      "Epoch [39/300], Step [201/225], Training Accuracy: 88.4562%, Training Loss: 0.3022%\n",
      "Epoch [39/300], Step [202/225], Training Accuracy: 88.4592%, Training Loss: 0.3021%\n",
      "Epoch [39/300], Step [203/225], Training Accuracy: 88.4698%, Training Loss: 0.3020%\n",
      "Epoch [39/300], Step [204/225], Training Accuracy: 88.4804%, Training Loss: 0.3018%\n",
      "Epoch [39/300], Step [205/225], Training Accuracy: 88.4680%, Training Loss: 0.3019%\n",
      "Epoch [39/300], Step [206/225], Training Accuracy: 88.4860%, Training Loss: 0.3017%\n",
      "Epoch [39/300], Step [207/225], Training Accuracy: 88.5039%, Training Loss: 0.3014%\n",
      "Epoch [39/300], Step [208/225], Training Accuracy: 88.5066%, Training Loss: 0.3011%\n",
      "Epoch [39/300], Step [209/225], Training Accuracy: 88.5093%, Training Loss: 0.3013%\n",
      "Epoch [39/300], Step [210/225], Training Accuracy: 88.5491%, Training Loss: 0.3006%\n",
      "Epoch [39/300], Step [211/225], Training Accuracy: 88.5515%, Training Loss: 0.3005%\n",
      "Epoch [39/300], Step [212/225], Training Accuracy: 88.5392%, Training Loss: 0.3006%\n",
      "Epoch [39/300], Step [213/225], Training Accuracy: 88.5490%, Training Loss: 0.3003%\n",
      "Epoch [39/300], Step [214/225], Training Accuracy: 88.5587%, Training Loss: 0.2997%\n",
      "Epoch [39/300], Step [215/225], Training Accuracy: 88.5610%, Training Loss: 0.2996%\n",
      "Epoch [39/300], Step [216/225], Training Accuracy: 88.5489%, Training Loss: 0.3000%\n",
      "Epoch [39/300], Step [217/225], Training Accuracy: 88.5369%, Training Loss: 0.3001%\n",
      "Epoch [39/300], Step [218/225], Training Accuracy: 88.5178%, Training Loss: 0.3006%\n",
      "Epoch [39/300], Step [219/225], Training Accuracy: 88.5203%, Training Loss: 0.3004%\n",
      "Epoch [39/300], Step [220/225], Training Accuracy: 88.5369%, Training Loss: 0.3001%\n",
      "Epoch [39/300], Step [221/225], Training Accuracy: 88.5393%, Training Loss: 0.3003%\n",
      "Epoch [39/300], Step [222/225], Training Accuracy: 88.5487%, Training Loss: 0.3002%\n",
      "Epoch [39/300], Step [223/225], Training Accuracy: 88.5510%, Training Loss: 0.3000%\n",
      "Epoch [39/300], Step [224/225], Training Accuracy: 88.5672%, Training Loss: 0.2995%\n",
      "Epoch [39/300], Step [225/225], Training Accuracy: 88.5839%, Training Loss: 0.2993%\n",
      "Epoch [40/300], Step [1/225], Training Accuracy: 92.1875%, Training Loss: 0.2350%\n",
      "Epoch [40/300], Step [2/225], Training Accuracy: 92.9688%, Training Loss: 0.2131%\n",
      "Epoch [40/300], Step [3/225], Training Accuracy: 89.0625%, Training Loss: 0.3101%\n",
      "Epoch [40/300], Step [4/225], Training Accuracy: 89.8438%, Training Loss: 0.2825%\n",
      "Epoch [40/300], Step [5/225], Training Accuracy: 89.3750%, Training Loss: 0.2879%\n",
      "Epoch [40/300], Step [6/225], Training Accuracy: 88.8021%, Training Loss: 0.2912%\n",
      "Epoch [40/300], Step [7/225], Training Accuracy: 89.2857%, Training Loss: 0.2908%\n",
      "Epoch [40/300], Step [8/225], Training Accuracy: 89.8438%, Training Loss: 0.2804%\n",
      "Epoch [40/300], Step [9/225], Training Accuracy: 90.6250%, Training Loss: 0.2630%\n",
      "Epoch [40/300], Step [10/225], Training Accuracy: 90.3125%, Training Loss: 0.2784%\n",
      "Epoch [40/300], Step [11/225], Training Accuracy: 90.9091%, Training Loss: 0.2692%\n",
      "Epoch [40/300], Step [12/225], Training Accuracy: 90.8854%, Training Loss: 0.2702%\n",
      "Epoch [40/300], Step [13/225], Training Accuracy: 90.6250%, Training Loss: 0.2745%\n",
      "Epoch [40/300], Step [14/225], Training Accuracy: 90.8482%, Training Loss: 0.2714%\n",
      "Epoch [40/300], Step [15/225], Training Accuracy: 90.6250%, Training Loss: 0.2738%\n",
      "Epoch [40/300], Step [16/225], Training Accuracy: 90.3320%, Training Loss: 0.2832%\n",
      "Epoch [40/300], Step [17/225], Training Accuracy: 89.8897%, Training Loss: 0.2892%\n",
      "Epoch [40/300], Step [18/225], Training Accuracy: 89.6701%, Training Loss: 0.2934%\n",
      "Epoch [40/300], Step [19/225], Training Accuracy: 89.7204%, Training Loss: 0.2906%\n",
      "Epoch [40/300], Step [20/225], Training Accuracy: 89.6875%, Training Loss: 0.2888%\n",
      "Epoch [40/300], Step [21/225], Training Accuracy: 89.6577%, Training Loss: 0.2859%\n",
      "Epoch [40/300], Step [22/225], Training Accuracy: 89.7017%, Training Loss: 0.2910%\n",
      "Epoch [40/300], Step [23/225], Training Accuracy: 89.1984%, Training Loss: 0.2980%\n",
      "Epoch [40/300], Step [24/225], Training Accuracy: 89.2578%, Training Loss: 0.2986%\n",
      "Epoch [40/300], Step [25/225], Training Accuracy: 89.4375%, Training Loss: 0.2938%\n",
      "Epoch [40/300], Step [26/225], Training Accuracy: 89.4231%, Training Loss: 0.2960%\n",
      "Epoch [40/300], Step [27/225], Training Accuracy: 89.1782%, Training Loss: 0.2986%\n",
      "Epoch [40/300], Step [28/225], Training Accuracy: 89.3973%, Training Loss: 0.2947%\n",
      "Epoch [40/300], Step [29/225], Training Accuracy: 89.3319%, Training Loss: 0.2964%\n",
      "Epoch [40/300], Step [30/225], Training Accuracy: 89.1667%, Training Loss: 0.2977%\n",
      "Epoch [40/300], Step [31/225], Training Accuracy: 89.1129%, Training Loss: 0.2999%\n",
      "Epoch [40/300], Step [32/225], Training Accuracy: 89.3066%, Training Loss: 0.2955%\n",
      "Epoch [40/300], Step [33/225], Training Accuracy: 89.4886%, Training Loss: 0.2915%\n",
      "Epoch [40/300], Step [34/225], Training Accuracy: 89.3382%, Training Loss: 0.2926%\n",
      "Epoch [40/300], Step [35/225], Training Accuracy: 89.4196%, Training Loss: 0.2932%\n",
      "Epoch [40/300], Step [36/225], Training Accuracy: 89.4965%, Training Loss: 0.2931%\n",
      "Epoch [40/300], Step [37/225], Training Accuracy: 89.4848%, Training Loss: 0.2946%\n",
      "Epoch [40/300], Step [38/225], Training Accuracy: 89.4737%, Training Loss: 0.2963%\n",
      "Epoch [40/300], Step [39/225], Training Accuracy: 89.4631%, Training Loss: 0.2961%\n",
      "Epoch [40/300], Step [40/225], Training Accuracy: 89.4141%, Training Loss: 0.2951%\n",
      "Epoch [40/300], Step [41/225], Training Accuracy: 89.3674%, Training Loss: 0.2966%\n",
      "Epoch [40/300], Step [42/225], Training Accuracy: 89.5089%, Training Loss: 0.2941%\n",
      "Epoch [40/300], Step [43/225], Training Accuracy: 89.4985%, Training Loss: 0.2949%\n",
      "Epoch [40/300], Step [44/225], Training Accuracy: 89.5241%, Training Loss: 0.2939%\n",
      "Epoch [40/300], Step [45/225], Training Accuracy: 89.5486%, Training Loss: 0.2937%\n",
      "Epoch [40/300], Step [46/225], Training Accuracy: 89.5041%, Training Loss: 0.2933%\n",
      "Epoch [40/300], Step [47/225], Training Accuracy: 89.5612%, Training Loss: 0.2933%\n",
      "Epoch [40/300], Step [48/225], Training Accuracy: 89.6484%, Training Loss: 0.2920%\n",
      "Epoch [40/300], Step [49/225], Training Accuracy: 89.6684%, Training Loss: 0.2905%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/300], Step [50/225], Training Accuracy: 89.6562%, Training Loss: 0.2904%\n",
      "Epoch [40/300], Step [51/225], Training Accuracy: 89.6752%, Training Loss: 0.2892%\n",
      "Epoch [40/300], Step [52/225], Training Accuracy: 89.7837%, Training Loss: 0.2866%\n",
      "Epoch [40/300], Step [53/225], Training Accuracy: 89.7995%, Training Loss: 0.2850%\n",
      "Epoch [40/300], Step [54/225], Training Accuracy: 89.6412%, Training Loss: 0.2904%\n",
      "Epoch [40/300], Step [55/225], Training Accuracy: 89.6023%, Training Loss: 0.2915%\n",
      "Epoch [40/300], Step [56/225], Training Accuracy: 89.5926%, Training Loss: 0.2912%\n",
      "Epoch [40/300], Step [57/225], Training Accuracy: 89.4737%, Training Loss: 0.2930%\n",
      "Epoch [40/300], Step [58/225], Training Accuracy: 89.4666%, Training Loss: 0.2935%\n",
      "Epoch [40/300], Step [59/225], Training Accuracy: 89.5127%, Training Loss: 0.2925%\n",
      "Epoch [40/300], Step [60/225], Training Accuracy: 89.4792%, Training Loss: 0.2928%\n",
      "Epoch [40/300], Step [61/225], Training Accuracy: 89.4211%, Training Loss: 0.2944%\n",
      "Epoch [40/300], Step [62/225], Training Accuracy: 89.3649%, Training Loss: 0.2949%\n",
      "Epoch [40/300], Step [63/225], Training Accuracy: 89.3601%, Training Loss: 0.2946%\n",
      "Epoch [40/300], Step [64/225], Training Accuracy: 89.4043%, Training Loss: 0.2941%\n",
      "Epoch [40/300], Step [65/225], Training Accuracy: 89.4712%, Training Loss: 0.2931%\n",
      "Epoch [40/300], Step [66/225], Training Accuracy: 89.5360%, Training Loss: 0.2917%\n",
      "Epoch [40/300], Step [67/225], Training Accuracy: 89.5756%, Training Loss: 0.2907%\n",
      "Epoch [40/300], Step [68/225], Training Accuracy: 89.5680%, Training Loss: 0.2906%\n",
      "Epoch [40/300], Step [69/225], Training Accuracy: 89.5833%, Training Loss: 0.2901%\n",
      "Epoch [40/300], Step [70/225], Training Accuracy: 89.5982%, Training Loss: 0.2890%\n",
      "Epoch [40/300], Step [71/225], Training Accuracy: 89.5467%, Training Loss: 0.2898%\n",
      "Epoch [40/300], Step [72/225], Training Accuracy: 89.5616%, Training Loss: 0.2891%\n",
      "Epoch [40/300], Step [73/225], Training Accuracy: 89.5548%, Training Loss: 0.2902%\n",
      "Epoch [40/300], Step [74/225], Training Accuracy: 89.5270%, Training Loss: 0.2916%\n",
      "Epoch [40/300], Step [75/225], Training Accuracy: 89.5208%, Training Loss: 0.2915%\n",
      "Epoch [40/300], Step [76/225], Training Accuracy: 89.5148%, Training Loss: 0.2911%\n",
      "Epoch [40/300], Step [77/225], Training Accuracy: 89.5495%, Training Loss: 0.2904%\n",
      "Epoch [40/300], Step [78/225], Training Accuracy: 89.6034%, Training Loss: 0.2897%\n",
      "Epoch [40/300], Step [79/225], Training Accuracy: 89.5965%, Training Loss: 0.2895%\n",
      "Epoch [40/300], Step [80/225], Training Accuracy: 89.5117%, Training Loss: 0.2914%\n",
      "Epoch [40/300], Step [81/225], Training Accuracy: 89.6219%, Training Loss: 0.2893%\n",
      "Epoch [40/300], Step [82/225], Training Accuracy: 89.6723%, Training Loss: 0.2885%\n",
      "Epoch [40/300], Step [83/225], Training Accuracy: 89.6273%, Training Loss: 0.2898%\n",
      "Epoch [40/300], Step [84/225], Training Accuracy: 89.5833%, Training Loss: 0.2912%\n",
      "Epoch [40/300], Step [85/225], Training Accuracy: 89.5588%, Training Loss: 0.2906%\n",
      "Epoch [40/300], Step [86/225], Training Accuracy: 89.5167%, Training Loss: 0.2909%\n",
      "Epoch [40/300], Step [87/225], Training Accuracy: 89.4576%, Training Loss: 0.2913%\n",
      "Epoch [40/300], Step [88/225], Training Accuracy: 89.4886%, Training Loss: 0.2914%\n",
      "Epoch [40/300], Step [89/225], Training Accuracy: 89.5716%, Training Loss: 0.2897%\n",
      "Epoch [40/300], Step [90/225], Training Accuracy: 89.5486%, Training Loss: 0.2903%\n",
      "Epoch [40/300], Step [91/225], Training Accuracy: 89.5776%, Training Loss: 0.2896%\n",
      "Epoch [40/300], Step [92/225], Training Accuracy: 89.5550%, Training Loss: 0.2903%\n",
      "Epoch [40/300], Step [93/225], Training Accuracy: 89.5665%, Training Loss: 0.2905%\n",
      "Epoch [40/300], Step [94/225], Training Accuracy: 89.6110%, Training Loss: 0.2894%\n",
      "Epoch [40/300], Step [95/225], Training Accuracy: 89.5724%, Training Loss: 0.2902%\n",
      "Epoch [40/300], Step [96/225], Training Accuracy: 89.6322%, Training Loss: 0.2892%\n",
      "Epoch [40/300], Step [97/225], Training Accuracy: 89.6746%, Training Loss: 0.2884%\n",
      "Epoch [40/300], Step [98/225], Training Accuracy: 89.6524%, Training Loss: 0.2891%\n",
      "Epoch [40/300], Step [99/225], Training Accuracy: 89.5833%, Training Loss: 0.2904%\n",
      "Epoch [40/300], Step [100/225], Training Accuracy: 89.5781%, Training Loss: 0.2901%\n",
      "Epoch [40/300], Step [101/225], Training Accuracy: 89.6349%, Training Loss: 0.2890%\n",
      "Epoch [40/300], Step [102/225], Training Accuracy: 89.6446%, Training Loss: 0.2889%\n",
      "Epoch [40/300], Step [103/225], Training Accuracy: 89.5783%, Training Loss: 0.2898%\n",
      "Epoch [40/300], Step [104/225], Training Accuracy: 89.6334%, Training Loss: 0.2891%\n",
      "Epoch [40/300], Step [105/225], Training Accuracy: 89.6429%, Training Loss: 0.2882%\n",
      "Epoch [40/300], Step [106/225], Training Accuracy: 89.5784%, Training Loss: 0.2895%\n",
      "Epoch [40/300], Step [107/225], Training Accuracy: 89.5882%, Training Loss: 0.2890%\n",
      "Epoch [40/300], Step [108/225], Training Accuracy: 89.5833%, Training Loss: 0.2891%\n",
      "Epoch [40/300], Step [109/225], Training Accuracy: 89.6072%, Training Loss: 0.2890%\n",
      "Epoch [40/300], Step [110/225], Training Accuracy: 89.6165%, Training Loss: 0.2883%\n",
      "Epoch [40/300], Step [111/225], Training Accuracy: 89.6537%, Training Loss: 0.2873%\n",
      "Epoch [40/300], Step [112/225], Training Accuracy: 89.6763%, Training Loss: 0.2867%\n",
      "Epoch [40/300], Step [113/225], Training Accuracy: 89.7124%, Training Loss: 0.2864%\n",
      "Epoch [40/300], Step [114/225], Training Accuracy: 89.6793%, Training Loss: 0.2869%\n",
      "Epoch [40/300], Step [115/225], Training Accuracy: 89.6875%, Training Loss: 0.2865%\n",
      "Epoch [40/300], Step [116/225], Training Accuracy: 89.6686%, Training Loss: 0.2868%\n",
      "Epoch [40/300], Step [117/225], Training Accuracy: 89.7035%, Training Loss: 0.2860%\n",
      "Epoch [40/300], Step [118/225], Training Accuracy: 89.6981%, Training Loss: 0.2862%\n",
      "Epoch [40/300], Step [119/225], Training Accuracy: 89.7059%, Training Loss: 0.2863%\n",
      "Epoch [40/300], Step [120/225], Training Accuracy: 89.7005%, Training Loss: 0.2859%\n",
      "Epoch [40/300], Step [121/225], Training Accuracy: 89.6823%, Training Loss: 0.2859%\n",
      "Epoch [40/300], Step [122/225], Training Accuracy: 89.7285%, Training Loss: 0.2849%\n",
      "Epoch [40/300], Step [123/225], Training Accuracy: 89.7612%, Training Loss: 0.2843%\n",
      "Epoch [40/300], Step [124/225], Training Accuracy: 89.7555%, Training Loss: 0.2837%\n",
      "Epoch [40/300], Step [125/225], Training Accuracy: 89.7375%, Training Loss: 0.2839%\n",
      "Epoch [40/300], Step [126/225], Training Accuracy: 89.7445%, Training Loss: 0.2837%\n",
      "Epoch [40/300], Step [127/225], Training Accuracy: 89.7269%, Training Loss: 0.2840%\n",
      "Epoch [40/300], Step [128/225], Training Accuracy: 89.7461%, Training Loss: 0.2836%\n",
      "Epoch [40/300], Step [129/225], Training Accuracy: 89.8014%, Training Loss: 0.2826%\n",
      "Epoch [40/300], Step [130/225], Training Accuracy: 89.7837%, Training Loss: 0.2826%\n",
      "Epoch [40/300], Step [131/225], Training Accuracy: 89.8139%, Training Loss: 0.2817%\n",
      "Epoch [40/300], Step [132/225], Training Accuracy: 89.7964%, Training Loss: 0.2813%\n",
      "Epoch [40/300], Step [133/225], Training Accuracy: 89.8261%, Training Loss: 0.2807%\n",
      "Epoch [40/300], Step [134/225], Training Accuracy: 89.7854%, Training Loss: 0.2811%\n",
      "Epoch [40/300], Step [135/225], Training Accuracy: 89.8264%, Training Loss: 0.2804%\n",
      "Epoch [40/300], Step [136/225], Training Accuracy: 89.8438%, Training Loss: 0.2804%\n",
      "Epoch [40/300], Step [137/225], Training Accuracy: 89.8495%, Training Loss: 0.2798%\n",
      "Epoch [40/300], Step [138/225], Training Accuracy: 89.8664%, Training Loss: 0.2797%\n",
      "Epoch [40/300], Step [139/225], Training Accuracy: 89.8606%, Training Loss: 0.2796%\n",
      "Epoch [40/300], Step [140/225], Training Accuracy: 89.8326%, Training Loss: 0.2797%\n",
      "Epoch [40/300], Step [141/225], Training Accuracy: 89.8382%, Training Loss: 0.2797%\n",
      "Epoch [40/300], Step [142/225], Training Accuracy: 89.8327%, Training Loss: 0.2797%\n",
      "Epoch [40/300], Step [143/225], Training Accuracy: 89.8820%, Training Loss: 0.2791%\n",
      "Epoch [40/300], Step [144/225], Training Accuracy: 89.8763%, Training Loss: 0.2794%\n",
      "Epoch [40/300], Step [145/225], Training Accuracy: 89.8707%, Training Loss: 0.2799%\n",
      "Epoch [40/300], Step [146/225], Training Accuracy: 89.8652%, Training Loss: 0.2803%\n",
      "Epoch [40/300], Step [147/225], Training Accuracy: 89.8491%, Training Loss: 0.2813%\n",
      "Epoch [40/300], Step [148/225], Training Accuracy: 89.8332%, Training Loss: 0.2812%\n",
      "Epoch [40/300], Step [149/225], Training Accuracy: 89.8070%, Training Loss: 0.2814%\n",
      "Epoch [40/300], Step [150/225], Training Accuracy: 89.8438%, Training Loss: 0.2804%\n",
      "Epoch [40/300], Step [151/225], Training Accuracy: 89.8593%, Training Loss: 0.2801%\n",
      "Epoch [40/300], Step [152/225], Training Accuracy: 89.8643%, Training Loss: 0.2798%\n",
      "Epoch [40/300], Step [153/225], Training Accuracy: 89.8795%, Training Loss: 0.2795%\n",
      "Epoch [40/300], Step [154/225], Training Accuracy: 89.8742%, Training Loss: 0.2800%\n",
      "Epoch [40/300], Step [155/225], Training Accuracy: 89.9093%, Training Loss: 0.2793%\n",
      "Epoch [40/300], Step [156/225], Training Accuracy: 89.8938%, Training Loss: 0.2797%\n",
      "Epoch [40/300], Step [157/225], Training Accuracy: 89.8686%, Training Loss: 0.2802%\n",
      "Epoch [40/300], Step [158/225], Training Accuracy: 89.8932%, Training Loss: 0.2798%\n",
      "Epoch [40/300], Step [159/225], Training Accuracy: 89.8978%, Training Loss: 0.2793%\n",
      "Epoch [40/300], Step [160/225], Training Accuracy: 89.9414%, Training Loss: 0.2787%\n",
      "Epoch [40/300], Step [161/225], Training Accuracy: 89.9651%, Training Loss: 0.2783%\n",
      "Epoch [40/300], Step [162/225], Training Accuracy: 89.9402%, Training Loss: 0.2789%\n",
      "Epoch [40/300], Step [163/225], Training Accuracy: 89.9156%, Training Loss: 0.2796%\n",
      "Epoch [40/300], Step [164/225], Training Accuracy: 89.8533%, Training Loss: 0.2800%\n",
      "Epoch [40/300], Step [165/225], Training Accuracy: 89.8864%, Training Loss: 0.2792%\n",
      "Epoch [40/300], Step [166/225], Training Accuracy: 89.8720%, Training Loss: 0.2796%\n",
      "Epoch [40/300], Step [167/225], Training Accuracy: 89.8484%, Training Loss: 0.2799%\n",
      "Epoch [40/300], Step [168/225], Training Accuracy: 89.8344%, Training Loss: 0.2798%\n",
      "Epoch [40/300], Step [169/225], Training Accuracy: 89.8484%, Training Loss: 0.2801%\n",
      "Epoch [40/300], Step [170/225], Training Accuracy: 89.8438%, Training Loss: 0.2809%\n",
      "Epoch [40/300], Step [171/225], Training Accuracy: 89.8026%, Training Loss: 0.2823%\n",
      "Epoch [40/300], Step [172/225], Training Accuracy: 89.8074%, Training Loss: 0.2824%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/300], Step [173/225], Training Accuracy: 89.7670%, Training Loss: 0.2826%\n",
      "Epoch [40/300], Step [174/225], Training Accuracy: 89.7629%, Training Loss: 0.2825%\n",
      "Epoch [40/300], Step [175/225], Training Accuracy: 89.7500%, Training Loss: 0.2825%\n",
      "Epoch [40/300], Step [176/225], Training Accuracy: 89.7638%, Training Loss: 0.2822%\n",
      "Epoch [40/300], Step [177/225], Training Accuracy: 89.7687%, Training Loss: 0.2819%\n",
      "Epoch [40/300], Step [178/225], Training Accuracy: 89.7472%, Training Loss: 0.2823%\n",
      "Epoch [40/300], Step [179/225], Training Accuracy: 89.7434%, Training Loss: 0.2827%\n",
      "Epoch [40/300], Step [180/225], Training Accuracy: 89.6962%, Training Loss: 0.2835%\n",
      "Epoch [40/300], Step [181/225], Training Accuracy: 89.6927%, Training Loss: 0.2835%\n",
      "Epoch [40/300], Step [182/225], Training Accuracy: 89.6549%, Training Loss: 0.2843%\n",
      "Epoch [40/300], Step [183/225], Training Accuracy: 89.6858%, Training Loss: 0.2835%\n",
      "Epoch [40/300], Step [184/225], Training Accuracy: 89.6739%, Training Loss: 0.2838%\n",
      "Epoch [40/300], Step [185/225], Training Accuracy: 89.6959%, Training Loss: 0.2838%\n",
      "Epoch [40/300], Step [186/225], Training Accuracy: 89.6841%, Training Loss: 0.2843%\n",
      "Epoch [40/300], Step [187/225], Training Accuracy: 89.6641%, Training Loss: 0.2846%\n",
      "Epoch [40/300], Step [188/225], Training Accuracy: 89.7025%, Training Loss: 0.2841%\n",
      "Epoch [40/300], Step [189/225], Training Accuracy: 89.7321%, Training Loss: 0.2835%\n",
      "Epoch [40/300], Step [190/225], Training Accuracy: 89.7368%, Training Loss: 0.2832%\n",
      "Epoch [40/300], Step [191/225], Training Accuracy: 89.7497%, Training Loss: 0.2830%\n",
      "Epoch [40/300], Step [192/225], Training Accuracy: 89.7380%, Training Loss: 0.2835%\n",
      "Epoch [40/300], Step [193/225], Training Accuracy: 89.7102%, Training Loss: 0.2839%\n",
      "Epoch [40/300], Step [194/225], Training Accuracy: 89.7310%, Training Loss: 0.2835%\n",
      "Epoch [40/300], Step [195/225], Training Accuracy: 89.7276%, Training Loss: 0.2835%\n",
      "Epoch [40/300], Step [196/225], Training Accuracy: 89.7481%, Training Loss: 0.2833%\n",
      "Epoch [40/300], Step [197/225], Training Accuracy: 89.7763%, Training Loss: 0.2826%\n",
      "Epoch [40/300], Step [198/225], Training Accuracy: 89.7648%, Training Loss: 0.2826%\n",
      "Epoch [40/300], Step [199/225], Training Accuracy: 89.7613%, Training Loss: 0.2828%\n",
      "Epoch [40/300], Step [200/225], Training Accuracy: 89.7500%, Training Loss: 0.2826%\n",
      "Epoch [40/300], Step [201/225], Training Accuracy: 89.7388%, Training Loss: 0.2826%\n",
      "Epoch [40/300], Step [202/225], Training Accuracy: 89.7355%, Training Loss: 0.2827%\n",
      "Epoch [40/300], Step [203/225], Training Accuracy: 89.7398%, Training Loss: 0.2826%\n",
      "Epoch [40/300], Step [204/225], Training Accuracy: 89.7289%, Training Loss: 0.2829%\n",
      "Epoch [40/300], Step [205/225], Training Accuracy: 89.7332%, Training Loss: 0.2825%\n",
      "Epoch [40/300], Step [206/225], Training Accuracy: 89.7376%, Training Loss: 0.2826%\n",
      "Epoch [40/300], Step [207/225], Training Accuracy: 89.7418%, Training Loss: 0.2825%\n",
      "Epoch [40/300], Step [208/225], Training Accuracy: 89.7386%, Training Loss: 0.2826%\n",
      "Epoch [40/300], Step [209/225], Training Accuracy: 89.7503%, Training Loss: 0.2824%\n",
      "Epoch [40/300], Step [210/225], Training Accuracy: 89.7396%, Training Loss: 0.2823%\n",
      "Epoch [40/300], Step [211/225], Training Accuracy: 89.7068%, Training Loss: 0.2828%\n",
      "Epoch [40/300], Step [212/225], Training Accuracy: 89.6890%, Training Loss: 0.2828%\n",
      "Epoch [40/300], Step [213/225], Training Accuracy: 89.6934%, Training Loss: 0.2827%\n",
      "Epoch [40/300], Step [214/225], Training Accuracy: 89.7050%, Training Loss: 0.2828%\n",
      "Epoch [40/300], Step [215/225], Training Accuracy: 89.7238%, Training Loss: 0.2824%\n",
      "Epoch [40/300], Step [216/225], Training Accuracy: 89.6846%, Training Loss: 0.2830%\n",
      "Epoch [40/300], Step [217/225], Training Accuracy: 89.6745%, Training Loss: 0.2830%\n",
      "Epoch [40/300], Step [218/225], Training Accuracy: 89.6717%, Training Loss: 0.2832%\n",
      "Epoch [40/300], Step [219/225], Training Accuracy: 89.6618%, Training Loss: 0.2829%\n",
      "Epoch [40/300], Step [220/225], Training Accuracy: 89.6804%, Training Loss: 0.2825%\n",
      "Epoch [40/300], Step [221/225], Training Accuracy: 89.6705%, Training Loss: 0.2828%\n",
      "Epoch [40/300], Step [222/225], Training Accuracy: 89.6748%, Training Loss: 0.2828%\n",
      "Epoch [40/300], Step [223/225], Training Accuracy: 89.6721%, Training Loss: 0.2833%\n",
      "Epoch [40/300], Step [224/225], Training Accuracy: 89.6763%, Training Loss: 0.2833%\n",
      "Epoch [40/300], Step [225/225], Training Accuracy: 89.6748%, Training Loss: 0.2835%\n",
      "Epoch [41/300], Step [1/225], Training Accuracy: 87.5000%, Training Loss: 0.3508%\n",
      "Epoch [41/300], Step [2/225], Training Accuracy: 88.2812%, Training Loss: 0.3066%\n",
      "Epoch [41/300], Step [3/225], Training Accuracy: 87.5000%, Training Loss: 0.3254%\n",
      "Epoch [41/300], Step [4/225], Training Accuracy: 87.8906%, Training Loss: 0.3031%\n",
      "Epoch [41/300], Step [5/225], Training Accuracy: 88.1250%, Training Loss: 0.3005%\n",
      "Epoch [41/300], Step [6/225], Training Accuracy: 87.2396%, Training Loss: 0.3190%\n",
      "Epoch [41/300], Step [7/225], Training Accuracy: 86.3839%, Training Loss: 0.3414%\n",
      "Epoch [41/300], Step [8/225], Training Accuracy: 86.7188%, Training Loss: 0.3331%\n",
      "Epoch [41/300], Step [9/225], Training Accuracy: 87.5000%, Training Loss: 0.3257%\n",
      "Epoch [41/300], Step [10/225], Training Accuracy: 87.3438%, Training Loss: 0.3243%\n",
      "Epoch [41/300], Step [11/225], Training Accuracy: 87.3580%, Training Loss: 0.3223%\n",
      "Epoch [41/300], Step [12/225], Training Accuracy: 87.2396%, Training Loss: 0.3244%\n",
      "Epoch [41/300], Step [13/225], Training Accuracy: 87.3798%, Training Loss: 0.3194%\n",
      "Epoch [41/300], Step [14/225], Training Accuracy: 87.6116%, Training Loss: 0.3121%\n",
      "Epoch [41/300], Step [15/225], Training Accuracy: 88.1250%, Training Loss: 0.3027%\n",
      "Epoch [41/300], Step [16/225], Training Accuracy: 88.0859%, Training Loss: 0.3008%\n",
      "Epoch [41/300], Step [17/225], Training Accuracy: 87.8676%, Training Loss: 0.3048%\n",
      "Epoch [41/300], Step [18/225], Training Accuracy: 88.1076%, Training Loss: 0.3061%\n",
      "Epoch [41/300], Step [19/225], Training Accuracy: 88.3224%, Training Loss: 0.3004%\n",
      "Epoch [41/300], Step [20/225], Training Accuracy: 88.3594%, Training Loss: 0.3007%\n",
      "Epoch [41/300], Step [21/225], Training Accuracy: 88.6905%, Training Loss: 0.2975%\n",
      "Epoch [41/300], Step [22/225], Training Accuracy: 88.6364%, Training Loss: 0.2968%\n",
      "Epoch [41/300], Step [23/225], Training Accuracy: 88.7908%, Training Loss: 0.2942%\n",
      "Epoch [41/300], Step [24/225], Training Accuracy: 88.8021%, Training Loss: 0.2952%\n",
      "Epoch [41/300], Step [25/225], Training Accuracy: 88.5625%, Training Loss: 0.2989%\n",
      "Epoch [41/300], Step [26/225], Training Accuracy: 88.4615%, Training Loss: 0.3002%\n",
      "Epoch [41/300], Step [27/225], Training Accuracy: 88.5417%, Training Loss: 0.2993%\n",
      "Epoch [41/300], Step [28/225], Training Accuracy: 88.8393%, Training Loss: 0.2930%\n",
      "Epoch [41/300], Step [29/225], Training Accuracy: 88.8470%, Training Loss: 0.2945%\n",
      "Epoch [41/300], Step [30/225], Training Accuracy: 88.9062%, Training Loss: 0.2932%\n",
      "Epoch [41/300], Step [31/225], Training Accuracy: 89.0625%, Training Loss: 0.2907%\n",
      "Epoch [41/300], Step [32/225], Training Accuracy: 89.0625%, Training Loss: 0.2898%\n",
      "Epoch [41/300], Step [33/225], Training Accuracy: 89.2045%, Training Loss: 0.2874%\n",
      "Epoch [41/300], Step [34/225], Training Accuracy: 89.1544%, Training Loss: 0.2878%\n",
      "Epoch [41/300], Step [35/225], Training Accuracy: 89.1071%, Training Loss: 0.2896%\n",
      "Epoch [41/300], Step [36/225], Training Accuracy: 89.2361%, Training Loss: 0.2868%\n",
      "Epoch [41/300], Step [37/225], Training Accuracy: 89.3581%, Training Loss: 0.2856%\n",
      "Epoch [41/300], Step [38/225], Training Accuracy: 89.3503%, Training Loss: 0.2855%\n",
      "Epoch [41/300], Step [39/225], Training Accuracy: 89.2628%, Training Loss: 0.2847%\n",
      "Epoch [41/300], Step [40/225], Training Accuracy: 89.3359%, Training Loss: 0.2829%\n",
      "Epoch [41/300], Step [41/225], Training Accuracy: 89.2530%, Training Loss: 0.2834%\n",
      "Epoch [41/300], Step [42/225], Training Accuracy: 89.2857%, Training Loss: 0.2827%\n",
      "Epoch [41/300], Step [43/225], Training Accuracy: 89.4259%, Training Loss: 0.2805%\n",
      "Epoch [41/300], Step [44/225], Training Accuracy: 89.4886%, Training Loss: 0.2799%\n",
      "Epoch [41/300], Step [45/225], Training Accuracy: 89.6181%, Training Loss: 0.2773%\n",
      "Epoch [41/300], Step [46/225], Training Accuracy: 89.6399%, Training Loss: 0.2756%\n",
      "Epoch [41/300], Step [47/225], Training Accuracy: 89.6277%, Training Loss: 0.2756%\n",
      "Epoch [41/300], Step [48/225], Training Accuracy: 89.6810%, Training Loss: 0.2753%\n",
      "Epoch [41/300], Step [49/225], Training Accuracy: 89.7003%, Training Loss: 0.2752%\n",
      "Epoch [41/300], Step [50/225], Training Accuracy: 89.6562%, Training Loss: 0.2759%\n",
      "Epoch [41/300], Step [51/225], Training Accuracy: 89.7059%, Training Loss: 0.2739%\n",
      "Epoch [41/300], Step [52/225], Training Accuracy: 89.7536%, Training Loss: 0.2728%\n",
      "Epoch [41/300], Step [53/225], Training Accuracy: 89.7995%, Training Loss: 0.2717%\n",
      "Epoch [41/300], Step [54/225], Training Accuracy: 89.7280%, Training Loss: 0.2729%\n",
      "Epoch [41/300], Step [55/225], Training Accuracy: 89.8011%, Training Loss: 0.2714%\n",
      "Epoch [41/300], Step [56/225], Training Accuracy: 89.8158%, Training Loss: 0.2706%\n",
      "Epoch [41/300], Step [57/225], Training Accuracy: 89.8849%, Training Loss: 0.2698%\n",
      "Epoch [41/300], Step [58/225], Training Accuracy: 89.9246%, Training Loss: 0.2692%\n",
      "Epoch [41/300], Step [59/225], Training Accuracy: 89.8570%, Training Loss: 0.2693%\n",
      "Epoch [41/300], Step [60/225], Training Accuracy: 89.8958%, Training Loss: 0.2689%\n",
      "Epoch [41/300], Step [61/225], Training Accuracy: 89.8822%, Training Loss: 0.2692%\n",
      "Epoch [41/300], Step [62/225], Training Accuracy: 89.8690%, Training Loss: 0.2687%\n",
      "Epoch [41/300], Step [63/225], Training Accuracy: 89.8810%, Training Loss: 0.2685%\n",
      "Epoch [41/300], Step [64/225], Training Accuracy: 89.9414%, Training Loss: 0.2677%\n",
      "Epoch [41/300], Step [65/225], Training Accuracy: 90.0240%, Training Loss: 0.2664%\n",
      "Epoch [41/300], Step [66/225], Training Accuracy: 89.9384%, Training Loss: 0.2683%\n",
      "Epoch [41/300], Step [67/225], Training Accuracy: 89.9254%, Training Loss: 0.2682%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/300], Step [68/225], Training Accuracy: 89.9357%, Training Loss: 0.2687%\n",
      "Epoch [41/300], Step [69/225], Training Accuracy: 89.9683%, Training Loss: 0.2678%\n",
      "Epoch [41/300], Step [70/225], Training Accuracy: 89.9330%, Training Loss: 0.2681%\n",
      "Epoch [41/300], Step [71/225], Training Accuracy: 89.8988%, Training Loss: 0.2692%\n",
      "Epoch [41/300], Step [72/225], Training Accuracy: 89.9957%, Training Loss: 0.2676%\n",
      "Epoch [41/300], Step [73/225], Training Accuracy: 90.0043%, Training Loss: 0.2677%\n",
      "Epoch [41/300], Step [74/225], Training Accuracy: 89.9704%, Training Loss: 0.2699%\n",
      "Epoch [41/300], Step [75/225], Training Accuracy: 89.9792%, Training Loss: 0.2697%\n",
      "Epoch [41/300], Step [76/225], Training Accuracy: 89.9671%, Training Loss: 0.2716%\n",
      "Epoch [41/300], Step [77/225], Training Accuracy: 90.0365%, Training Loss: 0.2709%\n",
      "Epoch [41/300], Step [78/225], Training Accuracy: 90.0841%, Training Loss: 0.2698%\n",
      "Epoch [41/300], Step [79/225], Training Accuracy: 90.0910%, Training Loss: 0.2697%\n",
      "Epoch [41/300], Step [80/225], Training Accuracy: 90.0391%, Training Loss: 0.2704%\n",
      "Epoch [41/300], Step [81/225], Training Accuracy: 90.0463%, Training Loss: 0.2696%\n",
      "Epoch [41/300], Step [82/225], Training Accuracy: 90.0534%, Training Loss: 0.2695%\n",
      "Epoch [41/300], Step [83/225], Training Accuracy: 90.0226%, Training Loss: 0.2707%\n",
      "Epoch [41/300], Step [84/225], Training Accuracy: 89.9368%, Training Loss: 0.2725%\n",
      "Epoch [41/300], Step [85/225], Training Accuracy: 89.9081%, Training Loss: 0.2729%\n",
      "Epoch [41/300], Step [86/225], Training Accuracy: 89.8438%, Training Loss: 0.2731%\n",
      "Epoch [41/300], Step [87/225], Training Accuracy: 89.8348%, Training Loss: 0.2729%\n",
      "Epoch [41/300], Step [88/225], Training Accuracy: 89.8082%, Training Loss: 0.2741%\n",
      "Epoch [41/300], Step [89/225], Training Accuracy: 89.7999%, Training Loss: 0.2740%\n",
      "Epoch [41/300], Step [90/225], Training Accuracy: 89.7917%, Training Loss: 0.2740%\n",
      "Epoch [41/300], Step [91/225], Training Accuracy: 89.7493%, Training Loss: 0.2741%\n",
      "Epoch [41/300], Step [92/225], Training Accuracy: 89.7758%, Training Loss: 0.2730%\n",
      "Epoch [41/300], Step [93/225], Training Accuracy: 89.7681%, Training Loss: 0.2734%\n",
      "Epoch [41/300], Step [94/225], Training Accuracy: 89.7939%, Training Loss: 0.2728%\n",
      "Epoch [41/300], Step [95/225], Training Accuracy: 89.7697%, Training Loss: 0.2739%\n",
      "Epoch [41/300], Step [96/225], Training Accuracy: 89.8275%, Training Loss: 0.2729%\n",
      "Epoch [41/300], Step [97/225], Training Accuracy: 89.8679%, Training Loss: 0.2720%\n",
      "Epoch [41/300], Step [98/225], Training Accuracy: 89.8756%, Training Loss: 0.2715%\n",
      "Epoch [41/300], Step [99/225], Training Accuracy: 89.8674%, Training Loss: 0.2712%\n",
      "Epoch [41/300], Step [100/225], Training Accuracy: 89.8594%, Training Loss: 0.2722%\n",
      "Epoch [41/300], Step [101/225], Training Accuracy: 89.8824%, Training Loss: 0.2714%\n",
      "Epoch [41/300], Step [102/225], Training Accuracy: 89.8284%, Training Loss: 0.2719%\n",
      "Epoch [41/300], Step [103/225], Training Accuracy: 89.7907%, Training Loss: 0.2727%\n",
      "Epoch [41/300], Step [104/225], Training Accuracy: 89.7536%, Training Loss: 0.2738%\n",
      "Epoch [41/300], Step [105/225], Training Accuracy: 89.7619%, Training Loss: 0.2741%\n",
      "Epoch [41/300], Step [106/225], Training Accuracy: 89.7700%, Training Loss: 0.2742%\n",
      "Epoch [41/300], Step [107/225], Training Accuracy: 89.7926%, Training Loss: 0.2741%\n",
      "Epoch [41/300], Step [108/225], Training Accuracy: 89.8293%, Training Loss: 0.2732%\n",
      "Epoch [41/300], Step [109/225], Training Accuracy: 89.8509%, Training Loss: 0.2726%\n",
      "Epoch [41/300], Step [110/225], Training Accuracy: 89.8580%, Training Loss: 0.2722%\n",
      "Epoch [41/300], Step [111/225], Training Accuracy: 89.8367%, Training Loss: 0.2720%\n",
      "Epoch [41/300], Step [112/225], Training Accuracy: 89.8717%, Training Loss: 0.2710%\n",
      "Epoch [41/300], Step [113/225], Training Accuracy: 89.8645%, Training Loss: 0.2712%\n",
      "Epoch [41/300], Step [114/225], Training Accuracy: 89.8849%, Training Loss: 0.2705%\n",
      "Epoch [41/300], Step [115/225], Training Accuracy: 89.9185%, Training Loss: 0.2703%\n",
      "Epoch [41/300], Step [116/225], Training Accuracy: 89.8976%, Training Loss: 0.2711%\n",
      "Epoch [41/300], Step [117/225], Training Accuracy: 89.9439%, Training Loss: 0.2699%\n",
      "Epoch [41/300], Step [118/225], Training Accuracy: 89.9497%, Training Loss: 0.2696%\n",
      "Epoch [41/300], Step [119/225], Training Accuracy: 89.9816%, Training Loss: 0.2689%\n",
      "Epoch [41/300], Step [120/225], Training Accuracy: 90.0521%, Training Loss: 0.2676%\n",
      "Epoch [41/300], Step [121/225], Training Accuracy: 90.0826%, Training Loss: 0.2674%\n",
      "Epoch [41/300], Step [122/225], Training Accuracy: 90.0743%, Training Loss: 0.2675%\n",
      "Epoch [41/300], Step [123/225], Training Accuracy: 90.0788%, Training Loss: 0.2677%\n",
      "Epoch [41/300], Step [124/225], Training Accuracy: 90.0832%, Training Loss: 0.2678%\n",
      "Epoch [41/300], Step [125/225], Training Accuracy: 90.1000%, Training Loss: 0.2675%\n",
      "Epoch [41/300], Step [126/225], Training Accuracy: 90.1538%, Training Loss: 0.2666%\n",
      "Epoch [41/300], Step [127/225], Training Accuracy: 90.1698%, Training Loss: 0.2667%\n",
      "Epoch [41/300], Step [128/225], Training Accuracy: 90.1489%, Training Loss: 0.2670%\n",
      "Epoch [41/300], Step [129/225], Training Accuracy: 90.1890%, Training Loss: 0.2662%\n",
      "Epoch [41/300], Step [130/225], Training Accuracy: 90.1442%, Training Loss: 0.2672%\n",
      "Epoch [41/300], Step [131/225], Training Accuracy: 90.1718%, Training Loss: 0.2667%\n",
      "Epoch [41/300], Step [132/225], Training Accuracy: 90.1752%, Training Loss: 0.2666%\n",
      "Epoch [41/300], Step [133/225], Training Accuracy: 90.1786%, Training Loss: 0.2665%\n",
      "Epoch [41/300], Step [134/225], Training Accuracy: 90.1936%, Training Loss: 0.2663%\n",
      "Epoch [41/300], Step [135/225], Training Accuracy: 90.1852%, Training Loss: 0.2660%\n",
      "Epoch [41/300], Step [136/225], Training Accuracy: 90.2114%, Training Loss: 0.2657%\n",
      "Epoch [41/300], Step [137/225], Training Accuracy: 90.1802%, Training Loss: 0.2663%\n",
      "Epoch [41/300], Step [138/225], Training Accuracy: 90.1155%, Training Loss: 0.2666%\n",
      "Epoch [41/300], Step [139/225], Training Accuracy: 90.1192%, Training Loss: 0.2662%\n",
      "Epoch [41/300], Step [140/225], Training Accuracy: 90.1451%, Training Loss: 0.2659%\n",
      "Epoch [41/300], Step [141/225], Training Accuracy: 90.1152%, Training Loss: 0.2662%\n",
      "Epoch [41/300], Step [142/225], Training Accuracy: 90.0968%, Training Loss: 0.2665%\n",
      "Epoch [41/300], Step [143/225], Training Accuracy: 90.0677%, Training Loss: 0.2671%\n",
      "Epoch [41/300], Step [144/225], Training Accuracy: 90.0825%, Training Loss: 0.2669%\n",
      "Epoch [41/300], Step [145/225], Training Accuracy: 90.0431%, Training Loss: 0.2667%\n",
      "Epoch [41/300], Step [146/225], Training Accuracy: 90.0685%, Training Loss: 0.2663%\n",
      "Epoch [41/300], Step [147/225], Training Accuracy: 90.0616%, Training Loss: 0.2665%\n",
      "Epoch [41/300], Step [148/225], Training Accuracy: 90.0655%, Training Loss: 0.2665%\n",
      "Epoch [41/300], Step [149/225], Training Accuracy: 90.0378%, Training Loss: 0.2671%\n",
      "Epoch [41/300], Step [150/225], Training Accuracy: 90.0833%, Training Loss: 0.2662%\n",
      "Epoch [41/300], Step [151/225], Training Accuracy: 90.1180%, Training Loss: 0.2659%\n",
      "Epoch [41/300], Step [152/225], Training Accuracy: 90.1007%, Training Loss: 0.2664%\n",
      "Epoch [41/300], Step [153/225], Training Accuracy: 90.1450%, Training Loss: 0.2657%\n",
      "Epoch [41/300], Step [154/225], Training Accuracy: 90.1075%, Training Loss: 0.2655%\n",
      "Epoch [41/300], Step [155/225], Training Accuracy: 90.1008%, Training Loss: 0.2656%\n",
      "Epoch [41/300], Step [156/225], Training Accuracy: 90.0841%, Training Loss: 0.2657%\n",
      "Epoch [41/300], Step [157/225], Training Accuracy: 90.0975%, Training Loss: 0.2657%\n",
      "Epoch [41/300], Step [158/225], Training Accuracy: 90.1305%, Training Loss: 0.2651%\n",
      "Epoch [41/300], Step [159/225], Training Accuracy: 90.1238%, Training Loss: 0.2651%\n",
      "Epoch [41/300], Step [160/225], Training Accuracy: 90.1465%, Training Loss: 0.2645%\n",
      "Epoch [41/300], Step [161/225], Training Accuracy: 90.1786%, Training Loss: 0.2639%\n",
      "Epoch [41/300], Step [162/225], Training Accuracy: 90.2006%, Training Loss: 0.2638%\n",
      "Epoch [41/300], Step [163/225], Training Accuracy: 90.1936%, Training Loss: 0.2636%\n",
      "Epoch [41/300], Step [164/225], Training Accuracy: 90.2058%, Training Loss: 0.2637%\n",
      "Epoch [41/300], Step [165/225], Training Accuracy: 90.2273%, Training Loss: 0.2633%\n",
      "Epoch [41/300], Step [166/225], Training Accuracy: 90.2579%, Training Loss: 0.2628%\n",
      "Epoch [41/300], Step [167/225], Training Accuracy: 90.2320%, Training Loss: 0.2626%\n",
      "Epoch [41/300], Step [168/225], Training Accuracy: 90.2437%, Training Loss: 0.2622%\n",
      "Epoch [41/300], Step [169/225], Training Accuracy: 90.2089%, Training Loss: 0.2626%\n",
      "Epoch [41/300], Step [170/225], Training Accuracy: 90.1930%, Training Loss: 0.2633%\n",
      "Epoch [41/300], Step [171/225], Training Accuracy: 90.1773%, Training Loss: 0.2639%\n",
      "Epoch [41/300], Step [172/225], Training Accuracy: 90.1617%, Training Loss: 0.2638%\n",
      "Epoch [41/300], Step [173/225], Training Accuracy: 90.1553%, Training Loss: 0.2640%\n",
      "Epoch [41/300], Step [174/225], Training Accuracy: 90.1760%, Training Loss: 0.2635%\n",
      "Epoch [41/300], Step [175/225], Training Accuracy: 90.1964%, Training Loss: 0.2631%\n",
      "Epoch [41/300], Step [176/225], Training Accuracy: 90.1989%, Training Loss: 0.2631%\n",
      "Epoch [41/300], Step [177/225], Training Accuracy: 90.2189%, Training Loss: 0.2628%\n",
      "Epoch [41/300], Step [178/225], Training Accuracy: 90.1773%, Training Loss: 0.2636%\n",
      "Epoch [41/300], Step [179/225], Training Accuracy: 90.1885%, Training Loss: 0.2635%\n",
      "Epoch [41/300], Step [180/225], Training Accuracy: 90.1910%, Training Loss: 0.2632%\n",
      "Epoch [41/300], Step [181/225], Training Accuracy: 90.1847%, Training Loss: 0.2632%\n",
      "Epoch [41/300], Step [182/225], Training Accuracy: 90.2043%, Training Loss: 0.2626%\n",
      "Epoch [41/300], Step [183/225], Training Accuracy: 90.2237%, Training Loss: 0.2621%\n",
      "Epoch [41/300], Step [184/225], Training Accuracy: 90.1664%, Training Loss: 0.2624%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/300], Step [185/225], Training Accuracy: 90.1943%, Training Loss: 0.2621%\n",
      "Epoch [41/300], Step [186/225], Training Accuracy: 90.1798%, Training Loss: 0.2624%\n",
      "Epoch [41/300], Step [187/225], Training Accuracy: 90.1654%, Training Loss: 0.2623%\n",
      "Epoch [41/300], Step [188/225], Training Accuracy: 90.1928%, Training Loss: 0.2615%\n",
      "Epoch [41/300], Step [189/225], Training Accuracy: 90.1786%, Training Loss: 0.2613%\n",
      "Epoch [41/300], Step [190/225], Training Accuracy: 90.1480%, Training Loss: 0.2623%\n",
      "Epoch [41/300], Step [191/225], Training Accuracy: 90.1751%, Training Loss: 0.2616%\n",
      "Epoch [41/300], Step [192/225], Training Accuracy: 90.1530%, Training Loss: 0.2619%\n",
      "Epoch [41/300], Step [193/225], Training Accuracy: 90.1554%, Training Loss: 0.2619%\n",
      "Epoch [41/300], Step [194/225], Training Accuracy: 90.1740%, Training Loss: 0.2615%\n",
      "Epoch [41/300], Step [195/225], Training Accuracy: 90.1683%, Training Loss: 0.2619%\n",
      "Epoch [41/300], Step [196/225], Training Accuracy: 90.1786%, Training Loss: 0.2614%\n",
      "Epoch [41/300], Step [197/225], Training Accuracy: 90.1491%, Training Loss: 0.2622%\n",
      "Epoch [41/300], Step [198/225], Training Accuracy: 90.1594%, Training Loss: 0.2621%\n",
      "Epoch [41/300], Step [199/225], Training Accuracy: 90.1932%, Training Loss: 0.2615%\n",
      "Epoch [41/300], Step [200/225], Training Accuracy: 90.2031%, Training Loss: 0.2612%\n",
      "Epoch [41/300], Step [201/225], Training Accuracy: 90.2130%, Training Loss: 0.2612%\n",
      "Epoch [41/300], Step [202/225], Training Accuracy: 90.2305%, Training Loss: 0.2610%\n",
      "Epoch [41/300], Step [203/225], Training Accuracy: 90.2555%, Training Loss: 0.2603%\n",
      "Epoch [41/300], Step [204/225], Training Accuracy: 90.2191%, Training Loss: 0.2607%\n",
      "Epoch [41/300], Step [205/225], Training Accuracy: 90.2210%, Training Loss: 0.2603%\n",
      "Epoch [41/300], Step [206/225], Training Accuracy: 90.2078%, Training Loss: 0.2605%\n",
      "Epoch [41/300], Step [207/225], Training Accuracy: 90.1947%, Training Loss: 0.2603%\n",
      "Epoch [41/300], Step [208/225], Training Accuracy: 90.1818%, Training Loss: 0.2602%\n",
      "Epoch [41/300], Step [209/225], Training Accuracy: 90.1839%, Training Loss: 0.2606%\n",
      "Epoch [41/300], Step [210/225], Training Accuracy: 90.1935%, Training Loss: 0.2603%\n",
      "Epoch [41/300], Step [211/225], Training Accuracy: 90.1659%, Training Loss: 0.2605%\n",
      "Epoch [41/300], Step [212/225], Training Accuracy: 90.1828%, Training Loss: 0.2607%\n",
      "Epoch [41/300], Step [213/225], Training Accuracy: 90.1849%, Training Loss: 0.2607%\n",
      "Epoch [41/300], Step [214/225], Training Accuracy: 90.1723%, Training Loss: 0.2608%\n",
      "Epoch [41/300], Step [215/225], Training Accuracy: 90.1744%, Training Loss: 0.2608%\n",
      "Epoch [41/300], Step [216/225], Training Accuracy: 90.1620%, Training Loss: 0.2610%\n",
      "Epoch [41/300], Step [217/225], Training Accuracy: 90.1786%, Training Loss: 0.2608%\n",
      "Epoch [41/300], Step [218/225], Training Accuracy: 90.2093%, Training Loss: 0.2604%\n",
      "Epoch [41/300], Step [219/225], Training Accuracy: 90.2112%, Training Loss: 0.2603%\n",
      "Epoch [41/300], Step [220/225], Training Accuracy: 90.2060%, Training Loss: 0.2605%\n",
      "Epoch [41/300], Step [221/225], Training Accuracy: 90.1725%, Training Loss: 0.2615%\n",
      "Epoch [41/300], Step [222/225], Training Accuracy: 90.1464%, Training Loss: 0.2621%\n",
      "Epoch [41/300], Step [223/225], Training Accuracy: 90.1555%, Training Loss: 0.2622%\n",
      "Epoch [41/300], Step [224/225], Training Accuracy: 90.1716%, Training Loss: 0.2619%\n",
      "Epoch [41/300], Step [225/225], Training Accuracy: 90.1681%, Training Loss: 0.2620%\n",
      "Epoch [42/300], Step [1/225], Training Accuracy: 92.1875%, Training Loss: 0.2171%\n",
      "Epoch [42/300], Step [2/225], Training Accuracy: 91.4062%, Training Loss: 0.2359%\n",
      "Epoch [42/300], Step [3/225], Training Accuracy: 87.5000%, Training Loss: 0.2985%\n",
      "Epoch [42/300], Step [4/225], Training Accuracy: 87.8906%, Training Loss: 0.2979%\n",
      "Epoch [42/300], Step [5/225], Training Accuracy: 88.7500%, Training Loss: 0.2765%\n",
      "Epoch [42/300], Step [6/225], Training Accuracy: 88.8021%, Training Loss: 0.2748%\n",
      "Epoch [42/300], Step [7/225], Training Accuracy: 88.6161%, Training Loss: 0.2850%\n",
      "Epoch [42/300], Step [8/225], Training Accuracy: 89.2578%, Training Loss: 0.2765%\n",
      "Epoch [42/300], Step [9/225], Training Accuracy: 89.5833%, Training Loss: 0.2656%\n",
      "Epoch [42/300], Step [10/225], Training Accuracy: 89.2188%, Training Loss: 0.2727%\n",
      "Epoch [42/300], Step [11/225], Training Accuracy: 89.2045%, Training Loss: 0.2723%\n",
      "Epoch [42/300], Step [12/225], Training Accuracy: 89.7135%, Training Loss: 0.2618%\n",
      "Epoch [42/300], Step [13/225], Training Accuracy: 89.9038%, Training Loss: 0.2706%\n",
      "Epoch [42/300], Step [14/225], Training Accuracy: 89.7321%, Training Loss: 0.2720%\n",
      "Epoch [42/300], Step [15/225], Training Accuracy: 89.8958%, Training Loss: 0.2652%\n",
      "Epoch [42/300], Step [16/225], Training Accuracy: 89.9414%, Training Loss: 0.2627%\n",
      "Epoch [42/300], Step [17/225], Training Accuracy: 89.7059%, Training Loss: 0.2681%\n",
      "Epoch [42/300], Step [18/225], Training Accuracy: 89.5833%, Training Loss: 0.2733%\n",
      "Epoch [42/300], Step [19/225], Training Accuracy: 89.6382%, Training Loss: 0.2724%\n",
      "Epoch [42/300], Step [20/225], Training Accuracy: 89.8438%, Training Loss: 0.2709%\n",
      "Epoch [42/300], Step [21/225], Training Accuracy: 89.8065%, Training Loss: 0.2673%\n",
      "Epoch [42/300], Step [22/225], Training Accuracy: 89.8438%, Training Loss: 0.2655%\n",
      "Epoch [42/300], Step [23/225], Training Accuracy: 89.4701%, Training Loss: 0.2699%\n",
      "Epoch [42/300], Step [24/225], Training Accuracy: 89.3880%, Training Loss: 0.2702%\n",
      "Epoch [42/300], Step [25/225], Training Accuracy: 89.4375%, Training Loss: 0.2680%\n",
      "Epoch [42/300], Step [26/225], Training Accuracy: 89.4832%, Training Loss: 0.2676%\n",
      "Epoch [42/300], Step [27/225], Training Accuracy: 89.4676%, Training Loss: 0.2682%\n",
      "Epoch [42/300], Step [28/225], Training Accuracy: 89.5647%, Training Loss: 0.2665%\n",
      "Epoch [42/300], Step [29/225], Training Accuracy: 89.5474%, Training Loss: 0.2666%\n",
      "Epoch [42/300], Step [30/225], Training Accuracy: 89.5312%, Training Loss: 0.2684%\n",
      "Epoch [42/300], Step [31/225], Training Accuracy: 89.4153%, Training Loss: 0.2696%\n",
      "Epoch [42/300], Step [32/225], Training Accuracy: 89.4043%, Training Loss: 0.2690%\n",
      "Epoch [42/300], Step [33/225], Training Accuracy: 89.4413%, Training Loss: 0.2681%\n",
      "Epoch [42/300], Step [34/225], Training Accuracy: 89.4761%, Training Loss: 0.2669%\n",
      "Epoch [42/300], Step [35/225], Training Accuracy: 89.5536%, Training Loss: 0.2670%\n",
      "Epoch [42/300], Step [36/225], Training Accuracy: 89.6267%, Training Loss: 0.2659%\n",
      "Epoch [42/300], Step [37/225], Training Accuracy: 89.5693%, Training Loss: 0.2668%\n",
      "Epoch [42/300], Step [38/225], Training Accuracy: 89.6382%, Training Loss: 0.2666%\n",
      "Epoch [42/300], Step [39/225], Training Accuracy: 89.6234%, Training Loss: 0.2661%\n",
      "Epoch [42/300], Step [40/225], Training Accuracy: 89.5312%, Training Loss: 0.2683%\n",
      "Epoch [42/300], Step [41/225], Training Accuracy: 89.5579%, Training Loss: 0.2710%\n",
      "Epoch [42/300], Step [42/225], Training Accuracy: 89.5833%, Training Loss: 0.2718%\n",
      "Epoch [42/300], Step [43/225], Training Accuracy: 89.6076%, Training Loss: 0.2714%\n",
      "Epoch [42/300], Step [44/225], Training Accuracy: 89.6307%, Training Loss: 0.2721%\n",
      "Epoch [42/300], Step [45/225], Training Accuracy: 89.6528%, Training Loss: 0.2718%\n",
      "Epoch [42/300], Step [46/225], Training Accuracy: 89.7079%, Training Loss: 0.2705%\n",
      "Epoch [42/300], Step [47/225], Training Accuracy: 89.7606%, Training Loss: 0.2694%\n",
      "Epoch [42/300], Step [48/225], Training Accuracy: 89.6810%, Training Loss: 0.2704%\n",
      "Epoch [42/300], Step [49/225], Training Accuracy: 89.7003%, Training Loss: 0.2687%\n",
      "Epoch [42/300], Step [50/225], Training Accuracy: 89.6250%, Training Loss: 0.2692%\n",
      "Epoch [42/300], Step [51/225], Training Accuracy: 89.6752%, Training Loss: 0.2679%\n",
      "Epoch [42/300], Step [52/225], Training Accuracy: 89.6334%, Training Loss: 0.2672%\n",
      "Epoch [42/300], Step [53/225], Training Accuracy: 89.5342%, Training Loss: 0.2682%\n",
      "Epoch [42/300], Step [54/225], Training Accuracy: 89.5544%, Training Loss: 0.2677%\n",
      "Epoch [42/300], Step [55/225], Training Accuracy: 89.6023%, Training Loss: 0.2659%\n",
      "Epoch [42/300], Step [56/225], Training Accuracy: 89.5926%, Training Loss: 0.2662%\n",
      "Epoch [42/300], Step [57/225], Training Accuracy: 89.6382%, Training Loss: 0.2652%\n",
      "Epoch [42/300], Step [58/225], Training Accuracy: 89.7091%, Training Loss: 0.2637%\n",
      "Epoch [42/300], Step [59/225], Training Accuracy: 89.6981%, Training Loss: 0.2644%\n",
      "Epoch [42/300], Step [60/225], Training Accuracy: 89.8438%, Training Loss: 0.2620%\n",
      "Epoch [42/300], Step [61/225], Training Accuracy: 89.6773%, Training Loss: 0.2631%\n",
      "Epoch [42/300], Step [62/225], Training Accuracy: 89.6925%, Training Loss: 0.2633%\n",
      "Epoch [42/300], Step [63/225], Training Accuracy: 89.7817%, Training Loss: 0.2620%\n",
      "Epoch [42/300], Step [64/225], Training Accuracy: 89.7705%, Training Loss: 0.2615%\n",
      "Epoch [42/300], Step [65/225], Training Accuracy: 89.8558%, Training Loss: 0.2604%\n",
      "Epoch [42/300], Step [66/225], Training Accuracy: 89.8438%, Training Loss: 0.2604%\n",
      "Epoch [42/300], Step [67/225], Training Accuracy: 89.8321%, Training Loss: 0.2619%\n",
      "Epoch [42/300], Step [68/225], Training Accuracy: 89.8897%, Training Loss: 0.2617%\n",
      "Epoch [42/300], Step [69/225], Training Accuracy: 89.8777%, Training Loss: 0.2612%\n",
      "Epoch [42/300], Step [70/225], Training Accuracy: 89.8438%, Training Loss: 0.2615%\n",
      "Epoch [42/300], Step [71/225], Training Accuracy: 89.8768%, Training Loss: 0.2618%\n",
      "Epoch [42/300], Step [72/225], Training Accuracy: 89.9306%, Training Loss: 0.2611%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/300], Step [73/225], Training Accuracy: 89.9401%, Training Loss: 0.2612%\n",
      "Epoch [42/300], Step [74/225], Training Accuracy: 89.8649%, Training Loss: 0.2624%\n",
      "Epoch [42/300], Step [75/225], Training Accuracy: 89.8750%, Training Loss: 0.2620%\n",
      "Epoch [42/300], Step [76/225], Training Accuracy: 89.8849%, Training Loss: 0.2625%\n",
      "Epoch [42/300], Step [77/225], Training Accuracy: 89.9148%, Training Loss: 0.2624%\n",
      "Epoch [42/300], Step [78/225], Training Accuracy: 89.9239%, Training Loss: 0.2622%\n",
      "Epoch [42/300], Step [79/225], Training Accuracy: 89.9130%, Training Loss: 0.2625%\n",
      "Epoch [42/300], Step [80/225], Training Accuracy: 89.8047%, Training Loss: 0.2646%\n",
      "Epoch [42/300], Step [81/225], Training Accuracy: 89.8148%, Training Loss: 0.2642%\n",
      "Epoch [42/300], Step [82/225], Training Accuracy: 89.8247%, Training Loss: 0.2640%\n",
      "Epoch [42/300], Step [83/225], Training Accuracy: 89.7590%, Training Loss: 0.2654%\n",
      "Epoch [42/300], Step [84/225], Training Accuracy: 89.7693%, Training Loss: 0.2645%\n",
      "Epoch [42/300], Step [85/225], Training Accuracy: 89.7610%, Training Loss: 0.2646%\n",
      "Epoch [42/300], Step [86/225], Training Accuracy: 89.6621%, Training Loss: 0.2670%\n",
      "Epoch [42/300], Step [87/225], Training Accuracy: 89.6372%, Training Loss: 0.2673%\n",
      "Epoch [42/300], Step [88/225], Training Accuracy: 89.6129%, Training Loss: 0.2696%\n",
      "Epoch [42/300], Step [89/225], Training Accuracy: 89.6770%, Training Loss: 0.2684%\n",
      "Epoch [42/300], Step [90/225], Training Accuracy: 89.6701%, Training Loss: 0.2681%\n",
      "Epoch [42/300], Step [91/225], Training Accuracy: 89.6635%, Training Loss: 0.2677%\n",
      "Epoch [42/300], Step [92/225], Training Accuracy: 89.6909%, Training Loss: 0.2672%\n",
      "Epoch [42/300], Step [93/225], Training Accuracy: 89.7009%, Training Loss: 0.2676%\n",
      "Epoch [42/300], Step [94/225], Training Accuracy: 89.6941%, Training Loss: 0.2687%\n",
      "Epoch [42/300], Step [95/225], Training Accuracy: 89.7039%, Training Loss: 0.2689%\n",
      "Epoch [42/300], Step [96/225], Training Accuracy: 89.7298%, Training Loss: 0.2680%\n",
      "Epoch [42/300], Step [97/225], Training Accuracy: 89.7874%, Training Loss: 0.2671%\n",
      "Epoch [42/300], Step [98/225], Training Accuracy: 89.7321%, Training Loss: 0.2671%\n",
      "Epoch [42/300], Step [99/225], Training Accuracy: 89.7254%, Training Loss: 0.2671%\n",
      "Epoch [42/300], Step [100/225], Training Accuracy: 89.6562%, Training Loss: 0.2684%\n",
      "Epoch [42/300], Step [101/225], Training Accuracy: 89.6658%, Training Loss: 0.2682%\n",
      "Epoch [42/300], Step [102/225], Training Accuracy: 89.6599%, Training Loss: 0.2684%\n",
      "Epoch [42/300], Step [103/225], Training Accuracy: 89.6996%, Training Loss: 0.2677%\n",
      "Epoch [42/300], Step [104/225], Training Accuracy: 89.6635%, Training Loss: 0.2678%\n",
      "Epoch [42/300], Step [105/225], Training Accuracy: 89.6429%, Training Loss: 0.2683%\n",
      "Epoch [42/300], Step [106/225], Training Accuracy: 89.7258%, Training Loss: 0.2670%\n",
      "Epoch [42/300], Step [107/225], Training Accuracy: 89.7780%, Training Loss: 0.2668%\n",
      "Epoch [42/300], Step [108/225], Training Accuracy: 89.7714%, Training Loss: 0.2670%\n",
      "Epoch [42/300], Step [109/225], Training Accuracy: 89.8222%, Training Loss: 0.2661%\n",
      "Epoch [42/300], Step [110/225], Training Accuracy: 89.8722%, Training Loss: 0.2656%\n",
      "Epoch [42/300], Step [111/225], Training Accuracy: 89.9071%, Training Loss: 0.2656%\n",
      "Epoch [42/300], Step [112/225], Training Accuracy: 89.8996%, Training Loss: 0.2657%\n",
      "Epoch [42/300], Step [113/225], Training Accuracy: 89.9198%, Training Loss: 0.2660%\n",
      "Epoch [42/300], Step [114/225], Training Accuracy: 89.9123%, Training Loss: 0.2660%\n",
      "Epoch [42/300], Step [115/225], Training Accuracy: 89.9321%, Training Loss: 0.2654%\n",
      "Epoch [42/300], Step [116/225], Training Accuracy: 89.9111%, Training Loss: 0.2660%\n",
      "Epoch [42/300], Step [117/225], Training Accuracy: 89.8905%, Training Loss: 0.2660%\n",
      "Epoch [42/300], Step [118/225], Training Accuracy: 89.9232%, Training Loss: 0.2655%\n",
      "Epoch [42/300], Step [119/225], Training Accuracy: 89.9160%, Training Loss: 0.2655%\n",
      "Epoch [42/300], Step [120/225], Training Accuracy: 89.9219%, Training Loss: 0.2653%\n",
      "Epoch [42/300], Step [121/225], Training Accuracy: 89.8631%, Training Loss: 0.2666%\n",
      "Epoch [42/300], Step [122/225], Training Accuracy: 89.8822%, Training Loss: 0.2664%\n",
      "Epoch [42/300], Step [123/225], Training Accuracy: 89.9263%, Training Loss: 0.2659%\n",
      "Epoch [42/300], Step [124/225], Training Accuracy: 89.9194%, Training Loss: 0.2661%\n",
      "Epoch [42/300], Step [125/225], Training Accuracy: 89.8875%, Training Loss: 0.2667%\n",
      "Epoch [42/300], Step [126/225], Training Accuracy: 89.8438%, Training Loss: 0.2672%\n",
      "Epoch [42/300], Step [127/225], Training Accuracy: 89.8622%, Training Loss: 0.2670%\n",
      "Epoch [42/300], Step [128/225], Training Accuracy: 89.8560%, Training Loss: 0.2673%\n",
      "Epoch [42/300], Step [129/225], Training Accuracy: 89.8498%, Training Loss: 0.2675%\n",
      "Epoch [42/300], Step [130/225], Training Accuracy: 89.8197%, Training Loss: 0.2679%\n",
      "Epoch [42/300], Step [131/225], Training Accuracy: 89.8139%, Training Loss: 0.2679%\n",
      "Epoch [42/300], Step [132/225], Training Accuracy: 89.8556%, Training Loss: 0.2671%\n",
      "Epoch [42/300], Step [133/225], Training Accuracy: 89.8966%, Training Loss: 0.2665%\n",
      "Epoch [42/300], Step [134/225], Training Accuracy: 89.9137%, Training Loss: 0.2662%\n",
      "Epoch [42/300], Step [135/225], Training Accuracy: 89.9537%, Training Loss: 0.2654%\n",
      "Epoch [42/300], Step [136/225], Training Accuracy: 89.9472%, Training Loss: 0.2656%\n",
      "Epoch [42/300], Step [137/225], Training Accuracy: 89.9293%, Training Loss: 0.2657%\n",
      "Epoch [42/300], Step [138/225], Training Accuracy: 89.9117%, Training Loss: 0.2659%\n",
      "Epoch [42/300], Step [139/225], Training Accuracy: 89.8831%, Training Loss: 0.2662%\n",
      "Epoch [42/300], Step [140/225], Training Accuracy: 89.8996%, Training Loss: 0.2658%\n",
      "Epoch [42/300], Step [141/225], Training Accuracy: 89.9269%, Training Loss: 0.2657%\n",
      "Epoch [42/300], Step [142/225], Training Accuracy: 89.9098%, Training Loss: 0.2658%\n",
      "Epoch [42/300], Step [143/225], Training Accuracy: 89.8601%, Training Loss: 0.2661%\n",
      "Epoch [42/300], Step [144/225], Training Accuracy: 89.8329%, Training Loss: 0.2665%\n",
      "Epoch [42/300], Step [145/225], Training Accuracy: 89.8491%, Training Loss: 0.2664%\n",
      "Epoch [42/300], Step [146/225], Training Accuracy: 89.8866%, Training Loss: 0.2659%\n",
      "Epoch [42/300], Step [147/225], Training Accuracy: 89.8597%, Training Loss: 0.2666%\n",
      "Epoch [42/300], Step [148/225], Training Accuracy: 89.8543%, Training Loss: 0.2664%\n",
      "Epoch [42/300], Step [149/225], Training Accuracy: 89.8595%, Training Loss: 0.2662%\n",
      "Epoch [42/300], Step [150/225], Training Accuracy: 89.8542%, Training Loss: 0.2664%\n",
      "Epoch [42/300], Step [151/225], Training Accuracy: 89.8593%, Training Loss: 0.2667%\n",
      "Epoch [42/300], Step [152/225], Training Accuracy: 89.9054%, Training Loss: 0.2660%\n",
      "Epoch [42/300], Step [153/225], Training Accuracy: 89.9203%, Training Loss: 0.2658%\n",
      "Epoch [42/300], Step [154/225], Training Accuracy: 89.9554%, Training Loss: 0.2652%\n",
      "Epoch [42/300], Step [155/225], Training Accuracy: 89.9597%, Training Loss: 0.2652%\n",
      "Epoch [42/300], Step [156/225], Training Accuracy: 89.9539%, Training Loss: 0.2648%\n",
      "Epoch [42/300], Step [157/225], Training Accuracy: 89.9682%, Training Loss: 0.2645%\n",
      "Epoch [42/300], Step [158/225], Training Accuracy: 89.9921%, Training Loss: 0.2645%\n",
      "Epoch [42/300], Step [159/225], Training Accuracy: 89.9862%, Training Loss: 0.2648%\n",
      "Epoch [42/300], Step [160/225], Training Accuracy: 90.0000%, Training Loss: 0.2647%\n",
      "Epoch [42/300], Step [161/225], Training Accuracy: 90.0524%, Training Loss: 0.2638%\n",
      "Epoch [42/300], Step [162/225], Training Accuracy: 90.0463%, Training Loss: 0.2636%\n",
      "Epoch [42/300], Step [163/225], Training Accuracy: 90.0211%, Training Loss: 0.2639%\n",
      "Epoch [42/300], Step [164/225], Training Accuracy: 90.0248%, Training Loss: 0.2638%\n",
      "Epoch [42/300], Step [165/225], Training Accuracy: 90.0284%, Training Loss: 0.2636%\n",
      "Epoch [42/300], Step [166/225], Training Accuracy: 90.0038%, Training Loss: 0.2640%\n",
      "Epoch [42/300], Step [167/225], Training Accuracy: 89.9981%, Training Loss: 0.2641%\n",
      "Epoch [42/300], Step [168/225], Training Accuracy: 89.9926%, Training Loss: 0.2640%\n",
      "Epoch [42/300], Step [169/225], Training Accuracy: 90.0055%, Training Loss: 0.2637%\n",
      "Epoch [42/300], Step [170/225], Training Accuracy: 90.0092%, Training Loss: 0.2634%\n",
      "Epoch [42/300], Step [171/225], Training Accuracy: 90.0037%, Training Loss: 0.2634%\n",
      "Epoch [42/300], Step [172/225], Training Accuracy: 90.0254%, Training Loss: 0.2630%\n",
      "Epoch [42/300], Step [173/225], Training Accuracy: 90.0108%, Training Loss: 0.2628%\n",
      "Epoch [42/300], Step [174/225], Training Accuracy: 89.9964%, Training Loss: 0.2630%\n",
      "Epoch [42/300], Step [175/225], Training Accuracy: 90.0268%, Training Loss: 0.2625%\n",
      "Epoch [42/300], Step [176/225], Training Accuracy: 90.0302%, Training Loss: 0.2625%\n",
      "Epoch [42/300], Step [177/225], Training Accuracy: 90.0512%, Training Loss: 0.2619%\n",
      "Epoch [42/300], Step [178/225], Training Accuracy: 90.0193%, Training Loss: 0.2628%\n",
      "Epoch [42/300], Step [179/225], Training Accuracy: 90.0402%, Training Loss: 0.2623%\n",
      "Epoch [42/300], Step [180/225], Training Accuracy: 90.0608%, Training Loss: 0.2622%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/300], Step [181/225], Training Accuracy: 90.0552%, Training Loss: 0.2625%\n",
      "Epoch [42/300], Step [182/225], Training Accuracy: 90.0498%, Training Loss: 0.2630%\n",
      "Epoch [42/300], Step [183/225], Training Accuracy: 90.0615%, Training Loss: 0.2625%\n",
      "Epoch [42/300], Step [184/225], Training Accuracy: 90.0645%, Training Loss: 0.2628%\n",
      "Epoch [42/300], Step [185/225], Training Accuracy: 90.0760%, Training Loss: 0.2624%\n",
      "Epoch [42/300], Step [186/225], Training Accuracy: 90.0958%, Training Loss: 0.2625%\n",
      "Epoch [42/300], Step [187/225], Training Accuracy: 90.0986%, Training Loss: 0.2624%\n",
      "Epoch [42/300], Step [188/225], Training Accuracy: 90.1097%, Training Loss: 0.2624%\n",
      "Epoch [42/300], Step [189/225], Training Accuracy: 90.1290%, Training Loss: 0.2618%\n",
      "Epoch [42/300], Step [190/225], Training Accuracy: 90.1069%, Training Loss: 0.2628%\n",
      "Epoch [42/300], Step [191/225], Training Accuracy: 90.1014%, Training Loss: 0.2626%\n",
      "Epoch [42/300], Step [192/225], Training Accuracy: 90.0716%, Training Loss: 0.2630%\n",
      "Epoch [42/300], Step [193/225], Training Accuracy: 90.0745%, Training Loss: 0.2629%\n",
      "Epoch [42/300], Step [194/225], Training Accuracy: 90.1015%, Training Loss: 0.2623%\n",
      "Epoch [42/300], Step [195/225], Training Accuracy: 90.0881%, Training Loss: 0.2625%\n",
      "Epoch [42/300], Step [196/225], Training Accuracy: 90.1228%, Training Loss: 0.2618%\n",
      "Epoch [42/300], Step [197/225], Training Accuracy: 90.1253%, Training Loss: 0.2621%\n",
      "Epoch [42/300], Step [198/225], Training Accuracy: 90.1357%, Training Loss: 0.2616%\n",
      "Epoch [42/300], Step [199/225], Training Accuracy: 90.1382%, Training Loss: 0.2615%\n",
      "Epoch [42/300], Step [200/225], Training Accuracy: 90.1328%, Training Loss: 0.2613%\n",
      "Epoch [42/300], Step [201/225], Training Accuracy: 90.1119%, Training Loss: 0.2620%\n",
      "Epoch [42/300], Step [202/225], Training Accuracy: 90.1300%, Training Loss: 0.2621%\n",
      "Epoch [42/300], Step [203/225], Training Accuracy: 90.1324%, Training Loss: 0.2623%\n",
      "Epoch [42/300], Step [204/225], Training Accuracy: 90.1425%, Training Loss: 0.2622%\n",
      "Epoch [42/300], Step [205/225], Training Accuracy: 90.1524%, Training Loss: 0.2617%\n",
      "Epoch [42/300], Step [206/225], Training Accuracy: 90.1168%, Training Loss: 0.2619%\n",
      "Epoch [42/300], Step [207/225], Training Accuracy: 90.1344%, Training Loss: 0.2615%\n",
      "Epoch [42/300], Step [208/225], Training Accuracy: 90.1593%, Training Loss: 0.2611%\n",
      "Epoch [42/300], Step [209/225], Training Accuracy: 90.1540%, Training Loss: 0.2611%\n",
      "Epoch [42/300], Step [210/225], Training Accuracy: 90.1562%, Training Loss: 0.2611%\n",
      "Epoch [42/300], Step [211/225], Training Accuracy: 90.1585%, Training Loss: 0.2613%\n",
      "Epoch [42/300], Step [212/225], Training Accuracy: 90.1533%, Training Loss: 0.2613%\n",
      "Epoch [42/300], Step [213/225], Training Accuracy: 90.1849%, Training Loss: 0.2609%\n",
      "Epoch [42/300], Step [214/225], Training Accuracy: 90.1942%, Training Loss: 0.2608%\n",
      "Epoch [42/300], Step [215/225], Training Accuracy: 90.2108%, Training Loss: 0.2610%\n",
      "Epoch [42/300], Step [216/225], Training Accuracy: 90.1910%, Training Loss: 0.2613%\n",
      "Epoch [42/300], Step [217/225], Training Accuracy: 90.2002%, Training Loss: 0.2611%\n",
      "Epoch [42/300], Step [218/225], Training Accuracy: 90.1878%, Training Loss: 0.2614%\n",
      "Epoch [42/300], Step [219/225], Training Accuracy: 90.1826%, Training Loss: 0.2613%\n",
      "Epoch [42/300], Step [220/225], Training Accuracy: 90.1705%, Training Loss: 0.2615%\n",
      "Epoch [42/300], Step [221/225], Training Accuracy: 90.1796%, Training Loss: 0.2617%\n",
      "Epoch [42/300], Step [222/225], Training Accuracy: 90.1745%, Training Loss: 0.2620%\n",
      "Epoch [42/300], Step [223/225], Training Accuracy: 90.1766%, Training Loss: 0.2619%\n",
      "Epoch [42/300], Step [224/225], Training Accuracy: 90.1995%, Training Loss: 0.2615%\n",
      "Epoch [42/300], Step [225/225], Training Accuracy: 90.1612%, Training Loss: 0.2624%\n",
      "Epoch [43/300], Step [1/225], Training Accuracy: 96.8750%, Training Loss: 0.1904%\n",
      "Epoch [43/300], Step [2/225], Training Accuracy: 95.3125%, Training Loss: 0.1987%\n",
      "Epoch [43/300], Step [3/225], Training Accuracy: 91.1458%, Training Loss: 0.2869%\n",
      "Epoch [43/300], Step [4/225], Training Accuracy: 91.0156%, Training Loss: 0.2746%\n",
      "Epoch [43/300], Step [5/225], Training Accuracy: 92.1875%, Training Loss: 0.2472%\n",
      "Epoch [43/300], Step [6/225], Training Accuracy: 91.6667%, Training Loss: 0.2522%\n",
      "Epoch [43/300], Step [7/225], Training Accuracy: 90.6250%, Training Loss: 0.2682%\n",
      "Epoch [43/300], Step [8/225], Training Accuracy: 90.6250%, Training Loss: 0.2680%\n",
      "Epoch [43/300], Step [9/225], Training Accuracy: 90.6250%, Training Loss: 0.2651%\n",
      "Epoch [43/300], Step [10/225], Training Accuracy: 90.3125%, Training Loss: 0.2691%\n",
      "Epoch [43/300], Step [11/225], Training Accuracy: 90.4830%, Training Loss: 0.2677%\n",
      "Epoch [43/300], Step [12/225], Training Accuracy: 90.7552%, Training Loss: 0.2639%\n",
      "Epoch [43/300], Step [13/225], Training Accuracy: 90.7452%, Training Loss: 0.2657%\n",
      "Epoch [43/300], Step [14/225], Training Accuracy: 90.7366%, Training Loss: 0.2670%\n",
      "Epoch [43/300], Step [15/225], Training Accuracy: 90.8333%, Training Loss: 0.2652%\n",
      "Epoch [43/300], Step [16/225], Training Accuracy: 90.3320%, Training Loss: 0.2696%\n",
      "Epoch [43/300], Step [17/225], Training Accuracy: 90.2574%, Training Loss: 0.2696%\n",
      "Epoch [43/300], Step [18/225], Training Accuracy: 89.7569%, Training Loss: 0.2770%\n",
      "Epoch [43/300], Step [19/225], Training Accuracy: 89.8849%, Training Loss: 0.2736%\n",
      "Epoch [43/300], Step [20/225], Training Accuracy: 90.0000%, Training Loss: 0.2701%\n",
      "Epoch [43/300], Step [21/225], Training Accuracy: 90.1042%, Training Loss: 0.2663%\n",
      "Epoch [43/300], Step [22/225], Training Accuracy: 89.9858%, Training Loss: 0.2683%\n",
      "Epoch [43/300], Step [23/225], Training Accuracy: 89.8098%, Training Loss: 0.2717%\n",
      "Epoch [43/300], Step [24/225], Training Accuracy: 89.5182%, Training Loss: 0.2768%\n",
      "Epoch [43/300], Step [25/225], Training Accuracy: 89.5625%, Training Loss: 0.2734%\n",
      "Epoch [43/300], Step [26/225], Training Accuracy: 89.5433%, Training Loss: 0.2719%\n",
      "Epoch [43/300], Step [27/225], Training Accuracy: 89.6412%, Training Loss: 0.2718%\n",
      "Epoch [43/300], Step [28/225], Training Accuracy: 89.9554%, Training Loss: 0.2664%\n",
      "Epoch [43/300], Step [29/225], Training Accuracy: 90.1401%, Training Loss: 0.2625%\n",
      "Epoch [43/300], Step [30/225], Training Accuracy: 90.1042%, Training Loss: 0.2609%\n",
      "Epoch [43/300], Step [31/225], Training Accuracy: 90.0202%, Training Loss: 0.2610%\n",
      "Epoch [43/300], Step [32/225], Training Accuracy: 89.9902%, Training Loss: 0.2601%\n",
      "Epoch [43/300], Step [33/225], Training Accuracy: 90.1989%, Training Loss: 0.2564%\n",
      "Epoch [43/300], Step [34/225], Training Accuracy: 90.0735%, Training Loss: 0.2572%\n",
      "Epoch [43/300], Step [35/225], Training Accuracy: 90.0446%, Training Loss: 0.2560%\n",
      "Epoch [43/300], Step [36/225], Training Accuracy: 90.1910%, Training Loss: 0.2541%\n",
      "Epoch [43/300], Step [37/225], Training Accuracy: 90.0338%, Training Loss: 0.2569%\n",
      "Epoch [43/300], Step [38/225], Training Accuracy: 89.9671%, Training Loss: 0.2597%\n",
      "Epoch [43/300], Step [39/225], Training Accuracy: 89.9840%, Training Loss: 0.2603%\n",
      "Epoch [43/300], Step [40/225], Training Accuracy: 89.9609%, Training Loss: 0.2612%\n",
      "Epoch [43/300], Step [41/225], Training Accuracy: 90.0152%, Training Loss: 0.2604%\n",
      "Epoch [43/300], Step [42/225], Training Accuracy: 90.1786%, Training Loss: 0.2585%\n",
      "Epoch [43/300], Step [43/225], Training Accuracy: 90.2616%, Training Loss: 0.2587%\n",
      "Epoch [43/300], Step [44/225], Training Accuracy: 90.1634%, Training Loss: 0.2603%\n",
      "Epoch [43/300], Step [45/225], Training Accuracy: 90.2083%, Training Loss: 0.2584%\n",
      "Epoch [43/300], Step [46/225], Training Accuracy: 90.1495%, Training Loss: 0.2587%\n",
      "Epoch [43/300], Step [47/225], Training Accuracy: 90.1263%, Training Loss: 0.2596%\n",
      "Epoch [43/300], Step [48/225], Training Accuracy: 90.1367%, Training Loss: 0.2599%\n",
      "Epoch [43/300], Step [49/225], Training Accuracy: 90.1467%, Training Loss: 0.2625%\n",
      "Epoch [43/300], Step [50/225], Training Accuracy: 90.1562%, Training Loss: 0.2611%\n",
      "Epoch [43/300], Step [51/225], Training Accuracy: 90.1042%, Training Loss: 0.2620%\n",
      "Epoch [43/300], Step [52/225], Training Accuracy: 90.1142%, Training Loss: 0.2606%\n",
      "Epoch [43/300], Step [53/225], Training Accuracy: 90.1828%, Training Loss: 0.2598%\n",
      "Epoch [43/300], Step [54/225], Training Accuracy: 90.1331%, Training Loss: 0.2596%\n",
      "Epoch [43/300], Step [55/225], Training Accuracy: 90.1420%, Training Loss: 0.2589%\n",
      "Epoch [43/300], Step [56/225], Training Accuracy: 90.1228%, Training Loss: 0.2584%\n",
      "Epoch [43/300], Step [57/225], Training Accuracy: 90.1042%, Training Loss: 0.2588%\n",
      "Epoch [43/300], Step [58/225], Training Accuracy: 90.2209%, Training Loss: 0.2578%\n",
      "Epoch [43/300], Step [59/225], Training Accuracy: 90.1483%, Training Loss: 0.2591%\n",
      "Epoch [43/300], Step [60/225], Training Accuracy: 90.2083%, Training Loss: 0.2582%\n",
      "Epoch [43/300], Step [61/225], Training Accuracy: 90.1639%, Training Loss: 0.2601%\n",
      "Epoch [43/300], Step [62/225], Training Accuracy: 90.1462%, Training Loss: 0.2601%\n",
      "Epoch [43/300], Step [63/225], Training Accuracy: 90.1538%, Training Loss: 0.2602%\n",
      "Epoch [43/300], Step [64/225], Training Accuracy: 90.1367%, Training Loss: 0.2603%\n",
      "Epoch [43/300], Step [65/225], Training Accuracy: 90.1923%, Training Loss: 0.2585%\n",
      "Epoch [43/300], Step [66/225], Training Accuracy: 90.1752%, Training Loss: 0.2590%\n",
      "Epoch [43/300], Step [67/225], Training Accuracy: 90.1586%, Training Loss: 0.2601%\n",
      "Epoch [43/300], Step [68/225], Training Accuracy: 90.2344%, Training Loss: 0.2586%\n",
      "Epoch [43/300], Step [69/225], Training Accuracy: 90.3080%, Training Loss: 0.2573%\n",
      "Epoch [43/300], Step [70/225], Training Accuracy: 90.3125%, Training Loss: 0.2593%\n",
      "Epoch [43/300], Step [71/225], Training Accuracy: 90.3829%, Training Loss: 0.2581%\n",
      "Epoch [43/300], Step [72/225], Training Accuracy: 90.3429%, Training Loss: 0.2584%\n",
      "Epoch [43/300], Step [73/225], Training Accuracy: 90.3467%, Training Loss: 0.2586%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/300], Step [74/225], Training Accuracy: 90.2660%, Training Loss: 0.2589%\n",
      "Epoch [43/300], Step [75/225], Training Accuracy: 90.3125%, Training Loss: 0.2579%\n",
      "Epoch [43/300], Step [76/225], Training Accuracy: 90.3166%, Training Loss: 0.2573%\n",
      "Epoch [43/300], Step [77/225], Training Accuracy: 90.3815%, Training Loss: 0.2560%\n",
      "Epoch [43/300], Step [78/225], Training Accuracy: 90.3245%, Training Loss: 0.2568%\n",
      "Epoch [43/300], Step [79/225], Training Accuracy: 90.3283%, Training Loss: 0.2576%\n",
      "Epoch [43/300], Step [80/225], Training Accuracy: 90.3125%, Training Loss: 0.2574%\n",
      "Epoch [43/300], Step [81/225], Training Accuracy: 90.3935%, Training Loss: 0.2563%\n",
      "Epoch [43/300], Step [82/225], Training Accuracy: 90.4154%, Training Loss: 0.2556%\n",
      "Epoch [43/300], Step [83/225], Training Accuracy: 90.3050%, Training Loss: 0.2571%\n",
      "Epoch [43/300], Step [84/225], Training Accuracy: 90.3274%, Training Loss: 0.2561%\n",
      "Epoch [43/300], Step [85/225], Training Accuracy: 90.3860%, Training Loss: 0.2555%\n",
      "Epoch [43/300], Step [86/225], Training Accuracy: 90.4251%, Training Loss: 0.2546%\n",
      "Epoch [43/300], Step [87/225], Training Accuracy: 90.3736%, Training Loss: 0.2552%\n",
      "Epoch [43/300], Step [88/225], Training Accuracy: 90.3587%, Training Loss: 0.2547%\n",
      "Epoch [43/300], Step [89/225], Training Accuracy: 90.3617%, Training Loss: 0.2549%\n",
      "Epoch [43/300], Step [90/225], Training Accuracy: 90.3819%, Training Loss: 0.2541%\n",
      "Epoch [43/300], Step [91/225], Training Accuracy: 90.3674%, Training Loss: 0.2535%\n",
      "Epoch [43/300], Step [92/225], Training Accuracy: 90.4042%, Training Loss: 0.2527%\n",
      "Epoch [43/300], Step [93/225], Training Accuracy: 90.3898%, Training Loss: 0.2534%\n",
      "Epoch [43/300], Step [94/225], Training Accuracy: 90.3923%, Training Loss: 0.2535%\n",
      "Epoch [43/300], Step [95/225], Training Accuracy: 90.3454%, Training Loss: 0.2538%\n",
      "Epoch [43/300], Step [96/225], Training Accuracy: 90.3809%, Training Loss: 0.2528%\n",
      "Epoch [43/300], Step [97/225], Training Accuracy: 90.3673%, Training Loss: 0.2528%\n",
      "Epoch [43/300], Step [98/225], Training Accuracy: 90.3858%, Training Loss: 0.2522%\n",
      "Epoch [43/300], Step [99/225], Training Accuracy: 90.3251%, Training Loss: 0.2531%\n",
      "Epoch [43/300], Step [100/225], Training Accuracy: 90.3281%, Training Loss: 0.2537%\n",
      "Epoch [43/300], Step [101/225], Training Accuracy: 90.3620%, Training Loss: 0.2527%\n",
      "Epoch [43/300], Step [102/225], Training Accuracy: 90.3186%, Training Loss: 0.2534%\n",
      "Epoch [43/300], Step [103/225], Training Accuracy: 90.3519%, Training Loss: 0.2533%\n",
      "Epoch [43/300], Step [104/225], Training Accuracy: 90.3546%, Training Loss: 0.2534%\n",
      "Epoch [43/300], Step [105/225], Training Accuracy: 90.3720%, Training Loss: 0.2531%\n",
      "Epoch [43/300], Step [106/225], Training Accuracy: 90.4039%, Training Loss: 0.2526%\n",
      "Epoch [43/300], Step [107/225], Training Accuracy: 90.3475%, Training Loss: 0.2535%\n",
      "Epoch [43/300], Step [108/225], Training Accuracy: 90.3067%, Training Loss: 0.2537%\n",
      "Epoch [43/300], Step [109/225], Training Accuracy: 90.2953%, Training Loss: 0.2537%\n",
      "Epoch [43/300], Step [110/225], Training Accuracy: 90.3125%, Training Loss: 0.2538%\n",
      "Epoch [43/300], Step [111/225], Training Accuracy: 90.3153%, Training Loss: 0.2539%\n",
      "Epoch [43/300], Step [112/225], Training Accuracy: 90.2762%, Training Loss: 0.2545%\n",
      "Epoch [43/300], Step [113/225], Training Accuracy: 90.3070%, Training Loss: 0.2550%\n",
      "Epoch [43/300], Step [114/225], Training Accuracy: 90.2686%, Training Loss: 0.2556%\n",
      "Epoch [43/300], Step [115/225], Training Accuracy: 90.3125%, Training Loss: 0.2546%\n",
      "Epoch [43/300], Step [116/225], Training Accuracy: 90.3017%, Training Loss: 0.2545%\n",
      "Epoch [43/300], Step [117/225], Training Accuracy: 90.2911%, Training Loss: 0.2554%\n",
      "Epoch [43/300], Step [118/225], Training Accuracy: 90.3072%, Training Loss: 0.2548%\n",
      "Epoch [43/300], Step [119/225], Training Accuracy: 90.2836%, Training Loss: 0.2555%\n",
      "Epoch [43/300], Step [120/225], Training Accuracy: 90.3385%, Training Loss: 0.2544%\n",
      "Epoch [43/300], Step [121/225], Training Accuracy: 90.3151%, Training Loss: 0.2549%\n",
      "Epoch [43/300], Step [122/225], Training Accuracy: 90.2920%, Training Loss: 0.2550%\n",
      "Epoch [43/300], Step [123/225], Training Accuracy: 90.3074%, Training Loss: 0.2545%\n",
      "Epoch [43/300], Step [124/225], Training Accuracy: 90.3226%, Training Loss: 0.2539%\n",
      "Epoch [43/300], Step [125/225], Training Accuracy: 90.2750%, Training Loss: 0.2542%\n",
      "Epoch [43/300], Step [126/225], Training Accuracy: 90.3274%, Training Loss: 0.2536%\n",
      "Epoch [43/300], Step [127/225], Training Accuracy: 90.3420%, Training Loss: 0.2541%\n",
      "Epoch [43/300], Step [128/225], Training Accuracy: 90.3320%, Training Loss: 0.2542%\n",
      "Epoch [43/300], Step [129/225], Training Accuracy: 90.3222%, Training Loss: 0.2549%\n",
      "Epoch [43/300], Step [130/225], Training Accuracy: 90.3486%, Training Loss: 0.2545%\n",
      "Epoch [43/300], Step [131/225], Training Accuracy: 90.3745%, Training Loss: 0.2539%\n",
      "Epoch [43/300], Step [132/225], Training Accuracy: 90.3646%, Training Loss: 0.2544%\n",
      "Epoch [43/300], Step [133/225], Training Accuracy: 90.3900%, Training Loss: 0.2539%\n",
      "Epoch [43/300], Step [134/225], Training Accuracy: 90.3685%, Training Loss: 0.2540%\n",
      "Epoch [43/300], Step [135/225], Training Accuracy: 90.4051%, Training Loss: 0.2535%\n",
      "Epoch [43/300], Step [136/225], Training Accuracy: 90.3608%, Training Loss: 0.2542%\n",
      "Epoch [43/300], Step [137/225], Training Accuracy: 90.3513%, Training Loss: 0.2540%\n",
      "Epoch [43/300], Step [138/225], Training Accuracy: 90.3193%, Training Loss: 0.2541%\n",
      "Epoch [43/300], Step [139/225], Training Accuracy: 90.2878%, Training Loss: 0.2555%\n",
      "Epoch [43/300], Step [140/225], Training Accuracy: 90.3125%, Training Loss: 0.2550%\n",
      "Epoch [43/300], Step [141/225], Training Accuracy: 90.2593%, Training Loss: 0.2557%\n",
      "Epoch [43/300], Step [142/225], Training Accuracy: 90.2729%, Training Loss: 0.2553%\n",
      "Epoch [43/300], Step [143/225], Training Accuracy: 90.2863%, Training Loss: 0.2554%\n",
      "Epoch [43/300], Step [144/225], Training Accuracy: 90.2995%, Training Loss: 0.2552%\n",
      "Epoch [43/300], Step [145/225], Training Accuracy: 90.3125%, Training Loss: 0.2551%\n",
      "Epoch [43/300], Step [146/225], Training Accuracy: 90.3467%, Training Loss: 0.2545%\n",
      "Epoch [43/300], Step [147/225], Training Accuracy: 90.3168%, Training Loss: 0.2550%\n",
      "Epoch [43/300], Step [148/225], Training Accuracy: 90.3083%, Training Loss: 0.2549%\n",
      "Epoch [43/300], Step [149/225], Training Accuracy: 90.2789%, Training Loss: 0.2555%\n",
      "Epoch [43/300], Step [150/225], Training Accuracy: 90.3125%, Training Loss: 0.2550%\n",
      "Epoch [43/300], Step [151/225], Training Accuracy: 90.3042%, Training Loss: 0.2550%\n",
      "Epoch [43/300], Step [152/225], Training Accuracy: 90.3063%, Training Loss: 0.2553%\n",
      "Epoch [43/300], Step [153/225], Training Accuracy: 90.2676%, Training Loss: 0.2556%\n",
      "Epoch [43/300], Step [154/225], Training Accuracy: 90.2800%, Training Loss: 0.2555%\n",
      "Epoch [43/300], Step [155/225], Training Accuracy: 90.2823%, Training Loss: 0.2555%\n",
      "Epoch [43/300], Step [156/225], Training Accuracy: 90.3145%, Training Loss: 0.2550%\n",
      "Epoch [43/300], Step [157/225], Training Accuracy: 90.2966%, Training Loss: 0.2551%\n",
      "Epoch [43/300], Step [158/225], Training Accuracy: 90.3283%, Training Loss: 0.2541%\n",
      "Epoch [43/300], Step [159/225], Training Accuracy: 90.3597%, Training Loss: 0.2536%\n",
      "Epoch [43/300], Step [160/225], Training Accuracy: 90.3809%, Training Loss: 0.2530%\n",
      "Epoch [43/300], Step [161/225], Training Accuracy: 90.3824%, Training Loss: 0.2531%\n",
      "Epoch [43/300], Step [162/225], Training Accuracy: 90.3935%, Training Loss: 0.2526%\n",
      "Epoch [43/300], Step [163/225], Training Accuracy: 90.3758%, Training Loss: 0.2528%\n",
      "Epoch [43/300], Step [164/225], Training Accuracy: 90.3678%, Training Loss: 0.2532%\n",
      "Epoch [43/300], Step [165/225], Training Accuracy: 90.4072%, Training Loss: 0.2528%\n",
      "Epoch [43/300], Step [166/225], Training Accuracy: 90.4085%, Training Loss: 0.2526%\n",
      "Epoch [43/300], Step [167/225], Training Accuracy: 90.4004%, Training Loss: 0.2527%\n",
      "Epoch [43/300], Step [168/225], Training Accuracy: 90.4390%, Training Loss: 0.2520%\n",
      "Epoch [43/300], Step [169/225], Training Accuracy: 90.4493%, Training Loss: 0.2520%\n",
      "Epoch [43/300], Step [170/225], Training Accuracy: 90.4596%, Training Loss: 0.2518%\n",
      "Epoch [43/300], Step [171/225], Training Accuracy: 90.4697%, Training Loss: 0.2515%\n",
      "Epoch [43/300], Step [172/225], Training Accuracy: 90.4706%, Training Loss: 0.2517%\n",
      "Epoch [43/300], Step [173/225], Training Accuracy: 90.4805%, Training Loss: 0.2514%\n",
      "Epoch [43/300], Step [174/225], Training Accuracy: 90.4634%, Training Loss: 0.2516%\n",
      "Epoch [43/300], Step [175/225], Training Accuracy: 90.4643%, Training Loss: 0.2517%\n",
      "Epoch [43/300], Step [176/225], Training Accuracy: 90.4386%, Training Loss: 0.2518%\n",
      "Epoch [43/300], Step [177/225], Training Accuracy: 90.4661%, Training Loss: 0.2513%\n",
      "Epoch [43/300], Step [178/225], Training Accuracy: 90.4231%, Training Loss: 0.2518%\n",
      "Epoch [43/300], Step [179/225], Training Accuracy: 90.4155%, Training Loss: 0.2519%\n",
      "Epoch [43/300], Step [180/225], Training Accuracy: 90.3993%, Training Loss: 0.2519%\n",
      "Epoch [43/300], Step [181/225], Training Accuracy: 90.3833%, Training Loss: 0.2525%\n",
      "Epoch [43/300], Step [182/225], Training Accuracy: 90.3760%, Training Loss: 0.2524%\n",
      "Epoch [43/300], Step [183/225], Training Accuracy: 90.3859%, Training Loss: 0.2521%\n",
      "Epoch [43/300], Step [184/225], Training Accuracy: 90.3787%, Training Loss: 0.2521%\n",
      "Epoch [43/300], Step [185/225], Training Accuracy: 90.3801%, Training Loss: 0.2522%\n",
      "Epoch [43/300], Step [186/225], Training Accuracy: 90.4234%, Training Loss: 0.2515%\n",
      "Epoch [43/300], Step [187/225], Training Accuracy: 90.4245%, Training Loss: 0.2513%\n",
      "Epoch [43/300], Step [188/225], Training Accuracy: 90.4172%, Training Loss: 0.2515%\n",
      "Epoch [43/300], Step [189/225], Training Accuracy: 90.4266%, Training Loss: 0.2513%\n",
      "Epoch [43/300], Step [190/225], Training Accuracy: 90.3783%, Training Loss: 0.2520%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/300], Step [191/225], Training Accuracy: 90.3714%, Training Loss: 0.2519%\n",
      "Epoch [43/300], Step [192/225], Training Accuracy: 90.3483%, Training Loss: 0.2521%\n",
      "Epoch [43/300], Step [193/225], Training Accuracy: 90.3578%, Training Loss: 0.2520%\n",
      "Epoch [43/300], Step [194/225], Training Accuracy: 90.3753%, Training Loss: 0.2515%\n",
      "Epoch [43/300], Step [195/225], Training Accuracy: 90.3686%, Training Loss: 0.2516%\n",
      "Epoch [43/300], Step [196/225], Training Accuracy: 90.3858%, Training Loss: 0.2512%\n",
      "Epoch [43/300], Step [197/225], Training Accuracy: 90.3950%, Training Loss: 0.2513%\n",
      "Epoch [43/300], Step [198/225], Training Accuracy: 90.4040%, Training Loss: 0.2512%\n",
      "Epoch [43/300], Step [199/225], Training Accuracy: 90.4287%, Training Loss: 0.2513%\n",
      "Epoch [43/300], Step [200/225], Training Accuracy: 90.4688%, Training Loss: 0.2505%\n",
      "Epoch [43/300], Step [201/225], Training Accuracy: 90.4773%, Training Loss: 0.2503%\n",
      "Epoch [43/300], Step [202/225], Training Accuracy: 90.4780%, Training Loss: 0.2503%\n",
      "Epoch [43/300], Step [203/225], Training Accuracy: 90.4788%, Training Loss: 0.2507%\n",
      "Epoch [43/300], Step [204/225], Training Accuracy: 90.4718%, Training Loss: 0.2507%\n",
      "Epoch [43/300], Step [205/225], Training Accuracy: 90.4726%, Training Loss: 0.2507%\n",
      "Epoch [43/300], Step [206/225], Training Accuracy: 90.4809%, Training Loss: 0.2505%\n",
      "Epoch [43/300], Step [207/225], Training Accuracy: 90.5042%, Training Loss: 0.2502%\n",
      "Epoch [43/300], Step [208/225], Training Accuracy: 90.5123%, Training Loss: 0.2499%\n",
      "Epoch [43/300], Step [209/225], Training Accuracy: 90.5428%, Training Loss: 0.2496%\n",
      "Epoch [43/300], Step [210/225], Training Accuracy: 90.5357%, Training Loss: 0.2498%\n",
      "Epoch [43/300], Step [211/225], Training Accuracy: 90.5213%, Training Loss: 0.2500%\n",
      "Epoch [43/300], Step [212/225], Training Accuracy: 90.5292%, Training Loss: 0.2495%\n",
      "Epoch [43/300], Step [213/225], Training Accuracy: 90.5443%, Training Loss: 0.2490%\n",
      "Epoch [43/300], Step [214/225], Training Accuracy: 90.5593%, Training Loss: 0.2488%\n",
      "Epoch [43/300], Step [215/225], Training Accuracy: 90.5669%, Training Loss: 0.2486%\n",
      "Epoch [43/300], Step [216/225], Training Accuracy: 90.5671%, Training Loss: 0.2488%\n",
      "Epoch [43/300], Step [217/225], Training Accuracy: 90.5674%, Training Loss: 0.2486%\n",
      "Epoch [43/300], Step [218/225], Training Accuracy: 90.6035%, Training Loss: 0.2481%\n",
      "Epoch [43/300], Step [219/225], Training Accuracy: 90.6179%, Training Loss: 0.2477%\n",
      "Epoch [43/300], Step [220/225], Training Accuracy: 90.6392%, Training Loss: 0.2472%\n",
      "Epoch [43/300], Step [221/225], Training Accuracy: 90.6533%, Training Loss: 0.2470%\n",
      "Epoch [43/300], Step [222/225], Training Accuracy: 90.6602%, Training Loss: 0.2470%\n",
      "Epoch [43/300], Step [223/225], Training Accuracy: 90.6740%, Training Loss: 0.2465%\n",
      "Epoch [43/300], Step [224/225], Training Accuracy: 90.6878%, Training Loss: 0.2464%\n",
      "Epoch [43/300], Step [225/225], Training Accuracy: 90.7032%, Training Loss: 0.2463%\n",
      "Epoch [44/300], Step [1/225], Training Accuracy: 93.7500%, Training Loss: 0.2363%\n",
      "Epoch [44/300], Step [2/225], Training Accuracy: 89.8438%, Training Loss: 0.2917%\n",
      "Epoch [44/300], Step [3/225], Training Accuracy: 88.5417%, Training Loss: 0.3237%\n",
      "Epoch [44/300], Step [4/225], Training Accuracy: 90.6250%, Training Loss: 0.2648%\n",
      "Epoch [44/300], Step [5/225], Training Accuracy: 91.8750%, Training Loss: 0.2359%\n",
      "Epoch [44/300], Step [6/225], Training Accuracy: 92.4479%, Training Loss: 0.2297%\n",
      "Epoch [44/300], Step [7/225], Training Accuracy: 91.0714%, Training Loss: 0.2466%\n",
      "Epoch [44/300], Step [8/225], Training Accuracy: 91.4062%, Training Loss: 0.2352%\n",
      "Epoch [44/300], Step [9/225], Training Accuracy: 91.3194%, Training Loss: 0.2354%\n",
      "Epoch [44/300], Step [10/225], Training Accuracy: 91.7188%, Training Loss: 0.2308%\n",
      "Epoch [44/300], Step [11/225], Training Accuracy: 91.6193%, Training Loss: 0.2280%\n",
      "Epoch [44/300], Step [12/225], Training Accuracy: 91.7969%, Training Loss: 0.2251%\n",
      "Epoch [44/300], Step [13/225], Training Accuracy: 91.9471%, Training Loss: 0.2262%\n",
      "Epoch [44/300], Step [14/225], Training Accuracy: 91.1830%, Training Loss: 0.2437%\n",
      "Epoch [44/300], Step [15/225], Training Accuracy: 91.1458%, Training Loss: 0.2409%\n",
      "Epoch [44/300], Step [16/225], Training Accuracy: 91.2109%, Training Loss: 0.2389%\n",
      "Epoch [44/300], Step [17/225], Training Accuracy: 90.9007%, Training Loss: 0.2414%\n",
      "Epoch [44/300], Step [18/225], Training Accuracy: 90.7986%, Training Loss: 0.2461%\n",
      "Epoch [44/300], Step [19/225], Training Accuracy: 90.9539%, Training Loss: 0.2429%\n",
      "Epoch [44/300], Step [20/225], Training Accuracy: 90.8594%, Training Loss: 0.2461%\n",
      "Epoch [44/300], Step [21/225], Training Accuracy: 90.9226%, Training Loss: 0.2452%\n",
      "Epoch [44/300], Step [22/225], Training Accuracy: 90.9091%, Training Loss: 0.2485%\n",
      "Epoch [44/300], Step [23/225], Training Accuracy: 90.7609%, Training Loss: 0.2476%\n",
      "Epoch [44/300], Step [24/225], Training Accuracy: 90.9505%, Training Loss: 0.2449%\n",
      "Epoch [44/300], Step [25/225], Training Accuracy: 91.0625%, Training Loss: 0.2400%\n",
      "Epoch [44/300], Step [26/225], Training Accuracy: 91.1058%, Training Loss: 0.2394%\n",
      "Epoch [44/300], Step [27/225], Training Accuracy: 90.9722%, Training Loss: 0.2458%\n",
      "Epoch [44/300], Step [28/225], Training Accuracy: 91.1830%, Training Loss: 0.2435%\n",
      "Epoch [44/300], Step [29/225], Training Accuracy: 91.1638%, Training Loss: 0.2432%\n",
      "Epoch [44/300], Step [30/225], Training Accuracy: 91.0938%, Training Loss: 0.2446%\n",
      "Epoch [44/300], Step [31/225], Training Accuracy: 91.1290%, Training Loss: 0.2431%\n",
      "Epoch [44/300], Step [32/225], Training Accuracy: 91.1621%, Training Loss: 0.2406%\n",
      "Epoch [44/300], Step [33/225], Training Accuracy: 91.2405%, Training Loss: 0.2374%\n",
      "Epoch [44/300], Step [34/225], Training Accuracy: 91.3603%, Training Loss: 0.2348%\n",
      "Epoch [44/300], Step [35/225], Training Accuracy: 91.2500%, Training Loss: 0.2362%\n",
      "Epoch [44/300], Step [36/225], Training Accuracy: 91.3194%, Training Loss: 0.2371%\n",
      "Epoch [44/300], Step [37/225], Training Accuracy: 91.2162%, Training Loss: 0.2385%\n",
      "Epoch [44/300], Step [38/225], Training Accuracy: 91.1595%, Training Loss: 0.2405%\n",
      "Epoch [44/300], Step [39/225], Training Accuracy: 91.1859%, Training Loss: 0.2419%\n",
      "Epoch [44/300], Step [40/225], Training Accuracy: 91.2109%, Training Loss: 0.2412%\n",
      "Epoch [44/300], Step [41/225], Training Accuracy: 91.2729%, Training Loss: 0.2405%\n",
      "Epoch [44/300], Step [42/225], Training Accuracy: 91.1458%, Training Loss: 0.2431%\n",
      "Epoch [44/300], Step [43/225], Training Accuracy: 91.2064%, Training Loss: 0.2415%\n",
      "Epoch [44/300], Step [44/225], Training Accuracy: 91.2997%, Training Loss: 0.2393%\n",
      "Epoch [44/300], Step [45/225], Training Accuracy: 91.2500%, Training Loss: 0.2391%\n",
      "Epoch [44/300], Step [46/225], Training Accuracy: 91.2024%, Training Loss: 0.2381%\n",
      "Epoch [44/300], Step [47/225], Training Accuracy: 91.1569%, Training Loss: 0.2377%\n",
      "Epoch [44/300], Step [48/225], Training Accuracy: 91.1458%, Training Loss: 0.2384%\n",
      "Epoch [44/300], Step [49/225], Training Accuracy: 91.1033%, Training Loss: 0.2386%\n",
      "Epoch [44/300], Step [50/225], Training Accuracy: 91.0000%, Training Loss: 0.2396%\n",
      "Epoch [44/300], Step [51/225], Training Accuracy: 91.0846%, Training Loss: 0.2370%\n",
      "Epoch [44/300], Step [52/225], Training Accuracy: 91.1058%, Training Loss: 0.2366%\n",
      "Epoch [44/300], Step [53/225], Training Accuracy: 91.1557%, Training Loss: 0.2353%\n",
      "Epoch [44/300], Step [54/225], Training Accuracy: 91.0880%, Training Loss: 0.2370%\n",
      "Epoch [44/300], Step [55/225], Training Accuracy: 91.0227%, Training Loss: 0.2387%\n",
      "Epoch [44/300], Step [56/225], Training Accuracy: 91.0993%, Training Loss: 0.2378%\n",
      "Epoch [44/300], Step [57/225], Training Accuracy: 91.0910%, Training Loss: 0.2386%\n",
      "Epoch [44/300], Step [58/225], Training Accuracy: 91.1099%, Training Loss: 0.2392%\n",
      "Epoch [44/300], Step [59/225], Training Accuracy: 90.9693%, Training Loss: 0.2408%\n",
      "Epoch [44/300], Step [60/225], Training Accuracy: 90.9375%, Training Loss: 0.2415%\n",
      "Epoch [44/300], Step [61/225], Training Accuracy: 90.8811%, Training Loss: 0.2438%\n",
      "Epoch [44/300], Step [62/225], Training Accuracy: 90.9022%, Training Loss: 0.2429%\n",
      "Epoch [44/300], Step [63/225], Training Accuracy: 90.7986%, Training Loss: 0.2452%\n",
      "Epoch [44/300], Step [64/225], Training Accuracy: 90.7715%, Training Loss: 0.2460%\n",
      "Epoch [44/300], Step [65/225], Training Accuracy: 90.8173%, Training Loss: 0.2453%\n",
      "Epoch [44/300], Step [66/225], Training Accuracy: 90.8144%, Training Loss: 0.2449%\n",
      "Epoch [44/300], Step [67/225], Training Accuracy: 90.8116%, Training Loss: 0.2449%\n",
      "Epoch [44/300], Step [68/225], Training Accuracy: 90.8088%, Training Loss: 0.2458%\n",
      "Epoch [44/300], Step [69/225], Training Accuracy: 90.8062%, Training Loss: 0.2465%\n",
      "Epoch [44/300], Step [70/225], Training Accuracy: 90.8482%, Training Loss: 0.2455%\n",
      "Epoch [44/300], Step [71/225], Training Accuracy: 90.9111%, Training Loss: 0.2445%\n",
      "Epoch [44/300], Step [72/225], Training Accuracy: 90.9288%, Training Loss: 0.2446%\n",
      "Epoch [44/300], Step [73/225], Training Accuracy: 90.8818%, Training Loss: 0.2456%\n",
      "Epoch [44/300], Step [74/225], Training Accuracy: 90.8573%, Training Loss: 0.2462%\n",
      "Epoch [44/300], Step [75/225], Training Accuracy: 90.8542%, Training Loss: 0.2459%\n",
      "Epoch [44/300], Step [76/225], Training Accuracy: 90.8717%, Training Loss: 0.2458%\n",
      "Epoch [44/300], Step [77/225], Training Accuracy: 90.8482%, Training Loss: 0.2468%\n",
      "Epoch [44/300], Step [78/225], Training Accuracy: 90.9054%, Training Loss: 0.2458%\n",
      "Epoch [44/300], Step [79/225], Training Accuracy: 90.8623%, Training Loss: 0.2470%\n",
      "Epoch [44/300], Step [80/225], Training Accuracy: 90.8789%, Training Loss: 0.2468%\n",
      "Epoch [44/300], Step [81/225], Training Accuracy: 90.8758%, Training Loss: 0.2479%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/300], Step [82/225], Training Accuracy: 90.9108%, Training Loss: 0.2477%\n",
      "Epoch [44/300], Step [83/225], Training Accuracy: 90.9262%, Training Loss: 0.2483%\n",
      "Epoch [44/300], Step [84/225], Training Accuracy: 90.9598%, Training Loss: 0.2476%\n",
      "Epoch [44/300], Step [85/225], Training Accuracy: 90.9191%, Training Loss: 0.2481%\n",
      "Epoch [44/300], Step [86/225], Training Accuracy: 90.9157%, Training Loss: 0.2478%\n",
      "Epoch [44/300], Step [87/225], Training Accuracy: 90.8764%, Training Loss: 0.2490%\n",
      "Epoch [44/300], Step [88/225], Training Accuracy: 90.8558%, Training Loss: 0.2493%\n",
      "Epoch [44/300], Step [89/225], Training Accuracy: 90.8708%, Training Loss: 0.2489%\n",
      "Epoch [44/300], Step [90/225], Training Accuracy: 90.8507%, Training Loss: 0.2485%\n",
      "Epoch [44/300], Step [91/225], Training Accuracy: 90.8482%, Training Loss: 0.2489%\n",
      "Epoch [44/300], Step [92/225], Training Accuracy: 90.8967%, Training Loss: 0.2481%\n",
      "Epoch [44/300], Step [93/225], Training Accuracy: 90.8938%, Training Loss: 0.2477%\n",
      "Epoch [44/300], Step [94/225], Training Accuracy: 90.8743%, Training Loss: 0.2482%\n",
      "Epoch [44/300], Step [95/225], Training Accuracy: 90.8553%, Training Loss: 0.2487%\n",
      "Epoch [44/300], Step [96/225], Training Accuracy: 90.9017%, Training Loss: 0.2475%\n",
      "Epoch [44/300], Step [97/225], Training Accuracy: 90.9311%, Training Loss: 0.2467%\n",
      "Epoch [44/300], Step [98/225], Training Accuracy: 90.8642%, Training Loss: 0.2484%\n",
      "Epoch [44/300], Step [99/225], Training Accuracy: 90.8775%, Training Loss: 0.2481%\n",
      "Epoch [44/300], Step [100/225], Training Accuracy: 90.8906%, Training Loss: 0.2472%\n",
      "Epoch [44/300], Step [101/225], Training Accuracy: 90.9344%, Training Loss: 0.2473%\n",
      "Epoch [44/300], Step [102/225], Training Accuracy: 90.9467%, Training Loss: 0.2473%\n",
      "Epoch [44/300], Step [103/225], Training Accuracy: 90.9587%, Training Loss: 0.2476%\n",
      "Epoch [44/300], Step [104/225], Training Accuracy: 91.0006%, Training Loss: 0.2477%\n",
      "Epoch [44/300], Step [105/225], Training Accuracy: 91.0417%, Training Loss: 0.2468%\n",
      "Epoch [44/300], Step [106/225], Training Accuracy: 91.0525%, Training Loss: 0.2466%\n",
      "Epoch [44/300], Step [107/225], Training Accuracy: 91.0047%, Training Loss: 0.2474%\n",
      "Epoch [44/300], Step [108/225], Training Accuracy: 91.0156%, Training Loss: 0.2472%\n",
      "Epoch [44/300], Step [109/225], Training Accuracy: 91.0407%, Training Loss: 0.2468%\n",
      "Epoch [44/300], Step [110/225], Training Accuracy: 91.0369%, Training Loss: 0.2466%\n",
      "Epoch [44/300], Step [111/225], Training Accuracy: 91.0755%, Training Loss: 0.2454%\n",
      "Epoch [44/300], Step [112/225], Training Accuracy: 91.0714%, Training Loss: 0.2454%\n",
      "Epoch [44/300], Step [113/225], Training Accuracy: 91.1090%, Training Loss: 0.2448%\n",
      "Epoch [44/300], Step [114/225], Training Accuracy: 91.0773%, Training Loss: 0.2452%\n",
      "Epoch [44/300], Step [115/225], Training Accuracy: 91.0870%, Training Loss: 0.2448%\n",
      "Epoch [44/300], Step [116/225], Training Accuracy: 91.0830%, Training Loss: 0.2453%\n",
      "Epoch [44/300], Step [117/225], Training Accuracy: 91.0791%, Training Loss: 0.2451%\n",
      "Epoch [44/300], Step [118/225], Training Accuracy: 91.0090%, Training Loss: 0.2466%\n",
      "Epoch [44/300], Step [119/225], Training Accuracy: 91.0189%, Training Loss: 0.2471%\n",
      "Epoch [44/300], Step [120/225], Training Accuracy: 91.0156%, Training Loss: 0.2469%\n",
      "Epoch [44/300], Step [121/225], Training Accuracy: 91.0382%, Training Loss: 0.2462%\n",
      "Epoch [44/300], Step [122/225], Training Accuracy: 91.0476%, Training Loss: 0.2455%\n",
      "Epoch [44/300], Step [123/225], Training Accuracy: 91.0188%, Training Loss: 0.2466%\n",
      "Epoch [44/300], Step [124/225], Training Accuracy: 91.0030%, Training Loss: 0.2466%\n",
      "Epoch [44/300], Step [125/225], Training Accuracy: 91.0125%, Training Loss: 0.2465%\n",
      "Epoch [44/300], Step [126/225], Training Accuracy: 90.9970%, Training Loss: 0.2471%\n",
      "Epoch [44/300], Step [127/225], Training Accuracy: 90.9818%, Training Loss: 0.2470%\n",
      "Epoch [44/300], Step [128/225], Training Accuracy: 90.9790%, Training Loss: 0.2473%\n",
      "Epoch [44/300], Step [129/225], Training Accuracy: 90.9399%, Training Loss: 0.2475%\n",
      "Epoch [44/300], Step [130/225], Training Accuracy: 90.9495%, Training Loss: 0.2472%\n",
      "Epoch [44/300], Step [131/225], Training Accuracy: 90.9351%, Training Loss: 0.2468%\n",
      "Epoch [44/300], Step [132/225], Training Accuracy: 90.9209%, Training Loss: 0.2471%\n",
      "Epoch [44/300], Step [133/225], Training Accuracy: 90.9657%, Training Loss: 0.2466%\n",
      "Epoch [44/300], Step [134/225], Training Accuracy: 90.9632%, Training Loss: 0.2468%\n",
      "Epoch [44/300], Step [135/225], Training Accuracy: 90.9954%, Training Loss: 0.2456%\n",
      "Epoch [44/300], Step [136/225], Training Accuracy: 90.9812%, Training Loss: 0.2460%\n",
      "Epoch [44/300], Step [137/225], Training Accuracy: 90.9557%, Training Loss: 0.2458%\n",
      "Epoch [44/300], Step [138/225], Training Accuracy: 90.9647%, Training Loss: 0.2451%\n",
      "Epoch [44/300], Step [139/225], Training Accuracy: 91.0072%, Training Loss: 0.2446%\n",
      "Epoch [44/300], Step [140/225], Training Accuracy: 91.0156%, Training Loss: 0.2442%\n",
      "Epoch [44/300], Step [141/225], Training Accuracy: 90.9574%, Training Loss: 0.2457%\n",
      "Epoch [44/300], Step [142/225], Training Accuracy: 90.9881%, Training Loss: 0.2450%\n",
      "Epoch [44/300], Step [143/225], Training Accuracy: 90.9419%, Training Loss: 0.2456%\n",
      "Epoch [44/300], Step [144/225], Training Accuracy: 90.9722%, Training Loss: 0.2450%\n",
      "Epoch [44/300], Step [145/225], Training Accuracy: 91.0129%, Training Loss: 0.2448%\n",
      "Epoch [44/300], Step [146/225], Training Accuracy: 90.9889%, Training Loss: 0.2454%\n",
      "Epoch [44/300], Step [147/225], Training Accuracy: 91.0077%, Training Loss: 0.2453%\n",
      "Epoch [44/300], Step [148/225], Training Accuracy: 91.0051%, Training Loss: 0.2453%\n",
      "Epoch [44/300], Step [149/225], Training Accuracy: 90.9606%, Training Loss: 0.2460%\n",
      "Epoch [44/300], Step [150/225], Training Accuracy: 90.9271%, Training Loss: 0.2464%\n",
      "Epoch [44/300], Step [151/225], Training Accuracy: 90.9147%, Training Loss: 0.2469%\n",
      "Epoch [44/300], Step [152/225], Training Accuracy: 90.9437%, Training Loss: 0.2471%\n",
      "Epoch [44/300], Step [153/225], Training Accuracy: 90.9722%, Training Loss: 0.2465%\n",
      "Epoch [44/300], Step [154/225], Training Accuracy: 90.9801%, Training Loss: 0.2462%\n",
      "Epoch [44/300], Step [155/225], Training Accuracy: 90.9879%, Training Loss: 0.2459%\n",
      "Epoch [44/300], Step [156/225], Training Accuracy: 91.0056%, Training Loss: 0.2456%\n",
      "Epoch [44/300], Step [157/225], Training Accuracy: 90.9932%, Training Loss: 0.2462%\n",
      "Epoch [44/300], Step [158/225], Training Accuracy: 91.0403%, Training Loss: 0.2453%\n",
      "Epoch [44/300], Step [159/225], Training Accuracy: 91.0181%, Training Loss: 0.2466%\n",
      "Epoch [44/300], Step [160/225], Training Accuracy: 91.0352%, Training Loss: 0.2463%\n",
      "Epoch [44/300], Step [161/225], Training Accuracy: 91.0423%, Training Loss: 0.2458%\n",
      "Epoch [44/300], Step [162/225], Training Accuracy: 91.0397%, Training Loss: 0.2460%\n",
      "Epoch [44/300], Step [163/225], Training Accuracy: 91.0468%, Training Loss: 0.2459%\n",
      "Epoch [44/300], Step [164/225], Training Accuracy: 91.0442%, Training Loss: 0.2459%\n",
      "Epoch [44/300], Step [165/225], Training Accuracy: 91.0701%, Training Loss: 0.2453%\n",
      "Epoch [44/300], Step [166/225], Training Accuracy: 91.0674%, Training Loss: 0.2457%\n",
      "Epoch [44/300], Step [167/225], Training Accuracy: 91.0741%, Training Loss: 0.2459%\n",
      "Epoch [44/300], Step [168/225], Training Accuracy: 91.0807%, Training Loss: 0.2454%\n",
      "Epoch [44/300], Step [169/225], Training Accuracy: 91.0780%, Training Loss: 0.2458%\n",
      "Epoch [44/300], Step [170/225], Training Accuracy: 91.0754%, Training Loss: 0.2457%\n",
      "Epoch [44/300], Step [171/225], Training Accuracy: 91.0819%, Training Loss: 0.2456%\n",
      "Epoch [44/300], Step [172/225], Training Accuracy: 91.0883%, Training Loss: 0.2456%\n",
      "Epoch [44/300], Step [173/225], Training Accuracy: 91.0856%, Training Loss: 0.2454%\n",
      "Epoch [44/300], Step [174/225], Training Accuracy: 91.0920%, Training Loss: 0.2452%\n",
      "Epoch [44/300], Step [175/225], Training Accuracy: 91.0804%, Training Loss: 0.2453%\n",
      "Epoch [44/300], Step [176/225], Training Accuracy: 91.0955%, Training Loss: 0.2451%\n",
      "Epoch [44/300], Step [177/225], Training Accuracy: 91.1194%, Training Loss: 0.2446%\n",
      "Epoch [44/300], Step [178/225], Training Accuracy: 91.0902%, Training Loss: 0.2450%\n",
      "Epoch [44/300], Step [179/225], Training Accuracy: 91.0876%, Training Loss: 0.2452%\n",
      "Epoch [44/300], Step [180/225], Training Accuracy: 91.0590%, Training Loss: 0.2454%\n",
      "Epoch [44/300], Step [181/225], Training Accuracy: 91.0480%, Training Loss: 0.2455%\n",
      "Epoch [44/300], Step [182/225], Training Accuracy: 91.0285%, Training Loss: 0.2460%\n",
      "Epoch [44/300], Step [183/225], Training Accuracy: 91.0605%, Training Loss: 0.2454%\n",
      "Epoch [44/300], Step [184/225], Training Accuracy: 91.0751%, Training Loss: 0.2455%\n",
      "Epoch [44/300], Step [185/225], Training Accuracy: 91.0642%, Training Loss: 0.2454%\n",
      "Epoch [44/300], Step [186/225], Training Accuracy: 91.0786%, Training Loss: 0.2448%\n",
      "Epoch [44/300], Step [187/225], Training Accuracy: 91.0929%, Training Loss: 0.2445%\n",
      "Epoch [44/300], Step [188/225], Training Accuracy: 91.0987%, Training Loss: 0.2444%\n",
      "Epoch [44/300], Step [189/225], Training Accuracy: 91.1128%, Training Loss: 0.2440%\n",
      "Epoch [44/300], Step [190/225], Training Accuracy: 91.0938%, Training Loss: 0.2451%\n",
      "Epoch [44/300], Step [191/225], Training Accuracy: 91.1240%, Training Loss: 0.2445%\n",
      "Epoch [44/300], Step [192/225], Training Accuracy: 91.1051%, Training Loss: 0.2447%\n",
      "Epoch [44/300], Step [193/225], Training Accuracy: 91.0541%, Training Loss: 0.2458%\n",
      "Epoch [44/300], Step [194/225], Training Accuracy: 91.0599%, Training Loss: 0.2458%\n",
      "Epoch [44/300], Step [195/225], Training Accuracy: 91.0817%, Training Loss: 0.2452%\n",
      "Epoch [44/300], Step [196/225], Training Accuracy: 91.0714%, Training Loss: 0.2452%\n",
      "Epoch [44/300], Step [197/225], Training Accuracy: 91.0533%, Training Loss: 0.2456%\n",
      "Epoch [44/300], Step [198/225], Training Accuracy: 91.0511%, Training Loss: 0.2460%\n",
      "Epoch [44/300], Step [199/225], Training Accuracy: 91.0568%, Training Loss: 0.2457%\n",
      "Epoch [44/300], Step [200/225], Training Accuracy: 91.0859%, Training Loss: 0.2454%\n",
      "Epoch [44/300], Step [201/225], Training Accuracy: 91.0759%, Training Loss: 0.2456%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/300], Step [202/225], Training Accuracy: 91.0736%, Training Loss: 0.2455%\n",
      "Epoch [44/300], Step [203/225], Training Accuracy: 91.0868%, Training Loss: 0.2459%\n",
      "Epoch [44/300], Step [204/225], Training Accuracy: 91.0692%, Training Loss: 0.2467%\n",
      "Epoch [44/300], Step [205/225], Training Accuracy: 91.0671%, Training Loss: 0.2473%\n",
      "Epoch [44/300], Step [206/225], Training Accuracy: 91.0573%, Training Loss: 0.2474%\n",
      "Epoch [44/300], Step [207/225], Training Accuracy: 91.0704%, Training Loss: 0.2469%\n",
      "Epoch [44/300], Step [208/225], Training Accuracy: 91.0907%, Training Loss: 0.2466%\n",
      "Epoch [44/300], Step [209/225], Training Accuracy: 91.0960%, Training Loss: 0.2468%\n",
      "Epoch [44/300], Step [210/225], Training Accuracy: 91.0863%, Training Loss: 0.2466%\n",
      "Epoch [44/300], Step [211/225], Training Accuracy: 91.0767%, Training Loss: 0.2469%\n",
      "Epoch [44/300], Step [212/225], Training Accuracy: 91.0746%, Training Loss: 0.2469%\n",
      "Epoch [44/300], Step [213/225], Training Accuracy: 91.0651%, Training Loss: 0.2466%\n",
      "Epoch [44/300], Step [214/225], Training Accuracy: 91.0631%, Training Loss: 0.2467%\n",
      "Epoch [44/300], Step [215/225], Training Accuracy: 91.0683%, Training Loss: 0.2468%\n",
      "Epoch [44/300], Step [216/225], Training Accuracy: 91.0735%, Training Loss: 0.2473%\n",
      "Epoch [44/300], Step [217/225], Training Accuracy: 91.0714%, Training Loss: 0.2470%\n",
      "Epoch [44/300], Step [218/225], Training Accuracy: 91.0765%, Training Loss: 0.2471%\n",
      "Epoch [44/300], Step [219/225], Training Accuracy: 91.0459%, Training Loss: 0.2474%\n",
      "Epoch [44/300], Step [220/225], Training Accuracy: 91.0653%, Training Loss: 0.2471%\n",
      "Epoch [44/300], Step [221/225], Training Accuracy: 91.0492%, Training Loss: 0.2474%\n",
      "Epoch [44/300], Step [222/225], Training Accuracy: 91.0543%, Training Loss: 0.2478%\n",
      "Epoch [44/300], Step [223/225], Training Accuracy: 91.0524%, Training Loss: 0.2477%\n",
      "Epoch [44/300], Step [224/225], Training Accuracy: 91.0645%, Training Loss: 0.2477%\n",
      "Epoch [44/300], Step [225/225], Training Accuracy: 91.0645%, Training Loss: 0.2474%\n",
      "Epoch [45/300], Step [1/225], Training Accuracy: 90.6250%, Training Loss: 0.1940%\n",
      "Epoch [45/300], Step [2/225], Training Accuracy: 91.4062%, Training Loss: 0.1667%\n",
      "Epoch [45/300], Step [3/225], Training Accuracy: 91.1458%, Training Loss: 0.2021%\n",
      "Epoch [45/300], Step [4/225], Training Accuracy: 92.1875%, Training Loss: 0.1835%\n",
      "Epoch [45/300], Step [5/225], Training Accuracy: 92.5000%, Training Loss: 0.1796%\n",
      "Epoch [45/300], Step [6/225], Training Accuracy: 92.1875%, Training Loss: 0.2061%\n",
      "Epoch [45/300], Step [7/225], Training Accuracy: 91.9643%, Training Loss: 0.2148%\n",
      "Epoch [45/300], Step [8/225], Training Accuracy: 92.1875%, Training Loss: 0.2182%\n",
      "Epoch [45/300], Step [9/225], Training Accuracy: 92.1875%, Training Loss: 0.2185%\n",
      "Epoch [45/300], Step [10/225], Training Accuracy: 92.3438%, Training Loss: 0.2191%\n",
      "Epoch [45/300], Step [11/225], Training Accuracy: 92.1875%, Training Loss: 0.2239%\n",
      "Epoch [45/300], Step [12/225], Training Accuracy: 92.1875%, Training Loss: 0.2303%\n",
      "Epoch [45/300], Step [13/225], Training Accuracy: 92.4279%, Training Loss: 0.2270%\n",
      "Epoch [45/300], Step [14/225], Training Accuracy: 92.6339%, Training Loss: 0.2257%\n",
      "Epoch [45/300], Step [15/225], Training Accuracy: 92.3958%, Training Loss: 0.2292%\n",
      "Epoch [45/300], Step [16/225], Training Accuracy: 92.4805%, Training Loss: 0.2266%\n",
      "Epoch [45/300], Step [17/225], Training Accuracy: 92.5551%, Training Loss: 0.2252%\n",
      "Epoch [45/300], Step [18/225], Training Accuracy: 92.2743%, Training Loss: 0.2269%\n",
      "Epoch [45/300], Step [19/225], Training Accuracy: 92.1875%, Training Loss: 0.2273%\n",
      "Epoch [45/300], Step [20/225], Training Accuracy: 92.1094%, Training Loss: 0.2279%\n",
      "Epoch [45/300], Step [21/225], Training Accuracy: 92.0387%, Training Loss: 0.2272%\n",
      "Epoch [45/300], Step [22/225], Training Accuracy: 91.9744%, Training Loss: 0.2305%\n",
      "Epoch [45/300], Step [23/225], Training Accuracy: 91.6440%, Training Loss: 0.2363%\n",
      "Epoch [45/300], Step [24/225], Training Accuracy: 91.3411%, Training Loss: 0.2388%\n",
      "Epoch [45/300], Step [25/225], Training Accuracy: 91.3125%, Training Loss: 0.2362%\n",
      "Epoch [45/300], Step [26/225], Training Accuracy: 91.1659%, Training Loss: 0.2407%\n",
      "Epoch [45/300], Step [27/225], Training Accuracy: 91.3773%, Training Loss: 0.2376%\n",
      "Epoch [45/300], Step [28/225], Training Accuracy: 91.4621%, Training Loss: 0.2353%\n",
      "Epoch [45/300], Step [29/225], Training Accuracy: 91.5409%, Training Loss: 0.2344%\n",
      "Epoch [45/300], Step [30/225], Training Accuracy: 91.6667%, Training Loss: 0.2330%\n",
      "Epoch [45/300], Step [31/225], Training Accuracy: 91.5323%, Training Loss: 0.2342%\n",
      "Epoch [45/300], Step [32/225], Training Accuracy: 91.5527%, Training Loss: 0.2315%\n",
      "Epoch [45/300], Step [33/225], Training Accuracy: 91.4773%, Training Loss: 0.2340%\n",
      "Epoch [45/300], Step [34/225], Training Accuracy: 91.5901%, Training Loss: 0.2310%\n",
      "Epoch [45/300], Step [35/225], Training Accuracy: 91.5179%, Training Loss: 0.2311%\n",
      "Epoch [45/300], Step [36/225], Training Accuracy: 91.6667%, Training Loss: 0.2292%\n",
      "Epoch [45/300], Step [37/225], Training Accuracy: 91.6807%, Training Loss: 0.2288%\n",
      "Epoch [45/300], Step [38/225], Training Accuracy: 91.6118%, Training Loss: 0.2340%\n",
      "Epoch [45/300], Step [39/225], Training Accuracy: 91.5064%, Training Loss: 0.2357%\n",
      "Epoch [45/300], Step [40/225], Training Accuracy: 91.4062%, Training Loss: 0.2357%\n",
      "Epoch [45/300], Step [41/225], Training Accuracy: 91.4253%, Training Loss: 0.2373%\n",
      "Epoch [45/300], Step [42/225], Training Accuracy: 91.5551%, Training Loss: 0.2347%\n",
      "Epoch [45/300], Step [43/225], Training Accuracy: 91.5698%, Training Loss: 0.2333%\n",
      "Epoch [45/300], Step [44/225], Training Accuracy: 91.6548%, Training Loss: 0.2310%\n",
      "Epoch [45/300], Step [45/225], Training Accuracy: 91.7708%, Training Loss: 0.2292%\n",
      "Epoch [45/300], Step [46/225], Training Accuracy: 91.8139%, Training Loss: 0.2282%\n",
      "Epoch [45/300], Step [47/225], Training Accuracy: 91.7221%, Training Loss: 0.2299%\n",
      "Epoch [45/300], Step [48/225], Training Accuracy: 91.6992%, Training Loss: 0.2298%\n",
      "Epoch [45/300], Step [49/225], Training Accuracy: 91.7092%, Training Loss: 0.2292%\n",
      "Epoch [45/300], Step [50/225], Training Accuracy: 91.6250%, Training Loss: 0.2302%\n",
      "Epoch [45/300], Step [51/225], Training Accuracy: 91.6054%, Training Loss: 0.2292%\n",
      "Epoch [45/300], Step [52/225], Training Accuracy: 91.7067%, Training Loss: 0.2271%\n",
      "Epoch [45/300], Step [53/225], Training Accuracy: 91.6568%, Training Loss: 0.2288%\n",
      "Epoch [45/300], Step [54/225], Training Accuracy: 91.6956%, Training Loss: 0.2286%\n",
      "Epoch [45/300], Step [55/225], Training Accuracy: 91.7614%, Training Loss: 0.2280%\n",
      "Epoch [45/300], Step [56/225], Training Accuracy: 91.7132%, Training Loss: 0.2286%\n",
      "Epoch [45/300], Step [57/225], Training Accuracy: 91.6393%, Training Loss: 0.2300%\n",
      "Epoch [45/300], Step [58/225], Training Accuracy: 91.6218%, Training Loss: 0.2307%\n",
      "Epoch [45/300], Step [59/225], Training Accuracy: 91.5784%, Training Loss: 0.2330%\n",
      "Epoch [45/300], Step [60/225], Training Accuracy: 91.5885%, Training Loss: 0.2327%\n",
      "Epoch [45/300], Step [61/225], Training Accuracy: 91.6240%, Training Loss: 0.2316%\n",
      "Epoch [45/300], Step [62/225], Training Accuracy: 91.6331%, Training Loss: 0.2321%\n",
      "Epoch [45/300], Step [63/225], Training Accuracy: 91.6419%, Training Loss: 0.2319%\n",
      "Epoch [45/300], Step [64/225], Training Accuracy: 91.5771%, Training Loss: 0.2329%\n",
      "Epoch [45/300], Step [65/225], Training Accuracy: 91.6106%, Training Loss: 0.2321%\n",
      "Epoch [45/300], Step [66/225], Training Accuracy: 91.6193%, Training Loss: 0.2328%\n",
      "Epoch [45/300], Step [67/225], Training Accuracy: 91.6278%, Training Loss: 0.2322%\n",
      "Epoch [45/300], Step [68/225], Training Accuracy: 91.6131%, Training Loss: 0.2327%\n",
      "Epoch [45/300], Step [69/225], Training Accuracy: 91.5534%, Training Loss: 0.2335%\n",
      "Epoch [45/300], Step [70/225], Training Accuracy: 91.5402%, Training Loss: 0.2337%\n",
      "Epoch [45/300], Step [71/225], Training Accuracy: 91.5273%, Training Loss: 0.2331%\n",
      "Epoch [45/300], Step [72/225], Training Accuracy: 91.5799%, Training Loss: 0.2320%\n",
      "Epoch [45/300], Step [73/225], Training Accuracy: 91.5668%, Training Loss: 0.2327%\n",
      "Epoch [45/300], Step [74/225], Training Accuracy: 91.4907%, Training Loss: 0.2356%\n",
      "Epoch [45/300], Step [75/225], Training Accuracy: 91.4792%, Training Loss: 0.2371%\n",
      "Epoch [45/300], Step [76/225], Training Accuracy: 91.4885%, Training Loss: 0.2363%\n",
      "Epoch [45/300], Step [77/225], Training Accuracy: 91.4773%, Training Loss: 0.2360%\n",
      "Epoch [45/300], Step [78/225], Training Accuracy: 91.4663%, Training Loss: 0.2368%\n",
      "Epoch [45/300], Step [79/225], Training Accuracy: 91.4755%, Training Loss: 0.2373%\n",
      "Epoch [45/300], Step [80/225], Training Accuracy: 91.4258%, Training Loss: 0.2389%\n",
      "Epoch [45/300], Step [81/225], Training Accuracy: 91.4738%, Training Loss: 0.2384%\n",
      "Epoch [45/300], Step [82/225], Training Accuracy: 91.5015%, Training Loss: 0.2381%\n",
      "Epoch [45/300], Step [83/225], Training Accuracy: 91.5663%, Training Loss: 0.2373%\n",
      "Epoch [45/300], Step [84/225], Training Accuracy: 91.6109%, Training Loss: 0.2366%\n",
      "Epoch [45/300], Step [85/225], Training Accuracy: 91.5993%, Training Loss: 0.2372%\n",
      "Epoch [45/300], Step [86/225], Training Accuracy: 91.5698%, Training Loss: 0.2375%\n",
      "Epoch [45/300], Step [87/225], Training Accuracy: 91.5589%, Training Loss: 0.2380%\n",
      "Epoch [45/300], Step [88/225], Training Accuracy: 91.5305%, Training Loss: 0.2391%\n",
      "Epoch [45/300], Step [89/225], Training Accuracy: 91.5730%, Training Loss: 0.2388%\n",
      "Epoch [45/300], Step [90/225], Training Accuracy: 91.5972%, Training Loss: 0.2384%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/300], Step [91/225], Training Accuracy: 91.6209%, Training Loss: 0.2375%\n",
      "Epoch [45/300], Step [92/225], Training Accuracy: 91.6780%, Training Loss: 0.2362%\n",
      "Epoch [45/300], Step [93/225], Training Accuracy: 91.6331%, Training Loss: 0.2365%\n",
      "Epoch [45/300], Step [94/225], Training Accuracy: 91.6556%, Training Loss: 0.2359%\n",
      "Epoch [45/300], Step [95/225], Training Accuracy: 91.5954%, Training Loss: 0.2370%\n",
      "Epoch [45/300], Step [96/225], Training Accuracy: 91.5853%, Training Loss: 0.2371%\n",
      "Epoch [45/300], Step [97/225], Training Accuracy: 91.5915%, Training Loss: 0.2377%\n",
      "Epoch [45/300], Step [98/225], Training Accuracy: 91.5976%, Training Loss: 0.2374%\n",
      "Epoch [45/300], Step [99/225], Training Accuracy: 91.6351%, Training Loss: 0.2371%\n",
      "Epoch [45/300], Step [100/225], Training Accuracy: 91.6406%, Training Loss: 0.2368%\n",
      "Epoch [45/300], Step [101/225], Training Accuracy: 91.6925%, Training Loss: 0.2360%\n",
      "Epoch [45/300], Step [102/225], Training Accuracy: 91.6513%, Training Loss: 0.2362%\n",
      "Epoch [45/300], Step [103/225], Training Accuracy: 91.6110%, Training Loss: 0.2364%\n",
      "Epoch [45/300], Step [104/225], Training Accuracy: 91.6316%, Training Loss: 0.2359%\n",
      "Epoch [45/300], Step [105/225], Training Accuracy: 91.6964%, Training Loss: 0.2352%\n",
      "Epoch [45/300], Step [106/225], Training Accuracy: 91.7453%, Training Loss: 0.2343%\n",
      "Epoch [45/300], Step [107/225], Training Accuracy: 91.7348%, Training Loss: 0.2338%\n",
      "Epoch [45/300], Step [108/225], Training Accuracy: 91.7245%, Training Loss: 0.2344%\n",
      "Epoch [45/300], Step [109/225], Training Accuracy: 91.7144%, Training Loss: 0.2343%\n",
      "Epoch [45/300], Step [110/225], Training Accuracy: 91.7045%, Training Loss: 0.2339%\n",
      "Epoch [45/300], Step [111/225], Training Accuracy: 91.7089%, Training Loss: 0.2334%\n",
      "Epoch [45/300], Step [112/225], Training Accuracy: 91.6853%, Training Loss: 0.2338%\n",
      "Epoch [45/300], Step [113/225], Training Accuracy: 91.7174%, Training Loss: 0.2334%\n",
      "Epoch [45/300], Step [114/225], Training Accuracy: 91.7626%, Training Loss: 0.2325%\n",
      "Epoch [45/300], Step [115/225], Training Accuracy: 91.7663%, Training Loss: 0.2325%\n",
      "Epoch [45/300], Step [116/225], Training Accuracy: 91.7026%, Training Loss: 0.2345%\n",
      "Epoch [45/300], Step [117/225], Training Accuracy: 91.7334%, Training Loss: 0.2337%\n",
      "Epoch [45/300], Step [118/225], Training Accuracy: 91.6843%, Training Loss: 0.2346%\n",
      "Epoch [45/300], Step [119/225], Training Accuracy: 91.7148%, Training Loss: 0.2340%\n",
      "Epoch [45/300], Step [120/225], Training Accuracy: 91.7188%, Training Loss: 0.2335%\n",
      "Epoch [45/300], Step [121/225], Training Accuracy: 91.6968%, Training Loss: 0.2331%\n",
      "Epoch [45/300], Step [122/225], Training Accuracy: 91.7008%, Training Loss: 0.2329%\n",
      "Epoch [45/300], Step [123/225], Training Accuracy: 91.7302%, Training Loss: 0.2324%\n",
      "Epoch [45/300], Step [124/225], Training Accuracy: 91.7339%, Training Loss: 0.2325%\n",
      "Epoch [45/300], Step [125/225], Training Accuracy: 91.7000%, Training Loss: 0.2332%\n",
      "Epoch [45/300], Step [126/225], Training Accuracy: 91.6915%, Training Loss: 0.2336%\n",
      "Epoch [45/300], Step [127/225], Training Accuracy: 91.7077%, Training Loss: 0.2339%\n",
      "Epoch [45/300], Step [128/225], Training Accuracy: 91.6138%, Training Loss: 0.2360%\n",
      "Epoch [45/300], Step [129/225], Training Accuracy: 91.5940%, Training Loss: 0.2361%\n",
      "Epoch [45/300], Step [130/225], Training Accuracy: 91.5986%, Training Loss: 0.2358%\n",
      "Epoch [45/300], Step [131/225], Training Accuracy: 91.5911%, Training Loss: 0.2357%\n",
      "Epoch [45/300], Step [132/225], Training Accuracy: 91.5720%, Training Loss: 0.2358%\n",
      "Epoch [45/300], Step [133/225], Training Accuracy: 91.5766%, Training Loss: 0.2355%\n",
      "Epoch [45/300], Step [134/225], Training Accuracy: 91.6045%, Training Loss: 0.2355%\n",
      "Epoch [45/300], Step [135/225], Training Accuracy: 91.6551%, Training Loss: 0.2345%\n",
      "Epoch [45/300], Step [136/225], Training Accuracy: 91.6590%, Training Loss: 0.2348%\n",
      "Epoch [45/300], Step [137/225], Training Accuracy: 91.6515%, Training Loss: 0.2352%\n",
      "Epoch [45/300], Step [138/225], Training Accuracy: 91.6440%, Training Loss: 0.2351%\n",
      "Epoch [45/300], Step [139/225], Training Accuracy: 91.6479%, Training Loss: 0.2350%\n",
      "Epoch [45/300], Step [140/225], Training Accuracy: 91.6629%, Training Loss: 0.2351%\n",
      "Epoch [45/300], Step [141/225], Training Accuracy: 91.6667%, Training Loss: 0.2352%\n",
      "Epoch [45/300], Step [142/225], Training Accuracy: 91.6703%, Training Loss: 0.2349%\n",
      "Epoch [45/300], Step [143/225], Training Accuracy: 91.6740%, Training Loss: 0.2350%\n",
      "Epoch [45/300], Step [144/225], Training Accuracy: 91.6450%, Training Loss: 0.2350%\n",
      "Epoch [45/300], Step [145/225], Training Accuracy: 91.6379%, Training Loss: 0.2349%\n",
      "Epoch [45/300], Step [146/225], Training Accuracy: 91.6845%, Training Loss: 0.2339%\n",
      "Epoch [45/300], Step [147/225], Training Accuracy: 91.6667%, Training Loss: 0.2340%\n",
      "Epoch [45/300], Step [148/225], Training Accuracy: 91.6280%, Training Loss: 0.2340%\n",
      "Epoch [45/300], Step [149/225], Training Accuracy: 91.5793%, Training Loss: 0.2346%\n",
      "Epoch [45/300], Step [150/225], Training Accuracy: 91.6146%, Training Loss: 0.2338%\n",
      "Epoch [45/300], Step [151/225], Training Accuracy: 91.6184%, Training Loss: 0.2340%\n",
      "Epoch [45/300], Step [152/225], Training Accuracy: 91.6016%, Training Loss: 0.2340%\n",
      "Epoch [45/300], Step [153/225], Training Accuracy: 91.6156%, Training Loss: 0.2337%\n",
      "Epoch [45/300], Step [154/225], Training Accuracy: 91.6193%, Training Loss: 0.2334%\n",
      "Epoch [45/300], Step [155/225], Training Accuracy: 91.5927%, Training Loss: 0.2335%\n",
      "Epoch [45/300], Step [156/225], Training Accuracy: 91.5966%, Training Loss: 0.2337%\n",
      "Epoch [45/300], Step [157/225], Training Accuracy: 91.5804%, Training Loss: 0.2342%\n",
      "Epoch [45/300], Step [158/225], Training Accuracy: 91.6337%, Training Loss: 0.2331%\n",
      "Epoch [45/300], Step [159/225], Training Accuracy: 91.6175%, Training Loss: 0.2332%\n",
      "Epoch [45/300], Step [160/225], Training Accuracy: 91.6211%, Training Loss: 0.2331%\n",
      "Epoch [45/300], Step [161/225], Training Accuracy: 91.6440%, Training Loss: 0.2324%\n",
      "Epoch [45/300], Step [162/225], Training Accuracy: 91.6184%, Training Loss: 0.2324%\n",
      "Epoch [45/300], Step [163/225], Training Accuracy: 91.6411%, Training Loss: 0.2323%\n",
      "Epoch [45/300], Step [164/225], Training Accuracy: 91.6254%, Training Loss: 0.2326%\n",
      "Epoch [45/300], Step [165/225], Training Accuracy: 91.6004%, Training Loss: 0.2325%\n",
      "Epoch [45/300], Step [166/225], Training Accuracy: 91.5663%, Training Loss: 0.2330%\n",
      "Epoch [45/300], Step [167/225], Training Accuracy: 91.5793%, Training Loss: 0.2329%\n",
      "Epoch [45/300], Step [168/225], Training Accuracy: 91.5737%, Training Loss: 0.2328%\n",
      "Epoch [45/300], Step [169/225], Training Accuracy: 91.5865%, Training Loss: 0.2324%\n",
      "Epoch [45/300], Step [170/225], Training Accuracy: 91.5901%, Training Loss: 0.2324%\n",
      "Epoch [45/300], Step [171/225], Training Accuracy: 91.5662%, Training Loss: 0.2326%\n",
      "Epoch [45/300], Step [172/225], Training Accuracy: 91.5698%, Training Loss: 0.2323%\n",
      "Epoch [45/300], Step [173/225], Training Accuracy: 91.5372%, Training Loss: 0.2333%\n",
      "Epoch [45/300], Step [174/225], Training Accuracy: 91.5409%, Training Loss: 0.2332%\n",
      "Epoch [45/300], Step [175/225], Training Accuracy: 91.5625%, Training Loss: 0.2326%\n",
      "Epoch [45/300], Step [176/225], Training Accuracy: 91.5217%, Training Loss: 0.2333%\n",
      "Epoch [45/300], Step [177/225], Training Accuracy: 91.5431%, Training Loss: 0.2326%\n",
      "Epoch [45/300], Step [178/225], Training Accuracy: 91.5291%, Training Loss: 0.2330%\n",
      "Epoch [45/300], Step [179/225], Training Accuracy: 91.5416%, Training Loss: 0.2328%\n",
      "Epoch [45/300], Step [180/225], Training Accuracy: 91.5451%, Training Loss: 0.2327%\n",
      "Epoch [45/300], Step [181/225], Training Accuracy: 91.5314%, Training Loss: 0.2325%\n",
      "Epoch [45/300], Step [182/225], Training Accuracy: 91.5436%, Training Loss: 0.2324%\n",
      "Epoch [45/300], Step [183/225], Training Accuracy: 91.5557%, Training Loss: 0.2319%\n",
      "Epoch [45/300], Step [184/225], Training Accuracy: 91.5082%, Training Loss: 0.2326%\n",
      "Epoch [45/300], Step [185/225], Training Accuracy: 91.5034%, Training Loss: 0.2331%\n",
      "Epoch [45/300], Step [186/225], Training Accuracy: 91.5071%, Training Loss: 0.2330%\n",
      "Epoch [45/300], Step [187/225], Training Accuracy: 91.5107%, Training Loss: 0.2326%\n",
      "Epoch [45/300], Step [188/225], Training Accuracy: 91.5226%, Training Loss: 0.2323%\n",
      "Epoch [45/300], Step [189/225], Training Accuracy: 91.5427%, Training Loss: 0.2322%\n",
      "Epoch [45/300], Step [190/225], Training Accuracy: 91.5296%, Training Loss: 0.2323%\n",
      "Epoch [45/300], Step [191/225], Training Accuracy: 91.5412%, Training Loss: 0.2320%\n",
      "Epoch [45/300], Step [192/225], Training Accuracy: 91.5365%, Training Loss: 0.2320%\n",
      "Epoch [45/300], Step [193/225], Training Accuracy: 91.5074%, Training Loss: 0.2329%\n",
      "Epoch [45/300], Step [194/225], Training Accuracy: 91.5190%, Training Loss: 0.2326%\n",
      "Epoch [45/300], Step [195/225], Training Accuracy: 91.5465%, Training Loss: 0.2322%\n",
      "Epoch [45/300], Step [196/225], Training Accuracy: 91.5657%, Training Loss: 0.2319%\n",
      "Epoch [45/300], Step [197/225], Training Accuracy: 91.5688%, Training Loss: 0.2319%\n",
      "Epoch [45/300], Step [198/225], Training Accuracy: 91.5404%, Training Loss: 0.2325%\n",
      "Epoch [45/300], Step [199/225], Training Accuracy: 91.5044%, Training Loss: 0.2331%\n",
      "Epoch [45/300], Step [200/225], Training Accuracy: 91.5156%, Training Loss: 0.2329%\n",
      "Epoch [45/300], Step [201/225], Training Accuracy: 91.5112%, Training Loss: 0.2327%\n",
      "Epoch [45/300], Step [202/225], Training Accuracy: 91.5145%, Training Loss: 0.2325%\n",
      "Epoch [45/300], Step [203/225], Training Accuracy: 91.4948%, Training Loss: 0.2327%\n",
      "Epoch [45/300], Step [204/225], Training Accuracy: 91.4905%, Training Loss: 0.2325%\n",
      "Epoch [45/300], Step [205/225], Training Accuracy: 91.4787%, Training Loss: 0.2326%\n",
      "Epoch [45/300], Step [206/225], Training Accuracy: 91.4745%, Training Loss: 0.2328%\n",
      "Epoch [45/300], Step [207/225], Training Accuracy: 91.4704%, Training Loss: 0.2327%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/300], Step [208/225], Training Accuracy: 91.4814%, Training Loss: 0.2329%\n",
      "Epoch [45/300], Step [209/225], Training Accuracy: 91.4922%, Training Loss: 0.2327%\n",
      "Epoch [45/300], Step [210/225], Training Accuracy: 91.4807%, Training Loss: 0.2328%\n",
      "Epoch [45/300], Step [211/225], Training Accuracy: 91.4692%, Training Loss: 0.2328%\n",
      "Epoch [45/300], Step [212/225], Training Accuracy: 91.4873%, Training Loss: 0.2323%\n",
      "Epoch [45/300], Step [213/225], Training Accuracy: 91.4979%, Training Loss: 0.2322%\n",
      "Epoch [45/300], Step [214/225], Training Accuracy: 91.4720%, Training Loss: 0.2325%\n",
      "Epoch [45/300], Step [215/225], Training Accuracy: 91.4826%, Training Loss: 0.2323%\n",
      "Epoch [45/300], Step [216/225], Training Accuracy: 91.4424%, Training Loss: 0.2326%\n",
      "Epoch [45/300], Step [217/225], Training Accuracy: 91.4459%, Training Loss: 0.2326%\n",
      "Epoch [45/300], Step [218/225], Training Accuracy: 91.4636%, Training Loss: 0.2322%\n",
      "Epoch [45/300], Step [219/225], Training Accuracy: 91.4598%, Training Loss: 0.2323%\n",
      "Epoch [45/300], Step [220/225], Training Accuracy: 91.4773%, Training Loss: 0.2321%\n",
      "Epoch [45/300], Step [221/225], Training Accuracy: 91.4522%, Training Loss: 0.2325%\n",
      "Epoch [45/300], Step [222/225], Training Accuracy: 91.4344%, Training Loss: 0.2329%\n",
      "Epoch [45/300], Step [223/225], Training Accuracy: 91.4308%, Training Loss: 0.2329%\n",
      "Epoch [45/300], Step [224/225], Training Accuracy: 91.4481%, Training Loss: 0.2328%\n",
      "Epoch [45/300], Step [225/225], Training Accuracy: 91.4258%, Training Loss: 0.2333%\n",
      "Epoch [46/300], Step [1/225], Training Accuracy: 92.1875%, Training Loss: 0.1942%\n",
      "Epoch [46/300], Step [2/225], Training Accuracy: 93.7500%, Training Loss: 0.1709%\n",
      "Epoch [46/300], Step [3/225], Training Accuracy: 91.6667%, Training Loss: 0.2100%\n",
      "Epoch [46/300], Step [4/225], Training Accuracy: 93.3594%, Training Loss: 0.1855%\n",
      "Epoch [46/300], Step [5/225], Training Accuracy: 94.0625%, Training Loss: 0.1751%\n",
      "Epoch [46/300], Step [6/225], Training Accuracy: 93.2292%, Training Loss: 0.1972%\n",
      "Epoch [46/300], Step [7/225], Training Accuracy: 92.4107%, Training Loss: 0.2114%\n",
      "Epoch [46/300], Step [8/225], Training Accuracy: 92.7734%, Training Loss: 0.1972%\n",
      "Epoch [46/300], Step [9/225], Training Accuracy: 92.7083%, Training Loss: 0.1964%\n",
      "Epoch [46/300], Step [10/225], Training Accuracy: 92.1875%, Training Loss: 0.2100%\n",
      "Epoch [46/300], Step [11/225], Training Accuracy: 92.0455%, Training Loss: 0.2161%\n",
      "Epoch [46/300], Step [12/225], Training Accuracy: 92.3177%, Training Loss: 0.2100%\n",
      "Epoch [46/300], Step [13/225], Training Accuracy: 92.0673%, Training Loss: 0.2170%\n",
      "Epoch [46/300], Step [14/225], Training Accuracy: 91.7411%, Training Loss: 0.2215%\n",
      "Epoch [46/300], Step [15/225], Training Accuracy: 91.9792%, Training Loss: 0.2163%\n",
      "Epoch [46/300], Step [16/225], Training Accuracy: 91.6016%, Training Loss: 0.2241%\n",
      "Epoch [46/300], Step [17/225], Training Accuracy: 91.6360%, Training Loss: 0.2250%\n",
      "Epoch [46/300], Step [18/225], Training Accuracy: 91.6667%, Training Loss: 0.2264%\n",
      "Epoch [46/300], Step [19/225], Training Accuracy: 91.6941%, Training Loss: 0.2253%\n",
      "Epoch [46/300], Step [20/225], Training Accuracy: 91.5625%, Training Loss: 0.2305%\n",
      "Epoch [46/300], Step [21/225], Training Accuracy: 91.5179%, Training Loss: 0.2336%\n",
      "Epoch [46/300], Step [22/225], Training Accuracy: 91.4062%, Training Loss: 0.2339%\n",
      "Epoch [46/300], Step [23/225], Training Accuracy: 91.5761%, Training Loss: 0.2314%\n",
      "Epoch [46/300], Step [24/225], Training Accuracy: 91.4714%, Training Loss: 0.2315%\n",
      "Epoch [46/300], Step [25/225], Training Accuracy: 91.7500%, Training Loss: 0.2269%\n",
      "Epoch [46/300], Step [26/225], Training Accuracy: 91.8870%, Training Loss: 0.2256%\n",
      "Epoch [46/300], Step [27/225], Training Accuracy: 91.7245%, Training Loss: 0.2296%\n",
      "Epoch [46/300], Step [28/225], Training Accuracy: 91.8527%, Training Loss: 0.2255%\n",
      "Epoch [46/300], Step [29/225], Training Accuracy: 91.8642%, Training Loss: 0.2253%\n",
      "Epoch [46/300], Step [30/225], Training Accuracy: 91.9271%, Training Loss: 0.2223%\n",
      "Epoch [46/300], Step [31/225], Training Accuracy: 91.7843%, Training Loss: 0.2237%\n",
      "Epoch [46/300], Step [32/225], Training Accuracy: 91.6992%, Training Loss: 0.2227%\n",
      "Epoch [46/300], Step [33/225], Training Accuracy: 91.6667%, Training Loss: 0.2243%\n",
      "Epoch [46/300], Step [34/225], Training Accuracy: 91.6360%, Training Loss: 0.2246%\n",
      "Epoch [46/300], Step [35/225], Training Accuracy: 91.4732%, Training Loss: 0.2278%\n",
      "Epoch [46/300], Step [36/225], Training Accuracy: 91.5365%, Training Loss: 0.2289%\n",
      "Epoch [46/300], Step [37/225], Training Accuracy: 91.5541%, Training Loss: 0.2270%\n",
      "Epoch [46/300], Step [38/225], Training Accuracy: 91.4885%, Training Loss: 0.2282%\n",
      "Epoch [46/300], Step [39/225], Training Accuracy: 91.3862%, Training Loss: 0.2296%\n",
      "Epoch [46/300], Step [40/225], Training Accuracy: 91.4453%, Training Loss: 0.2294%\n",
      "Epoch [46/300], Step [41/225], Training Accuracy: 91.3872%, Training Loss: 0.2303%\n",
      "Epoch [46/300], Step [42/225], Training Accuracy: 91.3318%, Training Loss: 0.2305%\n",
      "Epoch [46/300], Step [43/225], Training Accuracy: 91.4608%, Training Loss: 0.2289%\n",
      "Epoch [46/300], Step [44/225], Training Accuracy: 91.5128%, Training Loss: 0.2273%\n",
      "Epoch [46/300], Step [45/225], Training Accuracy: 91.4583%, Training Loss: 0.2284%\n",
      "Epoch [46/300], Step [46/225], Training Accuracy: 91.5421%, Training Loss: 0.2265%\n",
      "Epoch [46/300], Step [47/225], Training Accuracy: 91.5891%, Training Loss: 0.2253%\n",
      "Epoch [46/300], Step [48/225], Training Accuracy: 91.6341%, Training Loss: 0.2253%\n",
      "Epoch [46/300], Step [49/225], Training Accuracy: 91.7092%, Training Loss: 0.2235%\n",
      "Epoch [46/300], Step [50/225], Training Accuracy: 91.6250%, Training Loss: 0.2258%\n",
      "Epoch [46/300], Step [51/225], Training Accuracy: 91.7279%, Training Loss: 0.2246%\n",
      "Epoch [46/300], Step [52/225], Training Accuracy: 91.7668%, Training Loss: 0.2226%\n",
      "Epoch [46/300], Step [53/225], Training Accuracy: 91.7748%, Training Loss: 0.2224%\n",
      "Epoch [46/300], Step [54/225], Training Accuracy: 91.5799%, Training Loss: 0.2263%\n",
      "Epoch [46/300], Step [55/225], Training Accuracy: 91.6477%, Training Loss: 0.2248%\n",
      "Epoch [46/300], Step [56/225], Training Accuracy: 91.7411%, Training Loss: 0.2247%\n",
      "Epoch [46/300], Step [57/225], Training Accuracy: 91.7215%, Training Loss: 0.2247%\n",
      "Epoch [46/300], Step [58/225], Training Accuracy: 91.7565%, Training Loss: 0.2238%\n",
      "Epoch [46/300], Step [59/225], Training Accuracy: 91.7373%, Training Loss: 0.2234%\n",
      "Epoch [46/300], Step [60/225], Training Accuracy: 91.7188%, Training Loss: 0.2232%\n",
      "Epoch [46/300], Step [61/225], Training Accuracy: 91.6752%, Training Loss: 0.2246%\n",
      "Epoch [46/300], Step [62/225], Training Accuracy: 91.7087%, Training Loss: 0.2240%\n",
      "Epoch [46/300], Step [63/225], Training Accuracy: 91.6667%, Training Loss: 0.2246%\n",
      "Epoch [46/300], Step [64/225], Training Accuracy: 91.5771%, Training Loss: 0.2260%\n",
      "Epoch [46/300], Step [65/225], Training Accuracy: 91.5625%, Training Loss: 0.2253%\n",
      "Epoch [46/300], Step [66/225], Training Accuracy: 91.5483%, Training Loss: 0.2251%\n",
      "Epoch [46/300], Step [67/225], Training Accuracy: 91.5345%, Training Loss: 0.2249%\n",
      "Epoch [46/300], Step [68/225], Training Accuracy: 91.5901%, Training Loss: 0.2239%\n",
      "Epoch [46/300], Step [69/225], Training Accuracy: 91.5761%, Training Loss: 0.2247%\n",
      "Epoch [46/300], Step [70/225], Training Accuracy: 91.6295%, Training Loss: 0.2239%\n",
      "Epoch [46/300], Step [71/225], Training Accuracy: 91.6593%, Training Loss: 0.2238%\n",
      "Epoch [46/300], Step [72/225], Training Accuracy: 91.6016%, Training Loss: 0.2237%\n",
      "Epoch [46/300], Step [73/225], Training Accuracy: 91.6096%, Training Loss: 0.2236%\n",
      "Epoch [46/300], Step [74/225], Training Accuracy: 91.5329%, Training Loss: 0.2253%\n",
      "Epoch [46/300], Step [75/225], Training Accuracy: 91.6042%, Training Loss: 0.2245%\n",
      "Epoch [46/300], Step [76/225], Training Accuracy: 91.5296%, Training Loss: 0.2245%\n",
      "Epoch [46/300], Step [77/225], Training Accuracy: 91.5179%, Training Loss: 0.2244%\n",
      "Epoch [46/300], Step [78/225], Training Accuracy: 91.4864%, Training Loss: 0.2249%\n",
      "Epoch [46/300], Step [79/225], Training Accuracy: 91.5150%, Training Loss: 0.2245%\n",
      "Epoch [46/300], Step [80/225], Training Accuracy: 91.4844%, Training Loss: 0.2260%\n",
      "Epoch [46/300], Step [81/225], Training Accuracy: 91.5123%, Training Loss: 0.2253%\n",
      "Epoch [46/300], Step [82/225], Training Accuracy: 91.5206%, Training Loss: 0.2247%\n",
      "Epoch [46/300], Step [83/225], Training Accuracy: 91.5098%, Training Loss: 0.2248%\n",
      "Epoch [46/300], Step [84/225], Training Accuracy: 91.4621%, Training Loss: 0.2251%\n",
      "Epoch [46/300], Step [85/225], Training Accuracy: 91.5074%, Training Loss: 0.2244%\n",
      "Epoch [46/300], Step [86/225], Training Accuracy: 91.4426%, Training Loss: 0.2263%\n",
      "Epoch [46/300], Step [87/225], Training Accuracy: 91.4152%, Training Loss: 0.2271%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/300], Step [88/225], Training Accuracy: 91.4062%, Training Loss: 0.2275%\n",
      "Epoch [46/300], Step [89/225], Training Accuracy: 91.3975%, Training Loss: 0.2270%\n",
      "Epoch [46/300], Step [90/225], Training Accuracy: 91.3194%, Training Loss: 0.2273%\n",
      "Epoch [46/300], Step [91/225], Training Accuracy: 91.3290%, Training Loss: 0.2270%\n",
      "Epoch [46/300], Step [92/225], Training Accuracy: 91.2874%, Training Loss: 0.2276%\n",
      "Epoch [46/300], Step [93/225], Training Accuracy: 91.2466%, Training Loss: 0.2297%\n",
      "Epoch [46/300], Step [94/225], Training Accuracy: 91.2234%, Training Loss: 0.2302%\n",
      "Epoch [46/300], Step [95/225], Training Accuracy: 91.2336%, Training Loss: 0.2301%\n",
      "Epoch [46/300], Step [96/225], Training Accuracy: 91.2760%, Training Loss: 0.2293%\n",
      "Epoch [46/300], Step [97/225], Training Accuracy: 91.2854%, Training Loss: 0.2290%\n",
      "Epoch [46/300], Step [98/225], Training Accuracy: 91.2787%, Training Loss: 0.2288%\n",
      "Epoch [46/300], Step [99/225], Training Accuracy: 91.2721%, Training Loss: 0.2289%\n",
      "Epoch [46/300], Step [100/225], Training Accuracy: 91.2656%, Training Loss: 0.2286%\n",
      "Epoch [46/300], Step [101/225], Training Accuracy: 91.2593%, Training Loss: 0.2302%\n",
      "Epoch [46/300], Step [102/225], Training Accuracy: 91.2224%, Training Loss: 0.2306%\n",
      "Epoch [46/300], Step [103/225], Training Accuracy: 91.2015%, Training Loss: 0.2310%\n",
      "Epoch [46/300], Step [104/225], Training Accuracy: 91.2109%, Training Loss: 0.2309%\n",
      "Epoch [46/300], Step [105/225], Training Accuracy: 91.1756%, Training Loss: 0.2322%\n",
      "Epoch [46/300], Step [106/225], Training Accuracy: 91.1999%, Training Loss: 0.2324%\n",
      "Epoch [46/300], Step [107/225], Training Accuracy: 91.1215%, Training Loss: 0.2334%\n",
      "Epoch [46/300], Step [108/225], Training Accuracy: 91.1169%, Training Loss: 0.2332%\n",
      "Epoch [46/300], Step [109/225], Training Accuracy: 91.0837%, Training Loss: 0.2345%\n",
      "Epoch [46/300], Step [110/225], Training Accuracy: 91.1364%, Training Loss: 0.2333%\n",
      "Epoch [46/300], Step [111/225], Training Accuracy: 91.1318%, Training Loss: 0.2333%\n",
      "Epoch [46/300], Step [112/225], Training Accuracy: 91.1133%, Training Loss: 0.2327%\n",
      "Epoch [46/300], Step [113/225], Training Accuracy: 91.1504%, Training Loss: 0.2319%\n",
      "Epoch [46/300], Step [114/225], Training Accuracy: 91.1732%, Training Loss: 0.2318%\n",
      "Epoch [46/300], Step [115/225], Training Accuracy: 91.1549%, Training Loss: 0.2327%\n",
      "Epoch [46/300], Step [116/225], Training Accuracy: 91.1234%, Training Loss: 0.2329%\n",
      "Epoch [46/300], Step [117/225], Training Accuracy: 91.1725%, Training Loss: 0.2321%\n",
      "Epoch [46/300], Step [118/225], Training Accuracy: 91.1679%, Training Loss: 0.2319%\n",
      "Epoch [46/300], Step [119/225], Training Accuracy: 91.1371%, Training Loss: 0.2335%\n",
      "Epoch [46/300], Step [120/225], Training Accuracy: 91.1719%, Training Loss: 0.2326%\n",
      "Epoch [46/300], Step [121/225], Training Accuracy: 91.1157%, Training Loss: 0.2333%\n",
      "Epoch [46/300], Step [122/225], Training Accuracy: 91.0733%, Training Loss: 0.2335%\n",
      "Epoch [46/300], Step [123/225], Training Accuracy: 91.0696%, Training Loss: 0.2339%\n",
      "Epoch [46/300], Step [124/225], Training Accuracy: 91.0786%, Training Loss: 0.2344%\n",
      "Epoch [46/300], Step [125/225], Training Accuracy: 91.0625%, Training Loss: 0.2345%\n",
      "Epoch [46/300], Step [126/225], Training Accuracy: 91.0838%, Training Loss: 0.2339%\n",
      "Epoch [46/300], Step [127/225], Training Accuracy: 91.1171%, Training Loss: 0.2336%\n",
      "Epoch [46/300], Step [128/225], Training Accuracy: 91.0767%, Training Loss: 0.2337%\n",
      "Epoch [46/300], Step [129/225], Training Accuracy: 91.1216%, Training Loss: 0.2330%\n",
      "Epoch [46/300], Step [130/225], Training Accuracy: 91.1298%, Training Loss: 0.2331%\n",
      "Epoch [46/300], Step [131/225], Training Accuracy: 91.1140%, Training Loss: 0.2336%\n",
      "Epoch [46/300], Step [132/225], Training Accuracy: 91.0985%, Training Loss: 0.2339%\n",
      "Epoch [46/300], Step [133/225], Training Accuracy: 91.1184%, Training Loss: 0.2338%\n",
      "Epoch [46/300], Step [134/225], Training Accuracy: 91.1264%, Training Loss: 0.2341%\n",
      "Epoch [46/300], Step [135/225], Training Accuracy: 91.1458%, Training Loss: 0.2336%\n",
      "Epoch [46/300], Step [136/225], Training Accuracy: 91.1650%, Training Loss: 0.2339%\n",
      "Epoch [46/300], Step [137/225], Training Accuracy: 91.1268%, Training Loss: 0.2338%\n",
      "Epoch [46/300], Step [138/225], Training Accuracy: 91.1005%, Training Loss: 0.2351%\n",
      "Epoch [46/300], Step [139/225], Training Accuracy: 91.1196%, Training Loss: 0.2350%\n",
      "Epoch [46/300], Step [140/225], Training Accuracy: 91.1272%, Training Loss: 0.2349%\n",
      "Epoch [46/300], Step [141/225], Training Accuracy: 91.1015%, Training Loss: 0.2352%\n",
      "Epoch [46/300], Step [142/225], Training Accuracy: 91.1092%, Training Loss: 0.2346%\n",
      "Epoch [46/300], Step [143/225], Training Accuracy: 91.1058%, Training Loss: 0.2346%\n",
      "Epoch [46/300], Step [144/225], Training Accuracy: 91.1241%, Training Loss: 0.2341%\n",
      "Epoch [46/300], Step [145/225], Training Accuracy: 91.1530%, Training Loss: 0.2335%\n",
      "Epoch [46/300], Step [146/225], Training Accuracy: 91.1173%, Training Loss: 0.2340%\n",
      "Epoch [46/300], Step [147/225], Training Accuracy: 91.0927%, Training Loss: 0.2347%\n",
      "Epoch [46/300], Step [148/225], Training Accuracy: 91.1106%, Training Loss: 0.2342%\n",
      "Epoch [46/300], Step [149/225], Training Accuracy: 91.1179%, Training Loss: 0.2338%\n",
      "Epoch [46/300], Step [150/225], Training Accuracy: 91.1146%, Training Loss: 0.2336%\n",
      "Epoch [46/300], Step [151/225], Training Accuracy: 91.1113%, Training Loss: 0.2337%\n",
      "Epoch [46/300], Step [152/225], Training Accuracy: 91.1184%, Training Loss: 0.2333%\n",
      "Epoch [46/300], Step [153/225], Training Accuracy: 91.1152%, Training Loss: 0.2333%\n",
      "Epoch [46/300], Step [154/225], Training Accuracy: 91.1120%, Training Loss: 0.2335%\n",
      "Epoch [46/300], Step [155/225], Training Accuracy: 91.1190%, Training Loss: 0.2332%\n",
      "Epoch [46/300], Step [156/225], Training Accuracy: 91.1158%, Training Loss: 0.2330%\n",
      "Epoch [46/300], Step [157/225], Training Accuracy: 91.0928%, Training Loss: 0.2335%\n",
      "Epoch [46/300], Step [158/225], Training Accuracy: 91.0997%, Training Loss: 0.2331%\n",
      "Epoch [46/300], Step [159/225], Training Accuracy: 91.1065%, Training Loss: 0.2328%\n",
      "Epoch [46/300], Step [160/225], Training Accuracy: 91.1230%, Training Loss: 0.2325%\n",
      "Epoch [46/300], Step [161/225], Training Accuracy: 91.1491%, Training Loss: 0.2319%\n",
      "Epoch [46/300], Step [162/225], Training Accuracy: 91.1458%, Training Loss: 0.2320%\n",
      "Epoch [46/300], Step [163/225], Training Accuracy: 91.1522%, Training Loss: 0.2318%\n",
      "Epoch [46/300], Step [164/225], Training Accuracy: 91.1204%, Training Loss: 0.2323%\n",
      "Epoch [46/300], Step [165/225], Training Accuracy: 91.1553%, Training Loss: 0.2317%\n",
      "Epoch [46/300], Step [166/225], Training Accuracy: 91.1521%, Training Loss: 0.2315%\n",
      "Epoch [46/300], Step [167/225], Training Accuracy: 91.1677%, Training Loss: 0.2319%\n",
      "Epoch [46/300], Step [168/225], Training Accuracy: 91.1923%, Training Loss: 0.2311%\n",
      "Epoch [46/300], Step [169/225], Training Accuracy: 91.2075%, Training Loss: 0.2307%\n",
      "Epoch [46/300], Step [170/225], Training Accuracy: 91.2224%, Training Loss: 0.2309%\n",
      "Epoch [46/300], Step [171/225], Training Accuracy: 91.2281%, Training Loss: 0.2309%\n",
      "Epoch [46/300], Step [172/225], Training Accuracy: 91.2518%, Training Loss: 0.2304%\n",
      "Epoch [46/300], Step [173/225], Training Accuracy: 91.2392%, Training Loss: 0.2305%\n",
      "Epoch [46/300], Step [174/225], Training Accuracy: 91.2446%, Training Loss: 0.2310%\n",
      "Epoch [46/300], Step [175/225], Training Accuracy: 91.2589%, Training Loss: 0.2308%\n",
      "Epoch [46/300], Step [176/225], Training Accuracy: 91.2731%, Training Loss: 0.2306%\n",
      "Epoch [46/300], Step [177/225], Training Accuracy: 91.2782%, Training Loss: 0.2301%\n",
      "Epoch [46/300], Step [178/225], Training Accuracy: 91.2482%, Training Loss: 0.2307%\n",
      "Epoch [46/300], Step [179/225], Training Accuracy: 91.2797%, Training Loss: 0.2302%\n",
      "Epoch [46/300], Step [180/225], Training Accuracy: 91.2934%, Training Loss: 0.2300%\n",
      "Epoch [46/300], Step [181/225], Training Accuracy: 91.2897%, Training Loss: 0.2302%\n",
      "Epoch [46/300], Step [182/225], Training Accuracy: 91.3118%, Training Loss: 0.2297%\n",
      "Epoch [46/300], Step [183/225], Training Accuracy: 91.2910%, Training Loss: 0.2297%\n",
      "Epoch [46/300], Step [184/225], Training Accuracy: 91.3043%, Training Loss: 0.2293%\n",
      "Epoch [46/300], Step [185/225], Training Accuracy: 91.3007%, Training Loss: 0.2294%\n",
      "Epoch [46/300], Step [186/225], Training Accuracy: 91.3054%, Training Loss: 0.2293%\n",
      "Epoch [46/300], Step [187/225], Training Accuracy: 91.2851%, Training Loss: 0.2295%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/300], Step [188/225], Training Accuracy: 91.2982%, Training Loss: 0.2291%\n",
      "Epoch [46/300], Step [189/225], Training Accuracy: 91.3029%, Training Loss: 0.2292%\n",
      "Epoch [46/300], Step [190/225], Training Accuracy: 91.2829%, Training Loss: 0.2294%\n",
      "Epoch [46/300], Step [191/225], Training Accuracy: 91.2876%, Training Loss: 0.2293%\n",
      "Epoch [46/300], Step [192/225], Training Accuracy: 91.2923%, Training Loss: 0.2293%\n",
      "Epoch [46/300], Step [193/225], Training Accuracy: 91.2808%, Training Loss: 0.2297%\n",
      "Epoch [46/300], Step [194/225], Training Accuracy: 91.2854%, Training Loss: 0.2294%\n",
      "Epoch [46/300], Step [195/225], Training Accuracy: 91.2420%, Training Loss: 0.2304%\n",
      "Epoch [46/300], Step [196/225], Training Accuracy: 91.2388%, Training Loss: 0.2307%\n",
      "Epoch [46/300], Step [197/225], Training Accuracy: 91.2357%, Training Loss: 0.2304%\n",
      "Epoch [46/300], Step [198/225], Training Accuracy: 91.2484%, Training Loss: 0.2301%\n",
      "Epoch [46/300], Step [199/225], Training Accuracy: 91.2688%, Training Loss: 0.2299%\n",
      "Epoch [46/300], Step [200/225], Training Accuracy: 91.2812%, Training Loss: 0.2298%\n",
      "Epoch [46/300], Step [201/225], Training Accuracy: 91.2935%, Training Loss: 0.2296%\n",
      "Epoch [46/300], Step [202/225], Training Accuracy: 91.3057%, Training Loss: 0.2294%\n",
      "Epoch [46/300], Step [203/225], Training Accuracy: 91.3100%, Training Loss: 0.2294%\n",
      "Epoch [46/300], Step [204/225], Training Accuracy: 91.3067%, Training Loss: 0.2296%\n",
      "Epoch [46/300], Step [205/225], Training Accuracy: 91.3262%, Training Loss: 0.2292%\n",
      "Epoch [46/300], Step [206/225], Training Accuracy: 91.3152%, Training Loss: 0.2295%\n",
      "Epoch [46/300], Step [207/225], Training Accuracy: 91.3270%, Training Loss: 0.2293%\n",
      "Epoch [46/300], Step [208/225], Training Accuracy: 91.3462%, Training Loss: 0.2289%\n",
      "Epoch [46/300], Step [209/225], Training Accuracy: 91.3502%, Training Loss: 0.2289%\n",
      "Epoch [46/300], Step [210/225], Training Accuracy: 91.3393%, Training Loss: 0.2289%\n",
      "Epoch [46/300], Step [211/225], Training Accuracy: 91.3655%, Training Loss: 0.2286%\n",
      "Epoch [46/300], Step [212/225], Training Accuracy: 91.3694%, Training Loss: 0.2287%\n",
      "Epoch [46/300], Step [213/225], Training Accuracy: 91.3806%, Training Loss: 0.2287%\n",
      "Epoch [46/300], Step [214/225], Training Accuracy: 91.3770%, Training Loss: 0.2290%\n",
      "Epoch [46/300], Step [215/225], Training Accuracy: 91.3881%, Training Loss: 0.2287%\n",
      "Epoch [46/300], Step [216/225], Training Accuracy: 91.3628%, Training Loss: 0.2294%\n",
      "Epoch [46/300], Step [217/225], Training Accuracy: 91.3738%, Training Loss: 0.2292%\n",
      "Epoch [46/300], Step [218/225], Training Accuracy: 91.3704%, Training Loss: 0.2294%\n",
      "Epoch [46/300], Step [219/225], Training Accuracy: 91.3741%, Training Loss: 0.2296%\n",
      "Epoch [46/300], Step [220/225], Training Accuracy: 91.3920%, Training Loss: 0.2292%\n",
      "Epoch [46/300], Step [221/225], Training Accuracy: 91.3744%, Training Loss: 0.2292%\n",
      "Epoch [46/300], Step [222/225], Training Accuracy: 91.3640%, Training Loss: 0.2298%\n",
      "Epoch [46/300], Step [223/225], Training Accuracy: 91.3747%, Training Loss: 0.2296%\n",
      "Epoch [46/300], Step [224/225], Training Accuracy: 91.3644%, Training Loss: 0.2296%\n",
      "Epoch [46/300], Step [225/225], Training Accuracy: 91.3772%, Training Loss: 0.2293%\n",
      "Epoch [47/300], Step [1/225], Training Accuracy: 85.9375%, Training Loss: 0.3527%\n",
      "Epoch [47/300], Step [2/225], Training Accuracy: 90.6250%, Training Loss: 0.2527%\n",
      "Epoch [47/300], Step [3/225], Training Accuracy: 89.5833%, Training Loss: 0.2594%\n",
      "Epoch [47/300], Step [4/225], Training Accuracy: 90.2344%, Training Loss: 0.2573%\n",
      "Epoch [47/300], Step [5/225], Training Accuracy: 90.6250%, Training Loss: 0.2568%\n",
      "Epoch [47/300], Step [6/225], Training Accuracy: 90.3646%, Training Loss: 0.2606%\n",
      "Epoch [47/300], Step [7/225], Training Accuracy: 90.6250%, Training Loss: 0.2597%\n",
      "Epoch [47/300], Step [8/225], Training Accuracy: 91.4062%, Training Loss: 0.2403%\n",
      "Epoch [47/300], Step [9/225], Training Accuracy: 92.0139%, Training Loss: 0.2279%\n",
      "Epoch [47/300], Step [10/225], Training Accuracy: 92.0312%, Training Loss: 0.2279%\n",
      "Epoch [47/300], Step [11/225], Training Accuracy: 92.1875%, Training Loss: 0.2313%\n",
      "Epoch [47/300], Step [12/225], Training Accuracy: 92.4479%, Training Loss: 0.2254%\n",
      "Epoch [47/300], Step [13/225], Training Accuracy: 92.0673%, Training Loss: 0.2296%\n",
      "Epoch [47/300], Step [14/225], Training Accuracy: 91.7411%, Training Loss: 0.2347%\n",
      "Epoch [47/300], Step [15/225], Training Accuracy: 91.7708%, Training Loss: 0.2303%\n",
      "Epoch [47/300], Step [16/225], Training Accuracy: 91.7969%, Training Loss: 0.2274%\n",
      "Epoch [47/300], Step [17/225], Training Accuracy: 91.7279%, Training Loss: 0.2297%\n",
      "Epoch [47/300], Step [18/225], Training Accuracy: 91.8403%, Training Loss: 0.2276%\n",
      "Epoch [47/300], Step [19/225], Training Accuracy: 91.6941%, Training Loss: 0.2279%\n",
      "Epoch [47/300], Step [20/225], Training Accuracy: 91.6406%, Training Loss: 0.2269%\n",
      "Epoch [47/300], Step [21/225], Training Accuracy: 91.5923%, Training Loss: 0.2258%\n",
      "Epoch [47/300], Step [22/225], Training Accuracy: 91.3352%, Training Loss: 0.2295%\n",
      "Epoch [47/300], Step [23/225], Training Accuracy: 91.5082%, Training Loss: 0.2256%\n",
      "Epoch [47/300], Step [24/225], Training Accuracy: 91.5365%, Training Loss: 0.2263%\n",
      "Epoch [47/300], Step [25/225], Training Accuracy: 91.5625%, Training Loss: 0.2250%\n",
      "Epoch [47/300], Step [26/225], Training Accuracy: 91.4062%, Training Loss: 0.2272%\n",
      "Epoch [47/300], Step [27/225], Training Accuracy: 91.3773%, Training Loss: 0.2310%\n",
      "Epoch [47/300], Step [28/225], Training Accuracy: 91.4062%, Training Loss: 0.2341%\n",
      "Epoch [47/300], Step [29/225], Training Accuracy: 91.1638%, Training Loss: 0.2368%\n",
      "Epoch [47/300], Step [30/225], Training Accuracy: 91.1458%, Training Loss: 0.2395%\n",
      "Epoch [47/300], Step [31/225], Training Accuracy: 91.1290%, Training Loss: 0.2399%\n",
      "Epoch [47/300], Step [32/225], Training Accuracy: 91.1621%, Training Loss: 0.2369%\n",
      "Epoch [47/300], Step [33/225], Training Accuracy: 91.2405%, Training Loss: 0.2349%\n",
      "Epoch [47/300], Step [34/225], Training Accuracy: 91.2684%, Training Loss: 0.2349%\n",
      "Epoch [47/300], Step [35/225], Training Accuracy: 91.2500%, Training Loss: 0.2358%\n",
      "Epoch [47/300], Step [36/225], Training Accuracy: 91.1458%, Training Loss: 0.2369%\n",
      "Epoch [47/300], Step [37/225], Training Accuracy: 91.1740%, Training Loss: 0.2381%\n",
      "Epoch [47/300], Step [38/225], Training Accuracy: 91.0362%, Training Loss: 0.2408%\n",
      "Epoch [47/300], Step [39/225], Training Accuracy: 91.1859%, Training Loss: 0.2395%\n",
      "Epoch [47/300], Step [40/225], Training Accuracy: 91.2500%, Training Loss: 0.2388%\n",
      "Epoch [47/300], Step [41/225], Training Accuracy: 91.2348%, Training Loss: 0.2386%\n",
      "Epoch [47/300], Step [42/225], Training Accuracy: 91.2202%, Training Loss: 0.2387%\n",
      "Epoch [47/300], Step [43/225], Training Accuracy: 91.2427%, Training Loss: 0.2385%\n",
      "Epoch [47/300], Step [44/225], Training Accuracy: 91.4062%, Training Loss: 0.2362%\n",
      "Epoch [47/300], Step [45/225], Training Accuracy: 91.2847%, Training Loss: 0.2374%\n",
      "Epoch [47/300], Step [46/225], Training Accuracy: 91.3043%, Training Loss: 0.2365%\n",
      "Epoch [47/300], Step [47/225], Training Accuracy: 91.3896%, Training Loss: 0.2355%\n",
      "Epoch [47/300], Step [48/225], Training Accuracy: 91.2760%, Training Loss: 0.2364%\n",
      "Epoch [47/300], Step [49/225], Training Accuracy: 91.1990%, Training Loss: 0.2377%\n",
      "Epoch [47/300], Step [50/225], Training Accuracy: 91.1875%, Training Loss: 0.2382%\n",
      "Epoch [47/300], Step [51/225], Training Accuracy: 91.2990%, Training Loss: 0.2357%\n",
      "Epoch [47/300], Step [52/225], Training Accuracy: 91.3462%, Training Loss: 0.2341%\n",
      "Epoch [47/300], Step [53/225], Training Accuracy: 91.2146%, Training Loss: 0.2361%\n",
      "Epoch [47/300], Step [54/225], Training Accuracy: 91.2326%, Training Loss: 0.2353%\n",
      "Epoch [47/300], Step [55/225], Training Accuracy: 91.3352%, Training Loss: 0.2331%\n",
      "Epoch [47/300], Step [56/225], Training Accuracy: 91.2946%, Training Loss: 0.2333%\n",
      "Epoch [47/300], Step [57/225], Training Accuracy: 91.3377%, Training Loss: 0.2324%\n",
      "Epoch [47/300], Step [58/225], Training Accuracy: 91.4062%, Training Loss: 0.2310%\n",
      "Epoch [47/300], Step [59/225], Training Accuracy: 91.1811%, Training Loss: 0.2362%\n",
      "Epoch [47/300], Step [60/225], Training Accuracy: 91.1198%, Training Loss: 0.2361%\n",
      "Epoch [47/300], Step [61/225], Training Accuracy: 91.1885%, Training Loss: 0.2356%\n",
      "Epoch [47/300], Step [62/225], Training Accuracy: 91.1794%, Training Loss: 0.2363%\n",
      "Epoch [47/300], Step [63/225], Training Accuracy: 91.1458%, Training Loss: 0.2373%\n",
      "Epoch [47/300], Step [64/225], Training Accuracy: 91.0889%, Training Loss: 0.2366%\n",
      "Epoch [47/300], Step [65/225], Training Accuracy: 91.1538%, Training Loss: 0.2347%\n",
      "Epoch [47/300], Step [66/225], Training Accuracy: 91.1458%, Training Loss: 0.2354%\n",
      "Epoch [47/300], Step [67/225], Training Accuracy: 91.0914%, Training Loss: 0.2364%\n",
      "Epoch [47/300], Step [68/225], Training Accuracy: 91.0846%, Training Loss: 0.2362%\n",
      "Epoch [47/300], Step [69/225], Training Accuracy: 91.1232%, Training Loss: 0.2350%\n",
      "Epoch [47/300], Step [70/225], Training Accuracy: 91.1830%, Training Loss: 0.2344%\n",
      "Epoch [47/300], Step [71/225], Training Accuracy: 91.1312%, Training Loss: 0.2344%\n",
      "Epoch [47/300], Step [72/225], Training Accuracy: 91.1675%, Training Loss: 0.2338%\n",
      "Epoch [47/300], Step [73/225], Training Accuracy: 91.2243%, Training Loss: 0.2333%\n",
      "Epoch [47/300], Step [74/225], Training Accuracy: 91.1951%, Training Loss: 0.2332%\n",
      "Epoch [47/300], Step [75/225], Training Accuracy: 91.1875%, Training Loss: 0.2332%\n",
      "Epoch [47/300], Step [76/225], Training Accuracy: 91.2007%, Training Loss: 0.2339%\n",
      "Epoch [47/300], Step [77/225], Training Accuracy: 91.2135%, Training Loss: 0.2352%\n",
      "Epoch [47/300], Step [78/225], Training Accuracy: 91.2660%, Training Loss: 0.2339%\n",
      "Epoch [47/300], Step [79/225], Training Accuracy: 91.1986%, Training Loss: 0.2351%\n",
      "Epoch [47/300], Step [80/225], Training Accuracy: 91.0938%, Training Loss: 0.2373%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/300], Step [81/225], Training Accuracy: 91.1458%, Training Loss: 0.2363%\n",
      "Epoch [47/300], Step [82/225], Training Accuracy: 91.1585%, Training Loss: 0.2361%\n",
      "Epoch [47/300], Step [83/225], Training Accuracy: 91.1709%, Training Loss: 0.2360%\n",
      "Epoch [47/300], Step [84/225], Training Accuracy: 91.1644%, Training Loss: 0.2363%\n",
      "Epoch [47/300], Step [85/225], Training Accuracy: 91.2316%, Training Loss: 0.2356%\n",
      "Epoch [47/300], Step [86/225], Training Accuracy: 91.2246%, Training Loss: 0.2356%\n",
      "Epoch [47/300], Step [87/225], Training Accuracy: 91.2716%, Training Loss: 0.2348%\n",
      "Epoch [47/300], Step [88/225], Training Accuracy: 91.2642%, Training Loss: 0.2352%\n",
      "Epoch [47/300], Step [89/225], Training Accuracy: 91.2044%, Training Loss: 0.2353%\n",
      "Epoch [47/300], Step [90/225], Training Accuracy: 91.2500%, Training Loss: 0.2346%\n",
      "Epoch [47/300], Step [91/225], Training Accuracy: 91.2946%, Training Loss: 0.2338%\n",
      "Epoch [47/300], Step [92/225], Training Accuracy: 91.2364%, Training Loss: 0.2353%\n",
      "Epoch [47/300], Step [93/225], Training Accuracy: 91.2298%, Training Loss: 0.2359%\n",
      "Epoch [47/300], Step [94/225], Training Accuracy: 91.2566%, Training Loss: 0.2354%\n",
      "Epoch [47/300], Step [95/225], Training Accuracy: 91.2664%, Training Loss: 0.2356%\n",
      "Epoch [47/300], Step [96/225], Training Accuracy: 91.2923%, Training Loss: 0.2351%\n",
      "Epoch [47/300], Step [97/225], Training Accuracy: 91.2854%, Training Loss: 0.2355%\n",
      "Epoch [47/300], Step [98/225], Training Accuracy: 91.2946%, Training Loss: 0.2354%\n",
      "Epoch [47/300], Step [99/225], Training Accuracy: 91.2405%, Training Loss: 0.2362%\n",
      "Epoch [47/300], Step [100/225], Training Accuracy: 91.2500%, Training Loss: 0.2364%\n",
      "Epoch [47/300], Step [101/225], Training Accuracy: 91.1974%, Training Loss: 0.2369%\n",
      "Epoch [47/300], Step [102/225], Training Accuracy: 91.2377%, Training Loss: 0.2361%\n",
      "Epoch [47/300], Step [103/225], Training Accuracy: 91.2166%, Training Loss: 0.2367%\n",
      "Epoch [47/300], Step [104/225], Training Accuracy: 91.2260%, Training Loss: 0.2364%\n",
      "Epoch [47/300], Step [105/225], Training Accuracy: 91.1905%, Training Loss: 0.2363%\n",
      "Epoch [47/300], Step [106/225], Training Accuracy: 91.1114%, Training Loss: 0.2383%\n",
      "Epoch [47/300], Step [107/225], Training Accuracy: 91.1507%, Training Loss: 0.2381%\n",
      "Epoch [47/300], Step [108/225], Training Accuracy: 91.1748%, Training Loss: 0.2372%\n",
      "Epoch [47/300], Step [109/225], Training Accuracy: 91.2271%, Training Loss: 0.2367%\n",
      "Epoch [47/300], Step [110/225], Training Accuracy: 91.2784%, Training Loss: 0.2357%\n",
      "Epoch [47/300], Step [111/225], Training Accuracy: 91.3148%, Training Loss: 0.2353%\n",
      "Epoch [47/300], Step [112/225], Training Accuracy: 91.3365%, Training Loss: 0.2355%\n",
      "Epoch [47/300], Step [113/225], Training Accuracy: 91.3302%, Training Loss: 0.2355%\n",
      "Epoch [47/300], Step [114/225], Training Accuracy: 91.3514%, Training Loss: 0.2350%\n",
      "Epoch [47/300], Step [115/225], Training Accuracy: 91.3587%, Training Loss: 0.2345%\n",
      "Epoch [47/300], Step [116/225], Training Accuracy: 91.3254%, Training Loss: 0.2347%\n",
      "Epoch [47/300], Step [117/225], Training Accuracy: 91.3462%, Training Loss: 0.2345%\n",
      "Epoch [47/300], Step [118/225], Training Accuracy: 91.3798%, Training Loss: 0.2343%\n",
      "Epoch [47/300], Step [119/225], Training Accuracy: 91.3078%, Training Loss: 0.2354%\n",
      "Epoch [47/300], Step [120/225], Training Accuracy: 91.3411%, Training Loss: 0.2350%\n",
      "Epoch [47/300], Step [121/225], Training Accuracy: 91.3740%, Training Loss: 0.2339%\n",
      "Epoch [47/300], Step [122/225], Training Accuracy: 91.3934%, Training Loss: 0.2336%\n",
      "Epoch [47/300], Step [123/225], Training Accuracy: 91.3872%, Training Loss: 0.2337%\n",
      "Epoch [47/300], Step [124/225], Training Accuracy: 91.4062%, Training Loss: 0.2333%\n",
      "Epoch [47/300], Step [125/225], Training Accuracy: 91.4125%, Training Loss: 0.2331%\n",
      "Epoch [47/300], Step [126/225], Training Accuracy: 91.4435%, Training Loss: 0.2329%\n",
      "Epoch [47/300], Step [127/225], Training Accuracy: 91.4493%, Training Loss: 0.2331%\n",
      "Epoch [47/300], Step [128/225], Training Accuracy: 91.4673%, Training Loss: 0.2329%\n",
      "Epoch [47/300], Step [129/225], Training Accuracy: 91.5213%, Training Loss: 0.2321%\n",
      "Epoch [47/300], Step [130/225], Training Accuracy: 91.4904%, Training Loss: 0.2328%\n",
      "Epoch [47/300], Step [131/225], Training Accuracy: 91.5434%, Training Loss: 0.2320%\n",
      "Epoch [47/300], Step [132/225], Training Accuracy: 91.5365%, Training Loss: 0.2320%\n",
      "Epoch [47/300], Step [133/225], Training Accuracy: 91.5179%, Training Loss: 0.2321%\n",
      "Epoch [47/300], Step [134/225], Training Accuracy: 91.5462%, Training Loss: 0.2316%\n",
      "Epoch [47/300], Step [135/225], Training Accuracy: 91.5625%, Training Loss: 0.2311%\n",
      "Epoch [47/300], Step [136/225], Training Accuracy: 91.5441%, Training Loss: 0.2319%\n",
      "Epoch [47/300], Step [137/225], Training Accuracy: 91.5374%, Training Loss: 0.2316%\n",
      "Epoch [47/300], Step [138/225], Training Accuracy: 91.5648%, Training Loss: 0.2310%\n",
      "Epoch [47/300], Step [139/225], Training Accuracy: 91.6030%, Training Loss: 0.2303%\n",
      "Epoch [47/300], Step [140/225], Training Accuracy: 91.6406%, Training Loss: 0.2297%\n",
      "Epoch [47/300], Step [141/225], Training Accuracy: 91.6223%, Training Loss: 0.2301%\n",
      "Epoch [47/300], Step [142/225], Training Accuracy: 91.6043%, Training Loss: 0.2297%\n",
      "Epoch [47/300], Step [143/225], Training Accuracy: 91.5647%, Training Loss: 0.2308%\n",
      "Epoch [47/300], Step [144/225], Training Accuracy: 91.5582%, Training Loss: 0.2308%\n",
      "Epoch [47/300], Step [145/225], Training Accuracy: 91.5625%, Training Loss: 0.2311%\n",
      "Epoch [47/300], Step [146/225], Training Accuracy: 91.5026%, Training Loss: 0.2315%\n",
      "Epoch [47/300], Step [147/225], Training Accuracy: 91.4753%, Training Loss: 0.2323%\n",
      "Epoch [47/300], Step [148/225], Training Accuracy: 91.4485%, Training Loss: 0.2327%\n",
      "Epoch [47/300], Step [149/225], Training Accuracy: 91.3800%, Training Loss: 0.2332%\n",
      "Epoch [47/300], Step [150/225], Training Accuracy: 91.3854%, Training Loss: 0.2333%\n",
      "Epoch [47/300], Step [151/225], Training Accuracy: 91.3907%, Training Loss: 0.2332%\n",
      "Epoch [47/300], Step [152/225], Training Accuracy: 91.3651%, Training Loss: 0.2333%\n",
      "Epoch [47/300], Step [153/225], Training Accuracy: 91.3399%, Training Loss: 0.2333%\n",
      "Epoch [47/300], Step [154/225], Training Accuracy: 91.3352%, Training Loss: 0.2333%\n",
      "Epoch [47/300], Step [155/225], Training Accuracy: 91.3306%, Training Loss: 0.2334%\n",
      "Epoch [47/300], Step [156/225], Training Accuracy: 91.3462%, Training Loss: 0.2330%\n",
      "Epoch [47/300], Step [157/225], Training Accuracy: 91.3217%, Training Loss: 0.2332%\n",
      "Epoch [47/300], Step [158/225], Training Accuracy: 91.3667%, Training Loss: 0.2323%\n",
      "Epoch [47/300], Step [159/225], Training Accuracy: 91.3227%, Training Loss: 0.2334%\n",
      "Epoch [47/300], Step [160/225], Training Accuracy: 91.3379%, Training Loss: 0.2330%\n",
      "Epoch [47/300], Step [161/225], Training Accuracy: 91.3335%, Training Loss: 0.2327%\n",
      "Epoch [47/300], Step [162/225], Training Accuracy: 91.3387%, Training Loss: 0.2326%\n",
      "Epoch [47/300], Step [163/225], Training Accuracy: 91.3631%, Training Loss: 0.2322%\n",
      "Epoch [47/300], Step [164/225], Training Accuracy: 91.3681%, Training Loss: 0.2321%\n",
      "Epoch [47/300], Step [165/225], Training Accuracy: 91.3542%, Training Loss: 0.2319%\n",
      "Epoch [47/300], Step [166/225], Training Accuracy: 91.3686%, Training Loss: 0.2317%\n",
      "Epoch [47/300], Step [167/225], Training Accuracy: 91.3454%, Training Loss: 0.2324%\n",
      "Epoch [47/300], Step [168/225], Training Accuracy: 91.3318%, Training Loss: 0.2327%\n",
      "Epoch [47/300], Step [169/225], Training Accuracy: 91.3092%, Training Loss: 0.2326%\n",
      "Epoch [47/300], Step [170/225], Training Accuracy: 91.3327%, Training Loss: 0.2326%\n",
      "Epoch [47/300], Step [171/225], Training Accuracy: 91.3194%, Training Loss: 0.2324%\n",
      "Epoch [47/300], Step [172/225], Training Accuracy: 91.3336%, Training Loss: 0.2324%\n",
      "Epoch [47/300], Step [173/225], Training Accuracy: 91.3475%, Training Loss: 0.2320%\n",
      "Epoch [47/300], Step [174/225], Training Accuracy: 91.3614%, Training Loss: 0.2317%\n",
      "Epoch [47/300], Step [175/225], Training Accuracy: 91.3839%, Training Loss: 0.2312%\n",
      "Epoch [47/300], Step [176/225], Training Accuracy: 91.3885%, Training Loss: 0.2313%\n",
      "Epoch [47/300], Step [177/225], Training Accuracy: 91.4107%, Training Loss: 0.2306%\n",
      "Epoch [47/300], Step [178/225], Training Accuracy: 91.3711%, Training Loss: 0.2313%\n",
      "Epoch [47/300], Step [179/225], Training Accuracy: 91.3582%, Training Loss: 0.2315%\n",
      "Epoch [47/300], Step [180/225], Training Accuracy: 91.3889%, Training Loss: 0.2310%\n",
      "Epoch [47/300], Step [181/225], Training Accuracy: 91.3760%, Training Loss: 0.2316%\n",
      "Epoch [47/300], Step [182/225], Training Accuracy: 91.3462%, Training Loss: 0.2318%\n",
      "Epoch [47/300], Step [183/225], Training Accuracy: 91.3337%, Training Loss: 0.2321%\n",
      "Epoch [47/300], Step [184/225], Training Accuracy: 91.3553%, Training Loss: 0.2315%\n",
      "Epoch [47/300], Step [185/225], Training Accuracy: 91.3345%, Training Loss: 0.2319%\n",
      "Epoch [47/300], Step [186/225], Training Accuracy: 91.3222%, Training Loss: 0.2318%\n",
      "Epoch [47/300], Step [187/225], Training Accuracy: 91.3185%, Training Loss: 0.2317%\n",
      "Epoch [47/300], Step [188/225], Training Accuracy: 91.3398%, Training Loss: 0.2310%\n",
      "Epoch [47/300], Step [189/225], Training Accuracy: 91.3773%, Training Loss: 0.2302%\n",
      "Epoch [47/300], Step [190/225], Training Accuracy: 91.3651%, Training Loss: 0.2302%\n",
      "Epoch [47/300], Step [191/225], Training Accuracy: 91.3776%, Training Loss: 0.2300%\n",
      "Epoch [47/300], Step [192/225], Training Accuracy: 91.3574%, Training Loss: 0.2307%\n",
      "Epoch [47/300], Step [193/225], Training Accuracy: 91.3698%, Training Loss: 0.2305%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/300], Step [194/225], Training Accuracy: 91.3660%, Training Loss: 0.2303%\n",
      "Epoch [47/300], Step [195/225], Training Accuracy: 91.3462%, Training Loss: 0.2304%\n",
      "Epoch [47/300], Step [196/225], Training Accuracy: 91.3584%, Training Loss: 0.2301%\n",
      "Epoch [47/300], Step [197/225], Training Accuracy: 91.3706%, Training Loss: 0.2301%\n",
      "Epoch [47/300], Step [198/225], Training Accuracy: 91.3747%, Training Loss: 0.2297%\n",
      "Epoch [47/300], Step [199/225], Training Accuracy: 91.3709%, Training Loss: 0.2299%\n",
      "Epoch [47/300], Step [200/225], Training Accuracy: 91.3828%, Training Loss: 0.2299%\n",
      "Epoch [47/300], Step [201/225], Training Accuracy: 91.3790%, Training Loss: 0.2300%\n",
      "Epoch [47/300], Step [202/225], Training Accuracy: 91.3908%, Training Loss: 0.2298%\n",
      "Epoch [47/300], Step [203/225], Training Accuracy: 91.3870%, Training Loss: 0.2302%\n",
      "Epoch [47/300], Step [204/225], Training Accuracy: 91.4062%, Training Loss: 0.2299%\n",
      "Epoch [47/300], Step [205/225], Training Accuracy: 91.4101%, Training Loss: 0.2296%\n",
      "Epoch [47/300], Step [206/225], Training Accuracy: 91.4290%, Training Loss: 0.2293%\n",
      "Epoch [47/300], Step [207/225], Training Accuracy: 91.4402%, Training Loss: 0.2290%\n",
      "Epoch [47/300], Step [208/225], Training Accuracy: 91.4288%, Training Loss: 0.2291%\n",
      "Epoch [47/300], Step [209/225], Training Accuracy: 91.4399%, Training Loss: 0.2287%\n",
      "Epoch [47/300], Step [210/225], Training Accuracy: 91.4137%, Training Loss: 0.2291%\n",
      "Epoch [47/300], Step [211/225], Training Accuracy: 91.4025%, Training Loss: 0.2294%\n",
      "Epoch [47/300], Step [212/225], Training Accuracy: 91.4210%, Training Loss: 0.2290%\n",
      "Epoch [47/300], Step [213/225], Training Accuracy: 91.4466%, Training Loss: 0.2287%\n",
      "Epoch [47/300], Step [214/225], Training Accuracy: 91.4501%, Training Loss: 0.2284%\n",
      "Epoch [47/300], Step [215/225], Training Accuracy: 91.4535%, Training Loss: 0.2283%\n",
      "Epoch [47/300], Step [216/225], Training Accuracy: 91.4280%, Training Loss: 0.2287%\n",
      "Epoch [47/300], Step [217/225], Training Accuracy: 91.4243%, Training Loss: 0.2286%\n",
      "Epoch [47/300], Step [218/225], Training Accuracy: 91.3991%, Training Loss: 0.2289%\n",
      "Epoch [47/300], Step [219/225], Training Accuracy: 91.4098%, Training Loss: 0.2288%\n",
      "Epoch [47/300], Step [220/225], Training Accuracy: 91.4205%, Training Loss: 0.2285%\n",
      "Epoch [47/300], Step [221/225], Training Accuracy: 91.4310%, Training Loss: 0.2287%\n",
      "Epoch [47/300], Step [222/225], Training Accuracy: 91.4133%, Training Loss: 0.2288%\n",
      "Epoch [47/300], Step [223/225], Training Accuracy: 91.4168%, Training Loss: 0.2288%\n",
      "Epoch [47/300], Step [224/225], Training Accuracy: 91.4411%, Training Loss: 0.2282%\n",
      "Epoch [47/300], Step [225/225], Training Accuracy: 91.4327%, Training Loss: 0.2281%\n",
      "Epoch [48/300], Step [1/225], Training Accuracy: 90.6250%, Training Loss: 0.2057%\n",
      "Epoch [48/300], Step [2/225], Training Accuracy: 89.8438%, Training Loss: 0.2127%\n",
      "Epoch [48/300], Step [3/225], Training Accuracy: 86.9792%, Training Loss: 0.3014%\n",
      "Epoch [48/300], Step [4/225], Training Accuracy: 89.4531%, Training Loss: 0.2601%\n",
      "Epoch [48/300], Step [5/225], Training Accuracy: 90.0000%, Training Loss: 0.2566%\n",
      "Epoch [48/300], Step [6/225], Training Accuracy: 91.1458%, Training Loss: 0.2389%\n",
      "Epoch [48/300], Step [7/225], Training Accuracy: 90.4018%, Training Loss: 0.2719%\n",
      "Epoch [48/300], Step [8/225], Training Accuracy: 91.0156%, Training Loss: 0.2567%\n",
      "Epoch [48/300], Step [9/225], Training Accuracy: 91.3194%, Training Loss: 0.2448%\n",
      "Epoch [48/300], Step [10/225], Training Accuracy: 91.5625%, Training Loss: 0.2425%\n",
      "Epoch [48/300], Step [11/225], Training Accuracy: 92.1875%, Training Loss: 0.2358%\n",
      "Epoch [48/300], Step [12/225], Training Accuracy: 92.4479%, Training Loss: 0.2299%\n",
      "Epoch [48/300], Step [13/225], Training Accuracy: 92.7885%, Training Loss: 0.2242%\n",
      "Epoch [48/300], Step [14/225], Training Accuracy: 92.4107%, Training Loss: 0.2248%\n",
      "Epoch [48/300], Step [15/225], Training Accuracy: 92.1875%, Training Loss: 0.2257%\n",
      "Epoch [48/300], Step [16/225], Training Accuracy: 92.1875%, Training Loss: 0.2223%\n",
      "Epoch [48/300], Step [17/225], Training Accuracy: 91.8199%, Training Loss: 0.2261%\n",
      "Epoch [48/300], Step [18/225], Training Accuracy: 91.9271%, Training Loss: 0.2251%\n",
      "Epoch [48/300], Step [19/225], Training Accuracy: 91.8586%, Training Loss: 0.2278%\n",
      "Epoch [48/300], Step [20/225], Training Accuracy: 92.0312%, Training Loss: 0.2223%\n",
      "Epoch [48/300], Step [21/225], Training Accuracy: 92.1875%, Training Loss: 0.2195%\n",
      "Epoch [48/300], Step [22/225], Training Accuracy: 92.4006%, Training Loss: 0.2187%\n",
      "Epoch [48/300], Step [23/225], Training Accuracy: 92.2554%, Training Loss: 0.2187%\n",
      "Epoch [48/300], Step [24/225], Training Accuracy: 92.1875%, Training Loss: 0.2199%\n",
      "Epoch [48/300], Step [25/225], Training Accuracy: 92.1250%, Training Loss: 0.2238%\n",
      "Epoch [48/300], Step [26/225], Training Accuracy: 91.9471%, Training Loss: 0.2253%\n",
      "Epoch [48/300], Step [27/225], Training Accuracy: 91.8981%, Training Loss: 0.2266%\n",
      "Epoch [48/300], Step [28/225], Training Accuracy: 91.8527%, Training Loss: 0.2252%\n",
      "Epoch [48/300], Step [29/225], Training Accuracy: 91.7026%, Training Loss: 0.2307%\n",
      "Epoch [48/300], Step [30/225], Training Accuracy: 91.6146%, Training Loss: 0.2318%\n",
      "Epoch [48/300], Step [31/225], Training Accuracy: 91.4819%, Training Loss: 0.2340%\n",
      "Epoch [48/300], Step [32/225], Training Accuracy: 91.6016%, Training Loss: 0.2322%\n",
      "Epoch [48/300], Step [33/225], Training Accuracy: 91.6193%, Training Loss: 0.2306%\n",
      "Epoch [48/300], Step [34/225], Training Accuracy: 91.7279%, Training Loss: 0.2279%\n",
      "Epoch [48/300], Step [35/225], Training Accuracy: 91.6518%, Training Loss: 0.2280%\n",
      "Epoch [48/300], Step [36/225], Training Accuracy: 91.6233%, Training Loss: 0.2281%\n",
      "Epoch [48/300], Step [37/225], Training Accuracy: 91.5963%, Training Loss: 0.2302%\n",
      "Epoch [48/300], Step [38/225], Training Accuracy: 91.5296%, Training Loss: 0.2315%\n",
      "Epoch [48/300], Step [39/225], Training Accuracy: 91.5465%, Training Loss: 0.2309%\n",
      "Epoch [48/300], Step [40/225], Training Accuracy: 91.6016%, Training Loss: 0.2308%\n",
      "Epoch [48/300], Step [41/225], Training Accuracy: 91.5777%, Training Loss: 0.2318%\n",
      "Epoch [48/300], Step [42/225], Training Accuracy: 91.5923%, Training Loss: 0.2304%\n",
      "Epoch [48/300], Step [43/225], Training Accuracy: 91.4971%, Training Loss: 0.2321%\n",
      "Epoch [48/300], Step [44/225], Training Accuracy: 91.5483%, Training Loss: 0.2327%\n",
      "Epoch [48/300], Step [45/225], Training Accuracy: 91.6319%, Training Loss: 0.2312%\n",
      "Epoch [48/300], Step [46/225], Training Accuracy: 91.7459%, Training Loss: 0.2283%\n",
      "Epoch [48/300], Step [47/225], Training Accuracy: 91.7553%, Training Loss: 0.2275%\n",
      "Epoch [48/300], Step [48/225], Training Accuracy: 91.8620%, Training Loss: 0.2254%\n",
      "Epoch [48/300], Step [49/225], Training Accuracy: 91.9005%, Training Loss: 0.2243%\n",
      "Epoch [48/300], Step [50/225], Training Accuracy: 91.7812%, Training Loss: 0.2247%\n",
      "Epoch [48/300], Step [51/225], Training Accuracy: 91.9118%, Training Loss: 0.2222%\n",
      "Epoch [48/300], Step [52/225], Training Accuracy: 91.9471%, Training Loss: 0.2216%\n",
      "Epoch [48/300], Step [53/225], Training Accuracy: 92.0106%, Training Loss: 0.2206%\n",
      "Epoch [48/300], Step [54/225], Training Accuracy: 91.9560%, Training Loss: 0.2212%\n",
      "Epoch [48/300], Step [55/225], Training Accuracy: 91.9034%, Training Loss: 0.2223%\n",
      "Epoch [48/300], Step [56/225], Training Accuracy: 91.7690%, Training Loss: 0.2249%\n",
      "Epoch [48/300], Step [57/225], Training Accuracy: 91.7489%, Training Loss: 0.2245%\n",
      "Epoch [48/300], Step [58/225], Training Accuracy: 91.6756%, Training Loss: 0.2261%\n",
      "Epoch [48/300], Step [59/225], Training Accuracy: 91.6314%, Training Loss: 0.2268%\n",
      "Epoch [48/300], Step [60/225], Training Accuracy: 91.6927%, Training Loss: 0.2257%\n",
      "Epoch [48/300], Step [61/225], Training Accuracy: 91.6240%, Training Loss: 0.2263%\n",
      "Epoch [48/300], Step [62/225], Training Accuracy: 91.6583%, Training Loss: 0.2256%\n",
      "Epoch [48/300], Step [63/225], Training Accuracy: 91.7659%, Training Loss: 0.2235%\n",
      "Epoch [48/300], Step [64/225], Training Accuracy: 91.8701%, Training Loss: 0.2217%\n",
      "Epoch [48/300], Step [65/225], Training Accuracy: 91.8990%, Training Loss: 0.2226%\n",
      "Epoch [48/300], Step [66/225], Training Accuracy: 91.7614%, Training Loss: 0.2259%\n",
      "Epoch [48/300], Step [67/225], Training Accuracy: 91.6978%, Training Loss: 0.2273%\n",
      "Epoch [48/300], Step [68/225], Training Accuracy: 91.7050%, Training Loss: 0.2271%\n",
      "Epoch [48/300], Step [69/225], Training Accuracy: 91.6893%, Training Loss: 0.2269%\n",
      "Epoch [48/300], Step [70/225], Training Accuracy: 91.6295%, Training Loss: 0.2274%\n",
      "Epoch [48/300], Step [71/225], Training Accuracy: 91.5713%, Training Loss: 0.2283%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/300], Step [72/225], Training Accuracy: 91.5799%, Training Loss: 0.2280%\n",
      "Epoch [48/300], Step [73/225], Training Accuracy: 91.5882%, Training Loss: 0.2288%\n",
      "Epoch [48/300], Step [74/225], Training Accuracy: 91.5118%, Training Loss: 0.2308%\n",
      "Epoch [48/300], Step [75/225], Training Accuracy: 91.5625%, Training Loss: 0.2301%\n",
      "Epoch [48/300], Step [76/225], Training Accuracy: 91.5707%, Training Loss: 0.2307%\n",
      "Epoch [48/300], Step [77/225], Training Accuracy: 91.5990%, Training Loss: 0.2303%\n",
      "Epoch [48/300], Step [78/225], Training Accuracy: 91.5064%, Training Loss: 0.2316%\n",
      "Epoch [48/300], Step [79/225], Training Accuracy: 91.4953%, Training Loss: 0.2315%\n",
      "Epoch [48/300], Step [80/225], Training Accuracy: 91.5039%, Training Loss: 0.2313%\n",
      "Epoch [48/300], Step [81/225], Training Accuracy: 91.5702%, Training Loss: 0.2301%\n",
      "Epoch [48/300], Step [82/225], Training Accuracy: 91.5968%, Training Loss: 0.2295%\n",
      "Epoch [48/300], Step [83/225], Training Accuracy: 91.5851%, Training Loss: 0.2300%\n",
      "Epoch [48/300], Step [84/225], Training Accuracy: 91.6109%, Training Loss: 0.2296%\n",
      "Epoch [48/300], Step [85/225], Training Accuracy: 91.5441%, Training Loss: 0.2308%\n",
      "Epoch [48/300], Step [86/225], Training Accuracy: 91.5516%, Training Loss: 0.2307%\n",
      "Epoch [48/300], Step [87/225], Training Accuracy: 91.4511%, Training Loss: 0.2312%\n",
      "Epoch [48/300], Step [88/225], Training Accuracy: 91.4773%, Training Loss: 0.2302%\n",
      "Epoch [48/300], Step [89/225], Training Accuracy: 91.5204%, Training Loss: 0.2292%\n",
      "Epoch [48/300], Step [90/225], Training Accuracy: 91.5451%, Training Loss: 0.2282%\n",
      "Epoch [48/300], Step [91/225], Training Accuracy: 91.5865%, Training Loss: 0.2275%\n",
      "Epoch [48/300], Step [92/225], Training Accuracy: 91.6101%, Training Loss: 0.2267%\n",
      "Epoch [48/300], Step [93/225], Training Accuracy: 91.5659%, Training Loss: 0.2283%\n",
      "Epoch [48/300], Step [94/225], Training Accuracy: 91.6223%, Training Loss: 0.2270%\n",
      "Epoch [48/300], Step [95/225], Training Accuracy: 91.6447%, Training Loss: 0.2270%\n",
      "Epoch [48/300], Step [96/225], Training Accuracy: 91.7155%, Training Loss: 0.2254%\n",
      "Epoch [48/300], Step [97/225], Training Accuracy: 91.6720%, Training Loss: 0.2258%\n",
      "Epoch [48/300], Step [98/225], Training Accuracy: 91.6773%, Training Loss: 0.2257%\n",
      "Epoch [48/300], Step [99/225], Training Accuracy: 91.6509%, Training Loss: 0.2253%\n",
      "Epoch [48/300], Step [100/225], Training Accuracy: 91.6562%, Training Loss: 0.2260%\n",
      "Epoch [48/300], Step [101/225], Training Accuracy: 91.6615%, Training Loss: 0.2253%\n",
      "Epoch [48/300], Step [102/225], Training Accuracy: 91.6360%, Training Loss: 0.2260%\n",
      "Epoch [48/300], Step [103/225], Training Accuracy: 91.6566%, Training Loss: 0.2259%\n",
      "Epoch [48/300], Step [104/225], Training Accuracy: 91.6917%, Training Loss: 0.2251%\n",
      "Epoch [48/300], Step [105/225], Training Accuracy: 91.7262%, Training Loss: 0.2245%\n",
      "Epoch [48/300], Step [106/225], Training Accuracy: 91.7158%, Training Loss: 0.2247%\n",
      "Epoch [48/300], Step [107/225], Training Accuracy: 91.7494%, Training Loss: 0.2238%\n",
      "Epoch [48/300], Step [108/225], Training Accuracy: 91.7969%, Training Loss: 0.2229%\n",
      "Epoch [48/300], Step [109/225], Training Accuracy: 91.8291%, Training Loss: 0.2224%\n",
      "Epoch [48/300], Step [110/225], Training Accuracy: 91.8608%, Training Loss: 0.2219%\n",
      "Epoch [48/300], Step [111/225], Training Accuracy: 91.9200%, Training Loss: 0.2214%\n",
      "Epoch [48/300], Step [112/225], Training Accuracy: 91.9085%, Training Loss: 0.2214%\n",
      "Epoch [48/300], Step [113/225], Training Accuracy: 91.9386%, Training Loss: 0.2208%\n",
      "Epoch [48/300], Step [114/225], Training Accuracy: 91.9545%, Training Loss: 0.2201%\n",
      "Epoch [48/300], Step [115/225], Training Accuracy: 91.9565%, Training Loss: 0.2199%\n",
      "Epoch [48/300], Step [116/225], Training Accuracy: 91.9855%, Training Loss: 0.2197%\n",
      "Epoch [48/300], Step [117/225], Training Accuracy: 92.0139%, Training Loss: 0.2188%\n",
      "Epoch [48/300], Step [118/225], Training Accuracy: 91.9889%, Training Loss: 0.2192%\n",
      "Epoch [48/300], Step [119/225], Training Accuracy: 91.9643%, Training Loss: 0.2192%\n",
      "Epoch [48/300], Step [120/225], Training Accuracy: 91.9661%, Training Loss: 0.2188%\n",
      "Epoch [48/300], Step [121/225], Training Accuracy: 91.9551%, Training Loss: 0.2188%\n",
      "Epoch [48/300], Step [122/225], Training Accuracy: 91.9826%, Training Loss: 0.2181%\n",
      "Epoch [48/300], Step [123/225], Training Accuracy: 91.9715%, Training Loss: 0.2182%\n",
      "Epoch [48/300], Step [124/225], Training Accuracy: 91.9733%, Training Loss: 0.2186%\n",
      "Epoch [48/300], Step [125/225], Training Accuracy: 91.9750%, Training Loss: 0.2184%\n",
      "Epoch [48/300], Step [126/225], Training Accuracy: 91.9767%, Training Loss: 0.2185%\n",
      "Epoch [48/300], Step [127/225], Training Accuracy: 91.9783%, Training Loss: 0.2184%\n",
      "Epoch [48/300], Step [128/225], Training Accuracy: 91.9556%, Training Loss: 0.2189%\n",
      "Epoch [48/300], Step [129/225], Training Accuracy: 91.9816%, Training Loss: 0.2181%\n",
      "Epoch [48/300], Step [130/225], Training Accuracy: 91.9591%, Training Loss: 0.2193%\n",
      "Epoch [48/300], Step [131/225], Training Accuracy: 91.9609%, Training Loss: 0.2198%\n",
      "Epoch [48/300], Step [132/225], Training Accuracy: 91.9863%, Training Loss: 0.2193%\n",
      "Epoch [48/300], Step [133/225], Training Accuracy: 92.0113%, Training Loss: 0.2188%\n",
      "Epoch [48/300], Step [134/225], Training Accuracy: 92.0126%, Training Loss: 0.2190%\n",
      "Epoch [48/300], Step [135/225], Training Accuracy: 92.0486%, Training Loss: 0.2181%\n",
      "Epoch [48/300], Step [136/225], Training Accuracy: 92.0496%, Training Loss: 0.2187%\n",
      "Epoch [48/300], Step [137/225], Training Accuracy: 92.0392%, Training Loss: 0.2186%\n",
      "Epoch [48/300], Step [138/225], Training Accuracy: 92.0516%, Training Loss: 0.2183%\n",
      "Epoch [48/300], Step [139/225], Training Accuracy: 92.0414%, Training Loss: 0.2186%\n",
      "Epoch [48/300], Step [140/225], Training Accuracy: 92.0647%, Training Loss: 0.2182%\n",
      "Epoch [48/300], Step [141/225], Training Accuracy: 92.0767%, Training Loss: 0.2179%\n",
      "Epoch [48/300], Step [142/225], Training Accuracy: 92.0555%, Training Loss: 0.2177%\n",
      "Epoch [48/300], Step [143/225], Training Accuracy: 92.0345%, Training Loss: 0.2181%\n",
      "Epoch [48/300], Step [144/225], Training Accuracy: 92.0030%, Training Loss: 0.2182%\n",
      "Epoch [48/300], Step [145/225], Training Accuracy: 92.0366%, Training Loss: 0.2176%\n",
      "Epoch [48/300], Step [146/225], Training Accuracy: 92.0484%, Training Loss: 0.2172%\n",
      "Epoch [48/300], Step [147/225], Training Accuracy: 92.0493%, Training Loss: 0.2170%\n",
      "Epoch [48/300], Step [148/225], Training Accuracy: 91.9975%, Training Loss: 0.2174%\n",
      "Epoch [48/300], Step [149/225], Training Accuracy: 91.9778%, Training Loss: 0.2178%\n",
      "Epoch [48/300], Step [150/225], Training Accuracy: 92.0000%, Training Loss: 0.2176%\n",
      "Epoch [48/300], Step [151/225], Training Accuracy: 92.0426%, Training Loss: 0.2167%\n",
      "Epoch [48/300], Step [152/225], Training Accuracy: 92.0436%, Training Loss: 0.2165%\n",
      "Epoch [48/300], Step [153/225], Training Accuracy: 92.0547%, Training Loss: 0.2167%\n",
      "Epoch [48/300], Step [154/225], Training Accuracy: 92.0556%, Training Loss: 0.2163%\n",
      "Epoch [48/300], Step [155/225], Training Accuracy: 92.0464%, Training Loss: 0.2166%\n",
      "Epoch [48/300], Step [156/225], Training Accuracy: 92.0272%, Training Loss: 0.2173%\n",
      "Epoch [48/300], Step [157/225], Training Accuracy: 92.0084%, Training Loss: 0.2176%\n",
      "Epoch [48/300], Step [158/225], Training Accuracy: 91.9996%, Training Loss: 0.2174%\n",
      "Epoch [48/300], Step [159/225], Training Accuracy: 92.0204%, Training Loss: 0.2170%\n",
      "Epoch [48/300], Step [160/225], Training Accuracy: 92.0020%, Training Loss: 0.2174%\n",
      "Epoch [48/300], Step [161/225], Training Accuracy: 92.0225%, Training Loss: 0.2170%\n",
      "Epoch [48/300], Step [162/225], Training Accuracy: 92.0235%, Training Loss: 0.2171%\n",
      "Epoch [48/300], Step [163/225], Training Accuracy: 92.0533%, Training Loss: 0.2168%\n",
      "Epoch [48/300], Step [164/225], Training Accuracy: 92.0827%, Training Loss: 0.2165%\n",
      "Epoch [48/300], Step [165/225], Training Accuracy: 92.1023%, Training Loss: 0.2163%\n",
      "Epoch [48/300], Step [166/225], Training Accuracy: 92.0934%, Training Loss: 0.2163%\n",
      "Epoch [48/300], Step [167/225], Training Accuracy: 92.0939%, Training Loss: 0.2163%\n",
      "Epoch [48/300], Step [168/225], Training Accuracy: 92.1224%, Training Loss: 0.2158%\n",
      "Epoch [48/300], Step [169/225], Training Accuracy: 92.1043%, Training Loss: 0.2157%\n",
      "Epoch [48/300], Step [170/225], Training Accuracy: 92.0588%, Training Loss: 0.2163%\n",
      "Epoch [48/300], Step [171/225], Training Accuracy: 92.0413%, Training Loss: 0.2167%\n",
      "Epoch [48/300], Step [172/225], Training Accuracy: 92.0331%, Training Loss: 0.2169%\n",
      "Epoch [48/300], Step [173/225], Training Accuracy: 92.0520%, Training Loss: 0.2166%\n",
      "Epoch [48/300], Step [174/225], Training Accuracy: 92.0438%, Training Loss: 0.2165%\n",
      "Epoch [48/300], Step [175/225], Training Accuracy: 92.0268%, Training Loss: 0.2162%\n",
      "Epoch [48/300], Step [176/225], Training Accuracy: 92.0366%, Training Loss: 0.2161%\n",
      "Epoch [48/300], Step [177/225], Training Accuracy: 92.0463%, Training Loss: 0.2159%\n",
      "Epoch [48/300], Step [178/225], Training Accuracy: 92.0471%, Training Loss: 0.2160%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/300], Step [179/225], Training Accuracy: 92.0566%, Training Loss: 0.2156%\n",
      "Epoch [48/300], Step [180/225], Training Accuracy: 92.0573%, Training Loss: 0.2163%\n",
      "Epoch [48/300], Step [181/225], Training Accuracy: 92.0580%, Training Loss: 0.2159%\n",
      "Epoch [48/300], Step [182/225], Training Accuracy: 92.0673%, Training Loss: 0.2157%\n",
      "Epoch [48/300], Step [183/225], Training Accuracy: 92.0936%, Training Loss: 0.2152%\n",
      "Epoch [48/300], Step [184/225], Training Accuracy: 92.0856%, Training Loss: 0.2153%\n",
      "Epoch [48/300], Step [185/225], Training Accuracy: 92.0946%, Training Loss: 0.2150%\n",
      "Epoch [48/300], Step [186/225], Training Accuracy: 92.1203%, Training Loss: 0.2144%\n",
      "Epoch [48/300], Step [187/225], Training Accuracy: 92.1123%, Training Loss: 0.2146%\n",
      "Epoch [48/300], Step [188/225], Training Accuracy: 92.0961%, Training Loss: 0.2146%\n",
      "Epoch [48/300], Step [189/225], Training Accuracy: 92.1131%, Training Loss: 0.2144%\n",
      "Epoch [48/300], Step [190/225], Training Accuracy: 92.0806%, Training Loss: 0.2149%\n",
      "Epoch [48/300], Step [191/225], Training Accuracy: 92.1139%, Training Loss: 0.2142%\n",
      "Epoch [48/300], Step [192/225], Training Accuracy: 92.1143%, Training Loss: 0.2141%\n",
      "Epoch [48/300], Step [193/225], Training Accuracy: 92.1146%, Training Loss: 0.2140%\n",
      "Epoch [48/300], Step [194/225], Training Accuracy: 92.1311%, Training Loss: 0.2138%\n",
      "Epoch [48/300], Step [195/225], Training Accuracy: 92.0994%, Training Loss: 0.2142%\n",
      "Epoch [48/300], Step [196/225], Training Accuracy: 92.1078%, Training Loss: 0.2139%\n",
      "Epoch [48/300], Step [197/225], Training Accuracy: 92.1003%, Training Loss: 0.2145%\n",
      "Epoch [48/300], Step [198/225], Training Accuracy: 92.1165%, Training Loss: 0.2149%\n",
      "Epoch [48/300], Step [199/225], Training Accuracy: 92.1011%, Training Loss: 0.2153%\n",
      "Epoch [48/300], Step [200/225], Training Accuracy: 92.1016%, Training Loss: 0.2152%\n",
      "Epoch [48/300], Step [201/225], Training Accuracy: 92.1175%, Training Loss: 0.2152%\n",
      "Epoch [48/300], Step [202/225], Training Accuracy: 92.1256%, Training Loss: 0.2150%\n",
      "Epoch [48/300], Step [203/225], Training Accuracy: 92.1028%, Training Loss: 0.2154%\n",
      "Epoch [48/300], Step [204/225], Training Accuracy: 92.0650%, Training Loss: 0.2159%\n",
      "Epoch [48/300], Step [205/225], Training Accuracy: 92.0808%, Training Loss: 0.2155%\n",
      "Epoch [48/300], Step [206/225], Training Accuracy: 92.0661%, Training Loss: 0.2158%\n",
      "Epoch [48/300], Step [207/225], Training Accuracy: 92.0969%, Training Loss: 0.2152%\n",
      "Epoch [48/300], Step [208/225], Training Accuracy: 92.1199%, Training Loss: 0.2147%\n",
      "Epoch [48/300], Step [209/225], Training Accuracy: 92.1352%, Training Loss: 0.2143%\n",
      "Epoch [48/300], Step [210/225], Training Accuracy: 92.1205%, Training Loss: 0.2145%\n",
      "Epoch [48/300], Step [211/225], Training Accuracy: 92.1134%, Training Loss: 0.2147%\n",
      "Epoch [48/300], Step [212/225], Training Accuracy: 92.0548%, Training Loss: 0.2157%\n",
      "Epoch [48/300], Step [213/225], Training Accuracy: 92.0775%, Training Loss: 0.2155%\n",
      "Epoch [48/300], Step [214/225], Training Accuracy: 92.0707%, Training Loss: 0.2156%\n",
      "Epoch [48/300], Step [215/225], Training Accuracy: 92.0785%, Training Loss: 0.2155%\n",
      "Epoch [48/300], Step [216/225], Training Accuracy: 92.0718%, Training Loss: 0.2156%\n",
      "Epoch [48/300], Step [217/225], Training Accuracy: 92.0939%, Training Loss: 0.2152%\n",
      "Epoch [48/300], Step [218/225], Training Accuracy: 92.0800%, Training Loss: 0.2154%\n",
      "Epoch [48/300], Step [219/225], Training Accuracy: 92.0519%, Training Loss: 0.2160%\n",
      "Epoch [48/300], Step [220/225], Training Accuracy: 92.0597%, Training Loss: 0.2158%\n",
      "Epoch [48/300], Step [221/225], Training Accuracy: 92.0320%, Training Loss: 0.2164%\n",
      "Epoch [48/300], Step [222/225], Training Accuracy: 92.0256%, Training Loss: 0.2168%\n",
      "Epoch [48/300], Step [223/225], Training Accuracy: 92.0263%, Training Loss: 0.2166%\n",
      "Epoch [48/300], Step [224/225], Training Accuracy: 92.0550%, Training Loss: 0.2161%\n",
      "Epoch [48/300], Step [225/225], Training Accuracy: 92.0720%, Training Loss: 0.2159%\n",
      "Epoch [49/300], Step [1/225], Training Accuracy: 95.3125%, Training Loss: 0.1517%\n",
      "Epoch [49/300], Step [2/225], Training Accuracy: 92.9688%, Training Loss: 0.1809%\n",
      "Epoch [49/300], Step [3/225], Training Accuracy: 89.5833%, Training Loss: 0.2349%\n",
      "Epoch [49/300], Step [4/225], Training Accuracy: 90.6250%, Training Loss: 0.2110%\n",
      "Epoch [49/300], Step [5/225], Training Accuracy: 90.3125%, Training Loss: 0.2057%\n",
      "Epoch [49/300], Step [6/225], Training Accuracy: 89.3229%, Training Loss: 0.2235%\n",
      "Epoch [49/300], Step [7/225], Training Accuracy: 89.5089%, Training Loss: 0.2237%\n",
      "Epoch [49/300], Step [8/225], Training Accuracy: 90.2344%, Training Loss: 0.2077%\n",
      "Epoch [49/300], Step [9/225], Training Accuracy: 90.1042%, Training Loss: 0.2012%\n",
      "Epoch [49/300], Step [10/225], Training Accuracy: 90.4688%, Training Loss: 0.2014%\n",
      "Epoch [49/300], Step [11/225], Training Accuracy: 90.6250%, Training Loss: 0.2002%\n",
      "Epoch [49/300], Step [12/225], Training Accuracy: 90.8854%, Training Loss: 0.2036%\n",
      "Epoch [49/300], Step [13/225], Training Accuracy: 90.6250%, Training Loss: 0.2093%\n",
      "Epoch [49/300], Step [14/225], Training Accuracy: 90.5134%, Training Loss: 0.2099%\n",
      "Epoch [49/300], Step [15/225], Training Accuracy: 90.6250%, Training Loss: 0.2160%\n",
      "Epoch [49/300], Step [16/225], Training Accuracy: 90.9180%, Training Loss: 0.2110%\n",
      "Epoch [49/300], Step [17/225], Training Accuracy: 90.9007%, Training Loss: 0.2108%\n",
      "Epoch [49/300], Step [18/225], Training Accuracy: 90.7986%, Training Loss: 0.2120%\n",
      "Epoch [49/300], Step [19/225], Training Accuracy: 90.9539%, Training Loss: 0.2089%\n",
      "Epoch [49/300], Step [20/225], Training Accuracy: 91.0156%, Training Loss: 0.2087%\n",
      "Epoch [49/300], Step [21/225], Training Accuracy: 90.9226%, Training Loss: 0.2109%\n",
      "Epoch [49/300], Step [22/225], Training Accuracy: 90.8381%, Training Loss: 0.2122%\n",
      "Epoch [49/300], Step [23/225], Training Accuracy: 90.8967%, Training Loss: 0.2132%\n",
      "Epoch [49/300], Step [24/225], Training Accuracy: 90.6901%, Training Loss: 0.2202%\n",
      "Epoch [49/300], Step [25/225], Training Accuracy: 90.7500%, Training Loss: 0.2170%\n",
      "Epoch [49/300], Step [26/225], Training Accuracy: 90.6851%, Training Loss: 0.2175%\n",
      "Epoch [49/300], Step [27/225], Training Accuracy: 90.3935%, Training Loss: 0.2212%\n",
      "Epoch [49/300], Step [28/225], Training Accuracy: 90.6808%, Training Loss: 0.2168%\n",
      "Epoch [49/300], Step [29/225], Training Accuracy: 90.7866%, Training Loss: 0.2146%\n",
      "Epoch [49/300], Step [30/225], Training Accuracy: 90.8333%, Training Loss: 0.2131%\n",
      "Epoch [49/300], Step [31/225], Training Accuracy: 90.7762%, Training Loss: 0.2154%\n",
      "Epoch [49/300], Step [32/225], Training Accuracy: 90.9668%, Training Loss: 0.2119%\n",
      "Epoch [49/300], Step [33/225], Training Accuracy: 90.8144%, Training Loss: 0.2148%\n",
      "Epoch [49/300], Step [34/225], Training Accuracy: 90.9007%, Training Loss: 0.2152%\n",
      "Epoch [49/300], Step [35/225], Training Accuracy: 90.8929%, Training Loss: 0.2160%\n",
      "Epoch [49/300], Step [36/225], Training Accuracy: 90.9288%, Training Loss: 0.2162%\n",
      "Epoch [49/300], Step [37/225], Training Accuracy: 90.9206%, Training Loss: 0.2163%\n",
      "Epoch [49/300], Step [38/225], Training Accuracy: 90.9539%, Training Loss: 0.2165%\n",
      "Epoch [49/300], Step [39/225], Training Accuracy: 91.0256%, Training Loss: 0.2154%\n",
      "Epoch [49/300], Step [40/225], Training Accuracy: 91.0938%, Training Loss: 0.2145%\n",
      "Epoch [49/300], Step [41/225], Training Accuracy: 90.9299%, Training Loss: 0.2191%\n",
      "Epoch [49/300], Step [42/225], Training Accuracy: 90.9226%, Training Loss: 0.2178%\n",
      "Epoch [49/300], Step [43/225], Training Accuracy: 90.9884%, Training Loss: 0.2165%\n",
      "Epoch [49/300], Step [44/225], Training Accuracy: 90.9446%, Training Loss: 0.2161%\n",
      "Epoch [49/300], Step [45/225], Training Accuracy: 90.9722%, Training Loss: 0.2172%\n",
      "Epoch [49/300], Step [46/225], Training Accuracy: 91.0326%, Training Loss: 0.2157%\n",
      "Epoch [49/300], Step [47/225], Training Accuracy: 90.9242%, Training Loss: 0.2172%\n",
      "Epoch [49/300], Step [48/225], Training Accuracy: 91.0156%, Training Loss: 0.2168%\n",
      "Epoch [49/300], Step [49/225], Training Accuracy: 91.0714%, Training Loss: 0.2160%\n",
      "Epoch [49/300], Step [50/225], Training Accuracy: 91.0625%, Training Loss: 0.2155%\n",
      "Epoch [49/300], Step [51/225], Training Accuracy: 91.0846%, Training Loss: 0.2151%\n",
      "Epoch [49/300], Step [52/225], Training Accuracy: 91.1058%, Training Loss: 0.2143%\n",
      "Epoch [49/300], Step [53/225], Training Accuracy: 91.0377%, Training Loss: 0.2141%\n",
      "Epoch [49/300], Step [54/225], Training Accuracy: 90.9144%, Training Loss: 0.2168%\n",
      "Epoch [49/300], Step [55/225], Training Accuracy: 90.9375%, Training Loss: 0.2162%\n",
      "Epoch [49/300], Step [56/225], Training Accuracy: 90.9319%, Training Loss: 0.2173%\n",
      "Epoch [49/300], Step [57/225], Training Accuracy: 90.9265%, Training Loss: 0.2179%\n",
      "Epoch [49/300], Step [58/225], Training Accuracy: 90.9752%, Training Loss: 0.2211%\n",
      "Epoch [49/300], Step [59/225], Training Accuracy: 90.8898%, Training Loss: 0.2220%\n",
      "Epoch [49/300], Step [60/225], Training Accuracy: 90.8854%, Training Loss: 0.2219%\n",
      "Epoch [49/300], Step [61/225], Training Accuracy: 90.9068%, Training Loss: 0.2224%\n",
      "Epoch [49/300], Step [62/225], Training Accuracy: 90.9526%, Training Loss: 0.2225%\n",
      "Epoch [49/300], Step [63/225], Training Accuracy: 90.8482%, Training Loss: 0.2258%\n",
      "Epoch [49/300], Step [64/225], Training Accuracy: 90.8447%, Training Loss: 0.2263%\n",
      "Epoch [49/300], Step [65/225], Training Accuracy: 90.9615%, Training Loss: 0.2243%\n",
      "Epoch [49/300], Step [66/225], Training Accuracy: 91.0275%, Training Loss: 0.2233%\n",
      "Epoch [49/300], Step [67/225], Training Accuracy: 91.0681%, Training Loss: 0.2226%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/300], Step [68/225], Training Accuracy: 91.0156%, Training Loss: 0.2238%\n",
      "Epoch [49/300], Step [69/225], Training Accuracy: 91.0326%, Training Loss: 0.2235%\n",
      "Epoch [49/300], Step [70/225], Training Accuracy: 91.1161%, Training Loss: 0.2223%\n",
      "Epoch [49/300], Step [71/225], Training Accuracy: 91.1972%, Training Loss: 0.2212%\n",
      "Epoch [49/300], Step [72/225], Training Accuracy: 91.2760%, Training Loss: 0.2204%\n",
      "Epoch [49/300], Step [73/225], Training Accuracy: 91.2029%, Training Loss: 0.2219%\n",
      "Epoch [49/300], Step [74/225], Training Accuracy: 91.1951%, Training Loss: 0.2241%\n",
      "Epoch [49/300], Step [75/225], Training Accuracy: 91.1458%, Training Loss: 0.2254%\n",
      "Epoch [49/300], Step [76/225], Training Accuracy: 91.1801%, Training Loss: 0.2257%\n",
      "Epoch [49/300], Step [77/225], Training Accuracy: 91.1323%, Training Loss: 0.2267%\n",
      "Epoch [49/300], Step [78/225], Training Accuracy: 91.0657%, Training Loss: 0.2284%\n",
      "Epoch [49/300], Step [79/225], Training Accuracy: 91.0601%, Training Loss: 0.2289%\n",
      "Epoch [49/300], Step [80/225], Training Accuracy: 90.9766%, Training Loss: 0.2304%\n",
      "Epoch [49/300], Step [81/225], Training Accuracy: 91.0108%, Training Loss: 0.2300%\n",
      "Epoch [49/300], Step [82/225], Training Accuracy: 91.0442%, Training Loss: 0.2292%\n",
      "Epoch [49/300], Step [83/225], Training Accuracy: 91.0580%, Training Loss: 0.2293%\n",
      "Epoch [49/300], Step [84/225], Training Accuracy: 91.0528%, Training Loss: 0.2290%\n",
      "Epoch [49/300], Step [85/225], Training Accuracy: 91.0294%, Training Loss: 0.2292%\n",
      "Epoch [49/300], Step [86/225], Training Accuracy: 91.0065%, Training Loss: 0.2295%\n",
      "Epoch [49/300], Step [87/225], Training Accuracy: 91.0381%, Training Loss: 0.2294%\n",
      "Epoch [49/300], Step [88/225], Training Accuracy: 90.9801%, Training Loss: 0.2304%\n",
      "Epoch [49/300], Step [89/225], Training Accuracy: 90.9586%, Training Loss: 0.2313%\n",
      "Epoch [49/300], Step [90/225], Training Accuracy: 90.9722%, Training Loss: 0.2309%\n",
      "Epoch [49/300], Step [91/225], Training Accuracy: 90.9341%, Training Loss: 0.2312%\n",
      "Epoch [49/300], Step [92/225], Training Accuracy: 90.9477%, Training Loss: 0.2302%\n",
      "Epoch [49/300], Step [93/225], Training Accuracy: 90.9946%, Training Loss: 0.2293%\n",
      "Epoch [49/300], Step [94/225], Training Accuracy: 90.9907%, Training Loss: 0.2286%\n",
      "Epoch [49/300], Step [95/225], Training Accuracy: 90.9704%, Training Loss: 0.2294%\n",
      "Epoch [49/300], Step [96/225], Training Accuracy: 91.0319%, Training Loss: 0.2287%\n",
      "Epoch [49/300], Step [97/225], Training Accuracy: 91.1082%, Training Loss: 0.2272%\n",
      "Epoch [49/300], Step [98/225], Training Accuracy: 91.1193%, Training Loss: 0.2271%\n",
      "Epoch [49/300], Step [99/225], Training Accuracy: 91.1458%, Training Loss: 0.2265%\n",
      "Epoch [49/300], Step [100/225], Training Accuracy: 91.1094%, Training Loss: 0.2269%\n",
      "Epoch [49/300], Step [101/225], Training Accuracy: 91.0736%, Training Loss: 0.2272%\n",
      "Epoch [49/300], Step [102/225], Training Accuracy: 91.0539%, Training Loss: 0.2276%\n",
      "Epoch [49/300], Step [103/225], Training Accuracy: 91.0953%, Training Loss: 0.2275%\n",
      "Epoch [49/300], Step [104/225], Training Accuracy: 91.1208%, Training Loss: 0.2271%\n",
      "Epoch [49/300], Step [105/225], Training Accuracy: 91.1310%, Training Loss: 0.2268%\n",
      "Epoch [49/300], Step [106/225], Training Accuracy: 91.1409%, Training Loss: 0.2268%\n",
      "Epoch [49/300], Step [107/225], Training Accuracy: 91.1069%, Training Loss: 0.2273%\n",
      "Epoch [49/300], Step [108/225], Training Accuracy: 91.1314%, Training Loss: 0.2270%\n",
      "Epoch [49/300], Step [109/225], Training Accuracy: 91.1267%, Training Loss: 0.2267%\n",
      "Epoch [49/300], Step [110/225], Training Accuracy: 91.1648%, Training Loss: 0.2258%\n",
      "Epoch [49/300], Step [111/225], Training Accuracy: 91.1599%, Training Loss: 0.2261%\n",
      "Epoch [49/300], Step [112/225], Training Accuracy: 91.1412%, Training Loss: 0.2265%\n",
      "Epoch [49/300], Step [113/225], Training Accuracy: 91.1504%, Training Loss: 0.2265%\n",
      "Epoch [49/300], Step [114/225], Training Accuracy: 91.1458%, Training Loss: 0.2265%\n",
      "Epoch [49/300], Step [115/225], Training Accuracy: 91.1549%, Training Loss: 0.2267%\n",
      "Epoch [49/300], Step [116/225], Training Accuracy: 91.2042%, Training Loss: 0.2260%\n",
      "Epoch [49/300], Step [117/225], Training Accuracy: 91.1859%, Training Loss: 0.2259%\n",
      "Epoch [49/300], Step [118/225], Training Accuracy: 91.2209%, Training Loss: 0.2252%\n",
      "Epoch [49/300], Step [119/225], Training Accuracy: 91.2159%, Training Loss: 0.2252%\n",
      "Epoch [49/300], Step [120/225], Training Accuracy: 91.2500%, Training Loss: 0.2247%\n",
      "Epoch [49/300], Step [121/225], Training Accuracy: 91.2965%, Training Loss: 0.2240%\n",
      "Epoch [49/300], Step [122/225], Training Accuracy: 91.2910%, Training Loss: 0.2234%\n",
      "Epoch [49/300], Step [123/225], Training Accuracy: 91.2856%, Training Loss: 0.2233%\n",
      "Epoch [49/300], Step [124/225], Training Accuracy: 91.3054%, Training Loss: 0.2228%\n",
      "Epoch [49/300], Step [125/225], Training Accuracy: 91.2750%, Training Loss: 0.2228%\n",
      "Epoch [49/300], Step [126/225], Training Accuracy: 91.2946%, Training Loss: 0.2226%\n",
      "Epoch [49/300], Step [127/225], Training Accuracy: 91.3386%, Training Loss: 0.2219%\n",
      "Epoch [49/300], Step [128/225], Training Accuracy: 91.3330%, Training Loss: 0.2224%\n",
      "Epoch [49/300], Step [129/225], Training Accuracy: 91.3396%, Training Loss: 0.2229%\n",
      "Epoch [49/300], Step [130/225], Training Accuracy: 91.3822%, Training Loss: 0.2222%\n",
      "Epoch [49/300], Step [131/225], Training Accuracy: 91.4361%, Training Loss: 0.2212%\n",
      "Epoch [49/300], Step [132/225], Training Accuracy: 91.5009%, Training Loss: 0.2202%\n",
      "Epoch [49/300], Step [133/225], Training Accuracy: 91.4709%, Training Loss: 0.2206%\n",
      "Epoch [49/300], Step [134/225], Training Accuracy: 91.4529%, Training Loss: 0.2211%\n",
      "Epoch [49/300], Step [135/225], Training Accuracy: 91.4699%, Training Loss: 0.2207%\n",
      "Epoch [49/300], Step [136/225], Training Accuracy: 91.4867%, Training Loss: 0.2212%\n",
      "Epoch [49/300], Step [137/225], Training Accuracy: 91.4918%, Training Loss: 0.2207%\n",
      "Epoch [49/300], Step [138/225], Training Accuracy: 91.5195%, Training Loss: 0.2201%\n",
      "Epoch [49/300], Step [139/225], Training Accuracy: 91.5243%, Training Loss: 0.2200%\n",
      "Epoch [49/300], Step [140/225], Training Accuracy: 91.5402%, Training Loss: 0.2209%\n",
      "Epoch [49/300], Step [141/225], Training Accuracy: 91.5004%, Training Loss: 0.2213%\n",
      "Epoch [49/300], Step [142/225], Training Accuracy: 91.4943%, Training Loss: 0.2209%\n",
      "Epoch [49/300], Step [143/225], Training Accuracy: 91.5210%, Training Loss: 0.2203%\n",
      "Epoch [49/300], Step [144/225], Training Accuracy: 91.5256%, Training Loss: 0.2207%\n",
      "Epoch [49/300], Step [145/225], Training Accuracy: 91.5517%, Training Loss: 0.2205%\n",
      "Epoch [49/300], Step [146/225], Training Accuracy: 91.5668%, Training Loss: 0.2202%\n",
      "Epoch [49/300], Step [147/225], Training Accuracy: 91.5497%, Training Loss: 0.2205%\n",
      "Epoch [49/300], Step [148/225], Training Accuracy: 91.5963%, Training Loss: 0.2196%\n",
      "Epoch [49/300], Step [149/225], Training Accuracy: 91.5793%, Training Loss: 0.2198%\n",
      "Epoch [49/300], Step [150/225], Training Accuracy: 91.6042%, Training Loss: 0.2192%\n",
      "Epoch [49/300], Step [151/225], Training Accuracy: 91.6287%, Training Loss: 0.2190%\n",
      "Epoch [49/300], Step [152/225], Training Accuracy: 91.6324%, Training Loss: 0.2189%\n",
      "Epoch [49/300], Step [153/225], Training Accuracy: 91.6565%, Training Loss: 0.2185%\n",
      "Epoch [49/300], Step [154/225], Training Accuracy: 91.6700%, Training Loss: 0.2185%\n",
      "Epoch [49/300], Step [155/225], Training Accuracy: 91.6633%, Training Loss: 0.2187%\n",
      "Epoch [49/300], Step [156/225], Training Accuracy: 91.6667%, Training Loss: 0.2186%\n",
      "Epoch [49/300], Step [157/225], Training Accuracy: 91.6202%, Training Loss: 0.2189%\n",
      "Epoch [49/300], Step [158/225], Training Accuracy: 91.6535%, Training Loss: 0.2184%\n",
      "Epoch [49/300], Step [159/225], Training Accuracy: 91.6470%, Training Loss: 0.2185%\n",
      "Epoch [49/300], Step [160/225], Training Accuracy: 91.6113%, Training Loss: 0.2189%\n",
      "Epoch [49/300], Step [161/225], Training Accuracy: 91.6246%, Training Loss: 0.2186%\n",
      "Epoch [49/300], Step [162/225], Training Accuracy: 91.5992%, Training Loss: 0.2190%\n",
      "Epoch [49/300], Step [163/225], Training Accuracy: 91.6123%, Training Loss: 0.2191%\n",
      "Epoch [49/300], Step [164/225], Training Accuracy: 91.5777%, Training Loss: 0.2197%\n",
      "Epoch [49/300], Step [165/225], Training Accuracy: 91.5909%, Training Loss: 0.2198%\n",
      "Epoch [49/300], Step [166/225], Training Accuracy: 91.6227%, Training Loss: 0.2192%\n",
      "Epoch [49/300], Step [167/225], Training Accuracy: 91.6355%, Training Loss: 0.2189%\n",
      "Epoch [49/300], Step [168/225], Training Accuracy: 91.6574%, Training Loss: 0.2182%\n",
      "Epoch [49/300], Step [169/225], Training Accuracy: 91.6513%, Training Loss: 0.2182%\n",
      "Epoch [49/300], Step [170/225], Training Accuracy: 91.6728%, Training Loss: 0.2180%\n",
      "Epoch [49/300], Step [171/225], Training Accuracy: 91.6484%, Training Loss: 0.2182%\n",
      "Epoch [49/300], Step [172/225], Training Accuracy: 91.6606%, Training Loss: 0.2181%\n",
      "Epoch [49/300], Step [173/225], Training Accuracy: 91.6546%, Training Loss: 0.2183%\n",
      "Epoch [49/300], Step [174/225], Training Accuracy: 91.6756%, Training Loss: 0.2180%\n",
      "Epoch [49/300], Step [175/225], Training Accuracy: 91.6875%, Training Loss: 0.2179%\n",
      "Epoch [49/300], Step [176/225], Training Accuracy: 91.6637%, Training Loss: 0.2178%\n",
      "Epoch [49/300], Step [177/225], Training Accuracy: 91.6843%, Training Loss: 0.2173%\n",
      "Epoch [49/300], Step [178/225], Training Accuracy: 91.6696%, Training Loss: 0.2177%\n",
      "Epoch [49/300], Step [179/225], Training Accuracy: 91.6463%, Training Loss: 0.2180%\n",
      "Epoch [49/300], Step [180/225], Training Accuracy: 91.6580%, Training Loss: 0.2179%\n",
      "Epoch [49/300], Step [181/225], Training Accuracy: 91.6523%, Training Loss: 0.2189%\n",
      "Epoch [49/300], Step [182/225], Training Accuracy: 91.6724%, Training Loss: 0.2191%\n",
      "Epoch [49/300], Step [183/225], Training Accuracy: 91.7179%, Training Loss: 0.2184%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/300], Step [184/225], Training Accuracy: 91.7120%, Training Loss: 0.2184%\n",
      "Epoch [49/300], Step [185/225], Training Accuracy: 91.7145%, Training Loss: 0.2181%\n",
      "Epoch [49/300], Step [186/225], Training Accuracy: 91.7171%, Training Loss: 0.2178%\n",
      "Epoch [49/300], Step [187/225], Training Accuracy: 91.7363%, Training Loss: 0.2173%\n",
      "Epoch [49/300], Step [188/225], Training Accuracy: 91.7470%, Training Loss: 0.2169%\n",
      "Epoch [49/300], Step [189/225], Training Accuracy: 91.7576%, Training Loss: 0.2170%\n",
      "Epoch [49/300], Step [190/225], Training Accuracy: 91.7270%, Training Loss: 0.2174%\n",
      "Epoch [49/300], Step [191/225], Training Accuracy: 91.7457%, Training Loss: 0.2172%\n",
      "Epoch [49/300], Step [192/225], Training Accuracy: 91.7155%, Training Loss: 0.2177%\n",
      "Epoch [49/300], Step [193/225], Training Accuracy: 91.7017%, Training Loss: 0.2178%\n",
      "Epoch [49/300], Step [194/225], Training Accuracy: 91.7204%, Training Loss: 0.2172%\n",
      "Epoch [49/300], Step [195/225], Training Accuracy: 91.6827%, Training Loss: 0.2178%\n",
      "Epoch [49/300], Step [196/225], Training Accuracy: 91.6932%, Training Loss: 0.2179%\n",
      "Epoch [49/300], Step [197/225], Training Accuracy: 91.6957%, Training Loss: 0.2179%\n",
      "Epoch [49/300], Step [198/225], Training Accuracy: 91.6824%, Training Loss: 0.2180%\n",
      "Epoch [49/300], Step [199/225], Training Accuracy: 91.6928%, Training Loss: 0.2179%\n",
      "Epoch [49/300], Step [200/225], Training Accuracy: 91.6953%, Training Loss: 0.2180%\n",
      "Epoch [49/300], Step [201/225], Training Accuracy: 91.6978%, Training Loss: 0.2178%\n",
      "Epoch [49/300], Step [202/225], Training Accuracy: 91.7157%, Training Loss: 0.2176%\n",
      "Epoch [49/300], Step [203/225], Training Accuracy: 91.7103%, Training Loss: 0.2178%\n",
      "Epoch [49/300], Step [204/225], Training Accuracy: 91.7126%, Training Loss: 0.2178%\n",
      "Epoch [49/300], Step [205/225], Training Accuracy: 91.7530%, Training Loss: 0.2171%\n",
      "Epoch [49/300], Step [206/225], Training Accuracy: 91.7476%, Training Loss: 0.2176%\n",
      "Epoch [49/300], Step [207/225], Training Accuracy: 91.7346%, Training Loss: 0.2176%\n",
      "Epoch [49/300], Step [208/225], Training Accuracy: 91.7443%, Training Loss: 0.2172%\n",
      "Epoch [49/300], Step [209/225], Training Accuracy: 91.7389%, Training Loss: 0.2171%\n",
      "Epoch [49/300], Step [210/225], Training Accuracy: 91.7411%, Training Loss: 0.2169%\n",
      "Epoch [49/300], Step [211/225], Training Accuracy: 91.7432%, Training Loss: 0.2168%\n",
      "Epoch [49/300], Step [212/225], Training Accuracy: 91.7600%, Training Loss: 0.2165%\n",
      "Epoch [49/300], Step [213/225], Training Accuracy: 91.7767%, Training Loss: 0.2161%\n",
      "Epoch [49/300], Step [214/225], Training Accuracy: 91.7786%, Training Loss: 0.2157%\n",
      "Epoch [49/300], Step [215/225], Training Accuracy: 91.7878%, Training Loss: 0.2156%\n",
      "Epoch [49/300], Step [216/225], Training Accuracy: 91.7462%, Training Loss: 0.2165%\n",
      "Epoch [49/300], Step [217/225], Training Accuracy: 91.7555%, Training Loss: 0.2165%\n",
      "Epoch [49/300], Step [218/225], Training Accuracy: 91.7718%, Training Loss: 0.2162%\n",
      "Epoch [49/300], Step [219/225], Training Accuracy: 91.7880%, Training Loss: 0.2157%\n",
      "Epoch [49/300], Step [220/225], Training Accuracy: 91.7472%, Training Loss: 0.2165%\n",
      "Epoch [49/300], Step [221/225], Training Accuracy: 91.7350%, Training Loss: 0.2167%\n",
      "Epoch [49/300], Step [222/225], Training Accuracy: 91.7441%, Training Loss: 0.2166%\n",
      "Epoch [49/300], Step [223/225], Training Accuracy: 91.7531%, Training Loss: 0.2164%\n",
      "Epoch [49/300], Step [224/225], Training Accuracy: 91.7411%, Training Loss: 0.2168%\n",
      "Epoch [49/300], Step [225/225], Training Accuracy: 91.7454%, Training Loss: 0.2168%\n",
      "Epoch [50/300], Step [1/225], Training Accuracy: 96.8750%, Training Loss: 0.1675%\n",
      "Epoch [50/300], Step [2/225], Training Accuracy: 96.8750%, Training Loss: 0.1320%\n",
      "Epoch [50/300], Step [3/225], Training Accuracy: 95.3125%, Training Loss: 0.1666%\n",
      "Epoch [50/300], Step [4/225], Training Accuracy: 95.3125%, Training Loss: 0.1612%\n",
      "Epoch [50/300], Step [5/225], Training Accuracy: 95.6250%, Training Loss: 0.1550%\n",
      "Epoch [50/300], Step [6/225], Training Accuracy: 95.0521%, Training Loss: 0.1704%\n",
      "Epoch [50/300], Step [7/225], Training Accuracy: 93.9732%, Training Loss: 0.1774%\n",
      "Epoch [50/300], Step [8/225], Training Accuracy: 93.9453%, Training Loss: 0.1791%\n",
      "Epoch [50/300], Step [9/225], Training Accuracy: 93.9236%, Training Loss: 0.1760%\n",
      "Epoch [50/300], Step [10/225], Training Accuracy: 93.9062%, Training Loss: 0.1784%\n",
      "Epoch [50/300], Step [11/225], Training Accuracy: 93.7500%, Training Loss: 0.1797%\n",
      "Epoch [50/300], Step [12/225], Training Accuracy: 93.4896%, Training Loss: 0.1858%\n",
      "Epoch [50/300], Step [13/225], Training Accuracy: 93.1490%, Training Loss: 0.1949%\n",
      "Epoch [50/300], Step [14/225], Training Accuracy: 92.8571%, Training Loss: 0.1994%\n",
      "Epoch [50/300], Step [15/225], Training Accuracy: 93.1250%, Training Loss: 0.1918%\n",
      "Epoch [50/300], Step [16/225], Training Accuracy: 92.8711%, Training Loss: 0.1936%\n",
      "Epoch [50/300], Step [17/225], Training Accuracy: 92.7390%, Training Loss: 0.1968%\n",
      "Epoch [50/300], Step [18/225], Training Accuracy: 92.3611%, Training Loss: 0.2056%\n",
      "Epoch [50/300], Step [19/225], Training Accuracy: 92.5164%, Training Loss: 0.2014%\n",
      "Epoch [50/300], Step [20/225], Training Accuracy: 92.5000%, Training Loss: 0.2047%\n",
      "Epoch [50/300], Step [21/225], Training Accuracy: 92.4851%, Training Loss: 0.2020%\n",
      "Epoch [50/300], Step [22/225], Training Accuracy: 92.6136%, Training Loss: 0.2011%\n",
      "Epoch [50/300], Step [23/225], Training Accuracy: 92.7989%, Training Loss: 0.1983%\n",
      "Epoch [50/300], Step [24/225], Training Accuracy: 92.9036%, Training Loss: 0.1981%\n",
      "Epoch [50/300], Step [25/225], Training Accuracy: 92.8125%, Training Loss: 0.1996%\n",
      "Epoch [50/300], Step [26/225], Training Accuracy: 92.6683%, Training Loss: 0.2040%\n",
      "Epoch [50/300], Step [27/225], Training Accuracy: 92.5347%, Training Loss: 0.2058%\n",
      "Epoch [50/300], Step [28/225], Training Accuracy: 92.7455%, Training Loss: 0.2013%\n",
      "Epoch [50/300], Step [29/225], Training Accuracy: 92.5647%, Training Loss: 0.2040%\n",
      "Epoch [50/300], Step [30/225], Training Accuracy: 92.5521%, Training Loss: 0.2067%\n",
      "Epoch [50/300], Step [31/225], Training Accuracy: 92.4899%, Training Loss: 0.2079%\n",
      "Epoch [50/300], Step [32/225], Training Accuracy: 92.3340%, Training Loss: 0.2130%\n",
      "Epoch [50/300], Step [33/225], Training Accuracy: 92.3295%, Training Loss: 0.2128%\n",
      "Epoch [50/300], Step [34/225], Training Accuracy: 92.3254%, Training Loss: 0.2103%\n",
      "Epoch [50/300], Step [35/225], Training Accuracy: 92.3661%, Training Loss: 0.2103%\n",
      "Epoch [50/300], Step [36/225], Training Accuracy: 92.2309%, Training Loss: 0.2108%\n",
      "Epoch [50/300], Step [37/225], Training Accuracy: 92.3142%, Training Loss: 0.2113%\n",
      "Epoch [50/300], Step [38/225], Training Accuracy: 92.3931%, Training Loss: 0.2094%\n",
      "Epoch [50/300], Step [39/225], Training Accuracy: 92.2676%, Training Loss: 0.2105%\n",
      "Epoch [50/300], Step [40/225], Training Accuracy: 92.2656%, Training Loss: 0.2091%\n",
      "Epoch [50/300], Step [41/225], Training Accuracy: 92.1875%, Training Loss: 0.2103%\n",
      "Epoch [50/300], Step [42/225], Training Accuracy: 92.1131%, Training Loss: 0.2102%\n",
      "Epoch [50/300], Step [43/225], Training Accuracy: 92.0422%, Training Loss: 0.2106%\n",
      "Epoch [50/300], Step [44/225], Training Accuracy: 92.0810%, Training Loss: 0.2098%\n",
      "Epoch [50/300], Step [45/225], Training Accuracy: 92.1528%, Training Loss: 0.2073%\n",
      "Epoch [50/300], Step [46/225], Training Accuracy: 92.0856%, Training Loss: 0.2079%\n",
      "Epoch [50/300], Step [47/225], Training Accuracy: 92.0213%, Training Loss: 0.2102%\n",
      "Epoch [50/300], Step [48/225], Training Accuracy: 91.9922%, Training Loss: 0.2103%\n",
      "Epoch [50/300], Step [49/225], Training Accuracy: 92.0599%, Training Loss: 0.2097%\n",
      "Epoch [50/300], Step [50/225], Training Accuracy: 92.1875%, Training Loss: 0.2084%\n",
      "Epoch [50/300], Step [51/225], Training Accuracy: 92.2181%, Training Loss: 0.2081%\n",
      "Epoch [50/300], Step [52/225], Training Accuracy: 92.2776%, Training Loss: 0.2088%\n",
      "Epoch [50/300], Step [53/225], Training Accuracy: 92.2759%, Training Loss: 0.2095%\n",
      "Epoch [50/300], Step [54/225], Training Accuracy: 92.3032%, Training Loss: 0.2090%\n",
      "Epoch [50/300], Step [55/225], Training Accuracy: 92.3864%, Training Loss: 0.2072%\n",
      "Epoch [50/300], Step [56/225], Training Accuracy: 92.3270%, Training Loss: 0.2086%\n",
      "Epoch [50/300], Step [57/225], Training Accuracy: 92.2971%, Training Loss: 0.2102%\n",
      "Epoch [50/300], Step [58/225], Training Accuracy: 92.1606%, Training Loss: 0.2121%\n",
      "Epoch [50/300], Step [59/225], Training Accuracy: 92.1875%, Training Loss: 0.2119%\n",
      "Epoch [50/300], Step [60/225], Training Accuracy: 92.1615%, Training Loss: 0.2124%\n",
      "Epoch [50/300], Step [61/225], Training Accuracy: 92.1363%, Training Loss: 0.2133%\n",
      "Epoch [50/300], Step [62/225], Training Accuracy: 92.1623%, Training Loss: 0.2132%\n",
      "Epoch [50/300], Step [63/225], Training Accuracy: 92.2123%, Training Loss: 0.2135%\n",
      "Epoch [50/300], Step [64/225], Training Accuracy: 92.1387%, Training Loss: 0.2147%\n",
      "Epoch [50/300], Step [65/225], Training Accuracy: 92.1875%, Training Loss: 0.2136%\n",
      "Epoch [50/300], Step [66/225], Training Accuracy: 92.1875%, Training Loss: 0.2141%\n",
      "Epoch [50/300], Step [67/225], Training Accuracy: 92.2108%, Training Loss: 0.2141%\n",
      "Epoch [50/300], Step [68/225], Training Accuracy: 92.1645%, Training Loss: 0.2137%\n",
      "Epoch [50/300], Step [69/225], Training Accuracy: 92.2328%, Training Loss: 0.2124%\n",
      "Epoch [50/300], Step [70/225], Training Accuracy: 92.1875%, Training Loss: 0.2130%\n",
      "Epoch [50/300], Step [71/225], Training Accuracy: 92.1435%, Training Loss: 0.2145%\n",
      "Epoch [50/300], Step [72/225], Training Accuracy: 92.1658%, Training Loss: 0.2139%\n",
      "Epoch [50/300], Step [73/225], Training Accuracy: 92.2303%, Training Loss: 0.2126%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/300], Step [74/225], Training Accuracy: 92.1875%, Training Loss: 0.2138%\n",
      "Epoch [50/300], Step [75/225], Training Accuracy: 92.2083%, Training Loss: 0.2130%\n",
      "Epoch [50/300], Step [76/225], Training Accuracy: 92.2286%, Training Loss: 0.2138%\n",
      "Epoch [50/300], Step [77/225], Training Accuracy: 92.2281%, Training Loss: 0.2141%\n",
      "Epoch [50/300], Step [78/225], Training Accuracy: 92.2676%, Training Loss: 0.2143%\n",
      "Epoch [50/300], Step [79/225], Training Accuracy: 92.3062%, Training Loss: 0.2133%\n",
      "Epoch [50/300], Step [80/225], Training Accuracy: 92.3242%, Training Loss: 0.2141%\n",
      "Epoch [50/300], Step [81/225], Training Accuracy: 92.3418%, Training Loss: 0.2141%\n",
      "Epoch [50/300], Step [82/225], Training Accuracy: 92.3590%, Training Loss: 0.2132%\n",
      "Epoch [50/300], Step [83/225], Training Accuracy: 92.3569%, Training Loss: 0.2128%\n",
      "Epoch [50/300], Step [84/225], Training Accuracy: 92.2619%, Training Loss: 0.2139%\n",
      "Epoch [50/300], Step [85/225], Training Accuracy: 92.3162%, Training Loss: 0.2139%\n",
      "Epoch [50/300], Step [86/225], Training Accuracy: 92.3147%, Training Loss: 0.2138%\n",
      "Epoch [50/300], Step [87/225], Training Accuracy: 92.2953%, Training Loss: 0.2146%\n",
      "Epoch [50/300], Step [88/225], Training Accuracy: 92.2230%, Training Loss: 0.2148%\n",
      "Epoch [50/300], Step [89/225], Training Accuracy: 92.1875%, Training Loss: 0.2160%\n",
      "Epoch [50/300], Step [90/225], Training Accuracy: 92.1007%, Training Loss: 0.2181%\n",
      "Epoch [50/300], Step [91/225], Training Accuracy: 92.1188%, Training Loss: 0.2172%\n",
      "Epoch [50/300], Step [92/225], Training Accuracy: 92.1535%, Training Loss: 0.2165%\n",
      "Epoch [50/300], Step [93/225], Training Accuracy: 92.1707%, Training Loss: 0.2157%\n",
      "Epoch [50/300], Step [94/225], Training Accuracy: 92.1709%, Training Loss: 0.2158%\n",
      "Epoch [50/300], Step [95/225], Training Accuracy: 92.1382%, Training Loss: 0.2162%\n",
      "Epoch [50/300], Step [96/225], Training Accuracy: 92.2038%, Training Loss: 0.2150%\n",
      "Epoch [50/300], Step [97/225], Training Accuracy: 92.2036%, Training Loss: 0.2153%\n",
      "Epoch [50/300], Step [98/225], Training Accuracy: 92.2034%, Training Loss: 0.2153%\n",
      "Epoch [50/300], Step [99/225], Training Accuracy: 92.2348%, Training Loss: 0.2152%\n",
      "Epoch [50/300], Step [100/225], Training Accuracy: 92.1875%, Training Loss: 0.2159%\n",
      "Epoch [50/300], Step [101/225], Training Accuracy: 92.2494%, Training Loss: 0.2145%\n",
      "Epoch [50/300], Step [102/225], Training Accuracy: 92.2641%, Training Loss: 0.2146%\n",
      "Epoch [50/300], Step [103/225], Training Accuracy: 92.2482%, Training Loss: 0.2152%\n",
      "Epoch [50/300], Step [104/225], Training Accuracy: 92.2626%, Training Loss: 0.2150%\n",
      "Epoch [50/300], Step [105/225], Training Accuracy: 92.2470%, Training Loss: 0.2148%\n",
      "Epoch [50/300], Step [106/225], Training Accuracy: 92.2759%, Training Loss: 0.2142%\n",
      "Epoch [50/300], Step [107/225], Training Accuracy: 92.2605%, Training Loss: 0.2142%\n",
      "Epoch [50/300], Step [108/225], Training Accuracy: 92.2743%, Training Loss: 0.2140%\n",
      "Epoch [50/300], Step [109/225], Training Accuracy: 92.2878%, Training Loss: 0.2139%\n",
      "Epoch [50/300], Step [110/225], Training Accuracy: 92.3011%, Training Loss: 0.2135%\n",
      "Epoch [50/300], Step [111/225], Training Accuracy: 92.3142%, Training Loss: 0.2130%\n",
      "Epoch [50/300], Step [112/225], Training Accuracy: 92.3549%, Training Loss: 0.2125%\n",
      "Epoch [50/300], Step [113/225], Training Accuracy: 92.3673%, Training Loss: 0.2123%\n",
      "Epoch [50/300], Step [114/225], Training Accuracy: 92.3931%, Training Loss: 0.2120%\n",
      "Epoch [50/300], Step [115/225], Training Accuracy: 92.4321%, Training Loss: 0.2114%\n",
      "Epoch [50/300], Step [116/225], Training Accuracy: 92.4569%, Training Loss: 0.2112%\n",
      "Epoch [50/300], Step [117/225], Training Accuracy: 92.4412%, Training Loss: 0.2114%\n",
      "Epoch [50/300], Step [118/225], Training Accuracy: 92.3861%, Training Loss: 0.2124%\n",
      "Epoch [50/300], Step [119/225], Training Accuracy: 92.3582%, Training Loss: 0.2126%\n",
      "Epoch [50/300], Step [120/225], Training Accuracy: 92.3958%, Training Loss: 0.2119%\n",
      "Epoch [50/300], Step [121/225], Training Accuracy: 92.3941%, Training Loss: 0.2116%\n",
      "Epoch [50/300], Step [122/225], Training Accuracy: 92.4052%, Training Loss: 0.2111%\n",
      "Epoch [50/300], Step [123/225], Training Accuracy: 92.4416%, Training Loss: 0.2106%\n",
      "Epoch [50/300], Step [124/225], Training Accuracy: 92.4269%, Training Loss: 0.2105%\n",
      "Epoch [50/300], Step [125/225], Training Accuracy: 92.4375%, Training Loss: 0.2101%\n",
      "Epoch [50/300], Step [126/225], Training Accuracy: 92.4851%, Training Loss: 0.2090%\n",
      "Epoch [50/300], Step [127/225], Training Accuracy: 92.4582%, Training Loss: 0.2093%\n",
      "Epoch [50/300], Step [128/225], Training Accuracy: 92.4805%, Training Loss: 0.2094%\n",
      "Epoch [50/300], Step [129/225], Training Accuracy: 92.4540%, Training Loss: 0.2095%\n",
      "Epoch [50/300], Step [130/225], Training Accuracy: 92.4279%, Training Loss: 0.2100%\n",
      "Epoch [50/300], Step [131/225], Training Accuracy: 92.4738%, Training Loss: 0.2089%\n",
      "Epoch [50/300], Step [132/225], Training Accuracy: 92.4598%, Training Loss: 0.2092%\n",
      "Epoch [50/300], Step [133/225], Training Accuracy: 92.4460%, Training Loss: 0.2093%\n",
      "Epoch [50/300], Step [134/225], Training Accuracy: 92.4440%, Training Loss: 0.2094%\n",
      "Epoch [50/300], Step [135/225], Training Accuracy: 92.4653%, Training Loss: 0.2090%\n",
      "Epoch [50/300], Step [136/225], Training Accuracy: 92.4403%, Training Loss: 0.2099%\n",
      "Epoch [50/300], Step [137/225], Training Accuracy: 92.4498%, Training Loss: 0.2093%\n",
      "Epoch [50/300], Step [138/225], Training Accuracy: 92.4706%, Training Loss: 0.2087%\n",
      "Epoch [50/300], Step [139/225], Training Accuracy: 92.4685%, Training Loss: 0.2089%\n",
      "Epoch [50/300], Step [140/225], Training Accuracy: 92.4665%, Training Loss: 0.2093%\n",
      "Epoch [50/300], Step [141/225], Training Accuracy: 92.4535%, Training Loss: 0.2092%\n",
      "Epoch [50/300], Step [142/225], Training Accuracy: 92.4626%, Training Loss: 0.2092%\n",
      "Epoch [50/300], Step [143/225], Training Accuracy: 92.4825%, Training Loss: 0.2086%\n",
      "Epoch [50/300], Step [144/225], Training Accuracy: 92.5347%, Training Loss: 0.2076%\n",
      "Epoch [50/300], Step [145/225], Training Accuracy: 92.5216%, Training Loss: 0.2073%\n",
      "Epoch [50/300], Step [146/225], Training Accuracy: 92.5514%, Training Loss: 0.2066%\n",
      "Epoch [50/300], Step [147/225], Training Accuracy: 92.5914%, Training Loss: 0.2058%\n",
      "Epoch [50/300], Step [148/225], Training Accuracy: 92.5781%, Training Loss: 0.2057%\n",
      "Epoch [50/300], Step [149/225], Training Accuracy: 92.5755%, Training Loss: 0.2060%\n",
      "Epoch [50/300], Step [150/225], Training Accuracy: 92.5938%, Training Loss: 0.2056%\n",
      "Epoch [50/300], Step [151/225], Training Accuracy: 92.6118%, Training Loss: 0.2051%\n",
      "Epoch [50/300], Step [152/225], Training Accuracy: 92.6295%, Training Loss: 0.2050%\n",
      "Epoch [50/300], Step [153/225], Training Accuracy: 92.6368%, Training Loss: 0.2045%\n",
      "Epoch [50/300], Step [154/225], Training Accuracy: 92.6339%, Training Loss: 0.2045%\n",
      "Epoch [50/300], Step [155/225], Training Accuracy: 92.6714%, Training Loss: 0.2039%\n",
      "Epoch [50/300], Step [156/225], Training Accuracy: 92.6683%, Training Loss: 0.2039%\n",
      "Epoch [50/300], Step [157/225], Training Accuracy: 92.6652%, Training Loss: 0.2038%\n",
      "Epoch [50/300], Step [158/225], Training Accuracy: 92.6820%, Training Loss: 0.2035%\n",
      "Epoch [50/300], Step [159/225], Training Accuracy: 92.6985%, Training Loss: 0.2033%\n",
      "Epoch [50/300], Step [160/225], Training Accuracy: 92.6953%, Training Loss: 0.2031%\n",
      "Epoch [50/300], Step [161/225], Training Accuracy: 92.7116%, Training Loss: 0.2026%\n",
      "Epoch [50/300], Step [162/225], Training Accuracy: 92.7276%, Training Loss: 0.2022%\n",
      "Epoch [50/300], Step [163/225], Training Accuracy: 92.7339%, Training Loss: 0.2022%\n",
      "Epoch [50/300], Step [164/225], Training Accuracy: 92.7401%, Training Loss: 0.2021%\n",
      "Epoch [50/300], Step [165/225], Training Accuracy: 92.7462%, Training Loss: 0.2019%\n",
      "Epoch [50/300], Step [166/225], Training Accuracy: 92.7240%, Training Loss: 0.2025%\n",
      "Epoch [50/300], Step [167/225], Training Accuracy: 92.7395%, Training Loss: 0.2024%\n",
      "Epoch [50/300], Step [168/225], Training Accuracy: 92.7362%, Training Loss: 0.2023%\n",
      "Epoch [50/300], Step [169/225], Training Accuracy: 92.7053%, Training Loss: 0.2029%\n",
      "Epoch [50/300], Step [170/225], Training Accuracy: 92.6838%, Training Loss: 0.2035%\n",
      "Epoch [50/300], Step [171/225], Training Accuracy: 92.6901%, Training Loss: 0.2034%\n",
      "Epoch [50/300], Step [172/225], Training Accuracy: 92.7144%, Training Loss: 0.2029%\n",
      "Epoch [50/300], Step [173/225], Training Accuracy: 92.7113%, Training Loss: 0.2027%\n",
      "Epoch [50/300], Step [174/225], Training Accuracy: 92.7173%, Training Loss: 0.2025%\n",
      "Epoch [50/300], Step [175/225], Training Accuracy: 92.7500%, Training Loss: 0.2019%\n",
      "Epoch [50/300], Step [176/225], Training Accuracy: 92.7379%, Training Loss: 0.2019%\n",
      "Epoch [50/300], Step [177/225], Training Accuracy: 92.7525%, Training Loss: 0.2015%\n",
      "Epoch [50/300], Step [178/225], Training Accuracy: 92.7493%, Training Loss: 0.2014%\n",
      "Epoch [50/300], Step [179/225], Training Accuracy: 92.7549%, Training Loss: 0.2018%\n",
      "Epoch [50/300], Step [180/225], Training Accuracy: 92.6997%, Training Loss: 0.2030%\n",
      "Epoch [50/300], Step [181/225], Training Accuracy: 92.6796%, Training Loss: 0.2030%\n",
      "Epoch [50/300], Step [182/225], Training Accuracy: 92.6940%, Training Loss: 0.2027%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/300], Step [183/225], Training Accuracy: 92.7083%, Training Loss: 0.2022%\n",
      "Epoch [50/300], Step [184/225], Training Accuracy: 92.7140%, Training Loss: 0.2020%\n",
      "Epoch [50/300], Step [185/225], Training Accuracy: 92.7111%, Training Loss: 0.2020%\n",
      "Epoch [50/300], Step [186/225], Training Accuracy: 92.7419%, Training Loss: 0.2015%\n",
      "Epoch [50/300], Step [187/225], Training Accuracy: 92.7390%, Training Loss: 0.2014%\n",
      "Epoch [50/300], Step [188/225], Training Accuracy: 92.7527%, Training Loss: 0.2011%\n",
      "Epoch [50/300], Step [189/225], Training Accuracy: 92.7662%, Training Loss: 0.2007%\n",
      "Epoch [50/300], Step [190/225], Training Accuracy: 92.7467%, Training Loss: 0.2012%\n",
      "Epoch [50/300], Step [191/225], Training Accuracy: 92.7601%, Training Loss: 0.2011%\n",
      "Epoch [50/300], Step [192/225], Training Accuracy: 92.7409%, Training Loss: 0.2014%\n",
      "Epoch [50/300], Step [193/225], Training Accuracy: 92.7299%, Training Loss: 0.2016%\n",
      "Epoch [50/300], Step [194/225], Training Accuracy: 92.7432%, Training Loss: 0.2012%\n",
      "Epoch [50/300], Step [195/225], Training Accuracy: 92.7484%, Training Loss: 0.2010%\n",
      "Epoch [50/300], Step [196/225], Training Accuracy: 92.7535%, Training Loss: 0.2011%\n",
      "Epoch [50/300], Step [197/225], Training Accuracy: 92.7189%, Training Loss: 0.2022%\n",
      "Epoch [50/300], Step [198/225], Training Accuracy: 92.7004%, Training Loss: 0.2023%\n",
      "Epoch [50/300], Step [199/225], Training Accuracy: 92.7136%, Training Loss: 0.2019%\n",
      "Epoch [50/300], Step [200/225], Training Accuracy: 92.7188%, Training Loss: 0.2021%\n",
      "Epoch [50/300], Step [201/225], Training Accuracy: 92.7239%, Training Loss: 0.2021%\n",
      "Epoch [50/300], Step [202/225], Training Accuracy: 92.6980%, Training Loss: 0.2026%\n",
      "Epoch [50/300], Step [203/225], Training Accuracy: 92.7109%, Training Loss: 0.2025%\n",
      "Epoch [50/300], Step [204/225], Training Accuracy: 92.7313%, Training Loss: 0.2023%\n",
      "Epoch [50/300], Step [205/225], Training Accuracy: 92.7210%, Training Loss: 0.2024%\n",
      "Epoch [50/300], Step [206/225], Training Accuracy: 92.7033%, Training Loss: 0.2031%\n",
      "Epoch [50/300], Step [207/225], Training Accuracy: 92.7159%, Training Loss: 0.2028%\n",
      "Epoch [50/300], Step [208/225], Training Accuracy: 92.6833%, Training Loss: 0.2034%\n",
      "Epoch [50/300], Step [209/225], Training Accuracy: 92.6809%, Training Loss: 0.2033%\n",
      "Epoch [50/300], Step [210/225], Training Accuracy: 92.6637%, Training Loss: 0.2036%\n",
      "Epoch [50/300], Step [211/225], Training Accuracy: 92.6762%, Training Loss: 0.2035%\n",
      "Epoch [50/300], Step [212/225], Training Accuracy: 92.7034%, Training Loss: 0.2030%\n",
      "Epoch [50/300], Step [213/225], Training Accuracy: 92.7303%, Training Loss: 0.2026%\n",
      "Epoch [50/300], Step [214/225], Training Accuracy: 92.7424%, Training Loss: 0.2023%\n",
      "Epoch [50/300], Step [215/225], Training Accuracy: 92.7326%, Training Loss: 0.2025%\n",
      "Epoch [50/300], Step [216/225], Training Accuracy: 92.7228%, Training Loss: 0.2027%\n",
      "Epoch [50/300], Step [217/225], Training Accuracy: 92.7203%, Training Loss: 0.2026%\n",
      "Epoch [50/300], Step [218/225], Training Accuracy: 92.7179%, Training Loss: 0.2025%\n",
      "Epoch [50/300], Step [219/225], Training Accuracy: 92.7226%, Training Loss: 0.2025%\n",
      "Epoch [50/300], Step [220/225], Training Accuracy: 92.7344%, Training Loss: 0.2022%\n",
      "Epoch [50/300], Step [221/225], Training Accuracy: 92.7319%, Training Loss: 0.2023%\n",
      "Epoch [50/300], Step [222/225], Training Accuracy: 92.7435%, Training Loss: 0.2020%\n",
      "Epoch [50/300], Step [223/225], Training Accuracy: 92.7480%, Training Loss: 0.2022%\n",
      "Epoch [50/300], Step [224/225], Training Accuracy: 92.7595%, Training Loss: 0.2019%\n",
      "Epoch [50/300], Step [225/225], Training Accuracy: 92.7668%, Training Loss: 0.2018%\n",
      "Epoch [51/300], Step [1/225], Training Accuracy: 93.7500%, Training Loss: 0.1263%\n",
      "Epoch [51/300], Step [2/225], Training Accuracy: 88.2812%, Training Loss: 0.2684%\n",
      "Epoch [51/300], Step [3/225], Training Accuracy: 90.1042%, Training Loss: 0.2545%\n",
      "Epoch [51/300], Step [4/225], Training Accuracy: 90.6250%, Training Loss: 0.2343%\n",
      "Epoch [51/300], Step [5/225], Training Accuracy: 91.8750%, Training Loss: 0.2041%\n",
      "Epoch [51/300], Step [6/225], Training Accuracy: 92.1875%, Training Loss: 0.2056%\n",
      "Epoch [51/300], Step [7/225], Training Accuracy: 92.1875%, Training Loss: 0.2061%\n",
      "Epoch [51/300], Step [8/225], Training Accuracy: 92.7734%, Training Loss: 0.1964%\n",
      "Epoch [51/300], Step [9/225], Training Accuracy: 92.8819%, Training Loss: 0.1876%\n",
      "Epoch [51/300], Step [10/225], Training Accuracy: 93.2812%, Training Loss: 0.1815%\n",
      "Epoch [51/300], Step [11/225], Training Accuracy: 93.1818%, Training Loss: 0.1820%\n",
      "Epoch [51/300], Step [12/225], Training Accuracy: 93.2292%, Training Loss: 0.1776%\n",
      "Epoch [51/300], Step [13/225], Training Accuracy: 92.4279%, Training Loss: 0.1927%\n",
      "Epoch [51/300], Step [14/225], Training Accuracy: 92.7455%, Training Loss: 0.1888%\n",
      "Epoch [51/300], Step [15/225], Training Accuracy: 93.1250%, Training Loss: 0.1836%\n",
      "Epoch [51/300], Step [16/225], Training Accuracy: 93.1641%, Training Loss: 0.1855%\n",
      "Epoch [51/300], Step [17/225], Training Accuracy: 93.1985%, Training Loss: 0.1856%\n",
      "Epoch [51/300], Step [18/225], Training Accuracy: 93.3160%, Training Loss: 0.1857%\n",
      "Epoch [51/300], Step [19/225], Training Accuracy: 93.3388%, Training Loss: 0.1886%\n",
      "Epoch [51/300], Step [20/225], Training Accuracy: 93.2812%, Training Loss: 0.1920%\n",
      "Epoch [51/300], Step [21/225], Training Accuracy: 93.4524%, Training Loss: 0.1883%\n",
      "Epoch [51/300], Step [22/225], Training Accuracy: 93.4659%, Training Loss: 0.1893%\n",
      "Epoch [51/300], Step [23/225], Training Accuracy: 93.4783%, Training Loss: 0.1876%\n",
      "Epoch [51/300], Step [24/225], Training Accuracy: 93.0990%, Training Loss: 0.1932%\n",
      "Epoch [51/300], Step [25/225], Training Accuracy: 93.2500%, Training Loss: 0.1913%\n",
      "Epoch [51/300], Step [26/225], Training Accuracy: 93.2091%, Training Loss: 0.1912%\n",
      "Epoch [51/300], Step [27/225], Training Accuracy: 93.1134%, Training Loss: 0.1923%\n",
      "Epoch [51/300], Step [28/225], Training Accuracy: 93.2478%, Training Loss: 0.1886%\n",
      "Epoch [51/300], Step [29/225], Training Accuracy: 93.2651%, Training Loss: 0.1877%\n",
      "Epoch [51/300], Step [30/225], Training Accuracy: 93.3333%, Training Loss: 0.1861%\n",
      "Epoch [51/300], Step [31/225], Training Accuracy: 93.2964%, Training Loss: 0.1883%\n",
      "Epoch [51/300], Step [32/225], Training Accuracy: 93.4082%, Training Loss: 0.1872%\n",
      "Epoch [51/300], Step [33/225], Training Accuracy: 93.3239%, Training Loss: 0.1876%\n",
      "Epoch [51/300], Step [34/225], Training Accuracy: 93.4743%, Training Loss: 0.1848%\n",
      "Epoch [51/300], Step [35/225], Training Accuracy: 93.3036%, Training Loss: 0.1858%\n",
      "Epoch [51/300], Step [36/225], Training Accuracy: 93.4028%, Training Loss: 0.1841%\n",
      "Epoch [51/300], Step [37/225], Training Accuracy: 93.3277%, Training Loss: 0.1840%\n",
      "Epoch [51/300], Step [38/225], Training Accuracy: 93.2977%, Training Loss: 0.1840%\n",
      "Epoch [51/300], Step [39/225], Training Accuracy: 93.3494%, Training Loss: 0.1829%\n",
      "Epoch [51/300], Step [40/225], Training Accuracy: 93.3594%, Training Loss: 0.1823%\n",
      "Epoch [51/300], Step [41/225], Training Accuracy: 93.2546%, Training Loss: 0.1842%\n",
      "Epoch [51/300], Step [42/225], Training Accuracy: 93.3036%, Training Loss: 0.1823%\n",
      "Epoch [51/300], Step [43/225], Training Accuracy: 93.3866%, Training Loss: 0.1810%\n",
      "Epoch [51/300], Step [44/225], Training Accuracy: 93.4304%, Training Loss: 0.1810%\n",
      "Epoch [51/300], Step [45/225], Training Accuracy: 93.3681%, Training Loss: 0.1810%\n",
      "Epoch [51/300], Step [46/225], Training Accuracy: 93.4103%, Training Loss: 0.1794%\n",
      "Epoch [51/300], Step [47/225], Training Accuracy: 93.4840%, Training Loss: 0.1775%\n",
      "Epoch [51/300], Step [48/225], Training Accuracy: 93.4570%, Training Loss: 0.1779%\n",
      "Epoch [51/300], Step [49/225], Training Accuracy: 93.5268%, Training Loss: 0.1764%\n",
      "Epoch [51/300], Step [50/225], Training Accuracy: 93.4688%, Training Loss: 0.1777%\n",
      "Epoch [51/300], Step [51/225], Training Accuracy: 93.4743%, Training Loss: 0.1769%\n",
      "Epoch [51/300], Step [52/225], Training Accuracy: 93.4195%, Training Loss: 0.1760%\n",
      "Epoch [51/300], Step [53/225], Training Accuracy: 93.4257%, Training Loss: 0.1772%\n",
      "Epoch [51/300], Step [54/225], Training Accuracy: 93.4028%, Training Loss: 0.1778%\n",
      "Epoch [51/300], Step [55/225], Training Accuracy: 93.4375%, Training Loss: 0.1775%\n",
      "Epoch [51/300], Step [56/225], Training Accuracy: 93.3873%, Training Loss: 0.1784%\n",
      "Epoch [51/300], Step [57/225], Training Accuracy: 93.3936%, Training Loss: 0.1788%\n",
      "Epoch [51/300], Step [58/225], Training Accuracy: 93.3998%, Training Loss: 0.1784%\n",
      "Epoch [51/300], Step [59/225], Training Accuracy: 93.4322%, Training Loss: 0.1780%\n",
      "Epoch [51/300], Step [60/225], Training Accuracy: 93.4115%, Training Loss: 0.1786%\n",
      "Epoch [51/300], Step [61/225], Training Accuracy: 93.3658%, Training Loss: 0.1792%\n",
      "Epoch [51/300], Step [62/225], Training Accuracy: 93.4224%, Training Loss: 0.1783%\n",
      "Epoch [51/300], Step [63/225], Training Accuracy: 93.4772%, Training Loss: 0.1779%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/300], Step [64/225], Training Accuracy: 93.5059%, Training Loss: 0.1770%\n",
      "Epoch [51/300], Step [65/225], Training Accuracy: 93.5577%, Training Loss: 0.1757%\n",
      "Epoch [51/300], Step [66/225], Training Accuracy: 93.5606%, Training Loss: 0.1762%\n",
      "Epoch [51/300], Step [67/225], Training Accuracy: 93.6101%, Training Loss: 0.1755%\n",
      "Epoch [51/300], Step [68/225], Training Accuracy: 93.6581%, Training Loss: 0.1747%\n",
      "Epoch [51/300], Step [69/225], Training Accuracy: 93.6821%, Training Loss: 0.1742%\n",
      "Epoch [51/300], Step [70/225], Training Accuracy: 93.7054%, Training Loss: 0.1741%\n",
      "Epoch [51/300], Step [71/225], Training Accuracy: 93.6840%, Training Loss: 0.1735%\n",
      "Epoch [51/300], Step [72/225], Training Accuracy: 93.7066%, Training Loss: 0.1731%\n",
      "Epoch [51/300], Step [73/225], Training Accuracy: 93.6430%, Training Loss: 0.1732%\n",
      "Epoch [51/300], Step [74/225], Training Accuracy: 93.6022%, Training Loss: 0.1741%\n",
      "Epoch [51/300], Step [75/225], Training Accuracy: 93.5625%, Training Loss: 0.1755%\n",
      "Epoch [51/300], Step [76/225], Training Accuracy: 93.5650%, Training Loss: 0.1753%\n",
      "Epoch [51/300], Step [77/225], Training Accuracy: 93.5268%, Training Loss: 0.1763%\n",
      "Epoch [51/300], Step [78/225], Training Accuracy: 93.5296%, Training Loss: 0.1763%\n",
      "Epoch [51/300], Step [79/225], Training Accuracy: 93.4533%, Training Loss: 0.1771%\n",
      "Epoch [51/300], Step [80/225], Training Accuracy: 93.3984%, Training Loss: 0.1779%\n",
      "Epoch [51/300], Step [81/225], Training Accuracy: 93.3835%, Training Loss: 0.1778%\n",
      "Epoch [51/300], Step [82/225], Training Accuracy: 93.3880%, Training Loss: 0.1776%\n",
      "Epoch [51/300], Step [83/225], Training Accuracy: 93.2982%, Training Loss: 0.1793%\n",
      "Epoch [51/300], Step [84/225], Training Accuracy: 93.3036%, Training Loss: 0.1786%\n",
      "Epoch [51/300], Step [85/225], Training Accuracy: 93.3088%, Training Loss: 0.1781%\n",
      "Epoch [51/300], Step [86/225], Training Accuracy: 93.2594%, Training Loss: 0.1782%\n",
      "Epoch [51/300], Step [87/225], Training Accuracy: 93.2471%, Training Loss: 0.1785%\n",
      "Epoch [51/300], Step [88/225], Training Accuracy: 93.2173%, Training Loss: 0.1799%\n",
      "Epoch [51/300], Step [89/225], Training Accuracy: 93.2409%, Training Loss: 0.1794%\n",
      "Epoch [51/300], Step [90/225], Training Accuracy: 93.2812%, Training Loss: 0.1784%\n",
      "Epoch [51/300], Step [91/225], Training Accuracy: 93.3379%, Training Loss: 0.1776%\n",
      "Epoch [51/300], Step [92/225], Training Accuracy: 93.3764%, Training Loss: 0.1766%\n",
      "Epoch [51/300], Step [93/225], Training Accuracy: 93.3804%, Training Loss: 0.1766%\n",
      "Epoch [51/300], Step [94/225], Training Accuracy: 93.4009%, Training Loss: 0.1761%\n",
      "Epoch [51/300], Step [95/225], Training Accuracy: 93.3882%, Training Loss: 0.1761%\n",
      "Epoch [51/300], Step [96/225], Training Accuracy: 93.4082%, Training Loss: 0.1762%\n",
      "Epoch [51/300], Step [97/225], Training Accuracy: 93.4439%, Training Loss: 0.1756%\n",
      "Epoch [51/300], Step [98/225], Training Accuracy: 93.4311%, Training Loss: 0.1756%\n",
      "Epoch [51/300], Step [99/225], Training Accuracy: 93.4659%, Training Loss: 0.1751%\n",
      "Epoch [51/300], Step [100/225], Training Accuracy: 93.4844%, Training Loss: 0.1744%\n",
      "Epoch [51/300], Step [101/225], Training Accuracy: 93.5334%, Training Loss: 0.1734%\n",
      "Epoch [51/300], Step [102/225], Training Accuracy: 93.5049%, Training Loss: 0.1734%\n",
      "Epoch [51/300], Step [103/225], Training Accuracy: 93.5073%, Training Loss: 0.1737%\n",
      "Epoch [51/300], Step [104/225], Training Accuracy: 93.5096%, Training Loss: 0.1733%\n",
      "Epoch [51/300], Step [105/225], Training Accuracy: 93.4970%, Training Loss: 0.1739%\n",
      "Epoch [51/300], Step [106/225], Training Accuracy: 93.4847%, Training Loss: 0.1744%\n",
      "Epoch [51/300], Step [107/225], Training Accuracy: 93.5164%, Training Loss: 0.1741%\n",
      "Epoch [51/300], Step [108/225], Training Accuracy: 93.5185%, Training Loss: 0.1742%\n",
      "Epoch [51/300], Step [109/225], Training Accuracy: 93.5780%, Training Loss: 0.1734%\n",
      "Epoch [51/300], Step [110/225], Training Accuracy: 93.6222%, Training Loss: 0.1726%\n",
      "Epoch [51/300], Step [111/225], Training Accuracy: 93.6233%, Training Loss: 0.1722%\n",
      "Epoch [51/300], Step [112/225], Training Accuracy: 93.6384%, Training Loss: 0.1718%\n",
      "Epoch [51/300], Step [113/225], Training Accuracy: 93.6394%, Training Loss: 0.1713%\n",
      "Epoch [51/300], Step [114/225], Training Accuracy: 93.6952%, Training Loss: 0.1704%\n",
      "Epoch [51/300], Step [115/225], Training Accuracy: 93.7228%, Training Loss: 0.1699%\n",
      "Epoch [51/300], Step [116/225], Training Accuracy: 93.7365%, Training Loss: 0.1696%\n",
      "Epoch [51/300], Step [117/225], Training Accuracy: 93.7634%, Training Loss: 0.1688%\n",
      "Epoch [51/300], Step [118/225], Training Accuracy: 93.7632%, Training Loss: 0.1683%\n",
      "Epoch [51/300], Step [119/225], Training Accuracy: 93.7763%, Training Loss: 0.1682%\n",
      "Epoch [51/300], Step [120/225], Training Accuracy: 93.7891%, Training Loss: 0.1681%\n",
      "Epoch [51/300], Step [121/225], Training Accuracy: 93.8146%, Training Loss: 0.1675%\n",
      "Epoch [51/300], Step [122/225], Training Accuracy: 93.8525%, Training Loss: 0.1666%\n",
      "Epoch [51/300], Step [123/225], Training Accuracy: 93.8643%, Training Loss: 0.1663%\n",
      "Epoch [51/300], Step [124/225], Training Accuracy: 93.8634%, Training Loss: 0.1659%\n",
      "Epoch [51/300], Step [125/225], Training Accuracy: 93.8750%, Training Loss: 0.1662%\n",
      "Epoch [51/300], Step [126/225], Training Accuracy: 93.9112%, Training Loss: 0.1655%\n",
      "Epoch [51/300], Step [127/225], Training Accuracy: 93.9345%, Training Loss: 0.1652%\n",
      "Epoch [51/300], Step [128/225], Training Accuracy: 93.9575%, Training Loss: 0.1653%\n",
      "Epoch [51/300], Step [129/225], Training Accuracy: 93.9801%, Training Loss: 0.1650%\n",
      "Epoch [51/300], Step [130/225], Training Accuracy: 93.9904%, Training Loss: 0.1649%\n",
      "Epoch [51/300], Step [131/225], Training Accuracy: 94.0005%, Training Loss: 0.1646%\n",
      "Epoch [51/300], Step [132/225], Training Accuracy: 94.0341%, Training Loss: 0.1640%\n",
      "Epoch [51/300], Step [133/225], Training Accuracy: 93.9850%, Training Loss: 0.1649%\n",
      "Epoch [51/300], Step [134/225], Training Accuracy: 94.0065%, Training Loss: 0.1646%\n",
      "Epoch [51/300], Step [135/225], Training Accuracy: 94.0162%, Training Loss: 0.1640%\n",
      "Epoch [51/300], Step [136/225], Training Accuracy: 93.9913%, Training Loss: 0.1648%\n",
      "Epoch [51/300], Step [137/225], Training Accuracy: 94.0123%, Training Loss: 0.1646%\n",
      "Epoch [51/300], Step [138/225], Training Accuracy: 94.0217%, Training Loss: 0.1647%\n",
      "Epoch [51/300], Step [139/225], Training Accuracy: 94.0423%, Training Loss: 0.1645%\n",
      "Epoch [51/300], Step [140/225], Training Accuracy: 94.0513%, Training Loss: 0.1644%\n",
      "Epoch [51/300], Step [141/225], Training Accuracy: 94.0270%, Training Loss: 0.1650%\n",
      "Epoch [51/300], Step [142/225], Training Accuracy: 94.0361%, Training Loss: 0.1644%\n",
      "Epoch [51/300], Step [143/225], Training Accuracy: 94.0559%, Training Loss: 0.1640%\n",
      "Epoch [51/300], Step [144/225], Training Accuracy: 94.0755%, Training Loss: 0.1636%\n",
      "Epoch [51/300], Step [145/225], Training Accuracy: 94.0948%, Training Loss: 0.1633%\n",
      "Epoch [51/300], Step [146/225], Training Accuracy: 94.1032%, Training Loss: 0.1633%\n",
      "Epoch [51/300], Step [147/225], Training Accuracy: 94.1008%, Training Loss: 0.1632%\n",
      "Epoch [51/300], Step [148/225], Training Accuracy: 94.1195%, Training Loss: 0.1628%\n",
      "Epoch [51/300], Step [149/225], Training Accuracy: 94.1170%, Training Loss: 0.1630%\n",
      "Epoch [51/300], Step [150/225], Training Accuracy: 94.1354%, Training Loss: 0.1625%\n",
      "Epoch [51/300], Step [151/225], Training Accuracy: 94.1536%, Training Loss: 0.1622%\n",
      "Epoch [51/300], Step [152/225], Training Accuracy: 94.1612%, Training Loss: 0.1620%\n",
      "Epoch [51/300], Step [153/225], Training Accuracy: 94.1789%, Training Loss: 0.1619%\n",
      "Epoch [51/300], Step [154/225], Training Accuracy: 94.1761%, Training Loss: 0.1618%\n",
      "Epoch [51/300], Step [155/225], Training Accuracy: 94.2036%, Training Loss: 0.1612%\n",
      "Epoch [51/300], Step [156/225], Training Accuracy: 94.2208%, Training Loss: 0.1610%\n",
      "Epoch [51/300], Step [157/225], Training Accuracy: 94.1879%, Training Loss: 0.1613%\n",
      "Epoch [51/300], Step [158/225], Training Accuracy: 94.2049%, Training Loss: 0.1611%\n",
      "Epoch [51/300], Step [159/225], Training Accuracy: 94.2217%, Training Loss: 0.1609%\n",
      "Epoch [51/300], Step [160/225], Training Accuracy: 94.2188%, Training Loss: 0.1604%\n",
      "Epoch [51/300], Step [161/225], Training Accuracy: 94.2352%, Training Loss: 0.1603%\n",
      "Epoch [51/300], Step [162/225], Training Accuracy: 94.2419%, Training Loss: 0.1600%\n",
      "Epoch [51/300], Step [163/225], Training Accuracy: 94.2389%, Training Loss: 0.1601%\n",
      "Epoch [51/300], Step [164/225], Training Accuracy: 94.2359%, Training Loss: 0.1604%\n",
      "Epoch [51/300], Step [165/225], Training Accuracy: 94.2330%, Training Loss: 0.1602%\n",
      "Epoch [51/300], Step [166/225], Training Accuracy: 94.2489%, Training Loss: 0.1601%\n",
      "Epoch [51/300], Step [167/225], Training Accuracy: 94.2459%, Training Loss: 0.1603%\n",
      "Epoch [51/300], Step [168/225], Training Accuracy: 94.2429%, Training Loss: 0.1603%\n",
      "Epoch [51/300], Step [169/225], Training Accuracy: 94.2400%, Training Loss: 0.1606%\n",
      "Epoch [51/300], Step [170/225], Training Accuracy: 94.1912%, Training Loss: 0.1609%\n",
      "Epoch [51/300], Step [171/225], Training Accuracy: 94.1977%, Training Loss: 0.1609%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/300], Step [172/225], Training Accuracy: 94.1951%, Training Loss: 0.1607%\n",
      "Epoch [51/300], Step [173/225], Training Accuracy: 94.2016%, Training Loss: 0.1607%\n",
      "Epoch [51/300], Step [174/225], Training Accuracy: 94.2259%, Training Loss: 0.1602%\n",
      "Epoch [51/300], Step [175/225], Training Accuracy: 94.2500%, Training Loss: 0.1598%\n",
      "Epoch [51/300], Step [176/225], Training Accuracy: 94.2560%, Training Loss: 0.1596%\n",
      "Epoch [51/300], Step [177/225], Training Accuracy: 94.2620%, Training Loss: 0.1594%\n",
      "Epoch [51/300], Step [178/225], Training Accuracy: 94.2855%, Training Loss: 0.1592%\n",
      "Epoch [51/300], Step [179/225], Training Accuracy: 94.3087%, Training Loss: 0.1588%\n",
      "Epoch [51/300], Step [180/225], Training Accuracy: 94.2882%, Training Loss: 0.1592%\n",
      "Epoch [51/300], Step [181/225], Training Accuracy: 94.2852%, Training Loss: 0.1594%\n",
      "Epoch [51/300], Step [182/225], Training Accuracy: 94.2995%, Training Loss: 0.1598%\n",
      "Epoch [51/300], Step [183/225], Training Accuracy: 94.3221%, Training Loss: 0.1592%\n",
      "Epoch [51/300], Step [184/225], Training Accuracy: 94.3105%, Training Loss: 0.1596%\n",
      "Epoch [51/300], Step [185/225], Training Accuracy: 94.3243%, Training Loss: 0.1593%\n",
      "Epoch [51/300], Step [186/225], Training Accuracy: 94.3464%, Training Loss: 0.1588%\n",
      "Epoch [51/300], Step [187/225], Training Accuracy: 94.3600%, Training Loss: 0.1586%\n",
      "Epoch [51/300], Step [188/225], Training Accuracy: 94.3733%, Training Loss: 0.1584%\n",
      "Epoch [51/300], Step [189/225], Training Accuracy: 94.4031%, Training Loss: 0.1578%\n",
      "Epoch [51/300], Step [190/225], Training Accuracy: 94.3914%, Training Loss: 0.1580%\n",
      "Epoch [51/300], Step [191/225], Training Accuracy: 94.3963%, Training Loss: 0.1577%\n",
      "Epoch [51/300], Step [192/225], Training Accuracy: 94.4173%, Training Loss: 0.1575%\n",
      "Epoch [51/300], Step [193/225], Training Accuracy: 94.4220%, Training Loss: 0.1573%\n",
      "Epoch [51/300], Step [194/225], Training Accuracy: 94.4265%, Training Loss: 0.1572%\n",
      "Epoch [51/300], Step [195/225], Training Accuracy: 94.4231%, Training Loss: 0.1575%\n",
      "Epoch [51/300], Step [196/225], Training Accuracy: 94.4436%, Training Loss: 0.1571%\n",
      "Epoch [51/300], Step [197/225], Training Accuracy: 94.4321%, Training Loss: 0.1569%\n",
      "Epoch [51/300], Step [198/225], Training Accuracy: 94.4366%, Training Loss: 0.1569%\n",
      "Epoch [51/300], Step [199/225], Training Accuracy: 94.4253%, Training Loss: 0.1571%\n",
      "Epoch [51/300], Step [200/225], Training Accuracy: 94.4297%, Training Loss: 0.1570%\n",
      "Epoch [51/300], Step [201/225], Training Accuracy: 94.4263%, Training Loss: 0.1572%\n",
      "Epoch [51/300], Step [202/225], Training Accuracy: 94.4462%, Training Loss: 0.1568%\n",
      "Epoch [51/300], Step [203/225], Training Accuracy: 94.4119%, Training Loss: 0.1578%\n",
      "Epoch [51/300], Step [204/225], Training Accuracy: 94.4010%, Training Loss: 0.1578%\n",
      "Epoch [51/300], Step [205/225], Training Accuracy: 94.4207%, Training Loss: 0.1573%\n",
      "Epoch [51/300], Step [206/225], Training Accuracy: 94.4175%, Training Loss: 0.1574%\n",
      "Epoch [51/300], Step [207/225], Training Accuracy: 94.4218%, Training Loss: 0.1573%\n",
      "Epoch [51/300], Step [208/225], Training Accuracy: 94.4261%, Training Loss: 0.1572%\n",
      "Epoch [51/300], Step [209/225], Training Accuracy: 94.4453%, Training Loss: 0.1567%\n",
      "Epoch [51/300], Step [210/225], Training Accuracy: 94.4494%, Training Loss: 0.1564%\n",
      "Epoch [51/300], Step [211/225], Training Accuracy: 94.4461%, Training Loss: 0.1566%\n",
      "Epoch [51/300], Step [212/225], Training Accuracy: 94.4428%, Training Loss: 0.1567%\n",
      "Epoch [51/300], Step [213/225], Training Accuracy: 94.4616%, Training Loss: 0.1564%\n",
      "Epoch [51/300], Step [214/225], Training Accuracy: 94.4801%, Training Loss: 0.1561%\n",
      "Epoch [51/300], Step [215/225], Training Accuracy: 94.4840%, Training Loss: 0.1559%\n",
      "Epoch [51/300], Step [216/225], Training Accuracy: 94.4806%, Training Loss: 0.1563%\n",
      "Epoch [51/300], Step [217/225], Training Accuracy: 94.4916%, Training Loss: 0.1561%\n",
      "Epoch [51/300], Step [218/225], Training Accuracy: 94.5026%, Training Loss: 0.1559%\n",
      "Epoch [51/300], Step [219/225], Training Accuracy: 94.5134%, Training Loss: 0.1558%\n",
      "Epoch [51/300], Step [220/225], Training Accuracy: 94.5384%, Training Loss: 0.1554%\n",
      "Epoch [51/300], Step [221/225], Training Accuracy: 94.5419%, Training Loss: 0.1554%\n",
      "Epoch [51/300], Step [222/225], Training Accuracy: 94.5453%, Training Loss: 0.1555%\n",
      "Epoch [51/300], Step [223/225], Training Accuracy: 94.5558%, Training Loss: 0.1554%\n",
      "Epoch [51/300], Step [224/225], Training Accuracy: 94.5661%, Training Loss: 0.1551%\n",
      "Epoch [51/300], Step [225/225], Training Accuracy: 94.5317%, Training Loss: 0.1554%\n",
      "Epoch [52/300], Step [1/225], Training Accuracy: 96.8750%, Training Loss: 0.1050%\n",
      "Epoch [52/300], Step [2/225], Training Accuracy: 97.6562%, Training Loss: 0.0882%\n",
      "Epoch [52/300], Step [3/225], Training Accuracy: 96.3542%, Training Loss: 0.1070%\n",
      "Epoch [52/300], Step [4/225], Training Accuracy: 96.4844%, Training Loss: 0.1049%\n",
      "Epoch [52/300], Step [5/225], Training Accuracy: 97.1875%, Training Loss: 0.0969%\n",
      "Epoch [52/300], Step [6/225], Training Accuracy: 97.1354%, Training Loss: 0.0994%\n",
      "Epoch [52/300], Step [7/225], Training Accuracy: 97.3214%, Training Loss: 0.0983%\n",
      "Epoch [52/300], Step [8/225], Training Accuracy: 97.0703%, Training Loss: 0.1002%\n",
      "Epoch [52/300], Step [9/225], Training Accuracy: 97.0486%, Training Loss: 0.1007%\n",
      "Epoch [52/300], Step [10/225], Training Accuracy: 97.0312%, Training Loss: 0.1045%\n",
      "Epoch [52/300], Step [11/225], Training Accuracy: 96.7330%, Training Loss: 0.1092%\n",
      "Epoch [52/300], Step [12/225], Training Accuracy: 96.7448%, Training Loss: 0.1067%\n",
      "Epoch [52/300], Step [13/225], Training Accuracy: 96.7548%, Training Loss: 0.1062%\n",
      "Epoch [52/300], Step [14/225], Training Accuracy: 96.5402%, Training Loss: 0.1076%\n",
      "Epoch [52/300], Step [15/225], Training Accuracy: 96.5625%, Training Loss: 0.1068%\n",
      "Epoch [52/300], Step [16/225], Training Accuracy: 96.4844%, Training Loss: 0.1087%\n",
      "Epoch [52/300], Step [17/225], Training Accuracy: 96.5074%, Training Loss: 0.1095%\n",
      "Epoch [52/300], Step [18/225], Training Accuracy: 96.6146%, Training Loss: 0.1098%\n",
      "Epoch [52/300], Step [19/225], Training Accuracy: 96.4638%, Training Loss: 0.1120%\n",
      "Epoch [52/300], Step [20/225], Training Accuracy: 96.4844%, Training Loss: 0.1130%\n",
      "Epoch [52/300], Step [21/225], Training Accuracy: 96.5774%, Training Loss: 0.1112%\n",
      "Epoch [52/300], Step [22/225], Training Accuracy: 96.3778%, Training Loss: 0.1158%\n",
      "Epoch [52/300], Step [23/225], Training Accuracy: 96.4674%, Training Loss: 0.1145%\n",
      "Epoch [52/300], Step [24/225], Training Accuracy: 95.9635%, Training Loss: 0.1224%\n",
      "Epoch [52/300], Step [25/225], Training Accuracy: 95.9375%, Training Loss: 0.1225%\n",
      "Epoch [52/300], Step [26/225], Training Accuracy: 95.9736%, Training Loss: 0.1218%\n",
      "Epoch [52/300], Step [27/225], Training Accuracy: 95.9491%, Training Loss: 0.1222%\n",
      "Epoch [52/300], Step [28/225], Training Accuracy: 96.0379%, Training Loss: 0.1194%\n",
      "Epoch [52/300], Step [29/225], Training Accuracy: 96.0129%, Training Loss: 0.1206%\n",
      "Epoch [52/300], Step [30/225], Training Accuracy: 95.9896%, Training Loss: 0.1211%\n",
      "Epoch [52/300], Step [31/225], Training Accuracy: 96.0181%, Training Loss: 0.1201%\n",
      "Epoch [52/300], Step [32/225], Training Accuracy: 95.9473%, Training Loss: 0.1203%\n",
      "Epoch [52/300], Step [33/225], Training Accuracy: 95.9754%, Training Loss: 0.1195%\n",
      "Epoch [52/300], Step [34/225], Training Accuracy: 96.0018%, Training Loss: 0.1187%\n",
      "Epoch [52/300], Step [35/225], Training Accuracy: 95.9375%, Training Loss: 0.1210%\n",
      "Epoch [52/300], Step [36/225], Training Accuracy: 95.9635%, Training Loss: 0.1213%\n",
      "Epoch [52/300], Step [37/225], Training Accuracy: 95.9459%, Training Loss: 0.1213%\n",
      "Epoch [52/300], Step [38/225], Training Accuracy: 95.9293%, Training Loss: 0.1232%\n",
      "Epoch [52/300], Step [39/225], Training Accuracy: 95.9135%, Training Loss: 0.1228%\n",
      "Epoch [52/300], Step [40/225], Training Accuracy: 95.9766%, Training Loss: 0.1224%\n",
      "Epoch [52/300], Step [41/225], Training Accuracy: 95.9604%, Training Loss: 0.1226%\n",
      "Epoch [52/300], Step [42/225], Training Accuracy: 96.0193%, Training Loss: 0.1214%\n",
      "Epoch [52/300], Step [43/225], Training Accuracy: 96.1119%, Training Loss: 0.1200%\n",
      "Epoch [52/300], Step [44/225], Training Accuracy: 96.0227%, Training Loss: 0.1226%\n",
      "Epoch [52/300], Step [45/225], Training Accuracy: 95.9722%, Training Loss: 0.1223%\n",
      "Epoch [52/300], Step [46/225], Training Accuracy: 95.9918%, Training Loss: 0.1216%\n",
      "Epoch [52/300], Step [47/225], Training Accuracy: 96.0771%, Training Loss: 0.1206%\n",
      "Epoch [52/300], Step [48/225], Training Accuracy: 96.0286%, Training Loss: 0.1207%\n",
      "Epoch [52/300], Step [49/225], Training Accuracy: 96.0140%, Training Loss: 0.1203%\n",
      "Epoch [52/300], Step [50/225], Training Accuracy: 96.0312%, Training Loss: 0.1193%\n",
      "Epoch [52/300], Step [51/225], Training Accuracy: 96.0478%, Training Loss: 0.1185%\n",
      "Epoch [52/300], Step [52/225], Training Accuracy: 96.0938%, Training Loss: 0.1173%\n",
      "Epoch [52/300], Step [53/225], Training Accuracy: 96.0200%, Training Loss: 0.1182%\n",
      "Epoch [52/300], Step [54/225], Training Accuracy: 96.0069%, Training Loss: 0.1188%\n",
      "Epoch [52/300], Step [55/225], Training Accuracy: 96.0795%, Training Loss: 0.1179%\n",
      "Epoch [52/300], Step [56/225], Training Accuracy: 96.0379%, Training Loss: 0.1193%\n",
      "Epoch [52/300], Step [57/225], Training Accuracy: 96.0252%, Training Loss: 0.1198%\n",
      "Epoch [52/300], Step [58/225], Training Accuracy: 95.9860%, Training Loss: 0.1203%\n",
      "Epoch [52/300], Step [59/225], Training Accuracy: 96.0011%, Training Loss: 0.1204%\n",
      "Epoch [52/300], Step [60/225], Training Accuracy: 95.9896%, Training Loss: 0.1215%\n",
      "Epoch [52/300], Step [61/225], Training Accuracy: 95.9529%, Training Loss: 0.1224%\n",
      "Epoch [52/300], Step [62/225], Training Accuracy: 95.9173%, Training Loss: 0.1230%\n",
      "Epoch [52/300], Step [63/225], Training Accuracy: 95.9077%, Training Loss: 0.1233%\n",
      "Epoch [52/300], Step [64/225], Training Accuracy: 95.9473%, Training Loss: 0.1227%\n",
      "Epoch [52/300], Step [65/225], Training Accuracy: 96.0096%, Training Loss: 0.1217%\n",
      "Epoch [52/300], Step [66/225], Training Accuracy: 96.0464%, Training Loss: 0.1209%\n",
      "Epoch [52/300], Step [67/225], Training Accuracy: 96.1054%, Training Loss: 0.1201%\n",
      "Epoch [52/300], Step [68/225], Training Accuracy: 96.1397%, Training Loss: 0.1196%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/300], Step [69/225], Training Accuracy: 96.1051%, Training Loss: 0.1195%\n",
      "Epoch [52/300], Step [70/225], Training Accuracy: 96.0714%, Training Loss: 0.1196%\n",
      "Epoch [52/300], Step [71/225], Training Accuracy: 96.0167%, Training Loss: 0.1203%\n",
      "Epoch [52/300], Step [72/225], Training Accuracy: 96.0069%, Training Loss: 0.1202%\n",
      "Epoch [52/300], Step [73/225], Training Accuracy: 95.9546%, Training Loss: 0.1207%\n",
      "Epoch [52/300], Step [74/225], Training Accuracy: 95.9037%, Training Loss: 0.1214%\n",
      "Epoch [52/300], Step [75/225], Training Accuracy: 95.9167%, Training Loss: 0.1211%\n",
      "Epoch [52/300], Step [76/225], Training Accuracy: 95.8882%, Training Loss: 0.1216%\n",
      "Epoch [52/300], Step [77/225], Training Accuracy: 95.8807%, Training Loss: 0.1221%\n",
      "Epoch [52/300], Step [78/225], Training Accuracy: 95.8734%, Training Loss: 0.1224%\n",
      "Epoch [52/300], Step [79/225], Training Accuracy: 95.8465%, Training Loss: 0.1236%\n",
      "Epoch [52/300], Step [80/225], Training Accuracy: 95.8398%, Training Loss: 0.1240%\n",
      "Epoch [52/300], Step [81/225], Training Accuracy: 95.7755%, Training Loss: 0.1256%\n",
      "Epoch [52/300], Step [82/225], Training Accuracy: 95.7889%, Training Loss: 0.1253%\n",
      "Epoch [52/300], Step [83/225], Training Accuracy: 95.7831%, Training Loss: 0.1257%\n",
      "Epoch [52/300], Step [84/225], Training Accuracy: 95.7775%, Training Loss: 0.1260%\n",
      "Epoch [52/300], Step [85/225], Training Accuracy: 95.7904%, Training Loss: 0.1257%\n",
      "Epoch [52/300], Step [86/225], Training Accuracy: 95.8212%, Training Loss: 0.1254%\n",
      "Epoch [52/300], Step [87/225], Training Accuracy: 95.8154%, Training Loss: 0.1257%\n",
      "Epoch [52/300], Step [88/225], Training Accuracy: 95.7919%, Training Loss: 0.1257%\n",
      "Epoch [52/300], Step [89/225], Training Accuracy: 95.7865%, Training Loss: 0.1253%\n",
      "Epoch [52/300], Step [90/225], Training Accuracy: 95.7986%, Training Loss: 0.1251%\n",
      "Epoch [52/300], Step [91/225], Training Accuracy: 95.7933%, Training Loss: 0.1251%\n",
      "Epoch [52/300], Step [92/225], Training Accuracy: 95.8050%, Training Loss: 0.1247%\n",
      "Epoch [52/300], Step [93/225], Training Accuracy: 95.7997%, Training Loss: 0.1247%\n",
      "Epoch [52/300], Step [94/225], Training Accuracy: 95.7779%, Training Loss: 0.1247%\n",
      "Epoch [52/300], Step [95/225], Training Accuracy: 95.7730%, Training Loss: 0.1249%\n",
      "Epoch [52/300], Step [96/225], Training Accuracy: 95.7357%, Training Loss: 0.1254%\n",
      "Epoch [52/300], Step [97/225], Training Accuracy: 95.7474%, Training Loss: 0.1251%\n",
      "Epoch [52/300], Step [98/225], Training Accuracy: 95.7270%, Training Loss: 0.1254%\n",
      "Epoch [52/300], Step [99/225], Training Accuracy: 95.7544%, Training Loss: 0.1250%\n",
      "Epoch [52/300], Step [100/225], Training Accuracy: 95.7812%, Training Loss: 0.1245%\n",
      "Epoch [52/300], Step [101/225], Training Accuracy: 95.7921%, Training Loss: 0.1244%\n",
      "Epoch [52/300], Step [102/225], Training Accuracy: 95.7874%, Training Loss: 0.1241%\n",
      "Epoch [52/300], Step [103/225], Training Accuracy: 95.7979%, Training Loss: 0.1239%\n",
      "Epoch [52/300], Step [104/225], Training Accuracy: 95.8083%, Training Loss: 0.1236%\n",
      "Epoch [52/300], Step [105/225], Training Accuracy: 95.8036%, Training Loss: 0.1238%\n",
      "Epoch [52/300], Step [106/225], Training Accuracy: 95.7989%, Training Loss: 0.1239%\n",
      "Epoch [52/300], Step [107/225], Training Accuracy: 95.7506%, Training Loss: 0.1243%\n",
      "Epoch [52/300], Step [108/225], Training Accuracy: 95.7610%, Training Loss: 0.1239%\n",
      "Epoch [52/300], Step [109/225], Training Accuracy: 95.7282%, Training Loss: 0.1241%\n",
      "Epoch [52/300], Step [110/225], Training Accuracy: 95.7386%, Training Loss: 0.1239%\n",
      "Epoch [52/300], Step [111/225], Training Accuracy: 95.7066%, Training Loss: 0.1240%\n",
      "Epoch [52/300], Step [112/225], Training Accuracy: 95.7171%, Training Loss: 0.1239%\n",
      "Epoch [52/300], Step [113/225], Training Accuracy: 95.7273%, Training Loss: 0.1233%\n",
      "Epoch [52/300], Step [114/225], Training Accuracy: 95.7374%, Training Loss: 0.1232%\n",
      "Epoch [52/300], Step [115/225], Training Accuracy: 95.7745%, Training Loss: 0.1226%\n",
      "Epoch [52/300], Step [116/225], Training Accuracy: 95.7839%, Training Loss: 0.1222%\n",
      "Epoch [52/300], Step [117/225], Training Accuracy: 95.7799%, Training Loss: 0.1221%\n",
      "Epoch [52/300], Step [118/225], Training Accuracy: 95.8024%, Training Loss: 0.1217%\n",
      "Epoch [52/300], Step [119/225], Training Accuracy: 95.8114%, Training Loss: 0.1218%\n",
      "Epoch [52/300], Step [120/225], Training Accuracy: 95.8333%, Training Loss: 0.1214%\n",
      "Epoch [52/300], Step [121/225], Training Accuracy: 95.8419%, Training Loss: 0.1210%\n",
      "Epoch [52/300], Step [122/225], Training Accuracy: 95.8504%, Training Loss: 0.1209%\n",
      "Epoch [52/300], Step [123/225], Training Accuracy: 95.8714%, Training Loss: 0.1206%\n",
      "Epoch [52/300], Step [124/225], Training Accuracy: 95.8795%, Training Loss: 0.1203%\n",
      "Epoch [52/300], Step [125/225], Training Accuracy: 95.8875%, Training Loss: 0.1202%\n",
      "Epoch [52/300], Step [126/225], Training Accuracy: 95.9077%, Training Loss: 0.1198%\n",
      "Epoch [52/300], Step [127/225], Training Accuracy: 95.9400%, Training Loss: 0.1194%\n",
      "Epoch [52/300], Step [128/225], Training Accuracy: 95.9595%, Training Loss: 0.1193%\n",
      "Epoch [52/300], Step [129/225], Training Accuracy: 95.9666%, Training Loss: 0.1192%\n",
      "Epoch [52/300], Step [130/225], Training Accuracy: 95.9615%, Training Loss: 0.1194%\n",
      "Epoch [52/300], Step [131/225], Training Accuracy: 95.9804%, Training Loss: 0.1189%\n",
      "Epoch [52/300], Step [132/225], Training Accuracy: 95.9872%, Training Loss: 0.1187%\n",
      "Epoch [52/300], Step [133/225], Training Accuracy: 96.0056%, Training Loss: 0.1183%\n",
      "Epoch [52/300], Step [134/225], Training Accuracy: 96.0005%, Training Loss: 0.1182%\n",
      "Epoch [52/300], Step [135/225], Training Accuracy: 96.0069%, Training Loss: 0.1179%\n",
      "Epoch [52/300], Step [136/225], Training Accuracy: 95.9789%, Training Loss: 0.1189%\n",
      "Epoch [52/300], Step [137/225], Training Accuracy: 95.9968%, Training Loss: 0.1188%\n",
      "Epoch [52/300], Step [138/225], Training Accuracy: 96.0145%, Training Loss: 0.1184%\n",
      "Epoch [52/300], Step [139/225], Training Accuracy: 96.0319%, Training Loss: 0.1180%\n",
      "Epoch [52/300], Step [140/225], Training Accuracy: 96.0156%, Training Loss: 0.1182%\n",
      "Epoch [52/300], Step [141/225], Training Accuracy: 96.0217%, Training Loss: 0.1180%\n",
      "Epoch [52/300], Step [142/225], Training Accuracy: 96.0387%, Training Loss: 0.1174%\n",
      "Epoch [52/300], Step [143/225], Training Accuracy: 96.0337%, Training Loss: 0.1176%\n",
      "Epoch [52/300], Step [144/225], Training Accuracy: 96.0286%, Training Loss: 0.1175%\n",
      "Epoch [52/300], Step [145/225], Training Accuracy: 96.0453%, Training Loss: 0.1171%\n",
      "Epoch [52/300], Step [146/225], Training Accuracy: 96.0616%, Training Loss: 0.1167%\n",
      "Epoch [52/300], Step [147/225], Training Accuracy: 96.0672%, Training Loss: 0.1166%\n",
      "Epoch [52/300], Step [148/225], Training Accuracy: 96.0938%, Training Loss: 0.1162%\n",
      "Epoch [52/300], Step [149/225], Training Accuracy: 96.0675%, Training Loss: 0.1169%\n",
      "Epoch [52/300], Step [150/225], Training Accuracy: 96.0625%, Training Loss: 0.1167%\n",
      "Epoch [52/300], Step [151/225], Training Accuracy: 96.0679%, Training Loss: 0.1165%\n",
      "Epoch [52/300], Step [152/225], Training Accuracy: 96.0732%, Training Loss: 0.1163%\n",
      "Epoch [52/300], Step [153/225], Training Accuracy: 96.0886%, Training Loss: 0.1160%\n",
      "Epoch [52/300], Step [154/225], Training Accuracy: 96.1039%, Training Loss: 0.1158%\n",
      "Epoch [52/300], Step [155/225], Training Accuracy: 96.1089%, Training Loss: 0.1155%\n",
      "Epoch [52/300], Step [156/225], Training Accuracy: 96.1038%, Training Loss: 0.1154%\n",
      "Epoch [52/300], Step [157/225], Training Accuracy: 96.0888%, Training Loss: 0.1157%\n",
      "Epoch [52/300], Step [158/225], Training Accuracy: 96.0938%, Training Loss: 0.1154%\n",
      "Epoch [52/300], Step [159/225], Training Accuracy: 96.0888%, Training Loss: 0.1154%\n",
      "Epoch [52/300], Step [160/225], Training Accuracy: 96.1035%, Training Loss: 0.1152%\n",
      "Epoch [52/300], Step [161/225], Training Accuracy: 96.1180%, Training Loss: 0.1148%\n",
      "Epoch [52/300], Step [162/225], Training Accuracy: 96.1227%, Training Loss: 0.1147%\n",
      "Epoch [52/300], Step [163/225], Training Accuracy: 96.1081%, Training Loss: 0.1149%\n",
      "Epoch [52/300], Step [164/225], Training Accuracy: 96.1223%, Training Loss: 0.1148%\n",
      "Epoch [52/300], Step [165/225], Training Accuracy: 96.1364%, Training Loss: 0.1146%\n",
      "Epoch [52/300], Step [166/225], Training Accuracy: 96.1126%, Training Loss: 0.1150%\n",
      "Epoch [52/300], Step [167/225], Training Accuracy: 96.1265%, Training Loss: 0.1149%\n",
      "Epoch [52/300], Step [168/225], Training Accuracy: 96.1403%, Training Loss: 0.1146%\n",
      "Epoch [52/300], Step [169/225], Training Accuracy: 96.1446%, Training Loss: 0.1146%\n",
      "Epoch [52/300], Step [170/225], Training Accuracy: 96.1397%, Training Loss: 0.1149%\n",
      "Epoch [52/300], Step [171/225], Training Accuracy: 96.1440%, Training Loss: 0.1148%\n",
      "Epoch [52/300], Step [172/225], Training Accuracy: 96.1573%, Training Loss: 0.1147%\n",
      "Epoch [52/300], Step [173/225], Training Accuracy: 96.1705%, Training Loss: 0.1144%\n",
      "Epoch [52/300], Step [174/225], Training Accuracy: 96.1746%, Training Loss: 0.1142%\n",
      "Epoch [52/300], Step [175/225], Training Accuracy: 96.1786%, Training Loss: 0.1140%\n",
      "Epoch [52/300], Step [176/225], Training Accuracy: 96.1914%, Training Loss: 0.1138%\n",
      "Epoch [52/300], Step [177/225], Training Accuracy: 96.1953%, Training Loss: 0.1135%\n",
      "Epoch [52/300], Step [178/225], Training Accuracy: 96.1903%, Training Loss: 0.1135%\n",
      "Epoch [52/300], Step [179/225], Training Accuracy: 96.2029%, Training Loss: 0.1134%\n",
      "Epoch [52/300], Step [180/225], Training Accuracy: 96.2153%, Training Loss: 0.1131%\n",
      "Epoch [52/300], Step [181/225], Training Accuracy: 96.2189%, Training Loss: 0.1130%\n",
      "Epoch [52/300], Step [182/225], Training Accuracy: 96.1968%, Training Loss: 0.1134%\n",
      "Epoch [52/300], Step [183/225], Training Accuracy: 96.2176%, Training Loss: 0.1129%\n",
      "Epoch [52/300], Step [184/225], Training Accuracy: 96.2381%, Training Loss: 0.1128%\n",
      "Epoch [52/300], Step [185/225], Training Accuracy: 96.2416%, Training Loss: 0.1127%\n",
      "Epoch [52/300], Step [186/225], Training Accuracy: 96.2366%, Training Loss: 0.1127%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/300], Step [187/225], Training Accuracy: 96.2567%, Training Loss: 0.1124%\n",
      "Epoch [52/300], Step [188/225], Training Accuracy: 96.2600%, Training Loss: 0.1123%\n",
      "Epoch [52/300], Step [189/225], Training Accuracy: 96.2715%, Training Loss: 0.1121%\n",
      "Epoch [52/300], Step [190/225], Training Accuracy: 96.2747%, Training Loss: 0.1122%\n",
      "Epoch [52/300], Step [191/225], Training Accuracy: 96.2778%, Training Loss: 0.1121%\n",
      "Epoch [52/300], Step [192/225], Training Accuracy: 96.2565%, Training Loss: 0.1124%\n",
      "Epoch [52/300], Step [193/225], Training Accuracy: 96.2435%, Training Loss: 0.1125%\n",
      "Epoch [52/300], Step [194/225], Training Accuracy: 96.2468%, Training Loss: 0.1122%\n",
      "Epoch [52/300], Step [195/225], Training Accuracy: 96.2580%, Training Loss: 0.1121%\n",
      "Epoch [52/300], Step [196/225], Training Accuracy: 96.2771%, Training Loss: 0.1119%\n",
      "Epoch [52/300], Step [197/225], Training Accuracy: 96.2801%, Training Loss: 0.1118%\n",
      "Epoch [52/300], Step [198/225], Training Accuracy: 96.2831%, Training Loss: 0.1117%\n",
      "Epoch [52/300], Step [199/225], Training Accuracy: 96.2940%, Training Loss: 0.1117%\n",
      "Epoch [52/300], Step [200/225], Training Accuracy: 96.3047%, Training Loss: 0.1115%\n",
      "Epoch [52/300], Step [201/225], Training Accuracy: 96.3075%, Training Loss: 0.1115%\n",
      "Epoch [52/300], Step [202/225], Training Accuracy: 96.3026%, Training Loss: 0.1114%\n",
      "Epoch [52/300], Step [203/225], Training Accuracy: 96.3131%, Training Loss: 0.1112%\n",
      "Epoch [52/300], Step [204/225], Training Accuracy: 96.3006%, Training Loss: 0.1115%\n",
      "Epoch [52/300], Step [205/225], Training Accuracy: 96.3186%, Training Loss: 0.1112%\n",
      "Epoch [52/300], Step [206/225], Training Accuracy: 96.3289%, Training Loss: 0.1110%\n",
      "Epoch [52/300], Step [207/225], Training Accuracy: 96.3466%, Training Loss: 0.1107%\n",
      "Epoch [52/300], Step [208/225], Training Accuracy: 96.3567%, Training Loss: 0.1105%\n",
      "Epoch [52/300], Step [209/225], Training Accuracy: 96.3741%, Training Loss: 0.1102%\n",
      "Epoch [52/300], Step [210/225], Training Accuracy: 96.3765%, Training Loss: 0.1101%\n",
      "Epoch [52/300], Step [211/225], Training Accuracy: 96.3863%, Training Loss: 0.1100%\n",
      "Epoch [52/300], Step [212/225], Training Accuracy: 96.3959%, Training Loss: 0.1098%\n",
      "Epoch [52/300], Step [213/225], Training Accuracy: 96.4055%, Training Loss: 0.1096%\n",
      "Epoch [52/300], Step [214/225], Training Accuracy: 96.4004%, Training Loss: 0.1098%\n",
      "Epoch [52/300], Step [215/225], Training Accuracy: 96.4172%, Training Loss: 0.1096%\n",
      "Epoch [52/300], Step [216/225], Training Accuracy: 96.3903%, Training Loss: 0.1102%\n",
      "Epoch [52/300], Step [217/225], Training Accuracy: 96.3926%, Training Loss: 0.1102%\n",
      "Epoch [52/300], Step [218/225], Training Accuracy: 96.4019%, Training Loss: 0.1101%\n",
      "Epoch [52/300], Step [219/225], Training Accuracy: 96.4112%, Training Loss: 0.1099%\n",
      "Epoch [52/300], Step [220/225], Training Accuracy: 96.3991%, Training Loss: 0.1099%\n",
      "Epoch [52/300], Step [221/225], Training Accuracy: 96.3872%, Training Loss: 0.1100%\n",
      "Epoch [52/300], Step [222/225], Training Accuracy: 96.3894%, Training Loss: 0.1100%\n",
      "Epoch [52/300], Step [223/225], Training Accuracy: 96.3985%, Training Loss: 0.1098%\n",
      "Epoch [52/300], Step [224/225], Training Accuracy: 96.4007%, Training Loss: 0.1097%\n",
      "Epoch [52/300], Step [225/225], Training Accuracy: 96.4008%, Training Loss: 0.1096%\n",
      "Epoch [53/300], Step [1/225], Training Accuracy: 98.4375%, Training Loss: 0.0638%\n",
      "Epoch [53/300], Step [2/225], Training Accuracy: 96.0938%, Training Loss: 0.0983%\n",
      "Epoch [53/300], Step [3/225], Training Accuracy: 94.2708%, Training Loss: 0.1203%\n",
      "Epoch [53/300], Step [4/225], Training Accuracy: 95.3125%, Training Loss: 0.1027%\n",
      "Epoch [53/300], Step [5/225], Training Accuracy: 95.6250%, Training Loss: 0.0944%\n",
      "Epoch [53/300], Step [6/225], Training Accuracy: 96.3542%, Training Loss: 0.0872%\n",
      "Epoch [53/300], Step [7/225], Training Accuracy: 95.9821%, Training Loss: 0.0984%\n",
      "Epoch [53/300], Step [8/225], Training Accuracy: 96.0938%, Training Loss: 0.0985%\n",
      "Epoch [53/300], Step [9/225], Training Accuracy: 96.3542%, Training Loss: 0.0966%\n",
      "Epoch [53/300], Step [10/225], Training Accuracy: 96.2500%, Training Loss: 0.1034%\n",
      "Epoch [53/300], Step [11/225], Training Accuracy: 96.4489%, Training Loss: 0.1017%\n",
      "Epoch [53/300], Step [12/225], Training Accuracy: 96.3542%, Training Loss: 0.1026%\n",
      "Epoch [53/300], Step [13/225], Training Accuracy: 96.6346%, Training Loss: 0.0994%\n",
      "Epoch [53/300], Step [14/225], Training Accuracy: 96.5402%, Training Loss: 0.1029%\n",
      "Epoch [53/300], Step [15/225], Training Accuracy: 96.7708%, Training Loss: 0.0990%\n",
      "Epoch [53/300], Step [16/225], Training Accuracy: 96.7773%, Training Loss: 0.0983%\n",
      "Epoch [53/300], Step [17/225], Training Accuracy: 96.6912%, Training Loss: 0.1006%\n",
      "Epoch [53/300], Step [18/225], Training Accuracy: 96.7014%, Training Loss: 0.1011%\n",
      "Epoch [53/300], Step [19/225], Training Accuracy: 96.7105%, Training Loss: 0.1018%\n",
      "Epoch [53/300], Step [20/225], Training Accuracy: 96.7969%, Training Loss: 0.1023%\n",
      "Epoch [53/300], Step [21/225], Training Accuracy: 96.8750%, Training Loss: 0.1015%\n",
      "Epoch [53/300], Step [22/225], Training Accuracy: 97.0170%, Training Loss: 0.0997%\n",
      "Epoch [53/300], Step [23/225], Training Accuracy: 96.9429%, Training Loss: 0.0998%\n",
      "Epoch [53/300], Step [24/225], Training Accuracy: 96.8750%, Training Loss: 0.1013%\n",
      "Epoch [53/300], Step [25/225], Training Accuracy: 96.8750%, Training Loss: 0.0999%\n",
      "Epoch [53/300], Step [26/225], Training Accuracy: 96.6346%, Training Loss: 0.1018%\n",
      "Epoch [53/300], Step [27/225], Training Accuracy: 96.6435%, Training Loss: 0.1004%\n",
      "Epoch [53/300], Step [28/225], Training Accuracy: 96.7076%, Training Loss: 0.1001%\n",
      "Epoch [53/300], Step [29/225], Training Accuracy: 96.6595%, Training Loss: 0.1022%\n",
      "Epoch [53/300], Step [30/225], Training Accuracy: 96.6667%, Training Loss: 0.1024%\n",
      "Epoch [53/300], Step [31/225], Training Accuracy: 96.5726%, Training Loss: 0.1039%\n",
      "Epoch [53/300], Step [32/225], Training Accuracy: 96.4844%, Training Loss: 0.1038%\n",
      "Epoch [53/300], Step [33/225], Training Accuracy: 96.4015%, Training Loss: 0.1047%\n",
      "Epoch [53/300], Step [34/225], Training Accuracy: 96.4614%, Training Loss: 0.1046%\n",
      "Epoch [53/300], Step [35/225], Training Accuracy: 96.5179%, Training Loss: 0.1040%\n",
      "Epoch [53/300], Step [36/225], Training Accuracy: 96.5712%, Training Loss: 0.1032%\n",
      "Epoch [53/300], Step [37/225], Training Accuracy: 96.6639%, Training Loss: 0.1017%\n",
      "Epoch [53/300], Step [38/225], Training Accuracy: 96.5872%, Training Loss: 0.1048%\n",
      "Epoch [53/300], Step [39/225], Training Accuracy: 96.6346%, Training Loss: 0.1049%\n",
      "Epoch [53/300], Step [40/225], Training Accuracy: 96.6016%, Training Loss: 0.1057%\n",
      "Epoch [53/300], Step [41/225], Training Accuracy: 96.5701%, Training Loss: 0.1071%\n",
      "Epoch [53/300], Step [42/225], Training Accuracy: 96.5774%, Training Loss: 0.1066%\n",
      "Epoch [53/300], Step [43/225], Training Accuracy: 96.6570%, Training Loss: 0.1058%\n",
      "Epoch [53/300], Step [44/225], Training Accuracy: 96.6619%, Training Loss: 0.1056%\n",
      "Epoch [53/300], Step [45/225], Training Accuracy: 96.6667%, Training Loss: 0.1049%\n",
      "Epoch [53/300], Step [46/225], Training Accuracy: 96.7052%, Training Loss: 0.1036%\n",
      "Epoch [53/300], Step [47/225], Training Accuracy: 96.7420%, Training Loss: 0.1035%\n",
      "Epoch [53/300], Step [48/225], Training Accuracy: 96.8099%, Training Loss: 0.1026%\n",
      "Epoch [53/300], Step [49/225], Training Accuracy: 96.8750%, Training Loss: 0.1020%\n",
      "Epoch [53/300], Step [50/225], Training Accuracy: 96.8438%, Training Loss: 0.1036%\n",
      "Epoch [53/300], Step [51/225], Training Accuracy: 96.8750%, Training Loss: 0.1029%\n",
      "Epoch [53/300], Step [52/225], Training Accuracy: 96.9351%, Training Loss: 0.1016%\n",
      "Epoch [53/300], Step [53/225], Training Accuracy: 96.9634%, Training Loss: 0.1013%\n",
      "Epoch [53/300], Step [54/225], Training Accuracy: 96.9907%, Training Loss: 0.1012%\n",
      "Epoch [53/300], Step [55/225], Training Accuracy: 97.0455%, Training Loss: 0.1005%\n",
      "Epoch [53/300], Step [56/225], Training Accuracy: 96.9866%, Training Loss: 0.1016%\n",
      "Epoch [53/300], Step [57/225], Training Accuracy: 97.0395%, Training Loss: 0.1008%\n",
      "Epoch [53/300], Step [58/225], Training Accuracy: 96.9828%, Training Loss: 0.1015%\n",
      "Epoch [53/300], Step [59/225], Training Accuracy: 97.0074%, Training Loss: 0.1014%\n",
      "Epoch [53/300], Step [60/225], Training Accuracy: 97.0052%, Training Loss: 0.1014%\n",
      "Epoch [53/300], Step [61/225], Training Accuracy: 96.9518%, Training Loss: 0.1023%\n",
      "Epoch [53/300], Step [62/225], Training Accuracy: 96.9758%, Training Loss: 0.1021%\n",
      "Epoch [53/300], Step [63/225], Training Accuracy: 96.9742%, Training Loss: 0.1021%\n",
      "Epoch [53/300], Step [64/225], Training Accuracy: 96.9482%, Training Loss: 0.1019%\n",
      "Epoch [53/300], Step [65/225], Training Accuracy: 96.9712%, Training Loss: 0.1013%\n",
      "Epoch [53/300], Step [66/225], Training Accuracy: 96.9223%, Training Loss: 0.1019%\n",
      "Epoch [53/300], Step [67/225], Training Accuracy: 96.9450%, Training Loss: 0.1025%\n",
      "Epoch [53/300], Step [68/225], Training Accuracy: 96.9669%, Training Loss: 0.1022%\n",
      "Epoch [53/300], Step [69/225], Training Accuracy: 96.9656%, Training Loss: 0.1018%\n",
      "Epoch [53/300], Step [70/225], Training Accuracy: 96.9420%, Training Loss: 0.1017%\n",
      "Epoch [53/300], Step [71/225], Training Accuracy: 96.9630%, Training Loss: 0.1014%\n",
      "Epoch [53/300], Step [72/225], Training Accuracy: 97.0052%, Training Loss: 0.1007%\n",
      "Epoch [53/300], Step [73/225], Training Accuracy: 97.0248%, Training Loss: 0.1006%\n",
      "Epoch [53/300], Step [74/225], Training Accuracy: 97.0650%, Training Loss: 0.1000%\n",
      "Epoch [53/300], Step [75/225], Training Accuracy: 97.0417%, Training Loss: 0.1001%\n",
      "Epoch [53/300], Step [76/225], Training Accuracy: 97.0189%, Training Loss: 0.1010%\n",
      "Epoch [53/300], Step [77/225], Training Accuracy: 97.0170%, Training Loss: 0.1012%\n",
      "Epoch [53/300], Step [78/225], Training Accuracy: 97.0353%, Training Loss: 0.1007%\n",
      "Epoch [53/300], Step [79/225], Training Accuracy: 96.9937%, Training Loss: 0.1012%\n",
      "Epoch [53/300], Step [80/225], Training Accuracy: 96.9922%, Training Loss: 0.1010%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/300], Step [81/225], Training Accuracy: 96.9715%, Training Loss: 0.1018%\n",
      "Epoch [53/300], Step [82/225], Training Accuracy: 96.9893%, Training Loss: 0.1015%\n",
      "Epoch [53/300], Step [83/225], Training Accuracy: 96.9880%, Training Loss: 0.1020%\n",
      "Epoch [53/300], Step [84/225], Training Accuracy: 96.9494%, Training Loss: 0.1029%\n",
      "Epoch [53/300], Step [85/225], Training Accuracy: 96.9301%, Training Loss: 0.1034%\n",
      "Epoch [53/300], Step [86/225], Training Accuracy: 96.9477%, Training Loss: 0.1031%\n",
      "Epoch [53/300], Step [87/225], Training Accuracy: 96.9289%, Training Loss: 0.1030%\n",
      "Epoch [53/300], Step [88/225], Training Accuracy: 96.9105%, Training Loss: 0.1034%\n",
      "Epoch [53/300], Step [89/225], Training Accuracy: 96.9277%, Training Loss: 0.1031%\n",
      "Epoch [53/300], Step [90/225], Training Accuracy: 96.9618%, Training Loss: 0.1022%\n",
      "Epoch [53/300], Step [91/225], Training Accuracy: 96.9609%, Training Loss: 0.1018%\n",
      "Epoch [53/300], Step [92/225], Training Accuracy: 96.9939%, Training Loss: 0.1014%\n",
      "Epoch [53/300], Step [93/225], Training Accuracy: 97.0262%, Training Loss: 0.1006%\n",
      "Epoch [53/300], Step [94/225], Training Accuracy: 97.0080%, Training Loss: 0.1008%\n",
      "Epoch [53/300], Step [95/225], Training Accuracy: 96.9737%, Training Loss: 0.1013%\n",
      "Epoch [53/300], Step [96/225], Training Accuracy: 96.9889%, Training Loss: 0.1009%\n",
      "Epoch [53/300], Step [97/225], Training Accuracy: 96.9878%, Training Loss: 0.1008%\n",
      "Epoch [53/300], Step [98/225], Training Accuracy: 96.9866%, Training Loss: 0.1009%\n",
      "Epoch [53/300], Step [99/225], Training Accuracy: 97.0170%, Training Loss: 0.1004%\n",
      "Epoch [53/300], Step [100/225], Training Accuracy: 97.0312%, Training Loss: 0.1000%\n",
      "Epoch [53/300], Step [101/225], Training Accuracy: 97.0452%, Training Loss: 0.0997%\n",
      "Epoch [53/300], Step [102/225], Training Accuracy: 97.0741%, Training Loss: 0.0993%\n",
      "Epoch [53/300], Step [103/225], Training Accuracy: 97.0570%, Training Loss: 0.0996%\n",
      "Epoch [53/300], Step [104/225], Training Accuracy: 97.0553%, Training Loss: 0.0995%\n",
      "Epoch [53/300], Step [105/225], Training Accuracy: 97.0685%, Training Loss: 0.0994%\n",
      "Epoch [53/300], Step [106/225], Training Accuracy: 97.0666%, Training Loss: 0.0994%\n",
      "Epoch [53/300], Step [107/225], Training Accuracy: 97.0502%, Training Loss: 0.0996%\n",
      "Epoch [53/300], Step [108/225], Training Accuracy: 97.0341%, Training Loss: 0.0996%\n",
      "Epoch [53/300], Step [109/225], Training Accuracy: 97.0183%, Training Loss: 0.0996%\n",
      "Epoch [53/300], Step [110/225], Training Accuracy: 97.0312%, Training Loss: 0.0993%\n",
      "Epoch [53/300], Step [111/225], Training Accuracy: 97.0439%, Training Loss: 0.0988%\n",
      "Epoch [53/300], Step [112/225], Training Accuracy: 97.0424%, Training Loss: 0.0987%\n",
      "Epoch [53/300], Step [113/225], Training Accuracy: 97.0409%, Training Loss: 0.0985%\n",
      "Epoch [53/300], Step [114/225], Training Accuracy: 97.0532%, Training Loss: 0.0982%\n",
      "Epoch [53/300], Step [115/225], Training Accuracy: 97.0516%, Training Loss: 0.0980%\n",
      "Epoch [53/300], Step [116/225], Training Accuracy: 97.0770%, Training Loss: 0.0981%\n",
      "Epoch [53/300], Step [117/225], Training Accuracy: 97.0887%, Training Loss: 0.0978%\n",
      "Epoch [53/300], Step [118/225], Training Accuracy: 97.0471%, Training Loss: 0.0985%\n",
      "Epoch [53/300], Step [119/225], Training Accuracy: 97.0457%, Training Loss: 0.0984%\n",
      "Epoch [53/300], Step [120/225], Training Accuracy: 97.0573%, Training Loss: 0.0980%\n",
      "Epoch [53/300], Step [121/225], Training Accuracy: 97.0558%, Training Loss: 0.0981%\n",
      "Epoch [53/300], Step [122/225], Training Accuracy: 97.0671%, Training Loss: 0.0978%\n",
      "Epoch [53/300], Step [123/225], Training Accuracy: 97.0528%, Training Loss: 0.0979%\n",
      "Epoch [53/300], Step [124/225], Training Accuracy: 97.0514%, Training Loss: 0.0977%\n",
      "Epoch [53/300], Step [125/225], Training Accuracy: 97.0500%, Training Loss: 0.0979%\n",
      "Epoch [53/300], Step [126/225], Training Accuracy: 97.0486%, Training Loss: 0.0979%\n",
      "Epoch [53/300], Step [127/225], Training Accuracy: 96.9980%, Training Loss: 0.0982%\n",
      "Epoch [53/300], Step [128/225], Training Accuracy: 96.9971%, Training Loss: 0.0984%\n",
      "Epoch [53/300], Step [129/225], Training Accuracy: 96.9840%, Training Loss: 0.0985%\n",
      "Epoch [53/300], Step [130/225], Training Accuracy: 97.0072%, Training Loss: 0.0981%\n",
      "Epoch [53/300], Step [131/225], Training Accuracy: 97.0301%, Training Loss: 0.0976%\n",
      "Epoch [53/300], Step [132/225], Training Accuracy: 97.0289%, Training Loss: 0.0978%\n",
      "Epoch [53/300], Step [133/225], Training Accuracy: 97.0277%, Training Loss: 0.0979%\n",
      "Epoch [53/300], Step [134/225], Training Accuracy: 97.0499%, Training Loss: 0.0977%\n",
      "Epoch [53/300], Step [135/225], Training Accuracy: 97.0718%, Training Loss: 0.0973%\n",
      "Epoch [53/300], Step [136/225], Training Accuracy: 97.0473%, Training Loss: 0.0978%\n",
      "Epoch [53/300], Step [137/225], Training Accuracy: 97.0347%, Training Loss: 0.0980%\n",
      "Epoch [53/300], Step [138/225], Training Accuracy: 97.0448%, Training Loss: 0.0977%\n",
      "Epoch [53/300], Step [139/225], Training Accuracy: 97.0436%, Training Loss: 0.0978%\n",
      "Epoch [53/300], Step [140/225], Training Accuracy: 97.0647%, Training Loss: 0.0976%\n",
      "Epoch [53/300], Step [141/225], Training Accuracy: 97.0634%, Training Loss: 0.0977%\n",
      "Epoch [53/300], Step [142/225], Training Accuracy: 97.0731%, Training Loss: 0.0976%\n",
      "Epoch [53/300], Step [143/225], Training Accuracy: 97.0826%, Training Loss: 0.0976%\n",
      "Epoch [53/300], Step [144/225], Training Accuracy: 97.1029%, Training Loss: 0.0972%\n",
      "Epoch [53/300], Step [145/225], Training Accuracy: 97.1013%, Training Loss: 0.0971%\n",
      "Epoch [53/300], Step [146/225], Training Accuracy: 97.0890%, Training Loss: 0.0971%\n",
      "Epoch [53/300], Step [147/225], Training Accuracy: 97.0876%, Training Loss: 0.0972%\n",
      "Epoch [53/300], Step [148/225], Training Accuracy: 97.0861%, Training Loss: 0.0971%\n",
      "Epoch [53/300], Step [149/225], Training Accuracy: 97.0742%, Training Loss: 0.0974%\n",
      "Epoch [53/300], Step [150/225], Training Accuracy: 97.0625%, Training Loss: 0.0974%\n",
      "Epoch [53/300], Step [151/225], Training Accuracy: 97.0509%, Training Loss: 0.0974%\n",
      "Epoch [53/300], Step [152/225], Training Accuracy: 97.0600%, Training Loss: 0.0972%\n",
      "Epoch [53/300], Step [153/225], Training Accuracy: 97.0792%, Training Loss: 0.0968%\n",
      "Epoch [53/300], Step [154/225], Training Accuracy: 97.0881%, Training Loss: 0.0966%\n",
      "Epoch [53/300], Step [155/225], Training Accuracy: 97.1069%, Training Loss: 0.0964%\n",
      "Epoch [53/300], Step [156/225], Training Accuracy: 97.0954%, Training Loss: 0.0962%\n",
      "Epoch [53/300], Step [157/225], Training Accuracy: 97.1039%, Training Loss: 0.0962%\n",
      "Epoch [53/300], Step [158/225], Training Accuracy: 97.1123%, Training Loss: 0.0959%\n",
      "Epoch [53/300], Step [159/225], Training Accuracy: 97.1207%, Training Loss: 0.0957%\n",
      "Epoch [53/300], Step [160/225], Training Accuracy: 97.1289%, Training Loss: 0.0958%\n",
      "Epoch [53/300], Step [161/225], Training Accuracy: 97.1467%, Training Loss: 0.0954%\n",
      "Epoch [53/300], Step [162/225], Training Accuracy: 97.1547%, Training Loss: 0.0955%\n",
      "Epoch [53/300], Step [163/225], Training Accuracy: 97.1530%, Training Loss: 0.0958%\n",
      "Epoch [53/300], Step [164/225], Training Accuracy: 97.1513%, Training Loss: 0.0958%\n",
      "Epoch [53/300], Step [165/225], Training Accuracy: 97.1591%, Training Loss: 0.0956%\n",
      "Epoch [53/300], Step [166/225], Training Accuracy: 97.1197%, Training Loss: 0.0961%\n",
      "Epoch [53/300], Step [167/225], Training Accuracy: 97.1183%, Training Loss: 0.0962%\n",
      "Epoch [53/300], Step [168/225], Training Accuracy: 97.1075%, Training Loss: 0.0962%\n",
      "Epoch [53/300], Step [169/225], Training Accuracy: 97.1061%, Training Loss: 0.0960%\n",
      "Epoch [53/300], Step [170/225], Training Accuracy: 97.0956%, Training Loss: 0.0961%\n",
      "Epoch [53/300], Step [171/225], Training Accuracy: 97.1126%, Training Loss: 0.0959%\n",
      "Epoch [53/300], Step [172/225], Training Accuracy: 97.1021%, Training Loss: 0.0960%\n",
      "Epoch [53/300], Step [173/225], Training Accuracy: 97.1098%, Training Loss: 0.0959%\n",
      "Epoch [53/300], Step [174/225], Training Accuracy: 97.1175%, Training Loss: 0.0957%\n",
      "Epoch [53/300], Step [175/225], Training Accuracy: 97.1161%, Training Loss: 0.0958%\n",
      "Epoch [53/300], Step [176/225], Training Accuracy: 97.1325%, Training Loss: 0.0956%\n",
      "Epoch [53/300], Step [177/225], Training Accuracy: 97.1310%, Training Loss: 0.0955%\n",
      "Epoch [53/300], Step [178/225], Training Accuracy: 97.1383%, Training Loss: 0.0955%\n",
      "Epoch [53/300], Step [179/225], Training Accuracy: 97.1543%, Training Loss: 0.0951%\n",
      "Epoch [53/300], Step [180/225], Training Accuracy: 97.1354%, Training Loss: 0.0954%\n",
      "Epoch [53/300], Step [181/225], Training Accuracy: 97.1426%, Training Loss: 0.0953%\n",
      "Epoch [53/300], Step [182/225], Training Accuracy: 97.1497%, Training Loss: 0.0950%\n",
      "Epoch [53/300], Step [183/225], Training Accuracy: 97.1653%, Training Loss: 0.0947%\n",
      "Epoch [53/300], Step [184/225], Training Accuracy: 97.1552%, Training Loss: 0.0947%\n",
      "Epoch [53/300], Step [185/225], Training Accuracy: 97.1537%, Training Loss: 0.0947%\n",
      "Epoch [53/300], Step [186/225], Training Accuracy: 97.1606%, Training Loss: 0.0945%\n",
      "Epoch [53/300], Step [187/225], Training Accuracy: 97.1591%, Training Loss: 0.0945%\n",
      "Epoch [53/300], Step [188/225], Training Accuracy: 97.1742%, Training Loss: 0.0942%\n",
      "Epoch [53/300], Step [189/225], Training Accuracy: 97.1892%, Training Loss: 0.0940%\n",
      "Epoch [53/300], Step [190/225], Training Accuracy: 97.1957%, Training Loss: 0.0939%\n",
      "Epoch [53/300], Step [191/225], Training Accuracy: 97.2022%, Training Loss: 0.0939%\n",
      "Epoch [53/300], Step [192/225], Training Accuracy: 97.1761%, Training Loss: 0.0941%\n",
      "Epoch [53/300], Step [193/225], Training Accuracy: 97.1665%, Training Loss: 0.0941%\n",
      "Epoch [53/300], Step [194/225], Training Accuracy: 97.1488%, Training Loss: 0.0944%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/300], Step [195/225], Training Accuracy: 97.1474%, Training Loss: 0.0944%\n",
      "Epoch [53/300], Step [196/225], Training Accuracy: 97.1540%, Training Loss: 0.0942%\n",
      "Epoch [53/300], Step [197/225], Training Accuracy: 97.1447%, Training Loss: 0.0942%\n",
      "Epoch [53/300], Step [198/225], Training Accuracy: 97.1354%, Training Loss: 0.0943%\n",
      "Epoch [53/300], Step [199/225], Training Accuracy: 97.1420%, Training Loss: 0.0942%\n",
      "Epoch [53/300], Step [200/225], Training Accuracy: 97.1484%, Training Loss: 0.0941%\n",
      "Epoch [53/300], Step [201/225], Training Accuracy: 97.1315%, Training Loss: 0.0943%\n",
      "Epoch [53/300], Step [202/225], Training Accuracy: 97.1457%, Training Loss: 0.0940%\n",
      "Epoch [53/300], Step [203/225], Training Accuracy: 97.1598%, Training Loss: 0.0938%\n",
      "Epoch [53/300], Step [204/225], Training Accuracy: 97.1737%, Training Loss: 0.0937%\n",
      "Epoch [53/300], Step [205/225], Training Accuracy: 97.1875%, Training Loss: 0.0934%\n",
      "Epoch [53/300], Step [206/225], Training Accuracy: 97.1708%, Training Loss: 0.0937%\n",
      "Epoch [53/300], Step [207/225], Training Accuracy: 97.1769%, Training Loss: 0.0936%\n",
      "Epoch [53/300], Step [208/225], Training Accuracy: 97.1680%, Training Loss: 0.0937%\n",
      "Epoch [53/300], Step [209/225], Training Accuracy: 97.1666%, Training Loss: 0.0938%\n",
      "Epoch [53/300], Step [210/225], Training Accuracy: 97.1726%, Training Loss: 0.0937%\n",
      "Epoch [53/300], Step [211/225], Training Accuracy: 97.1712%, Training Loss: 0.0939%\n",
      "Epoch [53/300], Step [212/225], Training Accuracy: 97.1772%, Training Loss: 0.0937%\n",
      "Epoch [53/300], Step [213/225], Training Accuracy: 97.1831%, Training Loss: 0.0937%\n",
      "Epoch [53/300], Step [214/225], Training Accuracy: 97.1890%, Training Loss: 0.0936%\n",
      "Epoch [53/300], Step [215/225], Training Accuracy: 97.1875%, Training Loss: 0.0936%\n",
      "Epoch [53/300], Step [216/225], Training Accuracy: 97.1861%, Training Loss: 0.0937%\n",
      "Epoch [53/300], Step [217/225], Training Accuracy: 97.1702%, Training Loss: 0.0940%\n",
      "Epoch [53/300], Step [218/225], Training Accuracy: 97.1760%, Training Loss: 0.0938%\n",
      "Epoch [53/300], Step [219/225], Training Accuracy: 97.1818%, Training Loss: 0.0937%\n",
      "Epoch [53/300], Step [220/225], Training Accuracy: 97.1804%, Training Loss: 0.0937%\n",
      "Epoch [53/300], Step [221/225], Training Accuracy: 97.1719%, Training Loss: 0.0936%\n",
      "Epoch [53/300], Step [222/225], Training Accuracy: 97.1706%, Training Loss: 0.0937%\n",
      "Epoch [53/300], Step [223/225], Training Accuracy: 97.1693%, Training Loss: 0.0936%\n",
      "Epoch [53/300], Step [224/225], Training Accuracy: 97.1819%, Training Loss: 0.0934%\n",
      "Epoch [53/300], Step [225/225], Training Accuracy: 97.1929%, Training Loss: 0.0933%\n",
      "Epoch [54/300], Step [1/225], Training Accuracy: 95.3125%, Training Loss: 0.1258%\n",
      "Epoch [54/300], Step [2/225], Training Accuracy: 96.0938%, Training Loss: 0.0966%\n",
      "Epoch [54/300], Step [3/225], Training Accuracy: 96.8750%, Training Loss: 0.0852%\n",
      "Epoch [54/300], Step [4/225], Training Accuracy: 96.4844%, Training Loss: 0.0902%\n",
      "Epoch [54/300], Step [5/225], Training Accuracy: 96.8750%, Training Loss: 0.0910%\n",
      "Epoch [54/300], Step [6/225], Training Accuracy: 97.1354%, Training Loss: 0.0859%\n",
      "Epoch [54/300], Step [7/225], Training Accuracy: 96.6518%, Training Loss: 0.0920%\n",
      "Epoch [54/300], Step [8/225], Training Accuracy: 96.8750%, Training Loss: 0.0879%\n",
      "Epoch [54/300], Step [9/225], Training Accuracy: 96.7014%, Training Loss: 0.0880%\n",
      "Epoch [54/300], Step [10/225], Training Accuracy: 96.7188%, Training Loss: 0.0880%\n",
      "Epoch [54/300], Step [11/225], Training Accuracy: 96.5909%, Training Loss: 0.0902%\n",
      "Epoch [54/300], Step [12/225], Training Accuracy: 96.7448%, Training Loss: 0.0904%\n",
      "Epoch [54/300], Step [13/225], Training Accuracy: 96.5144%, Training Loss: 0.0946%\n",
      "Epoch [54/300], Step [14/225], Training Accuracy: 96.5402%, Training Loss: 0.0974%\n",
      "Epoch [54/300], Step [15/225], Training Accuracy: 96.6667%, Training Loss: 0.0961%\n",
      "Epoch [54/300], Step [16/225], Training Accuracy: 96.7773%, Training Loss: 0.0956%\n",
      "Epoch [54/300], Step [17/225], Training Accuracy: 96.6912%, Training Loss: 0.0974%\n",
      "Epoch [54/300], Step [18/225], Training Accuracy: 96.4410%, Training Loss: 0.1061%\n",
      "Epoch [54/300], Step [19/225], Training Accuracy: 96.5461%, Training Loss: 0.1042%\n",
      "Epoch [54/300], Step [20/225], Training Accuracy: 96.4844%, Training Loss: 0.1051%\n",
      "Epoch [54/300], Step [21/225], Training Accuracy: 96.5030%, Training Loss: 0.1048%\n",
      "Epoch [54/300], Step [22/225], Training Accuracy: 96.5909%, Training Loss: 0.1040%\n",
      "Epoch [54/300], Step [23/225], Training Accuracy: 96.6712%, Training Loss: 0.1031%\n",
      "Epoch [54/300], Step [24/225], Training Accuracy: 96.6797%, Training Loss: 0.1025%\n",
      "Epoch [54/300], Step [25/225], Training Accuracy: 96.7500%, Training Loss: 0.1002%\n",
      "Epoch [54/300], Step [26/225], Training Accuracy: 96.6947%, Training Loss: 0.0991%\n",
      "Epoch [54/300], Step [27/225], Training Accuracy: 96.5856%, Training Loss: 0.1005%\n",
      "Epoch [54/300], Step [28/225], Training Accuracy: 96.6518%, Training Loss: 0.0987%\n",
      "Epoch [54/300], Step [29/225], Training Accuracy: 96.7672%, Training Loss: 0.0970%\n",
      "Epoch [54/300], Step [30/225], Training Accuracy: 96.7708%, Training Loss: 0.0975%\n",
      "Epoch [54/300], Step [31/225], Training Accuracy: 96.7742%, Training Loss: 0.0997%\n",
      "Epoch [54/300], Step [32/225], Training Accuracy: 96.7773%, Training Loss: 0.0995%\n",
      "Epoch [54/300], Step [33/225], Training Accuracy: 96.7330%, Training Loss: 0.0994%\n",
      "Epoch [54/300], Step [34/225], Training Accuracy: 96.7831%, Training Loss: 0.0983%\n",
      "Epoch [54/300], Step [35/225], Training Accuracy: 96.8750%, Training Loss: 0.0969%\n",
      "Epoch [54/300], Step [36/225], Training Accuracy: 96.9184%, Training Loss: 0.0957%\n",
      "Epoch [54/300], Step [37/225], Training Accuracy: 96.9595%, Training Loss: 0.0956%\n",
      "Epoch [54/300], Step [38/225], Training Accuracy: 96.8750%, Training Loss: 0.0981%\n",
      "Epoch [54/300], Step [39/225], Training Accuracy: 96.8750%, Training Loss: 0.0985%\n",
      "Epoch [54/300], Step [40/225], Training Accuracy: 96.8750%, Training Loss: 0.0988%\n",
      "Epoch [54/300], Step [41/225], Training Accuracy: 96.7607%, Training Loss: 0.1010%\n",
      "Epoch [54/300], Step [42/225], Training Accuracy: 96.7634%, Training Loss: 0.1000%\n",
      "Epoch [54/300], Step [43/225], Training Accuracy: 96.8387%, Training Loss: 0.0988%\n",
      "Epoch [54/300], Step [44/225], Training Accuracy: 96.8395%, Training Loss: 0.0985%\n",
      "Epoch [54/300], Step [45/225], Training Accuracy: 96.8750%, Training Loss: 0.0979%\n",
      "Epoch [54/300], Step [46/225], Training Accuracy: 96.9090%, Training Loss: 0.0970%\n",
      "Epoch [54/300], Step [47/225], Training Accuracy: 96.9082%, Training Loss: 0.0971%\n",
      "Epoch [54/300], Step [48/225], Training Accuracy: 96.9401%, Training Loss: 0.0963%\n",
      "Epoch [54/300], Step [49/225], Training Accuracy: 96.8750%, Training Loss: 0.0972%\n",
      "Epoch [54/300], Step [50/225], Training Accuracy: 96.8750%, Training Loss: 0.0969%\n",
      "Epoch [54/300], Step [51/225], Training Accuracy: 96.9056%, Training Loss: 0.0963%\n",
      "Epoch [54/300], Step [52/225], Training Accuracy: 96.9651%, Training Loss: 0.0953%\n",
      "Epoch [54/300], Step [53/225], Training Accuracy: 97.0224%, Training Loss: 0.0949%\n",
      "Epoch [54/300], Step [54/225], Training Accuracy: 97.0197%, Training Loss: 0.0957%\n",
      "Epoch [54/300], Step [55/225], Training Accuracy: 97.0455%, Training Loss: 0.0951%\n",
      "Epoch [54/300], Step [56/225], Training Accuracy: 97.0424%, Training Loss: 0.0956%\n",
      "Epoch [54/300], Step [57/225], Training Accuracy: 97.0395%, Training Loss: 0.0956%\n",
      "Epoch [54/300], Step [58/225], Training Accuracy: 97.0905%, Training Loss: 0.0950%\n",
      "Epoch [54/300], Step [59/225], Training Accuracy: 97.0869%, Training Loss: 0.0951%\n",
      "Epoch [54/300], Step [60/225], Training Accuracy: 97.1354%, Training Loss: 0.0945%\n",
      "Epoch [54/300], Step [61/225], Training Accuracy: 97.1568%, Training Loss: 0.0942%\n",
      "Epoch [54/300], Step [62/225], Training Accuracy: 97.1522%, Training Loss: 0.0944%\n",
      "Epoch [54/300], Step [63/225], Training Accuracy: 97.1974%, Training Loss: 0.0941%\n",
      "Epoch [54/300], Step [64/225], Training Accuracy: 97.1924%, Training Loss: 0.0943%\n",
      "Epoch [54/300], Step [65/225], Training Accuracy: 97.2356%, Training Loss: 0.0935%\n",
      "Epoch [54/300], Step [66/225], Training Accuracy: 97.2301%, Training Loss: 0.0936%\n",
      "Epoch [54/300], Step [67/225], Training Accuracy: 97.2481%, Training Loss: 0.0936%\n",
      "Epoch [54/300], Step [68/225], Training Accuracy: 97.2197%, Training Loss: 0.0938%\n",
      "Epoch [54/300], Step [69/225], Training Accuracy: 97.1920%, Training Loss: 0.0944%\n",
      "Epoch [54/300], Step [70/225], Training Accuracy: 97.1652%, Training Loss: 0.0942%\n",
      "Epoch [54/300], Step [71/225], Training Accuracy: 97.1611%, Training Loss: 0.0940%\n",
      "Epoch [54/300], Step [72/225], Training Accuracy: 97.1788%, Training Loss: 0.0938%\n",
      "Epoch [54/300], Step [73/225], Training Accuracy: 97.1533%, Training Loss: 0.0945%\n",
      "Epoch [54/300], Step [74/225], Training Accuracy: 97.1284%, Training Loss: 0.0949%\n",
      "Epoch [54/300], Step [75/225], Training Accuracy: 97.1667%, Training Loss: 0.0944%\n",
      "Epoch [54/300], Step [76/225], Training Accuracy: 97.1628%, Training Loss: 0.0945%\n",
      "Epoch [54/300], Step [77/225], Training Accuracy: 97.1794%, Training Loss: 0.0948%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/300], Step [78/225], Training Accuracy: 97.2155%, Training Loss: 0.0942%\n",
      "Epoch [54/300], Step [79/225], Training Accuracy: 97.2112%, Training Loss: 0.0945%\n",
      "Epoch [54/300], Step [80/225], Training Accuracy: 97.2461%, Training Loss: 0.0942%\n",
      "Epoch [54/300], Step [81/225], Training Accuracy: 97.2801%, Training Loss: 0.0934%\n",
      "Epoch [54/300], Step [82/225], Training Accuracy: 97.2561%, Training Loss: 0.0937%\n",
      "Epoch [54/300], Step [83/225], Training Accuracy: 97.2515%, Training Loss: 0.0940%\n",
      "Epoch [54/300], Step [84/225], Training Accuracy: 97.2284%, Training Loss: 0.0941%\n",
      "Epoch [54/300], Step [85/225], Training Accuracy: 97.2059%, Training Loss: 0.0942%\n",
      "Epoch [54/300], Step [86/225], Training Accuracy: 97.1839%, Training Loss: 0.0947%\n",
      "Epoch [54/300], Step [87/225], Training Accuracy: 97.1803%, Training Loss: 0.0951%\n",
      "Epoch [54/300], Step [88/225], Training Accuracy: 97.1591%, Training Loss: 0.0952%\n",
      "Epoch [54/300], Step [89/225], Training Accuracy: 97.1208%, Training Loss: 0.0959%\n",
      "Epoch [54/300], Step [90/225], Training Accuracy: 97.1181%, Training Loss: 0.0960%\n",
      "Epoch [54/300], Step [91/225], Training Accuracy: 97.1497%, Training Loss: 0.0956%\n",
      "Epoch [54/300], Step [92/225], Training Accuracy: 97.1467%, Training Loss: 0.0958%\n",
      "Epoch [54/300], Step [93/225], Training Accuracy: 97.1606%, Training Loss: 0.0955%\n",
      "Epoch [54/300], Step [94/225], Training Accuracy: 97.1742%, Training Loss: 0.0951%\n",
      "Epoch [54/300], Step [95/225], Training Accuracy: 97.1546%, Training Loss: 0.0956%\n",
      "Epoch [54/300], Step [96/225], Training Accuracy: 97.1842%, Training Loss: 0.0951%\n",
      "Epoch [54/300], Step [97/225], Training Accuracy: 97.1488%, Training Loss: 0.0954%\n",
      "Epoch [54/300], Step [98/225], Training Accuracy: 97.1460%, Training Loss: 0.0953%\n",
      "Epoch [54/300], Step [99/225], Training Accuracy: 97.1433%, Training Loss: 0.0952%\n",
      "Epoch [54/300], Step [100/225], Training Accuracy: 97.1562%, Training Loss: 0.0949%\n",
      "Epoch [54/300], Step [101/225], Training Accuracy: 97.1535%, Training Loss: 0.0957%\n",
      "Epoch [54/300], Step [102/225], Training Accuracy: 97.1661%, Training Loss: 0.0952%\n",
      "Epoch [54/300], Step [103/225], Training Accuracy: 97.1784%, Training Loss: 0.0949%\n",
      "Epoch [54/300], Step [104/225], Training Accuracy: 97.1905%, Training Loss: 0.0948%\n",
      "Epoch [54/300], Step [105/225], Training Accuracy: 97.1875%, Training Loss: 0.0947%\n",
      "Epoch [54/300], Step [106/225], Training Accuracy: 97.1846%, Training Loss: 0.0948%\n",
      "Epoch [54/300], Step [107/225], Training Accuracy: 97.1963%, Training Loss: 0.0946%\n",
      "Epoch [54/300], Step [108/225], Training Accuracy: 97.2222%, Training Loss: 0.0939%\n",
      "Epoch [54/300], Step [109/225], Training Accuracy: 97.2477%, Training Loss: 0.0935%\n",
      "Epoch [54/300], Step [110/225], Training Accuracy: 97.2585%, Training Loss: 0.0931%\n",
      "Epoch [54/300], Step [111/225], Training Accuracy: 97.2551%, Training Loss: 0.0934%\n",
      "Epoch [54/300], Step [112/225], Training Accuracy: 97.2517%, Training Loss: 0.0938%\n",
      "Epoch [54/300], Step [113/225], Training Accuracy: 97.2622%, Training Loss: 0.0935%\n",
      "Epoch [54/300], Step [114/225], Training Accuracy: 97.2725%, Training Loss: 0.0934%\n",
      "Epoch [54/300], Step [115/225], Training Accuracy: 97.2690%, Training Loss: 0.0931%\n",
      "Epoch [54/300], Step [116/225], Training Accuracy: 97.2522%, Training Loss: 0.0932%\n",
      "Epoch [54/300], Step [117/225], Training Accuracy: 97.2489%, Training Loss: 0.0932%\n",
      "Epoch [54/300], Step [118/225], Training Accuracy: 97.2325%, Training Loss: 0.0930%\n",
      "Epoch [54/300], Step [119/225], Training Accuracy: 97.2164%, Training Loss: 0.0930%\n",
      "Epoch [54/300], Step [120/225], Training Accuracy: 97.2266%, Training Loss: 0.0930%\n",
      "Epoch [54/300], Step [121/225], Training Accuracy: 97.2237%, Training Loss: 0.0928%\n",
      "Epoch [54/300], Step [122/225], Training Accuracy: 97.2464%, Training Loss: 0.0924%\n",
      "Epoch [54/300], Step [123/225], Training Accuracy: 97.2561%, Training Loss: 0.0923%\n",
      "Epoch [54/300], Step [124/225], Training Accuracy: 97.2404%, Training Loss: 0.0926%\n",
      "Epoch [54/300], Step [125/225], Training Accuracy: 97.2500%, Training Loss: 0.0923%\n",
      "Epoch [54/300], Step [126/225], Training Accuracy: 97.2346%, Training Loss: 0.0924%\n",
      "Epoch [54/300], Step [127/225], Training Accuracy: 97.2441%, Training Loss: 0.0924%\n",
      "Epoch [54/300], Step [128/225], Training Accuracy: 97.2290%, Training Loss: 0.0926%\n",
      "Epoch [54/300], Step [129/225], Training Accuracy: 97.2384%, Training Loss: 0.0926%\n",
      "Epoch [54/300], Step [130/225], Training Accuracy: 97.2356%, Training Loss: 0.0927%\n",
      "Epoch [54/300], Step [131/225], Training Accuracy: 97.2448%, Training Loss: 0.0924%\n",
      "Epoch [54/300], Step [132/225], Training Accuracy: 97.2656%, Training Loss: 0.0920%\n",
      "Epoch [54/300], Step [133/225], Training Accuracy: 97.2627%, Training Loss: 0.0918%\n",
      "Epoch [54/300], Step [134/225], Training Accuracy: 97.2715%, Training Loss: 0.0919%\n",
      "Epoch [54/300], Step [135/225], Training Accuracy: 97.2917%, Training Loss: 0.0914%\n",
      "Epoch [54/300], Step [136/225], Training Accuracy: 97.2656%, Training Loss: 0.0918%\n",
      "Epoch [54/300], Step [137/225], Training Accuracy: 97.2856%, Training Loss: 0.0913%\n",
      "Epoch [54/300], Step [138/225], Training Accuracy: 97.3053%, Training Loss: 0.0911%\n",
      "Epoch [54/300], Step [139/225], Training Accuracy: 97.3134%, Training Loss: 0.0909%\n",
      "Epoch [54/300], Step [140/225], Training Accuracy: 97.3326%, Training Loss: 0.0907%\n",
      "Epoch [54/300], Step [141/225], Training Accuracy: 97.3404%, Training Loss: 0.0908%\n",
      "Epoch [54/300], Step [142/225], Training Accuracy: 97.3592%, Training Loss: 0.0904%\n",
      "Epoch [54/300], Step [143/225], Training Accuracy: 97.3448%, Training Loss: 0.0905%\n",
      "Epoch [54/300], Step [144/225], Training Accuracy: 97.3307%, Training Loss: 0.0908%\n",
      "Epoch [54/300], Step [145/225], Training Accuracy: 97.3276%, Training Loss: 0.0907%\n",
      "Epoch [54/300], Step [146/225], Training Accuracy: 97.3352%, Training Loss: 0.0906%\n",
      "Epoch [54/300], Step [147/225], Training Accuracy: 97.3321%, Training Loss: 0.0906%\n",
      "Epoch [54/300], Step [148/225], Training Accuracy: 97.3184%, Training Loss: 0.0909%\n",
      "Epoch [54/300], Step [149/225], Training Accuracy: 97.2945%, Training Loss: 0.0913%\n",
      "Epoch [54/300], Step [150/225], Training Accuracy: 97.3125%, Training Loss: 0.0911%\n",
      "Epoch [54/300], Step [151/225], Training Accuracy: 97.3303%, Training Loss: 0.0907%\n",
      "Epoch [54/300], Step [152/225], Training Accuracy: 97.3376%, Training Loss: 0.0905%\n",
      "Epoch [54/300], Step [153/225], Training Accuracy: 97.3346%, Training Loss: 0.0905%\n",
      "Epoch [54/300], Step [154/225], Training Accuracy: 97.3417%, Training Loss: 0.0904%\n",
      "Epoch [54/300], Step [155/225], Training Accuracy: 97.3488%, Training Loss: 0.0902%\n",
      "Epoch [54/300], Step [156/225], Training Accuracy: 97.3658%, Training Loss: 0.0899%\n",
      "Epoch [54/300], Step [157/225], Training Accuracy: 97.3627%, Training Loss: 0.0900%\n",
      "Epoch [54/300], Step [158/225], Training Accuracy: 97.3596%, Training Loss: 0.0899%\n",
      "Epoch [54/300], Step [159/225], Training Accuracy: 97.3467%, Training Loss: 0.0899%\n",
      "Epoch [54/300], Step [160/225], Training Accuracy: 97.3633%, Training Loss: 0.0896%\n",
      "Epoch [54/300], Step [161/225], Training Accuracy: 97.3797%, Training Loss: 0.0893%\n",
      "Epoch [54/300], Step [162/225], Training Accuracy: 97.3669%, Training Loss: 0.0892%\n",
      "Epoch [54/300], Step [163/225], Training Accuracy: 97.3831%, Training Loss: 0.0891%\n",
      "Epoch [54/300], Step [164/225], Training Accuracy: 97.3800%, Training Loss: 0.0891%\n",
      "Epoch [54/300], Step [165/225], Training Accuracy: 97.3864%, Training Loss: 0.0890%\n",
      "Epoch [54/300], Step [166/225], Training Accuracy: 97.3739%, Training Loss: 0.0892%\n",
      "Epoch [54/300], Step [167/225], Training Accuracy: 97.3802%, Training Loss: 0.0892%\n",
      "Epoch [54/300], Step [168/225], Training Accuracy: 97.3958%, Training Loss: 0.0889%\n",
      "Epoch [54/300], Step [169/225], Training Accuracy: 97.4020%, Training Loss: 0.0888%\n",
      "Epoch [54/300], Step [170/225], Training Accuracy: 97.3989%, Training Loss: 0.0890%\n",
      "Epoch [54/300], Step [171/225], Training Accuracy: 97.3958%, Training Loss: 0.0889%\n",
      "Epoch [54/300], Step [172/225], Training Accuracy: 97.3837%, Training Loss: 0.0890%\n",
      "Epoch [54/300], Step [173/225], Training Accuracy: 97.3808%, Training Loss: 0.0889%\n",
      "Epoch [54/300], Step [174/225], Training Accuracy: 97.3779%, Training Loss: 0.0888%\n",
      "Epoch [54/300], Step [175/225], Training Accuracy: 97.3750%, Training Loss: 0.0890%\n",
      "Epoch [54/300], Step [176/225], Training Accuracy: 97.3722%, Training Loss: 0.0889%\n",
      "Epoch [54/300], Step [177/225], Training Accuracy: 97.3782%, Training Loss: 0.0887%\n",
      "Epoch [54/300], Step [178/225], Training Accuracy: 97.3754%, Training Loss: 0.0886%\n",
      "Epoch [54/300], Step [179/225], Training Accuracy: 97.3726%, Training Loss: 0.0887%\n",
      "Epoch [54/300], Step [180/225], Training Accuracy: 97.3785%, Training Loss: 0.0886%\n",
      "Epoch [54/300], Step [181/225], Training Accuracy: 97.3843%, Training Loss: 0.0884%\n",
      "Epoch [54/300], Step [182/225], Training Accuracy: 97.3815%, Training Loss: 0.0884%\n",
      "Epoch [54/300], Step [183/225], Training Accuracy: 97.3958%, Training Loss: 0.0881%\n",
      "Epoch [54/300], Step [184/225], Training Accuracy: 97.3930%, Training Loss: 0.0881%\n",
      "Epoch [54/300], Step [185/225], Training Accuracy: 97.3902%, Training Loss: 0.0882%\n",
      "Epoch [54/300], Step [186/225], Training Accuracy: 97.3958%, Training Loss: 0.0880%\n",
      "Epoch [54/300], Step [187/225], Training Accuracy: 97.4014%, Training Loss: 0.0879%\n",
      "Epoch [54/300], Step [188/225], Training Accuracy: 97.4152%, Training Loss: 0.0877%\n",
      "Epoch [54/300], Step [189/225], Training Accuracy: 97.4289%, Training Loss: 0.0875%\n",
      "Epoch [54/300], Step [190/225], Training Accuracy: 97.4095%, Training Loss: 0.0878%\n",
      "Epoch [54/300], Step [191/225], Training Accuracy: 97.4149%, Training Loss: 0.0878%\n",
      "Epoch [54/300], Step [192/225], Training Accuracy: 97.4121%, Training Loss: 0.0877%\n",
      "Epoch [54/300], Step [193/225], Training Accuracy: 97.4093%, Training Loss: 0.0877%\n",
      "Epoch [54/300], Step [194/225], Training Accuracy: 97.4066%, Training Loss: 0.0879%\n",
      "Epoch [54/300], Step [195/225], Training Accuracy: 97.4038%, Training Loss: 0.0879%\n",
      "Epoch [54/300], Step [196/225], Training Accuracy: 97.4091%, Training Loss: 0.0878%\n",
      "Epoch [54/300], Step [197/225], Training Accuracy: 97.3905%, Training Loss: 0.0880%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/300], Step [198/225], Training Accuracy: 97.3879%, Training Loss: 0.0880%\n",
      "Epoch [54/300], Step [199/225], Training Accuracy: 97.3854%, Training Loss: 0.0881%\n",
      "Epoch [54/300], Step [200/225], Training Accuracy: 97.3672%, Training Loss: 0.0882%\n",
      "Epoch [54/300], Step [201/225], Training Accuracy: 97.3803%, Training Loss: 0.0882%\n",
      "Epoch [54/300], Step [202/225], Training Accuracy: 97.3855%, Training Loss: 0.0880%\n",
      "Epoch [54/300], Step [203/225], Training Accuracy: 97.3984%, Training Loss: 0.0878%\n",
      "Epoch [54/300], Step [204/225], Training Accuracy: 97.4035%, Training Loss: 0.0877%\n",
      "Epoch [54/300], Step [205/225], Training Accuracy: 97.4085%, Training Loss: 0.0876%\n",
      "Epoch [54/300], Step [206/225], Training Accuracy: 97.3984%, Training Loss: 0.0879%\n",
      "Epoch [54/300], Step [207/225], Training Accuracy: 97.4109%, Training Loss: 0.0879%\n",
      "Epoch [54/300], Step [208/225], Training Accuracy: 97.4234%, Training Loss: 0.0876%\n",
      "Epoch [54/300], Step [209/225], Training Accuracy: 97.4357%, Training Loss: 0.0875%\n",
      "Epoch [54/300], Step [210/225], Training Accuracy: 97.4405%, Training Loss: 0.0874%\n",
      "Epoch [54/300], Step [211/225], Training Accuracy: 97.4378%, Training Loss: 0.0874%\n",
      "Epoch [54/300], Step [212/225], Training Accuracy: 97.4425%, Training Loss: 0.0873%\n",
      "Epoch [54/300], Step [213/225], Training Accuracy: 97.4325%, Training Loss: 0.0874%\n",
      "Epoch [54/300], Step [214/225], Training Accuracy: 97.4226%, Training Loss: 0.0874%\n",
      "Epoch [54/300], Step [215/225], Training Accuracy: 97.4346%, Training Loss: 0.0873%\n",
      "Epoch [54/300], Step [216/225], Training Accuracy: 97.4248%, Training Loss: 0.0875%\n",
      "Epoch [54/300], Step [217/225], Training Accuracy: 97.4294%, Training Loss: 0.0875%\n",
      "Epoch [54/300], Step [218/225], Training Accuracy: 97.4412%, Training Loss: 0.0872%\n",
      "Epoch [54/300], Step [219/225], Training Accuracy: 97.4386%, Training Loss: 0.0872%\n",
      "Epoch [54/300], Step [220/225], Training Accuracy: 97.4290%, Training Loss: 0.0873%\n",
      "Epoch [54/300], Step [221/225], Training Accuracy: 97.4406%, Training Loss: 0.0872%\n",
      "Epoch [54/300], Step [222/225], Training Accuracy: 97.4240%, Training Loss: 0.0874%\n",
      "Epoch [54/300], Step [223/225], Training Accuracy: 97.4215%, Training Loss: 0.0873%\n",
      "Epoch [54/300], Step [224/225], Training Accuracy: 97.4261%, Training Loss: 0.0872%\n",
      "Epoch [54/300], Step [225/225], Training Accuracy: 97.4152%, Training Loss: 0.0873%\n",
      "Epoch [55/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0449%\n",
      "Epoch [55/300], Step [2/225], Training Accuracy: 99.2188%, Training Loss: 0.0575%\n",
      "Epoch [55/300], Step [3/225], Training Accuracy: 97.9167%, Training Loss: 0.0767%\n",
      "Epoch [55/300], Step [4/225], Training Accuracy: 98.4375%, Training Loss: 0.0723%\n",
      "Epoch [55/300], Step [5/225], Training Accuracy: 98.1250%, Training Loss: 0.0769%\n",
      "Epoch [55/300], Step [6/225], Training Accuracy: 97.6562%, Training Loss: 0.0803%\n",
      "Epoch [55/300], Step [7/225], Training Accuracy: 97.7679%, Training Loss: 0.0785%\n",
      "Epoch [55/300], Step [8/225], Training Accuracy: 98.0469%, Training Loss: 0.0747%\n",
      "Epoch [55/300], Step [9/225], Training Accuracy: 97.5694%, Training Loss: 0.0791%\n",
      "Epoch [55/300], Step [10/225], Training Accuracy: 97.1875%, Training Loss: 0.0852%\n",
      "Epoch [55/300], Step [11/225], Training Accuracy: 97.3011%, Training Loss: 0.0851%\n",
      "Epoch [55/300], Step [12/225], Training Accuracy: 97.3958%, Training Loss: 0.0846%\n",
      "Epoch [55/300], Step [13/225], Training Accuracy: 97.4760%, Training Loss: 0.0819%\n",
      "Epoch [55/300], Step [14/225], Training Accuracy: 97.4330%, Training Loss: 0.0833%\n",
      "Epoch [55/300], Step [15/225], Training Accuracy: 97.6042%, Training Loss: 0.0819%\n",
      "Epoch [55/300], Step [16/225], Training Accuracy: 97.6562%, Training Loss: 0.0821%\n",
      "Epoch [55/300], Step [17/225], Training Accuracy: 97.5184%, Training Loss: 0.0839%\n",
      "Epoch [55/300], Step [18/225], Training Accuracy: 97.3090%, Training Loss: 0.0879%\n",
      "Epoch [55/300], Step [19/225], Training Accuracy: 97.2862%, Training Loss: 0.0889%\n",
      "Epoch [55/300], Step [20/225], Training Accuracy: 97.4219%, Training Loss: 0.0875%\n",
      "Epoch [55/300], Step [21/225], Training Accuracy: 97.5446%, Training Loss: 0.0857%\n",
      "Epoch [55/300], Step [22/225], Training Accuracy: 97.5852%, Training Loss: 0.0848%\n",
      "Epoch [55/300], Step [23/225], Training Accuracy: 97.4864%, Training Loss: 0.0871%\n",
      "Epoch [55/300], Step [24/225], Training Accuracy: 97.5260%, Training Loss: 0.0870%\n",
      "Epoch [55/300], Step [25/225], Training Accuracy: 97.4375%, Training Loss: 0.0875%\n",
      "Epoch [55/300], Step [26/225], Training Accuracy: 97.4159%, Training Loss: 0.0888%\n",
      "Epoch [55/300], Step [27/225], Training Accuracy: 97.3380%, Training Loss: 0.0902%\n",
      "Epoch [55/300], Step [28/225], Training Accuracy: 97.4330%, Training Loss: 0.0880%\n",
      "Epoch [55/300], Step [29/225], Training Accuracy: 97.4138%, Training Loss: 0.0878%\n",
      "Epoch [55/300], Step [30/225], Training Accuracy: 97.4479%, Training Loss: 0.0882%\n",
      "Epoch [55/300], Step [31/225], Training Accuracy: 97.5302%, Training Loss: 0.0870%\n",
      "Epoch [55/300], Step [32/225], Training Accuracy: 97.6074%, Training Loss: 0.0853%\n",
      "Epoch [55/300], Step [33/225], Training Accuracy: 97.6326%, Training Loss: 0.0841%\n",
      "Epoch [55/300], Step [34/225], Training Accuracy: 97.6103%, Training Loss: 0.0847%\n",
      "Epoch [55/300], Step [35/225], Training Accuracy: 97.5000%, Training Loss: 0.0857%\n",
      "Epoch [55/300], Step [36/225], Training Accuracy: 97.5694%, Training Loss: 0.0846%\n",
      "Epoch [55/300], Step [37/225], Training Accuracy: 97.5929%, Training Loss: 0.0838%\n",
      "Epoch [55/300], Step [38/225], Training Accuracy: 97.5740%, Training Loss: 0.0848%\n",
      "Epoch [55/300], Step [39/225], Training Accuracy: 97.4760%, Training Loss: 0.0879%\n",
      "Epoch [55/300], Step [40/225], Training Accuracy: 97.5391%, Training Loss: 0.0868%\n",
      "Epoch [55/300], Step [41/225], Training Accuracy: 97.4848%, Training Loss: 0.0880%\n",
      "Epoch [55/300], Step [42/225], Training Accuracy: 97.4330%, Training Loss: 0.0878%\n",
      "Epoch [55/300], Step [43/225], Training Accuracy: 97.4564%, Training Loss: 0.0875%\n",
      "Epoch [55/300], Step [44/225], Training Accuracy: 97.4787%, Training Loss: 0.0873%\n",
      "Epoch [55/300], Step [45/225], Training Accuracy: 97.4653%, Training Loss: 0.0870%\n",
      "Epoch [55/300], Step [46/225], Training Accuracy: 97.4524%, Training Loss: 0.0867%\n",
      "Epoch [55/300], Step [47/225], Training Accuracy: 97.5066%, Training Loss: 0.0859%\n",
      "Epoch [55/300], Step [48/225], Training Accuracy: 97.5586%, Training Loss: 0.0852%\n",
      "Epoch [55/300], Step [49/225], Training Accuracy: 97.4171%, Training Loss: 0.0873%\n",
      "Epoch [55/300], Step [50/225], Training Accuracy: 97.4062%, Training Loss: 0.0872%\n",
      "Epoch [55/300], Step [51/225], Training Accuracy: 97.4571%, Training Loss: 0.0859%\n",
      "Epoch [55/300], Step [52/225], Training Accuracy: 97.5060%, Training Loss: 0.0848%\n",
      "Epoch [55/300], Step [53/225], Training Accuracy: 97.5531%, Training Loss: 0.0839%\n",
      "Epoch [55/300], Step [54/225], Training Accuracy: 97.5116%, Training Loss: 0.0848%\n",
      "Epoch [55/300], Step [55/225], Training Accuracy: 97.5568%, Training Loss: 0.0843%\n",
      "Epoch [55/300], Step [56/225], Training Accuracy: 97.5725%, Training Loss: 0.0843%\n",
      "Epoch [55/300], Step [57/225], Training Accuracy: 97.5877%, Training Loss: 0.0840%\n",
      "Epoch [55/300], Step [58/225], Training Accuracy: 97.6293%, Training Loss: 0.0834%\n",
      "Epoch [55/300], Step [59/225], Training Accuracy: 97.6165%, Training Loss: 0.0838%\n",
      "Epoch [55/300], Step [60/225], Training Accuracy: 97.6302%, Training Loss: 0.0834%\n",
      "Epoch [55/300], Step [61/225], Training Accuracy: 97.6434%, Training Loss: 0.0832%\n",
      "Epoch [55/300], Step [62/225], Training Accuracy: 97.6562%, Training Loss: 0.0832%\n",
      "Epoch [55/300], Step [63/225], Training Accuracy: 97.6190%, Training Loss: 0.0831%\n",
      "Epoch [55/300], Step [64/225], Training Accuracy: 97.6318%, Training Loss: 0.0829%\n",
      "Epoch [55/300], Step [65/225], Training Accuracy: 97.6202%, Training Loss: 0.0838%\n",
      "Epoch [55/300], Step [66/225], Training Accuracy: 97.6326%, Training Loss: 0.0838%\n",
      "Epoch [55/300], Step [67/225], Training Accuracy: 97.6679%, Training Loss: 0.0836%\n",
      "Epoch [55/300], Step [68/225], Training Accuracy: 97.6562%, Training Loss: 0.0843%\n",
      "Epoch [55/300], Step [69/225], Training Accuracy: 97.6676%, Training Loss: 0.0840%\n",
      "Epoch [55/300], Step [70/225], Training Accuracy: 97.6116%, Training Loss: 0.0843%\n",
      "Epoch [55/300], Step [71/225], Training Accuracy: 97.5572%, Training Loss: 0.0861%\n",
      "Epoch [55/300], Step [72/225], Training Accuracy: 97.5694%, Training Loss: 0.0858%\n",
      "Epoch [55/300], Step [73/225], Training Accuracy: 97.5813%, Training Loss: 0.0852%\n",
      "Epoch [55/300], Step [74/225], Training Accuracy: 97.5296%, Training Loss: 0.0855%\n",
      "Epoch [55/300], Step [75/225], Training Accuracy: 97.5625%, Training Loss: 0.0850%\n",
      "Epoch [55/300], Step [76/225], Training Accuracy: 97.5329%, Training Loss: 0.0855%\n",
      "Epoch [55/300], Step [77/225], Training Accuracy: 97.5041%, Training Loss: 0.0856%\n",
      "Epoch [55/300], Step [78/225], Training Accuracy: 97.4960%, Training Loss: 0.0856%\n",
      "Epoch [55/300], Step [79/225], Training Accuracy: 97.4486%, Training Loss: 0.0861%\n",
      "Epoch [55/300], Step [80/225], Training Accuracy: 97.4414%, Training Loss: 0.0862%\n",
      "Epoch [55/300], Step [81/225], Training Accuracy: 97.4344%, Training Loss: 0.0865%\n",
      "Epoch [55/300], Step [82/225], Training Accuracy: 97.4657%, Training Loss: 0.0861%\n",
      "Epoch [55/300], Step [83/225], Training Accuracy: 97.4586%, Training Loss: 0.0869%\n",
      "Epoch [55/300], Step [84/225], Training Accuracy: 97.4516%, Training Loss: 0.0872%\n",
      "Epoch [55/300], Step [85/225], Training Accuracy: 97.4081%, Training Loss: 0.0878%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/300], Step [86/225], Training Accuracy: 97.4019%, Training Loss: 0.0882%\n",
      "Epoch [55/300], Step [87/225], Training Accuracy: 97.3958%, Training Loss: 0.0880%\n",
      "Epoch [55/300], Step [88/225], Training Accuracy: 97.3899%, Training Loss: 0.0882%\n",
      "Epoch [55/300], Step [89/225], Training Accuracy: 97.4192%, Training Loss: 0.0879%\n",
      "Epoch [55/300], Step [90/225], Training Accuracy: 97.4306%, Training Loss: 0.0877%\n",
      "Epoch [55/300], Step [91/225], Training Accuracy: 97.4073%, Training Loss: 0.0882%\n",
      "Epoch [55/300], Step [92/225], Training Accuracy: 97.4185%, Training Loss: 0.0882%\n",
      "Epoch [55/300], Step [93/225], Training Accuracy: 97.4462%, Training Loss: 0.0875%\n",
      "Epoch [55/300], Step [94/225], Training Accuracy: 97.4568%, Training Loss: 0.0872%\n",
      "Epoch [55/300], Step [95/225], Training Accuracy: 97.4342%, Training Loss: 0.0874%\n",
      "Epoch [55/300], Step [96/225], Training Accuracy: 97.4121%, Training Loss: 0.0878%\n",
      "Epoch [55/300], Step [97/225], Training Accuracy: 97.4066%, Training Loss: 0.0878%\n",
      "Epoch [55/300], Step [98/225], Training Accuracy: 97.4011%, Training Loss: 0.0878%\n",
      "Epoch [55/300], Step [99/225], Training Accuracy: 97.4116%, Training Loss: 0.0876%\n",
      "Epoch [55/300], Step [100/225], Training Accuracy: 97.4375%, Training Loss: 0.0871%\n",
      "Epoch [55/300], Step [101/225], Training Accuracy: 97.4629%, Training Loss: 0.0867%\n",
      "Epoch [55/300], Step [102/225], Training Accuracy: 97.4265%, Training Loss: 0.0873%\n",
      "Epoch [55/300], Step [103/225], Training Accuracy: 97.4363%, Training Loss: 0.0876%\n",
      "Epoch [55/300], Step [104/225], Training Accuracy: 97.4459%, Training Loss: 0.0872%\n",
      "Epoch [55/300], Step [105/225], Training Accuracy: 97.4107%, Training Loss: 0.0877%\n",
      "Epoch [55/300], Step [106/225], Training Accuracy: 97.3762%, Training Loss: 0.0881%\n",
      "Epoch [55/300], Step [107/225], Training Accuracy: 97.3861%, Training Loss: 0.0878%\n",
      "Epoch [55/300], Step [108/225], Training Accuracy: 97.3958%, Training Loss: 0.0876%\n",
      "Epoch [55/300], Step [109/225], Training Accuracy: 97.4054%, Training Loss: 0.0873%\n",
      "Epoch [55/300], Step [110/225], Training Accuracy: 97.4148%, Training Loss: 0.0870%\n",
      "Epoch [55/300], Step [111/225], Training Accuracy: 97.4099%, Training Loss: 0.0869%\n",
      "Epoch [55/300], Step [112/225], Training Accuracy: 97.4330%, Training Loss: 0.0868%\n",
      "Epoch [55/300], Step [113/225], Training Accuracy: 97.4281%, Training Loss: 0.0870%\n",
      "Epoch [55/300], Step [114/225], Training Accuracy: 97.4507%, Training Loss: 0.0869%\n",
      "Epoch [55/300], Step [115/225], Training Accuracy: 97.4592%, Training Loss: 0.0866%\n",
      "Epoch [55/300], Step [116/225], Training Accuracy: 97.4542%, Training Loss: 0.0866%\n",
      "Epoch [55/300], Step [117/225], Training Accuracy: 97.4760%, Training Loss: 0.0863%\n",
      "Epoch [55/300], Step [118/225], Training Accuracy: 97.4841%, Training Loss: 0.0862%\n",
      "Epoch [55/300], Step [119/225], Training Accuracy: 97.4396%, Training Loss: 0.0865%\n",
      "Epoch [55/300], Step [120/225], Training Accuracy: 97.4479%, Training Loss: 0.0861%\n",
      "Epoch [55/300], Step [121/225], Training Accuracy: 97.4690%, Training Loss: 0.0856%\n",
      "Epoch [55/300], Step [122/225], Training Accuracy: 97.4898%, Training Loss: 0.0851%\n",
      "Epoch [55/300], Step [123/225], Training Accuracy: 97.4848%, Training Loss: 0.0853%\n",
      "Epoch [55/300], Step [124/225], Training Accuracy: 97.4924%, Training Loss: 0.0850%\n",
      "Epoch [55/300], Step [125/225], Training Accuracy: 97.4750%, Training Loss: 0.0852%\n",
      "Epoch [55/300], Step [126/225], Training Accuracy: 97.4702%, Training Loss: 0.0851%\n",
      "Epoch [55/300], Step [127/225], Training Accuracy: 97.4286%, Training Loss: 0.0856%\n",
      "Epoch [55/300], Step [128/225], Training Accuracy: 97.4365%, Training Loss: 0.0857%\n",
      "Epoch [55/300], Step [129/225], Training Accuracy: 97.3958%, Training Loss: 0.0861%\n",
      "Epoch [55/300], Step [130/225], Training Accuracy: 97.4159%, Training Loss: 0.0861%\n",
      "Epoch [55/300], Step [131/225], Training Accuracy: 97.4237%, Training Loss: 0.0859%\n",
      "Epoch [55/300], Step [132/225], Training Accuracy: 97.4432%, Training Loss: 0.0855%\n",
      "Epoch [55/300], Step [133/225], Training Accuracy: 97.4389%, Training Loss: 0.0856%\n",
      "Epoch [55/300], Step [134/225], Training Accuracy: 97.4230%, Training Loss: 0.0858%\n",
      "Epoch [55/300], Step [135/225], Training Accuracy: 97.4190%, Training Loss: 0.0856%\n",
      "Epoch [55/300], Step [136/225], Training Accuracy: 97.4150%, Training Loss: 0.0857%\n",
      "Epoch [55/300], Step [137/225], Training Accuracy: 97.4224%, Training Loss: 0.0856%\n",
      "Epoch [55/300], Step [138/225], Training Accuracy: 97.4072%, Training Loss: 0.0857%\n",
      "Epoch [55/300], Step [139/225], Training Accuracy: 97.3808%, Training Loss: 0.0861%\n",
      "Epoch [55/300], Step [140/225], Training Accuracy: 97.3884%, Training Loss: 0.0859%\n",
      "Epoch [55/300], Step [141/225], Training Accuracy: 97.3848%, Training Loss: 0.0860%\n",
      "Epoch [55/300], Step [142/225], Training Accuracy: 97.3812%, Training Loss: 0.0859%\n",
      "Epoch [55/300], Step [143/225], Training Accuracy: 97.3667%, Training Loss: 0.0862%\n",
      "Epoch [55/300], Step [144/225], Training Accuracy: 97.3524%, Training Loss: 0.0865%\n",
      "Epoch [55/300], Step [145/225], Training Accuracy: 97.3491%, Training Loss: 0.0863%\n",
      "Epoch [55/300], Step [146/225], Training Accuracy: 97.3566%, Training Loss: 0.0860%\n",
      "Epoch [55/300], Step [147/225], Training Accuracy: 97.3108%, Training Loss: 0.0868%\n",
      "Epoch [55/300], Step [148/225], Training Accuracy: 97.3079%, Training Loss: 0.0868%\n",
      "Epoch [55/300], Step [149/225], Training Accuracy: 97.2945%, Training Loss: 0.0873%\n",
      "Epoch [55/300], Step [150/225], Training Accuracy: 97.3021%, Training Loss: 0.0871%\n",
      "Epoch [55/300], Step [151/225], Training Accuracy: 97.2889%, Training Loss: 0.0872%\n",
      "Epoch [55/300], Step [152/225], Training Accuracy: 97.3067%, Training Loss: 0.0868%\n",
      "Epoch [55/300], Step [153/225], Training Accuracy: 97.3141%, Training Loss: 0.0867%\n",
      "Epoch [55/300], Step [154/225], Training Accuracy: 97.3113%, Training Loss: 0.0868%\n",
      "Epoch [55/300], Step [155/225], Training Accuracy: 97.2883%, Training Loss: 0.0870%\n",
      "Epoch [55/300], Step [156/225], Training Accuracy: 97.3057%, Training Loss: 0.0867%\n",
      "Epoch [55/300], Step [157/225], Training Accuracy: 97.2830%, Training Loss: 0.0870%\n",
      "Epoch [55/300], Step [158/225], Training Accuracy: 97.3002%, Training Loss: 0.0868%\n",
      "Epoch [55/300], Step [159/225], Training Accuracy: 97.2976%, Training Loss: 0.0867%\n",
      "Epoch [55/300], Step [160/225], Training Accuracy: 97.2949%, Training Loss: 0.0867%\n",
      "Epoch [55/300], Step [161/225], Training Accuracy: 97.3117%, Training Loss: 0.0866%\n",
      "Epoch [55/300], Step [162/225], Training Accuracy: 97.3090%, Training Loss: 0.0868%\n",
      "Epoch [55/300], Step [163/225], Training Accuracy: 97.2968%, Training Loss: 0.0872%\n",
      "Epoch [55/300], Step [164/225], Training Accuracy: 97.3133%, Training Loss: 0.0870%\n",
      "Epoch [55/300], Step [165/225], Training Accuracy: 97.3106%, Training Loss: 0.0869%\n",
      "Epoch [55/300], Step [166/225], Training Accuracy: 97.2892%, Training Loss: 0.0871%\n",
      "Epoch [55/300], Step [167/225], Training Accuracy: 97.2680%, Training Loss: 0.0875%\n",
      "Epoch [55/300], Step [168/225], Training Accuracy: 97.2470%, Training Loss: 0.0878%\n",
      "Epoch [55/300], Step [169/225], Training Accuracy: 97.2263%, Training Loss: 0.0882%\n",
      "Epoch [55/300], Step [170/225], Training Accuracy: 97.2335%, Training Loss: 0.0884%\n",
      "Epoch [55/300], Step [171/225], Training Accuracy: 97.2314%, Training Loss: 0.0883%\n",
      "Epoch [55/300], Step [172/225], Training Accuracy: 97.2384%, Training Loss: 0.0883%\n",
      "Epoch [55/300], Step [173/225], Training Accuracy: 97.2453%, Training Loss: 0.0884%\n",
      "Epoch [55/300], Step [174/225], Training Accuracy: 97.2611%, Training Loss: 0.0881%\n",
      "Epoch [55/300], Step [175/225], Training Accuracy: 97.2679%, Training Loss: 0.0878%\n",
      "Epoch [55/300], Step [176/225], Training Accuracy: 97.2834%, Training Loss: 0.0876%\n",
      "Epoch [55/300], Step [177/225], Training Accuracy: 97.2899%, Training Loss: 0.0874%\n",
      "Epoch [55/300], Step [178/225], Training Accuracy: 97.2788%, Training Loss: 0.0875%\n",
      "Epoch [55/300], Step [179/225], Training Accuracy: 97.2765%, Training Loss: 0.0875%\n",
      "Epoch [55/300], Step [180/225], Training Accuracy: 97.2743%, Training Loss: 0.0876%\n",
      "Epoch [55/300], Step [181/225], Training Accuracy: 97.2894%, Training Loss: 0.0875%\n",
      "Epoch [55/300], Step [182/225], Training Accuracy: 97.2699%, Training Loss: 0.0879%\n",
      "Epoch [55/300], Step [183/225], Training Accuracy: 97.2678%, Training Loss: 0.0880%\n",
      "Epoch [55/300], Step [184/225], Training Accuracy: 97.2486%, Training Loss: 0.0883%\n",
      "Epoch [55/300], Step [185/225], Training Accuracy: 97.2382%, Training Loss: 0.0885%\n",
      "Epoch [55/300], Step [186/225], Training Accuracy: 97.2446%, Training Loss: 0.0883%\n",
      "Epoch [55/300], Step [187/225], Training Accuracy: 97.2594%, Training Loss: 0.0882%\n",
      "Epoch [55/300], Step [188/225], Training Accuracy: 97.2739%, Training Loss: 0.0879%\n",
      "Epoch [55/300], Step [189/225], Training Accuracy: 97.2884%, Training Loss: 0.0877%\n",
      "Epoch [55/300], Step [190/225], Training Accuracy: 97.2780%, Training Loss: 0.0878%\n",
      "Epoch [55/300], Step [191/225], Training Accuracy: 97.2759%, Training Loss: 0.0878%\n",
      "Epoch [55/300], Step [192/225], Training Accuracy: 97.2819%, Training Loss: 0.0878%\n",
      "Epoch [55/300], Step [193/225], Training Accuracy: 97.2555%, Training Loss: 0.0880%\n",
      "Epoch [55/300], Step [194/225], Training Accuracy: 97.2535%, Training Loss: 0.0880%\n",
      "Epoch [55/300], Step [195/225], Training Accuracy: 97.2596%, Training Loss: 0.0879%\n",
      "Epoch [55/300], Step [196/225], Training Accuracy: 97.2656%, Training Loss: 0.0878%\n",
      "Epoch [55/300], Step [197/225], Training Accuracy: 97.2557%, Training Loss: 0.0878%\n",
      "Epoch [55/300], Step [198/225], Training Accuracy: 97.2617%, Training Loss: 0.0877%\n",
      "Epoch [55/300], Step [199/225], Training Accuracy: 97.2676%, Training Loss: 0.0877%\n",
      "Epoch [55/300], Step [200/225], Training Accuracy: 97.2734%, Training Loss: 0.0876%\n",
      "Epoch [55/300], Step [201/225], Training Accuracy: 97.2637%, Training Loss: 0.0876%\n",
      "Epoch [55/300], Step [202/225], Training Accuracy: 97.2695%, Training Loss: 0.0875%\n",
      "Epoch [55/300], Step [203/225], Training Accuracy: 97.2752%, Training Loss: 0.0873%\n",
      "Epoch [55/300], Step [204/225], Training Accuracy: 97.2733%, Training Loss: 0.0874%\n",
      "Epoch [55/300], Step [205/225], Training Accuracy: 97.2713%, Training Loss: 0.0874%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/300], Step [206/225], Training Accuracy: 97.2770%, Training Loss: 0.0874%\n",
      "Epoch [55/300], Step [207/225], Training Accuracy: 97.2902%, Training Loss: 0.0871%\n",
      "Epoch [55/300], Step [208/225], Training Accuracy: 97.2882%, Training Loss: 0.0872%\n",
      "Epoch [55/300], Step [209/225], Training Accuracy: 97.2937%, Training Loss: 0.0870%\n",
      "Epoch [55/300], Step [210/225], Training Accuracy: 97.2917%, Training Loss: 0.0871%\n",
      "Epoch [55/300], Step [211/225], Training Accuracy: 97.2823%, Training Loss: 0.0872%\n",
      "Epoch [55/300], Step [212/225], Training Accuracy: 97.2656%, Training Loss: 0.0875%\n",
      "Epoch [55/300], Step [213/225], Training Accuracy: 97.2638%, Training Loss: 0.0876%\n",
      "Epoch [55/300], Step [214/225], Training Accuracy: 97.2693%, Training Loss: 0.0875%\n",
      "Epoch [55/300], Step [215/225], Training Accuracy: 97.2820%, Training Loss: 0.0875%\n",
      "Epoch [55/300], Step [216/225], Training Accuracy: 97.2729%, Training Loss: 0.0876%\n",
      "Epoch [55/300], Step [217/225], Training Accuracy: 97.2854%, Training Loss: 0.0875%\n",
      "Epoch [55/300], Step [218/225], Training Accuracy: 97.2979%, Training Loss: 0.0873%\n",
      "Epoch [55/300], Step [219/225], Training Accuracy: 97.2817%, Training Loss: 0.0876%\n",
      "Epoch [55/300], Step [220/225], Training Accuracy: 97.2869%, Training Loss: 0.0875%\n",
      "Epoch [55/300], Step [221/225], Training Accuracy: 97.2851%, Training Loss: 0.0875%\n",
      "Epoch [55/300], Step [222/225], Training Accuracy: 97.2762%, Training Loss: 0.0876%\n",
      "Epoch [55/300], Step [223/225], Training Accuracy: 97.2674%, Training Loss: 0.0877%\n",
      "Epoch [55/300], Step [224/225], Training Accuracy: 97.2726%, Training Loss: 0.0877%\n",
      "Epoch [55/300], Step [225/225], Training Accuracy: 97.2624%, Training Loss: 0.0878%\n",
      "Epoch [56/300], Step [1/225], Training Accuracy: 93.7500%, Training Loss: 0.1184%\n",
      "Epoch [56/300], Step [2/225], Training Accuracy: 95.3125%, Training Loss: 0.1107%\n",
      "Epoch [56/300], Step [3/225], Training Accuracy: 96.3542%, Training Loss: 0.1045%\n",
      "Epoch [56/300], Step [4/225], Training Accuracy: 97.2656%, Training Loss: 0.0903%\n",
      "Epoch [56/300], Step [5/225], Training Accuracy: 97.5000%, Training Loss: 0.0842%\n",
      "Epoch [56/300], Step [6/225], Training Accuracy: 97.9167%, Training Loss: 0.0765%\n",
      "Epoch [56/300], Step [7/225], Training Accuracy: 97.7679%, Training Loss: 0.0816%\n",
      "Epoch [56/300], Step [8/225], Training Accuracy: 97.8516%, Training Loss: 0.0793%\n",
      "Epoch [56/300], Step [9/225], Training Accuracy: 97.9167%, Training Loss: 0.0787%\n",
      "Epoch [56/300], Step [10/225], Training Accuracy: 97.6562%, Training Loss: 0.0864%\n",
      "Epoch [56/300], Step [11/225], Training Accuracy: 97.4432%, Training Loss: 0.0860%\n",
      "Epoch [56/300], Step [12/225], Training Accuracy: 97.3958%, Training Loss: 0.0837%\n",
      "Epoch [56/300], Step [13/225], Training Accuracy: 97.4760%, Training Loss: 0.0834%\n",
      "Epoch [56/300], Step [14/225], Training Accuracy: 97.4330%, Training Loss: 0.0855%\n",
      "Epoch [56/300], Step [15/225], Training Accuracy: 97.5000%, Training Loss: 0.0832%\n",
      "Epoch [56/300], Step [16/225], Training Accuracy: 97.3633%, Training Loss: 0.0829%\n",
      "Epoch [56/300], Step [17/225], Training Accuracy: 97.3346%, Training Loss: 0.0853%\n",
      "Epoch [56/300], Step [18/225], Training Accuracy: 97.2222%, Training Loss: 0.0880%\n",
      "Epoch [56/300], Step [19/225], Training Accuracy: 97.3684%, Training Loss: 0.0858%\n",
      "Epoch [56/300], Step [20/225], Training Accuracy: 97.5000%, Training Loss: 0.0839%\n",
      "Epoch [56/300], Step [21/225], Training Accuracy: 97.6190%, Training Loss: 0.0812%\n",
      "Epoch [56/300], Step [22/225], Training Accuracy: 97.5852%, Training Loss: 0.0814%\n",
      "Epoch [56/300], Step [23/225], Training Accuracy: 97.6223%, Training Loss: 0.0814%\n",
      "Epoch [56/300], Step [24/225], Training Accuracy: 97.4609%, Training Loss: 0.0845%\n",
      "Epoch [56/300], Step [25/225], Training Accuracy: 97.4375%, Training Loss: 0.0841%\n",
      "Epoch [56/300], Step [26/225], Training Accuracy: 97.5361%, Training Loss: 0.0830%\n",
      "Epoch [56/300], Step [27/225], Training Accuracy: 97.5116%, Training Loss: 0.0830%\n",
      "Epoch [56/300], Step [28/225], Training Accuracy: 97.5446%, Training Loss: 0.0824%\n",
      "Epoch [56/300], Step [29/225], Training Accuracy: 97.5216%, Training Loss: 0.0825%\n",
      "Epoch [56/300], Step [30/225], Training Accuracy: 97.3958%, Training Loss: 0.0841%\n",
      "Epoch [56/300], Step [31/225], Training Accuracy: 97.3790%, Training Loss: 0.0843%\n",
      "Epoch [56/300], Step [32/225], Training Accuracy: 97.3145%, Training Loss: 0.0846%\n",
      "Epoch [56/300], Step [33/225], Training Accuracy: 97.3485%, Training Loss: 0.0841%\n",
      "Epoch [56/300], Step [34/225], Training Accuracy: 97.3805%, Training Loss: 0.0830%\n",
      "Epoch [56/300], Step [35/225], Training Accuracy: 97.3661%, Training Loss: 0.0840%\n",
      "Epoch [56/300], Step [36/225], Training Accuracy: 97.3524%, Training Loss: 0.0847%\n",
      "Epoch [56/300], Step [37/225], Training Accuracy: 97.2551%, Training Loss: 0.0863%\n",
      "Epoch [56/300], Step [38/225], Training Accuracy: 97.2451%, Training Loss: 0.0879%\n",
      "Epoch [56/300], Step [39/225], Training Accuracy: 97.2356%, Training Loss: 0.0885%\n",
      "Epoch [56/300], Step [40/225], Training Accuracy: 97.3047%, Training Loss: 0.0869%\n",
      "Epoch [56/300], Step [41/225], Training Accuracy: 97.2180%, Training Loss: 0.0880%\n",
      "Epoch [56/300], Step [42/225], Training Accuracy: 97.2842%, Training Loss: 0.0872%\n",
      "Epoch [56/300], Step [43/225], Training Accuracy: 97.3110%, Training Loss: 0.0870%\n",
      "Epoch [56/300], Step [44/225], Training Accuracy: 97.3722%, Training Loss: 0.0860%\n",
      "Epoch [56/300], Step [45/225], Training Accuracy: 97.4306%, Training Loss: 0.0848%\n",
      "Epoch [56/300], Step [46/225], Training Accuracy: 97.4524%, Training Loss: 0.0841%\n",
      "Epoch [56/300], Step [47/225], Training Accuracy: 97.4402%, Training Loss: 0.0840%\n",
      "Epoch [56/300], Step [48/225], Training Accuracy: 97.4284%, Training Loss: 0.0849%\n",
      "Epoch [56/300], Step [49/225], Training Accuracy: 97.4171%, Training Loss: 0.0845%\n",
      "Epoch [56/300], Step [50/225], Training Accuracy: 97.4375%, Training Loss: 0.0847%\n",
      "Epoch [56/300], Step [51/225], Training Accuracy: 97.4877%, Training Loss: 0.0839%\n",
      "Epoch [56/300], Step [52/225], Training Accuracy: 97.5361%, Training Loss: 0.0830%\n",
      "Epoch [56/300], Step [53/225], Training Accuracy: 97.5236%, Training Loss: 0.0836%\n",
      "Epoch [56/300], Step [54/225], Training Accuracy: 97.4826%, Training Loss: 0.0853%\n",
      "Epoch [56/300], Step [55/225], Training Accuracy: 97.4716%, Training Loss: 0.0855%\n",
      "Epoch [56/300], Step [56/225], Training Accuracy: 97.4609%, Training Loss: 0.0855%\n",
      "Epoch [56/300], Step [57/225], Training Accuracy: 97.4507%, Training Loss: 0.0855%\n",
      "Epoch [56/300], Step [58/225], Training Accuracy: 97.4407%, Training Loss: 0.0856%\n",
      "Epoch [56/300], Step [59/225], Training Accuracy: 97.4047%, Training Loss: 0.0861%\n",
      "Epoch [56/300], Step [60/225], Training Accuracy: 97.4219%, Training Loss: 0.0858%\n",
      "Epoch [56/300], Step [61/225], Training Accuracy: 97.4385%, Training Loss: 0.0857%\n",
      "Epoch [56/300], Step [62/225], Training Accuracy: 97.3790%, Training Loss: 0.0872%\n",
      "Epoch [56/300], Step [63/225], Training Accuracy: 97.4206%, Training Loss: 0.0868%\n",
      "Epoch [56/300], Step [64/225], Training Accuracy: 97.4121%, Training Loss: 0.0864%\n",
      "Epoch [56/300], Step [65/225], Training Accuracy: 97.4038%, Training Loss: 0.0865%\n",
      "Epoch [56/300], Step [66/225], Training Accuracy: 97.3722%, Training Loss: 0.0873%\n",
      "Epoch [56/300], Step [67/225], Training Accuracy: 97.3881%, Training Loss: 0.0867%\n",
      "Epoch [56/300], Step [68/225], Training Accuracy: 97.3805%, Training Loss: 0.0868%\n",
      "Epoch [56/300], Step [69/225], Training Accuracy: 97.3732%, Training Loss: 0.0867%\n",
      "Epoch [56/300], Step [70/225], Training Accuracy: 97.3661%, Training Loss: 0.0863%\n",
      "Epoch [56/300], Step [71/225], Training Accuracy: 97.3812%, Training Loss: 0.0862%\n",
      "Epoch [56/300], Step [72/225], Training Accuracy: 97.3958%, Training Loss: 0.0859%\n",
      "Epoch [56/300], Step [73/225], Training Accuracy: 97.4101%, Training Loss: 0.0858%\n",
      "Epoch [56/300], Step [74/225], Training Accuracy: 97.4029%, Training Loss: 0.0860%\n",
      "Epoch [56/300], Step [75/225], Training Accuracy: 97.4375%, Training Loss: 0.0852%\n",
      "Epoch [56/300], Step [76/225], Training Accuracy: 97.4507%, Training Loss: 0.0853%\n",
      "Epoch [56/300], Step [77/225], Training Accuracy: 97.4635%, Training Loss: 0.0853%\n",
      "Epoch [56/300], Step [78/225], Training Accuracy: 97.4960%, Training Loss: 0.0847%\n",
      "Epoch [56/300], Step [79/225], Training Accuracy: 97.4486%, Training Loss: 0.0857%\n",
      "Epoch [56/300], Step [80/225], Training Accuracy: 97.3828%, Training Loss: 0.0867%\n",
      "Epoch [56/300], Step [81/225], Training Accuracy: 97.3958%, Training Loss: 0.0864%\n",
      "Epoch [56/300], Step [82/225], Training Accuracy: 97.4085%, Training Loss: 0.0864%\n",
      "Epoch [56/300], Step [83/225], Training Accuracy: 97.4021%, Training Loss: 0.0867%\n",
      "Epoch [56/300], Step [84/225], Training Accuracy: 97.4144%, Training Loss: 0.0864%\n",
      "Epoch [56/300], Step [85/225], Training Accuracy: 97.4081%, Training Loss: 0.0865%\n",
      "Epoch [56/300], Step [86/225], Training Accuracy: 97.3837%, Training Loss: 0.0869%\n",
      "Epoch [56/300], Step [87/225], Training Accuracy: 97.3779%, Training Loss: 0.0871%\n",
      "Epoch [56/300], Step [88/225], Training Accuracy: 97.4077%, Training Loss: 0.0868%\n",
      "Epoch [56/300], Step [89/225], Training Accuracy: 97.3841%, Training Loss: 0.0874%\n",
      "Epoch [56/300], Step [90/225], Training Accuracy: 97.3958%, Training Loss: 0.0872%\n",
      "Epoch [56/300], Step [91/225], Training Accuracy: 97.4245%, Training Loss: 0.0867%\n",
      "Epoch [56/300], Step [92/225], Training Accuracy: 97.4524%, Training Loss: 0.0861%\n",
      "Epoch [56/300], Step [93/225], Training Accuracy: 97.4798%, Training Loss: 0.0856%\n",
      "Epoch [56/300], Step [94/225], Training Accuracy: 97.4568%, Training Loss: 0.0855%\n",
      "Epoch [56/300], Step [95/225], Training Accuracy: 97.4507%, Training Loss: 0.0856%\n",
      "Epoch [56/300], Step [96/225], Training Accuracy: 97.4772%, Training Loss: 0.0852%\n",
      "Epoch [56/300], Step [97/225], Training Accuracy: 97.4710%, Training Loss: 0.0854%\n",
      "Epoch [56/300], Step [98/225], Training Accuracy: 97.4171%, Training Loss: 0.0862%\n",
      "Epoch [56/300], Step [99/225], Training Accuracy: 97.4116%, Training Loss: 0.0863%\n",
      "Epoch [56/300], Step [100/225], Training Accuracy: 97.3906%, Training Loss: 0.0862%\n",
      "Epoch [56/300], Step [101/225], Training Accuracy: 97.3700%, Training Loss: 0.0864%\n",
      "Epoch [56/300], Step [102/225], Training Accuracy: 97.3805%, Training Loss: 0.0861%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/300], Step [103/225], Training Accuracy: 97.3453%, Training Loss: 0.0863%\n",
      "Epoch [56/300], Step [104/225], Training Accuracy: 97.3558%, Training Loss: 0.0861%\n",
      "Epoch [56/300], Step [105/225], Training Accuracy: 97.3810%, Training Loss: 0.0857%\n",
      "Epoch [56/300], Step [106/225], Training Accuracy: 97.3614%, Training Loss: 0.0860%\n",
      "Epoch [56/300], Step [107/225], Training Accuracy: 97.3569%, Training Loss: 0.0861%\n",
      "Epoch [56/300], Step [108/225], Training Accuracy: 97.3669%, Training Loss: 0.0863%\n",
      "Epoch [56/300], Step [109/225], Training Accuracy: 97.3911%, Training Loss: 0.0857%\n",
      "Epoch [56/300], Step [110/225], Training Accuracy: 97.4148%, Training Loss: 0.0852%\n",
      "Epoch [56/300], Step [111/225], Training Accuracy: 97.4381%, Training Loss: 0.0848%\n",
      "Epoch [56/300], Step [112/225], Training Accuracy: 97.4191%, Training Loss: 0.0848%\n",
      "Epoch [56/300], Step [113/225], Training Accuracy: 97.4281%, Training Loss: 0.0846%\n",
      "Epoch [56/300], Step [114/225], Training Accuracy: 97.4370%, Training Loss: 0.0844%\n",
      "Epoch [56/300], Step [115/225], Training Accuracy: 97.4592%, Training Loss: 0.0841%\n",
      "Epoch [56/300], Step [116/225], Training Accuracy: 97.4677%, Training Loss: 0.0838%\n",
      "Epoch [56/300], Step [117/225], Training Accuracy: 97.4760%, Training Loss: 0.0834%\n",
      "Epoch [56/300], Step [118/225], Training Accuracy: 97.4841%, Training Loss: 0.0834%\n",
      "Epoch [56/300], Step [119/225], Training Accuracy: 97.4921%, Training Loss: 0.0834%\n",
      "Epoch [56/300], Step [120/225], Training Accuracy: 97.4740%, Training Loss: 0.0834%\n",
      "Epoch [56/300], Step [121/225], Training Accuracy: 97.4690%, Training Loss: 0.0834%\n",
      "Epoch [56/300], Step [122/225], Training Accuracy: 97.4898%, Training Loss: 0.0830%\n",
      "Epoch [56/300], Step [123/225], Training Accuracy: 97.4721%, Training Loss: 0.0834%\n",
      "Epoch [56/300], Step [124/225], Training Accuracy: 97.4546%, Training Loss: 0.0835%\n",
      "Epoch [56/300], Step [125/225], Training Accuracy: 97.4750%, Training Loss: 0.0832%\n",
      "Epoch [56/300], Step [126/225], Training Accuracy: 97.4826%, Training Loss: 0.0832%\n",
      "Epoch [56/300], Step [127/225], Training Accuracy: 97.4902%, Training Loss: 0.0831%\n",
      "Epoch [56/300], Step [128/225], Training Accuracy: 97.5098%, Training Loss: 0.0829%\n",
      "Epoch [56/300], Step [129/225], Training Accuracy: 97.4806%, Training Loss: 0.0836%\n",
      "Epoch [56/300], Step [130/225], Training Accuracy: 97.4639%, Training Loss: 0.0843%\n",
      "Epoch [56/300], Step [131/225], Training Accuracy: 97.4594%, Training Loss: 0.0842%\n",
      "Epoch [56/300], Step [132/225], Training Accuracy: 97.4550%, Training Loss: 0.0843%\n",
      "Epoch [56/300], Step [133/225], Training Accuracy: 97.4624%, Training Loss: 0.0843%\n",
      "Epoch [56/300], Step [134/225], Training Accuracy: 97.4813%, Training Loss: 0.0841%\n",
      "Epoch [56/300], Step [135/225], Training Accuracy: 97.4884%, Training Loss: 0.0840%\n",
      "Epoch [56/300], Step [136/225], Training Accuracy: 97.4724%, Training Loss: 0.0842%\n",
      "Epoch [56/300], Step [137/225], Training Accuracy: 97.4681%, Training Loss: 0.0841%\n",
      "Epoch [56/300], Step [138/225], Training Accuracy: 97.4864%, Training Loss: 0.0840%\n",
      "Epoch [56/300], Step [139/225], Training Accuracy: 97.4595%, Training Loss: 0.0843%\n",
      "Epoch [56/300], Step [140/225], Training Accuracy: 97.4554%, Training Loss: 0.0843%\n",
      "Epoch [56/300], Step [141/225], Training Accuracy: 97.4402%, Training Loss: 0.0845%\n",
      "Epoch [56/300], Step [142/225], Training Accuracy: 97.4472%, Training Loss: 0.0842%\n",
      "Epoch [56/300], Step [143/225], Training Accuracy: 97.4432%, Training Loss: 0.0843%\n",
      "Epoch [56/300], Step [144/225], Training Accuracy: 97.4501%, Training Loss: 0.0843%\n",
      "Epoch [56/300], Step [145/225], Training Accuracy: 97.4569%, Training Loss: 0.0840%\n",
      "Epoch [56/300], Step [146/225], Training Accuracy: 97.4636%, Training Loss: 0.0839%\n",
      "Epoch [56/300], Step [147/225], Training Accuracy: 97.4809%, Training Loss: 0.0837%\n",
      "Epoch [56/300], Step [148/225], Training Accuracy: 97.4873%, Training Loss: 0.0834%\n",
      "Epoch [56/300], Step [149/225], Training Accuracy: 97.4727%, Training Loss: 0.0835%\n",
      "Epoch [56/300], Step [150/225], Training Accuracy: 97.4792%, Training Loss: 0.0835%\n",
      "Epoch [56/300], Step [151/225], Training Accuracy: 97.4752%, Training Loss: 0.0834%\n",
      "Epoch [56/300], Step [152/225], Training Accuracy: 97.4712%, Training Loss: 0.0835%\n",
      "Epoch [56/300], Step [153/225], Training Accuracy: 97.4775%, Training Loss: 0.0834%\n",
      "Epoch [56/300], Step [154/225], Training Accuracy: 97.4736%, Training Loss: 0.0833%\n",
      "Epoch [56/300], Step [155/225], Training Accuracy: 97.4899%, Training Loss: 0.0831%\n",
      "Epoch [56/300], Step [156/225], Training Accuracy: 97.5060%, Training Loss: 0.0828%\n",
      "Epoch [56/300], Step [157/225], Training Accuracy: 97.5020%, Training Loss: 0.0831%\n",
      "Epoch [56/300], Step [158/225], Training Accuracy: 97.4980%, Training Loss: 0.0830%\n",
      "Epoch [56/300], Step [159/225], Training Accuracy: 97.5039%, Training Loss: 0.0829%\n",
      "Epoch [56/300], Step [160/225], Training Accuracy: 97.4902%, Training Loss: 0.0833%\n",
      "Epoch [56/300], Step [161/225], Training Accuracy: 97.4961%, Training Loss: 0.0834%\n",
      "Epoch [56/300], Step [162/225], Training Accuracy: 97.5019%, Training Loss: 0.0833%\n",
      "Epoch [56/300], Step [163/225], Training Accuracy: 97.4789%, Training Loss: 0.0837%\n",
      "Epoch [56/300], Step [164/225], Training Accuracy: 97.4466%, Training Loss: 0.0839%\n",
      "Epoch [56/300], Step [165/225], Training Accuracy: 97.4527%, Training Loss: 0.0839%\n",
      "Epoch [56/300], Step [166/225], Training Accuracy: 97.4492%, Training Loss: 0.0839%\n",
      "Epoch [56/300], Step [167/225], Training Accuracy: 97.4551%, Training Loss: 0.0838%\n",
      "Epoch [56/300], Step [168/225], Training Accuracy: 97.4516%, Training Loss: 0.0837%\n",
      "Epoch [56/300], Step [169/225], Training Accuracy: 97.4575%, Training Loss: 0.0837%\n",
      "Epoch [56/300], Step [170/225], Training Accuracy: 97.4357%, Training Loss: 0.0840%\n",
      "Epoch [56/300], Step [171/225], Training Accuracy: 97.4507%, Training Loss: 0.0837%\n",
      "Epoch [56/300], Step [172/225], Training Accuracy: 97.4564%, Training Loss: 0.0836%\n",
      "Epoch [56/300], Step [173/225], Training Accuracy: 97.4530%, Training Loss: 0.0837%\n",
      "Epoch [56/300], Step [174/225], Training Accuracy: 97.4587%, Training Loss: 0.0836%\n",
      "Epoch [56/300], Step [175/225], Training Accuracy: 97.4732%, Training Loss: 0.0834%\n",
      "Epoch [56/300], Step [176/225], Training Accuracy: 97.4609%, Training Loss: 0.0834%\n",
      "Epoch [56/300], Step [177/225], Training Accuracy: 97.4753%, Training Loss: 0.0831%\n",
      "Epoch [56/300], Step [178/225], Training Accuracy: 97.4719%, Training Loss: 0.0833%\n",
      "Epoch [56/300], Step [179/225], Training Accuracy: 97.4686%, Training Loss: 0.0834%\n",
      "Epoch [56/300], Step [180/225], Training Accuracy: 97.4826%, Training Loss: 0.0832%\n",
      "Epoch [56/300], Step [181/225], Training Accuracy: 97.4879%, Training Loss: 0.0831%\n",
      "Epoch [56/300], Step [182/225], Training Accuracy: 97.5017%, Training Loss: 0.0830%\n",
      "Epoch [56/300], Step [183/225], Training Accuracy: 97.5154%, Training Loss: 0.0826%\n",
      "Epoch [56/300], Step [184/225], Training Accuracy: 97.5204%, Training Loss: 0.0826%\n",
      "Epoch [56/300], Step [185/225], Training Accuracy: 97.5253%, Training Loss: 0.0825%\n",
      "Epoch [56/300], Step [186/225], Training Accuracy: 97.5302%, Training Loss: 0.0824%\n",
      "Epoch [56/300], Step [187/225], Training Accuracy: 97.5267%, Training Loss: 0.0823%\n",
      "Epoch [56/300], Step [188/225], Training Accuracy: 97.4900%, Training Loss: 0.0825%\n",
      "Epoch [56/300], Step [189/225], Training Accuracy: 97.4868%, Training Loss: 0.0826%\n",
      "Epoch [56/300], Step [190/225], Training Accuracy: 97.4589%, Training Loss: 0.0830%\n",
      "Epoch [56/300], Step [191/225], Training Accuracy: 97.4722%, Training Loss: 0.0828%\n",
      "Epoch [56/300], Step [192/225], Training Accuracy: 97.4609%, Training Loss: 0.0830%\n",
      "Epoch [56/300], Step [193/225], Training Accuracy: 97.4498%, Training Loss: 0.0833%\n",
      "Epoch [56/300], Step [194/225], Training Accuracy: 97.4468%, Training Loss: 0.0833%\n",
      "Epoch [56/300], Step [195/225], Training Accuracy: 97.4359%, Training Loss: 0.0834%\n",
      "Epoch [56/300], Step [196/225], Training Accuracy: 97.4490%, Training Loss: 0.0832%\n",
      "Epoch [56/300], Step [197/225], Training Accuracy: 97.4461%, Training Loss: 0.0833%\n",
      "Epoch [56/300], Step [198/225], Training Accuracy: 97.4511%, Training Loss: 0.0833%\n",
      "Epoch [56/300], Step [199/225], Training Accuracy: 97.4560%, Training Loss: 0.0833%\n",
      "Epoch [56/300], Step [200/225], Training Accuracy: 97.4531%, Training Loss: 0.0835%\n",
      "Epoch [56/300], Step [201/225], Training Accuracy: 97.4580%, Training Loss: 0.0835%\n",
      "Epoch [56/300], Step [202/225], Training Accuracy: 97.4551%, Training Loss: 0.0837%\n",
      "Epoch [56/300], Step [203/225], Training Accuracy: 97.4677%, Training Loss: 0.0834%\n",
      "Epoch [56/300], Step [204/225], Training Accuracy: 97.4801%, Training Loss: 0.0832%\n",
      "Epoch [56/300], Step [205/225], Training Accuracy: 97.4848%, Training Loss: 0.0832%\n",
      "Epoch [56/300], Step [206/225], Training Accuracy: 97.4742%, Training Loss: 0.0834%\n",
      "Epoch [56/300], Step [207/225], Training Accuracy: 97.4789%, Training Loss: 0.0834%\n",
      "Epoch [56/300], Step [208/225], Training Accuracy: 97.4835%, Training Loss: 0.0832%\n",
      "Epoch [56/300], Step [209/225], Training Accuracy: 97.4955%, Training Loss: 0.0829%\n",
      "Epoch [56/300], Step [210/225], Training Accuracy: 97.5000%, Training Loss: 0.0828%\n",
      "Epoch [56/300], Step [211/225], Training Accuracy: 97.4674%, Training Loss: 0.0833%\n",
      "Epoch [56/300], Step [212/225], Training Accuracy: 97.4646%, Training Loss: 0.0834%\n",
      "Epoch [56/300], Step [213/225], Training Accuracy: 97.4765%, Training Loss: 0.0833%\n",
      "Epoch [56/300], Step [214/225], Training Accuracy: 97.4810%, Training Loss: 0.0832%\n",
      "Epoch [56/300], Step [215/225], Training Accuracy: 97.4782%, Training Loss: 0.0832%\n",
      "Epoch [56/300], Step [216/225], Training Accuracy: 97.4609%, Training Loss: 0.0834%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/300], Step [217/225], Training Accuracy: 97.4654%, Training Loss: 0.0833%\n",
      "Epoch [56/300], Step [218/225], Training Accuracy: 97.4699%, Training Loss: 0.0832%\n",
      "Epoch [56/300], Step [219/225], Training Accuracy: 97.4672%, Training Loss: 0.0833%\n",
      "Epoch [56/300], Step [220/225], Training Accuracy: 97.4787%, Training Loss: 0.0830%\n",
      "Epoch [56/300], Step [221/225], Training Accuracy: 97.4901%, Training Loss: 0.0829%\n",
      "Epoch [56/300], Step [222/225], Training Accuracy: 97.4873%, Training Loss: 0.0828%\n",
      "Epoch [56/300], Step [223/225], Training Accuracy: 97.4846%, Training Loss: 0.0828%\n",
      "Epoch [56/300], Step [224/225], Training Accuracy: 97.4888%, Training Loss: 0.0827%\n",
      "Epoch [56/300], Step [225/225], Training Accuracy: 97.4708%, Training Loss: 0.0832%\n",
      "Epoch [57/300], Step [1/225], Training Accuracy: 96.8750%, Training Loss: 0.0723%\n",
      "Epoch [57/300], Step [2/225], Training Accuracy: 97.6562%, Training Loss: 0.0761%\n",
      "Epoch [57/300], Step [3/225], Training Accuracy: 95.8333%, Training Loss: 0.1053%\n",
      "Epoch [57/300], Step [4/225], Training Accuracy: 96.4844%, Training Loss: 0.0891%\n",
      "Epoch [57/300], Step [5/225], Training Accuracy: 97.1875%, Training Loss: 0.0797%\n",
      "Epoch [57/300], Step [6/225], Training Accuracy: 97.3958%, Training Loss: 0.0773%\n",
      "Epoch [57/300], Step [7/225], Training Accuracy: 96.2054%, Training Loss: 0.1042%\n",
      "Epoch [57/300], Step [8/225], Training Accuracy: 95.8984%, Training Loss: 0.1072%\n",
      "Epoch [57/300], Step [9/225], Training Accuracy: 96.1806%, Training Loss: 0.1039%\n",
      "Epoch [57/300], Step [10/225], Training Accuracy: 96.2500%, Training Loss: 0.1068%\n",
      "Epoch [57/300], Step [11/225], Training Accuracy: 96.3068%, Training Loss: 0.1016%\n",
      "Epoch [57/300], Step [12/225], Training Accuracy: 96.3542%, Training Loss: 0.1013%\n",
      "Epoch [57/300], Step [13/225], Training Accuracy: 96.3942%, Training Loss: 0.0999%\n",
      "Epoch [57/300], Step [14/225], Training Accuracy: 96.3170%, Training Loss: 0.1037%\n",
      "Epoch [57/300], Step [15/225], Training Accuracy: 96.5625%, Training Loss: 0.0998%\n",
      "Epoch [57/300], Step [16/225], Training Accuracy: 96.6797%, Training Loss: 0.0971%\n",
      "Epoch [57/300], Step [17/225], Training Accuracy: 96.8750%, Training Loss: 0.0939%\n",
      "Epoch [57/300], Step [18/225], Training Accuracy: 96.8750%, Training Loss: 0.0954%\n",
      "Epoch [57/300], Step [19/225], Training Accuracy: 96.9572%, Training Loss: 0.0932%\n",
      "Epoch [57/300], Step [20/225], Training Accuracy: 97.0312%, Training Loss: 0.0925%\n",
      "Epoch [57/300], Step [21/225], Training Accuracy: 96.9494%, Training Loss: 0.0932%\n",
      "Epoch [57/300], Step [22/225], Training Accuracy: 97.0881%, Training Loss: 0.0906%\n",
      "Epoch [57/300], Step [23/225], Training Accuracy: 97.0788%, Training Loss: 0.0911%\n",
      "Epoch [57/300], Step [24/225], Training Accuracy: 97.0052%, Training Loss: 0.0938%\n",
      "Epoch [57/300], Step [25/225], Training Accuracy: 97.1250%, Training Loss: 0.0916%\n",
      "Epoch [57/300], Step [26/225], Training Accuracy: 97.1154%, Training Loss: 0.0913%\n",
      "Epoch [57/300], Step [27/225], Training Accuracy: 97.1644%, Training Loss: 0.0903%\n",
      "Epoch [57/300], Step [28/225], Training Accuracy: 97.0982%, Training Loss: 0.0907%\n",
      "Epoch [57/300], Step [29/225], Training Accuracy: 97.1444%, Training Loss: 0.0894%\n",
      "Epoch [57/300], Step [30/225], Training Accuracy: 97.1875%, Training Loss: 0.0897%\n",
      "Epoch [57/300], Step [31/225], Training Accuracy: 97.1270%, Training Loss: 0.0907%\n",
      "Epoch [57/300], Step [32/225], Training Accuracy: 97.0703%, Training Loss: 0.0902%\n",
      "Epoch [57/300], Step [33/225], Training Accuracy: 97.0170%, Training Loss: 0.0901%\n",
      "Epoch [57/300], Step [34/225], Training Accuracy: 96.9210%, Training Loss: 0.0903%\n",
      "Epoch [57/300], Step [35/225], Training Accuracy: 96.8750%, Training Loss: 0.0923%\n",
      "Epoch [57/300], Step [36/225], Training Accuracy: 96.9618%, Training Loss: 0.0913%\n",
      "Epoch [57/300], Step [37/225], Training Accuracy: 96.9595%, Training Loss: 0.0915%\n",
      "Epoch [57/300], Step [38/225], Training Accuracy: 96.9984%, Training Loss: 0.0922%\n",
      "Epoch [57/300], Step [39/225], Training Accuracy: 96.9551%, Training Loss: 0.0938%\n",
      "Epoch [57/300], Step [40/225], Training Accuracy: 96.9531%, Training Loss: 0.0940%\n",
      "Epoch [57/300], Step [41/225], Training Accuracy: 96.7988%, Training Loss: 0.0970%\n",
      "Epoch [57/300], Step [42/225], Training Accuracy: 96.8378%, Training Loss: 0.0959%\n",
      "Epoch [57/300], Step [43/225], Training Accuracy: 96.8023%, Training Loss: 0.0961%\n",
      "Epoch [57/300], Step [44/225], Training Accuracy: 96.8040%, Training Loss: 0.0965%\n",
      "Epoch [57/300], Step [45/225], Training Accuracy: 96.7708%, Training Loss: 0.0967%\n",
      "Epoch [57/300], Step [46/225], Training Accuracy: 96.8410%, Training Loss: 0.0960%\n",
      "Epoch [57/300], Step [47/225], Training Accuracy: 96.7420%, Training Loss: 0.0976%\n",
      "Epoch [57/300], Step [48/225], Training Accuracy: 96.7122%, Training Loss: 0.0984%\n",
      "Epoch [57/300], Step [49/225], Training Accuracy: 96.6837%, Training Loss: 0.0983%\n",
      "Epoch [57/300], Step [50/225], Training Accuracy: 96.6875%, Training Loss: 0.0981%\n",
      "Epoch [57/300], Step [51/225], Training Accuracy: 96.6912%, Training Loss: 0.0986%\n",
      "Epoch [57/300], Step [52/225], Training Accuracy: 96.6947%, Training Loss: 0.0977%\n",
      "Epoch [57/300], Step [53/225], Training Accuracy: 96.6981%, Training Loss: 0.0975%\n",
      "Epoch [57/300], Step [54/225], Training Accuracy: 96.5567%, Training Loss: 0.0999%\n",
      "Epoch [57/300], Step [55/225], Training Accuracy: 96.5625%, Training Loss: 0.0994%\n",
      "Epoch [57/300], Step [56/225], Training Accuracy: 96.5402%, Training Loss: 0.0999%\n",
      "Epoch [57/300], Step [57/225], Training Accuracy: 96.5186%, Training Loss: 0.1006%\n",
      "Epoch [57/300], Step [58/225], Training Accuracy: 96.5248%, Training Loss: 0.1003%\n",
      "Epoch [57/300], Step [59/225], Training Accuracy: 96.4778%, Training Loss: 0.1011%\n",
      "Epoch [57/300], Step [60/225], Training Accuracy: 96.4844%, Training Loss: 0.1006%\n",
      "Epoch [57/300], Step [61/225], Training Accuracy: 96.4652%, Training Loss: 0.1011%\n",
      "Epoch [57/300], Step [62/225], Training Accuracy: 96.4466%, Training Loss: 0.1015%\n",
      "Epoch [57/300], Step [63/225], Training Accuracy: 96.4038%, Training Loss: 0.1031%\n",
      "Epoch [57/300], Step [64/225], Training Accuracy: 96.4355%, Training Loss: 0.1028%\n",
      "Epoch [57/300], Step [65/225], Training Accuracy: 96.4663%, Training Loss: 0.1021%\n",
      "Epoch [57/300], Step [66/225], Training Accuracy: 96.4489%, Training Loss: 0.1024%\n",
      "Epoch [57/300], Step [67/225], Training Accuracy: 96.4319%, Training Loss: 0.1028%\n",
      "Epoch [57/300], Step [68/225], Training Accuracy: 96.4614%, Training Loss: 0.1023%\n",
      "Epoch [57/300], Step [69/225], Training Accuracy: 96.4900%, Training Loss: 0.1018%\n",
      "Epoch [57/300], Step [70/225], Training Accuracy: 96.5179%, Training Loss: 0.1011%\n",
      "Epoch [57/300], Step [71/225], Training Accuracy: 96.4349%, Training Loss: 0.1028%\n",
      "Epoch [57/300], Step [72/225], Training Accuracy: 96.4193%, Training Loss: 0.1030%\n",
      "Epoch [57/300], Step [73/225], Training Accuracy: 96.4469%, Training Loss: 0.1028%\n",
      "Epoch [57/300], Step [74/225], Training Accuracy: 96.3894%, Training Loss: 0.1038%\n",
      "Epoch [57/300], Step [75/225], Training Accuracy: 96.3958%, Training Loss: 0.1035%\n",
      "Epoch [57/300], Step [76/225], Training Accuracy: 96.4021%, Training Loss: 0.1034%\n",
      "Epoch [57/300], Step [77/225], Training Accuracy: 96.3677%, Training Loss: 0.1040%\n",
      "Epoch [57/300], Step [78/225], Training Accuracy: 96.4143%, Training Loss: 0.1033%\n",
      "Epoch [57/300], Step [79/225], Training Accuracy: 96.3608%, Training Loss: 0.1057%\n",
      "Epoch [57/300], Step [80/225], Training Accuracy: 96.3867%, Training Loss: 0.1055%\n",
      "Epoch [57/300], Step [81/225], Training Accuracy: 96.3927%, Training Loss: 0.1049%\n",
      "Epoch [57/300], Step [82/225], Training Accuracy: 96.4177%, Training Loss: 0.1049%\n",
      "Epoch [57/300], Step [83/225], Training Accuracy: 96.3855%, Training Loss: 0.1055%\n",
      "Epoch [57/300], Step [84/225], Training Accuracy: 96.4286%, Training Loss: 0.1049%\n",
      "Epoch [57/300], Step [85/225], Training Accuracy: 96.4154%, Training Loss: 0.1047%\n",
      "Epoch [57/300], Step [86/225], Training Accuracy: 96.4026%, Training Loss: 0.1049%\n",
      "Epoch [57/300], Step [87/225], Training Accuracy: 96.4440%, Training Loss: 0.1044%\n",
      "Epoch [57/300], Step [88/225], Training Accuracy: 96.4666%, Training Loss: 0.1038%\n",
      "Epoch [57/300], Step [89/225], Training Accuracy: 96.4712%, Training Loss: 0.1036%\n",
      "Epoch [57/300], Step [90/225], Training Accuracy: 96.4583%, Training Loss: 0.1038%\n",
      "Epoch [57/300], Step [91/225], Training Accuracy: 96.4286%, Training Loss: 0.1041%\n",
      "Epoch [57/300], Step [92/225], Training Accuracy: 96.4674%, Training Loss: 0.1033%\n",
      "Epoch [57/300], Step [93/225], Training Accuracy: 96.5054%, Training Loss: 0.1030%\n",
      "Epoch [57/300], Step [94/225], Training Accuracy: 96.5426%, Training Loss: 0.1023%\n",
      "Epoch [57/300], Step [95/225], Training Accuracy: 96.5296%, Training Loss: 0.1029%\n",
      "Epoch [57/300], Step [96/225], Training Accuracy: 96.5658%, Training Loss: 0.1022%\n",
      "Epoch [57/300], Step [97/225], Training Accuracy: 96.5689%, Training Loss: 0.1024%\n",
      "Epoch [57/300], Step [98/225], Training Accuracy: 96.5561%, Training Loss: 0.1028%\n",
      "Epoch [57/300], Step [99/225], Training Accuracy: 96.5751%, Training Loss: 0.1025%\n",
      "Epoch [57/300], Step [100/225], Training Accuracy: 96.6094%, Training Loss: 0.1020%\n",
      "Epoch [57/300], Step [101/225], Training Accuracy: 96.6275%, Training Loss: 0.1016%\n",
      "Epoch [57/300], Step [102/225], Training Accuracy: 96.6146%, Training Loss: 0.1023%\n",
      "Epoch [57/300], Step [103/225], Training Accuracy: 96.6171%, Training Loss: 0.1026%\n",
      "Epoch [57/300], Step [104/225], Training Accuracy: 96.6346%, Training Loss: 0.1023%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/300], Step [105/225], Training Accuracy: 96.6518%, Training Loss: 0.1020%\n",
      "Epoch [57/300], Step [106/225], Training Accuracy: 96.6686%, Training Loss: 0.1018%\n",
      "Epoch [57/300], Step [107/225], Training Accuracy: 96.6706%, Training Loss: 0.1025%\n",
      "Epoch [57/300], Step [108/225], Training Accuracy: 96.6869%, Training Loss: 0.1021%\n",
      "Epoch [57/300], Step [109/225], Training Accuracy: 96.6600%, Training Loss: 0.1026%\n",
      "Epoch [57/300], Step [110/225], Training Accuracy: 96.6477%, Training Loss: 0.1027%\n",
      "Epoch [57/300], Step [111/225], Training Accuracy: 96.6639%, Training Loss: 0.1022%\n",
      "Epoch [57/300], Step [112/225], Training Accuracy: 96.6378%, Training Loss: 0.1026%\n",
      "Epoch [57/300], Step [113/225], Training Accuracy: 96.6399%, Training Loss: 0.1022%\n",
      "Epoch [57/300], Step [114/225], Training Accuracy: 96.6283%, Training Loss: 0.1022%\n",
      "Epoch [57/300], Step [115/225], Training Accuracy: 96.6576%, Training Loss: 0.1017%\n",
      "Epoch [57/300], Step [116/225], Training Accuracy: 96.6460%, Training Loss: 0.1020%\n",
      "Epoch [57/300], Step [117/225], Training Accuracy: 96.6480%, Training Loss: 0.1017%\n",
      "Epoch [57/300], Step [118/225], Training Accuracy: 96.6234%, Training Loss: 0.1023%\n",
      "Epoch [57/300], Step [119/225], Training Accuracy: 96.6255%, Training Loss: 0.1024%\n",
      "Epoch [57/300], Step [120/225], Training Accuracy: 96.6406%, Training Loss: 0.1019%\n",
      "Epoch [57/300], Step [121/225], Training Accuracy: 96.6555%, Training Loss: 0.1019%\n",
      "Epoch [57/300], Step [122/225], Training Accuracy: 96.6573%, Training Loss: 0.1018%\n",
      "Epoch [57/300], Step [123/225], Training Accuracy: 96.6463%, Training Loss: 0.1017%\n",
      "Epoch [57/300], Step [124/225], Training Accuracy: 96.6734%, Training Loss: 0.1015%\n",
      "Epoch [57/300], Step [125/225], Training Accuracy: 96.6750%, Training Loss: 0.1015%\n",
      "Epoch [57/300], Step [126/225], Training Accuracy: 96.6766%, Training Loss: 0.1013%\n",
      "Epoch [57/300], Step [127/225], Training Accuracy: 96.6412%, Training Loss: 0.1016%\n",
      "Epoch [57/300], Step [128/225], Training Accuracy: 96.6187%, Training Loss: 0.1021%\n",
      "Epoch [57/300], Step [129/225], Training Accuracy: 96.5964%, Training Loss: 0.1029%\n",
      "Epoch [57/300], Step [130/225], Training Accuracy: 96.5986%, Training Loss: 0.1028%\n",
      "Epoch [57/300], Step [131/225], Training Accuracy: 96.5887%, Training Loss: 0.1028%\n",
      "Epoch [57/300], Step [132/225], Training Accuracy: 96.6027%, Training Loss: 0.1027%\n",
      "Epoch [57/300], Step [133/225], Training Accuracy: 96.6165%, Training Loss: 0.1024%\n",
      "Epoch [57/300], Step [134/225], Training Accuracy: 96.6068%, Training Loss: 0.1027%\n",
      "Epoch [57/300], Step [135/225], Training Accuracy: 96.6088%, Training Loss: 0.1025%\n",
      "Epoch [57/300], Step [136/225], Training Accuracy: 96.6222%, Training Loss: 0.1027%\n",
      "Epoch [57/300], Step [137/225], Training Accuracy: 96.6355%, Training Loss: 0.1025%\n",
      "Epoch [57/300], Step [138/225], Training Accuracy: 96.6486%, Training Loss: 0.1024%\n",
      "Epoch [57/300], Step [139/225], Training Accuracy: 96.6727%, Training Loss: 0.1020%\n",
      "Epoch [57/300], Step [140/225], Training Accuracy: 96.6629%, Training Loss: 0.1020%\n",
      "Epoch [57/300], Step [141/225], Training Accuracy: 96.6645%, Training Loss: 0.1018%\n",
      "Epoch [57/300], Step [142/225], Training Accuracy: 96.6659%, Training Loss: 0.1021%\n",
      "Epoch [57/300], Step [143/225], Training Accuracy: 96.6783%, Training Loss: 0.1017%\n",
      "Epoch [57/300], Step [144/225], Training Accuracy: 96.6905%, Training Loss: 0.1014%\n",
      "Epoch [57/300], Step [145/225], Training Accuracy: 96.7026%, Training Loss: 0.1009%\n",
      "Epoch [57/300], Step [146/225], Training Accuracy: 96.7145%, Training Loss: 0.1008%\n",
      "Epoch [57/300], Step [147/225], Training Accuracy: 96.7368%, Training Loss: 0.1005%\n",
      "Epoch [57/300], Step [148/225], Training Accuracy: 96.7272%, Training Loss: 0.1011%\n",
      "Epoch [57/300], Step [149/225], Training Accuracy: 96.7492%, Training Loss: 0.1010%\n",
      "Epoch [57/300], Step [150/225], Training Accuracy: 96.7292%, Training Loss: 0.1015%\n",
      "Epoch [57/300], Step [151/225], Training Accuracy: 96.7301%, Training Loss: 0.1012%\n",
      "Epoch [57/300], Step [152/225], Training Accuracy: 96.7208%, Training Loss: 0.1014%\n",
      "Epoch [57/300], Step [153/225], Training Accuracy: 96.7320%, Training Loss: 0.1010%\n",
      "Epoch [57/300], Step [154/225], Training Accuracy: 96.7330%, Training Loss: 0.1010%\n",
      "Epoch [57/300], Step [155/225], Training Accuracy: 96.7540%, Training Loss: 0.1006%\n",
      "Epoch [57/300], Step [156/225], Training Accuracy: 96.7548%, Training Loss: 0.1005%\n",
      "Epoch [57/300], Step [157/225], Training Accuracy: 96.7257%, Training Loss: 0.1009%\n",
      "Epoch [57/300], Step [158/225], Training Accuracy: 96.7366%, Training Loss: 0.1006%\n",
      "Epoch [57/300], Step [159/225], Training Accuracy: 96.7374%, Training Loss: 0.1007%\n",
      "Epoch [57/300], Step [160/225], Training Accuracy: 96.7480%, Training Loss: 0.1005%\n",
      "Epoch [57/300], Step [161/225], Training Accuracy: 96.7585%, Training Loss: 0.1004%\n",
      "Epoch [57/300], Step [162/225], Training Accuracy: 96.7689%, Training Loss: 0.1002%\n",
      "Epoch [57/300], Step [163/225], Training Accuracy: 96.7696%, Training Loss: 0.1004%\n",
      "Epoch [57/300], Step [164/225], Training Accuracy: 96.7607%, Training Loss: 0.1006%\n",
      "Epoch [57/300], Step [165/225], Training Accuracy: 96.7519%, Training Loss: 0.1007%\n",
      "Epoch [57/300], Step [166/225], Training Accuracy: 96.7432%, Training Loss: 0.1008%\n",
      "Epoch [57/300], Step [167/225], Training Accuracy: 96.7440%, Training Loss: 0.1008%\n",
      "Epoch [57/300], Step [168/225], Training Accuracy: 96.7355%, Training Loss: 0.1007%\n",
      "Epoch [57/300], Step [169/225], Training Accuracy: 96.7178%, Training Loss: 0.1013%\n",
      "Epoch [57/300], Step [170/225], Training Accuracy: 96.7279%, Training Loss: 0.1013%\n",
      "Epoch [57/300], Step [171/225], Training Accuracy: 96.7105%, Training Loss: 0.1016%\n",
      "Epoch [57/300], Step [172/225], Training Accuracy: 96.7297%, Training Loss: 0.1013%\n",
      "Epoch [57/300], Step [173/225], Training Accuracy: 96.7486%, Training Loss: 0.1010%\n",
      "Epoch [57/300], Step [174/225], Training Accuracy: 96.7493%, Training Loss: 0.1008%\n",
      "Epoch [57/300], Step [175/225], Training Accuracy: 96.7411%, Training Loss: 0.1009%\n",
      "Epoch [57/300], Step [176/225], Training Accuracy: 96.7596%, Training Loss: 0.1006%\n",
      "Epoch [57/300], Step [177/225], Training Accuracy: 96.7691%, Training Loss: 0.1006%\n",
      "Epoch [57/300], Step [178/225], Training Accuracy: 96.7784%, Training Loss: 0.1003%\n",
      "Epoch [57/300], Step [179/225], Training Accuracy: 96.7877%, Training Loss: 0.1001%\n",
      "Epoch [57/300], Step [180/225], Training Accuracy: 96.7882%, Training Loss: 0.0999%\n",
      "Epoch [57/300], Step [181/225], Training Accuracy: 96.8059%, Training Loss: 0.0997%\n",
      "Epoch [57/300], Step [182/225], Training Accuracy: 96.8149%, Training Loss: 0.0995%\n",
      "Epoch [57/300], Step [183/225], Training Accuracy: 96.8238%, Training Loss: 0.0993%\n",
      "Epoch [57/300], Step [184/225], Training Accuracy: 96.8240%, Training Loss: 0.0993%\n",
      "Epoch [57/300], Step [185/225], Training Accuracy: 96.8243%, Training Loss: 0.0991%\n",
      "Epoch [57/300], Step [186/225], Training Accuracy: 96.8414%, Training Loss: 0.0990%\n",
      "Epoch [57/300], Step [187/225], Training Accuracy: 96.8165%, Training Loss: 0.0993%\n",
      "Epoch [57/300], Step [188/225], Training Accuracy: 96.8168%, Training Loss: 0.0992%\n",
      "Epoch [57/300], Step [189/225], Training Accuracy: 96.8337%, Training Loss: 0.0989%\n",
      "Epoch [57/300], Step [190/225], Training Accuracy: 96.8503%, Training Loss: 0.0986%\n",
      "Epoch [57/300], Step [191/225], Training Accuracy: 96.8586%, Training Loss: 0.0984%\n",
      "Epoch [57/300], Step [192/225], Training Accuracy: 96.8506%, Training Loss: 0.0985%\n",
      "Epoch [57/300], Step [193/225], Training Accuracy: 96.8345%, Training Loss: 0.0986%\n",
      "Epoch [57/300], Step [194/225], Training Accuracy: 96.8347%, Training Loss: 0.0985%\n",
      "Epoch [57/300], Step [195/225], Training Accuracy: 96.8349%, Training Loss: 0.0986%\n",
      "Epoch [57/300], Step [196/225], Training Accuracy: 96.8192%, Training Loss: 0.0986%\n",
      "Epoch [57/300], Step [197/225], Training Accuracy: 96.8274%, Training Loss: 0.0986%\n",
      "Epoch [57/300], Step [198/225], Training Accuracy: 96.8198%, Training Loss: 0.0987%\n",
      "Epoch [57/300], Step [199/225], Training Accuracy: 96.8200%, Training Loss: 0.0986%\n",
      "Epoch [57/300], Step [200/225], Training Accuracy: 96.8359%, Training Loss: 0.0983%\n",
      "Epoch [57/300], Step [201/225], Training Accuracy: 96.8361%, Training Loss: 0.0984%\n",
      "Epoch [57/300], Step [202/225], Training Accuracy: 96.8286%, Training Loss: 0.0986%\n",
      "Epoch [57/300], Step [203/225], Training Accuracy: 96.8365%, Training Loss: 0.0986%\n",
      "Epoch [57/300], Step [204/225], Training Accuracy: 96.8137%, Training Loss: 0.0988%\n",
      "Epoch [57/300], Step [205/225], Training Accuracy: 96.7988%, Training Loss: 0.0989%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/300], Step [206/225], Training Accuracy: 96.7992%, Training Loss: 0.0987%\n",
      "Epoch [57/300], Step [207/225], Training Accuracy: 96.7920%, Training Loss: 0.0987%\n",
      "Epoch [57/300], Step [208/225], Training Accuracy: 96.7924%, Training Loss: 0.0987%\n",
      "Epoch [57/300], Step [209/225], Training Accuracy: 96.8077%, Training Loss: 0.0985%\n",
      "Epoch [57/300], Step [210/225], Training Accuracy: 96.8080%, Training Loss: 0.0983%\n",
      "Epoch [57/300], Step [211/225], Training Accuracy: 96.7935%, Training Loss: 0.0983%\n",
      "Epoch [57/300], Step [212/225], Training Accuracy: 96.7792%, Training Loss: 0.0983%\n",
      "Epoch [57/300], Step [213/225], Training Accuracy: 96.7943%, Training Loss: 0.0980%\n",
      "Epoch [57/300], Step [214/225], Training Accuracy: 96.7582%, Training Loss: 0.0985%\n",
      "Epoch [57/300], Step [215/225], Training Accuracy: 96.7442%, Training Loss: 0.0987%\n",
      "Epoch [57/300], Step [216/225], Training Accuracy: 96.7448%, Training Loss: 0.0987%\n",
      "Epoch [57/300], Step [217/225], Training Accuracy: 96.7382%, Training Loss: 0.0987%\n",
      "Epoch [57/300], Step [218/225], Training Accuracy: 96.7532%, Training Loss: 0.0985%\n",
      "Epoch [57/300], Step [219/225], Training Accuracy: 96.7608%, Training Loss: 0.0984%\n",
      "Epoch [57/300], Step [220/225], Training Accuracy: 96.7614%, Training Loss: 0.0982%\n",
      "Epoch [57/300], Step [221/225], Training Accuracy: 96.7477%, Training Loss: 0.0986%\n",
      "Epoch [57/300], Step [222/225], Training Accuracy: 96.7272%, Training Loss: 0.0990%\n",
      "Epoch [57/300], Step [223/225], Training Accuracy: 96.7349%, Training Loss: 0.0988%\n",
      "Epoch [57/300], Step [224/225], Training Accuracy: 96.7425%, Training Loss: 0.0987%\n",
      "Epoch [57/300], Step [225/225], Training Accuracy: 96.7273%, Training Loss: 0.0990%\n",
      "Epoch [58/300], Step [1/225], Training Accuracy: 98.4375%, Training Loss: 0.0857%\n",
      "Epoch [58/300], Step [2/225], Training Accuracy: 99.2188%, Training Loss: 0.0599%\n",
      "Epoch [58/300], Step [3/225], Training Accuracy: 97.3958%, Training Loss: 0.0856%\n",
      "Epoch [58/300], Step [4/225], Training Accuracy: 97.6562%, Training Loss: 0.0854%\n",
      "Epoch [58/300], Step [5/225], Training Accuracy: 97.8125%, Training Loss: 0.0814%\n",
      "Epoch [58/300], Step [6/225], Training Accuracy: 97.9167%, Training Loss: 0.0828%\n",
      "Epoch [58/300], Step [7/225], Training Accuracy: 97.7679%, Training Loss: 0.0834%\n",
      "Epoch [58/300], Step [8/225], Training Accuracy: 97.4609%, Training Loss: 0.0900%\n",
      "Epoch [58/300], Step [9/225], Training Accuracy: 97.2222%, Training Loss: 0.0888%\n",
      "Epoch [58/300], Step [10/225], Training Accuracy: 97.0312%, Training Loss: 0.0923%\n",
      "Epoch [58/300], Step [11/225], Training Accuracy: 96.8750%, Training Loss: 0.0935%\n",
      "Epoch [58/300], Step [12/225], Training Accuracy: 97.0052%, Training Loss: 0.0905%\n",
      "Epoch [58/300], Step [13/225], Training Accuracy: 96.7548%, Training Loss: 0.0977%\n",
      "Epoch [58/300], Step [14/225], Training Accuracy: 96.7634%, Training Loss: 0.0975%\n",
      "Epoch [58/300], Step [15/225], Training Accuracy: 96.6667%, Training Loss: 0.0982%\n",
      "Epoch [58/300], Step [16/225], Training Accuracy: 96.5820%, Training Loss: 0.0990%\n",
      "Epoch [58/300], Step [17/225], Training Accuracy: 96.6912%, Training Loss: 0.0978%\n",
      "Epoch [58/300], Step [18/225], Training Accuracy: 96.3542%, Training Loss: 0.1031%\n",
      "Epoch [58/300], Step [19/225], Training Accuracy: 96.3816%, Training Loss: 0.1033%\n",
      "Epoch [58/300], Step [20/225], Training Accuracy: 96.4844%, Training Loss: 0.1018%\n",
      "Epoch [58/300], Step [21/225], Training Accuracy: 96.6518%, Training Loss: 0.0996%\n",
      "Epoch [58/300], Step [22/225], Training Accuracy: 96.6619%, Training Loss: 0.0994%\n",
      "Epoch [58/300], Step [23/225], Training Accuracy: 96.5353%, Training Loss: 0.1007%\n",
      "Epoch [58/300], Step [24/225], Training Accuracy: 96.1589%, Training Loss: 0.1044%\n",
      "Epoch [58/300], Step [25/225], Training Accuracy: 96.2500%, Training Loss: 0.1027%\n",
      "Epoch [58/300], Step [26/225], Training Accuracy: 96.3942%, Training Loss: 0.1007%\n",
      "Epoch [58/300], Step [27/225], Training Accuracy: 96.3542%, Training Loss: 0.1016%\n",
      "Epoch [58/300], Step [28/225], Training Accuracy: 96.3170%, Training Loss: 0.1012%\n",
      "Epoch [58/300], Step [29/225], Training Accuracy: 96.3901%, Training Loss: 0.1008%\n",
      "Epoch [58/300], Step [30/225], Training Accuracy: 96.4583%, Training Loss: 0.1008%\n",
      "Epoch [58/300], Step [31/225], Training Accuracy: 96.4214%, Training Loss: 0.1022%\n",
      "Epoch [58/300], Step [32/225], Training Accuracy: 96.4355%, Training Loss: 0.1010%\n",
      "Epoch [58/300], Step [33/225], Training Accuracy: 96.4489%, Training Loss: 0.1007%\n",
      "Epoch [58/300], Step [34/225], Training Accuracy: 96.3695%, Training Loss: 0.1012%\n",
      "Epoch [58/300], Step [35/225], Training Accuracy: 96.3839%, Training Loss: 0.1014%\n",
      "Epoch [58/300], Step [36/225], Training Accuracy: 96.3542%, Training Loss: 0.1018%\n",
      "Epoch [58/300], Step [37/225], Training Accuracy: 96.3682%, Training Loss: 0.1020%\n",
      "Epoch [58/300], Step [38/225], Training Accuracy: 96.2993%, Training Loss: 0.1029%\n",
      "Epoch [58/300], Step [39/225], Training Accuracy: 96.3141%, Training Loss: 0.1027%\n",
      "Epoch [58/300], Step [40/225], Training Accuracy: 96.3672%, Training Loss: 0.1026%\n",
      "Epoch [58/300], Step [41/225], Training Accuracy: 96.3415%, Training Loss: 0.1025%\n",
      "Epoch [58/300], Step [42/225], Training Accuracy: 96.4286%, Training Loss: 0.1007%\n",
      "Epoch [58/300], Step [43/225], Training Accuracy: 96.4026%, Training Loss: 0.1006%\n",
      "Epoch [58/300], Step [44/225], Training Accuracy: 96.4134%, Training Loss: 0.1002%\n",
      "Epoch [58/300], Step [45/225], Training Accuracy: 96.4931%, Training Loss: 0.0986%\n",
      "Epoch [58/300], Step [46/225], Training Accuracy: 96.4674%, Training Loss: 0.0983%\n",
      "Epoch [58/300], Step [47/225], Training Accuracy: 96.5093%, Training Loss: 0.0972%\n",
      "Epoch [58/300], Step [48/225], Training Accuracy: 96.5495%, Training Loss: 0.0968%\n",
      "Epoch [58/300], Step [49/225], Training Accuracy: 96.5880%, Training Loss: 0.0963%\n",
      "Epoch [58/300], Step [50/225], Training Accuracy: 96.6250%, Training Loss: 0.0965%\n",
      "Epoch [58/300], Step [51/225], Training Accuracy: 96.6299%, Training Loss: 0.0967%\n",
      "Epoch [58/300], Step [52/225], Training Accuracy: 96.6947%, Training Loss: 0.0960%\n",
      "Epoch [58/300], Step [53/225], Training Accuracy: 96.6686%, Training Loss: 0.0964%\n",
      "Epoch [58/300], Step [54/225], Training Accuracy: 96.6725%, Training Loss: 0.0963%\n",
      "Epoch [58/300], Step [55/225], Training Accuracy: 96.6477%, Training Loss: 0.0969%\n",
      "Epoch [58/300], Step [56/225], Training Accuracy: 96.6518%, Training Loss: 0.0970%\n",
      "Epoch [58/300], Step [57/225], Training Accuracy: 96.6557%, Training Loss: 0.0970%\n",
      "Epoch [58/300], Step [58/225], Training Accuracy: 96.6056%, Training Loss: 0.0975%\n",
      "Epoch [58/300], Step [59/225], Training Accuracy: 96.6631%, Training Loss: 0.0971%\n",
      "Epoch [58/300], Step [60/225], Training Accuracy: 96.6146%, Training Loss: 0.0973%\n",
      "Epoch [58/300], Step [61/225], Training Accuracy: 96.5932%, Training Loss: 0.0982%\n",
      "Epoch [58/300], Step [62/225], Training Accuracy: 96.5474%, Training Loss: 0.0984%\n",
      "Epoch [58/300], Step [63/225], Training Accuracy: 96.5030%, Training Loss: 0.0990%\n",
      "Epoch [58/300], Step [64/225], Training Accuracy: 96.5332%, Training Loss: 0.0985%\n",
      "Epoch [58/300], Step [65/225], Training Accuracy: 96.5865%, Training Loss: 0.0973%\n",
      "Epoch [58/300], Step [66/225], Training Accuracy: 96.5909%, Training Loss: 0.0969%\n",
      "Epoch [58/300], Step [67/225], Training Accuracy: 96.6185%, Training Loss: 0.0964%\n",
      "Epoch [58/300], Step [68/225], Training Accuracy: 96.5993%, Training Loss: 0.0973%\n",
      "Epoch [58/300], Step [69/225], Training Accuracy: 96.6033%, Training Loss: 0.0967%\n",
      "Epoch [58/300], Step [70/225], Training Accuracy: 96.6071%, Training Loss: 0.0967%\n",
      "Epoch [58/300], Step [71/225], Training Accuracy: 96.5889%, Training Loss: 0.0973%\n",
      "Epoch [58/300], Step [72/225], Training Accuracy: 96.6146%, Training Loss: 0.0969%\n",
      "Epoch [58/300], Step [73/225], Training Accuracy: 96.6396%, Training Loss: 0.0969%\n",
      "Epoch [58/300], Step [74/225], Training Accuracy: 96.6216%, Training Loss: 0.0976%\n",
      "Epoch [58/300], Step [75/225], Training Accuracy: 96.6250%, Training Loss: 0.0972%\n",
      "Epoch [58/300], Step [76/225], Training Accuracy: 96.5666%, Training Loss: 0.0983%\n",
      "Epoch [58/300], Step [77/225], Training Accuracy: 96.5300%, Training Loss: 0.0995%\n",
      "Epoch [58/300], Step [78/225], Training Accuracy: 96.5745%, Training Loss: 0.0988%\n",
      "Epoch [58/300], Step [79/225], Training Accuracy: 96.5783%, Training Loss: 0.0989%\n",
      "Epoch [58/300], Step [80/225], Training Accuracy: 96.5820%, Training Loss: 0.0987%\n",
      "Epoch [58/300], Step [81/225], Training Accuracy: 96.6049%, Training Loss: 0.0984%\n",
      "Epoch [58/300], Step [82/225], Training Accuracy: 96.6463%, Training Loss: 0.0974%\n",
      "Epoch [58/300], Step [83/225], Training Accuracy: 96.6114%, Training Loss: 0.0984%\n",
      "Epoch [58/300], Step [84/225], Training Accuracy: 96.6518%, Training Loss: 0.0981%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/300], Step [85/225], Training Accuracy: 96.6360%, Training Loss: 0.0980%\n",
      "Epoch [58/300], Step [86/225], Training Accuracy: 96.6570%, Training Loss: 0.0981%\n",
      "Epoch [58/300], Step [87/225], Training Accuracy: 96.6774%, Training Loss: 0.0977%\n",
      "Epoch [58/300], Step [88/225], Training Accuracy: 96.6797%, Training Loss: 0.0977%\n",
      "Epoch [58/300], Step [89/225], Training Accuracy: 96.7170%, Training Loss: 0.0972%\n",
      "Epoch [58/300], Step [90/225], Training Accuracy: 96.7361%, Training Loss: 0.0968%\n",
      "Epoch [58/300], Step [91/225], Training Accuracy: 96.7548%, Training Loss: 0.0964%\n",
      "Epoch [58/300], Step [92/225], Training Accuracy: 96.7901%, Training Loss: 0.0957%\n",
      "Epoch [58/300], Step [93/225], Training Accuracy: 96.7910%, Training Loss: 0.0958%\n",
      "Epoch [58/300], Step [94/225], Training Accuracy: 96.7753%, Training Loss: 0.0959%\n",
      "Epoch [58/300], Step [95/225], Training Accuracy: 96.7105%, Training Loss: 0.0971%\n",
      "Epoch [58/300], Step [96/225], Training Accuracy: 96.7448%, Training Loss: 0.0965%\n",
      "Epoch [58/300], Step [97/225], Training Accuracy: 96.7300%, Training Loss: 0.0967%\n",
      "Epoch [58/300], Step [98/225], Training Accuracy: 96.6518%, Training Loss: 0.0985%\n",
      "Epoch [58/300], Step [99/225], Training Accuracy: 96.6698%, Training Loss: 0.0982%\n",
      "Epoch [58/300], Step [100/225], Training Accuracy: 96.6719%, Training Loss: 0.0980%\n",
      "Epoch [58/300], Step [101/225], Training Accuracy: 96.7048%, Training Loss: 0.0973%\n",
      "Epoch [58/300], Step [102/225], Training Accuracy: 96.7065%, Training Loss: 0.0975%\n",
      "Epoch [58/300], Step [103/225], Training Accuracy: 96.7081%, Training Loss: 0.0974%\n",
      "Epoch [58/300], Step [104/225], Training Accuracy: 96.6947%, Training Loss: 0.0975%\n",
      "Epoch [58/300], Step [105/225], Training Accuracy: 96.7262%, Training Loss: 0.0972%\n",
      "Epoch [58/300], Step [106/225], Training Accuracy: 96.7129%, Training Loss: 0.0977%\n",
      "Epoch [58/300], Step [107/225], Training Accuracy: 96.7144%, Training Loss: 0.0976%\n",
      "Epoch [58/300], Step [108/225], Training Accuracy: 96.6869%, Training Loss: 0.0975%\n",
      "Epoch [58/300], Step [109/225], Training Accuracy: 96.6886%, Training Loss: 0.0973%\n",
      "Epoch [58/300], Step [110/225], Training Accuracy: 96.7188%, Training Loss: 0.0966%\n",
      "Epoch [58/300], Step [111/225], Training Accuracy: 96.7202%, Training Loss: 0.0966%\n",
      "Epoch [58/300], Step [112/225], Training Accuracy: 96.6936%, Training Loss: 0.0970%\n",
      "Epoch [58/300], Step [113/225], Training Accuracy: 96.7229%, Training Loss: 0.0964%\n",
      "Epoch [58/300], Step [114/225], Training Accuracy: 96.7242%, Training Loss: 0.0966%\n",
      "Epoch [58/300], Step [115/225], Training Accuracy: 96.7391%, Training Loss: 0.0964%\n",
      "Epoch [58/300], Step [116/225], Training Accuracy: 96.7672%, Training Loss: 0.0960%\n",
      "Epoch [58/300], Step [117/225], Training Accuracy: 96.7682%, Training Loss: 0.0957%\n",
      "Epoch [58/300], Step [118/225], Training Accuracy: 96.7823%, Training Loss: 0.0954%\n",
      "Epoch [58/300], Step [119/225], Training Accuracy: 96.7831%, Training Loss: 0.0955%\n",
      "Epoch [58/300], Step [120/225], Training Accuracy: 96.7969%, Training Loss: 0.0954%\n",
      "Epoch [58/300], Step [121/225], Training Accuracy: 96.8104%, Training Loss: 0.0952%\n",
      "Epoch [58/300], Step [122/225], Training Accuracy: 96.8238%, Training Loss: 0.0949%\n",
      "Epoch [58/300], Step [123/225], Training Accuracy: 96.8242%, Training Loss: 0.0951%\n",
      "Epoch [58/300], Step [124/225], Training Accuracy: 96.8246%, Training Loss: 0.0951%\n",
      "Epoch [58/300], Step [125/225], Training Accuracy: 96.8250%, Training Loss: 0.0951%\n",
      "Epoch [58/300], Step [126/225], Training Accuracy: 96.8378%, Training Loss: 0.0949%\n",
      "Epoch [58/300], Step [127/225], Training Accuracy: 96.8258%, Training Loss: 0.0953%\n",
      "Epoch [58/300], Step [128/225], Training Accuracy: 96.8140%, Training Loss: 0.0955%\n",
      "Epoch [58/300], Step [129/225], Training Accuracy: 96.8023%, Training Loss: 0.0956%\n",
      "Epoch [58/300], Step [130/225], Training Accuracy: 96.7909%, Training Loss: 0.0959%\n",
      "Epoch [58/300], Step [131/225], Training Accuracy: 96.8034%, Training Loss: 0.0958%\n",
      "Epoch [58/300], Step [132/225], Training Accuracy: 96.8158%, Training Loss: 0.0956%\n",
      "Epoch [58/300], Step [133/225], Training Accuracy: 96.8045%, Training Loss: 0.0954%\n",
      "Epoch [58/300], Step [134/225], Training Accuracy: 96.8284%, Training Loss: 0.0953%\n",
      "Epoch [58/300], Step [135/225], Training Accuracy: 96.8403%, Training Loss: 0.0950%\n",
      "Epoch [58/300], Step [136/225], Training Accuracy: 96.8290%, Training Loss: 0.0953%\n",
      "Epoch [58/300], Step [137/225], Training Accuracy: 96.8522%, Training Loss: 0.0950%\n",
      "Epoch [58/300], Step [138/225], Training Accuracy: 96.8524%, Training Loss: 0.0950%\n",
      "Epoch [58/300], Step [139/225], Training Accuracy: 96.8525%, Training Loss: 0.0949%\n",
      "Epoch [58/300], Step [140/225], Training Accuracy: 96.8527%, Training Loss: 0.0948%\n",
      "Epoch [58/300], Step [141/225], Training Accuracy: 96.8639%, Training Loss: 0.0949%\n",
      "Epoch [58/300], Step [142/225], Training Accuracy: 96.8530%, Training Loss: 0.0951%\n",
      "Epoch [58/300], Step [143/225], Training Accuracy: 96.8531%, Training Loss: 0.0951%\n",
      "Epoch [58/300], Step [144/225], Training Accuracy: 96.8533%, Training Loss: 0.0951%\n",
      "Epoch [58/300], Step [145/225], Training Accuracy: 96.8534%, Training Loss: 0.0950%\n",
      "Epoch [58/300], Step [146/225], Training Accuracy: 96.8750%, Training Loss: 0.0947%\n",
      "Epoch [58/300], Step [147/225], Training Accuracy: 96.8750%, Training Loss: 0.0947%\n",
      "Epoch [58/300], Step [148/225], Training Accuracy: 96.8539%, Training Loss: 0.0949%\n",
      "Epoch [58/300], Step [149/225], Training Accuracy: 96.8121%, Training Loss: 0.0957%\n",
      "Epoch [58/300], Step [150/225], Training Accuracy: 96.8021%, Training Loss: 0.0958%\n",
      "Epoch [58/300], Step [151/225], Training Accuracy: 96.8026%, Training Loss: 0.0958%\n",
      "Epoch [58/300], Step [152/225], Training Accuracy: 96.8133%, Training Loss: 0.0956%\n",
      "Epoch [58/300], Step [153/225], Training Accuracy: 96.7831%, Training Loss: 0.0961%\n",
      "Epoch [58/300], Step [154/225], Training Accuracy: 96.7938%, Training Loss: 0.0958%\n",
      "Epoch [58/300], Step [155/225], Training Accuracy: 96.8145%, Training Loss: 0.0954%\n",
      "Epoch [58/300], Step [156/225], Training Accuracy: 96.8249%, Training Loss: 0.0952%\n",
      "Epoch [58/300], Step [157/225], Training Accuracy: 96.8153%, Training Loss: 0.0952%\n",
      "Epoch [58/300], Step [158/225], Training Accuracy: 96.8354%, Training Loss: 0.0949%\n",
      "Epoch [58/300], Step [159/225], Training Accuracy: 96.8455%, Training Loss: 0.0948%\n",
      "Epoch [58/300], Step [160/225], Training Accuracy: 96.8359%, Training Loss: 0.0946%\n",
      "Epoch [58/300], Step [161/225], Training Accuracy: 96.8362%, Training Loss: 0.0946%\n",
      "Epoch [58/300], Step [162/225], Training Accuracy: 96.8268%, Training Loss: 0.0948%\n",
      "Epoch [58/300], Step [163/225], Training Accuracy: 96.8271%, Training Loss: 0.0952%\n",
      "Epoch [58/300], Step [164/225], Training Accuracy: 96.8369%, Training Loss: 0.0950%\n",
      "Epoch [58/300], Step [165/225], Training Accuracy: 96.8371%, Training Loss: 0.0948%\n",
      "Epoch [58/300], Step [166/225], Training Accuracy: 96.8562%, Training Loss: 0.0945%\n",
      "Epoch [58/300], Step [167/225], Training Accuracy: 96.8469%, Training Loss: 0.0949%\n",
      "Epoch [58/300], Step [168/225], Training Accuracy: 96.8285%, Training Loss: 0.0951%\n",
      "Epoch [58/300], Step [169/225], Training Accuracy: 96.8195%, Training Loss: 0.0952%\n",
      "Epoch [58/300], Step [170/225], Training Accuracy: 96.8290%, Training Loss: 0.0950%\n",
      "Epoch [58/300], Step [171/225], Training Accuracy: 96.8476%, Training Loss: 0.0947%\n",
      "Epoch [58/300], Step [172/225], Training Accuracy: 96.8477%, Training Loss: 0.0948%\n",
      "Epoch [58/300], Step [173/225], Training Accuracy: 96.8389%, Training Loss: 0.0950%\n",
      "Epoch [58/300], Step [174/225], Training Accuracy: 96.8391%, Training Loss: 0.0949%\n",
      "Epoch [58/300], Step [175/225], Training Accuracy: 96.8571%, Training Loss: 0.0947%\n",
      "Epoch [58/300], Step [176/225], Training Accuracy: 96.8395%, Training Loss: 0.0949%\n",
      "Epoch [58/300], Step [177/225], Training Accuracy: 96.8485%, Training Loss: 0.0946%\n",
      "Epoch [58/300], Step [178/225], Training Accuracy: 96.8136%, Training Loss: 0.0951%\n",
      "Epoch [58/300], Step [179/225], Training Accuracy: 96.8226%, Training Loss: 0.0951%\n",
      "Epoch [58/300], Step [180/225], Training Accuracy: 96.8229%, Training Loss: 0.0953%\n",
      "Epoch [58/300], Step [181/225], Training Accuracy: 96.8232%, Training Loss: 0.0955%\n",
      "Epoch [58/300], Step [182/225], Training Accuracy: 96.8149%, Training Loss: 0.0956%\n",
      "Epoch [58/300], Step [183/225], Training Accuracy: 96.8238%, Training Loss: 0.0954%\n",
      "Epoch [58/300], Step [184/225], Training Accuracy: 96.8156%, Training Loss: 0.0957%\n",
      "Epoch [58/300], Step [185/225], Training Accuracy: 96.8243%, Training Loss: 0.0955%\n",
      "Epoch [58/300], Step [186/225], Training Accuracy: 96.8330%, Training Loss: 0.0954%\n",
      "Epoch [58/300], Step [187/225], Training Accuracy: 96.8249%, Training Loss: 0.0956%\n",
      "Epoch [58/300], Step [188/225], Training Accuracy: 96.8251%, Training Loss: 0.0955%\n",
      "Epoch [58/300], Step [189/225], Training Accuracy: 96.8254%, Training Loss: 0.0953%\n",
      "Epoch [58/300], Step [190/225], Training Accuracy: 96.8092%, Training Loss: 0.0956%\n",
      "Epoch [58/300], Step [191/225], Training Accuracy: 96.8177%, Training Loss: 0.0956%\n",
      "Epoch [58/300], Step [192/225], Training Accuracy: 96.8262%, Training Loss: 0.0955%\n",
      "Epoch [58/300], Step [193/225], Training Accuracy: 96.8345%, Training Loss: 0.0955%\n",
      "Epoch [58/300], Step [194/225], Training Accuracy: 96.8428%, Training Loss: 0.0954%\n",
      "Epoch [58/300], Step [195/225], Training Accuracy: 96.8429%, Training Loss: 0.0954%\n",
      "Epoch [58/300], Step [196/225], Training Accuracy: 96.8511%, Training Loss: 0.0951%\n",
      "Epoch [58/300], Step [197/225], Training Accuracy: 96.8591%, Training Loss: 0.0950%\n",
      "Epoch [58/300], Step [198/225], Training Accuracy: 96.8750%, Training Loss: 0.0948%\n",
      "Epoch [58/300], Step [199/225], Training Accuracy: 96.8750%, Training Loss: 0.0948%\n",
      "Epoch [58/300], Step [200/225], Training Accuracy: 96.8672%, Training Loss: 0.0948%\n",
      "Epoch [58/300], Step [201/225], Training Accuracy: 96.8517%, Training Loss: 0.0950%\n",
      "Epoch [58/300], Step [202/225], Training Accuracy: 96.8286%, Training Loss: 0.0953%\n",
      "Epoch [58/300], Step [203/225], Training Accuracy: 96.8365%, Training Loss: 0.0953%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/300], Step [204/225], Training Accuracy: 96.8290%, Training Loss: 0.0955%\n",
      "Epoch [58/300], Step [205/225], Training Accuracy: 96.8445%, Training Loss: 0.0952%\n",
      "Epoch [58/300], Step [206/225], Training Accuracy: 96.8522%, Training Loss: 0.0953%\n",
      "Epoch [58/300], Step [207/225], Training Accuracy: 96.8675%, Training Loss: 0.0950%\n",
      "Epoch [58/300], Step [208/225], Training Accuracy: 96.8525%, Training Loss: 0.0952%\n",
      "Epoch [58/300], Step [209/225], Training Accuracy: 96.8526%, Training Loss: 0.0953%\n",
      "Epoch [58/300], Step [210/225], Training Accuracy: 96.8527%, Training Loss: 0.0952%\n",
      "Epoch [58/300], Step [211/225], Training Accuracy: 96.8528%, Training Loss: 0.0951%\n",
      "Epoch [58/300], Step [212/225], Training Accuracy: 96.8381%, Training Loss: 0.0954%\n",
      "Epoch [58/300], Step [213/225], Training Accuracy: 96.8310%, Training Loss: 0.0954%\n",
      "Epoch [58/300], Step [214/225], Training Accuracy: 96.8020%, Training Loss: 0.0957%\n",
      "Epoch [58/300], Step [215/225], Training Accuracy: 96.8023%, Training Loss: 0.0957%\n",
      "Epoch [58/300], Step [216/225], Training Accuracy: 96.7810%, Training Loss: 0.0961%\n",
      "Epoch [58/300], Step [217/225], Training Accuracy: 96.7814%, Training Loss: 0.0961%\n",
      "Epoch [58/300], Step [218/225], Training Accuracy: 96.7818%, Training Loss: 0.0960%\n",
      "Epoch [58/300], Step [219/225], Training Accuracy: 96.7822%, Training Loss: 0.0959%\n",
      "Epoch [58/300], Step [220/225], Training Accuracy: 96.7969%, Training Loss: 0.0957%\n",
      "Epoch [58/300], Step [221/225], Training Accuracy: 96.8043%, Training Loss: 0.0955%\n",
      "Epoch [58/300], Step [222/225], Training Accuracy: 96.8117%, Training Loss: 0.0956%\n",
      "Epoch [58/300], Step [223/225], Training Accuracy: 96.8189%, Training Loss: 0.0954%\n",
      "Epoch [58/300], Step [224/225], Training Accuracy: 96.8331%, Training Loss: 0.0951%\n",
      "Epoch [58/300], Step [225/225], Training Accuracy: 96.8385%, Training Loss: 0.0950%\n",
      "Epoch [59/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0417%\n",
      "Epoch [59/300], Step [2/225], Training Accuracy: 98.4375%, Training Loss: 0.0551%\n",
      "Epoch [59/300], Step [3/225], Training Accuracy: 96.8750%, Training Loss: 0.0959%\n",
      "Epoch [59/300], Step [4/225], Training Accuracy: 97.2656%, Training Loss: 0.0857%\n",
      "Epoch [59/300], Step [5/225], Training Accuracy: 97.1875%, Training Loss: 0.0896%\n",
      "Epoch [59/300], Step [6/225], Training Accuracy: 97.1354%, Training Loss: 0.0839%\n",
      "Epoch [59/300], Step [7/225], Training Accuracy: 97.0982%, Training Loss: 0.0857%\n",
      "Epoch [59/300], Step [8/225], Training Accuracy: 96.4844%, Training Loss: 0.0932%\n",
      "Epoch [59/300], Step [9/225], Training Accuracy: 96.5278%, Training Loss: 0.0914%\n",
      "Epoch [59/300], Step [10/225], Training Accuracy: 96.4062%, Training Loss: 0.0926%\n",
      "Epoch [59/300], Step [11/225], Training Accuracy: 96.3068%, Training Loss: 0.0943%\n",
      "Epoch [59/300], Step [12/225], Training Accuracy: 96.4844%, Training Loss: 0.0911%\n",
      "Epoch [59/300], Step [13/225], Training Accuracy: 96.6346%, Training Loss: 0.0890%\n",
      "Epoch [59/300], Step [14/225], Training Accuracy: 96.6518%, Training Loss: 0.0881%\n",
      "Epoch [59/300], Step [15/225], Training Accuracy: 96.6667%, Training Loss: 0.0869%\n",
      "Epoch [59/300], Step [16/225], Training Accuracy: 96.5820%, Training Loss: 0.0871%\n",
      "Epoch [59/300], Step [17/225], Training Accuracy: 96.3235%, Training Loss: 0.0917%\n",
      "Epoch [59/300], Step [18/225], Training Accuracy: 96.0938%, Training Loss: 0.0953%\n",
      "Epoch [59/300], Step [19/225], Training Accuracy: 96.1349%, Training Loss: 0.0952%\n",
      "Epoch [59/300], Step [20/225], Training Accuracy: 96.1719%, Training Loss: 0.0957%\n",
      "Epoch [59/300], Step [21/225], Training Accuracy: 96.2798%, Training Loss: 0.0938%\n",
      "Epoch [59/300], Step [22/225], Training Accuracy: 96.1648%, Training Loss: 0.0950%\n",
      "Epoch [59/300], Step [23/225], Training Accuracy: 96.1957%, Training Loss: 0.0942%\n",
      "Epoch [59/300], Step [24/225], Training Accuracy: 96.2240%, Training Loss: 0.0936%\n",
      "Epoch [59/300], Step [25/225], Training Accuracy: 96.3750%, Training Loss: 0.0910%\n",
      "Epoch [59/300], Step [26/225], Training Accuracy: 96.4543%, Training Loss: 0.0898%\n",
      "Epoch [59/300], Step [27/225], Training Accuracy: 96.5278%, Training Loss: 0.0904%\n",
      "Epoch [59/300], Step [28/225], Training Accuracy: 96.5960%, Training Loss: 0.0889%\n",
      "Epoch [59/300], Step [29/225], Training Accuracy: 96.3901%, Training Loss: 0.0927%\n",
      "Epoch [59/300], Step [30/225], Training Accuracy: 96.4062%, Training Loss: 0.0935%\n",
      "Epoch [59/300], Step [31/225], Training Accuracy: 96.3206%, Training Loss: 0.0951%\n",
      "Epoch [59/300], Step [32/225], Training Accuracy: 96.3379%, Training Loss: 0.0947%\n",
      "Epoch [59/300], Step [33/225], Training Accuracy: 96.4489%, Training Loss: 0.0930%\n",
      "Epoch [59/300], Step [34/225], Training Accuracy: 96.4154%, Training Loss: 0.0958%\n",
      "Epoch [59/300], Step [35/225], Training Accuracy: 96.2500%, Training Loss: 0.0981%\n",
      "Epoch [59/300], Step [36/225], Training Accuracy: 96.1372%, Training Loss: 0.1001%\n",
      "Epoch [59/300], Step [37/225], Training Accuracy: 96.1993%, Training Loss: 0.0998%\n",
      "Epoch [59/300], Step [38/225], Training Accuracy: 96.1760%, Training Loss: 0.0999%\n",
      "Epoch [59/300], Step [39/225], Training Accuracy: 96.1939%, Training Loss: 0.1002%\n",
      "Epoch [59/300], Step [40/225], Training Accuracy: 96.2500%, Training Loss: 0.0997%\n",
      "Epoch [59/300], Step [41/225], Training Accuracy: 96.1890%, Training Loss: 0.1014%\n",
      "Epoch [59/300], Step [42/225], Training Accuracy: 96.2054%, Training Loss: 0.1011%\n",
      "Epoch [59/300], Step [43/225], Training Accuracy: 96.2936%, Training Loss: 0.1001%\n",
      "Epoch [59/300], Step [44/225], Training Accuracy: 96.3423%, Training Loss: 0.0991%\n",
      "Epoch [59/300], Step [45/225], Training Accuracy: 96.3889%, Training Loss: 0.0981%\n",
      "Epoch [59/300], Step [46/225], Training Accuracy: 96.3995%, Training Loss: 0.0979%\n",
      "Epoch [59/300], Step [47/225], Training Accuracy: 96.4428%, Training Loss: 0.0986%\n",
      "Epoch [59/300], Step [48/225], Training Accuracy: 96.4193%, Training Loss: 0.0995%\n",
      "Epoch [59/300], Step [49/225], Training Accuracy: 96.4286%, Training Loss: 0.0997%\n",
      "Epoch [59/300], Step [50/225], Training Accuracy: 96.3438%, Training Loss: 0.1014%\n",
      "Epoch [59/300], Step [51/225], Training Accuracy: 96.2316%, Training Loss: 0.1023%\n",
      "Epoch [59/300], Step [52/225], Training Accuracy: 96.2440%, Training Loss: 0.1019%\n",
      "Epoch [59/300], Step [53/225], Training Accuracy: 96.3149%, Training Loss: 0.1009%\n",
      "Epoch [59/300], Step [54/225], Training Accuracy: 96.2674%, Training Loss: 0.1012%\n",
      "Epoch [59/300], Step [55/225], Training Accuracy: 96.2216%, Training Loss: 0.1024%\n",
      "Epoch [59/300], Step [56/225], Training Accuracy: 96.2054%, Training Loss: 0.1031%\n",
      "Epoch [59/300], Step [57/225], Training Accuracy: 96.1349%, Training Loss: 0.1039%\n",
      "Epoch [59/300], Step [58/225], Training Accuracy: 96.0938%, Training Loss: 0.1042%\n",
      "Epoch [59/300], Step [59/225], Training Accuracy: 96.1070%, Training Loss: 0.1040%\n",
      "Epoch [59/300], Step [60/225], Training Accuracy: 96.1198%, Training Loss: 0.1041%\n",
      "Epoch [59/300], Step [61/225], Training Accuracy: 96.0809%, Training Loss: 0.1051%\n",
      "Epoch [59/300], Step [62/225], Training Accuracy: 96.0433%, Training Loss: 0.1073%\n",
      "Epoch [59/300], Step [63/225], Training Accuracy: 96.0565%, Training Loss: 0.1071%\n",
      "Epoch [59/300], Step [64/225], Training Accuracy: 96.0693%, Training Loss: 0.1070%\n",
      "Epoch [59/300], Step [65/225], Training Accuracy: 96.0337%, Training Loss: 0.1070%\n",
      "Epoch [59/300], Step [66/225], Training Accuracy: 96.0464%, Training Loss: 0.1067%\n",
      "Epoch [59/300], Step [67/225], Training Accuracy: 96.1054%, Training Loss: 0.1057%\n",
      "Epoch [59/300], Step [68/225], Training Accuracy: 96.0938%, Training Loss: 0.1060%\n",
      "Epoch [59/300], Step [69/225], Training Accuracy: 96.1504%, Training Loss: 0.1050%\n",
      "Epoch [59/300], Step [70/225], Training Accuracy: 96.1830%, Training Loss: 0.1045%\n",
      "Epoch [59/300], Step [71/225], Training Accuracy: 96.1928%, Training Loss: 0.1040%\n",
      "Epoch [59/300], Step [72/225], Training Accuracy: 96.2023%, Training Loss: 0.1038%\n",
      "Epoch [59/300], Step [73/225], Training Accuracy: 96.2115%, Training Loss: 0.1039%\n",
      "Epoch [59/300], Step [74/225], Training Accuracy: 96.1571%, Training Loss: 0.1047%\n",
      "Epoch [59/300], Step [75/225], Training Accuracy: 96.1042%, Training Loss: 0.1055%\n",
      "Epoch [59/300], Step [76/225], Training Accuracy: 96.0115%, Training Loss: 0.1071%\n",
      "Epoch [59/300], Step [77/225], Training Accuracy: 96.0024%, Training Loss: 0.1071%\n",
      "Epoch [59/300], Step [78/225], Training Accuracy: 95.9936%, Training Loss: 0.1071%\n",
      "Epoch [59/300], Step [79/225], Training Accuracy: 96.0245%, Training Loss: 0.1070%\n",
      "Epoch [59/300], Step [80/225], Training Accuracy: 95.9766%, Training Loss: 0.1076%\n",
      "Epoch [59/300], Step [81/225], Training Accuracy: 95.9877%, Training Loss: 0.1073%\n",
      "Epoch [59/300], Step [82/225], Training Accuracy: 95.9985%, Training Loss: 0.1073%\n",
      "Epoch [59/300], Step [83/225], Training Accuracy: 96.0090%, Training Loss: 0.1073%\n",
      "Epoch [59/300], Step [84/225], Training Accuracy: 96.0379%, Training Loss: 0.1069%\n",
      "Epoch [59/300], Step [85/225], Training Accuracy: 96.0110%, Training Loss: 0.1076%\n",
      "Epoch [59/300], Step [86/225], Training Accuracy: 95.9847%, Training Loss: 0.1080%\n",
      "Epoch [59/300], Step [87/225], Training Accuracy: 95.9411%, Training Loss: 0.1087%\n",
      "Epoch [59/300], Step [88/225], Training Accuracy: 95.9872%, Training Loss: 0.1081%\n",
      "Epoch [59/300], Step [89/225], Training Accuracy: 95.9972%, Training Loss: 0.1078%\n",
      "Epoch [59/300], Step [90/225], Training Accuracy: 96.0069%, Training Loss: 0.1075%\n",
      "Epoch [59/300], Step [91/225], Training Accuracy: 96.0337%, Training Loss: 0.1069%\n",
      "Epoch [59/300], Step [92/225], Training Accuracy: 96.0428%, Training Loss: 0.1068%\n",
      "Epoch [59/300], Step [93/225], Training Accuracy: 96.0685%, Training Loss: 0.1066%\n",
      "Epoch [59/300], Step [94/225], Training Accuracy: 96.0273%, Training Loss: 0.1069%\n",
      "Epoch [59/300], Step [95/225], Training Accuracy: 96.0197%, Training Loss: 0.1068%\n",
      "Epoch [59/300], Step [96/225], Training Accuracy: 96.0449%, Training Loss: 0.1062%\n",
      "Epoch [59/300], Step [97/225], Training Accuracy: 96.0535%, Training Loss: 0.1062%\n",
      "Epoch [59/300], Step [98/225], Training Accuracy: 96.0619%, Training Loss: 0.1064%\n",
      "Epoch [59/300], Step [99/225], Training Accuracy: 96.0859%, Training Loss: 0.1062%\n",
      "Epoch [59/300], Step [100/225], Training Accuracy: 96.0781%, Training Loss: 0.1062%\n",
      "Epoch [59/300], Step [101/225], Training Accuracy: 96.0860%, Training Loss: 0.1058%\n",
      "Epoch [59/300], Step [102/225], Training Accuracy: 96.0784%, Training Loss: 0.1061%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/300], Step [103/225], Training Accuracy: 96.0710%, Training Loss: 0.1062%\n",
      "Epoch [59/300], Step [104/225], Training Accuracy: 96.0637%, Training Loss: 0.1069%\n",
      "Epoch [59/300], Step [105/225], Training Accuracy: 96.1012%, Training Loss: 0.1065%\n",
      "Epoch [59/300], Step [106/225], Training Accuracy: 96.0938%, Training Loss: 0.1064%\n",
      "Epoch [59/300], Step [107/225], Training Accuracy: 96.1157%, Training Loss: 0.1061%\n",
      "Epoch [59/300], Step [108/225], Training Accuracy: 96.1372%, Training Loss: 0.1058%\n",
      "Epoch [59/300], Step [109/225], Training Accuracy: 96.1439%, Training Loss: 0.1057%\n",
      "Epoch [59/300], Step [110/225], Training Accuracy: 96.1648%, Training Loss: 0.1056%\n",
      "Epoch [59/300], Step [111/225], Training Accuracy: 96.1993%, Training Loss: 0.1052%\n",
      "Epoch [59/300], Step [112/225], Training Accuracy: 96.1914%, Training Loss: 0.1048%\n",
      "Epoch [59/300], Step [113/225], Training Accuracy: 96.2113%, Training Loss: 0.1045%\n",
      "Epoch [59/300], Step [114/225], Training Accuracy: 96.2034%, Training Loss: 0.1049%\n",
      "Epoch [59/300], Step [115/225], Training Accuracy: 96.2364%, Training Loss: 0.1042%\n",
      "Epoch [59/300], Step [116/225], Training Accuracy: 96.2015%, Training Loss: 0.1046%\n",
      "Epoch [59/300], Step [117/225], Training Accuracy: 96.1405%, Training Loss: 0.1050%\n",
      "Epoch [59/300], Step [118/225], Training Accuracy: 96.1335%, Training Loss: 0.1049%\n",
      "Epoch [59/300], Step [119/225], Training Accuracy: 96.1003%, Training Loss: 0.1056%\n",
      "Epoch [59/300], Step [120/225], Training Accuracy: 96.1328%, Training Loss: 0.1051%\n",
      "Epoch [59/300], Step [121/225], Training Accuracy: 96.1648%, Training Loss: 0.1046%\n",
      "Epoch [59/300], Step [122/225], Training Accuracy: 96.1834%, Training Loss: 0.1041%\n",
      "Epoch [59/300], Step [123/225], Training Accuracy: 96.1890%, Training Loss: 0.1040%\n",
      "Epoch [59/300], Step [124/225], Training Accuracy: 96.2072%, Training Loss: 0.1035%\n",
      "Epoch [59/300], Step [125/225], Training Accuracy: 96.2125%, Training Loss: 0.1038%\n",
      "Epoch [59/300], Step [126/225], Training Accuracy: 96.1558%, Training Loss: 0.1054%\n",
      "Epoch [59/300], Step [127/225], Training Accuracy: 96.1368%, Training Loss: 0.1054%\n",
      "Epoch [59/300], Step [128/225], Training Accuracy: 96.1548%, Training Loss: 0.1053%\n",
      "Epoch [59/300], Step [129/225], Training Accuracy: 96.1604%, Training Loss: 0.1052%\n",
      "Epoch [59/300], Step [130/225], Training Accuracy: 96.1418%, Training Loss: 0.1054%\n",
      "Epoch [59/300], Step [131/225], Training Accuracy: 96.1474%, Training Loss: 0.1057%\n",
      "Epoch [59/300], Step [132/225], Training Accuracy: 96.1174%, Training Loss: 0.1059%\n",
      "Epoch [59/300], Step [133/225], Training Accuracy: 96.1349%, Training Loss: 0.1059%\n",
      "Epoch [59/300], Step [134/225], Training Accuracy: 96.1521%, Training Loss: 0.1057%\n",
      "Epoch [59/300], Step [135/225], Training Accuracy: 96.1574%, Training Loss: 0.1056%\n",
      "Epoch [59/300], Step [136/225], Training Accuracy: 96.1282%, Training Loss: 0.1067%\n",
      "Epoch [59/300], Step [137/225], Training Accuracy: 96.1451%, Training Loss: 0.1064%\n",
      "Epoch [59/300], Step [138/225], Training Accuracy: 96.1164%, Training Loss: 0.1068%\n",
      "Epoch [59/300], Step [139/225], Training Accuracy: 96.1219%, Training Loss: 0.1068%\n",
      "Epoch [59/300], Step [140/225], Training Accuracy: 96.1384%, Training Loss: 0.1066%\n",
      "Epoch [59/300], Step [141/225], Training Accuracy: 96.1658%, Training Loss: 0.1064%\n",
      "Epoch [59/300], Step [142/225], Training Accuracy: 96.1818%, Training Loss: 0.1061%\n",
      "Epoch [59/300], Step [143/225], Training Accuracy: 96.1648%, Training Loss: 0.1063%\n",
      "Epoch [59/300], Step [144/225], Training Accuracy: 96.1480%, Training Loss: 0.1064%\n",
      "Epoch [59/300], Step [145/225], Training Accuracy: 96.1746%, Training Loss: 0.1059%\n",
      "Epoch [59/300], Step [146/225], Training Accuracy: 96.1794%, Training Loss: 0.1057%\n",
      "Epoch [59/300], Step [147/225], Training Accuracy: 96.1628%, Training Loss: 0.1058%\n",
      "Epoch [59/300], Step [148/225], Training Accuracy: 96.1782%, Training Loss: 0.1055%\n",
      "Epoch [59/300], Step [149/225], Training Accuracy: 96.1724%, Training Loss: 0.1056%\n",
      "Epoch [59/300], Step [150/225], Training Accuracy: 96.1667%, Training Loss: 0.1054%\n",
      "Epoch [59/300], Step [151/225], Training Accuracy: 96.1921%, Training Loss: 0.1052%\n",
      "Epoch [59/300], Step [152/225], Training Accuracy: 96.2068%, Training Loss: 0.1050%\n",
      "Epoch [59/300], Step [153/225], Training Accuracy: 96.1908%, Training Loss: 0.1052%\n",
      "Epoch [59/300], Step [154/225], Training Accuracy: 96.1851%, Training Loss: 0.1053%\n",
      "Epoch [59/300], Step [155/225], Training Accuracy: 96.1694%, Training Loss: 0.1057%\n",
      "Epoch [59/300], Step [156/225], Training Accuracy: 96.1839%, Training Loss: 0.1056%\n",
      "Epoch [59/300], Step [157/225], Training Accuracy: 96.1883%, Training Loss: 0.1055%\n",
      "Epoch [59/300], Step [158/225], Training Accuracy: 96.2025%, Training Loss: 0.1051%\n",
      "Epoch [59/300], Step [159/225], Training Accuracy: 96.2068%, Training Loss: 0.1050%\n",
      "Epoch [59/300], Step [160/225], Training Accuracy: 96.2305%, Training Loss: 0.1046%\n",
      "Epoch [59/300], Step [161/225], Training Accuracy: 96.2345%, Training Loss: 0.1044%\n",
      "Epoch [59/300], Step [162/225], Training Accuracy: 96.2384%, Training Loss: 0.1041%\n",
      "Epoch [59/300], Step [163/225], Training Accuracy: 96.2615%, Training Loss: 0.1037%\n",
      "Epoch [59/300], Step [164/225], Training Accuracy: 96.2652%, Training Loss: 0.1036%\n",
      "Epoch [59/300], Step [165/225], Training Accuracy: 96.2784%, Training Loss: 0.1033%\n",
      "Epoch [59/300], Step [166/225], Training Accuracy: 96.2820%, Training Loss: 0.1035%\n",
      "Epoch [59/300], Step [167/225], Training Accuracy: 96.2762%, Training Loss: 0.1037%\n",
      "Epoch [59/300], Step [168/225], Training Accuracy: 96.2798%, Training Loss: 0.1035%\n",
      "Epoch [59/300], Step [169/225], Training Accuracy: 96.2648%, Training Loss: 0.1039%\n",
      "Epoch [59/300], Step [170/225], Training Accuracy: 96.2776%, Training Loss: 0.1037%\n",
      "Epoch [59/300], Step [171/225], Training Accuracy: 96.2902%, Training Loss: 0.1035%\n",
      "Epoch [59/300], Step [172/225], Training Accuracy: 96.2936%, Training Loss: 0.1033%\n",
      "Epoch [59/300], Step [173/225], Training Accuracy: 96.3060%, Training Loss: 0.1031%\n",
      "Epoch [59/300], Step [174/225], Training Accuracy: 96.2913%, Training Loss: 0.1035%\n",
      "Epoch [59/300], Step [175/225], Training Accuracy: 96.2946%, Training Loss: 0.1033%\n",
      "Epoch [59/300], Step [176/225], Training Accuracy: 96.3068%, Training Loss: 0.1032%\n",
      "Epoch [59/300], Step [177/225], Training Accuracy: 96.3277%, Training Loss: 0.1029%\n",
      "Epoch [59/300], Step [178/225], Training Accuracy: 96.3308%, Training Loss: 0.1028%\n",
      "Epoch [59/300], Step [179/225], Training Accuracy: 96.3513%, Training Loss: 0.1025%\n",
      "Epoch [59/300], Step [180/225], Training Accuracy: 96.3542%, Training Loss: 0.1024%\n",
      "Epoch [59/300], Step [181/225], Training Accuracy: 96.3570%, Training Loss: 0.1025%\n",
      "Epoch [59/300], Step [182/225], Training Accuracy: 96.3599%, Training Loss: 0.1024%\n",
      "Epoch [59/300], Step [183/225], Training Accuracy: 96.3712%, Training Loss: 0.1021%\n",
      "Epoch [59/300], Step [184/225], Training Accuracy: 96.3570%, Training Loss: 0.1024%\n",
      "Epoch [59/300], Step [185/225], Training Accuracy: 96.3682%, Training Loss: 0.1021%\n",
      "Epoch [59/300], Step [186/225], Training Accuracy: 96.3542%, Training Loss: 0.1022%\n",
      "Epoch [59/300], Step [187/225], Training Accuracy: 96.3486%, Training Loss: 0.1023%\n",
      "Epoch [59/300], Step [188/225], Training Accuracy: 96.3597%, Training Loss: 0.1020%\n",
      "Epoch [59/300], Step [189/225], Training Accuracy: 96.3790%, Training Loss: 0.1017%\n",
      "Epoch [59/300], Step [190/225], Training Accuracy: 96.3734%, Training Loss: 0.1018%\n",
      "Epoch [59/300], Step [191/225], Training Accuracy: 96.3842%, Training Loss: 0.1016%\n",
      "Epoch [59/300], Step [192/225], Training Accuracy: 96.3786%, Training Loss: 0.1018%\n",
      "Epoch [59/300], Step [193/225], Training Accuracy: 96.3731%, Training Loss: 0.1018%\n",
      "Epoch [59/300], Step [194/225], Training Accuracy: 96.3676%, Training Loss: 0.1018%\n",
      "Epoch [59/300], Step [195/225], Training Accuracy: 96.3702%, Training Loss: 0.1017%\n",
      "Epoch [59/300], Step [196/225], Training Accuracy: 96.3887%, Training Loss: 0.1013%\n",
      "Epoch [59/300], Step [197/225], Training Accuracy: 96.3912%, Training Loss: 0.1014%\n",
      "Epoch [59/300], Step [198/225], Training Accuracy: 96.4015%, Training Loss: 0.1013%\n",
      "Epoch [59/300], Step [199/225], Training Accuracy: 96.4196%, Training Loss: 0.1012%\n",
      "Epoch [59/300], Step [200/225], Training Accuracy: 96.4297%, Training Loss: 0.1011%\n",
      "Epoch [59/300], Step [201/225], Training Accuracy: 96.4319%, Training Loss: 0.1011%\n",
      "Epoch [59/300], Step [202/225], Training Accuracy: 96.4418%, Training Loss: 0.1010%\n",
      "Epoch [59/300], Step [203/225], Training Accuracy: 96.4517%, Training Loss: 0.1008%\n",
      "Epoch [59/300], Step [204/225], Training Accuracy: 96.4461%, Training Loss: 0.1010%\n",
      "Epoch [59/300], Step [205/225], Training Accuracy: 96.4634%, Training Loss: 0.1008%\n",
      "Epoch [59/300], Step [206/225], Training Accuracy: 96.4730%, Training Loss: 0.1007%\n",
      "Epoch [59/300], Step [207/225], Training Accuracy: 96.4749%, Training Loss: 0.1007%\n",
      "Epoch [59/300], Step [208/225], Training Accuracy: 96.4543%, Training Loss: 0.1011%\n",
      "Epoch [59/300], Step [209/225], Training Accuracy: 96.4563%, Training Loss: 0.1011%\n",
      "Epoch [59/300], Step [210/225], Training Accuracy: 96.4658%, Training Loss: 0.1010%\n",
      "Epoch [59/300], Step [211/225], Training Accuracy: 96.4455%, Training Loss: 0.1013%\n",
      "Epoch [59/300], Step [212/225], Training Accuracy: 96.4549%, Training Loss: 0.1011%\n",
      "Epoch [59/300], Step [213/225], Training Accuracy: 96.4569%, Training Loss: 0.1012%\n",
      "Epoch [59/300], Step [214/225], Training Accuracy: 96.4515%, Training Loss: 0.1012%\n",
      "Epoch [59/300], Step [215/225], Training Accuracy: 96.4462%, Training Loss: 0.1012%\n",
      "Epoch [59/300], Step [216/225], Training Accuracy: 96.4337%, Training Loss: 0.1018%\n",
      "Epoch [59/300], Step [217/225], Training Accuracy: 96.4214%, Training Loss: 0.1018%\n",
      "Epoch [59/300], Step [218/225], Training Accuracy: 96.4235%, Training Loss: 0.1018%\n",
      "Epoch [59/300], Step [219/225], Training Accuracy: 96.4326%, Training Loss: 0.1016%\n",
      "Epoch [59/300], Step [220/225], Training Accuracy: 96.4418%, Training Loss: 0.1014%\n",
      "Epoch [59/300], Step [221/225], Training Accuracy: 96.4508%, Training Loss: 0.1013%\n",
      "Epoch [59/300], Step [222/225], Training Accuracy: 96.4527%, Training Loss: 0.1013%\n",
      "Epoch [59/300], Step [223/225], Training Accuracy: 96.4546%, Training Loss: 0.1011%\n",
      "Epoch [59/300], Step [224/225], Training Accuracy: 96.4704%, Training Loss: 0.1008%\n",
      "Epoch [59/300], Step [225/225], Training Accuracy: 96.4703%, Training Loss: 0.1009%\n",
      "Epoch [60/300], Step [1/225], Training Accuracy: 96.8750%, Training Loss: 0.0773%\n",
      "Epoch [60/300], Step [2/225], Training Accuracy: 97.6562%, Training Loss: 0.0782%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/300], Step [3/225], Training Accuracy: 96.8750%, Training Loss: 0.0766%\n",
      "Epoch [60/300], Step [4/225], Training Accuracy: 97.2656%, Training Loss: 0.0766%\n",
      "Epoch [60/300], Step [5/225], Training Accuracy: 97.1875%, Training Loss: 0.0770%\n",
      "Epoch [60/300], Step [6/225], Training Accuracy: 97.1354%, Training Loss: 0.0786%\n",
      "Epoch [60/300], Step [7/225], Training Accuracy: 96.4286%, Training Loss: 0.0907%\n",
      "Epoch [60/300], Step [8/225], Training Accuracy: 96.4844%, Training Loss: 0.0925%\n",
      "Epoch [60/300], Step [9/225], Training Accuracy: 96.0069%, Training Loss: 0.1073%\n",
      "Epoch [60/300], Step [10/225], Training Accuracy: 96.0938%, Training Loss: 0.1154%\n",
      "Epoch [60/300], Step [11/225], Training Accuracy: 96.0227%, Training Loss: 0.1150%\n",
      "Epoch [60/300], Step [12/225], Training Accuracy: 96.2240%, Training Loss: 0.1101%\n",
      "Epoch [60/300], Step [13/225], Training Accuracy: 96.3942%, Training Loss: 0.1064%\n",
      "Epoch [60/300], Step [14/225], Training Accuracy: 96.5402%, Training Loss: 0.1041%\n",
      "Epoch [60/300], Step [15/225], Training Accuracy: 96.5625%, Training Loss: 0.1031%\n",
      "Epoch [60/300], Step [16/225], Training Accuracy: 96.3867%, Training Loss: 0.1044%\n",
      "Epoch [60/300], Step [17/225], Training Accuracy: 96.3235%, Training Loss: 0.1077%\n",
      "Epoch [60/300], Step [18/225], Training Accuracy: 96.2674%, Training Loss: 0.1074%\n",
      "Epoch [60/300], Step [19/225], Training Accuracy: 96.2993%, Training Loss: 0.1059%\n",
      "Epoch [60/300], Step [20/225], Training Accuracy: 96.3281%, Training Loss: 0.1051%\n",
      "Epoch [60/300], Step [21/225], Training Accuracy: 96.5030%, Training Loss: 0.1031%\n",
      "Epoch [60/300], Step [22/225], Training Accuracy: 96.3778%, Training Loss: 0.1030%\n",
      "Epoch [60/300], Step [23/225], Training Accuracy: 96.2636%, Training Loss: 0.1033%\n",
      "Epoch [60/300], Step [24/225], Training Accuracy: 96.2891%, Training Loss: 0.1041%\n",
      "Epoch [60/300], Step [25/225], Training Accuracy: 96.1875%, Training Loss: 0.1060%\n",
      "Epoch [60/300], Step [26/225], Training Accuracy: 96.0938%, Training Loss: 0.1079%\n",
      "Epoch [60/300], Step [27/225], Training Accuracy: 96.0069%, Training Loss: 0.1113%\n",
      "Epoch [60/300], Step [28/225], Training Accuracy: 96.0379%, Training Loss: 0.1105%\n",
      "Epoch [60/300], Step [29/225], Training Accuracy: 96.1207%, Training Loss: 0.1093%\n",
      "Epoch [60/300], Step [30/225], Training Accuracy: 96.1979%, Training Loss: 0.1079%\n",
      "Epoch [60/300], Step [31/225], Training Accuracy: 96.2198%, Training Loss: 0.1083%\n",
      "Epoch [60/300], Step [32/225], Training Accuracy: 96.2891%, Training Loss: 0.1067%\n",
      "Epoch [60/300], Step [33/225], Training Accuracy: 96.3542%, Training Loss: 0.1055%\n",
      "Epoch [60/300], Step [34/225], Training Accuracy: 96.4154%, Training Loss: 0.1052%\n",
      "Epoch [60/300], Step [35/225], Training Accuracy: 96.4732%, Training Loss: 0.1042%\n",
      "Epoch [60/300], Step [36/225], Training Accuracy: 96.5712%, Training Loss: 0.1020%\n",
      "Epoch [60/300], Step [37/225], Training Accuracy: 96.4527%, Training Loss: 0.1054%\n",
      "Epoch [60/300], Step [38/225], Training Accuracy: 96.3405%, Training Loss: 0.1065%\n",
      "Epoch [60/300], Step [39/225], Training Accuracy: 96.3542%, Training Loss: 0.1060%\n",
      "Epoch [60/300], Step [40/225], Training Accuracy: 96.3281%, Training Loss: 0.1077%\n",
      "Epoch [60/300], Step [41/225], Training Accuracy: 96.3034%, Training Loss: 0.1083%\n",
      "Epoch [60/300], Step [42/225], Training Accuracy: 96.3914%, Training Loss: 0.1065%\n",
      "Epoch [60/300], Step [43/225], Training Accuracy: 96.4026%, Training Loss: 0.1056%\n",
      "Epoch [60/300], Step [44/225], Training Accuracy: 96.3423%, Training Loss: 0.1061%\n",
      "Epoch [60/300], Step [45/225], Training Accuracy: 96.3889%, Training Loss: 0.1052%\n",
      "Epoch [60/300], Step [46/225], Training Accuracy: 96.4334%, Training Loss: 0.1051%\n",
      "Epoch [60/300], Step [47/225], Training Accuracy: 96.4428%, Training Loss: 0.1051%\n",
      "Epoch [60/300], Step [48/225], Training Accuracy: 96.4193%, Training Loss: 0.1050%\n",
      "Epoch [60/300], Step [49/225], Training Accuracy: 96.3648%, Training Loss: 0.1061%\n",
      "Epoch [60/300], Step [50/225], Training Accuracy: 96.4062%, Training Loss: 0.1052%\n",
      "Epoch [60/300], Step [51/225], Training Accuracy: 96.3848%, Training Loss: 0.1051%\n",
      "Epoch [60/300], Step [52/225], Training Accuracy: 96.3942%, Training Loss: 0.1045%\n",
      "Epoch [60/300], Step [53/225], Training Accuracy: 96.3738%, Training Loss: 0.1048%\n",
      "Epoch [60/300], Step [54/225], Training Accuracy: 96.2963%, Training Loss: 0.1052%\n",
      "Epoch [60/300], Step [55/225], Training Accuracy: 96.3352%, Training Loss: 0.1051%\n",
      "Epoch [60/300], Step [56/225], Training Accuracy: 96.3728%, Training Loss: 0.1043%\n",
      "Epoch [60/300], Step [57/225], Training Accuracy: 96.3816%, Training Loss: 0.1042%\n",
      "Epoch [60/300], Step [58/225], Training Accuracy: 96.3631%, Training Loss: 0.1044%\n",
      "Epoch [60/300], Step [59/225], Training Accuracy: 96.3718%, Training Loss: 0.1054%\n",
      "Epoch [60/300], Step [60/225], Training Accuracy: 96.3542%, Training Loss: 0.1050%\n",
      "Epoch [60/300], Step [61/225], Training Accuracy: 96.2859%, Training Loss: 0.1063%\n",
      "Epoch [60/300], Step [62/225], Training Accuracy: 96.2954%, Training Loss: 0.1065%\n",
      "Epoch [60/300], Step [63/225], Training Accuracy: 96.3294%, Training Loss: 0.1066%\n",
      "Epoch [60/300], Step [64/225], Training Accuracy: 96.2891%, Training Loss: 0.1077%\n",
      "Epoch [60/300], Step [65/225], Training Accuracy: 96.2981%, Training Loss: 0.1074%\n",
      "Epoch [60/300], Step [66/225], Training Accuracy: 96.2358%, Training Loss: 0.1084%\n",
      "Epoch [60/300], Step [67/225], Training Accuracy: 96.2453%, Training Loss: 0.1082%\n",
      "Epoch [60/300], Step [68/225], Training Accuracy: 96.2776%, Training Loss: 0.1076%\n",
      "Epoch [60/300], Step [69/225], Training Accuracy: 96.3315%, Training Loss: 0.1066%\n",
      "Epoch [60/300], Step [70/225], Training Accuracy: 96.3393%, Training Loss: 0.1068%\n",
      "Epoch [60/300], Step [71/225], Training Accuracy: 96.3468%, Training Loss: 0.1063%\n",
      "Epoch [60/300], Step [72/225], Training Accuracy: 96.3542%, Training Loss: 0.1061%\n",
      "Epoch [60/300], Step [73/225], Training Accuracy: 96.3399%, Training Loss: 0.1069%\n",
      "Epoch [60/300], Step [74/225], Training Accuracy: 96.3260%, Training Loss: 0.1070%\n",
      "Epoch [60/300], Step [75/225], Training Accuracy: 96.3125%, Training Loss: 0.1067%\n",
      "Epoch [60/300], Step [76/225], Training Accuracy: 96.2582%, Training Loss: 0.1078%\n",
      "Epoch [60/300], Step [77/225], Training Accuracy: 96.2662%, Training Loss: 0.1075%\n",
      "Epoch [60/300], Step [78/225], Training Accuracy: 96.2340%, Training Loss: 0.1079%\n",
      "Epoch [60/300], Step [79/225], Training Accuracy: 96.2025%, Training Loss: 0.1091%\n",
      "Epoch [60/300], Step [80/225], Training Accuracy: 96.2109%, Training Loss: 0.1091%\n",
      "Epoch [60/300], Step [81/225], Training Accuracy: 96.2191%, Training Loss: 0.1087%\n",
      "Epoch [60/300], Step [82/225], Training Accuracy: 96.2271%, Training Loss: 0.1081%\n",
      "Epoch [60/300], Step [83/225], Training Accuracy: 96.1596%, Training Loss: 0.1100%\n",
      "Epoch [60/300], Step [84/225], Training Accuracy: 96.1496%, Training Loss: 0.1102%\n",
      "Epoch [60/300], Step [85/225], Training Accuracy: 96.1765%, Training Loss: 0.1098%\n",
      "Epoch [60/300], Step [86/225], Training Accuracy: 96.1846%, Training Loss: 0.1095%\n",
      "Epoch [60/300], Step [87/225], Training Accuracy: 96.1746%, Training Loss: 0.1098%\n",
      "Epoch [60/300], Step [88/225], Training Accuracy: 96.2180%, Training Loss: 0.1092%\n",
      "Epoch [60/300], Step [89/225], Training Accuracy: 96.1903%, Training Loss: 0.1098%\n",
      "Epoch [60/300], Step [90/225], Training Accuracy: 96.1806%, Training Loss: 0.1101%\n",
      "Epoch [60/300], Step [91/225], Training Accuracy: 96.2225%, Training Loss: 0.1096%\n",
      "Epoch [60/300], Step [92/225], Training Accuracy: 96.2296%, Training Loss: 0.1096%\n",
      "Epoch [60/300], Step [93/225], Training Accuracy: 96.2534%, Training Loss: 0.1090%\n",
      "Epoch [60/300], Step [94/225], Training Accuracy: 96.2434%, Training Loss: 0.1089%\n",
      "Epoch [60/300], Step [95/225], Training Accuracy: 96.2500%, Training Loss: 0.1087%\n",
      "Epoch [60/300], Step [96/225], Training Accuracy: 96.2891%, Training Loss: 0.1082%\n",
      "Epoch [60/300], Step [97/225], Training Accuracy: 96.2629%, Training Loss: 0.1084%\n",
      "Epoch [60/300], Step [98/225], Training Accuracy: 96.2851%, Training Loss: 0.1081%\n",
      "Epoch [60/300], Step [99/225], Training Accuracy: 96.2910%, Training Loss: 0.1077%\n",
      "Epoch [60/300], Step [100/225], Training Accuracy: 96.2969%, Training Loss: 0.1075%\n",
      "Epoch [60/300], Step [101/225], Training Accuracy: 96.3181%, Training Loss: 0.1071%\n",
      "Epoch [60/300], Step [102/225], Training Accuracy: 96.3235%, Training Loss: 0.1071%\n",
      "Epoch [60/300], Step [103/225], Training Accuracy: 96.2834%, Training Loss: 0.1076%\n",
      "Epoch [60/300], Step [104/225], Training Accuracy: 96.2891%, Training Loss: 0.1077%\n",
      "Epoch [60/300], Step [105/225], Training Accuracy: 96.3095%, Training Loss: 0.1076%\n",
      "Epoch [60/300], Step [106/225], Training Accuracy: 96.3443%, Training Loss: 0.1070%\n",
      "Epoch [60/300], Step [107/225], Training Accuracy: 96.3347%, Training Loss: 0.1071%\n",
      "Epoch [60/300], Step [108/225], Training Accuracy: 96.3397%, Training Loss: 0.1068%\n",
      "Epoch [60/300], Step [109/225], Training Accuracy: 96.3446%, Training Loss: 0.1066%\n",
      "Epoch [60/300], Step [110/225], Training Accuracy: 96.3778%, Training Loss: 0.1061%\n",
      "Epoch [60/300], Step [111/225], Training Accuracy: 96.3964%, Training Loss: 0.1058%\n",
      "Epoch [60/300], Step [112/225], Training Accuracy: 96.4007%, Training Loss: 0.1056%\n",
      "Epoch [60/300], Step [113/225], Training Accuracy: 96.3772%, Training Loss: 0.1055%\n",
      "Epoch [60/300], Step [114/225], Training Accuracy: 96.3816%, Training Loss: 0.1054%\n",
      "Epoch [60/300], Step [115/225], Training Accuracy: 96.3859%, Training Loss: 0.1053%\n",
      "Epoch [60/300], Step [116/225], Training Accuracy: 96.3766%, Training Loss: 0.1053%\n",
      "Epoch [60/300], Step [117/225], Training Accuracy: 96.3675%, Training Loss: 0.1052%\n",
      "Epoch [60/300], Step [118/225], Training Accuracy: 96.3586%, Training Loss: 0.1051%\n",
      "Epoch [60/300], Step [119/225], Training Accuracy: 96.3498%, Training Loss: 0.1052%\n",
      "Epoch [60/300], Step [120/225], Training Accuracy: 96.3542%, Training Loss: 0.1050%\n",
      "Epoch [60/300], Step [121/225], Training Accuracy: 96.3585%, Training Loss: 0.1047%\n",
      "Epoch [60/300], Step [122/225], Training Accuracy: 96.3755%, Training Loss: 0.1043%\n",
      "Epoch [60/300], Step [123/225], Training Accuracy: 96.3161%, Training Loss: 0.1060%\n",
      "Epoch [60/300], Step [124/225], Training Accuracy: 96.3206%, Training Loss: 0.1063%\n",
      "Epoch [60/300], Step [125/225], Training Accuracy: 96.3250%, Training Loss: 0.1064%\n",
      "Epoch [60/300], Step [126/225], Training Accuracy: 96.3418%, Training Loss: 0.1058%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/300], Step [127/225], Training Accuracy: 96.2968%, Training Loss: 0.1059%\n",
      "Epoch [60/300], Step [128/225], Training Accuracy: 96.2769%, Training Loss: 0.1062%\n",
      "Epoch [60/300], Step [129/225], Training Accuracy: 96.2936%, Training Loss: 0.1059%\n",
      "Epoch [60/300], Step [130/225], Training Accuracy: 96.2861%, Training Loss: 0.1058%\n",
      "Epoch [60/300], Step [131/225], Training Accuracy: 96.3144%, Training Loss: 0.1052%\n",
      "Epoch [60/300], Step [132/225], Training Accuracy: 96.2713%, Training Loss: 0.1058%\n",
      "Epoch [60/300], Step [133/225], Training Accuracy: 96.2641%, Training Loss: 0.1056%\n",
      "Epoch [60/300], Step [134/225], Training Accuracy: 96.2803%, Training Loss: 0.1054%\n",
      "Epoch [60/300], Step [135/225], Training Accuracy: 96.2847%, Training Loss: 0.1051%\n",
      "Epoch [60/300], Step [136/225], Training Accuracy: 96.2776%, Training Loss: 0.1055%\n",
      "Epoch [60/300], Step [137/225], Training Accuracy: 96.2705%, Training Loss: 0.1052%\n",
      "Epoch [60/300], Step [138/225], Training Accuracy: 96.2296%, Training Loss: 0.1057%\n",
      "Epoch [60/300], Step [139/225], Training Accuracy: 96.2230%, Training Loss: 0.1060%\n",
      "Epoch [60/300], Step [140/225], Training Accuracy: 96.2165%, Training Loss: 0.1059%\n",
      "Epoch [60/300], Step [141/225], Training Accuracy: 96.2212%, Training Loss: 0.1057%\n",
      "Epoch [60/300], Step [142/225], Training Accuracy: 96.2478%, Training Loss: 0.1055%\n",
      "Epoch [60/300], Step [143/225], Training Accuracy: 96.2303%, Training Loss: 0.1057%\n",
      "Epoch [60/300], Step [144/225], Training Accuracy: 96.2457%, Training Loss: 0.1055%\n",
      "Epoch [60/300], Step [145/225], Training Accuracy: 96.2392%, Training Loss: 0.1058%\n",
      "Epoch [60/300], Step [146/225], Training Accuracy: 96.2115%, Training Loss: 0.1059%\n",
      "Epoch [60/300], Step [147/225], Training Accuracy: 96.2054%, Training Loss: 0.1063%\n",
      "Epoch [60/300], Step [148/225], Training Accuracy: 96.2204%, Training Loss: 0.1062%\n",
      "Epoch [60/300], Step [149/225], Training Accuracy: 96.1934%, Training Loss: 0.1068%\n",
      "Epoch [60/300], Step [150/225], Training Accuracy: 96.2083%, Training Loss: 0.1065%\n",
      "Epoch [60/300], Step [151/225], Training Accuracy: 96.2024%, Training Loss: 0.1065%\n",
      "Epoch [60/300], Step [152/225], Training Accuracy: 96.1965%, Training Loss: 0.1065%\n",
      "Epoch [60/300], Step [153/225], Training Accuracy: 96.2010%, Training Loss: 0.1067%\n",
      "Epoch [60/300], Step [154/225], Training Accuracy: 96.2155%, Training Loss: 0.1065%\n",
      "Epoch [60/300], Step [155/225], Training Accuracy: 96.2298%, Training Loss: 0.1062%\n",
      "Epoch [60/300], Step [156/225], Training Accuracy: 96.2139%, Training Loss: 0.1065%\n",
      "Epoch [60/300], Step [157/225], Training Accuracy: 96.2182%, Training Loss: 0.1064%\n",
      "Epoch [60/300], Step [158/225], Training Accuracy: 96.2322%, Training Loss: 0.1059%\n",
      "Epoch [60/300], Step [159/225], Training Accuracy: 96.2362%, Training Loss: 0.1060%\n",
      "Epoch [60/300], Step [160/225], Training Accuracy: 96.2402%, Training Loss: 0.1058%\n",
      "Epoch [60/300], Step [161/225], Training Accuracy: 96.2539%, Training Loss: 0.1055%\n",
      "Epoch [60/300], Step [162/225], Training Accuracy: 96.2481%, Training Loss: 0.1055%\n",
      "Epoch [60/300], Step [163/225], Training Accuracy: 96.2232%, Training Loss: 0.1058%\n",
      "Epoch [60/300], Step [164/225], Training Accuracy: 96.2176%, Training Loss: 0.1057%\n",
      "Epoch [60/300], Step [165/225], Training Accuracy: 96.2216%, Training Loss: 0.1056%\n",
      "Epoch [60/300], Step [166/225], Training Accuracy: 96.2067%, Training Loss: 0.1057%\n",
      "Epoch [60/300], Step [167/225], Training Accuracy: 96.1920%, Training Loss: 0.1061%\n",
      "Epoch [60/300], Step [168/225], Training Accuracy: 96.1961%, Training Loss: 0.1059%\n",
      "Epoch [60/300], Step [169/225], Training Accuracy: 96.2001%, Training Loss: 0.1060%\n",
      "Epoch [60/300], Step [170/225], Training Accuracy: 96.2040%, Training Loss: 0.1061%\n",
      "Epoch [60/300], Step [171/225], Training Accuracy: 96.2171%, Training Loss: 0.1058%\n",
      "Epoch [60/300], Step [172/225], Training Accuracy: 96.2118%, Training Loss: 0.1059%\n",
      "Epoch [60/300], Step [173/225], Training Accuracy: 96.2247%, Training Loss: 0.1056%\n",
      "Epoch [60/300], Step [174/225], Training Accuracy: 96.2284%, Training Loss: 0.1057%\n",
      "Epoch [60/300], Step [175/225], Training Accuracy: 96.2411%, Training Loss: 0.1057%\n",
      "Epoch [60/300], Step [176/225], Training Accuracy: 96.2447%, Training Loss: 0.1059%\n",
      "Epoch [60/300], Step [177/225], Training Accuracy: 96.2571%, Training Loss: 0.1057%\n",
      "Epoch [60/300], Step [178/225], Training Accuracy: 96.2605%, Training Loss: 0.1055%\n",
      "Epoch [60/300], Step [179/225], Training Accuracy: 96.2640%, Training Loss: 0.1055%\n",
      "Epoch [60/300], Step [180/225], Training Accuracy: 96.2674%, Training Loss: 0.1053%\n",
      "Epoch [60/300], Step [181/225], Training Accuracy: 96.2621%, Training Loss: 0.1055%\n",
      "Epoch [60/300], Step [182/225], Training Accuracy: 96.2740%, Training Loss: 0.1051%\n",
      "Epoch [60/300], Step [183/225], Training Accuracy: 96.2773%, Training Loss: 0.1049%\n",
      "Epoch [60/300], Step [184/225], Training Accuracy: 96.2551%, Training Loss: 0.1053%\n",
      "Epoch [60/300], Step [185/225], Training Accuracy: 96.2500%, Training Loss: 0.1053%\n",
      "Epoch [60/300], Step [186/225], Training Accuracy: 96.2618%, Training Loss: 0.1052%\n",
      "Epoch [60/300], Step [187/225], Training Accuracy: 96.2316%, Training Loss: 0.1054%\n",
      "Epoch [60/300], Step [188/225], Training Accuracy: 96.2350%, Training Loss: 0.1054%\n",
      "Epoch [60/300], Step [189/225], Training Accuracy: 96.2384%, Training Loss: 0.1053%\n",
      "Epoch [60/300], Step [190/225], Training Accuracy: 96.2418%, Training Loss: 0.1052%\n",
      "Epoch [60/300], Step [191/225], Training Accuracy: 96.2533%, Training Loss: 0.1050%\n",
      "Epoch [60/300], Step [192/225], Training Accuracy: 96.2402%, Training Loss: 0.1050%\n",
      "Epoch [60/300], Step [193/225], Training Accuracy: 96.2516%, Training Loss: 0.1050%\n",
      "Epoch [60/300], Step [194/225], Training Accuracy: 96.2468%, Training Loss: 0.1052%\n",
      "Epoch [60/300], Step [195/225], Training Accuracy: 96.2099%, Training Loss: 0.1057%\n",
      "Epoch [60/300], Step [196/225], Training Accuracy: 96.2213%, Training Loss: 0.1055%\n",
      "Epoch [60/300], Step [197/225], Training Accuracy: 96.2246%, Training Loss: 0.1054%\n",
      "Epoch [60/300], Step [198/225], Training Accuracy: 96.2437%, Training Loss: 0.1051%\n",
      "Epoch [60/300], Step [199/225], Training Accuracy: 96.2626%, Training Loss: 0.1049%\n",
      "Epoch [60/300], Step [200/225], Training Accuracy: 96.2656%, Training Loss: 0.1047%\n",
      "Epoch [60/300], Step [201/225], Training Accuracy: 96.2531%, Training Loss: 0.1051%\n",
      "Epoch [60/300], Step [202/225], Training Accuracy: 96.2562%, Training Loss: 0.1050%\n",
      "Epoch [60/300], Step [203/225], Training Accuracy: 96.2515%, Training Loss: 0.1050%\n",
      "Epoch [60/300], Step [204/225], Training Accuracy: 96.2623%, Training Loss: 0.1048%\n",
      "Epoch [60/300], Step [205/225], Training Accuracy: 96.2729%, Training Loss: 0.1046%\n",
      "Epoch [60/300], Step [206/225], Training Accuracy: 96.2454%, Training Loss: 0.1050%\n",
      "Epoch [60/300], Step [207/225], Training Accuracy: 96.2560%, Training Loss: 0.1048%\n",
      "Epoch [60/300], Step [208/225], Training Accuracy: 96.2515%, Training Loss: 0.1048%\n",
      "Epoch [60/300], Step [209/225], Training Accuracy: 96.2694%, Training Loss: 0.1044%\n",
      "Epoch [60/300], Step [210/225], Training Accuracy: 96.2574%, Training Loss: 0.1047%\n",
      "Epoch [60/300], Step [211/225], Training Accuracy: 96.2752%, Training Loss: 0.1044%\n",
      "Epoch [60/300], Step [212/225], Training Accuracy: 96.2633%, Training Loss: 0.1045%\n",
      "Epoch [60/300], Step [213/225], Training Accuracy: 96.2808%, Training Loss: 0.1043%\n",
      "Epoch [60/300], Step [214/225], Training Accuracy: 96.2836%, Training Loss: 0.1043%\n",
      "Epoch [60/300], Step [215/225], Training Accuracy: 96.2791%, Training Loss: 0.1047%\n",
      "Epoch [60/300], Step [216/225], Training Accuracy: 96.2891%, Training Loss: 0.1045%\n",
      "Epoch [60/300], Step [217/225], Training Accuracy: 96.2846%, Training Loss: 0.1045%\n",
      "Epoch [60/300], Step [218/225], Training Accuracy: 96.2944%, Training Loss: 0.1043%\n",
      "Epoch [60/300], Step [219/225], Training Accuracy: 96.3042%, Training Loss: 0.1042%\n",
      "Epoch [60/300], Step [220/225], Training Accuracy: 96.3068%, Training Loss: 0.1040%\n",
      "Epoch [60/300], Step [221/225], Training Accuracy: 96.3235%, Training Loss: 0.1038%\n",
      "Epoch [60/300], Step [222/225], Training Accuracy: 96.3049%, Training Loss: 0.1043%\n",
      "Epoch [60/300], Step [223/225], Training Accuracy: 96.2934%, Training Loss: 0.1044%\n",
      "Epoch [60/300], Step [224/225], Training Accuracy: 96.3100%, Training Loss: 0.1041%\n",
      "Epoch [60/300], Step [225/225], Training Accuracy: 96.3105%, Training Loss: 0.1040%\n",
      "Epoch [61/300], Step [1/225], Training Accuracy: 95.3125%, Training Loss: 0.1108%\n",
      "Epoch [61/300], Step [2/225], Training Accuracy: 94.5312%, Training Loss: 0.1584%\n",
      "Epoch [61/300], Step [3/225], Training Accuracy: 94.2708%, Training Loss: 0.1497%\n",
      "Epoch [61/300], Step [4/225], Training Accuracy: 94.5312%, Training Loss: 0.1411%\n",
      "Epoch [61/300], Step [5/225], Training Accuracy: 95.3125%, Training Loss: 0.1225%\n",
      "Epoch [61/300], Step [6/225], Training Accuracy: 95.5729%, Training Loss: 0.1205%\n",
      "Epoch [61/300], Step [7/225], Training Accuracy: 95.5357%, Training Loss: 0.1195%\n",
      "Epoch [61/300], Step [8/225], Training Accuracy: 95.5078%, Training Loss: 0.1166%\n",
      "Epoch [61/300], Step [9/225], Training Accuracy: 95.6597%, Training Loss: 0.1129%\n",
      "Epoch [61/300], Step [10/225], Training Accuracy: 95.6250%, Training Loss: 0.1111%\n",
      "Epoch [61/300], Step [11/225], Training Accuracy: 95.8807%, Training Loss: 0.1054%\n",
      "Epoch [61/300], Step [12/225], Training Accuracy: 95.9635%, Training Loss: 0.1053%\n",
      "Epoch [61/300], Step [13/225], Training Accuracy: 96.2740%, Training Loss: 0.1002%\n",
      "Epoch [61/300], Step [14/225], Training Accuracy: 96.2054%, Training Loss: 0.1027%\n",
      "Epoch [61/300], Step [15/225], Training Accuracy: 96.4583%, Training Loss: 0.0990%\n",
      "Epoch [61/300], Step [16/225], Training Accuracy: 96.5820%, Training Loss: 0.0978%\n",
      "Epoch [61/300], Step [17/225], Training Accuracy: 96.6912%, Training Loss: 0.0963%\n",
      "Epoch [61/300], Step [18/225], Training Accuracy: 96.7014%, Training Loss: 0.0970%\n",
      "Epoch [61/300], Step [19/225], Training Accuracy: 96.7105%, Training Loss: 0.0968%\n",
      "Epoch [61/300], Step [20/225], Training Accuracy: 96.7188%, Training Loss: 0.0987%\n",
      "Epoch [61/300], Step [21/225], Training Accuracy: 96.8006%, Training Loss: 0.0969%\n",
      "Epoch [61/300], Step [22/225], Training Accuracy: 96.6619%, Training Loss: 0.0981%\n",
      "Epoch [61/300], Step [23/225], Training Accuracy: 96.6033%, Training Loss: 0.0980%\n",
      "Epoch [61/300], Step [24/225], Training Accuracy: 96.4844%, Training Loss: 0.0995%\n",
      "Epoch [61/300], Step [25/225], Training Accuracy: 96.5000%, Training Loss: 0.0983%\n",
      "Epoch [61/300], Step [26/225], Training Accuracy: 96.5144%, Training Loss: 0.0980%\n",
      "Epoch [61/300], Step [27/225], Training Accuracy: 96.4699%, Training Loss: 0.0976%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/300], Step [28/225], Training Accuracy: 96.4844%, Training Loss: 0.0972%\n",
      "Epoch [61/300], Step [29/225], Training Accuracy: 96.6056%, Training Loss: 0.0952%\n",
      "Epoch [61/300], Step [30/225], Training Accuracy: 96.2500%, Training Loss: 0.1017%\n",
      "Epoch [61/300], Step [31/225], Training Accuracy: 96.2198%, Training Loss: 0.1029%\n",
      "Epoch [61/300], Step [32/225], Training Accuracy: 96.2891%, Training Loss: 0.1024%\n",
      "Epoch [61/300], Step [33/225], Training Accuracy: 96.3542%, Training Loss: 0.1007%\n",
      "Epoch [61/300], Step [34/225], Training Accuracy: 96.3235%, Training Loss: 0.1012%\n",
      "Epoch [61/300], Step [35/225], Training Accuracy: 96.2946%, Training Loss: 0.1029%\n",
      "Epoch [61/300], Step [36/225], Training Accuracy: 96.3108%, Training Loss: 0.1026%\n",
      "Epoch [61/300], Step [37/225], Training Accuracy: 96.2416%, Training Loss: 0.1037%\n",
      "Epoch [61/300], Step [38/225], Training Accuracy: 96.2171%, Training Loss: 0.1052%\n",
      "Epoch [61/300], Step [39/225], Training Accuracy: 96.1939%, Training Loss: 0.1064%\n",
      "Epoch [61/300], Step [40/225], Training Accuracy: 96.2891%, Training Loss: 0.1048%\n",
      "Epoch [61/300], Step [41/225], Training Accuracy: 96.2271%, Training Loss: 0.1069%\n",
      "Epoch [61/300], Step [42/225], Training Accuracy: 96.3170%, Training Loss: 0.1052%\n",
      "Epoch [61/300], Step [43/225], Training Accuracy: 96.4026%, Training Loss: 0.1043%\n",
      "Epoch [61/300], Step [44/225], Training Accuracy: 96.4489%, Training Loss: 0.1033%\n",
      "Epoch [61/300], Step [45/225], Training Accuracy: 96.4931%, Training Loss: 0.1022%\n",
      "Epoch [61/300], Step [46/225], Training Accuracy: 96.5353%, Training Loss: 0.1012%\n",
      "Epoch [61/300], Step [47/225], Training Accuracy: 96.4761%, Training Loss: 0.1023%\n",
      "Epoch [61/300], Step [48/225], Training Accuracy: 96.5169%, Training Loss: 0.1016%\n",
      "Epoch [61/300], Step [49/225], Training Accuracy: 96.5561%, Training Loss: 0.1013%\n",
      "Epoch [61/300], Step [50/225], Training Accuracy: 96.5000%, Training Loss: 0.1014%\n",
      "Epoch [61/300], Step [51/225], Training Accuracy: 96.5074%, Training Loss: 0.1005%\n",
      "Epoch [61/300], Step [52/225], Training Accuracy: 96.5144%, Training Loss: 0.1003%\n",
      "Epoch [61/300], Step [53/225], Training Accuracy: 96.4328%, Training Loss: 0.1017%\n",
      "Epoch [61/300], Step [54/225], Training Accuracy: 96.3831%, Training Loss: 0.1027%\n",
      "Epoch [61/300], Step [55/225], Training Accuracy: 96.2500%, Training Loss: 0.1050%\n",
      "Epoch [61/300], Step [56/225], Training Accuracy: 96.2054%, Training Loss: 0.1052%\n",
      "Epoch [61/300], Step [57/225], Training Accuracy: 96.2171%, Training Loss: 0.1061%\n",
      "Epoch [61/300], Step [58/225], Training Accuracy: 96.2284%, Training Loss: 0.1061%\n",
      "Epoch [61/300], Step [59/225], Training Accuracy: 96.1600%, Training Loss: 0.1078%\n",
      "Epoch [61/300], Step [60/225], Training Accuracy: 96.0938%, Training Loss: 0.1084%\n",
      "Epoch [61/300], Step [61/225], Training Accuracy: 96.0553%, Training Loss: 0.1095%\n",
      "Epoch [61/300], Step [62/225], Training Accuracy: 96.0433%, Training Loss: 0.1093%\n",
      "Epoch [61/300], Step [63/225], Training Accuracy: 96.0317%, Training Loss: 0.1097%\n",
      "Epoch [61/300], Step [64/225], Training Accuracy: 96.0449%, Training Loss: 0.1093%\n",
      "Epoch [61/300], Step [65/225], Training Accuracy: 96.0096%, Training Loss: 0.1096%\n",
      "Epoch [61/300], Step [66/225], Training Accuracy: 95.9754%, Training Loss: 0.1100%\n",
      "Epoch [61/300], Step [67/225], Training Accuracy: 96.0121%, Training Loss: 0.1098%\n",
      "Epoch [61/300], Step [68/225], Training Accuracy: 96.0248%, Training Loss: 0.1095%\n",
      "Epoch [61/300], Step [69/225], Training Accuracy: 96.0598%, Training Loss: 0.1090%\n",
      "Epoch [61/300], Step [70/225], Training Accuracy: 96.0491%, Training Loss: 0.1090%\n",
      "Epoch [61/300], Step [71/225], Training Accuracy: 96.0167%, Training Loss: 0.1094%\n",
      "Epoch [61/300], Step [72/225], Training Accuracy: 96.0286%, Training Loss: 0.1089%\n",
      "Epoch [61/300], Step [73/225], Training Accuracy: 96.0402%, Training Loss: 0.1087%\n",
      "Epoch [61/300], Step [74/225], Training Accuracy: 96.0726%, Training Loss: 0.1085%\n",
      "Epoch [61/300], Step [75/225], Training Accuracy: 96.0417%, Training Loss: 0.1087%\n",
      "Epoch [61/300], Step [76/225], Training Accuracy: 96.0526%, Training Loss: 0.1085%\n",
      "Epoch [61/300], Step [77/225], Training Accuracy: 96.0430%, Training Loss: 0.1086%\n",
      "Epoch [61/300], Step [78/225], Training Accuracy: 96.0938%, Training Loss: 0.1079%\n",
      "Epoch [61/300], Step [79/225], Training Accuracy: 96.1036%, Training Loss: 0.1079%\n",
      "Epoch [61/300], Step [80/225], Training Accuracy: 96.1133%, Training Loss: 0.1079%\n",
      "Epoch [61/300], Step [81/225], Training Accuracy: 96.1227%, Training Loss: 0.1077%\n",
      "Epoch [61/300], Step [82/225], Training Accuracy: 96.1319%, Training Loss: 0.1071%\n",
      "Epoch [61/300], Step [83/225], Training Accuracy: 96.0467%, Training Loss: 0.1085%\n",
      "Epoch [61/300], Step [84/225], Training Accuracy: 96.0565%, Training Loss: 0.1084%\n",
      "Epoch [61/300], Step [85/225], Training Accuracy: 96.0294%, Training Loss: 0.1087%\n",
      "Epoch [61/300], Step [86/225], Training Accuracy: 96.0392%, Training Loss: 0.1087%\n",
      "Epoch [61/300], Step [87/225], Training Accuracy: 96.0489%, Training Loss: 0.1085%\n",
      "Epoch [61/300], Step [88/225], Training Accuracy: 96.0405%, Training Loss: 0.1085%\n",
      "Epoch [61/300], Step [89/225], Training Accuracy: 96.0674%, Training Loss: 0.1080%\n",
      "Epoch [61/300], Step [90/225], Training Accuracy: 96.0590%, Training Loss: 0.1079%\n",
      "Epoch [61/300], Step [91/225], Training Accuracy: 96.0508%, Training Loss: 0.1076%\n",
      "Epoch [61/300], Step [92/225], Training Accuracy: 96.0768%, Training Loss: 0.1069%\n",
      "Epoch [61/300], Step [93/225], Training Accuracy: 96.0685%, Training Loss: 0.1069%\n",
      "Epoch [61/300], Step [94/225], Training Accuracy: 96.0938%, Training Loss: 0.1064%\n",
      "Epoch [61/300], Step [95/225], Training Accuracy: 96.1349%, Training Loss: 0.1058%\n",
      "Epoch [61/300], Step [96/225], Training Accuracy: 96.1589%, Training Loss: 0.1054%\n",
      "Epoch [61/300], Step [97/225], Training Accuracy: 96.1662%, Training Loss: 0.1049%\n",
      "Epoch [61/300], Step [98/225], Training Accuracy: 96.1575%, Training Loss: 0.1054%\n",
      "Epoch [61/300], Step [99/225], Training Accuracy: 96.1490%, Training Loss: 0.1055%\n",
      "Epoch [61/300], Step [100/225], Training Accuracy: 96.1250%, Training Loss: 0.1055%\n",
      "Epoch [61/300], Step [101/225], Training Accuracy: 96.1479%, Training Loss: 0.1054%\n",
      "Epoch [61/300], Step [102/225], Training Accuracy: 96.1397%, Training Loss: 0.1059%\n",
      "Epoch [61/300], Step [103/225], Training Accuracy: 96.1620%, Training Loss: 0.1054%\n",
      "Epoch [61/300], Step [104/225], Training Accuracy: 96.1538%, Training Loss: 0.1053%\n",
      "Epoch [61/300], Step [105/225], Training Accuracy: 96.1905%, Training Loss: 0.1048%\n",
      "Epoch [61/300], Step [106/225], Training Accuracy: 96.1969%, Training Loss: 0.1045%\n",
      "Epoch [61/300], Step [107/225], Training Accuracy: 96.2179%, Training Loss: 0.1040%\n",
      "Epoch [61/300], Step [108/225], Training Accuracy: 96.2240%, Training Loss: 0.1038%\n",
      "Epoch [61/300], Step [109/225], Training Accuracy: 96.2443%, Training Loss: 0.1036%\n",
      "Epoch [61/300], Step [110/225], Training Accuracy: 96.2500%, Training Loss: 0.1035%\n",
      "Epoch [61/300], Step [111/225], Training Accuracy: 96.2556%, Training Loss: 0.1032%\n",
      "Epoch [61/300], Step [112/225], Training Accuracy: 96.2612%, Training Loss: 0.1027%\n",
      "Epoch [61/300], Step [113/225], Training Accuracy: 96.2804%, Training Loss: 0.1025%\n",
      "Epoch [61/300], Step [114/225], Training Accuracy: 96.2993%, Training Loss: 0.1021%\n",
      "Epoch [61/300], Step [115/225], Training Accuracy: 96.3043%, Training Loss: 0.1020%\n",
      "Epoch [61/300], Step [116/225], Training Accuracy: 96.2958%, Training Loss: 0.1020%\n",
      "Epoch [61/300], Step [117/225], Training Accuracy: 96.3141%, Training Loss: 0.1015%\n",
      "Epoch [61/300], Step [118/225], Training Accuracy: 96.3189%, Training Loss: 0.1016%\n",
      "Epoch [61/300], Step [119/225], Training Accuracy: 96.3235%, Training Loss: 0.1015%\n",
      "Epoch [61/300], Step [120/225], Training Accuracy: 96.3542%, Training Loss: 0.1008%\n",
      "Epoch [61/300], Step [121/225], Training Accuracy: 96.3843%, Training Loss: 0.1003%\n",
      "Epoch [61/300], Step [122/225], Training Accuracy: 96.4139%, Training Loss: 0.0998%\n",
      "Epoch [61/300], Step [123/225], Training Accuracy: 96.4304%, Training Loss: 0.0996%\n",
      "Epoch [61/300], Step [124/225], Training Accuracy: 96.4340%, Training Loss: 0.0998%\n",
      "Epoch [61/300], Step [125/225], Training Accuracy: 96.4625%, Training Loss: 0.0992%\n",
      "Epoch [61/300], Step [126/225], Training Accuracy: 96.4782%, Training Loss: 0.0992%\n",
      "Epoch [61/300], Step [127/225], Training Accuracy: 96.4936%, Training Loss: 0.0990%\n",
      "Epoch [61/300], Step [128/225], Training Accuracy: 96.4966%, Training Loss: 0.0989%\n",
      "Epoch [61/300], Step [129/225], Training Accuracy: 96.4995%, Training Loss: 0.0990%\n",
      "Epoch [61/300], Step [130/225], Training Accuracy: 96.4904%, Training Loss: 0.0989%\n",
      "Epoch [61/300], Step [131/225], Training Accuracy: 96.4933%, Training Loss: 0.0986%\n",
      "Epoch [61/300], Step [132/225], Training Accuracy: 96.5080%, Training Loss: 0.0984%\n",
      "Epoch [61/300], Step [133/225], Training Accuracy: 96.5226%, Training Loss: 0.0981%\n",
      "Epoch [61/300], Step [134/225], Training Accuracy: 96.5485%, Training Loss: 0.0978%\n",
      "Epoch [61/300], Step [135/225], Training Accuracy: 96.5509%, Training Loss: 0.0976%\n",
      "Epoch [61/300], Step [136/225], Training Accuracy: 96.5533%, Training Loss: 0.0980%\n",
      "Epoch [61/300], Step [137/225], Training Accuracy: 96.5671%, Training Loss: 0.0977%\n",
      "Epoch [61/300], Step [138/225], Training Accuracy: 96.5580%, Training Loss: 0.0978%\n",
      "Epoch [61/300], Step [139/225], Training Accuracy: 96.5490%, Training Loss: 0.0981%\n",
      "Epoch [61/300], Step [140/225], Training Accuracy: 96.5402%, Training Loss: 0.0981%\n",
      "Epoch [61/300], Step [141/225], Training Accuracy: 96.5204%, Training Loss: 0.0984%\n",
      "Epoch [61/300], Step [142/225], Training Accuracy: 96.5339%, Training Loss: 0.0980%\n",
      "Epoch [61/300], Step [143/225], Training Accuracy: 96.5363%, Training Loss: 0.0982%\n",
      "Epoch [61/300], Step [144/225], Training Accuracy: 96.5061%, Training Loss: 0.0987%\n",
      "Epoch [61/300], Step [145/225], Training Accuracy: 96.5302%, Training Loss: 0.0984%\n",
      "Epoch [61/300], Step [146/225], Training Accuracy: 96.5539%, Training Loss: 0.0979%\n",
      "Epoch [61/300], Step [147/225], Training Accuracy: 96.5774%, Training Loss: 0.0976%\n",
      "Epoch [61/300], Step [148/225], Training Accuracy: 96.6005%, Training Loss: 0.0972%\n",
      "Epoch [61/300], Step [149/225], Training Accuracy: 96.6023%, Training Loss: 0.0972%\n",
      "Epoch [61/300], Step [150/225], Training Accuracy: 96.6042%, Training Loss: 0.0972%\n",
      "Epoch [61/300], Step [151/225], Training Accuracy: 96.6267%, Training Loss: 0.0968%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/300], Step [152/225], Training Accuracy: 96.6386%, Training Loss: 0.0967%\n",
      "Epoch [61/300], Step [153/225], Training Accuracy: 96.6401%, Training Loss: 0.0966%\n",
      "Epoch [61/300], Step [154/225], Training Accuracy: 96.6315%, Training Loss: 0.0968%\n",
      "Epoch [61/300], Step [155/225], Training Accuracy: 96.6431%, Training Loss: 0.0968%\n",
      "Epoch [61/300], Step [156/225], Training Accuracy: 96.6446%, Training Loss: 0.0968%\n",
      "Epoch [61/300], Step [157/225], Training Accuracy: 96.6361%, Training Loss: 0.0969%\n",
      "Epoch [61/300], Step [158/225], Training Accuracy: 96.6475%, Training Loss: 0.0966%\n",
      "Epoch [61/300], Step [159/225], Training Accuracy: 96.6293%, Training Loss: 0.0973%\n",
      "Epoch [61/300], Step [160/225], Training Accuracy: 96.6406%, Training Loss: 0.0973%\n",
      "Epoch [61/300], Step [161/225], Training Accuracy: 96.6421%, Training Loss: 0.0972%\n",
      "Epoch [61/300], Step [162/225], Training Accuracy: 96.6339%, Training Loss: 0.0972%\n",
      "Epoch [61/300], Step [163/225], Training Accuracy: 96.6545%, Training Loss: 0.0970%\n",
      "Epoch [61/300], Step [164/225], Training Accuracy: 96.6654%, Training Loss: 0.0968%\n",
      "Epoch [61/300], Step [165/225], Training Accuracy: 96.6572%, Training Loss: 0.0969%\n",
      "Epoch [61/300], Step [166/225], Training Accuracy: 96.6397%, Training Loss: 0.0971%\n",
      "Epoch [61/300], Step [167/225], Training Accuracy: 96.6411%, Training Loss: 0.0969%\n",
      "Epoch [61/300], Step [168/225], Training Accuracy: 96.6332%, Training Loss: 0.0970%\n",
      "Epoch [61/300], Step [169/225], Training Accuracy: 96.5976%, Training Loss: 0.0973%\n",
      "Epoch [61/300], Step [170/225], Training Accuracy: 96.5993%, Training Loss: 0.0974%\n",
      "Epoch [61/300], Step [171/225], Training Accuracy: 96.6009%, Training Loss: 0.0972%\n",
      "Epoch [61/300], Step [172/225], Training Accuracy: 96.5752%, Training Loss: 0.0977%\n",
      "Epoch [61/300], Step [173/225], Training Accuracy: 96.5860%, Training Loss: 0.0975%\n",
      "Epoch [61/300], Step [174/225], Training Accuracy: 96.5966%, Training Loss: 0.0973%\n",
      "Epoch [61/300], Step [175/225], Training Accuracy: 96.6071%, Training Loss: 0.0973%\n",
      "Epoch [61/300], Step [176/225], Training Accuracy: 96.6175%, Training Loss: 0.0970%\n",
      "Epoch [61/300], Step [177/225], Training Accuracy: 96.6190%, Training Loss: 0.0968%\n",
      "Epoch [61/300], Step [178/225], Training Accuracy: 96.5941%, Training Loss: 0.0972%\n",
      "Epoch [61/300], Step [179/225], Training Accuracy: 96.5957%, Training Loss: 0.0971%\n",
      "Epoch [61/300], Step [180/225], Training Accuracy: 96.5972%, Training Loss: 0.0972%\n",
      "Epoch [61/300], Step [181/225], Training Accuracy: 96.5729%, Training Loss: 0.0975%\n",
      "Epoch [61/300], Step [182/225], Training Accuracy: 96.5831%, Training Loss: 0.0973%\n",
      "Epoch [61/300], Step [183/225], Training Accuracy: 96.5932%, Training Loss: 0.0970%\n",
      "Epoch [61/300], Step [184/225], Training Accuracy: 96.6033%, Training Loss: 0.0969%\n",
      "Epoch [61/300], Step [185/225], Training Accuracy: 96.6132%, Training Loss: 0.0968%\n",
      "Epoch [61/300], Step [186/225], Training Accuracy: 96.6230%, Training Loss: 0.0966%\n",
      "Epoch [61/300], Step [187/225], Training Accuracy: 96.6327%, Training Loss: 0.0965%\n",
      "Epoch [61/300], Step [188/225], Training Accuracy: 96.6257%, Training Loss: 0.0970%\n",
      "Epoch [61/300], Step [189/225], Training Accuracy: 96.6353%, Training Loss: 0.0968%\n",
      "Epoch [61/300], Step [190/225], Training Accuracy: 96.6447%, Training Loss: 0.0966%\n",
      "Epoch [61/300], Step [191/225], Training Accuracy: 96.6541%, Training Loss: 0.0965%\n",
      "Epoch [61/300], Step [192/225], Training Accuracy: 96.6634%, Training Loss: 0.0963%\n",
      "Epoch [61/300], Step [193/225], Training Accuracy: 96.6564%, Training Loss: 0.0964%\n",
      "Epoch [61/300], Step [194/225], Training Accuracy: 96.6575%, Training Loss: 0.0966%\n",
      "Epoch [61/300], Step [195/225], Training Accuracy: 96.6587%, Training Loss: 0.0966%\n",
      "Epoch [61/300], Step [196/225], Training Accuracy: 96.6677%, Training Loss: 0.0963%\n",
      "Epoch [61/300], Step [197/225], Training Accuracy: 96.6609%, Training Loss: 0.0965%\n",
      "Epoch [61/300], Step [198/225], Training Accuracy: 96.6698%, Training Loss: 0.0965%\n",
      "Epoch [61/300], Step [199/225], Training Accuracy: 96.6709%, Training Loss: 0.0968%\n",
      "Epoch [61/300], Step [200/225], Training Accuracy: 96.6797%, Training Loss: 0.0966%\n",
      "Epoch [61/300], Step [201/225], Training Accuracy: 96.6729%, Training Loss: 0.0966%\n",
      "Epoch [61/300], Step [202/225], Training Accuracy: 96.6429%, Training Loss: 0.0970%\n",
      "Epoch [61/300], Step [203/225], Training Accuracy: 96.6441%, Training Loss: 0.0971%\n",
      "Epoch [61/300], Step [204/225], Training Accuracy: 96.6529%, Training Loss: 0.0971%\n",
      "Epoch [61/300], Step [205/225], Training Accuracy: 96.6616%, Training Loss: 0.0970%\n",
      "Epoch [61/300], Step [206/225], Training Accuracy: 96.6626%, Training Loss: 0.0969%\n",
      "Epoch [61/300], Step [207/225], Training Accuracy: 96.6712%, Training Loss: 0.0968%\n",
      "Epoch [61/300], Step [208/225], Training Accuracy: 96.6797%, Training Loss: 0.0967%\n",
      "Epoch [61/300], Step [209/225], Training Accuracy: 96.6881%, Training Loss: 0.0966%\n",
      "Epoch [61/300], Step [210/225], Training Accuracy: 96.6890%, Training Loss: 0.0966%\n",
      "Epoch [61/300], Step [211/225], Training Accuracy: 96.7047%, Training Loss: 0.0965%\n",
      "Epoch [61/300], Step [212/225], Training Accuracy: 96.7055%, Training Loss: 0.0968%\n",
      "Epoch [61/300], Step [213/225], Training Accuracy: 96.6916%, Training Loss: 0.0969%\n",
      "Epoch [61/300], Step [214/225], Training Accuracy: 96.6998%, Training Loss: 0.0967%\n",
      "Epoch [61/300], Step [215/225], Training Accuracy: 96.7078%, Training Loss: 0.0965%\n",
      "Epoch [61/300], Step [216/225], Training Accuracy: 96.6869%, Training Loss: 0.0969%\n",
      "Epoch [61/300], Step [217/225], Training Accuracy: 96.7022%, Training Loss: 0.0967%\n",
      "Epoch [61/300], Step [218/225], Training Accuracy: 96.7173%, Training Loss: 0.0964%\n",
      "Epoch [61/300], Step [219/225], Training Accuracy: 96.7252%, Training Loss: 0.0961%\n",
      "Epoch [61/300], Step [220/225], Training Accuracy: 96.7330%, Training Loss: 0.0960%\n",
      "Epoch [61/300], Step [221/225], Training Accuracy: 96.7265%, Training Loss: 0.0962%\n",
      "Epoch [61/300], Step [222/225], Training Accuracy: 96.7202%, Training Loss: 0.0962%\n",
      "Epoch [61/300], Step [223/225], Training Accuracy: 96.7349%, Training Loss: 0.0959%\n",
      "Epoch [61/300], Step [224/225], Training Accuracy: 96.7425%, Training Loss: 0.0956%\n",
      "Epoch [61/300], Step [225/225], Training Accuracy: 96.7412%, Training Loss: 0.0955%\n",
      "Epoch [62/300], Step [1/225], Training Accuracy: 95.3125%, Training Loss: 0.0908%\n",
      "Epoch [62/300], Step [2/225], Training Accuracy: 94.5312%, Training Loss: 0.1503%\n",
      "Epoch [62/300], Step [3/225], Training Accuracy: 95.8333%, Training Loss: 0.1210%\n",
      "Epoch [62/300], Step [4/225], Training Accuracy: 96.4844%, Training Loss: 0.1042%\n",
      "Epoch [62/300], Step [5/225], Training Accuracy: 95.9375%, Training Loss: 0.1072%\n",
      "Epoch [62/300], Step [6/225], Training Accuracy: 96.3542%, Training Loss: 0.1006%\n",
      "Epoch [62/300], Step [7/225], Training Accuracy: 96.8750%, Training Loss: 0.0952%\n",
      "Epoch [62/300], Step [8/225], Training Accuracy: 97.0703%, Training Loss: 0.0912%\n",
      "Epoch [62/300], Step [9/225], Training Accuracy: 97.2222%, Training Loss: 0.0875%\n",
      "Epoch [62/300], Step [10/225], Training Accuracy: 97.0312%, Training Loss: 0.0887%\n",
      "Epoch [62/300], Step [11/225], Training Accuracy: 97.1591%, Training Loss: 0.0901%\n",
      "Epoch [62/300], Step [12/225], Training Accuracy: 97.2656%, Training Loss: 0.0843%\n",
      "Epoch [62/300], Step [13/225], Training Accuracy: 97.2356%, Training Loss: 0.0866%\n",
      "Epoch [62/300], Step [14/225], Training Accuracy: 96.9866%, Training Loss: 0.0912%\n",
      "Epoch [62/300], Step [15/225], Training Accuracy: 97.1875%, Training Loss: 0.0873%\n",
      "Epoch [62/300], Step [16/225], Training Accuracy: 97.2656%, Training Loss: 0.0856%\n",
      "Epoch [62/300], Step [17/225], Training Accuracy: 97.3346%, Training Loss: 0.0846%\n",
      "Epoch [62/300], Step [18/225], Training Accuracy: 97.1354%, Training Loss: 0.0870%\n",
      "Epoch [62/300], Step [19/225], Training Accuracy: 97.2862%, Training Loss: 0.0843%\n",
      "Epoch [62/300], Step [20/225], Training Accuracy: 97.3438%, Training Loss: 0.0840%\n",
      "Epoch [62/300], Step [21/225], Training Accuracy: 97.2470%, Training Loss: 0.0841%\n",
      "Epoch [62/300], Step [22/225], Training Accuracy: 97.1591%, Training Loss: 0.0850%\n",
      "Epoch [62/300], Step [23/225], Training Accuracy: 97.2147%, Training Loss: 0.0854%\n",
      "Epoch [62/300], Step [24/225], Training Accuracy: 97.0703%, Training Loss: 0.0860%\n",
      "Epoch [62/300], Step [25/225], Training Accuracy: 97.0625%, Training Loss: 0.0862%\n",
      "Epoch [62/300], Step [26/225], Training Accuracy: 96.9952%, Training Loss: 0.0867%\n",
      "Epoch [62/300], Step [27/225], Training Accuracy: 97.0486%, Training Loss: 0.0861%\n",
      "Epoch [62/300], Step [28/225], Training Accuracy: 97.0982%, Training Loss: 0.0852%\n",
      "Epoch [62/300], Step [29/225], Training Accuracy: 97.0905%, Training Loss: 0.0854%\n",
      "Epoch [62/300], Step [30/225], Training Accuracy: 97.1354%, Training Loss: 0.0840%\n",
      "Epoch [62/300], Step [31/225], Training Accuracy: 97.0766%, Training Loss: 0.0847%\n",
      "Epoch [62/300], Step [32/225], Training Accuracy: 97.0703%, Training Loss: 0.0851%\n",
      "Epoch [62/300], Step [33/225], Training Accuracy: 96.9697%, Training Loss: 0.0856%\n",
      "Epoch [62/300], Step [34/225], Training Accuracy: 96.9669%, Training Loss: 0.0854%\n",
      "Epoch [62/300], Step [35/225], Training Accuracy: 97.0536%, Training Loss: 0.0846%\n",
      "Epoch [62/300], Step [36/225], Training Accuracy: 97.1354%, Training Loss: 0.0832%\n",
      "Epoch [62/300], Step [37/225], Training Accuracy: 97.0439%, Training Loss: 0.0861%\n",
      "Epoch [62/300], Step [38/225], Training Accuracy: 96.9161%, Training Loss: 0.0895%\n",
      "Epoch [62/300], Step [39/225], Training Accuracy: 96.9151%, Training Loss: 0.0906%\n",
      "Epoch [62/300], Step [40/225], Training Accuracy: 96.9141%, Training Loss: 0.0909%\n",
      "Epoch [62/300], Step [41/225], Training Accuracy: 96.8369%, Training Loss: 0.0939%\n",
      "Epoch [62/300], Step [42/225], Training Accuracy: 96.8378%, Training Loss: 0.0934%\n",
      "Epoch [62/300], Step [43/225], Training Accuracy: 96.8750%, Training Loss: 0.0933%\n",
      "Epoch [62/300], Step [44/225], Training Accuracy: 96.8750%, Training Loss: 0.0926%\n",
      "Epoch [62/300], Step [45/225], Training Accuracy: 96.8750%, Training Loss: 0.0919%\n",
      "Epoch [62/300], Step [46/225], Training Accuracy: 96.9090%, Training Loss: 0.0913%\n",
      "Epoch [62/300], Step [47/225], Training Accuracy: 96.9415%, Training Loss: 0.0907%\n",
      "Epoch [62/300], Step [48/225], Training Accuracy: 96.9401%, Training Loss: 0.0904%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/300], Step [49/225], Training Accuracy: 96.8431%, Training Loss: 0.0926%\n",
      "Epoch [62/300], Step [50/225], Training Accuracy: 96.8438%, Training Loss: 0.0934%\n",
      "Epoch [62/300], Step [51/225], Training Accuracy: 96.8444%, Training Loss: 0.0934%\n",
      "Epoch [62/300], Step [52/225], Training Accuracy: 96.9050%, Training Loss: 0.0924%\n",
      "Epoch [62/300], Step [53/225], Training Accuracy: 96.9340%, Training Loss: 0.0921%\n",
      "Epoch [62/300], Step [54/225], Training Accuracy: 96.8750%, Training Loss: 0.0929%\n",
      "Epoch [62/300], Step [55/225], Training Accuracy: 96.8466%, Training Loss: 0.0935%\n",
      "Epoch [62/300], Step [56/225], Training Accuracy: 96.7634%, Training Loss: 0.0957%\n",
      "Epoch [62/300], Step [57/225], Training Accuracy: 96.7379%, Training Loss: 0.0958%\n",
      "Epoch [62/300], Step [58/225], Training Accuracy: 96.7134%, Training Loss: 0.0959%\n",
      "Epoch [62/300], Step [59/225], Training Accuracy: 96.7426%, Training Loss: 0.0958%\n",
      "Epoch [62/300], Step [60/225], Training Accuracy: 96.7448%, Training Loss: 0.0954%\n",
      "Epoch [62/300], Step [61/225], Training Accuracy: 96.6189%, Training Loss: 0.0977%\n",
      "Epoch [62/300], Step [62/225], Training Accuracy: 96.6230%, Training Loss: 0.0977%\n",
      "Epoch [62/300], Step [63/225], Training Accuracy: 96.6022%, Training Loss: 0.0981%\n",
      "Epoch [62/300], Step [64/225], Training Accuracy: 96.6309%, Training Loss: 0.0976%\n",
      "Epoch [62/300], Step [65/225], Training Accuracy: 96.6106%, Training Loss: 0.0975%\n",
      "Epoch [62/300], Step [66/225], Training Accuracy: 96.5909%, Training Loss: 0.0985%\n",
      "Epoch [62/300], Step [67/225], Training Accuracy: 96.5485%, Training Loss: 0.0983%\n",
      "Epoch [62/300], Step [68/225], Training Accuracy: 96.5074%, Training Loss: 0.0994%\n",
      "Epoch [62/300], Step [69/225], Training Accuracy: 96.5127%, Training Loss: 0.0995%\n",
      "Epoch [62/300], Step [70/225], Training Accuracy: 96.4955%, Training Loss: 0.0996%\n",
      "Epoch [62/300], Step [71/225], Training Accuracy: 96.5009%, Training Loss: 0.0991%\n",
      "Epoch [62/300], Step [72/225], Training Accuracy: 96.5061%, Training Loss: 0.0988%\n",
      "Epoch [62/300], Step [73/225], Training Accuracy: 96.5325%, Training Loss: 0.0984%\n",
      "Epoch [62/300], Step [74/225], Training Accuracy: 96.5160%, Training Loss: 0.0985%\n",
      "Epoch [62/300], Step [75/225], Training Accuracy: 96.5417%, Training Loss: 0.0979%\n",
      "Epoch [62/300], Step [76/225], Training Accuracy: 96.5255%, Training Loss: 0.0981%\n",
      "Epoch [62/300], Step [77/225], Training Accuracy: 96.5300%, Training Loss: 0.0979%\n",
      "Epoch [62/300], Step [78/225], Training Accuracy: 96.4944%, Training Loss: 0.0982%\n",
      "Epoch [62/300], Step [79/225], Training Accuracy: 96.5190%, Training Loss: 0.0986%\n",
      "Epoch [62/300], Step [80/225], Training Accuracy: 96.4453%, Training Loss: 0.1001%\n",
      "Epoch [62/300], Step [81/225], Training Accuracy: 96.4892%, Training Loss: 0.0994%\n",
      "Epoch [62/300], Step [82/225], Training Accuracy: 96.4558%, Training Loss: 0.0999%\n",
      "Epoch [62/300], Step [83/225], Training Accuracy: 96.3855%, Training Loss: 0.1009%\n",
      "Epoch [62/300], Step [84/225], Training Accuracy: 96.2984%, Training Loss: 0.1021%\n",
      "Epoch [62/300], Step [85/225], Training Accuracy: 96.3051%, Training Loss: 0.1029%\n",
      "Epoch [62/300], Step [86/225], Training Accuracy: 96.3118%, Training Loss: 0.1031%\n",
      "Epoch [62/300], Step [87/225], Training Accuracy: 96.3182%, Training Loss: 0.1034%\n",
      "Epoch [62/300], Step [88/225], Training Accuracy: 96.3246%, Training Loss: 0.1031%\n",
      "Epoch [62/300], Step [89/225], Training Accuracy: 96.3483%, Training Loss: 0.1024%\n",
      "Epoch [62/300], Step [90/225], Training Accuracy: 96.3715%, Training Loss: 0.1021%\n",
      "Epoch [62/300], Step [91/225], Training Accuracy: 96.3427%, Training Loss: 0.1025%\n",
      "Epoch [62/300], Step [92/225], Training Accuracy: 96.3315%, Training Loss: 0.1025%\n",
      "Epoch [62/300], Step [93/225], Training Accuracy: 96.3542%, Training Loss: 0.1025%\n",
      "Epoch [62/300], Step [94/225], Training Accuracy: 96.3597%, Training Loss: 0.1025%\n",
      "Epoch [62/300], Step [95/225], Training Accuracy: 96.3651%, Training Loss: 0.1021%\n",
      "Epoch [62/300], Step [96/225], Training Accuracy: 96.3542%, Training Loss: 0.1021%\n",
      "Epoch [62/300], Step [97/225], Training Accuracy: 96.3434%, Training Loss: 0.1023%\n",
      "Epoch [62/300], Step [98/225], Training Accuracy: 96.3489%, Training Loss: 0.1027%\n",
      "Epoch [62/300], Step [99/225], Training Accuracy: 96.3542%, Training Loss: 0.1027%\n",
      "Epoch [62/300], Step [100/225], Training Accuracy: 96.3438%, Training Loss: 0.1027%\n",
      "Epoch [62/300], Step [101/225], Training Accuracy: 96.3800%, Training Loss: 0.1022%\n",
      "Epoch [62/300], Step [102/225], Training Accuracy: 96.3848%, Training Loss: 0.1023%\n",
      "Epoch [62/300], Step [103/225], Training Accuracy: 96.3896%, Training Loss: 0.1028%\n",
      "Epoch [62/300], Step [104/225], Training Accuracy: 96.3492%, Training Loss: 0.1032%\n",
      "Epoch [62/300], Step [105/225], Training Accuracy: 96.3839%, Training Loss: 0.1029%\n",
      "Epoch [62/300], Step [106/225], Training Accuracy: 96.3886%, Training Loss: 0.1030%\n",
      "Epoch [62/300], Step [107/225], Training Accuracy: 96.3493%, Training Loss: 0.1041%\n",
      "Epoch [62/300], Step [108/225], Training Accuracy: 96.3252%, Training Loss: 0.1047%\n",
      "Epoch [62/300], Step [109/225], Training Accuracy: 96.3303%, Training Loss: 0.1046%\n",
      "Epoch [62/300], Step [110/225], Training Accuracy: 96.3352%, Training Loss: 0.1044%\n",
      "Epoch [62/300], Step [111/225], Training Accuracy: 96.3260%, Training Loss: 0.1045%\n",
      "Epoch [62/300], Step [112/225], Training Accuracy: 96.3449%, Training Loss: 0.1044%\n",
      "Epoch [62/300], Step [113/225], Training Accuracy: 96.3634%, Training Loss: 0.1040%\n",
      "Epoch [62/300], Step [114/225], Training Accuracy: 96.3679%, Training Loss: 0.1039%\n",
      "Epoch [62/300], Step [115/225], Training Accuracy: 96.3859%, Training Loss: 0.1036%\n",
      "Epoch [62/300], Step [116/225], Training Accuracy: 96.3901%, Training Loss: 0.1033%\n",
      "Epoch [62/300], Step [117/225], Training Accuracy: 96.3942%, Training Loss: 0.1032%\n",
      "Epoch [62/300], Step [118/225], Training Accuracy: 96.4115%, Training Loss: 0.1029%\n",
      "Epoch [62/300], Step [119/225], Training Accuracy: 96.4286%, Training Loss: 0.1027%\n",
      "Epoch [62/300], Step [120/225], Training Accuracy: 96.4323%, Training Loss: 0.1026%\n",
      "Epoch [62/300], Step [121/225], Training Accuracy: 96.4230%, Training Loss: 0.1026%\n",
      "Epoch [62/300], Step [122/225], Training Accuracy: 96.4011%, Training Loss: 0.1032%\n",
      "Epoch [62/300], Step [123/225], Training Accuracy: 96.4050%, Training Loss: 0.1030%\n",
      "Epoch [62/300], Step [124/225], Training Accuracy: 96.4214%, Training Loss: 0.1027%\n",
      "Epoch [62/300], Step [125/225], Training Accuracy: 96.4250%, Training Loss: 0.1024%\n",
      "Epoch [62/300], Step [126/225], Training Accuracy: 96.4286%, Training Loss: 0.1026%\n",
      "Epoch [62/300], Step [127/225], Training Accuracy: 96.4198%, Training Loss: 0.1027%\n",
      "Epoch [62/300], Step [128/225], Training Accuracy: 96.3989%, Training Loss: 0.1029%\n",
      "Epoch [62/300], Step [129/225], Training Accuracy: 96.4026%, Training Loss: 0.1028%\n",
      "Epoch [62/300], Step [130/225], Training Accuracy: 96.4183%, Training Loss: 0.1026%\n",
      "Epoch [62/300], Step [131/225], Training Accuracy: 96.4218%, Training Loss: 0.1026%\n",
      "Epoch [62/300], Step [132/225], Training Accuracy: 96.4370%, Training Loss: 0.1025%\n",
      "Epoch [62/300], Step [133/225], Training Accuracy: 96.4168%, Training Loss: 0.1026%\n",
      "Epoch [62/300], Step [134/225], Training Accuracy: 96.4319%, Training Loss: 0.1027%\n",
      "Epoch [62/300], Step [135/225], Training Accuracy: 96.4352%, Training Loss: 0.1024%\n",
      "Epoch [62/300], Step [136/225], Training Accuracy: 96.4384%, Training Loss: 0.1026%\n",
      "Epoch [62/300], Step [137/225], Training Accuracy: 96.4302%, Training Loss: 0.1026%\n",
      "Epoch [62/300], Step [138/225], Training Accuracy: 96.4108%, Training Loss: 0.1028%\n",
      "Epoch [62/300], Step [139/225], Training Accuracy: 96.4254%, Training Loss: 0.1025%\n",
      "Epoch [62/300], Step [140/225], Training Accuracy: 96.4509%, Training Loss: 0.1021%\n",
      "Epoch [62/300], Step [141/225], Training Accuracy: 96.4428%, Training Loss: 0.1024%\n",
      "Epoch [62/300], Step [142/225], Training Accuracy: 96.4459%, Training Loss: 0.1023%\n",
      "Epoch [62/300], Step [143/225], Training Accuracy: 96.4270%, Training Loss: 0.1028%\n",
      "Epoch [62/300], Step [144/225], Training Accuracy: 96.4193%, Training Loss: 0.1025%\n",
      "Epoch [62/300], Step [145/225], Training Accuracy: 96.4116%, Training Loss: 0.1023%\n",
      "Epoch [62/300], Step [146/225], Training Accuracy: 96.4362%, Training Loss: 0.1020%\n",
      "Epoch [62/300], Step [147/225], Training Accuracy: 96.4286%, Training Loss: 0.1022%\n",
      "Epoch [62/300], Step [148/225], Training Accuracy: 96.4421%, Training Loss: 0.1020%\n",
      "Epoch [62/300], Step [149/225], Training Accuracy: 96.4346%, Training Loss: 0.1020%\n",
      "Epoch [62/300], Step [150/225], Training Accuracy: 96.4271%, Training Loss: 0.1020%\n",
      "Epoch [62/300], Step [151/225], Training Accuracy: 96.4197%, Training Loss: 0.1022%\n",
      "Epoch [62/300], Step [152/225], Training Accuracy: 96.4124%, Training Loss: 0.1027%\n",
      "Epoch [62/300], Step [153/225], Training Accuracy: 96.3950%, Training Loss: 0.1028%\n",
      "Epoch [62/300], Step [154/225], Training Accuracy: 96.3981%, Training Loss: 0.1025%\n",
      "Epoch [62/300], Step [155/225], Training Accuracy: 96.4012%, Training Loss: 0.1025%\n",
      "Epoch [62/300], Step [156/225], Training Accuracy: 96.4042%, Training Loss: 0.1023%\n",
      "Epoch [62/300], Step [157/225], Training Accuracy: 96.3973%, Training Loss: 0.1026%\n",
      "Epoch [62/300], Step [158/225], Training Accuracy: 96.4201%, Training Loss: 0.1022%\n",
      "Epoch [62/300], Step [159/225], Training Accuracy: 96.4426%, Training Loss: 0.1018%\n",
      "Epoch [62/300], Step [160/225], Training Accuracy: 96.4648%, Training Loss: 0.1014%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/300], Step [161/225], Training Accuracy: 96.4577%, Training Loss: 0.1013%\n",
      "Epoch [62/300], Step [162/225], Training Accuracy: 96.4410%, Training Loss: 0.1014%\n",
      "Epoch [62/300], Step [163/225], Training Accuracy: 96.4245%, Training Loss: 0.1016%\n",
      "Epoch [62/300], Step [164/225], Training Accuracy: 96.3986%, Training Loss: 0.1018%\n",
      "Epoch [62/300], Step [165/225], Training Accuracy: 96.4110%, Training Loss: 0.1016%\n",
      "Epoch [62/300], Step [166/225], Training Accuracy: 96.4044%, Training Loss: 0.1018%\n",
      "Epoch [62/300], Step [167/225], Training Accuracy: 96.3978%, Training Loss: 0.1019%\n",
      "Epoch [62/300], Step [168/225], Training Accuracy: 96.3914%, Training Loss: 0.1021%\n",
      "Epoch [62/300], Step [169/225], Training Accuracy: 96.4035%, Training Loss: 0.1018%\n",
      "Epoch [62/300], Step [170/225], Training Accuracy: 96.3971%, Training Loss: 0.1022%\n",
      "Epoch [62/300], Step [171/225], Training Accuracy: 96.4181%, Training Loss: 0.1018%\n",
      "Epoch [62/300], Step [172/225], Training Accuracy: 96.4026%, Training Loss: 0.1019%\n",
      "Epoch [62/300], Step [173/225], Training Accuracy: 96.4053%, Training Loss: 0.1020%\n",
      "Epoch [62/300], Step [174/225], Training Accuracy: 96.4260%, Training Loss: 0.1018%\n",
      "Epoch [62/300], Step [175/225], Training Accuracy: 96.4196%, Training Loss: 0.1020%\n",
      "Epoch [62/300], Step [176/225], Training Accuracy: 96.4134%, Training Loss: 0.1022%\n",
      "Epoch [62/300], Step [177/225], Training Accuracy: 96.4336%, Training Loss: 0.1018%\n",
      "Epoch [62/300], Step [178/225], Training Accuracy: 96.4273%, Training Loss: 0.1018%\n",
      "Epoch [62/300], Step [179/225], Training Accuracy: 96.4211%, Training Loss: 0.1019%\n",
      "Epoch [62/300], Step [180/225], Training Accuracy: 96.4323%, Training Loss: 0.1018%\n",
      "Epoch [62/300], Step [181/225], Training Accuracy: 96.4434%, Training Loss: 0.1017%\n",
      "Epoch [62/300], Step [182/225], Training Accuracy: 96.4543%, Training Loss: 0.1017%\n",
      "Epoch [62/300], Step [183/225], Training Accuracy: 96.4652%, Training Loss: 0.1013%\n",
      "Epoch [62/300], Step [184/225], Training Accuracy: 96.4674%, Training Loss: 0.1012%\n",
      "Epoch [62/300], Step [185/225], Training Accuracy: 96.4780%, Training Loss: 0.1015%\n",
      "Epoch [62/300], Step [186/225], Training Accuracy: 96.4550%, Training Loss: 0.1021%\n",
      "Epoch [62/300], Step [187/225], Training Accuracy: 96.4656%, Training Loss: 0.1019%\n",
      "Epoch [62/300], Step [188/225], Training Accuracy: 96.4761%, Training Loss: 0.1016%\n",
      "Epoch [62/300], Step [189/225], Training Accuracy: 96.4782%, Training Loss: 0.1014%\n",
      "Epoch [62/300], Step [190/225], Training Accuracy: 96.4556%, Training Loss: 0.1023%\n",
      "Epoch [62/300], Step [191/225], Training Accuracy: 96.4414%, Training Loss: 0.1025%\n",
      "Epoch [62/300], Step [192/225], Training Accuracy: 96.4355%, Training Loss: 0.1028%\n",
      "Epoch [62/300], Step [193/225], Training Accuracy: 96.4297%, Training Loss: 0.1029%\n",
      "Epoch [62/300], Step [194/225], Training Accuracy: 96.4240%, Training Loss: 0.1030%\n",
      "Epoch [62/300], Step [195/225], Training Accuracy: 96.4263%, Training Loss: 0.1030%\n",
      "Epoch [62/300], Step [196/225], Training Accuracy: 96.4365%, Training Loss: 0.1029%\n",
      "Epoch [62/300], Step [197/225], Training Accuracy: 96.4467%, Training Loss: 0.1026%\n",
      "Epoch [62/300], Step [198/225], Training Accuracy: 96.4489%, Training Loss: 0.1026%\n",
      "Epoch [62/300], Step [199/225], Training Accuracy: 96.4274%, Training Loss: 0.1029%\n",
      "Epoch [62/300], Step [200/225], Training Accuracy: 96.4297%, Training Loss: 0.1029%\n",
      "Epoch [62/300], Step [201/225], Training Accuracy: 96.4164%, Training Loss: 0.1032%\n",
      "Epoch [62/300], Step [202/225], Training Accuracy: 96.4032%, Training Loss: 0.1035%\n",
      "Epoch [62/300], Step [203/225], Training Accuracy: 96.4132%, Training Loss: 0.1031%\n",
      "Epoch [62/300], Step [204/225], Training Accuracy: 96.4078%, Training Loss: 0.1032%\n",
      "Epoch [62/300], Step [205/225], Training Accuracy: 96.4253%, Training Loss: 0.1029%\n",
      "Epoch [62/300], Step [206/225], Training Accuracy: 96.4427%, Training Loss: 0.1027%\n",
      "Epoch [62/300], Step [207/225], Training Accuracy: 96.4447%, Training Loss: 0.1025%\n",
      "Epoch [62/300], Step [208/225], Training Accuracy: 96.4468%, Training Loss: 0.1026%\n",
      "Epoch [62/300], Step [209/225], Training Accuracy: 96.4489%, Training Loss: 0.1025%\n",
      "Epoch [62/300], Step [210/225], Training Accuracy: 96.4360%, Training Loss: 0.1030%\n",
      "Epoch [62/300], Step [211/225], Training Accuracy: 96.4233%, Training Loss: 0.1030%\n",
      "Epoch [62/300], Step [212/225], Training Accuracy: 96.4254%, Training Loss: 0.1029%\n",
      "Epoch [62/300], Step [213/225], Training Accuracy: 96.4275%, Training Loss: 0.1027%\n",
      "Epoch [62/300], Step [214/225], Training Accuracy: 96.4150%, Training Loss: 0.1031%\n",
      "Epoch [62/300], Step [215/225], Training Accuracy: 96.4172%, Training Loss: 0.1029%\n",
      "Epoch [62/300], Step [216/225], Training Accuracy: 96.4193%, Training Loss: 0.1030%\n",
      "Epoch [62/300], Step [217/225], Training Accuracy: 96.4214%, Training Loss: 0.1029%\n",
      "Epoch [62/300], Step [218/225], Training Accuracy: 96.4306%, Training Loss: 0.1027%\n",
      "Epoch [62/300], Step [219/225], Training Accuracy: 96.4326%, Training Loss: 0.1027%\n",
      "Epoch [62/300], Step [220/225], Training Accuracy: 96.4489%, Training Loss: 0.1025%\n",
      "Epoch [62/300], Step [221/225], Training Accuracy: 96.4508%, Training Loss: 0.1025%\n",
      "Epoch [62/300], Step [222/225], Training Accuracy: 96.4527%, Training Loss: 0.1024%\n",
      "Epoch [62/300], Step [223/225], Training Accuracy: 96.4546%, Training Loss: 0.1024%\n",
      "Epoch [62/300], Step [224/225], Training Accuracy: 96.4704%, Training Loss: 0.1022%\n",
      "Epoch [62/300], Step [225/225], Training Accuracy: 96.4703%, Training Loss: 0.1021%\n",
      "Epoch [63/300], Step [1/225], Training Accuracy: 98.4375%, Training Loss: 0.0648%\n",
      "Epoch [63/300], Step [2/225], Training Accuracy: 98.4375%, Training Loss: 0.0542%\n",
      "Epoch [63/300], Step [3/225], Training Accuracy: 96.3542%, Training Loss: 0.1087%\n",
      "Epoch [63/300], Step [4/225], Training Accuracy: 96.8750%, Training Loss: 0.0980%\n",
      "Epoch [63/300], Step [5/225], Training Accuracy: 97.1875%, Training Loss: 0.0876%\n",
      "Epoch [63/300], Step [6/225], Training Accuracy: 97.1354%, Training Loss: 0.0876%\n",
      "Epoch [63/300], Step [7/225], Training Accuracy: 96.8750%, Training Loss: 0.1047%\n",
      "Epoch [63/300], Step [8/225], Training Accuracy: 97.2656%, Training Loss: 0.0963%\n",
      "Epoch [63/300], Step [9/225], Training Accuracy: 97.2222%, Training Loss: 0.0929%\n",
      "Epoch [63/300], Step [10/225], Training Accuracy: 97.3438%, Training Loss: 0.0898%\n",
      "Epoch [63/300], Step [11/225], Training Accuracy: 97.3011%, Training Loss: 0.0960%\n",
      "Epoch [63/300], Step [12/225], Training Accuracy: 97.1354%, Training Loss: 0.1047%\n",
      "Epoch [63/300], Step [13/225], Training Accuracy: 96.8750%, Training Loss: 0.1082%\n",
      "Epoch [63/300], Step [14/225], Training Accuracy: 96.8750%, Training Loss: 0.1056%\n",
      "Epoch [63/300], Step [15/225], Training Accuracy: 96.8750%, Training Loss: 0.1032%\n",
      "Epoch [63/300], Step [16/225], Training Accuracy: 96.9727%, Training Loss: 0.1011%\n",
      "Epoch [63/300], Step [17/225], Training Accuracy: 96.6912%, Training Loss: 0.1042%\n",
      "Epoch [63/300], Step [18/225], Training Accuracy: 96.6146%, Training Loss: 0.1051%\n",
      "Epoch [63/300], Step [19/225], Training Accuracy: 96.7105%, Training Loss: 0.1085%\n",
      "Epoch [63/300], Step [20/225], Training Accuracy: 96.6406%, Training Loss: 0.1082%\n",
      "Epoch [63/300], Step [21/225], Training Accuracy: 96.7262%, Training Loss: 0.1053%\n",
      "Epoch [63/300], Step [22/225], Training Accuracy: 96.7330%, Training Loss: 0.1056%\n",
      "Epoch [63/300], Step [23/225], Training Accuracy: 96.6712%, Training Loss: 0.1044%\n",
      "Epoch [63/300], Step [24/225], Training Accuracy: 96.4844%, Training Loss: 0.1082%\n",
      "Epoch [63/300], Step [25/225], Training Accuracy: 96.5625%, Training Loss: 0.1068%\n",
      "Epoch [63/300], Step [26/225], Training Accuracy: 96.4543%, Training Loss: 0.1062%\n",
      "Epoch [63/300], Step [27/225], Training Accuracy: 96.4120%, Training Loss: 0.1060%\n",
      "Epoch [63/300], Step [28/225], Training Accuracy: 96.4286%, Training Loss: 0.1046%\n",
      "Epoch [63/300], Step [29/225], Training Accuracy: 96.4978%, Training Loss: 0.1038%\n",
      "Epoch [63/300], Step [30/225], Training Accuracy: 96.5625%, Training Loss: 0.1033%\n",
      "Epoch [63/300], Step [31/225], Training Accuracy: 96.6230%, Training Loss: 0.1029%\n",
      "Epoch [63/300], Step [32/225], Training Accuracy: 96.6797%, Training Loss: 0.1014%\n",
      "Epoch [63/300], Step [33/225], Training Accuracy: 96.6856%, Training Loss: 0.1007%\n",
      "Epoch [63/300], Step [34/225], Training Accuracy: 96.6452%, Training Loss: 0.1011%\n",
      "Epoch [63/300], Step [35/225], Training Accuracy: 96.6518%, Training Loss: 0.1003%\n",
      "Epoch [63/300], Step [36/225], Training Accuracy: 96.7448%, Training Loss: 0.0983%\n",
      "Epoch [63/300], Step [37/225], Training Accuracy: 96.7061%, Training Loss: 0.0979%\n",
      "Epoch [63/300], Step [38/225], Training Accuracy: 96.7105%, Training Loss: 0.0980%\n",
      "Epoch [63/300], Step [39/225], Training Accuracy: 96.6747%, Training Loss: 0.1002%\n",
      "Epoch [63/300], Step [40/225], Training Accuracy: 96.7188%, Training Loss: 0.0994%\n",
      "Epoch [63/300], Step [41/225], Training Accuracy: 96.7607%, Training Loss: 0.0991%\n",
      "Epoch [63/300], Step [42/225], Training Accuracy: 96.8006%, Training Loss: 0.0979%\n",
      "Epoch [63/300], Step [43/225], Training Accuracy: 96.8750%, Training Loss: 0.0969%\n",
      "Epoch [63/300], Step [44/225], Training Accuracy: 96.8395%, Training Loss: 0.0983%\n",
      "Epoch [63/300], Step [45/225], Training Accuracy: 96.9097%, Training Loss: 0.0970%\n",
      "Epoch [63/300], Step [46/225], Training Accuracy: 96.9090%, Training Loss: 0.0982%\n",
      "Epoch [63/300], Step [47/225], Training Accuracy: 96.9082%, Training Loss: 0.0996%\n",
      "Epoch [63/300], Step [48/225], Training Accuracy: 96.8750%, Training Loss: 0.0996%\n",
      "Epoch [63/300], Step [49/225], Training Accuracy: 96.8431%, Training Loss: 0.0997%\n",
      "Epoch [63/300], Step [50/225], Training Accuracy: 96.7812%, Training Loss: 0.1007%\n",
      "Epoch [63/300], Step [51/225], Training Accuracy: 96.8444%, Training Loss: 0.0999%\n",
      "Epoch [63/300], Step [52/225], Training Accuracy: 96.9050%, Training Loss: 0.0985%\n",
      "Epoch [63/300], Step [53/225], Training Accuracy: 96.9340%, Training Loss: 0.0975%\n",
      "Epoch [63/300], Step [54/225], Training Accuracy: 96.8171%, Training Loss: 0.0986%\n",
      "Epoch [63/300], Step [55/225], Training Accuracy: 96.7898%, Training Loss: 0.0988%\n",
      "Epoch [63/300], Step [56/225], Training Accuracy: 96.7913%, Training Loss: 0.0982%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/300], Step [57/225], Training Accuracy: 96.7654%, Training Loss: 0.0982%\n",
      "Epoch [63/300], Step [58/225], Training Accuracy: 96.7942%, Training Loss: 0.0978%\n",
      "Epoch [63/300], Step [59/225], Training Accuracy: 96.8220%, Training Loss: 0.0971%\n",
      "Epoch [63/300], Step [60/225], Training Accuracy: 96.8229%, Training Loss: 0.0975%\n",
      "Epoch [63/300], Step [61/225], Training Accuracy: 96.7725%, Training Loss: 0.0977%\n",
      "Epoch [63/300], Step [62/225], Training Accuracy: 96.7490%, Training Loss: 0.0976%\n",
      "Epoch [63/300], Step [63/225], Training Accuracy: 96.7262%, Training Loss: 0.0980%\n",
      "Epoch [63/300], Step [64/225], Training Accuracy: 96.7041%, Training Loss: 0.0981%\n",
      "Epoch [63/300], Step [65/225], Training Accuracy: 96.7308%, Training Loss: 0.0972%\n",
      "Epoch [63/300], Step [66/225], Training Accuracy: 96.6619%, Training Loss: 0.0977%\n",
      "Epoch [63/300], Step [67/225], Training Accuracy: 96.6884%, Training Loss: 0.0973%\n",
      "Epoch [63/300], Step [68/225], Training Accuracy: 96.6912%, Training Loss: 0.0973%\n",
      "Epoch [63/300], Step [69/225], Training Accuracy: 96.7165%, Training Loss: 0.0970%\n",
      "Epoch [63/300], Step [70/225], Training Accuracy: 96.7411%, Training Loss: 0.0967%\n",
      "Epoch [63/300], Step [71/225], Training Accuracy: 96.7870%, Training Loss: 0.0960%\n",
      "Epoch [63/300], Step [72/225], Training Accuracy: 96.8099%, Training Loss: 0.0952%\n",
      "Epoch [63/300], Step [73/225], Training Accuracy: 96.8108%, Training Loss: 0.0950%\n",
      "Epoch [63/300], Step [74/225], Training Accuracy: 96.8328%, Training Loss: 0.0958%\n",
      "Epoch [63/300], Step [75/225], Training Accuracy: 96.8542%, Training Loss: 0.0952%\n",
      "Epoch [63/300], Step [76/225], Training Accuracy: 96.8750%, Training Loss: 0.0949%\n",
      "Epoch [63/300], Step [77/225], Training Accuracy: 96.8750%, Training Loss: 0.0950%\n",
      "Epoch [63/300], Step [78/225], Training Accuracy: 96.8750%, Training Loss: 0.0957%\n",
      "Epoch [63/300], Step [79/225], Training Accuracy: 96.8750%, Training Loss: 0.0955%\n",
      "Epoch [63/300], Step [80/225], Training Accuracy: 96.8555%, Training Loss: 0.0968%\n",
      "Epoch [63/300], Step [81/225], Training Accuracy: 96.8750%, Training Loss: 0.0964%\n",
      "Epoch [63/300], Step [82/225], Training Accuracy: 96.9131%, Training Loss: 0.0959%\n",
      "Epoch [63/300], Step [83/225], Training Accuracy: 96.8938%, Training Loss: 0.0962%\n",
      "Epoch [63/300], Step [84/225], Training Accuracy: 96.9308%, Training Loss: 0.0955%\n",
      "Epoch [63/300], Step [85/225], Training Accuracy: 96.8934%, Training Loss: 0.0958%\n",
      "Epoch [63/300], Step [86/225], Training Accuracy: 96.8387%, Training Loss: 0.0963%\n",
      "Epoch [63/300], Step [87/225], Training Accuracy: 96.8391%, Training Loss: 0.0972%\n",
      "Epoch [63/300], Step [88/225], Training Accuracy: 96.7862%, Training Loss: 0.0986%\n",
      "Epoch [63/300], Step [89/225], Training Accuracy: 96.7872%, Training Loss: 0.0987%\n",
      "Epoch [63/300], Step [90/225], Training Accuracy: 96.8056%, Training Loss: 0.0982%\n",
      "Epoch [63/300], Step [91/225], Training Accuracy: 96.8063%, Training Loss: 0.0984%\n",
      "Epoch [63/300], Step [92/225], Training Accuracy: 96.8071%, Training Loss: 0.0985%\n",
      "Epoch [63/300], Step [93/225], Training Accuracy: 96.8414%, Training Loss: 0.0979%\n",
      "Epoch [63/300], Step [94/225], Training Accuracy: 96.8750%, Training Loss: 0.0973%\n",
      "Epoch [63/300], Step [95/225], Training Accuracy: 96.8914%, Training Loss: 0.0973%\n",
      "Epoch [63/300], Step [96/225], Training Accuracy: 96.8913%, Training Loss: 0.0973%\n",
      "Epoch [63/300], Step [97/225], Training Accuracy: 96.8911%, Training Loss: 0.0969%\n",
      "Epoch [63/300], Step [98/225], Training Accuracy: 96.8591%, Training Loss: 0.0979%\n",
      "Epoch [63/300], Step [99/225], Training Accuracy: 96.8434%, Training Loss: 0.0985%\n",
      "Epoch [63/300], Step [100/225], Training Accuracy: 96.8125%, Training Loss: 0.0995%\n",
      "Epoch [63/300], Step [101/225], Training Accuracy: 96.8131%, Training Loss: 0.0995%\n",
      "Epoch [63/300], Step [102/225], Training Accuracy: 96.7678%, Training Loss: 0.0997%\n",
      "Epoch [63/300], Step [103/225], Training Accuracy: 96.7840%, Training Loss: 0.0994%\n",
      "Epoch [63/300], Step [104/225], Training Accuracy: 96.7849%, Training Loss: 0.0993%\n",
      "Epoch [63/300], Step [105/225], Training Accuracy: 96.7857%, Training Loss: 0.0997%\n",
      "Epoch [63/300], Step [106/225], Training Accuracy: 96.7866%, Training Loss: 0.0998%\n",
      "Epoch [63/300], Step [107/225], Training Accuracy: 96.8166%, Training Loss: 0.0993%\n",
      "Epoch [63/300], Step [108/225], Training Accuracy: 96.8316%, Training Loss: 0.0991%\n",
      "Epoch [63/300], Step [109/225], Training Accuracy: 96.8463%, Training Loss: 0.0990%\n",
      "Epoch [63/300], Step [110/225], Training Accuracy: 96.8608%, Training Loss: 0.0986%\n",
      "Epoch [63/300], Step [111/225], Training Accuracy: 96.8750%, Training Loss: 0.0982%\n",
      "Epoch [63/300], Step [112/225], Training Accuracy: 96.8610%, Training Loss: 0.0979%\n",
      "Epoch [63/300], Step [113/225], Training Accuracy: 96.8612%, Training Loss: 0.0978%\n",
      "Epoch [63/300], Step [114/225], Training Accuracy: 96.8613%, Training Loss: 0.0977%\n",
      "Epoch [63/300], Step [115/225], Training Accuracy: 96.8478%, Training Loss: 0.0975%\n",
      "Epoch [63/300], Step [116/225], Training Accuracy: 96.8346%, Training Loss: 0.0980%\n",
      "Epoch [63/300], Step [117/225], Training Accuracy: 96.8349%, Training Loss: 0.0980%\n",
      "Epoch [63/300], Step [118/225], Training Accuracy: 96.8088%, Training Loss: 0.0980%\n",
      "Epoch [63/300], Step [119/225], Training Accuracy: 96.7962%, Training Loss: 0.0985%\n",
      "Epoch [63/300], Step [120/225], Training Accuracy: 96.8229%, Training Loss: 0.0980%\n",
      "Epoch [63/300], Step [121/225], Training Accuracy: 96.8492%, Training Loss: 0.0976%\n",
      "Epoch [63/300], Step [122/225], Training Accuracy: 96.8494%, Training Loss: 0.0977%\n",
      "Epoch [63/300], Step [123/225], Training Accuracy: 96.8369%, Training Loss: 0.0977%\n",
      "Epoch [63/300], Step [124/225], Training Accuracy: 96.8372%, Training Loss: 0.0977%\n",
      "Epoch [63/300], Step [125/225], Training Accuracy: 96.8250%, Training Loss: 0.0979%\n",
      "Epoch [63/300], Step [126/225], Training Accuracy: 96.8502%, Training Loss: 0.0976%\n",
      "Epoch [63/300], Step [127/225], Training Accuracy: 96.8258%, Training Loss: 0.0980%\n",
      "Epoch [63/300], Step [128/225], Training Accuracy: 96.8140%, Training Loss: 0.0980%\n",
      "Epoch [63/300], Step [129/225], Training Accuracy: 96.8023%, Training Loss: 0.0986%\n",
      "Epoch [63/300], Step [130/225], Training Accuracy: 96.8029%, Training Loss: 0.0986%\n",
      "Epoch [63/300], Step [131/225], Training Accuracy: 96.8273%, Training Loss: 0.0981%\n",
      "Epoch [63/300], Step [132/225], Training Accuracy: 96.8277%, Training Loss: 0.0980%\n",
      "Epoch [63/300], Step [133/225], Training Accuracy: 96.8398%, Training Loss: 0.0977%\n",
      "Epoch [63/300], Step [134/225], Training Accuracy: 96.8633%, Training Loss: 0.0972%\n",
      "Epoch [63/300], Step [135/225], Training Accuracy: 96.8287%, Training Loss: 0.0972%\n",
      "Epoch [63/300], Step [136/225], Training Accuracy: 96.7831%, Training Loss: 0.0976%\n",
      "Epoch [63/300], Step [137/225], Training Accuracy: 96.7609%, Training Loss: 0.0978%\n",
      "Epoch [63/300], Step [138/225], Training Accuracy: 96.7618%, Training Loss: 0.0978%\n",
      "Epoch [63/300], Step [139/225], Training Accuracy: 96.7513%, Training Loss: 0.0979%\n",
      "Epoch [63/300], Step [140/225], Training Accuracy: 96.7746%, Training Loss: 0.0974%\n",
      "Epoch [63/300], Step [141/225], Training Accuracy: 96.7753%, Training Loss: 0.0973%\n",
      "Epoch [63/300], Step [142/225], Training Accuracy: 96.7430%, Training Loss: 0.0980%\n",
      "Epoch [63/300], Step [143/225], Training Accuracy: 96.7548%, Training Loss: 0.0979%\n",
      "Epoch [63/300], Step [144/225], Training Accuracy: 96.7231%, Training Loss: 0.0984%\n",
      "Epoch [63/300], Step [145/225], Training Accuracy: 96.6810%, Training Loss: 0.0986%\n",
      "Epoch [63/300], Step [146/225], Training Accuracy: 96.6824%, Training Loss: 0.0984%\n",
      "Epoch [63/300], Step [147/225], Training Accuracy: 96.6837%, Training Loss: 0.0989%\n",
      "Epoch [63/300], Step [148/225], Training Accuracy: 96.6744%, Training Loss: 0.0990%\n",
      "Epoch [63/300], Step [149/225], Training Accuracy: 96.6758%, Training Loss: 0.0992%\n",
      "Epoch [63/300], Step [150/225], Training Accuracy: 96.6979%, Training Loss: 0.0988%\n",
      "Epoch [63/300], Step [151/225], Training Accuracy: 96.6784%, Training Loss: 0.0988%\n",
      "Epoch [63/300], Step [152/225], Training Accuracy: 96.7002%, Training Loss: 0.0984%\n",
      "Epoch [63/300], Step [153/225], Training Accuracy: 96.7014%, Training Loss: 0.0986%\n",
      "Epoch [63/300], Step [154/225], Training Accuracy: 96.7025%, Training Loss: 0.0989%\n",
      "Epoch [63/300], Step [155/225], Training Accuracy: 96.7036%, Training Loss: 0.0988%\n",
      "Epoch [63/300], Step [156/225], Training Accuracy: 96.6947%, Training Loss: 0.0988%\n",
      "Epoch [63/300], Step [157/225], Training Accuracy: 96.6859%, Training Loss: 0.0989%\n",
      "Epoch [63/300], Step [158/225], Training Accuracy: 96.6772%, Training Loss: 0.0991%\n",
      "Epoch [63/300], Step [159/225], Training Accuracy: 96.6588%, Training Loss: 0.0996%\n",
      "Epoch [63/300], Step [160/225], Training Accuracy: 96.6699%, Training Loss: 0.0994%\n",
      "Epoch [63/300], Step [161/225], Training Accuracy: 96.6809%, Training Loss: 0.0991%\n",
      "Epoch [63/300], Step [162/225], Training Accuracy: 96.6821%, Training Loss: 0.0990%\n",
      "Epoch [63/300], Step [163/225], Training Accuracy: 96.6929%, Training Loss: 0.0992%\n",
      "Epoch [63/300], Step [164/225], Training Accuracy: 96.6845%, Training Loss: 0.0992%\n",
      "Epoch [63/300], Step [165/225], Training Accuracy: 96.6856%, Training Loss: 0.0993%\n",
      "Epoch [63/300], Step [166/225], Training Accuracy: 96.6773%, Training Loss: 0.0993%\n",
      "Epoch [63/300], Step [167/225], Training Accuracy: 96.6879%, Training Loss: 0.0990%\n",
      "Epoch [63/300], Step [168/225], Training Accuracy: 96.6890%, Training Loss: 0.0989%\n",
      "Epoch [63/300], Step [169/225], Training Accuracy: 96.6993%, Training Loss: 0.0988%\n",
      "Epoch [63/300], Step [170/225], Training Accuracy: 96.6912%, Training Loss: 0.0989%\n",
      "Epoch [63/300], Step [171/225], Training Accuracy: 96.7014%, Training Loss: 0.0987%\n",
      "Epoch [63/300], Step [172/225], Training Accuracy: 96.7024%, Training Loss: 0.0988%\n",
      "Epoch [63/300], Step [173/225], Training Accuracy: 96.7124%, Training Loss: 0.0986%\n",
      "Epoch [63/300], Step [174/225], Training Accuracy: 96.7044%, Training Loss: 0.0985%\n",
      "Epoch [63/300], Step [175/225], Training Accuracy: 96.7054%, Training Loss: 0.0982%\n",
      "Epoch [63/300], Step [176/225], Training Accuracy: 96.6886%, Training Loss: 0.0984%\n",
      "Epoch [63/300], Step [177/225], Training Accuracy: 96.6984%, Training Loss: 0.0981%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/300], Step [178/225], Training Accuracy: 96.6907%, Training Loss: 0.0982%\n",
      "Epoch [63/300], Step [179/225], Training Accuracy: 96.6917%, Training Loss: 0.0983%\n",
      "Epoch [63/300], Step [180/225], Training Accuracy: 96.7014%, Training Loss: 0.0982%\n",
      "Epoch [63/300], Step [181/225], Training Accuracy: 96.7110%, Training Loss: 0.0981%\n",
      "Epoch [63/300], Step [182/225], Training Accuracy: 96.7033%, Training Loss: 0.0981%\n",
      "Epoch [63/300], Step [183/225], Training Accuracy: 96.6957%, Training Loss: 0.0983%\n",
      "Epoch [63/300], Step [184/225], Training Accuracy: 96.6967%, Training Loss: 0.0981%\n",
      "Epoch [63/300], Step [185/225], Training Accuracy: 96.6976%, Training Loss: 0.0983%\n",
      "Epoch [63/300], Step [186/225], Training Accuracy: 96.7070%, Training Loss: 0.0980%\n",
      "Epoch [63/300], Step [187/225], Training Accuracy: 96.6828%, Training Loss: 0.0983%\n",
      "Epoch [63/300], Step [188/225], Training Accuracy: 96.6922%, Training Loss: 0.0982%\n",
      "Epoch [63/300], Step [189/225], Training Accuracy: 96.6931%, Training Loss: 0.0981%\n",
      "Epoch [63/300], Step [190/225], Training Accuracy: 96.6694%, Training Loss: 0.0985%\n",
      "Epoch [63/300], Step [191/225], Training Accuracy: 96.6623%, Training Loss: 0.0985%\n",
      "Epoch [63/300], Step [192/225], Training Accuracy: 96.6634%, Training Loss: 0.0984%\n",
      "Epoch [63/300], Step [193/225], Training Accuracy: 96.6483%, Training Loss: 0.0986%\n",
      "Epoch [63/300], Step [194/225], Training Accuracy: 96.6656%, Training Loss: 0.0983%\n",
      "Epoch [63/300], Step [195/225], Training Accuracy: 96.6587%, Training Loss: 0.0985%\n",
      "Epoch [63/300], Step [196/225], Training Accuracy: 96.6598%, Training Loss: 0.0983%\n",
      "Epoch [63/300], Step [197/225], Training Accuracy: 96.6529%, Training Loss: 0.0984%\n",
      "Epoch [63/300], Step [198/225], Training Accuracy: 96.6461%, Training Loss: 0.0986%\n",
      "Epoch [63/300], Step [199/225], Training Accuracy: 96.6630%, Training Loss: 0.0984%\n",
      "Epoch [63/300], Step [200/225], Training Accuracy: 96.6719%, Training Loss: 0.0982%\n",
      "Epoch [63/300], Step [201/225], Training Accuracy: 96.6807%, Training Loss: 0.0981%\n",
      "Epoch [63/300], Step [202/225], Training Accuracy: 96.6739%, Training Loss: 0.0981%\n",
      "Epoch [63/300], Step [203/225], Training Accuracy: 96.6672%, Training Loss: 0.0981%\n",
      "Epoch [63/300], Step [204/225], Training Accuracy: 96.6759%, Training Loss: 0.0979%\n",
      "Epoch [63/300], Step [205/225], Training Accuracy: 96.6768%, Training Loss: 0.0981%\n",
      "Epoch [63/300], Step [206/225], Training Accuracy: 96.6854%, Training Loss: 0.0979%\n",
      "Epoch [63/300], Step [207/225], Training Accuracy: 96.7014%, Training Loss: 0.0976%\n",
      "Epoch [63/300], Step [208/225], Training Accuracy: 96.7022%, Training Loss: 0.0975%\n",
      "Epoch [63/300], Step [209/225], Training Accuracy: 96.6806%, Training Loss: 0.0976%\n",
      "Epoch [63/300], Step [210/225], Training Accuracy: 96.6815%, Training Loss: 0.0977%\n",
      "Epoch [63/300], Step [211/225], Training Accuracy: 96.6602%, Training Loss: 0.0980%\n",
      "Epoch [63/300], Step [212/225], Training Accuracy: 96.6686%, Training Loss: 0.0979%\n",
      "Epoch [63/300], Step [213/225], Training Accuracy: 96.6769%, Training Loss: 0.0978%\n",
      "Epoch [63/300], Step [214/225], Training Accuracy: 96.6706%, Training Loss: 0.0980%\n",
      "Epoch [63/300], Step [215/225], Training Accuracy: 96.6715%, Training Loss: 0.0980%\n",
      "Epoch [63/300], Step [216/225], Training Accuracy: 96.6797%, Training Loss: 0.0979%\n",
      "Epoch [63/300], Step [217/225], Training Accuracy: 96.6878%, Training Loss: 0.0979%\n",
      "Epoch [63/300], Step [218/225], Training Accuracy: 96.6958%, Training Loss: 0.0977%\n",
      "Epoch [63/300], Step [219/225], Training Accuracy: 96.6966%, Training Loss: 0.0977%\n",
      "Epoch [63/300], Step [220/225], Training Accuracy: 96.6974%, Training Loss: 0.0978%\n",
      "Epoch [63/300], Step [221/225], Training Accuracy: 96.7053%, Training Loss: 0.0978%\n",
      "Epoch [63/300], Step [222/225], Training Accuracy: 96.7061%, Training Loss: 0.0977%\n",
      "Epoch [63/300], Step [223/225], Training Accuracy: 96.7138%, Training Loss: 0.0976%\n",
      "Epoch [63/300], Step [224/225], Training Accuracy: 96.7076%, Training Loss: 0.0975%\n",
      "Epoch [63/300], Step [225/225], Training Accuracy: 96.7204%, Training Loss: 0.0973%\n",
      "Epoch [64/300], Step [1/225], Training Accuracy: 92.1875%, Training Loss: 0.2013%\n",
      "Epoch [64/300], Step [2/225], Training Accuracy: 93.7500%, Training Loss: 0.1466%\n",
      "Epoch [64/300], Step [3/225], Training Accuracy: 94.7917%, Training Loss: 0.1460%\n",
      "Epoch [64/300], Step [4/225], Training Accuracy: 96.0938%, Training Loss: 0.1167%\n",
      "Epoch [64/300], Step [5/225], Training Accuracy: 95.9375%, Training Loss: 0.1114%\n",
      "Epoch [64/300], Step [6/225], Training Accuracy: 96.6146%, Training Loss: 0.0988%\n",
      "Epoch [64/300], Step [7/225], Training Accuracy: 96.4286%, Training Loss: 0.1006%\n",
      "Epoch [64/300], Step [8/225], Training Accuracy: 96.6797%, Training Loss: 0.0951%\n",
      "Epoch [64/300], Step [9/225], Training Accuracy: 96.7014%, Training Loss: 0.0938%\n",
      "Epoch [64/300], Step [10/225], Training Accuracy: 96.7188%, Training Loss: 0.0939%\n",
      "Epoch [64/300], Step [11/225], Training Accuracy: 96.8750%, Training Loss: 0.0898%\n",
      "Epoch [64/300], Step [12/225], Training Accuracy: 96.7448%, Training Loss: 0.0901%\n",
      "Epoch [64/300], Step [13/225], Training Accuracy: 96.8750%, Training Loss: 0.0872%\n",
      "Epoch [64/300], Step [14/225], Training Accuracy: 97.0982%, Training Loss: 0.0860%\n",
      "Epoch [64/300], Step [15/225], Training Accuracy: 97.2917%, Training Loss: 0.0838%\n",
      "Epoch [64/300], Step [16/225], Training Accuracy: 97.4609%, Training Loss: 0.0821%\n",
      "Epoch [64/300], Step [17/225], Training Accuracy: 97.3346%, Training Loss: 0.0844%\n",
      "Epoch [64/300], Step [18/225], Training Accuracy: 97.1354%, Training Loss: 0.0864%\n",
      "Epoch [64/300], Step [19/225], Training Accuracy: 97.2039%, Training Loss: 0.0864%\n",
      "Epoch [64/300], Step [20/225], Training Accuracy: 97.1875%, Training Loss: 0.0858%\n",
      "Epoch [64/300], Step [21/225], Training Accuracy: 97.2470%, Training Loss: 0.0853%\n",
      "Epoch [64/300], Step [22/225], Training Accuracy: 97.3011%, Training Loss: 0.0843%\n",
      "Epoch [64/300], Step [23/225], Training Accuracy: 97.2826%, Training Loss: 0.0856%\n",
      "Epoch [64/300], Step [24/225], Training Accuracy: 97.3307%, Training Loss: 0.0859%\n",
      "Epoch [64/300], Step [25/225], Training Accuracy: 97.3125%, Training Loss: 0.0855%\n",
      "Epoch [64/300], Step [26/225], Training Accuracy: 97.2957%, Training Loss: 0.0851%\n",
      "Epoch [64/300], Step [27/225], Training Accuracy: 97.2222%, Training Loss: 0.0862%\n",
      "Epoch [64/300], Step [28/225], Training Accuracy: 97.3214%, Training Loss: 0.0849%\n",
      "Epoch [64/300], Step [29/225], Training Accuracy: 97.3599%, Training Loss: 0.0839%\n",
      "Epoch [64/300], Step [30/225], Training Accuracy: 97.2917%, Training Loss: 0.0849%\n",
      "Epoch [64/300], Step [31/225], Training Accuracy: 97.3286%, Training Loss: 0.0848%\n",
      "Epoch [64/300], Step [32/225], Training Accuracy: 97.4121%, Training Loss: 0.0840%\n",
      "Epoch [64/300], Step [33/225], Training Accuracy: 97.3485%, Training Loss: 0.0846%\n",
      "Epoch [64/300], Step [34/225], Training Accuracy: 97.2886%, Training Loss: 0.0866%\n",
      "Epoch [64/300], Step [35/225], Training Accuracy: 97.3661%, Training Loss: 0.0850%\n",
      "Epoch [64/300], Step [36/225], Training Accuracy: 97.3958%, Training Loss: 0.0842%\n",
      "Epoch [64/300], Step [37/225], Training Accuracy: 97.3395%, Training Loss: 0.0845%\n",
      "Epoch [64/300], Step [38/225], Training Accuracy: 97.3273%, Training Loss: 0.0854%\n",
      "Epoch [64/300], Step [39/225], Training Accuracy: 97.3157%, Training Loss: 0.0863%\n",
      "Epoch [64/300], Step [40/225], Training Accuracy: 97.3438%, Training Loss: 0.0858%\n",
      "Epoch [64/300], Step [41/225], Training Accuracy: 97.2942%, Training Loss: 0.0865%\n",
      "Epoch [64/300], Step [42/225], Training Accuracy: 97.3586%, Training Loss: 0.0855%\n",
      "Epoch [64/300], Step [43/225], Training Accuracy: 97.3837%, Training Loss: 0.0855%\n",
      "Epoch [64/300], Step [44/225], Training Accuracy: 97.3722%, Training Loss: 0.0849%\n",
      "Epoch [64/300], Step [45/225], Training Accuracy: 97.3264%, Training Loss: 0.0849%\n",
      "Epoch [64/300], Step [46/225], Training Accuracy: 97.3505%, Training Loss: 0.0843%\n",
      "Epoch [64/300], Step [47/225], Training Accuracy: 97.2739%, Training Loss: 0.0854%\n",
      "Epoch [64/300], Step [48/225], Training Accuracy: 97.2656%, Training Loss: 0.0849%\n",
      "Epoch [64/300], Step [49/225], Training Accuracy: 97.2895%, Training Loss: 0.0845%\n",
      "Epoch [64/300], Step [50/225], Training Accuracy: 97.3125%, Training Loss: 0.0841%\n",
      "Epoch [64/300], Step [51/225], Training Accuracy: 97.3652%, Training Loss: 0.0831%\n",
      "Epoch [64/300], Step [52/225], Training Accuracy: 97.3858%, Training Loss: 0.0826%\n",
      "Epoch [64/300], Step [53/225], Training Accuracy: 97.2877%, Training Loss: 0.0840%\n",
      "Epoch [64/300], Step [54/225], Training Accuracy: 97.2512%, Training Loss: 0.0846%\n",
      "Epoch [64/300], Step [55/225], Training Accuracy: 97.2727%, Training Loss: 0.0840%\n",
      "Epoch [64/300], Step [56/225], Training Accuracy: 97.2098%, Training Loss: 0.0857%\n",
      "Epoch [64/300], Step [57/225], Training Accuracy: 97.2039%, Training Loss: 0.0861%\n",
      "Epoch [64/300], Step [58/225], Training Accuracy: 97.1983%, Training Loss: 0.0860%\n",
      "Epoch [64/300], Step [59/225], Training Accuracy: 97.2193%, Training Loss: 0.0859%\n",
      "Epoch [64/300], Step [60/225], Training Accuracy: 97.2396%, Training Loss: 0.0856%\n",
      "Epoch [64/300], Step [61/225], Training Accuracy: 97.2336%, Training Loss: 0.0860%\n",
      "Epoch [64/300], Step [62/225], Training Accuracy: 97.2530%, Training Loss: 0.0857%\n",
      "Epoch [64/300], Step [63/225], Training Accuracy: 97.2470%, Training Loss: 0.0855%\n",
      "Epoch [64/300], Step [64/225], Training Accuracy: 97.2412%, Training Loss: 0.0852%\n",
      "Epoch [64/300], Step [65/225], Training Accuracy: 97.2356%, Training Loss: 0.0860%\n",
      "Epoch [64/300], Step [66/225], Training Accuracy: 97.2301%, Training Loss: 0.0862%\n",
      "Epoch [64/300], Step [67/225], Training Accuracy: 97.2248%, Training Loss: 0.0862%\n",
      "Epoch [64/300], Step [68/225], Training Accuracy: 97.1967%, Training Loss: 0.0865%\n",
      "Epoch [64/300], Step [69/225], Training Accuracy: 97.1920%, Training Loss: 0.0863%\n",
      "Epoch [64/300], Step [70/225], Training Accuracy: 97.1205%, Training Loss: 0.0870%\n",
      "Epoch [64/300], Step [71/225], Training Accuracy: 97.1391%, Training Loss: 0.0866%\n",
      "Epoch [64/300], Step [72/225], Training Accuracy: 97.1788%, Training Loss: 0.0858%\n",
      "Epoch [64/300], Step [73/225], Training Accuracy: 97.1533%, Training Loss: 0.0867%\n",
      "Epoch [64/300], Step [74/225], Training Accuracy: 97.1073%, Training Loss: 0.0878%\n",
      "Epoch [64/300], Step [75/225], Training Accuracy: 97.1250%, Training Loss: 0.0873%\n",
      "Epoch [64/300], Step [76/225], Training Accuracy: 97.0806%, Training Loss: 0.0880%\n",
      "Epoch [64/300], Step [77/225], Training Accuracy: 97.0982%, Training Loss: 0.0883%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/300], Step [78/225], Training Accuracy: 97.0954%, Training Loss: 0.0883%\n",
      "Epoch [64/300], Step [79/225], Training Accuracy: 97.0530%, Training Loss: 0.0887%\n",
      "Epoch [64/300], Step [80/225], Training Accuracy: 97.0508%, Training Loss: 0.0886%\n",
      "Epoch [64/300], Step [81/225], Training Accuracy: 97.0679%, Training Loss: 0.0880%\n",
      "Epoch [64/300], Step [82/225], Training Accuracy: 97.0846%, Training Loss: 0.0876%\n",
      "Epoch [64/300], Step [83/225], Training Accuracy: 97.0821%, Training Loss: 0.0878%\n",
      "Epoch [64/300], Step [84/225], Training Accuracy: 97.0796%, Training Loss: 0.0877%\n",
      "Epoch [64/300], Step [85/225], Training Accuracy: 97.0956%, Training Loss: 0.0872%\n",
      "Epoch [64/300], Step [86/225], Training Accuracy: 97.0930%, Training Loss: 0.0873%\n",
      "Epoch [64/300], Step [87/225], Training Accuracy: 97.1085%, Training Loss: 0.0871%\n",
      "Epoch [64/300], Step [88/225], Training Accuracy: 97.1058%, Training Loss: 0.0873%\n",
      "Epoch [64/300], Step [89/225], Training Accuracy: 97.0857%, Training Loss: 0.0876%\n",
      "Epoch [64/300], Step [90/225], Training Accuracy: 97.0833%, Training Loss: 0.0879%\n",
      "Epoch [64/300], Step [91/225], Training Accuracy: 97.0810%, Training Loss: 0.0875%\n",
      "Epoch [64/300], Step [92/225], Training Accuracy: 97.0618%, Training Loss: 0.0879%\n",
      "Epoch [64/300], Step [93/225], Training Accuracy: 97.0262%, Training Loss: 0.0884%\n",
      "Epoch [64/300], Step [94/225], Training Accuracy: 96.9914%, Training Loss: 0.0886%\n",
      "Epoch [64/300], Step [95/225], Training Accuracy: 97.0230%, Training Loss: 0.0883%\n",
      "Epoch [64/300], Step [96/225], Training Accuracy: 97.0378%, Training Loss: 0.0882%\n",
      "Epoch [64/300], Step [97/225], Training Accuracy: 97.0361%, Training Loss: 0.0881%\n",
      "Epoch [64/300], Step [98/225], Training Accuracy: 97.0504%, Training Loss: 0.0880%\n",
      "Epoch [64/300], Step [99/225], Training Accuracy: 97.0644%, Training Loss: 0.0877%\n",
      "Epoch [64/300], Step [100/225], Training Accuracy: 97.0156%, Training Loss: 0.0882%\n",
      "Epoch [64/300], Step [101/225], Training Accuracy: 97.0297%, Training Loss: 0.0883%\n",
      "Epoch [64/300], Step [102/225], Training Accuracy: 97.0435%, Training Loss: 0.0878%\n",
      "Epoch [64/300], Step [103/225], Training Accuracy: 97.0419%, Training Loss: 0.0881%\n",
      "Epoch [64/300], Step [104/225], Training Accuracy: 97.0553%, Training Loss: 0.0880%\n",
      "Epoch [64/300], Step [105/225], Training Accuracy: 97.0238%, Training Loss: 0.0882%\n",
      "Epoch [64/300], Step [106/225], Training Accuracy: 97.0077%, Training Loss: 0.0886%\n",
      "Epoch [64/300], Step [107/225], Training Accuracy: 96.9772%, Training Loss: 0.0888%\n",
      "Epoch [64/300], Step [108/225], Training Accuracy: 96.9618%, Training Loss: 0.0888%\n",
      "Epoch [64/300], Step [109/225], Training Accuracy: 96.9467%, Training Loss: 0.0890%\n",
      "Epoch [64/300], Step [110/225], Training Accuracy: 96.9602%, Training Loss: 0.0888%\n",
      "Epoch [64/300], Step [111/225], Training Accuracy: 96.9595%, Training Loss: 0.0886%\n",
      "Epoch [64/300], Step [112/225], Training Accuracy: 96.9727%, Training Loss: 0.0886%\n",
      "Epoch [64/300], Step [113/225], Training Accuracy: 96.9856%, Training Loss: 0.0882%\n",
      "Epoch [64/300], Step [114/225], Training Accuracy: 96.9709%, Training Loss: 0.0883%\n",
      "Epoch [64/300], Step [115/225], Training Accuracy: 96.9565%, Training Loss: 0.0889%\n",
      "Epoch [64/300], Step [116/225], Training Accuracy: 96.9693%, Training Loss: 0.0888%\n",
      "Epoch [64/300], Step [117/225], Training Accuracy: 96.9818%, Training Loss: 0.0887%\n",
      "Epoch [64/300], Step [118/225], Training Accuracy: 96.9942%, Training Loss: 0.0886%\n",
      "Epoch [64/300], Step [119/225], Training Accuracy: 96.9800%, Training Loss: 0.0886%\n",
      "Epoch [64/300], Step [120/225], Training Accuracy: 96.9792%, Training Loss: 0.0884%\n",
      "Epoch [64/300], Step [121/225], Training Accuracy: 96.9267%, Training Loss: 0.0893%\n",
      "Epoch [64/300], Step [122/225], Training Accuracy: 96.9134%, Training Loss: 0.0898%\n",
      "Epoch [64/300], Step [123/225], Training Accuracy: 96.9385%, Training Loss: 0.0894%\n",
      "Epoch [64/300], Step [124/225], Training Accuracy: 96.9002%, Training Loss: 0.0899%\n",
      "Epoch [64/300], Step [125/225], Training Accuracy: 96.9250%, Training Loss: 0.0896%\n",
      "Epoch [64/300], Step [126/225], Training Accuracy: 96.9122%, Training Loss: 0.0901%\n",
      "Epoch [64/300], Step [127/225], Training Accuracy: 96.9119%, Training Loss: 0.0900%\n",
      "Epoch [64/300], Step [128/225], Training Accuracy: 96.9238%, Training Loss: 0.0898%\n",
      "Epoch [64/300], Step [129/225], Training Accuracy: 96.9356%, Training Loss: 0.0895%\n",
      "Epoch [64/300], Step [130/225], Training Accuracy: 96.8870%, Training Loss: 0.0907%\n",
      "Epoch [64/300], Step [131/225], Training Accuracy: 96.9108%, Training Loss: 0.0904%\n",
      "Epoch [64/300], Step [132/225], Training Accuracy: 96.9105%, Training Loss: 0.0902%\n",
      "Epoch [64/300], Step [133/225], Training Accuracy: 96.9220%, Training Loss: 0.0899%\n",
      "Epoch [64/300], Step [134/225], Training Accuracy: 96.9333%, Training Loss: 0.0896%\n",
      "Epoch [64/300], Step [135/225], Training Accuracy: 96.9444%, Training Loss: 0.0892%\n",
      "Epoch [64/300], Step [136/225], Training Accuracy: 96.9324%, Training Loss: 0.0893%\n",
      "Epoch [64/300], Step [137/225], Training Accuracy: 96.9548%, Training Loss: 0.0888%\n",
      "Epoch [64/300], Step [138/225], Training Accuracy: 96.9769%, Training Loss: 0.0886%\n",
      "Epoch [64/300], Step [139/225], Training Accuracy: 96.9537%, Training Loss: 0.0892%\n",
      "Epoch [64/300], Step [140/225], Training Accuracy: 96.9531%, Training Loss: 0.0892%\n",
      "Epoch [64/300], Step [141/225], Training Accuracy: 96.9637%, Training Loss: 0.0892%\n",
      "Epoch [64/300], Step [142/225], Training Accuracy: 96.9520%, Training Loss: 0.0893%\n",
      "Epoch [64/300], Step [143/225], Training Accuracy: 96.9406%, Training Loss: 0.0895%\n",
      "Epoch [64/300], Step [144/225], Training Accuracy: 96.9618%, Training Loss: 0.0890%\n",
      "Epoch [64/300], Step [145/225], Training Accuracy: 96.9828%, Training Loss: 0.0886%\n",
      "Epoch [64/300], Step [146/225], Training Accuracy: 96.9820%, Training Loss: 0.0885%\n",
      "Epoch [64/300], Step [147/225], Training Accuracy: 96.9919%, Training Loss: 0.0884%\n",
      "Epoch [64/300], Step [148/225], Training Accuracy: 96.9700%, Training Loss: 0.0888%\n",
      "Epoch [64/300], Step [149/225], Training Accuracy: 96.9799%, Training Loss: 0.0886%\n",
      "Epoch [64/300], Step [150/225], Training Accuracy: 96.9792%, Training Loss: 0.0885%\n",
      "Epoch [64/300], Step [151/225], Training Accuracy: 96.9785%, Training Loss: 0.0886%\n",
      "Epoch [64/300], Step [152/225], Training Accuracy: 96.9778%, Training Loss: 0.0884%\n",
      "Epoch [64/300], Step [153/225], Training Accuracy: 96.9975%, Training Loss: 0.0881%\n",
      "Epoch [64/300], Step [154/225], Training Accuracy: 96.9866%, Training Loss: 0.0881%\n",
      "Epoch [64/300], Step [155/225], Training Accuracy: 96.9859%, Training Loss: 0.0886%\n",
      "Epoch [64/300], Step [156/225], Training Accuracy: 97.0052%, Training Loss: 0.0883%\n",
      "Epoch [64/300], Step [157/225], Training Accuracy: 97.0143%, Training Loss: 0.0883%\n",
      "Epoch [64/300], Step [158/225], Training Accuracy: 97.0332%, Training Loss: 0.0879%\n",
      "Epoch [64/300], Step [159/225], Training Accuracy: 97.0322%, Training Loss: 0.0879%\n",
      "Epoch [64/300], Step [160/225], Training Accuracy: 97.0410%, Training Loss: 0.0879%\n",
      "Epoch [64/300], Step [161/225], Training Accuracy: 97.0594%, Training Loss: 0.0876%\n",
      "Epoch [64/300], Step [162/225], Training Accuracy: 97.0197%, Training Loss: 0.0879%\n",
      "Epoch [64/300], Step [163/225], Training Accuracy: 97.0284%, Training Loss: 0.0880%\n",
      "Epoch [64/300], Step [164/225], Training Accuracy: 97.0465%, Training Loss: 0.0878%\n",
      "Epoch [64/300], Step [165/225], Training Accuracy: 97.0265%, Training Loss: 0.0880%\n",
      "Epoch [64/300], Step [166/225], Training Accuracy: 97.0256%, Training Loss: 0.0879%\n",
      "Epoch [64/300], Step [167/225], Training Accuracy: 97.0341%, Training Loss: 0.0876%\n",
      "Epoch [64/300], Step [168/225], Training Accuracy: 97.0424%, Training Loss: 0.0874%\n",
      "Epoch [64/300], Step [169/225], Training Accuracy: 97.0414%, Training Loss: 0.0873%\n",
      "Epoch [64/300], Step [170/225], Training Accuracy: 97.0221%, Training Loss: 0.0878%\n",
      "Epoch [64/300], Step [171/225], Training Accuracy: 96.9938%, Training Loss: 0.0880%\n",
      "Epoch [64/300], Step [172/225], Training Accuracy: 97.0022%, Training Loss: 0.0879%\n",
      "Epoch [64/300], Step [173/225], Training Accuracy: 97.0014%, Training Loss: 0.0877%\n",
      "Epoch [64/300], Step [174/225], Training Accuracy: 97.0007%, Training Loss: 0.0877%\n",
      "Epoch [64/300], Step [175/225], Training Accuracy: 97.0179%, Training Loss: 0.0874%\n",
      "Epoch [64/300], Step [176/225], Training Accuracy: 97.0348%, Training Loss: 0.0871%\n",
      "Epoch [64/300], Step [177/225], Training Accuracy: 97.0516%, Training Loss: 0.0868%\n",
      "Epoch [64/300], Step [178/225], Training Accuracy: 97.0418%, Training Loss: 0.0870%\n",
      "Epoch [64/300], Step [179/225], Training Accuracy: 97.0234%, Training Loss: 0.0873%\n",
      "Epoch [64/300], Step [180/225], Training Accuracy: 97.0226%, Training Loss: 0.0873%\n",
      "Epoch [64/300], Step [181/225], Training Accuracy: 97.0390%, Training Loss: 0.0872%\n",
      "Epoch [64/300], Step [182/225], Training Accuracy: 97.0467%, Training Loss: 0.0871%\n",
      "Epoch [64/300], Step [183/225], Training Accuracy: 97.0287%, Training Loss: 0.0877%\n",
      "Epoch [64/300], Step [184/225], Training Accuracy: 97.0279%, Training Loss: 0.0878%\n",
      "Epoch [64/300], Step [185/225], Training Accuracy: 97.0439%, Training Loss: 0.0875%\n",
      "Epoch [64/300], Step [186/225], Training Accuracy: 97.0514%, Training Loss: 0.0874%\n",
      "Epoch [64/300], Step [187/225], Training Accuracy: 97.0588%, Training Loss: 0.0873%\n",
      "Epoch [64/300], Step [188/225], Training Accuracy: 97.0745%, Training Loss: 0.0871%\n",
      "Epoch [64/300], Step [189/225], Training Accuracy: 97.0734%, Training Loss: 0.0870%\n",
      "Epoch [64/300], Step [190/225], Training Accuracy: 97.0559%, Training Loss: 0.0871%\n",
      "Epoch [64/300], Step [191/225], Training Accuracy: 97.0550%, Training Loss: 0.0872%\n",
      "Epoch [64/300], Step [192/225], Training Accuracy: 97.0133%, Training Loss: 0.0876%\n",
      "Epoch [64/300], Step [193/225], Training Accuracy: 97.0045%, Training Loss: 0.0876%\n",
      "Epoch [64/300], Step [194/225], Training Accuracy: 97.0039%, Training Loss: 0.0878%\n",
      "Epoch [64/300], Step [195/225], Training Accuracy: 97.0112%, Training Loss: 0.0878%\n",
      "Epoch [64/300], Step [196/225], Training Accuracy: 97.0185%, Training Loss: 0.0875%\n",
      "Epoch [64/300], Step [197/225], Training Accuracy: 96.9940%, Training Loss: 0.0879%\n",
      "Epoch [64/300], Step [198/225], Training Accuracy: 96.9934%, Training Loss: 0.0880%\n",
      "Epoch [64/300], Step [199/225], Training Accuracy: 97.0006%, Training Loss: 0.0879%\n",
      "Epoch [64/300], Step [200/225], Training Accuracy: 96.9922%, Training Loss: 0.0881%\n",
      "Epoch [64/300], Step [201/225], Training Accuracy: 96.9838%, Training Loss: 0.0882%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/300], Step [202/225], Training Accuracy: 96.9910%, Training Loss: 0.0882%\n",
      "Epoch [64/300], Step [203/225], Training Accuracy: 96.9982%, Training Loss: 0.0880%\n",
      "Epoch [64/300], Step [204/225], Training Accuracy: 96.9822%, Training Loss: 0.0883%\n",
      "Epoch [64/300], Step [205/225], Training Accuracy: 96.9741%, Training Loss: 0.0884%\n",
      "Epoch [64/300], Step [206/225], Training Accuracy: 96.9660%, Training Loss: 0.0884%\n",
      "Epoch [64/300], Step [207/225], Training Accuracy: 96.9731%, Training Loss: 0.0883%\n",
      "Epoch [64/300], Step [208/225], Training Accuracy: 96.9802%, Training Loss: 0.0882%\n",
      "Epoch [64/300], Step [209/225], Training Accuracy: 96.9871%, Training Loss: 0.0881%\n",
      "Epoch [64/300], Step [210/225], Training Accuracy: 96.9792%, Training Loss: 0.0885%\n",
      "Epoch [64/300], Step [211/225], Training Accuracy: 96.9639%, Training Loss: 0.0887%\n",
      "Epoch [64/300], Step [212/225], Training Accuracy: 96.9782%, Training Loss: 0.0885%\n",
      "Epoch [64/300], Step [213/225], Training Accuracy: 96.9777%, Training Loss: 0.0884%\n",
      "Epoch [64/300], Step [214/225], Training Accuracy: 96.9480%, Training Loss: 0.0889%\n",
      "Epoch [64/300], Step [215/225], Training Accuracy: 96.9404%, Training Loss: 0.0889%\n",
      "Epoch [64/300], Step [216/225], Training Accuracy: 96.9256%, Training Loss: 0.0890%\n",
      "Epoch [64/300], Step [217/225], Training Accuracy: 96.9326%, Training Loss: 0.0890%\n",
      "Epoch [64/300], Step [218/225], Training Accuracy: 96.9467%, Training Loss: 0.0889%\n",
      "Epoch [64/300], Step [219/225], Training Accuracy: 96.9535%, Training Loss: 0.0888%\n",
      "Epoch [64/300], Step [220/225], Training Accuracy: 96.9460%, Training Loss: 0.0888%\n",
      "Epoch [64/300], Step [221/225], Training Accuracy: 96.9528%, Training Loss: 0.0887%\n",
      "Epoch [64/300], Step [222/225], Training Accuracy: 96.9454%, Training Loss: 0.0890%\n",
      "Epoch [64/300], Step [223/225], Training Accuracy: 96.9381%, Training Loss: 0.0891%\n",
      "Epoch [64/300], Step [224/225], Training Accuracy: 96.9378%, Training Loss: 0.0892%\n",
      "Epoch [64/300], Step [225/225], Training Accuracy: 96.9358%, Training Loss: 0.0892%\n",
      "Epoch [65/300], Step [1/225], Training Accuracy: 95.3125%, Training Loss: 0.0876%\n",
      "Epoch [65/300], Step [2/225], Training Accuracy: 97.6562%, Training Loss: 0.0682%\n",
      "Epoch [65/300], Step [3/225], Training Accuracy: 97.9167%, Training Loss: 0.0695%\n",
      "Epoch [65/300], Step [4/225], Training Accuracy: 97.2656%, Training Loss: 0.0767%\n",
      "Epoch [65/300], Step [5/225], Training Accuracy: 97.5000%, Training Loss: 0.0763%\n",
      "Epoch [65/300], Step [6/225], Training Accuracy: 97.9167%, Training Loss: 0.0677%\n",
      "Epoch [65/300], Step [7/225], Training Accuracy: 98.2143%, Training Loss: 0.0636%\n",
      "Epoch [65/300], Step [8/225], Training Accuracy: 98.2422%, Training Loss: 0.0634%\n",
      "Epoch [65/300], Step [9/225], Training Accuracy: 98.2639%, Training Loss: 0.0640%\n",
      "Epoch [65/300], Step [10/225], Training Accuracy: 97.8125%, Training Loss: 0.0776%\n",
      "Epoch [65/300], Step [11/225], Training Accuracy: 97.8693%, Training Loss: 0.0753%\n",
      "Epoch [65/300], Step [12/225], Training Accuracy: 97.9167%, Training Loss: 0.0736%\n",
      "Epoch [65/300], Step [13/225], Training Accuracy: 97.9567%, Training Loss: 0.0743%\n",
      "Epoch [65/300], Step [14/225], Training Accuracy: 97.6562%, Training Loss: 0.0771%\n",
      "Epoch [65/300], Step [15/225], Training Accuracy: 97.7083%, Training Loss: 0.0762%\n",
      "Epoch [65/300], Step [16/225], Training Accuracy: 97.8516%, Training Loss: 0.0742%\n",
      "Epoch [65/300], Step [17/225], Training Accuracy: 97.7941%, Training Loss: 0.0775%\n",
      "Epoch [65/300], Step [18/225], Training Accuracy: 97.4826%, Training Loss: 0.0830%\n",
      "Epoch [65/300], Step [19/225], Training Accuracy: 97.3684%, Training Loss: 0.0836%\n",
      "Epoch [65/300], Step [20/225], Training Accuracy: 97.4219%, Training Loss: 0.0825%\n",
      "Epoch [65/300], Step [21/225], Training Accuracy: 97.5446%, Training Loss: 0.0800%\n",
      "Epoch [65/300], Step [22/225], Training Accuracy: 97.5852%, Training Loss: 0.0817%\n",
      "Epoch [65/300], Step [23/225], Training Accuracy: 97.5543%, Training Loss: 0.0817%\n",
      "Epoch [65/300], Step [24/225], Training Accuracy: 97.5260%, Training Loss: 0.0846%\n",
      "Epoch [65/300], Step [25/225], Training Accuracy: 97.5625%, Training Loss: 0.0838%\n",
      "Epoch [65/300], Step [26/225], Training Accuracy: 97.4760%, Training Loss: 0.0836%\n",
      "Epoch [65/300], Step [27/225], Training Accuracy: 97.4537%, Training Loss: 0.0829%\n",
      "Epoch [65/300], Step [28/225], Training Accuracy: 97.4888%, Training Loss: 0.0814%\n",
      "Epoch [65/300], Step [29/225], Training Accuracy: 97.5216%, Training Loss: 0.0811%\n",
      "Epoch [65/300], Step [30/225], Training Accuracy: 97.4479%, Training Loss: 0.0821%\n",
      "Epoch [65/300], Step [31/225], Training Accuracy: 97.2782%, Training Loss: 0.0834%\n",
      "Epoch [65/300], Step [32/225], Training Accuracy: 97.2168%, Training Loss: 0.0858%\n",
      "Epoch [65/300], Step [33/225], Training Accuracy: 97.2064%, Training Loss: 0.0859%\n",
      "Epoch [65/300], Step [34/225], Training Accuracy: 97.1048%, Training Loss: 0.0885%\n",
      "Epoch [65/300], Step [35/225], Training Accuracy: 96.9196%, Training Loss: 0.0931%\n",
      "Epoch [65/300], Step [36/225], Training Accuracy: 96.9184%, Training Loss: 0.0929%\n",
      "Epoch [65/300], Step [37/225], Training Accuracy: 96.9595%, Training Loss: 0.0927%\n",
      "Epoch [65/300], Step [38/225], Training Accuracy: 96.9161%, Training Loss: 0.0943%\n",
      "Epoch [65/300], Step [39/225], Training Accuracy: 96.9151%, Training Loss: 0.0948%\n",
      "Epoch [65/300], Step [40/225], Training Accuracy: 96.8359%, Training Loss: 0.0950%\n",
      "Epoch [65/300], Step [41/225], Training Accuracy: 96.8369%, Training Loss: 0.0947%\n",
      "Epoch [65/300], Step [42/225], Training Accuracy: 96.8006%, Training Loss: 0.0949%\n",
      "Epoch [65/300], Step [43/225], Training Accuracy: 96.8387%, Training Loss: 0.0938%\n",
      "Epoch [65/300], Step [44/225], Training Accuracy: 96.8395%, Training Loss: 0.0936%\n",
      "Epoch [65/300], Step [45/225], Training Accuracy: 96.7708%, Training Loss: 0.0944%\n",
      "Epoch [65/300], Step [46/225], Training Accuracy: 96.8071%, Training Loss: 0.0938%\n",
      "Epoch [65/300], Step [47/225], Training Accuracy: 96.8085%, Training Loss: 0.0942%\n",
      "Epoch [65/300], Step [48/225], Training Accuracy: 96.8099%, Training Loss: 0.0946%\n",
      "Epoch [65/300], Step [49/225], Training Accuracy: 96.8112%, Training Loss: 0.0946%\n",
      "Epoch [65/300], Step [50/225], Training Accuracy: 96.8125%, Training Loss: 0.0946%\n",
      "Epoch [65/300], Step [51/225], Training Accuracy: 96.8444%, Training Loss: 0.0941%\n",
      "Epoch [65/300], Step [52/225], Training Accuracy: 96.8750%, Training Loss: 0.0939%\n",
      "Epoch [65/300], Step [53/225], Training Accuracy: 96.9045%, Training Loss: 0.0935%\n",
      "Epoch [65/300], Step [54/225], Training Accuracy: 96.9039%, Training Loss: 0.0929%\n",
      "Epoch [65/300], Step [55/225], Training Accuracy: 96.9034%, Training Loss: 0.0924%\n",
      "Epoch [65/300], Step [56/225], Training Accuracy: 96.8471%, Training Loss: 0.0927%\n",
      "Epoch [65/300], Step [57/225], Training Accuracy: 96.9024%, Training Loss: 0.0920%\n",
      "Epoch [65/300], Step [58/225], Training Accuracy: 96.8481%, Training Loss: 0.0932%\n",
      "Epoch [65/300], Step [59/225], Training Accuracy: 96.7956%, Training Loss: 0.0935%\n",
      "Epoch [65/300], Step [60/225], Training Accuracy: 96.7969%, Training Loss: 0.0936%\n",
      "Epoch [65/300], Step [61/225], Training Accuracy: 96.8238%, Training Loss: 0.0940%\n",
      "Epoch [65/300], Step [62/225], Training Accuracy: 96.8246%, Training Loss: 0.0944%\n",
      "Epoch [65/300], Step [63/225], Training Accuracy: 96.8006%, Training Loss: 0.0952%\n",
      "Epoch [65/300], Step [64/225], Training Accuracy: 96.8262%, Training Loss: 0.0946%\n",
      "Epoch [65/300], Step [65/225], Training Accuracy: 96.8269%, Training Loss: 0.0942%\n",
      "Epoch [65/300], Step [66/225], Training Accuracy: 96.8277%, Training Loss: 0.0939%\n",
      "Epoch [65/300], Step [67/225], Training Accuracy: 96.8050%, Training Loss: 0.0940%\n",
      "Epoch [65/300], Step [68/225], Training Accuracy: 96.8061%, Training Loss: 0.0940%\n",
      "Epoch [65/300], Step [69/225], Training Accuracy: 96.8071%, Training Loss: 0.0935%\n",
      "Epoch [65/300], Step [70/225], Training Accuracy: 96.8527%, Training Loss: 0.0925%\n",
      "Epoch [65/300], Step [71/225], Training Accuracy: 96.8310%, Training Loss: 0.0930%\n",
      "Epoch [65/300], Step [72/225], Training Accuracy: 96.8533%, Training Loss: 0.0927%\n",
      "Epoch [65/300], Step [73/225], Training Accuracy: 96.8536%, Training Loss: 0.0927%\n",
      "Epoch [65/300], Step [74/225], Training Accuracy: 96.8328%, Training Loss: 0.0932%\n",
      "Epoch [65/300], Step [75/225], Training Accuracy: 96.8333%, Training Loss: 0.0930%\n",
      "Epoch [65/300], Step [76/225], Training Accuracy: 96.8750%, Training Loss: 0.0926%\n",
      "Epoch [65/300], Step [77/225], Training Accuracy: 96.8750%, Training Loss: 0.0925%\n",
      "Epoch [65/300], Step [78/225], Training Accuracy: 96.8950%, Training Loss: 0.0923%\n",
      "Epoch [65/300], Step [79/225], Training Accuracy: 96.8157%, Training Loss: 0.0939%\n",
      "Epoch [65/300], Step [80/225], Training Accuracy: 96.7773%, Training Loss: 0.0944%\n",
      "Epoch [65/300], Step [81/225], Training Accuracy: 96.7978%, Training Loss: 0.0942%\n",
      "Epoch [65/300], Step [82/225], Training Accuracy: 96.7797%, Training Loss: 0.0944%\n",
      "Epoch [65/300], Step [83/225], Training Accuracy: 96.7620%, Training Loss: 0.0945%\n",
      "Epoch [65/300], Step [84/225], Training Accuracy: 96.7634%, Training Loss: 0.0943%\n",
      "Epoch [65/300], Step [85/225], Training Accuracy: 96.8015%, Training Loss: 0.0938%\n",
      "Epoch [65/300], Step [86/225], Training Accuracy: 96.7842%, Training Loss: 0.0943%\n",
      "Epoch [65/300], Step [87/225], Training Accuracy: 96.7493%, Training Loss: 0.0950%\n",
      "Epoch [65/300], Step [88/225], Training Accuracy: 96.7507%, Training Loss: 0.0954%\n",
      "Epoch [65/300], Step [89/225], Training Accuracy: 96.7521%, Training Loss: 0.0951%\n",
      "Epoch [65/300], Step [90/225], Training Accuracy: 96.7535%, Training Loss: 0.0951%\n",
      "Epoch [65/300], Step [91/225], Training Accuracy: 96.7376%, Training Loss: 0.0955%\n",
      "Epoch [65/300], Step [92/225], Training Accuracy: 96.7561%, Training Loss: 0.0949%\n",
      "Epoch [65/300], Step [93/225], Training Accuracy: 96.7574%, Training Loss: 0.0955%\n",
      "Epoch [65/300], Step [94/225], Training Accuracy: 96.7753%, Training Loss: 0.0949%\n",
      "Epoch [65/300], Step [95/225], Training Accuracy: 96.7928%, Training Loss: 0.0943%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/300], Step [96/225], Training Accuracy: 96.8099%, Training Loss: 0.0940%\n",
      "Epoch [65/300], Step [97/225], Training Accuracy: 96.8106%, Training Loss: 0.0944%\n",
      "Epoch [65/300], Step [98/225], Training Accuracy: 96.7953%, Training Loss: 0.0947%\n",
      "Epoch [65/300], Step [99/225], Training Accuracy: 96.8119%, Training Loss: 0.0944%\n",
      "Epoch [65/300], Step [100/225], Training Accuracy: 96.7969%, Training Loss: 0.0944%\n",
      "Epoch [65/300], Step [101/225], Training Accuracy: 96.8131%, Training Loss: 0.0941%\n",
      "Epoch [65/300], Step [102/225], Training Accuracy: 96.8290%, Training Loss: 0.0938%\n",
      "Epoch [65/300], Step [103/225], Training Accuracy: 96.8143%, Training Loss: 0.0942%\n",
      "Epoch [65/300], Step [104/225], Training Accuracy: 96.8450%, Training Loss: 0.0938%\n",
      "Epoch [65/300], Step [105/225], Training Accuracy: 96.8750%, Training Loss: 0.0935%\n",
      "Epoch [65/300], Step [106/225], Training Accuracy: 96.8603%, Training Loss: 0.0940%\n",
      "Epoch [65/300], Step [107/225], Training Accuracy: 96.8312%, Training Loss: 0.0954%\n",
      "Epoch [65/300], Step [108/225], Training Accuracy: 96.8171%, Training Loss: 0.0959%\n",
      "Epoch [65/300], Step [109/225], Training Accuracy: 96.8320%, Training Loss: 0.0956%\n",
      "Epoch [65/300], Step [110/225], Training Accuracy: 96.8608%, Training Loss: 0.0951%\n",
      "Epoch [65/300], Step [111/225], Training Accuracy: 96.8891%, Training Loss: 0.0945%\n",
      "Epoch [65/300], Step [112/225], Training Accuracy: 96.8890%, Training Loss: 0.0945%\n",
      "Epoch [65/300], Step [113/225], Training Accuracy: 96.9027%, Training Loss: 0.0946%\n",
      "Epoch [65/300], Step [114/225], Training Accuracy: 96.8476%, Training Loss: 0.0952%\n",
      "Epoch [65/300], Step [115/225], Training Accuracy: 96.8614%, Training Loss: 0.0948%\n",
      "Epoch [65/300], Step [116/225], Training Accuracy: 96.8615%, Training Loss: 0.0949%\n",
      "Epoch [65/300], Step [117/225], Training Accuracy: 96.8750%, Training Loss: 0.0948%\n",
      "Epoch [65/300], Step [118/225], Training Accuracy: 96.8485%, Training Loss: 0.0954%\n",
      "Epoch [65/300], Step [119/225], Training Accuracy: 96.8619%, Training Loss: 0.0951%\n",
      "Epoch [65/300], Step [120/225], Training Accuracy: 96.8750%, Training Loss: 0.0949%\n",
      "Epoch [65/300], Step [121/225], Training Accuracy: 96.8879%, Training Loss: 0.0945%\n",
      "Epoch [65/300], Step [122/225], Training Accuracy: 96.8494%, Training Loss: 0.0958%\n",
      "Epoch [65/300], Step [123/225], Training Accuracy: 96.8750%, Training Loss: 0.0953%\n",
      "Epoch [65/300], Step [124/225], Training Accuracy: 96.8372%, Training Loss: 0.0958%\n",
      "Epoch [65/300], Step [125/225], Training Accuracy: 96.8500%, Training Loss: 0.0955%\n",
      "Epoch [65/300], Step [126/225], Training Accuracy: 96.8626%, Training Loss: 0.0952%\n",
      "Epoch [65/300], Step [127/225], Training Accuracy: 96.8750%, Training Loss: 0.0950%\n",
      "Epoch [65/300], Step [128/225], Training Accuracy: 96.8628%, Training Loss: 0.0957%\n",
      "Epoch [65/300], Step [129/225], Training Accuracy: 96.8750%, Training Loss: 0.0956%\n",
      "Epoch [65/300], Step [130/225], Training Accuracy: 96.8750%, Training Loss: 0.0957%\n",
      "Epoch [65/300], Step [131/225], Training Accuracy: 96.8869%, Training Loss: 0.0952%\n",
      "Epoch [65/300], Step [132/225], Training Accuracy: 96.8987%, Training Loss: 0.0950%\n",
      "Epoch [65/300], Step [133/225], Training Accuracy: 96.8867%, Training Loss: 0.0950%\n",
      "Epoch [65/300], Step [134/225], Training Accuracy: 96.8867%, Training Loss: 0.0948%\n",
      "Epoch [65/300], Step [135/225], Training Accuracy: 96.9097%, Training Loss: 0.0943%\n",
      "Epoch [65/300], Step [136/225], Training Accuracy: 96.8980%, Training Loss: 0.0944%\n",
      "Epoch [65/300], Step [137/225], Training Accuracy: 96.9092%, Training Loss: 0.0941%\n",
      "Epoch [65/300], Step [138/225], Training Accuracy: 96.8976%, Training Loss: 0.0942%\n",
      "Epoch [65/300], Step [139/225], Training Accuracy: 96.8862%, Training Loss: 0.0947%\n",
      "Epoch [65/300], Step [140/225], Training Accuracy: 96.8973%, Training Loss: 0.0945%\n",
      "Epoch [65/300], Step [141/225], Training Accuracy: 96.9082%, Training Loss: 0.0943%\n",
      "Epoch [65/300], Step [142/225], Training Accuracy: 96.9190%, Training Loss: 0.0940%\n",
      "Epoch [65/300], Step [143/225], Training Accuracy: 96.9296%, Training Loss: 0.0938%\n",
      "Epoch [65/300], Step [144/225], Training Accuracy: 96.9293%, Training Loss: 0.0936%\n",
      "Epoch [65/300], Step [145/225], Training Accuracy: 96.9397%, Training Loss: 0.0934%\n",
      "Epoch [65/300], Step [146/225], Training Accuracy: 96.9285%, Training Loss: 0.0937%\n",
      "Epoch [65/300], Step [147/225], Training Accuracy: 96.9069%, Training Loss: 0.0943%\n",
      "Epoch [65/300], Step [148/225], Training Accuracy: 96.8961%, Training Loss: 0.0944%\n",
      "Epoch [65/300], Step [149/225], Training Accuracy: 96.9065%, Training Loss: 0.0942%\n",
      "Epoch [65/300], Step [150/225], Training Accuracy: 96.9167%, Training Loss: 0.0939%\n",
      "Epoch [65/300], Step [151/225], Training Accuracy: 96.9267%, Training Loss: 0.0940%\n",
      "Epoch [65/300], Step [152/225], Training Accuracy: 96.9264%, Training Loss: 0.0939%\n",
      "Epoch [65/300], Step [153/225], Training Accuracy: 96.9158%, Training Loss: 0.0939%\n",
      "Epoch [65/300], Step [154/225], Training Accuracy: 96.9156%, Training Loss: 0.0938%\n",
      "Epoch [65/300], Step [155/225], Training Accuracy: 96.9153%, Training Loss: 0.0937%\n",
      "Epoch [65/300], Step [156/225], Training Accuracy: 96.9151%, Training Loss: 0.0937%\n",
      "Epoch [65/300], Step [157/225], Training Accuracy: 96.9148%, Training Loss: 0.0936%\n",
      "Epoch [65/300], Step [158/225], Training Accuracy: 96.9343%, Training Loss: 0.0933%\n",
      "Epoch [65/300], Step [159/225], Training Accuracy: 96.9340%, Training Loss: 0.0932%\n",
      "Epoch [65/300], Step [160/225], Training Accuracy: 96.9531%, Training Loss: 0.0930%\n",
      "Epoch [65/300], Step [161/225], Training Accuracy: 96.9623%, Training Loss: 0.0927%\n",
      "Epoch [65/300], Step [162/225], Training Accuracy: 96.9715%, Training Loss: 0.0927%\n",
      "Epoch [65/300], Step [163/225], Training Accuracy: 96.9804%, Training Loss: 0.0924%\n",
      "Epoch [65/300], Step [164/225], Training Accuracy: 96.9893%, Training Loss: 0.0923%\n",
      "Epoch [65/300], Step [165/225], Training Accuracy: 97.0076%, Training Loss: 0.0921%\n",
      "Epoch [65/300], Step [166/225], Training Accuracy: 96.9974%, Training Loss: 0.0920%\n",
      "Epoch [65/300], Step [167/225], Training Accuracy: 96.9686%, Training Loss: 0.0923%\n",
      "Epoch [65/300], Step [168/225], Training Accuracy: 96.9680%, Training Loss: 0.0923%\n",
      "Epoch [65/300], Step [169/225], Training Accuracy: 96.9675%, Training Loss: 0.0924%\n",
      "Epoch [65/300], Step [170/225], Training Accuracy: 96.9577%, Training Loss: 0.0926%\n",
      "Epoch [65/300], Step [171/225], Training Accuracy: 96.9481%, Training Loss: 0.0927%\n",
      "Epoch [65/300], Step [172/225], Training Accuracy: 96.9658%, Training Loss: 0.0925%\n",
      "Epoch [65/300], Step [173/225], Training Accuracy: 96.9563%, Training Loss: 0.0927%\n",
      "Epoch [65/300], Step [174/225], Training Accuracy: 96.9468%, Training Loss: 0.0931%\n",
      "Epoch [65/300], Step [175/225], Training Accuracy: 96.9464%, Training Loss: 0.0929%\n",
      "Epoch [65/300], Step [176/225], Training Accuracy: 96.9460%, Training Loss: 0.0931%\n",
      "Epoch [65/300], Step [177/225], Training Accuracy: 96.9633%, Training Loss: 0.0928%\n",
      "Epoch [65/300], Step [178/225], Training Accuracy: 96.9628%, Training Loss: 0.0929%\n",
      "Epoch [65/300], Step [179/225], Training Accuracy: 96.9797%, Training Loss: 0.0925%\n",
      "Epoch [65/300], Step [180/225], Training Accuracy: 96.9705%, Training Loss: 0.0924%\n",
      "Epoch [65/300], Step [181/225], Training Accuracy: 96.9700%, Training Loss: 0.0926%\n",
      "Epoch [65/300], Step [182/225], Training Accuracy: 96.9780%, Training Loss: 0.0926%\n",
      "Epoch [65/300], Step [183/225], Training Accuracy: 96.9775%, Training Loss: 0.0924%\n",
      "Epoch [65/300], Step [184/225], Training Accuracy: 96.9939%, Training Loss: 0.0921%\n",
      "Epoch [65/300], Step [185/225], Training Accuracy: 97.0017%, Training Loss: 0.0919%\n",
      "Epoch [65/300], Step [186/225], Training Accuracy: 97.0094%, Training Loss: 0.0918%\n",
      "Epoch [65/300], Step [187/225], Training Accuracy: 96.9920%, Training Loss: 0.0921%\n",
      "Epoch [65/300], Step [188/225], Training Accuracy: 96.9830%, Training Loss: 0.0922%\n",
      "Epoch [65/300], Step [189/225], Training Accuracy: 96.9825%, Training Loss: 0.0920%\n",
      "Epoch [65/300], Step [190/225], Training Accuracy: 96.9819%, Training Loss: 0.0922%\n",
      "Epoch [65/300], Step [191/225], Training Accuracy: 96.9977%, Training Loss: 0.0920%\n",
      "Epoch [65/300], Step [192/225], Training Accuracy: 96.9971%, Training Loss: 0.0920%\n",
      "Epoch [65/300], Step [193/225], Training Accuracy: 96.9964%, Training Loss: 0.0922%\n",
      "Epoch [65/300], Step [194/225], Training Accuracy: 96.9958%, Training Loss: 0.0922%\n",
      "Epoch [65/300], Step [195/225], Training Accuracy: 96.9872%, Training Loss: 0.0926%\n",
      "Epoch [65/300], Step [196/225], Training Accuracy: 97.0026%, Training Loss: 0.0925%\n",
      "Epoch [65/300], Step [197/225], Training Accuracy: 96.9543%, Training Loss: 0.0932%\n",
      "Epoch [65/300], Step [198/225], Training Accuracy: 96.9302%, Training Loss: 0.0935%\n",
      "Epoch [65/300], Step [199/225], Training Accuracy: 96.9378%, Training Loss: 0.0934%\n",
      "Epoch [65/300], Step [200/225], Training Accuracy: 96.9531%, Training Loss: 0.0932%\n",
      "Epoch [65/300], Step [201/225], Training Accuracy: 96.9372%, Training Loss: 0.0932%\n",
      "Epoch [65/300], Step [202/225], Training Accuracy: 96.9446%, Training Loss: 0.0930%\n",
      "Epoch [65/300], Step [203/225], Training Accuracy: 96.9443%, Training Loss: 0.0931%\n",
      "Epoch [65/300], Step [204/225], Training Accuracy: 96.9286%, Training Loss: 0.0932%\n",
      "Epoch [65/300], Step [205/225], Training Accuracy: 96.9360%, Training Loss: 0.0931%\n",
      "Epoch [65/300], Step [206/225], Training Accuracy: 96.9433%, Training Loss: 0.0931%\n",
      "Epoch [65/300], Step [207/225], Training Accuracy: 96.9505%, Training Loss: 0.0930%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/300], Step [208/225], Training Accuracy: 96.9501%, Training Loss: 0.0929%\n",
      "Epoch [65/300], Step [209/225], Training Accuracy: 96.9423%, Training Loss: 0.0929%\n",
      "Epoch [65/300], Step [210/225], Training Accuracy: 96.9494%, Training Loss: 0.0929%\n",
      "Epoch [65/300], Step [211/225], Training Accuracy: 96.9639%, Training Loss: 0.0928%\n",
      "Epoch [65/300], Step [212/225], Training Accuracy: 96.9708%, Training Loss: 0.0927%\n",
      "Epoch [65/300], Step [213/225], Training Accuracy: 96.9777%, Training Loss: 0.0925%\n",
      "Epoch [65/300], Step [214/225], Training Accuracy: 96.9772%, Training Loss: 0.0924%\n",
      "Epoch [65/300], Step [215/225], Training Accuracy: 96.9695%, Training Loss: 0.0925%\n",
      "Epoch [65/300], Step [216/225], Training Accuracy: 96.9546%, Training Loss: 0.0930%\n",
      "Epoch [65/300], Step [217/225], Training Accuracy: 96.9542%, Training Loss: 0.0929%\n",
      "Epoch [65/300], Step [218/225], Training Accuracy: 96.9538%, Training Loss: 0.0929%\n",
      "Epoch [65/300], Step [219/225], Training Accuracy: 96.9463%, Training Loss: 0.0930%\n",
      "Epoch [65/300], Step [220/225], Training Accuracy: 96.9531%, Training Loss: 0.0929%\n",
      "Epoch [65/300], Step [221/225], Training Accuracy: 96.9598%, Training Loss: 0.0928%\n",
      "Epoch [65/300], Step [222/225], Training Accuracy: 96.9524%, Training Loss: 0.0930%\n",
      "Epoch [65/300], Step [223/225], Training Accuracy: 96.9591%, Training Loss: 0.0928%\n",
      "Epoch [65/300], Step [224/225], Training Accuracy: 96.9587%, Training Loss: 0.0928%\n",
      "Epoch [65/300], Step [225/225], Training Accuracy: 96.9566%, Training Loss: 0.0927%\n",
      "Epoch [66/300], Step [1/225], Training Accuracy: 98.4375%, Training Loss: 0.0698%\n",
      "Epoch [66/300], Step [2/225], Training Accuracy: 98.4375%, Training Loss: 0.0664%\n",
      "Epoch [66/300], Step [3/225], Training Accuracy: 98.4375%, Training Loss: 0.0639%\n",
      "Epoch [66/300], Step [4/225], Training Accuracy: 98.0469%, Training Loss: 0.0663%\n",
      "Epoch [66/300], Step [5/225], Training Accuracy: 97.5000%, Training Loss: 0.0681%\n",
      "Epoch [66/300], Step [6/225], Training Accuracy: 97.1354%, Training Loss: 0.0725%\n",
      "Epoch [66/300], Step [7/225], Training Accuracy: 97.0982%, Training Loss: 0.0761%\n",
      "Epoch [66/300], Step [8/225], Training Accuracy: 97.4609%, Training Loss: 0.0716%\n",
      "Epoch [66/300], Step [9/225], Training Accuracy: 97.2222%, Training Loss: 0.0729%\n",
      "Epoch [66/300], Step [10/225], Training Accuracy: 97.1875%, Training Loss: 0.0773%\n",
      "Epoch [66/300], Step [11/225], Training Accuracy: 97.4432%, Training Loss: 0.0748%\n",
      "Epoch [66/300], Step [12/225], Training Accuracy: 97.1354%, Training Loss: 0.0774%\n",
      "Epoch [66/300], Step [13/225], Training Accuracy: 97.2356%, Training Loss: 0.0756%\n",
      "Epoch [66/300], Step [14/225], Training Accuracy: 97.3214%, Training Loss: 0.0751%\n",
      "Epoch [66/300], Step [15/225], Training Accuracy: 97.2917%, Training Loss: 0.0743%\n",
      "Epoch [66/300], Step [16/225], Training Accuracy: 97.2656%, Training Loss: 0.0764%\n",
      "Epoch [66/300], Step [17/225], Training Accuracy: 97.1507%, Training Loss: 0.0774%\n",
      "Epoch [66/300], Step [18/225], Training Accuracy: 97.0486%, Training Loss: 0.0805%\n",
      "Epoch [66/300], Step [19/225], Training Accuracy: 96.9572%, Training Loss: 0.0832%\n",
      "Epoch [66/300], Step [20/225], Training Accuracy: 96.9531%, Training Loss: 0.0838%\n",
      "Epoch [66/300], Step [21/225], Training Accuracy: 96.9494%, Training Loss: 0.0848%\n",
      "Epoch [66/300], Step [22/225], Training Accuracy: 96.8040%, Training Loss: 0.0885%\n",
      "Epoch [66/300], Step [23/225], Training Accuracy: 96.8750%, Training Loss: 0.0913%\n",
      "Epoch [66/300], Step [24/225], Training Accuracy: 96.8099%, Training Loss: 0.0921%\n",
      "Epoch [66/300], Step [25/225], Training Accuracy: 96.8125%, Training Loss: 0.0925%\n",
      "Epoch [66/300], Step [26/225], Training Accuracy: 96.8149%, Training Loss: 0.0927%\n",
      "Epoch [66/300], Step [27/225], Training Accuracy: 96.8171%, Training Loss: 0.0921%\n",
      "Epoch [66/300], Step [28/225], Training Accuracy: 96.8750%, Training Loss: 0.0911%\n",
      "Epoch [66/300], Step [29/225], Training Accuracy: 96.8750%, Training Loss: 0.0916%\n",
      "Epoch [66/300], Step [30/225], Training Accuracy: 96.9271%, Training Loss: 0.0934%\n",
      "Epoch [66/300], Step [31/225], Training Accuracy: 96.9758%, Training Loss: 0.0927%\n",
      "Epoch [66/300], Step [32/225], Training Accuracy: 97.0215%, Training Loss: 0.0915%\n",
      "Epoch [66/300], Step [33/225], Training Accuracy: 97.0170%, Training Loss: 0.0910%\n",
      "Epoch [66/300], Step [34/225], Training Accuracy: 97.0588%, Training Loss: 0.0930%\n",
      "Epoch [66/300], Step [35/225], Training Accuracy: 97.0982%, Training Loss: 0.0926%\n",
      "Epoch [66/300], Step [36/225], Training Accuracy: 97.1788%, Training Loss: 0.0910%\n",
      "Epoch [66/300], Step [37/225], Training Accuracy: 97.2551%, Training Loss: 0.0898%\n",
      "Epoch [66/300], Step [38/225], Training Accuracy: 97.2039%, Training Loss: 0.0909%\n",
      "Epoch [66/300], Step [39/225], Training Accuracy: 97.2356%, Training Loss: 0.0903%\n",
      "Epoch [66/300], Step [40/225], Training Accuracy: 97.2266%, Training Loss: 0.0898%\n",
      "Epoch [66/300], Step [41/225], Training Accuracy: 97.1418%, Training Loss: 0.0903%\n",
      "Epoch [66/300], Step [42/225], Training Accuracy: 97.0610%, Training Loss: 0.0906%\n",
      "Epoch [66/300], Step [43/225], Training Accuracy: 97.0203%, Training Loss: 0.0908%\n",
      "Epoch [66/300], Step [44/225], Training Accuracy: 96.9815%, Training Loss: 0.0911%\n",
      "Epoch [66/300], Step [45/225], Training Accuracy: 96.9444%, Training Loss: 0.0912%\n",
      "Epoch [66/300], Step [46/225], Training Accuracy: 97.0109%, Training Loss: 0.0895%\n",
      "Epoch [66/300], Step [47/225], Training Accuracy: 97.0412%, Training Loss: 0.0906%\n",
      "Epoch [66/300], Step [48/225], Training Accuracy: 96.9727%, Training Loss: 0.0919%\n",
      "Epoch [66/300], Step [49/225], Training Accuracy: 96.9388%, Training Loss: 0.0916%\n",
      "Epoch [66/300], Step [50/225], Training Accuracy: 96.9062%, Training Loss: 0.0918%\n",
      "Epoch [66/300], Step [51/225], Training Accuracy: 96.9056%, Training Loss: 0.0919%\n",
      "Epoch [66/300], Step [52/225], Training Accuracy: 96.9050%, Training Loss: 0.0920%\n",
      "Epoch [66/300], Step [53/225], Training Accuracy: 96.9634%, Training Loss: 0.0912%\n",
      "Epoch [66/300], Step [54/225], Training Accuracy: 96.8171%, Training Loss: 0.0931%\n",
      "Epoch [66/300], Step [55/225], Training Accuracy: 96.7330%, Training Loss: 0.0942%\n",
      "Epoch [66/300], Step [56/225], Training Accuracy: 96.6518%, Training Loss: 0.0954%\n",
      "Epoch [66/300], Step [57/225], Training Accuracy: 96.6283%, Training Loss: 0.0951%\n",
      "Epoch [66/300], Step [58/225], Training Accuracy: 96.6056%, Training Loss: 0.0951%\n",
      "Epoch [66/300], Step [59/225], Training Accuracy: 96.6631%, Training Loss: 0.0945%\n",
      "Epoch [66/300], Step [60/225], Training Accuracy: 96.6927%, Training Loss: 0.0938%\n",
      "Epoch [66/300], Step [61/225], Training Accuracy: 96.6701%, Training Loss: 0.0947%\n",
      "Epoch [66/300], Step [62/225], Training Accuracy: 96.6734%, Training Loss: 0.0948%\n",
      "Epoch [66/300], Step [63/225], Training Accuracy: 96.6766%, Training Loss: 0.0949%\n",
      "Epoch [66/300], Step [64/225], Training Accuracy: 96.6797%, Training Loss: 0.0949%\n",
      "Epoch [66/300], Step [65/225], Training Accuracy: 96.6346%, Training Loss: 0.0950%\n",
      "Epoch [66/300], Step [66/225], Training Accuracy: 96.6619%, Training Loss: 0.0950%\n",
      "Epoch [66/300], Step [67/225], Training Accuracy: 96.6651%, Training Loss: 0.0950%\n",
      "Epoch [66/300], Step [68/225], Training Accuracy: 96.6682%, Training Loss: 0.0952%\n",
      "Epoch [66/300], Step [69/225], Training Accuracy: 96.7165%, Training Loss: 0.0944%\n",
      "Epoch [66/300], Step [70/225], Training Accuracy: 96.7411%, Training Loss: 0.0938%\n",
      "Epoch [66/300], Step [71/225], Training Accuracy: 96.7430%, Training Loss: 0.0942%\n",
      "Epoch [66/300], Step [72/225], Training Accuracy: 96.7448%, Training Loss: 0.0939%\n",
      "Epoch [66/300], Step [73/225], Training Accuracy: 96.7680%, Training Loss: 0.0942%\n",
      "Epoch [66/300], Step [74/225], Training Accuracy: 96.7694%, Training Loss: 0.0945%\n",
      "Epoch [66/300], Step [75/225], Training Accuracy: 96.7708%, Training Loss: 0.0946%\n",
      "Epoch [66/300], Step [76/225], Training Accuracy: 96.7105%, Training Loss: 0.0963%\n",
      "Epoch [66/300], Step [77/225], Training Accuracy: 96.7127%, Training Loss: 0.0961%\n",
      "Epoch [66/300], Step [78/225], Training Accuracy: 96.7348%, Training Loss: 0.0956%\n",
      "Epoch [66/300], Step [79/225], Training Accuracy: 96.7168%, Training Loss: 0.0958%\n",
      "Epoch [66/300], Step [80/225], Training Accuracy: 96.7383%, Training Loss: 0.0957%\n",
      "Epoch [66/300], Step [81/225], Training Accuracy: 96.7593%, Training Loss: 0.0954%\n",
      "Epoch [66/300], Step [82/225], Training Accuracy: 96.7416%, Training Loss: 0.0953%\n",
      "Epoch [66/300], Step [83/225], Training Accuracy: 96.6867%, Training Loss: 0.0961%\n",
      "Epoch [66/300], Step [84/225], Training Accuracy: 96.6890%, Training Loss: 0.0964%\n",
      "Epoch [66/300], Step [85/225], Training Accuracy: 96.7096%, Training Loss: 0.0963%\n",
      "Epoch [66/300], Step [86/225], Training Accuracy: 96.7115%, Training Loss: 0.0963%\n",
      "Epoch [66/300], Step [87/225], Training Accuracy: 96.6415%, Training Loss: 0.0966%\n",
      "Epoch [66/300], Step [88/225], Training Accuracy: 96.6087%, Training Loss: 0.0967%\n",
      "Epoch [66/300], Step [89/225], Training Accuracy: 96.6117%, Training Loss: 0.0967%\n",
      "Epoch [66/300], Step [90/225], Training Accuracy: 96.6319%, Training Loss: 0.0963%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/300], Step [91/225], Training Accuracy: 96.6174%, Training Loss: 0.0962%\n",
      "Epoch [66/300], Step [92/225], Training Accuracy: 96.6202%, Training Loss: 0.0962%\n",
      "Epoch [66/300], Step [93/225], Training Accuracy: 96.6230%, Training Loss: 0.0960%\n",
      "Epoch [66/300], Step [94/225], Training Accuracy: 96.6589%, Training Loss: 0.0957%\n",
      "Epoch [66/300], Step [95/225], Training Accuracy: 96.6447%, Training Loss: 0.0958%\n",
      "Epoch [66/300], Step [96/225], Training Accuracy: 96.6471%, Training Loss: 0.0956%\n",
      "Epoch [66/300], Step [97/225], Training Accuracy: 96.6495%, Training Loss: 0.0954%\n",
      "Epoch [66/300], Step [98/225], Training Accuracy: 96.6518%, Training Loss: 0.0958%\n",
      "Epoch [66/300], Step [99/225], Training Accuracy: 96.6383%, Training Loss: 0.0961%\n",
      "Epoch [66/300], Step [100/225], Training Accuracy: 96.6406%, Training Loss: 0.0960%\n",
      "Epoch [66/300], Step [101/225], Training Accuracy: 96.6120%, Training Loss: 0.0959%\n",
      "Epoch [66/300], Step [102/225], Training Accuracy: 96.6299%, Training Loss: 0.0956%\n",
      "Epoch [66/300], Step [103/225], Training Accuracy: 96.6171%, Training Loss: 0.0965%\n",
      "Epoch [66/300], Step [104/225], Training Accuracy: 96.6496%, Training Loss: 0.0958%\n",
      "Epoch [66/300], Step [105/225], Training Accuracy: 96.6369%, Training Loss: 0.0959%\n",
      "Epoch [66/300], Step [106/225], Training Accuracy: 96.6244%, Training Loss: 0.0964%\n",
      "Epoch [66/300], Step [107/225], Training Accuracy: 96.6268%, Training Loss: 0.0962%\n",
      "Epoch [66/300], Step [108/225], Training Accuracy: 96.6291%, Training Loss: 0.0964%\n",
      "Epoch [66/300], Step [109/225], Training Accuracy: 96.6456%, Training Loss: 0.0960%\n",
      "Epoch [66/300], Step [110/225], Training Accuracy: 96.6335%, Training Loss: 0.0958%\n",
      "Epoch [66/300], Step [111/225], Training Accuracy: 96.6357%, Training Loss: 0.0955%\n",
      "Epoch [66/300], Step [112/225], Training Accuracy: 96.6239%, Training Loss: 0.0959%\n",
      "Epoch [66/300], Step [113/225], Training Accuracy: 96.6261%, Training Loss: 0.0956%\n",
      "Epoch [66/300], Step [114/225], Training Accuracy: 96.6420%, Training Loss: 0.0953%\n",
      "Epoch [66/300], Step [115/225], Training Accuracy: 96.6168%, Training Loss: 0.0958%\n",
      "Epoch [66/300], Step [116/225], Training Accuracy: 96.6460%, Training Loss: 0.0955%\n",
      "Epoch [66/300], Step [117/225], Training Accuracy: 96.6480%, Training Loss: 0.0956%\n",
      "Epoch [66/300], Step [118/225], Training Accuracy: 96.6234%, Training Loss: 0.0959%\n",
      "Epoch [66/300], Step [119/225], Training Accuracy: 96.5993%, Training Loss: 0.0964%\n",
      "Epoch [66/300], Step [120/225], Training Accuracy: 96.6016%, Training Loss: 0.0966%\n",
      "Epoch [66/300], Step [121/225], Training Accuracy: 96.6296%, Training Loss: 0.0963%\n",
      "Epoch [66/300], Step [122/225], Training Accuracy: 96.6317%, Training Loss: 0.0962%\n",
      "Epoch [66/300], Step [123/225], Training Accuracy: 96.5955%, Training Loss: 0.0966%\n",
      "Epoch [66/300], Step [124/225], Training Accuracy: 96.5852%, Training Loss: 0.0970%\n",
      "Epoch [66/300], Step [125/225], Training Accuracy: 96.5875%, Training Loss: 0.0967%\n",
      "Epoch [66/300], Step [126/225], Training Accuracy: 96.6022%, Training Loss: 0.0966%\n",
      "Epoch [66/300], Step [127/225], Training Accuracy: 96.6166%, Training Loss: 0.0966%\n",
      "Epoch [66/300], Step [128/225], Training Accuracy: 96.6064%, Training Loss: 0.0966%\n",
      "Epoch [66/300], Step [129/225], Training Accuracy: 96.6206%, Training Loss: 0.0965%\n",
      "Epoch [66/300], Step [130/225], Training Accuracy: 96.6106%, Training Loss: 0.0969%\n",
      "Epoch [66/300], Step [131/225], Training Accuracy: 96.6126%, Training Loss: 0.0971%\n",
      "Epoch [66/300], Step [132/225], Training Accuracy: 96.6146%, Training Loss: 0.0973%\n",
      "Epoch [66/300], Step [133/225], Training Accuracy: 96.6048%, Training Loss: 0.0975%\n",
      "Epoch [66/300], Step [134/225], Training Accuracy: 96.6185%, Training Loss: 0.0972%\n",
      "Epoch [66/300], Step [135/225], Training Accuracy: 96.6088%, Training Loss: 0.0970%\n",
      "Epoch [66/300], Step [136/225], Training Accuracy: 96.5993%, Training Loss: 0.0972%\n",
      "Epoch [66/300], Step [137/225], Training Accuracy: 96.6127%, Training Loss: 0.0974%\n",
      "Epoch [66/300], Step [138/225], Training Accuracy: 96.6033%, Training Loss: 0.0974%\n",
      "Epoch [66/300], Step [139/225], Training Accuracy: 96.5490%, Training Loss: 0.0983%\n",
      "Epoch [66/300], Step [140/225], Training Accuracy: 96.5625%, Training Loss: 0.0980%\n",
      "Epoch [66/300], Step [141/225], Training Accuracy: 96.5204%, Training Loss: 0.0989%\n",
      "Epoch [66/300], Step [142/225], Training Accuracy: 96.5449%, Training Loss: 0.0985%\n",
      "Epoch [66/300], Step [143/225], Training Accuracy: 96.5472%, Training Loss: 0.0983%\n",
      "Epoch [66/300], Step [144/225], Training Accuracy: 96.5495%, Training Loss: 0.0981%\n",
      "Epoch [66/300], Step [145/225], Training Accuracy: 96.5302%, Training Loss: 0.0983%\n",
      "Epoch [66/300], Step [146/225], Training Accuracy: 96.5432%, Training Loss: 0.0981%\n",
      "Epoch [66/300], Step [147/225], Training Accuracy: 96.5455%, Training Loss: 0.0979%\n",
      "Epoch [66/300], Step [148/225], Training Accuracy: 96.5477%, Training Loss: 0.0980%\n",
      "Epoch [66/300], Step [149/225], Training Accuracy: 96.5394%, Training Loss: 0.0982%\n",
      "Epoch [66/300], Step [150/225], Training Accuracy: 96.5521%, Training Loss: 0.0980%\n",
      "Epoch [66/300], Step [151/225], Training Accuracy: 96.5542%, Training Loss: 0.0979%\n",
      "Epoch [66/300], Step [152/225], Training Accuracy: 96.5461%, Training Loss: 0.0979%\n",
      "Epoch [66/300], Step [153/225], Training Accuracy: 96.5482%, Training Loss: 0.0978%\n",
      "Epoch [66/300], Step [154/225], Training Accuracy: 96.5199%, Training Loss: 0.0982%\n",
      "Epoch [66/300], Step [155/225], Training Accuracy: 96.5323%, Training Loss: 0.0979%\n",
      "Epoch [66/300], Step [156/225], Training Accuracy: 96.5445%, Training Loss: 0.0975%\n",
      "Epoch [66/300], Step [157/225], Training Accuracy: 96.5466%, Training Loss: 0.0977%\n",
      "Epoch [66/300], Step [158/225], Training Accuracy: 96.5585%, Training Loss: 0.0974%\n",
      "Epoch [66/300], Step [159/225], Training Accuracy: 96.5507%, Training Loss: 0.0979%\n",
      "Epoch [66/300], Step [160/225], Training Accuracy: 96.5527%, Training Loss: 0.0977%\n",
      "Epoch [66/300], Step [161/225], Training Accuracy: 96.5450%, Training Loss: 0.0976%\n",
      "Epoch [66/300], Step [162/225], Training Accuracy: 96.5567%, Training Loss: 0.0977%\n",
      "Epoch [66/300], Step [163/225], Training Accuracy: 96.5778%, Training Loss: 0.0976%\n",
      "Epoch [66/300], Step [164/225], Training Accuracy: 96.5701%, Training Loss: 0.0978%\n",
      "Epoch [66/300], Step [165/225], Training Accuracy: 96.5720%, Training Loss: 0.0978%\n",
      "Epoch [66/300], Step [166/225], Training Accuracy: 96.5832%, Training Loss: 0.0975%\n",
      "Epoch [66/300], Step [167/225], Training Accuracy: 96.5850%, Training Loss: 0.0974%\n",
      "Epoch [66/300], Step [168/225], Training Accuracy: 96.5960%, Training Loss: 0.0972%\n",
      "Epoch [66/300], Step [169/225], Training Accuracy: 96.5976%, Training Loss: 0.0969%\n",
      "Epoch [66/300], Step [170/225], Training Accuracy: 96.5901%, Training Loss: 0.0968%\n",
      "Epoch [66/300], Step [171/225], Training Accuracy: 96.6100%, Training Loss: 0.0965%\n",
      "Epoch [66/300], Step [172/225], Training Accuracy: 96.6025%, Training Loss: 0.0965%\n",
      "Epoch [66/300], Step [173/225], Training Accuracy: 96.6131%, Training Loss: 0.0962%\n",
      "Epoch [66/300], Step [174/225], Training Accuracy: 96.6325%, Training Loss: 0.0959%\n",
      "Epoch [66/300], Step [175/225], Training Accuracy: 96.6518%, Training Loss: 0.0956%\n",
      "Epoch [66/300], Step [176/225], Training Accuracy: 96.6442%, Training Loss: 0.0956%\n",
      "Epoch [66/300], Step [177/225], Training Accuracy: 96.6543%, Training Loss: 0.0954%\n",
      "Epoch [66/300], Step [178/225], Training Accuracy: 96.6643%, Training Loss: 0.0954%\n",
      "Epoch [66/300], Step [179/225], Training Accuracy: 96.6655%, Training Loss: 0.0953%\n",
      "Epoch [66/300], Step [180/225], Training Accuracy: 96.6406%, Training Loss: 0.0955%\n",
      "Epoch [66/300], Step [181/225], Training Accuracy: 96.6419%, Training Loss: 0.0955%\n",
      "Epoch [66/300], Step [182/225], Training Accuracy: 96.6432%, Training Loss: 0.0955%\n",
      "Epoch [66/300], Step [183/225], Training Accuracy: 96.6530%, Training Loss: 0.0952%\n",
      "Epoch [66/300], Step [184/225], Training Accuracy: 96.6542%, Training Loss: 0.0953%\n",
      "Epoch [66/300], Step [185/225], Training Accuracy: 96.6639%, Training Loss: 0.0953%\n",
      "Epoch [66/300], Step [186/225], Training Accuracy: 96.6818%, Training Loss: 0.0949%\n",
      "Epoch [66/300], Step [187/225], Training Accuracy: 96.6912%, Training Loss: 0.0947%\n",
      "Epoch [66/300], Step [188/225], Training Accuracy: 96.6922%, Training Loss: 0.0946%\n",
      "Epoch [66/300], Step [189/225], Training Accuracy: 96.6849%, Training Loss: 0.0950%\n",
      "Epoch [66/300], Step [190/225], Training Accuracy: 96.6859%, Training Loss: 0.0950%\n",
      "Epoch [66/300], Step [191/225], Training Accuracy: 96.6950%, Training Loss: 0.0948%\n",
      "Epoch [66/300], Step [192/225], Training Accuracy: 96.6960%, Training Loss: 0.0947%\n",
      "Epoch [66/300], Step [193/225], Training Accuracy: 96.6807%, Training Loss: 0.0953%\n",
      "Epoch [66/300], Step [194/225], Training Accuracy: 96.6898%, Training Loss: 0.0951%\n",
      "Epoch [66/300], Step [195/225], Training Accuracy: 96.6907%, Training Loss: 0.0953%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/300], Step [196/225], Training Accuracy: 96.6837%, Training Loss: 0.0957%\n",
      "Epoch [66/300], Step [197/225], Training Accuracy: 96.6846%, Training Loss: 0.0955%\n",
      "Epoch [66/300], Step [198/225], Training Accuracy: 96.6777%, Training Loss: 0.0959%\n",
      "Epoch [66/300], Step [199/225], Training Accuracy: 96.6552%, Training Loss: 0.0961%\n",
      "Epoch [66/300], Step [200/225], Training Accuracy: 96.6406%, Training Loss: 0.0962%\n",
      "Epoch [66/300], Step [201/225], Training Accuracy: 96.6185%, Training Loss: 0.0967%\n",
      "Epoch [66/300], Step [202/225], Training Accuracy: 96.6197%, Training Loss: 0.0967%\n",
      "Epoch [66/300], Step [203/225], Training Accuracy: 96.6287%, Training Loss: 0.0967%\n",
      "Epoch [66/300], Step [204/225], Training Accuracy: 96.6299%, Training Loss: 0.0967%\n",
      "Epoch [66/300], Step [205/225], Training Accuracy: 96.6463%, Training Loss: 0.0964%\n",
      "Epoch [66/300], Step [206/225], Training Accuracy: 96.6247%, Training Loss: 0.0967%\n",
      "Epoch [66/300], Step [207/225], Training Accuracy: 96.6410%, Training Loss: 0.0965%\n",
      "Epoch [66/300], Step [208/225], Training Accuracy: 96.6421%, Training Loss: 0.0964%\n",
      "Epoch [66/300], Step [209/225], Training Accuracy: 96.6507%, Training Loss: 0.0965%\n",
      "Epoch [66/300], Step [210/225], Training Accuracy: 96.6592%, Training Loss: 0.0963%\n",
      "Epoch [66/300], Step [211/225], Training Accuracy: 96.6528%, Training Loss: 0.0966%\n",
      "Epoch [66/300], Step [212/225], Training Accuracy: 96.6686%, Training Loss: 0.0963%\n",
      "Epoch [66/300], Step [213/225], Training Accuracy: 96.6696%, Training Loss: 0.0962%\n",
      "Epoch [66/300], Step [214/225], Training Accuracy: 96.6706%, Training Loss: 0.0962%\n",
      "Epoch [66/300], Step [215/225], Training Accuracy: 96.6642%, Training Loss: 0.0963%\n",
      "Epoch [66/300], Step [216/225], Training Accuracy: 96.6363%, Training Loss: 0.0969%\n",
      "Epoch [66/300], Step [217/225], Training Accuracy: 96.6302%, Training Loss: 0.0968%\n",
      "Epoch [66/300], Step [218/225], Training Accuracy: 96.6313%, Training Loss: 0.0967%\n",
      "Epoch [66/300], Step [219/225], Training Accuracy: 96.6253%, Training Loss: 0.0968%\n",
      "Epoch [66/300], Step [220/225], Training Accuracy: 96.6264%, Training Loss: 0.0968%\n",
      "Epoch [66/300], Step [221/225], Training Accuracy: 96.6346%, Training Loss: 0.0967%\n",
      "Epoch [66/300], Step [222/225], Training Accuracy: 96.6427%, Training Loss: 0.0966%\n",
      "Epoch [66/300], Step [223/225], Training Accuracy: 96.6438%, Training Loss: 0.0967%\n",
      "Epoch [66/300], Step [224/225], Training Accuracy: 96.6309%, Training Loss: 0.0971%\n",
      "Epoch [66/300], Step [225/225], Training Accuracy: 96.6162%, Training Loss: 0.0976%\n",
      "Epoch [67/300], Step [1/225], Training Accuracy: 95.3125%, Training Loss: 0.1255%\n",
      "Epoch [67/300], Step [2/225], Training Accuracy: 96.8750%, Training Loss: 0.1241%\n",
      "Epoch [67/300], Step [3/225], Training Accuracy: 96.8750%, Training Loss: 0.1208%\n",
      "Epoch [67/300], Step [4/225], Training Accuracy: 96.4844%, Training Loss: 0.1113%\n",
      "Epoch [67/300], Step [5/225], Training Accuracy: 96.8750%, Training Loss: 0.0980%\n",
      "Epoch [67/300], Step [6/225], Training Accuracy: 96.3542%, Training Loss: 0.1009%\n",
      "Epoch [67/300], Step [7/225], Training Accuracy: 96.2054%, Training Loss: 0.1014%\n",
      "Epoch [67/300], Step [8/225], Training Accuracy: 96.0938%, Training Loss: 0.1014%\n",
      "Epoch [67/300], Step [9/225], Training Accuracy: 96.0069%, Training Loss: 0.1038%\n",
      "Epoch [67/300], Step [10/225], Training Accuracy: 95.6250%, Training Loss: 0.1108%\n",
      "Epoch [67/300], Step [11/225], Training Accuracy: 95.5966%, Training Loss: 0.1137%\n",
      "Epoch [67/300], Step [12/225], Training Accuracy: 95.8333%, Training Loss: 0.1109%\n",
      "Epoch [67/300], Step [13/225], Training Accuracy: 95.7933%, Training Loss: 0.1119%\n",
      "Epoch [67/300], Step [14/225], Training Accuracy: 96.0938%, Training Loss: 0.1070%\n",
      "Epoch [67/300], Step [15/225], Training Accuracy: 95.9375%, Training Loss: 0.1081%\n",
      "Epoch [67/300], Step [16/225], Training Accuracy: 95.8984%, Training Loss: 0.1065%\n",
      "Epoch [67/300], Step [17/225], Training Accuracy: 96.1397%, Training Loss: 0.1034%\n",
      "Epoch [67/300], Step [18/225], Training Accuracy: 96.0069%, Training Loss: 0.1094%\n",
      "Epoch [67/300], Step [19/225], Training Accuracy: 96.1349%, Training Loss: 0.1074%\n",
      "Epoch [67/300], Step [20/225], Training Accuracy: 96.2500%, Training Loss: 0.1046%\n",
      "Epoch [67/300], Step [21/225], Training Accuracy: 96.3542%, Training Loss: 0.1034%\n",
      "Epoch [67/300], Step [22/225], Training Accuracy: 96.3778%, Training Loss: 0.1059%\n",
      "Epoch [67/300], Step [23/225], Training Accuracy: 96.3995%, Training Loss: 0.1044%\n",
      "Epoch [67/300], Step [24/225], Training Accuracy: 96.4193%, Training Loss: 0.1029%\n",
      "Epoch [67/300], Step [25/225], Training Accuracy: 96.5000%, Training Loss: 0.1011%\n",
      "Epoch [67/300], Step [26/225], Training Accuracy: 96.5745%, Training Loss: 0.1006%\n",
      "Epoch [67/300], Step [27/225], Training Accuracy: 96.5278%, Training Loss: 0.1013%\n",
      "Epoch [67/300], Step [28/225], Training Accuracy: 96.5402%, Training Loss: 0.1000%\n",
      "Epoch [67/300], Step [29/225], Training Accuracy: 96.5517%, Training Loss: 0.0998%\n",
      "Epoch [67/300], Step [30/225], Training Accuracy: 96.4583%, Training Loss: 0.1007%\n",
      "Epoch [67/300], Step [31/225], Training Accuracy: 96.4718%, Training Loss: 0.1012%\n",
      "Epoch [67/300], Step [32/225], Training Accuracy: 96.4355%, Training Loss: 0.1023%\n",
      "Epoch [67/300], Step [33/225], Training Accuracy: 96.4015%, Training Loss: 0.1021%\n",
      "Epoch [67/300], Step [34/225], Training Accuracy: 96.4154%, Training Loss: 0.1030%\n",
      "Epoch [67/300], Step [35/225], Training Accuracy: 96.4286%, Training Loss: 0.1031%\n",
      "Epoch [67/300], Step [36/225], Training Accuracy: 96.4410%, Training Loss: 0.1020%\n",
      "Epoch [67/300], Step [37/225], Training Accuracy: 96.3260%, Training Loss: 0.1021%\n",
      "Epoch [67/300], Step [38/225], Training Accuracy: 96.3816%, Training Loss: 0.1023%\n",
      "Epoch [67/300], Step [39/225], Training Accuracy: 96.3141%, Training Loss: 0.1045%\n",
      "Epoch [67/300], Step [40/225], Training Accuracy: 96.3281%, Training Loss: 0.1032%\n",
      "Epoch [67/300], Step [41/225], Training Accuracy: 96.3415%, Training Loss: 0.1032%\n",
      "Epoch [67/300], Step [42/225], Training Accuracy: 96.3914%, Training Loss: 0.1022%\n",
      "Epoch [67/300], Step [43/225], Training Accuracy: 96.3663%, Training Loss: 0.1033%\n",
      "Epoch [67/300], Step [44/225], Training Accuracy: 96.4134%, Training Loss: 0.1020%\n",
      "Epoch [67/300], Step [45/225], Training Accuracy: 96.2847%, Training Loss: 0.1033%\n",
      "Epoch [67/300], Step [46/225], Training Accuracy: 96.2976%, Training Loss: 0.1030%\n",
      "Epoch [67/300], Step [47/225], Training Accuracy: 96.2766%, Training Loss: 0.1022%\n",
      "Epoch [67/300], Step [48/225], Training Accuracy: 96.1914%, Training Loss: 0.1027%\n",
      "Epoch [67/300], Step [49/225], Training Accuracy: 96.0778%, Training Loss: 0.1046%\n",
      "Epoch [67/300], Step [50/225], Training Accuracy: 96.0312%, Training Loss: 0.1051%\n",
      "Epoch [67/300], Step [51/225], Training Accuracy: 96.0784%, Training Loss: 0.1048%\n",
      "Epoch [67/300], Step [52/225], Training Accuracy: 96.1538%, Training Loss: 0.1036%\n",
      "Epoch [67/300], Step [53/225], Training Accuracy: 96.1085%, Training Loss: 0.1035%\n",
      "Epoch [67/300], Step [54/225], Training Accuracy: 96.0648%, Training Loss: 0.1039%\n",
      "Epoch [67/300], Step [55/225], Training Accuracy: 96.0795%, Training Loss: 0.1032%\n",
      "Epoch [67/300], Step [56/225], Training Accuracy: 96.0658%, Training Loss: 0.1040%\n",
      "Epoch [67/300], Step [57/225], Training Accuracy: 96.0526%, Training Loss: 0.1036%\n",
      "Epoch [67/300], Step [58/225], Training Accuracy: 96.0938%, Training Loss: 0.1029%\n",
      "Epoch [67/300], Step [59/225], Training Accuracy: 96.0540%, Training Loss: 0.1046%\n",
      "Epoch [67/300], Step [60/225], Training Accuracy: 96.0677%, Training Loss: 0.1039%\n",
      "Epoch [67/300], Step [61/225], Training Accuracy: 96.0553%, Training Loss: 0.1045%\n",
      "Epoch [67/300], Step [62/225], Training Accuracy: 96.0938%, Training Loss: 0.1044%\n",
      "Epoch [67/300], Step [63/225], Training Accuracy: 96.0813%, Training Loss: 0.1042%\n",
      "Epoch [67/300], Step [64/225], Training Accuracy: 96.0693%, Training Loss: 0.1040%\n",
      "Epoch [67/300], Step [65/225], Training Accuracy: 96.1298%, Training Loss: 0.1032%\n",
      "Epoch [67/300], Step [66/225], Training Accuracy: 96.1884%, Training Loss: 0.1023%\n",
      "Epoch [67/300], Step [67/225], Training Accuracy: 96.2220%, Training Loss: 0.1019%\n",
      "Epoch [67/300], Step [68/225], Training Accuracy: 96.1627%, Training Loss: 0.1033%\n",
      "Epoch [67/300], Step [69/225], Training Accuracy: 96.1730%, Training Loss: 0.1026%\n",
      "Epoch [67/300], Step [70/225], Training Accuracy: 96.1830%, Training Loss: 0.1022%\n",
      "Epoch [67/300], Step [71/225], Training Accuracy: 96.2148%, Training Loss: 0.1015%\n",
      "Epoch [67/300], Step [72/225], Training Accuracy: 96.2023%, Training Loss: 0.1014%\n",
      "Epoch [67/300], Step [73/225], Training Accuracy: 96.2115%, Training Loss: 0.1011%\n",
      "Epoch [67/300], Step [74/225], Training Accuracy: 96.1993%, Training Loss: 0.1013%\n",
      "Epoch [67/300], Step [75/225], Training Accuracy: 96.1875%, Training Loss: 0.1013%\n",
      "Epoch [67/300], Step [76/225], Training Accuracy: 96.1554%, Training Loss: 0.1022%\n",
      "Epoch [67/300], Step [77/225], Training Accuracy: 96.1648%, Training Loss: 0.1019%\n",
      "Epoch [67/300], Step [78/225], Training Accuracy: 96.1739%, Training Loss: 0.1018%\n",
      "Epoch [67/300], Step [79/225], Training Accuracy: 96.1630%, Training Loss: 0.1022%\n",
      "Epoch [67/300], Step [80/225], Training Accuracy: 96.1328%, Training Loss: 0.1026%\n",
      "Epoch [67/300], Step [81/225], Training Accuracy: 96.1227%, Training Loss: 0.1029%\n",
      "Epoch [67/300], Step [82/225], Training Accuracy: 96.1128%, Training Loss: 0.1030%\n",
      "Epoch [67/300], Step [83/225], Training Accuracy: 96.1220%, Training Loss: 0.1032%\n",
      "Epoch [67/300], Step [84/225], Training Accuracy: 96.1496%, Training Loss: 0.1032%\n",
      "Epoch [67/300], Step [85/225], Training Accuracy: 96.1581%, Training Loss: 0.1029%\n",
      "Epoch [67/300], Step [86/225], Training Accuracy: 96.1301%, Training Loss: 0.1037%\n",
      "Epoch [67/300], Step [87/225], Training Accuracy: 96.1207%, Training Loss: 0.1039%\n",
      "Epoch [67/300], Step [88/225], Training Accuracy: 96.1293%, Training Loss: 0.1039%\n",
      "Epoch [67/300], Step [89/225], Training Accuracy: 96.1552%, Training Loss: 0.1036%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/300], Step [90/225], Training Accuracy: 96.1806%, Training Loss: 0.1035%\n",
      "Epoch [67/300], Step [91/225], Training Accuracy: 96.2054%, Training Loss: 0.1029%\n",
      "Epoch [67/300], Step [92/225], Training Accuracy: 96.2466%, Training Loss: 0.1020%\n",
      "Epoch [67/300], Step [93/225], Training Accuracy: 96.2702%, Training Loss: 0.1020%\n",
      "Epoch [67/300], Step [94/225], Training Accuracy: 96.2766%, Training Loss: 0.1018%\n",
      "Epoch [67/300], Step [95/225], Training Accuracy: 96.2336%, Training Loss: 0.1027%\n",
      "Epoch [67/300], Step [96/225], Training Accuracy: 96.2728%, Training Loss: 0.1021%\n",
      "Epoch [67/300], Step [97/225], Training Accuracy: 96.2307%, Training Loss: 0.1026%\n",
      "Epoch [67/300], Step [98/225], Training Accuracy: 96.2213%, Training Loss: 0.1028%\n",
      "Epoch [67/300], Step [99/225], Training Accuracy: 96.2121%, Training Loss: 0.1033%\n",
      "Epoch [67/300], Step [100/225], Training Accuracy: 96.2344%, Training Loss: 0.1026%\n",
      "Epoch [67/300], Step [101/225], Training Accuracy: 96.2252%, Training Loss: 0.1025%\n",
      "Epoch [67/300], Step [102/225], Training Accuracy: 96.2469%, Training Loss: 0.1022%\n",
      "Epoch [67/300], Step [103/225], Training Accuracy: 96.2227%, Training Loss: 0.1028%\n",
      "Epoch [67/300], Step [104/225], Training Accuracy: 96.2290%, Training Loss: 0.1025%\n",
      "Epoch [67/300], Step [105/225], Training Accuracy: 96.2054%, Training Loss: 0.1033%\n",
      "Epoch [67/300], Step [106/225], Training Accuracy: 96.1969%, Training Loss: 0.1037%\n",
      "Epoch [67/300], Step [107/225], Training Accuracy: 96.1887%, Training Loss: 0.1036%\n",
      "Epoch [67/300], Step [108/225], Training Accuracy: 96.2240%, Training Loss: 0.1029%\n",
      "Epoch [67/300], Step [109/225], Training Accuracy: 96.2443%, Training Loss: 0.1026%\n",
      "Epoch [67/300], Step [110/225], Training Accuracy: 96.2500%, Training Loss: 0.1024%\n",
      "Epoch [67/300], Step [111/225], Training Accuracy: 96.2697%, Training Loss: 0.1021%\n",
      "Epoch [67/300], Step [112/225], Training Accuracy: 96.3030%, Training Loss: 0.1018%\n",
      "Epoch [67/300], Step [113/225], Training Accuracy: 96.2942%, Training Loss: 0.1017%\n",
      "Epoch [67/300], Step [114/225], Training Accuracy: 96.3130%, Training Loss: 0.1013%\n",
      "Epoch [67/300], Step [115/225], Training Accuracy: 96.3043%, Training Loss: 0.1012%\n",
      "Epoch [67/300], Step [116/225], Training Accuracy: 96.2958%, Training Loss: 0.1015%\n",
      "Epoch [67/300], Step [117/225], Training Accuracy: 96.3007%, Training Loss: 0.1012%\n",
      "Epoch [67/300], Step [118/225], Training Accuracy: 96.3189%, Training Loss: 0.1010%\n",
      "Epoch [67/300], Step [119/225], Training Accuracy: 96.3235%, Training Loss: 0.1007%\n",
      "Epoch [67/300], Step [120/225], Training Accuracy: 96.3542%, Training Loss: 0.1002%\n",
      "Epoch [67/300], Step [121/225], Training Accuracy: 96.3585%, Training Loss: 0.1002%\n",
      "Epoch [67/300], Step [122/225], Training Accuracy: 96.3755%, Training Loss: 0.1001%\n",
      "Epoch [67/300], Step [123/225], Training Accuracy: 96.3923%, Training Loss: 0.1000%\n",
      "Epoch [67/300], Step [124/225], Training Accuracy: 96.4088%, Training Loss: 0.0996%\n",
      "Epoch [67/300], Step [125/225], Training Accuracy: 96.3875%, Training Loss: 0.0999%\n",
      "Epoch [67/300], Step [126/225], Training Accuracy: 96.3914%, Training Loss: 0.0997%\n",
      "Epoch [67/300], Step [127/225], Training Accuracy: 96.3829%, Training Loss: 0.1002%\n",
      "Epoch [67/300], Step [128/225], Training Accuracy: 96.3745%, Training Loss: 0.1002%\n",
      "Epoch [67/300], Step [129/225], Training Accuracy: 96.3663%, Training Loss: 0.1002%\n",
      "Epoch [67/300], Step [130/225], Training Accuracy: 96.3702%, Training Loss: 0.1000%\n",
      "Epoch [67/300], Step [131/225], Training Accuracy: 96.3860%, Training Loss: 0.0998%\n",
      "Epoch [67/300], Step [132/225], Training Accuracy: 96.3542%, Training Loss: 0.1005%\n",
      "Epoch [67/300], Step [133/225], Training Accuracy: 96.3463%, Training Loss: 0.1005%\n",
      "Epoch [67/300], Step [134/225], Training Accuracy: 96.3153%, Training Loss: 0.1014%\n",
      "Epoch [67/300], Step [135/225], Training Accuracy: 96.3194%, Training Loss: 0.1016%\n",
      "Epoch [67/300], Step [136/225], Training Accuracy: 96.3235%, Training Loss: 0.1016%\n",
      "Epoch [67/300], Step [137/225], Training Accuracy: 96.3161%, Training Loss: 0.1013%\n",
      "Epoch [67/300], Step [138/225], Training Accuracy: 96.3315%, Training Loss: 0.1011%\n",
      "Epoch [67/300], Step [139/225], Training Accuracy: 96.3354%, Training Loss: 0.1010%\n",
      "Epoch [67/300], Step [140/225], Training Accuracy: 96.2946%, Training Loss: 0.1011%\n",
      "Epoch [67/300], Step [141/225], Training Accuracy: 96.2544%, Training Loss: 0.1019%\n",
      "Epoch [67/300], Step [142/225], Training Accuracy: 96.2808%, Training Loss: 0.1016%\n",
      "Epoch [67/300], Step [143/225], Training Accuracy: 96.2303%, Training Loss: 0.1020%\n",
      "Epoch [67/300], Step [144/225], Training Accuracy: 96.2240%, Training Loss: 0.1019%\n",
      "Epoch [67/300], Step [145/225], Training Accuracy: 96.2392%, Training Loss: 0.1016%\n",
      "Epoch [67/300], Step [146/225], Training Accuracy: 96.2329%, Training Loss: 0.1018%\n",
      "Epoch [67/300], Step [147/225], Training Accuracy: 96.1947%, Training Loss: 0.1023%\n",
      "Epoch [67/300], Step [148/225], Training Accuracy: 96.1782%, Training Loss: 0.1024%\n",
      "Epoch [67/300], Step [149/225], Training Accuracy: 96.1829%, Training Loss: 0.1023%\n",
      "Epoch [67/300], Step [150/225], Training Accuracy: 96.1667%, Training Loss: 0.1028%\n",
      "Epoch [67/300], Step [151/225], Training Accuracy: 96.1714%, Training Loss: 0.1025%\n",
      "Epoch [67/300], Step [152/225], Training Accuracy: 96.1863%, Training Loss: 0.1023%\n",
      "Epoch [67/300], Step [153/225], Training Accuracy: 96.2010%, Training Loss: 0.1020%\n",
      "Epoch [67/300], Step [154/225], Training Accuracy: 96.2256%, Training Loss: 0.1015%\n",
      "Epoch [67/300], Step [155/225], Training Accuracy: 96.2298%, Training Loss: 0.1012%\n",
      "Epoch [67/300], Step [156/225], Training Accuracy: 96.2340%, Training Loss: 0.1009%\n",
      "Epoch [67/300], Step [157/225], Training Accuracy: 96.2281%, Training Loss: 0.1010%\n",
      "Epoch [67/300], Step [158/225], Training Accuracy: 96.2520%, Training Loss: 0.1005%\n",
      "Epoch [67/300], Step [159/225], Training Accuracy: 96.2756%, Training Loss: 0.1001%\n",
      "Epoch [67/300], Step [160/225], Training Accuracy: 96.2891%, Training Loss: 0.0997%\n",
      "Epoch [67/300], Step [161/225], Training Accuracy: 96.3121%, Training Loss: 0.0993%\n",
      "Epoch [67/300], Step [162/225], Training Accuracy: 96.3156%, Training Loss: 0.0993%\n",
      "Epoch [67/300], Step [163/225], Training Accuracy: 96.3190%, Training Loss: 0.0995%\n",
      "Epoch [67/300], Step [164/225], Training Accuracy: 96.3319%, Training Loss: 0.0992%\n",
      "Epoch [67/300], Step [165/225], Training Accuracy: 96.3258%, Training Loss: 0.0990%\n",
      "Epoch [67/300], Step [166/225], Training Accuracy: 96.3102%, Training Loss: 0.0992%\n",
      "Epoch [67/300], Step [167/225], Training Accuracy: 96.3136%, Training Loss: 0.0990%\n",
      "Epoch [67/300], Step [168/225], Training Accuracy: 96.3263%, Training Loss: 0.0987%\n",
      "Epoch [67/300], Step [169/225], Training Accuracy: 96.3203%, Training Loss: 0.0988%\n",
      "Epoch [67/300], Step [170/225], Training Accuracy: 96.3419%, Training Loss: 0.0984%\n",
      "Epoch [67/300], Step [171/225], Training Accuracy: 96.3176%, Training Loss: 0.0992%\n",
      "Epoch [67/300], Step [172/225], Training Accuracy: 96.3118%, Training Loss: 0.0991%\n",
      "Epoch [67/300], Step [173/225], Training Accuracy: 96.3150%, Training Loss: 0.0990%\n",
      "Epoch [67/300], Step [174/225], Training Accuracy: 96.3362%, Training Loss: 0.0988%\n",
      "Epoch [67/300], Step [175/225], Training Accuracy: 96.3393%, Training Loss: 0.0988%\n",
      "Epoch [67/300], Step [176/225], Training Accuracy: 96.3512%, Training Loss: 0.0985%\n",
      "Epoch [67/300], Step [177/225], Training Accuracy: 96.3718%, Training Loss: 0.0982%\n",
      "Epoch [67/300], Step [178/225], Training Accuracy: 96.3659%, Training Loss: 0.0982%\n",
      "Epoch [67/300], Step [179/225], Training Accuracy: 96.3425%, Training Loss: 0.0986%\n",
      "Epoch [67/300], Step [180/225], Training Accuracy: 96.3281%, Training Loss: 0.0986%\n",
      "Epoch [67/300], Step [181/225], Training Accuracy: 96.3225%, Training Loss: 0.0985%\n",
      "Epoch [67/300], Step [182/225], Training Accuracy: 96.3170%, Training Loss: 0.0984%\n",
      "Epoch [67/300], Step [183/225], Training Accuracy: 96.3115%, Training Loss: 0.0985%\n",
      "Epoch [67/300], Step [184/225], Training Accuracy: 96.2891%, Training Loss: 0.0991%\n",
      "Epoch [67/300], Step [185/225], Training Accuracy: 96.3007%, Training Loss: 0.0989%\n",
      "Epoch [67/300], Step [186/225], Training Accuracy: 96.3206%, Training Loss: 0.0985%\n",
      "Epoch [67/300], Step [187/225], Training Accuracy: 96.3235%, Training Loss: 0.0985%\n",
      "Epoch [67/300], Step [188/225], Training Accuracy: 96.3265%, Training Loss: 0.0985%\n",
      "Epoch [67/300], Step [189/225], Training Accuracy: 96.3294%, Training Loss: 0.0983%\n",
      "Epoch [67/300], Step [190/225], Training Accuracy: 96.3158%, Training Loss: 0.0985%\n",
      "Epoch [67/300], Step [191/225], Training Accuracy: 96.3269%, Training Loss: 0.0983%\n",
      "Epoch [67/300], Step [192/225], Training Accuracy: 96.3379%, Training Loss: 0.0980%\n",
      "Epoch [67/300], Step [193/225], Training Accuracy: 96.3326%, Training Loss: 0.0981%\n",
      "Epoch [67/300], Step [194/225], Training Accuracy: 96.3273%, Training Loss: 0.0982%\n",
      "Epoch [67/300], Step [195/225], Training Accuracy: 96.3301%, Training Loss: 0.0984%\n",
      "Epoch [67/300], Step [196/225], Training Accuracy: 96.3489%, Training Loss: 0.0980%\n",
      "Epoch [67/300], Step [197/225], Training Accuracy: 96.3436%, Training Loss: 0.0982%\n",
      "Epoch [67/300], Step [198/225], Training Accuracy: 96.3305%, Training Loss: 0.0985%\n",
      "Epoch [67/300], Step [199/225], Training Accuracy: 96.3254%, Training Loss: 0.0986%\n",
      "Epoch [67/300], Step [200/225], Training Accuracy: 96.3438%, Training Loss: 0.0982%\n",
      "Epoch [67/300], Step [201/225], Training Accuracy: 96.3464%, Training Loss: 0.0981%\n",
      "Epoch [67/300], Step [202/225], Training Accuracy: 96.3567%, Training Loss: 0.0979%\n",
      "Epoch [67/300], Step [203/225], Training Accuracy: 96.3593%, Training Loss: 0.0978%\n",
      "Epoch [67/300], Step [204/225], Training Accuracy: 96.3618%, Training Loss: 0.0978%\n",
      "Epoch [67/300], Step [205/225], Training Accuracy: 96.3567%, Training Loss: 0.0980%\n",
      "Epoch [67/300], Step [206/225], Training Accuracy: 96.3668%, Training Loss: 0.0980%\n",
      "Epoch [67/300], Step [207/225], Training Accuracy: 96.3693%, Training Loss: 0.0978%\n",
      "Epoch [67/300], Step [208/225], Training Accuracy: 96.3642%, Training Loss: 0.0978%\n",
      "Epoch [67/300], Step [209/225], Training Accuracy: 96.3592%, Training Loss: 0.0977%\n",
      "Epoch [67/300], Step [210/225], Training Accuracy: 96.3542%, Training Loss: 0.0979%\n",
      "Epoch [67/300], Step [211/225], Training Accuracy: 96.3344%, Training Loss: 0.0982%\n",
      "Epoch [67/300], Step [212/225], Training Accuracy: 96.3222%, Training Loss: 0.0985%\n",
      "Epoch [67/300], Step [213/225], Training Accuracy: 96.3248%, Training Loss: 0.0985%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/300], Step [214/225], Training Accuracy: 96.3347%, Training Loss: 0.0983%\n",
      "Epoch [67/300], Step [215/225], Training Accuracy: 96.3445%, Training Loss: 0.0982%\n",
      "Epoch [67/300], Step [216/225], Training Accuracy: 96.3325%, Training Loss: 0.0985%\n",
      "Epoch [67/300], Step [217/225], Training Accuracy: 96.3422%, Training Loss: 0.0984%\n",
      "Epoch [67/300], Step [218/225], Training Accuracy: 96.3374%, Training Loss: 0.0983%\n",
      "Epoch [67/300], Step [219/225], Training Accuracy: 96.3470%, Training Loss: 0.0983%\n",
      "Epoch [67/300], Step [220/225], Training Accuracy: 96.3565%, Training Loss: 0.0982%\n",
      "Epoch [67/300], Step [221/225], Training Accuracy: 96.3447%, Training Loss: 0.0982%\n",
      "Epoch [67/300], Step [222/225], Training Accuracy: 96.3401%, Training Loss: 0.0982%\n",
      "Epoch [67/300], Step [223/225], Training Accuracy: 96.3285%, Training Loss: 0.0983%\n",
      "Epoch [67/300], Step [224/225], Training Accuracy: 96.3170%, Training Loss: 0.0984%\n",
      "Epoch [67/300], Step [225/225], Training Accuracy: 96.2966%, Training Loss: 0.0988%\n",
      "Epoch [68/300], Step [1/225], Training Accuracy: 95.3125%, Training Loss: 0.0956%\n",
      "Epoch [68/300], Step [2/225], Training Accuracy: 94.5312%, Training Loss: 0.1332%\n",
      "Epoch [68/300], Step [3/225], Training Accuracy: 94.2708%, Training Loss: 0.1272%\n",
      "Epoch [68/300], Step [4/225], Training Accuracy: 94.9219%, Training Loss: 0.1135%\n",
      "Epoch [68/300], Step [5/225], Training Accuracy: 95.6250%, Training Loss: 0.1036%\n",
      "Epoch [68/300], Step [6/225], Training Accuracy: 95.8333%, Training Loss: 0.1016%\n",
      "Epoch [68/300], Step [7/225], Training Accuracy: 95.9821%, Training Loss: 0.0978%\n",
      "Epoch [68/300], Step [8/225], Training Accuracy: 95.8984%, Training Loss: 0.0958%\n",
      "Epoch [68/300], Step [9/225], Training Accuracy: 96.3542%, Training Loss: 0.0920%\n",
      "Epoch [68/300], Step [10/225], Training Accuracy: 96.4062%, Training Loss: 0.0936%\n",
      "Epoch [68/300], Step [11/225], Training Accuracy: 96.7330%, Training Loss: 0.0874%\n",
      "Epoch [68/300], Step [12/225], Training Accuracy: 96.4844%, Training Loss: 0.0911%\n",
      "Epoch [68/300], Step [13/225], Training Accuracy: 96.3942%, Training Loss: 0.0962%\n",
      "Epoch [68/300], Step [14/225], Training Accuracy: 96.5402%, Training Loss: 0.0943%\n",
      "Epoch [68/300], Step [15/225], Training Accuracy: 96.7708%, Training Loss: 0.0917%\n",
      "Epoch [68/300], Step [16/225], Training Accuracy: 96.7773%, Training Loss: 0.0906%\n",
      "Epoch [68/300], Step [17/225], Training Accuracy: 96.6912%, Training Loss: 0.0930%\n",
      "Epoch [68/300], Step [18/225], Training Accuracy: 96.5278%, Training Loss: 0.0965%\n",
      "Epoch [68/300], Step [19/225], Training Accuracy: 96.4638%, Training Loss: 0.0972%\n",
      "Epoch [68/300], Step [20/225], Training Accuracy: 96.6406%, Training Loss: 0.0940%\n",
      "Epoch [68/300], Step [21/225], Training Accuracy: 96.6518%, Training Loss: 0.0931%\n",
      "Epoch [68/300], Step [22/225], Training Accuracy: 96.5909%, Training Loss: 0.0946%\n",
      "Epoch [68/300], Step [23/225], Training Accuracy: 96.6712%, Training Loss: 0.0928%\n",
      "Epoch [68/300], Step [24/225], Training Accuracy: 96.6797%, Training Loss: 0.0924%\n",
      "Epoch [68/300], Step [25/225], Training Accuracy: 96.6875%, Training Loss: 0.0917%\n",
      "Epoch [68/300], Step [26/225], Training Accuracy: 96.8149%, Training Loss: 0.0905%\n",
      "Epoch [68/300], Step [27/225], Training Accuracy: 96.4699%, Training Loss: 0.0967%\n",
      "Epoch [68/300], Step [28/225], Training Accuracy: 96.4286%, Training Loss: 0.0972%\n",
      "Epoch [68/300], Step [29/225], Training Accuracy: 96.5517%, Training Loss: 0.0957%\n",
      "Epoch [68/300], Step [30/225], Training Accuracy: 96.4583%, Training Loss: 0.0963%\n",
      "Epoch [68/300], Step [31/225], Training Accuracy: 96.4718%, Training Loss: 0.0957%\n",
      "Epoch [68/300], Step [32/225], Training Accuracy: 96.4844%, Training Loss: 0.0950%\n",
      "Epoch [68/300], Step [33/225], Training Accuracy: 96.4489%, Training Loss: 0.0955%\n",
      "Epoch [68/300], Step [34/225], Training Accuracy: 96.4154%, Training Loss: 0.0957%\n",
      "Epoch [68/300], Step [35/225], Training Accuracy: 96.2946%, Training Loss: 0.0997%\n",
      "Epoch [68/300], Step [36/225], Training Accuracy: 96.3542%, Training Loss: 0.0993%\n",
      "Epoch [68/300], Step [37/225], Training Accuracy: 96.4105%, Training Loss: 0.0984%\n",
      "Epoch [68/300], Step [38/225], Training Accuracy: 96.2993%, Training Loss: 0.0999%\n",
      "Epoch [68/300], Step [39/225], Training Accuracy: 96.3542%, Training Loss: 0.0989%\n",
      "Epoch [68/300], Step [40/225], Training Accuracy: 96.4453%, Training Loss: 0.0974%\n",
      "Epoch [68/300], Step [41/225], Training Accuracy: 96.5320%, Training Loss: 0.0960%\n",
      "Epoch [68/300], Step [42/225], Training Accuracy: 96.5030%, Training Loss: 0.0954%\n",
      "Epoch [68/300], Step [43/225], Training Accuracy: 96.5480%, Training Loss: 0.0946%\n",
      "Epoch [68/300], Step [44/225], Training Accuracy: 96.5199%, Training Loss: 0.0949%\n",
      "Epoch [68/300], Step [45/225], Training Accuracy: 96.5625%, Training Loss: 0.0946%\n",
      "Epoch [68/300], Step [46/225], Training Accuracy: 96.6033%, Training Loss: 0.0936%\n",
      "Epoch [68/300], Step [47/225], Training Accuracy: 96.5758%, Training Loss: 0.0938%\n",
      "Epoch [68/300], Step [48/225], Training Accuracy: 96.6471%, Training Loss: 0.0928%\n",
      "Epoch [68/300], Step [49/225], Training Accuracy: 96.7156%, Training Loss: 0.0921%\n",
      "Epoch [68/300], Step [50/225], Training Accuracy: 96.6250%, Training Loss: 0.0934%\n",
      "Epoch [68/300], Step [51/225], Training Accuracy: 96.6605%, Training Loss: 0.0932%\n",
      "Epoch [68/300], Step [52/225], Training Accuracy: 96.7248%, Training Loss: 0.0920%\n",
      "Epoch [68/300], Step [53/225], Training Accuracy: 96.7276%, Training Loss: 0.0919%\n",
      "Epoch [68/300], Step [54/225], Training Accuracy: 96.6435%, Training Loss: 0.0935%\n",
      "Epoch [68/300], Step [55/225], Training Accuracy: 96.6761%, Training Loss: 0.0929%\n",
      "Epoch [68/300], Step [56/225], Training Accuracy: 96.6518%, Training Loss: 0.0939%\n",
      "Epoch [68/300], Step [57/225], Training Accuracy: 96.6831%, Training Loss: 0.0939%\n",
      "Epoch [68/300], Step [58/225], Training Accuracy: 96.7403%, Training Loss: 0.0929%\n",
      "Epoch [68/300], Step [59/225], Training Accuracy: 96.6896%, Training Loss: 0.0939%\n",
      "Epoch [68/300], Step [60/225], Training Accuracy: 96.6667%, Training Loss: 0.0935%\n",
      "Epoch [68/300], Step [61/225], Training Accuracy: 96.6445%, Training Loss: 0.0941%\n",
      "Epoch [68/300], Step [62/225], Training Accuracy: 96.6230%, Training Loss: 0.0945%\n",
      "Epoch [68/300], Step [63/225], Training Accuracy: 96.5774%, Training Loss: 0.0950%\n",
      "Epoch [68/300], Step [64/225], Training Accuracy: 96.5820%, Training Loss: 0.0951%\n",
      "Epoch [68/300], Step [65/225], Training Accuracy: 96.5385%, Training Loss: 0.0956%\n",
      "Epoch [68/300], Step [66/225], Training Accuracy: 96.5672%, Training Loss: 0.0952%\n",
      "Epoch [68/300], Step [67/225], Training Accuracy: 96.5252%, Training Loss: 0.0966%\n",
      "Epoch [68/300], Step [68/225], Training Accuracy: 96.4844%, Training Loss: 0.0973%\n",
      "Epoch [68/300], Step [69/225], Training Accuracy: 96.5127%, Training Loss: 0.0972%\n",
      "Epoch [68/300], Step [70/225], Training Accuracy: 96.4955%, Training Loss: 0.0973%\n",
      "Epoch [68/300], Step [71/225], Training Accuracy: 96.5009%, Training Loss: 0.0975%\n",
      "Epoch [68/300], Step [72/225], Training Accuracy: 96.5061%, Training Loss: 0.0981%\n",
      "Epoch [68/300], Step [73/225], Training Accuracy: 96.5111%, Training Loss: 0.0976%\n",
      "Epoch [68/300], Step [74/225], Training Accuracy: 96.4527%, Training Loss: 0.0989%\n",
      "Epoch [68/300], Step [75/225], Training Accuracy: 96.4583%, Training Loss: 0.0986%\n",
      "Epoch [68/300], Step [76/225], Training Accuracy: 96.4844%, Training Loss: 0.0980%\n",
      "Epoch [68/300], Step [77/225], Training Accuracy: 96.4894%, Training Loss: 0.0978%\n",
      "Epoch [68/300], Step [78/225], Training Accuracy: 96.4744%, Training Loss: 0.0978%\n",
      "Epoch [68/300], Step [79/225], Training Accuracy: 96.4003%, Training Loss: 0.0989%\n",
      "Epoch [68/300], Step [80/225], Training Accuracy: 96.3672%, Training Loss: 0.0995%\n",
      "Epoch [68/300], Step [81/225], Training Accuracy: 96.3542%, Training Loss: 0.0993%\n",
      "Epoch [68/300], Step [82/225], Training Accuracy: 96.3605%, Training Loss: 0.0997%\n",
      "Epoch [68/300], Step [83/225], Training Accuracy: 96.3667%, Training Loss: 0.1000%\n",
      "Epoch [68/300], Step [84/225], Training Accuracy: 96.3914%, Training Loss: 0.0996%\n",
      "Epoch [68/300], Step [85/225], Training Accuracy: 96.3971%, Training Loss: 0.0996%\n",
      "Epoch [68/300], Step [86/225], Training Accuracy: 96.4390%, Training Loss: 0.0990%\n",
      "Epoch [68/300], Step [87/225], Training Accuracy: 96.4260%, Training Loss: 0.0995%\n",
      "Epoch [68/300], Step [88/225], Training Accuracy: 96.4489%, Training Loss: 0.0992%\n",
      "Epoch [68/300], Step [89/225], Training Accuracy: 96.4888%, Training Loss: 0.0986%\n",
      "Epoch [68/300], Step [90/225], Training Accuracy: 96.5104%, Training Loss: 0.0981%\n",
      "Epoch [68/300], Step [91/225], Training Accuracy: 96.5488%, Training Loss: 0.0972%\n",
      "Epoch [68/300], Step [92/225], Training Accuracy: 96.5693%, Training Loss: 0.0966%\n",
      "Epoch [68/300], Step [93/225], Training Accuracy: 96.6062%, Training Loss: 0.0961%\n",
      "Epoch [68/300], Step [94/225], Training Accuracy: 96.5924%, Training Loss: 0.0961%\n",
      "Epoch [68/300], Step [95/225], Training Accuracy: 96.5954%, Training Loss: 0.0964%\n",
      "Epoch [68/300], Step [96/225], Training Accuracy: 96.6146%, Training Loss: 0.0959%\n",
      "Epoch [68/300], Step [97/225], Training Accuracy: 96.6495%, Training Loss: 0.0953%\n",
      "Epoch [68/300], Step [98/225], Training Accuracy: 96.6518%, Training Loss: 0.0952%\n",
      "Epoch [68/300], Step [99/225], Training Accuracy: 96.6856%, Training Loss: 0.0949%\n",
      "Epoch [68/300], Step [100/225], Training Accuracy: 96.7031%, Training Loss: 0.0946%\n",
      "Epoch [68/300], Step [101/225], Training Accuracy: 96.7203%, Training Loss: 0.0943%\n",
      "Epoch [68/300], Step [102/225], Training Accuracy: 96.6605%, Training Loss: 0.0953%\n",
      "Epoch [68/300], Step [103/225], Training Accuracy: 96.6930%, Training Loss: 0.0948%\n",
      "Epoch [68/300], Step [104/225], Training Accuracy: 96.7248%, Training Loss: 0.0943%\n",
      "Epoch [68/300], Step [105/225], Training Accuracy: 96.7113%, Training Loss: 0.0947%\n",
      "Epoch [68/300], Step [106/225], Training Accuracy: 96.7276%, Training Loss: 0.0947%\n",
      "Epoch [68/300], Step [107/225], Training Accuracy: 96.6998%, Training Loss: 0.0959%\n",
      "Epoch [68/300], Step [108/225], Training Accuracy: 96.7303%, Training Loss: 0.0953%\n",
      "Epoch [68/300], Step [109/225], Training Accuracy: 96.7173%, Training Loss: 0.0961%\n",
      "Epoch [68/300], Step [110/225], Training Accuracy: 96.7188%, Training Loss: 0.0960%\n",
      "Epoch [68/300], Step [111/225], Training Accuracy: 96.7202%, Training Loss: 0.0957%\n",
      "Epoch [68/300], Step [112/225], Training Accuracy: 96.7076%, Training Loss: 0.0959%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/300], Step [113/225], Training Accuracy: 96.6952%, Training Loss: 0.0959%\n",
      "Epoch [68/300], Step [114/225], Training Accuracy: 96.7242%, Training Loss: 0.0955%\n",
      "Epoch [68/300], Step [115/225], Training Accuracy: 96.7255%, Training Loss: 0.0955%\n",
      "Epoch [68/300], Step [116/225], Training Accuracy: 96.7134%, Training Loss: 0.0954%\n",
      "Epoch [68/300], Step [117/225], Training Accuracy: 96.7281%, Training Loss: 0.0950%\n",
      "Epoch [68/300], Step [118/225], Training Accuracy: 96.7426%, Training Loss: 0.0947%\n",
      "Epoch [68/300], Step [119/225], Training Accuracy: 96.7568%, Training Loss: 0.0942%\n",
      "Epoch [68/300], Step [120/225], Training Accuracy: 96.7448%, Training Loss: 0.0943%\n",
      "Epoch [68/300], Step [121/225], Training Accuracy: 96.7588%, Training Loss: 0.0940%\n",
      "Epoch [68/300], Step [122/225], Training Accuracy: 96.7469%, Training Loss: 0.0942%\n",
      "Epoch [68/300], Step [123/225], Training Accuracy: 96.7480%, Training Loss: 0.0941%\n",
      "Epoch [68/300], Step [124/225], Training Accuracy: 96.7616%, Training Loss: 0.0937%\n",
      "Epoch [68/300], Step [125/225], Training Accuracy: 96.7375%, Training Loss: 0.0938%\n",
      "Epoch [68/300], Step [126/225], Training Accuracy: 96.7138%, Training Loss: 0.0941%\n",
      "Epoch [68/300], Step [127/225], Training Accuracy: 96.7151%, Training Loss: 0.0941%\n",
      "Epoch [68/300], Step [128/225], Training Accuracy: 96.7041%, Training Loss: 0.0944%\n",
      "Epoch [68/300], Step [129/225], Training Accuracy: 96.7297%, Training Loss: 0.0938%\n",
      "Epoch [68/300], Step [130/225], Training Accuracy: 96.7067%, Training Loss: 0.0941%\n",
      "Epoch [68/300], Step [131/225], Training Accuracy: 96.7199%, Training Loss: 0.0938%\n",
      "Epoch [68/300], Step [132/225], Training Accuracy: 96.7211%, Training Loss: 0.0938%\n",
      "Epoch [68/300], Step [133/225], Training Accuracy: 96.7223%, Training Loss: 0.0939%\n",
      "Epoch [68/300], Step [134/225], Training Accuracy: 96.7118%, Training Loss: 0.0941%\n",
      "Epoch [68/300], Step [135/225], Training Accuracy: 96.7361%, Training Loss: 0.0937%\n",
      "Epoch [68/300], Step [136/225], Training Accuracy: 96.7371%, Training Loss: 0.0936%\n",
      "Epoch [68/300], Step [137/225], Training Accuracy: 96.7381%, Training Loss: 0.0936%\n",
      "Epoch [68/300], Step [138/225], Training Accuracy: 96.7052%, Training Loss: 0.0943%\n",
      "Epoch [68/300], Step [139/225], Training Accuracy: 96.7064%, Training Loss: 0.0941%\n",
      "Epoch [68/300], Step [140/225], Training Accuracy: 96.6964%, Training Loss: 0.0941%\n",
      "Epoch [68/300], Step [141/225], Training Accuracy: 96.7088%, Training Loss: 0.0939%\n",
      "Epoch [68/300], Step [142/225], Training Accuracy: 96.6879%, Training Loss: 0.0947%\n",
      "Epoch [68/300], Step [143/225], Training Accuracy: 96.7002%, Training Loss: 0.0948%\n",
      "Epoch [68/300], Step [144/225], Training Accuracy: 96.7122%, Training Loss: 0.0949%\n",
      "Epoch [68/300], Step [145/225], Training Accuracy: 96.7241%, Training Loss: 0.0946%\n",
      "Epoch [68/300], Step [146/225], Training Accuracy: 96.7466%, Training Loss: 0.0942%\n",
      "Epoch [68/300], Step [147/225], Training Accuracy: 96.7581%, Training Loss: 0.0941%\n",
      "Epoch [68/300], Step [148/225], Training Accuracy: 96.7694%, Training Loss: 0.0943%\n",
      "Epoch [68/300], Step [149/225], Training Accuracy: 96.7492%, Training Loss: 0.0945%\n",
      "Epoch [68/300], Step [150/225], Training Accuracy: 96.7604%, Training Loss: 0.0947%\n",
      "Epoch [68/300], Step [151/225], Training Accuracy: 96.7715%, Training Loss: 0.0945%\n",
      "Epoch [68/300], Step [152/225], Training Accuracy: 96.7516%, Training Loss: 0.0946%\n",
      "Epoch [68/300], Step [153/225], Training Accuracy: 96.7627%, Training Loss: 0.0944%\n",
      "Epoch [68/300], Step [154/225], Training Accuracy: 96.7735%, Training Loss: 0.0943%\n",
      "Epoch [68/300], Step [155/225], Training Accuracy: 96.7742%, Training Loss: 0.0942%\n",
      "Epoch [68/300], Step [156/225], Training Accuracy: 96.7648%, Training Loss: 0.0942%\n",
      "Epoch [68/300], Step [157/225], Training Accuracy: 96.7058%, Training Loss: 0.0950%\n",
      "Epoch [68/300], Step [158/225], Training Accuracy: 96.6970%, Training Loss: 0.0951%\n",
      "Epoch [68/300], Step [159/225], Training Accuracy: 96.6981%, Training Loss: 0.0951%\n",
      "Epoch [68/300], Step [160/225], Training Accuracy: 96.6895%, Training Loss: 0.0951%\n",
      "Epoch [68/300], Step [161/225], Training Accuracy: 96.6809%, Training Loss: 0.0949%\n",
      "Epoch [68/300], Step [162/225], Training Accuracy: 96.6917%, Training Loss: 0.0949%\n",
      "Epoch [68/300], Step [163/225], Training Accuracy: 96.6641%, Training Loss: 0.0953%\n",
      "Epoch [68/300], Step [164/225], Training Accuracy: 96.6749%, Training Loss: 0.0951%\n",
      "Epoch [68/300], Step [165/225], Training Accuracy: 96.6572%, Training Loss: 0.0954%\n",
      "Epoch [68/300], Step [166/225], Training Accuracy: 96.6773%, Training Loss: 0.0952%\n",
      "Epoch [68/300], Step [167/225], Training Accuracy: 96.6317%, Training Loss: 0.0958%\n",
      "Epoch [68/300], Step [168/225], Training Accuracy: 96.6518%, Training Loss: 0.0953%\n",
      "Epoch [68/300], Step [169/225], Training Accuracy: 96.6531%, Training Loss: 0.0954%\n",
      "Epoch [68/300], Step [170/225], Training Accuracy: 96.6544%, Training Loss: 0.0956%\n",
      "Epoch [68/300], Step [171/225], Training Accuracy: 96.6374%, Training Loss: 0.0959%\n",
      "Epoch [68/300], Step [172/225], Training Accuracy: 96.6297%, Training Loss: 0.0960%\n",
      "Epoch [68/300], Step [173/225], Training Accuracy: 96.6492%, Training Loss: 0.0957%\n",
      "Epoch [68/300], Step [174/225], Training Accuracy: 96.6595%, Training Loss: 0.0956%\n",
      "Epoch [68/300], Step [175/225], Training Accuracy: 96.6696%, Training Loss: 0.0954%\n",
      "Epoch [68/300], Step [176/225], Training Accuracy: 96.6531%, Training Loss: 0.0960%\n",
      "Epoch [68/300], Step [177/225], Training Accuracy: 96.6631%, Training Loss: 0.0957%\n",
      "Epoch [68/300], Step [178/225], Training Accuracy: 96.6555%, Training Loss: 0.0957%\n",
      "Epoch [68/300], Step [179/225], Training Accuracy: 96.6480%, Training Loss: 0.0957%\n",
      "Epoch [68/300], Step [180/225], Training Accuracy: 96.6667%, Training Loss: 0.0954%\n",
      "Epoch [68/300], Step [181/225], Training Accuracy: 96.6592%, Training Loss: 0.0962%\n",
      "Epoch [68/300], Step [182/225], Training Accuracy: 96.6604%, Training Loss: 0.0963%\n",
      "Epoch [68/300], Step [183/225], Training Accuracy: 96.6701%, Training Loss: 0.0960%\n",
      "Epoch [68/300], Step [184/225], Training Accuracy: 96.6712%, Training Loss: 0.0961%\n",
      "Epoch [68/300], Step [185/225], Training Accuracy: 96.6807%, Training Loss: 0.0959%\n",
      "Epoch [68/300], Step [186/225], Training Accuracy: 96.6818%, Training Loss: 0.0959%\n",
      "Epoch [68/300], Step [187/225], Training Accuracy: 96.6995%, Training Loss: 0.0956%\n",
      "Epoch [68/300], Step [188/225], Training Accuracy: 96.7171%, Training Loss: 0.0954%\n",
      "Epoch [68/300], Step [189/225], Training Accuracy: 96.7179%, Training Loss: 0.0955%\n",
      "Epoch [68/300], Step [190/225], Training Accuracy: 96.7105%, Training Loss: 0.0955%\n",
      "Epoch [68/300], Step [191/225], Training Accuracy: 96.7114%, Training Loss: 0.0954%\n",
      "Epoch [68/300], Step [192/225], Training Accuracy: 96.6960%, Training Loss: 0.0957%\n",
      "Epoch [68/300], Step [193/225], Training Accuracy: 96.6888%, Training Loss: 0.0958%\n",
      "Epoch [68/300], Step [194/225], Training Accuracy: 96.6898%, Training Loss: 0.0956%\n",
      "Epoch [68/300], Step [195/225], Training Accuracy: 96.6827%, Training Loss: 0.0956%\n",
      "Epoch [68/300], Step [196/225], Training Accuracy: 96.6916%, Training Loss: 0.0953%\n",
      "Epoch [68/300], Step [197/225], Training Accuracy: 96.6926%, Training Loss: 0.0952%\n",
      "Epoch [68/300], Step [198/225], Training Accuracy: 96.6540%, Training Loss: 0.0958%\n",
      "Epoch [68/300], Step [199/225], Training Accuracy: 96.6552%, Training Loss: 0.0959%\n",
      "Epoch [68/300], Step [200/225], Training Accuracy: 96.6641%, Training Loss: 0.0957%\n",
      "Epoch [68/300], Step [201/225], Training Accuracy: 96.6573%, Training Loss: 0.0957%\n",
      "Epoch [68/300], Step [202/225], Training Accuracy: 96.6662%, Training Loss: 0.0955%\n",
      "Epoch [68/300], Step [203/225], Training Accuracy: 96.6826%, Training Loss: 0.0954%\n",
      "Epoch [68/300], Step [204/225], Training Accuracy: 96.6759%, Training Loss: 0.0954%\n",
      "Epoch [68/300], Step [205/225], Training Accuracy: 96.6616%, Training Loss: 0.0956%\n",
      "Epoch [68/300], Step [206/225], Training Accuracy: 96.6702%, Training Loss: 0.0955%\n",
      "Epoch [68/300], Step [207/225], Training Accuracy: 96.6636%, Training Loss: 0.0953%\n",
      "Epoch [68/300], Step [208/225], Training Accuracy: 96.6647%, Training Loss: 0.0955%\n",
      "Epoch [68/300], Step [209/225], Training Accuracy: 96.6731%, Training Loss: 0.0952%\n",
      "Epoch [68/300], Step [210/225], Training Accuracy: 96.6667%, Training Loss: 0.0952%\n",
      "Epoch [68/300], Step [211/225], Training Accuracy: 96.6528%, Training Loss: 0.0955%\n",
      "Epoch [68/300], Step [212/225], Training Accuracy: 96.6244%, Training Loss: 0.0959%\n",
      "Epoch [68/300], Step [213/225], Training Accuracy: 96.6329%, Training Loss: 0.0958%\n",
      "Epoch [68/300], Step [214/225], Training Accuracy: 96.6487%, Training Loss: 0.0955%\n",
      "Epoch [68/300], Step [215/225], Training Accuracy: 96.6424%, Training Loss: 0.0957%\n",
      "Epoch [68/300], Step [216/225], Training Accuracy: 96.6291%, Training Loss: 0.0961%\n",
      "Epoch [68/300], Step [217/225], Training Accuracy: 96.6374%, Training Loss: 0.0959%\n",
      "Epoch [68/300], Step [218/225], Training Accuracy: 96.6456%, Training Loss: 0.0958%\n",
      "Epoch [68/300], Step [219/225], Training Accuracy: 96.6538%, Training Loss: 0.0957%\n",
      "Epoch [68/300], Step [220/225], Training Accuracy: 96.6406%, Training Loss: 0.0958%\n",
      "Epoch [68/300], Step [221/225], Training Accuracy: 96.6134%, Training Loss: 0.0962%\n",
      "Epoch [68/300], Step [222/225], Training Accuracy: 96.6005%, Training Loss: 0.0964%\n",
      "Epoch [68/300], Step [223/225], Training Accuracy: 96.6158%, Training Loss: 0.0962%\n",
      "Epoch [68/300], Step [224/225], Training Accuracy: 96.6239%, Training Loss: 0.0960%\n",
      "Epoch [68/300], Step [225/225], Training Accuracy: 96.6231%, Training Loss: 0.0960%\n",
      "Epoch [69/300], Step [1/225], Training Accuracy: 95.3125%, Training Loss: 0.0693%\n",
      "Epoch [69/300], Step [2/225], Training Accuracy: 96.0938%, Training Loss: 0.1173%\n",
      "Epoch [69/300], Step [3/225], Training Accuracy: 93.7500%, Training Loss: 0.1571%\n",
      "Epoch [69/300], Step [4/225], Training Accuracy: 93.3594%, Training Loss: 0.1632%\n",
      "Epoch [69/300], Step [5/225], Training Accuracy: 94.0625%, Training Loss: 0.1474%\n",
      "Epoch [69/300], Step [6/225], Training Accuracy: 93.4896%, Training Loss: 0.1528%\n",
      "Epoch [69/300], Step [7/225], Training Accuracy: 94.1964%, Training Loss: 0.1423%\n",
      "Epoch [69/300], Step [8/225], Training Accuracy: 94.7266%, Training Loss: 0.1323%\n",
      "Epoch [69/300], Step [9/225], Training Accuracy: 95.1389%, Training Loss: 0.1228%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/300], Step [10/225], Training Accuracy: 95.1562%, Training Loss: 0.1227%\n",
      "Epoch [69/300], Step [11/225], Training Accuracy: 95.1705%, Training Loss: 0.1222%\n",
      "Epoch [69/300], Step [12/225], Training Accuracy: 95.0521%, Training Loss: 0.1252%\n",
      "Epoch [69/300], Step [13/225], Training Accuracy: 95.4327%, Training Loss: 0.1193%\n",
      "Epoch [69/300], Step [14/225], Training Accuracy: 95.4241%, Training Loss: 0.1180%\n",
      "Epoch [69/300], Step [15/225], Training Accuracy: 95.5208%, Training Loss: 0.1141%\n",
      "Epoch [69/300], Step [16/225], Training Accuracy: 95.5078%, Training Loss: 0.1132%\n",
      "Epoch [69/300], Step [17/225], Training Accuracy: 95.4963%, Training Loss: 0.1142%\n",
      "Epoch [69/300], Step [18/225], Training Accuracy: 95.3993%, Training Loss: 0.1160%\n",
      "Epoch [69/300], Step [19/225], Training Accuracy: 95.3947%, Training Loss: 0.1144%\n",
      "Epoch [69/300], Step [20/225], Training Accuracy: 95.5469%, Training Loss: 0.1123%\n",
      "Epoch [69/300], Step [21/225], Training Accuracy: 95.6845%, Training Loss: 0.1091%\n",
      "Epoch [69/300], Step [22/225], Training Accuracy: 95.5256%, Training Loss: 0.1112%\n",
      "Epoch [69/300], Step [23/225], Training Accuracy: 95.5842%, Training Loss: 0.1102%\n",
      "Epoch [69/300], Step [24/225], Training Accuracy: 95.6380%, Training Loss: 0.1118%\n",
      "Epoch [69/300], Step [25/225], Training Accuracy: 95.5625%, Training Loss: 0.1126%\n",
      "Epoch [69/300], Step [26/225], Training Accuracy: 95.3726%, Training Loss: 0.1173%\n",
      "Epoch [69/300], Step [27/225], Training Accuracy: 95.4282%, Training Loss: 0.1161%\n",
      "Epoch [69/300], Step [28/225], Training Accuracy: 95.4799%, Training Loss: 0.1142%\n",
      "Epoch [69/300], Step [29/225], Training Accuracy: 95.5280%, Training Loss: 0.1128%\n",
      "Epoch [69/300], Step [30/225], Training Accuracy: 95.5208%, Training Loss: 0.1126%\n",
      "Epoch [69/300], Step [31/225], Training Accuracy: 95.5645%, Training Loss: 0.1120%\n",
      "Epoch [69/300], Step [32/225], Training Accuracy: 95.6543%, Training Loss: 0.1102%\n",
      "Epoch [69/300], Step [33/225], Training Accuracy: 95.7860%, Training Loss: 0.1082%\n",
      "Epoch [69/300], Step [34/225], Training Accuracy: 95.8640%, Training Loss: 0.1072%\n",
      "Epoch [69/300], Step [35/225], Training Accuracy: 95.8482%, Training Loss: 0.1080%\n",
      "Epoch [69/300], Step [36/225], Training Accuracy: 95.8333%, Training Loss: 0.1084%\n",
      "Epoch [69/300], Step [37/225], Training Accuracy: 95.7770%, Training Loss: 0.1100%\n",
      "Epoch [69/300], Step [38/225], Training Accuracy: 95.8470%, Training Loss: 0.1090%\n",
      "Epoch [69/300], Step [39/225], Training Accuracy: 95.9135%, Training Loss: 0.1085%\n",
      "Epoch [69/300], Step [40/225], Training Accuracy: 96.0156%, Training Loss: 0.1072%\n",
      "Epoch [69/300], Step [41/225], Training Accuracy: 96.0747%, Training Loss: 0.1066%\n",
      "Epoch [69/300], Step [42/225], Training Accuracy: 96.1310%, Training Loss: 0.1050%\n",
      "Epoch [69/300], Step [43/225], Training Accuracy: 96.1119%, Training Loss: 0.1051%\n",
      "Epoch [69/300], Step [44/225], Training Accuracy: 96.1293%, Training Loss: 0.1049%\n",
      "Epoch [69/300], Step [45/225], Training Accuracy: 96.1806%, Training Loss: 0.1041%\n",
      "Epoch [69/300], Step [46/225], Training Accuracy: 96.2296%, Training Loss: 0.1035%\n",
      "Epoch [69/300], Step [47/225], Training Accuracy: 96.2434%, Training Loss: 0.1032%\n",
      "Epoch [69/300], Step [48/225], Training Accuracy: 96.3216%, Training Loss: 0.1025%\n",
      "Epoch [69/300], Step [49/225], Training Accuracy: 96.2691%, Training Loss: 0.1029%\n",
      "Epoch [69/300], Step [50/225], Training Accuracy: 96.2500%, Training Loss: 0.1032%\n",
      "Epoch [69/300], Step [51/225], Training Accuracy: 96.2623%, Training Loss: 0.1029%\n",
      "Epoch [69/300], Step [52/225], Training Accuracy: 96.1839%, Training Loss: 0.1039%\n",
      "Epoch [69/300], Step [53/225], Training Accuracy: 96.2264%, Training Loss: 0.1029%\n",
      "Epoch [69/300], Step [54/225], Training Accuracy: 96.2095%, Training Loss: 0.1033%\n",
      "Epoch [69/300], Step [55/225], Training Accuracy: 96.1932%, Training Loss: 0.1039%\n",
      "Epoch [69/300], Step [56/225], Training Accuracy: 96.2612%, Training Loss: 0.1034%\n",
      "Epoch [69/300], Step [57/225], Training Accuracy: 96.2719%, Training Loss: 0.1037%\n",
      "Epoch [69/300], Step [58/225], Training Accuracy: 96.3362%, Training Loss: 0.1027%\n",
      "Epoch [69/300], Step [59/225], Training Accuracy: 96.3453%, Training Loss: 0.1026%\n",
      "Epoch [69/300], Step [60/225], Training Accuracy: 96.3542%, Training Loss: 0.1021%\n",
      "Epoch [69/300], Step [61/225], Training Accuracy: 96.3115%, Training Loss: 0.1037%\n",
      "Epoch [69/300], Step [62/225], Training Accuracy: 96.3458%, Training Loss: 0.1030%\n",
      "Epoch [69/300], Step [63/225], Training Accuracy: 96.3542%, Training Loss: 0.1041%\n",
      "Epoch [69/300], Step [64/225], Training Accuracy: 96.2646%, Training Loss: 0.1049%\n",
      "Epoch [69/300], Step [65/225], Training Accuracy: 96.3221%, Training Loss: 0.1040%\n",
      "Epoch [69/300], Step [66/225], Training Accuracy: 96.3778%, Training Loss: 0.1033%\n",
      "Epoch [69/300], Step [67/225], Training Accuracy: 96.4086%, Training Loss: 0.1028%\n",
      "Epoch [69/300], Step [68/225], Training Accuracy: 96.4154%, Training Loss: 0.1031%\n",
      "Epoch [69/300], Step [69/225], Training Accuracy: 96.4674%, Training Loss: 0.1022%\n",
      "Epoch [69/300], Step [70/225], Training Accuracy: 96.4062%, Training Loss: 0.1034%\n",
      "Epoch [69/300], Step [71/225], Training Accuracy: 96.3688%, Training Loss: 0.1037%\n",
      "Epoch [69/300], Step [72/225], Training Accuracy: 96.3759%, Training Loss: 0.1038%\n",
      "Epoch [69/300], Step [73/225], Training Accuracy: 96.3613%, Training Loss: 0.1040%\n",
      "Epoch [69/300], Step [74/225], Training Accuracy: 96.3471%, Training Loss: 0.1039%\n",
      "Epoch [69/300], Step [75/225], Training Accuracy: 96.3750%, Training Loss: 0.1031%\n",
      "Epoch [69/300], Step [76/225], Training Accuracy: 96.3199%, Training Loss: 0.1039%\n",
      "Epoch [69/300], Step [77/225], Training Accuracy: 96.3474%, Training Loss: 0.1032%\n",
      "Epoch [69/300], Step [78/225], Training Accuracy: 96.3542%, Training Loss: 0.1030%\n",
      "Epoch [69/300], Step [79/225], Training Accuracy: 96.3212%, Training Loss: 0.1034%\n",
      "Epoch [69/300], Step [80/225], Training Accuracy: 96.2695%, Training Loss: 0.1042%\n",
      "Epoch [69/300], Step [81/225], Training Accuracy: 96.2384%, Training Loss: 0.1046%\n",
      "Epoch [69/300], Step [82/225], Training Accuracy: 96.2843%, Training Loss: 0.1038%\n",
      "Epoch [69/300], Step [83/225], Training Accuracy: 96.1596%, Training Loss: 0.1055%\n",
      "Epoch [69/300], Step [84/225], Training Accuracy: 96.1496%, Training Loss: 0.1053%\n",
      "Epoch [69/300], Step [85/225], Training Accuracy: 96.1581%, Training Loss: 0.1049%\n",
      "Epoch [69/300], Step [86/225], Training Accuracy: 96.1301%, Training Loss: 0.1050%\n",
      "Epoch [69/300], Step [87/225], Training Accuracy: 96.0848%, Training Loss: 0.1057%\n",
      "Epoch [69/300], Step [88/225], Training Accuracy: 96.0938%, Training Loss: 0.1058%\n",
      "Epoch [69/300], Step [89/225], Training Accuracy: 96.1201%, Training Loss: 0.1054%\n",
      "Epoch [69/300], Step [90/225], Training Accuracy: 96.1285%, Training Loss: 0.1050%\n",
      "Epoch [69/300], Step [91/225], Training Accuracy: 96.1538%, Training Loss: 0.1045%\n",
      "Epoch [69/300], Step [92/225], Training Accuracy: 96.1787%, Training Loss: 0.1040%\n",
      "Epoch [69/300], Step [93/225], Training Accuracy: 96.1526%, Training Loss: 0.1051%\n",
      "Epoch [69/300], Step [94/225], Training Accuracy: 96.1436%, Training Loss: 0.1051%\n",
      "Epoch [69/300], Step [95/225], Training Accuracy: 96.1349%, Training Loss: 0.1054%\n",
      "Epoch [69/300], Step [96/225], Training Accuracy: 96.1589%, Training Loss: 0.1049%\n",
      "Epoch [69/300], Step [97/225], Training Accuracy: 96.1823%, Training Loss: 0.1044%\n",
      "Epoch [69/300], Step [98/225], Training Accuracy: 96.1575%, Training Loss: 0.1048%\n",
      "Epoch [69/300], Step [99/225], Training Accuracy: 96.1806%, Training Loss: 0.1044%\n",
      "Epoch [69/300], Step [100/225], Training Accuracy: 96.1719%, Training Loss: 0.1049%\n",
      "Epoch [69/300], Step [101/225], Training Accuracy: 96.2098%, Training Loss: 0.1043%\n",
      "Epoch [69/300], Step [102/225], Training Accuracy: 96.1703%, Training Loss: 0.1047%\n",
      "Epoch [69/300], Step [103/225], Training Accuracy: 96.1620%, Training Loss: 0.1054%\n",
      "Epoch [69/300], Step [104/225], Training Accuracy: 96.1689%, Training Loss: 0.1053%\n",
      "Epoch [69/300], Step [105/225], Training Accuracy: 96.1756%, Training Loss: 0.1050%\n",
      "Epoch [69/300], Step [106/225], Training Accuracy: 96.1969%, Training Loss: 0.1048%\n",
      "Epoch [69/300], Step [107/225], Training Accuracy: 96.2033%, Training Loss: 0.1044%\n",
      "Epoch [69/300], Step [108/225], Training Accuracy: 96.1950%, Training Loss: 0.1044%\n",
      "Epoch [69/300], Step [109/225], Training Accuracy: 96.1583%, Training Loss: 0.1044%\n",
      "Epoch [69/300], Step [110/225], Training Accuracy: 96.1506%, Training Loss: 0.1041%\n",
      "Epoch [69/300], Step [111/225], Training Accuracy: 96.1430%, Training Loss: 0.1041%\n",
      "Epoch [69/300], Step [112/225], Training Accuracy: 96.1496%, Training Loss: 0.1040%\n",
      "Epoch [69/300], Step [113/225], Training Accuracy: 96.1698%, Training Loss: 0.1036%\n",
      "Epoch [69/300], Step [114/225], Training Accuracy: 96.1349%, Training Loss: 0.1038%\n",
      "Epoch [69/300], Step [115/225], Training Accuracy: 96.1413%, Training Loss: 0.1037%\n",
      "Epoch [69/300], Step [116/225], Training Accuracy: 96.1476%, Training Loss: 0.1039%\n",
      "Epoch [69/300], Step [117/225], Training Accuracy: 96.1538%, Training Loss: 0.1037%\n",
      "Epoch [69/300], Step [118/225], Training Accuracy: 96.1732%, Training Loss: 0.1033%\n",
      "Epoch [69/300], Step [119/225], Training Accuracy: 96.2054%, Training Loss: 0.1029%\n",
      "Epoch [69/300], Step [120/225], Training Accuracy: 96.2240%, Training Loss: 0.1024%\n",
      "Epoch [69/300], Step [121/225], Training Accuracy: 96.2035%, Training Loss: 0.1027%\n",
      "Epoch [69/300], Step [122/225], Training Accuracy: 96.2218%, Training Loss: 0.1022%\n",
      "Epoch [69/300], Step [123/225], Training Accuracy: 96.2271%, Training Loss: 0.1021%\n",
      "Epoch [69/300], Step [124/225], Training Accuracy: 96.2198%, Training Loss: 0.1021%\n",
      "Epoch [69/300], Step [125/225], Training Accuracy: 96.2375%, Training Loss: 0.1019%\n",
      "Epoch [69/300], Step [126/225], Training Accuracy: 96.2054%, Training Loss: 0.1024%\n",
      "Epoch [69/300], Step [127/225], Training Accuracy: 96.1860%, Training Loss: 0.1025%\n",
      "Epoch [69/300], Step [128/225], Training Accuracy: 96.1426%, Training Loss: 0.1035%\n",
      "Epoch [69/300], Step [129/225], Training Accuracy: 96.1483%, Training Loss: 0.1032%\n",
      "Epoch [69/300], Step [130/225], Training Accuracy: 96.1538%, Training Loss: 0.1031%\n",
      "Epoch [69/300], Step [131/225], Training Accuracy: 96.1713%, Training Loss: 0.1026%\n",
      "Epoch [69/300], Step [132/225], Training Accuracy: 96.1648%, Training Loss: 0.1030%\n",
      "Epoch [69/300], Step [133/225], Training Accuracy: 96.1701%, Training Loss: 0.1028%\n",
      "Epoch [69/300], Step [134/225], Training Accuracy: 96.1521%, Training Loss: 0.1032%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/300], Step [135/225], Training Accuracy: 96.1806%, Training Loss: 0.1026%\n",
      "Epoch [69/300], Step [136/225], Training Accuracy: 96.1857%, Training Loss: 0.1030%\n",
      "Epoch [69/300], Step [137/225], Training Accuracy: 96.1679%, Training Loss: 0.1032%\n",
      "Epoch [69/300], Step [138/225], Training Accuracy: 96.1617%, Training Loss: 0.1034%\n",
      "Epoch [69/300], Step [139/225], Training Accuracy: 96.1668%, Training Loss: 0.1033%\n",
      "Epoch [69/300], Step [140/225], Training Accuracy: 96.1830%, Training Loss: 0.1031%\n",
      "Epoch [69/300], Step [141/225], Training Accuracy: 96.1769%, Training Loss: 0.1032%\n",
      "Epoch [69/300], Step [142/225], Training Accuracy: 96.2038%, Training Loss: 0.1028%\n",
      "Epoch [69/300], Step [143/225], Training Accuracy: 96.2085%, Training Loss: 0.1028%\n",
      "Epoch [69/300], Step [144/225], Training Accuracy: 96.2023%, Training Loss: 0.1027%\n",
      "Epoch [69/300], Step [145/225], Training Accuracy: 96.2069%, Training Loss: 0.1025%\n",
      "Epoch [69/300], Step [146/225], Training Accuracy: 96.2222%, Training Loss: 0.1021%\n",
      "Epoch [69/300], Step [147/225], Training Accuracy: 96.2266%, Training Loss: 0.1020%\n",
      "Epoch [69/300], Step [148/225], Training Accuracy: 96.2416%, Training Loss: 0.1018%\n",
      "Epoch [69/300], Step [149/225], Training Accuracy: 96.2248%, Training Loss: 0.1023%\n",
      "Epoch [69/300], Step [150/225], Training Accuracy: 96.2083%, Training Loss: 0.1026%\n",
      "Epoch [69/300], Step [151/225], Training Accuracy: 96.2127%, Training Loss: 0.1024%\n",
      "Epoch [69/300], Step [152/225], Training Accuracy: 96.2377%, Training Loss: 0.1020%\n",
      "Epoch [69/300], Step [153/225], Training Accuracy: 96.2520%, Training Loss: 0.1017%\n",
      "Epoch [69/300], Step [154/225], Training Accuracy: 96.2662%, Training Loss: 0.1015%\n",
      "Epoch [69/300], Step [155/225], Training Accuracy: 96.2399%, Training Loss: 0.1018%\n",
      "Epoch [69/300], Step [156/225], Training Accuracy: 96.2440%, Training Loss: 0.1016%\n",
      "Epoch [69/300], Step [157/225], Training Accuracy: 96.2182%, Training Loss: 0.1021%\n",
      "Epoch [69/300], Step [158/225], Training Accuracy: 96.2025%, Training Loss: 0.1023%\n",
      "Epoch [69/300], Step [159/225], Training Accuracy: 96.2068%, Training Loss: 0.1022%\n",
      "Epoch [69/300], Step [160/225], Training Accuracy: 96.2207%, Training Loss: 0.1018%\n",
      "Epoch [69/300], Step [161/225], Training Accuracy: 96.2151%, Training Loss: 0.1019%\n",
      "Epoch [69/300], Step [162/225], Training Accuracy: 96.2191%, Training Loss: 0.1019%\n",
      "Epoch [69/300], Step [163/225], Training Accuracy: 96.2040%, Training Loss: 0.1022%\n",
      "Epoch [69/300], Step [164/225], Training Accuracy: 96.2176%, Training Loss: 0.1021%\n",
      "Epoch [69/300], Step [165/225], Training Accuracy: 96.2121%, Training Loss: 0.1022%\n",
      "Epoch [69/300], Step [166/225], Training Accuracy: 96.1879%, Training Loss: 0.1030%\n",
      "Epoch [69/300], Step [167/225], Training Accuracy: 96.1546%, Training Loss: 0.1040%\n",
      "Epoch [69/300], Step [168/225], Training Accuracy: 96.1775%, Training Loss: 0.1035%\n",
      "Epoch [69/300], Step [169/225], Training Accuracy: 96.2001%, Training Loss: 0.1031%\n",
      "Epoch [69/300], Step [170/225], Training Accuracy: 96.1857%, Training Loss: 0.1034%\n",
      "Epoch [69/300], Step [171/225], Training Accuracy: 96.1806%, Training Loss: 0.1035%\n",
      "Epoch [69/300], Step [172/225], Training Accuracy: 96.1846%, Training Loss: 0.1034%\n",
      "Epoch [69/300], Step [173/225], Training Accuracy: 96.2066%, Training Loss: 0.1030%\n",
      "Epoch [69/300], Step [174/225], Training Accuracy: 96.1925%, Training Loss: 0.1031%\n",
      "Epoch [69/300], Step [175/225], Training Accuracy: 96.1875%, Training Loss: 0.1030%\n",
      "Epoch [69/300], Step [176/225], Training Accuracy: 96.1914%, Training Loss: 0.1031%\n",
      "Epoch [69/300], Step [177/225], Training Accuracy: 96.1953%, Training Loss: 0.1029%\n",
      "Epoch [69/300], Step [178/225], Training Accuracy: 96.1991%, Training Loss: 0.1029%\n",
      "Epoch [69/300], Step [179/225], Training Accuracy: 96.2029%, Training Loss: 0.1028%\n",
      "Epoch [69/300], Step [180/225], Training Accuracy: 96.2066%, Training Loss: 0.1027%\n",
      "Epoch [69/300], Step [181/225], Training Accuracy: 96.1930%, Training Loss: 0.1029%\n",
      "Epoch [69/300], Step [182/225], Training Accuracy: 96.1968%, Training Loss: 0.1028%\n",
      "Epoch [69/300], Step [183/225], Training Accuracy: 96.2090%, Training Loss: 0.1026%\n",
      "Epoch [69/300], Step [184/225], Training Accuracy: 96.1957%, Training Loss: 0.1027%\n",
      "Epoch [69/300], Step [185/225], Training Accuracy: 96.1909%, Training Loss: 0.1026%\n",
      "Epoch [69/300], Step [186/225], Training Accuracy: 96.1778%, Training Loss: 0.1027%\n",
      "Epoch [69/300], Step [187/225], Training Accuracy: 96.1982%, Training Loss: 0.1023%\n",
      "Epoch [69/300], Step [188/225], Training Accuracy: 96.2184%, Training Loss: 0.1020%\n",
      "Epoch [69/300], Step [189/225], Training Accuracy: 96.2219%, Training Loss: 0.1019%\n",
      "Epoch [69/300], Step [190/225], Training Accuracy: 96.2089%, Training Loss: 0.1020%\n",
      "Epoch [69/300], Step [191/225], Training Accuracy: 96.2124%, Training Loss: 0.1018%\n",
      "Epoch [69/300], Step [192/225], Training Accuracy: 96.2158%, Training Loss: 0.1019%\n",
      "Epoch [69/300], Step [193/225], Training Accuracy: 96.2192%, Training Loss: 0.1018%\n",
      "Epoch [69/300], Step [194/225], Training Accuracy: 96.2226%, Training Loss: 0.1016%\n",
      "Epoch [69/300], Step [195/225], Training Accuracy: 96.2340%, Training Loss: 0.1014%\n",
      "Epoch [69/300], Step [196/225], Training Accuracy: 96.2452%, Training Loss: 0.1011%\n",
      "Epoch [69/300], Step [197/225], Training Accuracy: 96.2643%, Training Loss: 0.1007%\n",
      "Epoch [69/300], Step [198/225], Training Accuracy: 96.2516%, Training Loss: 0.1011%\n",
      "Epoch [69/300], Step [199/225], Training Accuracy: 96.2390%, Training Loss: 0.1013%\n",
      "Epoch [69/300], Step [200/225], Training Accuracy: 96.2422%, Training Loss: 0.1010%\n",
      "Epoch [69/300], Step [201/225], Training Accuracy: 96.2531%, Training Loss: 0.1008%\n",
      "Epoch [69/300], Step [202/225], Training Accuracy: 96.2407%, Training Loss: 0.1009%\n",
      "Epoch [69/300], Step [203/225], Training Accuracy: 96.2515%, Training Loss: 0.1007%\n",
      "Epoch [69/300], Step [204/225], Training Accuracy: 96.2623%, Training Loss: 0.1006%\n",
      "Epoch [69/300], Step [205/225], Training Accuracy: 96.2805%, Training Loss: 0.1002%\n",
      "Epoch [69/300], Step [206/225], Training Accuracy: 96.2910%, Training Loss: 0.1000%\n",
      "Epoch [69/300], Step [207/225], Training Accuracy: 96.3089%, Training Loss: 0.0997%\n",
      "Epoch [69/300], Step [208/225], Training Accuracy: 96.3116%, Training Loss: 0.0996%\n",
      "Epoch [69/300], Step [209/225], Training Accuracy: 96.3068%, Training Loss: 0.0996%\n",
      "Epoch [69/300], Step [210/225], Training Accuracy: 96.3021%, Training Loss: 0.0997%\n",
      "Epoch [69/300], Step [211/225], Training Accuracy: 96.3048%, Training Loss: 0.0997%\n",
      "Epoch [69/300], Step [212/225], Training Accuracy: 96.3222%, Training Loss: 0.0995%\n",
      "Epoch [69/300], Step [213/225], Training Accuracy: 96.3395%, Training Loss: 0.0993%\n",
      "Epoch [69/300], Step [214/225], Training Accuracy: 96.3493%, Training Loss: 0.0991%\n",
      "Epoch [69/300], Step [215/225], Training Accuracy: 96.3590%, Training Loss: 0.0989%\n",
      "Epoch [69/300], Step [216/225], Training Accuracy: 96.3614%, Training Loss: 0.0988%\n",
      "Epoch [69/300], Step [217/225], Training Accuracy: 96.3494%, Training Loss: 0.0990%\n",
      "Epoch [69/300], Step [218/225], Training Accuracy: 96.3518%, Training Loss: 0.0988%\n",
      "Epoch [69/300], Step [219/225], Training Accuracy: 96.3613%, Training Loss: 0.0987%\n",
      "Epoch [69/300], Step [220/225], Training Accuracy: 96.3636%, Training Loss: 0.0987%\n",
      "Epoch [69/300], Step [221/225], Training Accuracy: 96.3660%, Training Loss: 0.0988%\n",
      "Epoch [69/300], Step [222/225], Training Accuracy: 96.3682%, Training Loss: 0.0990%\n",
      "Epoch [69/300], Step [223/225], Training Accuracy: 96.3845%, Training Loss: 0.0988%\n",
      "Epoch [69/300], Step [224/225], Training Accuracy: 96.3867%, Training Loss: 0.0988%\n",
      "Epoch [69/300], Step [225/225], Training Accuracy: 96.3869%, Training Loss: 0.0988%\n",
      "Epoch [70/300], Step [1/225], Training Accuracy: 96.8750%, Training Loss: 0.0769%\n",
      "Epoch [70/300], Step [2/225], Training Accuracy: 96.8750%, Training Loss: 0.0920%\n",
      "Epoch [70/300], Step [3/225], Training Accuracy: 96.3542%, Training Loss: 0.0940%\n",
      "Epoch [70/300], Step [4/225], Training Accuracy: 96.8750%, Training Loss: 0.0925%\n",
      "Epoch [70/300], Step [5/225], Training Accuracy: 97.1875%, Training Loss: 0.0844%\n",
      "Epoch [70/300], Step [6/225], Training Accuracy: 96.3542%, Training Loss: 0.1080%\n",
      "Epoch [70/300], Step [7/225], Training Accuracy: 95.9821%, Training Loss: 0.1106%\n",
      "Epoch [70/300], Step [8/225], Training Accuracy: 96.0938%, Training Loss: 0.1090%\n",
      "Epoch [70/300], Step [9/225], Training Accuracy: 96.1806%, Training Loss: 0.1039%\n",
      "Epoch [70/300], Step [10/225], Training Accuracy: 96.2500%, Training Loss: 0.1059%\n",
      "Epoch [70/300], Step [11/225], Training Accuracy: 95.8807%, Training Loss: 0.1068%\n",
      "Epoch [70/300], Step [12/225], Training Accuracy: 96.2240%, Training Loss: 0.1004%\n",
      "Epoch [70/300], Step [13/225], Training Accuracy: 96.1538%, Training Loss: 0.1018%\n",
      "Epoch [70/300], Step [14/225], Training Accuracy: 96.0938%, Training Loss: 0.1048%\n",
      "Epoch [70/300], Step [15/225], Training Accuracy: 96.0417%, Training Loss: 0.1044%\n",
      "Epoch [70/300], Step [16/225], Training Accuracy: 96.0938%, Training Loss: 0.1023%\n",
      "Epoch [70/300], Step [17/225], Training Accuracy: 95.8640%, Training Loss: 0.1058%\n",
      "Epoch [70/300], Step [18/225], Training Accuracy: 95.7465%, Training Loss: 0.1075%\n",
      "Epoch [70/300], Step [19/225], Training Accuracy: 95.8882%, Training Loss: 0.1055%\n",
      "Epoch [70/300], Step [20/225], Training Accuracy: 96.0156%, Training Loss: 0.1042%\n",
      "Epoch [70/300], Step [21/225], Training Accuracy: 96.1310%, Training Loss: 0.1047%\n",
      "Epoch [70/300], Step [22/225], Training Accuracy: 96.2358%, Training Loss: 0.1040%\n",
      "Epoch [70/300], Step [23/225], Training Accuracy: 96.3995%, Training Loss: 0.1019%\n",
      "Epoch [70/300], Step [24/225], Training Accuracy: 96.3542%, Training Loss: 0.1022%\n",
      "Epoch [70/300], Step [25/225], Training Accuracy: 96.4375%, Training Loss: 0.1001%\n",
      "Epoch [70/300], Step [26/225], Training Accuracy: 96.5144%, Training Loss: 0.0984%\n",
      "Epoch [70/300], Step [27/225], Training Accuracy: 96.4699%, Training Loss: 0.0980%\n",
      "Epoch [70/300], Step [28/225], Training Accuracy: 96.5960%, Training Loss: 0.0964%\n",
      "Epoch [70/300], Step [29/225], Training Accuracy: 96.4440%, Training Loss: 0.0987%\n",
      "Epoch [70/300], Step [30/225], Training Accuracy: 96.4062%, Training Loss: 0.0983%\n",
      "Epoch [70/300], Step [31/225], Training Accuracy: 96.4214%, Training Loss: 0.0983%\n",
      "Epoch [70/300], Step [32/225], Training Accuracy: 96.4355%, Training Loss: 0.0973%\n",
      "Epoch [70/300], Step [33/225], Training Accuracy: 96.4962%, Training Loss: 0.0966%\n",
      "Epoch [70/300], Step [34/225], Training Accuracy: 96.5074%, Training Loss: 0.0967%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/300], Step [35/225], Training Accuracy: 96.4732%, Training Loss: 0.0979%\n",
      "Epoch [70/300], Step [36/225], Training Accuracy: 96.4844%, Training Loss: 0.0976%\n",
      "Epoch [70/300], Step [37/225], Training Accuracy: 96.4527%, Training Loss: 0.0988%\n",
      "Epoch [70/300], Step [38/225], Training Accuracy: 96.3816%, Training Loss: 0.1000%\n",
      "Epoch [70/300], Step [39/225], Training Accuracy: 96.3141%, Training Loss: 0.1001%\n",
      "Epoch [70/300], Step [40/225], Training Accuracy: 96.4062%, Training Loss: 0.0984%\n",
      "Epoch [70/300], Step [41/225], Training Accuracy: 96.4177%, Training Loss: 0.0983%\n",
      "Epoch [70/300], Step [42/225], Training Accuracy: 96.3914%, Training Loss: 0.0983%\n",
      "Epoch [70/300], Step [43/225], Training Accuracy: 96.4390%, Training Loss: 0.0973%\n",
      "Epoch [70/300], Step [44/225], Training Accuracy: 96.3778%, Training Loss: 0.0981%\n",
      "Epoch [70/300], Step [45/225], Training Accuracy: 96.3889%, Training Loss: 0.0975%\n",
      "Epoch [70/300], Step [46/225], Training Accuracy: 96.3655%, Training Loss: 0.0972%\n",
      "Epoch [70/300], Step [47/225], Training Accuracy: 96.3098%, Training Loss: 0.0984%\n",
      "Epoch [70/300], Step [48/225], Training Accuracy: 96.3542%, Training Loss: 0.0977%\n",
      "Epoch [70/300], Step [49/225], Training Accuracy: 96.3648%, Training Loss: 0.0980%\n",
      "Epoch [70/300], Step [50/225], Training Accuracy: 96.3750%, Training Loss: 0.0978%\n",
      "Epoch [70/300], Step [51/225], Training Accuracy: 96.3848%, Training Loss: 0.0970%\n",
      "Epoch [70/300], Step [52/225], Training Accuracy: 96.3942%, Training Loss: 0.0965%\n",
      "Epoch [70/300], Step [53/225], Training Accuracy: 96.4623%, Training Loss: 0.0955%\n",
      "Epoch [70/300], Step [54/225], Training Accuracy: 96.5278%, Training Loss: 0.0947%\n",
      "Epoch [70/300], Step [55/225], Training Accuracy: 96.5341%, Training Loss: 0.0953%\n",
      "Epoch [70/300], Step [56/225], Training Accuracy: 96.5123%, Training Loss: 0.0963%\n",
      "Epoch [70/300], Step [57/225], Training Accuracy: 96.5186%, Training Loss: 0.0958%\n",
      "Epoch [70/300], Step [58/225], Training Accuracy: 96.5248%, Training Loss: 0.0959%\n",
      "Epoch [70/300], Step [59/225], Training Accuracy: 96.4513%, Training Loss: 0.0979%\n",
      "Epoch [70/300], Step [60/225], Training Accuracy: 96.4583%, Training Loss: 0.0981%\n",
      "Epoch [70/300], Step [61/225], Training Accuracy: 96.4652%, Training Loss: 0.0981%\n",
      "Epoch [70/300], Step [62/225], Training Accuracy: 96.4466%, Training Loss: 0.0985%\n",
      "Epoch [70/300], Step [63/225], Training Accuracy: 96.5030%, Training Loss: 0.0976%\n",
      "Epoch [70/300], Step [64/225], Training Accuracy: 96.5576%, Training Loss: 0.0968%\n",
      "Epoch [70/300], Step [65/225], Training Accuracy: 96.5625%, Training Loss: 0.0967%\n",
      "Epoch [70/300], Step [66/225], Training Accuracy: 96.5199%, Training Loss: 0.0974%\n",
      "Epoch [70/300], Step [67/225], Training Accuracy: 96.5252%, Training Loss: 0.0969%\n",
      "Epoch [70/300], Step [68/225], Training Accuracy: 96.5303%, Training Loss: 0.0969%\n",
      "Epoch [70/300], Step [69/225], Training Accuracy: 96.5580%, Training Loss: 0.0973%\n",
      "Epoch [70/300], Step [70/225], Training Accuracy: 96.5402%, Training Loss: 0.0975%\n",
      "Epoch [70/300], Step [71/225], Training Accuracy: 96.5889%, Training Loss: 0.0971%\n",
      "Epoch [70/300], Step [72/225], Training Accuracy: 96.6146%, Training Loss: 0.0965%\n",
      "Epoch [70/300], Step [73/225], Training Accuracy: 96.5967%, Training Loss: 0.0967%\n",
      "Epoch [70/300], Step [74/225], Training Accuracy: 96.6005%, Training Loss: 0.0974%\n",
      "Epoch [70/300], Step [75/225], Training Accuracy: 96.6250%, Training Loss: 0.0968%\n",
      "Epoch [70/300], Step [76/225], Training Accuracy: 96.5872%, Training Loss: 0.0973%\n",
      "Epoch [70/300], Step [77/225], Training Accuracy: 96.5909%, Training Loss: 0.0975%\n",
      "Epoch [70/300], Step [78/225], Training Accuracy: 96.6146%, Training Loss: 0.0974%\n",
      "Epoch [70/300], Step [79/225], Training Accuracy: 96.6179%, Training Loss: 0.0976%\n",
      "Epoch [70/300], Step [80/225], Training Accuracy: 96.6016%, Training Loss: 0.0986%\n",
      "Epoch [70/300], Step [81/225], Training Accuracy: 96.6435%, Training Loss: 0.0980%\n",
      "Epoch [70/300], Step [82/225], Training Accuracy: 96.6845%, Training Loss: 0.0973%\n",
      "Epoch [70/300], Step [83/225], Training Accuracy: 96.6679%, Training Loss: 0.0983%\n",
      "Epoch [70/300], Step [84/225], Training Accuracy: 96.6890%, Training Loss: 0.0983%\n",
      "Epoch [70/300], Step [85/225], Training Accuracy: 96.7279%, Training Loss: 0.0979%\n",
      "Epoch [70/300], Step [86/225], Training Accuracy: 96.6933%, Training Loss: 0.0981%\n",
      "Epoch [70/300], Step [87/225], Training Accuracy: 96.6774%, Training Loss: 0.0984%\n",
      "Epoch [70/300], Step [88/225], Training Accuracy: 96.7152%, Training Loss: 0.0982%\n",
      "Epoch [70/300], Step [89/225], Training Accuracy: 96.7170%, Training Loss: 0.0981%\n",
      "Epoch [70/300], Step [90/225], Training Accuracy: 96.7188%, Training Loss: 0.0979%\n",
      "Epoch [70/300], Step [91/225], Training Accuracy: 96.6861%, Training Loss: 0.0979%\n",
      "Epoch [70/300], Step [92/225], Training Accuracy: 96.6882%, Training Loss: 0.0976%\n",
      "Epoch [70/300], Step [93/225], Training Accuracy: 96.6734%, Training Loss: 0.0974%\n",
      "Epoch [70/300], Step [94/225], Training Accuracy: 96.6922%, Training Loss: 0.0968%\n",
      "Epoch [70/300], Step [95/225], Training Accuracy: 96.6612%, Training Loss: 0.0978%\n",
      "Epoch [70/300], Step [96/225], Training Accuracy: 96.6797%, Training Loss: 0.0974%\n",
      "Epoch [70/300], Step [97/225], Training Accuracy: 96.6495%, Training Loss: 0.0981%\n",
      "Epoch [70/300], Step [98/225], Training Accuracy: 96.6358%, Training Loss: 0.0981%\n",
      "Epoch [70/300], Step [99/225], Training Accuracy: 96.6540%, Training Loss: 0.0976%\n",
      "Epoch [70/300], Step [100/225], Training Accuracy: 96.6719%, Training Loss: 0.0973%\n",
      "Epoch [70/300], Step [101/225], Training Accuracy: 96.6584%, Training Loss: 0.0971%\n",
      "Epoch [70/300], Step [102/225], Training Accuracy: 96.6299%, Training Loss: 0.0971%\n",
      "Epoch [70/300], Step [103/225], Training Accuracy: 96.6019%, Training Loss: 0.0977%\n",
      "Epoch [70/300], Step [104/225], Training Accuracy: 96.6346%, Training Loss: 0.0971%\n",
      "Epoch [70/300], Step [105/225], Training Accuracy: 96.6220%, Training Loss: 0.0971%\n",
      "Epoch [70/300], Step [106/225], Training Accuracy: 96.6244%, Training Loss: 0.0973%\n",
      "Epoch [70/300], Step [107/225], Training Accuracy: 96.6414%, Training Loss: 0.0971%\n",
      "Epoch [70/300], Step [108/225], Training Accuracy: 96.6725%, Training Loss: 0.0968%\n",
      "Epoch [70/300], Step [109/225], Training Accuracy: 96.6743%, Training Loss: 0.0970%\n",
      "Epoch [70/300], Step [110/225], Training Accuracy: 96.6903%, Training Loss: 0.0965%\n",
      "Epoch [70/300], Step [111/225], Training Accuracy: 96.6920%, Training Loss: 0.0963%\n",
      "Epoch [70/300], Step [112/225], Training Accuracy: 96.6936%, Training Loss: 0.0960%\n",
      "Epoch [70/300], Step [113/225], Training Accuracy: 96.6814%, Training Loss: 0.0969%\n",
      "Epoch [70/300], Step [114/225], Training Accuracy: 96.6557%, Training Loss: 0.0973%\n",
      "Epoch [70/300], Step [115/225], Training Accuracy: 96.6440%, Training Loss: 0.0972%\n",
      "Epoch [70/300], Step [116/225], Training Accuracy: 96.6460%, Training Loss: 0.0974%\n",
      "Epoch [70/300], Step [117/225], Training Accuracy: 96.6613%, Training Loss: 0.0969%\n",
      "Epoch [70/300], Step [118/225], Training Accuracy: 96.6367%, Training Loss: 0.0975%\n",
      "Epoch [70/300], Step [119/225], Training Accuracy: 96.6518%, Training Loss: 0.0973%\n",
      "Epoch [70/300], Step [120/225], Training Accuracy: 96.6667%, Training Loss: 0.0970%\n",
      "Epoch [70/300], Step [121/225], Training Accuracy: 96.6813%, Training Loss: 0.0967%\n",
      "Epoch [70/300], Step [122/225], Training Accuracy: 96.6573%, Training Loss: 0.0971%\n",
      "Epoch [70/300], Step [123/225], Training Accuracy: 96.6463%, Training Loss: 0.0973%\n",
      "Epoch [70/300], Step [124/225], Training Accuracy: 96.6356%, Training Loss: 0.0973%\n",
      "Epoch [70/300], Step [125/225], Training Accuracy: 96.6625%, Training Loss: 0.0967%\n",
      "Epoch [70/300], Step [126/225], Training Accuracy: 96.6518%, Training Loss: 0.0969%\n",
      "Epoch [70/300], Step [127/225], Training Accuracy: 96.6658%, Training Loss: 0.0968%\n",
      "Epoch [70/300], Step [128/225], Training Accuracy: 96.6553%, Training Loss: 0.0977%\n",
      "Epoch [70/300], Step [129/225], Training Accuracy: 96.6812%, Training Loss: 0.0974%\n",
      "Epoch [70/300], Step [130/225], Training Accuracy: 96.6707%, Training Loss: 0.0973%\n",
      "Epoch [70/300], Step [131/225], Training Accuracy: 96.6722%, Training Loss: 0.0973%\n",
      "Epoch [70/300], Step [132/225], Training Accuracy: 96.6738%, Training Loss: 0.0971%\n",
      "Epoch [70/300], Step [133/225], Training Accuracy: 96.6753%, Training Loss: 0.0969%\n",
      "Epoch [70/300], Step [134/225], Training Accuracy: 96.6884%, Training Loss: 0.0965%\n",
      "Epoch [70/300], Step [135/225], Training Accuracy: 96.6898%, Training Loss: 0.0963%\n",
      "Epoch [70/300], Step [136/225], Training Accuracy: 96.6912%, Training Loss: 0.0964%\n",
      "Epoch [70/300], Step [137/225], Training Accuracy: 96.6697%, Training Loss: 0.0965%\n",
      "Epoch [70/300], Step [138/225], Training Accuracy: 96.6825%, Training Loss: 0.0961%\n",
      "Epoch [70/300], Step [139/225], Training Accuracy: 96.6839%, Training Loss: 0.0959%\n",
      "Epoch [70/300], Step [140/225], Training Accuracy: 96.6964%, Training Loss: 0.0957%\n",
      "Epoch [70/300], Step [141/225], Training Accuracy: 96.6866%, Training Loss: 0.0958%\n",
      "Epoch [70/300], Step [142/225], Training Accuracy: 96.6879%, Training Loss: 0.0955%\n",
      "Epoch [70/300], Step [143/225], Training Accuracy: 96.6565%, Training Loss: 0.0961%\n",
      "Epoch [70/300], Step [144/225], Training Accuracy: 96.6580%, Training Loss: 0.0960%\n",
      "Epoch [70/300], Step [145/225], Training Accuracy: 96.6487%, Training Loss: 0.0959%\n",
      "Epoch [70/300], Step [146/225], Training Accuracy: 96.6503%, Training Loss: 0.0957%\n",
      "Epoch [70/300], Step [147/225], Training Accuracy: 96.6412%, Training Loss: 0.0963%\n",
      "Epoch [70/300], Step [148/225], Training Accuracy: 96.6427%, Training Loss: 0.0961%\n",
      "Epoch [70/300], Step [149/225], Training Accuracy: 96.6653%, Training Loss: 0.0959%\n",
      "Epoch [70/300], Step [150/225], Training Accuracy: 96.6667%, Training Loss: 0.0957%\n",
      "Epoch [70/300], Step [151/225], Training Accuracy: 96.6577%, Training Loss: 0.0956%\n",
      "Epoch [70/300], Step [152/225], Training Accuracy: 96.6694%, Training Loss: 0.0954%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/300], Step [153/225], Training Accuracy: 96.6810%, Training Loss: 0.0951%\n",
      "Epoch [70/300], Step [154/225], Training Accuracy: 96.6822%, Training Loss: 0.0950%\n",
      "Epoch [70/300], Step [155/225], Training Accuracy: 96.6734%, Training Loss: 0.0953%\n",
      "Epoch [70/300], Step [156/225], Training Accuracy: 96.6747%, Training Loss: 0.0952%\n",
      "Epoch [70/300], Step [157/225], Training Accuracy: 96.6760%, Training Loss: 0.0951%\n",
      "Epoch [70/300], Step [158/225], Training Accuracy: 96.6871%, Training Loss: 0.0950%\n",
      "Epoch [70/300], Step [159/225], Training Accuracy: 96.6785%, Training Loss: 0.0950%\n",
      "Epoch [70/300], Step [160/225], Training Accuracy: 96.6797%, Training Loss: 0.0950%\n",
      "Epoch [70/300], Step [161/225], Training Accuracy: 96.6809%, Training Loss: 0.0951%\n",
      "Epoch [70/300], Step [162/225], Training Accuracy: 96.6725%, Training Loss: 0.0953%\n",
      "Epoch [70/300], Step [163/225], Training Accuracy: 96.6545%, Training Loss: 0.0956%\n",
      "Epoch [70/300], Step [164/225], Training Accuracy: 96.6463%, Training Loss: 0.0956%\n",
      "Epoch [70/300], Step [165/225], Training Accuracy: 96.6383%, Training Loss: 0.0954%\n",
      "Epoch [70/300], Step [166/225], Training Accuracy: 96.6114%, Training Loss: 0.0959%\n",
      "Epoch [70/300], Step [167/225], Training Accuracy: 96.6224%, Training Loss: 0.0957%\n",
      "Epoch [70/300], Step [168/225], Training Accuracy: 96.6332%, Training Loss: 0.0956%\n",
      "Epoch [70/300], Step [169/225], Training Accuracy: 96.6439%, Training Loss: 0.0956%\n",
      "Epoch [70/300], Step [170/225], Training Accuracy: 96.6360%, Training Loss: 0.0956%\n",
      "Epoch [70/300], Step [171/225], Training Accuracy: 96.6374%, Training Loss: 0.0958%\n",
      "Epoch [70/300], Step [172/225], Training Accuracy: 96.6116%, Training Loss: 0.0966%\n",
      "Epoch [70/300], Step [173/225], Training Accuracy: 96.6131%, Training Loss: 0.0965%\n",
      "Epoch [70/300], Step [174/225], Training Accuracy: 96.6236%, Training Loss: 0.0964%\n",
      "Epoch [70/300], Step [175/225], Training Accuracy: 96.6339%, Training Loss: 0.0963%\n",
      "Epoch [70/300], Step [176/225], Training Accuracy: 96.6353%, Training Loss: 0.0963%\n",
      "Epoch [70/300], Step [177/225], Training Accuracy: 96.6543%, Training Loss: 0.0961%\n",
      "Epoch [70/300], Step [178/225], Training Accuracy: 96.6555%, Training Loss: 0.0960%\n",
      "Epoch [70/300], Step [179/225], Training Accuracy: 96.6393%, Training Loss: 0.0963%\n",
      "Epoch [70/300], Step [180/225], Training Accuracy: 96.6319%, Training Loss: 0.0966%\n",
      "Epoch [70/300], Step [181/225], Training Accuracy: 96.6247%, Training Loss: 0.0966%\n",
      "Epoch [70/300], Step [182/225], Training Accuracy: 96.6174%, Training Loss: 0.0970%\n",
      "Epoch [70/300], Step [183/225], Training Accuracy: 96.6359%, Training Loss: 0.0968%\n",
      "Epoch [70/300], Step [184/225], Training Accuracy: 96.6202%, Training Loss: 0.0969%\n",
      "Epoch [70/300], Step [185/225], Training Accuracy: 96.6301%, Training Loss: 0.0969%\n",
      "Epoch [70/300], Step [186/225], Training Accuracy: 96.6398%, Training Loss: 0.0966%\n",
      "Epoch [70/300], Step [187/225], Training Accuracy: 96.6327%, Training Loss: 0.0970%\n",
      "Epoch [70/300], Step [188/225], Training Accuracy: 96.6423%, Training Loss: 0.0967%\n",
      "Epoch [70/300], Step [189/225], Training Accuracy: 96.6518%, Training Loss: 0.0965%\n",
      "Epoch [70/300], Step [190/225], Training Accuracy: 96.6365%, Training Loss: 0.0968%\n",
      "Epoch [70/300], Step [191/225], Training Accuracy: 96.6459%, Training Loss: 0.0966%\n",
      "Epoch [70/300], Step [192/225], Training Accuracy: 96.6227%, Training Loss: 0.0971%\n",
      "Epoch [70/300], Step [193/225], Training Accuracy: 96.6240%, Training Loss: 0.0971%\n",
      "Epoch [70/300], Step [194/225], Training Accuracy: 96.6334%, Training Loss: 0.0970%\n",
      "Epoch [70/300], Step [195/225], Training Accuracy: 96.6266%, Training Loss: 0.0971%\n",
      "Epoch [70/300], Step [196/225], Training Accuracy: 96.6358%, Training Loss: 0.0969%\n",
      "Epoch [70/300], Step [197/225], Training Accuracy: 96.6291%, Training Loss: 0.0969%\n",
      "Epoch [70/300], Step [198/225], Training Accuracy: 96.6461%, Training Loss: 0.0966%\n",
      "Epoch [70/300], Step [199/225], Training Accuracy: 96.6473%, Training Loss: 0.0969%\n",
      "Epoch [70/300], Step [200/225], Training Accuracy: 96.6406%, Training Loss: 0.0970%\n",
      "Epoch [70/300], Step [201/225], Training Accuracy: 96.6262%, Training Loss: 0.0971%\n",
      "Epoch [70/300], Step [202/225], Training Accuracy: 96.6275%, Training Loss: 0.0970%\n",
      "Epoch [70/300], Step [203/225], Training Accuracy: 96.6287%, Training Loss: 0.0971%\n",
      "Epoch [70/300], Step [204/225], Training Accuracy: 96.6376%, Training Loss: 0.0969%\n",
      "Epoch [70/300], Step [205/225], Training Accuracy: 96.6463%, Training Loss: 0.0968%\n",
      "Epoch [70/300], Step [206/225], Training Accuracy: 96.6399%, Training Loss: 0.0969%\n",
      "Epoch [70/300], Step [207/225], Training Accuracy: 96.6410%, Training Loss: 0.0968%\n",
      "Epoch [70/300], Step [208/225], Training Accuracy: 96.6496%, Training Loss: 0.0966%\n",
      "Epoch [70/300], Step [209/225], Training Accuracy: 96.6657%, Training Loss: 0.0963%\n",
      "Epoch [70/300], Step [210/225], Training Accuracy: 96.6667%, Training Loss: 0.0965%\n",
      "Epoch [70/300], Step [211/225], Training Accuracy: 96.6602%, Training Loss: 0.0970%\n",
      "Epoch [70/300], Step [212/225], Training Accuracy: 96.6539%, Training Loss: 0.0971%\n",
      "Epoch [70/300], Step [213/225], Training Accuracy: 96.6549%, Training Loss: 0.0971%\n",
      "Epoch [70/300], Step [214/225], Training Accuracy: 96.6633%, Training Loss: 0.0971%\n",
      "Epoch [70/300], Step [215/225], Training Accuracy: 96.6497%, Training Loss: 0.0973%\n",
      "Epoch [70/300], Step [216/225], Training Accuracy: 96.6291%, Training Loss: 0.0976%\n",
      "Epoch [70/300], Step [217/225], Training Accuracy: 96.6230%, Training Loss: 0.0979%\n",
      "Epoch [70/300], Step [218/225], Training Accuracy: 96.6241%, Training Loss: 0.0978%\n",
      "Epoch [70/300], Step [219/225], Training Accuracy: 96.6324%, Training Loss: 0.0976%\n",
      "Epoch [70/300], Step [220/225], Training Accuracy: 96.6335%, Training Loss: 0.0976%\n",
      "Epoch [70/300], Step [221/225], Training Accuracy: 96.6346%, Training Loss: 0.0975%\n",
      "Epoch [70/300], Step [222/225], Training Accuracy: 96.6427%, Training Loss: 0.0975%\n",
      "Epoch [70/300], Step [223/225], Training Accuracy: 96.6438%, Training Loss: 0.0974%\n",
      "Epoch [70/300], Step [224/225], Training Accuracy: 96.6588%, Training Loss: 0.0972%\n",
      "Epoch [70/300], Step [225/225], Training Accuracy: 96.6648%, Training Loss: 0.0970%\n",
      "Epoch [71/300], Step [1/225], Training Accuracy: 92.1875%, Training Loss: 0.1599%\n",
      "Epoch [71/300], Step [2/225], Training Accuracy: 95.3125%, Training Loss: 0.1082%\n",
      "Epoch [71/300], Step [3/225], Training Accuracy: 95.8333%, Training Loss: 0.0999%\n",
      "Epoch [71/300], Step [4/225], Training Accuracy: 96.4844%, Training Loss: 0.0932%\n",
      "Epoch [71/300], Step [5/225], Training Accuracy: 96.2500%, Training Loss: 0.0983%\n",
      "Epoch [71/300], Step [6/225], Training Accuracy: 96.3542%, Training Loss: 0.0942%\n",
      "Epoch [71/300], Step [7/225], Training Accuracy: 96.6518%, Training Loss: 0.0893%\n",
      "Epoch [71/300], Step [8/225], Training Accuracy: 96.6797%, Training Loss: 0.0898%\n",
      "Epoch [71/300], Step [9/225], Training Accuracy: 96.7014%, Training Loss: 0.0907%\n",
      "Epoch [71/300], Step [10/225], Training Accuracy: 97.0312%, Training Loss: 0.0859%\n",
      "Epoch [71/300], Step [11/225], Training Accuracy: 97.1591%, Training Loss: 0.0831%\n",
      "Epoch [71/300], Step [12/225], Training Accuracy: 97.1354%, Training Loss: 0.0816%\n",
      "Epoch [71/300], Step [13/225], Training Accuracy: 97.1154%, Training Loss: 0.0846%\n",
      "Epoch [71/300], Step [14/225], Training Accuracy: 97.2098%, Training Loss: 0.0844%\n",
      "Epoch [71/300], Step [15/225], Training Accuracy: 97.2917%, Training Loss: 0.0824%\n",
      "Epoch [71/300], Step [16/225], Training Accuracy: 97.1680%, Training Loss: 0.0857%\n",
      "Epoch [71/300], Step [17/225], Training Accuracy: 96.8750%, Training Loss: 0.0894%\n",
      "Epoch [71/300], Step [18/225], Training Accuracy: 96.7014%, Training Loss: 0.0934%\n",
      "Epoch [71/300], Step [19/225], Training Accuracy: 96.7105%, Training Loss: 0.0936%\n",
      "Epoch [71/300], Step [20/225], Training Accuracy: 96.4844%, Training Loss: 0.0967%\n",
      "Epoch [71/300], Step [21/225], Training Accuracy: 96.6518%, Training Loss: 0.0937%\n",
      "Epoch [71/300], Step [22/225], Training Accuracy: 96.5909%, Training Loss: 0.0961%\n",
      "Epoch [71/300], Step [23/225], Training Accuracy: 96.5353%, Training Loss: 0.0987%\n",
      "Epoch [71/300], Step [24/225], Training Accuracy: 96.5495%, Training Loss: 0.0992%\n",
      "Epoch [71/300], Step [25/225], Training Accuracy: 96.6250%, Training Loss: 0.0993%\n",
      "Epoch [71/300], Step [26/225], Training Accuracy: 96.5745%, Training Loss: 0.0997%\n",
      "Epoch [71/300], Step [27/225], Training Accuracy: 96.5278%, Training Loss: 0.0999%\n",
      "Epoch [71/300], Step [28/225], Training Accuracy: 96.5402%, Training Loss: 0.0989%\n",
      "Epoch [71/300], Step [29/225], Training Accuracy: 96.5517%, Training Loss: 0.0984%\n",
      "Epoch [71/300], Step [30/225], Training Accuracy: 96.4583%, Training Loss: 0.0993%\n",
      "Epoch [71/300], Step [31/225], Training Accuracy: 96.4718%, Training Loss: 0.0987%\n",
      "Epoch [71/300], Step [32/225], Training Accuracy: 96.4844%, Training Loss: 0.0980%\n",
      "Epoch [71/300], Step [33/225], Training Accuracy: 96.5436%, Training Loss: 0.0966%\n",
      "Epoch [71/300], Step [34/225], Training Accuracy: 96.5533%, Training Loss: 0.0962%\n",
      "Epoch [71/300], Step [35/225], Training Accuracy: 96.3393%, Training Loss: 0.0990%\n",
      "Epoch [71/300], Step [36/225], Training Accuracy: 96.3108%, Training Loss: 0.0998%\n",
      "Epoch [71/300], Step [37/225], Training Accuracy: 96.3682%, Training Loss: 0.1000%\n",
      "Epoch [71/300], Step [38/225], Training Accuracy: 96.3405%, Training Loss: 0.1009%\n",
      "Epoch [71/300], Step [39/225], Training Accuracy: 96.3542%, Training Loss: 0.1014%\n",
      "Epoch [71/300], Step [40/225], Training Accuracy: 96.4062%, Training Loss: 0.1008%\n",
      "Epoch [71/300], Step [41/225], Training Accuracy: 96.4177%, Training Loss: 0.1004%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/300], Step [42/225], Training Accuracy: 96.4658%, Training Loss: 0.1000%\n",
      "Epoch [71/300], Step [43/225], Training Accuracy: 96.4753%, Training Loss: 0.0994%\n",
      "Epoch [71/300], Step [44/225], Training Accuracy: 96.4844%, Training Loss: 0.0986%\n",
      "Epoch [71/300], Step [45/225], Training Accuracy: 96.5278%, Training Loss: 0.0971%\n",
      "Epoch [71/300], Step [46/225], Training Accuracy: 96.5014%, Training Loss: 0.0970%\n",
      "Epoch [71/300], Step [47/225], Training Accuracy: 96.5093%, Training Loss: 0.0967%\n",
      "Epoch [71/300], Step [48/225], Training Accuracy: 96.5169%, Training Loss: 0.0969%\n",
      "Epoch [71/300], Step [49/225], Training Accuracy: 96.5242%, Training Loss: 0.0963%\n",
      "Epoch [71/300], Step [50/225], Training Accuracy: 96.5312%, Training Loss: 0.0960%\n",
      "Epoch [71/300], Step [51/225], Training Accuracy: 96.5686%, Training Loss: 0.0949%\n",
      "Epoch [71/300], Step [52/225], Training Accuracy: 96.5745%, Training Loss: 0.0943%\n",
      "Epoch [71/300], Step [53/225], Training Accuracy: 96.4623%, Training Loss: 0.0958%\n",
      "Epoch [71/300], Step [54/225], Training Accuracy: 96.4699%, Training Loss: 0.0957%\n",
      "Epoch [71/300], Step [55/225], Training Accuracy: 96.5341%, Training Loss: 0.0943%\n",
      "Epoch [71/300], Step [56/225], Training Accuracy: 96.5123%, Training Loss: 0.0947%\n",
      "Epoch [71/300], Step [57/225], Training Accuracy: 96.4912%, Training Loss: 0.0947%\n",
      "Epoch [71/300], Step [58/225], Training Accuracy: 96.5248%, Training Loss: 0.0948%\n",
      "Epoch [71/300], Step [59/225], Training Accuracy: 96.5572%, Training Loss: 0.0947%\n",
      "Epoch [71/300], Step [60/225], Training Accuracy: 96.5365%, Training Loss: 0.0952%\n",
      "Epoch [71/300], Step [61/225], Training Accuracy: 96.5164%, Training Loss: 0.0953%\n",
      "Epoch [71/300], Step [62/225], Training Accuracy: 96.5474%, Training Loss: 0.0946%\n",
      "Epoch [71/300], Step [63/225], Training Accuracy: 96.5278%, Training Loss: 0.0952%\n",
      "Epoch [71/300], Step [64/225], Training Accuracy: 96.4844%, Training Loss: 0.0954%\n",
      "Epoch [71/300], Step [65/225], Training Accuracy: 96.5144%, Training Loss: 0.0948%\n",
      "Epoch [71/300], Step [66/225], Training Accuracy: 96.5199%, Training Loss: 0.0946%\n",
      "Epoch [71/300], Step [67/225], Training Accuracy: 96.4785%, Training Loss: 0.0956%\n",
      "Epoch [71/300], Step [68/225], Training Accuracy: 96.4844%, Training Loss: 0.0956%\n",
      "Epoch [71/300], Step [69/225], Training Accuracy: 96.4447%, Training Loss: 0.0967%\n",
      "Epoch [71/300], Step [70/225], Training Accuracy: 96.4732%, Training Loss: 0.0960%\n",
      "Epoch [71/300], Step [71/225], Training Accuracy: 96.4569%, Training Loss: 0.0958%\n",
      "Epoch [71/300], Step [72/225], Training Accuracy: 96.4410%, Training Loss: 0.0957%\n",
      "Epoch [71/300], Step [73/225], Training Accuracy: 96.4469%, Training Loss: 0.0958%\n",
      "Epoch [71/300], Step [74/225], Training Accuracy: 96.4316%, Training Loss: 0.0972%\n",
      "Epoch [71/300], Step [75/225], Training Accuracy: 96.4375%, Training Loss: 0.0978%\n",
      "Epoch [71/300], Step [76/225], Training Accuracy: 96.3816%, Training Loss: 0.0991%\n",
      "Epoch [71/300], Step [77/225], Training Accuracy: 96.3880%, Training Loss: 0.0994%\n",
      "Epoch [71/300], Step [78/225], Training Accuracy: 96.3942%, Training Loss: 0.0989%\n",
      "Epoch [71/300], Step [79/225], Training Accuracy: 96.4003%, Training Loss: 0.0997%\n",
      "Epoch [71/300], Step [80/225], Training Accuracy: 96.4062%, Training Loss: 0.0997%\n",
      "Epoch [71/300], Step [81/225], Training Accuracy: 96.3927%, Training Loss: 0.0995%\n",
      "Epoch [71/300], Step [82/225], Training Accuracy: 96.4177%, Training Loss: 0.0997%\n",
      "Epoch [71/300], Step [83/225], Training Accuracy: 96.3667%, Training Loss: 0.1005%\n",
      "Epoch [71/300], Step [84/225], Training Accuracy: 96.3542%, Training Loss: 0.1011%\n",
      "Epoch [71/300], Step [85/225], Training Accuracy: 96.3787%, Training Loss: 0.1006%\n",
      "Epoch [71/300], Step [86/225], Training Accuracy: 96.3844%, Training Loss: 0.1007%\n",
      "Epoch [71/300], Step [87/225], Training Accuracy: 96.4080%, Training Loss: 0.1006%\n",
      "Epoch [71/300], Step [88/225], Training Accuracy: 96.3601%, Training Loss: 0.1010%\n",
      "Epoch [71/300], Step [89/225], Training Accuracy: 96.3308%, Training Loss: 0.1016%\n",
      "Epoch [71/300], Step [90/225], Training Accuracy: 96.3368%, Training Loss: 0.1015%\n",
      "Epoch [71/300], Step [91/225], Training Accuracy: 96.3255%, Training Loss: 0.1012%\n",
      "Epoch [71/300], Step [92/225], Training Accuracy: 96.3315%, Training Loss: 0.1013%\n",
      "Epoch [71/300], Step [93/225], Training Accuracy: 96.3206%, Training Loss: 0.1012%\n",
      "Epoch [71/300], Step [94/225], Training Accuracy: 96.3431%, Training Loss: 0.1009%\n",
      "Epoch [71/300], Step [95/225], Training Accuracy: 96.3158%, Training Loss: 0.1015%\n",
      "Epoch [71/300], Step [96/225], Training Accuracy: 96.3216%, Training Loss: 0.1014%\n",
      "Epoch [71/300], Step [97/225], Training Accuracy: 96.3112%, Training Loss: 0.1016%\n",
      "Epoch [71/300], Step [98/225], Training Accuracy: 96.2851%, Training Loss: 0.1019%\n",
      "Epoch [71/300], Step [99/225], Training Accuracy: 96.2753%, Training Loss: 0.1020%\n",
      "Epoch [71/300], Step [100/225], Training Accuracy: 96.2812%, Training Loss: 0.1017%\n",
      "Epoch [71/300], Step [101/225], Training Accuracy: 96.3026%, Training Loss: 0.1018%\n",
      "Epoch [71/300], Step [102/225], Training Accuracy: 96.3388%, Training Loss: 0.1012%\n",
      "Epoch [71/300], Step [103/225], Training Accuracy: 96.3441%, Training Loss: 0.1013%\n",
      "Epoch [71/300], Step [104/225], Training Accuracy: 96.3792%, Training Loss: 0.1008%\n",
      "Epoch [71/300], Step [105/225], Training Accuracy: 96.3690%, Training Loss: 0.1011%\n",
      "Epoch [71/300], Step [106/225], Training Accuracy: 96.3443%, Training Loss: 0.1020%\n",
      "Epoch [71/300], Step [107/225], Training Accuracy: 96.3639%, Training Loss: 0.1018%\n",
      "Epoch [71/300], Step [108/225], Training Accuracy: 96.3686%, Training Loss: 0.1018%\n",
      "Epoch [71/300], Step [109/225], Training Accuracy: 96.3876%, Training Loss: 0.1015%\n",
      "Epoch [71/300], Step [110/225], Training Accuracy: 96.4062%, Training Loss: 0.1010%\n",
      "Epoch [71/300], Step [111/225], Training Accuracy: 96.4386%, Training Loss: 0.1003%\n",
      "Epoch [71/300], Step [112/225], Training Accuracy: 96.4704%, Training Loss: 0.0999%\n",
      "Epoch [71/300], Step [113/225], Training Accuracy: 96.4463%, Training Loss: 0.1000%\n",
      "Epoch [71/300], Step [114/225], Training Accuracy: 96.4090%, Training Loss: 0.1005%\n",
      "Epoch [71/300], Step [115/225], Training Accuracy: 96.4266%, Training Loss: 0.1000%\n",
      "Epoch [71/300], Step [116/225], Training Accuracy: 96.4305%, Training Loss: 0.0997%\n",
      "Epoch [71/300], Step [117/225], Training Accuracy: 96.4610%, Training Loss: 0.0991%\n",
      "Epoch [71/300], Step [118/225], Training Accuracy: 96.4513%, Training Loss: 0.0990%\n",
      "Epoch [71/300], Step [119/225], Training Accuracy: 96.4548%, Training Loss: 0.0991%\n",
      "Epoch [71/300], Step [120/225], Training Accuracy: 96.4453%, Training Loss: 0.0993%\n",
      "Epoch [71/300], Step [121/225], Training Accuracy: 96.4360%, Training Loss: 0.1001%\n",
      "Epoch [71/300], Step [122/225], Training Accuracy: 96.4524%, Training Loss: 0.0996%\n",
      "Epoch [71/300], Step [123/225], Training Accuracy: 96.4177%, Training Loss: 0.1005%\n",
      "Epoch [71/300], Step [124/225], Training Accuracy: 96.4214%, Training Loss: 0.1001%\n",
      "Epoch [71/300], Step [125/225], Training Accuracy: 96.4250%, Training Loss: 0.1000%\n",
      "Epoch [71/300], Step [126/225], Training Accuracy: 96.4410%, Training Loss: 0.0998%\n",
      "Epoch [71/300], Step [127/225], Training Accuracy: 96.4198%, Training Loss: 0.1003%\n",
      "Epoch [71/300], Step [128/225], Training Accuracy: 96.4355%, Training Loss: 0.1002%\n",
      "Epoch [71/300], Step [129/225], Training Accuracy: 96.4390%, Training Loss: 0.1000%\n",
      "Epoch [71/300], Step [130/225], Training Accuracy: 96.4062%, Training Loss: 0.1005%\n",
      "Epoch [71/300], Step [131/225], Training Accuracy: 96.4337%, Training Loss: 0.1001%\n",
      "Epoch [71/300], Step [132/225], Training Accuracy: 96.4370%, Training Loss: 0.0998%\n",
      "Epoch [71/300], Step [133/225], Training Accuracy: 96.4286%, Training Loss: 0.0995%\n",
      "Epoch [71/300], Step [134/225], Training Accuracy: 96.4086%, Training Loss: 0.0999%\n",
      "Epoch [71/300], Step [135/225], Training Accuracy: 96.4352%, Training Loss: 0.0995%\n",
      "Epoch [71/300], Step [136/225], Training Accuracy: 96.4040%, Training Loss: 0.0998%\n",
      "Epoch [71/300], Step [137/225], Training Accuracy: 96.4188%, Training Loss: 0.0995%\n",
      "Epoch [71/300], Step [138/225], Training Accuracy: 96.4221%, Training Loss: 0.0996%\n",
      "Epoch [71/300], Step [139/225], Training Accuracy: 96.4141%, Training Loss: 0.0995%\n",
      "Epoch [71/300], Step [140/225], Training Accuracy: 96.4397%, Training Loss: 0.0992%\n",
      "Epoch [71/300], Step [141/225], Training Accuracy: 96.4539%, Training Loss: 0.0989%\n",
      "Epoch [71/300], Step [142/225], Training Accuracy: 96.4459%, Training Loss: 0.0990%\n",
      "Epoch [71/300], Step [143/225], Training Accuracy: 96.4489%, Training Loss: 0.0989%\n",
      "Epoch [71/300], Step [144/225], Training Accuracy: 96.4735%, Training Loss: 0.0987%\n",
      "Epoch [71/300], Step [145/225], Training Accuracy: 96.4763%, Training Loss: 0.0987%\n",
      "Epoch [71/300], Step [146/225], Training Accuracy: 96.4897%, Training Loss: 0.0988%\n",
      "Epoch [71/300], Step [147/225], Training Accuracy: 96.4923%, Training Loss: 0.0988%\n",
      "Epoch [71/300], Step [148/225], Training Accuracy: 96.4738%, Training Loss: 0.0990%\n",
      "Epoch [71/300], Step [149/225], Training Accuracy: 96.4451%, Training Loss: 0.0998%\n",
      "Epoch [71/300], Step [150/225], Training Accuracy: 96.4479%, Training Loss: 0.0997%\n",
      "Epoch [71/300], Step [151/225], Training Accuracy: 96.4507%, Training Loss: 0.0994%\n",
      "Epoch [71/300], Step [152/225], Training Accuracy: 96.4330%, Training Loss: 0.0997%\n",
      "Epoch [71/300], Step [153/225], Training Accuracy: 96.4461%, Training Loss: 0.0995%\n",
      "Epoch [71/300], Step [154/225], Training Accuracy: 96.4387%, Training Loss: 0.0996%\n",
      "Epoch [71/300], Step [155/225], Training Accuracy: 96.4617%, Training Loss: 0.0992%\n",
      "Epoch [71/300], Step [156/225], Training Accuracy: 96.4443%, Training Loss: 0.0992%\n",
      "Epoch [71/300], Step [157/225], Training Accuracy: 96.4570%, Training Loss: 0.0991%\n",
      "Epoch [71/300], Step [158/225], Training Accuracy: 96.4695%, Training Loss: 0.0988%\n",
      "Epoch [71/300], Step [159/225], Training Accuracy: 96.4524%, Training Loss: 0.0993%\n",
      "Epoch [71/300], Step [160/225], Training Accuracy: 96.4258%, Training Loss: 0.0992%\n",
      "Epoch [71/300], Step [161/225], Training Accuracy: 96.4383%, Training Loss: 0.0989%\n",
      "Epoch [71/300], Step [162/225], Training Accuracy: 96.4506%, Training Loss: 0.0988%\n",
      "Epoch [71/300], Step [163/225], Training Accuracy: 96.4436%, Training Loss: 0.0991%\n",
      "Epoch [71/300], Step [164/225], Training Accuracy: 96.4272%, Training Loss: 0.0993%\n",
      "Epoch [71/300], Step [165/225], Training Accuracy: 96.4394%, Training Loss: 0.0989%\n",
      "Epoch [71/300], Step [166/225], Training Accuracy: 96.4420%, Training Loss: 0.0990%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/300], Step [167/225], Training Accuracy: 96.3978%, Training Loss: 0.0997%\n",
      "Epoch [71/300], Step [168/225], Training Accuracy: 96.4007%, Training Loss: 0.0995%\n",
      "Epoch [71/300], Step [169/225], Training Accuracy: 96.4127%, Training Loss: 0.0993%\n",
      "Epoch [71/300], Step [170/225], Training Accuracy: 96.4062%, Training Loss: 0.0995%\n",
      "Epoch [71/300], Step [171/225], Training Accuracy: 96.4181%, Training Loss: 0.0992%\n",
      "Epoch [71/300], Step [172/225], Training Accuracy: 96.4299%, Training Loss: 0.0991%\n",
      "Epoch [71/300], Step [173/225], Training Accuracy: 96.4415%, Training Loss: 0.0989%\n",
      "Epoch [71/300], Step [174/225], Training Accuracy: 96.4440%, Training Loss: 0.0987%\n",
      "Epoch [71/300], Step [175/225], Training Accuracy: 96.4464%, Training Loss: 0.0985%\n",
      "Epoch [71/300], Step [176/225], Training Accuracy: 96.4666%, Training Loss: 0.0982%\n",
      "Epoch [71/300], Step [177/225], Training Accuracy: 96.4866%, Training Loss: 0.0979%\n",
      "Epoch [71/300], Step [178/225], Training Accuracy: 96.4975%, Training Loss: 0.0978%\n",
      "Epoch [71/300], Step [179/225], Training Accuracy: 96.4997%, Training Loss: 0.0981%\n",
      "Epoch [71/300], Step [180/225], Training Accuracy: 96.4931%, Training Loss: 0.0983%\n",
      "Epoch [71/300], Step [181/225], Training Accuracy: 96.5038%, Training Loss: 0.0984%\n",
      "Epoch [71/300], Step [182/225], Training Accuracy: 96.5144%, Training Loss: 0.0983%\n",
      "Epoch [71/300], Step [183/225], Training Accuracy: 96.5335%, Training Loss: 0.0980%\n",
      "Epoch [71/300], Step [184/225], Training Accuracy: 96.5353%, Training Loss: 0.0980%\n",
      "Epoch [71/300], Step [185/225], Training Accuracy: 96.5541%, Training Loss: 0.0976%\n",
      "Epoch [71/300], Step [186/225], Training Accuracy: 96.5558%, Training Loss: 0.0974%\n",
      "Epoch [71/300], Step [187/225], Training Accuracy: 96.5491%, Training Loss: 0.0976%\n",
      "Epoch [71/300], Step [188/225], Training Accuracy: 96.5509%, Training Loss: 0.0974%\n",
      "Epoch [71/300], Step [189/225], Training Accuracy: 96.5691%, Training Loss: 0.0970%\n",
      "Epoch [71/300], Step [190/225], Training Accuracy: 96.5872%, Training Loss: 0.0967%\n",
      "Epoch [71/300], Step [191/225], Training Accuracy: 96.5805%, Training Loss: 0.0969%\n",
      "Epoch [71/300], Step [192/225], Training Accuracy: 96.5739%, Training Loss: 0.0970%\n",
      "Epoch [71/300], Step [193/225], Training Accuracy: 96.5835%, Training Loss: 0.0969%\n",
      "Epoch [71/300], Step [194/225], Training Accuracy: 96.5770%, Training Loss: 0.0968%\n",
      "Epoch [71/300], Step [195/225], Training Accuracy: 96.5785%, Training Loss: 0.0966%\n",
      "Epoch [71/300], Step [196/225], Training Accuracy: 96.5880%, Training Loss: 0.0965%\n",
      "Epoch [71/300], Step [197/225], Training Accuracy: 96.5895%, Training Loss: 0.0965%\n",
      "Epoch [71/300], Step [198/225], Training Accuracy: 96.5909%, Training Loss: 0.0964%\n",
      "Epoch [71/300], Step [199/225], Training Accuracy: 96.5766%, Training Loss: 0.0966%\n",
      "Epoch [71/300], Step [200/225], Training Accuracy: 96.5859%, Training Loss: 0.0964%\n",
      "Epoch [71/300], Step [201/225], Training Accuracy: 96.5796%, Training Loss: 0.0964%\n",
      "Epoch [71/300], Step [202/225], Training Accuracy: 96.5811%, Training Loss: 0.0963%\n",
      "Epoch [71/300], Step [203/225], Training Accuracy: 96.5902%, Training Loss: 0.0960%\n",
      "Epoch [71/300], Step [204/225], Training Accuracy: 96.5993%, Training Loss: 0.0960%\n",
      "Epoch [71/300], Step [205/225], Training Accuracy: 96.6006%, Training Loss: 0.0958%\n",
      "Epoch [71/300], Step [206/225], Training Accuracy: 96.5868%, Training Loss: 0.0959%\n",
      "Epoch [71/300], Step [207/225], Training Accuracy: 96.5731%, Training Loss: 0.0959%\n",
      "Epoch [71/300], Step [208/225], Training Accuracy: 96.5745%, Training Loss: 0.0957%\n",
      "Epoch [71/300], Step [209/225], Training Accuracy: 96.5909%, Training Loss: 0.0954%\n",
      "Epoch [71/300], Step [210/225], Training Accuracy: 96.5848%, Training Loss: 0.0955%\n",
      "Epoch [71/300], Step [211/225], Training Accuracy: 96.6010%, Training Loss: 0.0953%\n",
      "Epoch [71/300], Step [212/225], Training Accuracy: 96.6023%, Training Loss: 0.0953%\n",
      "Epoch [71/300], Step [213/225], Training Accuracy: 96.6036%, Training Loss: 0.0952%\n",
      "Epoch [71/300], Step [214/225], Training Accuracy: 96.6195%, Training Loss: 0.0950%\n",
      "Epoch [71/300], Step [215/225], Training Accuracy: 96.6352%, Training Loss: 0.0947%\n",
      "Epoch [71/300], Step [216/225], Training Accuracy: 96.6363%, Training Loss: 0.0947%\n",
      "Epoch [71/300], Step [217/225], Training Accuracy: 96.6446%, Training Loss: 0.0944%\n",
      "Epoch [71/300], Step [218/225], Training Accuracy: 96.6456%, Training Loss: 0.0945%\n",
      "Epoch [71/300], Step [219/225], Training Accuracy: 96.6324%, Training Loss: 0.0947%\n",
      "Epoch [71/300], Step [220/225], Training Accuracy: 96.6406%, Training Loss: 0.0945%\n",
      "Epoch [71/300], Step [221/225], Training Accuracy: 96.6275%, Training Loss: 0.0949%\n",
      "Epoch [71/300], Step [222/225], Training Accuracy: 96.6287%, Training Loss: 0.0950%\n",
      "Epoch [71/300], Step [223/225], Training Accuracy: 96.6298%, Training Loss: 0.0948%\n",
      "Epoch [71/300], Step [224/225], Training Accuracy: 96.6309%, Training Loss: 0.0949%\n",
      "Epoch [71/300], Step [225/225], Training Accuracy: 96.6301%, Training Loss: 0.0951%\n",
      "Epoch [72/300], Step [1/225], Training Accuracy: 98.4375%, Training Loss: 0.0401%\n",
      "Epoch [72/300], Step [2/225], Training Accuracy: 96.8750%, Training Loss: 0.0845%\n",
      "Epoch [72/300], Step [3/225], Training Accuracy: 95.8333%, Training Loss: 0.1049%\n",
      "Epoch [72/300], Step [4/225], Training Accuracy: 96.4844%, Training Loss: 0.0949%\n",
      "Epoch [72/300], Step [5/225], Training Accuracy: 96.8750%, Training Loss: 0.0873%\n",
      "Epoch [72/300], Step [6/225], Training Accuracy: 96.0938%, Training Loss: 0.0920%\n",
      "Epoch [72/300], Step [7/225], Training Accuracy: 96.4286%, Training Loss: 0.0900%\n",
      "Epoch [72/300], Step [8/225], Training Accuracy: 96.4844%, Training Loss: 0.0900%\n",
      "Epoch [72/300], Step [9/225], Training Accuracy: 96.7014%, Training Loss: 0.0844%\n",
      "Epoch [72/300], Step [10/225], Training Accuracy: 96.0938%, Training Loss: 0.1024%\n",
      "Epoch [72/300], Step [11/225], Training Accuracy: 96.3068%, Training Loss: 0.0993%\n",
      "Epoch [72/300], Step [12/225], Training Accuracy: 96.4844%, Training Loss: 0.0945%\n",
      "Epoch [72/300], Step [13/225], Training Accuracy: 96.2740%, Training Loss: 0.0988%\n",
      "Epoch [72/300], Step [14/225], Training Accuracy: 96.2054%, Training Loss: 0.0987%\n",
      "Epoch [72/300], Step [15/225], Training Accuracy: 96.2500%, Training Loss: 0.0974%\n",
      "Epoch [72/300], Step [16/225], Training Accuracy: 96.4844%, Training Loss: 0.0944%\n",
      "Epoch [72/300], Step [17/225], Training Accuracy: 96.5993%, Training Loss: 0.0929%\n",
      "Epoch [72/300], Step [18/225], Training Accuracy: 96.4410%, Training Loss: 0.0978%\n",
      "Epoch [72/300], Step [19/225], Training Accuracy: 96.4638%, Training Loss: 0.0972%\n",
      "Epoch [72/300], Step [20/225], Training Accuracy: 96.4844%, Training Loss: 0.1006%\n",
      "Epoch [72/300], Step [21/225], Training Accuracy: 96.4286%, Training Loss: 0.0997%\n",
      "Epoch [72/300], Step [22/225], Training Accuracy: 96.5909%, Training Loss: 0.0976%\n",
      "Epoch [72/300], Step [23/225], Training Accuracy: 96.6712%, Training Loss: 0.0949%\n",
      "Epoch [72/300], Step [24/225], Training Accuracy: 96.4844%, Training Loss: 0.0972%\n",
      "Epoch [72/300], Step [25/225], Training Accuracy: 96.5000%, Training Loss: 0.0961%\n",
      "Epoch [72/300], Step [26/225], Training Accuracy: 96.3942%, Training Loss: 0.0962%\n",
      "Epoch [72/300], Step [27/225], Training Accuracy: 96.3542%, Training Loss: 0.0985%\n",
      "Epoch [72/300], Step [28/225], Training Accuracy: 96.4844%, Training Loss: 0.0967%\n",
      "Epoch [72/300], Step [29/225], Training Accuracy: 96.4440%, Training Loss: 0.0967%\n",
      "Epoch [72/300], Step [30/225], Training Accuracy: 96.4062%, Training Loss: 0.0963%\n",
      "Epoch [72/300], Step [31/225], Training Accuracy: 96.4718%, Training Loss: 0.0959%\n",
      "Epoch [72/300], Step [32/225], Training Accuracy: 96.4844%, Training Loss: 0.0950%\n",
      "Epoch [72/300], Step [33/225], Training Accuracy: 96.4489%, Training Loss: 0.0969%\n",
      "Epoch [72/300], Step [34/225], Training Accuracy: 96.3695%, Training Loss: 0.1017%\n",
      "Epoch [72/300], Step [35/225], Training Accuracy: 96.3839%, Training Loss: 0.1018%\n",
      "Epoch [72/300], Step [36/225], Training Accuracy: 96.4410%, Training Loss: 0.1008%\n",
      "Epoch [72/300], Step [37/225], Training Accuracy: 96.4527%, Training Loss: 0.1003%\n",
      "Epoch [72/300], Step [38/225], Training Accuracy: 96.5049%, Training Loss: 0.1003%\n",
      "Epoch [72/300], Step [39/225], Training Accuracy: 96.4744%, Training Loss: 0.1001%\n",
      "Epoch [72/300], Step [40/225], Training Accuracy: 96.4844%, Training Loss: 0.0994%\n",
      "Epoch [72/300], Step [41/225], Training Accuracy: 96.5320%, Training Loss: 0.0990%\n",
      "Epoch [72/300], Step [42/225], Training Accuracy: 96.6146%, Training Loss: 0.0975%\n",
      "Epoch [72/300], Step [43/225], Training Accuracy: 96.6206%, Training Loss: 0.0969%\n",
      "Epoch [72/300], Step [44/225], Training Accuracy: 96.6264%, Training Loss: 0.0967%\n",
      "Epoch [72/300], Step [45/225], Training Accuracy: 96.6319%, Training Loss: 0.0960%\n",
      "Epoch [72/300], Step [46/225], Training Accuracy: 96.7052%, Training Loss: 0.0948%\n",
      "Epoch [72/300], Step [47/225], Training Accuracy: 96.7420%, Training Loss: 0.0942%\n",
      "Epoch [72/300], Step [48/225], Training Accuracy: 96.7773%, Training Loss: 0.0932%\n",
      "Epoch [72/300], Step [49/225], Training Accuracy: 96.8431%, Training Loss: 0.0924%\n",
      "Epoch [72/300], Step [50/225], Training Accuracy: 96.8125%, Training Loss: 0.0930%\n",
      "Epoch [72/300], Step [51/225], Training Accuracy: 96.8444%, Training Loss: 0.0921%\n",
      "Epoch [72/300], Step [52/225], Training Accuracy: 96.8750%, Training Loss: 0.0913%\n",
      "Epoch [72/300], Step [53/225], Training Accuracy: 96.8750%, Training Loss: 0.0917%\n",
      "Epoch [72/300], Step [54/225], Training Accuracy: 96.7882%, Training Loss: 0.0924%\n",
      "Epoch [72/300], Step [55/225], Training Accuracy: 96.8182%, Training Loss: 0.0915%\n",
      "Epoch [72/300], Step [56/225], Training Accuracy: 96.7634%, Training Loss: 0.0917%\n",
      "Epoch [72/300], Step [57/225], Training Accuracy: 96.8202%, Training Loss: 0.0907%\n",
      "Epoch [72/300], Step [58/225], Training Accuracy: 96.8750%, Training Loss: 0.0894%\n",
      "Epoch [72/300], Step [59/225], Training Accuracy: 96.8485%, Training Loss: 0.0895%\n",
      "Epoch [72/300], Step [60/225], Training Accuracy: 96.8750%, Training Loss: 0.0889%\n",
      "Epoch [72/300], Step [61/225], Training Accuracy: 96.8238%, Training Loss: 0.0903%\n",
      "Epoch [72/300], Step [62/225], Training Accuracy: 96.8246%, Training Loss: 0.0902%\n",
      "Epoch [72/300], Step [63/225], Training Accuracy: 96.8254%, Training Loss: 0.0895%\n",
      "Epoch [72/300], Step [64/225], Training Accuracy: 96.8262%, Training Loss: 0.0892%\n",
      "Epoch [72/300], Step [65/225], Training Accuracy: 96.8269%, Training Loss: 0.0890%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/300], Step [66/225], Training Accuracy: 96.8277%, Training Loss: 0.0889%\n",
      "Epoch [72/300], Step [67/225], Training Accuracy: 96.8284%, Training Loss: 0.0886%\n",
      "Epoch [72/300], Step [68/225], Training Accuracy: 96.8061%, Training Loss: 0.0895%\n",
      "Epoch [72/300], Step [69/225], Training Accuracy: 96.7391%, Training Loss: 0.0907%\n",
      "Epoch [72/300], Step [70/225], Training Accuracy: 96.7857%, Training Loss: 0.0900%\n",
      "Epoch [72/300], Step [71/225], Training Accuracy: 96.8090%, Training Loss: 0.0899%\n",
      "Epoch [72/300], Step [72/225], Training Accuracy: 96.8316%, Training Loss: 0.0895%\n",
      "Epoch [72/300], Step [73/225], Training Accuracy: 96.8750%, Training Loss: 0.0888%\n",
      "Epoch [72/300], Step [74/225], Training Accuracy: 96.8328%, Training Loss: 0.0890%\n",
      "Epoch [72/300], Step [75/225], Training Accuracy: 96.8125%, Training Loss: 0.0895%\n",
      "Epoch [72/300], Step [76/225], Training Accuracy: 96.8133%, Training Loss: 0.0892%\n",
      "Epoch [72/300], Step [77/225], Training Accuracy: 96.8344%, Training Loss: 0.0888%\n",
      "Epoch [72/300], Step [78/225], Training Accuracy: 96.8349%, Training Loss: 0.0889%\n",
      "Epoch [72/300], Step [79/225], Training Accuracy: 96.8354%, Training Loss: 0.0890%\n",
      "Epoch [72/300], Step [80/225], Training Accuracy: 96.8359%, Training Loss: 0.0888%\n",
      "Epoch [72/300], Step [81/225], Training Accuracy: 96.8364%, Training Loss: 0.0888%\n",
      "Epoch [72/300], Step [82/225], Training Accuracy: 96.7797%, Training Loss: 0.0894%\n",
      "Epoch [72/300], Step [83/225], Training Accuracy: 96.7809%, Training Loss: 0.0900%\n",
      "Epoch [72/300], Step [84/225], Training Accuracy: 96.7448%, Training Loss: 0.0903%\n",
      "Epoch [72/300], Step [85/225], Training Accuracy: 96.7647%, Training Loss: 0.0901%\n",
      "Epoch [72/300], Step [86/225], Training Accuracy: 96.7842%, Training Loss: 0.0901%\n",
      "Epoch [72/300], Step [87/225], Training Accuracy: 96.8032%, Training Loss: 0.0896%\n",
      "Epoch [72/300], Step [88/225], Training Accuracy: 96.8217%, Training Loss: 0.0895%\n",
      "Epoch [72/300], Step [89/225], Training Accuracy: 96.8048%, Training Loss: 0.0898%\n",
      "Epoch [72/300], Step [90/225], Training Accuracy: 96.8056%, Training Loss: 0.0896%\n",
      "Epoch [72/300], Step [91/225], Training Accuracy: 96.8063%, Training Loss: 0.0896%\n",
      "Epoch [72/300], Step [92/225], Training Accuracy: 96.8240%, Training Loss: 0.0893%\n",
      "Epoch [72/300], Step [93/225], Training Accuracy: 96.8246%, Training Loss: 0.0894%\n",
      "Epoch [72/300], Step [94/225], Training Accuracy: 96.8584%, Training Loss: 0.0888%\n",
      "Epoch [72/300], Step [95/225], Training Accuracy: 96.8914%, Training Loss: 0.0882%\n",
      "Epoch [72/300], Step [96/225], Training Accuracy: 96.8913%, Training Loss: 0.0880%\n",
      "Epoch [72/300], Step [97/225], Training Accuracy: 96.9233%, Training Loss: 0.0874%\n",
      "Epoch [72/300], Step [98/225], Training Accuracy: 96.8909%, Training Loss: 0.0882%\n",
      "Epoch [72/300], Step [99/225], Training Accuracy: 96.8750%, Training Loss: 0.0885%\n",
      "Epoch [72/300], Step [100/225], Training Accuracy: 96.8750%, Training Loss: 0.0884%\n",
      "Epoch [72/300], Step [101/225], Training Accuracy: 96.8905%, Training Loss: 0.0882%\n",
      "Epoch [72/300], Step [102/225], Training Accuracy: 96.8903%, Training Loss: 0.0887%\n",
      "Epoch [72/300], Step [103/225], Training Accuracy: 96.9205%, Training Loss: 0.0883%\n",
      "Epoch [72/300], Step [104/225], Training Accuracy: 96.9201%, Training Loss: 0.0886%\n",
      "Epoch [72/300], Step [105/225], Training Accuracy: 96.9345%, Training Loss: 0.0882%\n",
      "Epoch [72/300], Step [106/225], Training Accuracy: 96.9340%, Training Loss: 0.0883%\n",
      "Epoch [72/300], Step [107/225], Training Accuracy: 96.9334%, Training Loss: 0.0882%\n",
      "Epoch [72/300], Step [108/225], Training Accuracy: 96.9329%, Training Loss: 0.0880%\n",
      "Epoch [72/300], Step [109/225], Training Accuracy: 96.8893%, Training Loss: 0.0890%\n",
      "Epoch [72/300], Step [110/225], Training Accuracy: 96.9176%, Training Loss: 0.0884%\n",
      "Epoch [72/300], Step [111/225], Training Accuracy: 96.9172%, Training Loss: 0.0887%\n",
      "Epoch [72/300], Step [112/225], Training Accuracy: 96.9169%, Training Loss: 0.0885%\n",
      "Epoch [72/300], Step [113/225], Training Accuracy: 96.9027%, Training Loss: 0.0890%\n",
      "Epoch [72/300], Step [114/225], Training Accuracy: 96.9024%, Training Loss: 0.0888%\n",
      "Epoch [72/300], Step [115/225], Training Accuracy: 96.9022%, Training Loss: 0.0886%\n",
      "Epoch [72/300], Step [116/225], Training Accuracy: 96.9019%, Training Loss: 0.0886%\n",
      "Epoch [72/300], Step [117/225], Training Accuracy: 96.8884%, Training Loss: 0.0889%\n",
      "Epoch [72/300], Step [118/225], Training Accuracy: 96.8882%, Training Loss: 0.0892%\n",
      "Epoch [72/300], Step [119/225], Training Accuracy: 96.9013%, Training Loss: 0.0889%\n",
      "Epoch [72/300], Step [120/225], Training Accuracy: 96.9141%, Training Loss: 0.0886%\n",
      "Epoch [72/300], Step [121/225], Training Accuracy: 96.9137%, Training Loss: 0.0889%\n",
      "Epoch [72/300], Step [122/225], Training Accuracy: 96.9262%, Training Loss: 0.0888%\n",
      "Epoch [72/300], Step [123/225], Training Accuracy: 96.9385%, Training Loss: 0.0884%\n",
      "Epoch [72/300], Step [124/225], Training Accuracy: 96.9632%, Training Loss: 0.0881%\n",
      "Epoch [72/300], Step [125/225], Training Accuracy: 96.9625%, Training Loss: 0.0880%\n",
      "Epoch [72/300], Step [126/225], Training Accuracy: 96.9742%, Training Loss: 0.0878%\n",
      "Epoch [72/300], Step [127/225], Training Accuracy: 96.9611%, Training Loss: 0.0879%\n",
      "Epoch [72/300], Step [128/225], Training Accuracy: 96.9482%, Training Loss: 0.0883%\n",
      "Epoch [72/300], Step [129/225], Training Accuracy: 96.9477%, Training Loss: 0.0882%\n",
      "Epoch [72/300], Step [130/225], Training Accuracy: 96.9111%, Training Loss: 0.0892%\n",
      "Epoch [72/300], Step [131/225], Training Accuracy: 96.9346%, Training Loss: 0.0888%\n",
      "Epoch [72/300], Step [132/225], Training Accuracy: 96.9579%, Training Loss: 0.0884%\n",
      "Epoch [72/300], Step [133/225], Training Accuracy: 96.9690%, Training Loss: 0.0883%\n",
      "Epoch [72/300], Step [134/225], Training Accuracy: 96.9916%, Training Loss: 0.0879%\n",
      "Epoch [72/300], Step [135/225], Training Accuracy: 97.0023%, Training Loss: 0.0880%\n",
      "Epoch [72/300], Step [136/225], Training Accuracy: 96.9784%, Training Loss: 0.0883%\n",
      "Epoch [72/300], Step [137/225], Training Accuracy: 97.0005%, Training Loss: 0.0878%\n",
      "Epoch [72/300], Step [138/225], Training Accuracy: 97.0109%, Training Loss: 0.0876%\n",
      "Epoch [72/300], Step [139/225], Training Accuracy: 96.9987%, Training Loss: 0.0877%\n",
      "Epoch [72/300], Step [140/225], Training Accuracy: 96.9754%, Training Loss: 0.0880%\n",
      "Epoch [72/300], Step [141/225], Training Accuracy: 96.9637%, Training Loss: 0.0882%\n",
      "Epoch [72/300], Step [142/225], Training Accuracy: 96.9850%, Training Loss: 0.0878%\n",
      "Epoch [72/300], Step [143/225], Training Accuracy: 97.0061%, Training Loss: 0.0874%\n",
      "Epoch [72/300], Step [144/225], Training Accuracy: 97.0052%, Training Loss: 0.0875%\n",
      "Epoch [72/300], Step [145/225], Training Accuracy: 97.0151%, Training Loss: 0.0875%\n",
      "Epoch [72/300], Step [146/225], Training Accuracy: 97.0248%, Training Loss: 0.0873%\n",
      "Epoch [72/300], Step [147/225], Training Accuracy: 97.0344%, Training Loss: 0.0872%\n",
      "Epoch [72/300], Step [148/225], Training Accuracy: 97.0228%, Training Loss: 0.0874%\n",
      "Epoch [72/300], Step [149/225], Training Accuracy: 97.0323%, Training Loss: 0.0873%\n",
      "Epoch [72/300], Step [150/225], Training Accuracy: 97.0000%, Training Loss: 0.0875%\n",
      "Epoch [72/300], Step [151/225], Training Accuracy: 96.9992%, Training Loss: 0.0877%\n",
      "Epoch [72/300], Step [152/225], Training Accuracy: 96.9984%, Training Loss: 0.0876%\n",
      "Epoch [72/300], Step [153/225], Training Accuracy: 96.9975%, Training Loss: 0.0876%\n",
      "Epoch [72/300], Step [154/225], Training Accuracy: 96.9968%, Training Loss: 0.0875%\n",
      "Epoch [72/300], Step [155/225], Training Accuracy: 96.9960%, Training Loss: 0.0875%\n",
      "Epoch [72/300], Step [156/225], Training Accuracy: 97.0052%, Training Loss: 0.0876%\n",
      "Epoch [72/300], Step [157/225], Training Accuracy: 97.0044%, Training Loss: 0.0878%\n",
      "Epoch [72/300], Step [158/225], Training Accuracy: 97.0036%, Training Loss: 0.0879%\n",
      "Epoch [72/300], Step [159/225], Training Accuracy: 96.9831%, Training Loss: 0.0881%\n",
      "Epoch [72/300], Step [160/225], Training Accuracy: 96.9727%, Training Loss: 0.0881%\n",
      "Epoch [72/300], Step [161/225], Training Accuracy: 96.9818%, Training Loss: 0.0879%\n",
      "Epoch [72/300], Step [162/225], Training Accuracy: 96.9907%, Training Loss: 0.0878%\n",
      "Epoch [72/300], Step [163/225], Training Accuracy: 97.0092%, Training Loss: 0.0875%\n",
      "Epoch [72/300], Step [164/225], Training Accuracy: 97.0084%, Training Loss: 0.0875%\n",
      "Epoch [72/300], Step [165/225], Training Accuracy: 97.0170%, Training Loss: 0.0873%\n",
      "Epoch [72/300], Step [166/225], Training Accuracy: 96.9880%, Training Loss: 0.0876%\n",
      "Epoch [72/300], Step [167/225], Training Accuracy: 96.9686%, Training Loss: 0.0881%\n",
      "Epoch [72/300], Step [168/225], Training Accuracy: 96.9866%, Training Loss: 0.0878%\n",
      "Epoch [72/300], Step [169/225], Training Accuracy: 96.9675%, Training Loss: 0.0882%\n",
      "Epoch [72/300], Step [170/225], Training Accuracy: 96.9761%, Training Loss: 0.0880%\n",
      "Epoch [72/300], Step [171/225], Training Accuracy: 96.9846%, Training Loss: 0.0879%\n",
      "Epoch [72/300], Step [172/225], Training Accuracy: 96.9658%, Training Loss: 0.0879%\n",
      "Epoch [72/300], Step [173/225], Training Accuracy: 96.9563%, Training Loss: 0.0881%\n",
      "Epoch [72/300], Step [174/225], Training Accuracy: 96.9558%, Training Loss: 0.0881%\n",
      "Epoch [72/300], Step [175/225], Training Accuracy: 96.9554%, Training Loss: 0.0881%\n",
      "Epoch [72/300], Step [176/225], Training Accuracy: 96.9549%, Training Loss: 0.0880%\n",
      "Epoch [72/300], Step [177/225], Training Accuracy: 96.9544%, Training Loss: 0.0879%\n",
      "Epoch [72/300], Step [178/225], Training Accuracy: 96.9628%, Training Loss: 0.0877%\n",
      "Epoch [72/300], Step [179/225], Training Accuracy: 96.9623%, Training Loss: 0.0877%\n",
      "Epoch [72/300], Step [180/225], Training Accuracy: 96.9792%, Training Loss: 0.0875%\n",
      "Epoch [72/300], Step [181/225], Training Accuracy: 96.9700%, Training Loss: 0.0876%\n",
      "Epoch [72/300], Step [182/225], Training Accuracy: 96.9523%, Training Loss: 0.0882%\n",
      "Epoch [72/300], Step [183/225], Training Accuracy: 96.9689%, Training Loss: 0.0879%\n",
      "Epoch [72/300], Step [184/225], Training Accuracy: 96.9684%, Training Loss: 0.0879%\n",
      "Epoch [72/300], Step [185/225], Training Accuracy: 96.9848%, Training Loss: 0.0877%\n",
      "Epoch [72/300], Step [186/225], Training Accuracy: 96.9926%, Training Loss: 0.0875%\n",
      "Epoch [72/300], Step [187/225], Training Accuracy: 96.9836%, Training Loss: 0.0874%\n",
      "Epoch [72/300], Step [188/225], Training Accuracy: 96.9914%, Training Loss: 0.0872%\n",
      "Epoch [72/300], Step [189/225], Training Accuracy: 96.9990%, Training Loss: 0.0872%\n",
      "Epoch [72/300], Step [190/225], Training Accuracy: 96.9984%, Training Loss: 0.0874%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/300], Step [191/225], Training Accuracy: 97.0059%, Training Loss: 0.0873%\n",
      "Epoch [72/300], Step [192/225], Training Accuracy: 96.9971%, Training Loss: 0.0873%\n",
      "Epoch [72/300], Step [193/225], Training Accuracy: 97.0045%, Training Loss: 0.0874%\n",
      "Epoch [72/300], Step [194/225], Training Accuracy: 97.0119%, Training Loss: 0.0873%\n",
      "Epoch [72/300], Step [195/225], Training Accuracy: 97.0112%, Training Loss: 0.0872%\n",
      "Epoch [72/300], Step [196/225], Training Accuracy: 97.0265%, Training Loss: 0.0870%\n",
      "Epoch [72/300], Step [197/225], Training Accuracy: 97.0098%, Training Loss: 0.0874%\n",
      "Epoch [72/300], Step [198/225], Training Accuracy: 97.0092%, Training Loss: 0.0873%\n",
      "Epoch [72/300], Step [199/225], Training Accuracy: 97.0085%, Training Loss: 0.0874%\n",
      "Epoch [72/300], Step [200/225], Training Accuracy: 97.0156%, Training Loss: 0.0872%\n",
      "Epoch [72/300], Step [201/225], Training Accuracy: 97.0227%, Training Loss: 0.0872%\n",
      "Epoch [72/300], Step [202/225], Training Accuracy: 97.0142%, Training Loss: 0.0875%\n",
      "Epoch [72/300], Step [203/225], Training Accuracy: 97.0212%, Training Loss: 0.0876%\n",
      "Epoch [72/300], Step [204/225], Training Accuracy: 97.0205%, Training Loss: 0.0876%\n",
      "Epoch [72/300], Step [205/225], Training Accuracy: 97.0198%, Training Loss: 0.0875%\n",
      "Epoch [72/300], Step [206/225], Training Accuracy: 97.0115%, Training Loss: 0.0876%\n",
      "Epoch [72/300], Step [207/225], Training Accuracy: 97.0260%, Training Loss: 0.0873%\n",
      "Epoch [72/300], Step [208/225], Training Accuracy: 97.0252%, Training Loss: 0.0873%\n",
      "Epoch [72/300], Step [209/225], Training Accuracy: 97.0320%, Training Loss: 0.0872%\n",
      "Epoch [72/300], Step [210/225], Training Accuracy: 97.0238%, Training Loss: 0.0873%\n",
      "Epoch [72/300], Step [211/225], Training Accuracy: 97.0157%, Training Loss: 0.0876%\n",
      "Epoch [72/300], Step [212/225], Training Accuracy: 97.0150%, Training Loss: 0.0876%\n",
      "Epoch [72/300], Step [213/225], Training Accuracy: 97.0070%, Training Loss: 0.0876%\n",
      "Epoch [72/300], Step [214/225], Training Accuracy: 97.0137%, Training Loss: 0.0875%\n",
      "Epoch [72/300], Step [215/225], Training Accuracy: 97.0131%, Training Loss: 0.0876%\n",
      "Epoch [72/300], Step [216/225], Training Accuracy: 97.0124%, Training Loss: 0.0876%\n",
      "Epoch [72/300], Step [217/225], Training Accuracy: 97.0190%, Training Loss: 0.0875%\n",
      "Epoch [72/300], Step [218/225], Training Accuracy: 97.0183%, Training Loss: 0.0876%\n",
      "Epoch [72/300], Step [219/225], Training Accuracy: 97.0320%, Training Loss: 0.0874%\n",
      "Epoch [72/300], Step [220/225], Training Accuracy: 97.0384%, Training Loss: 0.0873%\n",
      "Epoch [72/300], Step [221/225], Training Accuracy: 97.0305%, Training Loss: 0.0874%\n",
      "Epoch [72/300], Step [222/225], Training Accuracy: 97.0298%, Training Loss: 0.0874%\n",
      "Epoch [72/300], Step [223/225], Training Accuracy: 97.0151%, Training Loss: 0.0876%\n",
      "Epoch [72/300], Step [224/225], Training Accuracy: 97.0285%, Training Loss: 0.0873%\n",
      "Epoch [72/300], Step [225/225], Training Accuracy: 97.0331%, Training Loss: 0.0872%\n",
      "Epoch [73/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0295%\n",
      "Epoch [73/300], Step [2/225], Training Accuracy: 98.4375%, Training Loss: 0.0538%\n",
      "Epoch [73/300], Step [3/225], Training Accuracy: 97.3958%, Training Loss: 0.1117%\n",
      "Epoch [73/300], Step [4/225], Training Accuracy: 97.6562%, Training Loss: 0.0952%\n",
      "Epoch [73/300], Step [5/225], Training Accuracy: 97.5000%, Training Loss: 0.0907%\n",
      "Epoch [73/300], Step [6/225], Training Accuracy: 97.6562%, Training Loss: 0.0840%\n",
      "Epoch [73/300], Step [7/225], Training Accuracy: 97.5446%, Training Loss: 0.0861%\n",
      "Epoch [73/300], Step [8/225], Training Accuracy: 97.8516%, Training Loss: 0.0797%\n",
      "Epoch [73/300], Step [9/225], Training Accuracy: 97.7431%, Training Loss: 0.0799%\n",
      "Epoch [73/300], Step [10/225], Training Accuracy: 97.8125%, Training Loss: 0.0770%\n",
      "Epoch [73/300], Step [11/225], Training Accuracy: 97.7273%, Training Loss: 0.0803%\n",
      "Epoch [73/300], Step [12/225], Training Accuracy: 97.9167%, Training Loss: 0.0760%\n",
      "Epoch [73/300], Step [13/225], Training Accuracy: 98.0769%, Training Loss: 0.0733%\n",
      "Epoch [73/300], Step [14/225], Training Accuracy: 97.9911%, Training Loss: 0.0736%\n",
      "Epoch [73/300], Step [15/225], Training Accuracy: 98.1250%, Training Loss: 0.0709%\n",
      "Epoch [73/300], Step [16/225], Training Accuracy: 98.2422%, Training Loss: 0.0680%\n",
      "Epoch [73/300], Step [17/225], Training Accuracy: 98.2537%, Training Loss: 0.0672%\n",
      "Epoch [73/300], Step [18/225], Training Accuracy: 98.1771%, Training Loss: 0.0704%\n",
      "Epoch [73/300], Step [19/225], Training Accuracy: 98.1908%, Training Loss: 0.0718%\n",
      "Epoch [73/300], Step [20/225], Training Accuracy: 98.0469%, Training Loss: 0.0751%\n",
      "Epoch [73/300], Step [21/225], Training Accuracy: 98.0655%, Training Loss: 0.0743%\n",
      "Epoch [73/300], Step [22/225], Training Accuracy: 98.0114%, Training Loss: 0.0741%\n",
      "Epoch [73/300], Step [23/225], Training Accuracy: 98.0299%, Training Loss: 0.0743%\n",
      "Epoch [73/300], Step [24/225], Training Accuracy: 97.8516%, Training Loss: 0.0814%\n",
      "Epoch [73/300], Step [25/225], Training Accuracy: 97.6875%, Training Loss: 0.0824%\n",
      "Epoch [73/300], Step [26/225], Training Accuracy: 97.5962%, Training Loss: 0.0846%\n",
      "Epoch [73/300], Step [27/225], Training Accuracy: 97.5694%, Training Loss: 0.0843%\n",
      "Epoch [73/300], Step [28/225], Training Accuracy: 97.5446%, Training Loss: 0.0832%\n",
      "Epoch [73/300], Step [29/225], Training Accuracy: 97.3060%, Training Loss: 0.0865%\n",
      "Epoch [73/300], Step [30/225], Training Accuracy: 97.2396%, Training Loss: 0.0870%\n",
      "Epoch [73/300], Step [31/225], Training Accuracy: 97.1270%, Training Loss: 0.0879%\n",
      "Epoch [73/300], Step [32/225], Training Accuracy: 97.1680%, Training Loss: 0.0865%\n",
      "Epoch [73/300], Step [33/225], Training Accuracy: 97.2538%, Training Loss: 0.0853%\n",
      "Epoch [73/300], Step [34/225], Training Accuracy: 97.1507%, Training Loss: 0.0881%\n",
      "Epoch [73/300], Step [35/225], Training Accuracy: 97.0982%, Training Loss: 0.0892%\n",
      "Epoch [73/300], Step [36/225], Training Accuracy: 97.1354%, Training Loss: 0.0886%\n",
      "Epoch [73/300], Step [37/225], Training Accuracy: 97.0861%, Training Loss: 0.0911%\n",
      "Epoch [73/300], Step [38/225], Training Accuracy: 96.9984%, Training Loss: 0.0934%\n",
      "Epoch [73/300], Step [39/225], Training Accuracy: 96.9952%, Training Loss: 0.0933%\n",
      "Epoch [73/300], Step [40/225], Training Accuracy: 96.9141%, Training Loss: 0.0936%\n",
      "Epoch [73/300], Step [41/225], Training Accuracy: 96.7607%, Training Loss: 0.0963%\n",
      "Epoch [73/300], Step [42/225], Training Accuracy: 96.7634%, Training Loss: 0.0960%\n",
      "Epoch [73/300], Step [43/225], Training Accuracy: 96.8387%, Training Loss: 0.0945%\n",
      "Epoch [73/300], Step [44/225], Training Accuracy: 96.8750%, Training Loss: 0.0935%\n",
      "Epoch [73/300], Step [45/225], Training Accuracy: 96.9097%, Training Loss: 0.0928%\n",
      "Epoch [73/300], Step [46/225], Training Accuracy: 96.9429%, Training Loss: 0.0915%\n",
      "Epoch [73/300], Step [47/225], Training Accuracy: 96.9747%, Training Loss: 0.0905%\n",
      "Epoch [73/300], Step [48/225], Training Accuracy: 96.9727%, Training Loss: 0.0901%\n",
      "Epoch [73/300], Step [49/225], Training Accuracy: 96.9707%, Training Loss: 0.0897%\n",
      "Epoch [73/300], Step [50/225], Training Accuracy: 96.9688%, Training Loss: 0.0904%\n",
      "Epoch [73/300], Step [51/225], Training Accuracy: 96.9363%, Training Loss: 0.0904%\n",
      "Epoch [73/300], Step [52/225], Training Accuracy: 96.9651%, Training Loss: 0.0898%\n",
      "Epoch [73/300], Step [53/225], Training Accuracy: 96.9929%, Training Loss: 0.0893%\n",
      "Epoch [73/300], Step [54/225], Training Accuracy: 96.9039%, Training Loss: 0.0899%\n",
      "Epoch [73/300], Step [55/225], Training Accuracy: 96.9602%, Training Loss: 0.0891%\n",
      "Epoch [73/300], Step [56/225], Training Accuracy: 96.9308%, Training Loss: 0.0896%\n",
      "Epoch [73/300], Step [57/225], Training Accuracy: 96.9298%, Training Loss: 0.0897%\n",
      "Epoch [73/300], Step [58/225], Training Accuracy: 96.9828%, Training Loss: 0.0886%\n",
      "Epoch [73/300], Step [59/225], Training Accuracy: 97.0074%, Training Loss: 0.0885%\n",
      "Epoch [73/300], Step [60/225], Training Accuracy: 96.9792%, Training Loss: 0.0889%\n",
      "Epoch [73/300], Step [61/225], Training Accuracy: 96.9262%, Training Loss: 0.0894%\n",
      "Epoch [73/300], Step [62/225], Training Accuracy: 96.9254%, Training Loss: 0.0892%\n",
      "Epoch [73/300], Step [63/225], Training Accuracy: 96.9246%, Training Loss: 0.0893%\n",
      "Epoch [73/300], Step [64/225], Training Accuracy: 96.9238%, Training Loss: 0.0894%\n",
      "Epoch [73/300], Step [65/225], Training Accuracy: 96.9231%, Training Loss: 0.0893%\n",
      "Epoch [73/300], Step [66/225], Training Accuracy: 96.8750%, Training Loss: 0.0898%\n",
      "Epoch [73/300], Step [67/225], Training Accuracy: 96.8050%, Training Loss: 0.0913%\n",
      "Epoch [73/300], Step [68/225], Training Accuracy: 96.7831%, Training Loss: 0.0913%\n",
      "Epoch [73/300], Step [69/225], Training Accuracy: 96.7618%, Training Loss: 0.0915%\n",
      "Epoch [73/300], Step [70/225], Training Accuracy: 96.7857%, Training Loss: 0.0911%\n",
      "Epoch [73/300], Step [71/225], Training Accuracy: 96.6989%, Training Loss: 0.0928%\n",
      "Epoch [73/300], Step [72/225], Training Accuracy: 96.7014%, Training Loss: 0.0926%\n",
      "Epoch [73/300], Step [73/225], Training Accuracy: 96.6824%, Training Loss: 0.0932%\n",
      "Epoch [73/300], Step [74/225], Training Accuracy: 96.6639%, Training Loss: 0.0938%\n",
      "Epoch [73/300], Step [75/225], Training Accuracy: 96.7083%, Training Loss: 0.0928%\n",
      "Epoch [73/300], Step [76/225], Training Accuracy: 96.7105%, Training Loss: 0.0926%\n",
      "Epoch [73/300], Step [77/225], Training Accuracy: 96.6924%, Training Loss: 0.0927%\n",
      "Epoch [73/300], Step [78/225], Training Accuracy: 96.6146%, Training Loss: 0.0941%\n",
      "Epoch [73/300], Step [79/225], Training Accuracy: 96.5981%, Training Loss: 0.0942%\n",
      "Epoch [73/300], Step [80/225], Training Accuracy: 96.6211%, Training Loss: 0.0938%\n",
      "Epoch [73/300], Step [81/225], Training Accuracy: 96.6242%, Training Loss: 0.0939%\n",
      "Epoch [73/300], Step [82/225], Training Accuracy: 96.5892%, Training Loss: 0.0944%\n",
      "Epoch [73/300], Step [83/225], Training Accuracy: 96.5550%, Training Loss: 0.0947%\n",
      "Epoch [73/300], Step [84/225], Training Accuracy: 96.5588%, Training Loss: 0.0944%\n",
      "Epoch [73/300], Step [85/225], Training Accuracy: 96.5809%, Training Loss: 0.0942%\n",
      "Epoch [73/300], Step [86/225], Training Accuracy: 96.5661%, Training Loss: 0.0944%\n",
      "Epoch [73/300], Step [87/225], Training Accuracy: 96.5517%, Training Loss: 0.0944%\n",
      "Epoch [73/300], Step [88/225], Training Accuracy: 96.5199%, Training Loss: 0.0952%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/300], Step [89/225], Training Accuracy: 96.5063%, Training Loss: 0.0954%\n",
      "Epoch [73/300], Step [90/225], Training Accuracy: 96.4583%, Training Loss: 0.0960%\n",
      "Epoch [73/300], Step [91/225], Training Accuracy: 96.4114%, Training Loss: 0.0977%\n",
      "Epoch [73/300], Step [92/225], Training Accuracy: 96.4164%, Training Loss: 0.0975%\n",
      "Epoch [73/300], Step [93/225], Training Accuracy: 96.3878%, Training Loss: 0.0981%\n",
      "Epoch [73/300], Step [94/225], Training Accuracy: 96.3930%, Training Loss: 0.0983%\n",
      "Epoch [73/300], Step [95/225], Training Accuracy: 96.4145%, Training Loss: 0.0980%\n",
      "Epoch [73/300], Step [96/225], Training Accuracy: 96.4355%, Training Loss: 0.0979%\n",
      "Epoch [73/300], Step [97/225], Training Accuracy: 96.4240%, Training Loss: 0.0982%\n",
      "Epoch [73/300], Step [98/225], Training Accuracy: 96.4445%, Training Loss: 0.0981%\n",
      "Epoch [73/300], Step [99/225], Training Accuracy: 96.4804%, Training Loss: 0.0975%\n",
      "Epoch [73/300], Step [100/225], Training Accuracy: 96.4531%, Training Loss: 0.0983%\n",
      "Epoch [73/300], Step [101/225], Training Accuracy: 96.4264%, Training Loss: 0.0984%\n",
      "Epoch [73/300], Step [102/225], Training Accuracy: 96.4308%, Training Loss: 0.0988%\n",
      "Epoch [73/300], Step [103/225], Training Accuracy: 96.4351%, Training Loss: 0.0992%\n",
      "Epoch [73/300], Step [104/225], Training Accuracy: 96.4393%, Training Loss: 0.0991%\n",
      "Epoch [73/300], Step [105/225], Training Accuracy: 96.4286%, Training Loss: 0.1002%\n",
      "Epoch [73/300], Step [106/225], Training Accuracy: 96.4180%, Training Loss: 0.1006%\n",
      "Epoch [73/300], Step [107/225], Training Accuracy: 96.4223%, Training Loss: 0.1004%\n",
      "Epoch [73/300], Step [108/225], Training Accuracy: 96.4265%, Training Loss: 0.1002%\n",
      "Epoch [73/300], Step [109/225], Training Accuracy: 96.4306%, Training Loss: 0.1000%\n",
      "Epoch [73/300], Step [110/225], Training Accuracy: 96.4631%, Training Loss: 0.0994%\n",
      "Epoch [73/300], Step [111/225], Training Accuracy: 96.4527%, Training Loss: 0.0996%\n",
      "Epoch [73/300], Step [112/225], Training Accuracy: 96.4704%, Training Loss: 0.0990%\n",
      "Epoch [73/300], Step [113/225], Training Accuracy: 96.4878%, Training Loss: 0.0985%\n",
      "Epoch [73/300], Step [114/225], Training Accuracy: 96.4912%, Training Loss: 0.0983%\n",
      "Epoch [73/300], Step [115/225], Training Accuracy: 96.4946%, Training Loss: 0.0984%\n",
      "Epoch [73/300], Step [116/225], Training Accuracy: 96.4709%, Training Loss: 0.0994%\n",
      "Epoch [73/300], Step [117/225], Training Accuracy: 96.4744%, Training Loss: 0.0993%\n",
      "Epoch [73/300], Step [118/225], Training Accuracy: 96.4778%, Training Loss: 0.0995%\n",
      "Epoch [73/300], Step [119/225], Training Accuracy: 96.4942%, Training Loss: 0.0994%\n",
      "Epoch [73/300], Step [120/225], Training Accuracy: 96.5104%, Training Loss: 0.0990%\n",
      "Epoch [73/300], Step [121/225], Training Accuracy: 96.5263%, Training Loss: 0.0986%\n",
      "Epoch [73/300], Step [122/225], Training Accuracy: 96.5420%, Training Loss: 0.0986%\n",
      "Epoch [73/300], Step [123/225], Training Accuracy: 96.5574%, Training Loss: 0.0984%\n",
      "Epoch [73/300], Step [124/225], Training Accuracy: 96.5474%, Training Loss: 0.0985%\n",
      "Epoch [73/300], Step [125/225], Training Accuracy: 96.5500%, Training Loss: 0.0983%\n",
      "Epoch [73/300], Step [126/225], Training Accuracy: 96.5526%, Training Loss: 0.0983%\n",
      "Epoch [73/300], Step [127/225], Training Accuracy: 96.5305%, Training Loss: 0.0983%\n",
      "Epoch [73/300], Step [128/225], Training Accuracy: 96.5210%, Training Loss: 0.0988%\n",
      "Epoch [73/300], Step [129/225], Training Accuracy: 96.5359%, Training Loss: 0.0985%\n",
      "Epoch [73/300], Step [130/225], Training Accuracy: 96.5264%, Training Loss: 0.0988%\n",
      "Epoch [73/300], Step [131/225], Training Accuracy: 96.5172%, Training Loss: 0.0993%\n",
      "Epoch [73/300], Step [132/225], Training Accuracy: 96.5080%, Training Loss: 0.0995%\n",
      "Epoch [73/300], Step [133/225], Training Accuracy: 96.5226%, Training Loss: 0.0992%\n",
      "Epoch [73/300], Step [134/225], Training Accuracy: 96.5485%, Training Loss: 0.0989%\n",
      "Epoch [73/300], Step [135/225], Training Accuracy: 96.5625%, Training Loss: 0.0986%\n",
      "Epoch [73/300], Step [136/225], Training Accuracy: 96.5763%, Training Loss: 0.0986%\n",
      "Epoch [73/300], Step [137/225], Training Accuracy: 96.5899%, Training Loss: 0.0984%\n",
      "Epoch [73/300], Step [138/225], Training Accuracy: 96.5693%, Training Loss: 0.0989%\n",
      "Epoch [73/300], Step [139/225], Training Accuracy: 96.5827%, Training Loss: 0.0988%\n",
      "Epoch [73/300], Step [140/225], Training Accuracy: 96.5960%, Training Loss: 0.0985%\n",
      "Epoch [73/300], Step [141/225], Training Accuracy: 96.5980%, Training Loss: 0.0983%\n",
      "Epoch [73/300], Step [142/225], Training Accuracy: 96.5999%, Training Loss: 0.0980%\n",
      "Epoch [73/300], Step [143/225], Training Accuracy: 96.6128%, Training Loss: 0.0979%\n",
      "Epoch [73/300], Step [144/225], Training Accuracy: 96.6363%, Training Loss: 0.0975%\n",
      "Epoch [73/300], Step [145/225], Training Accuracy: 96.6379%, Training Loss: 0.0972%\n",
      "Epoch [73/300], Step [146/225], Training Accuracy: 96.6396%, Training Loss: 0.0971%\n",
      "Epoch [73/300], Step [147/225], Training Accuracy: 96.6624%, Training Loss: 0.0967%\n",
      "Epoch [73/300], Step [148/225], Training Accuracy: 96.6744%, Training Loss: 0.0964%\n",
      "Epoch [73/300], Step [149/225], Training Accuracy: 96.6443%, Training Loss: 0.0968%\n",
      "Epoch [73/300], Step [150/225], Training Accuracy: 96.6458%, Training Loss: 0.0965%\n",
      "Epoch [73/300], Step [151/225], Training Accuracy: 96.6267%, Training Loss: 0.0966%\n",
      "Epoch [73/300], Step [152/225], Training Accuracy: 96.6077%, Training Loss: 0.0968%\n",
      "Epoch [73/300], Step [153/225], Training Accuracy: 96.5993%, Training Loss: 0.0968%\n",
      "Epoch [73/300], Step [154/225], Training Accuracy: 96.6213%, Training Loss: 0.0965%\n",
      "Epoch [73/300], Step [155/225], Training Accuracy: 96.6129%, Training Loss: 0.0966%\n",
      "Epoch [73/300], Step [156/225], Training Accuracy: 96.6146%, Training Loss: 0.0966%\n",
      "Epoch [73/300], Step [157/225], Training Accuracy: 96.5963%, Training Loss: 0.0968%\n",
      "Epoch [73/300], Step [158/225], Training Accuracy: 96.5882%, Training Loss: 0.0970%\n",
      "Epoch [73/300], Step [159/225], Training Accuracy: 96.5802%, Training Loss: 0.0972%\n",
      "Epoch [73/300], Step [160/225], Training Accuracy: 96.5820%, Training Loss: 0.0970%\n",
      "Epoch [73/300], Step [161/225], Training Accuracy: 96.5741%, Training Loss: 0.0970%\n",
      "Epoch [73/300], Step [162/225], Training Accuracy: 96.5760%, Training Loss: 0.0972%\n",
      "Epoch [73/300], Step [163/225], Training Accuracy: 96.5491%, Training Loss: 0.0978%\n",
      "Epoch [73/300], Step [164/225], Training Accuracy: 96.5415%, Training Loss: 0.0977%\n",
      "Epoch [73/300], Step [165/225], Training Accuracy: 96.5246%, Training Loss: 0.0979%\n",
      "Epoch [73/300], Step [166/225], Training Accuracy: 96.5173%, Training Loss: 0.0980%\n",
      "Epoch [73/300], Step [167/225], Training Accuracy: 96.5288%, Training Loss: 0.0977%\n",
      "Epoch [73/300], Step [168/225], Training Accuracy: 96.5309%, Training Loss: 0.0978%\n",
      "Epoch [73/300], Step [169/225], Training Accuracy: 96.5237%, Training Loss: 0.0980%\n",
      "Epoch [73/300], Step [170/225], Training Accuracy: 96.5165%, Training Loss: 0.0982%\n",
      "Epoch [73/300], Step [171/225], Training Accuracy: 96.5004%, Training Loss: 0.0984%\n",
      "Epoch [73/300], Step [172/225], Training Accuracy: 96.5025%, Training Loss: 0.0982%\n",
      "Epoch [73/300], Step [173/225], Training Accuracy: 96.4866%, Training Loss: 0.0982%\n",
      "Epoch [73/300], Step [174/225], Training Accuracy: 96.4978%, Training Loss: 0.0980%\n",
      "Epoch [73/300], Step [175/225], Training Accuracy: 96.4821%, Training Loss: 0.0985%\n",
      "Epoch [73/300], Step [176/225], Training Accuracy: 96.4933%, Training Loss: 0.0983%\n",
      "Epoch [73/300], Step [177/225], Training Accuracy: 96.5042%, Training Loss: 0.0981%\n",
      "Epoch [73/300], Step [178/225], Training Accuracy: 96.5151%, Training Loss: 0.0980%\n",
      "Epoch [73/300], Step [179/225], Training Accuracy: 96.5258%, Training Loss: 0.0978%\n",
      "Epoch [73/300], Step [180/225], Training Accuracy: 96.5191%, Training Loss: 0.0978%\n",
      "Epoch [73/300], Step [181/225], Training Accuracy: 96.5383%, Training Loss: 0.0976%\n",
      "Epoch [73/300], Step [182/225], Training Accuracy: 96.5488%, Training Loss: 0.0974%\n",
      "Epoch [73/300], Step [183/225], Training Accuracy: 96.5676%, Training Loss: 0.0971%\n",
      "Epoch [73/300], Step [184/225], Training Accuracy: 96.5523%, Training Loss: 0.0971%\n",
      "Epoch [73/300], Step [185/225], Training Accuracy: 96.5456%, Training Loss: 0.0971%\n",
      "Epoch [73/300], Step [186/225], Training Accuracy: 96.5642%, Training Loss: 0.0968%\n",
      "Epoch [73/300], Step [187/225], Training Accuracy: 96.5826%, Training Loss: 0.0966%\n",
      "Epoch [73/300], Step [188/225], Training Accuracy: 96.5924%, Training Loss: 0.0963%\n",
      "Epoch [73/300], Step [189/225], Training Accuracy: 96.6022%, Training Loss: 0.0960%\n",
      "Epoch [73/300], Step [190/225], Training Accuracy: 96.5954%, Training Loss: 0.0964%\n",
      "Epoch [73/300], Step [191/225], Training Accuracy: 96.6132%, Training Loss: 0.0961%\n",
      "Epoch [73/300], Step [192/225], Training Accuracy: 96.6146%, Training Loss: 0.0960%\n",
      "Epoch [73/300], Step [193/225], Training Accuracy: 96.5916%, Training Loss: 0.0962%\n",
      "Epoch [73/300], Step [194/225], Training Accuracy: 96.6012%, Training Loss: 0.0962%\n",
      "Epoch [73/300], Step [195/225], Training Accuracy: 96.6026%, Training Loss: 0.0961%\n",
      "Epoch [73/300], Step [196/225], Training Accuracy: 96.6199%, Training Loss: 0.0958%\n",
      "Epoch [73/300], Step [197/225], Training Accuracy: 96.6212%, Training Loss: 0.0958%\n",
      "Epoch [73/300], Step [198/225], Training Accuracy: 96.6225%, Training Loss: 0.0957%\n",
      "Epoch [73/300], Step [199/225], Training Accuracy: 96.6237%, Training Loss: 0.0957%\n",
      "Epoch [73/300], Step [200/225], Training Accuracy: 96.6172%, Training Loss: 0.0959%\n",
      "Epoch [73/300], Step [201/225], Training Accuracy: 96.6185%, Training Loss: 0.0957%\n",
      "Epoch [73/300], Step [202/225], Training Accuracy: 96.6120%, Training Loss: 0.0958%\n",
      "Epoch [73/300], Step [203/225], Training Accuracy: 96.6133%, Training Loss: 0.0958%\n",
      "Epoch [73/300], Step [204/225], Training Accuracy: 96.5993%, Training Loss: 0.0958%\n",
      "Epoch [73/300], Step [205/225], Training Accuracy: 96.6082%, Training Loss: 0.0957%\n",
      "Epoch [73/300], Step [206/225], Training Accuracy: 96.6095%, Training Loss: 0.0956%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/300], Step [207/225], Training Accuracy: 96.6184%, Training Loss: 0.0955%\n",
      "Epoch [73/300], Step [208/225], Training Accuracy: 96.6046%, Training Loss: 0.0959%\n",
      "Epoch [73/300], Step [209/225], Training Accuracy: 96.6133%, Training Loss: 0.0957%\n",
      "Epoch [73/300], Step [210/225], Training Accuracy: 96.6146%, Training Loss: 0.0957%\n",
      "Epoch [73/300], Step [211/225], Training Accuracy: 96.6010%, Training Loss: 0.0958%\n",
      "Epoch [73/300], Step [212/225], Training Accuracy: 96.6023%, Training Loss: 0.0959%\n",
      "Epoch [73/300], Step [213/225], Training Accuracy: 96.6109%, Training Loss: 0.0958%\n",
      "Epoch [73/300], Step [214/225], Training Accuracy: 96.6121%, Training Loss: 0.0957%\n",
      "Epoch [73/300], Step [215/225], Training Accuracy: 96.6206%, Training Loss: 0.0957%\n",
      "Epoch [73/300], Step [216/225], Training Accuracy: 96.6218%, Training Loss: 0.0959%\n",
      "Epoch [73/300], Step [217/225], Training Accuracy: 96.6374%, Training Loss: 0.0956%\n",
      "Epoch [73/300], Step [218/225], Training Accuracy: 96.6528%, Training Loss: 0.0953%\n",
      "Epoch [73/300], Step [219/225], Training Accuracy: 96.6681%, Training Loss: 0.0951%\n",
      "Epoch [73/300], Step [220/225], Training Accuracy: 96.6832%, Training Loss: 0.0948%\n",
      "Epoch [73/300], Step [221/225], Training Accuracy: 96.6912%, Training Loss: 0.0947%\n",
      "Epoch [73/300], Step [222/225], Training Accuracy: 96.6639%, Training Loss: 0.0951%\n",
      "Epoch [73/300], Step [223/225], Training Accuracy: 96.6718%, Training Loss: 0.0949%\n",
      "Epoch [73/300], Step [224/225], Training Accuracy: 96.6727%, Training Loss: 0.0949%\n",
      "Epoch [73/300], Step [225/225], Training Accuracy: 96.6718%, Training Loss: 0.0950%\n",
      "Epoch [74/300], Step [1/225], Training Accuracy: 95.3125%, Training Loss: 0.0930%\n",
      "Epoch [74/300], Step [2/225], Training Accuracy: 96.0938%, Training Loss: 0.0970%\n",
      "Epoch [74/300], Step [3/225], Training Accuracy: 94.2708%, Training Loss: 0.1237%\n",
      "Epoch [74/300], Step [4/225], Training Accuracy: 94.5312%, Training Loss: 0.1240%\n",
      "Epoch [74/300], Step [5/225], Training Accuracy: 95.3125%, Training Loss: 0.1073%\n",
      "Epoch [74/300], Step [6/225], Training Accuracy: 95.3125%, Training Loss: 0.1030%\n",
      "Epoch [74/300], Step [7/225], Training Accuracy: 95.3125%, Training Loss: 0.1010%\n",
      "Epoch [74/300], Step [8/225], Training Accuracy: 95.5078%, Training Loss: 0.0984%\n",
      "Epoch [74/300], Step [9/225], Training Accuracy: 95.1389%, Training Loss: 0.1028%\n",
      "Epoch [74/300], Step [10/225], Training Accuracy: 95.4688%, Training Loss: 0.1001%\n",
      "Epoch [74/300], Step [11/225], Training Accuracy: 95.7386%, Training Loss: 0.0988%\n",
      "Epoch [74/300], Step [12/225], Training Accuracy: 95.9635%, Training Loss: 0.0939%\n",
      "Epoch [74/300], Step [13/225], Training Accuracy: 96.0337%, Training Loss: 0.0985%\n",
      "Epoch [74/300], Step [14/225], Training Accuracy: 96.3170%, Training Loss: 0.0952%\n",
      "Epoch [74/300], Step [15/225], Training Accuracy: 96.3542%, Training Loss: 0.0947%\n",
      "Epoch [74/300], Step [16/225], Training Accuracy: 96.4844%, Training Loss: 0.0918%\n",
      "Epoch [74/300], Step [17/225], Training Accuracy: 96.6912%, Training Loss: 0.0893%\n",
      "Epoch [74/300], Step [18/225], Training Accuracy: 96.7014%, Training Loss: 0.0888%\n",
      "Epoch [74/300], Step [19/225], Training Accuracy: 96.8750%, Training Loss: 0.0851%\n",
      "Epoch [74/300], Step [20/225], Training Accuracy: 96.8750%, Training Loss: 0.0844%\n",
      "Epoch [74/300], Step [21/225], Training Accuracy: 96.8750%, Training Loss: 0.0870%\n",
      "Epoch [74/300], Step [22/225], Training Accuracy: 96.8750%, Training Loss: 0.0873%\n",
      "Epoch [74/300], Step [23/225], Training Accuracy: 96.9429%, Training Loss: 0.0875%\n",
      "Epoch [74/300], Step [24/225], Training Accuracy: 97.0703%, Training Loss: 0.0859%\n",
      "Epoch [74/300], Step [25/225], Training Accuracy: 97.0625%, Training Loss: 0.0858%\n",
      "Epoch [74/300], Step [26/225], Training Accuracy: 97.0553%, Training Loss: 0.0850%\n",
      "Epoch [74/300], Step [27/225], Training Accuracy: 96.8750%, Training Loss: 0.0896%\n",
      "Epoch [74/300], Step [28/225], Training Accuracy: 96.8750%, Training Loss: 0.0902%\n",
      "Epoch [74/300], Step [29/225], Training Accuracy: 96.9828%, Training Loss: 0.0891%\n",
      "Epoch [74/300], Step [30/225], Training Accuracy: 97.0312%, Training Loss: 0.0878%\n",
      "Epoch [74/300], Step [31/225], Training Accuracy: 97.0262%, Training Loss: 0.0887%\n",
      "Epoch [74/300], Step [32/225], Training Accuracy: 97.0215%, Training Loss: 0.0885%\n",
      "Epoch [74/300], Step [33/225], Training Accuracy: 97.0644%, Training Loss: 0.0881%\n",
      "Epoch [74/300], Step [34/225], Training Accuracy: 97.0129%, Training Loss: 0.0882%\n",
      "Epoch [74/300], Step [35/225], Training Accuracy: 97.0982%, Training Loss: 0.0878%\n",
      "Epoch [74/300], Step [36/225], Training Accuracy: 97.0920%, Training Loss: 0.0870%\n",
      "Epoch [74/300], Step [37/225], Training Accuracy: 97.1284%, Training Loss: 0.0866%\n",
      "Epoch [74/300], Step [38/225], Training Accuracy: 97.1628%, Training Loss: 0.0873%\n",
      "Epoch [74/300], Step [39/225], Training Accuracy: 97.0353%, Training Loss: 0.0921%\n",
      "Epoch [74/300], Step [40/225], Training Accuracy: 97.0312%, Training Loss: 0.0921%\n",
      "Epoch [74/300], Step [41/225], Training Accuracy: 96.9893%, Training Loss: 0.0931%\n",
      "Epoch [74/300], Step [42/225], Training Accuracy: 97.0238%, Training Loss: 0.0922%\n",
      "Epoch [74/300], Step [43/225], Training Accuracy: 97.0567%, Training Loss: 0.0915%\n",
      "Epoch [74/300], Step [44/225], Training Accuracy: 97.0526%, Training Loss: 0.0914%\n",
      "Epoch [74/300], Step [45/225], Training Accuracy: 97.0486%, Training Loss: 0.0910%\n",
      "Epoch [74/300], Step [46/225], Training Accuracy: 97.0109%, Training Loss: 0.0907%\n",
      "Epoch [74/300], Step [47/225], Training Accuracy: 97.0745%, Training Loss: 0.0896%\n",
      "Epoch [74/300], Step [48/225], Training Accuracy: 97.1354%, Training Loss: 0.0888%\n",
      "Epoch [74/300], Step [49/225], Training Accuracy: 97.0663%, Training Loss: 0.0895%\n",
      "Epoch [74/300], Step [50/225], Training Accuracy: 97.0625%, Training Loss: 0.0903%\n",
      "Epoch [74/300], Step [51/225], Training Accuracy: 97.0282%, Training Loss: 0.0909%\n",
      "Epoch [74/300], Step [52/225], Training Accuracy: 97.0853%, Training Loss: 0.0896%\n",
      "Epoch [74/300], Step [53/225], Training Accuracy: 97.1108%, Training Loss: 0.0886%\n",
      "Epoch [74/300], Step [54/225], Training Accuracy: 97.1354%, Training Loss: 0.0882%\n",
      "Epoch [74/300], Step [55/225], Training Accuracy: 97.1591%, Training Loss: 0.0873%\n",
      "Epoch [74/300], Step [56/225], Training Accuracy: 97.0703%, Training Loss: 0.0895%\n",
      "Epoch [74/300], Step [57/225], Training Accuracy: 97.0121%, Training Loss: 0.0905%\n",
      "Epoch [74/300], Step [58/225], Training Accuracy: 96.9828%, Training Loss: 0.0907%\n",
      "Epoch [74/300], Step [59/225], Training Accuracy: 96.9015%, Training Loss: 0.0930%\n",
      "Epoch [74/300], Step [60/225], Training Accuracy: 96.9271%, Training Loss: 0.0921%\n",
      "Epoch [74/300], Step [61/225], Training Accuracy: 96.8750%, Training Loss: 0.0933%\n",
      "Epoch [74/300], Step [62/225], Training Accuracy: 96.8498%, Training Loss: 0.0934%\n",
      "Epoch [74/300], Step [63/225], Training Accuracy: 96.7510%, Training Loss: 0.0949%\n",
      "Epoch [74/300], Step [64/225], Training Accuracy: 96.7285%, Training Loss: 0.0948%\n",
      "Epoch [74/300], Step [65/225], Training Accuracy: 96.6827%, Training Loss: 0.0958%\n",
      "Epoch [74/300], Step [66/225], Training Accuracy: 96.6856%, Training Loss: 0.0960%\n",
      "Epoch [74/300], Step [67/225], Training Accuracy: 96.7351%, Training Loss: 0.0955%\n",
      "Epoch [74/300], Step [68/225], Training Accuracy: 96.7831%, Training Loss: 0.0949%\n",
      "Epoch [74/300], Step [69/225], Training Accuracy: 96.7618%, Training Loss: 0.0956%\n",
      "Epoch [74/300], Step [70/225], Training Accuracy: 96.7634%, Training Loss: 0.0958%\n",
      "Epoch [74/300], Step [71/225], Training Accuracy: 96.7210%, Training Loss: 0.0968%\n",
      "Epoch [74/300], Step [72/225], Training Accuracy: 96.7231%, Training Loss: 0.0964%\n",
      "Epoch [74/300], Step [73/225], Training Accuracy: 96.7466%, Training Loss: 0.0965%\n",
      "Epoch [74/300], Step [74/225], Training Accuracy: 96.7694%, Training Loss: 0.0963%\n",
      "Epoch [74/300], Step [75/225], Training Accuracy: 96.7292%, Training Loss: 0.0964%\n",
      "Epoch [74/300], Step [76/225], Training Accuracy: 96.7311%, Training Loss: 0.0966%\n",
      "Epoch [74/300], Step [77/225], Training Accuracy: 96.6721%, Training Loss: 0.0971%\n",
      "Epoch [74/300], Step [78/225], Training Accuracy: 96.6947%, Training Loss: 0.0965%\n",
      "Epoch [74/300], Step [79/225], Training Accuracy: 96.7366%, Training Loss: 0.0956%\n",
      "Epoch [74/300], Step [80/225], Training Accuracy: 96.7578%, Training Loss: 0.0953%\n",
      "Epoch [74/300], Step [81/225], Training Accuracy: 96.7978%, Training Loss: 0.0945%\n",
      "Epoch [74/300], Step [82/225], Training Accuracy: 96.8178%, Training Loss: 0.0941%\n",
      "Epoch [74/300], Step [83/225], Training Accuracy: 96.7997%, Training Loss: 0.0942%\n",
      "Epoch [74/300], Step [84/225], Training Accuracy: 96.8192%, Training Loss: 0.0937%\n",
      "Epoch [74/300], Step [85/225], Training Accuracy: 96.8015%, Training Loss: 0.0942%\n",
      "Epoch [74/300], Step [86/225], Training Accuracy: 96.7842%, Training Loss: 0.0946%\n",
      "Epoch [74/300], Step [87/225], Training Accuracy: 96.7852%, Training Loss: 0.0948%\n",
      "Epoch [74/300], Step [88/225], Training Accuracy: 96.7862%, Training Loss: 0.0949%\n",
      "Epoch [74/300], Step [89/225], Training Accuracy: 96.7697%, Training Loss: 0.0951%\n",
      "Epoch [74/300], Step [90/225], Training Accuracy: 96.7882%, Training Loss: 0.0949%\n",
      "Epoch [74/300], Step [91/225], Training Accuracy: 96.7720%, Training Loss: 0.0950%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/300], Step [92/225], Training Accuracy: 96.7731%, Training Loss: 0.0949%\n",
      "Epoch [74/300], Step [93/225], Training Accuracy: 96.7574%, Training Loss: 0.0951%\n",
      "Epoch [74/300], Step [94/225], Training Accuracy: 96.7919%, Training Loss: 0.0945%\n",
      "Epoch [74/300], Step [95/225], Training Accuracy: 96.7763%, Training Loss: 0.0945%\n",
      "Epoch [74/300], Step [96/225], Training Accuracy: 96.8099%, Training Loss: 0.0938%\n",
      "Epoch [74/300], Step [97/225], Training Accuracy: 96.8267%, Training Loss: 0.0934%\n",
      "Epoch [74/300], Step [98/225], Training Accuracy: 96.8272%, Training Loss: 0.0935%\n",
      "Epoch [74/300], Step [99/225], Training Accuracy: 96.8592%, Training Loss: 0.0928%\n",
      "Epoch [74/300], Step [100/225], Training Accuracy: 96.8281%, Training Loss: 0.0932%\n",
      "Epoch [74/300], Step [101/225], Training Accuracy: 96.8286%, Training Loss: 0.0929%\n",
      "Epoch [74/300], Step [102/225], Training Accuracy: 96.8444%, Training Loss: 0.0926%\n",
      "Epoch [74/300], Step [103/225], Training Accuracy: 96.7840%, Training Loss: 0.0939%\n",
      "Epoch [74/300], Step [104/225], Training Accuracy: 96.8149%, Training Loss: 0.0935%\n",
      "Epoch [74/300], Step [105/225], Training Accuracy: 96.7857%, Training Loss: 0.0943%\n",
      "Epoch [74/300], Step [106/225], Training Accuracy: 96.7866%, Training Loss: 0.0947%\n",
      "Epoch [74/300], Step [107/225], Training Accuracy: 96.7436%, Training Loss: 0.0949%\n",
      "Epoch [74/300], Step [108/225], Training Accuracy: 96.7303%, Training Loss: 0.0953%\n",
      "Epoch [74/300], Step [109/225], Training Accuracy: 96.7603%, Training Loss: 0.0947%\n",
      "Epoch [74/300], Step [110/225], Training Accuracy: 96.7614%, Training Loss: 0.0948%\n",
      "Epoch [74/300], Step [111/225], Training Accuracy: 96.7765%, Training Loss: 0.0948%\n",
      "Epoch [74/300], Step [112/225], Training Accuracy: 96.8052%, Training Loss: 0.0942%\n",
      "Epoch [74/300], Step [113/225], Training Accuracy: 96.7920%, Training Loss: 0.0941%\n",
      "Epoch [74/300], Step [114/225], Training Accuracy: 96.7928%, Training Loss: 0.0941%\n",
      "Epoch [74/300], Step [115/225], Training Accuracy: 96.6848%, Training Loss: 0.0952%\n",
      "Epoch [74/300], Step [116/225], Training Accuracy: 96.6999%, Training Loss: 0.0952%\n",
      "Epoch [74/300], Step [117/225], Training Accuracy: 96.7014%, Training Loss: 0.0951%\n",
      "Epoch [74/300], Step [118/225], Training Accuracy: 96.6764%, Training Loss: 0.0960%\n",
      "Epoch [74/300], Step [119/225], Training Accuracy: 96.6387%, Training Loss: 0.0964%\n",
      "Epoch [74/300], Step [120/225], Training Accuracy: 96.6146%, Training Loss: 0.0966%\n",
      "Epoch [74/300], Step [121/225], Training Accuracy: 96.6038%, Training Loss: 0.0968%\n",
      "Epoch [74/300], Step [122/225], Training Accuracy: 96.5932%, Training Loss: 0.0967%\n",
      "Epoch [74/300], Step [123/225], Training Accuracy: 96.5955%, Training Loss: 0.0971%\n",
      "Epoch [74/300], Step [124/225], Training Accuracy: 96.6104%, Training Loss: 0.0968%\n",
      "Epoch [74/300], Step [125/225], Training Accuracy: 96.6000%, Training Loss: 0.0972%\n",
      "Epoch [74/300], Step [126/225], Training Accuracy: 96.6022%, Training Loss: 0.0970%\n",
      "Epoch [74/300], Step [127/225], Training Accuracy: 96.6166%, Training Loss: 0.0966%\n",
      "Epoch [74/300], Step [128/225], Training Accuracy: 96.5942%, Training Loss: 0.0971%\n",
      "Epoch [74/300], Step [129/225], Training Accuracy: 96.6206%, Training Loss: 0.0967%\n",
      "Epoch [74/300], Step [130/225], Training Accuracy: 96.6346%, Training Loss: 0.0966%\n",
      "Epoch [74/300], Step [131/225], Training Accuracy: 96.6126%, Training Loss: 0.0973%\n",
      "Epoch [74/300], Step [132/225], Training Accuracy: 96.6146%, Training Loss: 0.0972%\n",
      "Epoch [74/300], Step [133/225], Training Accuracy: 96.6283%, Training Loss: 0.0968%\n",
      "Epoch [74/300], Step [134/225], Training Accuracy: 96.6185%, Training Loss: 0.0971%\n",
      "Epoch [74/300], Step [135/225], Training Accuracy: 96.6435%, Training Loss: 0.0967%\n",
      "Epoch [74/300], Step [136/225], Training Accuracy: 96.6452%, Training Loss: 0.0970%\n",
      "Epoch [74/300], Step [137/225], Training Accuracy: 96.6469%, Training Loss: 0.0971%\n",
      "Epoch [74/300], Step [138/225], Training Accuracy: 96.6372%, Training Loss: 0.0974%\n",
      "Epoch [74/300], Step [139/225], Training Accuracy: 96.6502%, Training Loss: 0.0972%\n",
      "Epoch [74/300], Step [140/225], Training Accuracy: 96.6295%, Training Loss: 0.0975%\n",
      "Epoch [74/300], Step [141/225], Training Accuracy: 96.6090%, Training Loss: 0.0978%\n",
      "Epoch [74/300], Step [142/225], Training Accuracy: 96.5889%, Training Loss: 0.0982%\n",
      "Epoch [74/300], Step [143/225], Training Accuracy: 96.5800%, Training Loss: 0.0986%\n",
      "Epoch [74/300], Step [144/225], Training Accuracy: 96.5603%, Training Loss: 0.0987%\n",
      "Epoch [74/300], Step [145/225], Training Accuracy: 96.5302%, Training Loss: 0.0991%\n",
      "Epoch [74/300], Step [146/225], Training Accuracy: 96.5218%, Training Loss: 0.0993%\n",
      "Epoch [74/300], Step [147/225], Training Accuracy: 96.5030%, Training Loss: 0.0995%\n",
      "Epoch [74/300], Step [148/225], Training Accuracy: 96.4949%, Training Loss: 0.0997%\n",
      "Epoch [74/300], Step [149/225], Training Accuracy: 96.4660%, Training Loss: 0.1000%\n",
      "Epoch [74/300], Step [150/225], Training Accuracy: 96.4688%, Training Loss: 0.0998%\n",
      "Epoch [74/300], Step [151/225], Training Accuracy: 96.4714%, Training Loss: 0.0996%\n",
      "Epoch [74/300], Step [152/225], Training Accuracy: 96.4741%, Training Loss: 0.0996%\n",
      "Epoch [74/300], Step [153/225], Training Accuracy: 96.4665%, Training Loss: 0.0998%\n",
      "Epoch [74/300], Step [154/225], Training Accuracy: 96.4692%, Training Loss: 0.0999%\n",
      "Epoch [74/300], Step [155/225], Training Accuracy: 96.4819%, Training Loss: 0.0997%\n",
      "Epoch [74/300], Step [156/225], Training Accuracy: 96.4944%, Training Loss: 0.0996%\n",
      "Epoch [74/300], Step [157/225], Training Accuracy: 96.4968%, Training Loss: 0.0998%\n",
      "Epoch [74/300], Step [158/225], Training Accuracy: 96.4992%, Training Loss: 0.0998%\n",
      "Epoch [74/300], Step [159/225], Training Accuracy: 96.5016%, Training Loss: 0.0999%\n",
      "Epoch [74/300], Step [160/225], Training Accuracy: 96.5137%, Training Loss: 0.0998%\n",
      "Epoch [74/300], Step [161/225], Training Accuracy: 96.5159%, Training Loss: 0.0997%\n",
      "Epoch [74/300], Step [162/225], Training Accuracy: 96.5085%, Training Loss: 0.1000%\n",
      "Epoch [74/300], Step [163/225], Training Accuracy: 96.5012%, Training Loss: 0.1002%\n",
      "Epoch [74/300], Step [164/225], Training Accuracy: 96.5034%, Training Loss: 0.1001%\n",
      "Epoch [74/300], Step [165/225], Training Accuracy: 96.5057%, Training Loss: 0.1000%\n",
      "Epoch [74/300], Step [166/225], Training Accuracy: 96.4891%, Training Loss: 0.1007%\n",
      "Epoch [74/300], Step [167/225], Training Accuracy: 96.5007%, Training Loss: 0.1003%\n",
      "Epoch [74/300], Step [168/225], Training Accuracy: 96.5123%, Training Loss: 0.1000%\n",
      "Epoch [74/300], Step [169/225], Training Accuracy: 96.5052%, Training Loss: 0.1001%\n",
      "Epoch [74/300], Step [170/225], Training Accuracy: 96.5074%, Training Loss: 0.0999%\n",
      "Epoch [74/300], Step [171/225], Training Accuracy: 96.5278%, Training Loss: 0.0995%\n",
      "Epoch [74/300], Step [172/225], Training Accuracy: 96.5480%, Training Loss: 0.0992%\n",
      "Epoch [74/300], Step [173/225], Training Accuracy: 96.5318%, Training Loss: 0.0995%\n",
      "Epoch [74/300], Step [174/225], Training Accuracy: 96.5248%, Training Loss: 0.0995%\n",
      "Epoch [74/300], Step [175/225], Training Accuracy: 96.5268%, Training Loss: 0.0995%\n",
      "Epoch [74/300], Step [176/225], Training Accuracy: 96.5376%, Training Loss: 0.0992%\n",
      "Epoch [74/300], Step [177/225], Training Accuracy: 96.5395%, Training Loss: 0.0990%\n",
      "Epoch [74/300], Step [178/225], Training Accuracy: 96.5414%, Training Loss: 0.0990%\n",
      "Epoch [74/300], Step [179/225], Training Accuracy: 96.5608%, Training Loss: 0.0986%\n",
      "Epoch [74/300], Step [180/225], Training Accuracy: 96.5625%, Training Loss: 0.0984%\n",
      "Epoch [74/300], Step [181/225], Training Accuracy: 96.5383%, Training Loss: 0.0989%\n",
      "Epoch [74/300], Step [182/225], Training Accuracy: 96.5488%, Training Loss: 0.0988%\n",
      "Epoch [74/300], Step [183/225], Training Accuracy: 96.5505%, Training Loss: 0.0986%\n",
      "Epoch [74/300], Step [184/225], Training Accuracy: 96.5608%, Training Loss: 0.0984%\n",
      "Epoch [74/300], Step [185/225], Training Accuracy: 96.5456%, Training Loss: 0.0987%\n",
      "Epoch [74/300], Step [186/225], Training Accuracy: 96.5558%, Training Loss: 0.0988%\n",
      "Epoch [74/300], Step [187/225], Training Accuracy: 96.5491%, Training Loss: 0.0990%\n",
      "Epoch [74/300], Step [188/225], Training Accuracy: 96.5592%, Training Loss: 0.0989%\n",
      "Epoch [74/300], Step [189/225], Training Accuracy: 96.5691%, Training Loss: 0.0987%\n",
      "Epoch [74/300], Step [190/225], Training Accuracy: 96.5543%, Training Loss: 0.0990%\n",
      "Epoch [74/300], Step [191/225], Training Accuracy: 96.5641%, Training Loss: 0.0989%\n",
      "Epoch [74/300], Step [192/225], Training Accuracy: 96.5658%, Training Loss: 0.0991%\n",
      "Epoch [74/300], Step [193/225], Training Accuracy: 96.5431%, Training Loss: 0.0995%\n",
      "Epoch [74/300], Step [194/225], Training Accuracy: 96.5609%, Training Loss: 0.0993%\n",
      "Epoch [74/300], Step [195/225], Training Accuracy: 96.5385%, Training Loss: 0.0996%\n",
      "Epoch [74/300], Step [196/225], Training Accuracy: 96.5482%, Training Loss: 0.0994%\n",
      "Epoch [74/300], Step [197/225], Training Accuracy: 96.5419%, Training Loss: 0.0994%\n",
      "Epoch [74/300], Step [198/225], Training Accuracy: 96.5515%, Training Loss: 0.0993%\n",
      "Epoch [74/300], Step [199/225], Training Accuracy: 96.5609%, Training Loss: 0.0994%\n",
      "Epoch [74/300], Step [200/225], Training Accuracy: 96.5469%, Training Loss: 0.0995%\n",
      "Epoch [74/300], Step [201/225], Training Accuracy: 96.5407%, Training Loss: 0.0996%\n",
      "Epoch [74/300], Step [202/225], Training Accuracy: 96.5424%, Training Loss: 0.0996%\n",
      "Epoch [74/300], Step [203/225], Training Accuracy: 96.5440%, Training Loss: 0.0994%\n",
      "Epoch [74/300], Step [204/225], Training Accuracy: 96.5150%, Training Loss: 0.1000%\n",
      "Epoch [74/300], Step [205/225], Training Accuracy: 96.5244%, Training Loss: 0.0999%\n",
      "Epoch [74/300], Step [206/225], Training Accuracy: 96.5261%, Training Loss: 0.1001%\n",
      "Epoch [74/300], Step [207/225], Training Accuracy: 96.5429%, Training Loss: 0.0998%\n",
      "Epoch [74/300], Step [208/225], Training Accuracy: 96.5595%, Training Loss: 0.0995%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/300], Step [209/225], Training Accuracy: 96.5685%, Training Loss: 0.0995%\n",
      "Epoch [74/300], Step [210/225], Training Accuracy: 96.5848%, Training Loss: 0.0991%\n",
      "Epoch [74/300], Step [211/225], Training Accuracy: 96.5862%, Training Loss: 0.0991%\n",
      "Epoch [74/300], Step [212/225], Training Accuracy: 96.5876%, Training Loss: 0.0991%\n",
      "Epoch [74/300], Step [213/225], Training Accuracy: 96.6036%, Training Loss: 0.0989%\n",
      "Epoch [74/300], Step [214/225], Training Accuracy: 96.5975%, Training Loss: 0.0990%\n",
      "Epoch [74/300], Step [215/225], Training Accuracy: 96.5916%, Training Loss: 0.0992%\n",
      "Epoch [74/300], Step [216/225], Training Accuracy: 96.5856%, Training Loss: 0.0994%\n",
      "Epoch [74/300], Step [217/225], Training Accuracy: 96.5654%, Training Loss: 0.0994%\n",
      "Epoch [74/300], Step [218/225], Training Accuracy: 96.5525%, Training Loss: 0.0995%\n",
      "Epoch [74/300], Step [219/225], Training Accuracy: 96.5468%, Training Loss: 0.0994%\n",
      "Epoch [74/300], Step [220/225], Training Accuracy: 96.5412%, Training Loss: 0.0993%\n",
      "Epoch [74/300], Step [221/225], Training Accuracy: 96.5498%, Training Loss: 0.0991%\n",
      "Epoch [74/300], Step [222/225], Training Accuracy: 96.5442%, Training Loss: 0.0993%\n",
      "Epoch [74/300], Step [223/225], Training Accuracy: 96.5527%, Training Loss: 0.0990%\n",
      "Epoch [74/300], Step [224/225], Training Accuracy: 96.5681%, Training Loss: 0.0987%\n",
      "Epoch [74/300], Step [225/225], Training Accuracy: 96.5745%, Training Loss: 0.0985%\n",
      "Epoch [75/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0382%\n",
      "Epoch [75/300], Step [2/225], Training Accuracy: 99.2188%, Training Loss: 0.0486%\n",
      "Epoch [75/300], Step [3/225], Training Accuracy: 95.8333%, Training Loss: 0.1100%\n",
      "Epoch [75/300], Step [4/225], Training Accuracy: 96.8750%, Training Loss: 0.0895%\n",
      "Epoch [75/300], Step [5/225], Training Accuracy: 96.8750%, Training Loss: 0.0917%\n",
      "Epoch [75/300], Step [6/225], Training Accuracy: 96.8750%, Training Loss: 0.0883%\n",
      "Epoch [75/300], Step [7/225], Training Accuracy: 96.4286%, Training Loss: 0.0918%\n",
      "Epoch [75/300], Step [8/225], Training Accuracy: 96.2891%, Training Loss: 0.0969%\n",
      "Epoch [75/300], Step [9/225], Training Accuracy: 96.3542%, Training Loss: 0.0925%\n",
      "Epoch [75/300], Step [10/225], Training Accuracy: 96.4062%, Training Loss: 0.0909%\n",
      "Epoch [75/300], Step [11/225], Training Accuracy: 96.4489%, Training Loss: 0.0893%\n",
      "Epoch [75/300], Step [12/225], Training Accuracy: 96.4844%, Training Loss: 0.0888%\n",
      "Epoch [75/300], Step [13/225], Training Accuracy: 96.5144%, Training Loss: 0.0877%\n",
      "Epoch [75/300], Step [14/225], Training Accuracy: 96.5402%, Training Loss: 0.0879%\n",
      "Epoch [75/300], Step [15/225], Training Accuracy: 96.6667%, Training Loss: 0.0841%\n",
      "Epoch [75/300], Step [16/225], Training Accuracy: 96.6797%, Training Loss: 0.0829%\n",
      "Epoch [75/300], Step [17/225], Training Accuracy: 96.3235%, Training Loss: 0.0880%\n",
      "Epoch [75/300], Step [18/225], Training Accuracy: 96.3542%, Training Loss: 0.0876%\n",
      "Epoch [75/300], Step [19/225], Training Accuracy: 96.3816%, Training Loss: 0.0860%\n",
      "Epoch [75/300], Step [20/225], Training Accuracy: 96.3281%, Training Loss: 0.0883%\n",
      "Epoch [75/300], Step [21/225], Training Accuracy: 96.3542%, Training Loss: 0.0871%\n",
      "Epoch [75/300], Step [22/225], Training Accuracy: 96.4489%, Training Loss: 0.0871%\n",
      "Epoch [75/300], Step [23/225], Training Accuracy: 96.4674%, Training Loss: 0.0872%\n",
      "Epoch [75/300], Step [24/225], Training Accuracy: 96.4193%, Training Loss: 0.0877%\n",
      "Epoch [75/300], Step [25/225], Training Accuracy: 96.5625%, Training Loss: 0.0854%\n",
      "Epoch [75/300], Step [26/225], Training Accuracy: 96.4543%, Training Loss: 0.0881%\n",
      "Epoch [75/300], Step [27/225], Training Accuracy: 96.4120%, Training Loss: 0.0914%\n",
      "Epoch [75/300], Step [28/225], Training Accuracy: 96.3728%, Training Loss: 0.0921%\n",
      "Epoch [75/300], Step [29/225], Training Accuracy: 96.3362%, Training Loss: 0.0913%\n",
      "Epoch [75/300], Step [30/225], Training Accuracy: 96.3542%, Training Loss: 0.0904%\n",
      "Epoch [75/300], Step [31/225], Training Accuracy: 96.4214%, Training Loss: 0.0898%\n",
      "Epoch [75/300], Step [32/225], Training Accuracy: 96.3867%, Training Loss: 0.0902%\n",
      "Epoch [75/300], Step [33/225], Training Accuracy: 96.4489%, Training Loss: 0.0891%\n",
      "Epoch [75/300], Step [34/225], Training Accuracy: 96.4614%, Training Loss: 0.0890%\n",
      "Epoch [75/300], Step [35/225], Training Accuracy: 96.5179%, Training Loss: 0.0880%\n",
      "Epoch [75/300], Step [36/225], Training Accuracy: 96.6146%, Training Loss: 0.0865%\n",
      "Epoch [75/300], Step [37/225], Training Accuracy: 96.6639%, Training Loss: 0.0851%\n",
      "Epoch [75/300], Step [38/225], Training Accuracy: 96.5461%, Training Loss: 0.0860%\n",
      "Epoch [75/300], Step [39/225], Training Accuracy: 96.4744%, Training Loss: 0.0873%\n",
      "Epoch [75/300], Step [40/225], Training Accuracy: 96.4062%, Training Loss: 0.0890%\n",
      "Epoch [75/300], Step [41/225], Training Accuracy: 96.3034%, Training Loss: 0.0914%\n",
      "Epoch [75/300], Step [42/225], Training Accuracy: 96.3170%, Training Loss: 0.0912%\n",
      "Epoch [75/300], Step [43/225], Training Accuracy: 96.3299%, Training Loss: 0.0906%\n",
      "Epoch [75/300], Step [44/225], Training Accuracy: 96.3423%, Training Loss: 0.0908%\n",
      "Epoch [75/300], Step [45/225], Training Accuracy: 96.3542%, Training Loss: 0.0919%\n",
      "Epoch [75/300], Step [46/225], Training Accuracy: 96.3315%, Training Loss: 0.0919%\n",
      "Epoch [75/300], Step [47/225], Training Accuracy: 96.3431%, Training Loss: 0.0927%\n",
      "Epoch [75/300], Step [48/225], Training Accuracy: 96.3542%, Training Loss: 0.0924%\n",
      "Epoch [75/300], Step [49/225], Training Accuracy: 96.3967%, Training Loss: 0.0931%\n",
      "Epoch [75/300], Step [50/225], Training Accuracy: 96.3125%, Training Loss: 0.0944%\n",
      "Epoch [75/300], Step [51/225], Training Accuracy: 96.2929%, Training Loss: 0.0942%\n",
      "Epoch [75/300], Step [52/225], Training Accuracy: 96.3341%, Training Loss: 0.0934%\n",
      "Epoch [75/300], Step [53/225], Training Accuracy: 96.2264%, Training Loss: 0.0950%\n",
      "Epoch [75/300], Step [54/225], Training Accuracy: 96.1806%, Training Loss: 0.0967%\n",
      "Epoch [75/300], Step [55/225], Training Accuracy: 96.1648%, Training Loss: 0.0973%\n",
      "Epoch [75/300], Step [56/225], Training Accuracy: 96.1496%, Training Loss: 0.0988%\n",
      "Epoch [75/300], Step [57/225], Training Accuracy: 96.2171%, Training Loss: 0.0982%\n",
      "Epoch [75/300], Step [58/225], Training Accuracy: 96.2284%, Training Loss: 0.0985%\n",
      "Epoch [75/300], Step [59/225], Training Accuracy: 96.2924%, Training Loss: 0.0973%\n",
      "Epoch [75/300], Step [60/225], Training Accuracy: 96.3021%, Training Loss: 0.0973%\n",
      "Epoch [75/300], Step [61/225], Training Accuracy: 96.2602%, Training Loss: 0.0975%\n",
      "Epoch [75/300], Step [62/225], Training Accuracy: 96.2702%, Training Loss: 0.0975%\n",
      "Epoch [75/300], Step [63/225], Training Accuracy: 96.2054%, Training Loss: 0.0988%\n",
      "Epoch [75/300], Step [64/225], Training Accuracy: 96.2158%, Training Loss: 0.0990%\n",
      "Epoch [75/300], Step [65/225], Training Accuracy: 96.2260%, Training Loss: 0.0985%\n",
      "Epoch [75/300], Step [66/225], Training Accuracy: 96.1884%, Training Loss: 0.0996%\n",
      "Epoch [75/300], Step [67/225], Training Accuracy: 96.2220%, Training Loss: 0.0993%\n",
      "Epoch [75/300], Step [68/225], Training Accuracy: 96.2316%, Training Loss: 0.0992%\n",
      "Epoch [75/300], Step [69/225], Training Accuracy: 96.2862%, Training Loss: 0.0981%\n",
      "Epoch [75/300], Step [70/225], Training Accuracy: 96.3393%, Training Loss: 0.0972%\n",
      "Epoch [75/300], Step [71/225], Training Accuracy: 96.3468%, Training Loss: 0.0971%\n",
      "Epoch [75/300], Step [72/225], Training Accuracy: 96.3759%, Training Loss: 0.0968%\n",
      "Epoch [75/300], Step [73/225], Training Accuracy: 96.2543%, Training Loss: 0.0996%\n",
      "Epoch [75/300], Step [74/225], Training Accuracy: 96.2627%, Training Loss: 0.0993%\n",
      "Epoch [75/300], Step [75/225], Training Accuracy: 96.2708%, Training Loss: 0.0999%\n",
      "Epoch [75/300], Step [76/225], Training Accuracy: 96.2582%, Training Loss: 0.1001%\n",
      "Epoch [75/300], Step [77/225], Training Accuracy: 96.2054%, Training Loss: 0.1006%\n",
      "Epoch [75/300], Step [78/225], Training Accuracy: 96.2340%, Training Loss: 0.1000%\n",
      "Epoch [75/300], Step [79/225], Training Accuracy: 96.2421%, Training Loss: 0.1002%\n",
      "Epoch [75/300], Step [80/225], Training Accuracy: 96.2109%, Training Loss: 0.1016%\n",
      "Epoch [75/300], Step [81/225], Training Accuracy: 96.2384%, Training Loss: 0.1012%\n",
      "Epoch [75/300], Step [82/225], Training Accuracy: 96.2271%, Training Loss: 0.1009%\n",
      "Epoch [75/300], Step [83/225], Training Accuracy: 96.2349%, Training Loss: 0.1009%\n",
      "Epoch [75/300], Step [84/225], Training Accuracy: 96.2054%, Training Loss: 0.1015%\n",
      "Epoch [75/300], Step [85/225], Training Accuracy: 96.2316%, Training Loss: 0.1010%\n",
      "Epoch [75/300], Step [86/225], Training Accuracy: 96.2391%, Training Loss: 0.1012%\n",
      "Epoch [75/300], Step [87/225], Training Accuracy: 96.2105%, Training Loss: 0.1014%\n",
      "Epoch [75/300], Step [88/225], Training Accuracy: 96.2180%, Training Loss: 0.1013%\n",
      "Epoch [75/300], Step [89/225], Training Accuracy: 96.1903%, Training Loss: 0.1014%\n",
      "Epoch [75/300], Step [90/225], Training Accuracy: 96.1632%, Training Loss: 0.1021%\n",
      "Epoch [75/300], Step [91/225], Training Accuracy: 96.1710%, Training Loss: 0.1018%\n",
      "Epoch [75/300], Step [92/225], Training Accuracy: 96.1957%, Training Loss: 0.1011%\n",
      "Epoch [75/300], Step [93/225], Training Accuracy: 96.2366%, Training Loss: 0.1003%\n",
      "Epoch [75/300], Step [94/225], Training Accuracy: 96.2101%, Training Loss: 0.1005%\n",
      "Epoch [75/300], Step [95/225], Training Accuracy: 96.2171%, Training Loss: 0.1003%\n",
      "Epoch [75/300], Step [96/225], Training Accuracy: 96.2402%, Training Loss: 0.1000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/300], Step [97/225], Training Accuracy: 96.2629%, Training Loss: 0.0996%\n",
      "Epoch [75/300], Step [98/225], Training Accuracy: 96.2372%, Training Loss: 0.1015%\n",
      "Epoch [75/300], Step [99/225], Training Accuracy: 96.2279%, Training Loss: 0.1015%\n",
      "Epoch [75/300], Step [100/225], Training Accuracy: 96.2500%, Training Loss: 0.1015%\n",
      "Epoch [75/300], Step [101/225], Training Accuracy: 96.2562%, Training Loss: 0.1012%\n",
      "Epoch [75/300], Step [102/225], Training Accuracy: 96.2316%, Training Loss: 0.1018%\n",
      "Epoch [75/300], Step [103/225], Training Accuracy: 96.2379%, Training Loss: 0.1015%\n",
      "Epoch [75/300], Step [104/225], Training Accuracy: 96.2290%, Training Loss: 0.1014%\n",
      "Epoch [75/300], Step [105/225], Training Accuracy: 96.2500%, Training Loss: 0.1010%\n",
      "Epoch [75/300], Step [106/225], Training Accuracy: 96.2706%, Training Loss: 0.1007%\n",
      "Epoch [75/300], Step [107/225], Training Accuracy: 96.2763%, Training Loss: 0.1006%\n",
      "Epoch [75/300], Step [108/225], Training Accuracy: 96.2384%, Training Loss: 0.1011%\n",
      "Epoch [75/300], Step [109/225], Training Accuracy: 96.2443%, Training Loss: 0.1014%\n",
      "Epoch [75/300], Step [110/225], Training Accuracy: 96.2500%, Training Loss: 0.1014%\n",
      "Epoch [75/300], Step [111/225], Training Accuracy: 96.2416%, Training Loss: 0.1015%\n",
      "Epoch [75/300], Step [112/225], Training Accuracy: 96.1914%, Training Loss: 0.1020%\n",
      "Epoch [75/300], Step [113/225], Training Accuracy: 96.1698%, Training Loss: 0.1022%\n",
      "Epoch [75/300], Step [114/225], Training Accuracy: 96.1623%, Training Loss: 0.1021%\n",
      "Epoch [75/300], Step [115/225], Training Accuracy: 96.1413%, Training Loss: 0.1025%\n",
      "Epoch [75/300], Step [116/225], Training Accuracy: 96.1476%, Training Loss: 0.1027%\n",
      "Epoch [75/300], Step [117/225], Training Accuracy: 96.1405%, Training Loss: 0.1029%\n",
      "Epoch [75/300], Step [118/225], Training Accuracy: 96.1202%, Training Loss: 0.1030%\n",
      "Epoch [75/300], Step [119/225], Training Accuracy: 96.1266%, Training Loss: 0.1029%\n",
      "Epoch [75/300], Step [120/225], Training Accuracy: 96.1198%, Training Loss: 0.1029%\n",
      "Epoch [75/300], Step [121/225], Training Accuracy: 96.1131%, Training Loss: 0.1030%\n",
      "Epoch [75/300], Step [122/225], Training Accuracy: 96.1194%, Training Loss: 0.1027%\n",
      "Epoch [75/300], Step [123/225], Training Accuracy: 96.1255%, Training Loss: 0.1027%\n",
      "Epoch [75/300], Step [124/225], Training Accuracy: 96.1316%, Training Loss: 0.1032%\n",
      "Epoch [75/300], Step [125/225], Training Accuracy: 96.1250%, Training Loss: 0.1032%\n",
      "Epoch [75/300], Step [126/225], Training Accuracy: 96.1310%, Training Loss: 0.1032%\n",
      "Epoch [75/300], Step [127/225], Training Accuracy: 96.1122%, Training Loss: 0.1034%\n",
      "Epoch [75/300], Step [128/225], Training Accuracy: 96.1182%, Training Loss: 0.1033%\n",
      "Epoch [75/300], Step [129/225], Training Accuracy: 96.1361%, Training Loss: 0.1030%\n",
      "Epoch [75/300], Step [130/225], Training Accuracy: 96.1418%, Training Loss: 0.1031%\n",
      "Epoch [75/300], Step [131/225], Training Accuracy: 96.1713%, Training Loss: 0.1025%\n",
      "Epoch [75/300], Step [132/225], Training Accuracy: 96.1766%, Training Loss: 0.1022%\n",
      "Epoch [75/300], Step [133/225], Training Accuracy: 96.1936%, Training Loss: 0.1023%\n",
      "Epoch [75/300], Step [134/225], Training Accuracy: 96.1987%, Training Loss: 0.1022%\n",
      "Epoch [75/300], Step [135/225], Training Accuracy: 96.1806%, Training Loss: 0.1026%\n",
      "Epoch [75/300], Step [136/225], Training Accuracy: 96.1627%, Training Loss: 0.1032%\n",
      "Epoch [75/300], Step [137/225], Training Accuracy: 96.1793%, Training Loss: 0.1030%\n",
      "Epoch [75/300], Step [138/225], Training Accuracy: 96.2070%, Training Loss: 0.1025%\n",
      "Epoch [75/300], Step [139/225], Training Accuracy: 96.2005%, Training Loss: 0.1026%\n",
      "Epoch [75/300], Step [140/225], Training Accuracy: 96.1830%, Training Loss: 0.1029%\n",
      "Epoch [75/300], Step [141/225], Training Accuracy: 96.2101%, Training Loss: 0.1026%\n",
      "Epoch [75/300], Step [142/225], Training Accuracy: 96.2258%, Training Loss: 0.1024%\n",
      "Epoch [75/300], Step [143/225], Training Accuracy: 96.2194%, Training Loss: 0.1028%\n",
      "Epoch [75/300], Step [144/225], Training Accuracy: 96.2240%, Training Loss: 0.1028%\n",
      "Epoch [75/300], Step [145/225], Training Accuracy: 96.2177%, Training Loss: 0.1033%\n",
      "Epoch [75/300], Step [146/225], Training Accuracy: 96.2115%, Training Loss: 0.1033%\n",
      "Epoch [75/300], Step [147/225], Training Accuracy: 96.2372%, Training Loss: 0.1027%\n",
      "Epoch [75/300], Step [148/225], Training Accuracy: 96.2416%, Training Loss: 0.1026%\n",
      "Epoch [75/300], Step [149/225], Training Accuracy: 96.2353%, Training Loss: 0.1026%\n",
      "Epoch [75/300], Step [150/225], Training Accuracy: 96.2292%, Training Loss: 0.1027%\n",
      "Epoch [75/300], Step [151/225], Training Accuracy: 96.2334%, Training Loss: 0.1025%\n",
      "Epoch [75/300], Step [152/225], Training Accuracy: 96.2377%, Training Loss: 0.1026%\n",
      "Epoch [75/300], Step [153/225], Training Accuracy: 96.2520%, Training Loss: 0.1024%\n",
      "Epoch [75/300], Step [154/225], Training Accuracy: 96.2561%, Training Loss: 0.1023%\n",
      "Epoch [75/300], Step [155/225], Training Accuracy: 96.2298%, Training Loss: 0.1026%\n",
      "Epoch [75/300], Step [156/225], Training Accuracy: 96.2340%, Training Loss: 0.1026%\n",
      "Epoch [75/300], Step [157/225], Training Accuracy: 96.2082%, Training Loss: 0.1030%\n",
      "Epoch [75/300], Step [158/225], Training Accuracy: 96.2124%, Training Loss: 0.1029%\n",
      "Epoch [75/300], Step [159/225], Training Accuracy: 96.2166%, Training Loss: 0.1027%\n",
      "Epoch [75/300], Step [160/225], Training Accuracy: 96.2207%, Training Loss: 0.1024%\n",
      "Epoch [75/300], Step [161/225], Training Accuracy: 96.2345%, Training Loss: 0.1024%\n",
      "Epoch [75/300], Step [162/225], Training Accuracy: 96.2095%, Training Loss: 0.1034%\n",
      "Epoch [75/300], Step [163/225], Training Accuracy: 96.1752%, Training Loss: 0.1039%\n",
      "Epoch [75/300], Step [164/225], Training Accuracy: 96.1700%, Training Loss: 0.1039%\n",
      "Epoch [75/300], Step [165/225], Training Accuracy: 96.1742%, Training Loss: 0.1037%\n",
      "Epoch [75/300], Step [166/225], Training Accuracy: 96.1973%, Training Loss: 0.1033%\n",
      "Epoch [75/300], Step [167/225], Training Accuracy: 96.2013%, Training Loss: 0.1033%\n",
      "Epoch [75/300], Step [168/225], Training Accuracy: 96.1961%, Training Loss: 0.1031%\n",
      "Epoch [75/300], Step [169/225], Training Accuracy: 96.2001%, Training Loss: 0.1030%\n",
      "Epoch [75/300], Step [170/225], Training Accuracy: 96.2040%, Training Loss: 0.1030%\n",
      "Epoch [75/300], Step [171/225], Training Accuracy: 96.1806%, Training Loss: 0.1036%\n",
      "Epoch [75/300], Step [172/225], Training Accuracy: 96.1755%, Training Loss: 0.1037%\n",
      "Epoch [75/300], Step [173/225], Training Accuracy: 96.1796%, Training Loss: 0.1034%\n",
      "Epoch [75/300], Step [174/225], Training Accuracy: 96.1835%, Training Loss: 0.1033%\n",
      "Epoch [75/300], Step [175/225], Training Accuracy: 96.1875%, Training Loss: 0.1032%\n",
      "Epoch [75/300], Step [176/225], Training Accuracy: 96.1914%, Training Loss: 0.1035%\n",
      "Epoch [75/300], Step [177/225], Training Accuracy: 96.2041%, Training Loss: 0.1032%\n",
      "Epoch [75/300], Step [178/225], Training Accuracy: 96.1903%, Training Loss: 0.1034%\n",
      "Epoch [75/300], Step [179/225], Training Accuracy: 96.1679%, Training Loss: 0.1039%\n",
      "Epoch [75/300], Step [180/225], Training Accuracy: 96.1719%, Training Loss: 0.1039%\n",
      "Epoch [75/300], Step [181/225], Training Accuracy: 96.1585%, Training Loss: 0.1043%\n",
      "Epoch [75/300], Step [182/225], Training Accuracy: 96.1538%, Training Loss: 0.1043%\n",
      "Epoch [75/300], Step [183/225], Training Accuracy: 96.1749%, Training Loss: 0.1039%\n",
      "Epoch [75/300], Step [184/225], Training Accuracy: 96.1957%, Training Loss: 0.1036%\n",
      "Epoch [75/300], Step [185/225], Training Accuracy: 96.1993%, Training Loss: 0.1034%\n",
      "Epoch [75/300], Step [186/225], Training Accuracy: 96.2030%, Training Loss: 0.1034%\n",
      "Epoch [75/300], Step [187/225], Training Accuracy: 96.1982%, Training Loss: 0.1037%\n",
      "Epoch [75/300], Step [188/225], Training Accuracy: 96.2018%, Training Loss: 0.1035%\n",
      "Epoch [75/300], Step [189/225], Training Accuracy: 96.1971%, Training Loss: 0.1039%\n",
      "Epoch [75/300], Step [190/225], Training Accuracy: 96.1842%, Training Loss: 0.1039%\n",
      "Epoch [75/300], Step [191/225], Training Accuracy: 96.1960%, Training Loss: 0.1037%\n",
      "Epoch [75/300], Step [192/225], Training Accuracy: 96.1995%, Training Loss: 0.1035%\n",
      "Epoch [75/300], Step [193/225], Training Accuracy: 96.1869%, Training Loss: 0.1038%\n",
      "Epoch [75/300], Step [194/225], Training Accuracy: 96.2065%, Training Loss: 0.1035%\n",
      "Epoch [75/300], Step [195/225], Training Accuracy: 96.2099%, Training Loss: 0.1036%\n",
      "Epoch [75/300], Step [196/225], Training Accuracy: 96.2293%, Training Loss: 0.1031%\n",
      "Epoch [75/300], Step [197/225], Training Accuracy: 96.2326%, Training Loss: 0.1031%\n",
      "Epoch [75/300], Step [198/225], Training Accuracy: 96.2437%, Training Loss: 0.1028%\n",
      "Epoch [75/300], Step [199/225], Training Accuracy: 96.2626%, Training Loss: 0.1025%\n",
      "Epoch [75/300], Step [200/225], Training Accuracy: 96.2656%, Training Loss: 0.1025%\n",
      "Epoch [75/300], Step [201/225], Training Accuracy: 96.2687%, Training Loss: 0.1024%\n",
      "Epoch [75/300], Step [202/225], Training Accuracy: 96.2871%, Training Loss: 0.1022%\n",
      "Epoch [75/300], Step [203/225], Training Accuracy: 96.2900%, Training Loss: 0.1021%\n",
      "Epoch [75/300], Step [204/225], Training Accuracy: 96.2852%, Training Loss: 0.1022%\n",
      "Epoch [75/300], Step [205/225], Training Accuracy: 96.2957%, Training Loss: 0.1021%\n",
      "Epoch [75/300], Step [206/225], Training Accuracy: 96.2910%, Training Loss: 0.1021%\n",
      "Epoch [75/300], Step [207/225], Training Accuracy: 96.2938%, Training Loss: 0.1020%\n",
      "Epoch [75/300], Step [208/225], Training Accuracy: 96.3041%, Training Loss: 0.1019%\n",
      "Epoch [75/300], Step [209/225], Training Accuracy: 96.3068%, Training Loss: 0.1018%\n",
      "Epoch [75/300], Step [210/225], Training Accuracy: 96.3095%, Training Loss: 0.1016%\n",
      "Epoch [75/300], Step [211/225], Training Accuracy: 96.2974%, Training Loss: 0.1018%\n",
      "Epoch [75/300], Step [212/225], Training Accuracy: 96.2854%, Training Loss: 0.1020%\n",
      "Epoch [75/300], Step [213/225], Training Accuracy: 96.3028%, Training Loss: 0.1018%\n",
      "Epoch [75/300], Step [214/225], Training Accuracy: 96.2909%, Training Loss: 0.1020%\n",
      "Epoch [75/300], Step [215/225], Training Accuracy: 96.3081%, Training Loss: 0.1016%\n",
      "Epoch [75/300], Step [216/225], Training Accuracy: 96.2963%, Training Loss: 0.1018%\n",
      "Epoch [75/300], Step [217/225], Training Accuracy: 96.3062%, Training Loss: 0.1017%\n",
      "Epoch [75/300], Step [218/225], Training Accuracy: 96.3088%, Training Loss: 0.1017%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/300], Step [219/225], Training Accuracy: 96.2686%, Training Loss: 0.1023%\n",
      "Epoch [75/300], Step [220/225], Training Accuracy: 96.2784%, Training Loss: 0.1023%\n",
      "Epoch [75/300], Step [221/225], Training Accuracy: 96.2811%, Training Loss: 0.1022%\n",
      "Epoch [75/300], Step [222/225], Training Accuracy: 96.2767%, Training Loss: 0.1025%\n",
      "Epoch [75/300], Step [223/225], Training Accuracy: 96.2934%, Training Loss: 0.1023%\n",
      "Epoch [75/300], Step [224/225], Training Accuracy: 96.2960%, Training Loss: 0.1021%\n",
      "Epoch [75/300], Step [225/225], Training Accuracy: 96.3035%, Training Loss: 0.1020%\n",
      "Epoch [76/300], Step [1/225], Training Accuracy: 93.7500%, Training Loss: 0.1384%\n",
      "Epoch [76/300], Step [2/225], Training Accuracy: 96.0938%, Training Loss: 0.1030%\n",
      "Epoch [76/300], Step [3/225], Training Accuracy: 95.3125%, Training Loss: 0.1023%\n",
      "Epoch [76/300], Step [4/225], Training Accuracy: 94.9219%, Training Loss: 0.0986%\n",
      "Epoch [76/300], Step [5/225], Training Accuracy: 95.0000%, Training Loss: 0.1013%\n",
      "Epoch [76/300], Step [6/225], Training Accuracy: 95.3125%, Training Loss: 0.1008%\n",
      "Epoch [76/300], Step [7/225], Training Accuracy: 95.3125%, Training Loss: 0.1010%\n",
      "Epoch [76/300], Step [8/225], Training Accuracy: 95.7031%, Training Loss: 0.0926%\n",
      "Epoch [76/300], Step [9/225], Training Accuracy: 95.6597%, Training Loss: 0.0924%\n",
      "Epoch [76/300], Step [10/225], Training Accuracy: 95.6250%, Training Loss: 0.0950%\n",
      "Epoch [76/300], Step [11/225], Training Accuracy: 95.7386%, Training Loss: 0.0953%\n",
      "Epoch [76/300], Step [12/225], Training Accuracy: 95.9635%, Training Loss: 0.0917%\n",
      "Epoch [76/300], Step [13/225], Training Accuracy: 95.7933%, Training Loss: 0.0970%\n",
      "Epoch [76/300], Step [14/225], Training Accuracy: 95.7589%, Training Loss: 0.0983%\n",
      "Epoch [76/300], Step [15/225], Training Accuracy: 95.6250%, Training Loss: 0.0999%\n",
      "Epoch [76/300], Step [16/225], Training Accuracy: 95.8984%, Training Loss: 0.0963%\n",
      "Epoch [76/300], Step [17/225], Training Accuracy: 96.0478%, Training Loss: 0.0975%\n",
      "Epoch [76/300], Step [18/225], Training Accuracy: 96.1806%, Training Loss: 0.0962%\n",
      "Epoch [76/300], Step [19/225], Training Accuracy: 96.0526%, Training Loss: 0.0963%\n",
      "Epoch [76/300], Step [20/225], Training Accuracy: 96.0938%, Training Loss: 0.0945%\n",
      "Epoch [76/300], Step [21/225], Training Accuracy: 96.0565%, Training Loss: 0.0950%\n",
      "Epoch [76/300], Step [22/225], Training Accuracy: 96.0938%, Training Loss: 0.0983%\n",
      "Epoch [76/300], Step [23/225], Training Accuracy: 96.1277%, Training Loss: 0.0980%\n",
      "Epoch [76/300], Step [24/225], Training Accuracy: 95.9635%, Training Loss: 0.1010%\n",
      "Epoch [76/300], Step [25/225], Training Accuracy: 95.9375%, Training Loss: 0.1010%\n",
      "Epoch [76/300], Step [26/225], Training Accuracy: 95.9736%, Training Loss: 0.0997%\n",
      "Epoch [76/300], Step [27/225], Training Accuracy: 95.9491%, Training Loss: 0.1004%\n",
      "Epoch [76/300], Step [28/225], Training Accuracy: 95.9263%, Training Loss: 0.0995%\n",
      "Epoch [76/300], Step [29/225], Training Accuracy: 95.9591%, Training Loss: 0.0992%\n",
      "Epoch [76/300], Step [30/225], Training Accuracy: 95.9375%, Training Loss: 0.1011%\n",
      "Epoch [76/300], Step [31/225], Training Accuracy: 96.0181%, Training Loss: 0.1000%\n",
      "Epoch [76/300], Step [32/225], Training Accuracy: 95.9961%, Training Loss: 0.0999%\n",
      "Epoch [76/300], Step [33/225], Training Accuracy: 95.9754%, Training Loss: 0.1002%\n",
      "Epoch [76/300], Step [34/225], Training Accuracy: 96.0478%, Training Loss: 0.0992%\n",
      "Epoch [76/300], Step [35/225], Training Accuracy: 96.0714%, Training Loss: 0.1001%\n",
      "Epoch [76/300], Step [36/225], Training Accuracy: 95.9635%, Training Loss: 0.1018%\n",
      "Epoch [76/300], Step [37/225], Training Accuracy: 95.9882%, Training Loss: 0.1019%\n",
      "Epoch [76/300], Step [38/225], Training Accuracy: 96.0526%, Training Loss: 0.1018%\n",
      "Epoch [76/300], Step [39/225], Training Accuracy: 96.0337%, Training Loss: 0.1032%\n",
      "Epoch [76/300], Step [40/225], Training Accuracy: 95.9766%, Training Loss: 0.1042%\n",
      "Epoch [76/300], Step [41/225], Training Accuracy: 95.9985%, Training Loss: 0.1050%\n",
      "Epoch [76/300], Step [42/225], Training Accuracy: 96.0565%, Training Loss: 0.1036%\n",
      "Epoch [76/300], Step [43/225], Training Accuracy: 96.0756%, Training Loss: 0.1032%\n",
      "Epoch [76/300], Step [44/225], Training Accuracy: 96.0938%, Training Loss: 0.1035%\n",
      "Epoch [76/300], Step [45/225], Training Accuracy: 96.1458%, Training Loss: 0.1023%\n",
      "Epoch [76/300], Step [46/225], Training Accuracy: 96.1957%, Training Loss: 0.1012%\n",
      "Epoch [76/300], Step [47/225], Training Accuracy: 96.1769%, Training Loss: 0.1031%\n",
      "Epoch [76/300], Step [48/225], Training Accuracy: 96.1914%, Training Loss: 0.1026%\n",
      "Epoch [76/300], Step [49/225], Training Accuracy: 96.2372%, Training Loss: 0.1019%\n",
      "Epoch [76/300], Step [50/225], Training Accuracy: 96.2500%, Training Loss: 0.1015%\n",
      "Epoch [76/300], Step [51/225], Training Accuracy: 96.2929%, Training Loss: 0.1004%\n",
      "Epoch [76/300], Step [52/225], Training Accuracy: 96.3341%, Training Loss: 0.0991%\n",
      "Epoch [76/300], Step [53/225], Training Accuracy: 96.3443%, Training Loss: 0.0992%\n",
      "Epoch [76/300], Step [54/225], Training Accuracy: 96.2674%, Training Loss: 0.1006%\n",
      "Epoch [76/300], Step [55/225], Training Accuracy: 96.2500%, Training Loss: 0.1003%\n",
      "Epoch [76/300], Step [56/225], Training Accuracy: 96.2612%, Training Loss: 0.0999%\n",
      "Epoch [76/300], Step [57/225], Training Accuracy: 96.2993%, Training Loss: 0.0991%\n",
      "Epoch [76/300], Step [58/225], Training Accuracy: 96.2823%, Training Loss: 0.0999%\n",
      "Epoch [76/300], Step [59/225], Training Accuracy: 96.2924%, Training Loss: 0.0995%\n",
      "Epoch [76/300], Step [60/225], Training Accuracy: 96.2500%, Training Loss: 0.1007%\n",
      "Epoch [76/300], Step [61/225], Training Accuracy: 96.2859%, Training Loss: 0.1009%\n",
      "Epoch [76/300], Step [62/225], Training Accuracy: 96.2450%, Training Loss: 0.1020%\n",
      "Epoch [76/300], Step [63/225], Training Accuracy: 96.2302%, Training Loss: 0.1026%\n",
      "Epoch [76/300], Step [64/225], Training Accuracy: 96.2402%, Training Loss: 0.1021%\n",
      "Epoch [76/300], Step [65/225], Training Accuracy: 96.2981%, Training Loss: 0.1008%\n",
      "Epoch [76/300], Step [66/225], Training Accuracy: 96.2358%, Training Loss: 0.1021%\n",
      "Epoch [76/300], Step [67/225], Training Accuracy: 96.2920%, Training Loss: 0.1012%\n",
      "Epoch [76/300], Step [68/225], Training Accuracy: 96.3006%, Training Loss: 0.1009%\n",
      "Epoch [76/300], Step [69/225], Training Accuracy: 96.3315%, Training Loss: 0.1005%\n",
      "Epoch [76/300], Step [70/225], Training Accuracy: 96.3616%, Training Loss: 0.0997%\n",
      "Epoch [76/300], Step [71/225], Training Accuracy: 96.3468%, Training Loss: 0.1003%\n",
      "Epoch [76/300], Step [72/225], Training Accuracy: 96.3759%, Training Loss: 0.0998%\n",
      "Epoch [76/300], Step [73/225], Training Accuracy: 96.3827%, Training Loss: 0.1001%\n",
      "Epoch [76/300], Step [74/225], Training Accuracy: 96.4105%, Training Loss: 0.0998%\n",
      "Epoch [76/300], Step [75/225], Training Accuracy: 96.4375%, Training Loss: 0.0993%\n",
      "Epoch [76/300], Step [76/225], Training Accuracy: 96.4227%, Training Loss: 0.0994%\n",
      "Epoch [76/300], Step [77/225], Training Accuracy: 96.3880%, Training Loss: 0.1008%\n",
      "Epoch [76/300], Step [78/225], Training Accuracy: 96.4343%, Training Loss: 0.1001%\n",
      "Epoch [76/300], Step [79/225], Training Accuracy: 96.4399%, Training Loss: 0.0997%\n",
      "Epoch [76/300], Step [80/225], Training Accuracy: 96.4648%, Training Loss: 0.0996%\n",
      "Epoch [76/300], Step [81/225], Training Accuracy: 96.4892%, Training Loss: 0.0993%\n",
      "Epoch [76/300], Step [82/225], Training Accuracy: 96.4367%, Training Loss: 0.0999%\n",
      "Epoch [76/300], Step [83/225], Training Accuracy: 96.4232%, Training Loss: 0.1001%\n",
      "Epoch [76/300], Step [84/225], Training Accuracy: 96.4100%, Training Loss: 0.0999%\n",
      "Epoch [76/300], Step [85/225], Training Accuracy: 96.4338%, Training Loss: 0.0993%\n",
      "Epoch [76/300], Step [86/225], Training Accuracy: 96.4571%, Training Loss: 0.0990%\n",
      "Epoch [76/300], Step [87/225], Training Accuracy: 96.4799%, Training Loss: 0.0989%\n",
      "Epoch [76/300], Step [88/225], Training Accuracy: 96.5021%, Training Loss: 0.0988%\n",
      "Epoch [76/300], Step [89/225], Training Accuracy: 96.5063%, Training Loss: 0.0985%\n",
      "Epoch [76/300], Step [90/225], Training Accuracy: 96.5451%, Training Loss: 0.0978%\n",
      "Epoch [76/300], Step [91/225], Training Accuracy: 96.5831%, Training Loss: 0.0970%\n",
      "Epoch [76/300], Step [92/225], Training Accuracy: 96.6033%, Training Loss: 0.0968%\n",
      "Epoch [76/300], Step [93/225], Training Accuracy: 96.6398%, Training Loss: 0.0963%\n",
      "Epoch [76/300], Step [94/225], Training Accuracy: 96.6589%, Training Loss: 0.0958%\n",
      "Epoch [76/300], Step [95/225], Training Accuracy: 96.6612%, Training Loss: 0.0961%\n",
      "Epoch [76/300], Step [96/225], Training Accuracy: 96.6634%, Training Loss: 0.0959%\n",
      "Epoch [76/300], Step [97/225], Training Accuracy: 96.6817%, Training Loss: 0.0955%\n",
      "Epoch [76/300], Step [98/225], Training Accuracy: 96.6677%, Training Loss: 0.0957%\n",
      "Epoch [76/300], Step [99/225], Training Accuracy: 96.6698%, Training Loss: 0.0958%\n",
      "Epoch [76/300], Step [100/225], Training Accuracy: 96.6719%, Training Loss: 0.0955%\n",
      "Epoch [76/300], Step [101/225], Training Accuracy: 96.6120%, Training Loss: 0.0962%\n",
      "Epoch [76/300], Step [102/225], Training Accuracy: 96.6146%, Training Loss: 0.0965%\n",
      "Epoch [76/300], Step [103/225], Training Accuracy: 96.6171%, Training Loss: 0.0969%\n",
      "Epoch [76/300], Step [104/225], Training Accuracy: 96.5595%, Training Loss: 0.0977%\n",
      "Epoch [76/300], Step [105/225], Training Accuracy: 96.5327%, Training Loss: 0.0980%\n",
      "Epoch [76/300], Step [106/225], Training Accuracy: 96.4917%, Training Loss: 0.0982%\n",
      "Epoch [76/300], Step [107/225], Training Accuracy: 96.5099%, Training Loss: 0.0979%\n",
      "Epoch [76/300], Step [108/225], Training Accuracy: 96.5133%, Training Loss: 0.0978%\n",
      "Epoch [76/300], Step [109/225], Training Accuracy: 96.5166%, Training Loss: 0.0976%\n",
      "Epoch [76/300], Step [110/225], Training Accuracy: 96.5057%, Training Loss: 0.0974%\n",
      "Epoch [76/300], Step [111/225], Training Accuracy: 96.4949%, Training Loss: 0.0973%\n",
      "Epoch [76/300], Step [112/225], Training Accuracy: 96.4844%, Training Loss: 0.0973%\n",
      "Epoch [76/300], Step [113/225], Training Accuracy: 96.5017%, Training Loss: 0.0971%\n",
      "Epoch [76/300], Step [114/225], Training Accuracy: 96.4638%, Training Loss: 0.0975%\n",
      "Epoch [76/300], Step [115/225], Training Accuracy: 96.4810%, Training Loss: 0.0973%\n",
      "Epoch [76/300], Step [116/225], Training Accuracy: 96.5113%, Training Loss: 0.0969%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/300], Step [117/225], Training Accuracy: 96.5278%, Training Loss: 0.0968%\n",
      "Epoch [76/300], Step [118/225], Training Accuracy: 96.5175%, Training Loss: 0.0979%\n",
      "Epoch [76/300], Step [119/225], Training Accuracy: 96.4942%, Training Loss: 0.0981%\n",
      "Epoch [76/300], Step [120/225], Training Accuracy: 96.4974%, Training Loss: 0.0979%\n",
      "Epoch [76/300], Step [121/225], Training Accuracy: 96.5005%, Training Loss: 0.0983%\n",
      "Epoch [76/300], Step [122/225], Training Accuracy: 96.5292%, Training Loss: 0.0978%\n",
      "Epoch [76/300], Step [123/225], Training Accuracy: 96.5320%, Training Loss: 0.0977%\n",
      "Epoch [76/300], Step [124/225], Training Accuracy: 96.5348%, Training Loss: 0.0973%\n",
      "Epoch [76/300], Step [125/225], Training Accuracy: 96.5125%, Training Loss: 0.0977%\n",
      "Epoch [76/300], Step [126/225], Training Accuracy: 96.5402%, Training Loss: 0.0972%\n",
      "Epoch [76/300], Step [127/225], Training Accuracy: 96.5428%, Training Loss: 0.0975%\n",
      "Epoch [76/300], Step [128/225], Training Accuracy: 96.5088%, Training Loss: 0.0980%\n",
      "Epoch [76/300], Step [129/225], Training Accuracy: 96.4995%, Training Loss: 0.0982%\n",
      "Epoch [76/300], Step [130/225], Training Accuracy: 96.4904%, Training Loss: 0.0983%\n",
      "Epoch [76/300], Step [131/225], Training Accuracy: 96.5052%, Training Loss: 0.0979%\n",
      "Epoch [76/300], Step [132/225], Training Accuracy: 96.5080%, Training Loss: 0.0976%\n",
      "Epoch [76/300], Step [133/225], Training Accuracy: 96.4991%, Training Loss: 0.0976%\n",
      "Epoch [76/300], Step [134/225], Training Accuracy: 96.4902%, Training Loss: 0.0976%\n",
      "Epoch [76/300], Step [135/225], Training Accuracy: 96.4931%, Training Loss: 0.0973%\n",
      "Epoch [76/300], Step [136/225], Training Accuracy: 96.4959%, Training Loss: 0.0976%\n",
      "Epoch [76/300], Step [137/225], Training Accuracy: 96.4986%, Training Loss: 0.0975%\n",
      "Epoch [76/300], Step [138/225], Training Accuracy: 96.5014%, Training Loss: 0.0972%\n",
      "Epoch [76/300], Step [139/225], Training Accuracy: 96.5265%, Training Loss: 0.0967%\n",
      "Epoch [76/300], Step [140/225], Training Accuracy: 96.5402%, Training Loss: 0.0966%\n",
      "Epoch [76/300], Step [141/225], Training Accuracy: 96.5315%, Training Loss: 0.0967%\n",
      "Epoch [76/300], Step [142/225], Training Accuracy: 96.5119%, Training Loss: 0.0973%\n",
      "Epoch [76/300], Step [143/225], Training Accuracy: 96.5144%, Training Loss: 0.0971%\n",
      "Epoch [76/300], Step [144/225], Training Accuracy: 96.5169%, Training Loss: 0.0969%\n",
      "Epoch [76/300], Step [145/225], Training Accuracy: 96.5086%, Training Loss: 0.0969%\n",
      "Epoch [76/300], Step [146/225], Training Accuracy: 96.5218%, Training Loss: 0.0965%\n",
      "Epoch [76/300], Step [147/225], Training Accuracy: 96.5136%, Training Loss: 0.0968%\n",
      "Epoch [76/300], Step [148/225], Training Accuracy: 96.5266%, Training Loss: 0.0966%\n",
      "Epoch [76/300], Step [149/225], Training Accuracy: 96.5289%, Training Loss: 0.0964%\n",
      "Epoch [76/300], Step [150/225], Training Accuracy: 96.5208%, Training Loss: 0.0963%\n",
      "Epoch [76/300], Step [151/225], Training Accuracy: 96.5025%, Training Loss: 0.0967%\n",
      "Epoch [76/300], Step [152/225], Training Accuracy: 96.5152%, Training Loss: 0.0967%\n",
      "Epoch [76/300], Step [153/225], Training Accuracy: 96.5176%, Training Loss: 0.0964%\n",
      "Epoch [76/300], Step [154/225], Training Accuracy: 96.5300%, Training Loss: 0.0964%\n",
      "Epoch [76/300], Step [155/225], Training Accuracy: 96.5323%, Training Loss: 0.0968%\n",
      "Epoch [76/300], Step [156/225], Training Accuracy: 96.5345%, Training Loss: 0.0967%\n",
      "Epoch [76/300], Step [157/225], Training Accuracy: 96.5167%, Training Loss: 0.0970%\n",
      "Epoch [76/300], Step [158/225], Training Accuracy: 96.4992%, Training Loss: 0.0974%\n",
      "Epoch [76/300], Step [159/225], Training Accuracy: 96.5016%, Training Loss: 0.0973%\n",
      "Epoch [76/300], Step [160/225], Training Accuracy: 96.5137%, Training Loss: 0.0970%\n",
      "Epoch [76/300], Step [161/225], Training Accuracy: 96.5159%, Training Loss: 0.0970%\n",
      "Epoch [76/300], Step [162/225], Training Accuracy: 96.4796%, Training Loss: 0.0976%\n",
      "Epoch [76/300], Step [163/225], Training Accuracy: 96.4820%, Training Loss: 0.0974%\n",
      "Epoch [76/300], Step [164/225], Training Accuracy: 96.4939%, Training Loss: 0.0974%\n",
      "Epoch [76/300], Step [165/225], Training Accuracy: 96.5057%, Training Loss: 0.0973%\n",
      "Epoch [76/300], Step [166/225], Training Accuracy: 96.4797%, Training Loss: 0.0981%\n",
      "Epoch [76/300], Step [167/225], Training Accuracy: 96.4820%, Training Loss: 0.0981%\n",
      "Epoch [76/300], Step [168/225], Training Accuracy: 96.4844%, Training Loss: 0.0982%\n",
      "Epoch [76/300], Step [169/225], Training Accuracy: 96.4774%, Training Loss: 0.0982%\n",
      "Epoch [76/300], Step [170/225], Training Accuracy: 96.4706%, Training Loss: 0.0981%\n",
      "Epoch [76/300], Step [171/225], Training Accuracy: 96.4730%, Training Loss: 0.0979%\n",
      "Epoch [76/300], Step [172/225], Training Accuracy: 96.4753%, Training Loss: 0.0979%\n",
      "Epoch [76/300], Step [173/225], Training Accuracy: 96.4866%, Training Loss: 0.0979%\n",
      "Epoch [76/300], Step [174/225], Training Accuracy: 96.4978%, Training Loss: 0.0977%\n",
      "Epoch [76/300], Step [175/225], Training Accuracy: 96.5000%, Training Loss: 0.0976%\n",
      "Epoch [76/300], Step [176/225], Training Accuracy: 96.5021%, Training Loss: 0.0974%\n",
      "Epoch [76/300], Step [177/225], Training Accuracy: 96.5219%, Training Loss: 0.0972%\n",
      "Epoch [76/300], Step [178/225], Training Accuracy: 96.5151%, Training Loss: 0.0973%\n",
      "Epoch [76/300], Step [179/225], Training Accuracy: 96.5084%, Training Loss: 0.0975%\n",
      "Epoch [76/300], Step [180/225], Training Accuracy: 96.5017%, Training Loss: 0.0975%\n",
      "Epoch [76/300], Step [181/225], Training Accuracy: 96.5124%, Training Loss: 0.0973%\n",
      "Epoch [76/300], Step [182/225], Training Accuracy: 96.5144%, Training Loss: 0.0971%\n",
      "Epoch [76/300], Step [183/225], Training Accuracy: 96.5249%, Training Loss: 0.0969%\n",
      "Epoch [76/300], Step [184/225], Training Accuracy: 96.5183%, Training Loss: 0.0969%\n",
      "Epoch [76/300], Step [185/225], Training Accuracy: 96.5287%, Training Loss: 0.0968%\n",
      "Epoch [76/300], Step [186/225], Training Accuracy: 96.5390%, Training Loss: 0.0967%\n",
      "Epoch [76/300], Step [187/225], Training Accuracy: 96.5491%, Training Loss: 0.0963%\n",
      "Epoch [76/300], Step [188/225], Training Accuracy: 96.5592%, Training Loss: 0.0961%\n",
      "Epoch [76/300], Step [189/225], Training Accuracy: 96.5608%, Training Loss: 0.0959%\n",
      "Epoch [76/300], Step [190/225], Training Accuracy: 96.5707%, Training Loss: 0.0958%\n",
      "Epoch [76/300], Step [191/225], Training Accuracy: 96.5723%, Training Loss: 0.0958%\n",
      "Epoch [76/300], Step [192/225], Training Accuracy: 96.5820%, Training Loss: 0.0958%\n",
      "Epoch [76/300], Step [193/225], Training Accuracy: 96.5674%, Training Loss: 0.0959%\n",
      "Epoch [76/300], Step [194/225], Training Accuracy: 96.5851%, Training Loss: 0.0956%\n",
      "Epoch [76/300], Step [195/225], Training Accuracy: 96.5946%, Training Loss: 0.0953%\n",
      "Epoch [76/300], Step [196/225], Training Accuracy: 96.5960%, Training Loss: 0.0953%\n",
      "Epoch [76/300], Step [197/225], Training Accuracy: 96.5895%, Training Loss: 0.0953%\n",
      "Epoch [76/300], Step [198/225], Training Accuracy: 96.5830%, Training Loss: 0.0954%\n",
      "Epoch [76/300], Step [199/225], Training Accuracy: 96.5845%, Training Loss: 0.0954%\n",
      "Epoch [76/300], Step [200/225], Training Accuracy: 96.5938%, Training Loss: 0.0952%\n",
      "Epoch [76/300], Step [201/225], Training Accuracy: 96.6029%, Training Loss: 0.0952%\n",
      "Epoch [76/300], Step [202/225], Training Accuracy: 96.6120%, Training Loss: 0.0950%\n",
      "Epoch [76/300], Step [203/225], Training Accuracy: 96.6210%, Training Loss: 0.0948%\n",
      "Epoch [76/300], Step [204/225], Training Accuracy: 96.6069%, Training Loss: 0.0951%\n",
      "Epoch [76/300], Step [205/225], Training Accuracy: 96.6159%, Training Loss: 0.0949%\n",
      "Epoch [76/300], Step [206/225], Training Accuracy: 96.6171%, Training Loss: 0.0949%\n",
      "Epoch [76/300], Step [207/225], Training Accuracy: 96.6184%, Training Loss: 0.0949%\n",
      "Epoch [76/300], Step [208/225], Training Accuracy: 96.6121%, Training Loss: 0.0949%\n",
      "Epoch [76/300], Step [209/225], Training Accuracy: 96.6208%, Training Loss: 0.0948%\n",
      "Epoch [76/300], Step [210/225], Training Accuracy: 96.6220%, Training Loss: 0.0948%\n",
      "Epoch [76/300], Step [211/225], Training Accuracy: 96.6084%, Training Loss: 0.0953%\n",
      "Epoch [76/300], Step [212/225], Training Accuracy: 96.6244%, Training Loss: 0.0950%\n",
      "Epoch [76/300], Step [213/225], Training Accuracy: 96.6403%, Training Loss: 0.0947%\n",
      "Epoch [76/300], Step [214/225], Training Accuracy: 96.6560%, Training Loss: 0.0945%\n",
      "Epoch [76/300], Step [215/225], Training Accuracy: 96.6715%, Training Loss: 0.0942%\n",
      "Epoch [76/300], Step [216/225], Training Accuracy: 96.6725%, Training Loss: 0.0944%\n",
      "Epoch [76/300], Step [217/225], Training Accuracy: 96.6734%, Training Loss: 0.0943%\n",
      "Epoch [76/300], Step [218/225], Training Accuracy: 96.6815%, Training Loss: 0.0941%\n",
      "Epoch [76/300], Step [219/225], Training Accuracy: 96.6824%, Training Loss: 0.0940%\n",
      "Epoch [76/300], Step [220/225], Training Accuracy: 96.6903%, Training Loss: 0.0938%\n",
      "Epoch [76/300], Step [221/225], Training Accuracy: 96.6841%, Training Loss: 0.0938%\n",
      "Epoch [76/300], Step [222/225], Training Accuracy: 96.6990%, Training Loss: 0.0936%\n",
      "Epoch [76/300], Step [223/225], Training Accuracy: 96.7068%, Training Loss: 0.0936%\n",
      "Epoch [76/300], Step [224/225], Training Accuracy: 96.7006%, Training Loss: 0.0937%\n",
      "Epoch [76/300], Step [225/225], Training Accuracy: 96.7065%, Training Loss: 0.0937%\n",
      "Epoch [77/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0441%\n",
      "Epoch [77/300], Step [2/225], Training Accuracy: 97.6562%, Training Loss: 0.0835%\n",
      "Epoch [77/300], Step [3/225], Training Accuracy: 97.9167%, Training Loss: 0.0864%\n",
      "Epoch [77/300], Step [4/225], Training Accuracy: 98.4375%, Training Loss: 0.0758%\n",
      "Epoch [77/300], Step [5/225], Training Accuracy: 98.4375%, Training Loss: 0.0806%\n",
      "Epoch [77/300], Step [6/225], Training Accuracy: 98.4375%, Training Loss: 0.0882%\n",
      "Epoch [77/300], Step [7/225], Training Accuracy: 98.2143%, Training Loss: 0.0908%\n",
      "Epoch [77/300], Step [8/225], Training Accuracy: 97.8516%, Training Loss: 0.0933%\n",
      "Epoch [77/300], Step [9/225], Training Accuracy: 97.7431%, Training Loss: 0.0896%\n",
      "Epoch [77/300], Step [10/225], Training Accuracy: 97.6562%, Training Loss: 0.0893%\n",
      "Epoch [77/300], Step [11/225], Training Accuracy: 97.4432%, Training Loss: 0.0901%\n",
      "Epoch [77/300], Step [12/225], Training Accuracy: 97.5260%, Training Loss: 0.0875%\n",
      "Epoch [77/300], Step [13/225], Training Accuracy: 97.3558%, Training Loss: 0.0909%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/300], Step [14/225], Training Accuracy: 97.4330%, Training Loss: 0.0887%\n",
      "Epoch [77/300], Step [15/225], Training Accuracy: 97.6042%, Training Loss: 0.0860%\n",
      "Epoch [77/300], Step [16/225], Training Accuracy: 97.6562%, Training Loss: 0.0835%\n",
      "Epoch [77/300], Step [17/225], Training Accuracy: 97.4265%, Training Loss: 0.0862%\n",
      "Epoch [77/300], Step [18/225], Training Accuracy: 97.3090%, Training Loss: 0.0870%\n",
      "Epoch [77/300], Step [19/225], Training Accuracy: 97.2862%, Training Loss: 0.0858%\n",
      "Epoch [77/300], Step [20/225], Training Accuracy: 97.3438%, Training Loss: 0.0848%\n",
      "Epoch [77/300], Step [21/225], Training Accuracy: 97.3958%, Training Loss: 0.0841%\n",
      "Epoch [77/300], Step [22/225], Training Accuracy: 97.2301%, Training Loss: 0.0863%\n",
      "Epoch [77/300], Step [23/225], Training Accuracy: 97.0788%, Training Loss: 0.0871%\n",
      "Epoch [77/300], Step [24/225], Training Accuracy: 97.0703%, Training Loss: 0.0887%\n",
      "Epoch [77/300], Step [25/225], Training Accuracy: 97.1250%, Training Loss: 0.0867%\n",
      "Epoch [77/300], Step [26/225], Training Accuracy: 97.1154%, Training Loss: 0.0855%\n",
      "Epoch [77/300], Step [27/225], Training Accuracy: 96.9907%, Training Loss: 0.0882%\n",
      "Epoch [77/300], Step [28/225], Training Accuracy: 96.9866%, Training Loss: 0.0891%\n",
      "Epoch [77/300], Step [29/225], Training Accuracy: 97.0366%, Training Loss: 0.0880%\n",
      "Epoch [77/300], Step [30/225], Training Accuracy: 96.9271%, Training Loss: 0.0890%\n",
      "Epoch [77/300], Step [31/225], Training Accuracy: 96.9254%, Training Loss: 0.0914%\n",
      "Epoch [77/300], Step [32/225], Training Accuracy: 96.9238%, Training Loss: 0.0917%\n",
      "Epoch [77/300], Step [33/225], Training Accuracy: 96.9697%, Training Loss: 0.0914%\n",
      "Epoch [77/300], Step [34/225], Training Accuracy: 96.8750%, Training Loss: 0.0923%\n",
      "Epoch [77/300], Step [35/225], Training Accuracy: 96.8304%, Training Loss: 0.0938%\n",
      "Epoch [77/300], Step [36/225], Training Accuracy: 96.8316%, Training Loss: 0.0933%\n",
      "Epoch [77/300], Step [37/225], Training Accuracy: 96.8750%, Training Loss: 0.0922%\n",
      "Epoch [77/300], Step [38/225], Training Accuracy: 96.7928%, Training Loss: 0.0937%\n",
      "Epoch [77/300], Step [39/225], Training Accuracy: 96.7548%, Training Loss: 0.0938%\n",
      "Epoch [77/300], Step [40/225], Training Accuracy: 96.7969%, Training Loss: 0.0928%\n",
      "Epoch [77/300], Step [41/225], Training Accuracy: 96.7988%, Training Loss: 0.0928%\n",
      "Epoch [77/300], Step [42/225], Training Accuracy: 96.7634%, Training Loss: 0.0923%\n",
      "Epoch [77/300], Step [43/225], Training Accuracy: 96.7660%, Training Loss: 0.0927%\n",
      "Epoch [77/300], Step [44/225], Training Accuracy: 96.7685%, Training Loss: 0.0935%\n",
      "Epoch [77/300], Step [45/225], Training Accuracy: 96.8056%, Training Loss: 0.0928%\n",
      "Epoch [77/300], Step [46/225], Training Accuracy: 96.8410%, Training Loss: 0.0914%\n",
      "Epoch [77/300], Step [47/225], Training Accuracy: 96.8418%, Training Loss: 0.0906%\n",
      "Epoch [77/300], Step [48/225], Training Accuracy: 96.8099%, Training Loss: 0.0908%\n",
      "Epoch [77/300], Step [49/225], Training Accuracy: 96.8112%, Training Loss: 0.0917%\n",
      "Epoch [77/300], Step [50/225], Training Accuracy: 96.7500%, Training Loss: 0.0919%\n",
      "Epoch [77/300], Step [51/225], Training Accuracy: 96.7831%, Training Loss: 0.0910%\n",
      "Epoch [77/300], Step [52/225], Training Accuracy: 96.8450%, Training Loss: 0.0896%\n",
      "Epoch [77/300], Step [53/225], Training Accuracy: 96.8750%, Training Loss: 0.0893%\n",
      "Epoch [77/300], Step [54/225], Training Accuracy: 96.8461%, Training Loss: 0.0892%\n",
      "Epoch [77/300], Step [55/225], Training Accuracy: 96.8750%, Training Loss: 0.0899%\n",
      "Epoch [77/300], Step [56/225], Training Accuracy: 96.9029%, Training Loss: 0.0896%\n",
      "Epoch [77/300], Step [57/225], Training Accuracy: 96.9298%, Training Loss: 0.0892%\n",
      "Epoch [77/300], Step [58/225], Training Accuracy: 96.9558%, Training Loss: 0.0887%\n",
      "Epoch [77/300], Step [59/225], Training Accuracy: 96.9544%, Training Loss: 0.0889%\n",
      "Epoch [77/300], Step [60/225], Training Accuracy: 96.9271%, Training Loss: 0.0893%\n",
      "Epoch [77/300], Step [61/225], Training Accuracy: 96.8750%, Training Loss: 0.0896%\n",
      "Epoch [77/300], Step [62/225], Training Accuracy: 96.8750%, Training Loss: 0.0901%\n",
      "Epoch [77/300], Step [63/225], Training Accuracy: 96.8750%, Training Loss: 0.0904%\n",
      "Epoch [77/300], Step [64/225], Training Accuracy: 96.8750%, Training Loss: 0.0898%\n",
      "Epoch [77/300], Step [65/225], Training Accuracy: 96.8990%, Training Loss: 0.0898%\n",
      "Epoch [77/300], Step [66/225], Training Accuracy: 96.9223%, Training Loss: 0.0897%\n",
      "Epoch [77/300], Step [67/225], Training Accuracy: 96.9450%, Training Loss: 0.0896%\n",
      "Epoch [77/300], Step [68/225], Training Accuracy: 96.8520%, Training Loss: 0.0911%\n",
      "Epoch [77/300], Step [69/225], Training Accuracy: 96.8976%, Training Loss: 0.0902%\n",
      "Epoch [77/300], Step [70/225], Training Accuracy: 96.8973%, Training Loss: 0.0905%\n",
      "Epoch [77/300], Step [71/225], Training Accuracy: 96.9190%, Training Loss: 0.0903%\n",
      "Epoch [77/300], Step [72/225], Training Accuracy: 96.9184%, Training Loss: 0.0903%\n",
      "Epoch [77/300], Step [73/225], Training Accuracy: 96.9178%, Training Loss: 0.0901%\n",
      "Epoch [77/300], Step [74/225], Training Accuracy: 96.8328%, Training Loss: 0.0907%\n",
      "Epoch [77/300], Step [75/225], Training Accuracy: 96.8750%, Training Loss: 0.0900%\n",
      "Epoch [77/300], Step [76/225], Training Accuracy: 96.8544%, Training Loss: 0.0904%\n",
      "Epoch [77/300], Step [77/225], Training Accuracy: 96.8141%, Training Loss: 0.0915%\n",
      "Epoch [77/300], Step [78/225], Training Accuracy: 96.7949%, Training Loss: 0.0923%\n",
      "Epoch [77/300], Step [79/225], Training Accuracy: 96.7563%, Training Loss: 0.0929%\n",
      "Epoch [77/300], Step [80/225], Training Accuracy: 96.6797%, Training Loss: 0.0941%\n",
      "Epoch [77/300], Step [81/225], Training Accuracy: 96.7014%, Training Loss: 0.0940%\n",
      "Epoch [77/300], Step [82/225], Training Accuracy: 96.7035%, Training Loss: 0.0936%\n",
      "Epoch [77/300], Step [83/225], Training Accuracy: 96.7056%, Training Loss: 0.0935%\n",
      "Epoch [77/300], Step [84/225], Training Accuracy: 96.6890%, Training Loss: 0.0938%\n",
      "Epoch [77/300], Step [85/225], Training Accuracy: 96.6912%, Training Loss: 0.0935%\n",
      "Epoch [77/300], Step [86/225], Training Accuracy: 96.7115%, Training Loss: 0.0932%\n",
      "Epoch [77/300], Step [87/225], Training Accuracy: 96.6954%, Training Loss: 0.0937%\n",
      "Epoch [77/300], Step [88/225], Training Accuracy: 96.6619%, Training Loss: 0.0940%\n",
      "Epoch [77/300], Step [89/225], Training Accuracy: 96.6819%, Training Loss: 0.0938%\n",
      "Epoch [77/300], Step [90/225], Training Accuracy: 96.7188%, Training Loss: 0.0934%\n",
      "Epoch [77/300], Step [91/225], Training Accuracy: 96.6861%, Training Loss: 0.0937%\n",
      "Epoch [77/300], Step [92/225], Training Accuracy: 96.6882%, Training Loss: 0.0934%\n",
      "Epoch [77/300], Step [93/225], Training Accuracy: 96.6734%, Training Loss: 0.0933%\n",
      "Epoch [77/300], Step [94/225], Training Accuracy: 96.6423%, Training Loss: 0.0933%\n",
      "Epoch [77/300], Step [95/225], Training Accuracy: 96.6612%, Training Loss: 0.0940%\n",
      "Epoch [77/300], Step [96/225], Training Accuracy: 96.6797%, Training Loss: 0.0936%\n",
      "Epoch [77/300], Step [97/225], Training Accuracy: 96.6978%, Training Loss: 0.0935%\n",
      "Epoch [77/300], Step [98/225], Training Accuracy: 96.6677%, Training Loss: 0.0940%\n",
      "Epoch [77/300], Step [99/225], Training Accuracy: 96.6698%, Training Loss: 0.0938%\n",
      "Epoch [77/300], Step [100/225], Training Accuracy: 96.7031%, Training Loss: 0.0934%\n",
      "Epoch [77/300], Step [101/225], Training Accuracy: 96.7203%, Training Loss: 0.0931%\n",
      "Epoch [77/300], Step [102/225], Training Accuracy: 96.7218%, Training Loss: 0.0927%\n",
      "Epoch [77/300], Step [103/225], Training Accuracy: 96.7081%, Training Loss: 0.0929%\n",
      "Epoch [77/300], Step [104/225], Training Accuracy: 96.7097%, Training Loss: 0.0928%\n",
      "Epoch [77/300], Step [105/225], Training Accuracy: 96.7262%, Training Loss: 0.0927%\n",
      "Epoch [77/300], Step [106/225], Training Accuracy: 96.7129%, Training Loss: 0.0930%\n",
      "Epoch [77/300], Step [107/225], Training Accuracy: 96.7144%, Training Loss: 0.0933%\n",
      "Epoch [77/300], Step [108/225], Training Accuracy: 96.7303%, Training Loss: 0.0936%\n",
      "Epoch [77/300], Step [109/225], Training Accuracy: 96.7317%, Training Loss: 0.0936%\n",
      "Epoch [77/300], Step [110/225], Training Accuracy: 96.7188%, Training Loss: 0.0934%\n",
      "Epoch [77/300], Step [111/225], Training Accuracy: 96.7483%, Training Loss: 0.0930%\n",
      "Epoch [77/300], Step [112/225], Training Accuracy: 96.7773%, Training Loss: 0.0924%\n",
      "Epoch [77/300], Step [113/225], Training Accuracy: 96.8059%, Training Loss: 0.0918%\n",
      "Epoch [77/300], Step [114/225], Training Accuracy: 96.8065%, Training Loss: 0.0922%\n",
      "Epoch [77/300], Step [115/225], Training Accuracy: 96.8071%, Training Loss: 0.0923%\n",
      "Epoch [77/300], Step [116/225], Training Accuracy: 96.8077%, Training Loss: 0.0924%\n",
      "Epoch [77/300], Step [117/225], Training Accuracy: 96.8082%, Training Loss: 0.0923%\n",
      "Epoch [77/300], Step [118/225], Training Accuracy: 96.7956%, Training Loss: 0.0924%\n",
      "Epoch [77/300], Step [119/225], Training Accuracy: 96.7437%, Training Loss: 0.0929%\n",
      "Epoch [77/300], Step [120/225], Training Accuracy: 96.7708%, Training Loss: 0.0924%\n",
      "Epoch [77/300], Step [121/225], Training Accuracy: 96.7975%, Training Loss: 0.0921%\n",
      "Epoch [77/300], Step [122/225], Training Accuracy: 96.8110%, Training Loss: 0.0917%\n",
      "Epoch [77/300], Step [123/225], Training Accuracy: 96.8115%, Training Loss: 0.0917%\n",
      "Epoch [77/300], Step [124/225], Training Accuracy: 96.7994%, Training Loss: 0.0918%\n",
      "Epoch [77/300], Step [125/225], Training Accuracy: 96.7875%, Training Loss: 0.0918%\n",
      "Epoch [77/300], Step [126/225], Training Accuracy: 96.8006%, Training Loss: 0.0916%\n",
      "Epoch [77/300], Step [127/225], Training Accuracy: 96.7889%, Training Loss: 0.0917%\n",
      "Epoch [77/300], Step [128/225], Training Accuracy: 96.7896%, Training Loss: 0.0916%\n",
      "Epoch [77/300], Step [129/225], Training Accuracy: 96.7539%, Training Loss: 0.0920%\n",
      "Epoch [77/300], Step [130/225], Training Accuracy: 96.7308%, Training Loss: 0.0925%\n",
      "Epoch [77/300], Step [131/225], Training Accuracy: 96.7438%, Training Loss: 0.0921%\n",
      "Epoch [77/300], Step [132/225], Training Accuracy: 96.7330%, Training Loss: 0.0923%\n",
      "Epoch [77/300], Step [133/225], Training Accuracy: 96.7575%, Training Loss: 0.0921%\n",
      "Epoch [77/300], Step [134/225], Training Accuracy: 96.7584%, Training Loss: 0.0922%\n",
      "Epoch [77/300], Step [135/225], Training Accuracy: 96.7477%, Training Loss: 0.0923%\n",
      "Epoch [77/300], Step [136/225], Training Accuracy: 96.7371%, Training Loss: 0.0924%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/300], Step [137/225], Training Accuracy: 96.7267%, Training Loss: 0.0926%\n",
      "Epoch [77/300], Step [138/225], Training Accuracy: 96.7165%, Training Loss: 0.0931%\n",
      "Epoch [77/300], Step [139/225], Training Accuracy: 96.7176%, Training Loss: 0.0930%\n",
      "Epoch [77/300], Step [140/225], Training Accuracy: 96.6964%, Training Loss: 0.0932%\n",
      "Epoch [77/300], Step [141/225], Training Accuracy: 96.6977%, Training Loss: 0.0932%\n",
      "Epoch [77/300], Step [142/225], Training Accuracy: 96.6769%, Training Loss: 0.0936%\n",
      "Epoch [77/300], Step [143/225], Training Accuracy: 96.6565%, Training Loss: 0.0941%\n",
      "Epoch [77/300], Step [144/225], Training Accuracy: 96.6471%, Training Loss: 0.0943%\n",
      "Epoch [77/300], Step [145/225], Training Accuracy: 96.6595%, Training Loss: 0.0940%\n",
      "Epoch [77/300], Step [146/225], Training Accuracy: 96.6610%, Training Loss: 0.0938%\n",
      "Epoch [77/300], Step [147/225], Training Accuracy: 96.6199%, Training Loss: 0.0946%\n",
      "Epoch [77/300], Step [148/225], Training Accuracy: 96.6322%, Training Loss: 0.0945%\n",
      "Epoch [77/300], Step [149/225], Training Accuracy: 96.6023%, Training Loss: 0.0952%\n",
      "Epoch [77/300], Step [150/225], Training Accuracy: 96.6146%, Training Loss: 0.0950%\n",
      "Epoch [77/300], Step [151/225], Training Accuracy: 96.6370%, Training Loss: 0.0946%\n",
      "Epoch [77/300], Step [152/225], Training Accuracy: 96.6488%, Training Loss: 0.0944%\n",
      "Epoch [77/300], Step [153/225], Training Accuracy: 96.6605%, Training Loss: 0.0943%\n",
      "Epoch [77/300], Step [154/225], Training Accuracy: 96.6619%, Training Loss: 0.0943%\n",
      "Epoch [77/300], Step [155/225], Training Accuracy: 96.6734%, Training Loss: 0.0941%\n",
      "Epoch [77/300], Step [156/225], Training Accuracy: 96.6947%, Training Loss: 0.0936%\n",
      "Epoch [77/300], Step [157/225], Training Accuracy: 96.6959%, Training Loss: 0.0935%\n",
      "Epoch [77/300], Step [158/225], Training Accuracy: 96.7168%, Training Loss: 0.0930%\n",
      "Epoch [77/300], Step [159/225], Training Accuracy: 96.7374%, Training Loss: 0.0928%\n",
      "Epoch [77/300], Step [160/225], Training Accuracy: 96.7188%, Training Loss: 0.0928%\n",
      "Epoch [77/300], Step [161/225], Training Accuracy: 96.7100%, Training Loss: 0.0931%\n",
      "Epoch [77/300], Step [162/225], Training Accuracy: 96.7014%, Training Loss: 0.0931%\n",
      "Epoch [77/300], Step [163/225], Training Accuracy: 96.6929%, Training Loss: 0.0932%\n",
      "Epoch [77/300], Step [164/225], Training Accuracy: 96.6845%, Training Loss: 0.0933%\n",
      "Epoch [77/300], Step [165/225], Training Accuracy: 96.6856%, Training Loss: 0.0931%\n",
      "Epoch [77/300], Step [166/225], Training Accuracy: 96.6773%, Training Loss: 0.0932%\n",
      "Epoch [77/300], Step [167/225], Training Accuracy: 96.6692%, Training Loss: 0.0937%\n",
      "Epoch [77/300], Step [168/225], Training Accuracy: 96.6704%, Training Loss: 0.0935%\n",
      "Epoch [77/300], Step [169/225], Training Accuracy: 96.6624%, Training Loss: 0.0936%\n",
      "Epoch [77/300], Step [170/225], Training Accuracy: 96.6728%, Training Loss: 0.0936%\n",
      "Epoch [77/300], Step [171/225], Training Accuracy: 96.6831%, Training Loss: 0.0938%\n",
      "Epoch [77/300], Step [172/225], Training Accuracy: 96.6933%, Training Loss: 0.0936%\n",
      "Epoch [77/300], Step [173/225], Training Accuracy: 96.6944%, Training Loss: 0.0935%\n",
      "Epoch [77/300], Step [174/225], Training Accuracy: 96.7044%, Training Loss: 0.0932%\n",
      "Epoch [77/300], Step [175/225], Training Accuracy: 96.6964%, Training Loss: 0.0935%\n",
      "Epoch [77/300], Step [176/225], Training Accuracy: 96.7152%, Training Loss: 0.0932%\n",
      "Epoch [77/300], Step [177/225], Training Accuracy: 96.7338%, Training Loss: 0.0929%\n",
      "Epoch [77/300], Step [178/225], Training Accuracy: 96.7082%, Training Loss: 0.0933%\n",
      "Epoch [77/300], Step [179/225], Training Accuracy: 96.7179%, Training Loss: 0.0931%\n",
      "Epoch [77/300], Step [180/225], Training Accuracy: 96.7101%, Training Loss: 0.0931%\n",
      "Epoch [77/300], Step [181/225], Training Accuracy: 96.7023%, Training Loss: 0.0933%\n",
      "Epoch [77/300], Step [182/225], Training Accuracy: 96.7119%, Training Loss: 0.0930%\n",
      "Epoch [77/300], Step [183/225], Training Accuracy: 96.7128%, Training Loss: 0.0930%\n",
      "Epoch [77/300], Step [184/225], Training Accuracy: 96.6967%, Training Loss: 0.0935%\n",
      "Epoch [77/300], Step [185/225], Training Accuracy: 96.6976%, Training Loss: 0.0936%\n",
      "Epoch [77/300], Step [186/225], Training Accuracy: 96.7070%, Training Loss: 0.0936%\n",
      "Epoch [77/300], Step [187/225], Training Accuracy: 96.6995%, Training Loss: 0.0937%\n",
      "Epoch [77/300], Step [188/225], Training Accuracy: 96.7005%, Training Loss: 0.0937%\n",
      "Epoch [77/300], Step [189/225], Training Accuracy: 96.7014%, Training Loss: 0.0937%\n",
      "Epoch [77/300], Step [190/225], Training Accuracy: 96.6941%, Training Loss: 0.0941%\n",
      "Epoch [77/300], Step [191/225], Training Accuracy: 96.6705%, Training Loss: 0.0945%\n",
      "Epoch [77/300], Step [192/225], Training Accuracy: 96.6797%, Training Loss: 0.0944%\n",
      "Epoch [77/300], Step [193/225], Training Accuracy: 96.6807%, Training Loss: 0.0945%\n",
      "Epoch [77/300], Step [194/225], Training Accuracy: 96.6978%, Training Loss: 0.0942%\n",
      "Epoch [77/300], Step [195/225], Training Accuracy: 96.6667%, Training Loss: 0.0946%\n",
      "Epoch [77/300], Step [196/225], Training Accuracy: 96.6677%, Training Loss: 0.0945%\n",
      "Epoch [77/300], Step [197/225], Training Accuracy: 96.6609%, Training Loss: 0.0945%\n",
      "Epoch [77/300], Step [198/225], Training Accuracy: 96.6777%, Training Loss: 0.0943%\n",
      "Epoch [77/300], Step [199/225], Training Accuracy: 96.6552%, Training Loss: 0.0947%\n",
      "Epoch [77/300], Step [200/225], Training Accuracy: 96.6641%, Training Loss: 0.0946%\n",
      "Epoch [77/300], Step [201/225], Training Accuracy: 96.6651%, Training Loss: 0.0946%\n",
      "Epoch [77/300], Step [202/225], Training Accuracy: 96.6507%, Training Loss: 0.0952%\n",
      "Epoch [77/300], Step [203/225], Training Accuracy: 96.6595%, Training Loss: 0.0951%\n",
      "Epoch [77/300], Step [204/225], Training Accuracy: 96.6452%, Training Loss: 0.0955%\n",
      "Epoch [77/300], Step [205/225], Training Accuracy: 96.6540%, Training Loss: 0.0952%\n",
      "Epoch [77/300], Step [206/225], Training Accuracy: 96.6475%, Training Loss: 0.0951%\n",
      "Epoch [77/300], Step [207/225], Training Accuracy: 96.6486%, Training Loss: 0.0950%\n",
      "Epoch [77/300], Step [208/225], Training Accuracy: 96.6496%, Training Loss: 0.0949%\n",
      "Epoch [77/300], Step [209/225], Training Accuracy: 96.6432%, Training Loss: 0.0948%\n",
      "Epoch [77/300], Step [210/225], Training Accuracy: 96.6443%, Training Loss: 0.0947%\n",
      "Epoch [77/300], Step [211/225], Training Accuracy: 96.6306%, Training Loss: 0.0948%\n",
      "Epoch [77/300], Step [212/225], Training Accuracy: 96.6244%, Training Loss: 0.0949%\n",
      "Epoch [77/300], Step [213/225], Training Accuracy: 96.6329%, Training Loss: 0.0948%\n",
      "Epoch [77/300], Step [214/225], Training Accuracy: 96.6195%, Training Loss: 0.0949%\n",
      "Epoch [77/300], Step [215/225], Training Accuracy: 96.6134%, Training Loss: 0.0949%\n",
      "Epoch [77/300], Step [216/225], Training Accuracy: 96.6146%, Training Loss: 0.0951%\n",
      "Epoch [77/300], Step [217/225], Training Accuracy: 96.6158%, Training Loss: 0.0951%\n",
      "Epoch [77/300], Step [218/225], Training Accuracy: 96.6170%, Training Loss: 0.0954%\n",
      "Epoch [77/300], Step [219/225], Training Accuracy: 96.6182%, Training Loss: 0.0954%\n",
      "Epoch [77/300], Step [220/225], Training Accuracy: 96.6335%, Training Loss: 0.0952%\n",
      "Epoch [77/300], Step [221/225], Training Accuracy: 96.6417%, Training Loss: 0.0951%\n",
      "Epoch [77/300], Step [222/225], Training Accuracy: 96.6357%, Training Loss: 0.0953%\n",
      "Epoch [77/300], Step [223/225], Training Accuracy: 96.6438%, Training Loss: 0.0951%\n",
      "Epoch [77/300], Step [224/225], Training Accuracy: 96.6518%, Training Loss: 0.0950%\n",
      "Epoch [77/300], Step [225/225], Training Accuracy: 96.6301%, Training Loss: 0.0952%\n",
      "Epoch [78/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0538%\n",
      "Epoch [78/300], Step [2/225], Training Accuracy: 100.0000%, Training Loss: 0.0500%\n",
      "Epoch [78/300], Step [3/225], Training Accuracy: 98.9583%, Training Loss: 0.0757%\n",
      "Epoch [78/300], Step [4/225], Training Accuracy: 97.6562%, Training Loss: 0.0860%\n",
      "Epoch [78/300], Step [5/225], Training Accuracy: 96.8750%, Training Loss: 0.0914%\n",
      "Epoch [78/300], Step [6/225], Training Accuracy: 96.3542%, Training Loss: 0.0949%\n",
      "Epoch [78/300], Step [7/225], Training Accuracy: 95.7589%, Training Loss: 0.1029%\n",
      "Epoch [78/300], Step [8/225], Training Accuracy: 96.0938%, Training Loss: 0.1015%\n",
      "Epoch [78/300], Step [9/225], Training Accuracy: 96.5278%, Training Loss: 0.0987%\n",
      "Epoch [78/300], Step [10/225], Training Accuracy: 96.4062%, Training Loss: 0.1108%\n",
      "Epoch [78/300], Step [11/225], Training Accuracy: 96.4489%, Training Loss: 0.1055%\n",
      "Epoch [78/300], Step [12/225], Training Accuracy: 96.7448%, Training Loss: 0.1000%\n",
      "Epoch [78/300], Step [13/225], Training Accuracy: 96.5144%, Training Loss: 0.1023%\n",
      "Epoch [78/300], Step [14/225], Training Accuracy: 96.4286%, Training Loss: 0.1073%\n",
      "Epoch [78/300], Step [15/225], Training Accuracy: 96.5625%, Training Loss: 0.1076%\n",
      "Epoch [78/300], Step [16/225], Training Accuracy: 96.6797%, Training Loss: 0.1061%\n",
      "Epoch [78/300], Step [17/225], Training Accuracy: 96.7831%, Training Loss: 0.1027%\n",
      "Epoch [78/300], Step [18/225], Training Accuracy: 96.3542%, Training Loss: 0.1112%\n",
      "Epoch [78/300], Step [19/225], Training Accuracy: 96.4638%, Training Loss: 0.1074%\n",
      "Epoch [78/300], Step [20/225], Training Accuracy: 96.6406%, Training Loss: 0.1036%\n",
      "Epoch [78/300], Step [21/225], Training Accuracy: 96.7262%, Training Loss: 0.1012%\n",
      "Epoch [78/300], Step [22/225], Training Accuracy: 96.8040%, Training Loss: 0.0993%\n",
      "Epoch [78/300], Step [23/225], Training Accuracy: 96.7391%, Training Loss: 0.1013%\n",
      "Epoch [78/300], Step [24/225], Training Accuracy: 96.8750%, Training Loss: 0.0991%\n",
      "Epoch [78/300], Step [25/225], Training Accuracy: 96.8125%, Training Loss: 0.0985%\n",
      "Epoch [78/300], Step [26/225], Training Accuracy: 96.7548%, Training Loss: 0.0988%\n",
      "Epoch [78/300], Step [27/225], Training Accuracy: 96.7593%, Training Loss: 0.0992%\n",
      "Epoch [78/300], Step [28/225], Training Accuracy: 96.8192%, Training Loss: 0.0974%\n",
      "Epoch [78/300], Step [29/225], Training Accuracy: 96.8750%, Training Loss: 0.0966%\n",
      "Epoch [78/300], Step [30/225], Training Accuracy: 96.8750%, Training Loss: 0.0956%\n",
      "Epoch [78/300], Step [31/225], Training Accuracy: 96.8246%, Training Loss: 0.0966%\n",
      "Epoch [78/300], Step [32/225], Training Accuracy: 96.7285%, Training Loss: 0.0972%\n",
      "Epoch [78/300], Step [33/225], Training Accuracy: 96.7330%, Training Loss: 0.0966%\n",
      "Epoch [78/300], Step [34/225], Training Accuracy: 96.6912%, Training Loss: 0.0970%\n",
      "Epoch [78/300], Step [35/225], Training Accuracy: 96.6518%, Training Loss: 0.0985%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/300], Step [36/225], Training Accuracy: 96.5712%, Training Loss: 0.0989%\n",
      "Epoch [78/300], Step [37/225], Training Accuracy: 96.5794%, Training Loss: 0.0986%\n",
      "Epoch [78/300], Step [38/225], Training Accuracy: 96.5872%, Training Loss: 0.0980%\n",
      "Epoch [78/300], Step [39/225], Training Accuracy: 96.6346%, Training Loss: 0.0973%\n",
      "Epoch [78/300], Step [40/225], Training Accuracy: 96.6016%, Training Loss: 0.0979%\n",
      "Epoch [78/300], Step [41/225], Training Accuracy: 96.6463%, Training Loss: 0.0974%\n",
      "Epoch [78/300], Step [42/225], Training Accuracy: 96.6518%, Training Loss: 0.0972%\n",
      "Epoch [78/300], Step [43/225], Training Accuracy: 96.6570%, Training Loss: 0.0967%\n",
      "Epoch [78/300], Step [44/225], Training Accuracy: 96.7330%, Training Loss: 0.0957%\n",
      "Epoch [78/300], Step [45/225], Training Accuracy: 96.7361%, Training Loss: 0.0957%\n",
      "Epoch [78/300], Step [46/225], Training Accuracy: 96.7391%, Training Loss: 0.0953%\n",
      "Epoch [78/300], Step [47/225], Training Accuracy: 96.7088%, Training Loss: 0.0960%\n",
      "Epoch [78/300], Step [48/225], Training Accuracy: 96.7122%, Training Loss: 0.0954%\n",
      "Epoch [78/300], Step [49/225], Training Accuracy: 96.7474%, Training Loss: 0.0944%\n",
      "Epoch [78/300], Step [50/225], Training Accuracy: 96.7500%, Training Loss: 0.0940%\n",
      "Epoch [78/300], Step [51/225], Training Accuracy: 96.8137%, Training Loss: 0.0929%\n",
      "Epoch [78/300], Step [52/225], Training Accuracy: 96.8750%, Training Loss: 0.0918%\n",
      "Epoch [78/300], Step [53/225], Training Accuracy: 96.7866%, Training Loss: 0.0926%\n",
      "Epoch [78/300], Step [54/225], Training Accuracy: 96.8171%, Training Loss: 0.0926%\n",
      "Epoch [78/300], Step [55/225], Training Accuracy: 96.7898%, Training Loss: 0.0931%\n",
      "Epoch [78/300], Step [56/225], Training Accuracy: 96.7355%, Training Loss: 0.0956%\n",
      "Epoch [78/300], Step [57/225], Training Accuracy: 96.7379%, Training Loss: 0.0956%\n",
      "Epoch [78/300], Step [58/225], Training Accuracy: 96.7403%, Training Loss: 0.0953%\n",
      "Epoch [78/300], Step [59/225], Training Accuracy: 96.7426%, Training Loss: 0.0956%\n",
      "Epoch [78/300], Step [60/225], Training Accuracy: 96.7188%, Training Loss: 0.0960%\n",
      "Epoch [78/300], Step [61/225], Training Accuracy: 96.6957%, Training Loss: 0.0959%\n",
      "Epoch [78/300], Step [62/225], Training Accuracy: 96.7238%, Training Loss: 0.0951%\n",
      "Epoch [78/300], Step [63/225], Training Accuracy: 96.7510%, Training Loss: 0.0950%\n",
      "Epoch [78/300], Step [64/225], Training Accuracy: 96.7773%, Training Loss: 0.0942%\n",
      "Epoch [78/300], Step [65/225], Training Accuracy: 96.8029%, Training Loss: 0.0940%\n",
      "Epoch [78/300], Step [66/225], Training Accuracy: 96.8040%, Training Loss: 0.0938%\n",
      "Epoch [78/300], Step [67/225], Training Accuracy: 96.8050%, Training Loss: 0.0942%\n",
      "Epoch [78/300], Step [68/225], Training Accuracy: 96.8061%, Training Loss: 0.0940%\n",
      "Epoch [78/300], Step [69/225], Training Accuracy: 96.8524%, Training Loss: 0.0934%\n",
      "Epoch [78/300], Step [70/225], Training Accuracy: 96.8527%, Training Loss: 0.0928%\n",
      "Epoch [78/300], Step [71/225], Training Accuracy: 96.8750%, Training Loss: 0.0923%\n",
      "Epoch [78/300], Step [72/225], Training Accuracy: 96.8533%, Training Loss: 0.0920%\n",
      "Epoch [78/300], Step [73/225], Training Accuracy: 96.7680%, Training Loss: 0.0935%\n",
      "Epoch [78/300], Step [74/225], Training Accuracy: 96.7483%, Training Loss: 0.0936%\n",
      "Epoch [78/300], Step [75/225], Training Accuracy: 96.7083%, Training Loss: 0.0957%\n",
      "Epoch [78/300], Step [76/225], Training Accuracy: 96.7311%, Training Loss: 0.0955%\n",
      "Epoch [78/300], Step [77/225], Training Accuracy: 96.7330%, Training Loss: 0.0958%\n",
      "Epoch [78/300], Step [78/225], Training Accuracy: 96.7147%, Training Loss: 0.0968%\n",
      "Epoch [78/300], Step [79/225], Training Accuracy: 96.6772%, Training Loss: 0.0967%\n",
      "Epoch [78/300], Step [80/225], Training Accuracy: 96.6992%, Training Loss: 0.0963%\n",
      "Epoch [78/300], Step [81/225], Training Accuracy: 96.7014%, Training Loss: 0.0966%\n",
      "Epoch [78/300], Step [82/225], Training Accuracy: 96.7035%, Training Loss: 0.0964%\n",
      "Epoch [78/300], Step [83/225], Training Accuracy: 96.7056%, Training Loss: 0.0965%\n",
      "Epoch [78/300], Step [84/225], Training Accuracy: 96.7448%, Training Loss: 0.0956%\n",
      "Epoch [78/300], Step [85/225], Training Accuracy: 96.7279%, Training Loss: 0.0956%\n",
      "Epoch [78/300], Step [86/225], Training Accuracy: 96.7478%, Training Loss: 0.0955%\n",
      "Epoch [78/300], Step [87/225], Training Accuracy: 96.7672%, Training Loss: 0.0955%\n",
      "Epoch [78/300], Step [88/225], Training Accuracy: 96.7685%, Training Loss: 0.0951%\n",
      "Epoch [78/300], Step [89/225], Training Accuracy: 96.7170%, Training Loss: 0.0962%\n",
      "Epoch [78/300], Step [90/225], Training Accuracy: 96.7188%, Training Loss: 0.0963%\n",
      "Epoch [78/300], Step [91/225], Training Accuracy: 96.7548%, Training Loss: 0.0956%\n",
      "Epoch [78/300], Step [92/225], Training Accuracy: 96.7391%, Training Loss: 0.0962%\n",
      "Epoch [78/300], Step [93/225], Training Accuracy: 96.7574%, Training Loss: 0.0957%\n",
      "Epoch [78/300], Step [94/225], Training Accuracy: 96.7420%, Training Loss: 0.0961%\n",
      "Epoch [78/300], Step [95/225], Training Accuracy: 96.7434%, Training Loss: 0.0960%\n",
      "Epoch [78/300], Step [96/225], Training Accuracy: 96.7611%, Training Loss: 0.0956%\n",
      "Epoch [78/300], Step [97/225], Training Accuracy: 96.7461%, Training Loss: 0.0963%\n",
      "Epoch [78/300], Step [98/225], Training Accuracy: 96.6996%, Training Loss: 0.0971%\n",
      "Epoch [78/300], Step [99/225], Training Accuracy: 96.7014%, Training Loss: 0.0969%\n",
      "Epoch [78/300], Step [100/225], Training Accuracy: 96.7188%, Training Loss: 0.0966%\n",
      "Epoch [78/300], Step [101/225], Training Accuracy: 96.7358%, Training Loss: 0.0966%\n",
      "Epoch [78/300], Step [102/225], Training Accuracy: 96.7065%, Training Loss: 0.0969%\n",
      "Epoch [78/300], Step [103/225], Training Accuracy: 96.7081%, Training Loss: 0.0968%\n",
      "Epoch [78/300], Step [104/225], Training Accuracy: 96.7398%, Training Loss: 0.0963%\n",
      "Epoch [78/300], Step [105/225], Training Accuracy: 96.7113%, Training Loss: 0.0963%\n",
      "Epoch [78/300], Step [106/225], Training Accuracy: 96.7276%, Training Loss: 0.0959%\n",
      "Epoch [78/300], Step [107/225], Training Accuracy: 96.7290%, Training Loss: 0.0958%\n",
      "Epoch [78/300], Step [108/225], Training Accuracy: 96.7448%, Training Loss: 0.0953%\n",
      "Epoch [78/300], Step [109/225], Training Accuracy: 96.7460%, Training Loss: 0.0949%\n",
      "Epoch [78/300], Step [110/225], Training Accuracy: 96.7330%, Training Loss: 0.0947%\n",
      "Epoch [78/300], Step [111/225], Training Accuracy: 96.7624%, Training Loss: 0.0942%\n",
      "Epoch [78/300], Step [112/225], Training Accuracy: 96.7494%, Training Loss: 0.0945%\n",
      "Epoch [78/300], Step [113/225], Training Accuracy: 96.7782%, Training Loss: 0.0939%\n",
      "Epoch [78/300], Step [114/225], Training Accuracy: 96.7928%, Training Loss: 0.0937%\n",
      "Epoch [78/300], Step [115/225], Training Accuracy: 96.7799%, Training Loss: 0.0939%\n",
      "Epoch [78/300], Step [116/225], Training Accuracy: 96.7942%, Training Loss: 0.0937%\n",
      "Epoch [78/300], Step [117/225], Training Accuracy: 96.8082%, Training Loss: 0.0936%\n",
      "Epoch [78/300], Step [118/225], Training Accuracy: 96.8220%, Training Loss: 0.0936%\n",
      "Epoch [78/300], Step [119/225], Training Accuracy: 96.8487%, Training Loss: 0.0932%\n",
      "Epoch [78/300], Step [120/225], Training Accuracy: 96.8620%, Training Loss: 0.0930%\n",
      "Epoch [78/300], Step [121/225], Training Accuracy: 96.8879%, Training Loss: 0.0925%\n",
      "Epoch [78/300], Step [122/225], Training Accuracy: 96.8750%, Training Loss: 0.0928%\n",
      "Epoch [78/300], Step [123/225], Training Accuracy: 96.8623%, Training Loss: 0.0930%\n",
      "Epoch [78/300], Step [124/225], Training Accuracy: 96.8750%, Training Loss: 0.0927%\n",
      "Epoch [78/300], Step [125/225], Training Accuracy: 96.8750%, Training Loss: 0.0924%\n",
      "Epoch [78/300], Step [126/225], Training Accuracy: 96.8998%, Training Loss: 0.0921%\n",
      "Epoch [78/300], Step [127/225], Training Accuracy: 96.9119%, Training Loss: 0.0919%\n",
      "Epoch [78/300], Step [128/225], Training Accuracy: 96.9238%, Training Loss: 0.0918%\n",
      "Epoch [78/300], Step [129/225], Training Accuracy: 96.9113%, Training Loss: 0.0917%\n",
      "Epoch [78/300], Step [130/225], Training Accuracy: 96.9111%, Training Loss: 0.0918%\n",
      "Epoch [78/300], Step [131/225], Training Accuracy: 96.9346%, Training Loss: 0.0912%\n",
      "Epoch [78/300], Step [132/225], Training Accuracy: 96.9342%, Training Loss: 0.0915%\n",
      "Epoch [78/300], Step [133/225], Training Accuracy: 96.9220%, Training Loss: 0.0915%\n",
      "Epoch [78/300], Step [134/225], Training Accuracy: 96.9216%, Training Loss: 0.0912%\n",
      "Epoch [78/300], Step [135/225], Training Accuracy: 96.9213%, Training Loss: 0.0912%\n",
      "Epoch [78/300], Step [136/225], Training Accuracy: 96.9210%, Training Loss: 0.0918%\n",
      "Epoch [78/300], Step [137/225], Training Accuracy: 96.9092%, Training Loss: 0.0917%\n",
      "Epoch [78/300], Step [138/225], Training Accuracy: 96.8976%, Training Loss: 0.0915%\n",
      "Epoch [78/300], Step [139/225], Training Accuracy: 96.8975%, Training Loss: 0.0916%\n",
      "Epoch [78/300], Step [140/225], Training Accuracy: 96.9196%, Training Loss: 0.0913%\n",
      "Epoch [78/300], Step [141/225], Training Accuracy: 96.9304%, Training Loss: 0.0910%\n",
      "Epoch [78/300], Step [142/225], Training Accuracy: 96.9300%, Training Loss: 0.0908%\n",
      "Epoch [78/300], Step [143/225], Training Accuracy: 96.9406%, Training Loss: 0.0908%\n",
      "Epoch [78/300], Step [144/225], Training Accuracy: 96.9618%, Training Loss: 0.0905%\n",
      "Epoch [78/300], Step [145/225], Training Accuracy: 96.9828%, Training Loss: 0.0901%\n",
      "Epoch [78/300], Step [146/225], Training Accuracy: 96.9713%, Training Loss: 0.0901%\n",
      "Epoch [78/300], Step [147/225], Training Accuracy: 96.9600%, Training Loss: 0.0902%\n",
      "Epoch [78/300], Step [148/225], Training Accuracy: 96.9806%, Training Loss: 0.0898%\n",
      "Epoch [78/300], Step [149/225], Training Accuracy: 96.9694%, Training Loss: 0.0902%\n",
      "Epoch [78/300], Step [150/225], Training Accuracy: 96.9792%, Training Loss: 0.0900%\n",
      "Epoch [78/300], Step [151/225], Training Accuracy: 96.9785%, Training Loss: 0.0897%\n",
      "Epoch [78/300], Step [152/225], Training Accuracy: 96.9984%, Training Loss: 0.0894%\n",
      "Epoch [78/300], Step [153/225], Training Accuracy: 96.9975%, Training Loss: 0.0893%\n",
      "Epoch [78/300], Step [154/225], Training Accuracy: 97.0170%, Training Loss: 0.0889%\n",
      "Epoch [78/300], Step [155/225], Training Accuracy: 97.0363%, Training Loss: 0.0886%\n",
      "Epoch [78/300], Step [156/225], Training Accuracy: 97.0553%, Training Loss: 0.0882%\n",
      "Epoch [78/300], Step [157/225], Training Accuracy: 97.0342%, Training Loss: 0.0888%\n",
      "Epoch [78/300], Step [158/225], Training Accuracy: 97.0431%, Training Loss: 0.0886%\n",
      "Epoch [78/300], Step [159/225], Training Accuracy: 97.0224%, Training Loss: 0.0886%\n",
      "Epoch [78/300], Step [160/225], Training Accuracy: 97.0312%, Training Loss: 0.0883%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/300], Step [161/225], Training Accuracy: 97.0497%, Training Loss: 0.0880%\n",
      "Epoch [78/300], Step [162/225], Training Accuracy: 97.0679%, Training Loss: 0.0876%\n",
      "Epoch [78/300], Step [163/225], Training Accuracy: 97.0763%, Training Loss: 0.0874%\n",
      "Epoch [78/300], Step [164/225], Training Accuracy: 97.0751%, Training Loss: 0.0876%\n",
      "Epoch [78/300], Step [165/225], Training Accuracy: 97.0644%, Training Loss: 0.0879%\n",
      "Epoch [78/300], Step [166/225], Training Accuracy: 97.0821%, Training Loss: 0.0876%\n",
      "Epoch [78/300], Step [167/225], Training Accuracy: 97.0996%, Training Loss: 0.0874%\n",
      "Epoch [78/300], Step [168/225], Training Accuracy: 97.1075%, Training Loss: 0.0870%\n",
      "Epoch [78/300], Step [169/225], Training Accuracy: 97.1154%, Training Loss: 0.0869%\n",
      "Epoch [78/300], Step [170/225], Training Accuracy: 97.1232%, Training Loss: 0.0868%\n",
      "Epoch [78/300], Step [171/225], Training Accuracy: 97.1400%, Training Loss: 0.0865%\n",
      "Epoch [78/300], Step [172/225], Training Accuracy: 97.1475%, Training Loss: 0.0864%\n",
      "Epoch [78/300], Step [173/225], Training Accuracy: 97.1279%, Training Loss: 0.0867%\n",
      "Epoch [78/300], Step [174/225], Training Accuracy: 97.1444%, Training Loss: 0.0863%\n",
      "Epoch [78/300], Step [175/225], Training Accuracy: 97.1607%, Training Loss: 0.0859%\n",
      "Epoch [78/300], Step [176/225], Training Accuracy: 97.1591%, Training Loss: 0.0858%\n",
      "Epoch [78/300], Step [177/225], Training Accuracy: 97.1487%, Training Loss: 0.0856%\n",
      "Epoch [78/300], Step [178/225], Training Accuracy: 97.1471%, Training Loss: 0.0856%\n",
      "Epoch [78/300], Step [179/225], Training Accuracy: 97.1369%, Training Loss: 0.0860%\n",
      "Epoch [78/300], Step [180/225], Training Accuracy: 97.1528%, Training Loss: 0.0859%\n",
      "Epoch [78/300], Step [181/225], Training Accuracy: 97.1167%, Training Loss: 0.0863%\n",
      "Epoch [78/300], Step [182/225], Training Accuracy: 97.1068%, Training Loss: 0.0863%\n",
      "Epoch [78/300], Step [183/225], Training Accuracy: 97.1141%, Training Loss: 0.0860%\n",
      "Epoch [78/300], Step [184/225], Training Accuracy: 97.1213%, Training Loss: 0.0860%\n",
      "Epoch [78/300], Step [185/225], Training Accuracy: 97.1115%, Training Loss: 0.0861%\n",
      "Epoch [78/300], Step [186/225], Training Accuracy: 97.1270%, Training Loss: 0.0858%\n",
      "Epoch [78/300], Step [187/225], Training Accuracy: 97.1257%, Training Loss: 0.0858%\n",
      "Epoch [78/300], Step [188/225], Training Accuracy: 97.1160%, Training Loss: 0.0859%\n",
      "Epoch [78/300], Step [189/225], Training Accuracy: 97.1230%, Training Loss: 0.0857%\n",
      "Epoch [78/300], Step [190/225], Training Accuracy: 97.1053%, Training Loss: 0.0860%\n",
      "Epoch [78/300], Step [191/225], Training Accuracy: 97.1122%, Training Loss: 0.0859%\n",
      "Epoch [78/300], Step [192/225], Training Accuracy: 97.1191%, Training Loss: 0.0858%\n",
      "Epoch [78/300], Step [193/225], Training Accuracy: 97.1098%, Training Loss: 0.0859%\n",
      "Epoch [78/300], Step [194/225], Training Accuracy: 97.1166%, Training Loss: 0.0857%\n",
      "Epoch [78/300], Step [195/225], Training Accuracy: 97.1314%, Training Loss: 0.0854%\n",
      "Epoch [78/300], Step [196/225], Training Accuracy: 97.1460%, Training Loss: 0.0852%\n",
      "Epoch [78/300], Step [197/225], Training Accuracy: 97.1526%, Training Loss: 0.0851%\n",
      "Epoch [78/300], Step [198/225], Training Accuracy: 97.1354%, Training Loss: 0.0857%\n",
      "Epoch [78/300], Step [199/225], Training Accuracy: 97.1341%, Training Loss: 0.0857%\n",
      "Epoch [78/300], Step [200/225], Training Accuracy: 97.1172%, Training Loss: 0.0860%\n",
      "Epoch [78/300], Step [201/225], Training Accuracy: 97.0927%, Training Loss: 0.0863%\n",
      "Epoch [78/300], Step [202/225], Training Accuracy: 97.0916%, Training Loss: 0.0864%\n",
      "Epoch [78/300], Step [203/225], Training Accuracy: 97.0905%, Training Loss: 0.0865%\n",
      "Epoch [78/300], Step [204/225], Training Accuracy: 97.0971%, Training Loss: 0.0864%\n",
      "Epoch [78/300], Step [205/225], Training Accuracy: 97.0655%, Training Loss: 0.0871%\n",
      "Epoch [78/300], Step [206/225], Training Accuracy: 97.0646%, Training Loss: 0.0870%\n",
      "Epoch [78/300], Step [207/225], Training Accuracy: 97.0788%, Training Loss: 0.0867%\n",
      "Epoch [78/300], Step [208/225], Training Accuracy: 97.0853%, Training Loss: 0.0865%\n",
      "Epoch [78/300], Step [209/225], Training Accuracy: 97.0843%, Training Loss: 0.0863%\n",
      "Epoch [78/300], Step [210/225], Training Accuracy: 97.0610%, Training Loss: 0.0865%\n",
      "Epoch [78/300], Step [211/225], Training Accuracy: 97.0527%, Training Loss: 0.0865%\n",
      "Epoch [78/300], Step [212/225], Training Accuracy: 97.0519%, Training Loss: 0.0866%\n",
      "Epoch [78/300], Step [213/225], Training Accuracy: 97.0584%, Training Loss: 0.0864%\n",
      "Epoch [78/300], Step [214/225], Training Accuracy: 97.0502%, Training Loss: 0.0867%\n",
      "Epoch [78/300], Step [215/225], Training Accuracy: 97.0567%, Training Loss: 0.0865%\n",
      "Epoch [78/300], Step [216/225], Training Accuracy: 97.0486%, Training Loss: 0.0865%\n",
      "Epoch [78/300], Step [217/225], Training Accuracy: 97.0478%, Training Loss: 0.0865%\n",
      "Epoch [78/300], Step [218/225], Training Accuracy: 97.0470%, Training Loss: 0.0867%\n",
      "Epoch [78/300], Step [219/225], Training Accuracy: 97.0534%, Training Loss: 0.0865%\n",
      "Epoch [78/300], Step [220/225], Training Accuracy: 97.0597%, Training Loss: 0.0864%\n",
      "Epoch [78/300], Step [221/225], Training Accuracy: 97.0588%, Training Loss: 0.0863%\n",
      "Epoch [78/300], Step [222/225], Training Accuracy: 97.0650%, Training Loss: 0.0862%\n",
      "Epoch [78/300], Step [223/225], Training Accuracy: 97.0712%, Training Loss: 0.0861%\n",
      "Epoch [78/300], Step [224/225], Training Accuracy: 97.0773%, Training Loss: 0.0860%\n",
      "Epoch [78/300], Step [225/225], Training Accuracy: 97.0748%, Training Loss: 0.0861%\n",
      "Epoch [79/300], Step [1/225], Training Accuracy: 98.4375%, Training Loss: 0.0591%\n",
      "Epoch [79/300], Step [2/225], Training Accuracy: 98.4375%, Training Loss: 0.0645%\n",
      "Epoch [79/300], Step [3/225], Training Accuracy: 95.8333%, Training Loss: 0.1004%\n",
      "Epoch [79/300], Step [4/225], Training Accuracy: 96.4844%, Training Loss: 0.0876%\n",
      "Epoch [79/300], Step [5/225], Training Accuracy: 96.8750%, Training Loss: 0.0812%\n",
      "Epoch [79/300], Step [6/225], Training Accuracy: 96.8750%, Training Loss: 0.0797%\n",
      "Epoch [79/300], Step [7/225], Training Accuracy: 96.2054%, Training Loss: 0.0882%\n",
      "Epoch [79/300], Step [8/225], Training Accuracy: 96.4844%, Training Loss: 0.0822%\n",
      "Epoch [79/300], Step [9/225], Training Accuracy: 96.3542%, Training Loss: 0.0853%\n",
      "Epoch [79/300], Step [10/225], Training Accuracy: 96.5625%, Training Loss: 0.0863%\n",
      "Epoch [79/300], Step [11/225], Training Accuracy: 96.7330%, Training Loss: 0.0829%\n",
      "Epoch [79/300], Step [12/225], Training Accuracy: 97.0052%, Training Loss: 0.0801%\n",
      "Epoch [79/300], Step [13/225], Training Accuracy: 97.1154%, Training Loss: 0.0821%\n",
      "Epoch [79/300], Step [14/225], Training Accuracy: 97.3214%, Training Loss: 0.0782%\n",
      "Epoch [79/300], Step [15/225], Training Accuracy: 97.2917%, Training Loss: 0.0782%\n",
      "Epoch [79/300], Step [16/225], Training Accuracy: 97.3633%, Training Loss: 0.0768%\n",
      "Epoch [79/300], Step [17/225], Training Accuracy: 97.3346%, Training Loss: 0.0785%\n",
      "Epoch [79/300], Step [18/225], Training Accuracy: 96.8750%, Training Loss: 0.0892%\n",
      "Epoch [79/300], Step [19/225], Training Accuracy: 96.9572%, Training Loss: 0.0875%\n",
      "Epoch [79/300], Step [20/225], Training Accuracy: 96.9531%, Training Loss: 0.0873%\n",
      "Epoch [79/300], Step [21/225], Training Accuracy: 97.0982%, Training Loss: 0.0853%\n",
      "Epoch [79/300], Step [22/225], Training Accuracy: 97.1591%, Training Loss: 0.0838%\n",
      "Epoch [79/300], Step [23/225], Training Accuracy: 97.0788%, Training Loss: 0.0854%\n",
      "Epoch [79/300], Step [24/225], Training Accuracy: 97.0703%, Training Loss: 0.0843%\n",
      "Epoch [79/300], Step [25/225], Training Accuracy: 96.9375%, Training Loss: 0.0863%\n",
      "Epoch [79/300], Step [26/225], Training Accuracy: 96.9952%, Training Loss: 0.0867%\n",
      "Epoch [79/300], Step [27/225], Training Accuracy: 96.9907%, Training Loss: 0.0866%\n",
      "Epoch [79/300], Step [28/225], Training Accuracy: 96.9866%, Training Loss: 0.0864%\n",
      "Epoch [79/300], Step [29/225], Training Accuracy: 96.8750%, Training Loss: 0.0881%\n",
      "Epoch [79/300], Step [30/225], Training Accuracy: 96.7708%, Training Loss: 0.0889%\n",
      "Epoch [79/300], Step [31/225], Training Accuracy: 96.6230%, Training Loss: 0.0932%\n",
      "Epoch [79/300], Step [32/225], Training Accuracy: 96.6797%, Training Loss: 0.0922%\n",
      "Epoch [79/300], Step [33/225], Training Accuracy: 96.7330%, Training Loss: 0.0905%\n",
      "Epoch [79/300], Step [34/225], Training Accuracy: 96.6912%, Training Loss: 0.0907%\n",
      "Epoch [79/300], Step [35/225], Training Accuracy: 96.6964%, Training Loss: 0.0901%\n",
      "Epoch [79/300], Step [36/225], Training Accuracy: 96.7014%, Training Loss: 0.0908%\n",
      "Epoch [79/300], Step [37/225], Training Accuracy: 96.7483%, Training Loss: 0.0900%\n",
      "Epoch [79/300], Step [38/225], Training Accuracy: 96.7516%, Training Loss: 0.0910%\n",
      "Epoch [79/300], Step [39/225], Training Accuracy: 96.7949%, Training Loss: 0.0901%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/300], Step [40/225], Training Accuracy: 96.7578%, Training Loss: 0.0902%\n",
      "Epoch [79/300], Step [41/225], Training Accuracy: 96.7226%, Training Loss: 0.0917%\n",
      "Epoch [79/300], Step [42/225], Training Accuracy: 96.6146%, Training Loss: 0.0932%\n",
      "Epoch [79/300], Step [43/225], Training Accuracy: 96.5843%, Training Loss: 0.0941%\n",
      "Epoch [79/300], Step [44/225], Training Accuracy: 96.5554%, Training Loss: 0.0951%\n",
      "Epoch [79/300], Step [45/225], Training Accuracy: 96.5972%, Training Loss: 0.0937%\n",
      "Epoch [79/300], Step [46/225], Training Accuracy: 96.6033%, Training Loss: 0.0936%\n",
      "Epoch [79/300], Step [47/225], Training Accuracy: 96.6423%, Training Loss: 0.0931%\n",
      "Epoch [79/300], Step [48/225], Training Accuracy: 96.7122%, Training Loss: 0.0921%\n",
      "Epoch [79/300], Step [49/225], Training Accuracy: 96.6518%, Training Loss: 0.0935%\n",
      "Epoch [79/300], Step [50/225], Training Accuracy: 96.6875%, Training Loss: 0.0930%\n",
      "Epoch [79/300], Step [51/225], Training Accuracy: 96.6912%, Training Loss: 0.0921%\n",
      "Epoch [79/300], Step [52/225], Training Accuracy: 96.7548%, Training Loss: 0.0911%\n",
      "Epoch [79/300], Step [53/225], Training Accuracy: 96.7276%, Training Loss: 0.0926%\n",
      "Epoch [79/300], Step [54/225], Training Accuracy: 96.7593%, Training Loss: 0.0919%\n",
      "Epoch [79/300], Step [55/225], Training Accuracy: 96.6761%, Training Loss: 0.0932%\n",
      "Epoch [79/300], Step [56/225], Training Accuracy: 96.7076%, Training Loss: 0.0928%\n",
      "Epoch [79/300], Step [57/225], Training Accuracy: 96.7379%, Training Loss: 0.0921%\n",
      "Epoch [79/300], Step [58/225], Training Accuracy: 96.7134%, Training Loss: 0.0923%\n",
      "Epoch [79/300], Step [59/225], Training Accuracy: 96.7426%, Training Loss: 0.0916%\n",
      "Epoch [79/300], Step [60/225], Training Accuracy: 96.7188%, Training Loss: 0.0916%\n",
      "Epoch [79/300], Step [61/225], Training Accuracy: 96.6957%, Training Loss: 0.0925%\n",
      "Epoch [79/300], Step [62/225], Training Accuracy: 96.7490%, Training Loss: 0.0917%\n",
      "Epoch [79/300], Step [63/225], Training Accuracy: 96.6518%, Training Loss: 0.0940%\n",
      "Epoch [79/300], Step [64/225], Training Accuracy: 96.6309%, Training Loss: 0.0945%\n",
      "Epoch [79/300], Step [65/225], Training Accuracy: 96.6587%, Training Loss: 0.0942%\n",
      "Epoch [79/300], Step [66/225], Training Accuracy: 96.6619%, Training Loss: 0.0946%\n",
      "Epoch [79/300], Step [67/225], Training Accuracy: 96.5951%, Training Loss: 0.0963%\n",
      "Epoch [79/300], Step [68/225], Training Accuracy: 96.5763%, Training Loss: 0.0966%\n",
      "Epoch [79/300], Step [69/225], Training Accuracy: 96.5806%, Training Loss: 0.0965%\n",
      "Epoch [79/300], Step [70/225], Training Accuracy: 96.5848%, Training Loss: 0.0969%\n",
      "Epoch [79/300], Step [71/225], Training Accuracy: 96.5669%, Training Loss: 0.0970%\n",
      "Epoch [79/300], Step [72/225], Training Accuracy: 96.6146%, Training Loss: 0.0965%\n",
      "Epoch [79/300], Step [73/225], Training Accuracy: 96.5967%, Training Loss: 0.0964%\n",
      "Epoch [79/300], Step [74/225], Training Accuracy: 96.6216%, Training Loss: 0.0959%\n",
      "Epoch [79/300], Step [75/225], Training Accuracy: 96.6250%, Training Loss: 0.0960%\n",
      "Epoch [79/300], Step [76/225], Training Accuracy: 96.6283%, Training Loss: 0.0962%\n",
      "Epoch [79/300], Step [77/225], Training Accuracy: 96.6518%, Training Loss: 0.0956%\n",
      "Epoch [79/300], Step [78/225], Training Accuracy: 96.6947%, Training Loss: 0.0951%\n",
      "Epoch [79/300], Step [79/225], Training Accuracy: 96.6377%, Training Loss: 0.0967%\n",
      "Epoch [79/300], Step [80/225], Training Accuracy: 96.6406%, Training Loss: 0.0968%\n",
      "Epoch [79/300], Step [81/225], Training Accuracy: 96.6821%, Training Loss: 0.0959%\n",
      "Epoch [79/300], Step [82/225], Training Accuracy: 96.7035%, Training Loss: 0.0961%\n",
      "Epoch [79/300], Step [83/225], Training Accuracy: 96.7056%, Training Loss: 0.0962%\n",
      "Epoch [79/300], Step [84/225], Training Accuracy: 96.6890%, Training Loss: 0.0959%\n",
      "Epoch [79/300], Step [85/225], Training Accuracy: 96.6912%, Training Loss: 0.0957%\n",
      "Epoch [79/300], Step [86/225], Training Accuracy: 96.7115%, Training Loss: 0.0956%\n",
      "Epoch [79/300], Step [87/225], Training Accuracy: 96.7134%, Training Loss: 0.0953%\n",
      "Epoch [79/300], Step [88/225], Training Accuracy: 96.7330%, Training Loss: 0.0954%\n",
      "Epoch [79/300], Step [89/225], Training Accuracy: 96.7697%, Training Loss: 0.0948%\n",
      "Epoch [79/300], Step [90/225], Training Accuracy: 96.7535%, Training Loss: 0.0945%\n",
      "Epoch [79/300], Step [91/225], Training Accuracy: 96.7891%, Training Loss: 0.0938%\n",
      "Epoch [79/300], Step [92/225], Training Accuracy: 96.8071%, Training Loss: 0.0935%\n",
      "Epoch [79/300], Step [93/225], Training Accuracy: 96.8246%, Training Loss: 0.0931%\n",
      "Epoch [79/300], Step [94/225], Training Accuracy: 96.8251%, Training Loss: 0.0933%\n",
      "Epoch [79/300], Step [95/225], Training Accuracy: 96.8421%, Training Loss: 0.0928%\n",
      "Epoch [79/300], Step [96/225], Training Accuracy: 96.8587%, Training Loss: 0.0922%\n",
      "Epoch [79/300], Step [97/225], Training Accuracy: 96.8911%, Training Loss: 0.0916%\n",
      "Epoch [79/300], Step [98/225], Training Accuracy: 96.8909%, Training Loss: 0.0915%\n",
      "Epoch [79/300], Step [99/225], Training Accuracy: 96.9066%, Training Loss: 0.0910%\n",
      "Epoch [79/300], Step [100/225], Training Accuracy: 96.9062%, Training Loss: 0.0912%\n",
      "Epoch [79/300], Step [101/225], Training Accuracy: 96.9369%, Training Loss: 0.0906%\n",
      "Epoch [79/300], Step [102/225], Training Accuracy: 96.9363%, Training Loss: 0.0904%\n",
      "Epoch [79/300], Step [103/225], Training Accuracy: 96.9660%, Training Loss: 0.0901%\n",
      "Epoch [79/300], Step [104/225], Training Accuracy: 96.9802%, Training Loss: 0.0900%\n",
      "Epoch [79/300], Step [105/225], Training Accuracy: 97.0089%, Training Loss: 0.0894%\n",
      "Epoch [79/300], Step [106/225], Training Accuracy: 96.9929%, Training Loss: 0.0901%\n",
      "Epoch [79/300], Step [107/225], Training Accuracy: 97.0064%, Training Loss: 0.0897%\n",
      "Epoch [79/300], Step [108/225], Training Accuracy: 97.0052%, Training Loss: 0.0896%\n",
      "Epoch [79/300], Step [109/225], Training Accuracy: 96.9897%, Training Loss: 0.0897%\n",
      "Epoch [79/300], Step [110/225], Training Accuracy: 97.0170%, Training Loss: 0.0891%\n",
      "Epoch [79/300], Step [111/225], Training Accuracy: 97.0017%, Training Loss: 0.0892%\n",
      "Epoch [79/300], Step [112/225], Training Accuracy: 97.0145%, Training Loss: 0.0891%\n",
      "Epoch [79/300], Step [113/225], Training Accuracy: 97.0271%, Training Loss: 0.0888%\n",
      "Epoch [79/300], Step [114/225], Training Accuracy: 97.0532%, Training Loss: 0.0884%\n",
      "Epoch [79/300], Step [115/225], Training Accuracy: 96.9973%, Training Loss: 0.0890%\n",
      "Epoch [79/300], Step [116/225], Training Accuracy: 97.0097%, Training Loss: 0.0889%\n",
      "Epoch [79/300], Step [117/225], Training Accuracy: 97.0085%, Training Loss: 0.0886%\n",
      "Epoch [79/300], Step [118/225], Training Accuracy: 97.0339%, Training Loss: 0.0881%\n",
      "Epoch [79/300], Step [119/225], Training Accuracy: 97.0588%, Training Loss: 0.0876%\n",
      "Epoch [79/300], Step [120/225], Training Accuracy: 97.0833%, Training Loss: 0.0872%\n",
      "Epoch [79/300], Step [121/225], Training Accuracy: 97.1074%, Training Loss: 0.0868%\n",
      "Epoch [79/300], Step [122/225], Training Accuracy: 97.1183%, Training Loss: 0.0866%\n",
      "Epoch [79/300], Step [123/225], Training Accuracy: 97.1291%, Training Loss: 0.0863%\n",
      "Epoch [79/300], Step [124/225], Training Accuracy: 97.1522%, Training Loss: 0.0860%\n",
      "Epoch [79/300], Step [125/225], Training Accuracy: 97.1625%, Training Loss: 0.0859%\n",
      "Epoch [79/300], Step [126/225], Training Accuracy: 97.1602%, Training Loss: 0.0859%\n",
      "Epoch [79/300], Step [127/225], Training Accuracy: 97.1457%, Training Loss: 0.0858%\n",
      "Epoch [79/300], Step [128/225], Training Accuracy: 97.1436%, Training Loss: 0.0860%\n",
      "Epoch [79/300], Step [129/225], Training Accuracy: 97.1536%, Training Loss: 0.0859%\n",
      "Epoch [79/300], Step [130/225], Training Accuracy: 97.1635%, Training Loss: 0.0857%\n",
      "Epoch [79/300], Step [131/225], Training Accuracy: 97.1732%, Training Loss: 0.0854%\n",
      "Epoch [79/300], Step [132/225], Training Accuracy: 97.1709%, Training Loss: 0.0854%\n",
      "Epoch [79/300], Step [133/225], Training Accuracy: 97.1570%, Training Loss: 0.0854%\n",
      "Epoch [79/300], Step [134/225], Training Accuracy: 97.1549%, Training Loss: 0.0854%\n",
      "Epoch [79/300], Step [135/225], Training Accuracy: 97.1759%, Training Loss: 0.0850%\n",
      "Epoch [79/300], Step [136/225], Training Accuracy: 97.1852%, Training Loss: 0.0849%\n",
      "Epoch [79/300], Step [137/225], Training Accuracy: 97.1943%, Training Loss: 0.0848%\n",
      "Epoch [79/300], Step [138/225], Training Accuracy: 97.2034%, Training Loss: 0.0846%\n",
      "Epoch [79/300], Step [139/225], Training Accuracy: 97.2010%, Training Loss: 0.0845%\n",
      "Epoch [79/300], Step [140/225], Training Accuracy: 97.2210%, Training Loss: 0.0842%\n",
      "Epoch [79/300], Step [141/225], Training Accuracy: 97.2296%, Training Loss: 0.0840%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/300], Step [142/225], Training Accuracy: 97.2491%, Training Loss: 0.0837%\n",
      "Epoch [79/300], Step [143/225], Training Accuracy: 97.2684%, Training Loss: 0.0834%\n",
      "Epoch [79/300], Step [144/225], Training Accuracy: 97.2656%, Training Loss: 0.0834%\n",
      "Epoch [79/300], Step [145/225], Training Accuracy: 97.2737%, Training Loss: 0.0833%\n",
      "Epoch [79/300], Step [146/225], Training Accuracy: 97.2710%, Training Loss: 0.0832%\n",
      "Epoch [79/300], Step [147/225], Training Accuracy: 97.2258%, Training Loss: 0.0837%\n",
      "Epoch [79/300], Step [148/225], Training Accuracy: 97.2128%, Training Loss: 0.0837%\n",
      "Epoch [79/300], Step [149/225], Training Accuracy: 97.2106%, Training Loss: 0.0842%\n",
      "Epoch [79/300], Step [150/225], Training Accuracy: 97.2188%, Training Loss: 0.0839%\n",
      "Epoch [79/300], Step [151/225], Training Accuracy: 97.2268%, Training Loss: 0.0837%\n",
      "Epoch [79/300], Step [152/225], Training Accuracy: 97.2039%, Training Loss: 0.0838%\n",
      "Epoch [79/300], Step [153/225], Training Accuracy: 97.1916%, Training Loss: 0.0844%\n",
      "Epoch [79/300], Step [154/225], Training Accuracy: 97.1997%, Training Loss: 0.0843%\n",
      "Epoch [79/300], Step [155/225], Training Accuracy: 97.2077%, Training Loss: 0.0842%\n",
      "Epoch [79/300], Step [156/225], Training Accuracy: 97.1955%, Training Loss: 0.0847%\n",
      "Epoch [79/300], Step [157/225], Training Accuracy: 97.1736%, Training Loss: 0.0849%\n",
      "Epoch [79/300], Step [158/225], Training Accuracy: 97.1816%, Training Loss: 0.0848%\n",
      "Epoch [79/300], Step [159/225], Training Accuracy: 97.1796%, Training Loss: 0.0847%\n",
      "Epoch [79/300], Step [160/225], Training Accuracy: 97.1875%, Training Loss: 0.0845%\n",
      "Epoch [79/300], Step [161/225], Training Accuracy: 97.1953%, Training Loss: 0.0844%\n",
      "Epoch [79/300], Step [162/225], Training Accuracy: 97.1933%, Training Loss: 0.0843%\n",
      "Epoch [79/300], Step [163/225], Training Accuracy: 97.1913%, Training Loss: 0.0841%\n",
      "Epoch [79/300], Step [164/225], Training Accuracy: 97.1989%, Training Loss: 0.0842%\n",
      "Epoch [79/300], Step [165/225], Training Accuracy: 97.2064%, Training Loss: 0.0841%\n",
      "Epoch [79/300], Step [166/225], Training Accuracy: 97.2139%, Training Loss: 0.0841%\n",
      "Epoch [79/300], Step [167/225], Training Accuracy: 97.2212%, Training Loss: 0.0838%\n",
      "Epoch [79/300], Step [168/225], Training Accuracy: 97.2284%, Training Loss: 0.0836%\n",
      "Epoch [79/300], Step [169/225], Training Accuracy: 97.2356%, Training Loss: 0.0834%\n",
      "Epoch [79/300], Step [170/225], Training Accuracy: 97.2059%, Training Loss: 0.0839%\n",
      "Epoch [79/300], Step [171/225], Training Accuracy: 97.2039%, Training Loss: 0.0838%\n",
      "Epoch [79/300], Step [172/225], Training Accuracy: 97.2202%, Training Loss: 0.0834%\n",
      "Epoch [79/300], Step [173/225], Training Accuracy: 97.2272%, Training Loss: 0.0832%\n",
      "Epoch [79/300], Step [174/225], Training Accuracy: 97.2342%, Training Loss: 0.0832%\n",
      "Epoch [79/300], Step [175/225], Training Accuracy: 97.2500%, Training Loss: 0.0829%\n",
      "Epoch [79/300], Step [176/225], Training Accuracy: 97.2390%, Training Loss: 0.0829%\n",
      "Epoch [79/300], Step [177/225], Training Accuracy: 97.2546%, Training Loss: 0.0827%\n",
      "Epoch [79/300], Step [178/225], Training Accuracy: 97.2612%, Training Loss: 0.0825%\n",
      "Epoch [79/300], Step [179/225], Training Accuracy: 97.2591%, Training Loss: 0.0824%\n",
      "Epoch [79/300], Step [180/225], Training Accuracy: 97.2483%, Training Loss: 0.0824%\n",
      "Epoch [79/300], Step [181/225], Training Accuracy: 97.2548%, Training Loss: 0.0822%\n",
      "Epoch [79/300], Step [182/225], Training Accuracy: 97.2527%, Training Loss: 0.0822%\n",
      "Epoch [79/300], Step [183/225], Training Accuracy: 97.2421%, Training Loss: 0.0821%\n",
      "Epoch [79/300], Step [184/225], Training Accuracy: 97.2571%, Training Loss: 0.0819%\n",
      "Epoch [79/300], Step [185/225], Training Accuracy: 97.2720%, Training Loss: 0.0817%\n",
      "Epoch [79/300], Step [186/225], Training Accuracy: 97.2782%, Training Loss: 0.0816%\n",
      "Epoch [79/300], Step [187/225], Training Accuracy: 97.2928%, Training Loss: 0.0813%\n",
      "Epoch [79/300], Step [188/225], Training Accuracy: 97.2989%, Training Loss: 0.0813%\n",
      "Epoch [79/300], Step [189/225], Training Accuracy: 97.3132%, Training Loss: 0.0810%\n",
      "Epoch [79/300], Step [190/225], Training Accuracy: 97.3191%, Training Loss: 0.0810%\n",
      "Epoch [79/300], Step [191/225], Training Accuracy: 97.3249%, Training Loss: 0.0808%\n",
      "Epoch [79/300], Step [192/225], Training Accuracy: 97.3063%, Training Loss: 0.0811%\n",
      "Epoch [79/300], Step [193/225], Training Accuracy: 97.2960%, Training Loss: 0.0813%\n",
      "Epoch [79/300], Step [194/225], Training Accuracy: 97.3099%, Training Loss: 0.0811%\n",
      "Epoch [79/300], Step [195/225], Training Accuracy: 97.3237%, Training Loss: 0.0809%\n",
      "Epoch [79/300], Step [196/225], Training Accuracy: 97.3135%, Training Loss: 0.0809%\n",
      "Epoch [79/300], Step [197/225], Training Accuracy: 97.3112%, Training Loss: 0.0809%\n",
      "Epoch [79/300], Step [198/225], Training Accuracy: 97.3248%, Training Loss: 0.0807%\n",
      "Epoch [79/300], Step [199/225], Training Accuracy: 97.3226%, Training Loss: 0.0807%\n",
      "Epoch [79/300], Step [200/225], Training Accuracy: 97.3281%, Training Loss: 0.0806%\n",
      "Epoch [79/300], Step [201/225], Training Accuracy: 97.3259%, Training Loss: 0.0806%\n",
      "Epoch [79/300], Step [202/225], Training Accuracy: 97.3236%, Training Loss: 0.0809%\n",
      "Epoch [79/300], Step [203/225], Training Accuracy: 97.3291%, Training Loss: 0.0808%\n",
      "Epoch [79/300], Step [204/225], Training Accuracy: 97.3269%, Training Loss: 0.0808%\n",
      "Epoch [79/300], Step [205/225], Training Accuracy: 97.3323%, Training Loss: 0.0806%\n",
      "Epoch [79/300], Step [206/225], Training Accuracy: 97.3377%, Training Loss: 0.0804%\n",
      "Epoch [79/300], Step [207/225], Training Accuracy: 97.3279%, Training Loss: 0.0814%\n",
      "Epoch [79/300], Step [208/225], Training Accuracy: 97.3257%, Training Loss: 0.0815%\n",
      "Epoch [79/300], Step [209/225], Training Accuracy: 97.3236%, Training Loss: 0.0814%\n",
      "Epoch [79/300], Step [210/225], Training Accuracy: 97.3140%, Training Loss: 0.0815%\n",
      "Epoch [79/300], Step [211/225], Training Accuracy: 97.3193%, Training Loss: 0.0815%\n",
      "Epoch [79/300], Step [212/225], Training Accuracy: 97.3320%, Training Loss: 0.0813%\n",
      "Epoch [79/300], Step [213/225], Training Accuracy: 97.3371%, Training Loss: 0.0812%\n",
      "Epoch [79/300], Step [214/225], Training Accuracy: 97.3496%, Training Loss: 0.0809%\n",
      "Epoch [79/300], Step [215/225], Training Accuracy: 97.3474%, Training Loss: 0.0810%\n",
      "Epoch [79/300], Step [216/225], Training Accuracy: 97.3597%, Training Loss: 0.0809%\n",
      "Epoch [79/300], Step [217/225], Training Accuracy: 97.3574%, Training Loss: 0.0809%\n",
      "Epoch [79/300], Step [218/225], Training Accuracy: 97.3696%, Training Loss: 0.0807%\n",
      "Epoch [79/300], Step [219/225], Training Accuracy: 97.3530%, Training Loss: 0.0809%\n",
      "Epoch [79/300], Step [220/225], Training Accuracy: 97.3509%, Training Loss: 0.0810%\n",
      "Epoch [79/300], Step [221/225], Training Accuracy: 97.3487%, Training Loss: 0.0810%\n",
      "Epoch [79/300], Step [222/225], Training Accuracy: 97.3466%, Training Loss: 0.0810%\n",
      "Epoch [79/300], Step [223/225], Training Accuracy: 97.3515%, Training Loss: 0.0810%\n",
      "Epoch [79/300], Step [224/225], Training Accuracy: 97.3633%, Training Loss: 0.0808%\n",
      "Epoch [79/300], Step [225/225], Training Accuracy: 97.3666%, Training Loss: 0.0807%\n",
      "Epoch [80/300], Step [1/225], Training Accuracy: 95.3125%, Training Loss: 0.1409%\n",
      "Epoch [80/300], Step [2/225], Training Accuracy: 97.6562%, Training Loss: 0.0957%\n",
      "Epoch [80/300], Step [3/225], Training Accuracy: 96.3542%, Training Loss: 0.1044%\n",
      "Epoch [80/300], Step [4/225], Training Accuracy: 96.8750%, Training Loss: 0.0988%\n",
      "Epoch [80/300], Step [5/225], Training Accuracy: 97.5000%, Training Loss: 0.0858%\n",
      "Epoch [80/300], Step [6/225], Training Accuracy: 97.6562%, Training Loss: 0.0786%\n",
      "Epoch [80/300], Step [7/225], Training Accuracy: 97.0982%, Training Loss: 0.0896%\n",
      "Epoch [80/300], Step [8/225], Training Accuracy: 97.0703%, Training Loss: 0.0973%\n",
      "Epoch [80/300], Step [9/225], Training Accuracy: 96.8750%, Training Loss: 0.0992%\n",
      "Epoch [80/300], Step [10/225], Training Accuracy: 97.0312%, Training Loss: 0.0958%\n",
      "Epoch [80/300], Step [11/225], Training Accuracy: 97.1591%, Training Loss: 0.0913%\n",
      "Epoch [80/300], Step [12/225], Training Accuracy: 97.1354%, Training Loss: 0.0907%\n",
      "Epoch [80/300], Step [13/225], Training Accuracy: 97.3558%, Training Loss: 0.0860%\n",
      "Epoch [80/300], Step [14/225], Training Accuracy: 97.0982%, Training Loss: 0.0893%\n",
      "Epoch [80/300], Step [15/225], Training Accuracy: 97.0833%, Training Loss: 0.0895%\n",
      "Epoch [80/300], Step [16/225], Training Accuracy: 96.9727%, Training Loss: 0.0914%\n",
      "Epoch [80/300], Step [17/225], Training Accuracy: 97.0588%, Training Loss: 0.0897%\n",
      "Epoch [80/300], Step [18/225], Training Accuracy: 97.1354%, Training Loss: 0.0894%\n",
      "Epoch [80/300], Step [19/225], Training Accuracy: 97.2039%, Training Loss: 0.0879%\n",
      "Epoch [80/300], Step [20/225], Training Accuracy: 97.1875%, Training Loss: 0.0874%\n",
      "Epoch [80/300], Step [21/225], Training Accuracy: 97.2470%, Training Loss: 0.0858%\n",
      "Epoch [80/300], Step [22/225], Training Accuracy: 97.3011%, Training Loss: 0.0838%\n",
      "Epoch [80/300], Step [23/225], Training Accuracy: 97.4185%, Training Loss: 0.0810%\n",
      "Epoch [80/300], Step [24/225], Training Accuracy: 97.3958%, Training Loss: 0.0808%\n",
      "Epoch [80/300], Step [25/225], Training Accuracy: 97.3125%, Training Loss: 0.0810%\n",
      "Epoch [80/300], Step [26/225], Training Accuracy: 97.1755%, Training Loss: 0.0826%\n",
      "Epoch [80/300], Step [27/225], Training Accuracy: 97.1065%, Training Loss: 0.0844%\n",
      "Epoch [80/300], Step [28/225], Training Accuracy: 97.2098%, Training Loss: 0.0832%\n",
      "Epoch [80/300], Step [29/225], Training Accuracy: 97.2522%, Training Loss: 0.0818%\n",
      "Epoch [80/300], Step [30/225], Training Accuracy: 96.9792%, Training Loss: 0.0836%\n",
      "Epoch [80/300], Step [31/225], Training Accuracy: 96.8750%, Training Loss: 0.0846%\n",
      "Epoch [80/300], Step [32/225], Training Accuracy: 96.8750%, Training Loss: 0.0842%\n",
      "Epoch [80/300], Step [33/225], Training Accuracy: 96.7330%, Training Loss: 0.0858%\n",
      "Epoch [80/300], Step [34/225], Training Accuracy: 96.6912%, Training Loss: 0.0859%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/300], Step [35/225], Training Accuracy: 96.7411%, Training Loss: 0.0863%\n",
      "Epoch [80/300], Step [36/225], Training Accuracy: 96.7882%, Training Loss: 0.0854%\n",
      "Epoch [80/300], Step [37/225], Training Accuracy: 96.7061%, Training Loss: 0.0876%\n",
      "Epoch [80/300], Step [38/225], Training Accuracy: 96.6694%, Training Loss: 0.0893%\n",
      "Epoch [80/300], Step [39/225], Training Accuracy: 96.6346%, Training Loss: 0.0896%\n",
      "Epoch [80/300], Step [40/225], Training Accuracy: 96.5625%, Training Loss: 0.0906%\n",
      "Epoch [80/300], Step [41/225], Training Accuracy: 96.5320%, Training Loss: 0.0914%\n",
      "Epoch [80/300], Step [42/225], Training Accuracy: 96.5774%, Training Loss: 0.0909%\n",
      "Epoch [80/300], Step [43/225], Training Accuracy: 96.5843%, Training Loss: 0.0917%\n",
      "Epoch [80/300], Step [44/225], Training Accuracy: 96.5909%, Training Loss: 0.0914%\n",
      "Epoch [80/300], Step [45/225], Training Accuracy: 96.6319%, Training Loss: 0.0909%\n",
      "Epoch [80/300], Step [46/225], Training Accuracy: 96.6712%, Training Loss: 0.0901%\n",
      "Epoch [80/300], Step [47/225], Training Accuracy: 96.6423%, Training Loss: 0.0912%\n",
      "Epoch [80/300], Step [48/225], Training Accuracy: 96.6797%, Training Loss: 0.0903%\n",
      "Epoch [80/300], Step [49/225], Training Accuracy: 96.6837%, Training Loss: 0.0898%\n",
      "Epoch [80/300], Step [50/225], Training Accuracy: 96.7500%, Training Loss: 0.0887%\n",
      "Epoch [80/300], Step [51/225], Training Accuracy: 96.7831%, Training Loss: 0.0878%\n",
      "Epoch [80/300], Step [52/225], Training Accuracy: 96.8149%, Training Loss: 0.0872%\n",
      "Epoch [80/300], Step [53/225], Training Accuracy: 96.7571%, Training Loss: 0.0877%\n",
      "Epoch [80/300], Step [54/225], Training Accuracy: 96.7882%, Training Loss: 0.0872%\n",
      "Epoch [80/300], Step [55/225], Training Accuracy: 96.7898%, Training Loss: 0.0882%\n",
      "Epoch [80/300], Step [56/225], Training Accuracy: 96.7355%, Training Loss: 0.0892%\n",
      "Epoch [80/300], Step [57/225], Training Accuracy: 96.7105%, Training Loss: 0.0901%\n",
      "Epoch [80/300], Step [58/225], Training Accuracy: 96.7403%, Training Loss: 0.0897%\n",
      "Epoch [80/300], Step [59/225], Training Accuracy: 96.7426%, Training Loss: 0.0895%\n",
      "Epoch [80/300], Step [60/225], Training Accuracy: 96.7448%, Training Loss: 0.0898%\n",
      "Epoch [80/300], Step [61/225], Training Accuracy: 96.7725%, Training Loss: 0.0897%\n",
      "Epoch [80/300], Step [62/225], Training Accuracy: 96.7490%, Training Loss: 0.0904%\n",
      "Epoch [80/300], Step [63/225], Training Accuracy: 96.7758%, Training Loss: 0.0906%\n",
      "Epoch [80/300], Step [64/225], Training Accuracy: 96.7773%, Training Loss: 0.0910%\n",
      "Epoch [80/300], Step [65/225], Training Accuracy: 96.8029%, Training Loss: 0.0905%\n",
      "Epoch [80/300], Step [66/225], Training Accuracy: 96.7566%, Training Loss: 0.0912%\n",
      "Epoch [80/300], Step [67/225], Training Accuracy: 96.7584%, Training Loss: 0.0912%\n",
      "Epoch [80/300], Step [68/225], Training Accuracy: 96.7831%, Training Loss: 0.0905%\n",
      "Epoch [80/300], Step [69/225], Training Accuracy: 96.8297%, Training Loss: 0.0898%\n",
      "Epoch [80/300], Step [70/225], Training Accuracy: 96.8527%, Training Loss: 0.0893%\n",
      "Epoch [80/300], Step [71/225], Training Accuracy: 96.8310%, Training Loss: 0.0896%\n",
      "Epoch [80/300], Step [72/225], Training Accuracy: 96.8099%, Training Loss: 0.0904%\n",
      "Epoch [80/300], Step [73/225], Training Accuracy: 96.8108%, Training Loss: 0.0905%\n",
      "Epoch [80/300], Step [74/225], Training Accuracy: 96.7483%, Training Loss: 0.0917%\n",
      "Epoch [80/300], Step [75/225], Training Accuracy: 96.7917%, Training Loss: 0.0911%\n",
      "Epoch [80/300], Step [76/225], Training Accuracy: 96.7928%, Training Loss: 0.0913%\n",
      "Epoch [80/300], Step [77/225], Training Accuracy: 96.7735%, Training Loss: 0.0914%\n",
      "Epoch [80/300], Step [78/225], Training Accuracy: 96.7748%, Training Loss: 0.0912%\n",
      "Epoch [80/300], Step [79/225], Training Accuracy: 96.7761%, Training Loss: 0.0916%\n",
      "Epoch [80/300], Step [80/225], Training Accuracy: 96.7773%, Training Loss: 0.0913%\n",
      "Epoch [80/300], Step [81/225], Training Accuracy: 96.7785%, Training Loss: 0.0912%\n",
      "Epoch [80/300], Step [82/225], Training Accuracy: 96.7607%, Training Loss: 0.0921%\n",
      "Epoch [80/300], Step [83/225], Training Accuracy: 96.7620%, Training Loss: 0.0926%\n",
      "Epoch [80/300], Step [84/225], Training Accuracy: 96.7262%, Training Loss: 0.0938%\n",
      "Epoch [80/300], Step [85/225], Training Accuracy: 96.7096%, Training Loss: 0.0938%\n",
      "Epoch [80/300], Step [86/225], Training Accuracy: 96.6570%, Training Loss: 0.0943%\n",
      "Epoch [80/300], Step [87/225], Training Accuracy: 96.6595%, Training Loss: 0.0945%\n",
      "Epoch [80/300], Step [88/225], Training Accuracy: 96.6442%, Training Loss: 0.0945%\n",
      "Epoch [80/300], Step [89/225], Training Accuracy: 96.6292%, Training Loss: 0.0948%\n",
      "Epoch [80/300], Step [90/225], Training Accuracy: 96.6319%, Training Loss: 0.0946%\n",
      "Epoch [80/300], Step [91/225], Training Accuracy: 96.6174%, Training Loss: 0.0950%\n",
      "Epoch [80/300], Step [92/225], Training Accuracy: 96.5863%, Training Loss: 0.0956%\n",
      "Epoch [80/300], Step [93/225], Training Accuracy: 96.5894%, Training Loss: 0.0953%\n",
      "Epoch [80/300], Step [94/225], Training Accuracy: 96.6090%, Training Loss: 0.0947%\n",
      "Epoch [80/300], Step [95/225], Training Accuracy: 96.5789%, Training Loss: 0.0956%\n",
      "Epoch [80/300], Step [96/225], Training Accuracy: 96.5983%, Training Loss: 0.0951%\n",
      "Epoch [80/300], Step [97/225], Training Accuracy: 96.5851%, Training Loss: 0.0952%\n",
      "Epoch [80/300], Step [98/225], Training Accuracy: 96.5083%, Training Loss: 0.0961%\n",
      "Epoch [80/300], Step [99/225], Training Accuracy: 96.4804%, Training Loss: 0.0967%\n",
      "Epoch [80/300], Step [100/225], Training Accuracy: 96.4531%, Training Loss: 0.0975%\n",
      "Epoch [80/300], Step [101/225], Training Accuracy: 96.4728%, Training Loss: 0.0971%\n",
      "Epoch [80/300], Step [102/225], Training Accuracy: 96.4767%, Training Loss: 0.0968%\n",
      "Epoch [80/300], Step [103/225], Training Accuracy: 96.4654%, Training Loss: 0.0971%\n",
      "Epoch [80/300], Step [104/225], Training Accuracy: 96.4844%, Training Loss: 0.0966%\n",
      "Epoch [80/300], Step [105/225], Training Accuracy: 96.4881%, Training Loss: 0.0962%\n",
      "Epoch [80/300], Step [106/225], Training Accuracy: 96.4917%, Training Loss: 0.0961%\n",
      "Epoch [80/300], Step [107/225], Training Accuracy: 96.5099%, Training Loss: 0.0958%\n",
      "Epoch [80/300], Step [108/225], Training Accuracy: 96.4988%, Training Loss: 0.0960%\n",
      "Epoch [80/300], Step [109/225], Training Accuracy: 96.5023%, Training Loss: 0.0958%\n",
      "Epoch [80/300], Step [110/225], Training Accuracy: 96.5341%, Training Loss: 0.0952%\n",
      "Epoch [80/300], Step [111/225], Training Accuracy: 96.5231%, Training Loss: 0.0953%\n",
      "Epoch [80/300], Step [112/225], Training Accuracy: 96.5541%, Training Loss: 0.0947%\n",
      "Epoch [80/300], Step [113/225], Training Accuracy: 96.5570%, Training Loss: 0.0943%\n",
      "Epoch [80/300], Step [114/225], Training Accuracy: 96.5598%, Training Loss: 0.0943%\n",
      "Epoch [80/300], Step [115/225], Training Accuracy: 96.5897%, Training Loss: 0.0939%\n",
      "Epoch [80/300], Step [116/225], Training Accuracy: 96.5787%, Training Loss: 0.0942%\n",
      "Epoch [80/300], Step [117/225], Training Accuracy: 96.5545%, Training Loss: 0.0945%\n",
      "Epoch [80/300], Step [118/225], Training Accuracy: 96.5572%, Training Loss: 0.0943%\n",
      "Epoch [80/300], Step [119/225], Training Accuracy: 96.5730%, Training Loss: 0.0939%\n",
      "Epoch [80/300], Step [120/225], Training Accuracy: 96.5625%, Training Loss: 0.0941%\n",
      "Epoch [80/300], Step [121/225], Training Accuracy: 96.5780%, Training Loss: 0.0937%\n",
      "Epoch [80/300], Step [122/225], Training Accuracy: 96.5420%, Training Loss: 0.0938%\n",
      "Epoch [80/300], Step [123/225], Training Accuracy: 96.5320%, Training Loss: 0.0941%\n",
      "Epoch [80/300], Step [124/225], Training Accuracy: 96.5474%, Training Loss: 0.0938%\n",
      "Epoch [80/300], Step [125/225], Training Accuracy: 96.5250%, Training Loss: 0.0942%\n",
      "Epoch [80/300], Step [126/225], Training Accuracy: 96.5154%, Training Loss: 0.0943%\n",
      "Epoch [80/300], Step [127/225], Training Accuracy: 96.5305%, Training Loss: 0.0938%\n",
      "Epoch [80/300], Step [128/225], Training Accuracy: 96.5454%, Training Loss: 0.0935%\n",
      "Epoch [80/300], Step [129/225], Training Accuracy: 96.5480%, Training Loss: 0.0933%\n",
      "Epoch [80/300], Step [130/225], Training Accuracy: 96.5385%, Training Loss: 0.0935%\n",
      "Epoch [80/300], Step [131/225], Training Accuracy: 96.5530%, Training Loss: 0.0933%\n",
      "Epoch [80/300], Step [132/225], Training Accuracy: 96.5554%, Training Loss: 0.0933%\n",
      "Epoch [80/300], Step [133/225], Training Accuracy: 96.5578%, Training Loss: 0.0933%\n",
      "Epoch [80/300], Step [134/225], Training Accuracy: 96.5485%, Training Loss: 0.0932%\n",
      "Epoch [80/300], Step [135/225], Training Accuracy: 96.5625%, Training Loss: 0.0930%\n",
      "Epoch [80/300], Step [136/225], Training Accuracy: 96.5418%, Training Loss: 0.0933%\n",
      "Epoch [80/300], Step [137/225], Training Accuracy: 96.5443%, Training Loss: 0.0932%\n",
      "Epoch [80/300], Step [138/225], Training Accuracy: 96.5580%, Training Loss: 0.0930%\n",
      "Epoch [80/300], Step [139/225], Training Accuracy: 96.5715%, Training Loss: 0.0929%\n",
      "Epoch [80/300], Step [140/225], Training Accuracy: 96.5848%, Training Loss: 0.0931%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/300], Step [141/225], Training Accuracy: 96.5536%, Training Loss: 0.0938%\n",
      "Epoch [80/300], Step [142/225], Training Accuracy: 96.5669%, Training Loss: 0.0934%\n",
      "Epoch [80/300], Step [143/225], Training Accuracy: 96.5691%, Training Loss: 0.0934%\n",
      "Epoch [80/300], Step [144/225], Training Accuracy: 96.5495%, Training Loss: 0.0936%\n",
      "Epoch [80/300], Step [145/225], Training Accuracy: 96.5517%, Training Loss: 0.0934%\n",
      "Epoch [80/300], Step [146/225], Training Accuracy: 96.5646%, Training Loss: 0.0930%\n",
      "Epoch [80/300], Step [147/225], Training Accuracy: 96.5668%, Training Loss: 0.0929%\n",
      "Epoch [80/300], Step [148/225], Training Accuracy: 96.5583%, Training Loss: 0.0928%\n",
      "Epoch [80/300], Step [149/225], Training Accuracy: 96.5709%, Training Loss: 0.0928%\n",
      "Epoch [80/300], Step [150/225], Training Accuracy: 96.5729%, Training Loss: 0.0929%\n",
      "Epoch [80/300], Step [151/225], Training Accuracy: 96.5853%, Training Loss: 0.0926%\n",
      "Epoch [80/300], Step [152/225], Training Accuracy: 96.6077%, Training Loss: 0.0921%\n",
      "Epoch [80/300], Step [153/225], Training Accuracy: 96.6197%, Training Loss: 0.0919%\n",
      "Epoch [80/300], Step [154/225], Training Accuracy: 96.6416%, Training Loss: 0.0916%\n",
      "Epoch [80/300], Step [155/225], Training Accuracy: 96.6532%, Training Loss: 0.0915%\n",
      "Epoch [80/300], Step [156/225], Training Accuracy: 96.6647%, Training Loss: 0.0913%\n",
      "Epoch [80/300], Step [157/225], Training Accuracy: 96.6760%, Training Loss: 0.0912%\n",
      "Epoch [80/300], Step [158/225], Training Accuracy: 96.6673%, Training Loss: 0.0912%\n",
      "Epoch [80/300], Step [159/225], Training Accuracy: 96.6686%, Training Loss: 0.0913%\n",
      "Epoch [80/300], Step [160/225], Training Accuracy: 96.6797%, Training Loss: 0.0910%\n",
      "Epoch [80/300], Step [161/225], Training Accuracy: 96.6906%, Training Loss: 0.0910%\n",
      "Epoch [80/300], Step [162/225], Training Accuracy: 96.7014%, Training Loss: 0.0908%\n",
      "Epoch [80/300], Step [163/225], Training Accuracy: 96.6641%, Training Loss: 0.0913%\n",
      "Epoch [80/300], Step [164/225], Training Accuracy: 96.6749%, Training Loss: 0.0913%\n",
      "Epoch [80/300], Step [165/225], Training Accuracy: 96.6951%, Training Loss: 0.0910%\n",
      "Epoch [80/300], Step [166/225], Training Accuracy: 96.6867%, Training Loss: 0.0910%\n",
      "Epoch [80/300], Step [167/225], Training Accuracy: 96.6785%, Training Loss: 0.0910%\n",
      "Epoch [80/300], Step [168/225], Training Accuracy: 96.6890%, Training Loss: 0.0908%\n",
      "Epoch [80/300], Step [169/225], Training Accuracy: 96.6808%, Training Loss: 0.0910%\n",
      "Epoch [80/300], Step [170/225], Training Accuracy: 96.6820%, Training Loss: 0.0910%\n",
      "Epoch [80/300], Step [171/225], Training Accuracy: 96.6740%, Training Loss: 0.0910%\n",
      "Epoch [80/300], Step [172/225], Training Accuracy: 96.6751%, Training Loss: 0.0910%\n",
      "Epoch [80/300], Step [173/225], Training Accuracy: 96.6763%, Training Loss: 0.0912%\n",
      "Epoch [80/300], Step [174/225], Training Accuracy: 96.6774%, Training Loss: 0.0911%\n",
      "Epoch [80/300], Step [175/225], Training Accuracy: 96.6786%, Training Loss: 0.0910%\n",
      "Epoch [80/300], Step [176/225], Training Accuracy: 96.6797%, Training Loss: 0.0909%\n",
      "Epoch [80/300], Step [177/225], Training Accuracy: 96.6808%, Training Loss: 0.0911%\n",
      "Epoch [80/300], Step [178/225], Training Accuracy: 96.6819%, Training Loss: 0.0912%\n",
      "Epoch [80/300], Step [179/225], Training Accuracy: 96.6917%, Training Loss: 0.0909%\n",
      "Epoch [80/300], Step [180/225], Training Accuracy: 96.6927%, Training Loss: 0.0909%\n",
      "Epoch [80/300], Step [181/225], Training Accuracy: 96.7023%, Training Loss: 0.0908%\n",
      "Epoch [80/300], Step [182/225], Training Accuracy: 96.7119%, Training Loss: 0.0906%\n",
      "Epoch [80/300], Step [183/225], Training Accuracy: 96.7298%, Training Loss: 0.0903%\n",
      "Epoch [80/300], Step [184/225], Training Accuracy: 96.7391%, Training Loss: 0.0900%\n",
      "Epoch [80/300], Step [185/225], Training Accuracy: 96.7568%, Training Loss: 0.0896%\n",
      "Epoch [80/300], Step [186/225], Training Accuracy: 96.7742%, Training Loss: 0.0894%\n",
      "Epoch [80/300], Step [187/225], Training Accuracy: 96.7747%, Training Loss: 0.0893%\n",
      "Epoch [80/300], Step [188/225], Training Accuracy: 96.7670%, Training Loss: 0.0894%\n",
      "Epoch [80/300], Step [189/225], Training Accuracy: 96.7758%, Training Loss: 0.0893%\n",
      "Epoch [80/300], Step [190/225], Training Accuracy: 96.7681%, Training Loss: 0.0893%\n",
      "Epoch [80/300], Step [191/225], Training Accuracy: 96.7605%, Training Loss: 0.0893%\n",
      "Epoch [80/300], Step [192/225], Training Accuracy: 96.7611%, Training Loss: 0.0891%\n",
      "Epoch [80/300], Step [193/225], Training Accuracy: 96.7536%, Training Loss: 0.0897%\n",
      "Epoch [80/300], Step [194/225], Training Accuracy: 96.7703%, Training Loss: 0.0895%\n",
      "Epoch [80/300], Step [195/225], Training Accuracy: 96.7628%, Training Loss: 0.0894%\n",
      "Epoch [80/300], Step [196/225], Training Accuracy: 96.7793%, Training Loss: 0.0892%\n",
      "Epoch [80/300], Step [197/225], Training Accuracy: 96.7878%, Training Loss: 0.0892%\n",
      "Epoch [80/300], Step [198/225], Training Accuracy: 96.7724%, Training Loss: 0.0895%\n",
      "Epoch [80/300], Step [199/225], Training Accuracy: 96.7572%, Training Loss: 0.0900%\n",
      "Epoch [80/300], Step [200/225], Training Accuracy: 96.7500%, Training Loss: 0.0903%\n",
      "Epoch [80/300], Step [201/225], Training Accuracy: 96.7584%, Training Loss: 0.0902%\n",
      "Epoch [80/300], Step [202/225], Training Accuracy: 96.7667%, Training Loss: 0.0901%\n",
      "Epoch [80/300], Step [203/225], Training Accuracy: 96.7672%, Training Loss: 0.0902%\n",
      "Epoch [80/300], Step [204/225], Training Accuracy: 96.7601%, Training Loss: 0.0901%\n",
      "Epoch [80/300], Step [205/225], Training Accuracy: 96.7683%, Training Loss: 0.0899%\n",
      "Epoch [80/300], Step [206/225], Training Accuracy: 96.7461%, Training Loss: 0.0903%\n",
      "Epoch [80/300], Step [207/225], Training Accuracy: 96.7618%, Training Loss: 0.0901%\n",
      "Epoch [80/300], Step [208/225], Training Accuracy: 96.7623%, Training Loss: 0.0901%\n",
      "Epoch [80/300], Step [209/225], Training Accuracy: 96.7330%, Training Loss: 0.0905%\n",
      "Epoch [80/300], Step [210/225], Training Accuracy: 96.7113%, Training Loss: 0.0909%\n",
      "Epoch [80/300], Step [211/225], Training Accuracy: 96.6825%, Training Loss: 0.0910%\n",
      "Epoch [80/300], Step [212/225], Training Accuracy: 96.6760%, Training Loss: 0.0913%\n",
      "Epoch [80/300], Step [213/225], Training Accuracy: 96.6843%, Training Loss: 0.0912%\n",
      "Epoch [80/300], Step [214/225], Training Accuracy: 96.6779%, Training Loss: 0.0911%\n",
      "Epoch [80/300], Step [215/225], Training Accuracy: 96.6860%, Training Loss: 0.0913%\n",
      "Epoch [80/300], Step [216/225], Training Accuracy: 96.6725%, Training Loss: 0.0917%\n",
      "Epoch [80/300], Step [217/225], Training Accuracy: 96.6734%, Training Loss: 0.0916%\n",
      "Epoch [80/300], Step [218/225], Training Accuracy: 96.6671%, Training Loss: 0.0916%\n",
      "Epoch [80/300], Step [219/225], Training Accuracy: 96.6752%, Training Loss: 0.0913%\n",
      "Epoch [80/300], Step [220/225], Training Accuracy: 96.6761%, Training Loss: 0.0913%\n",
      "Epoch [80/300], Step [221/225], Training Accuracy: 96.6558%, Training Loss: 0.0916%\n",
      "Epoch [80/300], Step [222/225], Training Accuracy: 96.6357%, Training Loss: 0.0918%\n",
      "Epoch [80/300], Step [223/225], Training Accuracy: 96.6368%, Training Loss: 0.0917%\n",
      "Epoch [80/300], Step [224/225], Training Accuracy: 96.6378%, Training Loss: 0.0917%\n",
      "Epoch [80/300], Step [225/225], Training Accuracy: 96.6370%, Training Loss: 0.0916%\n",
      "Epoch [81/300], Step [1/225], Training Accuracy: 98.4375%, Training Loss: 0.0678%\n",
      "Epoch [81/300], Step [2/225], Training Accuracy: 97.6562%, Training Loss: 0.0782%\n",
      "Epoch [81/300], Step [3/225], Training Accuracy: 95.8333%, Training Loss: 0.1018%\n",
      "Epoch [81/300], Step [4/225], Training Accuracy: 96.4844%, Training Loss: 0.0879%\n",
      "Epoch [81/300], Step [5/225], Training Accuracy: 96.8750%, Training Loss: 0.0873%\n",
      "Epoch [81/300], Step [6/225], Training Accuracy: 96.6146%, Training Loss: 0.0886%\n",
      "Epoch [81/300], Step [7/225], Training Accuracy: 95.9821%, Training Loss: 0.0934%\n",
      "Epoch [81/300], Step [8/225], Training Accuracy: 95.3125%, Training Loss: 0.1007%\n",
      "Epoch [81/300], Step [9/225], Training Accuracy: 95.6597%, Training Loss: 0.0952%\n",
      "Epoch [81/300], Step [10/225], Training Accuracy: 95.1562%, Training Loss: 0.1127%\n",
      "Epoch [81/300], Step [11/225], Training Accuracy: 95.1705%, Training Loss: 0.1091%\n",
      "Epoch [81/300], Step [12/225], Training Accuracy: 95.4427%, Training Loss: 0.1046%\n",
      "Epoch [81/300], Step [13/225], Training Accuracy: 95.3125%, Training Loss: 0.1089%\n",
      "Epoch [81/300], Step [14/225], Training Accuracy: 95.4241%, Training Loss: 0.1087%\n",
      "Epoch [81/300], Step [15/225], Training Accuracy: 95.5208%, Training Loss: 0.1096%\n",
      "Epoch [81/300], Step [16/225], Training Accuracy: 95.5078%, Training Loss: 0.1109%\n",
      "Epoch [81/300], Step [17/225], Training Accuracy: 95.5882%, Training Loss: 0.1084%\n",
      "Epoch [81/300], Step [18/225], Training Accuracy: 95.3125%, Training Loss: 0.1177%\n",
      "Epoch [81/300], Step [19/225], Training Accuracy: 95.3947%, Training Loss: 0.1151%\n",
      "Epoch [81/300], Step [20/225], Training Accuracy: 95.4688%, Training Loss: 0.1136%\n",
      "Epoch [81/300], Step [21/225], Training Accuracy: 95.3869%, Training Loss: 0.1134%\n",
      "Epoch [81/300], Step [22/225], Training Accuracy: 95.4545%, Training Loss: 0.1125%\n",
      "Epoch [81/300], Step [23/225], Training Accuracy: 95.5842%, Training Loss: 0.1097%\n",
      "Epoch [81/300], Step [24/225], Training Accuracy: 95.6380%, Training Loss: 0.1085%\n",
      "Epoch [81/300], Step [25/225], Training Accuracy: 95.7500%, Training Loss: 0.1059%\n",
      "Epoch [81/300], Step [26/225], Training Accuracy: 95.8534%, Training Loss: 0.1061%\n",
      "Epoch [81/300], Step [27/225], Training Accuracy: 95.8912%, Training Loss: 0.1061%\n",
      "Epoch [81/300], Step [28/225], Training Accuracy: 96.0379%, Training Loss: 0.1033%\n",
      "Epoch [81/300], Step [29/225], Training Accuracy: 96.0129%, Training Loss: 0.1046%\n",
      "Epoch [81/300], Step [30/225], Training Accuracy: 96.0417%, Training Loss: 0.1036%\n",
      "Epoch [81/300], Step [31/225], Training Accuracy: 96.0181%, Training Loss: 0.1047%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/300], Step [32/225], Training Accuracy: 96.0449%, Training Loss: 0.1030%\n",
      "Epoch [81/300], Step [33/225], Training Accuracy: 96.0701%, Training Loss: 0.1028%\n",
      "Epoch [81/300], Step [34/225], Training Accuracy: 96.1397%, Training Loss: 0.1018%\n",
      "Epoch [81/300], Step [35/225], Training Accuracy: 96.2500%, Training Loss: 0.0999%\n",
      "Epoch [81/300], Step [36/225], Training Accuracy: 96.2240%, Training Loss: 0.0999%\n",
      "Epoch [81/300], Step [37/225], Training Accuracy: 96.3260%, Training Loss: 0.0982%\n",
      "Epoch [81/300], Step [38/225], Training Accuracy: 96.2171%, Training Loss: 0.0999%\n",
      "Epoch [81/300], Step [39/225], Training Accuracy: 96.1939%, Training Loss: 0.1002%\n",
      "Epoch [81/300], Step [40/225], Training Accuracy: 96.1719%, Training Loss: 0.1004%\n",
      "Epoch [81/300], Step [41/225], Training Accuracy: 96.1509%, Training Loss: 0.1003%\n",
      "Epoch [81/300], Step [42/225], Training Accuracy: 96.2426%, Training Loss: 0.0985%\n",
      "Epoch [81/300], Step [43/225], Training Accuracy: 96.2936%, Training Loss: 0.0973%\n",
      "Epoch [81/300], Step [44/225], Training Accuracy: 96.2358%, Training Loss: 0.0972%\n",
      "Epoch [81/300], Step [45/225], Training Accuracy: 96.2500%, Training Loss: 0.0970%\n",
      "Epoch [81/300], Step [46/225], Training Accuracy: 96.2296%, Training Loss: 0.0971%\n",
      "Epoch [81/300], Step [47/225], Training Accuracy: 96.2766%, Training Loss: 0.0963%\n",
      "Epoch [81/300], Step [48/225], Training Accuracy: 96.2565%, Training Loss: 0.0969%\n",
      "Epoch [81/300], Step [49/225], Training Accuracy: 96.2691%, Training Loss: 0.0961%\n",
      "Epoch [81/300], Step [50/225], Training Accuracy: 96.3125%, Training Loss: 0.0951%\n",
      "Epoch [81/300], Step [51/225], Training Accuracy: 96.2929%, Training Loss: 0.0950%\n",
      "Epoch [81/300], Step [52/225], Training Accuracy: 96.3041%, Training Loss: 0.0949%\n",
      "Epoch [81/300], Step [53/225], Training Accuracy: 96.3738%, Training Loss: 0.0936%\n",
      "Epoch [81/300], Step [54/225], Training Accuracy: 96.4410%, Training Loss: 0.0927%\n",
      "Epoch [81/300], Step [55/225], Training Accuracy: 96.4489%, Training Loss: 0.0929%\n",
      "Epoch [81/300], Step [56/225], Training Accuracy: 96.4007%, Training Loss: 0.0933%\n",
      "Epoch [81/300], Step [57/225], Training Accuracy: 96.3542%, Training Loss: 0.0940%\n",
      "Epoch [81/300], Step [58/225], Training Accuracy: 96.3631%, Training Loss: 0.0937%\n",
      "Epoch [81/300], Step [59/225], Training Accuracy: 96.3983%, Training Loss: 0.0926%\n",
      "Epoch [81/300], Step [60/225], Training Accuracy: 96.4062%, Training Loss: 0.0930%\n",
      "Epoch [81/300], Step [61/225], Training Accuracy: 96.3627%, Training Loss: 0.0933%\n",
      "Epoch [81/300], Step [62/225], Training Accuracy: 96.4214%, Training Loss: 0.0925%\n",
      "Epoch [81/300], Step [63/225], Training Accuracy: 96.4038%, Training Loss: 0.0935%\n",
      "Epoch [81/300], Step [64/225], Training Accuracy: 96.4355%, Training Loss: 0.0929%\n",
      "Epoch [81/300], Step [65/225], Training Accuracy: 96.4663%, Training Loss: 0.0923%\n",
      "Epoch [81/300], Step [66/225], Training Accuracy: 96.4962%, Training Loss: 0.0915%\n",
      "Epoch [81/300], Step [67/225], Training Accuracy: 96.4785%, Training Loss: 0.0918%\n",
      "Epoch [81/300], Step [68/225], Training Accuracy: 96.4844%, Training Loss: 0.0921%\n",
      "Epoch [81/300], Step [69/225], Training Accuracy: 96.5127%, Training Loss: 0.0914%\n",
      "Epoch [81/300], Step [70/225], Training Accuracy: 96.5625%, Training Loss: 0.0903%\n",
      "Epoch [81/300], Step [71/225], Training Accuracy: 96.5669%, Training Loss: 0.0902%\n",
      "Epoch [81/300], Step [72/225], Training Accuracy: 96.5495%, Training Loss: 0.0904%\n",
      "Epoch [81/300], Step [73/225], Training Accuracy: 96.5111%, Training Loss: 0.0914%\n",
      "Epoch [81/300], Step [74/225], Training Accuracy: 96.5160%, Training Loss: 0.0909%\n",
      "Epoch [81/300], Step [75/225], Training Accuracy: 96.5000%, Training Loss: 0.0910%\n",
      "Epoch [81/300], Step [76/225], Training Accuracy: 96.5255%, Training Loss: 0.0904%\n",
      "Epoch [81/300], Step [77/225], Training Accuracy: 96.5503%, Training Loss: 0.0904%\n",
      "Epoch [81/300], Step [78/225], Training Accuracy: 96.5345%, Training Loss: 0.0906%\n",
      "Epoch [81/300], Step [79/225], Training Accuracy: 96.5388%, Training Loss: 0.0904%\n",
      "Epoch [81/300], Step [80/225], Training Accuracy: 96.5430%, Training Loss: 0.0922%\n",
      "Epoch [81/300], Step [81/225], Training Accuracy: 96.4892%, Training Loss: 0.0932%\n",
      "Epoch [81/300], Step [82/225], Training Accuracy: 96.4558%, Training Loss: 0.0934%\n",
      "Epoch [81/300], Step [83/225], Training Accuracy: 96.4232%, Training Loss: 0.0939%\n",
      "Epoch [81/300], Step [84/225], Training Accuracy: 96.3914%, Training Loss: 0.0947%\n",
      "Epoch [81/300], Step [85/225], Training Accuracy: 96.4154%, Training Loss: 0.0943%\n",
      "Epoch [81/300], Step [86/225], Training Accuracy: 96.4390%, Training Loss: 0.0944%\n",
      "Epoch [81/300], Step [87/225], Training Accuracy: 96.4260%, Training Loss: 0.0947%\n",
      "Epoch [81/300], Step [88/225], Training Accuracy: 96.4489%, Training Loss: 0.0947%\n",
      "Epoch [81/300], Step [89/225], Training Accuracy: 96.4185%, Training Loss: 0.0949%\n",
      "Epoch [81/300], Step [90/225], Training Accuracy: 96.4062%, Training Loss: 0.0949%\n",
      "Epoch [81/300], Step [91/225], Training Accuracy: 96.3771%, Training Loss: 0.0951%\n",
      "Epoch [81/300], Step [92/225], Training Accuracy: 96.4164%, Training Loss: 0.0944%\n",
      "Epoch [81/300], Step [93/225], Training Accuracy: 96.4382%, Training Loss: 0.0939%\n",
      "Epoch [81/300], Step [94/225], Training Accuracy: 96.4262%, Training Loss: 0.0940%\n",
      "Epoch [81/300], Step [95/225], Training Accuracy: 96.3816%, Training Loss: 0.0944%\n",
      "Epoch [81/300], Step [96/225], Training Accuracy: 96.3704%, Training Loss: 0.0948%\n",
      "Epoch [81/300], Step [97/225], Training Accuracy: 96.3918%, Training Loss: 0.0944%\n",
      "Epoch [81/300], Step [98/225], Training Accuracy: 96.3807%, Training Loss: 0.0950%\n",
      "Epoch [81/300], Step [99/225], Training Accuracy: 96.3699%, Training Loss: 0.0951%\n",
      "Epoch [81/300], Step [100/225], Training Accuracy: 96.3594%, Training Loss: 0.0953%\n",
      "Epoch [81/300], Step [101/225], Training Accuracy: 96.3645%, Training Loss: 0.0953%\n",
      "Epoch [81/300], Step [102/225], Training Accuracy: 96.3848%, Training Loss: 0.0950%\n",
      "Epoch [81/300], Step [103/225], Training Accuracy: 96.4047%, Training Loss: 0.0947%\n",
      "Epoch [81/300], Step [104/225], Training Accuracy: 96.3942%, Training Loss: 0.0945%\n",
      "Epoch [81/300], Step [105/225], Training Accuracy: 96.4137%, Training Loss: 0.0941%\n",
      "Epoch [81/300], Step [106/225], Training Accuracy: 96.4475%, Training Loss: 0.0937%\n",
      "Epoch [81/300], Step [107/225], Training Accuracy: 96.4369%, Training Loss: 0.0937%\n",
      "Epoch [81/300], Step [108/225], Training Accuracy: 96.4554%, Training Loss: 0.0934%\n",
      "Epoch [81/300], Step [109/225], Training Accuracy: 96.4880%, Training Loss: 0.0931%\n",
      "Epoch [81/300], Step [110/225], Training Accuracy: 96.4915%, Training Loss: 0.0928%\n",
      "Epoch [81/300], Step [111/225], Training Accuracy: 96.5090%, Training Loss: 0.0925%\n",
      "Epoch [81/300], Step [112/225], Training Accuracy: 96.5123%, Training Loss: 0.0924%\n",
      "Epoch [81/300], Step [113/225], Training Accuracy: 96.5017%, Training Loss: 0.0925%\n",
      "Epoch [81/300], Step [114/225], Training Accuracy: 96.4501%, Training Loss: 0.0933%\n",
      "Epoch [81/300], Step [115/225], Training Accuracy: 96.4674%, Training Loss: 0.0929%\n",
      "Epoch [81/300], Step [116/225], Training Accuracy: 96.4978%, Training Loss: 0.0925%\n",
      "Epoch [81/300], Step [117/225], Training Accuracy: 96.5011%, Training Loss: 0.0922%\n",
      "Epoch [81/300], Step [118/225], Training Accuracy: 96.4910%, Training Loss: 0.0921%\n",
      "Epoch [81/300], Step [119/225], Training Accuracy: 96.4811%, Training Loss: 0.0925%\n",
      "Epoch [81/300], Step [120/225], Training Accuracy: 96.4974%, Training Loss: 0.0922%\n",
      "Epoch [81/300], Step [121/225], Training Accuracy: 96.5263%, Training Loss: 0.0919%\n",
      "Epoch [81/300], Step [122/225], Training Accuracy: 96.5292%, Training Loss: 0.0921%\n",
      "Epoch [81/300], Step [123/225], Training Accuracy: 96.5066%, Training Loss: 0.0932%\n",
      "Epoch [81/300], Step [124/225], Training Accuracy: 96.5222%, Training Loss: 0.0928%\n",
      "Epoch [81/300], Step [125/225], Training Accuracy: 96.5375%, Training Loss: 0.0924%\n",
      "Epoch [81/300], Step [126/225], Training Accuracy: 96.5526%, Training Loss: 0.0923%\n",
      "Epoch [81/300], Step [127/225], Training Accuracy: 96.5428%, Training Loss: 0.0921%\n",
      "Epoch [81/300], Step [128/225], Training Accuracy: 96.5576%, Training Loss: 0.0921%\n",
      "Epoch [81/300], Step [129/225], Training Accuracy: 96.5237%, Training Loss: 0.0929%\n",
      "Epoch [81/300], Step [130/225], Training Accuracy: 96.5385%, Training Loss: 0.0927%\n",
      "Epoch [81/300], Step [131/225], Training Accuracy: 96.5649%, Training Loss: 0.0924%\n",
      "Epoch [81/300], Step [132/225], Training Accuracy: 96.5436%, Training Loss: 0.0927%\n",
      "Epoch [81/300], Step [133/225], Training Accuracy: 96.5343%, Training Loss: 0.0927%\n",
      "Epoch [81/300], Step [134/225], Training Accuracy: 96.5485%, Training Loss: 0.0924%\n",
      "Epoch [81/300], Step [135/225], Training Accuracy: 96.5741%, Training Loss: 0.0920%\n",
      "Epoch [81/300], Step [136/225], Training Accuracy: 96.5763%, Training Loss: 0.0920%\n",
      "Epoch [81/300], Step [137/225], Training Accuracy: 96.5785%, Training Loss: 0.0919%\n",
      "Epoch [81/300], Step [138/225], Training Accuracy: 96.5580%, Training Loss: 0.0923%\n",
      "Epoch [81/300], Step [139/225], Training Accuracy: 96.5490%, Training Loss: 0.0925%\n",
      "Epoch [81/300], Step [140/225], Training Accuracy: 96.5290%, Training Loss: 0.0927%\n",
      "Epoch [81/300], Step [141/225], Training Accuracy: 96.5204%, Training Loss: 0.0926%\n",
      "Epoch [81/300], Step [142/225], Training Accuracy: 96.5339%, Training Loss: 0.0923%\n",
      "Epoch [81/300], Step [143/225], Training Accuracy: 96.5363%, Training Loss: 0.0921%\n",
      "Epoch [81/300], Step [144/225], Training Accuracy: 96.5495%, Training Loss: 0.0920%\n",
      "Epoch [81/300], Step [145/225], Training Accuracy: 96.5517%, Training Loss: 0.0918%\n",
      "Epoch [81/300], Step [146/225], Training Accuracy: 96.5646%, Training Loss: 0.0914%\n",
      "Epoch [81/300], Step [147/225], Training Accuracy: 96.5455%, Training Loss: 0.0919%\n",
      "Epoch [81/300], Step [148/225], Training Accuracy: 96.5688%, Training Loss: 0.0915%\n",
      "Epoch [81/300], Step [149/225], Training Accuracy: 96.5394%, Training Loss: 0.0923%\n",
      "Epoch [81/300], Step [150/225], Training Accuracy: 96.5312%, Training Loss: 0.0926%\n",
      "Epoch [81/300], Step [151/225], Training Accuracy: 96.5439%, Training Loss: 0.0924%\n",
      "Epoch [81/300], Step [152/225], Training Accuracy: 96.5563%, Training Loss: 0.0923%\n",
      "Epoch [81/300], Step [153/225], Training Accuracy: 96.5584%, Training Loss: 0.0921%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/300], Step [154/225], Training Accuracy: 96.5402%, Training Loss: 0.0925%\n",
      "Epoch [81/300], Step [155/225], Training Accuracy: 96.5423%, Training Loss: 0.0923%\n",
      "Epoch [81/300], Step [156/225], Training Accuracy: 96.5445%, Training Loss: 0.0926%\n",
      "Epoch [81/300], Step [157/225], Training Accuracy: 96.5466%, Training Loss: 0.0924%\n",
      "Epoch [81/300], Step [158/225], Training Accuracy: 96.5585%, Training Loss: 0.0922%\n",
      "Epoch [81/300], Step [159/225], Training Accuracy: 96.5704%, Training Loss: 0.0921%\n",
      "Epoch [81/300], Step [160/225], Training Accuracy: 96.5625%, Training Loss: 0.0921%\n",
      "Epoch [81/300], Step [161/225], Training Accuracy: 96.5741%, Training Loss: 0.0919%\n",
      "Epoch [81/300], Step [162/225], Training Accuracy: 96.5471%, Training Loss: 0.0925%\n",
      "Epoch [81/300], Step [163/225], Training Accuracy: 96.5395%, Training Loss: 0.0928%\n",
      "Epoch [81/300], Step [164/225], Training Accuracy: 96.5511%, Training Loss: 0.0926%\n",
      "Epoch [81/300], Step [165/225], Training Accuracy: 96.5625%, Training Loss: 0.0926%\n",
      "Epoch [81/300], Step [166/225], Training Accuracy: 96.5456%, Training Loss: 0.0929%\n",
      "Epoch [81/300], Step [167/225], Training Accuracy: 96.5288%, Training Loss: 0.0930%\n",
      "Epoch [81/300], Step [168/225], Training Accuracy: 96.5402%, Training Loss: 0.0927%\n",
      "Epoch [81/300], Step [169/225], Training Accuracy: 96.5329%, Training Loss: 0.0928%\n",
      "Epoch [81/300], Step [170/225], Training Accuracy: 96.5441%, Training Loss: 0.0928%\n",
      "Epoch [81/300], Step [171/225], Training Accuracy: 96.5369%, Training Loss: 0.0932%\n",
      "Epoch [81/300], Step [172/225], Training Accuracy: 96.5298%, Training Loss: 0.0932%\n",
      "Epoch [81/300], Step [173/225], Training Accuracy: 96.5318%, Training Loss: 0.0931%\n",
      "Epoch [81/300], Step [174/225], Training Accuracy: 96.5517%, Training Loss: 0.0928%\n",
      "Epoch [81/300], Step [175/225], Training Accuracy: 96.5357%, Training Loss: 0.0935%\n",
      "Epoch [81/300], Step [176/225], Training Accuracy: 96.5376%, Training Loss: 0.0934%\n",
      "Epoch [81/300], Step [177/225], Training Accuracy: 96.5219%, Training Loss: 0.0935%\n",
      "Epoch [81/300], Step [178/225], Training Accuracy: 96.5151%, Training Loss: 0.0935%\n",
      "Epoch [81/300], Step [179/225], Training Accuracy: 96.5171%, Training Loss: 0.0935%\n",
      "Epoch [81/300], Step [180/225], Training Accuracy: 96.5191%, Training Loss: 0.0935%\n",
      "Epoch [81/300], Step [181/225], Training Accuracy: 96.5124%, Training Loss: 0.0937%\n",
      "Epoch [81/300], Step [182/225], Training Accuracy: 96.4715%, Training Loss: 0.0947%\n",
      "Epoch [81/300], Step [183/225], Training Accuracy: 96.4908%, Training Loss: 0.0943%\n",
      "Epoch [81/300], Step [184/225], Training Accuracy: 96.4929%, Training Loss: 0.0942%\n",
      "Epoch [81/300], Step [185/225], Training Accuracy: 96.4949%, Training Loss: 0.0940%\n",
      "Epoch [81/300], Step [186/225], Training Accuracy: 96.5138%, Training Loss: 0.0938%\n",
      "Epoch [81/300], Step [187/225], Training Accuracy: 96.5241%, Training Loss: 0.0937%\n",
      "Epoch [81/300], Step [188/225], Training Accuracy: 96.5259%, Training Loss: 0.0938%\n",
      "Epoch [81/300], Step [189/225], Training Accuracy: 96.5278%, Training Loss: 0.0939%\n",
      "Epoch [81/300], Step [190/225], Training Accuracy: 96.5214%, Training Loss: 0.0940%\n",
      "Epoch [81/300], Step [191/225], Training Accuracy: 96.5314%, Training Loss: 0.0938%\n",
      "Epoch [81/300], Step [192/225], Training Accuracy: 96.5495%, Training Loss: 0.0935%\n",
      "Epoch [81/300], Step [193/225], Training Accuracy: 96.5512%, Training Loss: 0.0935%\n",
      "Epoch [81/300], Step [194/225], Training Accuracy: 96.5609%, Training Loss: 0.0935%\n",
      "Epoch [81/300], Step [195/225], Training Accuracy: 96.5705%, Training Loss: 0.0935%\n",
      "Epoch [81/300], Step [196/225], Training Accuracy: 96.5800%, Training Loss: 0.0933%\n",
      "Epoch [81/300], Step [197/225], Training Accuracy: 96.5736%, Training Loss: 0.0933%\n",
      "Epoch [81/300], Step [198/225], Training Accuracy: 96.5672%, Training Loss: 0.0933%\n",
      "Epoch [81/300], Step [199/225], Training Accuracy: 96.5688%, Training Loss: 0.0931%\n",
      "Epoch [81/300], Step [200/225], Training Accuracy: 96.5781%, Training Loss: 0.0930%\n",
      "Epoch [81/300], Step [201/225], Training Accuracy: 96.5874%, Training Loss: 0.0927%\n",
      "Epoch [81/300], Step [202/225], Training Accuracy: 96.5811%, Training Loss: 0.0927%\n",
      "Epoch [81/300], Step [203/225], Training Accuracy: 96.5671%, Training Loss: 0.0928%\n",
      "Epoch [81/300], Step [204/225], Training Accuracy: 96.5686%, Training Loss: 0.0927%\n",
      "Epoch [81/300], Step [205/225], Training Accuracy: 96.5777%, Training Loss: 0.0924%\n",
      "Epoch [81/300], Step [206/225], Training Accuracy: 96.5792%, Training Loss: 0.0925%\n",
      "Epoch [81/300], Step [207/225], Training Accuracy: 96.5882%, Training Loss: 0.0924%\n",
      "Epoch [81/300], Step [208/225], Training Accuracy: 96.5971%, Training Loss: 0.0923%\n",
      "Epoch [81/300], Step [209/225], Training Accuracy: 96.5909%, Training Loss: 0.0928%\n",
      "Epoch [81/300], Step [210/225], Training Accuracy: 96.6071%, Training Loss: 0.0926%\n",
      "Epoch [81/300], Step [211/225], Training Accuracy: 96.6158%, Training Loss: 0.0925%\n",
      "Epoch [81/300], Step [212/225], Training Accuracy: 96.6097%, Training Loss: 0.0926%\n",
      "Epoch [81/300], Step [213/225], Training Accuracy: 96.6109%, Training Loss: 0.0926%\n",
      "Epoch [81/300], Step [214/225], Training Accuracy: 96.6195%, Training Loss: 0.0925%\n",
      "Epoch [81/300], Step [215/225], Training Accuracy: 96.6279%, Training Loss: 0.0924%\n",
      "Epoch [81/300], Step [216/225], Training Accuracy: 96.6218%, Training Loss: 0.0923%\n",
      "Epoch [81/300], Step [217/225], Training Accuracy: 96.6158%, Training Loss: 0.0924%\n",
      "Epoch [81/300], Step [218/225], Training Accuracy: 96.6313%, Training Loss: 0.0922%\n",
      "Epoch [81/300], Step [219/225], Training Accuracy: 96.6467%, Training Loss: 0.0919%\n",
      "Epoch [81/300], Step [220/225], Training Accuracy: 96.6548%, Training Loss: 0.0918%\n",
      "Epoch [81/300], Step [221/225], Training Accuracy: 96.6629%, Training Loss: 0.0916%\n",
      "Epoch [81/300], Step [222/225], Training Accuracy: 96.6639%, Training Loss: 0.0916%\n",
      "Epoch [81/300], Step [223/225], Training Accuracy: 96.6718%, Training Loss: 0.0914%\n",
      "Epoch [81/300], Step [224/225], Training Accuracy: 96.6727%, Training Loss: 0.0912%\n",
      "Epoch [81/300], Step [225/225], Training Accuracy: 96.6648%, Training Loss: 0.0917%\n",
      "Epoch [82/300], Step [1/225], Training Accuracy: 98.4375%, Training Loss: 0.0933%\n",
      "Epoch [82/300], Step [2/225], Training Accuracy: 96.8750%, Training Loss: 0.1062%\n",
      "Epoch [82/300], Step [3/225], Training Accuracy: 96.3542%, Training Loss: 0.1006%\n",
      "Epoch [82/300], Step [4/225], Training Accuracy: 97.2656%, Training Loss: 0.0889%\n",
      "Epoch [82/300], Step [5/225], Training Accuracy: 97.8125%, Training Loss: 0.0761%\n",
      "Epoch [82/300], Step [6/225], Training Accuracy: 97.9167%, Training Loss: 0.0740%\n",
      "Epoch [82/300], Step [7/225], Training Accuracy: 97.7679%, Training Loss: 0.0756%\n",
      "Epoch [82/300], Step [8/225], Training Accuracy: 98.0469%, Training Loss: 0.0713%\n",
      "Epoch [82/300], Step [9/225], Training Accuracy: 97.9167%, Training Loss: 0.0722%\n",
      "Epoch [82/300], Step [10/225], Training Accuracy: 97.3438%, Training Loss: 0.0810%\n",
      "Epoch [82/300], Step [11/225], Training Accuracy: 96.8750%, Training Loss: 0.0884%\n",
      "Epoch [82/300], Step [12/225], Training Accuracy: 97.0052%, Training Loss: 0.0911%\n",
      "Epoch [82/300], Step [13/225], Training Accuracy: 96.7548%, Training Loss: 0.0964%\n",
      "Epoch [82/300], Step [14/225], Training Accuracy: 96.7634%, Training Loss: 0.0999%\n",
      "Epoch [82/300], Step [15/225], Training Accuracy: 96.8750%, Training Loss: 0.0967%\n",
      "Epoch [82/300], Step [16/225], Training Accuracy: 96.7773%, Training Loss: 0.0970%\n",
      "Epoch [82/300], Step [17/225], Training Accuracy: 96.8750%, Training Loss: 0.0944%\n",
      "Epoch [82/300], Step [18/225], Training Accuracy: 96.7014%, Training Loss: 0.1000%\n",
      "Epoch [82/300], Step [19/225], Training Accuracy: 96.7928%, Training Loss: 0.0976%\n",
      "Epoch [82/300], Step [20/225], Training Accuracy: 96.7969%, Training Loss: 0.0964%\n",
      "Epoch [82/300], Step [21/225], Training Accuracy: 96.7262%, Training Loss: 0.0954%\n",
      "Epoch [82/300], Step [22/225], Training Accuracy: 96.5909%, Training Loss: 0.0976%\n",
      "Epoch [82/300], Step [23/225], Training Accuracy: 96.3995%, Training Loss: 0.0998%\n",
      "Epoch [82/300], Step [24/225], Training Accuracy: 96.3542%, Training Loss: 0.1001%\n",
      "Epoch [82/300], Step [25/225], Training Accuracy: 96.4375%, Training Loss: 0.0993%\n",
      "Epoch [82/300], Step [26/225], Training Accuracy: 96.2740%, Training Loss: 0.1007%\n",
      "Epoch [82/300], Step [27/225], Training Accuracy: 96.2384%, Training Loss: 0.1024%\n",
      "Epoch [82/300], Step [28/225], Training Accuracy: 96.3170%, Training Loss: 0.1007%\n",
      "Epoch [82/300], Step [29/225], Training Accuracy: 96.1746%, Training Loss: 0.1020%\n",
      "Epoch [82/300], Step [30/225], Training Accuracy: 96.1458%, Training Loss: 0.1023%\n",
      "Epoch [82/300], Step [31/225], Training Accuracy: 96.2702%, Training Loss: 0.1003%\n",
      "Epoch [82/300], Step [32/225], Training Accuracy: 96.2891%, Training Loss: 0.1006%\n",
      "Epoch [82/300], Step [33/225], Training Accuracy: 96.3542%, Training Loss: 0.0996%\n",
      "Epoch [82/300], Step [34/225], Training Accuracy: 96.3695%, Training Loss: 0.0989%\n",
      "Epoch [82/300], Step [35/225], Training Accuracy: 96.3393%, Training Loss: 0.1009%\n",
      "Epoch [82/300], Step [36/225], Training Accuracy: 96.4410%, Training Loss: 0.0992%\n",
      "Epoch [82/300], Step [37/225], Training Accuracy: 96.5372%, Training Loss: 0.0972%\n",
      "Epoch [82/300], Step [38/225], Training Accuracy: 96.5872%, Training Loss: 0.0972%\n",
      "Epoch [82/300], Step [39/225], Training Accuracy: 96.5545%, Training Loss: 0.0972%\n",
      "Epoch [82/300], Step [40/225], Training Accuracy: 96.5625%, Training Loss: 0.0965%\n",
      "Epoch [82/300], Step [41/225], Training Accuracy: 96.6082%, Training Loss: 0.0966%\n",
      "Epoch [82/300], Step [42/225], Training Accuracy: 96.6518%, Training Loss: 0.0959%\n",
      "Epoch [82/300], Step [43/225], Training Accuracy: 96.6570%, Training Loss: 0.0963%\n",
      "Epoch [82/300], Step [44/225], Training Accuracy: 96.6264%, Training Loss: 0.0973%\n",
      "Epoch [82/300], Step [45/225], Training Accuracy: 96.4931%, Training Loss: 0.0991%\n",
      "Epoch [82/300], Step [46/225], Training Accuracy: 96.4674%, Training Loss: 0.0986%\n",
      "Epoch [82/300], Step [47/225], Training Accuracy: 96.5426%, Training Loss: 0.0977%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/300], Step [48/225], Training Accuracy: 96.5820%, Training Loss: 0.0978%\n",
      "Epoch [82/300], Step [49/225], Training Accuracy: 96.4286%, Training Loss: 0.1009%\n",
      "Epoch [82/300], Step [50/225], Training Accuracy: 96.4062%, Training Loss: 0.1004%\n",
      "Epoch [82/300], Step [51/225], Training Accuracy: 96.3235%, Training Loss: 0.1019%\n",
      "Epoch [82/300], Step [52/225], Training Accuracy: 96.3942%, Training Loss: 0.1007%\n",
      "Epoch [82/300], Step [53/225], Training Accuracy: 96.3738%, Training Loss: 0.1005%\n",
      "Epoch [82/300], Step [54/225], Training Accuracy: 96.3831%, Training Loss: 0.1000%\n",
      "Epoch [82/300], Step [55/225], Training Accuracy: 96.3920%, Training Loss: 0.0994%\n",
      "Epoch [82/300], Step [56/225], Training Accuracy: 96.3170%, Training Loss: 0.1008%\n",
      "Epoch [82/300], Step [57/225], Training Accuracy: 96.3542%, Training Loss: 0.0999%\n",
      "Epoch [82/300], Step [58/225], Training Accuracy: 96.4170%, Training Loss: 0.0990%\n",
      "Epoch [82/300], Step [59/225], Training Accuracy: 96.4248%, Training Loss: 0.0983%\n",
      "Epoch [82/300], Step [60/225], Training Accuracy: 96.4844%, Training Loss: 0.0970%\n",
      "Epoch [82/300], Step [61/225], Training Accuracy: 96.4395%, Training Loss: 0.0979%\n",
      "Epoch [82/300], Step [62/225], Training Accuracy: 96.4466%, Training Loss: 0.0981%\n",
      "Epoch [82/300], Step [63/225], Training Accuracy: 96.4286%, Training Loss: 0.0977%\n",
      "Epoch [82/300], Step [64/225], Training Accuracy: 96.4844%, Training Loss: 0.0967%\n",
      "Epoch [82/300], Step [65/225], Training Accuracy: 96.4904%, Training Loss: 0.0971%\n",
      "Epoch [82/300], Step [66/225], Training Accuracy: 96.5199%, Training Loss: 0.0967%\n",
      "Epoch [82/300], Step [67/225], Training Accuracy: 96.4785%, Training Loss: 0.0970%\n",
      "Epoch [82/300], Step [68/225], Training Accuracy: 96.5303%, Training Loss: 0.0959%\n",
      "Epoch [82/300], Step [69/225], Training Accuracy: 96.5127%, Training Loss: 0.0961%\n",
      "Epoch [82/300], Step [70/225], Training Accuracy: 96.4955%, Training Loss: 0.0966%\n",
      "Epoch [82/300], Step [71/225], Training Accuracy: 96.4789%, Training Loss: 0.0972%\n",
      "Epoch [82/300], Step [72/225], Training Accuracy: 96.4627%, Training Loss: 0.0983%\n",
      "Epoch [82/300], Step [73/225], Training Accuracy: 96.4683%, Training Loss: 0.0979%\n",
      "Epoch [82/300], Step [74/225], Training Accuracy: 96.5160%, Training Loss: 0.0969%\n",
      "Epoch [82/300], Step [75/225], Training Accuracy: 96.5208%, Training Loss: 0.0966%\n",
      "Epoch [82/300], Step [76/225], Training Accuracy: 96.5255%, Training Loss: 0.0975%\n",
      "Epoch [82/300], Step [77/225], Training Accuracy: 96.5503%, Training Loss: 0.0971%\n",
      "Epoch [82/300], Step [78/225], Training Accuracy: 96.4944%, Training Loss: 0.0978%\n",
      "Epoch [82/300], Step [79/225], Training Accuracy: 96.5388%, Training Loss: 0.0972%\n",
      "Epoch [82/300], Step [80/225], Training Accuracy: 96.5430%, Training Loss: 0.0973%\n",
      "Epoch [82/300], Step [81/225], Training Accuracy: 96.5856%, Training Loss: 0.0965%\n",
      "Epoch [82/300], Step [82/225], Training Accuracy: 96.6082%, Training Loss: 0.0963%\n",
      "Epoch [82/300], Step [83/225], Training Accuracy: 96.5926%, Training Loss: 0.0962%\n",
      "Epoch [82/300], Step [84/225], Training Accuracy: 96.5588%, Training Loss: 0.0967%\n",
      "Epoch [82/300], Step [85/225], Training Accuracy: 96.5993%, Training Loss: 0.0960%\n",
      "Epoch [82/300], Step [86/225], Training Accuracy: 96.6206%, Training Loss: 0.0956%\n",
      "Epoch [82/300], Step [87/225], Training Accuracy: 96.5697%, Training Loss: 0.0961%\n",
      "Epoch [82/300], Step [88/225], Training Accuracy: 96.5732%, Training Loss: 0.0957%\n",
      "Epoch [82/300], Step [89/225], Training Accuracy: 96.5063%, Training Loss: 0.0963%\n",
      "Epoch [82/300], Step [90/225], Training Accuracy: 96.5278%, Training Loss: 0.0959%\n",
      "Epoch [82/300], Step [91/225], Training Accuracy: 96.5659%, Training Loss: 0.0954%\n",
      "Epoch [82/300], Step [92/225], Training Accuracy: 96.5523%, Training Loss: 0.0952%\n",
      "Epoch [82/300], Step [93/225], Training Accuracy: 96.5726%, Training Loss: 0.0946%\n",
      "Epoch [82/300], Step [94/225], Training Accuracy: 96.5924%, Training Loss: 0.0941%\n",
      "Epoch [82/300], Step [95/225], Training Accuracy: 96.5296%, Training Loss: 0.0952%\n",
      "Epoch [82/300], Step [96/225], Training Accuracy: 96.5658%, Training Loss: 0.0947%\n",
      "Epoch [82/300], Step [97/225], Training Accuracy: 96.5851%, Training Loss: 0.0943%\n",
      "Epoch [82/300], Step [98/225], Training Accuracy: 96.5721%, Training Loss: 0.0945%\n",
      "Epoch [82/300], Step [99/225], Training Accuracy: 96.5593%, Training Loss: 0.0942%\n",
      "Epoch [82/300], Step [100/225], Training Accuracy: 96.5781%, Training Loss: 0.0936%\n",
      "Epoch [82/300], Step [101/225], Training Accuracy: 96.6120%, Training Loss: 0.0931%\n",
      "Epoch [82/300], Step [102/225], Training Accuracy: 96.6452%, Training Loss: 0.0926%\n",
      "Epoch [82/300], Step [103/225], Training Accuracy: 96.6019%, Training Loss: 0.0928%\n",
      "Epoch [82/300], Step [104/225], Training Accuracy: 96.5895%, Training Loss: 0.0929%\n",
      "Epoch [82/300], Step [105/225], Training Accuracy: 96.5774%, Training Loss: 0.0929%\n",
      "Epoch [82/300], Step [106/225], Training Accuracy: 96.5949%, Training Loss: 0.0926%\n",
      "Epoch [82/300], Step [107/225], Training Accuracy: 96.5975%, Training Loss: 0.0930%\n",
      "Epoch [82/300], Step [108/225], Training Accuracy: 96.6001%, Training Loss: 0.0931%\n",
      "Epoch [82/300], Step [109/225], Training Accuracy: 96.6313%, Training Loss: 0.0926%\n",
      "Epoch [82/300], Step [110/225], Training Accuracy: 96.6619%, Training Loss: 0.0922%\n",
      "Epoch [82/300], Step [111/225], Training Accuracy: 96.6639%, Training Loss: 0.0921%\n",
      "Epoch [82/300], Step [112/225], Training Accuracy: 96.6657%, Training Loss: 0.0922%\n",
      "Epoch [82/300], Step [113/225], Training Accuracy: 96.6814%, Training Loss: 0.0919%\n",
      "Epoch [82/300], Step [114/225], Training Accuracy: 96.6557%, Training Loss: 0.0921%\n",
      "Epoch [82/300], Step [115/225], Training Accuracy: 96.6576%, Training Loss: 0.0920%\n",
      "Epoch [82/300], Step [116/225], Training Accuracy: 96.6730%, Training Loss: 0.0920%\n",
      "Epoch [82/300], Step [117/225], Training Accuracy: 96.6747%, Training Loss: 0.0921%\n",
      "Epoch [82/300], Step [118/225], Training Accuracy: 96.6896%, Training Loss: 0.0918%\n",
      "Epoch [82/300], Step [119/225], Training Accuracy: 96.6780%, Training Loss: 0.0920%\n",
      "Epoch [82/300], Step [120/225], Training Accuracy: 96.6927%, Training Loss: 0.0915%\n",
      "Epoch [82/300], Step [121/225], Training Accuracy: 96.6813%, Training Loss: 0.0913%\n",
      "Epoch [82/300], Step [122/225], Training Accuracy: 96.6701%, Training Loss: 0.0918%\n",
      "Epoch [82/300], Step [123/225], Training Accuracy: 96.6590%, Training Loss: 0.0916%\n",
      "Epoch [82/300], Step [124/225], Training Accuracy: 96.6608%, Training Loss: 0.0914%\n",
      "Epoch [82/300], Step [125/225], Training Accuracy: 96.6750%, Training Loss: 0.0913%\n",
      "Epoch [82/300], Step [126/225], Training Accuracy: 96.6766%, Training Loss: 0.0913%\n",
      "Epoch [82/300], Step [127/225], Training Accuracy: 96.6658%, Training Loss: 0.0915%\n",
      "Epoch [82/300], Step [128/225], Training Accuracy: 96.6553%, Training Loss: 0.0915%\n",
      "Epoch [82/300], Step [129/225], Training Accuracy: 96.6570%, Training Loss: 0.0915%\n",
      "Epoch [82/300], Step [130/225], Training Accuracy: 96.6346%, Training Loss: 0.0919%\n",
      "Epoch [82/300], Step [131/225], Training Accuracy: 96.6126%, Training Loss: 0.0919%\n",
      "Epoch [82/300], Step [132/225], Training Accuracy: 96.6264%, Training Loss: 0.0916%\n",
      "Epoch [82/300], Step [133/225], Training Accuracy: 96.6283%, Training Loss: 0.0914%\n",
      "Epoch [82/300], Step [134/225], Training Accuracy: 96.6301%, Training Loss: 0.0911%\n",
      "Epoch [82/300], Step [135/225], Training Accuracy: 96.6551%, Training Loss: 0.0906%\n",
      "Epoch [82/300], Step [136/225], Training Accuracy: 96.6682%, Training Loss: 0.0904%\n",
      "Epoch [82/300], Step [137/225], Training Accuracy: 96.6697%, Training Loss: 0.0907%\n",
      "Epoch [82/300], Step [138/225], Training Accuracy: 96.6712%, Training Loss: 0.0906%\n",
      "Epoch [82/300], Step [139/225], Training Accuracy: 96.6277%, Training Loss: 0.0913%\n",
      "Epoch [82/300], Step [140/225], Training Accuracy: 96.6406%, Training Loss: 0.0913%\n",
      "Epoch [82/300], Step [141/225], Training Accuracy: 96.6534%, Training Loss: 0.0911%\n",
      "Epoch [82/300], Step [142/225], Training Accuracy: 96.6549%, Training Loss: 0.0910%\n",
      "Epoch [82/300], Step [143/225], Training Accuracy: 96.6455%, Training Loss: 0.0910%\n",
      "Epoch [82/300], Step [144/225], Training Accuracy: 96.6580%, Training Loss: 0.0907%\n",
      "Epoch [82/300], Step [145/225], Training Accuracy: 96.6703%, Training Loss: 0.0905%\n",
      "Epoch [82/300], Step [146/225], Training Accuracy: 96.6931%, Training Loss: 0.0902%\n",
      "Epoch [82/300], Step [147/225], Training Accuracy: 96.6837%, Training Loss: 0.0903%\n",
      "Epoch [82/300], Step [148/225], Training Accuracy: 96.6533%, Training Loss: 0.0907%\n",
      "Epoch [82/300], Step [149/225], Training Accuracy: 96.6548%, Training Loss: 0.0907%\n",
      "Epoch [82/300], Step [150/225], Training Accuracy: 96.6667%, Training Loss: 0.0906%\n",
      "Epoch [82/300], Step [151/225], Training Accuracy: 96.6680%, Training Loss: 0.0905%\n",
      "Epoch [82/300], Step [152/225], Training Accuracy: 96.6797%, Training Loss: 0.0907%\n",
      "Epoch [82/300], Step [153/225], Training Accuracy: 96.6605%, Training Loss: 0.0917%\n",
      "Epoch [82/300], Step [154/225], Training Accuracy: 96.6822%, Training Loss: 0.0913%\n",
      "Epoch [82/300], Step [155/225], Training Accuracy: 96.6734%, Training Loss: 0.0920%\n",
      "Epoch [82/300], Step [156/225], Training Accuracy: 96.6947%, Training Loss: 0.0916%\n",
      "Epoch [82/300], Step [157/225], Training Accuracy: 96.6959%, Training Loss: 0.0914%\n",
      "Epoch [82/300], Step [158/225], Training Accuracy: 96.7069%, Training Loss: 0.0915%\n",
      "Epoch [82/300], Step [159/225], Training Accuracy: 96.7276%, Training Loss: 0.0912%\n",
      "Epoch [82/300], Step [160/225], Training Accuracy: 96.7383%, Training Loss: 0.0908%\n",
      "Epoch [82/300], Step [161/225], Training Accuracy: 96.7391%, Training Loss: 0.0907%\n",
      "Epoch [82/300], Step [162/225], Training Accuracy: 96.7303%, Training Loss: 0.0907%\n",
      "Epoch [82/300], Step [163/225], Training Accuracy: 96.7312%, Training Loss: 0.0907%\n",
      "Epoch [82/300], Step [164/225], Training Accuracy: 96.7511%, Training Loss: 0.0904%\n",
      "Epoch [82/300], Step [165/225], Training Accuracy: 96.7614%, Training Loss: 0.0903%\n",
      "Epoch [82/300], Step [166/225], Training Accuracy: 96.7809%, Training Loss: 0.0899%\n",
      "Epoch [82/300], Step [167/225], Training Accuracy: 96.7627%, Training Loss: 0.0902%\n",
      "Epoch [82/300], Step [168/225], Training Accuracy: 96.7727%, Training Loss: 0.0899%\n",
      "Epoch [82/300], Step [169/225], Training Accuracy: 96.7733%, Training Loss: 0.0897%\n",
      "Epoch [82/300], Step [170/225], Training Accuracy: 96.7647%, Training Loss: 0.0898%\n",
      "Epoch [82/300], Step [171/225], Training Accuracy: 96.7836%, Training Loss: 0.0895%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/300], Step [172/225], Training Accuracy: 96.7660%, Training Loss: 0.0898%\n",
      "Epoch [82/300], Step [173/225], Training Accuracy: 96.7757%, Training Loss: 0.0898%\n",
      "Epoch [82/300], Step [174/225], Training Accuracy: 96.7672%, Training Loss: 0.0898%\n",
      "Epoch [82/300], Step [175/225], Training Accuracy: 96.7589%, Training Loss: 0.0898%\n",
      "Epoch [82/300], Step [176/225], Training Accuracy: 96.7773%, Training Loss: 0.0894%\n",
      "Epoch [82/300], Step [177/225], Training Accuracy: 96.7867%, Training Loss: 0.0892%\n",
      "Epoch [82/300], Step [178/225], Training Accuracy: 96.7697%, Training Loss: 0.0892%\n",
      "Epoch [82/300], Step [179/225], Training Accuracy: 96.7528%, Training Loss: 0.0894%\n",
      "Epoch [82/300], Step [180/225], Training Accuracy: 96.7361%, Training Loss: 0.0900%\n",
      "Epoch [82/300], Step [181/225], Training Accuracy: 96.7455%, Training Loss: 0.0899%\n",
      "Epoch [82/300], Step [182/225], Training Accuracy: 96.7634%, Training Loss: 0.0896%\n",
      "Epoch [82/300], Step [183/225], Training Accuracy: 96.7555%, Training Loss: 0.0894%\n",
      "Epoch [82/300], Step [184/225], Training Accuracy: 96.7561%, Training Loss: 0.0894%\n",
      "Epoch [82/300], Step [185/225], Training Accuracy: 96.7652%, Training Loss: 0.0893%\n",
      "Epoch [82/300], Step [186/225], Training Accuracy: 96.7742%, Training Loss: 0.0891%\n",
      "Epoch [82/300], Step [187/225], Training Accuracy: 96.7747%, Training Loss: 0.0890%\n",
      "Epoch [82/300], Step [188/225], Training Accuracy: 96.7836%, Training Loss: 0.0889%\n",
      "Epoch [82/300], Step [189/225], Training Accuracy: 96.7841%, Training Loss: 0.0887%\n",
      "Epoch [82/300], Step [190/225], Training Accuracy: 96.7763%, Training Loss: 0.0890%\n",
      "Epoch [82/300], Step [191/225], Training Accuracy: 96.7850%, Training Loss: 0.0890%\n",
      "Epoch [82/300], Step [192/225], Training Accuracy: 96.7936%, Training Loss: 0.0887%\n",
      "Epoch [82/300], Step [193/225], Training Accuracy: 96.7940%, Training Loss: 0.0888%\n",
      "Epoch [82/300], Step [194/225], Training Accuracy: 96.7945%, Training Loss: 0.0887%\n",
      "Epoch [82/300], Step [195/225], Training Accuracy: 96.7869%, Training Loss: 0.0893%\n",
      "Epoch [82/300], Step [196/225], Training Accuracy: 96.7873%, Training Loss: 0.0893%\n",
      "Epoch [82/300], Step [197/225], Training Accuracy: 96.7957%, Training Loss: 0.0892%\n",
      "Epoch [82/300], Step [198/225], Training Accuracy: 96.8040%, Training Loss: 0.0890%\n",
      "Epoch [82/300], Step [199/225], Training Accuracy: 96.8122%, Training Loss: 0.0889%\n",
      "Epoch [82/300], Step [200/225], Training Accuracy: 96.8203%, Training Loss: 0.0887%\n",
      "Epoch [82/300], Step [201/225], Training Accuracy: 96.8050%, Training Loss: 0.0888%\n",
      "Epoch [82/300], Step [202/225], Training Accuracy: 96.7976%, Training Loss: 0.0889%\n",
      "Epoch [82/300], Step [203/225], Training Accuracy: 96.7903%, Training Loss: 0.0889%\n",
      "Epoch [82/300], Step [204/225], Training Accuracy: 96.7907%, Training Loss: 0.0888%\n",
      "Epoch [82/300], Step [205/225], Training Accuracy: 96.7988%, Training Loss: 0.0886%\n",
      "Epoch [82/300], Step [206/225], Training Accuracy: 96.7992%, Training Loss: 0.0887%\n",
      "Epoch [82/300], Step [207/225], Training Accuracy: 96.7618%, Training Loss: 0.0892%\n",
      "Epoch [82/300], Step [208/225], Training Accuracy: 96.7548%, Training Loss: 0.0892%\n",
      "Epoch [82/300], Step [209/225], Training Accuracy: 96.7479%, Training Loss: 0.0892%\n",
      "Epoch [82/300], Step [210/225], Training Accuracy: 96.7485%, Training Loss: 0.0890%\n",
      "Epoch [82/300], Step [211/225], Training Accuracy: 96.7639%, Training Loss: 0.0889%\n",
      "Epoch [82/300], Step [212/225], Training Accuracy: 96.7718%, Training Loss: 0.0887%\n",
      "Epoch [82/300], Step [213/225], Training Accuracy: 96.7796%, Training Loss: 0.0886%\n",
      "Epoch [82/300], Step [214/225], Training Accuracy: 96.7947%, Training Loss: 0.0884%\n",
      "Epoch [82/300], Step [215/225], Training Accuracy: 96.7951%, Training Loss: 0.0885%\n",
      "Epoch [82/300], Step [216/225], Training Accuracy: 96.8099%, Training Loss: 0.0882%\n",
      "Epoch [82/300], Step [217/225], Training Accuracy: 96.7958%, Training Loss: 0.0884%\n",
      "Epoch [82/300], Step [218/225], Training Accuracy: 96.8033%, Training Loss: 0.0883%\n",
      "Epoch [82/300], Step [219/225], Training Accuracy: 96.8108%, Training Loss: 0.0883%\n",
      "Epoch [82/300], Step [220/225], Training Accuracy: 96.8182%, Training Loss: 0.0884%\n",
      "Epoch [82/300], Step [221/225], Training Accuracy: 96.8184%, Training Loss: 0.0887%\n",
      "Epoch [82/300], Step [222/225], Training Accuracy: 96.8187%, Training Loss: 0.0887%\n",
      "Epoch [82/300], Step [223/225], Training Accuracy: 96.8119%, Training Loss: 0.0888%\n",
      "Epoch [82/300], Step [224/225], Training Accuracy: 96.8192%, Training Loss: 0.0887%\n",
      "Epoch [82/300], Step [225/225], Training Accuracy: 96.8107%, Training Loss: 0.0888%\n",
      "Epoch [83/300], Step [1/225], Training Accuracy: 96.8750%, Training Loss: 0.0698%\n",
      "Epoch [83/300], Step [2/225], Training Accuracy: 96.0938%, Training Loss: 0.0701%\n",
      "Epoch [83/300], Step [3/225], Training Accuracy: 95.8333%, Training Loss: 0.0838%\n",
      "Epoch [83/300], Step [4/225], Training Accuracy: 95.7031%, Training Loss: 0.0881%\n",
      "Epoch [83/300], Step [5/225], Training Accuracy: 96.5625%, Training Loss: 0.0804%\n",
      "Epoch [83/300], Step [6/225], Training Accuracy: 96.8750%, Training Loss: 0.0787%\n",
      "Epoch [83/300], Step [7/225], Training Accuracy: 96.6518%, Training Loss: 0.0853%\n",
      "Epoch [83/300], Step [8/225], Training Accuracy: 97.0703%, Training Loss: 0.0785%\n",
      "Epoch [83/300], Step [9/225], Training Accuracy: 97.3958%, Training Loss: 0.0712%\n",
      "Epoch [83/300], Step [10/225], Training Accuracy: 97.5000%, Training Loss: 0.0689%\n",
      "Epoch [83/300], Step [11/225], Training Accuracy: 97.0170%, Training Loss: 0.0728%\n",
      "Epoch [83/300], Step [12/225], Training Accuracy: 96.8750%, Training Loss: 0.0758%\n",
      "Epoch [83/300], Step [13/225], Training Accuracy: 96.8750%, Training Loss: 0.0785%\n",
      "Epoch [83/300], Step [14/225], Training Accuracy: 97.0982%, Training Loss: 0.0789%\n",
      "Epoch [83/300], Step [15/225], Training Accuracy: 97.1875%, Training Loss: 0.0768%\n",
      "Epoch [83/300], Step [16/225], Training Accuracy: 97.3633%, Training Loss: 0.0745%\n",
      "Epoch [83/300], Step [17/225], Training Accuracy: 97.4265%, Training Loss: 0.0749%\n",
      "Epoch [83/300], Step [18/225], Training Accuracy: 97.3958%, Training Loss: 0.0766%\n",
      "Epoch [83/300], Step [19/225], Training Accuracy: 97.3684%, Training Loss: 0.0778%\n",
      "Epoch [83/300], Step [20/225], Training Accuracy: 97.4219%, Training Loss: 0.0766%\n",
      "Epoch [83/300], Step [21/225], Training Accuracy: 97.5446%, Training Loss: 0.0737%\n",
      "Epoch [83/300], Step [22/225], Training Accuracy: 97.5852%, Training Loss: 0.0737%\n",
      "Epoch [83/300], Step [23/225], Training Accuracy: 97.5543%, Training Loss: 0.0749%\n",
      "Epoch [83/300], Step [24/225], Training Accuracy: 97.5911%, Training Loss: 0.0751%\n",
      "Epoch [83/300], Step [25/225], Training Accuracy: 97.6250%, Training Loss: 0.0741%\n",
      "Epoch [83/300], Step [26/225], Training Accuracy: 97.5361%, Training Loss: 0.0754%\n",
      "Epoch [83/300], Step [27/225], Training Accuracy: 97.5694%, Training Loss: 0.0750%\n",
      "Epoch [83/300], Step [28/225], Training Accuracy: 97.6004%, Training Loss: 0.0742%\n",
      "Epoch [83/300], Step [29/225], Training Accuracy: 97.4677%, Training Loss: 0.0749%\n",
      "Epoch [83/300], Step [30/225], Training Accuracy: 97.3438%, Training Loss: 0.0762%\n",
      "Epoch [83/300], Step [31/225], Training Accuracy: 97.3286%, Training Loss: 0.0765%\n",
      "Epoch [83/300], Step [32/225], Training Accuracy: 97.2656%, Training Loss: 0.0770%\n",
      "Epoch [83/300], Step [33/225], Training Accuracy: 97.3485%, Training Loss: 0.0760%\n",
      "Epoch [83/300], Step [34/225], Training Accuracy: 97.4265%, Training Loss: 0.0750%\n",
      "Epoch [83/300], Step [35/225], Training Accuracy: 97.4107%, Training Loss: 0.0746%\n",
      "Epoch [83/300], Step [36/225], Training Accuracy: 97.2656%, Training Loss: 0.0767%\n",
      "Epoch [83/300], Step [37/225], Training Accuracy: 97.2973%, Training Loss: 0.0765%\n",
      "Epoch [83/300], Step [38/225], Training Accuracy: 97.1217%, Training Loss: 0.0807%\n",
      "Epoch [83/300], Step [39/225], Training Accuracy: 97.1154%, Training Loss: 0.0813%\n",
      "Epoch [83/300], Step [40/225], Training Accuracy: 97.0312%, Training Loss: 0.0834%\n",
      "Epoch [83/300], Step [41/225], Training Accuracy: 96.9131%, Training Loss: 0.0846%\n",
      "Epoch [83/300], Step [42/225], Training Accuracy: 96.9494%, Training Loss: 0.0838%\n",
      "Epoch [83/300], Step [43/225], Training Accuracy: 96.9113%, Training Loss: 0.0845%\n",
      "Epoch [83/300], Step [44/225], Training Accuracy: 96.9460%, Training Loss: 0.0834%\n",
      "Epoch [83/300], Step [45/225], Training Accuracy: 96.8750%, Training Loss: 0.0841%\n",
      "Epoch [83/300], Step [46/225], Training Accuracy: 96.9090%, Training Loss: 0.0830%\n",
      "Epoch [83/300], Step [47/225], Training Accuracy: 96.9415%, Training Loss: 0.0829%\n",
      "Epoch [83/300], Step [48/225], Training Accuracy: 97.0052%, Training Loss: 0.0819%\n",
      "Epoch [83/300], Step [49/225], Training Accuracy: 97.0026%, Training Loss: 0.0825%\n",
      "Epoch [83/300], Step [50/225], Training Accuracy: 97.0625%, Training Loss: 0.0819%\n",
      "Epoch [83/300], Step [51/225], Training Accuracy: 97.1201%, Training Loss: 0.0807%\n",
      "Epoch [83/300], Step [52/225], Training Accuracy: 97.1454%, Training Loss: 0.0803%\n",
      "Epoch [83/300], Step [53/225], Training Accuracy: 97.1698%, Training Loss: 0.0801%\n",
      "Epoch [83/300], Step [54/225], Training Accuracy: 97.1354%, Training Loss: 0.0816%\n",
      "Epoch [83/300], Step [55/225], Training Accuracy: 97.1591%, Training Loss: 0.0813%\n",
      "Epoch [83/300], Step [56/225], Training Accuracy: 97.1819%, Training Loss: 0.0808%\n",
      "Epoch [83/300], Step [57/225], Training Accuracy: 97.1765%, Training Loss: 0.0814%\n",
      "Epoch [83/300], Step [58/225], Training Accuracy: 97.1444%, Training Loss: 0.0821%\n",
      "Epoch [83/300], Step [59/225], Training Accuracy: 97.1398%, Training Loss: 0.0823%\n",
      "Epoch [83/300], Step [60/225], Training Accuracy: 97.1094%, Training Loss: 0.0828%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/300], Step [61/225], Training Accuracy: 97.0799%, Training Loss: 0.0829%\n",
      "Epoch [83/300], Step [62/225], Training Accuracy: 97.1018%, Training Loss: 0.0826%\n",
      "Epoch [83/300], Step [63/225], Training Accuracy: 97.0982%, Training Loss: 0.0822%\n",
      "Epoch [83/300], Step [64/225], Training Accuracy: 97.1436%, Training Loss: 0.0815%\n",
      "Epoch [83/300], Step [65/225], Training Accuracy: 97.1635%, Training Loss: 0.0815%\n",
      "Epoch [83/300], Step [66/225], Training Accuracy: 97.0644%, Training Loss: 0.0831%\n",
      "Epoch [83/300], Step [67/225], Training Accuracy: 97.0849%, Training Loss: 0.0826%\n",
      "Epoch [83/300], Step [68/225], Training Accuracy: 97.1278%, Training Loss: 0.0822%\n",
      "Epoch [83/300], Step [69/225], Training Accuracy: 97.1014%, Training Loss: 0.0827%\n",
      "Epoch [83/300], Step [70/225], Training Accuracy: 97.0982%, Training Loss: 0.0827%\n",
      "Epoch [83/300], Step [71/225], Training Accuracy: 97.0951%, Training Loss: 0.0827%\n",
      "Epoch [83/300], Step [72/225], Training Accuracy: 97.0920%, Training Loss: 0.0828%\n",
      "Epoch [83/300], Step [73/225], Training Accuracy: 97.1104%, Training Loss: 0.0828%\n",
      "Epoch [83/300], Step [74/225], Training Accuracy: 97.1073%, Training Loss: 0.0831%\n",
      "Epoch [83/300], Step [75/225], Training Accuracy: 97.1042%, Training Loss: 0.0832%\n",
      "Epoch [83/300], Step [76/225], Training Accuracy: 97.1217%, Training Loss: 0.0828%\n",
      "Epoch [83/300], Step [77/225], Training Accuracy: 97.1185%, Training Loss: 0.0828%\n",
      "Epoch [83/300], Step [78/225], Training Accuracy: 97.0954%, Training Loss: 0.0835%\n",
      "Epoch [83/300], Step [79/225], Training Accuracy: 97.0728%, Training Loss: 0.0845%\n",
      "Epoch [83/300], Step [80/225], Training Accuracy: 97.1094%, Training Loss: 0.0838%\n",
      "Epoch [83/300], Step [81/225], Training Accuracy: 97.0872%, Training Loss: 0.0844%\n",
      "Epoch [83/300], Step [82/225], Training Accuracy: 97.1037%, Training Loss: 0.0841%\n",
      "Epoch [83/300], Step [83/225], Training Accuracy: 97.0444%, Training Loss: 0.0852%\n",
      "Epoch [83/300], Step [84/225], Training Accuracy: 96.9680%, Training Loss: 0.0864%\n",
      "Epoch [83/300], Step [85/225], Training Accuracy: 96.9669%, Training Loss: 0.0865%\n",
      "Epoch [83/300], Step [86/225], Training Accuracy: 96.8932%, Training Loss: 0.0880%\n",
      "Epoch [83/300], Step [87/225], Training Accuracy: 96.8391%, Training Loss: 0.0884%\n",
      "Epoch [83/300], Step [88/225], Training Accuracy: 96.8395%, Training Loss: 0.0886%\n",
      "Epoch [83/300], Step [89/225], Training Accuracy: 96.7872%, Training Loss: 0.0896%\n",
      "Epoch [83/300], Step [90/225], Training Accuracy: 96.7882%, Training Loss: 0.0895%\n",
      "Epoch [83/300], Step [91/225], Training Accuracy: 96.7891%, Training Loss: 0.0893%\n",
      "Epoch [83/300], Step [92/225], Training Accuracy: 96.8071%, Training Loss: 0.0891%\n",
      "Epoch [83/300], Step [93/225], Training Accuracy: 96.8414%, Training Loss: 0.0885%\n",
      "Epoch [83/300], Step [94/225], Training Accuracy: 96.8085%, Training Loss: 0.0893%\n",
      "Epoch [83/300], Step [95/225], Training Accuracy: 96.7928%, Training Loss: 0.0895%\n",
      "Epoch [83/300], Step [96/225], Training Accuracy: 96.7773%, Training Loss: 0.0897%\n",
      "Epoch [83/300], Step [97/225], Training Accuracy: 96.7300%, Training Loss: 0.0900%\n",
      "Epoch [83/300], Step [98/225], Training Accuracy: 96.7315%, Training Loss: 0.0898%\n",
      "Epoch [83/300], Step [99/225], Training Accuracy: 96.7172%, Training Loss: 0.0898%\n",
      "Epoch [83/300], Step [100/225], Training Accuracy: 96.7344%, Training Loss: 0.0898%\n",
      "Epoch [83/300], Step [101/225], Training Accuracy: 96.7358%, Training Loss: 0.0898%\n",
      "Epoch [83/300], Step [102/225], Training Accuracy: 96.7371%, Training Loss: 0.0898%\n",
      "Epoch [83/300], Step [103/225], Training Accuracy: 96.7385%, Training Loss: 0.0903%\n",
      "Epoch [83/300], Step [104/225], Training Accuracy: 96.7097%, Training Loss: 0.0905%\n",
      "Epoch [83/300], Step [105/225], Training Accuracy: 96.7113%, Training Loss: 0.0908%\n",
      "Epoch [83/300], Step [106/225], Training Accuracy: 96.6981%, Training Loss: 0.0910%\n",
      "Epoch [83/300], Step [107/225], Training Accuracy: 96.6560%, Training Loss: 0.0915%\n",
      "Epoch [83/300], Step [108/225], Training Accuracy: 96.6869%, Training Loss: 0.0910%\n",
      "Epoch [83/300], Step [109/225], Training Accuracy: 96.6743%, Training Loss: 0.0911%\n",
      "Epoch [83/300], Step [110/225], Training Accuracy: 96.6903%, Training Loss: 0.0907%\n",
      "Epoch [83/300], Step [111/225], Training Accuracy: 96.7061%, Training Loss: 0.0905%\n",
      "Epoch [83/300], Step [112/225], Training Accuracy: 96.7076%, Training Loss: 0.0904%\n",
      "Epoch [83/300], Step [113/225], Training Accuracy: 96.6952%, Training Loss: 0.0904%\n",
      "Epoch [83/300], Step [114/225], Training Accuracy: 96.6420%, Training Loss: 0.0911%\n",
      "Epoch [83/300], Step [115/225], Training Accuracy: 96.6440%, Training Loss: 0.0910%\n",
      "Epoch [83/300], Step [116/225], Training Accuracy: 96.6460%, Training Loss: 0.0911%\n",
      "Epoch [83/300], Step [117/225], Training Accuracy: 96.6613%, Training Loss: 0.0908%\n",
      "Epoch [83/300], Step [118/225], Training Accuracy: 96.6631%, Training Loss: 0.0910%\n",
      "Epoch [83/300], Step [119/225], Training Accuracy: 96.6518%, Training Loss: 0.0910%\n",
      "Epoch [83/300], Step [120/225], Training Accuracy: 96.6536%, Training Loss: 0.0909%\n",
      "Epoch [83/300], Step [121/225], Training Accuracy: 96.5909%, Training Loss: 0.0927%\n",
      "Epoch [83/300], Step [122/225], Training Accuracy: 96.6189%, Training Loss: 0.0923%\n",
      "Epoch [83/300], Step [123/225], Training Accuracy: 96.5828%, Training Loss: 0.0928%\n",
      "Epoch [83/300], Step [124/225], Training Accuracy: 96.5852%, Training Loss: 0.0926%\n",
      "Epoch [83/300], Step [125/225], Training Accuracy: 96.5500%, Training Loss: 0.0932%\n",
      "Epoch [83/300], Step [126/225], Training Accuracy: 96.5526%, Training Loss: 0.0929%\n",
      "Epoch [83/300], Step [127/225], Training Accuracy: 96.5305%, Training Loss: 0.0930%\n",
      "Epoch [83/300], Step [128/225], Training Accuracy: 96.5088%, Training Loss: 0.0932%\n",
      "Epoch [83/300], Step [129/225], Training Accuracy: 96.5359%, Training Loss: 0.0929%\n",
      "Epoch [83/300], Step [130/225], Training Accuracy: 96.5505%, Training Loss: 0.0928%\n",
      "Epoch [83/300], Step [131/225], Training Accuracy: 96.5768%, Training Loss: 0.0923%\n",
      "Epoch [83/300], Step [132/225], Training Accuracy: 96.5672%, Training Loss: 0.0926%\n",
      "Epoch [83/300], Step [133/225], Training Accuracy: 96.5813%, Training Loss: 0.0924%\n",
      "Epoch [83/300], Step [134/225], Training Accuracy: 96.5718%, Training Loss: 0.0931%\n",
      "Epoch [83/300], Step [135/225], Training Accuracy: 96.5856%, Training Loss: 0.0930%\n",
      "Epoch [83/300], Step [136/225], Training Accuracy: 96.5993%, Training Loss: 0.0930%\n",
      "Epoch [83/300], Step [137/225], Training Accuracy: 96.5785%, Training Loss: 0.0934%\n",
      "Epoch [83/300], Step [138/225], Training Accuracy: 96.5693%, Training Loss: 0.0937%\n",
      "Epoch [83/300], Step [139/225], Training Accuracy: 96.5603%, Training Loss: 0.0940%\n",
      "Epoch [83/300], Step [140/225], Training Accuracy: 96.5848%, Training Loss: 0.0935%\n",
      "Epoch [83/300], Step [141/225], Training Accuracy: 96.5869%, Training Loss: 0.0933%\n",
      "Epoch [83/300], Step [142/225], Training Accuracy: 96.5779%, Training Loss: 0.0932%\n",
      "Epoch [83/300], Step [143/225], Training Accuracy: 96.5800%, Training Loss: 0.0934%\n",
      "Epoch [83/300], Step [144/225], Training Accuracy: 96.5820%, Training Loss: 0.0932%\n",
      "Epoch [83/300], Step [145/225], Training Accuracy: 96.6056%, Training Loss: 0.0929%\n",
      "Epoch [83/300], Step [146/225], Training Accuracy: 96.6289%, Training Loss: 0.0926%\n",
      "Epoch [83/300], Step [147/225], Training Accuracy: 96.6412%, Training Loss: 0.0925%\n",
      "Epoch [83/300], Step [148/225], Training Accuracy: 96.6533%, Training Loss: 0.0923%\n",
      "Epoch [83/300], Step [149/225], Training Accuracy: 96.6548%, Training Loss: 0.0923%\n",
      "Epoch [83/300], Step [150/225], Training Accuracy: 96.6771%, Training Loss: 0.0919%\n",
      "Epoch [83/300], Step [151/225], Training Accuracy: 96.6680%, Training Loss: 0.0921%\n",
      "Epoch [83/300], Step [152/225], Training Accuracy: 96.6797%, Training Loss: 0.0918%\n",
      "Epoch [83/300], Step [153/225], Training Accuracy: 96.7014%, Training Loss: 0.0916%\n",
      "Epoch [83/300], Step [154/225], Training Accuracy: 96.7127%, Training Loss: 0.0914%\n",
      "Epoch [83/300], Step [155/225], Training Accuracy: 96.7137%, Training Loss: 0.0912%\n",
      "Epoch [83/300], Step [156/225], Training Accuracy: 96.7248%, Training Loss: 0.0910%\n",
      "Epoch [83/300], Step [157/225], Training Accuracy: 96.6959%, Training Loss: 0.0914%\n",
      "Epoch [83/300], Step [158/225], Training Accuracy: 96.6871%, Training Loss: 0.0914%\n",
      "Epoch [83/300], Step [159/225], Training Accuracy: 96.6392%, Training Loss: 0.0918%\n",
      "Epoch [83/300], Step [160/225], Training Accuracy: 96.6504%, Training Loss: 0.0916%\n",
      "Epoch [83/300], Step [161/225], Training Accuracy: 96.6615%, Training Loss: 0.0914%\n",
      "Epoch [83/300], Step [162/225], Training Accuracy: 96.6435%, Training Loss: 0.0917%\n",
      "Epoch [83/300], Step [163/225], Training Accuracy: 96.6641%, Training Loss: 0.0913%\n",
      "Epoch [83/300], Step [164/225], Training Accuracy: 96.6463%, Training Loss: 0.0916%\n",
      "Epoch [83/300], Step [165/225], Training Accuracy: 96.6383%, Training Loss: 0.0918%\n",
      "Epoch [83/300], Step [166/225], Training Accuracy: 96.6303%, Training Loss: 0.0921%\n",
      "Epoch [83/300], Step [167/225], Training Accuracy: 96.6224%, Training Loss: 0.0922%\n",
      "Epoch [83/300], Step [168/225], Training Accuracy: 96.6425%, Training Loss: 0.0918%\n",
      "Epoch [83/300], Step [169/225], Training Accuracy: 96.6346%, Training Loss: 0.0921%\n",
      "Epoch [83/300], Step [170/225], Training Accuracy: 96.6360%, Training Loss: 0.0922%\n",
      "Epoch [83/300], Step [171/225], Training Accuracy: 96.6283%, Training Loss: 0.0925%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/300], Step [172/225], Training Accuracy: 96.6025%, Training Loss: 0.0928%\n",
      "Epoch [83/300], Step [173/225], Training Accuracy: 96.5950%, Training Loss: 0.0929%\n",
      "Epoch [83/300], Step [174/225], Training Accuracy: 96.6056%, Training Loss: 0.0927%\n",
      "Epoch [83/300], Step [175/225], Training Accuracy: 96.6161%, Training Loss: 0.0925%\n",
      "Epoch [83/300], Step [176/225], Training Accuracy: 96.6264%, Training Loss: 0.0924%\n",
      "Epoch [83/300], Step [177/225], Training Accuracy: 96.6278%, Training Loss: 0.0927%\n",
      "Epoch [83/300], Step [178/225], Training Accuracy: 96.6292%, Training Loss: 0.0928%\n",
      "Epoch [83/300], Step [179/225], Training Accuracy: 96.6044%, Training Loss: 0.0931%\n",
      "Epoch [83/300], Step [180/225], Training Accuracy: 96.5799%, Training Loss: 0.0933%\n",
      "Epoch [83/300], Step [181/225], Training Accuracy: 96.5642%, Training Loss: 0.0934%\n",
      "Epoch [83/300], Step [182/225], Training Accuracy: 96.5659%, Training Loss: 0.0937%\n",
      "Epoch [83/300], Step [183/225], Training Accuracy: 96.5676%, Training Loss: 0.0935%\n",
      "Epoch [83/300], Step [184/225], Training Accuracy: 96.5778%, Training Loss: 0.0933%\n",
      "Epoch [83/300], Step [185/225], Training Accuracy: 96.5878%, Training Loss: 0.0932%\n",
      "Epoch [83/300], Step [186/225], Training Accuracy: 96.5978%, Training Loss: 0.0930%\n",
      "Epoch [83/300], Step [187/225], Training Accuracy: 96.6076%, Training Loss: 0.0927%\n",
      "Epoch [83/300], Step [188/225], Training Accuracy: 96.6174%, Training Loss: 0.0924%\n",
      "Epoch [83/300], Step [189/225], Training Accuracy: 96.6187%, Training Loss: 0.0923%\n",
      "Epoch [83/300], Step [190/225], Training Accuracy: 96.6118%, Training Loss: 0.0925%\n",
      "Epoch [83/300], Step [191/225], Training Accuracy: 96.5887%, Training Loss: 0.0929%\n",
      "Epoch [83/300], Step [192/225], Training Accuracy: 96.5983%, Training Loss: 0.0931%\n",
      "Epoch [83/300], Step [193/225], Training Accuracy: 96.5755%, Training Loss: 0.0935%\n",
      "Epoch [83/300], Step [194/225], Training Accuracy: 96.5689%, Training Loss: 0.0937%\n",
      "Epoch [83/300], Step [195/225], Training Accuracy: 96.5705%, Training Loss: 0.0939%\n",
      "Epoch [83/300], Step [196/225], Training Accuracy: 96.5641%, Training Loss: 0.0939%\n",
      "Epoch [83/300], Step [197/225], Training Accuracy: 96.5577%, Training Loss: 0.0942%\n",
      "Epoch [83/300], Step [198/225], Training Accuracy: 96.5593%, Training Loss: 0.0941%\n",
      "Epoch [83/300], Step [199/225], Training Accuracy: 96.5609%, Training Loss: 0.0940%\n",
      "Epoch [83/300], Step [200/225], Training Accuracy: 96.5547%, Training Loss: 0.0940%\n",
      "Epoch [83/300], Step [201/225], Training Accuracy: 96.5563%, Training Loss: 0.0939%\n",
      "Epoch [83/300], Step [202/225], Training Accuracy: 96.5656%, Training Loss: 0.0936%\n",
      "Epoch [83/300], Step [203/225], Training Accuracy: 96.5748%, Training Loss: 0.0935%\n",
      "Epoch [83/300], Step [204/225], Training Accuracy: 96.5763%, Training Loss: 0.0937%\n",
      "Epoch [83/300], Step [205/225], Training Accuracy: 96.5777%, Training Loss: 0.0939%\n",
      "Epoch [83/300], Step [206/225], Training Accuracy: 96.5716%, Training Loss: 0.0940%\n",
      "Epoch [83/300], Step [207/225], Training Accuracy: 96.5806%, Training Loss: 0.0937%\n",
      "Epoch [83/300], Step [208/225], Training Accuracy: 96.5745%, Training Loss: 0.0940%\n",
      "Epoch [83/300], Step [209/225], Training Accuracy: 96.5834%, Training Loss: 0.0939%\n",
      "Epoch [83/300], Step [210/225], Training Accuracy: 96.5625%, Training Loss: 0.0945%\n",
      "Epoch [83/300], Step [211/225], Training Accuracy: 96.5640%, Training Loss: 0.0946%\n",
      "Epoch [83/300], Step [212/225], Training Accuracy: 96.5802%, Training Loss: 0.0943%\n",
      "Epoch [83/300], Step [213/225], Training Accuracy: 96.5889%, Training Loss: 0.0942%\n",
      "Epoch [83/300], Step [214/225], Training Accuracy: 96.5756%, Training Loss: 0.0942%\n",
      "Epoch [83/300], Step [215/225], Training Accuracy: 96.5770%, Training Loss: 0.0942%\n",
      "Epoch [83/300], Step [216/225], Training Accuracy: 96.5856%, Training Loss: 0.0942%\n",
      "Epoch [83/300], Step [217/225], Training Accuracy: 96.5726%, Training Loss: 0.0946%\n",
      "Epoch [83/300], Step [218/225], Training Accuracy: 96.5668%, Training Loss: 0.0948%\n",
      "Epoch [83/300], Step [219/225], Training Accuracy: 96.5825%, Training Loss: 0.0946%\n",
      "Epoch [83/300], Step [220/225], Training Accuracy: 96.5909%, Training Loss: 0.0944%\n",
      "Epoch [83/300], Step [221/225], Training Accuracy: 96.5922%, Training Loss: 0.0942%\n",
      "Epoch [83/300], Step [222/225], Training Accuracy: 96.5864%, Training Loss: 0.0943%\n",
      "Epoch [83/300], Step [223/225], Training Accuracy: 96.5947%, Training Loss: 0.0941%\n",
      "Epoch [83/300], Step [224/225], Training Accuracy: 96.6030%, Training Loss: 0.0939%\n",
      "Epoch [83/300], Step [225/225], Training Accuracy: 96.6023%, Training Loss: 0.0938%\n",
      "Epoch [84/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0209%\n",
      "Epoch [84/300], Step [2/225], Training Accuracy: 96.8750%, Training Loss: 0.0682%\n",
      "Epoch [84/300], Step [3/225], Training Accuracy: 95.8333%, Training Loss: 0.1165%\n",
      "Epoch [84/300], Step [4/225], Training Accuracy: 96.8750%, Training Loss: 0.0931%\n",
      "Epoch [84/300], Step [5/225], Training Accuracy: 97.5000%, Training Loss: 0.0805%\n",
      "Epoch [84/300], Step [6/225], Training Accuracy: 96.8750%, Training Loss: 0.0852%\n",
      "Epoch [84/300], Step [7/225], Training Accuracy: 96.8750%, Training Loss: 0.0843%\n",
      "Epoch [84/300], Step [8/225], Training Accuracy: 97.0703%, Training Loss: 0.0890%\n",
      "Epoch [84/300], Step [9/225], Training Accuracy: 97.0486%, Training Loss: 0.0862%\n",
      "Epoch [84/300], Step [10/225], Training Accuracy: 97.0312%, Training Loss: 0.0842%\n",
      "Epoch [84/300], Step [11/225], Training Accuracy: 97.0170%, Training Loss: 0.0864%\n",
      "Epoch [84/300], Step [12/225], Training Accuracy: 97.1354%, Training Loss: 0.0854%\n",
      "Epoch [84/300], Step [13/225], Training Accuracy: 97.2356%, Training Loss: 0.0857%\n",
      "Epoch [84/300], Step [14/225], Training Accuracy: 96.9866%, Training Loss: 0.0937%\n",
      "Epoch [84/300], Step [15/225], Training Accuracy: 96.8750%, Training Loss: 0.0972%\n",
      "Epoch [84/300], Step [16/225], Training Accuracy: 97.0703%, Training Loss: 0.0935%\n",
      "Epoch [84/300], Step [17/225], Training Accuracy: 97.0588%, Training Loss: 0.0959%\n",
      "Epoch [84/300], Step [18/225], Training Accuracy: 96.9618%, Training Loss: 0.0974%\n",
      "Epoch [84/300], Step [19/225], Training Accuracy: 96.7105%, Training Loss: 0.0998%\n",
      "Epoch [84/300], Step [20/225], Training Accuracy: 96.5625%, Training Loss: 0.1002%\n",
      "Epoch [84/300], Step [21/225], Training Accuracy: 96.6518%, Training Loss: 0.0977%\n",
      "Epoch [84/300], Step [22/225], Training Accuracy: 96.5909%, Training Loss: 0.0980%\n",
      "Epoch [84/300], Step [23/225], Training Accuracy: 96.6033%, Training Loss: 0.0967%\n",
      "Epoch [84/300], Step [24/225], Training Accuracy: 96.6146%, Training Loss: 0.0963%\n",
      "Epoch [84/300], Step [25/225], Training Accuracy: 96.6875%, Training Loss: 0.0942%\n",
      "Epoch [84/300], Step [26/225], Training Accuracy: 96.7548%, Training Loss: 0.0931%\n",
      "Epoch [84/300], Step [27/225], Training Accuracy: 96.8750%, Training Loss: 0.0921%\n",
      "Epoch [84/300], Step [28/225], Training Accuracy: 96.8750%, Training Loss: 0.0928%\n",
      "Epoch [84/300], Step [29/225], Training Accuracy: 96.8750%, Training Loss: 0.0929%\n",
      "Epoch [84/300], Step [30/225], Training Accuracy: 96.9271%, Training Loss: 0.0937%\n",
      "Epoch [84/300], Step [31/225], Training Accuracy: 96.9254%, Training Loss: 0.0932%\n",
      "Epoch [84/300], Step [32/225], Training Accuracy: 96.9238%, Training Loss: 0.0927%\n",
      "Epoch [84/300], Step [33/225], Training Accuracy: 97.0170%, Training Loss: 0.0906%\n",
      "Epoch [84/300], Step [34/225], Training Accuracy: 97.0129%, Training Loss: 0.0910%\n",
      "Epoch [84/300], Step [35/225], Training Accuracy: 97.0536%, Training Loss: 0.0902%\n",
      "Epoch [84/300], Step [36/225], Training Accuracy: 96.9618%, Training Loss: 0.0936%\n",
      "Epoch [84/300], Step [37/225], Training Accuracy: 96.9595%, Training Loss: 0.0932%\n",
      "Epoch [84/300], Step [38/225], Training Accuracy: 96.8750%, Training Loss: 0.0950%\n",
      "Epoch [84/300], Step [39/225], Training Accuracy: 96.8349%, Training Loss: 0.0953%\n",
      "Epoch [84/300], Step [40/225], Training Accuracy: 96.8359%, Training Loss: 0.0954%\n",
      "Epoch [84/300], Step [41/225], Training Accuracy: 96.7607%, Training Loss: 0.0964%\n",
      "Epoch [84/300], Step [42/225], Training Accuracy: 96.7262%, Training Loss: 0.0969%\n",
      "Epoch [84/300], Step [43/225], Training Accuracy: 96.6933%, Training Loss: 0.0973%\n",
      "Epoch [84/300], Step [44/225], Training Accuracy: 96.7685%, Training Loss: 0.0958%\n",
      "Epoch [84/300], Step [45/225], Training Accuracy: 96.8403%, Training Loss: 0.0942%\n",
      "Epoch [84/300], Step [46/225], Training Accuracy: 96.8410%, Training Loss: 0.0943%\n",
      "Epoch [84/300], Step [47/225], Training Accuracy: 96.8750%, Training Loss: 0.0937%\n",
      "Epoch [84/300], Step [48/225], Training Accuracy: 96.8750%, Training Loss: 0.0936%\n",
      "Epoch [84/300], Step [49/225], Training Accuracy: 96.8750%, Training Loss: 0.0934%\n",
      "Epoch [84/300], Step [50/225], Training Accuracy: 96.9062%, Training Loss: 0.0928%\n",
      "Epoch [84/300], Step [51/225], Training Accuracy: 96.8750%, Training Loss: 0.0925%\n",
      "Epoch [84/300], Step [52/225], Training Accuracy: 96.9050%, Training Loss: 0.0914%\n",
      "Epoch [84/300], Step [53/225], Training Accuracy: 96.9340%, Training Loss: 0.0907%\n",
      "Epoch [84/300], Step [54/225], Training Accuracy: 96.8171%, Training Loss: 0.0933%\n",
      "Epoch [84/300], Step [55/225], Training Accuracy: 96.8466%, Training Loss: 0.0926%\n",
      "Epoch [84/300], Step [56/225], Training Accuracy: 96.8471%, Training Loss: 0.0927%\n",
      "Epoch [84/300], Step [57/225], Training Accuracy: 96.8202%, Training Loss: 0.0925%\n",
      "Epoch [84/300], Step [58/225], Training Accuracy: 96.7403%, Training Loss: 0.0936%\n",
      "Epoch [84/300], Step [59/225], Training Accuracy: 96.6367%, Training Loss: 0.0948%\n",
      "Epoch [84/300], Step [60/225], Training Accuracy: 96.6667%, Training Loss: 0.0940%\n",
      "Epoch [84/300], Step [61/225], Training Accuracy: 96.7213%, Training Loss: 0.0934%\n",
      "Epoch [84/300], Step [62/225], Training Accuracy: 96.7238%, Training Loss: 0.0935%\n",
      "Epoch [84/300], Step [63/225], Training Accuracy: 96.7510%, Training Loss: 0.0933%\n",
      "Epoch [84/300], Step [64/225], Training Accuracy: 96.7285%, Training Loss: 0.0938%\n",
      "Epoch [84/300], Step [65/225], Training Accuracy: 96.6587%, Training Loss: 0.0945%\n",
      "Epoch [84/300], Step [66/225], Training Accuracy: 96.6619%, Training Loss: 0.0949%\n",
      "Epoch [84/300], Step [67/225], Training Accuracy: 96.6185%, Training Loss: 0.0957%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/300], Step [68/225], Training Accuracy: 96.5993%, Training Loss: 0.0960%\n",
      "Epoch [84/300], Step [69/225], Training Accuracy: 96.6259%, Training Loss: 0.0952%\n",
      "Epoch [84/300], Step [70/225], Training Accuracy: 96.6071%, Training Loss: 0.0965%\n",
      "Epoch [84/300], Step [71/225], Training Accuracy: 96.5669%, Training Loss: 0.0977%\n",
      "Epoch [84/300], Step [72/225], Training Accuracy: 96.6146%, Training Loss: 0.0974%\n",
      "Epoch [84/300], Step [73/225], Training Accuracy: 96.5753%, Training Loss: 0.0982%\n",
      "Epoch [84/300], Step [74/225], Training Accuracy: 96.5372%, Training Loss: 0.0993%\n",
      "Epoch [84/300], Step [75/225], Training Accuracy: 96.5833%, Training Loss: 0.0982%\n",
      "Epoch [84/300], Step [76/225], Training Accuracy: 96.5461%, Training Loss: 0.0989%\n",
      "Epoch [84/300], Step [77/225], Training Accuracy: 96.5300%, Training Loss: 0.0990%\n",
      "Epoch [84/300], Step [78/225], Training Accuracy: 96.5144%, Training Loss: 0.0990%\n",
      "Epoch [84/300], Step [79/225], Training Accuracy: 96.5190%, Training Loss: 0.0990%\n",
      "Epoch [84/300], Step [80/225], Training Accuracy: 96.4453%, Training Loss: 0.1000%\n",
      "Epoch [84/300], Step [81/225], Training Accuracy: 96.4506%, Training Loss: 0.0997%\n",
      "Epoch [84/300], Step [82/225], Training Accuracy: 96.4939%, Training Loss: 0.0988%\n",
      "Epoch [84/300], Step [83/225], Training Accuracy: 96.4797%, Training Loss: 0.0993%\n",
      "Epoch [84/300], Step [84/225], Training Accuracy: 96.4472%, Training Loss: 0.0995%\n",
      "Epoch [84/300], Step [85/225], Training Accuracy: 96.4522%, Training Loss: 0.0993%\n",
      "Epoch [84/300], Step [86/225], Training Accuracy: 96.4753%, Training Loss: 0.0989%\n",
      "Epoch [84/300], Step [87/225], Training Accuracy: 96.4619%, Training Loss: 0.0995%\n",
      "Epoch [84/300], Step [88/225], Training Accuracy: 96.4489%, Training Loss: 0.0998%\n",
      "Epoch [84/300], Step [89/225], Training Accuracy: 96.4888%, Training Loss: 0.0993%\n",
      "Epoch [84/300], Step [90/225], Training Accuracy: 96.5278%, Training Loss: 0.0988%\n",
      "Epoch [84/300], Step [91/225], Training Accuracy: 96.4973%, Training Loss: 0.0991%\n",
      "Epoch [84/300], Step [92/225], Training Accuracy: 96.5014%, Training Loss: 0.0992%\n",
      "Epoch [84/300], Step [93/225], Training Accuracy: 96.5390%, Training Loss: 0.0986%\n",
      "Epoch [84/300], Step [94/225], Training Accuracy: 96.5592%, Training Loss: 0.0981%\n",
      "Epoch [84/300], Step [95/225], Training Accuracy: 96.5132%, Training Loss: 0.0987%\n",
      "Epoch [84/300], Step [96/225], Training Accuracy: 96.5332%, Training Loss: 0.0984%\n",
      "Epoch [84/300], Step [97/225], Training Accuracy: 96.5367%, Training Loss: 0.0984%\n",
      "Epoch [84/300], Step [98/225], Training Accuracy: 96.5242%, Training Loss: 0.0987%\n",
      "Epoch [84/300], Step [99/225], Training Accuracy: 96.5278%, Training Loss: 0.0989%\n",
      "Epoch [84/300], Step [100/225], Training Accuracy: 96.5000%, Training Loss: 0.0997%\n",
      "Epoch [84/300], Step [101/225], Training Accuracy: 96.5037%, Training Loss: 0.0994%\n",
      "Epoch [84/300], Step [102/225], Training Accuracy: 96.4767%, Training Loss: 0.0995%\n",
      "Epoch [84/300], Step [103/225], Training Accuracy: 96.4806%, Training Loss: 0.0992%\n",
      "Epoch [84/300], Step [104/225], Training Accuracy: 96.4844%, Training Loss: 0.0993%\n",
      "Epoch [84/300], Step [105/225], Training Accuracy: 96.4286%, Training Loss: 0.0999%\n",
      "Epoch [84/300], Step [106/225], Training Accuracy: 96.4033%, Training Loss: 0.1005%\n",
      "Epoch [84/300], Step [107/225], Training Accuracy: 96.3785%, Training Loss: 0.1008%\n",
      "Epoch [84/300], Step [108/225], Training Accuracy: 96.4120%, Training Loss: 0.1002%\n",
      "Epoch [84/300], Step [109/225], Training Accuracy: 96.4450%, Training Loss: 0.0996%\n",
      "Epoch [84/300], Step [110/225], Training Accuracy: 96.4773%, Training Loss: 0.0990%\n",
      "Epoch [84/300], Step [111/225], Training Accuracy: 96.4527%, Training Loss: 0.0991%\n",
      "Epoch [84/300], Step [112/225], Training Accuracy: 96.4844%, Training Loss: 0.0986%\n",
      "Epoch [84/300], Step [113/225], Training Accuracy: 96.4740%, Training Loss: 0.0984%\n",
      "Epoch [84/300], Step [114/225], Training Accuracy: 96.4912%, Training Loss: 0.0981%\n",
      "Epoch [84/300], Step [115/225], Training Accuracy: 96.4810%, Training Loss: 0.0983%\n",
      "Epoch [84/300], Step [116/225], Training Accuracy: 96.4844%, Training Loss: 0.0982%\n",
      "Epoch [84/300], Step [117/225], Training Accuracy: 96.4744%, Training Loss: 0.0992%\n",
      "Epoch [84/300], Step [118/225], Training Accuracy: 96.4380%, Training Loss: 0.0992%\n",
      "Epoch [84/300], Step [119/225], Training Accuracy: 96.4417%, Training Loss: 0.0997%\n",
      "Epoch [84/300], Step [120/225], Training Accuracy: 96.4583%, Training Loss: 0.0993%\n",
      "Epoch [84/300], Step [121/225], Training Accuracy: 96.4618%, Training Loss: 0.0993%\n",
      "Epoch [84/300], Step [122/225], Training Accuracy: 96.4652%, Training Loss: 0.0989%\n",
      "Epoch [84/300], Step [123/225], Training Accuracy: 96.4685%, Training Loss: 0.0985%\n",
      "Epoch [84/300], Step [124/225], Training Accuracy: 96.4592%, Training Loss: 0.0987%\n",
      "Epoch [84/300], Step [125/225], Training Accuracy: 96.4750%, Training Loss: 0.0992%\n",
      "Epoch [84/300], Step [126/225], Training Accuracy: 96.4658%, Training Loss: 0.0991%\n",
      "Epoch [84/300], Step [127/225], Training Accuracy: 96.4567%, Training Loss: 0.0989%\n",
      "Epoch [84/300], Step [128/225], Training Accuracy: 96.4600%, Training Loss: 0.0990%\n",
      "Epoch [84/300], Step [129/225], Training Accuracy: 96.4753%, Training Loss: 0.0986%\n",
      "Epoch [84/300], Step [130/225], Training Accuracy: 96.4904%, Training Loss: 0.0982%\n",
      "Epoch [84/300], Step [131/225], Training Accuracy: 96.4814%, Training Loss: 0.0982%\n",
      "Epoch [84/300], Step [132/225], Training Accuracy: 96.4844%, Training Loss: 0.0980%\n",
      "Epoch [84/300], Step [133/225], Training Accuracy: 96.4873%, Training Loss: 0.0980%\n",
      "Epoch [84/300], Step [134/225], Training Accuracy: 96.5019%, Training Loss: 0.0976%\n",
      "Epoch [84/300], Step [135/225], Training Accuracy: 96.4699%, Training Loss: 0.0977%\n",
      "Epoch [84/300], Step [136/225], Training Accuracy: 96.4844%, Training Loss: 0.0977%\n",
      "Epoch [84/300], Step [137/225], Training Accuracy: 96.4758%, Training Loss: 0.0981%\n",
      "Epoch [84/300], Step [138/225], Training Accuracy: 96.4900%, Training Loss: 0.0979%\n",
      "Epoch [84/300], Step [139/225], Training Accuracy: 96.4928%, Training Loss: 0.0979%\n",
      "Epoch [84/300], Step [140/225], Training Accuracy: 96.5179%, Training Loss: 0.0975%\n",
      "Epoch [84/300], Step [141/225], Training Accuracy: 96.5204%, Training Loss: 0.0976%\n",
      "Epoch [84/300], Step [142/225], Training Accuracy: 96.5339%, Training Loss: 0.0974%\n",
      "Epoch [84/300], Step [143/225], Training Accuracy: 96.5363%, Training Loss: 0.0973%\n",
      "Epoch [84/300], Step [144/225], Training Accuracy: 96.5386%, Training Loss: 0.0972%\n",
      "Epoch [84/300], Step [145/225], Training Accuracy: 96.5409%, Training Loss: 0.0970%\n",
      "Epoch [84/300], Step [146/225], Training Accuracy: 96.5218%, Training Loss: 0.0975%\n",
      "Epoch [84/300], Step [147/225], Training Accuracy: 96.5349%, Training Loss: 0.0972%\n",
      "Epoch [84/300], Step [148/225], Training Accuracy: 96.5372%, Training Loss: 0.0972%\n",
      "Epoch [84/300], Step [149/225], Training Accuracy: 96.5289%, Training Loss: 0.0974%\n",
      "Epoch [84/300], Step [150/225], Training Accuracy: 96.5521%, Training Loss: 0.0969%\n",
      "Epoch [84/300], Step [151/225], Training Accuracy: 96.5542%, Training Loss: 0.0971%\n",
      "Epoch [84/300], Step [152/225], Training Accuracy: 96.5358%, Training Loss: 0.0973%\n",
      "Epoch [84/300], Step [153/225], Training Accuracy: 96.5482%, Training Loss: 0.0971%\n",
      "Epoch [84/300], Step [154/225], Training Accuracy: 96.5503%, Training Loss: 0.0969%\n",
      "Epoch [84/300], Step [155/225], Training Accuracy: 96.5726%, Training Loss: 0.0965%\n",
      "Epoch [84/300], Step [156/225], Training Accuracy: 96.5745%, Training Loss: 0.0965%\n",
      "Epoch [84/300], Step [157/225], Training Accuracy: 96.5665%, Training Loss: 0.0966%\n",
      "Epoch [84/300], Step [158/225], Training Accuracy: 96.5684%, Training Loss: 0.0964%\n",
      "Epoch [84/300], Step [159/225], Training Accuracy: 96.5802%, Training Loss: 0.0962%\n",
      "Epoch [84/300], Step [160/225], Training Accuracy: 96.5918%, Training Loss: 0.0959%\n",
      "Epoch [84/300], Step [161/225], Training Accuracy: 96.6130%, Training Loss: 0.0954%\n",
      "Epoch [84/300], Step [162/225], Training Accuracy: 96.6049%, Training Loss: 0.0956%\n",
      "Epoch [84/300], Step [163/225], Training Accuracy: 96.6162%, Training Loss: 0.0953%\n",
      "Epoch [84/300], Step [164/225], Training Accuracy: 96.6178%, Training Loss: 0.0951%\n",
      "Epoch [84/300], Step [165/225], Training Accuracy: 96.6288%, Training Loss: 0.0948%\n",
      "Epoch [84/300], Step [166/225], Training Accuracy: 96.6397%, Training Loss: 0.0945%\n",
      "Epoch [84/300], Step [167/225], Training Accuracy: 96.6411%, Training Loss: 0.0944%\n",
      "Epoch [84/300], Step [168/225], Training Accuracy: 96.6332%, Training Loss: 0.0948%\n",
      "Epoch [84/300], Step [169/225], Training Accuracy: 96.6439%, Training Loss: 0.0947%\n",
      "Epoch [84/300], Step [170/225], Training Accuracy: 96.6360%, Training Loss: 0.0949%\n",
      "Epoch [84/300], Step [171/225], Training Accuracy: 96.6466%, Training Loss: 0.0950%\n",
      "Epoch [84/300], Step [172/225], Training Accuracy: 96.6297%, Training Loss: 0.0951%\n",
      "Epoch [84/300], Step [173/225], Training Accuracy: 96.6131%, Training Loss: 0.0954%\n",
      "Epoch [84/300], Step [174/225], Training Accuracy: 96.6146%, Training Loss: 0.0956%\n",
      "Epoch [84/300], Step [175/225], Training Accuracy: 96.6071%, Training Loss: 0.0956%\n",
      "Epoch [84/300], Step [176/225], Training Accuracy: 96.6087%, Training Loss: 0.0956%\n",
      "Epoch [84/300], Step [177/225], Training Accuracy: 96.6190%, Training Loss: 0.0954%\n",
      "Epoch [84/300], Step [178/225], Training Accuracy: 96.6292%, Training Loss: 0.0952%\n",
      "Epoch [84/300], Step [179/225], Training Accuracy: 96.6393%, Training Loss: 0.0949%\n",
      "Epoch [84/300], Step [180/225], Training Accuracy: 96.6580%, Training Loss: 0.0946%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/300], Step [181/225], Training Accuracy: 96.6592%, Training Loss: 0.0945%\n",
      "Epoch [84/300], Step [182/225], Training Accuracy: 96.6690%, Training Loss: 0.0944%\n",
      "Epoch [84/300], Step [183/225], Training Accuracy: 96.6786%, Training Loss: 0.0942%\n",
      "Epoch [84/300], Step [184/225], Training Accuracy: 96.6712%, Training Loss: 0.0942%\n",
      "Epoch [84/300], Step [185/225], Training Accuracy: 96.6639%, Training Loss: 0.0946%\n",
      "Epoch [84/300], Step [186/225], Training Accuracy: 96.6650%, Training Loss: 0.0944%\n",
      "Epoch [84/300], Step [187/225], Training Accuracy: 96.6828%, Training Loss: 0.0942%\n",
      "Epoch [84/300], Step [188/225], Training Accuracy: 96.6838%, Training Loss: 0.0940%\n",
      "Epoch [84/300], Step [189/225], Training Accuracy: 96.6766%, Training Loss: 0.0940%\n",
      "Epoch [84/300], Step [190/225], Training Accuracy: 96.6941%, Training Loss: 0.0936%\n",
      "Epoch [84/300], Step [191/225], Training Accuracy: 96.6868%, Training Loss: 0.0936%\n",
      "Epoch [84/300], Step [192/225], Training Accuracy: 96.6797%, Training Loss: 0.0937%\n",
      "Epoch [84/300], Step [193/225], Training Accuracy: 96.6969%, Training Loss: 0.0934%\n",
      "Epoch [84/300], Step [194/225], Training Accuracy: 96.6817%, Training Loss: 0.0936%\n",
      "Epoch [84/300], Step [195/225], Training Accuracy: 96.6827%, Training Loss: 0.0938%\n",
      "Epoch [84/300], Step [196/225], Training Accuracy: 96.6916%, Training Loss: 0.0937%\n",
      "Epoch [84/300], Step [197/225], Training Accuracy: 96.6846%, Training Loss: 0.0937%\n",
      "Epoch [84/300], Step [198/225], Training Accuracy: 96.6856%, Training Loss: 0.0936%\n",
      "Epoch [84/300], Step [199/225], Training Accuracy: 96.6944%, Training Loss: 0.0933%\n",
      "Epoch [84/300], Step [200/225], Training Accuracy: 96.7031%, Training Loss: 0.0934%\n",
      "Epoch [84/300], Step [201/225], Training Accuracy: 96.7040%, Training Loss: 0.0935%\n",
      "Epoch [84/300], Step [202/225], Training Accuracy: 96.7126%, Training Loss: 0.0934%\n",
      "Epoch [84/300], Step [203/225], Training Accuracy: 96.7211%, Training Loss: 0.0933%\n",
      "Epoch [84/300], Step [204/225], Training Accuracy: 96.7295%, Training Loss: 0.0932%\n",
      "Epoch [84/300], Step [205/225], Training Accuracy: 96.7378%, Training Loss: 0.0930%\n",
      "Epoch [84/300], Step [206/225], Training Accuracy: 96.7385%, Training Loss: 0.0930%\n",
      "Epoch [84/300], Step [207/225], Training Accuracy: 96.7467%, Training Loss: 0.0928%\n",
      "Epoch [84/300], Step [208/225], Training Accuracy: 96.7548%, Training Loss: 0.0926%\n",
      "Epoch [84/300], Step [209/225], Training Accuracy: 96.7479%, Training Loss: 0.0925%\n",
      "Epoch [84/300], Step [210/225], Training Accuracy: 96.7485%, Training Loss: 0.0924%\n",
      "Epoch [84/300], Step [211/225], Training Accuracy: 96.7343%, Training Loss: 0.0928%\n",
      "Epoch [84/300], Step [212/225], Training Accuracy: 96.7276%, Training Loss: 0.0930%\n",
      "Epoch [84/300], Step [213/225], Training Accuracy: 96.7356%, Training Loss: 0.0930%\n",
      "Epoch [84/300], Step [214/225], Training Accuracy: 96.7363%, Training Loss: 0.0928%\n",
      "Epoch [84/300], Step [215/225], Training Accuracy: 96.7515%, Training Loss: 0.0926%\n",
      "Epoch [84/300], Step [216/225], Training Accuracy: 96.7520%, Training Loss: 0.0925%\n",
      "Epoch [84/300], Step [217/225], Training Accuracy: 96.7526%, Training Loss: 0.0924%\n",
      "Epoch [84/300], Step [218/225], Training Accuracy: 96.7460%, Training Loss: 0.0926%\n",
      "Epoch [84/300], Step [219/225], Training Accuracy: 96.7608%, Training Loss: 0.0923%\n",
      "Epoch [84/300], Step [220/225], Training Accuracy: 96.7685%, Training Loss: 0.0921%\n",
      "Epoch [84/300], Step [221/225], Training Accuracy: 96.7689%, Training Loss: 0.0920%\n",
      "Epoch [84/300], Step [222/225], Training Accuracy: 96.7483%, Training Loss: 0.0922%\n",
      "Epoch [84/300], Step [223/225], Training Accuracy: 96.7489%, Training Loss: 0.0922%\n",
      "Epoch [84/300], Step [224/225], Training Accuracy: 96.7494%, Training Loss: 0.0923%\n",
      "Epoch [84/300], Step [225/225], Training Accuracy: 96.7343%, Training Loss: 0.0926%\n",
      "Epoch [85/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0374%\n",
      "Epoch [85/300], Step [2/225], Training Accuracy: 100.0000%, Training Loss: 0.0332%\n",
      "Epoch [85/300], Step [3/225], Training Accuracy: 99.4792%, Training Loss: 0.0444%\n",
      "Epoch [85/300], Step [4/225], Training Accuracy: 98.4375%, Training Loss: 0.0580%\n",
      "Epoch [85/300], Step [5/225], Training Accuracy: 98.1250%, Training Loss: 0.0559%\n",
      "Epoch [85/300], Step [6/225], Training Accuracy: 96.8750%, Training Loss: 0.0700%\n",
      "Epoch [85/300], Step [7/225], Training Accuracy: 96.8750%, Training Loss: 0.0728%\n",
      "Epoch [85/300], Step [8/225], Training Accuracy: 96.6797%, Training Loss: 0.0729%\n",
      "Epoch [85/300], Step [9/225], Training Accuracy: 96.8750%, Training Loss: 0.0720%\n",
      "Epoch [85/300], Step [10/225], Training Accuracy: 96.2500%, Training Loss: 0.0850%\n",
      "Epoch [85/300], Step [11/225], Training Accuracy: 96.1648%, Training Loss: 0.0869%\n",
      "Epoch [85/300], Step [12/225], Training Accuracy: 96.3542%, Training Loss: 0.0853%\n",
      "Epoch [85/300], Step [13/225], Training Accuracy: 96.6346%, Training Loss: 0.0809%\n",
      "Epoch [85/300], Step [14/225], Training Accuracy: 96.6518%, Training Loss: 0.0869%\n",
      "Epoch [85/300], Step [15/225], Training Accuracy: 96.7708%, Training Loss: 0.0854%\n",
      "Epoch [85/300], Step [16/225], Training Accuracy: 96.9727%, Training Loss: 0.0821%\n",
      "Epoch [85/300], Step [17/225], Training Accuracy: 96.7831%, Training Loss: 0.0889%\n",
      "Epoch [85/300], Step [18/225], Training Accuracy: 96.6146%, Training Loss: 0.0947%\n",
      "Epoch [85/300], Step [19/225], Training Accuracy: 96.7105%, Training Loss: 0.0927%\n",
      "Epoch [85/300], Step [20/225], Training Accuracy: 96.7969%, Training Loss: 0.0900%\n",
      "Epoch [85/300], Step [21/225], Training Accuracy: 96.5774%, Training Loss: 0.0935%\n",
      "Epoch [85/300], Step [22/225], Training Accuracy: 96.6619%, Training Loss: 0.0920%\n",
      "Epoch [85/300], Step [23/225], Training Accuracy: 96.7391%, Training Loss: 0.0906%\n",
      "Epoch [85/300], Step [24/225], Training Accuracy: 96.6797%, Training Loss: 0.0917%\n",
      "Epoch [85/300], Step [25/225], Training Accuracy: 96.6250%, Training Loss: 0.0903%\n",
      "Epoch [85/300], Step [26/225], Training Accuracy: 96.7548%, Training Loss: 0.0888%\n",
      "Epoch [85/300], Step [27/225], Training Accuracy: 96.6435%, Training Loss: 0.0894%\n",
      "Epoch [85/300], Step [28/225], Training Accuracy: 96.5960%, Training Loss: 0.0893%\n",
      "Epoch [85/300], Step [29/225], Training Accuracy: 96.7134%, Training Loss: 0.0875%\n",
      "Epoch [85/300], Step [30/225], Training Accuracy: 96.7708%, Training Loss: 0.0865%\n",
      "Epoch [85/300], Step [31/225], Training Accuracy: 96.6734%, Training Loss: 0.0874%\n",
      "Epoch [85/300], Step [32/225], Training Accuracy: 96.6797%, Training Loss: 0.0887%\n",
      "Epoch [85/300], Step [33/225], Training Accuracy: 96.7330%, Training Loss: 0.0877%\n",
      "Epoch [85/300], Step [34/225], Training Accuracy: 96.7831%, Training Loss: 0.0862%\n",
      "Epoch [85/300], Step [35/225], Training Accuracy: 96.8304%, Training Loss: 0.0859%\n",
      "Epoch [85/300], Step [36/225], Training Accuracy: 96.8750%, Training Loss: 0.0857%\n",
      "Epoch [85/300], Step [37/225], Training Accuracy: 96.9595%, Training Loss: 0.0840%\n",
      "Epoch [85/300], Step [38/225], Training Accuracy: 96.9572%, Training Loss: 0.0840%\n",
      "Epoch [85/300], Step [39/225], Training Accuracy: 96.9151%, Training Loss: 0.0857%\n",
      "Epoch [85/300], Step [40/225], Training Accuracy: 96.9922%, Training Loss: 0.0841%\n",
      "Epoch [85/300], Step [41/225], Training Accuracy: 96.9893%, Training Loss: 0.0845%\n",
      "Epoch [85/300], Step [42/225], Training Accuracy: 96.9494%, Training Loss: 0.0843%\n",
      "Epoch [85/300], Step [43/225], Training Accuracy: 96.9840%, Training Loss: 0.0844%\n",
      "Epoch [85/300], Step [44/225], Training Accuracy: 97.0526%, Training Loss: 0.0832%\n",
      "Epoch [85/300], Step [45/225], Training Accuracy: 97.1181%, Training Loss: 0.0820%\n",
      "Epoch [85/300], Step [46/225], Training Accuracy: 97.1128%, Training Loss: 0.0828%\n",
      "Epoch [85/300], Step [47/225], Training Accuracy: 97.1410%, Training Loss: 0.0822%\n",
      "Epoch [85/300], Step [48/225], Training Accuracy: 97.1029%, Training Loss: 0.0826%\n",
      "Epoch [85/300], Step [49/225], Training Accuracy: 97.1620%, Training Loss: 0.0821%\n",
      "Epoch [85/300], Step [50/225], Training Accuracy: 97.1875%, Training Loss: 0.0814%\n",
      "Epoch [85/300], Step [51/225], Training Accuracy: 97.2120%, Training Loss: 0.0804%\n",
      "Epoch [85/300], Step [52/225], Training Accuracy: 97.2656%, Training Loss: 0.0795%\n",
      "Epoch [85/300], Step [53/225], Training Accuracy: 97.2583%, Training Loss: 0.0793%\n",
      "Epoch [85/300], Step [54/225], Training Accuracy: 97.2512%, Training Loss: 0.0797%\n",
      "Epoch [85/300], Step [55/225], Training Accuracy: 97.2727%, Training Loss: 0.0792%\n",
      "Epoch [85/300], Step [56/225], Training Accuracy: 97.1819%, Training Loss: 0.0830%\n",
      "Epoch [85/300], Step [57/225], Training Accuracy: 97.1491%, Training Loss: 0.0842%\n",
      "Epoch [85/300], Step [58/225], Training Accuracy: 97.1713%, Training Loss: 0.0840%\n",
      "Epoch [85/300], Step [59/225], Training Accuracy: 97.1928%, Training Loss: 0.0833%\n",
      "Epoch [85/300], Step [60/225], Training Accuracy: 97.2135%, Training Loss: 0.0828%\n",
      "Epoch [85/300], Step [61/225], Training Accuracy: 97.1568%, Training Loss: 0.0838%\n",
      "Epoch [85/300], Step [62/225], Training Accuracy: 97.0766%, Training Loss: 0.0843%\n",
      "Epoch [85/300], Step [63/225], Training Accuracy: 97.0238%, Training Loss: 0.0846%\n",
      "Epoch [85/300], Step [64/225], Training Accuracy: 97.0459%, Training Loss: 0.0847%\n",
      "Epoch [85/300], Step [65/225], Training Accuracy: 97.0433%, Training Loss: 0.0851%\n",
      "Epoch [85/300], Step [66/225], Training Accuracy: 97.0881%, Training Loss: 0.0846%\n",
      "Epoch [85/300], Step [67/225], Training Accuracy: 97.0616%, Training Loss: 0.0848%\n",
      "Epoch [85/300], Step [68/225], Training Accuracy: 97.0358%, Training Loss: 0.0850%\n",
      "Epoch [85/300], Step [69/225], Training Accuracy: 96.9429%, Training Loss: 0.0857%\n",
      "Epoch [85/300], Step [70/225], Training Accuracy: 96.9643%, Training Loss: 0.0851%\n",
      "Epoch [85/300], Step [71/225], Training Accuracy: 96.9630%, Training Loss: 0.0852%\n",
      "Epoch [85/300], Step [72/225], Training Accuracy: 96.9401%, Training Loss: 0.0850%\n",
      "Epoch [85/300], Step [73/225], Training Accuracy: 96.9606%, Training Loss: 0.0845%\n",
      "Epoch [85/300], Step [74/225], Training Accuracy: 97.0017%, Training Loss: 0.0839%\n",
      "Epoch [85/300], Step [75/225], Training Accuracy: 97.0208%, Training Loss: 0.0834%\n",
      "Epoch [85/300], Step [76/225], Training Accuracy: 96.9778%, Training Loss: 0.0839%\n",
      "Epoch [85/300], Step [77/225], Training Accuracy: 96.9968%, Training Loss: 0.0839%\n",
      "Epoch [85/300], Step [78/225], Training Accuracy: 96.9952%, Training Loss: 0.0838%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/300], Step [79/225], Training Accuracy: 96.9541%, Training Loss: 0.0845%\n",
      "Epoch [85/300], Step [80/225], Training Accuracy: 96.9336%, Training Loss: 0.0850%\n",
      "Epoch [85/300], Step [81/225], Training Accuracy: 96.9522%, Training Loss: 0.0844%\n",
      "Epoch [85/300], Step [82/225], Training Accuracy: 96.9322%, Training Loss: 0.0845%\n",
      "Epoch [85/300], Step [83/225], Training Accuracy: 96.9127%, Training Loss: 0.0850%\n",
      "Epoch [85/300], Step [84/225], Training Accuracy: 96.9122%, Training Loss: 0.0855%\n",
      "Epoch [85/300], Step [85/225], Training Accuracy: 96.8750%, Training Loss: 0.0861%\n",
      "Epoch [85/300], Step [86/225], Training Accuracy: 96.8750%, Training Loss: 0.0863%\n",
      "Epoch [85/300], Step [87/225], Training Accuracy: 96.8750%, Training Loss: 0.0862%\n",
      "Epoch [85/300], Step [88/225], Training Accuracy: 96.8750%, Training Loss: 0.0862%\n",
      "Epoch [85/300], Step [89/225], Training Accuracy: 96.8750%, Training Loss: 0.0864%\n",
      "Epoch [85/300], Step [90/225], Training Accuracy: 96.9097%, Training Loss: 0.0856%\n",
      "Epoch [85/300], Step [91/225], Training Accuracy: 96.9265%, Training Loss: 0.0852%\n",
      "Epoch [85/300], Step [92/225], Training Accuracy: 96.9260%, Training Loss: 0.0853%\n",
      "Epoch [85/300], Step [93/225], Training Accuracy: 96.9422%, Training Loss: 0.0853%\n",
      "Epoch [85/300], Step [94/225], Training Accuracy: 96.9581%, Training Loss: 0.0850%\n",
      "Epoch [85/300], Step [95/225], Training Accuracy: 96.9901%, Training Loss: 0.0845%\n",
      "Epoch [85/300], Step [96/225], Training Accuracy: 96.9889%, Training Loss: 0.0843%\n",
      "Epoch [85/300], Step [97/225], Training Accuracy: 97.0039%, Training Loss: 0.0840%\n",
      "Epoch [85/300], Step [98/225], Training Accuracy: 96.9866%, Training Loss: 0.0844%\n",
      "Epoch [85/300], Step [99/225], Training Accuracy: 96.9855%, Training Loss: 0.0844%\n",
      "Epoch [85/300], Step [100/225], Training Accuracy: 96.9844%, Training Loss: 0.0845%\n",
      "Epoch [85/300], Step [101/225], Training Accuracy: 97.0142%, Training Loss: 0.0839%\n",
      "Epoch [85/300], Step [102/225], Training Accuracy: 97.0282%, Training Loss: 0.0838%\n",
      "Epoch [85/300], Step [103/225], Training Accuracy: 97.0267%, Training Loss: 0.0840%\n",
      "Epoch [85/300], Step [104/225], Training Accuracy: 97.0252%, Training Loss: 0.0843%\n",
      "Epoch [85/300], Step [105/225], Training Accuracy: 97.0536%, Training Loss: 0.0838%\n",
      "Epoch [85/300], Step [106/225], Training Accuracy: 96.9929%, Training Loss: 0.0848%\n",
      "Epoch [85/300], Step [107/225], Training Accuracy: 97.0064%, Training Loss: 0.0845%\n",
      "Epoch [85/300], Step [108/225], Training Accuracy: 97.0197%, Training Loss: 0.0847%\n",
      "Epoch [85/300], Step [109/225], Training Accuracy: 97.0040%, Training Loss: 0.0855%\n",
      "Epoch [85/300], Step [110/225], Training Accuracy: 97.0028%, Training Loss: 0.0856%\n",
      "Epoch [85/300], Step [111/225], Training Accuracy: 97.0158%, Training Loss: 0.0855%\n",
      "Epoch [85/300], Step [112/225], Training Accuracy: 97.0424%, Training Loss: 0.0850%\n",
      "Epoch [85/300], Step [113/225], Training Accuracy: 97.0548%, Training Loss: 0.0846%\n",
      "Epoch [85/300], Step [114/225], Training Accuracy: 97.0806%, Training Loss: 0.0840%\n",
      "Epoch [85/300], Step [115/225], Training Accuracy: 97.0924%, Training Loss: 0.0838%\n",
      "Epoch [85/300], Step [116/225], Training Accuracy: 97.1040%, Training Loss: 0.0836%\n",
      "Epoch [85/300], Step [117/225], Training Accuracy: 97.1287%, Training Loss: 0.0831%\n",
      "Epoch [85/300], Step [118/225], Training Accuracy: 97.1001%, Training Loss: 0.0837%\n",
      "Epoch [85/300], Step [119/225], Training Accuracy: 97.1113%, Training Loss: 0.0840%\n",
      "Epoch [85/300], Step [120/225], Training Accuracy: 97.1224%, Training Loss: 0.0838%\n",
      "Epoch [85/300], Step [121/225], Training Accuracy: 97.1462%, Training Loss: 0.0834%\n",
      "Epoch [85/300], Step [122/225], Training Accuracy: 97.1568%, Training Loss: 0.0832%\n",
      "Epoch [85/300], Step [123/225], Training Accuracy: 97.1545%, Training Loss: 0.0832%\n",
      "Epoch [85/300], Step [124/225], Training Accuracy: 97.1396%, Training Loss: 0.0832%\n",
      "Epoch [85/300], Step [125/225], Training Accuracy: 97.1625%, Training Loss: 0.0827%\n",
      "Epoch [85/300], Step [126/225], Training Accuracy: 97.1602%, Training Loss: 0.0828%\n",
      "Epoch [85/300], Step [127/225], Training Accuracy: 97.1703%, Training Loss: 0.0827%\n",
      "Epoch [85/300], Step [128/225], Training Accuracy: 97.1558%, Training Loss: 0.0828%\n",
      "Epoch [85/300], Step [129/225], Training Accuracy: 97.1657%, Training Loss: 0.0826%\n",
      "Epoch [85/300], Step [130/225], Training Accuracy: 97.1274%, Training Loss: 0.0830%\n",
      "Epoch [85/300], Step [131/225], Training Accuracy: 97.1493%, Training Loss: 0.0826%\n",
      "Epoch [85/300], Step [132/225], Training Accuracy: 97.1354%, Training Loss: 0.0827%\n",
      "Epoch [85/300], Step [133/225], Training Accuracy: 97.1335%, Training Loss: 0.0830%\n",
      "Epoch [85/300], Step [134/225], Training Accuracy: 97.1315%, Training Loss: 0.0827%\n",
      "Epoch [85/300], Step [135/225], Training Accuracy: 97.1528%, Training Loss: 0.0823%\n",
      "Epoch [85/300], Step [136/225], Training Accuracy: 97.1622%, Training Loss: 0.0823%\n",
      "Epoch [85/300], Step [137/225], Training Accuracy: 97.1715%, Training Loss: 0.0820%\n",
      "Epoch [85/300], Step [138/225], Training Accuracy: 97.1467%, Training Loss: 0.0823%\n",
      "Epoch [85/300], Step [139/225], Training Accuracy: 97.1560%, Training Loss: 0.0821%\n",
      "Epoch [85/300], Step [140/225], Training Accuracy: 97.1652%, Training Loss: 0.0820%\n",
      "Epoch [85/300], Step [141/225], Training Accuracy: 97.1853%, Training Loss: 0.0817%\n",
      "Epoch [85/300], Step [142/225], Training Accuracy: 97.2051%, Training Loss: 0.0814%\n",
      "Epoch [85/300], Step [143/225], Training Accuracy: 97.1809%, Training Loss: 0.0816%\n",
      "Epoch [85/300], Step [144/225], Training Accuracy: 97.1788%, Training Loss: 0.0817%\n",
      "Epoch [85/300], Step [145/225], Training Accuracy: 97.1983%, Training Loss: 0.0813%\n",
      "Epoch [85/300], Step [146/225], Training Accuracy: 97.1747%, Training Loss: 0.0817%\n",
      "Epoch [85/300], Step [147/225], Training Accuracy: 97.1514%, Training Loss: 0.0823%\n",
      "Epoch [85/300], Step [148/225], Training Accuracy: 97.1495%, Training Loss: 0.0825%\n",
      "Epoch [85/300], Step [149/225], Training Accuracy: 97.1581%, Training Loss: 0.0824%\n",
      "Epoch [85/300], Step [150/225], Training Accuracy: 97.1771%, Training Loss: 0.0820%\n",
      "Epoch [85/300], Step [151/225], Training Accuracy: 97.1751%, Training Loss: 0.0820%\n",
      "Epoch [85/300], Step [152/225], Training Accuracy: 97.1731%, Training Loss: 0.0818%\n",
      "Epoch [85/300], Step [153/225], Training Accuracy: 97.1814%, Training Loss: 0.0815%\n",
      "Epoch [85/300], Step [154/225], Training Accuracy: 97.1591%, Training Loss: 0.0825%\n",
      "Epoch [85/300], Step [155/225], Training Accuracy: 97.1472%, Training Loss: 0.0828%\n",
      "Epoch [85/300], Step [156/225], Training Accuracy: 97.1554%, Training Loss: 0.0826%\n",
      "Epoch [85/300], Step [157/225], Training Accuracy: 97.1636%, Training Loss: 0.0825%\n",
      "Epoch [85/300], Step [158/225], Training Accuracy: 97.1420%, Training Loss: 0.0830%\n",
      "Epoch [85/300], Step [159/225], Training Accuracy: 97.1305%, Training Loss: 0.0830%\n",
      "Epoch [85/300], Step [160/225], Training Accuracy: 97.1289%, Training Loss: 0.0828%\n",
      "Epoch [85/300], Step [161/225], Training Accuracy: 97.1370%, Training Loss: 0.0826%\n",
      "Epoch [85/300], Step [162/225], Training Accuracy: 97.1354%, Training Loss: 0.0828%\n",
      "Epoch [85/300], Step [163/225], Training Accuracy: 97.1434%, Training Loss: 0.0828%\n",
      "Epoch [85/300], Step [164/225], Training Accuracy: 97.1418%, Training Loss: 0.0828%\n",
      "Epoch [85/300], Step [165/225], Training Accuracy: 97.1496%, Training Loss: 0.0826%\n",
      "Epoch [85/300], Step [166/225], Training Accuracy: 97.1197%, Training Loss: 0.0835%\n",
      "Epoch [85/300], Step [167/225], Training Accuracy: 97.1276%, Training Loss: 0.0835%\n",
      "Epoch [85/300], Step [168/225], Training Accuracy: 97.1168%, Training Loss: 0.0836%\n",
      "Epoch [85/300], Step [169/225], Training Accuracy: 97.1154%, Training Loss: 0.0840%\n",
      "Epoch [85/300], Step [170/225], Training Accuracy: 97.1140%, Training Loss: 0.0841%\n",
      "Epoch [85/300], Step [171/225], Training Accuracy: 97.1217%, Training Loss: 0.0840%\n",
      "Epoch [85/300], Step [172/225], Training Accuracy: 97.1384%, Training Loss: 0.0837%\n",
      "Epoch [85/300], Step [173/225], Training Accuracy: 97.1369%, Training Loss: 0.0839%\n",
      "Epoch [85/300], Step [174/225], Training Accuracy: 97.1534%, Training Loss: 0.0837%\n",
      "Epoch [85/300], Step [175/225], Training Accuracy: 97.1607%, Training Loss: 0.0835%\n",
      "Epoch [85/300], Step [176/225], Training Accuracy: 97.1591%, Training Loss: 0.0836%\n",
      "Epoch [85/300], Step [177/225], Training Accuracy: 97.1663%, Training Loss: 0.0835%\n",
      "Epoch [85/300], Step [178/225], Training Accuracy: 97.1559%, Training Loss: 0.0838%\n",
      "Epoch [85/300], Step [179/225], Training Accuracy: 97.1631%, Training Loss: 0.0837%\n",
      "Epoch [85/300], Step [180/225], Training Accuracy: 97.1701%, Training Loss: 0.0834%\n",
      "Epoch [85/300], Step [181/225], Training Accuracy: 97.1685%, Training Loss: 0.0836%\n",
      "Epoch [85/300], Step [182/225], Training Accuracy: 97.1669%, Training Loss: 0.0836%\n",
      "Epoch [85/300], Step [183/225], Training Accuracy: 97.1568%, Training Loss: 0.0836%\n",
      "Epoch [85/300], Step [184/225], Training Accuracy: 97.1467%, Training Loss: 0.0838%\n",
      "Epoch [85/300], Step [185/225], Training Accuracy: 97.1368%, Training Loss: 0.0838%\n",
      "Epoch [85/300], Step [186/225], Training Accuracy: 97.1522%, Training Loss: 0.0836%\n",
      "Epoch [85/300], Step [187/225], Training Accuracy: 97.1674%, Training Loss: 0.0833%\n",
      "Epoch [85/300], Step [188/225], Training Accuracy: 97.1659%, Training Loss: 0.0831%\n",
      "Epoch [85/300], Step [189/225], Training Accuracy: 97.1478%, Training Loss: 0.0836%\n",
      "Epoch [85/300], Step [190/225], Training Accuracy: 97.1382%, Training Loss: 0.0838%\n",
      "Epoch [85/300], Step [191/225], Training Accuracy: 97.1368%, Training Loss: 0.0839%\n",
      "Epoch [85/300], Step [192/225], Training Accuracy: 97.1517%, Training Loss: 0.0838%\n",
      "Epoch [85/300], Step [193/225], Training Accuracy: 97.1179%, Training Loss: 0.0841%\n",
      "Epoch [85/300], Step [194/225], Training Accuracy: 97.1327%, Training Loss: 0.0839%\n",
      "Epoch [85/300], Step [195/225], Training Accuracy: 97.1394%, Training Loss: 0.0843%\n",
      "Epoch [85/300], Step [196/225], Training Accuracy: 97.1460%, Training Loss: 0.0841%\n",
      "Epoch [85/300], Step [197/225], Training Accuracy: 97.1367%, Training Loss: 0.0842%\n",
      "Epoch [85/300], Step [198/225], Training Accuracy: 97.1433%, Training Loss: 0.0841%\n",
      "Epoch [85/300], Step [199/225], Training Accuracy: 97.1341%, Training Loss: 0.0841%\n",
      "Epoch [85/300], Step [200/225], Training Accuracy: 97.1484%, Training Loss: 0.0838%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/300], Step [201/225], Training Accuracy: 97.1471%, Training Loss: 0.0839%\n",
      "Epoch [85/300], Step [202/225], Training Accuracy: 97.1457%, Training Loss: 0.0842%\n",
      "Epoch [85/300], Step [203/225], Training Accuracy: 97.1521%, Training Loss: 0.0842%\n",
      "Epoch [85/300], Step [204/225], Training Accuracy: 97.1584%, Training Loss: 0.0842%\n",
      "Epoch [85/300], Step [205/225], Training Accuracy: 97.1570%, Training Loss: 0.0842%\n",
      "Epoch [85/300], Step [206/225], Training Accuracy: 97.1556%, Training Loss: 0.0842%\n",
      "Epoch [85/300], Step [207/225], Training Accuracy: 97.1392%, Training Loss: 0.0843%\n",
      "Epoch [85/300], Step [208/225], Training Accuracy: 97.1304%, Training Loss: 0.0846%\n",
      "Epoch [85/300], Step [209/225], Training Accuracy: 97.1217%, Training Loss: 0.0847%\n",
      "Epoch [85/300], Step [210/225], Training Accuracy: 97.1280%, Training Loss: 0.0844%\n",
      "Epoch [85/300], Step [211/225], Training Accuracy: 97.1342%, Training Loss: 0.0845%\n",
      "Epoch [85/300], Step [212/225], Training Accuracy: 97.1477%, Training Loss: 0.0844%\n",
      "Epoch [85/300], Step [213/225], Training Accuracy: 97.1538%, Training Loss: 0.0844%\n",
      "Epoch [85/300], Step [214/225], Training Accuracy: 97.1379%, Training Loss: 0.0846%\n",
      "Epoch [85/300], Step [215/225], Training Accuracy: 97.1439%, Training Loss: 0.0844%\n",
      "Epoch [85/300], Step [216/225], Training Accuracy: 97.1354%, Training Loss: 0.0845%\n",
      "Epoch [85/300], Step [217/225], Training Accuracy: 97.1270%, Training Loss: 0.0845%\n",
      "Epoch [85/300], Step [218/225], Training Accuracy: 97.1115%, Training Loss: 0.0848%\n",
      "Epoch [85/300], Step [219/225], Training Accuracy: 97.0890%, Training Loss: 0.0854%\n",
      "Epoch [85/300], Step [220/225], Training Accuracy: 97.0952%, Training Loss: 0.0852%\n",
      "Epoch [85/300], Step [221/225], Training Accuracy: 97.1012%, Training Loss: 0.0850%\n",
      "Epoch [85/300], Step [222/225], Training Accuracy: 97.0932%, Training Loss: 0.0853%\n",
      "Epoch [85/300], Step [223/225], Training Accuracy: 97.0992%, Training Loss: 0.0851%\n",
      "Epoch [85/300], Step [224/225], Training Accuracy: 97.1052%, Training Loss: 0.0851%\n",
      "Epoch [85/300], Step [225/225], Training Accuracy: 97.1095%, Training Loss: 0.0851%\n",
      "Epoch [86/300], Step [1/225], Training Accuracy: 96.8750%, Training Loss: 0.0744%\n",
      "Epoch [86/300], Step [2/225], Training Accuracy: 96.8750%, Training Loss: 0.0796%\n",
      "Epoch [86/300], Step [3/225], Training Accuracy: 96.8750%, Training Loss: 0.0766%\n",
      "Epoch [86/300], Step [4/225], Training Accuracy: 96.8750%, Training Loss: 0.0748%\n",
      "Epoch [86/300], Step [5/225], Training Accuracy: 97.1875%, Training Loss: 0.0673%\n",
      "Epoch [86/300], Step [6/225], Training Accuracy: 97.3958%, Training Loss: 0.0653%\n",
      "Epoch [86/300], Step [7/225], Training Accuracy: 97.5446%, Training Loss: 0.0638%\n",
      "Epoch [86/300], Step [8/225], Training Accuracy: 97.4609%, Training Loss: 0.0698%\n",
      "Epoch [86/300], Step [9/225], Training Accuracy: 97.5694%, Training Loss: 0.0691%\n",
      "Epoch [86/300], Step [10/225], Training Accuracy: 97.6562%, Training Loss: 0.0679%\n",
      "Epoch [86/300], Step [11/225], Training Accuracy: 97.4432%, Training Loss: 0.0701%\n",
      "Epoch [86/300], Step [12/225], Training Accuracy: 97.6562%, Training Loss: 0.0666%\n",
      "Epoch [86/300], Step [13/225], Training Accuracy: 97.5962%, Training Loss: 0.0669%\n",
      "Epoch [86/300], Step [14/225], Training Accuracy: 97.6562%, Training Loss: 0.0654%\n",
      "Epoch [86/300], Step [15/225], Training Accuracy: 97.6042%, Training Loss: 0.0658%\n",
      "Epoch [86/300], Step [16/225], Training Accuracy: 97.6562%, Training Loss: 0.0645%\n",
      "Epoch [86/300], Step [17/225], Training Accuracy: 97.7022%, Training Loss: 0.0656%\n",
      "Epoch [86/300], Step [18/225], Training Accuracy: 97.5694%, Training Loss: 0.0674%\n",
      "Epoch [86/300], Step [19/225], Training Accuracy: 97.6151%, Training Loss: 0.0671%\n",
      "Epoch [86/300], Step [20/225], Training Accuracy: 97.7344%, Training Loss: 0.0650%\n",
      "Epoch [86/300], Step [21/225], Training Accuracy: 97.6190%, Training Loss: 0.0679%\n",
      "Epoch [86/300], Step [22/225], Training Accuracy: 97.7273%, Training Loss: 0.0682%\n",
      "Epoch [86/300], Step [23/225], Training Accuracy: 97.6902%, Training Loss: 0.0686%\n",
      "Epoch [86/300], Step [24/225], Training Accuracy: 97.7214%, Training Loss: 0.0692%\n",
      "Epoch [86/300], Step [25/225], Training Accuracy: 97.6250%, Training Loss: 0.0703%\n",
      "Epoch [86/300], Step [26/225], Training Accuracy: 97.7163%, Training Loss: 0.0688%\n",
      "Epoch [86/300], Step [27/225], Training Accuracy: 97.6852%, Training Loss: 0.0688%\n",
      "Epoch [86/300], Step [28/225], Training Accuracy: 97.7121%, Training Loss: 0.0695%\n",
      "Epoch [86/300], Step [29/225], Training Accuracy: 97.6293%, Training Loss: 0.0704%\n",
      "Epoch [86/300], Step [30/225], Training Accuracy: 97.6562%, Training Loss: 0.0702%\n",
      "Epoch [86/300], Step [31/225], Training Accuracy: 97.5806%, Training Loss: 0.0723%\n",
      "Epoch [86/300], Step [32/225], Training Accuracy: 97.6562%, Training Loss: 0.0708%\n",
      "Epoch [86/300], Step [33/225], Training Accuracy: 97.7273%, Training Loss: 0.0698%\n",
      "Epoch [86/300], Step [34/225], Training Accuracy: 97.6562%, Training Loss: 0.0701%\n",
      "Epoch [86/300], Step [35/225], Training Accuracy: 97.4107%, Training Loss: 0.0730%\n",
      "Epoch [86/300], Step [36/225], Training Accuracy: 97.3958%, Training Loss: 0.0731%\n",
      "Epoch [86/300], Step [37/225], Training Accuracy: 97.3818%, Training Loss: 0.0746%\n",
      "Epoch [86/300], Step [38/225], Training Accuracy: 97.3684%, Training Loss: 0.0744%\n",
      "Epoch [86/300], Step [39/225], Training Accuracy: 97.3157%, Training Loss: 0.0742%\n",
      "Epoch [86/300], Step [40/225], Training Accuracy: 97.2266%, Training Loss: 0.0762%\n",
      "Epoch [86/300], Step [41/225], Training Accuracy: 97.1799%, Training Loss: 0.0777%\n",
      "Epoch [86/300], Step [42/225], Training Accuracy: 97.1726%, Training Loss: 0.0774%\n",
      "Epoch [86/300], Step [43/225], Training Accuracy: 97.0203%, Training Loss: 0.0795%\n",
      "Epoch [86/300], Step [44/225], Training Accuracy: 97.0170%, Training Loss: 0.0794%\n",
      "Epoch [86/300], Step [45/225], Training Accuracy: 97.0486%, Training Loss: 0.0790%\n",
      "Epoch [86/300], Step [46/225], Training Accuracy: 97.1128%, Training Loss: 0.0777%\n",
      "Epoch [86/300], Step [47/225], Training Accuracy: 97.1742%, Training Loss: 0.0771%\n",
      "Epoch [86/300], Step [48/225], Training Accuracy: 97.2005%, Training Loss: 0.0767%\n",
      "Epoch [86/300], Step [49/225], Training Accuracy: 97.2258%, Training Loss: 0.0760%\n",
      "Epoch [86/300], Step [50/225], Training Accuracy: 97.2188%, Training Loss: 0.0778%\n",
      "Epoch [86/300], Step [51/225], Training Accuracy: 97.2733%, Training Loss: 0.0768%\n",
      "Epoch [86/300], Step [52/225], Training Accuracy: 97.2656%, Training Loss: 0.0768%\n",
      "Epoch [86/300], Step [53/225], Training Accuracy: 97.2583%, Training Loss: 0.0767%\n",
      "Epoch [86/300], Step [54/225], Training Accuracy: 97.2512%, Training Loss: 0.0775%\n",
      "Epoch [86/300], Step [55/225], Training Accuracy: 97.2443%, Training Loss: 0.0777%\n",
      "Epoch [86/300], Step [56/225], Training Accuracy: 97.2656%, Training Loss: 0.0783%\n",
      "Epoch [86/300], Step [57/225], Training Accuracy: 97.2314%, Training Loss: 0.0788%\n",
      "Epoch [86/300], Step [58/225], Training Accuracy: 97.1713%, Training Loss: 0.0792%\n",
      "Epoch [86/300], Step [59/225], Training Accuracy: 97.1928%, Training Loss: 0.0795%\n",
      "Epoch [86/300], Step [60/225], Training Accuracy: 97.1615%, Training Loss: 0.0794%\n",
      "Epoch [86/300], Step [61/225], Training Accuracy: 97.1568%, Training Loss: 0.0795%\n",
      "Epoch [86/300], Step [62/225], Training Accuracy: 97.1018%, Training Loss: 0.0804%\n",
      "Epoch [86/300], Step [63/225], Training Accuracy: 97.0486%, Training Loss: 0.0808%\n",
      "Epoch [86/300], Step [64/225], Training Accuracy: 97.0215%, Training Loss: 0.0817%\n",
      "Epoch [86/300], Step [65/225], Training Accuracy: 97.0433%, Training Loss: 0.0813%\n",
      "Epoch [86/300], Step [66/225], Training Accuracy: 96.9223%, Training Loss: 0.0839%\n",
      "Epoch [86/300], Step [67/225], Training Accuracy: 96.9450%, Training Loss: 0.0835%\n",
      "Epoch [86/300], Step [68/225], Training Accuracy: 96.9210%, Training Loss: 0.0835%\n",
      "Epoch [86/300], Step [69/225], Training Accuracy: 96.9429%, Training Loss: 0.0834%\n",
      "Epoch [86/300], Step [70/225], Training Accuracy: 96.9643%, Training Loss: 0.0831%\n",
      "Epoch [86/300], Step [71/225], Training Accuracy: 96.9410%, Training Loss: 0.0832%\n",
      "Epoch [86/300], Step [72/225], Training Accuracy: 96.9618%, Training Loss: 0.0825%\n",
      "Epoch [86/300], Step [73/225], Training Accuracy: 96.9820%, Training Loss: 0.0824%\n",
      "Epoch [86/300], Step [74/225], Training Accuracy: 96.9806%, Training Loss: 0.0822%\n",
      "Epoch [86/300], Step [75/225], Training Accuracy: 97.0208%, Training Loss: 0.0815%\n",
      "Epoch [86/300], Step [76/225], Training Accuracy: 96.9778%, Training Loss: 0.0819%\n",
      "Epoch [86/300], Step [77/225], Training Accuracy: 96.9968%, Training Loss: 0.0814%\n",
      "Epoch [86/300], Step [78/225], Training Accuracy: 96.9952%, Training Loss: 0.0814%\n",
      "Epoch [86/300], Step [79/225], Training Accuracy: 96.9937%, Training Loss: 0.0812%\n",
      "Epoch [86/300], Step [80/225], Training Accuracy: 96.9727%, Training Loss: 0.0815%\n",
      "Epoch [86/300], Step [81/225], Training Accuracy: 96.9329%, Training Loss: 0.0820%\n",
      "Epoch [86/300], Step [82/225], Training Accuracy: 96.9322%, Training Loss: 0.0822%\n",
      "Epoch [86/300], Step [83/225], Training Accuracy: 96.9691%, Training Loss: 0.0816%\n",
      "Epoch [86/300], Step [84/225], Training Accuracy: 96.9866%, Training Loss: 0.0814%\n",
      "Epoch [86/300], Step [85/225], Training Accuracy: 97.0221%, Training Loss: 0.0808%\n",
      "Epoch [86/300], Step [86/225], Training Accuracy: 97.0385%, Training Loss: 0.0807%\n",
      "Epoch [86/300], Step [87/225], Training Accuracy: 96.9828%, Training Loss: 0.0814%\n",
      "Epoch [86/300], Step [88/225], Training Accuracy: 96.9993%, Training Loss: 0.0810%\n",
      "Epoch [86/300], Step [89/225], Training Accuracy: 96.9979%, Training Loss: 0.0811%\n",
      "Epoch [86/300], Step [90/225], Training Accuracy: 96.9965%, Training Loss: 0.0812%\n",
      "Epoch [86/300], Step [91/225], Training Accuracy: 97.0124%, Training Loss: 0.0809%\n",
      "Epoch [86/300], Step [92/225], Training Accuracy: 97.0109%, Training Loss: 0.0806%\n",
      "Epoch [86/300], Step [93/225], Training Accuracy: 97.0262%, Training Loss: 0.0810%\n",
      "Epoch [86/300], Step [94/225], Training Accuracy: 97.0412%, Training Loss: 0.0810%\n",
      "Epoch [86/300], Step [95/225], Training Accuracy: 97.0395%, Training Loss: 0.0809%\n",
      "Epoch [86/300], Step [96/225], Training Accuracy: 97.0215%, Training Loss: 0.0816%\n",
      "Epoch [86/300], Step [97/225], Training Accuracy: 97.0039%, Training Loss: 0.0832%\n",
      "Epoch [86/300], Step [98/225], Training Accuracy: 96.9707%, Training Loss: 0.0835%\n",
      "Epoch [86/300], Step [99/225], Training Accuracy: 96.9855%, Training Loss: 0.0831%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/300], Step [100/225], Training Accuracy: 96.9531%, Training Loss: 0.0833%\n",
      "Epoch [86/300], Step [101/225], Training Accuracy: 96.9369%, Training Loss: 0.0833%\n",
      "Epoch [86/300], Step [102/225], Training Accuracy: 96.9516%, Training Loss: 0.0832%\n",
      "Epoch [86/300], Step [103/225], Training Accuracy: 96.9357%, Training Loss: 0.0834%\n",
      "Epoch [86/300], Step [104/225], Training Accuracy: 96.9501%, Training Loss: 0.0831%\n",
      "Epoch [86/300], Step [105/225], Training Accuracy: 96.9792%, Training Loss: 0.0826%\n",
      "Epoch [86/300], Step [106/225], Training Accuracy: 96.9929%, Training Loss: 0.0824%\n",
      "Epoch [86/300], Step [107/225], Training Accuracy: 96.9918%, Training Loss: 0.0824%\n",
      "Epoch [86/300], Step [108/225], Training Accuracy: 97.0052%, Training Loss: 0.0820%\n",
      "Epoch [86/300], Step [109/225], Training Accuracy: 96.9897%, Training Loss: 0.0821%\n",
      "Epoch [86/300], Step [110/225], Training Accuracy: 97.0170%, Training Loss: 0.0817%\n",
      "Epoch [86/300], Step [111/225], Training Accuracy: 97.0158%, Training Loss: 0.0818%\n",
      "Epoch [86/300], Step [112/225], Training Accuracy: 97.0285%, Training Loss: 0.0818%\n",
      "Epoch [86/300], Step [113/225], Training Accuracy: 97.0133%, Training Loss: 0.0823%\n",
      "Epoch [86/300], Step [114/225], Training Accuracy: 96.9846%, Training Loss: 0.0826%\n",
      "Epoch [86/300], Step [115/225], Training Accuracy: 96.9701%, Training Loss: 0.0828%\n",
      "Epoch [86/300], Step [116/225], Training Accuracy: 96.9962%, Training Loss: 0.0825%\n",
      "Epoch [86/300], Step [117/225], Training Accuracy: 96.9952%, Training Loss: 0.0823%\n",
      "Epoch [86/300], Step [118/225], Training Accuracy: 96.9544%, Training Loss: 0.0830%\n",
      "Epoch [86/300], Step [119/225], Training Accuracy: 96.9669%, Training Loss: 0.0827%\n",
      "Epoch [86/300], Step [120/225], Training Accuracy: 96.9922%, Training Loss: 0.0822%\n",
      "Epoch [86/300], Step [121/225], Training Accuracy: 97.0170%, Training Loss: 0.0817%\n",
      "Epoch [86/300], Step [122/225], Training Accuracy: 97.0415%, Training Loss: 0.0813%\n",
      "Epoch [86/300], Step [123/225], Training Accuracy: 97.0528%, Training Loss: 0.0811%\n",
      "Epoch [86/300], Step [124/225], Training Accuracy: 97.0262%, Training Loss: 0.0826%\n",
      "Epoch [86/300], Step [125/225], Training Accuracy: 97.0500%, Training Loss: 0.0823%\n",
      "Epoch [86/300], Step [126/225], Training Accuracy: 97.0486%, Training Loss: 0.0823%\n",
      "Epoch [86/300], Step [127/225], Training Accuracy: 97.0226%, Training Loss: 0.0829%\n",
      "Epoch [86/300], Step [128/225], Training Accuracy: 97.0337%, Training Loss: 0.0827%\n",
      "Epoch [86/300], Step [129/225], Training Accuracy: 97.0325%, Training Loss: 0.0827%\n",
      "Epoch [86/300], Step [130/225], Training Accuracy: 97.0312%, Training Loss: 0.0827%\n",
      "Epoch [86/300], Step [131/225], Training Accuracy: 97.0181%, Training Loss: 0.0830%\n",
      "Epoch [86/300], Step [132/225], Training Accuracy: 97.0289%, Training Loss: 0.0829%\n",
      "Epoch [86/300], Step [133/225], Training Accuracy: 97.0277%, Training Loss: 0.0828%\n",
      "Epoch [86/300], Step [134/225], Training Accuracy: 97.0149%, Training Loss: 0.0831%\n",
      "Epoch [86/300], Step [135/225], Training Accuracy: 97.0255%, Training Loss: 0.0829%\n",
      "Epoch [86/300], Step [136/225], Training Accuracy: 97.0014%, Training Loss: 0.0837%\n",
      "Epoch [86/300], Step [137/225], Training Accuracy: 97.0119%, Training Loss: 0.0834%\n",
      "Epoch [86/300], Step [138/225], Training Accuracy: 97.0335%, Training Loss: 0.0831%\n",
      "Epoch [86/300], Step [139/225], Training Accuracy: 97.0324%, Training Loss: 0.0831%\n",
      "Epoch [86/300], Step [140/225], Training Accuracy: 97.0424%, Training Loss: 0.0829%\n",
      "Epoch [86/300], Step [141/225], Training Accuracy: 96.9969%, Training Loss: 0.0834%\n",
      "Epoch [86/300], Step [142/225], Training Accuracy: 96.9960%, Training Loss: 0.0831%\n",
      "Epoch [86/300], Step [143/225], Training Accuracy: 97.0061%, Training Loss: 0.0831%\n",
      "Epoch [86/300], Step [144/225], Training Accuracy: 96.9944%, Training Loss: 0.0836%\n",
      "Epoch [86/300], Step [145/225], Training Accuracy: 97.0043%, Training Loss: 0.0833%\n",
      "Epoch [86/300], Step [146/225], Training Accuracy: 97.0034%, Training Loss: 0.0833%\n",
      "Epoch [86/300], Step [147/225], Training Accuracy: 97.0132%, Training Loss: 0.0831%\n",
      "Epoch [86/300], Step [148/225], Training Accuracy: 97.0017%, Training Loss: 0.0833%\n",
      "Epoch [86/300], Step [149/225], Training Accuracy: 97.0113%, Training Loss: 0.0835%\n",
      "Epoch [86/300], Step [150/225], Training Accuracy: 97.0208%, Training Loss: 0.0832%\n",
      "Epoch [86/300], Step [151/225], Training Accuracy: 97.0406%, Training Loss: 0.0829%\n",
      "Epoch [86/300], Step [152/225], Training Accuracy: 97.0292%, Training Loss: 0.0829%\n",
      "Epoch [86/300], Step [153/225], Training Accuracy: 97.0384%, Training Loss: 0.0825%\n",
      "Epoch [86/300], Step [154/225], Training Accuracy: 97.0475%, Training Loss: 0.0829%\n",
      "Epoch [86/300], Step [155/225], Training Accuracy: 97.0464%, Training Loss: 0.0829%\n",
      "Epoch [86/300], Step [156/225], Training Accuracy: 97.0553%, Training Loss: 0.0826%\n",
      "Epoch [86/300], Step [157/225], Training Accuracy: 97.0740%, Training Loss: 0.0822%\n",
      "Epoch [86/300], Step [158/225], Training Accuracy: 97.0926%, Training Loss: 0.0818%\n",
      "Epoch [86/300], Step [159/225], Training Accuracy: 97.0617%, Training Loss: 0.0822%\n",
      "Epoch [86/300], Step [160/225], Training Accuracy: 97.0508%, Training Loss: 0.0824%\n",
      "Epoch [86/300], Step [161/225], Training Accuracy: 97.0594%, Training Loss: 0.0821%\n",
      "Epoch [86/300], Step [162/225], Training Accuracy: 97.0583%, Training Loss: 0.0820%\n",
      "Epoch [86/300], Step [163/225], Training Accuracy: 97.0667%, Training Loss: 0.0819%\n",
      "Epoch [86/300], Step [164/225], Training Accuracy: 97.0370%, Training Loss: 0.0823%\n",
      "Epoch [86/300], Step [165/225], Training Accuracy: 97.0455%, Training Loss: 0.0821%\n",
      "Epoch [86/300], Step [166/225], Training Accuracy: 97.0256%, Training Loss: 0.0822%\n",
      "Epoch [86/300], Step [167/225], Training Accuracy: 96.9966%, Training Loss: 0.0826%\n",
      "Epoch [86/300], Step [168/225], Training Accuracy: 97.0145%, Training Loss: 0.0823%\n",
      "Epoch [86/300], Step [169/225], Training Accuracy: 97.0044%, Training Loss: 0.0828%\n",
      "Epoch [86/300], Step [170/225], Training Accuracy: 96.9945%, Training Loss: 0.0830%\n",
      "Epoch [86/300], Step [171/225], Training Accuracy: 97.0029%, Training Loss: 0.0828%\n",
      "Epoch [86/300], Step [172/225], Training Accuracy: 97.0113%, Training Loss: 0.0829%\n",
      "Epoch [86/300], Step [173/225], Training Accuracy: 97.0105%, Training Loss: 0.0832%\n",
      "Epoch [86/300], Step [174/225], Training Accuracy: 97.0187%, Training Loss: 0.0831%\n",
      "Epoch [86/300], Step [175/225], Training Accuracy: 97.0357%, Training Loss: 0.0827%\n",
      "Epoch [86/300], Step [176/225], Training Accuracy: 97.0437%, Training Loss: 0.0825%\n",
      "Epoch [86/300], Step [177/225], Training Accuracy: 97.0427%, Training Loss: 0.0825%\n",
      "Epoch [86/300], Step [178/225], Training Accuracy: 97.0506%, Training Loss: 0.0825%\n",
      "Epoch [86/300], Step [179/225], Training Accuracy: 97.0409%, Training Loss: 0.0826%\n",
      "Epoch [86/300], Step [180/225], Training Accuracy: 97.0399%, Training Loss: 0.0826%\n",
      "Epoch [86/300], Step [181/225], Training Accuracy: 97.0304%, Training Loss: 0.0827%\n",
      "Epoch [86/300], Step [182/225], Training Accuracy: 97.0295%, Training Loss: 0.0827%\n",
      "Epoch [86/300], Step [183/225], Training Accuracy: 97.0287%, Training Loss: 0.0828%\n",
      "Epoch [86/300], Step [184/225], Training Accuracy: 97.0363%, Training Loss: 0.0829%\n",
      "Epoch [86/300], Step [185/225], Training Accuracy: 97.0270%, Training Loss: 0.0831%\n",
      "Epoch [86/300], Step [186/225], Training Accuracy: 97.0430%, Training Loss: 0.0829%\n",
      "Epoch [86/300], Step [187/225], Training Accuracy: 97.0505%, Training Loss: 0.0828%\n",
      "Epoch [86/300], Step [188/225], Training Accuracy: 97.0495%, Training Loss: 0.0829%\n",
      "Epoch [86/300], Step [189/225], Training Accuracy: 97.0486%, Training Loss: 0.0828%\n",
      "Epoch [86/300], Step [190/225], Training Accuracy: 97.0477%, Training Loss: 0.0828%\n",
      "Epoch [86/300], Step [191/225], Training Accuracy: 97.0550%, Training Loss: 0.0826%\n",
      "Epoch [86/300], Step [192/225], Training Accuracy: 97.0622%, Training Loss: 0.0825%\n",
      "Epoch [86/300], Step [193/225], Training Accuracy: 97.0531%, Training Loss: 0.0825%\n",
      "Epoch [86/300], Step [194/225], Training Accuracy: 97.0683%, Training Loss: 0.0822%\n",
      "Epoch [86/300], Step [195/225], Training Accuracy: 97.0513%, Training Loss: 0.0827%\n",
      "Epoch [86/300], Step [196/225], Training Accuracy: 97.0344%, Training Loss: 0.0830%\n",
      "Epoch [86/300], Step [197/225], Training Accuracy: 97.0336%, Training Loss: 0.0830%\n",
      "Epoch [86/300], Step [198/225], Training Accuracy: 97.0486%, Training Loss: 0.0828%\n",
      "Epoch [86/300], Step [199/225], Training Accuracy: 97.0634%, Training Loss: 0.0825%\n",
      "Epoch [86/300], Step [200/225], Training Accuracy: 97.0469%, Training Loss: 0.0828%\n",
      "Epoch [86/300], Step [201/225], Training Accuracy: 97.0382%, Training Loss: 0.0828%\n",
      "Epoch [86/300], Step [202/225], Training Accuracy: 97.0142%, Training Loss: 0.0831%\n",
      "Epoch [86/300], Step [203/225], Training Accuracy: 96.9982%, Training Loss: 0.0834%\n",
      "Epoch [86/300], Step [204/225], Training Accuracy: 96.9975%, Training Loss: 0.0833%\n",
      "Epoch [86/300], Step [205/225], Training Accuracy: 97.0122%, Training Loss: 0.0831%\n",
      "Epoch [86/300], Step [206/225], Training Accuracy: 96.9964%, Training Loss: 0.0831%\n",
      "Epoch [86/300], Step [207/225], Training Accuracy: 96.9958%, Training Loss: 0.0831%\n",
      "Epoch [86/300], Step [208/225], Training Accuracy: 97.0027%, Training Loss: 0.0830%\n",
      "Epoch [86/300], Step [209/225], Training Accuracy: 97.0170%, Training Loss: 0.0827%\n",
      "Epoch [86/300], Step [210/225], Training Accuracy: 97.0238%, Training Loss: 0.0826%\n",
      "Epoch [86/300], Step [211/225], Training Accuracy: 97.0305%, Training Loss: 0.0825%\n",
      "Epoch [86/300], Step [212/225], Training Accuracy: 97.0445%, Training Loss: 0.0823%\n",
      "Epoch [86/300], Step [213/225], Training Accuracy: 97.0437%, Training Loss: 0.0822%\n",
      "Epoch [86/300], Step [214/225], Training Accuracy: 97.0356%, Training Loss: 0.0823%\n",
      "Epoch [86/300], Step [215/225], Training Accuracy: 97.0422%, Training Loss: 0.0821%\n",
      "Epoch [86/300], Step [216/225], Training Accuracy: 97.0414%, Training Loss: 0.0820%\n",
      "Epoch [86/300], Step [217/225], Training Accuracy: 97.0262%, Training Loss: 0.0825%\n",
      "Epoch [86/300], Step [218/225], Training Accuracy: 97.0327%, Training Loss: 0.0825%\n",
      "Epoch [86/300], Step [219/225], Training Accuracy: 97.0320%, Training Loss: 0.0825%\n",
      "Epoch [86/300], Step [220/225], Training Accuracy: 97.0312%, Training Loss: 0.0826%\n",
      "Epoch [86/300], Step [221/225], Training Accuracy: 97.0235%, Training Loss: 0.0826%\n",
      "Epoch [86/300], Step [222/225], Training Accuracy: 97.0369%, Training Loss: 0.0824%\n",
      "Epoch [86/300], Step [223/225], Training Accuracy: 97.0362%, Training Loss: 0.0825%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/300], Step [224/225], Training Accuracy: 97.0494%, Training Loss: 0.0823%\n",
      "Epoch [86/300], Step [225/225], Training Accuracy: 97.0609%, Training Loss: 0.0821%\n",
      "Epoch [87/300], Step [1/225], Training Accuracy: 96.8750%, Training Loss: 0.0845%\n",
      "Epoch [87/300], Step [2/225], Training Accuracy: 98.4375%, Training Loss: 0.0716%\n",
      "Epoch [87/300], Step [3/225], Training Accuracy: 98.4375%, Training Loss: 0.0650%\n",
      "Epoch [87/300], Step [4/225], Training Accuracy: 98.8281%, Training Loss: 0.0619%\n",
      "Epoch [87/300], Step [5/225], Training Accuracy: 99.0625%, Training Loss: 0.0549%\n",
      "Epoch [87/300], Step [6/225], Training Accuracy: 97.9167%, Training Loss: 0.0756%\n",
      "Epoch [87/300], Step [7/225], Training Accuracy: 98.2143%, Training Loss: 0.0699%\n",
      "Epoch [87/300], Step [8/225], Training Accuracy: 98.0469%, Training Loss: 0.0678%\n",
      "Epoch [87/300], Step [9/225], Training Accuracy: 97.3958%, Training Loss: 0.0730%\n",
      "Epoch [87/300], Step [10/225], Training Accuracy: 97.3438%, Training Loss: 0.0715%\n",
      "Epoch [87/300], Step [11/225], Training Accuracy: 97.5852%, Training Loss: 0.0668%\n",
      "Epoch [87/300], Step [12/225], Training Accuracy: 97.6562%, Training Loss: 0.0648%\n",
      "Epoch [87/300], Step [13/225], Training Accuracy: 97.7163%, Training Loss: 0.0681%\n",
      "Epoch [87/300], Step [14/225], Training Accuracy: 97.5446%, Training Loss: 0.0706%\n",
      "Epoch [87/300], Step [15/225], Training Accuracy: 97.6042%, Training Loss: 0.0693%\n",
      "Epoch [87/300], Step [16/225], Training Accuracy: 97.6562%, Training Loss: 0.0678%\n",
      "Epoch [87/300], Step [17/225], Training Accuracy: 97.5184%, Training Loss: 0.0733%\n",
      "Epoch [87/300], Step [18/225], Training Accuracy: 97.3090%, Training Loss: 0.0762%\n",
      "Epoch [87/300], Step [19/225], Training Accuracy: 97.3684%, Training Loss: 0.0742%\n",
      "Epoch [87/300], Step [20/225], Training Accuracy: 97.5000%, Training Loss: 0.0729%\n",
      "Epoch [87/300], Step [21/225], Training Accuracy: 97.5446%, Training Loss: 0.0731%\n",
      "Epoch [87/300], Step [22/225], Training Accuracy: 97.5852%, Training Loss: 0.0728%\n",
      "Epoch [87/300], Step [23/225], Training Accuracy: 97.4864%, Training Loss: 0.0741%\n",
      "Epoch [87/300], Step [24/225], Training Accuracy: 97.4609%, Training Loss: 0.0759%\n",
      "Epoch [87/300], Step [25/225], Training Accuracy: 97.5000%, Training Loss: 0.0763%\n",
      "Epoch [87/300], Step [26/225], Training Accuracy: 97.4760%, Training Loss: 0.0780%\n",
      "Epoch [87/300], Step [27/225], Training Accuracy: 97.4537%, Training Loss: 0.0780%\n",
      "Epoch [87/300], Step [28/225], Training Accuracy: 97.4888%, Training Loss: 0.0770%\n",
      "Epoch [87/300], Step [29/225], Training Accuracy: 97.5216%, Training Loss: 0.0756%\n",
      "Epoch [87/300], Step [30/225], Training Accuracy: 97.5521%, Training Loss: 0.0752%\n",
      "Epoch [87/300], Step [31/225], Training Accuracy: 97.4294%, Training Loss: 0.0782%\n",
      "Epoch [87/300], Step [32/225], Training Accuracy: 97.3633%, Training Loss: 0.0812%\n",
      "Epoch [87/300], Step [33/225], Training Accuracy: 97.4432%, Training Loss: 0.0797%\n",
      "Epoch [87/300], Step [34/225], Training Accuracy: 97.4265%, Training Loss: 0.0803%\n",
      "Epoch [87/300], Step [35/225], Training Accuracy: 97.4554%, Training Loss: 0.0802%\n",
      "Epoch [87/300], Step [36/225], Training Accuracy: 97.4826%, Training Loss: 0.0794%\n",
      "Epoch [87/300], Step [37/225], Training Accuracy: 97.5507%, Training Loss: 0.0783%\n",
      "Epoch [87/300], Step [38/225], Training Accuracy: 97.5329%, Training Loss: 0.0779%\n",
      "Epoch [87/300], Step [39/225], Training Accuracy: 97.5561%, Training Loss: 0.0778%\n",
      "Epoch [87/300], Step [40/225], Training Accuracy: 97.5781%, Training Loss: 0.0783%\n",
      "Epoch [87/300], Step [41/225], Training Accuracy: 97.4848%, Training Loss: 0.0803%\n",
      "Epoch [87/300], Step [42/225], Training Accuracy: 97.4702%, Training Loss: 0.0806%\n",
      "Epoch [87/300], Step [43/225], Training Accuracy: 97.4927%, Training Loss: 0.0802%\n",
      "Epoch [87/300], Step [44/225], Training Accuracy: 97.4787%, Training Loss: 0.0795%\n",
      "Epoch [87/300], Step [45/225], Training Accuracy: 97.4653%, Training Loss: 0.0793%\n",
      "Epoch [87/300], Step [46/225], Training Accuracy: 97.4524%, Training Loss: 0.0789%\n",
      "Epoch [87/300], Step [47/225], Training Accuracy: 97.4734%, Training Loss: 0.0790%\n",
      "Epoch [87/300], Step [48/225], Training Accuracy: 97.3633%, Training Loss: 0.0836%\n",
      "Epoch [87/300], Step [49/225], Training Accuracy: 97.3533%, Training Loss: 0.0841%\n",
      "Epoch [87/300], Step [50/225], Training Accuracy: 97.3750%, Training Loss: 0.0839%\n",
      "Epoch [87/300], Step [51/225], Training Accuracy: 97.4265%, Training Loss: 0.0828%\n",
      "Epoch [87/300], Step [52/225], Training Accuracy: 97.4760%, Training Loss: 0.0820%\n",
      "Epoch [87/300], Step [53/225], Training Accuracy: 97.4941%, Training Loss: 0.0817%\n",
      "Epoch [87/300], Step [54/225], Training Accuracy: 97.4826%, Training Loss: 0.0826%\n",
      "Epoch [87/300], Step [55/225], Training Accuracy: 97.4432%, Training Loss: 0.0831%\n",
      "Epoch [87/300], Step [56/225], Training Accuracy: 97.4888%, Training Loss: 0.0827%\n",
      "Epoch [87/300], Step [57/225], Training Accuracy: 97.4507%, Training Loss: 0.0829%\n",
      "Epoch [87/300], Step [58/225], Training Accuracy: 97.4677%, Training Loss: 0.0825%\n",
      "Epoch [87/300], Step [59/225], Training Accuracy: 97.5106%, Training Loss: 0.0818%\n",
      "Epoch [87/300], Step [60/225], Training Accuracy: 97.5521%, Training Loss: 0.0810%\n",
      "Epoch [87/300], Step [61/225], Training Accuracy: 97.5666%, Training Loss: 0.0811%\n",
      "Epoch [87/300], Step [62/225], Training Accuracy: 97.6058%, Training Loss: 0.0803%\n",
      "Epoch [87/300], Step [63/225], Training Accuracy: 97.5694%, Training Loss: 0.0814%\n",
      "Epoch [87/300], Step [64/225], Training Accuracy: 97.5586%, Training Loss: 0.0812%\n",
      "Epoch [87/300], Step [65/225], Training Accuracy: 97.5481%, Training Loss: 0.0815%\n",
      "Epoch [87/300], Step [66/225], Training Accuracy: 97.5379%, Training Loss: 0.0816%\n",
      "Epoch [87/300], Step [67/225], Training Accuracy: 97.5513%, Training Loss: 0.0812%\n",
      "Epoch [87/300], Step [68/225], Training Accuracy: 97.5643%, Training Loss: 0.0809%\n",
      "Epoch [87/300], Step [69/225], Training Accuracy: 97.5770%, Training Loss: 0.0806%\n",
      "Epoch [87/300], Step [70/225], Training Accuracy: 97.5670%, Training Loss: 0.0805%\n",
      "Epoch [87/300], Step [71/225], Training Accuracy: 97.5792%, Training Loss: 0.0801%\n",
      "Epoch [87/300], Step [72/225], Training Accuracy: 97.6128%, Training Loss: 0.0794%\n",
      "Epoch [87/300], Step [73/225], Training Accuracy: 97.5599%, Training Loss: 0.0804%\n",
      "Epoch [87/300], Step [74/225], Training Accuracy: 97.5718%, Training Loss: 0.0800%\n",
      "Epoch [87/300], Step [75/225], Training Accuracy: 97.6042%, Training Loss: 0.0794%\n",
      "Epoch [87/300], Step [76/225], Training Accuracy: 97.6357%, Training Loss: 0.0787%\n",
      "Epoch [87/300], Step [77/225], Training Accuracy: 97.5649%, Training Loss: 0.0797%\n",
      "Epoch [87/300], Step [78/225], Training Accuracy: 97.5761%, Training Loss: 0.0795%\n",
      "Epoch [87/300], Step [79/225], Training Accuracy: 97.5475%, Training Loss: 0.0797%\n",
      "Epoch [87/300], Step [80/225], Training Accuracy: 97.5391%, Training Loss: 0.0796%\n",
      "Epoch [87/300], Step [81/225], Training Accuracy: 97.5502%, Training Loss: 0.0792%\n",
      "Epoch [87/300], Step [82/225], Training Accuracy: 97.5610%, Training Loss: 0.0790%\n",
      "Epoch [87/300], Step [83/225], Training Accuracy: 97.5527%, Training Loss: 0.0794%\n",
      "Epoch [87/300], Step [84/225], Training Accuracy: 97.5818%, Training Loss: 0.0787%\n",
      "Epoch [87/300], Step [85/225], Training Accuracy: 97.5551%, Training Loss: 0.0791%\n",
      "Epoch [87/300], Step [86/225], Training Accuracy: 97.4927%, Training Loss: 0.0797%\n",
      "Epoch [87/300], Step [87/225], Training Accuracy: 97.4856%, Training Loss: 0.0796%\n",
      "Epoch [87/300], Step [88/225], Training Accuracy: 97.5142%, Training Loss: 0.0790%\n",
      "Epoch [87/300], Step [89/225], Training Accuracy: 97.5421%, Training Loss: 0.0785%\n",
      "Epoch [87/300], Step [90/225], Training Accuracy: 97.5174%, Training Loss: 0.0788%\n",
      "Epoch [87/300], Step [91/225], Training Accuracy: 97.5275%, Training Loss: 0.0783%\n",
      "Epoch [87/300], Step [92/225], Training Accuracy: 97.5374%, Training Loss: 0.0779%\n",
      "Epoch [87/300], Step [93/225], Training Accuracy: 97.5470%, Training Loss: 0.0776%\n",
      "Epoch [87/300], Step [94/225], Training Accuracy: 97.5565%, Training Loss: 0.0773%\n",
      "Epoch [87/300], Step [95/225], Training Accuracy: 97.5493%, Training Loss: 0.0777%\n",
      "Epoch [87/300], Step [96/225], Training Accuracy: 97.5586%, Training Loss: 0.0773%\n",
      "Epoch [87/300], Step [97/225], Training Accuracy: 97.5677%, Training Loss: 0.0769%\n",
      "Epoch [87/300], Step [98/225], Training Accuracy: 97.5446%, Training Loss: 0.0777%\n",
      "Epoch [87/300], Step [99/225], Training Accuracy: 97.5694%, Training Loss: 0.0773%\n",
      "Epoch [87/300], Step [100/225], Training Accuracy: 97.5938%, Training Loss: 0.0772%\n",
      "Epoch [87/300], Step [101/225], Training Accuracy: 97.5712%, Training Loss: 0.0772%\n",
      "Epoch [87/300], Step [102/225], Training Accuracy: 97.5643%, Training Loss: 0.0771%\n",
      "Epoch [87/300], Step [103/225], Training Accuracy: 97.5425%, Training Loss: 0.0775%\n",
      "Epoch [87/300], Step [104/225], Training Accuracy: 97.5661%, Training Loss: 0.0774%\n",
      "Epoch [87/300], Step [105/225], Training Accuracy: 97.5893%, Training Loss: 0.0770%\n",
      "Epoch [87/300], Step [106/225], Training Accuracy: 97.5973%, Training Loss: 0.0769%\n",
      "Epoch [87/300], Step [107/225], Training Accuracy: 97.6197%, Training Loss: 0.0765%\n",
      "Epoch [87/300], Step [108/225], Training Accuracy: 97.6273%, Training Loss: 0.0761%\n",
      "Epoch [87/300], Step [109/225], Training Accuracy: 97.6347%, Training Loss: 0.0761%\n",
      "Epoch [87/300], Step [110/225], Training Accuracy: 97.6420%, Training Loss: 0.0757%\n",
      "Epoch [87/300], Step [111/225], Training Accuracy: 97.6492%, Training Loss: 0.0754%\n",
      "Epoch [87/300], Step [112/225], Training Accuracy: 97.6283%, Training Loss: 0.0758%\n",
      "Epoch [87/300], Step [113/225], Training Accuracy: 97.6217%, Training Loss: 0.0759%\n",
      "Epoch [87/300], Step [114/225], Training Accuracy: 97.6014%, Training Loss: 0.0763%\n",
      "Epoch [87/300], Step [115/225], Training Accuracy: 97.6223%, Training Loss: 0.0760%\n",
      "Epoch [87/300], Step [116/225], Training Accuracy: 97.5754%, Training Loss: 0.0771%\n",
      "Epoch [87/300], Step [117/225], Training Accuracy: 97.5694%, Training Loss: 0.0774%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/300], Step [118/225], Training Accuracy: 97.5636%, Training Loss: 0.0774%\n",
      "Epoch [87/300], Step [119/225], Training Accuracy: 97.5578%, Training Loss: 0.0772%\n",
      "Epoch [87/300], Step [120/225], Training Accuracy: 97.5521%, Training Loss: 0.0770%\n",
      "Epoch [87/300], Step [121/225], Training Accuracy: 97.5594%, Training Loss: 0.0767%\n",
      "Epoch [87/300], Step [122/225], Training Accuracy: 97.5666%, Training Loss: 0.0765%\n",
      "Epoch [87/300], Step [123/225], Training Accuracy: 97.5737%, Training Loss: 0.0766%\n",
      "Epoch [87/300], Step [124/225], Training Accuracy: 97.5806%, Training Loss: 0.0764%\n",
      "Epoch [87/300], Step [125/225], Training Accuracy: 97.5875%, Training Loss: 0.0764%\n",
      "Epoch [87/300], Step [126/225], Training Accuracy: 97.5570%, Training Loss: 0.0771%\n",
      "Epoch [87/300], Step [127/225], Training Accuracy: 97.5763%, Training Loss: 0.0769%\n",
      "Epoch [87/300], Step [128/225], Training Accuracy: 97.5708%, Training Loss: 0.0772%\n",
      "Epoch [87/300], Step [129/225], Training Accuracy: 97.5654%, Training Loss: 0.0774%\n",
      "Epoch [87/300], Step [130/225], Training Accuracy: 97.5481%, Training Loss: 0.0775%\n",
      "Epoch [87/300], Step [131/225], Training Accuracy: 97.5310%, Training Loss: 0.0778%\n",
      "Epoch [87/300], Step [132/225], Training Accuracy: 97.5142%, Training Loss: 0.0779%\n",
      "Epoch [87/300], Step [133/225], Training Accuracy: 97.5211%, Training Loss: 0.0779%\n",
      "Epoch [87/300], Step [134/225], Training Accuracy: 97.5280%, Training Loss: 0.0776%\n",
      "Epoch [87/300], Step [135/225], Training Accuracy: 97.5463%, Training Loss: 0.0771%\n",
      "Epoch [87/300], Step [136/225], Training Accuracy: 97.5299%, Training Loss: 0.0779%\n",
      "Epoch [87/300], Step [137/225], Training Accuracy: 97.5365%, Training Loss: 0.0776%\n",
      "Epoch [87/300], Step [138/225], Training Accuracy: 97.5204%, Training Loss: 0.0779%\n",
      "Epoch [87/300], Step [139/225], Training Accuracy: 97.5382%, Training Loss: 0.0775%\n",
      "Epoch [87/300], Step [140/225], Training Accuracy: 97.5446%, Training Loss: 0.0775%\n",
      "Epoch [87/300], Step [141/225], Training Accuracy: 97.5510%, Training Loss: 0.0774%\n",
      "Epoch [87/300], Step [142/225], Training Accuracy: 97.5242%, Training Loss: 0.0777%\n",
      "Epoch [87/300], Step [143/225], Training Accuracy: 97.5087%, Training Loss: 0.0780%\n",
      "Epoch [87/300], Step [144/225], Training Accuracy: 97.4935%, Training Loss: 0.0779%\n",
      "Epoch [87/300], Step [145/225], Training Accuracy: 97.5000%, Training Loss: 0.0779%\n",
      "Epoch [87/300], Step [146/225], Training Accuracy: 97.5064%, Training Loss: 0.0777%\n",
      "Epoch [87/300], Step [147/225], Training Accuracy: 97.5128%, Training Loss: 0.0776%\n",
      "Epoch [87/300], Step [148/225], Training Accuracy: 97.5296%, Training Loss: 0.0775%\n",
      "Epoch [87/300], Step [149/225], Training Accuracy: 97.5252%, Training Loss: 0.0775%\n",
      "Epoch [87/300], Step [150/225], Training Accuracy: 97.5312%, Training Loss: 0.0775%\n",
      "Epoch [87/300], Step [151/225], Training Accuracy: 97.5269%, Training Loss: 0.0779%\n",
      "Epoch [87/300], Step [152/225], Training Accuracy: 97.5329%, Training Loss: 0.0779%\n",
      "Epoch [87/300], Step [153/225], Training Accuracy: 97.5388%, Training Loss: 0.0777%\n",
      "Epoch [87/300], Step [154/225], Training Accuracy: 97.5446%, Training Loss: 0.0777%\n",
      "Epoch [87/300], Step [155/225], Training Accuracy: 97.5605%, Training Loss: 0.0775%\n",
      "Epoch [87/300], Step [156/225], Training Accuracy: 97.5761%, Training Loss: 0.0772%\n",
      "Epoch [87/300], Step [157/225], Training Accuracy: 97.5518%, Training Loss: 0.0778%\n",
      "Epoch [87/300], Step [158/225], Training Accuracy: 97.5574%, Training Loss: 0.0777%\n",
      "Epoch [87/300], Step [159/225], Training Accuracy: 97.5727%, Training Loss: 0.0775%\n",
      "Epoch [87/300], Step [160/225], Training Accuracy: 97.5781%, Training Loss: 0.0773%\n",
      "Epoch [87/300], Step [161/225], Training Accuracy: 97.5738%, Training Loss: 0.0772%\n",
      "Epoch [87/300], Step [162/225], Training Accuracy: 97.5598%, Training Loss: 0.0774%\n",
      "Epoch [87/300], Step [163/225], Training Accuracy: 97.5556%, Training Loss: 0.0774%\n",
      "Epoch [87/300], Step [164/225], Training Accuracy: 97.5419%, Training Loss: 0.0775%\n",
      "Epoch [87/300], Step [165/225], Training Accuracy: 97.5568%, Training Loss: 0.0773%\n",
      "Epoch [87/300], Step [166/225], Training Accuracy: 97.5621%, Training Loss: 0.0772%\n",
      "Epoch [87/300], Step [167/225], Training Accuracy: 97.5580%, Training Loss: 0.0774%\n",
      "Epoch [87/300], Step [168/225], Training Accuracy: 97.5539%, Training Loss: 0.0773%\n",
      "Epoch [87/300], Step [169/225], Training Accuracy: 97.5592%, Training Loss: 0.0774%\n",
      "Epoch [87/300], Step [170/225], Training Accuracy: 97.5643%, Training Loss: 0.0774%\n",
      "Epoch [87/300], Step [171/225], Training Accuracy: 97.5603%, Training Loss: 0.0778%\n",
      "Epoch [87/300], Step [172/225], Training Accuracy: 97.5291%, Training Loss: 0.0782%\n",
      "Epoch [87/300], Step [173/225], Training Accuracy: 97.5343%, Training Loss: 0.0780%\n",
      "Epoch [87/300], Step [174/225], Training Accuracy: 97.5395%, Training Loss: 0.0779%\n",
      "Epoch [87/300], Step [175/225], Training Accuracy: 97.5446%, Training Loss: 0.0777%\n",
      "Epoch [87/300], Step [176/225], Training Accuracy: 97.5497%, Training Loss: 0.0776%\n",
      "Epoch [87/300], Step [177/225], Training Accuracy: 97.5371%, Training Loss: 0.0780%\n",
      "Epoch [87/300], Step [178/225], Training Accuracy: 97.5421%, Training Loss: 0.0779%\n",
      "Epoch [87/300], Step [179/225], Training Accuracy: 97.5384%, Training Loss: 0.0778%\n",
      "Epoch [87/300], Step [180/225], Training Accuracy: 97.5347%, Training Loss: 0.0778%\n",
      "Epoch [87/300], Step [181/225], Training Accuracy: 97.5052%, Training Loss: 0.0783%\n",
      "Epoch [87/300], Step [182/225], Training Accuracy: 97.4845%, Training Loss: 0.0787%\n",
      "Epoch [87/300], Step [183/225], Training Accuracy: 97.4898%, Training Loss: 0.0786%\n",
      "Epoch [87/300], Step [184/225], Training Accuracy: 97.4864%, Training Loss: 0.0784%\n",
      "Epoch [87/300], Step [185/225], Training Accuracy: 97.4916%, Training Loss: 0.0783%\n",
      "Epoch [87/300], Step [186/225], Training Accuracy: 97.4966%, Training Loss: 0.0782%\n",
      "Epoch [87/300], Step [187/225], Training Accuracy: 97.4933%, Training Loss: 0.0781%\n",
      "Epoch [87/300], Step [188/225], Training Accuracy: 97.4817%, Training Loss: 0.0781%\n",
      "Epoch [87/300], Step [189/225], Training Accuracy: 97.4868%, Training Loss: 0.0779%\n",
      "Epoch [87/300], Step [190/225], Training Accuracy: 97.4836%, Training Loss: 0.0781%\n",
      "Epoch [87/300], Step [191/225], Training Accuracy: 97.4722%, Training Loss: 0.0784%\n",
      "Epoch [87/300], Step [192/225], Training Accuracy: 97.4772%, Training Loss: 0.0783%\n",
      "Epoch [87/300], Step [193/225], Training Accuracy: 97.4822%, Training Loss: 0.0786%\n",
      "Epoch [87/300], Step [194/225], Training Accuracy: 97.4710%, Training Loss: 0.0786%\n",
      "Epoch [87/300], Step [195/225], Training Accuracy: 97.4599%, Training Loss: 0.0788%\n",
      "Epoch [87/300], Step [196/225], Training Accuracy: 97.4649%, Training Loss: 0.0787%\n",
      "Epoch [87/300], Step [197/225], Training Accuracy: 97.4699%, Training Loss: 0.0786%\n",
      "Epoch [87/300], Step [198/225], Training Accuracy: 97.4747%, Training Loss: 0.0785%\n",
      "Epoch [87/300], Step [199/225], Training Accuracy: 97.4639%, Training Loss: 0.0787%\n",
      "Epoch [87/300], Step [200/225], Training Accuracy: 97.4688%, Training Loss: 0.0786%\n",
      "Epoch [87/300], Step [201/225], Training Accuracy: 97.4658%, Training Loss: 0.0788%\n",
      "Epoch [87/300], Step [202/225], Training Accuracy: 97.4551%, Training Loss: 0.0792%\n",
      "Epoch [87/300], Step [203/225], Training Accuracy: 97.4600%, Training Loss: 0.0790%\n",
      "Epoch [87/300], Step [204/225], Training Accuracy: 97.4571%, Training Loss: 0.0790%\n",
      "Epoch [87/300], Step [205/225], Training Accuracy: 97.4390%, Training Loss: 0.0793%\n",
      "Epoch [87/300], Step [206/225], Training Accuracy: 97.4211%, Training Loss: 0.0795%\n",
      "Epoch [87/300], Step [207/225], Training Accuracy: 97.4185%, Training Loss: 0.0794%\n",
      "Epoch [87/300], Step [208/225], Training Accuracy: 97.4159%, Training Loss: 0.0793%\n",
      "Epoch [87/300], Step [209/225], Training Accuracy: 97.3983%, Training Loss: 0.0796%\n",
      "Epoch [87/300], Step [210/225], Training Accuracy: 97.3958%, Training Loss: 0.0799%\n",
      "Epoch [87/300], Step [211/225], Training Accuracy: 97.3934%, Training Loss: 0.0799%\n",
      "Epoch [87/300], Step [212/225], Training Accuracy: 97.3835%, Training Loss: 0.0800%\n",
      "Epoch [87/300], Step [213/225], Training Accuracy: 97.3958%, Training Loss: 0.0798%\n",
      "Epoch [87/300], Step [214/225], Training Accuracy: 97.4007%, Training Loss: 0.0796%\n",
      "Epoch [87/300], Step [215/225], Training Accuracy: 97.4128%, Training Loss: 0.0795%\n",
      "Epoch [87/300], Step [216/225], Training Accuracy: 97.4175%, Training Loss: 0.0796%\n",
      "Epoch [87/300], Step [217/225], Training Accuracy: 97.4006%, Training Loss: 0.0797%\n",
      "Epoch [87/300], Step [218/225], Training Accuracy: 97.3839%, Training Loss: 0.0800%\n",
      "Epoch [87/300], Step [219/225], Training Accuracy: 97.3744%, Training Loss: 0.0802%\n",
      "Epoch [87/300], Step [220/225], Training Accuracy: 97.3722%, Training Loss: 0.0802%\n",
      "Epoch [87/300], Step [221/225], Training Accuracy: 97.3840%, Training Loss: 0.0800%\n",
      "Epoch [87/300], Step [222/225], Training Accuracy: 97.3818%, Training Loss: 0.0800%\n",
      "Epoch [87/300], Step [223/225], Training Accuracy: 97.3725%, Training Loss: 0.0799%\n",
      "Epoch [87/300], Step [224/225], Training Accuracy: 97.3772%, Training Loss: 0.0799%\n",
      "Epoch [87/300], Step [225/225], Training Accuracy: 97.3805%, Training Loss: 0.0797%\n",
      "Epoch [88/300], Step [1/225], Training Accuracy: 96.8750%, Training Loss: 0.0755%\n",
      "Epoch [88/300], Step [2/225], Training Accuracy: 96.8750%, Training Loss: 0.0838%\n",
      "Epoch [88/300], Step [3/225], Training Accuracy: 96.3542%, Training Loss: 0.1014%\n",
      "Epoch [88/300], Step [4/225], Training Accuracy: 96.4844%, Training Loss: 0.0872%\n",
      "Epoch [88/300], Step [5/225], Training Accuracy: 96.8750%, Training Loss: 0.0833%\n",
      "Epoch [88/300], Step [6/225], Training Accuracy: 96.8750%, Training Loss: 0.0851%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/300], Step [7/225], Training Accuracy: 97.0982%, Training Loss: 0.0818%\n",
      "Epoch [88/300], Step [8/225], Training Accuracy: 97.2656%, Training Loss: 0.0750%\n",
      "Epoch [88/300], Step [9/225], Training Accuracy: 97.2222%, Training Loss: 0.0738%\n",
      "Epoch [88/300], Step [10/225], Training Accuracy: 97.3438%, Training Loss: 0.0694%\n",
      "Epoch [88/300], Step [11/225], Training Accuracy: 97.3011%, Training Loss: 0.0692%\n",
      "Epoch [88/300], Step [12/225], Training Accuracy: 97.3958%, Training Loss: 0.0660%\n",
      "Epoch [88/300], Step [13/225], Training Accuracy: 97.4760%, Training Loss: 0.0667%\n",
      "Epoch [88/300], Step [14/225], Training Accuracy: 97.5446%, Training Loss: 0.0674%\n",
      "Epoch [88/300], Step [15/225], Training Accuracy: 97.6042%, Training Loss: 0.0669%\n",
      "Epoch [88/300], Step [16/225], Training Accuracy: 97.6562%, Training Loss: 0.0675%\n",
      "Epoch [88/300], Step [17/225], Training Accuracy: 97.2426%, Training Loss: 0.0750%\n",
      "Epoch [88/300], Step [18/225], Training Accuracy: 96.9618%, Training Loss: 0.0775%\n",
      "Epoch [88/300], Step [19/225], Training Accuracy: 96.9572%, Training Loss: 0.0774%\n",
      "Epoch [88/300], Step [20/225], Training Accuracy: 96.8750%, Training Loss: 0.0785%\n",
      "Epoch [88/300], Step [21/225], Training Accuracy: 96.8750%, Training Loss: 0.0777%\n",
      "Epoch [88/300], Step [22/225], Training Accuracy: 96.8750%, Training Loss: 0.0787%\n",
      "Epoch [88/300], Step [23/225], Training Accuracy: 96.8750%, Training Loss: 0.0794%\n",
      "Epoch [88/300], Step [24/225], Training Accuracy: 96.7448%, Training Loss: 0.0828%\n",
      "Epoch [88/300], Step [25/225], Training Accuracy: 96.7500%, Training Loss: 0.0812%\n",
      "Epoch [88/300], Step [26/225], Training Accuracy: 96.6947%, Training Loss: 0.0823%\n",
      "Epoch [88/300], Step [27/225], Training Accuracy: 96.7014%, Training Loss: 0.0840%\n",
      "Epoch [88/300], Step [28/225], Training Accuracy: 96.5960%, Training Loss: 0.0855%\n",
      "Epoch [88/300], Step [29/225], Training Accuracy: 96.6056%, Training Loss: 0.0856%\n",
      "Epoch [88/300], Step [30/225], Training Accuracy: 96.6146%, Training Loss: 0.0865%\n",
      "Epoch [88/300], Step [31/225], Training Accuracy: 96.6734%, Training Loss: 0.0860%\n",
      "Epoch [88/300], Step [32/225], Training Accuracy: 96.5820%, Training Loss: 0.0867%\n",
      "Epoch [88/300], Step [33/225], Training Accuracy: 96.5909%, Training Loss: 0.0873%\n",
      "Epoch [88/300], Step [34/225], Training Accuracy: 96.5533%, Training Loss: 0.0878%\n",
      "Epoch [88/300], Step [35/225], Training Accuracy: 96.4732%, Training Loss: 0.0894%\n",
      "Epoch [88/300], Step [36/225], Training Accuracy: 96.5712%, Training Loss: 0.0875%\n",
      "Epoch [88/300], Step [37/225], Training Accuracy: 96.5794%, Training Loss: 0.0886%\n",
      "Epoch [88/300], Step [38/225], Training Accuracy: 96.5872%, Training Loss: 0.0898%\n",
      "Epoch [88/300], Step [39/225], Training Accuracy: 96.6346%, Training Loss: 0.0892%\n",
      "Epoch [88/300], Step [40/225], Training Accuracy: 96.6406%, Training Loss: 0.0896%\n",
      "Epoch [88/300], Step [41/225], Training Accuracy: 96.6845%, Training Loss: 0.0888%\n",
      "Epoch [88/300], Step [42/225], Training Accuracy: 96.6890%, Training Loss: 0.0891%\n",
      "Epoch [88/300], Step [43/225], Training Accuracy: 96.7297%, Training Loss: 0.0881%\n",
      "Epoch [88/300], Step [44/225], Training Accuracy: 96.7685%, Training Loss: 0.0874%\n",
      "Epoch [88/300], Step [45/225], Training Accuracy: 96.8056%, Training Loss: 0.0864%\n",
      "Epoch [88/300], Step [46/225], Training Accuracy: 96.8071%, Training Loss: 0.0865%\n",
      "Epoch [88/300], Step [47/225], Training Accuracy: 96.8418%, Training Loss: 0.0865%\n",
      "Epoch [88/300], Step [48/225], Training Accuracy: 96.8424%, Training Loss: 0.0861%\n",
      "Epoch [88/300], Step [49/225], Training Accuracy: 96.8431%, Training Loss: 0.0855%\n",
      "Epoch [88/300], Step [50/225], Training Accuracy: 96.9062%, Training Loss: 0.0847%\n",
      "Epoch [88/300], Step [51/225], Training Accuracy: 96.9363%, Training Loss: 0.0846%\n",
      "Epoch [88/300], Step [52/225], Training Accuracy: 96.9351%, Training Loss: 0.0841%\n",
      "Epoch [88/300], Step [53/225], Training Accuracy: 96.9634%, Training Loss: 0.0836%\n",
      "Epoch [88/300], Step [54/225], Training Accuracy: 96.8750%, Training Loss: 0.0846%\n",
      "Epoch [88/300], Step [55/225], Training Accuracy: 96.9034%, Training Loss: 0.0840%\n",
      "Epoch [88/300], Step [56/225], Training Accuracy: 96.8750%, Training Loss: 0.0845%\n",
      "Epoch [88/300], Step [57/225], Training Accuracy: 96.9298%, Training Loss: 0.0833%\n",
      "Epoch [88/300], Step [58/225], Training Accuracy: 96.9289%, Training Loss: 0.0834%\n",
      "Epoch [88/300], Step [59/225], Training Accuracy: 96.8750%, Training Loss: 0.0849%\n",
      "Epoch [88/300], Step [60/225], Training Accuracy: 96.9271%, Training Loss: 0.0841%\n",
      "Epoch [88/300], Step [61/225], Training Accuracy: 96.7982%, Training Loss: 0.0878%\n",
      "Epoch [88/300], Step [62/225], Training Accuracy: 96.7742%, Training Loss: 0.0877%\n",
      "Epoch [88/300], Step [63/225], Training Accuracy: 96.7758%, Training Loss: 0.0876%\n",
      "Epoch [88/300], Step [64/225], Training Accuracy: 96.7529%, Training Loss: 0.0877%\n",
      "Epoch [88/300], Step [65/225], Training Accuracy: 96.7788%, Training Loss: 0.0873%\n",
      "Epoch [88/300], Step [66/225], Training Accuracy: 96.8040%, Training Loss: 0.0873%\n",
      "Epoch [88/300], Step [67/225], Training Accuracy: 96.8517%, Training Loss: 0.0864%\n",
      "Epoch [88/300], Step [68/225], Training Accuracy: 96.8750%, Training Loss: 0.0867%\n",
      "Epoch [88/300], Step [69/225], Training Accuracy: 96.8750%, Training Loss: 0.0865%\n",
      "Epoch [88/300], Step [70/225], Training Accuracy: 96.8750%, Training Loss: 0.0861%\n",
      "Epoch [88/300], Step [71/225], Training Accuracy: 96.8750%, Training Loss: 0.0860%\n",
      "Epoch [88/300], Step [72/225], Training Accuracy: 96.8533%, Training Loss: 0.0870%\n",
      "Epoch [88/300], Step [73/225], Training Accuracy: 96.8536%, Training Loss: 0.0873%\n",
      "Epoch [88/300], Step [74/225], Training Accuracy: 96.8117%, Training Loss: 0.0876%\n",
      "Epoch [88/300], Step [75/225], Training Accuracy: 96.8125%, Training Loss: 0.0873%\n",
      "Epoch [88/300], Step [76/225], Training Accuracy: 96.8544%, Training Loss: 0.0865%\n",
      "Epoch [88/300], Step [77/225], Training Accuracy: 96.8344%, Training Loss: 0.0866%\n",
      "Epoch [88/300], Step [78/225], Training Accuracy: 96.8550%, Training Loss: 0.0862%\n",
      "Epoch [88/300], Step [79/225], Training Accuracy: 96.8552%, Training Loss: 0.0864%\n",
      "Epoch [88/300], Step [80/225], Training Accuracy: 96.8359%, Training Loss: 0.0868%\n",
      "Epoch [88/300], Step [81/225], Training Accuracy: 96.8750%, Training Loss: 0.0859%\n",
      "Epoch [88/300], Step [82/225], Training Accuracy: 96.9131%, Training Loss: 0.0853%\n",
      "Epoch [88/300], Step [83/225], Training Accuracy: 96.8938%, Training Loss: 0.0859%\n",
      "Epoch [88/300], Step [84/225], Training Accuracy: 96.9308%, Training Loss: 0.0851%\n",
      "Epoch [88/300], Step [85/225], Training Accuracy: 96.9301%, Training Loss: 0.0848%\n",
      "Epoch [88/300], Step [86/225], Training Accuracy: 96.9477%, Training Loss: 0.0845%\n",
      "Epoch [88/300], Step [87/225], Training Accuracy: 96.9289%, Training Loss: 0.0847%\n",
      "Epoch [88/300], Step [88/225], Training Accuracy: 96.9283%, Training Loss: 0.0848%\n",
      "Epoch [88/300], Step [89/225], Training Accuracy: 96.9452%, Training Loss: 0.0849%\n",
      "Epoch [88/300], Step [90/225], Training Accuracy: 96.9444%, Training Loss: 0.0855%\n",
      "Epoch [88/300], Step [91/225], Training Accuracy: 96.9093%, Training Loss: 0.0860%\n",
      "Epoch [88/300], Step [92/225], Training Accuracy: 96.8750%, Training Loss: 0.0861%\n",
      "Epoch [88/300], Step [93/225], Training Accuracy: 96.9086%, Training Loss: 0.0856%\n",
      "Epoch [88/300], Step [94/225], Training Accuracy: 96.9415%, Training Loss: 0.0851%\n",
      "Epoch [88/300], Step [95/225], Training Accuracy: 96.9243%, Training Loss: 0.0856%\n",
      "Epoch [88/300], Step [96/225], Training Accuracy: 96.8913%, Training Loss: 0.0860%\n",
      "Epoch [88/300], Step [97/225], Training Accuracy: 96.9072%, Training Loss: 0.0864%\n",
      "Epoch [88/300], Step [98/225], Training Accuracy: 96.8909%, Training Loss: 0.0865%\n",
      "Epoch [88/300], Step [99/225], Training Accuracy: 96.8908%, Training Loss: 0.0864%\n",
      "Epoch [88/300], Step [100/225], Training Accuracy: 96.8750%, Training Loss: 0.0868%\n",
      "Epoch [88/300], Step [101/225], Training Accuracy: 96.9059%, Training Loss: 0.0861%\n",
      "Epoch [88/300], Step [102/225], Training Accuracy: 96.9056%, Training Loss: 0.0864%\n",
      "Epoch [88/300], Step [103/225], Training Accuracy: 96.9205%, Training Loss: 0.0862%\n",
      "Epoch [88/300], Step [104/225], Training Accuracy: 96.9201%, Training Loss: 0.0863%\n",
      "Epoch [88/300], Step [105/225], Training Accuracy: 96.9196%, Training Loss: 0.0871%\n",
      "Epoch [88/300], Step [106/225], Training Accuracy: 96.9192%, Training Loss: 0.0879%\n",
      "Epoch [88/300], Step [107/225], Training Accuracy: 96.9480%, Training Loss: 0.0874%\n",
      "Epoch [88/300], Step [108/225], Training Accuracy: 96.9329%, Training Loss: 0.0876%\n",
      "Epoch [88/300], Step [109/225], Training Accuracy: 96.9323%, Training Loss: 0.0875%\n",
      "Epoch [88/300], Step [110/225], Training Accuracy: 96.9176%, Training Loss: 0.0874%\n",
      "Epoch [88/300], Step [111/225], Training Accuracy: 96.9454%, Training Loss: 0.0870%\n",
      "Epoch [88/300], Step [112/225], Training Accuracy: 96.9727%, Training Loss: 0.0867%\n",
      "Epoch [88/300], Step [113/225], Training Accuracy: 96.9718%, Training Loss: 0.0865%\n",
      "Epoch [88/300], Step [114/225], Training Accuracy: 96.9709%, Training Loss: 0.0862%\n",
      "Epoch [88/300], Step [115/225], Training Accuracy: 96.9837%, Training Loss: 0.0866%\n",
      "Epoch [88/300], Step [116/225], Training Accuracy: 96.9828%, Training Loss: 0.0864%\n",
      "Epoch [88/300], Step [117/225], Training Accuracy: 96.9685%, Training Loss: 0.0864%\n",
      "Epoch [88/300], Step [118/225], Training Accuracy: 96.9280%, Training Loss: 0.0871%\n",
      "Epoch [88/300], Step [119/225], Training Accuracy: 96.9407%, Training Loss: 0.0869%\n",
      "Epoch [88/300], Step [120/225], Training Accuracy: 96.9531%, Training Loss: 0.0866%\n",
      "Epoch [88/300], Step [121/225], Training Accuracy: 96.9654%, Training Loss: 0.0866%\n",
      "Epoch [88/300], Step [122/225], Training Accuracy: 96.9647%, Training Loss: 0.0866%\n",
      "Epoch [88/300], Step [123/225], Training Accuracy: 96.9766%, Training Loss: 0.0866%\n",
      "Epoch [88/300], Step [124/225], Training Accuracy: 97.0010%, Training Loss: 0.0863%\n",
      "Epoch [88/300], Step [125/225], Training Accuracy: 97.0250%, Training Loss: 0.0860%\n",
      "Epoch [88/300], Step [126/225], Training Accuracy: 96.9990%, Training Loss: 0.0864%\n",
      "Epoch [88/300], Step [127/225], Training Accuracy: 96.9857%, Training Loss: 0.0867%\n",
      "Epoch [88/300], Step [128/225], Training Accuracy: 96.9604%, Training Loss: 0.0869%\n",
      "Epoch [88/300], Step [129/225], Training Accuracy: 96.9477%, Training Loss: 0.0872%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/300], Step [130/225], Training Accuracy: 96.9591%, Training Loss: 0.0869%\n",
      "Epoch [88/300], Step [131/225], Training Accuracy: 96.9704%, Training Loss: 0.0872%\n",
      "Epoch [88/300], Step [132/225], Training Accuracy: 96.9934%, Training Loss: 0.0866%\n",
      "Epoch [88/300], Step [133/225], Training Accuracy: 97.0042%, Training Loss: 0.0865%\n",
      "Epoch [88/300], Step [134/225], Training Accuracy: 97.0033%, Training Loss: 0.0865%\n",
      "Epoch [88/300], Step [135/225], Training Accuracy: 97.0023%, Training Loss: 0.0863%\n",
      "Epoch [88/300], Step [136/225], Training Accuracy: 97.0129%, Training Loss: 0.0860%\n",
      "Epoch [88/300], Step [137/225], Training Accuracy: 96.9891%, Training Loss: 0.0866%\n",
      "Epoch [88/300], Step [138/225], Training Accuracy: 97.0109%, Training Loss: 0.0861%\n",
      "Epoch [88/300], Step [139/225], Training Accuracy: 96.9987%, Training Loss: 0.0862%\n",
      "Epoch [88/300], Step [140/225], Training Accuracy: 96.9754%, Training Loss: 0.0865%\n",
      "Epoch [88/300], Step [141/225], Training Accuracy: 96.9637%, Training Loss: 0.0868%\n",
      "Epoch [88/300], Step [142/225], Training Accuracy: 96.9520%, Training Loss: 0.0870%\n",
      "Epoch [88/300], Step [143/225], Training Accuracy: 96.9406%, Training Loss: 0.0871%\n",
      "Epoch [88/300], Step [144/225], Training Accuracy: 96.9618%, Training Loss: 0.0867%\n",
      "Epoch [88/300], Step [145/225], Training Accuracy: 96.9612%, Training Loss: 0.0865%\n",
      "Epoch [88/300], Step [146/225], Training Accuracy: 96.9606%, Training Loss: 0.0869%\n",
      "Epoch [88/300], Step [147/225], Training Accuracy: 96.9707%, Training Loss: 0.0866%\n",
      "Epoch [88/300], Step [148/225], Training Accuracy: 96.9700%, Training Loss: 0.0868%\n",
      "Epoch [88/300], Step [149/225], Training Accuracy: 96.9694%, Training Loss: 0.0868%\n",
      "Epoch [88/300], Step [150/225], Training Accuracy: 96.9688%, Training Loss: 0.0868%\n",
      "Epoch [88/300], Step [151/225], Training Accuracy: 96.9785%, Training Loss: 0.0865%\n",
      "Epoch [88/300], Step [152/225], Training Accuracy: 96.9778%, Training Loss: 0.0865%\n",
      "Epoch [88/300], Step [153/225], Training Accuracy: 96.9975%, Training Loss: 0.0861%\n",
      "Epoch [88/300], Step [154/225], Training Accuracy: 97.0069%, Training Loss: 0.0863%\n",
      "Epoch [88/300], Step [155/225], Training Accuracy: 97.0161%, Training Loss: 0.0860%\n",
      "Epoch [88/300], Step [156/225], Training Accuracy: 97.0252%, Training Loss: 0.0857%\n",
      "Epoch [88/300], Step [157/225], Training Accuracy: 97.0044%, Training Loss: 0.0863%\n",
      "Epoch [88/300], Step [158/225], Training Accuracy: 97.0036%, Training Loss: 0.0860%\n",
      "Epoch [88/300], Step [159/225], Training Accuracy: 97.0126%, Training Loss: 0.0858%\n",
      "Epoch [88/300], Step [160/225], Training Accuracy: 97.0020%, Training Loss: 0.0858%\n",
      "Epoch [88/300], Step [161/225], Training Accuracy: 97.0109%, Training Loss: 0.0855%\n",
      "Epoch [88/300], Step [162/225], Training Accuracy: 97.0004%, Training Loss: 0.0856%\n",
      "Epoch [88/300], Step [163/225], Training Accuracy: 97.0092%, Training Loss: 0.0855%\n",
      "Epoch [88/300], Step [164/225], Training Accuracy: 96.9989%, Training Loss: 0.0856%\n",
      "Epoch [88/300], Step [165/225], Training Accuracy: 96.9886%, Training Loss: 0.0855%\n",
      "Epoch [88/300], Step [166/225], Training Accuracy: 96.9880%, Training Loss: 0.0857%\n",
      "Epoch [88/300], Step [167/225], Training Accuracy: 96.9779%, Training Loss: 0.0859%\n",
      "Epoch [88/300], Step [168/225], Training Accuracy: 96.9866%, Training Loss: 0.0856%\n",
      "Epoch [88/300], Step [169/225], Training Accuracy: 96.9675%, Training Loss: 0.0862%\n",
      "Epoch [88/300], Step [170/225], Training Accuracy: 96.9669%, Training Loss: 0.0862%\n",
      "Epoch [88/300], Step [171/225], Training Accuracy: 96.9390%, Training Loss: 0.0869%\n",
      "Epoch [88/300], Step [172/225], Training Accuracy: 96.9568%, Training Loss: 0.0866%\n",
      "Epoch [88/300], Step [173/225], Training Accuracy: 96.9563%, Training Loss: 0.0867%\n",
      "Epoch [88/300], Step [174/225], Training Accuracy: 96.9558%, Training Loss: 0.0867%\n",
      "Epoch [88/300], Step [175/225], Training Accuracy: 96.9464%, Training Loss: 0.0867%\n",
      "Epoch [88/300], Step [176/225], Training Accuracy: 96.9371%, Training Loss: 0.0866%\n",
      "Epoch [88/300], Step [177/225], Training Accuracy: 96.9544%, Training Loss: 0.0864%\n",
      "Epoch [88/300], Step [178/225], Training Accuracy: 96.9628%, Training Loss: 0.0863%\n",
      "Epoch [88/300], Step [179/225], Training Accuracy: 96.9623%, Training Loss: 0.0863%\n",
      "Epoch [88/300], Step [180/225], Training Accuracy: 96.9618%, Training Loss: 0.0861%\n",
      "Epoch [88/300], Step [181/225], Training Accuracy: 96.9700%, Training Loss: 0.0859%\n",
      "Epoch [88/300], Step [182/225], Training Accuracy: 96.9780%, Training Loss: 0.0857%\n",
      "Epoch [88/300], Step [183/225], Training Accuracy: 96.9860%, Training Loss: 0.0855%\n",
      "Epoch [88/300], Step [184/225], Training Accuracy: 97.0024%, Training Loss: 0.0853%\n",
      "Epoch [88/300], Step [185/225], Training Accuracy: 97.0186%, Training Loss: 0.0850%\n",
      "Epoch [88/300], Step [186/225], Training Accuracy: 97.0346%, Training Loss: 0.0847%\n",
      "Epoch [88/300], Step [187/225], Training Accuracy: 97.0254%, Training Loss: 0.0847%\n",
      "Epoch [88/300], Step [188/225], Training Accuracy: 97.0329%, Training Loss: 0.0845%\n",
      "Epoch [88/300], Step [189/225], Training Accuracy: 97.0486%, Training Loss: 0.0841%\n",
      "Epoch [88/300], Step [190/225], Training Accuracy: 97.0230%, Training Loss: 0.0846%\n",
      "Epoch [88/300], Step [191/225], Training Accuracy: 97.0223%, Training Loss: 0.0846%\n",
      "Epoch [88/300], Step [192/225], Training Accuracy: 97.0215%, Training Loss: 0.0845%\n",
      "Epoch [88/300], Step [193/225], Training Accuracy: 97.0207%, Training Loss: 0.0844%\n",
      "Epoch [88/300], Step [194/225], Training Accuracy: 97.0361%, Training Loss: 0.0842%\n",
      "Epoch [88/300], Step [195/225], Training Accuracy: 97.0353%, Training Loss: 0.0843%\n",
      "Epoch [88/300], Step [196/225], Training Accuracy: 97.0344%, Training Loss: 0.0841%\n",
      "Epoch [88/300], Step [197/225], Training Accuracy: 97.0416%, Training Loss: 0.0839%\n",
      "Epoch [88/300], Step [198/225], Training Accuracy: 97.0407%, Training Loss: 0.0838%\n",
      "Epoch [88/300], Step [199/225], Training Accuracy: 97.0477%, Training Loss: 0.0839%\n",
      "Epoch [88/300], Step [200/225], Training Accuracy: 97.0547%, Training Loss: 0.0839%\n",
      "Epoch [88/300], Step [201/225], Training Accuracy: 97.0460%, Training Loss: 0.0840%\n",
      "Epoch [88/300], Step [202/225], Training Accuracy: 97.0374%, Training Loss: 0.0846%\n",
      "Epoch [88/300], Step [203/225], Training Accuracy: 97.0366%, Training Loss: 0.0846%\n",
      "Epoch [88/300], Step [204/225], Training Accuracy: 97.0282%, Training Loss: 0.0847%\n",
      "Epoch [88/300], Step [205/225], Training Accuracy: 97.0198%, Training Loss: 0.0850%\n",
      "Epoch [88/300], Step [206/225], Training Accuracy: 97.0191%, Training Loss: 0.0850%\n",
      "Epoch [88/300], Step [207/225], Training Accuracy: 97.0184%, Training Loss: 0.0850%\n",
      "Epoch [88/300], Step [208/225], Training Accuracy: 97.0252%, Training Loss: 0.0848%\n",
      "Epoch [88/300], Step [209/225], Training Accuracy: 97.0170%, Training Loss: 0.0849%\n",
      "Epoch [88/300], Step [210/225], Training Accuracy: 97.0238%, Training Loss: 0.0847%\n",
      "Epoch [88/300], Step [211/225], Training Accuracy: 97.0305%, Training Loss: 0.0850%\n",
      "Epoch [88/300], Step [212/225], Training Accuracy: 97.0150%, Training Loss: 0.0853%\n",
      "Epoch [88/300], Step [213/225], Training Accuracy: 97.0144%, Training Loss: 0.0852%\n",
      "Epoch [88/300], Step [214/225], Training Accuracy: 97.0137%, Training Loss: 0.0851%\n",
      "Epoch [88/300], Step [215/225], Training Accuracy: 96.9767%, Training Loss: 0.0857%\n",
      "Epoch [88/300], Step [216/225], Training Accuracy: 96.9763%, Training Loss: 0.0862%\n",
      "Epoch [88/300], Step [217/225], Training Accuracy: 96.9758%, Training Loss: 0.0863%\n",
      "Epoch [88/300], Step [218/225], Training Accuracy: 96.9825%, Training Loss: 0.0863%\n",
      "Epoch [88/300], Step [219/225], Training Accuracy: 96.9892%, Training Loss: 0.0862%\n",
      "Epoch [88/300], Step [220/225], Training Accuracy: 97.0028%, Training Loss: 0.0859%\n",
      "Epoch [88/300], Step [221/225], Training Accuracy: 97.0023%, Training Loss: 0.0860%\n",
      "Epoch [88/300], Step [222/225], Training Accuracy: 96.9947%, Training Loss: 0.0863%\n",
      "Epoch [88/300], Step [223/225], Training Accuracy: 96.9941%, Training Loss: 0.0863%\n",
      "Epoch [88/300], Step [224/225], Training Accuracy: 97.0006%, Training Loss: 0.0861%\n",
      "Epoch [88/300], Step [225/225], Training Accuracy: 96.9983%, Training Loss: 0.0861%\n",
      "Epoch [89/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0381%\n",
      "Epoch [89/300], Step [2/225], Training Accuracy: 96.0938%, Training Loss: 0.1030%\n",
      "Epoch [89/300], Step [3/225], Training Accuracy: 94.7917%, Training Loss: 0.1098%\n",
      "Epoch [89/300], Step [4/225], Training Accuracy: 95.7031%, Training Loss: 0.0976%\n",
      "Epoch [89/300], Step [5/225], Training Accuracy: 94.6875%, Training Loss: 0.1389%\n",
      "Epoch [89/300], Step [6/225], Training Accuracy: 94.7917%, Training Loss: 0.1290%\n",
      "Epoch [89/300], Step [7/225], Training Accuracy: 94.4196%, Training Loss: 0.1393%\n",
      "Epoch [89/300], Step [8/225], Training Accuracy: 94.7266%, Training Loss: 0.1297%\n",
      "Epoch [89/300], Step [9/225], Training Accuracy: 95.1389%, Training Loss: 0.1244%\n",
      "Epoch [89/300], Step [10/225], Training Accuracy: 95.3125%, Training Loss: 0.1223%\n",
      "Epoch [89/300], Step [11/225], Training Accuracy: 95.5966%, Training Loss: 0.1210%\n",
      "Epoch [89/300], Step [12/225], Training Accuracy: 95.7031%, Training Loss: 0.1158%\n",
      "Epoch [89/300], Step [13/225], Training Accuracy: 95.9135%, Training Loss: 0.1148%\n",
      "Epoch [89/300], Step [14/225], Training Accuracy: 95.8705%, Training Loss: 0.1143%\n",
      "Epoch [89/300], Step [15/225], Training Accuracy: 96.0417%, Training Loss: 0.1091%\n",
      "Epoch [89/300], Step [16/225], Training Accuracy: 96.2891%, Training Loss: 0.1040%\n",
      "Epoch [89/300], Step [17/225], Training Accuracy: 96.0478%, Training Loss: 0.1080%\n",
      "Epoch [89/300], Step [18/225], Training Accuracy: 95.9201%, Training Loss: 0.1086%\n",
      "Epoch [89/300], Step [19/225], Training Accuracy: 96.0526%, Training Loss: 0.1050%\n",
      "Epoch [89/300], Step [20/225], Training Accuracy: 96.1719%, Training Loss: 0.1017%\n",
      "Epoch [89/300], Step [21/225], Training Accuracy: 96.2798%, Training Loss: 0.1013%\n",
      "Epoch [89/300], Step [22/225], Training Accuracy: 96.2358%, Training Loss: 0.1014%\n",
      "Epoch [89/300], Step [23/225], Training Accuracy: 96.1957%, Training Loss: 0.1014%\n",
      "Epoch [89/300], Step [24/225], Training Accuracy: 96.2240%, Training Loss: 0.1006%\n",
      "Epoch [89/300], Step [25/225], Training Accuracy: 96.3125%, Training Loss: 0.0988%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/300], Step [26/225], Training Accuracy: 96.2740%, Training Loss: 0.0991%\n",
      "Epoch [89/300], Step [27/225], Training Accuracy: 96.3542%, Training Loss: 0.0976%\n",
      "Epoch [89/300], Step [28/225], Training Accuracy: 96.4844%, Training Loss: 0.0948%\n",
      "Epoch [89/300], Step [29/225], Training Accuracy: 96.4978%, Training Loss: 0.0941%\n",
      "Epoch [89/300], Step [30/225], Training Accuracy: 96.4062%, Training Loss: 0.0949%\n",
      "Epoch [89/300], Step [31/225], Training Accuracy: 96.3710%, Training Loss: 0.0947%\n",
      "Epoch [89/300], Step [32/225], Training Accuracy: 96.3867%, Training Loss: 0.0958%\n",
      "Epoch [89/300], Step [33/225], Training Accuracy: 96.4015%, Training Loss: 0.0952%\n",
      "Epoch [89/300], Step [34/225], Training Accuracy: 96.3235%, Training Loss: 0.0965%\n",
      "Epoch [89/300], Step [35/225], Training Accuracy: 96.4286%, Training Loss: 0.0946%\n",
      "Epoch [89/300], Step [36/225], Training Accuracy: 96.4844%, Training Loss: 0.0937%\n",
      "Epoch [89/300], Step [37/225], Training Accuracy: 96.5794%, Training Loss: 0.0925%\n",
      "Epoch [89/300], Step [38/225], Training Accuracy: 96.4638%, Training Loss: 0.0935%\n",
      "Epoch [89/300], Step [39/225], Training Accuracy: 96.5144%, Training Loss: 0.0931%\n",
      "Epoch [89/300], Step [40/225], Training Accuracy: 96.6016%, Training Loss: 0.0913%\n",
      "Epoch [89/300], Step [41/225], Training Accuracy: 96.5701%, Training Loss: 0.0932%\n",
      "Epoch [89/300], Step [42/225], Training Accuracy: 96.6518%, Training Loss: 0.0919%\n",
      "Epoch [89/300], Step [43/225], Training Accuracy: 96.6933%, Training Loss: 0.0911%\n",
      "Epoch [89/300], Step [44/225], Training Accuracy: 96.6974%, Training Loss: 0.0913%\n",
      "Epoch [89/300], Step [45/225], Training Accuracy: 96.7361%, Training Loss: 0.0903%\n",
      "Epoch [89/300], Step [46/225], Training Accuracy: 96.7052%, Training Loss: 0.0906%\n",
      "Epoch [89/300], Step [47/225], Training Accuracy: 96.6755%, Training Loss: 0.0905%\n",
      "Epoch [89/300], Step [48/225], Training Accuracy: 96.6797%, Training Loss: 0.0903%\n",
      "Epoch [89/300], Step [49/225], Training Accuracy: 96.6518%, Training Loss: 0.0911%\n",
      "Epoch [89/300], Step [50/225], Training Accuracy: 96.6250%, Training Loss: 0.0907%\n",
      "Epoch [89/300], Step [51/225], Training Accuracy: 96.6605%, Training Loss: 0.0900%\n",
      "Epoch [89/300], Step [52/225], Training Accuracy: 96.6346%, Training Loss: 0.0901%\n",
      "Epoch [89/300], Step [53/225], Training Accuracy: 96.6097%, Training Loss: 0.0902%\n",
      "Epoch [89/300], Step [54/225], Training Accuracy: 96.6435%, Training Loss: 0.0897%\n",
      "Epoch [89/300], Step [55/225], Training Accuracy: 96.5625%, Training Loss: 0.0904%\n",
      "Epoch [89/300], Step [56/225], Training Accuracy: 96.5960%, Training Loss: 0.0899%\n",
      "Epoch [89/300], Step [57/225], Training Accuracy: 96.5735%, Training Loss: 0.0903%\n",
      "Epoch [89/300], Step [58/225], Training Accuracy: 96.6325%, Training Loss: 0.0894%\n",
      "Epoch [89/300], Step [59/225], Training Accuracy: 96.6102%, Training Loss: 0.0895%\n",
      "Epoch [89/300], Step [60/225], Training Accuracy: 96.5885%, Training Loss: 0.0902%\n",
      "Epoch [89/300], Step [61/225], Training Accuracy: 96.5932%, Training Loss: 0.0904%\n",
      "Epoch [89/300], Step [62/225], Training Accuracy: 96.6482%, Training Loss: 0.0896%\n",
      "Epoch [89/300], Step [63/225], Training Accuracy: 96.5774%, Training Loss: 0.0924%\n",
      "Epoch [89/300], Step [64/225], Training Accuracy: 96.6064%, Training Loss: 0.0917%\n",
      "Epoch [89/300], Step [65/225], Training Accuracy: 96.6106%, Training Loss: 0.0918%\n",
      "Epoch [89/300], Step [66/225], Training Accuracy: 96.5909%, Training Loss: 0.0920%\n",
      "Epoch [89/300], Step [67/225], Training Accuracy: 96.5951%, Training Loss: 0.0913%\n",
      "Epoch [89/300], Step [68/225], Training Accuracy: 96.5993%, Training Loss: 0.0923%\n",
      "Epoch [89/300], Step [69/225], Training Accuracy: 96.6259%, Training Loss: 0.0923%\n",
      "Epoch [89/300], Step [70/225], Training Accuracy: 96.6295%, Training Loss: 0.0918%\n",
      "Epoch [89/300], Step [71/225], Training Accuracy: 96.6329%, Training Loss: 0.0934%\n",
      "Epoch [89/300], Step [72/225], Training Accuracy: 96.6797%, Training Loss: 0.0926%\n",
      "Epoch [89/300], Step [73/225], Training Accuracy: 96.6396%, Training Loss: 0.0939%\n",
      "Epoch [89/300], Step [74/225], Training Accuracy: 96.6005%, Training Loss: 0.0941%\n",
      "Epoch [89/300], Step [75/225], Training Accuracy: 96.5833%, Training Loss: 0.0943%\n",
      "Epoch [89/300], Step [76/225], Training Accuracy: 96.5666%, Training Loss: 0.0959%\n",
      "Epoch [89/300], Step [77/225], Training Accuracy: 96.5706%, Training Loss: 0.0957%\n",
      "Epoch [89/300], Step [78/225], Training Accuracy: 96.5745%, Training Loss: 0.0953%\n",
      "Epoch [89/300], Step [79/225], Training Accuracy: 96.5585%, Training Loss: 0.0956%\n",
      "Epoch [89/300], Step [80/225], Training Accuracy: 96.5625%, Training Loss: 0.0955%\n",
      "Epoch [89/300], Step [81/225], Training Accuracy: 96.5664%, Training Loss: 0.0952%\n",
      "Epoch [89/300], Step [82/225], Training Accuracy: 96.5701%, Training Loss: 0.0950%\n",
      "Epoch [89/300], Step [83/225], Training Accuracy: 96.5173%, Training Loss: 0.0970%\n",
      "Epoch [89/300], Step [84/225], Training Accuracy: 96.5216%, Training Loss: 0.0967%\n",
      "Epoch [89/300], Step [85/225], Training Accuracy: 96.5074%, Training Loss: 0.0970%\n",
      "Epoch [89/300], Step [86/225], Training Accuracy: 96.5298%, Training Loss: 0.0969%\n",
      "Epoch [89/300], Step [87/225], Training Accuracy: 96.5517%, Training Loss: 0.0969%\n",
      "Epoch [89/300], Step [88/225], Training Accuracy: 96.5376%, Training Loss: 0.0967%\n",
      "Epoch [89/300], Step [89/225], Training Accuracy: 96.5765%, Training Loss: 0.0964%\n",
      "Epoch [89/300], Step [90/225], Training Accuracy: 96.5799%, Training Loss: 0.0961%\n",
      "Epoch [89/300], Step [91/225], Training Accuracy: 96.5488%, Training Loss: 0.0969%\n",
      "Epoch [89/300], Step [92/225], Training Accuracy: 96.5693%, Training Loss: 0.0965%\n",
      "Epoch [89/300], Step [93/225], Training Accuracy: 96.5726%, Training Loss: 0.0962%\n",
      "Epoch [89/300], Step [94/225], Training Accuracy: 96.5924%, Training Loss: 0.0957%\n",
      "Epoch [89/300], Step [95/225], Training Accuracy: 96.5625%, Training Loss: 0.0960%\n",
      "Epoch [89/300], Step [96/225], Training Accuracy: 96.5820%, Training Loss: 0.0958%\n",
      "Epoch [89/300], Step [97/225], Training Accuracy: 96.6012%, Training Loss: 0.0954%\n",
      "Epoch [89/300], Step [98/225], Training Accuracy: 96.5561%, Training Loss: 0.0969%\n",
      "Epoch [89/300], Step [99/225], Training Accuracy: 96.4962%, Training Loss: 0.0978%\n",
      "Epoch [89/300], Step [100/225], Training Accuracy: 96.5312%, Training Loss: 0.0972%\n",
      "Epoch [89/300], Step [101/225], Training Accuracy: 96.5656%, Training Loss: 0.0968%\n",
      "Epoch [89/300], Step [102/225], Training Accuracy: 96.5993%, Training Loss: 0.0965%\n",
      "Epoch [89/300], Step [103/225], Training Accuracy: 96.6171%, Training Loss: 0.0962%\n",
      "Epoch [89/300], Step [104/225], Training Accuracy: 96.6196%, Training Loss: 0.0963%\n",
      "Epoch [89/300], Step [105/225], Training Accuracy: 96.5923%, Training Loss: 0.0966%\n",
      "Epoch [89/300], Step [106/225], Training Accuracy: 96.6097%, Training Loss: 0.0963%\n",
      "Epoch [89/300], Step [107/225], Training Accuracy: 96.6121%, Training Loss: 0.0964%\n",
      "Epoch [89/300], Step [108/225], Training Accuracy: 96.5712%, Training Loss: 0.0969%\n",
      "Epoch [89/300], Step [109/225], Training Accuracy: 96.5740%, Training Loss: 0.0966%\n",
      "Epoch [89/300], Step [110/225], Training Accuracy: 96.5625%, Training Loss: 0.0965%\n",
      "Epoch [89/300], Step [111/225], Training Accuracy: 96.5653%, Training Loss: 0.0964%\n",
      "Epoch [89/300], Step [112/225], Training Accuracy: 96.5262%, Training Loss: 0.0975%\n",
      "Epoch [89/300], Step [113/225], Training Accuracy: 96.5155%, Training Loss: 0.0982%\n",
      "Epoch [89/300], Step [114/225], Training Accuracy: 96.5186%, Training Loss: 0.0982%\n",
      "Epoch [89/300], Step [115/225], Training Accuracy: 96.5353%, Training Loss: 0.0978%\n",
      "Epoch [89/300], Step [116/225], Training Accuracy: 96.5113%, Training Loss: 0.0983%\n",
      "Epoch [89/300], Step [117/225], Training Accuracy: 96.5278%, Training Loss: 0.0980%\n",
      "Epoch [89/300], Step [118/225], Training Accuracy: 96.5440%, Training Loss: 0.0977%\n",
      "Epoch [89/300], Step [119/225], Training Accuracy: 96.5599%, Training Loss: 0.0975%\n",
      "Epoch [89/300], Step [120/225], Training Accuracy: 96.5495%, Training Loss: 0.0974%\n",
      "Epoch [89/300], Step [121/225], Training Accuracy: 96.5393%, Training Loss: 0.0973%\n",
      "Epoch [89/300], Step [122/225], Training Accuracy: 96.5548%, Training Loss: 0.0968%\n",
      "Epoch [89/300], Step [123/225], Training Accuracy: 96.5701%, Training Loss: 0.0968%\n",
      "Epoch [89/300], Step [124/225], Training Accuracy: 96.5348%, Training Loss: 0.0976%\n",
      "Epoch [89/300], Step [125/225], Training Accuracy: 96.4875%, Training Loss: 0.0980%\n",
      "Epoch [89/300], Step [126/225], Training Accuracy: 96.4534%, Training Loss: 0.0982%\n",
      "Epoch [89/300], Step [127/225], Training Accuracy: 96.4444%, Training Loss: 0.0984%\n",
      "Epoch [89/300], Step [128/225], Training Accuracy: 96.4478%, Training Loss: 0.0990%\n",
      "Epoch [89/300], Step [129/225], Training Accuracy: 96.4511%, Training Loss: 0.0990%\n",
      "Epoch [89/300], Step [130/225], Training Accuracy: 96.4303%, Training Loss: 0.0992%\n",
      "Epoch [89/300], Step [131/225], Training Accuracy: 96.4337%, Training Loss: 0.0989%\n",
      "Epoch [89/300], Step [132/225], Training Accuracy: 96.4370%, Training Loss: 0.0987%\n",
      "Epoch [89/300], Step [133/225], Training Accuracy: 96.4521%, Training Loss: 0.0984%\n",
      "Epoch [89/300], Step [134/225], Training Accuracy: 96.4785%, Training Loss: 0.0980%\n",
      "Epoch [89/300], Step [135/225], Training Accuracy: 96.4699%, Training Loss: 0.0978%\n",
      "Epoch [89/300], Step [136/225], Training Accuracy: 96.4729%, Training Loss: 0.0982%\n",
      "Epoch [89/300], Step [137/225], Training Accuracy: 96.4872%, Training Loss: 0.0980%\n",
      "Epoch [89/300], Step [138/225], Training Accuracy: 96.4787%, Training Loss: 0.0980%\n",
      "Epoch [89/300], Step [139/225], Training Accuracy: 96.4928%, Training Loss: 0.0981%\n",
      "Epoch [89/300], Step [140/225], Training Accuracy: 96.4844%, Training Loss: 0.0981%\n",
      "Epoch [89/300], Step [141/225], Training Accuracy: 96.5093%, Training Loss: 0.0978%\n",
      "Epoch [89/300], Step [142/225], Training Accuracy: 96.5009%, Training Loss: 0.0979%\n",
      "Epoch [89/300], Step [143/225], Training Accuracy: 96.4926%, Training Loss: 0.0979%\n",
      "Epoch [89/300], Step [144/225], Training Accuracy: 96.4844%, Training Loss: 0.0980%\n",
      "Epoch [89/300], Step [145/225], Training Accuracy: 96.4978%, Training Loss: 0.0977%\n",
      "Epoch [89/300], Step [146/225], Training Accuracy: 96.5004%, Training Loss: 0.0976%\n",
      "Epoch [89/300], Step [147/225], Training Accuracy: 96.5136%, Training Loss: 0.0973%\n",
      "Epoch [89/300], Step [148/225], Training Accuracy: 96.5160%, Training Loss: 0.0972%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/300], Step [149/225], Training Accuracy: 96.5080%, Training Loss: 0.0974%\n",
      "Epoch [89/300], Step [150/225], Training Accuracy: 96.5104%, Training Loss: 0.0974%\n",
      "Epoch [89/300], Step [151/225], Training Accuracy: 96.4921%, Training Loss: 0.0975%\n",
      "Epoch [89/300], Step [152/225], Training Accuracy: 96.4844%, Training Loss: 0.0985%\n",
      "Epoch [89/300], Step [153/225], Training Accuracy: 96.4869%, Training Loss: 0.0984%\n",
      "Epoch [89/300], Step [154/225], Training Accuracy: 96.4996%, Training Loss: 0.0982%\n",
      "Epoch [89/300], Step [155/225], Training Accuracy: 96.5020%, Training Loss: 0.0980%\n",
      "Epoch [89/300], Step [156/225], Training Accuracy: 96.5144%, Training Loss: 0.0976%\n",
      "Epoch [89/300], Step [157/225], Training Accuracy: 96.5068%, Training Loss: 0.0976%\n",
      "Epoch [89/300], Step [158/225], Training Accuracy: 96.5190%, Training Loss: 0.0972%\n",
      "Epoch [89/300], Step [159/225], Training Accuracy: 96.5409%, Training Loss: 0.0969%\n",
      "Epoch [89/300], Step [160/225], Training Accuracy: 96.5527%, Training Loss: 0.0968%\n",
      "Epoch [89/300], Step [161/225], Training Accuracy: 96.5644%, Training Loss: 0.0965%\n",
      "Epoch [89/300], Step [162/225], Training Accuracy: 96.5760%, Training Loss: 0.0964%\n",
      "Epoch [89/300], Step [163/225], Training Accuracy: 96.5587%, Training Loss: 0.0968%\n",
      "Epoch [89/300], Step [164/225], Training Accuracy: 96.5320%, Training Loss: 0.0970%\n",
      "Epoch [89/300], Step [165/225], Training Accuracy: 96.5341%, Training Loss: 0.0970%\n",
      "Epoch [89/300], Step [166/225], Training Accuracy: 96.5456%, Training Loss: 0.0967%\n",
      "Epoch [89/300], Step [167/225], Training Accuracy: 96.5569%, Training Loss: 0.0965%\n",
      "Epoch [89/300], Step [168/225], Training Accuracy: 96.5774%, Training Loss: 0.0964%\n",
      "Epoch [89/300], Step [169/225], Training Accuracy: 96.5884%, Training Loss: 0.0962%\n",
      "Epoch [89/300], Step [170/225], Training Accuracy: 96.5717%, Training Loss: 0.0964%\n",
      "Epoch [89/300], Step [171/225], Training Accuracy: 96.5643%, Training Loss: 0.0962%\n",
      "Epoch [89/300], Step [172/225], Training Accuracy: 96.5752%, Training Loss: 0.0961%\n",
      "Epoch [89/300], Step [173/225], Training Accuracy: 96.5770%, Training Loss: 0.0960%\n",
      "Epoch [89/300], Step [174/225], Training Accuracy: 96.5876%, Training Loss: 0.0958%\n",
      "Epoch [89/300], Step [175/225], Training Accuracy: 96.5893%, Training Loss: 0.0956%\n",
      "Epoch [89/300], Step [176/225], Training Accuracy: 96.5909%, Training Loss: 0.0956%\n",
      "Epoch [89/300], Step [177/225], Training Accuracy: 96.6102%, Training Loss: 0.0953%\n",
      "Epoch [89/300], Step [178/225], Training Accuracy: 96.6204%, Training Loss: 0.0954%\n",
      "Epoch [89/300], Step [179/225], Training Accuracy: 96.6306%, Training Loss: 0.0952%\n",
      "Epoch [89/300], Step [180/225], Training Accuracy: 96.6406%, Training Loss: 0.0949%\n",
      "Epoch [89/300], Step [181/225], Training Accuracy: 96.6592%, Training Loss: 0.0946%\n",
      "Epoch [89/300], Step [182/225], Training Accuracy: 96.6604%, Training Loss: 0.0946%\n",
      "Epoch [89/300], Step [183/225], Training Accuracy: 96.6701%, Training Loss: 0.0944%\n",
      "Epoch [89/300], Step [184/225], Training Accuracy: 96.6542%, Training Loss: 0.0947%\n",
      "Epoch [89/300], Step [185/225], Training Accuracy: 96.6554%, Training Loss: 0.0948%\n",
      "Epoch [89/300], Step [186/225], Training Accuracy: 96.6734%, Training Loss: 0.0945%\n",
      "Epoch [89/300], Step [187/225], Training Accuracy: 96.6745%, Training Loss: 0.0944%\n",
      "Epoch [89/300], Step [188/225], Training Accuracy: 96.6922%, Training Loss: 0.0941%\n",
      "Epoch [89/300], Step [189/225], Training Accuracy: 96.7014%, Training Loss: 0.0939%\n",
      "Epoch [89/300], Step [190/225], Training Accuracy: 96.6941%, Training Loss: 0.0941%\n",
      "Epoch [89/300], Step [191/225], Training Accuracy: 96.7032%, Training Loss: 0.0938%\n",
      "Epoch [89/300], Step [192/225], Training Accuracy: 96.6960%, Training Loss: 0.0938%\n",
      "Epoch [89/300], Step [193/225], Training Accuracy: 96.6888%, Training Loss: 0.0940%\n",
      "Epoch [89/300], Step [194/225], Training Accuracy: 96.6978%, Training Loss: 0.0938%\n",
      "Epoch [89/300], Step [195/225], Training Accuracy: 96.6987%, Training Loss: 0.0940%\n",
      "Epoch [89/300], Step [196/225], Training Accuracy: 96.7156%, Training Loss: 0.0936%\n",
      "Epoch [89/300], Step [197/225], Training Accuracy: 96.7243%, Training Loss: 0.0934%\n",
      "Epoch [89/300], Step [198/225], Training Accuracy: 96.7408%, Training Loss: 0.0932%\n",
      "Epoch [89/300], Step [199/225], Training Accuracy: 96.7494%, Training Loss: 0.0932%\n",
      "Epoch [89/300], Step [200/225], Training Accuracy: 96.7500%, Training Loss: 0.0931%\n",
      "Epoch [89/300], Step [201/225], Training Accuracy: 96.7662%, Training Loss: 0.0929%\n",
      "Epoch [89/300], Step [202/225], Training Accuracy: 96.7590%, Training Loss: 0.0928%\n",
      "Epoch [89/300], Step [203/225], Training Accuracy: 96.7672%, Training Loss: 0.0927%\n",
      "Epoch [89/300], Step [204/225], Training Accuracy: 96.7754%, Training Loss: 0.0925%\n",
      "Epoch [89/300], Step [205/225], Training Accuracy: 96.7683%, Training Loss: 0.0926%\n",
      "Epoch [89/300], Step [206/225], Training Accuracy: 96.7536%, Training Loss: 0.0928%\n",
      "Epoch [89/300], Step [207/225], Training Accuracy: 96.7693%, Training Loss: 0.0925%\n",
      "Epoch [89/300], Step [208/225], Training Accuracy: 96.7623%, Training Loss: 0.0924%\n",
      "Epoch [89/300], Step [209/225], Training Accuracy: 96.7703%, Training Loss: 0.0922%\n",
      "Epoch [89/300], Step [210/225], Training Accuracy: 96.7560%, Training Loss: 0.0923%\n",
      "Epoch [89/300], Step [211/225], Training Accuracy: 96.7713%, Training Loss: 0.0920%\n",
      "Epoch [89/300], Step [212/225], Training Accuracy: 96.7718%, Training Loss: 0.0920%\n",
      "Epoch [89/300], Step [213/225], Training Accuracy: 96.7723%, Training Loss: 0.0919%\n",
      "Epoch [89/300], Step [214/225], Training Accuracy: 96.7874%, Training Loss: 0.0918%\n",
      "Epoch [89/300], Step [215/225], Training Accuracy: 96.7951%, Training Loss: 0.0916%\n",
      "Epoch [89/300], Step [216/225], Training Accuracy: 96.7593%, Training Loss: 0.0925%\n",
      "Epoch [89/300], Step [217/225], Training Accuracy: 96.7670%, Training Loss: 0.0924%\n",
      "Epoch [89/300], Step [218/225], Training Accuracy: 96.7747%, Training Loss: 0.0922%\n",
      "Epoch [89/300], Step [219/225], Training Accuracy: 96.7751%, Training Loss: 0.0920%\n",
      "Epoch [89/300], Step [220/225], Training Accuracy: 96.7827%, Training Loss: 0.0917%\n",
      "Epoch [89/300], Step [221/225], Training Accuracy: 96.7760%, Training Loss: 0.0918%\n",
      "Epoch [89/300], Step [222/225], Training Accuracy: 96.7835%, Training Loss: 0.0917%\n",
      "Epoch [89/300], Step [223/225], Training Accuracy: 96.7979%, Training Loss: 0.0915%\n",
      "Epoch [89/300], Step [224/225], Training Accuracy: 96.7913%, Training Loss: 0.0915%\n",
      "Epoch [89/300], Step [225/225], Training Accuracy: 96.7968%, Training Loss: 0.0914%\n",
      "Epoch [90/300], Step [1/225], Training Accuracy: 96.8750%, Training Loss: 0.0671%\n",
      "Epoch [90/300], Step [2/225], Training Accuracy: 96.8750%, Training Loss: 0.0642%\n",
      "Epoch [90/300], Step [3/225], Training Accuracy: 97.3958%, Training Loss: 0.0788%\n",
      "Epoch [90/300], Step [4/225], Training Accuracy: 97.6562%, Training Loss: 0.0717%\n",
      "Epoch [90/300], Step [5/225], Training Accuracy: 98.1250%, Training Loss: 0.0630%\n",
      "Epoch [90/300], Step [6/225], Training Accuracy: 97.9167%, Training Loss: 0.0732%\n",
      "Epoch [90/300], Step [7/225], Training Accuracy: 97.3214%, Training Loss: 0.0936%\n",
      "Epoch [90/300], Step [8/225], Training Accuracy: 97.4609%, Training Loss: 0.0867%\n",
      "Epoch [90/300], Step [9/225], Training Accuracy: 97.5694%, Training Loss: 0.0822%\n",
      "Epoch [90/300], Step [10/225], Training Accuracy: 97.3438%, Training Loss: 0.0863%\n",
      "Epoch [90/300], Step [11/225], Training Accuracy: 97.5852%, Training Loss: 0.0829%\n",
      "Epoch [90/300], Step [12/225], Training Accuracy: 97.5260%, Training Loss: 0.0812%\n",
      "Epoch [90/300], Step [13/225], Training Accuracy: 97.4760%, Training Loss: 0.0804%\n",
      "Epoch [90/300], Step [14/225], Training Accuracy: 97.2098%, Training Loss: 0.0818%\n",
      "Epoch [90/300], Step [15/225], Training Accuracy: 97.1875%, Training Loss: 0.0875%\n",
      "Epoch [90/300], Step [16/225], Training Accuracy: 97.1680%, Training Loss: 0.0891%\n",
      "Epoch [90/300], Step [17/225], Training Accuracy: 97.0588%, Training Loss: 0.0931%\n",
      "Epoch [90/300], Step [18/225], Training Accuracy: 97.0486%, Training Loss: 0.0947%\n",
      "Epoch [90/300], Step [19/225], Training Accuracy: 97.1217%, Training Loss: 0.0923%\n",
      "Epoch [90/300], Step [20/225], Training Accuracy: 97.1875%, Training Loss: 0.0903%\n",
      "Epoch [90/300], Step [21/225], Training Accuracy: 97.2470%, Training Loss: 0.0889%\n",
      "Epoch [90/300], Step [22/225], Training Accuracy: 97.1591%, Training Loss: 0.0891%\n",
      "Epoch [90/300], Step [23/225], Training Accuracy: 97.2826%, Training Loss: 0.0859%\n",
      "Epoch [90/300], Step [24/225], Training Accuracy: 97.3307%, Training Loss: 0.0845%\n",
      "Epoch [90/300], Step [25/225], Training Accuracy: 97.2500%, Training Loss: 0.0878%\n",
      "Epoch [90/300], Step [26/225], Training Accuracy: 97.3558%, Training Loss: 0.0871%\n",
      "Epoch [90/300], Step [27/225], Training Accuracy: 97.4537%, Training Loss: 0.0860%\n",
      "Epoch [90/300], Step [28/225], Training Accuracy: 97.4330%, Training Loss: 0.0860%\n",
      "Epoch [90/300], Step [29/225], Training Accuracy: 97.3599%, Training Loss: 0.0874%\n",
      "Epoch [90/300], Step [30/225], Training Accuracy: 97.3438%, Training Loss: 0.0869%\n",
      "Epoch [90/300], Step [31/225], Training Accuracy: 97.3286%, Training Loss: 0.0873%\n",
      "Epoch [90/300], Step [32/225], Training Accuracy: 97.3633%, Training Loss: 0.0862%\n",
      "Epoch [90/300], Step [33/225], Training Accuracy: 97.3485%, Training Loss: 0.0854%\n",
      "Epoch [90/300], Step [34/225], Training Accuracy: 97.2886%, Training Loss: 0.0855%\n",
      "Epoch [90/300], Step [35/225], Training Accuracy: 97.1875%, Training Loss: 0.0872%\n",
      "Epoch [90/300], Step [36/225], Training Accuracy: 97.1354%, Training Loss: 0.0878%\n",
      "Epoch [90/300], Step [37/225], Training Accuracy: 97.2128%, Training Loss: 0.0870%\n",
      "Epoch [90/300], Step [38/225], Training Accuracy: 97.2039%, Training Loss: 0.0864%\n",
      "Epoch [90/300], Step [39/225], Training Accuracy: 97.2356%, Training Loss: 0.0859%\n",
      "Epoch [90/300], Step [40/225], Training Accuracy: 97.1875%, Training Loss: 0.0858%\n",
      "Epoch [90/300], Step [41/225], Training Accuracy: 97.1037%, Training Loss: 0.0878%\n",
      "Epoch [90/300], Step [42/225], Training Accuracy: 97.0982%, Training Loss: 0.0890%\n",
      "Epoch [90/300], Step [43/225], Training Accuracy: 97.1657%, Training Loss: 0.0882%\n",
      "Epoch [90/300], Step [44/225], Training Accuracy: 97.1236%, Training Loss: 0.0877%\n",
      "Epoch [90/300], Step [45/225], Training Accuracy: 97.1181%, Training Loss: 0.0879%\n",
      "Epoch [90/300], Step [46/225], Training Accuracy: 97.1807%, Training Loss: 0.0868%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/300], Step [47/225], Training Accuracy: 97.1742%, Training Loss: 0.0866%\n",
      "Epoch [90/300], Step [48/225], Training Accuracy: 97.2005%, Training Loss: 0.0859%\n",
      "Epoch [90/300], Step [49/225], Training Accuracy: 97.2577%, Training Loss: 0.0846%\n",
      "Epoch [90/300], Step [50/225], Training Accuracy: 97.2812%, Training Loss: 0.0845%\n",
      "Epoch [90/300], Step [51/225], Training Accuracy: 97.3039%, Training Loss: 0.0838%\n",
      "Epoch [90/300], Step [52/225], Training Accuracy: 97.3257%, Training Loss: 0.0832%\n",
      "Epoch [90/300], Step [53/225], Training Accuracy: 97.3172%, Training Loss: 0.0834%\n",
      "Epoch [90/300], Step [54/225], Training Accuracy: 97.2512%, Training Loss: 0.0852%\n",
      "Epoch [90/300], Step [55/225], Training Accuracy: 97.2443%, Training Loss: 0.0847%\n",
      "Epoch [90/300], Step [56/225], Training Accuracy: 97.2935%, Training Loss: 0.0840%\n",
      "Epoch [90/300], Step [57/225], Training Accuracy: 97.2588%, Training Loss: 0.0845%\n",
      "Epoch [90/300], Step [58/225], Training Accuracy: 97.2791%, Training Loss: 0.0844%\n",
      "Epoch [90/300], Step [59/225], Training Accuracy: 97.2193%, Training Loss: 0.0852%\n",
      "Epoch [90/300], Step [60/225], Training Accuracy: 97.2656%, Training Loss: 0.0843%\n",
      "Epoch [90/300], Step [61/225], Training Accuracy: 97.2592%, Training Loss: 0.0851%\n",
      "Epoch [90/300], Step [62/225], Training Accuracy: 97.2530%, Training Loss: 0.0847%\n",
      "Epoch [90/300], Step [63/225], Training Accuracy: 97.2222%, Training Loss: 0.0858%\n",
      "Epoch [90/300], Step [64/225], Training Accuracy: 97.2168%, Training Loss: 0.0859%\n",
      "Epoch [90/300], Step [65/225], Training Accuracy: 97.2356%, Training Loss: 0.0855%\n",
      "Epoch [90/300], Step [66/225], Training Accuracy: 97.2301%, Training Loss: 0.0856%\n",
      "Epoch [90/300], Step [67/225], Training Accuracy: 97.2481%, Training Loss: 0.0859%\n",
      "Epoch [90/300], Step [68/225], Training Accuracy: 97.2426%, Training Loss: 0.0859%\n",
      "Epoch [90/300], Step [69/225], Training Accuracy: 97.2600%, Training Loss: 0.0853%\n",
      "Epoch [90/300], Step [70/225], Training Accuracy: 97.2545%, Training Loss: 0.0856%\n",
      "Epoch [90/300], Step [71/225], Training Accuracy: 97.2271%, Training Loss: 0.0861%\n",
      "Epoch [90/300], Step [72/225], Training Accuracy: 97.1788%, Training Loss: 0.0863%\n",
      "Epoch [90/300], Step [73/225], Training Accuracy: 97.1961%, Training Loss: 0.0860%\n",
      "Epoch [90/300], Step [74/225], Training Accuracy: 97.1917%, Training Loss: 0.0859%\n",
      "Epoch [90/300], Step [75/225], Training Accuracy: 97.1875%, Training Loss: 0.0856%\n",
      "Epoch [90/300], Step [76/225], Training Accuracy: 97.1423%, Training Loss: 0.0864%\n",
      "Epoch [90/300], Step [77/225], Training Accuracy: 97.1794%, Training Loss: 0.0860%\n",
      "Epoch [90/300], Step [78/225], Training Accuracy: 97.1755%, Training Loss: 0.0855%\n",
      "Epoch [90/300], Step [79/225], Training Accuracy: 97.2112%, Training Loss: 0.0848%\n",
      "Epoch [90/300], Step [80/225], Training Accuracy: 97.2266%, Training Loss: 0.0848%\n",
      "Epoch [90/300], Step [81/225], Training Accuracy: 97.2415%, Training Loss: 0.0845%\n",
      "Epoch [90/300], Step [82/225], Training Accuracy: 97.2180%, Training Loss: 0.0848%\n",
      "Epoch [90/300], Step [83/225], Training Accuracy: 97.1762%, Training Loss: 0.0855%\n",
      "Epoch [90/300], Step [84/225], Training Accuracy: 97.1354%, Training Loss: 0.0862%\n",
      "Epoch [90/300], Step [85/225], Training Accuracy: 97.1507%, Training Loss: 0.0857%\n",
      "Epoch [90/300], Step [86/225], Training Accuracy: 97.1294%, Training Loss: 0.0855%\n",
      "Epoch [90/300], Step [87/225], Training Accuracy: 97.1444%, Training Loss: 0.0853%\n",
      "Epoch [90/300], Step [88/225], Training Accuracy: 97.1768%, Training Loss: 0.0849%\n",
      "Epoch [90/300], Step [89/225], Training Accuracy: 97.1559%, Training Loss: 0.0852%\n",
      "Epoch [90/300], Step [90/225], Training Accuracy: 97.1528%, Training Loss: 0.0851%\n",
      "Epoch [90/300], Step [91/225], Training Accuracy: 97.1841%, Training Loss: 0.0848%\n",
      "Epoch [90/300], Step [92/225], Training Accuracy: 97.2147%, Training Loss: 0.0844%\n",
      "Epoch [90/300], Step [93/225], Training Accuracy: 97.2446%, Training Loss: 0.0839%\n",
      "Epoch [90/300], Step [94/225], Training Accuracy: 97.2407%, Training Loss: 0.0841%\n",
      "Epoch [90/300], Step [95/225], Training Accuracy: 97.2204%, Training Loss: 0.0847%\n",
      "Epoch [90/300], Step [96/225], Training Accuracy: 97.2331%, Training Loss: 0.0845%\n",
      "Epoch [90/300], Step [97/225], Training Accuracy: 97.2294%, Training Loss: 0.0848%\n",
      "Epoch [90/300], Step [98/225], Training Accuracy: 97.2098%, Training Loss: 0.0857%\n",
      "Epoch [90/300], Step [99/225], Training Accuracy: 97.2222%, Training Loss: 0.0855%\n",
      "Epoch [90/300], Step [100/225], Training Accuracy: 97.2344%, Training Loss: 0.0853%\n",
      "Epoch [90/300], Step [101/225], Training Accuracy: 97.2463%, Training Loss: 0.0849%\n",
      "Epoch [90/300], Step [102/225], Training Accuracy: 97.2273%, Training Loss: 0.0848%\n",
      "Epoch [90/300], Step [103/225], Training Accuracy: 97.2391%, Training Loss: 0.0849%\n",
      "Epoch [90/300], Step [104/225], Training Accuracy: 97.2356%, Training Loss: 0.0848%\n",
      "Epoch [90/300], Step [105/225], Training Accuracy: 97.1875%, Training Loss: 0.0861%\n",
      "Epoch [90/300], Step [106/225], Training Accuracy: 97.1698%, Training Loss: 0.0865%\n",
      "Epoch [90/300], Step [107/225], Training Accuracy: 97.1671%, Training Loss: 0.0865%\n",
      "Epoch [90/300], Step [108/225], Training Accuracy: 97.1788%, Training Loss: 0.0860%\n",
      "Epoch [90/300], Step [109/225], Training Accuracy: 97.2047%, Training Loss: 0.0855%\n",
      "Epoch [90/300], Step [110/225], Training Accuracy: 97.2017%, Training Loss: 0.0857%\n",
      "Epoch [90/300], Step [111/225], Training Accuracy: 97.2269%, Training Loss: 0.0852%\n",
      "Epoch [90/300], Step [112/225], Training Accuracy: 97.2377%, Training Loss: 0.0850%\n",
      "Epoch [90/300], Step [113/225], Training Accuracy: 97.2207%, Training Loss: 0.0856%\n",
      "Epoch [90/300], Step [114/225], Training Accuracy: 97.2177%, Training Loss: 0.0857%\n",
      "Epoch [90/300], Step [115/225], Training Accuracy: 97.2147%, Training Loss: 0.0858%\n",
      "Epoch [90/300], Step [116/225], Training Accuracy: 97.2117%, Training Loss: 0.0856%\n",
      "Epoch [90/300], Step [117/225], Training Accuracy: 97.2222%, Training Loss: 0.0855%\n",
      "Epoch [90/300], Step [118/225], Training Accuracy: 97.2193%, Training Loss: 0.0858%\n",
      "Epoch [90/300], Step [119/225], Training Accuracy: 97.2295%, Training Loss: 0.0855%\n",
      "Epoch [90/300], Step [120/225], Training Accuracy: 97.2266%, Training Loss: 0.0854%\n",
      "Epoch [90/300], Step [121/225], Training Accuracy: 97.2237%, Training Loss: 0.0855%\n",
      "Epoch [90/300], Step [122/225], Training Accuracy: 97.1952%, Training Loss: 0.0857%\n",
      "Epoch [90/300], Step [123/225], Training Accuracy: 97.1672%, Training Loss: 0.0859%\n",
      "Epoch [90/300], Step [124/225], Training Accuracy: 97.1774%, Training Loss: 0.0855%\n",
      "Epoch [90/300], Step [125/225], Training Accuracy: 97.1375%, Training Loss: 0.0861%\n",
      "Epoch [90/300], Step [126/225], Training Accuracy: 97.1602%, Training Loss: 0.0858%\n",
      "Epoch [90/300], Step [127/225], Training Accuracy: 97.1580%, Training Loss: 0.0858%\n",
      "Epoch [90/300], Step [128/225], Training Accuracy: 97.1069%, Training Loss: 0.0866%\n",
      "Epoch [90/300], Step [129/225], Training Accuracy: 97.0930%, Training Loss: 0.0868%\n",
      "Epoch [90/300], Step [130/225], Training Accuracy: 97.0673%, Training Loss: 0.0871%\n",
      "Epoch [90/300], Step [131/225], Training Accuracy: 97.0539%, Training Loss: 0.0869%\n",
      "Epoch [90/300], Step [132/225], Training Accuracy: 97.0644%, Training Loss: 0.0867%\n",
      "Epoch [90/300], Step [133/225], Training Accuracy: 97.0865%, Training Loss: 0.0864%\n",
      "Epoch [90/300], Step [134/225], Training Accuracy: 97.0965%, Training Loss: 0.0862%\n",
      "Epoch [90/300], Step [135/225], Training Accuracy: 97.1065%, Training Loss: 0.0858%\n",
      "Epoch [90/300], Step [136/225], Training Accuracy: 97.0818%, Training Loss: 0.0864%\n",
      "Epoch [90/300], Step [137/225], Training Accuracy: 97.0917%, Training Loss: 0.0864%\n",
      "Epoch [90/300], Step [138/225], Training Accuracy: 97.0788%, Training Loss: 0.0867%\n",
      "Epoch [90/300], Step [139/225], Training Accuracy: 97.0998%, Training Loss: 0.0864%\n",
      "Epoch [90/300], Step [140/225], Training Accuracy: 97.1094%, Training Loss: 0.0863%\n",
      "Epoch [90/300], Step [141/225], Training Accuracy: 97.0966%, Training Loss: 0.0864%\n",
      "Epoch [90/300], Step [142/225], Training Accuracy: 97.1171%, Training Loss: 0.0860%\n",
      "Epoch [90/300], Step [143/225], Training Accuracy: 97.1154%, Training Loss: 0.0862%\n",
      "Epoch [90/300], Step [144/225], Training Accuracy: 97.1137%, Training Loss: 0.0862%\n",
      "Epoch [90/300], Step [145/225], Training Accuracy: 97.1336%, Training Loss: 0.0859%\n",
      "Epoch [90/300], Step [146/225], Training Accuracy: 97.1104%, Training Loss: 0.0865%\n",
      "Epoch [90/300], Step [147/225], Training Accuracy: 97.1195%, Training Loss: 0.0862%\n",
      "Epoch [90/300], Step [148/225], Training Accuracy: 97.1073%, Training Loss: 0.0865%\n",
      "Epoch [90/300], Step [149/225], Training Accuracy: 97.0847%, Training Loss: 0.0872%\n",
      "Epoch [90/300], Step [150/225], Training Accuracy: 97.0729%, Training Loss: 0.0874%\n",
      "Epoch [90/300], Step [151/225], Training Accuracy: 97.0820%, Training Loss: 0.0871%\n",
      "Epoch [90/300], Step [152/225], Training Accuracy: 97.0806%, Training Loss: 0.0875%\n",
      "Epoch [90/300], Step [153/225], Training Accuracy: 97.0690%, Training Loss: 0.0878%\n",
      "Epoch [90/300], Step [154/225], Training Accuracy: 97.0576%, Training Loss: 0.0882%\n",
      "Epoch [90/300], Step [155/225], Training Accuracy: 97.0464%, Training Loss: 0.0883%\n",
      "Epoch [90/300], Step [156/225], Training Accuracy: 97.0453%, Training Loss: 0.0886%\n",
      "Epoch [90/300], Step [157/225], Training Accuracy: 97.0442%, Training Loss: 0.0886%\n",
      "Epoch [90/300], Step [158/225], Training Accuracy: 97.0629%, Training Loss: 0.0882%\n",
      "Epoch [90/300], Step [159/225], Training Accuracy: 97.0519%, Training Loss: 0.0885%\n",
      "Epoch [90/300], Step [160/225], Training Accuracy: 97.0605%, Training Loss: 0.0884%\n",
      "Epoch [90/300], Step [161/225], Training Accuracy: 97.0594%, Training Loss: 0.0883%\n",
      "Epoch [90/300], Step [162/225], Training Accuracy: 97.0583%, Training Loss: 0.0887%\n",
      "Epoch [90/300], Step [163/225], Training Accuracy: 97.0667%, Training Loss: 0.0885%\n",
      "Epoch [90/300], Step [164/225], Training Accuracy: 97.0751%, Training Loss: 0.0883%\n",
      "Epoch [90/300], Step [165/225], Training Accuracy: 97.0644%, Training Loss: 0.0886%\n",
      "Epoch [90/300], Step [166/225], Training Accuracy: 97.0444%, Training Loss: 0.0889%\n",
      "Epoch [90/300], Step [167/225], Training Accuracy: 97.0341%, Training Loss: 0.0893%\n",
      "Epoch [90/300], Step [168/225], Training Accuracy: 97.0517%, Training Loss: 0.0889%\n",
      "Epoch [90/300], Step [169/225], Training Accuracy: 97.0322%, Training Loss: 0.0891%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/300], Step [170/225], Training Accuracy: 97.0129%, Training Loss: 0.0898%\n",
      "Epoch [90/300], Step [171/225], Training Accuracy: 97.0029%, Training Loss: 0.0897%\n",
      "Epoch [90/300], Step [172/225], Training Accuracy: 97.0113%, Training Loss: 0.0895%\n",
      "Epoch [90/300], Step [173/225], Training Accuracy: 97.0105%, Training Loss: 0.0894%\n",
      "Epoch [90/300], Step [174/225], Training Accuracy: 97.0097%, Training Loss: 0.0894%\n",
      "Epoch [90/300], Step [175/225], Training Accuracy: 96.9821%, Training Loss: 0.0896%\n",
      "Epoch [90/300], Step [176/225], Training Accuracy: 96.9815%, Training Loss: 0.0897%\n",
      "Epoch [90/300], Step [177/225], Training Accuracy: 96.9721%, Training Loss: 0.0896%\n",
      "Epoch [90/300], Step [178/225], Training Accuracy: 96.9891%, Training Loss: 0.0892%\n",
      "Epoch [90/300], Step [179/225], Training Accuracy: 97.0059%, Training Loss: 0.0890%\n",
      "Epoch [90/300], Step [180/225], Training Accuracy: 96.9965%, Training Loss: 0.0891%\n",
      "Epoch [90/300], Step [181/225], Training Accuracy: 96.9959%, Training Loss: 0.0891%\n",
      "Epoch [90/300], Step [182/225], Training Accuracy: 96.9952%, Training Loss: 0.0894%\n",
      "Epoch [90/300], Step [183/225], Training Accuracy: 97.0116%, Training Loss: 0.0892%\n",
      "Epoch [90/300], Step [184/225], Training Accuracy: 97.0109%, Training Loss: 0.0891%\n",
      "Epoch [90/300], Step [185/225], Training Accuracy: 97.0186%, Training Loss: 0.0888%\n",
      "Epoch [90/300], Step [186/225], Training Accuracy: 97.0346%, Training Loss: 0.0885%\n",
      "Epoch [90/300], Step [187/225], Training Accuracy: 97.0338%, Training Loss: 0.0884%\n",
      "Epoch [90/300], Step [188/225], Training Accuracy: 97.0412%, Training Loss: 0.0882%\n",
      "Epoch [90/300], Step [189/225], Training Accuracy: 97.0403%, Training Loss: 0.0882%\n",
      "Epoch [90/300], Step [190/225], Training Accuracy: 97.0230%, Training Loss: 0.0887%\n",
      "Epoch [90/300], Step [191/225], Training Accuracy: 97.0386%, Training Loss: 0.0883%\n",
      "Epoch [90/300], Step [192/225], Training Accuracy: 97.0215%, Training Loss: 0.0884%\n",
      "Epoch [90/300], Step [193/225], Training Accuracy: 97.0207%, Training Loss: 0.0884%\n",
      "Epoch [90/300], Step [194/225], Training Accuracy: 97.0200%, Training Loss: 0.0884%\n",
      "Epoch [90/300], Step [195/225], Training Accuracy: 97.0112%, Training Loss: 0.0884%\n",
      "Epoch [90/300], Step [196/225], Training Accuracy: 97.0265%, Training Loss: 0.0880%\n",
      "Epoch [90/300], Step [197/225], Training Accuracy: 97.0416%, Training Loss: 0.0878%\n",
      "Epoch [90/300], Step [198/225], Training Accuracy: 97.0486%, Training Loss: 0.0876%\n",
      "Epoch [90/300], Step [199/225], Training Accuracy: 97.0556%, Training Loss: 0.0875%\n",
      "Epoch [90/300], Step [200/225], Training Accuracy: 97.0703%, Training Loss: 0.0873%\n",
      "Epoch [90/300], Step [201/225], Training Accuracy: 97.0616%, Training Loss: 0.0876%\n",
      "Epoch [90/300], Step [202/225], Training Accuracy: 97.0761%, Training Loss: 0.0873%\n",
      "Epoch [90/300], Step [203/225], Training Accuracy: 97.0905%, Training Loss: 0.0871%\n",
      "Epoch [90/300], Step [204/225], Training Accuracy: 97.0895%, Training Loss: 0.0871%\n",
      "Epoch [90/300], Step [205/225], Training Accuracy: 97.0960%, Training Loss: 0.0871%\n",
      "Epoch [90/300], Step [206/225], Training Accuracy: 97.0874%, Training Loss: 0.0872%\n",
      "Epoch [90/300], Step [207/225], Training Accuracy: 97.0939%, Training Loss: 0.0870%\n",
      "Epoch [90/300], Step [208/225], Training Accuracy: 97.1004%, Training Loss: 0.0868%\n",
      "Epoch [90/300], Step [209/225], Training Accuracy: 97.1142%, Training Loss: 0.0865%\n",
      "Epoch [90/300], Step [210/225], Training Accuracy: 97.1057%, Training Loss: 0.0866%\n",
      "Epoch [90/300], Step [211/225], Training Accuracy: 97.1046%, Training Loss: 0.0867%\n",
      "Epoch [90/300], Step [212/225], Training Accuracy: 97.1035%, Training Loss: 0.0868%\n",
      "Epoch [90/300], Step [213/225], Training Accuracy: 97.1024%, Training Loss: 0.0870%\n",
      "Epoch [90/300], Step [214/225], Training Accuracy: 97.1086%, Training Loss: 0.0870%\n",
      "Epoch [90/300], Step [215/225], Training Accuracy: 97.0930%, Training Loss: 0.0873%\n",
      "Epoch [90/300], Step [216/225], Training Accuracy: 97.0920%, Training Loss: 0.0873%\n",
      "Epoch [90/300], Step [217/225], Training Accuracy: 97.1054%, Training Loss: 0.0871%\n",
      "Epoch [90/300], Step [218/225], Training Accuracy: 97.1115%, Training Loss: 0.0869%\n",
      "Epoch [90/300], Step [219/225], Training Accuracy: 97.0890%, Training Loss: 0.0872%\n",
      "Epoch [90/300], Step [220/225], Training Accuracy: 97.0952%, Training Loss: 0.0872%\n",
      "Epoch [90/300], Step [221/225], Training Accuracy: 97.0871%, Training Loss: 0.0875%\n",
      "Epoch [90/300], Step [222/225], Training Accuracy: 97.0721%, Training Loss: 0.0877%\n",
      "Epoch [90/300], Step [223/225], Training Accuracy: 97.0712%, Training Loss: 0.0876%\n",
      "Epoch [90/300], Step [224/225], Training Accuracy: 97.0773%, Training Loss: 0.0875%\n",
      "Epoch [90/300], Step [225/225], Training Accuracy: 97.0748%, Training Loss: 0.0876%\n",
      "Epoch [91/300], Step [1/225], Training Accuracy: 98.4375%, Training Loss: 0.0663%\n",
      "Epoch [91/300], Step [2/225], Training Accuracy: 96.8750%, Training Loss: 0.1090%\n",
      "Epoch [91/300], Step [3/225], Training Accuracy: 97.3958%, Training Loss: 0.0877%\n",
      "Epoch [91/300], Step [4/225], Training Accuracy: 96.8750%, Training Loss: 0.0983%\n",
      "Epoch [91/300], Step [5/225], Training Accuracy: 97.1875%, Training Loss: 0.0885%\n",
      "Epoch [91/300], Step [6/225], Training Accuracy: 97.3958%, Training Loss: 0.0837%\n",
      "Epoch [91/300], Step [7/225], Training Accuracy: 96.6518%, Training Loss: 0.0917%\n",
      "Epoch [91/300], Step [8/225], Training Accuracy: 96.6797%, Training Loss: 0.0970%\n",
      "Epoch [91/300], Step [9/225], Training Accuracy: 96.8750%, Training Loss: 0.0939%\n",
      "Epoch [91/300], Step [10/225], Training Accuracy: 96.7188%, Training Loss: 0.0942%\n",
      "Epoch [91/300], Step [11/225], Training Accuracy: 96.4489%, Training Loss: 0.0965%\n",
      "Epoch [91/300], Step [12/225], Training Accuracy: 96.7448%, Training Loss: 0.0922%\n",
      "Epoch [91/300], Step [13/225], Training Accuracy: 96.2740%, Training Loss: 0.1053%\n",
      "Epoch [91/300], Step [14/225], Training Accuracy: 95.8705%, Training Loss: 0.1060%\n",
      "Epoch [91/300], Step [15/225], Training Accuracy: 96.0417%, Training Loss: 0.1034%\n",
      "Epoch [91/300], Step [16/225], Training Accuracy: 96.1914%, Training Loss: 0.1010%\n",
      "Epoch [91/300], Step [17/225], Training Accuracy: 96.2316%, Training Loss: 0.1011%\n",
      "Epoch [91/300], Step [18/225], Training Accuracy: 96.0938%, Training Loss: 0.1035%\n",
      "Epoch [91/300], Step [19/225], Training Accuracy: 96.0526%, Training Loss: 0.1034%\n",
      "Epoch [91/300], Step [20/225], Training Accuracy: 96.2500%, Training Loss: 0.0992%\n",
      "Epoch [91/300], Step [21/225], Training Accuracy: 96.2798%, Training Loss: 0.0977%\n",
      "Epoch [91/300], Step [22/225], Training Accuracy: 96.3068%, Training Loss: 0.0991%\n",
      "Epoch [91/300], Step [23/225], Training Accuracy: 96.2636%, Training Loss: 0.1005%\n",
      "Epoch [91/300], Step [24/225], Training Accuracy: 96.1589%, Training Loss: 0.1012%\n",
      "Epoch [91/300], Step [25/225], Training Accuracy: 96.1875%, Training Loss: 0.0999%\n",
      "Epoch [91/300], Step [26/225], Training Accuracy: 96.0938%, Training Loss: 0.1015%\n",
      "Epoch [91/300], Step [27/225], Training Accuracy: 96.1227%, Training Loss: 0.1008%\n",
      "Epoch [91/300], Step [28/225], Training Accuracy: 96.0379%, Training Loss: 0.1020%\n",
      "Epoch [91/300], Step [29/225], Training Accuracy: 96.1207%, Training Loss: 0.1008%\n",
      "Epoch [91/300], Step [30/225], Training Accuracy: 96.2500%, Training Loss: 0.0988%\n",
      "Epoch [91/300], Step [31/225], Training Accuracy: 96.1694%, Training Loss: 0.1013%\n",
      "Epoch [91/300], Step [32/225], Training Accuracy: 96.2402%, Training Loss: 0.0996%\n",
      "Epoch [91/300], Step [33/225], Training Accuracy: 96.2121%, Training Loss: 0.0993%\n",
      "Epoch [91/300], Step [34/225], Training Accuracy: 96.1857%, Training Loss: 0.0998%\n",
      "Epoch [91/300], Step [35/225], Training Accuracy: 96.2946%, Training Loss: 0.0981%\n",
      "Epoch [91/300], Step [36/225], Training Accuracy: 96.2674%, Training Loss: 0.0980%\n",
      "Epoch [91/300], Step [37/225], Training Accuracy: 96.3260%, Training Loss: 0.0971%\n",
      "Epoch [91/300], Step [38/225], Training Accuracy: 96.3405%, Training Loss: 0.0967%\n",
      "Epoch [91/300], Step [39/225], Training Accuracy: 96.3141%, Training Loss: 0.0968%\n",
      "Epoch [91/300], Step [40/225], Training Accuracy: 96.3672%, Training Loss: 0.0958%\n",
      "Epoch [91/300], Step [41/225], Training Accuracy: 96.3796%, Training Loss: 0.0955%\n",
      "Epoch [91/300], Step [42/225], Training Accuracy: 96.4286%, Training Loss: 0.0950%\n",
      "Epoch [91/300], Step [43/225], Training Accuracy: 96.4753%, Training Loss: 0.0940%\n",
      "Epoch [91/300], Step [44/225], Training Accuracy: 96.4844%, Training Loss: 0.0948%\n",
      "Epoch [91/300], Step [45/225], Training Accuracy: 96.5278%, Training Loss: 0.0941%\n",
      "Epoch [91/300], Step [46/225], Training Accuracy: 96.5353%, Training Loss: 0.0930%\n",
      "Epoch [91/300], Step [47/225], Training Accuracy: 96.6090%, Training Loss: 0.0920%\n",
      "Epoch [91/300], Step [48/225], Training Accuracy: 96.6797%, Training Loss: 0.0909%\n",
      "Epoch [91/300], Step [49/225], Training Accuracy: 96.7156%, Training Loss: 0.0904%\n",
      "Epoch [91/300], Step [50/225], Training Accuracy: 96.7500%, Training Loss: 0.0897%\n",
      "Epoch [91/300], Step [51/225], Training Accuracy: 96.7525%, Training Loss: 0.0890%\n",
      "Epoch [91/300], Step [52/225], Training Accuracy: 96.8149%, Training Loss: 0.0878%\n",
      "Epoch [91/300], Step [53/225], Training Accuracy: 96.7571%, Training Loss: 0.0884%\n",
      "Epoch [91/300], Step [54/225], Training Accuracy: 96.7882%, Training Loss: 0.0882%\n",
      "Epoch [91/300], Step [55/225], Training Accuracy: 96.8182%, Training Loss: 0.0878%\n",
      "Epoch [91/300], Step [56/225], Training Accuracy: 96.7076%, Training Loss: 0.0898%\n",
      "Epoch [91/300], Step [57/225], Training Accuracy: 96.6557%, Training Loss: 0.0900%\n",
      "Epoch [91/300], Step [58/225], Training Accuracy: 96.5787%, Training Loss: 0.0914%\n",
      "Epoch [91/300], Step [59/225], Training Accuracy: 96.5572%, Training Loss: 0.0917%\n",
      "Epoch [91/300], Step [60/225], Training Accuracy: 96.5885%, Training Loss: 0.0917%\n",
      "Epoch [91/300], Step [61/225], Training Accuracy: 96.5676%, Training Loss: 0.0916%\n",
      "Epoch [91/300], Step [62/225], Training Accuracy: 96.5474%, Training Loss: 0.0912%\n",
      "Epoch [91/300], Step [63/225], Training Accuracy: 96.5774%, Training Loss: 0.0904%\n",
      "Epoch [91/300], Step [64/225], Training Accuracy: 96.6064%, Training Loss: 0.0897%\n",
      "Epoch [91/300], Step [65/225], Training Accuracy: 96.6106%, Training Loss: 0.0895%\n",
      "Epoch [91/300], Step [66/225], Training Accuracy: 96.4962%, Training Loss: 0.0904%\n",
      "Epoch [91/300], Step [67/225], Training Accuracy: 96.5252%, Training Loss: 0.0901%\n",
      "Epoch [91/300], Step [68/225], Training Accuracy: 96.4614%, Training Loss: 0.0909%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/300], Step [69/225], Training Accuracy: 96.4674%, Training Loss: 0.0906%\n",
      "Epoch [91/300], Step [70/225], Training Accuracy: 96.4062%, Training Loss: 0.0918%\n",
      "Epoch [91/300], Step [71/225], Training Accuracy: 96.4349%, Training Loss: 0.0913%\n",
      "Epoch [91/300], Step [72/225], Training Accuracy: 96.4410%, Training Loss: 0.0925%\n",
      "Epoch [91/300], Step [73/225], Training Accuracy: 96.4469%, Training Loss: 0.0925%\n",
      "Epoch [91/300], Step [74/225], Training Accuracy: 96.4527%, Training Loss: 0.0925%\n",
      "Epoch [91/300], Step [75/225], Training Accuracy: 96.4583%, Training Loss: 0.0924%\n",
      "Epoch [91/300], Step [76/225], Training Accuracy: 96.5049%, Training Loss: 0.0915%\n",
      "Epoch [91/300], Step [77/225], Training Accuracy: 96.5300%, Training Loss: 0.0911%\n",
      "Epoch [91/300], Step [78/225], Training Accuracy: 96.5745%, Training Loss: 0.0905%\n",
      "Epoch [91/300], Step [79/225], Training Accuracy: 96.4992%, Training Loss: 0.0917%\n",
      "Epoch [91/300], Step [80/225], Training Accuracy: 96.5039%, Training Loss: 0.0921%\n",
      "Epoch [91/300], Step [81/225], Training Accuracy: 96.5085%, Training Loss: 0.0923%\n",
      "Epoch [91/300], Step [82/225], Training Accuracy: 96.5130%, Training Loss: 0.0926%\n",
      "Epoch [91/300], Step [83/225], Training Accuracy: 96.4985%, Training Loss: 0.0931%\n",
      "Epoch [91/300], Step [84/225], Training Accuracy: 96.5216%, Training Loss: 0.0932%\n",
      "Epoch [91/300], Step [85/225], Training Accuracy: 96.5074%, Training Loss: 0.0945%\n",
      "Epoch [91/300], Step [86/225], Training Accuracy: 96.4753%, Training Loss: 0.0949%\n",
      "Epoch [91/300], Step [87/225], Training Accuracy: 96.4080%, Training Loss: 0.0964%\n",
      "Epoch [91/300], Step [88/225], Training Accuracy: 96.3956%, Training Loss: 0.0962%\n",
      "Epoch [91/300], Step [89/225], Training Accuracy: 96.4185%, Training Loss: 0.0959%\n",
      "Epoch [91/300], Step [90/225], Training Accuracy: 96.4236%, Training Loss: 0.0955%\n",
      "Epoch [91/300], Step [91/225], Training Accuracy: 96.3942%, Training Loss: 0.0957%\n",
      "Epoch [91/300], Step [92/225], Training Accuracy: 96.4164%, Training Loss: 0.0954%\n",
      "Epoch [91/300], Step [93/225], Training Accuracy: 96.4214%, Training Loss: 0.0955%\n",
      "Epoch [91/300], Step [94/225], Training Accuracy: 96.4594%, Training Loss: 0.0948%\n",
      "Epoch [91/300], Step [95/225], Training Accuracy: 96.4474%, Training Loss: 0.0957%\n",
      "Epoch [91/300], Step [96/225], Training Accuracy: 96.4518%, Training Loss: 0.0958%\n",
      "Epoch [91/300], Step [97/225], Training Accuracy: 96.4723%, Training Loss: 0.0953%\n",
      "Epoch [91/300], Step [98/225], Training Accuracy: 96.4286%, Training Loss: 0.0958%\n",
      "Epoch [91/300], Step [99/225], Training Accuracy: 96.4015%, Training Loss: 0.0968%\n",
      "Epoch [91/300], Step [100/225], Training Accuracy: 96.3906%, Training Loss: 0.0969%\n",
      "Epoch [91/300], Step [101/225], Training Accuracy: 96.3954%, Training Loss: 0.0969%\n",
      "Epoch [91/300], Step [102/225], Training Accuracy: 96.4154%, Training Loss: 0.0964%\n",
      "Epoch [91/300], Step [103/225], Training Accuracy: 96.4351%, Training Loss: 0.0961%\n",
      "Epoch [91/300], Step [104/225], Training Accuracy: 96.3942%, Training Loss: 0.0975%\n",
      "Epoch [91/300], Step [105/225], Training Accuracy: 96.3988%, Training Loss: 0.0979%\n",
      "Epoch [91/300], Step [106/225], Training Accuracy: 96.4180%, Training Loss: 0.0977%\n",
      "Epoch [91/300], Step [107/225], Training Accuracy: 96.4223%, Training Loss: 0.0977%\n",
      "Epoch [91/300], Step [108/225], Training Accuracy: 96.3831%, Training Loss: 0.0987%\n",
      "Epoch [91/300], Step [109/225], Training Accuracy: 96.3876%, Training Loss: 0.0986%\n",
      "Epoch [91/300], Step [110/225], Training Accuracy: 96.4062%, Training Loss: 0.0984%\n",
      "Epoch [91/300], Step [111/225], Training Accuracy: 96.4245%, Training Loss: 0.0980%\n",
      "Epoch [91/300], Step [112/225], Training Accuracy: 96.4286%, Training Loss: 0.0980%\n",
      "Epoch [91/300], Step [113/225], Training Accuracy: 96.4325%, Training Loss: 0.0978%\n",
      "Epoch [91/300], Step [114/225], Training Accuracy: 96.4090%, Training Loss: 0.0983%\n",
      "Epoch [91/300], Step [115/225], Training Accuracy: 96.4130%, Training Loss: 0.0979%\n",
      "Epoch [91/300], Step [116/225], Training Accuracy: 96.4440%, Training Loss: 0.0975%\n",
      "Epoch [91/300], Step [117/225], Training Accuracy: 96.4209%, Training Loss: 0.0985%\n",
      "Epoch [91/300], Step [118/225], Training Accuracy: 96.4115%, Training Loss: 0.0992%\n",
      "Epoch [91/300], Step [119/225], Training Accuracy: 96.4154%, Training Loss: 0.0991%\n",
      "Epoch [91/300], Step [120/225], Training Accuracy: 96.3802%, Training Loss: 0.0998%\n",
      "Epoch [91/300], Step [121/225], Training Accuracy: 96.3972%, Training Loss: 0.0994%\n",
      "Epoch [91/300], Step [122/225], Training Accuracy: 96.3755%, Training Loss: 0.0996%\n",
      "Epoch [91/300], Step [123/225], Training Accuracy: 96.3923%, Training Loss: 0.0999%\n",
      "Epoch [91/300], Step [124/225], Training Accuracy: 96.4088%, Training Loss: 0.0996%\n",
      "Epoch [91/300], Step [125/225], Training Accuracy: 96.4250%, Training Loss: 0.0993%\n",
      "Epoch [91/300], Step [126/225], Training Accuracy: 96.4534%, Training Loss: 0.0989%\n",
      "Epoch [91/300], Step [127/225], Training Accuracy: 96.4444%, Training Loss: 0.0989%\n",
      "Epoch [91/300], Step [128/225], Training Accuracy: 96.4600%, Training Loss: 0.0986%\n",
      "Epoch [91/300], Step [129/225], Training Accuracy: 96.4268%, Training Loss: 0.0994%\n",
      "Epoch [91/300], Step [130/225], Training Accuracy: 96.4183%, Training Loss: 0.0996%\n",
      "Epoch [91/300], Step [131/225], Training Accuracy: 96.4218%, Training Loss: 0.0994%\n",
      "Epoch [91/300], Step [132/225], Training Accuracy: 96.4252%, Training Loss: 0.0996%\n",
      "Epoch [91/300], Step [133/225], Training Accuracy: 96.4168%, Training Loss: 0.1002%\n",
      "Epoch [91/300], Step [134/225], Training Accuracy: 96.4086%, Training Loss: 0.1002%\n",
      "Epoch [91/300], Step [135/225], Training Accuracy: 96.4120%, Training Loss: 0.1001%\n",
      "Epoch [91/300], Step [136/225], Training Accuracy: 96.4154%, Training Loss: 0.1004%\n",
      "Epoch [91/300], Step [137/225], Training Accuracy: 96.4188%, Training Loss: 0.1002%\n",
      "Epoch [91/300], Step [138/225], Training Accuracy: 96.4221%, Training Loss: 0.1001%\n",
      "Epoch [91/300], Step [139/225], Training Accuracy: 96.4254%, Training Loss: 0.0998%\n",
      "Epoch [91/300], Step [140/225], Training Accuracy: 96.4397%, Training Loss: 0.0994%\n",
      "Epoch [91/300], Step [141/225], Training Accuracy: 96.4207%, Training Loss: 0.0997%\n",
      "Epoch [91/300], Step [142/225], Training Accuracy: 96.4129%, Training Loss: 0.0998%\n",
      "Epoch [91/300], Step [143/225], Training Accuracy: 96.3942%, Training Loss: 0.1000%\n",
      "Epoch [91/300], Step [144/225], Training Accuracy: 96.3976%, Training Loss: 0.1001%\n",
      "Epoch [91/300], Step [145/225], Training Accuracy: 96.4116%, Training Loss: 0.0999%\n",
      "Epoch [91/300], Step [146/225], Training Accuracy: 96.4362%, Training Loss: 0.0996%\n",
      "Epoch [91/300], Step [147/225], Training Accuracy: 96.4498%, Training Loss: 0.0994%\n",
      "Epoch [91/300], Step [148/225], Training Accuracy: 96.4527%, Training Loss: 0.0991%\n",
      "Epoch [91/300], Step [149/225], Training Accuracy: 96.4555%, Training Loss: 0.0992%\n",
      "Epoch [91/300], Step [150/225], Training Accuracy: 96.4479%, Training Loss: 0.0994%\n",
      "Epoch [91/300], Step [151/225], Training Accuracy: 96.4404%, Training Loss: 0.0994%\n",
      "Epoch [91/300], Step [152/225], Training Accuracy: 96.4535%, Training Loss: 0.0992%\n",
      "Epoch [91/300], Step [153/225], Training Accuracy: 96.4767%, Training Loss: 0.0988%\n",
      "Epoch [91/300], Step [154/225], Training Accuracy: 96.4286%, Training Loss: 0.0996%\n",
      "Epoch [91/300], Step [155/225], Training Accuracy: 96.4214%, Training Loss: 0.0997%\n",
      "Epoch [91/300], Step [156/225], Training Accuracy: 96.4042%, Training Loss: 0.1000%\n",
      "Epoch [91/300], Step [157/225], Training Accuracy: 96.4072%, Training Loss: 0.1000%\n",
      "Epoch [91/300], Step [158/225], Training Accuracy: 96.4102%, Training Loss: 0.0998%\n",
      "Epoch [91/300], Step [159/225], Training Accuracy: 96.4033%, Training Loss: 0.1003%\n",
      "Epoch [91/300], Step [160/225], Training Accuracy: 96.4160%, Training Loss: 0.1001%\n",
      "Epoch [91/300], Step [161/225], Training Accuracy: 96.4383%, Training Loss: 0.0996%\n",
      "Epoch [91/300], Step [162/225], Training Accuracy: 96.4410%, Training Loss: 0.0995%\n",
      "Epoch [91/300], Step [163/225], Training Accuracy: 96.4149%, Training Loss: 0.1001%\n",
      "Epoch [91/300], Step [164/225], Training Accuracy: 96.3891%, Training Loss: 0.1003%\n",
      "Epoch [91/300], Step [165/225], Training Accuracy: 96.4015%, Training Loss: 0.1002%\n",
      "Epoch [91/300], Step [166/225], Training Accuracy: 96.4044%, Training Loss: 0.1002%\n",
      "Epoch [91/300], Step [167/225], Training Accuracy: 96.3978%, Training Loss: 0.1003%\n",
      "Epoch [91/300], Step [168/225], Training Accuracy: 96.4007%, Training Loss: 0.1003%\n",
      "Epoch [91/300], Step [169/225], Training Accuracy: 96.3942%, Training Loss: 0.1006%\n",
      "Epoch [91/300], Step [170/225], Training Accuracy: 96.3879%, Training Loss: 0.1006%\n",
      "Epoch [91/300], Step [171/225], Training Accuracy: 96.3724%, Training Loss: 0.1008%\n",
      "Epoch [91/300], Step [172/225], Training Accuracy: 96.3572%, Training Loss: 0.1011%\n",
      "Epoch [91/300], Step [173/225], Training Accuracy: 96.3692%, Training Loss: 0.1008%\n",
      "Epoch [91/300], Step [174/225], Training Accuracy: 96.3721%, Training Loss: 0.1007%\n",
      "Epoch [91/300], Step [175/225], Training Accuracy: 96.3839%, Training Loss: 0.1005%\n",
      "Epoch [91/300], Step [176/225], Training Accuracy: 96.4045%, Training Loss: 0.1002%\n",
      "Epoch [91/300], Step [177/225], Training Accuracy: 96.4160%, Training Loss: 0.0999%\n",
      "Epoch [91/300], Step [178/225], Training Accuracy: 96.4185%, Training Loss: 0.0998%\n",
      "Epoch [91/300], Step [179/225], Training Accuracy: 96.4124%, Training Loss: 0.1000%\n",
      "Epoch [91/300], Step [180/225], Training Accuracy: 96.4149%, Training Loss: 0.1002%\n",
      "Epoch [91/300], Step [181/225], Training Accuracy: 96.4002%, Training Loss: 0.1003%\n",
      "Epoch [91/300], Step [182/225], Training Accuracy: 96.3856%, Training Loss: 0.1005%\n",
      "Epoch [91/300], Step [183/225], Training Accuracy: 96.4054%, Training Loss: 0.1001%\n",
      "Epoch [91/300], Step [184/225], Training Accuracy: 96.3910%, Training Loss: 0.1004%\n",
      "Epoch [91/300], Step [185/225], Training Accuracy: 96.3936%, Training Loss: 0.1003%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/300], Step [186/225], Training Accuracy: 96.4046%, Training Loss: 0.1000%\n",
      "Epoch [91/300], Step [187/225], Training Accuracy: 96.3904%, Training Loss: 0.1002%\n",
      "Epoch [91/300], Step [188/225], Training Accuracy: 96.3846%, Training Loss: 0.1001%\n",
      "Epoch [91/300], Step [189/225], Training Accuracy: 96.3872%, Training Loss: 0.0999%\n",
      "Epoch [91/300], Step [190/225], Training Accuracy: 96.3898%, Training Loss: 0.0997%\n",
      "Epoch [91/300], Step [191/225], Training Accuracy: 96.3923%, Training Loss: 0.0995%\n",
      "Epoch [91/300], Step [192/225], Training Accuracy: 96.3786%, Training Loss: 0.0997%\n",
      "Epoch [91/300], Step [193/225], Training Accuracy: 96.3650%, Training Loss: 0.0997%\n",
      "Epoch [91/300], Step [194/225], Training Accuracy: 96.3434%, Training Loss: 0.1002%\n",
      "Epoch [91/300], Step [195/225], Training Accuracy: 96.3622%, Training Loss: 0.1000%\n",
      "Epoch [91/300], Step [196/225], Training Accuracy: 96.3409%, Training Loss: 0.1001%\n",
      "Epoch [91/300], Step [197/225], Training Accuracy: 96.3277%, Training Loss: 0.1002%\n",
      "Epoch [91/300], Step [198/225], Training Accuracy: 96.3305%, Training Loss: 0.1004%\n",
      "Epoch [91/300], Step [199/225], Training Accuracy: 96.3411%, Training Loss: 0.1003%\n",
      "Epoch [91/300], Step [200/225], Training Accuracy: 96.3281%, Training Loss: 0.1005%\n",
      "Epoch [91/300], Step [201/225], Training Accuracy: 96.3308%, Training Loss: 0.1005%\n",
      "Epoch [91/300], Step [202/225], Training Accuracy: 96.3413%, Training Loss: 0.1003%\n",
      "Epoch [91/300], Step [203/225], Training Accuracy: 96.3516%, Training Loss: 0.1002%\n",
      "Epoch [91/300], Step [204/225], Training Accuracy: 96.3542%, Training Loss: 0.1002%\n",
      "Epoch [91/300], Step [205/225], Training Accuracy: 96.3491%, Training Loss: 0.1003%\n",
      "Epoch [91/300], Step [206/225], Training Accuracy: 96.3592%, Training Loss: 0.1001%\n",
      "Epoch [91/300], Step [207/225], Training Accuracy: 96.3693%, Training Loss: 0.1001%\n",
      "Epoch [91/300], Step [208/225], Training Accuracy: 96.3792%, Training Loss: 0.0998%\n",
      "Epoch [91/300], Step [209/225], Training Accuracy: 96.3891%, Training Loss: 0.0996%\n",
      "Epoch [91/300], Step [210/225], Training Accuracy: 96.3914%, Training Loss: 0.0995%\n",
      "Epoch [91/300], Step [211/225], Training Accuracy: 96.3937%, Training Loss: 0.0993%\n",
      "Epoch [91/300], Step [212/225], Training Accuracy: 96.4107%, Training Loss: 0.0990%\n",
      "Epoch [91/300], Step [213/225], Training Accuracy: 96.3908%, Training Loss: 0.0991%\n",
      "Epoch [91/300], Step [214/225], Training Accuracy: 96.4004%, Training Loss: 0.0989%\n",
      "Epoch [91/300], Step [215/225], Training Accuracy: 96.3953%, Training Loss: 0.0999%\n",
      "Epoch [91/300], Step [216/225], Training Accuracy: 96.3976%, Training Loss: 0.0998%\n",
      "Epoch [91/300], Step [217/225], Training Accuracy: 96.3926%, Training Loss: 0.1000%\n",
      "Epoch [91/300], Step [218/225], Training Accuracy: 96.3948%, Training Loss: 0.0999%\n",
      "Epoch [91/300], Step [219/225], Training Accuracy: 96.4041%, Training Loss: 0.0997%\n",
      "Epoch [91/300], Step [220/225], Training Accuracy: 96.4205%, Training Loss: 0.0994%\n",
      "Epoch [91/300], Step [221/225], Training Accuracy: 96.4296%, Training Loss: 0.0995%\n",
      "Epoch [91/300], Step [222/225], Training Accuracy: 96.4245%, Training Loss: 0.0995%\n",
      "Epoch [91/300], Step [223/225], Training Accuracy: 96.4196%, Training Loss: 0.0995%\n",
      "Epoch [91/300], Step [224/225], Training Accuracy: 96.4216%, Training Loss: 0.0995%\n",
      "Epoch [91/300], Step [225/225], Training Accuracy: 96.4008%, Training Loss: 0.0997%\n",
      "Epoch [92/300], Step [1/225], Training Accuracy: 95.3125%, Training Loss: 0.0840%\n",
      "Epoch [92/300], Step [2/225], Training Accuracy: 96.0938%, Training Loss: 0.0845%\n",
      "Epoch [92/300], Step [3/225], Training Accuracy: 96.8750%, Training Loss: 0.0846%\n",
      "Epoch [92/300], Step [4/225], Training Accuracy: 96.0938%, Training Loss: 0.0883%\n",
      "Epoch [92/300], Step [5/225], Training Accuracy: 96.5625%, Training Loss: 0.0846%\n",
      "Epoch [92/300], Step [6/225], Training Accuracy: 97.1354%, Training Loss: 0.0768%\n",
      "Epoch [92/300], Step [7/225], Training Accuracy: 97.0982%, Training Loss: 0.0747%\n",
      "Epoch [92/300], Step [8/225], Training Accuracy: 97.4609%, Training Loss: 0.0768%\n",
      "Epoch [92/300], Step [9/225], Training Accuracy: 97.5694%, Training Loss: 0.0731%\n",
      "Epoch [92/300], Step [10/225], Training Accuracy: 97.0312%, Training Loss: 0.0811%\n",
      "Epoch [92/300], Step [11/225], Training Accuracy: 97.0170%, Training Loss: 0.0856%\n",
      "Epoch [92/300], Step [12/225], Training Accuracy: 97.0052%, Training Loss: 0.0852%\n",
      "Epoch [92/300], Step [13/225], Training Accuracy: 96.8750%, Training Loss: 0.0888%\n",
      "Epoch [92/300], Step [14/225], Training Accuracy: 96.8750%, Training Loss: 0.0901%\n",
      "Epoch [92/300], Step [15/225], Training Accuracy: 96.7708%, Training Loss: 0.0900%\n",
      "Epoch [92/300], Step [16/225], Training Accuracy: 96.8750%, Training Loss: 0.0897%\n",
      "Epoch [92/300], Step [17/225], Training Accuracy: 96.6912%, Training Loss: 0.0898%\n",
      "Epoch [92/300], Step [18/225], Training Accuracy: 96.6146%, Training Loss: 0.0899%\n",
      "Epoch [92/300], Step [19/225], Training Accuracy: 96.6283%, Training Loss: 0.0897%\n",
      "Epoch [92/300], Step [20/225], Training Accuracy: 96.6406%, Training Loss: 0.0884%\n",
      "Epoch [92/300], Step [21/225], Training Accuracy: 96.7262%, Training Loss: 0.0872%\n",
      "Epoch [92/300], Step [22/225], Training Accuracy: 96.5909%, Training Loss: 0.0886%\n",
      "Epoch [92/300], Step [23/225], Training Accuracy: 96.7391%, Training Loss: 0.0861%\n",
      "Epoch [92/300], Step [24/225], Training Accuracy: 96.4844%, Training Loss: 0.0903%\n",
      "Epoch [92/300], Step [25/225], Training Accuracy: 96.6250%, Training Loss: 0.0883%\n",
      "Epoch [92/300], Step [26/225], Training Accuracy: 96.6947%, Training Loss: 0.0876%\n",
      "Epoch [92/300], Step [27/225], Training Accuracy: 96.7593%, Training Loss: 0.0867%\n",
      "Epoch [92/300], Step [28/225], Training Accuracy: 96.7634%, Training Loss: 0.0873%\n",
      "Epoch [92/300], Step [29/225], Training Accuracy: 96.7134%, Training Loss: 0.0874%\n",
      "Epoch [92/300], Step [30/225], Training Accuracy: 96.8229%, Training Loss: 0.0851%\n",
      "Epoch [92/300], Step [31/225], Training Accuracy: 96.8750%, Training Loss: 0.0839%\n",
      "Epoch [92/300], Step [32/225], Training Accuracy: 96.9238%, Training Loss: 0.0830%\n",
      "Epoch [92/300], Step [33/225], Training Accuracy: 96.8750%, Training Loss: 0.0852%\n",
      "Epoch [92/300], Step [34/225], Training Accuracy: 96.8290%, Training Loss: 0.0858%\n",
      "Epoch [92/300], Step [35/225], Training Accuracy: 96.8304%, Training Loss: 0.0856%\n",
      "Epoch [92/300], Step [36/225], Training Accuracy: 96.7882%, Training Loss: 0.0864%\n",
      "Epoch [92/300], Step [37/225], Training Accuracy: 96.8328%, Training Loss: 0.0857%\n",
      "Epoch [92/300], Step [38/225], Training Accuracy: 96.7928%, Training Loss: 0.0870%\n",
      "Epoch [92/300], Step [39/225], Training Accuracy: 96.6747%, Training Loss: 0.0888%\n",
      "Epoch [92/300], Step [40/225], Training Accuracy: 96.6406%, Training Loss: 0.0904%\n",
      "Epoch [92/300], Step [41/225], Training Accuracy: 96.6463%, Training Loss: 0.0902%\n",
      "Epoch [92/300], Step [42/225], Training Accuracy: 96.6890%, Training Loss: 0.0895%\n",
      "Epoch [92/300], Step [43/225], Training Accuracy: 96.6933%, Training Loss: 0.0891%\n",
      "Epoch [92/300], Step [44/225], Training Accuracy: 96.7330%, Training Loss: 0.0883%\n",
      "Epoch [92/300], Step [45/225], Training Accuracy: 96.7708%, Training Loss: 0.0875%\n",
      "Epoch [92/300], Step [46/225], Training Accuracy: 96.8071%, Training Loss: 0.0866%\n",
      "Epoch [92/300], Step [47/225], Training Accuracy: 96.8750%, Training Loss: 0.0858%\n",
      "Epoch [92/300], Step [48/225], Training Accuracy: 96.9076%, Training Loss: 0.0853%\n",
      "Epoch [92/300], Step [49/225], Training Accuracy: 96.8112%, Training Loss: 0.0861%\n",
      "Epoch [92/300], Step [50/225], Training Accuracy: 96.7188%, Training Loss: 0.0884%\n",
      "Epoch [92/300], Step [51/225], Training Accuracy: 96.7525%, Training Loss: 0.0876%\n",
      "Epoch [92/300], Step [52/225], Training Accuracy: 96.7849%, Training Loss: 0.0869%\n",
      "Epoch [92/300], Step [53/225], Training Accuracy: 96.7276%, Training Loss: 0.0880%\n",
      "Epoch [92/300], Step [54/225], Training Accuracy: 96.7593%, Training Loss: 0.0880%\n",
      "Epoch [92/300], Step [55/225], Training Accuracy: 96.7330%, Training Loss: 0.0880%\n",
      "Epoch [92/300], Step [56/225], Training Accuracy: 96.7355%, Training Loss: 0.0886%\n",
      "Epoch [92/300], Step [57/225], Training Accuracy: 96.7379%, Training Loss: 0.0881%\n",
      "Epoch [92/300], Step [58/225], Training Accuracy: 96.7942%, Training Loss: 0.0870%\n",
      "Epoch [92/300], Step [59/225], Training Accuracy: 96.7956%, Training Loss: 0.0868%\n",
      "Epoch [92/300], Step [60/225], Training Accuracy: 96.8490%, Training Loss: 0.0861%\n",
      "Epoch [92/300], Step [61/225], Training Accuracy: 96.8494%, Training Loss: 0.0865%\n",
      "Epoch [92/300], Step [62/225], Training Accuracy: 96.7490%, Training Loss: 0.0879%\n",
      "Epoch [92/300], Step [63/225], Training Accuracy: 96.7510%, Training Loss: 0.0873%\n",
      "Epoch [92/300], Step [64/225], Training Accuracy: 96.7285%, Training Loss: 0.0882%\n",
      "Epoch [92/300], Step [65/225], Training Accuracy: 96.7308%, Training Loss: 0.0880%\n",
      "Epoch [92/300], Step [66/225], Training Accuracy: 96.6383%, Training Loss: 0.0894%\n",
      "Epoch [92/300], Step [67/225], Training Accuracy: 96.6651%, Training Loss: 0.0891%\n",
      "Epoch [92/300], Step [68/225], Training Accuracy: 96.6912%, Training Loss: 0.0886%\n",
      "Epoch [92/300], Step [69/225], Training Accuracy: 96.7165%, Training Loss: 0.0878%\n",
      "Epoch [92/300], Step [70/225], Training Accuracy: 96.7411%, Training Loss: 0.0871%\n",
      "Epoch [92/300], Step [71/225], Training Accuracy: 96.7650%, Training Loss: 0.0872%\n",
      "Epoch [92/300], Step [72/225], Training Accuracy: 96.7882%, Training Loss: 0.0868%\n",
      "Epoch [92/300], Step [73/225], Training Accuracy: 96.7894%, Training Loss: 0.0872%\n",
      "Epoch [92/300], Step [74/225], Training Accuracy: 96.7694%, Training Loss: 0.0884%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/300], Step [75/225], Training Accuracy: 96.7917%, Training Loss: 0.0880%\n",
      "Epoch [92/300], Step [76/225], Training Accuracy: 96.8133%, Training Loss: 0.0878%\n",
      "Epoch [92/300], Step [77/225], Training Accuracy: 96.8547%, Training Loss: 0.0873%\n",
      "Epoch [92/300], Step [78/225], Training Accuracy: 96.8750%, Training Loss: 0.0870%\n",
      "Epoch [92/300], Step [79/225], Training Accuracy: 96.8354%, Training Loss: 0.0881%\n",
      "Epoch [92/300], Step [80/225], Training Accuracy: 96.8555%, Training Loss: 0.0879%\n",
      "Epoch [92/300], Step [81/225], Training Accuracy: 96.8557%, Training Loss: 0.0876%\n",
      "Epoch [92/300], Step [82/225], Training Accuracy: 96.8750%, Training Loss: 0.0869%\n",
      "Epoch [92/300], Step [83/225], Training Accuracy: 96.8750%, Training Loss: 0.0869%\n",
      "Epoch [92/300], Step [84/225], Training Accuracy: 96.8750%, Training Loss: 0.0870%\n",
      "Epoch [92/300], Step [85/225], Training Accuracy: 96.8750%, Training Loss: 0.0873%\n",
      "Epoch [92/300], Step [86/225], Training Accuracy: 96.8568%, Training Loss: 0.0882%\n",
      "Epoch [92/300], Step [87/225], Training Accuracy: 96.8032%, Training Loss: 0.0895%\n",
      "Epoch [92/300], Step [88/225], Training Accuracy: 96.7685%, Training Loss: 0.0901%\n",
      "Epoch [92/300], Step [89/225], Training Accuracy: 96.7872%, Training Loss: 0.0901%\n",
      "Epoch [92/300], Step [90/225], Training Accuracy: 96.7882%, Training Loss: 0.0901%\n",
      "Epoch [92/300], Step [91/225], Training Accuracy: 96.7720%, Training Loss: 0.0903%\n",
      "Epoch [92/300], Step [92/225], Training Accuracy: 96.7901%, Training Loss: 0.0900%\n",
      "Epoch [92/300], Step [93/225], Training Accuracy: 96.7406%, Training Loss: 0.0910%\n",
      "Epoch [92/300], Step [94/225], Training Accuracy: 96.7254%, Training Loss: 0.0919%\n",
      "Epoch [92/300], Step [95/225], Training Accuracy: 96.7105%, Training Loss: 0.0922%\n",
      "Epoch [92/300], Step [96/225], Training Accuracy: 96.6797%, Training Loss: 0.0927%\n",
      "Epoch [92/300], Step [97/225], Training Accuracy: 96.6656%, Training Loss: 0.0930%\n",
      "Epoch [92/300], Step [98/225], Training Accuracy: 96.6837%, Training Loss: 0.0934%\n",
      "Epoch [92/300], Step [99/225], Training Accuracy: 96.7172%, Training Loss: 0.0928%\n",
      "Epoch [92/300], Step [100/225], Training Accuracy: 96.6875%, Training Loss: 0.0930%\n",
      "Epoch [92/300], Step [101/225], Training Accuracy: 96.6584%, Training Loss: 0.0937%\n",
      "Epoch [92/300], Step [102/225], Training Accuracy: 96.6146%, Training Loss: 0.0946%\n",
      "Epoch [92/300], Step [103/225], Training Accuracy: 96.6171%, Training Loss: 0.0944%\n",
      "Epoch [92/300], Step [104/225], Training Accuracy: 96.5294%, Training Loss: 0.0958%\n",
      "Epoch [92/300], Step [105/225], Training Accuracy: 96.5476%, Training Loss: 0.0956%\n",
      "Epoch [92/300], Step [106/225], Training Accuracy: 96.5802%, Training Loss: 0.0954%\n",
      "Epoch [92/300], Step [107/225], Training Accuracy: 96.5391%, Training Loss: 0.0958%\n",
      "Epoch [92/300], Step [108/225], Training Accuracy: 96.5133%, Training Loss: 0.0963%\n",
      "Epoch [92/300], Step [109/225], Training Accuracy: 96.5310%, Training Loss: 0.0959%\n",
      "Epoch [92/300], Step [110/225], Training Accuracy: 96.5483%, Training Loss: 0.0954%\n",
      "Epoch [92/300], Step [111/225], Training Accuracy: 96.5512%, Training Loss: 0.0956%\n",
      "Epoch [92/300], Step [112/225], Training Accuracy: 96.5681%, Training Loss: 0.0951%\n",
      "Epoch [92/300], Step [113/225], Training Accuracy: 96.5985%, Training Loss: 0.0947%\n",
      "Epoch [92/300], Step [114/225], Training Accuracy: 96.5872%, Training Loss: 0.0947%\n",
      "Epoch [92/300], Step [115/225], Training Accuracy: 96.5625%, Training Loss: 0.0948%\n",
      "Epoch [92/300], Step [116/225], Training Accuracy: 96.5383%, Training Loss: 0.0950%\n",
      "Epoch [92/300], Step [117/225], Training Accuracy: 96.5411%, Training Loss: 0.0949%\n",
      "Epoch [92/300], Step [118/225], Training Accuracy: 96.5572%, Training Loss: 0.0945%\n",
      "Epoch [92/300], Step [119/225], Training Accuracy: 96.5599%, Training Loss: 0.0946%\n",
      "Epoch [92/300], Step [120/225], Training Accuracy: 96.5625%, Training Loss: 0.0944%\n",
      "Epoch [92/300], Step [121/225], Training Accuracy: 96.5909%, Training Loss: 0.0940%\n",
      "Epoch [92/300], Step [122/225], Training Accuracy: 96.5932%, Training Loss: 0.0939%\n",
      "Epoch [92/300], Step [123/225], Training Accuracy: 96.5701%, Training Loss: 0.0940%\n",
      "Epoch [92/300], Step [124/225], Training Accuracy: 96.5852%, Training Loss: 0.0939%\n",
      "Epoch [92/300], Step [125/225], Training Accuracy: 96.6000%, Training Loss: 0.0941%\n",
      "Epoch [92/300], Step [126/225], Training Accuracy: 96.6146%, Training Loss: 0.0938%\n",
      "Epoch [92/300], Step [127/225], Training Accuracy: 96.6289%, Training Loss: 0.0940%\n",
      "Epoch [92/300], Step [128/225], Training Accuracy: 96.6309%, Training Loss: 0.0940%\n",
      "Epoch [92/300], Step [129/225], Training Accuracy: 96.6449%, Training Loss: 0.0942%\n",
      "Epoch [92/300], Step [130/225], Training Accuracy: 96.6587%, Training Loss: 0.0938%\n",
      "Epoch [92/300], Step [131/225], Training Accuracy: 96.6842%, Training Loss: 0.0935%\n",
      "Epoch [92/300], Step [132/225], Training Accuracy: 96.6501%, Training Loss: 0.0940%\n",
      "Epoch [92/300], Step [133/225], Training Accuracy: 96.6635%, Training Loss: 0.0935%\n",
      "Epoch [92/300], Step [134/225], Training Accuracy: 96.6768%, Training Loss: 0.0933%\n",
      "Epoch [92/300], Step [135/225], Training Accuracy: 96.6898%, Training Loss: 0.0929%\n",
      "Epoch [92/300], Step [136/225], Training Accuracy: 96.6682%, Training Loss: 0.0936%\n",
      "Epoch [92/300], Step [137/225], Training Accuracy: 96.6469%, Training Loss: 0.0939%\n",
      "Epoch [92/300], Step [138/225], Training Accuracy: 96.6372%, Training Loss: 0.0938%\n",
      "Epoch [92/300], Step [139/225], Training Accuracy: 96.6389%, Training Loss: 0.0936%\n",
      "Epoch [92/300], Step [140/225], Training Accuracy: 96.6295%, Training Loss: 0.0936%\n",
      "Epoch [92/300], Step [141/225], Training Accuracy: 96.6090%, Training Loss: 0.0940%\n",
      "Epoch [92/300], Step [142/225], Training Accuracy: 96.6329%, Training Loss: 0.0937%\n",
      "Epoch [92/300], Step [143/225], Training Accuracy: 96.6346%, Training Loss: 0.0935%\n",
      "Epoch [92/300], Step [144/225], Training Accuracy: 96.6146%, Training Loss: 0.0940%\n",
      "Epoch [92/300], Step [145/225], Training Accuracy: 96.6272%, Training Loss: 0.0937%\n",
      "Epoch [92/300], Step [146/225], Training Accuracy: 96.6289%, Training Loss: 0.0934%\n",
      "Epoch [92/300], Step [147/225], Training Accuracy: 96.6412%, Training Loss: 0.0934%\n",
      "Epoch [92/300], Step [148/225], Training Accuracy: 96.6639%, Training Loss: 0.0932%\n",
      "Epoch [92/300], Step [149/225], Training Accuracy: 96.6653%, Training Loss: 0.0930%\n",
      "Epoch [92/300], Step [150/225], Training Accuracy: 96.6667%, Training Loss: 0.0929%\n",
      "Epoch [92/300], Step [151/225], Training Accuracy: 96.6370%, Training Loss: 0.0937%\n",
      "Epoch [92/300], Step [152/225], Training Accuracy: 96.6386%, Training Loss: 0.0935%\n",
      "Epoch [92/300], Step [153/225], Training Accuracy: 96.6503%, Training Loss: 0.0933%\n",
      "Epoch [92/300], Step [154/225], Training Accuracy: 96.6518%, Training Loss: 0.0933%\n",
      "Epoch [92/300], Step [155/225], Training Accuracy: 96.6331%, Training Loss: 0.0936%\n",
      "Epoch [92/300], Step [156/225], Training Accuracy: 96.6446%, Training Loss: 0.0936%\n",
      "Epoch [92/300], Step [157/225], Training Accuracy: 96.6162%, Training Loss: 0.0942%\n",
      "Epoch [92/300], Step [158/225], Training Accuracy: 96.6278%, Training Loss: 0.0940%\n",
      "Epoch [92/300], Step [159/225], Training Accuracy: 96.6097%, Training Loss: 0.0941%\n",
      "Epoch [92/300], Step [160/225], Training Accuracy: 96.5918%, Training Loss: 0.0945%\n",
      "Epoch [92/300], Step [161/225], Training Accuracy: 96.6033%, Training Loss: 0.0941%\n",
      "Epoch [92/300], Step [162/225], Training Accuracy: 96.5953%, Training Loss: 0.0942%\n",
      "Epoch [92/300], Step [163/225], Training Accuracy: 96.5970%, Training Loss: 0.0942%\n",
      "Epoch [92/300], Step [164/225], Training Accuracy: 96.5892%, Training Loss: 0.0943%\n",
      "Epoch [92/300], Step [165/225], Training Accuracy: 96.6098%, Training Loss: 0.0939%\n",
      "Epoch [92/300], Step [166/225], Training Accuracy: 96.6114%, Training Loss: 0.0941%\n",
      "Epoch [92/300], Step [167/225], Training Accuracy: 96.6224%, Training Loss: 0.0939%\n",
      "Epoch [92/300], Step [168/225], Training Accuracy: 96.6239%, Training Loss: 0.0938%\n",
      "Epoch [92/300], Step [169/225], Training Accuracy: 96.6254%, Training Loss: 0.0939%\n",
      "Epoch [92/300], Step [170/225], Training Accuracy: 96.6176%, Training Loss: 0.0940%\n",
      "Epoch [92/300], Step [171/225], Training Accuracy: 96.6192%, Training Loss: 0.0938%\n",
      "Epoch [92/300], Step [172/225], Training Accuracy: 96.6206%, Training Loss: 0.0938%\n",
      "Epoch [92/300], Step [173/225], Training Accuracy: 96.6311%, Training Loss: 0.0934%\n",
      "Epoch [92/300], Step [174/225], Training Accuracy: 96.6505%, Training Loss: 0.0931%\n",
      "Epoch [92/300], Step [175/225], Training Accuracy: 96.6607%, Training Loss: 0.0928%\n",
      "Epoch [92/300], Step [176/225], Training Accuracy: 96.6708%, Training Loss: 0.0926%\n",
      "Epoch [92/300], Step [177/225], Training Accuracy: 96.6631%, Training Loss: 0.0926%\n",
      "Epoch [92/300], Step [178/225], Training Accuracy: 96.6731%, Training Loss: 0.0925%\n",
      "Epoch [92/300], Step [179/225], Training Accuracy: 96.6655%, Training Loss: 0.0929%\n",
      "Epoch [92/300], Step [180/225], Training Accuracy: 96.6667%, Training Loss: 0.0931%\n",
      "Epoch [92/300], Step [181/225], Training Accuracy: 96.6506%, Training Loss: 0.0931%\n",
      "Epoch [92/300], Step [182/225], Training Accuracy: 96.6604%, Training Loss: 0.0930%\n",
      "Epoch [92/300], Step [183/225], Training Accuracy: 96.6701%, Training Loss: 0.0929%\n",
      "Epoch [92/300], Step [184/225], Training Accuracy: 96.6627%, Training Loss: 0.0929%\n",
      "Epoch [92/300], Step [185/225], Training Accuracy: 96.6723%, Training Loss: 0.0928%\n",
      "Epoch [92/300], Step [186/225], Training Accuracy: 96.6650%, Training Loss: 0.0928%\n",
      "Epoch [92/300], Step [187/225], Training Accuracy: 96.6745%, Training Loss: 0.0926%\n",
      "Epoch [92/300], Step [188/225], Training Accuracy: 96.6838%, Training Loss: 0.0925%\n",
      "Epoch [92/300], Step [189/225], Training Accuracy: 96.6849%, Training Loss: 0.0925%\n",
      "Epoch [92/300], Step [190/225], Training Accuracy: 96.6612%, Training Loss: 0.0931%\n",
      "Epoch [92/300], Step [191/225], Training Accuracy: 96.6623%, Training Loss: 0.0930%\n",
      "Epoch [92/300], Step [192/225], Training Accuracy: 96.6715%, Training Loss: 0.0928%\n",
      "Epoch [92/300], Step [193/225], Training Accuracy: 96.6726%, Training Loss: 0.0930%\n",
      "Epoch [92/300], Step [194/225], Training Accuracy: 96.6817%, Training Loss: 0.0927%\n",
      "Epoch [92/300], Step [195/225], Training Accuracy: 96.6747%, Training Loss: 0.0930%\n",
      "Epoch [92/300], Step [196/225], Training Accuracy: 96.6837%, Training Loss: 0.0928%\n",
      "Epoch [92/300], Step [197/225], Training Accuracy: 96.7005%, Training Loss: 0.0927%\n",
      "Epoch [92/300], Step [198/225], Training Accuracy: 96.7093%, Training Loss: 0.0926%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/300], Step [199/225], Training Accuracy: 96.7101%, Training Loss: 0.0927%\n",
      "Epoch [92/300], Step [200/225], Training Accuracy: 96.7109%, Training Loss: 0.0926%\n",
      "Epoch [92/300], Step [201/225], Training Accuracy: 96.7118%, Training Loss: 0.0925%\n",
      "Epoch [92/300], Step [202/225], Training Accuracy: 96.7203%, Training Loss: 0.0922%\n",
      "Epoch [92/300], Step [203/225], Training Accuracy: 96.7134%, Training Loss: 0.0923%\n",
      "Epoch [92/300], Step [204/225], Training Accuracy: 96.7295%, Training Loss: 0.0921%\n",
      "Epoch [92/300], Step [205/225], Training Accuracy: 96.7226%, Training Loss: 0.0921%\n",
      "Epoch [92/300], Step [206/225], Training Accuracy: 96.7309%, Training Loss: 0.0921%\n",
      "Epoch [92/300], Step [207/225], Training Accuracy: 96.7240%, Training Loss: 0.0922%\n",
      "Epoch [92/300], Step [208/225], Training Accuracy: 96.7097%, Training Loss: 0.0923%\n",
      "Epoch [92/300], Step [209/225], Training Accuracy: 96.7180%, Training Loss: 0.0920%\n",
      "Epoch [92/300], Step [210/225], Training Accuracy: 96.7262%, Training Loss: 0.0918%\n",
      "Epoch [92/300], Step [211/225], Training Accuracy: 96.7269%, Training Loss: 0.0920%\n",
      "Epoch [92/300], Step [212/225], Training Accuracy: 96.7129%, Training Loss: 0.0921%\n",
      "Epoch [92/300], Step [213/225], Training Accuracy: 96.6916%, Training Loss: 0.0924%\n",
      "Epoch [92/300], Step [214/225], Training Accuracy: 96.7071%, Training Loss: 0.0922%\n",
      "Epoch [92/300], Step [215/225], Training Accuracy: 96.7151%, Training Loss: 0.0922%\n",
      "Epoch [92/300], Step [216/225], Training Accuracy: 96.7159%, Training Loss: 0.0922%\n",
      "Epoch [92/300], Step [217/225], Training Accuracy: 96.7238%, Training Loss: 0.0921%\n",
      "Epoch [92/300], Step [218/225], Training Accuracy: 96.7245%, Training Loss: 0.0921%\n",
      "Epoch [92/300], Step [219/225], Training Accuracy: 96.7252%, Training Loss: 0.0919%\n",
      "Epoch [92/300], Step [220/225], Training Accuracy: 96.7330%, Training Loss: 0.0919%\n",
      "Epoch [92/300], Step [221/225], Training Accuracy: 96.7336%, Training Loss: 0.0919%\n",
      "Epoch [92/300], Step [222/225], Training Accuracy: 96.7342%, Training Loss: 0.0919%\n",
      "Epoch [92/300], Step [223/225], Training Accuracy: 96.7489%, Training Loss: 0.0916%\n",
      "Epoch [92/300], Step [224/225], Training Accuracy: 96.7494%, Training Loss: 0.0915%\n",
      "Epoch [92/300], Step [225/225], Training Accuracy: 96.7482%, Training Loss: 0.0915%\n",
      "Epoch [93/300], Step [1/225], Training Accuracy: 98.4375%, Training Loss: 0.0463%\n",
      "Epoch [93/300], Step [2/225], Training Accuracy: 96.8750%, Training Loss: 0.0717%\n",
      "Epoch [93/300], Step [3/225], Training Accuracy: 95.8333%, Training Loss: 0.0871%\n",
      "Epoch [93/300], Step [4/225], Training Accuracy: 96.0938%, Training Loss: 0.0831%\n",
      "Epoch [93/300], Step [5/225], Training Accuracy: 96.5625%, Training Loss: 0.0796%\n",
      "Epoch [93/300], Step [6/225], Training Accuracy: 96.8750%, Training Loss: 0.0751%\n",
      "Epoch [93/300], Step [7/225], Training Accuracy: 97.0982%, Training Loss: 0.0710%\n",
      "Epoch [93/300], Step [8/225], Training Accuracy: 96.2891%, Training Loss: 0.0859%\n",
      "Epoch [93/300], Step [9/225], Training Accuracy: 96.5278%, Training Loss: 0.0831%\n",
      "Epoch [93/300], Step [10/225], Training Accuracy: 96.8750%, Training Loss: 0.0796%\n",
      "Epoch [93/300], Step [11/225], Training Accuracy: 97.1591%, Training Loss: 0.0741%\n",
      "Epoch [93/300], Step [12/225], Training Accuracy: 97.3958%, Training Loss: 0.0702%\n",
      "Epoch [93/300], Step [13/225], Training Accuracy: 97.2356%, Training Loss: 0.0736%\n",
      "Epoch [93/300], Step [14/225], Training Accuracy: 97.2098%, Training Loss: 0.0742%\n",
      "Epoch [93/300], Step [15/225], Training Accuracy: 97.1875%, Training Loss: 0.0749%\n",
      "Epoch [93/300], Step [16/225], Training Accuracy: 97.2656%, Training Loss: 0.0750%\n",
      "Epoch [93/300], Step [17/225], Training Accuracy: 97.0588%, Training Loss: 0.0799%\n",
      "Epoch [93/300], Step [18/225], Training Accuracy: 96.8750%, Training Loss: 0.0860%\n",
      "Epoch [93/300], Step [19/225], Training Accuracy: 96.8750%, Training Loss: 0.0870%\n",
      "Epoch [93/300], Step [20/225], Training Accuracy: 97.0312%, Training Loss: 0.0840%\n",
      "Epoch [93/300], Step [21/225], Training Accuracy: 97.1726%, Training Loss: 0.0806%\n",
      "Epoch [93/300], Step [22/225], Training Accuracy: 97.2301%, Training Loss: 0.0796%\n",
      "Epoch [93/300], Step [23/225], Training Accuracy: 97.2147%, Training Loss: 0.0787%\n",
      "Epoch [93/300], Step [24/225], Training Accuracy: 97.1354%, Training Loss: 0.0828%\n",
      "Epoch [93/300], Step [25/225], Training Accuracy: 97.2500%, Training Loss: 0.0806%\n",
      "Epoch [93/300], Step [26/225], Training Accuracy: 97.2356%, Training Loss: 0.0822%\n",
      "Epoch [93/300], Step [27/225], Training Accuracy: 97.2801%, Training Loss: 0.0811%\n",
      "Epoch [93/300], Step [28/225], Training Accuracy: 97.1540%, Training Loss: 0.0822%\n",
      "Epoch [93/300], Step [29/225], Training Accuracy: 97.0905%, Training Loss: 0.0826%\n",
      "Epoch [93/300], Step [30/225], Training Accuracy: 96.9792%, Training Loss: 0.0832%\n",
      "Epoch [93/300], Step [31/225], Training Accuracy: 96.9758%, Training Loss: 0.0824%\n",
      "Epoch [93/300], Step [32/225], Training Accuracy: 96.8750%, Training Loss: 0.0829%\n",
      "Epoch [93/300], Step [33/225], Training Accuracy: 96.8277%, Training Loss: 0.0828%\n",
      "Epoch [93/300], Step [34/225], Training Accuracy: 96.8750%, Training Loss: 0.0823%\n",
      "Epoch [93/300], Step [35/225], Training Accuracy: 96.9643%, Training Loss: 0.0809%\n",
      "Epoch [93/300], Step [36/225], Training Accuracy: 96.9618%, Training Loss: 0.0810%\n",
      "Epoch [93/300], Step [37/225], Training Accuracy: 97.0017%, Training Loss: 0.0804%\n",
      "Epoch [93/300], Step [38/225], Training Accuracy: 96.9984%, Training Loss: 0.0811%\n",
      "Epoch [93/300], Step [39/225], Training Accuracy: 96.9151%, Training Loss: 0.0828%\n",
      "Epoch [93/300], Step [40/225], Training Accuracy: 96.8750%, Training Loss: 0.0843%\n",
      "Epoch [93/300], Step [41/225], Training Accuracy: 96.7607%, Training Loss: 0.0864%\n",
      "Epoch [93/300], Step [42/225], Training Accuracy: 96.7634%, Training Loss: 0.0865%\n",
      "Epoch [93/300], Step [43/225], Training Accuracy: 96.8023%, Training Loss: 0.0854%\n",
      "Epoch [93/300], Step [44/225], Training Accuracy: 96.8395%, Training Loss: 0.0844%\n",
      "Epoch [93/300], Step [45/225], Training Accuracy: 96.8056%, Training Loss: 0.0846%\n",
      "Epoch [93/300], Step [46/225], Training Accuracy: 96.8750%, Training Loss: 0.0834%\n",
      "Epoch [93/300], Step [47/225], Training Accuracy: 96.9082%, Training Loss: 0.0831%\n",
      "Epoch [93/300], Step [48/225], Training Accuracy: 96.9401%, Training Loss: 0.0826%\n",
      "Epoch [93/300], Step [49/225], Training Accuracy: 96.9707%, Training Loss: 0.0833%\n",
      "Epoch [93/300], Step [50/225], Training Accuracy: 96.9688%, Training Loss: 0.0836%\n",
      "Epoch [93/300], Step [51/225], Training Accuracy: 96.9056%, Training Loss: 0.0873%\n",
      "Epoch [93/300], Step [52/225], Training Accuracy: 96.9651%, Training Loss: 0.0861%\n",
      "Epoch [93/300], Step [53/225], Training Accuracy: 96.9929%, Training Loss: 0.0857%\n",
      "Epoch [93/300], Step [54/225], Training Accuracy: 96.9329%, Training Loss: 0.0859%\n",
      "Epoch [93/300], Step [55/225], Training Accuracy: 96.9602%, Training Loss: 0.0856%\n",
      "Epoch [93/300], Step [56/225], Training Accuracy: 96.9308%, Training Loss: 0.0854%\n",
      "Epoch [93/300], Step [57/225], Training Accuracy: 96.9024%, Training Loss: 0.0855%\n",
      "Epoch [93/300], Step [58/225], Training Accuracy: 96.9289%, Training Loss: 0.0849%\n",
      "Epoch [93/300], Step [59/225], Training Accuracy: 96.8750%, Training Loss: 0.0857%\n",
      "Epoch [93/300], Step [60/225], Training Accuracy: 96.8750%, Training Loss: 0.0858%\n",
      "Epoch [93/300], Step [61/225], Training Accuracy: 96.8238%, Training Loss: 0.0876%\n",
      "Epoch [93/300], Step [62/225], Training Accuracy: 96.7994%, Training Loss: 0.0879%\n",
      "Epoch [93/300], Step [63/225], Training Accuracy: 96.7758%, Training Loss: 0.0886%\n",
      "Epoch [93/300], Step [64/225], Training Accuracy: 96.7529%, Training Loss: 0.0888%\n",
      "Epoch [93/300], Step [65/225], Training Accuracy: 96.7548%, Training Loss: 0.0887%\n",
      "Epoch [93/300], Step [66/225], Training Accuracy: 96.7566%, Training Loss: 0.0895%\n",
      "Epoch [93/300], Step [67/225], Training Accuracy: 96.8050%, Training Loss: 0.0891%\n",
      "Epoch [93/300], Step [68/225], Training Accuracy: 96.8061%, Training Loss: 0.0889%\n",
      "Epoch [93/300], Step [69/225], Training Accuracy: 96.8297%, Training Loss: 0.0885%\n",
      "Epoch [93/300], Step [70/225], Training Accuracy: 96.8080%, Training Loss: 0.0882%\n",
      "Epoch [93/300], Step [71/225], Training Accuracy: 96.8310%, Training Loss: 0.0878%\n",
      "Epoch [93/300], Step [72/225], Training Accuracy: 96.8533%, Training Loss: 0.0878%\n",
      "Epoch [93/300], Step [73/225], Training Accuracy: 96.8750%, Training Loss: 0.0878%\n",
      "Epoch [93/300], Step [74/225], Training Accuracy: 96.9172%, Training Loss: 0.0872%\n",
      "Epoch [93/300], Step [75/225], Training Accuracy: 96.8958%, Training Loss: 0.0878%\n",
      "Epoch [93/300], Step [76/225], Training Accuracy: 96.8544%, Training Loss: 0.0885%\n",
      "Epoch [93/300], Step [77/225], Training Accuracy: 96.8547%, Training Loss: 0.0886%\n",
      "Epoch [93/300], Step [78/225], Training Accuracy: 96.8950%, Training Loss: 0.0879%\n",
      "Epoch [93/300], Step [79/225], Training Accuracy: 96.8552%, Training Loss: 0.0883%\n",
      "Epoch [93/300], Step [80/225], Training Accuracy: 96.8750%, Training Loss: 0.0880%\n",
      "Epoch [93/300], Step [81/225], Training Accuracy: 96.9136%, Training Loss: 0.0872%\n",
      "Epoch [93/300], Step [82/225], Training Accuracy: 96.9322%, Training Loss: 0.0868%\n",
      "Epoch [93/300], Step [83/225], Training Accuracy: 96.9503%, Training Loss: 0.0868%\n",
      "Epoch [93/300], Step [84/225], Training Accuracy: 96.9308%, Training Loss: 0.0873%\n",
      "Epoch [93/300], Step [85/225], Training Accuracy: 96.9485%, Training Loss: 0.0868%\n",
      "Epoch [93/300], Step [86/225], Training Accuracy: 96.9295%, Training Loss: 0.0870%\n",
      "Epoch [93/300], Step [87/225], Training Accuracy: 96.9468%, Training Loss: 0.0867%\n",
      "Epoch [93/300], Step [88/225], Training Accuracy: 96.9815%, Training Loss: 0.0862%\n",
      "Epoch [93/300], Step [89/225], Training Accuracy: 96.9979%, Training Loss: 0.0862%\n",
      "Epoch [93/300], Step [90/225], Training Accuracy: 97.0312%, Training Loss: 0.0860%\n",
      "Epoch [93/300], Step [91/225], Training Accuracy: 96.9952%, Training Loss: 0.0864%\n",
      "Epoch [93/300], Step [92/225], Training Accuracy: 96.9429%, Training Loss: 0.0879%\n",
      "Epoch [93/300], Step [93/225], Training Accuracy: 96.9758%, Training Loss: 0.0874%\n",
      "Epoch [93/300], Step [94/225], Training Accuracy: 96.9581%, Training Loss: 0.0874%\n",
      "Epoch [93/300], Step [95/225], Training Accuracy: 96.9572%, Training Loss: 0.0870%\n",
      "Epoch [93/300], Step [96/225], Training Accuracy: 96.9889%, Training Loss: 0.0863%\n",
      "Epoch [93/300], Step [97/225], Training Accuracy: 97.0039%, Training Loss: 0.0862%\n",
      "Epoch [93/300], Step [98/225], Training Accuracy: 97.0185%, Training Loss: 0.0862%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/300], Step [99/225], Training Accuracy: 97.0170%, Training Loss: 0.0862%\n",
      "Epoch [93/300], Step [100/225], Training Accuracy: 97.0000%, Training Loss: 0.0875%\n",
      "Epoch [93/300], Step [101/225], Training Accuracy: 96.9988%, Training Loss: 0.0872%\n",
      "Epoch [93/300], Step [102/225], Training Accuracy: 96.9669%, Training Loss: 0.0879%\n",
      "Epoch [93/300], Step [103/225], Training Accuracy: 96.9508%, Training Loss: 0.0878%\n",
      "Epoch [93/300], Step [104/225], Training Accuracy: 96.9351%, Training Loss: 0.0880%\n",
      "Epoch [93/300], Step [105/225], Training Accuracy: 96.9643%, Training Loss: 0.0876%\n",
      "Epoch [93/300], Step [106/225], Training Accuracy: 96.9929%, Training Loss: 0.0870%\n",
      "Epoch [93/300], Step [107/225], Training Accuracy: 96.9772%, Training Loss: 0.0871%\n",
      "Epoch [93/300], Step [108/225], Training Accuracy: 96.9763%, Training Loss: 0.0870%\n",
      "Epoch [93/300], Step [109/225], Training Accuracy: 96.9753%, Training Loss: 0.0874%\n",
      "Epoch [93/300], Step [110/225], Training Accuracy: 97.0028%, Training Loss: 0.0867%\n",
      "Epoch [93/300], Step [111/225], Training Accuracy: 97.0158%, Training Loss: 0.0862%\n",
      "Epoch [93/300], Step [112/225], Training Accuracy: 97.0145%, Training Loss: 0.0860%\n",
      "Epoch [93/300], Step [113/225], Training Accuracy: 97.0271%, Training Loss: 0.0860%\n",
      "Epoch [93/300], Step [114/225], Training Accuracy: 97.0395%, Training Loss: 0.0858%\n",
      "Epoch [93/300], Step [115/225], Training Accuracy: 97.0380%, Training Loss: 0.0857%\n",
      "Epoch [93/300], Step [116/225], Training Accuracy: 97.0366%, Training Loss: 0.0857%\n",
      "Epoch [93/300], Step [117/225], Training Accuracy: 97.0620%, Training Loss: 0.0852%\n",
      "Epoch [93/300], Step [118/225], Training Accuracy: 97.0471%, Training Loss: 0.0856%\n",
      "Epoch [93/300], Step [119/225], Training Accuracy: 97.0588%, Training Loss: 0.0860%\n",
      "Epoch [93/300], Step [120/225], Training Accuracy: 97.0573%, Training Loss: 0.0858%\n",
      "Epoch [93/300], Step [121/225], Training Accuracy: 97.0687%, Training Loss: 0.0855%\n",
      "Epoch [93/300], Step [122/225], Training Accuracy: 97.0543%, Training Loss: 0.0854%\n",
      "Epoch [93/300], Step [123/225], Training Accuracy: 97.0783%, Training Loss: 0.0849%\n",
      "Epoch [93/300], Step [124/225], Training Accuracy: 97.0766%, Training Loss: 0.0849%\n",
      "Epoch [93/300], Step [125/225], Training Accuracy: 97.0875%, Training Loss: 0.0846%\n",
      "Epoch [93/300], Step [126/225], Training Accuracy: 97.0982%, Training Loss: 0.0843%\n",
      "Epoch [93/300], Step [127/225], Training Accuracy: 97.0965%, Training Loss: 0.0845%\n",
      "Epoch [93/300], Step [128/225], Training Accuracy: 97.1191%, Training Loss: 0.0841%\n",
      "Epoch [93/300], Step [129/225], Training Accuracy: 97.1294%, Training Loss: 0.0839%\n",
      "Epoch [93/300], Step [130/225], Training Accuracy: 97.1274%, Training Loss: 0.0842%\n",
      "Epoch [93/300], Step [131/225], Training Accuracy: 97.1135%, Training Loss: 0.0844%\n",
      "Epoch [93/300], Step [132/225], Training Accuracy: 97.1354%, Training Loss: 0.0840%\n",
      "Epoch [93/300], Step [133/225], Training Accuracy: 97.1335%, Training Loss: 0.0840%\n",
      "Epoch [93/300], Step [134/225], Training Accuracy: 97.1199%, Training Loss: 0.0841%\n",
      "Epoch [93/300], Step [135/225], Training Accuracy: 97.0949%, Training Loss: 0.0841%\n",
      "Epoch [93/300], Step [136/225], Training Accuracy: 97.0703%, Training Loss: 0.0842%\n",
      "Epoch [93/300], Step [137/225], Training Accuracy: 97.0803%, Training Loss: 0.0841%\n",
      "Epoch [93/300], Step [138/225], Training Accuracy: 97.0788%, Training Loss: 0.0840%\n",
      "Epoch [93/300], Step [139/225], Training Accuracy: 97.0886%, Training Loss: 0.0839%\n",
      "Epoch [93/300], Step [140/225], Training Accuracy: 97.0759%, Training Loss: 0.0842%\n",
      "Epoch [93/300], Step [141/225], Training Accuracy: 97.0745%, Training Loss: 0.0842%\n",
      "Epoch [93/300], Step [142/225], Training Accuracy: 97.0841%, Training Loss: 0.0840%\n",
      "Epoch [93/300], Step [143/225], Training Accuracy: 97.0935%, Training Loss: 0.0838%\n",
      "Epoch [93/300], Step [144/225], Training Accuracy: 97.1029%, Training Loss: 0.0834%\n",
      "Epoch [93/300], Step [145/225], Training Accuracy: 97.0582%, Training Loss: 0.0844%\n",
      "Epoch [93/300], Step [146/225], Training Accuracy: 97.0676%, Training Loss: 0.0843%\n",
      "Epoch [93/300], Step [147/225], Training Accuracy: 97.0770%, Training Loss: 0.0842%\n",
      "Epoch [93/300], Step [148/225], Training Accuracy: 97.0545%, Training Loss: 0.0848%\n",
      "Epoch [93/300], Step [149/225], Training Accuracy: 97.0428%, Training Loss: 0.0855%\n",
      "Epoch [93/300], Step [150/225], Training Accuracy: 97.0417%, Training Loss: 0.0854%\n",
      "Epoch [93/300], Step [151/225], Training Accuracy: 97.0509%, Training Loss: 0.0851%\n",
      "Epoch [93/300], Step [152/225], Training Accuracy: 97.0600%, Training Loss: 0.0849%\n",
      "Epoch [93/300], Step [153/225], Training Accuracy: 97.0690%, Training Loss: 0.0848%\n",
      "Epoch [93/300], Step [154/225], Training Accuracy: 97.0678%, Training Loss: 0.0846%\n",
      "Epoch [93/300], Step [155/225], Training Accuracy: 97.0867%, Training Loss: 0.0843%\n",
      "Epoch [93/300], Step [156/225], Training Accuracy: 97.0954%, Training Loss: 0.0841%\n",
      "Epoch [93/300], Step [157/225], Training Accuracy: 97.1039%, Training Loss: 0.0839%\n",
      "Epoch [93/300], Step [158/225], Training Accuracy: 97.1222%, Training Loss: 0.0835%\n",
      "Epoch [93/300], Step [159/225], Training Accuracy: 97.1305%, Training Loss: 0.0834%\n",
      "Epoch [93/300], Step [160/225], Training Accuracy: 97.1387%, Training Loss: 0.0830%\n",
      "Epoch [93/300], Step [161/225], Training Accuracy: 97.1467%, Training Loss: 0.0828%\n",
      "Epoch [93/300], Step [162/225], Training Accuracy: 97.1451%, Training Loss: 0.0829%\n",
      "Epoch [93/300], Step [163/225], Training Accuracy: 97.1626%, Training Loss: 0.0827%\n",
      "Epoch [93/300], Step [164/225], Training Accuracy: 97.1704%, Training Loss: 0.0826%\n",
      "Epoch [93/300], Step [165/225], Training Accuracy: 97.1591%, Training Loss: 0.0826%\n",
      "Epoch [93/300], Step [166/225], Training Accuracy: 97.1574%, Training Loss: 0.0825%\n",
      "Epoch [93/300], Step [167/225], Training Accuracy: 97.1557%, Training Loss: 0.0824%\n",
      "Epoch [93/300], Step [168/225], Training Accuracy: 97.1633%, Training Loss: 0.0821%\n",
      "Epoch [93/300], Step [169/225], Training Accuracy: 97.1524%, Training Loss: 0.0822%\n",
      "Epoch [93/300], Step [170/225], Training Accuracy: 97.1507%, Training Loss: 0.0827%\n",
      "Epoch [93/300], Step [171/225], Training Accuracy: 97.1674%, Training Loss: 0.0825%\n",
      "Epoch [93/300], Step [172/225], Training Accuracy: 97.1748%, Training Loss: 0.0825%\n",
      "Epoch [93/300], Step [173/225], Training Accuracy: 97.1730%, Training Loss: 0.0824%\n",
      "Epoch [93/300], Step [174/225], Training Accuracy: 97.1713%, Training Loss: 0.0822%\n",
      "Epoch [93/300], Step [175/225], Training Accuracy: 97.1875%, Training Loss: 0.0819%\n",
      "Epoch [93/300], Step [176/225], Training Accuracy: 97.1857%, Training Loss: 0.0821%\n",
      "Epoch [93/300], Step [177/225], Training Accuracy: 97.1928%, Training Loss: 0.0820%\n",
      "Epoch [93/300], Step [178/225], Training Accuracy: 97.1910%, Training Loss: 0.0821%\n",
      "Epoch [93/300], Step [179/225], Training Accuracy: 97.1980%, Training Loss: 0.0820%\n",
      "Epoch [93/300], Step [180/225], Training Accuracy: 97.2049%, Training Loss: 0.0820%\n",
      "Epoch [93/300], Step [181/225], Training Accuracy: 97.2117%, Training Loss: 0.0819%\n",
      "Epoch [93/300], Step [182/225], Training Accuracy: 97.2270%, Training Loss: 0.0815%\n",
      "Epoch [93/300], Step [183/225], Training Accuracy: 97.2421%, Training Loss: 0.0812%\n",
      "Epoch [93/300], Step [184/225], Training Accuracy: 97.2401%, Training Loss: 0.0812%\n",
      "Epoch [93/300], Step [185/225], Training Accuracy: 97.2551%, Training Loss: 0.0809%\n",
      "Epoch [93/300], Step [186/225], Training Accuracy: 97.2530%, Training Loss: 0.0807%\n",
      "Epoch [93/300], Step [187/225], Training Accuracy: 97.2510%, Training Loss: 0.0808%\n",
      "Epoch [93/300], Step [188/225], Training Accuracy: 97.2490%, Training Loss: 0.0807%\n",
      "Epoch [93/300], Step [189/225], Training Accuracy: 97.2470%, Training Loss: 0.0807%\n",
      "Epoch [93/300], Step [190/225], Training Accuracy: 97.2533%, Training Loss: 0.0806%\n",
      "Epoch [93/300], Step [191/225], Training Accuracy: 97.2595%, Training Loss: 0.0804%\n",
      "Epoch [93/300], Step [192/225], Training Accuracy: 97.2575%, Training Loss: 0.0805%\n",
      "Epoch [93/300], Step [193/225], Training Accuracy: 97.2474%, Training Loss: 0.0808%\n",
      "Epoch [93/300], Step [194/225], Training Accuracy: 97.2455%, Training Loss: 0.0807%\n",
      "Epoch [93/300], Step [195/225], Training Accuracy: 97.2356%, Training Loss: 0.0808%\n",
      "Epoch [93/300], Step [196/225], Training Accuracy: 97.2417%, Training Loss: 0.0808%\n",
      "Epoch [93/300], Step [197/225], Training Accuracy: 97.2398%, Training Loss: 0.0809%\n",
      "Epoch [93/300], Step [198/225], Training Accuracy: 97.2459%, Training Loss: 0.0808%\n",
      "Epoch [93/300], Step [199/225], Training Accuracy: 97.2519%, Training Loss: 0.0806%\n",
      "Epoch [93/300], Step [200/225], Training Accuracy: 97.2656%, Training Loss: 0.0803%\n",
      "Epoch [93/300], Step [201/225], Training Accuracy: 97.2559%, Training Loss: 0.0804%\n",
      "Epoch [93/300], Step [202/225], Training Accuracy: 97.2386%, Training Loss: 0.0808%\n",
      "Epoch [93/300], Step [203/225], Training Accuracy: 97.2368%, Training Loss: 0.0809%\n",
      "Epoch [93/300], Step [204/225], Training Accuracy: 97.2426%, Training Loss: 0.0808%\n",
      "Epoch [93/300], Step [205/225], Training Accuracy: 97.2409%, Training Loss: 0.0809%\n",
      "Epoch [93/300], Step [206/225], Training Accuracy: 97.2542%, Training Loss: 0.0806%\n",
      "Epoch [93/300], Step [207/225], Training Accuracy: 97.2675%, Training Loss: 0.0803%\n",
      "Epoch [93/300], Step [208/225], Training Accuracy: 97.2581%, Training Loss: 0.0804%\n",
      "Epoch [93/300], Step [209/225], Training Accuracy: 97.2712%, Training Loss: 0.0802%\n",
      "Epoch [93/300], Step [210/225], Training Accuracy: 97.2693%, Training Loss: 0.0803%\n",
      "Epoch [93/300], Step [211/225], Training Accuracy: 97.2601%, Training Loss: 0.0804%\n",
      "Epoch [93/300], Step [212/225], Training Accuracy: 97.2583%, Training Loss: 0.0804%\n",
      "Epoch [93/300], Step [213/225], Training Accuracy: 97.2638%, Training Loss: 0.0803%\n",
      "Epoch [93/300], Step [214/225], Training Accuracy: 97.2693%, Training Loss: 0.0803%\n",
      "Epoch [93/300], Step [215/225], Training Accuracy: 97.2747%, Training Loss: 0.0802%\n",
      "Epoch [93/300], Step [216/225], Training Accuracy: 97.2729%, Training Loss: 0.0803%\n",
      "Epoch [93/300], Step [217/225], Training Accuracy: 97.2710%, Training Loss: 0.0804%\n",
      "Epoch [93/300], Step [218/225], Training Accuracy: 97.2835%, Training Loss: 0.0803%\n",
      "Epoch [93/300], Step [219/225], Training Accuracy: 97.2959%, Training Loss: 0.0801%\n",
      "Epoch [93/300], Step [220/225], Training Accuracy: 97.3011%, Training Loss: 0.0799%\n",
      "Epoch [93/300], Step [221/225], Training Accuracy: 97.3133%, Training Loss: 0.0798%\n",
      "Epoch [93/300], Step [222/225], Training Accuracy: 97.3184%, Training Loss: 0.0797%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/300], Step [223/225], Training Accuracy: 97.3094%, Training Loss: 0.0797%\n",
      "Epoch [93/300], Step [224/225], Training Accuracy: 97.2935%, Training Loss: 0.0800%\n",
      "Epoch [93/300], Step [225/225], Training Accuracy: 97.2902%, Training Loss: 0.0800%\n",
      "Epoch [94/300], Step [1/225], Training Accuracy: 98.4375%, Training Loss: 0.0479%\n",
      "Epoch [94/300], Step [2/225], Training Accuracy: 96.8750%, Training Loss: 0.0827%\n",
      "Epoch [94/300], Step [3/225], Training Accuracy: 97.9167%, Training Loss: 0.0735%\n",
      "Epoch [94/300], Step [4/225], Training Accuracy: 98.0469%, Training Loss: 0.0692%\n",
      "Epoch [94/300], Step [5/225], Training Accuracy: 98.1250%, Training Loss: 0.0669%\n",
      "Epoch [94/300], Step [6/225], Training Accuracy: 98.1771%, Training Loss: 0.0620%\n",
      "Epoch [94/300], Step [7/225], Training Accuracy: 97.5446%, Training Loss: 0.0722%\n",
      "Epoch [94/300], Step [8/225], Training Accuracy: 97.8516%, Training Loss: 0.0722%\n",
      "Epoch [94/300], Step [9/225], Training Accuracy: 97.7431%, Training Loss: 0.0732%\n",
      "Epoch [94/300], Step [10/225], Training Accuracy: 97.9688%, Training Loss: 0.0731%\n",
      "Epoch [94/300], Step [11/225], Training Accuracy: 98.1534%, Training Loss: 0.0703%\n",
      "Epoch [94/300], Step [12/225], Training Accuracy: 98.0469%, Training Loss: 0.0685%\n",
      "Epoch [94/300], Step [13/225], Training Accuracy: 97.8365%, Training Loss: 0.0708%\n",
      "Epoch [94/300], Step [14/225], Training Accuracy: 97.8795%, Training Loss: 0.0713%\n",
      "Epoch [94/300], Step [15/225], Training Accuracy: 97.6042%, Training Loss: 0.0761%\n",
      "Epoch [94/300], Step [16/225], Training Accuracy: 97.5586%, Training Loss: 0.0765%\n",
      "Epoch [94/300], Step [17/225], Training Accuracy: 97.6103%, Training Loss: 0.0766%\n",
      "Epoch [94/300], Step [18/225], Training Accuracy: 97.4826%, Training Loss: 0.0773%\n",
      "Epoch [94/300], Step [19/225], Training Accuracy: 97.6151%, Training Loss: 0.0749%\n",
      "Epoch [94/300], Step [20/225], Training Accuracy: 97.6562%, Training Loss: 0.0730%\n",
      "Epoch [94/300], Step [21/225], Training Accuracy: 97.7679%, Training Loss: 0.0716%\n",
      "Epoch [94/300], Step [22/225], Training Accuracy: 97.6562%, Training Loss: 0.0737%\n",
      "Epoch [94/300], Step [23/225], Training Accuracy: 97.6902%, Training Loss: 0.0728%\n",
      "Epoch [94/300], Step [24/225], Training Accuracy: 97.6562%, Training Loss: 0.0734%\n",
      "Epoch [94/300], Step [25/225], Training Accuracy: 97.6250%, Training Loss: 0.0734%\n",
      "Epoch [94/300], Step [26/225], Training Accuracy: 97.5962%, Training Loss: 0.0725%\n",
      "Epoch [94/300], Step [27/225], Training Accuracy: 97.6273%, Training Loss: 0.0722%\n",
      "Epoch [94/300], Step [28/225], Training Accuracy: 97.7121%, Training Loss: 0.0712%\n",
      "Epoch [94/300], Step [29/225], Training Accuracy: 97.6293%, Training Loss: 0.0717%\n",
      "Epoch [94/300], Step [30/225], Training Accuracy: 97.5521%, Training Loss: 0.0726%\n",
      "Epoch [94/300], Step [31/225], Training Accuracy: 97.5302%, Training Loss: 0.0725%\n",
      "Epoch [94/300], Step [32/225], Training Accuracy: 97.6074%, Training Loss: 0.0713%\n",
      "Epoch [94/300], Step [33/225], Training Accuracy: 97.5852%, Training Loss: 0.0720%\n",
      "Epoch [94/300], Step [34/225], Training Accuracy: 97.5643%, Training Loss: 0.0725%\n",
      "Epoch [94/300], Step [35/225], Training Accuracy: 97.5893%, Training Loss: 0.0721%\n",
      "Epoch [94/300], Step [36/225], Training Accuracy: 97.4826%, Training Loss: 0.0727%\n",
      "Epoch [94/300], Step [37/225], Training Accuracy: 97.5084%, Training Loss: 0.0718%\n",
      "Epoch [94/300], Step [38/225], Training Accuracy: 97.3684%, Training Loss: 0.0747%\n",
      "Epoch [94/300], Step [39/225], Training Accuracy: 97.4359%, Training Loss: 0.0735%\n",
      "Epoch [94/300], Step [40/225], Training Accuracy: 97.4609%, Training Loss: 0.0730%\n",
      "Epoch [94/300], Step [41/225], Training Accuracy: 97.2942%, Training Loss: 0.0756%\n",
      "Epoch [94/300], Step [42/225], Training Accuracy: 97.2098%, Training Loss: 0.0774%\n",
      "Epoch [94/300], Step [43/225], Training Accuracy: 97.1657%, Training Loss: 0.0781%\n",
      "Epoch [94/300], Step [44/225], Training Accuracy: 97.2301%, Training Loss: 0.0771%\n",
      "Epoch [94/300], Step [45/225], Training Accuracy: 97.2222%, Training Loss: 0.0767%\n",
      "Epoch [94/300], Step [46/225], Training Accuracy: 97.2486%, Training Loss: 0.0760%\n",
      "Epoch [94/300], Step [47/225], Training Accuracy: 97.2739%, Training Loss: 0.0761%\n",
      "Epoch [94/300], Step [48/225], Training Accuracy: 97.3307%, Training Loss: 0.0750%\n",
      "Epoch [94/300], Step [49/225], Training Accuracy: 97.3533%, Training Loss: 0.0755%\n",
      "Epoch [94/300], Step [50/225], Training Accuracy: 97.3438%, Training Loss: 0.0764%\n",
      "Epoch [94/300], Step [51/225], Training Accuracy: 97.3958%, Training Loss: 0.0753%\n",
      "Epoch [94/300], Step [52/225], Training Accuracy: 97.4159%, Training Loss: 0.0750%\n",
      "Epoch [94/300], Step [53/225], Training Accuracy: 97.2877%, Training Loss: 0.0765%\n",
      "Epoch [94/300], Step [54/225], Training Accuracy: 97.3090%, Training Loss: 0.0766%\n",
      "Epoch [94/300], Step [55/225], Training Accuracy: 97.3295%, Training Loss: 0.0775%\n",
      "Epoch [94/300], Step [56/225], Training Accuracy: 97.3214%, Training Loss: 0.0778%\n",
      "Epoch [94/300], Step [57/225], Training Accuracy: 97.3136%, Training Loss: 0.0774%\n",
      "Epoch [94/300], Step [58/225], Training Accuracy: 97.3330%, Training Loss: 0.0767%\n",
      "Epoch [94/300], Step [59/225], Training Accuracy: 97.3782%, Training Loss: 0.0760%\n",
      "Epoch [94/300], Step [60/225], Training Accuracy: 97.3958%, Training Loss: 0.0759%\n",
      "Epoch [94/300], Step [61/225], Training Accuracy: 97.3361%, Training Loss: 0.0787%\n",
      "Epoch [94/300], Step [62/225], Training Accuracy: 97.3286%, Training Loss: 0.0782%\n",
      "Epoch [94/300], Step [63/225], Training Accuracy: 97.3462%, Training Loss: 0.0783%\n",
      "Epoch [94/300], Step [64/225], Training Accuracy: 97.3877%, Training Loss: 0.0776%\n",
      "Epoch [94/300], Step [65/225], Training Accuracy: 97.3798%, Training Loss: 0.0775%\n",
      "Epoch [94/300], Step [66/225], Training Accuracy: 97.3958%, Training Loss: 0.0770%\n",
      "Epoch [94/300], Step [67/225], Training Accuracy: 97.4114%, Training Loss: 0.0771%\n",
      "Epoch [94/300], Step [68/225], Training Accuracy: 97.4035%, Training Loss: 0.0768%\n",
      "Epoch [94/300], Step [69/225], Training Accuracy: 97.4185%, Training Loss: 0.0766%\n",
      "Epoch [94/300], Step [70/225], Training Accuracy: 97.4107%, Training Loss: 0.0763%\n",
      "Epoch [94/300], Step [71/225], Training Accuracy: 97.3371%, Training Loss: 0.0770%\n",
      "Epoch [94/300], Step [72/225], Training Accuracy: 97.3090%, Training Loss: 0.0773%\n",
      "Epoch [94/300], Step [73/225], Training Accuracy: 97.3031%, Training Loss: 0.0774%\n",
      "Epoch [94/300], Step [74/225], Training Accuracy: 97.3184%, Training Loss: 0.0770%\n",
      "Epoch [94/300], Step [75/225], Training Accuracy: 97.2917%, Training Loss: 0.0779%\n",
      "Epoch [94/300], Step [76/225], Training Accuracy: 97.2862%, Training Loss: 0.0782%\n",
      "Epoch [94/300], Step [77/225], Training Accuracy: 97.3214%, Training Loss: 0.0776%\n",
      "Epoch [94/300], Step [78/225], Training Accuracy: 97.3157%, Training Loss: 0.0776%\n",
      "Epoch [94/300], Step [79/225], Training Accuracy: 97.3101%, Training Loss: 0.0778%\n",
      "Epoch [94/300], Step [80/225], Training Accuracy: 97.2656%, Training Loss: 0.0786%\n",
      "Epoch [94/300], Step [81/225], Training Accuracy: 97.2608%, Training Loss: 0.0785%\n",
      "Epoch [94/300], Step [82/225], Training Accuracy: 97.2942%, Training Loss: 0.0779%\n",
      "Epoch [94/300], Step [83/225], Training Accuracy: 97.2892%, Training Loss: 0.0785%\n",
      "Epoch [94/300], Step [84/225], Training Accuracy: 97.3214%, Training Loss: 0.0779%\n",
      "Epoch [94/300], Step [85/225], Training Accuracy: 97.3162%, Training Loss: 0.0779%\n",
      "Epoch [94/300], Step [86/225], Training Accuracy: 97.3474%, Training Loss: 0.0776%\n",
      "Epoch [94/300], Step [87/225], Training Accuracy: 97.3240%, Training Loss: 0.0782%\n",
      "Epoch [94/300], Step [88/225], Training Accuracy: 97.3189%, Training Loss: 0.0783%\n",
      "Epoch [94/300], Step [89/225], Training Accuracy: 97.3490%, Training Loss: 0.0782%\n",
      "Epoch [94/300], Step [90/225], Training Accuracy: 97.3611%, Training Loss: 0.0778%\n",
      "Epoch [94/300], Step [91/225], Training Accuracy: 97.3386%, Training Loss: 0.0785%\n",
      "Epoch [94/300], Step [92/225], Training Accuracy: 97.3505%, Training Loss: 0.0782%\n",
      "Epoch [94/300], Step [93/225], Training Accuracy: 97.3622%, Training Loss: 0.0784%\n",
      "Epoch [94/300], Step [94/225], Training Accuracy: 97.3238%, Training Loss: 0.0786%\n",
      "Epoch [94/300], Step [95/225], Training Accuracy: 97.2862%, Training Loss: 0.0792%\n",
      "Epoch [94/300], Step [96/225], Training Accuracy: 97.2982%, Training Loss: 0.0791%\n",
      "Epoch [94/300], Step [97/225], Training Accuracy: 97.2938%, Training Loss: 0.0793%\n",
      "Epoch [94/300], Step [98/225], Training Accuracy: 97.2258%, Training Loss: 0.0804%\n",
      "Epoch [94/300], Step [99/225], Training Accuracy: 97.2222%, Training Loss: 0.0805%\n",
      "Epoch [94/300], Step [100/225], Training Accuracy: 97.2344%, Training Loss: 0.0804%\n",
      "Epoch [94/300], Step [101/225], Training Accuracy: 97.2463%, Training Loss: 0.0803%\n",
      "Epoch [94/300], Step [102/225], Training Accuracy: 97.2426%, Training Loss: 0.0802%\n",
      "Epoch [94/300], Step [103/225], Training Accuracy: 97.2239%, Training Loss: 0.0806%\n",
      "Epoch [94/300], Step [104/225], Training Accuracy: 97.1905%, Training Loss: 0.0809%\n",
      "Epoch [94/300], Step [105/225], Training Accuracy: 97.2173%, Training Loss: 0.0805%\n",
      "Epoch [94/300], Step [106/225], Training Accuracy: 97.1993%, Training Loss: 0.0810%\n",
      "Epoch [94/300], Step [107/225], Training Accuracy: 97.1963%, Training Loss: 0.0812%\n",
      "Epoch [94/300], Step [108/225], Training Accuracy: 97.1933%, Training Loss: 0.0811%\n",
      "Epoch [94/300], Step [109/225], Training Accuracy: 97.2190%, Training Loss: 0.0807%\n",
      "Epoch [94/300], Step [110/225], Training Accuracy: 97.2017%, Training Loss: 0.0807%\n",
      "Epoch [94/300], Step [111/225], Training Accuracy: 97.1847%, Training Loss: 0.0811%\n",
      "Epoch [94/300], Step [112/225], Training Accuracy: 97.1819%, Training Loss: 0.0810%\n",
      "Epoch [94/300], Step [113/225], Training Accuracy: 97.1930%, Training Loss: 0.0808%\n",
      "Epoch [94/300], Step [114/225], Training Accuracy: 97.2039%, Training Loss: 0.0806%\n",
      "Epoch [94/300], Step [115/225], Training Accuracy: 97.2011%, Training Loss: 0.0811%\n",
      "Epoch [94/300], Step [116/225], Training Accuracy: 97.1983%, Training Loss: 0.0810%\n",
      "Epoch [94/300], Step [117/225], Training Accuracy: 97.1822%, Training Loss: 0.0810%\n",
      "Epoch [94/300], Step [118/225], Training Accuracy: 97.1796%, Training Loss: 0.0808%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/300], Step [119/225], Training Accuracy: 97.1376%, Training Loss: 0.0811%\n",
      "Epoch [94/300], Step [120/225], Training Accuracy: 97.1615%, Training Loss: 0.0807%\n",
      "Epoch [94/300], Step [121/225], Training Accuracy: 97.1720%, Training Loss: 0.0803%\n",
      "Epoch [94/300], Step [122/225], Training Accuracy: 97.1696%, Training Loss: 0.0803%\n",
      "Epoch [94/300], Step [123/225], Training Accuracy: 97.1291%, Training Loss: 0.0806%\n",
      "Epoch [94/300], Step [124/225], Training Accuracy: 97.1396%, Training Loss: 0.0804%\n",
      "Epoch [94/300], Step [125/225], Training Accuracy: 97.1625%, Training Loss: 0.0800%\n",
      "Epoch [94/300], Step [126/225], Training Accuracy: 97.1478%, Training Loss: 0.0800%\n",
      "Epoch [94/300], Step [127/225], Training Accuracy: 97.1457%, Training Loss: 0.0798%\n",
      "Epoch [94/300], Step [128/225], Training Accuracy: 97.1313%, Training Loss: 0.0801%\n",
      "Epoch [94/300], Step [129/225], Training Accuracy: 97.0930%, Training Loss: 0.0809%\n",
      "Epoch [94/300], Step [130/225], Training Accuracy: 97.0913%, Training Loss: 0.0811%\n",
      "Epoch [94/300], Step [131/225], Training Accuracy: 97.1135%, Training Loss: 0.0806%\n",
      "Epoch [94/300], Step [132/225], Training Accuracy: 97.0881%, Training Loss: 0.0816%\n",
      "Epoch [94/300], Step [133/225], Training Accuracy: 97.0630%, Training Loss: 0.0820%\n",
      "Epoch [94/300], Step [134/225], Training Accuracy: 97.0732%, Training Loss: 0.0818%\n",
      "Epoch [94/300], Step [135/225], Training Accuracy: 97.0833%, Training Loss: 0.0815%\n",
      "Epoch [94/300], Step [136/225], Training Accuracy: 97.1048%, Training Loss: 0.0812%\n",
      "Epoch [94/300], Step [137/225], Training Accuracy: 97.0917%, Training Loss: 0.0813%\n",
      "Epoch [94/300], Step [138/225], Training Accuracy: 97.0788%, Training Loss: 0.0816%\n",
      "Epoch [94/300], Step [139/225], Training Accuracy: 97.0549%, Training Loss: 0.0818%\n",
      "Epoch [94/300], Step [140/225], Training Accuracy: 97.0536%, Training Loss: 0.0819%\n",
      "Epoch [94/300], Step [141/225], Training Accuracy: 97.0523%, Training Loss: 0.0820%\n",
      "Epoch [94/300], Step [142/225], Training Accuracy: 97.0511%, Training Loss: 0.0821%\n",
      "Epoch [94/300], Step [143/225], Training Accuracy: 97.0608%, Training Loss: 0.0820%\n",
      "Epoch [94/300], Step [144/225], Training Accuracy: 97.0595%, Training Loss: 0.0820%\n",
      "Epoch [94/300], Step [145/225], Training Accuracy: 97.0582%, Training Loss: 0.0824%\n",
      "Epoch [94/300], Step [146/225], Training Accuracy: 97.0462%, Training Loss: 0.0829%\n",
      "Epoch [94/300], Step [147/225], Training Accuracy: 97.0557%, Training Loss: 0.0827%\n",
      "Epoch [94/300], Step [148/225], Training Accuracy: 97.0545%, Training Loss: 0.0827%\n",
      "Epoch [94/300], Step [149/225], Training Accuracy: 97.0323%, Training Loss: 0.0831%\n",
      "Epoch [94/300], Step [150/225], Training Accuracy: 97.0521%, Training Loss: 0.0827%\n",
      "Epoch [94/300], Step [151/225], Training Accuracy: 97.0613%, Training Loss: 0.0825%\n",
      "Epoch [94/300], Step [152/225], Training Accuracy: 97.0600%, Training Loss: 0.0824%\n",
      "Epoch [94/300], Step [153/225], Training Accuracy: 97.0384%, Training Loss: 0.0830%\n",
      "Epoch [94/300], Step [154/225], Training Accuracy: 97.0272%, Training Loss: 0.0833%\n",
      "Epoch [94/300], Step [155/225], Training Accuracy: 97.0060%, Training Loss: 0.0835%\n",
      "Epoch [94/300], Step [156/225], Training Accuracy: 96.9651%, Training Loss: 0.0844%\n",
      "Epoch [94/300], Step [157/225], Training Accuracy: 96.9546%, Training Loss: 0.0847%\n",
      "Epoch [94/300], Step [158/225], Training Accuracy: 96.9541%, Training Loss: 0.0846%\n",
      "Epoch [94/300], Step [159/225], Training Accuracy: 96.9241%, Training Loss: 0.0848%\n",
      "Epoch [94/300], Step [160/225], Training Accuracy: 96.9238%, Training Loss: 0.0846%\n",
      "Epoch [94/300], Step [161/225], Training Accuracy: 96.9235%, Training Loss: 0.0848%\n",
      "Epoch [94/300], Step [162/225], Training Accuracy: 96.9136%, Training Loss: 0.0850%\n",
      "Epoch [94/300], Step [163/225], Training Accuracy: 96.9229%, Training Loss: 0.0848%\n",
      "Epoch [94/300], Step [164/225], Training Accuracy: 96.9322%, Training Loss: 0.0845%\n",
      "Epoch [94/300], Step [165/225], Training Accuracy: 96.9318%, Training Loss: 0.0845%\n",
      "Epoch [94/300], Step [166/225], Training Accuracy: 96.9409%, Training Loss: 0.0844%\n",
      "Epoch [94/300], Step [167/225], Training Accuracy: 96.9311%, Training Loss: 0.0849%\n",
      "Epoch [94/300], Step [168/225], Training Accuracy: 96.9122%, Training Loss: 0.0852%\n",
      "Epoch [94/300], Step [169/225], Training Accuracy: 96.9120%, Training Loss: 0.0851%\n",
      "Epoch [94/300], Step [170/225], Training Accuracy: 96.9118%, Training Loss: 0.0852%\n",
      "Epoch [94/300], Step [171/225], Training Accuracy: 96.9207%, Training Loss: 0.0851%\n",
      "Epoch [94/300], Step [172/225], Training Accuracy: 96.9295%, Training Loss: 0.0849%\n",
      "Epoch [94/300], Step [173/225], Training Accuracy: 96.9292%, Training Loss: 0.0848%\n",
      "Epoch [94/300], Step [174/225], Training Accuracy: 96.9379%, Training Loss: 0.0846%\n",
      "Epoch [94/300], Step [175/225], Training Accuracy: 96.9196%, Training Loss: 0.0849%\n",
      "Epoch [94/300], Step [176/225], Training Accuracy: 96.9283%, Training Loss: 0.0846%\n",
      "Epoch [94/300], Step [177/225], Training Accuracy: 96.9191%, Training Loss: 0.0847%\n",
      "Epoch [94/300], Step [178/225], Training Accuracy: 96.9277%, Training Loss: 0.0845%\n",
      "Epoch [94/300], Step [179/225], Training Accuracy: 96.9274%, Training Loss: 0.0846%\n",
      "Epoch [94/300], Step [180/225], Training Accuracy: 96.9271%, Training Loss: 0.0849%\n",
      "Epoch [94/300], Step [181/225], Training Accuracy: 96.9182%, Training Loss: 0.0852%\n",
      "Epoch [94/300], Step [182/225], Training Accuracy: 96.9265%, Training Loss: 0.0850%\n",
      "Epoch [94/300], Step [183/225], Training Accuracy: 96.9348%, Training Loss: 0.0848%\n",
      "Epoch [94/300], Step [184/225], Training Accuracy: 96.9175%, Training Loss: 0.0853%\n",
      "Epoch [94/300], Step [185/225], Training Accuracy: 96.9257%, Training Loss: 0.0850%\n",
      "Epoch [94/300], Step [186/225], Training Accuracy: 96.9170%, Training Loss: 0.0850%\n",
      "Epoch [94/300], Step [187/225], Training Accuracy: 96.9335%, Training Loss: 0.0847%\n",
      "Epoch [94/300], Step [188/225], Training Accuracy: 96.9332%, Training Loss: 0.0849%\n",
      "Epoch [94/300], Step [189/225], Training Accuracy: 96.9411%, Training Loss: 0.0847%\n",
      "Epoch [94/300], Step [190/225], Training Accuracy: 96.9490%, Training Loss: 0.0846%\n",
      "Epoch [94/300], Step [191/225], Training Accuracy: 96.9486%, Training Loss: 0.0846%\n",
      "Epoch [94/300], Step [192/225], Training Accuracy: 96.9564%, Training Loss: 0.0845%\n",
      "Epoch [94/300], Step [193/225], Training Accuracy: 96.9560%, Training Loss: 0.0845%\n",
      "Epoch [94/300], Step [194/225], Training Accuracy: 96.9475%, Training Loss: 0.0848%\n",
      "Epoch [94/300], Step [195/225], Training Accuracy: 96.9551%, Training Loss: 0.0846%\n",
      "Epoch [94/300], Step [196/225], Training Accuracy: 96.9627%, Training Loss: 0.0845%\n",
      "Epoch [94/300], Step [197/225], Training Accuracy: 96.9622%, Training Loss: 0.0845%\n",
      "Epoch [94/300], Step [198/225], Training Accuracy: 96.9539%, Training Loss: 0.0847%\n",
      "Epoch [94/300], Step [199/225], Training Accuracy: 96.9692%, Training Loss: 0.0844%\n",
      "Epoch [94/300], Step [200/225], Training Accuracy: 96.9844%, Training Loss: 0.0842%\n",
      "Epoch [94/300], Step [201/225], Training Accuracy: 96.9994%, Training Loss: 0.0840%\n",
      "Epoch [94/300], Step [202/225], Training Accuracy: 96.9910%, Training Loss: 0.0840%\n",
      "Epoch [94/300], Step [203/225], Training Accuracy: 96.9982%, Training Loss: 0.0841%\n",
      "Epoch [94/300], Step [204/225], Training Accuracy: 96.9975%, Training Loss: 0.0841%\n",
      "Epoch [94/300], Step [205/225], Training Accuracy: 96.9817%, Training Loss: 0.0846%\n",
      "Epoch [94/300], Step [206/225], Training Accuracy: 96.9888%, Training Loss: 0.0845%\n",
      "Epoch [94/300], Step [207/225], Training Accuracy: 96.9958%, Training Loss: 0.0844%\n",
      "Epoch [94/300], Step [208/225], Training Accuracy: 96.9877%, Training Loss: 0.0844%\n",
      "Epoch [94/300], Step [209/225], Training Accuracy: 96.9946%, Training Loss: 0.0843%\n",
      "Epoch [94/300], Step [210/225], Training Accuracy: 96.9717%, Training Loss: 0.0844%\n",
      "Epoch [94/300], Step [211/225], Training Accuracy: 96.9639%, Training Loss: 0.0844%\n",
      "Epoch [94/300], Step [212/225], Training Accuracy: 96.9634%, Training Loss: 0.0844%\n",
      "Epoch [94/300], Step [213/225], Training Accuracy: 96.9630%, Training Loss: 0.0843%\n",
      "Epoch [94/300], Step [214/225], Training Accuracy: 96.9480%, Training Loss: 0.0845%\n",
      "Epoch [94/300], Step [215/225], Training Accuracy: 96.9622%, Training Loss: 0.0844%\n",
      "Epoch [94/300], Step [216/225], Training Accuracy: 96.9473%, Training Loss: 0.0846%\n",
      "Epoch [94/300], Step [217/225], Training Accuracy: 96.9470%, Training Loss: 0.0845%\n",
      "Epoch [94/300], Step [218/225], Training Accuracy: 96.9467%, Training Loss: 0.0845%\n",
      "Epoch [94/300], Step [219/225], Training Accuracy: 96.9392%, Training Loss: 0.0845%\n",
      "Epoch [94/300], Step [220/225], Training Accuracy: 96.9389%, Training Loss: 0.0845%\n",
      "Epoch [94/300], Step [221/225], Training Accuracy: 96.9457%, Training Loss: 0.0845%\n",
      "Epoch [94/300], Step [222/225], Training Accuracy: 96.9102%, Training Loss: 0.0849%\n",
      "Epoch [94/300], Step [223/225], Training Accuracy: 96.9240%, Training Loss: 0.0847%\n",
      "Epoch [94/300], Step [224/225], Training Accuracy: 96.9308%, Training Loss: 0.0846%\n",
      "Epoch [94/300], Step [225/225], Training Accuracy: 96.9288%, Training Loss: 0.0845%\n",
      "Epoch [95/300], Step [1/225], Training Accuracy: 96.8750%, Training Loss: 0.0573%\n",
      "Epoch [95/300], Step [2/225], Training Accuracy: 96.0938%, Training Loss: 0.0752%\n",
      "Epoch [95/300], Step [3/225], Training Accuracy: 95.3125%, Training Loss: 0.0916%\n",
      "Epoch [95/300], Step [4/225], Training Accuracy: 94.9219%, Training Loss: 0.1106%\n",
      "Epoch [95/300], Step [5/225], Training Accuracy: 95.0000%, Training Loss: 0.1078%\n",
      "Epoch [95/300], Step [6/225], Training Accuracy: 95.5729%, Training Loss: 0.0994%\n",
      "Epoch [95/300], Step [7/225], Training Accuracy: 95.9821%, Training Loss: 0.0926%\n",
      "Epoch [95/300], Step [8/225], Training Accuracy: 96.4844%, Training Loss: 0.0902%\n",
      "Epoch [95/300], Step [9/225], Training Accuracy: 96.7014%, Training Loss: 0.0912%\n",
      "Epoch [95/300], Step [10/225], Training Accuracy: 96.8750%, Training Loss: 0.0917%\n",
      "Epoch [95/300], Step [11/225], Training Accuracy: 96.8750%, Training Loss: 0.0904%\n",
      "Epoch [95/300], Step [12/225], Training Accuracy: 97.0052%, Training Loss: 0.0919%\n",
      "Epoch [95/300], Step [13/225], Training Accuracy: 96.8750%, Training Loss: 0.0902%\n",
      "Epoch [95/300], Step [14/225], Training Accuracy: 96.9866%, Training Loss: 0.0876%\n",
      "Epoch [95/300], Step [15/225], Training Accuracy: 96.9792%, Training Loss: 0.0895%\n",
      "Epoch [95/300], Step [16/225], Training Accuracy: 96.9727%, Training Loss: 0.0899%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/300], Step [17/225], Training Accuracy: 96.9669%, Training Loss: 0.0890%\n",
      "Epoch [95/300], Step [18/225], Training Accuracy: 96.7882%, Training Loss: 0.0949%\n",
      "Epoch [95/300], Step [19/225], Training Accuracy: 96.7928%, Training Loss: 0.0933%\n",
      "Epoch [95/300], Step [20/225], Training Accuracy: 96.8750%, Training Loss: 0.0914%\n",
      "Epoch [95/300], Step [21/225], Training Accuracy: 97.0238%, Training Loss: 0.0878%\n",
      "Epoch [95/300], Step [22/225], Training Accuracy: 96.9460%, Training Loss: 0.0889%\n",
      "Epoch [95/300], Step [23/225], Training Accuracy: 96.8750%, Training Loss: 0.0928%\n",
      "Epoch [95/300], Step [24/225], Training Accuracy: 96.8099%, Training Loss: 0.0958%\n",
      "Epoch [95/300], Step [25/225], Training Accuracy: 96.8750%, Training Loss: 0.0953%\n",
      "Epoch [95/300], Step [26/225], Training Accuracy: 96.9952%, Training Loss: 0.0938%\n",
      "Epoch [95/300], Step [27/225], Training Accuracy: 96.9329%, Training Loss: 0.0956%\n",
      "Epoch [95/300], Step [28/225], Training Accuracy: 96.9308%, Training Loss: 0.0942%\n",
      "Epoch [95/300], Step [29/225], Training Accuracy: 97.0366%, Training Loss: 0.0920%\n",
      "Epoch [95/300], Step [30/225], Training Accuracy: 97.0312%, Training Loss: 0.0914%\n",
      "Epoch [95/300], Step [31/225], Training Accuracy: 96.9254%, Training Loss: 0.0931%\n",
      "Epoch [95/300], Step [32/225], Training Accuracy: 96.9727%, Training Loss: 0.0922%\n",
      "Epoch [95/300], Step [33/225], Training Accuracy: 97.0170%, Training Loss: 0.0926%\n",
      "Epoch [95/300], Step [34/225], Training Accuracy: 96.9669%, Training Loss: 0.0943%\n",
      "Epoch [95/300], Step [35/225], Training Accuracy: 96.8304%, Training Loss: 0.0970%\n",
      "Epoch [95/300], Step [36/225], Training Accuracy: 96.9184%, Training Loss: 0.0950%\n",
      "Epoch [95/300], Step [37/225], Training Accuracy: 96.7905%, Training Loss: 0.0982%\n",
      "Epoch [95/300], Step [38/225], Training Accuracy: 96.8339%, Training Loss: 0.0977%\n",
      "Epoch [95/300], Step [39/225], Training Accuracy: 96.8750%, Training Loss: 0.0972%\n",
      "Epoch [95/300], Step [40/225], Training Accuracy: 96.8359%, Training Loss: 0.0970%\n",
      "Epoch [95/300], Step [41/225], Training Accuracy: 96.7988%, Training Loss: 0.0974%\n",
      "Epoch [95/300], Step [42/225], Training Accuracy: 96.8006%, Training Loss: 0.0969%\n",
      "Epoch [95/300], Step [43/225], Training Accuracy: 96.6933%, Training Loss: 0.0995%\n",
      "Epoch [95/300], Step [44/225], Training Accuracy: 96.7685%, Training Loss: 0.0977%\n",
      "Epoch [95/300], Step [45/225], Training Accuracy: 96.7014%, Training Loss: 0.0981%\n",
      "Epoch [95/300], Step [46/225], Training Accuracy: 96.7731%, Training Loss: 0.0972%\n",
      "Epoch [95/300], Step [47/225], Training Accuracy: 96.7088%, Training Loss: 0.0987%\n",
      "Epoch [95/300], Step [48/225], Training Accuracy: 96.6797%, Training Loss: 0.0994%\n",
      "Epoch [95/300], Step [49/225], Training Accuracy: 96.6837%, Training Loss: 0.0992%\n",
      "Epoch [95/300], Step [50/225], Training Accuracy: 96.7188%, Training Loss: 0.0989%\n",
      "Epoch [95/300], Step [51/225], Training Accuracy: 96.7218%, Training Loss: 0.0983%\n",
      "Epoch [95/300], Step [52/225], Training Accuracy: 96.7849%, Training Loss: 0.0972%\n",
      "Epoch [95/300], Step [53/225], Training Accuracy: 96.7866%, Training Loss: 0.0975%\n",
      "Epoch [95/300], Step [54/225], Training Accuracy: 96.7882%, Training Loss: 0.0969%\n",
      "Epoch [95/300], Step [55/225], Training Accuracy: 96.6761%, Training Loss: 0.0985%\n",
      "Epoch [95/300], Step [56/225], Training Accuracy: 96.7076%, Training Loss: 0.0982%\n",
      "Epoch [95/300], Step [57/225], Training Accuracy: 96.6831%, Training Loss: 0.0989%\n",
      "Epoch [95/300], Step [58/225], Training Accuracy: 96.6595%, Training Loss: 0.0991%\n",
      "Epoch [95/300], Step [59/225], Training Accuracy: 96.6631%, Training Loss: 0.0994%\n",
      "Epoch [95/300], Step [60/225], Training Accuracy: 96.6927%, Training Loss: 0.0989%\n",
      "Epoch [95/300], Step [61/225], Training Accuracy: 96.6957%, Training Loss: 0.0983%\n",
      "Epoch [95/300], Step [62/225], Training Accuracy: 96.6734%, Training Loss: 0.0980%\n",
      "Epoch [95/300], Step [63/225], Training Accuracy: 96.6766%, Training Loss: 0.0989%\n",
      "Epoch [95/300], Step [64/225], Training Accuracy: 96.7285%, Training Loss: 0.0978%\n",
      "Epoch [95/300], Step [65/225], Training Accuracy: 96.7067%, Training Loss: 0.0978%\n",
      "Epoch [95/300], Step [66/225], Training Accuracy: 96.6146%, Training Loss: 0.1007%\n",
      "Epoch [95/300], Step [67/225], Training Accuracy: 96.5718%, Training Loss: 0.1012%\n",
      "Epoch [95/300], Step [68/225], Training Accuracy: 96.5763%, Training Loss: 0.1007%\n",
      "Epoch [95/300], Step [69/225], Training Accuracy: 96.5806%, Training Loss: 0.1009%\n",
      "Epoch [95/300], Step [70/225], Training Accuracy: 96.5848%, Training Loss: 0.1008%\n",
      "Epoch [95/300], Step [71/225], Training Accuracy: 96.5669%, Training Loss: 0.1014%\n",
      "Epoch [95/300], Step [72/225], Training Accuracy: 96.5929%, Training Loss: 0.1008%\n",
      "Epoch [95/300], Step [73/225], Training Accuracy: 96.6182%, Training Loss: 0.1014%\n",
      "Epoch [95/300], Step [74/225], Training Accuracy: 96.5794%, Training Loss: 0.1020%\n",
      "Epoch [95/300], Step [75/225], Training Accuracy: 96.5833%, Training Loss: 0.1019%\n",
      "Epoch [95/300], Step [76/225], Training Accuracy: 96.5872%, Training Loss: 0.1015%\n",
      "Epoch [95/300], Step [77/225], Training Accuracy: 96.6112%, Training Loss: 0.1012%\n",
      "Epoch [95/300], Step [78/225], Training Accuracy: 96.5946%, Training Loss: 0.1010%\n",
      "Epoch [95/300], Step [79/225], Training Accuracy: 96.6179%, Training Loss: 0.1007%\n",
      "Epoch [95/300], Step [80/225], Training Accuracy: 96.6406%, Training Loss: 0.1001%\n",
      "Epoch [95/300], Step [81/225], Training Accuracy: 96.6435%, Training Loss: 0.1006%\n",
      "Epoch [95/300], Step [82/225], Training Accuracy: 96.6845%, Training Loss: 0.0998%\n",
      "Epoch [95/300], Step [83/225], Training Accuracy: 96.6867%, Training Loss: 0.0999%\n",
      "Epoch [95/300], Step [84/225], Training Accuracy: 96.7076%, Training Loss: 0.0993%\n",
      "Epoch [95/300], Step [85/225], Training Accuracy: 96.7279%, Training Loss: 0.0988%\n",
      "Epoch [95/300], Step [86/225], Training Accuracy: 96.7115%, Training Loss: 0.0992%\n",
      "Epoch [95/300], Step [87/225], Training Accuracy: 96.7134%, Training Loss: 0.0992%\n",
      "Epoch [95/300], Step [88/225], Training Accuracy: 96.7152%, Training Loss: 0.0991%\n",
      "Epoch [95/300], Step [89/225], Training Accuracy: 96.7170%, Training Loss: 0.0987%\n",
      "Epoch [95/300], Step [90/225], Training Accuracy: 96.7188%, Training Loss: 0.0990%\n",
      "Epoch [95/300], Step [91/225], Training Accuracy: 96.7376%, Training Loss: 0.0984%\n",
      "Epoch [95/300], Step [92/225], Training Accuracy: 96.7221%, Training Loss: 0.0983%\n",
      "Epoch [95/300], Step [93/225], Training Accuracy: 96.7070%, Training Loss: 0.0984%\n",
      "Epoch [95/300], Step [94/225], Training Accuracy: 96.7088%, Training Loss: 0.0988%\n",
      "Epoch [95/300], Step [95/225], Training Accuracy: 96.7434%, Training Loss: 0.0981%\n",
      "Epoch [95/300], Step [96/225], Training Accuracy: 96.7611%, Training Loss: 0.0981%\n",
      "Epoch [95/300], Step [97/225], Training Accuracy: 96.7622%, Training Loss: 0.0975%\n",
      "Epoch [95/300], Step [98/225], Training Accuracy: 96.7315%, Training Loss: 0.0983%\n",
      "Epoch [95/300], Step [99/225], Training Accuracy: 96.7645%, Training Loss: 0.0976%\n",
      "Epoch [95/300], Step [100/225], Training Accuracy: 96.7500%, Training Loss: 0.0985%\n",
      "Epoch [95/300], Step [101/225], Training Accuracy: 96.7667%, Training Loss: 0.0980%\n",
      "Epoch [95/300], Step [102/225], Training Accuracy: 96.7831%, Training Loss: 0.0977%\n",
      "Epoch [95/300], Step [103/225], Training Accuracy: 96.7536%, Training Loss: 0.0979%\n",
      "Epoch [95/300], Step [104/225], Training Accuracy: 96.7698%, Training Loss: 0.0976%\n",
      "Epoch [95/300], Step [105/225], Training Accuracy: 96.7708%, Training Loss: 0.0978%\n",
      "Epoch [95/300], Step [106/225], Training Accuracy: 96.7866%, Training Loss: 0.0977%\n",
      "Epoch [95/300], Step [107/225], Training Accuracy: 96.7582%, Training Loss: 0.0979%\n",
      "Epoch [95/300], Step [108/225], Training Accuracy: 96.7737%, Training Loss: 0.0975%\n",
      "Epoch [95/300], Step [109/225], Training Accuracy: 96.7603%, Training Loss: 0.0976%\n",
      "Epoch [95/300], Step [110/225], Training Accuracy: 96.7898%, Training Loss: 0.0973%\n",
      "Epoch [95/300], Step [111/225], Training Accuracy: 96.7905%, Training Loss: 0.0973%\n",
      "Epoch [95/300], Step [112/225], Training Accuracy: 96.7913%, Training Loss: 0.0969%\n",
      "Epoch [95/300], Step [113/225], Training Accuracy: 96.7920%, Training Loss: 0.0972%\n",
      "Epoch [95/300], Step [114/225], Training Accuracy: 96.7928%, Training Loss: 0.0972%\n",
      "Epoch [95/300], Step [115/225], Training Accuracy: 96.8071%, Training Loss: 0.0969%\n",
      "Epoch [95/300], Step [116/225], Training Accuracy: 96.7807%, Training Loss: 0.0975%\n",
      "Epoch [95/300], Step [117/225], Training Accuracy: 96.8082%, Training Loss: 0.0968%\n",
      "Epoch [95/300], Step [118/225], Training Accuracy: 96.8220%, Training Loss: 0.0964%\n",
      "Epoch [95/300], Step [119/225], Training Accuracy: 96.8356%, Training Loss: 0.0960%\n",
      "Epoch [95/300], Step [120/225], Training Accuracy: 96.8490%, Training Loss: 0.0957%\n",
      "Epoch [95/300], Step [121/225], Training Accuracy: 96.8750%, Training Loss: 0.0951%\n",
      "Epoch [95/300], Step [122/225], Training Accuracy: 96.8622%, Training Loss: 0.0952%\n",
      "Epoch [95/300], Step [123/225], Training Accuracy: 96.8496%, Training Loss: 0.0953%\n",
      "Epoch [95/300], Step [124/225], Training Accuracy: 96.8372%, Training Loss: 0.0953%\n",
      "Epoch [95/300], Step [125/225], Training Accuracy: 96.8500%, Training Loss: 0.0949%\n",
      "Epoch [95/300], Step [126/225], Training Accuracy: 96.8750%, Training Loss: 0.0945%\n",
      "Epoch [95/300], Step [127/225], Training Accuracy: 96.8996%, Training Loss: 0.0940%\n",
      "Epoch [95/300], Step [128/225], Training Accuracy: 96.9116%, Training Loss: 0.0943%\n",
      "Epoch [95/300], Step [129/225], Training Accuracy: 96.9234%, Training Loss: 0.0942%\n",
      "Epoch [95/300], Step [130/225], Training Accuracy: 96.9351%, Training Loss: 0.0940%\n",
      "Epoch [95/300], Step [131/225], Training Accuracy: 96.9585%, Training Loss: 0.0935%\n",
      "Epoch [95/300], Step [132/225], Training Accuracy: 96.9342%, Training Loss: 0.0940%\n",
      "Epoch [95/300], Step [133/225], Training Accuracy: 96.9455%, Training Loss: 0.0939%\n",
      "Epoch [95/300], Step [134/225], Training Accuracy: 96.9566%, Training Loss: 0.0937%\n",
      "Epoch [95/300], Step [135/225], Training Accuracy: 96.9560%, Training Loss: 0.0936%\n",
      "Epoch [95/300], Step [136/225], Training Accuracy: 96.9439%, Training Loss: 0.0938%\n",
      "Epoch [95/300], Step [137/225], Training Accuracy: 96.9662%, Training Loss: 0.0933%\n",
      "Epoch [95/300], Step [138/225], Training Accuracy: 96.9316%, Training Loss: 0.0935%\n",
      "Epoch [95/300], Step [139/225], Training Accuracy: 96.9087%, Training Loss: 0.0933%\n",
      "Epoch [95/300], Step [140/225], Training Accuracy: 96.9085%, Training Loss: 0.0932%\n",
      "Epoch [95/300], Step [141/225], Training Accuracy: 96.8861%, Training Loss: 0.0934%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/300], Step [142/225], Training Accuracy: 96.9080%, Training Loss: 0.0931%\n",
      "Epoch [95/300], Step [143/225], Training Accuracy: 96.9296%, Training Loss: 0.0929%\n",
      "Epoch [95/300], Step [144/225], Training Accuracy: 96.9510%, Training Loss: 0.0925%\n",
      "Epoch [95/300], Step [145/225], Training Accuracy: 96.9504%, Training Loss: 0.0925%\n",
      "Epoch [95/300], Step [146/225], Training Accuracy: 96.9713%, Training Loss: 0.0922%\n",
      "Epoch [95/300], Step [147/225], Training Accuracy: 96.9600%, Training Loss: 0.0922%\n",
      "Epoch [95/300], Step [148/225], Training Accuracy: 96.9806%, Training Loss: 0.0918%\n",
      "Epoch [95/300], Step [149/225], Training Accuracy: 97.0008%, Training Loss: 0.0915%\n",
      "Epoch [95/300], Step [150/225], Training Accuracy: 97.0104%, Training Loss: 0.0912%\n",
      "Epoch [95/300], Step [151/225], Training Accuracy: 97.0199%, Training Loss: 0.0910%\n",
      "Epoch [95/300], Step [152/225], Training Accuracy: 97.0292%, Training Loss: 0.0909%\n",
      "Epoch [95/300], Step [153/225], Training Accuracy: 97.0078%, Training Loss: 0.0911%\n",
      "Epoch [95/300], Step [154/225], Training Accuracy: 97.0170%, Training Loss: 0.0908%\n",
      "Epoch [95/300], Step [155/225], Training Accuracy: 97.0161%, Training Loss: 0.0913%\n",
      "Epoch [95/300], Step [156/225], Training Accuracy: 97.0052%, Training Loss: 0.0914%\n",
      "Epoch [95/300], Step [157/225], Training Accuracy: 96.9944%, Training Loss: 0.0916%\n",
      "Epoch [95/300], Step [158/225], Training Accuracy: 97.0036%, Training Loss: 0.0913%\n",
      "Epoch [95/300], Step [159/225], Training Accuracy: 96.9929%, Training Loss: 0.0913%\n",
      "Epoch [95/300], Step [160/225], Training Accuracy: 97.0020%, Training Loss: 0.0910%\n",
      "Epoch [95/300], Step [161/225], Training Accuracy: 97.0109%, Training Loss: 0.0907%\n",
      "Epoch [95/300], Step [162/225], Training Accuracy: 97.0100%, Training Loss: 0.0907%\n",
      "Epoch [95/300], Step [163/225], Training Accuracy: 97.0092%, Training Loss: 0.0905%\n",
      "Epoch [95/300], Step [164/225], Training Accuracy: 97.0274%, Training Loss: 0.0902%\n",
      "Epoch [95/300], Step [165/225], Training Accuracy: 97.0170%, Training Loss: 0.0904%\n",
      "Epoch [95/300], Step [166/225], Training Accuracy: 96.9880%, Training Loss: 0.0911%\n",
      "Epoch [95/300], Step [167/225], Training Accuracy: 97.0060%, Training Loss: 0.0907%\n",
      "Epoch [95/300], Step [168/225], Training Accuracy: 97.0238%, Training Loss: 0.0903%\n",
      "Epoch [95/300], Step [169/225], Training Accuracy: 97.0414%, Training Loss: 0.0900%\n",
      "Epoch [95/300], Step [170/225], Training Accuracy: 97.0404%, Training Loss: 0.0901%\n",
      "Epoch [95/300], Step [171/225], Training Accuracy: 97.0486%, Training Loss: 0.0899%\n",
      "Epoch [95/300], Step [172/225], Training Accuracy: 97.0385%, Training Loss: 0.0900%\n",
      "Epoch [95/300], Step [173/225], Training Accuracy: 97.0285%, Training Loss: 0.0901%\n",
      "Epoch [95/300], Step [174/225], Training Accuracy: 97.0366%, Training Loss: 0.0899%\n",
      "Epoch [95/300], Step [175/225], Training Accuracy: 97.0357%, Training Loss: 0.0897%\n",
      "Epoch [95/300], Step [176/225], Training Accuracy: 97.0170%, Training Loss: 0.0900%\n",
      "Epoch [95/300], Step [177/225], Training Accuracy: 97.0339%, Training Loss: 0.0898%\n",
      "Epoch [95/300], Step [178/225], Training Accuracy: 97.0418%, Training Loss: 0.0896%\n",
      "Epoch [95/300], Step [179/225], Training Accuracy: 97.0321%, Training Loss: 0.0896%\n",
      "Epoch [95/300], Step [180/225], Training Accuracy: 97.0399%, Training Loss: 0.0894%\n",
      "Epoch [95/300], Step [181/225], Training Accuracy: 97.0563%, Training Loss: 0.0891%\n",
      "Epoch [95/300], Step [182/225], Training Accuracy: 97.0639%, Training Loss: 0.0891%\n",
      "Epoch [95/300], Step [183/225], Training Accuracy: 97.0714%, Training Loss: 0.0890%\n",
      "Epoch [95/300], Step [184/225], Training Accuracy: 97.0618%, Training Loss: 0.0890%\n",
      "Epoch [95/300], Step [185/225], Training Accuracy: 97.0777%, Training Loss: 0.0889%\n",
      "Epoch [95/300], Step [186/225], Training Accuracy: 97.0766%, Training Loss: 0.0890%\n",
      "Epoch [95/300], Step [187/225], Training Accuracy: 97.0672%, Training Loss: 0.0889%\n",
      "Epoch [95/300], Step [188/225], Training Accuracy: 97.0662%, Training Loss: 0.0893%\n",
      "Epoch [95/300], Step [189/225], Training Accuracy: 97.0734%, Training Loss: 0.0892%\n",
      "Epoch [95/300], Step [190/225], Training Accuracy: 97.0641%, Training Loss: 0.0893%\n",
      "Epoch [95/300], Step [191/225], Training Accuracy: 97.0632%, Training Loss: 0.0892%\n",
      "Epoch [95/300], Step [192/225], Training Accuracy: 97.0703%, Training Loss: 0.0890%\n",
      "Epoch [95/300], Step [193/225], Training Accuracy: 97.0693%, Training Loss: 0.0890%\n",
      "Epoch [95/300], Step [194/225], Training Accuracy: 97.0764%, Training Loss: 0.0889%\n",
      "Epoch [95/300], Step [195/225], Training Accuracy: 97.0753%, Training Loss: 0.0888%\n",
      "Epoch [95/300], Step [196/225], Training Accuracy: 97.0902%, Training Loss: 0.0885%\n",
      "Epoch [95/300], Step [197/225], Training Accuracy: 97.0812%, Training Loss: 0.0886%\n",
      "Epoch [95/300], Step [198/225], Training Accuracy: 97.0723%, Training Loss: 0.0889%\n",
      "Epoch [95/300], Step [199/225], Training Accuracy: 97.0870%, Training Loss: 0.0887%\n",
      "Epoch [95/300], Step [200/225], Training Accuracy: 97.0859%, Training Loss: 0.0887%\n",
      "Epoch [95/300], Step [201/225], Training Accuracy: 97.0771%, Training Loss: 0.0886%\n",
      "Epoch [95/300], Step [202/225], Training Accuracy: 97.0761%, Training Loss: 0.0887%\n",
      "Epoch [95/300], Step [203/225], Training Accuracy: 97.0828%, Training Loss: 0.0885%\n",
      "Epoch [95/300], Step [204/225], Training Accuracy: 97.0588%, Training Loss: 0.0886%\n",
      "Epoch [95/300], Step [205/225], Training Accuracy: 97.0579%, Training Loss: 0.0884%\n",
      "Epoch [95/300], Step [206/225], Training Accuracy: 97.0646%, Training Loss: 0.0883%\n",
      "Epoch [95/300], Step [207/225], Training Accuracy: 97.0788%, Training Loss: 0.0880%\n",
      "Epoch [95/300], Step [208/225], Training Accuracy: 97.0778%, Training Loss: 0.0880%\n",
      "Epoch [95/300], Step [209/225], Training Accuracy: 97.0843%, Training Loss: 0.0880%\n",
      "Epoch [95/300], Step [210/225], Training Accuracy: 97.0833%, Training Loss: 0.0879%\n",
      "Epoch [95/300], Step [211/225], Training Accuracy: 97.0823%, Training Loss: 0.0880%\n",
      "Epoch [95/300], Step [212/225], Training Accuracy: 97.0961%, Training Loss: 0.0877%\n",
      "Epoch [95/300], Step [213/225], Training Accuracy: 97.0951%, Training Loss: 0.0876%\n",
      "Epoch [95/300], Step [214/225], Training Accuracy: 97.0867%, Training Loss: 0.0878%\n",
      "Epoch [95/300], Step [215/225], Training Accuracy: 97.0930%, Training Loss: 0.0877%\n",
      "Epoch [95/300], Step [216/225], Training Accuracy: 97.0920%, Training Loss: 0.0877%\n",
      "Epoch [95/300], Step [217/225], Training Accuracy: 97.0910%, Training Loss: 0.0876%\n",
      "Epoch [95/300], Step [218/225], Training Accuracy: 97.1044%, Training Loss: 0.0874%\n",
      "Epoch [95/300], Step [219/225], Training Accuracy: 97.0962%, Training Loss: 0.0875%\n",
      "Epoch [95/300], Step [220/225], Training Accuracy: 97.0881%, Training Loss: 0.0874%\n",
      "Epoch [95/300], Step [221/225], Training Accuracy: 97.0800%, Training Loss: 0.0875%\n",
      "Epoch [95/300], Step [222/225], Training Accuracy: 97.0721%, Training Loss: 0.0875%\n",
      "Epoch [95/300], Step [223/225], Training Accuracy: 97.0572%, Training Loss: 0.0878%\n",
      "Epoch [95/300], Step [224/225], Training Accuracy: 97.0564%, Training Loss: 0.0878%\n",
      "Epoch [95/300], Step [225/225], Training Accuracy: 97.0539%, Training Loss: 0.0877%\n",
      "Epoch [96/300], Step [1/225], Training Accuracy: 98.4375%, Training Loss: 0.0632%\n",
      "Epoch [96/300], Step [2/225], Training Accuracy: 97.6562%, Training Loss: 0.0816%\n",
      "Epoch [96/300], Step [3/225], Training Accuracy: 98.4375%, Training Loss: 0.0731%\n",
      "Epoch [96/300], Step [4/225], Training Accuracy: 98.0469%, Training Loss: 0.0793%\n",
      "Epoch [96/300], Step [5/225], Training Accuracy: 98.1250%, Training Loss: 0.0717%\n",
      "Epoch [96/300], Step [6/225], Training Accuracy: 98.1771%, Training Loss: 0.0685%\n",
      "Epoch [96/300], Step [7/225], Training Accuracy: 97.7679%, Training Loss: 0.0749%\n",
      "Epoch [96/300], Step [8/225], Training Accuracy: 98.0469%, Training Loss: 0.0716%\n",
      "Epoch [96/300], Step [9/225], Training Accuracy: 98.0903%, Training Loss: 0.0683%\n",
      "Epoch [96/300], Step [10/225], Training Accuracy: 97.8125%, Training Loss: 0.0689%\n",
      "Epoch [96/300], Step [11/225], Training Accuracy: 97.7273%, Training Loss: 0.0708%\n",
      "Epoch [96/300], Step [12/225], Training Accuracy: 97.3958%, Training Loss: 0.0737%\n",
      "Epoch [96/300], Step [13/225], Training Accuracy: 97.3558%, Training Loss: 0.0735%\n",
      "Epoch [96/300], Step [14/225], Training Accuracy: 97.3214%, Training Loss: 0.0777%\n",
      "Epoch [96/300], Step [15/225], Training Accuracy: 97.5000%, Training Loss: 0.0739%\n",
      "Epoch [96/300], Step [16/225], Training Accuracy: 97.4609%, Training Loss: 0.0746%\n",
      "Epoch [96/300], Step [17/225], Training Accuracy: 97.3346%, Training Loss: 0.0783%\n",
      "Epoch [96/300], Step [18/225], Training Accuracy: 97.4826%, Training Loss: 0.0767%\n",
      "Epoch [96/300], Step [19/225], Training Accuracy: 97.5329%, Training Loss: 0.0747%\n",
      "Epoch [96/300], Step [20/225], Training Accuracy: 97.4219%, Training Loss: 0.0753%\n",
      "Epoch [96/300], Step [21/225], Training Accuracy: 97.4702%, Training Loss: 0.0742%\n",
      "Epoch [96/300], Step [22/225], Training Accuracy: 97.4432%, Training Loss: 0.0734%\n",
      "Epoch [96/300], Step [23/225], Training Accuracy: 97.4185%, Training Loss: 0.0751%\n",
      "Epoch [96/300], Step [24/225], Training Accuracy: 97.3307%, Training Loss: 0.0761%\n",
      "Epoch [96/300], Step [25/225], Training Accuracy: 97.3750%, Training Loss: 0.0772%\n",
      "Epoch [96/300], Step [26/225], Training Accuracy: 97.3558%, Training Loss: 0.0771%\n",
      "Epoch [96/300], Step [27/225], Training Accuracy: 97.2801%, Training Loss: 0.0786%\n",
      "Epoch [96/300], Step [28/225], Training Accuracy: 97.1540%, Training Loss: 0.0833%\n",
      "Epoch [96/300], Step [29/225], Training Accuracy: 97.1983%, Training Loss: 0.0824%\n",
      "Epoch [96/300], Step [30/225], Training Accuracy: 97.1354%, Training Loss: 0.0834%\n",
      "Epoch [96/300], Step [31/225], Training Accuracy: 97.1774%, Training Loss: 0.0832%\n",
      "Epoch [96/300], Step [32/225], Training Accuracy: 97.2656%, Training Loss: 0.0817%\n",
      "Epoch [96/300], Step [33/225], Training Accuracy: 97.3485%, Training Loss: 0.0797%\n",
      "Epoch [96/300], Step [34/225], Training Accuracy: 97.2886%, Training Loss: 0.0815%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/300], Step [35/225], Training Accuracy: 97.2768%, Training Loss: 0.0819%\n",
      "Epoch [96/300], Step [36/225], Training Accuracy: 97.3090%, Training Loss: 0.0815%\n",
      "Epoch [96/300], Step [37/225], Training Accuracy: 97.3395%, Training Loss: 0.0809%\n",
      "Epoch [96/300], Step [38/225], Training Accuracy: 97.2451%, Training Loss: 0.0811%\n",
      "Epoch [96/300], Step [39/225], Training Accuracy: 97.2356%, Training Loss: 0.0822%\n",
      "Epoch [96/300], Step [40/225], Training Accuracy: 97.2266%, Training Loss: 0.0819%\n",
      "Epoch [96/300], Step [41/225], Training Accuracy: 97.1799%, Training Loss: 0.0829%\n",
      "Epoch [96/300], Step [42/225], Training Accuracy: 97.1726%, Training Loss: 0.0823%\n",
      "Epoch [96/300], Step [43/225], Training Accuracy: 97.2020%, Training Loss: 0.0817%\n",
      "Epoch [96/300], Step [44/225], Training Accuracy: 97.2301%, Training Loss: 0.0812%\n",
      "Epoch [96/300], Step [45/225], Training Accuracy: 97.1875%, Training Loss: 0.0808%\n",
      "Epoch [96/300], Step [46/225], Training Accuracy: 97.1807%, Training Loss: 0.0814%\n",
      "Epoch [96/300], Step [47/225], Training Accuracy: 97.1077%, Training Loss: 0.0826%\n",
      "Epoch [96/300], Step [48/225], Training Accuracy: 97.1354%, Training Loss: 0.0819%\n",
      "Epoch [96/300], Step [49/225], Training Accuracy: 97.0663%, Training Loss: 0.0833%\n",
      "Epoch [96/300], Step [50/225], Training Accuracy: 97.0938%, Training Loss: 0.0827%\n",
      "Epoch [96/300], Step [51/225], Training Accuracy: 97.1507%, Training Loss: 0.0814%\n",
      "Epoch [96/300], Step [52/225], Training Accuracy: 97.1755%, Training Loss: 0.0805%\n",
      "Epoch [96/300], Step [53/225], Training Accuracy: 97.2288%, Training Loss: 0.0794%\n",
      "Epoch [96/300], Step [54/225], Training Accuracy: 97.2222%, Training Loss: 0.0794%\n",
      "Epoch [96/300], Step [55/225], Training Accuracy: 97.1875%, Training Loss: 0.0795%\n",
      "Epoch [96/300], Step [56/225], Training Accuracy: 97.2098%, Training Loss: 0.0793%\n",
      "Epoch [96/300], Step [57/225], Training Accuracy: 97.1217%, Training Loss: 0.0811%\n",
      "Epoch [96/300], Step [58/225], Training Accuracy: 97.1713%, Training Loss: 0.0803%\n",
      "Epoch [96/300], Step [59/225], Training Accuracy: 97.1133%, Training Loss: 0.0820%\n",
      "Epoch [96/300], Step [60/225], Training Accuracy: 97.0312%, Training Loss: 0.0831%\n",
      "Epoch [96/300], Step [61/225], Training Accuracy: 97.0543%, Training Loss: 0.0829%\n",
      "Epoch [96/300], Step [62/225], Training Accuracy: 96.9758%, Training Loss: 0.0843%\n",
      "Epoch [96/300], Step [63/225], Training Accuracy: 96.9742%, Training Loss: 0.0849%\n",
      "Epoch [96/300], Step [64/225], Training Accuracy: 96.9727%, Training Loss: 0.0844%\n",
      "Epoch [96/300], Step [65/225], Training Accuracy: 97.0192%, Training Loss: 0.0836%\n",
      "Epoch [96/300], Step [66/225], Training Accuracy: 97.0407%, Training Loss: 0.0834%\n",
      "Epoch [96/300], Step [67/225], Training Accuracy: 97.0849%, Training Loss: 0.0825%\n",
      "Epoch [96/300], Step [68/225], Training Accuracy: 97.1048%, Training Loss: 0.0820%\n",
      "Epoch [96/300], Step [69/225], Training Accuracy: 97.0788%, Training Loss: 0.0820%\n",
      "Epoch [96/300], Step [70/225], Training Accuracy: 97.1205%, Training Loss: 0.0814%\n",
      "Epoch [96/300], Step [71/225], Training Accuracy: 97.1391%, Training Loss: 0.0815%\n",
      "Epoch [96/300], Step [72/225], Training Accuracy: 97.1137%, Training Loss: 0.0825%\n",
      "Epoch [96/300], Step [73/225], Training Accuracy: 97.0676%, Training Loss: 0.0829%\n",
      "Epoch [96/300], Step [74/225], Training Accuracy: 97.0439%, Training Loss: 0.0832%\n",
      "Epoch [96/300], Step [75/225], Training Accuracy: 96.9792%, Training Loss: 0.0839%\n",
      "Epoch [96/300], Step [76/225], Training Accuracy: 96.9572%, Training Loss: 0.0851%\n",
      "Epoch [96/300], Step [77/225], Training Accuracy: 96.9359%, Training Loss: 0.0854%\n",
      "Epoch [96/300], Step [78/225], Training Accuracy: 96.8950%, Training Loss: 0.0860%\n",
      "Epoch [96/300], Step [79/225], Training Accuracy: 96.8552%, Training Loss: 0.0866%\n",
      "Epoch [96/300], Step [80/225], Training Accuracy: 96.7969%, Training Loss: 0.0869%\n",
      "Epoch [96/300], Step [81/225], Training Accuracy: 96.8171%, Training Loss: 0.0865%\n",
      "Epoch [96/300], Step [82/225], Training Accuracy: 96.8559%, Training Loss: 0.0860%\n",
      "Epoch [96/300], Step [83/225], Training Accuracy: 96.7809%, Training Loss: 0.0871%\n",
      "Epoch [96/300], Step [84/225], Training Accuracy: 96.8006%, Training Loss: 0.0868%\n",
      "Epoch [96/300], Step [85/225], Training Accuracy: 96.8015%, Training Loss: 0.0868%\n",
      "Epoch [96/300], Step [86/225], Training Accuracy: 96.8023%, Training Loss: 0.0879%\n",
      "Epoch [96/300], Step [87/225], Training Accuracy: 96.8211%, Training Loss: 0.0876%\n",
      "Epoch [96/300], Step [88/225], Training Accuracy: 96.8040%, Training Loss: 0.0875%\n",
      "Epoch [96/300], Step [89/225], Training Accuracy: 96.8223%, Training Loss: 0.0873%\n",
      "Epoch [96/300], Step [90/225], Training Accuracy: 96.8229%, Training Loss: 0.0871%\n",
      "Epoch [96/300], Step [91/225], Training Accuracy: 96.8407%, Training Loss: 0.0868%\n",
      "Epoch [96/300], Step [92/225], Training Accuracy: 96.8580%, Training Loss: 0.0867%\n",
      "Epoch [96/300], Step [93/225], Training Accuracy: 96.8414%, Training Loss: 0.0870%\n",
      "Epoch [96/300], Step [94/225], Training Accuracy: 96.8251%, Training Loss: 0.0873%\n",
      "Epoch [96/300], Step [95/225], Training Accuracy: 96.8421%, Training Loss: 0.0867%\n",
      "Epoch [96/300], Step [96/225], Training Accuracy: 96.8262%, Training Loss: 0.0869%\n",
      "Epoch [96/300], Step [97/225], Training Accuracy: 96.8267%, Training Loss: 0.0871%\n",
      "Epoch [96/300], Step [98/225], Training Accuracy: 96.8112%, Training Loss: 0.0873%\n",
      "Epoch [96/300], Step [99/225], Training Accuracy: 96.7803%, Training Loss: 0.0878%\n",
      "Epoch [96/300], Step [100/225], Training Accuracy: 96.8125%, Training Loss: 0.0873%\n",
      "Epoch [96/300], Step [101/225], Training Accuracy: 96.8131%, Training Loss: 0.0873%\n",
      "Epoch [96/300], Step [102/225], Training Accuracy: 96.8444%, Training Loss: 0.0872%\n",
      "Epoch [96/300], Step [103/225], Training Accuracy: 96.8750%, Training Loss: 0.0866%\n",
      "Epoch [96/300], Step [104/225], Training Accuracy: 96.9050%, Training Loss: 0.0861%\n",
      "Epoch [96/300], Step [105/225], Training Accuracy: 96.9048%, Training Loss: 0.0861%\n",
      "Epoch [96/300], Step [106/225], Training Accuracy: 96.9045%, Training Loss: 0.0859%\n",
      "Epoch [96/300], Step [107/225], Training Accuracy: 96.9188%, Training Loss: 0.0855%\n",
      "Epoch [96/300], Step [108/225], Training Accuracy: 96.9473%, Training Loss: 0.0849%\n",
      "Epoch [96/300], Step [109/225], Training Accuracy: 96.9467%, Training Loss: 0.0849%\n",
      "Epoch [96/300], Step [110/225], Training Accuracy: 96.9602%, Training Loss: 0.0850%\n",
      "Epoch [96/300], Step [111/225], Training Accuracy: 96.9735%, Training Loss: 0.0848%\n",
      "Epoch [96/300], Step [112/225], Training Accuracy: 96.9866%, Training Loss: 0.0847%\n",
      "Epoch [96/300], Step [113/225], Training Accuracy: 96.9994%, Training Loss: 0.0848%\n",
      "Epoch [96/300], Step [114/225], Training Accuracy: 96.9984%, Training Loss: 0.0847%\n",
      "Epoch [96/300], Step [115/225], Training Accuracy: 96.9973%, Training Loss: 0.0846%\n",
      "Epoch [96/300], Step [116/225], Training Accuracy: 96.9962%, Training Loss: 0.0848%\n",
      "Epoch [96/300], Step [117/225], Training Accuracy: 97.0085%, Training Loss: 0.0846%\n",
      "Epoch [96/300], Step [118/225], Training Accuracy: 97.0207%, Training Loss: 0.0848%\n",
      "Epoch [96/300], Step [119/225], Training Accuracy: 97.0063%, Training Loss: 0.0850%\n",
      "Epoch [96/300], Step [120/225], Training Accuracy: 97.0182%, Training Loss: 0.0849%\n",
      "Epoch [96/300], Step [121/225], Training Accuracy: 97.0429%, Training Loss: 0.0846%\n",
      "Epoch [96/300], Step [122/225], Training Accuracy: 97.0543%, Training Loss: 0.0844%\n",
      "Epoch [96/300], Step [123/225], Training Accuracy: 97.0783%, Training Loss: 0.0840%\n",
      "Epoch [96/300], Step [124/225], Training Accuracy: 97.1018%, Training Loss: 0.0835%\n",
      "Epoch [96/300], Step [125/225], Training Accuracy: 97.0625%, Training Loss: 0.0839%\n",
      "Epoch [96/300], Step [126/225], Training Accuracy: 97.0734%, Training Loss: 0.0838%\n",
      "Epoch [96/300], Step [127/225], Training Accuracy: 97.0719%, Training Loss: 0.0838%\n",
      "Epoch [96/300], Step [128/225], Training Accuracy: 97.0703%, Training Loss: 0.0838%\n",
      "Epoch [96/300], Step [129/225], Training Accuracy: 97.0446%, Training Loss: 0.0841%\n",
      "Epoch [96/300], Step [130/225], Training Accuracy: 97.0312%, Training Loss: 0.0846%\n",
      "Epoch [96/300], Step [131/225], Training Accuracy: 97.0539%, Training Loss: 0.0840%\n",
      "Epoch [96/300], Step [132/225], Training Accuracy: 97.0526%, Training Loss: 0.0840%\n",
      "Epoch [96/300], Step [133/225], Training Accuracy: 97.0747%, Training Loss: 0.0836%\n",
      "Epoch [96/300], Step [134/225], Training Accuracy: 97.0965%, Training Loss: 0.0832%\n",
      "Epoch [96/300], Step [135/225], Training Accuracy: 97.1181%, Training Loss: 0.0829%\n",
      "Epoch [96/300], Step [136/225], Training Accuracy: 97.1278%, Training Loss: 0.0829%\n",
      "Epoch [96/300], Step [137/225], Training Accuracy: 97.1145%, Training Loss: 0.0831%\n",
      "Epoch [96/300], Step [138/225], Training Accuracy: 97.1241%, Training Loss: 0.0828%\n",
      "Epoch [96/300], Step [139/225], Training Accuracy: 97.1111%, Training Loss: 0.0828%\n",
      "Epoch [96/300], Step [140/225], Training Accuracy: 97.1317%, Training Loss: 0.0827%\n",
      "Epoch [96/300], Step [141/225], Training Accuracy: 97.1188%, Training Loss: 0.0832%\n",
      "Epoch [96/300], Step [142/225], Training Accuracy: 97.1171%, Training Loss: 0.0829%\n",
      "Epoch [96/300], Step [143/225], Training Accuracy: 97.1263%, Training Loss: 0.0827%\n",
      "Epoch [96/300], Step [144/225], Training Accuracy: 97.0812%, Training Loss: 0.0831%\n",
      "Epoch [96/300], Step [145/225], Training Accuracy: 97.1013%, Training Loss: 0.0827%\n",
      "Epoch [96/300], Step [146/225], Training Accuracy: 97.1211%, Training Loss: 0.0824%\n",
      "Epoch [96/300], Step [147/225], Training Accuracy: 97.1301%, Training Loss: 0.0822%\n",
      "Epoch [96/300], Step [148/225], Training Accuracy: 97.1284%, Training Loss: 0.0822%\n",
      "Epoch [96/300], Step [149/225], Training Accuracy: 97.1372%, Training Loss: 0.0823%\n",
      "Epoch [96/300], Step [150/225], Training Accuracy: 97.1458%, Training Loss: 0.0820%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/300], Step [151/225], Training Accuracy: 97.1647%, Training Loss: 0.0818%\n",
      "Epoch [96/300], Step [152/225], Training Accuracy: 97.1731%, Training Loss: 0.0815%\n",
      "Epoch [96/300], Step [153/225], Training Accuracy: 97.1712%, Training Loss: 0.0814%\n",
      "Epoch [96/300], Step [154/225], Training Accuracy: 97.1794%, Training Loss: 0.0813%\n",
      "Epoch [96/300], Step [155/225], Training Accuracy: 97.1875%, Training Loss: 0.0810%\n",
      "Epoch [96/300], Step [156/225], Training Accuracy: 97.1554%, Training Loss: 0.0812%\n",
      "Epoch [96/300], Step [157/225], Training Accuracy: 97.1537%, Training Loss: 0.0812%\n",
      "Epoch [96/300], Step [158/225], Training Accuracy: 97.1717%, Training Loss: 0.0808%\n",
      "Epoch [96/300], Step [159/225], Training Accuracy: 97.1796%, Training Loss: 0.0806%\n",
      "Epoch [96/300], Step [160/225], Training Accuracy: 97.1777%, Training Loss: 0.0806%\n",
      "Epoch [96/300], Step [161/225], Training Accuracy: 97.1953%, Training Loss: 0.0803%\n",
      "Epoch [96/300], Step [162/225], Training Accuracy: 97.1740%, Training Loss: 0.0805%\n",
      "Epoch [96/300], Step [163/225], Training Accuracy: 97.1626%, Training Loss: 0.0807%\n",
      "Epoch [96/300], Step [164/225], Training Accuracy: 97.1608%, Training Loss: 0.0808%\n",
      "Epoch [96/300], Step [165/225], Training Accuracy: 97.1780%, Training Loss: 0.0807%\n",
      "Epoch [96/300], Step [166/225], Training Accuracy: 97.1950%, Training Loss: 0.0804%\n",
      "Epoch [96/300], Step [167/225], Training Accuracy: 97.2025%, Training Loss: 0.0803%\n",
      "Epoch [96/300], Step [168/225], Training Accuracy: 97.2098%, Training Loss: 0.0801%\n",
      "Epoch [96/300], Step [169/225], Training Accuracy: 97.2263%, Training Loss: 0.0799%\n",
      "Epoch [96/300], Step [170/225], Training Accuracy: 97.2335%, Training Loss: 0.0798%\n",
      "Epoch [96/300], Step [171/225], Training Accuracy: 97.2131%, Training Loss: 0.0800%\n",
      "Epoch [96/300], Step [172/225], Training Accuracy: 97.2111%, Training Loss: 0.0799%\n",
      "Epoch [96/300], Step [173/225], Training Accuracy: 97.2182%, Training Loss: 0.0798%\n",
      "Epoch [96/300], Step [174/225], Training Accuracy: 97.2252%, Training Loss: 0.0797%\n",
      "Epoch [96/300], Step [175/225], Training Accuracy: 97.2411%, Training Loss: 0.0794%\n",
      "Epoch [96/300], Step [176/225], Training Accuracy: 97.2567%, Training Loss: 0.0792%\n",
      "Epoch [96/300], Step [177/225], Training Accuracy: 97.2722%, Training Loss: 0.0788%\n",
      "Epoch [96/300], Step [178/225], Training Accuracy: 97.2700%, Training Loss: 0.0788%\n",
      "Epoch [96/300], Step [179/225], Training Accuracy: 97.2765%, Training Loss: 0.0787%\n",
      "Epoch [96/300], Step [180/225], Training Accuracy: 97.2917%, Training Loss: 0.0785%\n",
      "Epoch [96/300], Step [181/225], Training Accuracy: 97.2894%, Training Loss: 0.0785%\n",
      "Epoch [96/300], Step [182/225], Training Accuracy: 97.2785%, Training Loss: 0.0786%\n",
      "Epoch [96/300], Step [183/225], Training Accuracy: 97.2848%, Training Loss: 0.0785%\n",
      "Epoch [96/300], Step [184/225], Training Accuracy: 97.2911%, Training Loss: 0.0783%\n",
      "Epoch [96/300], Step [185/225], Training Accuracy: 97.2804%, Training Loss: 0.0784%\n",
      "Epoch [96/300], Step [186/225], Training Accuracy: 97.2866%, Training Loss: 0.0783%\n",
      "Epoch [96/300], Step [187/225], Training Accuracy: 97.2928%, Training Loss: 0.0786%\n",
      "Epoch [96/300], Step [188/225], Training Accuracy: 97.2989%, Training Loss: 0.0785%\n",
      "Epoch [96/300], Step [189/225], Training Accuracy: 97.3132%, Training Loss: 0.0782%\n",
      "Epoch [96/300], Step [190/225], Training Accuracy: 97.3109%, Training Loss: 0.0783%\n",
      "Epoch [96/300], Step [191/225], Training Accuracy: 97.3249%, Training Loss: 0.0782%\n",
      "Epoch [96/300], Step [192/225], Training Accuracy: 97.3145%, Training Loss: 0.0784%\n",
      "Epoch [96/300], Step [193/225], Training Accuracy: 97.3122%, Training Loss: 0.0788%\n",
      "Epoch [96/300], Step [194/225], Training Accuracy: 97.3260%, Training Loss: 0.0786%\n",
      "Epoch [96/300], Step [195/225], Training Accuracy: 97.3317%, Training Loss: 0.0785%\n",
      "Epoch [96/300], Step [196/225], Training Accuracy: 97.3294%, Training Loss: 0.0783%\n",
      "Epoch [96/300], Step [197/225], Training Accuracy: 97.3430%, Training Loss: 0.0781%\n",
      "Epoch [96/300], Step [198/225], Training Accuracy: 97.3327%, Training Loss: 0.0781%\n",
      "Epoch [96/300], Step [199/225], Training Accuracy: 97.3304%, Training Loss: 0.0782%\n",
      "Epoch [96/300], Step [200/225], Training Accuracy: 97.3203%, Training Loss: 0.0782%\n",
      "Epoch [96/300], Step [201/225], Training Accuracy: 97.3259%, Training Loss: 0.0780%\n",
      "Epoch [96/300], Step [202/225], Training Accuracy: 97.3391%, Training Loss: 0.0778%\n",
      "Epoch [96/300], Step [203/225], Training Accuracy: 97.3368%, Training Loss: 0.0778%\n",
      "Epoch [96/300], Step [204/225], Training Accuracy: 97.3422%, Training Loss: 0.0778%\n",
      "Epoch [96/300], Step [205/225], Training Accuracy: 97.3552%, Training Loss: 0.0776%\n",
      "Epoch [96/300], Step [206/225], Training Accuracy: 97.3529%, Training Loss: 0.0776%\n",
      "Epoch [96/300], Step [207/225], Training Accuracy: 97.3581%, Training Loss: 0.0776%\n",
      "Epoch [96/300], Step [208/225], Training Accuracy: 97.3558%, Training Loss: 0.0778%\n",
      "Epoch [96/300], Step [209/225], Training Accuracy: 97.3609%, Training Loss: 0.0775%\n",
      "Epoch [96/300], Step [210/225], Training Accuracy: 97.3586%, Training Loss: 0.0776%\n",
      "Epoch [96/300], Step [211/225], Training Accuracy: 97.3637%, Training Loss: 0.0776%\n",
      "Epoch [96/300], Step [212/225], Training Accuracy: 97.3614%, Training Loss: 0.0776%\n",
      "Epoch [96/300], Step [213/225], Training Accuracy: 97.3665%, Training Loss: 0.0775%\n",
      "Epoch [96/300], Step [214/225], Training Accuracy: 97.3715%, Training Loss: 0.0774%\n",
      "Epoch [96/300], Step [215/225], Training Accuracy: 97.3692%, Training Loss: 0.0779%\n",
      "Epoch [96/300], Step [216/225], Training Accuracy: 97.3669%, Training Loss: 0.0780%\n",
      "Epoch [96/300], Step [217/225], Training Accuracy: 97.3718%, Training Loss: 0.0779%\n",
      "Epoch [96/300], Step [218/225], Training Accuracy: 97.3696%, Training Loss: 0.0778%\n",
      "Epoch [96/300], Step [219/225], Training Accuracy: 97.3744%, Training Loss: 0.0780%\n",
      "Epoch [96/300], Step [220/225], Training Accuracy: 97.3793%, Training Loss: 0.0778%\n",
      "Epoch [96/300], Step [221/225], Training Accuracy: 97.3699%, Training Loss: 0.0783%\n",
      "Epoch [96/300], Step [222/225], Training Accuracy: 97.3677%, Training Loss: 0.0782%\n",
      "Epoch [96/300], Step [223/225], Training Accuracy: 97.3585%, Training Loss: 0.0784%\n",
      "Epoch [96/300], Step [224/225], Training Accuracy: 97.3703%, Training Loss: 0.0781%\n",
      "Epoch [96/300], Step [225/225], Training Accuracy: 97.3735%, Training Loss: 0.0780%\n",
      "Epoch [97/300], Step [1/225], Training Accuracy: 95.3125%, Training Loss: 0.0776%\n",
      "Epoch [97/300], Step [2/225], Training Accuracy: 96.8750%, Training Loss: 0.0776%\n",
      "Epoch [97/300], Step [3/225], Training Accuracy: 96.8750%, Training Loss: 0.0885%\n",
      "Epoch [97/300], Step [4/225], Training Accuracy: 96.8750%, Training Loss: 0.0914%\n",
      "Epoch [97/300], Step [5/225], Training Accuracy: 96.8750%, Training Loss: 0.1062%\n",
      "Epoch [97/300], Step [6/225], Training Accuracy: 96.8750%, Training Loss: 0.1016%\n",
      "Epoch [97/300], Step [7/225], Training Accuracy: 96.8750%, Training Loss: 0.0958%\n",
      "Epoch [97/300], Step [8/225], Training Accuracy: 97.2656%, Training Loss: 0.0905%\n",
      "Epoch [97/300], Step [9/225], Training Accuracy: 97.0486%, Training Loss: 0.0896%\n",
      "Epoch [97/300], Step [10/225], Training Accuracy: 97.0312%, Training Loss: 0.0851%\n",
      "Epoch [97/300], Step [11/225], Training Accuracy: 97.1591%, Training Loss: 0.0818%\n",
      "Epoch [97/300], Step [12/225], Training Accuracy: 97.1354%, Training Loss: 0.0817%\n",
      "Epoch [97/300], Step [13/225], Training Accuracy: 97.3558%, Training Loss: 0.0795%\n",
      "Epoch [97/300], Step [14/225], Training Accuracy: 97.2098%, Training Loss: 0.0821%\n",
      "Epoch [97/300], Step [15/225], Training Accuracy: 97.2917%, Training Loss: 0.0798%\n",
      "Epoch [97/300], Step [16/225], Training Accuracy: 97.2656%, Training Loss: 0.0794%\n",
      "Epoch [97/300], Step [17/225], Training Accuracy: 97.2426%, Training Loss: 0.0786%\n",
      "Epoch [97/300], Step [18/225], Training Accuracy: 96.7882%, Training Loss: 0.0865%\n",
      "Epoch [97/300], Step [19/225], Training Accuracy: 96.9572%, Training Loss: 0.0840%\n",
      "Epoch [97/300], Step [20/225], Training Accuracy: 97.0312%, Training Loss: 0.0816%\n",
      "Epoch [97/300], Step [21/225], Training Accuracy: 97.0982%, Training Loss: 0.0810%\n",
      "Epoch [97/300], Step [22/225], Training Accuracy: 97.1591%, Training Loss: 0.0803%\n",
      "Epoch [97/300], Step [23/225], Training Accuracy: 97.2826%, Training Loss: 0.0776%\n",
      "Epoch [97/300], Step [24/225], Training Accuracy: 97.2656%, Training Loss: 0.0775%\n",
      "Epoch [97/300], Step [25/225], Training Accuracy: 97.2500%, Training Loss: 0.0778%\n",
      "Epoch [97/300], Step [26/225], Training Accuracy: 97.2957%, Training Loss: 0.0781%\n",
      "Epoch [97/300], Step [27/225], Training Accuracy: 97.2801%, Training Loss: 0.0801%\n",
      "Epoch [97/300], Step [28/225], Training Accuracy: 97.3772%, Training Loss: 0.0785%\n",
      "Epoch [97/300], Step [29/225], Training Accuracy: 97.2522%, Training Loss: 0.0804%\n",
      "Epoch [97/300], Step [30/225], Training Accuracy: 97.2917%, Training Loss: 0.0801%\n",
      "Epoch [97/300], Step [31/225], Training Accuracy: 97.3286%, Training Loss: 0.0799%\n",
      "Epoch [97/300], Step [32/225], Training Accuracy: 97.3633%, Training Loss: 0.0786%\n",
      "Epoch [97/300], Step [33/225], Training Accuracy: 97.4432%, Training Loss: 0.0766%\n",
      "Epoch [97/300], Step [34/225], Training Accuracy: 97.4724%, Training Loss: 0.0755%\n",
      "Epoch [97/300], Step [35/225], Training Accuracy: 97.4107%, Training Loss: 0.0775%\n",
      "Epoch [97/300], Step [36/225], Training Accuracy: 97.4392%, Training Loss: 0.0774%\n",
      "Epoch [97/300], Step [37/225], Training Accuracy: 97.3818%, Training Loss: 0.0791%\n",
      "Epoch [97/300], Step [38/225], Training Accuracy: 97.3684%, Training Loss: 0.0793%\n",
      "Epoch [97/300], Step [39/225], Training Accuracy: 97.3157%, Training Loss: 0.0809%\n",
      "Epoch [97/300], Step [40/225], Training Accuracy: 97.3047%, Training Loss: 0.0808%\n",
      "Epoch [97/300], Step [41/225], Training Accuracy: 97.3323%, Training Loss: 0.0805%\n",
      "Epoch [97/300], Step [42/225], Training Accuracy: 97.3586%, Training Loss: 0.0798%\n",
      "Epoch [97/300], Step [43/225], Training Accuracy: 97.4201%, Training Loss: 0.0788%\n",
      "Epoch [97/300], Step [44/225], Training Accuracy: 97.4787%, Training Loss: 0.0778%\n",
      "Epoch [97/300], Step [45/225], Training Accuracy: 97.5000%, Training Loss: 0.0775%\n",
      "Epoch [97/300], Step [46/225], Training Accuracy: 97.4864%, Training Loss: 0.0771%\n",
      "Epoch [97/300], Step [47/225], Training Accuracy: 97.4402%, Training Loss: 0.0785%\n",
      "Epoch [97/300], Step [48/225], Training Accuracy: 97.3958%, Training Loss: 0.0812%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/300], Step [49/225], Training Accuracy: 97.3214%, Training Loss: 0.0819%\n",
      "Epoch [97/300], Step [50/225], Training Accuracy: 97.3438%, Training Loss: 0.0814%\n",
      "Epoch [97/300], Step [51/225], Training Accuracy: 97.3346%, Training Loss: 0.0813%\n",
      "Epoch [97/300], Step [52/225], Training Accuracy: 97.3558%, Training Loss: 0.0805%\n",
      "Epoch [97/300], Step [53/225], Training Accuracy: 97.3172%, Training Loss: 0.0814%\n",
      "Epoch [97/300], Step [54/225], Training Accuracy: 97.3090%, Training Loss: 0.0812%\n",
      "Epoch [97/300], Step [55/225], Training Accuracy: 97.2443%, Training Loss: 0.0825%\n",
      "Epoch [97/300], Step [56/225], Training Accuracy: 97.2377%, Training Loss: 0.0823%\n",
      "Epoch [97/300], Step [57/225], Training Accuracy: 97.2314%, Training Loss: 0.0828%\n",
      "Epoch [97/300], Step [58/225], Training Accuracy: 97.2252%, Training Loss: 0.0831%\n",
      "Epoch [97/300], Step [59/225], Training Accuracy: 97.2458%, Training Loss: 0.0830%\n",
      "Epoch [97/300], Step [60/225], Training Accuracy: 97.2917%, Training Loss: 0.0823%\n",
      "Epoch [97/300], Step [61/225], Training Accuracy: 97.3105%, Training Loss: 0.0819%\n",
      "Epoch [97/300], Step [62/225], Training Accuracy: 97.3034%, Training Loss: 0.0820%\n",
      "Epoch [97/300], Step [63/225], Training Accuracy: 97.2718%, Training Loss: 0.0822%\n",
      "Epoch [97/300], Step [64/225], Training Accuracy: 97.2900%, Training Loss: 0.0814%\n",
      "Epoch [97/300], Step [65/225], Training Accuracy: 97.3077%, Training Loss: 0.0808%\n",
      "Epoch [97/300], Step [66/225], Training Accuracy: 97.2775%, Training Loss: 0.0827%\n",
      "Epoch [97/300], Step [67/225], Training Accuracy: 97.2715%, Training Loss: 0.0825%\n",
      "Epoch [97/300], Step [68/225], Training Accuracy: 97.2886%, Training Loss: 0.0822%\n",
      "Epoch [97/300], Step [69/225], Training Accuracy: 97.2826%, Training Loss: 0.0823%\n",
      "Epoch [97/300], Step [70/225], Training Accuracy: 97.2321%, Training Loss: 0.0828%\n",
      "Epoch [97/300], Step [71/225], Training Accuracy: 97.2051%, Training Loss: 0.0838%\n",
      "Epoch [97/300], Step [72/225], Training Accuracy: 97.2005%, Training Loss: 0.0837%\n",
      "Epoch [97/300], Step [73/225], Training Accuracy: 97.1747%, Training Loss: 0.0839%\n",
      "Epoch [97/300], Step [74/225], Training Accuracy: 97.1706%, Training Loss: 0.0841%\n",
      "Epoch [97/300], Step [75/225], Training Accuracy: 97.1667%, Training Loss: 0.0840%\n",
      "Epoch [97/300], Step [76/225], Training Accuracy: 97.1423%, Training Loss: 0.0845%\n",
      "Epoch [97/300], Step [77/225], Training Accuracy: 97.1185%, Training Loss: 0.0846%\n",
      "Epoch [97/300], Step [78/225], Training Accuracy: 97.1154%, Training Loss: 0.0844%\n",
      "Epoch [97/300], Step [79/225], Training Accuracy: 97.0926%, Training Loss: 0.0842%\n",
      "Epoch [97/300], Step [80/225], Training Accuracy: 97.0898%, Training Loss: 0.0849%\n",
      "Epoch [97/300], Step [81/225], Training Accuracy: 97.0679%, Training Loss: 0.0857%\n",
      "Epoch [97/300], Step [82/225], Training Accuracy: 97.0655%, Training Loss: 0.0863%\n",
      "Epoch [97/300], Step [83/225], Training Accuracy: 97.1009%, Training Loss: 0.0858%\n",
      "Epoch [97/300], Step [84/225], Training Accuracy: 97.0982%, Training Loss: 0.0856%\n",
      "Epoch [97/300], Step [85/225], Training Accuracy: 97.0404%, Training Loss: 0.0865%\n",
      "Epoch [97/300], Step [86/225], Training Accuracy: 97.0022%, Training Loss: 0.0875%\n",
      "Epoch [97/300], Step [87/225], Training Accuracy: 97.0007%, Training Loss: 0.0875%\n",
      "Epoch [97/300], Step [88/225], Training Accuracy: 96.9993%, Training Loss: 0.0875%\n",
      "Epoch [97/300], Step [89/225], Training Accuracy: 96.9979%, Training Loss: 0.0877%\n",
      "Epoch [97/300], Step [90/225], Training Accuracy: 96.9965%, Training Loss: 0.0876%\n",
      "Epoch [97/300], Step [91/225], Training Accuracy: 97.0295%, Training Loss: 0.0869%\n",
      "Epoch [97/300], Step [92/225], Training Accuracy: 96.9769%, Training Loss: 0.0873%\n",
      "Epoch [97/300], Step [93/225], Training Accuracy: 96.9590%, Training Loss: 0.0877%\n",
      "Epoch [97/300], Step [94/225], Training Accuracy: 96.9249%, Training Loss: 0.0884%\n",
      "Epoch [97/300], Step [95/225], Training Accuracy: 96.9408%, Training Loss: 0.0884%\n",
      "Epoch [97/300], Step [96/225], Training Accuracy: 96.9727%, Training Loss: 0.0881%\n",
      "Epoch [97/300], Step [97/225], Training Accuracy: 96.9555%, Training Loss: 0.0888%\n",
      "Epoch [97/300], Step [98/225], Training Accuracy: 96.9388%, Training Loss: 0.0892%\n",
      "Epoch [97/300], Step [99/225], Training Accuracy: 96.9381%, Training Loss: 0.0890%\n",
      "Epoch [97/300], Step [100/225], Training Accuracy: 96.9062%, Training Loss: 0.0890%\n",
      "Epoch [97/300], Step [101/225], Training Accuracy: 96.9369%, Training Loss: 0.0886%\n",
      "Epoch [97/300], Step [102/225], Training Accuracy: 96.9669%, Training Loss: 0.0881%\n",
      "Epoch [97/300], Step [103/225], Training Accuracy: 96.9508%, Training Loss: 0.0882%\n",
      "Epoch [97/300], Step [104/225], Training Accuracy: 96.9501%, Training Loss: 0.0884%\n",
      "Epoch [97/300], Step [105/225], Training Accuracy: 96.9494%, Training Loss: 0.0886%\n",
      "Epoch [97/300], Step [106/225], Training Accuracy: 96.9487%, Training Loss: 0.0885%\n",
      "Epoch [97/300], Step [107/225], Training Accuracy: 96.9626%, Training Loss: 0.0880%\n",
      "Epoch [97/300], Step [108/225], Training Accuracy: 96.9907%, Training Loss: 0.0877%\n",
      "Epoch [97/300], Step [109/225], Training Accuracy: 96.9897%, Training Loss: 0.0878%\n",
      "Epoch [97/300], Step [110/225], Training Accuracy: 97.0170%, Training Loss: 0.0873%\n",
      "Epoch [97/300], Step [111/225], Training Accuracy: 97.0158%, Training Loss: 0.0877%\n",
      "Epoch [97/300], Step [112/225], Training Accuracy: 97.0285%, Training Loss: 0.0875%\n",
      "Epoch [97/300], Step [113/225], Training Accuracy: 97.0133%, Training Loss: 0.0885%\n",
      "Epoch [97/300], Step [114/225], Training Accuracy: 97.0121%, Training Loss: 0.0888%\n",
      "Epoch [97/300], Step [115/225], Training Accuracy: 97.0380%, Training Loss: 0.0882%\n",
      "Epoch [97/300], Step [116/225], Training Accuracy: 97.0366%, Training Loss: 0.0881%\n",
      "Epoch [97/300], Step [117/225], Training Accuracy: 97.0353%, Training Loss: 0.0878%\n",
      "Epoch [97/300], Step [118/225], Training Accuracy: 97.0339%, Training Loss: 0.0875%\n",
      "Epoch [97/300], Step [119/225], Training Accuracy: 97.0588%, Training Loss: 0.0872%\n",
      "Epoch [97/300], Step [120/225], Training Accuracy: 97.0573%, Training Loss: 0.0872%\n",
      "Epoch [97/300], Step [121/225], Training Accuracy: 97.0816%, Training Loss: 0.0867%\n",
      "Epoch [97/300], Step [122/225], Training Accuracy: 97.0543%, Training Loss: 0.0870%\n",
      "Epoch [97/300], Step [123/225], Training Accuracy: 97.0401%, Training Loss: 0.0871%\n",
      "Epoch [97/300], Step [124/225], Training Accuracy: 97.0388%, Training Loss: 0.0873%\n",
      "Epoch [97/300], Step [125/225], Training Accuracy: 97.0375%, Training Loss: 0.0872%\n",
      "Epoch [97/300], Step [126/225], Training Accuracy: 97.0486%, Training Loss: 0.0871%\n",
      "Epoch [97/300], Step [127/225], Training Accuracy: 97.0472%, Training Loss: 0.0870%\n",
      "Epoch [97/300], Step [128/225], Training Accuracy: 97.0093%, Training Loss: 0.0877%\n",
      "Epoch [97/300], Step [129/225], Training Accuracy: 97.0082%, Training Loss: 0.0877%\n",
      "Epoch [97/300], Step [130/225], Training Accuracy: 97.0072%, Training Loss: 0.0876%\n",
      "Epoch [97/300], Step [131/225], Training Accuracy: 97.0301%, Training Loss: 0.0871%\n",
      "Epoch [97/300], Step [132/225], Training Accuracy: 97.0052%, Training Loss: 0.0872%\n",
      "Epoch [97/300], Step [133/225], Training Accuracy: 97.0160%, Training Loss: 0.0869%\n",
      "Epoch [97/300], Step [134/225], Training Accuracy: 97.0266%, Training Loss: 0.0866%\n",
      "Epoch [97/300], Step [135/225], Training Accuracy: 97.0370%, Training Loss: 0.0867%\n",
      "Epoch [97/300], Step [136/225], Training Accuracy: 97.0129%, Training Loss: 0.0875%\n",
      "Epoch [97/300], Step [137/225], Training Accuracy: 97.0347%, Training Loss: 0.0871%\n",
      "Epoch [97/300], Step [138/225], Training Accuracy: 96.9995%, Training Loss: 0.0872%\n",
      "Epoch [97/300], Step [139/225], Training Accuracy: 96.9987%, Training Loss: 0.0872%\n",
      "Epoch [97/300], Step [140/225], Training Accuracy: 97.0201%, Training Loss: 0.0870%\n",
      "Epoch [97/300], Step [141/225], Training Accuracy: 97.0412%, Training Loss: 0.0868%\n",
      "Epoch [97/300], Step [142/225], Training Accuracy: 97.0621%, Training Loss: 0.0864%\n",
      "Epoch [97/300], Step [143/225], Training Accuracy: 97.0717%, Training Loss: 0.0861%\n",
      "Epoch [97/300], Step [144/225], Training Accuracy: 97.0812%, Training Loss: 0.0858%\n",
      "Epoch [97/300], Step [145/225], Training Accuracy: 97.0905%, Training Loss: 0.0855%\n",
      "Epoch [97/300], Step [146/225], Training Accuracy: 97.0997%, Training Loss: 0.0853%\n",
      "Epoch [97/300], Step [147/225], Training Accuracy: 97.0982%, Training Loss: 0.0855%\n",
      "Epoch [97/300], Step [148/225], Training Accuracy: 97.0650%, Training Loss: 0.0859%\n",
      "Epoch [97/300], Step [149/225], Training Accuracy: 97.0638%, Training Loss: 0.0858%\n",
      "Epoch [97/300], Step [150/225], Training Accuracy: 97.0833%, Training Loss: 0.0855%\n",
      "Epoch [97/300], Step [151/225], Training Accuracy: 97.0923%, Training Loss: 0.0853%\n",
      "Epoch [97/300], Step [152/225], Training Accuracy: 97.1012%, Training Loss: 0.0850%\n",
      "Epoch [97/300], Step [153/225], Training Accuracy: 97.1099%, Training Loss: 0.0847%\n",
      "Epoch [97/300], Step [154/225], Training Accuracy: 97.1185%, Training Loss: 0.0847%\n",
      "Epoch [97/300], Step [155/225], Training Accuracy: 97.1169%, Training Loss: 0.0845%\n",
      "Epoch [97/300], Step [156/225], Training Accuracy: 97.1254%, Training Loss: 0.0843%\n",
      "Epoch [97/300], Step [157/225], Training Accuracy: 97.1139%, Training Loss: 0.0847%\n",
      "Epoch [97/300], Step [158/225], Training Accuracy: 97.1222%, Training Loss: 0.0846%\n",
      "Epoch [97/300], Step [159/225], Training Accuracy: 97.1403%, Training Loss: 0.0843%\n",
      "Epoch [97/300], Step [160/225], Training Accuracy: 97.1582%, Training Loss: 0.0841%\n",
      "Epoch [97/300], Step [161/225], Training Accuracy: 97.1564%, Training Loss: 0.0839%\n",
      "Epoch [97/300], Step [162/225], Training Accuracy: 97.1547%, Training Loss: 0.0839%\n",
      "Epoch [97/300], Step [163/225], Training Accuracy: 97.1626%, Training Loss: 0.0837%\n",
      "Epoch [97/300], Step [164/225], Training Accuracy: 97.1704%, Training Loss: 0.0835%\n",
      "Epoch [97/300], Step [165/225], Training Accuracy: 97.1875%, Training Loss: 0.0833%\n",
      "Epoch [97/300], Step [166/225], Training Accuracy: 97.1950%, Training Loss: 0.0831%\n",
      "Epoch [97/300], Step [167/225], Training Accuracy: 97.1838%, Training Loss: 0.0834%\n",
      "Epoch [97/300], Step [168/225], Training Accuracy: 97.1726%, Training Loss: 0.0835%\n",
      "Epoch [97/300], Step [169/225], Training Accuracy: 97.1709%, Training Loss: 0.0834%\n",
      "Epoch [97/300], Step [170/225], Training Accuracy: 97.1599%, Training Loss: 0.0838%\n",
      "Epoch [97/300], Step [171/225], Training Accuracy: 97.1583%, Training Loss: 0.0837%\n",
      "Epoch [97/300], Step [172/225], Training Accuracy: 97.1384%, Training Loss: 0.0838%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/300], Step [173/225], Training Accuracy: 97.1460%, Training Loss: 0.0835%\n",
      "Epoch [97/300], Step [174/225], Training Accuracy: 97.1534%, Training Loss: 0.0837%\n",
      "Epoch [97/300], Step [175/225], Training Accuracy: 97.1607%, Training Loss: 0.0837%\n",
      "Epoch [97/300], Step [176/225], Training Accuracy: 97.1591%, Training Loss: 0.0837%\n",
      "Epoch [97/300], Step [177/225], Training Accuracy: 97.1575%, Training Loss: 0.0835%\n",
      "Epoch [97/300], Step [178/225], Training Accuracy: 97.1471%, Training Loss: 0.0838%\n",
      "Epoch [97/300], Step [179/225], Training Accuracy: 97.1543%, Training Loss: 0.0836%\n",
      "Epoch [97/300], Step [180/225], Training Accuracy: 97.1528%, Training Loss: 0.0835%\n",
      "Epoch [97/300], Step [181/225], Training Accuracy: 97.1599%, Training Loss: 0.0833%\n",
      "Epoch [97/300], Step [182/225], Training Accuracy: 97.1755%, Training Loss: 0.0831%\n",
      "Epoch [97/300], Step [183/225], Training Accuracy: 97.1738%, Training Loss: 0.0829%\n",
      "Epoch [97/300], Step [184/225], Training Accuracy: 97.1892%, Training Loss: 0.0826%\n",
      "Epoch [97/300], Step [185/225], Training Accuracy: 97.1959%, Training Loss: 0.0823%\n",
      "Epoch [97/300], Step [186/225], Training Accuracy: 97.2026%, Training Loss: 0.0821%\n",
      "Epoch [97/300], Step [187/225], Training Accuracy: 97.2176%, Training Loss: 0.0819%\n",
      "Epoch [97/300], Step [188/225], Training Accuracy: 97.2241%, Training Loss: 0.0817%\n",
      "Epoch [97/300], Step [189/225], Training Accuracy: 97.2222%, Training Loss: 0.0816%\n",
      "Epoch [97/300], Step [190/225], Training Accuracy: 97.2286%, Training Loss: 0.0816%\n",
      "Epoch [97/300], Step [191/225], Training Accuracy: 97.2431%, Training Loss: 0.0814%\n",
      "Epoch [97/300], Step [192/225], Training Accuracy: 97.2493%, Training Loss: 0.0813%\n",
      "Epoch [97/300], Step [193/225], Training Accuracy: 97.2555%, Training Loss: 0.0812%\n",
      "Epoch [97/300], Step [194/225], Training Accuracy: 97.2697%, Training Loss: 0.0810%\n",
      "Epoch [97/300], Step [195/225], Training Accuracy: 97.2837%, Training Loss: 0.0809%\n",
      "Epoch [97/300], Step [196/225], Training Accuracy: 97.2895%, Training Loss: 0.0808%\n",
      "Epoch [97/300], Step [197/225], Training Accuracy: 97.2716%, Training Loss: 0.0811%\n",
      "Epoch [97/300], Step [198/225], Training Accuracy: 97.2459%, Training Loss: 0.0815%\n",
      "Epoch [97/300], Step [199/225], Training Accuracy: 97.2597%, Training Loss: 0.0813%\n",
      "Epoch [97/300], Step [200/225], Training Accuracy: 97.2734%, Training Loss: 0.0810%\n",
      "Epoch [97/300], Step [201/225], Training Accuracy: 97.2715%, Training Loss: 0.0810%\n",
      "Epoch [97/300], Step [202/225], Training Accuracy: 97.2695%, Training Loss: 0.0810%\n",
      "Epoch [97/300], Step [203/225], Training Accuracy: 97.2752%, Training Loss: 0.0808%\n",
      "Epoch [97/300], Step [204/225], Training Accuracy: 97.2733%, Training Loss: 0.0809%\n",
      "Epoch [97/300], Step [205/225], Training Accuracy: 97.2866%, Training Loss: 0.0806%\n",
      "Epoch [97/300], Step [206/225], Training Accuracy: 97.2770%, Training Loss: 0.0807%\n",
      "Epoch [97/300], Step [207/225], Training Accuracy: 97.2751%, Training Loss: 0.0807%\n",
      "Epoch [97/300], Step [208/225], Training Accuracy: 97.2882%, Training Loss: 0.0805%\n",
      "Epoch [97/300], Step [209/225], Training Accuracy: 97.2862%, Training Loss: 0.0806%\n",
      "Epoch [97/300], Step [210/225], Training Accuracy: 97.2991%, Training Loss: 0.0804%\n",
      "Epoch [97/300], Step [211/225], Training Accuracy: 97.2749%, Training Loss: 0.0809%\n",
      "Epoch [97/300], Step [212/225], Training Accuracy: 97.2730%, Training Loss: 0.0811%\n",
      "Epoch [97/300], Step [213/225], Training Accuracy: 97.2711%, Training Loss: 0.0810%\n",
      "Epoch [97/300], Step [214/225], Training Accuracy: 97.2547%, Training Loss: 0.0812%\n",
      "Epoch [97/300], Step [215/225], Training Accuracy: 97.2602%, Training Loss: 0.0813%\n",
      "Epoch [97/300], Step [216/225], Training Accuracy: 97.2512%, Training Loss: 0.0815%\n",
      "Epoch [97/300], Step [217/225], Training Accuracy: 97.2566%, Training Loss: 0.0814%\n",
      "Epoch [97/300], Step [218/225], Training Accuracy: 97.2549%, Training Loss: 0.0813%\n",
      "Epoch [97/300], Step [219/225], Training Accuracy: 97.2531%, Training Loss: 0.0813%\n",
      "Epoch [97/300], Step [220/225], Training Accuracy: 97.2514%, Training Loss: 0.0812%\n",
      "Epoch [97/300], Step [221/225], Training Accuracy: 97.2497%, Training Loss: 0.0812%\n",
      "Epoch [97/300], Step [222/225], Training Accuracy: 97.2340%, Training Loss: 0.0813%\n",
      "Epoch [97/300], Step [223/225], Training Accuracy: 97.2464%, Training Loss: 0.0811%\n",
      "Epoch [97/300], Step [224/225], Training Accuracy: 97.2447%, Training Loss: 0.0811%\n",
      "Epoch [97/300], Step [225/225], Training Accuracy: 97.2485%, Training Loss: 0.0812%\n",
      "Epoch [98/300], Step [1/225], Training Accuracy: 96.8750%, Training Loss: 0.0963%\n",
      "Epoch [98/300], Step [2/225], Training Accuracy: 96.0938%, Training Loss: 0.0831%\n",
      "Epoch [98/300], Step [3/225], Training Accuracy: 96.8750%, Training Loss: 0.0782%\n",
      "Epoch [98/300], Step [4/225], Training Accuracy: 97.2656%, Training Loss: 0.0696%\n",
      "Epoch [98/300], Step [5/225], Training Accuracy: 97.5000%, Training Loss: 0.0662%\n",
      "Epoch [98/300], Step [6/225], Training Accuracy: 97.1354%, Training Loss: 0.0707%\n",
      "Epoch [98/300], Step [7/225], Training Accuracy: 97.0982%, Training Loss: 0.0712%\n",
      "Epoch [98/300], Step [8/225], Training Accuracy: 97.2656%, Training Loss: 0.0696%\n",
      "Epoch [98/300], Step [9/225], Training Accuracy: 97.0486%, Training Loss: 0.0703%\n",
      "Epoch [98/300], Step [10/225], Training Accuracy: 97.0312%, Training Loss: 0.0740%\n",
      "Epoch [98/300], Step [11/225], Training Accuracy: 97.3011%, Training Loss: 0.0695%\n",
      "Epoch [98/300], Step [12/225], Training Accuracy: 97.3958%, Training Loss: 0.0669%\n",
      "Epoch [98/300], Step [13/225], Training Accuracy: 97.3558%, Training Loss: 0.0691%\n",
      "Epoch [98/300], Step [14/225], Training Accuracy: 97.0982%, Training Loss: 0.0718%\n",
      "Epoch [98/300], Step [15/225], Training Accuracy: 97.0833%, Training Loss: 0.0727%\n",
      "Epoch [98/300], Step [16/225], Training Accuracy: 96.8750%, Training Loss: 0.0736%\n",
      "Epoch [98/300], Step [17/225], Training Accuracy: 96.6912%, Training Loss: 0.0781%\n",
      "Epoch [98/300], Step [18/225], Training Accuracy: 96.7882%, Training Loss: 0.0785%\n",
      "Epoch [98/300], Step [19/225], Training Accuracy: 96.9572%, Training Loss: 0.0762%\n",
      "Epoch [98/300], Step [20/225], Training Accuracy: 96.9531%, Training Loss: 0.0787%\n",
      "Epoch [98/300], Step [21/225], Training Accuracy: 96.8006%, Training Loss: 0.0809%\n",
      "Epoch [98/300], Step [22/225], Training Accuracy: 96.8750%, Training Loss: 0.0806%\n",
      "Epoch [98/300], Step [23/225], Training Accuracy: 96.8750%, Training Loss: 0.0804%\n",
      "Epoch [98/300], Step [24/225], Training Accuracy: 96.7448%, Training Loss: 0.0841%\n",
      "Epoch [98/300], Step [25/225], Training Accuracy: 96.7500%, Training Loss: 0.0833%\n",
      "Epoch [98/300], Step [26/225], Training Accuracy: 96.7548%, Training Loss: 0.0843%\n",
      "Epoch [98/300], Step [27/225], Training Accuracy: 96.6435%, Training Loss: 0.0854%\n",
      "Epoch [98/300], Step [28/225], Training Accuracy: 96.7634%, Training Loss: 0.0835%\n",
      "Epoch [98/300], Step [29/225], Training Accuracy: 96.8211%, Training Loss: 0.0823%\n",
      "Epoch [98/300], Step [30/225], Training Accuracy: 96.8750%, Training Loss: 0.0820%\n",
      "Epoch [98/300], Step [31/225], Training Accuracy: 96.8750%, Training Loss: 0.0826%\n",
      "Epoch [98/300], Step [32/225], Training Accuracy: 96.8750%, Training Loss: 0.0820%\n",
      "Epoch [98/300], Step [33/225], Training Accuracy: 96.9697%, Training Loss: 0.0805%\n",
      "Epoch [98/300], Step [34/225], Training Accuracy: 96.9669%, Training Loss: 0.0799%\n",
      "Epoch [98/300], Step [35/225], Training Accuracy: 96.7411%, Training Loss: 0.0857%\n",
      "Epoch [98/300], Step [36/225], Training Accuracy: 96.7882%, Training Loss: 0.0847%\n",
      "Epoch [98/300], Step [37/225], Training Accuracy: 96.7905%, Training Loss: 0.0844%\n",
      "Epoch [98/300], Step [38/225], Training Accuracy: 96.8750%, Training Loss: 0.0833%\n",
      "Epoch [98/300], Step [39/225], Training Accuracy: 96.8349%, Training Loss: 0.0846%\n",
      "Epoch [98/300], Step [40/225], Training Accuracy: 96.8359%, Training Loss: 0.0842%\n",
      "Epoch [98/300], Step [41/225], Training Accuracy: 96.7988%, Training Loss: 0.0851%\n",
      "Epoch [98/300], Step [42/225], Training Accuracy: 96.8378%, Training Loss: 0.0849%\n",
      "Epoch [98/300], Step [43/225], Training Accuracy: 96.9113%, Training Loss: 0.0838%\n",
      "Epoch [98/300], Step [44/225], Training Accuracy: 96.9815%, Training Loss: 0.0824%\n",
      "Epoch [98/300], Step [45/225], Training Accuracy: 96.9792%, Training Loss: 0.0819%\n",
      "Epoch [98/300], Step [46/225], Training Accuracy: 97.0448%, Training Loss: 0.0810%\n",
      "Epoch [98/300], Step [47/225], Training Accuracy: 97.0412%, Training Loss: 0.0813%\n",
      "Epoch [98/300], Step [48/225], Training Accuracy: 97.0703%, Training Loss: 0.0805%\n",
      "Epoch [98/300], Step [49/225], Training Accuracy: 97.1301%, Training Loss: 0.0793%\n",
      "Epoch [98/300], Step [50/225], Training Accuracy: 97.1562%, Training Loss: 0.0789%\n",
      "Epoch [98/300], Step [51/225], Training Accuracy: 97.2120%, Training Loss: 0.0782%\n",
      "Epoch [98/300], Step [52/225], Training Accuracy: 97.1755%, Training Loss: 0.0786%\n",
      "Epoch [98/300], Step [53/225], Training Accuracy: 97.1993%, Training Loss: 0.0791%\n",
      "Epoch [98/300], Step [54/225], Training Accuracy: 97.1644%, Training Loss: 0.0797%\n",
      "Epoch [98/300], Step [55/225], Training Accuracy: 97.1591%, Training Loss: 0.0798%\n",
      "Epoch [98/300], Step [56/225], Training Accuracy: 97.1540%, Training Loss: 0.0799%\n",
      "Epoch [98/300], Step [57/225], Training Accuracy: 97.1765%, Training Loss: 0.0800%\n",
      "Epoch [98/300], Step [58/225], Training Accuracy: 97.1713%, Training Loss: 0.0800%\n",
      "Epoch [98/300], Step [59/225], Training Accuracy: 97.1398%, Training Loss: 0.0806%\n",
      "Epoch [98/300], Step [60/225], Training Accuracy: 97.1354%, Training Loss: 0.0804%\n",
      "Epoch [98/300], Step [61/225], Training Accuracy: 97.1311%, Training Loss: 0.0812%\n",
      "Epoch [98/300], Step [62/225], Training Accuracy: 97.1774%, Training Loss: 0.0804%\n",
      "Epoch [98/300], Step [63/225], Training Accuracy: 97.1478%, Training Loss: 0.0817%\n",
      "Epoch [98/300], Step [64/225], Training Accuracy: 97.1191%, Training Loss: 0.0816%\n",
      "Epoch [98/300], Step [65/225], Training Accuracy: 97.1154%, Training Loss: 0.0825%\n",
      "Epoch [98/300], Step [66/225], Training Accuracy: 97.1354%, Training Loss: 0.0818%\n",
      "Epoch [98/300], Step [67/225], Training Accuracy: 97.1315%, Training Loss: 0.0816%\n",
      "Epoch [98/300], Step [68/225], Training Accuracy: 97.1507%, Training Loss: 0.0812%\n",
      "Epoch [98/300], Step [69/225], Training Accuracy: 97.1694%, Training Loss: 0.0805%\n",
      "Epoch [98/300], Step [70/225], Training Accuracy: 97.1429%, Training Loss: 0.0805%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/300], Step [71/225], Training Accuracy: 97.1391%, Training Loss: 0.0807%\n",
      "Epoch [98/300], Step [72/225], Training Accuracy: 97.1354%, Training Loss: 0.0809%\n",
      "Epoch [98/300], Step [73/225], Training Accuracy: 97.1318%, Training Loss: 0.0814%\n",
      "Epoch [98/300], Step [74/225], Training Accuracy: 97.1073%, Training Loss: 0.0818%\n",
      "Epoch [98/300], Step [75/225], Training Accuracy: 97.1042%, Training Loss: 0.0814%\n",
      "Epoch [98/300], Step [76/225], Training Accuracy: 97.1012%, Training Loss: 0.0813%\n",
      "Epoch [98/300], Step [77/225], Training Accuracy: 97.1388%, Training Loss: 0.0809%\n",
      "Epoch [98/300], Step [78/225], Training Accuracy: 97.1755%, Training Loss: 0.0804%\n",
      "Epoch [98/300], Step [79/225], Training Accuracy: 97.1717%, Training Loss: 0.0809%\n",
      "Epoch [98/300], Step [80/225], Training Accuracy: 97.1094%, Training Loss: 0.0822%\n",
      "Epoch [98/300], Step [81/225], Training Accuracy: 97.1258%, Training Loss: 0.0816%\n",
      "Epoch [98/300], Step [82/225], Training Accuracy: 97.1608%, Training Loss: 0.0810%\n",
      "Epoch [98/300], Step [83/225], Training Accuracy: 97.1574%, Training Loss: 0.0809%\n",
      "Epoch [98/300], Step [84/225], Training Accuracy: 97.0610%, Training Loss: 0.0821%\n",
      "Epoch [98/300], Step [85/225], Training Accuracy: 97.0404%, Training Loss: 0.0824%\n",
      "Epoch [98/300], Step [86/225], Training Accuracy: 97.0203%, Training Loss: 0.0829%\n",
      "Epoch [98/300], Step [87/225], Training Accuracy: 97.0546%, Training Loss: 0.0825%\n",
      "Epoch [98/300], Step [88/225], Training Accuracy: 97.0881%, Training Loss: 0.0821%\n",
      "Epoch [98/300], Step [89/225], Training Accuracy: 97.0681%, Training Loss: 0.0822%\n",
      "Epoch [98/300], Step [90/225], Training Accuracy: 97.0833%, Training Loss: 0.0825%\n",
      "Epoch [98/300], Step [91/225], Training Accuracy: 97.0810%, Training Loss: 0.0821%\n",
      "Epoch [98/300], Step [92/225], Training Accuracy: 97.1128%, Training Loss: 0.0815%\n",
      "Epoch [98/300], Step [93/225], Training Accuracy: 97.0934%, Training Loss: 0.0820%\n",
      "Epoch [98/300], Step [94/225], Training Accuracy: 97.0911%, Training Loss: 0.0817%\n",
      "Epoch [98/300], Step [95/225], Training Accuracy: 97.1053%, Training Loss: 0.0816%\n",
      "Epoch [98/300], Step [96/225], Training Accuracy: 97.1191%, Training Loss: 0.0812%\n",
      "Epoch [98/300], Step [97/225], Training Accuracy: 97.1166%, Training Loss: 0.0811%\n",
      "Epoch [98/300], Step [98/225], Training Accuracy: 97.1142%, Training Loss: 0.0809%\n",
      "Epoch [98/300], Step [99/225], Training Accuracy: 97.1117%, Training Loss: 0.0813%\n",
      "Epoch [98/300], Step [100/225], Training Accuracy: 97.1250%, Training Loss: 0.0811%\n",
      "Epoch [98/300], Step [101/225], Training Accuracy: 97.1380%, Training Loss: 0.0808%\n",
      "Epoch [98/300], Step [102/225], Training Accuracy: 97.1354%, Training Loss: 0.0810%\n",
      "Epoch [98/300], Step [103/225], Training Accuracy: 97.1481%, Training Loss: 0.0807%\n",
      "Epoch [98/300], Step [104/225], Training Accuracy: 97.1304%, Training Loss: 0.0813%\n",
      "Epoch [98/300], Step [105/225], Training Accuracy: 97.1577%, Training Loss: 0.0808%\n",
      "Epoch [98/300], Step [106/225], Training Accuracy: 97.1698%, Training Loss: 0.0807%\n",
      "Epoch [98/300], Step [107/225], Training Accuracy: 97.1963%, Training Loss: 0.0802%\n",
      "Epoch [98/300], Step [108/225], Training Accuracy: 97.1788%, Training Loss: 0.0804%\n",
      "Epoch [98/300], Step [109/225], Training Accuracy: 97.1904%, Training Loss: 0.0803%\n",
      "Epoch [98/300], Step [110/225], Training Accuracy: 97.2017%, Training Loss: 0.0802%\n",
      "Epoch [98/300], Step [111/225], Training Accuracy: 97.1988%, Training Loss: 0.0802%\n",
      "Epoch [98/300], Step [112/225], Training Accuracy: 97.1819%, Training Loss: 0.0802%\n",
      "Epoch [98/300], Step [113/225], Training Accuracy: 97.1792%, Training Loss: 0.0804%\n",
      "Epoch [98/300], Step [114/225], Training Accuracy: 97.1765%, Training Loss: 0.0803%\n",
      "Epoch [98/300], Step [115/225], Training Accuracy: 97.1875%, Training Loss: 0.0798%\n",
      "Epoch [98/300], Step [116/225], Training Accuracy: 97.1983%, Training Loss: 0.0796%\n",
      "Epoch [98/300], Step [117/225], Training Accuracy: 97.1955%, Training Loss: 0.0793%\n",
      "Epoch [98/300], Step [118/225], Training Accuracy: 97.1928%, Training Loss: 0.0793%\n",
      "Epoch [98/300], Step [119/225], Training Accuracy: 97.2164%, Training Loss: 0.0791%\n",
      "Epoch [98/300], Step [120/225], Training Accuracy: 97.2396%, Training Loss: 0.0787%\n",
      "Epoch [98/300], Step [121/225], Training Accuracy: 97.2366%, Training Loss: 0.0789%\n",
      "Epoch [98/300], Step [122/225], Training Accuracy: 97.2464%, Training Loss: 0.0787%\n",
      "Epoch [98/300], Step [123/225], Training Accuracy: 97.2688%, Training Loss: 0.0784%\n",
      "Epoch [98/300], Step [124/225], Training Accuracy: 97.2656%, Training Loss: 0.0785%\n",
      "Epoch [98/300], Step [125/225], Training Accuracy: 97.2750%, Training Loss: 0.0782%\n",
      "Epoch [98/300], Step [126/225], Training Accuracy: 97.2718%, Training Loss: 0.0781%\n",
      "Epoch [98/300], Step [127/225], Training Accuracy: 97.2564%, Training Loss: 0.0782%\n",
      "Epoch [98/300], Step [128/225], Training Accuracy: 97.2412%, Training Loss: 0.0787%\n",
      "Epoch [98/300], Step [129/225], Training Accuracy: 97.2505%, Training Loss: 0.0785%\n",
      "Epoch [98/300], Step [130/225], Training Accuracy: 97.2596%, Training Loss: 0.0783%\n",
      "Epoch [98/300], Step [131/225], Training Accuracy: 97.2567%, Training Loss: 0.0781%\n",
      "Epoch [98/300], Step [132/225], Training Accuracy: 97.2420%, Training Loss: 0.0783%\n",
      "Epoch [98/300], Step [133/225], Training Accuracy: 97.2392%, Training Loss: 0.0784%\n",
      "Epoch [98/300], Step [134/225], Training Accuracy: 97.2248%, Training Loss: 0.0783%\n",
      "Epoch [98/300], Step [135/225], Training Accuracy: 97.2222%, Training Loss: 0.0784%\n",
      "Epoch [98/300], Step [136/225], Training Accuracy: 97.2197%, Training Loss: 0.0784%\n",
      "Epoch [98/300], Step [137/225], Training Accuracy: 97.2286%, Training Loss: 0.0781%\n",
      "Epoch [98/300], Step [138/225], Training Accuracy: 97.2373%, Training Loss: 0.0778%\n",
      "Epoch [98/300], Step [139/225], Training Accuracy: 97.2122%, Training Loss: 0.0784%\n",
      "Epoch [98/300], Step [140/225], Training Accuracy: 97.1987%, Training Loss: 0.0790%\n",
      "Epoch [98/300], Step [141/225], Training Accuracy: 97.1964%, Training Loss: 0.0793%\n",
      "Epoch [98/300], Step [142/225], Training Accuracy: 97.1941%, Training Loss: 0.0792%\n",
      "Epoch [98/300], Step [143/225], Training Accuracy: 97.2028%, Training Loss: 0.0792%\n",
      "Epoch [98/300], Step [144/225], Training Accuracy: 97.1897%, Training Loss: 0.0793%\n",
      "Epoch [98/300], Step [145/225], Training Accuracy: 97.1875%, Training Loss: 0.0794%\n",
      "Epoch [98/300], Step [146/225], Training Accuracy: 97.1640%, Training Loss: 0.0796%\n",
      "Epoch [98/300], Step [147/225], Training Accuracy: 97.1726%, Training Loss: 0.0795%\n",
      "Epoch [98/300], Step [148/225], Training Accuracy: 97.1812%, Training Loss: 0.0794%\n",
      "Epoch [98/300], Step [149/225], Training Accuracy: 97.1686%, Training Loss: 0.0799%\n",
      "Epoch [98/300], Step [150/225], Training Accuracy: 97.1875%, Training Loss: 0.0796%\n",
      "Epoch [98/300], Step [151/225], Training Accuracy: 97.1958%, Training Loss: 0.0794%\n",
      "Epoch [98/300], Step [152/225], Training Accuracy: 97.2039%, Training Loss: 0.0792%\n",
      "Epoch [98/300], Step [153/225], Training Accuracy: 97.2120%, Training Loss: 0.0795%\n",
      "Epoch [98/300], Step [154/225], Training Accuracy: 97.1997%, Training Loss: 0.0798%\n",
      "Epoch [98/300], Step [155/225], Training Accuracy: 97.2077%, Training Loss: 0.0795%\n",
      "Epoch [98/300], Step [156/225], Training Accuracy: 97.2055%, Training Loss: 0.0796%\n",
      "Epoch [98/300], Step [157/225], Training Accuracy: 97.2034%, Training Loss: 0.0799%\n",
      "Epoch [98/300], Step [158/225], Training Accuracy: 97.1915%, Training Loss: 0.0806%\n",
      "Epoch [98/300], Step [159/225], Training Accuracy: 97.2091%, Training Loss: 0.0803%\n",
      "Epoch [98/300], Step [160/225], Training Accuracy: 97.2266%, Training Loss: 0.0800%\n",
      "Epoch [98/300], Step [161/225], Training Accuracy: 97.2244%, Training Loss: 0.0799%\n",
      "Epoch [98/300], Step [162/225], Training Accuracy: 97.2222%, Training Loss: 0.0799%\n",
      "Epoch [98/300], Step [163/225], Training Accuracy: 97.2201%, Training Loss: 0.0802%\n",
      "Epoch [98/300], Step [164/225], Training Accuracy: 97.2370%, Training Loss: 0.0798%\n",
      "Epoch [98/300], Step [165/225], Training Accuracy: 97.2159%, Training Loss: 0.0802%\n",
      "Epoch [98/300], Step [166/225], Training Accuracy: 97.2139%, Training Loss: 0.0804%\n",
      "Epoch [98/300], Step [167/225], Training Accuracy: 97.2118%, Training Loss: 0.0804%\n",
      "Epoch [98/300], Step [168/225], Training Accuracy: 97.2191%, Training Loss: 0.0802%\n",
      "Epoch [98/300], Step [169/225], Training Accuracy: 97.1986%, Training Loss: 0.0809%\n",
      "Epoch [98/300], Step [170/225], Training Accuracy: 97.1875%, Training Loss: 0.0811%\n",
      "Epoch [98/300], Step [171/225], Training Accuracy: 97.1765%, Training Loss: 0.0813%\n",
      "Epoch [98/300], Step [172/225], Training Accuracy: 97.1748%, Training Loss: 0.0811%\n",
      "Epoch [98/300], Step [173/225], Training Accuracy: 97.1730%, Training Loss: 0.0814%\n",
      "Epoch [98/300], Step [174/225], Training Accuracy: 97.1893%, Training Loss: 0.0810%\n",
      "Epoch [98/300], Step [175/225], Training Accuracy: 97.2054%, Training Loss: 0.0807%\n",
      "Epoch [98/300], Step [176/225], Training Accuracy: 97.1946%, Training Loss: 0.0807%\n",
      "Epoch [98/300], Step [177/225], Training Accuracy: 97.1840%, Training Loss: 0.0808%\n",
      "Epoch [98/300], Step [178/225], Training Accuracy: 97.1910%, Training Loss: 0.0807%\n",
      "Epoch [98/300], Step [179/225], Training Accuracy: 97.1805%, Training Loss: 0.0810%\n",
      "Epoch [98/300], Step [180/225], Training Accuracy: 97.1875%, Training Loss: 0.0811%\n",
      "Epoch [98/300], Step [181/225], Training Accuracy: 97.1858%, Training Loss: 0.0812%\n",
      "Epoch [98/300], Step [182/225], Training Accuracy: 97.2012%, Training Loss: 0.0810%\n",
      "Epoch [98/300], Step [183/225], Training Accuracy: 97.2080%, Training Loss: 0.0808%\n",
      "Epoch [98/300], Step [184/225], Training Accuracy: 97.2062%, Training Loss: 0.0808%\n",
      "Epoch [98/300], Step [185/225], Training Accuracy: 97.2128%, Training Loss: 0.0808%\n",
      "Epoch [98/300], Step [186/225], Training Accuracy: 97.2110%, Training Loss: 0.0808%\n",
      "Epoch [98/300], Step [187/225], Training Accuracy: 97.2176%, Training Loss: 0.0807%\n",
      "Epoch [98/300], Step [188/225], Training Accuracy: 97.2158%, Training Loss: 0.0806%\n",
      "Epoch [98/300], Step [189/225], Training Accuracy: 97.2305%, Training Loss: 0.0803%\n",
      "Epoch [98/300], Step [190/225], Training Accuracy: 97.2368%, Training Loss: 0.0801%\n",
      "Epoch [98/300], Step [191/225], Training Accuracy: 97.2268%, Training Loss: 0.0804%\n",
      "Epoch [98/300], Step [192/225], Training Accuracy: 97.2331%, Training Loss: 0.0801%\n",
      "Epoch [98/300], Step [193/225], Training Accuracy: 97.2231%, Training Loss: 0.0806%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/300], Step [194/225], Training Accuracy: 97.2133%, Training Loss: 0.0807%\n",
      "Epoch [98/300], Step [195/225], Training Accuracy: 97.2196%, Training Loss: 0.0808%\n",
      "Epoch [98/300], Step [196/225], Training Accuracy: 97.2258%, Training Loss: 0.0806%\n",
      "Epoch [98/300], Step [197/225], Training Accuracy: 97.2240%, Training Loss: 0.0806%\n",
      "Epoch [98/300], Step [198/225], Training Accuracy: 97.2064%, Training Loss: 0.0808%\n",
      "Epoch [98/300], Step [199/225], Training Accuracy: 97.1812%, Training Loss: 0.0815%\n",
      "Epoch [98/300], Step [200/225], Training Accuracy: 97.1875%, Training Loss: 0.0815%\n",
      "Epoch [98/300], Step [201/225], Training Accuracy: 97.1937%, Training Loss: 0.0814%\n",
      "Epoch [98/300], Step [202/225], Training Accuracy: 97.1767%, Training Loss: 0.0814%\n",
      "Epoch [98/300], Step [203/225], Training Accuracy: 97.1752%, Training Loss: 0.0814%\n",
      "Epoch [98/300], Step [204/225], Training Accuracy: 97.1814%, Training Loss: 0.0813%\n",
      "Epoch [98/300], Step [205/225], Training Accuracy: 97.1875%, Training Loss: 0.0812%\n",
      "Epoch [98/300], Step [206/225], Training Accuracy: 97.1556%, Training Loss: 0.0816%\n",
      "Epoch [98/300], Step [207/225], Training Accuracy: 97.1694%, Training Loss: 0.0814%\n",
      "Epoch [98/300], Step [208/225], Training Accuracy: 97.1680%, Training Loss: 0.0813%\n",
      "Epoch [98/300], Step [209/225], Training Accuracy: 97.1441%, Training Loss: 0.0818%\n",
      "Epoch [98/300], Step [210/225], Training Accuracy: 97.1503%, Training Loss: 0.0817%\n",
      "Epoch [98/300], Step [211/225], Training Accuracy: 97.1564%, Training Loss: 0.0816%\n",
      "Epoch [98/300], Step [212/225], Training Accuracy: 97.1551%, Training Loss: 0.0814%\n",
      "Epoch [98/300], Step [213/225], Training Accuracy: 97.1684%, Training Loss: 0.0814%\n",
      "Epoch [98/300], Step [214/225], Training Accuracy: 97.1598%, Training Loss: 0.0815%\n",
      "Epoch [98/300], Step [215/225], Training Accuracy: 97.1512%, Training Loss: 0.0815%\n",
      "Epoch [98/300], Step [216/225], Training Accuracy: 97.1571%, Training Loss: 0.0815%\n",
      "Epoch [98/300], Step [217/225], Training Accuracy: 97.1558%, Training Loss: 0.0816%\n",
      "Epoch [98/300], Step [218/225], Training Accuracy: 97.1402%, Training Loss: 0.0818%\n",
      "Epoch [98/300], Step [219/225], Training Accuracy: 97.1318%, Training Loss: 0.0817%\n",
      "Epoch [98/300], Step [220/225], Training Accuracy: 97.1165%, Training Loss: 0.0818%\n",
      "Epoch [98/300], Step [221/225], Training Accuracy: 97.1083%, Training Loss: 0.0819%\n",
      "Epoch [98/300], Step [222/225], Training Accuracy: 97.1143%, Training Loss: 0.0818%\n",
      "Epoch [98/300], Step [223/225], Training Accuracy: 97.0992%, Training Loss: 0.0820%\n",
      "Epoch [98/300], Step [224/225], Training Accuracy: 97.1052%, Training Loss: 0.0819%\n",
      "Epoch [98/300], Step [225/225], Training Accuracy: 97.1026%, Training Loss: 0.0819%\n",
      "Epoch [99/300], Step [1/225], Training Accuracy: 98.4375%, Training Loss: 0.0587%\n",
      "Epoch [99/300], Step [2/225], Training Accuracy: 99.2188%, Training Loss: 0.0454%\n",
      "Epoch [99/300], Step [3/225], Training Accuracy: 98.9583%, Training Loss: 0.0531%\n",
      "Epoch [99/300], Step [4/225], Training Accuracy: 98.8281%, Training Loss: 0.0508%\n",
      "Epoch [99/300], Step [5/225], Training Accuracy: 98.1250%, Training Loss: 0.0616%\n",
      "Epoch [99/300], Step [6/225], Training Accuracy: 97.9167%, Training Loss: 0.0651%\n",
      "Epoch [99/300], Step [7/225], Training Accuracy: 97.9911%, Training Loss: 0.0640%\n",
      "Epoch [99/300], Step [8/225], Training Accuracy: 98.0469%, Training Loss: 0.0628%\n",
      "Epoch [99/300], Step [9/225], Training Accuracy: 97.3958%, Training Loss: 0.0717%\n",
      "Epoch [99/300], Step [10/225], Training Accuracy: 97.0312%, Training Loss: 0.0771%\n",
      "Epoch [99/300], Step [11/225], Training Accuracy: 97.3011%, Training Loss: 0.0739%\n",
      "Epoch [99/300], Step [12/225], Training Accuracy: 97.0052%, Training Loss: 0.0797%\n",
      "Epoch [99/300], Step [13/225], Training Accuracy: 96.9952%, Training Loss: 0.0797%\n",
      "Epoch [99/300], Step [14/225], Training Accuracy: 96.9866%, Training Loss: 0.0825%\n",
      "Epoch [99/300], Step [15/225], Training Accuracy: 97.1875%, Training Loss: 0.0794%\n",
      "Epoch [99/300], Step [16/225], Training Accuracy: 97.3633%, Training Loss: 0.0763%\n",
      "Epoch [99/300], Step [17/225], Training Accuracy: 97.4265%, Training Loss: 0.0756%\n",
      "Epoch [99/300], Step [18/225], Training Accuracy: 97.3090%, Training Loss: 0.0789%\n",
      "Epoch [99/300], Step [19/225], Training Accuracy: 97.4507%, Training Loss: 0.0774%\n",
      "Epoch [99/300], Step [20/225], Training Accuracy: 97.5000%, Training Loss: 0.0765%\n",
      "Epoch [99/300], Step [21/225], Training Accuracy: 97.6190%, Training Loss: 0.0746%\n",
      "Epoch [99/300], Step [22/225], Training Accuracy: 97.5852%, Training Loss: 0.0767%\n",
      "Epoch [99/300], Step [23/225], Training Accuracy: 97.6223%, Training Loss: 0.0777%\n",
      "Epoch [99/300], Step [24/225], Training Accuracy: 97.5260%, Training Loss: 0.0780%\n",
      "Epoch [99/300], Step [25/225], Training Accuracy: 97.6250%, Training Loss: 0.0763%\n",
      "Epoch [99/300], Step [26/225], Training Accuracy: 97.6562%, Training Loss: 0.0750%\n",
      "Epoch [99/300], Step [27/225], Training Accuracy: 97.6852%, Training Loss: 0.0738%\n",
      "Epoch [99/300], Step [28/225], Training Accuracy: 97.5446%, Training Loss: 0.0767%\n",
      "Epoch [99/300], Step [29/225], Training Accuracy: 97.5216%, Training Loss: 0.0776%\n",
      "Epoch [99/300], Step [30/225], Training Accuracy: 97.4479%, Training Loss: 0.0784%\n",
      "Epoch [99/300], Step [31/225], Training Accuracy: 97.5302%, Training Loss: 0.0774%\n",
      "Epoch [99/300], Step [32/225], Training Accuracy: 97.5586%, Training Loss: 0.0768%\n",
      "Epoch [99/300], Step [33/225], Training Accuracy: 97.5852%, Training Loss: 0.0758%\n",
      "Epoch [99/300], Step [34/225], Training Accuracy: 97.6562%, Training Loss: 0.0746%\n",
      "Epoch [99/300], Step [35/225], Training Accuracy: 97.6339%, Training Loss: 0.0761%\n",
      "Epoch [99/300], Step [36/225], Training Accuracy: 97.6562%, Training Loss: 0.0758%\n",
      "Epoch [99/300], Step [37/225], Training Accuracy: 97.6774%, Training Loss: 0.0761%\n",
      "Epoch [99/300], Step [38/225], Training Accuracy: 97.6151%, Training Loss: 0.0762%\n",
      "Epoch [99/300], Step [39/225], Training Accuracy: 97.5160%, Training Loss: 0.0769%\n",
      "Epoch [99/300], Step [40/225], Training Accuracy: 97.5000%, Training Loss: 0.0778%\n",
      "Epoch [99/300], Step [41/225], Training Accuracy: 97.4848%, Training Loss: 0.0779%\n",
      "Epoch [99/300], Step [42/225], Training Accuracy: 97.4330%, Training Loss: 0.0778%\n",
      "Epoch [99/300], Step [43/225], Training Accuracy: 97.4201%, Training Loss: 0.0779%\n",
      "Epoch [99/300], Step [44/225], Training Accuracy: 97.4432%, Training Loss: 0.0772%\n",
      "Epoch [99/300], Step [45/225], Training Accuracy: 97.4306%, Training Loss: 0.0779%\n",
      "Epoch [99/300], Step [46/225], Training Accuracy: 97.4864%, Training Loss: 0.0767%\n",
      "Epoch [99/300], Step [47/225], Training Accuracy: 97.4402%, Training Loss: 0.0776%\n",
      "Epoch [99/300], Step [48/225], Training Accuracy: 97.3633%, Training Loss: 0.0810%\n",
      "Epoch [99/300], Step [49/225], Training Accuracy: 97.2895%, Training Loss: 0.0822%\n",
      "Epoch [99/300], Step [50/225], Training Accuracy: 97.2500%, Training Loss: 0.0827%\n",
      "Epoch [99/300], Step [51/225], Training Accuracy: 97.2426%, Training Loss: 0.0823%\n",
      "Epoch [99/300], Step [52/225], Training Accuracy: 97.2356%, Training Loss: 0.0832%\n",
      "Epoch [99/300], Step [53/225], Training Accuracy: 97.2583%, Training Loss: 0.0835%\n",
      "Epoch [99/300], Step [54/225], Training Accuracy: 97.2222%, Training Loss: 0.0836%\n",
      "Epoch [99/300], Step [55/225], Training Accuracy: 97.2727%, Training Loss: 0.0826%\n",
      "Epoch [99/300], Step [56/225], Training Accuracy: 97.2377%, Training Loss: 0.0829%\n",
      "Epoch [99/300], Step [57/225], Training Accuracy: 97.2862%, Training Loss: 0.0820%\n",
      "Epoch [99/300], Step [58/225], Training Accuracy: 97.2522%, Training Loss: 0.0819%\n",
      "Epoch [99/300], Step [59/225], Training Accuracy: 97.2458%, Training Loss: 0.0816%\n",
      "Epoch [99/300], Step [60/225], Training Accuracy: 97.2917%, Training Loss: 0.0808%\n",
      "Epoch [99/300], Step [61/225], Training Accuracy: 97.2848%, Training Loss: 0.0810%\n",
      "Epoch [99/300], Step [62/225], Training Accuracy: 97.2530%, Training Loss: 0.0818%\n",
      "Epoch [99/300], Step [63/225], Training Accuracy: 97.1974%, Training Loss: 0.0823%\n",
      "Epoch [99/300], Step [64/225], Training Accuracy: 97.1924%, Training Loss: 0.0821%\n",
      "Epoch [99/300], Step [65/225], Training Accuracy: 97.2115%, Training Loss: 0.0817%\n",
      "Epoch [99/300], Step [66/225], Training Accuracy: 97.2301%, Training Loss: 0.0819%\n",
      "Epoch [99/300], Step [67/225], Training Accuracy: 97.2481%, Training Loss: 0.0818%\n",
      "Epoch [99/300], Step [68/225], Training Accuracy: 97.2426%, Training Loss: 0.0824%\n",
      "Epoch [99/300], Step [69/225], Training Accuracy: 97.2600%, Training Loss: 0.0824%\n",
      "Epoch [99/300], Step [70/225], Training Accuracy: 97.2545%, Training Loss: 0.0821%\n",
      "Epoch [99/300], Step [71/225], Training Accuracy: 97.2271%, Training Loss: 0.0819%\n",
      "Epoch [99/300], Step [72/225], Training Accuracy: 97.2222%, Training Loss: 0.0816%\n",
      "Epoch [99/300], Step [73/225], Training Accuracy: 97.1961%, Training Loss: 0.0821%\n",
      "Epoch [99/300], Step [74/225], Training Accuracy: 97.1917%, Training Loss: 0.0822%\n",
      "Epoch [99/300], Step [75/225], Training Accuracy: 97.2292%, Training Loss: 0.0817%\n",
      "Epoch [99/300], Step [76/225], Training Accuracy: 97.1834%, Training Loss: 0.0823%\n",
      "Epoch [99/300], Step [77/225], Training Accuracy: 97.1997%, Training Loss: 0.0821%\n",
      "Epoch [99/300], Step [78/225], Training Accuracy: 97.2356%, Training Loss: 0.0816%\n",
      "Epoch [99/300], Step [79/225], Training Accuracy: 97.2112%, Training Loss: 0.0815%\n",
      "Epoch [99/300], Step [80/225], Training Accuracy: 97.1875%, Training Loss: 0.0823%\n",
      "Epoch [99/300], Step [81/225], Training Accuracy: 97.2222%, Training Loss: 0.0815%\n",
      "Epoch [99/300], Step [82/225], Training Accuracy: 97.1989%, Training Loss: 0.0823%\n",
      "Epoch [99/300], Step [83/225], Training Accuracy: 97.1574%, Training Loss: 0.0832%\n",
      "Epoch [99/300], Step [84/225], Training Accuracy: 97.1726%, Training Loss: 0.0827%\n",
      "Epoch [99/300], Step [85/225], Training Accuracy: 97.1691%, Training Loss: 0.0826%\n",
      "Epoch [99/300], Step [86/225], Training Accuracy: 97.1657%, Training Loss: 0.0829%\n",
      "Epoch [99/300], Step [87/225], Training Accuracy: 97.1624%, Training Loss: 0.0829%\n",
      "Epoch [99/300], Step [88/225], Training Accuracy: 97.1768%, Training Loss: 0.0827%\n",
      "Epoch [99/300], Step [89/225], Training Accuracy: 97.1910%, Training Loss: 0.0830%\n",
      "Epoch [99/300], Step [90/225], Training Accuracy: 97.2049%, Training Loss: 0.0827%\n",
      "Epoch [99/300], Step [91/225], Training Accuracy: 97.2184%, Training Loss: 0.0823%\n",
      "Epoch [99/300], Step [92/225], Training Accuracy: 97.2317%, Training Loss: 0.0820%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/300], Step [93/225], Training Accuracy: 97.2446%, Training Loss: 0.0814%\n",
      "Epoch [99/300], Step [94/225], Training Accuracy: 97.2739%, Training Loss: 0.0809%\n",
      "Epoch [99/300], Step [95/225], Training Accuracy: 97.2862%, Training Loss: 0.0807%\n",
      "Epoch [99/300], Step [96/225], Training Accuracy: 97.3145%, Training Loss: 0.0801%\n",
      "Epoch [99/300], Step [97/225], Training Accuracy: 97.3260%, Training Loss: 0.0802%\n",
      "Epoch [99/300], Step [98/225], Training Accuracy: 97.3055%, Training Loss: 0.0806%\n",
      "Epoch [99/300], Step [99/225], Training Accuracy: 97.2854%, Training Loss: 0.0808%\n",
      "Epoch [99/300], Step [100/225], Training Accuracy: 97.2969%, Training Loss: 0.0809%\n",
      "Epoch [99/300], Step [101/225], Training Accuracy: 97.3082%, Training Loss: 0.0808%\n",
      "Epoch [99/300], Step [102/225], Training Accuracy: 97.3039%, Training Loss: 0.0806%\n",
      "Epoch [99/300], Step [103/225], Training Accuracy: 97.2998%, Training Loss: 0.0808%\n",
      "Epoch [99/300], Step [104/225], Training Accuracy: 97.2806%, Training Loss: 0.0810%\n",
      "Epoch [99/300], Step [105/225], Training Accuracy: 97.2619%, Training Loss: 0.0810%\n",
      "Epoch [99/300], Step [106/225], Training Accuracy: 97.2435%, Training Loss: 0.0814%\n",
      "Epoch [99/300], Step [107/225], Training Accuracy: 97.2401%, Training Loss: 0.0816%\n",
      "Epoch [99/300], Step [108/225], Training Accuracy: 97.2512%, Training Loss: 0.0814%\n",
      "Epoch [99/300], Step [109/225], Training Accuracy: 97.2334%, Training Loss: 0.0821%\n",
      "Epoch [99/300], Step [110/225], Training Accuracy: 97.2585%, Training Loss: 0.0818%\n",
      "Epoch [99/300], Step [111/225], Training Accuracy: 97.2551%, Training Loss: 0.0816%\n",
      "Epoch [99/300], Step [112/225], Training Accuracy: 97.2517%, Training Loss: 0.0819%\n",
      "Epoch [99/300], Step [113/225], Training Accuracy: 97.2345%, Training Loss: 0.0819%\n",
      "Epoch [99/300], Step [114/225], Training Accuracy: 97.2314%, Training Loss: 0.0819%\n",
      "Epoch [99/300], Step [115/225], Training Accuracy: 97.2554%, Training Loss: 0.0817%\n",
      "Epoch [99/300], Step [116/225], Training Accuracy: 97.2117%, Training Loss: 0.0827%\n",
      "Epoch [99/300], Step [117/225], Training Accuracy: 97.1955%, Training Loss: 0.0829%\n",
      "Epoch [99/300], Step [118/225], Training Accuracy: 97.1796%, Training Loss: 0.0827%\n",
      "Epoch [99/300], Step [119/225], Training Accuracy: 97.1901%, Training Loss: 0.0825%\n",
      "Epoch [99/300], Step [120/225], Training Accuracy: 97.2135%, Training Loss: 0.0820%\n",
      "Epoch [99/300], Step [121/225], Training Accuracy: 97.2107%, Training Loss: 0.0819%\n",
      "Epoch [99/300], Step [122/225], Training Accuracy: 97.2208%, Training Loss: 0.0820%\n",
      "Epoch [99/300], Step [123/225], Training Accuracy: 97.2180%, Training Loss: 0.0818%\n",
      "Epoch [99/300], Step [124/225], Training Accuracy: 97.2278%, Training Loss: 0.0819%\n",
      "Epoch [99/300], Step [125/225], Training Accuracy: 97.2125%, Training Loss: 0.0820%\n",
      "Epoch [99/300], Step [126/225], Training Accuracy: 97.2222%, Training Loss: 0.0818%\n",
      "Epoch [99/300], Step [127/225], Training Accuracy: 97.2072%, Training Loss: 0.0820%\n",
      "Epoch [99/300], Step [128/225], Training Accuracy: 97.2046%, Training Loss: 0.0822%\n",
      "Epoch [99/300], Step [129/225], Training Accuracy: 97.2141%, Training Loss: 0.0823%\n",
      "Epoch [99/300], Step [130/225], Training Accuracy: 97.1875%, Training Loss: 0.0830%\n",
      "Epoch [99/300], Step [131/225], Training Accuracy: 97.1851%, Training Loss: 0.0831%\n",
      "Epoch [99/300], Step [132/225], Training Accuracy: 97.1946%, Training Loss: 0.0830%\n",
      "Epoch [99/300], Step [133/225], Training Accuracy: 97.1922%, Training Loss: 0.0829%\n",
      "Epoch [99/300], Step [134/225], Training Accuracy: 97.1898%, Training Loss: 0.0829%\n",
      "Epoch [99/300], Step [135/225], Training Accuracy: 97.1528%, Training Loss: 0.0833%\n",
      "Epoch [99/300], Step [136/225], Training Accuracy: 97.1163%, Training Loss: 0.0836%\n",
      "Epoch [99/300], Step [137/225], Training Accuracy: 97.1145%, Training Loss: 0.0834%\n",
      "Epoch [99/300], Step [138/225], Training Accuracy: 97.1241%, Training Loss: 0.0832%\n",
      "Epoch [99/300], Step [139/225], Training Accuracy: 97.1335%, Training Loss: 0.0829%\n",
      "Epoch [99/300], Step [140/225], Training Accuracy: 97.1429%, Training Loss: 0.0830%\n",
      "Epoch [99/300], Step [141/225], Training Accuracy: 97.1520%, Training Loss: 0.0829%\n",
      "Epoch [99/300], Step [142/225], Training Accuracy: 97.1721%, Training Loss: 0.0825%\n",
      "Epoch [99/300], Step [143/225], Training Accuracy: 97.1919%, Training Loss: 0.0822%\n",
      "Epoch [99/300], Step [144/225], Training Accuracy: 97.1680%, Training Loss: 0.0823%\n",
      "Epoch [99/300], Step [145/225], Training Accuracy: 97.1767%, Training Loss: 0.0820%\n",
      "Epoch [99/300], Step [146/225], Training Accuracy: 97.1533%, Training Loss: 0.0821%\n",
      "Epoch [99/300], Step [147/225], Training Accuracy: 97.1620%, Training Loss: 0.0820%\n",
      "Epoch [99/300], Step [148/225], Training Accuracy: 97.1495%, Training Loss: 0.0822%\n",
      "Epoch [99/300], Step [149/225], Training Accuracy: 97.1267%, Training Loss: 0.0827%\n",
      "Epoch [99/300], Step [150/225], Training Accuracy: 97.1250%, Training Loss: 0.0826%\n",
      "Epoch [99/300], Step [151/225], Training Accuracy: 97.1233%, Training Loss: 0.0827%\n",
      "Epoch [99/300], Step [152/225], Training Accuracy: 97.1423%, Training Loss: 0.0824%\n",
      "Epoch [99/300], Step [153/225], Training Accuracy: 97.1507%, Training Loss: 0.0822%\n",
      "Epoch [99/300], Step [154/225], Training Accuracy: 97.1591%, Training Loss: 0.0822%\n",
      "Epoch [99/300], Step [155/225], Training Accuracy: 97.1774%, Training Loss: 0.0819%\n",
      "Epoch [99/300], Step [156/225], Training Accuracy: 97.1955%, Training Loss: 0.0816%\n",
      "Epoch [99/300], Step [157/225], Training Accuracy: 97.1935%, Training Loss: 0.0818%\n",
      "Epoch [99/300], Step [158/225], Training Accuracy: 97.2112%, Training Loss: 0.0815%\n",
      "Epoch [99/300], Step [159/225], Training Accuracy: 97.1993%, Training Loss: 0.0818%\n",
      "Epoch [99/300], Step [160/225], Training Accuracy: 97.1777%, Training Loss: 0.0821%\n",
      "Epoch [99/300], Step [161/225], Training Accuracy: 97.1759%, Training Loss: 0.0819%\n",
      "Epoch [99/300], Step [162/225], Training Accuracy: 97.1644%, Training Loss: 0.0820%\n",
      "Epoch [99/300], Step [163/225], Training Accuracy: 97.1434%, Training Loss: 0.0824%\n",
      "Epoch [99/300], Step [164/225], Training Accuracy: 97.1418%, Training Loss: 0.0825%\n",
      "Epoch [99/300], Step [165/225], Training Accuracy: 97.1496%, Training Loss: 0.0824%\n",
      "Epoch [99/300], Step [166/225], Training Accuracy: 97.1197%, Training Loss: 0.0833%\n",
      "Epoch [99/300], Step [167/225], Training Accuracy: 97.1370%, Training Loss: 0.0829%\n",
      "Epoch [99/300], Step [168/225], Training Accuracy: 97.1354%, Training Loss: 0.0830%\n",
      "Epoch [99/300], Step [169/225], Training Accuracy: 97.1339%, Training Loss: 0.0833%\n",
      "Epoch [99/300], Step [170/225], Training Accuracy: 97.1324%, Training Loss: 0.0833%\n",
      "Epoch [99/300], Step [171/225], Training Accuracy: 97.1126%, Training Loss: 0.0836%\n",
      "Epoch [99/300], Step [172/225], Training Accuracy: 97.1294%, Training Loss: 0.0835%\n",
      "Epoch [99/300], Step [173/225], Training Accuracy: 97.1189%, Training Loss: 0.0835%\n",
      "Epoch [99/300], Step [174/225], Training Accuracy: 97.1175%, Training Loss: 0.0835%\n",
      "Epoch [99/300], Step [175/225], Training Accuracy: 97.1250%, Training Loss: 0.0837%\n",
      "Epoch [99/300], Step [176/225], Training Accuracy: 97.1058%, Training Loss: 0.0838%\n",
      "Epoch [99/300], Step [177/225], Training Accuracy: 97.1045%, Training Loss: 0.0838%\n",
      "Epoch [99/300], Step [178/225], Training Accuracy: 97.1032%, Training Loss: 0.0836%\n",
      "Epoch [99/300], Step [179/225], Training Accuracy: 97.1020%, Training Loss: 0.0835%\n",
      "Epoch [99/300], Step [180/225], Training Accuracy: 97.1094%, Training Loss: 0.0833%\n",
      "Epoch [99/300], Step [181/225], Training Accuracy: 97.1081%, Training Loss: 0.0835%\n",
      "Epoch [99/300], Step [182/225], Training Accuracy: 97.0982%, Training Loss: 0.0837%\n",
      "Epoch [99/300], Step [183/225], Training Accuracy: 97.1055%, Training Loss: 0.0836%\n",
      "Epoch [99/300], Step [184/225], Training Accuracy: 97.1128%, Training Loss: 0.0836%\n",
      "Epoch [99/300], Step [185/225], Training Accuracy: 97.1284%, Training Loss: 0.0833%\n",
      "Epoch [99/300], Step [186/225], Training Accuracy: 97.1354%, Training Loss: 0.0830%\n",
      "Epoch [99/300], Step [187/225], Training Accuracy: 97.1507%, Training Loss: 0.0827%\n",
      "Epoch [99/300], Step [188/225], Training Accuracy: 97.1659%, Training Loss: 0.0825%\n",
      "Epoch [99/300], Step [189/225], Training Accuracy: 97.1644%, Training Loss: 0.0825%\n",
      "Epoch [99/300], Step [190/225], Training Accuracy: 97.1628%, Training Loss: 0.0824%\n",
      "Epoch [99/300], Step [191/225], Training Accuracy: 97.1613%, Training Loss: 0.0825%\n",
      "Epoch [99/300], Step [192/225], Training Accuracy: 97.1598%, Training Loss: 0.0824%\n",
      "Epoch [99/300], Step [193/225], Training Accuracy: 97.1584%, Training Loss: 0.0824%\n",
      "Epoch [99/300], Step [194/225], Training Accuracy: 97.1569%, Training Loss: 0.0824%\n",
      "Epoch [99/300], Step [195/225], Training Accuracy: 97.1635%, Training Loss: 0.0826%\n",
      "Epoch [99/300], Step [196/225], Training Accuracy: 97.1540%, Training Loss: 0.0827%\n",
      "Epoch [99/300], Step [197/225], Training Accuracy: 97.1526%, Training Loss: 0.0828%\n",
      "Epoch [99/300], Step [198/225], Training Accuracy: 97.1670%, Training Loss: 0.0826%\n",
      "Epoch [99/300], Step [199/225], Training Accuracy: 97.1341%, Training Loss: 0.0835%\n",
      "Epoch [99/300], Step [200/225], Training Accuracy: 97.1484%, Training Loss: 0.0832%\n",
      "Epoch [99/300], Step [201/225], Training Accuracy: 97.1471%, Training Loss: 0.0833%\n",
      "Epoch [99/300], Step [202/225], Training Accuracy: 97.1457%, Training Loss: 0.0834%\n",
      "Epoch [99/300], Step [203/225], Training Accuracy: 97.1444%, Training Loss: 0.0834%\n",
      "Epoch [99/300], Step [204/225], Training Accuracy: 97.1431%, Training Loss: 0.0834%\n",
      "Epoch [99/300], Step [205/225], Training Accuracy: 97.1341%, Training Loss: 0.0836%\n",
      "Epoch [99/300], Step [206/225], Training Accuracy: 97.1329%, Training Loss: 0.0837%\n",
      "Epoch [99/300], Step [207/225], Training Accuracy: 97.1316%, Training Loss: 0.0837%\n",
      "Epoch [99/300], Step [208/225], Training Accuracy: 97.1379%, Training Loss: 0.0838%\n",
      "Epoch [99/300], Step [209/225], Training Accuracy: 97.1367%, Training Loss: 0.0840%\n",
      "Epoch [99/300], Step [210/225], Training Accuracy: 97.1354%, Training Loss: 0.0840%\n",
      "Epoch [99/300], Step [211/225], Training Accuracy: 97.1416%, Training Loss: 0.0838%\n",
      "Epoch [99/300], Step [212/225], Training Accuracy: 97.1551%, Training Loss: 0.0836%\n",
      "Epoch [99/300], Step [213/225], Training Accuracy: 97.1538%, Training Loss: 0.0840%\n",
      "Epoch [99/300], Step [214/225], Training Accuracy: 97.1671%, Training Loss: 0.0837%\n",
      "Epoch [99/300], Step [215/225], Training Accuracy: 97.1730%, Training Loss: 0.0837%\n",
      "Epoch [99/300], Step [216/225], Training Accuracy: 97.1644%, Training Loss: 0.0839%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/300], Step [217/225], Training Accuracy: 97.1486%, Training Loss: 0.0842%\n",
      "Epoch [99/300], Step [218/225], Training Accuracy: 97.1474%, Training Loss: 0.0840%\n",
      "Epoch [99/300], Step [219/225], Training Accuracy: 97.1461%, Training Loss: 0.0841%\n",
      "Epoch [99/300], Step [220/225], Training Accuracy: 97.1307%, Training Loss: 0.0844%\n",
      "Epoch [99/300], Step [221/225], Training Accuracy: 97.1366%, Training Loss: 0.0843%\n",
      "Epoch [99/300], Step [222/225], Training Accuracy: 97.1143%, Training Loss: 0.0848%\n",
      "Epoch [99/300], Step [223/225], Training Accuracy: 97.1062%, Training Loss: 0.0850%\n",
      "Epoch [99/300], Step [224/225], Training Accuracy: 97.1122%, Training Loss: 0.0849%\n",
      "Epoch [99/300], Step [225/225], Training Accuracy: 97.1165%, Training Loss: 0.0847%\n",
      "Epoch [100/300], Step [1/225], Training Accuracy: 92.1875%, Training Loss: 0.1238%\n",
      "Epoch [100/300], Step [2/225], Training Accuracy: 95.3125%, Training Loss: 0.1050%\n",
      "Epoch [100/300], Step [3/225], Training Accuracy: 96.3542%, Training Loss: 0.0964%\n",
      "Epoch [100/300], Step [4/225], Training Accuracy: 95.7031%, Training Loss: 0.1034%\n",
      "Epoch [100/300], Step [5/225], Training Accuracy: 95.6250%, Training Loss: 0.1004%\n",
      "Epoch [100/300], Step [6/225], Training Accuracy: 95.5729%, Training Loss: 0.1051%\n",
      "Epoch [100/300], Step [7/225], Training Accuracy: 95.3125%, Training Loss: 0.1072%\n",
      "Epoch [100/300], Step [8/225], Training Accuracy: 95.3125%, Training Loss: 0.1094%\n",
      "Epoch [100/300], Step [9/225], Training Accuracy: 95.8333%, Training Loss: 0.1031%\n",
      "Epoch [100/300], Step [10/225], Training Accuracy: 95.6250%, Training Loss: 0.1076%\n",
      "Epoch [100/300], Step [11/225], Training Accuracy: 95.7386%, Training Loss: 0.1050%\n",
      "Epoch [100/300], Step [12/225], Training Accuracy: 95.8333%, Training Loss: 0.1024%\n",
      "Epoch [100/300], Step [13/225], Training Accuracy: 96.0337%, Training Loss: 0.1008%\n",
      "Epoch [100/300], Step [14/225], Training Accuracy: 95.9821%, Training Loss: 0.1083%\n",
      "Epoch [100/300], Step [15/225], Training Accuracy: 96.1458%, Training Loss: 0.1060%\n",
      "Epoch [100/300], Step [16/225], Training Accuracy: 96.3867%, Training Loss: 0.1015%\n",
      "Epoch [100/300], Step [17/225], Training Accuracy: 96.5074%, Training Loss: 0.0984%\n",
      "Epoch [100/300], Step [18/225], Training Accuracy: 96.1806%, Training Loss: 0.1086%\n",
      "Epoch [100/300], Step [19/225], Training Accuracy: 96.2171%, Training Loss: 0.1076%\n",
      "Epoch [100/300], Step [20/225], Training Accuracy: 96.3281%, Training Loss: 0.1048%\n",
      "Epoch [100/300], Step [21/225], Training Accuracy: 96.2798%, Training Loss: 0.1040%\n",
      "Epoch [100/300], Step [22/225], Training Accuracy: 96.3068%, Training Loss: 0.1026%\n",
      "Epoch [100/300], Step [23/225], Training Accuracy: 96.3315%, Training Loss: 0.1011%\n",
      "Epoch [100/300], Step [24/225], Training Accuracy: 96.3542%, Training Loss: 0.1007%\n",
      "Epoch [100/300], Step [25/225], Training Accuracy: 96.5000%, Training Loss: 0.0982%\n",
      "Epoch [100/300], Step [26/225], Training Accuracy: 96.5144%, Training Loss: 0.0970%\n",
      "Epoch [100/300], Step [27/225], Training Accuracy: 96.4120%, Training Loss: 0.0981%\n",
      "Epoch [100/300], Step [28/225], Training Accuracy: 96.4844%, Training Loss: 0.0963%\n",
      "Epoch [100/300], Step [29/225], Training Accuracy: 96.6056%, Training Loss: 0.0948%\n",
      "Epoch [100/300], Step [30/225], Training Accuracy: 96.5625%, Training Loss: 0.0953%\n",
      "Epoch [100/300], Step [31/225], Training Accuracy: 96.5222%, Training Loss: 0.0948%\n",
      "Epoch [100/300], Step [32/225], Training Accuracy: 96.5332%, Training Loss: 0.0935%\n",
      "Epoch [100/300], Step [33/225], Training Accuracy: 96.6383%, Training Loss: 0.0922%\n",
      "Epoch [100/300], Step [34/225], Training Accuracy: 96.6912%, Training Loss: 0.0914%\n",
      "Epoch [100/300], Step [35/225], Training Accuracy: 96.6071%, Training Loss: 0.0927%\n",
      "Epoch [100/300], Step [36/225], Training Accuracy: 96.6580%, Training Loss: 0.0917%\n",
      "Epoch [100/300], Step [37/225], Training Accuracy: 96.7483%, Training Loss: 0.0907%\n",
      "Epoch [100/300], Step [38/225], Training Accuracy: 96.7516%, Training Loss: 0.0907%\n",
      "Epoch [100/300], Step [39/225], Training Accuracy: 96.7548%, Training Loss: 0.0910%\n",
      "Epoch [100/300], Step [40/225], Training Accuracy: 96.7578%, Training Loss: 0.0904%\n",
      "Epoch [100/300], Step [41/225], Training Accuracy: 96.7988%, Training Loss: 0.0896%\n",
      "Epoch [100/300], Step [42/225], Training Accuracy: 96.7634%, Training Loss: 0.0904%\n",
      "Epoch [100/300], Step [43/225], Training Accuracy: 96.7660%, Training Loss: 0.0896%\n",
      "Epoch [100/300], Step [44/225], Training Accuracy: 96.8040%, Training Loss: 0.0884%\n",
      "Epoch [100/300], Step [45/225], Training Accuracy: 96.8056%, Training Loss: 0.0878%\n",
      "Epoch [100/300], Step [46/225], Training Accuracy: 96.7391%, Training Loss: 0.0888%\n",
      "Epoch [100/300], Step [47/225], Training Accuracy: 96.8085%, Training Loss: 0.0878%\n",
      "Epoch [100/300], Step [48/225], Training Accuracy: 96.7773%, Training Loss: 0.0896%\n",
      "Epoch [100/300], Step [49/225], Training Accuracy: 96.7793%, Training Loss: 0.0893%\n",
      "Epoch [100/300], Step [50/225], Training Accuracy: 96.7812%, Training Loss: 0.0888%\n",
      "Epoch [100/300], Step [51/225], Training Accuracy: 96.8444%, Training Loss: 0.0879%\n",
      "Epoch [100/300], Step [52/225], Training Accuracy: 96.8450%, Training Loss: 0.0873%\n",
      "Epoch [100/300], Step [53/225], Training Accuracy: 96.8160%, Training Loss: 0.0883%\n",
      "Epoch [100/300], Step [54/225], Training Accuracy: 96.7882%, Training Loss: 0.0888%\n",
      "Epoch [100/300], Step [55/225], Training Accuracy: 96.7330%, Training Loss: 0.0888%\n",
      "Epoch [100/300], Step [56/225], Training Accuracy: 96.7076%, Training Loss: 0.0903%\n",
      "Epoch [100/300], Step [57/225], Training Accuracy: 96.7105%, Training Loss: 0.0908%\n",
      "Epoch [100/300], Step [58/225], Training Accuracy: 96.7134%, Training Loss: 0.0909%\n",
      "Epoch [100/300], Step [59/225], Training Accuracy: 96.7426%, Training Loss: 0.0907%\n",
      "Epoch [100/300], Step [60/225], Training Accuracy: 96.7708%, Training Loss: 0.0901%\n",
      "Epoch [100/300], Step [61/225], Training Accuracy: 96.7982%, Training Loss: 0.0899%\n",
      "Epoch [100/300], Step [62/225], Training Accuracy: 96.7994%, Training Loss: 0.0892%\n",
      "Epoch [100/300], Step [63/225], Training Accuracy: 96.8254%, Training Loss: 0.0891%\n",
      "Epoch [100/300], Step [64/225], Training Accuracy: 96.7773%, Training Loss: 0.0898%\n",
      "Epoch [100/300], Step [65/225], Training Accuracy: 96.8029%, Training Loss: 0.0895%\n",
      "Epoch [100/300], Step [66/225], Training Accuracy: 96.8513%, Training Loss: 0.0887%\n",
      "Epoch [100/300], Step [67/225], Training Accuracy: 96.8750%, Training Loss: 0.0881%\n",
      "Epoch [100/300], Step [68/225], Training Accuracy: 96.8750%, Training Loss: 0.0878%\n",
      "Epoch [100/300], Step [69/225], Training Accuracy: 96.8750%, Training Loss: 0.0896%\n",
      "Epoch [100/300], Step [70/225], Training Accuracy: 96.8750%, Training Loss: 0.0890%\n",
      "Epoch [100/300], Step [71/225], Training Accuracy: 96.8530%, Training Loss: 0.0892%\n",
      "Epoch [100/300], Step [72/225], Training Accuracy: 96.8316%, Training Loss: 0.0896%\n",
      "Epoch [100/300], Step [73/225], Training Accuracy: 96.8322%, Training Loss: 0.0892%\n",
      "Epoch [100/300], Step [74/225], Training Accuracy: 96.8328%, Training Loss: 0.0890%\n",
      "Epoch [100/300], Step [75/225], Training Accuracy: 96.8125%, Training Loss: 0.0892%\n",
      "Epoch [100/300], Step [76/225], Training Accuracy: 96.8133%, Training Loss: 0.0893%\n",
      "Epoch [100/300], Step [77/225], Training Accuracy: 96.7938%, Training Loss: 0.0895%\n",
      "Epoch [100/300], Step [78/225], Training Accuracy: 96.8149%, Training Loss: 0.0889%\n",
      "Epoch [100/300], Step [79/225], Training Accuracy: 96.8157%, Training Loss: 0.0886%\n",
      "Epoch [100/300], Step [80/225], Training Accuracy: 96.8164%, Training Loss: 0.0884%\n",
      "Epoch [100/300], Step [81/225], Training Accuracy: 96.8557%, Training Loss: 0.0878%\n",
      "Epoch [100/300], Step [82/225], Training Accuracy: 96.8559%, Training Loss: 0.0880%\n",
      "Epoch [100/300], Step [83/225], Training Accuracy: 96.8562%, Training Loss: 0.0880%\n",
      "Epoch [100/300], Step [84/225], Training Accuracy: 96.8378%, Training Loss: 0.0879%\n",
      "Epoch [100/300], Step [85/225], Training Accuracy: 96.8199%, Training Loss: 0.0881%\n",
      "Epoch [100/300], Step [86/225], Training Accuracy: 96.8205%, Training Loss: 0.0879%\n",
      "Epoch [100/300], Step [87/225], Training Accuracy: 96.7672%, Training Loss: 0.0883%\n",
      "Epoch [100/300], Step [88/225], Training Accuracy: 96.7862%, Training Loss: 0.0881%\n",
      "Epoch [100/300], Step [89/225], Training Accuracy: 96.7872%, Training Loss: 0.0878%\n",
      "Epoch [100/300], Step [90/225], Training Accuracy: 96.8056%, Training Loss: 0.0879%\n",
      "Epoch [100/300], Step [91/225], Training Accuracy: 96.8235%, Training Loss: 0.0878%\n",
      "Epoch [100/300], Step [92/225], Training Accuracy: 96.8410%, Training Loss: 0.0873%\n",
      "Epoch [100/300], Step [93/225], Training Accuracy: 96.8750%, Training Loss: 0.0867%\n",
      "Epoch [100/300], Step [94/225], Training Accuracy: 96.8916%, Training Loss: 0.0863%\n",
      "Epoch [100/300], Step [95/225], Training Accuracy: 96.9079%, Training Loss: 0.0859%\n",
      "Epoch [100/300], Step [96/225], Training Accuracy: 96.8913%, Training Loss: 0.0865%\n",
      "Epoch [100/300], Step [97/225], Training Accuracy: 96.8589%, Training Loss: 0.0873%\n",
      "Epoch [100/300], Step [98/225], Training Accuracy: 96.8591%, Training Loss: 0.0876%\n",
      "Epoch [100/300], Step [99/225], Training Accuracy: 96.8592%, Training Loss: 0.0875%\n",
      "Epoch [100/300], Step [100/225], Training Accuracy: 96.8438%, Training Loss: 0.0873%\n",
      "Epoch [100/300], Step [101/225], Training Accuracy: 96.7976%, Training Loss: 0.0894%\n",
      "Epoch [100/300], Step [102/225], Training Accuracy: 96.7525%, Training Loss: 0.0899%\n",
      "Epoch [100/300], Step [103/225], Training Accuracy: 96.7840%, Training Loss: 0.0895%\n",
      "Epoch [100/300], Step [104/225], Training Accuracy: 96.8149%, Training Loss: 0.0893%\n",
      "Epoch [100/300], Step [105/225], Training Accuracy: 96.8155%, Training Loss: 0.0890%\n",
      "Epoch [100/300], Step [106/225], Training Accuracy: 96.8160%, Training Loss: 0.0893%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/300], Step [107/225], Training Accuracy: 96.8312%, Training Loss: 0.0895%\n",
      "Epoch [100/300], Step [108/225], Training Accuracy: 96.8316%, Training Loss: 0.0895%\n",
      "Epoch [100/300], Step [109/225], Training Accuracy: 96.8607%, Training Loss: 0.0891%\n",
      "Epoch [100/300], Step [110/225], Training Accuracy: 96.8608%, Training Loss: 0.0890%\n",
      "Epoch [100/300], Step [111/225], Training Accuracy: 96.8891%, Training Loss: 0.0886%\n",
      "Epoch [100/300], Step [112/225], Training Accuracy: 96.8750%, Training Loss: 0.0887%\n",
      "Epoch [100/300], Step [113/225], Training Accuracy: 96.8612%, Training Loss: 0.0888%\n",
      "Epoch [100/300], Step [114/225], Training Accuracy: 96.8476%, Training Loss: 0.0889%\n",
      "Epoch [100/300], Step [115/225], Training Accuracy: 96.8478%, Training Loss: 0.0889%\n",
      "Epoch [100/300], Step [116/225], Training Accuracy: 96.8346%, Training Loss: 0.0889%\n",
      "Epoch [100/300], Step [117/225], Training Accuracy: 96.8483%, Training Loss: 0.0887%\n",
      "Epoch [100/300], Step [118/225], Training Accuracy: 96.8353%, Training Loss: 0.0894%\n",
      "Epoch [100/300], Step [119/225], Training Accuracy: 96.8487%, Training Loss: 0.0892%\n",
      "Epoch [100/300], Step [120/225], Training Accuracy: 96.8490%, Training Loss: 0.0890%\n",
      "Epoch [100/300], Step [121/225], Training Accuracy: 96.8750%, Training Loss: 0.0885%\n",
      "Epoch [100/300], Step [122/225], Training Accuracy: 96.8878%, Training Loss: 0.0885%\n",
      "Epoch [100/300], Step [123/225], Training Accuracy: 96.8877%, Training Loss: 0.0883%\n",
      "Epoch [100/300], Step [124/225], Training Accuracy: 96.9128%, Training Loss: 0.0879%\n",
      "Epoch [100/300], Step [125/225], Training Accuracy: 96.9125%, Training Loss: 0.0878%\n",
      "Epoch [100/300], Step [126/225], Training Accuracy: 96.9246%, Training Loss: 0.0876%\n",
      "Epoch [100/300], Step [127/225], Training Accuracy: 96.9488%, Training Loss: 0.0872%\n",
      "Epoch [100/300], Step [128/225], Training Accuracy: 96.9116%, Training Loss: 0.0882%\n",
      "Epoch [100/300], Step [129/225], Training Accuracy: 96.9234%, Training Loss: 0.0881%\n",
      "Epoch [100/300], Step [130/225], Training Accuracy: 96.8990%, Training Loss: 0.0884%\n",
      "Epoch [100/300], Step [131/225], Training Accuracy: 96.9227%, Training Loss: 0.0880%\n",
      "Epoch [100/300], Step [132/225], Training Accuracy: 96.9342%, Training Loss: 0.0880%\n",
      "Epoch [100/300], Step [133/225], Training Accuracy: 96.9220%, Training Loss: 0.0882%\n",
      "Epoch [100/300], Step [134/225], Training Accuracy: 96.9333%, Training Loss: 0.0880%\n",
      "Epoch [100/300], Step [135/225], Training Accuracy: 96.9213%, Training Loss: 0.0880%\n",
      "Epoch [100/300], Step [136/225], Training Accuracy: 96.9324%, Training Loss: 0.0878%\n",
      "Epoch [100/300], Step [137/225], Training Accuracy: 96.9434%, Training Loss: 0.0876%\n",
      "Epoch [100/300], Step [138/225], Training Accuracy: 96.9429%, Training Loss: 0.0876%\n",
      "Epoch [100/300], Step [139/225], Training Accuracy: 96.9424%, Training Loss: 0.0875%\n",
      "Epoch [100/300], Step [140/225], Training Accuracy: 96.9308%, Training Loss: 0.0878%\n",
      "Epoch [100/300], Step [141/225], Training Accuracy: 96.9193%, Training Loss: 0.0882%\n",
      "Epoch [100/300], Step [142/225], Training Accuracy: 96.9190%, Training Loss: 0.0882%\n",
      "Epoch [100/300], Step [143/225], Training Accuracy: 96.9296%, Training Loss: 0.0881%\n",
      "Epoch [100/300], Step [144/225], Training Accuracy: 96.9401%, Training Loss: 0.0877%\n",
      "Epoch [100/300], Step [145/225], Training Accuracy: 96.9612%, Training Loss: 0.0871%\n",
      "Epoch [100/300], Step [146/225], Training Accuracy: 96.9499%, Training Loss: 0.0872%\n",
      "Epoch [100/300], Step [147/225], Training Accuracy: 96.9388%, Training Loss: 0.0875%\n",
      "Epoch [100/300], Step [148/225], Training Accuracy: 96.9383%, Training Loss: 0.0873%\n",
      "Epoch [100/300], Step [149/225], Training Accuracy: 96.9065%, Training Loss: 0.0877%\n",
      "Epoch [100/300], Step [150/225], Training Accuracy: 96.9062%, Training Loss: 0.0875%\n",
      "Epoch [100/300], Step [151/225], Training Accuracy: 96.8957%, Training Loss: 0.0876%\n",
      "Epoch [100/300], Step [152/225], Training Accuracy: 96.8853%, Training Loss: 0.0876%\n",
      "Epoch [100/300], Step [153/225], Training Accuracy: 96.8852%, Training Loss: 0.0876%\n",
      "Epoch [100/300], Step [154/225], Training Accuracy: 96.8446%, Training Loss: 0.0884%\n",
      "Epoch [100/300], Step [155/225], Training Accuracy: 96.8548%, Training Loss: 0.0882%\n",
      "Epoch [100/300], Step [156/225], Training Accuracy: 96.8650%, Training Loss: 0.0879%\n",
      "Epoch [100/300], Step [157/225], Training Accuracy: 96.8650%, Training Loss: 0.0878%\n",
      "Epoch [100/300], Step [158/225], Training Accuracy: 96.8750%, Training Loss: 0.0878%\n",
      "Epoch [100/300], Step [159/225], Training Accuracy: 96.8357%, Training Loss: 0.0883%\n",
      "Epoch [100/300], Step [160/225], Training Accuracy: 96.8555%, Training Loss: 0.0879%\n",
      "Epoch [100/300], Step [161/225], Training Accuracy: 96.8459%, Training Loss: 0.0881%\n",
      "Epoch [100/300], Step [162/225], Training Accuracy: 96.8461%, Training Loss: 0.0882%\n",
      "Epoch [100/300], Step [163/225], Training Accuracy: 96.8558%, Training Loss: 0.0882%\n",
      "Epoch [100/300], Step [164/225], Training Accuracy: 96.8559%, Training Loss: 0.0882%\n",
      "Epoch [100/300], Step [165/225], Training Accuracy: 96.8561%, Training Loss: 0.0881%\n",
      "Epoch [100/300], Step [166/225], Training Accuracy: 96.8279%, Training Loss: 0.0885%\n",
      "Epoch [100/300], Step [167/225], Training Accuracy: 96.8282%, Training Loss: 0.0887%\n",
      "Epoch [100/300], Step [168/225], Training Accuracy: 96.8378%, Training Loss: 0.0886%\n",
      "Epoch [100/300], Step [169/225], Training Accuracy: 96.8288%, Training Loss: 0.0885%\n",
      "Epoch [100/300], Step [170/225], Training Accuracy: 96.8015%, Training Loss: 0.0890%\n",
      "Epoch [100/300], Step [171/225], Training Accuracy: 96.7928%, Training Loss: 0.0891%\n",
      "Epoch [100/300], Step [172/225], Training Accuracy: 96.8023%, Training Loss: 0.0888%\n",
      "Epoch [100/300], Step [173/225], Training Accuracy: 96.7937%, Training Loss: 0.0893%\n",
      "Epoch [100/300], Step [174/225], Training Accuracy: 96.8032%, Training Loss: 0.0892%\n",
      "Epoch [100/300], Step [175/225], Training Accuracy: 96.7857%, Training Loss: 0.0894%\n",
      "Epoch [100/300], Step [176/225], Training Accuracy: 96.7951%, Training Loss: 0.0892%\n",
      "Epoch [100/300], Step [177/225], Training Accuracy: 96.7956%, Training Loss: 0.0893%\n",
      "Epoch [100/300], Step [178/225], Training Accuracy: 96.8048%, Training Loss: 0.0890%\n",
      "Epoch [100/300], Step [179/225], Training Accuracy: 96.7877%, Training Loss: 0.0891%\n",
      "Epoch [100/300], Step [180/225], Training Accuracy: 96.7882%, Training Loss: 0.0890%\n",
      "Epoch [100/300], Step [181/225], Training Accuracy: 96.7887%, Training Loss: 0.0888%\n",
      "Epoch [100/300], Step [182/225], Training Accuracy: 96.7720%, Training Loss: 0.0891%\n",
      "Epoch [100/300], Step [183/225], Training Accuracy: 96.7725%, Training Loss: 0.0892%\n",
      "Epoch [100/300], Step [184/225], Training Accuracy: 96.7816%, Training Loss: 0.0890%\n",
      "Epoch [100/300], Step [185/225], Training Accuracy: 96.7821%, Training Loss: 0.0889%\n",
      "Epoch [100/300], Step [186/225], Training Accuracy: 96.7994%, Training Loss: 0.0886%\n",
      "Epoch [100/300], Step [187/225], Training Accuracy: 96.7998%, Training Loss: 0.0890%\n",
      "Epoch [100/300], Step [188/225], Training Accuracy: 96.8168%, Training Loss: 0.0887%\n",
      "Epoch [100/300], Step [189/225], Training Accuracy: 96.8254%, Training Loss: 0.0885%\n",
      "Epoch [100/300], Step [190/225], Training Accuracy: 96.8174%, Training Loss: 0.0886%\n",
      "Epoch [100/300], Step [191/225], Training Accuracy: 96.8259%, Training Loss: 0.0884%\n",
      "Epoch [100/300], Step [192/225], Training Accuracy: 96.8343%, Training Loss: 0.0884%\n",
      "Epoch [100/300], Step [193/225], Training Accuracy: 96.8345%, Training Loss: 0.0883%\n",
      "Epoch [100/300], Step [194/225], Training Accuracy: 96.8428%, Training Loss: 0.0883%\n",
      "Epoch [100/300], Step [195/225], Training Accuracy: 96.8189%, Training Loss: 0.0886%\n",
      "Epoch [100/300], Step [196/225], Training Accuracy: 96.8112%, Training Loss: 0.0888%\n",
      "Epoch [100/300], Step [197/225], Training Accuracy: 96.7957%, Training Loss: 0.0890%\n",
      "Epoch [100/300], Step [198/225], Training Accuracy: 96.8040%, Training Loss: 0.0890%\n",
      "Epoch [100/300], Step [199/225], Training Accuracy: 96.8122%, Training Loss: 0.0889%\n",
      "Epoch [100/300], Step [200/225], Training Accuracy: 96.7969%, Training Loss: 0.0890%\n",
      "Epoch [100/300], Step [201/225], Training Accuracy: 96.7895%, Training Loss: 0.0893%\n",
      "Epoch [100/300], Step [202/225], Training Accuracy: 96.7822%, Training Loss: 0.0895%\n",
      "Epoch [100/300], Step [203/225], Training Accuracy: 96.7980%, Training Loss: 0.0892%\n",
      "Epoch [100/300], Step [204/225], Training Accuracy: 96.7984%, Training Loss: 0.0892%\n",
      "Epoch [100/300], Step [205/225], Training Accuracy: 96.8140%, Training Loss: 0.0890%\n",
      "Epoch [100/300], Step [206/225], Training Accuracy: 96.8143%, Training Loss: 0.0889%\n",
      "Epoch [100/300], Step [207/225], Training Accuracy: 96.8146%, Training Loss: 0.0888%\n",
      "Epoch [100/300], Step [208/225], Training Accuracy: 96.7924%, Training Loss: 0.0892%\n",
      "Epoch [100/300], Step [209/225], Training Accuracy: 96.7928%, Training Loss: 0.0890%\n",
      "Epoch [100/300], Step [210/225], Training Accuracy: 96.7857%, Training Loss: 0.0891%\n",
      "Epoch [100/300], Step [211/225], Training Accuracy: 96.7935%, Training Loss: 0.0888%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/300], Step [212/225], Training Accuracy: 96.7939%, Training Loss: 0.0889%\n",
      "Epoch [100/300], Step [213/225], Training Accuracy: 96.7870%, Training Loss: 0.0890%\n",
      "Epoch [100/300], Step [214/225], Training Accuracy: 96.7874%, Training Loss: 0.0889%\n",
      "Epoch [100/300], Step [215/225], Training Accuracy: 96.7878%, Training Loss: 0.0889%\n",
      "Epoch [100/300], Step [216/225], Training Accuracy: 96.7737%, Training Loss: 0.0892%\n",
      "Epoch [100/300], Step [217/225], Training Accuracy: 96.7742%, Training Loss: 0.0894%\n",
      "Epoch [100/300], Step [218/225], Training Accuracy: 96.7675%, Training Loss: 0.0897%\n",
      "Epoch [100/300], Step [219/225], Training Accuracy: 96.7680%, Training Loss: 0.0895%\n",
      "Epoch [100/300], Step [220/225], Training Accuracy: 96.7827%, Training Loss: 0.0892%\n",
      "Epoch [100/300], Step [221/225], Training Accuracy: 96.7902%, Training Loss: 0.0891%\n",
      "Epoch [100/300], Step [222/225], Training Accuracy: 96.7905%, Training Loss: 0.0892%\n",
      "Epoch [100/300], Step [223/225], Training Accuracy: 96.7979%, Training Loss: 0.0890%\n",
      "Epoch [100/300], Step [224/225], Training Accuracy: 96.8122%, Training Loss: 0.0888%\n",
      "Epoch [100/300], Step [225/225], Training Accuracy: 96.8107%, Training Loss: 0.0890%\n",
      "Epoch [101/300], Step [1/225], Training Accuracy: 96.8750%, Training Loss: 0.0952%\n",
      "Epoch [101/300], Step [2/225], Training Accuracy: 96.0938%, Training Loss: 0.0871%\n",
      "Epoch [101/300], Step [3/225], Training Accuracy: 95.8333%, Training Loss: 0.1186%\n",
      "Epoch [101/300], Step [4/225], Training Accuracy: 96.4844%, Training Loss: 0.1016%\n",
      "Epoch [101/300], Step [5/225], Training Accuracy: 96.8750%, Training Loss: 0.0895%\n",
      "Epoch [101/300], Step [6/225], Training Accuracy: 96.6146%, Training Loss: 0.0947%\n",
      "Epoch [101/300], Step [7/225], Training Accuracy: 96.6518%, Training Loss: 0.0945%\n",
      "Epoch [101/300], Step [8/225], Training Accuracy: 96.4844%, Training Loss: 0.0926%\n",
      "Epoch [101/300], Step [9/225], Training Accuracy: 96.8750%, Training Loss: 0.0860%\n",
      "Epoch [101/300], Step [10/225], Training Accuracy: 97.1875%, Training Loss: 0.0827%\n",
      "Epoch [101/300], Step [11/225], Training Accuracy: 97.4432%, Training Loss: 0.0792%\n",
      "Epoch [101/300], Step [12/225], Training Accuracy: 97.2656%, Training Loss: 0.0845%\n",
      "Epoch [101/300], Step [13/225], Training Accuracy: 97.3558%, Training Loss: 0.0814%\n",
      "Epoch [101/300], Step [14/225], Training Accuracy: 97.4330%, Training Loss: 0.0803%\n",
      "Epoch [101/300], Step [15/225], Training Accuracy: 97.3958%, Training Loss: 0.0821%\n",
      "Epoch [101/300], Step [16/225], Training Accuracy: 97.3633%, Training Loss: 0.0812%\n",
      "Epoch [101/300], Step [17/225], Training Accuracy: 97.1507%, Training Loss: 0.0866%\n",
      "Epoch [101/300], Step [18/225], Training Accuracy: 96.7882%, Training Loss: 0.0921%\n",
      "Epoch [101/300], Step [19/225], Training Accuracy: 96.8750%, Training Loss: 0.0896%\n",
      "Epoch [101/300], Step [20/225], Training Accuracy: 96.9531%, Training Loss: 0.0881%\n",
      "Epoch [101/300], Step [21/225], Training Accuracy: 96.8750%, Training Loss: 0.0911%\n",
      "Epoch [101/300], Step [22/225], Training Accuracy: 96.9460%, Training Loss: 0.0897%\n",
      "Epoch [101/300], Step [23/225], Training Accuracy: 96.9429%, Training Loss: 0.0888%\n",
      "Epoch [101/300], Step [24/225], Training Accuracy: 96.9401%, Training Loss: 0.0893%\n",
      "Epoch [101/300], Step [25/225], Training Accuracy: 96.8750%, Training Loss: 0.0902%\n",
      "Epoch [101/300], Step [26/225], Training Accuracy: 96.8149%, Training Loss: 0.0911%\n",
      "Epoch [101/300], Step [27/225], Training Accuracy: 96.9329%, Training Loss: 0.0894%\n",
      "Epoch [101/300], Step [28/225], Training Accuracy: 96.9308%, Training Loss: 0.0889%\n",
      "Epoch [101/300], Step [29/225], Training Accuracy: 96.8750%, Training Loss: 0.0887%\n",
      "Epoch [101/300], Step [30/225], Training Accuracy: 96.8229%, Training Loss: 0.0889%\n",
      "Epoch [101/300], Step [31/225], Training Accuracy: 96.8750%, Training Loss: 0.0881%\n",
      "Epoch [101/300], Step [32/225], Training Accuracy: 96.9238%, Training Loss: 0.0872%\n",
      "Epoch [101/300], Step [33/225], Training Accuracy: 97.0170%, Training Loss: 0.0851%\n",
      "Epoch [101/300], Step [34/225], Training Accuracy: 97.0588%, Training Loss: 0.0844%\n",
      "Epoch [101/300], Step [35/225], Training Accuracy: 97.0536%, Training Loss: 0.0850%\n",
      "Epoch [101/300], Step [36/225], Training Accuracy: 97.0052%, Training Loss: 0.0858%\n",
      "Epoch [101/300], Step [37/225], Training Accuracy: 97.0439%, Training Loss: 0.0847%\n",
      "Epoch [101/300], Step [38/225], Training Accuracy: 96.9984%, Training Loss: 0.0850%\n",
      "Epoch [101/300], Step [39/225], Training Accuracy: 96.9551%, Training Loss: 0.0847%\n",
      "Epoch [101/300], Step [40/225], Training Accuracy: 96.9922%, Training Loss: 0.0844%\n",
      "Epoch [101/300], Step [41/225], Training Accuracy: 96.9893%, Training Loss: 0.0853%\n",
      "Epoch [101/300], Step [42/225], Training Accuracy: 96.9866%, Training Loss: 0.0847%\n",
      "Epoch [101/300], Step [43/225], Training Accuracy: 97.0567%, Training Loss: 0.0834%\n",
      "Epoch [101/300], Step [44/225], Training Accuracy: 97.0881%, Training Loss: 0.0824%\n",
      "Epoch [101/300], Step [45/225], Training Accuracy: 97.1528%, Training Loss: 0.0811%\n",
      "Epoch [101/300], Step [46/225], Training Accuracy: 97.2147%, Training Loss: 0.0797%\n",
      "Epoch [101/300], Step [47/225], Training Accuracy: 97.2074%, Training Loss: 0.0795%\n",
      "Epoch [101/300], Step [48/225], Training Accuracy: 97.2331%, Training Loss: 0.0790%\n",
      "Epoch [101/300], Step [49/225], Training Accuracy: 97.2258%, Training Loss: 0.0788%\n",
      "Epoch [101/300], Step [50/225], Training Accuracy: 97.2500%, Training Loss: 0.0780%\n",
      "Epoch [101/300], Step [51/225], Training Accuracy: 97.2733%, Training Loss: 0.0776%\n",
      "Epoch [101/300], Step [52/225], Training Accuracy: 97.3257%, Training Loss: 0.0763%\n",
      "Epoch [101/300], Step [53/225], Training Accuracy: 97.3172%, Training Loss: 0.0760%\n",
      "Epoch [101/300], Step [54/225], Training Accuracy: 97.3669%, Training Loss: 0.0750%\n",
      "Epoch [101/300], Step [55/225], Training Accuracy: 97.4148%, Training Loss: 0.0739%\n",
      "Epoch [101/300], Step [56/225], Training Accuracy: 97.4609%, Training Loss: 0.0734%\n",
      "Epoch [101/300], Step [57/225], Training Accuracy: 97.4781%, Training Loss: 0.0733%\n",
      "Epoch [101/300], Step [58/225], Training Accuracy: 97.5216%, Training Loss: 0.0731%\n",
      "Epoch [101/300], Step [59/225], Training Accuracy: 97.4841%, Training Loss: 0.0745%\n",
      "Epoch [101/300], Step [60/225], Training Accuracy: 97.4740%, Training Loss: 0.0742%\n",
      "Epoch [101/300], Step [61/225], Training Accuracy: 97.4129%, Training Loss: 0.0753%\n",
      "Epoch [101/300], Step [62/225], Training Accuracy: 97.4546%, Training Loss: 0.0747%\n",
      "Epoch [101/300], Step [63/225], Training Accuracy: 97.4950%, Training Loss: 0.0742%\n",
      "Epoch [101/300], Step [64/225], Training Accuracy: 97.4854%, Training Loss: 0.0744%\n",
      "Epoch [101/300], Step [65/225], Training Accuracy: 97.5240%, Training Loss: 0.0736%\n",
      "Epoch [101/300], Step [66/225], Training Accuracy: 97.5616%, Training Loss: 0.0727%\n",
      "Epoch [101/300], Step [67/225], Training Accuracy: 97.5746%, Training Loss: 0.0725%\n",
      "Epoch [101/300], Step [68/225], Training Accuracy: 97.5643%, Training Loss: 0.0729%\n",
      "Epoch [101/300], Step [69/225], Training Accuracy: 97.5770%, Training Loss: 0.0723%\n",
      "Epoch [101/300], Step [70/225], Training Accuracy: 97.6116%, Training Loss: 0.0717%\n",
      "Epoch [101/300], Step [71/225], Training Accuracy: 97.6232%, Training Loss: 0.0719%\n",
      "Epoch [101/300], Step [72/225], Training Accuracy: 97.6128%, Training Loss: 0.0723%\n",
      "Epoch [101/300], Step [73/225], Training Accuracy: 97.6241%, Training Loss: 0.0718%\n",
      "Epoch [101/300], Step [74/225], Training Accuracy: 97.5929%, Training Loss: 0.0724%\n",
      "Epoch [101/300], Step [75/225], Training Accuracy: 97.5625%, Training Loss: 0.0727%\n",
      "Epoch [101/300], Step [76/225], Training Accuracy: 97.5946%, Training Loss: 0.0724%\n",
      "Epoch [101/300], Step [77/225], Training Accuracy: 97.6258%, Training Loss: 0.0719%\n",
      "Epoch [101/300], Step [78/225], Training Accuracy: 97.6562%, Training Loss: 0.0713%\n",
      "Epoch [101/300], Step [79/225], Training Accuracy: 97.6661%, Training Loss: 0.0710%\n",
      "Epoch [101/300], Step [80/225], Training Accuracy: 97.6953%, Training Loss: 0.0706%\n",
      "Epoch [101/300], Step [81/225], Training Accuracy: 97.7045%, Training Loss: 0.0703%\n",
      "Epoch [101/300], Step [82/225], Training Accuracy: 97.6944%, Training Loss: 0.0702%\n",
      "Epoch [101/300], Step [83/225], Training Accuracy: 97.6280%, Training Loss: 0.0714%\n",
      "Epoch [101/300], Step [84/225], Training Accuracy: 97.6562%, Training Loss: 0.0708%\n",
      "Epoch [101/300], Step [85/225], Training Accuracy: 97.6838%, Training Loss: 0.0704%\n",
      "Epoch [101/300], Step [86/225], Training Accuracy: 97.6926%, Training Loss: 0.0701%\n",
      "Epoch [101/300], Step [87/225], Training Accuracy: 97.6652%, Training Loss: 0.0705%\n",
      "Epoch [101/300], Step [88/225], Training Accuracy: 97.6562%, Training Loss: 0.0704%\n",
      "Epoch [101/300], Step [89/225], Training Accuracy: 97.6299%, Training Loss: 0.0713%\n",
      "Epoch [101/300], Step [90/225], Training Accuracy: 97.6042%, Training Loss: 0.0715%\n",
      "Epoch [101/300], Step [91/225], Training Accuracy: 97.6133%, Training Loss: 0.0713%\n",
      "Epoch [101/300], Step [92/225], Training Accuracy: 97.6393%, Training Loss: 0.0708%\n",
      "Epoch [101/300], Step [93/225], Training Accuracy: 97.6647%, Training Loss: 0.0704%\n",
      "Epoch [101/300], Step [94/225], Training Accuracy: 97.6895%, Training Loss: 0.0701%\n",
      "Epoch [101/300], Step [95/225], Training Accuracy: 97.6809%, Training Loss: 0.0705%\n",
      "Epoch [101/300], Step [96/225], Training Accuracy: 97.6888%, Training Loss: 0.0701%\n",
      "Epoch [101/300], Step [97/225], Training Accuracy: 97.6965%, Training Loss: 0.0700%\n",
      "Epoch [101/300], Step [98/225], Training Accuracy: 97.6562%, Training Loss: 0.0710%\n",
      "Epoch [101/300], Step [99/225], Training Accuracy: 97.6799%, Training Loss: 0.0706%\n",
      "Epoch [101/300], Step [100/225], Training Accuracy: 97.6875%, Training Loss: 0.0704%\n",
      "Epoch [101/300], Step [101/225], Training Accuracy: 97.6795%, Training Loss: 0.0706%\n",
      "Epoch [101/300], Step [102/225], Training Accuracy: 97.6869%, Training Loss: 0.0709%\n",
      "Epoch [101/300], Step [103/225], Training Accuracy: 97.6790%, Training Loss: 0.0709%\n",
      "Epoch [101/300], Step [104/225], Training Accuracy: 97.7013%, Training Loss: 0.0705%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [101/300], Step [105/225], Training Accuracy: 97.6786%, Training Loss: 0.0708%\n",
      "Epoch [101/300], Step [106/225], Training Accuracy: 97.6857%, Training Loss: 0.0707%\n",
      "Epoch [101/300], Step [107/225], Training Accuracy: 97.6782%, Training Loss: 0.0704%\n",
      "Epoch [101/300], Step [108/225], Training Accuracy: 97.6707%, Training Loss: 0.0706%\n",
      "Epoch [101/300], Step [109/225], Training Accuracy: 97.6634%, Training Loss: 0.0704%\n",
      "Epoch [101/300], Step [110/225], Training Accuracy: 97.6847%, Training Loss: 0.0700%\n",
      "Epoch [101/300], Step [111/225], Training Accuracy: 97.7055%, Training Loss: 0.0696%\n",
      "Epoch [101/300], Step [112/225], Training Accuracy: 97.7121%, Training Loss: 0.0695%\n",
      "Epoch [101/300], Step [113/225], Training Accuracy: 97.7185%, Training Loss: 0.0692%\n",
      "Epoch [101/300], Step [114/225], Training Accuracy: 97.7111%, Training Loss: 0.0695%\n",
      "Epoch [101/300], Step [115/225], Training Accuracy: 97.7310%, Training Loss: 0.0692%\n",
      "Epoch [101/300], Step [116/225], Training Accuracy: 97.7371%, Training Loss: 0.0694%\n",
      "Epoch [101/300], Step [117/225], Training Accuracy: 97.7431%, Training Loss: 0.0692%\n",
      "Epoch [101/300], Step [118/225], Training Accuracy: 97.7489%, Training Loss: 0.0689%\n",
      "Epoch [101/300], Step [119/225], Training Accuracy: 97.7679%, Training Loss: 0.0687%\n",
      "Epoch [101/300], Step [120/225], Training Accuracy: 97.7734%, Training Loss: 0.0686%\n",
      "Epoch [101/300], Step [121/225], Training Accuracy: 97.7789%, Training Loss: 0.0684%\n",
      "Epoch [101/300], Step [122/225], Training Accuracy: 97.7971%, Training Loss: 0.0679%\n",
      "Epoch [101/300], Step [123/225], Training Accuracy: 97.7642%, Training Loss: 0.0685%\n",
      "Epoch [101/300], Step [124/225], Training Accuracy: 97.7697%, Training Loss: 0.0684%\n",
      "Epoch [101/300], Step [125/225], Training Accuracy: 97.7625%, Training Loss: 0.0682%\n",
      "Epoch [101/300], Step [126/225], Training Accuracy: 97.7679%, Training Loss: 0.0680%\n",
      "Epoch [101/300], Step [127/225], Training Accuracy: 97.7854%, Training Loss: 0.0677%\n",
      "Epoch [101/300], Step [128/225], Training Accuracy: 97.7905%, Training Loss: 0.0676%\n",
      "Epoch [101/300], Step [129/225], Training Accuracy: 97.8077%, Training Loss: 0.0673%\n",
      "Epoch [101/300], Step [130/225], Training Accuracy: 97.8125%, Training Loss: 0.0670%\n",
      "Epoch [101/300], Step [131/225], Training Accuracy: 97.8292%, Training Loss: 0.0667%\n",
      "Epoch [101/300], Step [132/225], Training Accuracy: 97.8338%, Training Loss: 0.0667%\n",
      "Epoch [101/300], Step [133/225], Training Accuracy: 97.8501%, Training Loss: 0.0664%\n",
      "Epoch [101/300], Step [134/225], Training Accuracy: 97.8661%, Training Loss: 0.0661%\n",
      "Epoch [101/300], Step [135/225], Training Accuracy: 97.8704%, Training Loss: 0.0661%\n",
      "Epoch [101/300], Step [136/225], Training Accuracy: 97.8516%, Training Loss: 0.0664%\n",
      "Epoch [101/300], Step [137/225], Training Accuracy: 97.8558%, Training Loss: 0.0663%\n",
      "Epoch [101/300], Step [138/225], Training Accuracy: 97.8487%, Training Loss: 0.0665%\n",
      "Epoch [101/300], Step [139/225], Training Accuracy: 97.8530%, Training Loss: 0.0663%\n",
      "Epoch [101/300], Step [140/225], Training Accuracy: 97.8683%, Training Loss: 0.0661%\n",
      "Epoch [101/300], Step [141/225], Training Accuracy: 97.8613%, Training Loss: 0.0662%\n",
      "Epoch [101/300], Step [142/225], Training Accuracy: 97.8763%, Training Loss: 0.0659%\n",
      "Epoch [101/300], Step [143/225], Training Accuracy: 97.8802%, Training Loss: 0.0659%\n",
      "Epoch [101/300], Step [144/225], Training Accuracy: 97.8950%, Training Loss: 0.0656%\n",
      "Epoch [101/300], Step [145/225], Training Accuracy: 97.8987%, Training Loss: 0.0654%\n",
      "Epoch [101/300], Step [146/225], Training Accuracy: 97.8810%, Training Loss: 0.0657%\n",
      "Epoch [101/300], Step [147/225], Training Accuracy: 97.8954%, Training Loss: 0.0655%\n",
      "Epoch [101/300], Step [148/225], Training Accuracy: 97.8991%, Training Loss: 0.0656%\n",
      "Epoch [101/300], Step [149/225], Training Accuracy: 97.9027%, Training Loss: 0.0656%\n",
      "Epoch [101/300], Step [150/225], Training Accuracy: 97.9167%, Training Loss: 0.0653%\n",
      "Epoch [101/300], Step [151/225], Training Accuracy: 97.9201%, Training Loss: 0.0651%\n",
      "Epoch [101/300], Step [152/225], Training Accuracy: 97.9030%, Training Loss: 0.0653%\n",
      "Epoch [101/300], Step [153/225], Training Accuracy: 97.8962%, Training Loss: 0.0653%\n",
      "Epoch [101/300], Step [154/225], Training Accuracy: 97.9099%, Training Loss: 0.0652%\n",
      "Epoch [101/300], Step [155/225], Training Accuracy: 97.9133%, Training Loss: 0.0650%\n",
      "Epoch [101/300], Step [156/225], Training Accuracy: 97.9267%, Training Loss: 0.0648%\n",
      "Epoch [101/300], Step [157/225], Training Accuracy: 97.9299%, Training Loss: 0.0648%\n",
      "Epoch [101/300], Step [158/225], Training Accuracy: 97.9430%, Training Loss: 0.0646%\n",
      "Epoch [101/300], Step [159/225], Training Accuracy: 97.9560%, Training Loss: 0.0644%\n",
      "Epoch [101/300], Step [160/225], Training Accuracy: 97.9688%, Training Loss: 0.0641%\n",
      "Epoch [101/300], Step [161/225], Training Accuracy: 97.9717%, Training Loss: 0.0640%\n",
      "Epoch [101/300], Step [162/225], Training Accuracy: 97.9745%, Training Loss: 0.0640%\n",
      "Epoch [101/300], Step [163/225], Training Accuracy: 97.9870%, Training Loss: 0.0638%\n",
      "Epoch [101/300], Step [164/225], Training Accuracy: 97.9992%, Training Loss: 0.0636%\n",
      "Epoch [101/300], Step [165/225], Training Accuracy: 98.0114%, Training Loss: 0.0633%\n",
      "Epoch [101/300], Step [166/225], Training Accuracy: 98.0233%, Training Loss: 0.0632%\n",
      "Epoch [101/300], Step [167/225], Training Accuracy: 98.0071%, Training Loss: 0.0634%\n",
      "Epoch [101/300], Step [168/225], Training Accuracy: 98.0097%, Training Loss: 0.0632%\n",
      "Epoch [101/300], Step [169/225], Training Accuracy: 98.0122%, Training Loss: 0.0631%\n",
      "Epoch [101/300], Step [170/225], Training Accuracy: 98.0147%, Training Loss: 0.0631%\n",
      "Epoch [101/300], Step [171/225], Training Accuracy: 98.0080%, Training Loss: 0.0631%\n",
      "Epoch [101/300], Step [172/225], Training Accuracy: 98.0196%, Training Loss: 0.0630%\n",
      "Epoch [101/300], Step [173/225], Training Accuracy: 98.0311%, Training Loss: 0.0628%\n",
      "Epoch [101/300], Step [174/225], Training Accuracy: 98.0424%, Training Loss: 0.0627%\n",
      "Epoch [101/300], Step [175/225], Training Accuracy: 98.0536%, Training Loss: 0.0625%\n",
      "Epoch [101/300], Step [176/225], Training Accuracy: 98.0646%, Training Loss: 0.0622%\n",
      "Epoch [101/300], Step [177/225], Training Accuracy: 98.0756%, Training Loss: 0.0620%\n",
      "Epoch [101/300], Step [178/225], Training Accuracy: 98.0600%, Training Loss: 0.0623%\n",
      "Epoch [101/300], Step [179/225], Training Accuracy: 98.0534%, Training Loss: 0.0623%\n",
      "Epoch [101/300], Step [180/225], Training Accuracy: 98.0642%, Training Loss: 0.0622%\n",
      "Epoch [101/300], Step [181/225], Training Accuracy: 98.0663%, Training Loss: 0.0621%\n",
      "Epoch [101/300], Step [182/225], Training Accuracy: 98.0683%, Training Loss: 0.0620%\n",
      "Epoch [101/300], Step [183/225], Training Accuracy: 98.0704%, Training Loss: 0.0619%\n",
      "Epoch [101/300], Step [184/225], Training Accuracy: 98.0808%, Training Loss: 0.0617%\n",
      "Epoch [101/300], Step [185/225], Training Accuracy: 98.0743%, Training Loss: 0.0618%\n",
      "Epoch [101/300], Step [186/225], Training Accuracy: 98.0595%, Training Loss: 0.0621%\n",
      "Epoch [101/300], Step [187/225], Training Accuracy: 98.0615%, Training Loss: 0.0620%\n",
      "Epoch [101/300], Step [188/225], Training Accuracy: 98.0718%, Training Loss: 0.0618%\n",
      "Epoch [101/300], Step [189/225], Training Accuracy: 98.0737%, Training Loss: 0.0616%\n",
      "Epoch [101/300], Step [190/225], Training Accuracy: 98.0757%, Training Loss: 0.0615%\n",
      "Epoch [101/300], Step [191/225], Training Accuracy: 98.0776%, Training Loss: 0.0614%\n",
      "Epoch [101/300], Step [192/225], Training Accuracy: 98.0632%, Training Loss: 0.0619%\n",
      "Epoch [101/300], Step [193/225], Training Accuracy: 98.0732%, Training Loss: 0.0618%\n",
      "Epoch [101/300], Step [194/225], Training Accuracy: 98.0751%, Training Loss: 0.0619%\n",
      "Epoch [101/300], Step [195/225], Training Accuracy: 98.0849%, Training Loss: 0.0619%\n",
      "Epoch [101/300], Step [196/225], Training Accuracy: 98.0947%, Training Loss: 0.0616%\n",
      "Epoch [101/300], Step [197/225], Training Accuracy: 98.0727%, Training Loss: 0.0619%\n",
      "Epoch [101/300], Step [198/225], Training Accuracy: 98.0745%, Training Loss: 0.0619%\n",
      "Epoch [101/300], Step [199/225], Training Accuracy: 98.0606%, Training Loss: 0.0623%\n",
      "Epoch [101/300], Step [200/225], Training Accuracy: 98.0625%, Training Loss: 0.0622%\n",
      "Epoch [101/300], Step [201/225], Training Accuracy: 98.0644%, Training Loss: 0.0621%\n",
      "Epoch [101/300], Step [202/225], Training Accuracy: 98.0739%, Training Loss: 0.0620%\n",
      "Epoch [101/300], Step [203/225], Training Accuracy: 98.0834%, Training Loss: 0.0618%\n",
      "Epoch [101/300], Step [204/225], Training Accuracy: 98.0928%, Training Loss: 0.0616%\n",
      "Epoch [101/300], Step [205/225], Training Accuracy: 98.1021%, Training Loss: 0.0615%\n",
      "Epoch [101/300], Step [206/225], Training Accuracy: 98.0962%, Training Loss: 0.0618%\n",
      "Epoch [101/300], Step [207/225], Training Accuracy: 98.0903%, Training Loss: 0.0617%\n",
      "Epoch [101/300], Step [208/225], Training Accuracy: 98.0919%, Training Loss: 0.0616%\n",
      "Epoch [101/300], Step [209/225], Training Accuracy: 98.0786%, Training Loss: 0.0618%\n",
      "Epoch [101/300], Step [210/225], Training Accuracy: 98.0506%, Training Loss: 0.0621%\n",
      "Epoch [101/300], Step [211/225], Training Accuracy: 98.0524%, Training Loss: 0.0620%\n",
      "Epoch [101/300], Step [212/225], Training Accuracy: 98.0469%, Training Loss: 0.0619%\n",
      "Epoch [101/300], Step [213/225], Training Accuracy: 98.0560%, Training Loss: 0.0618%\n",
      "Epoch [101/300], Step [214/225], Training Accuracy: 98.0651%, Training Loss: 0.0617%\n",
      "Epoch [101/300], Step [215/225], Training Accuracy: 98.0596%, Training Loss: 0.0619%\n",
      "Epoch [101/300], Step [216/225], Training Accuracy: 98.0541%, Training Loss: 0.0619%\n",
      "Epoch [101/300], Step [217/225], Training Accuracy: 98.0559%, Training Loss: 0.0618%\n",
      "Epoch [101/300], Step [218/225], Training Accuracy: 98.0648%, Training Loss: 0.0616%\n",
      "Epoch [101/300], Step [219/225], Training Accuracy: 98.0736%, Training Loss: 0.0615%\n",
      "Epoch [101/300], Step [220/225], Training Accuracy: 98.0682%, Training Loss: 0.0614%\n",
      "Epoch [101/300], Step [221/225], Training Accuracy: 98.0769%, Training Loss: 0.0612%\n",
      "Epoch [101/300], Step [222/225], Training Accuracy: 98.0785%, Training Loss: 0.0611%\n",
      "Epoch [101/300], Step [223/225], Training Accuracy: 98.0732%, Training Loss: 0.0612%\n",
      "Epoch [101/300], Step [224/225], Training Accuracy: 98.0818%, Training Loss: 0.0611%\n",
      "Epoch [101/300], Step [225/225], Training Accuracy: 98.0892%, Training Loss: 0.0609%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [102/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0333%\n",
      "Epoch [102/300], Step [2/225], Training Accuracy: 98.4375%, Training Loss: 0.0879%\n",
      "Epoch [102/300], Step [3/225], Training Accuracy: 98.4375%, Training Loss: 0.0776%\n",
      "Epoch [102/300], Step [4/225], Training Accuracy: 98.8281%, Training Loss: 0.0652%\n",
      "Epoch [102/300], Step [5/225], Training Accuracy: 98.7500%, Training Loss: 0.0622%\n",
      "Epoch [102/300], Step [6/225], Training Accuracy: 98.9583%, Training Loss: 0.0561%\n",
      "Epoch [102/300], Step [7/225], Training Accuracy: 97.9911%, Training Loss: 0.0621%\n",
      "Epoch [102/300], Step [8/225], Training Accuracy: 98.2422%, Training Loss: 0.0575%\n",
      "Epoch [102/300], Step [9/225], Training Accuracy: 98.2639%, Training Loss: 0.0556%\n",
      "Epoch [102/300], Step [10/225], Training Accuracy: 98.4375%, Training Loss: 0.0529%\n",
      "Epoch [102/300], Step [11/225], Training Accuracy: 98.2955%, Training Loss: 0.0547%\n",
      "Epoch [102/300], Step [12/225], Training Accuracy: 98.4375%, Training Loss: 0.0528%\n",
      "Epoch [102/300], Step [13/225], Training Accuracy: 98.5577%, Training Loss: 0.0504%\n",
      "Epoch [102/300], Step [14/225], Training Accuracy: 98.4375%, Training Loss: 0.0533%\n",
      "Epoch [102/300], Step [15/225], Training Accuracy: 98.4375%, Training Loss: 0.0519%\n",
      "Epoch [102/300], Step [16/225], Training Accuracy: 98.5352%, Training Loss: 0.0495%\n",
      "Epoch [102/300], Step [17/225], Training Accuracy: 98.5294%, Training Loss: 0.0502%\n",
      "Epoch [102/300], Step [18/225], Training Accuracy: 98.3507%, Training Loss: 0.0526%\n",
      "Epoch [102/300], Step [19/225], Training Accuracy: 98.3553%, Training Loss: 0.0516%\n",
      "Epoch [102/300], Step [20/225], Training Accuracy: 98.4375%, Training Loss: 0.0494%\n",
      "Epoch [102/300], Step [21/225], Training Accuracy: 98.5119%, Training Loss: 0.0484%\n",
      "Epoch [102/300], Step [22/225], Training Accuracy: 98.3665%, Training Loss: 0.0519%\n",
      "Epoch [102/300], Step [23/225], Training Accuracy: 98.4375%, Training Loss: 0.0505%\n",
      "Epoch [102/300], Step [24/225], Training Accuracy: 98.5026%, Training Loss: 0.0497%\n",
      "Epoch [102/300], Step [25/225], Training Accuracy: 98.5000%, Training Loss: 0.0490%\n",
      "Epoch [102/300], Step [26/225], Training Accuracy: 98.3774%, Training Loss: 0.0504%\n",
      "Epoch [102/300], Step [27/225], Training Accuracy: 98.4375%, Training Loss: 0.0491%\n",
      "Epoch [102/300], Step [28/225], Training Accuracy: 98.4933%, Training Loss: 0.0484%\n",
      "Epoch [102/300], Step [29/225], Training Accuracy: 98.5453%, Training Loss: 0.0480%\n",
      "Epoch [102/300], Step [30/225], Training Accuracy: 98.5938%, Training Loss: 0.0476%\n",
      "Epoch [102/300], Step [31/225], Training Accuracy: 98.5383%, Training Loss: 0.0488%\n",
      "Epoch [102/300], Step [32/225], Training Accuracy: 98.5352%, Training Loss: 0.0480%\n",
      "Epoch [102/300], Step [33/225], Training Accuracy: 98.5795%, Training Loss: 0.0473%\n",
      "Epoch [102/300], Step [34/225], Training Accuracy: 98.6213%, Training Loss: 0.0465%\n",
      "Epoch [102/300], Step [35/225], Training Accuracy: 98.5714%, Training Loss: 0.0467%\n",
      "Epoch [102/300], Step [36/225], Training Accuracy: 98.6111%, Training Loss: 0.0459%\n",
      "Epoch [102/300], Step [37/225], Training Accuracy: 98.6064%, Training Loss: 0.0455%\n",
      "Epoch [102/300], Step [38/225], Training Accuracy: 98.5609%, Training Loss: 0.0462%\n",
      "Epoch [102/300], Step [39/225], Training Accuracy: 98.5577%, Training Loss: 0.0476%\n",
      "Epoch [102/300], Step [40/225], Training Accuracy: 98.5938%, Training Loss: 0.0469%\n",
      "Epoch [102/300], Step [41/225], Training Accuracy: 98.5518%, Training Loss: 0.0474%\n",
      "Epoch [102/300], Step [42/225], Training Accuracy: 98.5491%, Training Loss: 0.0471%\n",
      "Epoch [102/300], Step [43/225], Training Accuracy: 98.5465%, Training Loss: 0.0471%\n",
      "Epoch [102/300], Step [44/225], Training Accuracy: 98.5440%, Training Loss: 0.0474%\n",
      "Epoch [102/300], Step [45/225], Training Accuracy: 98.4722%, Training Loss: 0.0489%\n",
      "Epoch [102/300], Step [46/225], Training Accuracy: 98.4715%, Training Loss: 0.0486%\n",
      "Epoch [102/300], Step [47/225], Training Accuracy: 98.4375%, Training Loss: 0.0483%\n",
      "Epoch [102/300], Step [48/225], Training Accuracy: 98.4375%, Training Loss: 0.0480%\n",
      "Epoch [102/300], Step [49/225], Training Accuracy: 98.4375%, Training Loss: 0.0481%\n",
      "Epoch [102/300], Step [50/225], Training Accuracy: 98.4062%, Training Loss: 0.0481%\n",
      "Epoch [102/300], Step [51/225], Training Accuracy: 98.4375%, Training Loss: 0.0475%\n",
      "Epoch [102/300], Step [52/225], Training Accuracy: 98.4675%, Training Loss: 0.0471%\n",
      "Epoch [102/300], Step [53/225], Training Accuracy: 98.4080%, Training Loss: 0.0476%\n",
      "Epoch [102/300], Step [54/225], Training Accuracy: 98.4086%, Training Loss: 0.0484%\n",
      "Epoch [102/300], Step [55/225], Training Accuracy: 98.3807%, Training Loss: 0.0488%\n",
      "Epoch [102/300], Step [56/225], Training Accuracy: 98.3538%, Training Loss: 0.0486%\n",
      "Epoch [102/300], Step [57/225], Training Accuracy: 98.3827%, Training Loss: 0.0484%\n",
      "Epoch [102/300], Step [58/225], Training Accuracy: 98.4106%, Training Loss: 0.0478%\n",
      "Epoch [102/300], Step [59/225], Training Accuracy: 98.4375%, Training Loss: 0.0475%\n",
      "Epoch [102/300], Step [60/225], Training Accuracy: 98.4115%, Training Loss: 0.0479%\n",
      "Epoch [102/300], Step [61/225], Training Accuracy: 98.3607%, Training Loss: 0.0489%\n",
      "Epoch [102/300], Step [62/225], Training Accuracy: 98.3871%, Training Loss: 0.0485%\n",
      "Epoch [102/300], Step [63/225], Training Accuracy: 98.3631%, Training Loss: 0.0488%\n",
      "Epoch [102/300], Step [64/225], Training Accuracy: 98.3887%, Training Loss: 0.0485%\n",
      "Epoch [102/300], Step [65/225], Training Accuracy: 98.4135%, Training Loss: 0.0480%\n",
      "Epoch [102/300], Step [66/225], Training Accuracy: 98.4375%, Training Loss: 0.0475%\n",
      "Epoch [102/300], Step [67/225], Training Accuracy: 98.4142%, Training Loss: 0.0480%\n",
      "Epoch [102/300], Step [68/225], Training Accuracy: 98.4145%, Training Loss: 0.0480%\n",
      "Epoch [102/300], Step [69/225], Training Accuracy: 98.4149%, Training Loss: 0.0478%\n",
      "Epoch [102/300], Step [70/225], Training Accuracy: 98.4375%, Training Loss: 0.0474%\n",
      "Epoch [102/300], Step [71/225], Training Accuracy: 98.4375%, Training Loss: 0.0472%\n",
      "Epoch [102/300], Step [72/225], Training Accuracy: 98.4375%, Training Loss: 0.0471%\n",
      "Epoch [102/300], Step [73/225], Training Accuracy: 98.4589%, Training Loss: 0.0470%\n",
      "Epoch [102/300], Step [74/225], Training Accuracy: 98.4797%, Training Loss: 0.0466%\n",
      "Epoch [102/300], Step [75/225], Training Accuracy: 98.5000%, Training Loss: 0.0464%\n",
      "Epoch [102/300], Step [76/225], Training Accuracy: 98.4992%, Training Loss: 0.0463%\n",
      "Epoch [102/300], Step [77/225], Training Accuracy: 98.4984%, Training Loss: 0.0462%\n",
      "Epoch [102/300], Step [78/225], Training Accuracy: 98.5176%, Training Loss: 0.0458%\n",
      "Epoch [102/300], Step [79/225], Training Accuracy: 98.5166%, Training Loss: 0.0456%\n",
      "Epoch [102/300], Step [80/225], Training Accuracy: 98.5352%, Training Loss: 0.0455%\n",
      "Epoch [102/300], Step [81/225], Training Accuracy: 98.5340%, Training Loss: 0.0457%\n",
      "Epoch [102/300], Step [82/225], Training Accuracy: 98.5328%, Training Loss: 0.0456%\n",
      "Epoch [102/300], Step [83/225], Training Accuracy: 98.5128%, Training Loss: 0.0461%\n",
      "Epoch [102/300], Step [84/225], Training Accuracy: 98.5305%, Training Loss: 0.0459%\n",
      "Epoch [102/300], Step [85/225], Training Accuracy: 98.5294%, Training Loss: 0.0457%\n",
      "Epoch [102/300], Step [86/225], Training Accuracy: 98.4920%, Training Loss: 0.0468%\n",
      "Epoch [102/300], Step [87/225], Training Accuracy: 98.4914%, Training Loss: 0.0472%\n",
      "Epoch [102/300], Step [88/225], Training Accuracy: 98.4553%, Training Loss: 0.0478%\n",
      "Epoch [102/300], Step [89/225], Training Accuracy: 98.4375%, Training Loss: 0.0483%\n",
      "Epoch [102/300], Step [90/225], Training Accuracy: 98.4549%, Training Loss: 0.0480%\n",
      "Epoch [102/300], Step [91/225], Training Accuracy: 98.4718%, Training Loss: 0.0478%\n",
      "Epoch [102/300], Step [92/225], Training Accuracy: 98.4885%, Training Loss: 0.0479%\n",
      "Epoch [102/300], Step [93/225], Training Accuracy: 98.5047%, Training Loss: 0.0478%\n",
      "Epoch [102/300], Step [94/225], Training Accuracy: 98.5040%, Training Loss: 0.0478%\n",
      "Epoch [102/300], Step [95/225], Training Accuracy: 98.5033%, Training Loss: 0.0476%\n",
      "Epoch [102/300], Step [96/225], Training Accuracy: 98.5026%, Training Loss: 0.0475%\n",
      "Epoch [102/300], Step [97/225], Training Accuracy: 98.5019%, Training Loss: 0.0476%\n",
      "Epoch [102/300], Step [98/225], Training Accuracy: 98.4853%, Training Loss: 0.0479%\n",
      "Epoch [102/300], Step [99/225], Training Accuracy: 98.4848%, Training Loss: 0.0480%\n",
      "Epoch [102/300], Step [100/225], Training Accuracy: 98.5000%, Training Loss: 0.0479%\n",
      "Epoch [102/300], Step [101/225], Training Accuracy: 98.5149%, Training Loss: 0.0476%\n",
      "Epoch [102/300], Step [102/225], Training Accuracy: 98.5294%, Training Loss: 0.0474%\n",
      "Epoch [102/300], Step [103/225], Training Accuracy: 98.5437%, Training Loss: 0.0473%\n",
      "Epoch [102/300], Step [104/225], Training Accuracy: 98.5427%, Training Loss: 0.0472%\n",
      "Epoch [102/300], Step [105/225], Training Accuracy: 98.5268%, Training Loss: 0.0474%\n",
      "Epoch [102/300], Step [106/225], Training Accuracy: 98.5407%, Training Loss: 0.0473%\n",
      "Epoch [102/300], Step [107/225], Training Accuracy: 98.5397%, Training Loss: 0.0472%\n",
      "Epoch [102/300], Step [108/225], Training Accuracy: 98.5243%, Training Loss: 0.0474%\n",
      "Epoch [102/300], Step [109/225], Training Accuracy: 98.5378%, Training Loss: 0.0473%\n",
      "Epoch [102/300], Step [110/225], Training Accuracy: 98.5369%, Training Loss: 0.0473%\n",
      "Epoch [102/300], Step [111/225], Training Accuracy: 98.5360%, Training Loss: 0.0472%\n",
      "Epoch [102/300], Step [112/225], Training Accuracy: 98.5491%, Training Loss: 0.0472%\n",
      "Epoch [102/300], Step [113/225], Training Accuracy: 98.5481%, Training Loss: 0.0471%\n",
      "Epoch [102/300], Step [114/225], Training Accuracy: 98.5197%, Training Loss: 0.0476%\n",
      "Epoch [102/300], Step [115/225], Training Accuracy: 98.5326%, Training Loss: 0.0476%\n",
      "Epoch [102/300], Step [116/225], Training Accuracy: 98.5318%, Training Loss: 0.0476%\n",
      "Epoch [102/300], Step [117/225], Training Accuracy: 98.5443%, Training Loss: 0.0472%\n",
      "Epoch [102/300], Step [118/225], Training Accuracy: 98.5567%, Training Loss: 0.0470%\n",
      "Epoch [102/300], Step [119/225], Training Accuracy: 98.5688%, Training Loss: 0.0468%\n",
      "Epoch [102/300], Step [120/225], Training Accuracy: 98.5807%, Training Loss: 0.0465%\n",
      "Epoch [102/300], Step [121/225], Training Accuracy: 98.5925%, Training Loss: 0.0464%\n",
      "Epoch [102/300], Step [122/225], Training Accuracy: 98.6040%, Training Loss: 0.0461%\n",
      "Epoch [102/300], Step [123/225], Training Accuracy: 98.6026%, Training Loss: 0.0461%\n",
      "Epoch [102/300], Step [124/225], Training Accuracy: 98.6139%, Training Loss: 0.0462%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [102/300], Step [125/225], Training Accuracy: 98.6000%, Training Loss: 0.0464%\n",
      "Epoch [102/300], Step [126/225], Training Accuracy: 98.6111%, Training Loss: 0.0462%\n",
      "Epoch [102/300], Step [127/225], Training Accuracy: 98.6220%, Training Loss: 0.0460%\n",
      "Epoch [102/300], Step [128/225], Training Accuracy: 98.6328%, Training Loss: 0.0458%\n",
      "Epoch [102/300], Step [129/225], Training Accuracy: 98.6192%, Training Loss: 0.0461%\n",
      "Epoch [102/300], Step [130/225], Training Accuracy: 98.6298%, Training Loss: 0.0459%\n",
      "Epoch [102/300], Step [131/225], Training Accuracy: 98.6283%, Training Loss: 0.0459%\n",
      "Epoch [102/300], Step [132/225], Training Accuracy: 98.6151%, Training Loss: 0.0461%\n",
      "Epoch [102/300], Step [133/225], Training Accuracy: 98.6255%, Training Loss: 0.0460%\n",
      "Epoch [102/300], Step [134/225], Training Accuracy: 98.6357%, Training Loss: 0.0458%\n",
      "Epoch [102/300], Step [135/225], Training Accuracy: 98.6458%, Training Loss: 0.0456%\n",
      "Epoch [102/300], Step [136/225], Training Accuracy: 98.6443%, Training Loss: 0.0457%\n",
      "Epoch [102/300], Step [137/225], Training Accuracy: 98.6200%, Training Loss: 0.0459%\n",
      "Epoch [102/300], Step [138/225], Training Accuracy: 98.6187%, Training Loss: 0.0459%\n",
      "Epoch [102/300], Step [139/225], Training Accuracy: 98.6286%, Training Loss: 0.0457%\n",
      "Epoch [102/300], Step [140/225], Training Accuracy: 98.6049%, Training Loss: 0.0461%\n",
      "Epoch [102/300], Step [141/225], Training Accuracy: 98.6037%, Training Loss: 0.0461%\n",
      "Epoch [102/300], Step [142/225], Training Accuracy: 98.6136%, Training Loss: 0.0458%\n",
      "Epoch [102/300], Step [143/225], Training Accuracy: 98.6123%, Training Loss: 0.0459%\n",
      "Epoch [102/300], Step [144/225], Training Accuracy: 98.6111%, Training Loss: 0.0459%\n",
      "Epoch [102/300], Step [145/225], Training Accuracy: 98.6099%, Training Loss: 0.0458%\n",
      "Epoch [102/300], Step [146/225], Training Accuracy: 98.6194%, Training Loss: 0.0457%\n",
      "Epoch [102/300], Step [147/225], Training Accuracy: 98.6288%, Training Loss: 0.0455%\n",
      "Epoch [102/300], Step [148/225], Training Accuracy: 98.6170%, Training Loss: 0.0456%\n",
      "Epoch [102/300], Step [149/225], Training Accuracy: 98.6053%, Training Loss: 0.0458%\n",
      "Epoch [102/300], Step [150/225], Training Accuracy: 98.6042%, Training Loss: 0.0458%\n",
      "Epoch [102/300], Step [151/225], Training Accuracy: 98.6031%, Training Loss: 0.0457%\n",
      "Epoch [102/300], Step [152/225], Training Accuracy: 98.6123%, Training Loss: 0.0456%\n",
      "Epoch [102/300], Step [153/225], Training Accuracy: 98.6213%, Training Loss: 0.0454%\n",
      "Epoch [102/300], Step [154/225], Training Accuracy: 98.6303%, Training Loss: 0.0454%\n",
      "Epoch [102/300], Step [155/225], Training Accuracy: 98.6290%, Training Loss: 0.0454%\n",
      "Epoch [102/300], Step [156/225], Training Accuracy: 98.6378%, Training Loss: 0.0452%\n",
      "Epoch [102/300], Step [157/225], Training Accuracy: 98.6465%, Training Loss: 0.0452%\n",
      "Epoch [102/300], Step [158/225], Training Accuracy: 98.6551%, Training Loss: 0.0450%\n",
      "Epoch [102/300], Step [159/225], Training Accuracy: 98.6537%, Training Loss: 0.0450%\n",
      "Epoch [102/300], Step [160/225], Training Accuracy: 98.6621%, Training Loss: 0.0449%\n",
      "Epoch [102/300], Step [161/225], Training Accuracy: 98.6704%, Training Loss: 0.0448%\n",
      "Epoch [102/300], Step [162/225], Training Accuracy: 98.6690%, Training Loss: 0.0448%\n",
      "Epoch [102/300], Step [163/225], Training Accuracy: 98.6771%, Training Loss: 0.0448%\n",
      "Epoch [102/300], Step [164/225], Training Accuracy: 98.6757%, Training Loss: 0.0447%\n",
      "Epoch [102/300], Step [165/225], Training Accuracy: 98.6742%, Training Loss: 0.0446%\n",
      "Epoch [102/300], Step [166/225], Training Accuracy: 98.6822%, Training Loss: 0.0446%\n",
      "Epoch [102/300], Step [167/225], Training Accuracy: 98.6901%, Training Loss: 0.0445%\n",
      "Epoch [102/300], Step [168/225], Training Accuracy: 98.6979%, Training Loss: 0.0443%\n",
      "Epoch [102/300], Step [169/225], Training Accuracy: 98.6779%, Training Loss: 0.0446%\n",
      "Epoch [102/300], Step [170/225], Training Accuracy: 98.6857%, Training Loss: 0.0445%\n",
      "Epoch [102/300], Step [171/225], Training Accuracy: 98.6933%, Training Loss: 0.0443%\n",
      "Epoch [102/300], Step [172/225], Training Accuracy: 98.6919%, Training Loss: 0.0443%\n",
      "Epoch [102/300], Step [173/225], Training Accuracy: 98.6994%, Training Loss: 0.0443%\n",
      "Epoch [102/300], Step [174/225], Training Accuracy: 98.6979%, Training Loss: 0.0442%\n",
      "Epoch [102/300], Step [175/225], Training Accuracy: 98.7054%, Training Loss: 0.0440%\n",
      "Epoch [102/300], Step [176/225], Training Accuracy: 98.7127%, Training Loss: 0.0439%\n",
      "Epoch [102/300], Step [177/225], Training Accuracy: 98.7112%, Training Loss: 0.0438%\n",
      "Epoch [102/300], Step [178/225], Training Accuracy: 98.7008%, Training Loss: 0.0440%\n",
      "Epoch [102/300], Step [179/225], Training Accuracy: 98.7081%, Training Loss: 0.0439%\n",
      "Epoch [102/300], Step [180/225], Training Accuracy: 98.7066%, Training Loss: 0.0439%\n",
      "Epoch [102/300], Step [181/225], Training Accuracy: 98.6965%, Training Loss: 0.0440%\n",
      "Epoch [102/300], Step [182/225], Training Accuracy: 98.7036%, Training Loss: 0.0439%\n",
      "Epoch [102/300], Step [183/225], Training Accuracy: 98.7107%, Training Loss: 0.0438%\n",
      "Epoch [102/300], Step [184/225], Training Accuracy: 98.7092%, Training Loss: 0.0438%\n",
      "Epoch [102/300], Step [185/225], Training Accuracy: 98.7162%, Training Loss: 0.0437%\n",
      "Epoch [102/300], Step [186/225], Training Accuracy: 98.7063%, Training Loss: 0.0438%\n",
      "Epoch [102/300], Step [187/225], Training Accuracy: 98.7132%, Training Loss: 0.0437%\n",
      "Epoch [102/300], Step [188/225], Training Accuracy: 98.7201%, Training Loss: 0.0435%\n",
      "Epoch [102/300], Step [189/225], Training Accuracy: 98.7103%, Training Loss: 0.0435%\n",
      "Epoch [102/300], Step [190/225], Training Accuracy: 98.7089%, Training Loss: 0.0435%\n",
      "Epoch [102/300], Step [191/225], Training Accuracy: 98.7075%, Training Loss: 0.0434%\n",
      "Epoch [102/300], Step [192/225], Training Accuracy: 98.7142%, Training Loss: 0.0433%\n",
      "Epoch [102/300], Step [193/225], Training Accuracy: 98.7128%, Training Loss: 0.0433%\n",
      "Epoch [102/300], Step [194/225], Training Accuracy: 98.7113%, Training Loss: 0.0433%\n",
      "Epoch [102/300], Step [195/225], Training Accuracy: 98.7179%, Training Loss: 0.0432%\n",
      "Epoch [102/300], Step [196/225], Training Accuracy: 98.7165%, Training Loss: 0.0431%\n",
      "Epoch [102/300], Step [197/225], Training Accuracy: 98.7230%, Training Loss: 0.0430%\n",
      "Epoch [102/300], Step [198/225], Training Accuracy: 98.7295%, Training Loss: 0.0429%\n",
      "Epoch [102/300], Step [199/225], Training Accuracy: 98.7359%, Training Loss: 0.0428%\n",
      "Epoch [102/300], Step [200/225], Training Accuracy: 98.7344%, Training Loss: 0.0428%\n",
      "Epoch [102/300], Step [201/225], Training Accuracy: 98.7329%, Training Loss: 0.0428%\n",
      "Epoch [102/300], Step [202/225], Training Accuracy: 98.7314%, Training Loss: 0.0428%\n",
      "Epoch [102/300], Step [203/225], Training Accuracy: 98.7146%, Training Loss: 0.0429%\n",
      "Epoch [102/300], Step [204/225], Training Accuracy: 98.7209%, Training Loss: 0.0428%\n",
      "Epoch [102/300], Step [205/225], Training Accuracy: 98.7195%, Training Loss: 0.0428%\n",
      "Epoch [102/300], Step [206/225], Training Accuracy: 98.7181%, Training Loss: 0.0427%\n",
      "Epoch [102/300], Step [207/225], Training Accuracy: 98.7168%, Training Loss: 0.0426%\n",
      "Epoch [102/300], Step [208/225], Training Accuracy: 98.7079%, Training Loss: 0.0426%\n",
      "Epoch [102/300], Step [209/225], Training Accuracy: 98.7141%, Training Loss: 0.0425%\n",
      "Epoch [102/300], Step [210/225], Training Accuracy: 98.7202%, Training Loss: 0.0423%\n",
      "Epoch [102/300], Step [211/225], Training Accuracy: 98.7115%, Training Loss: 0.0424%\n",
      "Epoch [102/300], Step [212/225], Training Accuracy: 98.7102%, Training Loss: 0.0425%\n",
      "Epoch [102/300], Step [213/225], Training Accuracy: 98.7089%, Training Loss: 0.0425%\n",
      "Epoch [102/300], Step [214/225], Training Accuracy: 98.7077%, Training Loss: 0.0425%\n",
      "Epoch [102/300], Step [215/225], Training Accuracy: 98.7064%, Training Loss: 0.0425%\n",
      "Epoch [102/300], Step [216/225], Training Accuracy: 98.7124%, Training Loss: 0.0425%\n",
      "Epoch [102/300], Step [217/225], Training Accuracy: 98.7183%, Training Loss: 0.0424%\n",
      "Epoch [102/300], Step [218/225], Training Accuracy: 98.7242%, Training Loss: 0.0423%\n",
      "Epoch [102/300], Step [219/225], Training Accuracy: 98.7158%, Training Loss: 0.0424%\n",
      "Epoch [102/300], Step [220/225], Training Accuracy: 98.7216%, Training Loss: 0.0423%\n",
      "Epoch [102/300], Step [221/225], Training Accuracy: 98.7274%, Training Loss: 0.0422%\n",
      "Epoch [102/300], Step [222/225], Training Accuracy: 98.7331%, Training Loss: 0.0421%\n",
      "Epoch [102/300], Step [223/225], Training Accuracy: 98.7318%, Training Loss: 0.0421%\n",
      "Epoch [102/300], Step [224/225], Training Accuracy: 98.7305%, Training Loss: 0.0420%\n",
      "Epoch [102/300], Step [225/225], Training Accuracy: 98.7285%, Training Loss: 0.0420%\n",
      "Epoch [103/300], Step [1/225], Training Accuracy: 98.4375%, Training Loss: 0.0840%\n",
      "Epoch [103/300], Step [2/225], Training Accuracy: 99.2188%, Training Loss: 0.0482%\n",
      "Epoch [103/300], Step [3/225], Training Accuracy: 99.4792%, Training Loss: 0.0455%\n",
      "Epoch [103/300], Step [4/225], Training Accuracy: 99.6094%, Training Loss: 0.0408%\n",
      "Epoch [103/300], Step [5/225], Training Accuracy: 99.3750%, Training Loss: 0.0382%\n",
      "Epoch [103/300], Step [6/225], Training Accuracy: 99.4792%, Training Loss: 0.0344%\n",
      "Epoch [103/300], Step [7/225], Training Accuracy: 99.3304%, Training Loss: 0.0345%\n",
      "Epoch [103/300], Step [8/225], Training Accuracy: 99.2188%, Training Loss: 0.0353%\n",
      "Epoch [103/300], Step [9/225], Training Accuracy: 99.3056%, Training Loss: 0.0334%\n",
      "Epoch [103/300], Step [10/225], Training Accuracy: 99.2188%, Training Loss: 0.0377%\n",
      "Epoch [103/300], Step [11/225], Training Accuracy: 99.1477%, Training Loss: 0.0365%\n",
      "Epoch [103/300], Step [12/225], Training Accuracy: 99.2188%, Training Loss: 0.0345%\n",
      "Epoch [103/300], Step [13/225], Training Accuracy: 99.2788%, Training Loss: 0.0348%\n",
      "Epoch [103/300], Step [14/225], Training Accuracy: 99.3304%, Training Loss: 0.0340%\n",
      "Epoch [103/300], Step [15/225], Training Accuracy: 99.2708%, Training Loss: 0.0366%\n",
      "Epoch [103/300], Step [16/225], Training Accuracy: 99.3164%, Training Loss: 0.0351%\n",
      "Epoch [103/300], Step [17/225], Training Accuracy: 99.3566%, Training Loss: 0.0350%\n",
      "Epoch [103/300], Step [18/225], Training Accuracy: 99.2188%, Training Loss: 0.0372%\n",
      "Epoch [103/300], Step [19/225], Training Accuracy: 99.1776%, Training Loss: 0.0373%\n",
      "Epoch [103/300], Step [20/225], Training Accuracy: 99.2188%, Training Loss: 0.0371%\n",
      "Epoch [103/300], Step [21/225], Training Accuracy: 99.1815%, Training Loss: 0.0367%\n",
      "Epoch [103/300], Step [22/225], Training Accuracy: 99.2188%, Training Loss: 0.0361%\n",
      "Epoch [103/300], Step [23/225], Training Accuracy: 99.1168%, Training Loss: 0.0366%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [103/300], Step [24/225], Training Accuracy: 99.1536%, Training Loss: 0.0362%\n",
      "Epoch [103/300], Step [25/225], Training Accuracy: 99.1875%, Training Loss: 0.0359%\n",
      "Epoch [103/300], Step [26/225], Training Accuracy: 99.2188%, Training Loss: 0.0363%\n",
      "Epoch [103/300], Step [27/225], Training Accuracy: 99.1898%, Training Loss: 0.0367%\n",
      "Epoch [103/300], Step [28/225], Training Accuracy: 99.1629%, Training Loss: 0.0371%\n",
      "Epoch [103/300], Step [29/225], Training Accuracy: 99.1379%, Training Loss: 0.0387%\n",
      "Epoch [103/300], Step [30/225], Training Accuracy: 99.1667%, Training Loss: 0.0381%\n",
      "Epoch [103/300], Step [31/225], Training Accuracy: 99.1935%, Training Loss: 0.0379%\n",
      "Epoch [103/300], Step [32/225], Training Accuracy: 99.2188%, Training Loss: 0.0374%\n",
      "Epoch [103/300], Step [33/225], Training Accuracy: 99.1951%, Training Loss: 0.0371%\n",
      "Epoch [103/300], Step [34/225], Training Accuracy: 99.1728%, Training Loss: 0.0373%\n",
      "Epoch [103/300], Step [35/225], Training Accuracy: 99.1964%, Training Loss: 0.0371%\n",
      "Epoch [103/300], Step [36/225], Training Accuracy: 99.1753%, Training Loss: 0.0371%\n",
      "Epoch [103/300], Step [37/225], Training Accuracy: 99.1976%, Training Loss: 0.0365%\n",
      "Epoch [103/300], Step [38/225], Training Accuracy: 99.1776%, Training Loss: 0.0369%\n",
      "Epoch [103/300], Step [39/225], Training Accuracy: 99.1987%, Training Loss: 0.0371%\n",
      "Epoch [103/300], Step [40/225], Training Accuracy: 99.2188%, Training Loss: 0.0367%\n",
      "Epoch [103/300], Step [41/225], Training Accuracy: 99.2378%, Training Loss: 0.0369%\n",
      "Epoch [103/300], Step [42/225], Training Accuracy: 99.2560%, Training Loss: 0.0363%\n",
      "Epoch [103/300], Step [43/225], Training Accuracy: 99.2369%, Training Loss: 0.0364%\n",
      "Epoch [103/300], Step [44/225], Training Accuracy: 99.2543%, Training Loss: 0.0358%\n",
      "Epoch [103/300], Step [45/225], Training Accuracy: 99.2708%, Training Loss: 0.0355%\n",
      "Epoch [103/300], Step [46/225], Training Accuracy: 99.2867%, Training Loss: 0.0348%\n",
      "Epoch [103/300], Step [47/225], Training Accuracy: 99.2686%, Training Loss: 0.0349%\n",
      "Epoch [103/300], Step [48/225], Training Accuracy: 99.2839%, Training Loss: 0.0345%\n",
      "Epoch [103/300], Step [49/225], Training Accuracy: 99.2985%, Training Loss: 0.0341%\n",
      "Epoch [103/300], Step [50/225], Training Accuracy: 99.3125%, Training Loss: 0.0341%\n",
      "Epoch [103/300], Step [51/225], Training Accuracy: 99.2953%, Training Loss: 0.0342%\n",
      "Epoch [103/300], Step [52/225], Training Accuracy: 99.3089%, Training Loss: 0.0339%\n",
      "Epoch [103/300], Step [53/225], Training Accuracy: 99.2925%, Training Loss: 0.0338%\n",
      "Epoch [103/300], Step [54/225], Training Accuracy: 99.2188%, Training Loss: 0.0347%\n",
      "Epoch [103/300], Step [55/225], Training Accuracy: 99.2330%, Training Loss: 0.0347%\n",
      "Epoch [103/300], Step [56/225], Training Accuracy: 99.2188%, Training Loss: 0.0357%\n",
      "Epoch [103/300], Step [57/225], Training Accuracy: 99.2325%, Training Loss: 0.0356%\n",
      "Epoch [103/300], Step [58/225], Training Accuracy: 99.2457%, Training Loss: 0.0355%\n",
      "Epoch [103/300], Step [59/225], Training Accuracy: 99.2320%, Training Loss: 0.0358%\n",
      "Epoch [103/300], Step [60/225], Training Accuracy: 99.2448%, Training Loss: 0.0358%\n",
      "Epoch [103/300], Step [61/225], Training Accuracy: 99.2316%, Training Loss: 0.0359%\n",
      "Epoch [103/300], Step [62/225], Training Accuracy: 99.2188%, Training Loss: 0.0360%\n",
      "Epoch [103/300], Step [63/225], Training Accuracy: 99.2063%, Training Loss: 0.0362%\n",
      "Epoch [103/300], Step [64/225], Training Accuracy: 99.1943%, Training Loss: 0.0364%\n",
      "Epoch [103/300], Step [65/225], Training Accuracy: 99.1827%, Training Loss: 0.0364%\n",
      "Epoch [103/300], Step [66/225], Training Accuracy: 99.1004%, Training Loss: 0.0382%\n",
      "Epoch [103/300], Step [67/225], Training Accuracy: 99.0672%, Training Loss: 0.0386%\n",
      "Epoch [103/300], Step [68/225], Training Accuracy: 99.0809%, Training Loss: 0.0385%\n",
      "Epoch [103/300], Step [69/225], Training Accuracy: 99.0489%, Training Loss: 0.0387%\n",
      "Epoch [103/300], Step [70/225], Training Accuracy: 99.0179%, Training Loss: 0.0387%\n",
      "Epoch [103/300], Step [71/225], Training Accuracy: 99.0097%, Training Loss: 0.0389%\n",
      "Epoch [103/300], Step [72/225], Training Accuracy: 99.0234%, Training Loss: 0.0386%\n",
      "Epoch [103/300], Step [73/225], Training Accuracy: 98.9940%, Training Loss: 0.0392%\n",
      "Epoch [103/300], Step [74/225], Training Accuracy: 98.9865%, Training Loss: 0.0395%\n",
      "Epoch [103/300], Step [75/225], Training Accuracy: 99.0000%, Training Loss: 0.0391%\n",
      "Epoch [103/300], Step [76/225], Training Accuracy: 99.0132%, Training Loss: 0.0389%\n",
      "Epoch [103/300], Step [77/225], Training Accuracy: 99.0260%, Training Loss: 0.0387%\n",
      "Epoch [103/300], Step [78/225], Training Accuracy: 98.9984%, Training Loss: 0.0390%\n",
      "Epoch [103/300], Step [79/225], Training Accuracy: 98.9913%, Training Loss: 0.0390%\n",
      "Epoch [103/300], Step [80/225], Training Accuracy: 99.0039%, Training Loss: 0.0390%\n",
      "Epoch [103/300], Step [81/225], Training Accuracy: 99.0162%, Training Loss: 0.0387%\n",
      "Epoch [103/300], Step [82/225], Training Accuracy: 99.0282%, Training Loss: 0.0384%\n",
      "Epoch [103/300], Step [83/225], Training Accuracy: 99.0211%, Training Loss: 0.0387%\n",
      "Epoch [103/300], Step [84/225], Training Accuracy: 99.0141%, Training Loss: 0.0388%\n",
      "Epoch [103/300], Step [85/225], Training Accuracy: 99.0257%, Training Loss: 0.0387%\n",
      "Epoch [103/300], Step [86/225], Training Accuracy: 99.0007%, Training Loss: 0.0390%\n",
      "Epoch [103/300], Step [87/225], Training Accuracy: 98.9763%, Training Loss: 0.0394%\n",
      "Epoch [103/300], Step [88/225], Training Accuracy: 98.9879%, Training Loss: 0.0392%\n",
      "Epoch [103/300], Step [89/225], Training Accuracy: 98.9642%, Training Loss: 0.0396%\n",
      "Epoch [103/300], Step [90/225], Training Accuracy: 98.9410%, Training Loss: 0.0398%\n",
      "Epoch [103/300], Step [91/225], Training Accuracy: 98.9526%, Training Loss: 0.0397%\n",
      "Epoch [103/300], Step [92/225], Training Accuracy: 98.9300%, Training Loss: 0.0398%\n",
      "Epoch [103/300], Step [93/225], Training Accuracy: 98.9415%, Training Loss: 0.0397%\n",
      "Epoch [103/300], Step [94/225], Training Accuracy: 98.9528%, Training Loss: 0.0396%\n",
      "Epoch [103/300], Step [95/225], Training Accuracy: 98.9474%, Training Loss: 0.0395%\n",
      "Epoch [103/300], Step [96/225], Training Accuracy: 98.9421%, Training Loss: 0.0395%\n",
      "Epoch [103/300], Step [97/225], Training Accuracy: 98.9530%, Training Loss: 0.0393%\n",
      "Epoch [103/300], Step [98/225], Training Accuracy: 98.9636%, Training Loss: 0.0394%\n",
      "Epoch [103/300], Step [99/225], Training Accuracy: 98.9741%, Training Loss: 0.0392%\n",
      "Epoch [103/300], Step [100/225], Training Accuracy: 98.9844%, Training Loss: 0.0390%\n",
      "Epoch [103/300], Step [101/225], Training Accuracy: 98.9944%, Training Loss: 0.0389%\n",
      "Epoch [103/300], Step [102/225], Training Accuracy: 98.9890%, Training Loss: 0.0389%\n",
      "Epoch [103/300], Step [103/225], Training Accuracy: 98.9836%, Training Loss: 0.0389%\n",
      "Epoch [103/300], Step [104/225], Training Accuracy: 98.9934%, Training Loss: 0.0387%\n",
      "Epoch [103/300], Step [105/225], Training Accuracy: 98.9732%, Training Loss: 0.0395%\n",
      "Epoch [103/300], Step [106/225], Training Accuracy: 98.9829%, Training Loss: 0.0393%\n",
      "Epoch [103/300], Step [107/225], Training Accuracy: 98.9924%, Training Loss: 0.0391%\n",
      "Epoch [103/300], Step [108/225], Training Accuracy: 98.9873%, Training Loss: 0.0392%\n",
      "Epoch [103/300], Step [109/225], Training Accuracy: 98.9966%, Training Loss: 0.0390%\n",
      "Epoch [103/300], Step [110/225], Training Accuracy: 99.0057%, Training Loss: 0.0387%\n",
      "Epoch [103/300], Step [111/225], Training Accuracy: 99.0146%, Training Loss: 0.0385%\n",
      "Epoch [103/300], Step [112/225], Training Accuracy: 99.0234%, Training Loss: 0.0384%\n",
      "Epoch [103/300], Step [113/225], Training Accuracy: 99.0183%, Training Loss: 0.0383%\n",
      "Epoch [103/300], Step [114/225], Training Accuracy: 98.9995%, Training Loss: 0.0385%\n",
      "Epoch [103/300], Step [115/225], Training Accuracy: 98.9810%, Training Loss: 0.0386%\n",
      "Epoch [103/300], Step [116/225], Training Accuracy: 98.9898%, Training Loss: 0.0384%\n",
      "Epoch [103/300], Step [117/225], Training Accuracy: 98.9984%, Training Loss: 0.0383%\n",
      "Epoch [103/300], Step [118/225], Training Accuracy: 99.0069%, Training Loss: 0.0382%\n",
      "Epoch [103/300], Step [119/225], Training Accuracy: 99.0152%, Training Loss: 0.0380%\n",
      "Epoch [103/300], Step [120/225], Training Accuracy: 99.0234%, Training Loss: 0.0380%\n",
      "Epoch [103/300], Step [121/225], Training Accuracy: 99.0315%, Training Loss: 0.0378%\n",
      "Epoch [103/300], Step [122/225], Training Accuracy: 99.0394%, Training Loss: 0.0376%\n",
      "Epoch [103/300], Step [123/225], Training Accuracy: 99.0346%, Training Loss: 0.0375%\n",
      "Epoch [103/300], Step [124/225], Training Accuracy: 99.0297%, Training Loss: 0.0377%\n",
      "Epoch [103/300], Step [125/225], Training Accuracy: 99.0250%, Training Loss: 0.0376%\n",
      "Epoch [103/300], Step [126/225], Training Accuracy: 99.0327%, Training Loss: 0.0375%\n",
      "Epoch [103/300], Step [127/225], Training Accuracy: 99.0404%, Training Loss: 0.0373%\n",
      "Epoch [103/300], Step [128/225], Training Accuracy: 99.0356%, Training Loss: 0.0374%\n",
      "Epoch [103/300], Step [129/225], Training Accuracy: 99.0431%, Training Loss: 0.0373%\n",
      "Epoch [103/300], Step [130/225], Training Accuracy: 99.0385%, Training Loss: 0.0372%\n",
      "Epoch [103/300], Step [131/225], Training Accuracy: 99.0458%, Training Loss: 0.0372%\n",
      "Epoch [103/300], Step [132/225], Training Accuracy: 99.0530%, Training Loss: 0.0371%\n",
      "Epoch [103/300], Step [133/225], Training Accuracy: 99.0484%, Training Loss: 0.0370%\n",
      "Epoch [103/300], Step [134/225], Training Accuracy: 99.0555%, Training Loss: 0.0369%\n",
      "Epoch [103/300], Step [135/225], Training Accuracy: 99.0625%, Training Loss: 0.0367%\n",
      "Epoch [103/300], Step [136/225], Training Accuracy: 99.0579%, Training Loss: 0.0369%\n",
      "Epoch [103/300], Step [137/225], Training Accuracy: 99.0420%, Training Loss: 0.0370%\n",
      "Epoch [103/300], Step [138/225], Training Accuracy: 99.0376%, Training Loss: 0.0371%\n",
      "Epoch [103/300], Step [139/225], Training Accuracy: 99.0445%, Training Loss: 0.0369%\n",
      "Epoch [103/300], Step [140/225], Training Accuracy: 99.0290%, Training Loss: 0.0373%\n",
      "Epoch [103/300], Step [141/225], Training Accuracy: 99.0359%, Training Loss: 0.0372%\n",
      "Epoch [103/300], Step [142/225], Training Accuracy: 99.0317%, Training Loss: 0.0373%\n",
      "Epoch [103/300], Step [143/225], Training Accuracy: 99.0385%, Training Loss: 0.0371%\n",
      "Epoch [103/300], Step [144/225], Training Accuracy: 99.0451%, Training Loss: 0.0370%\n",
      "Epoch [103/300], Step [145/225], Training Accuracy: 99.0409%, Training Loss: 0.0371%\n",
      "Epoch [103/300], Step [146/225], Training Accuracy: 99.0475%, Training Loss: 0.0370%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [103/300], Step [147/225], Training Accuracy: 99.0540%, Training Loss: 0.0368%\n",
      "Epoch [103/300], Step [148/225], Training Accuracy: 99.0498%, Training Loss: 0.0368%\n",
      "Epoch [103/300], Step [149/225], Training Accuracy: 99.0352%, Training Loss: 0.0371%\n",
      "Epoch [103/300], Step [150/225], Training Accuracy: 99.0417%, Training Loss: 0.0371%\n",
      "Epoch [103/300], Step [151/225], Training Accuracy: 99.0480%, Training Loss: 0.0370%\n",
      "Epoch [103/300], Step [152/225], Training Accuracy: 99.0543%, Training Loss: 0.0370%\n",
      "Epoch [103/300], Step [153/225], Training Accuracy: 99.0605%, Training Loss: 0.0369%\n",
      "Epoch [103/300], Step [154/225], Training Accuracy: 99.0463%, Training Loss: 0.0371%\n",
      "Epoch [103/300], Step [155/225], Training Accuracy: 99.0524%, Training Loss: 0.0370%\n",
      "Epoch [103/300], Step [156/225], Training Accuracy: 99.0385%, Training Loss: 0.0372%\n",
      "Epoch [103/300], Step [157/225], Training Accuracy: 99.0247%, Training Loss: 0.0373%\n",
      "Epoch [103/300], Step [158/225], Training Accuracy: 99.0309%, Training Loss: 0.0372%\n",
      "Epoch [103/300], Step [159/225], Training Accuracy: 99.0271%, Training Loss: 0.0372%\n",
      "Epoch [103/300], Step [160/225], Training Accuracy: 99.0332%, Training Loss: 0.0371%\n",
      "Epoch [103/300], Step [161/225], Training Accuracy: 99.0295%, Training Loss: 0.0371%\n",
      "Epoch [103/300], Step [162/225], Training Accuracy: 99.0258%, Training Loss: 0.0372%\n",
      "Epoch [103/300], Step [163/225], Training Accuracy: 99.0318%, Training Loss: 0.0371%\n",
      "Epoch [103/300], Step [164/225], Training Accuracy: 99.0282%, Training Loss: 0.0371%\n",
      "Epoch [103/300], Step [165/225], Training Accuracy: 99.0246%, Training Loss: 0.0372%\n",
      "Epoch [103/300], Step [166/225], Training Accuracy: 99.0211%, Training Loss: 0.0372%\n",
      "Epoch [103/300], Step [167/225], Training Accuracy: 99.0176%, Training Loss: 0.0373%\n",
      "Epoch [103/300], Step [168/225], Training Accuracy: 99.0141%, Training Loss: 0.0374%\n",
      "Epoch [103/300], Step [169/225], Training Accuracy: 99.0015%, Training Loss: 0.0376%\n",
      "Epoch [103/300], Step [170/225], Training Accuracy: 98.9982%, Training Loss: 0.0377%\n",
      "Epoch [103/300], Step [171/225], Training Accuracy: 99.0040%, Training Loss: 0.0375%\n",
      "Epoch [103/300], Step [172/225], Training Accuracy: 98.9916%, Training Loss: 0.0376%\n",
      "Epoch [103/300], Step [173/225], Training Accuracy: 98.9975%, Training Loss: 0.0374%\n",
      "Epoch [103/300], Step [174/225], Training Accuracy: 98.9853%, Training Loss: 0.0375%\n",
      "Epoch [103/300], Step [175/225], Training Accuracy: 98.9911%, Training Loss: 0.0374%\n",
      "Epoch [103/300], Step [176/225], Training Accuracy: 98.9879%, Training Loss: 0.0375%\n",
      "Epoch [103/300], Step [177/225], Training Accuracy: 98.9936%, Training Loss: 0.0376%\n",
      "Epoch [103/300], Step [178/225], Training Accuracy: 98.9817%, Training Loss: 0.0377%\n",
      "Epoch [103/300], Step [179/225], Training Accuracy: 98.9874%, Training Loss: 0.0375%\n",
      "Epoch [103/300], Step [180/225], Training Accuracy: 98.9931%, Training Loss: 0.0374%\n",
      "Epoch [103/300], Step [181/225], Training Accuracy: 98.9986%, Training Loss: 0.0372%\n",
      "Epoch [103/300], Step [182/225], Training Accuracy: 99.0041%, Training Loss: 0.0371%\n",
      "Epoch [103/300], Step [183/225], Training Accuracy: 99.0010%, Training Loss: 0.0372%\n",
      "Epoch [103/300], Step [184/225], Training Accuracy: 98.9980%, Training Loss: 0.0372%\n",
      "Epoch [103/300], Step [185/225], Training Accuracy: 99.0034%, Training Loss: 0.0371%\n",
      "Epoch [103/300], Step [186/225], Training Accuracy: 98.9919%, Training Loss: 0.0373%\n",
      "Epoch [103/300], Step [187/225], Training Accuracy: 98.9973%, Training Loss: 0.0373%\n",
      "Epoch [103/300], Step [188/225], Training Accuracy: 99.0027%, Training Loss: 0.0372%\n",
      "Epoch [103/300], Step [189/225], Training Accuracy: 98.9997%, Training Loss: 0.0372%\n",
      "Epoch [103/300], Step [190/225], Training Accuracy: 99.0049%, Training Loss: 0.0371%\n",
      "Epoch [103/300], Step [191/225], Training Accuracy: 98.9938%, Training Loss: 0.0371%\n",
      "Epoch [103/300], Step [192/225], Training Accuracy: 98.9827%, Training Loss: 0.0373%\n",
      "Epoch [103/300], Step [193/225], Training Accuracy: 98.9799%, Training Loss: 0.0373%\n",
      "Epoch [103/300], Step [194/225], Training Accuracy: 98.9691%, Training Loss: 0.0373%\n",
      "Epoch [103/300], Step [195/225], Training Accuracy: 98.9744%, Training Loss: 0.0373%\n",
      "Epoch [103/300], Step [196/225], Training Accuracy: 98.9796%, Training Loss: 0.0372%\n",
      "Epoch [103/300], Step [197/225], Training Accuracy: 98.9768%, Training Loss: 0.0372%\n",
      "Epoch [103/300], Step [198/225], Training Accuracy: 98.9820%, Training Loss: 0.0371%\n",
      "Epoch [103/300], Step [199/225], Training Accuracy: 98.9793%, Training Loss: 0.0372%\n",
      "Epoch [103/300], Step [200/225], Training Accuracy: 98.9688%, Training Loss: 0.0372%\n",
      "Epoch [103/300], Step [201/225], Training Accuracy: 98.9661%, Training Loss: 0.0373%\n",
      "Epoch [103/300], Step [202/225], Training Accuracy: 98.9712%, Training Loss: 0.0372%\n",
      "Epoch [103/300], Step [203/225], Training Accuracy: 98.9763%, Training Loss: 0.0371%\n",
      "Epoch [103/300], Step [204/225], Training Accuracy: 98.9737%, Training Loss: 0.0371%\n",
      "Epoch [103/300], Step [205/225], Training Accuracy: 98.9787%, Training Loss: 0.0369%\n",
      "Epoch [103/300], Step [206/225], Training Accuracy: 98.9836%, Training Loss: 0.0369%\n",
      "Epoch [103/300], Step [207/225], Training Accuracy: 98.9810%, Training Loss: 0.0368%\n",
      "Epoch [103/300], Step [208/225], Training Accuracy: 98.9784%, Training Loss: 0.0368%\n",
      "Epoch [103/300], Step [209/225], Training Accuracy: 98.9833%, Training Loss: 0.0367%\n",
      "Epoch [103/300], Step [210/225], Training Accuracy: 98.9881%, Training Loss: 0.0367%\n",
      "Epoch [103/300], Step [211/225], Training Accuracy: 98.9929%, Training Loss: 0.0367%\n",
      "Epoch [103/300], Step [212/225], Training Accuracy: 98.9976%, Training Loss: 0.0367%\n",
      "Epoch [103/300], Step [213/225], Training Accuracy: 99.0023%, Training Loss: 0.0367%\n",
      "Epoch [103/300], Step [214/225], Training Accuracy: 98.9997%, Training Loss: 0.0366%\n",
      "Epoch [103/300], Step [215/225], Training Accuracy: 98.9971%, Training Loss: 0.0366%\n",
      "Epoch [103/300], Step [216/225], Training Accuracy: 99.0017%, Training Loss: 0.0365%\n",
      "Epoch [103/300], Step [217/225], Training Accuracy: 98.9991%, Training Loss: 0.0365%\n",
      "Epoch [103/300], Step [218/225], Training Accuracy: 99.0037%, Training Loss: 0.0364%\n",
      "Epoch [103/300], Step [219/225], Training Accuracy: 99.0011%, Training Loss: 0.0364%\n",
      "Epoch [103/300], Step [220/225], Training Accuracy: 99.0057%, Training Loss: 0.0363%\n",
      "Epoch [103/300], Step [221/225], Training Accuracy: 99.0102%, Training Loss: 0.0362%\n",
      "Epoch [103/300], Step [222/225], Training Accuracy: 99.0076%, Training Loss: 0.0362%\n",
      "Epoch [103/300], Step [223/225], Training Accuracy: 99.0121%, Training Loss: 0.0361%\n",
      "Epoch [103/300], Step [224/225], Training Accuracy: 99.0165%, Training Loss: 0.0360%\n",
      "Epoch [103/300], Step [225/225], Training Accuracy: 99.0133%, Training Loss: 0.0360%\n",
      "Epoch [104/300], Step [1/225], Training Accuracy: 98.4375%, Training Loss: 0.0409%\n",
      "Epoch [104/300], Step [2/225], Training Accuracy: 99.2188%, Training Loss: 0.0310%\n",
      "Epoch [104/300], Step [3/225], Training Accuracy: 98.9583%, Training Loss: 0.0437%\n",
      "Epoch [104/300], Step [4/225], Training Accuracy: 98.4375%, Training Loss: 0.0448%\n",
      "Epoch [104/300], Step [5/225], Training Accuracy: 98.7500%, Training Loss: 0.0403%\n",
      "Epoch [104/300], Step [6/225], Training Accuracy: 98.9583%, Training Loss: 0.0383%\n",
      "Epoch [104/300], Step [7/225], Training Accuracy: 99.1071%, Training Loss: 0.0362%\n",
      "Epoch [104/300], Step [8/225], Training Accuracy: 99.2188%, Training Loss: 0.0339%\n",
      "Epoch [104/300], Step [9/225], Training Accuracy: 99.3056%, Training Loss: 0.0313%\n",
      "Epoch [104/300], Step [10/225], Training Accuracy: 99.2188%, Training Loss: 0.0345%\n",
      "Epoch [104/300], Step [11/225], Training Accuracy: 99.2898%, Training Loss: 0.0329%\n",
      "Epoch [104/300], Step [12/225], Training Accuracy: 99.2188%, Training Loss: 0.0337%\n",
      "Epoch [104/300], Step [13/225], Training Accuracy: 99.1587%, Training Loss: 0.0362%\n",
      "Epoch [104/300], Step [14/225], Training Accuracy: 99.2188%, Training Loss: 0.0353%\n",
      "Epoch [104/300], Step [15/225], Training Accuracy: 99.2708%, Training Loss: 0.0337%\n",
      "Epoch [104/300], Step [16/225], Training Accuracy: 99.2188%, Training Loss: 0.0340%\n",
      "Epoch [104/300], Step [17/225], Training Accuracy: 99.2647%, Training Loss: 0.0339%\n",
      "Epoch [104/300], Step [18/225], Training Accuracy: 99.1319%, Training Loss: 0.0375%\n",
      "Epoch [104/300], Step [19/225], Training Accuracy: 99.1776%, Training Loss: 0.0372%\n",
      "Epoch [104/300], Step [20/225], Training Accuracy: 99.1406%, Training Loss: 0.0373%\n",
      "Epoch [104/300], Step [21/225], Training Accuracy: 99.1071%, Training Loss: 0.0373%\n",
      "Epoch [104/300], Step [22/225], Training Accuracy: 99.1477%, Training Loss: 0.0368%\n",
      "Epoch [104/300], Step [23/225], Training Accuracy: 99.1168%, Training Loss: 0.0369%\n",
      "Epoch [104/300], Step [24/225], Training Accuracy: 99.1536%, Training Loss: 0.0370%\n",
      "Epoch [104/300], Step [25/225], Training Accuracy: 99.1250%, Training Loss: 0.0373%\n",
      "Epoch [104/300], Step [26/225], Training Accuracy: 99.0385%, Training Loss: 0.0384%\n",
      "Epoch [104/300], Step [27/225], Training Accuracy: 99.0162%, Training Loss: 0.0385%\n",
      "Epoch [104/300], Step [28/225], Training Accuracy: 98.9955%, Training Loss: 0.0388%\n",
      "Epoch [104/300], Step [29/225], Training Accuracy: 99.0302%, Training Loss: 0.0380%\n",
      "Epoch [104/300], Step [30/225], Training Accuracy: 99.0625%, Training Loss: 0.0378%\n",
      "Epoch [104/300], Step [31/225], Training Accuracy: 99.0927%, Training Loss: 0.0373%\n",
      "Epoch [104/300], Step [32/225], Training Accuracy: 99.1211%, Training Loss: 0.0368%\n",
      "Epoch [104/300], Step [33/225], Training Accuracy: 99.1477%, Training Loss: 0.0360%\n",
      "Epoch [104/300], Step [34/225], Training Accuracy: 99.1728%, Training Loss: 0.0357%\n",
      "Epoch [104/300], Step [35/225], Training Accuracy: 99.1518%, Training Loss: 0.0364%\n",
      "Epoch [104/300], Step [36/225], Training Accuracy: 99.0885%, Training Loss: 0.0368%\n",
      "Epoch [104/300], Step [37/225], Training Accuracy: 99.1132%, Training Loss: 0.0366%\n",
      "Epoch [104/300], Step [38/225], Training Accuracy: 99.0543%, Training Loss: 0.0378%\n",
      "Epoch [104/300], Step [39/225], Training Accuracy: 99.0785%, Training Loss: 0.0380%\n",
      "Epoch [104/300], Step [40/225], Training Accuracy: 99.0625%, Training Loss: 0.0379%\n",
      "Epoch [104/300], Step [41/225], Training Accuracy: 99.0091%, Training Loss: 0.0388%\n",
      "Epoch [104/300], Step [42/225], Training Accuracy: 99.0327%, Training Loss: 0.0382%\n",
      "Epoch [104/300], Step [43/225], Training Accuracy: 99.0552%, Training Loss: 0.0378%\n",
      "Epoch [104/300], Step [44/225], Training Accuracy: 99.0412%, Training Loss: 0.0375%\n",
      "Epoch [104/300], Step [45/225], Training Accuracy: 99.0625%, Training Loss: 0.0371%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [104/300], Step [46/225], Training Accuracy: 99.0829%, Training Loss: 0.0366%\n",
      "Epoch [104/300], Step [47/225], Training Accuracy: 99.1024%, Training Loss: 0.0365%\n",
      "Epoch [104/300], Step [48/225], Training Accuracy: 99.1211%, Training Loss: 0.0363%\n",
      "Epoch [104/300], Step [49/225], Training Accuracy: 99.1390%, Training Loss: 0.0357%\n",
      "Epoch [104/300], Step [50/225], Training Accuracy: 99.1562%, Training Loss: 0.0356%\n",
      "Epoch [104/300], Step [51/225], Training Accuracy: 99.1728%, Training Loss: 0.0352%\n",
      "Epoch [104/300], Step [52/225], Training Accuracy: 99.1286%, Training Loss: 0.0362%\n",
      "Epoch [104/300], Step [53/225], Training Accuracy: 99.1156%, Training Loss: 0.0362%\n",
      "Epoch [104/300], Step [54/225], Training Accuracy: 99.1319%, Training Loss: 0.0360%\n",
      "Epoch [104/300], Step [55/225], Training Accuracy: 99.1477%, Training Loss: 0.0356%\n",
      "Epoch [104/300], Step [56/225], Training Accuracy: 99.1350%, Training Loss: 0.0363%\n",
      "Epoch [104/300], Step [57/225], Training Accuracy: 99.1502%, Training Loss: 0.0360%\n",
      "Epoch [104/300], Step [58/225], Training Accuracy: 99.1379%, Training Loss: 0.0362%\n",
      "Epoch [104/300], Step [59/225], Training Accuracy: 99.1525%, Training Loss: 0.0360%\n",
      "Epoch [104/300], Step [60/225], Training Accuracy: 99.1667%, Training Loss: 0.0357%\n",
      "Epoch [104/300], Step [61/225], Training Accuracy: 99.1547%, Training Loss: 0.0368%\n",
      "Epoch [104/300], Step [62/225], Training Accuracy: 99.1683%, Training Loss: 0.0364%\n",
      "Epoch [104/300], Step [63/225], Training Accuracy: 99.1815%, Training Loss: 0.0362%\n",
      "Epoch [104/300], Step [64/225], Training Accuracy: 99.1943%, Training Loss: 0.0358%\n",
      "Epoch [104/300], Step [65/225], Training Accuracy: 99.1587%, Training Loss: 0.0360%\n",
      "Epoch [104/300], Step [66/225], Training Accuracy: 99.1477%, Training Loss: 0.0359%\n",
      "Epoch [104/300], Step [67/225], Training Accuracy: 99.1604%, Training Loss: 0.0357%\n",
      "Epoch [104/300], Step [68/225], Training Accuracy: 99.1728%, Training Loss: 0.0354%\n",
      "Epoch [104/300], Step [69/225], Training Accuracy: 99.1848%, Training Loss: 0.0352%\n",
      "Epoch [104/300], Step [70/225], Training Accuracy: 99.1964%, Training Loss: 0.0349%\n",
      "Epoch [104/300], Step [71/225], Training Accuracy: 99.1417%, Training Loss: 0.0359%\n",
      "Epoch [104/300], Step [72/225], Training Accuracy: 99.1536%, Training Loss: 0.0356%\n",
      "Epoch [104/300], Step [73/225], Training Accuracy: 99.1438%, Training Loss: 0.0357%\n",
      "Epoch [104/300], Step [74/225], Training Accuracy: 99.1554%, Training Loss: 0.0357%\n",
      "Epoch [104/300], Step [75/225], Training Accuracy: 99.1458%, Training Loss: 0.0358%\n",
      "Epoch [104/300], Step [76/225], Training Accuracy: 99.1365%, Training Loss: 0.0359%\n",
      "Epoch [104/300], Step [77/225], Training Accuracy: 99.1071%, Training Loss: 0.0361%\n",
      "Epoch [104/300], Step [78/225], Training Accuracy: 99.1186%, Training Loss: 0.0359%\n",
      "Epoch [104/300], Step [79/225], Training Accuracy: 99.0902%, Training Loss: 0.0363%\n",
      "Epoch [104/300], Step [80/225], Training Accuracy: 99.0820%, Training Loss: 0.0363%\n",
      "Epoch [104/300], Step [81/225], Training Accuracy: 99.0741%, Training Loss: 0.0362%\n",
      "Epoch [104/300], Step [82/225], Training Accuracy: 99.0663%, Training Loss: 0.0363%\n",
      "Epoch [104/300], Step [83/225], Training Accuracy: 99.0587%, Training Loss: 0.0365%\n",
      "Epoch [104/300], Step [84/225], Training Accuracy: 99.0699%, Training Loss: 0.0365%\n",
      "Epoch [104/300], Step [85/225], Training Accuracy: 99.0625%, Training Loss: 0.0367%\n",
      "Epoch [104/300], Step [86/225], Training Accuracy: 99.0552%, Training Loss: 0.0369%\n",
      "Epoch [104/300], Step [87/225], Training Accuracy: 99.0481%, Training Loss: 0.0369%\n",
      "Epoch [104/300], Step [88/225], Training Accuracy: 99.0234%, Training Loss: 0.0375%\n",
      "Epoch [104/300], Step [89/225], Training Accuracy: 99.0344%, Training Loss: 0.0374%\n",
      "Epoch [104/300], Step [90/225], Training Accuracy: 99.0278%, Training Loss: 0.0375%\n",
      "Epoch [104/300], Step [91/225], Training Accuracy: 99.0385%, Training Loss: 0.0372%\n",
      "Epoch [104/300], Step [92/225], Training Accuracy: 99.0489%, Training Loss: 0.0370%\n",
      "Epoch [104/300], Step [93/225], Training Accuracy: 99.0591%, Training Loss: 0.0367%\n",
      "Epoch [104/300], Step [94/225], Training Accuracy: 99.0691%, Training Loss: 0.0367%\n",
      "Epoch [104/300], Step [95/225], Training Accuracy: 99.0625%, Training Loss: 0.0368%\n",
      "Epoch [104/300], Step [96/225], Training Accuracy: 99.0560%, Training Loss: 0.0368%\n",
      "Epoch [104/300], Step [97/225], Training Accuracy: 99.0657%, Training Loss: 0.0367%\n",
      "Epoch [104/300], Step [98/225], Training Accuracy: 99.0434%, Training Loss: 0.0371%\n",
      "Epoch [104/300], Step [99/225], Training Accuracy: 99.0530%, Training Loss: 0.0369%\n",
      "Epoch [104/300], Step [100/225], Training Accuracy: 99.0625%, Training Loss: 0.0369%\n",
      "Epoch [104/300], Step [101/225], Training Accuracy: 99.0718%, Training Loss: 0.0367%\n",
      "Epoch [104/300], Step [102/225], Training Accuracy: 99.0809%, Training Loss: 0.0365%\n",
      "Epoch [104/300], Step [103/225], Training Accuracy: 99.0898%, Training Loss: 0.0363%\n",
      "Epoch [104/300], Step [104/225], Training Accuracy: 99.0986%, Training Loss: 0.0362%\n",
      "Epoch [104/300], Step [105/225], Training Accuracy: 99.1071%, Training Loss: 0.0361%\n",
      "Epoch [104/300], Step [106/225], Training Accuracy: 99.1156%, Training Loss: 0.0359%\n",
      "Epoch [104/300], Step [107/225], Training Accuracy: 99.1092%, Training Loss: 0.0361%\n",
      "Epoch [104/300], Step [108/225], Training Accuracy: 99.1030%, Training Loss: 0.0362%\n",
      "Epoch [104/300], Step [109/225], Training Accuracy: 99.1112%, Training Loss: 0.0361%\n",
      "Epoch [104/300], Step [110/225], Training Accuracy: 99.1193%, Training Loss: 0.0359%\n",
      "Epoch [104/300], Step [111/225], Training Accuracy: 99.1273%, Training Loss: 0.0357%\n",
      "Epoch [104/300], Step [112/225], Training Accuracy: 99.1350%, Training Loss: 0.0355%\n",
      "Epoch [104/300], Step [113/225], Training Accuracy: 99.1427%, Training Loss: 0.0353%\n",
      "Epoch [104/300], Step [114/225], Training Accuracy: 99.1502%, Training Loss: 0.0352%\n",
      "Epoch [104/300], Step [115/225], Training Accuracy: 99.1576%, Training Loss: 0.0350%\n",
      "Epoch [104/300], Step [116/225], Training Accuracy: 99.1514%, Training Loss: 0.0350%\n",
      "Epoch [104/300], Step [117/225], Training Accuracy: 99.1453%, Training Loss: 0.0350%\n",
      "Epoch [104/300], Step [118/225], Training Accuracy: 99.1393%, Training Loss: 0.0349%\n",
      "Epoch [104/300], Step [119/225], Training Accuracy: 99.1334%, Training Loss: 0.0350%\n",
      "Epoch [104/300], Step [120/225], Training Accuracy: 99.1276%, Training Loss: 0.0349%\n",
      "Epoch [104/300], Step [121/225], Training Accuracy: 99.1219%, Training Loss: 0.0350%\n",
      "Epoch [104/300], Step [122/225], Training Accuracy: 99.1291%, Training Loss: 0.0347%\n",
      "Epoch [104/300], Step [123/225], Training Accuracy: 99.1235%, Training Loss: 0.0348%\n",
      "Epoch [104/300], Step [124/225], Training Accuracy: 99.1179%, Training Loss: 0.0347%\n",
      "Epoch [104/300], Step [125/225], Training Accuracy: 99.1125%, Training Loss: 0.0348%\n",
      "Epoch [104/300], Step [126/225], Training Accuracy: 99.0947%, Training Loss: 0.0350%\n",
      "Epoch [104/300], Step [127/225], Training Accuracy: 99.0896%, Training Loss: 0.0351%\n",
      "Epoch [104/300], Step [128/225], Training Accuracy: 99.0967%, Training Loss: 0.0352%\n",
      "Epoch [104/300], Step [129/225], Training Accuracy: 99.1037%, Training Loss: 0.0350%\n",
      "Epoch [104/300], Step [130/225], Training Accuracy: 99.1106%, Training Loss: 0.0349%\n",
      "Epoch [104/300], Step [131/225], Training Accuracy: 99.0935%, Training Loss: 0.0350%\n",
      "Epoch [104/300], Step [132/225], Training Accuracy: 99.0885%, Training Loss: 0.0352%\n",
      "Epoch [104/300], Step [133/225], Training Accuracy: 99.0954%, Training Loss: 0.0350%\n",
      "Epoch [104/300], Step [134/225], Training Accuracy: 99.1021%, Training Loss: 0.0349%\n",
      "Epoch [104/300], Step [135/225], Training Accuracy: 99.1088%, Training Loss: 0.0347%\n",
      "Epoch [104/300], Step [136/225], Training Accuracy: 99.1039%, Training Loss: 0.0348%\n",
      "Epoch [104/300], Step [137/225], Training Accuracy: 99.0876%, Training Loss: 0.0351%\n",
      "Epoch [104/300], Step [138/225], Training Accuracy: 99.0942%, Training Loss: 0.0350%\n",
      "Epoch [104/300], Step [139/225], Training Accuracy: 99.1007%, Training Loss: 0.0351%\n",
      "Epoch [104/300], Step [140/225], Training Accuracy: 99.1071%, Training Loss: 0.0349%\n",
      "Epoch [104/300], Step [141/225], Training Accuracy: 99.1135%, Training Loss: 0.0349%\n",
      "Epoch [104/300], Step [142/225], Training Accuracy: 99.1087%, Training Loss: 0.0350%\n",
      "Epoch [104/300], Step [143/225], Training Accuracy: 99.1040%, Training Loss: 0.0351%\n",
      "Epoch [104/300], Step [144/225], Training Accuracy: 99.1102%, Training Loss: 0.0349%\n",
      "Epoch [104/300], Step [145/225], Training Accuracy: 99.1056%, Training Loss: 0.0349%\n",
      "Epoch [104/300], Step [146/225], Training Accuracy: 99.1010%, Training Loss: 0.0349%\n",
      "Epoch [104/300], Step [147/225], Training Accuracy: 99.1071%, Training Loss: 0.0348%\n",
      "Epoch [104/300], Step [148/225], Training Accuracy: 99.1132%, Training Loss: 0.0346%\n",
      "Epoch [104/300], Step [149/225], Training Accuracy: 99.1191%, Training Loss: 0.0346%\n",
      "Epoch [104/300], Step [150/225], Training Accuracy: 99.1250%, Training Loss: 0.0346%\n",
      "Epoch [104/300], Step [151/225], Training Accuracy: 99.1204%, Training Loss: 0.0347%\n",
      "Epoch [104/300], Step [152/225], Training Accuracy: 99.1262%, Training Loss: 0.0346%\n",
      "Epoch [104/300], Step [153/225], Training Accuracy: 99.1319%, Training Loss: 0.0346%\n",
      "Epoch [104/300], Step [154/225], Training Accuracy: 99.1173%, Training Loss: 0.0347%\n",
      "Epoch [104/300], Step [155/225], Training Accuracy: 99.1230%, Training Loss: 0.0347%\n",
      "Epoch [104/300], Step [156/225], Training Accuracy: 99.1186%, Training Loss: 0.0346%\n",
      "Epoch [104/300], Step [157/225], Training Accuracy: 99.1043%, Training Loss: 0.0349%\n",
      "Epoch [104/300], Step [158/225], Training Accuracy: 99.1100%, Training Loss: 0.0348%\n",
      "Epoch [104/300], Step [159/225], Training Accuracy: 99.1156%, Training Loss: 0.0346%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [104/300], Step [160/225], Training Accuracy: 99.1211%, Training Loss: 0.0345%\n",
      "Epoch [104/300], Step [161/225], Training Accuracy: 99.1266%, Training Loss: 0.0344%\n",
      "Epoch [104/300], Step [162/225], Training Accuracy: 99.1223%, Training Loss: 0.0344%\n",
      "Epoch [104/300], Step [163/225], Training Accuracy: 99.1181%, Training Loss: 0.0347%\n",
      "Epoch [104/300], Step [164/225], Training Accuracy: 99.1139%, Training Loss: 0.0348%\n",
      "Epoch [104/300], Step [165/225], Training Accuracy: 99.1098%, Training Loss: 0.0349%\n",
      "Epoch [104/300], Step [166/225], Training Accuracy: 99.1152%, Training Loss: 0.0349%\n",
      "Epoch [104/300], Step [167/225], Training Accuracy: 99.1205%, Training Loss: 0.0348%\n",
      "Epoch [104/300], Step [168/225], Training Accuracy: 99.1257%, Training Loss: 0.0347%\n",
      "Epoch [104/300], Step [169/225], Training Accuracy: 99.1124%, Training Loss: 0.0347%\n",
      "Epoch [104/300], Step [170/225], Training Accuracy: 99.1085%, Training Loss: 0.0347%\n",
      "Epoch [104/300], Step [171/225], Training Accuracy: 99.1045%, Training Loss: 0.0348%\n",
      "Epoch [104/300], Step [172/225], Training Accuracy: 99.1007%, Training Loss: 0.0348%\n",
      "Epoch [104/300], Step [173/225], Training Accuracy: 99.0968%, Training Loss: 0.0348%\n",
      "Epoch [104/300], Step [174/225], Training Accuracy: 99.1020%, Training Loss: 0.0347%\n",
      "Epoch [104/300], Step [175/225], Training Accuracy: 99.0982%, Training Loss: 0.0347%\n",
      "Epoch [104/300], Step [176/225], Training Accuracy: 99.1033%, Training Loss: 0.0346%\n",
      "Epoch [104/300], Step [177/225], Training Accuracy: 99.1084%, Training Loss: 0.0346%\n",
      "Epoch [104/300], Step [178/225], Training Accuracy: 99.1046%, Training Loss: 0.0345%\n",
      "Epoch [104/300], Step [179/225], Training Accuracy: 99.1096%, Training Loss: 0.0345%\n",
      "Epoch [104/300], Step [180/225], Training Accuracy: 99.1146%, Training Loss: 0.0345%\n",
      "Epoch [104/300], Step [181/225], Training Accuracy: 99.1195%, Training Loss: 0.0344%\n",
      "Epoch [104/300], Step [182/225], Training Accuracy: 99.0986%, Training Loss: 0.0346%\n",
      "Epoch [104/300], Step [183/225], Training Accuracy: 99.1035%, Training Loss: 0.0345%\n",
      "Epoch [104/300], Step [184/225], Training Accuracy: 99.0999%, Training Loss: 0.0346%\n",
      "Epoch [104/300], Step [185/225], Training Accuracy: 99.1047%, Training Loss: 0.0346%\n",
      "Epoch [104/300], Step [186/225], Training Accuracy: 99.1011%, Training Loss: 0.0345%\n",
      "Epoch [104/300], Step [187/225], Training Accuracy: 99.1059%, Training Loss: 0.0345%\n",
      "Epoch [104/300], Step [188/225], Training Accuracy: 99.1107%, Training Loss: 0.0345%\n",
      "Epoch [104/300], Step [189/225], Training Accuracy: 99.1154%, Training Loss: 0.0344%\n",
      "Epoch [104/300], Step [190/225], Training Accuracy: 99.1118%, Training Loss: 0.0346%\n",
      "Epoch [104/300], Step [191/225], Training Accuracy: 99.1165%, Training Loss: 0.0345%\n",
      "Epoch [104/300], Step [192/225], Training Accuracy: 99.1211%, Training Loss: 0.0343%\n",
      "Epoch [104/300], Step [193/225], Training Accuracy: 99.1176%, Training Loss: 0.0345%\n",
      "Epoch [104/300], Step [194/225], Training Accuracy: 99.1221%, Training Loss: 0.0345%\n",
      "Epoch [104/300], Step [195/225], Training Accuracy: 99.1186%, Training Loss: 0.0345%\n",
      "Epoch [104/300], Step [196/225], Training Accuracy: 99.1231%, Training Loss: 0.0344%\n",
      "Epoch [104/300], Step [197/225], Training Accuracy: 99.1275%, Training Loss: 0.0343%\n",
      "Epoch [104/300], Step [198/225], Training Accuracy: 99.1241%, Training Loss: 0.0343%\n",
      "Epoch [104/300], Step [199/225], Training Accuracy: 99.1206%, Training Loss: 0.0342%\n",
      "Epoch [104/300], Step [200/225], Training Accuracy: 99.1250%, Training Loss: 0.0341%\n",
      "Epoch [104/300], Step [201/225], Training Accuracy: 99.1294%, Training Loss: 0.0342%\n",
      "Epoch [104/300], Step [202/225], Training Accuracy: 99.1337%, Training Loss: 0.0340%\n",
      "Epoch [104/300], Step [203/225], Training Accuracy: 99.1379%, Training Loss: 0.0340%\n",
      "Epoch [104/300], Step [204/225], Training Accuracy: 99.1422%, Training Loss: 0.0339%\n",
      "Epoch [104/300], Step [205/225], Training Accuracy: 99.1387%, Training Loss: 0.0340%\n",
      "Epoch [104/300], Step [206/225], Training Accuracy: 99.1429%, Training Loss: 0.0339%\n",
      "Epoch [104/300], Step [207/225], Training Accuracy: 99.1470%, Training Loss: 0.0338%\n",
      "Epoch [104/300], Step [208/225], Training Accuracy: 99.1511%, Training Loss: 0.0337%\n",
      "Epoch [104/300], Step [209/225], Training Accuracy: 99.1552%, Training Loss: 0.0336%\n",
      "Epoch [104/300], Step [210/225], Training Accuracy: 99.1592%, Training Loss: 0.0335%\n",
      "Epoch [104/300], Step [211/225], Training Accuracy: 99.1632%, Training Loss: 0.0335%\n",
      "Epoch [104/300], Step [212/225], Training Accuracy: 99.1524%, Training Loss: 0.0336%\n",
      "Epoch [104/300], Step [213/225], Training Accuracy: 99.1417%, Training Loss: 0.0337%\n",
      "Epoch [104/300], Step [214/225], Training Accuracy: 99.1457%, Training Loss: 0.0336%\n",
      "Epoch [104/300], Step [215/225], Training Accuracy: 99.1424%, Training Loss: 0.0337%\n",
      "Epoch [104/300], Step [216/225], Training Accuracy: 99.1464%, Training Loss: 0.0337%\n",
      "Epoch [104/300], Step [217/225], Training Accuracy: 99.1431%, Training Loss: 0.0336%\n",
      "Epoch [104/300], Step [218/225], Training Accuracy: 99.1471%, Training Loss: 0.0336%\n",
      "Epoch [104/300], Step [219/225], Training Accuracy: 99.1510%, Training Loss: 0.0335%\n",
      "Epoch [104/300], Step [220/225], Training Accuracy: 99.1477%, Training Loss: 0.0334%\n",
      "Epoch [104/300], Step [221/225], Training Accuracy: 99.1516%, Training Loss: 0.0334%\n",
      "Epoch [104/300], Step [222/225], Training Accuracy: 99.1554%, Training Loss: 0.0334%\n",
      "Epoch [104/300], Step [223/225], Training Accuracy: 99.1592%, Training Loss: 0.0333%\n",
      "Epoch [104/300], Step [224/225], Training Accuracy: 99.1629%, Training Loss: 0.0332%\n",
      "Epoch [104/300], Step [225/225], Training Accuracy: 99.1523%, Training Loss: 0.0332%\n",
      "Epoch [105/300], Step [1/225], Training Accuracy: 96.8750%, Training Loss: 0.0674%\n",
      "Epoch [105/300], Step [2/225], Training Accuracy: 97.6562%, Training Loss: 0.0542%\n",
      "Epoch [105/300], Step [3/225], Training Accuracy: 98.4375%, Training Loss: 0.0502%\n",
      "Epoch [105/300], Step [4/225], Training Accuracy: 98.8281%, Training Loss: 0.0415%\n",
      "Epoch [105/300], Step [5/225], Training Accuracy: 99.0625%, Training Loss: 0.0359%\n",
      "Epoch [105/300], Step [6/225], Training Accuracy: 99.2188%, Training Loss: 0.0316%\n",
      "Epoch [105/300], Step [7/225], Training Accuracy: 99.1071%, Training Loss: 0.0308%\n",
      "Epoch [105/300], Step [8/225], Training Accuracy: 99.2188%, Training Loss: 0.0297%\n",
      "Epoch [105/300], Step [9/225], Training Accuracy: 99.3056%, Training Loss: 0.0278%\n",
      "Epoch [105/300], Step [10/225], Training Accuracy: 99.2188%, Training Loss: 0.0316%\n",
      "Epoch [105/300], Step [11/225], Training Accuracy: 99.2898%, Training Loss: 0.0315%\n",
      "Epoch [105/300], Step [12/225], Training Accuracy: 99.3490%, Training Loss: 0.0303%\n",
      "Epoch [105/300], Step [13/225], Training Accuracy: 99.3990%, Training Loss: 0.0306%\n",
      "Epoch [105/300], Step [14/225], Training Accuracy: 99.4420%, Training Loss: 0.0308%\n",
      "Epoch [105/300], Step [15/225], Training Accuracy: 99.4792%, Training Loss: 0.0306%\n",
      "Epoch [105/300], Step [16/225], Training Accuracy: 99.5117%, Training Loss: 0.0293%\n",
      "Epoch [105/300], Step [17/225], Training Accuracy: 99.5404%, Training Loss: 0.0296%\n",
      "Epoch [105/300], Step [18/225], Training Accuracy: 99.5660%, Training Loss: 0.0298%\n",
      "Epoch [105/300], Step [19/225], Training Accuracy: 99.5888%, Training Loss: 0.0289%\n",
      "Epoch [105/300], Step [20/225], Training Accuracy: 99.5312%, Training Loss: 0.0293%\n",
      "Epoch [105/300], Step [21/225], Training Accuracy: 99.5536%, Training Loss: 0.0284%\n",
      "Epoch [105/300], Step [22/225], Training Accuracy: 99.5739%, Training Loss: 0.0286%\n",
      "Epoch [105/300], Step [23/225], Training Accuracy: 99.5924%, Training Loss: 0.0287%\n",
      "Epoch [105/300], Step [24/225], Training Accuracy: 99.6094%, Training Loss: 0.0287%\n",
      "Epoch [105/300], Step [25/225], Training Accuracy: 99.6250%, Training Loss: 0.0284%\n",
      "Epoch [105/300], Step [26/225], Training Accuracy: 99.6394%, Training Loss: 0.0291%\n",
      "Epoch [105/300], Step [27/225], Training Accuracy: 99.6528%, Training Loss: 0.0292%\n",
      "Epoch [105/300], Step [28/225], Training Accuracy: 99.6652%, Training Loss: 0.0292%\n",
      "Epoch [105/300], Step [29/225], Training Accuracy: 99.6767%, Training Loss: 0.0287%\n",
      "Epoch [105/300], Step [30/225], Training Accuracy: 99.6354%, Training Loss: 0.0293%\n",
      "Epoch [105/300], Step [31/225], Training Accuracy: 99.6472%, Training Loss: 0.0292%\n",
      "Epoch [105/300], Step [32/225], Training Accuracy: 99.6582%, Training Loss: 0.0286%\n",
      "Epoch [105/300], Step [33/225], Training Accuracy: 99.6686%, Training Loss: 0.0285%\n",
      "Epoch [105/300], Step [34/225], Training Accuracy: 99.6324%, Training Loss: 0.0289%\n",
      "Epoch [105/300], Step [35/225], Training Accuracy: 99.6429%, Training Loss: 0.0288%\n",
      "Epoch [105/300], Step [36/225], Training Accuracy: 99.6094%, Training Loss: 0.0292%\n",
      "Epoch [105/300], Step [37/225], Training Accuracy: 99.6199%, Training Loss: 0.0291%\n",
      "Epoch [105/300], Step [38/225], Training Accuracy: 99.5888%, Training Loss: 0.0295%\n",
      "Epoch [105/300], Step [39/225], Training Accuracy: 99.5593%, Training Loss: 0.0300%\n",
      "Epoch [105/300], Step [40/225], Training Accuracy: 99.5703%, Training Loss: 0.0298%\n",
      "Epoch [105/300], Step [41/225], Training Accuracy: 99.5427%, Training Loss: 0.0306%\n",
      "Epoch [105/300], Step [42/225], Training Accuracy: 99.5536%, Training Loss: 0.0301%\n",
      "Epoch [105/300], Step [43/225], Training Accuracy: 99.5276%, Training Loss: 0.0302%\n",
      "Epoch [105/300], Step [44/225], Training Accuracy: 99.5028%, Training Loss: 0.0304%\n",
      "Epoch [105/300], Step [45/225], Training Accuracy: 99.4792%, Training Loss: 0.0305%\n",
      "Epoch [105/300], Step [46/225], Training Accuracy: 99.4905%, Training Loss: 0.0305%\n",
      "Epoch [105/300], Step [47/225], Training Accuracy: 99.5013%, Training Loss: 0.0302%\n",
      "Epoch [105/300], Step [48/225], Training Accuracy: 99.4792%, Training Loss: 0.0302%\n",
      "Epoch [105/300], Step [49/225], Training Accuracy: 99.4579%, Training Loss: 0.0303%\n",
      "Epoch [105/300], Step [50/225], Training Accuracy: 99.4688%, Training Loss: 0.0307%\n",
      "Epoch [105/300], Step [51/225], Training Accuracy: 99.4485%, Training Loss: 0.0307%\n",
      "Epoch [105/300], Step [52/225], Training Accuracy: 99.4291%, Training Loss: 0.0307%\n",
      "Epoch [105/300], Step [53/225], Training Accuracy: 99.4399%, Training Loss: 0.0307%\n",
      "Epoch [105/300], Step [54/225], Training Accuracy: 99.4502%, Training Loss: 0.0307%\n",
      "Epoch [105/300], Step [55/225], Training Accuracy: 99.4602%, Training Loss: 0.0307%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [105/300], Step [56/225], Training Accuracy: 99.4420%, Training Loss: 0.0309%\n",
      "Epoch [105/300], Step [57/225], Training Accuracy: 99.4518%, Training Loss: 0.0307%\n",
      "Epoch [105/300], Step [58/225], Training Accuracy: 99.4612%, Training Loss: 0.0305%\n",
      "Epoch [105/300], Step [59/225], Training Accuracy: 99.4703%, Training Loss: 0.0305%\n",
      "Epoch [105/300], Step [60/225], Training Accuracy: 99.4531%, Training Loss: 0.0308%\n",
      "Epoch [105/300], Step [61/225], Training Accuracy: 99.4109%, Training Loss: 0.0321%\n",
      "Epoch [105/300], Step [62/225], Training Accuracy: 99.4204%, Training Loss: 0.0321%\n",
      "Epoch [105/300], Step [63/225], Training Accuracy: 99.4048%, Training Loss: 0.0328%\n",
      "Epoch [105/300], Step [64/225], Training Accuracy: 99.4141%, Training Loss: 0.0328%\n",
      "Epoch [105/300], Step [65/225], Training Accuracy: 99.4231%, Training Loss: 0.0327%\n",
      "Epoch [105/300], Step [66/225], Training Accuracy: 99.4081%, Training Loss: 0.0331%\n",
      "Epoch [105/300], Step [67/225], Training Accuracy: 99.4170%, Training Loss: 0.0330%\n",
      "Epoch [105/300], Step [68/225], Training Accuracy: 99.4256%, Training Loss: 0.0330%\n",
      "Epoch [105/300], Step [69/225], Training Accuracy: 99.4339%, Training Loss: 0.0329%\n",
      "Epoch [105/300], Step [70/225], Training Accuracy: 99.4196%, Training Loss: 0.0330%\n",
      "Epoch [105/300], Step [71/225], Training Accuracy: 99.4058%, Training Loss: 0.0334%\n",
      "Epoch [105/300], Step [72/225], Training Accuracy: 99.3924%, Training Loss: 0.0335%\n",
      "Epoch [105/300], Step [73/225], Training Accuracy: 99.4007%, Training Loss: 0.0336%\n",
      "Epoch [105/300], Step [74/225], Training Accuracy: 99.4088%, Training Loss: 0.0335%\n",
      "Epoch [105/300], Step [75/225], Training Accuracy: 99.3958%, Training Loss: 0.0335%\n",
      "Epoch [105/300], Step [76/225], Training Accuracy: 99.4038%, Training Loss: 0.0332%\n",
      "Epoch [105/300], Step [77/225], Training Accuracy: 99.4115%, Training Loss: 0.0330%\n",
      "Epoch [105/300], Step [78/225], Training Accuracy: 99.4191%, Training Loss: 0.0330%\n",
      "Epoch [105/300], Step [79/225], Training Accuracy: 99.3869%, Training Loss: 0.0332%\n",
      "Epoch [105/300], Step [80/225], Training Accuracy: 99.3750%, Training Loss: 0.0331%\n",
      "Epoch [105/300], Step [81/225], Training Accuracy: 99.3634%, Training Loss: 0.0332%\n",
      "Epoch [105/300], Step [82/225], Training Accuracy: 99.3712%, Training Loss: 0.0330%\n",
      "Epoch [105/300], Step [83/225], Training Accuracy: 99.3788%, Training Loss: 0.0333%\n",
      "Epoch [105/300], Step [84/225], Training Accuracy: 99.3676%, Training Loss: 0.0336%\n",
      "Epoch [105/300], Step [85/225], Training Accuracy: 99.3750%, Training Loss: 0.0336%\n",
      "Epoch [105/300], Step [86/225], Training Accuracy: 99.3641%, Training Loss: 0.0338%\n",
      "Epoch [105/300], Step [87/225], Training Accuracy: 99.3534%, Training Loss: 0.0342%\n",
      "Epoch [105/300], Step [88/225], Training Accuracy: 99.3608%, Training Loss: 0.0340%\n",
      "Epoch [105/300], Step [89/225], Training Accuracy: 99.3504%, Training Loss: 0.0344%\n",
      "Epoch [105/300], Step [90/225], Training Accuracy: 99.3576%, Training Loss: 0.0342%\n",
      "Epoch [105/300], Step [91/225], Training Accuracy: 99.3647%, Training Loss: 0.0342%\n",
      "Epoch [105/300], Step [92/225], Training Accuracy: 99.3716%, Training Loss: 0.0343%\n",
      "Epoch [105/300], Step [93/225], Training Accuracy: 99.3448%, Training Loss: 0.0349%\n",
      "Epoch [105/300], Step [94/225], Training Accuracy: 99.3517%, Training Loss: 0.0348%\n",
      "Epoch [105/300], Step [95/225], Training Accuracy: 99.3586%, Training Loss: 0.0347%\n",
      "Epoch [105/300], Step [96/225], Training Accuracy: 99.3652%, Training Loss: 0.0345%\n",
      "Epoch [105/300], Step [97/225], Training Accuracy: 99.3396%, Training Loss: 0.0347%\n",
      "Epoch [105/300], Step [98/225], Training Accuracy: 99.3304%, Training Loss: 0.0352%\n",
      "Epoch [105/300], Step [99/225], Training Accuracy: 99.3213%, Training Loss: 0.0356%\n",
      "Epoch [105/300], Step [100/225], Training Accuracy: 99.3125%, Training Loss: 0.0356%\n",
      "Epoch [105/300], Step [101/225], Training Accuracy: 99.3038%, Training Loss: 0.0356%\n",
      "Epoch [105/300], Step [102/225], Training Accuracy: 99.2494%, Training Loss: 0.0365%\n",
      "Epoch [105/300], Step [103/225], Training Accuracy: 99.2567%, Training Loss: 0.0365%\n",
      "Epoch [105/300], Step [104/225], Training Accuracy: 99.2638%, Training Loss: 0.0364%\n",
      "Epoch [105/300], Step [105/225], Training Accuracy: 99.2708%, Training Loss: 0.0362%\n",
      "Epoch [105/300], Step [106/225], Training Accuracy: 99.2777%, Training Loss: 0.0361%\n",
      "Epoch [105/300], Step [107/225], Training Accuracy: 99.2845%, Training Loss: 0.0360%\n",
      "Epoch [105/300], Step [108/225], Training Accuracy: 99.2911%, Training Loss: 0.0358%\n",
      "Epoch [105/300], Step [109/225], Training Accuracy: 99.2833%, Training Loss: 0.0359%\n",
      "Epoch [105/300], Step [110/225], Training Accuracy: 99.2756%, Training Loss: 0.0363%\n",
      "Epoch [105/300], Step [111/225], Training Accuracy: 99.2680%, Training Loss: 0.0363%\n",
      "Epoch [105/300], Step [112/225], Training Accuracy: 99.2746%, Training Loss: 0.0363%\n",
      "Epoch [105/300], Step [113/225], Training Accuracy: 99.2533%, Training Loss: 0.0364%\n",
      "Epoch [105/300], Step [114/225], Training Accuracy: 99.2325%, Training Loss: 0.0364%\n",
      "Epoch [105/300], Step [115/225], Training Accuracy: 99.2120%, Training Loss: 0.0366%\n",
      "Epoch [105/300], Step [116/225], Training Accuracy: 99.2053%, Training Loss: 0.0366%\n",
      "Epoch [105/300], Step [117/225], Training Accuracy: 99.1987%, Training Loss: 0.0366%\n",
      "Epoch [105/300], Step [118/225], Training Accuracy: 99.1923%, Training Loss: 0.0366%\n",
      "Epoch [105/300], Step [119/225], Training Accuracy: 99.1991%, Training Loss: 0.0364%\n",
      "Epoch [105/300], Step [120/225], Training Accuracy: 99.1927%, Training Loss: 0.0365%\n",
      "Epoch [105/300], Step [121/225], Training Accuracy: 99.1994%, Training Loss: 0.0364%\n",
      "Epoch [105/300], Step [122/225], Training Accuracy: 99.2059%, Training Loss: 0.0362%\n",
      "Epoch [105/300], Step [123/225], Training Accuracy: 99.1997%, Training Loss: 0.0362%\n",
      "Epoch [105/300], Step [124/225], Training Accuracy: 99.1935%, Training Loss: 0.0362%\n",
      "Epoch [105/300], Step [125/225], Training Accuracy: 99.2000%, Training Loss: 0.0360%\n",
      "Epoch [105/300], Step [126/225], Training Accuracy: 99.2063%, Training Loss: 0.0360%\n",
      "Epoch [105/300], Step [127/225], Training Accuracy: 99.2126%, Training Loss: 0.0360%\n",
      "Epoch [105/300], Step [128/225], Training Accuracy: 99.2188%, Training Loss: 0.0358%\n",
      "Epoch [105/300], Step [129/225], Training Accuracy: 99.2127%, Training Loss: 0.0358%\n",
      "Epoch [105/300], Step [130/225], Training Accuracy: 99.2067%, Training Loss: 0.0358%\n",
      "Epoch [105/300], Step [131/225], Training Accuracy: 99.2128%, Training Loss: 0.0356%\n",
      "Epoch [105/300], Step [132/225], Training Accuracy: 99.2188%, Training Loss: 0.0356%\n",
      "Epoch [105/300], Step [133/225], Training Accuracy: 99.2129%, Training Loss: 0.0355%\n",
      "Epoch [105/300], Step [134/225], Training Accuracy: 99.2071%, Training Loss: 0.0354%\n",
      "Epoch [105/300], Step [135/225], Training Accuracy: 99.2014%, Training Loss: 0.0353%\n",
      "Epoch [105/300], Step [136/225], Training Accuracy: 99.1958%, Training Loss: 0.0353%\n",
      "Epoch [105/300], Step [137/225], Training Accuracy: 99.1902%, Training Loss: 0.0354%\n",
      "Epoch [105/300], Step [138/225], Training Accuracy: 99.1848%, Training Loss: 0.0355%\n",
      "Epoch [105/300], Step [139/225], Training Accuracy: 99.1906%, Training Loss: 0.0355%\n",
      "Epoch [105/300], Step [140/225], Training Accuracy: 99.1964%, Training Loss: 0.0354%\n",
      "Epoch [105/300], Step [141/225], Training Accuracy: 99.1910%, Training Loss: 0.0353%\n",
      "Epoch [105/300], Step [142/225], Training Accuracy: 99.1967%, Training Loss: 0.0353%\n",
      "Epoch [105/300], Step [143/225], Training Accuracy: 99.2024%, Training Loss: 0.0351%\n",
      "Epoch [105/300], Step [144/225], Training Accuracy: 99.1970%, Training Loss: 0.0353%\n",
      "Epoch [105/300], Step [145/225], Training Accuracy: 99.1918%, Training Loss: 0.0352%\n",
      "Epoch [105/300], Step [146/225], Training Accuracy: 99.1866%, Training Loss: 0.0352%\n",
      "Epoch [105/300], Step [147/225], Training Accuracy: 99.1815%, Training Loss: 0.0352%\n",
      "Epoch [105/300], Step [148/225], Training Accuracy: 99.1871%, Training Loss: 0.0351%\n",
      "Epoch [105/300], Step [149/225], Training Accuracy: 99.1820%, Training Loss: 0.0352%\n",
      "Epoch [105/300], Step [150/225], Training Accuracy: 99.1875%, Training Loss: 0.0350%\n",
      "Epoch [105/300], Step [151/225], Training Accuracy: 99.1825%, Training Loss: 0.0351%\n",
      "Epoch [105/300], Step [152/225], Training Accuracy: 99.1879%, Training Loss: 0.0350%\n",
      "Epoch [105/300], Step [153/225], Training Accuracy: 99.1830%, Training Loss: 0.0351%\n",
      "Epoch [105/300], Step [154/225], Training Accuracy: 99.1782%, Training Loss: 0.0352%\n",
      "Epoch [105/300], Step [155/225], Training Accuracy: 99.1734%, Training Loss: 0.0353%\n",
      "Epoch [105/300], Step [156/225], Training Accuracy: 99.1687%, Training Loss: 0.0353%\n",
      "Epoch [105/300], Step [157/225], Training Accuracy: 99.1740%, Training Loss: 0.0353%\n",
      "Epoch [105/300], Step [158/225], Training Accuracy: 99.1693%, Training Loss: 0.0352%\n",
      "Epoch [105/300], Step [159/225], Training Accuracy: 99.1647%, Training Loss: 0.0353%\n",
      "Epoch [105/300], Step [160/225], Training Accuracy: 99.1699%, Training Loss: 0.0351%\n",
      "Epoch [105/300], Step [161/225], Training Accuracy: 99.1751%, Training Loss: 0.0350%\n",
      "Epoch [105/300], Step [162/225], Training Accuracy: 99.1802%, Training Loss: 0.0349%\n",
      "Epoch [105/300], Step [163/225], Training Accuracy: 99.1852%, Training Loss: 0.0349%\n",
      "Epoch [105/300], Step [164/225], Training Accuracy: 99.1902%, Training Loss: 0.0348%\n",
      "Epoch [105/300], Step [165/225], Training Accuracy: 99.1951%, Training Loss: 0.0348%\n",
      "Epoch [105/300], Step [166/225], Training Accuracy: 99.1905%, Training Loss: 0.0350%\n",
      "Epoch [105/300], Step [167/225], Training Accuracy: 99.1954%, Training Loss: 0.0348%\n",
      "Epoch [105/300], Step [168/225], Training Accuracy: 99.2001%, Training Loss: 0.0348%\n",
      "Epoch [105/300], Step [169/225], Training Accuracy: 99.1956%, Training Loss: 0.0349%\n",
      "Epoch [105/300], Step [170/225], Training Accuracy: 99.1912%, Training Loss: 0.0351%\n",
      "Epoch [105/300], Step [171/225], Training Accuracy: 99.1959%, Training Loss: 0.0350%\n",
      "Epoch [105/300], Step [172/225], Training Accuracy: 99.1915%, Training Loss: 0.0350%\n",
      "Epoch [105/300], Step [173/225], Training Accuracy: 99.1962%, Training Loss: 0.0350%\n",
      "Epoch [105/300], Step [174/225], Training Accuracy: 99.1828%, Training Loss: 0.0352%\n",
      "Epoch [105/300], Step [175/225], Training Accuracy: 99.1786%, Training Loss: 0.0352%\n",
      "Epoch [105/300], Step [176/225], Training Accuracy: 99.1832%, Training Loss: 0.0353%\n",
      "Epoch [105/300], Step [177/225], Training Accuracy: 99.1879%, Training Loss: 0.0352%\n",
      "Epoch [105/300], Step [178/225], Training Accuracy: 99.1924%, Training Loss: 0.0351%\n",
      "Epoch [105/300], Step [179/225], Training Accuracy: 99.1969%, Training Loss: 0.0350%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [105/300], Step [180/225], Training Accuracy: 99.1927%, Training Loss: 0.0351%\n",
      "Epoch [105/300], Step [181/225], Training Accuracy: 99.1972%, Training Loss: 0.0350%\n",
      "Epoch [105/300], Step [182/225], Training Accuracy: 99.2016%, Training Loss: 0.0349%\n",
      "Epoch [105/300], Step [183/225], Training Accuracy: 99.2059%, Training Loss: 0.0349%\n",
      "Epoch [105/300], Step [184/225], Training Accuracy: 99.2103%, Training Loss: 0.0348%\n",
      "Epoch [105/300], Step [185/225], Training Accuracy: 99.2061%, Training Loss: 0.0348%\n",
      "Epoch [105/300], Step [186/225], Training Accuracy: 99.2103%, Training Loss: 0.0347%\n",
      "Epoch [105/300], Step [187/225], Training Accuracy: 99.2062%, Training Loss: 0.0348%\n",
      "Epoch [105/300], Step [188/225], Training Accuracy: 99.2104%, Training Loss: 0.0346%\n",
      "Epoch [105/300], Step [189/225], Training Accuracy: 99.2063%, Training Loss: 0.0346%\n",
      "Epoch [105/300], Step [190/225], Training Accuracy: 99.2105%, Training Loss: 0.0346%\n",
      "Epoch [105/300], Step [191/225], Training Accuracy: 99.2065%, Training Loss: 0.0345%\n",
      "Epoch [105/300], Step [192/225], Training Accuracy: 99.2106%, Training Loss: 0.0344%\n",
      "Epoch [105/300], Step [193/225], Training Accuracy: 99.2066%, Training Loss: 0.0344%\n",
      "Epoch [105/300], Step [194/225], Training Accuracy: 99.2026%, Training Loss: 0.0344%\n",
      "Epoch [105/300], Step [195/225], Training Accuracy: 99.1987%, Training Loss: 0.0345%\n",
      "Epoch [105/300], Step [196/225], Training Accuracy: 99.2028%, Training Loss: 0.0344%\n",
      "Epoch [105/300], Step [197/225], Training Accuracy: 99.2069%, Training Loss: 0.0345%\n",
      "Epoch [105/300], Step [198/225], Training Accuracy: 99.2030%, Training Loss: 0.0345%\n",
      "Epoch [105/300], Step [199/225], Training Accuracy: 99.2070%, Training Loss: 0.0345%\n",
      "Epoch [105/300], Step [200/225], Training Accuracy: 99.2109%, Training Loss: 0.0345%\n",
      "Epoch [105/300], Step [201/225], Training Accuracy: 99.1993%, Training Loss: 0.0347%\n",
      "Epoch [105/300], Step [202/225], Training Accuracy: 99.1955%, Training Loss: 0.0347%\n",
      "Epoch [105/300], Step [203/225], Training Accuracy: 99.1995%, Training Loss: 0.0346%\n",
      "Epoch [105/300], Step [204/225], Training Accuracy: 99.1958%, Training Loss: 0.0346%\n",
      "Epoch [105/300], Step [205/225], Training Accuracy: 99.1997%, Training Loss: 0.0345%\n",
      "Epoch [105/300], Step [206/225], Training Accuracy: 99.1960%, Training Loss: 0.0345%\n",
      "Epoch [105/300], Step [207/225], Training Accuracy: 99.1923%, Training Loss: 0.0345%\n",
      "Epoch [105/300], Step [208/225], Training Accuracy: 99.1962%, Training Loss: 0.0344%\n",
      "Epoch [105/300], Step [209/225], Training Accuracy: 99.1926%, Training Loss: 0.0344%\n",
      "Epoch [105/300], Step [210/225], Training Accuracy: 99.1890%, Training Loss: 0.0344%\n",
      "Epoch [105/300], Step [211/225], Training Accuracy: 99.1854%, Training Loss: 0.0345%\n",
      "Epoch [105/300], Step [212/225], Training Accuracy: 99.1893%, Training Loss: 0.0344%\n",
      "Epoch [105/300], Step [213/225], Training Accuracy: 99.1857%, Training Loss: 0.0345%\n",
      "Epoch [105/300], Step [214/225], Training Accuracy: 99.1822%, Training Loss: 0.0345%\n",
      "Epoch [105/300], Step [215/225], Training Accuracy: 99.1860%, Training Loss: 0.0345%\n",
      "Epoch [105/300], Step [216/225], Training Accuracy: 99.1826%, Training Loss: 0.0345%\n",
      "Epoch [105/300], Step [217/225], Training Accuracy: 99.1863%, Training Loss: 0.0344%\n",
      "Epoch [105/300], Step [218/225], Training Accuracy: 99.1901%, Training Loss: 0.0343%\n",
      "Epoch [105/300], Step [219/225], Training Accuracy: 99.1866%, Training Loss: 0.0343%\n",
      "Epoch [105/300], Step [220/225], Training Accuracy: 99.1903%, Training Loss: 0.0342%\n",
      "Epoch [105/300], Step [221/225], Training Accuracy: 99.1869%, Training Loss: 0.0343%\n",
      "Epoch [105/300], Step [222/225], Training Accuracy: 99.1906%, Training Loss: 0.0342%\n",
      "Epoch [105/300], Step [223/225], Training Accuracy: 99.1942%, Training Loss: 0.0342%\n",
      "Epoch [105/300], Step [224/225], Training Accuracy: 99.1978%, Training Loss: 0.0342%\n",
      "Epoch [105/300], Step [225/225], Training Accuracy: 99.2009%, Training Loss: 0.0341%\n",
      "Epoch [106/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0077%\n",
      "Epoch [106/300], Step [2/225], Training Accuracy: 100.0000%, Training Loss: 0.0088%\n",
      "Epoch [106/300], Step [3/225], Training Accuracy: 99.4792%, Training Loss: 0.0285%\n",
      "Epoch [106/300], Step [4/225], Training Accuracy: 99.6094%, Training Loss: 0.0246%\n",
      "Epoch [106/300], Step [5/225], Training Accuracy: 99.3750%, Training Loss: 0.0272%\n",
      "Epoch [106/300], Step [6/225], Training Accuracy: 99.4792%, Training Loss: 0.0253%\n",
      "Epoch [106/300], Step [7/225], Training Accuracy: 99.5536%, Training Loss: 0.0245%\n",
      "Epoch [106/300], Step [8/225], Training Accuracy: 99.4141%, Training Loss: 0.0281%\n",
      "Epoch [106/300], Step [9/225], Training Accuracy: 99.3056%, Training Loss: 0.0324%\n",
      "Epoch [106/300], Step [10/225], Training Accuracy: 99.2188%, Training Loss: 0.0336%\n",
      "Epoch [106/300], Step [11/225], Training Accuracy: 99.2898%, Training Loss: 0.0322%\n",
      "Epoch [106/300], Step [12/225], Training Accuracy: 99.3490%, Training Loss: 0.0318%\n",
      "Epoch [106/300], Step [13/225], Training Accuracy: 99.3990%, Training Loss: 0.0314%\n",
      "Epoch [106/300], Step [14/225], Training Accuracy: 99.2188%, Training Loss: 0.0321%\n",
      "Epoch [106/300], Step [15/225], Training Accuracy: 99.2708%, Training Loss: 0.0314%\n",
      "Epoch [106/300], Step [16/225], Training Accuracy: 99.2188%, Training Loss: 0.0325%\n",
      "Epoch [106/300], Step [17/225], Training Accuracy: 99.2647%, Training Loss: 0.0322%\n",
      "Epoch [106/300], Step [18/225], Training Accuracy: 99.1319%, Training Loss: 0.0329%\n",
      "Epoch [106/300], Step [19/225], Training Accuracy: 99.0954%, Training Loss: 0.0334%\n",
      "Epoch [106/300], Step [20/225], Training Accuracy: 99.1406%, Training Loss: 0.0323%\n",
      "Epoch [106/300], Step [21/225], Training Accuracy: 99.1815%, Training Loss: 0.0317%\n",
      "Epoch [106/300], Step [22/225], Training Accuracy: 99.1477%, Training Loss: 0.0319%\n",
      "Epoch [106/300], Step [23/225], Training Accuracy: 99.1168%, Training Loss: 0.0322%\n",
      "Epoch [106/300], Step [24/225], Training Accuracy: 99.1536%, Training Loss: 0.0320%\n",
      "Epoch [106/300], Step [25/225], Training Accuracy: 99.1250%, Training Loss: 0.0322%\n",
      "Epoch [106/300], Step [26/225], Training Accuracy: 99.1587%, Training Loss: 0.0318%\n",
      "Epoch [106/300], Step [27/225], Training Accuracy: 99.1898%, Training Loss: 0.0313%\n",
      "Epoch [106/300], Step [28/225], Training Accuracy: 99.1629%, Training Loss: 0.0313%\n",
      "Epoch [106/300], Step [29/225], Training Accuracy: 99.1379%, Training Loss: 0.0316%\n",
      "Epoch [106/300], Step [30/225], Training Accuracy: 99.0625%, Training Loss: 0.0334%\n",
      "Epoch [106/300], Step [31/225], Training Accuracy: 99.0423%, Training Loss: 0.0336%\n",
      "Epoch [106/300], Step [32/225], Training Accuracy: 99.0723%, Training Loss: 0.0336%\n",
      "Epoch [106/300], Step [33/225], Training Accuracy: 98.9583%, Training Loss: 0.0360%\n",
      "Epoch [106/300], Step [34/225], Training Accuracy: 98.9890%, Training Loss: 0.0357%\n",
      "Epoch [106/300], Step [35/225], Training Accuracy: 98.9286%, Training Loss: 0.0364%\n",
      "Epoch [106/300], Step [36/225], Training Accuracy: 98.9583%, Training Loss: 0.0357%\n",
      "Epoch [106/300], Step [37/225], Training Accuracy: 98.9865%, Training Loss: 0.0352%\n",
      "Epoch [106/300], Step [38/225], Training Accuracy: 98.9720%, Training Loss: 0.0361%\n",
      "Epoch [106/300], Step [39/225], Training Accuracy: 98.8782%, Training Loss: 0.0371%\n",
      "Epoch [106/300], Step [40/225], Training Accuracy: 98.9062%, Training Loss: 0.0366%\n",
      "Epoch [106/300], Step [41/225], Training Accuracy: 98.8948%, Training Loss: 0.0369%\n",
      "Epoch [106/300], Step [42/225], Training Accuracy: 98.9211%, Training Loss: 0.0363%\n",
      "Epoch [106/300], Step [43/225], Training Accuracy: 98.9099%, Training Loss: 0.0368%\n",
      "Epoch [106/300], Step [44/225], Training Accuracy: 98.8991%, Training Loss: 0.0369%\n",
      "Epoch [106/300], Step [45/225], Training Accuracy: 98.7847%, Training Loss: 0.0407%\n",
      "Epoch [106/300], Step [46/225], Training Accuracy: 98.8111%, Training Loss: 0.0401%\n",
      "Epoch [106/300], Step [47/225], Training Accuracy: 98.8364%, Training Loss: 0.0397%\n",
      "Epoch [106/300], Step [48/225], Training Accuracy: 98.8607%, Training Loss: 0.0394%\n",
      "Epoch [106/300], Step [49/225], Training Accuracy: 98.8839%, Training Loss: 0.0388%\n",
      "Epoch [106/300], Step [50/225], Training Accuracy: 98.9062%, Training Loss: 0.0386%\n",
      "Epoch [106/300], Step [51/225], Training Accuracy: 98.9277%, Training Loss: 0.0383%\n",
      "Epoch [106/300], Step [52/225], Training Accuracy: 98.9183%, Training Loss: 0.0380%\n",
      "Epoch [106/300], Step [53/225], Training Accuracy: 98.9387%, Training Loss: 0.0378%\n",
      "Epoch [106/300], Step [54/225], Training Accuracy: 98.9005%, Training Loss: 0.0380%\n",
      "Epoch [106/300], Step [55/225], Training Accuracy: 98.9205%, Training Loss: 0.0379%\n",
      "Epoch [106/300], Step [56/225], Training Accuracy: 98.9118%, Training Loss: 0.0382%\n",
      "Epoch [106/300], Step [57/225], Training Accuracy: 98.9309%, Training Loss: 0.0378%\n",
      "Epoch [106/300], Step [58/225], Training Accuracy: 98.9224%, Training Loss: 0.0376%\n",
      "Epoch [106/300], Step [59/225], Training Accuracy: 98.9407%, Training Loss: 0.0377%\n",
      "Epoch [106/300], Step [60/225], Training Accuracy: 98.9583%, Training Loss: 0.0374%\n",
      "Epoch [106/300], Step [61/225], Training Accuracy: 98.9754%, Training Loss: 0.0373%\n",
      "Epoch [106/300], Step [62/225], Training Accuracy: 98.9919%, Training Loss: 0.0372%\n",
      "Epoch [106/300], Step [63/225], Training Accuracy: 99.0079%, Training Loss: 0.0368%\n",
      "Epoch [106/300], Step [64/225], Training Accuracy: 99.0234%, Training Loss: 0.0367%\n",
      "Epoch [106/300], Step [65/225], Training Accuracy: 99.0144%, Training Loss: 0.0366%\n",
      "Epoch [106/300], Step [66/225], Training Accuracy: 98.9820%, Training Loss: 0.0375%\n",
      "Epoch [106/300], Step [67/225], Training Accuracy: 98.9739%, Training Loss: 0.0377%\n",
      "Epoch [106/300], Step [68/225], Training Accuracy: 98.9660%, Training Loss: 0.0377%\n",
      "Epoch [106/300], Step [69/225], Training Accuracy: 98.9810%, Training Loss: 0.0374%\n",
      "Epoch [106/300], Step [70/225], Training Accuracy: 98.9732%, Training Loss: 0.0374%\n",
      "Epoch [106/300], Step [71/225], Training Accuracy: 98.9657%, Training Loss: 0.0376%\n",
      "Epoch [106/300], Step [72/225], Training Accuracy: 98.9583%, Training Loss: 0.0374%\n",
      "Epoch [106/300], Step [73/225], Training Accuracy: 98.9512%, Training Loss: 0.0375%\n",
      "Epoch [106/300], Step [74/225], Training Accuracy: 98.9654%, Training Loss: 0.0372%\n",
      "Epoch [106/300], Step [75/225], Training Accuracy: 98.9792%, Training Loss: 0.0370%\n",
      "Epoch [106/300], Step [76/225], Training Accuracy: 98.9309%, Training Loss: 0.0374%\n",
      "Epoch [106/300], Step [77/225], Training Accuracy: 98.9245%, Training Loss: 0.0375%\n",
      "Epoch [106/300], Step [78/225], Training Accuracy: 98.9183%, Training Loss: 0.0377%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [106/300], Step [79/225], Training Accuracy: 98.9122%, Training Loss: 0.0379%\n",
      "Epoch [106/300], Step [80/225], Training Accuracy: 98.9062%, Training Loss: 0.0379%\n",
      "Epoch [106/300], Step [81/225], Training Accuracy: 98.9005%, Training Loss: 0.0377%\n",
      "Epoch [106/300], Step [82/225], Training Accuracy: 98.9139%, Training Loss: 0.0376%\n",
      "Epoch [106/300], Step [83/225], Training Accuracy: 98.9081%, Training Loss: 0.0382%\n",
      "Epoch [106/300], Step [84/225], Training Accuracy: 98.9211%, Training Loss: 0.0379%\n",
      "Epoch [106/300], Step [85/225], Training Accuracy: 98.9338%, Training Loss: 0.0376%\n",
      "Epoch [106/300], Step [86/225], Training Accuracy: 98.9099%, Training Loss: 0.0380%\n",
      "Epoch [106/300], Step [87/225], Training Accuracy: 98.9224%, Training Loss: 0.0378%\n",
      "Epoch [106/300], Step [88/225], Training Accuracy: 98.9347%, Training Loss: 0.0376%\n",
      "Epoch [106/300], Step [89/225], Training Accuracy: 98.9291%, Training Loss: 0.0378%\n",
      "Epoch [106/300], Step [90/225], Training Accuracy: 98.9410%, Training Loss: 0.0377%\n",
      "Epoch [106/300], Step [91/225], Training Accuracy: 98.9526%, Training Loss: 0.0374%\n",
      "Epoch [106/300], Step [92/225], Training Accuracy: 98.9470%, Training Loss: 0.0375%\n",
      "Epoch [106/300], Step [93/225], Training Accuracy: 98.9583%, Training Loss: 0.0373%\n",
      "Epoch [106/300], Step [94/225], Training Accuracy: 98.9528%, Training Loss: 0.0372%\n",
      "Epoch [106/300], Step [95/225], Training Accuracy: 98.9638%, Training Loss: 0.0371%\n",
      "Epoch [106/300], Step [96/225], Training Accuracy: 98.9583%, Training Loss: 0.0372%\n",
      "Epoch [106/300], Step [97/225], Training Accuracy: 98.9530%, Training Loss: 0.0373%\n",
      "Epoch [106/300], Step [98/225], Training Accuracy: 98.9477%, Training Loss: 0.0374%\n",
      "Epoch [106/300], Step [99/225], Training Accuracy: 98.9583%, Training Loss: 0.0373%\n",
      "Epoch [106/300], Step [100/225], Training Accuracy: 98.9688%, Training Loss: 0.0371%\n",
      "Epoch [106/300], Step [101/225], Training Accuracy: 98.9790%, Training Loss: 0.0368%\n",
      "Epoch [106/300], Step [102/225], Training Accuracy: 98.9890%, Training Loss: 0.0367%\n",
      "Epoch [106/300], Step [103/225], Training Accuracy: 98.9836%, Training Loss: 0.0372%\n",
      "Epoch [106/300], Step [104/225], Training Accuracy: 98.9934%, Training Loss: 0.0370%\n",
      "Epoch [106/300], Step [105/225], Training Accuracy: 99.0030%, Training Loss: 0.0369%\n",
      "Epoch [106/300], Step [106/225], Training Accuracy: 98.9829%, Training Loss: 0.0371%\n",
      "Epoch [106/300], Step [107/225], Training Accuracy: 98.9924%, Training Loss: 0.0369%\n",
      "Epoch [106/300], Step [108/225], Training Accuracy: 99.0017%, Training Loss: 0.0368%\n",
      "Epoch [106/300], Step [109/225], Training Accuracy: 99.0109%, Training Loss: 0.0369%\n",
      "Epoch [106/300], Step [110/225], Training Accuracy: 99.0199%, Training Loss: 0.0367%\n",
      "Epoch [106/300], Step [111/225], Training Accuracy: 99.0146%, Training Loss: 0.0368%\n",
      "Epoch [106/300], Step [112/225], Training Accuracy: 99.0095%, Training Loss: 0.0368%\n",
      "Epoch [106/300], Step [113/225], Training Accuracy: 99.0183%, Training Loss: 0.0367%\n",
      "Epoch [106/300], Step [114/225], Training Accuracy: 99.0132%, Training Loss: 0.0367%\n",
      "Epoch [106/300], Step [115/225], Training Accuracy: 98.9946%, Training Loss: 0.0368%\n",
      "Epoch [106/300], Step [116/225], Training Accuracy: 98.9898%, Training Loss: 0.0369%\n",
      "Epoch [106/300], Step [117/225], Training Accuracy: 98.9850%, Training Loss: 0.0369%\n",
      "Epoch [106/300], Step [118/225], Training Accuracy: 98.9804%, Training Loss: 0.0368%\n",
      "Epoch [106/300], Step [119/225], Training Accuracy: 98.9890%, Training Loss: 0.0367%\n",
      "Epoch [106/300], Step [120/225], Training Accuracy: 98.9583%, Training Loss: 0.0369%\n",
      "Epoch [106/300], Step [121/225], Training Accuracy: 98.9669%, Training Loss: 0.0368%\n",
      "Epoch [106/300], Step [122/225], Training Accuracy: 98.9754%, Training Loss: 0.0366%\n",
      "Epoch [106/300], Step [123/225], Training Accuracy: 98.9710%, Training Loss: 0.0366%\n",
      "Epoch [106/300], Step [124/225], Training Accuracy: 98.9793%, Training Loss: 0.0364%\n",
      "Epoch [106/300], Step [125/225], Training Accuracy: 98.9875%, Training Loss: 0.0363%\n",
      "Epoch [106/300], Step [126/225], Training Accuracy: 98.9831%, Training Loss: 0.0364%\n",
      "Epoch [106/300], Step [127/225], Training Accuracy: 98.9911%, Training Loss: 0.0362%\n",
      "Epoch [106/300], Step [128/225], Training Accuracy: 98.9868%, Training Loss: 0.0362%\n",
      "Epoch [106/300], Step [129/225], Training Accuracy: 98.9947%, Training Loss: 0.0360%\n",
      "Epoch [106/300], Step [130/225], Training Accuracy: 99.0024%, Training Loss: 0.0361%\n",
      "Epoch [106/300], Step [131/225], Training Accuracy: 99.0100%, Training Loss: 0.0360%\n",
      "Epoch [106/300], Step [132/225], Training Accuracy: 99.0175%, Training Loss: 0.0358%\n",
      "Epoch [106/300], Step [133/225], Training Accuracy: 98.9779%, Training Loss: 0.0361%\n",
      "Epoch [106/300], Step [134/225], Training Accuracy: 98.9855%, Training Loss: 0.0361%\n",
      "Epoch [106/300], Step [135/225], Training Accuracy: 98.9931%, Training Loss: 0.0361%\n",
      "Epoch [106/300], Step [136/225], Training Accuracy: 98.9890%, Training Loss: 0.0364%\n",
      "Epoch [106/300], Step [137/225], Training Accuracy: 98.9964%, Training Loss: 0.0364%\n",
      "Epoch [106/300], Step [138/225], Training Accuracy: 98.9923%, Training Loss: 0.0363%\n",
      "Epoch [106/300], Step [139/225], Training Accuracy: 98.9996%, Training Loss: 0.0362%\n",
      "Epoch [106/300], Step [140/225], Training Accuracy: 99.0067%, Training Loss: 0.0362%\n",
      "Epoch [106/300], Step [141/225], Training Accuracy: 99.0027%, Training Loss: 0.0362%\n",
      "Epoch [106/300], Step [142/225], Training Accuracy: 99.0097%, Training Loss: 0.0360%\n",
      "Epoch [106/300], Step [143/225], Training Accuracy: 99.0057%, Training Loss: 0.0360%\n",
      "Epoch [106/300], Step [144/225], Training Accuracy: 99.0126%, Training Loss: 0.0360%\n",
      "Epoch [106/300], Step [145/225], Training Accuracy: 99.0086%, Training Loss: 0.0359%\n",
      "Epoch [106/300], Step [146/225], Training Accuracy: 99.0047%, Training Loss: 0.0360%\n",
      "Epoch [106/300], Step [147/225], Training Accuracy: 99.0009%, Training Loss: 0.0361%\n",
      "Epoch [106/300], Step [148/225], Training Accuracy: 99.0076%, Training Loss: 0.0360%\n",
      "Epoch [106/300], Step [149/225], Training Accuracy: 99.0143%, Training Loss: 0.0360%\n",
      "Epoch [106/300], Step [150/225], Training Accuracy: 99.0104%, Training Loss: 0.0360%\n",
      "Epoch [106/300], Step [151/225], Training Accuracy: 99.0170%, Training Loss: 0.0360%\n",
      "Epoch [106/300], Step [152/225], Training Accuracy: 99.0234%, Training Loss: 0.0359%\n",
      "Epoch [106/300], Step [153/225], Training Accuracy: 99.0298%, Training Loss: 0.0357%\n",
      "Epoch [106/300], Step [154/225], Training Accuracy: 99.0260%, Training Loss: 0.0357%\n",
      "Epoch [106/300], Step [155/225], Training Accuracy: 99.0222%, Training Loss: 0.0356%\n",
      "Epoch [106/300], Step [156/225], Training Accuracy: 99.0284%, Training Loss: 0.0354%\n",
      "Epoch [106/300], Step [157/225], Training Accuracy: 99.0247%, Training Loss: 0.0355%\n",
      "Epoch [106/300], Step [158/225], Training Accuracy: 99.0210%, Training Loss: 0.0356%\n",
      "Epoch [106/300], Step [159/225], Training Accuracy: 99.0173%, Training Loss: 0.0358%\n",
      "Epoch [106/300], Step [160/225], Training Accuracy: 99.0234%, Training Loss: 0.0357%\n",
      "Epoch [106/300], Step [161/225], Training Accuracy: 99.0198%, Training Loss: 0.0357%\n",
      "Epoch [106/300], Step [162/225], Training Accuracy: 99.0162%, Training Loss: 0.0357%\n",
      "Epoch [106/300], Step [163/225], Training Accuracy: 99.0222%, Training Loss: 0.0356%\n",
      "Epoch [106/300], Step [164/225], Training Accuracy: 99.0282%, Training Loss: 0.0355%\n",
      "Epoch [106/300], Step [165/225], Training Accuracy: 99.0246%, Training Loss: 0.0356%\n",
      "Epoch [106/300], Step [166/225], Training Accuracy: 99.0211%, Training Loss: 0.0357%\n",
      "Epoch [106/300], Step [167/225], Training Accuracy: 99.0176%, Training Loss: 0.0357%\n",
      "Epoch [106/300], Step [168/225], Training Accuracy: 99.0141%, Training Loss: 0.0358%\n",
      "Epoch [106/300], Step [169/225], Training Accuracy: 99.0200%, Training Loss: 0.0358%\n",
      "Epoch [106/300], Step [170/225], Training Accuracy: 99.0165%, Training Loss: 0.0359%\n",
      "Epoch [106/300], Step [171/225], Training Accuracy: 99.0132%, Training Loss: 0.0359%\n",
      "Epoch [106/300], Step [172/225], Training Accuracy: 99.0189%, Training Loss: 0.0361%\n",
      "Epoch [106/300], Step [173/225], Training Accuracy: 99.0065%, Training Loss: 0.0361%\n",
      "Epoch [106/300], Step [174/225], Training Accuracy: 99.0032%, Training Loss: 0.0361%\n",
      "Epoch [106/300], Step [175/225], Training Accuracy: 99.0089%, Training Loss: 0.0360%\n",
      "Epoch [106/300], Step [176/225], Training Accuracy: 99.0057%, Training Loss: 0.0361%\n",
      "Epoch [106/300], Step [177/225], Training Accuracy: 99.0113%, Training Loss: 0.0360%\n",
      "Epoch [106/300], Step [178/225], Training Accuracy: 99.0081%, Training Loss: 0.0360%\n",
      "Epoch [106/300], Step [179/225], Training Accuracy: 99.0049%, Training Loss: 0.0360%\n",
      "Epoch [106/300], Step [180/225], Training Accuracy: 99.0104%, Training Loss: 0.0360%\n",
      "Epoch [106/300], Step [181/225], Training Accuracy: 98.9986%, Training Loss: 0.0360%\n",
      "Epoch [106/300], Step [182/225], Training Accuracy: 99.0041%, Training Loss: 0.0360%\n",
      "Epoch [106/300], Step [183/225], Training Accuracy: 99.0096%, Training Loss: 0.0358%\n",
      "Epoch [106/300], Step [184/225], Training Accuracy: 99.0149%, Training Loss: 0.0357%\n",
      "Epoch [106/300], Step [185/225], Training Accuracy: 99.0203%, Training Loss: 0.0357%\n",
      "Epoch [106/300], Step [186/225], Training Accuracy: 99.0255%, Training Loss: 0.0356%\n",
      "Epoch [106/300], Step [187/225], Training Accuracy: 99.0307%, Training Loss: 0.0354%\n",
      "Epoch [106/300], Step [188/225], Training Accuracy: 99.0359%, Training Loss: 0.0353%\n",
      "Epoch [106/300], Step [189/225], Training Accuracy: 99.0410%, Training Loss: 0.0352%\n",
      "Epoch [106/300], Step [190/225], Training Accuracy: 99.0461%, Training Loss: 0.0351%\n",
      "Epoch [106/300], Step [191/225], Training Accuracy: 99.0429%, Training Loss: 0.0351%\n",
      "Epoch [106/300], Step [192/225], Training Accuracy: 99.0479%, Training Loss: 0.0350%\n",
      "Epoch [106/300], Step [193/225], Training Accuracy: 99.0366%, Training Loss: 0.0350%\n",
      "Epoch [106/300], Step [194/225], Training Accuracy: 99.0416%, Training Loss: 0.0349%\n",
      "Epoch [106/300], Step [195/225], Training Accuracy: 99.0304%, Training Loss: 0.0350%\n",
      "Epoch [106/300], Step [196/225], Training Accuracy: 99.0354%, Training Loss: 0.0349%\n",
      "Epoch [106/300], Step [197/225], Training Accuracy: 99.0403%, Training Loss: 0.0348%\n",
      "Epoch [106/300], Step [198/225], Training Accuracy: 99.0451%, Training Loss: 0.0348%\n",
      "Epoch [106/300], Step [199/225], Training Accuracy: 99.0499%, Training Loss: 0.0347%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [106/300], Step [200/225], Training Accuracy: 99.0469%, Training Loss: 0.0346%\n",
      "Epoch [106/300], Step [201/225], Training Accuracy: 99.0438%, Training Loss: 0.0348%\n",
      "Epoch [106/300], Step [202/225], Training Accuracy: 99.0254%, Training Loss: 0.0353%\n",
      "Epoch [106/300], Step [203/225], Training Accuracy: 99.0302%, Training Loss: 0.0353%\n",
      "Epoch [106/300], Step [204/225], Training Accuracy: 99.0349%, Training Loss: 0.0353%\n",
      "Epoch [106/300], Step [205/225], Training Accuracy: 99.0396%, Training Loss: 0.0352%\n",
      "Epoch [106/300], Step [206/225], Training Accuracy: 99.0443%, Training Loss: 0.0352%\n",
      "Epoch [106/300], Step [207/225], Training Accuracy: 99.0489%, Training Loss: 0.0351%\n",
      "Epoch [106/300], Step [208/225], Training Accuracy: 99.0460%, Training Loss: 0.0351%\n",
      "Epoch [106/300], Step [209/225], Training Accuracy: 99.0431%, Training Loss: 0.0352%\n",
      "Epoch [106/300], Step [210/225], Training Accuracy: 99.0327%, Training Loss: 0.0353%\n",
      "Epoch [106/300], Step [211/225], Training Accuracy: 99.0373%, Training Loss: 0.0353%\n",
      "Epoch [106/300], Step [212/225], Training Accuracy: 99.0198%, Training Loss: 0.0355%\n",
      "Epoch [106/300], Step [213/225], Training Accuracy: 99.0244%, Training Loss: 0.0355%\n",
      "Epoch [106/300], Step [214/225], Training Accuracy: 99.0289%, Training Loss: 0.0354%\n",
      "Epoch [106/300], Step [215/225], Training Accuracy: 99.0334%, Training Loss: 0.0353%\n",
      "Epoch [106/300], Step [216/225], Training Accuracy: 99.0234%, Training Loss: 0.0354%\n",
      "Epoch [106/300], Step [217/225], Training Accuracy: 99.0207%, Training Loss: 0.0355%\n",
      "Epoch [106/300], Step [218/225], Training Accuracy: 99.0252%, Training Loss: 0.0354%\n",
      "Epoch [106/300], Step [219/225], Training Accuracy: 99.0297%, Training Loss: 0.0353%\n",
      "Epoch [106/300], Step [220/225], Training Accuracy: 99.0341%, Training Loss: 0.0352%\n",
      "Epoch [106/300], Step [221/225], Training Accuracy: 99.0314%, Training Loss: 0.0352%\n",
      "Epoch [106/300], Step [222/225], Training Accuracy: 99.0217%, Training Loss: 0.0353%\n",
      "Epoch [106/300], Step [223/225], Training Accuracy: 99.0191%, Training Loss: 0.0353%\n",
      "Epoch [106/300], Step [224/225], Training Accuracy: 99.0234%, Training Loss: 0.0352%\n",
      "Epoch [106/300], Step [225/225], Training Accuracy: 99.0272%, Training Loss: 0.0351%\n",
      "Epoch [107/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0125%\n",
      "Epoch [107/300], Step [2/225], Training Accuracy: 97.6562%, Training Loss: 0.0761%\n",
      "Epoch [107/300], Step [3/225], Training Accuracy: 97.9167%, Training Loss: 0.0626%\n",
      "Epoch [107/300], Step [4/225], Training Accuracy: 98.4375%, Training Loss: 0.0529%\n",
      "Epoch [107/300], Step [5/225], Training Accuracy: 98.7500%, Training Loss: 0.0493%\n",
      "Epoch [107/300], Step [6/225], Training Accuracy: 98.6979%, Training Loss: 0.0504%\n",
      "Epoch [107/300], Step [7/225], Training Accuracy: 98.8839%, Training Loss: 0.0484%\n",
      "Epoch [107/300], Step [8/225], Training Accuracy: 99.0234%, Training Loss: 0.0442%\n",
      "Epoch [107/300], Step [9/225], Training Accuracy: 99.1319%, Training Loss: 0.0405%\n",
      "Epoch [107/300], Step [10/225], Training Accuracy: 99.0625%, Training Loss: 0.0401%\n",
      "Epoch [107/300], Step [11/225], Training Accuracy: 99.1477%, Training Loss: 0.0396%\n",
      "Epoch [107/300], Step [12/225], Training Accuracy: 99.0885%, Training Loss: 0.0388%\n",
      "Epoch [107/300], Step [13/225], Training Accuracy: 99.1587%, Training Loss: 0.0381%\n",
      "Epoch [107/300], Step [14/225], Training Accuracy: 99.2188%, Training Loss: 0.0370%\n",
      "Epoch [107/300], Step [15/225], Training Accuracy: 99.2708%, Training Loss: 0.0359%\n",
      "Epoch [107/300], Step [16/225], Training Accuracy: 99.2188%, Training Loss: 0.0359%\n",
      "Epoch [107/300], Step [17/225], Training Accuracy: 99.0809%, Training Loss: 0.0380%\n",
      "Epoch [107/300], Step [18/225], Training Accuracy: 99.0451%, Training Loss: 0.0401%\n",
      "Epoch [107/300], Step [19/225], Training Accuracy: 99.0954%, Training Loss: 0.0390%\n",
      "Epoch [107/300], Step [20/225], Training Accuracy: 99.0625%, Training Loss: 0.0386%\n",
      "Epoch [107/300], Step [21/225], Training Accuracy: 98.9583%, Training Loss: 0.0391%\n",
      "Epoch [107/300], Step [22/225], Training Accuracy: 98.9347%, Training Loss: 0.0396%\n",
      "Epoch [107/300], Step [23/225], Training Accuracy: 98.9810%, Training Loss: 0.0385%\n",
      "Epoch [107/300], Step [24/225], Training Accuracy: 99.0234%, Training Loss: 0.0378%\n",
      "Epoch [107/300], Step [25/225], Training Accuracy: 99.0625%, Training Loss: 0.0373%\n",
      "Epoch [107/300], Step [26/225], Training Accuracy: 99.0986%, Training Loss: 0.0368%\n",
      "Epoch [107/300], Step [27/225], Training Accuracy: 99.0162%, Training Loss: 0.0372%\n",
      "Epoch [107/300], Step [28/225], Training Accuracy: 99.0513%, Training Loss: 0.0369%\n",
      "Epoch [107/300], Step [29/225], Training Accuracy: 99.0841%, Training Loss: 0.0365%\n",
      "Epoch [107/300], Step [30/225], Training Accuracy: 99.1146%, Training Loss: 0.0359%\n",
      "Epoch [107/300], Step [31/225], Training Accuracy: 99.0927%, Training Loss: 0.0359%\n",
      "Epoch [107/300], Step [32/225], Training Accuracy: 99.1211%, Training Loss: 0.0352%\n",
      "Epoch [107/300], Step [33/225], Training Accuracy: 99.1004%, Training Loss: 0.0352%\n",
      "Epoch [107/300], Step [34/225], Training Accuracy: 99.0809%, Training Loss: 0.0354%\n",
      "Epoch [107/300], Step [35/225], Training Accuracy: 99.0179%, Training Loss: 0.0370%\n",
      "Epoch [107/300], Step [36/225], Training Accuracy: 99.0451%, Training Loss: 0.0366%\n",
      "Epoch [107/300], Step [37/225], Training Accuracy: 99.0287%, Training Loss: 0.0381%\n",
      "Epoch [107/300], Step [38/225], Training Accuracy: 98.9720%, Training Loss: 0.0389%\n",
      "Epoch [107/300], Step [39/225], Training Accuracy: 98.9583%, Training Loss: 0.0389%\n",
      "Epoch [107/300], Step [40/225], Training Accuracy: 98.9844%, Training Loss: 0.0386%\n",
      "Epoch [107/300], Step [41/225], Training Accuracy: 99.0091%, Training Loss: 0.0383%\n",
      "Epoch [107/300], Step [42/225], Training Accuracy: 99.0327%, Training Loss: 0.0377%\n",
      "Epoch [107/300], Step [43/225], Training Accuracy: 99.0552%, Training Loss: 0.0371%\n",
      "Epoch [107/300], Step [44/225], Training Accuracy: 99.0767%, Training Loss: 0.0367%\n",
      "Epoch [107/300], Step [45/225], Training Accuracy: 99.0625%, Training Loss: 0.0370%\n",
      "Epoch [107/300], Step [46/225], Training Accuracy: 99.0489%, Training Loss: 0.0369%\n",
      "Epoch [107/300], Step [47/225], Training Accuracy: 99.0691%, Training Loss: 0.0364%\n",
      "Epoch [107/300], Step [48/225], Training Accuracy: 99.0885%, Training Loss: 0.0360%\n",
      "Epoch [107/300], Step [49/225], Training Accuracy: 99.1071%, Training Loss: 0.0355%\n",
      "Epoch [107/300], Step [50/225], Training Accuracy: 99.0938%, Training Loss: 0.0359%\n",
      "Epoch [107/300], Step [51/225], Training Accuracy: 99.1115%, Training Loss: 0.0353%\n",
      "Epoch [107/300], Step [52/225], Training Accuracy: 99.1286%, Training Loss: 0.0348%\n",
      "Epoch [107/300], Step [53/225], Training Accuracy: 99.1450%, Training Loss: 0.0346%\n",
      "Epoch [107/300], Step [54/225], Training Accuracy: 99.1609%, Training Loss: 0.0344%\n",
      "Epoch [107/300], Step [55/225], Training Accuracy: 99.1761%, Training Loss: 0.0339%\n",
      "Epoch [107/300], Step [56/225], Training Accuracy: 99.1629%, Training Loss: 0.0341%\n",
      "Epoch [107/300], Step [57/225], Training Accuracy: 99.1776%, Training Loss: 0.0338%\n",
      "Epoch [107/300], Step [58/225], Training Accuracy: 99.1918%, Training Loss: 0.0334%\n",
      "Epoch [107/300], Step [59/225], Training Accuracy: 99.1525%, Training Loss: 0.0337%\n",
      "Epoch [107/300], Step [60/225], Training Accuracy: 99.1667%, Training Loss: 0.0335%\n",
      "Epoch [107/300], Step [61/225], Training Accuracy: 99.1547%, Training Loss: 0.0337%\n",
      "Epoch [107/300], Step [62/225], Training Accuracy: 99.1683%, Training Loss: 0.0334%\n",
      "Epoch [107/300], Step [63/225], Training Accuracy: 99.1815%, Training Loss: 0.0332%\n",
      "Epoch [107/300], Step [64/225], Training Accuracy: 99.1943%, Training Loss: 0.0331%\n",
      "Epoch [107/300], Step [65/225], Training Accuracy: 99.1587%, Training Loss: 0.0332%\n",
      "Epoch [107/300], Step [66/225], Training Accuracy: 99.1241%, Training Loss: 0.0334%\n",
      "Epoch [107/300], Step [67/225], Training Accuracy: 99.1138%, Training Loss: 0.0333%\n",
      "Epoch [107/300], Step [68/225], Training Accuracy: 99.1268%, Training Loss: 0.0329%\n",
      "Epoch [107/300], Step [69/225], Training Accuracy: 99.1395%, Training Loss: 0.0329%\n",
      "Epoch [107/300], Step [70/225], Training Accuracy: 99.1295%, Training Loss: 0.0331%\n",
      "Epoch [107/300], Step [71/225], Training Accuracy: 99.1417%, Training Loss: 0.0329%\n",
      "Epoch [107/300], Step [72/225], Training Accuracy: 99.1536%, Training Loss: 0.0327%\n",
      "Epoch [107/300], Step [73/225], Training Accuracy: 99.1652%, Training Loss: 0.0328%\n",
      "Epoch [107/300], Step [74/225], Training Accuracy: 99.1554%, Training Loss: 0.0331%\n",
      "Epoch [107/300], Step [75/225], Training Accuracy: 99.1458%, Training Loss: 0.0330%\n",
      "Epoch [107/300], Step [76/225], Training Accuracy: 99.1365%, Training Loss: 0.0330%\n",
      "Epoch [107/300], Step [77/225], Training Accuracy: 99.1274%, Training Loss: 0.0332%\n",
      "Epoch [107/300], Step [78/225], Training Accuracy: 99.1186%, Training Loss: 0.0332%\n",
      "Epoch [107/300], Step [79/225], Training Accuracy: 99.1297%, Training Loss: 0.0330%\n",
      "Epoch [107/300], Step [80/225], Training Accuracy: 99.1016%, Training Loss: 0.0335%\n",
      "Epoch [107/300], Step [81/225], Training Accuracy: 99.0934%, Training Loss: 0.0339%\n",
      "Epoch [107/300], Step [82/225], Training Accuracy: 99.1044%, Training Loss: 0.0337%\n",
      "Epoch [107/300], Step [83/225], Training Accuracy: 99.0964%, Training Loss: 0.0339%\n",
      "Epoch [107/300], Step [84/225], Training Accuracy: 99.1071%, Training Loss: 0.0338%\n",
      "Epoch [107/300], Step [85/225], Training Accuracy: 99.1176%, Training Loss: 0.0336%\n",
      "Epoch [107/300], Step [86/225], Training Accuracy: 99.0916%, Training Loss: 0.0342%\n",
      "Epoch [107/300], Step [87/225], Training Accuracy: 99.1020%, Training Loss: 0.0340%\n",
      "Epoch [107/300], Step [88/225], Training Accuracy: 99.0945%, Training Loss: 0.0341%\n",
      "Epoch [107/300], Step [89/225], Training Accuracy: 99.0695%, Training Loss: 0.0343%\n",
      "Epoch [107/300], Step [90/225], Training Accuracy: 99.0451%, Training Loss: 0.0345%\n",
      "Epoch [107/300], Step [91/225], Training Accuracy: 99.0556%, Training Loss: 0.0343%\n",
      "Epoch [107/300], Step [92/225], Training Accuracy: 99.0489%, Training Loss: 0.0348%\n",
      "Epoch [107/300], Step [93/225], Training Accuracy: 99.0087%, Training Loss: 0.0353%\n",
      "Epoch [107/300], Step [94/225], Training Accuracy: 99.0193%, Training Loss: 0.0352%\n",
      "Epoch [107/300], Step [95/225], Training Accuracy: 99.0132%, Training Loss: 0.0352%\n",
      "Epoch [107/300], Step [96/225], Training Accuracy: 99.0234%, Training Loss: 0.0350%\n",
      "Epoch [107/300], Step [97/225], Training Accuracy: 99.0013%, Training Loss: 0.0354%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [107/300], Step [98/225], Training Accuracy: 98.9955%, Training Loss: 0.0357%\n",
      "Epoch [107/300], Step [99/225], Training Accuracy: 98.9899%, Training Loss: 0.0357%\n",
      "Epoch [107/300], Step [100/225], Training Accuracy: 99.0000%, Training Loss: 0.0356%\n",
      "Epoch [107/300], Step [101/225], Training Accuracy: 99.0099%, Training Loss: 0.0355%\n",
      "Epoch [107/300], Step [102/225], Training Accuracy: 99.0043%, Training Loss: 0.0361%\n",
      "Epoch [107/300], Step [103/225], Training Accuracy: 98.9988%, Training Loss: 0.0363%\n",
      "Epoch [107/300], Step [104/225], Training Accuracy: 99.0084%, Training Loss: 0.0361%\n",
      "Epoch [107/300], Step [105/225], Training Accuracy: 99.0179%, Training Loss: 0.0361%\n",
      "Epoch [107/300], Step [106/225], Training Accuracy: 99.0271%, Training Loss: 0.0360%\n",
      "Epoch [107/300], Step [107/225], Training Accuracy: 99.0216%, Training Loss: 0.0361%\n",
      "Epoch [107/300], Step [108/225], Training Accuracy: 99.0162%, Training Loss: 0.0361%\n",
      "Epoch [107/300], Step [109/225], Training Accuracy: 99.0252%, Training Loss: 0.0359%\n",
      "Epoch [107/300], Step [110/225], Training Accuracy: 99.0341%, Training Loss: 0.0356%\n",
      "Epoch [107/300], Step [111/225], Training Accuracy: 99.0428%, Training Loss: 0.0355%\n",
      "Epoch [107/300], Step [112/225], Training Accuracy: 99.0513%, Training Loss: 0.0354%\n",
      "Epoch [107/300], Step [113/225], Training Accuracy: 99.0597%, Training Loss: 0.0352%\n",
      "Epoch [107/300], Step [114/225], Training Accuracy: 99.0680%, Training Loss: 0.0352%\n",
      "Epoch [107/300], Step [115/225], Training Accuracy: 99.0761%, Training Loss: 0.0351%\n",
      "Epoch [107/300], Step [116/225], Training Accuracy: 99.0841%, Training Loss: 0.0351%\n",
      "Epoch [107/300], Step [117/225], Training Accuracy: 99.0785%, Training Loss: 0.0352%\n",
      "Epoch [107/300], Step [118/225], Training Accuracy: 99.0599%, Training Loss: 0.0354%\n",
      "Epoch [107/300], Step [119/225], Training Accuracy: 99.0546%, Training Loss: 0.0355%\n",
      "Epoch [107/300], Step [120/225], Training Accuracy: 99.0495%, Training Loss: 0.0355%\n",
      "Epoch [107/300], Step [121/225], Training Accuracy: 99.0573%, Training Loss: 0.0354%\n",
      "Epoch [107/300], Step [122/225], Training Accuracy: 99.0523%, Training Loss: 0.0355%\n",
      "Epoch [107/300], Step [123/225], Training Accuracy: 99.0218%, Training Loss: 0.0362%\n",
      "Epoch [107/300], Step [124/225], Training Accuracy: 99.0171%, Training Loss: 0.0363%\n",
      "Epoch [107/300], Step [125/225], Training Accuracy: 99.0250%, Training Loss: 0.0364%\n",
      "Epoch [107/300], Step [126/225], Training Accuracy: 99.0079%, Training Loss: 0.0366%\n",
      "Epoch [107/300], Step [127/225], Training Accuracy: 99.0157%, Training Loss: 0.0365%\n",
      "Epoch [107/300], Step [128/225], Training Accuracy: 99.0234%, Training Loss: 0.0366%\n",
      "Epoch [107/300], Step [129/225], Training Accuracy: 99.0189%, Training Loss: 0.0367%\n",
      "Epoch [107/300], Step [130/225], Training Accuracy: 99.0264%, Training Loss: 0.0365%\n",
      "Epoch [107/300], Step [131/225], Training Accuracy: 99.0339%, Training Loss: 0.0364%\n",
      "Epoch [107/300], Step [132/225], Training Accuracy: 99.0412%, Training Loss: 0.0362%\n",
      "Epoch [107/300], Step [133/225], Training Accuracy: 99.0484%, Training Loss: 0.0361%\n",
      "Epoch [107/300], Step [134/225], Training Accuracy: 99.0555%, Training Loss: 0.0360%\n",
      "Epoch [107/300], Step [135/225], Training Accuracy: 99.0625%, Training Loss: 0.0359%\n",
      "Epoch [107/300], Step [136/225], Training Accuracy: 99.0694%, Training Loss: 0.0359%\n",
      "Epoch [107/300], Step [137/225], Training Accuracy: 99.0762%, Training Loss: 0.0358%\n",
      "Epoch [107/300], Step [138/225], Training Accuracy: 99.0602%, Training Loss: 0.0362%\n",
      "Epoch [107/300], Step [139/225], Training Accuracy: 99.0558%, Training Loss: 0.0364%\n",
      "Epoch [107/300], Step [140/225], Training Accuracy: 99.0402%, Training Loss: 0.0366%\n",
      "Epoch [107/300], Step [141/225], Training Accuracy: 99.0248%, Training Loss: 0.0370%\n",
      "Epoch [107/300], Step [142/225], Training Accuracy: 99.0207%, Training Loss: 0.0370%\n",
      "Epoch [107/300], Step [143/225], Training Accuracy: 99.0275%, Training Loss: 0.0368%\n",
      "Epoch [107/300], Step [144/225], Training Accuracy: 99.0234%, Training Loss: 0.0368%\n",
      "Epoch [107/300], Step [145/225], Training Accuracy: 99.0302%, Training Loss: 0.0366%\n",
      "Epoch [107/300], Step [146/225], Training Accuracy: 99.0261%, Training Loss: 0.0365%\n",
      "Epoch [107/300], Step [147/225], Training Accuracy: 99.0115%, Training Loss: 0.0366%\n",
      "Epoch [107/300], Step [148/225], Training Accuracy: 99.0182%, Training Loss: 0.0365%\n",
      "Epoch [107/300], Step [149/225], Training Accuracy: 99.0247%, Training Loss: 0.0365%\n",
      "Epoch [107/300], Step [150/225], Training Accuracy: 99.0104%, Training Loss: 0.0367%\n",
      "Epoch [107/300], Step [151/225], Training Accuracy: 98.9963%, Training Loss: 0.0370%\n",
      "Epoch [107/300], Step [152/225], Training Accuracy: 98.9926%, Training Loss: 0.0370%\n",
      "Epoch [107/300], Step [153/225], Training Accuracy: 98.9788%, Training Loss: 0.0371%\n",
      "Epoch [107/300], Step [154/225], Training Accuracy: 98.9854%, Training Loss: 0.0371%\n",
      "Epoch [107/300], Step [155/225], Training Accuracy: 98.9617%, Training Loss: 0.0373%\n",
      "Epoch [107/300], Step [156/225], Training Accuracy: 98.9583%, Training Loss: 0.0372%\n",
      "Epoch [107/300], Step [157/225], Training Accuracy: 98.9550%, Training Loss: 0.0372%\n",
      "Epoch [107/300], Step [158/225], Training Accuracy: 98.9616%, Training Loss: 0.0371%\n",
      "Epoch [107/300], Step [159/225], Training Accuracy: 98.9583%, Training Loss: 0.0374%\n",
      "Epoch [107/300], Step [160/225], Training Accuracy: 98.9551%, Training Loss: 0.0373%\n",
      "Epoch [107/300], Step [161/225], Training Accuracy: 98.9616%, Training Loss: 0.0372%\n",
      "Epoch [107/300], Step [162/225], Training Accuracy: 98.9583%, Training Loss: 0.0374%\n",
      "Epoch [107/300], Step [163/225], Training Accuracy: 98.9551%, Training Loss: 0.0374%\n",
      "Epoch [107/300], Step [164/225], Training Accuracy: 98.9520%, Training Loss: 0.0376%\n",
      "Epoch [107/300], Step [165/225], Training Accuracy: 98.9489%, Training Loss: 0.0376%\n",
      "Epoch [107/300], Step [166/225], Training Accuracy: 98.9364%, Training Loss: 0.0379%\n",
      "Epoch [107/300], Step [167/225], Training Accuracy: 98.9427%, Training Loss: 0.0377%\n",
      "Epoch [107/300], Step [168/225], Training Accuracy: 98.9490%, Training Loss: 0.0376%\n",
      "Epoch [107/300], Step [169/225], Training Accuracy: 98.9553%, Training Loss: 0.0375%\n",
      "Epoch [107/300], Step [170/225], Training Accuracy: 98.9522%, Training Loss: 0.0376%\n",
      "Epoch [107/300], Step [171/225], Training Accuracy: 98.9583%, Training Loss: 0.0376%\n",
      "Epoch [107/300], Step [172/225], Training Accuracy: 98.9644%, Training Loss: 0.0375%\n",
      "Epoch [107/300], Step [173/225], Training Accuracy: 98.9613%, Training Loss: 0.0375%\n",
      "Epoch [107/300], Step [174/225], Training Accuracy: 98.9583%, Training Loss: 0.0375%\n",
      "Epoch [107/300], Step [175/225], Training Accuracy: 98.9554%, Training Loss: 0.0377%\n",
      "Epoch [107/300], Step [176/225], Training Accuracy: 98.9613%, Training Loss: 0.0375%\n",
      "Epoch [107/300], Step [177/225], Training Accuracy: 98.9495%, Training Loss: 0.0379%\n",
      "Epoch [107/300], Step [178/225], Training Accuracy: 98.9466%, Training Loss: 0.0379%\n",
      "Epoch [107/300], Step [179/225], Training Accuracy: 98.9525%, Training Loss: 0.0378%\n",
      "Epoch [107/300], Step [180/225], Training Accuracy: 98.9497%, Training Loss: 0.0377%\n",
      "Epoch [107/300], Step [181/225], Training Accuracy: 98.9296%, Training Loss: 0.0381%\n",
      "Epoch [107/300], Step [182/225], Training Accuracy: 98.9354%, Training Loss: 0.0380%\n",
      "Epoch [107/300], Step [183/225], Training Accuracy: 98.9413%, Training Loss: 0.0379%\n",
      "Epoch [107/300], Step [184/225], Training Accuracy: 98.9385%, Training Loss: 0.0379%\n",
      "Epoch [107/300], Step [185/225], Training Accuracy: 98.9274%, Training Loss: 0.0380%\n",
      "Epoch [107/300], Step [186/225], Training Accuracy: 98.9331%, Training Loss: 0.0378%\n",
      "Epoch [107/300], Step [187/225], Training Accuracy: 98.9305%, Training Loss: 0.0378%\n",
      "Epoch [107/300], Step [188/225], Training Accuracy: 98.9362%, Training Loss: 0.0377%\n",
      "Epoch [107/300], Step [189/225], Training Accuracy: 98.9418%, Training Loss: 0.0375%\n",
      "Epoch [107/300], Step [190/225], Training Accuracy: 98.9309%, Training Loss: 0.0377%\n",
      "Epoch [107/300], Step [191/225], Training Accuracy: 98.9365%, Training Loss: 0.0375%\n",
      "Epoch [107/300], Step [192/225], Training Accuracy: 98.9339%, Training Loss: 0.0376%\n",
      "Epoch [107/300], Step [193/225], Training Accuracy: 98.9233%, Training Loss: 0.0379%\n",
      "Epoch [107/300], Step [194/225], Training Accuracy: 98.9127%, Training Loss: 0.0380%\n",
      "Epoch [107/300], Step [195/225], Training Accuracy: 98.9022%, Training Loss: 0.0381%\n",
      "Epoch [107/300], Step [196/225], Training Accuracy: 98.9078%, Training Loss: 0.0380%\n",
      "Epoch [107/300], Step [197/225], Training Accuracy: 98.9134%, Training Loss: 0.0380%\n",
      "Epoch [107/300], Step [198/225], Training Accuracy: 98.9189%, Training Loss: 0.0380%\n",
      "Epoch [107/300], Step [199/225], Training Accuracy: 98.9243%, Training Loss: 0.0380%\n",
      "Epoch [107/300], Step [200/225], Training Accuracy: 98.9297%, Training Loss: 0.0379%\n",
      "Epoch [107/300], Step [201/225], Training Accuracy: 98.9117%, Training Loss: 0.0381%\n",
      "Epoch [107/300], Step [202/225], Training Accuracy: 98.9016%, Training Loss: 0.0383%\n",
      "Epoch [107/300], Step [203/225], Training Accuracy: 98.9070%, Training Loss: 0.0382%\n",
      "Epoch [107/300], Step [204/225], Training Accuracy: 98.9047%, Training Loss: 0.0383%\n",
      "Epoch [107/300], Step [205/225], Training Accuracy: 98.9101%, Training Loss: 0.0383%\n",
      "Epoch [107/300], Step [206/225], Training Accuracy: 98.9002%, Training Loss: 0.0385%\n",
      "Epoch [107/300], Step [207/225], Training Accuracy: 98.9055%, Training Loss: 0.0384%\n",
      "Epoch [107/300], Step [208/225], Training Accuracy: 98.9032%, Training Loss: 0.0384%\n",
      "Epoch [107/300], Step [209/225], Training Accuracy: 98.9010%, Training Loss: 0.0384%\n",
      "Epoch [107/300], Step [210/225], Training Accuracy: 98.8988%, Training Loss: 0.0383%\n",
      "Epoch [107/300], Step [211/225], Training Accuracy: 98.9040%, Training Loss: 0.0382%\n",
      "Epoch [107/300], Step [212/225], Training Accuracy: 98.9092%, Training Loss: 0.0381%\n",
      "Epoch [107/300], Step [213/225], Training Accuracy: 98.9143%, Training Loss: 0.0381%\n",
      "Epoch [107/300], Step [214/225], Training Accuracy: 98.9048%, Training Loss: 0.0382%\n",
      "Epoch [107/300], Step [215/225], Training Accuracy: 98.9099%, Training Loss: 0.0381%\n",
      "Epoch [107/300], Step [216/225], Training Accuracy: 98.9077%, Training Loss: 0.0381%\n",
      "Epoch [107/300], Step [217/225], Training Accuracy: 98.9127%, Training Loss: 0.0381%\n",
      "Epoch [107/300], Step [218/225], Training Accuracy: 98.9106%, Training Loss: 0.0381%\n",
      "Epoch [107/300], Step [219/225], Training Accuracy: 98.9084%, Training Loss: 0.0382%\n",
      "Epoch [107/300], Step [220/225], Training Accuracy: 98.9134%, Training Loss: 0.0381%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [107/300], Step [221/225], Training Accuracy: 98.9112%, Training Loss: 0.0381%\n",
      "Epoch [107/300], Step [222/225], Training Accuracy: 98.9091%, Training Loss: 0.0382%\n",
      "Epoch [107/300], Step [223/225], Training Accuracy: 98.9140%, Training Loss: 0.0381%\n",
      "Epoch [107/300], Step [224/225], Training Accuracy: 98.9188%, Training Loss: 0.0380%\n",
      "Epoch [107/300], Step [225/225], Training Accuracy: 98.9230%, Training Loss: 0.0379%\n",
      "Epoch [108/300], Step [1/225], Training Accuracy: 96.8750%, Training Loss: 0.0505%\n",
      "Epoch [108/300], Step [2/225], Training Accuracy: 98.4375%, Training Loss: 0.0361%\n",
      "Epoch [108/300], Step [3/225], Training Accuracy: 98.9583%, Training Loss: 0.0286%\n",
      "Epoch [108/300], Step [4/225], Training Accuracy: 99.2188%, Training Loss: 0.0247%\n",
      "Epoch [108/300], Step [5/225], Training Accuracy: 99.3750%, Training Loss: 0.0265%\n",
      "Epoch [108/300], Step [6/225], Training Accuracy: 99.2188%, Training Loss: 0.0309%\n",
      "Epoch [108/300], Step [7/225], Training Accuracy: 99.1071%, Training Loss: 0.0321%\n",
      "Epoch [108/300], Step [8/225], Training Accuracy: 99.0234%, Training Loss: 0.0330%\n",
      "Epoch [108/300], Step [9/225], Training Accuracy: 98.9583%, Training Loss: 0.0356%\n",
      "Epoch [108/300], Step [10/225], Training Accuracy: 98.9062%, Training Loss: 0.0371%\n",
      "Epoch [108/300], Step [11/225], Training Accuracy: 99.0057%, Training Loss: 0.0349%\n",
      "Epoch [108/300], Step [12/225], Training Accuracy: 99.0885%, Training Loss: 0.0331%\n",
      "Epoch [108/300], Step [13/225], Training Accuracy: 99.1587%, Training Loss: 0.0316%\n",
      "Epoch [108/300], Step [14/225], Training Accuracy: 99.1071%, Training Loss: 0.0329%\n",
      "Epoch [108/300], Step [15/225], Training Accuracy: 99.1667%, Training Loss: 0.0319%\n",
      "Epoch [108/300], Step [16/225], Training Accuracy: 99.2188%, Training Loss: 0.0305%\n",
      "Epoch [108/300], Step [17/225], Training Accuracy: 99.1728%, Training Loss: 0.0326%\n",
      "Epoch [108/300], Step [18/225], Training Accuracy: 99.1319%, Training Loss: 0.0368%\n",
      "Epoch [108/300], Step [19/225], Training Accuracy: 99.0954%, Training Loss: 0.0375%\n",
      "Epoch [108/300], Step [20/225], Training Accuracy: 99.0625%, Training Loss: 0.0377%\n",
      "Epoch [108/300], Step [21/225], Training Accuracy: 99.1071%, Training Loss: 0.0372%\n",
      "Epoch [108/300], Step [22/225], Training Accuracy: 99.0767%, Training Loss: 0.0374%\n",
      "Epoch [108/300], Step [23/225], Training Accuracy: 99.1168%, Training Loss: 0.0373%\n",
      "Epoch [108/300], Step [24/225], Training Accuracy: 99.0234%, Training Loss: 0.0387%\n",
      "Epoch [108/300], Step [25/225], Training Accuracy: 98.9375%, Training Loss: 0.0401%\n",
      "Epoch [108/300], Step [26/225], Training Accuracy: 98.9183%, Training Loss: 0.0403%\n",
      "Epoch [108/300], Step [27/225], Training Accuracy: 98.8426%, Training Loss: 0.0416%\n",
      "Epoch [108/300], Step [28/225], Training Accuracy: 98.8839%, Training Loss: 0.0409%\n",
      "Epoch [108/300], Step [29/225], Training Accuracy: 98.8147%, Training Loss: 0.0425%\n",
      "Epoch [108/300], Step [30/225], Training Accuracy: 98.8021%, Training Loss: 0.0419%\n",
      "Epoch [108/300], Step [31/225], Training Accuracy: 98.7903%, Training Loss: 0.0441%\n",
      "Epoch [108/300], Step [32/225], Training Accuracy: 98.7305%, Training Loss: 0.0442%\n",
      "Epoch [108/300], Step [33/225], Training Accuracy: 98.7216%, Training Loss: 0.0443%\n",
      "Epoch [108/300], Step [34/225], Training Accuracy: 98.7132%, Training Loss: 0.0442%\n",
      "Epoch [108/300], Step [35/225], Training Accuracy: 98.7054%, Training Loss: 0.0439%\n",
      "Epoch [108/300], Step [36/225], Training Accuracy: 98.7413%, Training Loss: 0.0429%\n",
      "Epoch [108/300], Step [37/225], Training Accuracy: 98.7331%, Training Loss: 0.0426%\n",
      "Epoch [108/300], Step [38/225], Training Accuracy: 98.7253%, Training Loss: 0.0423%\n",
      "Epoch [108/300], Step [39/225], Training Accuracy: 98.7179%, Training Loss: 0.0447%\n",
      "Epoch [108/300], Step [40/225], Training Accuracy: 98.6719%, Training Loss: 0.0452%\n",
      "Epoch [108/300], Step [41/225], Training Accuracy: 98.6662%, Training Loss: 0.0449%\n",
      "Epoch [108/300], Step [42/225], Training Accuracy: 98.6235%, Training Loss: 0.0448%\n",
      "Epoch [108/300], Step [43/225], Training Accuracy: 98.6555%, Training Loss: 0.0441%\n",
      "Epoch [108/300], Step [44/225], Training Accuracy: 98.6506%, Training Loss: 0.0445%\n",
      "Epoch [108/300], Step [45/225], Training Accuracy: 98.6458%, Training Loss: 0.0442%\n",
      "Epoch [108/300], Step [46/225], Training Accuracy: 98.6413%, Training Loss: 0.0446%\n",
      "Epoch [108/300], Step [47/225], Training Accuracy: 98.6702%, Training Loss: 0.0441%\n",
      "Epoch [108/300], Step [48/225], Training Accuracy: 98.6979%, Training Loss: 0.0437%\n",
      "Epoch [108/300], Step [49/225], Training Accuracy: 98.6926%, Training Loss: 0.0436%\n",
      "Epoch [108/300], Step [50/225], Training Accuracy: 98.6875%, Training Loss: 0.0434%\n",
      "Epoch [108/300], Step [51/225], Training Accuracy: 98.6826%, Training Loss: 0.0432%\n",
      "Epoch [108/300], Step [52/225], Training Accuracy: 98.7079%, Training Loss: 0.0426%\n",
      "Epoch [108/300], Step [53/225], Training Accuracy: 98.7323%, Training Loss: 0.0423%\n",
      "Epoch [108/300], Step [54/225], Training Accuracy: 98.7558%, Training Loss: 0.0418%\n",
      "Epoch [108/300], Step [55/225], Training Accuracy: 98.7784%, Training Loss: 0.0413%\n",
      "Epoch [108/300], Step [56/225], Training Accuracy: 98.7444%, Training Loss: 0.0418%\n",
      "Epoch [108/300], Step [57/225], Training Accuracy: 98.7390%, Training Loss: 0.0418%\n",
      "Epoch [108/300], Step [58/225], Training Accuracy: 98.7338%, Training Loss: 0.0419%\n",
      "Epoch [108/300], Step [59/225], Training Accuracy: 98.7288%, Training Loss: 0.0418%\n",
      "Epoch [108/300], Step [60/225], Training Accuracy: 98.7240%, Training Loss: 0.0416%\n",
      "Epoch [108/300], Step [61/225], Training Accuracy: 98.7193%, Training Loss: 0.0421%\n",
      "Epoch [108/300], Step [62/225], Training Accuracy: 98.7399%, Training Loss: 0.0417%\n",
      "Epoch [108/300], Step [63/225], Training Accuracy: 98.7599%, Training Loss: 0.0413%\n",
      "Epoch [108/300], Step [64/225], Training Accuracy: 98.7549%, Training Loss: 0.0413%\n",
      "Epoch [108/300], Step [65/225], Training Accuracy: 98.7260%, Training Loss: 0.0413%\n",
      "Epoch [108/300], Step [66/225], Training Accuracy: 98.7453%, Training Loss: 0.0410%\n",
      "Epoch [108/300], Step [67/225], Training Accuracy: 98.7407%, Training Loss: 0.0410%\n",
      "Epoch [108/300], Step [68/225], Training Accuracy: 98.7362%, Training Loss: 0.0408%\n",
      "Epoch [108/300], Step [69/225], Training Accuracy: 98.7545%, Training Loss: 0.0407%\n",
      "Epoch [108/300], Step [70/225], Training Accuracy: 98.7723%, Training Loss: 0.0405%\n",
      "Epoch [108/300], Step [71/225], Training Accuracy: 98.7676%, Training Loss: 0.0406%\n",
      "Epoch [108/300], Step [72/225], Training Accuracy: 98.7630%, Training Loss: 0.0404%\n",
      "Epoch [108/300], Step [73/225], Training Accuracy: 98.7800%, Training Loss: 0.0402%\n",
      "Epoch [108/300], Step [74/225], Training Accuracy: 98.7965%, Training Loss: 0.0400%\n",
      "Epoch [108/300], Step [75/225], Training Accuracy: 98.7917%, Training Loss: 0.0402%\n",
      "Epoch [108/300], Step [76/225], Training Accuracy: 98.8076%, Training Loss: 0.0400%\n",
      "Epoch [108/300], Step [77/225], Training Accuracy: 98.8028%, Training Loss: 0.0399%\n",
      "Epoch [108/300], Step [78/225], Training Accuracy: 98.8181%, Training Loss: 0.0397%\n",
      "Epoch [108/300], Step [79/225], Training Accuracy: 98.8133%, Training Loss: 0.0398%\n",
      "Epoch [108/300], Step [80/225], Training Accuracy: 98.8281%, Training Loss: 0.0398%\n",
      "Epoch [108/300], Step [81/225], Training Accuracy: 98.8426%, Training Loss: 0.0396%\n",
      "Epoch [108/300], Step [82/225], Training Accuracy: 98.8377%, Training Loss: 0.0395%\n",
      "Epoch [108/300], Step [83/225], Training Accuracy: 98.7952%, Training Loss: 0.0398%\n",
      "Epoch [108/300], Step [84/225], Training Accuracy: 98.7909%, Training Loss: 0.0401%\n",
      "Epoch [108/300], Step [85/225], Training Accuracy: 98.7868%, Training Loss: 0.0400%\n",
      "Epoch [108/300], Step [86/225], Training Accuracy: 98.7827%, Training Loss: 0.0402%\n",
      "Epoch [108/300], Step [87/225], Training Accuracy: 98.7967%, Training Loss: 0.0398%\n",
      "Epoch [108/300], Step [88/225], Training Accuracy: 98.8104%, Training Loss: 0.0396%\n",
      "Epoch [108/300], Step [89/225], Training Accuracy: 98.8237%, Training Loss: 0.0394%\n",
      "Epoch [108/300], Step [90/225], Training Accuracy: 98.8194%, Training Loss: 0.0394%\n",
      "Epoch [108/300], Step [91/225], Training Accuracy: 98.8324%, Training Loss: 0.0391%\n",
      "Epoch [108/300], Step [92/225], Training Accuracy: 98.8451%, Training Loss: 0.0389%\n",
      "Epoch [108/300], Step [93/225], Training Accuracy: 98.8575%, Training Loss: 0.0389%\n",
      "Epoch [108/300], Step [94/225], Training Accuracy: 98.8697%, Training Loss: 0.0388%\n",
      "Epoch [108/300], Step [95/225], Training Accuracy: 98.8816%, Training Loss: 0.0386%\n",
      "Epoch [108/300], Step [96/225], Training Accuracy: 98.8770%, Training Loss: 0.0386%\n",
      "Epoch [108/300], Step [97/225], Training Accuracy: 98.8724%, Training Loss: 0.0388%\n",
      "Epoch [108/300], Step [98/225], Training Accuracy: 98.8361%, Training Loss: 0.0393%\n",
      "Epoch [108/300], Step [99/225], Training Accuracy: 98.8321%, Training Loss: 0.0392%\n",
      "Epoch [108/300], Step [100/225], Training Accuracy: 98.8125%, Training Loss: 0.0392%\n",
      "Epoch [108/300], Step [101/225], Training Accuracy: 98.8088%, Training Loss: 0.0395%\n",
      "Epoch [108/300], Step [102/225], Training Accuracy: 98.8051%, Training Loss: 0.0394%\n",
      "Epoch [108/300], Step [103/225], Training Accuracy: 98.8167%, Training Loss: 0.0391%\n",
      "Epoch [108/300], Step [104/225], Training Accuracy: 98.8281%, Training Loss: 0.0388%\n",
      "Epoch [108/300], Step [105/225], Training Accuracy: 98.8393%, Training Loss: 0.0388%\n",
      "Epoch [108/300], Step [106/225], Training Accuracy: 98.8502%, Training Loss: 0.0385%\n",
      "Epoch [108/300], Step [107/225], Training Accuracy: 98.8464%, Training Loss: 0.0384%\n",
      "Epoch [108/300], Step [108/225], Training Accuracy: 98.8426%, Training Loss: 0.0383%\n",
      "Epoch [108/300], Step [109/225], Training Accuracy: 98.8532%, Training Loss: 0.0382%\n",
      "Epoch [108/300], Step [110/225], Training Accuracy: 98.8636%, Training Loss: 0.0380%\n",
      "Epoch [108/300], Step [111/225], Training Accuracy: 98.8457%, Training Loss: 0.0381%\n",
      "Epoch [108/300], Step [112/225], Training Accuracy: 98.8560%, Training Loss: 0.0380%\n",
      "Epoch [108/300], Step [113/225], Training Accuracy: 98.8662%, Training Loss: 0.0377%\n",
      "Epoch [108/300], Step [114/225], Training Accuracy: 98.8761%, Training Loss: 0.0377%\n",
      "Epoch [108/300], Step [115/225], Training Accuracy: 98.8859%, Training Loss: 0.0375%\n",
      "Epoch [108/300], Step [116/225], Training Accuracy: 98.8955%, Training Loss: 0.0373%\n",
      "Epoch [108/300], Step [117/225], Training Accuracy: 98.9049%, Training Loss: 0.0371%\n",
      "Epoch [108/300], Step [118/225], Training Accuracy: 98.8877%, Training Loss: 0.0371%\n",
      "Epoch [108/300], Step [119/225], Training Accuracy: 98.8839%, Training Loss: 0.0371%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [108/300], Step [120/225], Training Accuracy: 98.8802%, Training Loss: 0.0371%\n",
      "Epoch [108/300], Step [121/225], Training Accuracy: 98.8895%, Training Loss: 0.0369%\n",
      "Epoch [108/300], Step [122/225], Training Accuracy: 98.8986%, Training Loss: 0.0367%\n",
      "Epoch [108/300], Step [123/225], Training Accuracy: 98.9075%, Training Loss: 0.0365%\n",
      "Epoch [108/300], Step [124/225], Training Accuracy: 98.9163%, Training Loss: 0.0364%\n",
      "Epoch [108/300], Step [125/225], Training Accuracy: 98.9000%, Training Loss: 0.0367%\n",
      "Epoch [108/300], Step [126/225], Training Accuracy: 98.8715%, Training Loss: 0.0368%\n",
      "Epoch [108/300], Step [127/225], Training Accuracy: 98.8804%, Training Loss: 0.0368%\n",
      "Epoch [108/300], Step [128/225], Training Accuracy: 98.8770%, Training Loss: 0.0369%\n",
      "Epoch [108/300], Step [129/225], Training Accuracy: 98.8735%, Training Loss: 0.0370%\n",
      "Epoch [108/300], Step [130/225], Training Accuracy: 98.8822%, Training Loss: 0.0370%\n",
      "Epoch [108/300], Step [131/225], Training Accuracy: 98.8788%, Training Loss: 0.0370%\n",
      "Epoch [108/300], Step [132/225], Training Accuracy: 98.8755%, Training Loss: 0.0370%\n",
      "Epoch [108/300], Step [133/225], Training Accuracy: 98.8604%, Training Loss: 0.0371%\n",
      "Epoch [108/300], Step [134/225], Training Accuracy: 98.8689%, Training Loss: 0.0371%\n",
      "Epoch [108/300], Step [135/225], Training Accuracy: 98.8657%, Training Loss: 0.0372%\n",
      "Epoch [108/300], Step [136/225], Training Accuracy: 98.8626%, Training Loss: 0.0373%\n",
      "Epoch [108/300], Step [137/225], Training Accuracy: 98.8709%, Training Loss: 0.0372%\n",
      "Epoch [108/300], Step [138/225], Training Accuracy: 98.8791%, Training Loss: 0.0369%\n",
      "Epoch [108/300], Step [139/225], Training Accuracy: 98.8647%, Training Loss: 0.0371%\n",
      "Epoch [108/300], Step [140/225], Training Accuracy: 98.8504%, Training Loss: 0.0372%\n",
      "Epoch [108/300], Step [141/225], Training Accuracy: 98.8364%, Training Loss: 0.0376%\n",
      "Epoch [108/300], Step [142/225], Training Accuracy: 98.8226%, Training Loss: 0.0379%\n",
      "Epoch [108/300], Step [143/225], Training Accuracy: 98.8199%, Training Loss: 0.0380%\n",
      "Epoch [108/300], Step [144/225], Training Accuracy: 98.8173%, Training Loss: 0.0381%\n",
      "Epoch [108/300], Step [145/225], Training Accuracy: 98.8039%, Training Loss: 0.0382%\n",
      "Epoch [108/300], Step [146/225], Training Accuracy: 98.7907%, Training Loss: 0.0383%\n",
      "Epoch [108/300], Step [147/225], Training Accuracy: 98.7989%, Training Loss: 0.0382%\n",
      "Epoch [108/300], Step [148/225], Training Accuracy: 98.8070%, Training Loss: 0.0381%\n",
      "Epoch [108/300], Step [149/225], Training Accuracy: 98.8150%, Training Loss: 0.0381%\n",
      "Epoch [108/300], Step [150/225], Training Accuracy: 98.8229%, Training Loss: 0.0381%\n",
      "Epoch [108/300], Step [151/225], Training Accuracy: 98.8100%, Training Loss: 0.0382%\n",
      "Epoch [108/300], Step [152/225], Training Accuracy: 98.8178%, Training Loss: 0.0381%\n",
      "Epoch [108/300], Step [153/225], Training Accuracy: 98.8256%, Training Loss: 0.0379%\n",
      "Epoch [108/300], Step [154/225], Training Accuracy: 98.8332%, Training Loss: 0.0377%\n",
      "Epoch [108/300], Step [155/225], Training Accuracy: 98.8407%, Training Loss: 0.0376%\n",
      "Epoch [108/300], Step [156/225], Training Accuracy: 98.8482%, Training Loss: 0.0374%\n",
      "Epoch [108/300], Step [157/225], Training Accuracy: 98.8356%, Training Loss: 0.0376%\n",
      "Epoch [108/300], Step [158/225], Training Accuracy: 98.8430%, Training Loss: 0.0374%\n",
      "Epoch [108/300], Step [159/225], Training Accuracy: 98.8208%, Training Loss: 0.0380%\n",
      "Epoch [108/300], Step [160/225], Training Accuracy: 98.8281%, Training Loss: 0.0380%\n",
      "Epoch [108/300], Step [161/225], Training Accuracy: 98.8354%, Training Loss: 0.0379%\n",
      "Epoch [108/300], Step [162/225], Training Accuracy: 98.8233%, Training Loss: 0.0382%\n",
      "Epoch [108/300], Step [163/225], Training Accuracy: 98.8113%, Training Loss: 0.0384%\n",
      "Epoch [108/300], Step [164/225], Training Accuracy: 98.8091%, Training Loss: 0.0386%\n",
      "Epoch [108/300], Step [165/225], Training Accuracy: 98.8068%, Training Loss: 0.0385%\n",
      "Epoch [108/300], Step [166/225], Training Accuracy: 98.8046%, Training Loss: 0.0386%\n",
      "Epoch [108/300], Step [167/225], Training Accuracy: 98.8024%, Training Loss: 0.0387%\n",
      "Epoch [108/300], Step [168/225], Training Accuracy: 98.8095%, Training Loss: 0.0385%\n",
      "Epoch [108/300], Step [169/225], Training Accuracy: 98.8073%, Training Loss: 0.0386%\n",
      "Epoch [108/300], Step [170/225], Training Accuracy: 98.8051%, Training Loss: 0.0388%\n",
      "Epoch [108/300], Step [171/225], Training Accuracy: 98.8121%, Training Loss: 0.0386%\n",
      "Epoch [108/300], Step [172/225], Training Accuracy: 98.8190%, Training Loss: 0.0387%\n",
      "Epoch [108/300], Step [173/225], Training Accuracy: 98.8259%, Training Loss: 0.0386%\n",
      "Epoch [108/300], Step [174/225], Training Accuracy: 98.8147%, Training Loss: 0.0387%\n",
      "Epoch [108/300], Step [175/225], Training Accuracy: 98.8125%, Training Loss: 0.0387%\n",
      "Epoch [108/300], Step [176/225], Training Accuracy: 98.8192%, Training Loss: 0.0387%\n",
      "Epoch [108/300], Step [177/225], Training Accuracy: 98.8171%, Training Loss: 0.0386%\n",
      "Epoch [108/300], Step [178/225], Training Accuracy: 98.8150%, Training Loss: 0.0386%\n",
      "Epoch [108/300], Step [179/225], Training Accuracy: 98.8128%, Training Loss: 0.0385%\n",
      "Epoch [108/300], Step [180/225], Training Accuracy: 98.8194%, Training Loss: 0.0385%\n",
      "Epoch [108/300], Step [181/225], Training Accuracy: 98.8173%, Training Loss: 0.0386%\n",
      "Epoch [108/300], Step [182/225], Training Accuracy: 98.8238%, Training Loss: 0.0386%\n",
      "Epoch [108/300], Step [183/225], Training Accuracy: 98.8303%, Training Loss: 0.0385%\n",
      "Epoch [108/300], Step [184/225], Training Accuracy: 98.8281%, Training Loss: 0.0385%\n",
      "Epoch [108/300], Step [185/225], Training Accuracy: 98.8260%, Training Loss: 0.0387%\n",
      "Epoch [108/300], Step [186/225], Training Accuracy: 98.8323%, Training Loss: 0.0386%\n",
      "Epoch [108/300], Step [187/225], Training Accuracy: 98.8386%, Training Loss: 0.0385%\n",
      "Epoch [108/300], Step [188/225], Training Accuracy: 98.8364%, Training Loss: 0.0385%\n",
      "Epoch [108/300], Step [189/225], Training Accuracy: 98.8343%, Training Loss: 0.0384%\n",
      "Epoch [108/300], Step [190/225], Training Accuracy: 98.8322%, Training Loss: 0.0384%\n",
      "Epoch [108/300], Step [191/225], Training Accuracy: 98.8302%, Training Loss: 0.0384%\n",
      "Epoch [108/300], Step [192/225], Training Accuracy: 98.8363%, Training Loss: 0.0383%\n",
      "Epoch [108/300], Step [193/225], Training Accuracy: 98.8261%, Training Loss: 0.0385%\n",
      "Epoch [108/300], Step [194/225], Training Accuracy: 98.8322%, Training Loss: 0.0386%\n",
      "Epoch [108/300], Step [195/225], Training Accuracy: 98.8301%, Training Loss: 0.0386%\n",
      "Epoch [108/300], Step [196/225], Training Accuracy: 98.8281%, Training Loss: 0.0385%\n",
      "Epoch [108/300], Step [197/225], Training Accuracy: 98.8261%, Training Loss: 0.0385%\n",
      "Epoch [108/300], Step [198/225], Training Accuracy: 98.8242%, Training Loss: 0.0385%\n",
      "Epoch [108/300], Step [199/225], Training Accuracy: 98.8222%, Training Loss: 0.0385%\n",
      "Epoch [108/300], Step [200/225], Training Accuracy: 98.8125%, Training Loss: 0.0386%\n",
      "Epoch [108/300], Step [201/225], Training Accuracy: 98.8106%, Training Loss: 0.0386%\n",
      "Epoch [108/300], Step [202/225], Training Accuracy: 98.8165%, Training Loss: 0.0385%\n",
      "Epoch [108/300], Step [203/225], Training Accuracy: 98.8224%, Training Loss: 0.0385%\n",
      "Epoch [108/300], Step [204/225], Training Accuracy: 98.8205%, Training Loss: 0.0386%\n",
      "Epoch [108/300], Step [205/225], Training Accuracy: 98.8262%, Training Loss: 0.0386%\n",
      "Epoch [108/300], Step [206/225], Training Accuracy: 98.8243%, Training Loss: 0.0386%\n",
      "Epoch [108/300], Step [207/225], Training Accuracy: 98.8225%, Training Loss: 0.0386%\n",
      "Epoch [108/300], Step [208/225], Training Accuracy: 98.8281%, Training Loss: 0.0385%\n",
      "Epoch [108/300], Step [209/225], Training Accuracy: 98.8337%, Training Loss: 0.0384%\n",
      "Epoch [108/300], Step [210/225], Training Accuracy: 98.8393%, Training Loss: 0.0383%\n",
      "Epoch [108/300], Step [211/225], Training Accuracy: 98.8300%, Training Loss: 0.0387%\n",
      "Epoch [108/300], Step [212/225], Training Accuracy: 98.8355%, Training Loss: 0.0386%\n",
      "Epoch [108/300], Step [213/225], Training Accuracy: 98.8410%, Training Loss: 0.0385%\n",
      "Epoch [108/300], Step [214/225], Training Accuracy: 98.8391%, Training Loss: 0.0385%\n",
      "Epoch [108/300], Step [215/225], Training Accuracy: 98.8372%, Training Loss: 0.0386%\n",
      "Epoch [108/300], Step [216/225], Training Accuracy: 98.8426%, Training Loss: 0.0386%\n",
      "Epoch [108/300], Step [217/225], Training Accuracy: 98.8407%, Training Loss: 0.0387%\n",
      "Epoch [108/300], Step [218/225], Training Accuracy: 98.8389%, Training Loss: 0.0387%\n",
      "Epoch [108/300], Step [219/225], Training Accuracy: 98.8442%, Training Loss: 0.0386%\n",
      "Epoch [108/300], Step [220/225], Training Accuracy: 98.8494%, Training Loss: 0.0385%\n",
      "Epoch [108/300], Step [221/225], Training Accuracy: 98.8546%, Training Loss: 0.0384%\n",
      "Epoch [108/300], Step [222/225], Training Accuracy: 98.8528%, Training Loss: 0.0384%\n",
      "Epoch [108/300], Step [223/225], Training Accuracy: 98.8509%, Training Loss: 0.0383%\n",
      "Epoch [108/300], Step [224/225], Training Accuracy: 98.8351%, Training Loss: 0.0386%\n",
      "Epoch [108/300], Step [225/225], Training Accuracy: 98.8396%, Training Loss: 0.0385%\n",
      "Epoch [109/300], Step [1/225], Training Accuracy: 96.8750%, Training Loss: 0.0816%\n",
      "Epoch [109/300], Step [2/225], Training Accuracy: 97.6562%, Training Loss: 0.0603%\n",
      "Epoch [109/300], Step [3/225], Training Accuracy: 98.4375%, Training Loss: 0.0501%\n",
      "Epoch [109/300], Step [4/225], Training Accuracy: 98.4375%, Training Loss: 0.0436%\n",
      "Epoch [109/300], Step [5/225], Training Accuracy: 98.7500%, Training Loss: 0.0402%\n",
      "Epoch [109/300], Step [6/225], Training Accuracy: 98.6979%, Training Loss: 0.0395%\n",
      "Epoch [109/300], Step [7/225], Training Accuracy: 98.6607%, Training Loss: 0.0442%\n",
      "Epoch [109/300], Step [8/225], Training Accuracy: 98.6328%, Training Loss: 0.0443%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [109/300], Step [9/225], Training Accuracy: 98.6111%, Training Loss: 0.0442%\n",
      "Epoch [109/300], Step [10/225], Training Accuracy: 98.4375%, Training Loss: 0.0446%\n",
      "Epoch [109/300], Step [11/225], Training Accuracy: 98.5795%, Training Loss: 0.0420%\n",
      "Epoch [109/300], Step [12/225], Training Accuracy: 98.5677%, Training Loss: 0.0415%\n",
      "Epoch [109/300], Step [13/225], Training Accuracy: 98.5577%, Training Loss: 0.0435%\n",
      "Epoch [109/300], Step [14/225], Training Accuracy: 98.5491%, Training Loss: 0.0437%\n",
      "Epoch [109/300], Step [15/225], Training Accuracy: 98.5417%, Training Loss: 0.0442%\n",
      "Epoch [109/300], Step [16/225], Training Accuracy: 98.4375%, Training Loss: 0.0444%\n",
      "Epoch [109/300], Step [17/225], Training Accuracy: 98.3456%, Training Loss: 0.0466%\n",
      "Epoch [109/300], Step [18/225], Training Accuracy: 98.3507%, Training Loss: 0.0466%\n",
      "Epoch [109/300], Step [19/225], Training Accuracy: 98.4375%, Training Loss: 0.0458%\n",
      "Epoch [109/300], Step [20/225], Training Accuracy: 98.5156%, Training Loss: 0.0441%\n",
      "Epoch [109/300], Step [21/225], Training Accuracy: 98.5119%, Training Loss: 0.0435%\n",
      "Epoch [109/300], Step [22/225], Training Accuracy: 98.5795%, Training Loss: 0.0430%\n",
      "Epoch [109/300], Step [23/225], Training Accuracy: 98.6413%, Training Loss: 0.0416%\n",
      "Epoch [109/300], Step [24/225], Training Accuracy: 98.6979%, Training Loss: 0.0412%\n",
      "Epoch [109/300], Step [25/225], Training Accuracy: 98.6875%, Training Loss: 0.0410%\n",
      "Epoch [109/300], Step [26/225], Training Accuracy: 98.7380%, Training Loss: 0.0400%\n",
      "Epoch [109/300], Step [27/225], Training Accuracy: 98.6690%, Training Loss: 0.0427%\n",
      "Epoch [109/300], Step [28/225], Training Accuracy: 98.7165%, Training Loss: 0.0421%\n",
      "Epoch [109/300], Step [29/225], Training Accuracy: 98.7608%, Training Loss: 0.0416%\n",
      "Epoch [109/300], Step [30/225], Training Accuracy: 98.7500%, Training Loss: 0.0424%\n",
      "Epoch [109/300], Step [31/225], Training Accuracy: 98.7399%, Training Loss: 0.0427%\n",
      "Epoch [109/300], Step [32/225], Training Accuracy: 98.7305%, Training Loss: 0.0423%\n",
      "Epoch [109/300], Step [33/225], Training Accuracy: 98.7689%, Training Loss: 0.0414%\n",
      "Epoch [109/300], Step [34/225], Training Accuracy: 98.8051%, Training Loss: 0.0408%\n",
      "Epoch [109/300], Step [35/225], Training Accuracy: 98.7946%, Training Loss: 0.0405%\n",
      "Epoch [109/300], Step [36/225], Training Accuracy: 98.8281%, Training Loss: 0.0400%\n",
      "Epoch [109/300], Step [37/225], Training Accuracy: 98.8598%, Training Loss: 0.0393%\n",
      "Epoch [109/300], Step [38/225], Training Accuracy: 98.8898%, Training Loss: 0.0387%\n",
      "Epoch [109/300], Step [39/225], Training Accuracy: 98.9183%, Training Loss: 0.0393%\n",
      "Epoch [109/300], Step [40/225], Training Accuracy: 98.9062%, Training Loss: 0.0402%\n",
      "Epoch [109/300], Step [41/225], Training Accuracy: 98.8186%, Training Loss: 0.0415%\n",
      "Epoch [109/300], Step [42/225], Training Accuracy: 98.8467%, Training Loss: 0.0412%\n",
      "Epoch [109/300], Step [43/225], Training Accuracy: 98.8735%, Training Loss: 0.0411%\n",
      "Epoch [109/300], Step [44/225], Training Accuracy: 98.8636%, Training Loss: 0.0410%\n",
      "Epoch [109/300], Step [45/225], Training Accuracy: 98.8889%, Training Loss: 0.0403%\n",
      "Epoch [109/300], Step [46/225], Training Accuracy: 98.8451%, Training Loss: 0.0409%\n",
      "Epoch [109/300], Step [47/225], Training Accuracy: 98.8697%, Training Loss: 0.0405%\n",
      "Epoch [109/300], Step [48/225], Training Accuracy: 98.8607%, Training Loss: 0.0404%\n",
      "Epoch [109/300], Step [49/225], Training Accuracy: 98.8839%, Training Loss: 0.0399%\n",
      "Epoch [109/300], Step [50/225], Training Accuracy: 98.8750%, Training Loss: 0.0403%\n",
      "Epoch [109/300], Step [51/225], Training Accuracy: 98.8664%, Training Loss: 0.0404%\n",
      "Epoch [109/300], Step [52/225], Training Accuracy: 98.8882%, Training Loss: 0.0399%\n",
      "Epoch [109/300], Step [53/225], Training Accuracy: 98.8502%, Training Loss: 0.0404%\n",
      "Epoch [109/300], Step [54/225], Training Accuracy: 98.8426%, Training Loss: 0.0404%\n",
      "Epoch [109/300], Step [55/225], Training Accuracy: 98.8636%, Training Loss: 0.0400%\n",
      "Epoch [109/300], Step [56/225], Training Accuracy: 98.8839%, Training Loss: 0.0399%\n",
      "Epoch [109/300], Step [57/225], Training Accuracy: 98.8487%, Training Loss: 0.0404%\n",
      "Epoch [109/300], Step [58/225], Training Accuracy: 98.7877%, Training Loss: 0.0423%\n",
      "Epoch [109/300], Step [59/225], Training Accuracy: 98.7818%, Training Loss: 0.0423%\n",
      "Epoch [109/300], Step [60/225], Training Accuracy: 98.8021%, Training Loss: 0.0427%\n",
      "Epoch [109/300], Step [61/225], Training Accuracy: 98.7961%, Training Loss: 0.0426%\n",
      "Epoch [109/300], Step [62/225], Training Accuracy: 98.8155%, Training Loss: 0.0421%\n",
      "Epoch [109/300], Step [63/225], Training Accuracy: 98.8343%, Training Loss: 0.0418%\n",
      "Epoch [109/300], Step [64/225], Training Accuracy: 98.8281%, Training Loss: 0.0417%\n",
      "Epoch [109/300], Step [65/225], Training Accuracy: 98.8462%, Training Loss: 0.0414%\n",
      "Epoch [109/300], Step [66/225], Training Accuracy: 98.8400%, Training Loss: 0.0414%\n",
      "Epoch [109/300], Step [67/225], Training Accuracy: 98.8340%, Training Loss: 0.0415%\n",
      "Epoch [109/300], Step [68/225], Training Accuracy: 98.8281%, Training Loss: 0.0416%\n",
      "Epoch [109/300], Step [69/225], Training Accuracy: 98.8225%, Training Loss: 0.0416%\n",
      "Epoch [109/300], Step [70/225], Training Accuracy: 98.8393%, Training Loss: 0.0412%\n",
      "Epoch [109/300], Step [71/225], Training Accuracy: 98.8116%, Training Loss: 0.0418%\n",
      "Epoch [109/300], Step [72/225], Training Accuracy: 98.8281%, Training Loss: 0.0416%\n",
      "Epoch [109/300], Step [73/225], Training Accuracy: 98.8228%, Training Loss: 0.0420%\n",
      "Epoch [109/300], Step [74/225], Training Accuracy: 98.8176%, Training Loss: 0.0425%\n",
      "Epoch [109/300], Step [75/225], Training Accuracy: 98.8125%, Training Loss: 0.0427%\n",
      "Epoch [109/300], Step [76/225], Training Accuracy: 98.8281%, Training Loss: 0.0427%\n",
      "Epoch [109/300], Step [77/225], Training Accuracy: 98.8028%, Training Loss: 0.0439%\n",
      "Epoch [109/300], Step [78/225], Training Accuracy: 98.7580%, Training Loss: 0.0441%\n",
      "Epoch [109/300], Step [79/225], Training Accuracy: 98.7144%, Training Loss: 0.0443%\n",
      "Epoch [109/300], Step [80/225], Training Accuracy: 98.7305%, Training Loss: 0.0442%\n",
      "Epoch [109/300], Step [81/225], Training Accuracy: 98.7269%, Training Loss: 0.0442%\n",
      "Epoch [109/300], Step [82/225], Training Accuracy: 98.7233%, Training Loss: 0.0442%\n",
      "Epoch [109/300], Step [83/225], Training Accuracy: 98.7011%, Training Loss: 0.0446%\n",
      "Epoch [109/300], Step [84/225], Training Accuracy: 98.7165%, Training Loss: 0.0442%\n",
      "Epoch [109/300], Step [85/225], Training Accuracy: 98.7132%, Training Loss: 0.0445%\n",
      "Epoch [109/300], Step [86/225], Training Accuracy: 98.6919%, Training Loss: 0.0446%\n",
      "Epoch [109/300], Step [87/225], Training Accuracy: 98.7069%, Training Loss: 0.0445%\n",
      "Epoch [109/300], Step [88/225], Training Accuracy: 98.7216%, Training Loss: 0.0441%\n",
      "Epoch [109/300], Step [89/225], Training Accuracy: 98.7184%, Training Loss: 0.0439%\n",
      "Epoch [109/300], Step [90/225], Training Accuracy: 98.7153%, Training Loss: 0.0437%\n",
      "Epoch [109/300], Step [91/225], Training Accuracy: 98.7122%, Training Loss: 0.0436%\n",
      "Epoch [109/300], Step [92/225], Training Accuracy: 98.7092%, Training Loss: 0.0434%\n",
      "Epoch [109/300], Step [93/225], Training Accuracy: 98.7231%, Training Loss: 0.0431%\n",
      "Epoch [109/300], Step [94/225], Training Accuracy: 98.7367%, Training Loss: 0.0429%\n",
      "Epoch [109/300], Step [95/225], Training Accuracy: 98.7500%, Training Loss: 0.0428%\n",
      "Epoch [109/300], Step [96/225], Training Accuracy: 98.7467%, Training Loss: 0.0427%\n",
      "Epoch [109/300], Step [97/225], Training Accuracy: 98.7597%, Training Loss: 0.0424%\n",
      "Epoch [109/300], Step [98/225], Training Accuracy: 98.7564%, Training Loss: 0.0425%\n",
      "Epoch [109/300], Step [99/225], Training Accuracy: 98.7689%, Training Loss: 0.0424%\n",
      "Epoch [109/300], Step [100/225], Training Accuracy: 98.7656%, Training Loss: 0.0424%\n",
      "Epoch [109/300], Step [101/225], Training Accuracy: 98.7778%, Training Loss: 0.0422%\n",
      "Epoch [109/300], Step [102/225], Training Accuracy: 98.7745%, Training Loss: 0.0422%\n",
      "Epoch [109/300], Step [103/225], Training Accuracy: 98.7561%, Training Loss: 0.0426%\n",
      "Epoch [109/300], Step [104/225], Training Accuracy: 98.7680%, Training Loss: 0.0425%\n",
      "Epoch [109/300], Step [105/225], Training Accuracy: 98.7649%, Training Loss: 0.0425%\n",
      "Epoch [109/300], Step [106/225], Training Accuracy: 98.7618%, Training Loss: 0.0425%\n",
      "Epoch [109/300], Step [107/225], Training Accuracy: 98.7588%, Training Loss: 0.0428%\n",
      "Epoch [109/300], Step [108/225], Training Accuracy: 98.7703%, Training Loss: 0.0425%\n",
      "Epoch [109/300], Step [109/225], Training Accuracy: 98.7815%, Training Loss: 0.0424%\n",
      "Epoch [109/300], Step [110/225], Training Accuracy: 98.7926%, Training Loss: 0.0422%\n",
      "Epoch [109/300], Step [111/225], Training Accuracy: 98.7753%, Training Loss: 0.0422%\n",
      "Epoch [109/300], Step [112/225], Training Accuracy: 98.7863%, Training Loss: 0.0420%\n",
      "Epoch [109/300], Step [113/225], Training Accuracy: 98.7970%, Training Loss: 0.0417%\n",
      "Epoch [109/300], Step [114/225], Training Accuracy: 98.7939%, Training Loss: 0.0417%\n",
      "Epoch [109/300], Step [115/225], Training Accuracy: 98.8043%, Training Loss: 0.0414%\n",
      "Epoch [109/300], Step [116/225], Training Accuracy: 98.8147%, Training Loss: 0.0413%\n",
      "Epoch [109/300], Step [117/225], Training Accuracy: 98.7981%, Training Loss: 0.0416%\n",
      "Epoch [109/300], Step [118/225], Training Accuracy: 98.7818%, Training Loss: 0.0418%\n",
      "Epoch [109/300], Step [119/225], Training Accuracy: 98.7658%, Training Loss: 0.0418%\n",
      "Epoch [109/300], Step [120/225], Training Accuracy: 98.7630%, Training Loss: 0.0419%\n",
      "Epoch [109/300], Step [121/225], Training Accuracy: 98.7732%, Training Loss: 0.0417%\n",
      "Epoch [109/300], Step [122/225], Training Accuracy: 98.7833%, Training Loss: 0.0415%\n",
      "Epoch [109/300], Step [123/225], Training Accuracy: 98.7678%, Training Loss: 0.0417%\n",
      "Epoch [109/300], Step [124/225], Training Accuracy: 98.7525%, Training Loss: 0.0421%\n",
      "Epoch [109/300], Step [125/225], Training Accuracy: 98.7250%, Training Loss: 0.0426%\n",
      "Epoch [109/300], Step [126/225], Training Accuracy: 98.7227%, Training Loss: 0.0426%\n",
      "Epoch [109/300], Step [127/225], Training Accuracy: 98.7205%, Training Loss: 0.0428%\n",
      "Epoch [109/300], Step [128/225], Training Accuracy: 98.7305%, Training Loss: 0.0427%\n",
      "Epoch [109/300], Step [129/225], Training Accuracy: 98.7282%, Training Loss: 0.0427%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [109/300], Step [130/225], Training Accuracy: 98.7019%, Training Loss: 0.0432%\n",
      "Epoch [109/300], Step [131/225], Training Accuracy: 98.7118%, Training Loss: 0.0430%\n",
      "Epoch [109/300], Step [132/225], Training Accuracy: 98.7216%, Training Loss: 0.0428%\n",
      "Epoch [109/300], Step [133/225], Training Accuracy: 98.7312%, Training Loss: 0.0428%\n",
      "Epoch [109/300], Step [134/225], Training Accuracy: 98.7290%, Training Loss: 0.0427%\n",
      "Epoch [109/300], Step [135/225], Training Accuracy: 98.7384%, Training Loss: 0.0426%\n",
      "Epoch [109/300], Step [136/225], Training Accuracy: 98.7477%, Training Loss: 0.0427%\n",
      "Epoch [109/300], Step [137/225], Training Accuracy: 98.7568%, Training Loss: 0.0425%\n",
      "Epoch [109/300], Step [138/225], Training Accuracy: 98.7659%, Training Loss: 0.0424%\n",
      "Epoch [109/300], Step [139/225], Training Accuracy: 98.7635%, Training Loss: 0.0424%\n",
      "Epoch [109/300], Step [140/225], Training Accuracy: 98.7723%, Training Loss: 0.0423%\n",
      "Epoch [109/300], Step [141/225], Training Accuracy: 98.7810%, Training Loss: 0.0423%\n",
      "Epoch [109/300], Step [142/225], Training Accuracy: 98.7896%, Training Loss: 0.0422%\n",
      "Epoch [109/300], Step [143/225], Training Accuracy: 98.7872%, Training Loss: 0.0423%\n",
      "Epoch [109/300], Step [144/225], Training Accuracy: 98.7956%, Training Loss: 0.0421%\n",
      "Epoch [109/300], Step [145/225], Training Accuracy: 98.8039%, Training Loss: 0.0419%\n",
      "Epoch [109/300], Step [146/225], Training Accuracy: 98.8121%, Training Loss: 0.0418%\n",
      "Epoch [109/300], Step [147/225], Training Accuracy: 98.8202%, Training Loss: 0.0416%\n",
      "Epoch [109/300], Step [148/225], Training Accuracy: 98.8281%, Training Loss: 0.0414%\n",
      "Epoch [109/300], Step [149/225], Training Accuracy: 98.8150%, Training Loss: 0.0415%\n",
      "Epoch [109/300], Step [150/225], Training Accuracy: 98.8229%, Training Loss: 0.0413%\n",
      "Epoch [109/300], Step [151/225], Training Accuracy: 98.8204%, Training Loss: 0.0413%\n",
      "Epoch [109/300], Step [152/225], Training Accuracy: 98.8281%, Training Loss: 0.0412%\n",
      "Epoch [109/300], Step [153/225], Training Accuracy: 98.8256%, Training Loss: 0.0411%\n",
      "Epoch [109/300], Step [154/225], Training Accuracy: 98.8332%, Training Loss: 0.0410%\n",
      "Epoch [109/300], Step [155/225], Training Accuracy: 98.8407%, Training Loss: 0.0409%\n",
      "Epoch [109/300], Step [156/225], Training Accuracy: 98.8482%, Training Loss: 0.0407%\n",
      "Epoch [109/300], Step [157/225], Training Accuracy: 98.8555%, Training Loss: 0.0406%\n",
      "Epoch [109/300], Step [158/225], Training Accuracy: 98.8430%, Training Loss: 0.0409%\n",
      "Epoch [109/300], Step [159/225], Training Accuracy: 98.8502%, Training Loss: 0.0408%\n",
      "Epoch [109/300], Step [160/225], Training Accuracy: 98.8477%, Training Loss: 0.0407%\n",
      "Epoch [109/300], Step [161/225], Training Accuracy: 98.8548%, Training Loss: 0.0406%\n",
      "Epoch [109/300], Step [162/225], Training Accuracy: 98.8426%, Training Loss: 0.0406%\n",
      "Epoch [109/300], Step [163/225], Training Accuracy: 98.8497%, Training Loss: 0.0407%\n",
      "Epoch [109/300], Step [164/225], Training Accuracy: 98.8567%, Training Loss: 0.0406%\n",
      "Epoch [109/300], Step [165/225], Training Accuracy: 98.8636%, Training Loss: 0.0406%\n",
      "Epoch [109/300], Step [166/225], Training Accuracy: 98.8611%, Training Loss: 0.0405%\n",
      "Epoch [109/300], Step [167/225], Training Accuracy: 98.8679%, Training Loss: 0.0404%\n",
      "Epoch [109/300], Step [168/225], Training Accuracy: 98.8746%, Training Loss: 0.0403%\n",
      "Epoch [109/300], Step [169/225], Training Accuracy: 98.8628%, Training Loss: 0.0404%\n",
      "Epoch [109/300], Step [170/225], Training Accuracy: 98.8603%, Training Loss: 0.0406%\n",
      "Epoch [109/300], Step [171/225], Training Accuracy: 98.8670%, Training Loss: 0.0405%\n",
      "Epoch [109/300], Step [172/225], Training Accuracy: 98.8645%, Training Loss: 0.0405%\n",
      "Epoch [109/300], Step [173/225], Training Accuracy: 98.8710%, Training Loss: 0.0403%\n",
      "Epoch [109/300], Step [174/225], Training Accuracy: 98.8596%, Training Loss: 0.0407%\n",
      "Epoch [109/300], Step [175/225], Training Accuracy: 98.8661%, Training Loss: 0.0406%\n",
      "Epoch [109/300], Step [176/225], Training Accuracy: 98.8725%, Training Loss: 0.0405%\n",
      "Epoch [109/300], Step [177/225], Training Accuracy: 98.8789%, Training Loss: 0.0404%\n",
      "Epoch [109/300], Step [178/225], Training Accuracy: 98.8852%, Training Loss: 0.0403%\n",
      "Epoch [109/300], Step [179/225], Training Accuracy: 98.8827%, Training Loss: 0.0402%\n",
      "Epoch [109/300], Step [180/225], Training Accuracy: 98.8715%, Training Loss: 0.0406%\n",
      "Epoch [109/300], Step [181/225], Training Accuracy: 98.8691%, Training Loss: 0.0405%\n",
      "Epoch [109/300], Step [182/225], Training Accuracy: 98.8668%, Training Loss: 0.0406%\n",
      "Epoch [109/300], Step [183/225], Training Accuracy: 98.8644%, Training Loss: 0.0406%\n",
      "Epoch [109/300], Step [184/225], Training Accuracy: 98.8706%, Training Loss: 0.0405%\n",
      "Epoch [109/300], Step [185/225], Training Accuracy: 98.8767%, Training Loss: 0.0404%\n",
      "Epoch [109/300], Step [186/225], Training Accuracy: 98.8827%, Training Loss: 0.0403%\n",
      "Epoch [109/300], Step [187/225], Training Accuracy: 98.8803%, Training Loss: 0.0404%\n",
      "Epoch [109/300], Step [188/225], Training Accuracy: 98.8863%, Training Loss: 0.0403%\n",
      "Epoch [109/300], Step [189/225], Training Accuracy: 98.8757%, Training Loss: 0.0403%\n",
      "Epoch [109/300], Step [190/225], Training Accuracy: 98.8569%, Training Loss: 0.0407%\n",
      "Epoch [109/300], Step [191/225], Training Accuracy: 98.8629%, Training Loss: 0.0406%\n",
      "Epoch [109/300], Step [192/225], Training Accuracy: 98.8607%, Training Loss: 0.0407%\n",
      "Epoch [109/300], Step [193/225], Training Accuracy: 98.8585%, Training Loss: 0.0408%\n",
      "Epoch [109/300], Step [194/225], Training Accuracy: 98.8483%, Training Loss: 0.0409%\n",
      "Epoch [109/300], Step [195/225], Training Accuracy: 98.8462%, Training Loss: 0.0409%\n",
      "Epoch [109/300], Step [196/225], Training Accuracy: 98.8520%, Training Loss: 0.0408%\n",
      "Epoch [109/300], Step [197/225], Training Accuracy: 98.8499%, Training Loss: 0.0408%\n",
      "Epoch [109/300], Step [198/225], Training Accuracy: 98.8479%, Training Loss: 0.0409%\n",
      "Epoch [109/300], Step [199/225], Training Accuracy: 98.8379%, Training Loss: 0.0411%\n",
      "Epoch [109/300], Step [200/225], Training Accuracy: 98.8359%, Training Loss: 0.0411%\n",
      "Epoch [109/300], Step [201/225], Training Accuracy: 98.8417%, Training Loss: 0.0410%\n",
      "Epoch [109/300], Step [202/225], Training Accuracy: 98.8475%, Training Loss: 0.0409%\n",
      "Epoch [109/300], Step [203/225], Training Accuracy: 98.8454%, Training Loss: 0.0408%\n",
      "Epoch [109/300], Step [204/225], Training Accuracy: 98.8511%, Training Loss: 0.0408%\n",
      "Epoch [109/300], Step [205/225], Training Accuracy: 98.8567%, Training Loss: 0.0407%\n",
      "Epoch [109/300], Step [206/225], Training Accuracy: 98.8471%, Training Loss: 0.0408%\n",
      "Epoch [109/300], Step [207/225], Training Accuracy: 98.8527%, Training Loss: 0.0406%\n",
      "Epoch [109/300], Step [208/225], Training Accuracy: 98.8582%, Training Loss: 0.0405%\n",
      "Epoch [109/300], Step [209/225], Training Accuracy: 98.8487%, Training Loss: 0.0405%\n",
      "Epoch [109/300], Step [210/225], Training Accuracy: 98.8467%, Training Loss: 0.0405%\n",
      "Epoch [109/300], Step [211/225], Training Accuracy: 98.8448%, Training Loss: 0.0404%\n",
      "Epoch [109/300], Step [212/225], Training Accuracy: 98.8429%, Training Loss: 0.0404%\n",
      "Epoch [109/300], Step [213/225], Training Accuracy: 98.8483%, Training Loss: 0.0403%\n",
      "Epoch [109/300], Step [214/225], Training Accuracy: 98.8464%, Training Loss: 0.0403%\n",
      "Epoch [109/300], Step [215/225], Training Accuracy: 98.8445%, Training Loss: 0.0403%\n",
      "Epoch [109/300], Step [216/225], Training Accuracy: 98.8426%, Training Loss: 0.0403%\n",
      "Epoch [109/300], Step [217/225], Training Accuracy: 98.8479%, Training Loss: 0.0403%\n",
      "Epoch [109/300], Step [218/225], Training Accuracy: 98.8460%, Training Loss: 0.0403%\n",
      "Epoch [109/300], Step [219/225], Training Accuracy: 98.8513%, Training Loss: 0.0403%\n",
      "Epoch [109/300], Step [220/225], Training Accuracy: 98.8565%, Training Loss: 0.0402%\n",
      "Epoch [109/300], Step [221/225], Training Accuracy: 98.8476%, Training Loss: 0.0404%\n",
      "Epoch [109/300], Step [222/225], Training Accuracy: 98.8457%, Training Loss: 0.0404%\n",
      "Epoch [109/300], Step [223/225], Training Accuracy: 98.8439%, Training Loss: 0.0403%\n",
      "Epoch [109/300], Step [224/225], Training Accuracy: 98.8351%, Training Loss: 0.0404%\n",
      "Epoch [109/300], Step [225/225], Training Accuracy: 98.8396%, Training Loss: 0.0403%\n",
      "Epoch [110/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0388%\n",
      "Epoch [110/300], Step [2/225], Training Accuracy: 100.0000%, Training Loss: 0.0280%\n",
      "Epoch [110/300], Step [3/225], Training Accuracy: 99.4792%, Training Loss: 0.0326%\n",
      "Epoch [110/300], Step [4/225], Training Accuracy: 99.6094%, Training Loss: 0.0299%\n",
      "Epoch [110/300], Step [5/225], Training Accuracy: 99.0625%, Training Loss: 0.0322%\n",
      "Epoch [110/300], Step [6/225], Training Accuracy: 98.9583%, Training Loss: 0.0373%\n",
      "Epoch [110/300], Step [7/225], Training Accuracy: 99.1071%, Training Loss: 0.0340%\n",
      "Epoch [110/300], Step [8/225], Training Accuracy: 99.2188%, Training Loss: 0.0313%\n",
      "Epoch [110/300], Step [9/225], Training Accuracy: 99.3056%, Training Loss: 0.0289%\n",
      "Epoch [110/300], Step [10/225], Training Accuracy: 99.3750%, Training Loss: 0.0274%\n",
      "Epoch [110/300], Step [11/225], Training Accuracy: 99.4318%, Training Loss: 0.0270%\n",
      "Epoch [110/300], Step [12/225], Training Accuracy: 99.3490%, Training Loss: 0.0284%\n",
      "Epoch [110/300], Step [13/225], Training Accuracy: 99.3990%, Training Loss: 0.0281%\n",
      "Epoch [110/300], Step [14/225], Training Accuracy: 99.3304%, Training Loss: 0.0287%\n",
      "Epoch [110/300], Step [15/225], Training Accuracy: 99.2708%, Training Loss: 0.0294%\n",
      "Epoch [110/300], Step [16/225], Training Accuracy: 99.3164%, Training Loss: 0.0284%\n",
      "Epoch [110/300], Step [17/225], Training Accuracy: 99.2647%, Training Loss: 0.0302%\n",
      "Epoch [110/300], Step [18/225], Training Accuracy: 99.3056%, Training Loss: 0.0310%\n",
      "Epoch [110/300], Step [19/225], Training Accuracy: 99.3421%, Training Loss: 0.0307%\n",
      "Epoch [110/300], Step [20/225], Training Accuracy: 99.3750%, Training Loss: 0.0305%\n",
      "Epoch [110/300], Step [21/225], Training Accuracy: 99.4048%, Training Loss: 0.0302%\n",
      "Epoch [110/300], Step [22/225], Training Accuracy: 99.3608%, Training Loss: 0.0307%\n",
      "Epoch [110/300], Step [23/225], Training Accuracy: 99.3207%, Training Loss: 0.0312%\n",
      "Epoch [110/300], Step [24/225], Training Accuracy: 99.2839%, Training Loss: 0.0330%\n",
      "Epoch [110/300], Step [25/225], Training Accuracy: 99.1875%, Training Loss: 0.0329%\n",
      "Epoch [110/300], Step [26/225], Training Accuracy: 99.2188%, Training Loss: 0.0336%\n",
      "Epoch [110/300], Step [27/225], Training Accuracy: 99.1898%, Training Loss: 0.0343%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [110/300], Step [28/225], Training Accuracy: 99.2188%, Training Loss: 0.0339%\n",
      "Epoch [110/300], Step [29/225], Training Accuracy: 99.1918%, Training Loss: 0.0342%\n",
      "Epoch [110/300], Step [30/225], Training Accuracy: 99.1667%, Training Loss: 0.0352%\n",
      "Epoch [110/300], Step [31/225], Training Accuracy: 99.1935%, Training Loss: 0.0350%\n",
      "Epoch [110/300], Step [32/225], Training Accuracy: 99.2188%, Training Loss: 0.0344%\n",
      "Epoch [110/300], Step [33/225], Training Accuracy: 99.2424%, Training Loss: 0.0343%\n",
      "Epoch [110/300], Step [34/225], Training Accuracy: 99.2647%, Training Loss: 0.0342%\n",
      "Epoch [110/300], Step [35/225], Training Accuracy: 99.2857%, Training Loss: 0.0335%\n",
      "Epoch [110/300], Step [36/225], Training Accuracy: 99.3056%, Training Loss: 0.0331%\n",
      "Epoch [110/300], Step [37/225], Training Accuracy: 99.2821%, Training Loss: 0.0333%\n",
      "Epoch [110/300], Step [38/225], Training Accuracy: 99.3010%, Training Loss: 0.0331%\n",
      "Epoch [110/300], Step [39/225], Training Accuracy: 99.2388%, Training Loss: 0.0343%\n",
      "Epoch [110/300], Step [40/225], Training Accuracy: 99.2188%, Training Loss: 0.0349%\n",
      "Epoch [110/300], Step [41/225], Training Accuracy: 99.1997%, Training Loss: 0.0358%\n",
      "Epoch [110/300], Step [42/225], Training Accuracy: 99.2188%, Training Loss: 0.0353%\n",
      "Epoch [110/300], Step [43/225], Training Accuracy: 99.1642%, Training Loss: 0.0357%\n",
      "Epoch [110/300], Step [44/225], Training Accuracy: 99.1832%, Training Loss: 0.0355%\n",
      "Epoch [110/300], Step [45/225], Training Accuracy: 99.1667%, Training Loss: 0.0362%\n",
      "Epoch [110/300], Step [46/225], Training Accuracy: 99.1848%, Training Loss: 0.0358%\n",
      "Epoch [110/300], Step [47/225], Training Accuracy: 99.1356%, Training Loss: 0.0362%\n",
      "Epoch [110/300], Step [48/225], Training Accuracy: 99.0560%, Training Loss: 0.0372%\n",
      "Epoch [110/300], Step [49/225], Training Accuracy: 99.0753%, Training Loss: 0.0370%\n",
      "Epoch [110/300], Step [50/225], Training Accuracy: 99.0625%, Training Loss: 0.0368%\n",
      "Epoch [110/300], Step [51/225], Training Accuracy: 99.0809%, Training Loss: 0.0363%\n",
      "Epoch [110/300], Step [52/225], Training Accuracy: 99.0986%, Training Loss: 0.0359%\n",
      "Epoch [110/300], Step [53/225], Training Accuracy: 99.1156%, Training Loss: 0.0359%\n",
      "Epoch [110/300], Step [54/225], Training Accuracy: 99.1319%, Training Loss: 0.0356%\n",
      "Epoch [110/300], Step [55/225], Training Accuracy: 99.1193%, Training Loss: 0.0357%\n",
      "Epoch [110/300], Step [56/225], Training Accuracy: 99.0513%, Training Loss: 0.0370%\n",
      "Epoch [110/300], Step [57/225], Training Accuracy: 99.0680%, Training Loss: 0.0366%\n",
      "Epoch [110/300], Step [58/225], Training Accuracy: 99.0571%, Training Loss: 0.0371%\n",
      "Epoch [110/300], Step [59/225], Training Accuracy: 99.0466%, Training Loss: 0.0373%\n",
      "Epoch [110/300], Step [60/225], Training Accuracy: 99.0365%, Training Loss: 0.0377%\n",
      "Epoch [110/300], Step [61/225], Training Accuracy: 99.0523%, Training Loss: 0.0376%\n",
      "Epoch [110/300], Step [62/225], Training Accuracy: 99.0675%, Training Loss: 0.0375%\n",
      "Epoch [110/300], Step [63/225], Training Accuracy: 99.0575%, Training Loss: 0.0374%\n",
      "Epoch [110/300], Step [64/225], Training Accuracy: 99.0723%, Training Loss: 0.0373%\n",
      "Epoch [110/300], Step [65/225], Training Accuracy: 99.0865%, Training Loss: 0.0370%\n",
      "Epoch [110/300], Step [66/225], Training Accuracy: 99.0767%, Training Loss: 0.0370%\n",
      "Epoch [110/300], Step [67/225], Training Accuracy: 99.0672%, Training Loss: 0.0373%\n",
      "Epoch [110/300], Step [68/225], Training Accuracy: 99.0809%, Training Loss: 0.0371%\n",
      "Epoch [110/300], Step [69/225], Training Accuracy: 99.0942%, Training Loss: 0.0367%\n",
      "Epoch [110/300], Step [70/225], Training Accuracy: 99.1071%, Training Loss: 0.0363%\n",
      "Epoch [110/300], Step [71/225], Training Accuracy: 99.1197%, Training Loss: 0.0362%\n",
      "Epoch [110/300], Step [72/225], Training Accuracy: 99.1102%, Training Loss: 0.0360%\n",
      "Epoch [110/300], Step [73/225], Training Accuracy: 99.1010%, Training Loss: 0.0360%\n",
      "Epoch [110/300], Step [74/225], Training Accuracy: 99.0709%, Training Loss: 0.0363%\n",
      "Epoch [110/300], Step [75/225], Training Accuracy: 99.0833%, Training Loss: 0.0363%\n",
      "Epoch [110/300], Step [76/225], Training Accuracy: 99.0954%, Training Loss: 0.0363%\n",
      "Epoch [110/300], Step [77/225], Training Accuracy: 99.0869%, Training Loss: 0.0364%\n",
      "Epoch [110/300], Step [78/225], Training Accuracy: 99.0585%, Training Loss: 0.0365%\n",
      "Epoch [110/300], Step [79/225], Training Accuracy: 99.0309%, Training Loss: 0.0371%\n",
      "Epoch [110/300], Step [80/225], Training Accuracy: 99.0234%, Training Loss: 0.0372%\n",
      "Epoch [110/300], Step [81/225], Training Accuracy: 99.0162%, Training Loss: 0.0370%\n",
      "Epoch [110/300], Step [82/225], Training Accuracy: 99.0091%, Training Loss: 0.0373%\n",
      "Epoch [110/300], Step [83/225], Training Accuracy: 99.0023%, Training Loss: 0.0374%\n",
      "Epoch [110/300], Step [84/225], Training Accuracy: 98.9955%, Training Loss: 0.0373%\n",
      "Epoch [110/300], Step [85/225], Training Accuracy: 99.0074%, Training Loss: 0.0371%\n",
      "Epoch [110/300], Step [86/225], Training Accuracy: 98.9826%, Training Loss: 0.0376%\n",
      "Epoch [110/300], Step [87/225], Training Accuracy: 98.9763%, Training Loss: 0.0376%\n",
      "Epoch [110/300], Step [88/225], Training Accuracy: 98.9524%, Training Loss: 0.0379%\n",
      "Epoch [110/300], Step [89/225], Training Accuracy: 98.9466%, Training Loss: 0.0378%\n",
      "Epoch [110/300], Step [90/225], Training Accuracy: 98.9236%, Training Loss: 0.0381%\n",
      "Epoch [110/300], Step [91/225], Training Accuracy: 98.9011%, Training Loss: 0.0385%\n",
      "Epoch [110/300], Step [92/225], Training Accuracy: 98.9130%, Training Loss: 0.0382%\n",
      "Epoch [110/300], Step [93/225], Training Accuracy: 98.9079%, Training Loss: 0.0382%\n",
      "Epoch [110/300], Step [94/225], Training Accuracy: 98.9029%, Training Loss: 0.0381%\n",
      "Epoch [110/300], Step [95/225], Training Accuracy: 98.9145%, Training Loss: 0.0381%\n",
      "Epoch [110/300], Step [96/225], Training Accuracy: 98.9095%, Training Loss: 0.0384%\n",
      "Epoch [110/300], Step [97/225], Training Accuracy: 98.9207%, Training Loss: 0.0382%\n",
      "Epoch [110/300], Step [98/225], Training Accuracy: 98.8680%, Training Loss: 0.0391%\n",
      "Epoch [110/300], Step [99/225], Training Accuracy: 98.8479%, Training Loss: 0.0392%\n",
      "Epoch [110/300], Step [100/225], Training Accuracy: 98.8594%, Training Loss: 0.0390%\n",
      "Epoch [110/300], Step [101/225], Training Accuracy: 98.8552%, Training Loss: 0.0393%\n",
      "Epoch [110/300], Step [102/225], Training Accuracy: 98.8664%, Training Loss: 0.0392%\n",
      "Epoch [110/300], Step [103/225], Training Accuracy: 98.8774%, Training Loss: 0.0389%\n",
      "Epoch [110/300], Step [104/225], Training Accuracy: 98.8732%, Training Loss: 0.0389%\n",
      "Epoch [110/300], Step [105/225], Training Accuracy: 98.8839%, Training Loss: 0.0387%\n",
      "Epoch [110/300], Step [106/225], Training Accuracy: 98.8797%, Training Loss: 0.0389%\n",
      "Epoch [110/300], Step [107/225], Training Accuracy: 98.8610%, Training Loss: 0.0391%\n",
      "Epoch [110/300], Step [108/225], Training Accuracy: 98.8715%, Training Loss: 0.0391%\n",
      "Epoch [110/300], Step [109/225], Training Accuracy: 98.8819%, Training Loss: 0.0388%\n",
      "Epoch [110/300], Step [110/225], Training Accuracy: 98.8920%, Training Loss: 0.0386%\n",
      "Epoch [110/300], Step [111/225], Training Accuracy: 98.9020%, Training Loss: 0.0384%\n",
      "Epoch [110/300], Step [112/225], Training Accuracy: 98.9118%, Training Loss: 0.0383%\n",
      "Epoch [110/300], Step [113/225], Training Accuracy: 98.9215%, Training Loss: 0.0381%\n",
      "Epoch [110/300], Step [114/225], Training Accuracy: 98.9309%, Training Loss: 0.0381%\n",
      "Epoch [110/300], Step [115/225], Training Accuracy: 98.9402%, Training Loss: 0.0381%\n",
      "Epoch [110/300], Step [116/225], Training Accuracy: 98.9224%, Training Loss: 0.0382%\n",
      "Epoch [110/300], Step [117/225], Training Accuracy: 98.9316%, Training Loss: 0.0379%\n",
      "Epoch [110/300], Step [118/225], Training Accuracy: 98.9407%, Training Loss: 0.0378%\n",
      "Epoch [110/300], Step [119/225], Training Accuracy: 98.9496%, Training Loss: 0.0376%\n",
      "Epoch [110/300], Step [120/225], Training Accuracy: 98.9583%, Training Loss: 0.0375%\n",
      "Epoch [110/300], Step [121/225], Training Accuracy: 98.9411%, Training Loss: 0.0379%\n",
      "Epoch [110/300], Step [122/225], Training Accuracy: 98.9498%, Training Loss: 0.0377%\n",
      "Epoch [110/300], Step [123/225], Training Accuracy: 98.9456%, Training Loss: 0.0379%\n",
      "Epoch [110/300], Step [124/225], Training Accuracy: 98.9415%, Training Loss: 0.0378%\n",
      "Epoch [110/300], Step [125/225], Training Accuracy: 98.9500%, Training Loss: 0.0378%\n",
      "Epoch [110/300], Step [126/225], Training Accuracy: 98.9459%, Training Loss: 0.0378%\n",
      "Epoch [110/300], Step [127/225], Training Accuracy: 98.9419%, Training Loss: 0.0378%\n",
      "Epoch [110/300], Step [128/225], Training Accuracy: 98.9502%, Training Loss: 0.0378%\n",
      "Epoch [110/300], Step [129/225], Training Accuracy: 98.9583%, Training Loss: 0.0378%\n",
      "Epoch [110/300], Step [130/225], Training Accuracy: 98.9663%, Training Loss: 0.0376%\n",
      "Epoch [110/300], Step [131/225], Training Accuracy: 98.9742%, Training Loss: 0.0373%\n",
      "Epoch [110/300], Step [132/225], Training Accuracy: 98.9702%, Training Loss: 0.0373%\n",
      "Epoch [110/300], Step [133/225], Training Accuracy: 98.9662%, Training Loss: 0.0372%\n",
      "Epoch [110/300], Step [134/225], Training Accuracy: 98.9622%, Training Loss: 0.0373%\n",
      "Epoch [110/300], Step [135/225], Training Accuracy: 98.9583%, Training Loss: 0.0372%\n",
      "Epoch [110/300], Step [136/225], Training Accuracy: 98.9660%, Training Loss: 0.0372%\n",
      "Epoch [110/300], Step [137/225], Training Accuracy: 98.9621%, Training Loss: 0.0372%\n",
      "Epoch [110/300], Step [138/225], Training Accuracy: 98.9583%, Training Loss: 0.0372%\n",
      "Epoch [110/300], Step [139/225], Training Accuracy: 98.9546%, Training Loss: 0.0372%\n",
      "Epoch [110/300], Step [140/225], Training Accuracy: 98.9509%, Training Loss: 0.0373%\n",
      "Epoch [110/300], Step [141/225], Training Accuracy: 98.9583%, Training Loss: 0.0372%\n",
      "Epoch [110/300], Step [142/225], Training Accuracy: 98.9657%, Training Loss: 0.0371%\n",
      "Epoch [110/300], Step [143/225], Training Accuracy: 98.9729%, Training Loss: 0.0370%\n",
      "Epoch [110/300], Step [144/225], Training Accuracy: 98.9800%, Training Loss: 0.0369%\n",
      "Epoch [110/300], Step [145/225], Training Accuracy: 98.9871%, Training Loss: 0.0367%\n",
      "Epoch [110/300], Step [146/225], Training Accuracy: 98.9940%, Training Loss: 0.0366%\n",
      "Epoch [110/300], Step [147/225], Training Accuracy: 99.0009%, Training Loss: 0.0365%\n",
      "Epoch [110/300], Step [148/225], Training Accuracy: 98.9970%, Training Loss: 0.0365%\n",
      "Epoch [110/300], Step [149/225], Training Accuracy: 99.0038%, Training Loss: 0.0365%\n",
      "Epoch [110/300], Step [150/225], Training Accuracy: 99.0000%, Training Loss: 0.0366%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [110/300], Step [151/225], Training Accuracy: 99.0066%, Training Loss: 0.0365%\n",
      "Epoch [110/300], Step [152/225], Training Accuracy: 99.0132%, Training Loss: 0.0365%\n",
      "Epoch [110/300], Step [153/225], Training Accuracy: 99.0094%, Training Loss: 0.0365%\n",
      "Epoch [110/300], Step [154/225], Training Accuracy: 99.0158%, Training Loss: 0.0365%\n",
      "Epoch [110/300], Step [155/225], Training Accuracy: 99.0222%, Training Loss: 0.0364%\n",
      "Epoch [110/300], Step [156/225], Training Accuracy: 99.0284%, Training Loss: 0.0363%\n",
      "Epoch [110/300], Step [157/225], Training Accuracy: 99.0346%, Training Loss: 0.0362%\n",
      "Epoch [110/300], Step [158/225], Training Accuracy: 99.0407%, Training Loss: 0.0361%\n",
      "Epoch [110/300], Step [159/225], Training Accuracy: 99.0468%, Training Loss: 0.0361%\n",
      "Epoch [110/300], Step [160/225], Training Accuracy: 99.0527%, Training Loss: 0.0360%\n",
      "Epoch [110/300], Step [161/225], Training Accuracy: 99.0586%, Training Loss: 0.0359%\n",
      "Epoch [110/300], Step [162/225], Training Accuracy: 99.0548%, Training Loss: 0.0360%\n",
      "Epoch [110/300], Step [163/225], Training Accuracy: 99.0606%, Training Loss: 0.0359%\n",
      "Epoch [110/300], Step [164/225], Training Accuracy: 99.0663%, Training Loss: 0.0358%\n",
      "Epoch [110/300], Step [165/225], Training Accuracy: 99.0720%, Training Loss: 0.0356%\n",
      "Epoch [110/300], Step [166/225], Training Accuracy: 99.0681%, Training Loss: 0.0357%\n",
      "Epoch [110/300], Step [167/225], Training Accuracy: 99.0737%, Training Loss: 0.0356%\n",
      "Epoch [110/300], Step [168/225], Training Accuracy: 99.0606%, Training Loss: 0.0358%\n",
      "Epoch [110/300], Step [169/225], Training Accuracy: 99.0570%, Training Loss: 0.0358%\n",
      "Epoch [110/300], Step [170/225], Training Accuracy: 99.0441%, Training Loss: 0.0360%\n",
      "Epoch [110/300], Step [171/225], Training Accuracy: 99.0497%, Training Loss: 0.0358%\n",
      "Epoch [110/300], Step [172/225], Training Accuracy: 99.0461%, Training Loss: 0.0359%\n",
      "Epoch [110/300], Step [173/225], Training Accuracy: 99.0336%, Training Loss: 0.0360%\n",
      "Epoch [110/300], Step [174/225], Training Accuracy: 99.0302%, Training Loss: 0.0361%\n",
      "Epoch [110/300], Step [175/225], Training Accuracy: 99.0357%, Training Loss: 0.0360%\n",
      "Epoch [110/300], Step [176/225], Training Accuracy: 99.0234%, Training Loss: 0.0360%\n",
      "Epoch [110/300], Step [177/225], Training Accuracy: 99.0290%, Training Loss: 0.0359%\n",
      "Epoch [110/300], Step [178/225], Training Accuracy: 99.0256%, Training Loss: 0.0359%\n",
      "Epoch [110/300], Step [179/225], Training Accuracy: 99.0311%, Training Loss: 0.0359%\n",
      "Epoch [110/300], Step [180/225], Training Accuracy: 99.0365%, Training Loss: 0.0359%\n",
      "Epoch [110/300], Step [181/225], Training Accuracy: 99.0418%, Training Loss: 0.0358%\n",
      "Epoch [110/300], Step [182/225], Training Accuracy: 99.0385%, Training Loss: 0.0361%\n",
      "Epoch [110/300], Step [183/225], Training Accuracy: 99.0437%, Training Loss: 0.0359%\n",
      "Epoch [110/300], Step [184/225], Training Accuracy: 99.0489%, Training Loss: 0.0358%\n",
      "Epoch [110/300], Step [185/225], Training Accuracy: 99.0541%, Training Loss: 0.0358%\n",
      "Epoch [110/300], Step [186/225], Training Accuracy: 99.0591%, Training Loss: 0.0357%\n",
      "Epoch [110/300], Step [187/225], Training Accuracy: 99.0642%, Training Loss: 0.0356%\n",
      "Epoch [110/300], Step [188/225], Training Accuracy: 99.0608%, Training Loss: 0.0356%\n",
      "Epoch [110/300], Step [189/225], Training Accuracy: 99.0575%, Training Loss: 0.0356%\n",
      "Epoch [110/300], Step [190/225], Training Accuracy: 99.0461%, Training Loss: 0.0358%\n",
      "Epoch [110/300], Step [191/225], Training Accuracy: 99.0510%, Training Loss: 0.0356%\n",
      "Epoch [110/300], Step [192/225], Training Accuracy: 99.0560%, Training Loss: 0.0356%\n",
      "Epoch [110/300], Step [193/225], Training Accuracy: 99.0528%, Training Loss: 0.0356%\n",
      "Epoch [110/300], Step [194/225], Training Accuracy: 99.0496%, Training Loss: 0.0358%\n",
      "Epoch [110/300], Step [195/225], Training Accuracy: 99.0545%, Training Loss: 0.0357%\n",
      "Epoch [110/300], Step [196/225], Training Accuracy: 99.0593%, Training Loss: 0.0357%\n",
      "Epoch [110/300], Step [197/225], Training Accuracy: 99.0641%, Training Loss: 0.0357%\n",
      "Epoch [110/300], Step [198/225], Training Accuracy: 99.0609%, Training Loss: 0.0357%\n",
      "Epoch [110/300], Step [199/225], Training Accuracy: 99.0656%, Training Loss: 0.0357%\n",
      "Epoch [110/300], Step [200/225], Training Accuracy: 99.0703%, Training Loss: 0.0356%\n",
      "Epoch [110/300], Step [201/225], Training Accuracy: 99.0594%, Training Loss: 0.0359%\n",
      "Epoch [110/300], Step [202/225], Training Accuracy: 99.0563%, Training Loss: 0.0360%\n",
      "Epoch [110/300], Step [203/225], Training Accuracy: 99.0533%, Training Loss: 0.0361%\n",
      "Epoch [110/300], Step [204/225], Training Accuracy: 99.0502%, Training Loss: 0.0361%\n",
      "Epoch [110/300], Step [205/225], Training Accuracy: 99.0473%, Training Loss: 0.0361%\n",
      "Epoch [110/300], Step [206/225], Training Accuracy: 99.0367%, Training Loss: 0.0361%\n",
      "Epoch [110/300], Step [207/225], Training Accuracy: 99.0414%, Training Loss: 0.0360%\n",
      "Epoch [110/300], Step [208/225], Training Accuracy: 99.0309%, Training Loss: 0.0361%\n",
      "Epoch [110/300], Step [209/225], Training Accuracy: 99.0356%, Training Loss: 0.0360%\n",
      "Epoch [110/300], Step [210/225], Training Accuracy: 99.0327%, Training Loss: 0.0361%\n",
      "Epoch [110/300], Step [211/225], Training Accuracy: 99.0373%, Training Loss: 0.0360%\n",
      "Epoch [110/300], Step [212/225], Training Accuracy: 99.0419%, Training Loss: 0.0360%\n",
      "Epoch [110/300], Step [213/225], Training Accuracy: 99.0464%, Training Loss: 0.0360%\n",
      "Epoch [110/300], Step [214/225], Training Accuracy: 99.0508%, Training Loss: 0.0359%\n",
      "Epoch [110/300], Step [215/225], Training Accuracy: 99.0552%, Training Loss: 0.0358%\n",
      "Epoch [110/300], Step [216/225], Training Accuracy: 99.0524%, Training Loss: 0.0359%\n",
      "Epoch [110/300], Step [217/225], Training Accuracy: 99.0567%, Training Loss: 0.0359%\n",
      "Epoch [110/300], Step [218/225], Training Accuracy: 99.0611%, Training Loss: 0.0358%\n",
      "Epoch [110/300], Step [219/225], Training Accuracy: 99.0582%, Training Loss: 0.0358%\n",
      "Epoch [110/300], Step [220/225], Training Accuracy: 99.0483%, Training Loss: 0.0360%\n",
      "Epoch [110/300], Step [221/225], Training Accuracy: 99.0526%, Training Loss: 0.0359%\n",
      "Epoch [110/300], Step [222/225], Training Accuracy: 99.0498%, Training Loss: 0.0359%\n",
      "Epoch [110/300], Step [223/225], Training Accuracy: 99.0541%, Training Loss: 0.0358%\n",
      "Epoch [110/300], Step [224/225], Training Accuracy: 99.0583%, Training Loss: 0.0357%\n",
      "Epoch [110/300], Step [225/225], Training Accuracy: 99.0550%, Training Loss: 0.0357%\n",
      "Epoch [111/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0132%\n",
      "Epoch [111/300], Step [2/225], Training Accuracy: 99.2188%, Training Loss: 0.0238%\n",
      "Epoch [111/300], Step [3/225], Training Accuracy: 98.9583%, Training Loss: 0.0323%\n",
      "Epoch [111/300], Step [4/225], Training Accuracy: 99.2188%, Training Loss: 0.0315%\n",
      "Epoch [111/300], Step [5/225], Training Accuracy: 98.7500%, Training Loss: 0.0369%\n",
      "Epoch [111/300], Step [6/225], Training Accuracy: 98.9583%, Training Loss: 0.0333%\n",
      "Epoch [111/300], Step [7/225], Training Accuracy: 99.1071%, Training Loss: 0.0322%\n",
      "Epoch [111/300], Step [8/225], Training Accuracy: 98.4375%, Training Loss: 0.0398%\n",
      "Epoch [111/300], Step [9/225], Training Accuracy: 98.4375%, Training Loss: 0.0409%\n",
      "Epoch [111/300], Step [10/225], Training Accuracy: 98.5938%, Training Loss: 0.0388%\n",
      "Epoch [111/300], Step [11/225], Training Accuracy: 98.7216%, Training Loss: 0.0373%\n",
      "Epoch [111/300], Step [12/225], Training Accuracy: 98.8281%, Training Loss: 0.0347%\n",
      "Epoch [111/300], Step [13/225], Training Accuracy: 98.7981%, Training Loss: 0.0358%\n",
      "Epoch [111/300], Step [14/225], Training Accuracy: 98.7723%, Training Loss: 0.0361%\n",
      "Epoch [111/300], Step [15/225], Training Accuracy: 98.8542%, Training Loss: 0.0358%\n",
      "Epoch [111/300], Step [16/225], Training Accuracy: 98.9258%, Training Loss: 0.0348%\n",
      "Epoch [111/300], Step [17/225], Training Accuracy: 98.9890%, Training Loss: 0.0341%\n",
      "Epoch [111/300], Step [18/225], Training Accuracy: 98.9583%, Training Loss: 0.0356%\n",
      "Epoch [111/300], Step [19/225], Training Accuracy: 98.9309%, Training Loss: 0.0358%\n",
      "Epoch [111/300], Step [20/225], Training Accuracy: 98.9844%, Training Loss: 0.0351%\n",
      "Epoch [111/300], Step [21/225], Training Accuracy: 99.0327%, Training Loss: 0.0342%\n",
      "Epoch [111/300], Step [22/225], Training Accuracy: 99.0057%, Training Loss: 0.0351%\n",
      "Epoch [111/300], Step [23/225], Training Accuracy: 98.9810%, Training Loss: 0.0352%\n",
      "Epoch [111/300], Step [24/225], Training Accuracy: 99.0234%, Training Loss: 0.0355%\n",
      "Epoch [111/300], Step [25/225], Training Accuracy: 99.0000%, Training Loss: 0.0357%\n",
      "Epoch [111/300], Step [26/225], Training Accuracy: 98.9784%, Training Loss: 0.0364%\n",
      "Epoch [111/300], Step [27/225], Training Accuracy: 98.9583%, Training Loss: 0.0373%\n",
      "Epoch [111/300], Step [28/225], Training Accuracy: 98.9955%, Training Loss: 0.0370%\n",
      "Epoch [111/300], Step [29/225], Training Accuracy: 99.0302%, Training Loss: 0.0367%\n",
      "Epoch [111/300], Step [30/225], Training Accuracy: 99.0104%, Training Loss: 0.0370%\n",
      "Epoch [111/300], Step [31/225], Training Accuracy: 98.8407%, Training Loss: 0.0384%\n",
      "Epoch [111/300], Step [32/225], Training Accuracy: 98.8770%, Training Loss: 0.0376%\n",
      "Epoch [111/300], Step [33/225], Training Accuracy: 98.8163%, Training Loss: 0.0380%\n",
      "Epoch [111/300], Step [34/225], Training Accuracy: 98.8051%, Training Loss: 0.0391%\n",
      "Epoch [111/300], Step [35/225], Training Accuracy: 98.8393%, Training Loss: 0.0387%\n",
      "Epoch [111/300], Step [36/225], Training Accuracy: 98.8281%, Training Loss: 0.0389%\n",
      "Epoch [111/300], Step [37/225], Training Accuracy: 98.8176%, Training Loss: 0.0385%\n",
      "Epoch [111/300], Step [38/225], Training Accuracy: 98.7253%, Training Loss: 0.0409%\n",
      "Epoch [111/300], Step [39/225], Training Accuracy: 98.7580%, Training Loss: 0.0409%\n",
      "Epoch [111/300], Step [40/225], Training Accuracy: 98.7500%, Training Loss: 0.0408%\n",
      "Epoch [111/300], Step [41/225], Training Accuracy: 98.7043%, Training Loss: 0.0423%\n",
      "Epoch [111/300], Step [42/225], Training Accuracy: 98.6607%, Training Loss: 0.0428%\n",
      "Epoch [111/300], Step [43/225], Training Accuracy: 98.6919%, Training Loss: 0.0421%\n",
      "Epoch [111/300], Step [44/225], Training Accuracy: 98.6506%, Training Loss: 0.0427%\n",
      "Epoch [111/300], Step [45/225], Training Accuracy: 98.6458%, Training Loss: 0.0430%\n",
      "Epoch [111/300], Step [46/225], Training Accuracy: 98.6753%, Training Loss: 0.0423%\n",
      "Epoch [111/300], Step [47/225], Training Accuracy: 98.7035%, Training Loss: 0.0420%\n",
      "Epoch [111/300], Step [48/225], Training Accuracy: 98.7305%, Training Loss: 0.0416%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [111/300], Step [49/225], Training Accuracy: 98.7564%, Training Loss: 0.0414%\n",
      "Epoch [111/300], Step [50/225], Training Accuracy: 98.7812%, Training Loss: 0.0417%\n",
      "Epoch [111/300], Step [51/225], Training Accuracy: 98.8051%, Training Loss: 0.0415%\n",
      "Epoch [111/300], Step [52/225], Training Accuracy: 98.7981%, Training Loss: 0.0413%\n",
      "Epoch [111/300], Step [53/225], Training Accuracy: 98.7913%, Training Loss: 0.0416%\n",
      "Epoch [111/300], Step [54/225], Training Accuracy: 98.7558%, Training Loss: 0.0418%\n",
      "Epoch [111/300], Step [55/225], Training Accuracy: 98.7500%, Training Loss: 0.0427%\n",
      "Epoch [111/300], Step [56/225], Training Accuracy: 98.7723%, Training Loss: 0.0422%\n",
      "Epoch [111/300], Step [57/225], Training Accuracy: 98.7939%, Training Loss: 0.0417%\n",
      "Epoch [111/300], Step [58/225], Training Accuracy: 98.8147%, Training Loss: 0.0415%\n",
      "Epoch [111/300], Step [59/225], Training Accuracy: 98.8083%, Training Loss: 0.0413%\n",
      "Epoch [111/300], Step [60/225], Training Accuracy: 98.8021%, Training Loss: 0.0420%\n",
      "Epoch [111/300], Step [61/225], Training Accuracy: 98.7705%, Training Loss: 0.0434%\n",
      "Epoch [111/300], Step [62/225], Training Accuracy: 98.7651%, Training Loss: 0.0436%\n",
      "Epoch [111/300], Step [63/225], Training Accuracy: 98.7847%, Training Loss: 0.0432%\n",
      "Epoch [111/300], Step [64/225], Training Accuracy: 98.7793%, Training Loss: 0.0431%\n",
      "Epoch [111/300], Step [65/225], Training Accuracy: 98.7740%, Training Loss: 0.0430%\n",
      "Epoch [111/300], Step [66/225], Training Accuracy: 98.7689%, Training Loss: 0.0434%\n",
      "Epoch [111/300], Step [67/225], Training Accuracy: 98.7873%, Training Loss: 0.0431%\n",
      "Epoch [111/300], Step [68/225], Training Accuracy: 98.7822%, Training Loss: 0.0429%\n",
      "Epoch [111/300], Step [69/225], Training Accuracy: 98.7998%, Training Loss: 0.0424%\n",
      "Epoch [111/300], Step [70/225], Training Accuracy: 98.8170%, Training Loss: 0.0421%\n",
      "Epoch [111/300], Step [71/225], Training Accuracy: 98.8116%, Training Loss: 0.0424%\n",
      "Epoch [111/300], Step [72/225], Training Accuracy: 98.8064%, Training Loss: 0.0428%\n",
      "Epoch [111/300], Step [73/225], Training Accuracy: 98.7800%, Training Loss: 0.0429%\n",
      "Epoch [111/300], Step [74/225], Training Accuracy: 98.7965%, Training Loss: 0.0427%\n",
      "Epoch [111/300], Step [75/225], Training Accuracy: 98.7917%, Training Loss: 0.0425%\n",
      "Epoch [111/300], Step [76/225], Training Accuracy: 98.7870%, Training Loss: 0.0426%\n",
      "Epoch [111/300], Step [77/225], Training Accuracy: 98.7825%, Training Loss: 0.0428%\n",
      "Epoch [111/300], Step [78/225], Training Accuracy: 98.7780%, Training Loss: 0.0431%\n",
      "Epoch [111/300], Step [79/225], Training Accuracy: 98.7737%, Training Loss: 0.0431%\n",
      "Epoch [111/300], Step [80/225], Training Accuracy: 98.7695%, Training Loss: 0.0431%\n",
      "Epoch [111/300], Step [81/225], Training Accuracy: 98.7847%, Training Loss: 0.0427%\n",
      "Epoch [111/300], Step [82/225], Training Accuracy: 98.7995%, Training Loss: 0.0426%\n",
      "Epoch [111/300], Step [83/225], Training Accuracy: 98.7764%, Training Loss: 0.0432%\n",
      "Epoch [111/300], Step [84/225], Training Accuracy: 98.7909%, Training Loss: 0.0430%\n",
      "Epoch [111/300], Step [85/225], Training Accuracy: 98.8051%, Training Loss: 0.0428%\n",
      "Epoch [111/300], Step [86/225], Training Accuracy: 98.8009%, Training Loss: 0.0428%\n",
      "Epoch [111/300], Step [87/225], Training Accuracy: 98.8147%, Training Loss: 0.0424%\n",
      "Epoch [111/300], Step [88/225], Training Accuracy: 98.8104%, Training Loss: 0.0426%\n",
      "Epoch [111/300], Step [89/225], Training Accuracy: 98.8237%, Training Loss: 0.0424%\n",
      "Epoch [111/300], Step [90/225], Training Accuracy: 98.8368%, Training Loss: 0.0422%\n",
      "Epoch [111/300], Step [91/225], Training Accuracy: 98.8496%, Training Loss: 0.0419%\n",
      "Epoch [111/300], Step [92/225], Training Accuracy: 98.8621%, Training Loss: 0.0416%\n",
      "Epoch [111/300], Step [93/225], Training Accuracy: 98.8743%, Training Loss: 0.0415%\n",
      "Epoch [111/300], Step [94/225], Training Accuracy: 98.8531%, Training Loss: 0.0418%\n",
      "Epoch [111/300], Step [95/225], Training Accuracy: 98.8487%, Training Loss: 0.0417%\n",
      "Epoch [111/300], Step [96/225], Training Accuracy: 98.8607%, Training Loss: 0.0414%\n",
      "Epoch [111/300], Step [97/225], Training Accuracy: 98.8724%, Training Loss: 0.0414%\n",
      "Epoch [111/300], Step [98/225], Training Accuracy: 98.8680%, Training Loss: 0.0415%\n",
      "Epoch [111/300], Step [99/225], Training Accuracy: 98.8794%, Training Loss: 0.0413%\n",
      "Epoch [111/300], Step [100/225], Training Accuracy: 98.8906%, Training Loss: 0.0412%\n",
      "Epoch [111/300], Step [101/225], Training Accuracy: 98.8861%, Training Loss: 0.0412%\n",
      "Epoch [111/300], Step [102/225], Training Accuracy: 98.8664%, Training Loss: 0.0412%\n",
      "Epoch [111/300], Step [103/225], Training Accuracy: 98.8774%, Training Loss: 0.0410%\n",
      "Epoch [111/300], Step [104/225], Training Accuracy: 98.8732%, Training Loss: 0.0410%\n",
      "Epoch [111/300], Step [105/225], Training Accuracy: 98.8839%, Training Loss: 0.0409%\n",
      "Epoch [111/300], Step [106/225], Training Accuracy: 98.8797%, Training Loss: 0.0408%\n",
      "Epoch [111/300], Step [107/225], Training Accuracy: 98.8756%, Training Loss: 0.0409%\n",
      "Epoch [111/300], Step [108/225], Training Accuracy: 98.8715%, Training Loss: 0.0411%\n",
      "Epoch [111/300], Step [109/225], Training Accuracy: 98.8675%, Training Loss: 0.0412%\n",
      "Epoch [111/300], Step [110/225], Training Accuracy: 98.8636%, Training Loss: 0.0412%\n",
      "Epoch [111/300], Step [111/225], Training Accuracy: 98.8739%, Training Loss: 0.0411%\n",
      "Epoch [111/300], Step [112/225], Training Accuracy: 98.8839%, Training Loss: 0.0410%\n",
      "Epoch [111/300], Step [113/225], Training Accuracy: 98.8800%, Training Loss: 0.0409%\n",
      "Epoch [111/300], Step [114/225], Training Accuracy: 98.8898%, Training Loss: 0.0408%\n",
      "Epoch [111/300], Step [115/225], Training Accuracy: 98.8995%, Training Loss: 0.0407%\n",
      "Epoch [111/300], Step [116/225], Training Accuracy: 98.9089%, Training Loss: 0.0405%\n",
      "Epoch [111/300], Step [117/225], Training Accuracy: 98.9183%, Training Loss: 0.0405%\n",
      "Epoch [111/300], Step [118/225], Training Accuracy: 98.9142%, Training Loss: 0.0405%\n",
      "Epoch [111/300], Step [119/225], Training Accuracy: 98.9233%, Training Loss: 0.0402%\n",
      "Epoch [111/300], Step [120/225], Training Accuracy: 98.9062%, Training Loss: 0.0402%\n",
      "Epoch [111/300], Step [121/225], Training Accuracy: 98.9153%, Training Loss: 0.0401%\n",
      "Epoch [111/300], Step [122/225], Training Accuracy: 98.9242%, Training Loss: 0.0399%\n",
      "Epoch [111/300], Step [123/225], Training Accuracy: 98.9329%, Training Loss: 0.0397%\n",
      "Epoch [111/300], Step [124/225], Training Accuracy: 98.9415%, Training Loss: 0.0395%\n",
      "Epoch [111/300], Step [125/225], Training Accuracy: 98.9375%, Training Loss: 0.0396%\n",
      "Epoch [111/300], Step [126/225], Training Accuracy: 98.9335%, Training Loss: 0.0396%\n",
      "Epoch [111/300], Step [127/225], Training Accuracy: 98.9419%, Training Loss: 0.0394%\n",
      "Epoch [111/300], Step [128/225], Training Accuracy: 98.9502%, Training Loss: 0.0393%\n",
      "Epoch [111/300], Step [129/225], Training Accuracy: 98.9220%, Training Loss: 0.0398%\n",
      "Epoch [111/300], Step [130/225], Training Accuracy: 98.9062%, Training Loss: 0.0401%\n",
      "Epoch [111/300], Step [131/225], Training Accuracy: 98.9146%, Training Loss: 0.0399%\n",
      "Epoch [111/300], Step [132/225], Training Accuracy: 98.9110%, Training Loss: 0.0399%\n",
      "Epoch [111/300], Step [133/225], Training Accuracy: 98.9074%, Training Loss: 0.0400%\n",
      "Epoch [111/300], Step [134/225], Training Accuracy: 98.9039%, Training Loss: 0.0399%\n",
      "Epoch [111/300], Step [135/225], Training Accuracy: 98.9120%, Training Loss: 0.0397%\n",
      "Epoch [111/300], Step [136/225], Training Accuracy: 98.9200%, Training Loss: 0.0395%\n",
      "Epoch [111/300], Step [137/225], Training Accuracy: 98.9165%, Training Loss: 0.0395%\n",
      "Epoch [111/300], Step [138/225], Training Accuracy: 98.9244%, Training Loss: 0.0392%\n",
      "Epoch [111/300], Step [139/225], Training Accuracy: 98.9209%, Training Loss: 0.0393%\n",
      "Epoch [111/300], Step [140/225], Training Accuracy: 98.9286%, Training Loss: 0.0391%\n",
      "Epoch [111/300], Step [141/225], Training Accuracy: 98.9362%, Training Loss: 0.0390%\n",
      "Epoch [111/300], Step [142/225], Training Accuracy: 98.9437%, Training Loss: 0.0389%\n",
      "Epoch [111/300], Step [143/225], Training Accuracy: 98.9401%, Training Loss: 0.0390%\n",
      "Epoch [111/300], Step [144/225], Training Accuracy: 98.9475%, Training Loss: 0.0389%\n",
      "Epoch [111/300], Step [145/225], Training Accuracy: 98.9547%, Training Loss: 0.0389%\n",
      "Epoch [111/300], Step [146/225], Training Accuracy: 98.9298%, Training Loss: 0.0392%\n",
      "Epoch [111/300], Step [147/225], Training Accuracy: 98.9264%, Training Loss: 0.0392%\n",
      "Epoch [111/300], Step [148/225], Training Accuracy: 98.9337%, Training Loss: 0.0391%\n",
      "Epoch [111/300], Step [149/225], Training Accuracy: 98.9409%, Training Loss: 0.0390%\n",
      "Epoch [111/300], Step [150/225], Training Accuracy: 98.9479%, Training Loss: 0.0389%\n",
      "Epoch [111/300], Step [151/225], Training Accuracy: 98.9445%, Training Loss: 0.0389%\n",
      "Epoch [111/300], Step [152/225], Training Accuracy: 98.9412%, Training Loss: 0.0390%\n",
      "Epoch [111/300], Step [153/225], Training Accuracy: 98.9481%, Training Loss: 0.0389%\n",
      "Epoch [111/300], Step [154/225], Training Accuracy: 98.9550%, Training Loss: 0.0387%\n",
      "Epoch [111/300], Step [155/225], Training Accuracy: 98.9516%, Training Loss: 0.0386%\n",
      "Epoch [111/300], Step [156/225], Training Accuracy: 98.9583%, Training Loss: 0.0385%\n",
      "Epoch [111/300], Step [157/225], Training Accuracy: 98.9650%, Training Loss: 0.0384%\n",
      "Epoch [111/300], Step [158/225], Training Accuracy: 98.9715%, Training Loss: 0.0382%\n",
      "Epoch [111/300], Step [159/225], Training Accuracy: 98.9780%, Training Loss: 0.0381%\n",
      "Epoch [111/300], Step [160/225], Training Accuracy: 98.9844%, Training Loss: 0.0380%\n",
      "Epoch [111/300], Step [161/225], Training Accuracy: 98.9907%, Training Loss: 0.0378%\n",
      "Epoch [111/300], Step [162/225], Training Accuracy: 98.9873%, Training Loss: 0.0379%\n",
      "Epoch [111/300], Step [163/225], Training Accuracy: 98.9935%, Training Loss: 0.0379%\n",
      "Epoch [111/300], Step [164/225], Training Accuracy: 98.9901%, Training Loss: 0.0379%\n",
      "Epoch [111/300], Step [165/225], Training Accuracy: 98.9962%, Training Loss: 0.0378%\n",
      "Epoch [111/300], Step [166/225], Training Accuracy: 98.9928%, Training Loss: 0.0377%\n",
      "Epoch [111/300], Step [167/225], Training Accuracy: 98.9989%, Training Loss: 0.0376%\n",
      "Epoch [111/300], Step [168/225], Training Accuracy: 99.0048%, Training Loss: 0.0374%\n",
      "Epoch [111/300], Step [169/225], Training Accuracy: 99.0107%, Training Loss: 0.0374%\n",
      "Epoch [111/300], Step [170/225], Training Accuracy: 98.9982%, Training Loss: 0.0376%\n",
      "Epoch [111/300], Step [171/225], Training Accuracy: 99.0040%, Training Loss: 0.0375%\n",
      "Epoch [111/300], Step [172/225], Training Accuracy: 99.0098%, Training Loss: 0.0375%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [111/300], Step [173/225], Training Accuracy: 99.0065%, Training Loss: 0.0377%\n",
      "Epoch [111/300], Step [174/225], Training Accuracy: 99.0032%, Training Loss: 0.0377%\n",
      "Epoch [111/300], Step [175/225], Training Accuracy: 99.0089%, Training Loss: 0.0376%\n",
      "Epoch [111/300], Step [176/225], Training Accuracy: 99.0057%, Training Loss: 0.0376%\n",
      "Epoch [111/300], Step [177/225], Training Accuracy: 99.0113%, Training Loss: 0.0375%\n",
      "Epoch [111/300], Step [178/225], Training Accuracy: 99.0169%, Training Loss: 0.0375%\n",
      "Epoch [111/300], Step [179/225], Training Accuracy: 99.0223%, Training Loss: 0.0374%\n",
      "Epoch [111/300], Step [180/225], Training Accuracy: 99.0278%, Training Loss: 0.0374%\n",
      "Epoch [111/300], Step [181/225], Training Accuracy: 99.0331%, Training Loss: 0.0373%\n",
      "Epoch [111/300], Step [182/225], Training Accuracy: 99.0385%, Training Loss: 0.0372%\n",
      "Epoch [111/300], Step [183/225], Training Accuracy: 99.0437%, Training Loss: 0.0371%\n",
      "Epoch [111/300], Step [184/225], Training Accuracy: 99.0489%, Training Loss: 0.0370%\n",
      "Epoch [111/300], Step [185/225], Training Accuracy: 99.0541%, Training Loss: 0.0369%\n",
      "Epoch [111/300], Step [186/225], Training Accuracy: 99.0591%, Training Loss: 0.0368%\n",
      "Epoch [111/300], Step [187/225], Training Accuracy: 99.0558%, Training Loss: 0.0369%\n",
      "Epoch [111/300], Step [188/225], Training Accuracy: 99.0608%, Training Loss: 0.0368%\n",
      "Epoch [111/300], Step [189/225], Training Accuracy: 99.0575%, Training Loss: 0.0367%\n",
      "Epoch [111/300], Step [190/225], Training Accuracy: 99.0378%, Training Loss: 0.0369%\n",
      "Epoch [111/300], Step [191/225], Training Accuracy: 99.0429%, Training Loss: 0.0368%\n",
      "Epoch [111/300], Step [192/225], Training Accuracy: 99.0479%, Training Loss: 0.0367%\n",
      "Epoch [111/300], Step [193/225], Training Accuracy: 99.0447%, Training Loss: 0.0367%\n",
      "Epoch [111/300], Step [194/225], Training Accuracy: 99.0335%, Training Loss: 0.0368%\n",
      "Epoch [111/300], Step [195/225], Training Accuracy: 99.0385%, Training Loss: 0.0368%\n",
      "Epoch [111/300], Step [196/225], Training Accuracy: 99.0354%, Training Loss: 0.0368%\n",
      "Epoch [111/300], Step [197/225], Training Accuracy: 99.0324%, Training Loss: 0.0371%\n",
      "Epoch [111/300], Step [198/225], Training Accuracy: 99.0294%, Training Loss: 0.0371%\n",
      "Epoch [111/300], Step [199/225], Training Accuracy: 99.0342%, Training Loss: 0.0371%\n",
      "Epoch [111/300], Step [200/225], Training Accuracy: 99.0391%, Training Loss: 0.0370%\n",
      "Epoch [111/300], Step [201/225], Training Accuracy: 99.0205%, Training Loss: 0.0371%\n",
      "Epoch [111/300], Step [202/225], Training Accuracy: 99.0176%, Training Loss: 0.0373%\n",
      "Epoch [111/300], Step [203/225], Training Accuracy: 99.0225%, Training Loss: 0.0373%\n",
      "Epoch [111/300], Step [204/225], Training Accuracy: 99.0196%, Training Loss: 0.0373%\n",
      "Epoch [111/300], Step [205/225], Training Accuracy: 99.0244%, Training Loss: 0.0371%\n",
      "Epoch [111/300], Step [206/225], Training Accuracy: 99.0140%, Training Loss: 0.0373%\n",
      "Epoch [111/300], Step [207/225], Training Accuracy: 99.0187%, Training Loss: 0.0373%\n",
      "Epoch [111/300], Step [208/225], Training Accuracy: 99.0084%, Training Loss: 0.0374%\n",
      "Epoch [111/300], Step [209/225], Training Accuracy: 99.0057%, Training Loss: 0.0373%\n",
      "Epoch [111/300], Step [210/225], Training Accuracy: 99.0030%, Training Loss: 0.0373%\n",
      "Epoch [111/300], Step [211/225], Training Accuracy: 99.0003%, Training Loss: 0.0373%\n",
      "Epoch [111/300], Step [212/225], Training Accuracy: 98.9976%, Training Loss: 0.0373%\n",
      "Epoch [111/300], Step [213/225], Training Accuracy: 99.0023%, Training Loss: 0.0372%\n",
      "Epoch [111/300], Step [214/225], Training Accuracy: 99.0070%, Training Loss: 0.0372%\n",
      "Epoch [111/300], Step [215/225], Training Accuracy: 99.0116%, Training Loss: 0.0372%\n",
      "Epoch [111/300], Step [216/225], Training Accuracy: 99.0162%, Training Loss: 0.0371%\n",
      "Epoch [111/300], Step [217/225], Training Accuracy: 98.9991%, Training Loss: 0.0376%\n",
      "Epoch [111/300], Step [218/225], Training Accuracy: 98.9966%, Training Loss: 0.0377%\n",
      "Epoch [111/300], Step [219/225], Training Accuracy: 98.9655%, Training Loss: 0.0381%\n",
      "Epoch [111/300], Step [220/225], Training Accuracy: 98.9631%, Training Loss: 0.0380%\n",
      "Epoch [111/300], Step [221/225], Training Accuracy: 98.9678%, Training Loss: 0.0380%\n",
      "Epoch [111/300], Step [222/225], Training Accuracy: 98.9654%, Training Loss: 0.0379%\n",
      "Epoch [111/300], Step [223/225], Training Accuracy: 98.9630%, Training Loss: 0.0379%\n",
      "Epoch [111/300], Step [224/225], Training Accuracy: 98.9676%, Training Loss: 0.0378%\n",
      "Epoch [111/300], Step [225/225], Training Accuracy: 98.9717%, Training Loss: 0.0377%\n",
      "Epoch [112/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0085%\n",
      "Epoch [112/300], Step [2/225], Training Accuracy: 100.0000%, Training Loss: 0.0123%\n",
      "Epoch [112/300], Step [3/225], Training Accuracy: 99.4792%, Training Loss: 0.0195%\n",
      "Epoch [112/300], Step [4/225], Training Accuracy: 99.2188%, Training Loss: 0.0305%\n",
      "Epoch [112/300], Step [5/225], Training Accuracy: 99.3750%, Training Loss: 0.0288%\n",
      "Epoch [112/300], Step [6/225], Training Accuracy: 99.4792%, Training Loss: 0.0278%\n",
      "Epoch [112/300], Step [7/225], Training Accuracy: 99.5536%, Training Loss: 0.0278%\n",
      "Epoch [112/300], Step [8/225], Training Accuracy: 99.4141%, Training Loss: 0.0290%\n",
      "Epoch [112/300], Step [9/225], Training Accuracy: 99.3056%, Training Loss: 0.0326%\n",
      "Epoch [112/300], Step [10/225], Training Accuracy: 99.3750%, Training Loss: 0.0300%\n",
      "Epoch [112/300], Step [11/225], Training Accuracy: 99.4318%, Training Loss: 0.0299%\n",
      "Epoch [112/300], Step [12/225], Training Accuracy: 99.3490%, Training Loss: 0.0335%\n",
      "Epoch [112/300], Step [13/225], Training Accuracy: 99.3990%, Training Loss: 0.0328%\n",
      "Epoch [112/300], Step [14/225], Training Accuracy: 99.3304%, Training Loss: 0.0334%\n",
      "Epoch [112/300], Step [15/225], Training Accuracy: 99.2708%, Training Loss: 0.0333%\n",
      "Epoch [112/300], Step [16/225], Training Accuracy: 99.2188%, Training Loss: 0.0328%\n",
      "Epoch [112/300], Step [17/225], Training Accuracy: 99.0809%, Training Loss: 0.0352%\n",
      "Epoch [112/300], Step [18/225], Training Accuracy: 98.9583%, Training Loss: 0.0382%\n",
      "Epoch [112/300], Step [19/225], Training Accuracy: 98.9309%, Training Loss: 0.0383%\n",
      "Epoch [112/300], Step [20/225], Training Accuracy: 98.9844%, Training Loss: 0.0376%\n",
      "Epoch [112/300], Step [21/225], Training Accuracy: 99.0327%, Training Loss: 0.0366%\n",
      "Epoch [112/300], Step [22/225], Training Accuracy: 99.0057%, Training Loss: 0.0377%\n",
      "Epoch [112/300], Step [23/225], Training Accuracy: 98.9130%, Training Loss: 0.0382%\n",
      "Epoch [112/300], Step [24/225], Training Accuracy: 98.8281%, Training Loss: 0.0384%\n",
      "Epoch [112/300], Step [25/225], Training Accuracy: 98.6875%, Training Loss: 0.0396%\n",
      "Epoch [112/300], Step [26/225], Training Accuracy: 98.6779%, Training Loss: 0.0414%\n",
      "Epoch [112/300], Step [27/225], Training Accuracy: 98.7269%, Training Loss: 0.0411%\n",
      "Epoch [112/300], Step [28/225], Training Accuracy: 98.7723%, Training Loss: 0.0402%\n",
      "Epoch [112/300], Step [29/225], Training Accuracy: 98.7608%, Training Loss: 0.0405%\n",
      "Epoch [112/300], Step [30/225], Training Accuracy: 98.7500%, Training Loss: 0.0416%\n",
      "Epoch [112/300], Step [31/225], Training Accuracy: 98.7399%, Training Loss: 0.0414%\n",
      "Epoch [112/300], Step [32/225], Training Accuracy: 98.7793%, Training Loss: 0.0411%\n",
      "Epoch [112/300], Step [33/225], Training Accuracy: 98.7689%, Training Loss: 0.0405%\n",
      "Epoch [112/300], Step [34/225], Training Accuracy: 98.7592%, Training Loss: 0.0405%\n",
      "Epoch [112/300], Step [35/225], Training Accuracy: 98.7500%, Training Loss: 0.0399%\n",
      "Epoch [112/300], Step [36/225], Training Accuracy: 98.7847%, Training Loss: 0.0392%\n",
      "Epoch [112/300], Step [37/225], Training Accuracy: 98.7753%, Training Loss: 0.0391%\n",
      "Epoch [112/300], Step [38/225], Training Accuracy: 98.7664%, Training Loss: 0.0395%\n",
      "Epoch [112/300], Step [39/225], Training Accuracy: 98.7580%, Training Loss: 0.0397%\n",
      "Epoch [112/300], Step [40/225], Training Accuracy: 98.7891%, Training Loss: 0.0398%\n",
      "Epoch [112/300], Step [41/225], Training Accuracy: 98.8186%, Training Loss: 0.0394%\n",
      "Epoch [112/300], Step [42/225], Training Accuracy: 98.7723%, Training Loss: 0.0397%\n",
      "Epoch [112/300], Step [43/225], Training Accuracy: 98.8009%, Training Loss: 0.0399%\n",
      "Epoch [112/300], Step [44/225], Training Accuracy: 98.7926%, Training Loss: 0.0399%\n",
      "Epoch [112/300], Step [45/225], Training Accuracy: 98.8194%, Training Loss: 0.0397%\n",
      "Epoch [112/300], Step [46/225], Training Accuracy: 98.8451%, Training Loss: 0.0394%\n",
      "Epoch [112/300], Step [47/225], Training Accuracy: 98.8697%, Training Loss: 0.0389%\n",
      "Epoch [112/300], Step [48/225], Training Accuracy: 98.8932%, Training Loss: 0.0388%\n",
      "Epoch [112/300], Step [49/225], Training Accuracy: 98.9158%, Training Loss: 0.0383%\n",
      "Epoch [112/300], Step [50/225], Training Accuracy: 98.8750%, Training Loss: 0.0387%\n",
      "Epoch [112/300], Step [51/225], Training Accuracy: 98.8971%, Training Loss: 0.0384%\n",
      "Epoch [112/300], Step [52/225], Training Accuracy: 98.9183%, Training Loss: 0.0378%\n",
      "Epoch [112/300], Step [53/225], Training Accuracy: 98.9387%, Training Loss: 0.0377%\n",
      "Epoch [112/300], Step [54/225], Training Accuracy: 98.9005%, Training Loss: 0.0387%\n",
      "Epoch [112/300], Step [55/225], Training Accuracy: 98.9205%, Training Loss: 0.0384%\n",
      "Epoch [112/300], Step [56/225], Training Accuracy: 98.9118%, Training Loss: 0.0386%\n",
      "Epoch [112/300], Step [57/225], Training Accuracy: 98.8761%, Training Loss: 0.0393%\n",
      "Epoch [112/300], Step [58/225], Training Accuracy: 98.8955%, Training Loss: 0.0390%\n",
      "Epoch [112/300], Step [59/225], Training Accuracy: 98.9142%, Training Loss: 0.0386%\n",
      "Epoch [112/300], Step [60/225], Training Accuracy: 98.9062%, Training Loss: 0.0388%\n",
      "Epoch [112/300], Step [61/225], Training Accuracy: 98.8986%, Training Loss: 0.0393%\n",
      "Epoch [112/300], Step [62/225], Training Accuracy: 98.9163%, Training Loss: 0.0391%\n",
      "Epoch [112/300], Step [63/225], Training Accuracy: 98.9087%, Training Loss: 0.0394%\n",
      "Epoch [112/300], Step [64/225], Training Accuracy: 98.9014%, Training Loss: 0.0395%\n",
      "Epoch [112/300], Step [65/225], Training Accuracy: 98.9183%, Training Loss: 0.0395%\n",
      "Epoch [112/300], Step [66/225], Training Accuracy: 98.9347%, Training Loss: 0.0391%\n",
      "Epoch [112/300], Step [67/225], Training Accuracy: 98.9272%, Training Loss: 0.0391%\n",
      "Epoch [112/300], Step [68/225], Training Accuracy: 98.9200%, Training Loss: 0.0388%\n",
      "Epoch [112/300], Step [69/225], Training Accuracy: 98.9130%, Training Loss: 0.0390%\n",
      "Epoch [112/300], Step [70/225], Training Accuracy: 98.9286%, Training Loss: 0.0388%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [112/300], Step [71/225], Training Accuracy: 98.9437%, Training Loss: 0.0387%\n",
      "Epoch [112/300], Step [72/225], Training Accuracy: 98.9366%, Training Loss: 0.0388%\n",
      "Epoch [112/300], Step [73/225], Training Accuracy: 98.9512%, Training Loss: 0.0386%\n",
      "Epoch [112/300], Step [74/225], Training Accuracy: 98.9020%, Training Loss: 0.0401%\n",
      "Epoch [112/300], Step [75/225], Training Accuracy: 98.8958%, Training Loss: 0.0400%\n",
      "Epoch [112/300], Step [76/225], Training Accuracy: 98.8898%, Training Loss: 0.0399%\n",
      "Epoch [112/300], Step [77/225], Training Accuracy: 98.9042%, Training Loss: 0.0397%\n",
      "Epoch [112/300], Step [78/225], Training Accuracy: 98.9183%, Training Loss: 0.0397%\n",
      "Epoch [112/300], Step [79/225], Training Accuracy: 98.9320%, Training Loss: 0.0395%\n",
      "Epoch [112/300], Step [80/225], Training Accuracy: 98.9453%, Training Loss: 0.0394%\n",
      "Epoch [112/300], Step [81/225], Training Accuracy: 98.9198%, Training Loss: 0.0400%\n",
      "Epoch [112/300], Step [82/225], Training Accuracy: 98.9139%, Training Loss: 0.0400%\n",
      "Epoch [112/300], Step [83/225], Training Accuracy: 98.9270%, Training Loss: 0.0399%\n",
      "Epoch [112/300], Step [84/225], Training Accuracy: 98.9211%, Training Loss: 0.0400%\n",
      "Epoch [112/300], Step [85/225], Training Accuracy: 98.8971%, Training Loss: 0.0401%\n",
      "Epoch [112/300], Step [86/225], Training Accuracy: 98.8917%, Training Loss: 0.0402%\n",
      "Epoch [112/300], Step [87/225], Training Accuracy: 98.9045%, Training Loss: 0.0399%\n",
      "Epoch [112/300], Step [88/225], Training Accuracy: 98.9169%, Training Loss: 0.0398%\n",
      "Epoch [112/300], Step [89/225], Training Accuracy: 98.9115%, Training Loss: 0.0401%\n",
      "Epoch [112/300], Step [90/225], Training Accuracy: 98.9236%, Training Loss: 0.0399%\n",
      "Epoch [112/300], Step [91/225], Training Accuracy: 98.9183%, Training Loss: 0.0403%\n",
      "Epoch [112/300], Step [92/225], Training Accuracy: 98.9130%, Training Loss: 0.0404%\n",
      "Epoch [112/300], Step [93/225], Training Accuracy: 98.9079%, Training Loss: 0.0402%\n",
      "Epoch [112/300], Step [94/225], Training Accuracy: 98.9029%, Training Loss: 0.0404%\n",
      "Epoch [112/300], Step [95/225], Training Accuracy: 98.8980%, Training Loss: 0.0406%\n",
      "Epoch [112/300], Step [96/225], Training Accuracy: 98.8932%, Training Loss: 0.0407%\n",
      "Epoch [112/300], Step [97/225], Training Accuracy: 98.9046%, Training Loss: 0.0406%\n",
      "Epoch [112/300], Step [98/225], Training Accuracy: 98.8999%, Training Loss: 0.0409%\n",
      "Epoch [112/300], Step [99/225], Training Accuracy: 98.9110%, Training Loss: 0.0407%\n",
      "Epoch [112/300], Step [100/225], Training Accuracy: 98.8906%, Training Loss: 0.0407%\n",
      "Epoch [112/300], Step [101/225], Training Accuracy: 98.9016%, Training Loss: 0.0406%\n",
      "Epoch [112/300], Step [102/225], Training Accuracy: 98.8817%, Training Loss: 0.0408%\n",
      "Epoch [112/300], Step [103/225], Training Accuracy: 98.8774%, Training Loss: 0.0407%\n",
      "Epoch [112/300], Step [104/225], Training Accuracy: 98.8882%, Training Loss: 0.0405%\n",
      "Epoch [112/300], Step [105/225], Training Accuracy: 98.8839%, Training Loss: 0.0405%\n",
      "Epoch [112/300], Step [106/225], Training Accuracy: 98.8650%, Training Loss: 0.0406%\n",
      "Epoch [112/300], Step [107/225], Training Accuracy: 98.8756%, Training Loss: 0.0406%\n",
      "Epoch [112/300], Step [108/225], Training Accuracy: 98.8860%, Training Loss: 0.0405%\n",
      "Epoch [112/300], Step [109/225], Training Accuracy: 98.8819%, Training Loss: 0.0410%\n",
      "Epoch [112/300], Step [110/225], Training Accuracy: 98.8778%, Training Loss: 0.0410%\n",
      "Epoch [112/300], Step [111/225], Training Accuracy: 98.8880%, Training Loss: 0.0408%\n",
      "Epoch [112/300], Step [112/225], Training Accuracy: 98.8839%, Training Loss: 0.0408%\n",
      "Epoch [112/300], Step [113/225], Training Accuracy: 98.8938%, Training Loss: 0.0405%\n",
      "Epoch [112/300], Step [114/225], Training Accuracy: 98.8898%, Training Loss: 0.0405%\n",
      "Epoch [112/300], Step [115/225], Training Accuracy: 98.8995%, Training Loss: 0.0403%\n",
      "Epoch [112/300], Step [116/225], Training Accuracy: 98.8820%, Training Loss: 0.0404%\n",
      "Epoch [112/300], Step [117/225], Training Accuracy: 98.8916%, Training Loss: 0.0403%\n",
      "Epoch [112/300], Step [118/225], Training Accuracy: 98.8877%, Training Loss: 0.0407%\n",
      "Epoch [112/300], Step [119/225], Training Accuracy: 98.8971%, Training Loss: 0.0405%\n",
      "Epoch [112/300], Step [120/225], Training Accuracy: 98.8802%, Training Loss: 0.0405%\n",
      "Epoch [112/300], Step [121/225], Training Accuracy: 98.8895%, Training Loss: 0.0403%\n",
      "Epoch [112/300], Step [122/225], Training Accuracy: 98.8986%, Training Loss: 0.0402%\n",
      "Epoch [112/300], Step [123/225], Training Accuracy: 98.8948%, Training Loss: 0.0403%\n",
      "Epoch [112/300], Step [124/225], Training Accuracy: 98.8911%, Training Loss: 0.0403%\n",
      "Epoch [112/300], Step [125/225], Training Accuracy: 98.8875%, Training Loss: 0.0403%\n",
      "Epoch [112/300], Step [126/225], Training Accuracy: 98.8715%, Training Loss: 0.0405%\n",
      "Epoch [112/300], Step [127/225], Training Accuracy: 98.8681%, Training Loss: 0.0405%\n",
      "Epoch [112/300], Step [128/225], Training Accuracy: 98.8770%, Training Loss: 0.0404%\n",
      "Epoch [112/300], Step [129/225], Training Accuracy: 98.8735%, Training Loss: 0.0407%\n",
      "Epoch [112/300], Step [130/225], Training Accuracy: 98.8822%, Training Loss: 0.0405%\n",
      "Epoch [112/300], Step [131/225], Training Accuracy: 98.8788%, Training Loss: 0.0408%\n",
      "Epoch [112/300], Step [132/225], Training Accuracy: 98.8755%, Training Loss: 0.0409%\n",
      "Epoch [112/300], Step [133/225], Training Accuracy: 98.8722%, Training Loss: 0.0407%\n",
      "Epoch [112/300], Step [134/225], Training Accuracy: 98.8689%, Training Loss: 0.0408%\n",
      "Epoch [112/300], Step [135/225], Training Accuracy: 98.8657%, Training Loss: 0.0408%\n",
      "Epoch [112/300], Step [136/225], Training Accuracy: 98.8396%, Training Loss: 0.0415%\n",
      "Epoch [112/300], Step [137/225], Training Accuracy: 98.8481%, Training Loss: 0.0413%\n",
      "Epoch [112/300], Step [138/225], Training Accuracy: 98.8564%, Training Loss: 0.0412%\n",
      "Epoch [112/300], Step [139/225], Training Accuracy: 98.8309%, Training Loss: 0.0421%\n",
      "Epoch [112/300], Step [140/225], Training Accuracy: 98.8170%, Training Loss: 0.0421%\n",
      "Epoch [112/300], Step [141/225], Training Accuracy: 98.8032%, Training Loss: 0.0423%\n",
      "Epoch [112/300], Step [142/225], Training Accuracy: 98.8006%, Training Loss: 0.0423%\n",
      "Epoch [112/300], Step [143/225], Training Accuracy: 98.7981%, Training Loss: 0.0424%\n",
      "Epoch [112/300], Step [144/225], Training Accuracy: 98.8064%, Training Loss: 0.0425%\n",
      "Epoch [112/300], Step [145/225], Training Accuracy: 98.8147%, Training Loss: 0.0423%\n",
      "Epoch [112/300], Step [146/225], Training Accuracy: 98.8121%, Training Loss: 0.0423%\n",
      "Epoch [112/300], Step [147/225], Training Accuracy: 98.8095%, Training Loss: 0.0424%\n",
      "Epoch [112/300], Step [148/225], Training Accuracy: 98.8176%, Training Loss: 0.0424%\n",
      "Epoch [112/300], Step [149/225], Training Accuracy: 98.8045%, Training Loss: 0.0425%\n",
      "Epoch [112/300], Step [150/225], Training Accuracy: 98.8021%, Training Loss: 0.0424%\n",
      "Epoch [112/300], Step [151/225], Training Accuracy: 98.8100%, Training Loss: 0.0423%\n",
      "Epoch [112/300], Step [152/225], Training Accuracy: 98.8178%, Training Loss: 0.0420%\n",
      "Epoch [112/300], Step [153/225], Training Accuracy: 98.8154%, Training Loss: 0.0420%\n",
      "Epoch [112/300], Step [154/225], Training Accuracy: 98.8028%, Training Loss: 0.0420%\n",
      "Epoch [112/300], Step [155/225], Training Accuracy: 98.7802%, Training Loss: 0.0423%\n",
      "Epoch [112/300], Step [156/225], Training Accuracy: 98.7881%, Training Loss: 0.0423%\n",
      "Epoch [112/300], Step [157/225], Training Accuracy: 98.7858%, Training Loss: 0.0423%\n",
      "Epoch [112/300], Step [158/225], Training Accuracy: 98.7836%, Training Loss: 0.0423%\n",
      "Epoch [112/300], Step [159/225], Training Accuracy: 98.7913%, Training Loss: 0.0422%\n",
      "Epoch [112/300], Step [160/225], Training Accuracy: 98.7891%, Training Loss: 0.0423%\n",
      "Epoch [112/300], Step [161/225], Training Accuracy: 98.7966%, Training Loss: 0.0422%\n",
      "Epoch [112/300], Step [162/225], Training Accuracy: 98.7847%, Training Loss: 0.0425%\n",
      "Epoch [112/300], Step [163/225], Training Accuracy: 98.7730%, Training Loss: 0.0427%\n",
      "Epoch [112/300], Step [164/225], Training Accuracy: 98.7710%, Training Loss: 0.0426%\n",
      "Epoch [112/300], Step [165/225], Training Accuracy: 98.7784%, Training Loss: 0.0425%\n",
      "Epoch [112/300], Step [166/225], Training Accuracy: 98.7669%, Training Loss: 0.0427%\n",
      "Epoch [112/300], Step [167/225], Training Accuracy: 98.7650%, Training Loss: 0.0427%\n",
      "Epoch [112/300], Step [168/225], Training Accuracy: 98.7723%, Training Loss: 0.0426%\n",
      "Epoch [112/300], Step [169/225], Training Accuracy: 98.7611%, Training Loss: 0.0427%\n",
      "Epoch [112/300], Step [170/225], Training Accuracy: 98.7592%, Training Loss: 0.0428%\n",
      "Epoch [112/300], Step [171/225], Training Accuracy: 98.7573%, Training Loss: 0.0434%\n",
      "Epoch [112/300], Step [172/225], Training Accuracy: 98.7555%, Training Loss: 0.0434%\n",
      "Epoch [112/300], Step [173/225], Training Accuracy: 98.7626%, Training Loss: 0.0433%\n",
      "Epoch [112/300], Step [174/225], Training Accuracy: 98.7608%, Training Loss: 0.0433%\n",
      "Epoch [112/300], Step [175/225], Training Accuracy: 98.7679%, Training Loss: 0.0431%\n",
      "Epoch [112/300], Step [176/225], Training Accuracy: 98.7571%, Training Loss: 0.0433%\n",
      "Epoch [112/300], Step [177/225], Training Accuracy: 98.7641%, Training Loss: 0.0432%\n",
      "Epoch [112/300], Step [178/225], Training Accuracy: 98.7447%, Training Loss: 0.0436%\n",
      "Epoch [112/300], Step [179/225], Training Accuracy: 98.7430%, Training Loss: 0.0436%\n",
      "Epoch [112/300], Step [180/225], Training Accuracy: 98.7240%, Training Loss: 0.0438%\n",
      "Epoch [112/300], Step [181/225], Training Accuracy: 98.7137%, Training Loss: 0.0442%\n",
      "Epoch [112/300], Step [182/225], Training Accuracy: 98.7208%, Training Loss: 0.0441%\n",
      "Epoch [112/300], Step [183/225], Training Accuracy: 98.7278%, Training Loss: 0.0440%\n",
      "Epoch [112/300], Step [184/225], Training Accuracy: 98.7262%, Training Loss: 0.0440%\n",
      "Epoch [112/300], Step [185/225], Training Accuracy: 98.7247%, Training Loss: 0.0439%\n",
      "Epoch [112/300], Step [186/225], Training Accuracy: 98.7315%, Training Loss: 0.0438%\n",
      "Epoch [112/300], Step [187/225], Training Accuracy: 98.7299%, Training Loss: 0.0440%\n",
      "Epoch [112/300], Step [188/225], Training Accuracy: 98.7284%, Training Loss: 0.0440%\n",
      "Epoch [112/300], Step [189/225], Training Accuracy: 98.7351%, Training Loss: 0.0439%\n",
      "Epoch [112/300], Step [190/225], Training Accuracy: 98.7418%, Training Loss: 0.0438%\n",
      "Epoch [112/300], Step [191/225], Training Accuracy: 98.7402%, Training Loss: 0.0437%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [112/300], Step [192/225], Training Accuracy: 98.7386%, Training Loss: 0.0438%\n",
      "Epoch [112/300], Step [193/225], Training Accuracy: 98.7370%, Training Loss: 0.0438%\n",
      "Epoch [112/300], Step [194/225], Training Accuracy: 98.7436%, Training Loss: 0.0437%\n",
      "Epoch [112/300], Step [195/225], Training Accuracy: 98.7420%, Training Loss: 0.0441%\n",
      "Epoch [112/300], Step [196/225], Training Accuracy: 98.7484%, Training Loss: 0.0439%\n",
      "Epoch [112/300], Step [197/225], Training Accuracy: 98.7548%, Training Loss: 0.0438%\n",
      "Epoch [112/300], Step [198/225], Training Accuracy: 98.7532%, Training Loss: 0.0440%\n",
      "Epoch [112/300], Step [199/225], Training Accuracy: 98.7516%, Training Loss: 0.0440%\n",
      "Epoch [112/300], Step [200/225], Training Accuracy: 98.7578%, Training Loss: 0.0439%\n",
      "Epoch [112/300], Step [201/225], Training Accuracy: 98.7562%, Training Loss: 0.0439%\n",
      "Epoch [112/300], Step [202/225], Training Accuracy: 98.7546%, Training Loss: 0.0439%\n",
      "Epoch [112/300], Step [203/225], Training Accuracy: 98.7608%, Training Loss: 0.0439%\n",
      "Epoch [112/300], Step [204/225], Training Accuracy: 98.7669%, Training Loss: 0.0438%\n",
      "Epoch [112/300], Step [205/225], Training Accuracy: 98.7576%, Training Loss: 0.0440%\n",
      "Epoch [112/300], Step [206/225], Training Accuracy: 98.7637%, Training Loss: 0.0440%\n",
      "Epoch [112/300], Step [207/225], Training Accuracy: 98.7621%, Training Loss: 0.0439%\n",
      "Epoch [112/300], Step [208/225], Training Accuracy: 98.7680%, Training Loss: 0.0438%\n",
      "Epoch [112/300], Step [209/225], Training Accuracy: 98.7664%, Training Loss: 0.0439%\n",
      "Epoch [112/300], Step [210/225], Training Accuracy: 98.7649%, Training Loss: 0.0438%\n",
      "Epoch [112/300], Step [211/225], Training Accuracy: 98.7411%, Training Loss: 0.0443%\n",
      "Epoch [112/300], Step [212/225], Training Accuracy: 98.7397%, Training Loss: 0.0443%\n",
      "Epoch [112/300], Step [213/225], Training Accuracy: 98.7456%, Training Loss: 0.0442%\n",
      "Epoch [112/300], Step [214/225], Training Accuracy: 98.7515%, Training Loss: 0.0441%\n",
      "Epoch [112/300], Step [215/225], Training Accuracy: 98.7573%, Training Loss: 0.0441%\n",
      "Epoch [112/300], Step [216/225], Training Accuracy: 98.7630%, Training Loss: 0.0439%\n",
      "Epoch [112/300], Step [217/225], Training Accuracy: 98.7687%, Training Loss: 0.0438%\n",
      "Epoch [112/300], Step [218/225], Training Accuracy: 98.7672%, Training Loss: 0.0438%\n",
      "Epoch [112/300], Step [219/225], Training Accuracy: 98.7728%, Training Loss: 0.0437%\n",
      "Epoch [112/300], Step [220/225], Training Accuracy: 98.7784%, Training Loss: 0.0436%\n",
      "Epoch [112/300], Step [221/225], Training Accuracy: 98.7839%, Training Loss: 0.0436%\n",
      "Epoch [112/300], Step [222/225], Training Accuracy: 98.7753%, Training Loss: 0.0439%\n",
      "Epoch [112/300], Step [223/225], Training Accuracy: 98.7808%, Training Loss: 0.0438%\n",
      "Epoch [112/300], Step [224/225], Training Accuracy: 98.7723%, Training Loss: 0.0438%\n",
      "Epoch [112/300], Step [225/225], Training Accuracy: 98.7771%, Training Loss: 0.0437%\n",
      "Epoch [113/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0307%\n",
      "Epoch [113/300], Step [2/225], Training Accuracy: 97.6562%, Training Loss: 0.0495%\n",
      "Epoch [113/300], Step [3/225], Training Accuracy: 97.9167%, Training Loss: 0.0508%\n",
      "Epoch [113/300], Step [4/225], Training Accuracy: 98.4375%, Training Loss: 0.0474%\n",
      "Epoch [113/300], Step [5/225], Training Accuracy: 98.7500%, Training Loss: 0.0416%\n",
      "Epoch [113/300], Step [6/225], Training Accuracy: 98.9583%, Training Loss: 0.0368%\n",
      "Epoch [113/300], Step [7/225], Training Accuracy: 99.1071%, Training Loss: 0.0352%\n",
      "Epoch [113/300], Step [8/225], Training Accuracy: 99.2188%, Training Loss: 0.0335%\n",
      "Epoch [113/300], Step [9/225], Training Accuracy: 99.3056%, Training Loss: 0.0336%\n",
      "Epoch [113/300], Step [10/225], Training Accuracy: 99.0625%, Training Loss: 0.0396%\n",
      "Epoch [113/300], Step [11/225], Training Accuracy: 98.8636%, Training Loss: 0.0406%\n",
      "Epoch [113/300], Step [12/225], Training Accuracy: 98.5677%, Training Loss: 0.0445%\n",
      "Epoch [113/300], Step [13/225], Training Accuracy: 98.6779%, Training Loss: 0.0436%\n",
      "Epoch [113/300], Step [14/225], Training Accuracy: 98.6607%, Training Loss: 0.0441%\n",
      "Epoch [113/300], Step [15/225], Training Accuracy: 98.7500%, Training Loss: 0.0426%\n",
      "Epoch [113/300], Step [16/225], Training Accuracy: 98.8281%, Training Loss: 0.0414%\n",
      "Epoch [113/300], Step [17/225], Training Accuracy: 98.7132%, Training Loss: 0.0426%\n",
      "Epoch [113/300], Step [18/225], Training Accuracy: 98.6111%, Training Loss: 0.0437%\n",
      "Epoch [113/300], Step [19/225], Training Accuracy: 98.6842%, Training Loss: 0.0429%\n",
      "Epoch [113/300], Step [20/225], Training Accuracy: 98.6719%, Training Loss: 0.0426%\n",
      "Epoch [113/300], Step [21/225], Training Accuracy: 98.7351%, Training Loss: 0.0413%\n",
      "Epoch [113/300], Step [22/225], Training Accuracy: 98.7216%, Training Loss: 0.0410%\n",
      "Epoch [113/300], Step [23/225], Training Accuracy: 98.7092%, Training Loss: 0.0410%\n",
      "Epoch [113/300], Step [24/225], Training Accuracy: 98.6979%, Training Loss: 0.0424%\n",
      "Epoch [113/300], Step [25/225], Training Accuracy: 98.6875%, Training Loss: 0.0422%\n",
      "Epoch [113/300], Step [26/225], Training Accuracy: 98.7380%, Training Loss: 0.0418%\n",
      "Epoch [113/300], Step [27/225], Training Accuracy: 98.7847%, Training Loss: 0.0410%\n",
      "Epoch [113/300], Step [28/225], Training Accuracy: 98.8281%, Training Loss: 0.0399%\n",
      "Epoch [113/300], Step [29/225], Training Accuracy: 98.8685%, Training Loss: 0.0399%\n",
      "Epoch [113/300], Step [30/225], Training Accuracy: 98.6979%, Training Loss: 0.0423%\n",
      "Epoch [113/300], Step [31/225], Training Accuracy: 98.7399%, Training Loss: 0.0416%\n",
      "Epoch [113/300], Step [32/225], Training Accuracy: 98.7305%, Training Loss: 0.0413%\n",
      "Epoch [113/300], Step [33/225], Training Accuracy: 98.7689%, Training Loss: 0.0406%\n",
      "Epoch [113/300], Step [34/225], Training Accuracy: 98.8051%, Training Loss: 0.0402%\n",
      "Epoch [113/300], Step [35/225], Training Accuracy: 98.7946%, Training Loss: 0.0400%\n",
      "Epoch [113/300], Step [36/225], Training Accuracy: 98.8281%, Training Loss: 0.0395%\n",
      "Epoch [113/300], Step [37/225], Training Accuracy: 98.8598%, Training Loss: 0.0386%\n",
      "Epoch [113/300], Step [38/225], Training Accuracy: 98.8487%, Training Loss: 0.0386%\n",
      "Epoch [113/300], Step [39/225], Training Accuracy: 98.7981%, Training Loss: 0.0398%\n",
      "Epoch [113/300], Step [40/225], Training Accuracy: 98.7891%, Training Loss: 0.0396%\n",
      "Epoch [113/300], Step [41/225], Training Accuracy: 98.7424%, Training Loss: 0.0399%\n",
      "Epoch [113/300], Step [42/225], Training Accuracy: 98.7351%, Training Loss: 0.0406%\n",
      "Epoch [113/300], Step [43/225], Training Accuracy: 98.7282%, Training Loss: 0.0405%\n",
      "Epoch [113/300], Step [44/225], Training Accuracy: 98.7571%, Training Loss: 0.0400%\n",
      "Epoch [113/300], Step [45/225], Training Accuracy: 98.7847%, Training Loss: 0.0397%\n",
      "Epoch [113/300], Step [46/225], Training Accuracy: 98.8111%, Training Loss: 0.0400%\n",
      "Epoch [113/300], Step [47/225], Training Accuracy: 98.8364%, Training Loss: 0.0396%\n",
      "Epoch [113/300], Step [48/225], Training Accuracy: 98.8281%, Training Loss: 0.0400%\n",
      "Epoch [113/300], Step [49/225], Training Accuracy: 98.8520%, Training Loss: 0.0396%\n",
      "Epoch [113/300], Step [50/225], Training Accuracy: 98.8438%, Training Loss: 0.0399%\n",
      "Epoch [113/300], Step [51/225], Training Accuracy: 98.8664%, Training Loss: 0.0396%\n",
      "Epoch [113/300], Step [52/225], Training Accuracy: 98.8582%, Training Loss: 0.0398%\n",
      "Epoch [113/300], Step [53/225], Training Accuracy: 98.8208%, Training Loss: 0.0404%\n",
      "Epoch [113/300], Step [54/225], Training Accuracy: 98.8137%, Training Loss: 0.0401%\n",
      "Epoch [113/300], Step [55/225], Training Accuracy: 98.8352%, Training Loss: 0.0397%\n",
      "Epoch [113/300], Step [56/225], Training Accuracy: 98.8002%, Training Loss: 0.0403%\n",
      "Epoch [113/300], Step [57/225], Training Accuracy: 98.8213%, Training Loss: 0.0400%\n",
      "Epoch [113/300], Step [58/225], Training Accuracy: 98.7877%, Training Loss: 0.0401%\n",
      "Epoch [113/300], Step [59/225], Training Accuracy: 98.7553%, Training Loss: 0.0406%\n",
      "Epoch [113/300], Step [60/225], Training Accuracy: 98.7240%, Training Loss: 0.0409%\n",
      "Epoch [113/300], Step [61/225], Training Accuracy: 98.6680%, Training Loss: 0.0427%\n",
      "Epoch [113/300], Step [62/225], Training Accuracy: 98.6643%, Training Loss: 0.0427%\n",
      "Epoch [113/300], Step [63/225], Training Accuracy: 98.6855%, Training Loss: 0.0425%\n",
      "Epoch [113/300], Step [64/225], Training Accuracy: 98.7061%, Training Loss: 0.0422%\n",
      "Epoch [113/300], Step [65/225], Training Accuracy: 98.7019%, Training Loss: 0.0423%\n",
      "Epoch [113/300], Step [66/225], Training Accuracy: 98.6979%, Training Loss: 0.0426%\n",
      "Epoch [113/300], Step [67/225], Training Accuracy: 98.7174%, Training Loss: 0.0428%\n",
      "Epoch [113/300], Step [68/225], Training Accuracy: 98.7132%, Training Loss: 0.0431%\n",
      "Epoch [113/300], Step [69/225], Training Accuracy: 98.7092%, Training Loss: 0.0428%\n",
      "Epoch [113/300], Step [70/225], Training Accuracy: 98.7054%, Training Loss: 0.0428%\n",
      "Epoch [113/300], Step [71/225], Training Accuracy: 98.6356%, Training Loss: 0.0433%\n",
      "Epoch [113/300], Step [72/225], Training Accuracy: 98.6111%, Training Loss: 0.0436%\n",
      "Epoch [113/300], Step [73/225], Training Accuracy: 98.5873%, Training Loss: 0.0441%\n",
      "Epoch [113/300], Step [74/225], Training Accuracy: 98.5853%, Training Loss: 0.0444%\n",
      "Epoch [113/300], Step [75/225], Training Accuracy: 98.6042%, Training Loss: 0.0440%\n",
      "Epoch [113/300], Step [76/225], Training Accuracy: 98.5814%, Training Loss: 0.0445%\n",
      "Epoch [113/300], Step [77/225], Training Accuracy: 98.5795%, Training Loss: 0.0447%\n",
      "Epoch [113/300], Step [78/225], Training Accuracy: 98.5978%, Training Loss: 0.0445%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [113/300], Step [79/225], Training Accuracy: 98.5957%, Training Loss: 0.0444%\n",
      "Epoch [113/300], Step [80/225], Training Accuracy: 98.5938%, Training Loss: 0.0444%\n",
      "Epoch [113/300], Step [81/225], Training Accuracy: 98.5918%, Training Loss: 0.0442%\n",
      "Epoch [113/300], Step [82/225], Training Accuracy: 98.6090%, Training Loss: 0.0439%\n",
      "Epoch [113/300], Step [83/225], Training Accuracy: 98.6258%, Training Loss: 0.0435%\n",
      "Epoch [113/300], Step [84/225], Training Accuracy: 98.5863%, Training Loss: 0.0439%\n",
      "Epoch [113/300], Step [85/225], Training Accuracy: 98.5846%, Training Loss: 0.0440%\n",
      "Epoch [113/300], Step [86/225], Training Accuracy: 98.5647%, Training Loss: 0.0442%\n",
      "Epoch [113/300], Step [87/225], Training Accuracy: 98.5812%, Training Loss: 0.0440%\n",
      "Epoch [113/300], Step [88/225], Training Accuracy: 98.5973%, Training Loss: 0.0438%\n",
      "Epoch [113/300], Step [89/225], Training Accuracy: 98.6131%, Training Loss: 0.0437%\n",
      "Epoch [113/300], Step [90/225], Training Accuracy: 98.5938%, Training Loss: 0.0453%\n",
      "Epoch [113/300], Step [91/225], Training Accuracy: 98.5920%, Training Loss: 0.0457%\n",
      "Epoch [113/300], Step [92/225], Training Accuracy: 98.6073%, Training Loss: 0.0454%\n",
      "Epoch [113/300], Step [93/225], Training Accuracy: 98.5719%, Training Loss: 0.0456%\n",
      "Epoch [113/300], Step [94/225], Training Accuracy: 98.5539%, Training Loss: 0.0456%\n",
      "Epoch [113/300], Step [95/225], Training Accuracy: 98.5526%, Training Loss: 0.0455%\n",
      "Epoch [113/300], Step [96/225], Training Accuracy: 98.5352%, Training Loss: 0.0457%\n",
      "Epoch [113/300], Step [97/225], Training Accuracy: 98.5341%, Training Loss: 0.0461%\n",
      "Epoch [113/300], Step [98/225], Training Accuracy: 98.4694%, Training Loss: 0.0476%\n",
      "Epoch [113/300], Step [99/225], Training Accuracy: 98.4848%, Training Loss: 0.0473%\n",
      "Epoch [113/300], Step [100/225], Training Accuracy: 98.5000%, Training Loss: 0.0470%\n",
      "Epoch [113/300], Step [101/225], Training Accuracy: 98.5149%, Training Loss: 0.0467%\n",
      "Epoch [113/300], Step [102/225], Training Accuracy: 98.5294%, Training Loss: 0.0467%\n",
      "Epoch [113/300], Step [103/225], Training Accuracy: 98.5285%, Training Loss: 0.0467%\n",
      "Epoch [113/300], Step [104/225], Training Accuracy: 98.5276%, Training Loss: 0.0467%\n",
      "Epoch [113/300], Step [105/225], Training Accuracy: 98.5417%, Training Loss: 0.0465%\n",
      "Epoch [113/300], Step [106/225], Training Accuracy: 98.5554%, Training Loss: 0.0464%\n",
      "Epoch [113/300], Step [107/225], Training Accuracy: 98.5543%, Training Loss: 0.0463%\n",
      "Epoch [113/300], Step [108/225], Training Accuracy: 98.5532%, Training Loss: 0.0464%\n",
      "Epoch [113/300], Step [109/225], Training Accuracy: 98.5522%, Training Loss: 0.0468%\n",
      "Epoch [113/300], Step [110/225], Training Accuracy: 98.5511%, Training Loss: 0.0468%\n",
      "Epoch [113/300], Step [111/225], Training Accuracy: 98.5501%, Training Loss: 0.0468%\n",
      "Epoch [113/300], Step [112/225], Training Accuracy: 98.5491%, Training Loss: 0.0469%\n",
      "Epoch [113/300], Step [113/225], Training Accuracy: 98.5619%, Training Loss: 0.0466%\n",
      "Epoch [113/300], Step [114/225], Training Accuracy: 98.5609%, Training Loss: 0.0467%\n",
      "Epoch [113/300], Step [115/225], Training Accuracy: 98.5734%, Training Loss: 0.0464%\n",
      "Epoch [113/300], Step [116/225], Training Accuracy: 98.5857%, Training Loss: 0.0462%\n",
      "Epoch [113/300], Step [117/225], Training Accuracy: 98.5978%, Training Loss: 0.0458%\n",
      "Epoch [113/300], Step [118/225], Training Accuracy: 98.5964%, Training Loss: 0.0457%\n",
      "Epoch [113/300], Step [119/225], Training Accuracy: 98.6082%, Training Loss: 0.0455%\n",
      "Epoch [113/300], Step [120/225], Training Accuracy: 98.6198%, Training Loss: 0.0453%\n",
      "Epoch [113/300], Step [121/225], Training Accuracy: 98.6312%, Training Loss: 0.0450%\n",
      "Epoch [113/300], Step [122/225], Training Accuracy: 98.6424%, Training Loss: 0.0448%\n",
      "Epoch [113/300], Step [123/225], Training Accuracy: 98.6408%, Training Loss: 0.0448%\n",
      "Epoch [113/300], Step [124/225], Training Accuracy: 98.6391%, Training Loss: 0.0448%\n",
      "Epoch [113/300], Step [125/225], Training Accuracy: 98.6500%, Training Loss: 0.0445%\n",
      "Epoch [113/300], Step [126/225], Training Accuracy: 98.6607%, Training Loss: 0.0443%\n",
      "Epoch [113/300], Step [127/225], Training Accuracy: 98.6590%, Training Loss: 0.0444%\n",
      "Epoch [113/300], Step [128/225], Training Accuracy: 98.6328%, Training Loss: 0.0445%\n",
      "Epoch [113/300], Step [129/225], Training Accuracy: 98.6434%, Training Loss: 0.0443%\n",
      "Epoch [113/300], Step [130/225], Training Accuracy: 98.6538%, Training Loss: 0.0441%\n",
      "Epoch [113/300], Step [131/225], Training Accuracy: 98.6641%, Training Loss: 0.0439%\n",
      "Epoch [113/300], Step [132/225], Training Accuracy: 98.6742%, Training Loss: 0.0438%\n",
      "Epoch [113/300], Step [133/225], Training Accuracy: 98.6842%, Training Loss: 0.0436%\n",
      "Epoch [113/300], Step [134/225], Training Accuracy: 98.6940%, Training Loss: 0.0434%\n",
      "Epoch [113/300], Step [135/225], Training Accuracy: 98.7037%, Training Loss: 0.0433%\n",
      "Epoch [113/300], Step [136/225], Training Accuracy: 98.6788%, Training Loss: 0.0439%\n",
      "Epoch [113/300], Step [137/225], Training Accuracy: 98.6884%, Training Loss: 0.0438%\n",
      "Epoch [113/300], Step [138/225], Training Accuracy: 98.6753%, Training Loss: 0.0440%\n",
      "Epoch [113/300], Step [139/225], Training Accuracy: 98.6623%, Training Loss: 0.0441%\n",
      "Epoch [113/300], Step [140/225], Training Accuracy: 98.6719%, Training Loss: 0.0439%\n",
      "Epoch [113/300], Step [141/225], Training Accuracy: 98.6813%, Training Loss: 0.0437%\n",
      "Epoch [113/300], Step [142/225], Training Accuracy: 98.6906%, Training Loss: 0.0436%\n",
      "Epoch [113/300], Step [143/225], Training Accuracy: 98.6997%, Training Loss: 0.0436%\n",
      "Epoch [113/300], Step [144/225], Training Accuracy: 98.6979%, Training Loss: 0.0437%\n",
      "Epoch [113/300], Step [145/225], Training Accuracy: 98.6853%, Training Loss: 0.0439%\n",
      "Epoch [113/300], Step [146/225], Training Accuracy: 98.6729%, Training Loss: 0.0440%\n",
      "Epoch [113/300], Step [147/225], Training Accuracy: 98.6607%, Training Loss: 0.0442%\n",
      "Epoch [113/300], Step [148/225], Training Accuracy: 98.6592%, Training Loss: 0.0442%\n",
      "Epoch [113/300], Step [149/225], Training Accuracy: 98.6682%, Training Loss: 0.0441%\n",
      "Epoch [113/300], Step [150/225], Training Accuracy: 98.6667%, Training Loss: 0.0441%\n",
      "Epoch [113/300], Step [151/225], Training Accuracy: 98.6755%, Training Loss: 0.0439%\n",
      "Epoch [113/300], Step [152/225], Training Accuracy: 98.6739%, Training Loss: 0.0439%\n",
      "Epoch [113/300], Step [153/225], Training Accuracy: 98.6724%, Training Loss: 0.0437%\n",
      "Epoch [113/300], Step [154/225], Training Accuracy: 98.6709%, Training Loss: 0.0438%\n",
      "Epoch [113/300], Step [155/225], Training Accuracy: 98.6794%, Training Loss: 0.0438%\n",
      "Epoch [113/300], Step [156/225], Training Accuracy: 98.6779%, Training Loss: 0.0436%\n",
      "Epoch [113/300], Step [157/225], Training Accuracy: 98.6764%, Training Loss: 0.0438%\n",
      "Epoch [113/300], Step [158/225], Training Accuracy: 98.6748%, Training Loss: 0.0438%\n",
      "Epoch [113/300], Step [159/225], Training Accuracy: 98.6832%, Training Loss: 0.0437%\n",
      "Epoch [113/300], Step [160/225], Training Accuracy: 98.6816%, Training Loss: 0.0437%\n",
      "Epoch [113/300], Step [161/225], Training Accuracy: 98.6898%, Training Loss: 0.0436%\n",
      "Epoch [113/300], Step [162/225], Training Accuracy: 98.6786%, Training Loss: 0.0438%\n",
      "Epoch [113/300], Step [163/225], Training Accuracy: 98.6484%, Training Loss: 0.0443%\n",
      "Epoch [113/300], Step [164/225], Training Accuracy: 98.6471%, Training Loss: 0.0442%\n",
      "Epoch [113/300], Step [165/225], Training Accuracy: 98.6458%, Training Loss: 0.0442%\n",
      "Epoch [113/300], Step [166/225], Training Accuracy: 98.6540%, Training Loss: 0.0441%\n",
      "Epoch [113/300], Step [167/225], Training Accuracy: 98.6527%, Training Loss: 0.0440%\n",
      "Epoch [113/300], Step [168/225], Training Accuracy: 98.6514%, Training Loss: 0.0441%\n",
      "Epoch [113/300], Step [169/225], Training Accuracy: 98.6594%, Training Loss: 0.0439%\n",
      "Epoch [113/300], Step [170/225], Training Accuracy: 98.6581%, Training Loss: 0.0442%\n",
      "Epoch [113/300], Step [171/225], Training Accuracy: 98.6568%, Training Loss: 0.0444%\n",
      "Epoch [113/300], Step [172/225], Training Accuracy: 98.6464%, Training Loss: 0.0445%\n",
      "Epoch [113/300], Step [173/225], Training Accuracy: 98.6362%, Training Loss: 0.0447%\n",
      "Epoch [113/300], Step [174/225], Training Accuracy: 98.6440%, Training Loss: 0.0445%\n",
      "Epoch [113/300], Step [175/225], Training Accuracy: 98.6518%, Training Loss: 0.0443%\n",
      "Epoch [113/300], Step [176/225], Training Accuracy: 98.6506%, Training Loss: 0.0444%\n",
      "Epoch [113/300], Step [177/225], Training Accuracy: 98.6582%, Training Loss: 0.0443%\n",
      "Epoch [113/300], Step [178/225], Training Accuracy: 98.6657%, Training Loss: 0.0442%\n",
      "Epoch [113/300], Step [179/225], Training Accuracy: 98.6645%, Training Loss: 0.0442%\n",
      "Epoch [113/300], Step [180/225], Training Accuracy: 98.6719%, Training Loss: 0.0440%\n",
      "Epoch [113/300], Step [181/225], Training Accuracy: 98.6792%, Training Loss: 0.0439%\n",
      "Epoch [113/300], Step [182/225], Training Accuracy: 98.6779%, Training Loss: 0.0439%\n",
      "Epoch [113/300], Step [183/225], Training Accuracy: 98.6851%, Training Loss: 0.0436%\n",
      "Epoch [113/300], Step [184/225], Training Accuracy: 98.6753%, Training Loss: 0.0438%\n",
      "Epoch [113/300], Step [185/225], Training Accuracy: 98.6740%, Training Loss: 0.0438%\n",
      "Epoch [113/300], Step [186/225], Training Accuracy: 98.6811%, Training Loss: 0.0437%\n",
      "Epoch [113/300], Step [187/225], Training Accuracy: 98.6547%, Training Loss: 0.0440%\n",
      "Epoch [113/300], Step [188/225], Training Accuracy: 98.6536%, Training Loss: 0.0441%\n",
      "Epoch [113/300], Step [189/225], Training Accuracy: 98.6607%, Training Loss: 0.0439%\n",
      "Epoch [113/300], Step [190/225], Training Accuracy: 98.6595%, Training Loss: 0.0441%\n",
      "Epoch [113/300], Step [191/225], Training Accuracy: 98.6666%, Training Loss: 0.0440%\n",
      "Epoch [113/300], Step [192/225], Training Accuracy: 98.6572%, Training Loss: 0.0442%\n",
      "Epoch [113/300], Step [193/225], Training Accuracy: 98.6642%, Training Loss: 0.0443%\n",
      "Epoch [113/300], Step [194/225], Training Accuracy: 98.6630%, Training Loss: 0.0442%\n",
      "Epoch [113/300], Step [195/225], Training Accuracy: 98.6538%, Training Loss: 0.0442%\n",
      "Epoch [113/300], Step [196/225], Training Accuracy: 98.6527%, Training Loss: 0.0442%\n",
      "Epoch [113/300], Step [197/225], Training Accuracy: 98.6516%, Training Loss: 0.0443%\n",
      "Epoch [113/300], Step [198/225], Training Accuracy: 98.6585%, Training Loss: 0.0443%\n",
      "Epoch [113/300], Step [199/225], Training Accuracy: 98.6652%, Training Loss: 0.0442%\n",
      "Epoch [113/300], Step [200/225], Training Accuracy: 98.6641%, Training Loss: 0.0442%\n",
      "Epoch [113/300], Step [201/225], Training Accuracy: 98.6707%, Training Loss: 0.0441%\n",
      "Epoch [113/300], Step [202/225], Training Accuracy: 98.6773%, Training Loss: 0.0440%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [113/300], Step [203/225], Training Accuracy: 98.6761%, Training Loss: 0.0439%\n",
      "Epoch [113/300], Step [204/225], Training Accuracy: 98.6826%, Training Loss: 0.0438%\n",
      "Epoch [113/300], Step [205/225], Training Accuracy: 98.6738%, Training Loss: 0.0439%\n",
      "Epoch [113/300], Step [206/225], Training Accuracy: 98.6726%, Training Loss: 0.0441%\n",
      "Epoch [113/300], Step [207/225], Training Accuracy: 98.6790%, Training Loss: 0.0439%\n",
      "Epoch [113/300], Step [208/225], Training Accuracy: 98.6779%, Training Loss: 0.0439%\n",
      "Epoch [113/300], Step [209/225], Training Accuracy: 98.6842%, Training Loss: 0.0438%\n",
      "Epoch [113/300], Step [210/225], Training Accuracy: 98.6830%, Training Loss: 0.0440%\n",
      "Epoch [113/300], Step [211/225], Training Accuracy: 98.6893%, Training Loss: 0.0439%\n",
      "Epoch [113/300], Step [212/225], Training Accuracy: 98.6881%, Training Loss: 0.0439%\n",
      "Epoch [113/300], Step [213/225], Training Accuracy: 98.6869%, Training Loss: 0.0440%\n",
      "Epoch [113/300], Step [214/225], Training Accuracy: 98.6930%, Training Loss: 0.0439%\n",
      "Epoch [113/300], Step [215/225], Training Accuracy: 98.6919%, Training Loss: 0.0439%\n",
      "Epoch [113/300], Step [216/225], Training Accuracy: 98.6907%, Training Loss: 0.0441%\n",
      "Epoch [113/300], Step [217/225], Training Accuracy: 98.6823%, Training Loss: 0.0441%\n",
      "Epoch [113/300], Step [218/225], Training Accuracy: 98.6812%, Training Loss: 0.0441%\n",
      "Epoch [113/300], Step [219/225], Training Accuracy: 98.6872%, Training Loss: 0.0440%\n",
      "Epoch [113/300], Step [220/225], Training Accuracy: 98.6861%, Training Loss: 0.0440%\n",
      "Epoch [113/300], Step [221/225], Training Accuracy: 98.6708%, Training Loss: 0.0442%\n",
      "Epoch [113/300], Step [222/225], Training Accuracy: 98.6627%, Training Loss: 0.0443%\n",
      "Epoch [113/300], Step [223/225], Training Accuracy: 98.6547%, Training Loss: 0.0448%\n",
      "Epoch [113/300], Step [224/225], Training Accuracy: 98.6468%, Training Loss: 0.0449%\n",
      "Epoch [113/300], Step [225/225], Training Accuracy: 98.6451%, Training Loss: 0.0450%\n",
      "Epoch [114/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0280%\n",
      "Epoch [114/300], Step [2/225], Training Accuracy: 97.6562%, Training Loss: 0.0520%\n",
      "Epoch [114/300], Step [3/225], Training Accuracy: 97.9167%, Training Loss: 0.0501%\n",
      "Epoch [114/300], Step [4/225], Training Accuracy: 98.0469%, Training Loss: 0.0592%\n",
      "Epoch [114/300], Step [5/225], Training Accuracy: 98.4375%, Training Loss: 0.0514%\n",
      "Epoch [114/300], Step [6/225], Training Accuracy: 98.4375%, Training Loss: 0.0519%\n",
      "Epoch [114/300], Step [7/225], Training Accuracy: 98.6607%, Training Loss: 0.0456%\n",
      "Epoch [114/300], Step [8/225], Training Accuracy: 98.8281%, Training Loss: 0.0435%\n",
      "Epoch [114/300], Step [9/225], Training Accuracy: 98.7847%, Training Loss: 0.0435%\n",
      "Epoch [114/300], Step [10/225], Training Accuracy: 98.7500%, Training Loss: 0.0444%\n",
      "Epoch [114/300], Step [11/225], Training Accuracy: 98.8636%, Training Loss: 0.0435%\n",
      "Epoch [114/300], Step [12/225], Training Accuracy: 98.8281%, Training Loss: 0.0431%\n",
      "Epoch [114/300], Step [13/225], Training Accuracy: 98.9183%, Training Loss: 0.0432%\n",
      "Epoch [114/300], Step [14/225], Training Accuracy: 98.9955%, Training Loss: 0.0425%\n",
      "Epoch [114/300], Step [15/225], Training Accuracy: 99.0625%, Training Loss: 0.0418%\n",
      "Epoch [114/300], Step [16/225], Training Accuracy: 98.7305%, Training Loss: 0.0490%\n",
      "Epoch [114/300], Step [17/225], Training Accuracy: 98.7132%, Training Loss: 0.0480%\n",
      "Epoch [114/300], Step [18/225], Training Accuracy: 98.6111%, Training Loss: 0.0510%\n",
      "Epoch [114/300], Step [19/225], Training Accuracy: 98.6020%, Training Loss: 0.0499%\n",
      "Epoch [114/300], Step [20/225], Training Accuracy: 98.5156%, Training Loss: 0.0503%\n",
      "Epoch [114/300], Step [21/225], Training Accuracy: 98.5863%, Training Loss: 0.0491%\n",
      "Epoch [114/300], Step [22/225], Training Accuracy: 98.3665%, Training Loss: 0.0506%\n",
      "Epoch [114/300], Step [23/225], Training Accuracy: 98.3016%, Training Loss: 0.0503%\n",
      "Epoch [114/300], Step [24/225], Training Accuracy: 98.3724%, Training Loss: 0.0510%\n",
      "Epoch [114/300], Step [25/225], Training Accuracy: 98.4375%, Training Loss: 0.0499%\n",
      "Epoch [114/300], Step [26/225], Training Accuracy: 98.4375%, Training Loss: 0.0496%\n",
      "Epoch [114/300], Step [27/225], Training Accuracy: 98.3796%, Training Loss: 0.0501%\n",
      "Epoch [114/300], Step [28/225], Training Accuracy: 98.3259%, Training Loss: 0.0505%\n",
      "Epoch [114/300], Step [29/225], Training Accuracy: 98.3297%, Training Loss: 0.0504%\n",
      "Epoch [114/300], Step [30/225], Training Accuracy: 98.3333%, Training Loss: 0.0509%\n",
      "Epoch [114/300], Step [31/225], Training Accuracy: 98.3871%, Training Loss: 0.0499%\n",
      "Epoch [114/300], Step [32/225], Training Accuracy: 98.2910%, Training Loss: 0.0517%\n",
      "Epoch [114/300], Step [33/225], Training Accuracy: 98.3428%, Training Loss: 0.0505%\n",
      "Epoch [114/300], Step [34/225], Training Accuracy: 98.3456%, Training Loss: 0.0513%\n",
      "Epoch [114/300], Step [35/225], Training Accuracy: 98.3482%, Training Loss: 0.0510%\n",
      "Epoch [114/300], Step [36/225], Training Accuracy: 98.3507%, Training Loss: 0.0503%\n",
      "Epoch [114/300], Step [37/225], Training Accuracy: 98.3530%, Training Loss: 0.0497%\n",
      "Epoch [114/300], Step [38/225], Training Accuracy: 98.2730%, Training Loss: 0.0517%\n",
      "Epoch [114/300], Step [39/225], Training Accuracy: 98.3173%, Training Loss: 0.0519%\n",
      "Epoch [114/300], Step [40/225], Training Accuracy: 98.2812%, Training Loss: 0.0527%\n",
      "Epoch [114/300], Step [41/225], Training Accuracy: 98.2851%, Training Loss: 0.0523%\n",
      "Epoch [114/300], Step [42/225], Training Accuracy: 98.2887%, Training Loss: 0.0518%\n",
      "Epoch [114/300], Step [43/225], Training Accuracy: 98.2195%, Training Loss: 0.0532%\n",
      "Epoch [114/300], Step [44/225], Training Accuracy: 98.2599%, Training Loss: 0.0527%\n",
      "Epoch [114/300], Step [45/225], Training Accuracy: 98.2639%, Training Loss: 0.0525%\n",
      "Epoch [114/300], Step [46/225], Training Accuracy: 98.2677%, Training Loss: 0.0525%\n",
      "Epoch [114/300], Step [47/225], Training Accuracy: 98.2713%, Training Loss: 0.0527%\n",
      "Epoch [114/300], Step [48/225], Training Accuracy: 98.2747%, Training Loss: 0.0529%\n",
      "Epoch [114/300], Step [49/225], Training Accuracy: 98.2462%, Training Loss: 0.0544%\n",
      "Epoch [114/300], Step [50/225], Training Accuracy: 98.2500%, Training Loss: 0.0541%\n",
      "Epoch [114/300], Step [51/225], Training Accuracy: 98.2843%, Training Loss: 0.0537%\n",
      "Epoch [114/300], Step [52/225], Training Accuracy: 98.2572%, Training Loss: 0.0540%\n",
      "Epoch [114/300], Step [53/225], Training Accuracy: 98.2606%, Training Loss: 0.0535%\n",
      "Epoch [114/300], Step [54/225], Training Accuracy: 98.2350%, Training Loss: 0.0542%\n",
      "Epoch [114/300], Step [55/225], Training Accuracy: 98.2102%, Training Loss: 0.0552%\n",
      "Epoch [114/300], Step [56/225], Training Accuracy: 98.2143%, Training Loss: 0.0550%\n",
      "Epoch [114/300], Step [57/225], Training Accuracy: 98.2182%, Training Loss: 0.0546%\n",
      "Epoch [114/300], Step [58/225], Training Accuracy: 98.2489%, Training Loss: 0.0539%\n",
      "Epoch [114/300], Step [59/225], Training Accuracy: 98.2521%, Training Loss: 0.0535%\n",
      "Epoch [114/300], Step [60/225], Training Accuracy: 98.2552%, Training Loss: 0.0539%\n",
      "Epoch [114/300], Step [61/225], Training Accuracy: 98.2582%, Training Loss: 0.0539%\n",
      "Epoch [114/300], Step [62/225], Training Accuracy: 98.2863%, Training Loss: 0.0536%\n",
      "Epoch [114/300], Step [63/225], Training Accuracy: 98.2639%, Training Loss: 0.0540%\n",
      "Epoch [114/300], Step [64/225], Training Accuracy: 98.2422%, Training Loss: 0.0543%\n",
      "Epoch [114/300], Step [65/225], Training Accuracy: 98.2692%, Training Loss: 0.0538%\n",
      "Epoch [114/300], Step [66/225], Training Accuracy: 98.2244%, Training Loss: 0.0543%\n",
      "Epoch [114/300], Step [67/225], Training Accuracy: 98.2509%, Training Loss: 0.0540%\n",
      "Epoch [114/300], Step [68/225], Training Accuracy: 98.2307%, Training Loss: 0.0539%\n",
      "Epoch [114/300], Step [69/225], Training Accuracy: 98.2563%, Training Loss: 0.0534%\n",
      "Epoch [114/300], Step [70/225], Training Accuracy: 98.2812%, Training Loss: 0.0531%\n",
      "Epoch [114/300], Step [71/225], Training Accuracy: 98.2394%, Training Loss: 0.0540%\n",
      "Epoch [114/300], Step [72/225], Training Accuracy: 98.2639%, Training Loss: 0.0536%\n",
      "Epoch [114/300], Step [73/225], Training Accuracy: 98.2877%, Training Loss: 0.0534%\n",
      "Epoch [114/300], Step [74/225], Training Accuracy: 98.3108%, Training Loss: 0.0531%\n",
      "Epoch [114/300], Step [75/225], Training Accuracy: 98.3125%, Training Loss: 0.0535%\n",
      "Epoch [114/300], Step [76/225], Training Accuracy: 98.3141%, Training Loss: 0.0537%\n",
      "Epoch [114/300], Step [77/225], Training Accuracy: 98.3157%, Training Loss: 0.0536%\n",
      "Epoch [114/300], Step [78/225], Training Accuracy: 98.3373%, Training Loss: 0.0532%\n",
      "Epoch [114/300], Step [79/225], Training Accuracy: 98.3584%, Training Loss: 0.0528%\n",
      "Epoch [114/300], Step [80/225], Training Accuracy: 98.3594%, Training Loss: 0.0528%\n",
      "Epoch [114/300], Step [81/225], Training Accuracy: 98.3796%, Training Loss: 0.0525%\n",
      "Epoch [114/300], Step [82/225], Training Accuracy: 98.3803%, Training Loss: 0.0528%\n",
      "Epoch [114/300], Step [83/225], Training Accuracy: 98.3810%, Training Loss: 0.0526%\n",
      "Epoch [114/300], Step [84/225], Training Accuracy: 98.4003%, Training Loss: 0.0523%\n",
      "Epoch [114/300], Step [85/225], Training Accuracy: 98.4191%, Training Loss: 0.0521%\n",
      "Epoch [114/300], Step [86/225], Training Accuracy: 98.4012%, Training Loss: 0.0521%\n",
      "Epoch [114/300], Step [87/225], Training Accuracy: 98.4195%, Training Loss: 0.0518%\n",
      "Epoch [114/300], Step [88/225], Training Accuracy: 98.4375%, Training Loss: 0.0516%\n",
      "Epoch [114/300], Step [89/225], Training Accuracy: 98.4551%, Training Loss: 0.0513%\n",
      "Epoch [114/300], Step [90/225], Training Accuracy: 98.4722%, Training Loss: 0.0513%\n",
      "Epoch [114/300], Step [91/225], Training Accuracy: 98.4718%, Training Loss: 0.0513%\n",
      "Epoch [114/300], Step [92/225], Training Accuracy: 98.4715%, Training Loss: 0.0515%\n",
      "Epoch [114/300], Step [93/225], Training Accuracy: 98.4543%, Training Loss: 0.0516%\n",
      "Epoch [114/300], Step [94/225], Training Accuracy: 98.4541%, Training Loss: 0.0516%\n",
      "Epoch [114/300], Step [95/225], Training Accuracy: 98.4704%, Training Loss: 0.0513%\n",
      "Epoch [114/300], Step [96/225], Training Accuracy: 98.4701%, Training Loss: 0.0511%\n",
      "Epoch [114/300], Step [97/225], Training Accuracy: 98.4697%, Training Loss: 0.0511%\n",
      "Epoch [114/300], Step [98/225], Training Accuracy: 98.4534%, Training Loss: 0.0516%\n",
      "Epoch [114/300], Step [99/225], Training Accuracy: 98.4533%, Training Loss: 0.0514%\n",
      "Epoch [114/300], Step [100/225], Training Accuracy: 98.4688%, Training Loss: 0.0511%\n",
      "Epoch [114/300], Step [101/225], Training Accuracy: 98.4839%, Training Loss: 0.0509%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [114/300], Step [102/225], Training Accuracy: 98.4988%, Training Loss: 0.0508%\n",
      "Epoch [114/300], Step [103/225], Training Accuracy: 98.4830%, Training Loss: 0.0511%\n",
      "Epoch [114/300], Step [104/225], Training Accuracy: 98.4525%, Training Loss: 0.0517%\n",
      "Epoch [114/300], Step [105/225], Training Accuracy: 98.4673%, Training Loss: 0.0513%\n",
      "Epoch [114/300], Step [106/225], Training Accuracy: 98.4817%, Training Loss: 0.0511%\n",
      "Epoch [114/300], Step [107/225], Training Accuracy: 98.4521%, Training Loss: 0.0515%\n",
      "Epoch [114/300], Step [108/225], Training Accuracy: 98.4664%, Training Loss: 0.0513%\n",
      "Epoch [114/300], Step [109/225], Training Accuracy: 98.4662%, Training Loss: 0.0513%\n",
      "Epoch [114/300], Step [110/225], Training Accuracy: 98.4801%, Training Loss: 0.0510%\n",
      "Epoch [114/300], Step [111/225], Training Accuracy: 98.4657%, Training Loss: 0.0511%\n",
      "Epoch [114/300], Step [112/225], Training Accuracy: 98.4515%, Training Loss: 0.0513%\n",
      "Epoch [114/300], Step [113/225], Training Accuracy: 98.4513%, Training Loss: 0.0511%\n",
      "Epoch [114/300], Step [114/225], Training Accuracy: 98.4649%, Training Loss: 0.0510%\n",
      "Epoch [114/300], Step [115/225], Training Accuracy: 98.4783%, Training Loss: 0.0507%\n",
      "Epoch [114/300], Step [116/225], Training Accuracy: 98.4779%, Training Loss: 0.0507%\n",
      "Epoch [114/300], Step [117/225], Training Accuracy: 98.4776%, Training Loss: 0.0505%\n",
      "Epoch [114/300], Step [118/225], Training Accuracy: 98.4640%, Training Loss: 0.0506%\n",
      "Epoch [114/300], Step [119/225], Training Accuracy: 98.4769%, Training Loss: 0.0505%\n",
      "Epoch [114/300], Step [120/225], Training Accuracy: 98.4635%, Training Loss: 0.0509%\n",
      "Epoch [114/300], Step [121/225], Training Accuracy: 98.4633%, Training Loss: 0.0510%\n",
      "Epoch [114/300], Step [122/225], Training Accuracy: 98.4759%, Training Loss: 0.0507%\n",
      "Epoch [114/300], Step [123/225], Training Accuracy: 98.4756%, Training Loss: 0.0507%\n",
      "Epoch [114/300], Step [124/225], Training Accuracy: 98.4753%, Training Loss: 0.0506%\n",
      "Epoch [114/300], Step [125/225], Training Accuracy: 98.4875%, Training Loss: 0.0505%\n",
      "Epoch [114/300], Step [126/225], Training Accuracy: 98.4995%, Training Loss: 0.0503%\n",
      "Epoch [114/300], Step [127/225], Training Accuracy: 98.5113%, Training Loss: 0.0502%\n",
      "Epoch [114/300], Step [128/225], Training Accuracy: 98.5229%, Training Loss: 0.0499%\n",
      "Epoch [114/300], Step [129/225], Training Accuracy: 98.5102%, Training Loss: 0.0505%\n",
      "Epoch [114/300], Step [130/225], Training Accuracy: 98.5216%, Training Loss: 0.0503%\n",
      "Epoch [114/300], Step [131/225], Training Accuracy: 98.5210%, Training Loss: 0.0502%\n",
      "Epoch [114/300], Step [132/225], Training Accuracy: 98.5322%, Training Loss: 0.0502%\n",
      "Epoch [114/300], Step [133/225], Training Accuracy: 98.5315%, Training Loss: 0.0502%\n",
      "Epoch [114/300], Step [134/225], Training Accuracy: 98.5308%, Training Loss: 0.0501%\n",
      "Epoch [114/300], Step [135/225], Training Accuracy: 98.5417%, Training Loss: 0.0499%\n",
      "Epoch [114/300], Step [136/225], Training Accuracy: 98.5524%, Training Loss: 0.0497%\n",
      "Epoch [114/300], Step [137/225], Training Accuracy: 98.5401%, Training Loss: 0.0501%\n",
      "Epoch [114/300], Step [138/225], Training Accuracy: 98.5394%, Training Loss: 0.0499%\n",
      "Epoch [114/300], Step [139/225], Training Accuracy: 98.5499%, Training Loss: 0.0497%\n",
      "Epoch [114/300], Step [140/225], Training Accuracy: 98.5603%, Training Loss: 0.0496%\n",
      "Epoch [114/300], Step [141/225], Training Accuracy: 98.5705%, Training Loss: 0.0494%\n",
      "Epoch [114/300], Step [142/225], Training Accuracy: 98.5805%, Training Loss: 0.0491%\n",
      "Epoch [114/300], Step [143/225], Training Accuracy: 98.5795%, Training Loss: 0.0491%\n",
      "Epoch [114/300], Step [144/225], Training Accuracy: 98.5677%, Training Loss: 0.0492%\n",
      "Epoch [114/300], Step [145/225], Training Accuracy: 98.5668%, Training Loss: 0.0491%\n",
      "Epoch [114/300], Step [146/225], Training Accuracy: 98.5659%, Training Loss: 0.0490%\n",
      "Epoch [114/300], Step [147/225], Training Accuracy: 98.5757%, Training Loss: 0.0488%\n",
      "Epoch [114/300], Step [148/225], Training Accuracy: 98.5536%, Training Loss: 0.0491%\n",
      "Epoch [114/300], Step [149/225], Training Accuracy: 98.5529%, Training Loss: 0.0491%\n",
      "Epoch [114/300], Step [150/225], Training Accuracy: 98.5625%, Training Loss: 0.0489%\n",
      "Epoch [114/300], Step [151/225], Training Accuracy: 98.5617%, Training Loss: 0.0490%\n",
      "Epoch [114/300], Step [152/225], Training Accuracy: 98.5609%, Training Loss: 0.0489%\n",
      "Epoch [114/300], Step [153/225], Training Accuracy: 98.5600%, Training Loss: 0.0488%\n",
      "Epoch [114/300], Step [154/225], Training Accuracy: 98.5593%, Training Loss: 0.0489%\n",
      "Epoch [114/300], Step [155/225], Training Accuracy: 98.5585%, Training Loss: 0.0489%\n",
      "Epoch [114/300], Step [156/225], Training Accuracy: 98.5477%, Training Loss: 0.0488%\n",
      "Epoch [114/300], Step [157/225], Training Accuracy: 98.5569%, Training Loss: 0.0487%\n",
      "Epoch [114/300], Step [158/225], Training Accuracy: 98.5463%, Training Loss: 0.0487%\n",
      "Epoch [114/300], Step [159/225], Training Accuracy: 98.5554%, Training Loss: 0.0485%\n",
      "Epoch [114/300], Step [160/225], Training Accuracy: 98.5449%, Training Loss: 0.0489%\n",
      "Epoch [114/300], Step [161/225], Training Accuracy: 98.5540%, Training Loss: 0.0487%\n",
      "Epoch [114/300], Step [162/225], Training Accuracy: 98.5340%, Training Loss: 0.0490%\n",
      "Epoch [114/300], Step [163/225], Training Accuracy: 98.5429%, Training Loss: 0.0489%\n",
      "Epoch [114/300], Step [164/225], Training Accuracy: 98.5518%, Training Loss: 0.0487%\n",
      "Epoch [114/300], Step [165/225], Training Accuracy: 98.5606%, Training Loss: 0.0486%\n",
      "Epoch [114/300], Step [166/225], Training Accuracy: 98.5693%, Training Loss: 0.0484%\n",
      "Epoch [114/300], Step [167/225], Training Accuracy: 98.5685%, Training Loss: 0.0483%\n",
      "Epoch [114/300], Step [168/225], Training Accuracy: 98.5677%, Training Loss: 0.0486%\n",
      "Epoch [114/300], Step [169/225], Training Accuracy: 98.5762%, Training Loss: 0.0484%\n",
      "Epoch [114/300], Step [170/225], Training Accuracy: 98.5662%, Training Loss: 0.0485%\n",
      "Epoch [114/300], Step [171/225], Training Accuracy: 98.5746%, Training Loss: 0.0484%\n",
      "Epoch [114/300], Step [172/225], Training Accuracy: 98.5828%, Training Loss: 0.0484%\n",
      "Epoch [114/300], Step [173/225], Training Accuracy: 98.5820%, Training Loss: 0.0483%\n",
      "Epoch [114/300], Step [174/225], Training Accuracy: 98.5812%, Training Loss: 0.0484%\n",
      "Epoch [114/300], Step [175/225], Training Accuracy: 98.5804%, Training Loss: 0.0484%\n",
      "Epoch [114/300], Step [176/225], Training Accuracy: 98.5884%, Training Loss: 0.0483%\n",
      "Epoch [114/300], Step [177/225], Training Accuracy: 98.5876%, Training Loss: 0.0483%\n",
      "Epoch [114/300], Step [178/225], Training Accuracy: 98.5867%, Training Loss: 0.0483%\n",
      "Epoch [114/300], Step [179/225], Training Accuracy: 98.5684%, Training Loss: 0.0488%\n",
      "Epoch [114/300], Step [180/225], Training Accuracy: 98.5677%, Training Loss: 0.0488%\n",
      "Epoch [114/300], Step [181/225], Training Accuracy: 98.5670%, Training Loss: 0.0489%\n",
      "Epoch [114/300], Step [182/225], Training Accuracy: 98.5749%, Training Loss: 0.0487%\n",
      "Epoch [114/300], Step [183/225], Training Accuracy: 98.5827%, Training Loss: 0.0485%\n",
      "Epoch [114/300], Step [184/225], Training Accuracy: 98.5904%, Training Loss: 0.0484%\n",
      "Epoch [114/300], Step [185/225], Training Accuracy: 98.5895%, Training Loss: 0.0484%\n",
      "Epoch [114/300], Step [186/225], Training Accuracy: 98.5971%, Training Loss: 0.0483%\n",
      "Epoch [114/300], Step [187/225], Training Accuracy: 98.6046%, Training Loss: 0.0481%\n",
      "Epoch [114/300], Step [188/225], Training Accuracy: 98.6120%, Training Loss: 0.0480%\n",
      "Epoch [114/300], Step [189/225], Training Accuracy: 98.6028%, Training Loss: 0.0482%\n",
      "Epoch [114/300], Step [190/225], Training Accuracy: 98.6020%, Training Loss: 0.0482%\n",
      "Epoch [114/300], Step [191/225], Training Accuracy: 98.6011%, Training Loss: 0.0482%\n",
      "Epoch [114/300], Step [192/225], Training Accuracy: 98.5677%, Training Loss: 0.0487%\n",
      "Epoch [114/300], Step [193/225], Training Accuracy: 98.5508%, Training Loss: 0.0490%\n",
      "Epoch [114/300], Step [194/225], Training Accuracy: 98.5503%, Training Loss: 0.0490%\n",
      "Epoch [114/300], Step [195/225], Training Accuracy: 98.5417%, Training Loss: 0.0490%\n",
      "Epoch [114/300], Step [196/225], Training Accuracy: 98.5411%, Training Loss: 0.0490%\n",
      "Epoch [114/300], Step [197/225], Training Accuracy: 98.5327%, Training Loss: 0.0490%\n",
      "Epoch [114/300], Step [198/225], Training Accuracy: 98.5322%, Training Loss: 0.0491%\n",
      "Epoch [114/300], Step [199/225], Training Accuracy: 98.5160%, Training Loss: 0.0493%\n",
      "Epoch [114/300], Step [200/225], Training Accuracy: 98.5156%, Training Loss: 0.0493%\n",
      "Epoch [114/300], Step [201/225], Training Accuracy: 98.5075%, Training Loss: 0.0493%\n",
      "Epoch [114/300], Step [202/225], Training Accuracy: 98.4916%, Training Loss: 0.0497%\n",
      "Epoch [114/300], Step [203/225], Training Accuracy: 98.4837%, Training Loss: 0.0498%\n",
      "Epoch [114/300], Step [204/225], Training Accuracy: 98.4835%, Training Loss: 0.0497%\n",
      "Epoch [114/300], Step [205/225], Training Accuracy: 98.4909%, Training Loss: 0.0496%\n",
      "Epoch [114/300], Step [206/225], Training Accuracy: 98.4982%, Training Loss: 0.0495%\n",
      "Epoch [114/300], Step [207/225], Training Accuracy: 98.4979%, Training Loss: 0.0494%\n",
      "Epoch [114/300], Step [208/225], Training Accuracy: 98.4976%, Training Loss: 0.0493%\n",
      "Epoch [114/300], Step [209/225], Training Accuracy: 98.4973%, Training Loss: 0.0495%\n",
      "Epoch [114/300], Step [210/225], Training Accuracy: 98.5045%, Training Loss: 0.0494%\n",
      "Epoch [114/300], Step [211/225], Training Accuracy: 98.4893%, Training Loss: 0.0497%\n",
      "Epoch [114/300], Step [212/225], Training Accuracy: 98.4891%, Training Loss: 0.0497%\n",
      "Epoch [114/300], Step [213/225], Training Accuracy: 98.4888%, Training Loss: 0.0497%\n",
      "Epoch [114/300], Step [214/225], Training Accuracy: 98.4886%, Training Loss: 0.0499%\n",
      "Epoch [114/300], Step [215/225], Training Accuracy: 98.4956%, Training Loss: 0.0497%\n",
      "Epoch [114/300], Step [216/225], Training Accuracy: 98.4954%, Training Loss: 0.0497%\n",
      "Epoch [114/300], Step [217/225], Training Accuracy: 98.5023%, Training Loss: 0.0497%\n",
      "Epoch [114/300], Step [218/225], Training Accuracy: 98.5020%, Training Loss: 0.0496%\n",
      "Epoch [114/300], Step [219/225], Training Accuracy: 98.5017%, Training Loss: 0.0497%\n",
      "Epoch [114/300], Step [220/225], Training Accuracy: 98.4872%, Training Loss: 0.0499%\n",
      "Epoch [114/300], Step [221/225], Training Accuracy: 98.4799%, Training Loss: 0.0499%\n",
      "Epoch [114/300], Step [222/225], Training Accuracy: 98.4657%, Training Loss: 0.0499%\n",
      "Epoch [114/300], Step [223/225], Training Accuracy: 98.4585%, Training Loss: 0.0499%\n",
      "Epoch [114/300], Step [224/225], Training Accuracy: 98.4515%, Training Loss: 0.0499%\n",
      "Epoch [114/300], Step [225/225], Training Accuracy: 98.4505%, Training Loss: 0.0499%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [115/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0217%\n",
      "Epoch [115/300], Step [2/225], Training Accuracy: 100.0000%, Training Loss: 0.0196%\n",
      "Epoch [115/300], Step [3/225], Training Accuracy: 98.4375%, Training Loss: 0.0454%\n",
      "Epoch [115/300], Step [4/225], Training Accuracy: 98.8281%, Training Loss: 0.0444%\n",
      "Epoch [115/300], Step [5/225], Training Accuracy: 99.0625%, Training Loss: 0.0396%\n",
      "Epoch [115/300], Step [6/225], Training Accuracy: 98.9583%, Training Loss: 0.0390%\n",
      "Epoch [115/300], Step [7/225], Training Accuracy: 98.6607%, Training Loss: 0.0431%\n",
      "Epoch [115/300], Step [8/225], Training Accuracy: 98.6328%, Training Loss: 0.0438%\n",
      "Epoch [115/300], Step [9/225], Training Accuracy: 98.6111%, Training Loss: 0.0467%\n",
      "Epoch [115/300], Step [10/225], Training Accuracy: 98.4375%, Training Loss: 0.0503%\n",
      "Epoch [115/300], Step [11/225], Training Accuracy: 98.4375%, Training Loss: 0.0482%\n",
      "Epoch [115/300], Step [12/225], Training Accuracy: 98.5677%, Training Loss: 0.0459%\n",
      "Epoch [115/300], Step [13/225], Training Accuracy: 98.5577%, Training Loss: 0.0451%\n",
      "Epoch [115/300], Step [14/225], Training Accuracy: 98.6607%, Training Loss: 0.0435%\n",
      "Epoch [115/300], Step [15/225], Training Accuracy: 98.4375%, Training Loss: 0.0460%\n",
      "Epoch [115/300], Step [16/225], Training Accuracy: 98.5352%, Training Loss: 0.0448%\n",
      "Epoch [115/300], Step [17/225], Training Accuracy: 98.5294%, Training Loss: 0.0445%\n",
      "Epoch [115/300], Step [18/225], Training Accuracy: 98.4375%, Training Loss: 0.0473%\n",
      "Epoch [115/300], Step [19/225], Training Accuracy: 98.4375%, Training Loss: 0.0484%\n",
      "Epoch [115/300], Step [20/225], Training Accuracy: 98.3594%, Training Loss: 0.0504%\n",
      "Epoch [115/300], Step [21/225], Training Accuracy: 98.3631%, Training Loss: 0.0493%\n",
      "Epoch [115/300], Step [22/225], Training Accuracy: 98.2955%, Training Loss: 0.0512%\n",
      "Epoch [115/300], Step [23/225], Training Accuracy: 98.3016%, Training Loss: 0.0515%\n",
      "Epoch [115/300], Step [24/225], Training Accuracy: 98.2422%, Training Loss: 0.0543%\n",
      "Epoch [115/300], Step [25/225], Training Accuracy: 98.3125%, Training Loss: 0.0530%\n",
      "Epoch [115/300], Step [26/225], Training Accuracy: 98.1370%, Training Loss: 0.0549%\n",
      "Epoch [115/300], Step [27/225], Training Accuracy: 97.9745%, Training Loss: 0.0575%\n",
      "Epoch [115/300], Step [28/225], Training Accuracy: 98.0469%, Training Loss: 0.0568%\n",
      "Epoch [115/300], Step [29/225], Training Accuracy: 98.1142%, Training Loss: 0.0558%\n",
      "Epoch [115/300], Step [30/225], Training Accuracy: 98.1771%, Training Loss: 0.0545%\n",
      "Epoch [115/300], Step [31/225], Training Accuracy: 98.2359%, Training Loss: 0.0534%\n",
      "Epoch [115/300], Step [32/225], Training Accuracy: 98.2910%, Training Loss: 0.0520%\n",
      "Epoch [115/300], Step [33/225], Training Accuracy: 98.2955%, Training Loss: 0.0514%\n",
      "Epoch [115/300], Step [34/225], Training Accuracy: 98.2537%, Training Loss: 0.0516%\n",
      "Epoch [115/300], Step [35/225], Training Accuracy: 98.2589%, Training Loss: 0.0510%\n",
      "Epoch [115/300], Step [36/225], Training Accuracy: 98.2639%, Training Loss: 0.0508%\n",
      "Epoch [115/300], Step [37/225], Training Accuracy: 98.2686%, Training Loss: 0.0508%\n",
      "Epoch [115/300], Step [38/225], Training Accuracy: 98.2319%, Training Loss: 0.0516%\n",
      "Epoch [115/300], Step [39/225], Training Accuracy: 98.2372%, Training Loss: 0.0516%\n",
      "Epoch [115/300], Step [40/225], Training Accuracy: 98.2422%, Training Loss: 0.0523%\n",
      "Epoch [115/300], Step [41/225], Training Accuracy: 98.2851%, Training Loss: 0.0515%\n",
      "Epoch [115/300], Step [42/225], Training Accuracy: 98.2887%, Training Loss: 0.0521%\n",
      "Epoch [115/300], Step [43/225], Training Accuracy: 98.3285%, Training Loss: 0.0512%\n",
      "Epoch [115/300], Step [44/225], Training Accuracy: 98.2955%, Training Loss: 0.0512%\n",
      "Epoch [115/300], Step [45/225], Training Accuracy: 98.2639%, Training Loss: 0.0523%\n",
      "Epoch [115/300], Step [46/225], Training Accuracy: 98.3016%, Training Loss: 0.0519%\n",
      "Epoch [115/300], Step [47/225], Training Accuracy: 98.2380%, Training Loss: 0.0534%\n",
      "Epoch [115/300], Step [48/225], Training Accuracy: 98.2747%, Training Loss: 0.0530%\n",
      "Epoch [115/300], Step [49/225], Training Accuracy: 98.2781%, Training Loss: 0.0533%\n",
      "Epoch [115/300], Step [50/225], Training Accuracy: 98.2812%, Training Loss: 0.0531%\n",
      "Epoch [115/300], Step [51/225], Training Accuracy: 98.2843%, Training Loss: 0.0531%\n",
      "Epoch [115/300], Step [52/225], Training Accuracy: 98.2873%, Training Loss: 0.0525%\n",
      "Epoch [115/300], Step [53/225], Training Accuracy: 98.3196%, Training Loss: 0.0522%\n",
      "Epoch [115/300], Step [54/225], Training Accuracy: 98.3218%, Training Loss: 0.0524%\n",
      "Epoch [115/300], Step [55/225], Training Accuracy: 98.2670%, Training Loss: 0.0527%\n",
      "Epoch [115/300], Step [56/225], Training Accuracy: 98.2701%, Training Loss: 0.0530%\n",
      "Epoch [115/300], Step [57/225], Training Accuracy: 98.3004%, Training Loss: 0.0526%\n",
      "Epoch [115/300], Step [58/225], Training Accuracy: 98.3028%, Training Loss: 0.0531%\n",
      "Epoch [115/300], Step [59/225], Training Accuracy: 98.2256%, Training Loss: 0.0546%\n",
      "Epoch [115/300], Step [60/225], Training Accuracy: 98.2552%, Training Loss: 0.0542%\n",
      "Epoch [115/300], Step [61/225], Training Accuracy: 98.2070%, Training Loss: 0.0547%\n",
      "Epoch [115/300], Step [62/225], Training Accuracy: 98.2107%, Training Loss: 0.0547%\n",
      "Epoch [115/300], Step [63/225], Training Accuracy: 98.2391%, Training Loss: 0.0542%\n",
      "Epoch [115/300], Step [64/225], Training Accuracy: 98.2178%, Training Loss: 0.0544%\n",
      "Epoch [115/300], Step [65/225], Training Accuracy: 98.2212%, Training Loss: 0.0542%\n",
      "Epoch [115/300], Step [66/225], Training Accuracy: 98.2481%, Training Loss: 0.0536%\n",
      "Epoch [115/300], Step [67/225], Training Accuracy: 98.2743%, Training Loss: 0.0532%\n",
      "Epoch [115/300], Step [68/225], Training Accuracy: 98.2537%, Training Loss: 0.0535%\n",
      "Epoch [115/300], Step [69/225], Training Accuracy: 98.2563%, Training Loss: 0.0536%\n",
      "Epoch [115/300], Step [70/225], Training Accuracy: 98.2143%, Training Loss: 0.0543%\n",
      "Epoch [115/300], Step [71/225], Training Accuracy: 98.1514%, Training Loss: 0.0560%\n",
      "Epoch [115/300], Step [72/225], Training Accuracy: 98.1771%, Training Loss: 0.0555%\n",
      "Epoch [115/300], Step [73/225], Training Accuracy: 98.1807%, Training Loss: 0.0553%\n",
      "Epoch [115/300], Step [74/225], Training Accuracy: 98.1630%, Training Loss: 0.0561%\n",
      "Epoch [115/300], Step [75/225], Training Accuracy: 98.1458%, Training Loss: 0.0565%\n",
      "Epoch [115/300], Step [76/225], Training Accuracy: 98.1497%, Training Loss: 0.0569%\n",
      "Epoch [115/300], Step [77/225], Training Accuracy: 98.1331%, Training Loss: 0.0581%\n",
      "Epoch [115/300], Step [78/225], Training Accuracy: 98.1571%, Training Loss: 0.0575%\n",
      "Epoch [115/300], Step [79/225], Training Accuracy: 98.1013%, Training Loss: 0.0585%\n",
      "Epoch [115/300], Step [80/225], Training Accuracy: 98.1250%, Training Loss: 0.0582%\n",
      "Epoch [115/300], Step [81/225], Training Accuracy: 98.1289%, Training Loss: 0.0585%\n",
      "Epoch [115/300], Step [82/225], Training Accuracy: 98.1326%, Training Loss: 0.0582%\n",
      "Epoch [115/300], Step [83/225], Training Accuracy: 98.1175%, Training Loss: 0.0584%\n",
      "Epoch [115/300], Step [84/225], Training Accuracy: 98.0841%, Training Loss: 0.0589%\n",
      "Epoch [115/300], Step [85/225], Training Accuracy: 98.1066%, Training Loss: 0.0587%\n",
      "Epoch [115/300], Step [86/225], Training Accuracy: 98.1105%, Training Loss: 0.0590%\n",
      "Epoch [115/300], Step [87/225], Training Accuracy: 98.1322%, Training Loss: 0.0585%\n",
      "Epoch [115/300], Step [88/225], Training Accuracy: 98.1179%, Training Loss: 0.0587%\n",
      "Epoch [115/300], Step [89/225], Training Accuracy: 98.0864%, Training Loss: 0.0590%\n",
      "Epoch [115/300], Step [90/225], Training Accuracy: 98.0903%, Training Loss: 0.0588%\n",
      "Epoch [115/300], Step [91/225], Training Accuracy: 98.1113%, Training Loss: 0.0582%\n",
      "Epoch [115/300], Step [92/225], Training Accuracy: 98.1318%, Training Loss: 0.0579%\n",
      "Epoch [115/300], Step [93/225], Training Accuracy: 98.1519%, Training Loss: 0.0574%\n",
      "Epoch [115/300], Step [94/225], Training Accuracy: 98.1549%, Training Loss: 0.0573%\n",
      "Epoch [115/300], Step [95/225], Training Accuracy: 98.1579%, Training Loss: 0.0571%\n",
      "Epoch [115/300], Step [96/225], Training Accuracy: 98.1771%, Training Loss: 0.0567%\n",
      "Epoch [115/300], Step [97/225], Training Accuracy: 98.1798%, Training Loss: 0.0563%\n",
      "Epoch [115/300], Step [98/225], Training Accuracy: 98.1665%, Training Loss: 0.0570%\n",
      "Epoch [115/300], Step [99/225], Training Accuracy: 98.1692%, Training Loss: 0.0569%\n",
      "Epoch [115/300], Step [100/225], Training Accuracy: 98.1562%, Training Loss: 0.0570%\n",
      "Epoch [115/300], Step [101/225], Training Accuracy: 98.1590%, Training Loss: 0.0569%\n",
      "Epoch [115/300], Step [102/225], Training Accuracy: 98.1464%, Training Loss: 0.0569%\n",
      "Epoch [115/300], Step [103/225], Training Accuracy: 98.1493%, Training Loss: 0.0568%\n",
      "Epoch [115/300], Step [104/225], Training Accuracy: 98.1520%, Training Loss: 0.0568%\n",
      "Epoch [115/300], Step [105/225], Training Accuracy: 98.1696%, Training Loss: 0.0564%\n",
      "Epoch [115/300], Step [106/225], Training Accuracy: 98.1869%, Training Loss: 0.0563%\n",
      "Epoch [115/300], Step [107/225], Training Accuracy: 98.1600%, Training Loss: 0.0565%\n",
      "Epoch [115/300], Step [108/225], Training Accuracy: 98.1626%, Training Loss: 0.0565%\n",
      "Epoch [115/300], Step [109/225], Training Accuracy: 98.1651%, Training Loss: 0.0564%\n",
      "Epoch [115/300], Step [110/225], Training Accuracy: 98.1676%, Training Loss: 0.0563%\n",
      "Epoch [115/300], Step [111/225], Training Accuracy: 98.1841%, Training Loss: 0.0561%\n",
      "Epoch [115/300], Step [112/225], Training Accuracy: 98.2003%, Training Loss: 0.0558%\n",
      "Epoch [115/300], Step [113/225], Training Accuracy: 98.2024%, Training Loss: 0.0557%\n",
      "Epoch [115/300], Step [114/225], Training Accuracy: 98.2045%, Training Loss: 0.0557%\n",
      "Epoch [115/300], Step [115/225], Training Accuracy: 98.1929%, Training Loss: 0.0560%\n",
      "Epoch [115/300], Step [116/225], Training Accuracy: 98.1950%, Training Loss: 0.0558%\n",
      "Epoch [115/300], Step [117/225], Training Accuracy: 98.2105%, Training Loss: 0.0556%\n",
      "Epoch [115/300], Step [118/225], Training Accuracy: 98.2124%, Training Loss: 0.0555%\n",
      "Epoch [115/300], Step [119/225], Training Accuracy: 98.2143%, Training Loss: 0.0555%\n",
      "Epoch [115/300], Step [120/225], Training Accuracy: 98.2161%, Training Loss: 0.0552%\n",
      "Epoch [115/300], Step [121/225], Training Accuracy: 98.2051%, Training Loss: 0.0553%\n",
      "Epoch [115/300], Step [122/225], Training Accuracy: 98.2070%, Training Loss: 0.0552%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [115/300], Step [123/225], Training Accuracy: 98.2215%, Training Loss: 0.0550%\n",
      "Epoch [115/300], Step [124/225], Training Accuracy: 98.2359%, Training Loss: 0.0547%\n",
      "Epoch [115/300], Step [125/225], Training Accuracy: 98.2375%, Training Loss: 0.0545%\n",
      "Epoch [115/300], Step [126/225], Training Accuracy: 98.2515%, Training Loss: 0.0543%\n",
      "Epoch [115/300], Step [127/225], Training Accuracy: 98.2406%, Training Loss: 0.0545%\n",
      "Epoch [115/300], Step [128/225], Training Accuracy: 98.2544%, Training Loss: 0.0544%\n",
      "Epoch [115/300], Step [129/225], Training Accuracy: 98.2679%, Training Loss: 0.0542%\n",
      "Epoch [115/300], Step [130/225], Training Accuracy: 98.2452%, Training Loss: 0.0545%\n",
      "Epoch [115/300], Step [131/225], Training Accuracy: 98.2467%, Training Loss: 0.0544%\n",
      "Epoch [115/300], Step [132/225], Training Accuracy: 98.2363%, Training Loss: 0.0545%\n",
      "Epoch [115/300], Step [133/225], Training Accuracy: 98.2495%, Training Loss: 0.0543%\n",
      "Epoch [115/300], Step [134/225], Training Accuracy: 98.2393%, Training Loss: 0.0544%\n",
      "Epoch [115/300], Step [135/225], Training Accuracy: 98.2292%, Training Loss: 0.0545%\n",
      "Epoch [115/300], Step [136/225], Training Accuracy: 98.2307%, Training Loss: 0.0544%\n",
      "Epoch [115/300], Step [137/225], Training Accuracy: 98.2322%, Training Loss: 0.0543%\n",
      "Epoch [115/300], Step [138/225], Training Accuracy: 98.2337%, Training Loss: 0.0540%\n",
      "Epoch [115/300], Step [139/225], Training Accuracy: 98.2239%, Training Loss: 0.0541%\n",
      "Epoch [115/300], Step [140/225], Training Accuracy: 98.2254%, Training Loss: 0.0541%\n",
      "Epoch [115/300], Step [141/225], Training Accuracy: 98.2270%, Training Loss: 0.0539%\n",
      "Epoch [115/300], Step [142/225], Training Accuracy: 98.2394%, Training Loss: 0.0538%\n",
      "Epoch [115/300], Step [143/225], Training Accuracy: 98.2517%, Training Loss: 0.0537%\n",
      "Epoch [115/300], Step [144/225], Training Accuracy: 98.2530%, Training Loss: 0.0537%\n",
      "Epoch [115/300], Step [145/225], Training Accuracy: 98.2543%, Training Loss: 0.0535%\n",
      "Epoch [115/300], Step [146/225], Training Accuracy: 98.2556%, Training Loss: 0.0536%\n",
      "Epoch [115/300], Step [147/225], Training Accuracy: 98.2568%, Training Loss: 0.0536%\n",
      "Epoch [115/300], Step [148/225], Training Accuracy: 98.2580%, Training Loss: 0.0537%\n",
      "Epoch [115/300], Step [149/225], Training Accuracy: 98.2592%, Training Loss: 0.0536%\n",
      "Epoch [115/300], Step [150/225], Training Accuracy: 98.2604%, Training Loss: 0.0534%\n",
      "Epoch [115/300], Step [151/225], Training Accuracy: 98.2616%, Training Loss: 0.0533%\n",
      "Epoch [115/300], Step [152/225], Training Accuracy: 98.2525%, Training Loss: 0.0532%\n",
      "Epoch [115/300], Step [153/225], Training Accuracy: 98.2537%, Training Loss: 0.0532%\n",
      "Epoch [115/300], Step [154/225], Training Accuracy: 98.2549%, Training Loss: 0.0531%\n",
      "Epoch [115/300], Step [155/225], Training Accuracy: 98.2661%, Training Loss: 0.0529%\n",
      "Epoch [115/300], Step [156/225], Training Accuracy: 98.2772%, Training Loss: 0.0526%\n",
      "Epoch [115/300], Step [157/225], Training Accuracy: 98.2783%, Training Loss: 0.0526%\n",
      "Epoch [115/300], Step [158/225], Training Accuracy: 98.2892%, Training Loss: 0.0524%\n",
      "Epoch [115/300], Step [159/225], Training Accuracy: 98.2999%, Training Loss: 0.0523%\n",
      "Epoch [115/300], Step [160/225], Training Accuracy: 98.3008%, Training Loss: 0.0522%\n",
      "Epoch [115/300], Step [161/225], Training Accuracy: 98.3113%, Training Loss: 0.0520%\n",
      "Epoch [115/300], Step [162/225], Training Accuracy: 98.3025%, Training Loss: 0.0520%\n",
      "Epoch [115/300], Step [163/225], Training Accuracy: 98.3033%, Training Loss: 0.0520%\n",
      "Epoch [115/300], Step [164/225], Training Accuracy: 98.2851%, Training Loss: 0.0522%\n",
      "Epoch [115/300], Step [165/225], Training Accuracy: 98.2860%, Training Loss: 0.0521%\n",
      "Epoch [115/300], Step [166/225], Training Accuracy: 98.2775%, Training Loss: 0.0524%\n",
      "Epoch [115/300], Step [167/225], Training Accuracy: 98.2784%, Training Loss: 0.0523%\n",
      "Epoch [115/300], Step [168/225], Training Accuracy: 98.2887%, Training Loss: 0.0522%\n",
      "Epoch [115/300], Step [169/225], Training Accuracy: 98.2988%, Training Loss: 0.0520%\n",
      "Epoch [115/300], Step [170/225], Training Accuracy: 98.2904%, Training Loss: 0.0523%\n",
      "Epoch [115/300], Step [171/225], Training Accuracy: 98.2913%, Training Loss: 0.0523%\n",
      "Epoch [115/300], Step [172/225], Training Accuracy: 98.3012%, Training Loss: 0.0522%\n",
      "Epoch [115/300], Step [173/225], Training Accuracy: 98.3111%, Training Loss: 0.0520%\n",
      "Epoch [115/300], Step [174/225], Training Accuracy: 98.3118%, Training Loss: 0.0522%\n",
      "Epoch [115/300], Step [175/225], Training Accuracy: 98.3214%, Training Loss: 0.0520%\n",
      "Epoch [115/300], Step [176/225], Training Accuracy: 98.3310%, Training Loss: 0.0518%\n",
      "Epoch [115/300], Step [177/225], Training Accuracy: 98.3404%, Training Loss: 0.0516%\n",
      "Epoch [115/300], Step [178/225], Training Accuracy: 98.3234%, Training Loss: 0.0518%\n",
      "Epoch [115/300], Step [179/225], Training Accuracy: 98.3328%, Training Loss: 0.0516%\n",
      "Epoch [115/300], Step [180/225], Training Accuracy: 98.3333%, Training Loss: 0.0516%\n",
      "Epoch [115/300], Step [181/225], Training Accuracy: 98.3253%, Training Loss: 0.0519%\n",
      "Epoch [115/300], Step [182/225], Training Accuracy: 98.3345%, Training Loss: 0.0518%\n",
      "Epoch [115/300], Step [183/225], Training Accuracy: 98.3350%, Training Loss: 0.0518%\n",
      "Epoch [115/300], Step [184/225], Training Accuracy: 98.3271%, Training Loss: 0.0518%\n",
      "Epoch [115/300], Step [185/225], Training Accuracy: 98.3277%, Training Loss: 0.0518%\n",
      "Epoch [115/300], Step [186/225], Training Accuracy: 98.3283%, Training Loss: 0.0519%\n",
      "Epoch [115/300], Step [187/225], Training Accuracy: 98.3372%, Training Loss: 0.0518%\n",
      "Epoch [115/300], Step [188/225], Training Accuracy: 98.3378%, Training Loss: 0.0518%\n",
      "Epoch [115/300], Step [189/225], Training Accuracy: 98.3300%, Training Loss: 0.0520%\n",
      "Epoch [115/300], Step [190/225], Training Accuracy: 98.3306%, Training Loss: 0.0520%\n",
      "Epoch [115/300], Step [191/225], Training Accuracy: 98.3393%, Training Loss: 0.0519%\n",
      "Epoch [115/300], Step [192/225], Training Accuracy: 98.3480%, Training Loss: 0.0518%\n",
      "Epoch [115/300], Step [193/225], Training Accuracy: 98.3484%, Training Loss: 0.0518%\n",
      "Epoch [115/300], Step [194/225], Training Accuracy: 98.3489%, Training Loss: 0.0518%\n",
      "Epoch [115/300], Step [195/225], Training Accuracy: 98.3413%, Training Loss: 0.0520%\n",
      "Epoch [115/300], Step [196/225], Training Accuracy: 98.3418%, Training Loss: 0.0519%\n",
      "Epoch [115/300], Step [197/225], Training Accuracy: 98.3344%, Training Loss: 0.0522%\n",
      "Epoch [115/300], Step [198/225], Training Accuracy: 98.3349%, Training Loss: 0.0522%\n",
      "Epoch [115/300], Step [199/225], Training Accuracy: 98.3354%, Training Loss: 0.0522%\n",
      "Epoch [115/300], Step [200/225], Training Accuracy: 98.3359%, Training Loss: 0.0522%\n",
      "Epoch [115/300], Step [201/225], Training Accuracy: 98.3287%, Training Loss: 0.0526%\n",
      "Epoch [115/300], Step [202/225], Training Accuracy: 98.3292%, Training Loss: 0.0525%\n",
      "Epoch [115/300], Step [203/225], Training Accuracy: 98.3374%, Training Loss: 0.0524%\n",
      "Epoch [115/300], Step [204/225], Training Accuracy: 98.3303%, Training Loss: 0.0525%\n",
      "Epoch [115/300], Step [205/225], Training Accuracy: 98.3384%, Training Loss: 0.0525%\n",
      "Epoch [115/300], Step [206/225], Training Accuracy: 98.3313%, Training Loss: 0.0525%\n",
      "Epoch [115/300], Step [207/225], Training Accuracy: 98.3394%, Training Loss: 0.0523%\n",
      "Epoch [115/300], Step [208/225], Training Accuracy: 98.3474%, Training Loss: 0.0522%\n",
      "Epoch [115/300], Step [209/225], Training Accuracy: 98.3553%, Training Loss: 0.0520%\n",
      "Epoch [115/300], Step [210/225], Training Accuracy: 98.3631%, Training Loss: 0.0519%\n",
      "Epoch [115/300], Step [211/225], Training Accuracy: 98.3560%, Training Loss: 0.0521%\n",
      "Epoch [115/300], Step [212/225], Training Accuracy: 98.3564%, Training Loss: 0.0520%\n",
      "Epoch [115/300], Step [213/225], Training Accuracy: 98.3641%, Training Loss: 0.0518%\n",
      "Epoch [115/300], Step [214/225], Training Accuracy: 98.3572%, Training Loss: 0.0519%\n",
      "Epoch [115/300], Step [215/225], Training Accuracy: 98.3648%, Training Loss: 0.0518%\n",
      "Epoch [115/300], Step [216/225], Training Accuracy: 98.3724%, Training Loss: 0.0517%\n",
      "Epoch [115/300], Step [217/225], Training Accuracy: 98.3799%, Training Loss: 0.0515%\n",
      "Epoch [115/300], Step [218/225], Training Accuracy: 98.3802%, Training Loss: 0.0515%\n",
      "Epoch [115/300], Step [219/225], Training Accuracy: 98.3804%, Training Loss: 0.0514%\n",
      "Epoch [115/300], Step [220/225], Training Accuracy: 98.3878%, Training Loss: 0.0513%\n",
      "Epoch [115/300], Step [221/225], Training Accuracy: 98.3739%, Training Loss: 0.0514%\n",
      "Epoch [115/300], Step [222/225], Training Accuracy: 98.3812%, Training Loss: 0.0513%\n",
      "Epoch [115/300], Step [223/225], Training Accuracy: 98.3814%, Training Loss: 0.0513%\n",
      "Epoch [115/300], Step [224/225], Training Accuracy: 98.3817%, Training Loss: 0.0512%\n",
      "Epoch [115/300], Step [225/225], Training Accuracy: 98.3810%, Training Loss: 0.0511%\n",
      "Epoch [116/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0212%\n",
      "Epoch [116/300], Step [2/225], Training Accuracy: 99.2188%, Training Loss: 0.0387%\n",
      "Epoch [116/300], Step [3/225], Training Accuracy: 99.4792%, Training Loss: 0.0348%\n",
      "Epoch [116/300], Step [4/225], Training Accuracy: 99.6094%, Training Loss: 0.0335%\n",
      "Epoch [116/300], Step [5/225], Training Accuracy: 99.3750%, Training Loss: 0.0356%\n",
      "Epoch [116/300], Step [6/225], Training Accuracy: 99.4792%, Training Loss: 0.0324%\n",
      "Epoch [116/300], Step [7/225], Training Accuracy: 99.3304%, Training Loss: 0.0325%\n",
      "Epoch [116/300], Step [8/225], Training Accuracy: 99.2188%, Training Loss: 0.0330%\n",
      "Epoch [116/300], Step [9/225], Training Accuracy: 99.1319%, Training Loss: 0.0378%\n",
      "Epoch [116/300], Step [10/225], Training Accuracy: 98.7500%, Training Loss: 0.0438%\n",
      "Epoch [116/300], Step [11/225], Training Accuracy: 98.7216%, Training Loss: 0.0446%\n",
      "Epoch [116/300], Step [12/225], Training Accuracy: 98.5677%, Training Loss: 0.0460%\n",
      "Epoch [116/300], Step [13/225], Training Accuracy: 98.5577%, Training Loss: 0.0451%\n",
      "Epoch [116/300], Step [14/225], Training Accuracy: 98.5491%, Training Loss: 0.0447%\n",
      "Epoch [116/300], Step [15/225], Training Accuracy: 98.5417%, Training Loss: 0.0446%\n",
      "Epoch [116/300], Step [16/225], Training Accuracy: 98.6328%, Training Loss: 0.0426%\n",
      "Epoch [116/300], Step [17/225], Training Accuracy: 98.5294%, Training Loss: 0.0437%\n",
      "Epoch [116/300], Step [18/225], Training Accuracy: 98.3507%, Training Loss: 0.0523%\n",
      "Epoch [116/300], Step [19/225], Training Accuracy: 98.3553%, Training Loss: 0.0511%\n",
      "Epoch [116/300], Step [20/225], Training Accuracy: 98.3594%, Training Loss: 0.0503%\n",
      "Epoch [116/300], Step [21/225], Training Accuracy: 98.4375%, Training Loss: 0.0482%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [116/300], Step [22/225], Training Accuracy: 98.3665%, Training Loss: 0.0500%\n",
      "Epoch [116/300], Step [23/225], Training Accuracy: 98.4375%, Training Loss: 0.0486%\n",
      "Epoch [116/300], Step [24/225], Training Accuracy: 98.5026%, Training Loss: 0.0476%\n",
      "Epoch [116/300], Step [25/225], Training Accuracy: 98.5000%, Training Loss: 0.0466%\n",
      "Epoch [116/300], Step [26/225], Training Accuracy: 98.4976%, Training Loss: 0.0462%\n",
      "Epoch [116/300], Step [27/225], Training Accuracy: 98.5532%, Training Loss: 0.0451%\n",
      "Epoch [116/300], Step [28/225], Training Accuracy: 98.6049%, Training Loss: 0.0441%\n",
      "Epoch [116/300], Step [29/225], Training Accuracy: 98.5991%, Training Loss: 0.0441%\n",
      "Epoch [116/300], Step [30/225], Training Accuracy: 98.4375%, Training Loss: 0.0455%\n",
      "Epoch [116/300], Step [31/225], Training Accuracy: 98.4375%, Training Loss: 0.0456%\n",
      "Epoch [116/300], Step [32/225], Training Accuracy: 98.4375%, Training Loss: 0.0451%\n",
      "Epoch [116/300], Step [33/225], Training Accuracy: 98.3902%, Training Loss: 0.0467%\n",
      "Epoch [116/300], Step [34/225], Training Accuracy: 98.2996%, Training Loss: 0.0480%\n",
      "Epoch [116/300], Step [35/225], Training Accuracy: 98.3482%, Training Loss: 0.0469%\n",
      "Epoch [116/300], Step [36/225], Training Accuracy: 98.2639%, Training Loss: 0.0494%\n",
      "Epoch [116/300], Step [37/225], Training Accuracy: 98.2686%, Training Loss: 0.0492%\n",
      "Epoch [116/300], Step [38/225], Training Accuracy: 98.2730%, Training Loss: 0.0488%\n",
      "Epoch [116/300], Step [39/225], Training Accuracy: 98.2772%, Training Loss: 0.0489%\n",
      "Epoch [116/300], Step [40/225], Training Accuracy: 98.2812%, Training Loss: 0.0490%\n",
      "Epoch [116/300], Step [41/225], Training Accuracy: 98.2851%, Training Loss: 0.0488%\n",
      "Epoch [116/300], Step [42/225], Training Accuracy: 98.2887%, Training Loss: 0.0488%\n",
      "Epoch [116/300], Step [43/225], Training Accuracy: 98.3285%, Training Loss: 0.0481%\n",
      "Epoch [116/300], Step [44/225], Training Accuracy: 98.3310%, Training Loss: 0.0478%\n",
      "Epoch [116/300], Step [45/225], Training Accuracy: 98.3681%, Training Loss: 0.0470%\n",
      "Epoch [116/300], Step [46/225], Training Accuracy: 98.4035%, Training Loss: 0.0466%\n",
      "Epoch [116/300], Step [47/225], Training Accuracy: 98.4043%, Training Loss: 0.0461%\n",
      "Epoch [116/300], Step [48/225], Training Accuracy: 98.3724%, Training Loss: 0.0466%\n",
      "Epoch [116/300], Step [49/225], Training Accuracy: 98.3737%, Training Loss: 0.0463%\n",
      "Epoch [116/300], Step [50/225], Training Accuracy: 98.4062%, Training Loss: 0.0459%\n",
      "Epoch [116/300], Step [51/225], Training Accuracy: 98.4375%, Training Loss: 0.0455%\n",
      "Epoch [116/300], Step [52/225], Training Accuracy: 98.4075%, Training Loss: 0.0458%\n",
      "Epoch [116/300], Step [53/225], Training Accuracy: 98.4375%, Training Loss: 0.0454%\n",
      "Epoch [116/300], Step [54/225], Training Accuracy: 98.4375%, Training Loss: 0.0458%\n",
      "Epoch [116/300], Step [55/225], Training Accuracy: 98.4659%, Training Loss: 0.0453%\n",
      "Epoch [116/300], Step [56/225], Training Accuracy: 98.4654%, Training Loss: 0.0463%\n",
      "Epoch [116/300], Step [57/225], Training Accuracy: 98.4649%, Training Loss: 0.0471%\n",
      "Epoch [116/300], Step [58/225], Training Accuracy: 98.4914%, Training Loss: 0.0466%\n",
      "Epoch [116/300], Step [59/225], Training Accuracy: 98.4640%, Training Loss: 0.0472%\n",
      "Epoch [116/300], Step [60/225], Training Accuracy: 98.4375%, Training Loss: 0.0475%\n",
      "Epoch [116/300], Step [61/225], Training Accuracy: 98.3607%, Training Loss: 0.0483%\n",
      "Epoch [116/300], Step [62/225], Training Accuracy: 98.3619%, Training Loss: 0.0480%\n",
      "Epoch [116/300], Step [63/225], Training Accuracy: 98.3879%, Training Loss: 0.0476%\n",
      "Epoch [116/300], Step [64/225], Training Accuracy: 98.3887%, Training Loss: 0.0475%\n",
      "Epoch [116/300], Step [65/225], Training Accuracy: 98.4135%, Training Loss: 0.0470%\n",
      "Epoch [116/300], Step [66/225], Training Accuracy: 98.4138%, Training Loss: 0.0470%\n",
      "Epoch [116/300], Step [67/225], Training Accuracy: 98.3909%, Training Loss: 0.0477%\n",
      "Epoch [116/300], Step [68/225], Training Accuracy: 98.4145%, Training Loss: 0.0472%\n",
      "Epoch [116/300], Step [69/225], Training Accuracy: 98.3922%, Training Loss: 0.0481%\n",
      "Epoch [116/300], Step [70/225], Training Accuracy: 98.3929%, Training Loss: 0.0483%\n",
      "Epoch [116/300], Step [71/225], Training Accuracy: 98.3935%, Training Loss: 0.0482%\n",
      "Epoch [116/300], Step [72/225], Training Accuracy: 98.4158%, Training Loss: 0.0479%\n",
      "Epoch [116/300], Step [73/225], Training Accuracy: 98.4161%, Training Loss: 0.0478%\n",
      "Epoch [116/300], Step [74/225], Training Accuracy: 98.4164%, Training Loss: 0.0476%\n",
      "Epoch [116/300], Step [75/225], Training Accuracy: 98.4167%, Training Loss: 0.0477%\n",
      "Epoch [116/300], Step [76/225], Training Accuracy: 98.3964%, Training Loss: 0.0481%\n",
      "Epoch [116/300], Step [77/225], Training Accuracy: 98.4172%, Training Loss: 0.0479%\n",
      "Epoch [116/300], Step [78/225], Training Accuracy: 98.4175%, Training Loss: 0.0481%\n",
      "Epoch [116/300], Step [79/225], Training Accuracy: 98.3979%, Training Loss: 0.0484%\n",
      "Epoch [116/300], Step [80/225], Training Accuracy: 98.3594%, Training Loss: 0.0488%\n",
      "Epoch [116/300], Step [81/225], Training Accuracy: 98.3603%, Training Loss: 0.0484%\n",
      "Epoch [116/300], Step [82/225], Training Accuracy: 98.3803%, Training Loss: 0.0481%\n",
      "Epoch [116/300], Step [83/225], Training Accuracy: 98.3998%, Training Loss: 0.0477%\n",
      "Epoch [116/300], Step [84/225], Training Accuracy: 98.4189%, Training Loss: 0.0475%\n",
      "Epoch [116/300], Step [85/225], Training Accuracy: 98.4191%, Training Loss: 0.0475%\n",
      "Epoch [116/300], Step [86/225], Training Accuracy: 98.4193%, Training Loss: 0.0474%\n",
      "Epoch [116/300], Step [87/225], Training Accuracy: 98.4195%, Training Loss: 0.0475%\n",
      "Epoch [116/300], Step [88/225], Training Accuracy: 98.4375%, Training Loss: 0.0474%\n",
      "Epoch [116/300], Step [89/225], Training Accuracy: 98.4375%, Training Loss: 0.0474%\n",
      "Epoch [116/300], Step [90/225], Training Accuracy: 98.4375%, Training Loss: 0.0479%\n",
      "Epoch [116/300], Step [91/225], Training Accuracy: 98.4547%, Training Loss: 0.0477%\n",
      "Epoch [116/300], Step [92/225], Training Accuracy: 98.4545%, Training Loss: 0.0479%\n",
      "Epoch [116/300], Step [93/225], Training Accuracy: 98.4543%, Training Loss: 0.0482%\n",
      "Epoch [116/300], Step [94/225], Training Accuracy: 98.4707%, Training Loss: 0.0481%\n",
      "Epoch [116/300], Step [95/225], Training Accuracy: 98.4868%, Training Loss: 0.0478%\n",
      "Epoch [116/300], Step [96/225], Training Accuracy: 98.4701%, Training Loss: 0.0480%\n",
      "Epoch [116/300], Step [97/225], Training Accuracy: 98.4536%, Training Loss: 0.0483%\n",
      "Epoch [116/300], Step [98/225], Training Accuracy: 98.4534%, Training Loss: 0.0484%\n",
      "Epoch [116/300], Step [99/225], Training Accuracy: 98.4691%, Training Loss: 0.0481%\n",
      "Epoch [116/300], Step [100/225], Training Accuracy: 98.4531%, Training Loss: 0.0484%\n",
      "Epoch [116/300], Step [101/225], Training Accuracy: 98.4684%, Training Loss: 0.0483%\n",
      "Epoch [116/300], Step [102/225], Training Accuracy: 98.4681%, Training Loss: 0.0483%\n",
      "Epoch [116/300], Step [103/225], Training Accuracy: 98.4375%, Training Loss: 0.0489%\n",
      "Epoch [116/300], Step [104/225], Training Accuracy: 98.4375%, Training Loss: 0.0487%\n",
      "Epoch [116/300], Step [105/225], Training Accuracy: 98.4226%, Training Loss: 0.0494%\n",
      "Epoch [116/300], Step [106/225], Training Accuracy: 98.4080%, Training Loss: 0.0495%\n",
      "Epoch [116/300], Step [107/225], Training Accuracy: 98.4229%, Training Loss: 0.0492%\n",
      "Epoch [116/300], Step [108/225], Training Accuracy: 98.4230%, Training Loss: 0.0490%\n",
      "Epoch [116/300], Step [109/225], Training Accuracy: 98.4375%, Training Loss: 0.0488%\n",
      "Epoch [116/300], Step [110/225], Training Accuracy: 98.4233%, Training Loss: 0.0491%\n",
      "Epoch [116/300], Step [111/225], Training Accuracy: 98.4234%, Training Loss: 0.0489%\n",
      "Epoch [116/300], Step [112/225], Training Accuracy: 98.4235%, Training Loss: 0.0491%\n",
      "Epoch [116/300], Step [113/225], Training Accuracy: 98.4098%, Training Loss: 0.0491%\n",
      "Epoch [116/300], Step [114/225], Training Accuracy: 98.3827%, Training Loss: 0.0498%\n",
      "Epoch [116/300], Step [115/225], Training Accuracy: 98.3696%, Training Loss: 0.0499%\n",
      "Epoch [116/300], Step [116/225], Training Accuracy: 98.3836%, Training Loss: 0.0498%\n",
      "Epoch [116/300], Step [117/225], Training Accuracy: 98.3841%, Training Loss: 0.0499%\n",
      "Epoch [116/300], Step [118/225], Training Accuracy: 98.3845%, Training Loss: 0.0501%\n",
      "Epoch [116/300], Step [119/225], Training Accuracy: 98.3981%, Training Loss: 0.0498%\n",
      "Epoch [116/300], Step [120/225], Training Accuracy: 98.3984%, Training Loss: 0.0497%\n",
      "Epoch [116/300], Step [121/225], Training Accuracy: 98.4117%, Training Loss: 0.0496%\n",
      "Epoch [116/300], Step [122/225], Training Accuracy: 98.3991%, Training Loss: 0.0497%\n",
      "Epoch [116/300], Step [123/225], Training Accuracy: 98.4121%, Training Loss: 0.0495%\n",
      "Epoch [116/300], Step [124/225], Training Accuracy: 98.4123%, Training Loss: 0.0500%\n",
      "Epoch [116/300], Step [125/225], Training Accuracy: 98.4000%, Training Loss: 0.0503%\n",
      "Epoch [116/300], Step [126/225], Training Accuracy: 98.4003%, Training Loss: 0.0502%\n",
      "Epoch [116/300], Step [127/225], Training Accuracy: 98.3883%, Training Loss: 0.0503%\n",
      "Epoch [116/300], Step [128/225], Training Accuracy: 98.3887%, Training Loss: 0.0502%\n",
      "Epoch [116/300], Step [129/225], Training Accuracy: 98.3891%, Training Loss: 0.0501%\n",
      "Epoch [116/300], Step [130/225], Training Accuracy: 98.3654%, Training Loss: 0.0504%\n",
      "Epoch [116/300], Step [131/225], Training Accuracy: 98.3540%, Training Loss: 0.0505%\n",
      "Epoch [116/300], Step [132/225], Training Accuracy: 98.3428%, Training Loss: 0.0509%\n",
      "Epoch [116/300], Step [133/225], Training Accuracy: 98.3553%, Training Loss: 0.0506%\n",
      "Epoch [116/300], Step [134/225], Training Accuracy: 98.3559%, Training Loss: 0.0505%\n",
      "Epoch [116/300], Step [135/225], Training Accuracy: 98.3681%, Training Loss: 0.0503%\n",
      "Epoch [116/300], Step [136/225], Training Accuracy: 98.3686%, Training Loss: 0.0503%\n",
      "Epoch [116/300], Step [137/225], Training Accuracy: 98.3577%, Training Loss: 0.0503%\n",
      "Epoch [116/300], Step [138/225], Training Accuracy: 98.3696%, Training Loss: 0.0501%\n",
      "Epoch [116/300], Step [139/225], Training Accuracy: 98.3701%, Training Loss: 0.0502%\n",
      "Epoch [116/300], Step [140/225], Training Accuracy: 98.3817%, Training Loss: 0.0500%\n",
      "Epoch [116/300], Step [141/225], Training Accuracy: 98.3821%, Training Loss: 0.0499%\n",
      "Epoch [116/300], Step [142/225], Training Accuracy: 98.3935%, Training Loss: 0.0497%\n",
      "Epoch [116/300], Step [143/225], Training Accuracy: 98.4047%, Training Loss: 0.0497%\n",
      "Epoch [116/300], Step [144/225], Training Accuracy: 98.4158%, Training Loss: 0.0495%\n",
      "Epoch [116/300], Step [145/225], Training Accuracy: 98.4159%, Training Loss: 0.0494%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [116/300], Step [146/225], Training Accuracy: 98.4161%, Training Loss: 0.0494%\n",
      "Epoch [116/300], Step [147/225], Training Accuracy: 98.4056%, Training Loss: 0.0494%\n",
      "Epoch [116/300], Step [148/225], Training Accuracy: 98.4164%, Training Loss: 0.0494%\n",
      "Epoch [116/300], Step [149/225], Training Accuracy: 98.3956%, Training Loss: 0.0499%\n",
      "Epoch [116/300], Step [150/225], Training Accuracy: 98.4062%, Training Loss: 0.0497%\n",
      "Epoch [116/300], Step [151/225], Training Accuracy: 98.4168%, Training Loss: 0.0496%\n",
      "Epoch [116/300], Step [152/225], Training Accuracy: 98.4272%, Training Loss: 0.0494%\n",
      "Epoch [116/300], Step [153/225], Training Accuracy: 98.4171%, Training Loss: 0.0494%\n",
      "Epoch [116/300], Step [154/225], Training Accuracy: 98.4274%, Training Loss: 0.0493%\n",
      "Epoch [116/300], Step [155/225], Training Accuracy: 98.4375%, Training Loss: 0.0491%\n",
      "Epoch [116/300], Step [156/225], Training Accuracy: 98.4475%, Training Loss: 0.0488%\n",
      "Epoch [116/300], Step [157/225], Training Accuracy: 98.4475%, Training Loss: 0.0488%\n",
      "Epoch [116/300], Step [158/225], Training Accuracy: 98.4573%, Training Loss: 0.0486%\n",
      "Epoch [116/300], Step [159/225], Training Accuracy: 98.4473%, Training Loss: 0.0487%\n",
      "Epoch [116/300], Step [160/225], Training Accuracy: 98.4570%, Training Loss: 0.0485%\n",
      "Epoch [116/300], Step [161/225], Training Accuracy: 98.4569%, Training Loss: 0.0483%\n",
      "Epoch [116/300], Step [162/225], Training Accuracy: 98.4568%, Training Loss: 0.0484%\n",
      "Epoch [116/300], Step [163/225], Training Accuracy: 98.4567%, Training Loss: 0.0483%\n",
      "Epoch [116/300], Step [164/225], Training Accuracy: 98.4566%, Training Loss: 0.0483%\n",
      "Epoch [116/300], Step [165/225], Training Accuracy: 98.4659%, Training Loss: 0.0481%\n",
      "Epoch [116/300], Step [166/225], Training Accuracy: 98.4752%, Training Loss: 0.0481%\n",
      "Epoch [116/300], Step [167/225], Training Accuracy: 98.4749%, Training Loss: 0.0483%\n",
      "Epoch [116/300], Step [168/225], Training Accuracy: 98.4840%, Training Loss: 0.0481%\n",
      "Epoch [116/300], Step [169/225], Training Accuracy: 98.4930%, Training Loss: 0.0480%\n",
      "Epoch [116/300], Step [170/225], Training Accuracy: 98.5018%, Training Loss: 0.0479%\n",
      "Epoch [116/300], Step [171/225], Training Accuracy: 98.5015%, Training Loss: 0.0478%\n",
      "Epoch [116/300], Step [172/225], Training Accuracy: 98.4920%, Training Loss: 0.0479%\n",
      "Epoch [116/300], Step [173/225], Training Accuracy: 98.4917%, Training Loss: 0.0478%\n",
      "Epoch [116/300], Step [174/225], Training Accuracy: 98.5004%, Training Loss: 0.0477%\n",
      "Epoch [116/300], Step [175/225], Training Accuracy: 98.5089%, Training Loss: 0.0476%\n",
      "Epoch [116/300], Step [176/225], Training Accuracy: 98.5085%, Training Loss: 0.0475%\n",
      "Epoch [116/300], Step [177/225], Training Accuracy: 98.5169%, Training Loss: 0.0473%\n",
      "Epoch [116/300], Step [178/225], Training Accuracy: 98.5165%, Training Loss: 0.0473%\n",
      "Epoch [116/300], Step [179/225], Training Accuracy: 98.5248%, Training Loss: 0.0471%\n",
      "Epoch [116/300], Step [180/225], Training Accuracy: 98.5330%, Training Loss: 0.0470%\n",
      "Epoch [116/300], Step [181/225], Training Accuracy: 98.5411%, Training Loss: 0.0468%\n",
      "Epoch [116/300], Step [182/225], Training Accuracy: 98.5491%, Training Loss: 0.0468%\n",
      "Epoch [116/300], Step [183/225], Training Accuracy: 98.5570%, Training Loss: 0.0466%\n",
      "Epoch [116/300], Step [184/225], Training Accuracy: 98.5564%, Training Loss: 0.0467%\n",
      "Epoch [116/300], Step [185/225], Training Accuracy: 98.5557%, Training Loss: 0.0466%\n",
      "Epoch [116/300], Step [186/225], Training Accuracy: 98.5635%, Training Loss: 0.0465%\n",
      "Epoch [116/300], Step [187/225], Training Accuracy: 98.5712%, Training Loss: 0.0463%\n",
      "Epoch [116/300], Step [188/225], Training Accuracy: 98.5788%, Training Loss: 0.0462%\n",
      "Epoch [116/300], Step [189/225], Training Accuracy: 98.5780%, Training Loss: 0.0461%\n",
      "Epoch [116/300], Step [190/225], Training Accuracy: 98.5855%, Training Loss: 0.0461%\n",
      "Epoch [116/300], Step [191/225], Training Accuracy: 98.5929%, Training Loss: 0.0460%\n",
      "Epoch [116/300], Step [192/225], Training Accuracy: 98.5921%, Training Loss: 0.0461%\n",
      "Epoch [116/300], Step [193/225], Training Accuracy: 98.5913%, Training Loss: 0.0461%\n",
      "Epoch [116/300], Step [194/225], Training Accuracy: 98.5986%, Training Loss: 0.0460%\n",
      "Epoch [116/300], Step [195/225], Training Accuracy: 98.6058%, Training Loss: 0.0459%\n",
      "Epoch [116/300], Step [196/225], Training Accuracy: 98.6129%, Training Loss: 0.0457%\n",
      "Epoch [116/300], Step [197/225], Training Accuracy: 98.6199%, Training Loss: 0.0457%\n",
      "Epoch [116/300], Step [198/225], Training Accuracy: 98.6269%, Training Loss: 0.0456%\n",
      "Epoch [116/300], Step [199/225], Training Accuracy: 98.6259%, Training Loss: 0.0456%\n",
      "Epoch [116/300], Step [200/225], Training Accuracy: 98.6250%, Training Loss: 0.0460%\n",
      "Epoch [116/300], Step [201/225], Training Accuracy: 98.6318%, Training Loss: 0.0460%\n",
      "Epoch [116/300], Step [202/225], Training Accuracy: 98.6309%, Training Loss: 0.0461%\n",
      "Epoch [116/300], Step [203/225], Training Accuracy: 98.6376%, Training Loss: 0.0459%\n",
      "Epoch [116/300], Step [204/225], Training Accuracy: 98.6366%, Training Loss: 0.0459%\n",
      "Epoch [116/300], Step [205/225], Training Accuracy: 98.6433%, Training Loss: 0.0458%\n",
      "Epoch [116/300], Step [206/225], Training Accuracy: 98.6499%, Training Loss: 0.0456%\n",
      "Epoch [116/300], Step [207/225], Training Accuracy: 98.6564%, Training Loss: 0.0455%\n",
      "Epoch [116/300], Step [208/225], Training Accuracy: 98.6553%, Training Loss: 0.0455%\n",
      "Epoch [116/300], Step [209/225], Training Accuracy: 98.6618%, Training Loss: 0.0454%\n",
      "Epoch [116/300], Step [210/225], Training Accuracy: 98.6384%, Training Loss: 0.0458%\n",
      "Epoch [116/300], Step [211/225], Training Accuracy: 98.6374%, Training Loss: 0.0458%\n",
      "Epoch [116/300], Step [212/225], Training Accuracy: 98.6365%, Training Loss: 0.0458%\n",
      "Epoch [116/300], Step [213/225], Training Accuracy: 98.6429%, Training Loss: 0.0458%\n",
      "Epoch [116/300], Step [214/225], Training Accuracy: 98.6419%, Training Loss: 0.0457%\n",
      "Epoch [116/300], Step [215/225], Training Accuracy: 98.6410%, Training Loss: 0.0456%\n",
      "Epoch [116/300], Step [216/225], Training Accuracy: 98.6183%, Training Loss: 0.0461%\n",
      "Epoch [116/300], Step [217/225], Training Accuracy: 98.6103%, Training Loss: 0.0463%\n",
      "Epoch [116/300], Step [218/225], Training Accuracy: 98.6167%, Training Loss: 0.0462%\n",
      "Epoch [116/300], Step [219/225], Training Accuracy: 98.6087%, Training Loss: 0.0463%\n",
      "Epoch [116/300], Step [220/225], Training Accuracy: 98.6151%, Training Loss: 0.0462%\n",
      "Epoch [116/300], Step [221/225], Training Accuracy: 98.6213%, Training Loss: 0.0461%\n",
      "Epoch [116/300], Step [222/225], Training Accuracy: 98.6275%, Training Loss: 0.0460%\n",
      "Epoch [116/300], Step [223/225], Training Accuracy: 98.6197%, Training Loss: 0.0461%\n",
      "Epoch [116/300], Step [224/225], Training Accuracy: 98.6258%, Training Loss: 0.0459%\n",
      "Epoch [116/300], Step [225/225], Training Accuracy: 98.6312%, Training Loss: 0.0457%\n",
      "Epoch [117/300], Step [1/225], Training Accuracy: 98.4375%, Training Loss: 0.0468%\n",
      "Epoch [117/300], Step [2/225], Training Accuracy: 99.2188%, Training Loss: 0.0372%\n",
      "Epoch [117/300], Step [3/225], Training Accuracy: 98.4375%, Training Loss: 0.0469%\n",
      "Epoch [117/300], Step [4/225], Training Accuracy: 98.4375%, Training Loss: 0.0462%\n",
      "Epoch [117/300], Step [5/225], Training Accuracy: 97.8125%, Training Loss: 0.0566%\n",
      "Epoch [117/300], Step [6/225], Training Accuracy: 98.1771%, Training Loss: 0.0500%\n",
      "Epoch [117/300], Step [7/225], Training Accuracy: 97.9911%, Training Loss: 0.0537%\n",
      "Epoch [117/300], Step [8/225], Training Accuracy: 98.2422%, Training Loss: 0.0485%\n",
      "Epoch [117/300], Step [9/225], Training Accuracy: 98.4375%, Training Loss: 0.0456%\n",
      "Epoch [117/300], Step [10/225], Training Accuracy: 98.5938%, Training Loss: 0.0435%\n",
      "Epoch [117/300], Step [11/225], Training Accuracy: 98.7216%, Training Loss: 0.0409%\n",
      "Epoch [117/300], Step [12/225], Training Accuracy: 98.5677%, Training Loss: 0.0476%\n",
      "Epoch [117/300], Step [13/225], Training Accuracy: 98.5577%, Training Loss: 0.0464%\n",
      "Epoch [117/300], Step [14/225], Training Accuracy: 98.5491%, Training Loss: 0.0463%\n",
      "Epoch [117/300], Step [15/225], Training Accuracy: 98.5417%, Training Loss: 0.0468%\n",
      "Epoch [117/300], Step [16/225], Training Accuracy: 98.6328%, Training Loss: 0.0453%\n",
      "Epoch [117/300], Step [17/225], Training Accuracy: 98.6213%, Training Loss: 0.0465%\n",
      "Epoch [117/300], Step [18/225], Training Accuracy: 98.6111%, Training Loss: 0.0479%\n",
      "Epoch [117/300], Step [19/225], Training Accuracy: 98.6842%, Training Loss: 0.0460%\n",
      "Epoch [117/300], Step [20/225], Training Accuracy: 98.6719%, Training Loss: 0.0451%\n",
      "Epoch [117/300], Step [21/225], Training Accuracy: 98.7351%, Training Loss: 0.0446%\n",
      "Epoch [117/300], Step [22/225], Training Accuracy: 98.7216%, Training Loss: 0.0444%\n",
      "Epoch [117/300], Step [23/225], Training Accuracy: 98.7772%, Training Loss: 0.0428%\n",
      "Epoch [117/300], Step [24/225], Training Accuracy: 98.7630%, Training Loss: 0.0426%\n",
      "Epoch [117/300], Step [25/225], Training Accuracy: 98.7500%, Training Loss: 0.0421%\n",
      "Epoch [117/300], Step [26/225], Training Accuracy: 98.7380%, Training Loss: 0.0423%\n",
      "Epoch [117/300], Step [27/225], Training Accuracy: 98.7847%, Training Loss: 0.0419%\n",
      "Epoch [117/300], Step [28/225], Training Accuracy: 98.7723%, Training Loss: 0.0421%\n",
      "Epoch [117/300], Step [29/225], Training Accuracy: 98.6530%, Training Loss: 0.0446%\n",
      "Epoch [117/300], Step [30/225], Training Accuracy: 98.6458%, Training Loss: 0.0447%\n",
      "Epoch [117/300], Step [31/225], Training Accuracy: 98.6895%, Training Loss: 0.0443%\n",
      "Epoch [117/300], Step [32/225], Training Accuracy: 98.7305%, Training Loss: 0.0433%\n",
      "Epoch [117/300], Step [33/225], Training Accuracy: 98.7689%, Training Loss: 0.0426%\n",
      "Epoch [117/300], Step [34/225], Training Accuracy: 98.7132%, Training Loss: 0.0429%\n",
      "Epoch [117/300], Step [35/225], Training Accuracy: 98.7500%, Training Loss: 0.0427%\n",
      "Epoch [117/300], Step [36/225], Training Accuracy: 98.6979%, Training Loss: 0.0450%\n",
      "Epoch [117/300], Step [37/225], Training Accuracy: 98.6909%, Training Loss: 0.0446%\n",
      "Epoch [117/300], Step [38/225], Training Accuracy: 98.6431%, Training Loss: 0.0458%\n",
      "Epoch [117/300], Step [39/225], Training Accuracy: 98.5978%, Training Loss: 0.0464%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [117/300], Step [40/225], Training Accuracy: 98.5938%, Training Loss: 0.0466%\n",
      "Epoch [117/300], Step [41/225], Training Accuracy: 98.5899%, Training Loss: 0.0466%\n",
      "Epoch [117/300], Step [42/225], Training Accuracy: 98.6235%, Training Loss: 0.0458%\n",
      "Epoch [117/300], Step [43/225], Training Accuracy: 98.6192%, Training Loss: 0.0453%\n",
      "Epoch [117/300], Step [44/225], Training Accuracy: 98.6506%, Training Loss: 0.0447%\n",
      "Epoch [117/300], Step [45/225], Training Accuracy: 98.6458%, Training Loss: 0.0448%\n",
      "Epoch [117/300], Step [46/225], Training Accuracy: 98.6413%, Training Loss: 0.0449%\n",
      "Epoch [117/300], Step [47/225], Training Accuracy: 98.6037%, Training Loss: 0.0457%\n",
      "Epoch [117/300], Step [48/225], Training Accuracy: 98.6003%, Training Loss: 0.0453%\n",
      "Epoch [117/300], Step [49/225], Training Accuracy: 98.5969%, Training Loss: 0.0453%\n",
      "Epoch [117/300], Step [50/225], Training Accuracy: 98.5938%, Training Loss: 0.0452%\n",
      "Epoch [117/300], Step [51/225], Training Accuracy: 98.5600%, Training Loss: 0.0453%\n",
      "Epoch [117/300], Step [52/225], Training Accuracy: 98.5276%, Training Loss: 0.0456%\n",
      "Epoch [117/300], Step [53/225], Training Accuracy: 98.4670%, Training Loss: 0.0470%\n",
      "Epoch [117/300], Step [54/225], Training Accuracy: 98.4954%, Training Loss: 0.0464%\n",
      "Epoch [117/300], Step [55/225], Training Accuracy: 98.4943%, Training Loss: 0.0462%\n",
      "Epoch [117/300], Step [56/225], Training Accuracy: 98.4933%, Training Loss: 0.0462%\n",
      "Epoch [117/300], Step [57/225], Training Accuracy: 98.5197%, Training Loss: 0.0458%\n",
      "Epoch [117/300], Step [58/225], Training Accuracy: 98.4914%, Training Loss: 0.0459%\n",
      "Epoch [117/300], Step [59/225], Training Accuracy: 98.4905%, Training Loss: 0.0462%\n",
      "Epoch [117/300], Step [60/225], Training Accuracy: 98.4375%, Training Loss: 0.0464%\n",
      "Epoch [117/300], Step [61/225], Training Accuracy: 98.4375%, Training Loss: 0.0465%\n",
      "Epoch [117/300], Step [62/225], Training Accuracy: 98.4375%, Training Loss: 0.0463%\n",
      "Epoch [117/300], Step [63/225], Training Accuracy: 98.4375%, Training Loss: 0.0462%\n",
      "Epoch [117/300], Step [64/225], Training Accuracy: 98.4619%, Training Loss: 0.0458%\n",
      "Epoch [117/300], Step [65/225], Training Accuracy: 98.4615%, Training Loss: 0.0456%\n",
      "Epoch [117/300], Step [66/225], Training Accuracy: 98.4612%, Training Loss: 0.0461%\n",
      "Epoch [117/300], Step [67/225], Training Accuracy: 98.4375%, Training Loss: 0.0465%\n",
      "Epoch [117/300], Step [68/225], Training Accuracy: 98.4605%, Training Loss: 0.0464%\n",
      "Epoch [117/300], Step [69/225], Training Accuracy: 98.4601%, Training Loss: 0.0462%\n",
      "Epoch [117/300], Step [70/225], Training Accuracy: 98.4375%, Training Loss: 0.0466%\n",
      "Epoch [117/300], Step [71/225], Training Accuracy: 98.4155%, Training Loss: 0.0465%\n",
      "Epoch [117/300], Step [72/225], Training Accuracy: 98.4375%, Training Loss: 0.0461%\n",
      "Epoch [117/300], Step [73/225], Training Accuracy: 98.4375%, Training Loss: 0.0466%\n",
      "Epoch [117/300], Step [74/225], Training Accuracy: 98.4586%, Training Loss: 0.0462%\n",
      "Epoch [117/300], Step [75/225], Training Accuracy: 98.4792%, Training Loss: 0.0460%\n",
      "Epoch [117/300], Step [76/225], Training Accuracy: 98.4375%, Training Loss: 0.0469%\n",
      "Epoch [117/300], Step [77/225], Training Accuracy: 98.4578%, Training Loss: 0.0468%\n",
      "Epoch [117/300], Step [78/225], Training Accuracy: 98.4575%, Training Loss: 0.0466%\n",
      "Epoch [117/300], Step [79/225], Training Accuracy: 98.4177%, Training Loss: 0.0469%\n",
      "Epoch [117/300], Step [80/225], Training Accuracy: 98.4375%, Training Loss: 0.0466%\n",
      "Epoch [117/300], Step [81/225], Training Accuracy: 98.4375%, Training Loss: 0.0464%\n",
      "Epoch [117/300], Step [82/225], Training Accuracy: 98.4375%, Training Loss: 0.0465%\n",
      "Epoch [117/300], Step [83/225], Training Accuracy: 98.4563%, Training Loss: 0.0462%\n",
      "Epoch [117/300], Step [84/225], Training Accuracy: 98.4561%, Training Loss: 0.0463%\n",
      "Epoch [117/300], Step [85/225], Training Accuracy: 98.4559%, Training Loss: 0.0463%\n",
      "Epoch [117/300], Step [86/225], Training Accuracy: 98.4375%, Training Loss: 0.0464%\n",
      "Epoch [117/300], Step [87/225], Training Accuracy: 98.4375%, Training Loss: 0.0465%\n",
      "Epoch [117/300], Step [88/225], Training Accuracy: 98.4553%, Training Loss: 0.0462%\n",
      "Epoch [117/300], Step [89/225], Training Accuracy: 98.4375%, Training Loss: 0.0466%\n",
      "Epoch [117/300], Step [90/225], Training Accuracy: 98.4201%, Training Loss: 0.0467%\n",
      "Epoch [117/300], Step [91/225], Training Accuracy: 98.4203%, Training Loss: 0.0469%\n",
      "Epoch [117/300], Step [92/225], Training Accuracy: 98.4375%, Training Loss: 0.0468%\n",
      "Epoch [117/300], Step [93/225], Training Accuracy: 98.4375%, Training Loss: 0.0468%\n",
      "Epoch [117/300], Step [94/225], Training Accuracy: 98.4375%, Training Loss: 0.0468%\n",
      "Epoch [117/300], Step [95/225], Training Accuracy: 98.4375%, Training Loss: 0.0468%\n",
      "Epoch [117/300], Step [96/225], Training Accuracy: 98.4538%, Training Loss: 0.0464%\n",
      "Epoch [117/300], Step [97/225], Training Accuracy: 98.4697%, Training Loss: 0.0463%\n",
      "Epoch [117/300], Step [98/225], Training Accuracy: 98.4853%, Training Loss: 0.0462%\n",
      "Epoch [117/300], Step [99/225], Training Accuracy: 98.5006%, Training Loss: 0.0459%\n",
      "Epoch [117/300], Step [100/225], Training Accuracy: 98.4844%, Training Loss: 0.0461%\n",
      "Epoch [117/300], Step [101/225], Training Accuracy: 98.4994%, Training Loss: 0.0459%\n",
      "Epoch [117/300], Step [102/225], Training Accuracy: 98.4988%, Training Loss: 0.0459%\n",
      "Epoch [117/300], Step [103/225], Training Accuracy: 98.4982%, Training Loss: 0.0460%\n",
      "Epoch [117/300], Step [104/225], Training Accuracy: 98.5126%, Training Loss: 0.0460%\n",
      "Epoch [117/300], Step [105/225], Training Accuracy: 98.4970%, Training Loss: 0.0462%\n",
      "Epoch [117/300], Step [106/225], Training Accuracy: 98.4817%, Training Loss: 0.0464%\n",
      "Epoch [117/300], Step [107/225], Training Accuracy: 98.4813%, Training Loss: 0.0465%\n",
      "Epoch [117/300], Step [108/225], Training Accuracy: 98.4664%, Training Loss: 0.0467%\n",
      "Epoch [117/300], Step [109/225], Training Accuracy: 98.4662%, Training Loss: 0.0467%\n",
      "Epoch [117/300], Step [110/225], Training Accuracy: 98.4801%, Training Loss: 0.0465%\n",
      "Epoch [117/300], Step [111/225], Training Accuracy: 98.4938%, Training Loss: 0.0464%\n",
      "Epoch [117/300], Step [112/225], Training Accuracy: 98.4933%, Training Loss: 0.0463%\n",
      "Epoch [117/300], Step [113/225], Training Accuracy: 98.4790%, Training Loss: 0.0464%\n",
      "Epoch [117/300], Step [114/225], Training Accuracy: 98.4923%, Training Loss: 0.0464%\n",
      "Epoch [117/300], Step [115/225], Training Accuracy: 98.4783%, Training Loss: 0.0467%\n",
      "Epoch [117/300], Step [116/225], Training Accuracy: 98.4644%, Training Loss: 0.0467%\n",
      "Epoch [117/300], Step [117/225], Training Accuracy: 98.4776%, Training Loss: 0.0465%\n",
      "Epoch [117/300], Step [118/225], Training Accuracy: 98.4905%, Training Loss: 0.0463%\n",
      "Epoch [117/300], Step [119/225], Training Accuracy: 98.4638%, Training Loss: 0.0465%\n",
      "Epoch [117/300], Step [120/225], Training Accuracy: 98.4635%, Training Loss: 0.0466%\n",
      "Epoch [117/300], Step [121/225], Training Accuracy: 98.4762%, Training Loss: 0.0464%\n",
      "Epoch [117/300], Step [122/225], Training Accuracy: 98.4759%, Training Loss: 0.0464%\n",
      "Epoch [117/300], Step [123/225], Training Accuracy: 98.4883%, Training Loss: 0.0462%\n",
      "Epoch [117/300], Step [124/225], Training Accuracy: 98.4879%, Training Loss: 0.0462%\n",
      "Epoch [117/300], Step [125/225], Training Accuracy: 98.4875%, Training Loss: 0.0462%\n",
      "Epoch [117/300], Step [126/225], Training Accuracy: 98.4375%, Training Loss: 0.0470%\n",
      "Epoch [117/300], Step [127/225], Training Accuracy: 98.4375%, Training Loss: 0.0470%\n",
      "Epoch [117/300], Step [128/225], Training Accuracy: 98.4253%, Training Loss: 0.0472%\n",
      "Epoch [117/300], Step [129/225], Training Accuracy: 98.4375%, Training Loss: 0.0469%\n",
      "Epoch [117/300], Step [130/225], Training Accuracy: 98.4375%, Training Loss: 0.0470%\n",
      "Epoch [117/300], Step [131/225], Training Accuracy: 98.4494%, Training Loss: 0.0468%\n",
      "Epoch [117/300], Step [132/225], Training Accuracy: 98.4493%, Training Loss: 0.0467%\n",
      "Epoch [117/300], Step [133/225], Training Accuracy: 98.4375%, Training Loss: 0.0467%\n",
      "Epoch [117/300], Step [134/225], Training Accuracy: 98.4375%, Training Loss: 0.0467%\n",
      "Epoch [117/300], Step [135/225], Training Accuracy: 98.4375%, Training Loss: 0.0466%\n",
      "Epoch [117/300], Step [136/225], Training Accuracy: 98.4490%, Training Loss: 0.0464%\n",
      "Epoch [117/300], Step [137/225], Training Accuracy: 98.4489%, Training Loss: 0.0464%\n",
      "Epoch [117/300], Step [138/225], Training Accuracy: 98.4262%, Training Loss: 0.0464%\n",
      "Epoch [117/300], Step [139/225], Training Accuracy: 98.4375%, Training Loss: 0.0462%\n",
      "Epoch [117/300], Step [140/225], Training Accuracy: 98.4487%, Training Loss: 0.0461%\n",
      "Epoch [117/300], Step [141/225], Training Accuracy: 98.4486%, Training Loss: 0.0462%\n",
      "Epoch [117/300], Step [142/225], Training Accuracy: 98.4485%, Training Loss: 0.0461%\n",
      "Epoch [117/300], Step [143/225], Training Accuracy: 98.4594%, Training Loss: 0.0459%\n",
      "Epoch [117/300], Step [144/225], Training Accuracy: 98.4592%, Training Loss: 0.0458%\n",
      "Epoch [117/300], Step [145/225], Training Accuracy: 98.4591%, Training Loss: 0.0459%\n",
      "Epoch [117/300], Step [146/225], Training Accuracy: 98.4589%, Training Loss: 0.0458%\n",
      "Epoch [117/300], Step [147/225], Training Accuracy: 98.4694%, Training Loss: 0.0456%\n",
      "Epoch [117/300], Step [148/225], Training Accuracy: 98.4797%, Training Loss: 0.0455%\n",
      "Epoch [117/300], Step [149/225], Training Accuracy: 98.4899%, Training Loss: 0.0455%\n",
      "Epoch [117/300], Step [150/225], Training Accuracy: 98.4792%, Training Loss: 0.0458%\n",
      "Epoch [117/300], Step [151/225], Training Accuracy: 98.4789%, Training Loss: 0.0457%\n",
      "Epoch [117/300], Step [152/225], Training Accuracy: 98.4786%, Training Loss: 0.0457%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [117/300], Step [153/225], Training Accuracy: 98.4783%, Training Loss: 0.0456%\n",
      "Epoch [117/300], Step [154/225], Training Accuracy: 98.4882%, Training Loss: 0.0455%\n",
      "Epoch [117/300], Step [155/225], Training Accuracy: 98.4778%, Training Loss: 0.0456%\n",
      "Epoch [117/300], Step [156/225], Training Accuracy: 98.4776%, Training Loss: 0.0456%\n",
      "Epoch [117/300], Step [157/225], Training Accuracy: 98.4674%, Training Loss: 0.0457%\n",
      "Epoch [117/300], Step [158/225], Training Accuracy: 98.4672%, Training Loss: 0.0457%\n",
      "Epoch [117/300], Step [159/225], Training Accuracy: 98.4572%, Training Loss: 0.0459%\n",
      "Epoch [117/300], Step [160/225], Training Accuracy: 98.4668%, Training Loss: 0.0457%\n",
      "Epoch [117/300], Step [161/225], Training Accuracy: 98.4666%, Training Loss: 0.0458%\n",
      "Epoch [117/300], Step [162/225], Training Accuracy: 98.4761%, Training Loss: 0.0456%\n",
      "Epoch [117/300], Step [163/225], Training Accuracy: 98.4758%, Training Loss: 0.0457%\n",
      "Epoch [117/300], Step [164/225], Training Accuracy: 98.4851%, Training Loss: 0.0456%\n",
      "Epoch [117/300], Step [165/225], Training Accuracy: 98.4659%, Training Loss: 0.0458%\n",
      "Epoch [117/300], Step [166/225], Training Accuracy: 98.4752%, Training Loss: 0.0457%\n",
      "Epoch [117/300], Step [167/225], Training Accuracy: 98.4749%, Training Loss: 0.0456%\n",
      "Epoch [117/300], Step [168/225], Training Accuracy: 98.4840%, Training Loss: 0.0456%\n",
      "Epoch [117/300], Step [169/225], Training Accuracy: 98.4837%, Training Loss: 0.0456%\n",
      "Epoch [117/300], Step [170/225], Training Accuracy: 98.4651%, Training Loss: 0.0459%\n",
      "Epoch [117/300], Step [171/225], Training Accuracy: 98.4649%, Training Loss: 0.0459%\n",
      "Epoch [117/300], Step [172/225], Training Accuracy: 98.4648%, Training Loss: 0.0458%\n",
      "Epoch [117/300], Step [173/225], Training Accuracy: 98.4736%, Training Loss: 0.0457%\n",
      "Epoch [117/300], Step [174/225], Training Accuracy: 98.4465%, Training Loss: 0.0458%\n",
      "Epoch [117/300], Step [175/225], Training Accuracy: 98.4554%, Training Loss: 0.0456%\n",
      "Epoch [117/300], Step [176/225], Training Accuracy: 98.4641%, Training Loss: 0.0455%\n",
      "Epoch [117/300], Step [177/225], Training Accuracy: 98.4552%, Training Loss: 0.0460%\n",
      "Epoch [117/300], Step [178/225], Training Accuracy: 98.4551%, Training Loss: 0.0460%\n",
      "Epoch [117/300], Step [179/225], Training Accuracy: 98.4637%, Training Loss: 0.0458%\n",
      "Epoch [117/300], Step [180/225], Training Accuracy: 98.4722%, Training Loss: 0.0456%\n",
      "Epoch [117/300], Step [181/225], Training Accuracy: 98.4807%, Training Loss: 0.0456%\n",
      "Epoch [117/300], Step [182/225], Training Accuracy: 98.4804%, Training Loss: 0.0456%\n",
      "Epoch [117/300], Step [183/225], Training Accuracy: 98.4887%, Training Loss: 0.0455%\n",
      "Epoch [117/300], Step [184/225], Training Accuracy: 98.4800%, Training Loss: 0.0456%\n",
      "Epoch [117/300], Step [185/225], Training Accuracy: 98.4882%, Training Loss: 0.0455%\n",
      "Epoch [117/300], Step [186/225], Training Accuracy: 98.4963%, Training Loss: 0.0454%\n",
      "Epoch [117/300], Step [187/225], Training Accuracy: 98.5043%, Training Loss: 0.0453%\n",
      "Epoch [117/300], Step [188/225], Training Accuracy: 98.5040%, Training Loss: 0.0453%\n",
      "Epoch [117/300], Step [189/225], Training Accuracy: 98.5036%, Training Loss: 0.0453%\n",
      "Epoch [117/300], Step [190/225], Training Accuracy: 98.5115%, Training Loss: 0.0452%\n",
      "Epoch [117/300], Step [191/225], Training Accuracy: 98.5111%, Training Loss: 0.0452%\n",
      "Epoch [117/300], Step [192/225], Training Accuracy: 98.5189%, Training Loss: 0.0451%\n",
      "Epoch [117/300], Step [193/225], Training Accuracy: 98.5185%, Training Loss: 0.0451%\n",
      "Epoch [117/300], Step [194/225], Training Accuracy: 98.5180%, Training Loss: 0.0451%\n",
      "Epoch [117/300], Step [195/225], Training Accuracy: 98.5176%, Training Loss: 0.0451%\n",
      "Epoch [117/300], Step [196/225], Training Accuracy: 98.5172%, Training Loss: 0.0450%\n",
      "Epoch [117/300], Step [197/225], Training Accuracy: 98.5089%, Training Loss: 0.0453%\n",
      "Epoch [117/300], Step [198/225], Training Accuracy: 98.5164%, Training Loss: 0.0452%\n",
      "Epoch [117/300], Step [199/225], Training Accuracy: 98.5003%, Training Loss: 0.0455%\n",
      "Epoch [117/300], Step [200/225], Training Accuracy: 98.5000%, Training Loss: 0.0455%\n",
      "Epoch [117/300], Step [201/225], Training Accuracy: 98.4997%, Training Loss: 0.0455%\n",
      "Epoch [117/300], Step [202/225], Training Accuracy: 98.5071%, Training Loss: 0.0455%\n",
      "Epoch [117/300], Step [203/225], Training Accuracy: 98.4991%, Training Loss: 0.0455%\n",
      "Epoch [117/300], Step [204/225], Training Accuracy: 98.4911%, Training Loss: 0.0455%\n",
      "Epoch [117/300], Step [205/225], Training Accuracy: 98.4985%, Training Loss: 0.0454%\n",
      "Epoch [117/300], Step [206/225], Training Accuracy: 98.5058%, Training Loss: 0.0453%\n",
      "Epoch [117/300], Step [207/225], Training Accuracy: 98.5130%, Training Loss: 0.0452%\n",
      "Epoch [117/300], Step [208/225], Training Accuracy: 98.5126%, Training Loss: 0.0453%\n",
      "Epoch [117/300], Step [209/225], Training Accuracy: 98.5197%, Training Loss: 0.0451%\n",
      "Epoch [117/300], Step [210/225], Training Accuracy: 98.5193%, Training Loss: 0.0451%\n",
      "Epoch [117/300], Step [211/225], Training Accuracy: 98.5264%, Training Loss: 0.0450%\n",
      "Epoch [117/300], Step [212/225], Training Accuracy: 98.5259%, Training Loss: 0.0449%\n",
      "Epoch [117/300], Step [213/225], Training Accuracy: 98.5329%, Training Loss: 0.0448%\n",
      "Epoch [117/300], Step [214/225], Training Accuracy: 98.5324%, Training Loss: 0.0450%\n",
      "Epoch [117/300], Step [215/225], Training Accuracy: 98.5392%, Training Loss: 0.0449%\n",
      "Epoch [117/300], Step [216/225], Training Accuracy: 98.5243%, Training Loss: 0.0451%\n",
      "Epoch [117/300], Step [217/225], Training Accuracy: 98.5311%, Training Loss: 0.0450%\n",
      "Epoch [117/300], Step [218/225], Training Accuracy: 98.5163%, Training Loss: 0.0451%\n",
      "Epoch [117/300], Step [219/225], Training Accuracy: 98.5160%, Training Loss: 0.0451%\n",
      "Epoch [117/300], Step [220/225], Training Accuracy: 98.5227%, Training Loss: 0.0451%\n",
      "Epoch [117/300], Step [221/225], Training Accuracy: 98.5223%, Training Loss: 0.0450%\n",
      "Epoch [117/300], Step [222/225], Training Accuracy: 98.5220%, Training Loss: 0.0452%\n",
      "Epoch [117/300], Step [223/225], Training Accuracy: 98.5216%, Training Loss: 0.0451%\n",
      "Epoch [117/300], Step [224/225], Training Accuracy: 98.5212%, Training Loss: 0.0451%\n",
      "Epoch [117/300], Step [225/225], Training Accuracy: 98.5270%, Training Loss: 0.0450%\n",
      "Epoch [118/300], Step [1/225], Training Accuracy: 98.4375%, Training Loss: 0.0338%\n",
      "Epoch [118/300], Step [2/225], Training Accuracy: 99.2188%, Training Loss: 0.0336%\n",
      "Epoch [118/300], Step [3/225], Training Accuracy: 98.9583%, Training Loss: 0.0334%\n",
      "Epoch [118/300], Step [4/225], Training Accuracy: 99.2188%, Training Loss: 0.0286%\n",
      "Epoch [118/300], Step [5/225], Training Accuracy: 99.0625%, Training Loss: 0.0323%\n",
      "Epoch [118/300], Step [6/225], Training Accuracy: 98.9583%, Training Loss: 0.0324%\n",
      "Epoch [118/300], Step [7/225], Training Accuracy: 98.4375%, Training Loss: 0.0365%\n",
      "Epoch [118/300], Step [8/225], Training Accuracy: 98.6328%, Training Loss: 0.0354%\n",
      "Epoch [118/300], Step [9/225], Training Accuracy: 98.7847%, Training Loss: 0.0329%\n",
      "Epoch [118/300], Step [10/225], Training Accuracy: 98.5938%, Training Loss: 0.0400%\n",
      "Epoch [118/300], Step [11/225], Training Accuracy: 98.7216%, Training Loss: 0.0376%\n",
      "Epoch [118/300], Step [12/225], Training Accuracy: 98.8281%, Training Loss: 0.0363%\n",
      "Epoch [118/300], Step [13/225], Training Accuracy: 98.9183%, Training Loss: 0.0359%\n",
      "Epoch [118/300], Step [14/225], Training Accuracy: 98.9955%, Training Loss: 0.0351%\n",
      "Epoch [118/300], Step [15/225], Training Accuracy: 99.0625%, Training Loss: 0.0338%\n",
      "Epoch [118/300], Step [16/225], Training Accuracy: 98.9258%, Training Loss: 0.0353%\n",
      "Epoch [118/300], Step [17/225], Training Accuracy: 98.8971%, Training Loss: 0.0357%\n",
      "Epoch [118/300], Step [18/225], Training Accuracy: 98.6979%, Training Loss: 0.0392%\n",
      "Epoch [118/300], Step [19/225], Training Accuracy: 98.6842%, Training Loss: 0.0403%\n",
      "Epoch [118/300], Step [20/225], Training Accuracy: 98.7500%, Training Loss: 0.0393%\n",
      "Epoch [118/300], Step [21/225], Training Accuracy: 98.7351%, Training Loss: 0.0401%\n",
      "Epoch [118/300], Step [22/225], Training Accuracy: 98.7926%, Training Loss: 0.0395%\n",
      "Epoch [118/300], Step [23/225], Training Accuracy: 98.7772%, Training Loss: 0.0399%\n",
      "Epoch [118/300], Step [24/225], Training Accuracy: 98.6979%, Training Loss: 0.0417%\n",
      "Epoch [118/300], Step [25/225], Training Accuracy: 98.6875%, Training Loss: 0.0414%\n",
      "Epoch [118/300], Step [26/225], Training Accuracy: 98.6178%, Training Loss: 0.0418%\n",
      "Epoch [118/300], Step [27/225], Training Accuracy: 98.6111%, Training Loss: 0.0426%\n",
      "Epoch [118/300], Step [28/225], Training Accuracy: 98.6049%, Training Loss: 0.0427%\n",
      "Epoch [118/300], Step [29/225], Training Accuracy: 98.6530%, Training Loss: 0.0432%\n",
      "Epoch [118/300], Step [30/225], Training Accuracy: 98.6458%, Training Loss: 0.0429%\n",
      "Epoch [118/300], Step [31/225], Training Accuracy: 98.6391%, Training Loss: 0.0431%\n",
      "Epoch [118/300], Step [32/225], Training Accuracy: 98.6328%, Training Loss: 0.0438%\n",
      "Epoch [118/300], Step [33/225], Training Accuracy: 98.6269%, Training Loss: 0.0436%\n",
      "Epoch [118/300], Step [34/225], Training Accuracy: 98.6213%, Training Loss: 0.0436%\n",
      "Epoch [118/300], Step [35/225], Training Accuracy: 98.6161%, Training Loss: 0.0450%\n",
      "Epoch [118/300], Step [36/225], Training Accuracy: 98.6111%, Training Loss: 0.0449%\n",
      "Epoch [118/300], Step [37/225], Training Accuracy: 98.6486%, Training Loss: 0.0442%\n",
      "Epoch [118/300], Step [38/225], Training Accuracy: 98.6020%, Training Loss: 0.0451%\n",
      "Epoch [118/300], Step [39/225], Training Accuracy: 98.5978%, Training Loss: 0.0451%\n",
      "Epoch [118/300], Step [40/225], Training Accuracy: 98.6328%, Training Loss: 0.0454%\n",
      "Epoch [118/300], Step [41/225], Training Accuracy: 98.5899%, Training Loss: 0.0464%\n",
      "Epoch [118/300], Step [42/225], Training Accuracy: 98.6235%, Training Loss: 0.0456%\n",
      "Epoch [118/300], Step [43/225], Training Accuracy: 98.4738%, Training Loss: 0.0503%\n",
      "Epoch [118/300], Step [44/225], Training Accuracy: 98.4375%, Training Loss: 0.0503%\n",
      "Epoch [118/300], Step [45/225], Training Accuracy: 98.4375%, Training Loss: 0.0498%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [118/300], Step [46/225], Training Accuracy: 98.4715%, Training Loss: 0.0491%\n",
      "Epoch [118/300], Step [47/225], Training Accuracy: 98.4707%, Training Loss: 0.0490%\n",
      "Epoch [118/300], Step [48/225], Training Accuracy: 98.5026%, Training Loss: 0.0486%\n",
      "Epoch [118/300], Step [49/225], Training Accuracy: 98.5332%, Training Loss: 0.0480%\n",
      "Epoch [118/300], Step [50/225], Training Accuracy: 98.5625%, Training Loss: 0.0474%\n",
      "Epoch [118/300], Step [51/225], Training Accuracy: 98.5600%, Training Loss: 0.0473%\n",
      "Epoch [118/300], Step [52/225], Training Accuracy: 98.5577%, Training Loss: 0.0470%\n",
      "Epoch [118/300], Step [53/225], Training Accuracy: 98.5554%, Training Loss: 0.0469%\n",
      "Epoch [118/300], Step [54/225], Training Accuracy: 98.4954%, Training Loss: 0.0488%\n",
      "Epoch [118/300], Step [55/225], Training Accuracy: 98.5227%, Training Loss: 0.0484%\n",
      "Epoch [118/300], Step [56/225], Training Accuracy: 98.5212%, Training Loss: 0.0487%\n",
      "Epoch [118/300], Step [57/225], Training Accuracy: 98.5197%, Training Loss: 0.0490%\n",
      "Epoch [118/300], Step [58/225], Training Accuracy: 98.4914%, Training Loss: 0.0489%\n",
      "Epoch [118/300], Step [59/225], Training Accuracy: 98.5169%, Training Loss: 0.0483%\n",
      "Epoch [118/300], Step [60/225], Training Accuracy: 98.5156%, Training Loss: 0.0481%\n",
      "Epoch [118/300], Step [61/225], Training Accuracy: 98.5400%, Training Loss: 0.0477%\n",
      "Epoch [118/300], Step [62/225], Training Accuracy: 98.4879%, Training Loss: 0.0480%\n",
      "Epoch [118/300], Step [63/225], Training Accuracy: 98.4623%, Training Loss: 0.0481%\n",
      "Epoch [118/300], Step [64/225], Training Accuracy: 98.4619%, Training Loss: 0.0478%\n",
      "Epoch [118/300], Step [65/225], Training Accuracy: 98.4856%, Training Loss: 0.0473%\n",
      "Epoch [118/300], Step [66/225], Training Accuracy: 98.4138%, Training Loss: 0.0485%\n",
      "Epoch [118/300], Step [67/225], Training Accuracy: 98.3675%, Training Loss: 0.0490%\n",
      "Epoch [118/300], Step [68/225], Training Accuracy: 98.3915%, Training Loss: 0.0485%\n",
      "Epoch [118/300], Step [69/225], Training Accuracy: 98.3922%, Training Loss: 0.0485%\n",
      "Epoch [118/300], Step [70/225], Training Accuracy: 98.4152%, Training Loss: 0.0482%\n",
      "Epoch [118/300], Step [71/225], Training Accuracy: 98.3935%, Training Loss: 0.0486%\n",
      "Epoch [118/300], Step [72/225], Training Accuracy: 98.3724%, Training Loss: 0.0494%\n",
      "Epoch [118/300], Step [73/225], Training Accuracy: 98.3947%, Training Loss: 0.0492%\n",
      "Epoch [118/300], Step [74/225], Training Accuracy: 98.4164%, Training Loss: 0.0487%\n",
      "Epoch [118/300], Step [75/225], Training Accuracy: 98.4167%, Training Loss: 0.0488%\n",
      "Epoch [118/300], Step [76/225], Training Accuracy: 98.4375%, Training Loss: 0.0486%\n",
      "Epoch [118/300], Step [77/225], Training Accuracy: 98.4172%, Training Loss: 0.0488%\n",
      "Epoch [118/300], Step [78/225], Training Accuracy: 98.4175%, Training Loss: 0.0492%\n",
      "Epoch [118/300], Step [79/225], Training Accuracy: 98.4177%, Training Loss: 0.0490%\n",
      "Epoch [118/300], Step [80/225], Training Accuracy: 98.4375%, Training Loss: 0.0488%\n",
      "Epoch [118/300], Step [81/225], Training Accuracy: 98.4182%, Training Loss: 0.0497%\n",
      "Epoch [118/300], Step [82/225], Training Accuracy: 98.4375%, Training Loss: 0.0495%\n",
      "Epoch [118/300], Step [83/225], Training Accuracy: 98.4375%, Training Loss: 0.0497%\n",
      "Epoch [118/300], Step [84/225], Training Accuracy: 98.4561%, Training Loss: 0.0497%\n",
      "Epoch [118/300], Step [85/225], Training Accuracy: 98.4743%, Training Loss: 0.0494%\n",
      "Epoch [118/300], Step [86/225], Training Accuracy: 98.4738%, Training Loss: 0.0492%\n",
      "Epoch [118/300], Step [87/225], Training Accuracy: 98.4914%, Training Loss: 0.0489%\n",
      "Epoch [118/300], Step [88/225], Training Accuracy: 98.4730%, Training Loss: 0.0488%\n",
      "Epoch [118/300], Step [89/225], Training Accuracy: 98.4726%, Training Loss: 0.0488%\n",
      "Epoch [118/300], Step [90/225], Training Accuracy: 98.4896%, Training Loss: 0.0487%\n",
      "Epoch [118/300], Step [91/225], Training Accuracy: 98.5062%, Training Loss: 0.0482%\n",
      "Epoch [118/300], Step [92/225], Training Accuracy: 98.5054%, Training Loss: 0.0482%\n",
      "Epoch [118/300], Step [93/225], Training Accuracy: 98.5047%, Training Loss: 0.0482%\n",
      "Epoch [118/300], Step [94/225], Training Accuracy: 98.4874%, Training Loss: 0.0485%\n",
      "Epoch [118/300], Step [95/225], Training Accuracy: 98.4868%, Training Loss: 0.0485%\n",
      "Epoch [118/300], Step [96/225], Training Accuracy: 98.4863%, Training Loss: 0.0484%\n",
      "Epoch [118/300], Step [97/225], Training Accuracy: 98.4858%, Training Loss: 0.0485%\n",
      "Epoch [118/300], Step [98/225], Training Accuracy: 98.4694%, Training Loss: 0.0488%\n",
      "Epoch [118/300], Step [99/225], Training Accuracy: 98.4691%, Training Loss: 0.0487%\n",
      "Epoch [118/300], Step [100/225], Training Accuracy: 98.4531%, Training Loss: 0.0491%\n",
      "Epoch [118/300], Step [101/225], Training Accuracy: 98.4530%, Training Loss: 0.0491%\n",
      "Epoch [118/300], Step [102/225], Training Accuracy: 98.4375%, Training Loss: 0.0494%\n",
      "Epoch [118/300], Step [103/225], Training Accuracy: 98.4527%, Training Loss: 0.0490%\n",
      "Epoch [118/300], Step [104/225], Training Accuracy: 98.4675%, Training Loss: 0.0487%\n",
      "Epoch [118/300], Step [105/225], Training Accuracy: 98.4821%, Training Loss: 0.0484%\n",
      "Epoch [118/300], Step [106/225], Training Accuracy: 98.4670%, Training Loss: 0.0484%\n",
      "Epoch [118/300], Step [107/225], Training Accuracy: 98.4813%, Training Loss: 0.0483%\n",
      "Epoch [118/300], Step [108/225], Training Accuracy: 98.4954%, Training Loss: 0.0481%\n",
      "Epoch [118/300], Step [109/225], Training Accuracy: 98.4805%, Training Loss: 0.0482%\n",
      "Epoch [118/300], Step [110/225], Training Accuracy: 98.4659%, Training Loss: 0.0483%\n",
      "Epoch [118/300], Step [111/225], Training Accuracy: 98.4516%, Training Loss: 0.0484%\n",
      "Epoch [118/300], Step [112/225], Training Accuracy: 98.4654%, Training Loss: 0.0482%\n",
      "Epoch [118/300], Step [113/225], Training Accuracy: 98.4790%, Training Loss: 0.0478%\n",
      "Epoch [118/300], Step [114/225], Training Accuracy: 98.4786%, Training Loss: 0.0480%\n",
      "Epoch [118/300], Step [115/225], Training Accuracy: 98.4918%, Training Loss: 0.0479%\n",
      "Epoch [118/300], Step [116/225], Training Accuracy: 98.4914%, Training Loss: 0.0479%\n",
      "Epoch [118/300], Step [117/225], Training Accuracy: 98.4642%, Training Loss: 0.0483%\n",
      "Epoch [118/300], Step [118/225], Training Accuracy: 98.4772%, Training Loss: 0.0480%\n",
      "Epoch [118/300], Step [119/225], Training Accuracy: 98.4769%, Training Loss: 0.0482%\n",
      "Epoch [118/300], Step [120/225], Training Accuracy: 98.4896%, Training Loss: 0.0480%\n",
      "Epoch [118/300], Step [121/225], Training Accuracy: 98.5021%, Training Loss: 0.0477%\n",
      "Epoch [118/300], Step [122/225], Training Accuracy: 98.5015%, Training Loss: 0.0478%\n",
      "Epoch [118/300], Step [123/225], Training Accuracy: 98.5010%, Training Loss: 0.0479%\n",
      "Epoch [118/300], Step [124/225], Training Accuracy: 98.5131%, Training Loss: 0.0477%\n",
      "Epoch [118/300], Step [125/225], Training Accuracy: 98.5125%, Training Loss: 0.0478%\n",
      "Epoch [118/300], Step [126/225], Training Accuracy: 98.5119%, Training Loss: 0.0477%\n",
      "Epoch [118/300], Step [127/225], Training Accuracy: 98.5236%, Training Loss: 0.0477%\n",
      "Epoch [118/300], Step [128/225], Training Accuracy: 98.5229%, Training Loss: 0.0479%\n",
      "Epoch [118/300], Step [129/225], Training Accuracy: 98.5344%, Training Loss: 0.0477%\n",
      "Epoch [118/300], Step [130/225], Training Accuracy: 98.5337%, Training Loss: 0.0477%\n",
      "Epoch [118/300], Step [131/225], Training Accuracy: 98.5329%, Training Loss: 0.0477%\n",
      "Epoch [118/300], Step [132/225], Training Accuracy: 98.5204%, Training Loss: 0.0480%\n",
      "Epoch [118/300], Step [133/225], Training Accuracy: 98.5197%, Training Loss: 0.0478%\n",
      "Epoch [118/300], Step [134/225], Training Accuracy: 98.5308%, Training Loss: 0.0477%\n",
      "Epoch [118/300], Step [135/225], Training Accuracy: 98.5301%, Training Loss: 0.0476%\n",
      "Epoch [118/300], Step [136/225], Training Accuracy: 98.5294%, Training Loss: 0.0475%\n",
      "Epoch [118/300], Step [137/225], Training Accuracy: 98.5287%, Training Loss: 0.0475%\n",
      "Epoch [118/300], Step [138/225], Training Accuracy: 98.5394%, Training Loss: 0.0474%\n",
      "Epoch [118/300], Step [139/225], Training Accuracy: 98.5499%, Training Loss: 0.0472%\n",
      "Epoch [118/300], Step [140/225], Training Accuracy: 98.5379%, Training Loss: 0.0473%\n",
      "Epoch [118/300], Step [141/225], Training Accuracy: 98.5262%, Training Loss: 0.0474%\n",
      "Epoch [118/300], Step [142/225], Training Accuracy: 98.5255%, Training Loss: 0.0474%\n",
      "Epoch [118/300], Step [143/225], Training Accuracy: 98.5358%, Training Loss: 0.0472%\n",
      "Epoch [118/300], Step [144/225], Training Accuracy: 98.5460%, Training Loss: 0.0470%\n",
      "Epoch [118/300], Step [145/225], Training Accuracy: 98.5560%, Training Loss: 0.0469%\n",
      "Epoch [118/300], Step [146/225], Training Accuracy: 98.5445%, Training Loss: 0.0469%\n",
      "Epoch [118/300], Step [147/225], Training Accuracy: 98.5544%, Training Loss: 0.0467%\n",
      "Epoch [118/300], Step [148/225], Training Accuracy: 98.5536%, Training Loss: 0.0467%\n",
      "Epoch [118/300], Step [149/225], Training Accuracy: 98.5529%, Training Loss: 0.0471%\n",
      "Epoch [118/300], Step [150/225], Training Accuracy: 98.5521%, Training Loss: 0.0469%\n",
      "Epoch [118/300], Step [151/225], Training Accuracy: 98.5410%, Training Loss: 0.0469%\n",
      "Epoch [118/300], Step [152/225], Training Accuracy: 98.5506%, Training Loss: 0.0467%\n",
      "Epoch [118/300], Step [153/225], Training Accuracy: 98.5600%, Training Loss: 0.0465%\n",
      "Epoch [118/300], Step [154/225], Training Accuracy: 98.5491%, Training Loss: 0.0465%\n",
      "Epoch [118/300], Step [155/225], Training Accuracy: 98.5181%, Training Loss: 0.0469%\n",
      "Epoch [118/300], Step [156/225], Training Accuracy: 98.5176%, Training Loss: 0.0469%\n",
      "Epoch [118/300], Step [157/225], Training Accuracy: 98.5271%, Training Loss: 0.0467%\n",
      "Epoch [118/300], Step [158/225], Training Accuracy: 98.5067%, Training Loss: 0.0473%\n",
      "Epoch [118/300], Step [159/225], Training Accuracy: 98.5063%, Training Loss: 0.0472%\n",
      "Epoch [118/300], Step [160/225], Training Accuracy: 98.5059%, Training Loss: 0.0473%\n",
      "Epoch [118/300], Step [161/225], Training Accuracy: 98.4957%, Training Loss: 0.0474%\n",
      "Epoch [118/300], Step [162/225], Training Accuracy: 98.4857%, Training Loss: 0.0474%\n",
      "Epoch [118/300], Step [163/225], Training Accuracy: 98.4854%, Training Loss: 0.0476%\n",
      "Epoch [118/300], Step [164/225], Training Accuracy: 98.4851%, Training Loss: 0.0475%\n",
      "Epoch [118/300], Step [165/225], Training Accuracy: 98.4848%, Training Loss: 0.0479%\n",
      "Epoch [118/300], Step [166/225], Training Accuracy: 98.4752%, Training Loss: 0.0480%\n",
      "Epoch [118/300], Step [167/225], Training Accuracy: 98.4843%, Training Loss: 0.0478%\n",
      "Epoch [118/300], Step [168/225], Training Accuracy: 98.4840%, Training Loss: 0.0478%\n",
      "Epoch [118/300], Step [169/225], Training Accuracy: 98.4745%, Training Loss: 0.0479%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [118/300], Step [170/225], Training Accuracy: 98.4559%, Training Loss: 0.0483%\n",
      "Epoch [118/300], Step [171/225], Training Accuracy: 98.4649%, Training Loss: 0.0481%\n",
      "Epoch [118/300], Step [172/225], Training Accuracy: 98.4557%, Training Loss: 0.0483%\n",
      "Epoch [118/300], Step [173/225], Training Accuracy: 98.4646%, Training Loss: 0.0481%\n",
      "Epoch [118/300], Step [174/225], Training Accuracy: 98.4644%, Training Loss: 0.0481%\n",
      "Epoch [118/300], Step [175/225], Training Accuracy: 98.4732%, Training Loss: 0.0480%\n",
      "Epoch [118/300], Step [176/225], Training Accuracy: 98.4819%, Training Loss: 0.0478%\n",
      "Epoch [118/300], Step [177/225], Training Accuracy: 98.4728%, Training Loss: 0.0480%\n",
      "Epoch [118/300], Step [178/225], Training Accuracy: 98.4726%, Training Loss: 0.0480%\n",
      "Epoch [118/300], Step [179/225], Training Accuracy: 98.4724%, Training Loss: 0.0480%\n",
      "Epoch [118/300], Step [180/225], Training Accuracy: 98.4809%, Training Loss: 0.0479%\n",
      "Epoch [118/300], Step [181/225], Training Accuracy: 98.4720%, Training Loss: 0.0481%\n",
      "Epoch [118/300], Step [182/225], Training Accuracy: 98.4804%, Training Loss: 0.0480%\n",
      "Epoch [118/300], Step [183/225], Training Accuracy: 98.4887%, Training Loss: 0.0479%\n",
      "Epoch [118/300], Step [184/225], Training Accuracy: 98.4969%, Training Loss: 0.0478%\n",
      "Epoch [118/300], Step [185/225], Training Accuracy: 98.4966%, Training Loss: 0.0477%\n",
      "Epoch [118/300], Step [186/225], Training Accuracy: 98.4963%, Training Loss: 0.0476%\n",
      "Epoch [118/300], Step [187/225], Training Accuracy: 98.4793%, Training Loss: 0.0478%\n",
      "Epoch [118/300], Step [188/225], Training Accuracy: 98.4791%, Training Loss: 0.0477%\n",
      "Epoch [118/300], Step [189/225], Training Accuracy: 98.4788%, Training Loss: 0.0477%\n",
      "Epoch [118/300], Step [190/225], Training Accuracy: 98.4786%, Training Loss: 0.0477%\n",
      "Epoch [118/300], Step [191/225], Training Accuracy: 98.4784%, Training Loss: 0.0478%\n",
      "Epoch [118/300], Step [192/225], Training Accuracy: 98.4619%, Training Loss: 0.0478%\n",
      "Epoch [118/300], Step [193/225], Training Accuracy: 98.4537%, Training Loss: 0.0480%\n",
      "Epoch [118/300], Step [194/225], Training Accuracy: 98.4617%, Training Loss: 0.0479%\n",
      "Epoch [118/300], Step [195/225], Training Accuracy: 98.4615%, Training Loss: 0.0479%\n",
      "Epoch [118/300], Step [196/225], Training Accuracy: 98.4614%, Training Loss: 0.0479%\n",
      "Epoch [118/300], Step [197/225], Training Accuracy: 98.4613%, Training Loss: 0.0479%\n",
      "Epoch [118/300], Step [198/225], Training Accuracy: 98.4691%, Training Loss: 0.0478%\n",
      "Epoch [118/300], Step [199/225], Training Accuracy: 98.4689%, Training Loss: 0.0479%\n",
      "Epoch [118/300], Step [200/225], Training Accuracy: 98.4609%, Training Loss: 0.0479%\n",
      "Epoch [118/300], Step [201/225], Training Accuracy: 98.4686%, Training Loss: 0.0478%\n",
      "Epoch [118/300], Step [202/225], Training Accuracy: 98.4762%, Training Loss: 0.0477%\n",
      "Epoch [118/300], Step [203/225], Training Accuracy: 98.4683%, Training Loss: 0.0477%\n",
      "Epoch [118/300], Step [204/225], Training Accuracy: 98.4758%, Training Loss: 0.0475%\n",
      "Epoch [118/300], Step [205/225], Training Accuracy: 98.4832%, Training Loss: 0.0474%\n",
      "Epoch [118/300], Step [206/225], Training Accuracy: 98.4830%, Training Loss: 0.0476%\n",
      "Epoch [118/300], Step [207/225], Training Accuracy: 98.4828%, Training Loss: 0.0476%\n",
      "Epoch [118/300], Step [208/225], Training Accuracy: 98.4751%, Training Loss: 0.0477%\n",
      "Epoch [118/300], Step [209/225], Training Accuracy: 98.4674%, Training Loss: 0.0479%\n",
      "Epoch [118/300], Step [210/225], Training Accuracy: 98.4524%, Training Loss: 0.0482%\n",
      "Epoch [118/300], Step [211/225], Training Accuracy: 98.4523%, Training Loss: 0.0484%\n",
      "Epoch [118/300], Step [212/225], Training Accuracy: 98.4596%, Training Loss: 0.0483%\n",
      "Epoch [118/300], Step [213/225], Training Accuracy: 98.4522%, Training Loss: 0.0483%\n",
      "Epoch [118/300], Step [214/225], Training Accuracy: 98.4594%, Training Loss: 0.0481%\n",
      "Epoch [118/300], Step [215/225], Training Accuracy: 98.4593%, Training Loss: 0.0482%\n",
      "Epoch [118/300], Step [216/225], Training Accuracy: 98.4520%, Training Loss: 0.0484%\n",
      "Epoch [118/300], Step [217/225], Training Accuracy: 98.4591%, Training Loss: 0.0484%\n",
      "Epoch [118/300], Step [218/225], Training Accuracy: 98.4590%, Training Loss: 0.0484%\n",
      "Epoch [118/300], Step [219/225], Training Accuracy: 98.4589%, Training Loss: 0.0484%\n",
      "Epoch [118/300], Step [220/225], Training Accuracy: 98.4588%, Training Loss: 0.0483%\n",
      "Epoch [118/300], Step [221/225], Training Accuracy: 98.4587%, Training Loss: 0.0484%\n",
      "Epoch [118/300], Step [222/225], Training Accuracy: 98.4657%, Training Loss: 0.0483%\n",
      "Epoch [118/300], Step [223/225], Training Accuracy: 98.4655%, Training Loss: 0.0483%\n",
      "Epoch [118/300], Step [224/225], Training Accuracy: 98.4654%, Training Loss: 0.0483%\n",
      "Epoch [118/300], Step [225/225], Training Accuracy: 98.4644%, Training Loss: 0.0484%\n",
      "Epoch [119/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0313%\n",
      "Epoch [119/300], Step [2/225], Training Accuracy: 100.0000%, Training Loss: 0.0334%\n",
      "Epoch [119/300], Step [3/225], Training Accuracy: 99.4792%, Training Loss: 0.0335%\n",
      "Epoch [119/300], Step [4/225], Training Accuracy: 99.6094%, Training Loss: 0.0286%\n",
      "Epoch [119/300], Step [5/225], Training Accuracy: 99.3750%, Training Loss: 0.0324%\n",
      "Epoch [119/300], Step [6/225], Training Accuracy: 99.4792%, Training Loss: 0.0308%\n",
      "Epoch [119/300], Step [7/225], Training Accuracy: 99.5536%, Training Loss: 0.0297%\n",
      "Epoch [119/300], Step [8/225], Training Accuracy: 99.2188%, Training Loss: 0.0341%\n",
      "Epoch [119/300], Step [9/225], Training Accuracy: 99.1319%, Training Loss: 0.0368%\n",
      "Epoch [119/300], Step [10/225], Training Accuracy: 99.0625%, Training Loss: 0.0384%\n",
      "Epoch [119/300], Step [11/225], Training Accuracy: 98.8636%, Training Loss: 0.0414%\n",
      "Epoch [119/300], Step [12/225], Training Accuracy: 98.8281%, Training Loss: 0.0413%\n",
      "Epoch [119/300], Step [13/225], Training Accuracy: 98.9183%, Training Loss: 0.0405%\n",
      "Epoch [119/300], Step [14/225], Training Accuracy: 98.9955%, Training Loss: 0.0397%\n",
      "Epoch [119/300], Step [15/225], Training Accuracy: 98.9583%, Training Loss: 0.0410%\n",
      "Epoch [119/300], Step [16/225], Training Accuracy: 99.0234%, Training Loss: 0.0396%\n",
      "Epoch [119/300], Step [17/225], Training Accuracy: 99.0809%, Training Loss: 0.0391%\n",
      "Epoch [119/300], Step [18/225], Training Accuracy: 98.9583%, Training Loss: 0.0402%\n",
      "Epoch [119/300], Step [19/225], Training Accuracy: 99.0132%, Training Loss: 0.0390%\n",
      "Epoch [119/300], Step [20/225], Training Accuracy: 98.9062%, Training Loss: 0.0405%\n",
      "Epoch [119/300], Step [21/225], Training Accuracy: 98.8839%, Training Loss: 0.0405%\n",
      "Epoch [119/300], Step [22/225], Training Accuracy: 98.7926%, Training Loss: 0.0418%\n",
      "Epoch [119/300], Step [23/225], Training Accuracy: 98.8451%, Training Loss: 0.0405%\n",
      "Epoch [119/300], Step [24/225], Training Accuracy: 98.8281%, Training Loss: 0.0407%\n",
      "Epoch [119/300], Step [25/225], Training Accuracy: 98.8750%, Training Loss: 0.0400%\n",
      "Epoch [119/300], Step [26/225], Training Accuracy: 98.9183%, Training Loss: 0.0394%\n",
      "Epoch [119/300], Step [27/225], Training Accuracy: 98.9005%, Training Loss: 0.0398%\n",
      "Epoch [119/300], Step [28/225], Training Accuracy: 98.8839%, Training Loss: 0.0391%\n",
      "Epoch [119/300], Step [29/225], Training Accuracy: 98.7608%, Training Loss: 0.0411%\n",
      "Epoch [119/300], Step [30/225], Training Accuracy: 98.8021%, Training Loss: 0.0401%\n",
      "Epoch [119/300], Step [31/225], Training Accuracy: 98.7903%, Training Loss: 0.0400%\n",
      "Epoch [119/300], Step [32/225], Training Accuracy: 98.7305%, Training Loss: 0.0427%\n",
      "Epoch [119/300], Step [33/225], Training Accuracy: 98.7689%, Training Loss: 0.0420%\n",
      "Epoch [119/300], Step [34/225], Training Accuracy: 98.8051%, Training Loss: 0.0415%\n",
      "Epoch [119/300], Step [35/225], Training Accuracy: 98.8393%, Training Loss: 0.0405%\n",
      "Epoch [119/300], Step [36/225], Training Accuracy: 98.7413%, Training Loss: 0.0419%\n",
      "Epoch [119/300], Step [37/225], Training Accuracy: 98.7753%, Training Loss: 0.0417%\n",
      "Epoch [119/300], Step [38/225], Training Accuracy: 98.8076%, Training Loss: 0.0414%\n",
      "Epoch [119/300], Step [39/225], Training Accuracy: 98.7580%, Training Loss: 0.0427%\n",
      "Epoch [119/300], Step [40/225], Training Accuracy: 98.7500%, Training Loss: 0.0423%\n",
      "Epoch [119/300], Step [41/225], Training Accuracy: 98.7805%, Training Loss: 0.0420%\n",
      "Epoch [119/300], Step [42/225], Training Accuracy: 98.8095%, Training Loss: 0.0414%\n",
      "Epoch [119/300], Step [43/225], Training Accuracy: 98.8372%, Training Loss: 0.0412%\n",
      "Epoch [119/300], Step [44/225], Training Accuracy: 98.7926%, Training Loss: 0.0416%\n",
      "Epoch [119/300], Step [45/225], Training Accuracy: 98.7847%, Training Loss: 0.0415%\n",
      "Epoch [119/300], Step [46/225], Training Accuracy: 98.8111%, Training Loss: 0.0411%\n",
      "Epoch [119/300], Step [47/225], Training Accuracy: 98.8032%, Training Loss: 0.0416%\n",
      "Epoch [119/300], Step [48/225], Training Accuracy: 98.8281%, Training Loss: 0.0415%\n",
      "Epoch [119/300], Step [49/225], Training Accuracy: 98.8520%, Training Loss: 0.0412%\n",
      "Epoch [119/300], Step [50/225], Training Accuracy: 98.8750%, Training Loss: 0.0409%\n",
      "Epoch [119/300], Step [51/225], Training Accuracy: 98.8971%, Training Loss: 0.0405%\n",
      "Epoch [119/300], Step [52/225], Training Accuracy: 98.9183%, Training Loss: 0.0400%\n",
      "Epoch [119/300], Step [53/225], Training Accuracy: 98.9387%, Training Loss: 0.0397%\n",
      "Epoch [119/300], Step [54/225], Training Accuracy: 98.9005%, Training Loss: 0.0404%\n",
      "Epoch [119/300], Step [55/225], Training Accuracy: 98.9205%, Training Loss: 0.0404%\n",
      "Epoch [119/300], Step [56/225], Training Accuracy: 98.9118%, Training Loss: 0.0408%\n",
      "Epoch [119/300], Step [57/225], Training Accuracy: 98.9035%, Training Loss: 0.0409%\n",
      "Epoch [119/300], Step [58/225], Training Accuracy: 98.9224%, Training Loss: 0.0407%\n",
      "Epoch [119/300], Step [59/225], Training Accuracy: 98.9142%, Training Loss: 0.0409%\n",
      "Epoch [119/300], Step [60/225], Training Accuracy: 98.9323%, Training Loss: 0.0407%\n",
      "Epoch [119/300], Step [61/225], Training Accuracy: 98.9242%, Training Loss: 0.0410%\n",
      "Epoch [119/300], Step [62/225], Training Accuracy: 98.9415%, Training Loss: 0.0406%\n",
      "Epoch [119/300], Step [63/225], Training Accuracy: 98.9335%, Training Loss: 0.0409%\n",
      "Epoch [119/300], Step [64/225], Training Accuracy: 98.9502%, Training Loss: 0.0407%\n",
      "Epoch [119/300], Step [65/225], Training Accuracy: 98.9183%, Training Loss: 0.0409%\n",
      "Epoch [119/300], Step [66/225], Training Accuracy: 98.9347%, Training Loss: 0.0405%\n",
      "Epoch [119/300], Step [67/225], Training Accuracy: 98.9506%, Training Loss: 0.0402%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [119/300], Step [68/225], Training Accuracy: 98.9430%, Training Loss: 0.0402%\n",
      "Epoch [119/300], Step [69/225], Training Accuracy: 98.9130%, Training Loss: 0.0404%\n",
      "Epoch [119/300], Step [70/225], Training Accuracy: 98.9286%, Training Loss: 0.0400%\n",
      "Epoch [119/300], Step [71/225], Training Accuracy: 98.8776%, Training Loss: 0.0409%\n",
      "Epoch [119/300], Step [72/225], Training Accuracy: 98.8932%, Training Loss: 0.0407%\n",
      "Epoch [119/300], Step [73/225], Training Accuracy: 98.8870%, Training Loss: 0.0407%\n",
      "Epoch [119/300], Step [74/225], Training Accuracy: 98.9020%, Training Loss: 0.0407%\n",
      "Epoch [119/300], Step [75/225], Training Accuracy: 98.8750%, Training Loss: 0.0410%\n",
      "Epoch [119/300], Step [76/225], Training Accuracy: 98.8281%, Training Loss: 0.0418%\n",
      "Epoch [119/300], Step [77/225], Training Accuracy: 98.8231%, Training Loss: 0.0419%\n",
      "Epoch [119/300], Step [78/225], Training Accuracy: 98.7981%, Training Loss: 0.0420%\n",
      "Epoch [119/300], Step [79/225], Training Accuracy: 98.8133%, Training Loss: 0.0417%\n",
      "Epoch [119/300], Step [80/225], Training Accuracy: 98.8281%, Training Loss: 0.0416%\n",
      "Epoch [119/300], Step [81/225], Training Accuracy: 98.8233%, Training Loss: 0.0415%\n",
      "Epoch [119/300], Step [82/225], Training Accuracy: 98.8186%, Training Loss: 0.0414%\n",
      "Epoch [119/300], Step [83/225], Training Accuracy: 98.8140%, Training Loss: 0.0418%\n",
      "Epoch [119/300], Step [84/225], Training Accuracy: 98.8095%, Training Loss: 0.0417%\n",
      "Epoch [119/300], Step [85/225], Training Accuracy: 98.8235%, Training Loss: 0.0418%\n",
      "Epoch [119/300], Step [86/225], Training Accuracy: 98.8190%, Training Loss: 0.0419%\n",
      "Epoch [119/300], Step [87/225], Training Accuracy: 98.8326%, Training Loss: 0.0418%\n",
      "Epoch [119/300], Step [88/225], Training Accuracy: 98.8459%, Training Loss: 0.0417%\n",
      "Epoch [119/300], Step [89/225], Training Accuracy: 98.8588%, Training Loss: 0.0416%\n",
      "Epoch [119/300], Step [90/225], Training Accuracy: 98.8542%, Training Loss: 0.0416%\n",
      "Epoch [119/300], Step [91/225], Training Accuracy: 98.8496%, Training Loss: 0.0415%\n",
      "Epoch [119/300], Step [92/225], Training Accuracy: 98.8111%, Training Loss: 0.0421%\n",
      "Epoch [119/300], Step [93/225], Training Accuracy: 98.7903%, Training Loss: 0.0427%\n",
      "Epoch [119/300], Step [94/225], Training Accuracy: 98.7866%, Training Loss: 0.0427%\n",
      "Epoch [119/300], Step [95/225], Training Accuracy: 98.7993%, Training Loss: 0.0426%\n",
      "Epoch [119/300], Step [96/225], Training Accuracy: 98.7793%, Training Loss: 0.0427%\n",
      "Epoch [119/300], Step [97/225], Training Accuracy: 98.7758%, Training Loss: 0.0430%\n",
      "Epoch [119/300], Step [98/225], Training Accuracy: 98.7723%, Training Loss: 0.0434%\n",
      "Epoch [119/300], Step [99/225], Training Accuracy: 98.7689%, Training Loss: 0.0434%\n",
      "Epoch [119/300], Step [100/225], Training Accuracy: 98.7656%, Training Loss: 0.0434%\n",
      "Epoch [119/300], Step [101/225], Training Accuracy: 98.7778%, Training Loss: 0.0433%\n",
      "Epoch [119/300], Step [102/225], Training Accuracy: 98.7745%, Training Loss: 0.0433%\n",
      "Epoch [119/300], Step [103/225], Training Accuracy: 98.7409%, Training Loss: 0.0438%\n",
      "Epoch [119/300], Step [104/225], Training Accuracy: 98.7530%, Training Loss: 0.0435%\n",
      "Epoch [119/300], Step [105/225], Training Accuracy: 98.7500%, Training Loss: 0.0440%\n",
      "Epoch [119/300], Step [106/225], Training Accuracy: 98.7618%, Training Loss: 0.0439%\n",
      "Epoch [119/300], Step [107/225], Training Accuracy: 98.7734%, Training Loss: 0.0437%\n",
      "Epoch [119/300], Step [108/225], Training Accuracy: 98.7703%, Training Loss: 0.0436%\n",
      "Epoch [119/300], Step [109/225], Training Accuracy: 98.7529%, Training Loss: 0.0439%\n",
      "Epoch [119/300], Step [110/225], Training Accuracy: 98.7642%, Training Loss: 0.0436%\n",
      "Epoch [119/300], Step [111/225], Training Accuracy: 98.7753%, Training Loss: 0.0434%\n",
      "Epoch [119/300], Step [112/225], Training Accuracy: 98.7863%, Training Loss: 0.0433%\n",
      "Epoch [119/300], Step [113/225], Training Accuracy: 98.7694%, Training Loss: 0.0434%\n",
      "Epoch [119/300], Step [114/225], Training Accuracy: 98.7664%, Training Loss: 0.0435%\n",
      "Epoch [119/300], Step [115/225], Training Accuracy: 98.7636%, Training Loss: 0.0435%\n",
      "Epoch [119/300], Step [116/225], Training Accuracy: 98.7742%, Training Loss: 0.0432%\n",
      "Epoch [119/300], Step [117/225], Training Accuracy: 98.7714%, Training Loss: 0.0433%\n",
      "Epoch [119/300], Step [118/225], Training Accuracy: 98.7818%, Training Loss: 0.0431%\n",
      "Epoch [119/300], Step [119/225], Training Accuracy: 98.7789%, Training Loss: 0.0431%\n",
      "Epoch [119/300], Step [120/225], Training Accuracy: 98.7891%, Training Loss: 0.0429%\n",
      "Epoch [119/300], Step [121/225], Training Accuracy: 98.7862%, Training Loss: 0.0427%\n",
      "Epoch [119/300], Step [122/225], Training Accuracy: 98.7961%, Training Loss: 0.0426%\n",
      "Epoch [119/300], Step [123/225], Training Accuracy: 98.8059%, Training Loss: 0.0424%\n",
      "Epoch [119/300], Step [124/225], Training Accuracy: 98.8029%, Training Loss: 0.0425%\n",
      "Epoch [119/300], Step [125/225], Training Accuracy: 98.8125%, Training Loss: 0.0423%\n",
      "Epoch [119/300], Step [126/225], Training Accuracy: 98.8095%, Training Loss: 0.0424%\n",
      "Epoch [119/300], Step [127/225], Training Accuracy: 98.8066%, Training Loss: 0.0426%\n",
      "Epoch [119/300], Step [128/225], Training Accuracy: 98.8159%, Training Loss: 0.0424%\n",
      "Epoch [119/300], Step [129/225], Training Accuracy: 98.8009%, Training Loss: 0.0427%\n",
      "Epoch [119/300], Step [130/225], Training Accuracy: 98.8101%, Training Loss: 0.0426%\n",
      "Epoch [119/300], Step [131/225], Training Accuracy: 98.8073%, Training Loss: 0.0426%\n",
      "Epoch [119/300], Step [132/225], Training Accuracy: 98.8045%, Training Loss: 0.0425%\n",
      "Epoch [119/300], Step [133/225], Training Accuracy: 98.8134%, Training Loss: 0.0424%\n",
      "Epoch [119/300], Step [134/225], Training Accuracy: 98.8223%, Training Loss: 0.0423%\n",
      "Epoch [119/300], Step [135/225], Training Accuracy: 98.8310%, Training Loss: 0.0423%\n",
      "Epoch [119/300], Step [136/225], Training Accuracy: 98.8281%, Training Loss: 0.0424%\n",
      "Epoch [119/300], Step [137/225], Training Accuracy: 98.8367%, Training Loss: 0.0421%\n",
      "Epoch [119/300], Step [138/225], Training Accuracy: 98.8338%, Training Loss: 0.0422%\n",
      "Epoch [119/300], Step [139/225], Training Accuracy: 98.8309%, Training Loss: 0.0421%\n",
      "Epoch [119/300], Step [140/225], Training Accuracy: 98.8393%, Training Loss: 0.0419%\n",
      "Epoch [119/300], Step [141/225], Training Accuracy: 98.8364%, Training Loss: 0.0419%\n",
      "Epoch [119/300], Step [142/225], Training Accuracy: 98.8336%, Training Loss: 0.0418%\n",
      "Epoch [119/300], Step [143/225], Training Accuracy: 98.8418%, Training Loss: 0.0417%\n",
      "Epoch [119/300], Step [144/225], Training Accuracy: 98.8390%, Training Loss: 0.0417%\n",
      "Epoch [119/300], Step [145/225], Training Accuracy: 98.8470%, Training Loss: 0.0416%\n",
      "Epoch [119/300], Step [146/225], Training Accuracy: 98.8549%, Training Loss: 0.0415%\n",
      "Epoch [119/300], Step [147/225], Training Accuracy: 98.8627%, Training Loss: 0.0414%\n",
      "Epoch [119/300], Step [148/225], Training Accuracy: 98.8387%, Training Loss: 0.0418%\n",
      "Epoch [119/300], Step [149/225], Training Accuracy: 98.8045%, Training Loss: 0.0425%\n",
      "Epoch [119/300], Step [150/225], Training Accuracy: 98.8125%, Training Loss: 0.0425%\n",
      "Epoch [119/300], Step [151/225], Training Accuracy: 98.8100%, Training Loss: 0.0425%\n",
      "Epoch [119/300], Step [152/225], Training Accuracy: 98.8178%, Training Loss: 0.0423%\n",
      "Epoch [119/300], Step [153/225], Training Accuracy: 98.8256%, Training Loss: 0.0422%\n",
      "Epoch [119/300], Step [154/225], Training Accuracy: 98.8231%, Training Loss: 0.0422%\n",
      "Epoch [119/300], Step [155/225], Training Accuracy: 98.8306%, Training Loss: 0.0422%\n",
      "Epoch [119/300], Step [156/225], Training Accuracy: 98.8181%, Training Loss: 0.0423%\n",
      "Epoch [119/300], Step [157/225], Training Accuracy: 98.8256%, Training Loss: 0.0423%\n",
      "Epoch [119/300], Step [158/225], Training Accuracy: 98.8331%, Training Loss: 0.0422%\n",
      "Epoch [119/300], Step [159/225], Training Accuracy: 98.8404%, Training Loss: 0.0422%\n",
      "Epoch [119/300], Step [160/225], Training Accuracy: 98.8379%, Training Loss: 0.0423%\n",
      "Epoch [119/300], Step [161/225], Training Accuracy: 98.8257%, Training Loss: 0.0424%\n",
      "Epoch [119/300], Step [162/225], Training Accuracy: 98.8233%, Training Loss: 0.0424%\n",
      "Epoch [119/300], Step [163/225], Training Accuracy: 98.8305%, Training Loss: 0.0423%\n",
      "Epoch [119/300], Step [164/225], Training Accuracy: 98.8281%, Training Loss: 0.0423%\n",
      "Epoch [119/300], Step [165/225], Training Accuracy: 98.8352%, Training Loss: 0.0422%\n",
      "Epoch [119/300], Step [166/225], Training Accuracy: 98.8422%, Training Loss: 0.0421%\n",
      "Epoch [119/300], Step [167/225], Training Accuracy: 98.8305%, Training Loss: 0.0421%\n",
      "Epoch [119/300], Step [168/225], Training Accuracy: 98.8374%, Training Loss: 0.0419%\n",
      "Epoch [119/300], Step [169/225], Training Accuracy: 98.8258%, Training Loss: 0.0420%\n",
      "Epoch [119/300], Step [170/225], Training Accuracy: 98.8143%, Training Loss: 0.0420%\n",
      "Epoch [119/300], Step [171/225], Training Accuracy: 98.8213%, Training Loss: 0.0419%\n",
      "Epoch [119/300], Step [172/225], Training Accuracy: 98.8281%, Training Loss: 0.0417%\n",
      "Epoch [119/300], Step [173/225], Training Accuracy: 98.8349%, Training Loss: 0.0416%\n",
      "Epoch [119/300], Step [174/225], Training Accuracy: 98.8416%, Training Loss: 0.0415%\n",
      "Epoch [119/300], Step [175/225], Training Accuracy: 98.8482%, Training Loss: 0.0414%\n",
      "Epoch [119/300], Step [176/225], Training Accuracy: 98.8548%, Training Loss: 0.0412%\n",
      "Epoch [119/300], Step [177/225], Training Accuracy: 98.8524%, Training Loss: 0.0413%\n",
      "Epoch [119/300], Step [178/225], Training Accuracy: 98.8588%, Training Loss: 0.0413%\n",
      "Epoch [119/300], Step [179/225], Training Accuracy: 98.8565%, Training Loss: 0.0413%\n",
      "Epoch [119/300], Step [180/225], Training Accuracy: 98.8628%, Training Loss: 0.0413%\n",
      "Epoch [119/300], Step [181/225], Training Accuracy: 98.8691%, Training Loss: 0.0412%\n",
      "Epoch [119/300], Step [182/225], Training Accuracy: 98.8753%, Training Loss: 0.0410%\n",
      "Epoch [119/300], Step [183/225], Training Accuracy: 98.8815%, Training Loss: 0.0410%\n",
      "Epoch [119/300], Step [184/225], Training Accuracy: 98.8791%, Training Loss: 0.0411%\n",
      "Epoch [119/300], Step [185/225], Training Accuracy: 98.8851%, Training Loss: 0.0409%\n",
      "Epoch [119/300], Step [186/225], Training Accuracy: 98.8911%, Training Loss: 0.0409%\n",
      "Epoch [119/300], Step [187/225], Training Accuracy: 98.8803%, Training Loss: 0.0413%\n",
      "Epoch [119/300], Step [188/225], Training Accuracy: 98.8863%, Training Loss: 0.0412%\n",
      "Epoch [119/300], Step [189/225], Training Accuracy: 98.8839%, Training Loss: 0.0411%\n",
      "Epoch [119/300], Step [190/225], Training Accuracy: 98.8898%, Training Loss: 0.0411%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [119/300], Step [191/225], Training Accuracy: 98.8956%, Training Loss: 0.0411%\n",
      "Epoch [119/300], Step [192/225], Training Accuracy: 98.9014%, Training Loss: 0.0411%\n",
      "Epoch [119/300], Step [193/225], Training Accuracy: 98.8990%, Training Loss: 0.0410%\n",
      "Epoch [119/300], Step [194/225], Training Accuracy: 98.8966%, Training Loss: 0.0411%\n",
      "Epoch [119/300], Step [195/225], Training Accuracy: 98.9022%, Training Loss: 0.0411%\n",
      "Epoch [119/300], Step [196/225], Training Accuracy: 98.8999%, Training Loss: 0.0410%\n",
      "Epoch [119/300], Step [197/225], Training Accuracy: 98.8817%, Training Loss: 0.0413%\n",
      "Epoch [119/300], Step [198/225], Training Accuracy: 98.8794%, Training Loss: 0.0414%\n",
      "Epoch [119/300], Step [199/225], Training Accuracy: 98.8851%, Training Loss: 0.0413%\n",
      "Epoch [119/300], Step [200/225], Training Accuracy: 98.8828%, Training Loss: 0.0412%\n",
      "Epoch [119/300], Step [201/225], Training Accuracy: 98.8884%, Training Loss: 0.0412%\n",
      "Epoch [119/300], Step [202/225], Training Accuracy: 98.8784%, Training Loss: 0.0412%\n",
      "Epoch [119/300], Step [203/225], Training Accuracy: 98.8839%, Training Loss: 0.0411%\n",
      "Epoch [119/300], Step [204/225], Training Accuracy: 98.8817%, Training Loss: 0.0413%\n",
      "Epoch [119/300], Step [205/225], Training Accuracy: 98.8872%, Training Loss: 0.0411%\n",
      "Epoch [119/300], Step [206/225], Training Accuracy: 98.8850%, Training Loss: 0.0412%\n",
      "Epoch [119/300], Step [207/225], Training Accuracy: 98.8904%, Training Loss: 0.0411%\n",
      "Epoch [119/300], Step [208/225], Training Accuracy: 98.8807%, Training Loss: 0.0412%\n",
      "Epoch [119/300], Step [209/225], Training Accuracy: 98.8786%, Training Loss: 0.0412%\n",
      "Epoch [119/300], Step [210/225], Training Accuracy: 98.8690%, Training Loss: 0.0413%\n",
      "Epoch [119/300], Step [211/225], Training Accuracy: 98.8744%, Training Loss: 0.0412%\n",
      "Epoch [119/300], Step [212/225], Training Accuracy: 98.8650%, Training Loss: 0.0413%\n",
      "Epoch [119/300], Step [213/225], Training Accuracy: 98.8703%, Training Loss: 0.0412%\n",
      "Epoch [119/300], Step [214/225], Training Accuracy: 98.8683%, Training Loss: 0.0413%\n",
      "Epoch [119/300], Step [215/225], Training Accuracy: 98.8735%, Training Loss: 0.0412%\n",
      "Epoch [119/300], Step [216/225], Training Accuracy: 98.8715%, Training Loss: 0.0413%\n",
      "Epoch [119/300], Step [217/225], Training Accuracy: 98.8551%, Training Loss: 0.0416%\n",
      "Epoch [119/300], Step [218/225], Training Accuracy: 98.8460%, Training Loss: 0.0417%\n",
      "Epoch [119/300], Step [219/225], Training Accuracy: 98.8513%, Training Loss: 0.0417%\n",
      "Epoch [119/300], Step [220/225], Training Accuracy: 98.8494%, Training Loss: 0.0417%\n",
      "Epoch [119/300], Step [221/225], Training Accuracy: 98.8546%, Training Loss: 0.0416%\n",
      "Epoch [119/300], Step [222/225], Training Accuracy: 98.8598%, Training Loss: 0.0416%\n",
      "Epoch [119/300], Step [223/225], Training Accuracy: 98.8649%, Training Loss: 0.0415%\n",
      "Epoch [119/300], Step [224/225], Training Accuracy: 98.8630%, Training Loss: 0.0414%\n",
      "Epoch [119/300], Step [225/225], Training Accuracy: 98.8605%, Training Loss: 0.0417%\n",
      "Epoch [120/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0136%\n",
      "Epoch [120/300], Step [2/225], Training Accuracy: 99.2188%, Training Loss: 0.0310%\n",
      "Epoch [120/300], Step [3/225], Training Accuracy: 98.9583%, Training Loss: 0.0347%\n",
      "Epoch [120/300], Step [4/225], Training Accuracy: 99.2188%, Training Loss: 0.0295%\n",
      "Epoch [120/300], Step [5/225], Training Accuracy: 99.3750%, Training Loss: 0.0286%\n",
      "Epoch [120/300], Step [6/225], Training Accuracy: 99.4792%, Training Loss: 0.0277%\n",
      "Epoch [120/300], Step [7/225], Training Accuracy: 98.6607%, Training Loss: 0.0421%\n",
      "Epoch [120/300], Step [8/225], Training Accuracy: 98.6328%, Training Loss: 0.0401%\n",
      "Epoch [120/300], Step [9/225], Training Accuracy: 98.6111%, Training Loss: 0.0417%\n",
      "Epoch [120/300], Step [10/225], Training Accuracy: 98.7500%, Training Loss: 0.0399%\n",
      "Epoch [120/300], Step [11/225], Training Accuracy: 98.7216%, Training Loss: 0.0390%\n",
      "Epoch [120/300], Step [12/225], Training Accuracy: 98.8281%, Training Loss: 0.0380%\n",
      "Epoch [120/300], Step [13/225], Training Accuracy: 98.5577%, Training Loss: 0.0427%\n",
      "Epoch [120/300], Step [14/225], Training Accuracy: 98.6607%, Training Loss: 0.0409%\n",
      "Epoch [120/300], Step [15/225], Training Accuracy: 98.7500%, Training Loss: 0.0394%\n",
      "Epoch [120/300], Step [16/225], Training Accuracy: 98.7305%, Training Loss: 0.0403%\n",
      "Epoch [120/300], Step [17/225], Training Accuracy: 98.6213%, Training Loss: 0.0424%\n",
      "Epoch [120/300], Step [18/225], Training Accuracy: 98.5243%, Training Loss: 0.0478%\n",
      "Epoch [120/300], Step [19/225], Training Accuracy: 98.5197%, Training Loss: 0.0473%\n",
      "Epoch [120/300], Step [20/225], Training Accuracy: 98.5156%, Training Loss: 0.0470%\n",
      "Epoch [120/300], Step [21/225], Training Accuracy: 98.5119%, Training Loss: 0.0463%\n",
      "Epoch [120/300], Step [22/225], Training Accuracy: 98.5795%, Training Loss: 0.0455%\n",
      "Epoch [120/300], Step [23/225], Training Accuracy: 98.6413%, Training Loss: 0.0439%\n",
      "Epoch [120/300], Step [24/225], Training Accuracy: 98.6328%, Training Loss: 0.0437%\n",
      "Epoch [120/300], Step [25/225], Training Accuracy: 98.6875%, Training Loss: 0.0431%\n",
      "Epoch [120/300], Step [26/225], Training Accuracy: 98.7380%, Training Loss: 0.0425%\n",
      "Epoch [120/300], Step [27/225], Training Accuracy: 98.7269%, Training Loss: 0.0428%\n",
      "Epoch [120/300], Step [28/225], Training Accuracy: 98.7723%, Training Loss: 0.0422%\n",
      "Epoch [120/300], Step [29/225], Training Accuracy: 98.8147%, Training Loss: 0.0425%\n",
      "Epoch [120/300], Step [30/225], Training Accuracy: 98.8021%, Training Loss: 0.0421%\n",
      "Epoch [120/300], Step [31/225], Training Accuracy: 98.7399%, Training Loss: 0.0424%\n",
      "Epoch [120/300], Step [32/225], Training Accuracy: 98.6816%, Training Loss: 0.0432%\n",
      "Epoch [120/300], Step [33/225], Training Accuracy: 98.6742%, Training Loss: 0.0430%\n",
      "Epoch [120/300], Step [34/225], Training Accuracy: 98.7132%, Training Loss: 0.0432%\n",
      "Epoch [120/300], Step [35/225], Training Accuracy: 98.7054%, Training Loss: 0.0433%\n",
      "Epoch [120/300], Step [36/225], Training Accuracy: 98.6545%, Training Loss: 0.0434%\n",
      "Epoch [120/300], Step [37/225], Training Accuracy: 98.6909%, Training Loss: 0.0431%\n",
      "Epoch [120/300], Step [38/225], Training Accuracy: 98.6842%, Training Loss: 0.0427%\n",
      "Epoch [120/300], Step [39/225], Training Accuracy: 98.6779%, Training Loss: 0.0427%\n",
      "Epoch [120/300], Step [40/225], Training Accuracy: 98.6719%, Training Loss: 0.0432%\n",
      "Epoch [120/300], Step [41/225], Training Accuracy: 98.6662%, Training Loss: 0.0437%\n",
      "Epoch [120/300], Step [42/225], Training Accuracy: 98.6235%, Training Loss: 0.0439%\n",
      "Epoch [120/300], Step [43/225], Training Accuracy: 98.6555%, Training Loss: 0.0432%\n",
      "Epoch [120/300], Step [44/225], Training Accuracy: 98.6861%, Training Loss: 0.0428%\n",
      "Epoch [120/300], Step [45/225], Training Accuracy: 98.7153%, Training Loss: 0.0421%\n",
      "Epoch [120/300], Step [46/225], Training Accuracy: 98.6753%, Training Loss: 0.0425%\n",
      "Epoch [120/300], Step [47/225], Training Accuracy: 98.7035%, Training Loss: 0.0424%\n",
      "Epoch [120/300], Step [48/225], Training Accuracy: 98.6979%, Training Loss: 0.0427%\n",
      "Epoch [120/300], Step [49/225], Training Accuracy: 98.6926%, Training Loss: 0.0425%\n",
      "Epoch [120/300], Step [50/225], Training Accuracy: 98.7188%, Training Loss: 0.0420%\n",
      "Epoch [120/300], Step [51/225], Training Accuracy: 98.7132%, Training Loss: 0.0420%\n",
      "Epoch [120/300], Step [52/225], Training Accuracy: 98.7380%, Training Loss: 0.0412%\n",
      "Epoch [120/300], Step [53/225], Training Accuracy: 98.7323%, Training Loss: 0.0412%\n",
      "Epoch [120/300], Step [54/225], Training Accuracy: 98.7269%, Training Loss: 0.0412%\n",
      "Epoch [120/300], Step [55/225], Training Accuracy: 98.7500%, Training Loss: 0.0409%\n",
      "Epoch [120/300], Step [56/225], Training Accuracy: 98.7165%, Training Loss: 0.0412%\n",
      "Epoch [120/300], Step [57/225], Training Accuracy: 98.7390%, Training Loss: 0.0408%\n",
      "Epoch [120/300], Step [58/225], Training Accuracy: 98.7608%, Training Loss: 0.0406%\n",
      "Epoch [120/300], Step [59/225], Training Accuracy: 98.7818%, Training Loss: 0.0403%\n",
      "Epoch [120/300], Step [60/225], Training Accuracy: 98.7500%, Training Loss: 0.0410%\n",
      "Epoch [120/300], Step [61/225], Training Accuracy: 98.6936%, Training Loss: 0.0414%\n",
      "Epoch [120/300], Step [62/225], Training Accuracy: 98.6895%, Training Loss: 0.0417%\n",
      "Epoch [120/300], Step [63/225], Training Accuracy: 98.7103%, Training Loss: 0.0415%\n",
      "Epoch [120/300], Step [64/225], Training Accuracy: 98.7305%, Training Loss: 0.0411%\n",
      "Epoch [120/300], Step [65/225], Training Accuracy: 98.7500%, Training Loss: 0.0408%\n",
      "Epoch [120/300], Step [66/225], Training Accuracy: 98.7453%, Training Loss: 0.0407%\n",
      "Epoch [120/300], Step [67/225], Training Accuracy: 98.7174%, Training Loss: 0.0410%\n",
      "Epoch [120/300], Step [68/225], Training Accuracy: 98.7362%, Training Loss: 0.0407%\n",
      "Epoch [120/300], Step [69/225], Training Accuracy: 98.7545%, Training Loss: 0.0403%\n",
      "Epoch [120/300], Step [70/225], Training Accuracy: 98.7500%, Training Loss: 0.0402%\n",
      "Epoch [120/300], Step [71/225], Training Accuracy: 98.7456%, Training Loss: 0.0405%\n",
      "Epoch [120/300], Step [72/225], Training Accuracy: 98.7630%, Training Loss: 0.0401%\n",
      "Epoch [120/300], Step [73/225], Training Accuracy: 98.7586%, Training Loss: 0.0404%\n",
      "Epoch [120/300], Step [74/225], Training Accuracy: 98.7753%, Training Loss: 0.0402%\n",
      "Epoch [120/300], Step [75/225], Training Accuracy: 98.7708%, Training Loss: 0.0402%\n",
      "Epoch [120/300], Step [76/225], Training Accuracy: 98.7459%, Training Loss: 0.0407%\n",
      "Epoch [120/300], Step [77/225], Training Accuracy: 98.7622%, Training Loss: 0.0405%\n",
      "Epoch [120/300], Step [78/225], Training Accuracy: 98.7780%, Training Loss: 0.0405%\n",
      "Epoch [120/300], Step [79/225], Training Accuracy: 98.7935%, Training Loss: 0.0403%\n",
      "Epoch [120/300], Step [80/225], Training Accuracy: 98.8086%, Training Loss: 0.0402%\n",
      "Epoch [120/300], Step [81/225], Training Accuracy: 98.8233%, Training Loss: 0.0398%\n",
      "Epoch [120/300], Step [82/225], Training Accuracy: 98.8186%, Training Loss: 0.0397%\n",
      "Epoch [120/300], Step [83/225], Training Accuracy: 98.8140%, Training Loss: 0.0398%\n",
      "Epoch [120/300], Step [84/225], Training Accuracy: 98.8095%, Training Loss: 0.0399%\n",
      "Epoch [120/300], Step [85/225], Training Accuracy: 98.7868%, Training Loss: 0.0404%\n",
      "Epoch [120/300], Step [86/225], Training Accuracy: 98.8009%, Training Loss: 0.0403%\n",
      "Epoch [120/300], Step [87/225], Training Accuracy: 98.8147%, Training Loss: 0.0401%\n",
      "Epoch [120/300], Step [88/225], Training Accuracy: 98.7926%, Training Loss: 0.0401%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [120/300], Step [89/225], Training Accuracy: 98.7886%, Training Loss: 0.0402%\n",
      "Epoch [120/300], Step [90/225], Training Accuracy: 98.7847%, Training Loss: 0.0406%\n",
      "Epoch [120/300], Step [91/225], Training Accuracy: 98.7981%, Training Loss: 0.0404%\n",
      "Epoch [120/300], Step [92/225], Training Accuracy: 98.7942%, Training Loss: 0.0403%\n",
      "Epoch [120/300], Step [93/225], Training Accuracy: 98.7903%, Training Loss: 0.0401%\n",
      "Epoch [120/300], Step [94/225], Training Accuracy: 98.8032%, Training Loss: 0.0401%\n",
      "Epoch [120/300], Step [95/225], Training Accuracy: 98.8158%, Training Loss: 0.0400%\n",
      "Epoch [120/300], Step [96/225], Training Accuracy: 98.8281%, Training Loss: 0.0398%\n",
      "Epoch [120/300], Step [97/225], Training Accuracy: 98.8241%, Training Loss: 0.0399%\n",
      "Epoch [120/300], Step [98/225], Training Accuracy: 98.8202%, Training Loss: 0.0400%\n",
      "Epoch [120/300], Step [99/225], Training Accuracy: 98.8163%, Training Loss: 0.0399%\n",
      "Epoch [120/300], Step [100/225], Training Accuracy: 98.8281%, Training Loss: 0.0397%\n",
      "Epoch [120/300], Step [101/225], Training Accuracy: 98.8088%, Training Loss: 0.0404%\n",
      "Epoch [120/300], Step [102/225], Training Accuracy: 98.7745%, Training Loss: 0.0408%\n",
      "Epoch [120/300], Step [103/225], Training Accuracy: 98.7864%, Training Loss: 0.0407%\n",
      "Epoch [120/300], Step [104/225], Training Accuracy: 98.7831%, Training Loss: 0.0413%\n",
      "Epoch [120/300], Step [105/225], Training Accuracy: 98.7798%, Training Loss: 0.0413%\n",
      "Epoch [120/300], Step [106/225], Training Accuracy: 98.7913%, Training Loss: 0.0410%\n",
      "Epoch [120/300], Step [107/225], Training Accuracy: 98.8026%, Training Loss: 0.0408%\n",
      "Epoch [120/300], Step [108/225], Training Accuracy: 98.8137%, Training Loss: 0.0407%\n",
      "Epoch [120/300], Step [109/225], Training Accuracy: 98.8102%, Training Loss: 0.0407%\n",
      "Epoch [120/300], Step [110/225], Training Accuracy: 98.8210%, Training Loss: 0.0405%\n",
      "Epoch [120/300], Step [111/225], Training Accuracy: 98.8316%, Training Loss: 0.0404%\n",
      "Epoch [120/300], Step [112/225], Training Accuracy: 98.8002%, Training Loss: 0.0406%\n",
      "Epoch [120/300], Step [113/225], Training Accuracy: 98.7970%, Training Loss: 0.0405%\n",
      "Epoch [120/300], Step [114/225], Training Accuracy: 98.7939%, Training Loss: 0.0405%\n",
      "Epoch [120/300], Step [115/225], Training Accuracy: 98.8043%, Training Loss: 0.0405%\n",
      "Epoch [120/300], Step [116/225], Training Accuracy: 98.7877%, Training Loss: 0.0406%\n",
      "Epoch [120/300], Step [117/225], Training Accuracy: 98.7981%, Training Loss: 0.0404%\n",
      "Epoch [120/300], Step [118/225], Training Accuracy: 98.7950%, Training Loss: 0.0404%\n",
      "Epoch [120/300], Step [119/225], Training Accuracy: 98.7920%, Training Loss: 0.0405%\n",
      "Epoch [120/300], Step [120/225], Training Accuracy: 98.8021%, Training Loss: 0.0402%\n",
      "Epoch [120/300], Step [121/225], Training Accuracy: 98.8120%, Training Loss: 0.0402%\n",
      "Epoch [120/300], Step [122/225], Training Accuracy: 98.8089%, Training Loss: 0.0401%\n",
      "Epoch [120/300], Step [123/225], Training Accuracy: 98.8059%, Training Loss: 0.0401%\n",
      "Epoch [120/300], Step [124/225], Training Accuracy: 98.7903%, Training Loss: 0.0403%\n",
      "Epoch [120/300], Step [125/225], Training Accuracy: 98.8000%, Training Loss: 0.0403%\n",
      "Epoch [120/300], Step [126/225], Training Accuracy: 98.7847%, Training Loss: 0.0403%\n",
      "Epoch [120/300], Step [127/225], Training Accuracy: 98.7943%, Training Loss: 0.0403%\n",
      "Epoch [120/300], Step [128/225], Training Accuracy: 98.7915%, Training Loss: 0.0403%\n",
      "Epoch [120/300], Step [129/225], Training Accuracy: 98.8009%, Training Loss: 0.0402%\n",
      "Epoch [120/300], Step [130/225], Training Accuracy: 98.7740%, Training Loss: 0.0406%\n",
      "Epoch [120/300], Step [131/225], Training Accuracy: 98.7834%, Training Loss: 0.0405%\n",
      "Epoch [120/300], Step [132/225], Training Accuracy: 98.7808%, Training Loss: 0.0405%\n",
      "Epoch [120/300], Step [133/225], Training Accuracy: 98.7899%, Training Loss: 0.0403%\n",
      "Epoch [120/300], Step [134/225], Training Accuracy: 98.7873%, Training Loss: 0.0402%\n",
      "Epoch [120/300], Step [135/225], Training Accuracy: 98.7963%, Training Loss: 0.0400%\n",
      "Epoch [120/300], Step [136/225], Training Accuracy: 98.8051%, Training Loss: 0.0399%\n",
      "Epoch [120/300], Step [137/225], Training Accuracy: 98.8139%, Training Loss: 0.0398%\n",
      "Epoch [120/300], Step [138/225], Training Accuracy: 98.8111%, Training Loss: 0.0399%\n",
      "Epoch [120/300], Step [139/225], Training Accuracy: 98.8197%, Training Loss: 0.0397%\n",
      "Epoch [120/300], Step [140/225], Training Accuracy: 98.8281%, Training Loss: 0.0396%\n",
      "Epoch [120/300], Step [141/225], Training Accuracy: 98.7921%, Training Loss: 0.0403%\n",
      "Epoch [120/300], Step [142/225], Training Accuracy: 98.8006%, Training Loss: 0.0402%\n",
      "Epoch [120/300], Step [143/225], Training Accuracy: 98.8090%, Training Loss: 0.0402%\n",
      "Epoch [120/300], Step [144/225], Training Accuracy: 98.7847%, Training Loss: 0.0405%\n",
      "Epoch [120/300], Step [145/225], Training Accuracy: 98.7931%, Training Loss: 0.0403%\n",
      "Epoch [120/300], Step [146/225], Training Accuracy: 98.7907%, Training Loss: 0.0405%\n",
      "Epoch [120/300], Step [147/225], Training Accuracy: 98.7776%, Training Loss: 0.0407%\n",
      "Epoch [120/300], Step [148/225], Training Accuracy: 98.7753%, Training Loss: 0.0411%\n",
      "Epoch [120/300], Step [149/225], Training Accuracy: 98.7731%, Training Loss: 0.0412%\n",
      "Epoch [120/300], Step [150/225], Training Accuracy: 98.7812%, Training Loss: 0.0410%\n",
      "Epoch [120/300], Step [151/225], Training Accuracy: 98.7790%, Training Loss: 0.0411%\n",
      "Epoch [120/300], Step [152/225], Training Accuracy: 98.7767%, Training Loss: 0.0412%\n",
      "Epoch [120/300], Step [153/225], Training Accuracy: 98.7745%, Training Loss: 0.0411%\n",
      "Epoch [120/300], Step [154/225], Training Accuracy: 98.7723%, Training Loss: 0.0412%\n",
      "Epoch [120/300], Step [155/225], Training Accuracy: 98.7702%, Training Loss: 0.0412%\n",
      "Epoch [120/300], Step [156/225], Training Accuracy: 98.7680%, Training Loss: 0.0414%\n",
      "Epoch [120/300], Step [157/225], Training Accuracy: 98.7759%, Training Loss: 0.0415%\n",
      "Epoch [120/300], Step [158/225], Training Accuracy: 98.7737%, Training Loss: 0.0414%\n",
      "Epoch [120/300], Step [159/225], Training Accuracy: 98.7814%, Training Loss: 0.0412%\n",
      "Epoch [120/300], Step [160/225], Training Accuracy: 98.7793%, Training Loss: 0.0412%\n",
      "Epoch [120/300], Step [161/225], Training Accuracy: 98.7772%, Training Loss: 0.0411%\n",
      "Epoch [120/300], Step [162/225], Training Accuracy: 98.7751%, Training Loss: 0.0416%\n",
      "Epoch [120/300], Step [163/225], Training Accuracy: 98.7730%, Training Loss: 0.0416%\n",
      "Epoch [120/300], Step [164/225], Training Accuracy: 98.7710%, Training Loss: 0.0416%\n",
      "Epoch [120/300], Step [165/225], Training Accuracy: 98.7784%, Training Loss: 0.0414%\n",
      "Epoch [120/300], Step [166/225], Training Accuracy: 98.7858%, Training Loss: 0.0415%\n",
      "Epoch [120/300], Step [167/225], Training Accuracy: 98.7930%, Training Loss: 0.0414%\n",
      "Epoch [120/300], Step [168/225], Training Accuracy: 98.7909%, Training Loss: 0.0415%\n",
      "Epoch [120/300], Step [169/225], Training Accuracy: 98.7981%, Training Loss: 0.0414%\n",
      "Epoch [120/300], Step [170/225], Training Accuracy: 98.7960%, Training Loss: 0.0415%\n",
      "Epoch [120/300], Step [171/225], Training Accuracy: 98.7939%, Training Loss: 0.0415%\n",
      "Epoch [120/300], Step [172/225], Training Accuracy: 98.7918%, Training Loss: 0.0416%\n",
      "Epoch [120/300], Step [173/225], Training Accuracy: 98.7988%, Training Loss: 0.0416%\n",
      "Epoch [120/300], Step [174/225], Training Accuracy: 98.8057%, Training Loss: 0.0415%\n",
      "Epoch [120/300], Step [175/225], Training Accuracy: 98.8036%, Training Loss: 0.0415%\n",
      "Epoch [120/300], Step [176/225], Training Accuracy: 98.7837%, Training Loss: 0.0418%\n",
      "Epoch [120/300], Step [177/225], Training Accuracy: 98.7906%, Training Loss: 0.0416%\n",
      "Epoch [120/300], Step [178/225], Training Accuracy: 98.7974%, Training Loss: 0.0415%\n",
      "Epoch [120/300], Step [179/225], Training Accuracy: 98.8041%, Training Loss: 0.0414%\n",
      "Epoch [120/300], Step [180/225], Training Accuracy: 98.8021%, Training Loss: 0.0414%\n",
      "Epoch [120/300], Step [181/225], Training Accuracy: 98.8001%, Training Loss: 0.0415%\n",
      "Epoch [120/300], Step [182/225], Training Accuracy: 98.7895%, Training Loss: 0.0416%\n",
      "Epoch [120/300], Step [183/225], Training Accuracy: 98.7961%, Training Loss: 0.0415%\n",
      "Epoch [120/300], Step [184/225], Training Accuracy: 98.7942%, Training Loss: 0.0415%\n",
      "Epoch [120/300], Step [185/225], Training Accuracy: 98.8007%, Training Loss: 0.0415%\n",
      "Epoch [120/300], Step [186/225], Training Accuracy: 98.7987%, Training Loss: 0.0414%\n",
      "Epoch [120/300], Step [187/225], Training Accuracy: 98.7968%, Training Loss: 0.0416%\n",
      "Epoch [120/300], Step [188/225], Training Accuracy: 98.7866%, Training Loss: 0.0418%\n",
      "Epoch [120/300], Step [189/225], Training Accuracy: 98.7765%, Training Loss: 0.0418%\n",
      "Epoch [120/300], Step [190/225], Training Accuracy: 98.7829%, Training Loss: 0.0417%\n",
      "Epoch [120/300], Step [191/225], Training Accuracy: 98.7811%, Training Loss: 0.0416%\n",
      "Epoch [120/300], Step [192/225], Training Accuracy: 98.7874%, Training Loss: 0.0415%\n",
      "Epoch [120/300], Step [193/225], Training Accuracy: 98.7856%, Training Loss: 0.0416%\n",
      "Epoch [120/300], Step [194/225], Training Accuracy: 98.7919%, Training Loss: 0.0415%\n",
      "Epoch [120/300], Step [195/225], Training Accuracy: 98.7981%, Training Loss: 0.0416%\n",
      "Epoch [120/300], Step [196/225], Training Accuracy: 98.7883%, Training Loss: 0.0417%\n",
      "Epoch [120/300], Step [197/225], Training Accuracy: 98.7944%, Training Loss: 0.0416%\n",
      "Epoch [120/300], Step [198/225], Training Accuracy: 98.8005%, Training Loss: 0.0416%\n",
      "Epoch [120/300], Step [199/225], Training Accuracy: 98.8065%, Training Loss: 0.0416%\n",
      "Epoch [120/300], Step [200/225], Training Accuracy: 98.7969%, Training Loss: 0.0416%\n",
      "Epoch [120/300], Step [201/225], Training Accuracy: 98.8029%, Training Loss: 0.0416%\n",
      "Epoch [120/300], Step [202/225], Training Accuracy: 98.7933%, Training Loss: 0.0417%\n",
      "Epoch [120/300], Step [203/225], Training Accuracy: 98.7916%, Training Loss: 0.0418%\n",
      "Epoch [120/300], Step [204/225], Training Accuracy: 98.7822%, Training Loss: 0.0420%\n",
      "Epoch [120/300], Step [205/225], Training Accuracy: 98.7881%, Training Loss: 0.0418%\n",
      "Epoch [120/300], Step [206/225], Training Accuracy: 98.7864%, Training Loss: 0.0419%\n",
      "Epoch [120/300], Step [207/225], Training Accuracy: 98.7923%, Training Loss: 0.0418%\n",
      "Epoch [120/300], Step [208/225], Training Accuracy: 98.7981%, Training Loss: 0.0418%\n",
      "Epoch [120/300], Step [209/225], Training Accuracy: 98.7964%, Training Loss: 0.0418%\n",
      "Epoch [120/300], Step [210/225], Training Accuracy: 98.7946%, Training Loss: 0.0419%\n",
      "Epoch [120/300], Step [211/225], Training Accuracy: 98.8004%, Training Loss: 0.0418%\n",
      "Epoch [120/300], Step [212/225], Training Accuracy: 98.8060%, Training Loss: 0.0417%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [120/300], Step [213/225], Training Accuracy: 98.8116%, Training Loss: 0.0416%\n",
      "Epoch [120/300], Step [214/225], Training Accuracy: 98.8172%, Training Loss: 0.0415%\n",
      "Epoch [120/300], Step [215/225], Training Accuracy: 98.8081%, Training Loss: 0.0418%\n",
      "Epoch [120/300], Step [216/225], Training Accuracy: 98.8137%, Training Loss: 0.0419%\n",
      "Epoch [120/300], Step [217/225], Training Accuracy: 98.8119%, Training Loss: 0.0420%\n",
      "Epoch [120/300], Step [218/225], Training Accuracy: 98.8102%, Training Loss: 0.0420%\n",
      "Epoch [120/300], Step [219/225], Training Accuracy: 98.8085%, Training Loss: 0.0420%\n",
      "Epoch [120/300], Step [220/225], Training Accuracy: 98.8139%, Training Loss: 0.0419%\n",
      "Epoch [120/300], Step [221/225], Training Accuracy: 98.8193%, Training Loss: 0.0418%\n",
      "Epoch [120/300], Step [222/225], Training Accuracy: 98.8176%, Training Loss: 0.0419%\n",
      "Epoch [120/300], Step [223/225], Training Accuracy: 98.8229%, Training Loss: 0.0420%\n",
      "Epoch [120/300], Step [224/225], Training Accuracy: 98.8211%, Training Loss: 0.0419%\n",
      "Epoch [120/300], Step [225/225], Training Accuracy: 98.8257%, Training Loss: 0.0419%\n",
      "Epoch [121/300], Step [1/225], Training Accuracy: 96.8750%, Training Loss: 0.0838%\n",
      "Epoch [121/300], Step [2/225], Training Accuracy: 98.4375%, Training Loss: 0.0558%\n",
      "Epoch [121/300], Step [3/225], Training Accuracy: 98.9583%, Training Loss: 0.0481%\n",
      "Epoch [121/300], Step [4/225], Training Accuracy: 98.8281%, Training Loss: 0.0482%\n",
      "Epoch [121/300], Step [5/225], Training Accuracy: 98.1250%, Training Loss: 0.0608%\n",
      "Epoch [121/300], Step [6/225], Training Accuracy: 98.1771%, Training Loss: 0.0668%\n",
      "Epoch [121/300], Step [7/225], Training Accuracy: 97.9911%, Training Loss: 0.0663%\n",
      "Epoch [121/300], Step [8/225], Training Accuracy: 98.2422%, Training Loss: 0.0622%\n",
      "Epoch [121/300], Step [9/225], Training Accuracy: 98.2639%, Training Loss: 0.0590%\n",
      "Epoch [121/300], Step [10/225], Training Accuracy: 98.1250%, Training Loss: 0.0603%\n",
      "Epoch [121/300], Step [11/225], Training Accuracy: 98.1534%, Training Loss: 0.0579%\n",
      "Epoch [121/300], Step [12/225], Training Accuracy: 98.3073%, Training Loss: 0.0546%\n",
      "Epoch [121/300], Step [13/225], Training Accuracy: 98.1971%, Training Loss: 0.0556%\n",
      "Epoch [121/300], Step [14/225], Training Accuracy: 98.1027%, Training Loss: 0.0560%\n",
      "Epoch [121/300], Step [15/225], Training Accuracy: 98.2292%, Training Loss: 0.0536%\n",
      "Epoch [121/300], Step [16/225], Training Accuracy: 98.3398%, Training Loss: 0.0510%\n",
      "Epoch [121/300], Step [17/225], Training Accuracy: 98.2537%, Training Loss: 0.0522%\n",
      "Epoch [121/300], Step [18/225], Training Accuracy: 98.1771%, Training Loss: 0.0533%\n",
      "Epoch [121/300], Step [19/225], Training Accuracy: 98.2730%, Training Loss: 0.0526%\n",
      "Epoch [121/300], Step [20/225], Training Accuracy: 98.2812%, Training Loss: 0.0524%\n",
      "Epoch [121/300], Step [21/225], Training Accuracy: 98.3631%, Training Loss: 0.0506%\n",
      "Epoch [121/300], Step [22/225], Training Accuracy: 98.2955%, Training Loss: 0.0517%\n",
      "Epoch [121/300], Step [23/225], Training Accuracy: 98.3696%, Training Loss: 0.0502%\n",
      "Epoch [121/300], Step [24/225], Training Accuracy: 98.2422%, Training Loss: 0.0510%\n",
      "Epoch [121/300], Step [25/225], Training Accuracy: 98.2500%, Training Loss: 0.0501%\n",
      "Epoch [121/300], Step [26/225], Training Accuracy: 98.3173%, Training Loss: 0.0486%\n",
      "Epoch [121/300], Step [27/225], Training Accuracy: 98.3796%, Training Loss: 0.0483%\n",
      "Epoch [121/300], Step [28/225], Training Accuracy: 98.3817%, Training Loss: 0.0480%\n",
      "Epoch [121/300], Step [29/225], Training Accuracy: 98.3836%, Training Loss: 0.0476%\n",
      "Epoch [121/300], Step [30/225], Training Accuracy: 98.3854%, Training Loss: 0.0481%\n",
      "Epoch [121/300], Step [31/225], Training Accuracy: 98.3871%, Training Loss: 0.0492%\n",
      "Epoch [121/300], Step [32/225], Training Accuracy: 98.4375%, Training Loss: 0.0489%\n",
      "Epoch [121/300], Step [33/225], Training Accuracy: 98.3902%, Training Loss: 0.0490%\n",
      "Epoch [121/300], Step [34/225], Training Accuracy: 98.3456%, Training Loss: 0.0494%\n",
      "Epoch [121/300], Step [35/225], Training Accuracy: 98.3929%, Training Loss: 0.0493%\n",
      "Epoch [121/300], Step [36/225], Training Accuracy: 98.4375%, Training Loss: 0.0483%\n",
      "Epoch [121/300], Step [37/225], Training Accuracy: 98.4375%, Training Loss: 0.0489%\n",
      "Epoch [121/300], Step [38/225], Training Accuracy: 98.4786%, Training Loss: 0.0480%\n",
      "Epoch [121/300], Step [39/225], Training Accuracy: 98.5176%, Training Loss: 0.0476%\n",
      "Epoch [121/300], Step [40/225], Training Accuracy: 98.5156%, Training Loss: 0.0474%\n",
      "Epoch [121/300], Step [41/225], Training Accuracy: 98.5518%, Training Loss: 0.0470%\n",
      "Epoch [121/300], Step [42/225], Training Accuracy: 98.5863%, Training Loss: 0.0468%\n",
      "Epoch [121/300], Step [43/225], Training Accuracy: 98.6192%, Training Loss: 0.0463%\n",
      "Epoch [121/300], Step [44/225], Training Accuracy: 98.6151%, Training Loss: 0.0463%\n",
      "Epoch [121/300], Step [45/225], Training Accuracy: 98.6458%, Training Loss: 0.0462%\n",
      "Epoch [121/300], Step [46/225], Training Accuracy: 98.6753%, Training Loss: 0.0459%\n",
      "Epoch [121/300], Step [47/225], Training Accuracy: 98.6370%, Training Loss: 0.0468%\n",
      "Epoch [121/300], Step [48/225], Training Accuracy: 98.6328%, Training Loss: 0.0473%\n",
      "Epoch [121/300], Step [49/225], Training Accuracy: 98.5651%, Training Loss: 0.0478%\n",
      "Epoch [121/300], Step [50/225], Training Accuracy: 98.5938%, Training Loss: 0.0475%\n",
      "Epoch [121/300], Step [51/225], Training Accuracy: 98.6213%, Training Loss: 0.0470%\n",
      "Epoch [121/300], Step [52/225], Training Accuracy: 98.6478%, Training Loss: 0.0464%\n",
      "Epoch [121/300], Step [53/225], Training Accuracy: 98.6144%, Training Loss: 0.0466%\n",
      "Epoch [121/300], Step [54/225], Training Accuracy: 98.6111%, Training Loss: 0.0467%\n",
      "Epoch [121/300], Step [55/225], Training Accuracy: 98.6364%, Training Loss: 0.0460%\n",
      "Epoch [121/300], Step [56/225], Training Accuracy: 98.6328%, Training Loss: 0.0463%\n",
      "Epoch [121/300], Step [57/225], Training Accuracy: 98.6020%, Training Loss: 0.0463%\n",
      "Epoch [121/300], Step [58/225], Training Accuracy: 98.6261%, Training Loss: 0.0457%\n",
      "Epoch [121/300], Step [59/225], Training Accuracy: 98.6229%, Training Loss: 0.0456%\n",
      "Epoch [121/300], Step [60/225], Training Accuracy: 98.6458%, Training Loss: 0.0451%\n",
      "Epoch [121/300], Step [61/225], Training Accuracy: 98.5912%, Training Loss: 0.0461%\n",
      "Epoch [121/300], Step [62/225], Training Accuracy: 98.6139%, Training Loss: 0.0456%\n",
      "Epoch [121/300], Step [63/225], Training Accuracy: 98.6111%, Training Loss: 0.0454%\n",
      "Epoch [121/300], Step [64/225], Training Accuracy: 98.6084%, Training Loss: 0.0455%\n",
      "Epoch [121/300], Step [65/225], Training Accuracy: 98.6058%, Training Loss: 0.0459%\n",
      "Epoch [121/300], Step [66/225], Training Accuracy: 98.6032%, Training Loss: 0.0459%\n",
      "Epoch [121/300], Step [67/225], Training Accuracy: 98.5774%, Training Loss: 0.0461%\n",
      "Epoch [121/300], Step [68/225], Training Accuracy: 98.5983%, Training Loss: 0.0458%\n",
      "Epoch [121/300], Step [69/225], Training Accuracy: 98.6187%, Training Loss: 0.0453%\n",
      "Epoch [121/300], Step [70/225], Training Accuracy: 98.5938%, Training Loss: 0.0457%\n",
      "Epoch [121/300], Step [71/225], Training Accuracy: 98.6136%, Training Loss: 0.0455%\n",
      "Epoch [121/300], Step [72/225], Training Accuracy: 98.6328%, Training Loss: 0.0452%\n",
      "Epoch [121/300], Step [73/225], Training Accuracy: 98.6515%, Training Loss: 0.0453%\n",
      "Epoch [121/300], Step [74/225], Training Accuracy: 98.6486%, Training Loss: 0.0454%\n",
      "Epoch [121/300], Step [75/225], Training Accuracy: 98.6250%, Training Loss: 0.0456%\n",
      "Epoch [121/300], Step [76/225], Training Accuracy: 98.6020%, Training Loss: 0.0464%\n",
      "Epoch [121/300], Step [77/225], Training Accuracy: 98.5795%, Training Loss: 0.0467%\n",
      "Epoch [121/300], Step [78/225], Training Accuracy: 98.5777%, Training Loss: 0.0465%\n",
      "Epoch [121/300], Step [79/225], Training Accuracy: 98.5759%, Training Loss: 0.0463%\n",
      "Epoch [121/300], Step [80/225], Training Accuracy: 98.5938%, Training Loss: 0.0460%\n",
      "Epoch [121/300], Step [81/225], Training Accuracy: 98.5918%, Training Loss: 0.0459%\n",
      "Epoch [121/300], Step [82/225], Training Accuracy: 98.6090%, Training Loss: 0.0455%\n",
      "Epoch [121/300], Step [83/225], Training Accuracy: 98.5881%, Training Loss: 0.0461%\n",
      "Epoch [121/300], Step [84/225], Training Accuracy: 98.6049%, Training Loss: 0.0458%\n",
      "Epoch [121/300], Step [85/225], Training Accuracy: 98.6213%, Training Loss: 0.0456%\n",
      "Epoch [121/300], Step [86/225], Training Accuracy: 98.6010%, Training Loss: 0.0459%\n",
      "Epoch [121/300], Step [87/225], Training Accuracy: 98.5991%, Training Loss: 0.0457%\n",
      "Epoch [121/300], Step [88/225], Training Accuracy: 98.6151%, Training Loss: 0.0456%\n",
      "Epoch [121/300], Step [89/225], Training Accuracy: 98.6131%, Training Loss: 0.0457%\n",
      "Epoch [121/300], Step [90/225], Training Accuracy: 98.5938%, Training Loss: 0.0459%\n",
      "Epoch [121/300], Step [91/225], Training Accuracy: 98.6092%, Training Loss: 0.0459%\n",
      "Epoch [121/300], Step [92/225], Training Accuracy: 98.6073%, Training Loss: 0.0458%\n",
      "Epoch [121/300], Step [93/225], Training Accuracy: 98.6055%, Training Loss: 0.0458%\n",
      "Epoch [121/300], Step [94/225], Training Accuracy: 98.6037%, Training Loss: 0.0460%\n",
      "Epoch [121/300], Step [95/225], Training Accuracy: 98.6020%, Training Loss: 0.0462%\n",
      "Epoch [121/300], Step [96/225], Training Accuracy: 98.6003%, Training Loss: 0.0460%\n",
      "Epoch [121/300], Step [97/225], Training Accuracy: 98.5986%, Training Loss: 0.0458%\n",
      "Epoch [121/300], Step [98/225], Training Accuracy: 98.5810%, Training Loss: 0.0461%\n",
      "Epoch [121/300], Step [99/225], Training Accuracy: 98.5795%, Training Loss: 0.0462%\n",
      "Epoch [121/300], Step [100/225], Training Accuracy: 98.5781%, Training Loss: 0.0462%\n",
      "Epoch [121/300], Step [101/225], Training Accuracy: 98.5922%, Training Loss: 0.0460%\n",
      "Epoch [121/300], Step [102/225], Training Accuracy: 98.5907%, Training Loss: 0.0461%\n",
      "Epoch [121/300], Step [103/225], Training Accuracy: 98.5892%, Training Loss: 0.0461%\n",
      "Epoch [121/300], Step [104/225], Training Accuracy: 98.6028%, Training Loss: 0.0458%\n",
      "Epoch [121/300], Step [105/225], Training Accuracy: 98.5863%, Training Loss: 0.0460%\n",
      "Epoch [121/300], Step [106/225], Training Accuracy: 98.5849%, Training Loss: 0.0459%\n",
      "Epoch [121/300], Step [107/225], Training Accuracy: 98.5689%, Training Loss: 0.0462%\n",
      "Epoch [121/300], Step [108/225], Training Accuracy: 98.5822%, Training Loss: 0.0459%\n",
      "Epoch [121/300], Step [109/225], Training Accuracy: 98.5952%, Training Loss: 0.0457%\n",
      "Epoch [121/300], Step [110/225], Training Accuracy: 98.6080%, Training Loss: 0.0454%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [121/300], Step [111/225], Training Accuracy: 98.5783%, Training Loss: 0.0456%\n",
      "Epoch [121/300], Step [112/225], Training Accuracy: 98.5910%, Training Loss: 0.0454%\n",
      "Epoch [121/300], Step [113/225], Training Accuracy: 98.6034%, Training Loss: 0.0451%\n",
      "Epoch [121/300], Step [114/225], Training Accuracy: 98.5883%, Training Loss: 0.0453%\n",
      "Epoch [121/300], Step [115/225], Training Accuracy: 98.5870%, Training Loss: 0.0451%\n",
      "Epoch [121/300], Step [116/225], Training Accuracy: 98.5991%, Training Loss: 0.0450%\n",
      "Epoch [121/300], Step [117/225], Training Accuracy: 98.5978%, Training Loss: 0.0448%\n",
      "Epoch [121/300], Step [118/225], Training Accuracy: 98.5964%, Training Loss: 0.0448%\n",
      "Epoch [121/300], Step [119/225], Training Accuracy: 98.5951%, Training Loss: 0.0447%\n",
      "Epoch [121/300], Step [120/225], Training Accuracy: 98.5938%, Training Loss: 0.0446%\n",
      "Epoch [121/300], Step [121/225], Training Accuracy: 98.6054%, Training Loss: 0.0446%\n",
      "Epoch [121/300], Step [122/225], Training Accuracy: 98.6168%, Training Loss: 0.0444%\n",
      "Epoch [121/300], Step [123/225], Training Accuracy: 98.6280%, Training Loss: 0.0442%\n",
      "Epoch [121/300], Step [124/225], Training Accuracy: 98.6265%, Training Loss: 0.0441%\n",
      "Epoch [121/300], Step [125/225], Training Accuracy: 98.6375%, Training Loss: 0.0439%\n",
      "Epoch [121/300], Step [126/225], Training Accuracy: 98.6359%, Training Loss: 0.0442%\n",
      "Epoch [121/300], Step [127/225], Training Accuracy: 98.6344%, Training Loss: 0.0441%\n",
      "Epoch [121/300], Step [128/225], Training Accuracy: 98.6450%, Training Loss: 0.0439%\n",
      "Epoch [121/300], Step [129/225], Training Accuracy: 98.6434%, Training Loss: 0.0440%\n",
      "Epoch [121/300], Step [130/225], Training Accuracy: 98.6418%, Training Loss: 0.0441%\n",
      "Epoch [121/300], Step [131/225], Training Accuracy: 98.6403%, Training Loss: 0.0440%\n",
      "Epoch [121/300], Step [132/225], Training Accuracy: 98.6506%, Training Loss: 0.0437%\n",
      "Epoch [121/300], Step [133/225], Training Accuracy: 98.6490%, Training Loss: 0.0437%\n",
      "Epoch [121/300], Step [134/225], Training Accuracy: 98.6474%, Training Loss: 0.0436%\n",
      "Epoch [121/300], Step [135/225], Training Accuracy: 98.6574%, Training Loss: 0.0434%\n",
      "Epoch [121/300], Step [136/225], Training Accuracy: 98.6558%, Training Loss: 0.0434%\n",
      "Epoch [121/300], Step [137/225], Training Accuracy: 98.6542%, Training Loss: 0.0434%\n",
      "Epoch [121/300], Step [138/225], Training Accuracy: 98.6639%, Training Loss: 0.0433%\n",
      "Epoch [121/300], Step [139/225], Training Accuracy: 98.6736%, Training Loss: 0.0434%\n",
      "Epoch [121/300], Step [140/225], Training Accuracy: 98.6830%, Training Loss: 0.0432%\n",
      "Epoch [121/300], Step [141/225], Training Accuracy: 98.6924%, Training Loss: 0.0431%\n",
      "Epoch [121/300], Step [142/225], Training Accuracy: 98.7016%, Training Loss: 0.0429%\n",
      "Epoch [121/300], Step [143/225], Training Accuracy: 98.7107%, Training Loss: 0.0429%\n",
      "Epoch [121/300], Step [144/225], Training Accuracy: 98.6979%, Training Loss: 0.0430%\n",
      "Epoch [121/300], Step [145/225], Training Accuracy: 98.7069%, Training Loss: 0.0429%\n",
      "Epoch [121/300], Step [146/225], Training Accuracy: 98.7051%, Training Loss: 0.0429%\n",
      "Epoch [121/300], Step [147/225], Training Accuracy: 98.7139%, Training Loss: 0.0428%\n",
      "Epoch [121/300], Step [148/225], Training Accuracy: 98.6909%, Training Loss: 0.0432%\n",
      "Epoch [121/300], Step [149/225], Training Accuracy: 98.6787%, Training Loss: 0.0435%\n",
      "Epoch [121/300], Step [150/225], Training Accuracy: 98.6562%, Training Loss: 0.0440%\n",
      "Epoch [121/300], Step [151/225], Training Accuracy: 98.6548%, Training Loss: 0.0439%\n",
      "Epoch [121/300], Step [152/225], Training Accuracy: 98.6534%, Training Loss: 0.0439%\n",
      "Epoch [121/300], Step [153/225], Training Accuracy: 98.6622%, Training Loss: 0.0437%\n",
      "Epoch [121/300], Step [154/225], Training Accuracy: 98.6607%, Training Loss: 0.0436%\n",
      "Epoch [121/300], Step [155/225], Training Accuracy: 98.6593%, Training Loss: 0.0435%\n",
      "Epoch [121/300], Step [156/225], Training Accuracy: 98.6679%, Training Loss: 0.0435%\n",
      "Epoch [121/300], Step [157/225], Training Accuracy: 98.6664%, Training Loss: 0.0435%\n",
      "Epoch [121/300], Step [158/225], Training Accuracy: 98.6551%, Training Loss: 0.0436%\n",
      "Epoch [121/300], Step [159/225], Training Accuracy: 98.6635%, Training Loss: 0.0434%\n",
      "Epoch [121/300], Step [160/225], Training Accuracy: 98.6523%, Training Loss: 0.0435%\n",
      "Epoch [121/300], Step [161/225], Training Accuracy: 98.6413%, Training Loss: 0.0436%\n",
      "Epoch [121/300], Step [162/225], Training Accuracy: 98.6304%, Training Loss: 0.0437%\n",
      "Epoch [121/300], Step [163/225], Training Accuracy: 98.6388%, Training Loss: 0.0436%\n",
      "Epoch [121/300], Step [164/225], Training Accuracy: 98.6471%, Training Loss: 0.0435%\n",
      "Epoch [121/300], Step [165/225], Training Accuracy: 98.6458%, Training Loss: 0.0435%\n",
      "Epoch [121/300], Step [166/225], Training Accuracy: 98.6446%, Training Loss: 0.0436%\n",
      "Epoch [121/300], Step [167/225], Training Accuracy: 98.6527%, Training Loss: 0.0435%\n",
      "Epoch [121/300], Step [168/225], Training Accuracy: 98.6607%, Training Loss: 0.0434%\n",
      "Epoch [121/300], Step [169/225], Training Accuracy: 98.6686%, Training Loss: 0.0432%\n",
      "Epoch [121/300], Step [170/225], Training Accuracy: 98.6765%, Training Loss: 0.0431%\n",
      "Epoch [121/300], Step [171/225], Training Accuracy: 98.6751%, Training Loss: 0.0431%\n",
      "Epoch [121/300], Step [172/225], Training Accuracy: 98.6828%, Training Loss: 0.0430%\n",
      "Epoch [121/300], Step [173/225], Training Accuracy: 98.6904%, Training Loss: 0.0428%\n",
      "Epoch [121/300], Step [174/225], Training Accuracy: 98.6979%, Training Loss: 0.0427%\n",
      "Epoch [121/300], Step [175/225], Training Accuracy: 98.6875%, Training Loss: 0.0428%\n",
      "Epoch [121/300], Step [176/225], Training Accuracy: 98.6861%, Training Loss: 0.0428%\n",
      "Epoch [121/300], Step [177/225], Training Accuracy: 98.6935%, Training Loss: 0.0427%\n",
      "Epoch [121/300], Step [178/225], Training Accuracy: 98.7008%, Training Loss: 0.0426%\n",
      "Epoch [121/300], Step [179/225], Training Accuracy: 98.7081%, Training Loss: 0.0425%\n",
      "Epoch [121/300], Step [180/225], Training Accuracy: 98.7066%, Training Loss: 0.0427%\n",
      "Epoch [121/300], Step [181/225], Training Accuracy: 98.6965%, Training Loss: 0.0428%\n",
      "Epoch [121/300], Step [182/225], Training Accuracy: 98.6865%, Training Loss: 0.0430%\n",
      "Epoch [121/300], Step [183/225], Training Accuracy: 98.6936%, Training Loss: 0.0428%\n",
      "Epoch [121/300], Step [184/225], Training Accuracy: 98.6923%, Training Loss: 0.0428%\n",
      "Epoch [121/300], Step [185/225], Training Accuracy: 98.6909%, Training Loss: 0.0428%\n",
      "Epoch [121/300], Step [186/225], Training Accuracy: 98.6979%, Training Loss: 0.0427%\n",
      "Epoch [121/300], Step [187/225], Training Accuracy: 98.6882%, Training Loss: 0.0428%\n",
      "Epoch [121/300], Step [188/225], Training Accuracy: 98.6868%, Training Loss: 0.0428%\n",
      "Epoch [121/300], Step [189/225], Training Accuracy: 98.6855%, Training Loss: 0.0429%\n",
      "Epoch [121/300], Step [190/225], Training Accuracy: 98.6842%, Training Loss: 0.0428%\n",
      "Epoch [121/300], Step [191/225], Training Accuracy: 98.6747%, Training Loss: 0.0428%\n",
      "Epoch [121/300], Step [192/225], Training Accuracy: 98.6816%, Training Loss: 0.0428%\n",
      "Epoch [121/300], Step [193/225], Training Accuracy: 98.6723%, Training Loss: 0.0428%\n",
      "Epoch [121/300], Step [194/225], Training Accuracy: 98.6791%, Training Loss: 0.0427%\n",
      "Epoch [121/300], Step [195/225], Training Accuracy: 98.6619%, Training Loss: 0.0429%\n",
      "Epoch [121/300], Step [196/225], Training Accuracy: 98.6687%, Training Loss: 0.0427%\n",
      "Epoch [121/300], Step [197/225], Training Accuracy: 98.6675%, Training Loss: 0.0428%\n",
      "Epoch [121/300], Step [198/225], Training Accuracy: 98.6664%, Training Loss: 0.0429%\n",
      "Epoch [121/300], Step [199/225], Training Accuracy: 98.6731%, Training Loss: 0.0428%\n",
      "Epoch [121/300], Step [200/225], Training Accuracy: 98.6641%, Training Loss: 0.0430%\n",
      "Epoch [121/300], Step [201/225], Training Accuracy: 98.6552%, Training Loss: 0.0431%\n",
      "Epoch [121/300], Step [202/225], Training Accuracy: 98.6541%, Training Loss: 0.0432%\n",
      "Epoch [121/300], Step [203/225], Training Accuracy: 98.6453%, Training Loss: 0.0433%\n",
      "Epoch [121/300], Step [204/225], Training Accuracy: 98.6443%, Training Loss: 0.0433%\n",
      "Epoch [121/300], Step [205/225], Training Accuracy: 98.6509%, Training Loss: 0.0433%\n",
      "Epoch [121/300], Step [206/225], Training Accuracy: 98.6575%, Training Loss: 0.0434%\n",
      "Epoch [121/300], Step [207/225], Training Accuracy: 98.6564%, Training Loss: 0.0433%\n",
      "Epoch [121/300], Step [208/225], Training Accuracy: 98.6629%, Training Loss: 0.0433%\n",
      "Epoch [121/300], Step [209/225], Training Accuracy: 98.6693%, Training Loss: 0.0432%\n",
      "Epoch [121/300], Step [210/225], Training Accuracy: 98.6682%, Training Loss: 0.0432%\n",
      "Epoch [121/300], Step [211/225], Training Accuracy: 98.6597%, Training Loss: 0.0434%\n",
      "Epoch [121/300], Step [212/225], Training Accuracy: 98.6512%, Training Loss: 0.0435%\n",
      "Epoch [121/300], Step [213/225], Training Accuracy: 98.6502%, Training Loss: 0.0435%\n",
      "Epoch [121/300], Step [214/225], Training Accuracy: 98.6492%, Training Loss: 0.0435%\n",
      "Epoch [121/300], Step [215/225], Training Accuracy: 98.6483%, Training Loss: 0.0436%\n",
      "Epoch [121/300], Step [216/225], Training Accuracy: 98.6473%, Training Loss: 0.0435%\n",
      "Epoch [121/300], Step [217/225], Training Accuracy: 98.6535%, Training Loss: 0.0434%\n",
      "Epoch [121/300], Step [218/225], Training Accuracy: 98.6454%, Training Loss: 0.0436%\n",
      "Epoch [121/300], Step [219/225], Training Accuracy: 98.6444%, Training Loss: 0.0435%\n",
      "Epoch [121/300], Step [220/225], Training Accuracy: 98.6435%, Training Loss: 0.0435%\n",
      "Epoch [121/300], Step [221/225], Training Accuracy: 98.6496%, Training Loss: 0.0434%\n",
      "Epoch [121/300], Step [222/225], Training Accuracy: 98.6557%, Training Loss: 0.0434%\n",
      "Epoch [121/300], Step [223/225], Training Accuracy: 98.6617%, Training Loss: 0.0433%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [121/300], Step [224/225], Training Accuracy: 98.6607%, Training Loss: 0.0433%\n",
      "Epoch [121/300], Step [225/225], Training Accuracy: 98.6659%, Training Loss: 0.0433%\n",
      "Epoch [122/300], Step [1/225], Training Accuracy: 98.4375%, Training Loss: 0.0617%\n",
      "Epoch [122/300], Step [2/225], Training Accuracy: 97.6562%, Training Loss: 0.0604%\n",
      "Epoch [122/300], Step [3/225], Training Accuracy: 97.9167%, Training Loss: 0.0594%\n",
      "Epoch [122/300], Step [4/225], Training Accuracy: 98.4375%, Training Loss: 0.0495%\n",
      "Epoch [122/300], Step [5/225], Training Accuracy: 98.7500%, Training Loss: 0.0454%\n",
      "Epoch [122/300], Step [6/225], Training Accuracy: 98.6979%, Training Loss: 0.0475%\n",
      "Epoch [122/300], Step [7/225], Training Accuracy: 98.4375%, Training Loss: 0.0480%\n",
      "Epoch [122/300], Step [8/225], Training Accuracy: 98.4375%, Training Loss: 0.0458%\n",
      "Epoch [122/300], Step [9/225], Training Accuracy: 98.4375%, Training Loss: 0.0469%\n",
      "Epoch [122/300], Step [10/225], Training Accuracy: 98.4375%, Training Loss: 0.0468%\n",
      "Epoch [122/300], Step [11/225], Training Accuracy: 98.5795%, Training Loss: 0.0462%\n",
      "Epoch [122/300], Step [12/225], Training Accuracy: 98.5677%, Training Loss: 0.0450%\n",
      "Epoch [122/300], Step [13/225], Training Accuracy: 98.5577%, Training Loss: 0.0446%\n",
      "Epoch [122/300], Step [14/225], Training Accuracy: 98.5491%, Training Loss: 0.0449%\n",
      "Epoch [122/300], Step [15/225], Training Accuracy: 98.5417%, Training Loss: 0.0439%\n",
      "Epoch [122/300], Step [16/225], Training Accuracy: 98.6328%, Training Loss: 0.0423%\n",
      "Epoch [122/300], Step [17/225], Training Accuracy: 98.5294%, Training Loss: 0.0427%\n",
      "Epoch [122/300], Step [18/225], Training Accuracy: 98.5243%, Training Loss: 0.0431%\n",
      "Epoch [122/300], Step [19/225], Training Accuracy: 98.5197%, Training Loss: 0.0429%\n",
      "Epoch [122/300], Step [20/225], Training Accuracy: 98.5938%, Training Loss: 0.0419%\n",
      "Epoch [122/300], Step [21/225], Training Accuracy: 98.6607%, Training Loss: 0.0410%\n",
      "Epoch [122/300], Step [22/225], Training Accuracy: 98.7216%, Training Loss: 0.0401%\n",
      "Epoch [122/300], Step [23/225], Training Accuracy: 98.5734%, Training Loss: 0.0414%\n",
      "Epoch [122/300], Step [24/225], Training Accuracy: 98.5677%, Training Loss: 0.0418%\n",
      "Epoch [122/300], Step [25/225], Training Accuracy: 98.6250%, Training Loss: 0.0405%\n",
      "Epoch [122/300], Step [26/225], Training Accuracy: 98.6178%, Training Loss: 0.0398%\n",
      "Epoch [122/300], Step [27/225], Training Accuracy: 98.6111%, Training Loss: 0.0409%\n",
      "Epoch [122/300], Step [28/225], Training Accuracy: 98.6607%, Training Loss: 0.0405%\n",
      "Epoch [122/300], Step [29/225], Training Accuracy: 98.7069%, Training Loss: 0.0407%\n",
      "Epoch [122/300], Step [30/225], Training Accuracy: 98.7500%, Training Loss: 0.0403%\n",
      "Epoch [122/300], Step [31/225], Training Accuracy: 98.7903%, Training Loss: 0.0399%\n",
      "Epoch [122/300], Step [32/225], Training Accuracy: 98.8281%, Training Loss: 0.0394%\n",
      "Epoch [122/300], Step [33/225], Training Accuracy: 98.8636%, Training Loss: 0.0389%\n",
      "Epoch [122/300], Step [34/225], Training Accuracy: 98.8971%, Training Loss: 0.0391%\n",
      "Epoch [122/300], Step [35/225], Training Accuracy: 98.9286%, Training Loss: 0.0390%\n",
      "Epoch [122/300], Step [36/225], Training Accuracy: 98.8715%, Training Loss: 0.0394%\n",
      "Epoch [122/300], Step [37/225], Training Accuracy: 98.8176%, Training Loss: 0.0397%\n",
      "Epoch [122/300], Step [38/225], Training Accuracy: 98.8076%, Training Loss: 0.0399%\n",
      "Epoch [122/300], Step [39/225], Training Accuracy: 98.7179%, Training Loss: 0.0413%\n",
      "Epoch [122/300], Step [40/225], Training Accuracy: 98.7109%, Training Loss: 0.0415%\n",
      "Epoch [122/300], Step [41/225], Training Accuracy: 98.6280%, Training Loss: 0.0424%\n",
      "Epoch [122/300], Step [42/225], Training Accuracy: 98.6607%, Training Loss: 0.0418%\n",
      "Epoch [122/300], Step [43/225], Training Accuracy: 98.6555%, Training Loss: 0.0415%\n",
      "Epoch [122/300], Step [44/225], Training Accuracy: 98.6151%, Training Loss: 0.0420%\n",
      "Epoch [122/300], Step [45/225], Training Accuracy: 98.6111%, Training Loss: 0.0420%\n",
      "Epoch [122/300], Step [46/225], Training Accuracy: 98.6413%, Training Loss: 0.0415%\n",
      "Epoch [122/300], Step [47/225], Training Accuracy: 98.6370%, Training Loss: 0.0414%\n",
      "Epoch [122/300], Step [48/225], Training Accuracy: 98.6328%, Training Loss: 0.0411%\n",
      "Epoch [122/300], Step [49/225], Training Accuracy: 98.6607%, Training Loss: 0.0408%\n",
      "Epoch [122/300], Step [50/225], Training Accuracy: 98.6562%, Training Loss: 0.0409%\n",
      "Epoch [122/300], Step [51/225], Training Accuracy: 98.6520%, Training Loss: 0.0408%\n",
      "Epoch [122/300], Step [52/225], Training Accuracy: 98.6779%, Training Loss: 0.0403%\n",
      "Epoch [122/300], Step [53/225], Training Accuracy: 98.6439%, Training Loss: 0.0404%\n",
      "Epoch [122/300], Step [54/225], Training Accuracy: 98.6690%, Training Loss: 0.0403%\n",
      "Epoch [122/300], Step [55/225], Training Accuracy: 98.6364%, Training Loss: 0.0407%\n",
      "Epoch [122/300], Step [56/225], Training Accuracy: 98.5770%, Training Loss: 0.0415%\n",
      "Epoch [122/300], Step [57/225], Training Accuracy: 98.6020%, Training Loss: 0.0412%\n",
      "Epoch [122/300], Step [58/225], Training Accuracy: 98.6261%, Training Loss: 0.0408%\n",
      "Epoch [122/300], Step [59/225], Training Accuracy: 98.5699%, Training Loss: 0.0415%\n",
      "Epoch [122/300], Step [60/225], Training Accuracy: 98.5677%, Training Loss: 0.0416%\n",
      "Epoch [122/300], Step [61/225], Training Accuracy: 98.5143%, Training Loss: 0.0423%\n",
      "Epoch [122/300], Step [62/225], Training Accuracy: 98.5131%, Training Loss: 0.0423%\n",
      "Epoch [122/300], Step [63/225], Training Accuracy: 98.5119%, Training Loss: 0.0427%\n",
      "Epoch [122/300], Step [64/225], Training Accuracy: 98.5352%, Training Loss: 0.0422%\n",
      "Epoch [122/300], Step [65/225], Training Accuracy: 98.5337%, Training Loss: 0.0425%\n",
      "Epoch [122/300], Step [66/225], Training Accuracy: 98.5322%, Training Loss: 0.0423%\n",
      "Epoch [122/300], Step [67/225], Training Accuracy: 98.5541%, Training Loss: 0.0422%\n",
      "Epoch [122/300], Step [68/225], Training Accuracy: 98.5524%, Training Loss: 0.0422%\n",
      "Epoch [122/300], Step [69/225], Training Accuracy: 98.5281%, Training Loss: 0.0432%\n",
      "Epoch [122/300], Step [70/225], Training Accuracy: 98.5268%, Training Loss: 0.0429%\n",
      "Epoch [122/300], Step [71/225], Training Accuracy: 98.5475%, Training Loss: 0.0426%\n",
      "Epoch [122/300], Step [72/225], Training Accuracy: 98.5243%, Training Loss: 0.0433%\n",
      "Epoch [122/300], Step [73/225], Training Accuracy: 98.5231%, Training Loss: 0.0432%\n",
      "Epoch [122/300], Step [74/225], Training Accuracy: 98.5431%, Training Loss: 0.0431%\n",
      "Epoch [122/300], Step [75/225], Training Accuracy: 98.5208%, Training Loss: 0.0434%\n",
      "Epoch [122/300], Step [76/225], Training Accuracy: 98.5197%, Training Loss: 0.0433%\n",
      "Epoch [122/300], Step [77/225], Training Accuracy: 98.4781%, Training Loss: 0.0439%\n",
      "Epoch [122/300], Step [78/225], Training Accuracy: 98.4575%, Training Loss: 0.0440%\n",
      "Epoch [122/300], Step [79/225], Training Accuracy: 98.4375%, Training Loss: 0.0442%\n",
      "Epoch [122/300], Step [80/225], Training Accuracy: 98.4180%, Training Loss: 0.0443%\n",
      "Epoch [122/300], Step [81/225], Training Accuracy: 98.4375%, Training Loss: 0.0441%\n",
      "Epoch [122/300], Step [82/225], Training Accuracy: 98.4375%, Training Loss: 0.0440%\n",
      "Epoch [122/300], Step [83/225], Training Accuracy: 98.4187%, Training Loss: 0.0444%\n",
      "Epoch [122/300], Step [84/225], Training Accuracy: 98.4375%, Training Loss: 0.0442%\n",
      "Epoch [122/300], Step [85/225], Training Accuracy: 98.4375%, Training Loss: 0.0440%\n",
      "Epoch [122/300], Step [86/225], Training Accuracy: 98.4375%, Training Loss: 0.0438%\n",
      "Epoch [122/300], Step [87/225], Training Accuracy: 98.4555%, Training Loss: 0.0435%\n",
      "Epoch [122/300], Step [88/225], Training Accuracy: 98.4730%, Training Loss: 0.0433%\n",
      "Epoch [122/300], Step [89/225], Training Accuracy: 98.4726%, Training Loss: 0.0433%\n",
      "Epoch [122/300], Step [90/225], Training Accuracy: 98.4896%, Training Loss: 0.0432%\n",
      "Epoch [122/300], Step [91/225], Training Accuracy: 98.4718%, Training Loss: 0.0437%\n",
      "Epoch [122/300], Step [92/225], Training Accuracy: 98.4715%, Training Loss: 0.0438%\n",
      "Epoch [122/300], Step [93/225], Training Accuracy: 98.4711%, Training Loss: 0.0438%\n",
      "Epoch [122/300], Step [94/225], Training Accuracy: 98.4874%, Training Loss: 0.0435%\n",
      "Epoch [122/300], Step [95/225], Training Accuracy: 98.4704%, Training Loss: 0.0436%\n",
      "Epoch [122/300], Step [96/225], Training Accuracy: 98.4863%, Training Loss: 0.0434%\n",
      "Epoch [122/300], Step [97/225], Training Accuracy: 98.4536%, Training Loss: 0.0437%\n",
      "Epoch [122/300], Step [98/225], Training Accuracy: 98.4534%, Training Loss: 0.0439%\n",
      "Epoch [122/300], Step [99/225], Training Accuracy: 98.4691%, Training Loss: 0.0437%\n",
      "Epoch [122/300], Step [100/225], Training Accuracy: 98.4688%, Training Loss: 0.0437%\n",
      "Epoch [122/300], Step [101/225], Training Accuracy: 98.4839%, Training Loss: 0.0437%\n",
      "Epoch [122/300], Step [102/225], Training Accuracy: 98.4988%, Training Loss: 0.0434%\n",
      "Epoch [122/300], Step [103/225], Training Accuracy: 98.5133%, Training Loss: 0.0432%\n",
      "Epoch [122/300], Step [104/225], Training Accuracy: 98.5276%, Training Loss: 0.0431%\n",
      "Epoch [122/300], Step [105/225], Training Accuracy: 98.5268%, Training Loss: 0.0432%\n",
      "Epoch [122/300], Step [106/225], Training Accuracy: 98.5112%, Training Loss: 0.0433%\n",
      "Epoch [122/300], Step [107/225], Training Accuracy: 98.5251%, Training Loss: 0.0431%\n",
      "Epoch [122/300], Step [108/225], Training Accuracy: 98.5388%, Training Loss: 0.0429%\n",
      "Epoch [122/300], Step [109/225], Training Accuracy: 98.5522%, Training Loss: 0.0427%\n",
      "Epoch [122/300], Step [110/225], Training Accuracy: 98.5653%, Training Loss: 0.0424%\n",
      "Epoch [122/300], Step [111/225], Training Accuracy: 98.5501%, Training Loss: 0.0427%\n",
      "Epoch [122/300], Step [112/225], Training Accuracy: 98.5212%, Training Loss: 0.0433%\n",
      "Epoch [122/300], Step [113/225], Training Accuracy: 98.4928%, Training Loss: 0.0436%\n",
      "Epoch [122/300], Step [114/225], Training Accuracy: 98.4923%, Training Loss: 0.0436%\n",
      "Epoch [122/300], Step [115/225], Training Accuracy: 98.4918%, Training Loss: 0.0434%\n",
      "Epoch [122/300], Step [116/225], Training Accuracy: 98.5048%, Training Loss: 0.0433%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [122/300], Step [117/225], Training Accuracy: 98.5176%, Training Loss: 0.0431%\n",
      "Epoch [122/300], Step [118/225], Training Accuracy: 98.5302%, Training Loss: 0.0429%\n",
      "Epoch [122/300], Step [119/225], Training Accuracy: 98.5425%, Training Loss: 0.0428%\n",
      "Epoch [122/300], Step [120/225], Training Accuracy: 98.5417%, Training Loss: 0.0430%\n",
      "Epoch [122/300], Step [121/225], Training Accuracy: 98.5537%, Training Loss: 0.0428%\n",
      "Epoch [122/300], Step [122/225], Training Accuracy: 98.5656%, Training Loss: 0.0426%\n",
      "Epoch [122/300], Step [123/225], Training Accuracy: 98.5645%, Training Loss: 0.0426%\n",
      "Epoch [122/300], Step [124/225], Training Accuracy: 98.5761%, Training Loss: 0.0425%\n",
      "Epoch [122/300], Step [125/225], Training Accuracy: 98.5625%, Training Loss: 0.0428%\n",
      "Epoch [122/300], Step [126/225], Training Accuracy: 98.5739%, Training Loss: 0.0429%\n",
      "Epoch [122/300], Step [127/225], Training Accuracy: 98.5728%, Training Loss: 0.0430%\n",
      "Epoch [122/300], Step [128/225], Training Accuracy: 98.5718%, Training Loss: 0.0429%\n",
      "Epoch [122/300], Step [129/225], Training Accuracy: 98.5828%, Training Loss: 0.0427%\n",
      "Epoch [122/300], Step [130/225], Training Accuracy: 98.5938%, Training Loss: 0.0427%\n",
      "Epoch [122/300], Step [131/225], Training Accuracy: 98.5926%, Training Loss: 0.0428%\n",
      "Epoch [122/300], Step [132/225], Training Accuracy: 98.6032%, Training Loss: 0.0426%\n",
      "Epoch [122/300], Step [133/225], Training Accuracy: 98.6020%, Training Loss: 0.0426%\n",
      "Epoch [122/300], Step [134/225], Training Accuracy: 98.6007%, Training Loss: 0.0426%\n",
      "Epoch [122/300], Step [135/225], Training Accuracy: 98.6111%, Training Loss: 0.0423%\n",
      "Epoch [122/300], Step [136/225], Training Accuracy: 98.5983%, Training Loss: 0.0424%\n",
      "Epoch [122/300], Step [137/225], Training Accuracy: 98.6086%, Training Loss: 0.0421%\n",
      "Epoch [122/300], Step [138/225], Training Accuracy: 98.6187%, Training Loss: 0.0421%\n",
      "Epoch [122/300], Step [139/225], Training Accuracy: 98.6174%, Training Loss: 0.0422%\n",
      "Epoch [122/300], Step [140/225], Training Accuracy: 98.6272%, Training Loss: 0.0420%\n",
      "Epoch [122/300], Step [141/225], Training Accuracy: 98.6370%, Training Loss: 0.0419%\n",
      "Epoch [122/300], Step [142/225], Training Accuracy: 98.6466%, Training Loss: 0.0417%\n",
      "Epoch [122/300], Step [143/225], Training Accuracy: 98.6560%, Training Loss: 0.0416%\n",
      "Epoch [122/300], Step [144/225], Training Accuracy: 98.6654%, Training Loss: 0.0415%\n",
      "Epoch [122/300], Step [145/225], Training Accuracy: 98.6530%, Training Loss: 0.0416%\n",
      "Epoch [122/300], Step [146/225], Training Accuracy: 98.6515%, Training Loss: 0.0416%\n",
      "Epoch [122/300], Step [147/225], Training Accuracy: 98.6395%, Training Loss: 0.0417%\n",
      "Epoch [122/300], Step [148/225], Training Accuracy: 98.6486%, Training Loss: 0.0416%\n",
      "Epoch [122/300], Step [149/225], Training Accuracy: 98.6577%, Training Loss: 0.0415%\n",
      "Epoch [122/300], Step [150/225], Training Accuracy: 98.6667%, Training Loss: 0.0413%\n",
      "Epoch [122/300], Step [151/225], Training Accuracy: 98.6755%, Training Loss: 0.0411%\n",
      "Epoch [122/300], Step [152/225], Training Accuracy: 98.6842%, Training Loss: 0.0409%\n",
      "Epoch [122/300], Step [153/225], Training Accuracy: 98.6826%, Training Loss: 0.0409%\n",
      "Epoch [122/300], Step [154/225], Training Accuracy: 98.6912%, Training Loss: 0.0408%\n",
      "Epoch [122/300], Step [155/225], Training Accuracy: 98.6996%, Training Loss: 0.0407%\n",
      "Epoch [122/300], Step [156/225], Training Accuracy: 98.6979%, Training Loss: 0.0409%\n",
      "Epoch [122/300], Step [157/225], Training Accuracy: 98.6963%, Training Loss: 0.0409%\n",
      "Epoch [122/300], Step [158/225], Training Accuracy: 98.7045%, Training Loss: 0.0408%\n",
      "Epoch [122/300], Step [159/225], Training Accuracy: 98.7028%, Training Loss: 0.0409%\n",
      "Epoch [122/300], Step [160/225], Training Accuracy: 98.7109%, Training Loss: 0.0407%\n",
      "Epoch [122/300], Step [161/225], Training Accuracy: 98.7189%, Training Loss: 0.0406%\n",
      "Epoch [122/300], Step [162/225], Training Accuracy: 98.7076%, Training Loss: 0.0406%\n",
      "Epoch [122/300], Step [163/225], Training Accuracy: 98.7059%, Training Loss: 0.0407%\n",
      "Epoch [122/300], Step [164/225], Training Accuracy: 98.6947%, Training Loss: 0.0410%\n",
      "Epoch [122/300], Step [165/225], Training Accuracy: 98.6932%, Training Loss: 0.0409%\n",
      "Epoch [122/300], Step [166/225], Training Accuracy: 98.6916%, Training Loss: 0.0410%\n",
      "Epoch [122/300], Step [167/225], Training Accuracy: 98.6621%, Training Loss: 0.0411%\n",
      "Epoch [122/300], Step [168/225], Training Accuracy: 98.6700%, Training Loss: 0.0410%\n",
      "Epoch [122/300], Step [169/225], Training Accuracy: 98.6686%, Training Loss: 0.0410%\n",
      "Epoch [122/300], Step [170/225], Training Accuracy: 98.6673%, Training Loss: 0.0410%\n",
      "Epoch [122/300], Step [171/225], Training Accuracy: 98.6751%, Training Loss: 0.0409%\n",
      "Epoch [122/300], Step [172/225], Training Accuracy: 98.6737%, Training Loss: 0.0408%\n",
      "Epoch [122/300], Step [173/225], Training Accuracy: 98.6814%, Training Loss: 0.0407%\n",
      "Epoch [122/300], Step [174/225], Training Accuracy: 98.6800%, Training Loss: 0.0408%\n",
      "Epoch [122/300], Step [175/225], Training Accuracy: 98.6875%, Training Loss: 0.0406%\n",
      "Epoch [122/300], Step [176/225], Training Accuracy: 98.6950%, Training Loss: 0.0405%\n",
      "Epoch [122/300], Step [177/225], Training Accuracy: 98.7023%, Training Loss: 0.0404%\n",
      "Epoch [122/300], Step [178/225], Training Accuracy: 98.7096%, Training Loss: 0.0402%\n",
      "Epoch [122/300], Step [179/225], Training Accuracy: 98.7168%, Training Loss: 0.0402%\n",
      "Epoch [122/300], Step [180/225], Training Accuracy: 98.7066%, Training Loss: 0.0403%\n",
      "Epoch [122/300], Step [181/225], Training Accuracy: 98.6965%, Training Loss: 0.0404%\n",
      "Epoch [122/300], Step [182/225], Training Accuracy: 98.6865%, Training Loss: 0.0407%\n",
      "Epoch [122/300], Step [183/225], Training Accuracy: 98.6936%, Training Loss: 0.0406%\n",
      "Epoch [122/300], Step [184/225], Training Accuracy: 98.6923%, Training Loss: 0.0405%\n",
      "Epoch [122/300], Step [185/225], Training Accuracy: 98.6909%, Training Loss: 0.0405%\n",
      "Epoch [122/300], Step [186/225], Training Accuracy: 98.6979%, Training Loss: 0.0404%\n",
      "Epoch [122/300], Step [187/225], Training Accuracy: 98.6882%, Training Loss: 0.0405%\n",
      "Epoch [122/300], Step [188/225], Training Accuracy: 98.6951%, Training Loss: 0.0405%\n",
      "Epoch [122/300], Step [189/225], Training Accuracy: 98.6938%, Training Loss: 0.0406%\n",
      "Epoch [122/300], Step [190/225], Training Accuracy: 98.6760%, Training Loss: 0.0408%\n",
      "Epoch [122/300], Step [191/225], Training Accuracy: 98.6747%, Training Loss: 0.0408%\n",
      "Epoch [122/300], Step [192/225], Training Accuracy: 98.6654%, Training Loss: 0.0409%\n",
      "Epoch [122/300], Step [193/225], Training Accuracy: 98.6561%, Training Loss: 0.0410%\n",
      "Epoch [122/300], Step [194/225], Training Accuracy: 98.6469%, Training Loss: 0.0411%\n",
      "Epoch [122/300], Step [195/225], Training Accuracy: 98.6538%, Training Loss: 0.0410%\n",
      "Epoch [122/300], Step [196/225], Training Accuracy: 98.6607%, Training Loss: 0.0409%\n",
      "Epoch [122/300], Step [197/225], Training Accuracy: 98.6675%, Training Loss: 0.0408%\n",
      "Epoch [122/300], Step [198/225], Training Accuracy: 98.6742%, Training Loss: 0.0407%\n",
      "Epoch [122/300], Step [199/225], Training Accuracy: 98.6731%, Training Loss: 0.0408%\n",
      "Epoch [122/300], Step [200/225], Training Accuracy: 98.6719%, Training Loss: 0.0407%\n",
      "Epoch [122/300], Step [201/225], Training Accuracy: 98.6785%, Training Loss: 0.0407%\n",
      "Epoch [122/300], Step [202/225], Training Accuracy: 98.6850%, Training Loss: 0.0407%\n",
      "Epoch [122/300], Step [203/225], Training Accuracy: 98.6915%, Training Loss: 0.0406%\n",
      "Epoch [122/300], Step [204/225], Training Accuracy: 98.6979%, Training Loss: 0.0407%\n",
      "Epoch [122/300], Step [205/225], Training Accuracy: 98.6966%, Training Loss: 0.0406%\n",
      "Epoch [122/300], Step [206/225], Training Accuracy: 98.6878%, Training Loss: 0.0408%\n",
      "Epoch [122/300], Step [207/225], Training Accuracy: 98.6941%, Training Loss: 0.0408%\n",
      "Epoch [122/300], Step [208/225], Training Accuracy: 98.6779%, Training Loss: 0.0411%\n",
      "Epoch [122/300], Step [209/225], Training Accuracy: 98.6767%, Training Loss: 0.0411%\n",
      "Epoch [122/300], Step [210/225], Training Accuracy: 98.6682%, Training Loss: 0.0412%\n",
      "Epoch [122/300], Step [211/225], Training Accuracy: 98.6597%, Training Loss: 0.0414%\n",
      "Epoch [122/300], Step [212/225], Training Accuracy: 98.6512%, Training Loss: 0.0415%\n",
      "Epoch [122/300], Step [213/225], Training Accuracy: 98.6502%, Training Loss: 0.0414%\n",
      "Epoch [122/300], Step [214/225], Training Accuracy: 98.6565%, Training Loss: 0.0414%\n",
      "Epoch [122/300], Step [215/225], Training Accuracy: 98.6410%, Training Loss: 0.0416%\n",
      "Epoch [122/300], Step [216/225], Training Accuracy: 98.6400%, Training Loss: 0.0417%\n",
      "Epoch [122/300], Step [217/225], Training Accuracy: 98.6391%, Training Loss: 0.0418%\n",
      "Epoch [122/300], Step [218/225], Training Accuracy: 98.6454%, Training Loss: 0.0417%\n",
      "Epoch [122/300], Step [219/225], Training Accuracy: 98.6444%, Training Loss: 0.0417%\n",
      "Epoch [122/300], Step [220/225], Training Accuracy: 98.6435%, Training Loss: 0.0417%\n",
      "Epoch [122/300], Step [221/225], Training Accuracy: 98.6425%, Training Loss: 0.0417%\n",
      "Epoch [122/300], Step [222/225], Training Accuracy: 98.6486%, Training Loss: 0.0416%\n",
      "Epoch [122/300], Step [223/225], Training Accuracy: 98.6477%, Training Loss: 0.0416%\n",
      "Epoch [122/300], Step [224/225], Training Accuracy: 98.6537%, Training Loss: 0.0416%\n",
      "Epoch [122/300], Step [225/225], Training Accuracy: 98.6590%, Training Loss: 0.0415%\n",
      "Epoch [123/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0317%\n",
      "Epoch [123/300], Step [2/225], Training Accuracy: 99.2188%, Training Loss: 0.0333%\n",
      "Epoch [123/300], Step [3/225], Training Accuracy: 98.9583%, Training Loss: 0.0316%\n",
      "Epoch [123/300], Step [4/225], Training Accuracy: 98.8281%, Training Loss: 0.0287%\n",
      "Epoch [123/300], Step [5/225], Training Accuracy: 99.0625%, Training Loss: 0.0255%\n",
      "Epoch [123/300], Step [6/225], Training Accuracy: 98.6979%, Training Loss: 0.0304%\n",
      "Epoch [123/300], Step [7/225], Training Accuracy: 98.6607%, Training Loss: 0.0315%\n",
      "Epoch [123/300], Step [8/225], Training Accuracy: 98.8281%, Training Loss: 0.0293%\n",
      "Epoch [123/300], Step [9/225], Training Accuracy: 98.6111%, Training Loss: 0.0336%\n",
      "Epoch [123/300], Step [10/225], Training Accuracy: 98.4375%, Training Loss: 0.0383%\n",
      "Epoch [123/300], Step [11/225], Training Accuracy: 98.5795%, Training Loss: 0.0356%\n",
      "Epoch [123/300], Step [12/225], Training Accuracy: 98.5677%, Training Loss: 0.0345%\n",
      "Epoch [123/300], Step [13/225], Training Accuracy: 98.5577%, Training Loss: 0.0360%\n",
      "Epoch [123/300], Step [14/225], Training Accuracy: 98.5491%, Training Loss: 0.0366%\n",
      "Epoch [123/300], Step [15/225], Training Accuracy: 98.6458%, Training Loss: 0.0365%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [123/300], Step [16/225], Training Accuracy: 98.7305%, Training Loss: 0.0351%\n",
      "Epoch [123/300], Step [17/225], Training Accuracy: 98.6213%, Training Loss: 0.0354%\n",
      "Epoch [123/300], Step [18/225], Training Accuracy: 98.5243%, Training Loss: 0.0372%\n",
      "Epoch [123/300], Step [19/225], Training Accuracy: 98.5197%, Training Loss: 0.0379%\n",
      "Epoch [123/300], Step [20/225], Training Accuracy: 98.5938%, Training Loss: 0.0375%\n",
      "Epoch [123/300], Step [21/225], Training Accuracy: 98.5863%, Training Loss: 0.0375%\n",
      "Epoch [123/300], Step [22/225], Training Accuracy: 98.5085%, Training Loss: 0.0384%\n",
      "Epoch [123/300], Step [23/225], Training Accuracy: 98.5734%, Training Loss: 0.0381%\n",
      "Epoch [123/300], Step [24/225], Training Accuracy: 98.5677%, Training Loss: 0.0382%\n",
      "Epoch [123/300], Step [25/225], Training Accuracy: 98.5625%, Training Loss: 0.0399%\n",
      "Epoch [123/300], Step [26/225], Training Accuracy: 98.5577%, Training Loss: 0.0397%\n",
      "Epoch [123/300], Step [27/225], Training Accuracy: 98.6111%, Training Loss: 0.0388%\n",
      "Epoch [123/300], Step [28/225], Training Accuracy: 98.4933%, Training Loss: 0.0422%\n",
      "Epoch [123/300], Step [29/225], Training Accuracy: 98.5453%, Training Loss: 0.0413%\n",
      "Epoch [123/300], Step [30/225], Training Accuracy: 98.5938%, Training Loss: 0.0407%\n",
      "Epoch [123/300], Step [31/225], Training Accuracy: 98.5383%, Training Loss: 0.0415%\n",
      "Epoch [123/300], Step [32/225], Training Accuracy: 98.5352%, Training Loss: 0.0417%\n",
      "Epoch [123/300], Step [33/225], Training Accuracy: 98.5322%, Training Loss: 0.0416%\n",
      "Epoch [123/300], Step [34/225], Training Accuracy: 98.5294%, Training Loss: 0.0419%\n",
      "Epoch [123/300], Step [35/225], Training Accuracy: 98.5268%, Training Loss: 0.0428%\n",
      "Epoch [123/300], Step [36/225], Training Accuracy: 98.5243%, Training Loss: 0.0426%\n",
      "Epoch [123/300], Step [37/225], Training Accuracy: 98.5642%, Training Loss: 0.0421%\n",
      "Epoch [123/300], Step [38/225], Training Accuracy: 98.5197%, Training Loss: 0.0429%\n",
      "Epoch [123/300], Step [39/225], Training Accuracy: 98.5176%, Training Loss: 0.0431%\n",
      "Epoch [123/300], Step [40/225], Training Accuracy: 98.5547%, Training Loss: 0.0425%\n",
      "Epoch [123/300], Step [41/225], Training Accuracy: 98.5518%, Training Loss: 0.0426%\n",
      "Epoch [123/300], Step [42/225], Training Accuracy: 98.5863%, Training Loss: 0.0418%\n",
      "Epoch [123/300], Step [43/225], Training Accuracy: 98.5828%, Training Loss: 0.0424%\n",
      "Epoch [123/300], Step [44/225], Training Accuracy: 98.6151%, Training Loss: 0.0418%\n",
      "Epoch [123/300], Step [45/225], Training Accuracy: 98.6458%, Training Loss: 0.0413%\n",
      "Epoch [123/300], Step [46/225], Training Accuracy: 98.6753%, Training Loss: 0.0408%\n",
      "Epoch [123/300], Step [47/225], Training Accuracy: 98.6370%, Training Loss: 0.0413%\n",
      "Epoch [123/300], Step [48/225], Training Accuracy: 98.6654%, Training Loss: 0.0408%\n",
      "Epoch [123/300], Step [49/225], Training Accuracy: 98.5969%, Training Loss: 0.0420%\n",
      "Epoch [123/300], Step [50/225], Training Accuracy: 98.6250%, Training Loss: 0.0418%\n",
      "Epoch [123/300], Step [51/225], Training Accuracy: 98.6213%, Training Loss: 0.0420%\n",
      "Epoch [123/300], Step [52/225], Training Accuracy: 98.6478%, Training Loss: 0.0413%\n",
      "Epoch [123/300], Step [53/225], Training Accuracy: 98.6733%, Training Loss: 0.0410%\n",
      "Epoch [123/300], Step [54/225], Training Accuracy: 98.6979%, Training Loss: 0.0409%\n",
      "Epoch [123/300], Step [55/225], Training Accuracy: 98.7216%, Training Loss: 0.0408%\n",
      "Epoch [123/300], Step [56/225], Training Accuracy: 98.7165%, Training Loss: 0.0410%\n",
      "Epoch [123/300], Step [57/225], Training Accuracy: 98.7390%, Training Loss: 0.0407%\n",
      "Epoch [123/300], Step [58/225], Training Accuracy: 98.6800%, Training Loss: 0.0421%\n",
      "Epoch [123/300], Step [59/225], Training Accuracy: 98.7023%, Training Loss: 0.0417%\n",
      "Epoch [123/300], Step [60/225], Training Accuracy: 98.7240%, Training Loss: 0.0413%\n",
      "Epoch [123/300], Step [61/225], Training Accuracy: 98.7193%, Training Loss: 0.0417%\n",
      "Epoch [123/300], Step [62/225], Training Accuracy: 98.7399%, Training Loss: 0.0414%\n",
      "Epoch [123/300], Step [63/225], Training Accuracy: 98.7599%, Training Loss: 0.0413%\n",
      "Epoch [123/300], Step [64/225], Training Accuracy: 98.7549%, Training Loss: 0.0414%\n",
      "Epoch [123/300], Step [65/225], Training Accuracy: 98.7500%, Training Loss: 0.0414%\n",
      "Epoch [123/300], Step [66/225], Training Accuracy: 98.7453%, Training Loss: 0.0416%\n",
      "Epoch [123/300], Step [67/225], Training Accuracy: 98.7640%, Training Loss: 0.0415%\n",
      "Epoch [123/300], Step [68/225], Training Accuracy: 98.7362%, Training Loss: 0.0421%\n",
      "Epoch [123/300], Step [69/225], Training Accuracy: 98.7319%, Training Loss: 0.0422%\n",
      "Epoch [123/300], Step [70/225], Training Accuracy: 98.7277%, Training Loss: 0.0422%\n",
      "Epoch [123/300], Step [71/225], Training Accuracy: 98.6796%, Training Loss: 0.0426%\n",
      "Epoch [123/300], Step [72/225], Training Accuracy: 98.6545%, Training Loss: 0.0429%\n",
      "Epoch [123/300], Step [73/225], Training Accuracy: 98.6729%, Training Loss: 0.0428%\n",
      "Epoch [123/300], Step [74/225], Training Accuracy: 98.6909%, Training Loss: 0.0426%\n",
      "Epoch [123/300], Step [75/225], Training Accuracy: 98.7083%, Training Loss: 0.0425%\n",
      "Epoch [123/300], Step [76/225], Training Accuracy: 98.6637%, Training Loss: 0.0433%\n",
      "Epoch [123/300], Step [77/225], Training Accuracy: 98.6607%, Training Loss: 0.0434%\n",
      "Epoch [123/300], Step [78/225], Training Accuracy: 98.6779%, Training Loss: 0.0433%\n",
      "Epoch [123/300], Step [79/225], Training Accuracy: 98.6748%, Training Loss: 0.0433%\n",
      "Epoch [123/300], Step [80/225], Training Accuracy: 98.6914%, Training Loss: 0.0433%\n",
      "Epoch [123/300], Step [81/225], Training Accuracy: 98.6883%, Training Loss: 0.0431%\n",
      "Epoch [123/300], Step [82/225], Training Accuracy: 98.6852%, Training Loss: 0.0429%\n",
      "Epoch [123/300], Step [83/225], Training Accuracy: 98.6822%, Training Loss: 0.0430%\n",
      "Epoch [123/300], Step [84/225], Training Accuracy: 98.6421%, Training Loss: 0.0435%\n",
      "Epoch [123/300], Step [85/225], Training Accuracy: 98.6581%, Training Loss: 0.0434%\n",
      "Epoch [123/300], Step [86/225], Training Accuracy: 98.6374%, Training Loss: 0.0438%\n",
      "Epoch [123/300], Step [87/225], Training Accuracy: 98.6171%, Training Loss: 0.0439%\n",
      "Epoch [123/300], Step [88/225], Training Accuracy: 98.6151%, Training Loss: 0.0438%\n",
      "Epoch [123/300], Step [89/225], Training Accuracy: 98.6306%, Training Loss: 0.0435%\n",
      "Epoch [123/300], Step [90/225], Training Accuracy: 98.6458%, Training Loss: 0.0432%\n",
      "Epoch [123/300], Step [91/225], Training Accuracy: 98.6607%, Training Loss: 0.0431%\n",
      "Epoch [123/300], Step [92/225], Training Accuracy: 98.6753%, Training Loss: 0.0430%\n",
      "Epoch [123/300], Step [93/225], Training Accuracy: 98.6559%, Training Loss: 0.0430%\n",
      "Epoch [123/300], Step [94/225], Training Accuracy: 98.6536%, Training Loss: 0.0431%\n",
      "Epoch [123/300], Step [95/225], Training Accuracy: 98.6513%, Training Loss: 0.0431%\n",
      "Epoch [123/300], Step [96/225], Training Accuracy: 98.6654%, Training Loss: 0.0432%\n",
      "Epoch [123/300], Step [97/225], Training Accuracy: 98.6630%, Training Loss: 0.0432%\n",
      "Epoch [123/300], Step [98/225], Training Accuracy: 98.6767%, Training Loss: 0.0430%\n",
      "Epoch [123/300], Step [99/225], Training Accuracy: 98.6900%, Training Loss: 0.0428%\n",
      "Epoch [123/300], Step [100/225], Training Accuracy: 98.7031%, Training Loss: 0.0426%\n",
      "Epoch [123/300], Step [101/225], Training Accuracy: 98.7160%, Training Loss: 0.0424%\n",
      "Epoch [123/300], Step [102/225], Training Accuracy: 98.7132%, Training Loss: 0.0425%\n",
      "Epoch [123/300], Step [103/225], Training Accuracy: 98.7257%, Training Loss: 0.0424%\n",
      "Epoch [123/300], Step [104/225], Training Accuracy: 98.7380%, Training Loss: 0.0421%\n",
      "Epoch [123/300], Step [105/225], Training Accuracy: 98.7351%, Training Loss: 0.0421%\n",
      "Epoch [123/300], Step [106/225], Training Accuracy: 98.7471%, Training Loss: 0.0420%\n",
      "Epoch [123/300], Step [107/225], Training Accuracy: 98.7588%, Training Loss: 0.0418%\n",
      "Epoch [123/300], Step [108/225], Training Accuracy: 98.7413%, Training Loss: 0.0421%\n",
      "Epoch [123/300], Step [109/225], Training Accuracy: 98.7529%, Training Loss: 0.0420%\n",
      "Epoch [123/300], Step [110/225], Training Accuracy: 98.7500%, Training Loss: 0.0419%\n",
      "Epoch [123/300], Step [111/225], Training Accuracy: 98.7472%, Training Loss: 0.0419%\n",
      "Epoch [123/300], Step [112/225], Training Accuracy: 98.7165%, Training Loss: 0.0422%\n",
      "Epoch [123/300], Step [113/225], Training Accuracy: 98.7140%, Training Loss: 0.0421%\n",
      "Epoch [123/300], Step [114/225], Training Accuracy: 98.7253%, Training Loss: 0.0421%\n",
      "Epoch [123/300], Step [115/225], Training Accuracy: 98.7364%, Training Loss: 0.0418%\n",
      "Epoch [123/300], Step [116/225], Training Accuracy: 98.7204%, Training Loss: 0.0421%\n",
      "Epoch [123/300], Step [117/225], Training Accuracy: 98.7313%, Training Loss: 0.0419%\n",
      "Epoch [123/300], Step [118/225], Training Accuracy: 98.7023%, Training Loss: 0.0422%\n",
      "Epoch [123/300], Step [119/225], Training Accuracy: 98.7001%, Training Loss: 0.0423%\n",
      "Epoch [123/300], Step [120/225], Training Accuracy: 98.6979%, Training Loss: 0.0425%\n",
      "Epoch [123/300], Step [121/225], Training Accuracy: 98.7087%, Training Loss: 0.0424%\n",
      "Epoch [123/300], Step [122/225], Training Accuracy: 98.7193%, Training Loss: 0.0423%\n",
      "Epoch [123/300], Step [123/225], Training Accuracy: 98.7297%, Training Loss: 0.0421%\n",
      "Epoch [123/300], Step [124/225], Training Accuracy: 98.7273%, Training Loss: 0.0422%\n",
      "Epoch [123/300], Step [125/225], Training Accuracy: 98.7375%, Training Loss: 0.0423%\n",
      "Epoch [123/300], Step [126/225], Training Accuracy: 98.7475%, Training Loss: 0.0422%\n",
      "Epoch [123/300], Step [127/225], Training Accuracy: 98.7205%, Training Loss: 0.0426%\n",
      "Epoch [123/300], Step [128/225], Training Accuracy: 98.7305%, Training Loss: 0.0424%\n",
      "Epoch [123/300], Step [129/225], Training Accuracy: 98.7282%, Training Loss: 0.0423%\n",
      "Epoch [123/300], Step [130/225], Training Accuracy: 98.7380%, Training Loss: 0.0422%\n",
      "Epoch [123/300], Step [131/225], Training Accuracy: 98.7357%, Training Loss: 0.0422%\n",
      "Epoch [123/300], Step [132/225], Training Accuracy: 98.7334%, Training Loss: 0.0421%\n",
      "Epoch [123/300], Step [133/225], Training Accuracy: 98.7312%, Training Loss: 0.0422%\n",
      "Epoch [123/300], Step [134/225], Training Accuracy: 98.7407%, Training Loss: 0.0421%\n",
      "Epoch [123/300], Step [135/225], Training Accuracy: 98.7500%, Training Loss: 0.0420%\n",
      "Epoch [123/300], Step [136/225], Training Accuracy: 98.7477%, Training Loss: 0.0420%\n",
      "Epoch [123/300], Step [137/225], Training Accuracy: 98.7340%, Training Loss: 0.0423%\n",
      "Epoch [123/300], Step [138/225], Training Accuracy: 98.7432%, Training Loss: 0.0422%\n",
      "Epoch [123/300], Step [139/225], Training Accuracy: 98.7410%, Training Loss: 0.0424%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [123/300], Step [140/225], Training Accuracy: 98.7388%, Training Loss: 0.0425%\n",
      "Epoch [123/300], Step [141/225], Training Accuracy: 98.7256%, Training Loss: 0.0426%\n",
      "Epoch [123/300], Step [142/225], Training Accuracy: 98.7236%, Training Loss: 0.0427%\n",
      "Epoch [123/300], Step [143/225], Training Accuracy: 98.7325%, Training Loss: 0.0426%\n",
      "Epoch [123/300], Step [144/225], Training Accuracy: 98.7413%, Training Loss: 0.0424%\n",
      "Epoch [123/300], Step [145/225], Training Accuracy: 98.7392%, Training Loss: 0.0423%\n",
      "Epoch [123/300], Step [146/225], Training Accuracy: 98.7479%, Training Loss: 0.0421%\n",
      "Epoch [123/300], Step [147/225], Training Accuracy: 98.7457%, Training Loss: 0.0422%\n",
      "Epoch [123/300], Step [148/225], Training Accuracy: 98.7437%, Training Loss: 0.0425%\n",
      "Epoch [123/300], Step [149/225], Training Accuracy: 98.7311%, Training Loss: 0.0429%\n",
      "Epoch [123/300], Step [150/225], Training Accuracy: 98.7396%, Training Loss: 0.0427%\n",
      "Epoch [123/300], Step [151/225], Training Accuracy: 98.7272%, Training Loss: 0.0430%\n",
      "Epoch [123/300], Step [152/225], Training Accuracy: 98.7356%, Training Loss: 0.0429%\n",
      "Epoch [123/300], Step [153/225], Training Accuracy: 98.7337%, Training Loss: 0.0430%\n",
      "Epoch [123/300], Step [154/225], Training Accuracy: 98.7317%, Training Loss: 0.0429%\n",
      "Epoch [123/300], Step [155/225], Training Accuracy: 98.7399%, Training Loss: 0.0428%\n",
      "Epoch [123/300], Step [156/225], Training Accuracy: 98.7480%, Training Loss: 0.0426%\n",
      "Epoch [123/300], Step [157/225], Training Accuracy: 98.7361%, Training Loss: 0.0428%\n",
      "Epoch [123/300], Step [158/225], Training Accuracy: 98.7441%, Training Loss: 0.0428%\n",
      "Epoch [123/300], Step [159/225], Training Accuracy: 98.7421%, Training Loss: 0.0427%\n",
      "Epoch [123/300], Step [160/225], Training Accuracy: 98.7500%, Training Loss: 0.0426%\n",
      "Epoch [123/300], Step [161/225], Training Accuracy: 98.7481%, Training Loss: 0.0425%\n",
      "Epoch [123/300], Step [162/225], Training Accuracy: 98.7365%, Training Loss: 0.0425%\n",
      "Epoch [123/300], Step [163/225], Training Accuracy: 98.7442%, Training Loss: 0.0424%\n",
      "Epoch [123/300], Step [164/225], Training Accuracy: 98.7424%, Training Loss: 0.0424%\n",
      "Epoch [123/300], Step [165/225], Training Accuracy: 98.7405%, Training Loss: 0.0424%\n",
      "Epoch [123/300], Step [166/225], Training Accuracy: 98.7387%, Training Loss: 0.0426%\n",
      "Epoch [123/300], Step [167/225], Training Accuracy: 98.7369%, Training Loss: 0.0427%\n",
      "Epoch [123/300], Step [168/225], Training Accuracy: 98.7351%, Training Loss: 0.0426%\n",
      "Epoch [123/300], Step [169/225], Training Accuracy: 98.7426%, Training Loss: 0.0424%\n",
      "Epoch [123/300], Step [170/225], Training Accuracy: 98.7408%, Training Loss: 0.0426%\n",
      "Epoch [123/300], Step [171/225], Training Accuracy: 98.7299%, Training Loss: 0.0427%\n",
      "Epoch [123/300], Step [172/225], Training Accuracy: 98.7373%, Training Loss: 0.0425%\n",
      "Epoch [123/300], Step [173/225], Training Accuracy: 98.7446%, Training Loss: 0.0424%\n",
      "Epoch [123/300], Step [174/225], Training Accuracy: 98.7338%, Training Loss: 0.0424%\n",
      "Epoch [123/300], Step [175/225], Training Accuracy: 98.7321%, Training Loss: 0.0425%\n",
      "Epoch [123/300], Step [176/225], Training Accuracy: 98.7393%, Training Loss: 0.0424%\n",
      "Epoch [123/300], Step [177/225], Training Accuracy: 98.7376%, Training Loss: 0.0424%\n",
      "Epoch [123/300], Step [178/225], Training Accuracy: 98.7447%, Training Loss: 0.0422%\n",
      "Epoch [123/300], Step [179/225], Training Accuracy: 98.7430%, Training Loss: 0.0422%\n",
      "Epoch [123/300], Step [180/225], Training Accuracy: 98.7413%, Training Loss: 0.0423%\n",
      "Epoch [123/300], Step [181/225], Training Accuracy: 98.7310%, Training Loss: 0.0424%\n",
      "Epoch [123/300], Step [182/225], Training Accuracy: 98.7294%, Training Loss: 0.0425%\n",
      "Epoch [123/300], Step [183/225], Training Accuracy: 98.7107%, Training Loss: 0.0426%\n",
      "Epoch [123/300], Step [184/225], Training Accuracy: 98.7092%, Training Loss: 0.0426%\n",
      "Epoch [123/300], Step [185/225], Training Accuracy: 98.7162%, Training Loss: 0.0424%\n",
      "Epoch [123/300], Step [186/225], Training Accuracy: 98.7231%, Training Loss: 0.0423%\n",
      "Epoch [123/300], Step [187/225], Training Accuracy: 98.7216%, Training Loss: 0.0423%\n",
      "Epoch [123/300], Step [188/225], Training Accuracy: 98.7284%, Training Loss: 0.0422%\n",
      "Epoch [123/300], Step [189/225], Training Accuracy: 98.7269%, Training Loss: 0.0422%\n",
      "Epoch [123/300], Step [190/225], Training Accuracy: 98.7089%, Training Loss: 0.0427%\n",
      "Epoch [123/300], Step [191/225], Training Accuracy: 98.7156%, Training Loss: 0.0425%\n",
      "Epoch [123/300], Step [192/225], Training Accuracy: 98.7223%, Training Loss: 0.0424%\n",
      "Epoch [123/300], Step [193/225], Training Accuracy: 98.7128%, Training Loss: 0.0425%\n",
      "Epoch [123/300], Step [194/225], Training Accuracy: 98.7113%, Training Loss: 0.0425%\n",
      "Epoch [123/300], Step [195/225], Training Accuracy: 98.7179%, Training Loss: 0.0424%\n",
      "Epoch [123/300], Step [196/225], Training Accuracy: 98.7165%, Training Loss: 0.0424%\n",
      "Epoch [123/300], Step [197/225], Training Accuracy: 98.7151%, Training Loss: 0.0423%\n",
      "Epoch [123/300], Step [198/225], Training Accuracy: 98.7058%, Training Loss: 0.0424%\n",
      "Epoch [123/300], Step [199/225], Training Accuracy: 98.7123%, Training Loss: 0.0422%\n",
      "Epoch [123/300], Step [200/225], Training Accuracy: 98.7188%, Training Loss: 0.0421%\n",
      "Epoch [123/300], Step [201/225], Training Accuracy: 98.7018%, Training Loss: 0.0422%\n",
      "Epoch [123/300], Step [202/225], Training Accuracy: 98.7005%, Training Loss: 0.0422%\n",
      "Epoch [123/300], Step [203/225], Training Accuracy: 98.6992%, Training Loss: 0.0422%\n",
      "Epoch [123/300], Step [204/225], Training Accuracy: 98.6979%, Training Loss: 0.0422%\n",
      "Epoch [123/300], Step [205/225], Training Accuracy: 98.6890%, Training Loss: 0.0423%\n",
      "Epoch [123/300], Step [206/225], Training Accuracy: 98.6878%, Training Loss: 0.0423%\n",
      "Epoch [123/300], Step [207/225], Training Accuracy: 98.6866%, Training Loss: 0.0423%\n",
      "Epoch [123/300], Step [208/225], Training Accuracy: 98.6929%, Training Loss: 0.0422%\n",
      "Epoch [123/300], Step [209/225], Training Accuracy: 98.6992%, Training Loss: 0.0420%\n",
      "Epoch [123/300], Step [210/225], Training Accuracy: 98.6979%, Training Loss: 0.0421%\n",
      "Epoch [123/300], Step [211/225], Training Accuracy: 98.6967%, Training Loss: 0.0421%\n",
      "Epoch [123/300], Step [212/225], Training Accuracy: 98.7028%, Training Loss: 0.0420%\n",
      "Epoch [123/300], Step [213/225], Training Accuracy: 98.6942%, Training Loss: 0.0421%\n",
      "Epoch [123/300], Step [214/225], Training Accuracy: 98.7004%, Training Loss: 0.0420%\n",
      "Epoch [123/300], Step [215/225], Training Accuracy: 98.6991%, Training Loss: 0.0420%\n",
      "Epoch [123/300], Step [216/225], Training Accuracy: 98.6979%, Training Loss: 0.0423%\n",
      "Epoch [123/300], Step [217/225], Training Accuracy: 98.6967%, Training Loss: 0.0424%\n",
      "Epoch [123/300], Step [218/225], Training Accuracy: 98.6955%, Training Loss: 0.0424%\n",
      "Epoch [123/300], Step [219/225], Training Accuracy: 98.7015%, Training Loss: 0.0423%\n",
      "Epoch [123/300], Step [220/225], Training Accuracy: 98.7003%, Training Loss: 0.0422%\n",
      "Epoch [123/300], Step [221/225], Training Accuracy: 98.6991%, Training Loss: 0.0422%\n",
      "Epoch [123/300], Step [222/225], Training Accuracy: 98.6979%, Training Loss: 0.0423%\n",
      "Epoch [123/300], Step [223/225], Training Accuracy: 98.6967%, Training Loss: 0.0423%\n",
      "Epoch [123/300], Step [224/225], Training Accuracy: 98.7026%, Training Loss: 0.0422%\n",
      "Epoch [123/300], Step [225/225], Training Accuracy: 98.7076%, Training Loss: 0.0421%\n",
      "Epoch [124/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0241%\n",
      "Epoch [124/300], Step [2/225], Training Accuracy: 100.0000%, Training Loss: 0.0192%\n",
      "Epoch [124/300], Step [3/225], Training Accuracy: 100.0000%, Training Loss: 0.0202%\n",
      "Epoch [124/300], Step [4/225], Training Accuracy: 100.0000%, Training Loss: 0.0259%\n",
      "Epoch [124/300], Step [5/225], Training Accuracy: 99.6875%, Training Loss: 0.0277%\n",
      "Epoch [124/300], Step [6/225], Training Accuracy: 99.4792%, Training Loss: 0.0282%\n",
      "Epoch [124/300], Step [7/225], Training Accuracy: 99.3304%, Training Loss: 0.0294%\n",
      "Epoch [124/300], Step [8/225], Training Accuracy: 99.4141%, Training Loss: 0.0283%\n",
      "Epoch [124/300], Step [9/225], Training Accuracy: 99.3056%, Training Loss: 0.0295%\n",
      "Epoch [124/300], Step [10/225], Training Accuracy: 99.2188%, Training Loss: 0.0302%\n",
      "Epoch [124/300], Step [11/225], Training Accuracy: 99.2898%, Training Loss: 0.0287%\n",
      "Epoch [124/300], Step [12/225], Training Accuracy: 99.3490%, Training Loss: 0.0271%\n",
      "Epoch [124/300], Step [13/225], Training Accuracy: 99.1587%, Training Loss: 0.0309%\n",
      "Epoch [124/300], Step [14/225], Training Accuracy: 98.9955%, Training Loss: 0.0342%\n",
      "Epoch [124/300], Step [15/225], Training Accuracy: 98.9583%, Training Loss: 0.0363%\n",
      "Epoch [124/300], Step [16/225], Training Accuracy: 98.9258%, Training Loss: 0.0364%\n",
      "Epoch [124/300], Step [17/225], Training Accuracy: 98.9890%, Training Loss: 0.0360%\n",
      "Epoch [124/300], Step [18/225], Training Accuracy: 98.8715%, Training Loss: 0.0378%\n",
      "Epoch [124/300], Step [19/225], Training Accuracy: 98.7664%, Training Loss: 0.0383%\n",
      "Epoch [124/300], Step [20/225], Training Accuracy: 98.8281%, Training Loss: 0.0373%\n",
      "Epoch [124/300], Step [21/225], Training Accuracy: 98.8839%, Training Loss: 0.0364%\n",
      "Epoch [124/300], Step [22/225], Training Accuracy: 98.7216%, Training Loss: 0.0379%\n",
      "Epoch [124/300], Step [23/225], Training Accuracy: 98.7092%, Training Loss: 0.0378%\n",
      "Epoch [124/300], Step [24/225], Training Accuracy: 98.7630%, Training Loss: 0.0377%\n",
      "Epoch [124/300], Step [25/225], Training Accuracy: 98.6875%, Training Loss: 0.0384%\n",
      "Epoch [124/300], Step [26/225], Training Accuracy: 98.7380%, Training Loss: 0.0373%\n",
      "Epoch [124/300], Step [27/225], Training Accuracy: 98.7269%, Training Loss: 0.0368%\n",
      "Epoch [124/300], Step [28/225], Training Accuracy: 98.7165%, Training Loss: 0.0374%\n",
      "Epoch [124/300], Step [29/225], Training Accuracy: 98.6530%, Training Loss: 0.0373%\n",
      "Epoch [124/300], Step [30/225], Training Accuracy: 98.6979%, Training Loss: 0.0365%\n",
      "Epoch [124/300], Step [31/225], Training Accuracy: 98.5887%, Training Loss: 0.0379%\n",
      "Epoch [124/300], Step [32/225], Training Accuracy: 98.6328%, Training Loss: 0.0371%\n",
      "Epoch [124/300], Step [33/225], Training Accuracy: 98.6742%, Training Loss: 0.0363%\n",
      "Epoch [124/300], Step [34/225], Training Accuracy: 98.7132%, Training Loss: 0.0362%\n",
      "Epoch [124/300], Step [35/225], Training Accuracy: 98.7500%, Training Loss: 0.0362%\n",
      "Epoch [124/300], Step [36/225], Training Accuracy: 98.6545%, Training Loss: 0.0377%\n",
      "Epoch [124/300], Step [37/225], Training Accuracy: 98.6486%, Training Loss: 0.0376%\n",
      "Epoch [124/300], Step [38/225], Training Accuracy: 98.6431%, Training Loss: 0.0375%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [124/300], Step [39/225], Training Accuracy: 98.6378%, Training Loss: 0.0380%\n",
      "Epoch [124/300], Step [40/225], Training Accuracy: 98.6719%, Training Loss: 0.0376%\n",
      "Epoch [124/300], Step [41/225], Training Accuracy: 98.6280%, Training Loss: 0.0382%\n",
      "Epoch [124/300], Step [42/225], Training Accuracy: 98.5863%, Training Loss: 0.0387%\n",
      "Epoch [124/300], Step [43/225], Training Accuracy: 98.6192%, Training Loss: 0.0385%\n",
      "Epoch [124/300], Step [44/225], Training Accuracy: 98.6151%, Training Loss: 0.0387%\n",
      "Epoch [124/300], Step [45/225], Training Accuracy: 98.6458%, Training Loss: 0.0384%\n",
      "Epoch [124/300], Step [46/225], Training Accuracy: 98.6413%, Training Loss: 0.0379%\n",
      "Epoch [124/300], Step [47/225], Training Accuracy: 98.6037%, Training Loss: 0.0386%\n",
      "Epoch [124/300], Step [48/225], Training Accuracy: 98.6003%, Training Loss: 0.0387%\n",
      "Epoch [124/300], Step [49/225], Training Accuracy: 98.6288%, Training Loss: 0.0382%\n",
      "Epoch [124/300], Step [50/225], Training Accuracy: 98.6250%, Training Loss: 0.0382%\n",
      "Epoch [124/300], Step [51/225], Training Accuracy: 98.6520%, Training Loss: 0.0381%\n",
      "Epoch [124/300], Step [52/225], Training Accuracy: 98.6478%, Training Loss: 0.0380%\n",
      "Epoch [124/300], Step [53/225], Training Accuracy: 98.6439%, Training Loss: 0.0382%\n",
      "Epoch [124/300], Step [54/225], Training Accuracy: 98.6111%, Training Loss: 0.0394%\n",
      "Epoch [124/300], Step [55/225], Training Accuracy: 98.6364%, Training Loss: 0.0389%\n",
      "Epoch [124/300], Step [56/225], Training Accuracy: 98.6607%, Training Loss: 0.0385%\n",
      "Epoch [124/300], Step [57/225], Training Accuracy: 98.6842%, Training Loss: 0.0382%\n",
      "Epoch [124/300], Step [58/225], Training Accuracy: 98.7069%, Training Loss: 0.0381%\n",
      "Epoch [124/300], Step [59/225], Training Accuracy: 98.7288%, Training Loss: 0.0380%\n",
      "Epoch [124/300], Step [60/225], Training Accuracy: 98.7240%, Training Loss: 0.0379%\n",
      "Epoch [124/300], Step [61/225], Training Accuracy: 98.7193%, Training Loss: 0.0380%\n",
      "Epoch [124/300], Step [62/225], Training Accuracy: 98.7399%, Training Loss: 0.0376%\n",
      "Epoch [124/300], Step [63/225], Training Accuracy: 98.7103%, Training Loss: 0.0383%\n",
      "Epoch [124/300], Step [64/225], Training Accuracy: 98.6816%, Training Loss: 0.0382%\n",
      "Epoch [124/300], Step [65/225], Training Accuracy: 98.7019%, Training Loss: 0.0380%\n",
      "Epoch [124/300], Step [66/225], Training Accuracy: 98.6742%, Training Loss: 0.0381%\n",
      "Epoch [124/300], Step [67/225], Training Accuracy: 98.6474%, Training Loss: 0.0386%\n",
      "Epoch [124/300], Step [68/225], Training Accuracy: 98.6443%, Training Loss: 0.0386%\n",
      "Epoch [124/300], Step [69/225], Training Accuracy: 98.6413%, Training Loss: 0.0390%\n",
      "Epoch [124/300], Step [70/225], Training Accuracy: 98.6607%, Training Loss: 0.0386%\n",
      "Epoch [124/300], Step [71/225], Training Accuracy: 98.6796%, Training Loss: 0.0383%\n",
      "Epoch [124/300], Step [72/225], Training Accuracy: 98.6979%, Training Loss: 0.0382%\n",
      "Epoch [124/300], Step [73/225], Training Accuracy: 98.6943%, Training Loss: 0.0380%\n",
      "Epoch [124/300], Step [74/225], Training Accuracy: 98.6698%, Training Loss: 0.0380%\n",
      "Epoch [124/300], Step [75/225], Training Accuracy: 98.6667%, Training Loss: 0.0388%\n",
      "Epoch [124/300], Step [76/225], Training Accuracy: 98.6225%, Training Loss: 0.0398%\n",
      "Epoch [124/300], Step [77/225], Training Accuracy: 98.6404%, Training Loss: 0.0397%\n",
      "Epoch [124/300], Step [78/225], Training Accuracy: 98.6579%, Training Loss: 0.0393%\n",
      "Epoch [124/300], Step [79/225], Training Accuracy: 98.6551%, Training Loss: 0.0393%\n",
      "Epoch [124/300], Step [80/225], Training Accuracy: 98.6719%, Training Loss: 0.0392%\n",
      "Epoch [124/300], Step [81/225], Training Accuracy: 98.6883%, Training Loss: 0.0389%\n",
      "Epoch [124/300], Step [82/225], Training Accuracy: 98.6852%, Training Loss: 0.0390%\n",
      "Epoch [124/300], Step [83/225], Training Accuracy: 98.6634%, Training Loss: 0.0394%\n",
      "Epoch [124/300], Step [84/225], Training Accuracy: 98.6607%, Training Loss: 0.0393%\n",
      "Epoch [124/300], Step [85/225], Training Accuracy: 98.6397%, Training Loss: 0.0396%\n",
      "Epoch [124/300], Step [86/225], Training Accuracy: 98.6374%, Training Loss: 0.0397%\n",
      "Epoch [124/300], Step [87/225], Training Accuracy: 98.6171%, Training Loss: 0.0405%\n",
      "Epoch [124/300], Step [88/225], Training Accuracy: 98.6151%, Training Loss: 0.0404%\n",
      "Epoch [124/300], Step [89/225], Training Accuracy: 98.6306%, Training Loss: 0.0403%\n",
      "Epoch [124/300], Step [90/225], Training Accuracy: 98.6458%, Training Loss: 0.0401%\n",
      "Epoch [124/300], Step [91/225], Training Accuracy: 98.6607%, Training Loss: 0.0400%\n",
      "Epoch [124/300], Step [92/225], Training Accuracy: 98.6753%, Training Loss: 0.0400%\n",
      "Epoch [124/300], Step [93/225], Training Accuracy: 98.6727%, Training Loss: 0.0400%\n",
      "Epoch [124/300], Step [94/225], Training Accuracy: 98.6702%, Training Loss: 0.0401%\n",
      "Epoch [124/300], Step [95/225], Training Accuracy: 98.6349%, Training Loss: 0.0408%\n",
      "Epoch [124/300], Step [96/225], Training Accuracy: 98.6491%, Training Loss: 0.0405%\n",
      "Epoch [124/300], Step [97/225], Training Accuracy: 98.6630%, Training Loss: 0.0403%\n",
      "Epoch [124/300], Step [98/225], Training Accuracy: 98.6607%, Training Loss: 0.0405%\n",
      "Epoch [124/300], Step [99/225], Training Accuracy: 98.6427%, Training Loss: 0.0410%\n",
      "Epoch [124/300], Step [100/225], Training Accuracy: 98.6562%, Training Loss: 0.0407%\n",
      "Epoch [124/300], Step [101/225], Training Accuracy: 98.6541%, Training Loss: 0.0408%\n",
      "Epoch [124/300], Step [102/225], Training Accuracy: 98.6673%, Training Loss: 0.0405%\n",
      "Epoch [124/300], Step [103/225], Training Accuracy: 98.6499%, Training Loss: 0.0409%\n",
      "Epoch [124/300], Step [104/225], Training Accuracy: 98.6328%, Training Loss: 0.0411%\n",
      "Epoch [124/300], Step [105/225], Training Accuracy: 98.6310%, Training Loss: 0.0413%\n",
      "Epoch [124/300], Step [106/225], Training Accuracy: 98.6439%, Training Loss: 0.0412%\n",
      "Epoch [124/300], Step [107/225], Training Accuracy: 98.6419%, Training Loss: 0.0415%\n",
      "Epoch [124/300], Step [108/225], Training Accuracy: 98.6545%, Training Loss: 0.0415%\n",
      "Epoch [124/300], Step [109/225], Training Accuracy: 98.6669%, Training Loss: 0.0414%\n",
      "Epoch [124/300], Step [110/225], Training Accuracy: 98.6648%, Training Loss: 0.0414%\n",
      "Epoch [124/300], Step [111/225], Training Accuracy: 98.6627%, Training Loss: 0.0414%\n",
      "Epoch [124/300], Step [112/225], Training Accuracy: 98.6747%, Training Loss: 0.0412%\n",
      "Epoch [124/300], Step [113/225], Training Accuracy: 98.6726%, Training Loss: 0.0413%\n",
      "Epoch [124/300], Step [114/225], Training Accuracy: 98.6705%, Training Loss: 0.0414%\n",
      "Epoch [124/300], Step [115/225], Training Accuracy: 98.6821%, Training Loss: 0.0411%\n",
      "Epoch [124/300], Step [116/225], Training Accuracy: 98.6665%, Training Loss: 0.0412%\n",
      "Epoch [124/300], Step [117/225], Training Accuracy: 98.6645%, Training Loss: 0.0412%\n",
      "Epoch [124/300], Step [118/225], Training Accuracy: 98.6626%, Training Loss: 0.0412%\n",
      "Epoch [124/300], Step [119/225], Training Accuracy: 98.6476%, Training Loss: 0.0415%\n",
      "Epoch [124/300], Step [120/225], Training Accuracy: 98.6458%, Training Loss: 0.0415%\n",
      "Epoch [124/300], Step [121/225], Training Accuracy: 98.6570%, Training Loss: 0.0413%\n",
      "Epoch [124/300], Step [122/225], Training Accuracy: 98.6552%, Training Loss: 0.0413%\n",
      "Epoch [124/300], Step [123/225], Training Accuracy: 98.6662%, Training Loss: 0.0413%\n",
      "Epoch [124/300], Step [124/225], Training Accuracy: 98.6643%, Training Loss: 0.0413%\n",
      "Epoch [124/300], Step [125/225], Training Accuracy: 98.6750%, Training Loss: 0.0411%\n",
      "Epoch [124/300], Step [126/225], Training Accuracy: 98.6607%, Training Loss: 0.0413%\n",
      "Epoch [124/300], Step [127/225], Training Accuracy: 98.6713%, Training Loss: 0.0412%\n",
      "Epoch [124/300], Step [128/225], Training Accuracy: 98.6694%, Training Loss: 0.0413%\n",
      "Epoch [124/300], Step [129/225], Training Accuracy: 98.6555%, Training Loss: 0.0415%\n",
      "Epoch [124/300], Step [130/225], Training Accuracy: 98.6418%, Training Loss: 0.0416%\n",
      "Epoch [124/300], Step [131/225], Training Accuracy: 98.6522%, Training Loss: 0.0415%\n",
      "Epoch [124/300], Step [132/225], Training Accuracy: 98.6506%, Training Loss: 0.0416%\n",
      "Epoch [124/300], Step [133/225], Training Accuracy: 98.6490%, Training Loss: 0.0415%\n",
      "Epoch [124/300], Step [134/225], Training Accuracy: 98.6474%, Training Loss: 0.0417%\n",
      "Epoch [124/300], Step [135/225], Training Accuracy: 98.6574%, Training Loss: 0.0417%\n",
      "Epoch [124/300], Step [136/225], Training Accuracy: 98.6558%, Training Loss: 0.0417%\n",
      "Epoch [124/300], Step [137/225], Training Accuracy: 98.6428%, Training Loss: 0.0419%\n",
      "Epoch [124/300], Step [138/225], Training Accuracy: 98.6413%, Training Loss: 0.0419%\n",
      "Epoch [124/300], Step [139/225], Training Accuracy: 98.6511%, Training Loss: 0.0418%\n",
      "Epoch [124/300], Step [140/225], Training Accuracy: 98.6607%, Training Loss: 0.0416%\n",
      "Epoch [124/300], Step [141/225], Training Accuracy: 98.6480%, Training Loss: 0.0418%\n",
      "Epoch [124/300], Step [142/225], Training Accuracy: 98.6356%, Training Loss: 0.0419%\n",
      "Epoch [124/300], Step [143/225], Training Accuracy: 98.6342%, Training Loss: 0.0418%\n",
      "Epoch [124/300], Step [144/225], Training Accuracy: 98.6220%, Training Loss: 0.0419%\n",
      "Epoch [124/300], Step [145/225], Training Accuracy: 98.6099%, Training Loss: 0.0420%\n",
      "Epoch [124/300], Step [146/225], Training Accuracy: 98.6194%, Training Loss: 0.0419%\n",
      "Epoch [124/300], Step [147/225], Training Accuracy: 98.6182%, Training Loss: 0.0423%\n",
      "Epoch [124/300], Step [148/225], Training Accuracy: 98.6275%, Training Loss: 0.0421%\n",
      "Epoch [124/300], Step [149/225], Training Accuracy: 98.6263%, Training Loss: 0.0423%\n",
      "Epoch [124/300], Step [150/225], Training Accuracy: 98.6250%, Training Loss: 0.0422%\n",
      "Epoch [124/300], Step [151/225], Training Accuracy: 98.6238%, Training Loss: 0.0425%\n",
      "Epoch [124/300], Step [152/225], Training Accuracy: 98.6328%, Training Loss: 0.0424%\n",
      "Epoch [124/300], Step [153/225], Training Accuracy: 98.6417%, Training Loss: 0.0423%\n",
      "Epoch [124/300], Step [154/225], Training Accuracy: 98.6303%, Training Loss: 0.0423%\n",
      "Epoch [124/300], Step [155/225], Training Accuracy: 98.6391%, Training Loss: 0.0423%\n",
      "Epoch [124/300], Step [156/225], Training Accuracy: 98.6478%, Training Loss: 0.0421%\n",
      "Epoch [124/300], Step [157/225], Training Accuracy: 98.6365%, Training Loss: 0.0424%\n",
      "Epoch [124/300], Step [158/225], Training Accuracy: 98.6452%, Training Loss: 0.0423%\n",
      "Epoch [124/300], Step [159/225], Training Accuracy: 98.6537%, Training Loss: 0.0422%\n",
      "Epoch [124/300], Step [160/225], Training Accuracy: 98.6621%, Training Loss: 0.0421%\n",
      "Epoch [124/300], Step [161/225], Training Accuracy: 98.6607%, Training Loss: 0.0421%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [124/300], Step [162/225], Training Accuracy: 98.6690%, Training Loss: 0.0420%\n",
      "Epoch [124/300], Step [163/225], Training Accuracy: 98.6676%, Training Loss: 0.0421%\n",
      "Epoch [124/300], Step [164/225], Training Accuracy: 98.6566%, Training Loss: 0.0423%\n",
      "Epoch [124/300], Step [165/225], Training Accuracy: 98.6458%, Training Loss: 0.0424%\n",
      "Epoch [124/300], Step [166/225], Training Accuracy: 98.6446%, Training Loss: 0.0424%\n",
      "Epoch [124/300], Step [167/225], Training Accuracy: 98.6527%, Training Loss: 0.0424%\n",
      "Epoch [124/300], Step [168/225], Training Accuracy: 98.6607%, Training Loss: 0.0422%\n",
      "Epoch [124/300], Step [169/225], Training Accuracy: 98.6594%, Training Loss: 0.0422%\n",
      "Epoch [124/300], Step [170/225], Training Accuracy: 98.6397%, Training Loss: 0.0425%\n",
      "Epoch [124/300], Step [171/225], Training Accuracy: 98.6477%, Training Loss: 0.0424%\n",
      "Epoch [124/300], Step [172/225], Training Accuracy: 98.6464%, Training Loss: 0.0425%\n",
      "Epoch [124/300], Step [173/225], Training Accuracy: 98.6543%, Training Loss: 0.0424%\n",
      "Epoch [124/300], Step [174/225], Training Accuracy: 98.6530%, Training Loss: 0.0424%\n",
      "Epoch [124/300], Step [175/225], Training Accuracy: 98.6339%, Training Loss: 0.0426%\n",
      "Epoch [124/300], Step [176/225], Training Accuracy: 98.6417%, Training Loss: 0.0425%\n",
      "Epoch [124/300], Step [177/225], Training Accuracy: 98.6494%, Training Loss: 0.0424%\n",
      "Epoch [124/300], Step [178/225], Training Accuracy: 98.6570%, Training Loss: 0.0423%\n",
      "Epoch [124/300], Step [179/225], Training Accuracy: 98.6645%, Training Loss: 0.0422%\n",
      "Epoch [124/300], Step [180/225], Training Accuracy: 98.6545%, Training Loss: 0.0423%\n",
      "Epoch [124/300], Step [181/225], Training Accuracy: 98.6533%, Training Loss: 0.0423%\n",
      "Epoch [124/300], Step [182/225], Training Accuracy: 98.6607%, Training Loss: 0.0421%\n",
      "Epoch [124/300], Step [183/225], Training Accuracy: 98.6595%, Training Loss: 0.0421%\n",
      "Epoch [124/300], Step [184/225], Training Accuracy: 98.6668%, Training Loss: 0.0420%\n",
      "Epoch [124/300], Step [185/225], Training Accuracy: 98.6655%, Training Loss: 0.0420%\n",
      "Epoch [124/300], Step [186/225], Training Accuracy: 98.6727%, Training Loss: 0.0418%\n",
      "Epoch [124/300], Step [187/225], Training Accuracy: 98.6798%, Training Loss: 0.0417%\n",
      "Epoch [124/300], Step [188/225], Training Accuracy: 98.6868%, Training Loss: 0.0416%\n",
      "Epoch [124/300], Step [189/225], Training Accuracy: 98.6938%, Training Loss: 0.0415%\n",
      "Epoch [124/300], Step [190/225], Training Accuracy: 98.6924%, Training Loss: 0.0415%\n",
      "Epoch [124/300], Step [191/225], Training Accuracy: 98.6911%, Training Loss: 0.0415%\n",
      "Epoch [124/300], Step [192/225], Training Accuracy: 98.6979%, Training Loss: 0.0415%\n",
      "Epoch [124/300], Step [193/225], Training Accuracy: 98.7047%, Training Loss: 0.0413%\n",
      "Epoch [124/300], Step [194/225], Training Accuracy: 98.7113%, Training Loss: 0.0413%\n",
      "Epoch [124/300], Step [195/225], Training Accuracy: 98.7019%, Training Loss: 0.0415%\n",
      "Epoch [124/300], Step [196/225], Training Accuracy: 98.7006%, Training Loss: 0.0416%\n",
      "Epoch [124/300], Step [197/225], Training Accuracy: 98.6992%, Training Loss: 0.0416%\n",
      "Epoch [124/300], Step [198/225], Training Accuracy: 98.6979%, Training Loss: 0.0416%\n",
      "Epoch [124/300], Step [199/225], Training Accuracy: 98.6888%, Training Loss: 0.0418%\n",
      "Epoch [124/300], Step [200/225], Training Accuracy: 98.6797%, Training Loss: 0.0418%\n",
      "Epoch [124/300], Step [201/225], Training Accuracy: 98.6785%, Training Loss: 0.0418%\n",
      "Epoch [124/300], Step [202/225], Training Accuracy: 98.6850%, Training Loss: 0.0418%\n",
      "Epoch [124/300], Step [203/225], Training Accuracy: 98.6838%, Training Loss: 0.0419%\n",
      "Epoch [124/300], Step [204/225], Training Accuracy: 98.6903%, Training Loss: 0.0418%\n",
      "Epoch [124/300], Step [205/225], Training Accuracy: 98.6966%, Training Loss: 0.0417%\n",
      "Epoch [124/300], Step [206/225], Training Accuracy: 98.6954%, Training Loss: 0.0417%\n",
      "Epoch [124/300], Step [207/225], Training Accuracy: 98.6866%, Training Loss: 0.0418%\n",
      "Epoch [124/300], Step [208/225], Training Accuracy: 98.6929%, Training Loss: 0.0418%\n",
      "Epoch [124/300], Step [209/225], Training Accuracy: 98.6842%, Training Loss: 0.0418%\n",
      "Epoch [124/300], Step [210/225], Training Accuracy: 98.6682%, Training Loss: 0.0420%\n",
      "Epoch [124/300], Step [211/225], Training Accuracy: 98.6597%, Training Loss: 0.0423%\n",
      "Epoch [124/300], Step [212/225], Training Accuracy: 98.6512%, Training Loss: 0.0425%\n",
      "Epoch [124/300], Step [213/225], Training Accuracy: 98.6429%, Training Loss: 0.0426%\n",
      "Epoch [124/300], Step [214/225], Training Accuracy: 98.6492%, Training Loss: 0.0426%\n",
      "Epoch [124/300], Step [215/225], Training Accuracy: 98.6410%, Training Loss: 0.0426%\n",
      "Epoch [124/300], Step [216/225], Training Accuracy: 98.6400%, Training Loss: 0.0426%\n",
      "Epoch [124/300], Step [217/225], Training Accuracy: 98.6463%, Training Loss: 0.0425%\n",
      "Epoch [124/300], Step [218/225], Training Accuracy: 98.6525%, Training Loss: 0.0424%\n",
      "Epoch [124/300], Step [219/225], Training Accuracy: 98.6587%, Training Loss: 0.0423%\n",
      "Epoch [124/300], Step [220/225], Training Accuracy: 98.6577%, Training Loss: 0.0424%\n",
      "Epoch [124/300], Step [221/225], Training Accuracy: 98.6567%, Training Loss: 0.0425%\n",
      "Epoch [124/300], Step [222/225], Training Accuracy: 98.6486%, Training Loss: 0.0426%\n",
      "Epoch [124/300], Step [223/225], Training Accuracy: 98.6407%, Training Loss: 0.0428%\n",
      "Epoch [124/300], Step [224/225], Training Accuracy: 98.6468%, Training Loss: 0.0427%\n",
      "Epoch [124/300], Step [225/225], Training Accuracy: 98.6451%, Training Loss: 0.0427%\n",
      "Epoch [125/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0246%\n",
      "Epoch [125/300], Step [2/225], Training Accuracy: 98.4375%, Training Loss: 0.0487%\n",
      "Epoch [125/300], Step [3/225], Training Accuracy: 97.9167%, Training Loss: 0.0504%\n",
      "Epoch [125/300], Step [4/225], Training Accuracy: 97.6562%, Training Loss: 0.0544%\n",
      "Epoch [125/300], Step [5/225], Training Accuracy: 98.1250%, Training Loss: 0.0490%\n",
      "Epoch [125/300], Step [6/225], Training Accuracy: 98.1771%, Training Loss: 0.0580%\n",
      "Epoch [125/300], Step [7/225], Training Accuracy: 98.2143%, Training Loss: 0.0552%\n",
      "Epoch [125/300], Step [8/225], Training Accuracy: 98.4375%, Training Loss: 0.0536%\n",
      "Epoch [125/300], Step [9/225], Training Accuracy: 98.4375%, Training Loss: 0.0521%\n",
      "Epoch [125/300], Step [10/225], Training Accuracy: 98.4375%, Training Loss: 0.0539%\n",
      "Epoch [125/300], Step [11/225], Training Accuracy: 98.5795%, Training Loss: 0.0508%\n",
      "Epoch [125/300], Step [12/225], Training Accuracy: 98.6979%, Training Loss: 0.0499%\n",
      "Epoch [125/300], Step [13/225], Training Accuracy: 98.3173%, Training Loss: 0.0579%\n",
      "Epoch [125/300], Step [14/225], Training Accuracy: 98.4375%, Training Loss: 0.0566%\n",
      "Epoch [125/300], Step [15/225], Training Accuracy: 98.5417%, Training Loss: 0.0540%\n",
      "Epoch [125/300], Step [16/225], Training Accuracy: 98.4375%, Training Loss: 0.0536%\n",
      "Epoch [125/300], Step [17/225], Training Accuracy: 98.4375%, Training Loss: 0.0538%\n",
      "Epoch [125/300], Step [18/225], Training Accuracy: 98.3507%, Training Loss: 0.0580%\n",
      "Epoch [125/300], Step [19/225], Training Accuracy: 98.2730%, Training Loss: 0.0571%\n",
      "Epoch [125/300], Step [20/225], Training Accuracy: 98.3594%, Training Loss: 0.0551%\n",
      "Epoch [125/300], Step [21/225], Training Accuracy: 98.4375%, Training Loss: 0.0536%\n",
      "Epoch [125/300], Step [22/225], Training Accuracy: 98.4375%, Training Loss: 0.0529%\n",
      "Epoch [125/300], Step [23/225], Training Accuracy: 98.4375%, Training Loss: 0.0541%\n",
      "Epoch [125/300], Step [24/225], Training Accuracy: 98.2422%, Training Loss: 0.0584%\n",
      "Epoch [125/300], Step [25/225], Training Accuracy: 98.3125%, Training Loss: 0.0567%\n",
      "Epoch [125/300], Step [26/225], Training Accuracy: 98.1971%, Training Loss: 0.0577%\n",
      "Epoch [125/300], Step [27/225], Training Accuracy: 98.1481%, Training Loss: 0.0593%\n",
      "Epoch [125/300], Step [28/225], Training Accuracy: 98.1585%, Training Loss: 0.0590%\n",
      "Epoch [125/300], Step [29/225], Training Accuracy: 98.1681%, Training Loss: 0.0584%\n",
      "Epoch [125/300], Step [30/225], Training Accuracy: 98.1250%, Training Loss: 0.0590%\n",
      "Epoch [125/300], Step [31/225], Training Accuracy: 98.1855%, Training Loss: 0.0576%\n",
      "Epoch [125/300], Step [32/225], Training Accuracy: 98.2422%, Training Loss: 0.0565%\n",
      "Epoch [125/300], Step [33/225], Training Accuracy: 98.2955%, Training Loss: 0.0556%\n",
      "Epoch [125/300], Step [34/225], Training Accuracy: 98.2537%, Training Loss: 0.0572%\n",
      "Epoch [125/300], Step [35/225], Training Accuracy: 98.3036%, Training Loss: 0.0565%\n",
      "Epoch [125/300], Step [36/225], Training Accuracy: 98.3073%, Training Loss: 0.0568%\n",
      "Epoch [125/300], Step [37/225], Training Accuracy: 98.3108%, Training Loss: 0.0562%\n",
      "Epoch [125/300], Step [38/225], Training Accuracy: 98.3141%, Training Loss: 0.0561%\n",
      "Epoch [125/300], Step [39/225], Training Accuracy: 98.2772%, Training Loss: 0.0576%\n",
      "Epoch [125/300], Step [40/225], Training Accuracy: 98.2422%, Training Loss: 0.0585%\n",
      "Epoch [125/300], Step [41/225], Training Accuracy: 98.2470%, Training Loss: 0.0580%\n",
      "Epoch [125/300], Step [42/225], Training Accuracy: 98.2515%, Training Loss: 0.0583%\n",
      "Epoch [125/300], Step [43/225], Training Accuracy: 98.2558%, Training Loss: 0.0581%\n",
      "Epoch [125/300], Step [44/225], Training Accuracy: 98.2599%, Training Loss: 0.0576%\n",
      "Epoch [125/300], Step [45/225], Training Accuracy: 98.2986%, Training Loss: 0.0567%\n",
      "Epoch [125/300], Step [46/225], Training Accuracy: 98.3356%, Training Loss: 0.0560%\n",
      "Epoch [125/300], Step [47/225], Training Accuracy: 98.3378%, Training Loss: 0.0555%\n",
      "Epoch [125/300], Step [48/225], Training Accuracy: 98.3398%, Training Loss: 0.0554%\n",
      "Epoch [125/300], Step [49/225], Training Accuracy: 98.3099%, Training Loss: 0.0563%\n",
      "Epoch [125/300], Step [50/225], Training Accuracy: 98.2500%, Training Loss: 0.0570%\n",
      "Epoch [125/300], Step [51/225], Training Accuracy: 98.2230%, Training Loss: 0.0572%\n",
      "Epoch [125/300], Step [52/225], Training Accuracy: 98.1671%, Training Loss: 0.0574%\n",
      "Epoch [125/300], Step [53/225], Training Accuracy: 98.1427%, Training Loss: 0.0598%\n",
      "Epoch [125/300], Step [54/225], Training Accuracy: 98.1481%, Training Loss: 0.0602%\n",
      "Epoch [125/300], Step [55/225], Training Accuracy: 98.1818%, Training Loss: 0.0593%\n",
      "Epoch [125/300], Step [56/225], Training Accuracy: 98.1585%, Training Loss: 0.0594%\n",
      "Epoch [125/300], Step [57/225], Training Accuracy: 98.1634%, Training Loss: 0.0596%\n",
      "Epoch [125/300], Step [58/225], Training Accuracy: 98.1681%, Training Loss: 0.0591%\n",
      "Epoch [125/300], Step [59/225], Training Accuracy: 98.1992%, Training Loss: 0.0586%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [125/300], Step [60/225], Training Accuracy: 98.2031%, Training Loss: 0.0584%\n",
      "Epoch [125/300], Step [61/225], Training Accuracy: 98.1557%, Training Loss: 0.0594%\n",
      "Epoch [125/300], Step [62/225], Training Accuracy: 98.1603%, Training Loss: 0.0594%\n",
      "Epoch [125/300], Step [63/225], Training Accuracy: 98.1895%, Training Loss: 0.0589%\n",
      "Epoch [125/300], Step [64/225], Training Accuracy: 98.1445%, Training Loss: 0.0598%\n",
      "Epoch [125/300], Step [65/225], Training Accuracy: 98.1490%, Training Loss: 0.0600%\n",
      "Epoch [125/300], Step [66/225], Training Accuracy: 98.1297%, Training Loss: 0.0602%\n",
      "Epoch [125/300], Step [67/225], Training Accuracy: 98.1576%, Training Loss: 0.0599%\n",
      "Epoch [125/300], Step [68/225], Training Accuracy: 98.1618%, Training Loss: 0.0597%\n",
      "Epoch [125/300], Step [69/225], Training Accuracy: 98.1205%, Training Loss: 0.0600%\n",
      "Epoch [125/300], Step [70/225], Training Accuracy: 98.1027%, Training Loss: 0.0600%\n",
      "Epoch [125/300], Step [71/225], Training Accuracy: 98.1074%, Training Loss: 0.0601%\n",
      "Epoch [125/300], Step [72/225], Training Accuracy: 98.1120%, Training Loss: 0.0602%\n",
      "Epoch [125/300], Step [73/225], Training Accuracy: 98.1164%, Training Loss: 0.0606%\n",
      "Epoch [125/300], Step [74/225], Training Accuracy: 98.0997%, Training Loss: 0.0608%\n",
      "Epoch [125/300], Step [75/225], Training Accuracy: 98.0833%, Training Loss: 0.0609%\n",
      "Epoch [125/300], Step [76/225], Training Accuracy: 98.0880%, Training Loss: 0.0608%\n",
      "Epoch [125/300], Step [77/225], Training Accuracy: 98.0519%, Training Loss: 0.0615%\n",
      "Epoch [125/300], Step [78/225], Training Accuracy: 98.0168%, Training Loss: 0.0617%\n",
      "Epoch [125/300], Step [79/225], Training Accuracy: 98.0024%, Training Loss: 0.0615%\n",
      "Epoch [125/300], Step [80/225], Training Accuracy: 98.0078%, Training Loss: 0.0615%\n",
      "Epoch [125/300], Step [81/225], Training Accuracy: 97.9745%, Training Loss: 0.0622%\n",
      "Epoch [125/300], Step [82/225], Training Accuracy: 97.9802%, Training Loss: 0.0618%\n",
      "Epoch [125/300], Step [83/225], Training Accuracy: 98.0045%, Training Loss: 0.0618%\n",
      "Epoch [125/300], Step [84/225], Training Accuracy: 98.0097%, Training Loss: 0.0616%\n",
      "Epoch [125/300], Step [85/225], Training Accuracy: 98.0331%, Training Loss: 0.0613%\n",
      "Epoch [125/300], Step [86/225], Training Accuracy: 97.9833%, Training Loss: 0.0616%\n",
      "Epoch [125/300], Step [87/225], Training Accuracy: 97.9526%, Training Loss: 0.0622%\n",
      "Epoch [125/300], Step [88/225], Training Accuracy: 97.9759%, Training Loss: 0.0620%\n",
      "Epoch [125/300], Step [89/225], Training Accuracy: 97.9986%, Training Loss: 0.0617%\n",
      "Epoch [125/300], Step [90/225], Training Accuracy: 98.0208%, Training Loss: 0.0614%\n",
      "Epoch [125/300], Step [91/225], Training Accuracy: 98.0426%, Training Loss: 0.0609%\n",
      "Epoch [125/300], Step [92/225], Training Accuracy: 98.0639%, Training Loss: 0.0606%\n",
      "Epoch [125/300], Step [93/225], Training Accuracy: 98.0847%, Training Loss: 0.0602%\n",
      "Epoch [125/300], Step [94/225], Training Accuracy: 98.1051%, Training Loss: 0.0597%\n",
      "Epoch [125/300], Step [95/225], Training Accuracy: 98.1086%, Training Loss: 0.0595%\n",
      "Epoch [125/300], Step [96/225], Training Accuracy: 98.1283%, Training Loss: 0.0592%\n",
      "Epoch [125/300], Step [97/225], Training Accuracy: 98.1476%, Training Loss: 0.0588%\n",
      "Epoch [125/300], Step [98/225], Training Accuracy: 98.1505%, Training Loss: 0.0589%\n",
      "Epoch [125/300], Step [99/225], Training Accuracy: 98.1534%, Training Loss: 0.0589%\n",
      "Epoch [125/300], Step [100/225], Training Accuracy: 98.1719%, Training Loss: 0.0585%\n",
      "Epoch [125/300], Step [101/225], Training Accuracy: 98.1745%, Training Loss: 0.0584%\n",
      "Epoch [125/300], Step [102/225], Training Accuracy: 98.1924%, Training Loss: 0.0579%\n",
      "Epoch [125/300], Step [103/225], Training Accuracy: 98.2100%, Training Loss: 0.0576%\n",
      "Epoch [125/300], Step [104/225], Training Accuracy: 98.2121%, Training Loss: 0.0575%\n",
      "Epoch [125/300], Step [105/225], Training Accuracy: 98.2143%, Training Loss: 0.0575%\n",
      "Epoch [125/300], Step [106/225], Training Accuracy: 98.1869%, Training Loss: 0.0577%\n",
      "Epoch [125/300], Step [107/225], Training Accuracy: 98.2039%, Training Loss: 0.0575%\n",
      "Epoch [125/300], Step [108/225], Training Accuracy: 98.2060%, Training Loss: 0.0573%\n",
      "Epoch [125/300], Step [109/225], Training Accuracy: 98.2225%, Training Loss: 0.0570%\n",
      "Epoch [125/300], Step [110/225], Training Accuracy: 98.2244%, Training Loss: 0.0569%\n",
      "Epoch [125/300], Step [111/225], Training Accuracy: 98.2264%, Training Loss: 0.0569%\n",
      "Epoch [125/300], Step [112/225], Training Accuracy: 98.2422%, Training Loss: 0.0567%\n",
      "Epoch [125/300], Step [113/225], Training Accuracy: 98.2577%, Training Loss: 0.0564%\n",
      "Epoch [125/300], Step [114/225], Training Accuracy: 98.2730%, Training Loss: 0.0561%\n",
      "Epoch [125/300], Step [115/225], Training Accuracy: 98.2609%, Training Loss: 0.0560%\n",
      "Epoch [125/300], Step [116/225], Training Accuracy: 98.2759%, Training Loss: 0.0559%\n",
      "Epoch [125/300], Step [117/225], Training Accuracy: 98.2906%, Training Loss: 0.0557%\n",
      "Epoch [125/300], Step [118/225], Training Accuracy: 98.2786%, Training Loss: 0.0560%\n",
      "Epoch [125/300], Step [119/225], Training Accuracy: 98.2931%, Training Loss: 0.0557%\n",
      "Epoch [125/300], Step [120/225], Training Accuracy: 98.2812%, Training Loss: 0.0559%\n",
      "Epoch [125/300], Step [121/225], Training Accuracy: 98.2825%, Training Loss: 0.0556%\n",
      "Epoch [125/300], Step [122/225], Training Accuracy: 98.2966%, Training Loss: 0.0552%\n",
      "Epoch [125/300], Step [123/225], Training Accuracy: 98.2978%, Training Loss: 0.0551%\n",
      "Epoch [125/300], Step [124/225], Training Accuracy: 98.2989%, Training Loss: 0.0551%\n",
      "Epoch [125/300], Step [125/225], Training Accuracy: 98.3000%, Training Loss: 0.0549%\n",
      "Epoch [125/300], Step [126/225], Training Accuracy: 98.2887%, Training Loss: 0.0550%\n",
      "Epoch [125/300], Step [127/225], Training Accuracy: 98.2899%, Training Loss: 0.0548%\n",
      "Epoch [125/300], Step [128/225], Training Accuracy: 98.2666%, Training Loss: 0.0553%\n",
      "Epoch [125/300], Step [129/225], Training Accuracy: 98.2558%, Training Loss: 0.0554%\n",
      "Epoch [125/300], Step [130/225], Training Accuracy: 98.2692%, Training Loss: 0.0552%\n",
      "Epoch [125/300], Step [131/225], Training Accuracy: 98.2824%, Training Loss: 0.0550%\n",
      "Epoch [125/300], Step [132/225], Training Accuracy: 98.2955%, Training Loss: 0.0548%\n",
      "Epoch [125/300], Step [133/225], Training Accuracy: 98.3083%, Training Loss: 0.0546%\n",
      "Epoch [125/300], Step [134/225], Training Accuracy: 98.2976%, Training Loss: 0.0549%\n",
      "Epoch [125/300], Step [135/225], Training Accuracy: 98.3102%, Training Loss: 0.0547%\n",
      "Epoch [125/300], Step [136/225], Training Accuracy: 98.3226%, Training Loss: 0.0545%\n",
      "Epoch [125/300], Step [137/225], Training Accuracy: 98.3349%, Training Loss: 0.0544%\n",
      "Epoch [125/300], Step [138/225], Training Accuracy: 98.3243%, Training Loss: 0.0546%\n",
      "Epoch [125/300], Step [139/225], Training Accuracy: 98.3363%, Training Loss: 0.0544%\n",
      "Epoch [125/300], Step [140/225], Training Accuracy: 98.3482%, Training Loss: 0.0542%\n",
      "Epoch [125/300], Step [141/225], Training Accuracy: 98.3488%, Training Loss: 0.0542%\n",
      "Epoch [125/300], Step [142/225], Training Accuracy: 98.3605%, Training Loss: 0.0541%\n",
      "Epoch [125/300], Step [143/225], Training Accuracy: 98.3610%, Training Loss: 0.0541%\n",
      "Epoch [125/300], Step [144/225], Training Accuracy: 98.3724%, Training Loss: 0.0538%\n",
      "Epoch [125/300], Step [145/225], Training Accuracy: 98.3728%, Training Loss: 0.0536%\n",
      "Epoch [125/300], Step [146/225], Training Accuracy: 98.3733%, Training Loss: 0.0535%\n",
      "Epoch [125/300], Step [147/225], Training Accuracy: 98.3737%, Training Loss: 0.0535%\n",
      "Epoch [125/300], Step [148/225], Training Accuracy: 98.3636%, Training Loss: 0.0535%\n",
      "Epoch [125/300], Step [149/225], Training Accuracy: 98.3641%, Training Loss: 0.0535%\n",
      "Epoch [125/300], Step [150/225], Training Accuracy: 98.3542%, Training Loss: 0.0537%\n",
      "Epoch [125/300], Step [151/225], Training Accuracy: 98.3651%, Training Loss: 0.0535%\n",
      "Epoch [125/300], Step [152/225], Training Accuracy: 98.3655%, Training Loss: 0.0535%\n",
      "Epoch [125/300], Step [153/225], Training Accuracy: 98.3762%, Training Loss: 0.0533%\n",
      "Epoch [125/300], Step [154/225], Training Accuracy: 98.3766%, Training Loss: 0.0532%\n",
      "Epoch [125/300], Step [155/225], Training Accuracy: 98.3669%, Training Loss: 0.0535%\n",
      "Epoch [125/300], Step [156/225], Training Accuracy: 98.3774%, Training Loss: 0.0532%\n",
      "Epoch [125/300], Step [157/225], Training Accuracy: 98.3778%, Training Loss: 0.0531%\n",
      "Epoch [125/300], Step [158/225], Training Accuracy: 98.3782%, Training Loss: 0.0530%\n",
      "Epoch [125/300], Step [159/225], Training Accuracy: 98.3884%, Training Loss: 0.0530%\n",
      "Epoch [125/300], Step [160/225], Training Accuracy: 98.3691%, Training Loss: 0.0530%\n",
      "Epoch [125/300], Step [161/225], Training Accuracy: 98.3793%, Training Loss: 0.0528%\n",
      "Epoch [125/300], Step [162/225], Training Accuracy: 98.3796%, Training Loss: 0.0527%\n",
      "Epoch [125/300], Step [163/225], Training Accuracy: 98.3800%, Training Loss: 0.0529%\n",
      "Epoch [125/300], Step [164/225], Training Accuracy: 98.3899%, Training Loss: 0.0526%\n",
      "Epoch [125/300], Step [165/225], Training Accuracy: 98.3996%, Training Loss: 0.0525%\n",
      "Epoch [125/300], Step [166/225], Training Accuracy: 98.4093%, Training Loss: 0.0523%\n",
      "Epoch [125/300], Step [167/225], Training Accuracy: 98.4094%, Training Loss: 0.0521%\n",
      "Epoch [125/300], Step [168/225], Training Accuracy: 98.4189%, Training Loss: 0.0520%\n",
      "Epoch [125/300], Step [169/225], Training Accuracy: 98.4283%, Training Loss: 0.0518%\n",
      "Epoch [125/300], Step [170/225], Training Accuracy: 98.4191%, Training Loss: 0.0520%\n",
      "Epoch [125/300], Step [171/225], Training Accuracy: 98.4192%, Training Loss: 0.0519%\n",
      "Epoch [125/300], Step [172/225], Training Accuracy: 98.4284%, Training Loss: 0.0517%\n",
      "Epoch [125/300], Step [173/225], Training Accuracy: 98.4104%, Training Loss: 0.0519%\n",
      "Epoch [125/300], Step [174/225], Training Accuracy: 98.4195%, Training Loss: 0.0517%\n",
      "Epoch [125/300], Step [175/225], Training Accuracy: 98.4018%, Training Loss: 0.0518%\n",
      "Epoch [125/300], Step [176/225], Training Accuracy: 98.4109%, Training Loss: 0.0516%\n",
      "Epoch [125/300], Step [177/225], Training Accuracy: 98.4198%, Training Loss: 0.0514%\n",
      "Epoch [125/300], Step [178/225], Training Accuracy: 98.4199%, Training Loss: 0.0514%\n",
      "Epoch [125/300], Step [179/225], Training Accuracy: 98.4026%, Training Loss: 0.0517%\n",
      "Epoch [125/300], Step [180/225], Training Accuracy: 98.4028%, Training Loss: 0.0517%\n",
      "Epoch [125/300], Step [181/225], Training Accuracy: 98.4116%, Training Loss: 0.0516%\n",
      "Epoch [125/300], Step [182/225], Training Accuracy: 98.4203%, Training Loss: 0.0514%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [125/300], Step [183/225], Training Accuracy: 98.4119%, Training Loss: 0.0517%\n",
      "Epoch [125/300], Step [184/225], Training Accuracy: 98.4035%, Training Loss: 0.0520%\n",
      "Epoch [125/300], Step [185/225], Training Accuracy: 98.4037%, Training Loss: 0.0519%\n",
      "Epoch [125/300], Step [186/225], Training Accuracy: 98.4039%, Training Loss: 0.0518%\n",
      "Epoch [125/300], Step [187/225], Training Accuracy: 98.4041%, Training Loss: 0.0517%\n",
      "Epoch [125/300], Step [188/225], Training Accuracy: 98.3959%, Training Loss: 0.0518%\n",
      "Epoch [125/300], Step [189/225], Training Accuracy: 98.4044%, Training Loss: 0.0517%\n",
      "Epoch [125/300], Step [190/225], Training Accuracy: 98.4128%, Training Loss: 0.0516%\n",
      "Epoch [125/300], Step [191/225], Training Accuracy: 98.4130%, Training Loss: 0.0517%\n",
      "Epoch [125/300], Step [192/225], Training Accuracy: 98.4131%, Training Loss: 0.0516%\n",
      "Epoch [125/300], Step [193/225], Training Accuracy: 98.4132%, Training Loss: 0.0519%\n",
      "Epoch [125/300], Step [194/225], Training Accuracy: 98.4214%, Training Loss: 0.0518%\n",
      "Epoch [125/300], Step [195/225], Training Accuracy: 98.4295%, Training Loss: 0.0518%\n",
      "Epoch [125/300], Step [196/225], Training Accuracy: 98.4375%, Training Loss: 0.0516%\n",
      "Epoch [125/300], Step [197/225], Training Accuracy: 98.4454%, Training Loss: 0.0515%\n",
      "Epoch [125/300], Step [198/225], Training Accuracy: 98.4533%, Training Loss: 0.0514%\n",
      "Epoch [125/300], Step [199/225], Training Accuracy: 98.4532%, Training Loss: 0.0513%\n",
      "Epoch [125/300], Step [200/225], Training Accuracy: 98.4531%, Training Loss: 0.0513%\n",
      "Epoch [125/300], Step [201/225], Training Accuracy: 98.4453%, Training Loss: 0.0514%\n",
      "Epoch [125/300], Step [202/225], Training Accuracy: 98.4298%, Training Loss: 0.0519%\n",
      "Epoch [125/300], Step [203/225], Training Accuracy: 98.4298%, Training Loss: 0.0518%\n",
      "Epoch [125/300], Step [204/225], Training Accuracy: 98.4375%, Training Loss: 0.0517%\n",
      "Epoch [125/300], Step [205/225], Training Accuracy: 98.4375%, Training Loss: 0.0516%\n",
      "Epoch [125/300], Step [206/225], Training Accuracy: 98.4223%, Training Loss: 0.0520%\n",
      "Epoch [125/300], Step [207/225], Training Accuracy: 98.4300%, Training Loss: 0.0518%\n",
      "Epoch [125/300], Step [208/225], Training Accuracy: 98.4375%, Training Loss: 0.0517%\n",
      "Epoch [125/300], Step [209/225], Training Accuracy: 98.4450%, Training Loss: 0.0515%\n",
      "Epoch [125/300], Step [210/225], Training Accuracy: 98.4449%, Training Loss: 0.0515%\n",
      "Epoch [125/300], Step [211/225], Training Accuracy: 98.4449%, Training Loss: 0.0515%\n",
      "Epoch [125/300], Step [212/225], Training Accuracy: 98.4375%, Training Loss: 0.0517%\n",
      "Epoch [125/300], Step [213/225], Training Accuracy: 98.4448%, Training Loss: 0.0515%\n",
      "Epoch [125/300], Step [214/225], Training Accuracy: 98.4448%, Training Loss: 0.0515%\n",
      "Epoch [125/300], Step [215/225], Training Accuracy: 98.4448%, Training Loss: 0.0514%\n",
      "Epoch [125/300], Step [216/225], Training Accuracy: 98.4520%, Training Loss: 0.0512%\n",
      "Epoch [125/300], Step [217/225], Training Accuracy: 98.4519%, Training Loss: 0.0515%\n",
      "Epoch [125/300], Step [218/225], Training Accuracy: 98.4518%, Training Loss: 0.0514%\n",
      "Epoch [125/300], Step [219/225], Training Accuracy: 98.4589%, Training Loss: 0.0513%\n",
      "Epoch [125/300], Step [220/225], Training Accuracy: 98.4659%, Training Loss: 0.0511%\n",
      "Epoch [125/300], Step [221/225], Training Accuracy: 98.4516%, Training Loss: 0.0517%\n",
      "Epoch [125/300], Step [222/225], Training Accuracy: 98.4445%, Training Loss: 0.0519%\n",
      "Epoch [125/300], Step [223/225], Training Accuracy: 98.4515%, Training Loss: 0.0518%\n",
      "Epoch [125/300], Step [224/225], Training Accuracy: 98.4515%, Training Loss: 0.0517%\n",
      "Epoch [125/300], Step [225/225], Training Accuracy: 98.4575%, Training Loss: 0.0516%\n",
      "Epoch [126/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0076%\n",
      "Epoch [126/300], Step [2/225], Training Accuracy: 100.0000%, Training Loss: 0.0080%\n",
      "Epoch [126/300], Step [3/225], Training Accuracy: 99.4792%, Training Loss: 0.0205%\n",
      "Epoch [126/300], Step [4/225], Training Accuracy: 99.6094%, Training Loss: 0.0188%\n",
      "Epoch [126/300], Step [5/225], Training Accuracy: 99.6875%, Training Loss: 0.0182%\n",
      "Epoch [126/300], Step [6/225], Training Accuracy: 98.9583%, Training Loss: 0.0285%\n",
      "Epoch [126/300], Step [7/225], Training Accuracy: 99.1071%, Training Loss: 0.0265%\n",
      "Epoch [126/300], Step [8/225], Training Accuracy: 99.2188%, Training Loss: 0.0251%\n",
      "Epoch [126/300], Step [9/225], Training Accuracy: 99.3056%, Training Loss: 0.0245%\n",
      "Epoch [126/300], Step [10/225], Training Accuracy: 99.3750%, Training Loss: 0.0244%\n",
      "Epoch [126/300], Step [11/225], Training Accuracy: 99.4318%, Training Loss: 0.0244%\n",
      "Epoch [126/300], Step [12/225], Training Accuracy: 99.4792%, Training Loss: 0.0239%\n",
      "Epoch [126/300], Step [13/225], Training Accuracy: 99.5192%, Training Loss: 0.0240%\n",
      "Epoch [126/300], Step [14/225], Training Accuracy: 99.4420%, Training Loss: 0.0253%\n",
      "Epoch [126/300], Step [15/225], Training Accuracy: 99.3750%, Training Loss: 0.0268%\n",
      "Epoch [126/300], Step [16/225], Training Accuracy: 99.4141%, Training Loss: 0.0272%\n",
      "Epoch [126/300], Step [17/225], Training Accuracy: 99.4485%, Training Loss: 0.0279%\n",
      "Epoch [126/300], Step [18/225], Training Accuracy: 99.3056%, Training Loss: 0.0307%\n",
      "Epoch [126/300], Step [19/225], Training Accuracy: 99.3421%, Training Loss: 0.0299%\n",
      "Epoch [126/300], Step [20/225], Training Accuracy: 99.3750%, Training Loss: 0.0291%\n",
      "Epoch [126/300], Step [21/225], Training Accuracy: 99.4048%, Training Loss: 0.0288%\n",
      "Epoch [126/300], Step [22/225], Training Accuracy: 99.3608%, Training Loss: 0.0290%\n",
      "Epoch [126/300], Step [23/225], Training Accuracy: 99.1848%, Training Loss: 0.0320%\n",
      "Epoch [126/300], Step [24/225], Training Accuracy: 99.1536%, Training Loss: 0.0321%\n",
      "Epoch [126/300], Step [25/225], Training Accuracy: 99.0625%, Training Loss: 0.0340%\n",
      "Epoch [126/300], Step [26/225], Training Accuracy: 99.0385%, Training Loss: 0.0336%\n",
      "Epoch [126/300], Step [27/225], Training Accuracy: 99.0741%, Training Loss: 0.0344%\n",
      "Epoch [126/300], Step [28/225], Training Accuracy: 99.1071%, Training Loss: 0.0336%\n",
      "Epoch [126/300], Step [29/225], Training Accuracy: 99.0841%, Training Loss: 0.0339%\n",
      "Epoch [126/300], Step [30/225], Training Accuracy: 99.0625%, Training Loss: 0.0342%\n",
      "Epoch [126/300], Step [31/225], Training Accuracy: 99.0927%, Training Loss: 0.0341%\n",
      "Epoch [126/300], Step [32/225], Training Accuracy: 99.1211%, Training Loss: 0.0348%\n",
      "Epoch [126/300], Step [33/225], Training Accuracy: 99.1477%, Training Loss: 0.0342%\n",
      "Epoch [126/300], Step [34/225], Training Accuracy: 99.0809%, Training Loss: 0.0357%\n",
      "Epoch [126/300], Step [35/225], Training Accuracy: 99.1071%, Training Loss: 0.0349%\n",
      "Epoch [126/300], Step [36/225], Training Accuracy: 99.0885%, Training Loss: 0.0347%\n",
      "Epoch [126/300], Step [37/225], Training Accuracy: 99.1132%, Training Loss: 0.0346%\n",
      "Epoch [126/300], Step [38/225], Training Accuracy: 99.0954%, Training Loss: 0.0351%\n",
      "Epoch [126/300], Step [39/225], Training Accuracy: 99.0785%, Training Loss: 0.0349%\n",
      "Epoch [126/300], Step [40/225], Training Accuracy: 99.0625%, Training Loss: 0.0347%\n",
      "Epoch [126/300], Step [41/225], Training Accuracy: 99.0473%, Training Loss: 0.0347%\n",
      "Epoch [126/300], Step [42/225], Training Accuracy: 99.0327%, Training Loss: 0.0347%\n",
      "Epoch [126/300], Step [43/225], Training Accuracy: 99.0552%, Training Loss: 0.0347%\n",
      "Epoch [126/300], Step [44/225], Training Accuracy: 99.0412%, Training Loss: 0.0346%\n",
      "Epoch [126/300], Step [45/225], Training Accuracy: 99.0625%, Training Loss: 0.0342%\n",
      "Epoch [126/300], Step [46/225], Training Accuracy: 99.0489%, Training Loss: 0.0341%\n",
      "Epoch [126/300], Step [47/225], Training Accuracy: 99.0691%, Training Loss: 0.0341%\n",
      "Epoch [126/300], Step [48/225], Training Accuracy: 99.0234%, Training Loss: 0.0347%\n",
      "Epoch [126/300], Step [49/225], Training Accuracy: 98.8839%, Training Loss: 0.0362%\n",
      "Epoch [126/300], Step [50/225], Training Accuracy: 98.8750%, Training Loss: 0.0363%\n",
      "Epoch [126/300], Step [51/225], Training Accuracy: 98.8971%, Training Loss: 0.0358%\n",
      "Epoch [126/300], Step [52/225], Training Accuracy: 98.9183%, Training Loss: 0.0354%\n",
      "Epoch [126/300], Step [53/225], Training Accuracy: 98.9387%, Training Loss: 0.0349%\n",
      "Epoch [126/300], Step [54/225], Training Accuracy: 98.9294%, Training Loss: 0.0353%\n",
      "Epoch [126/300], Step [55/225], Training Accuracy: 98.9489%, Training Loss: 0.0350%\n",
      "Epoch [126/300], Step [56/225], Training Accuracy: 98.9676%, Training Loss: 0.0351%\n",
      "Epoch [126/300], Step [57/225], Training Accuracy: 98.9309%, Training Loss: 0.0360%\n",
      "Epoch [126/300], Step [58/225], Training Accuracy: 98.9494%, Training Loss: 0.0358%\n",
      "Epoch [126/300], Step [59/225], Training Accuracy: 98.9407%, Training Loss: 0.0358%\n",
      "Epoch [126/300], Step [60/225], Training Accuracy: 98.9323%, Training Loss: 0.0360%\n",
      "Epoch [126/300], Step [61/225], Training Accuracy: 98.9498%, Training Loss: 0.0357%\n",
      "Epoch [126/300], Step [62/225], Training Accuracy: 98.9667%, Training Loss: 0.0354%\n",
      "Epoch [126/300], Step [63/225], Training Accuracy: 98.9583%, Training Loss: 0.0363%\n",
      "Epoch [126/300], Step [64/225], Training Accuracy: 98.9746%, Training Loss: 0.0363%\n",
      "Epoch [126/300], Step [65/225], Training Accuracy: 98.9904%, Training Loss: 0.0359%\n",
      "Epoch [126/300], Step [66/225], Training Accuracy: 98.9820%, Training Loss: 0.0360%\n",
      "Epoch [126/300], Step [67/225], Training Accuracy: 98.9739%, Training Loss: 0.0360%\n",
      "Epoch [126/300], Step [68/225], Training Accuracy: 98.9430%, Training Loss: 0.0364%\n",
      "Epoch [126/300], Step [69/225], Training Accuracy: 98.9583%, Training Loss: 0.0363%\n",
      "Epoch [126/300], Step [70/225], Training Accuracy: 98.9732%, Training Loss: 0.0361%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [126/300], Step [71/225], Training Accuracy: 98.9657%, Training Loss: 0.0363%\n",
      "Epoch [126/300], Step [72/225], Training Accuracy: 98.9583%, Training Loss: 0.0363%\n",
      "Epoch [126/300], Step [73/225], Training Accuracy: 98.9298%, Training Loss: 0.0372%\n",
      "Epoch [126/300], Step [74/225], Training Accuracy: 98.9231%, Training Loss: 0.0374%\n",
      "Epoch [126/300], Step [75/225], Training Accuracy: 98.9375%, Training Loss: 0.0372%\n",
      "Epoch [126/300], Step [76/225], Training Accuracy: 98.9515%, Training Loss: 0.0371%\n",
      "Epoch [126/300], Step [77/225], Training Accuracy: 98.9448%, Training Loss: 0.0374%\n",
      "Epoch [126/300], Step [78/225], Training Accuracy: 98.9583%, Training Loss: 0.0371%\n",
      "Epoch [126/300], Step [79/225], Training Accuracy: 98.9517%, Training Loss: 0.0375%\n",
      "Epoch [126/300], Step [80/225], Training Accuracy: 98.9453%, Training Loss: 0.0379%\n",
      "Epoch [126/300], Step [81/225], Training Accuracy: 98.9583%, Training Loss: 0.0377%\n",
      "Epoch [126/300], Step [82/225], Training Accuracy: 98.9520%, Training Loss: 0.0375%\n",
      "Epoch [126/300], Step [83/225], Training Accuracy: 98.9458%, Training Loss: 0.0379%\n",
      "Epoch [126/300], Step [84/225], Training Accuracy: 98.9583%, Training Loss: 0.0377%\n",
      "Epoch [126/300], Step [85/225], Training Accuracy: 98.9706%, Training Loss: 0.0376%\n",
      "Epoch [126/300], Step [86/225], Training Accuracy: 98.9826%, Training Loss: 0.0376%\n",
      "Epoch [126/300], Step [87/225], Training Accuracy: 98.9763%, Training Loss: 0.0376%\n",
      "Epoch [126/300], Step [88/225], Training Accuracy: 98.9702%, Training Loss: 0.0376%\n",
      "Epoch [126/300], Step [89/225], Training Accuracy: 98.9642%, Training Loss: 0.0379%\n",
      "Epoch [126/300], Step [90/225], Training Accuracy: 98.9583%, Training Loss: 0.0381%\n",
      "Epoch [126/300], Step [91/225], Training Accuracy: 98.9698%, Training Loss: 0.0378%\n",
      "Epoch [126/300], Step [92/225], Training Accuracy: 98.9810%, Training Loss: 0.0377%\n",
      "Epoch [126/300], Step [93/225], Training Accuracy: 98.9751%, Training Loss: 0.0381%\n",
      "Epoch [126/300], Step [94/225], Training Accuracy: 98.9694%, Training Loss: 0.0382%\n",
      "Epoch [126/300], Step [95/225], Training Accuracy: 98.9638%, Training Loss: 0.0381%\n",
      "Epoch [126/300], Step [96/225], Training Accuracy: 98.9421%, Training Loss: 0.0386%\n",
      "Epoch [126/300], Step [97/225], Training Accuracy: 98.9530%, Training Loss: 0.0386%\n",
      "Epoch [126/300], Step [98/225], Training Accuracy: 98.9318%, Training Loss: 0.0391%\n",
      "Epoch [126/300], Step [99/225], Training Accuracy: 98.9426%, Training Loss: 0.0389%\n",
      "Epoch [126/300], Step [100/225], Training Accuracy: 98.9531%, Training Loss: 0.0389%\n",
      "Epoch [126/300], Step [101/225], Training Accuracy: 98.9635%, Training Loss: 0.0387%\n",
      "Epoch [126/300], Step [102/225], Training Accuracy: 98.9737%, Training Loss: 0.0385%\n",
      "Epoch [126/300], Step [103/225], Training Accuracy: 98.9836%, Training Loss: 0.0384%\n",
      "Epoch [126/300], Step [104/225], Training Accuracy: 98.9784%, Training Loss: 0.0384%\n",
      "Epoch [126/300], Step [105/225], Training Accuracy: 98.9881%, Training Loss: 0.0382%\n",
      "Epoch [126/300], Step [106/225], Training Accuracy: 98.9829%, Training Loss: 0.0385%\n",
      "Epoch [126/300], Step [107/225], Training Accuracy: 98.9924%, Training Loss: 0.0383%\n",
      "Epoch [126/300], Step [108/225], Training Accuracy: 99.0017%, Training Loss: 0.0381%\n",
      "Epoch [126/300], Step [109/225], Training Accuracy: 99.0109%, Training Loss: 0.0381%\n",
      "Epoch [126/300], Step [110/225], Training Accuracy: 99.0057%, Training Loss: 0.0381%\n",
      "Epoch [126/300], Step [111/225], Training Accuracy: 99.0146%, Training Loss: 0.0380%\n",
      "Epoch [126/300], Step [112/225], Training Accuracy: 99.0234%, Training Loss: 0.0380%\n",
      "Epoch [126/300], Step [113/225], Training Accuracy: 99.0183%, Training Loss: 0.0379%\n",
      "Epoch [126/300], Step [114/225], Training Accuracy: 99.0269%, Training Loss: 0.0377%\n",
      "Epoch [126/300], Step [115/225], Training Accuracy: 99.0217%, Training Loss: 0.0378%\n",
      "Epoch [126/300], Step [116/225], Training Accuracy: 99.0302%, Training Loss: 0.0376%\n",
      "Epoch [126/300], Step [117/225], Training Accuracy: 99.0385%, Training Loss: 0.0375%\n",
      "Epoch [126/300], Step [118/225], Training Accuracy: 99.0069%, Training Loss: 0.0379%\n",
      "Epoch [126/300], Step [119/225], Training Accuracy: 99.0021%, Training Loss: 0.0379%\n",
      "Epoch [126/300], Step [120/225], Training Accuracy: 98.9714%, Training Loss: 0.0383%\n",
      "Epoch [126/300], Step [121/225], Training Accuracy: 98.9799%, Training Loss: 0.0382%\n",
      "Epoch [126/300], Step [122/225], Training Accuracy: 98.9882%, Training Loss: 0.0380%\n",
      "Epoch [126/300], Step [123/225], Training Accuracy: 98.9583%, Training Loss: 0.0387%\n",
      "Epoch [126/300], Step [124/225], Training Accuracy: 98.9667%, Training Loss: 0.0385%\n",
      "Epoch [126/300], Step [125/225], Training Accuracy: 98.9500%, Training Loss: 0.0387%\n",
      "Epoch [126/300], Step [126/225], Training Accuracy: 98.9459%, Training Loss: 0.0387%\n",
      "Epoch [126/300], Step [127/225], Training Accuracy: 98.9296%, Training Loss: 0.0388%\n",
      "Epoch [126/300], Step [128/225], Training Accuracy: 98.9380%, Training Loss: 0.0387%\n",
      "Epoch [126/300], Step [129/225], Training Accuracy: 98.9462%, Training Loss: 0.0387%\n",
      "Epoch [126/300], Step [130/225], Training Accuracy: 98.9543%, Training Loss: 0.0385%\n",
      "Epoch [126/300], Step [131/225], Training Accuracy: 98.9265%, Training Loss: 0.0388%\n",
      "Epoch [126/300], Step [132/225], Training Accuracy: 98.9347%, Training Loss: 0.0388%\n",
      "Epoch [126/300], Step [133/225], Training Accuracy: 98.9192%, Training Loss: 0.0388%\n",
      "Epoch [126/300], Step [134/225], Training Accuracy: 98.9039%, Training Loss: 0.0390%\n",
      "Epoch [126/300], Step [135/225], Training Accuracy: 98.8889%, Training Loss: 0.0392%\n",
      "Epoch [126/300], Step [136/225], Training Accuracy: 98.8741%, Training Loss: 0.0396%\n",
      "Epoch [126/300], Step [137/225], Training Accuracy: 98.8823%, Training Loss: 0.0394%\n",
      "Epoch [126/300], Step [138/225], Training Accuracy: 98.8791%, Training Loss: 0.0395%\n",
      "Epoch [126/300], Step [139/225], Training Accuracy: 98.8647%, Training Loss: 0.0400%\n",
      "Epoch [126/300], Step [140/225], Training Accuracy: 98.8616%, Training Loss: 0.0402%\n",
      "Epoch [126/300], Step [141/225], Training Accuracy: 98.8364%, Training Loss: 0.0405%\n",
      "Epoch [126/300], Step [142/225], Training Accuracy: 98.8446%, Training Loss: 0.0404%\n",
      "Epoch [126/300], Step [143/225], Training Accuracy: 98.8418%, Training Loss: 0.0404%\n",
      "Epoch [126/300], Step [144/225], Training Accuracy: 98.8390%, Training Loss: 0.0404%\n",
      "Epoch [126/300], Step [145/225], Training Accuracy: 98.8470%, Training Loss: 0.0402%\n",
      "Epoch [126/300], Step [146/225], Training Accuracy: 98.8442%, Training Loss: 0.0402%\n",
      "Epoch [126/300], Step [147/225], Training Accuracy: 98.8520%, Training Loss: 0.0402%\n",
      "Epoch [126/300], Step [148/225], Training Accuracy: 98.8492%, Training Loss: 0.0402%\n",
      "Epoch [126/300], Step [149/225], Training Accuracy: 98.8465%, Training Loss: 0.0402%\n",
      "Epoch [126/300], Step [150/225], Training Accuracy: 98.8438%, Training Loss: 0.0402%\n",
      "Epoch [126/300], Step [151/225], Training Accuracy: 98.8514%, Training Loss: 0.0400%\n",
      "Epoch [126/300], Step [152/225], Training Accuracy: 98.8590%, Training Loss: 0.0399%\n",
      "Epoch [126/300], Step [153/225], Training Accuracy: 98.8664%, Training Loss: 0.0397%\n",
      "Epoch [126/300], Step [154/225], Training Accuracy: 98.8738%, Training Loss: 0.0396%\n",
      "Epoch [126/300], Step [155/225], Training Accuracy: 98.8609%, Training Loss: 0.0397%\n",
      "Epoch [126/300], Step [156/225], Training Accuracy: 98.8482%, Training Loss: 0.0398%\n",
      "Epoch [126/300], Step [157/225], Training Accuracy: 98.8555%, Training Loss: 0.0398%\n",
      "Epoch [126/300], Step [158/225], Training Accuracy: 98.8627%, Training Loss: 0.0396%\n",
      "Epoch [126/300], Step [159/225], Training Accuracy: 98.8699%, Training Loss: 0.0396%\n",
      "Epoch [126/300], Step [160/225], Training Accuracy: 98.8672%, Training Loss: 0.0396%\n",
      "Epoch [126/300], Step [161/225], Training Accuracy: 98.8742%, Training Loss: 0.0394%\n",
      "Epoch [126/300], Step [162/225], Training Accuracy: 98.8715%, Training Loss: 0.0394%\n",
      "Epoch [126/300], Step [163/225], Training Accuracy: 98.8689%, Training Loss: 0.0393%\n",
      "Epoch [126/300], Step [164/225], Training Accuracy: 98.8472%, Training Loss: 0.0396%\n",
      "Epoch [126/300], Step [165/225], Training Accuracy: 98.8542%, Training Loss: 0.0395%\n",
      "Epoch [126/300], Step [166/225], Training Accuracy: 98.8611%, Training Loss: 0.0394%\n",
      "Epoch [126/300], Step [167/225], Training Accuracy: 98.8679%, Training Loss: 0.0394%\n",
      "Epoch [126/300], Step [168/225], Training Accuracy: 98.8653%, Training Loss: 0.0394%\n",
      "Epoch [126/300], Step [169/225], Training Accuracy: 98.8628%, Training Loss: 0.0395%\n",
      "Epoch [126/300], Step [170/225], Training Accuracy: 98.8511%, Training Loss: 0.0397%\n",
      "Epoch [126/300], Step [171/225], Training Accuracy: 98.8487%, Training Loss: 0.0399%\n",
      "Epoch [126/300], Step [172/225], Training Accuracy: 98.8372%, Training Loss: 0.0402%\n",
      "Epoch [126/300], Step [173/225], Training Accuracy: 98.8259%, Training Loss: 0.0404%\n",
      "Epoch [126/300], Step [174/225], Training Accuracy: 98.8147%, Training Loss: 0.0405%\n",
      "Epoch [126/300], Step [175/225], Training Accuracy: 98.8125%, Training Loss: 0.0405%\n",
      "Epoch [126/300], Step [176/225], Training Accuracy: 98.8104%, Training Loss: 0.0405%\n",
      "Epoch [126/300], Step [177/225], Training Accuracy: 98.8171%, Training Loss: 0.0404%\n",
      "Epoch [126/300], Step [178/225], Training Accuracy: 98.8150%, Training Loss: 0.0404%\n",
      "Epoch [126/300], Step [179/225], Training Accuracy: 98.8128%, Training Loss: 0.0406%\n",
      "Epoch [126/300], Step [180/225], Training Accuracy: 98.8194%, Training Loss: 0.0405%\n",
      "Epoch [126/300], Step [181/225], Training Accuracy: 98.8173%, Training Loss: 0.0405%\n",
      "Epoch [126/300], Step [182/225], Training Accuracy: 98.8067%, Training Loss: 0.0408%\n",
      "Epoch [126/300], Step [183/225], Training Accuracy: 98.8132%, Training Loss: 0.0407%\n",
      "Epoch [126/300], Step [184/225], Training Accuracy: 98.8026%, Training Loss: 0.0408%\n",
      "Epoch [126/300], Step [185/225], Training Accuracy: 98.8091%, Training Loss: 0.0407%\n",
      "Epoch [126/300], Step [186/225], Training Accuracy: 98.7987%, Training Loss: 0.0408%\n",
      "Epoch [126/300], Step [187/225], Training Accuracy: 98.8051%, Training Loss: 0.0408%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [126/300], Step [188/225], Training Accuracy: 98.8115%, Training Loss: 0.0406%\n",
      "Epoch [126/300], Step [189/225], Training Accuracy: 98.8095%, Training Loss: 0.0405%\n",
      "Epoch [126/300], Step [190/225], Training Accuracy: 98.8158%, Training Loss: 0.0404%\n",
      "Epoch [126/300], Step [191/225], Training Accuracy: 98.8056%, Training Loss: 0.0408%\n",
      "Epoch [126/300], Step [192/225], Training Accuracy: 98.8118%, Training Loss: 0.0407%\n",
      "Epoch [126/300], Step [193/225], Training Accuracy: 98.7937%, Training Loss: 0.0410%\n",
      "Epoch [126/300], Step [194/225], Training Accuracy: 98.7999%, Training Loss: 0.0410%\n",
      "Epoch [126/300], Step [195/225], Training Accuracy: 98.7901%, Training Loss: 0.0410%\n",
      "Epoch [126/300], Step [196/225], Training Accuracy: 98.7883%, Training Loss: 0.0411%\n",
      "Epoch [126/300], Step [197/225], Training Accuracy: 98.7865%, Training Loss: 0.0411%\n",
      "Epoch [126/300], Step [198/225], Training Accuracy: 98.7847%, Training Loss: 0.0411%\n",
      "Epoch [126/300], Step [199/225], Training Accuracy: 98.7751%, Training Loss: 0.0412%\n",
      "Epoch [126/300], Step [200/225], Training Accuracy: 98.7812%, Training Loss: 0.0412%\n",
      "Epoch [126/300], Step [201/225], Training Accuracy: 98.7795%, Training Loss: 0.0412%\n",
      "Epoch [126/300], Step [202/225], Training Accuracy: 98.7856%, Training Loss: 0.0411%\n",
      "Epoch [126/300], Step [203/225], Training Accuracy: 98.7916%, Training Loss: 0.0411%\n",
      "Epoch [126/300], Step [204/225], Training Accuracy: 98.7822%, Training Loss: 0.0413%\n",
      "Epoch [126/300], Step [205/225], Training Accuracy: 98.7881%, Training Loss: 0.0412%\n",
      "Epoch [126/300], Step [206/225], Training Accuracy: 98.7940%, Training Loss: 0.0411%\n",
      "Epoch [126/300], Step [207/225], Training Accuracy: 98.7923%, Training Loss: 0.0411%\n",
      "Epoch [126/300], Step [208/225], Training Accuracy: 98.7906%, Training Loss: 0.0413%\n",
      "Epoch [126/300], Step [209/225], Training Accuracy: 98.7889%, Training Loss: 0.0412%\n",
      "Epoch [126/300], Step [210/225], Training Accuracy: 98.7946%, Training Loss: 0.0412%\n",
      "Epoch [126/300], Step [211/225], Training Accuracy: 98.7930%, Training Loss: 0.0412%\n",
      "Epoch [126/300], Step [212/225], Training Accuracy: 98.7913%, Training Loss: 0.0413%\n",
      "Epoch [126/300], Step [213/225], Training Accuracy: 98.7969%, Training Loss: 0.0413%\n",
      "Epoch [126/300], Step [214/225], Training Accuracy: 98.7953%, Training Loss: 0.0413%\n",
      "Epoch [126/300], Step [215/225], Training Accuracy: 98.7863%, Training Loss: 0.0415%\n",
      "Epoch [126/300], Step [216/225], Training Accuracy: 98.7847%, Training Loss: 0.0417%\n",
      "Epoch [126/300], Step [217/225], Training Accuracy: 98.7831%, Training Loss: 0.0417%\n",
      "Epoch [126/300], Step [218/225], Training Accuracy: 98.7672%, Training Loss: 0.0418%\n",
      "Epoch [126/300], Step [219/225], Training Accuracy: 98.7728%, Training Loss: 0.0418%\n",
      "Epoch [126/300], Step [220/225], Training Accuracy: 98.7784%, Training Loss: 0.0418%\n",
      "Epoch [126/300], Step [221/225], Training Accuracy: 98.7769%, Training Loss: 0.0420%\n",
      "Epoch [126/300], Step [222/225], Training Accuracy: 98.7824%, Training Loss: 0.0418%\n",
      "Epoch [126/300], Step [223/225], Training Accuracy: 98.7738%, Training Loss: 0.0421%\n",
      "Epoch [126/300], Step [224/225], Training Accuracy: 98.7723%, Training Loss: 0.0420%\n",
      "Epoch [126/300], Step [225/225], Training Accuracy: 98.7702%, Training Loss: 0.0422%\n",
      "Epoch [127/300], Step [1/225], Training Accuracy: 96.8750%, Training Loss: 0.0580%\n",
      "Epoch [127/300], Step [2/225], Training Accuracy: 98.4375%, Training Loss: 0.0422%\n",
      "Epoch [127/300], Step [3/225], Training Accuracy: 96.8750%, Training Loss: 0.0901%\n",
      "Epoch [127/300], Step [4/225], Training Accuracy: 97.6562%, Training Loss: 0.0775%\n",
      "Epoch [127/300], Step [5/225], Training Accuracy: 97.8125%, Training Loss: 0.0711%\n",
      "Epoch [127/300], Step [6/225], Training Accuracy: 97.9167%, Training Loss: 0.0685%\n",
      "Epoch [127/300], Step [7/225], Training Accuracy: 97.3214%, Training Loss: 0.0724%\n",
      "Epoch [127/300], Step [8/225], Training Accuracy: 97.4609%, Training Loss: 0.0710%\n",
      "Epoch [127/300], Step [9/225], Training Accuracy: 97.7431%, Training Loss: 0.0636%\n",
      "Epoch [127/300], Step [10/225], Training Accuracy: 97.8125%, Training Loss: 0.0632%\n",
      "Epoch [127/300], Step [11/225], Training Accuracy: 97.7273%, Training Loss: 0.0628%\n",
      "Epoch [127/300], Step [12/225], Training Accuracy: 97.9167%, Training Loss: 0.0591%\n",
      "Epoch [127/300], Step [13/225], Training Accuracy: 98.0769%, Training Loss: 0.0559%\n",
      "Epoch [127/300], Step [14/225], Training Accuracy: 98.2143%, Training Loss: 0.0543%\n",
      "Epoch [127/300], Step [15/225], Training Accuracy: 98.2292%, Training Loss: 0.0526%\n",
      "Epoch [127/300], Step [16/225], Training Accuracy: 98.2422%, Training Loss: 0.0524%\n",
      "Epoch [127/300], Step [17/225], Training Accuracy: 98.3456%, Training Loss: 0.0511%\n",
      "Epoch [127/300], Step [18/225], Training Accuracy: 98.2639%, Training Loss: 0.0515%\n",
      "Epoch [127/300], Step [19/225], Training Accuracy: 98.3553%, Training Loss: 0.0499%\n",
      "Epoch [127/300], Step [20/225], Training Accuracy: 98.4375%, Training Loss: 0.0485%\n",
      "Epoch [127/300], Step [21/225], Training Accuracy: 98.4375%, Training Loss: 0.0489%\n",
      "Epoch [127/300], Step [22/225], Training Accuracy: 98.2955%, Training Loss: 0.0510%\n",
      "Epoch [127/300], Step [23/225], Training Accuracy: 98.3696%, Training Loss: 0.0495%\n",
      "Epoch [127/300], Step [24/225], Training Accuracy: 98.4375%, Training Loss: 0.0479%\n",
      "Epoch [127/300], Step [25/225], Training Accuracy: 98.3750%, Training Loss: 0.0485%\n",
      "Epoch [127/300], Step [26/225], Training Accuracy: 98.3774%, Training Loss: 0.0487%\n",
      "Epoch [127/300], Step [27/225], Training Accuracy: 98.3218%, Training Loss: 0.0485%\n",
      "Epoch [127/300], Step [28/225], Training Accuracy: 98.3817%, Training Loss: 0.0471%\n",
      "Epoch [127/300], Step [29/225], Training Accuracy: 98.4375%, Training Loss: 0.0464%\n",
      "Epoch [127/300], Step [30/225], Training Accuracy: 98.3333%, Training Loss: 0.0491%\n",
      "Epoch [127/300], Step [31/225], Training Accuracy: 98.3367%, Training Loss: 0.0497%\n",
      "Epoch [127/300], Step [32/225], Training Accuracy: 98.3887%, Training Loss: 0.0493%\n",
      "Epoch [127/300], Step [33/225], Training Accuracy: 98.4375%, Training Loss: 0.0482%\n",
      "Epoch [127/300], Step [34/225], Training Accuracy: 98.3915%, Training Loss: 0.0481%\n",
      "Epoch [127/300], Step [35/225], Training Accuracy: 98.3482%, Training Loss: 0.0494%\n",
      "Epoch [127/300], Step [36/225], Training Accuracy: 98.3507%, Training Loss: 0.0494%\n",
      "Epoch [127/300], Step [37/225], Training Accuracy: 98.3953%, Training Loss: 0.0484%\n",
      "Epoch [127/300], Step [38/225], Training Accuracy: 98.4375%, Training Loss: 0.0479%\n",
      "Epoch [127/300], Step [39/225], Training Accuracy: 98.4375%, Training Loss: 0.0478%\n",
      "Epoch [127/300], Step [40/225], Training Accuracy: 98.4375%, Training Loss: 0.0481%\n",
      "Epoch [127/300], Step [41/225], Training Accuracy: 98.4756%, Training Loss: 0.0475%\n",
      "Epoch [127/300], Step [42/225], Training Accuracy: 98.4747%, Training Loss: 0.0474%\n",
      "Epoch [127/300], Step [43/225], Training Accuracy: 98.5102%, Training Loss: 0.0467%\n",
      "Epoch [127/300], Step [44/225], Training Accuracy: 98.5440%, Training Loss: 0.0460%\n",
      "Epoch [127/300], Step [45/225], Training Accuracy: 98.5764%, Training Loss: 0.0455%\n",
      "Epoch [127/300], Step [46/225], Training Accuracy: 98.6073%, Training Loss: 0.0447%\n",
      "Epoch [127/300], Step [47/225], Training Accuracy: 98.6037%, Training Loss: 0.0446%\n",
      "Epoch [127/300], Step [48/225], Training Accuracy: 98.6003%, Training Loss: 0.0443%\n",
      "Epoch [127/300], Step [49/225], Training Accuracy: 98.5969%, Training Loss: 0.0443%\n",
      "Epoch [127/300], Step [50/225], Training Accuracy: 98.5625%, Training Loss: 0.0445%\n",
      "Epoch [127/300], Step [51/225], Training Accuracy: 98.5294%, Training Loss: 0.0458%\n",
      "Epoch [127/300], Step [52/225], Training Accuracy: 98.5276%, Training Loss: 0.0457%\n",
      "Epoch [127/300], Step [53/225], Training Accuracy: 98.5259%, Training Loss: 0.0457%\n",
      "Epoch [127/300], Step [54/225], Training Accuracy: 98.5532%, Training Loss: 0.0455%\n",
      "Epoch [127/300], Step [55/225], Training Accuracy: 98.5227%, Training Loss: 0.0457%\n",
      "Epoch [127/300], Step [56/225], Training Accuracy: 98.5212%, Training Loss: 0.0458%\n",
      "Epoch [127/300], Step [57/225], Training Accuracy: 98.5471%, Training Loss: 0.0455%\n",
      "Epoch [127/300], Step [58/225], Training Accuracy: 98.4914%, Training Loss: 0.0463%\n",
      "Epoch [127/300], Step [59/225], Training Accuracy: 98.4375%, Training Loss: 0.0472%\n",
      "Epoch [127/300], Step [60/225], Training Accuracy: 98.3854%, Training Loss: 0.0476%\n",
      "Epoch [127/300], Step [61/225], Training Accuracy: 98.3863%, Training Loss: 0.0476%\n",
      "Epoch [127/300], Step [62/225], Training Accuracy: 98.3619%, Training Loss: 0.0484%\n",
      "Epoch [127/300], Step [63/225], Training Accuracy: 98.3631%, Training Loss: 0.0481%\n",
      "Epoch [127/300], Step [64/225], Training Accuracy: 98.3887%, Training Loss: 0.0476%\n",
      "Epoch [127/300], Step [65/225], Training Accuracy: 98.3894%, Training Loss: 0.0475%\n",
      "Epoch [127/300], Step [66/225], Training Accuracy: 98.3902%, Training Loss: 0.0475%\n",
      "Epoch [127/300], Step [67/225], Training Accuracy: 98.3442%, Training Loss: 0.0481%\n",
      "Epoch [127/300], Step [68/225], Training Accuracy: 98.3226%, Training Loss: 0.0486%\n",
      "Epoch [127/300], Step [69/225], Training Accuracy: 98.3243%, Training Loss: 0.0483%\n",
      "Epoch [127/300], Step [70/225], Training Accuracy: 98.3259%, Training Loss: 0.0481%\n",
      "Epoch [127/300], Step [71/225], Training Accuracy: 98.3275%, Training Loss: 0.0478%\n",
      "Epoch [127/300], Step [72/225], Training Accuracy: 98.3073%, Training Loss: 0.0483%\n",
      "Epoch [127/300], Step [73/225], Training Accuracy: 98.2449%, Training Loss: 0.0490%\n",
      "Epoch [127/300], Step [74/225], Training Accuracy: 98.2475%, Training Loss: 0.0488%\n",
      "Epoch [127/300], Step [75/225], Training Accuracy: 98.2500%, Training Loss: 0.0484%\n",
      "Epoch [127/300], Step [76/225], Training Accuracy: 98.2730%, Training Loss: 0.0483%\n",
      "Epoch [127/300], Step [77/225], Training Accuracy: 98.2955%, Training Loss: 0.0478%\n",
      "Epoch [127/300], Step [78/225], Training Accuracy: 98.2973%, Training Loss: 0.0478%\n",
      "Epoch [127/300], Step [79/225], Training Accuracy: 98.2793%, Training Loss: 0.0479%\n",
      "Epoch [127/300], Step [80/225], Training Accuracy: 98.3008%, Training Loss: 0.0475%\n",
      "Epoch [127/300], Step [81/225], Training Accuracy: 98.2832%, Training Loss: 0.0477%\n",
      "Epoch [127/300], Step [82/225], Training Accuracy: 98.2660%, Training Loss: 0.0478%\n",
      "Epoch [127/300], Step [83/225], Training Accuracy: 98.2681%, Training Loss: 0.0478%\n",
      "Epoch [127/300], Step [84/225], Training Accuracy: 98.2701%, Training Loss: 0.0477%\n",
      "Epoch [127/300], Step [85/225], Training Accuracy: 98.2904%, Training Loss: 0.0475%\n",
      "Epoch [127/300], Step [86/225], Training Accuracy: 98.2558%, Training Loss: 0.0476%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [127/300], Step [87/225], Training Accuracy: 98.2399%, Training Loss: 0.0479%\n",
      "Epoch [127/300], Step [88/225], Training Accuracy: 98.2599%, Training Loss: 0.0474%\n",
      "Epoch [127/300], Step [89/225], Training Accuracy: 98.2795%, Training Loss: 0.0471%\n",
      "Epoch [127/300], Step [90/225], Training Accuracy: 98.2812%, Training Loss: 0.0470%\n",
      "Epoch [127/300], Step [91/225], Training Accuracy: 98.2830%, Training Loss: 0.0468%\n",
      "Epoch [127/300], Step [92/225], Training Accuracy: 98.2846%, Training Loss: 0.0469%\n",
      "Epoch [127/300], Step [93/225], Training Accuracy: 98.2695%, Training Loss: 0.0468%\n",
      "Epoch [127/300], Step [94/225], Training Accuracy: 98.2713%, Training Loss: 0.0468%\n",
      "Epoch [127/300], Step [95/225], Training Accuracy: 98.2895%, Training Loss: 0.0465%\n",
      "Epoch [127/300], Step [96/225], Training Accuracy: 98.3073%, Training Loss: 0.0462%\n",
      "Epoch [127/300], Step [97/225], Training Accuracy: 98.3086%, Training Loss: 0.0466%\n",
      "Epoch [127/300], Step [98/225], Training Accuracy: 98.2621%, Training Loss: 0.0473%\n",
      "Epoch [127/300], Step [99/225], Training Accuracy: 98.2639%, Training Loss: 0.0472%\n",
      "Epoch [127/300], Step [100/225], Training Accuracy: 98.2656%, Training Loss: 0.0474%\n",
      "Epoch [127/300], Step [101/225], Training Accuracy: 98.2828%, Training Loss: 0.0472%\n",
      "Epoch [127/300], Step [102/225], Training Accuracy: 98.2690%, Training Loss: 0.0477%\n",
      "Epoch [127/300], Step [103/225], Training Accuracy: 98.2706%, Training Loss: 0.0480%\n",
      "Epoch [127/300], Step [104/225], Training Accuracy: 98.2873%, Training Loss: 0.0477%\n",
      "Epoch [127/300], Step [105/225], Training Accuracy: 98.2738%, Training Loss: 0.0485%\n",
      "Epoch [127/300], Step [106/225], Training Accuracy: 98.2754%, Training Loss: 0.0487%\n",
      "Epoch [127/300], Step [107/225], Training Accuracy: 98.2915%, Training Loss: 0.0485%\n",
      "Epoch [127/300], Step [108/225], Training Accuracy: 98.2928%, Training Loss: 0.0486%\n",
      "Epoch [127/300], Step [109/225], Training Accuracy: 98.2942%, Training Loss: 0.0485%\n",
      "Epoch [127/300], Step [110/225], Training Accuracy: 98.3097%, Training Loss: 0.0483%\n",
      "Epoch [127/300], Step [111/225], Training Accuracy: 98.3108%, Training Loss: 0.0482%\n",
      "Epoch [127/300], Step [112/225], Training Accuracy: 98.3259%, Training Loss: 0.0479%\n",
      "Epoch [127/300], Step [113/225], Training Accuracy: 98.3131%, Training Loss: 0.0481%\n",
      "Epoch [127/300], Step [114/225], Training Accuracy: 98.3141%, Training Loss: 0.0479%\n",
      "Epoch [127/300], Step [115/225], Training Accuracy: 98.3288%, Training Loss: 0.0479%\n",
      "Epoch [127/300], Step [116/225], Training Accuracy: 98.3432%, Training Loss: 0.0479%\n",
      "Epoch [127/300], Step [117/225], Training Accuracy: 98.3040%, Training Loss: 0.0485%\n",
      "Epoch [127/300], Step [118/225], Training Accuracy: 98.2786%, Training Loss: 0.0490%\n",
      "Epoch [127/300], Step [119/225], Training Accuracy: 98.2668%, Training Loss: 0.0493%\n",
      "Epoch [127/300], Step [120/225], Training Accuracy: 98.2682%, Training Loss: 0.0492%\n",
      "Epoch [127/300], Step [121/225], Training Accuracy: 98.2825%, Training Loss: 0.0489%\n",
      "Epoch [127/300], Step [122/225], Training Accuracy: 98.2966%, Training Loss: 0.0488%\n",
      "Epoch [127/300], Step [123/225], Training Accuracy: 98.2851%, Training Loss: 0.0489%\n",
      "Epoch [127/300], Step [124/225], Training Accuracy: 98.2863%, Training Loss: 0.0488%\n",
      "Epoch [127/300], Step [125/225], Training Accuracy: 98.3000%, Training Loss: 0.0487%\n",
      "Epoch [127/300], Step [126/225], Training Accuracy: 98.3011%, Training Loss: 0.0486%\n",
      "Epoch [127/300], Step [127/225], Training Accuracy: 98.3145%, Training Loss: 0.0484%\n",
      "Epoch [127/300], Step [128/225], Training Accuracy: 98.3276%, Training Loss: 0.0483%\n",
      "Epoch [127/300], Step [129/225], Training Accuracy: 98.3164%, Training Loss: 0.0485%\n",
      "Epoch [127/300], Step [130/225], Training Accuracy: 98.3173%, Training Loss: 0.0483%\n",
      "Epoch [127/300], Step [131/225], Training Accuracy: 98.3302%, Training Loss: 0.0480%\n",
      "Epoch [127/300], Step [132/225], Training Accuracy: 98.3428%, Training Loss: 0.0479%\n",
      "Epoch [127/300], Step [133/225], Training Accuracy: 98.3553%, Training Loss: 0.0478%\n",
      "Epoch [127/300], Step [134/225], Training Accuracy: 98.3559%, Training Loss: 0.0477%\n",
      "Epoch [127/300], Step [135/225], Training Accuracy: 98.3565%, Training Loss: 0.0477%\n",
      "Epoch [127/300], Step [136/225], Training Accuracy: 98.3571%, Training Loss: 0.0477%\n",
      "Epoch [127/300], Step [137/225], Training Accuracy: 98.3463%, Training Loss: 0.0477%\n",
      "Epoch [127/300], Step [138/225], Training Accuracy: 98.3582%, Training Loss: 0.0475%\n",
      "Epoch [127/300], Step [139/225], Training Accuracy: 98.3701%, Training Loss: 0.0474%\n",
      "Epoch [127/300], Step [140/225], Training Accuracy: 98.3705%, Training Loss: 0.0473%\n",
      "Epoch [127/300], Step [141/225], Training Accuracy: 98.3821%, Training Loss: 0.0472%\n",
      "Epoch [127/300], Step [142/225], Training Accuracy: 98.3935%, Training Loss: 0.0470%\n",
      "Epoch [127/300], Step [143/225], Training Accuracy: 98.3938%, Training Loss: 0.0470%\n",
      "Epoch [127/300], Step [144/225], Training Accuracy: 98.3832%, Training Loss: 0.0471%\n",
      "Epoch [127/300], Step [145/225], Training Accuracy: 98.3836%, Training Loss: 0.0470%\n",
      "Epoch [127/300], Step [146/225], Training Accuracy: 98.3733%, Training Loss: 0.0470%\n",
      "Epoch [127/300], Step [147/225], Training Accuracy: 98.3737%, Training Loss: 0.0470%\n",
      "Epoch [127/300], Step [148/225], Training Accuracy: 98.3847%, Training Loss: 0.0468%\n",
      "Epoch [127/300], Step [149/225], Training Accuracy: 98.3956%, Training Loss: 0.0467%\n",
      "Epoch [127/300], Step [150/225], Training Accuracy: 98.3958%, Training Loss: 0.0468%\n",
      "Epoch [127/300], Step [151/225], Training Accuracy: 98.3547%, Training Loss: 0.0472%\n",
      "Epoch [127/300], Step [152/225], Training Accuracy: 98.3655%, Training Loss: 0.0470%\n",
      "Epoch [127/300], Step [153/225], Training Accuracy: 98.3762%, Training Loss: 0.0469%\n",
      "Epoch [127/300], Step [154/225], Training Accuracy: 98.3868%, Training Loss: 0.0468%\n",
      "Epoch [127/300], Step [155/225], Training Accuracy: 98.3972%, Training Loss: 0.0467%\n",
      "Epoch [127/300], Step [156/225], Training Accuracy: 98.3974%, Training Loss: 0.0467%\n",
      "Epoch [127/300], Step [157/225], Training Accuracy: 98.3877%, Training Loss: 0.0468%\n",
      "Epoch [127/300], Step [158/225], Training Accuracy: 98.3881%, Training Loss: 0.0468%\n",
      "Epoch [127/300], Step [159/225], Training Accuracy: 98.3687%, Training Loss: 0.0469%\n",
      "Epoch [127/300], Step [160/225], Training Accuracy: 98.3789%, Training Loss: 0.0467%\n",
      "Epoch [127/300], Step [161/225], Training Accuracy: 98.3696%, Training Loss: 0.0468%\n",
      "Epoch [127/300], Step [162/225], Training Accuracy: 98.3700%, Training Loss: 0.0469%\n",
      "Epoch [127/300], Step [163/225], Training Accuracy: 98.3704%, Training Loss: 0.0470%\n",
      "Epoch [127/300], Step [164/225], Training Accuracy: 98.3613%, Training Loss: 0.0471%\n",
      "Epoch [127/300], Step [165/225], Training Accuracy: 98.3523%, Training Loss: 0.0473%\n",
      "Epoch [127/300], Step [166/225], Training Accuracy: 98.3340%, Training Loss: 0.0474%\n",
      "Epoch [127/300], Step [167/225], Training Accuracy: 98.3346%, Training Loss: 0.0473%\n",
      "Epoch [127/300], Step [168/225], Training Accuracy: 98.3352%, Training Loss: 0.0472%\n",
      "Epoch [127/300], Step [169/225], Training Accuracy: 98.3358%, Training Loss: 0.0471%\n",
      "Epoch [127/300], Step [170/225], Training Accuracy: 98.3364%, Training Loss: 0.0472%\n",
      "Epoch [127/300], Step [171/225], Training Accuracy: 98.3370%, Training Loss: 0.0472%\n",
      "Epoch [127/300], Step [172/225], Training Accuracy: 98.3467%, Training Loss: 0.0472%\n",
      "Epoch [127/300], Step [173/225], Training Accuracy: 98.3562%, Training Loss: 0.0472%\n",
      "Epoch [127/300], Step [174/225], Training Accuracy: 98.3477%, Training Loss: 0.0472%\n",
      "Epoch [127/300], Step [175/225], Training Accuracy: 98.3393%, Training Loss: 0.0474%\n",
      "Epoch [127/300], Step [176/225], Training Accuracy: 98.3487%, Training Loss: 0.0472%\n",
      "Epoch [127/300], Step [177/225], Training Accuracy: 98.3581%, Training Loss: 0.0472%\n",
      "Epoch [127/300], Step [178/225], Training Accuracy: 98.3673%, Training Loss: 0.0471%\n",
      "Epoch [127/300], Step [179/225], Training Accuracy: 98.3677%, Training Loss: 0.0470%\n",
      "Epoch [127/300], Step [180/225], Training Accuracy: 98.3767%, Training Loss: 0.0469%\n",
      "Epoch [127/300], Step [181/225], Training Accuracy: 98.3771%, Training Loss: 0.0468%\n",
      "Epoch [127/300], Step [182/225], Training Accuracy: 98.3774%, Training Loss: 0.0468%\n",
      "Epoch [127/300], Step [183/225], Training Accuracy: 98.3692%, Training Loss: 0.0468%\n",
      "Epoch [127/300], Step [184/225], Training Accuracy: 98.3696%, Training Loss: 0.0468%\n",
      "Epoch [127/300], Step [185/225], Training Accuracy: 98.3699%, Training Loss: 0.0468%\n",
      "Epoch [127/300], Step [186/225], Training Accuracy: 98.3787%, Training Loss: 0.0467%\n",
      "Epoch [127/300], Step [187/225], Training Accuracy: 98.3790%, Training Loss: 0.0466%\n",
      "Epoch [127/300], Step [188/225], Training Accuracy: 98.3876%, Training Loss: 0.0464%\n",
      "Epoch [127/300], Step [189/225], Training Accuracy: 98.3962%, Training Loss: 0.0462%\n",
      "Epoch [127/300], Step [190/225], Training Accuracy: 98.3964%, Training Loss: 0.0463%\n",
      "Epoch [127/300], Step [191/225], Training Accuracy: 98.4048%, Training Loss: 0.0462%\n",
      "Epoch [127/300], Step [192/225], Training Accuracy: 98.4131%, Training Loss: 0.0461%\n",
      "Epoch [127/300], Step [193/225], Training Accuracy: 98.4051%, Training Loss: 0.0462%\n",
      "Epoch [127/300], Step [194/225], Training Accuracy: 98.4133%, Training Loss: 0.0462%\n",
      "Epoch [127/300], Step [195/225], Training Accuracy: 98.4135%, Training Loss: 0.0461%\n",
      "Epoch [127/300], Step [196/225], Training Accuracy: 98.4216%, Training Loss: 0.0460%\n",
      "Epoch [127/300], Step [197/225], Training Accuracy: 98.4296%, Training Loss: 0.0458%\n",
      "Epoch [127/300], Step [198/225], Training Accuracy: 98.4375%, Training Loss: 0.0458%\n",
      "Epoch [127/300], Step [199/225], Training Accuracy: 98.4375%, Training Loss: 0.0457%\n",
      "Epoch [127/300], Step [200/225], Training Accuracy: 98.4375%, Training Loss: 0.0456%\n",
      "Epoch [127/300], Step [201/225], Training Accuracy: 98.4453%, Training Loss: 0.0455%\n",
      "Epoch [127/300], Step [202/225], Training Accuracy: 98.4530%, Training Loss: 0.0454%\n",
      "Epoch [127/300], Step [203/225], Training Accuracy: 98.4606%, Training Loss: 0.0453%\n",
      "Epoch [127/300], Step [204/225], Training Accuracy: 98.4681%, Training Loss: 0.0453%\n",
      "Epoch [127/300], Step [205/225], Training Accuracy: 98.4680%, Training Loss: 0.0453%\n",
      "Epoch [127/300], Step [206/225], Training Accuracy: 98.4678%, Training Loss: 0.0455%\n",
      "Epoch [127/300], Step [207/225], Training Accuracy: 98.4752%, Training Loss: 0.0454%\n",
      "Epoch [127/300], Step [208/225], Training Accuracy: 98.4751%, Training Loss: 0.0453%\n",
      "Epoch [127/300], Step [209/225], Training Accuracy: 98.4674%, Training Loss: 0.0454%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [127/300], Step [210/225], Training Accuracy: 98.4747%, Training Loss: 0.0453%\n",
      "Epoch [127/300], Step [211/225], Training Accuracy: 98.4745%, Training Loss: 0.0454%\n",
      "Epoch [127/300], Step [212/225], Training Accuracy: 98.4670%, Training Loss: 0.0455%\n",
      "Epoch [127/300], Step [213/225], Training Accuracy: 98.4668%, Training Loss: 0.0454%\n",
      "Epoch [127/300], Step [214/225], Training Accuracy: 98.4667%, Training Loss: 0.0454%\n",
      "Epoch [127/300], Step [215/225], Training Accuracy: 98.4593%, Training Loss: 0.0456%\n",
      "Epoch [127/300], Step [216/225], Training Accuracy: 98.4592%, Training Loss: 0.0457%\n",
      "Epoch [127/300], Step [217/225], Training Accuracy: 98.4591%, Training Loss: 0.0457%\n",
      "Epoch [127/300], Step [218/225], Training Accuracy: 98.4590%, Training Loss: 0.0456%\n",
      "Epoch [127/300], Step [219/225], Training Accuracy: 98.4518%, Training Loss: 0.0457%\n",
      "Epoch [127/300], Step [220/225], Training Accuracy: 98.4517%, Training Loss: 0.0456%\n",
      "Epoch [127/300], Step [221/225], Training Accuracy: 98.4446%, Training Loss: 0.0458%\n",
      "Epoch [127/300], Step [222/225], Training Accuracy: 98.4445%, Training Loss: 0.0458%\n",
      "Epoch [127/300], Step [223/225], Training Accuracy: 98.4445%, Training Loss: 0.0457%\n",
      "Epoch [127/300], Step [224/225], Training Accuracy: 98.4445%, Training Loss: 0.0457%\n",
      "Epoch [127/300], Step [225/225], Training Accuracy: 98.4505%, Training Loss: 0.0456%\n",
      "Epoch [128/300], Step [1/225], Training Accuracy: 98.4375%, Training Loss: 0.0435%\n",
      "Epoch [128/300], Step [2/225], Training Accuracy: 99.2188%, Training Loss: 0.0302%\n",
      "Epoch [128/300], Step [3/225], Training Accuracy: 97.9167%, Training Loss: 0.0444%\n",
      "Epoch [128/300], Step [4/225], Training Accuracy: 98.0469%, Training Loss: 0.0434%\n",
      "Epoch [128/300], Step [5/225], Training Accuracy: 98.4375%, Training Loss: 0.0377%\n",
      "Epoch [128/300], Step [6/225], Training Accuracy: 98.6979%, Training Loss: 0.0353%\n",
      "Epoch [128/300], Step [7/225], Training Accuracy: 98.8839%, Training Loss: 0.0328%\n",
      "Epoch [128/300], Step [8/225], Training Accuracy: 99.0234%, Training Loss: 0.0313%\n",
      "Epoch [128/300], Step [9/225], Training Accuracy: 98.9583%, Training Loss: 0.0308%\n",
      "Epoch [128/300], Step [10/225], Training Accuracy: 99.0625%, Training Loss: 0.0310%\n",
      "Epoch [128/300], Step [11/225], Training Accuracy: 99.1477%, Training Loss: 0.0311%\n",
      "Epoch [128/300], Step [12/225], Training Accuracy: 99.2188%, Training Loss: 0.0299%\n",
      "Epoch [128/300], Step [13/225], Training Accuracy: 99.1587%, Training Loss: 0.0298%\n",
      "Epoch [128/300], Step [14/225], Training Accuracy: 99.1071%, Training Loss: 0.0303%\n",
      "Epoch [128/300], Step [15/225], Training Accuracy: 99.1667%, Training Loss: 0.0288%\n",
      "Epoch [128/300], Step [16/225], Training Accuracy: 99.1211%, Training Loss: 0.0289%\n",
      "Epoch [128/300], Step [17/225], Training Accuracy: 99.1728%, Training Loss: 0.0283%\n",
      "Epoch [128/300], Step [18/225], Training Accuracy: 99.0451%, Training Loss: 0.0346%\n",
      "Epoch [128/300], Step [19/225], Training Accuracy: 98.9309%, Training Loss: 0.0367%\n",
      "Epoch [128/300], Step [20/225], Training Accuracy: 98.9844%, Training Loss: 0.0360%\n",
      "Epoch [128/300], Step [21/225], Training Accuracy: 99.0327%, Training Loss: 0.0357%\n",
      "Epoch [128/300], Step [22/225], Training Accuracy: 98.7926%, Training Loss: 0.0373%\n",
      "Epoch [128/300], Step [23/225], Training Accuracy: 98.8451%, Training Loss: 0.0369%\n",
      "Epoch [128/300], Step [24/225], Training Accuracy: 98.8281%, Training Loss: 0.0375%\n",
      "Epoch [128/300], Step [25/225], Training Accuracy: 98.8125%, Training Loss: 0.0375%\n",
      "Epoch [128/300], Step [26/225], Training Accuracy: 98.8582%, Training Loss: 0.0372%\n",
      "Epoch [128/300], Step [27/225], Training Accuracy: 98.8426%, Training Loss: 0.0375%\n",
      "Epoch [128/300], Step [28/225], Training Accuracy: 98.8839%, Training Loss: 0.0366%\n",
      "Epoch [128/300], Step [29/225], Training Accuracy: 98.9224%, Training Loss: 0.0366%\n",
      "Epoch [128/300], Step [30/225], Training Accuracy: 98.9583%, Training Loss: 0.0361%\n",
      "Epoch [128/300], Step [31/225], Training Accuracy: 98.9919%, Training Loss: 0.0356%\n",
      "Epoch [128/300], Step [32/225], Training Accuracy: 98.9746%, Training Loss: 0.0356%\n",
      "Epoch [128/300], Step [33/225], Training Accuracy: 99.0057%, Training Loss: 0.0351%\n",
      "Epoch [128/300], Step [34/225], Training Accuracy: 98.8971%, Training Loss: 0.0367%\n",
      "Epoch [128/300], Step [35/225], Training Accuracy: 98.8839%, Training Loss: 0.0370%\n",
      "Epoch [128/300], Step [36/225], Training Accuracy: 98.8281%, Training Loss: 0.0372%\n",
      "Epoch [128/300], Step [37/225], Training Accuracy: 98.8598%, Training Loss: 0.0365%\n",
      "Epoch [128/300], Step [38/225], Training Accuracy: 98.8487%, Training Loss: 0.0372%\n",
      "Epoch [128/300], Step [39/225], Training Accuracy: 98.8381%, Training Loss: 0.0367%\n",
      "Epoch [128/300], Step [40/225], Training Accuracy: 98.8672%, Training Loss: 0.0364%\n",
      "Epoch [128/300], Step [41/225], Training Accuracy: 98.8567%, Training Loss: 0.0375%\n",
      "Epoch [128/300], Step [42/225], Training Accuracy: 98.8839%, Training Loss: 0.0370%\n",
      "Epoch [128/300], Step [43/225], Training Accuracy: 98.8372%, Training Loss: 0.0385%\n",
      "Epoch [128/300], Step [44/225], Training Accuracy: 98.8281%, Training Loss: 0.0386%\n",
      "Epoch [128/300], Step [45/225], Training Accuracy: 98.8194%, Training Loss: 0.0386%\n",
      "Epoch [128/300], Step [46/225], Training Accuracy: 98.8111%, Training Loss: 0.0384%\n",
      "Epoch [128/300], Step [47/225], Training Accuracy: 98.8032%, Training Loss: 0.0381%\n",
      "Epoch [128/300], Step [48/225], Training Accuracy: 98.7630%, Training Loss: 0.0400%\n",
      "Epoch [128/300], Step [49/225], Training Accuracy: 98.7245%, Training Loss: 0.0407%\n",
      "Epoch [128/300], Step [50/225], Training Accuracy: 98.7188%, Training Loss: 0.0409%\n",
      "Epoch [128/300], Step [51/225], Training Accuracy: 98.7439%, Training Loss: 0.0402%\n",
      "Epoch [128/300], Step [52/225], Training Accuracy: 98.7380%, Training Loss: 0.0400%\n",
      "Epoch [128/300], Step [53/225], Training Accuracy: 98.7618%, Training Loss: 0.0397%\n",
      "Epoch [128/300], Step [54/225], Training Accuracy: 98.7558%, Training Loss: 0.0398%\n",
      "Epoch [128/300], Step [55/225], Training Accuracy: 98.7784%, Training Loss: 0.0395%\n",
      "Epoch [128/300], Step [56/225], Training Accuracy: 98.7444%, Training Loss: 0.0397%\n",
      "Epoch [128/300], Step [57/225], Training Accuracy: 98.7116%, Training Loss: 0.0402%\n",
      "Epoch [128/300], Step [58/225], Training Accuracy: 98.7338%, Training Loss: 0.0400%\n",
      "Epoch [128/300], Step [59/225], Training Accuracy: 98.7288%, Training Loss: 0.0404%\n",
      "Epoch [128/300], Step [60/225], Training Accuracy: 98.7500%, Training Loss: 0.0403%\n",
      "Epoch [128/300], Step [61/225], Training Accuracy: 98.7449%, Training Loss: 0.0410%\n",
      "Epoch [128/300], Step [62/225], Training Accuracy: 98.7399%, Training Loss: 0.0410%\n",
      "Epoch [128/300], Step [63/225], Training Accuracy: 98.7599%, Training Loss: 0.0406%\n",
      "Epoch [128/300], Step [64/225], Training Accuracy: 98.7793%, Training Loss: 0.0404%\n",
      "Epoch [128/300], Step [65/225], Training Accuracy: 98.7740%, Training Loss: 0.0404%\n",
      "Epoch [128/300], Step [66/225], Training Accuracy: 98.7453%, Training Loss: 0.0416%\n",
      "Epoch [128/300], Step [67/225], Training Accuracy: 98.7407%, Training Loss: 0.0419%\n",
      "Epoch [128/300], Step [68/225], Training Accuracy: 98.7592%, Training Loss: 0.0416%\n",
      "Epoch [128/300], Step [69/225], Training Accuracy: 98.7545%, Training Loss: 0.0415%\n",
      "Epoch [128/300], Step [70/225], Training Accuracy: 98.7500%, Training Loss: 0.0415%\n",
      "Epoch [128/300], Step [71/225], Training Accuracy: 98.7456%, Training Loss: 0.0415%\n",
      "Epoch [128/300], Step [72/225], Training Accuracy: 98.7630%, Training Loss: 0.0411%\n",
      "Epoch [128/300], Step [73/225], Training Accuracy: 98.7800%, Training Loss: 0.0410%\n",
      "Epoch [128/300], Step [74/225], Training Accuracy: 98.7542%, Training Loss: 0.0416%\n",
      "Epoch [128/300], Step [75/225], Training Accuracy: 98.7708%, Training Loss: 0.0413%\n",
      "Epoch [128/300], Step [76/225], Training Accuracy: 98.7048%, Training Loss: 0.0426%\n",
      "Epoch [128/300], Step [77/225], Training Accuracy: 98.7013%, Training Loss: 0.0426%\n",
      "Epoch [128/300], Step [78/225], Training Accuracy: 98.6979%, Training Loss: 0.0429%\n",
      "Epoch [128/300], Step [79/225], Training Accuracy: 98.6748%, Training Loss: 0.0431%\n",
      "Epoch [128/300], Step [80/225], Training Accuracy: 98.6523%, Training Loss: 0.0434%\n",
      "Epoch [128/300], Step [81/225], Training Accuracy: 98.6497%, Training Loss: 0.0436%\n",
      "Epoch [128/300], Step [82/225], Training Accuracy: 98.6662%, Training Loss: 0.0434%\n",
      "Epoch [128/300], Step [83/225], Training Accuracy: 98.6822%, Training Loss: 0.0433%\n",
      "Epoch [128/300], Step [84/225], Training Accuracy: 98.6979%, Training Loss: 0.0431%\n",
      "Epoch [128/300], Step [85/225], Training Accuracy: 98.6949%, Training Loss: 0.0430%\n",
      "Epoch [128/300], Step [86/225], Training Accuracy: 98.6919%, Training Loss: 0.0430%\n",
      "Epoch [128/300], Step [87/225], Training Accuracy: 98.6889%, Training Loss: 0.0433%\n",
      "Epoch [128/300], Step [88/225], Training Accuracy: 98.6861%, Training Loss: 0.0433%\n",
      "Epoch [128/300], Step [89/225], Training Accuracy: 98.7008%, Training Loss: 0.0430%\n",
      "Epoch [128/300], Step [90/225], Training Accuracy: 98.6632%, Training Loss: 0.0433%\n",
      "Epoch [128/300], Step [91/225], Training Accuracy: 98.6435%, Training Loss: 0.0442%\n",
      "Epoch [128/300], Step [92/225], Training Accuracy: 98.6583%, Training Loss: 0.0438%\n",
      "Epoch [128/300], Step [93/225], Training Accuracy: 98.6391%, Training Loss: 0.0440%\n",
      "Epoch [128/300], Step [94/225], Training Accuracy: 98.6536%, Training Loss: 0.0438%\n",
      "Epoch [128/300], Step [95/225], Training Accuracy: 98.6513%, Training Loss: 0.0438%\n",
      "Epoch [128/300], Step [96/225], Training Accuracy: 98.6491%, Training Loss: 0.0438%\n",
      "Epoch [128/300], Step [97/225], Training Accuracy: 98.6630%, Training Loss: 0.0436%\n",
      "Epoch [128/300], Step [98/225], Training Accuracy: 98.6607%, Training Loss: 0.0439%\n",
      "Epoch [128/300], Step [99/225], Training Accuracy: 98.6742%, Training Loss: 0.0437%\n",
      "Epoch [128/300], Step [100/225], Training Accuracy: 98.6719%, Training Loss: 0.0439%\n",
      "Epoch [128/300], Step [101/225], Training Accuracy: 98.6850%, Training Loss: 0.0437%\n",
      "Epoch [128/300], Step [102/225], Training Accuracy: 98.6979%, Training Loss: 0.0435%\n",
      "Epoch [128/300], Step [103/225], Training Accuracy: 98.7106%, Training Loss: 0.0432%\n",
      "Epoch [128/300], Step [104/225], Training Accuracy: 98.7079%, Training Loss: 0.0433%\n",
      "Epoch [128/300], Step [105/225], Training Accuracy: 98.7054%, Training Loss: 0.0432%\n",
      "Epoch [128/300], Step [106/225], Training Accuracy: 98.6733%, Training Loss: 0.0438%\n",
      "Epoch [128/300], Step [107/225], Training Accuracy: 98.6857%, Training Loss: 0.0436%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [128/300], Step [108/225], Training Accuracy: 98.6979%, Training Loss: 0.0435%\n",
      "Epoch [128/300], Step [109/225], Training Accuracy: 98.6812%, Training Loss: 0.0436%\n",
      "Epoch [128/300], Step [110/225], Training Accuracy: 98.6932%, Training Loss: 0.0434%\n",
      "Epoch [128/300], Step [111/225], Training Accuracy: 98.6909%, Training Loss: 0.0435%\n",
      "Epoch [128/300], Step [112/225], Training Accuracy: 98.6886%, Training Loss: 0.0437%\n",
      "Epoch [128/300], Step [113/225], Training Accuracy: 98.6864%, Training Loss: 0.0439%\n",
      "Epoch [128/300], Step [114/225], Training Accuracy: 98.6842%, Training Loss: 0.0440%\n",
      "Epoch [128/300], Step [115/225], Training Accuracy: 98.6957%, Training Loss: 0.0440%\n",
      "Epoch [128/300], Step [116/225], Training Accuracy: 98.7069%, Training Loss: 0.0439%\n",
      "Epoch [128/300], Step [117/225], Training Accuracy: 98.7179%, Training Loss: 0.0437%\n",
      "Epoch [128/300], Step [118/225], Training Accuracy: 98.7156%, Training Loss: 0.0438%\n",
      "Epoch [128/300], Step [119/225], Training Accuracy: 98.7132%, Training Loss: 0.0439%\n",
      "Epoch [128/300], Step [120/225], Training Accuracy: 98.7109%, Training Loss: 0.0439%\n",
      "Epoch [128/300], Step [121/225], Training Accuracy: 98.7216%, Training Loss: 0.0438%\n",
      "Epoch [128/300], Step [122/225], Training Accuracy: 98.7321%, Training Loss: 0.0436%\n",
      "Epoch [128/300], Step [123/225], Training Accuracy: 98.7424%, Training Loss: 0.0434%\n",
      "Epoch [128/300], Step [124/225], Training Accuracy: 98.7399%, Training Loss: 0.0435%\n",
      "Epoch [128/300], Step [125/225], Training Accuracy: 98.7375%, Training Loss: 0.0437%\n",
      "Epoch [128/300], Step [126/225], Training Accuracy: 98.7475%, Training Loss: 0.0435%\n",
      "Epoch [128/300], Step [127/225], Training Accuracy: 98.7451%, Training Loss: 0.0437%\n",
      "Epoch [128/300], Step [128/225], Training Accuracy: 98.7549%, Training Loss: 0.0434%\n",
      "Epoch [128/300], Step [129/225], Training Accuracy: 98.7645%, Training Loss: 0.0432%\n",
      "Epoch [128/300], Step [130/225], Training Accuracy: 98.7380%, Training Loss: 0.0436%\n",
      "Epoch [128/300], Step [131/225], Training Accuracy: 98.7476%, Training Loss: 0.0433%\n",
      "Epoch [128/300], Step [132/225], Training Accuracy: 98.7571%, Training Loss: 0.0430%\n",
      "Epoch [128/300], Step [133/225], Training Accuracy: 98.7547%, Training Loss: 0.0430%\n",
      "Epoch [128/300], Step [134/225], Training Accuracy: 98.7640%, Training Loss: 0.0428%\n",
      "Epoch [128/300], Step [135/225], Training Accuracy: 98.7616%, Training Loss: 0.0428%\n",
      "Epoch [128/300], Step [136/225], Training Accuracy: 98.7707%, Training Loss: 0.0427%\n",
      "Epoch [128/300], Step [137/225], Training Accuracy: 98.7568%, Training Loss: 0.0429%\n",
      "Epoch [128/300], Step [138/225], Training Accuracy: 98.7659%, Training Loss: 0.0428%\n",
      "Epoch [128/300], Step [139/225], Training Accuracy: 98.7410%, Training Loss: 0.0431%\n",
      "Epoch [128/300], Step [140/225], Training Accuracy: 98.7388%, Training Loss: 0.0431%\n",
      "Epoch [128/300], Step [141/225], Training Accuracy: 98.7367%, Training Loss: 0.0431%\n",
      "Epoch [128/300], Step [142/225], Training Accuracy: 98.7456%, Training Loss: 0.0431%\n",
      "Epoch [128/300], Step [143/225], Training Accuracy: 98.7325%, Training Loss: 0.0435%\n",
      "Epoch [128/300], Step [144/225], Training Accuracy: 98.7413%, Training Loss: 0.0434%\n",
      "Epoch [128/300], Step [145/225], Training Accuracy: 98.7500%, Training Loss: 0.0432%\n",
      "Epoch [128/300], Step [146/225], Training Accuracy: 98.7265%, Training Loss: 0.0434%\n",
      "Epoch [128/300], Step [147/225], Training Accuracy: 98.7139%, Training Loss: 0.0433%\n",
      "Epoch [128/300], Step [148/225], Training Accuracy: 98.7014%, Training Loss: 0.0435%\n",
      "Epoch [128/300], Step [149/225], Training Accuracy: 98.6892%, Training Loss: 0.0438%\n",
      "Epoch [128/300], Step [150/225], Training Accuracy: 98.6979%, Training Loss: 0.0437%\n",
      "Epoch [128/300], Step [151/225], Training Accuracy: 98.6962%, Training Loss: 0.0436%\n",
      "Epoch [128/300], Step [152/225], Training Accuracy: 98.7048%, Training Loss: 0.0435%\n",
      "Epoch [128/300], Step [153/225], Training Accuracy: 98.7030%, Training Loss: 0.0434%\n",
      "Epoch [128/300], Step [154/225], Training Accuracy: 98.7114%, Training Loss: 0.0433%\n",
      "Epoch [128/300], Step [155/225], Training Accuracy: 98.7198%, Training Loss: 0.0432%\n",
      "Epoch [128/300], Step [156/225], Training Accuracy: 98.7280%, Training Loss: 0.0430%\n",
      "Epoch [128/300], Step [157/225], Training Accuracy: 98.7162%, Training Loss: 0.0431%\n",
      "Epoch [128/300], Step [158/225], Training Accuracy: 98.7243%, Training Loss: 0.0430%\n",
      "Epoch [128/300], Step [159/225], Training Accuracy: 98.7225%, Training Loss: 0.0431%\n",
      "Epoch [128/300], Step [160/225], Training Accuracy: 98.7207%, Training Loss: 0.0431%\n",
      "Epoch [128/300], Step [161/225], Training Accuracy: 98.7286%, Training Loss: 0.0429%\n",
      "Epoch [128/300], Step [162/225], Training Accuracy: 98.7172%, Training Loss: 0.0432%\n",
      "Epoch [128/300], Step [163/225], Training Accuracy: 98.7251%, Training Loss: 0.0431%\n",
      "Epoch [128/300], Step [164/225], Training Accuracy: 98.7233%, Training Loss: 0.0431%\n",
      "Epoch [128/300], Step [165/225], Training Accuracy: 98.7216%, Training Loss: 0.0431%\n",
      "Epoch [128/300], Step [166/225], Training Accuracy: 98.7105%, Training Loss: 0.0432%\n",
      "Epoch [128/300], Step [167/225], Training Accuracy: 98.6901%, Training Loss: 0.0436%\n",
      "Epoch [128/300], Step [168/225], Training Accuracy: 98.6886%, Training Loss: 0.0436%\n",
      "Epoch [128/300], Step [169/225], Training Accuracy: 98.6871%, Training Loss: 0.0436%\n",
      "Epoch [128/300], Step [170/225], Training Accuracy: 98.6857%, Training Loss: 0.0436%\n",
      "Epoch [128/300], Step [171/225], Training Accuracy: 98.6933%, Training Loss: 0.0435%\n",
      "Epoch [128/300], Step [172/225], Training Accuracy: 98.6828%, Training Loss: 0.0435%\n",
      "Epoch [128/300], Step [173/225], Training Accuracy: 98.6814%, Training Loss: 0.0435%\n",
      "Epoch [128/300], Step [174/225], Training Accuracy: 98.6710%, Training Loss: 0.0435%\n",
      "Epoch [128/300], Step [175/225], Training Accuracy: 98.6607%, Training Loss: 0.0435%\n",
      "Epoch [128/300], Step [176/225], Training Accuracy: 98.6506%, Training Loss: 0.0436%\n",
      "Epoch [128/300], Step [177/225], Training Accuracy: 98.6582%, Training Loss: 0.0435%\n",
      "Epoch [128/300], Step [178/225], Training Accuracy: 98.6657%, Training Loss: 0.0434%\n",
      "Epoch [128/300], Step [179/225], Training Accuracy: 98.6732%, Training Loss: 0.0433%\n",
      "Epoch [128/300], Step [180/225], Training Accuracy: 98.6719%, Training Loss: 0.0434%\n",
      "Epoch [128/300], Step [181/225], Training Accuracy: 98.6706%, Training Loss: 0.0433%\n",
      "Epoch [128/300], Step [182/225], Training Accuracy: 98.6693%, Training Loss: 0.0433%\n",
      "Epoch [128/300], Step [183/225], Training Accuracy: 98.6595%, Training Loss: 0.0438%\n",
      "Epoch [128/300], Step [184/225], Training Accuracy: 98.6583%, Training Loss: 0.0438%\n",
      "Epoch [128/300], Step [185/225], Training Accuracy: 98.6655%, Training Loss: 0.0437%\n",
      "Epoch [128/300], Step [186/225], Training Accuracy: 98.6643%, Training Loss: 0.0437%\n",
      "Epoch [128/300], Step [187/225], Training Accuracy: 98.6715%, Training Loss: 0.0436%\n",
      "Epoch [128/300], Step [188/225], Training Accuracy: 98.6785%, Training Loss: 0.0435%\n",
      "Epoch [128/300], Step [189/225], Training Accuracy: 98.6855%, Training Loss: 0.0435%\n",
      "Epoch [128/300], Step [190/225], Training Accuracy: 98.6842%, Training Loss: 0.0435%\n",
      "Epoch [128/300], Step [191/225], Training Accuracy: 98.6829%, Training Loss: 0.0434%\n",
      "Epoch [128/300], Step [192/225], Training Accuracy: 98.6816%, Training Loss: 0.0434%\n",
      "Epoch [128/300], Step [193/225], Training Accuracy: 98.6723%, Training Loss: 0.0435%\n",
      "Epoch [128/300], Step [194/225], Training Accuracy: 98.6711%, Training Loss: 0.0435%\n",
      "Epoch [128/300], Step [195/225], Training Accuracy: 98.6699%, Training Loss: 0.0435%\n",
      "Epoch [128/300], Step [196/225], Training Accuracy: 98.6687%, Training Loss: 0.0435%\n",
      "Epoch [128/300], Step [197/225], Training Accuracy: 98.6675%, Training Loss: 0.0435%\n",
      "Epoch [128/300], Step [198/225], Training Accuracy: 98.6664%, Training Loss: 0.0435%\n",
      "Epoch [128/300], Step [199/225], Training Accuracy: 98.6573%, Training Loss: 0.0438%\n",
      "Epoch [128/300], Step [200/225], Training Accuracy: 98.6484%, Training Loss: 0.0440%\n",
      "Epoch [128/300], Step [201/225], Training Accuracy: 98.6474%, Training Loss: 0.0439%\n",
      "Epoch [128/300], Step [202/225], Training Accuracy: 98.6386%, Training Loss: 0.0439%\n",
      "Epoch [128/300], Step [203/225], Training Accuracy: 98.6376%, Training Loss: 0.0439%\n",
      "Epoch [128/300], Step [204/225], Training Accuracy: 98.6443%, Training Loss: 0.0438%\n",
      "Epoch [128/300], Step [205/225], Training Accuracy: 98.6433%, Training Loss: 0.0438%\n",
      "Epoch [128/300], Step [206/225], Training Accuracy: 98.6423%, Training Loss: 0.0438%\n",
      "Epoch [128/300], Step [207/225], Training Accuracy: 98.6338%, Training Loss: 0.0438%\n",
      "Epoch [128/300], Step [208/225], Training Accuracy: 98.6403%, Training Loss: 0.0436%\n",
      "Epoch [128/300], Step [209/225], Training Accuracy: 98.6468%, Training Loss: 0.0436%\n",
      "Epoch [128/300], Step [210/225], Training Accuracy: 98.6384%, Training Loss: 0.0437%\n",
      "Epoch [128/300], Step [211/225], Training Accuracy: 98.6448%, Training Loss: 0.0436%\n",
      "Epoch [128/300], Step [212/225], Training Accuracy: 98.6365%, Training Loss: 0.0437%\n",
      "Epoch [128/300], Step [213/225], Training Accuracy: 98.6429%, Training Loss: 0.0436%\n",
      "Epoch [128/300], Step [214/225], Training Accuracy: 98.6419%, Training Loss: 0.0436%\n",
      "Epoch [128/300], Step [215/225], Training Accuracy: 98.6410%, Training Loss: 0.0436%\n",
      "Epoch [128/300], Step [216/225], Training Accuracy: 98.6328%, Training Loss: 0.0439%\n",
      "Epoch [128/300], Step [217/225], Training Accuracy: 98.6175%, Training Loss: 0.0440%\n",
      "Epoch [128/300], Step [218/225], Training Accuracy: 98.6239%, Training Loss: 0.0440%\n",
      "Epoch [128/300], Step [219/225], Training Accuracy: 98.6301%, Training Loss: 0.0440%\n",
      "Epoch [128/300], Step [220/225], Training Accuracy: 98.6293%, Training Loss: 0.0440%\n",
      "Epoch [128/300], Step [221/225], Training Accuracy: 98.6284%, Training Loss: 0.0440%\n",
      "Epoch [128/300], Step [222/225], Training Accuracy: 98.6205%, Training Loss: 0.0440%\n",
      "Epoch [128/300], Step [223/225], Training Accuracy: 98.6197%, Training Loss: 0.0440%\n",
      "Epoch [128/300], Step [224/225], Training Accuracy: 98.6189%, Training Loss: 0.0441%\n",
      "Epoch [128/300], Step [225/225], Training Accuracy: 98.6242%, Training Loss: 0.0439%\n",
      "Epoch [129/300], Step [1/225], Training Accuracy: 98.4375%, Training Loss: 0.0463%\n",
      "Epoch [129/300], Step [2/225], Training Accuracy: 98.4375%, Training Loss: 0.0436%\n",
      "Epoch [129/300], Step [3/225], Training Accuracy: 98.4375%, Training Loss: 0.0458%\n",
      "Epoch [129/300], Step [4/225], Training Accuracy: 98.8281%, Training Loss: 0.0405%\n",
      "Epoch [129/300], Step [5/225], Training Accuracy: 98.7500%, Training Loss: 0.0408%\n",
      "Epoch [129/300], Step [6/225], Training Accuracy: 98.6979%, Training Loss: 0.0455%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [129/300], Step [7/225], Training Accuracy: 98.4375%, Training Loss: 0.0438%\n",
      "Epoch [129/300], Step [8/225], Training Accuracy: 98.2422%, Training Loss: 0.0446%\n",
      "Epoch [129/300], Step [9/225], Training Accuracy: 98.2639%, Training Loss: 0.0427%\n",
      "Epoch [129/300], Step [10/225], Training Accuracy: 98.4375%, Training Loss: 0.0398%\n",
      "Epoch [129/300], Step [11/225], Training Accuracy: 98.5795%, Training Loss: 0.0373%\n",
      "Epoch [129/300], Step [12/225], Training Accuracy: 98.5677%, Training Loss: 0.0367%\n",
      "Epoch [129/300], Step [13/225], Training Accuracy: 98.4375%, Training Loss: 0.0387%\n",
      "Epoch [129/300], Step [14/225], Training Accuracy: 98.4375%, Training Loss: 0.0389%\n",
      "Epoch [129/300], Step [15/225], Training Accuracy: 98.5417%, Training Loss: 0.0374%\n",
      "Epoch [129/300], Step [16/225], Training Accuracy: 98.6328%, Training Loss: 0.0364%\n",
      "Epoch [129/300], Step [17/225], Training Accuracy: 98.6213%, Training Loss: 0.0369%\n",
      "Epoch [129/300], Step [18/225], Training Accuracy: 98.6111%, Training Loss: 0.0380%\n",
      "Epoch [129/300], Step [19/225], Training Accuracy: 98.6842%, Training Loss: 0.0367%\n",
      "Epoch [129/300], Step [20/225], Training Accuracy: 98.7500%, Training Loss: 0.0361%\n",
      "Epoch [129/300], Step [21/225], Training Accuracy: 98.8095%, Training Loss: 0.0355%\n",
      "Epoch [129/300], Step [22/225], Training Accuracy: 98.7216%, Training Loss: 0.0368%\n",
      "Epoch [129/300], Step [23/225], Training Accuracy: 98.7092%, Training Loss: 0.0372%\n",
      "Epoch [129/300], Step [24/225], Training Accuracy: 98.6979%, Training Loss: 0.0371%\n",
      "Epoch [129/300], Step [25/225], Training Accuracy: 98.7500%, Training Loss: 0.0366%\n",
      "Epoch [129/300], Step [26/225], Training Accuracy: 98.7380%, Training Loss: 0.0367%\n",
      "Epoch [129/300], Step [27/225], Training Accuracy: 98.7847%, Training Loss: 0.0365%\n",
      "Epoch [129/300], Step [28/225], Training Accuracy: 98.8281%, Training Loss: 0.0363%\n",
      "Epoch [129/300], Step [29/225], Training Accuracy: 98.7608%, Training Loss: 0.0383%\n",
      "Epoch [129/300], Step [30/225], Training Accuracy: 98.6979%, Training Loss: 0.0383%\n",
      "Epoch [129/300], Step [31/225], Training Accuracy: 98.6895%, Training Loss: 0.0381%\n",
      "Epoch [129/300], Step [32/225], Training Accuracy: 98.7305%, Training Loss: 0.0376%\n",
      "Epoch [129/300], Step [33/225], Training Accuracy: 98.7689%, Training Loss: 0.0373%\n",
      "Epoch [129/300], Step [34/225], Training Accuracy: 98.8051%, Training Loss: 0.0368%\n",
      "Epoch [129/300], Step [35/225], Training Accuracy: 98.7946%, Training Loss: 0.0372%\n",
      "Epoch [129/300], Step [36/225], Training Accuracy: 98.8281%, Training Loss: 0.0371%\n",
      "Epoch [129/300], Step [37/225], Training Accuracy: 98.8176%, Training Loss: 0.0373%\n",
      "Epoch [129/300], Step [38/225], Training Accuracy: 98.7253%, Training Loss: 0.0389%\n",
      "Epoch [129/300], Step [39/225], Training Accuracy: 98.6779%, Training Loss: 0.0401%\n",
      "Epoch [129/300], Step [40/225], Training Accuracy: 98.6328%, Training Loss: 0.0406%\n",
      "Epoch [129/300], Step [41/225], Training Accuracy: 98.5899%, Training Loss: 0.0419%\n",
      "Epoch [129/300], Step [42/225], Training Accuracy: 98.5863%, Training Loss: 0.0417%\n",
      "Epoch [129/300], Step [43/225], Training Accuracy: 98.5465%, Training Loss: 0.0420%\n",
      "Epoch [129/300], Step [44/225], Training Accuracy: 98.5795%, Training Loss: 0.0414%\n",
      "Epoch [129/300], Step [45/225], Training Accuracy: 98.5764%, Training Loss: 0.0416%\n",
      "Epoch [129/300], Step [46/225], Training Accuracy: 98.6073%, Training Loss: 0.0414%\n",
      "Epoch [129/300], Step [47/225], Training Accuracy: 98.6037%, Training Loss: 0.0415%\n",
      "Epoch [129/300], Step [48/225], Training Accuracy: 98.6003%, Training Loss: 0.0418%\n",
      "Epoch [129/300], Step [49/225], Training Accuracy: 98.6288%, Training Loss: 0.0416%\n",
      "Epoch [129/300], Step [50/225], Training Accuracy: 98.6250%, Training Loss: 0.0425%\n",
      "Epoch [129/300], Step [51/225], Training Accuracy: 98.6520%, Training Loss: 0.0419%\n",
      "Epoch [129/300], Step [52/225], Training Accuracy: 98.6779%, Training Loss: 0.0413%\n",
      "Epoch [129/300], Step [53/225], Training Accuracy: 98.6733%, Training Loss: 0.0415%\n",
      "Epoch [129/300], Step [54/225], Training Accuracy: 98.6400%, Training Loss: 0.0425%\n",
      "Epoch [129/300], Step [55/225], Training Accuracy: 98.6364%, Training Loss: 0.0432%\n",
      "Epoch [129/300], Step [56/225], Training Accuracy: 98.6328%, Training Loss: 0.0437%\n",
      "Epoch [129/300], Step [57/225], Training Accuracy: 98.6294%, Training Loss: 0.0437%\n",
      "Epoch [129/300], Step [58/225], Training Accuracy: 98.6261%, Training Loss: 0.0449%\n",
      "Epoch [129/300], Step [59/225], Training Accuracy: 98.6229%, Training Loss: 0.0449%\n",
      "Epoch [129/300], Step [60/225], Training Accuracy: 98.6198%, Training Loss: 0.0451%\n",
      "Epoch [129/300], Step [61/225], Training Accuracy: 98.5656%, Training Loss: 0.0456%\n",
      "Epoch [129/300], Step [62/225], Training Accuracy: 98.5887%, Training Loss: 0.0453%\n",
      "Epoch [129/300], Step [63/225], Training Accuracy: 98.5863%, Training Loss: 0.0453%\n",
      "Epoch [129/300], Step [64/225], Training Accuracy: 98.5596%, Training Loss: 0.0455%\n",
      "Epoch [129/300], Step [65/225], Training Accuracy: 98.5577%, Training Loss: 0.0452%\n",
      "Epoch [129/300], Step [66/225], Training Accuracy: 98.5795%, Training Loss: 0.0451%\n",
      "Epoch [129/300], Step [67/225], Training Accuracy: 98.5541%, Training Loss: 0.0459%\n",
      "Epoch [129/300], Step [68/225], Training Accuracy: 98.5524%, Training Loss: 0.0460%\n",
      "Epoch [129/300], Step [69/225], Training Accuracy: 98.5507%, Training Loss: 0.0457%\n",
      "Epoch [129/300], Step [70/225], Training Accuracy: 98.5045%, Training Loss: 0.0462%\n",
      "Epoch [129/300], Step [71/225], Training Accuracy: 98.5255%, Training Loss: 0.0459%\n",
      "Epoch [129/300], Step [72/225], Training Accuracy: 98.5243%, Training Loss: 0.0459%\n",
      "Epoch [129/300], Step [73/225], Training Accuracy: 98.5231%, Training Loss: 0.0462%\n",
      "Epoch [129/300], Step [74/225], Training Accuracy: 98.5220%, Training Loss: 0.0462%\n",
      "Epoch [129/300], Step [75/225], Training Accuracy: 98.5208%, Training Loss: 0.0460%\n",
      "Epoch [129/300], Step [76/225], Training Accuracy: 98.4786%, Training Loss: 0.0471%\n",
      "Epoch [129/300], Step [77/225], Training Accuracy: 98.4578%, Training Loss: 0.0475%\n",
      "Epoch [129/300], Step [78/225], Training Accuracy: 98.4776%, Training Loss: 0.0473%\n",
      "Epoch [129/300], Step [79/225], Training Accuracy: 98.4771%, Training Loss: 0.0474%\n",
      "Epoch [129/300], Step [80/225], Training Accuracy: 98.4766%, Training Loss: 0.0472%\n",
      "Epoch [129/300], Step [81/225], Training Accuracy: 98.4761%, Training Loss: 0.0471%\n",
      "Epoch [129/300], Step [82/225], Training Accuracy: 98.4756%, Training Loss: 0.0470%\n",
      "Epoch [129/300], Step [83/225], Training Accuracy: 98.4375%, Training Loss: 0.0478%\n",
      "Epoch [129/300], Step [84/225], Training Accuracy: 98.4189%, Training Loss: 0.0480%\n",
      "Epoch [129/300], Step [85/225], Training Accuracy: 98.4007%, Training Loss: 0.0482%\n",
      "Epoch [129/300], Step [86/225], Training Accuracy: 98.4012%, Training Loss: 0.0483%\n",
      "Epoch [129/300], Step [87/225], Training Accuracy: 98.3836%, Training Loss: 0.0485%\n",
      "Epoch [129/300], Step [88/225], Training Accuracy: 98.3665%, Training Loss: 0.0492%\n",
      "Epoch [129/300], Step [89/225], Training Accuracy: 98.3322%, Training Loss: 0.0497%\n",
      "Epoch [129/300], Step [90/225], Training Accuracy: 98.3507%, Training Loss: 0.0495%\n",
      "Epoch [129/300], Step [91/225], Training Accuracy: 98.3173%, Training Loss: 0.0515%\n",
      "Epoch [129/300], Step [92/225], Training Accuracy: 98.3186%, Training Loss: 0.0517%\n",
      "Epoch [129/300], Step [93/225], Training Accuracy: 98.3199%, Training Loss: 0.0514%\n",
      "Epoch [129/300], Step [94/225], Training Accuracy: 98.3045%, Training Loss: 0.0515%\n",
      "Epoch [129/300], Step [95/225], Training Accuracy: 98.3059%, Training Loss: 0.0514%\n",
      "Epoch [129/300], Step [96/225], Training Accuracy: 98.3236%, Training Loss: 0.0511%\n",
      "Epoch [129/300], Step [97/225], Training Accuracy: 98.3247%, Training Loss: 0.0512%\n",
      "Epoch [129/300], Step [98/225], Training Accuracy: 98.2940%, Training Loss: 0.0515%\n",
      "Epoch [129/300], Step [99/225], Training Accuracy: 98.2797%, Training Loss: 0.0517%\n",
      "Epoch [129/300], Step [100/225], Training Accuracy: 98.2812%, Training Loss: 0.0515%\n",
      "Epoch [129/300], Step [101/225], Training Accuracy: 98.2828%, Training Loss: 0.0516%\n",
      "Epoch [129/300], Step [102/225], Training Accuracy: 98.2996%, Training Loss: 0.0513%\n",
      "Epoch [129/300], Step [103/225], Training Accuracy: 98.2858%, Training Loss: 0.0512%\n",
      "Epoch [129/300], Step [104/225], Training Accuracy: 98.3023%, Training Loss: 0.0508%\n",
      "Epoch [129/300], Step [105/225], Training Accuracy: 98.3036%, Training Loss: 0.0507%\n",
      "Epoch [129/300], Step [106/225], Training Accuracy: 98.3048%, Training Loss: 0.0508%\n",
      "Epoch [129/300], Step [107/225], Training Accuracy: 98.3061%, Training Loss: 0.0508%\n",
      "Epoch [129/300], Step [108/225], Training Accuracy: 98.3073%, Training Loss: 0.0508%\n",
      "Epoch [129/300], Step [109/225], Training Accuracy: 98.3228%, Training Loss: 0.0507%\n",
      "Epoch [129/300], Step [110/225], Training Accuracy: 98.3239%, Training Loss: 0.0508%\n",
      "Epoch [129/300], Step [111/225], Training Accuracy: 98.3249%, Training Loss: 0.0506%\n",
      "Epoch [129/300], Step [112/225], Training Accuracy: 98.3259%, Training Loss: 0.0506%\n",
      "Epoch [129/300], Step [113/225], Training Accuracy: 98.3407%, Training Loss: 0.0503%\n",
      "Epoch [129/300], Step [114/225], Training Accuracy: 98.3553%, Training Loss: 0.0501%\n",
      "Epoch [129/300], Step [115/225], Training Accuracy: 98.3288%, Training Loss: 0.0505%\n",
      "Epoch [129/300], Step [116/225], Training Accuracy: 98.2893%, Training Loss: 0.0512%\n",
      "Epoch [129/300], Step [117/225], Training Accuracy: 98.3040%, Training Loss: 0.0509%\n",
      "Epoch [129/300], Step [118/225], Training Accuracy: 98.3183%, Training Loss: 0.0508%\n",
      "Epoch [129/300], Step [119/225], Training Accuracy: 98.3062%, Training Loss: 0.0507%\n",
      "Epoch [129/300], Step [120/225], Training Accuracy: 98.2812%, Training Loss: 0.0514%\n",
      "Epoch [129/300], Step [121/225], Training Accuracy: 98.2955%, Training Loss: 0.0511%\n",
      "Epoch [129/300], Step [122/225], Training Accuracy: 98.2966%, Training Loss: 0.0511%\n",
      "Epoch [129/300], Step [123/225], Training Accuracy: 98.3105%, Training Loss: 0.0509%\n",
      "Epoch [129/300], Step [124/225], Training Accuracy: 98.3241%, Training Loss: 0.0507%\n",
      "Epoch [129/300], Step [125/225], Training Accuracy: 98.3250%, Training Loss: 0.0507%\n",
      "Epoch [129/300], Step [126/225], Training Accuracy: 98.3383%, Training Loss: 0.0507%\n",
      "Epoch [129/300], Step [127/225], Training Accuracy: 98.3514%, Training Loss: 0.0504%\n",
      "Epoch [129/300], Step [128/225], Training Accuracy: 98.3521%, Training Loss: 0.0504%\n",
      "Epoch [129/300], Step [129/225], Training Accuracy: 98.3527%, Training Loss: 0.0504%\n",
      "Epoch [129/300], Step [130/225], Training Accuracy: 98.3654%, Training Loss: 0.0502%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [129/300], Step [131/225], Training Accuracy: 98.3779%, Training Loss: 0.0500%\n",
      "Epoch [129/300], Step [132/225], Training Accuracy: 98.3546%, Training Loss: 0.0502%\n",
      "Epoch [129/300], Step [133/225], Training Accuracy: 98.3670%, Training Loss: 0.0501%\n",
      "Epoch [129/300], Step [134/225], Training Accuracy: 98.3792%, Training Loss: 0.0499%\n",
      "Epoch [129/300], Step [135/225], Training Accuracy: 98.3912%, Training Loss: 0.0497%\n",
      "Epoch [129/300], Step [136/225], Training Accuracy: 98.3915%, Training Loss: 0.0497%\n",
      "Epoch [129/300], Step [137/225], Training Accuracy: 98.3691%, Training Loss: 0.0499%\n",
      "Epoch [129/300], Step [138/225], Training Accuracy: 98.3582%, Training Loss: 0.0499%\n",
      "Epoch [129/300], Step [139/225], Training Accuracy: 98.3476%, Training Loss: 0.0506%\n",
      "Epoch [129/300], Step [140/225], Training Accuracy: 98.3594%, Training Loss: 0.0504%\n",
      "Epoch [129/300], Step [141/225], Training Accuracy: 98.3710%, Training Loss: 0.0502%\n",
      "Epoch [129/300], Step [142/225], Training Accuracy: 98.3825%, Training Loss: 0.0500%\n",
      "Epoch [129/300], Step [143/225], Training Accuracy: 98.3392%, Training Loss: 0.0504%\n",
      "Epoch [129/300], Step [144/225], Training Accuracy: 98.3398%, Training Loss: 0.0505%\n",
      "Epoch [129/300], Step [145/225], Training Accuracy: 98.3513%, Training Loss: 0.0502%\n",
      "Epoch [129/300], Step [146/225], Training Accuracy: 98.3626%, Training Loss: 0.0500%\n",
      "Epoch [129/300], Step [147/225], Training Accuracy: 98.3737%, Training Loss: 0.0498%\n",
      "Epoch [129/300], Step [148/225], Training Accuracy: 98.3742%, Training Loss: 0.0497%\n",
      "Epoch [129/300], Step [149/225], Training Accuracy: 98.3746%, Training Loss: 0.0496%\n",
      "Epoch [129/300], Step [150/225], Training Accuracy: 98.3646%, Training Loss: 0.0496%\n",
      "Epoch [129/300], Step [151/225], Training Accuracy: 98.3754%, Training Loss: 0.0494%\n",
      "Epoch [129/300], Step [152/225], Training Accuracy: 98.3758%, Training Loss: 0.0495%\n",
      "Epoch [129/300], Step [153/225], Training Accuracy: 98.3864%, Training Loss: 0.0494%\n",
      "Epoch [129/300], Step [154/225], Training Accuracy: 98.3868%, Training Loss: 0.0493%\n",
      "Epoch [129/300], Step [155/225], Training Accuracy: 98.3770%, Training Loss: 0.0495%\n",
      "Epoch [129/300], Step [156/225], Training Accuracy: 98.3774%, Training Loss: 0.0494%\n",
      "Epoch [129/300], Step [157/225], Training Accuracy: 98.3778%, Training Loss: 0.0495%\n",
      "Epoch [129/300], Step [158/225], Training Accuracy: 98.3881%, Training Loss: 0.0493%\n",
      "Epoch [129/300], Step [159/225], Training Accuracy: 98.3982%, Training Loss: 0.0493%\n",
      "Epoch [129/300], Step [160/225], Training Accuracy: 98.3984%, Training Loss: 0.0492%\n",
      "Epoch [129/300], Step [161/225], Training Accuracy: 98.4084%, Training Loss: 0.0491%\n",
      "Epoch [129/300], Step [162/225], Training Accuracy: 98.4086%, Training Loss: 0.0491%\n",
      "Epoch [129/300], Step [163/225], Training Accuracy: 98.4183%, Training Loss: 0.0490%\n",
      "Epoch [129/300], Step [164/225], Training Accuracy: 98.3994%, Training Loss: 0.0494%\n",
      "Epoch [129/300], Step [165/225], Training Accuracy: 98.4091%, Training Loss: 0.0493%\n",
      "Epoch [129/300], Step [166/225], Training Accuracy: 98.3904%, Training Loss: 0.0494%\n",
      "Epoch [129/300], Step [167/225], Training Accuracy: 98.3907%, Training Loss: 0.0494%\n",
      "Epoch [129/300], Step [168/225], Training Accuracy: 98.4003%, Training Loss: 0.0492%\n",
      "Epoch [129/300], Step [169/225], Training Accuracy: 98.4098%, Training Loss: 0.0490%\n",
      "Epoch [129/300], Step [170/225], Training Accuracy: 98.4099%, Training Loss: 0.0490%\n",
      "Epoch [129/300], Step [171/225], Training Accuracy: 98.4192%, Training Loss: 0.0489%\n",
      "Epoch [129/300], Step [172/225], Training Accuracy: 98.4102%, Training Loss: 0.0490%\n",
      "Epoch [129/300], Step [173/225], Training Accuracy: 98.4194%, Training Loss: 0.0489%\n",
      "Epoch [129/300], Step [174/225], Training Accuracy: 98.4195%, Training Loss: 0.0490%\n",
      "Epoch [129/300], Step [175/225], Training Accuracy: 98.4107%, Training Loss: 0.0490%\n",
      "Epoch [129/300], Step [176/225], Training Accuracy: 98.4020%, Training Loss: 0.0491%\n",
      "Epoch [129/300], Step [177/225], Training Accuracy: 98.4022%, Training Loss: 0.0491%\n",
      "Epoch [129/300], Step [178/225], Training Accuracy: 98.4112%, Training Loss: 0.0490%\n",
      "Epoch [129/300], Step [179/225], Training Accuracy: 98.4200%, Training Loss: 0.0488%\n",
      "Epoch [129/300], Step [180/225], Training Accuracy: 98.4201%, Training Loss: 0.0488%\n",
      "Epoch [129/300], Step [181/225], Training Accuracy: 98.4289%, Training Loss: 0.0488%\n",
      "Epoch [129/300], Step [182/225], Training Accuracy: 98.4375%, Training Loss: 0.0487%\n",
      "Epoch [129/300], Step [183/225], Training Accuracy: 98.4460%, Training Loss: 0.0485%\n",
      "Epoch [129/300], Step [184/225], Training Accuracy: 98.4545%, Training Loss: 0.0484%\n",
      "Epoch [129/300], Step [185/225], Training Accuracy: 98.4459%, Training Loss: 0.0486%\n",
      "Epoch [129/300], Step [186/225], Training Accuracy: 98.4459%, Training Loss: 0.0486%\n",
      "Epoch [129/300], Step [187/225], Training Accuracy: 98.4542%, Training Loss: 0.0485%\n",
      "Epoch [129/300], Step [188/225], Training Accuracy: 98.4624%, Training Loss: 0.0484%\n",
      "Epoch [129/300], Step [189/225], Training Accuracy: 98.4706%, Training Loss: 0.0483%\n",
      "Epoch [129/300], Step [190/225], Training Accuracy: 98.4786%, Training Loss: 0.0481%\n",
      "Epoch [129/300], Step [191/225], Training Accuracy: 98.4866%, Training Loss: 0.0480%\n",
      "Epoch [129/300], Step [192/225], Training Accuracy: 98.4863%, Training Loss: 0.0480%\n",
      "Epoch [129/300], Step [193/225], Training Accuracy: 98.4942%, Training Loss: 0.0478%\n",
      "Epoch [129/300], Step [194/225], Training Accuracy: 98.4858%, Training Loss: 0.0478%\n",
      "Epoch [129/300], Step [195/225], Training Accuracy: 98.4936%, Training Loss: 0.0477%\n",
      "Epoch [129/300], Step [196/225], Training Accuracy: 98.4774%, Training Loss: 0.0478%\n",
      "Epoch [129/300], Step [197/225], Training Accuracy: 98.4772%, Training Loss: 0.0477%\n",
      "Epoch [129/300], Step [198/225], Training Accuracy: 98.4691%, Training Loss: 0.0478%\n",
      "Epoch [129/300], Step [199/225], Training Accuracy: 98.4689%, Training Loss: 0.0477%\n",
      "Epoch [129/300], Step [200/225], Training Accuracy: 98.4766%, Training Loss: 0.0476%\n",
      "Epoch [129/300], Step [201/225], Training Accuracy: 98.4841%, Training Loss: 0.0475%\n",
      "Epoch [129/300], Step [202/225], Training Accuracy: 98.4916%, Training Loss: 0.0474%\n",
      "Epoch [129/300], Step [203/225], Training Accuracy: 98.4914%, Training Loss: 0.0473%\n",
      "Epoch [129/300], Step [204/225], Training Accuracy: 98.4911%, Training Loss: 0.0474%\n",
      "Epoch [129/300], Step [205/225], Training Accuracy: 98.4909%, Training Loss: 0.0475%\n",
      "Epoch [129/300], Step [206/225], Training Accuracy: 98.4982%, Training Loss: 0.0474%\n",
      "Epoch [129/300], Step [207/225], Training Accuracy: 98.5054%, Training Loss: 0.0472%\n",
      "Epoch [129/300], Step [208/225], Training Accuracy: 98.5126%, Training Loss: 0.0472%\n",
      "Epoch [129/300], Step [209/225], Training Accuracy: 98.5197%, Training Loss: 0.0470%\n",
      "Epoch [129/300], Step [210/225], Training Accuracy: 98.5119%, Training Loss: 0.0472%\n",
      "Epoch [129/300], Step [211/225], Training Accuracy: 98.5116%, Training Loss: 0.0475%\n",
      "Epoch [129/300], Step [212/225], Training Accuracy: 98.5112%, Training Loss: 0.0477%\n",
      "Epoch [129/300], Step [213/225], Training Accuracy: 98.5182%, Training Loss: 0.0475%\n",
      "Epoch [129/300], Step [214/225], Training Accuracy: 98.5251%, Training Loss: 0.0474%\n",
      "Epoch [129/300], Step [215/225], Training Accuracy: 98.5174%, Training Loss: 0.0475%\n",
      "Epoch [129/300], Step [216/225], Training Accuracy: 98.5098%, Training Loss: 0.0476%\n",
      "Epoch [129/300], Step [217/225], Training Accuracy: 98.5095%, Training Loss: 0.0478%\n",
      "Epoch [129/300], Step [218/225], Training Accuracy: 98.5163%, Training Loss: 0.0477%\n",
      "Epoch [129/300], Step [219/225], Training Accuracy: 98.5231%, Training Loss: 0.0477%\n",
      "Epoch [129/300], Step [220/225], Training Accuracy: 98.5227%, Training Loss: 0.0477%\n",
      "Epoch [129/300], Step [221/225], Training Accuracy: 98.5294%, Training Loss: 0.0477%\n",
      "Epoch [129/300], Step [222/225], Training Accuracy: 98.5360%, Training Loss: 0.0476%\n",
      "Epoch [129/300], Step [223/225], Training Accuracy: 98.5356%, Training Loss: 0.0476%\n",
      "Epoch [129/300], Step [224/225], Training Accuracy: 98.5421%, Training Loss: 0.0475%\n",
      "Epoch [129/300], Step [225/225], Training Accuracy: 98.5339%, Training Loss: 0.0475%\n",
      "Epoch [130/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0235%\n",
      "Epoch [130/300], Step [2/225], Training Accuracy: 99.2188%, Training Loss: 0.0551%\n",
      "Epoch [130/300], Step [3/225], Training Accuracy: 99.4792%, Training Loss: 0.0446%\n",
      "Epoch [130/300], Step [4/225], Training Accuracy: 99.6094%, Training Loss: 0.0369%\n",
      "Epoch [130/300], Step [5/225], Training Accuracy: 99.6875%, Training Loss: 0.0326%\n",
      "Epoch [130/300], Step [6/225], Training Accuracy: 99.4792%, Training Loss: 0.0343%\n",
      "Epoch [130/300], Step [7/225], Training Accuracy: 99.5536%, Training Loss: 0.0335%\n",
      "Epoch [130/300], Step [8/225], Training Accuracy: 99.6094%, Training Loss: 0.0321%\n",
      "Epoch [130/300], Step [9/225], Training Accuracy: 99.6528%, Training Loss: 0.0311%\n",
      "Epoch [130/300], Step [10/225], Training Accuracy: 99.5312%, Training Loss: 0.0312%\n",
      "Epoch [130/300], Step [11/225], Training Accuracy: 99.4318%, Training Loss: 0.0321%\n",
      "Epoch [130/300], Step [12/225], Training Accuracy: 99.2188%, Training Loss: 0.0347%\n",
      "Epoch [130/300], Step [13/225], Training Accuracy: 99.2788%, Training Loss: 0.0342%\n",
      "Epoch [130/300], Step [14/225], Training Accuracy: 99.2188%, Training Loss: 0.0346%\n",
      "Epoch [130/300], Step [15/225], Training Accuracy: 99.0625%, Training Loss: 0.0356%\n",
      "Epoch [130/300], Step [16/225], Training Accuracy: 98.8281%, Training Loss: 0.0412%\n",
      "Epoch [130/300], Step [17/225], Training Accuracy: 98.8051%, Training Loss: 0.0429%\n",
      "Epoch [130/300], Step [18/225], Training Accuracy: 98.7847%, Training Loss: 0.0445%\n",
      "Epoch [130/300], Step [19/225], Training Accuracy: 98.8487%, Training Loss: 0.0436%\n",
      "Epoch [130/300], Step [20/225], Training Accuracy: 98.8281%, Training Loss: 0.0437%\n",
      "Epoch [130/300], Step [21/225], Training Accuracy: 98.8839%, Training Loss: 0.0431%\n",
      "Epoch [130/300], Step [22/225], Training Accuracy: 98.8636%, Training Loss: 0.0423%\n",
      "Epoch [130/300], Step [23/225], Training Accuracy: 98.8451%, Training Loss: 0.0419%\n",
      "Epoch [130/300], Step [24/225], Training Accuracy: 98.8932%, Training Loss: 0.0420%\n",
      "Epoch [130/300], Step [25/225], Training Accuracy: 98.9375%, Training Loss: 0.0409%\n",
      "Epoch [130/300], Step [26/225], Training Accuracy: 98.9784%, Training Loss: 0.0406%\n",
      "Epoch [130/300], Step [27/225], Training Accuracy: 99.0162%, Training Loss: 0.0398%\n",
      "Epoch [130/300], Step [28/225], Training Accuracy: 98.9955%, Training Loss: 0.0407%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [130/300], Step [29/225], Training Accuracy: 98.9763%, Training Loss: 0.0407%\n",
      "Epoch [130/300], Step [30/225], Training Accuracy: 98.9062%, Training Loss: 0.0413%\n",
      "Epoch [130/300], Step [31/225], Training Accuracy: 98.9415%, Training Loss: 0.0413%\n",
      "Epoch [130/300], Step [32/225], Training Accuracy: 98.9258%, Training Loss: 0.0412%\n",
      "Epoch [130/300], Step [33/225], Training Accuracy: 98.9110%, Training Loss: 0.0414%\n",
      "Epoch [130/300], Step [34/225], Training Accuracy: 98.9430%, Training Loss: 0.0407%\n",
      "Epoch [130/300], Step [35/225], Training Accuracy: 98.8839%, Training Loss: 0.0420%\n",
      "Epoch [130/300], Step [36/225], Training Accuracy: 98.9149%, Training Loss: 0.0416%\n",
      "Epoch [130/300], Step [37/225], Training Accuracy: 98.9443%, Training Loss: 0.0409%\n",
      "Epoch [130/300], Step [38/225], Training Accuracy: 98.9309%, Training Loss: 0.0414%\n",
      "Epoch [130/300], Step [39/225], Training Accuracy: 98.9583%, Training Loss: 0.0415%\n",
      "Epoch [130/300], Step [40/225], Training Accuracy: 98.9844%, Training Loss: 0.0414%\n",
      "Epoch [130/300], Step [41/225], Training Accuracy: 98.9329%, Training Loss: 0.0427%\n",
      "Epoch [130/300], Step [42/225], Training Accuracy: 98.9583%, Training Loss: 0.0422%\n",
      "Epoch [130/300], Step [43/225], Training Accuracy: 98.9462%, Training Loss: 0.0421%\n",
      "Epoch [130/300], Step [44/225], Training Accuracy: 98.9347%, Training Loss: 0.0417%\n",
      "Epoch [130/300], Step [45/225], Training Accuracy: 98.9236%, Training Loss: 0.0415%\n",
      "Epoch [130/300], Step [46/225], Training Accuracy: 98.8791%, Training Loss: 0.0423%\n",
      "Epoch [130/300], Step [47/225], Training Accuracy: 98.8697%, Training Loss: 0.0424%\n",
      "Epoch [130/300], Step [48/225], Training Accuracy: 98.8281%, Training Loss: 0.0426%\n",
      "Epoch [130/300], Step [49/225], Training Accuracy: 98.8202%, Training Loss: 0.0426%\n",
      "Epoch [130/300], Step [50/225], Training Accuracy: 98.7188%, Training Loss: 0.0443%\n",
      "Epoch [130/300], Step [51/225], Training Accuracy: 98.7439%, Training Loss: 0.0437%\n",
      "Epoch [130/300], Step [52/225], Training Accuracy: 98.6779%, Training Loss: 0.0450%\n",
      "Epoch [130/300], Step [53/225], Training Accuracy: 98.6733%, Training Loss: 0.0448%\n",
      "Epoch [130/300], Step [54/225], Training Accuracy: 98.6690%, Training Loss: 0.0448%\n",
      "Epoch [130/300], Step [55/225], Training Accuracy: 98.6932%, Training Loss: 0.0444%\n",
      "Epoch [130/300], Step [56/225], Training Accuracy: 98.6607%, Training Loss: 0.0451%\n",
      "Epoch [130/300], Step [57/225], Training Accuracy: 98.6842%, Training Loss: 0.0445%\n",
      "Epoch [130/300], Step [58/225], Training Accuracy: 98.6800%, Training Loss: 0.0448%\n",
      "Epoch [130/300], Step [59/225], Training Accuracy: 98.6758%, Training Loss: 0.0448%\n",
      "Epoch [130/300], Step [60/225], Training Accuracy: 98.6719%, Training Loss: 0.0452%\n",
      "Epoch [130/300], Step [61/225], Training Accuracy: 98.6424%, Training Loss: 0.0459%\n",
      "Epoch [130/300], Step [62/225], Training Accuracy: 98.6391%, Training Loss: 0.0457%\n",
      "Epoch [130/300], Step [63/225], Training Accuracy: 98.6359%, Training Loss: 0.0459%\n",
      "Epoch [130/300], Step [64/225], Training Accuracy: 98.6328%, Training Loss: 0.0459%\n",
      "Epoch [130/300], Step [65/225], Training Accuracy: 98.6058%, Training Loss: 0.0461%\n",
      "Epoch [130/300], Step [66/225], Training Accuracy: 98.6032%, Training Loss: 0.0460%\n",
      "Epoch [130/300], Step [67/225], Training Accuracy: 98.6241%, Training Loss: 0.0457%\n",
      "Epoch [130/300], Step [68/225], Training Accuracy: 98.6213%, Training Loss: 0.0457%\n",
      "Epoch [130/300], Step [69/225], Training Accuracy: 98.6413%, Training Loss: 0.0456%\n",
      "Epoch [130/300], Step [70/225], Training Accuracy: 98.6607%, Training Loss: 0.0452%\n",
      "Epoch [130/300], Step [71/225], Training Accuracy: 98.6356%, Training Loss: 0.0455%\n",
      "Epoch [130/300], Step [72/225], Training Accuracy: 98.6545%, Training Loss: 0.0453%\n",
      "Epoch [130/300], Step [73/225], Training Accuracy: 98.6515%, Training Loss: 0.0456%\n",
      "Epoch [130/300], Step [74/225], Training Accuracy: 98.6486%, Training Loss: 0.0463%\n",
      "Epoch [130/300], Step [75/225], Training Accuracy: 98.6458%, Training Loss: 0.0461%\n",
      "Epoch [130/300], Step [76/225], Training Accuracy: 98.6637%, Training Loss: 0.0457%\n",
      "Epoch [130/300], Step [77/225], Training Accuracy: 98.6607%, Training Loss: 0.0457%\n",
      "Epoch [130/300], Step [78/225], Training Accuracy: 98.6779%, Training Loss: 0.0455%\n",
      "Epoch [130/300], Step [79/225], Training Accuracy: 98.6353%, Training Loss: 0.0465%\n",
      "Epoch [130/300], Step [80/225], Training Accuracy: 98.6328%, Training Loss: 0.0463%\n",
      "Epoch [130/300], Step [81/225], Training Accuracy: 98.6304%, Training Loss: 0.0466%\n",
      "Epoch [130/300], Step [82/225], Training Accuracy: 98.6471%, Training Loss: 0.0464%\n",
      "Epoch [130/300], Step [83/225], Training Accuracy: 98.6634%, Training Loss: 0.0460%\n",
      "Epoch [130/300], Step [84/225], Training Accuracy: 98.6607%, Training Loss: 0.0461%\n",
      "Epoch [130/300], Step [85/225], Training Accuracy: 98.6765%, Training Loss: 0.0458%\n",
      "Epoch [130/300], Step [86/225], Training Accuracy: 98.6374%, Training Loss: 0.0462%\n",
      "Epoch [130/300], Step [87/225], Training Accuracy: 98.6530%, Training Loss: 0.0460%\n",
      "Epoch [130/300], Step [88/225], Training Accuracy: 98.6151%, Training Loss: 0.0464%\n",
      "Epoch [130/300], Step [89/225], Training Accuracy: 98.6131%, Training Loss: 0.0461%\n",
      "Epoch [130/300], Step [90/225], Training Accuracy: 98.6285%, Training Loss: 0.0460%\n",
      "Epoch [130/300], Step [91/225], Training Accuracy: 98.6264%, Training Loss: 0.0460%\n",
      "Epoch [130/300], Step [92/225], Training Accuracy: 98.6073%, Training Loss: 0.0462%\n",
      "Epoch [130/300], Step [93/225], Training Accuracy: 98.5887%, Training Loss: 0.0467%\n",
      "Epoch [130/300], Step [94/225], Training Accuracy: 98.5871%, Training Loss: 0.0466%\n",
      "Epoch [130/300], Step [95/225], Training Accuracy: 98.5855%, Training Loss: 0.0464%\n",
      "Epoch [130/300], Step [96/225], Training Accuracy: 98.5840%, Training Loss: 0.0463%\n",
      "Epoch [130/300], Step [97/225], Training Accuracy: 98.5664%, Training Loss: 0.0465%\n",
      "Epoch [130/300], Step [98/225], Training Accuracy: 98.5332%, Training Loss: 0.0470%\n",
      "Epoch [130/300], Step [99/225], Training Accuracy: 98.5480%, Training Loss: 0.0468%\n",
      "Epoch [130/300], Step [100/225], Training Accuracy: 98.5625%, Training Loss: 0.0467%\n",
      "Epoch [130/300], Step [101/225], Training Accuracy: 98.5458%, Training Loss: 0.0474%\n",
      "Epoch [130/300], Step [102/225], Training Accuracy: 98.5141%, Training Loss: 0.0477%\n",
      "Epoch [130/300], Step [103/225], Training Accuracy: 98.4982%, Training Loss: 0.0478%\n",
      "Epoch [130/300], Step [104/225], Training Accuracy: 98.4826%, Training Loss: 0.0481%\n",
      "Epoch [130/300], Step [105/225], Training Accuracy: 98.4821%, Training Loss: 0.0481%\n",
      "Epoch [130/300], Step [106/225], Training Accuracy: 98.4817%, Training Loss: 0.0481%\n",
      "Epoch [130/300], Step [107/225], Training Accuracy: 98.4667%, Training Loss: 0.0482%\n",
      "Epoch [130/300], Step [108/225], Training Accuracy: 98.4664%, Training Loss: 0.0482%\n",
      "Epoch [130/300], Step [109/225], Training Accuracy: 98.4662%, Training Loss: 0.0483%\n",
      "Epoch [130/300], Step [110/225], Training Accuracy: 98.4801%, Training Loss: 0.0481%\n",
      "Epoch [130/300], Step [111/225], Training Accuracy: 98.4375%, Training Loss: 0.0493%\n",
      "Epoch [130/300], Step [112/225], Training Accuracy: 98.4235%, Training Loss: 0.0497%\n",
      "Epoch [130/300], Step [113/225], Training Accuracy: 98.4375%, Training Loss: 0.0494%\n",
      "Epoch [130/300], Step [114/225], Training Accuracy: 98.4375%, Training Loss: 0.0495%\n",
      "Epoch [130/300], Step [115/225], Training Accuracy: 98.4103%, Training Loss: 0.0498%\n",
      "Epoch [130/300], Step [116/225], Training Accuracy: 98.4106%, Training Loss: 0.0499%\n",
      "Epoch [130/300], Step [117/225], Training Accuracy: 98.3841%, Training Loss: 0.0500%\n",
      "Epoch [130/300], Step [118/225], Training Accuracy: 98.3845%, Training Loss: 0.0503%\n",
      "Epoch [130/300], Step [119/225], Training Accuracy: 98.3850%, Training Loss: 0.0502%\n",
      "Epoch [130/300], Step [120/225], Training Accuracy: 98.3854%, Training Loss: 0.0502%\n",
      "Epoch [130/300], Step [121/225], Training Accuracy: 98.3729%, Training Loss: 0.0504%\n",
      "Epoch [130/300], Step [122/225], Training Accuracy: 98.3735%, Training Loss: 0.0505%\n",
      "Epoch [130/300], Step [123/225], Training Accuracy: 98.3740%, Training Loss: 0.0505%\n",
      "Epoch [130/300], Step [124/225], Training Accuracy: 98.3745%, Training Loss: 0.0505%\n",
      "Epoch [130/300], Step [125/225], Training Accuracy: 98.3875%, Training Loss: 0.0502%\n",
      "Epoch [130/300], Step [126/225], Training Accuracy: 98.3879%, Training Loss: 0.0503%\n",
      "Epoch [130/300], Step [127/225], Training Accuracy: 98.4006%, Training Loss: 0.0500%\n",
      "Epoch [130/300], Step [128/225], Training Accuracy: 98.4009%, Training Loss: 0.0500%\n",
      "Epoch [130/300], Step [129/225], Training Accuracy: 98.4012%, Training Loss: 0.0498%\n",
      "Epoch [130/300], Step [130/225], Training Accuracy: 98.3894%, Training Loss: 0.0498%\n",
      "Epoch [130/300], Step [131/225], Training Accuracy: 98.3898%, Training Loss: 0.0497%\n",
      "Epoch [130/300], Step [132/225], Training Accuracy: 98.4020%, Training Loss: 0.0495%\n",
      "Epoch [130/300], Step [133/225], Training Accuracy: 98.4140%, Training Loss: 0.0493%\n",
      "Epoch [130/300], Step [134/225], Training Accuracy: 98.4142%, Training Loss: 0.0494%\n",
      "Epoch [130/300], Step [135/225], Training Accuracy: 98.4144%, Training Loss: 0.0494%\n",
      "Epoch [130/300], Step [136/225], Training Accuracy: 98.4145%, Training Loss: 0.0496%\n",
      "Epoch [130/300], Step [137/225], Training Accuracy: 98.4147%, Training Loss: 0.0496%\n",
      "Epoch [130/300], Step [138/225], Training Accuracy: 98.4035%, Training Loss: 0.0497%\n",
      "Epoch [130/300], Step [139/225], Training Accuracy: 98.4038%, Training Loss: 0.0496%\n",
      "Epoch [130/300], Step [140/225], Training Accuracy: 98.3929%, Training Loss: 0.0497%\n",
      "Epoch [130/300], Step [141/225], Training Accuracy: 98.3821%, Training Loss: 0.0499%\n",
      "Epoch [130/300], Step [142/225], Training Accuracy: 98.3935%, Training Loss: 0.0498%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [130/300], Step [143/225], Training Accuracy: 98.3829%, Training Loss: 0.0500%\n",
      "Epoch [130/300], Step [144/225], Training Accuracy: 98.3832%, Training Loss: 0.0500%\n",
      "Epoch [130/300], Step [145/225], Training Accuracy: 98.3944%, Training Loss: 0.0498%\n",
      "Epoch [130/300], Step [146/225], Training Accuracy: 98.3947%, Training Loss: 0.0497%\n",
      "Epoch [130/300], Step [147/225], Training Accuracy: 98.3950%, Training Loss: 0.0496%\n",
      "Epoch [130/300], Step [148/225], Training Accuracy: 98.3953%, Training Loss: 0.0497%\n",
      "Epoch [130/300], Step [149/225], Training Accuracy: 98.4060%, Training Loss: 0.0496%\n",
      "Epoch [130/300], Step [150/225], Training Accuracy: 98.4062%, Training Loss: 0.0497%\n",
      "Epoch [130/300], Step [151/225], Training Accuracy: 98.3961%, Training Loss: 0.0497%\n",
      "Epoch [130/300], Step [152/225], Training Accuracy: 98.4067%, Training Loss: 0.0495%\n",
      "Epoch [130/300], Step [153/225], Training Accuracy: 98.4171%, Training Loss: 0.0494%\n",
      "Epoch [130/300], Step [154/225], Training Accuracy: 98.4274%, Training Loss: 0.0493%\n",
      "Epoch [130/300], Step [155/225], Training Accuracy: 98.4375%, Training Loss: 0.0491%\n",
      "Epoch [130/300], Step [156/225], Training Accuracy: 98.4275%, Training Loss: 0.0493%\n",
      "Epoch [130/300], Step [157/225], Training Accuracy: 98.4275%, Training Loss: 0.0493%\n",
      "Epoch [130/300], Step [158/225], Training Accuracy: 98.4276%, Training Loss: 0.0493%\n",
      "Epoch [130/300], Step [159/225], Training Accuracy: 98.4277%, Training Loss: 0.0493%\n",
      "Epoch [130/300], Step [160/225], Training Accuracy: 98.4277%, Training Loss: 0.0493%\n",
      "Epoch [130/300], Step [161/225], Training Accuracy: 98.4278%, Training Loss: 0.0492%\n",
      "Epoch [130/300], Step [162/225], Training Accuracy: 98.4279%, Training Loss: 0.0491%\n",
      "Epoch [130/300], Step [163/225], Training Accuracy: 98.4279%, Training Loss: 0.0491%\n",
      "Epoch [130/300], Step [164/225], Training Accuracy: 98.4280%, Training Loss: 0.0490%\n",
      "Epoch [130/300], Step [165/225], Training Accuracy: 98.4280%, Training Loss: 0.0490%\n",
      "Epoch [130/300], Step [166/225], Training Accuracy: 98.4375%, Training Loss: 0.0488%\n",
      "Epoch [130/300], Step [167/225], Training Accuracy: 98.4281%, Training Loss: 0.0488%\n",
      "Epoch [130/300], Step [168/225], Training Accuracy: 98.4375%, Training Loss: 0.0487%\n",
      "Epoch [130/300], Step [169/225], Training Accuracy: 98.4375%, Training Loss: 0.0487%\n",
      "Epoch [130/300], Step [170/225], Training Accuracy: 98.4467%, Training Loss: 0.0485%\n",
      "Epoch [130/300], Step [171/225], Training Accuracy: 98.4558%, Training Loss: 0.0484%\n",
      "Epoch [130/300], Step [172/225], Training Accuracy: 98.4557%, Training Loss: 0.0483%\n",
      "Epoch [130/300], Step [173/225], Training Accuracy: 98.4465%, Training Loss: 0.0483%\n",
      "Epoch [130/300], Step [174/225], Training Accuracy: 98.4465%, Training Loss: 0.0484%\n",
      "Epoch [130/300], Step [175/225], Training Accuracy: 98.4554%, Training Loss: 0.0481%\n",
      "Epoch [130/300], Step [176/225], Training Accuracy: 98.4286%, Training Loss: 0.0484%\n",
      "Epoch [130/300], Step [177/225], Training Accuracy: 98.4375%, Training Loss: 0.0484%\n",
      "Epoch [130/300], Step [178/225], Training Accuracy: 98.4375%, Training Loss: 0.0485%\n",
      "Epoch [130/300], Step [179/225], Training Accuracy: 98.4375%, Training Loss: 0.0485%\n",
      "Epoch [130/300], Step [180/225], Training Accuracy: 98.4462%, Training Loss: 0.0484%\n",
      "Epoch [130/300], Step [181/225], Training Accuracy: 98.4289%, Training Loss: 0.0487%\n",
      "Epoch [130/300], Step [182/225], Training Accuracy: 98.4375%, Training Loss: 0.0485%\n",
      "Epoch [130/300], Step [183/225], Training Accuracy: 98.4375%, Training Loss: 0.0484%\n",
      "Epoch [130/300], Step [184/225], Training Accuracy: 98.4460%, Training Loss: 0.0483%\n",
      "Epoch [130/300], Step [185/225], Training Accuracy: 98.4544%, Training Loss: 0.0481%\n",
      "Epoch [130/300], Step [186/225], Training Accuracy: 98.4627%, Training Loss: 0.0480%\n",
      "Epoch [130/300], Step [187/225], Training Accuracy: 98.4375%, Training Loss: 0.0483%\n",
      "Epoch [130/300], Step [188/225], Training Accuracy: 98.4458%, Training Loss: 0.0482%\n",
      "Epoch [130/300], Step [189/225], Training Accuracy: 98.4458%, Training Loss: 0.0482%\n",
      "Epoch [130/300], Step [190/225], Training Accuracy: 98.4375%, Training Loss: 0.0485%\n",
      "Epoch [130/300], Step [191/225], Training Accuracy: 98.4457%, Training Loss: 0.0483%\n",
      "Epoch [130/300], Step [192/225], Training Accuracy: 98.4538%, Training Loss: 0.0482%\n",
      "Epoch [130/300], Step [193/225], Training Accuracy: 98.4375%, Training Loss: 0.0484%\n",
      "Epoch [130/300], Step [194/225], Training Accuracy: 98.4133%, Training Loss: 0.0486%\n",
      "Epoch [130/300], Step [195/225], Training Accuracy: 98.4135%, Training Loss: 0.0486%\n",
      "Epoch [130/300], Step [196/225], Training Accuracy: 98.4216%, Training Loss: 0.0484%\n",
      "Epoch [130/300], Step [197/225], Training Accuracy: 98.4216%, Training Loss: 0.0484%\n",
      "Epoch [130/300], Step [198/225], Training Accuracy: 98.4138%, Training Loss: 0.0485%\n",
      "Epoch [130/300], Step [199/225], Training Accuracy: 98.4218%, Training Loss: 0.0484%\n",
      "Epoch [130/300], Step [200/225], Training Accuracy: 98.4297%, Training Loss: 0.0483%\n",
      "Epoch [130/300], Step [201/225], Training Accuracy: 98.4220%, Training Loss: 0.0483%\n",
      "Epoch [130/300], Step [202/225], Training Accuracy: 98.4066%, Training Loss: 0.0486%\n",
      "Epoch [130/300], Step [203/225], Training Accuracy: 98.4067%, Training Loss: 0.0485%\n",
      "Epoch [130/300], Step [204/225], Training Accuracy: 98.3992%, Training Loss: 0.0486%\n",
      "Epoch [130/300], Step [205/225], Training Accuracy: 98.4070%, Training Loss: 0.0485%\n",
      "Epoch [130/300], Step [206/225], Training Accuracy: 98.4072%, Training Loss: 0.0485%\n",
      "Epoch [130/300], Step [207/225], Training Accuracy: 98.4149%, Training Loss: 0.0483%\n",
      "Epoch [130/300], Step [208/225], Training Accuracy: 98.4225%, Training Loss: 0.0481%\n",
      "Epoch [130/300], Step [209/225], Training Accuracy: 98.4300%, Training Loss: 0.0479%\n",
      "Epoch [130/300], Step [210/225], Training Accuracy: 98.4301%, Training Loss: 0.0479%\n",
      "Epoch [130/300], Step [211/225], Training Accuracy: 98.4301%, Training Loss: 0.0479%\n",
      "Epoch [130/300], Step [212/225], Training Accuracy: 98.4375%, Training Loss: 0.0477%\n",
      "Epoch [130/300], Step [213/225], Training Accuracy: 98.4375%, Training Loss: 0.0478%\n",
      "Epoch [130/300], Step [214/225], Training Accuracy: 98.4302%, Training Loss: 0.0478%\n",
      "Epoch [130/300], Step [215/225], Training Accuracy: 98.4375%, Training Loss: 0.0477%\n",
      "Epoch [130/300], Step [216/225], Training Accuracy: 98.4447%, Training Loss: 0.0477%\n",
      "Epoch [130/300], Step [217/225], Training Accuracy: 98.4519%, Training Loss: 0.0476%\n",
      "Epoch [130/300], Step [218/225], Training Accuracy: 98.4518%, Training Loss: 0.0476%\n",
      "Epoch [130/300], Step [219/225], Training Accuracy: 98.4518%, Training Loss: 0.0475%\n",
      "Epoch [130/300], Step [220/225], Training Accuracy: 98.4517%, Training Loss: 0.0474%\n",
      "Epoch [130/300], Step [221/225], Training Accuracy: 98.4446%, Training Loss: 0.0474%\n",
      "Epoch [130/300], Step [222/225], Training Accuracy: 98.4164%, Training Loss: 0.0478%\n",
      "Epoch [130/300], Step [223/225], Training Accuracy: 98.4095%, Training Loss: 0.0480%\n",
      "Epoch [130/300], Step [224/225], Training Accuracy: 98.4166%, Training Loss: 0.0479%\n",
      "Epoch [130/300], Step [225/225], Training Accuracy: 98.4227%, Training Loss: 0.0477%\n",
      "Epoch [131/300], Step [1/225], Training Accuracy: 98.4375%, Training Loss: 0.0297%\n",
      "Epoch [131/300], Step [2/225], Training Accuracy: 98.4375%, Training Loss: 0.0301%\n",
      "Epoch [131/300], Step [3/225], Training Accuracy: 97.9167%, Training Loss: 0.0505%\n",
      "Epoch [131/300], Step [4/225], Training Accuracy: 98.0469%, Training Loss: 0.0448%\n",
      "Epoch [131/300], Step [5/225], Training Accuracy: 98.1250%, Training Loss: 0.0420%\n",
      "Epoch [131/300], Step [6/225], Training Accuracy: 98.1771%, Training Loss: 0.0433%\n",
      "Epoch [131/300], Step [7/225], Training Accuracy: 98.2143%, Training Loss: 0.0417%\n",
      "Epoch [131/300], Step [8/225], Training Accuracy: 98.2422%, Training Loss: 0.0455%\n",
      "Epoch [131/300], Step [9/225], Training Accuracy: 98.4375%, Training Loss: 0.0433%\n",
      "Epoch [131/300], Step [10/225], Training Accuracy: 98.2812%, Training Loss: 0.0497%\n",
      "Epoch [131/300], Step [11/225], Training Accuracy: 98.0114%, Training Loss: 0.0551%\n",
      "Epoch [131/300], Step [12/225], Training Accuracy: 98.1771%, Training Loss: 0.0514%\n",
      "Epoch [131/300], Step [13/225], Training Accuracy: 98.3173%, Training Loss: 0.0496%\n",
      "Epoch [131/300], Step [14/225], Training Accuracy: 98.3259%, Training Loss: 0.0496%\n",
      "Epoch [131/300], Step [15/225], Training Accuracy: 98.3333%, Training Loss: 0.0479%\n",
      "Epoch [131/300], Step [16/225], Training Accuracy: 98.4375%, Training Loss: 0.0453%\n",
      "Epoch [131/300], Step [17/225], Training Accuracy: 98.5294%, Training Loss: 0.0444%\n",
      "Epoch [131/300], Step [18/225], Training Accuracy: 98.6111%, Training Loss: 0.0443%\n",
      "Epoch [131/300], Step [19/225], Training Accuracy: 98.6020%, Training Loss: 0.0440%\n",
      "Epoch [131/300], Step [20/225], Training Accuracy: 98.5938%, Training Loss: 0.0440%\n",
      "Epoch [131/300], Step [21/225], Training Accuracy: 98.6607%, Training Loss: 0.0433%\n",
      "Epoch [131/300], Step [22/225], Training Accuracy: 98.5795%, Training Loss: 0.0469%\n",
      "Epoch [131/300], Step [23/225], Training Accuracy: 98.5734%, Training Loss: 0.0479%\n",
      "Epoch [131/300], Step [24/225], Training Accuracy: 98.4375%, Training Loss: 0.0499%\n",
      "Epoch [131/300], Step [25/225], Training Accuracy: 98.4375%, Training Loss: 0.0493%\n",
      "Epoch [131/300], Step [26/225], Training Accuracy: 98.3774%, Training Loss: 0.0505%\n",
      "Epoch [131/300], Step [27/225], Training Accuracy: 98.3796%, Training Loss: 0.0502%\n",
      "Epoch [131/300], Step [28/225], Training Accuracy: 98.3817%, Training Loss: 0.0492%\n",
      "Epoch [131/300], Step [29/225], Training Accuracy: 98.4375%, Training Loss: 0.0483%\n",
      "Epoch [131/300], Step [30/225], Training Accuracy: 98.4375%, Training Loss: 0.0482%\n",
      "Epoch [131/300], Step [31/225], Training Accuracy: 98.4375%, Training Loss: 0.0478%\n",
      "Epoch [131/300], Step [32/225], Training Accuracy: 98.4863%, Training Loss: 0.0469%\n",
      "Epoch [131/300], Step [33/225], Training Accuracy: 98.5322%, Training Loss: 0.0460%\n",
      "Epoch [131/300], Step [34/225], Training Accuracy: 98.5294%, Training Loss: 0.0467%\n",
      "Epoch [131/300], Step [35/225], Training Accuracy: 98.5268%, Training Loss: 0.0471%\n",
      "Epoch [131/300], Step [36/225], Training Accuracy: 98.5677%, Training Loss: 0.0465%\n",
      "Epoch [131/300], Step [37/225], Training Accuracy: 98.5642%, Training Loss: 0.0471%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [131/300], Step [38/225], Training Accuracy: 98.6020%, Training Loss: 0.0465%\n",
      "Epoch [131/300], Step [39/225], Training Accuracy: 98.5978%, Training Loss: 0.0463%\n",
      "Epoch [131/300], Step [40/225], Training Accuracy: 98.6328%, Training Loss: 0.0457%\n",
      "Epoch [131/300], Step [41/225], Training Accuracy: 98.6280%, Training Loss: 0.0459%\n",
      "Epoch [131/300], Step [42/225], Training Accuracy: 98.6607%, Training Loss: 0.0450%\n",
      "Epoch [131/300], Step [43/225], Training Accuracy: 98.6555%, Training Loss: 0.0448%\n",
      "Epoch [131/300], Step [44/225], Training Accuracy: 98.6506%, Training Loss: 0.0445%\n",
      "Epoch [131/300], Step [45/225], Training Accuracy: 98.6458%, Training Loss: 0.0441%\n",
      "Epoch [131/300], Step [46/225], Training Accuracy: 98.6413%, Training Loss: 0.0440%\n",
      "Epoch [131/300], Step [47/225], Training Accuracy: 98.6702%, Training Loss: 0.0441%\n",
      "Epoch [131/300], Step [48/225], Training Accuracy: 98.6979%, Training Loss: 0.0436%\n",
      "Epoch [131/300], Step [49/225], Training Accuracy: 98.6926%, Training Loss: 0.0436%\n",
      "Epoch [131/300], Step [50/225], Training Accuracy: 98.6875%, Training Loss: 0.0436%\n",
      "Epoch [131/300], Step [51/225], Training Accuracy: 98.7132%, Training Loss: 0.0433%\n",
      "Epoch [131/300], Step [52/225], Training Accuracy: 98.7079%, Training Loss: 0.0432%\n",
      "Epoch [131/300], Step [53/225], Training Accuracy: 98.7028%, Training Loss: 0.0430%\n",
      "Epoch [131/300], Step [54/225], Training Accuracy: 98.7269%, Training Loss: 0.0425%\n",
      "Epoch [131/300], Step [55/225], Training Accuracy: 98.6932%, Training Loss: 0.0431%\n",
      "Epoch [131/300], Step [56/225], Training Accuracy: 98.6049%, Training Loss: 0.0444%\n",
      "Epoch [131/300], Step [57/225], Training Accuracy: 98.5746%, Training Loss: 0.0451%\n",
      "Epoch [131/300], Step [58/225], Training Accuracy: 98.5722%, Training Loss: 0.0451%\n",
      "Epoch [131/300], Step [59/225], Training Accuracy: 98.5964%, Training Loss: 0.0447%\n",
      "Epoch [131/300], Step [60/225], Training Accuracy: 98.5938%, Training Loss: 0.0446%\n",
      "Epoch [131/300], Step [61/225], Training Accuracy: 98.5400%, Training Loss: 0.0454%\n",
      "Epoch [131/300], Step [62/225], Training Accuracy: 98.5131%, Training Loss: 0.0456%\n",
      "Epoch [131/300], Step [63/225], Training Accuracy: 98.5367%, Training Loss: 0.0451%\n",
      "Epoch [131/300], Step [64/225], Training Accuracy: 98.5352%, Training Loss: 0.0450%\n",
      "Epoch [131/300], Step [65/225], Training Accuracy: 98.5337%, Training Loss: 0.0447%\n",
      "Epoch [131/300], Step [66/225], Training Accuracy: 98.5322%, Training Loss: 0.0450%\n",
      "Epoch [131/300], Step [67/225], Training Accuracy: 98.5308%, Training Loss: 0.0454%\n",
      "Epoch [131/300], Step [68/225], Training Accuracy: 98.5524%, Training Loss: 0.0449%\n",
      "Epoch [131/300], Step [69/225], Training Accuracy: 98.5734%, Training Loss: 0.0445%\n",
      "Epoch [131/300], Step [70/225], Training Accuracy: 98.5714%, Training Loss: 0.0443%\n",
      "Epoch [131/300], Step [71/225], Training Accuracy: 98.5915%, Training Loss: 0.0442%\n",
      "Epoch [131/300], Step [72/225], Training Accuracy: 98.5894%, Training Loss: 0.0440%\n",
      "Epoch [131/300], Step [73/225], Training Accuracy: 98.6087%, Training Loss: 0.0438%\n",
      "Epoch [131/300], Step [74/225], Training Accuracy: 98.6275%, Training Loss: 0.0436%\n",
      "Epoch [131/300], Step [75/225], Training Accuracy: 98.6250%, Training Loss: 0.0436%\n",
      "Epoch [131/300], Step [76/225], Training Accuracy: 98.5814%, Training Loss: 0.0444%\n",
      "Epoch [131/300], Step [77/225], Training Accuracy: 98.5998%, Training Loss: 0.0441%\n",
      "Epoch [131/300], Step [78/225], Training Accuracy: 98.6178%, Training Loss: 0.0437%\n",
      "Epoch [131/300], Step [79/225], Training Accuracy: 98.5957%, Training Loss: 0.0443%\n",
      "Epoch [131/300], Step [80/225], Training Accuracy: 98.5742%, Training Loss: 0.0447%\n",
      "Epoch [131/300], Step [81/225], Training Accuracy: 98.5725%, Training Loss: 0.0447%\n",
      "Epoch [131/300], Step [82/225], Training Accuracy: 98.5899%, Training Loss: 0.0445%\n",
      "Epoch [131/300], Step [83/225], Training Accuracy: 98.5316%, Training Loss: 0.0450%\n",
      "Epoch [131/300], Step [84/225], Training Accuracy: 98.5491%, Training Loss: 0.0449%\n",
      "Epoch [131/300], Step [85/225], Training Accuracy: 98.5294%, Training Loss: 0.0451%\n",
      "Epoch [131/300], Step [86/225], Training Accuracy: 98.5102%, Training Loss: 0.0454%\n",
      "Epoch [131/300], Step [87/225], Training Accuracy: 98.5273%, Training Loss: 0.0450%\n",
      "Epoch [131/300], Step [88/225], Training Accuracy: 98.5263%, Training Loss: 0.0452%\n",
      "Epoch [131/300], Step [89/225], Training Accuracy: 98.5253%, Training Loss: 0.0452%\n",
      "Epoch [131/300], Step [90/225], Training Accuracy: 98.5069%, Training Loss: 0.0455%\n",
      "Epoch [131/300], Step [91/225], Training Accuracy: 98.5062%, Training Loss: 0.0456%\n",
      "Epoch [131/300], Step [92/225], Training Accuracy: 98.5054%, Training Loss: 0.0459%\n",
      "Epoch [131/300], Step [93/225], Training Accuracy: 98.5215%, Training Loss: 0.0456%\n",
      "Epoch [131/300], Step [94/225], Training Accuracy: 98.5206%, Training Loss: 0.0454%\n",
      "Epoch [131/300], Step [95/225], Training Accuracy: 98.5033%, Training Loss: 0.0457%\n",
      "Epoch [131/300], Step [96/225], Training Accuracy: 98.5189%, Training Loss: 0.0454%\n",
      "Epoch [131/300], Step [97/225], Training Accuracy: 98.5341%, Training Loss: 0.0451%\n",
      "Epoch [131/300], Step [98/225], Training Accuracy: 98.5332%, Training Loss: 0.0451%\n",
      "Epoch [131/300], Step [99/225], Training Accuracy: 98.4848%, Training Loss: 0.0459%\n",
      "Epoch [131/300], Step [100/225], Training Accuracy: 98.5000%, Training Loss: 0.0458%\n",
      "Epoch [131/300], Step [101/225], Training Accuracy: 98.4994%, Training Loss: 0.0457%\n",
      "Epoch [131/300], Step [102/225], Training Accuracy: 98.4835%, Training Loss: 0.0458%\n",
      "Epoch [131/300], Step [103/225], Training Accuracy: 98.4982%, Training Loss: 0.0455%\n",
      "Epoch [131/300], Step [104/225], Training Accuracy: 98.5126%, Training Loss: 0.0453%\n",
      "Epoch [131/300], Step [105/225], Training Accuracy: 98.4821%, Training Loss: 0.0458%\n",
      "Epoch [131/300], Step [106/225], Training Accuracy: 98.4670%, Training Loss: 0.0462%\n",
      "Epoch [131/300], Step [107/225], Training Accuracy: 98.4813%, Training Loss: 0.0459%\n",
      "Epoch [131/300], Step [108/225], Training Accuracy: 98.4809%, Training Loss: 0.0458%\n",
      "Epoch [131/300], Step [109/225], Training Accuracy: 98.4805%, Training Loss: 0.0464%\n",
      "Epoch [131/300], Step [110/225], Training Accuracy: 98.4517%, Training Loss: 0.0464%\n",
      "Epoch [131/300], Step [111/225], Training Accuracy: 98.4516%, Training Loss: 0.0467%\n",
      "Epoch [131/300], Step [112/225], Training Accuracy: 98.4654%, Training Loss: 0.0465%\n",
      "Epoch [131/300], Step [113/225], Training Accuracy: 98.4652%, Training Loss: 0.0464%\n",
      "Epoch [131/300], Step [114/225], Training Accuracy: 98.4649%, Training Loss: 0.0465%\n",
      "Epoch [131/300], Step [115/225], Training Accuracy: 98.4783%, Training Loss: 0.0464%\n",
      "Epoch [131/300], Step [116/225], Training Accuracy: 98.4779%, Training Loss: 0.0465%\n",
      "Epoch [131/300], Step [117/225], Training Accuracy: 98.4909%, Training Loss: 0.0462%\n",
      "Epoch [131/300], Step [118/225], Training Accuracy: 98.5037%, Training Loss: 0.0461%\n",
      "Epoch [131/300], Step [119/225], Training Accuracy: 98.5032%, Training Loss: 0.0460%\n",
      "Epoch [131/300], Step [120/225], Training Accuracy: 98.5026%, Training Loss: 0.0462%\n",
      "Epoch [131/300], Step [121/225], Training Accuracy: 98.5150%, Training Loss: 0.0461%\n",
      "Epoch [131/300], Step [122/225], Training Accuracy: 98.4887%, Training Loss: 0.0471%\n",
      "Epoch [131/300], Step [123/225], Training Accuracy: 98.5010%, Training Loss: 0.0469%\n",
      "Epoch [131/300], Step [124/225], Training Accuracy: 98.5005%, Training Loss: 0.0469%\n",
      "Epoch [131/300], Step [125/225], Training Accuracy: 98.4875%, Training Loss: 0.0469%\n",
      "Epoch [131/300], Step [126/225], Training Accuracy: 98.4871%, Training Loss: 0.0470%\n",
      "Epoch [131/300], Step [127/225], Training Accuracy: 98.4990%, Training Loss: 0.0469%\n",
      "Epoch [131/300], Step [128/225], Training Accuracy: 98.4863%, Training Loss: 0.0471%\n",
      "Epoch [131/300], Step [129/225], Training Accuracy: 98.4859%, Training Loss: 0.0473%\n",
      "Epoch [131/300], Step [130/225], Training Accuracy: 98.4856%, Training Loss: 0.0474%\n",
      "Epoch [131/300], Step [131/225], Training Accuracy: 98.4971%, Training Loss: 0.0471%\n",
      "Epoch [131/300], Step [132/225], Training Accuracy: 98.5085%, Training Loss: 0.0470%\n",
      "Epoch [131/300], Step [133/225], Training Accuracy: 98.5080%, Training Loss: 0.0469%\n",
      "Epoch [131/300], Step [134/225], Training Accuracy: 98.5191%, Training Loss: 0.0468%\n",
      "Epoch [131/300], Step [135/225], Training Accuracy: 98.5301%, Training Loss: 0.0465%\n",
      "Epoch [131/300], Step [136/225], Training Accuracy: 98.5409%, Training Loss: 0.0463%\n",
      "Epoch [131/300], Step [137/225], Training Accuracy: 98.5401%, Training Loss: 0.0464%\n",
      "Epoch [131/300], Step [138/225], Training Accuracy: 98.5394%, Training Loss: 0.0464%\n",
      "Epoch [131/300], Step [139/225], Training Accuracy: 98.5387%, Training Loss: 0.0465%\n",
      "Epoch [131/300], Step [140/225], Training Accuracy: 98.5491%, Training Loss: 0.0463%\n",
      "Epoch [131/300], Step [141/225], Training Accuracy: 98.5483%, Training Loss: 0.0464%\n",
      "Epoch [131/300], Step [142/225], Training Accuracy: 98.5475%, Training Loss: 0.0463%\n",
      "Epoch [131/300], Step [143/225], Training Accuracy: 98.5577%, Training Loss: 0.0462%\n",
      "Epoch [131/300], Step [144/225], Training Accuracy: 98.5569%, Training Loss: 0.0461%\n",
      "Epoch [131/300], Step [145/225], Training Accuracy: 98.5668%, Training Loss: 0.0459%\n",
      "Epoch [131/300], Step [146/225], Training Accuracy: 98.5766%, Training Loss: 0.0458%\n",
      "Epoch [131/300], Step [147/225], Training Accuracy: 98.5863%, Training Loss: 0.0456%\n",
      "Epoch [131/300], Step [148/225], Training Accuracy: 98.5959%, Training Loss: 0.0455%\n",
      "Epoch [131/300], Step [149/225], Training Accuracy: 98.6053%, Training Loss: 0.0455%\n",
      "Epoch [131/300], Step [150/225], Training Accuracy: 98.6042%, Training Loss: 0.0454%\n",
      "Epoch [131/300], Step [151/225], Training Accuracy: 98.6031%, Training Loss: 0.0456%\n",
      "Epoch [131/300], Step [152/225], Training Accuracy: 98.6020%, Training Loss: 0.0458%\n",
      "Epoch [131/300], Step [153/225], Training Accuracy: 98.6111%, Training Loss: 0.0456%\n",
      "Epoch [131/300], Step [154/225], Training Accuracy: 98.6100%, Training Loss: 0.0455%\n",
      "Epoch [131/300], Step [155/225], Training Accuracy: 98.6089%, Training Loss: 0.0455%\n",
      "Epoch [131/300], Step [156/225], Training Accuracy: 98.6078%, Training Loss: 0.0454%\n",
      "Epoch [131/300], Step [157/225], Training Accuracy: 98.6067%, Training Loss: 0.0453%\n",
      "Epoch [131/300], Step [158/225], Training Accuracy: 98.6056%, Training Loss: 0.0455%\n",
      "Epoch [131/300], Step [159/225], Training Accuracy: 98.6046%, Training Loss: 0.0454%\n",
      "Epoch [131/300], Step [160/225], Training Accuracy: 98.6035%, Training Loss: 0.0453%\n",
      "Epoch [131/300], Step [161/225], Training Accuracy: 98.6122%, Training Loss: 0.0451%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [131/300], Step [162/225], Training Accuracy: 98.6111%, Training Loss: 0.0454%\n",
      "Epoch [131/300], Step [163/225], Training Accuracy: 98.6196%, Training Loss: 0.0453%\n",
      "Epoch [131/300], Step [164/225], Training Accuracy: 98.6185%, Training Loss: 0.0454%\n",
      "Epoch [131/300], Step [165/225], Training Accuracy: 98.6269%, Training Loss: 0.0452%\n",
      "Epoch [131/300], Step [166/225], Training Accuracy: 98.6258%, Training Loss: 0.0453%\n",
      "Epoch [131/300], Step [167/225], Training Accuracy: 98.6246%, Training Loss: 0.0452%\n",
      "Epoch [131/300], Step [168/225], Training Accuracy: 98.6142%, Training Loss: 0.0455%\n",
      "Epoch [131/300], Step [169/225], Training Accuracy: 98.6224%, Training Loss: 0.0454%\n",
      "Epoch [131/300], Step [170/225], Training Accuracy: 98.6213%, Training Loss: 0.0454%\n",
      "Epoch [131/300], Step [171/225], Training Accuracy: 98.6020%, Training Loss: 0.0457%\n",
      "Epoch [131/300], Step [172/225], Training Accuracy: 98.6010%, Training Loss: 0.0457%\n",
      "Epoch [131/300], Step [173/225], Training Accuracy: 98.6001%, Training Loss: 0.0457%\n",
      "Epoch [131/300], Step [174/225], Training Accuracy: 98.6081%, Training Loss: 0.0455%\n",
      "Epoch [131/300], Step [175/225], Training Accuracy: 98.6161%, Training Loss: 0.0454%\n",
      "Epoch [131/300], Step [176/225], Training Accuracy: 98.6239%, Training Loss: 0.0453%\n",
      "Epoch [131/300], Step [177/225], Training Accuracy: 98.6141%, Training Loss: 0.0454%\n",
      "Epoch [131/300], Step [178/225], Training Accuracy: 98.6218%, Training Loss: 0.0453%\n",
      "Epoch [131/300], Step [179/225], Training Accuracy: 98.6121%, Training Loss: 0.0453%\n",
      "Epoch [131/300], Step [180/225], Training Accuracy: 98.6198%, Training Loss: 0.0452%\n",
      "Epoch [131/300], Step [181/225], Training Accuracy: 98.6188%, Training Loss: 0.0453%\n",
      "Epoch [131/300], Step [182/225], Training Accuracy: 98.6178%, Training Loss: 0.0453%\n",
      "Epoch [131/300], Step [183/225], Training Accuracy: 98.6083%, Training Loss: 0.0453%\n",
      "Epoch [131/300], Step [184/225], Training Accuracy: 98.5904%, Training Loss: 0.0456%\n",
      "Epoch [131/300], Step [185/225], Training Accuracy: 98.5811%, Training Loss: 0.0458%\n",
      "Epoch [131/300], Step [186/225], Training Accuracy: 98.5635%, Training Loss: 0.0461%\n",
      "Epoch [131/300], Step [187/225], Training Accuracy: 98.5712%, Training Loss: 0.0460%\n",
      "Epoch [131/300], Step [188/225], Training Accuracy: 98.5788%, Training Loss: 0.0459%\n",
      "Epoch [131/300], Step [189/225], Training Accuracy: 98.5780%, Training Loss: 0.0458%\n",
      "Epoch [131/300], Step [190/225], Training Accuracy: 98.5691%, Training Loss: 0.0459%\n",
      "Epoch [131/300], Step [191/225], Training Accuracy: 98.5766%, Training Loss: 0.0458%\n",
      "Epoch [131/300], Step [192/225], Training Accuracy: 98.5758%, Training Loss: 0.0458%\n",
      "Epoch [131/300], Step [193/225], Training Accuracy: 98.5751%, Training Loss: 0.0460%\n",
      "Epoch [131/300], Step [194/225], Training Accuracy: 98.5744%, Training Loss: 0.0459%\n",
      "Epoch [131/300], Step [195/225], Training Accuracy: 98.5737%, Training Loss: 0.0463%\n",
      "Epoch [131/300], Step [196/225], Training Accuracy: 98.5810%, Training Loss: 0.0462%\n",
      "Epoch [131/300], Step [197/225], Training Accuracy: 98.5723%, Training Loss: 0.0461%\n",
      "Epoch [131/300], Step [198/225], Training Accuracy: 98.5717%, Training Loss: 0.0461%\n",
      "Epoch [131/300], Step [199/225], Training Accuracy: 98.5788%, Training Loss: 0.0461%\n",
      "Epoch [131/300], Step [200/225], Training Accuracy: 98.5781%, Training Loss: 0.0460%\n",
      "Epoch [131/300], Step [201/225], Training Accuracy: 98.5697%, Training Loss: 0.0464%\n",
      "Epoch [131/300], Step [202/225], Training Accuracy: 98.5535%, Training Loss: 0.0465%\n",
      "Epoch [131/300], Step [203/225], Training Accuracy: 98.5530%, Training Loss: 0.0465%\n",
      "Epoch [131/300], Step [204/225], Training Accuracy: 98.5524%, Training Loss: 0.0465%\n",
      "Epoch [131/300], Step [205/225], Training Accuracy: 98.5595%, Training Loss: 0.0463%\n",
      "Epoch [131/300], Step [206/225], Training Accuracy: 98.5664%, Training Loss: 0.0462%\n",
      "Epoch [131/300], Step [207/225], Training Accuracy: 98.5734%, Training Loss: 0.0461%\n",
      "Epoch [131/300], Step [208/225], Training Accuracy: 98.5727%, Training Loss: 0.0460%\n",
      "Epoch [131/300], Step [209/225], Training Accuracy: 98.5721%, Training Loss: 0.0460%\n",
      "Epoch [131/300], Step [210/225], Training Accuracy: 98.5714%, Training Loss: 0.0459%\n",
      "Epoch [131/300], Step [211/225], Training Accuracy: 98.5634%, Training Loss: 0.0461%\n",
      "Epoch [131/300], Step [212/225], Training Accuracy: 98.5702%, Training Loss: 0.0460%\n",
      "Epoch [131/300], Step [213/225], Training Accuracy: 98.5695%, Training Loss: 0.0461%\n",
      "Epoch [131/300], Step [214/225], Training Accuracy: 98.5689%, Training Loss: 0.0460%\n",
      "Epoch [131/300], Step [215/225], Training Accuracy: 98.5756%, Training Loss: 0.0459%\n",
      "Epoch [131/300], Step [216/225], Training Accuracy: 98.5822%, Training Loss: 0.0458%\n",
      "Epoch [131/300], Step [217/225], Training Accuracy: 98.5815%, Training Loss: 0.0458%\n",
      "Epoch [131/300], Step [218/225], Training Accuracy: 98.5880%, Training Loss: 0.0456%\n",
      "Epoch [131/300], Step [219/225], Training Accuracy: 98.5945%, Training Loss: 0.0455%\n",
      "Epoch [131/300], Step [220/225], Training Accuracy: 98.5938%, Training Loss: 0.0455%\n",
      "Epoch [131/300], Step [221/225], Training Accuracy: 98.6001%, Training Loss: 0.0454%\n",
      "Epoch [131/300], Step [222/225], Training Accuracy: 98.6064%, Training Loss: 0.0453%\n",
      "Epoch [131/300], Step [223/225], Training Accuracy: 98.6057%, Training Loss: 0.0453%\n",
      "Epoch [131/300], Step [224/225], Training Accuracy: 98.6049%, Training Loss: 0.0452%\n",
      "Epoch [131/300], Step [225/225], Training Accuracy: 98.5964%, Training Loss: 0.0452%\n",
      "Epoch [132/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0220%\n",
      "Epoch [132/300], Step [2/225], Training Accuracy: 100.0000%, Training Loss: 0.0233%\n",
      "Epoch [132/300], Step [3/225], Training Accuracy: 99.4792%, Training Loss: 0.0478%\n",
      "Epoch [132/300], Step [4/225], Training Accuracy: 99.2188%, Training Loss: 0.0441%\n",
      "Epoch [132/300], Step [5/225], Training Accuracy: 98.7500%, Training Loss: 0.0449%\n",
      "Epoch [132/300], Step [6/225], Training Accuracy: 98.9583%, Training Loss: 0.0410%\n",
      "Epoch [132/300], Step [7/225], Training Accuracy: 98.8839%, Training Loss: 0.0403%\n",
      "Epoch [132/300], Step [8/225], Training Accuracy: 99.0234%, Training Loss: 0.0371%\n",
      "Epoch [132/300], Step [9/225], Training Accuracy: 99.1319%, Training Loss: 0.0339%\n",
      "Epoch [132/300], Step [10/225], Training Accuracy: 99.2188%, Training Loss: 0.0337%\n",
      "Epoch [132/300], Step [11/225], Training Accuracy: 99.2898%, Training Loss: 0.0328%\n",
      "Epoch [132/300], Step [12/225], Training Accuracy: 99.3490%, Training Loss: 0.0320%\n",
      "Epoch [132/300], Step [13/225], Training Accuracy: 99.0385%, Training Loss: 0.0391%\n",
      "Epoch [132/300], Step [14/225], Training Accuracy: 99.1071%, Training Loss: 0.0398%\n",
      "Epoch [132/300], Step [15/225], Training Accuracy: 99.1667%, Training Loss: 0.0384%\n",
      "Epoch [132/300], Step [16/225], Training Accuracy: 99.1211%, Training Loss: 0.0381%\n",
      "Epoch [132/300], Step [17/225], Training Accuracy: 99.0809%, Training Loss: 0.0400%\n",
      "Epoch [132/300], Step [18/225], Training Accuracy: 98.7847%, Training Loss: 0.0442%\n",
      "Epoch [132/300], Step [19/225], Training Accuracy: 98.8487%, Training Loss: 0.0423%\n",
      "Epoch [132/300], Step [20/225], Training Accuracy: 98.7500%, Training Loss: 0.0424%\n",
      "Epoch [132/300], Step [21/225], Training Accuracy: 98.8095%, Training Loss: 0.0410%\n",
      "Epoch [132/300], Step [22/225], Training Accuracy: 98.8636%, Training Loss: 0.0398%\n",
      "Epoch [132/300], Step [23/225], Training Accuracy: 98.9130%, Training Loss: 0.0386%\n",
      "Epoch [132/300], Step [24/225], Training Accuracy: 98.9583%, Training Loss: 0.0387%\n",
      "Epoch [132/300], Step [25/225], Training Accuracy: 98.9375%, Training Loss: 0.0392%\n",
      "Epoch [132/300], Step [26/225], Training Accuracy: 98.9183%, Training Loss: 0.0384%\n",
      "Epoch [132/300], Step [27/225], Training Accuracy: 98.9005%, Training Loss: 0.0384%\n",
      "Epoch [132/300], Step [28/225], Training Accuracy: 98.9397%, Training Loss: 0.0379%\n",
      "Epoch [132/300], Step [29/225], Training Accuracy: 98.9224%, Training Loss: 0.0386%\n",
      "Epoch [132/300], Step [30/225], Training Accuracy: 98.8542%, Training Loss: 0.0399%\n",
      "Epoch [132/300], Step [31/225], Training Accuracy: 98.8407%, Training Loss: 0.0397%\n",
      "Epoch [132/300], Step [32/225], Training Accuracy: 98.8281%, Training Loss: 0.0398%\n",
      "Epoch [132/300], Step [33/225], Training Accuracy: 98.8163%, Training Loss: 0.0403%\n",
      "Epoch [132/300], Step [34/225], Training Accuracy: 98.8511%, Training Loss: 0.0399%\n",
      "Epoch [132/300], Step [35/225], Training Accuracy: 98.8393%, Training Loss: 0.0400%\n",
      "Epoch [132/300], Step [36/225], Training Accuracy: 98.8281%, Training Loss: 0.0407%\n",
      "Epoch [132/300], Step [37/225], Training Accuracy: 98.8598%, Training Loss: 0.0402%\n",
      "Epoch [132/300], Step [38/225], Training Accuracy: 98.8487%, Training Loss: 0.0403%\n",
      "Epoch [132/300], Step [39/225], Training Accuracy: 98.7981%, Training Loss: 0.0412%\n",
      "Epoch [132/300], Step [40/225], Training Accuracy: 98.8281%, Training Loss: 0.0404%\n",
      "Epoch [132/300], Step [41/225], Training Accuracy: 98.7805%, Training Loss: 0.0411%\n",
      "Epoch [132/300], Step [42/225], Training Accuracy: 98.8095%, Training Loss: 0.0406%\n",
      "Epoch [132/300], Step [43/225], Training Accuracy: 98.8372%, Training Loss: 0.0401%\n",
      "Epoch [132/300], Step [44/225], Training Accuracy: 98.8281%, Training Loss: 0.0398%\n",
      "Epoch [132/300], Step [45/225], Training Accuracy: 98.8542%, Training Loss: 0.0393%\n",
      "Epoch [132/300], Step [46/225], Training Accuracy: 98.8451%, Training Loss: 0.0392%\n",
      "Epoch [132/300], Step [47/225], Training Accuracy: 98.8697%, Training Loss: 0.0389%\n",
      "Epoch [132/300], Step [48/225], Training Accuracy: 98.8281%, Training Loss: 0.0391%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [132/300], Step [49/225], Training Accuracy: 98.8202%, Training Loss: 0.0392%\n",
      "Epoch [132/300], Step [50/225], Training Accuracy: 98.8438%, Training Loss: 0.0389%\n",
      "Epoch [132/300], Step [51/225], Training Accuracy: 98.8664%, Training Loss: 0.0385%\n",
      "Epoch [132/300], Step [52/225], Training Accuracy: 98.8582%, Training Loss: 0.0382%\n",
      "Epoch [132/300], Step [53/225], Training Accuracy: 98.8797%, Training Loss: 0.0380%\n",
      "Epoch [132/300], Step [54/225], Training Accuracy: 98.8426%, Training Loss: 0.0384%\n",
      "Epoch [132/300], Step [55/225], Training Accuracy: 98.8352%, Training Loss: 0.0389%\n",
      "Epoch [132/300], Step [56/225], Training Accuracy: 98.8281%, Training Loss: 0.0392%\n",
      "Epoch [132/300], Step [57/225], Training Accuracy: 98.8487%, Training Loss: 0.0392%\n",
      "Epoch [132/300], Step [58/225], Training Accuracy: 98.8416%, Training Loss: 0.0392%\n",
      "Epoch [132/300], Step [59/225], Training Accuracy: 98.8612%, Training Loss: 0.0390%\n",
      "Epoch [132/300], Step [60/225], Training Accuracy: 98.8542%, Training Loss: 0.0392%\n",
      "Epoch [132/300], Step [61/225], Training Accuracy: 98.8473%, Training Loss: 0.0392%\n",
      "Epoch [132/300], Step [62/225], Training Accuracy: 98.7399%, Training Loss: 0.0411%\n",
      "Epoch [132/300], Step [63/225], Training Accuracy: 98.7599%, Training Loss: 0.0410%\n",
      "Epoch [132/300], Step [64/225], Training Accuracy: 98.6816%, Training Loss: 0.0423%\n",
      "Epoch [132/300], Step [65/225], Training Accuracy: 98.7019%, Training Loss: 0.0421%\n",
      "Epoch [132/300], Step [66/225], Training Accuracy: 98.6979%, Training Loss: 0.0420%\n",
      "Epoch [132/300], Step [67/225], Training Accuracy: 98.6940%, Training Loss: 0.0418%\n",
      "Epoch [132/300], Step [68/225], Training Accuracy: 98.6673%, Training Loss: 0.0419%\n",
      "Epoch [132/300], Step [69/225], Training Accuracy: 98.6639%, Training Loss: 0.0420%\n",
      "Epoch [132/300], Step [70/225], Training Accuracy: 98.6607%, Training Loss: 0.0419%\n",
      "Epoch [132/300], Step [71/225], Training Accuracy: 98.6796%, Training Loss: 0.0419%\n",
      "Epoch [132/300], Step [72/225], Training Accuracy: 98.6979%, Training Loss: 0.0419%\n",
      "Epoch [132/300], Step [73/225], Training Accuracy: 98.7158%, Training Loss: 0.0418%\n",
      "Epoch [132/300], Step [74/225], Training Accuracy: 98.7120%, Training Loss: 0.0421%\n",
      "Epoch [132/300], Step [75/225], Training Accuracy: 98.7292%, Training Loss: 0.0418%\n",
      "Epoch [132/300], Step [76/225], Training Accuracy: 98.7253%, Training Loss: 0.0417%\n",
      "Epoch [132/300], Step [77/225], Training Accuracy: 98.7216%, Training Loss: 0.0419%\n",
      "Epoch [132/300], Step [78/225], Training Accuracy: 98.7380%, Training Loss: 0.0417%\n",
      "Epoch [132/300], Step [79/225], Training Accuracy: 98.7342%, Training Loss: 0.0417%\n",
      "Epoch [132/300], Step [80/225], Training Accuracy: 98.7109%, Training Loss: 0.0419%\n",
      "Epoch [132/300], Step [81/225], Training Accuracy: 98.7269%, Training Loss: 0.0416%\n",
      "Epoch [132/300], Step [82/225], Training Accuracy: 98.7233%, Training Loss: 0.0417%\n",
      "Epoch [132/300], Step [83/225], Training Accuracy: 98.7199%, Training Loss: 0.0420%\n",
      "Epoch [132/300], Step [84/225], Training Accuracy: 98.7351%, Training Loss: 0.0420%\n",
      "Epoch [132/300], Step [85/225], Training Accuracy: 98.7500%, Training Loss: 0.0418%\n",
      "Epoch [132/300], Step [86/225], Training Accuracy: 98.7645%, Training Loss: 0.0418%\n",
      "Epoch [132/300], Step [87/225], Training Accuracy: 98.7608%, Training Loss: 0.0419%\n",
      "Epoch [132/300], Step [88/225], Training Accuracy: 98.7393%, Training Loss: 0.0422%\n",
      "Epoch [132/300], Step [89/225], Training Accuracy: 98.7535%, Training Loss: 0.0421%\n",
      "Epoch [132/300], Step [90/225], Training Accuracy: 98.7674%, Training Loss: 0.0419%\n",
      "Epoch [132/300], Step [91/225], Training Accuracy: 98.7637%, Training Loss: 0.0417%\n",
      "Epoch [132/300], Step [92/225], Training Accuracy: 98.7772%, Training Loss: 0.0415%\n",
      "Epoch [132/300], Step [93/225], Training Accuracy: 98.7735%, Training Loss: 0.0414%\n",
      "Epoch [132/300], Step [94/225], Training Accuracy: 98.7699%, Training Loss: 0.0414%\n",
      "Epoch [132/300], Step [95/225], Training Accuracy: 98.7500%, Training Loss: 0.0416%\n",
      "Epoch [132/300], Step [96/225], Training Accuracy: 98.7630%, Training Loss: 0.0415%\n",
      "Epoch [132/300], Step [97/225], Training Accuracy: 98.7436%, Training Loss: 0.0417%\n",
      "Epoch [132/300], Step [98/225], Training Accuracy: 98.7404%, Training Loss: 0.0417%\n",
      "Epoch [132/300], Step [99/225], Training Accuracy: 98.7374%, Training Loss: 0.0417%\n",
      "Epoch [132/300], Step [100/225], Training Accuracy: 98.7031%, Training Loss: 0.0423%\n",
      "Epoch [132/300], Step [101/225], Training Accuracy: 98.7005%, Training Loss: 0.0424%\n",
      "Epoch [132/300], Step [102/225], Training Accuracy: 98.6979%, Training Loss: 0.0424%\n",
      "Epoch [132/300], Step [103/225], Training Accuracy: 98.6954%, Training Loss: 0.0423%\n",
      "Epoch [132/300], Step [104/225], Training Accuracy: 98.6929%, Training Loss: 0.0422%\n",
      "Epoch [132/300], Step [105/225], Training Accuracy: 98.7054%, Training Loss: 0.0420%\n",
      "Epoch [132/300], Step [106/225], Training Accuracy: 98.7176%, Training Loss: 0.0419%\n",
      "Epoch [132/300], Step [107/225], Training Accuracy: 98.7296%, Training Loss: 0.0416%\n",
      "Epoch [132/300], Step [108/225], Training Accuracy: 98.7413%, Training Loss: 0.0415%\n",
      "Epoch [132/300], Step [109/225], Training Accuracy: 98.7529%, Training Loss: 0.0413%\n",
      "Epoch [132/300], Step [110/225], Training Accuracy: 98.7642%, Training Loss: 0.0411%\n",
      "Epoch [132/300], Step [111/225], Training Accuracy: 98.7753%, Training Loss: 0.0408%\n",
      "Epoch [132/300], Step [112/225], Training Accuracy: 98.7723%, Training Loss: 0.0411%\n",
      "Epoch [132/300], Step [113/225], Training Accuracy: 98.7694%, Training Loss: 0.0410%\n",
      "Epoch [132/300], Step [114/225], Training Accuracy: 98.7802%, Training Loss: 0.0409%\n",
      "Epoch [132/300], Step [115/225], Training Accuracy: 98.7636%, Training Loss: 0.0409%\n",
      "Epoch [132/300], Step [116/225], Training Accuracy: 98.7742%, Training Loss: 0.0408%\n",
      "Epoch [132/300], Step [117/225], Training Accuracy: 98.7714%, Training Loss: 0.0407%\n",
      "Epoch [132/300], Step [118/225], Training Accuracy: 98.7685%, Training Loss: 0.0406%\n",
      "Epoch [132/300], Step [119/225], Training Accuracy: 98.7658%, Training Loss: 0.0407%\n",
      "Epoch [132/300], Step [120/225], Training Accuracy: 98.7630%, Training Loss: 0.0406%\n",
      "Epoch [132/300], Step [121/225], Training Accuracy: 98.7474%, Training Loss: 0.0409%\n",
      "Epoch [132/300], Step [122/225], Training Accuracy: 98.7321%, Training Loss: 0.0411%\n",
      "Epoch [132/300], Step [123/225], Training Accuracy: 98.7043%, Training Loss: 0.0414%\n",
      "Epoch [132/300], Step [124/225], Training Accuracy: 98.7147%, Training Loss: 0.0412%\n",
      "Epoch [132/300], Step [125/225], Training Accuracy: 98.6750%, Training Loss: 0.0417%\n",
      "Epoch [132/300], Step [126/225], Training Accuracy: 98.6731%, Training Loss: 0.0417%\n",
      "Epoch [132/300], Step [127/225], Training Accuracy: 98.6713%, Training Loss: 0.0419%\n",
      "Epoch [132/300], Step [128/225], Training Accuracy: 98.6816%, Training Loss: 0.0419%\n",
      "Epoch [132/300], Step [129/225], Training Accuracy: 98.6676%, Training Loss: 0.0420%\n",
      "Epoch [132/300], Step [130/225], Training Accuracy: 98.6538%, Training Loss: 0.0421%\n",
      "Epoch [132/300], Step [131/225], Training Accuracy: 98.6522%, Training Loss: 0.0421%\n",
      "Epoch [132/300], Step [132/225], Training Accuracy: 98.6506%, Training Loss: 0.0423%\n",
      "Epoch [132/300], Step [133/225], Training Accuracy: 98.6372%, Training Loss: 0.0427%\n",
      "Epoch [132/300], Step [134/225], Training Accuracy: 98.6357%, Training Loss: 0.0427%\n",
      "Epoch [132/300], Step [135/225], Training Accuracy: 98.6458%, Training Loss: 0.0425%\n",
      "Epoch [132/300], Step [136/225], Training Accuracy: 98.6558%, Training Loss: 0.0424%\n",
      "Epoch [132/300], Step [137/225], Training Accuracy: 98.6656%, Training Loss: 0.0422%\n",
      "Epoch [132/300], Step [138/225], Training Accuracy: 98.6639%, Training Loss: 0.0423%\n",
      "Epoch [132/300], Step [139/225], Training Accuracy: 98.6511%, Training Loss: 0.0425%\n",
      "Epoch [132/300], Step [140/225], Training Accuracy: 98.6384%, Training Loss: 0.0428%\n",
      "Epoch [132/300], Step [141/225], Training Accuracy: 98.6370%, Training Loss: 0.0428%\n",
      "Epoch [132/300], Step [142/225], Training Accuracy: 98.6356%, Training Loss: 0.0428%\n",
      "Epoch [132/300], Step [143/225], Training Accuracy: 98.6342%, Training Loss: 0.0429%\n",
      "Epoch [132/300], Step [144/225], Training Accuracy: 98.6437%, Training Loss: 0.0429%\n",
      "Epoch [132/300], Step [145/225], Training Accuracy: 98.6422%, Training Loss: 0.0429%\n",
      "Epoch [132/300], Step [146/225], Training Accuracy: 98.6515%, Training Loss: 0.0428%\n",
      "Epoch [132/300], Step [147/225], Training Accuracy: 98.6395%, Training Loss: 0.0432%\n",
      "Epoch [132/300], Step [148/225], Training Accuracy: 98.6486%, Training Loss: 0.0431%\n",
      "Epoch [132/300], Step [149/225], Training Accuracy: 98.6367%, Training Loss: 0.0434%\n",
      "Epoch [132/300], Step [150/225], Training Accuracy: 98.6458%, Training Loss: 0.0432%\n",
      "Epoch [132/300], Step [151/225], Training Accuracy: 98.6445%, Training Loss: 0.0432%\n",
      "Epoch [132/300], Step [152/225], Training Accuracy: 98.6431%, Training Loss: 0.0431%\n",
      "Epoch [132/300], Step [153/225], Training Accuracy: 98.6417%, Training Loss: 0.0432%\n",
      "Epoch [132/300], Step [154/225], Training Accuracy: 98.6303%, Training Loss: 0.0434%\n",
      "Epoch [132/300], Step [155/225], Training Accuracy: 98.6391%, Training Loss: 0.0432%\n",
      "Epoch [132/300], Step [156/225], Training Accuracy: 98.6478%, Training Loss: 0.0431%\n",
      "Epoch [132/300], Step [157/225], Training Accuracy: 98.6465%, Training Loss: 0.0431%\n",
      "Epoch [132/300], Step [158/225], Training Accuracy: 98.6452%, Training Loss: 0.0430%\n",
      "Epoch [132/300], Step [159/225], Training Accuracy: 98.6537%, Training Loss: 0.0429%\n",
      "Epoch [132/300], Step [160/225], Training Accuracy: 98.6621%, Training Loss: 0.0428%\n",
      "Epoch [132/300], Step [161/225], Training Accuracy: 98.6704%, Training Loss: 0.0427%\n",
      "Epoch [132/300], Step [162/225], Training Accuracy: 98.6593%, Training Loss: 0.0429%\n",
      "Epoch [132/300], Step [163/225], Training Accuracy: 98.6580%, Training Loss: 0.0430%\n",
      "Epoch [132/300], Step [164/225], Training Accuracy: 98.6662%, Training Loss: 0.0429%\n",
      "Epoch [132/300], Step [165/225], Training Accuracy: 98.6553%, Training Loss: 0.0429%\n",
      "Epoch [132/300], Step [166/225], Training Accuracy: 98.6634%, Training Loss: 0.0428%\n",
      "Epoch [132/300], Step [167/225], Training Accuracy: 98.6714%, Training Loss: 0.0427%\n",
      "Epoch [132/300], Step [168/225], Training Accuracy: 98.6607%, Training Loss: 0.0427%\n",
      "Epoch [132/300], Step [169/225], Training Accuracy: 98.6594%, Training Loss: 0.0427%\n",
      "Epoch [132/300], Step [170/225], Training Accuracy: 98.6581%, Training Loss: 0.0429%\n",
      "Epoch [132/300], Step [171/225], Training Accuracy: 98.6477%, Training Loss: 0.0432%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [132/300], Step [172/225], Training Accuracy: 98.6555%, Training Loss: 0.0431%\n",
      "Epoch [132/300], Step [173/225], Training Accuracy: 98.6362%, Training Loss: 0.0432%\n",
      "Epoch [132/300], Step [174/225], Training Accuracy: 98.6261%, Training Loss: 0.0432%\n",
      "Epoch [132/300], Step [175/225], Training Accuracy: 98.6339%, Training Loss: 0.0430%\n",
      "Epoch [132/300], Step [176/225], Training Accuracy: 98.6417%, Training Loss: 0.0429%\n",
      "Epoch [132/300], Step [177/225], Training Accuracy: 98.6494%, Training Loss: 0.0429%\n",
      "Epoch [132/300], Step [178/225], Training Accuracy: 98.6570%, Training Loss: 0.0427%\n",
      "Epoch [132/300], Step [179/225], Training Accuracy: 98.6557%, Training Loss: 0.0426%\n",
      "Epoch [132/300], Step [180/225], Training Accuracy: 98.6545%, Training Loss: 0.0428%\n",
      "Epoch [132/300], Step [181/225], Training Accuracy: 98.6533%, Training Loss: 0.0428%\n",
      "Epoch [132/300], Step [182/225], Training Accuracy: 98.6521%, Training Loss: 0.0428%\n",
      "Epoch [132/300], Step [183/225], Training Accuracy: 98.6510%, Training Loss: 0.0428%\n",
      "Epoch [132/300], Step [184/225], Training Accuracy: 98.6498%, Training Loss: 0.0428%\n",
      "Epoch [132/300], Step [185/225], Training Accuracy: 98.6571%, Training Loss: 0.0427%\n",
      "Epoch [132/300], Step [186/225], Training Accuracy: 98.6559%, Training Loss: 0.0427%\n",
      "Epoch [132/300], Step [187/225], Training Accuracy: 98.6547%, Training Loss: 0.0426%\n",
      "Epoch [132/300], Step [188/225], Training Accuracy: 98.6619%, Training Loss: 0.0426%\n",
      "Epoch [132/300], Step [189/225], Training Accuracy: 98.6607%, Training Loss: 0.0426%\n",
      "Epoch [132/300], Step [190/225], Training Accuracy: 98.6513%, Training Loss: 0.0430%\n",
      "Epoch [132/300], Step [191/225], Training Accuracy: 98.6420%, Training Loss: 0.0433%\n",
      "Epoch [132/300], Step [192/225], Training Accuracy: 98.6410%, Training Loss: 0.0432%\n",
      "Epoch [132/300], Step [193/225], Training Accuracy: 98.6399%, Training Loss: 0.0434%\n",
      "Epoch [132/300], Step [194/225], Training Accuracy: 98.6389%, Training Loss: 0.0436%\n",
      "Epoch [132/300], Step [195/225], Training Accuracy: 98.6378%, Training Loss: 0.0436%\n",
      "Epoch [132/300], Step [196/225], Training Accuracy: 98.6368%, Training Loss: 0.0436%\n",
      "Epoch [132/300], Step [197/225], Training Accuracy: 98.6437%, Training Loss: 0.0435%\n",
      "Epoch [132/300], Step [198/225], Training Accuracy: 98.6506%, Training Loss: 0.0434%\n",
      "Epoch [132/300], Step [199/225], Training Accuracy: 98.6416%, Training Loss: 0.0435%\n",
      "Epoch [132/300], Step [200/225], Training Accuracy: 98.6328%, Training Loss: 0.0436%\n",
      "Epoch [132/300], Step [201/225], Training Accuracy: 98.6318%, Training Loss: 0.0437%\n",
      "Epoch [132/300], Step [202/225], Training Accuracy: 98.6309%, Training Loss: 0.0437%\n",
      "Epoch [132/300], Step [203/225], Training Accuracy: 98.6376%, Training Loss: 0.0435%\n",
      "Epoch [132/300], Step [204/225], Training Accuracy: 98.6443%, Training Loss: 0.0434%\n",
      "Epoch [132/300], Step [205/225], Training Accuracy: 98.6280%, Training Loss: 0.0436%\n",
      "Epoch [132/300], Step [206/225], Training Accuracy: 98.6347%, Training Loss: 0.0435%\n",
      "Epoch [132/300], Step [207/225], Training Accuracy: 98.6338%, Training Loss: 0.0435%\n",
      "Epoch [132/300], Step [208/225], Training Accuracy: 98.6403%, Training Loss: 0.0434%\n",
      "Epoch [132/300], Step [209/225], Training Accuracy: 98.6319%, Training Loss: 0.0435%\n",
      "Epoch [132/300], Step [210/225], Training Accuracy: 98.6384%, Training Loss: 0.0434%\n",
      "Epoch [132/300], Step [211/225], Training Accuracy: 98.6374%, Training Loss: 0.0434%\n",
      "Epoch [132/300], Step [212/225], Training Accuracy: 98.6365%, Training Loss: 0.0434%\n",
      "Epoch [132/300], Step [213/225], Training Accuracy: 98.6429%, Training Loss: 0.0433%\n",
      "Epoch [132/300], Step [214/225], Training Accuracy: 98.6273%, Training Loss: 0.0436%\n",
      "Epoch [132/300], Step [215/225], Training Accuracy: 98.6265%, Training Loss: 0.0436%\n",
      "Epoch [132/300], Step [216/225], Training Accuracy: 98.6183%, Training Loss: 0.0438%\n",
      "Epoch [132/300], Step [217/225], Training Accuracy: 98.6175%, Training Loss: 0.0438%\n",
      "Epoch [132/300], Step [218/225], Training Accuracy: 98.6024%, Training Loss: 0.0440%\n",
      "Epoch [132/300], Step [219/225], Training Accuracy: 98.6087%, Training Loss: 0.0439%\n",
      "Epoch [132/300], Step [220/225], Training Accuracy: 98.6080%, Training Loss: 0.0438%\n",
      "Epoch [132/300], Step [221/225], Training Accuracy: 98.6001%, Training Loss: 0.0440%\n",
      "Epoch [132/300], Step [222/225], Training Accuracy: 98.5994%, Training Loss: 0.0441%\n",
      "Epoch [132/300], Step [223/225], Training Accuracy: 98.5987%, Training Loss: 0.0440%\n",
      "Epoch [132/300], Step [224/225], Training Accuracy: 98.6049%, Training Loss: 0.0439%\n",
      "Epoch [132/300], Step [225/225], Training Accuracy: 98.6103%, Training Loss: 0.0438%\n",
      "Epoch [133/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0284%\n",
      "Epoch [133/300], Step [2/225], Training Accuracy: 98.4375%, Training Loss: 0.0482%\n",
      "Epoch [133/300], Step [3/225], Training Accuracy: 96.8750%, Training Loss: 0.0658%\n",
      "Epoch [133/300], Step [4/225], Training Accuracy: 97.6562%, Training Loss: 0.0514%\n",
      "Epoch [133/300], Step [5/225], Training Accuracy: 97.8125%, Training Loss: 0.0486%\n",
      "Epoch [133/300], Step [6/225], Training Accuracy: 98.1771%, Training Loss: 0.0460%\n",
      "Epoch [133/300], Step [7/225], Training Accuracy: 98.4375%, Training Loss: 0.0423%\n",
      "Epoch [133/300], Step [8/225], Training Accuracy: 98.6328%, Training Loss: 0.0400%\n",
      "Epoch [133/300], Step [9/225], Training Accuracy: 98.6111%, Training Loss: 0.0387%\n",
      "Epoch [133/300], Step [10/225], Training Accuracy: 98.4375%, Training Loss: 0.0413%\n",
      "Epoch [133/300], Step [11/225], Training Accuracy: 98.5795%, Training Loss: 0.0393%\n",
      "Epoch [133/300], Step [12/225], Training Accuracy: 98.6979%, Training Loss: 0.0372%\n",
      "Epoch [133/300], Step [13/225], Training Accuracy: 98.5577%, Training Loss: 0.0401%\n",
      "Epoch [133/300], Step [14/225], Training Accuracy: 98.5491%, Training Loss: 0.0393%\n",
      "Epoch [133/300], Step [15/225], Training Accuracy: 98.6458%, Training Loss: 0.0382%\n",
      "Epoch [133/300], Step [16/225], Training Accuracy: 98.7305%, Training Loss: 0.0365%\n",
      "Epoch [133/300], Step [17/225], Training Accuracy: 98.8051%, Training Loss: 0.0368%\n",
      "Epoch [133/300], Step [18/225], Training Accuracy: 98.6111%, Training Loss: 0.0414%\n",
      "Epoch [133/300], Step [19/225], Training Accuracy: 98.5197%, Training Loss: 0.0431%\n",
      "Epoch [133/300], Step [20/225], Training Accuracy: 98.5938%, Training Loss: 0.0417%\n",
      "Epoch [133/300], Step [21/225], Training Accuracy: 98.6607%, Training Loss: 0.0412%\n",
      "Epoch [133/300], Step [22/225], Training Accuracy: 98.6506%, Training Loss: 0.0422%\n",
      "Epoch [133/300], Step [23/225], Training Accuracy: 98.6413%, Training Loss: 0.0425%\n",
      "Epoch [133/300], Step [24/225], Training Accuracy: 98.6328%, Training Loss: 0.0431%\n",
      "Epoch [133/300], Step [25/225], Training Accuracy: 98.6250%, Training Loss: 0.0434%\n",
      "Epoch [133/300], Step [26/225], Training Accuracy: 98.6178%, Training Loss: 0.0445%\n",
      "Epoch [133/300], Step [27/225], Training Accuracy: 98.4954%, Training Loss: 0.0478%\n",
      "Epoch [133/300], Step [28/225], Training Accuracy: 98.4933%, Training Loss: 0.0474%\n",
      "Epoch [133/300], Step [29/225], Training Accuracy: 98.3836%, Training Loss: 0.0498%\n",
      "Epoch [133/300], Step [30/225], Training Accuracy: 98.4375%, Training Loss: 0.0487%\n",
      "Epoch [133/300], Step [31/225], Training Accuracy: 98.3367%, Training Loss: 0.0495%\n",
      "Epoch [133/300], Step [32/225], Training Accuracy: 98.3887%, Training Loss: 0.0482%\n",
      "Epoch [133/300], Step [33/225], Training Accuracy: 98.3902%, Training Loss: 0.0479%\n",
      "Epoch [133/300], Step [34/225], Training Accuracy: 98.4375%, Training Loss: 0.0470%\n",
      "Epoch [133/300], Step [35/225], Training Accuracy: 98.3929%, Training Loss: 0.0494%\n",
      "Epoch [133/300], Step [36/225], Training Accuracy: 98.3941%, Training Loss: 0.0490%\n",
      "Epoch [133/300], Step [37/225], Training Accuracy: 98.4375%, Training Loss: 0.0482%\n",
      "Epoch [133/300], Step [38/225], Training Accuracy: 98.4786%, Training Loss: 0.0476%\n",
      "Epoch [133/300], Step [39/225], Training Accuracy: 98.4375%, Training Loss: 0.0491%\n",
      "Epoch [133/300], Step [40/225], Training Accuracy: 98.4375%, Training Loss: 0.0488%\n",
      "Epoch [133/300], Step [41/225], Training Accuracy: 98.4375%, Training Loss: 0.0488%\n",
      "Epoch [133/300], Step [42/225], Training Accuracy: 98.4747%, Training Loss: 0.0482%\n",
      "Epoch [133/300], Step [43/225], Training Accuracy: 98.4375%, Training Loss: 0.0484%\n",
      "Epoch [133/300], Step [44/225], Training Accuracy: 98.3665%, Training Loss: 0.0494%\n",
      "Epoch [133/300], Step [45/225], Training Accuracy: 98.4028%, Training Loss: 0.0491%\n",
      "Epoch [133/300], Step [46/225], Training Accuracy: 98.3696%, Training Loss: 0.0493%\n",
      "Epoch [133/300], Step [47/225], Training Accuracy: 98.4043%, Training Loss: 0.0488%\n",
      "Epoch [133/300], Step [48/225], Training Accuracy: 98.4375%, Training Loss: 0.0481%\n",
      "Epoch [133/300], Step [49/225], Training Accuracy: 98.4056%, Training Loss: 0.0484%\n",
      "Epoch [133/300], Step [50/225], Training Accuracy: 98.4062%, Training Loss: 0.0489%\n",
      "Epoch [133/300], Step [51/225], Training Accuracy: 98.4375%, Training Loss: 0.0484%\n",
      "Epoch [133/300], Step [52/225], Training Accuracy: 98.4375%, Training Loss: 0.0487%\n",
      "Epoch [133/300], Step [53/225], Training Accuracy: 98.4670%, Training Loss: 0.0484%\n",
      "Epoch [133/300], Step [54/225], Training Accuracy: 98.4954%, Training Loss: 0.0479%\n",
      "Epoch [133/300], Step [55/225], Training Accuracy: 98.4943%, Training Loss: 0.0481%\n",
      "Epoch [133/300], Step [56/225], Training Accuracy: 98.4654%, Training Loss: 0.0487%\n",
      "Epoch [133/300], Step [57/225], Training Accuracy: 98.4923%, Training Loss: 0.0487%\n",
      "Epoch [133/300], Step [58/225], Training Accuracy: 98.4914%, Training Loss: 0.0489%\n",
      "Epoch [133/300], Step [59/225], Training Accuracy: 98.4640%, Training Loss: 0.0492%\n",
      "Epoch [133/300], Step [60/225], Training Accuracy: 98.4635%, Training Loss: 0.0489%\n",
      "Epoch [133/300], Step [61/225], Training Accuracy: 98.4631%, Training Loss: 0.0490%\n",
      "Epoch [133/300], Step [62/225], Training Accuracy: 98.4627%, Training Loss: 0.0487%\n",
      "Epoch [133/300], Step [63/225], Training Accuracy: 98.4623%, Training Loss: 0.0486%\n",
      "Epoch [133/300], Step [64/225], Training Accuracy: 98.4863%, Training Loss: 0.0483%\n",
      "Epoch [133/300], Step [65/225], Training Accuracy: 98.5096%, Training Loss: 0.0479%\n",
      "Epoch [133/300], Step [66/225], Training Accuracy: 98.4848%, Training Loss: 0.0480%\n",
      "Epoch [133/300], Step [67/225], Training Accuracy: 98.5075%, Training Loss: 0.0475%\n",
      "Epoch [133/300], Step [68/225], Training Accuracy: 98.5064%, Training Loss: 0.0473%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [133/300], Step [69/225], Training Accuracy: 98.4828%, Training Loss: 0.0480%\n",
      "Epoch [133/300], Step [70/225], Training Accuracy: 98.4821%, Training Loss: 0.0479%\n",
      "Epoch [133/300], Step [71/225], Training Accuracy: 98.4375%, Training Loss: 0.0486%\n",
      "Epoch [133/300], Step [72/225], Training Accuracy: 98.4592%, Training Loss: 0.0482%\n",
      "Epoch [133/300], Step [73/225], Training Accuracy: 98.4803%, Training Loss: 0.0479%\n",
      "Epoch [133/300], Step [74/225], Training Accuracy: 98.4797%, Training Loss: 0.0479%\n",
      "Epoch [133/300], Step [75/225], Training Accuracy: 98.4792%, Training Loss: 0.0480%\n",
      "Epoch [133/300], Step [76/225], Training Accuracy: 98.4581%, Training Loss: 0.0480%\n",
      "Epoch [133/300], Step [77/225], Training Accuracy: 98.4172%, Training Loss: 0.0484%\n",
      "Epoch [133/300], Step [78/225], Training Accuracy: 98.4375%, Training Loss: 0.0482%\n",
      "Epoch [133/300], Step [79/225], Training Accuracy: 98.4177%, Training Loss: 0.0483%\n",
      "Epoch [133/300], Step [80/225], Training Accuracy: 98.4375%, Training Loss: 0.0482%\n",
      "Epoch [133/300], Step [81/225], Training Accuracy: 98.4568%, Training Loss: 0.0479%\n",
      "Epoch [133/300], Step [82/225], Training Accuracy: 98.4756%, Training Loss: 0.0477%\n",
      "Epoch [133/300], Step [83/225], Training Accuracy: 98.4752%, Training Loss: 0.0481%\n",
      "Epoch [133/300], Step [84/225], Training Accuracy: 98.4933%, Training Loss: 0.0478%\n",
      "Epoch [133/300], Step [85/225], Training Accuracy: 98.5110%, Training Loss: 0.0475%\n",
      "Epoch [133/300], Step [86/225], Training Accuracy: 98.5283%, Training Loss: 0.0472%\n",
      "Epoch [133/300], Step [87/225], Training Accuracy: 98.5273%, Training Loss: 0.0471%\n",
      "Epoch [133/300], Step [88/225], Training Accuracy: 98.5263%, Training Loss: 0.0469%\n",
      "Epoch [133/300], Step [89/225], Training Accuracy: 98.5253%, Training Loss: 0.0468%\n",
      "Epoch [133/300], Step [90/225], Training Accuracy: 98.5243%, Training Loss: 0.0468%\n",
      "Epoch [133/300], Step [91/225], Training Accuracy: 98.5405%, Training Loss: 0.0466%\n",
      "Epoch [133/300], Step [92/225], Training Accuracy: 98.5394%, Training Loss: 0.0466%\n",
      "Epoch [133/300], Step [93/225], Training Accuracy: 98.5215%, Training Loss: 0.0468%\n",
      "Epoch [133/300], Step [94/225], Training Accuracy: 98.5372%, Training Loss: 0.0466%\n",
      "Epoch [133/300], Step [95/225], Training Accuracy: 98.5362%, Training Loss: 0.0463%\n",
      "Epoch [133/300], Step [96/225], Training Accuracy: 98.5026%, Training Loss: 0.0465%\n",
      "Epoch [133/300], Step [97/225], Training Accuracy: 98.5019%, Training Loss: 0.0465%\n",
      "Epoch [133/300], Step [98/225], Training Accuracy: 98.4853%, Training Loss: 0.0468%\n",
      "Epoch [133/300], Step [99/225], Training Accuracy: 98.4691%, Training Loss: 0.0469%\n",
      "Epoch [133/300], Step [100/225], Training Accuracy: 98.4844%, Training Loss: 0.0465%\n",
      "Epoch [133/300], Step [101/225], Training Accuracy: 98.4684%, Training Loss: 0.0466%\n",
      "Epoch [133/300], Step [102/225], Training Accuracy: 98.4681%, Training Loss: 0.0467%\n",
      "Epoch [133/300], Step [103/225], Training Accuracy: 98.4527%, Training Loss: 0.0468%\n",
      "Epoch [133/300], Step [104/225], Training Accuracy: 98.4675%, Training Loss: 0.0464%\n",
      "Epoch [133/300], Step [105/225], Training Accuracy: 98.4673%, Training Loss: 0.0462%\n",
      "Epoch [133/300], Step [106/225], Training Accuracy: 98.4817%, Training Loss: 0.0461%\n",
      "Epoch [133/300], Step [107/225], Training Accuracy: 98.4959%, Training Loss: 0.0458%\n",
      "Epoch [133/300], Step [108/225], Training Accuracy: 98.4954%, Training Loss: 0.0460%\n",
      "Epoch [133/300], Step [109/225], Training Accuracy: 98.4948%, Training Loss: 0.0465%\n",
      "Epoch [133/300], Step [110/225], Training Accuracy: 98.4801%, Training Loss: 0.0466%\n",
      "Epoch [133/300], Step [111/225], Training Accuracy: 98.4797%, Training Loss: 0.0467%\n",
      "Epoch [133/300], Step [112/225], Training Accuracy: 98.4933%, Training Loss: 0.0466%\n",
      "Epoch [133/300], Step [113/225], Training Accuracy: 98.5066%, Training Loss: 0.0463%\n",
      "Epoch [133/300], Step [114/225], Training Accuracy: 98.5060%, Training Loss: 0.0463%\n",
      "Epoch [133/300], Step [115/225], Training Accuracy: 98.5190%, Training Loss: 0.0460%\n",
      "Epoch [133/300], Step [116/225], Training Accuracy: 98.5318%, Training Loss: 0.0458%\n",
      "Epoch [133/300], Step [117/225], Training Accuracy: 98.5443%, Training Loss: 0.0454%\n",
      "Epoch [133/300], Step [118/225], Training Accuracy: 98.5567%, Training Loss: 0.0452%\n",
      "Epoch [133/300], Step [119/225], Training Accuracy: 98.5557%, Training Loss: 0.0453%\n",
      "Epoch [133/300], Step [120/225], Training Accuracy: 98.5677%, Training Loss: 0.0451%\n",
      "Epoch [133/300], Step [121/225], Training Accuracy: 98.5666%, Training Loss: 0.0449%\n",
      "Epoch [133/300], Step [122/225], Training Accuracy: 98.5656%, Training Loss: 0.0449%\n",
      "Epoch [133/300], Step [123/225], Training Accuracy: 98.5645%, Training Loss: 0.0449%\n",
      "Epoch [133/300], Step [124/225], Training Accuracy: 98.5509%, Training Loss: 0.0450%\n",
      "Epoch [133/300], Step [125/225], Training Accuracy: 98.5500%, Training Loss: 0.0450%\n",
      "Epoch [133/300], Step [126/225], Training Accuracy: 98.5491%, Training Loss: 0.0450%\n",
      "Epoch [133/300], Step [127/225], Training Accuracy: 98.5482%, Training Loss: 0.0449%\n",
      "Epoch [133/300], Step [128/225], Training Accuracy: 98.5596%, Training Loss: 0.0448%\n",
      "Epoch [133/300], Step [129/225], Training Accuracy: 98.5586%, Training Loss: 0.0449%\n",
      "Epoch [133/300], Step [130/225], Training Accuracy: 98.5337%, Training Loss: 0.0459%\n",
      "Epoch [133/300], Step [131/225], Training Accuracy: 98.5448%, Training Loss: 0.0456%\n",
      "Epoch [133/300], Step [132/225], Training Accuracy: 98.5440%, Training Loss: 0.0458%\n",
      "Epoch [133/300], Step [133/225], Training Accuracy: 98.5550%, Training Loss: 0.0457%\n",
      "Epoch [133/300], Step [134/225], Training Accuracy: 98.5541%, Training Loss: 0.0457%\n",
      "Epoch [133/300], Step [135/225], Training Accuracy: 98.5648%, Training Loss: 0.0454%\n",
      "Epoch [133/300], Step [136/225], Training Accuracy: 98.5754%, Training Loss: 0.0453%\n",
      "Epoch [133/300], Step [137/225], Training Accuracy: 98.5744%, Training Loss: 0.0451%\n",
      "Epoch [133/300], Step [138/225], Training Accuracy: 98.5847%, Training Loss: 0.0450%\n",
      "Epoch [133/300], Step [139/225], Training Accuracy: 98.5724%, Training Loss: 0.0451%\n",
      "Epoch [133/300], Step [140/225], Training Accuracy: 98.5826%, Training Loss: 0.0450%\n",
      "Epoch [133/300], Step [141/225], Training Accuracy: 98.5816%, Training Loss: 0.0450%\n",
      "Epoch [133/300], Step [142/225], Training Accuracy: 98.5915%, Training Loss: 0.0449%\n",
      "Epoch [133/300], Step [143/225], Training Accuracy: 98.6014%, Training Loss: 0.0448%\n",
      "Epoch [133/300], Step [144/225], Training Accuracy: 98.6003%, Training Loss: 0.0447%\n",
      "Epoch [133/300], Step [145/225], Training Accuracy: 98.6099%, Training Loss: 0.0444%\n",
      "Epoch [133/300], Step [146/225], Training Accuracy: 98.6087%, Training Loss: 0.0444%\n",
      "Epoch [133/300], Step [147/225], Training Accuracy: 98.6076%, Training Loss: 0.0443%\n",
      "Epoch [133/300], Step [148/225], Training Accuracy: 98.6170%, Training Loss: 0.0442%\n",
      "Epoch [133/300], Step [149/225], Training Accuracy: 98.6053%, Training Loss: 0.0447%\n",
      "Epoch [133/300], Step [150/225], Training Accuracy: 98.6146%, Training Loss: 0.0445%\n",
      "Epoch [133/300], Step [151/225], Training Accuracy: 98.6134%, Training Loss: 0.0444%\n",
      "Epoch [133/300], Step [152/225], Training Accuracy: 98.6225%, Training Loss: 0.0442%\n",
      "Epoch [133/300], Step [153/225], Training Accuracy: 98.6009%, Training Loss: 0.0443%\n",
      "Epoch [133/300], Step [154/225], Training Accuracy: 98.5795%, Training Loss: 0.0445%\n",
      "Epoch [133/300], Step [155/225], Training Accuracy: 98.5786%, Training Loss: 0.0445%\n",
      "Epoch [133/300], Step [156/225], Training Accuracy: 98.5877%, Training Loss: 0.0443%\n",
      "Epoch [133/300], Step [157/225], Training Accuracy: 98.5967%, Training Loss: 0.0442%\n",
      "Epoch [133/300], Step [158/225], Training Accuracy: 98.5957%, Training Loss: 0.0442%\n",
      "Epoch [133/300], Step [159/225], Training Accuracy: 98.5947%, Training Loss: 0.0443%\n",
      "Epoch [133/300], Step [160/225], Training Accuracy: 98.5938%, Training Loss: 0.0443%\n",
      "Epoch [133/300], Step [161/225], Training Accuracy: 98.6025%, Training Loss: 0.0441%\n",
      "Epoch [133/300], Step [162/225], Training Accuracy: 98.5918%, Training Loss: 0.0443%\n",
      "Epoch [133/300], Step [163/225], Training Accuracy: 98.6005%, Training Loss: 0.0441%\n",
      "Epoch [133/300], Step [164/225], Training Accuracy: 98.6090%, Training Loss: 0.0440%\n",
      "Epoch [133/300], Step [165/225], Training Accuracy: 98.6174%, Training Loss: 0.0438%\n",
      "Epoch [133/300], Step [166/225], Training Accuracy: 98.6258%, Training Loss: 0.0437%\n",
      "Epoch [133/300], Step [167/225], Training Accuracy: 98.6246%, Training Loss: 0.0437%\n",
      "Epoch [133/300], Step [168/225], Training Accuracy: 98.6328%, Training Loss: 0.0435%\n",
      "Epoch [133/300], Step [169/225], Training Accuracy: 98.6224%, Training Loss: 0.0437%\n",
      "Epoch [133/300], Step [170/225], Training Accuracy: 98.6213%, Training Loss: 0.0437%\n",
      "Epoch [133/300], Step [171/225], Training Accuracy: 98.6202%, Training Loss: 0.0436%\n",
      "Epoch [133/300], Step [172/225], Training Accuracy: 98.6283%, Training Loss: 0.0434%\n",
      "Epoch [133/300], Step [173/225], Training Accuracy: 98.6362%, Training Loss: 0.0433%\n",
      "Epoch [133/300], Step [174/225], Training Accuracy: 98.6440%, Training Loss: 0.0432%\n",
      "Epoch [133/300], Step [175/225], Training Accuracy: 98.6429%, Training Loss: 0.0432%\n",
      "Epoch [133/300], Step [176/225], Training Accuracy: 98.6506%, Training Loss: 0.0430%\n",
      "Epoch [133/300], Step [177/225], Training Accuracy: 98.6494%, Training Loss: 0.0432%\n",
      "Epoch [133/300], Step [178/225], Training Accuracy: 98.6570%, Training Loss: 0.0431%\n",
      "Epoch [133/300], Step [179/225], Training Accuracy: 98.6557%, Training Loss: 0.0432%\n",
      "Epoch [133/300], Step [180/225], Training Accuracy: 98.6632%, Training Loss: 0.0432%\n",
      "Epoch [133/300], Step [181/225], Training Accuracy: 98.6706%, Training Loss: 0.0430%\n",
      "Epoch [133/300], Step [182/225], Training Accuracy: 98.6779%, Training Loss: 0.0429%\n",
      "Epoch [133/300], Step [183/225], Training Accuracy: 98.6766%, Training Loss: 0.0430%\n",
      "Epoch [133/300], Step [184/225], Training Accuracy: 98.6668%, Training Loss: 0.0431%\n",
      "Epoch [133/300], Step [185/225], Training Accuracy: 98.6740%, Training Loss: 0.0429%\n",
      "Epoch [133/300], Step [186/225], Training Accuracy: 98.6811%, Training Loss: 0.0428%\n",
      "Epoch [133/300], Step [187/225], Training Accuracy: 98.6882%, Training Loss: 0.0427%\n",
      "Epoch [133/300], Step [188/225], Training Accuracy: 98.6785%, Training Loss: 0.0427%\n",
      "Epoch [133/300], Step [189/225], Training Accuracy: 98.6855%, Training Loss: 0.0426%\n",
      "Epoch [133/300], Step [190/225], Training Accuracy: 98.6842%, Training Loss: 0.0427%\n",
      "Epoch [133/300], Step [191/225], Training Accuracy: 98.6911%, Training Loss: 0.0426%\n",
      "Epoch [133/300], Step [192/225], Training Accuracy: 98.6654%, Training Loss: 0.0429%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [133/300], Step [193/225], Training Accuracy: 98.6642%, Training Loss: 0.0430%\n",
      "Epoch [133/300], Step [194/225], Training Accuracy: 98.6711%, Training Loss: 0.0428%\n",
      "Epoch [133/300], Step [195/225], Training Accuracy: 98.6619%, Training Loss: 0.0430%\n",
      "Epoch [133/300], Step [196/225], Training Accuracy: 98.6607%, Training Loss: 0.0431%\n",
      "Epoch [133/300], Step [197/225], Training Accuracy: 98.6596%, Training Loss: 0.0431%\n",
      "Epoch [133/300], Step [198/225], Training Accuracy: 98.6506%, Training Loss: 0.0435%\n",
      "Epoch [133/300], Step [199/225], Training Accuracy: 98.6495%, Training Loss: 0.0435%\n",
      "Epoch [133/300], Step [200/225], Training Accuracy: 98.6406%, Training Loss: 0.0437%\n",
      "Epoch [133/300], Step [201/225], Training Accuracy: 98.6396%, Training Loss: 0.0437%\n",
      "Epoch [133/300], Step [202/225], Training Accuracy: 98.6463%, Training Loss: 0.0437%\n",
      "Epoch [133/300], Step [203/225], Training Accuracy: 98.6376%, Training Loss: 0.0439%\n",
      "Epoch [133/300], Step [204/225], Training Accuracy: 98.6213%, Training Loss: 0.0442%\n",
      "Epoch [133/300], Step [205/225], Training Accuracy: 98.6280%, Training Loss: 0.0441%\n",
      "Epoch [133/300], Step [206/225], Training Accuracy: 98.6195%, Training Loss: 0.0441%\n",
      "Epoch [133/300], Step [207/225], Training Accuracy: 98.6187%, Training Loss: 0.0440%\n",
      "Epoch [133/300], Step [208/225], Training Accuracy: 98.6253%, Training Loss: 0.0439%\n",
      "Epoch [133/300], Step [209/225], Training Accuracy: 98.6319%, Training Loss: 0.0438%\n",
      "Epoch [133/300], Step [210/225], Training Accuracy: 98.6235%, Training Loss: 0.0441%\n",
      "Epoch [133/300], Step [211/225], Training Accuracy: 98.6226%, Training Loss: 0.0441%\n",
      "Epoch [133/300], Step [212/225], Training Accuracy: 98.6291%, Training Loss: 0.0440%\n",
      "Epoch [133/300], Step [213/225], Training Accuracy: 98.6356%, Training Loss: 0.0441%\n",
      "Epoch [133/300], Step [214/225], Training Accuracy: 98.6346%, Training Loss: 0.0441%\n",
      "Epoch [133/300], Step [215/225], Training Accuracy: 98.6337%, Training Loss: 0.0442%\n",
      "Epoch [133/300], Step [216/225], Training Accuracy: 98.6256%, Training Loss: 0.0445%\n",
      "Epoch [133/300], Step [217/225], Training Accuracy: 98.6319%, Training Loss: 0.0444%\n",
      "Epoch [133/300], Step [218/225], Training Accuracy: 98.6310%, Training Loss: 0.0445%\n",
      "Epoch [133/300], Step [219/225], Training Accuracy: 98.6373%, Training Loss: 0.0444%\n",
      "Epoch [133/300], Step [220/225], Training Accuracy: 98.6435%, Training Loss: 0.0443%\n",
      "Epoch [133/300], Step [221/225], Training Accuracy: 98.6496%, Training Loss: 0.0442%\n",
      "Epoch [133/300], Step [222/225], Training Accuracy: 98.6557%, Training Loss: 0.0441%\n",
      "Epoch [133/300], Step [223/225], Training Accuracy: 98.6477%, Training Loss: 0.0442%\n",
      "Epoch [133/300], Step [224/225], Training Accuracy: 98.6537%, Training Loss: 0.0442%\n",
      "Epoch [133/300], Step [225/225], Training Accuracy: 98.6590%, Training Loss: 0.0441%\n",
      "Epoch [134/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0181%\n",
      "Epoch [134/300], Step [2/225], Training Accuracy: 98.4375%, Training Loss: 0.0356%\n",
      "Epoch [134/300], Step [3/225], Training Accuracy: 96.3542%, Training Loss: 0.0561%\n",
      "Epoch [134/300], Step [4/225], Training Accuracy: 96.8750%, Training Loss: 0.0630%\n",
      "Epoch [134/300], Step [5/225], Training Accuracy: 97.1875%, Training Loss: 0.0566%\n",
      "Epoch [134/300], Step [6/225], Training Accuracy: 97.6562%, Training Loss: 0.0530%\n",
      "Epoch [134/300], Step [7/225], Training Accuracy: 97.7679%, Training Loss: 0.0547%\n",
      "Epoch [134/300], Step [8/225], Training Accuracy: 97.6562%, Training Loss: 0.0564%\n",
      "Epoch [134/300], Step [9/225], Training Accuracy: 97.5694%, Training Loss: 0.0591%\n",
      "Epoch [134/300], Step [10/225], Training Accuracy: 97.3438%, Training Loss: 0.0634%\n",
      "Epoch [134/300], Step [11/225], Training Accuracy: 97.4432%, Training Loss: 0.0610%\n",
      "Epoch [134/300], Step [12/225], Training Accuracy: 97.6562%, Training Loss: 0.0581%\n",
      "Epoch [134/300], Step [13/225], Training Accuracy: 97.5962%, Training Loss: 0.0582%\n",
      "Epoch [134/300], Step [14/225], Training Accuracy: 97.6562%, Training Loss: 0.0583%\n",
      "Epoch [134/300], Step [15/225], Training Accuracy: 97.7083%, Training Loss: 0.0567%\n",
      "Epoch [134/300], Step [16/225], Training Accuracy: 97.7539%, Training Loss: 0.0555%\n",
      "Epoch [134/300], Step [17/225], Training Accuracy: 97.8860%, Training Loss: 0.0545%\n",
      "Epoch [134/300], Step [18/225], Training Accuracy: 97.6562%, Training Loss: 0.0588%\n",
      "Epoch [134/300], Step [19/225], Training Accuracy: 97.6151%, Training Loss: 0.0589%\n",
      "Epoch [134/300], Step [20/225], Training Accuracy: 97.7344%, Training Loss: 0.0569%\n",
      "Epoch [134/300], Step [21/225], Training Accuracy: 97.7679%, Training Loss: 0.0565%\n",
      "Epoch [134/300], Step [22/225], Training Accuracy: 97.8693%, Training Loss: 0.0557%\n",
      "Epoch [134/300], Step [23/225], Training Accuracy: 97.8940%, Training Loss: 0.0548%\n",
      "Epoch [134/300], Step [24/225], Training Accuracy: 97.9818%, Training Loss: 0.0547%\n",
      "Epoch [134/300], Step [25/225], Training Accuracy: 98.0000%, Training Loss: 0.0546%\n",
      "Epoch [134/300], Step [26/225], Training Accuracy: 97.9567%, Training Loss: 0.0594%\n",
      "Epoch [134/300], Step [27/225], Training Accuracy: 98.0324%, Training Loss: 0.0586%\n",
      "Epoch [134/300], Step [28/225], Training Accuracy: 98.1027%, Training Loss: 0.0572%\n",
      "Epoch [134/300], Step [29/225], Training Accuracy: 98.1142%, Training Loss: 0.0562%\n",
      "Epoch [134/300], Step [30/225], Training Accuracy: 98.0729%, Training Loss: 0.0584%\n",
      "Epoch [134/300], Step [31/225], Training Accuracy: 97.9839%, Training Loss: 0.0597%\n",
      "Epoch [134/300], Step [32/225], Training Accuracy: 97.9980%, Training Loss: 0.0592%\n",
      "Epoch [134/300], Step [33/225], Training Accuracy: 98.0114%, Training Loss: 0.0582%\n",
      "Epoch [134/300], Step [34/225], Training Accuracy: 98.0699%, Training Loss: 0.0570%\n",
      "Epoch [134/300], Step [35/225], Training Accuracy: 98.0804%, Training Loss: 0.0585%\n",
      "Epoch [134/300], Step [36/225], Training Accuracy: 98.0469%, Training Loss: 0.0591%\n",
      "Epoch [134/300], Step [37/225], Training Accuracy: 98.0152%, Training Loss: 0.0589%\n",
      "Epoch [134/300], Step [38/225], Training Accuracy: 97.9030%, Training Loss: 0.0600%\n",
      "Epoch [134/300], Step [39/225], Training Accuracy: 97.9167%, Training Loss: 0.0594%\n",
      "Epoch [134/300], Step [40/225], Training Accuracy: 97.9688%, Training Loss: 0.0589%\n",
      "Epoch [134/300], Step [41/225], Training Accuracy: 97.9040%, Training Loss: 0.0594%\n",
      "Epoch [134/300], Step [42/225], Training Accuracy: 97.9539%, Training Loss: 0.0589%\n",
      "Epoch [134/300], Step [43/225], Training Accuracy: 97.9288%, Training Loss: 0.0586%\n",
      "Epoch [134/300], Step [44/225], Training Accuracy: 97.9403%, Training Loss: 0.0580%\n",
      "Epoch [134/300], Step [45/225], Training Accuracy: 97.9514%, Training Loss: 0.0578%\n",
      "Epoch [134/300], Step [46/225], Training Accuracy: 97.9280%, Training Loss: 0.0580%\n",
      "Epoch [134/300], Step [47/225], Training Accuracy: 97.8391%, Training Loss: 0.0588%\n",
      "Epoch [134/300], Step [48/225], Training Accuracy: 97.8516%, Training Loss: 0.0587%\n",
      "Epoch [134/300], Step [49/225], Training Accuracy: 97.7997%, Training Loss: 0.0595%\n",
      "Epoch [134/300], Step [50/225], Training Accuracy: 97.7812%, Training Loss: 0.0593%\n",
      "Epoch [134/300], Step [51/225], Training Accuracy: 97.8248%, Training Loss: 0.0585%\n",
      "Epoch [134/300], Step [52/225], Training Accuracy: 97.8666%, Training Loss: 0.0578%\n",
      "Epoch [134/300], Step [53/225], Training Accuracy: 97.8184%, Training Loss: 0.0582%\n",
      "Epoch [134/300], Step [54/225], Training Accuracy: 97.8299%, Training Loss: 0.0580%\n",
      "Epoch [134/300], Step [55/225], Training Accuracy: 97.8409%, Training Loss: 0.0583%\n",
      "Epoch [134/300], Step [56/225], Training Accuracy: 97.8795%, Training Loss: 0.0577%\n",
      "Epoch [134/300], Step [57/225], Training Accuracy: 97.8893%, Training Loss: 0.0574%\n",
      "Epoch [134/300], Step [58/225], Training Accuracy: 97.8987%, Training Loss: 0.0572%\n",
      "Epoch [134/300], Step [59/225], Training Accuracy: 97.9343%, Training Loss: 0.0566%\n",
      "Epoch [134/300], Step [60/225], Training Accuracy: 97.9427%, Training Loss: 0.0566%\n",
      "Epoch [134/300], Step [61/225], Training Accuracy: 97.8996%, Training Loss: 0.0569%\n",
      "Epoch [134/300], Step [62/225], Training Accuracy: 97.9335%, Training Loss: 0.0565%\n",
      "Epoch [134/300], Step [63/225], Training Accuracy: 97.8919%, Training Loss: 0.0575%\n",
      "Epoch [134/300], Step [64/225], Training Accuracy: 97.9248%, Training Loss: 0.0571%\n",
      "Epoch [134/300], Step [65/225], Training Accuracy: 97.9567%, Training Loss: 0.0566%\n",
      "Epoch [134/300], Step [66/225], Training Accuracy: 97.9403%, Training Loss: 0.0565%\n",
      "Epoch [134/300], Step [67/225], Training Accuracy: 97.9478%, Training Loss: 0.0560%\n",
      "Epoch [134/300], Step [68/225], Training Accuracy: 97.9779%, Training Loss: 0.0555%\n",
      "Epoch [134/300], Step [69/225], Training Accuracy: 98.0072%, Training Loss: 0.0548%\n",
      "Epoch [134/300], Step [70/225], Training Accuracy: 98.0357%, Training Loss: 0.0543%\n",
      "Epoch [134/300], Step [71/225], Training Accuracy: 98.0634%, Training Loss: 0.0538%\n",
      "Epoch [134/300], Step [72/225], Training Accuracy: 98.0686%, Training Loss: 0.0536%\n",
      "Epoch [134/300], Step [73/225], Training Accuracy: 98.0950%, Training Loss: 0.0532%\n",
      "Epoch [134/300], Step [74/225], Training Accuracy: 98.0997%, Training Loss: 0.0531%\n",
      "Epoch [134/300], Step [75/225], Training Accuracy: 98.1042%, Training Loss: 0.0530%\n",
      "Epoch [134/300], Step [76/225], Training Accuracy: 98.0469%, Training Loss: 0.0539%\n",
      "Epoch [134/300], Step [77/225], Training Accuracy: 98.0114%, Training Loss: 0.0546%\n",
      "Epoch [134/300], Step [78/225], Training Accuracy: 98.0168%, Training Loss: 0.0544%\n",
      "Epoch [134/300], Step [79/225], Training Accuracy: 98.0222%, Training Loss: 0.0543%\n",
      "Epoch [134/300], Step [80/225], Training Accuracy: 98.0273%, Training Loss: 0.0541%\n",
      "Epoch [134/300], Step [81/225], Training Accuracy: 98.0517%, Training Loss: 0.0535%\n",
      "Epoch [134/300], Step [82/225], Training Accuracy: 98.0183%, Training Loss: 0.0546%\n",
      "Epoch [134/300], Step [83/225], Training Accuracy: 98.0422%, Training Loss: 0.0544%\n",
      "Epoch [134/300], Step [84/225], Training Accuracy: 98.0469%, Training Loss: 0.0543%\n",
      "Epoch [134/300], Step [85/225], Training Accuracy: 98.0699%, Training Loss: 0.0540%\n",
      "Epoch [134/300], Step [86/225], Training Accuracy: 98.0560%, Training Loss: 0.0542%\n",
      "Epoch [134/300], Step [87/225], Training Accuracy: 98.0603%, Training Loss: 0.0543%\n",
      "Epoch [134/300], Step [88/225], Training Accuracy: 98.0469%, Training Loss: 0.0545%\n",
      "Epoch [134/300], Step [89/225], Training Accuracy: 98.0513%, Training Loss: 0.0544%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [134/300], Step [90/225], Training Accuracy: 98.0729%, Training Loss: 0.0544%\n",
      "Epoch [134/300], Step [91/225], Training Accuracy: 98.0941%, Training Loss: 0.0542%\n",
      "Epoch [134/300], Step [92/225], Training Accuracy: 98.0639%, Training Loss: 0.0543%\n",
      "Epoch [134/300], Step [93/225], Training Accuracy: 98.0847%, Training Loss: 0.0538%\n",
      "Epoch [134/300], Step [94/225], Training Accuracy: 98.0884%, Training Loss: 0.0541%\n",
      "Epoch [134/300], Step [95/225], Training Accuracy: 98.1086%, Training Loss: 0.0538%\n",
      "Epoch [134/300], Step [96/225], Training Accuracy: 98.1120%, Training Loss: 0.0537%\n",
      "Epoch [134/300], Step [97/225], Training Accuracy: 98.1314%, Training Loss: 0.0534%\n",
      "Epoch [134/300], Step [98/225], Training Accuracy: 98.1346%, Training Loss: 0.0534%\n",
      "Epoch [134/300], Step [99/225], Training Accuracy: 98.1534%, Training Loss: 0.0532%\n",
      "Epoch [134/300], Step [100/225], Training Accuracy: 98.1094%, Training Loss: 0.0536%\n",
      "Epoch [134/300], Step [101/225], Training Accuracy: 98.0972%, Training Loss: 0.0537%\n",
      "Epoch [134/300], Step [102/225], Training Accuracy: 98.0852%, Training Loss: 0.0540%\n",
      "Epoch [134/300], Step [103/225], Training Accuracy: 98.1038%, Training Loss: 0.0539%\n",
      "Epoch [134/300], Step [104/225], Training Accuracy: 98.1220%, Training Loss: 0.0535%\n",
      "Epoch [134/300], Step [105/225], Training Accuracy: 98.1399%, Training Loss: 0.0533%\n",
      "Epoch [134/300], Step [106/225], Training Accuracy: 98.1574%, Training Loss: 0.0531%\n",
      "Epoch [134/300], Step [107/225], Training Accuracy: 98.1600%, Training Loss: 0.0534%\n",
      "Epoch [134/300], Step [108/225], Training Accuracy: 98.1626%, Training Loss: 0.0532%\n",
      "Epoch [134/300], Step [109/225], Training Accuracy: 98.1651%, Training Loss: 0.0532%\n",
      "Epoch [134/300], Step [110/225], Training Accuracy: 98.1676%, Training Loss: 0.0530%\n",
      "Epoch [134/300], Step [111/225], Training Accuracy: 98.1841%, Training Loss: 0.0527%\n",
      "Epoch [134/300], Step [112/225], Training Accuracy: 98.1724%, Training Loss: 0.0528%\n",
      "Epoch [134/300], Step [113/225], Training Accuracy: 98.1886%, Training Loss: 0.0525%\n",
      "Epoch [134/300], Step [114/225], Training Accuracy: 98.1908%, Training Loss: 0.0525%\n",
      "Epoch [134/300], Step [115/225], Training Accuracy: 98.2065%, Training Loss: 0.0523%\n",
      "Epoch [134/300], Step [116/225], Training Accuracy: 98.2220%, Training Loss: 0.0520%\n",
      "Epoch [134/300], Step [117/225], Training Accuracy: 98.2372%, Training Loss: 0.0517%\n",
      "Epoch [134/300], Step [118/225], Training Accuracy: 98.2521%, Training Loss: 0.0516%\n",
      "Epoch [134/300], Step [119/225], Training Accuracy: 98.2668%, Training Loss: 0.0514%\n",
      "Epoch [134/300], Step [120/225], Training Accuracy: 98.2682%, Training Loss: 0.0513%\n",
      "Epoch [134/300], Step [121/225], Training Accuracy: 98.2825%, Training Loss: 0.0510%\n",
      "Epoch [134/300], Step [122/225], Training Accuracy: 98.2838%, Training Loss: 0.0511%\n",
      "Epoch [134/300], Step [123/225], Training Accuracy: 98.2851%, Training Loss: 0.0510%\n",
      "Epoch [134/300], Step [124/225], Training Accuracy: 98.2863%, Training Loss: 0.0508%\n",
      "Epoch [134/300], Step [125/225], Training Accuracy: 98.2875%, Training Loss: 0.0507%\n",
      "Epoch [134/300], Step [126/225], Training Accuracy: 98.2639%, Training Loss: 0.0511%\n",
      "Epoch [134/300], Step [127/225], Training Accuracy: 98.2283%, Training Loss: 0.0516%\n",
      "Epoch [134/300], Step [128/225], Training Accuracy: 98.2056%, Training Loss: 0.0523%\n",
      "Epoch [134/300], Step [129/225], Training Accuracy: 98.2195%, Training Loss: 0.0520%\n",
      "Epoch [134/300], Step [130/225], Training Accuracy: 98.2091%, Training Loss: 0.0521%\n",
      "Epoch [134/300], Step [131/225], Training Accuracy: 98.2109%, Training Loss: 0.0520%\n",
      "Epoch [134/300], Step [132/225], Training Accuracy: 98.1652%, Training Loss: 0.0530%\n",
      "Epoch [134/300], Step [133/225], Training Accuracy: 98.1790%, Training Loss: 0.0527%\n",
      "Epoch [134/300], Step [134/225], Training Accuracy: 98.1926%, Training Loss: 0.0524%\n",
      "Epoch [134/300], Step [135/225], Training Accuracy: 98.2060%, Training Loss: 0.0522%\n",
      "Epoch [134/300], Step [136/225], Training Accuracy: 98.2192%, Training Loss: 0.0519%\n",
      "Epoch [134/300], Step [137/225], Training Accuracy: 98.2208%, Training Loss: 0.0520%\n",
      "Epoch [134/300], Step [138/225], Training Accuracy: 98.2337%, Training Loss: 0.0517%\n",
      "Epoch [134/300], Step [139/225], Training Accuracy: 98.2352%, Training Loss: 0.0519%\n",
      "Epoch [134/300], Step [140/225], Training Accuracy: 98.2254%, Training Loss: 0.0522%\n",
      "Epoch [134/300], Step [141/225], Training Accuracy: 98.2048%, Training Loss: 0.0525%\n",
      "Epoch [134/300], Step [142/225], Training Accuracy: 98.1844%, Training Loss: 0.0533%\n",
      "Epoch [134/300], Step [143/225], Training Accuracy: 98.1862%, Training Loss: 0.0534%\n",
      "Epoch [134/300], Step [144/225], Training Accuracy: 98.1988%, Training Loss: 0.0532%\n",
      "Epoch [134/300], Step [145/225], Training Accuracy: 98.2112%, Training Loss: 0.0529%\n",
      "Epoch [134/300], Step [146/225], Training Accuracy: 98.2021%, Training Loss: 0.0532%\n",
      "Epoch [134/300], Step [147/225], Training Accuracy: 98.2143%, Training Loss: 0.0532%\n",
      "Epoch [134/300], Step [148/225], Training Accuracy: 98.2158%, Training Loss: 0.0532%\n",
      "Epoch [134/300], Step [149/225], Training Accuracy: 98.2068%, Training Loss: 0.0535%\n",
      "Epoch [134/300], Step [150/225], Training Accuracy: 98.2188%, Training Loss: 0.0533%\n",
      "Epoch [134/300], Step [151/225], Training Accuracy: 98.2305%, Training Loss: 0.0532%\n",
      "Epoch [134/300], Step [152/225], Training Accuracy: 98.2319%, Training Loss: 0.0530%\n",
      "Epoch [134/300], Step [153/225], Training Accuracy: 98.2333%, Training Loss: 0.0529%\n",
      "Epoch [134/300], Step [154/225], Training Accuracy: 98.2346%, Training Loss: 0.0529%\n",
      "Epoch [134/300], Step [155/225], Training Accuracy: 98.2460%, Training Loss: 0.0527%\n",
      "Epoch [134/300], Step [156/225], Training Accuracy: 98.2472%, Training Loss: 0.0527%\n",
      "Epoch [134/300], Step [157/225], Training Accuracy: 98.2285%, Training Loss: 0.0532%\n",
      "Epoch [134/300], Step [158/225], Training Accuracy: 98.2298%, Training Loss: 0.0531%\n",
      "Epoch [134/300], Step [159/225], Training Accuracy: 98.2410%, Training Loss: 0.0530%\n",
      "Epoch [134/300], Step [160/225], Training Accuracy: 98.2422%, Training Loss: 0.0530%\n",
      "Epoch [134/300], Step [161/225], Training Accuracy: 98.2434%, Training Loss: 0.0528%\n",
      "Epoch [134/300], Step [162/225], Training Accuracy: 98.2350%, Training Loss: 0.0529%\n",
      "Epoch [134/300], Step [163/225], Training Accuracy: 98.2458%, Training Loss: 0.0528%\n",
      "Epoch [134/300], Step [164/225], Training Accuracy: 98.2565%, Training Loss: 0.0526%\n",
      "Epoch [134/300], Step [165/225], Training Accuracy: 98.2481%, Training Loss: 0.0525%\n",
      "Epoch [134/300], Step [166/225], Training Accuracy: 98.2492%, Training Loss: 0.0524%\n",
      "Epoch [134/300], Step [167/225], Training Accuracy: 98.2317%, Training Loss: 0.0529%\n",
      "Epoch [134/300], Step [168/225], Training Accuracy: 98.2422%, Training Loss: 0.0527%\n",
      "Epoch [134/300], Step [169/225], Training Accuracy: 98.2433%, Training Loss: 0.0526%\n",
      "Epoch [134/300], Step [170/225], Training Accuracy: 98.2445%, Training Loss: 0.0526%\n",
      "Epoch [134/300], Step [171/225], Training Accuracy: 98.2548%, Training Loss: 0.0527%\n",
      "Epoch [134/300], Step [172/225], Training Accuracy: 98.2558%, Training Loss: 0.0527%\n",
      "Epoch [134/300], Step [173/225], Training Accuracy: 98.2659%, Training Loss: 0.0525%\n",
      "Epoch [134/300], Step [174/225], Training Accuracy: 98.2759%, Training Loss: 0.0523%\n",
      "Epoch [134/300], Step [175/225], Training Accuracy: 98.2857%, Training Loss: 0.0522%\n",
      "Epoch [134/300], Step [176/225], Training Accuracy: 98.2777%, Training Loss: 0.0524%\n",
      "Epoch [134/300], Step [177/225], Training Accuracy: 98.2786%, Training Loss: 0.0524%\n",
      "Epoch [134/300], Step [178/225], Training Accuracy: 98.2795%, Training Loss: 0.0524%\n",
      "Epoch [134/300], Step [179/225], Training Accuracy: 98.2629%, Training Loss: 0.0527%\n",
      "Epoch [134/300], Step [180/225], Training Accuracy: 98.2726%, Training Loss: 0.0524%\n",
      "Epoch [134/300], Step [181/225], Training Accuracy: 98.2648%, Training Loss: 0.0525%\n",
      "Epoch [134/300], Step [182/225], Training Accuracy: 98.2744%, Training Loss: 0.0523%\n",
      "Epoch [134/300], Step [183/225], Training Accuracy: 98.2838%, Training Loss: 0.0522%\n",
      "Epoch [134/300], Step [184/225], Training Accuracy: 98.2931%, Training Loss: 0.0520%\n",
      "Epoch [134/300], Step [185/225], Training Accuracy: 98.2939%, Training Loss: 0.0520%\n",
      "Epoch [134/300], Step [186/225], Training Accuracy: 98.2863%, Training Loss: 0.0521%\n",
      "Epoch [134/300], Step [187/225], Training Accuracy: 98.2871%, Training Loss: 0.0521%\n",
      "Epoch [134/300], Step [188/225], Training Accuracy: 98.2962%, Training Loss: 0.0520%\n",
      "Epoch [134/300], Step [189/225], Training Accuracy: 98.3052%, Training Loss: 0.0518%\n",
      "Epoch [134/300], Step [190/225], Training Accuracy: 98.3141%, Training Loss: 0.0518%\n",
      "Epoch [134/300], Step [191/225], Training Accuracy: 98.3066%, Training Loss: 0.0520%\n",
      "Epoch [134/300], Step [192/225], Training Accuracy: 98.3154%, Training Loss: 0.0518%\n",
      "Epoch [134/300], Step [193/225], Training Accuracy: 98.2999%, Training Loss: 0.0519%\n",
      "Epoch [134/300], Step [194/225], Training Accuracy: 98.3086%, Training Loss: 0.0518%\n",
      "Epoch [134/300], Step [195/225], Training Accuracy: 98.3093%, Training Loss: 0.0518%\n",
      "Epoch [134/300], Step [196/225], Training Accuracy: 98.3099%, Training Loss: 0.0517%\n",
      "Epoch [134/300], Step [197/225], Training Accuracy: 98.3185%, Training Loss: 0.0516%\n",
      "Epoch [134/300], Step [198/225], Training Accuracy: 98.3112%, Training Loss: 0.0517%\n",
      "Epoch [134/300], Step [199/225], Training Accuracy: 98.3197%, Training Loss: 0.0516%\n",
      "Epoch [134/300], Step [200/225], Training Accuracy: 98.3281%, Training Loss: 0.0515%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [134/300], Step [201/225], Training Accuracy: 98.3209%, Training Loss: 0.0518%\n",
      "Epoch [134/300], Step [202/225], Training Accuracy: 98.3215%, Training Loss: 0.0517%\n",
      "Epoch [134/300], Step [203/225], Training Accuracy: 98.3143%, Training Loss: 0.0519%\n",
      "Epoch [134/300], Step [204/225], Training Accuracy: 98.3073%, Training Loss: 0.0521%\n",
      "Epoch [134/300], Step [205/225], Training Accuracy: 98.3003%, Training Loss: 0.0521%\n",
      "Epoch [134/300], Step [206/225], Training Accuracy: 98.3010%, Training Loss: 0.0520%\n",
      "Epoch [134/300], Step [207/225], Training Accuracy: 98.3092%, Training Loss: 0.0520%\n",
      "Epoch [134/300], Step [208/225], Training Accuracy: 98.3173%, Training Loss: 0.0518%\n",
      "Epoch [134/300], Step [209/225], Training Accuracy: 98.3254%, Training Loss: 0.0518%\n",
      "Epoch [134/300], Step [210/225], Training Accuracy: 98.3333%, Training Loss: 0.0516%\n",
      "Epoch [134/300], Step [211/225], Training Accuracy: 98.3190%, Training Loss: 0.0518%\n",
      "Epoch [134/300], Step [212/225], Training Accuracy: 98.3196%, Training Loss: 0.0517%\n",
      "Epoch [134/300], Step [213/225], Training Accuracy: 98.3201%, Training Loss: 0.0518%\n",
      "Epoch [134/300], Step [214/225], Training Accuracy: 98.3207%, Training Loss: 0.0520%\n",
      "Epoch [134/300], Step [215/225], Training Accuracy: 98.3285%, Training Loss: 0.0518%\n",
      "Epoch [134/300], Step [216/225], Training Accuracy: 98.3290%, Training Loss: 0.0518%\n",
      "Epoch [134/300], Step [217/225], Training Accuracy: 98.3367%, Training Loss: 0.0516%\n",
      "Epoch [134/300], Step [218/225], Training Accuracy: 98.3443%, Training Loss: 0.0515%\n",
      "Epoch [134/300], Step [219/225], Training Accuracy: 98.3519%, Training Loss: 0.0515%\n",
      "Epoch [134/300], Step [220/225], Training Accuracy: 98.3523%, Training Loss: 0.0514%\n",
      "Epoch [134/300], Step [221/225], Training Accuracy: 98.3527%, Training Loss: 0.0515%\n",
      "Epoch [134/300], Step [222/225], Training Accuracy: 98.3530%, Training Loss: 0.0515%\n",
      "Epoch [134/300], Step [223/225], Training Accuracy: 98.3464%, Training Loss: 0.0516%\n",
      "Epoch [134/300], Step [224/225], Training Accuracy: 98.3538%, Training Loss: 0.0514%\n",
      "Epoch [134/300], Step [225/225], Training Accuracy: 98.3533%, Training Loss: 0.0513%\n",
      "Epoch [135/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0317%\n",
      "Epoch [135/300], Step [2/225], Training Accuracy: 99.2188%, Training Loss: 0.0351%\n",
      "Epoch [135/300], Step [3/225], Training Accuracy: 98.9583%, Training Loss: 0.0381%\n",
      "Epoch [135/300], Step [4/225], Training Accuracy: 98.4375%, Training Loss: 0.0473%\n",
      "Epoch [135/300], Step [5/225], Training Accuracy: 98.7500%, Training Loss: 0.0422%\n",
      "Epoch [135/300], Step [6/225], Training Accuracy: 98.4375%, Training Loss: 0.0468%\n",
      "Epoch [135/300], Step [7/225], Training Accuracy: 98.6607%, Training Loss: 0.0477%\n",
      "Epoch [135/300], Step [8/225], Training Accuracy: 98.4375%, Training Loss: 0.0474%\n",
      "Epoch [135/300], Step [9/225], Training Accuracy: 98.4375%, Training Loss: 0.0445%\n",
      "Epoch [135/300], Step [10/225], Training Accuracy: 98.2812%, Training Loss: 0.0475%\n",
      "Epoch [135/300], Step [11/225], Training Accuracy: 98.4375%, Training Loss: 0.0481%\n",
      "Epoch [135/300], Step [12/225], Training Accuracy: 98.3073%, Training Loss: 0.0519%\n",
      "Epoch [135/300], Step [13/225], Training Accuracy: 98.3173%, Training Loss: 0.0496%\n",
      "Epoch [135/300], Step [14/225], Training Accuracy: 98.3259%, Training Loss: 0.0488%\n",
      "Epoch [135/300], Step [15/225], Training Accuracy: 98.3333%, Training Loss: 0.0486%\n",
      "Epoch [135/300], Step [16/225], Training Accuracy: 98.2422%, Training Loss: 0.0485%\n",
      "Epoch [135/300], Step [17/225], Training Accuracy: 98.3456%, Training Loss: 0.0473%\n",
      "Epoch [135/300], Step [18/225], Training Accuracy: 98.3507%, Training Loss: 0.0485%\n",
      "Epoch [135/300], Step [19/225], Training Accuracy: 98.3553%, Training Loss: 0.0486%\n",
      "Epoch [135/300], Step [20/225], Training Accuracy: 98.3594%, Training Loss: 0.0483%\n",
      "Epoch [135/300], Step [21/225], Training Accuracy: 98.4375%, Training Loss: 0.0473%\n",
      "Epoch [135/300], Step [22/225], Training Accuracy: 98.5085%, Training Loss: 0.0458%\n",
      "Epoch [135/300], Step [23/225], Training Accuracy: 98.5054%, Training Loss: 0.0454%\n",
      "Epoch [135/300], Step [24/225], Training Accuracy: 98.5677%, Training Loss: 0.0445%\n",
      "Epoch [135/300], Step [25/225], Training Accuracy: 98.5625%, Training Loss: 0.0442%\n",
      "Epoch [135/300], Step [26/225], Training Accuracy: 98.3774%, Training Loss: 0.0460%\n",
      "Epoch [135/300], Step [27/225], Training Accuracy: 98.3218%, Training Loss: 0.0481%\n",
      "Epoch [135/300], Step [28/225], Training Accuracy: 98.3817%, Training Loss: 0.0468%\n",
      "Epoch [135/300], Step [29/225], Training Accuracy: 98.4375%, Training Loss: 0.0456%\n",
      "Epoch [135/300], Step [30/225], Training Accuracy: 98.4375%, Training Loss: 0.0462%\n",
      "Epoch [135/300], Step [31/225], Training Accuracy: 98.4879%, Training Loss: 0.0457%\n",
      "Epoch [135/300], Step [32/225], Training Accuracy: 98.5352%, Training Loss: 0.0453%\n",
      "Epoch [135/300], Step [33/225], Training Accuracy: 98.5322%, Training Loss: 0.0458%\n",
      "Epoch [135/300], Step [34/225], Training Accuracy: 98.5294%, Training Loss: 0.0457%\n",
      "Epoch [135/300], Step [35/225], Training Accuracy: 98.4821%, Training Loss: 0.0456%\n",
      "Epoch [135/300], Step [36/225], Training Accuracy: 98.5243%, Training Loss: 0.0453%\n",
      "Epoch [135/300], Step [37/225], Training Accuracy: 98.5642%, Training Loss: 0.0446%\n",
      "Epoch [135/300], Step [38/225], Training Accuracy: 98.5609%, Training Loss: 0.0444%\n",
      "Epoch [135/300], Step [39/225], Training Accuracy: 98.5176%, Training Loss: 0.0446%\n",
      "Epoch [135/300], Step [40/225], Training Accuracy: 98.4375%, Training Loss: 0.0453%\n",
      "Epoch [135/300], Step [41/225], Training Accuracy: 98.3994%, Training Loss: 0.0465%\n",
      "Epoch [135/300], Step [42/225], Training Accuracy: 98.4003%, Training Loss: 0.0462%\n",
      "Epoch [135/300], Step [43/225], Training Accuracy: 98.3648%, Training Loss: 0.0464%\n",
      "Epoch [135/300], Step [44/225], Training Accuracy: 98.3665%, Training Loss: 0.0460%\n",
      "Epoch [135/300], Step [45/225], Training Accuracy: 98.3681%, Training Loss: 0.0458%\n",
      "Epoch [135/300], Step [46/225], Training Accuracy: 98.4035%, Training Loss: 0.0450%\n",
      "Epoch [135/300], Step [47/225], Training Accuracy: 98.4375%, Training Loss: 0.0445%\n",
      "Epoch [135/300], Step [48/225], Training Accuracy: 98.4375%, Training Loss: 0.0448%\n",
      "Epoch [135/300], Step [49/225], Training Accuracy: 98.4056%, Training Loss: 0.0452%\n",
      "Epoch [135/300], Step [50/225], Training Accuracy: 98.3750%, Training Loss: 0.0456%\n",
      "Epoch [135/300], Step [51/225], Training Accuracy: 98.4069%, Training Loss: 0.0452%\n",
      "Epoch [135/300], Step [52/225], Training Accuracy: 98.4375%, Training Loss: 0.0446%\n",
      "Epoch [135/300], Step [53/225], Training Accuracy: 98.4670%, Training Loss: 0.0441%\n",
      "Epoch [135/300], Step [54/225], Training Accuracy: 98.4954%, Training Loss: 0.0437%\n",
      "Epoch [135/300], Step [55/225], Training Accuracy: 98.4943%, Training Loss: 0.0441%\n",
      "Epoch [135/300], Step [56/225], Training Accuracy: 98.4654%, Training Loss: 0.0442%\n",
      "Epoch [135/300], Step [57/225], Training Accuracy: 98.4649%, Training Loss: 0.0441%\n",
      "Epoch [135/300], Step [58/225], Training Accuracy: 98.4644%, Training Loss: 0.0439%\n",
      "Epoch [135/300], Step [59/225], Training Accuracy: 98.4640%, Training Loss: 0.0440%\n",
      "Epoch [135/300], Step [60/225], Training Accuracy: 98.4896%, Training Loss: 0.0437%\n",
      "Epoch [135/300], Step [61/225], Training Accuracy: 98.4375%, Training Loss: 0.0451%\n",
      "Epoch [135/300], Step [62/225], Training Accuracy: 98.4375%, Training Loss: 0.0450%\n",
      "Epoch [135/300], Step [63/225], Training Accuracy: 98.4623%, Training Loss: 0.0449%\n",
      "Epoch [135/300], Step [64/225], Training Accuracy: 98.4619%, Training Loss: 0.0454%\n",
      "Epoch [135/300], Step [65/225], Training Accuracy: 98.4856%, Training Loss: 0.0450%\n",
      "Epoch [135/300], Step [66/225], Training Accuracy: 98.5085%, Training Loss: 0.0447%\n",
      "Epoch [135/300], Step [67/225], Training Accuracy: 98.5308%, Training Loss: 0.0444%\n",
      "Epoch [135/300], Step [68/225], Training Accuracy: 98.5294%, Training Loss: 0.0441%\n",
      "Epoch [135/300], Step [69/225], Training Accuracy: 98.5507%, Training Loss: 0.0438%\n",
      "Epoch [135/300], Step [70/225], Training Accuracy: 98.5491%, Training Loss: 0.0435%\n",
      "Epoch [135/300], Step [71/225], Training Accuracy: 98.5475%, Training Loss: 0.0437%\n",
      "Epoch [135/300], Step [72/225], Training Accuracy: 98.5243%, Training Loss: 0.0437%\n",
      "Epoch [135/300], Step [73/225], Training Accuracy: 98.5017%, Training Loss: 0.0436%\n",
      "Epoch [135/300], Step [74/225], Training Accuracy: 98.5220%, Training Loss: 0.0434%\n",
      "Epoch [135/300], Step [75/225], Training Accuracy: 98.5000%, Training Loss: 0.0437%\n",
      "Epoch [135/300], Step [76/225], Training Accuracy: 98.4786%, Training Loss: 0.0443%\n",
      "Epoch [135/300], Step [77/225], Training Accuracy: 98.4984%, Training Loss: 0.0441%\n",
      "Epoch [135/300], Step [78/225], Training Accuracy: 98.5176%, Training Loss: 0.0437%\n",
      "Epoch [135/300], Step [79/225], Training Accuracy: 98.4968%, Training Loss: 0.0439%\n",
      "Epoch [135/300], Step [80/225], Training Accuracy: 98.5156%, Training Loss: 0.0435%\n",
      "Epoch [135/300], Step [81/225], Training Accuracy: 98.5147%, Training Loss: 0.0438%\n",
      "Epoch [135/300], Step [82/225], Training Accuracy: 98.5328%, Training Loss: 0.0437%\n",
      "Epoch [135/300], Step [83/225], Training Accuracy: 98.5505%, Training Loss: 0.0434%\n",
      "Epoch [135/300], Step [84/225], Training Accuracy: 98.5677%, Training Loss: 0.0435%\n",
      "Epoch [135/300], Step [85/225], Training Accuracy: 98.5846%, Training Loss: 0.0433%\n",
      "Epoch [135/300], Step [86/225], Training Accuracy: 98.5465%, Training Loss: 0.0446%\n",
      "Epoch [135/300], Step [87/225], Training Accuracy: 98.5453%, Training Loss: 0.0444%\n",
      "Epoch [135/300], Step [88/225], Training Accuracy: 98.5618%, Training Loss: 0.0444%\n",
      "Epoch [135/300], Step [89/225], Training Accuracy: 98.5779%, Training Loss: 0.0442%\n",
      "Epoch [135/300], Step [90/225], Training Accuracy: 98.5938%, Training Loss: 0.0438%\n",
      "Epoch [135/300], Step [91/225], Training Accuracy: 98.5749%, Training Loss: 0.0445%\n",
      "Epoch [135/300], Step [92/225], Training Accuracy: 98.5904%, Training Loss: 0.0442%\n",
      "Epoch [135/300], Step [93/225], Training Accuracy: 98.5887%, Training Loss: 0.0441%\n",
      "Epoch [135/300], Step [94/225], Training Accuracy: 98.6037%, Training Loss: 0.0439%\n",
      "Epoch [135/300], Step [95/225], Training Accuracy: 98.6020%, Training Loss: 0.0440%\n",
      "Epoch [135/300], Step [96/225], Training Accuracy: 98.6165%, Training Loss: 0.0438%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [135/300], Step [97/225], Training Accuracy: 98.6308%, Training Loss: 0.0436%\n",
      "Epoch [135/300], Step [98/225], Training Accuracy: 98.5810%, Training Loss: 0.0443%\n",
      "Epoch [135/300], Step [99/225], Training Accuracy: 98.5953%, Training Loss: 0.0439%\n",
      "Epoch [135/300], Step [100/225], Training Accuracy: 98.5781%, Training Loss: 0.0446%\n",
      "Epoch [135/300], Step [101/225], Training Accuracy: 98.5767%, Training Loss: 0.0446%\n",
      "Epoch [135/300], Step [102/225], Training Accuracy: 98.5907%, Training Loss: 0.0444%\n",
      "Epoch [135/300], Step [103/225], Training Accuracy: 98.6044%, Training Loss: 0.0441%\n",
      "Epoch [135/300], Step [104/225], Training Accuracy: 98.6178%, Training Loss: 0.0439%\n",
      "Epoch [135/300], Step [105/225], Training Accuracy: 98.6161%, Training Loss: 0.0440%\n",
      "Epoch [135/300], Step [106/225], Training Accuracy: 98.6291%, Training Loss: 0.0439%\n",
      "Epoch [135/300], Step [107/225], Training Accuracy: 98.6127%, Training Loss: 0.0441%\n",
      "Epoch [135/300], Step [108/225], Training Accuracy: 98.6111%, Training Loss: 0.0439%\n",
      "Epoch [135/300], Step [109/225], Training Accuracy: 98.6095%, Training Loss: 0.0438%\n",
      "Epoch [135/300], Step [110/225], Training Accuracy: 98.5938%, Training Loss: 0.0440%\n",
      "Epoch [135/300], Step [111/225], Training Accuracy: 98.6064%, Training Loss: 0.0438%\n",
      "Epoch [135/300], Step [112/225], Training Accuracy: 98.6189%, Training Loss: 0.0435%\n",
      "Epoch [135/300], Step [113/225], Training Accuracy: 98.6173%, Training Loss: 0.0435%\n",
      "Epoch [135/300], Step [114/225], Training Accuracy: 98.6020%, Training Loss: 0.0439%\n",
      "Epoch [135/300], Step [115/225], Training Accuracy: 98.6141%, Training Loss: 0.0437%\n",
      "Epoch [135/300], Step [116/225], Training Accuracy: 98.6126%, Training Loss: 0.0437%\n",
      "Epoch [135/300], Step [117/225], Training Accuracy: 98.6111%, Training Loss: 0.0437%\n",
      "Epoch [135/300], Step [118/225], Training Accuracy: 98.6229%, Training Loss: 0.0435%\n",
      "Epoch [135/300], Step [119/225], Training Accuracy: 98.6345%, Training Loss: 0.0433%\n",
      "Epoch [135/300], Step [120/225], Training Accuracy: 98.6458%, Training Loss: 0.0430%\n",
      "Epoch [135/300], Step [121/225], Training Accuracy: 98.6570%, Training Loss: 0.0428%\n",
      "Epoch [135/300], Step [122/225], Training Accuracy: 98.6680%, Training Loss: 0.0426%\n",
      "Epoch [135/300], Step [123/225], Training Accuracy: 98.6662%, Training Loss: 0.0427%\n",
      "Epoch [135/300], Step [124/225], Training Accuracy: 98.6769%, Training Loss: 0.0426%\n",
      "Epoch [135/300], Step [125/225], Training Accuracy: 98.6750%, Training Loss: 0.0426%\n",
      "Epoch [135/300], Step [126/225], Training Accuracy: 98.6731%, Training Loss: 0.0425%\n",
      "Epoch [135/300], Step [127/225], Training Accuracy: 98.6836%, Training Loss: 0.0423%\n",
      "Epoch [135/300], Step [128/225], Training Accuracy: 98.6694%, Training Loss: 0.0423%\n",
      "Epoch [135/300], Step [129/225], Training Accuracy: 98.6797%, Training Loss: 0.0422%\n",
      "Epoch [135/300], Step [130/225], Training Accuracy: 98.6779%, Training Loss: 0.0421%\n",
      "Epoch [135/300], Step [131/225], Training Accuracy: 98.6880%, Training Loss: 0.0421%\n",
      "Epoch [135/300], Step [132/225], Training Accuracy: 98.6861%, Training Loss: 0.0423%\n",
      "Epoch [135/300], Step [133/225], Training Accuracy: 98.6842%, Training Loss: 0.0424%\n",
      "Epoch [135/300], Step [134/225], Training Accuracy: 98.6940%, Training Loss: 0.0423%\n",
      "Epoch [135/300], Step [135/225], Training Accuracy: 98.7037%, Training Loss: 0.0421%\n",
      "Epoch [135/300], Step [136/225], Training Accuracy: 98.7017%, Training Loss: 0.0421%\n",
      "Epoch [135/300], Step [137/225], Training Accuracy: 98.6998%, Training Loss: 0.0422%\n",
      "Epoch [135/300], Step [138/225], Training Accuracy: 98.7092%, Training Loss: 0.0420%\n",
      "Epoch [135/300], Step [139/225], Training Accuracy: 98.7185%, Training Loss: 0.0419%\n",
      "Epoch [135/300], Step [140/225], Training Accuracy: 98.7277%, Training Loss: 0.0419%\n",
      "Epoch [135/300], Step [141/225], Training Accuracy: 98.7367%, Training Loss: 0.0417%\n",
      "Epoch [135/300], Step [142/225], Training Accuracy: 98.7456%, Training Loss: 0.0415%\n",
      "Epoch [135/300], Step [143/225], Training Accuracy: 98.7544%, Training Loss: 0.0414%\n",
      "Epoch [135/300], Step [144/225], Training Accuracy: 98.7630%, Training Loss: 0.0413%\n",
      "Epoch [135/300], Step [145/225], Training Accuracy: 98.7716%, Training Loss: 0.0412%\n",
      "Epoch [135/300], Step [146/225], Training Accuracy: 98.7800%, Training Loss: 0.0411%\n",
      "Epoch [135/300], Step [147/225], Training Accuracy: 98.7776%, Training Loss: 0.0410%\n",
      "Epoch [135/300], Step [148/225], Training Accuracy: 98.7753%, Training Loss: 0.0411%\n",
      "Epoch [135/300], Step [149/225], Training Accuracy: 98.7521%, Training Loss: 0.0413%\n",
      "Epoch [135/300], Step [150/225], Training Accuracy: 98.7500%, Training Loss: 0.0413%\n",
      "Epoch [135/300], Step [151/225], Training Accuracy: 98.7583%, Training Loss: 0.0411%\n",
      "Epoch [135/300], Step [152/225], Training Accuracy: 98.7562%, Training Loss: 0.0411%\n",
      "Epoch [135/300], Step [153/225], Training Accuracy: 98.7439%, Training Loss: 0.0412%\n",
      "Epoch [135/300], Step [154/225], Training Accuracy: 98.7520%, Training Loss: 0.0411%\n",
      "Epoch [135/300], Step [155/225], Training Accuracy: 98.7601%, Training Loss: 0.0410%\n",
      "Epoch [135/300], Step [156/225], Training Accuracy: 98.7680%, Training Loss: 0.0408%\n",
      "Epoch [135/300], Step [157/225], Training Accuracy: 98.7759%, Training Loss: 0.0408%\n",
      "Epoch [135/300], Step [158/225], Training Accuracy: 98.7836%, Training Loss: 0.0406%\n",
      "Epoch [135/300], Step [159/225], Training Accuracy: 98.7814%, Training Loss: 0.0406%\n",
      "Epoch [135/300], Step [160/225], Training Accuracy: 98.7891%, Training Loss: 0.0405%\n",
      "Epoch [135/300], Step [161/225], Training Accuracy: 98.7966%, Training Loss: 0.0404%\n",
      "Epoch [135/300], Step [162/225], Training Accuracy: 98.8040%, Training Loss: 0.0404%\n",
      "Epoch [135/300], Step [163/225], Training Accuracy: 98.7922%, Training Loss: 0.0406%\n",
      "Epoch [135/300], Step [164/225], Training Accuracy: 98.7995%, Training Loss: 0.0404%\n",
      "Epoch [135/300], Step [165/225], Training Accuracy: 98.8068%, Training Loss: 0.0403%\n",
      "Epoch [135/300], Step [166/225], Training Accuracy: 98.8140%, Training Loss: 0.0402%\n",
      "Epoch [135/300], Step [167/225], Training Accuracy: 98.8211%, Training Loss: 0.0402%\n",
      "Epoch [135/300], Step [168/225], Training Accuracy: 98.8095%, Training Loss: 0.0403%\n",
      "Epoch [135/300], Step [169/225], Training Accuracy: 98.8166%, Training Loss: 0.0403%\n",
      "Epoch [135/300], Step [170/225], Training Accuracy: 98.8235%, Training Loss: 0.0403%\n",
      "Epoch [135/300], Step [171/225], Training Accuracy: 98.8304%, Training Loss: 0.0402%\n",
      "Epoch [135/300], Step [172/225], Training Accuracy: 98.8190%, Training Loss: 0.0405%\n",
      "Epoch [135/300], Step [173/225], Training Accuracy: 98.8078%, Training Loss: 0.0405%\n",
      "Epoch [135/300], Step [174/225], Training Accuracy: 98.8147%, Training Loss: 0.0406%\n",
      "Epoch [135/300], Step [175/225], Training Accuracy: 98.8214%, Training Loss: 0.0404%\n",
      "Epoch [135/300], Step [176/225], Training Accuracy: 98.8281%, Training Loss: 0.0404%\n",
      "Epoch [135/300], Step [177/225], Training Accuracy: 98.8347%, Training Loss: 0.0403%\n",
      "Epoch [135/300], Step [178/225], Training Accuracy: 98.8237%, Training Loss: 0.0405%\n",
      "Epoch [135/300], Step [179/225], Training Accuracy: 98.8216%, Training Loss: 0.0406%\n",
      "Epoch [135/300], Step [180/225], Training Accuracy: 98.8281%, Training Loss: 0.0405%\n",
      "Epoch [135/300], Step [181/225], Training Accuracy: 98.8346%, Training Loss: 0.0403%\n",
      "Epoch [135/300], Step [182/225], Training Accuracy: 98.8410%, Training Loss: 0.0402%\n",
      "Epoch [135/300], Step [183/225], Training Accuracy: 98.8473%, Training Loss: 0.0401%\n",
      "Epoch [135/300], Step [184/225], Training Accuracy: 98.8536%, Training Loss: 0.0400%\n",
      "Epoch [135/300], Step [185/225], Training Accuracy: 98.8429%, Training Loss: 0.0402%\n",
      "Epoch [135/300], Step [186/225], Training Accuracy: 98.8491%, Training Loss: 0.0401%\n",
      "Epoch [135/300], Step [187/225], Training Accuracy: 98.8386%, Training Loss: 0.0403%\n",
      "Epoch [135/300], Step [188/225], Training Accuracy: 98.8447%, Training Loss: 0.0402%\n",
      "Epoch [135/300], Step [189/225], Training Accuracy: 98.8509%, Training Loss: 0.0400%\n",
      "Epoch [135/300], Step [190/225], Training Accuracy: 98.8569%, Training Loss: 0.0400%\n",
      "Epoch [135/300], Step [191/225], Training Accuracy: 98.8629%, Training Loss: 0.0398%\n",
      "Epoch [135/300], Step [192/225], Training Accuracy: 98.8607%, Training Loss: 0.0398%\n",
      "Epoch [135/300], Step [193/225], Training Accuracy: 98.8504%, Training Loss: 0.0400%\n",
      "Epoch [135/300], Step [194/225], Training Accuracy: 98.8563%, Training Loss: 0.0398%\n",
      "Epoch [135/300], Step [195/225], Training Accuracy: 98.8622%, Training Loss: 0.0397%\n",
      "Epoch [135/300], Step [196/225], Training Accuracy: 98.8680%, Training Loss: 0.0396%\n",
      "Epoch [135/300], Step [197/225], Training Accuracy: 98.8499%, Training Loss: 0.0398%\n",
      "Epoch [135/300], Step [198/225], Training Accuracy: 98.8557%, Training Loss: 0.0398%\n",
      "Epoch [135/300], Step [199/225], Training Accuracy: 98.8615%, Training Loss: 0.0397%\n",
      "Epoch [135/300], Step [200/225], Training Accuracy: 98.8672%, Training Loss: 0.0396%\n",
      "Epoch [135/300], Step [201/225], Training Accuracy: 98.8650%, Training Loss: 0.0396%\n",
      "Epoch [135/300], Step [202/225], Training Accuracy: 98.8552%, Training Loss: 0.0397%\n",
      "Epoch [135/300], Step [203/225], Training Accuracy: 98.8531%, Training Loss: 0.0397%\n",
      "Epoch [135/300], Step [204/225], Training Accuracy: 98.8588%, Training Loss: 0.0397%\n",
      "Epoch [135/300], Step [205/225], Training Accuracy: 98.8643%, Training Loss: 0.0396%\n",
      "Epoch [135/300], Step [206/225], Training Accuracy: 98.8547%, Training Loss: 0.0398%\n",
      "Epoch [135/300], Step [207/225], Training Accuracy: 98.8602%, Training Loss: 0.0397%\n",
      "Epoch [135/300], Step [208/225], Training Accuracy: 98.8582%, Training Loss: 0.0397%\n",
      "Epoch [135/300], Step [209/225], Training Accuracy: 98.8636%, Training Loss: 0.0395%\n",
      "Epoch [135/300], Step [210/225], Training Accuracy: 98.8616%, Training Loss: 0.0396%\n",
      "Epoch [135/300], Step [211/225], Training Accuracy: 98.8670%, Training Loss: 0.0395%\n",
      "Epoch [135/300], Step [212/225], Training Accuracy: 98.8723%, Training Loss: 0.0394%\n",
      "Epoch [135/300], Step [213/225], Training Accuracy: 98.8703%, Training Loss: 0.0394%\n",
      "Epoch [135/300], Step [214/225], Training Accuracy: 98.8756%, Training Loss: 0.0393%\n",
      "Epoch [135/300], Step [215/225], Training Accuracy: 98.8735%, Training Loss: 0.0393%\n",
      "Epoch [135/300], Step [216/225], Training Accuracy: 98.8426%, Training Loss: 0.0397%\n",
      "Epoch [135/300], Step [217/225], Training Accuracy: 98.8479%, Training Loss: 0.0397%\n",
      "Epoch [135/300], Step [218/225], Training Accuracy: 98.8317%, Training Loss: 0.0398%\n",
      "Epoch [135/300], Step [219/225], Training Accuracy: 98.8156%, Training Loss: 0.0399%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [135/300], Step [220/225], Training Accuracy: 98.8210%, Training Loss: 0.0399%\n",
      "Epoch [135/300], Step [221/225], Training Accuracy: 98.8264%, Training Loss: 0.0398%\n",
      "Epoch [135/300], Step [222/225], Training Accuracy: 98.8246%, Training Loss: 0.0398%\n",
      "Epoch [135/300], Step [223/225], Training Accuracy: 98.8299%, Training Loss: 0.0397%\n",
      "Epoch [135/300], Step [224/225], Training Accuracy: 98.8281%, Training Loss: 0.0397%\n",
      "Epoch [135/300], Step [225/225], Training Accuracy: 98.8327%, Training Loss: 0.0396%\n",
      "Epoch [136/300], Step [1/225], Training Accuracy: 98.4375%, Training Loss: 0.0532%\n",
      "Epoch [136/300], Step [2/225], Training Accuracy: 98.4375%, Training Loss: 0.0440%\n",
      "Epoch [136/300], Step [3/225], Training Accuracy: 97.9167%, Training Loss: 0.0517%\n",
      "Epoch [136/300], Step [4/225], Training Accuracy: 98.0469%, Training Loss: 0.0527%\n",
      "Epoch [136/300], Step [5/225], Training Accuracy: 98.4375%, Training Loss: 0.0457%\n",
      "Epoch [136/300], Step [6/225], Training Accuracy: 98.6979%, Training Loss: 0.0416%\n",
      "Epoch [136/300], Step [7/225], Training Accuracy: 98.6607%, Training Loss: 0.0394%\n",
      "Epoch [136/300], Step [8/225], Training Accuracy: 98.8281%, Training Loss: 0.0375%\n",
      "Epoch [136/300], Step [9/225], Training Accuracy: 98.6111%, Training Loss: 0.0414%\n",
      "Epoch [136/300], Step [10/225], Training Accuracy: 98.7500%, Training Loss: 0.0409%\n",
      "Epoch [136/300], Step [11/225], Training Accuracy: 98.7216%, Training Loss: 0.0418%\n",
      "Epoch [136/300], Step [12/225], Training Accuracy: 98.4375%, Training Loss: 0.0456%\n",
      "Epoch [136/300], Step [13/225], Training Accuracy: 98.5577%, Training Loss: 0.0434%\n",
      "Epoch [136/300], Step [14/225], Training Accuracy: 98.5491%, Training Loss: 0.0429%\n",
      "Epoch [136/300], Step [15/225], Training Accuracy: 98.5417%, Training Loss: 0.0430%\n",
      "Epoch [136/300], Step [16/225], Training Accuracy: 98.4375%, Training Loss: 0.0441%\n",
      "Epoch [136/300], Step [17/225], Training Accuracy: 98.5294%, Training Loss: 0.0432%\n",
      "Epoch [136/300], Step [18/225], Training Accuracy: 98.1771%, Training Loss: 0.0519%\n",
      "Epoch [136/300], Step [19/225], Training Accuracy: 98.2730%, Training Loss: 0.0509%\n",
      "Epoch [136/300], Step [20/225], Training Accuracy: 98.3594%, Training Loss: 0.0501%\n",
      "Epoch [136/300], Step [21/225], Training Accuracy: 98.4375%, Training Loss: 0.0490%\n",
      "Epoch [136/300], Step [22/225], Training Accuracy: 98.4375%, Training Loss: 0.0506%\n",
      "Epoch [136/300], Step [23/225], Training Accuracy: 98.4375%, Training Loss: 0.0507%\n",
      "Epoch [136/300], Step [24/225], Training Accuracy: 98.3073%, Training Loss: 0.0521%\n",
      "Epoch [136/300], Step [25/225], Training Accuracy: 98.3125%, Training Loss: 0.0510%\n",
      "Epoch [136/300], Step [26/225], Training Accuracy: 98.2572%, Training Loss: 0.0504%\n",
      "Epoch [136/300], Step [27/225], Training Accuracy: 98.0903%, Training Loss: 0.0530%\n",
      "Epoch [136/300], Step [28/225], Training Accuracy: 98.1585%, Training Loss: 0.0520%\n",
      "Epoch [136/300], Step [29/225], Training Accuracy: 98.2220%, Training Loss: 0.0511%\n",
      "Epoch [136/300], Step [30/225], Training Accuracy: 98.1250%, Training Loss: 0.0514%\n",
      "Epoch [136/300], Step [31/225], Training Accuracy: 98.1855%, Training Loss: 0.0509%\n",
      "Epoch [136/300], Step [32/225], Training Accuracy: 98.2422%, Training Loss: 0.0501%\n",
      "Epoch [136/300], Step [33/225], Training Accuracy: 98.2481%, Training Loss: 0.0495%\n",
      "Epoch [136/300], Step [34/225], Training Accuracy: 98.2537%, Training Loss: 0.0490%\n",
      "Epoch [136/300], Step [35/225], Training Accuracy: 98.3036%, Training Loss: 0.0485%\n",
      "Epoch [136/300], Step [36/225], Training Accuracy: 98.2639%, Training Loss: 0.0489%\n",
      "Epoch [136/300], Step [37/225], Training Accuracy: 98.3108%, Training Loss: 0.0481%\n",
      "Epoch [136/300], Step [38/225], Training Accuracy: 98.3553%, Training Loss: 0.0475%\n",
      "Epoch [136/300], Step [39/225], Training Accuracy: 98.3574%, Training Loss: 0.0476%\n",
      "Epoch [136/300], Step [40/225], Training Accuracy: 98.3984%, Training Loss: 0.0470%\n",
      "Epoch [136/300], Step [41/225], Training Accuracy: 98.3613%, Training Loss: 0.0476%\n",
      "Epoch [136/300], Step [42/225], Training Accuracy: 98.4003%, Training Loss: 0.0474%\n",
      "Epoch [136/300], Step [43/225], Training Accuracy: 98.4375%, Training Loss: 0.0467%\n",
      "Epoch [136/300], Step [44/225], Training Accuracy: 98.4020%, Training Loss: 0.0475%\n",
      "Epoch [136/300], Step [45/225], Training Accuracy: 98.4028%, Training Loss: 0.0474%\n",
      "Epoch [136/300], Step [46/225], Training Accuracy: 98.4035%, Training Loss: 0.0472%\n",
      "Epoch [136/300], Step [47/225], Training Accuracy: 98.4375%, Training Loss: 0.0467%\n",
      "Epoch [136/300], Step [48/225], Training Accuracy: 98.4375%, Training Loss: 0.0464%\n",
      "Epoch [136/300], Step [49/225], Training Accuracy: 98.4375%, Training Loss: 0.0463%\n",
      "Epoch [136/300], Step [50/225], Training Accuracy: 98.4688%, Training Loss: 0.0459%\n",
      "Epoch [136/300], Step [51/225], Training Accuracy: 98.4988%, Training Loss: 0.0451%\n",
      "Epoch [136/300], Step [52/225], Training Accuracy: 98.4976%, Training Loss: 0.0455%\n",
      "Epoch [136/300], Step [53/225], Training Accuracy: 98.4670%, Training Loss: 0.0461%\n",
      "Epoch [136/300], Step [54/225], Training Accuracy: 98.4375%, Training Loss: 0.0464%\n",
      "Epoch [136/300], Step [55/225], Training Accuracy: 98.4375%, Training Loss: 0.0469%\n",
      "Epoch [136/300], Step [56/225], Training Accuracy: 98.4096%, Training Loss: 0.0477%\n",
      "Epoch [136/300], Step [57/225], Training Accuracy: 98.3827%, Training Loss: 0.0489%\n",
      "Epoch [136/300], Step [58/225], Training Accuracy: 98.3836%, Training Loss: 0.0489%\n",
      "Epoch [136/300], Step [59/225], Training Accuracy: 98.3581%, Training Loss: 0.0491%\n",
      "Epoch [136/300], Step [60/225], Training Accuracy: 98.3594%, Training Loss: 0.0491%\n",
      "Epoch [136/300], Step [61/225], Training Accuracy: 98.3607%, Training Loss: 0.0488%\n",
      "Epoch [136/300], Step [62/225], Training Accuracy: 98.3619%, Training Loss: 0.0486%\n",
      "Epoch [136/300], Step [63/225], Training Accuracy: 98.3135%, Training Loss: 0.0496%\n",
      "Epoch [136/300], Step [64/225], Training Accuracy: 98.3154%, Training Loss: 0.0502%\n",
      "Epoch [136/300], Step [65/225], Training Accuracy: 98.2692%, Training Loss: 0.0510%\n",
      "Epoch [136/300], Step [66/225], Training Accuracy: 98.2955%, Training Loss: 0.0507%\n",
      "Epoch [136/300], Step [67/225], Training Accuracy: 98.2976%, Training Loss: 0.0507%\n",
      "Epoch [136/300], Step [68/225], Training Accuracy: 98.3226%, Training Loss: 0.0504%\n",
      "Epoch [136/300], Step [69/225], Training Accuracy: 98.3243%, Training Loss: 0.0503%\n",
      "Epoch [136/300], Step [70/225], Training Accuracy: 98.3036%, Training Loss: 0.0503%\n",
      "Epoch [136/300], Step [71/225], Training Accuracy: 98.3055%, Training Loss: 0.0503%\n",
      "Epoch [136/300], Step [72/225], Training Accuracy: 98.3290%, Training Loss: 0.0500%\n",
      "Epoch [136/300], Step [73/225], Training Accuracy: 98.3305%, Training Loss: 0.0499%\n",
      "Epoch [136/300], Step [74/225], Training Accuracy: 98.3319%, Training Loss: 0.0499%\n",
      "Epoch [136/300], Step [75/225], Training Accuracy: 98.3542%, Training Loss: 0.0496%\n",
      "Epoch [136/300], Step [76/225], Training Accuracy: 98.3347%, Training Loss: 0.0498%\n",
      "Epoch [136/300], Step [77/225], Training Accuracy: 98.3563%, Training Loss: 0.0494%\n",
      "Epoch [136/300], Step [78/225], Training Accuracy: 98.3373%, Training Loss: 0.0494%\n",
      "Epoch [136/300], Step [79/225], Training Accuracy: 98.3386%, Training Loss: 0.0493%\n",
      "Epoch [136/300], Step [80/225], Training Accuracy: 98.3594%, Training Loss: 0.0493%\n",
      "Epoch [136/300], Step [81/225], Training Accuracy: 98.3603%, Training Loss: 0.0491%\n",
      "Epoch [136/300], Step [82/225], Training Accuracy: 98.3232%, Training Loss: 0.0495%\n",
      "Epoch [136/300], Step [83/225], Training Accuracy: 98.2681%, Training Loss: 0.0507%\n",
      "Epoch [136/300], Step [84/225], Training Accuracy: 98.2887%, Training Loss: 0.0505%\n",
      "Epoch [136/300], Step [85/225], Training Accuracy: 98.3088%, Training Loss: 0.0503%\n",
      "Epoch [136/300], Step [86/225], Training Accuracy: 98.3285%, Training Loss: 0.0501%\n",
      "Epoch [136/300], Step [87/225], Training Accuracy: 98.3118%, Training Loss: 0.0502%\n",
      "Epoch [136/300], Step [88/225], Training Accuracy: 98.2955%, Training Loss: 0.0509%\n",
      "Epoch [136/300], Step [89/225], Training Accuracy: 98.2795%, Training Loss: 0.0510%\n",
      "Epoch [136/300], Step [90/225], Training Accuracy: 98.2465%, Training Loss: 0.0516%\n",
      "Epoch [136/300], Step [91/225], Training Accuracy: 98.2486%, Training Loss: 0.0515%\n",
      "Epoch [136/300], Step [92/225], Training Accuracy: 98.2677%, Training Loss: 0.0512%\n",
      "Epoch [136/300], Step [93/225], Training Accuracy: 98.2863%, Training Loss: 0.0510%\n",
      "Epoch [136/300], Step [94/225], Training Accuracy: 98.3045%, Training Loss: 0.0507%\n",
      "Epoch [136/300], Step [95/225], Training Accuracy: 98.3224%, Training Loss: 0.0503%\n",
      "Epoch [136/300], Step [96/225], Training Accuracy: 98.3236%, Training Loss: 0.0502%\n",
      "Epoch [136/300], Step [97/225], Training Accuracy: 98.3247%, Training Loss: 0.0501%\n",
      "Epoch [136/300], Step [98/225], Training Accuracy: 98.2940%, Training Loss: 0.0510%\n",
      "Epoch [136/300], Step [99/225], Training Accuracy: 98.3112%, Training Loss: 0.0506%\n",
      "Epoch [136/300], Step [100/225], Training Accuracy: 98.3125%, Training Loss: 0.0506%\n",
      "Epoch [136/300], Step [101/225], Training Accuracy: 98.2828%, Training Loss: 0.0510%\n",
      "Epoch [136/300], Step [102/225], Training Accuracy: 98.2843%, Training Loss: 0.0508%\n",
      "Epoch [136/300], Step [103/225], Training Accuracy: 98.2858%, Training Loss: 0.0507%\n",
      "Epoch [136/300], Step [104/225], Training Accuracy: 98.3023%, Training Loss: 0.0505%\n",
      "Epoch [136/300], Step [105/225], Training Accuracy: 98.3036%, Training Loss: 0.0504%\n",
      "Epoch [136/300], Step [106/225], Training Accuracy: 98.3048%, Training Loss: 0.0504%\n",
      "Epoch [136/300], Step [107/225], Training Accuracy: 98.3207%, Training Loss: 0.0503%\n",
      "Epoch [136/300], Step [108/225], Training Accuracy: 98.3362%, Training Loss: 0.0501%\n",
      "Epoch [136/300], Step [109/225], Training Accuracy: 98.3515%, Training Loss: 0.0499%\n",
      "Epoch [136/300], Step [110/225], Training Accuracy: 98.3523%, Training Loss: 0.0500%\n",
      "Epoch [136/300], Step [111/225], Training Accuracy: 98.3530%, Training Loss: 0.0498%\n",
      "Epoch [136/300], Step [112/225], Training Accuracy: 98.3538%, Training Loss: 0.0498%\n",
      "Epoch [136/300], Step [113/225], Training Accuracy: 98.3407%, Training Loss: 0.0498%\n",
      "Epoch [136/300], Step [114/225], Training Accuracy: 98.3416%, Training Loss: 0.0499%\n",
      "Epoch [136/300], Step [115/225], Training Accuracy: 98.3560%, Training Loss: 0.0496%\n",
      "Epoch [136/300], Step [116/225], Training Accuracy: 98.3567%, Training Loss: 0.0495%\n",
      "Epoch [136/300], Step [117/225], Training Accuracy: 98.3574%, Training Loss: 0.0496%\n",
      "Epoch [136/300], Step [118/225], Training Accuracy: 98.3713%, Training Loss: 0.0494%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [136/300], Step [119/225], Training Accuracy: 98.3850%, Training Loss: 0.0491%\n",
      "Epoch [136/300], Step [120/225], Training Accuracy: 98.3984%, Training Loss: 0.0489%\n",
      "Epoch [136/300], Step [121/225], Training Accuracy: 98.3988%, Training Loss: 0.0487%\n",
      "Epoch [136/300], Step [122/225], Training Accuracy: 98.3991%, Training Loss: 0.0490%\n",
      "Epoch [136/300], Step [123/225], Training Accuracy: 98.3867%, Training Loss: 0.0491%\n",
      "Epoch [136/300], Step [124/225], Training Accuracy: 98.3493%, Training Loss: 0.0494%\n",
      "Epoch [136/300], Step [125/225], Training Accuracy: 98.3625%, Training Loss: 0.0492%\n",
      "Epoch [136/300], Step [126/225], Training Accuracy: 98.3755%, Training Loss: 0.0490%\n",
      "Epoch [136/300], Step [127/225], Training Accuracy: 98.3760%, Training Loss: 0.0491%\n",
      "Epoch [136/300], Step [128/225], Training Accuracy: 98.3643%, Training Loss: 0.0494%\n",
      "Epoch [136/300], Step [129/225], Training Accuracy: 98.3769%, Training Loss: 0.0490%\n",
      "Epoch [136/300], Step [130/225], Training Accuracy: 98.3534%, Training Loss: 0.0494%\n",
      "Epoch [136/300], Step [131/225], Training Accuracy: 98.3540%, Training Loss: 0.0494%\n",
      "Epoch [136/300], Step [132/225], Training Accuracy: 98.3546%, Training Loss: 0.0493%\n",
      "Epoch [136/300], Step [133/225], Training Accuracy: 98.3670%, Training Loss: 0.0491%\n",
      "Epoch [136/300], Step [134/225], Training Accuracy: 98.3792%, Training Loss: 0.0489%\n",
      "Epoch [136/300], Step [135/225], Training Accuracy: 98.3796%, Training Loss: 0.0491%\n",
      "Epoch [136/300], Step [136/225], Training Accuracy: 98.3801%, Training Loss: 0.0492%\n",
      "Epoch [136/300], Step [137/225], Training Accuracy: 98.3919%, Training Loss: 0.0490%\n",
      "Epoch [136/300], Step [138/225], Training Accuracy: 98.3922%, Training Loss: 0.0491%\n",
      "Epoch [136/300], Step [139/225], Training Accuracy: 98.3925%, Training Loss: 0.0490%\n",
      "Epoch [136/300], Step [140/225], Training Accuracy: 98.3929%, Training Loss: 0.0492%\n",
      "Epoch [136/300], Step [141/225], Training Accuracy: 98.3821%, Training Loss: 0.0491%\n",
      "Epoch [136/300], Step [142/225], Training Accuracy: 98.3935%, Training Loss: 0.0493%\n",
      "Epoch [136/300], Step [143/225], Training Accuracy: 98.4047%, Training Loss: 0.0490%\n",
      "Epoch [136/300], Step [144/225], Training Accuracy: 98.3941%, Training Loss: 0.0494%\n",
      "Epoch [136/300], Step [145/225], Training Accuracy: 98.4052%, Training Loss: 0.0492%\n",
      "Epoch [136/300], Step [146/225], Training Accuracy: 98.4054%, Training Loss: 0.0491%\n",
      "Epoch [136/300], Step [147/225], Training Accuracy: 98.3950%, Training Loss: 0.0491%\n",
      "Epoch [136/300], Step [148/225], Training Accuracy: 98.3847%, Training Loss: 0.0491%\n",
      "Epoch [136/300], Step [149/225], Training Accuracy: 98.3746%, Training Loss: 0.0492%\n",
      "Epoch [136/300], Step [150/225], Training Accuracy: 98.3750%, Training Loss: 0.0491%\n",
      "Epoch [136/300], Step [151/225], Training Accuracy: 98.3651%, Training Loss: 0.0492%\n",
      "Epoch [136/300], Step [152/225], Training Accuracy: 98.3758%, Training Loss: 0.0490%\n",
      "Epoch [136/300], Step [153/225], Training Accuracy: 98.3762%, Training Loss: 0.0488%\n",
      "Epoch [136/300], Step [154/225], Training Accuracy: 98.3766%, Training Loss: 0.0488%\n",
      "Epoch [136/300], Step [155/225], Training Accuracy: 98.3871%, Training Loss: 0.0486%\n",
      "Epoch [136/300], Step [156/225], Training Accuracy: 98.3874%, Training Loss: 0.0484%\n",
      "Epoch [136/300], Step [157/225], Training Accuracy: 98.3877%, Training Loss: 0.0483%\n",
      "Epoch [136/300], Step [158/225], Training Accuracy: 98.3979%, Training Loss: 0.0482%\n",
      "Epoch [136/300], Step [159/225], Training Accuracy: 98.4080%, Training Loss: 0.0480%\n",
      "Epoch [136/300], Step [160/225], Training Accuracy: 98.4082%, Training Loss: 0.0480%\n",
      "Epoch [136/300], Step [161/225], Training Accuracy: 98.4084%, Training Loss: 0.0479%\n",
      "Epoch [136/300], Step [162/225], Training Accuracy: 98.3893%, Training Loss: 0.0481%\n",
      "Epoch [136/300], Step [163/225], Training Accuracy: 98.3896%, Training Loss: 0.0481%\n",
      "Epoch [136/300], Step [164/225], Training Accuracy: 98.3994%, Training Loss: 0.0479%\n",
      "Epoch [136/300], Step [165/225], Training Accuracy: 98.4091%, Training Loss: 0.0478%\n",
      "Epoch [136/300], Step [166/225], Training Accuracy: 98.4093%, Training Loss: 0.0476%\n",
      "Epoch [136/300], Step [167/225], Training Accuracy: 98.4094%, Training Loss: 0.0476%\n",
      "Epoch [136/300], Step [168/225], Training Accuracy: 98.4096%, Training Loss: 0.0475%\n",
      "Epoch [136/300], Step [169/225], Training Accuracy: 98.4098%, Training Loss: 0.0476%\n",
      "Epoch [136/300], Step [170/225], Training Accuracy: 98.4191%, Training Loss: 0.0475%\n",
      "Epoch [136/300], Step [171/225], Training Accuracy: 98.4101%, Training Loss: 0.0477%\n",
      "Epoch [136/300], Step [172/225], Training Accuracy: 98.4193%, Training Loss: 0.0476%\n",
      "Epoch [136/300], Step [173/225], Training Accuracy: 98.4285%, Training Loss: 0.0474%\n",
      "Epoch [136/300], Step [174/225], Training Accuracy: 98.4195%, Training Loss: 0.0475%\n",
      "Epoch [136/300], Step [175/225], Training Accuracy: 98.4286%, Training Loss: 0.0473%\n",
      "Epoch [136/300], Step [176/225], Training Accuracy: 98.4197%, Training Loss: 0.0477%\n",
      "Epoch [136/300], Step [177/225], Training Accuracy: 98.4287%, Training Loss: 0.0475%\n",
      "Epoch [136/300], Step [178/225], Training Accuracy: 98.4287%, Training Loss: 0.0475%\n",
      "Epoch [136/300], Step [179/225], Training Accuracy: 98.4375%, Training Loss: 0.0474%\n",
      "Epoch [136/300], Step [180/225], Training Accuracy: 98.4375%, Training Loss: 0.0474%\n",
      "Epoch [136/300], Step [181/225], Training Accuracy: 98.4375%, Training Loss: 0.0474%\n",
      "Epoch [136/300], Step [182/225], Training Accuracy: 98.4375%, Training Loss: 0.0474%\n",
      "Epoch [136/300], Step [183/225], Training Accuracy: 98.4460%, Training Loss: 0.0472%\n",
      "Epoch [136/300], Step [184/225], Training Accuracy: 98.4460%, Training Loss: 0.0472%\n",
      "Epoch [136/300], Step [185/225], Training Accuracy: 98.4544%, Training Loss: 0.0470%\n",
      "Epoch [136/300], Step [186/225], Training Accuracy: 98.4543%, Training Loss: 0.0470%\n",
      "Epoch [136/300], Step [187/225], Training Accuracy: 98.4459%, Training Loss: 0.0473%\n",
      "Epoch [136/300], Step [188/225], Training Accuracy: 98.4541%, Training Loss: 0.0472%\n",
      "Epoch [136/300], Step [189/225], Training Accuracy: 98.4623%, Training Loss: 0.0471%\n",
      "Epoch [136/300], Step [190/225], Training Accuracy: 98.4539%, Training Loss: 0.0473%\n",
      "Epoch [136/300], Step [191/225], Training Accuracy: 98.4620%, Training Loss: 0.0472%\n",
      "Epoch [136/300], Step [192/225], Training Accuracy: 98.4701%, Training Loss: 0.0471%\n",
      "Epoch [136/300], Step [193/225], Training Accuracy: 98.4618%, Training Loss: 0.0473%\n",
      "Epoch [136/300], Step [194/225], Training Accuracy: 98.4697%, Training Loss: 0.0472%\n",
      "Epoch [136/300], Step [195/225], Training Accuracy: 98.4615%, Training Loss: 0.0472%\n",
      "Epoch [136/300], Step [196/225], Training Accuracy: 98.4694%, Training Loss: 0.0471%\n",
      "Epoch [136/300], Step [197/225], Training Accuracy: 98.4772%, Training Loss: 0.0469%\n",
      "Epoch [136/300], Step [198/225], Training Accuracy: 98.4612%, Training Loss: 0.0472%\n",
      "Epoch [136/300], Step [199/225], Training Accuracy: 98.4532%, Training Loss: 0.0472%\n",
      "Epoch [136/300], Step [200/225], Training Accuracy: 98.4609%, Training Loss: 0.0471%\n",
      "Epoch [136/300], Step [201/225], Training Accuracy: 98.4608%, Training Loss: 0.0471%\n",
      "Epoch [136/300], Step [202/225], Training Accuracy: 98.4684%, Training Loss: 0.0469%\n",
      "Epoch [136/300], Step [203/225], Training Accuracy: 98.4760%, Training Loss: 0.0469%\n",
      "Epoch [136/300], Step [204/225], Training Accuracy: 98.4835%, Training Loss: 0.0468%\n",
      "Epoch [136/300], Step [205/225], Training Accuracy: 98.4832%, Training Loss: 0.0467%\n",
      "Epoch [136/300], Step [206/225], Training Accuracy: 98.4830%, Training Loss: 0.0467%\n",
      "Epoch [136/300], Step [207/225], Training Accuracy: 98.4903%, Training Loss: 0.0465%\n",
      "Epoch [136/300], Step [208/225], Training Accuracy: 98.4901%, Training Loss: 0.0466%\n",
      "Epoch [136/300], Step [209/225], Training Accuracy: 98.4749%, Training Loss: 0.0469%\n",
      "Epoch [136/300], Step [210/225], Training Accuracy: 98.4673%, Training Loss: 0.0469%\n",
      "Epoch [136/300], Step [211/225], Training Accuracy: 98.4671%, Training Loss: 0.0470%\n",
      "Epoch [136/300], Step [212/225], Training Accuracy: 98.4670%, Training Loss: 0.0469%\n",
      "Epoch [136/300], Step [213/225], Training Accuracy: 98.4668%, Training Loss: 0.0470%\n",
      "Epoch [136/300], Step [214/225], Training Accuracy: 98.4667%, Training Loss: 0.0469%\n",
      "Epoch [136/300], Step [215/225], Training Accuracy: 98.4738%, Training Loss: 0.0468%\n",
      "Epoch [136/300], Step [216/225], Training Accuracy: 98.4737%, Training Loss: 0.0467%\n",
      "Epoch [136/300], Step [217/225], Training Accuracy: 98.4735%, Training Loss: 0.0468%\n",
      "Epoch [136/300], Step [218/225], Training Accuracy: 98.4662%, Training Loss: 0.0469%\n",
      "Epoch [136/300], Step [219/225], Training Accuracy: 98.4660%, Training Loss: 0.0468%\n",
      "Epoch [136/300], Step [220/225], Training Accuracy: 98.4659%, Training Loss: 0.0467%\n",
      "Epoch [136/300], Step [221/225], Training Accuracy: 98.4658%, Training Loss: 0.0468%\n",
      "Epoch [136/300], Step [222/225], Training Accuracy: 98.4586%, Training Loss: 0.0469%\n",
      "Epoch [136/300], Step [223/225], Training Accuracy: 98.4655%, Training Loss: 0.0468%\n",
      "Epoch [136/300], Step [224/225], Training Accuracy: 98.4515%, Training Loss: 0.0470%\n",
      "Epoch [136/300], Step [225/225], Training Accuracy: 98.4505%, Training Loss: 0.0471%\n",
      "Epoch [137/300], Step [1/225], Training Accuracy: 98.4375%, Training Loss: 0.0541%\n",
      "Epoch [137/300], Step [2/225], Training Accuracy: 98.4375%, Training Loss: 0.0592%\n",
      "Epoch [137/300], Step [3/225], Training Accuracy: 98.9583%, Training Loss: 0.0466%\n",
      "Epoch [137/300], Step [4/225], Training Accuracy: 98.8281%, Training Loss: 0.0443%\n",
      "Epoch [137/300], Step [5/225], Training Accuracy: 98.7500%, Training Loss: 0.0410%\n",
      "Epoch [137/300], Step [6/225], Training Accuracy: 98.9583%, Training Loss: 0.0396%\n",
      "Epoch [137/300], Step [7/225], Training Accuracy: 99.1071%, Training Loss: 0.0378%\n",
      "Epoch [137/300], Step [8/225], Training Accuracy: 99.2188%, Training Loss: 0.0373%\n",
      "Epoch [137/300], Step [9/225], Training Accuracy: 99.3056%, Training Loss: 0.0360%\n",
      "Epoch [137/300], Step [10/225], Training Accuracy: 99.3750%, Training Loss: 0.0347%\n",
      "Epoch [137/300], Step [11/225], Training Accuracy: 99.2898%, Training Loss: 0.0344%\n",
      "Epoch [137/300], Step [12/225], Training Accuracy: 99.2188%, Training Loss: 0.0348%\n",
      "Epoch [137/300], Step [13/225], Training Accuracy: 99.0385%, Training Loss: 0.0373%\n",
      "Epoch [137/300], Step [14/225], Training Accuracy: 98.9955%, Training Loss: 0.0391%\n",
      "Epoch [137/300], Step [15/225], Training Accuracy: 98.9583%, Training Loss: 0.0392%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [137/300], Step [16/225], Training Accuracy: 98.8281%, Training Loss: 0.0399%\n",
      "Epoch [137/300], Step [17/225], Training Accuracy: 98.8971%, Training Loss: 0.0396%\n",
      "Epoch [137/300], Step [18/225], Training Accuracy: 98.7847%, Training Loss: 0.0412%\n",
      "Epoch [137/300], Step [19/225], Training Accuracy: 98.8487%, Training Loss: 0.0400%\n",
      "Epoch [137/300], Step [20/225], Training Accuracy: 98.7500%, Training Loss: 0.0427%\n",
      "Epoch [137/300], Step [21/225], Training Accuracy: 98.8095%, Training Loss: 0.0418%\n",
      "Epoch [137/300], Step [22/225], Training Accuracy: 98.7926%, Training Loss: 0.0424%\n",
      "Epoch [137/300], Step [23/225], Training Accuracy: 98.8451%, Training Loss: 0.0413%\n",
      "Epoch [137/300], Step [24/225], Training Accuracy: 98.8281%, Training Loss: 0.0409%\n",
      "Epoch [137/300], Step [25/225], Training Accuracy: 98.8125%, Training Loss: 0.0407%\n",
      "Epoch [137/300], Step [26/225], Training Accuracy: 98.7981%, Training Loss: 0.0402%\n",
      "Epoch [137/300], Step [27/225], Training Accuracy: 98.8426%, Training Loss: 0.0394%\n",
      "Epoch [137/300], Step [28/225], Training Accuracy: 98.8839%, Training Loss: 0.0384%\n",
      "Epoch [137/300], Step [29/225], Training Accuracy: 98.9224%, Training Loss: 0.0379%\n",
      "Epoch [137/300], Step [30/225], Training Accuracy: 98.9583%, Training Loss: 0.0375%\n",
      "Epoch [137/300], Step [31/225], Training Accuracy: 98.9415%, Training Loss: 0.0388%\n",
      "Epoch [137/300], Step [32/225], Training Accuracy: 98.9746%, Training Loss: 0.0384%\n",
      "Epoch [137/300], Step [33/225], Training Accuracy: 98.8636%, Training Loss: 0.0396%\n",
      "Epoch [137/300], Step [34/225], Training Accuracy: 98.8511%, Training Loss: 0.0399%\n",
      "Epoch [137/300], Step [35/225], Training Accuracy: 98.8839%, Training Loss: 0.0397%\n",
      "Epoch [137/300], Step [36/225], Training Accuracy: 98.9149%, Training Loss: 0.0389%\n",
      "Epoch [137/300], Step [37/225], Training Accuracy: 98.9443%, Training Loss: 0.0384%\n",
      "Epoch [137/300], Step [38/225], Training Accuracy: 98.9720%, Training Loss: 0.0377%\n",
      "Epoch [137/300], Step [39/225], Training Accuracy: 98.9984%, Training Loss: 0.0375%\n",
      "Epoch [137/300], Step [40/225], Training Accuracy: 98.9844%, Training Loss: 0.0375%\n",
      "Epoch [137/300], Step [41/225], Training Accuracy: 99.0091%, Training Loss: 0.0368%\n",
      "Epoch [137/300], Step [42/225], Training Accuracy: 98.9955%, Training Loss: 0.0370%\n",
      "Epoch [137/300], Step [43/225], Training Accuracy: 98.9462%, Training Loss: 0.0382%\n",
      "Epoch [137/300], Step [44/225], Training Accuracy: 98.9347%, Training Loss: 0.0385%\n",
      "Epoch [137/300], Step [45/225], Training Accuracy: 98.9236%, Training Loss: 0.0385%\n",
      "Epoch [137/300], Step [46/225], Training Accuracy: 98.9470%, Training Loss: 0.0379%\n",
      "Epoch [137/300], Step [47/225], Training Accuracy: 98.9694%, Training Loss: 0.0374%\n",
      "Epoch [137/300], Step [48/225], Training Accuracy: 98.9258%, Training Loss: 0.0390%\n",
      "Epoch [137/300], Step [49/225], Training Accuracy: 98.9477%, Training Loss: 0.0385%\n",
      "Epoch [137/300], Step [50/225], Training Accuracy: 98.9375%, Training Loss: 0.0390%\n",
      "Epoch [137/300], Step [51/225], Training Accuracy: 98.9277%, Training Loss: 0.0390%\n",
      "Epoch [137/300], Step [52/225], Training Accuracy: 98.9483%, Training Loss: 0.0386%\n",
      "Epoch [137/300], Step [53/225], Training Accuracy: 98.9387%, Training Loss: 0.0388%\n",
      "Epoch [137/300], Step [54/225], Training Accuracy: 98.9583%, Training Loss: 0.0387%\n",
      "Epoch [137/300], Step [55/225], Training Accuracy: 98.9773%, Training Loss: 0.0384%\n",
      "Epoch [137/300], Step [56/225], Training Accuracy: 98.9397%, Training Loss: 0.0393%\n",
      "Epoch [137/300], Step [57/225], Training Accuracy: 98.9583%, Training Loss: 0.0393%\n",
      "Epoch [137/300], Step [58/225], Training Accuracy: 98.9494%, Training Loss: 0.0392%\n",
      "Epoch [137/300], Step [59/225], Training Accuracy: 98.9142%, Training Loss: 0.0395%\n",
      "Epoch [137/300], Step [60/225], Training Accuracy: 98.9062%, Training Loss: 0.0397%\n",
      "Epoch [137/300], Step [61/225], Training Accuracy: 98.8730%, Training Loss: 0.0398%\n",
      "Epoch [137/300], Step [62/225], Training Accuracy: 98.8911%, Training Loss: 0.0395%\n",
      "Epoch [137/300], Step [63/225], Training Accuracy: 98.9087%, Training Loss: 0.0393%\n",
      "Epoch [137/300], Step [64/225], Training Accuracy: 98.9014%, Training Loss: 0.0392%\n",
      "Epoch [137/300], Step [65/225], Training Accuracy: 98.9183%, Training Loss: 0.0388%\n",
      "Epoch [137/300], Step [66/225], Training Accuracy: 98.9110%, Training Loss: 0.0389%\n",
      "Epoch [137/300], Step [67/225], Training Accuracy: 98.9272%, Training Loss: 0.0388%\n",
      "Epoch [137/300], Step [68/225], Training Accuracy: 98.9430%, Training Loss: 0.0387%\n",
      "Epoch [137/300], Step [69/225], Training Accuracy: 98.9357%, Training Loss: 0.0385%\n",
      "Epoch [137/300], Step [70/225], Training Accuracy: 98.9062%, Training Loss: 0.0385%\n",
      "Epoch [137/300], Step [71/225], Training Accuracy: 98.8996%, Training Loss: 0.0385%\n",
      "Epoch [137/300], Step [72/225], Training Accuracy: 98.8932%, Training Loss: 0.0384%\n",
      "Epoch [137/300], Step [73/225], Training Accuracy: 98.9084%, Training Loss: 0.0384%\n",
      "Epoch [137/300], Step [74/225], Training Accuracy: 98.9231%, Training Loss: 0.0380%\n",
      "Epoch [137/300], Step [75/225], Training Accuracy: 98.9375%, Training Loss: 0.0379%\n",
      "Epoch [137/300], Step [76/225], Training Accuracy: 98.9515%, Training Loss: 0.0380%\n",
      "Epoch [137/300], Step [77/225], Training Accuracy: 98.9245%, Training Loss: 0.0380%\n",
      "Epoch [137/300], Step [78/225], Training Accuracy: 98.9383%, Training Loss: 0.0377%\n",
      "Epoch [137/300], Step [79/225], Training Accuracy: 98.8924%, Training Loss: 0.0381%\n",
      "Epoch [137/300], Step [80/225], Training Accuracy: 98.8867%, Training Loss: 0.0386%\n",
      "Epoch [137/300], Step [81/225], Training Accuracy: 98.9005%, Training Loss: 0.0382%\n",
      "Epoch [137/300], Step [82/225], Training Accuracy: 98.8948%, Training Loss: 0.0381%\n",
      "Epoch [137/300], Step [83/225], Training Accuracy: 98.8705%, Training Loss: 0.0387%\n",
      "Epoch [137/300], Step [84/225], Training Accuracy: 98.8653%, Training Loss: 0.0387%\n",
      "Epoch [137/300], Step [85/225], Training Accuracy: 98.8787%, Training Loss: 0.0385%\n",
      "Epoch [137/300], Step [86/225], Training Accuracy: 98.8735%, Training Loss: 0.0386%\n",
      "Epoch [137/300], Step [87/225], Training Accuracy: 98.8865%, Training Loss: 0.0384%\n",
      "Epoch [137/300], Step [88/225], Training Accuracy: 98.8814%, Training Loss: 0.0385%\n",
      "Epoch [137/300], Step [89/225], Training Accuracy: 98.8940%, Training Loss: 0.0384%\n",
      "Epoch [137/300], Step [90/225], Training Accuracy: 98.9062%, Training Loss: 0.0382%\n",
      "Epoch [137/300], Step [91/225], Training Accuracy: 98.9183%, Training Loss: 0.0379%\n",
      "Epoch [137/300], Step [92/225], Training Accuracy: 98.9300%, Training Loss: 0.0378%\n",
      "Epoch [137/300], Step [93/225], Training Accuracy: 98.9079%, Training Loss: 0.0379%\n",
      "Epoch [137/300], Step [94/225], Training Accuracy: 98.9195%, Training Loss: 0.0377%\n",
      "Epoch [137/300], Step [95/225], Training Accuracy: 98.9145%, Training Loss: 0.0378%\n",
      "Epoch [137/300], Step [96/225], Training Accuracy: 98.8932%, Training Loss: 0.0379%\n",
      "Epoch [137/300], Step [97/225], Training Accuracy: 98.8724%, Training Loss: 0.0381%\n",
      "Epoch [137/300], Step [98/225], Training Accuracy: 98.8361%, Training Loss: 0.0389%\n",
      "Epoch [137/300], Step [99/225], Training Accuracy: 98.8321%, Training Loss: 0.0390%\n",
      "Epoch [137/300], Step [100/225], Training Accuracy: 98.8438%, Training Loss: 0.0389%\n",
      "Epoch [137/300], Step [101/225], Training Accuracy: 98.8397%, Training Loss: 0.0388%\n",
      "Epoch [137/300], Step [102/225], Training Accuracy: 98.8205%, Training Loss: 0.0393%\n",
      "Epoch [137/300], Step [103/225], Training Accuracy: 98.8319%, Training Loss: 0.0392%\n",
      "Epoch [137/300], Step [104/225], Training Accuracy: 98.8431%, Training Loss: 0.0390%\n",
      "Epoch [137/300], Step [105/225], Training Accuracy: 98.8393%, Training Loss: 0.0393%\n",
      "Epoch [137/300], Step [106/225], Training Accuracy: 98.8502%, Training Loss: 0.0392%\n",
      "Epoch [137/300], Step [107/225], Training Accuracy: 98.8610%, Training Loss: 0.0390%\n",
      "Epoch [137/300], Step [108/225], Training Accuracy: 98.8426%, Training Loss: 0.0393%\n",
      "Epoch [137/300], Step [109/225], Training Accuracy: 98.8245%, Training Loss: 0.0396%\n",
      "Epoch [137/300], Step [110/225], Training Accuracy: 98.8352%, Training Loss: 0.0396%\n",
      "Epoch [137/300], Step [111/225], Training Accuracy: 98.8316%, Training Loss: 0.0397%\n",
      "Epoch [137/300], Step [112/225], Training Accuracy: 98.8421%, Training Loss: 0.0396%\n",
      "Epoch [137/300], Step [113/225], Training Accuracy: 98.8247%, Training Loss: 0.0399%\n",
      "Epoch [137/300], Step [114/225], Training Accuracy: 98.8213%, Training Loss: 0.0399%\n",
      "Epoch [137/300], Step [115/225], Training Accuracy: 98.8179%, Training Loss: 0.0399%\n",
      "Epoch [137/300], Step [116/225], Training Accuracy: 98.8147%, Training Loss: 0.0398%\n",
      "Epoch [137/300], Step [117/225], Training Accuracy: 98.8114%, Training Loss: 0.0399%\n",
      "Epoch [137/300], Step [118/225], Training Accuracy: 98.8215%, Training Loss: 0.0398%\n",
      "Epoch [137/300], Step [119/225], Training Accuracy: 98.8051%, Training Loss: 0.0399%\n",
      "Epoch [137/300], Step [120/225], Training Accuracy: 98.8021%, Training Loss: 0.0401%\n",
      "Epoch [137/300], Step [121/225], Training Accuracy: 98.7991%, Training Loss: 0.0401%\n",
      "Epoch [137/300], Step [122/225], Training Accuracy: 98.8089%, Training Loss: 0.0400%\n",
      "Epoch [137/300], Step [123/225], Training Accuracy: 98.8059%, Training Loss: 0.0399%\n",
      "Epoch [137/300], Step [124/225], Training Accuracy: 98.7777%, Training Loss: 0.0402%\n",
      "Epoch [137/300], Step [125/225], Training Accuracy: 98.7625%, Training Loss: 0.0405%\n",
      "Epoch [137/300], Step [126/225], Training Accuracy: 98.7723%, Training Loss: 0.0403%\n",
      "Epoch [137/300], Step [127/225], Training Accuracy: 98.7697%, Training Loss: 0.0406%\n",
      "Epoch [137/300], Step [128/225], Training Accuracy: 98.7793%, Training Loss: 0.0403%\n",
      "Epoch [137/300], Step [129/225], Training Accuracy: 98.7766%, Training Loss: 0.0406%\n",
      "Epoch [137/300], Step [130/225], Training Accuracy: 98.7380%, Training Loss: 0.0413%\n",
      "Epoch [137/300], Step [131/225], Training Accuracy: 98.7476%, Training Loss: 0.0410%\n",
      "Epoch [137/300], Step [132/225], Training Accuracy: 98.7453%, Training Loss: 0.0411%\n",
      "Epoch [137/300], Step [133/225], Training Accuracy: 98.7547%, Training Loss: 0.0410%\n",
      "Epoch [137/300], Step [134/225], Training Accuracy: 98.7523%, Training Loss: 0.0410%\n",
      "Epoch [137/300], Step [135/225], Training Accuracy: 98.7384%, Training Loss: 0.0412%\n",
      "Epoch [137/300], Step [136/225], Training Accuracy: 98.7247%, Training Loss: 0.0413%\n",
      "Epoch [137/300], Step [137/225], Training Accuracy: 98.7340%, Training Loss: 0.0411%\n",
      "Epoch [137/300], Step [138/225], Training Accuracy: 98.7432%, Training Loss: 0.0410%\n",
      "Epoch [137/300], Step [139/225], Training Accuracy: 98.7522%, Training Loss: 0.0409%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [137/300], Step [140/225], Training Accuracy: 98.7612%, Training Loss: 0.0409%\n",
      "Epoch [137/300], Step [141/225], Training Accuracy: 98.7589%, Training Loss: 0.0409%\n",
      "Epoch [137/300], Step [142/225], Training Accuracy: 98.7676%, Training Loss: 0.0407%\n",
      "Epoch [137/300], Step [143/225], Training Accuracy: 98.7653%, Training Loss: 0.0407%\n",
      "Epoch [137/300], Step [144/225], Training Accuracy: 98.7522%, Training Loss: 0.0411%\n",
      "Epoch [137/300], Step [145/225], Training Accuracy: 98.7608%, Training Loss: 0.0411%\n",
      "Epoch [137/300], Step [146/225], Training Accuracy: 98.7693%, Training Loss: 0.0409%\n",
      "Epoch [137/300], Step [147/225], Training Accuracy: 98.7670%, Training Loss: 0.0407%\n",
      "Epoch [137/300], Step [148/225], Training Accuracy: 98.7648%, Training Loss: 0.0407%\n",
      "Epoch [137/300], Step [149/225], Training Accuracy: 98.7311%, Training Loss: 0.0414%\n",
      "Epoch [137/300], Step [150/225], Training Accuracy: 98.7396%, Training Loss: 0.0413%\n",
      "Epoch [137/300], Step [151/225], Training Accuracy: 98.7376%, Training Loss: 0.0412%\n",
      "Epoch [137/300], Step [152/225], Training Accuracy: 98.7459%, Training Loss: 0.0411%\n",
      "Epoch [137/300], Step [153/225], Training Accuracy: 98.7439%, Training Loss: 0.0411%\n",
      "Epoch [137/300], Step [154/225], Training Accuracy: 98.7317%, Training Loss: 0.0413%\n",
      "Epoch [137/300], Step [155/225], Training Accuracy: 98.7298%, Training Loss: 0.0412%\n",
      "Epoch [137/300], Step [156/225], Training Accuracy: 98.7380%, Training Loss: 0.0410%\n",
      "Epoch [137/300], Step [157/225], Training Accuracy: 98.7361%, Training Loss: 0.0411%\n",
      "Epoch [137/300], Step [158/225], Training Accuracy: 98.7342%, Training Loss: 0.0411%\n",
      "Epoch [137/300], Step [159/225], Training Accuracy: 98.7421%, Training Loss: 0.0410%\n",
      "Epoch [137/300], Step [160/225], Training Accuracy: 98.7305%, Training Loss: 0.0412%\n",
      "Epoch [137/300], Step [161/225], Training Accuracy: 98.7384%, Training Loss: 0.0411%\n",
      "Epoch [137/300], Step [162/225], Training Accuracy: 98.7076%, Training Loss: 0.0415%\n",
      "Epoch [137/300], Step [163/225], Training Accuracy: 98.7059%, Training Loss: 0.0415%\n",
      "Epoch [137/300], Step [164/225], Training Accuracy: 98.7043%, Training Loss: 0.0414%\n",
      "Epoch [137/300], Step [165/225], Training Accuracy: 98.7121%, Training Loss: 0.0413%\n",
      "Epoch [137/300], Step [166/225], Training Accuracy: 98.7105%, Training Loss: 0.0415%\n",
      "Epoch [137/300], Step [167/225], Training Accuracy: 98.7182%, Training Loss: 0.0413%\n",
      "Epoch [137/300], Step [168/225], Training Accuracy: 98.7258%, Training Loss: 0.0412%\n",
      "Epoch [137/300], Step [169/225], Training Accuracy: 98.7334%, Training Loss: 0.0411%\n",
      "Epoch [137/300], Step [170/225], Training Accuracy: 98.7040%, Training Loss: 0.0419%\n",
      "Epoch [137/300], Step [171/225], Training Accuracy: 98.7116%, Training Loss: 0.0418%\n",
      "Epoch [137/300], Step [172/225], Training Accuracy: 98.7009%, Training Loss: 0.0420%\n",
      "Epoch [137/300], Step [173/225], Training Accuracy: 98.6994%, Training Loss: 0.0420%\n",
      "Epoch [137/300], Step [174/225], Training Accuracy: 98.6979%, Training Loss: 0.0420%\n",
      "Epoch [137/300], Step [175/225], Training Accuracy: 98.6786%, Training Loss: 0.0425%\n",
      "Epoch [137/300], Step [176/225], Training Accuracy: 98.6861%, Training Loss: 0.0424%\n",
      "Epoch [137/300], Step [177/225], Training Accuracy: 98.6847%, Training Loss: 0.0423%\n",
      "Epoch [137/300], Step [178/225], Training Accuracy: 98.6921%, Training Loss: 0.0422%\n",
      "Epoch [137/300], Step [179/225], Training Accuracy: 98.6994%, Training Loss: 0.0422%\n",
      "Epoch [137/300], Step [180/225], Training Accuracy: 98.6979%, Training Loss: 0.0423%\n",
      "Epoch [137/300], Step [181/225], Training Accuracy: 98.7051%, Training Loss: 0.0422%\n",
      "Epoch [137/300], Step [182/225], Training Accuracy: 98.7122%, Training Loss: 0.0421%\n",
      "Epoch [137/300], Step [183/225], Training Accuracy: 98.7022%, Training Loss: 0.0421%\n",
      "Epoch [137/300], Step [184/225], Training Accuracy: 98.7007%, Training Loss: 0.0421%\n",
      "Epoch [137/300], Step [185/225], Training Accuracy: 98.6993%, Training Loss: 0.0421%\n",
      "Epoch [137/300], Step [186/225], Training Accuracy: 98.6979%, Training Loss: 0.0422%\n",
      "Epoch [137/300], Step [187/225], Training Accuracy: 98.6965%, Training Loss: 0.0423%\n",
      "Epoch [137/300], Step [188/225], Training Accuracy: 98.6951%, Training Loss: 0.0424%\n",
      "Epoch [137/300], Step [189/225], Training Accuracy: 98.7021%, Training Loss: 0.0423%\n",
      "Epoch [137/300], Step [190/225], Training Accuracy: 98.7007%, Training Loss: 0.0422%\n",
      "Epoch [137/300], Step [191/225], Training Accuracy: 98.6747%, Training Loss: 0.0426%\n",
      "Epoch [137/300], Step [192/225], Training Accuracy: 98.6816%, Training Loss: 0.0424%\n",
      "Epoch [137/300], Step [193/225], Training Accuracy: 98.6804%, Training Loss: 0.0426%\n",
      "Epoch [137/300], Step [194/225], Training Accuracy: 98.6872%, Training Loss: 0.0425%\n",
      "Epoch [137/300], Step [195/225], Training Accuracy: 98.6939%, Training Loss: 0.0424%\n",
      "Epoch [137/300], Step [196/225], Training Accuracy: 98.7006%, Training Loss: 0.0423%\n",
      "Epoch [137/300], Step [197/225], Training Accuracy: 98.6992%, Training Loss: 0.0424%\n",
      "Epoch [137/300], Step [198/225], Training Accuracy: 98.6979%, Training Loss: 0.0425%\n",
      "Epoch [137/300], Step [199/225], Training Accuracy: 98.6888%, Training Loss: 0.0426%\n",
      "Epoch [137/300], Step [200/225], Training Accuracy: 98.6875%, Training Loss: 0.0425%\n",
      "Epoch [137/300], Step [201/225], Training Accuracy: 98.6707%, Training Loss: 0.0430%\n",
      "Epoch [137/300], Step [202/225], Training Accuracy: 98.6696%, Training Loss: 0.0431%\n",
      "Epoch [137/300], Step [203/225], Training Accuracy: 98.6761%, Training Loss: 0.0432%\n",
      "Epoch [137/300], Step [204/225], Training Accuracy: 98.6673%, Training Loss: 0.0434%\n",
      "Epoch [137/300], Step [205/225], Training Accuracy: 98.6662%, Training Loss: 0.0434%\n",
      "Epoch [137/300], Step [206/225], Training Accuracy: 98.6650%, Training Loss: 0.0435%\n",
      "Epoch [137/300], Step [207/225], Training Accuracy: 98.6715%, Training Loss: 0.0435%\n",
      "Epoch [137/300], Step [208/225], Training Accuracy: 98.6704%, Training Loss: 0.0436%\n",
      "Epoch [137/300], Step [209/225], Training Accuracy: 98.6693%, Training Loss: 0.0436%\n",
      "Epoch [137/300], Step [210/225], Training Accuracy: 98.6756%, Training Loss: 0.0435%\n",
      "Epoch [137/300], Step [211/225], Training Accuracy: 98.6745%, Training Loss: 0.0436%\n",
      "Epoch [137/300], Step [212/225], Training Accuracy: 98.6733%, Training Loss: 0.0436%\n",
      "Epoch [137/300], Step [213/225], Training Accuracy: 98.6722%, Training Loss: 0.0436%\n",
      "Epoch [137/300], Step [214/225], Training Accuracy: 98.6784%, Training Loss: 0.0435%\n",
      "Epoch [137/300], Step [215/225], Training Accuracy: 98.6701%, Training Loss: 0.0437%\n",
      "Epoch [137/300], Step [216/225], Training Accuracy: 98.6690%, Training Loss: 0.0438%\n",
      "Epoch [137/300], Step [217/225], Training Accuracy: 98.6751%, Training Loss: 0.0437%\n",
      "Epoch [137/300], Step [218/225], Training Accuracy: 98.6669%, Training Loss: 0.0438%\n",
      "Epoch [137/300], Step [219/225], Training Accuracy: 98.6587%, Training Loss: 0.0438%\n",
      "Epoch [137/300], Step [220/225], Training Accuracy: 98.6577%, Training Loss: 0.0438%\n",
      "Epoch [137/300], Step [221/225], Training Accuracy: 98.6637%, Training Loss: 0.0437%\n",
      "Epoch [137/300], Step [222/225], Training Accuracy: 98.6627%, Training Loss: 0.0437%\n",
      "Epoch [137/300], Step [223/225], Training Accuracy: 98.6547%, Training Loss: 0.0438%\n",
      "Epoch [137/300], Step [224/225], Training Accuracy: 98.6607%, Training Loss: 0.0438%\n",
      "Epoch [137/300], Step [225/225], Training Accuracy: 98.6659%, Training Loss: 0.0437%\n",
      "Epoch [138/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0233%\n",
      "Epoch [138/300], Step [2/225], Training Accuracy: 99.2188%, Training Loss: 0.0249%\n",
      "Epoch [138/300], Step [3/225], Training Accuracy: 99.4792%, Training Loss: 0.0247%\n",
      "Epoch [138/300], Step [4/225], Training Accuracy: 99.6094%, Training Loss: 0.0224%\n",
      "Epoch [138/300], Step [5/225], Training Accuracy: 99.0625%, Training Loss: 0.0379%\n",
      "Epoch [138/300], Step [6/225], Training Accuracy: 98.9583%, Training Loss: 0.0361%\n",
      "Epoch [138/300], Step [7/225], Training Accuracy: 99.1071%, Training Loss: 0.0332%\n",
      "Epoch [138/300], Step [8/225], Training Accuracy: 99.0234%, Training Loss: 0.0350%\n",
      "Epoch [138/300], Step [9/225], Training Accuracy: 99.1319%, Training Loss: 0.0339%\n",
      "Epoch [138/300], Step [10/225], Training Accuracy: 98.9062%, Training Loss: 0.0362%\n",
      "Epoch [138/300], Step [11/225], Training Accuracy: 98.8636%, Training Loss: 0.0352%\n",
      "Epoch [138/300], Step [12/225], Training Accuracy: 98.9583%, Training Loss: 0.0339%\n",
      "Epoch [138/300], Step [13/225], Training Accuracy: 99.0385%, Training Loss: 0.0335%\n",
      "Epoch [138/300], Step [14/225], Training Accuracy: 98.9955%, Training Loss: 0.0346%\n",
      "Epoch [138/300], Step [15/225], Training Accuracy: 99.0625%, Training Loss: 0.0332%\n",
      "Epoch [138/300], Step [16/225], Training Accuracy: 98.8281%, Training Loss: 0.0354%\n",
      "Epoch [138/300], Step [17/225], Training Accuracy: 98.8051%, Training Loss: 0.0356%\n",
      "Epoch [138/300], Step [18/225], Training Accuracy: 98.8715%, Training Loss: 0.0358%\n",
      "Epoch [138/300], Step [19/225], Training Accuracy: 98.9309%, Training Loss: 0.0344%\n",
      "Epoch [138/300], Step [20/225], Training Accuracy: 98.8281%, Training Loss: 0.0350%\n",
      "Epoch [138/300], Step [21/225], Training Accuracy: 98.8095%, Training Loss: 0.0358%\n",
      "Epoch [138/300], Step [22/225], Training Accuracy: 98.8636%, Training Loss: 0.0351%\n",
      "Epoch [138/300], Step [23/225], Training Accuracy: 98.9130%, Training Loss: 0.0341%\n",
      "Epoch [138/300], Step [24/225], Training Accuracy: 98.8281%, Training Loss: 0.0350%\n",
      "Epoch [138/300], Step [25/225], Training Accuracy: 98.8750%, Training Loss: 0.0345%\n",
      "Epoch [138/300], Step [26/225], Training Accuracy: 98.9183%, Training Loss: 0.0346%\n",
      "Epoch [138/300], Step [27/225], Training Accuracy: 98.8426%, Training Loss: 0.0361%\n",
      "Epoch [138/300], Step [28/225], Training Accuracy: 98.8281%, Training Loss: 0.0358%\n",
      "Epoch [138/300], Step [29/225], Training Accuracy: 98.8685%, Training Loss: 0.0355%\n",
      "Epoch [138/300], Step [30/225], Training Accuracy: 98.8021%, Training Loss: 0.0375%\n",
      "Epoch [138/300], Step [31/225], Training Accuracy: 98.7903%, Training Loss: 0.0373%\n",
      "Epoch [138/300], Step [32/225], Training Accuracy: 98.7305%, Training Loss: 0.0377%\n",
      "Epoch [138/300], Step [33/225], Training Accuracy: 98.7689%, Training Loss: 0.0371%\n",
      "Epoch [138/300], Step [34/225], Training Accuracy: 98.7592%, Training Loss: 0.0373%\n",
      "Epoch [138/300], Step [35/225], Training Accuracy: 98.7946%, Training Loss: 0.0373%\n",
      "Epoch [138/300], Step [36/225], Training Accuracy: 98.7847%, Training Loss: 0.0376%\n",
      "Epoch [138/300], Step [37/225], Training Accuracy: 98.7753%, Training Loss: 0.0376%\n",
      "Epoch [138/300], Step [38/225], Training Accuracy: 98.8076%, Training Loss: 0.0376%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [138/300], Step [39/225], Training Accuracy: 98.8381%, Training Loss: 0.0370%\n",
      "Epoch [138/300], Step [40/225], Training Accuracy: 98.7891%, Training Loss: 0.0376%\n",
      "Epoch [138/300], Step [41/225], Training Accuracy: 98.8186%, Training Loss: 0.0373%\n",
      "Epoch [138/300], Step [42/225], Training Accuracy: 98.8467%, Training Loss: 0.0365%\n",
      "Epoch [138/300], Step [43/225], Training Accuracy: 98.8372%, Training Loss: 0.0365%\n",
      "Epoch [138/300], Step [44/225], Training Accuracy: 98.8636%, Training Loss: 0.0360%\n",
      "Epoch [138/300], Step [45/225], Training Accuracy: 98.8889%, Training Loss: 0.0358%\n",
      "Epoch [138/300], Step [46/225], Training Accuracy: 98.8791%, Training Loss: 0.0357%\n",
      "Epoch [138/300], Step [47/225], Training Accuracy: 98.9029%, Training Loss: 0.0353%\n",
      "Epoch [138/300], Step [48/225], Training Accuracy: 98.8607%, Training Loss: 0.0365%\n",
      "Epoch [138/300], Step [49/225], Training Accuracy: 98.8520%, Training Loss: 0.0371%\n",
      "Epoch [138/300], Step [50/225], Training Accuracy: 98.8125%, Training Loss: 0.0376%\n",
      "Epoch [138/300], Step [51/225], Training Accuracy: 98.8358%, Training Loss: 0.0370%\n",
      "Epoch [138/300], Step [52/225], Training Accuracy: 98.8281%, Training Loss: 0.0371%\n",
      "Epoch [138/300], Step [53/225], Training Accuracy: 98.8502%, Training Loss: 0.0369%\n",
      "Epoch [138/300], Step [54/225], Training Accuracy: 98.8137%, Training Loss: 0.0373%\n",
      "Epoch [138/300], Step [55/225], Training Accuracy: 98.7500%, Training Loss: 0.0380%\n",
      "Epoch [138/300], Step [56/225], Training Accuracy: 98.7723%, Training Loss: 0.0377%\n",
      "Epoch [138/300], Step [57/225], Training Accuracy: 98.7390%, Training Loss: 0.0389%\n",
      "Epoch [138/300], Step [58/225], Training Accuracy: 98.7608%, Training Loss: 0.0387%\n",
      "Epoch [138/300], Step [59/225], Training Accuracy: 98.7818%, Training Loss: 0.0384%\n",
      "Epoch [138/300], Step [60/225], Training Accuracy: 98.8021%, Training Loss: 0.0381%\n",
      "Epoch [138/300], Step [61/225], Training Accuracy: 98.7193%, Training Loss: 0.0402%\n",
      "Epoch [138/300], Step [62/225], Training Accuracy: 98.7399%, Training Loss: 0.0400%\n",
      "Epoch [138/300], Step [63/225], Training Accuracy: 98.7351%, Training Loss: 0.0399%\n",
      "Epoch [138/300], Step [64/225], Training Accuracy: 98.7549%, Training Loss: 0.0396%\n",
      "Epoch [138/300], Step [65/225], Training Accuracy: 98.6779%, Training Loss: 0.0409%\n",
      "Epoch [138/300], Step [66/225], Training Accuracy: 98.6742%, Training Loss: 0.0412%\n",
      "Epoch [138/300], Step [67/225], Training Accuracy: 98.6940%, Training Loss: 0.0409%\n",
      "Epoch [138/300], Step [68/225], Training Accuracy: 98.7132%, Training Loss: 0.0405%\n",
      "Epoch [138/300], Step [69/225], Training Accuracy: 98.7092%, Training Loss: 0.0406%\n",
      "Epoch [138/300], Step [70/225], Training Accuracy: 98.6830%, Training Loss: 0.0407%\n",
      "Epoch [138/300], Step [71/225], Training Accuracy: 98.6796%, Training Loss: 0.0413%\n",
      "Epoch [138/300], Step [72/225], Training Accuracy: 98.6762%, Training Loss: 0.0418%\n",
      "Epoch [138/300], Step [73/225], Training Accuracy: 98.6515%, Training Loss: 0.0424%\n",
      "Epoch [138/300], Step [74/225], Training Accuracy: 98.6486%, Training Loss: 0.0426%\n",
      "Epoch [138/300], Step [75/225], Training Accuracy: 98.6250%, Training Loss: 0.0427%\n",
      "Epoch [138/300], Step [76/225], Training Accuracy: 98.6431%, Training Loss: 0.0425%\n",
      "Epoch [138/300], Step [77/225], Training Accuracy: 98.6607%, Training Loss: 0.0422%\n",
      "Epoch [138/300], Step [78/225], Training Accuracy: 98.6779%, Training Loss: 0.0418%\n",
      "Epoch [138/300], Step [79/225], Training Accuracy: 98.6551%, Training Loss: 0.0419%\n",
      "Epoch [138/300], Step [80/225], Training Accuracy: 98.6328%, Training Loss: 0.0421%\n",
      "Epoch [138/300], Step [81/225], Training Accuracy: 98.6304%, Training Loss: 0.0420%\n",
      "Epoch [138/300], Step [82/225], Training Accuracy: 98.6280%, Training Loss: 0.0421%\n",
      "Epoch [138/300], Step [83/225], Training Accuracy: 98.6258%, Training Loss: 0.0425%\n",
      "Epoch [138/300], Step [84/225], Training Accuracy: 98.6421%, Training Loss: 0.0422%\n",
      "Epoch [138/300], Step [85/225], Training Accuracy: 98.6397%, Training Loss: 0.0421%\n",
      "Epoch [138/300], Step [86/225], Training Accuracy: 98.6192%, Training Loss: 0.0425%\n",
      "Epoch [138/300], Step [87/225], Training Accuracy: 98.6171%, Training Loss: 0.0426%\n",
      "Epoch [138/300], Step [88/225], Training Accuracy: 98.5973%, Training Loss: 0.0428%\n",
      "Epoch [138/300], Step [89/225], Training Accuracy: 98.5779%, Training Loss: 0.0430%\n",
      "Epoch [138/300], Step [90/225], Training Accuracy: 98.5938%, Training Loss: 0.0428%\n",
      "Epoch [138/300], Step [91/225], Training Accuracy: 98.5920%, Training Loss: 0.0426%\n",
      "Epoch [138/300], Step [92/225], Training Accuracy: 98.6073%, Training Loss: 0.0426%\n",
      "Epoch [138/300], Step [93/225], Training Accuracy: 98.6055%, Training Loss: 0.0426%\n",
      "Epoch [138/300], Step [94/225], Training Accuracy: 98.5871%, Training Loss: 0.0426%\n",
      "Epoch [138/300], Step [95/225], Training Accuracy: 98.5691%, Training Loss: 0.0428%\n",
      "Epoch [138/300], Step [96/225], Training Accuracy: 98.5677%, Training Loss: 0.0429%\n",
      "Epoch [138/300], Step [97/225], Training Accuracy: 98.5503%, Training Loss: 0.0432%\n",
      "Epoch [138/300], Step [98/225], Training Accuracy: 98.5491%, Training Loss: 0.0432%\n",
      "Epoch [138/300], Step [99/225], Training Accuracy: 98.5322%, Training Loss: 0.0434%\n",
      "Epoch [138/300], Step [100/225], Training Accuracy: 98.5156%, Training Loss: 0.0441%\n",
      "Epoch [138/300], Step [101/225], Training Accuracy: 98.5149%, Training Loss: 0.0440%\n",
      "Epoch [138/300], Step [102/225], Training Accuracy: 98.5141%, Training Loss: 0.0438%\n",
      "Epoch [138/300], Step [103/225], Training Accuracy: 98.5133%, Training Loss: 0.0438%\n",
      "Epoch [138/300], Step [104/225], Training Accuracy: 98.4826%, Training Loss: 0.0443%\n",
      "Epoch [138/300], Step [105/225], Training Accuracy: 98.4821%, Training Loss: 0.0444%\n",
      "Epoch [138/300], Step [106/225], Training Accuracy: 98.4670%, Training Loss: 0.0446%\n",
      "Epoch [138/300], Step [107/225], Training Accuracy: 98.4813%, Training Loss: 0.0443%\n",
      "Epoch [138/300], Step [108/225], Training Accuracy: 98.4809%, Training Loss: 0.0445%\n",
      "Epoch [138/300], Step [109/225], Training Accuracy: 98.4518%, Training Loss: 0.0451%\n",
      "Epoch [138/300], Step [110/225], Training Accuracy: 98.4659%, Training Loss: 0.0449%\n",
      "Epoch [138/300], Step [111/225], Training Accuracy: 98.4797%, Training Loss: 0.0446%\n",
      "Epoch [138/300], Step [112/225], Training Accuracy: 98.4933%, Training Loss: 0.0443%\n",
      "Epoch [138/300], Step [113/225], Training Accuracy: 98.4928%, Training Loss: 0.0443%\n",
      "Epoch [138/300], Step [114/225], Training Accuracy: 98.5060%, Training Loss: 0.0442%\n",
      "Epoch [138/300], Step [115/225], Training Accuracy: 98.5054%, Training Loss: 0.0442%\n",
      "Epoch [138/300], Step [116/225], Training Accuracy: 98.5183%, Training Loss: 0.0440%\n",
      "Epoch [138/300], Step [117/225], Training Accuracy: 98.4909%, Training Loss: 0.0443%\n",
      "Epoch [138/300], Step [118/225], Training Accuracy: 98.4905%, Training Loss: 0.0442%\n",
      "Epoch [138/300], Step [119/225], Training Accuracy: 98.5032%, Training Loss: 0.0440%\n",
      "Epoch [138/300], Step [120/225], Training Accuracy: 98.5156%, Training Loss: 0.0437%\n",
      "Epoch [138/300], Step [121/225], Training Accuracy: 98.5150%, Training Loss: 0.0435%\n",
      "Epoch [138/300], Step [122/225], Training Accuracy: 98.5015%, Training Loss: 0.0437%\n",
      "Epoch [138/300], Step [123/225], Training Accuracy: 98.5010%, Training Loss: 0.0437%\n",
      "Epoch [138/300], Step [124/225], Training Accuracy: 98.5005%, Training Loss: 0.0436%\n",
      "Epoch [138/300], Step [125/225], Training Accuracy: 98.5125%, Training Loss: 0.0434%\n",
      "Epoch [138/300], Step [126/225], Training Accuracy: 98.5119%, Training Loss: 0.0435%\n",
      "Epoch [138/300], Step [127/225], Training Accuracy: 98.4990%, Training Loss: 0.0438%\n",
      "Epoch [138/300], Step [128/225], Training Accuracy: 98.4741%, Training Loss: 0.0447%\n",
      "Epoch [138/300], Step [129/225], Training Accuracy: 98.4617%, Training Loss: 0.0449%\n",
      "Epoch [138/300], Step [130/225], Training Accuracy: 98.4615%, Training Loss: 0.0450%\n",
      "Epoch [138/300], Step [131/225], Training Accuracy: 98.4614%, Training Loss: 0.0451%\n",
      "Epoch [138/300], Step [132/225], Training Accuracy: 98.4493%, Training Loss: 0.0453%\n",
      "Epoch [138/300], Step [133/225], Training Accuracy: 98.4492%, Training Loss: 0.0453%\n",
      "Epoch [138/300], Step [134/225], Training Accuracy: 98.4492%, Training Loss: 0.0453%\n",
      "Epoch [138/300], Step [135/225], Training Accuracy: 98.4606%, Training Loss: 0.0451%\n",
      "Epoch [138/300], Step [136/225], Training Accuracy: 98.4490%, Training Loss: 0.0454%\n",
      "Epoch [138/300], Step [137/225], Training Accuracy: 98.4603%, Training Loss: 0.0452%\n",
      "Epoch [138/300], Step [138/225], Training Accuracy: 98.4715%, Training Loss: 0.0450%\n",
      "Epoch [138/300], Step [139/225], Training Accuracy: 98.4712%, Training Loss: 0.0450%\n",
      "Epoch [138/300], Step [140/225], Training Accuracy: 98.4710%, Training Loss: 0.0450%\n",
      "Epoch [138/300], Step [141/225], Training Accuracy: 98.4486%, Training Loss: 0.0453%\n",
      "Epoch [138/300], Step [142/225], Training Accuracy: 98.4485%, Training Loss: 0.0452%\n",
      "Epoch [138/300], Step [143/225], Training Accuracy: 98.4594%, Training Loss: 0.0451%\n",
      "Epoch [138/300], Step [144/225], Training Accuracy: 98.4701%, Training Loss: 0.0450%\n",
      "Epoch [138/300], Step [145/225], Training Accuracy: 98.4806%, Training Loss: 0.0448%\n",
      "Epoch [138/300], Step [146/225], Training Accuracy: 98.4803%, Training Loss: 0.0449%\n",
      "Epoch [138/300], Step [147/225], Training Accuracy: 98.4906%, Training Loss: 0.0447%\n",
      "Epoch [138/300], Step [148/225], Training Accuracy: 98.4903%, Training Loss: 0.0448%\n",
      "Epoch [138/300], Step [149/225], Training Accuracy: 98.4794%, Training Loss: 0.0449%\n",
      "Epoch [138/300], Step [150/225], Training Accuracy: 98.4896%, Training Loss: 0.0447%\n",
      "Epoch [138/300], Step [151/225], Training Accuracy: 98.4892%, Training Loss: 0.0447%\n",
      "Epoch [138/300], Step [152/225], Training Accuracy: 98.4683%, Training Loss: 0.0451%\n",
      "Epoch [138/300], Step [153/225], Training Accuracy: 98.4783%, Training Loss: 0.0451%\n",
      "Epoch [138/300], Step [154/225], Training Accuracy: 98.4882%, Training Loss: 0.0451%\n",
      "Epoch [138/300], Step [155/225], Training Accuracy: 98.4677%, Training Loss: 0.0454%\n",
      "Epoch [138/300], Step [156/225], Training Accuracy: 98.4776%, Training Loss: 0.0453%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [138/300], Step [157/225], Training Accuracy: 98.4873%, Training Loss: 0.0451%\n",
      "Epoch [138/300], Step [158/225], Training Accuracy: 98.4968%, Training Loss: 0.0449%\n",
      "Epoch [138/300], Step [159/225], Training Accuracy: 98.4866%, Training Loss: 0.0454%\n",
      "Epoch [138/300], Step [160/225], Training Accuracy: 98.4961%, Training Loss: 0.0452%\n",
      "Epoch [138/300], Step [161/225], Training Accuracy: 98.4763%, Training Loss: 0.0456%\n",
      "Epoch [138/300], Step [162/225], Training Accuracy: 98.4857%, Training Loss: 0.0454%\n",
      "Epoch [138/300], Step [163/225], Training Accuracy: 98.4854%, Training Loss: 0.0454%\n",
      "Epoch [138/300], Step [164/225], Training Accuracy: 98.4947%, Training Loss: 0.0453%\n",
      "Epoch [138/300], Step [165/225], Training Accuracy: 98.5038%, Training Loss: 0.0452%\n",
      "Epoch [138/300], Step [166/225], Training Accuracy: 98.4940%, Training Loss: 0.0453%\n",
      "Epoch [138/300], Step [167/225], Training Accuracy: 98.4936%, Training Loss: 0.0454%\n",
      "Epoch [138/300], Step [168/225], Training Accuracy: 98.5026%, Training Loss: 0.0452%\n",
      "Epoch [138/300], Step [169/225], Training Accuracy: 98.5022%, Training Loss: 0.0452%\n",
      "Epoch [138/300], Step [170/225], Training Accuracy: 98.5018%, Training Loss: 0.0454%\n",
      "Epoch [138/300], Step [171/225], Training Accuracy: 98.5015%, Training Loss: 0.0454%\n",
      "Epoch [138/300], Step [172/225], Training Accuracy: 98.4920%, Training Loss: 0.0456%\n",
      "Epoch [138/300], Step [173/225], Training Accuracy: 98.4917%, Training Loss: 0.0455%\n",
      "Epoch [138/300], Step [174/225], Training Accuracy: 98.4824%, Training Loss: 0.0457%\n",
      "Epoch [138/300], Step [175/225], Training Accuracy: 98.4911%, Training Loss: 0.0455%\n",
      "Epoch [138/300], Step [176/225], Training Accuracy: 98.4908%, Training Loss: 0.0455%\n",
      "Epoch [138/300], Step [177/225], Training Accuracy: 98.4993%, Training Loss: 0.0454%\n",
      "Epoch [138/300], Step [178/225], Training Accuracy: 98.4989%, Training Loss: 0.0454%\n",
      "Epoch [138/300], Step [179/225], Training Accuracy: 98.4899%, Training Loss: 0.0456%\n",
      "Epoch [138/300], Step [180/225], Training Accuracy: 98.4983%, Training Loss: 0.0454%\n",
      "Epoch [138/300], Step [181/225], Training Accuracy: 98.4893%, Training Loss: 0.0455%\n",
      "Epoch [138/300], Step [182/225], Training Accuracy: 98.4976%, Training Loss: 0.0454%\n",
      "Epoch [138/300], Step [183/225], Training Accuracy: 98.5058%, Training Loss: 0.0453%\n",
      "Epoch [138/300], Step [184/225], Training Accuracy: 98.5139%, Training Loss: 0.0453%\n",
      "Epoch [138/300], Step [185/225], Training Accuracy: 98.5135%, Training Loss: 0.0452%\n",
      "Epoch [138/300], Step [186/225], Training Accuracy: 98.5047%, Training Loss: 0.0452%\n",
      "Epoch [138/300], Step [187/225], Training Accuracy: 98.5127%, Training Loss: 0.0451%\n",
      "Epoch [138/300], Step [188/225], Training Accuracy: 98.5206%, Training Loss: 0.0449%\n",
      "Epoch [138/300], Step [189/225], Training Accuracy: 98.5202%, Training Loss: 0.0450%\n",
      "Epoch [138/300], Step [190/225], Training Accuracy: 98.5115%, Training Loss: 0.0451%\n",
      "Epoch [138/300], Step [191/225], Training Accuracy: 98.5111%, Training Loss: 0.0450%\n",
      "Epoch [138/300], Step [192/225], Training Accuracy: 98.5107%, Training Loss: 0.0450%\n",
      "Epoch [138/300], Step [193/225], Training Accuracy: 98.5185%, Training Loss: 0.0449%\n",
      "Epoch [138/300], Step [194/225], Training Accuracy: 98.5261%, Training Loss: 0.0449%\n",
      "Epoch [138/300], Step [195/225], Training Accuracy: 98.5337%, Training Loss: 0.0448%\n",
      "Epoch [138/300], Step [196/225], Training Accuracy: 98.5332%, Training Loss: 0.0448%\n",
      "Epoch [138/300], Step [197/225], Training Accuracy: 98.5406%, Training Loss: 0.0447%\n",
      "Epoch [138/300], Step [198/225], Training Accuracy: 98.5322%, Training Loss: 0.0448%\n",
      "Epoch [138/300], Step [199/225], Training Accuracy: 98.5239%, Training Loss: 0.0450%\n",
      "Epoch [138/300], Step [200/225], Training Accuracy: 98.5078%, Training Loss: 0.0452%\n",
      "Epoch [138/300], Step [201/225], Training Accuracy: 98.4919%, Training Loss: 0.0456%\n",
      "Epoch [138/300], Step [202/225], Training Accuracy: 98.4916%, Training Loss: 0.0456%\n",
      "Epoch [138/300], Step [203/225], Training Accuracy: 98.4991%, Training Loss: 0.0455%\n",
      "Epoch [138/300], Step [204/225], Training Accuracy: 98.4988%, Training Loss: 0.0455%\n",
      "Epoch [138/300], Step [205/225], Training Accuracy: 98.5061%, Training Loss: 0.0454%\n",
      "Epoch [138/300], Step [206/225], Training Accuracy: 98.4906%, Training Loss: 0.0458%\n",
      "Epoch [138/300], Step [207/225], Training Accuracy: 98.4979%, Training Loss: 0.0457%\n",
      "Epoch [138/300], Step [208/225], Training Accuracy: 98.5051%, Training Loss: 0.0456%\n",
      "Epoch [138/300], Step [209/225], Training Accuracy: 98.5048%, Training Loss: 0.0455%\n",
      "Epoch [138/300], Step [210/225], Training Accuracy: 98.5119%, Training Loss: 0.0455%\n",
      "Epoch [138/300], Step [211/225], Training Accuracy: 98.5116%, Training Loss: 0.0456%\n",
      "Epoch [138/300], Step [212/225], Training Accuracy: 98.5186%, Training Loss: 0.0455%\n",
      "Epoch [138/300], Step [213/225], Training Accuracy: 98.5182%, Training Loss: 0.0455%\n",
      "Epoch [138/300], Step [214/225], Training Accuracy: 98.5105%, Training Loss: 0.0458%\n",
      "Epoch [138/300], Step [215/225], Training Accuracy: 98.5029%, Training Loss: 0.0459%\n",
      "Epoch [138/300], Step [216/225], Training Accuracy: 98.4954%, Training Loss: 0.0461%\n",
      "Epoch [138/300], Step [217/225], Training Accuracy: 98.4879%, Training Loss: 0.0462%\n",
      "Epoch [138/300], Step [218/225], Training Accuracy: 98.4877%, Training Loss: 0.0462%\n",
      "Epoch [138/300], Step [219/225], Training Accuracy: 98.4874%, Training Loss: 0.0462%\n",
      "Epoch [138/300], Step [220/225], Training Accuracy: 98.4872%, Training Loss: 0.0462%\n",
      "Epoch [138/300], Step [221/225], Training Accuracy: 98.4729%, Training Loss: 0.0465%\n",
      "Epoch [138/300], Step [222/225], Training Accuracy: 98.4657%, Training Loss: 0.0466%\n",
      "Epoch [138/300], Step [223/225], Training Accuracy: 98.4655%, Training Loss: 0.0468%\n",
      "Epoch [138/300], Step [224/225], Training Accuracy: 98.4724%, Training Loss: 0.0466%\n",
      "Epoch [138/300], Step [225/225], Training Accuracy: 98.4783%, Training Loss: 0.0465%\n",
      "Epoch [139/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0236%\n",
      "Epoch [139/300], Step [2/225], Training Accuracy: 99.2188%, Training Loss: 0.0336%\n",
      "Epoch [139/300], Step [3/225], Training Accuracy: 98.9583%, Training Loss: 0.0370%\n",
      "Epoch [139/300], Step [4/225], Training Accuracy: 98.4375%, Training Loss: 0.0404%\n",
      "Epoch [139/300], Step [5/225], Training Accuracy: 98.7500%, Training Loss: 0.0373%\n",
      "Epoch [139/300], Step [6/225], Training Accuracy: 98.9583%, Training Loss: 0.0352%\n",
      "Epoch [139/300], Step [7/225], Training Accuracy: 99.1071%, Training Loss: 0.0337%\n",
      "Epoch [139/300], Step [8/225], Training Accuracy: 99.2188%, Training Loss: 0.0362%\n",
      "Epoch [139/300], Step [9/225], Training Accuracy: 99.3056%, Training Loss: 0.0353%\n",
      "Epoch [139/300], Step [10/225], Training Accuracy: 99.0625%, Training Loss: 0.0390%\n",
      "Epoch [139/300], Step [11/225], Training Accuracy: 99.1477%, Training Loss: 0.0365%\n",
      "Epoch [139/300], Step [12/225], Training Accuracy: 99.2188%, Training Loss: 0.0349%\n",
      "Epoch [139/300], Step [13/225], Training Accuracy: 99.0385%, Training Loss: 0.0363%\n",
      "Epoch [139/300], Step [14/225], Training Accuracy: 99.1071%, Training Loss: 0.0348%\n",
      "Epoch [139/300], Step [15/225], Training Accuracy: 99.0625%, Training Loss: 0.0354%\n",
      "Epoch [139/300], Step [16/225], Training Accuracy: 99.1211%, Training Loss: 0.0350%\n",
      "Epoch [139/300], Step [17/225], Training Accuracy: 99.0809%, Training Loss: 0.0356%\n",
      "Epoch [139/300], Step [18/225], Training Accuracy: 99.0451%, Training Loss: 0.0359%\n",
      "Epoch [139/300], Step [19/225], Training Accuracy: 99.0954%, Training Loss: 0.0352%\n",
      "Epoch [139/300], Step [20/225], Training Accuracy: 99.0625%, Training Loss: 0.0357%\n",
      "Epoch [139/300], Step [21/225], Training Accuracy: 99.1071%, Training Loss: 0.0350%\n",
      "Epoch [139/300], Step [22/225], Training Accuracy: 99.0767%, Training Loss: 0.0355%\n",
      "Epoch [139/300], Step [23/225], Training Accuracy: 99.1168%, Training Loss: 0.0349%\n",
      "Epoch [139/300], Step [24/225], Training Accuracy: 99.0234%, Training Loss: 0.0379%\n",
      "Epoch [139/300], Step [25/225], Training Accuracy: 99.0625%, Training Loss: 0.0378%\n",
      "Epoch [139/300], Step [26/225], Training Accuracy: 98.9784%, Training Loss: 0.0394%\n",
      "Epoch [139/300], Step [27/225], Training Accuracy: 99.0162%, Training Loss: 0.0391%\n",
      "Epoch [139/300], Step [28/225], Training Accuracy: 99.0513%, Training Loss: 0.0383%\n",
      "Epoch [139/300], Step [29/225], Training Accuracy: 99.0302%, Training Loss: 0.0380%\n",
      "Epoch [139/300], Step [30/225], Training Accuracy: 99.0625%, Training Loss: 0.0378%\n",
      "Epoch [139/300], Step [31/225], Training Accuracy: 98.9919%, Training Loss: 0.0402%\n",
      "Epoch [139/300], Step [32/225], Training Accuracy: 99.0234%, Training Loss: 0.0395%\n",
      "Epoch [139/300], Step [33/225], Training Accuracy: 99.0530%, Training Loss: 0.0392%\n",
      "Epoch [139/300], Step [34/225], Training Accuracy: 99.0349%, Training Loss: 0.0397%\n",
      "Epoch [139/300], Step [35/225], Training Accuracy: 99.0179%, Training Loss: 0.0408%\n",
      "Epoch [139/300], Step [36/225], Training Accuracy: 99.0017%, Training Loss: 0.0405%\n",
      "Epoch [139/300], Step [37/225], Training Accuracy: 98.9865%, Training Loss: 0.0402%\n",
      "Epoch [139/300], Step [38/225], Training Accuracy: 98.9720%, Training Loss: 0.0407%\n",
      "Epoch [139/300], Step [39/225], Training Accuracy: 98.9183%, Training Loss: 0.0424%\n",
      "Epoch [139/300], Step [40/225], Training Accuracy: 98.9453%, Training Loss: 0.0418%\n",
      "Epoch [139/300], Step [41/225], Training Accuracy: 98.9329%, Training Loss: 0.0417%\n",
      "Epoch [139/300], Step [42/225], Training Accuracy: 98.8839%, Training Loss: 0.0424%\n",
      "Epoch [139/300], Step [43/225], Training Accuracy: 98.8372%, Training Loss: 0.0430%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [139/300], Step [44/225], Training Accuracy: 98.8636%, Training Loss: 0.0426%\n",
      "Epoch [139/300], Step [45/225], Training Accuracy: 98.8194%, Training Loss: 0.0427%\n",
      "Epoch [139/300], Step [46/225], Training Accuracy: 98.8111%, Training Loss: 0.0431%\n",
      "Epoch [139/300], Step [47/225], Training Accuracy: 98.7699%, Training Loss: 0.0435%\n",
      "Epoch [139/300], Step [48/225], Training Accuracy: 98.7630%, Training Loss: 0.0434%\n",
      "Epoch [139/300], Step [49/225], Training Accuracy: 98.7245%, Training Loss: 0.0441%\n",
      "Epoch [139/300], Step [50/225], Training Accuracy: 98.7500%, Training Loss: 0.0438%\n",
      "Epoch [139/300], Step [51/225], Training Accuracy: 98.7439%, Training Loss: 0.0441%\n",
      "Epoch [139/300], Step [52/225], Training Accuracy: 98.7079%, Training Loss: 0.0448%\n",
      "Epoch [139/300], Step [53/225], Training Accuracy: 98.7028%, Training Loss: 0.0454%\n",
      "Epoch [139/300], Step [54/225], Training Accuracy: 98.6979%, Training Loss: 0.0454%\n",
      "Epoch [139/300], Step [55/225], Training Accuracy: 98.6648%, Training Loss: 0.0456%\n",
      "Epoch [139/300], Step [56/225], Training Accuracy: 98.6049%, Training Loss: 0.0458%\n",
      "Epoch [139/300], Step [57/225], Training Accuracy: 98.6294%, Training Loss: 0.0453%\n",
      "Epoch [139/300], Step [58/225], Training Accuracy: 98.6261%, Training Loss: 0.0451%\n",
      "Epoch [139/300], Step [59/225], Training Accuracy: 98.6494%, Training Loss: 0.0446%\n",
      "Epoch [139/300], Step [60/225], Training Accuracy: 98.6198%, Training Loss: 0.0453%\n",
      "Epoch [139/300], Step [61/225], Training Accuracy: 98.5656%, Training Loss: 0.0458%\n",
      "Epoch [139/300], Step [62/225], Training Accuracy: 98.5635%, Training Loss: 0.0455%\n",
      "Epoch [139/300], Step [63/225], Training Accuracy: 98.5615%, Training Loss: 0.0457%\n",
      "Epoch [139/300], Step [64/225], Training Accuracy: 98.5840%, Training Loss: 0.0453%\n",
      "Epoch [139/300], Step [65/225], Training Accuracy: 98.5337%, Training Loss: 0.0458%\n",
      "Epoch [139/300], Step [66/225], Training Accuracy: 98.5322%, Training Loss: 0.0459%\n",
      "Epoch [139/300], Step [67/225], Training Accuracy: 98.4608%, Training Loss: 0.0470%\n",
      "Epoch [139/300], Step [68/225], Training Accuracy: 98.4835%, Training Loss: 0.0466%\n",
      "Epoch [139/300], Step [69/225], Training Accuracy: 98.5054%, Training Loss: 0.0462%\n",
      "Epoch [139/300], Step [70/225], Training Accuracy: 98.4821%, Training Loss: 0.0464%\n",
      "Epoch [139/300], Step [71/225], Training Accuracy: 98.4595%, Training Loss: 0.0468%\n",
      "Epoch [139/300], Step [72/225], Training Accuracy: 98.4809%, Training Loss: 0.0464%\n",
      "Epoch [139/300], Step [73/225], Training Accuracy: 98.4803%, Training Loss: 0.0466%\n",
      "Epoch [139/300], Step [74/225], Training Accuracy: 98.4797%, Training Loss: 0.0467%\n",
      "Epoch [139/300], Step [75/225], Training Accuracy: 98.4583%, Training Loss: 0.0467%\n",
      "Epoch [139/300], Step [76/225], Training Accuracy: 98.4375%, Training Loss: 0.0473%\n",
      "Epoch [139/300], Step [77/225], Training Accuracy: 98.4172%, Training Loss: 0.0479%\n",
      "Epoch [139/300], Step [78/225], Training Accuracy: 98.4175%, Training Loss: 0.0478%\n",
      "Epoch [139/300], Step [79/225], Training Accuracy: 98.4375%, Training Loss: 0.0475%\n",
      "Epoch [139/300], Step [80/225], Training Accuracy: 98.4375%, Training Loss: 0.0474%\n",
      "Epoch [139/300], Step [81/225], Training Accuracy: 98.4568%, Training Loss: 0.0470%\n",
      "Epoch [139/300], Step [82/225], Training Accuracy: 98.4756%, Training Loss: 0.0466%\n",
      "Epoch [139/300], Step [83/225], Training Accuracy: 98.4752%, Training Loss: 0.0465%\n",
      "Epoch [139/300], Step [84/225], Training Accuracy: 98.4933%, Training Loss: 0.0463%\n",
      "Epoch [139/300], Step [85/225], Training Accuracy: 98.5110%, Training Loss: 0.0462%\n",
      "Epoch [139/300], Step [86/225], Training Accuracy: 98.4920%, Training Loss: 0.0471%\n",
      "Epoch [139/300], Step [87/225], Training Accuracy: 98.4555%, Training Loss: 0.0475%\n",
      "Epoch [139/300], Step [88/225], Training Accuracy: 98.4553%, Training Loss: 0.0477%\n",
      "Epoch [139/300], Step [89/225], Training Accuracy: 98.4375%, Training Loss: 0.0483%\n",
      "Epoch [139/300], Step [90/225], Training Accuracy: 98.4375%, Training Loss: 0.0483%\n",
      "Epoch [139/300], Step [91/225], Training Accuracy: 98.4032%, Training Loss: 0.0488%\n",
      "Epoch [139/300], Step [92/225], Training Accuracy: 98.4205%, Training Loss: 0.0486%\n",
      "Epoch [139/300], Step [93/225], Training Accuracy: 98.4375%, Training Loss: 0.0483%\n",
      "Epoch [139/300], Step [94/225], Training Accuracy: 98.4541%, Training Loss: 0.0483%\n",
      "Epoch [139/300], Step [95/225], Training Accuracy: 98.4704%, Training Loss: 0.0480%\n",
      "Epoch [139/300], Step [96/225], Training Accuracy: 98.4863%, Training Loss: 0.0478%\n",
      "Epoch [139/300], Step [97/225], Training Accuracy: 98.4858%, Training Loss: 0.0481%\n",
      "Epoch [139/300], Step [98/225], Training Accuracy: 98.5013%, Training Loss: 0.0480%\n",
      "Epoch [139/300], Step [99/225], Training Accuracy: 98.5164%, Training Loss: 0.0477%\n",
      "Epoch [139/300], Step [100/225], Training Accuracy: 98.5156%, Training Loss: 0.0477%\n",
      "Epoch [139/300], Step [101/225], Training Accuracy: 98.5303%, Training Loss: 0.0476%\n",
      "Epoch [139/300], Step [102/225], Training Accuracy: 98.5294%, Training Loss: 0.0474%\n",
      "Epoch [139/300], Step [103/225], Training Accuracy: 98.4830%, Training Loss: 0.0480%\n",
      "Epoch [139/300], Step [104/225], Training Accuracy: 98.4976%, Training Loss: 0.0479%\n",
      "Epoch [139/300], Step [105/225], Training Accuracy: 98.4821%, Training Loss: 0.0479%\n",
      "Epoch [139/300], Step [106/225], Training Accuracy: 98.4965%, Training Loss: 0.0477%\n",
      "Epoch [139/300], Step [107/225], Training Accuracy: 98.5105%, Training Loss: 0.0476%\n",
      "Epoch [139/300], Step [108/225], Training Accuracy: 98.5098%, Training Loss: 0.0476%\n",
      "Epoch [139/300], Step [109/225], Training Accuracy: 98.5235%, Training Loss: 0.0475%\n",
      "Epoch [139/300], Step [110/225], Training Accuracy: 98.5369%, Training Loss: 0.0472%\n",
      "Epoch [139/300], Step [111/225], Training Accuracy: 98.5501%, Training Loss: 0.0470%\n",
      "Epoch [139/300], Step [112/225], Training Accuracy: 98.5491%, Training Loss: 0.0469%\n",
      "Epoch [139/300], Step [113/225], Training Accuracy: 98.5619%, Training Loss: 0.0467%\n",
      "Epoch [139/300], Step [114/225], Training Accuracy: 98.5197%, Training Loss: 0.0473%\n",
      "Epoch [139/300], Step [115/225], Training Accuracy: 98.5326%, Training Loss: 0.0472%\n",
      "Epoch [139/300], Step [116/225], Training Accuracy: 98.5318%, Training Loss: 0.0471%\n",
      "Epoch [139/300], Step [117/225], Training Accuracy: 98.5310%, Training Loss: 0.0472%\n",
      "Epoch [139/300], Step [118/225], Training Accuracy: 98.5302%, Training Loss: 0.0471%\n",
      "Epoch [139/300], Step [119/225], Training Accuracy: 98.5294%, Training Loss: 0.0470%\n",
      "Epoch [139/300], Step [120/225], Training Accuracy: 98.5286%, Training Loss: 0.0470%\n",
      "Epoch [139/300], Step [121/225], Training Accuracy: 98.5408%, Training Loss: 0.0467%\n",
      "Epoch [139/300], Step [122/225], Training Accuracy: 98.5528%, Training Loss: 0.0465%\n",
      "Epoch [139/300], Step [123/225], Training Accuracy: 98.5518%, Training Loss: 0.0464%\n",
      "Epoch [139/300], Step [124/225], Training Accuracy: 98.5635%, Training Loss: 0.0463%\n",
      "Epoch [139/300], Step [125/225], Training Accuracy: 98.5750%, Training Loss: 0.0462%\n",
      "Epoch [139/300], Step [126/225], Training Accuracy: 98.5739%, Training Loss: 0.0460%\n",
      "Epoch [139/300], Step [127/225], Training Accuracy: 98.5359%, Training Loss: 0.0466%\n",
      "Epoch [139/300], Step [128/225], Training Accuracy: 98.5352%, Training Loss: 0.0467%\n",
      "Epoch [139/300], Step [129/225], Training Accuracy: 98.5344%, Training Loss: 0.0468%\n",
      "Epoch [139/300], Step [130/225], Training Accuracy: 98.5457%, Training Loss: 0.0467%\n",
      "Epoch [139/300], Step [131/225], Training Accuracy: 98.5448%, Training Loss: 0.0465%\n",
      "Epoch [139/300], Step [132/225], Training Accuracy: 98.5559%, Training Loss: 0.0465%\n",
      "Epoch [139/300], Step [133/225], Training Accuracy: 98.5667%, Training Loss: 0.0463%\n",
      "Epoch [139/300], Step [134/225], Training Accuracy: 98.5658%, Training Loss: 0.0461%\n",
      "Epoch [139/300], Step [135/225], Training Accuracy: 98.5648%, Training Loss: 0.0461%\n",
      "Epoch [139/300], Step [136/225], Training Accuracy: 98.5754%, Training Loss: 0.0459%\n",
      "Epoch [139/300], Step [137/225], Training Accuracy: 98.5744%, Training Loss: 0.0460%\n",
      "Epoch [139/300], Step [138/225], Training Accuracy: 98.5847%, Training Loss: 0.0459%\n",
      "Epoch [139/300], Step [139/225], Training Accuracy: 98.5612%, Training Loss: 0.0461%\n",
      "Epoch [139/300], Step [140/225], Training Accuracy: 98.5714%, Training Loss: 0.0459%\n",
      "Epoch [139/300], Step [141/225], Training Accuracy: 98.5705%, Training Loss: 0.0461%\n",
      "Epoch [139/300], Step [142/225], Training Accuracy: 98.5805%, Training Loss: 0.0459%\n",
      "Epoch [139/300], Step [143/225], Training Accuracy: 98.5905%, Training Loss: 0.0458%\n",
      "Epoch [139/300], Step [144/225], Training Accuracy: 98.6003%, Training Loss: 0.0456%\n",
      "Epoch [139/300], Step [145/225], Training Accuracy: 98.6099%, Training Loss: 0.0454%\n",
      "Epoch [139/300], Step [146/225], Training Accuracy: 98.6087%, Training Loss: 0.0454%\n",
      "Epoch [139/300], Step [147/225], Training Accuracy: 98.6076%, Training Loss: 0.0454%\n",
      "Epoch [139/300], Step [148/225], Training Accuracy: 98.6170%, Training Loss: 0.0453%\n",
      "Epoch [139/300], Step [149/225], Training Accuracy: 98.6263%, Training Loss: 0.0451%\n",
      "Epoch [139/300], Step [150/225], Training Accuracy: 98.6354%, Training Loss: 0.0450%\n",
      "Epoch [139/300], Step [151/225], Training Accuracy: 98.6445%, Training Loss: 0.0447%\n",
      "Epoch [139/300], Step [152/225], Training Accuracy: 98.6431%, Training Loss: 0.0446%\n",
      "Epoch [139/300], Step [153/225], Training Accuracy: 98.6417%, Training Loss: 0.0446%\n",
      "Epoch [139/300], Step [154/225], Training Accuracy: 98.6404%, Training Loss: 0.0446%\n",
      "Epoch [139/300], Step [155/225], Training Accuracy: 98.6290%, Training Loss: 0.0449%\n",
      "Epoch [139/300], Step [156/225], Training Accuracy: 98.6278%, Training Loss: 0.0449%\n",
      "Epoch [139/300], Step [157/225], Training Accuracy: 98.6266%, Training Loss: 0.0449%\n",
      "Epoch [139/300], Step [158/225], Training Accuracy: 98.6254%, Training Loss: 0.0448%\n",
      "Epoch [139/300], Step [159/225], Training Accuracy: 98.6340%, Training Loss: 0.0446%\n",
      "Epoch [139/300], Step [160/225], Training Accuracy: 98.6426%, Training Loss: 0.0444%\n",
      "Epoch [139/300], Step [161/225], Training Accuracy: 98.6510%, Training Loss: 0.0442%\n",
      "Epoch [139/300], Step [162/225], Training Accuracy: 98.6593%, Training Loss: 0.0441%\n",
      "Epoch [139/300], Step [163/225], Training Accuracy: 98.6484%, Training Loss: 0.0442%\n",
      "Epoch [139/300], Step [164/225], Training Accuracy: 98.6566%, Training Loss: 0.0440%\n",
      "Epoch [139/300], Step [165/225], Training Accuracy: 98.6648%, Training Loss: 0.0439%\n",
      "Epoch [139/300], Step [166/225], Training Accuracy: 98.6728%, Training Loss: 0.0438%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [139/300], Step [167/225], Training Accuracy: 98.6621%, Training Loss: 0.0441%\n",
      "Epoch [139/300], Step [168/225], Training Accuracy: 98.6700%, Training Loss: 0.0440%\n",
      "Epoch [139/300], Step [169/225], Training Accuracy: 98.6779%, Training Loss: 0.0440%\n",
      "Epoch [139/300], Step [170/225], Training Accuracy: 98.6673%, Training Loss: 0.0442%\n",
      "Epoch [139/300], Step [171/225], Training Accuracy: 98.6751%, Training Loss: 0.0441%\n",
      "Epoch [139/300], Step [172/225], Training Accuracy: 98.6737%, Training Loss: 0.0441%\n",
      "Epoch [139/300], Step [173/225], Training Accuracy: 98.6814%, Training Loss: 0.0440%\n",
      "Epoch [139/300], Step [174/225], Training Accuracy: 98.6889%, Training Loss: 0.0439%\n",
      "Epoch [139/300], Step [175/225], Training Accuracy: 98.6964%, Training Loss: 0.0438%\n",
      "Epoch [139/300], Step [176/225], Training Accuracy: 98.7038%, Training Loss: 0.0436%\n",
      "Epoch [139/300], Step [177/225], Training Accuracy: 98.7112%, Training Loss: 0.0434%\n",
      "Epoch [139/300], Step [178/225], Training Accuracy: 98.7184%, Training Loss: 0.0433%\n",
      "Epoch [139/300], Step [179/225], Training Accuracy: 98.6906%, Training Loss: 0.0436%\n",
      "Epoch [139/300], Step [180/225], Training Accuracy: 98.6806%, Training Loss: 0.0439%\n",
      "Epoch [139/300], Step [181/225], Training Accuracy: 98.6706%, Training Loss: 0.0441%\n",
      "Epoch [139/300], Step [182/225], Training Accuracy: 98.6779%, Training Loss: 0.0440%\n",
      "Epoch [139/300], Step [183/225], Training Accuracy: 98.6766%, Training Loss: 0.0440%\n",
      "Epoch [139/300], Step [184/225], Training Accuracy: 98.6753%, Training Loss: 0.0439%\n",
      "Epoch [139/300], Step [185/225], Training Accuracy: 98.6740%, Training Loss: 0.0440%\n",
      "Epoch [139/300], Step [186/225], Training Accuracy: 98.6811%, Training Loss: 0.0438%\n",
      "Epoch [139/300], Step [187/225], Training Accuracy: 98.6798%, Training Loss: 0.0438%\n",
      "Epoch [139/300], Step [188/225], Training Accuracy: 98.6868%, Training Loss: 0.0436%\n",
      "Epoch [139/300], Step [189/225], Training Accuracy: 98.6938%, Training Loss: 0.0436%\n",
      "Epoch [139/300], Step [190/225], Training Accuracy: 98.7007%, Training Loss: 0.0435%\n",
      "Epoch [139/300], Step [191/225], Training Accuracy: 98.7075%, Training Loss: 0.0433%\n",
      "Epoch [139/300], Step [192/225], Training Accuracy: 98.7142%, Training Loss: 0.0433%\n",
      "Epoch [139/300], Step [193/225], Training Accuracy: 98.6966%, Training Loss: 0.0438%\n",
      "Epoch [139/300], Step [194/225], Training Accuracy: 98.6952%, Training Loss: 0.0438%\n",
      "Epoch [139/300], Step [195/225], Training Accuracy: 98.6859%, Training Loss: 0.0439%\n",
      "Epoch [139/300], Step [196/225], Training Accuracy: 98.6926%, Training Loss: 0.0437%\n",
      "Epoch [139/300], Step [197/225], Training Accuracy: 98.6913%, Training Loss: 0.0437%\n",
      "Epoch [139/300], Step [198/225], Training Accuracy: 98.6821%, Training Loss: 0.0439%\n",
      "Epoch [139/300], Step [199/225], Training Accuracy: 98.6731%, Training Loss: 0.0440%\n",
      "Epoch [139/300], Step [200/225], Training Accuracy: 98.6797%, Training Loss: 0.0439%\n",
      "Epoch [139/300], Step [201/225], Training Accuracy: 98.6863%, Training Loss: 0.0439%\n",
      "Epoch [139/300], Step [202/225], Training Accuracy: 98.6928%, Training Loss: 0.0438%\n",
      "Epoch [139/300], Step [203/225], Training Accuracy: 98.6915%, Training Loss: 0.0437%\n",
      "Epoch [139/300], Step [204/225], Training Accuracy: 98.6903%, Training Loss: 0.0439%\n",
      "Epoch [139/300], Step [205/225], Training Accuracy: 98.6966%, Training Loss: 0.0438%\n",
      "Epoch [139/300], Step [206/225], Training Accuracy: 98.6878%, Training Loss: 0.0439%\n",
      "Epoch [139/300], Step [207/225], Training Accuracy: 98.6866%, Training Loss: 0.0439%\n",
      "Epoch [139/300], Step [208/225], Training Accuracy: 98.6854%, Training Loss: 0.0439%\n",
      "Epoch [139/300], Step [209/225], Training Accuracy: 98.6917%, Training Loss: 0.0438%\n",
      "Epoch [139/300], Step [210/225], Training Accuracy: 98.6979%, Training Loss: 0.0437%\n",
      "Epoch [139/300], Step [211/225], Training Accuracy: 98.7041%, Training Loss: 0.0437%\n",
      "Epoch [139/300], Step [212/225], Training Accuracy: 98.7102%, Training Loss: 0.0436%\n",
      "Epoch [139/300], Step [213/225], Training Accuracy: 98.7089%, Training Loss: 0.0436%\n",
      "Epoch [139/300], Step [214/225], Training Accuracy: 98.7077%, Training Loss: 0.0437%\n",
      "Epoch [139/300], Step [215/225], Training Accuracy: 98.7137%, Training Loss: 0.0436%\n",
      "Epoch [139/300], Step [216/225], Training Accuracy: 98.7196%, Training Loss: 0.0436%\n",
      "Epoch [139/300], Step [217/225], Training Accuracy: 98.7183%, Training Loss: 0.0436%\n",
      "Epoch [139/300], Step [218/225], Training Accuracy: 98.7170%, Training Loss: 0.0435%\n",
      "Epoch [139/300], Step [219/225], Training Accuracy: 98.7158%, Training Loss: 0.0435%\n",
      "Epoch [139/300], Step [220/225], Training Accuracy: 98.7216%, Training Loss: 0.0434%\n",
      "Epoch [139/300], Step [221/225], Training Accuracy: 98.7274%, Training Loss: 0.0434%\n",
      "Epoch [139/300], Step [222/225], Training Accuracy: 98.7190%, Training Loss: 0.0434%\n",
      "Epoch [139/300], Step [223/225], Training Accuracy: 98.7038%, Training Loss: 0.0436%\n",
      "Epoch [139/300], Step [224/225], Training Accuracy: 98.7026%, Training Loss: 0.0438%\n",
      "Epoch [139/300], Step [225/225], Training Accuracy: 98.7076%, Training Loss: 0.0437%\n",
      "Epoch [140/300], Step [1/225], Training Accuracy: 96.8750%, Training Loss: 0.0641%\n",
      "Epoch [140/300], Step [2/225], Training Accuracy: 98.4375%, Training Loss: 0.0459%\n",
      "Epoch [140/300], Step [3/225], Training Accuracy: 97.9167%, Training Loss: 0.0563%\n",
      "Epoch [140/300], Step [4/225], Training Accuracy: 98.4375%, Training Loss: 0.0463%\n",
      "Epoch [140/300], Step [5/225], Training Accuracy: 98.7500%, Training Loss: 0.0414%\n",
      "Epoch [140/300], Step [6/225], Training Accuracy: 98.4375%, Training Loss: 0.0412%\n",
      "Epoch [140/300], Step [7/225], Training Accuracy: 98.6607%, Training Loss: 0.0370%\n",
      "Epoch [140/300], Step [8/225], Training Accuracy: 98.8281%, Training Loss: 0.0345%\n",
      "Epoch [140/300], Step [9/225], Training Accuracy: 98.6111%, Training Loss: 0.0361%\n",
      "Epoch [140/300], Step [10/225], Training Accuracy: 98.5938%, Training Loss: 0.0358%\n",
      "Epoch [140/300], Step [11/225], Training Accuracy: 98.5795%, Training Loss: 0.0372%\n",
      "Epoch [140/300], Step [12/225], Training Accuracy: 98.6979%, Training Loss: 0.0360%\n",
      "Epoch [140/300], Step [13/225], Training Accuracy: 98.6779%, Training Loss: 0.0365%\n",
      "Epoch [140/300], Step [14/225], Training Accuracy: 98.7723%, Training Loss: 0.0364%\n",
      "Epoch [140/300], Step [15/225], Training Accuracy: 98.7500%, Training Loss: 0.0358%\n",
      "Epoch [140/300], Step [16/225], Training Accuracy: 98.8281%, Training Loss: 0.0352%\n",
      "Epoch [140/300], Step [17/225], Training Accuracy: 98.8051%, Training Loss: 0.0367%\n",
      "Epoch [140/300], Step [18/225], Training Accuracy: 98.7847%, Training Loss: 0.0389%\n",
      "Epoch [140/300], Step [19/225], Training Accuracy: 98.8487%, Training Loss: 0.0378%\n",
      "Epoch [140/300], Step [20/225], Training Accuracy: 98.8281%, Training Loss: 0.0374%\n",
      "Epoch [140/300], Step [21/225], Training Accuracy: 98.8839%, Training Loss: 0.0363%\n",
      "Epoch [140/300], Step [22/225], Training Accuracy: 98.9347%, Training Loss: 0.0362%\n",
      "Epoch [140/300], Step [23/225], Training Accuracy: 98.9810%, Training Loss: 0.0357%\n",
      "Epoch [140/300], Step [24/225], Training Accuracy: 99.0234%, Training Loss: 0.0365%\n",
      "Epoch [140/300], Step [25/225], Training Accuracy: 99.0625%, Training Loss: 0.0362%\n",
      "Epoch [140/300], Step [26/225], Training Accuracy: 99.0986%, Training Loss: 0.0358%\n",
      "Epoch [140/300], Step [27/225], Training Accuracy: 99.1319%, Training Loss: 0.0354%\n",
      "Epoch [140/300], Step [28/225], Training Accuracy: 99.1629%, Training Loss: 0.0355%\n",
      "Epoch [140/300], Step [29/225], Training Accuracy: 99.1918%, Training Loss: 0.0349%\n",
      "Epoch [140/300], Step [30/225], Training Accuracy: 99.2188%, Training Loss: 0.0348%\n",
      "Epoch [140/300], Step [31/225], Training Accuracy: 99.1935%, Training Loss: 0.0348%\n",
      "Epoch [140/300], Step [32/225], Training Accuracy: 99.2188%, Training Loss: 0.0345%\n",
      "Epoch [140/300], Step [33/225], Training Accuracy: 99.1951%, Training Loss: 0.0346%\n",
      "Epoch [140/300], Step [34/225], Training Accuracy: 99.1268%, Training Loss: 0.0359%\n",
      "Epoch [140/300], Step [35/225], Training Accuracy: 99.1518%, Training Loss: 0.0355%\n",
      "Epoch [140/300], Step [36/225], Training Accuracy: 99.1753%, Training Loss: 0.0349%\n",
      "Epoch [140/300], Step [37/225], Training Accuracy: 99.1554%, Training Loss: 0.0349%\n",
      "Epoch [140/300], Step [38/225], Training Accuracy: 99.1776%, Training Loss: 0.0345%\n",
      "Epoch [140/300], Step [39/225], Training Accuracy: 99.1987%, Training Loss: 0.0347%\n",
      "Epoch [140/300], Step [40/225], Training Accuracy: 99.1797%, Training Loss: 0.0351%\n",
      "Epoch [140/300], Step [41/225], Training Accuracy: 99.1616%, Training Loss: 0.0358%\n",
      "Epoch [140/300], Step [42/225], Training Accuracy: 99.1815%, Training Loss: 0.0352%\n",
      "Epoch [140/300], Step [43/225], Training Accuracy: 99.1642%, Training Loss: 0.0357%\n",
      "Epoch [140/300], Step [44/225], Training Accuracy: 99.1477%, Training Loss: 0.0358%\n",
      "Epoch [140/300], Step [45/225], Training Accuracy: 99.1319%, Training Loss: 0.0359%\n",
      "Epoch [140/300], Step [46/225], Training Accuracy: 99.1168%, Training Loss: 0.0359%\n",
      "Epoch [140/300], Step [47/225], Training Accuracy: 99.1024%, Training Loss: 0.0364%\n",
      "Epoch [140/300], Step [48/225], Training Accuracy: 99.1211%, Training Loss: 0.0360%\n",
      "Epoch [140/300], Step [49/225], Training Accuracy: 99.0753%, Training Loss: 0.0367%\n",
      "Epoch [140/300], Step [50/225], Training Accuracy: 99.0625%, Training Loss: 0.0370%\n",
      "Epoch [140/300], Step [51/225], Training Accuracy: 99.0809%, Training Loss: 0.0368%\n",
      "Epoch [140/300], Step [52/225], Training Accuracy: 99.0685%, Training Loss: 0.0367%\n",
      "Epoch [140/300], Step [53/225], Training Accuracy: 99.0861%, Training Loss: 0.0365%\n",
      "Epoch [140/300], Step [54/225], Training Accuracy: 99.0741%, Training Loss: 0.0368%\n",
      "Epoch [140/300], Step [55/225], Training Accuracy: 99.0341%, Training Loss: 0.0414%\n",
      "Epoch [140/300], Step [56/225], Training Accuracy: 99.0234%, Training Loss: 0.0414%\n",
      "Epoch [140/300], Step [57/225], Training Accuracy: 98.9857%, Training Loss: 0.0420%\n",
      "Epoch [140/300], Step [58/225], Training Accuracy: 99.0032%, Training Loss: 0.0415%\n",
      "Epoch [140/300], Step [59/225], Training Accuracy: 99.0201%, Training Loss: 0.0417%\n",
      "Epoch [140/300], Step [60/225], Training Accuracy: 98.9583%, Training Loss: 0.0421%\n",
      "Epoch [140/300], Step [61/225], Training Accuracy: 98.9754%, Training Loss: 0.0419%\n",
      "Epoch [140/300], Step [62/225], Training Accuracy: 98.9415%, Training Loss: 0.0422%\n",
      "Epoch [140/300], Step [63/225], Training Accuracy: 98.9087%, Training Loss: 0.0424%\n",
      "Epoch [140/300], Step [64/225], Training Accuracy: 98.9014%, Training Loss: 0.0422%\n",
      "Epoch [140/300], Step [65/225], Training Accuracy: 98.8942%, Training Loss: 0.0424%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [140/300], Step [66/225], Training Accuracy: 98.8873%, Training Loss: 0.0424%\n",
      "Epoch [140/300], Step [67/225], Training Accuracy: 98.8806%, Training Loss: 0.0425%\n",
      "Epoch [140/300], Step [68/225], Training Accuracy: 98.8971%, Training Loss: 0.0420%\n",
      "Epoch [140/300], Step [69/225], Training Accuracy: 98.9130%, Training Loss: 0.0416%\n",
      "Epoch [140/300], Step [70/225], Training Accuracy: 98.9062%, Training Loss: 0.0418%\n",
      "Epoch [140/300], Step [71/225], Training Accuracy: 98.9217%, Training Loss: 0.0415%\n",
      "Epoch [140/300], Step [72/225], Training Accuracy: 98.9149%, Training Loss: 0.0418%\n",
      "Epoch [140/300], Step [73/225], Training Accuracy: 98.9084%, Training Loss: 0.0422%\n",
      "Epoch [140/300], Step [74/225], Training Accuracy: 98.9020%, Training Loss: 0.0424%\n",
      "Epoch [140/300], Step [75/225], Training Accuracy: 98.8958%, Training Loss: 0.0422%\n",
      "Epoch [140/300], Step [76/225], Training Accuracy: 98.8692%, Training Loss: 0.0430%\n",
      "Epoch [140/300], Step [77/225], Training Accuracy: 98.8433%, Training Loss: 0.0431%\n",
      "Epoch [140/300], Step [78/225], Training Accuracy: 98.8582%, Training Loss: 0.0427%\n",
      "Epoch [140/300], Step [79/225], Training Accuracy: 98.8331%, Training Loss: 0.0429%\n",
      "Epoch [140/300], Step [80/225], Training Accuracy: 98.7891%, Training Loss: 0.0446%\n",
      "Epoch [140/300], Step [81/225], Training Accuracy: 98.7847%, Training Loss: 0.0445%\n",
      "Epoch [140/300], Step [82/225], Training Accuracy: 98.7995%, Training Loss: 0.0442%\n",
      "Epoch [140/300], Step [83/225], Training Accuracy: 98.7952%, Training Loss: 0.0443%\n",
      "Epoch [140/300], Step [84/225], Training Accuracy: 98.8095%, Training Loss: 0.0439%\n",
      "Epoch [140/300], Step [85/225], Training Accuracy: 98.7868%, Training Loss: 0.0447%\n",
      "Epoch [140/300], Step [86/225], Training Accuracy: 98.8009%, Training Loss: 0.0447%\n",
      "Epoch [140/300], Step [87/225], Training Accuracy: 98.7787%, Training Loss: 0.0449%\n",
      "Epoch [140/300], Step [88/225], Training Accuracy: 98.7749%, Training Loss: 0.0447%\n",
      "Epoch [140/300], Step [89/225], Training Accuracy: 98.7535%, Training Loss: 0.0448%\n",
      "Epoch [140/300], Step [90/225], Training Accuracy: 98.7674%, Training Loss: 0.0448%\n",
      "Epoch [140/300], Step [91/225], Training Accuracy: 98.7809%, Training Loss: 0.0447%\n",
      "Epoch [140/300], Step [92/225], Training Accuracy: 98.7772%, Training Loss: 0.0446%\n",
      "Epoch [140/300], Step [93/225], Training Accuracy: 98.7903%, Training Loss: 0.0443%\n",
      "Epoch [140/300], Step [94/225], Training Accuracy: 98.8032%, Training Loss: 0.0442%\n",
      "Epoch [140/300], Step [95/225], Training Accuracy: 98.7993%, Training Loss: 0.0441%\n",
      "Epoch [140/300], Step [96/225], Training Accuracy: 98.7956%, Training Loss: 0.0441%\n",
      "Epoch [140/300], Step [97/225], Training Accuracy: 98.7758%, Training Loss: 0.0443%\n",
      "Epoch [140/300], Step [98/225], Training Accuracy: 98.7564%, Training Loss: 0.0450%\n",
      "Epoch [140/300], Step [99/225], Training Accuracy: 98.7532%, Training Loss: 0.0453%\n",
      "Epoch [140/300], Step [100/225], Training Accuracy: 98.7500%, Training Loss: 0.0451%\n",
      "Epoch [140/300], Step [101/225], Training Accuracy: 98.7624%, Training Loss: 0.0449%\n",
      "Epoch [140/300], Step [102/225], Training Accuracy: 98.7592%, Training Loss: 0.0449%\n",
      "Epoch [140/300], Step [103/225], Training Accuracy: 98.7561%, Training Loss: 0.0451%\n",
      "Epoch [140/300], Step [104/225], Training Accuracy: 98.7530%, Training Loss: 0.0450%\n",
      "Epoch [140/300], Step [105/225], Training Accuracy: 98.7500%, Training Loss: 0.0449%\n",
      "Epoch [140/300], Step [106/225], Training Accuracy: 98.7618%, Training Loss: 0.0447%\n",
      "Epoch [140/300], Step [107/225], Training Accuracy: 98.7734%, Training Loss: 0.0445%\n",
      "Epoch [140/300], Step [108/225], Training Accuracy: 98.7847%, Training Loss: 0.0442%\n",
      "Epoch [140/300], Step [109/225], Training Accuracy: 98.7242%, Training Loss: 0.0451%\n",
      "Epoch [140/300], Step [110/225], Training Accuracy: 98.7216%, Training Loss: 0.0449%\n",
      "Epoch [140/300], Step [111/225], Training Accuracy: 98.6909%, Training Loss: 0.0453%\n",
      "Epoch [140/300], Step [112/225], Training Accuracy: 98.6886%, Training Loss: 0.0453%\n",
      "Epoch [140/300], Step [113/225], Training Accuracy: 98.7002%, Training Loss: 0.0451%\n",
      "Epoch [140/300], Step [114/225], Training Accuracy: 98.6979%, Training Loss: 0.0453%\n",
      "Epoch [140/300], Step [115/225], Training Accuracy: 98.7092%, Training Loss: 0.0452%\n",
      "Epoch [140/300], Step [116/225], Training Accuracy: 98.7069%, Training Loss: 0.0452%\n",
      "Epoch [140/300], Step [117/225], Training Accuracy: 98.7046%, Training Loss: 0.0452%\n",
      "Epoch [140/300], Step [118/225], Training Accuracy: 98.6891%, Training Loss: 0.0454%\n",
      "Epoch [140/300], Step [119/225], Training Accuracy: 98.6738%, Training Loss: 0.0454%\n",
      "Epoch [140/300], Step [120/225], Training Accuracy: 98.6849%, Training Loss: 0.0452%\n",
      "Epoch [140/300], Step [121/225], Training Accuracy: 98.6958%, Training Loss: 0.0449%\n",
      "Epoch [140/300], Step [122/225], Training Accuracy: 98.6936%, Training Loss: 0.0448%\n",
      "Epoch [140/300], Step [123/225], Training Accuracy: 98.6916%, Training Loss: 0.0447%\n",
      "Epoch [140/300], Step [124/225], Training Accuracy: 98.7021%, Training Loss: 0.0447%\n",
      "Epoch [140/300], Step [125/225], Training Accuracy: 98.6750%, Training Loss: 0.0453%\n",
      "Epoch [140/300], Step [126/225], Training Accuracy: 98.6731%, Training Loss: 0.0455%\n",
      "Epoch [140/300], Step [127/225], Training Accuracy: 98.6713%, Training Loss: 0.0453%\n",
      "Epoch [140/300], Step [128/225], Training Accuracy: 98.6816%, Training Loss: 0.0452%\n",
      "Epoch [140/300], Step [129/225], Training Accuracy: 98.6919%, Training Loss: 0.0452%\n",
      "Epoch [140/300], Step [130/225], Training Accuracy: 98.7019%, Training Loss: 0.0451%\n",
      "Epoch [140/300], Step [131/225], Training Accuracy: 98.7118%, Training Loss: 0.0450%\n",
      "Epoch [140/300], Step [132/225], Training Accuracy: 98.7098%, Training Loss: 0.0449%\n",
      "Epoch [140/300], Step [133/225], Training Accuracy: 98.7077%, Training Loss: 0.0450%\n",
      "Epoch [140/300], Step [134/225], Training Accuracy: 98.7057%, Training Loss: 0.0449%\n",
      "Epoch [140/300], Step [135/225], Training Accuracy: 98.7153%, Training Loss: 0.0447%\n",
      "Epoch [140/300], Step [136/225], Training Accuracy: 98.7132%, Training Loss: 0.0449%\n",
      "Epoch [140/300], Step [137/225], Training Accuracy: 98.7112%, Training Loss: 0.0449%\n",
      "Epoch [140/300], Step [138/225], Training Accuracy: 98.7206%, Training Loss: 0.0448%\n",
      "Epoch [140/300], Step [139/225], Training Accuracy: 98.7298%, Training Loss: 0.0446%\n",
      "Epoch [140/300], Step [140/225], Training Accuracy: 98.7388%, Training Loss: 0.0445%\n",
      "Epoch [140/300], Step [141/225], Training Accuracy: 98.6924%, Training Loss: 0.0449%\n",
      "Epoch [140/300], Step [142/225], Training Accuracy: 98.6906%, Training Loss: 0.0451%\n",
      "Epoch [140/300], Step [143/225], Training Accuracy: 98.6997%, Training Loss: 0.0450%\n",
      "Epoch [140/300], Step [144/225], Training Accuracy: 98.6762%, Training Loss: 0.0454%\n",
      "Epoch [140/300], Step [145/225], Training Accuracy: 98.6853%, Training Loss: 0.0452%\n",
      "Epoch [140/300], Step [146/225], Training Accuracy: 98.6622%, Training Loss: 0.0453%\n",
      "Epoch [140/300], Step [147/225], Training Accuracy: 98.6713%, Training Loss: 0.0452%\n",
      "Epoch [140/300], Step [148/225], Training Accuracy: 98.6592%, Training Loss: 0.0453%\n",
      "Epoch [140/300], Step [149/225], Training Accuracy: 98.6682%, Training Loss: 0.0452%\n",
      "Epoch [140/300], Step [150/225], Training Accuracy: 98.6771%, Training Loss: 0.0451%\n",
      "Epoch [140/300], Step [151/225], Training Accuracy: 98.6755%, Training Loss: 0.0450%\n",
      "Epoch [140/300], Step [152/225], Training Accuracy: 98.6637%, Training Loss: 0.0450%\n",
      "Epoch [140/300], Step [153/225], Training Accuracy: 98.6724%, Training Loss: 0.0448%\n",
      "Epoch [140/300], Step [154/225], Training Accuracy: 98.6810%, Training Loss: 0.0447%\n",
      "Epoch [140/300], Step [155/225], Training Accuracy: 98.6694%, Training Loss: 0.0448%\n",
      "Epoch [140/300], Step [156/225], Training Accuracy: 98.6679%, Training Loss: 0.0447%\n",
      "Epoch [140/300], Step [157/225], Training Accuracy: 98.6664%, Training Loss: 0.0448%\n",
      "Epoch [140/300], Step [158/225], Training Accuracy: 98.6551%, Training Loss: 0.0449%\n",
      "Epoch [140/300], Step [159/225], Training Accuracy: 98.6242%, Training Loss: 0.0454%\n",
      "Epoch [140/300], Step [160/225], Training Accuracy: 98.6328%, Training Loss: 0.0453%\n",
      "Epoch [140/300], Step [161/225], Training Accuracy: 98.6413%, Training Loss: 0.0451%\n",
      "Epoch [140/300], Step [162/225], Training Accuracy: 98.6400%, Training Loss: 0.0452%\n",
      "Epoch [140/300], Step [163/225], Training Accuracy: 98.6292%, Training Loss: 0.0452%\n",
      "Epoch [140/300], Step [164/225], Training Accuracy: 98.6280%, Training Loss: 0.0452%\n",
      "Epoch [140/300], Step [165/225], Training Accuracy: 98.6364%, Training Loss: 0.0452%\n",
      "Epoch [140/300], Step [166/225], Training Accuracy: 98.6446%, Training Loss: 0.0451%\n",
      "Epoch [140/300], Step [167/225], Training Accuracy: 98.6527%, Training Loss: 0.0449%\n",
      "Epoch [140/300], Step [168/225], Training Accuracy: 98.6514%, Training Loss: 0.0448%\n",
      "Epoch [140/300], Step [169/225], Training Accuracy: 98.6594%, Training Loss: 0.0447%\n",
      "Epoch [140/300], Step [170/225], Training Accuracy: 98.6581%, Training Loss: 0.0447%\n",
      "Epoch [140/300], Step [171/225], Training Accuracy: 98.6568%, Training Loss: 0.0448%\n",
      "Epoch [140/300], Step [172/225], Training Accuracy: 98.6646%, Training Loss: 0.0447%\n",
      "Epoch [140/300], Step [173/225], Training Accuracy: 98.6723%, Training Loss: 0.0445%\n",
      "Epoch [140/300], Step [174/225], Training Accuracy: 98.6710%, Training Loss: 0.0444%\n",
      "Epoch [140/300], Step [175/225], Training Accuracy: 98.6786%, Training Loss: 0.0443%\n",
      "Epoch [140/300], Step [176/225], Training Accuracy: 98.6861%, Training Loss: 0.0442%\n",
      "Epoch [140/300], Step [177/225], Training Accuracy: 98.6935%, Training Loss: 0.0441%\n",
      "Epoch [140/300], Step [178/225], Training Accuracy: 98.6921%, Training Loss: 0.0441%\n",
      "Epoch [140/300], Step [179/225], Training Accuracy: 98.6906%, Training Loss: 0.0441%\n",
      "Epoch [140/300], Step [180/225], Training Accuracy: 98.6979%, Training Loss: 0.0440%\n",
      "Epoch [140/300], Step [181/225], Training Accuracy: 98.7051%, Training Loss: 0.0439%\n",
      "Epoch [140/300], Step [182/225], Training Accuracy: 98.7036%, Training Loss: 0.0440%\n",
      "Epoch [140/300], Step [183/225], Training Accuracy: 98.7107%, Training Loss: 0.0438%\n",
      "Epoch [140/300], Step [184/225], Training Accuracy: 98.7092%, Training Loss: 0.0438%\n",
      "Epoch [140/300], Step [185/225], Training Accuracy: 98.7162%, Training Loss: 0.0436%\n",
      "Epoch [140/300], Step [186/225], Training Accuracy: 98.7231%, Training Loss: 0.0434%\n",
      "Epoch [140/300], Step [187/225], Training Accuracy: 98.7216%, Training Loss: 0.0435%\n",
      "Epoch [140/300], Step [188/225], Training Accuracy: 98.7284%, Training Loss: 0.0434%\n",
      "Epoch [140/300], Step [189/225], Training Accuracy: 98.7351%, Training Loss: 0.0434%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [140/300], Step [190/225], Training Accuracy: 98.7418%, Training Loss: 0.0433%\n",
      "Epoch [140/300], Step [191/225], Training Accuracy: 98.7484%, Training Loss: 0.0433%\n",
      "Epoch [140/300], Step [192/225], Training Accuracy: 98.7386%, Training Loss: 0.0432%\n",
      "Epoch [140/300], Step [193/225], Training Accuracy: 98.7370%, Training Loss: 0.0433%\n",
      "Epoch [140/300], Step [194/225], Training Accuracy: 98.7355%, Training Loss: 0.0432%\n",
      "Epoch [140/300], Step [195/225], Training Accuracy: 98.7420%, Training Loss: 0.0431%\n",
      "Epoch [140/300], Step [196/225], Training Accuracy: 98.7484%, Training Loss: 0.0430%\n",
      "Epoch [140/300], Step [197/225], Training Accuracy: 98.7548%, Training Loss: 0.0429%\n",
      "Epoch [140/300], Step [198/225], Training Accuracy: 98.7610%, Training Loss: 0.0430%\n",
      "Epoch [140/300], Step [199/225], Training Accuracy: 98.7594%, Training Loss: 0.0430%\n",
      "Epoch [140/300], Step [200/225], Training Accuracy: 98.7500%, Training Loss: 0.0431%\n",
      "Epoch [140/300], Step [201/225], Training Accuracy: 98.7407%, Training Loss: 0.0431%\n",
      "Epoch [140/300], Step [202/225], Training Accuracy: 98.7469%, Training Loss: 0.0430%\n",
      "Epoch [140/300], Step [203/225], Training Accuracy: 98.7377%, Training Loss: 0.0433%\n",
      "Epoch [140/300], Step [204/225], Training Accuracy: 98.7362%, Training Loss: 0.0434%\n",
      "Epoch [140/300], Step [205/225], Training Accuracy: 98.7424%, Training Loss: 0.0433%\n",
      "Epoch [140/300], Step [206/225], Training Accuracy: 98.7485%, Training Loss: 0.0432%\n",
      "Epoch [140/300], Step [207/225], Training Accuracy: 98.7545%, Training Loss: 0.0432%\n",
      "Epoch [140/300], Step [208/225], Training Accuracy: 98.7530%, Training Loss: 0.0432%\n",
      "Epoch [140/300], Step [209/225], Training Accuracy: 98.7590%, Training Loss: 0.0431%\n",
      "Epoch [140/300], Step [210/225], Training Accuracy: 98.7649%, Training Loss: 0.0430%\n",
      "Epoch [140/300], Step [211/225], Training Accuracy: 98.7633%, Training Loss: 0.0430%\n",
      "Epoch [140/300], Step [212/225], Training Accuracy: 98.7544%, Training Loss: 0.0432%\n",
      "Epoch [140/300], Step [213/225], Training Accuracy: 98.7603%, Training Loss: 0.0430%\n",
      "Epoch [140/300], Step [214/225], Training Accuracy: 98.7588%, Training Loss: 0.0430%\n",
      "Epoch [140/300], Step [215/225], Training Accuracy: 98.7645%, Training Loss: 0.0428%\n",
      "Epoch [140/300], Step [216/225], Training Accuracy: 98.7703%, Training Loss: 0.0428%\n",
      "Epoch [140/300], Step [217/225], Training Accuracy: 98.7759%, Training Loss: 0.0427%\n",
      "Epoch [140/300], Step [218/225], Training Accuracy: 98.7815%, Training Loss: 0.0426%\n",
      "Epoch [140/300], Step [219/225], Training Accuracy: 98.7871%, Training Loss: 0.0424%\n",
      "Epoch [140/300], Step [220/225], Training Accuracy: 98.7784%, Training Loss: 0.0426%\n",
      "Epoch [140/300], Step [221/225], Training Accuracy: 98.7839%, Training Loss: 0.0424%\n",
      "Epoch [140/300], Step [222/225], Training Accuracy: 98.7753%, Training Loss: 0.0425%\n",
      "Epoch [140/300], Step [223/225], Training Accuracy: 98.7738%, Training Loss: 0.0426%\n",
      "Epoch [140/300], Step [224/225], Training Accuracy: 98.7653%, Training Loss: 0.0428%\n",
      "Epoch [140/300], Step [225/225], Training Accuracy: 98.7563%, Training Loss: 0.0429%\n",
      "Epoch [141/300], Step [1/225], Training Accuracy: 98.4375%, Training Loss: 0.0447%\n",
      "Epoch [141/300], Step [2/225], Training Accuracy: 96.8750%, Training Loss: 0.0544%\n",
      "Epoch [141/300], Step [3/225], Training Accuracy: 97.3958%, Training Loss: 0.0462%\n",
      "Epoch [141/300], Step [4/225], Training Accuracy: 97.2656%, Training Loss: 0.0630%\n",
      "Epoch [141/300], Step [5/225], Training Accuracy: 97.5000%, Training Loss: 0.0580%\n",
      "Epoch [141/300], Step [6/225], Training Accuracy: 97.6562%, Training Loss: 0.0553%\n",
      "Epoch [141/300], Step [7/225], Training Accuracy: 97.9911%, Training Loss: 0.0541%\n",
      "Epoch [141/300], Step [8/225], Training Accuracy: 97.6562%, Training Loss: 0.0566%\n",
      "Epoch [141/300], Step [9/225], Training Accuracy: 97.7431%, Training Loss: 0.0550%\n",
      "Epoch [141/300], Step [10/225], Training Accuracy: 97.6562%, Training Loss: 0.0556%\n",
      "Epoch [141/300], Step [11/225], Training Accuracy: 97.7273%, Training Loss: 0.0564%\n",
      "Epoch [141/300], Step [12/225], Training Accuracy: 97.6562%, Training Loss: 0.0637%\n",
      "Epoch [141/300], Step [13/225], Training Accuracy: 97.5962%, Training Loss: 0.0656%\n",
      "Epoch [141/300], Step [14/225], Training Accuracy: 97.5446%, Training Loss: 0.0656%\n",
      "Epoch [141/300], Step [15/225], Training Accuracy: 97.5000%, Training Loss: 0.0651%\n",
      "Epoch [141/300], Step [16/225], Training Accuracy: 97.6562%, Training Loss: 0.0618%\n",
      "Epoch [141/300], Step [17/225], Training Accuracy: 97.6103%, Training Loss: 0.0643%\n",
      "Epoch [141/300], Step [18/225], Training Accuracy: 97.4826%, Training Loss: 0.0707%\n",
      "Epoch [141/300], Step [19/225], Training Accuracy: 97.5329%, Training Loss: 0.0688%\n",
      "Epoch [141/300], Step [20/225], Training Accuracy: 97.5000%, Training Loss: 0.0679%\n",
      "Epoch [141/300], Step [21/225], Training Accuracy: 97.6190%, Training Loss: 0.0652%\n",
      "Epoch [141/300], Step [22/225], Training Accuracy: 97.5852%, Training Loss: 0.0654%\n",
      "Epoch [141/300], Step [23/225], Training Accuracy: 97.6223%, Training Loss: 0.0651%\n",
      "Epoch [141/300], Step [24/225], Training Accuracy: 97.5911%, Training Loss: 0.0654%\n",
      "Epoch [141/300], Step [25/225], Training Accuracy: 97.6875%, Training Loss: 0.0636%\n",
      "Epoch [141/300], Step [26/225], Training Accuracy: 97.7163%, Training Loss: 0.0634%\n",
      "Epoch [141/300], Step [27/225], Training Accuracy: 97.7431%, Training Loss: 0.0628%\n",
      "Epoch [141/300], Step [28/225], Training Accuracy: 97.7121%, Training Loss: 0.0629%\n",
      "Epoch [141/300], Step [29/225], Training Accuracy: 97.7371%, Training Loss: 0.0620%\n",
      "Epoch [141/300], Step [30/225], Training Accuracy: 97.8125%, Training Loss: 0.0611%\n",
      "Epoch [141/300], Step [31/225], Training Accuracy: 97.8831%, Training Loss: 0.0599%\n",
      "Epoch [141/300], Step [32/225], Training Accuracy: 97.9492%, Training Loss: 0.0586%\n",
      "Epoch [141/300], Step [33/225], Training Accuracy: 97.9640%, Training Loss: 0.0587%\n",
      "Epoch [141/300], Step [34/225], Training Accuracy: 97.9779%, Training Loss: 0.0586%\n",
      "Epoch [141/300], Step [35/225], Training Accuracy: 98.0357%, Training Loss: 0.0577%\n",
      "Epoch [141/300], Step [36/225], Training Accuracy: 98.0903%, Training Loss: 0.0568%\n",
      "Epoch [141/300], Step [37/225], Training Accuracy: 98.0997%, Training Loss: 0.0571%\n",
      "Epoch [141/300], Step [38/225], Training Accuracy: 97.9030%, Training Loss: 0.0600%\n",
      "Epoch [141/300], Step [39/225], Training Accuracy: 97.8365%, Training Loss: 0.0603%\n",
      "Epoch [141/300], Step [40/225], Training Accuracy: 97.8906%, Training Loss: 0.0597%\n",
      "Epoch [141/300], Step [41/225], Training Accuracy: 97.8659%, Training Loss: 0.0606%\n",
      "Epoch [141/300], Step [42/225], Training Accuracy: 97.9167%, Training Loss: 0.0597%\n",
      "Epoch [141/300], Step [43/225], Training Accuracy: 97.9651%, Training Loss: 0.0590%\n",
      "Epoch [141/300], Step [44/225], Training Accuracy: 98.0114%, Training Loss: 0.0586%\n",
      "Epoch [141/300], Step [45/225], Training Accuracy: 98.0556%, Training Loss: 0.0576%\n",
      "Epoch [141/300], Step [46/225], Training Accuracy: 98.0639%, Training Loss: 0.0571%\n",
      "Epoch [141/300], Step [47/225], Training Accuracy: 98.0718%, Training Loss: 0.0568%\n",
      "Epoch [141/300], Step [48/225], Training Accuracy: 98.0794%, Training Loss: 0.0569%\n",
      "Epoch [141/300], Step [49/225], Training Accuracy: 98.0867%, Training Loss: 0.0571%\n",
      "Epoch [141/300], Step [50/225], Training Accuracy: 98.0312%, Training Loss: 0.0582%\n",
      "Epoch [141/300], Step [51/225], Training Accuracy: 98.0392%, Training Loss: 0.0580%\n",
      "Epoch [141/300], Step [52/225], Training Accuracy: 98.0769%, Training Loss: 0.0571%\n",
      "Epoch [141/300], Step [53/225], Training Accuracy: 98.0542%, Training Loss: 0.0587%\n",
      "Epoch [141/300], Step [54/225], Training Accuracy: 98.0324%, Training Loss: 0.0597%\n",
      "Epoch [141/300], Step [55/225], Training Accuracy: 98.0398%, Training Loss: 0.0594%\n",
      "Epoch [141/300], Step [56/225], Training Accuracy: 98.0469%, Training Loss: 0.0594%\n",
      "Epoch [141/300], Step [57/225], Training Accuracy: 98.0537%, Training Loss: 0.0589%\n",
      "Epoch [141/300], Step [58/225], Training Accuracy: 98.0603%, Training Loss: 0.0585%\n",
      "Epoch [141/300], Step [59/225], Training Accuracy: 98.0138%, Training Loss: 0.0599%\n",
      "Epoch [141/300], Step [60/225], Training Accuracy: 98.0208%, Training Loss: 0.0596%\n",
      "Epoch [141/300], Step [61/225], Training Accuracy: 97.9764%, Training Loss: 0.0601%\n",
      "Epoch [141/300], Step [62/225], Training Accuracy: 97.9587%, Training Loss: 0.0609%\n",
      "Epoch [141/300], Step [63/225], Training Accuracy: 97.8919%, Training Loss: 0.0618%\n",
      "Epoch [141/300], Step [64/225], Training Accuracy: 97.9004%, Training Loss: 0.0615%\n",
      "Epoch [141/300], Step [65/225], Training Accuracy: 97.9327%, Training Loss: 0.0612%\n",
      "Epoch [141/300], Step [66/225], Training Accuracy: 97.9640%, Training Loss: 0.0608%\n",
      "Epoch [141/300], Step [67/225], Training Accuracy: 97.9711%, Training Loss: 0.0615%\n",
      "Epoch [141/300], Step [68/225], Training Accuracy: 97.9779%, Training Loss: 0.0610%\n",
      "Epoch [141/300], Step [69/225], Training Accuracy: 97.9846%, Training Loss: 0.0609%\n",
      "Epoch [141/300], Step [70/225], Training Accuracy: 97.9464%, Training Loss: 0.0609%\n",
      "Epoch [141/300], Step [71/225], Training Accuracy: 97.9533%, Training Loss: 0.0606%\n",
      "Epoch [141/300], Step [72/225], Training Accuracy: 97.9384%, Training Loss: 0.0609%\n",
      "Epoch [141/300], Step [73/225], Training Accuracy: 97.8810%, Training Loss: 0.0617%\n",
      "Epoch [141/300], Step [74/225], Training Accuracy: 97.9096%, Training Loss: 0.0610%\n",
      "Epoch [141/300], Step [75/225], Training Accuracy: 97.9167%, Training Loss: 0.0607%\n",
      "Epoch [141/300], Step [76/225], Training Accuracy: 97.9441%, Training Loss: 0.0603%\n",
      "Epoch [141/300], Step [77/225], Training Accuracy: 97.9302%, Training Loss: 0.0603%\n",
      "Epoch [141/300], Step [78/225], Training Accuracy: 97.9567%, Training Loss: 0.0597%\n",
      "Epoch [141/300], Step [79/225], Training Accuracy: 97.9628%, Training Loss: 0.0595%\n",
      "Epoch [141/300], Step [80/225], Training Accuracy: 97.9102%, Training Loss: 0.0613%\n",
      "Epoch [141/300], Step [81/225], Training Accuracy: 97.9167%, Training Loss: 0.0610%\n",
      "Epoch [141/300], Step [82/225], Training Accuracy: 97.9230%, Training Loss: 0.0609%\n",
      "Epoch [141/300], Step [83/225], Training Accuracy: 97.8916%, Training Loss: 0.0616%\n",
      "Epoch [141/300], Step [84/225], Training Accuracy: 97.8795%, Training Loss: 0.0616%\n",
      "Epoch [141/300], Step [85/225], Training Accuracy: 97.9044%, Training Loss: 0.0610%\n",
      "Epoch [141/300], Step [86/225], Training Accuracy: 97.9288%, Training Loss: 0.0609%\n",
      "Epoch [141/300], Step [87/225], Training Accuracy: 97.9526%, Training Loss: 0.0604%\n",
      "Epoch [141/300], Step [88/225], Training Accuracy: 97.9403%, Training Loss: 0.0602%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [141/300], Step [89/225], Training Accuracy: 97.9459%, Training Loss: 0.0601%\n",
      "Epoch [141/300], Step [90/225], Training Accuracy: 97.9688%, Training Loss: 0.0599%\n",
      "Epoch [141/300], Step [91/225], Training Accuracy: 97.9739%, Training Loss: 0.0596%\n",
      "Epoch [141/300], Step [92/225], Training Accuracy: 97.9959%, Training Loss: 0.0594%\n",
      "Epoch [141/300], Step [93/225], Training Accuracy: 98.0007%, Training Loss: 0.0592%\n",
      "Epoch [141/300], Step [94/225], Training Accuracy: 98.0219%, Training Loss: 0.0588%\n",
      "Epoch [141/300], Step [95/225], Training Accuracy: 98.0099%, Training Loss: 0.0589%\n",
      "Epoch [141/300], Step [96/225], Training Accuracy: 97.9818%, Training Loss: 0.0591%\n",
      "Epoch [141/300], Step [97/225], Training Accuracy: 97.9865%, Training Loss: 0.0588%\n",
      "Epoch [141/300], Step [98/225], Training Accuracy: 97.9114%, Training Loss: 0.0603%\n",
      "Epoch [141/300], Step [99/225], Training Accuracy: 97.9009%, Training Loss: 0.0606%\n",
      "Epoch [141/300], Step [100/225], Training Accuracy: 97.9219%, Training Loss: 0.0602%\n",
      "Epoch [141/300], Step [101/225], Training Accuracy: 97.9115%, Training Loss: 0.0607%\n",
      "Epoch [141/300], Step [102/225], Training Accuracy: 97.9013%, Training Loss: 0.0615%\n",
      "Epoch [141/300], Step [103/225], Training Accuracy: 97.9217%, Training Loss: 0.0611%\n",
      "Epoch [141/300], Step [104/225], Training Accuracy: 97.9417%, Training Loss: 0.0606%\n",
      "Epoch [141/300], Step [105/225], Training Accuracy: 97.9613%, Training Loss: 0.0604%\n",
      "Epoch [141/300], Step [106/225], Training Accuracy: 97.9511%, Training Loss: 0.0603%\n",
      "Epoch [141/300], Step [107/225], Training Accuracy: 97.9556%, Training Loss: 0.0601%\n",
      "Epoch [141/300], Step [108/225], Training Accuracy: 97.9456%, Training Loss: 0.0604%\n",
      "Epoch [141/300], Step [109/225], Training Accuracy: 97.9501%, Training Loss: 0.0602%\n",
      "Epoch [141/300], Step [110/225], Training Accuracy: 97.9688%, Training Loss: 0.0598%\n",
      "Epoch [141/300], Step [111/225], Training Accuracy: 97.9448%, Training Loss: 0.0600%\n",
      "Epoch [141/300], Step [112/225], Training Accuracy: 97.9632%, Training Loss: 0.0598%\n",
      "Epoch [141/300], Step [113/225], Training Accuracy: 97.9674%, Training Loss: 0.0596%\n",
      "Epoch [141/300], Step [114/225], Training Accuracy: 97.9715%, Training Loss: 0.0594%\n",
      "Epoch [141/300], Step [115/225], Training Accuracy: 97.9755%, Training Loss: 0.0593%\n",
      "Epoch [141/300], Step [116/225], Training Accuracy: 97.9930%, Training Loss: 0.0592%\n",
      "Epoch [141/300], Step [117/225], Training Accuracy: 97.9968%, Training Loss: 0.0590%\n",
      "Epoch [141/300], Step [118/225], Training Accuracy: 97.9873%, Training Loss: 0.0590%\n",
      "Epoch [141/300], Step [119/225], Training Accuracy: 98.0042%, Training Loss: 0.0587%\n",
      "Epoch [141/300], Step [120/225], Training Accuracy: 98.0208%, Training Loss: 0.0583%\n",
      "Epoch [141/300], Step [121/225], Training Accuracy: 98.0243%, Training Loss: 0.0583%\n",
      "Epoch [141/300], Step [122/225], Training Accuracy: 98.0405%, Training Loss: 0.0583%\n",
      "Epoch [141/300], Step [123/225], Training Accuracy: 98.0564%, Training Loss: 0.0581%\n",
      "Epoch [141/300], Step [124/225], Training Accuracy: 98.0343%, Training Loss: 0.0583%\n",
      "Epoch [141/300], Step [125/225], Training Accuracy: 98.0375%, Training Loss: 0.0582%\n",
      "Epoch [141/300], Step [126/225], Training Accuracy: 98.0531%, Training Loss: 0.0579%\n",
      "Epoch [141/300], Step [127/225], Training Accuracy: 98.0561%, Training Loss: 0.0579%\n",
      "Epoch [141/300], Step [128/225], Training Accuracy: 98.0347%, Training Loss: 0.0582%\n",
      "Epoch [141/300], Step [129/225], Training Accuracy: 98.0257%, Training Loss: 0.0588%\n",
      "Epoch [141/300], Step [130/225], Training Accuracy: 98.0288%, Training Loss: 0.0587%\n",
      "Epoch [141/300], Step [131/225], Training Accuracy: 98.0439%, Training Loss: 0.0584%\n",
      "Epoch [141/300], Step [132/225], Training Accuracy: 98.0469%, Training Loss: 0.0582%\n",
      "Epoch [141/300], Step [133/225], Training Accuracy: 98.0146%, Training Loss: 0.0585%\n",
      "Epoch [141/300], Step [134/225], Training Accuracy: 98.0177%, Training Loss: 0.0583%\n",
      "Epoch [141/300], Step [135/225], Training Accuracy: 98.0208%, Training Loss: 0.0581%\n",
      "Epoch [141/300], Step [136/225], Training Accuracy: 98.0124%, Training Loss: 0.0583%\n",
      "Epoch [141/300], Step [137/225], Training Accuracy: 98.0269%, Training Loss: 0.0581%\n",
      "Epoch [141/300], Step [138/225], Training Accuracy: 98.0299%, Training Loss: 0.0580%\n",
      "Epoch [141/300], Step [139/225], Training Accuracy: 98.0216%, Training Loss: 0.0583%\n",
      "Epoch [141/300], Step [140/225], Training Accuracy: 98.0246%, Training Loss: 0.0581%\n",
      "Epoch [141/300], Step [141/225], Training Accuracy: 98.0164%, Training Loss: 0.0582%\n",
      "Epoch [141/300], Step [142/225], Training Accuracy: 98.0084%, Training Loss: 0.0582%\n",
      "Epoch [141/300], Step [143/225], Training Accuracy: 98.0223%, Training Loss: 0.0582%\n",
      "Epoch [141/300], Step [144/225], Training Accuracy: 98.0360%, Training Loss: 0.0579%\n",
      "Epoch [141/300], Step [145/225], Training Accuracy: 98.0388%, Training Loss: 0.0577%\n",
      "Epoch [141/300], Step [146/225], Training Accuracy: 98.0308%, Training Loss: 0.0580%\n",
      "Epoch [141/300], Step [147/225], Training Accuracy: 98.0442%, Training Loss: 0.0577%\n",
      "Epoch [141/300], Step [148/225], Training Accuracy: 98.0469%, Training Loss: 0.0577%\n",
      "Epoch [141/300], Step [149/225], Training Accuracy: 98.0600%, Training Loss: 0.0575%\n",
      "Epoch [141/300], Step [150/225], Training Accuracy: 98.0312%, Training Loss: 0.0576%\n",
      "Epoch [141/300], Step [151/225], Training Accuracy: 98.0443%, Training Loss: 0.0574%\n",
      "Epoch [141/300], Step [152/225], Training Accuracy: 98.0469%, Training Loss: 0.0573%\n",
      "Epoch [141/300], Step [153/225], Training Accuracy: 98.0494%, Training Loss: 0.0572%\n",
      "Epoch [141/300], Step [154/225], Training Accuracy: 98.0317%, Training Loss: 0.0574%\n",
      "Epoch [141/300], Step [155/225], Training Accuracy: 98.0242%, Training Loss: 0.0575%\n",
      "Epoch [141/300], Step [156/225], Training Accuracy: 98.0168%, Training Loss: 0.0576%\n",
      "Epoch [141/300], Step [157/225], Training Accuracy: 98.0295%, Training Loss: 0.0574%\n",
      "Epoch [141/300], Step [158/225], Training Accuracy: 98.0419%, Training Loss: 0.0572%\n",
      "Epoch [141/300], Step [159/225], Training Accuracy: 98.0542%, Training Loss: 0.0569%\n",
      "Epoch [141/300], Step [160/225], Training Accuracy: 98.0566%, Training Loss: 0.0568%\n",
      "Epoch [141/300], Step [161/225], Training Accuracy: 98.0687%, Training Loss: 0.0566%\n",
      "Epoch [141/300], Step [162/225], Training Accuracy: 98.0613%, Training Loss: 0.0568%\n",
      "Epoch [141/300], Step [163/225], Training Accuracy: 98.0445%, Training Loss: 0.0570%\n",
      "Epoch [141/300], Step [164/225], Training Accuracy: 98.0564%, Training Loss: 0.0568%\n",
      "Epoch [141/300], Step [165/225], Training Accuracy: 98.0682%, Training Loss: 0.0566%\n",
      "Epoch [141/300], Step [166/225], Training Accuracy: 98.0704%, Training Loss: 0.0566%\n",
      "Epoch [141/300], Step [167/225], Training Accuracy: 98.0726%, Training Loss: 0.0566%\n",
      "Epoch [141/300], Step [168/225], Training Accuracy: 98.0841%, Training Loss: 0.0564%\n",
      "Epoch [141/300], Step [169/225], Training Accuracy: 98.0862%, Training Loss: 0.0563%\n",
      "Epoch [141/300], Step [170/225], Training Accuracy: 98.0974%, Training Loss: 0.0561%\n",
      "Epoch [141/300], Step [171/225], Training Accuracy: 98.0994%, Training Loss: 0.0560%\n",
      "Epoch [141/300], Step [172/225], Training Accuracy: 98.0923%, Training Loss: 0.0560%\n",
      "Epoch [141/300], Step [173/225], Training Accuracy: 98.0943%, Training Loss: 0.0559%\n",
      "Epoch [141/300], Step [174/225], Training Accuracy: 98.1052%, Training Loss: 0.0556%\n",
      "Epoch [141/300], Step [175/225], Training Accuracy: 98.1161%, Training Loss: 0.0554%\n",
      "Epoch [141/300], Step [176/225], Training Accuracy: 98.1179%, Training Loss: 0.0555%\n",
      "Epoch [141/300], Step [177/225], Training Accuracy: 98.1285%, Training Loss: 0.0555%\n",
      "Epoch [141/300], Step [178/225], Training Accuracy: 98.1303%, Training Loss: 0.0554%\n",
      "Epoch [141/300], Step [179/225], Training Accuracy: 98.1407%, Training Loss: 0.0552%\n",
      "Epoch [141/300], Step [180/225], Training Accuracy: 98.1424%, Training Loss: 0.0552%\n",
      "Epoch [141/300], Step [181/225], Training Accuracy: 98.1354%, Training Loss: 0.0552%\n",
      "Epoch [141/300], Step [182/225], Training Accuracy: 98.1284%, Training Loss: 0.0552%\n",
      "Epoch [141/300], Step [183/225], Training Accuracy: 98.1387%, Training Loss: 0.0550%\n",
      "Epoch [141/300], Step [184/225], Training Accuracy: 98.1148%, Training Loss: 0.0554%\n",
      "Epoch [141/300], Step [185/225], Training Accuracy: 98.1166%, Training Loss: 0.0552%\n",
      "Epoch [141/300], Step [186/225], Training Accuracy: 98.1267%, Training Loss: 0.0550%\n",
      "Epoch [141/300], Step [187/225], Training Accuracy: 98.1367%, Training Loss: 0.0549%\n",
      "Epoch [141/300], Step [188/225], Training Accuracy: 98.1466%, Training Loss: 0.0547%\n",
      "Epoch [141/300], Step [189/225], Training Accuracy: 98.1481%, Training Loss: 0.0546%\n",
      "Epoch [141/300], Step [190/225], Training Accuracy: 98.1414%, Training Loss: 0.0547%\n",
      "Epoch [141/300], Step [191/225], Training Accuracy: 98.1430%, Training Loss: 0.0546%\n",
      "Epoch [141/300], Step [192/225], Training Accuracy: 98.1445%, Training Loss: 0.0546%\n",
      "Epoch [141/300], Step [193/225], Training Accuracy: 98.1380%, Training Loss: 0.0546%\n",
      "Epoch [141/300], Step [194/225], Training Accuracy: 98.1395%, Training Loss: 0.0544%\n",
      "Epoch [141/300], Step [195/225], Training Accuracy: 98.1410%, Training Loss: 0.0544%\n",
      "Epoch [141/300], Step [196/225], Training Accuracy: 98.1505%, Training Loss: 0.0543%\n",
      "Epoch [141/300], Step [197/225], Training Accuracy: 98.1599%, Training Loss: 0.0542%\n",
      "Epoch [141/300], Step [198/225], Training Accuracy: 98.1613%, Training Loss: 0.0542%\n",
      "Epoch [141/300], Step [199/225], Training Accuracy: 98.1627%, Training Loss: 0.0542%\n",
      "Epoch [141/300], Step [200/225], Training Accuracy: 98.1719%, Training Loss: 0.0541%\n",
      "Epoch [141/300], Step [201/225], Training Accuracy: 98.1654%, Training Loss: 0.0543%\n",
      "Epoch [141/300], Step [202/225], Training Accuracy: 98.1745%, Training Loss: 0.0541%\n",
      "Epoch [141/300], Step [203/225], Training Accuracy: 98.1681%, Training Loss: 0.0542%\n",
      "Epoch [141/300], Step [204/225], Training Accuracy: 98.1694%, Training Loss: 0.0542%\n",
      "Epoch [141/300], Step [205/225], Training Accuracy: 98.1784%, Training Loss: 0.0540%\n",
      "Epoch [141/300], Step [206/225], Training Accuracy: 98.1796%, Training Loss: 0.0539%\n",
      "Epoch [141/300], Step [207/225], Training Accuracy: 98.1733%, Training Loss: 0.0540%\n",
      "Epoch [141/300], Step [208/225], Training Accuracy: 98.1821%, Training Loss: 0.0539%\n",
      "Epoch [141/300], Step [209/225], Training Accuracy: 98.1908%, Training Loss: 0.0538%\n",
      "Epoch [141/300], Step [210/225], Training Accuracy: 98.1920%, Training Loss: 0.0537%\n",
      "Epoch [141/300], Step [211/225], Training Accuracy: 98.1931%, Training Loss: 0.0536%\n",
      "Epoch [141/300], Step [212/225], Training Accuracy: 98.1943%, Training Loss: 0.0535%\n",
      "Epoch [141/300], Step [213/225], Training Accuracy: 98.2028%, Training Loss: 0.0534%\n",
      "Epoch [141/300], Step [214/225], Training Accuracy: 98.2112%, Training Loss: 0.0532%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [141/300], Step [215/225], Training Accuracy: 98.2122%, Training Loss: 0.0531%\n",
      "Epoch [141/300], Step [216/225], Training Accuracy: 98.2060%, Training Loss: 0.0532%\n",
      "Epoch [141/300], Step [217/225], Training Accuracy: 98.2143%, Training Loss: 0.0531%\n",
      "Epoch [141/300], Step [218/225], Training Accuracy: 98.2225%, Training Loss: 0.0529%\n",
      "Epoch [141/300], Step [219/225], Training Accuracy: 98.2021%, Training Loss: 0.0533%\n",
      "Epoch [141/300], Step [220/225], Training Accuracy: 98.2102%, Training Loss: 0.0531%\n",
      "Epoch [141/300], Step [221/225], Training Accuracy: 98.2113%, Training Loss: 0.0533%\n",
      "Epoch [141/300], Step [222/225], Training Accuracy: 98.2052%, Training Loss: 0.0533%\n",
      "Epoch [141/300], Step [223/225], Training Accuracy: 98.2133%, Training Loss: 0.0532%\n",
      "Epoch [141/300], Step [224/225], Training Accuracy: 98.2213%, Training Loss: 0.0530%\n",
      "Epoch [141/300], Step [225/225], Training Accuracy: 98.2282%, Training Loss: 0.0529%\n",
      "Epoch [142/300], Step [1/225], Training Accuracy: 98.4375%, Training Loss: 0.0540%\n",
      "Epoch [142/300], Step [2/225], Training Accuracy: 98.4375%, Training Loss: 0.0715%\n",
      "Epoch [142/300], Step [3/225], Training Accuracy: 98.4375%, Training Loss: 0.0636%\n",
      "Epoch [142/300], Step [4/225], Training Accuracy: 98.0469%, Training Loss: 0.0655%\n",
      "Epoch [142/300], Step [5/225], Training Accuracy: 98.4375%, Training Loss: 0.0593%\n",
      "Epoch [142/300], Step [6/225], Training Accuracy: 98.6979%, Training Loss: 0.0555%\n",
      "Epoch [142/300], Step [7/225], Training Accuracy: 98.4375%, Training Loss: 0.0585%\n",
      "Epoch [142/300], Step [8/225], Training Accuracy: 98.6328%, Training Loss: 0.0544%\n",
      "Epoch [142/300], Step [9/225], Training Accuracy: 98.7847%, Training Loss: 0.0524%\n",
      "Epoch [142/300], Step [10/225], Training Accuracy: 98.7500%, Training Loss: 0.0518%\n",
      "Epoch [142/300], Step [11/225], Training Accuracy: 98.7216%, Training Loss: 0.0515%\n",
      "Epoch [142/300], Step [12/225], Training Accuracy: 98.6979%, Training Loss: 0.0521%\n",
      "Epoch [142/300], Step [13/225], Training Accuracy: 98.6779%, Training Loss: 0.0529%\n",
      "Epoch [142/300], Step [14/225], Training Accuracy: 98.5491%, Training Loss: 0.0540%\n",
      "Epoch [142/300], Step [15/225], Training Accuracy: 98.5417%, Training Loss: 0.0524%\n",
      "Epoch [142/300], Step [16/225], Training Accuracy: 98.5352%, Training Loss: 0.0521%\n",
      "Epoch [142/300], Step [17/225], Training Accuracy: 98.5294%, Training Loss: 0.0510%\n",
      "Epoch [142/300], Step [18/225], Training Accuracy: 98.5243%, Training Loss: 0.0504%\n",
      "Epoch [142/300], Step [19/225], Training Accuracy: 98.5197%, Training Loss: 0.0507%\n",
      "Epoch [142/300], Step [20/225], Training Accuracy: 98.5156%, Training Loss: 0.0496%\n",
      "Epoch [142/300], Step [21/225], Training Accuracy: 98.5119%, Training Loss: 0.0516%\n",
      "Epoch [142/300], Step [22/225], Training Accuracy: 98.5795%, Training Loss: 0.0504%\n",
      "Epoch [142/300], Step [23/225], Training Accuracy: 98.6413%, Training Loss: 0.0490%\n",
      "Epoch [142/300], Step [24/225], Training Accuracy: 98.6979%, Training Loss: 0.0488%\n",
      "Epoch [142/300], Step [25/225], Training Accuracy: 98.6250%, Training Loss: 0.0490%\n",
      "Epoch [142/300], Step [26/225], Training Accuracy: 98.5577%, Training Loss: 0.0505%\n",
      "Epoch [142/300], Step [27/225], Training Accuracy: 98.6111%, Training Loss: 0.0497%\n",
      "Epoch [142/300], Step [28/225], Training Accuracy: 98.5491%, Training Loss: 0.0508%\n",
      "Epoch [142/300], Step [29/225], Training Accuracy: 98.5991%, Training Loss: 0.0503%\n",
      "Epoch [142/300], Step [30/225], Training Accuracy: 98.5938%, Training Loss: 0.0497%\n",
      "Epoch [142/300], Step [31/225], Training Accuracy: 98.5887%, Training Loss: 0.0495%\n",
      "Epoch [142/300], Step [32/225], Training Accuracy: 98.5840%, Training Loss: 0.0491%\n",
      "Epoch [142/300], Step [33/225], Training Accuracy: 98.5322%, Training Loss: 0.0508%\n",
      "Epoch [142/300], Step [34/225], Training Accuracy: 98.5754%, Training Loss: 0.0497%\n",
      "Epoch [142/300], Step [35/225], Training Accuracy: 98.6161%, Training Loss: 0.0488%\n",
      "Epoch [142/300], Step [36/225], Training Accuracy: 98.6545%, Training Loss: 0.0486%\n",
      "Epoch [142/300], Step [37/225], Training Accuracy: 98.6909%, Training Loss: 0.0485%\n",
      "Epoch [142/300], Step [38/225], Training Accuracy: 98.6842%, Training Loss: 0.0482%\n",
      "Epoch [142/300], Step [39/225], Training Accuracy: 98.7179%, Training Loss: 0.0479%\n",
      "Epoch [142/300], Step [40/225], Training Accuracy: 98.7109%, Training Loss: 0.0482%\n",
      "Epoch [142/300], Step [41/225], Training Accuracy: 98.7043%, Training Loss: 0.0481%\n",
      "Epoch [142/300], Step [42/225], Training Accuracy: 98.7351%, Training Loss: 0.0471%\n",
      "Epoch [142/300], Step [43/225], Training Accuracy: 98.7282%, Training Loss: 0.0470%\n",
      "Epoch [142/300], Step [44/225], Training Accuracy: 98.7571%, Training Loss: 0.0469%\n",
      "Epoch [142/300], Step [45/225], Training Accuracy: 98.7847%, Training Loss: 0.0462%\n",
      "Epoch [142/300], Step [46/225], Training Accuracy: 98.8111%, Training Loss: 0.0455%\n",
      "Epoch [142/300], Step [47/225], Training Accuracy: 98.8364%, Training Loss: 0.0449%\n",
      "Epoch [142/300], Step [48/225], Training Accuracy: 98.8607%, Training Loss: 0.0444%\n",
      "Epoch [142/300], Step [49/225], Training Accuracy: 98.8202%, Training Loss: 0.0456%\n",
      "Epoch [142/300], Step [50/225], Training Accuracy: 98.8438%, Training Loss: 0.0457%\n",
      "Epoch [142/300], Step [51/225], Training Accuracy: 98.8358%, Training Loss: 0.0454%\n",
      "Epoch [142/300], Step [52/225], Training Accuracy: 98.8582%, Training Loss: 0.0446%\n",
      "Epoch [142/300], Step [53/225], Training Accuracy: 98.8797%, Training Loss: 0.0445%\n",
      "Epoch [142/300], Step [54/225], Training Accuracy: 98.8426%, Training Loss: 0.0464%\n",
      "Epoch [142/300], Step [55/225], Training Accuracy: 98.8352%, Training Loss: 0.0461%\n",
      "Epoch [142/300], Step [56/225], Training Accuracy: 98.8560%, Training Loss: 0.0458%\n",
      "Epoch [142/300], Step [57/225], Training Accuracy: 98.8761%, Training Loss: 0.0456%\n",
      "Epoch [142/300], Step [58/225], Training Accuracy: 98.8685%, Training Loss: 0.0452%\n",
      "Epoch [142/300], Step [59/225], Training Accuracy: 98.8083%, Training Loss: 0.0457%\n",
      "Epoch [142/300], Step [60/225], Training Accuracy: 98.8281%, Training Loss: 0.0454%\n",
      "Epoch [142/300], Step [61/225], Training Accuracy: 98.7961%, Training Loss: 0.0471%\n",
      "Epoch [142/300], Step [62/225], Training Accuracy: 98.8155%, Training Loss: 0.0466%\n",
      "Epoch [142/300], Step [63/225], Training Accuracy: 98.8343%, Training Loss: 0.0464%\n",
      "Epoch [142/300], Step [64/225], Training Accuracy: 98.8281%, Training Loss: 0.0466%\n",
      "Epoch [142/300], Step [65/225], Training Accuracy: 98.8221%, Training Loss: 0.0464%\n",
      "Epoch [142/300], Step [66/225], Training Accuracy: 98.7926%, Training Loss: 0.0466%\n",
      "Epoch [142/300], Step [67/225], Training Accuracy: 98.8106%, Training Loss: 0.0466%\n",
      "Epoch [142/300], Step [68/225], Training Accuracy: 98.8281%, Training Loss: 0.0463%\n",
      "Epoch [142/300], Step [69/225], Training Accuracy: 98.8451%, Training Loss: 0.0459%\n",
      "Epoch [142/300], Step [70/225], Training Accuracy: 98.8393%, Training Loss: 0.0464%\n",
      "Epoch [142/300], Step [71/225], Training Accuracy: 98.8336%, Training Loss: 0.0463%\n",
      "Epoch [142/300], Step [72/225], Training Accuracy: 98.8498%, Training Loss: 0.0460%\n",
      "Epoch [142/300], Step [73/225], Training Accuracy: 98.8442%, Training Loss: 0.0459%\n",
      "Epoch [142/300], Step [74/225], Training Accuracy: 98.8176%, Training Loss: 0.0466%\n",
      "Epoch [142/300], Step [75/225], Training Accuracy: 98.7917%, Training Loss: 0.0468%\n",
      "Epoch [142/300], Step [76/225], Training Accuracy: 98.7870%, Training Loss: 0.0472%\n",
      "Epoch [142/300], Step [77/225], Training Accuracy: 98.8028%, Training Loss: 0.0469%\n",
      "Epoch [142/300], Step [78/225], Training Accuracy: 98.8181%, Training Loss: 0.0468%\n",
      "Epoch [142/300], Step [79/225], Training Accuracy: 98.8133%, Training Loss: 0.0468%\n",
      "Epoch [142/300], Step [80/225], Training Accuracy: 98.8086%, Training Loss: 0.0472%\n",
      "Epoch [142/300], Step [81/225], Training Accuracy: 98.8233%, Training Loss: 0.0469%\n",
      "Epoch [142/300], Step [82/225], Training Accuracy: 98.8377%, Training Loss: 0.0466%\n",
      "Epoch [142/300], Step [83/225], Training Accuracy: 98.8140%, Training Loss: 0.0470%\n",
      "Epoch [142/300], Step [84/225], Training Accuracy: 98.8281%, Training Loss: 0.0469%\n",
      "Epoch [142/300], Step [85/225], Training Accuracy: 98.8419%, Training Loss: 0.0467%\n",
      "Epoch [142/300], Step [86/225], Training Accuracy: 98.8009%, Training Loss: 0.0473%\n",
      "Epoch [142/300], Step [87/225], Training Accuracy: 98.7608%, Training Loss: 0.0477%\n",
      "Epoch [142/300], Step [88/225], Training Accuracy: 98.7749%, Training Loss: 0.0474%\n",
      "Epoch [142/300], Step [89/225], Training Accuracy: 98.7711%, Training Loss: 0.0472%\n",
      "Epoch [142/300], Step [90/225], Training Accuracy: 98.7674%, Training Loss: 0.0472%\n",
      "Epoch [142/300], Step [91/225], Training Accuracy: 98.7637%, Training Loss: 0.0472%\n",
      "Epoch [142/300], Step [92/225], Training Accuracy: 98.7772%, Training Loss: 0.0472%\n",
      "Epoch [142/300], Step [93/225], Training Accuracy: 98.7735%, Training Loss: 0.0469%\n",
      "Epoch [142/300], Step [94/225], Training Accuracy: 98.7699%, Training Loss: 0.0471%\n",
      "Epoch [142/300], Step [95/225], Training Accuracy: 98.7829%, Training Loss: 0.0470%\n",
      "Epoch [142/300], Step [96/225], Training Accuracy: 98.7630%, Training Loss: 0.0470%\n",
      "Epoch [142/300], Step [97/225], Training Accuracy: 98.7758%, Training Loss: 0.0469%\n",
      "Epoch [142/300], Step [98/225], Training Accuracy: 98.7564%, Training Loss: 0.0474%\n",
      "Epoch [142/300], Step [99/225], Training Accuracy: 98.7689%, Training Loss: 0.0471%\n",
      "Epoch [142/300], Step [100/225], Training Accuracy: 98.7812%, Training Loss: 0.0468%\n",
      "Epoch [142/300], Step [101/225], Training Accuracy: 98.7778%, Training Loss: 0.0468%\n",
      "Epoch [142/300], Step [102/225], Training Accuracy: 98.7745%, Training Loss: 0.0466%\n",
      "Epoch [142/300], Step [103/225], Training Accuracy: 98.7712%, Training Loss: 0.0467%\n",
      "Epoch [142/300], Step [104/225], Training Accuracy: 98.7530%, Training Loss: 0.0468%\n",
      "Epoch [142/300], Step [105/225], Training Accuracy: 98.7649%, Training Loss: 0.0465%\n",
      "Epoch [142/300], Step [106/225], Training Accuracy: 98.7618%, Training Loss: 0.0465%\n",
      "Epoch [142/300], Step [107/225], Training Accuracy: 98.7588%, Training Loss: 0.0467%\n",
      "Epoch [142/300], Step [108/225], Training Accuracy: 98.7558%, Training Loss: 0.0467%\n",
      "Epoch [142/300], Step [109/225], Training Accuracy: 98.7529%, Training Loss: 0.0466%\n",
      "Epoch [142/300], Step [110/225], Training Accuracy: 98.7642%, Training Loss: 0.0463%\n",
      "Epoch [142/300], Step [111/225], Training Accuracy: 98.7753%, Training Loss: 0.0461%\n",
      "Epoch [142/300], Step [112/225], Training Accuracy: 98.7723%, Training Loss: 0.0460%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [142/300], Step [113/225], Training Accuracy: 98.7832%, Training Loss: 0.0457%\n",
      "Epoch [142/300], Step [114/225], Training Accuracy: 98.7527%, Training Loss: 0.0461%\n",
      "Epoch [142/300], Step [115/225], Training Accuracy: 98.7500%, Training Loss: 0.0459%\n",
      "Epoch [142/300], Step [116/225], Training Accuracy: 98.7473%, Training Loss: 0.0458%\n",
      "Epoch [142/300], Step [117/225], Training Accuracy: 98.7447%, Training Loss: 0.0458%\n",
      "Epoch [142/300], Step [118/225], Training Accuracy: 98.7156%, Training Loss: 0.0463%\n",
      "Epoch [142/300], Step [119/225], Training Accuracy: 98.7001%, Training Loss: 0.0468%\n",
      "Epoch [142/300], Step [120/225], Training Accuracy: 98.7109%, Training Loss: 0.0465%\n",
      "Epoch [142/300], Step [121/225], Training Accuracy: 98.6958%, Training Loss: 0.0466%\n",
      "Epoch [142/300], Step [122/225], Training Accuracy: 98.7065%, Training Loss: 0.0465%\n",
      "Epoch [142/300], Step [123/225], Training Accuracy: 98.7170%, Training Loss: 0.0463%\n",
      "Epoch [142/300], Step [124/225], Training Accuracy: 98.7147%, Training Loss: 0.0462%\n",
      "Epoch [142/300], Step [125/225], Training Accuracy: 98.7125%, Training Loss: 0.0463%\n",
      "Epoch [142/300], Step [126/225], Training Accuracy: 98.6731%, Training Loss: 0.0470%\n",
      "Epoch [142/300], Step [127/225], Training Accuracy: 98.6220%, Training Loss: 0.0475%\n",
      "Epoch [142/300], Step [128/225], Training Accuracy: 98.6084%, Training Loss: 0.0485%\n",
      "Epoch [142/300], Step [129/225], Training Accuracy: 98.6071%, Training Loss: 0.0487%\n",
      "Epoch [142/300], Step [130/225], Training Accuracy: 98.5938%, Training Loss: 0.0488%\n",
      "Epoch [142/300], Step [131/225], Training Accuracy: 98.5806%, Training Loss: 0.0488%\n",
      "Epoch [142/300], Step [132/225], Training Accuracy: 98.5677%, Training Loss: 0.0489%\n",
      "Epoch [142/300], Step [133/225], Training Accuracy: 98.5667%, Training Loss: 0.0488%\n",
      "Epoch [142/300], Step [134/225], Training Accuracy: 98.5774%, Training Loss: 0.0486%\n",
      "Epoch [142/300], Step [135/225], Training Accuracy: 98.5764%, Training Loss: 0.0486%\n",
      "Epoch [142/300], Step [136/225], Training Accuracy: 98.5754%, Training Loss: 0.0486%\n",
      "Epoch [142/300], Step [137/225], Training Accuracy: 98.5858%, Training Loss: 0.0483%\n",
      "Epoch [142/300], Step [138/225], Training Accuracy: 98.5734%, Training Loss: 0.0486%\n",
      "Epoch [142/300], Step [139/225], Training Accuracy: 98.5724%, Training Loss: 0.0486%\n",
      "Epoch [142/300], Step [140/225], Training Accuracy: 98.5714%, Training Loss: 0.0485%\n",
      "Epoch [142/300], Step [141/225], Training Accuracy: 98.5372%, Training Loss: 0.0489%\n",
      "Epoch [142/300], Step [142/225], Training Accuracy: 98.5475%, Training Loss: 0.0487%\n",
      "Epoch [142/300], Step [143/225], Training Accuracy: 98.5358%, Training Loss: 0.0489%\n",
      "Epoch [142/300], Step [144/225], Training Accuracy: 98.5352%, Training Loss: 0.0490%\n",
      "Epoch [142/300], Step [145/225], Training Accuracy: 98.5237%, Training Loss: 0.0491%\n",
      "Epoch [142/300], Step [146/225], Training Accuracy: 98.5231%, Training Loss: 0.0491%\n",
      "Epoch [142/300], Step [147/225], Training Accuracy: 98.5119%, Training Loss: 0.0495%\n",
      "Epoch [142/300], Step [148/225], Training Accuracy: 98.5114%, Training Loss: 0.0494%\n",
      "Epoch [142/300], Step [149/225], Training Accuracy: 98.5004%, Training Loss: 0.0496%\n",
      "Epoch [142/300], Step [150/225], Training Accuracy: 98.5000%, Training Loss: 0.0498%\n",
      "Epoch [142/300], Step [151/225], Training Accuracy: 98.5099%, Training Loss: 0.0496%\n",
      "Epoch [142/300], Step [152/225], Training Accuracy: 98.5197%, Training Loss: 0.0494%\n",
      "Epoch [142/300], Step [153/225], Training Accuracy: 98.5294%, Training Loss: 0.0492%\n",
      "Epoch [142/300], Step [154/225], Training Accuracy: 98.5288%, Training Loss: 0.0491%\n",
      "Epoch [142/300], Step [155/225], Training Accuracy: 98.5282%, Training Loss: 0.0490%\n",
      "Epoch [142/300], Step [156/225], Training Accuracy: 98.5377%, Training Loss: 0.0488%\n",
      "Epoch [142/300], Step [157/225], Training Accuracy: 98.5470%, Training Loss: 0.0487%\n",
      "Epoch [142/300], Step [158/225], Training Accuracy: 98.5463%, Training Loss: 0.0486%\n",
      "Epoch [142/300], Step [159/225], Training Accuracy: 98.5456%, Training Loss: 0.0485%\n",
      "Epoch [142/300], Step [160/225], Training Accuracy: 98.5352%, Training Loss: 0.0486%\n",
      "Epoch [142/300], Step [161/225], Training Accuracy: 98.5345%, Training Loss: 0.0485%\n",
      "Epoch [142/300], Step [162/225], Training Accuracy: 98.5436%, Training Loss: 0.0484%\n",
      "Epoch [142/300], Step [163/225], Training Accuracy: 98.5429%, Training Loss: 0.0484%\n",
      "Epoch [142/300], Step [164/225], Training Accuracy: 98.5328%, Training Loss: 0.0486%\n",
      "Epoch [142/300], Step [165/225], Training Accuracy: 98.5417%, Training Loss: 0.0483%\n",
      "Epoch [142/300], Step [166/225], Training Accuracy: 98.5316%, Training Loss: 0.0485%\n",
      "Epoch [142/300], Step [167/225], Training Accuracy: 98.5217%, Training Loss: 0.0485%\n",
      "Epoch [142/300], Step [168/225], Training Accuracy: 98.5119%, Training Loss: 0.0486%\n",
      "Epoch [142/300], Step [169/225], Training Accuracy: 98.5115%, Training Loss: 0.0487%\n",
      "Epoch [142/300], Step [170/225], Training Accuracy: 98.5110%, Training Loss: 0.0487%\n",
      "Epoch [142/300], Step [171/225], Training Accuracy: 98.5106%, Training Loss: 0.0489%\n",
      "Epoch [142/300], Step [172/225], Training Accuracy: 98.4920%, Training Loss: 0.0492%\n",
      "Epoch [142/300], Step [173/225], Training Accuracy: 98.5007%, Training Loss: 0.0490%\n",
      "Epoch [142/300], Step [174/225], Training Accuracy: 98.5004%, Training Loss: 0.0489%\n",
      "Epoch [142/300], Step [175/225], Training Accuracy: 98.4911%, Training Loss: 0.0490%\n",
      "Epoch [142/300], Step [176/225], Training Accuracy: 98.4996%, Training Loss: 0.0489%\n",
      "Epoch [142/300], Step [177/225], Training Accuracy: 98.4905%, Training Loss: 0.0491%\n",
      "Epoch [142/300], Step [178/225], Training Accuracy: 98.4814%, Training Loss: 0.0492%\n",
      "Epoch [142/300], Step [179/225], Training Accuracy: 98.4462%, Training Loss: 0.0497%\n",
      "Epoch [142/300], Step [180/225], Training Accuracy: 98.4549%, Training Loss: 0.0495%\n",
      "Epoch [142/300], Step [181/225], Training Accuracy: 98.4634%, Training Loss: 0.0494%\n",
      "Epoch [142/300], Step [182/225], Training Accuracy: 98.4718%, Training Loss: 0.0492%\n",
      "Epoch [142/300], Step [183/225], Training Accuracy: 98.4802%, Training Loss: 0.0490%\n",
      "Epoch [142/300], Step [184/225], Training Accuracy: 98.4800%, Training Loss: 0.0491%\n",
      "Epoch [142/300], Step [185/225], Training Accuracy: 98.4713%, Training Loss: 0.0491%\n",
      "Epoch [142/300], Step [186/225], Training Accuracy: 98.4711%, Training Loss: 0.0492%\n",
      "Epoch [142/300], Step [187/225], Training Accuracy: 98.4542%, Training Loss: 0.0494%\n",
      "Epoch [142/300], Step [188/225], Training Accuracy: 98.4458%, Training Loss: 0.0495%\n",
      "Epoch [142/300], Step [189/225], Training Accuracy: 98.4375%, Training Loss: 0.0496%\n",
      "Epoch [142/300], Step [190/225], Training Accuracy: 98.4375%, Training Loss: 0.0496%\n",
      "Epoch [142/300], Step [191/225], Training Accuracy: 98.4457%, Training Loss: 0.0495%\n",
      "Epoch [142/300], Step [192/225], Training Accuracy: 98.4375%, Training Loss: 0.0496%\n",
      "Epoch [142/300], Step [193/225], Training Accuracy: 98.4294%, Training Loss: 0.0498%\n",
      "Epoch [142/300], Step [194/225], Training Accuracy: 98.4294%, Training Loss: 0.0498%\n",
      "Epoch [142/300], Step [195/225], Training Accuracy: 98.4295%, Training Loss: 0.0497%\n",
      "Epoch [142/300], Step [196/225], Training Accuracy: 98.4375%, Training Loss: 0.0495%\n",
      "Epoch [142/300], Step [197/225], Training Accuracy: 98.4375%, Training Loss: 0.0495%\n",
      "Epoch [142/300], Step [198/225], Training Accuracy: 98.4375%, Training Loss: 0.0496%\n",
      "Epoch [142/300], Step [199/225], Training Accuracy: 98.4375%, Training Loss: 0.0495%\n",
      "Epoch [142/300], Step [200/225], Training Accuracy: 98.4375%, Training Loss: 0.0494%\n",
      "Epoch [142/300], Step [201/225], Training Accuracy: 98.4297%, Training Loss: 0.0496%\n",
      "Epoch [142/300], Step [202/225], Training Accuracy: 98.4298%, Training Loss: 0.0497%\n",
      "Epoch [142/300], Step [203/225], Training Accuracy: 98.4375%, Training Loss: 0.0497%\n",
      "Epoch [142/300], Step [204/225], Training Accuracy: 98.4452%, Training Loss: 0.0496%\n",
      "Epoch [142/300], Step [205/225], Training Accuracy: 98.4451%, Training Loss: 0.0497%\n",
      "Epoch [142/300], Step [206/225], Training Accuracy: 98.4527%, Training Loss: 0.0497%\n",
      "Epoch [142/300], Step [207/225], Training Accuracy: 98.4526%, Training Loss: 0.0497%\n",
      "Epoch [142/300], Step [208/225], Training Accuracy: 98.4525%, Training Loss: 0.0497%\n",
      "Epoch [142/300], Step [209/225], Training Accuracy: 98.4599%, Training Loss: 0.0495%\n",
      "Epoch [142/300], Step [210/225], Training Accuracy: 98.4598%, Training Loss: 0.0495%\n",
      "Epoch [142/300], Step [211/225], Training Accuracy: 98.4523%, Training Loss: 0.0495%\n",
      "Epoch [142/300], Step [212/225], Training Accuracy: 98.4596%, Training Loss: 0.0494%\n",
      "Epoch [142/300], Step [213/225], Training Accuracy: 98.4595%, Training Loss: 0.0497%\n",
      "Epoch [142/300], Step [214/225], Training Accuracy: 98.4448%, Training Loss: 0.0499%\n",
      "Epoch [142/300], Step [215/225], Training Accuracy: 98.4520%, Training Loss: 0.0497%\n",
      "Epoch [142/300], Step [216/225], Training Accuracy: 98.4447%, Training Loss: 0.0499%\n",
      "Epoch [142/300], Step [217/225], Training Accuracy: 98.4519%, Training Loss: 0.0498%\n",
      "Epoch [142/300], Step [218/225], Training Accuracy: 98.4447%, Training Loss: 0.0498%\n",
      "Epoch [142/300], Step [219/225], Training Accuracy: 98.4446%, Training Loss: 0.0498%\n",
      "Epoch [142/300], Step [220/225], Training Accuracy: 98.4517%, Training Loss: 0.0497%\n",
      "Epoch [142/300], Step [221/225], Training Accuracy: 98.4516%, Training Loss: 0.0496%\n",
      "Epoch [142/300], Step [222/225], Training Accuracy: 98.4516%, Training Loss: 0.0496%\n",
      "Epoch [142/300], Step [223/225], Training Accuracy: 98.4585%, Training Loss: 0.0494%\n",
      "Epoch [142/300], Step [224/225], Training Accuracy: 98.4654%, Training Loss: 0.0493%\n",
      "Epoch [142/300], Step [225/225], Training Accuracy: 98.4714%, Training Loss: 0.0492%\n",
      "Epoch [143/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0235%\n",
      "Epoch [143/300], Step [2/225], Training Accuracy: 100.0000%, Training Loss: 0.0202%\n",
      "Epoch [143/300], Step [3/225], Training Accuracy: 98.9583%, Training Loss: 0.0370%\n",
      "Epoch [143/300], Step [4/225], Training Accuracy: 98.8281%, Training Loss: 0.0367%\n",
      "Epoch [143/300], Step [5/225], Training Accuracy: 98.7500%, Training Loss: 0.0382%\n",
      "Epoch [143/300], Step [6/225], Training Accuracy: 98.9583%, Training Loss: 0.0346%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [143/300], Step [7/225], Training Accuracy: 99.1071%, Training Loss: 0.0315%\n",
      "Epoch [143/300], Step [8/225], Training Accuracy: 99.2188%, Training Loss: 0.0290%\n",
      "Epoch [143/300], Step [9/225], Training Accuracy: 99.3056%, Training Loss: 0.0281%\n",
      "Epoch [143/300], Step [10/225], Training Accuracy: 99.2188%, Training Loss: 0.0289%\n",
      "Epoch [143/300], Step [11/225], Training Accuracy: 99.2898%, Training Loss: 0.0284%\n",
      "Epoch [143/300], Step [12/225], Training Accuracy: 99.3490%, Training Loss: 0.0273%\n",
      "Epoch [143/300], Step [13/225], Training Accuracy: 99.3990%, Training Loss: 0.0267%\n",
      "Epoch [143/300], Step [14/225], Training Accuracy: 99.2188%, Training Loss: 0.0293%\n",
      "Epoch [143/300], Step [15/225], Training Accuracy: 99.2708%, Training Loss: 0.0283%\n",
      "Epoch [143/300], Step [16/225], Training Accuracy: 99.3164%, Training Loss: 0.0280%\n",
      "Epoch [143/300], Step [17/225], Training Accuracy: 99.3566%, Training Loss: 0.0280%\n",
      "Epoch [143/300], Step [18/225], Training Accuracy: 99.3924%, Training Loss: 0.0286%\n",
      "Epoch [143/300], Step [19/225], Training Accuracy: 99.3421%, Training Loss: 0.0286%\n",
      "Epoch [143/300], Step [20/225], Training Accuracy: 99.1406%, Training Loss: 0.0304%\n",
      "Epoch [143/300], Step [21/225], Training Accuracy: 99.1071%, Training Loss: 0.0321%\n",
      "Epoch [143/300], Step [22/225], Training Accuracy: 99.0767%, Training Loss: 0.0322%\n",
      "Epoch [143/300], Step [23/225], Training Accuracy: 98.9810%, Training Loss: 0.0326%\n",
      "Epoch [143/300], Step [24/225], Training Accuracy: 98.9583%, Training Loss: 0.0325%\n",
      "Epoch [143/300], Step [25/225], Training Accuracy: 98.9375%, Training Loss: 0.0329%\n",
      "Epoch [143/300], Step [26/225], Training Accuracy: 98.7981%, Training Loss: 0.0359%\n",
      "Epoch [143/300], Step [27/225], Training Accuracy: 98.7269%, Training Loss: 0.0368%\n",
      "Epoch [143/300], Step [28/225], Training Accuracy: 98.7723%, Training Loss: 0.0357%\n",
      "Epoch [143/300], Step [29/225], Training Accuracy: 98.7608%, Training Loss: 0.0354%\n",
      "Epoch [143/300], Step [30/225], Training Accuracy: 98.7500%, Training Loss: 0.0355%\n",
      "Epoch [143/300], Step [31/225], Training Accuracy: 98.6895%, Training Loss: 0.0365%\n",
      "Epoch [143/300], Step [32/225], Training Accuracy: 98.7305%, Training Loss: 0.0359%\n",
      "Epoch [143/300], Step [33/225], Training Accuracy: 98.7216%, Training Loss: 0.0361%\n",
      "Epoch [143/300], Step [34/225], Training Accuracy: 98.7592%, Training Loss: 0.0357%\n",
      "Epoch [143/300], Step [35/225], Training Accuracy: 98.7946%, Training Loss: 0.0353%\n",
      "Epoch [143/300], Step [36/225], Training Accuracy: 98.8281%, Training Loss: 0.0350%\n",
      "Epoch [143/300], Step [37/225], Training Accuracy: 98.7753%, Training Loss: 0.0362%\n",
      "Epoch [143/300], Step [38/225], Training Accuracy: 98.7664%, Training Loss: 0.0370%\n",
      "Epoch [143/300], Step [39/225], Training Accuracy: 98.7981%, Training Loss: 0.0364%\n",
      "Epoch [143/300], Step [40/225], Training Accuracy: 98.8281%, Training Loss: 0.0362%\n",
      "Epoch [143/300], Step [41/225], Training Accuracy: 98.8186%, Training Loss: 0.0367%\n",
      "Epoch [143/300], Step [42/225], Training Accuracy: 98.8467%, Training Loss: 0.0364%\n",
      "Epoch [143/300], Step [43/225], Training Accuracy: 98.8735%, Training Loss: 0.0358%\n",
      "Epoch [143/300], Step [44/225], Training Accuracy: 98.8991%, Training Loss: 0.0352%\n",
      "Epoch [143/300], Step [45/225], Training Accuracy: 98.9236%, Training Loss: 0.0352%\n",
      "Epoch [143/300], Step [46/225], Training Accuracy: 98.9470%, Training Loss: 0.0347%\n",
      "Epoch [143/300], Step [47/225], Training Accuracy: 98.8364%, Training Loss: 0.0367%\n",
      "Epoch [143/300], Step [48/225], Training Accuracy: 98.8281%, Training Loss: 0.0368%\n",
      "Epoch [143/300], Step [49/225], Training Accuracy: 98.8520%, Training Loss: 0.0364%\n",
      "Epoch [143/300], Step [50/225], Training Accuracy: 98.8750%, Training Loss: 0.0362%\n",
      "Epoch [143/300], Step [51/225], Training Accuracy: 98.8664%, Training Loss: 0.0362%\n",
      "Epoch [143/300], Step [52/225], Training Accuracy: 98.8882%, Training Loss: 0.0358%\n",
      "Epoch [143/300], Step [53/225], Training Accuracy: 98.8797%, Training Loss: 0.0357%\n",
      "Epoch [143/300], Step [54/225], Training Accuracy: 98.8715%, Training Loss: 0.0361%\n",
      "Epoch [143/300], Step [55/225], Training Accuracy: 98.8636%, Training Loss: 0.0365%\n",
      "Epoch [143/300], Step [56/225], Training Accuracy: 98.8281%, Training Loss: 0.0375%\n",
      "Epoch [143/300], Step [57/225], Training Accuracy: 98.8487%, Training Loss: 0.0371%\n",
      "Epoch [143/300], Step [58/225], Training Accuracy: 98.8685%, Training Loss: 0.0367%\n",
      "Epoch [143/300], Step [59/225], Training Accuracy: 98.8612%, Training Loss: 0.0367%\n",
      "Epoch [143/300], Step [60/225], Training Accuracy: 98.8802%, Training Loss: 0.0364%\n",
      "Epoch [143/300], Step [61/225], Training Accuracy: 98.8730%, Training Loss: 0.0366%\n",
      "Epoch [143/300], Step [62/225], Training Accuracy: 98.8155%, Training Loss: 0.0372%\n",
      "Epoch [143/300], Step [63/225], Training Accuracy: 98.8095%, Training Loss: 0.0375%\n",
      "Epoch [143/300], Step [64/225], Training Accuracy: 98.8281%, Training Loss: 0.0373%\n",
      "Epoch [143/300], Step [65/225], Training Accuracy: 98.8462%, Training Loss: 0.0368%\n",
      "Epoch [143/300], Step [66/225], Training Accuracy: 98.8636%, Training Loss: 0.0366%\n",
      "Epoch [143/300], Step [67/225], Training Accuracy: 98.8340%, Training Loss: 0.0370%\n",
      "Epoch [143/300], Step [68/225], Training Accuracy: 98.8281%, Training Loss: 0.0368%\n",
      "Epoch [143/300], Step [69/225], Training Accuracy: 98.7998%, Training Loss: 0.0373%\n",
      "Epoch [143/300], Step [70/225], Training Accuracy: 98.8170%, Training Loss: 0.0371%\n",
      "Epoch [143/300], Step [71/225], Training Accuracy: 98.7896%, Training Loss: 0.0374%\n",
      "Epoch [143/300], Step [72/225], Training Accuracy: 98.7847%, Training Loss: 0.0374%\n",
      "Epoch [143/300], Step [73/225], Training Accuracy: 98.7800%, Training Loss: 0.0376%\n",
      "Epoch [143/300], Step [74/225], Training Accuracy: 98.7331%, Training Loss: 0.0381%\n",
      "Epoch [143/300], Step [75/225], Training Accuracy: 98.7500%, Training Loss: 0.0378%\n",
      "Epoch [143/300], Step [76/225], Training Accuracy: 98.7459%, Training Loss: 0.0377%\n",
      "Epoch [143/300], Step [77/225], Training Accuracy: 98.7216%, Training Loss: 0.0379%\n",
      "Epoch [143/300], Step [78/225], Training Accuracy: 98.7380%, Training Loss: 0.0378%\n",
      "Epoch [143/300], Step [79/225], Training Accuracy: 98.7144%, Training Loss: 0.0382%\n",
      "Epoch [143/300], Step [80/225], Training Accuracy: 98.7109%, Training Loss: 0.0387%\n",
      "Epoch [143/300], Step [81/225], Training Accuracy: 98.7269%, Training Loss: 0.0384%\n",
      "Epoch [143/300], Step [82/225], Training Accuracy: 98.6852%, Training Loss: 0.0389%\n",
      "Epoch [143/300], Step [83/225], Training Accuracy: 98.6822%, Training Loss: 0.0390%\n",
      "Epoch [143/300], Step [84/225], Training Accuracy: 98.6793%, Training Loss: 0.0393%\n",
      "Epoch [143/300], Step [85/225], Training Accuracy: 98.6765%, Training Loss: 0.0392%\n",
      "Epoch [143/300], Step [86/225], Training Accuracy: 98.6737%, Training Loss: 0.0396%\n",
      "Epoch [143/300], Step [87/225], Training Accuracy: 98.6889%, Training Loss: 0.0393%\n",
      "Epoch [143/300], Step [88/225], Training Accuracy: 98.6683%, Training Loss: 0.0394%\n",
      "Epoch [143/300], Step [89/225], Training Accuracy: 98.6657%, Training Loss: 0.0394%\n",
      "Epoch [143/300], Step [90/225], Training Accuracy: 98.6458%, Training Loss: 0.0396%\n",
      "Epoch [143/300], Step [91/225], Training Accuracy: 98.6607%, Training Loss: 0.0395%\n",
      "Epoch [143/300], Step [92/225], Training Accuracy: 98.6753%, Training Loss: 0.0393%\n",
      "Epoch [143/300], Step [93/225], Training Accuracy: 98.6391%, Training Loss: 0.0399%\n",
      "Epoch [143/300], Step [94/225], Training Accuracy: 98.6536%, Training Loss: 0.0396%\n",
      "Epoch [143/300], Step [95/225], Training Accuracy: 98.6513%, Training Loss: 0.0396%\n",
      "Epoch [143/300], Step [96/225], Training Accuracy: 98.6654%, Training Loss: 0.0393%\n",
      "Epoch [143/300], Step [97/225], Training Accuracy: 98.6469%, Training Loss: 0.0400%\n",
      "Epoch [143/300], Step [98/225], Training Accuracy: 98.6607%, Training Loss: 0.0399%\n",
      "Epoch [143/300], Step [99/225], Training Accuracy: 98.6585%, Training Loss: 0.0399%\n",
      "Epoch [143/300], Step [100/225], Training Accuracy: 98.6406%, Training Loss: 0.0404%\n",
      "Epoch [143/300], Step [101/225], Training Accuracy: 98.6386%, Training Loss: 0.0406%\n",
      "Epoch [143/300], Step [102/225], Training Accuracy: 98.6520%, Training Loss: 0.0404%\n",
      "Epoch [143/300], Step [103/225], Training Accuracy: 98.6044%, Training Loss: 0.0416%\n",
      "Epoch [143/300], Step [104/225], Training Accuracy: 98.6178%, Training Loss: 0.0414%\n",
      "Epoch [143/300], Step [105/225], Training Accuracy: 98.6012%, Training Loss: 0.0422%\n",
      "Epoch [143/300], Step [106/225], Training Accuracy: 98.6144%, Training Loss: 0.0420%\n",
      "Epoch [143/300], Step [107/225], Training Accuracy: 98.6273%, Training Loss: 0.0419%\n",
      "Epoch [143/300], Step [108/225], Training Accuracy: 98.6111%, Training Loss: 0.0422%\n",
      "Epoch [143/300], Step [109/225], Training Accuracy: 98.5952%, Training Loss: 0.0424%\n",
      "Epoch [143/300], Step [110/225], Training Accuracy: 98.5795%, Training Loss: 0.0425%\n",
      "Epoch [143/300], Step [111/225], Training Accuracy: 98.5783%, Training Loss: 0.0424%\n",
      "Epoch [143/300], Step [112/225], Training Accuracy: 98.5910%, Training Loss: 0.0421%\n",
      "Epoch [143/300], Step [113/225], Training Accuracy: 98.5896%, Training Loss: 0.0422%\n",
      "Epoch [143/300], Step [114/225], Training Accuracy: 98.6020%, Training Loss: 0.0421%\n",
      "Epoch [143/300], Step [115/225], Training Accuracy: 98.6141%, Training Loss: 0.0420%\n",
      "Epoch [143/300], Step [116/225], Training Accuracy: 98.6261%, Training Loss: 0.0420%\n",
      "Epoch [143/300], Step [117/225], Training Accuracy: 98.6378%, Training Loss: 0.0419%\n",
      "Epoch [143/300], Step [118/225], Training Accuracy: 98.6096%, Training Loss: 0.0424%\n",
      "Epoch [143/300], Step [119/225], Training Accuracy: 98.6213%, Training Loss: 0.0423%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [143/300], Step [120/225], Training Accuracy: 98.6328%, Training Loss: 0.0421%\n",
      "Epoch [143/300], Step [121/225], Training Accuracy: 98.6183%, Training Loss: 0.0423%\n",
      "Epoch [143/300], Step [122/225], Training Accuracy: 98.6040%, Training Loss: 0.0424%\n",
      "Epoch [143/300], Step [123/225], Training Accuracy: 98.6153%, Training Loss: 0.0423%\n",
      "Epoch [143/300], Step [124/225], Training Accuracy: 98.6139%, Training Loss: 0.0423%\n",
      "Epoch [143/300], Step [125/225], Training Accuracy: 98.6125%, Training Loss: 0.0423%\n",
      "Epoch [143/300], Step [126/225], Training Accuracy: 98.6111%, Training Loss: 0.0423%\n",
      "Epoch [143/300], Step [127/225], Training Accuracy: 98.6097%, Training Loss: 0.0423%\n",
      "Epoch [143/300], Step [128/225], Training Accuracy: 98.5962%, Training Loss: 0.0429%\n",
      "Epoch [143/300], Step [129/225], Training Accuracy: 98.6071%, Training Loss: 0.0428%\n",
      "Epoch [143/300], Step [130/225], Training Accuracy: 98.6178%, Training Loss: 0.0427%\n",
      "Epoch [143/300], Step [131/225], Training Accuracy: 98.6283%, Training Loss: 0.0425%\n",
      "Epoch [143/300], Step [132/225], Training Accuracy: 98.6387%, Training Loss: 0.0424%\n",
      "Epoch [143/300], Step [133/225], Training Accuracy: 98.6490%, Training Loss: 0.0422%\n",
      "Epoch [143/300], Step [134/225], Training Accuracy: 98.6474%, Training Loss: 0.0421%\n",
      "Epoch [143/300], Step [135/225], Training Accuracy: 98.6574%, Training Loss: 0.0420%\n",
      "Epoch [143/300], Step [136/225], Training Accuracy: 98.6673%, Training Loss: 0.0418%\n",
      "Epoch [143/300], Step [137/225], Training Accuracy: 98.6770%, Training Loss: 0.0417%\n",
      "Epoch [143/300], Step [138/225], Training Accuracy: 98.6753%, Training Loss: 0.0418%\n",
      "Epoch [143/300], Step [139/225], Training Accuracy: 98.6623%, Training Loss: 0.0422%\n",
      "Epoch [143/300], Step [140/225], Training Accuracy: 98.6719%, Training Loss: 0.0420%\n",
      "Epoch [143/300], Step [141/225], Training Accuracy: 98.6702%, Training Loss: 0.0420%\n",
      "Epoch [143/300], Step [142/225], Training Accuracy: 98.6796%, Training Loss: 0.0419%\n",
      "Epoch [143/300], Step [143/225], Training Accuracy: 98.6779%, Training Loss: 0.0418%\n",
      "Epoch [143/300], Step [144/225], Training Accuracy: 98.6871%, Training Loss: 0.0419%\n",
      "Epoch [143/300], Step [145/225], Training Accuracy: 98.6961%, Training Loss: 0.0419%\n",
      "Epoch [143/300], Step [146/225], Training Accuracy: 98.6943%, Training Loss: 0.0418%\n",
      "Epoch [143/300], Step [147/225], Training Accuracy: 98.6820%, Training Loss: 0.0419%\n",
      "Epoch [143/300], Step [148/225], Training Accuracy: 98.6909%, Training Loss: 0.0419%\n",
      "Epoch [143/300], Step [149/225], Training Accuracy: 98.6892%, Training Loss: 0.0419%\n",
      "Epoch [143/300], Step [150/225], Training Accuracy: 98.6979%, Training Loss: 0.0417%\n",
      "Epoch [143/300], Step [151/225], Training Accuracy: 98.7065%, Training Loss: 0.0416%\n",
      "Epoch [143/300], Step [152/225], Training Accuracy: 98.7150%, Training Loss: 0.0415%\n",
      "Epoch [143/300], Step [153/225], Training Accuracy: 98.7234%, Training Loss: 0.0414%\n",
      "Epoch [143/300], Step [154/225], Training Accuracy: 98.7317%, Training Loss: 0.0413%\n",
      "Epoch [143/300], Step [155/225], Training Accuracy: 98.7298%, Training Loss: 0.0413%\n",
      "Epoch [143/300], Step [156/225], Training Accuracy: 98.7380%, Training Loss: 0.0413%\n",
      "Epoch [143/300], Step [157/225], Training Accuracy: 98.7460%, Training Loss: 0.0412%\n",
      "Epoch [143/300], Step [158/225], Training Accuracy: 98.7342%, Training Loss: 0.0414%\n",
      "Epoch [143/300], Step [159/225], Training Accuracy: 98.7421%, Training Loss: 0.0413%\n",
      "Epoch [143/300], Step [160/225], Training Accuracy: 98.7402%, Training Loss: 0.0413%\n",
      "Epoch [143/300], Step [161/225], Training Accuracy: 98.7481%, Training Loss: 0.0411%\n",
      "Epoch [143/300], Step [162/225], Training Accuracy: 98.7461%, Training Loss: 0.0411%\n",
      "Epoch [143/300], Step [163/225], Training Accuracy: 98.7442%, Training Loss: 0.0411%\n",
      "Epoch [143/300], Step [164/225], Training Accuracy: 98.7329%, Training Loss: 0.0412%\n",
      "Epoch [143/300], Step [165/225], Training Accuracy: 98.7311%, Training Loss: 0.0411%\n",
      "Epoch [143/300], Step [166/225], Training Accuracy: 98.7293%, Training Loss: 0.0413%\n",
      "Epoch [143/300], Step [167/225], Training Accuracy: 98.7088%, Training Loss: 0.0414%\n",
      "Epoch [143/300], Step [168/225], Training Accuracy: 98.7072%, Training Loss: 0.0414%\n",
      "Epoch [143/300], Step [169/225], Training Accuracy: 98.6964%, Training Loss: 0.0416%\n",
      "Epoch [143/300], Step [170/225], Training Accuracy: 98.6857%, Training Loss: 0.0417%\n",
      "Epoch [143/300], Step [171/225], Training Accuracy: 98.6842%, Training Loss: 0.0417%\n",
      "Epoch [143/300], Step [172/225], Training Accuracy: 98.6919%, Training Loss: 0.0417%\n",
      "Epoch [143/300], Step [173/225], Training Accuracy: 98.6904%, Training Loss: 0.0418%\n",
      "Epoch [143/300], Step [174/225], Training Accuracy: 98.6889%, Training Loss: 0.0418%\n",
      "Epoch [143/300], Step [175/225], Training Accuracy: 98.6786%, Training Loss: 0.0420%\n",
      "Epoch [143/300], Step [176/225], Training Accuracy: 98.6772%, Training Loss: 0.0420%\n",
      "Epoch [143/300], Step [177/225], Training Accuracy: 98.6670%, Training Loss: 0.0421%\n",
      "Epoch [143/300], Step [178/225], Training Accuracy: 98.6657%, Training Loss: 0.0420%\n",
      "Epoch [143/300], Step [179/225], Training Accuracy: 98.6645%, Training Loss: 0.0420%\n",
      "Epoch [143/300], Step [180/225], Training Accuracy: 98.6719%, Training Loss: 0.0419%\n",
      "Epoch [143/300], Step [181/225], Training Accuracy: 98.6792%, Training Loss: 0.0418%\n",
      "Epoch [143/300], Step [182/225], Training Accuracy: 98.6607%, Training Loss: 0.0422%\n",
      "Epoch [143/300], Step [183/225], Training Accuracy: 98.6680%, Training Loss: 0.0421%\n",
      "Epoch [143/300], Step [184/225], Training Accuracy: 98.6753%, Training Loss: 0.0420%\n",
      "Epoch [143/300], Step [185/225], Training Accuracy: 98.6740%, Training Loss: 0.0420%\n",
      "Epoch [143/300], Step [186/225], Training Accuracy: 98.6811%, Training Loss: 0.0419%\n",
      "Epoch [143/300], Step [187/225], Training Accuracy: 98.6882%, Training Loss: 0.0418%\n",
      "Epoch [143/300], Step [188/225], Training Accuracy: 98.6868%, Training Loss: 0.0420%\n",
      "Epoch [143/300], Step [189/225], Training Accuracy: 98.6855%, Training Loss: 0.0420%\n",
      "Epoch [143/300], Step [190/225], Training Accuracy: 98.6842%, Training Loss: 0.0420%\n",
      "Epoch [143/300], Step [191/225], Training Accuracy: 98.6829%, Training Loss: 0.0419%\n",
      "Epoch [143/300], Step [192/225], Training Accuracy: 98.6816%, Training Loss: 0.0420%\n",
      "Epoch [143/300], Step [193/225], Training Accuracy: 98.6885%, Training Loss: 0.0419%\n",
      "Epoch [143/300], Step [194/225], Training Accuracy: 98.6791%, Training Loss: 0.0420%\n",
      "Epoch [143/300], Step [195/225], Training Accuracy: 98.6458%, Training Loss: 0.0426%\n",
      "Epoch [143/300], Step [196/225], Training Accuracy: 98.6527%, Training Loss: 0.0424%\n",
      "Epoch [143/300], Step [197/225], Training Accuracy: 98.6596%, Training Loss: 0.0424%\n",
      "Epoch [143/300], Step [198/225], Training Accuracy: 98.6585%, Training Loss: 0.0425%\n",
      "Epoch [143/300], Step [199/225], Training Accuracy: 98.6573%, Training Loss: 0.0426%\n",
      "Epoch [143/300], Step [200/225], Training Accuracy: 98.6484%, Training Loss: 0.0427%\n",
      "Epoch [143/300], Step [201/225], Training Accuracy: 98.6552%, Training Loss: 0.0426%\n",
      "Epoch [143/300], Step [202/225], Training Accuracy: 98.6463%, Training Loss: 0.0427%\n",
      "Epoch [143/300], Step [203/225], Training Accuracy: 98.6453%, Training Loss: 0.0427%\n",
      "Epoch [143/300], Step [204/225], Training Accuracy: 98.6366%, Training Loss: 0.0427%\n",
      "Epoch [143/300], Step [205/225], Training Accuracy: 98.6357%, Training Loss: 0.0428%\n",
      "Epoch [143/300], Step [206/225], Training Accuracy: 98.6423%, Training Loss: 0.0427%\n",
      "Epoch [143/300], Step [207/225], Training Accuracy: 98.6413%, Training Loss: 0.0426%\n",
      "Epoch [143/300], Step [208/225], Training Accuracy: 98.6478%, Training Loss: 0.0425%\n",
      "Epoch [143/300], Step [209/225], Training Accuracy: 98.6543%, Training Loss: 0.0424%\n",
      "Epoch [143/300], Step [210/225], Training Accuracy: 98.6458%, Training Loss: 0.0426%\n",
      "Epoch [143/300], Step [211/225], Training Accuracy: 98.6523%, Training Loss: 0.0425%\n",
      "Epoch [143/300], Step [212/225], Training Accuracy: 98.6439%, Training Loss: 0.0426%\n",
      "Epoch [143/300], Step [213/225], Training Accuracy: 98.6502%, Training Loss: 0.0425%\n",
      "Epoch [143/300], Step [214/225], Training Accuracy: 98.6492%, Training Loss: 0.0426%\n",
      "Epoch [143/300], Step [215/225], Training Accuracy: 98.6410%, Training Loss: 0.0428%\n",
      "Epoch [143/300], Step [216/225], Training Accuracy: 98.6400%, Training Loss: 0.0428%\n",
      "Epoch [143/300], Step [217/225], Training Accuracy: 98.6319%, Training Loss: 0.0429%\n",
      "Epoch [143/300], Step [218/225], Training Accuracy: 98.6382%, Training Loss: 0.0429%\n",
      "Epoch [143/300], Step [219/225], Training Accuracy: 98.6444%, Training Loss: 0.0428%\n",
      "Epoch [143/300], Step [220/225], Training Accuracy: 98.6364%, Training Loss: 0.0429%\n",
      "Epoch [143/300], Step [221/225], Training Accuracy: 98.6355%, Training Loss: 0.0429%\n",
      "Epoch [143/300], Step [222/225], Training Accuracy: 98.6275%, Training Loss: 0.0430%\n",
      "Epoch [143/300], Step [223/225], Training Accuracy: 98.6337%, Training Loss: 0.0429%\n",
      "Epoch [143/300], Step [224/225], Training Accuracy: 98.6119%, Training Loss: 0.0432%\n",
      "Epoch [143/300], Step [225/225], Training Accuracy: 98.6034%, Training Loss: 0.0432%\n",
      "Epoch [144/300], Step [1/225], Training Accuracy: 96.8750%, Training Loss: 0.0712%\n",
      "Epoch [144/300], Step [2/225], Training Accuracy: 97.6562%, Training Loss: 0.0496%\n",
      "Epoch [144/300], Step [3/225], Training Accuracy: 98.4375%, Training Loss: 0.0483%\n",
      "Epoch [144/300], Step [4/225], Training Accuracy: 98.4375%, Training Loss: 0.0574%\n",
      "Epoch [144/300], Step [5/225], Training Accuracy: 98.4375%, Training Loss: 0.0543%\n",
      "Epoch [144/300], Step [6/225], Training Accuracy: 98.6979%, Training Loss: 0.0500%\n",
      "Epoch [144/300], Step [7/225], Training Accuracy: 98.4375%, Training Loss: 0.0512%\n",
      "Epoch [144/300], Step [8/225], Training Accuracy: 98.2422%, Training Loss: 0.0525%\n",
      "Epoch [144/300], Step [9/225], Training Accuracy: 98.4375%, Training Loss: 0.0487%\n",
      "Epoch [144/300], Step [10/225], Training Accuracy: 98.5938%, Training Loss: 0.0462%\n",
      "Epoch [144/300], Step [11/225], Training Accuracy: 98.7216%, Training Loss: 0.0440%\n",
      "Epoch [144/300], Step [12/225], Training Accuracy: 98.8281%, Training Loss: 0.0416%\n",
      "Epoch [144/300], Step [13/225], Training Accuracy: 98.6779%, Training Loss: 0.0447%\n",
      "Epoch [144/300], Step [14/225], Training Accuracy: 98.5491%, Training Loss: 0.0456%\n",
      "Epoch [144/300], Step [15/225], Training Accuracy: 98.6458%, Training Loss: 0.0434%\n",
      "Epoch [144/300], Step [16/225], Training Accuracy: 98.7305%, Training Loss: 0.0423%\n",
      "Epoch [144/300], Step [17/225], Training Accuracy: 98.8051%, Training Loss: 0.0417%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [144/300], Step [18/225], Training Accuracy: 98.6979%, Training Loss: 0.0432%\n",
      "Epoch [144/300], Step [19/225], Training Accuracy: 98.6842%, Training Loss: 0.0429%\n",
      "Epoch [144/300], Step [20/225], Training Accuracy: 98.6719%, Training Loss: 0.0443%\n",
      "Epoch [144/300], Step [21/225], Training Accuracy: 98.6607%, Training Loss: 0.0435%\n",
      "Epoch [144/300], Step [22/225], Training Accuracy: 98.6506%, Training Loss: 0.0439%\n",
      "Epoch [144/300], Step [23/225], Training Accuracy: 98.5734%, Training Loss: 0.0451%\n",
      "Epoch [144/300], Step [24/225], Training Accuracy: 98.5026%, Training Loss: 0.0461%\n",
      "Epoch [144/300], Step [25/225], Training Accuracy: 98.4375%, Training Loss: 0.0473%\n",
      "Epoch [144/300], Step [26/225], Training Accuracy: 98.4375%, Training Loss: 0.0478%\n",
      "Epoch [144/300], Step [27/225], Training Accuracy: 98.3218%, Training Loss: 0.0508%\n",
      "Epoch [144/300], Step [28/225], Training Accuracy: 98.3817%, Training Loss: 0.0498%\n",
      "Epoch [144/300], Step [29/225], Training Accuracy: 98.4375%, Training Loss: 0.0489%\n",
      "Epoch [144/300], Step [30/225], Training Accuracy: 98.4375%, Training Loss: 0.0482%\n",
      "Epoch [144/300], Step [31/225], Training Accuracy: 98.4375%, Training Loss: 0.0480%\n",
      "Epoch [144/300], Step [32/225], Training Accuracy: 98.3887%, Training Loss: 0.0487%\n",
      "Epoch [144/300], Step [33/225], Training Accuracy: 98.3902%, Training Loss: 0.0481%\n",
      "Epoch [144/300], Step [34/225], Training Accuracy: 98.3915%, Training Loss: 0.0490%\n",
      "Epoch [144/300], Step [35/225], Training Accuracy: 98.3482%, Training Loss: 0.0508%\n",
      "Epoch [144/300], Step [36/225], Training Accuracy: 98.3941%, Training Loss: 0.0501%\n",
      "Epoch [144/300], Step [37/225], Training Accuracy: 98.4375%, Training Loss: 0.0489%\n",
      "Epoch [144/300], Step [38/225], Training Accuracy: 98.4375%, Training Loss: 0.0490%\n",
      "Epoch [144/300], Step [39/225], Training Accuracy: 98.4776%, Training Loss: 0.0484%\n",
      "Epoch [144/300], Step [40/225], Training Accuracy: 98.4766%, Training Loss: 0.0486%\n",
      "Epoch [144/300], Step [41/225], Training Accuracy: 98.4375%, Training Loss: 0.0497%\n",
      "Epoch [144/300], Step [42/225], Training Accuracy: 98.4747%, Training Loss: 0.0489%\n",
      "Epoch [144/300], Step [43/225], Training Accuracy: 98.4375%, Training Loss: 0.0499%\n",
      "Epoch [144/300], Step [44/225], Training Accuracy: 98.4375%, Training Loss: 0.0496%\n",
      "Epoch [144/300], Step [45/225], Training Accuracy: 98.4375%, Training Loss: 0.0491%\n",
      "Epoch [144/300], Step [46/225], Training Accuracy: 98.4715%, Training Loss: 0.0485%\n",
      "Epoch [144/300], Step [47/225], Training Accuracy: 98.5040%, Training Loss: 0.0483%\n",
      "Epoch [144/300], Step [48/225], Training Accuracy: 98.5352%, Training Loss: 0.0478%\n",
      "Epoch [144/300], Step [49/225], Training Accuracy: 98.5332%, Training Loss: 0.0476%\n",
      "Epoch [144/300], Step [50/225], Training Accuracy: 98.5000%, Training Loss: 0.0476%\n",
      "Epoch [144/300], Step [51/225], Training Accuracy: 98.5294%, Training Loss: 0.0473%\n",
      "Epoch [144/300], Step [52/225], Training Accuracy: 98.5577%, Training Loss: 0.0466%\n",
      "Epoch [144/300], Step [53/225], Training Accuracy: 98.5259%, Training Loss: 0.0474%\n",
      "Epoch [144/300], Step [54/225], Training Accuracy: 98.5532%, Training Loss: 0.0472%\n",
      "Epoch [144/300], Step [55/225], Training Accuracy: 98.5795%, Training Loss: 0.0469%\n",
      "Epoch [144/300], Step [56/225], Training Accuracy: 98.5491%, Training Loss: 0.0482%\n",
      "Epoch [144/300], Step [57/225], Training Accuracy: 98.4923%, Training Loss: 0.0485%\n",
      "Epoch [144/300], Step [58/225], Training Accuracy: 98.5183%, Training Loss: 0.0483%\n",
      "Epoch [144/300], Step [59/225], Training Accuracy: 98.4905%, Training Loss: 0.0491%\n",
      "Epoch [144/300], Step [60/225], Training Accuracy: 98.4896%, Training Loss: 0.0490%\n",
      "Epoch [144/300], Step [61/225], Training Accuracy: 98.4887%, Training Loss: 0.0494%\n",
      "Epoch [144/300], Step [62/225], Training Accuracy: 98.4879%, Training Loss: 0.0491%\n",
      "Epoch [144/300], Step [63/225], Training Accuracy: 98.5119%, Training Loss: 0.0488%\n",
      "Epoch [144/300], Step [64/225], Training Accuracy: 98.4863%, Training Loss: 0.0491%\n",
      "Epoch [144/300], Step [65/225], Training Accuracy: 98.5096%, Training Loss: 0.0489%\n",
      "Epoch [144/300], Step [66/225], Training Accuracy: 98.5322%, Training Loss: 0.0484%\n",
      "Epoch [144/300], Step [67/225], Training Accuracy: 98.5308%, Training Loss: 0.0483%\n",
      "Epoch [144/300], Step [68/225], Training Accuracy: 98.5524%, Training Loss: 0.0478%\n",
      "Epoch [144/300], Step [69/225], Training Accuracy: 98.5507%, Training Loss: 0.0476%\n",
      "Epoch [144/300], Step [70/225], Training Accuracy: 98.5714%, Training Loss: 0.0472%\n",
      "Epoch [144/300], Step [71/225], Training Accuracy: 98.5475%, Training Loss: 0.0475%\n",
      "Epoch [144/300], Step [72/225], Training Accuracy: 98.5677%, Training Loss: 0.0472%\n",
      "Epoch [144/300], Step [73/225], Training Accuracy: 98.5659%, Training Loss: 0.0474%\n",
      "Epoch [144/300], Step [74/225], Training Accuracy: 98.5642%, Training Loss: 0.0473%\n",
      "Epoch [144/300], Step [75/225], Training Accuracy: 98.5833%, Training Loss: 0.0471%\n",
      "Epoch [144/300], Step [76/225], Training Accuracy: 98.5814%, Training Loss: 0.0471%\n",
      "Epoch [144/300], Step [77/225], Training Accuracy: 98.5593%, Training Loss: 0.0472%\n",
      "Epoch [144/300], Step [78/225], Training Accuracy: 98.5777%, Training Loss: 0.0471%\n",
      "Epoch [144/300], Step [79/225], Training Accuracy: 98.5957%, Training Loss: 0.0471%\n",
      "Epoch [144/300], Step [80/225], Training Accuracy: 98.6133%, Training Loss: 0.0467%\n",
      "Epoch [144/300], Step [81/225], Training Accuracy: 98.6111%, Training Loss: 0.0465%\n",
      "Epoch [144/300], Step [82/225], Training Accuracy: 98.6280%, Training Loss: 0.0462%\n",
      "Epoch [144/300], Step [83/225], Training Accuracy: 98.5881%, Training Loss: 0.0467%\n",
      "Epoch [144/300], Step [84/225], Training Accuracy: 98.5491%, Training Loss: 0.0474%\n",
      "Epoch [144/300], Step [85/225], Training Accuracy: 98.5294%, Training Loss: 0.0472%\n",
      "Epoch [144/300], Step [86/225], Training Accuracy: 98.5102%, Training Loss: 0.0478%\n",
      "Epoch [144/300], Step [87/225], Training Accuracy: 98.5093%, Training Loss: 0.0476%\n",
      "Epoch [144/300], Step [88/225], Training Accuracy: 98.5085%, Training Loss: 0.0475%\n",
      "Epoch [144/300], Step [89/225], Training Accuracy: 98.5253%, Training Loss: 0.0471%\n",
      "Epoch [144/300], Step [90/225], Training Accuracy: 98.5417%, Training Loss: 0.0468%\n",
      "Epoch [144/300], Step [91/225], Training Accuracy: 98.5577%, Training Loss: 0.0465%\n",
      "Epoch [144/300], Step [92/225], Training Accuracy: 98.5564%, Training Loss: 0.0464%\n",
      "Epoch [144/300], Step [93/225], Training Accuracy: 98.5719%, Training Loss: 0.0460%\n",
      "Epoch [144/300], Step [94/225], Training Accuracy: 98.5871%, Training Loss: 0.0456%\n",
      "Epoch [144/300], Step [95/225], Training Accuracy: 98.6020%, Training Loss: 0.0454%\n",
      "Epoch [144/300], Step [96/225], Training Accuracy: 98.5840%, Training Loss: 0.0455%\n",
      "Epoch [144/300], Step [97/225], Training Accuracy: 98.5825%, Training Loss: 0.0454%\n",
      "Epoch [144/300], Step [98/225], Training Accuracy: 98.5810%, Training Loss: 0.0453%\n",
      "Epoch [144/300], Step [99/225], Training Accuracy: 98.5795%, Training Loss: 0.0452%\n",
      "Epoch [144/300], Step [100/225], Training Accuracy: 98.5938%, Training Loss: 0.0451%\n",
      "Epoch [144/300], Step [101/225], Training Accuracy: 98.5767%, Training Loss: 0.0457%\n",
      "Epoch [144/300], Step [102/225], Training Accuracy: 98.5907%, Training Loss: 0.0454%\n",
      "Epoch [144/300], Step [103/225], Training Accuracy: 98.5892%, Training Loss: 0.0455%\n",
      "Epoch [144/300], Step [104/225], Training Accuracy: 98.5727%, Training Loss: 0.0455%\n",
      "Epoch [144/300], Step [105/225], Training Accuracy: 98.5565%, Training Loss: 0.0456%\n",
      "Epoch [144/300], Step [106/225], Training Accuracy: 98.5407%, Training Loss: 0.0457%\n",
      "Epoch [144/300], Step [107/225], Training Accuracy: 98.5397%, Training Loss: 0.0458%\n",
      "Epoch [144/300], Step [108/225], Training Accuracy: 98.5388%, Training Loss: 0.0457%\n",
      "Epoch [144/300], Step [109/225], Training Accuracy: 98.5522%, Training Loss: 0.0455%\n",
      "Epoch [144/300], Step [110/225], Training Accuracy: 98.5653%, Training Loss: 0.0453%\n",
      "Epoch [144/300], Step [111/225], Training Accuracy: 98.5642%, Training Loss: 0.0455%\n",
      "Epoch [144/300], Step [112/225], Training Accuracy: 98.5770%, Training Loss: 0.0452%\n",
      "Epoch [144/300], Step [113/225], Training Accuracy: 98.5758%, Training Loss: 0.0451%\n",
      "Epoch [144/300], Step [114/225], Training Accuracy: 98.5609%, Training Loss: 0.0457%\n",
      "Epoch [144/300], Step [115/225], Training Accuracy: 98.5734%, Training Loss: 0.0455%\n",
      "Epoch [144/300], Step [116/225], Training Accuracy: 98.5722%, Training Loss: 0.0455%\n",
      "Epoch [144/300], Step [117/225], Training Accuracy: 98.5710%, Training Loss: 0.0455%\n",
      "Epoch [144/300], Step [118/225], Training Accuracy: 98.5699%, Training Loss: 0.0455%\n",
      "Epoch [144/300], Step [119/225], Training Accuracy: 98.5819%, Training Loss: 0.0452%\n",
      "Epoch [144/300], Step [120/225], Training Accuracy: 98.5807%, Training Loss: 0.0452%\n",
      "Epoch [144/300], Step [121/225], Training Accuracy: 98.5795%, Training Loss: 0.0453%\n",
      "Epoch [144/300], Step [122/225], Training Accuracy: 98.5912%, Training Loss: 0.0451%\n",
      "Epoch [144/300], Step [123/225], Training Accuracy: 98.6026%, Training Loss: 0.0449%\n",
      "Epoch [144/300], Step [124/225], Training Accuracy: 98.5887%, Training Loss: 0.0451%\n",
      "Epoch [144/300], Step [125/225], Training Accuracy: 98.6000%, Training Loss: 0.0452%\n",
      "Epoch [144/300], Step [126/225], Training Accuracy: 98.6111%, Training Loss: 0.0450%\n",
      "Epoch [144/300], Step [127/225], Training Accuracy: 98.6097%, Training Loss: 0.0450%\n",
      "Epoch [144/300], Step [128/225], Training Accuracy: 98.6206%, Training Loss: 0.0449%\n",
      "Epoch [144/300], Step [129/225], Training Accuracy: 98.6313%, Training Loss: 0.0448%\n",
      "Epoch [144/300], Step [130/225], Training Accuracy: 98.6298%, Training Loss: 0.0448%\n",
      "Epoch [144/300], Step [131/225], Training Accuracy: 98.6403%, Training Loss: 0.0448%\n",
      "Epoch [144/300], Step [132/225], Training Accuracy: 98.6151%, Training Loss: 0.0451%\n",
      "Epoch [144/300], Step [133/225], Training Accuracy: 98.6137%, Training Loss: 0.0451%\n",
      "Epoch [144/300], Step [134/225], Training Accuracy: 98.6241%, Training Loss: 0.0449%\n",
      "Epoch [144/300], Step [135/225], Training Accuracy: 98.6343%, Training Loss: 0.0447%\n",
      "Epoch [144/300], Step [136/225], Training Accuracy: 98.6328%, Training Loss: 0.0450%\n",
      "Epoch [144/300], Step [137/225], Training Accuracy: 98.6314%, Training Loss: 0.0449%\n",
      "Epoch [144/300], Step [138/225], Training Accuracy: 98.6300%, Training Loss: 0.0449%\n",
      "Epoch [144/300], Step [139/225], Training Accuracy: 98.6398%, Training Loss: 0.0448%\n",
      "Epoch [144/300], Step [140/225], Training Accuracy: 98.6272%, Training Loss: 0.0451%\n",
      "Epoch [144/300], Step [141/225], Training Accuracy: 98.6148%, Training Loss: 0.0455%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [144/300], Step [142/225], Training Accuracy: 98.6026%, Training Loss: 0.0457%\n",
      "Epoch [144/300], Step [143/225], Training Accuracy: 98.5905%, Training Loss: 0.0459%\n",
      "Epoch [144/300], Step [144/225], Training Accuracy: 98.6003%, Training Loss: 0.0456%\n",
      "Epoch [144/300], Step [145/225], Training Accuracy: 98.5991%, Training Loss: 0.0458%\n",
      "Epoch [144/300], Step [146/225], Training Accuracy: 98.5873%, Training Loss: 0.0458%\n",
      "Epoch [144/300], Step [147/225], Training Accuracy: 98.5863%, Training Loss: 0.0457%\n",
      "Epoch [144/300], Step [148/225], Training Accuracy: 98.5959%, Training Loss: 0.0456%\n",
      "Epoch [144/300], Step [149/225], Training Accuracy: 98.5843%, Training Loss: 0.0460%\n",
      "Epoch [144/300], Step [150/225], Training Accuracy: 98.5833%, Training Loss: 0.0459%\n",
      "Epoch [144/300], Step [151/225], Training Accuracy: 98.5927%, Training Loss: 0.0458%\n",
      "Epoch [144/300], Step [152/225], Training Accuracy: 98.6020%, Training Loss: 0.0456%\n",
      "Epoch [144/300], Step [153/225], Training Accuracy: 98.6009%, Training Loss: 0.0458%\n",
      "Epoch [144/300], Step [154/225], Training Accuracy: 98.5795%, Training Loss: 0.0461%\n",
      "Epoch [144/300], Step [155/225], Training Accuracy: 98.5685%, Training Loss: 0.0461%\n",
      "Epoch [144/300], Step [156/225], Training Accuracy: 98.5677%, Training Loss: 0.0463%\n",
      "Epoch [144/300], Step [157/225], Training Accuracy: 98.5569%, Training Loss: 0.0465%\n",
      "Epoch [144/300], Step [158/225], Training Accuracy: 98.5463%, Training Loss: 0.0466%\n",
      "Epoch [144/300], Step [159/225], Training Accuracy: 98.5358%, Training Loss: 0.0466%\n",
      "Epoch [144/300], Step [160/225], Training Accuracy: 98.5352%, Training Loss: 0.0465%\n",
      "Epoch [144/300], Step [161/225], Training Accuracy: 98.5443%, Training Loss: 0.0462%\n",
      "Epoch [144/300], Step [162/225], Training Accuracy: 98.5340%, Training Loss: 0.0462%\n",
      "Epoch [144/300], Step [163/225], Training Accuracy: 98.5238%, Training Loss: 0.0463%\n",
      "Epoch [144/300], Step [164/225], Training Accuracy: 98.5232%, Training Loss: 0.0464%\n",
      "Epoch [144/300], Step [165/225], Training Accuracy: 98.5133%, Training Loss: 0.0466%\n",
      "Epoch [144/300], Step [166/225], Training Accuracy: 98.5034%, Training Loss: 0.0466%\n",
      "Epoch [144/300], Step [167/225], Training Accuracy: 98.4936%, Training Loss: 0.0467%\n",
      "Epoch [144/300], Step [168/225], Training Accuracy: 98.4933%, Training Loss: 0.0466%\n",
      "Epoch [144/300], Step [169/225], Training Accuracy: 98.4930%, Training Loss: 0.0466%\n",
      "Epoch [144/300], Step [170/225], Training Accuracy: 98.4835%, Training Loss: 0.0467%\n",
      "Epoch [144/300], Step [171/225], Training Accuracy: 98.4832%, Training Loss: 0.0466%\n",
      "Epoch [144/300], Step [172/225], Training Accuracy: 98.4648%, Training Loss: 0.0469%\n",
      "Epoch [144/300], Step [173/225], Training Accuracy: 98.4556%, Training Loss: 0.0470%\n",
      "Epoch [144/300], Step [174/225], Training Accuracy: 98.4555%, Training Loss: 0.0469%\n",
      "Epoch [144/300], Step [175/225], Training Accuracy: 98.4643%, Training Loss: 0.0467%\n",
      "Epoch [144/300], Step [176/225], Training Accuracy: 98.4553%, Training Loss: 0.0468%\n",
      "Epoch [144/300], Step [177/225], Training Accuracy: 98.4552%, Training Loss: 0.0469%\n",
      "Epoch [144/300], Step [178/225], Training Accuracy: 98.4551%, Training Loss: 0.0469%\n",
      "Epoch [144/300], Step [179/225], Training Accuracy: 98.4550%, Training Loss: 0.0469%\n",
      "Epoch [144/300], Step [180/225], Training Accuracy: 98.4549%, Training Loss: 0.0470%\n",
      "Epoch [144/300], Step [181/225], Training Accuracy: 98.4461%, Training Loss: 0.0471%\n",
      "Epoch [144/300], Step [182/225], Training Accuracy: 98.4461%, Training Loss: 0.0472%\n",
      "Epoch [144/300], Step [183/225], Training Accuracy: 98.4460%, Training Loss: 0.0471%\n",
      "Epoch [144/300], Step [184/225], Training Accuracy: 98.4545%, Training Loss: 0.0469%\n",
      "Epoch [144/300], Step [185/225], Training Accuracy: 98.4544%, Training Loss: 0.0468%\n",
      "Epoch [144/300], Step [186/225], Training Accuracy: 98.4543%, Training Loss: 0.0468%\n",
      "Epoch [144/300], Step [187/225], Training Accuracy: 98.4542%, Training Loss: 0.0467%\n",
      "Epoch [144/300], Step [188/225], Training Accuracy: 98.4541%, Training Loss: 0.0467%\n",
      "Epoch [144/300], Step [189/225], Training Accuracy: 98.4623%, Training Loss: 0.0466%\n",
      "Epoch [144/300], Step [190/225], Training Accuracy: 98.4704%, Training Loss: 0.0465%\n",
      "Epoch [144/300], Step [191/225], Training Accuracy: 98.4784%, Training Loss: 0.0464%\n",
      "Epoch [144/300], Step [192/225], Training Accuracy: 98.4782%, Training Loss: 0.0465%\n",
      "Epoch [144/300], Step [193/225], Training Accuracy: 98.4780%, Training Loss: 0.0465%\n",
      "Epoch [144/300], Step [194/225], Training Accuracy: 98.4858%, Training Loss: 0.0464%\n",
      "Epoch [144/300], Step [195/225], Training Accuracy: 98.4856%, Training Loss: 0.0464%\n",
      "Epoch [144/300], Step [196/225], Training Accuracy: 98.4853%, Training Loss: 0.0463%\n",
      "Epoch [144/300], Step [197/225], Training Accuracy: 98.4930%, Training Loss: 0.0462%\n",
      "Epoch [144/300], Step [198/225], Training Accuracy: 98.4770%, Training Loss: 0.0466%\n",
      "Epoch [144/300], Step [199/225], Training Accuracy: 98.4846%, Training Loss: 0.0465%\n",
      "Epoch [144/300], Step [200/225], Training Accuracy: 98.4922%, Training Loss: 0.0463%\n",
      "Epoch [144/300], Step [201/225], Training Accuracy: 98.4919%, Training Loss: 0.0463%\n",
      "Epoch [144/300], Step [202/225], Training Accuracy: 98.4916%, Training Loss: 0.0462%\n",
      "Epoch [144/300], Step [203/225], Training Accuracy: 98.4991%, Training Loss: 0.0462%\n",
      "Epoch [144/300], Step [204/225], Training Accuracy: 98.4988%, Training Loss: 0.0462%\n",
      "Epoch [144/300], Step [205/225], Training Accuracy: 98.5061%, Training Loss: 0.0461%\n",
      "Epoch [144/300], Step [206/225], Training Accuracy: 98.5133%, Training Loss: 0.0460%\n",
      "Epoch [144/300], Step [207/225], Training Accuracy: 98.5130%, Training Loss: 0.0460%\n",
      "Epoch [144/300], Step [208/225], Training Accuracy: 98.5201%, Training Loss: 0.0458%\n",
      "Epoch [144/300], Step [209/225], Training Accuracy: 98.5123%, Training Loss: 0.0458%\n",
      "Epoch [144/300], Step [210/225], Training Accuracy: 98.5119%, Training Loss: 0.0460%\n",
      "Epoch [144/300], Step [211/225], Training Accuracy: 98.5190%, Training Loss: 0.0459%\n",
      "Epoch [144/300], Step [212/225], Training Accuracy: 98.5259%, Training Loss: 0.0458%\n",
      "Epoch [144/300], Step [213/225], Training Accuracy: 98.5182%, Training Loss: 0.0460%\n",
      "Epoch [144/300], Step [214/225], Training Accuracy: 98.5032%, Training Loss: 0.0462%\n",
      "Epoch [144/300], Step [215/225], Training Accuracy: 98.5102%, Training Loss: 0.0460%\n",
      "Epoch [144/300], Step [216/225], Training Accuracy: 98.5171%, Training Loss: 0.0459%\n",
      "Epoch [144/300], Step [217/225], Training Accuracy: 98.5239%, Training Loss: 0.0459%\n",
      "Epoch [144/300], Step [218/225], Training Accuracy: 98.5235%, Training Loss: 0.0460%\n",
      "Epoch [144/300], Step [219/225], Training Accuracy: 98.5231%, Training Loss: 0.0460%\n",
      "Epoch [144/300], Step [220/225], Training Accuracy: 98.5227%, Training Loss: 0.0459%\n",
      "Epoch [144/300], Step [221/225], Training Accuracy: 98.5294%, Training Loss: 0.0458%\n",
      "Epoch [144/300], Step [222/225], Training Accuracy: 98.5360%, Training Loss: 0.0457%\n",
      "Epoch [144/300], Step [223/225], Training Accuracy: 98.5356%, Training Loss: 0.0457%\n",
      "Epoch [144/300], Step [224/225], Training Accuracy: 98.5421%, Training Loss: 0.0455%\n",
      "Epoch [144/300], Step [225/225], Training Accuracy: 98.5478%, Training Loss: 0.0454%\n",
      "Epoch [145/300], Step [1/225], Training Accuracy: 98.4375%, Training Loss: 0.0439%\n",
      "Epoch [145/300], Step [2/225], Training Accuracy: 99.2188%, Training Loss: 0.0325%\n",
      "Epoch [145/300], Step [3/225], Training Accuracy: 99.4792%, Training Loss: 0.0309%\n",
      "Epoch [145/300], Step [4/225], Training Accuracy: 99.6094%, Training Loss: 0.0310%\n",
      "Epoch [145/300], Step [5/225], Training Accuracy: 99.6875%, Training Loss: 0.0277%\n",
      "Epoch [145/300], Step [6/225], Training Accuracy: 98.9583%, Training Loss: 0.0415%\n",
      "Epoch [145/300], Step [7/225], Training Accuracy: 98.8839%, Training Loss: 0.0432%\n",
      "Epoch [145/300], Step [8/225], Training Accuracy: 99.0234%, Training Loss: 0.0393%\n",
      "Epoch [145/300], Step [9/225], Training Accuracy: 98.9583%, Training Loss: 0.0385%\n",
      "Epoch [145/300], Step [10/225], Training Accuracy: 98.9062%, Training Loss: 0.0365%\n",
      "Epoch [145/300], Step [11/225], Training Accuracy: 99.0057%, Training Loss: 0.0347%\n",
      "Epoch [145/300], Step [12/225], Training Accuracy: 98.9583%, Training Loss: 0.0366%\n",
      "Epoch [145/300], Step [13/225], Training Accuracy: 99.0385%, Training Loss: 0.0363%\n",
      "Epoch [145/300], Step [14/225], Training Accuracy: 98.9955%, Training Loss: 0.0360%\n",
      "Epoch [145/300], Step [15/225], Training Accuracy: 99.0625%, Training Loss: 0.0351%\n",
      "Epoch [145/300], Step [16/225], Training Accuracy: 99.0234%, Training Loss: 0.0358%\n",
      "Epoch [145/300], Step [17/225], Training Accuracy: 98.8971%, Training Loss: 0.0369%\n",
      "Epoch [145/300], Step [18/225], Training Accuracy: 98.7847%, Training Loss: 0.0380%\n",
      "Epoch [145/300], Step [19/225], Training Accuracy: 98.8487%, Training Loss: 0.0372%\n",
      "Epoch [145/300], Step [20/225], Training Accuracy: 98.8281%, Training Loss: 0.0369%\n",
      "Epoch [145/300], Step [21/225], Training Accuracy: 98.8839%, Training Loss: 0.0358%\n",
      "Epoch [145/300], Step [22/225], Training Accuracy: 98.7926%, Training Loss: 0.0390%\n",
      "Epoch [145/300], Step [23/225], Training Accuracy: 98.8451%, Training Loss: 0.0384%\n",
      "Epoch [145/300], Step [24/225], Training Accuracy: 98.8281%, Training Loss: 0.0384%\n",
      "Epoch [145/300], Step [25/225], Training Accuracy: 98.8125%, Training Loss: 0.0394%\n",
      "Epoch [145/300], Step [26/225], Training Accuracy: 98.8582%, Training Loss: 0.0390%\n",
      "Epoch [145/300], Step [27/225], Training Accuracy: 98.8426%, Training Loss: 0.0393%\n",
      "Epoch [145/300], Step [28/225], Training Accuracy: 98.8839%, Training Loss: 0.0384%\n",
      "Epoch [145/300], Step [29/225], Training Accuracy: 98.8685%, Training Loss: 0.0398%\n",
      "Epoch [145/300], Step [30/225], Training Accuracy: 98.9062%, Training Loss: 0.0397%\n",
      "Epoch [145/300], Step [31/225], Training Accuracy: 98.8407%, Training Loss: 0.0411%\n",
      "Epoch [145/300], Step [32/225], Training Accuracy: 98.8281%, Training Loss: 0.0408%\n",
      "Epoch [145/300], Step [33/225], Training Accuracy: 98.8636%, Training Loss: 0.0400%\n",
      "Epoch [145/300], Step [34/225], Training Accuracy: 98.8971%, Training Loss: 0.0399%\n",
      "Epoch [145/300], Step [35/225], Training Accuracy: 98.8839%, Training Loss: 0.0397%\n",
      "Epoch [145/300], Step [36/225], Training Accuracy: 98.9149%, Training Loss: 0.0395%\n",
      "Epoch [145/300], Step [37/225], Training Accuracy: 98.9443%, Training Loss: 0.0391%\n",
      "Epoch [145/300], Step [38/225], Training Accuracy: 98.9720%, Training Loss: 0.0390%\n",
      "Epoch [145/300], Step [39/225], Training Accuracy: 98.9183%, Training Loss: 0.0397%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [145/300], Step [40/225], Training Accuracy: 98.9062%, Training Loss: 0.0398%\n",
      "Epoch [145/300], Step [41/225], Training Accuracy: 98.8567%, Training Loss: 0.0404%\n",
      "Epoch [145/300], Step [42/225], Training Accuracy: 98.8839%, Training Loss: 0.0398%\n",
      "Epoch [145/300], Step [43/225], Training Accuracy: 98.8735%, Training Loss: 0.0402%\n",
      "Epoch [145/300], Step [44/225], Training Accuracy: 98.8636%, Training Loss: 0.0400%\n",
      "Epoch [145/300], Step [45/225], Training Accuracy: 98.8542%, Training Loss: 0.0398%\n",
      "Epoch [145/300], Step [46/225], Training Accuracy: 98.8451%, Training Loss: 0.0394%\n",
      "Epoch [145/300], Step [47/225], Training Accuracy: 98.8697%, Training Loss: 0.0391%\n",
      "Epoch [145/300], Step [48/225], Training Accuracy: 98.8932%, Training Loss: 0.0387%\n",
      "Epoch [145/300], Step [49/225], Training Accuracy: 98.8839%, Training Loss: 0.0384%\n",
      "Epoch [145/300], Step [50/225], Training Accuracy: 98.8750%, Training Loss: 0.0390%\n",
      "Epoch [145/300], Step [51/225], Training Accuracy: 98.8971%, Training Loss: 0.0386%\n",
      "Epoch [145/300], Step [52/225], Training Accuracy: 98.8882%, Training Loss: 0.0384%\n",
      "Epoch [145/300], Step [53/225], Training Accuracy: 98.9092%, Training Loss: 0.0381%\n",
      "Epoch [145/300], Step [54/225], Training Accuracy: 98.9294%, Training Loss: 0.0377%\n",
      "Epoch [145/300], Step [55/225], Training Accuracy: 98.8636%, Training Loss: 0.0384%\n",
      "Epoch [145/300], Step [56/225], Training Accuracy: 98.8839%, Training Loss: 0.0384%\n",
      "Epoch [145/300], Step [57/225], Training Accuracy: 98.8761%, Training Loss: 0.0383%\n",
      "Epoch [145/300], Step [58/225], Training Accuracy: 98.8955%, Training Loss: 0.0378%\n",
      "Epoch [145/300], Step [59/225], Training Accuracy: 98.9142%, Training Loss: 0.0375%\n",
      "Epoch [145/300], Step [60/225], Training Accuracy: 98.8802%, Training Loss: 0.0379%\n",
      "Epoch [145/300], Step [61/225], Training Accuracy: 98.8473%, Training Loss: 0.0384%\n",
      "Epoch [145/300], Step [62/225], Training Accuracy: 98.8155%, Training Loss: 0.0388%\n",
      "Epoch [145/300], Step [63/225], Training Accuracy: 98.8095%, Training Loss: 0.0388%\n",
      "Epoch [145/300], Step [64/225], Training Accuracy: 98.8037%, Training Loss: 0.0388%\n",
      "Epoch [145/300], Step [65/225], Training Accuracy: 98.7981%, Training Loss: 0.0387%\n",
      "Epoch [145/300], Step [66/225], Training Accuracy: 98.8163%, Training Loss: 0.0384%\n",
      "Epoch [145/300], Step [67/225], Training Accuracy: 98.8340%, Training Loss: 0.0381%\n",
      "Epoch [145/300], Step [68/225], Training Accuracy: 98.8511%, Training Loss: 0.0378%\n",
      "Epoch [145/300], Step [69/225], Training Accuracy: 98.8678%, Training Loss: 0.0376%\n",
      "Epoch [145/300], Step [70/225], Training Accuracy: 98.8616%, Training Loss: 0.0376%\n",
      "Epoch [145/300], Step [71/225], Training Accuracy: 98.8556%, Training Loss: 0.0381%\n",
      "Epoch [145/300], Step [72/225], Training Accuracy: 98.8715%, Training Loss: 0.0377%\n",
      "Epoch [145/300], Step [73/225], Training Accuracy: 98.8656%, Training Loss: 0.0378%\n",
      "Epoch [145/300], Step [74/225], Training Accuracy: 98.8387%, Training Loss: 0.0385%\n",
      "Epoch [145/300], Step [75/225], Training Accuracy: 98.8333%, Training Loss: 0.0388%\n",
      "Epoch [145/300], Step [76/225], Training Accuracy: 98.8487%, Training Loss: 0.0385%\n",
      "Epoch [145/300], Step [77/225], Training Accuracy: 98.8433%, Training Loss: 0.0384%\n",
      "Epoch [145/300], Step [78/225], Training Accuracy: 98.8381%, Training Loss: 0.0385%\n",
      "Epoch [145/300], Step [79/225], Training Accuracy: 98.8331%, Training Loss: 0.0384%\n",
      "Epoch [145/300], Step [80/225], Training Accuracy: 98.8477%, Training Loss: 0.0383%\n",
      "Epoch [145/300], Step [81/225], Training Accuracy: 98.8619%, Training Loss: 0.0380%\n",
      "Epoch [145/300], Step [82/225], Training Accuracy: 98.8758%, Training Loss: 0.0378%\n",
      "Epoch [145/300], Step [83/225], Training Accuracy: 98.8705%, Training Loss: 0.0378%\n",
      "Epoch [145/300], Step [84/225], Training Accuracy: 98.8467%, Training Loss: 0.0381%\n",
      "Epoch [145/300], Step [85/225], Training Accuracy: 98.8235%, Training Loss: 0.0381%\n",
      "Epoch [145/300], Step [86/225], Training Accuracy: 98.8190%, Training Loss: 0.0384%\n",
      "Epoch [145/300], Step [87/225], Training Accuracy: 98.7967%, Training Loss: 0.0385%\n",
      "Epoch [145/300], Step [88/225], Training Accuracy: 98.8104%, Training Loss: 0.0382%\n",
      "Epoch [145/300], Step [89/225], Training Accuracy: 98.8062%, Training Loss: 0.0384%\n",
      "Epoch [145/300], Step [90/225], Training Accuracy: 98.7847%, Training Loss: 0.0389%\n",
      "Epoch [145/300], Step [91/225], Training Accuracy: 98.7809%, Training Loss: 0.0388%\n",
      "Epoch [145/300], Step [92/225], Training Accuracy: 98.7942%, Training Loss: 0.0388%\n",
      "Epoch [145/300], Step [93/225], Training Accuracy: 98.8071%, Training Loss: 0.0386%\n",
      "Epoch [145/300], Step [94/225], Training Accuracy: 98.8198%, Training Loss: 0.0385%\n",
      "Epoch [145/300], Step [95/225], Training Accuracy: 98.8158%, Training Loss: 0.0386%\n",
      "Epoch [145/300], Step [96/225], Training Accuracy: 98.8118%, Training Loss: 0.0386%\n",
      "Epoch [145/300], Step [97/225], Training Accuracy: 98.7919%, Training Loss: 0.0390%\n",
      "Epoch [145/300], Step [98/225], Training Accuracy: 98.7883%, Training Loss: 0.0390%\n",
      "Epoch [145/300], Step [99/225], Training Accuracy: 98.7847%, Training Loss: 0.0390%\n",
      "Epoch [145/300], Step [100/225], Training Accuracy: 98.7812%, Training Loss: 0.0390%\n",
      "Epoch [145/300], Step [101/225], Training Accuracy: 98.7933%, Training Loss: 0.0388%\n",
      "Epoch [145/300], Step [102/225], Training Accuracy: 98.7745%, Training Loss: 0.0390%\n",
      "Epoch [145/300], Step [103/225], Training Accuracy: 98.7864%, Training Loss: 0.0388%\n",
      "Epoch [145/300], Step [104/225], Training Accuracy: 98.7680%, Training Loss: 0.0394%\n",
      "Epoch [145/300], Step [105/225], Training Accuracy: 98.7500%, Training Loss: 0.0397%\n",
      "Epoch [145/300], Step [106/225], Training Accuracy: 98.7618%, Training Loss: 0.0397%\n",
      "Epoch [145/300], Step [107/225], Training Accuracy: 98.7734%, Training Loss: 0.0395%\n",
      "Epoch [145/300], Step [108/225], Training Accuracy: 98.7558%, Training Loss: 0.0397%\n",
      "Epoch [145/300], Step [109/225], Training Accuracy: 98.7672%, Training Loss: 0.0396%\n",
      "Epoch [145/300], Step [110/225], Training Accuracy: 98.7784%, Training Loss: 0.0393%\n",
      "Epoch [145/300], Step [111/225], Training Accuracy: 98.7753%, Training Loss: 0.0394%\n",
      "Epoch [145/300], Step [112/225], Training Accuracy: 98.7444%, Training Loss: 0.0400%\n",
      "Epoch [145/300], Step [113/225], Training Accuracy: 98.7417%, Training Loss: 0.0399%\n",
      "Epoch [145/300], Step [114/225], Training Accuracy: 98.6979%, Training Loss: 0.0404%\n",
      "Epoch [145/300], Step [115/225], Training Accuracy: 98.6957%, Training Loss: 0.0404%\n",
      "Epoch [145/300], Step [116/225], Training Accuracy: 98.6934%, Training Loss: 0.0405%\n",
      "Epoch [145/300], Step [117/225], Training Accuracy: 98.6645%, Training Loss: 0.0408%\n",
      "Epoch [145/300], Step [118/225], Training Accuracy: 98.6494%, Training Loss: 0.0408%\n",
      "Epoch [145/300], Step [119/225], Training Accuracy: 98.6607%, Training Loss: 0.0408%\n",
      "Epoch [145/300], Step [120/225], Training Accuracy: 98.6719%, Training Loss: 0.0406%\n",
      "Epoch [145/300], Step [121/225], Training Accuracy: 98.6829%, Training Loss: 0.0404%\n",
      "Epoch [145/300], Step [122/225], Training Accuracy: 98.6808%, Training Loss: 0.0405%\n",
      "Epoch [145/300], Step [123/225], Training Accuracy: 98.6789%, Training Loss: 0.0409%\n",
      "Epoch [145/300], Step [124/225], Training Accuracy: 98.6895%, Training Loss: 0.0407%\n",
      "Epoch [145/300], Step [125/225], Training Accuracy: 98.6875%, Training Loss: 0.0413%\n",
      "Epoch [145/300], Step [126/225], Training Accuracy: 98.6855%, Training Loss: 0.0413%\n",
      "Epoch [145/300], Step [127/225], Training Accuracy: 98.6836%, Training Loss: 0.0413%\n",
      "Epoch [145/300], Step [128/225], Training Accuracy: 98.6938%, Training Loss: 0.0411%\n",
      "Epoch [145/300], Step [129/225], Training Accuracy: 98.7040%, Training Loss: 0.0411%\n",
      "Epoch [145/300], Step [130/225], Training Accuracy: 98.7139%, Training Loss: 0.0411%\n",
      "Epoch [145/300], Step [131/225], Training Accuracy: 98.7238%, Training Loss: 0.0409%\n",
      "Epoch [145/300], Step [132/225], Training Accuracy: 98.7334%, Training Loss: 0.0408%\n",
      "Epoch [145/300], Step [133/225], Training Accuracy: 98.7312%, Training Loss: 0.0409%\n",
      "Epoch [145/300], Step [134/225], Training Accuracy: 98.7407%, Training Loss: 0.0407%\n",
      "Epoch [145/300], Step [135/225], Training Accuracy: 98.7500%, Training Loss: 0.0405%\n",
      "Epoch [145/300], Step [136/225], Training Accuracy: 98.7132%, Training Loss: 0.0412%\n",
      "Epoch [145/300], Step [137/225], Training Accuracy: 98.7112%, Training Loss: 0.0414%\n",
      "Epoch [145/300], Step [138/225], Training Accuracy: 98.7206%, Training Loss: 0.0412%\n",
      "Epoch [145/300], Step [139/225], Training Accuracy: 98.7298%, Training Loss: 0.0411%\n",
      "Epoch [145/300], Step [140/225], Training Accuracy: 98.7388%, Training Loss: 0.0409%\n",
      "Epoch [145/300], Step [141/225], Training Accuracy: 98.7367%, Training Loss: 0.0410%\n",
      "Epoch [145/300], Step [142/225], Training Accuracy: 98.7346%, Training Loss: 0.0409%\n",
      "Epoch [145/300], Step [143/225], Training Accuracy: 98.7325%, Training Loss: 0.0410%\n",
      "Epoch [145/300], Step [144/225], Training Accuracy: 98.7088%, Training Loss: 0.0414%\n",
      "Epoch [145/300], Step [145/225], Training Accuracy: 98.7069%, Training Loss: 0.0413%\n",
      "Epoch [145/300], Step [146/225], Training Accuracy: 98.7158%, Training Loss: 0.0411%\n",
      "Epoch [145/300], Step [147/225], Training Accuracy: 98.7245%, Training Loss: 0.0410%\n",
      "Epoch [145/300], Step [148/225], Training Accuracy: 98.7120%, Training Loss: 0.0410%\n",
      "Epoch [145/300], Step [149/225], Training Accuracy: 98.7206%, Training Loss: 0.0408%\n",
      "Epoch [145/300], Step [150/225], Training Accuracy: 98.7188%, Training Loss: 0.0413%\n",
      "Epoch [145/300], Step [151/225], Training Accuracy: 98.7272%, Training Loss: 0.0411%\n",
      "Epoch [145/300], Step [152/225], Training Accuracy: 98.7356%, Training Loss: 0.0410%\n",
      "Epoch [145/300], Step [153/225], Training Accuracy: 98.7234%, Training Loss: 0.0412%\n",
      "Epoch [145/300], Step [154/225], Training Accuracy: 98.7216%, Training Loss: 0.0415%\n",
      "Epoch [145/300], Step [155/225], Training Accuracy: 98.7097%, Training Loss: 0.0416%\n",
      "Epoch [145/300], Step [156/225], Training Accuracy: 98.7179%, Training Loss: 0.0414%\n",
      "Epoch [145/300], Step [157/225], Training Accuracy: 98.7261%, Training Loss: 0.0413%\n",
      "Epoch [145/300], Step [158/225], Training Accuracy: 98.7342%, Training Loss: 0.0412%\n",
      "Epoch [145/300], Step [159/225], Training Accuracy: 98.7421%, Training Loss: 0.0410%\n",
      "Epoch [145/300], Step [160/225], Training Accuracy: 98.7500%, Training Loss: 0.0409%\n",
      "Epoch [145/300], Step [161/225], Training Accuracy: 98.7578%, Training Loss: 0.0407%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [145/300], Step [162/225], Training Accuracy: 98.7365%, Training Loss: 0.0411%\n",
      "Epoch [145/300], Step [163/225], Training Accuracy: 98.7347%, Training Loss: 0.0411%\n",
      "Epoch [145/300], Step [164/225], Training Accuracy: 98.7233%, Training Loss: 0.0415%\n",
      "Epoch [145/300], Step [165/225], Training Accuracy: 98.7311%, Training Loss: 0.0413%\n",
      "Epoch [145/300], Step [166/225], Training Accuracy: 98.7293%, Training Loss: 0.0413%\n",
      "Epoch [145/300], Step [167/225], Training Accuracy: 98.7369%, Training Loss: 0.0412%\n",
      "Epoch [145/300], Step [168/225], Training Accuracy: 98.7444%, Training Loss: 0.0411%\n",
      "Epoch [145/300], Step [169/225], Training Accuracy: 98.7426%, Training Loss: 0.0411%\n",
      "Epoch [145/300], Step [170/225], Training Accuracy: 98.7408%, Training Loss: 0.0413%\n",
      "Epoch [145/300], Step [171/225], Training Accuracy: 98.7390%, Training Loss: 0.0414%\n",
      "Epoch [145/300], Step [172/225], Training Accuracy: 98.7464%, Training Loss: 0.0412%\n",
      "Epoch [145/300], Step [173/225], Training Accuracy: 98.7446%, Training Loss: 0.0413%\n",
      "Epoch [145/300], Step [174/225], Training Accuracy: 98.7518%, Training Loss: 0.0411%\n",
      "Epoch [145/300], Step [175/225], Training Accuracy: 98.7500%, Training Loss: 0.0412%\n",
      "Epoch [145/300], Step [176/225], Training Accuracy: 98.7571%, Training Loss: 0.0412%\n",
      "Epoch [145/300], Step [177/225], Training Accuracy: 98.7465%, Training Loss: 0.0412%\n",
      "Epoch [145/300], Step [178/225], Training Accuracy: 98.7535%, Training Loss: 0.0411%\n",
      "Epoch [145/300], Step [179/225], Training Accuracy: 98.7430%, Training Loss: 0.0411%\n",
      "Epoch [145/300], Step [180/225], Training Accuracy: 98.7500%, Training Loss: 0.0411%\n",
      "Epoch [145/300], Step [181/225], Training Accuracy: 98.7569%, Training Loss: 0.0409%\n",
      "Epoch [145/300], Step [182/225], Training Accuracy: 98.7552%, Training Loss: 0.0411%\n",
      "Epoch [145/300], Step [183/225], Training Accuracy: 98.7534%, Training Loss: 0.0410%\n",
      "Epoch [145/300], Step [184/225], Training Accuracy: 98.7432%, Training Loss: 0.0411%\n",
      "Epoch [145/300], Step [185/225], Training Accuracy: 98.7500%, Training Loss: 0.0410%\n",
      "Epoch [145/300], Step [186/225], Training Accuracy: 98.7483%, Training Loss: 0.0410%\n",
      "Epoch [145/300], Step [187/225], Training Accuracy: 98.7467%, Training Loss: 0.0412%\n",
      "Epoch [145/300], Step [188/225], Training Accuracy: 98.7533%, Training Loss: 0.0411%\n",
      "Epoch [145/300], Step [189/225], Training Accuracy: 98.7599%, Training Loss: 0.0409%\n",
      "Epoch [145/300], Step [190/225], Training Accuracy: 98.7582%, Training Loss: 0.0409%\n",
      "Epoch [145/300], Step [191/225], Training Accuracy: 98.7647%, Training Loss: 0.0408%\n",
      "Epoch [145/300], Step [192/225], Training Accuracy: 98.7630%, Training Loss: 0.0410%\n",
      "Epoch [145/300], Step [193/225], Training Accuracy: 98.7694%, Training Loss: 0.0408%\n",
      "Epoch [145/300], Step [194/225], Training Accuracy: 98.7597%, Training Loss: 0.0411%\n",
      "Epoch [145/300], Step [195/225], Training Accuracy: 98.7660%, Training Loss: 0.0411%\n",
      "Epoch [145/300], Step [196/225], Training Accuracy: 98.7723%, Training Loss: 0.0410%\n",
      "Epoch [145/300], Step [197/225], Training Accuracy: 98.7786%, Training Loss: 0.0410%\n",
      "Epoch [145/300], Step [198/225], Training Accuracy: 98.7847%, Training Loss: 0.0408%\n",
      "Epoch [145/300], Step [199/225], Training Accuracy: 98.7751%, Training Loss: 0.0410%\n",
      "Epoch [145/300], Step [200/225], Training Accuracy: 98.7812%, Training Loss: 0.0409%\n",
      "Epoch [145/300], Step [201/225], Training Accuracy: 98.7718%, Training Loss: 0.0409%\n",
      "Epoch [145/300], Step [202/225], Training Accuracy: 98.7701%, Training Loss: 0.0411%\n",
      "Epoch [145/300], Step [203/225], Training Accuracy: 98.7685%, Training Loss: 0.0410%\n",
      "Epoch [145/300], Step [204/225], Training Accuracy: 98.7592%, Training Loss: 0.0410%\n",
      "Epoch [145/300], Step [205/225], Training Accuracy: 98.7652%, Training Loss: 0.0409%\n",
      "Epoch [145/300], Step [206/225], Training Accuracy: 98.7561%, Training Loss: 0.0412%\n",
      "Epoch [145/300], Step [207/225], Training Accuracy: 98.7545%, Training Loss: 0.0411%\n",
      "Epoch [145/300], Step [208/225], Training Accuracy: 98.7605%, Training Loss: 0.0409%\n",
      "Epoch [145/300], Step [209/225], Training Accuracy: 98.7590%, Training Loss: 0.0409%\n",
      "Epoch [145/300], Step [210/225], Training Accuracy: 98.7574%, Training Loss: 0.0410%\n",
      "Epoch [145/300], Step [211/225], Training Accuracy: 98.7633%, Training Loss: 0.0409%\n",
      "Epoch [145/300], Step [212/225], Training Accuracy: 98.7692%, Training Loss: 0.0408%\n",
      "Epoch [145/300], Step [213/225], Training Accuracy: 98.7749%, Training Loss: 0.0407%\n",
      "Epoch [145/300], Step [214/225], Training Accuracy: 98.7807%, Training Loss: 0.0406%\n",
      "Epoch [145/300], Step [215/225], Training Accuracy: 98.7791%, Training Loss: 0.0408%\n",
      "Epoch [145/300], Step [216/225], Training Accuracy: 98.7630%, Training Loss: 0.0413%\n",
      "Epoch [145/300], Step [217/225], Training Accuracy: 98.7687%, Training Loss: 0.0412%\n",
      "Epoch [145/300], Step [218/225], Training Accuracy: 98.7600%, Training Loss: 0.0412%\n",
      "Epoch [145/300], Step [219/225], Training Accuracy: 98.7657%, Training Loss: 0.0410%\n",
      "Epoch [145/300], Step [220/225], Training Accuracy: 98.7642%, Training Loss: 0.0411%\n",
      "Epoch [145/300], Step [221/225], Training Accuracy: 98.7698%, Training Loss: 0.0410%\n",
      "Epoch [145/300], Step [222/225], Training Accuracy: 98.7753%, Training Loss: 0.0409%\n",
      "Epoch [145/300], Step [223/225], Training Accuracy: 98.7668%, Training Loss: 0.0410%\n",
      "Epoch [145/300], Step [224/225], Training Accuracy: 98.7653%, Training Loss: 0.0410%\n",
      "Epoch [145/300], Step [225/225], Training Accuracy: 98.7632%, Training Loss: 0.0410%\n",
      "Epoch [146/300], Step [1/225], Training Accuracy: 96.8750%, Training Loss: 0.0993%\n",
      "Epoch [146/300], Step [2/225], Training Accuracy: 98.4375%, Training Loss: 0.0634%\n",
      "Epoch [146/300], Step [3/225], Training Accuracy: 98.4375%, Training Loss: 0.0601%\n",
      "Epoch [146/300], Step [4/225], Training Accuracy: 98.8281%, Training Loss: 0.0531%\n",
      "Epoch [146/300], Step [5/225], Training Accuracy: 98.4375%, Training Loss: 0.0597%\n",
      "Epoch [146/300], Step [6/225], Training Accuracy: 98.6979%, Training Loss: 0.0530%\n",
      "Epoch [146/300], Step [7/225], Training Accuracy: 98.8839%, Training Loss: 0.0526%\n",
      "Epoch [146/300], Step [8/225], Training Accuracy: 99.0234%, Training Loss: 0.0490%\n",
      "Epoch [146/300], Step [9/225], Training Accuracy: 99.1319%, Training Loss: 0.0463%\n",
      "Epoch [146/300], Step [10/225], Training Accuracy: 99.2188%, Training Loss: 0.0436%\n",
      "Epoch [146/300], Step [11/225], Training Accuracy: 99.2898%, Training Loss: 0.0410%\n",
      "Epoch [146/300], Step [12/225], Training Accuracy: 99.2188%, Training Loss: 0.0424%\n",
      "Epoch [146/300], Step [13/225], Training Accuracy: 99.2788%, Training Loss: 0.0403%\n",
      "Epoch [146/300], Step [14/225], Training Accuracy: 98.9955%, Training Loss: 0.0444%\n",
      "Epoch [146/300], Step [15/225], Training Accuracy: 98.8542%, Training Loss: 0.0444%\n",
      "Epoch [146/300], Step [16/225], Training Accuracy: 98.9258%, Training Loss: 0.0425%\n",
      "Epoch [146/300], Step [17/225], Training Accuracy: 98.9890%, Training Loss: 0.0415%\n",
      "Epoch [146/300], Step [18/225], Training Accuracy: 98.9583%, Training Loss: 0.0417%\n",
      "Epoch [146/300], Step [19/225], Training Accuracy: 98.9309%, Training Loss: 0.0416%\n",
      "Epoch [146/300], Step [20/225], Training Accuracy: 98.9844%, Training Loss: 0.0408%\n",
      "Epoch [146/300], Step [21/225], Training Accuracy: 99.0327%, Training Loss: 0.0402%\n",
      "Epoch [146/300], Step [22/225], Training Accuracy: 99.0057%, Training Loss: 0.0403%\n",
      "Epoch [146/300], Step [23/225], Training Accuracy: 99.0489%, Training Loss: 0.0400%\n",
      "Epoch [146/300], Step [24/225], Training Accuracy: 98.8932%, Training Loss: 0.0435%\n",
      "Epoch [146/300], Step [25/225], Training Accuracy: 98.8750%, Training Loss: 0.0441%\n",
      "Epoch [146/300], Step [26/225], Training Accuracy: 98.7380%, Training Loss: 0.0451%\n",
      "Epoch [146/300], Step [27/225], Training Accuracy: 98.6690%, Training Loss: 0.0457%\n",
      "Epoch [146/300], Step [28/225], Training Accuracy: 98.7165%, Training Loss: 0.0445%\n",
      "Epoch [146/300], Step [29/225], Training Accuracy: 98.7069%, Training Loss: 0.0441%\n",
      "Epoch [146/300], Step [30/225], Training Accuracy: 98.7500%, Training Loss: 0.0435%\n",
      "Epoch [146/300], Step [31/225], Training Accuracy: 98.6895%, Training Loss: 0.0443%\n",
      "Epoch [146/300], Step [32/225], Training Accuracy: 98.7305%, Training Loss: 0.0439%\n",
      "Epoch [146/300], Step [33/225], Training Accuracy: 98.7689%, Training Loss: 0.0433%\n",
      "Epoch [146/300], Step [34/225], Training Accuracy: 98.7132%, Training Loss: 0.0446%\n",
      "Epoch [146/300], Step [35/225], Training Accuracy: 98.6607%, Training Loss: 0.0453%\n",
      "Epoch [146/300], Step [36/225], Training Accuracy: 98.6979%, Training Loss: 0.0443%\n",
      "Epoch [146/300], Step [37/225], Training Accuracy: 98.6909%, Training Loss: 0.0440%\n",
      "Epoch [146/300], Step [38/225], Training Accuracy: 98.6431%, Training Loss: 0.0448%\n",
      "Epoch [146/300], Step [39/225], Training Accuracy: 98.6779%, Training Loss: 0.0445%\n",
      "Epoch [146/300], Step [40/225], Training Accuracy: 98.7109%, Training Loss: 0.0436%\n",
      "Epoch [146/300], Step [41/225], Training Accuracy: 98.7424%, Training Loss: 0.0435%\n",
      "Epoch [146/300], Step [42/225], Training Accuracy: 98.7351%, Training Loss: 0.0434%\n",
      "Epoch [146/300], Step [43/225], Training Accuracy: 98.7645%, Training Loss: 0.0430%\n",
      "Epoch [146/300], Step [44/225], Training Accuracy: 98.7571%, Training Loss: 0.0431%\n",
      "Epoch [146/300], Step [45/225], Training Accuracy: 98.7500%, Training Loss: 0.0433%\n",
      "Epoch [146/300], Step [46/225], Training Accuracy: 98.7772%, Training Loss: 0.0430%\n",
      "Epoch [146/300], Step [47/225], Training Accuracy: 98.7367%, Training Loss: 0.0438%\n",
      "Epoch [146/300], Step [48/225], Training Accuracy: 98.7305%, Training Loss: 0.0436%\n",
      "Epoch [146/300], Step [49/225], Training Accuracy: 98.6926%, Training Loss: 0.0441%\n",
      "Epoch [146/300], Step [50/225], Training Accuracy: 98.6250%, Training Loss: 0.0454%\n",
      "Epoch [146/300], Step [51/225], Training Accuracy: 98.6213%, Training Loss: 0.0452%\n",
      "Epoch [146/300], Step [52/225], Training Accuracy: 98.6478%, Training Loss: 0.0446%\n",
      "Epoch [146/300], Step [53/225], Training Accuracy: 98.6733%, Training Loss: 0.0441%\n",
      "Epoch [146/300], Step [54/225], Training Accuracy: 98.6979%, Training Loss: 0.0439%\n",
      "Epoch [146/300], Step [55/225], Training Accuracy: 98.7216%, Training Loss: 0.0435%\n",
      "Epoch [146/300], Step [56/225], Training Accuracy: 98.7165%, Training Loss: 0.0436%\n",
      "Epoch [146/300], Step [57/225], Training Accuracy: 98.7116%, Training Loss: 0.0437%\n",
      "Epoch [146/300], Step [58/225], Training Accuracy: 98.7069%, Training Loss: 0.0433%\n",
      "Epoch [146/300], Step [59/225], Training Accuracy: 98.6758%, Training Loss: 0.0438%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [146/300], Step [60/225], Training Accuracy: 98.6719%, Training Loss: 0.0435%\n",
      "Epoch [146/300], Step [61/225], Training Accuracy: 98.5912%, Training Loss: 0.0462%\n",
      "Epoch [146/300], Step [62/225], Training Accuracy: 98.5887%, Training Loss: 0.0459%\n",
      "Epoch [146/300], Step [63/225], Training Accuracy: 98.6111%, Training Loss: 0.0455%\n",
      "Epoch [146/300], Step [64/225], Training Accuracy: 98.6328%, Training Loss: 0.0452%\n",
      "Epoch [146/300], Step [65/225], Training Accuracy: 98.6538%, Training Loss: 0.0447%\n",
      "Epoch [146/300], Step [66/225], Training Accuracy: 98.6506%, Training Loss: 0.0451%\n",
      "Epoch [146/300], Step [67/225], Training Accuracy: 98.6707%, Training Loss: 0.0452%\n",
      "Epoch [146/300], Step [68/225], Training Accuracy: 98.6673%, Training Loss: 0.0454%\n",
      "Epoch [146/300], Step [69/225], Training Accuracy: 98.6639%, Training Loss: 0.0453%\n",
      "Epoch [146/300], Step [70/225], Training Accuracy: 98.6830%, Training Loss: 0.0450%\n",
      "Epoch [146/300], Step [71/225], Training Accuracy: 98.6796%, Training Loss: 0.0450%\n",
      "Epoch [146/300], Step [72/225], Training Accuracy: 98.6762%, Training Loss: 0.0450%\n",
      "Epoch [146/300], Step [73/225], Training Accuracy: 98.6943%, Training Loss: 0.0447%\n",
      "Epoch [146/300], Step [74/225], Training Accuracy: 98.6909%, Training Loss: 0.0448%\n",
      "Epoch [146/300], Step [75/225], Training Accuracy: 98.6875%, Training Loss: 0.0448%\n",
      "Epoch [146/300], Step [76/225], Training Accuracy: 98.6637%, Training Loss: 0.0450%\n",
      "Epoch [146/300], Step [77/225], Training Accuracy: 98.6607%, Training Loss: 0.0455%\n",
      "Epoch [146/300], Step [78/225], Training Accuracy: 98.6779%, Training Loss: 0.0451%\n",
      "Epoch [146/300], Step [79/225], Training Accuracy: 98.6551%, Training Loss: 0.0455%\n",
      "Epoch [146/300], Step [80/225], Training Accuracy: 98.6523%, Training Loss: 0.0454%\n",
      "Epoch [146/300], Step [81/225], Training Accuracy: 98.6690%, Training Loss: 0.0454%\n",
      "Epoch [146/300], Step [82/225], Training Accuracy: 98.6852%, Training Loss: 0.0452%\n",
      "Epoch [146/300], Step [83/225], Training Accuracy: 98.6822%, Training Loss: 0.0450%\n",
      "Epoch [146/300], Step [84/225], Training Accuracy: 98.6421%, Training Loss: 0.0451%\n",
      "Epoch [146/300], Step [85/225], Training Accuracy: 98.6581%, Training Loss: 0.0448%\n",
      "Epoch [146/300], Step [86/225], Training Accuracy: 98.6374%, Training Loss: 0.0455%\n",
      "Epoch [146/300], Step [87/225], Training Accuracy: 98.6171%, Training Loss: 0.0455%\n",
      "Epoch [146/300], Step [88/225], Training Accuracy: 98.5973%, Training Loss: 0.0458%\n",
      "Epoch [146/300], Step [89/225], Training Accuracy: 98.6131%, Training Loss: 0.0456%\n",
      "Epoch [146/300], Step [90/225], Training Accuracy: 98.6111%, Training Loss: 0.0457%\n",
      "Epoch [146/300], Step [91/225], Training Accuracy: 98.6264%, Training Loss: 0.0455%\n",
      "Epoch [146/300], Step [92/225], Training Accuracy: 98.6413%, Training Loss: 0.0452%\n",
      "Epoch [146/300], Step [93/225], Training Accuracy: 98.6391%, Training Loss: 0.0450%\n",
      "Epoch [146/300], Step [94/225], Training Accuracy: 98.6037%, Training Loss: 0.0456%\n",
      "Epoch [146/300], Step [95/225], Training Accuracy: 98.5691%, Training Loss: 0.0460%\n",
      "Epoch [146/300], Step [96/225], Training Accuracy: 98.5514%, Training Loss: 0.0463%\n",
      "Epoch [146/300], Step [97/225], Training Accuracy: 98.5664%, Training Loss: 0.0461%\n",
      "Epoch [146/300], Step [98/225], Training Accuracy: 98.5651%, Training Loss: 0.0465%\n",
      "Epoch [146/300], Step [99/225], Training Accuracy: 98.5795%, Training Loss: 0.0462%\n",
      "Epoch [146/300], Step [100/225], Training Accuracy: 98.5781%, Training Loss: 0.0460%\n",
      "Epoch [146/300], Step [101/225], Training Accuracy: 98.5922%, Training Loss: 0.0459%\n",
      "Epoch [146/300], Step [102/225], Training Accuracy: 98.6060%, Training Loss: 0.0456%\n",
      "Epoch [146/300], Step [103/225], Training Accuracy: 98.5892%, Training Loss: 0.0462%\n",
      "Epoch [146/300], Step [104/225], Training Accuracy: 98.5727%, Training Loss: 0.0464%\n",
      "Epoch [146/300], Step [105/225], Training Accuracy: 98.5863%, Training Loss: 0.0462%\n",
      "Epoch [146/300], Step [106/225], Training Accuracy: 98.5849%, Training Loss: 0.0461%\n",
      "Epoch [146/300], Step [107/225], Training Accuracy: 98.5981%, Training Loss: 0.0459%\n",
      "Epoch [146/300], Step [108/225], Training Accuracy: 98.5966%, Training Loss: 0.0458%\n",
      "Epoch [146/300], Step [109/225], Training Accuracy: 98.5952%, Training Loss: 0.0459%\n",
      "Epoch [146/300], Step [110/225], Training Accuracy: 98.5795%, Training Loss: 0.0460%\n",
      "Epoch [146/300], Step [111/225], Training Accuracy: 98.5783%, Training Loss: 0.0459%\n",
      "Epoch [146/300], Step [112/225], Training Accuracy: 98.5910%, Training Loss: 0.0458%\n",
      "Epoch [146/300], Step [113/225], Training Accuracy: 98.6034%, Training Loss: 0.0456%\n",
      "Epoch [146/300], Step [114/225], Training Accuracy: 98.6157%, Training Loss: 0.0453%\n",
      "Epoch [146/300], Step [115/225], Training Accuracy: 98.6277%, Training Loss: 0.0451%\n",
      "Epoch [146/300], Step [116/225], Training Accuracy: 98.6395%, Training Loss: 0.0450%\n",
      "Epoch [146/300], Step [117/225], Training Accuracy: 98.6512%, Training Loss: 0.0448%\n",
      "Epoch [146/300], Step [118/225], Training Accuracy: 98.6494%, Training Loss: 0.0449%\n",
      "Epoch [146/300], Step [119/225], Training Accuracy: 98.6607%, Training Loss: 0.0448%\n",
      "Epoch [146/300], Step [120/225], Training Accuracy: 98.6589%, Training Loss: 0.0448%\n",
      "Epoch [146/300], Step [121/225], Training Accuracy: 98.6699%, Training Loss: 0.0445%\n",
      "Epoch [146/300], Step [122/225], Training Accuracy: 98.6808%, Training Loss: 0.0443%\n",
      "Epoch [146/300], Step [123/225], Training Accuracy: 98.6916%, Training Loss: 0.0442%\n",
      "Epoch [146/300], Step [124/225], Training Accuracy: 98.7021%, Training Loss: 0.0439%\n",
      "Epoch [146/300], Step [125/225], Training Accuracy: 98.7000%, Training Loss: 0.0438%\n",
      "Epoch [146/300], Step [126/225], Training Accuracy: 98.6979%, Training Loss: 0.0437%\n",
      "Epoch [146/300], Step [127/225], Training Accuracy: 98.6959%, Training Loss: 0.0436%\n",
      "Epoch [146/300], Step [128/225], Training Accuracy: 98.6938%, Training Loss: 0.0438%\n",
      "Epoch [146/300], Step [129/225], Training Accuracy: 98.7040%, Training Loss: 0.0436%\n",
      "Epoch [146/300], Step [130/225], Training Accuracy: 98.7139%, Training Loss: 0.0434%\n",
      "Epoch [146/300], Step [131/225], Training Accuracy: 98.7238%, Training Loss: 0.0432%\n",
      "Epoch [146/300], Step [132/225], Training Accuracy: 98.7216%, Training Loss: 0.0433%\n",
      "Epoch [146/300], Step [133/225], Training Accuracy: 98.7312%, Training Loss: 0.0431%\n",
      "Epoch [146/300], Step [134/225], Training Accuracy: 98.7174%, Training Loss: 0.0432%\n",
      "Epoch [146/300], Step [135/225], Training Accuracy: 98.6806%, Training Loss: 0.0439%\n",
      "Epoch [146/300], Step [136/225], Training Accuracy: 98.6443%, Training Loss: 0.0444%\n",
      "Epoch [146/300], Step [137/225], Training Accuracy: 98.6428%, Training Loss: 0.0444%\n",
      "Epoch [146/300], Step [138/225], Training Accuracy: 98.6413%, Training Loss: 0.0443%\n",
      "Epoch [146/300], Step [139/225], Training Accuracy: 98.6398%, Training Loss: 0.0441%\n",
      "Epoch [146/300], Step [140/225], Training Accuracy: 98.6384%, Training Loss: 0.0441%\n",
      "Epoch [146/300], Step [141/225], Training Accuracy: 98.6370%, Training Loss: 0.0441%\n",
      "Epoch [146/300], Step [142/225], Training Accuracy: 98.6356%, Training Loss: 0.0441%\n",
      "Epoch [146/300], Step [143/225], Training Accuracy: 98.6342%, Training Loss: 0.0442%\n",
      "Epoch [146/300], Step [144/225], Training Accuracy: 98.6220%, Training Loss: 0.0443%\n",
      "Epoch [146/300], Step [145/225], Training Accuracy: 98.6315%, Training Loss: 0.0441%\n",
      "Epoch [146/300], Step [146/225], Training Accuracy: 98.6301%, Training Loss: 0.0440%\n",
      "Epoch [146/300], Step [147/225], Training Accuracy: 98.6288%, Training Loss: 0.0439%\n",
      "Epoch [146/300], Step [148/225], Training Accuracy: 98.5959%, Training Loss: 0.0443%\n",
      "Epoch [146/300], Step [149/225], Training Accuracy: 98.5633%, Training Loss: 0.0447%\n",
      "Epoch [146/300], Step [150/225], Training Accuracy: 98.5729%, Training Loss: 0.0445%\n",
      "Epoch [146/300], Step [151/225], Training Accuracy: 98.5720%, Training Loss: 0.0445%\n",
      "Epoch [146/300], Step [152/225], Training Accuracy: 98.5814%, Training Loss: 0.0443%\n",
      "Epoch [146/300], Step [153/225], Training Accuracy: 98.5907%, Training Loss: 0.0442%\n",
      "Epoch [146/300], Step [154/225], Training Accuracy: 98.5998%, Training Loss: 0.0441%\n",
      "Epoch [146/300], Step [155/225], Training Accuracy: 98.5988%, Training Loss: 0.0441%\n",
      "Epoch [146/300], Step [156/225], Training Accuracy: 98.5978%, Training Loss: 0.0441%\n",
      "Epoch [146/300], Step [157/225], Training Accuracy: 98.5967%, Training Loss: 0.0442%\n",
      "Epoch [146/300], Step [158/225], Training Accuracy: 98.6056%, Training Loss: 0.0441%\n",
      "Epoch [146/300], Step [159/225], Training Accuracy: 98.6144%, Training Loss: 0.0439%\n",
      "Epoch [146/300], Step [160/225], Training Accuracy: 98.6230%, Training Loss: 0.0437%\n",
      "Epoch [146/300], Step [161/225], Training Accuracy: 98.6316%, Training Loss: 0.0435%\n",
      "Epoch [146/300], Step [162/225], Training Accuracy: 98.6208%, Training Loss: 0.0437%\n",
      "Epoch [146/300], Step [163/225], Training Accuracy: 98.6292%, Training Loss: 0.0436%\n",
      "Epoch [146/300], Step [164/225], Training Accuracy: 98.6280%, Training Loss: 0.0436%\n",
      "Epoch [146/300], Step [165/225], Training Accuracy: 98.6269%, Training Loss: 0.0436%\n",
      "Epoch [146/300], Step [166/225], Training Accuracy: 98.6352%, Training Loss: 0.0435%\n",
      "Epoch [146/300], Step [167/225], Training Accuracy: 98.6340%, Training Loss: 0.0435%\n",
      "Epoch [146/300], Step [168/225], Training Accuracy: 98.6328%, Training Loss: 0.0435%\n",
      "Epoch [146/300], Step [169/225], Training Accuracy: 98.6317%, Training Loss: 0.0434%\n",
      "Epoch [146/300], Step [170/225], Training Accuracy: 98.6305%, Training Loss: 0.0436%\n",
      "Epoch [146/300], Step [171/225], Training Accuracy: 98.6294%, Training Loss: 0.0435%\n",
      "Epoch [146/300], Step [172/225], Training Accuracy: 98.6374%, Training Loss: 0.0434%\n",
      "Epoch [146/300], Step [173/225], Training Accuracy: 98.6452%, Training Loss: 0.0432%\n",
      "Epoch [146/300], Step [174/225], Training Accuracy: 98.6530%, Training Loss: 0.0430%\n",
      "Epoch [146/300], Step [175/225], Training Accuracy: 98.6518%, Training Loss: 0.0430%\n",
      "Epoch [146/300], Step [176/225], Training Accuracy: 98.6594%, Training Loss: 0.0428%\n",
      "Epoch [146/300], Step [177/225], Training Accuracy: 98.6582%, Training Loss: 0.0427%\n",
      "Epoch [146/300], Step [178/225], Training Accuracy: 98.6657%, Training Loss: 0.0427%\n",
      "Epoch [146/300], Step [179/225], Training Accuracy: 98.6470%, Training Loss: 0.0429%\n",
      "Epoch [146/300], Step [180/225], Training Accuracy: 98.6458%, Training Loss: 0.0429%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [146/300], Step [181/225], Training Accuracy: 98.6533%, Training Loss: 0.0428%\n",
      "Epoch [146/300], Step [182/225], Training Accuracy: 98.6435%, Training Loss: 0.0430%\n",
      "Epoch [146/300], Step [183/225], Training Accuracy: 98.6424%, Training Loss: 0.0429%\n",
      "Epoch [146/300], Step [184/225], Training Accuracy: 98.6413%, Training Loss: 0.0430%\n",
      "Epoch [146/300], Step [185/225], Training Accuracy: 98.6402%, Training Loss: 0.0431%\n",
      "Epoch [146/300], Step [186/225], Training Accuracy: 98.6475%, Training Loss: 0.0431%\n",
      "Epoch [146/300], Step [187/225], Training Accuracy: 98.6464%, Training Loss: 0.0431%\n",
      "Epoch [146/300], Step [188/225], Training Accuracy: 98.6536%, Training Loss: 0.0430%\n",
      "Epoch [146/300], Step [189/225], Training Accuracy: 98.6524%, Training Loss: 0.0430%\n",
      "Epoch [146/300], Step [190/225], Training Accuracy: 98.6431%, Training Loss: 0.0430%\n",
      "Epoch [146/300], Step [191/225], Training Accuracy: 98.6502%, Training Loss: 0.0430%\n",
      "Epoch [146/300], Step [192/225], Training Accuracy: 98.6491%, Training Loss: 0.0429%\n",
      "Epoch [146/300], Step [193/225], Training Accuracy: 98.6480%, Training Loss: 0.0429%\n",
      "Epoch [146/300], Step [194/225], Training Accuracy: 98.6550%, Training Loss: 0.0428%\n",
      "Epoch [146/300], Step [195/225], Training Accuracy: 98.6619%, Training Loss: 0.0427%\n",
      "Epoch [146/300], Step [196/225], Training Accuracy: 98.6687%, Training Loss: 0.0426%\n",
      "Epoch [146/300], Step [197/225], Training Accuracy: 98.6675%, Training Loss: 0.0425%\n",
      "Epoch [146/300], Step [198/225], Training Accuracy: 98.6742%, Training Loss: 0.0425%\n",
      "Epoch [146/300], Step [199/225], Training Accuracy: 98.6652%, Training Loss: 0.0426%\n",
      "Epoch [146/300], Step [200/225], Training Accuracy: 98.6719%, Training Loss: 0.0425%\n",
      "Epoch [146/300], Step [201/225], Training Accuracy: 98.6707%, Training Loss: 0.0425%\n",
      "Epoch [146/300], Step [202/225], Training Accuracy: 98.6618%, Training Loss: 0.0426%\n",
      "Epoch [146/300], Step [203/225], Training Accuracy: 98.6684%, Training Loss: 0.0424%\n",
      "Epoch [146/300], Step [204/225], Training Accuracy: 98.6749%, Training Loss: 0.0423%\n",
      "Epoch [146/300], Step [205/225], Training Accuracy: 98.6814%, Training Loss: 0.0421%\n",
      "Epoch [146/300], Step [206/225], Training Accuracy: 98.6878%, Training Loss: 0.0420%\n",
      "Epoch [146/300], Step [207/225], Training Accuracy: 98.6866%, Training Loss: 0.0421%\n",
      "Epoch [146/300], Step [208/225], Training Accuracy: 98.6929%, Training Loss: 0.0420%\n",
      "Epoch [146/300], Step [209/225], Training Accuracy: 98.6917%, Training Loss: 0.0420%\n",
      "Epoch [146/300], Step [210/225], Training Accuracy: 98.6979%, Training Loss: 0.0418%\n",
      "Epoch [146/300], Step [211/225], Training Accuracy: 98.6893%, Training Loss: 0.0422%\n",
      "Epoch [146/300], Step [212/225], Training Accuracy: 98.6807%, Training Loss: 0.0423%\n",
      "Epoch [146/300], Step [213/225], Training Accuracy: 98.6869%, Training Loss: 0.0422%\n",
      "Epoch [146/300], Step [214/225], Training Accuracy: 98.6857%, Training Loss: 0.0423%\n",
      "Epoch [146/300], Step [215/225], Training Accuracy: 98.6919%, Training Loss: 0.0422%\n",
      "Epoch [146/300], Step [216/225], Training Accuracy: 98.6762%, Training Loss: 0.0424%\n",
      "Epoch [146/300], Step [217/225], Training Accuracy: 98.6823%, Training Loss: 0.0424%\n",
      "Epoch [146/300], Step [218/225], Training Accuracy: 98.6812%, Training Loss: 0.0423%\n",
      "Epoch [146/300], Step [219/225], Training Accuracy: 98.6872%, Training Loss: 0.0422%\n",
      "Epoch [146/300], Step [220/225], Training Accuracy: 98.6861%, Training Loss: 0.0422%\n",
      "Epoch [146/300], Step [221/225], Training Accuracy: 98.6920%, Training Loss: 0.0421%\n",
      "Epoch [146/300], Step [222/225], Training Accuracy: 98.6979%, Training Loss: 0.0420%\n",
      "Epoch [146/300], Step [223/225], Training Accuracy: 98.7038%, Training Loss: 0.0419%\n",
      "Epoch [146/300], Step [224/225], Training Accuracy: 98.7026%, Training Loss: 0.0419%\n",
      "Epoch [146/300], Step [225/225], Training Accuracy: 98.7007%, Training Loss: 0.0418%\n",
      "Epoch [147/300], Step [1/225], Training Accuracy: 100.0000%, Training Loss: 0.0403%\n",
      "Epoch [147/300], Step [2/225], Training Accuracy: 100.0000%, Training Loss: 0.0408%\n",
      "Epoch [147/300], Step [3/225], Training Accuracy: 100.0000%, Training Loss: 0.0346%\n",
      "Epoch [147/300], Step [4/225], Training Accuracy: 100.0000%, Training Loss: 0.0285%\n",
      "Epoch [147/300], Step [5/225], Training Accuracy: 98.7500%, Training Loss: 0.0413%\n",
      "Epoch [147/300], Step [6/225], Training Accuracy: 98.6979%, Training Loss: 0.0414%\n",
      "Epoch [147/300], Step [7/225], Training Accuracy: 98.4375%, Training Loss: 0.0544%\n",
      "Epoch [147/300], Step [8/225], Training Accuracy: 98.4375%, Training Loss: 0.0532%\n",
      "Epoch [147/300], Step [9/225], Training Accuracy: 98.4375%, Training Loss: 0.0536%\n",
      "Epoch [147/300], Step [10/225], Training Accuracy: 98.4375%, Training Loss: 0.0522%\n",
      "Epoch [147/300], Step [11/225], Training Accuracy: 98.5795%, Training Loss: 0.0492%\n",
      "Epoch [147/300], Step [12/225], Training Accuracy: 98.5677%, Training Loss: 0.0484%\n",
      "Epoch [147/300], Step [13/225], Training Accuracy: 98.6779%, Training Loss: 0.0455%\n",
      "Epoch [147/300], Step [14/225], Training Accuracy: 98.6607%, Training Loss: 0.0473%\n",
      "Epoch [147/300], Step [15/225], Training Accuracy: 98.5417%, Training Loss: 0.0475%\n",
      "Epoch [147/300], Step [16/225], Training Accuracy: 98.6328%, Training Loss: 0.0466%\n",
      "Epoch [147/300], Step [17/225], Training Accuracy: 98.5294%, Training Loss: 0.0480%\n",
      "Epoch [147/300], Step [18/225], Training Accuracy: 98.5243%, Training Loss: 0.0478%\n",
      "Epoch [147/300], Step [19/225], Training Accuracy: 98.6020%, Training Loss: 0.0472%\n",
      "Epoch [147/300], Step [20/225], Training Accuracy: 98.5156%, Training Loss: 0.0486%\n",
      "Epoch [147/300], Step [21/225], Training Accuracy: 98.5863%, Training Loss: 0.0473%\n",
      "Epoch [147/300], Step [22/225], Training Accuracy: 98.6506%, Training Loss: 0.0458%\n",
      "Epoch [147/300], Step [23/225], Training Accuracy: 98.7092%, Training Loss: 0.0443%\n",
      "Epoch [147/300], Step [24/225], Training Accuracy: 98.6328%, Training Loss: 0.0459%\n",
      "Epoch [147/300], Step [25/225], Training Accuracy: 98.5625%, Training Loss: 0.0470%\n",
      "Epoch [147/300], Step [26/225], Training Accuracy: 98.4976%, Training Loss: 0.0491%\n",
      "Epoch [147/300], Step [27/225], Training Accuracy: 98.4375%, Training Loss: 0.0500%\n",
      "Epoch [147/300], Step [28/225], Training Accuracy: 98.3817%, Training Loss: 0.0503%\n",
      "Epoch [147/300], Step [29/225], Training Accuracy: 98.2220%, Training Loss: 0.0528%\n",
      "Epoch [147/300], Step [30/225], Training Accuracy: 98.2292%, Training Loss: 0.0521%\n",
      "Epoch [147/300], Step [31/225], Training Accuracy: 98.1855%, Training Loss: 0.0537%\n",
      "Epoch [147/300], Step [32/225], Training Accuracy: 98.2422%, Training Loss: 0.0526%\n",
      "Epoch [147/300], Step [33/225], Training Accuracy: 98.2481%, Training Loss: 0.0526%\n",
      "Epoch [147/300], Step [34/225], Training Accuracy: 98.1618%, Training Loss: 0.0532%\n",
      "Epoch [147/300], Step [35/225], Training Accuracy: 98.2143%, Training Loss: 0.0525%\n",
      "Epoch [147/300], Step [36/225], Training Accuracy: 98.1771%, Training Loss: 0.0528%\n",
      "Epoch [147/300], Step [37/225], Training Accuracy: 98.1841%, Training Loss: 0.0522%\n",
      "Epoch [147/300], Step [38/225], Training Accuracy: 98.1908%, Training Loss: 0.0518%\n",
      "Epoch [147/300], Step [39/225], Training Accuracy: 98.1971%, Training Loss: 0.0517%\n",
      "Epoch [147/300], Step [40/225], Training Accuracy: 98.2422%, Training Loss: 0.0511%\n",
      "Epoch [147/300], Step [41/225], Training Accuracy: 98.2851%, Training Loss: 0.0506%\n",
      "Epoch [147/300], Step [42/225], Training Accuracy: 98.3259%, Training Loss: 0.0501%\n",
      "Epoch [147/300], Step [43/225], Training Accuracy: 98.3648%, Training Loss: 0.0492%\n",
      "Epoch [147/300], Step [44/225], Training Accuracy: 98.3665%, Training Loss: 0.0487%\n",
      "Epoch [147/300], Step [45/225], Training Accuracy: 98.4028%, Training Loss: 0.0482%\n",
      "Epoch [147/300], Step [46/225], Training Accuracy: 98.3356%, Training Loss: 0.0487%\n",
      "Epoch [147/300], Step [47/225], Training Accuracy: 98.3045%, Training Loss: 0.0488%\n",
      "Epoch [147/300], Step [48/225], Training Accuracy: 98.3398%, Training Loss: 0.0482%\n",
      "Epoch [147/300], Step [49/225], Training Accuracy: 98.3418%, Training Loss: 0.0489%\n",
      "Epoch [147/300], Step [50/225], Training Accuracy: 98.3750%, Training Loss: 0.0483%\n",
      "Epoch [147/300], Step [51/225], Training Accuracy: 98.3762%, Training Loss: 0.0486%\n",
      "Epoch [147/300], Step [52/225], Training Accuracy: 98.3774%, Training Loss: 0.0488%\n",
      "Epoch [147/300], Step [53/225], Training Accuracy: 98.3491%, Training Loss: 0.0495%\n",
      "Epoch [147/300], Step [54/225], Training Accuracy: 98.2639%, Training Loss: 0.0503%\n",
      "Epoch [147/300], Step [55/225], Training Accuracy: 98.2955%, Training Loss: 0.0498%\n",
      "Epoch [147/300], Step [56/225], Training Accuracy: 98.2701%, Training Loss: 0.0503%\n",
      "Epoch [147/300], Step [57/225], Training Accuracy: 98.3004%, Training Loss: 0.0500%\n",
      "Epoch [147/300], Step [58/225], Training Accuracy: 98.3028%, Training Loss: 0.0495%\n",
      "Epoch [147/300], Step [59/225], Training Accuracy: 98.3051%, Training Loss: 0.0494%\n",
      "Epoch [147/300], Step [60/225], Training Accuracy: 98.3333%, Training Loss: 0.0490%\n",
      "Epoch [147/300], Step [61/225], Training Accuracy: 98.3350%, Training Loss: 0.0486%\n",
      "Epoch [147/300], Step [62/225], Training Accuracy: 98.3619%, Training Loss: 0.0480%\n",
      "Epoch [147/300], Step [63/225], Training Accuracy: 98.3879%, Training Loss: 0.0479%\n",
      "Epoch [147/300], Step [64/225], Training Accuracy: 98.3887%, Training Loss: 0.0475%\n",
      "Epoch [147/300], Step [65/225], Training Accuracy: 98.4135%, Training Loss: 0.0471%\n",
      "Epoch [147/300], Step [66/225], Training Accuracy: 98.4375%, Training Loss: 0.0466%\n",
      "Epoch [147/300], Step [67/225], Training Accuracy: 98.4142%, Training Loss: 0.0467%\n",
      "Epoch [147/300], Step [68/225], Training Accuracy: 98.4375%, Training Loss: 0.0463%\n",
      "Epoch [147/300], Step [69/225], Training Accuracy: 98.4375%, Training Loss: 0.0462%\n",
      "Epoch [147/300], Step [70/225], Training Accuracy: 98.4152%, Training Loss: 0.0463%\n",
      "Epoch [147/300], Step [71/225], Training Accuracy: 98.4375%, Training Loss: 0.0461%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [147/300], Step [72/225], Training Accuracy: 98.4592%, Training Loss: 0.0458%\n",
      "Epoch [147/300], Step [73/225], Training Accuracy: 98.4589%, Training Loss: 0.0457%\n",
      "Epoch [147/300], Step [74/225], Training Accuracy: 98.4797%, Training Loss: 0.0453%\n",
      "Epoch [147/300], Step [75/225], Training Accuracy: 98.5000%, Training Loss: 0.0450%\n",
      "Epoch [147/300], Step [76/225], Training Accuracy: 98.5197%, Training Loss: 0.0447%\n",
      "Epoch [147/300], Step [77/225], Training Accuracy: 98.5187%, Training Loss: 0.0446%\n",
      "Epoch [147/300], Step [78/225], Training Accuracy: 98.5377%, Training Loss: 0.0444%\n",
      "Epoch [147/300], Step [79/225], Training Accuracy: 98.5562%, Training Loss: 0.0440%\n",
      "Epoch [147/300], Step [80/225], Training Accuracy: 98.5352%, Training Loss: 0.0446%\n",
      "Epoch [147/300], Step [81/225], Training Accuracy: 98.5532%, Training Loss: 0.0443%\n",
      "Epoch [147/300], Step [82/225], Training Accuracy: 98.5518%, Training Loss: 0.0444%\n",
      "Epoch [147/300], Step [83/225], Training Accuracy: 98.5693%, Training Loss: 0.0442%\n",
      "Epoch [147/300], Step [84/225], Training Accuracy: 98.5863%, Training Loss: 0.0440%\n",
      "Epoch [147/300], Step [85/225], Training Accuracy: 98.5662%, Training Loss: 0.0442%\n",
      "Epoch [147/300], Step [86/225], Training Accuracy: 98.5647%, Training Loss: 0.0445%\n",
      "Epoch [147/300], Step [87/225], Training Accuracy: 98.5632%, Training Loss: 0.0448%\n",
      "Epoch [147/300], Step [88/225], Training Accuracy: 98.5263%, Training Loss: 0.0451%\n",
      "Epoch [147/300], Step [89/225], Training Accuracy: 98.5077%, Training Loss: 0.0455%\n",
      "Epoch [147/300], Step [90/225], Training Accuracy: 98.4896%, Training Loss: 0.0458%\n",
      "Epoch [147/300], Step [91/225], Training Accuracy: 98.4890%, Training Loss: 0.0457%\n",
      "Epoch [147/300], Step [92/225], Training Accuracy: 98.5054%, Training Loss: 0.0455%\n",
      "Epoch [147/300], Step [93/225], Training Accuracy: 98.5215%, Training Loss: 0.0452%\n",
      "Epoch [147/300], Step [94/225], Training Accuracy: 98.5372%, Training Loss: 0.0451%\n",
      "Epoch [147/300], Step [95/225], Training Accuracy: 98.5197%, Training Loss: 0.0452%\n",
      "Epoch [147/300], Step [96/225], Training Accuracy: 98.5352%, Training Loss: 0.0450%\n",
      "Epoch [147/300], Step [97/225], Training Accuracy: 98.5503%, Training Loss: 0.0448%\n",
      "Epoch [147/300], Step [98/225], Training Accuracy: 98.5491%, Training Loss: 0.0449%\n",
      "Epoch [147/300], Step [99/225], Training Accuracy: 98.5480%, Training Loss: 0.0448%\n",
      "Epoch [147/300], Step [100/225], Training Accuracy: 98.5469%, Training Loss: 0.0448%\n",
      "Epoch [147/300], Step [101/225], Training Accuracy: 98.5458%, Training Loss: 0.0447%\n",
      "Epoch [147/300], Step [102/225], Training Accuracy: 98.5447%, Training Loss: 0.0446%\n",
      "Epoch [147/300], Step [103/225], Training Accuracy: 98.5285%, Training Loss: 0.0448%\n",
      "Epoch [147/300], Step [104/225], Training Accuracy: 98.5126%, Training Loss: 0.0449%\n",
      "Epoch [147/300], Step [105/225], Training Accuracy: 98.5119%, Training Loss: 0.0448%\n",
      "Epoch [147/300], Step [106/225], Training Accuracy: 98.5112%, Training Loss: 0.0450%\n",
      "Epoch [147/300], Step [107/225], Training Accuracy: 98.5251%, Training Loss: 0.0448%\n",
      "Epoch [147/300], Step [108/225], Training Accuracy: 98.5098%, Training Loss: 0.0451%\n",
      "Epoch [147/300], Step [109/225], Training Accuracy: 98.5092%, Training Loss: 0.0451%\n",
      "Epoch [147/300], Step [110/225], Training Accuracy: 98.5227%, Training Loss: 0.0449%\n",
      "Epoch [147/300], Step [111/225], Training Accuracy: 98.5360%, Training Loss: 0.0448%\n",
      "Epoch [147/300], Step [112/225], Training Accuracy: 98.4933%, Training Loss: 0.0454%\n",
      "Epoch [147/300], Step [113/225], Training Accuracy: 98.4928%, Training Loss: 0.0452%\n",
      "Epoch [147/300], Step [114/225], Training Accuracy: 98.4923%, Training Loss: 0.0454%\n",
      "Epoch [147/300], Step [115/225], Training Accuracy: 98.4918%, Training Loss: 0.0453%\n",
      "Epoch [147/300], Step [116/225], Training Accuracy: 98.4779%, Training Loss: 0.0453%\n",
      "Epoch [147/300], Step [117/225], Training Accuracy: 98.4909%, Training Loss: 0.0450%\n",
      "Epoch [147/300], Step [118/225], Training Accuracy: 98.5037%, Training Loss: 0.0448%\n",
      "Epoch [147/300], Step [119/225], Training Accuracy: 98.5163%, Training Loss: 0.0446%\n",
      "Epoch [147/300], Step [120/225], Training Accuracy: 98.5286%, Training Loss: 0.0444%\n",
      "Epoch [147/300], Step [121/225], Training Accuracy: 98.5150%, Training Loss: 0.0447%\n",
      "Epoch [147/300], Step [122/225], Training Accuracy: 98.5272%, Training Loss: 0.0444%\n",
      "Epoch [147/300], Step [123/225], Training Accuracy: 98.5264%, Training Loss: 0.0446%\n",
      "Epoch [147/300], Step [124/225], Training Accuracy: 98.5257%, Training Loss: 0.0447%\n",
      "Epoch [147/300], Step [125/225], Training Accuracy: 98.5250%, Training Loss: 0.0449%\n",
      "Epoch [147/300], Step [126/225], Training Accuracy: 98.5367%, Training Loss: 0.0448%\n",
      "Epoch [147/300], Step [127/225], Training Accuracy: 98.5482%, Training Loss: 0.0446%\n",
      "Epoch [147/300], Step [128/225], Training Accuracy: 98.5352%, Training Loss: 0.0448%\n",
      "Epoch [147/300], Step [129/225], Training Accuracy: 98.5102%, Training Loss: 0.0453%\n",
      "Epoch [147/300], Step [130/225], Training Accuracy: 98.5216%, Training Loss: 0.0452%\n",
      "Epoch [147/300], Step [131/225], Training Accuracy: 98.5210%, Training Loss: 0.0452%\n",
      "Epoch [147/300], Step [132/225], Training Accuracy: 98.5322%, Training Loss: 0.0450%\n",
      "Epoch [147/300], Step [133/225], Training Accuracy: 98.5315%, Training Loss: 0.0455%\n",
      "Epoch [147/300], Step [134/225], Training Accuracy: 98.5308%, Training Loss: 0.0455%\n",
      "Epoch [147/300], Step [135/225], Training Accuracy: 98.5417%, Training Loss: 0.0454%\n",
      "Epoch [147/300], Step [136/225], Training Accuracy: 98.5524%, Training Loss: 0.0452%\n",
      "Epoch [147/300], Step [137/225], Training Accuracy: 98.5516%, Training Loss: 0.0453%\n",
      "Epoch [147/300], Step [138/225], Training Accuracy: 98.5394%, Training Loss: 0.0454%\n",
      "Epoch [147/300], Step [139/225], Training Accuracy: 98.5499%, Training Loss: 0.0452%\n",
      "Epoch [147/300], Step [140/225], Training Accuracy: 98.5379%, Training Loss: 0.0453%\n",
      "Epoch [147/300], Step [141/225], Training Accuracy: 98.5372%, Training Loss: 0.0452%\n",
      "Epoch [147/300], Step [142/225], Training Accuracy: 98.5255%, Training Loss: 0.0455%\n",
      "Epoch [147/300], Step [143/225], Training Accuracy: 98.5031%, Training Loss: 0.0460%\n",
      "Epoch [147/300], Step [144/225], Training Accuracy: 98.5135%, Training Loss: 0.0459%\n",
      "Epoch [147/300], Step [145/225], Training Accuracy: 98.5237%, Training Loss: 0.0457%\n",
      "Epoch [147/300], Step [146/225], Training Accuracy: 98.5231%, Training Loss: 0.0459%\n",
      "Epoch [147/300], Step [147/225], Training Accuracy: 98.5332%, Training Loss: 0.0457%\n",
      "Epoch [147/300], Step [148/225], Training Accuracy: 98.5431%, Training Loss: 0.0456%\n",
      "Epoch [147/300], Step [149/225], Training Accuracy: 98.5319%, Training Loss: 0.0459%\n",
      "Epoch [147/300], Step [150/225], Training Accuracy: 98.5312%, Training Loss: 0.0457%\n",
      "Epoch [147/300], Step [151/225], Training Accuracy: 98.5306%, Training Loss: 0.0458%\n",
      "Epoch [147/300], Step [152/225], Training Accuracy: 98.5197%, Training Loss: 0.0459%\n",
      "Epoch [147/300], Step [153/225], Training Accuracy: 98.5294%, Training Loss: 0.0458%\n",
      "Epoch [147/300], Step [154/225], Training Accuracy: 98.5288%, Training Loss: 0.0457%\n",
      "Epoch [147/300], Step [155/225], Training Accuracy: 98.5181%, Training Loss: 0.0462%\n",
      "Epoch [147/300], Step [156/225], Training Accuracy: 98.5176%, Training Loss: 0.0462%\n",
      "Epoch [147/300], Step [157/225], Training Accuracy: 98.5072%, Training Loss: 0.0462%\n",
      "Epoch [147/300], Step [158/225], Training Accuracy: 98.5166%, Training Loss: 0.0463%\n",
      "Epoch [147/300], Step [159/225], Training Accuracy: 98.5161%, Training Loss: 0.0462%\n",
      "Epoch [147/300], Step [160/225], Training Accuracy: 98.5254%, Training Loss: 0.0460%\n",
      "Epoch [147/300], Step [161/225], Training Accuracy: 98.5345%, Training Loss: 0.0459%\n",
      "Epoch [147/300], Step [162/225], Training Accuracy: 98.5340%, Training Loss: 0.0459%\n",
      "Epoch [147/300], Step [163/225], Training Accuracy: 98.5334%, Training Loss: 0.0459%\n",
      "Epoch [147/300], Step [164/225], Training Accuracy: 98.5328%, Training Loss: 0.0459%\n",
      "Epoch [147/300], Step [165/225], Training Accuracy: 98.5227%, Training Loss: 0.0461%\n",
      "Epoch [147/300], Step [166/225], Training Accuracy: 98.5316%, Training Loss: 0.0459%\n",
      "Epoch [147/300], Step [167/225], Training Accuracy: 98.5217%, Training Loss: 0.0463%\n",
      "Epoch [147/300], Step [168/225], Training Accuracy: 98.5305%, Training Loss: 0.0461%\n",
      "Epoch [147/300], Step [169/225], Training Accuracy: 98.5115%, Training Loss: 0.0466%\n",
      "Epoch [147/300], Step [170/225], Training Accuracy: 98.5110%, Training Loss: 0.0468%\n",
      "Epoch [147/300], Step [171/225], Training Accuracy: 98.5197%, Training Loss: 0.0467%\n",
      "Epoch [147/300], Step [172/225], Training Accuracy: 98.5102%, Training Loss: 0.0468%\n",
      "Epoch [147/300], Step [173/225], Training Accuracy: 98.5098%, Training Loss: 0.0468%\n",
      "Epoch [147/300], Step [174/225], Training Accuracy: 98.5093%, Training Loss: 0.0468%\n",
      "Epoch [147/300], Step [175/225], Training Accuracy: 98.5179%, Training Loss: 0.0466%\n",
      "Epoch [147/300], Step [176/225], Training Accuracy: 98.5263%, Training Loss: 0.0465%\n",
      "Epoch [147/300], Step [177/225], Training Accuracy: 98.5346%, Training Loss: 0.0464%\n",
      "Epoch [147/300], Step [178/225], Training Accuracy: 98.5341%, Training Loss: 0.0463%\n",
      "Epoch [147/300], Step [179/225], Training Accuracy: 98.5335%, Training Loss: 0.0462%\n",
      "Epoch [147/300], Step [180/225], Training Accuracy: 98.5330%, Training Loss: 0.0461%\n",
      "Epoch [147/300], Step [181/225], Training Accuracy: 98.5238%, Training Loss: 0.0462%\n",
      "Epoch [147/300], Step [182/225], Training Accuracy: 98.5319%, Training Loss: 0.0461%\n",
      "Epoch [147/300], Step [183/225], Training Accuracy: 98.5400%, Training Loss: 0.0459%\n",
      "Epoch [147/300], Step [184/225], Training Accuracy: 98.5309%, Training Loss: 0.0459%\n",
      "Epoch [147/300], Step [185/225], Training Accuracy: 98.5389%, Training Loss: 0.0458%\n",
      "Epoch [147/300], Step [186/225], Training Accuracy: 98.5467%, Training Loss: 0.0457%\n",
      "Epoch [147/300], Step [187/225], Training Accuracy: 98.5545%, Training Loss: 0.0457%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [147/300], Step [188/225], Training Accuracy: 98.5455%, Training Loss: 0.0457%\n",
      "Epoch [147/300], Step [189/225], Training Accuracy: 98.5450%, Training Loss: 0.0456%\n",
      "Epoch [147/300], Step [190/225], Training Accuracy: 98.5444%, Training Loss: 0.0457%\n",
      "Epoch [147/300], Step [191/225], Training Accuracy: 98.5520%, Training Loss: 0.0456%\n",
      "Epoch [147/300], Step [192/225], Training Accuracy: 98.5270%, Training Loss: 0.0459%\n",
      "Epoch [147/300], Step [193/225], Training Accuracy: 98.5266%, Training Loss: 0.0460%\n",
      "Epoch [147/300], Step [194/225], Training Accuracy: 98.5261%, Training Loss: 0.0459%\n",
      "Epoch [147/300], Step [195/225], Training Accuracy: 98.5256%, Training Loss: 0.0459%\n",
      "Epoch [147/300], Step [196/225], Training Accuracy: 98.5252%, Training Loss: 0.0459%\n",
      "Epoch [147/300], Step [197/225], Training Accuracy: 98.5168%, Training Loss: 0.0463%\n",
      "Epoch [147/300], Step [198/225], Training Accuracy: 98.5243%, Training Loss: 0.0462%\n",
      "Epoch [147/300], Step [199/225], Training Accuracy: 98.5239%, Training Loss: 0.0465%\n",
      "Epoch [147/300], Step [200/225], Training Accuracy: 98.5234%, Training Loss: 0.0464%\n",
      "Epoch [147/300], Step [201/225], Training Accuracy: 98.5308%, Training Loss: 0.0465%\n",
      "Epoch [147/300], Step [202/225], Training Accuracy: 98.5303%, Training Loss: 0.0463%\n",
      "Epoch [147/300], Step [203/225], Training Accuracy: 98.5222%, Training Loss: 0.0465%\n",
      "Epoch [147/300], Step [204/225], Training Accuracy: 98.5218%, Training Loss: 0.0464%\n",
      "Epoch [147/300], Step [205/225], Training Accuracy: 98.5213%, Training Loss: 0.0465%\n",
      "Epoch [147/300], Step [206/225], Training Accuracy: 98.5285%, Training Loss: 0.0464%\n",
      "Epoch [147/300], Step [207/225], Training Accuracy: 98.5281%, Training Loss: 0.0464%\n",
      "Epoch [147/300], Step [208/225], Training Accuracy: 98.5201%, Training Loss: 0.0465%\n",
      "Epoch [147/300], Step [209/225], Training Accuracy: 98.5197%, Training Loss: 0.0465%\n",
      "Epoch [147/300], Step [210/225], Training Accuracy: 98.5119%, Training Loss: 0.0467%\n",
      "Epoch [147/300], Step [211/225], Training Accuracy: 98.4967%, Training Loss: 0.0469%\n",
      "Epoch [147/300], Step [212/225], Training Accuracy: 98.4817%, Training Loss: 0.0471%\n",
      "Epoch [147/300], Step [213/225], Training Accuracy: 98.4815%, Training Loss: 0.0470%\n",
      "Epoch [147/300], Step [214/225], Training Accuracy: 98.4813%, Training Loss: 0.0470%\n",
      "Epoch [147/300], Step [215/225], Training Accuracy: 98.4884%, Training Loss: 0.0471%\n",
      "Epoch [147/300], Step [216/225], Training Accuracy: 98.4737%, Training Loss: 0.0474%\n",
      "Epoch [147/300], Step [217/225], Training Accuracy: 98.4807%, Training Loss: 0.0473%\n",
      "Epoch [147/300], Step [218/225], Training Accuracy: 98.4662%, Training Loss: 0.0474%\n",
      "Epoch [147/300], Step [219/225], Training Accuracy: 98.4660%, Training Loss: 0.0474%\n",
      "Epoch [147/300], Step [220/225], Training Accuracy: 98.4659%, Training Loss: 0.0472%\n",
      "Epoch [147/300], Step [221/225], Training Accuracy: 98.4729%, Training Loss: 0.0472%\n",
      "Epoch [147/300], Step [222/225], Training Accuracy: 98.4727%, Training Loss: 0.0472%\n",
      "Epoch [147/300], Step [223/225], Training Accuracy: 98.4725%, Training Loss: 0.0471%\n",
      "Epoch [147/300], Step [224/225], Training Accuracy: 98.4654%, Training Loss: 0.0473%\n",
      "Epoch [147/300], Step [225/225], Training Accuracy: 98.4644%, Training Loss: 0.0473%\n",
      "Epoch [148/300], Step [1/225], Training Accuracy: 98.4375%, Training Loss: 0.0728%\n",
      "Epoch [148/300], Step [2/225], Training Accuracy: 97.6562%, Training Loss: 0.0682%\n",
      "Epoch [148/300], Step [3/225], Training Accuracy: 96.8750%, Training Loss: 0.1004%\n",
      "Epoch [148/300], Step [4/225], Training Accuracy: 97.2656%, Training Loss: 0.0862%\n",
      "Epoch [148/300], Step [5/225], Training Accuracy: 97.1875%, Training Loss: 0.0866%\n",
      "Epoch [148/300], Step [6/225], Training Accuracy: 97.3958%, Training Loss: 0.0843%\n",
      "Epoch [148/300], Step [7/225], Training Accuracy: 96.8750%, Training Loss: 0.0954%\n",
      "Epoch [148/300], Step [8/225], Training Accuracy: 97.0703%, Training Loss: 0.0904%\n",
      "Epoch [148/300], Step [9/225], Training Accuracy: 97.3958%, Training Loss: 0.0831%\n",
      "Epoch [148/300], Step [10/225], Training Accuracy: 97.3438%, Training Loss: 0.0838%\n",
      "Epoch [148/300], Step [11/225], Training Accuracy: 97.4432%, Training Loss: 0.0815%\n",
      "Epoch [148/300], Step [12/225], Training Accuracy: 97.6562%, Training Loss: 0.0776%\n",
      "Epoch [148/300], Step [13/225], Training Accuracy: 97.8365%, Training Loss: 0.0732%\n",
      "Epoch [148/300], Step [14/225], Training Accuracy: 97.9911%, Training Loss: 0.0698%\n",
      "Epoch [148/300], Step [15/225], Training Accuracy: 98.1250%, Training Loss: 0.0671%\n",
      "Epoch [148/300], Step [16/225], Training Accuracy: 98.1445%, Training Loss: 0.0655%\n",
      "Epoch [148/300], Step [17/225], Training Accuracy: 98.1618%, Training Loss: 0.0655%\n",
      "Epoch [148/300], Step [18/225], Training Accuracy: 98.1771%, Training Loss: 0.0653%\n",
      "Epoch [148/300], Step [19/225], Training Accuracy: 98.1086%, Training Loss: 0.0641%\n",
      "Epoch [148/300], Step [20/225], Training Accuracy: 98.2031%, Training Loss: 0.0617%\n",
      "Epoch [148/300], Step [21/225], Training Accuracy: 98.0655%, Training Loss: 0.0625%\n",
      "Epoch [148/300], Step [22/225], Training Accuracy: 98.0824%, Training Loss: 0.0613%\n",
      "Epoch [148/300], Step [23/225], Training Accuracy: 98.1658%, Training Loss: 0.0599%\n",
      "Epoch [148/300], Step [24/225], Training Accuracy: 98.2422%, Training Loss: 0.0591%\n",
      "Epoch [148/300], Step [25/225], Training Accuracy: 98.3125%, Training Loss: 0.0576%\n",
      "Epoch [148/300], Step [26/225], Training Accuracy: 98.3173%, Training Loss: 0.0568%\n",
      "Epoch [148/300], Step [27/225], Training Accuracy: 98.2639%, Training Loss: 0.0573%\n",
      "Epoch [148/300], Step [28/225], Training Accuracy: 98.2143%, Training Loss: 0.0569%\n",
      "Epoch [148/300], Step [29/225], Training Accuracy: 98.2220%, Training Loss: 0.0565%\n",
      "Epoch [148/300], Step [30/225], Training Accuracy: 98.1250%, Training Loss: 0.0574%\n",
      "Epoch [148/300], Step [31/225], Training Accuracy: 98.1351%, Training Loss: 0.0567%\n",
      "Epoch [148/300], Step [32/225], Training Accuracy: 98.1445%, Training Loss: 0.0567%\n",
      "Epoch [148/300], Step [33/225], Training Accuracy: 98.1061%, Training Loss: 0.0571%\n",
      "Epoch [148/300], Step [34/225], Training Accuracy: 98.1158%, Training Loss: 0.0609%\n",
      "Epoch [148/300], Step [35/225], Training Accuracy: 98.1696%, Training Loss: 0.0602%\n",
      "Epoch [148/300], Step [36/225], Training Accuracy: 98.2205%, Training Loss: 0.0592%\n",
      "Epoch [148/300], Step [37/225], Training Accuracy: 98.2686%, Training Loss: 0.0584%\n",
      "Epoch [148/300], Step [38/225], Training Accuracy: 98.2319%, Training Loss: 0.0598%\n",
      "Epoch [148/300], Step [39/225], Training Accuracy: 98.2372%, Training Loss: 0.0594%\n",
      "Epoch [148/300], Step [40/225], Training Accuracy: 98.2422%, Training Loss: 0.0594%\n",
      "Epoch [148/300], Step [41/225], Training Accuracy: 98.1707%, Training Loss: 0.0614%\n",
      "Epoch [148/300], Step [42/225], Training Accuracy: 98.1771%, Training Loss: 0.0610%\n",
      "Epoch [148/300], Step [43/225], Training Accuracy: 98.1831%, Training Loss: 0.0609%\n",
      "Epoch [148/300], Step [44/225], Training Accuracy: 98.1534%, Training Loss: 0.0612%\n",
      "Epoch [148/300], Step [45/225], Training Accuracy: 98.0903%, Training Loss: 0.0614%\n",
      "Epoch [148/300], Step [46/225], Training Accuracy: 98.1318%, Training Loss: 0.0606%\n",
      "Epoch [148/300], Step [47/225], Training Accuracy: 98.1051%, Training Loss: 0.0624%\n",
      "Epoch [148/300], Step [48/225], Training Accuracy: 98.1120%, Training Loss: 0.0616%\n",
      "Epoch [148/300], Step [49/225], Training Accuracy: 98.1505%, Training Loss: 0.0606%\n",
      "Epoch [148/300], Step [50/225], Training Accuracy: 98.1875%, Training Loss: 0.0600%\n",
      "Epoch [148/300], Step [51/225], Training Accuracy: 98.2230%, Training Loss: 0.0591%\n",
      "Epoch [148/300], Step [52/225], Training Accuracy: 98.2272%, Training Loss: 0.0588%\n",
      "Epoch [148/300], Step [53/225], Training Accuracy: 98.2017%, Training Loss: 0.0587%\n",
      "Epoch [148/300], Step [54/225], Training Accuracy: 98.1771%, Training Loss: 0.0588%\n",
      "Epoch [148/300], Step [55/225], Training Accuracy: 98.1534%, Training Loss: 0.0586%\n",
      "Epoch [148/300], Step [56/225], Training Accuracy: 98.1306%, Training Loss: 0.0595%\n",
      "Epoch [148/300], Step [57/225], Training Accuracy: 98.1634%, Training Loss: 0.0589%\n",
      "Epoch [148/300], Step [58/225], Training Accuracy: 98.1142%, Training Loss: 0.0592%\n",
      "Epoch [148/300], Step [59/225], Training Accuracy: 98.1462%, Training Loss: 0.0590%\n",
      "Epoch [148/300], Step [60/225], Training Accuracy: 98.1250%, Training Loss: 0.0592%\n",
      "Epoch [148/300], Step [61/225], Training Accuracy: 98.1045%, Training Loss: 0.0596%\n",
      "Epoch [148/300], Step [62/225], Training Accuracy: 98.1099%, Training Loss: 0.0593%\n",
      "Epoch [148/300], Step [63/225], Training Accuracy: 98.0903%, Training Loss: 0.0596%\n",
      "Epoch [148/300], Step [64/225], Training Accuracy: 98.0469%, Training Loss: 0.0607%\n",
      "Epoch [148/300], Step [65/225], Training Accuracy: 98.0048%, Training Loss: 0.0616%\n",
      "Epoch [148/300], Step [66/225], Training Accuracy: 97.9403%, Training Loss: 0.0623%\n",
      "Epoch [148/300], Step [67/225], Training Accuracy: 97.9478%, Training Loss: 0.0620%\n",
      "Epoch [148/300], Step [68/225], Training Accuracy: 97.9550%, Training Loss: 0.0616%\n",
      "Epoch [148/300], Step [69/225], Training Accuracy: 97.9167%, Training Loss: 0.0624%\n",
      "Epoch [148/300], Step [70/225], Training Accuracy: 97.9241%, Training Loss: 0.0620%\n",
      "Epoch [148/300], Step [71/225], Training Accuracy: 97.9533%, Training Loss: 0.0616%\n",
      "Epoch [148/300], Step [72/225], Training Accuracy: 97.9818%, Training Loss: 0.0611%\n",
      "Epoch [148/300], Step [73/225], Training Accuracy: 98.0094%, Training Loss: 0.0605%\n",
      "Epoch [148/300], Step [74/225], Training Accuracy: 97.9730%, Training Loss: 0.0613%\n",
      "Epoch [148/300], Step [75/225], Training Accuracy: 97.9792%, Training Loss: 0.0611%\n",
      "Epoch [148/300], Step [76/225], Training Accuracy: 97.9646%, Training Loss: 0.0613%\n",
      "Epoch [148/300], Step [77/225], Training Accuracy: 97.9911%, Training Loss: 0.0608%\n",
      "Epoch [148/300], Step [78/225], Training Accuracy: 98.0168%, Training Loss: 0.0602%\n",
      "Epoch [148/300], Step [79/225], Training Accuracy: 98.0419%, Training Loss: 0.0600%\n",
      "Epoch [148/300], Step [80/225], Training Accuracy: 98.0273%, Training Loss: 0.0605%\n",
      "Epoch [148/300], Step [81/225], Training Accuracy: 98.0324%, Training Loss: 0.0603%\n",
      "Epoch [148/300], Step [82/225], Training Accuracy: 98.0183%, Training Loss: 0.0601%\n",
      "Epoch [148/300], Step [83/225], Training Accuracy: 98.0233%, Training Loss: 0.0598%\n",
      "Epoch [148/300], Step [84/225], Training Accuracy: 98.0469%, Training Loss: 0.0594%\n",
      "Epoch [148/300], Step [85/225], Training Accuracy: 98.0699%, Training Loss: 0.0590%\n",
      "Epoch [148/300], Step [86/225], Training Accuracy: 98.0923%, Training Loss: 0.0588%\n",
      "Epoch [148/300], Step [87/225], Training Accuracy: 98.0963%, Training Loss: 0.0586%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [148/300], Step [88/225], Training Accuracy: 98.0824%, Training Loss: 0.0587%\n",
      "Epoch [148/300], Step [89/225], Training Accuracy: 98.1039%, Training Loss: 0.0585%\n",
      "Epoch [148/300], Step [90/225], Training Accuracy: 98.1076%, Training Loss: 0.0583%\n",
      "Epoch [148/300], Step [91/225], Training Accuracy: 98.1113%, Training Loss: 0.0581%\n",
      "Epoch [148/300], Step [92/225], Training Accuracy: 98.1148%, Training Loss: 0.0579%\n",
      "Epoch [148/300], Step [93/225], Training Accuracy: 98.1351%, Training Loss: 0.0574%\n",
      "Epoch [148/300], Step [94/225], Training Accuracy: 98.1217%, Training Loss: 0.0579%\n",
      "Epoch [148/300], Step [95/225], Training Accuracy: 98.0921%, Training Loss: 0.0581%\n",
      "Epoch [148/300], Step [96/225], Training Accuracy: 98.0794%, Training Loss: 0.0584%\n",
      "Epoch [148/300], Step [97/225], Training Accuracy: 98.0831%, Training Loss: 0.0583%\n",
      "Epoch [148/300], Step [98/225], Training Accuracy: 98.0708%, Training Loss: 0.0585%\n",
      "Epoch [148/300], Step [99/225], Training Accuracy: 98.0745%, Training Loss: 0.0586%\n",
      "Epoch [148/300], Step [100/225], Training Accuracy: 98.0938%, Training Loss: 0.0581%\n",
      "Epoch [148/300], Step [101/225], Training Accuracy: 98.0972%, Training Loss: 0.0580%\n",
      "Epoch [148/300], Step [102/225], Training Accuracy: 98.0852%, Training Loss: 0.0580%\n",
      "Epoch [148/300], Step [103/225], Training Accuracy: 98.1038%, Training Loss: 0.0576%\n",
      "Epoch [148/300], Step [104/225], Training Accuracy: 98.1070%, Training Loss: 0.0578%\n",
      "Epoch [148/300], Step [105/225], Training Accuracy: 98.1250%, Training Loss: 0.0574%\n",
      "Epoch [148/300], Step [106/225], Training Accuracy: 98.1427%, Training Loss: 0.0569%\n",
      "Epoch [148/300], Step [107/225], Training Accuracy: 98.1454%, Training Loss: 0.0568%\n",
      "Epoch [148/300], Step [108/225], Training Accuracy: 98.1626%, Training Loss: 0.0564%\n",
      "Epoch [148/300], Step [109/225], Training Accuracy: 98.1651%, Training Loss: 0.0565%\n",
      "Epoch [148/300], Step [110/225], Training Accuracy: 98.1818%, Training Loss: 0.0562%\n",
      "Epoch [148/300], Step [111/225], Training Accuracy: 98.1982%, Training Loss: 0.0560%\n",
      "Epoch [148/300], Step [112/225], Training Accuracy: 98.2143%, Training Loss: 0.0559%\n",
      "Epoch [148/300], Step [113/225], Training Accuracy: 98.2301%, Training Loss: 0.0556%\n",
      "Epoch [148/300], Step [114/225], Training Accuracy: 98.2319%, Training Loss: 0.0555%\n",
      "Epoch [148/300], Step [115/225], Training Accuracy: 98.2337%, Training Loss: 0.0553%\n",
      "Epoch [148/300], Step [116/225], Training Accuracy: 98.2220%, Training Loss: 0.0553%\n",
      "Epoch [148/300], Step [117/225], Training Accuracy: 98.2238%, Training Loss: 0.0551%\n",
      "Epoch [148/300], Step [118/225], Training Accuracy: 98.2256%, Training Loss: 0.0549%\n",
      "Epoch [148/300], Step [119/225], Training Accuracy: 98.2405%, Training Loss: 0.0546%\n",
      "Epoch [148/300], Step [120/225], Training Accuracy: 98.2292%, Training Loss: 0.0544%\n",
      "Epoch [148/300], Step [121/225], Training Accuracy: 98.2309%, Training Loss: 0.0541%\n",
      "Epoch [148/300], Step [122/225], Training Accuracy: 98.2326%, Training Loss: 0.0540%\n",
      "Epoch [148/300], Step [123/225], Training Accuracy: 98.2215%, Training Loss: 0.0543%\n",
      "Epoch [148/300], Step [124/225], Training Accuracy: 98.2359%, Training Loss: 0.0539%\n",
      "Epoch [148/300], Step [125/225], Training Accuracy: 98.2375%, Training Loss: 0.0538%\n",
      "Epoch [148/300], Step [126/225], Training Accuracy: 98.2515%, Training Loss: 0.0537%\n",
      "Epoch [148/300], Step [127/225], Training Accuracy: 98.2653%, Training Loss: 0.0534%\n",
      "Epoch [148/300], Step [128/225], Training Accuracy: 98.2788%, Training Loss: 0.0533%\n",
      "Epoch [148/300], Step [129/225], Training Accuracy: 98.2800%, Training Loss: 0.0532%\n",
      "Epoch [148/300], Step [130/225], Training Accuracy: 98.2812%, Training Loss: 0.0532%\n",
      "Epoch [148/300], Step [131/225], Training Accuracy: 98.2824%, Training Loss: 0.0531%\n",
      "Epoch [148/300], Step [132/225], Training Accuracy: 98.2955%, Training Loss: 0.0528%\n",
      "Epoch [148/300], Step [133/225], Training Accuracy: 98.3083%, Training Loss: 0.0527%\n",
      "Epoch [148/300], Step [134/225], Training Accuracy: 98.3092%, Training Loss: 0.0527%\n",
      "Epoch [148/300], Step [135/225], Training Accuracy: 98.3102%, Training Loss: 0.0526%\n",
      "Epoch [148/300], Step [136/225], Training Accuracy: 98.3226%, Training Loss: 0.0524%\n",
      "Epoch [148/300], Step [137/225], Training Accuracy: 98.3349%, Training Loss: 0.0521%\n",
      "Epoch [148/300], Step [138/225], Training Accuracy: 98.3469%, Training Loss: 0.0518%\n",
      "Epoch [148/300], Step [139/225], Training Accuracy: 98.3251%, Training Loss: 0.0521%\n",
      "Epoch [148/300], Step [140/225], Training Accuracy: 98.3371%, Training Loss: 0.0519%\n",
      "Epoch [148/300], Step [141/225], Training Accuracy: 98.3488%, Training Loss: 0.0517%\n",
      "Epoch [148/300], Step [142/225], Training Accuracy: 98.3385%, Training Loss: 0.0522%\n",
      "Epoch [148/300], Step [143/225], Training Accuracy: 98.3501%, Training Loss: 0.0521%\n",
      "Epoch [148/300], Step [144/225], Training Accuracy: 98.3507%, Training Loss: 0.0520%\n",
      "Epoch [148/300], Step [145/225], Training Accuracy: 98.3621%, Training Loss: 0.0517%\n",
      "Epoch [148/300], Step [146/225], Training Accuracy: 98.3733%, Training Loss: 0.0515%\n",
      "Epoch [148/300], Step [147/225], Training Accuracy: 98.3844%, Training Loss: 0.0513%\n",
      "Epoch [148/300], Step [148/225], Training Accuracy: 98.3847%, Training Loss: 0.0513%\n",
      "Epoch [148/300], Step [149/225], Training Accuracy: 98.3641%, Training Loss: 0.0517%\n",
      "Epoch [148/300], Step [150/225], Training Accuracy: 98.3542%, Training Loss: 0.0518%\n",
      "Epoch [148/300], Step [151/225], Training Accuracy: 98.3651%, Training Loss: 0.0516%\n",
      "Epoch [148/300], Step [152/225], Training Accuracy: 98.3758%, Training Loss: 0.0514%\n",
      "Epoch [148/300], Step [153/225], Training Accuracy: 98.3660%, Training Loss: 0.0514%\n",
      "Epoch [148/300], Step [154/225], Training Accuracy: 98.3563%, Training Loss: 0.0515%\n",
      "Epoch [148/300], Step [155/225], Training Accuracy: 98.3569%, Training Loss: 0.0514%\n",
      "Epoch [148/300], Step [156/225], Training Accuracy: 98.3574%, Training Loss: 0.0512%\n",
      "Epoch [148/300], Step [157/225], Training Accuracy: 98.3380%, Training Loss: 0.0514%\n",
      "Epoch [148/300], Step [158/225], Training Accuracy: 98.3485%, Training Loss: 0.0511%\n",
      "Epoch [148/300], Step [159/225], Training Accuracy: 98.3196%, Training Loss: 0.0515%\n",
      "Epoch [148/300], Step [160/225], Training Accuracy: 98.3301%, Training Loss: 0.0513%\n",
      "Epoch [148/300], Step [161/225], Training Accuracy: 98.3307%, Training Loss: 0.0513%\n",
      "Epoch [148/300], Step [162/225], Training Accuracy: 98.3410%, Training Loss: 0.0512%\n",
      "Epoch [148/300], Step [163/225], Training Accuracy: 98.3416%, Training Loss: 0.0512%\n",
      "Epoch [148/300], Step [164/225], Training Accuracy: 98.3518%, Training Loss: 0.0511%\n",
      "Epoch [148/300], Step [165/225], Training Accuracy: 98.3333%, Training Loss: 0.0515%\n",
      "Epoch [148/300], Step [166/225], Training Accuracy: 98.3057%, Training Loss: 0.0518%\n",
      "Epoch [148/300], Step [167/225], Training Accuracy: 98.3065%, Training Loss: 0.0518%\n",
      "Epoch [148/300], Step [168/225], Training Accuracy: 98.3166%, Training Loss: 0.0516%\n",
      "Epoch [148/300], Step [169/225], Training Accuracy: 98.3173%, Training Loss: 0.0515%\n",
      "Epoch [148/300], Step [170/225], Training Accuracy: 98.3180%, Training Loss: 0.0514%\n",
      "Epoch [148/300], Step [171/225], Training Accuracy: 98.3279%, Training Loss: 0.0513%\n",
      "Epoch [148/300], Step [172/225], Training Accuracy: 98.3376%, Training Loss: 0.0513%\n",
      "Epoch [148/300], Step [173/225], Training Accuracy: 98.3291%, Training Loss: 0.0513%\n",
      "Epoch [148/300], Step [174/225], Training Accuracy: 98.3297%, Training Loss: 0.0512%\n",
      "Epoch [148/300], Step [175/225], Training Accuracy: 98.3214%, Training Loss: 0.0515%\n",
      "Epoch [148/300], Step [176/225], Training Accuracy: 98.3310%, Training Loss: 0.0513%\n",
      "Epoch [148/300], Step [177/225], Training Accuracy: 98.3404%, Training Loss: 0.0510%\n",
      "Epoch [148/300], Step [178/225], Training Accuracy: 98.3497%, Training Loss: 0.0509%\n",
      "Epoch [148/300], Step [179/225], Training Accuracy: 98.3502%, Training Loss: 0.0510%\n",
      "Epoch [148/300], Step [180/225], Training Accuracy: 98.3420%, Training Loss: 0.0511%\n",
      "Epoch [148/300], Step [181/225], Training Accuracy: 98.3425%, Training Loss: 0.0511%\n",
      "Epoch [148/300], Step [182/225], Training Accuracy: 98.3516%, Training Loss: 0.0509%\n",
      "Epoch [148/300], Step [183/225], Training Accuracy: 98.3521%, Training Loss: 0.0509%\n",
      "Epoch [148/300], Step [184/225], Training Accuracy: 98.3611%, Training Loss: 0.0508%\n",
      "Epoch [148/300], Step [185/225], Training Accuracy: 98.3699%, Training Loss: 0.0507%\n",
      "Epoch [148/300], Step [186/225], Training Accuracy: 98.3787%, Training Loss: 0.0506%\n",
      "Epoch [148/300], Step [187/225], Training Accuracy: 98.3790%, Training Loss: 0.0505%\n",
      "Epoch [148/300], Step [188/225], Training Accuracy: 98.3793%, Training Loss: 0.0504%\n",
      "Epoch [148/300], Step [189/225], Training Accuracy: 98.3879%, Training Loss: 0.0503%\n",
      "Epoch [148/300], Step [190/225], Training Accuracy: 98.3717%, Training Loss: 0.0506%\n",
      "Epoch [148/300], Step [191/225], Training Accuracy: 98.3802%, Training Loss: 0.0505%\n",
      "Epoch [148/300], Step [192/225], Training Accuracy: 98.3887%, Training Loss: 0.0505%\n",
      "Epoch [148/300], Step [193/225], Training Accuracy: 98.3889%, Training Loss: 0.0506%\n",
      "Epoch [148/300], Step [194/225], Training Accuracy: 98.3972%, Training Loss: 0.0505%\n",
      "Epoch [148/300], Step [195/225], Training Accuracy: 98.3974%, Training Loss: 0.0504%\n",
      "Epoch [148/300], Step [196/225], Training Accuracy: 98.3737%, Training Loss: 0.0508%\n",
      "Epoch [148/300], Step [197/225], Training Accuracy: 98.3740%, Training Loss: 0.0508%\n",
      "Epoch [148/300], Step [198/225], Training Accuracy: 98.3665%, Training Loss: 0.0509%\n",
      "Epoch [148/300], Step [199/225], Training Accuracy: 98.3590%, Training Loss: 0.0512%\n",
      "Epoch [148/300], Step [200/225], Training Accuracy: 98.3672%, Training Loss: 0.0512%\n",
      "Epoch [148/300], Step [201/225], Training Accuracy: 98.3675%, Training Loss: 0.0512%\n",
      "Epoch [148/300], Step [202/225], Training Accuracy: 98.3756%, Training Loss: 0.0510%\n",
      "Epoch [148/300], Step [203/225], Training Accuracy: 98.3759%, Training Loss: 0.0510%\n",
      "Epoch [148/300], Step [204/225], Training Accuracy: 98.3839%, Training Loss: 0.0508%\n",
      "Epoch [148/300], Step [205/225], Training Accuracy: 98.3765%, Training Loss: 0.0508%\n",
      "Epoch [148/300], Step [206/225], Training Accuracy: 98.3617%, Training Loss: 0.0512%\n",
      "Epoch [148/300], Step [207/225], Training Accuracy: 98.3620%, Training Loss: 0.0511%\n",
      "Epoch [148/300], Step [208/225], Training Accuracy: 98.3624%, Training Loss: 0.0510%\n",
      "Epoch [148/300], Step [209/225], Training Accuracy: 98.3627%, Training Loss: 0.0510%\n",
      "Epoch [148/300], Step [210/225], Training Accuracy: 98.3557%, Training Loss: 0.0511%\n",
      "Epoch [148/300], Step [211/225], Training Accuracy: 98.3486%, Training Loss: 0.0511%\n",
      "Epoch [148/300], Step [212/225], Training Accuracy: 98.3564%, Training Loss: 0.0510%\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    correct=0\n",
    "    total=0\n",
    "    running_loss = 0\n",
    "    for i, (X, Y) in enumerate(train_loader):\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, Y)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        #scheduler.step() \n",
    "        #print(scheduler.get_last_lr()[0])\n",
    "      \n",
    "        optimizer.step()\n",
    "        scheduler.step() \n",
    "        #print(optimizer.param_groups[0][\"lr\"])\n",
    "        \n",
    "        _, predicted = outputs.max(1)\n",
    "        total += Y.size(0)\n",
    "        correct += predicted.eq(Y).sum().item()\n",
    "        running_loss += loss.item()\n",
    "        accu=100.*correct/total\n",
    "        train_loss = running_loss/(i+1)\n",
    "        print ('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.4f}%, Training Loss: {:.4f}%'.format(epoch+1, num_epochs, i+1, total_step, accu, train_loss))\n",
    "    \n",
    "   \n",
    "        #writer.add_scalar(f'train/accuracy', accu, epoch)\n",
    "        #writer.add_scalar(f'train/loss', train_loss, epoch)\n",
    "        writer.add_scalars(f'train/accuracy_loss', {\n",
    "            'accuracy': accu,\n",
    "            'loss': train_loss,\n",
    "        }, epoch)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3148bcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from playsound import playsound\n",
    "playsound(u\"sound.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdfa83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for X, Y in test_loader:\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += Y.size(0)\n",
    "        correct += (predicted == Y).sum().item()\n",
    "\n",
    "    print('Test Accuracy : {} %'.format(100 * correct / total))\n",
    "\n",
    "# Save the model checkpoint\n",
    "#torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734c39e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
