{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce5e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f58eded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8a3116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"data/final_format/train_set.csv\",header=None).to_numpy()\n",
    "train_label = pd.read_csv(\"data/final_format/train_label.csv\",header=None).to_numpy()\n",
    "test_set = pd.read_csv(\"data/final_format/test_set.csv\",header=None).to_numpy()\n",
    "test_label = pd.read_csv(\"data/final_format/test_label.csv\",header=None).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37f64e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14393, 4096) (14393, 1) (3599, 4096) (3599, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_set.shape, train_label.shape, test_set.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27d522cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14392, 4096) (14392, 1) (3598, 4096) (3598, 1)\n"
     ]
    }
   ],
   "source": [
    "#delet first row data\n",
    "train_set = train_set[1:]\n",
    "train_label = train_label[1:]\n",
    "test_set = test_set[1:]\n",
    "test_label = test_label[1:]\n",
    "print(train_set.shape, train_label.shape, test_set.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a84a2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14392, 1, 64, 64) (14392, 1) (3598, 1, 64, 64) (3598, 1)\n"
     ]
    }
   ],
   "source": [
    "train_set = train_set.reshape((-1,1,64,64))\n",
    "test_set = test_set.reshape((-1,1,64,64))\n",
    "print(train_set.shape, train_label.shape, test_set.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53e23a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14392, 1, 64, 64) (14392,) (3598, 1, 64, 64) (3598,)\n"
     ]
    }
   ],
   "source": [
    "train_label = train_label.reshape(-1)\n",
    "test_label = test_label.reshape(-1)\n",
    "\n",
    "print(train_set.shape, train_label.shape, test_set.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f62253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 300\n",
    "num_classes = 4\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d66b9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_tensor = Tensor(train_set) \n",
    "train_label_tensor = Tensor(train_label).type(torch.LongTensor)\n",
    "\n",
    "train_dataset = TensorDataset(train_set_tensor,train_label_tensor) \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size) \n",
    "\n",
    "test_set_tensor = Tensor(test_set) \n",
    "test_label_tensor = Tensor(test_label).type(torch.LongTensor)\n",
    "\n",
    "test_dataset = TensorDataset(test_set_tensor,test_label_tensor) \n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33820b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd6f6295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional neural network (two convolutional layers)\n",
    "class DenseCNN(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(DenseCNN, self).__init__()\n",
    "        self.c1 = nn.Conv2d(1, 32, kernel_size=3, padding='same')\n",
    "        self.c2 = nn.Conv2d(33, 64, kernel_size=3,padding='same')\n",
    "        self.c3 = nn.Conv2d(64, 128, kernel_size=3,padding='same') \n",
    "        self.c4 = nn.Conv2d(192, 256, kernel_size=3, padding='same')\n",
    "        self.c5 = nn.Conv2d(256, 256, kernel_size=3,padding='same')\n",
    "        self.c6 = nn.Conv2d(512, 512, kernel_size=3, padding='same')\n",
    "        \n",
    "        self.d1 = nn.Dropout(p=0.25)\n",
    "     \n",
    "        self.bn1 =  nn.BatchNorm2d(1)\n",
    "        self.bn2 =  nn.BatchNorm2d(33)\n",
    "        self.bn3 =  nn.BatchNorm2d(64)\n",
    "        self.bn4 =  nn.BatchNorm2d(192)\n",
    "        self.bn5 =  nn.BatchNorm2d(256)\n",
    "        self.bn6 =  nn.BatchNorm2d(512)\n",
    "        self.bn7 =  nn.BatchNorm1d(512)\n",
    "\n",
    "        \n",
    "        self.fc1 = nn.Linear(481*8*8, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        C1 = self.bn1(x)\n",
    "        C1 = F.leaky_relu(C1,0.2)\n",
    "        C1 = self.c1(C1)\n",
    "        sum1 = torch.cat((x, C1), dim=1)\n",
    "        sum1 = self.bn2(sum1)\n",
    "        sum1 = F.leaky_relu(sum1,0.2)\n",
    "        C2 = self.c2(sum1)\n",
    "        M1 = F.max_pool2d(C2, kernel_size=2, stride=2)\n",
    "        \n",
    "        \n",
    "        C3 = self.bn3(M1)\n",
    "        C3 = F.leaky_relu(C3,0.2)\n",
    "        C3 = self.c3(C3)\n",
    "        sum2 = torch.cat((M1, C3), dim=1)\n",
    "        sum2 = self.bn4(sum2)\n",
    "        sum2 = F.leaky_relu(sum2,0.2)\n",
    "        C4 = self.c4(sum2)\n",
    "        M2 = F.max_pool2d(C4, kernel_size=2, stride=2)\n",
    "        \n",
    "        \n",
    "        C5 = self.bn5(M2)\n",
    "        C5 = F.leaky_relu(C5,0.2)\n",
    "        C5 = self.c5(C5)\n",
    "        sum3 = torch.cat((M2, C5), dim=1)\n",
    "        sum3 = self.bn6(sum3)\n",
    "        sum3 = F.leaky_relu(sum3,0.2)\n",
    "        C6 = self.c6(sum3)\n",
    "        M3 = F.max_pool2d(C6, kernel_size=2, stride=2)\n",
    "        \n",
    "        \n",
    "\n",
    "        F1 = M3.reshape(M3.size(0), -1)\n",
    "        Fc1 = self.fc1(F1)\n",
    "        Fc1 = self.bn7(Fc1)\n",
    "        Fc1 = F.leaky_relu(Fc1,0.2)\n",
    "        Fc1 = self.d1(Fc1)\n",
    "        Fc2 = self.fc2(Fc1)\n",
    "       \n",
    "        return Fc2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "901366a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseCNN(num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45ae0d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-3) \n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "milestones = [50,100,150,200,250]\n",
    "milestones = [a * len(train_loader) for a in milestones]\n",
    "scheduler = MultiStepLR(optimizer, milestones=milestones, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b03775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Step [1/225], Training Accuracy: 12.5000%, Training Loss: 1.4610%\n",
      "Epoch [1/300], Step [2/225], Training Accuracy: 21.0938%, Training Loss: 87.2805%\n",
      "Epoch [1/300], Step [3/225], Training Accuracy: 23.9583%, Training Loss: 120.0232%\n",
      "Epoch [1/300], Step [4/225], Training Accuracy: 25.0000%, Training Loss: 152.5562%\n",
      "Epoch [1/300], Step [5/225], Training Accuracy: 26.2500%, Training Loss: 158.8763%\n",
      "Epoch [1/300], Step [6/225], Training Accuracy: 24.7396%, Training Loss: 152.3065%\n",
      "Epoch [1/300], Step [7/225], Training Accuracy: 25.0000%, Training Loss: 138.2789%\n",
      "Epoch [1/300], Step [8/225], Training Accuracy: 24.6094%, Training Loss: 127.1409%\n",
      "Epoch [1/300], Step [9/225], Training Accuracy: 24.6528%, Training Loss: 119.5572%\n",
      "Epoch [1/300], Step [10/225], Training Accuracy: 25.0000%, Training Loss: 110.5816%\n",
      "Epoch [1/300], Step [11/225], Training Accuracy: 25.5682%, Training Loss: 105.9678%\n",
      "Epoch [1/300], Step [12/225], Training Accuracy: 25.7812%, Training Loss: 102.5912%\n",
      "Epoch [1/300], Step [13/225], Training Accuracy: 25.6010%, Training Loss: 99.9807%\n",
      "Epoch [1/300], Step [14/225], Training Accuracy: 25.2232%, Training Loss: 98.3085%\n",
      "Epoch [1/300], Step [15/225], Training Accuracy: 25.2083%, Training Loss: 94.8711%\n",
      "Epoch [1/300], Step [16/225], Training Accuracy: 25.2930%, Training Loss: 91.4517%\n",
      "Epoch [1/300], Step [17/225], Training Accuracy: 25.0000%, Training Loss: 87.9878%\n",
      "Epoch [1/300], Step [18/225], Training Accuracy: 25.3472%, Training Loss: 84.5570%\n",
      "Epoch [1/300], Step [19/225], Training Accuracy: 25.7401%, Training Loss: 81.1414%\n",
      "Epoch [1/300], Step [20/225], Training Accuracy: 26.1719%, Training Loss: 77.8472%\n",
      "Epoch [1/300], Step [21/225], Training Accuracy: 26.1905%, Training Loss: 74.6565%\n",
      "Epoch [1/300], Step [22/225], Training Accuracy: 26.2074%, Training Loss: 71.7995%\n",
      "Epoch [1/300], Step [23/225], Training Accuracy: 26.2228%, Training Loss: 69.4363%\n",
      "Epoch [1/300], Step [24/225], Training Accuracy: 25.9766%, Training Loss: 67.6440%\n",
      "Epoch [1/300], Step [25/225], Training Accuracy: 26.0625%, Training Loss: 65.4884%\n",
      "Epoch [1/300], Step [26/225], Training Accuracy: 25.7812%, Training Loss: 63.5766%\n",
      "Epoch [1/300], Step [27/225], Training Accuracy: 26.1574%, Training Loss: 61.4482%\n",
      "Epoch [1/300], Step [28/225], Training Accuracy: 26.0045%, Training Loss: 59.5506%\n",
      "Epoch [1/300], Step [29/225], Training Accuracy: 25.7004%, Training Loss: 57.6964%\n",
      "Epoch [1/300], Step [30/225], Training Accuracy: 25.7292%, Training Loss: 56.0133%\n",
      "Epoch [1/300], Step [31/225], Training Accuracy: 25.5544%, Training Loss: 54.4423%\n",
      "Epoch [1/300], Step [32/225], Training Accuracy: 25.4883%, Training Loss: 52.9246%\n",
      "Epoch [1/300], Step [33/225], Training Accuracy: 25.6629%, Training Loss: 51.5336%\n",
      "Epoch [1/300], Step [34/225], Training Accuracy: 25.5055%, Training Loss: 50.1261%\n",
      "Epoch [1/300], Step [35/225], Training Accuracy: 25.4464%, Training Loss: 48.8279%\n",
      "Epoch [1/300], Step [36/225], Training Accuracy: 25.2604%, Training Loss: 47.6787%\n",
      "Epoch [1/300], Step [37/225], Training Accuracy: 25.4223%, Training Loss: 46.5357%\n",
      "Epoch [1/300], Step [38/225], Training Accuracy: 25.6168%, Training Loss: 45.4245%\n",
      "Epoch [1/300], Step [39/225], Training Accuracy: 25.4808%, Training Loss: 44.3946%\n",
      "Epoch [1/300], Step [40/225], Training Accuracy: 25.6641%, Training Loss: 43.3752%\n",
      "Epoch [1/300], Step [41/225], Training Accuracy: 25.7241%, Training Loss: 42.3703%\n",
      "Epoch [1/300], Step [42/225], Training Accuracy: 25.6696%, Training Loss: 41.4623%\n",
      "Epoch [1/300], Step [43/225], Training Accuracy: 25.6541%, Training Loss: 40.5780%\n",
      "Epoch [1/300], Step [44/225], Training Accuracy: 25.7812%, Training Loss: 39.7324%\n",
      "Epoch [1/300], Step [45/225], Training Accuracy: 25.8333%, Training Loss: 38.9086%\n",
      "Epoch [1/300], Step [46/225], Training Accuracy: 25.9851%, Training Loss: 38.1173%\n",
      "Epoch [1/300], Step [47/225], Training Accuracy: 25.9973%, Training Loss: 37.3789%\n",
      "Epoch [1/300], Step [48/225], Training Accuracy: 26.2695%, Training Loss: 36.6707%\n",
      "Epoch [1/300], Step [49/225], Training Accuracy: 26.6901%, Training Loss: 35.9556%\n",
      "Epoch [1/300], Step [50/225], Training Accuracy: 26.8125%, Training Loss: 35.2966%\n",
      "Epoch [1/300], Step [51/225], Training Accuracy: 26.6238%, Training Loss: 34.6850%\n",
      "Epoch [1/300], Step [52/225], Training Accuracy: 26.6827%, Training Loss: 34.0651%\n",
      "Epoch [1/300], Step [53/225], Training Accuracy: 26.8573%, Training Loss: 33.4754%\n",
      "Epoch [1/300], Step [54/225], Training Accuracy: 26.8229%, Training Loss: 32.9094%\n",
      "Epoch [1/300], Step [55/225], Training Accuracy: 26.7898%, Training Loss: 32.3473%\n",
      "Epoch [1/300], Step [56/225], Training Accuracy: 26.7857%, Training Loss: 31.8144%\n",
      "Epoch [1/300], Step [57/225], Training Accuracy: 27.0559%, Training Loss: 31.2932%\n",
      "Epoch [1/300], Step [58/225], Training Accuracy: 27.0474%, Training Loss: 30.7955%\n",
      "Epoch [1/300], Step [59/225], Training Accuracy: 27.3305%, Training Loss: 30.3168%\n",
      "Epoch [1/300], Step [60/225], Training Accuracy: 27.3958%, Training Loss: 29.8565%\n",
      "Epoch [1/300], Step [61/225], Training Accuracy: 27.4846%, Training Loss: 29.3949%\n",
      "Epoch [1/300], Step [62/225], Training Accuracy: 27.3438%, Training Loss: 28.9635%\n",
      "Epoch [1/300], Step [63/225], Training Accuracy: 27.3562%, Training Loss: 28.5473%\n",
      "Epoch [1/300], Step [64/225], Training Accuracy: 27.2217%, Training Loss: 28.1485%\n",
      "Epoch [1/300], Step [65/225], Training Accuracy: 27.1635%, Training Loss: 27.7471%\n",
      "Epoch [1/300], Step [66/225], Training Accuracy: 27.0123%, Training Loss: 27.3748%\n",
      "Epoch [1/300], Step [67/225], Training Accuracy: 27.0522%, Training Loss: 27.0062%\n",
      "Epoch [1/300], Step [68/225], Training Accuracy: 26.9761%, Training Loss: 26.6421%\n",
      "Epoch [1/300], Step [69/225], Training Accuracy: 26.9475%, Training Loss: 26.2851%\n",
      "Epoch [1/300], Step [70/225], Training Accuracy: 26.9196%, Training Loss: 25.9531%\n",
      "Epoch [1/300], Step [71/225], Training Accuracy: 26.9806%, Training Loss: 25.6227%\n",
      "Epoch [1/300], Step [72/225], Training Accuracy: 26.9965%, Training Loss: 25.2984%\n",
      "Epoch [1/300], Step [73/225], Training Accuracy: 27.1190%, Training Loss: 24.9811%\n",
      "Epoch [1/300], Step [74/225], Training Accuracy: 27.2171%, Training Loss: 24.6702%\n",
      "Epoch [1/300], Step [75/225], Training Accuracy: 27.2500%, Training Loss: 24.3650%\n",
      "Epoch [1/300], Step [76/225], Training Accuracy: 27.3643%, Training Loss: 24.0640%\n",
      "Epoch [1/300], Step [77/225], Training Accuracy: 27.3336%, Training Loss: 23.7737%\n",
      "Epoch [1/300], Step [78/225], Training Accuracy: 27.4038%, Training Loss: 23.4957%\n",
      "Epoch [1/300], Step [79/225], Training Accuracy: 27.5119%, Training Loss: 23.2229%\n",
      "Epoch [1/300], Step [80/225], Training Accuracy: 27.5977%, Training Loss: 22.9576%\n",
      "Epoch [1/300], Step [81/225], Training Accuracy: 27.5656%, Training Loss: 22.7003%\n",
      "Epoch [1/300], Step [82/225], Training Accuracy: 27.5534%, Training Loss: 22.4485%\n",
      "Epoch [1/300], Step [83/225], Training Accuracy: 27.6732%, Training Loss: 22.1981%\n",
      "Epoch [1/300], Step [84/225], Training Accuracy: 27.6600%, Training Loss: 21.9591%\n",
      "Epoch [1/300], Step [85/225], Training Accuracy: 27.7022%, Training Loss: 21.7239%\n",
      "Epoch [1/300], Step [86/225], Training Accuracy: 27.7798%, Training Loss: 21.4912%\n",
      "Epoch [1/300], Step [87/225], Training Accuracy: 27.8197%, Training Loss: 21.2633%\n",
      "Epoch [1/300], Step [88/225], Training Accuracy: 27.8409%, Training Loss: 21.0456%\n",
      "Epoch [1/300], Step [89/225], Training Accuracy: 27.8265%, Training Loss: 20.8305%\n",
      "Epoch [1/300], Step [90/225], Training Accuracy: 27.9688%, Training Loss: 20.6177%\n",
      "Epoch [1/300], Step [91/225], Training Accuracy: 28.0220%, Training Loss: 20.4132%\n",
      "Epoch [1/300], Step [92/225], Training Accuracy: 27.9552%, Training Loss: 20.2128%\n",
      "Epoch [1/300], Step [93/225], Training Accuracy: 27.8562%, Training Loss: 20.0154%\n",
      "Epoch [1/300], Step [94/225], Training Accuracy: 27.9588%, Training Loss: 19.8208%\n",
      "Epoch [1/300], Step [95/225], Training Accuracy: 27.9276%, Training Loss: 19.6376%\n",
      "Epoch [1/300], Step [96/225], Training Accuracy: 27.9622%, Training Loss: 19.4597%\n",
      "Epoch [1/300], Step [97/225], Training Accuracy: 27.9156%, Training Loss: 19.2820%\n",
      "Epoch [1/300], Step [98/225], Training Accuracy: 27.8221%, Training Loss: 19.1181%\n",
      "Epoch [1/300], Step [99/225], Training Accuracy: 27.7936%, Training Loss: 18.9545%\n",
      "Epoch [1/300], Step [100/225], Training Accuracy: 27.8125%, Training Loss: 18.7822%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Step [101/225], Training Accuracy: 27.8929%, Training Loss: 18.6225%\n",
      "Epoch [1/300], Step [102/225], Training Accuracy: 27.8339%, Training Loss: 18.4752%\n",
      "Epoch [1/300], Step [103/225], Training Accuracy: 27.8368%, Training Loss: 18.3175%\n",
      "Epoch [1/300], Step [104/225], Training Accuracy: 27.8095%, Training Loss: 18.1661%\n",
      "Epoch [1/300], Step [105/225], Training Accuracy: 27.8274%, Training Loss: 18.0153%\n",
      "Epoch [1/300], Step [106/225], Training Accuracy: 27.8154%, Training Loss: 17.8663%\n",
      "Epoch [1/300], Step [107/225], Training Accuracy: 27.8329%, Training Loss: 17.7193%\n",
      "Epoch [1/300], Step [108/225], Training Accuracy: 27.9080%, Training Loss: 17.5784%\n",
      "Epoch [1/300], Step [109/225], Training Accuracy: 27.9960%, Training Loss: 17.4366%\n",
      "Epoch [1/300], Step [110/225], Training Accuracy: 27.9688%, Training Loss: 17.3079%\n",
      "Epoch [1/300], Step [111/225], Training Accuracy: 27.8575%, Training Loss: 17.1798%\n",
      "Epoch [1/300], Step [112/225], Training Accuracy: 27.8320%, Training Loss: 17.0494%\n",
      "Epoch [1/300], Step [113/225], Training Accuracy: 27.8623%, Training Loss: 16.9236%\n",
      "Epoch [1/300], Step [114/225], Training Accuracy: 27.9194%, Training Loss: 16.7937%\n",
      "Epoch [1/300], Step [115/225], Training Accuracy: 27.9076%, Training Loss: 16.6763%\n",
      "Epoch [1/300], Step [116/225], Training Accuracy: 27.9903%, Training Loss: 16.5530%\n",
      "Epoch [1/300], Step [117/225], Training Accuracy: 27.9915%, Training Loss: 16.4316%\n",
      "Epoch [1/300], Step [118/225], Training Accuracy: 27.9529%, Training Loss: 16.3165%\n",
      "Epoch [1/300], Step [119/225], Training Accuracy: 27.9149%, Training Loss: 16.1945%\n",
      "Epoch [1/300], Step [120/225], Training Accuracy: 27.8646%, Training Loss: 16.0730%\n",
      "Epoch [1/300], Step [121/225], Training Accuracy: 27.8796%, Training Loss: 15.9554%\n",
      "Epoch [1/300], Step [122/225], Training Accuracy: 27.9457%, Training Loss: 15.8381%\n",
      "Epoch [1/300], Step [123/225], Training Accuracy: 27.9472%, Training Loss: 15.7253%\n",
      "Epoch [1/300], Step [124/225], Training Accuracy: 27.9990%, Training Loss: 15.6172%\n",
      "Epoch [1/300], Step [125/225], Training Accuracy: 27.9625%, Training Loss: 15.5097%\n",
      "Epoch [1/300], Step [126/225], Training Accuracy: 27.9142%, Training Loss: 15.4022%\n",
      "Epoch [1/300], Step [127/225], Training Accuracy: 27.9281%, Training Loss: 15.3011%\n",
      "Epoch [1/300], Step [128/225], Training Accuracy: 27.8687%, Training Loss: 15.2000%\n",
      "Epoch [1/300], Step [129/225], Training Accuracy: 27.8343%, Training Loss: 15.0998%\n",
      "Epoch [1/300], Step [130/225], Training Accuracy: 27.8606%, Training Loss: 14.9985%\n",
      "Epoch [1/300], Step [131/225], Training Accuracy: 27.8268%, Training Loss: 14.9014%\n",
      "Epoch [1/300], Step [132/225], Training Accuracy: 27.8409%, Training Loss: 14.8008%\n",
      "Epoch [1/300], Step [133/225], Training Accuracy: 27.8665%, Training Loss: 14.7039%\n",
      "Epoch [1/300], Step [134/225], Training Accuracy: 27.8451%, Training Loss: 14.6182%\n",
      "Epoch [1/300], Step [135/225], Training Accuracy: 27.8356%, Training Loss: 14.5285%\n",
      "Epoch [1/300], Step [136/225], Training Accuracy: 27.9067%, Training Loss: 14.4336%\n",
      "Epoch [1/300], Step [137/225], Training Accuracy: 27.8741%, Training Loss: 14.3512%\n",
      "Epoch [1/300], Step [138/225], Training Accuracy: 27.9552%, Training Loss: 14.2639%\n",
      "Epoch [1/300], Step [139/225], Training Accuracy: 27.9114%, Training Loss: 14.1802%\n",
      "Epoch [1/300], Step [140/225], Training Accuracy: 27.9688%, Training Loss: 14.0952%\n",
      "Epoch [1/300], Step [141/225], Training Accuracy: 28.0031%, Training Loss: 14.0162%\n",
      "Epoch [1/300], Step [142/225], Training Accuracy: 28.0040%, Training Loss: 13.9428%\n",
      "Epoch [1/300], Step [143/225], Training Accuracy: 28.0267%, Training Loss: 13.8587%\n",
      "Epoch [1/300], Step [144/225], Training Accuracy: 28.0490%, Training Loss: 13.7755%\n",
      "Epoch [1/300], Step [145/225], Training Accuracy: 28.0927%, Training Loss: 13.6968%\n",
      "Epoch [1/300], Step [146/225], Training Accuracy: 28.1250%, Training Loss: 13.6185%\n",
      "Epoch [1/300], Step [147/225], Training Accuracy: 28.1569%, Training Loss: 13.5406%\n",
      "Epoch [1/300], Step [148/225], Training Accuracy: 28.1672%, Training Loss: 13.4669%\n",
      "Epoch [1/300], Step [149/225], Training Accuracy: 28.1565%, Training Loss: 13.3888%\n",
      "Epoch [1/300], Step [150/225], Training Accuracy: 28.1562%, Training Loss: 13.3134%\n",
      "Epoch [1/300], Step [151/225], Training Accuracy: 28.1250%, Training Loss: 13.2392%\n",
      "Epoch [1/300], Step [152/225], Training Accuracy: 28.0736%, Training Loss: 13.1648%\n",
      "Epoch [1/300], Step [153/225], Training Accuracy: 28.0842%, Training Loss: 13.0893%\n",
      "Epoch [1/300], Step [154/225], Training Accuracy: 28.0641%, Training Loss: 13.0157%\n",
      "Epoch [1/300], Step [155/225], Training Accuracy: 28.0645%, Training Loss: 12.9435%\n",
      "Epoch [1/300], Step [156/225], Training Accuracy: 28.0749%, Training Loss: 12.8719%\n",
      "Epoch [1/300], Step [157/225], Training Accuracy: 28.0752%, Training Loss: 12.8022%\n",
      "Epoch [1/300], Step [158/225], Training Accuracy: 28.0459%, Training Loss: 12.7355%\n",
      "Epoch [1/300], Step [159/225], Training Accuracy: 28.0562%, Training Loss: 12.6678%\n",
      "Epoch [1/300], Step [160/225], Training Accuracy: 28.0664%, Training Loss: 12.6002%\n",
      "Epoch [1/300], Step [161/225], Training Accuracy: 28.0765%, Training Loss: 12.5352%\n",
      "Epoch [1/300], Step [162/225], Training Accuracy: 28.0768%, Training Loss: 12.4681%\n",
      "Epoch [1/300], Step [163/225], Training Accuracy: 28.0291%, Training Loss: 12.4048%\n",
      "Epoch [1/300], Step [164/225], Training Accuracy: 28.0583%, Training Loss: 12.3394%\n",
      "Epoch [1/300], Step [165/225], Training Accuracy: 28.0871%, Training Loss: 12.2746%\n",
      "Epoch [1/300], Step [166/225], Training Accuracy: 28.0591%, Training Loss: 12.2105%\n",
      "Epoch [1/300], Step [167/225], Training Accuracy: 28.0408%, Training Loss: 12.1486%\n",
      "Epoch [1/300], Step [168/225], Training Accuracy: 27.9948%, Training Loss: 12.0870%\n",
      "Epoch [1/300], Step [169/225], Training Accuracy: 27.9678%, Training Loss: 12.0258%\n",
      "Epoch [1/300], Step [170/225], Training Accuracy: 27.9871%, Training Loss: 11.9653%\n",
      "Epoch [1/300], Step [171/225], Training Accuracy: 27.9788%, Training Loss: 11.9080%\n",
      "Epoch [1/300], Step [172/225], Training Accuracy: 27.9887%, Training Loss: 11.8483%\n",
      "Epoch [1/300], Step [173/225], Training Accuracy: 28.0076%, Training Loss: 11.7893%\n",
      "Epoch [1/300], Step [174/225], Training Accuracy: 28.0442%, Training Loss: 11.7323%\n",
      "Epoch [1/300], Step [175/225], Training Accuracy: 28.0893%, Training Loss: 11.6754%\n",
      "Epoch [1/300], Step [176/225], Training Accuracy: 28.0362%, Training Loss: 11.6184%\n",
      "Epoch [1/300], Step [177/225], Training Accuracy: 28.0014%, Training Loss: 11.5639%\n",
      "Epoch [1/300], Step [178/225], Training Accuracy: 28.0284%, Training Loss: 11.5075%\n",
      "Epoch [1/300], Step [179/225], Training Accuracy: 27.9941%, Training Loss: 11.4529%\n",
      "Epoch [1/300], Step [180/225], Training Accuracy: 28.0469%, Training Loss: 11.3972%\n",
      "Epoch [1/300], Step [181/225], Training Accuracy: 28.0128%, Training Loss: 11.3468%\n",
      "Epoch [1/300], Step [182/225], Training Accuracy: 28.0048%, Training Loss: 11.2939%\n",
      "Epoch [1/300], Step [183/225], Training Accuracy: 27.9884%, Training Loss: 11.2415%\n",
      "Epoch [1/300], Step [184/225], Training Accuracy: 28.0061%, Training Loss: 11.1885%\n",
      "Epoch [1/300], Step [185/225], Training Accuracy: 27.9814%, Training Loss: 11.1404%\n",
      "Epoch [1/300], Step [186/225], Training Accuracy: 27.9318%, Training Loss: 11.0915%\n",
      "Epoch [1/300], Step [187/225], Training Accuracy: 27.8994%, Training Loss: 11.0428%\n",
      "Epoch [1/300], Step [188/225], Training Accuracy: 27.8923%, Training Loss: 10.9926%\n",
      "Epoch [1/300], Step [189/225], Training Accuracy: 27.9183%, Training Loss: 10.9436%\n",
      "Epoch [1/300], Step [190/225], Training Accuracy: 27.8865%, Training Loss: 10.8948%\n",
      "Epoch [1/300], Step [191/225], Training Accuracy: 27.9368%, Training Loss: 10.8459%\n",
      "Epoch [1/300], Step [192/225], Training Accuracy: 27.8971%, Training Loss: 10.7988%\n",
      "Epoch [1/300], Step [193/225], Training Accuracy: 27.8578%, Training Loss: 10.7537%\n",
      "Epoch [1/300], Step [194/225], Training Accuracy: 27.8351%, Training Loss: 10.7076%\n",
      "Epoch [1/300], Step [195/225], Training Accuracy: 27.8365%, Training Loss: 10.6624%\n",
      "Epoch [1/300], Step [196/225], Training Accuracy: 27.8460%, Training Loss: 10.6169%\n",
      "Epoch [1/300], Step [197/225], Training Accuracy: 27.8791%, Training Loss: 10.5707%\n",
      "Epoch [1/300], Step [198/225], Training Accuracy: 27.9435%, Training Loss: 10.5254%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Step [199/225], Training Accuracy: 27.9444%, Training Loss: 10.4833%\n",
      "Epoch [1/300], Step [200/225], Training Accuracy: 27.9219%, Training Loss: 10.4393%\n",
      "Epoch [1/300], Step [201/225], Training Accuracy: 27.9618%, Training Loss: 10.3946%\n",
      "Epoch [1/300], Step [202/225], Training Accuracy: 27.9394%, Training Loss: 10.3519%\n",
      "Epoch [1/300], Step [203/225], Training Accuracy: 27.9557%, Training Loss: 10.3092%\n",
      "Epoch [1/300], Step [204/225], Training Accuracy: 27.9488%, Training Loss: 10.2701%\n",
      "Epoch [1/300], Step [205/225], Training Accuracy: 27.8963%, Training Loss: 10.2338%\n",
      "Epoch [1/300], Step [206/225], Training Accuracy: 27.8671%, Training Loss: 10.1925%\n",
      "Epoch [1/300], Step [207/225], Training Accuracy: 27.8533%, Training Loss: 10.1529%\n",
      "Epoch [1/300], Step [208/225], Training Accuracy: 27.8771%, Training Loss: 10.1138%\n",
      "Epoch [1/300], Step [209/225], Training Accuracy: 27.8783%, Training Loss: 10.0754%\n",
      "Epoch [1/300], Step [210/225], Training Accuracy: 27.8646%, Training Loss: 10.0354%\n",
      "Epoch [1/300], Step [211/225], Training Accuracy: 27.8214%, Training Loss: 9.9994%\n",
      "Epoch [1/300], Step [212/225], Training Accuracy: 27.8302%, Training Loss: 9.9614%\n",
      "Epoch [1/300], Step [213/225], Training Accuracy: 27.8609%, Training Loss: 9.9249%\n",
      "Epoch [1/300], Step [214/225], Training Accuracy: 27.8256%, Training Loss: 9.8884%\n",
      "Epoch [1/300], Step [215/225], Training Accuracy: 27.7762%, Training Loss: 9.8526%\n",
      "Epoch [1/300], Step [216/225], Training Accuracy: 27.8356%, Training Loss: 9.8156%\n",
      "Epoch [1/300], Step [217/225], Training Accuracy: 27.9162%, Training Loss: 9.7767%\n",
      "Epoch [1/300], Step [218/225], Training Accuracy: 27.9386%, Training Loss: 9.7411%\n",
      "Epoch [1/300], Step [219/225], Training Accuracy: 27.9466%, Training Loss: 9.7049%\n",
      "Epoch [1/300], Step [220/225], Training Accuracy: 27.9261%, Training Loss: 9.6690%\n",
      "Epoch [1/300], Step [221/225], Training Accuracy: 27.9200%, Training Loss: 9.6336%\n",
      "Epoch [1/300], Step [222/225], Training Accuracy: 27.8716%, Training Loss: 9.5978%\n",
      "Epoch [1/300], Step [223/225], Training Accuracy: 27.8728%, Training Loss: 9.5626%\n",
      "Epoch [1/300], Step [224/225], Training Accuracy: 27.8948%, Training Loss: 9.5274%\n",
      "Epoch [1/300], Step [225/225], Training Accuracy: 27.8905%, Training Loss: 9.4920%\n",
      "Epoch [2/300], Step [1/225], Training Accuracy: 42.1875%, Training Loss: 1.4995%\n",
      "Epoch [2/300], Step [2/225], Training Accuracy: 39.0625%, Training Loss: 1.7353%\n",
      "Epoch [2/300], Step [3/225], Training Accuracy: 34.8958%, Training Loss: 1.8066%\n",
      "Epoch [2/300], Step [4/225], Training Accuracy: 36.3281%, Training Loss: 1.7661%\n",
      "Epoch [2/300], Step [5/225], Training Accuracy: 35.0000%, Training Loss: 1.7860%\n",
      "Epoch [2/300], Step [6/225], Training Accuracy: 34.3750%, Training Loss: 1.7475%\n",
      "Epoch [2/300], Step [7/225], Training Accuracy: 33.9286%, Training Loss: 1.6944%\n",
      "Epoch [2/300], Step [8/225], Training Accuracy: 32.8125%, Training Loss: 1.6762%\n",
      "Epoch [2/300], Step [9/225], Training Accuracy: 32.1181%, Training Loss: 1.7178%\n",
      "Epoch [2/300], Step [10/225], Training Accuracy: 31.4062%, Training Loss: 1.7216%\n",
      "Epoch [2/300], Step [11/225], Training Accuracy: 30.6818%, Training Loss: 1.7214%\n",
      "Epoch [2/300], Step [12/225], Training Accuracy: 29.9479%, Training Loss: 1.7350%\n",
      "Epoch [2/300], Step [13/225], Training Accuracy: 29.3269%, Training Loss: 1.7304%\n",
      "Epoch [2/300], Step [14/225], Training Accuracy: 29.1295%, Training Loss: 1.7473%\n",
      "Epoch [2/300], Step [15/225], Training Accuracy: 29.0625%, Training Loss: 1.7991%\n",
      "Epoch [2/300], Step [16/225], Training Accuracy: 29.4922%, Training Loss: 1.8130%\n",
      "Epoch [2/300], Step [17/225], Training Accuracy: 30.0551%, Training Loss: 1.7951%\n",
      "Epoch [2/300], Step [18/225], Training Accuracy: 30.4688%, Training Loss: 1.7944%\n",
      "Epoch [2/300], Step [19/225], Training Accuracy: 30.4276%, Training Loss: 1.7792%\n",
      "Epoch [2/300], Step [20/225], Training Accuracy: 30.5469%, Training Loss: 1.7814%\n",
      "Epoch [2/300], Step [21/225], Training Accuracy: 30.7292%, Training Loss: 1.7784%\n",
      "Epoch [2/300], Step [22/225], Training Accuracy: 30.7528%, Training Loss: 1.7879%\n",
      "Epoch [2/300], Step [23/225], Training Accuracy: 30.4348%, Training Loss: 1.7837%\n",
      "Epoch [2/300], Step [24/225], Training Accuracy: 30.2083%, Training Loss: 1.7982%\n",
      "Epoch [2/300], Step [25/225], Training Accuracy: 30.1875%, Training Loss: 1.8088%\n",
      "Epoch [2/300], Step [26/225], Training Accuracy: 30.3486%, Training Loss: 1.7975%\n",
      "Epoch [2/300], Step [27/225], Training Accuracy: 30.2083%, Training Loss: 1.7941%\n",
      "Epoch [2/300], Step [28/225], Training Accuracy: 30.1897%, Training Loss: 1.7909%\n",
      "Epoch [2/300], Step [29/225], Training Accuracy: 30.0108%, Training Loss: 1.8046%\n",
      "Epoch [2/300], Step [30/225], Training Accuracy: 30.1562%, Training Loss: 1.7990%\n",
      "Epoch [2/300], Step [31/225], Training Accuracy: 29.9395%, Training Loss: 1.7941%\n",
      "Epoch [2/300], Step [32/225], Training Accuracy: 29.8828%, Training Loss: 1.8089%\n",
      "Epoch [2/300], Step [33/225], Training Accuracy: 29.8769%, Training Loss: 1.8003%\n",
      "Epoch [2/300], Step [34/225], Training Accuracy: 29.8713%, Training Loss: 1.7951%\n",
      "Epoch [2/300], Step [35/225], Training Accuracy: 30.0000%, Training Loss: 1.7974%\n",
      "Epoch [2/300], Step [36/225], Training Accuracy: 29.7309%, Training Loss: 1.8147%\n",
      "Epoch [2/300], Step [37/225], Training Accuracy: 29.7297%, Training Loss: 1.8116%\n",
      "Epoch [2/300], Step [38/225], Training Accuracy: 29.8931%, Training Loss: 1.8100%\n",
      "Epoch [2/300], Step [39/225], Training Accuracy: 29.7676%, Training Loss: 1.8136%\n",
      "Epoch [2/300], Step [40/225], Training Accuracy: 29.8438%, Training Loss: 1.8049%\n",
      "Epoch [2/300], Step [41/225], Training Accuracy: 29.8018%, Training Loss: 1.7993%\n",
      "Epoch [2/300], Step [42/225], Training Accuracy: 29.8363%, Training Loss: 1.7964%\n",
      "Epoch [2/300], Step [43/225], Training Accuracy: 29.5422%, Training Loss: 1.7926%\n",
      "Epoch [2/300], Step [44/225], Training Accuracy: 29.4034%, Training Loss: 1.7856%\n",
      "Epoch [2/300], Step [45/225], Training Accuracy: 29.5833%, Training Loss: 1.7878%\n",
      "Epoch [2/300], Step [46/225], Training Accuracy: 29.6535%, Training Loss: 1.7788%\n",
      "Epoch [2/300], Step [47/225], Training Accuracy: 29.6543%, Training Loss: 1.7759%\n",
      "Epoch [2/300], Step [48/225], Training Accuracy: 29.5247%, Training Loss: 1.7784%\n",
      "Epoch [2/300], Step [49/225], Training Accuracy: 29.4324%, Training Loss: 1.7768%\n",
      "Epoch [2/300], Step [50/225], Training Accuracy: 29.3125%, Training Loss: 1.7794%\n",
      "Epoch [2/300], Step [51/225], Training Accuracy: 29.2586%, Training Loss: 1.7745%\n",
      "Epoch [2/300], Step [52/225], Training Accuracy: 29.1466%, Training Loss: 1.7804%\n",
      "Epoch [2/300], Step [53/225], Training Accuracy: 29.1274%, Training Loss: 1.7904%\n",
      "Epoch [2/300], Step [54/225], Training Accuracy: 29.3113%, Training Loss: 1.7934%\n",
      "Epoch [2/300], Step [55/225], Training Accuracy: 29.3466%, Training Loss: 1.7931%\n",
      "Epoch [2/300], Step [56/225], Training Accuracy: 29.3806%, Training Loss: 1.7935%\n",
      "Epoch [2/300], Step [57/225], Training Accuracy: 29.4134%, Training Loss: 1.7890%\n",
      "Epoch [2/300], Step [58/225], Training Accuracy: 29.3912%, Training Loss: 1.7869%\n",
      "Epoch [2/300], Step [59/225], Training Accuracy: 29.6610%, Training Loss: 1.7782%\n",
      "Epoch [2/300], Step [60/225], Training Accuracy: 29.6875%, Training Loss: 1.7789%\n",
      "Epoch [2/300], Step [61/225], Training Accuracy: 29.6363%, Training Loss: 1.7830%\n",
      "Epoch [2/300], Step [62/225], Training Accuracy: 29.6875%, Training Loss: 1.7823%\n",
      "Epoch [2/300], Step [63/225], Training Accuracy: 29.8363%, Training Loss: 1.7771%\n",
      "Epoch [2/300], Step [64/225], Training Accuracy: 29.8584%, Training Loss: 1.7798%\n",
      "Epoch [2/300], Step [65/225], Training Accuracy: 29.8077%, Training Loss: 1.7787%\n",
      "Epoch [2/300], Step [66/225], Training Accuracy: 29.9242%, Training Loss: 1.7722%\n",
      "Epoch [2/300], Step [67/225], Training Accuracy: 29.9440%, Training Loss: 1.7650%\n",
      "Epoch [2/300], Step [68/225], Training Accuracy: 29.9403%, Training Loss: 1.7621%\n",
      "Epoch [2/300], Step [69/225], Training Accuracy: 30.0045%, Training Loss: 1.7619%\n",
      "Epoch [2/300], Step [70/225], Training Accuracy: 30.0000%, Training Loss: 1.7597%\n",
      "Epoch [2/300], Step [71/225], Training Accuracy: 30.0176%, Training Loss: 1.7566%\n",
      "Epoch [2/300], Step [72/225], Training Accuracy: 30.0130%, Training Loss: 1.7539%\n",
      "Epoch [2/300], Step [73/225], Training Accuracy: 30.0086%, Training Loss: 1.7543%\n",
      "Epoch [2/300], Step [74/225], Training Accuracy: 30.1098%, Training Loss: 1.7521%\n",
      "Epoch [2/300], Step [75/225], Training Accuracy: 30.1042%, Training Loss: 1.7491%\n",
      "Epoch [2/300], Step [76/225], Training Accuracy: 30.0164%, Training Loss: 1.7464%\n",
      "Epoch [2/300], Step [77/225], Training Accuracy: 30.0325%, Training Loss: 1.7429%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/300], Step [78/225], Training Accuracy: 30.0881%, Training Loss: 1.7405%\n",
      "Epoch [2/300], Step [79/225], Training Accuracy: 30.0633%, Training Loss: 1.7373%\n",
      "Epoch [2/300], Step [80/225], Training Accuracy: 30.0586%, Training Loss: 1.7335%\n",
      "Epoch [2/300], Step [81/225], Training Accuracy: 29.9961%, Training Loss: 1.7323%\n",
      "Epoch [2/300], Step [82/225], Training Accuracy: 29.9162%, Training Loss: 1.7337%\n",
      "Epoch [2/300], Step [83/225], Training Accuracy: 29.8758%, Training Loss: 1.7294%\n",
      "Epoch [2/300], Step [84/225], Training Accuracy: 29.8363%, Training Loss: 1.7253%\n",
      "Epoch [2/300], Step [85/225], Training Accuracy: 29.8529%, Training Loss: 1.7223%\n",
      "Epoch [2/300], Step [86/225], Training Accuracy: 29.8510%, Training Loss: 1.7196%\n",
      "Epoch [2/300], Step [87/225], Training Accuracy: 29.9210%, Training Loss: 1.7203%\n",
      "Epoch [2/300], Step [88/225], Training Accuracy: 29.9006%, Training Loss: 1.7192%\n",
      "Epoch [2/300], Step [89/225], Training Accuracy: 29.8455%, Training Loss: 1.7172%\n",
      "Epoch [2/300], Step [90/225], Training Accuracy: 29.9826%, Training Loss: 1.7134%\n",
      "Epoch [2/300], Step [91/225], Training Accuracy: 29.9279%, Training Loss: 1.7181%\n",
      "Epoch [2/300], Step [92/225], Training Accuracy: 29.8234%, Training Loss: 1.7257%\n",
      "Epoch [2/300], Step [93/225], Training Accuracy: 29.7715%, Training Loss: 1.7278%\n",
      "Epoch [2/300], Step [94/225], Training Accuracy: 29.8205%, Training Loss: 1.7281%\n",
      "Epoch [2/300], Step [95/225], Training Accuracy: 29.8355%, Training Loss: 1.7283%\n",
      "Epoch [2/300], Step [96/225], Training Accuracy: 29.9316%, Training Loss: 1.7320%\n",
      "Epoch [2/300], Step [97/225], Training Accuracy: 29.9291%, Training Loss: 1.7362%\n",
      "Epoch [2/300], Step [98/225], Training Accuracy: 29.9745%, Training Loss: 1.7351%\n",
      "Epoch [2/300], Step [99/225], Training Accuracy: 29.9716%, Training Loss: 1.7331%\n",
      "Epoch [2/300], Step [100/225], Training Accuracy: 30.0156%, Training Loss: 1.7300%\n",
      "Epoch [2/300], Step [101/225], Training Accuracy: 30.0124%, Training Loss: 1.7303%\n",
      "Epoch [2/300], Step [102/225], Training Accuracy: 29.9632%, Training Loss: 1.7319%\n",
      "Epoch [2/300], Step [103/225], Training Accuracy: 29.8544%, Training Loss: 1.7332%\n",
      "Epoch [2/300], Step [104/225], Training Accuracy: 29.8678%, Training Loss: 1.7300%\n",
      "Epoch [2/300], Step [105/225], Training Accuracy: 29.8661%, Training Loss: 1.7309%\n",
      "Epoch [2/300], Step [106/225], Training Accuracy: 29.7759%, Training Loss: 1.7275%\n",
      "Epoch [2/300], Step [107/225], Training Accuracy: 29.6875%, Training Loss: 1.7260%\n",
      "Epoch [2/300], Step [108/225], Training Accuracy: 29.7020%, Training Loss: 1.7248%\n",
      "Epoch [2/300], Step [109/225], Training Accuracy: 29.6732%, Training Loss: 1.7244%\n",
      "Epoch [2/300], Step [110/225], Training Accuracy: 29.6875%, Training Loss: 1.7220%\n",
      "Epoch [2/300], Step [111/225], Training Accuracy: 29.6312%, Training Loss: 1.7195%\n",
      "Epoch [2/300], Step [112/225], Training Accuracy: 29.5898%, Training Loss: 1.7199%\n",
      "Epoch [2/300], Step [113/225], Training Accuracy: 29.5492%, Training Loss: 1.7185%\n",
      "Epoch [2/300], Step [114/225], Training Accuracy: 29.5093%, Training Loss: 1.7162%\n",
      "Epoch [2/300], Step [115/225], Training Accuracy: 29.5380%, Training Loss: 1.7137%\n",
      "Epoch [2/300], Step [116/225], Training Accuracy: 29.5393%, Training Loss: 1.7137%\n",
      "Epoch [2/300], Step [117/225], Training Accuracy: 29.4471%, Training Loss: 1.7144%\n",
      "Epoch [2/300], Step [118/225], Training Accuracy: 29.4889%, Training Loss: 1.7125%\n",
      "Epoch [2/300], Step [119/225], Training Accuracy: 29.4905%, Training Loss: 1.7122%\n",
      "Epoch [2/300], Step [120/225], Training Accuracy: 29.4401%, Training Loss: 1.7121%\n",
      "Epoch [2/300], Step [121/225], Training Accuracy: 29.3776%, Training Loss: 1.7118%\n",
      "Epoch [2/300], Step [122/225], Training Accuracy: 29.3289%, Training Loss: 1.7109%\n",
      "Epoch [2/300], Step [123/225], Training Accuracy: 29.3191%, Training Loss: 1.7099%\n",
      "Epoch [2/300], Step [124/225], Training Accuracy: 29.3347%, Training Loss: 1.7109%\n",
      "Epoch [2/300], Step [125/225], Training Accuracy: 29.2750%, Training Loss: 1.7110%\n",
      "Epoch [2/300], Step [126/225], Training Accuracy: 29.2535%, Training Loss: 1.7112%\n",
      "Epoch [2/300], Step [127/225], Training Accuracy: 29.2446%, Training Loss: 1.7099%\n",
      "Epoch [2/300], Step [128/225], Training Accuracy: 29.2358%, Training Loss: 1.7105%\n",
      "Epoch [2/300], Step [129/225], Training Accuracy: 29.2757%, Training Loss: 1.7084%\n",
      "Epoch [2/300], Step [130/225], Training Accuracy: 29.2308%, Training Loss: 1.7081%\n",
      "Epoch [2/300], Step [131/225], Training Accuracy: 29.2223%, Training Loss: 1.7068%\n",
      "Epoch [2/300], Step [132/225], Training Accuracy: 29.1430%, Training Loss: 1.7070%\n",
      "Epoch [2/300], Step [133/225], Training Accuracy: 29.1706%, Training Loss: 1.7068%\n",
      "Epoch [2/300], Step [134/225], Training Accuracy: 29.1395%, Training Loss: 1.7078%\n",
      "Epoch [2/300], Step [135/225], Training Accuracy: 29.2014%, Training Loss: 1.7073%\n",
      "Epoch [2/300], Step [136/225], Training Accuracy: 29.2279%, Training Loss: 1.7065%\n",
      "Epoch [2/300], Step [137/225], Training Accuracy: 29.2541%, Training Loss: 1.7049%\n",
      "Epoch [2/300], Step [138/225], Training Accuracy: 29.3252%, Training Loss: 1.7036%\n",
      "Epoch [2/300], Step [139/225], Training Accuracy: 29.3053%, Training Loss: 1.7034%\n",
      "Epoch [2/300], Step [140/225], Training Accuracy: 29.3080%, Training Loss: 1.7010%\n",
      "Epoch [2/300], Step [141/225], Training Accuracy: 29.3661%, Training Loss: 1.6988%\n",
      "Epoch [2/300], Step [142/225], Training Accuracy: 29.3354%, Training Loss: 1.6987%\n",
      "Epoch [2/300], Step [143/225], Training Accuracy: 29.3378%, Training Loss: 1.6976%\n",
      "Epoch [2/300], Step [144/225], Training Accuracy: 29.2752%, Training Loss: 1.6986%\n",
      "Epoch [2/300], Step [145/225], Training Accuracy: 29.2996%, Training Loss: 1.6965%\n",
      "Epoch [2/300], Step [146/225], Training Accuracy: 29.3129%, Training Loss: 1.6945%\n",
      "Epoch [2/300], Step [147/225], Training Accuracy: 29.3793%, Training Loss: 1.6936%\n",
      "Epoch [2/300], Step [148/225], Training Accuracy: 29.3180%, Training Loss: 1.6959%\n",
      "Epoch [2/300], Step [149/225], Training Accuracy: 29.3100%, Training Loss: 1.6957%\n",
      "Epoch [2/300], Step [150/225], Training Accuracy: 29.3333%, Training Loss: 1.6957%\n",
      "Epoch [2/300], Step [151/225], Training Accuracy: 29.3771%, Training Loss: 1.6932%\n",
      "Epoch [2/300], Step [152/225], Training Accuracy: 29.4819%, Training Loss: 1.6935%\n",
      "Epoch [2/300], Step [153/225], Training Accuracy: 29.4935%, Training Loss: 1.6935%\n",
      "Epoch [2/300], Step [154/225], Training Accuracy: 29.4947%, Training Loss: 1.6920%\n",
      "Epoch [2/300], Step [155/225], Training Accuracy: 29.4556%, Training Loss: 1.6904%\n",
      "Epoch [2/300], Step [156/225], Training Accuracy: 29.4471%, Training Loss: 1.6887%\n",
      "Epoch [2/300], Step [157/225], Training Accuracy: 29.3790%, Training Loss: 1.6911%\n",
      "Epoch [2/300], Step [158/225], Training Accuracy: 29.3908%, Training Loss: 1.6901%\n",
      "Epoch [2/300], Step [159/225], Training Accuracy: 29.3337%, Training Loss: 1.6906%\n",
      "Epoch [2/300], Step [160/225], Training Accuracy: 29.3164%, Training Loss: 1.6883%\n",
      "Epoch [2/300], Step [161/225], Training Accuracy: 29.3672%, Training Loss: 1.6865%\n",
      "Epoch [2/300], Step [162/225], Training Accuracy: 29.3981%, Training Loss: 1.6870%\n",
      "Epoch [2/300], Step [163/225], Training Accuracy: 29.4574%, Training Loss: 1.6850%\n",
      "Epoch [2/300], Step [164/225], Training Accuracy: 29.4588%, Training Loss: 1.6836%\n",
      "Epoch [2/300], Step [165/225], Training Accuracy: 29.3939%, Training Loss: 1.6838%\n",
      "Epoch [2/300], Step [166/225], Training Accuracy: 29.4239%, Training Loss: 1.6825%\n",
      "Epoch [2/300], Step [167/225], Training Accuracy: 29.3694%, Training Loss: 1.6820%\n",
      "Epoch [2/300], Step [168/225], Training Accuracy: 29.3434%, Training Loss: 1.6821%\n",
      "Epoch [2/300], Step [169/225], Training Accuracy: 29.2530%, Training Loss: 1.6839%\n",
      "Epoch [2/300], Step [170/225], Training Accuracy: 29.2923%, Training Loss: 1.6832%\n",
      "Epoch [2/300], Step [171/225], Training Accuracy: 29.3129%, Training Loss: 1.6840%\n",
      "Epoch [2/300], Step [172/225], Training Accuracy: 29.2878%, Training Loss: 1.6853%\n",
      "Epoch [2/300], Step [173/225], Training Accuracy: 29.3172%, Training Loss: 1.6862%\n",
      "Epoch [2/300], Step [174/225], Training Accuracy: 29.3103%, Training Loss: 1.6870%\n",
      "Epoch [2/300], Step [175/225], Training Accuracy: 29.3036%, Training Loss: 1.6876%\n",
      "Epoch [2/300], Step [176/225], Training Accuracy: 29.2880%, Training Loss: 1.6887%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/300], Step [177/225], Training Accuracy: 29.2814%, Training Loss: 1.6915%\n",
      "Epoch [2/300], Step [178/225], Training Accuracy: 29.3013%, Training Loss: 1.6896%\n",
      "Epoch [2/300], Step [179/225], Training Accuracy: 29.3645%, Training Loss: 1.6875%\n",
      "Epoch [2/300], Step [180/225], Training Accuracy: 29.4184%, Training Loss: 1.6878%\n",
      "Epoch [2/300], Step [181/225], Training Accuracy: 29.3681%, Training Loss: 1.6874%\n",
      "Epoch [2/300], Step [182/225], Training Accuracy: 29.3441%, Training Loss: 1.6886%\n",
      "Epoch [2/300], Step [183/225], Training Accuracy: 29.3460%, Training Loss: 1.6901%\n",
      "Epoch [2/300], Step [184/225], Training Accuracy: 29.4073%, Training Loss: 1.6888%\n",
      "Epoch [2/300], Step [185/225], Training Accuracy: 29.3919%, Training Loss: 1.6882%\n",
      "Epoch [2/300], Step [186/225], Training Accuracy: 29.3683%, Training Loss: 1.6885%\n",
      "Epoch [2/300], Step [187/225], Training Accuracy: 29.3366%, Training Loss: 1.6891%\n",
      "Epoch [2/300], Step [188/225], Training Accuracy: 29.3634%, Training Loss: 1.6878%\n",
      "Epoch [2/300], Step [189/225], Training Accuracy: 29.3733%, Training Loss: 1.6865%\n",
      "Epoch [2/300], Step [190/225], Training Accuracy: 29.3750%, Training Loss: 1.6858%\n",
      "Epoch [2/300], Step [191/225], Training Accuracy: 29.3848%, Training Loss: 1.6851%\n",
      "Epoch [2/300], Step [192/225], Training Accuracy: 29.3783%, Training Loss: 1.6843%\n",
      "Epoch [2/300], Step [193/225], Training Accuracy: 29.4203%, Training Loss: 1.6830%\n",
      "Epoch [2/300], Step [194/225], Training Accuracy: 29.4539%, Training Loss: 1.6826%\n",
      "Epoch [2/300], Step [195/225], Training Accuracy: 29.4551%, Training Loss: 1.6817%\n",
      "Epoch [2/300], Step [196/225], Training Accuracy: 29.3766%, Training Loss: 1.6825%\n",
      "Epoch [2/300], Step [197/225], Training Accuracy: 29.3782%, Training Loss: 1.6815%\n",
      "Epoch [2/300], Step [198/225], Training Accuracy: 29.3797%, Training Loss: 1.6796%\n",
      "Epoch [2/300], Step [199/225], Training Accuracy: 29.3813%, Training Loss: 1.6797%\n",
      "Epoch [2/300], Step [200/225], Training Accuracy: 29.3594%, Training Loss: 1.6788%\n",
      "Epoch [2/300], Step [201/225], Training Accuracy: 29.3688%, Training Loss: 1.6782%\n",
      "Epoch [2/300], Step [202/225], Training Accuracy: 29.3781%, Training Loss: 1.6770%\n",
      "Epoch [2/300], Step [203/225], Training Accuracy: 29.3488%, Training Loss: 1.6774%\n",
      "Epoch [2/300], Step [204/225], Training Accuracy: 29.3811%, Training Loss: 1.6761%\n",
      "Epoch [2/300], Step [205/225], Training Accuracy: 29.3369%, Training Loss: 1.6763%\n",
      "Epoch [2/300], Step [206/225], Training Accuracy: 29.3310%, Training Loss: 1.6756%\n",
      "Epoch [2/300], Step [207/225], Training Accuracy: 29.3478%, Training Loss: 1.6745%\n",
      "Epoch [2/300], Step [208/225], Training Accuracy: 29.3945%, Training Loss: 1.6732%\n",
      "Epoch [2/300], Step [209/225], Training Accuracy: 29.3735%, Training Loss: 1.6725%\n",
      "Epoch [2/300], Step [210/225], Training Accuracy: 29.3676%, Training Loss: 1.6724%\n",
      "Epoch [2/300], Step [211/225], Training Accuracy: 29.3543%, Training Loss: 1.6706%\n",
      "Epoch [2/300], Step [212/225], Training Accuracy: 29.3853%, Training Loss: 1.6694%\n",
      "Epoch [2/300], Step [213/225], Training Accuracy: 29.4087%, Training Loss: 1.6685%\n",
      "Epoch [2/300], Step [214/225], Training Accuracy: 29.3954%, Training Loss: 1.6674%\n",
      "Epoch [2/300], Step [215/225], Training Accuracy: 29.3314%, Training Loss: 1.6674%\n",
      "Epoch [2/300], Step [216/225], Training Accuracy: 29.3475%, Training Loss: 1.6662%\n",
      "Epoch [2/300], Step [217/225], Training Accuracy: 29.3995%, Training Loss: 1.6647%\n",
      "Epoch [2/300], Step [218/225], Training Accuracy: 29.4438%, Training Loss: 1.6638%\n",
      "Epoch [2/300], Step [219/225], Training Accuracy: 29.4092%, Training Loss: 1.6637%\n",
      "Epoch [2/300], Step [220/225], Training Accuracy: 29.4105%, Training Loss: 1.6628%\n",
      "Epoch [2/300], Step [221/225], Training Accuracy: 29.3835%, Training Loss: 1.6625%\n",
      "Epoch [2/300], Step [222/225], Training Accuracy: 29.3567%, Training Loss: 1.6613%\n",
      "Epoch [2/300], Step [223/225], Training Accuracy: 29.3442%, Training Loss: 1.6602%\n",
      "Epoch [2/300], Step [224/225], Training Accuracy: 29.3248%, Training Loss: 1.6591%\n",
      "Epoch [2/300], Step [225/225], Training Accuracy: 29.3288%, Training Loss: 1.6581%\n",
      "Epoch [3/300], Step [1/225], Training Accuracy: 25.0000%, Training Loss: 1.5323%\n",
      "Epoch [3/300], Step [2/225], Training Accuracy: 31.2500%, Training Loss: 1.5259%\n",
      "Epoch [3/300], Step [3/225], Training Accuracy: 30.7292%, Training Loss: 1.5218%\n",
      "Epoch [3/300], Step [4/225], Training Accuracy: 33.2031%, Training Loss: 1.4858%\n",
      "Epoch [3/300], Step [5/225], Training Accuracy: 32.8125%, Training Loss: 1.5091%\n",
      "Epoch [3/300], Step [6/225], Training Accuracy: 32.2917%, Training Loss: 1.4821%\n",
      "Epoch [3/300], Step [7/225], Training Accuracy: 32.3661%, Training Loss: 1.4763%\n",
      "Epoch [3/300], Step [8/225], Training Accuracy: 31.2500%, Training Loss: 1.4691%\n",
      "Epoch [3/300], Step [9/225], Training Accuracy: 31.5972%, Training Loss: 1.4577%\n",
      "Epoch [3/300], Step [10/225], Training Accuracy: 31.4062%, Training Loss: 1.4582%\n",
      "Epoch [3/300], Step [11/225], Training Accuracy: 30.6818%, Training Loss: 1.4675%\n",
      "Epoch [3/300], Step [12/225], Training Accuracy: 30.7292%, Training Loss: 1.4825%\n",
      "Epoch [3/300], Step [13/225], Training Accuracy: 30.8894%, Training Loss: 1.4771%\n",
      "Epoch [3/300], Step [14/225], Training Accuracy: 30.5804%, Training Loss: 1.4945%\n",
      "Epoch [3/300], Step [15/225], Training Accuracy: 30.6250%, Training Loss: 1.5022%\n",
      "Epoch [3/300], Step [16/225], Training Accuracy: 30.7617%, Training Loss: 1.5106%\n",
      "Epoch [3/300], Step [17/225], Training Accuracy: 30.7904%, Training Loss: 1.5179%\n",
      "Epoch [3/300], Step [18/225], Training Accuracy: 31.3368%, Training Loss: 1.5267%\n",
      "Epoch [3/300], Step [19/225], Training Accuracy: 31.3322%, Training Loss: 1.5296%\n",
      "Epoch [3/300], Step [20/225], Training Accuracy: 30.9375%, Training Loss: 1.5344%\n",
      "Epoch [3/300], Step [21/225], Training Accuracy: 30.8036%, Training Loss: 1.5346%\n",
      "Epoch [3/300], Step [22/225], Training Accuracy: 30.5398%, Training Loss: 1.5351%\n",
      "Epoch [3/300], Step [23/225], Training Accuracy: 30.5707%, Training Loss: 1.5237%\n",
      "Epoch [3/300], Step [24/225], Training Accuracy: 30.3385%, Training Loss: 1.5251%\n",
      "Epoch [3/300], Step [25/225], Training Accuracy: 30.6875%, Training Loss: 1.5252%\n",
      "Epoch [3/300], Step [26/225], Training Accuracy: 30.5288%, Training Loss: 1.5219%\n",
      "Epoch [3/300], Step [27/225], Training Accuracy: 30.3819%, Training Loss: 1.5232%\n",
      "Epoch [3/300], Step [28/225], Training Accuracy: 30.4129%, Training Loss: 1.5220%\n",
      "Epoch [3/300], Step [29/225], Training Accuracy: 30.3341%, Training Loss: 1.5233%\n",
      "Epoch [3/300], Step [30/225], Training Accuracy: 30.5729%, Training Loss: 1.5224%\n",
      "Epoch [3/300], Step [31/225], Training Accuracy: 30.6956%, Training Loss: 1.5198%\n",
      "Epoch [3/300], Step [32/225], Training Accuracy: 30.5664%, Training Loss: 1.5197%\n",
      "Epoch [3/300], Step [33/225], Training Accuracy: 30.5871%, Training Loss: 1.5150%\n",
      "Epoch [3/300], Step [34/225], Training Accuracy: 30.5607%, Training Loss: 1.5165%\n",
      "Epoch [3/300], Step [35/225], Training Accuracy: 30.3571%, Training Loss: 1.5219%\n",
      "Epoch [3/300], Step [36/225], Training Accuracy: 30.2517%, Training Loss: 1.5256%\n",
      "Epoch [3/300], Step [37/225], Training Accuracy: 30.1943%, Training Loss: 1.5272%\n",
      "Epoch [3/300], Step [38/225], Training Accuracy: 30.3454%, Training Loss: 1.5232%\n",
      "Epoch [3/300], Step [39/225], Training Accuracy: 30.2484%, Training Loss: 1.5203%\n",
      "Epoch [3/300], Step [40/225], Training Accuracy: 30.3516%, Training Loss: 1.5241%\n",
      "Epoch [3/300], Step [41/225], Training Accuracy: 30.3354%, Training Loss: 1.5242%\n",
      "Epoch [3/300], Step [42/225], Training Accuracy: 30.4315%, Training Loss: 1.5235%\n",
      "Epoch [3/300], Step [43/225], Training Accuracy: 30.4869%, Training Loss: 1.5203%\n",
      "Epoch [3/300], Step [44/225], Training Accuracy: 30.5043%, Training Loss: 1.5171%\n",
      "Epoch [3/300], Step [45/225], Training Accuracy: 30.5208%, Training Loss: 1.5184%\n",
      "Epoch [3/300], Step [46/225], Training Accuracy: 30.4688%, Training Loss: 1.5143%\n",
      "Epoch [3/300], Step [47/225], Training Accuracy: 30.5519%, Training Loss: 1.5126%\n",
      "Epoch [3/300], Step [48/225], Training Accuracy: 30.4688%, Training Loss: 1.5133%\n",
      "Epoch [3/300], Step [49/225], Training Accuracy: 30.4847%, Training Loss: 1.5107%\n",
      "Epoch [3/300], Step [50/225], Training Accuracy: 30.4062%, Training Loss: 1.5108%\n",
      "Epoch [3/300], Step [51/225], Training Accuracy: 30.6066%, Training Loss: 1.5080%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/300], Step [52/225], Training Accuracy: 30.5589%, Training Loss: 1.5093%\n",
      "Epoch [3/300], Step [53/225], Training Accuracy: 30.5425%, Training Loss: 1.5106%\n",
      "Epoch [3/300], Step [54/225], Training Accuracy: 30.4977%, Training Loss: 1.5120%\n",
      "Epoch [3/300], Step [55/225], Training Accuracy: 30.4830%, Training Loss: 1.5121%\n",
      "Epoch [3/300], Step [56/225], Training Accuracy: 30.3850%, Training Loss: 1.5112%\n",
      "Epoch [3/300], Step [57/225], Training Accuracy: 30.2906%, Training Loss: 1.5094%\n",
      "Epoch [3/300], Step [58/225], Training Accuracy: 30.1994%, Training Loss: 1.5058%\n",
      "Epoch [3/300], Step [59/225], Training Accuracy: 30.0583%, Training Loss: 1.5088%\n",
      "Epoch [3/300], Step [60/225], Training Accuracy: 30.1302%, Training Loss: 1.5063%\n",
      "Epoch [3/300], Step [61/225], Training Accuracy: 30.1742%, Training Loss: 1.5050%\n",
      "Epoch [3/300], Step [62/225], Training Accuracy: 30.2923%, Training Loss: 1.5042%\n",
      "Epoch [3/300], Step [63/225], Training Accuracy: 30.2827%, Training Loss: 1.5021%\n",
      "Epoch [3/300], Step [64/225], Training Accuracy: 30.2490%, Training Loss: 1.5036%\n",
      "Epoch [3/300], Step [65/225], Training Accuracy: 30.3365%, Training Loss: 1.5027%\n",
      "Epoch [3/300], Step [66/225], Training Accuracy: 30.4451%, Training Loss: 1.5005%\n",
      "Epoch [3/300], Step [67/225], Training Accuracy: 30.5271%, Training Loss: 1.4974%\n",
      "Epoch [3/300], Step [68/225], Training Accuracy: 30.5607%, Training Loss: 1.4984%\n",
      "Epoch [3/300], Step [69/225], Training Accuracy: 30.6159%, Training Loss: 1.5006%\n",
      "Epoch [3/300], Step [70/225], Training Accuracy: 30.5580%, Training Loss: 1.5025%\n",
      "Epoch [3/300], Step [71/225], Training Accuracy: 30.4357%, Training Loss: 1.5032%\n",
      "Epoch [3/300], Step [72/225], Training Accuracy: 30.4253%, Training Loss: 1.5021%\n",
      "Epoch [3/300], Step [73/225], Training Accuracy: 30.3510%, Training Loss: 1.5009%\n",
      "Epoch [3/300], Step [74/225], Training Accuracy: 30.5110%, Training Loss: 1.4988%\n",
      "Epoch [3/300], Step [75/225], Training Accuracy: 30.5417%, Training Loss: 1.4969%\n",
      "Epoch [3/300], Step [76/225], Training Accuracy: 30.5304%, Training Loss: 1.4975%\n",
      "Epoch [3/300], Step [77/225], Training Accuracy: 30.4586%, Training Loss: 1.4976%\n",
      "Epoch [3/300], Step [78/225], Training Accuracy: 30.4688%, Training Loss: 1.4976%\n",
      "Epoch [3/300], Step [79/225], Training Accuracy: 30.5380%, Training Loss: 1.4958%\n",
      "Epoch [3/300], Step [80/225], Training Accuracy: 30.4102%, Training Loss: 1.4955%\n",
      "Epoch [3/300], Step [81/225], Training Accuracy: 30.5363%, Training Loss: 1.4948%\n",
      "Epoch [3/300], Step [82/225], Training Accuracy: 30.5259%, Training Loss: 1.4955%\n",
      "Epoch [3/300], Step [83/225], Training Accuracy: 30.4970%, Training Loss: 1.4945%\n",
      "Epoch [3/300], Step [84/225], Training Accuracy: 30.5618%, Training Loss: 1.4940%\n",
      "Epoch [3/300], Step [85/225], Training Accuracy: 30.5515%, Training Loss: 1.4939%\n",
      "Epoch [3/300], Step [86/225], Training Accuracy: 30.5233%, Training Loss: 1.4932%\n",
      "Epoch [3/300], Step [87/225], Training Accuracy: 30.6034%, Training Loss: 1.4924%\n",
      "Epoch [3/300], Step [88/225], Training Accuracy: 30.5043%, Training Loss: 1.4933%\n",
      "Epoch [3/300], Step [89/225], Training Accuracy: 30.3546%, Training Loss: 1.4965%\n",
      "Epoch [3/300], Step [90/225], Training Accuracy: 30.2604%, Training Loss: 1.4983%\n",
      "Epoch [3/300], Step [91/225], Training Accuracy: 30.2541%, Training Loss: 1.4980%\n",
      "Epoch [3/300], Step [92/225], Training Accuracy: 30.2819%, Training Loss: 1.4968%\n",
      "Epoch [3/300], Step [93/225], Training Accuracy: 30.2923%, Training Loss: 1.4972%\n",
      "Epoch [3/300], Step [94/225], Training Accuracy: 30.2859%, Training Loss: 1.4975%\n",
      "Epoch [3/300], Step [95/225], Training Accuracy: 30.2796%, Training Loss: 1.4984%\n",
      "Epoch [3/300], Step [96/225], Training Accuracy: 30.3385%, Training Loss: 1.4973%\n",
      "Epoch [3/300], Step [97/225], Training Accuracy: 30.3157%, Training Loss: 1.4964%\n",
      "Epoch [3/300], Step [98/225], Training Accuracy: 30.3253%, Training Loss: 1.4950%\n",
      "Epoch [3/300], Step [99/225], Training Accuracy: 30.3977%, Training Loss: 1.4935%\n",
      "Epoch [3/300], Step [100/225], Training Accuracy: 30.2969%, Training Loss: 1.4932%\n",
      "Epoch [3/300], Step [101/225], Training Accuracy: 30.3218%, Training Loss: 1.4935%\n",
      "Epoch [3/300], Step [102/225], Training Accuracy: 30.3309%, Training Loss: 1.4930%\n",
      "Epoch [3/300], Step [103/225], Training Accuracy: 30.3701%, Training Loss: 1.4923%\n",
      "Epoch [3/300], Step [104/225], Training Accuracy: 30.4688%, Training Loss: 1.4901%\n",
      "Epoch [3/300], Step [105/225], Training Accuracy: 30.4315%, Training Loss: 1.4902%\n",
      "Epoch [3/300], Step [106/225], Training Accuracy: 30.3950%, Training Loss: 1.4891%\n",
      "Epoch [3/300], Step [107/225], Training Accuracy: 30.4030%, Training Loss: 1.4886%\n",
      "Epoch [3/300], Step [108/225], Training Accuracy: 30.4109%, Training Loss: 1.4890%\n",
      "Epoch [3/300], Step [109/225], Training Accuracy: 30.4472%, Training Loss: 1.4885%\n",
      "Epoch [3/300], Step [110/225], Training Accuracy: 30.5398%, Training Loss: 1.4878%\n",
      "Epoch [3/300], Step [111/225], Training Accuracy: 30.5180%, Training Loss: 1.4882%\n",
      "Epoch [3/300], Step [112/225], Training Accuracy: 30.5664%, Training Loss: 1.4877%\n",
      "Epoch [3/300], Step [113/225], Training Accuracy: 30.5310%, Training Loss: 1.4874%\n",
      "Epoch [3/300], Step [114/225], Training Accuracy: 30.6743%, Training Loss: 1.4852%\n",
      "Epoch [3/300], Step [115/225], Training Accuracy: 30.7609%, Training Loss: 1.4836%\n",
      "Epoch [3/300], Step [116/225], Training Accuracy: 30.7112%, Training Loss: 1.4830%\n",
      "Epoch [3/300], Step [117/225], Training Accuracy: 30.6757%, Training Loss: 1.4833%\n",
      "Epoch [3/300], Step [118/225], Training Accuracy: 30.7203%, Training Loss: 1.4822%\n",
      "Epoch [3/300], Step [119/225], Training Accuracy: 30.7773%, Training Loss: 1.4816%\n",
      "Epoch [3/300], Step [120/225], Training Accuracy: 30.8724%, Training Loss: 1.4804%\n",
      "Epoch [3/300], Step [121/225], Training Accuracy: 30.7851%, Training Loss: 1.4818%\n",
      "Epoch [3/300], Step [122/225], Training Accuracy: 30.7377%, Training Loss: 1.4820%\n",
      "Epoch [3/300], Step [123/225], Training Accuracy: 30.7292%, Training Loss: 1.4815%\n",
      "Epoch [3/300], Step [124/225], Training Accuracy: 30.6704%, Training Loss: 1.4838%\n",
      "Epoch [3/300], Step [125/225], Training Accuracy: 30.6750%, Training Loss: 1.4845%\n",
      "Epoch [3/300], Step [126/225], Training Accuracy: 30.6672%, Training Loss: 1.4844%\n",
      "Epoch [3/300], Step [127/225], Training Accuracy: 30.6225%, Training Loss: 1.4859%\n",
      "Epoch [3/300], Step [128/225], Training Accuracy: 30.6396%, Training Loss: 1.4859%\n",
      "Epoch [3/300], Step [129/225], Training Accuracy: 30.5838%, Training Loss: 1.4855%\n",
      "Epoch [3/300], Step [130/225], Training Accuracy: 30.6250%, Training Loss: 1.4847%\n",
      "Epoch [3/300], Step [131/225], Training Accuracy: 30.6536%, Training Loss: 1.4839%\n",
      "Epoch [3/300], Step [132/225], Training Accuracy: 30.7292%, Training Loss: 1.4828%\n",
      "Epoch [3/300], Step [133/225], Training Accuracy: 30.7918%, Training Loss: 1.4845%\n",
      "Epoch [3/300], Step [134/225], Training Accuracy: 30.7836%, Training Loss: 1.4838%\n",
      "Epoch [3/300], Step [135/225], Training Accuracy: 30.6944%, Training Loss: 1.4835%\n",
      "Epoch [3/300], Step [136/225], Training Accuracy: 30.7675%, Training Loss: 1.4819%\n",
      "Epoch [3/300], Step [137/225], Training Accuracy: 30.8166%, Training Loss: 1.4807%\n",
      "Epoch [3/300], Step [138/225], Training Accuracy: 30.8764%, Training Loss: 1.4796%\n",
      "Epoch [3/300], Step [139/225], Training Accuracy: 30.8116%, Training Loss: 1.4794%\n",
      "Epoch [3/300], Step [140/225], Training Accuracy: 30.8817%, Training Loss: 1.4788%\n",
      "Epoch [3/300], Step [141/225], Training Accuracy: 30.9619%, Training Loss: 1.4774%\n",
      "Epoch [3/300], Step [142/225], Training Accuracy: 30.9419%, Training Loss: 1.4769%\n",
      "Epoch [3/300], Step [143/225], Training Accuracy: 30.9768%, Training Loss: 1.4757%\n",
      "Epoch [3/300], Step [144/225], Training Accuracy: 30.9570%, Training Loss: 1.4754%\n",
      "Epoch [3/300], Step [145/225], Training Accuracy: 30.9914%, Training Loss: 1.4747%\n",
      "Epoch [3/300], Step [146/225], Training Accuracy: 31.0146%, Training Loss: 1.4741%\n",
      "Epoch [3/300], Step [147/225], Training Accuracy: 31.0906%, Training Loss: 1.4734%\n",
      "Epoch [3/300], Step [148/225], Training Accuracy: 31.0705%, Training Loss: 1.4729%\n",
      "Epoch [3/300], Step [149/225], Training Accuracy: 31.0822%, Training Loss: 1.4730%\n",
      "Epoch [3/300], Step [150/225], Training Accuracy: 31.0833%, Training Loss: 1.4734%\n",
      "Epoch [3/300], Step [151/225], Training Accuracy: 31.1362%, Training Loss: 1.4724%\n",
      "Epoch [3/300], Step [152/225], Training Accuracy: 31.1575%, Training Loss: 1.4721%\n",
      "Epoch [3/300], Step [153/225], Training Accuracy: 31.1785%, Training Loss: 1.4713%\n",
      "Epoch [3/300], Step [154/225], Training Accuracy: 31.1790%, Training Loss: 1.4709%\n",
      "Epoch [3/300], Step [155/225], Training Accuracy: 31.1593%, Training Loss: 1.4707%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/300], Step [156/225], Training Accuracy: 31.1699%, Training Loss: 1.4701%\n",
      "Epoch [3/300], Step [157/225], Training Accuracy: 31.1803%, Training Loss: 1.4696%\n",
      "Epoch [3/300], Step [158/225], Training Accuracy: 31.1907%, Training Loss: 1.4696%\n",
      "Epoch [3/300], Step [159/225], Training Accuracy: 31.2402%, Training Loss: 1.4685%\n",
      "Epoch [3/300], Step [160/225], Training Accuracy: 31.2109%, Training Loss: 1.4676%\n",
      "Epoch [3/300], Step [161/225], Training Accuracy: 31.1918%, Training Loss: 1.4672%\n",
      "Epoch [3/300], Step [162/225], Training Accuracy: 31.1825%, Training Loss: 1.4674%\n",
      "Epoch [3/300], Step [163/225], Training Accuracy: 31.2212%, Training Loss: 1.4668%\n",
      "Epoch [3/300], Step [164/225], Training Accuracy: 31.2119%, Training Loss: 1.4665%\n",
      "Epoch [3/300], Step [165/225], Training Accuracy: 31.1553%, Training Loss: 1.4672%\n",
      "Epoch [3/300], Step [166/225], Training Accuracy: 31.1935%, Training Loss: 1.4667%\n",
      "Epoch [3/300], Step [167/225], Training Accuracy: 31.2032%, Training Loss: 1.4663%\n",
      "Epoch [3/300], Step [168/225], Training Accuracy: 31.2035%, Training Loss: 1.4657%\n",
      "Epoch [3/300], Step [169/225], Training Accuracy: 31.2315%, Training Loss: 1.4649%\n",
      "Epoch [3/300], Step [170/225], Training Accuracy: 31.2408%, Training Loss: 1.4649%\n",
      "Epoch [3/300], Step [171/225], Training Accuracy: 31.2683%, Training Loss: 1.4650%\n",
      "Epoch [3/300], Step [172/225], Training Accuracy: 31.2954%, Training Loss: 1.4644%\n",
      "Epoch [3/300], Step [173/225], Training Accuracy: 31.3313%, Training Loss: 1.4640%\n",
      "Epoch [3/300], Step [174/225], Training Accuracy: 31.3488%, Training Loss: 1.4638%\n",
      "Epoch [3/300], Step [175/225], Training Accuracy: 31.3571%, Training Loss: 1.4640%\n",
      "Epoch [3/300], Step [176/225], Training Accuracy: 31.3477%, Training Loss: 1.4633%\n",
      "Epoch [3/300], Step [177/225], Training Accuracy: 31.3383%, Training Loss: 1.4637%\n",
      "Epoch [3/300], Step [178/225], Training Accuracy: 31.3202%, Training Loss: 1.4631%\n",
      "Epoch [3/300], Step [179/225], Training Accuracy: 31.3809%, Training Loss: 1.4620%\n",
      "Epoch [3/300], Step [180/225], Training Accuracy: 31.4323%, Training Loss: 1.4611%\n",
      "Epoch [3/300], Step [181/225], Training Accuracy: 31.4399%, Training Loss: 1.4610%\n",
      "Epoch [3/300], Step [182/225], Training Accuracy: 31.5161%, Training Loss: 1.4601%\n",
      "Epoch [3/300], Step [183/225], Training Accuracy: 31.4976%, Training Loss: 1.4594%\n",
      "Epoch [3/300], Step [184/225], Training Accuracy: 31.5132%, Training Loss: 1.4586%\n",
      "Epoch [3/300], Step [185/225], Training Accuracy: 31.5118%, Training Loss: 1.4582%\n",
      "Epoch [3/300], Step [186/225], Training Accuracy: 31.5272%, Training Loss: 1.4582%\n",
      "Epoch [3/300], Step [187/225], Training Accuracy: 31.5592%, Training Loss: 1.4576%\n",
      "Epoch [3/300], Step [188/225], Training Accuracy: 31.5492%, Training Loss: 1.4573%\n",
      "Epoch [3/300], Step [189/225], Training Accuracy: 31.5394%, Training Loss: 1.4563%\n",
      "Epoch [3/300], Step [190/225], Training Accuracy: 31.5214%, Training Loss: 1.4561%\n",
      "Epoch [3/300], Step [191/225], Training Accuracy: 31.4872%, Training Loss: 1.4565%\n",
      "Epoch [3/300], Step [192/225], Training Accuracy: 31.4779%, Training Loss: 1.4565%\n",
      "Epoch [3/300], Step [193/225], Training Accuracy: 31.4443%, Training Loss: 1.4562%\n",
      "Epoch [3/300], Step [194/225], Training Accuracy: 31.4594%, Training Loss: 1.4553%\n",
      "Epoch [3/300], Step [195/225], Training Accuracy: 31.4503%, Training Loss: 1.4551%\n",
      "Epoch [3/300], Step [196/225], Training Accuracy: 31.4334%, Training Loss: 1.4557%\n",
      "Epoch [3/300], Step [197/225], Training Accuracy: 31.4086%, Training Loss: 1.4554%\n",
      "Epoch [3/300], Step [198/225], Training Accuracy: 31.4394%, Training Loss: 1.4545%\n",
      "Epoch [3/300], Step [199/225], Training Accuracy: 31.4306%, Training Loss: 1.4549%\n",
      "Epoch [3/300], Step [200/225], Training Accuracy: 31.4219%, Training Loss: 1.4553%\n",
      "Epoch [3/300], Step [201/225], Training Accuracy: 31.4132%, Training Loss: 1.4549%\n",
      "Epoch [3/300], Step [202/225], Training Accuracy: 31.4202%, Training Loss: 1.4549%\n",
      "Epoch [3/300], Step [203/225], Training Accuracy: 31.3962%, Training Loss: 1.4546%\n",
      "Epoch [3/300], Step [204/225], Training Accuracy: 31.4108%, Training Loss: 1.4541%\n",
      "Epoch [3/300], Step [205/225], Training Accuracy: 31.3720%, Training Loss: 1.4554%\n",
      "Epoch [3/300], Step [206/225], Training Accuracy: 31.3562%, Training Loss: 1.4552%\n",
      "Epoch [3/300], Step [207/225], Training Accuracy: 31.3557%, Training Loss: 1.4550%\n",
      "Epoch [3/300], Step [208/225], Training Accuracy: 31.3477%, Training Loss: 1.4550%\n",
      "Epoch [3/300], Step [209/225], Training Accuracy: 31.3920%, Training Loss: 1.4546%\n",
      "Epoch [3/300], Step [210/225], Training Accuracy: 31.4137%, Training Loss: 1.4539%\n",
      "Epoch [3/300], Step [211/225], Training Accuracy: 31.4648%, Training Loss: 1.4533%\n",
      "Epoch [3/300], Step [212/225], Training Accuracy: 31.4416%, Training Loss: 1.4533%\n",
      "Epoch [3/300], Step [213/225], Training Accuracy: 31.4114%, Training Loss: 1.4548%\n",
      "Epoch [3/300], Step [214/225], Training Accuracy: 31.4106%, Training Loss: 1.4546%\n",
      "Epoch [3/300], Step [215/225], Training Accuracy: 31.4099%, Training Loss: 1.4554%\n",
      "Epoch [3/300], Step [216/225], Training Accuracy: 31.4453%, Training Loss: 1.4563%\n",
      "Epoch [3/300], Step [217/225], Training Accuracy: 31.5092%, Training Loss: 1.4558%\n",
      "Epoch [3/300], Step [218/225], Training Accuracy: 31.4937%, Training Loss: 1.4572%\n",
      "Epoch [3/300], Step [219/225], Training Accuracy: 31.4640%, Training Loss: 1.4586%\n",
      "Epoch [3/300], Step [220/225], Training Accuracy: 31.4418%, Training Loss: 1.4590%\n",
      "Epoch [3/300], Step [221/225], Training Accuracy: 31.4338%, Training Loss: 1.4594%\n",
      "Epoch [3/300], Step [222/225], Training Accuracy: 31.4752%, Training Loss: 1.4589%\n",
      "Epoch [3/300], Step [223/225], Training Accuracy: 31.4602%, Training Loss: 1.4593%\n",
      "Epoch [3/300], Step [224/225], Training Accuracy: 31.4244%, Training Loss: 1.4593%\n",
      "Epoch [3/300], Step [225/225], Training Accuracy: 31.4272%, Training Loss: 1.4590%\n",
      "Epoch [4/300], Step [1/225], Training Accuracy: 31.2500%, Training Loss: 1.6024%\n",
      "Epoch [4/300], Step [2/225], Training Accuracy: 32.0312%, Training Loss: 1.6026%\n",
      "Epoch [4/300], Step [3/225], Training Accuracy: 34.3750%, Training Loss: 1.5406%\n",
      "Epoch [4/300], Step [4/225], Training Accuracy: 35.5469%, Training Loss: 1.5045%\n",
      "Epoch [4/300], Step [5/225], Training Accuracy: 35.3125%, Training Loss: 1.5246%\n",
      "Epoch [4/300], Step [6/225], Training Accuracy: 35.9375%, Training Loss: 1.5375%\n",
      "Epoch [4/300], Step [7/225], Training Accuracy: 34.8214%, Training Loss: 1.5088%\n",
      "Epoch [4/300], Step [8/225], Training Accuracy: 34.7656%, Training Loss: 1.4951%\n",
      "Epoch [4/300], Step [9/225], Training Accuracy: 35.2431%, Training Loss: 1.4799%\n",
      "Epoch [4/300], Step [10/225], Training Accuracy: 34.6875%, Training Loss: 1.4834%\n",
      "Epoch [4/300], Step [11/225], Training Accuracy: 34.2330%, Training Loss: 1.4818%\n",
      "Epoch [4/300], Step [12/225], Training Accuracy: 34.5052%, Training Loss: 1.4788%\n",
      "Epoch [4/300], Step [13/225], Training Accuracy: 33.8942%, Training Loss: 1.4744%\n",
      "Epoch [4/300], Step [14/225], Training Accuracy: 33.2589%, Training Loss: 1.4736%\n",
      "Epoch [4/300], Step [15/225], Training Accuracy: 33.0208%, Training Loss: 1.4743%\n",
      "Epoch [4/300], Step [16/225], Training Accuracy: 32.7148%, Training Loss: 1.4730%\n",
      "Epoch [4/300], Step [17/225], Training Accuracy: 32.9044%, Training Loss: 1.4678%\n",
      "Epoch [4/300], Step [18/225], Training Accuracy: 32.6389%, Training Loss: 1.4703%\n",
      "Epoch [4/300], Step [19/225], Training Accuracy: 32.9770%, Training Loss: 1.4666%\n",
      "Epoch [4/300], Step [20/225], Training Accuracy: 33.2812%, Training Loss: 1.4643%\n",
      "Epoch [4/300], Step [21/225], Training Accuracy: 32.9613%, Training Loss: 1.4706%\n",
      "Epoch [4/300], Step [22/225], Training Accuracy: 33.0966%, Training Loss: 1.4695%\n",
      "Epoch [4/300], Step [23/225], Training Accuracy: 32.9484%, Training Loss: 1.4663%\n",
      "Epoch [4/300], Step [24/225], Training Accuracy: 32.8776%, Training Loss: 1.4683%\n",
      "Epoch [4/300], Step [25/225], Training Accuracy: 32.6250%, Training Loss: 1.4753%\n",
      "Epoch [4/300], Step [26/225], Training Accuracy: 32.5721%, Training Loss: 1.4701%\n",
      "Epoch [4/300], Step [27/225], Training Accuracy: 32.1759%, Training Loss: 1.4694%\n",
      "Epoch [4/300], Step [28/225], Training Accuracy: 32.1429%, Training Loss: 1.4701%\n",
      "Epoch [4/300], Step [29/225], Training Accuracy: 32.4353%, Training Loss: 1.4648%\n",
      "Epoch [4/300], Step [30/225], Training Accuracy: 32.3438%, Training Loss: 1.4635%\n",
      "Epoch [4/300], Step [31/225], Training Accuracy: 32.4093%, Training Loss: 1.4605%\n",
      "Epoch [4/300], Step [32/225], Training Accuracy: 32.6172%, Training Loss: 1.4553%\n",
      "Epoch [4/300], Step [33/225], Training Accuracy: 32.7652%, Training Loss: 1.4513%\n",
      "Epoch [4/300], Step [34/225], Training Accuracy: 32.5368%, Training Loss: 1.4499%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/300], Step [35/225], Training Accuracy: 32.1429%, Training Loss: 1.4515%\n",
      "Epoch [4/300], Step [36/225], Training Accuracy: 31.9878%, Training Loss: 1.4543%\n",
      "Epoch [4/300], Step [37/225], Training Accuracy: 31.9679%, Training Loss: 1.4550%\n",
      "Epoch [4/300], Step [38/225], Training Accuracy: 32.0724%, Training Loss: 1.4541%\n",
      "Epoch [4/300], Step [39/225], Training Accuracy: 32.0112%, Training Loss: 1.4506%\n",
      "Epoch [4/300], Step [40/225], Training Accuracy: 31.9922%, Training Loss: 1.4493%\n",
      "Epoch [4/300], Step [41/225], Training Accuracy: 31.8598%, Training Loss: 1.4475%\n",
      "Epoch [4/300], Step [42/225], Training Accuracy: 31.9196%, Training Loss: 1.4473%\n",
      "Epoch [4/300], Step [43/225], Training Accuracy: 32.3038%, Training Loss: 1.4437%\n",
      "Epoch [4/300], Step [44/225], Training Accuracy: 32.3153%, Training Loss: 1.4415%\n",
      "Epoch [4/300], Step [45/225], Training Accuracy: 32.3611%, Training Loss: 1.4401%\n",
      "Epoch [4/300], Step [46/225], Training Accuracy: 32.4728%, Training Loss: 1.4366%\n",
      "Epoch [4/300], Step [47/225], Training Accuracy: 32.5798%, Training Loss: 1.4380%\n",
      "Epoch [4/300], Step [48/225], Training Accuracy: 32.5846%, Training Loss: 1.4383%\n",
      "Epoch [4/300], Step [49/225], Training Accuracy: 32.7487%, Training Loss: 1.4367%\n",
      "Epoch [4/300], Step [50/225], Training Accuracy: 32.5312%, Training Loss: 1.4386%\n",
      "Epoch [4/300], Step [51/225], Training Accuracy: 32.5674%, Training Loss: 1.4387%\n",
      "Epoch [4/300], Step [52/225], Training Accuracy: 32.5721%, Training Loss: 1.4383%\n",
      "Epoch [4/300], Step [53/225], Training Accuracy: 32.5767%, Training Loss: 1.4371%\n",
      "Epoch [4/300], Step [54/225], Training Accuracy: 32.5231%, Training Loss: 1.4370%\n",
      "Epoch [4/300], Step [55/225], Training Accuracy: 32.6420%, Training Loss: 1.4364%\n",
      "Epoch [4/300], Step [56/225], Training Accuracy: 32.8125%, Training Loss: 1.4339%\n",
      "Epoch [4/300], Step [57/225], Training Accuracy: 32.9221%, Training Loss: 1.4321%\n",
      "Epoch [4/300], Step [58/225], Training Accuracy: 33.0011%, Training Loss: 1.4297%\n",
      "Epoch [4/300], Step [59/225], Training Accuracy: 32.8390%, Training Loss: 1.4296%\n",
      "Epoch [4/300], Step [60/225], Training Accuracy: 32.9427%, Training Loss: 1.4279%\n",
      "Epoch [4/300], Step [61/225], Training Accuracy: 33.0174%, Training Loss: 1.4258%\n",
      "Epoch [4/300], Step [62/225], Training Accuracy: 33.0645%, Training Loss: 1.4243%\n",
      "Epoch [4/300], Step [63/225], Training Accuracy: 33.0109%, Training Loss: 1.4236%\n",
      "Epoch [4/300], Step [64/225], Training Accuracy: 32.9834%, Training Loss: 1.4236%\n",
      "Epoch [4/300], Step [65/225], Training Accuracy: 32.9808%, Training Loss: 1.4224%\n",
      "Epoch [4/300], Step [66/225], Training Accuracy: 33.0492%, Training Loss: 1.4205%\n",
      "Epoch [4/300], Step [67/225], Training Accuracy: 33.1157%, Training Loss: 1.4185%\n",
      "Epoch [4/300], Step [68/225], Training Accuracy: 33.1112%, Training Loss: 1.4187%\n",
      "Epoch [4/300], Step [69/225], Training Accuracy: 33.2654%, Training Loss: 1.4183%\n",
      "Epoch [4/300], Step [70/225], Training Accuracy: 33.2143%, Training Loss: 1.4182%\n",
      "Epoch [4/300], Step [71/225], Training Accuracy: 33.1206%, Training Loss: 1.4185%\n",
      "Epoch [4/300], Step [72/225], Training Accuracy: 33.0512%, Training Loss: 1.4186%\n",
      "Epoch [4/300], Step [73/225], Training Accuracy: 33.0479%, Training Loss: 1.4187%\n",
      "Epoch [4/300], Step [74/225], Training Accuracy: 33.0870%, Training Loss: 1.4179%\n",
      "Epoch [4/300], Step [75/225], Training Accuracy: 33.1042%, Training Loss: 1.4160%\n",
      "Epoch [4/300], Step [76/225], Training Accuracy: 33.0798%, Training Loss: 1.4167%\n",
      "Epoch [4/300], Step [77/225], Training Accuracy: 33.1372%, Training Loss: 1.4159%\n",
      "Epoch [4/300], Step [78/225], Training Accuracy: 33.1530%, Training Loss: 1.4159%\n",
      "Epoch [4/300], Step [79/225], Training Accuracy: 33.1290%, Training Loss: 1.4163%\n",
      "Epoch [4/300], Step [80/225], Training Accuracy: 32.9883%, Training Loss: 1.4161%\n",
      "Epoch [4/300], Step [81/225], Training Accuracy: 32.9668%, Training Loss: 1.4151%\n",
      "Epoch [4/300], Step [82/225], Training Accuracy: 33.0030%, Training Loss: 1.4147%\n",
      "Epoch [4/300], Step [83/225], Training Accuracy: 33.0572%, Training Loss: 1.4144%\n",
      "Epoch [4/300], Step [84/225], Training Accuracy: 33.1101%, Training Loss: 1.4143%\n",
      "Epoch [4/300], Step [85/225], Training Accuracy: 33.1250%, Training Loss: 1.4147%\n",
      "Epoch [4/300], Step [86/225], Training Accuracy: 33.1577%, Training Loss: 1.4137%\n",
      "Epoch [4/300], Step [87/225], Training Accuracy: 33.2076%, Training Loss: 1.4120%\n",
      "Epoch [4/300], Step [88/225], Training Accuracy: 33.1854%, Training Loss: 1.4110%\n",
      "Epoch [4/300], Step [89/225], Training Accuracy: 33.1110%, Training Loss: 1.4129%\n",
      "Epoch [4/300], Step [90/225], Training Accuracy: 33.0729%, Training Loss: 1.4129%\n",
      "Epoch [4/300], Step [91/225], Training Accuracy: 32.9842%, Training Loss: 1.4130%\n",
      "Epoch [4/300], Step [92/225], Training Accuracy: 33.0333%, Training Loss: 1.4118%\n",
      "Epoch [4/300], Step [93/225], Training Accuracy: 33.0813%, Training Loss: 1.4116%\n",
      "Epoch [4/300], Step [94/225], Training Accuracy: 33.1117%, Training Loss: 1.4096%\n",
      "Epoch [4/300], Step [95/225], Training Accuracy: 33.0099%, Training Loss: 1.4103%\n",
      "Epoch [4/300], Step [96/225], Training Accuracy: 33.0078%, Training Loss: 1.4089%\n",
      "Epoch [4/300], Step [97/225], Training Accuracy: 33.1024%, Training Loss: 1.4092%\n",
      "Epoch [4/300], Step [98/225], Training Accuracy: 33.1633%, Training Loss: 1.4086%\n",
      "Epoch [4/300], Step [99/225], Training Accuracy: 33.2386%, Training Loss: 1.4072%\n",
      "Epoch [4/300], Step [100/225], Training Accuracy: 33.2500%, Training Loss: 1.4065%\n",
      "Epoch [4/300], Step [101/225], Training Accuracy: 33.3075%, Training Loss: 1.4065%\n",
      "Epoch [4/300], Step [102/225], Training Accuracy: 33.1801%, Training Loss: 1.4068%\n",
      "Epoch [4/300], Step [103/225], Training Accuracy: 33.2069%, Training Loss: 1.4064%\n",
      "Epoch [4/300], Step [104/225], Training Accuracy: 33.2933%, Training Loss: 1.4044%\n",
      "Epoch [4/300], Step [105/225], Training Accuracy: 33.3780%, Training Loss: 1.4042%\n",
      "Epoch [4/300], Step [106/225], Training Accuracy: 33.2400%, Training Loss: 1.4039%\n",
      "Epoch [4/300], Step [107/225], Training Accuracy: 33.2506%, Training Loss: 1.4030%\n",
      "Epoch [4/300], Step [108/225], Training Accuracy: 33.2176%, Training Loss: 1.4028%\n",
      "Epoch [4/300], Step [109/225], Training Accuracy: 33.3142%, Training Loss: 1.4023%\n",
      "Epoch [4/300], Step [110/225], Training Accuracy: 33.3239%, Training Loss: 1.4016%\n",
      "Epoch [4/300], Step [111/225], Training Accuracy: 33.3052%, Training Loss: 1.4012%\n",
      "Epoch [4/300], Step [112/225], Training Accuracy: 33.3147%, Training Loss: 1.4019%\n",
      "Epoch [4/300], Step [113/225], Training Accuracy: 33.2412%, Training Loss: 1.4019%\n",
      "Epoch [4/300], Step [114/225], Training Accuracy: 33.3607%, Training Loss: 1.4001%\n",
      "Epoch [4/300], Step [115/225], Training Accuracy: 33.3424%, Training Loss: 1.3993%\n",
      "Epoch [4/300], Step [116/225], Training Accuracy: 33.3648%, Training Loss: 1.3986%\n",
      "Epoch [4/300], Step [117/225], Training Accuracy: 33.2799%, Training Loss: 1.3995%\n",
      "Epoch [4/300], Step [118/225], Training Accuracy: 33.3157%, Training Loss: 1.3984%\n",
      "Epoch [4/300], Step [119/225], Training Accuracy: 33.3114%, Training Loss: 1.3977%\n",
      "Epoch [4/300], Step [120/225], Training Accuracy: 33.2943%, Training Loss: 1.3982%\n",
      "Epoch [4/300], Step [121/225], Training Accuracy: 33.2257%, Training Loss: 1.3991%\n",
      "Epoch [4/300], Step [122/225], Training Accuracy: 33.2736%, Training Loss: 1.3986%\n",
      "Epoch [4/300], Step [123/225], Training Accuracy: 33.2952%, Training Loss: 1.3986%\n",
      "Epoch [4/300], Step [124/225], Training Accuracy: 33.2787%, Training Loss: 1.3998%\n",
      "Epoch [4/300], Step [125/225], Training Accuracy: 33.3375%, Training Loss: 1.4000%\n",
      "Epoch [4/300], Step [126/225], Training Accuracy: 33.2961%, Training Loss: 1.3995%\n",
      "Epoch [4/300], Step [127/225], Training Accuracy: 33.2308%, Training Loss: 1.4005%\n",
      "Epoch [4/300], Step [128/225], Training Accuracy: 33.2520%, Training Loss: 1.3998%\n",
      "Epoch [4/300], Step [129/225], Training Accuracy: 33.2243%, Training Loss: 1.3996%\n",
      "Epoch [4/300], Step [130/225], Training Accuracy: 33.2212%, Training Loss: 1.4001%\n",
      "Epoch [4/300], Step [131/225], Training Accuracy: 33.2300%, Training Loss: 1.3999%\n",
      "Epoch [4/300], Step [132/225], Training Accuracy: 33.2741%, Training Loss: 1.3990%\n",
      "Epoch [4/300], Step [133/225], Training Accuracy: 33.2589%, Training Loss: 1.3993%\n",
      "Epoch [4/300], Step [134/225], Training Accuracy: 33.1623%, Training Loss: 1.3994%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/300], Step [135/225], Training Accuracy: 33.2060%, Training Loss: 1.3999%\n",
      "Epoch [4/300], Step [136/225], Training Accuracy: 33.2376%, Training Loss: 1.3989%\n",
      "Epoch [4/300], Step [137/225], Training Accuracy: 33.3029%, Training Loss: 1.3977%\n",
      "Epoch [4/300], Step [138/225], Training Accuracy: 33.3447%, Training Loss: 1.3974%\n",
      "Epoch [4/300], Step [139/225], Training Accuracy: 33.2621%, Training Loss: 1.3984%\n",
      "Epoch [4/300], Step [140/225], Training Accuracy: 33.3147%, Training Loss: 1.3993%\n",
      "Epoch [4/300], Step [141/225], Training Accuracy: 33.4109%, Training Loss: 1.3982%\n",
      "Epoch [4/300], Step [142/225], Training Accuracy: 33.4727%, Training Loss: 1.3973%\n",
      "Epoch [4/300], Step [143/225], Training Accuracy: 33.4353%, Training Loss: 1.3965%\n",
      "Epoch [4/300], Step [144/225], Training Accuracy: 33.4527%, Training Loss: 1.3971%\n",
      "Epoch [4/300], Step [145/225], Training Accuracy: 33.4267%, Training Loss: 1.3972%\n",
      "Epoch [4/300], Step [146/225], Training Accuracy: 33.4011%, Training Loss: 1.3969%\n",
      "Epoch [4/300], Step [147/225], Training Accuracy: 33.4821%, Training Loss: 1.3961%\n",
      "Epoch [4/300], Step [148/225], Training Accuracy: 33.5093%, Training Loss: 1.3955%\n",
      "Epoch [4/300], Step [149/225], Training Accuracy: 33.5151%, Training Loss: 1.3952%\n",
      "Epoch [4/300], Step [150/225], Training Accuracy: 33.5417%, Training Loss: 1.3959%\n",
      "Epoch [4/300], Step [151/225], Training Accuracy: 33.5679%, Training Loss: 1.3950%\n",
      "Epoch [4/300], Step [152/225], Training Accuracy: 33.5526%, Training Loss: 1.3947%\n",
      "Epoch [4/300], Step [153/225], Training Accuracy: 33.5376%, Training Loss: 1.3953%\n",
      "Epoch [4/300], Step [154/225], Training Accuracy: 33.5227%, Training Loss: 1.3951%\n",
      "Epoch [4/300], Step [155/225], Training Accuracy: 33.5282%, Training Loss: 1.3950%\n",
      "Epoch [4/300], Step [156/225], Training Accuracy: 33.5236%, Training Loss: 1.3949%\n",
      "Epoch [4/300], Step [157/225], Training Accuracy: 33.4992%, Training Loss: 1.3952%\n",
      "Epoch [4/300], Step [158/225], Training Accuracy: 33.4751%, Training Loss: 1.3948%\n",
      "Epoch [4/300], Step [159/225], Training Accuracy: 33.4513%, Training Loss: 1.3950%\n",
      "Epoch [4/300], Step [160/225], Training Accuracy: 33.4277%, Training Loss: 1.3944%\n",
      "Epoch [4/300], Step [161/225], Training Accuracy: 33.4627%, Training Loss: 1.3936%\n",
      "Epoch [4/300], Step [162/225], Training Accuracy: 33.4394%, Training Loss: 1.3937%\n",
      "Epoch [4/300], Step [163/225], Training Accuracy: 33.4835%, Training Loss: 1.3933%\n",
      "Epoch [4/300], Step [164/225], Training Accuracy: 33.4699%, Training Loss: 1.3942%\n",
      "Epoch [4/300], Step [165/225], Training Accuracy: 33.4375%, Training Loss: 1.3956%\n",
      "Epoch [4/300], Step [166/225], Training Accuracy: 33.4714%, Training Loss: 1.3954%\n",
      "Epoch [4/300], Step [167/225], Training Accuracy: 33.4674%, Training Loss: 1.3952%\n",
      "Epoch [4/300], Step [168/225], Training Accuracy: 33.4821%, Training Loss: 1.3945%\n",
      "Epoch [4/300], Step [169/225], Training Accuracy: 33.4967%, Training Loss: 1.3938%\n",
      "Epoch [4/300], Step [170/225], Training Accuracy: 33.5294%, Training Loss: 1.3938%\n",
      "Epoch [4/300], Step [171/225], Training Accuracy: 33.5344%, Training Loss: 1.3937%\n",
      "Epoch [4/300], Step [172/225], Training Accuracy: 33.4847%, Training Loss: 1.3933%\n",
      "Epoch [4/300], Step [173/225], Training Accuracy: 33.4176%, Training Loss: 1.3930%\n",
      "Epoch [4/300], Step [174/225], Training Accuracy: 33.4231%, Training Loss: 1.3927%\n",
      "Epoch [4/300], Step [175/225], Training Accuracy: 33.4107%, Training Loss: 1.3933%\n",
      "Epoch [4/300], Step [176/225], Training Accuracy: 33.4073%, Training Loss: 1.3928%\n",
      "Epoch [4/300], Step [177/225], Training Accuracy: 33.4481%, Training Loss: 1.3922%\n",
      "Epoch [4/300], Step [178/225], Training Accuracy: 33.4533%, Training Loss: 1.3917%\n",
      "Epoch [4/300], Step [179/225], Training Accuracy: 33.4497%, Training Loss: 1.3916%\n",
      "Epoch [4/300], Step [180/225], Training Accuracy: 33.5503%, Training Loss: 1.3908%\n",
      "Epoch [4/300], Step [181/225], Training Accuracy: 33.5549%, Training Loss: 1.3909%\n",
      "Epoch [4/300], Step [182/225], Training Accuracy: 33.6367%, Training Loss: 1.3900%\n",
      "Epoch [4/300], Step [183/225], Training Accuracy: 33.6407%, Training Loss: 1.3898%\n",
      "Epoch [4/300], Step [184/225], Training Accuracy: 33.6617%, Training Loss: 1.3891%\n",
      "Epoch [4/300], Step [185/225], Training Accuracy: 33.6571%, Training Loss: 1.3889%\n",
      "Epoch [4/300], Step [186/225], Training Accuracy: 33.6694%, Training Loss: 1.3889%\n",
      "Epoch [4/300], Step [187/225], Training Accuracy: 33.7066%, Training Loss: 1.3883%\n",
      "Epoch [4/300], Step [188/225], Training Accuracy: 33.7101%, Training Loss: 1.3883%\n",
      "Epoch [4/300], Step [189/225], Training Accuracy: 33.7219%, Training Loss: 1.3875%\n",
      "Epoch [4/300], Step [190/225], Training Accuracy: 33.6678%, Training Loss: 1.3877%\n",
      "Epoch [4/300], Step [191/225], Training Accuracy: 33.6387%, Training Loss: 1.3880%\n",
      "Epoch [4/300], Step [192/225], Training Accuracy: 33.6344%, Training Loss: 1.3878%\n",
      "Epoch [4/300], Step [193/225], Training Accuracy: 33.6383%, Training Loss: 1.3875%\n",
      "Epoch [4/300], Step [194/225], Training Accuracy: 33.6179%, Training Loss: 1.3875%\n",
      "Epoch [4/300], Step [195/225], Training Accuracy: 33.6298%, Training Loss: 1.3874%\n",
      "Epoch [4/300], Step [196/225], Training Accuracy: 33.6416%, Training Loss: 1.3879%\n",
      "Epoch [4/300], Step [197/225], Training Accuracy: 33.5977%, Training Loss: 1.3885%\n",
      "Epoch [4/300], Step [198/225], Training Accuracy: 33.5543%, Training Loss: 1.3881%\n",
      "Epoch [4/300], Step [199/225], Training Accuracy: 33.5349%, Training Loss: 1.3879%\n",
      "Epoch [4/300], Step [200/225], Training Accuracy: 33.5312%, Training Loss: 1.3877%\n",
      "Epoch [4/300], Step [201/225], Training Accuracy: 33.5588%, Training Loss: 1.3877%\n",
      "Epoch [4/300], Step [202/225], Training Accuracy: 33.5628%, Training Loss: 1.3874%\n",
      "Epoch [4/300], Step [203/225], Training Accuracy: 33.5360%, Training Loss: 1.3879%\n",
      "Epoch [4/300], Step [204/225], Training Accuracy: 33.5555%, Training Loss: 1.3876%\n",
      "Epoch [4/300], Step [205/225], Training Accuracy: 33.5671%, Training Loss: 1.3872%\n",
      "Epoch [4/300], Step [206/225], Training Accuracy: 33.5482%, Training Loss: 1.3869%\n",
      "Epoch [4/300], Step [207/225], Training Accuracy: 33.5371%, Training Loss: 1.3870%\n",
      "Epoch [4/300], Step [208/225], Training Accuracy: 33.5862%, Training Loss: 1.3867%\n",
      "Epoch [4/300], Step [209/225], Training Accuracy: 33.6423%, Training Loss: 1.3862%\n",
      "Epoch [4/300], Step [210/225], Training Accuracy: 33.6905%, Training Loss: 1.3856%\n",
      "Epoch [4/300], Step [211/225], Training Accuracy: 33.6863%, Training Loss: 1.3850%\n",
      "Epoch [4/300], Step [212/225], Training Accuracy: 33.6675%, Training Loss: 1.3848%\n",
      "Epoch [4/300], Step [213/225], Training Accuracy: 33.6561%, Training Loss: 1.3850%\n",
      "Epoch [4/300], Step [214/225], Training Accuracy: 33.6522%, Training Loss: 1.3847%\n",
      "Epoch [4/300], Step [215/225], Training Accuracy: 33.6192%, Training Loss: 1.3847%\n",
      "Epoch [4/300], Step [216/225], Training Accuracy: 33.6227%, Training Loss: 1.3846%\n",
      "Epoch [4/300], Step [217/225], Training Accuracy: 33.6766%, Training Loss: 1.3836%\n",
      "Epoch [4/300], Step [218/225], Training Accuracy: 33.6869%, Training Loss: 1.3832%\n",
      "Epoch [4/300], Step [219/225], Training Accuracy: 33.6901%, Training Loss: 1.3832%\n",
      "Epoch [4/300], Step [220/225], Training Accuracy: 33.6861%, Training Loss: 1.3827%\n",
      "Epoch [4/300], Step [221/225], Training Accuracy: 33.6963%, Training Loss: 1.3823%\n",
      "Epoch [4/300], Step [222/225], Training Accuracy: 33.6641%, Training Loss: 1.3821%\n",
      "Epoch [4/300], Step [223/225], Training Accuracy: 33.6603%, Training Loss: 1.3821%\n",
      "Epoch [4/300], Step [224/225], Training Accuracy: 33.6705%, Training Loss: 1.3816%\n",
      "Epoch [4/300], Step [225/225], Training Accuracy: 33.7062%, Training Loss: 1.3814%\n",
      "Epoch [5/300], Step [1/225], Training Accuracy: 37.5000%, Training Loss: 1.3751%\n",
      "Epoch [5/300], Step [2/225], Training Accuracy: 35.1562%, Training Loss: 1.3965%\n",
      "Epoch [5/300], Step [3/225], Training Accuracy: 34.8958%, Training Loss: 1.3745%\n",
      "Epoch [5/300], Step [4/225], Training Accuracy: 37.5000%, Training Loss: 1.3466%\n",
      "Epoch [5/300], Step [5/225], Training Accuracy: 36.8750%, Training Loss: 1.3549%\n",
      "Epoch [5/300], Step [6/225], Training Accuracy: 36.1979%, Training Loss: 1.3515%\n",
      "Epoch [5/300], Step [7/225], Training Accuracy: 35.9375%, Training Loss: 1.3664%\n",
      "Epoch [5/300], Step [8/225], Training Accuracy: 35.5469%, Training Loss: 1.3662%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/300], Step [9/225], Training Accuracy: 35.9375%, Training Loss: 1.3646%\n",
      "Epoch [5/300], Step [10/225], Training Accuracy: 36.4062%, Training Loss: 1.3580%\n",
      "Epoch [5/300], Step [11/225], Training Accuracy: 36.2216%, Training Loss: 1.3578%\n",
      "Epoch [5/300], Step [12/225], Training Accuracy: 36.1979%, Training Loss: 1.3542%\n",
      "Epoch [5/300], Step [13/225], Training Accuracy: 36.4183%, Training Loss: 1.3581%\n",
      "Epoch [5/300], Step [14/225], Training Accuracy: 36.1607%, Training Loss: 1.3609%\n",
      "Epoch [5/300], Step [15/225], Training Accuracy: 35.9375%, Training Loss: 1.3737%\n",
      "Epoch [5/300], Step [16/225], Training Accuracy: 36.3281%, Training Loss: 1.3662%\n",
      "Epoch [5/300], Step [17/225], Training Accuracy: 36.8566%, Training Loss: 1.3568%\n",
      "Epoch [5/300], Step [18/225], Training Accuracy: 36.1979%, Training Loss: 1.3607%\n",
      "Epoch [5/300], Step [19/225], Training Accuracy: 36.2664%, Training Loss: 1.3589%\n",
      "Epoch [5/300], Step [20/225], Training Accuracy: 36.7188%, Training Loss: 1.3546%\n",
      "Epoch [5/300], Step [21/225], Training Accuracy: 36.6071%, Training Loss: 1.3522%\n",
      "Epoch [5/300], Step [22/225], Training Accuracy: 36.7188%, Training Loss: 1.3503%\n",
      "Epoch [5/300], Step [23/225], Training Accuracy: 36.7527%, Training Loss: 1.3478%\n",
      "Epoch [5/300], Step [24/225], Training Accuracy: 36.9792%, Training Loss: 1.3456%\n",
      "Epoch [5/300], Step [25/225], Training Accuracy: 36.8750%, Training Loss: 1.3489%\n",
      "Epoch [5/300], Step [26/225], Training Accuracy: 36.8389%, Training Loss: 1.3496%\n",
      "Epoch [5/300], Step [27/225], Training Accuracy: 37.0949%, Training Loss: 1.3488%\n",
      "Epoch [5/300], Step [28/225], Training Accuracy: 37.5000%, Training Loss: 1.3459%\n",
      "Epoch [5/300], Step [29/225], Training Accuracy: 37.4461%, Training Loss: 1.3449%\n",
      "Epoch [5/300], Step [30/225], Training Accuracy: 37.6042%, Training Loss: 1.3429%\n",
      "Epoch [5/300], Step [31/225], Training Accuracy: 37.7016%, Training Loss: 1.3421%\n",
      "Epoch [5/300], Step [32/225], Training Accuracy: 38.0371%, Training Loss: 1.3392%\n",
      "Epoch [5/300], Step [33/225], Training Accuracy: 38.0208%, Training Loss: 1.3369%\n",
      "Epoch [5/300], Step [34/225], Training Accuracy: 37.9596%, Training Loss: 1.3363%\n",
      "Epoch [5/300], Step [35/225], Training Accuracy: 37.8125%, Training Loss: 1.3374%\n",
      "Epoch [5/300], Step [36/225], Training Accuracy: 37.4566%, Training Loss: 1.3407%\n",
      "Epoch [5/300], Step [37/225], Training Accuracy: 37.4155%, Training Loss: 1.3425%\n",
      "Epoch [5/300], Step [38/225], Training Accuracy: 37.2122%, Training Loss: 1.3413%\n",
      "Epoch [5/300], Step [39/225], Training Accuracy: 37.0593%, Training Loss: 1.3428%\n",
      "Epoch [5/300], Step [40/225], Training Accuracy: 36.7969%, Training Loss: 1.3432%\n",
      "Epoch [5/300], Step [41/225], Training Accuracy: 36.6235%, Training Loss: 1.3433%\n",
      "Epoch [5/300], Step [42/225], Training Accuracy: 36.6443%, Training Loss: 1.3430%\n",
      "Epoch [5/300], Step [43/225], Training Accuracy: 36.7369%, Training Loss: 1.3418%\n",
      "Epoch [5/300], Step [44/225], Training Accuracy: 36.8253%, Training Loss: 1.3400%\n",
      "Epoch [5/300], Step [45/225], Training Accuracy: 36.7361%, Training Loss: 1.3390%\n",
      "Epoch [5/300], Step [46/225], Training Accuracy: 36.7188%, Training Loss: 1.3368%\n",
      "Epoch [5/300], Step [47/225], Training Accuracy: 36.6689%, Training Loss: 1.3374%\n",
      "Epoch [5/300], Step [48/225], Training Accuracy: 36.5885%, Training Loss: 1.3379%\n",
      "Epoch [5/300], Step [49/225], Training Accuracy: 36.5434%, Training Loss: 1.3375%\n",
      "Epoch [5/300], Step [50/225], Training Accuracy: 36.5625%, Training Loss: 1.3379%\n",
      "Epoch [5/300], Step [51/225], Training Accuracy: 36.6115%, Training Loss: 1.3380%\n",
      "Epoch [5/300], Step [52/225], Training Accuracy: 36.5986%, Training Loss: 1.3390%\n",
      "Epoch [5/300], Step [53/225], Training Accuracy: 36.4682%, Training Loss: 1.3389%\n",
      "Epoch [5/300], Step [54/225], Training Accuracy: 36.3715%, Training Loss: 1.3386%\n",
      "Epoch [5/300], Step [55/225], Training Accuracy: 36.2500%, Training Loss: 1.3396%\n",
      "Epoch [5/300], Step [56/225], Training Accuracy: 36.2444%, Training Loss: 1.3385%\n",
      "Epoch [5/300], Step [57/225], Training Accuracy: 36.4857%, Training Loss: 1.3365%\n",
      "Epoch [5/300], Step [58/225], Training Accuracy: 36.5032%, Training Loss: 1.3348%\n",
      "Epoch [5/300], Step [59/225], Training Accuracy: 36.3083%, Training Loss: 1.3347%\n",
      "Epoch [5/300], Step [60/225], Training Accuracy: 36.3281%, Training Loss: 1.3328%\n",
      "Epoch [5/300], Step [61/225], Training Accuracy: 36.2705%, Training Loss: 1.3327%\n",
      "Epoch [5/300], Step [62/225], Training Accuracy: 36.3407%, Training Loss: 1.3315%\n",
      "Epoch [5/300], Step [63/225], Training Accuracy: 36.4087%, Training Loss: 1.3300%\n",
      "Epoch [5/300], Step [64/225], Training Accuracy: 36.3525%, Training Loss: 1.3308%\n",
      "Epoch [5/300], Step [65/225], Training Accuracy: 36.3221%, Training Loss: 1.3312%\n",
      "Epoch [5/300], Step [66/225], Training Accuracy: 36.4820%, Training Loss: 1.3302%\n",
      "Epoch [5/300], Step [67/225], Training Accuracy: 36.5672%, Training Loss: 1.3286%\n",
      "Epoch [5/300], Step [68/225], Training Accuracy: 36.5579%, Training Loss: 1.3284%\n",
      "Epoch [5/300], Step [69/225], Training Accuracy: 36.5942%, Training Loss: 1.3284%\n",
      "Epoch [5/300], Step [70/225], Training Accuracy: 36.5848%, Training Loss: 1.3284%\n",
      "Epoch [5/300], Step [71/225], Training Accuracy: 36.5537%, Training Loss: 1.3278%\n",
      "Epoch [5/300], Step [72/225], Training Accuracy: 36.5451%, Training Loss: 1.3276%\n",
      "Epoch [5/300], Step [73/225], Training Accuracy: 36.4512%, Training Loss: 1.3286%\n",
      "Epoch [5/300], Step [74/225], Training Accuracy: 36.3809%, Training Loss: 1.3286%\n",
      "Epoch [5/300], Step [75/225], Training Accuracy: 36.5000%, Training Loss: 1.3265%\n",
      "Epoch [5/300], Step [76/225], Training Accuracy: 36.4926%, Training Loss: 1.3263%\n",
      "Epoch [5/300], Step [77/225], Training Accuracy: 36.4042%, Training Loss: 1.3268%\n",
      "Epoch [5/300], Step [78/225], Training Accuracy: 36.4383%, Training Loss: 1.3266%\n",
      "Epoch [5/300], Step [79/225], Training Accuracy: 36.4122%, Training Loss: 1.3265%\n",
      "Epoch [5/300], Step [80/225], Training Accuracy: 36.2500%, Training Loss: 1.3276%\n",
      "Epoch [5/300], Step [81/225], Training Accuracy: 36.1497%, Training Loss: 1.3280%\n",
      "Epoch [5/300], Step [82/225], Training Accuracy: 36.1471%, Training Loss: 1.3290%\n",
      "Epoch [5/300], Step [83/225], Training Accuracy: 36.2199%, Training Loss: 1.3275%\n",
      "Epoch [5/300], Step [84/225], Training Accuracy: 36.3281%, Training Loss: 1.3266%\n",
      "Epoch [5/300], Step [85/225], Training Accuracy: 36.3235%, Training Loss: 1.3267%\n",
      "Epoch [5/300], Step [86/225], Training Accuracy: 36.2464%, Training Loss: 1.3268%\n",
      "Epoch [5/300], Step [87/225], Training Accuracy: 36.4045%, Training Loss: 1.3260%\n",
      "Epoch [5/300], Step [88/225], Training Accuracy: 36.3636%, Training Loss: 1.3260%\n",
      "Epoch [5/300], Step [89/225], Training Accuracy: 36.3237%, Training Loss: 1.3283%\n",
      "Epoch [5/300], Step [90/225], Training Accuracy: 36.2500%, Training Loss: 1.3289%\n",
      "Epoch [5/300], Step [91/225], Training Accuracy: 36.3839%, Training Loss: 1.3285%\n",
      "Epoch [5/300], Step [92/225], Training Accuracy: 36.4130%, Training Loss: 1.3279%\n",
      "Epoch [5/300], Step [93/225], Training Accuracy: 36.4583%, Training Loss: 1.3278%\n",
      "Epoch [5/300], Step [94/225], Training Accuracy: 36.5027%, Training Loss: 1.3259%\n",
      "Epoch [5/300], Step [95/225], Training Accuracy: 36.4309%, Training Loss: 1.3269%\n",
      "Epoch [5/300], Step [96/225], Training Accuracy: 36.4258%, Training Loss: 1.3262%\n",
      "Epoch [5/300], Step [97/225], Training Accuracy: 36.4691%, Training Loss: 1.3266%\n",
      "Epoch [5/300], Step [98/225], Training Accuracy: 36.4796%, Training Loss: 1.3263%\n",
      "Epoch [5/300], Step [99/225], Training Accuracy: 36.5215%, Training Loss: 1.3261%\n",
      "Epoch [5/300], Step [100/225], Training Accuracy: 36.5156%, Training Loss: 1.3259%\n",
      "Epoch [5/300], Step [101/225], Training Accuracy: 36.5873%, Training Loss: 1.3273%\n",
      "Epoch [5/300], Step [102/225], Training Accuracy: 36.5196%, Training Loss: 1.3276%\n",
      "Epoch [5/300], Step [103/225], Training Accuracy: 36.4988%, Training Loss: 1.3280%\n",
      "Epoch [5/300], Step [104/225], Training Accuracy: 36.5234%, Training Loss: 1.3273%\n",
      "Epoch [5/300], Step [105/225], Training Accuracy: 36.4881%, Training Loss: 1.3275%\n",
      "Epoch [5/300], Step [106/225], Training Accuracy: 36.4534%, Training Loss: 1.3276%\n",
      "Epoch [5/300], Step [107/225], Training Accuracy: 36.4048%, Training Loss: 1.3276%\n",
      "Epoch [5/300], Step [108/225], Training Accuracy: 36.3281%, Training Loss: 1.3287%\n",
      "Epoch [5/300], Step [109/225], Training Accuracy: 36.4679%, Training Loss: 1.3279%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/300], Step [110/225], Training Accuracy: 36.4773%, Training Loss: 1.3285%\n",
      "Epoch [5/300], Step [111/225], Training Accuracy: 36.4161%, Training Loss: 1.3285%\n",
      "Epoch [5/300], Step [112/225], Training Accuracy: 36.4397%, Training Loss: 1.3283%\n",
      "Epoch [5/300], Step [113/225], Training Accuracy: 36.4629%, Training Loss: 1.3287%\n",
      "Epoch [5/300], Step [114/225], Training Accuracy: 36.5132%, Training Loss: 1.3275%\n",
      "Epoch [5/300], Step [115/225], Training Accuracy: 36.5489%, Training Loss: 1.3271%\n",
      "Epoch [5/300], Step [116/225], Training Accuracy: 36.5302%, Training Loss: 1.3268%\n",
      "Epoch [5/300], Step [117/225], Training Accuracy: 36.4583%, Training Loss: 1.3283%\n",
      "Epoch [5/300], Step [118/225], Training Accuracy: 36.5201%, Training Loss: 1.3273%\n",
      "Epoch [5/300], Step [119/225], Training Accuracy: 36.5284%, Training Loss: 1.3265%\n",
      "Epoch [5/300], Step [120/225], Training Accuracy: 36.4844%, Training Loss: 1.3270%\n",
      "Epoch [5/300], Step [121/225], Training Accuracy: 36.4411%, Training Loss: 1.3273%\n",
      "Epoch [5/300], Step [122/225], Training Accuracy: 36.4754%, Training Loss: 1.3269%\n",
      "Epoch [5/300], Step [123/225], Training Accuracy: 36.4583%, Training Loss: 1.3273%\n",
      "Epoch [5/300], Step [124/225], Training Accuracy: 36.5045%, Training Loss: 1.3264%\n",
      "Epoch [5/300], Step [125/225], Training Accuracy: 36.5125%, Training Loss: 1.3269%\n",
      "Epoch [5/300], Step [126/225], Training Accuracy: 36.4583%, Training Loss: 1.3273%\n",
      "Epoch [5/300], Step [127/225], Training Accuracy: 36.3558%, Training Loss: 1.3282%\n",
      "Epoch [5/300], Step [128/225], Training Accuracy: 36.2915%, Training Loss: 1.3283%\n",
      "Epoch [5/300], Step [129/225], Training Accuracy: 36.2888%, Training Loss: 1.3278%\n",
      "Epoch [5/300], Step [130/225], Training Accuracy: 36.2500%, Training Loss: 1.3283%\n",
      "Epoch [5/300], Step [131/225], Training Accuracy: 36.2595%, Training Loss: 1.3282%\n",
      "Epoch [5/300], Step [132/225], Training Accuracy: 36.3163%, Training Loss: 1.3276%\n",
      "Epoch [5/300], Step [133/225], Training Accuracy: 36.3957%, Training Loss: 1.3272%\n",
      "Epoch [5/300], Step [134/225], Training Accuracy: 36.2990%, Training Loss: 1.3273%\n",
      "Epoch [5/300], Step [135/225], Training Accuracy: 36.2500%, Training Loss: 1.3281%\n",
      "Epoch [5/300], Step [136/225], Training Accuracy: 36.2592%, Training Loss: 1.3282%\n",
      "Epoch [5/300], Step [137/225], Training Accuracy: 36.2226%, Training Loss: 1.3284%\n",
      "Epoch [5/300], Step [138/225], Training Accuracy: 36.2545%, Training Loss: 1.3277%\n",
      "Epoch [5/300], Step [139/225], Training Accuracy: 36.1848%, Training Loss: 1.3284%\n",
      "Epoch [5/300], Step [140/225], Training Accuracy: 36.1942%, Training Loss: 1.3293%\n",
      "Epoch [5/300], Step [141/225], Training Accuracy: 36.2699%, Training Loss: 1.3285%\n",
      "Epoch [5/300], Step [142/225], Training Accuracy: 36.3226%, Training Loss: 1.3276%\n",
      "Epoch [5/300], Step [143/225], Training Accuracy: 36.3636%, Training Loss: 1.3274%\n",
      "Epoch [5/300], Step [144/225], Training Accuracy: 36.3173%, Training Loss: 1.3274%\n",
      "Epoch [5/300], Step [145/225], Training Accuracy: 36.3039%, Training Loss: 1.3276%\n",
      "Epoch [5/300], Step [146/225], Training Accuracy: 36.3014%, Training Loss: 1.3275%\n",
      "Epoch [5/300], Step [147/225], Training Accuracy: 36.3308%, Training Loss: 1.3269%\n",
      "Epoch [5/300], Step [148/225], Training Accuracy: 36.3176%, Training Loss: 1.3265%\n",
      "Epoch [5/300], Step [149/225], Training Accuracy: 36.3570%, Training Loss: 1.3260%\n",
      "Epoch [5/300], Step [150/225], Training Accuracy: 36.3646%, Training Loss: 1.3259%\n",
      "Epoch [5/300], Step [151/225], Training Accuracy: 36.4031%, Training Loss: 1.3255%\n",
      "Epoch [5/300], Step [152/225], Training Accuracy: 36.3590%, Training Loss: 1.3258%\n",
      "Epoch [5/300], Step [153/225], Training Accuracy: 36.3051%, Training Loss: 1.3259%\n",
      "Epoch [5/300], Step [154/225], Training Accuracy: 36.2723%, Training Loss: 1.3258%\n",
      "Epoch [5/300], Step [155/225], Training Accuracy: 36.3206%, Training Loss: 1.3257%\n",
      "Epoch [5/300], Step [156/225], Training Accuracy: 36.2780%, Training Loss: 1.3260%\n",
      "Epoch [5/300], Step [157/225], Training Accuracy: 36.2560%, Training Loss: 1.3259%\n",
      "Epoch [5/300], Step [158/225], Training Accuracy: 36.2342%, Training Loss: 1.3260%\n",
      "Epoch [5/300], Step [159/225], Training Accuracy: 36.3011%, Training Loss: 1.3255%\n",
      "Epoch [5/300], Step [160/225], Training Accuracy: 36.2402%, Training Loss: 1.3260%\n",
      "Epoch [5/300], Step [161/225], Training Accuracy: 36.3160%, Training Loss: 1.3252%\n",
      "Epoch [5/300], Step [162/225], Training Accuracy: 36.2944%, Training Loss: 1.3253%\n",
      "Epoch [5/300], Step [163/225], Training Accuracy: 36.3497%, Training Loss: 1.3253%\n",
      "Epoch [5/300], Step [164/225], Training Accuracy: 36.3091%, Training Loss: 1.3258%\n",
      "Epoch [5/300], Step [165/225], Training Accuracy: 36.2405%, Training Loss: 1.3269%\n",
      "Epoch [5/300], Step [166/225], Training Accuracy: 36.2105%, Training Loss: 1.3268%\n",
      "Epoch [5/300], Step [167/225], Training Accuracy: 36.2463%, Training Loss: 1.3262%\n",
      "Epoch [5/300], Step [168/225], Training Accuracy: 36.2630%, Training Loss: 1.3258%\n",
      "Epoch [5/300], Step [169/225], Training Accuracy: 36.3351%, Training Loss: 1.3253%\n",
      "Epoch [5/300], Step [170/225], Training Accuracy: 36.2960%, Training Loss: 1.3253%\n",
      "Epoch [5/300], Step [171/225], Training Accuracy: 36.3213%, Training Loss: 1.3247%\n",
      "Epoch [5/300], Step [172/225], Training Accuracy: 36.3190%, Training Loss: 1.3242%\n",
      "Epoch [5/300], Step [173/225], Training Accuracy: 36.2717%, Training Loss: 1.3240%\n",
      "Epoch [5/300], Step [174/225], Training Accuracy: 36.2428%, Training Loss: 1.3239%\n",
      "Epoch [5/300], Step [175/225], Training Accuracy: 36.1964%, Training Loss: 1.3246%\n",
      "Epoch [5/300], Step [176/225], Training Accuracy: 36.1861%, Training Loss: 1.3248%\n",
      "Epoch [5/300], Step [177/225], Training Accuracy: 36.1758%, Training Loss: 1.3248%\n",
      "Epoch [5/300], Step [178/225], Training Accuracy: 36.1482%, Training Loss: 1.3245%\n",
      "Epoch [5/300], Step [179/225], Training Accuracy: 36.2168%, Training Loss: 1.3244%\n",
      "Epoch [5/300], Step [180/225], Training Accuracy: 36.3368%, Training Loss: 1.3235%\n",
      "Epoch [5/300], Step [181/225], Training Accuracy: 36.3432%, Training Loss: 1.3238%\n",
      "Epoch [5/300], Step [182/225], Training Accuracy: 36.3496%, Training Loss: 1.3233%\n",
      "Epoch [5/300], Step [183/225], Training Accuracy: 36.3559%, Training Loss: 1.3231%\n",
      "Epoch [5/300], Step [184/225], Training Accuracy: 36.3536%, Training Loss: 1.3230%\n",
      "Epoch [5/300], Step [185/225], Training Accuracy: 36.3851%, Training Loss: 1.3228%\n",
      "Epoch [5/300], Step [186/225], Training Accuracy: 36.3743%, Training Loss: 1.3231%\n",
      "Epoch [5/300], Step [187/225], Training Accuracy: 36.4054%, Training Loss: 1.3228%\n",
      "Epoch [5/300], Step [188/225], Training Accuracy: 36.3614%, Training Loss: 1.3229%\n",
      "Epoch [5/300], Step [189/225], Training Accuracy: 36.3839%, Training Loss: 1.3224%\n",
      "Epoch [5/300], Step [190/225], Training Accuracy: 36.3734%, Training Loss: 1.3223%\n",
      "Epoch [5/300], Step [191/225], Training Accuracy: 36.3874%, Training Loss: 1.3225%\n",
      "Epoch [5/300], Step [192/225], Training Accuracy: 36.4095%, Training Loss: 1.3223%\n",
      "Epoch [5/300], Step [193/225], Training Accuracy: 36.4313%, Training Loss: 1.3220%\n",
      "Epoch [5/300], Step [194/225], Training Accuracy: 36.4207%, Training Loss: 1.3219%\n",
      "Epoch [5/300], Step [195/225], Training Accuracy: 36.4183%, Training Loss: 1.3220%\n",
      "Epoch [5/300], Step [196/225], Training Accuracy: 36.3919%, Training Loss: 1.3222%\n",
      "Epoch [5/300], Step [197/225], Training Accuracy: 36.4055%, Training Loss: 1.3223%\n",
      "Epoch [5/300], Step [198/225], Training Accuracy: 36.4189%, Training Loss: 1.3219%\n",
      "Epoch [5/300], Step [199/225], Training Accuracy: 36.4008%, Training Loss: 1.3220%\n",
      "Epoch [5/300], Step [200/225], Training Accuracy: 36.3984%, Training Loss: 1.3218%\n",
      "Epoch [5/300], Step [201/225], Training Accuracy: 36.3884%, Training Loss: 1.3214%\n",
      "Epoch [5/300], Step [202/225], Training Accuracy: 36.3629%, Training Loss: 1.3214%\n",
      "Epoch [5/300], Step [203/225], Training Accuracy: 36.3300%, Training Loss: 1.3220%\n",
      "Epoch [5/300], Step [204/225], Training Accuracy: 36.3281%, Training Loss: 1.3218%\n",
      "Epoch [5/300], Step [205/225], Training Accuracy: 36.3720%, Training Loss: 1.3214%\n",
      "Epoch [5/300], Step [206/225], Training Accuracy: 36.3395%, Training Loss: 1.3214%\n",
      "Epoch [5/300], Step [207/225], Training Accuracy: 36.3225%, Training Loss: 1.3214%\n",
      "Epoch [5/300], Step [208/225], Training Accuracy: 36.3732%, Training Loss: 1.3207%\n",
      "Epoch [5/300], Step [209/225], Training Accuracy: 36.4309%, Training Loss: 1.3201%\n",
      "Epoch [5/300], Step [210/225], Training Accuracy: 36.4435%, Training Loss: 1.3198%\n",
      "Epoch [5/300], Step [211/225], Training Accuracy: 36.4707%, Training Loss: 1.3193%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/300], Step [212/225], Training Accuracy: 36.4755%, Training Loss: 1.3189%\n",
      "Epoch [5/300], Step [213/225], Training Accuracy: 36.4363%, Training Loss: 1.3191%\n",
      "Epoch [5/300], Step [214/225], Training Accuracy: 36.4048%, Training Loss: 1.3190%\n",
      "Epoch [5/300], Step [215/225], Training Accuracy: 36.3881%, Training Loss: 1.3195%\n",
      "Epoch [5/300], Step [216/225], Training Accuracy: 36.3281%, Training Loss: 1.3197%\n",
      "Epoch [5/300], Step [217/225], Training Accuracy: 36.3551%, Training Loss: 1.3189%\n",
      "Epoch [5/300], Step [218/225], Training Accuracy: 36.3532%, Training Loss: 1.3188%\n",
      "Epoch [5/300], Step [219/225], Training Accuracy: 36.3656%, Training Loss: 1.3185%\n",
      "Epoch [5/300], Step [220/225], Training Accuracy: 36.3494%, Training Loss: 1.3185%\n",
      "Epoch [5/300], Step [221/225], Training Accuracy: 36.3476%, Training Loss: 1.3185%\n",
      "Epoch [5/300], Step [222/225], Training Accuracy: 36.3528%, Training Loss: 1.3182%\n",
      "Epoch [5/300], Step [223/225], Training Accuracy: 36.3859%, Training Loss: 1.3183%\n",
      "Epoch [5/300], Step [224/225], Training Accuracy: 36.4049%, Training Loss: 1.3177%\n",
      "Epoch [5/300], Step [225/225], Training Accuracy: 36.4230%, Training Loss: 1.3176%\n",
      "Epoch [6/300], Step [1/225], Training Accuracy: 40.6250%, Training Loss: 1.3530%\n",
      "Epoch [6/300], Step [2/225], Training Accuracy: 33.5938%, Training Loss: 1.3691%\n",
      "Epoch [6/300], Step [3/225], Training Accuracy: 32.8125%, Training Loss: 1.3609%\n",
      "Epoch [6/300], Step [4/225], Training Accuracy: 34.7656%, Training Loss: 1.3265%\n",
      "Epoch [6/300], Step [5/225], Training Accuracy: 34.6875%, Training Loss: 1.3199%\n",
      "Epoch [6/300], Step [6/225], Training Accuracy: 33.8542%, Training Loss: 1.3114%\n",
      "Epoch [6/300], Step [7/225], Training Accuracy: 34.3750%, Training Loss: 1.3157%\n",
      "Epoch [6/300], Step [8/225], Training Accuracy: 34.1797%, Training Loss: 1.3097%\n",
      "Epoch [6/300], Step [9/225], Training Accuracy: 35.2431%, Training Loss: 1.3117%\n",
      "Epoch [6/300], Step [10/225], Training Accuracy: 35.1562%, Training Loss: 1.3142%\n",
      "Epoch [6/300], Step [11/225], Training Accuracy: 35.6534%, Training Loss: 1.3121%\n",
      "Epoch [6/300], Step [12/225], Training Accuracy: 35.5469%, Training Loss: 1.3078%\n",
      "Epoch [6/300], Step [13/225], Training Accuracy: 36.0577%, Training Loss: 1.3103%\n",
      "Epoch [6/300], Step [14/225], Training Accuracy: 35.7143%, Training Loss: 1.3149%\n",
      "Epoch [6/300], Step [15/225], Training Accuracy: 34.7917%, Training Loss: 1.3266%\n",
      "Epoch [6/300], Step [16/225], Training Accuracy: 34.9609%, Training Loss: 1.3251%\n",
      "Epoch [6/300], Step [17/225], Training Accuracy: 35.1103%, Training Loss: 1.3196%\n",
      "Epoch [6/300], Step [18/225], Training Accuracy: 35.1562%, Training Loss: 1.3300%\n",
      "Epoch [6/300], Step [19/225], Training Accuracy: 34.8684%, Training Loss: 1.3285%\n",
      "Epoch [6/300], Step [20/225], Training Accuracy: 35.0000%, Training Loss: 1.3264%\n",
      "Epoch [6/300], Step [21/225], Training Accuracy: 35.5655%, Training Loss: 1.3197%\n",
      "Epoch [6/300], Step [22/225], Training Accuracy: 35.7955%, Training Loss: 1.3176%\n",
      "Epoch [6/300], Step [23/225], Training Accuracy: 36.0054%, Training Loss: 1.3161%\n",
      "Epoch [6/300], Step [24/225], Training Accuracy: 36.0677%, Training Loss: 1.3136%\n",
      "Epoch [6/300], Step [25/225], Training Accuracy: 36.3125%, Training Loss: 1.3145%\n",
      "Epoch [6/300], Step [26/225], Training Accuracy: 35.8774%, Training Loss: 1.3171%\n",
      "Epoch [6/300], Step [27/225], Training Accuracy: 35.8796%, Training Loss: 1.3194%\n",
      "Epoch [6/300], Step [28/225], Training Accuracy: 36.1607%, Training Loss: 1.3142%\n",
      "Epoch [6/300], Step [29/225], Training Accuracy: 36.2069%, Training Loss: 1.3110%\n",
      "Epoch [6/300], Step [30/225], Training Accuracy: 36.2500%, Training Loss: 1.3118%\n",
      "Epoch [6/300], Step [31/225], Training Accuracy: 36.2399%, Training Loss: 1.3123%\n",
      "Epoch [6/300], Step [32/225], Training Accuracy: 36.3770%, Training Loss: 1.3093%\n",
      "Epoch [6/300], Step [33/225], Training Accuracy: 36.4583%, Training Loss: 1.3072%\n",
      "Epoch [6/300], Step [34/225], Training Accuracy: 36.6268%, Training Loss: 1.3054%\n",
      "Epoch [6/300], Step [35/225], Training Accuracy: 36.8304%, Training Loss: 1.3050%\n",
      "Epoch [6/300], Step [36/225], Training Accuracy: 36.5451%, Training Loss: 1.3105%\n",
      "Epoch [6/300], Step [37/225], Training Accuracy: 36.6132%, Training Loss: 1.3114%\n",
      "Epoch [6/300], Step [38/225], Training Accuracy: 36.6365%, Training Loss: 1.3088%\n",
      "Epoch [6/300], Step [39/225], Training Accuracy: 36.6186%, Training Loss: 1.3085%\n",
      "Epoch [6/300], Step [40/225], Training Accuracy: 36.6406%, Training Loss: 1.3077%\n",
      "Epoch [6/300], Step [41/225], Training Accuracy: 36.5854%, Training Loss: 1.3071%\n",
      "Epoch [6/300], Step [42/225], Training Accuracy: 36.6815%, Training Loss: 1.3067%\n",
      "Epoch [6/300], Step [43/225], Training Accuracy: 36.5916%, Training Loss: 1.3058%\n",
      "Epoch [6/300], Step [44/225], Training Accuracy: 36.5412%, Training Loss: 1.3043%\n",
      "Epoch [6/300], Step [45/225], Training Accuracy: 36.7014%, Training Loss: 1.3021%\n",
      "Epoch [6/300], Step [46/225], Training Accuracy: 36.5489%, Training Loss: 1.3009%\n",
      "Epoch [6/300], Step [47/225], Training Accuracy: 36.5027%, Training Loss: 1.3014%\n",
      "Epoch [6/300], Step [48/225], Training Accuracy: 36.5234%, Training Loss: 1.2997%\n",
      "Epoch [6/300], Step [49/225], Training Accuracy: 36.5115%, Training Loss: 1.3001%\n",
      "Epoch [6/300], Step [50/225], Training Accuracy: 36.4062%, Training Loss: 1.3010%\n",
      "Epoch [6/300], Step [51/225], Training Accuracy: 36.4277%, Training Loss: 1.3032%\n",
      "Epoch [6/300], Step [52/225], Training Accuracy: 36.2680%, Training Loss: 1.3028%\n",
      "Epoch [6/300], Step [53/225], Training Accuracy: 36.2028%, Training Loss: 1.3020%\n",
      "Epoch [6/300], Step [54/225], Training Accuracy: 36.2269%, Training Loss: 1.3018%\n",
      "Epoch [6/300], Step [55/225], Training Accuracy: 36.1932%, Training Loss: 1.3026%\n",
      "Epoch [6/300], Step [56/225], Training Accuracy: 36.1049%, Training Loss: 1.3036%\n",
      "Epoch [6/300], Step [57/225], Training Accuracy: 36.3213%, Training Loss: 1.3015%\n",
      "Epoch [6/300], Step [58/225], Training Accuracy: 36.3147%, Training Loss: 1.3003%\n",
      "Epoch [6/300], Step [59/225], Training Accuracy: 36.2023%, Training Loss: 1.3004%\n",
      "Epoch [6/300], Step [60/225], Training Accuracy: 36.2760%, Training Loss: 1.2996%\n",
      "Epoch [6/300], Step [61/225], Training Accuracy: 36.3217%, Training Loss: 1.2985%\n",
      "Epoch [6/300], Step [62/225], Training Accuracy: 36.5423%, Training Loss: 1.2972%\n",
      "Epoch [6/300], Step [63/225], Training Accuracy: 36.5079%, Training Loss: 1.2979%\n",
      "Epoch [6/300], Step [64/225], Training Accuracy: 36.3770%, Training Loss: 1.2986%\n",
      "Epoch [6/300], Step [65/225], Training Accuracy: 36.4423%, Training Loss: 1.2993%\n",
      "Epoch [6/300], Step [66/225], Training Accuracy: 36.4820%, Training Loss: 1.2982%\n",
      "Epoch [6/300], Step [67/225], Training Accuracy: 36.5672%, Training Loss: 1.2969%\n",
      "Epoch [6/300], Step [68/225], Training Accuracy: 36.6039%, Training Loss: 1.2960%\n",
      "Epoch [6/300], Step [69/225], Training Accuracy: 36.5716%, Training Loss: 1.2959%\n",
      "Epoch [6/300], Step [70/225], Training Accuracy: 36.4062%, Training Loss: 1.2960%\n",
      "Epoch [6/300], Step [71/225], Training Accuracy: 36.3776%, Training Loss: 1.2961%\n",
      "Epoch [6/300], Step [72/225], Training Accuracy: 36.3932%, Training Loss: 1.2967%\n",
      "Epoch [6/300], Step [73/225], Training Accuracy: 36.3228%, Training Loss: 1.2985%\n",
      "Epoch [6/300], Step [74/225], Training Accuracy: 36.3176%, Training Loss: 1.2983%\n",
      "Epoch [6/300], Step [75/225], Training Accuracy: 36.4167%, Training Loss: 1.2966%\n",
      "Epoch [6/300], Step [76/225], Training Accuracy: 36.4926%, Training Loss: 1.2960%\n",
      "Epoch [6/300], Step [77/225], Training Accuracy: 36.5463%, Training Loss: 1.2955%\n",
      "Epoch [6/300], Step [78/225], Training Accuracy: 36.5385%, Training Loss: 1.2953%\n",
      "Epoch [6/300], Step [79/225], Training Accuracy: 36.5111%, Training Loss: 1.2957%\n",
      "Epoch [6/300], Step [80/225], Training Accuracy: 36.3477%, Training Loss: 1.2966%\n",
      "Epoch [6/300], Step [81/225], Training Accuracy: 36.3233%, Training Loss: 1.2970%\n",
      "Epoch [6/300], Step [82/225], Training Accuracy: 36.2424%, Training Loss: 1.2969%\n",
      "Epoch [6/300], Step [83/225], Training Accuracy: 36.4834%, Training Loss: 1.2948%\n",
      "Epoch [6/300], Step [84/225], Training Accuracy: 36.4397%, Training Loss: 1.2939%\n",
      "Epoch [6/300], Step [85/225], Training Accuracy: 36.5074%, Training Loss: 1.2937%\n",
      "Epoch [6/300], Step [86/225], Training Accuracy: 36.3735%, Training Loss: 1.2953%\n",
      "Epoch [6/300], Step [87/225], Training Accuracy: 36.4943%, Training Loss: 1.2950%\n",
      "Epoch [6/300], Step [88/225], Training Accuracy: 36.4879%, Training Loss: 1.2952%\n",
      "Epoch [6/300], Step [89/225], Training Accuracy: 36.4817%, Training Loss: 1.2956%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/300], Step [90/225], Training Accuracy: 36.4931%, Training Loss: 1.2958%\n",
      "Epoch [6/300], Step [91/225], Training Accuracy: 36.4183%, Training Loss: 1.2961%\n",
      "Epoch [6/300], Step [92/225], Training Accuracy: 36.3961%, Training Loss: 1.2963%\n",
      "Epoch [6/300], Step [93/225], Training Accuracy: 36.4079%, Training Loss: 1.2966%\n",
      "Epoch [6/300], Step [94/225], Training Accuracy: 36.4694%, Training Loss: 1.2949%\n",
      "Epoch [6/300], Step [95/225], Training Accuracy: 36.3651%, Training Loss: 1.2959%\n",
      "Epoch [6/300], Step [96/225], Training Accuracy: 36.4095%, Training Loss: 1.2956%\n",
      "Epoch [6/300], Step [97/225], Training Accuracy: 36.5174%, Training Loss: 1.2946%\n",
      "Epoch [6/300], Step [98/225], Training Accuracy: 36.5593%, Training Loss: 1.2938%\n",
      "Epoch [6/300], Step [99/225], Training Accuracy: 36.6477%, Training Loss: 1.2930%\n",
      "Epoch [6/300], Step [100/225], Training Accuracy: 36.6406%, Training Loss: 1.2928%\n",
      "Epoch [6/300], Step [101/225], Training Accuracy: 36.7420%, Training Loss: 1.2924%\n",
      "Epoch [6/300], Step [102/225], Training Accuracy: 36.6268%, Training Loss: 1.2928%\n",
      "Epoch [6/300], Step [103/225], Training Accuracy: 36.6960%, Training Loss: 1.2924%\n",
      "Epoch [6/300], Step [104/225], Training Accuracy: 36.7488%, Training Loss: 1.2916%\n",
      "Epoch [6/300], Step [105/225], Training Accuracy: 36.7113%, Training Loss: 1.2917%\n",
      "Epoch [6/300], Step [106/225], Training Accuracy: 36.7630%, Training Loss: 1.2916%\n",
      "Epoch [6/300], Step [107/225], Training Accuracy: 36.7407%, Training Loss: 1.2910%\n",
      "Epoch [6/300], Step [108/225], Training Accuracy: 36.7188%, Training Loss: 1.2914%\n",
      "Epoch [6/300], Step [109/225], Training Accuracy: 36.8406%, Training Loss: 1.2906%\n",
      "Epoch [6/300], Step [110/225], Training Accuracy: 36.8750%, Training Loss: 1.2909%\n",
      "Epoch [6/300], Step [111/225], Training Accuracy: 36.9088%, Training Loss: 1.2909%\n",
      "Epoch [6/300], Step [112/225], Training Accuracy: 36.9141%, Training Loss: 1.2910%\n",
      "Epoch [6/300], Step [113/225], Training Accuracy: 36.8501%, Training Loss: 1.2914%\n",
      "Epoch [6/300], Step [114/225], Training Accuracy: 36.8558%, Training Loss: 1.2903%\n",
      "Epoch [6/300], Step [115/225], Training Accuracy: 36.9158%, Training Loss: 1.2896%\n",
      "Epoch [6/300], Step [116/225], Training Accuracy: 36.8939%, Training Loss: 1.2893%\n",
      "Epoch [6/300], Step [117/225], Training Accuracy: 36.8189%, Training Loss: 1.2899%\n",
      "Epoch [6/300], Step [118/225], Training Accuracy: 36.8512%, Training Loss: 1.2896%\n",
      "Epoch [6/300], Step [119/225], Training Accuracy: 36.8041%, Training Loss: 1.2893%\n",
      "Epoch [6/300], Step [120/225], Training Accuracy: 36.7969%, Training Loss: 1.2892%\n",
      "Epoch [6/300], Step [121/225], Training Accuracy: 36.7898%, Training Loss: 1.2891%\n",
      "Epoch [6/300], Step [122/225], Training Accuracy: 36.8212%, Training Loss: 1.2883%\n",
      "Epoch [6/300], Step [123/225], Training Accuracy: 36.8521%, Training Loss: 1.2885%\n",
      "Epoch [6/300], Step [124/225], Training Accuracy: 36.9708%, Training Loss: 1.2869%\n",
      "Epoch [6/300], Step [125/225], Training Accuracy: 36.9250%, Training Loss: 1.2872%\n",
      "Epoch [6/300], Step [126/225], Training Accuracy: 36.9172%, Training Loss: 1.2874%\n",
      "Epoch [6/300], Step [127/225], Training Accuracy: 36.8848%, Training Loss: 1.2878%\n",
      "Epoch [6/300], Step [128/225], Training Accuracy: 36.8652%, Training Loss: 1.2880%\n",
      "Epoch [6/300], Step [129/225], Training Accuracy: 36.8823%, Training Loss: 1.2875%\n",
      "Epoch [6/300], Step [130/225], Training Accuracy: 36.8630%, Training Loss: 1.2877%\n",
      "Epoch [6/300], Step [131/225], Training Accuracy: 36.8917%, Training Loss: 1.2874%\n",
      "Epoch [6/300], Step [132/225], Training Accuracy: 36.9437%, Training Loss: 1.2868%\n",
      "Epoch [6/300], Step [133/225], Training Accuracy: 37.0183%, Training Loss: 1.2861%\n",
      "Epoch [6/300], Step [134/225], Training Accuracy: 36.9170%, Training Loss: 1.2868%\n",
      "Epoch [6/300], Step [135/225], Training Accuracy: 36.8866%, Training Loss: 1.2878%\n",
      "Epoch [6/300], Step [136/225], Training Accuracy: 36.8222%, Training Loss: 1.2876%\n",
      "Epoch [6/300], Step [137/225], Training Accuracy: 36.8499%, Training Loss: 1.2866%\n",
      "Epoch [6/300], Step [138/225], Training Accuracy: 36.9226%, Training Loss: 1.2863%\n",
      "Epoch [6/300], Step [139/225], Training Accuracy: 36.9042%, Training Loss: 1.2864%\n",
      "Epoch [6/300], Step [140/225], Training Accuracy: 36.8973%, Training Loss: 1.2866%\n",
      "Epoch [6/300], Step [141/225], Training Accuracy: 36.9902%, Training Loss: 1.2854%\n",
      "Epoch [6/300], Step [142/225], Training Accuracy: 37.0268%, Training Loss: 1.2851%\n",
      "Epoch [6/300], Step [143/225], Training Accuracy: 37.0302%, Training Loss: 1.2849%\n",
      "Epoch [6/300], Step [144/225], Training Accuracy: 36.9683%, Training Loss: 1.2854%\n",
      "Epoch [6/300], Step [145/225], Training Accuracy: 36.9397%, Training Loss: 1.2855%\n",
      "Epoch [6/300], Step [146/225], Training Accuracy: 36.9328%, Training Loss: 1.2858%\n",
      "Epoch [6/300], Step [147/225], Training Accuracy: 36.9473%, Training Loss: 1.2852%\n",
      "Epoch [6/300], Step [148/225], Training Accuracy: 37.0460%, Training Loss: 1.2842%\n",
      "Epoch [6/300], Step [149/225], Training Accuracy: 37.1015%, Training Loss: 1.2839%\n",
      "Epoch [6/300], Step [150/225], Training Accuracy: 37.0938%, Training Loss: 1.2835%\n",
      "Epoch [6/300], Step [151/225], Training Accuracy: 37.1275%, Training Loss: 1.2831%\n",
      "Epoch [6/300], Step [152/225], Training Accuracy: 37.1094%, Training Loss: 1.2831%\n",
      "Epoch [6/300], Step [153/225], Training Accuracy: 37.0915%, Training Loss: 1.2833%\n",
      "Epoch [6/300], Step [154/225], Training Accuracy: 37.0942%, Training Loss: 1.2832%\n",
      "Epoch [6/300], Step [155/225], Training Accuracy: 37.0867%, Training Loss: 1.2832%\n",
      "Epoch [6/300], Step [156/225], Training Accuracy: 37.0693%, Training Loss: 1.2835%\n",
      "Epoch [6/300], Step [157/225], Training Accuracy: 37.0223%, Training Loss: 1.2839%\n",
      "Epoch [6/300], Step [158/225], Training Accuracy: 37.0451%, Training Loss: 1.2837%\n",
      "Epoch [6/300], Step [159/225], Training Accuracy: 37.0873%, Training Loss: 1.2831%\n",
      "Epoch [6/300], Step [160/225], Training Accuracy: 37.0801%, Training Loss: 1.2833%\n",
      "Epoch [6/300], Step [161/225], Training Accuracy: 37.1409%, Training Loss: 1.2827%\n",
      "Epoch [6/300], Step [162/225], Training Accuracy: 37.1335%, Training Loss: 1.2829%\n",
      "Epoch [6/300], Step [163/225], Training Accuracy: 37.1453%, Training Loss: 1.2824%\n",
      "Epoch [6/300], Step [164/225], Training Accuracy: 37.1856%, Training Loss: 1.2823%\n",
      "Epoch [6/300], Step [165/225], Training Accuracy: 37.1402%, Training Loss: 1.2830%\n",
      "Epoch [6/300], Step [166/225], Training Accuracy: 37.1423%, Training Loss: 1.2828%\n",
      "Epoch [6/300], Step [167/225], Training Accuracy: 37.1819%, Training Loss: 1.2822%\n",
      "Epoch [6/300], Step [168/225], Training Accuracy: 37.2117%, Training Loss: 1.2819%\n",
      "Epoch [6/300], Step [169/225], Training Accuracy: 37.2689%, Training Loss: 1.2813%\n",
      "Epoch [6/300], Step [170/225], Training Accuracy: 37.2518%, Training Loss: 1.2810%\n",
      "Epoch [6/300], Step [171/225], Training Accuracy: 37.2898%, Training Loss: 1.2804%\n",
      "Epoch [6/300], Step [172/225], Training Accuracy: 37.2547%, Training Loss: 1.2801%\n",
      "Epoch [6/300], Step [173/225], Training Accuracy: 37.2561%, Training Loss: 1.2799%\n",
      "Epoch [6/300], Step [174/225], Training Accuracy: 37.2486%, Training Loss: 1.2799%\n",
      "Epoch [6/300], Step [175/225], Training Accuracy: 37.2143%, Training Loss: 1.2802%\n",
      "Epoch [6/300], Step [176/225], Training Accuracy: 37.1893%, Training Loss: 1.2802%\n",
      "Epoch [6/300], Step [177/225], Training Accuracy: 37.1999%, Training Loss: 1.2801%\n",
      "Epoch [6/300], Step [178/225], Training Accuracy: 37.2367%, Training Loss: 1.2798%\n",
      "Epoch [6/300], Step [179/225], Training Accuracy: 37.2556%, Training Loss: 1.2800%\n",
      "Epoch [6/300], Step [180/225], Training Accuracy: 37.3524%, Training Loss: 1.2792%\n",
      "Epoch [6/300], Step [181/225], Training Accuracy: 37.3446%, Training Loss: 1.2793%\n",
      "Epoch [6/300], Step [182/225], Training Accuracy: 37.3541%, Training Loss: 1.2791%\n",
      "Epoch [6/300], Step [183/225], Training Accuracy: 37.3719%, Training Loss: 1.2789%\n",
      "Epoch [6/300], Step [184/225], Training Accuracy: 37.4151%, Training Loss: 1.2785%\n",
      "Epoch [6/300], Step [185/225], Training Accuracy: 37.4493%, Training Loss: 1.2781%\n",
      "Epoch [6/300], Step [186/225], Training Accuracy: 37.4748%, Training Loss: 1.2779%\n",
      "Epoch [6/300], Step [187/225], Training Accuracy: 37.5585%, Training Loss: 1.2771%\n",
      "Epoch [6/300], Step [188/225], Training Accuracy: 37.6330%, Training Loss: 1.2767%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/300], Step [189/225], Training Accuracy: 37.6571%, Training Loss: 1.2762%\n",
      "Epoch [6/300], Step [190/225], Training Accuracy: 37.6480%, Training Loss: 1.2762%\n",
      "Epoch [6/300], Step [191/225], Training Accuracy: 37.6309%, Training Loss: 1.2766%\n",
      "Epoch [6/300], Step [192/225], Training Accuracy: 37.6628%, Training Loss: 1.2765%\n",
      "Epoch [6/300], Step [193/225], Training Accuracy: 37.6457%, Training Loss: 1.2763%\n",
      "Epoch [6/300], Step [194/225], Training Accuracy: 37.6691%, Training Loss: 1.2759%\n",
      "Epoch [6/300], Step [195/225], Training Accuracy: 37.6763%, Training Loss: 1.2756%\n",
      "Epoch [6/300], Step [196/225], Training Accuracy: 37.6754%, Training Loss: 1.2759%\n",
      "Epoch [6/300], Step [197/225], Training Accuracy: 37.6666%, Training Loss: 1.2763%\n",
      "Epoch [6/300], Step [198/225], Training Accuracy: 37.6815%, Training Loss: 1.2756%\n",
      "Epoch [6/300], Step [199/225], Training Accuracy: 37.6570%, Training Loss: 1.2755%\n",
      "Epoch [6/300], Step [200/225], Training Accuracy: 37.6406%, Training Loss: 1.2756%\n",
      "Epoch [6/300], Step [201/225], Training Accuracy: 37.6632%, Training Loss: 1.2755%\n",
      "Epoch [6/300], Step [202/225], Training Accuracy: 37.6702%, Training Loss: 1.2754%\n",
      "Epoch [6/300], Step [203/225], Training Accuracy: 37.6539%, Training Loss: 1.2758%\n",
      "Epoch [6/300], Step [204/225], Training Accuracy: 37.6302%, Training Loss: 1.2759%\n",
      "Epoch [6/300], Step [205/225], Training Accuracy: 37.6677%, Training Loss: 1.2755%\n",
      "Epoch [6/300], Step [206/225], Training Accuracy: 37.6820%, Training Loss: 1.2755%\n",
      "Epoch [6/300], Step [207/225], Training Accuracy: 37.6661%, Training Loss: 1.2756%\n",
      "Epoch [6/300], Step [208/225], Training Accuracy: 37.7028%, Training Loss: 1.2750%\n",
      "Epoch [6/300], Step [209/225], Training Accuracy: 37.7019%, Training Loss: 1.2749%\n",
      "Epoch [6/300], Step [210/225], Training Accuracy: 37.7381%, Training Loss: 1.2745%\n",
      "Epoch [6/300], Step [211/225], Training Accuracy: 37.7370%, Training Loss: 1.2741%\n",
      "Epoch [6/300], Step [212/225], Training Accuracy: 37.7580%, Training Loss: 1.2737%\n",
      "Epoch [6/300], Step [213/225], Training Accuracy: 37.7421%, Training Loss: 1.2738%\n",
      "Epoch [6/300], Step [214/225], Training Accuracy: 37.7555%, Training Loss: 1.2736%\n",
      "Epoch [6/300], Step [215/225], Training Accuracy: 37.7326%, Training Loss: 1.2739%\n",
      "Epoch [6/300], Step [216/225], Training Accuracy: 37.6664%, Training Loss: 1.2742%\n",
      "Epoch [6/300], Step [217/225], Training Accuracy: 37.6584%, Training Loss: 1.2739%\n",
      "Epoch [6/300], Step [218/225], Training Accuracy: 37.6792%, Training Loss: 1.2738%\n",
      "Epoch [6/300], Step [219/225], Training Accuracy: 37.7069%, Training Loss: 1.2732%\n",
      "Epoch [6/300], Step [220/225], Training Accuracy: 37.7131%, Training Loss: 1.2728%\n",
      "Epoch [6/300], Step [221/225], Training Accuracy: 37.7333%, Training Loss: 1.2727%\n",
      "Epoch [6/300], Step [222/225], Training Accuracy: 37.7815%, Training Loss: 1.2721%\n",
      "Epoch [6/300], Step [223/225], Training Accuracy: 37.7943%, Training Loss: 1.2723%\n",
      "Epoch [6/300], Step [224/225], Training Accuracy: 37.8069%, Training Loss: 1.2717%\n",
      "Epoch [6/300], Step [225/225], Training Accuracy: 37.7918%, Training Loss: 1.2718%\n",
      "Epoch [7/300], Step [1/225], Training Accuracy: 34.3750%, Training Loss: 1.3461%\n",
      "Epoch [7/300], Step [2/225], Training Accuracy: 33.5938%, Training Loss: 1.3031%\n",
      "Epoch [7/300], Step [3/225], Training Accuracy: 32.8125%, Training Loss: 1.3040%\n",
      "Epoch [7/300], Step [4/225], Training Accuracy: 34.7656%, Training Loss: 1.2924%\n",
      "Epoch [7/300], Step [5/225], Training Accuracy: 36.5625%, Training Loss: 1.2812%\n",
      "Epoch [7/300], Step [6/225], Training Accuracy: 36.4583%, Training Loss: 1.2701%\n",
      "Epoch [7/300], Step [7/225], Training Accuracy: 35.7143%, Training Loss: 1.2775%\n",
      "Epoch [7/300], Step [8/225], Training Accuracy: 34.7656%, Training Loss: 1.2843%\n",
      "Epoch [7/300], Step [9/225], Training Accuracy: 35.5903%, Training Loss: 1.2801%\n",
      "Epoch [7/300], Step [10/225], Training Accuracy: 36.0938%, Training Loss: 1.2801%\n",
      "Epoch [7/300], Step [11/225], Training Accuracy: 36.5057%, Training Loss: 1.2746%\n",
      "Epoch [7/300], Step [12/225], Training Accuracy: 36.0677%, Training Loss: 1.2752%\n",
      "Epoch [7/300], Step [13/225], Training Accuracy: 35.5769%, Training Loss: 1.2793%\n",
      "Epoch [7/300], Step [14/225], Training Accuracy: 35.7143%, Training Loss: 1.2798%\n",
      "Epoch [7/300], Step [15/225], Training Accuracy: 35.3125%, Training Loss: 1.2897%\n",
      "Epoch [7/300], Step [16/225], Training Accuracy: 36.3281%, Training Loss: 1.2842%\n",
      "Epoch [7/300], Step [17/225], Training Accuracy: 36.7647%, Training Loss: 1.2802%\n",
      "Epoch [7/300], Step [18/225], Training Accuracy: 36.6319%, Training Loss: 1.2820%\n",
      "Epoch [7/300], Step [19/225], Training Accuracy: 36.5954%, Training Loss: 1.2810%\n",
      "Epoch [7/300], Step [20/225], Training Accuracy: 36.9531%, Training Loss: 1.2763%\n",
      "Epoch [7/300], Step [21/225], Training Accuracy: 37.1280%, Training Loss: 1.2760%\n",
      "Epoch [7/300], Step [22/225], Training Accuracy: 37.2159%, Training Loss: 1.2736%\n",
      "Epoch [7/300], Step [23/225], Training Accuracy: 37.0924%, Training Loss: 1.2740%\n",
      "Epoch [7/300], Step [24/225], Training Accuracy: 37.2396%, Training Loss: 1.2717%\n",
      "Epoch [7/300], Step [25/225], Training Accuracy: 37.5000%, Training Loss: 1.2695%\n",
      "Epoch [7/300], Step [26/225], Training Accuracy: 37.1394%, Training Loss: 1.2719%\n",
      "Epoch [7/300], Step [27/225], Training Accuracy: 37.0949%, Training Loss: 1.2723%\n",
      "Epoch [7/300], Step [28/225], Training Accuracy: 37.3884%, Training Loss: 1.2694%\n",
      "Epoch [7/300], Step [29/225], Training Accuracy: 37.6078%, Training Loss: 1.2652%\n",
      "Epoch [7/300], Step [30/225], Training Accuracy: 37.6562%, Training Loss: 1.2628%\n",
      "Epoch [7/300], Step [31/225], Training Accuracy: 37.5504%, Training Loss: 1.2632%\n",
      "Epoch [7/300], Step [32/225], Training Accuracy: 37.5488%, Training Loss: 1.2604%\n",
      "Epoch [7/300], Step [33/225], Training Accuracy: 37.5947%, Training Loss: 1.2581%\n",
      "Epoch [7/300], Step [34/225], Training Accuracy: 37.5460%, Training Loss: 1.2590%\n",
      "Epoch [7/300], Step [35/225], Training Accuracy: 37.5000%, Training Loss: 1.2595%\n",
      "Epoch [7/300], Step [36/225], Training Accuracy: 37.3264%, Training Loss: 1.2629%\n",
      "Epoch [7/300], Step [37/225], Training Accuracy: 37.5000%, Training Loss: 1.2642%\n",
      "Epoch [7/300], Step [38/225], Training Accuracy: 37.5822%, Training Loss: 1.2630%\n",
      "Epoch [7/300], Step [39/225], Training Accuracy: 37.5401%, Training Loss: 1.2623%\n",
      "Epoch [7/300], Step [40/225], Training Accuracy: 37.3828%, Training Loss: 1.2624%\n",
      "Epoch [7/300], Step [41/225], Training Accuracy: 37.5000%, Training Loss: 1.2615%\n",
      "Epoch [7/300], Step [42/225], Training Accuracy: 37.6116%, Training Loss: 1.2602%\n",
      "Epoch [7/300], Step [43/225], Training Accuracy: 37.4637%, Training Loss: 1.2603%\n",
      "Epoch [7/300], Step [44/225], Training Accuracy: 37.5000%, Training Loss: 1.2594%\n",
      "Epoch [7/300], Step [45/225], Training Accuracy: 37.8472%, Training Loss: 1.2564%\n",
      "Epoch [7/300], Step [46/225], Training Accuracy: 37.8397%, Training Loss: 1.2553%\n",
      "Epoch [7/300], Step [47/225], Training Accuracy: 37.9322%, Training Loss: 1.2545%\n",
      "Epoch [7/300], Step [48/225], Training Accuracy: 38.0208%, Training Loss: 1.2531%\n",
      "Epoch [7/300], Step [49/225], Training Accuracy: 38.1378%, Training Loss: 1.2528%\n",
      "Epoch [7/300], Step [50/225], Training Accuracy: 38.2500%, Training Loss: 1.2515%\n",
      "Epoch [7/300], Step [51/225], Training Accuracy: 38.3578%, Training Loss: 1.2519%\n",
      "Epoch [7/300], Step [52/225], Training Accuracy: 38.4916%, Training Loss: 1.2519%\n",
      "Epoch [7/300], Step [53/225], Training Accuracy: 38.5613%, Training Loss: 1.2523%\n",
      "Epoch [7/300], Step [54/225], Training Accuracy: 38.5706%, Training Loss: 1.2512%\n",
      "Epoch [7/300], Step [55/225], Training Accuracy: 38.5511%, Training Loss: 1.2525%\n",
      "Epoch [7/300], Step [56/225], Training Accuracy: 38.4487%, Training Loss: 1.2535%\n",
      "Epoch [7/300], Step [57/225], Training Accuracy: 38.5965%, Training Loss: 1.2516%\n",
      "Epoch [7/300], Step [58/225], Training Accuracy: 38.5506%, Training Loss: 1.2506%\n",
      "Epoch [7/300], Step [59/225], Training Accuracy: 38.4534%, Training Loss: 1.2497%\n",
      "Epoch [7/300], Step [60/225], Training Accuracy: 38.4635%, Training Loss: 1.2484%\n",
      "Epoch [7/300], Step [61/225], Training Accuracy: 38.5502%, Training Loss: 1.2472%\n",
      "Epoch [7/300], Step [62/225], Training Accuracy: 38.5585%, Training Loss: 1.2463%\n",
      "Epoch [7/300], Step [63/225], Training Accuracy: 38.4921%, Training Loss: 1.2479%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/300], Step [64/225], Training Accuracy: 38.4277%, Training Loss: 1.2492%\n",
      "Epoch [7/300], Step [65/225], Training Accuracy: 38.4856%, Training Loss: 1.2510%\n",
      "Epoch [7/300], Step [66/225], Training Accuracy: 38.5180%, Training Loss: 1.2497%\n",
      "Epoch [7/300], Step [67/225], Training Accuracy: 38.6194%, Training Loss: 1.2488%\n",
      "Epoch [7/300], Step [68/225], Training Accuracy: 38.6029%, Training Loss: 1.2485%\n",
      "Epoch [7/300], Step [69/225], Training Accuracy: 38.5643%, Training Loss: 1.2491%\n",
      "Epoch [7/300], Step [70/225], Training Accuracy: 38.5491%, Training Loss: 1.2500%\n",
      "Epoch [7/300], Step [71/225], Training Accuracy: 38.6004%, Training Loss: 1.2503%\n",
      "Epoch [7/300], Step [72/225], Training Accuracy: 38.6719%, Training Loss: 1.2502%\n",
      "Epoch [7/300], Step [73/225], Training Accuracy: 38.7200%, Training Loss: 1.2514%\n",
      "Epoch [7/300], Step [74/225], Training Accuracy: 38.8302%, Training Loss: 1.2505%\n",
      "Epoch [7/300], Step [75/225], Training Accuracy: 38.9583%, Training Loss: 1.2492%\n",
      "Epoch [7/300], Step [76/225], Training Accuracy: 39.0625%, Training Loss: 1.2483%\n",
      "Epoch [7/300], Step [77/225], Training Accuracy: 39.1031%, Training Loss: 1.2482%\n",
      "Epoch [7/300], Step [78/225], Training Accuracy: 39.0825%, Training Loss: 1.2481%\n",
      "Epoch [7/300], Step [79/225], Training Accuracy: 39.1416%, Training Loss: 1.2487%\n",
      "Epoch [7/300], Step [80/225], Training Accuracy: 39.1211%, Training Loss: 1.2495%\n",
      "Epoch [7/300], Step [81/225], Training Accuracy: 39.2168%, Training Loss: 1.2496%\n",
      "Epoch [7/300], Step [82/225], Training Accuracy: 39.3483%, Training Loss: 1.2485%\n",
      "Epoch [7/300], Step [83/225], Training Accuracy: 39.5331%, Training Loss: 1.2468%\n",
      "Epoch [7/300], Step [84/225], Training Accuracy: 39.5833%, Training Loss: 1.2461%\n",
      "Epoch [7/300], Step [85/225], Training Accuracy: 39.6875%, Training Loss: 1.2451%\n",
      "Epoch [7/300], Step [86/225], Training Accuracy: 39.6257%, Training Loss: 1.2469%\n",
      "Epoch [7/300], Step [87/225], Training Accuracy: 39.7091%, Training Loss: 1.2466%\n",
      "Epoch [7/300], Step [88/225], Training Accuracy: 39.6129%, Training Loss: 1.2469%\n",
      "Epoch [7/300], Step [89/225], Training Accuracy: 39.5190%, Training Loss: 1.2477%\n",
      "Epoch [7/300], Step [90/225], Training Accuracy: 39.5139%, Training Loss: 1.2474%\n",
      "Epoch [7/300], Step [91/225], Training Accuracy: 39.4918%, Training Loss: 1.2479%\n",
      "Epoch [7/300], Step [92/225], Training Accuracy: 39.4871%, Training Loss: 1.2476%\n",
      "Epoch [7/300], Step [93/225], Training Accuracy: 39.4993%, Training Loss: 1.2480%\n",
      "Epoch [7/300], Step [94/225], Training Accuracy: 39.5612%, Training Loss: 1.2465%\n",
      "Epoch [7/300], Step [95/225], Training Accuracy: 39.4243%, Training Loss: 1.2476%\n",
      "Epoch [7/300], Step [96/225], Training Accuracy: 39.5345%, Training Loss: 1.2469%\n",
      "Epoch [7/300], Step [97/225], Training Accuracy: 39.5457%, Training Loss: 1.2460%\n",
      "Epoch [7/300], Step [98/225], Training Accuracy: 39.4770%, Training Loss: 1.2459%\n",
      "Epoch [7/300], Step [99/225], Training Accuracy: 39.5991%, Training Loss: 1.2452%\n",
      "Epoch [7/300], Step [100/225], Training Accuracy: 39.5312%, Training Loss: 1.2453%\n",
      "Epoch [7/300], Step [101/225], Training Accuracy: 39.6349%, Training Loss: 1.2448%\n",
      "Epoch [7/300], Step [102/225], Training Accuracy: 39.5680%, Training Loss: 1.2447%\n",
      "Epoch [7/300], Step [103/225], Training Accuracy: 39.6238%, Training Loss: 1.2443%\n",
      "Epoch [7/300], Step [104/225], Training Accuracy: 39.6334%, Training Loss: 1.2439%\n",
      "Epoch [7/300], Step [105/225], Training Accuracy: 39.7024%, Training Loss: 1.2438%\n",
      "Epoch [7/300], Step [106/225], Training Accuracy: 39.7848%, Training Loss: 1.2434%\n",
      "Epoch [7/300], Step [107/225], Training Accuracy: 39.7488%, Training Loss: 1.2431%\n",
      "Epoch [7/300], Step [108/225], Training Accuracy: 39.6846%, Training Loss: 1.2432%\n",
      "Epoch [7/300], Step [109/225], Training Accuracy: 39.7506%, Training Loss: 1.2425%\n",
      "Epoch [7/300], Step [110/225], Training Accuracy: 39.8438%, Training Loss: 1.2416%\n",
      "Epoch [7/300], Step [111/225], Training Accuracy: 39.8508%, Training Loss: 1.2419%\n",
      "Epoch [7/300], Step [112/225], Training Accuracy: 39.8717%, Training Loss: 1.2423%\n",
      "Epoch [7/300], Step [113/225], Training Accuracy: 39.8368%, Training Loss: 1.2424%\n",
      "Epoch [7/300], Step [114/225], Training Accuracy: 39.8849%, Training Loss: 1.2412%\n",
      "Epoch [7/300], Step [115/225], Training Accuracy: 39.9185%, Training Loss: 1.2405%\n",
      "Epoch [7/300], Step [116/225], Training Accuracy: 39.8976%, Training Loss: 1.2401%\n",
      "Epoch [7/300], Step [117/225], Training Accuracy: 39.8104%, Training Loss: 1.2409%\n",
      "Epoch [7/300], Step [118/225], Training Accuracy: 39.8305%, Training Loss: 1.2407%\n",
      "Epoch [7/300], Step [119/225], Training Accuracy: 39.7978%, Training Loss: 1.2405%\n",
      "Epoch [7/300], Step [120/225], Training Accuracy: 39.7656%, Training Loss: 1.2410%\n",
      "Epoch [7/300], Step [121/225], Training Accuracy: 39.7727%, Training Loss: 1.2403%\n",
      "Epoch [7/300], Step [122/225], Training Accuracy: 39.7925%, Training Loss: 1.2399%\n",
      "Epoch [7/300], Step [123/225], Training Accuracy: 39.8120%, Training Loss: 1.2398%\n",
      "Epoch [7/300], Step [124/225], Training Accuracy: 39.8564%, Training Loss: 1.2384%\n",
      "Epoch [7/300], Step [125/225], Training Accuracy: 39.8125%, Training Loss: 1.2387%\n",
      "Epoch [7/300], Step [126/225], Training Accuracy: 39.7817%, Training Loss: 1.2391%\n",
      "Epoch [7/300], Step [127/225], Training Accuracy: 39.7761%, Training Loss: 1.2389%\n",
      "Epoch [7/300], Step [128/225], Training Accuracy: 39.7461%, Training Loss: 1.2384%\n",
      "Epoch [7/300], Step [129/225], Training Accuracy: 39.7529%, Training Loss: 1.2379%\n",
      "Epoch [7/300], Step [130/225], Training Accuracy: 39.6995%, Training Loss: 1.2386%\n",
      "Epoch [7/300], Step [131/225], Training Accuracy: 39.7066%, Training Loss: 1.2384%\n",
      "Epoch [7/300], Step [132/225], Training Accuracy: 39.7609%, Training Loss: 1.2379%\n",
      "Epoch [7/300], Step [133/225], Training Accuracy: 39.7556%, Training Loss: 1.2377%\n",
      "Epoch [7/300], Step [134/225], Training Accuracy: 39.6572%, Training Loss: 1.2386%\n",
      "Epoch [7/300], Step [135/225], Training Accuracy: 39.6528%, Training Loss: 1.2389%\n",
      "Epoch [7/300], Step [136/225], Training Accuracy: 39.6140%, Training Loss: 1.2390%\n",
      "Epoch [7/300], Step [137/225], Training Accuracy: 39.6442%, Training Loss: 1.2384%\n",
      "Epoch [7/300], Step [138/225], Training Accuracy: 39.6626%, Training Loss: 1.2385%\n",
      "Epoch [7/300], Step [139/225], Training Accuracy: 39.6358%, Training Loss: 1.2388%\n",
      "Epoch [7/300], Step [140/225], Training Accuracy: 39.6652%, Training Loss: 1.2390%\n",
      "Epoch [7/300], Step [141/225], Training Accuracy: 39.7717%, Training Loss: 1.2378%\n",
      "Epoch [7/300], Step [142/225], Training Accuracy: 39.7777%, Training Loss: 1.2370%\n",
      "Epoch [7/300], Step [143/225], Training Accuracy: 39.8274%, Training Loss: 1.2368%\n",
      "Epoch [7/300], Step [144/225], Training Accuracy: 39.7895%, Training Loss: 1.2372%\n",
      "Epoch [7/300], Step [145/225], Training Accuracy: 39.7737%, Training Loss: 1.2375%\n",
      "Epoch [7/300], Step [146/225], Training Accuracy: 39.7153%, Training Loss: 1.2383%\n",
      "Epoch [7/300], Step [147/225], Training Accuracy: 39.7428%, Training Loss: 1.2376%\n",
      "Epoch [7/300], Step [148/225], Training Accuracy: 39.8226%, Training Loss: 1.2367%\n",
      "Epoch [7/300], Step [149/225], Training Accuracy: 39.8700%, Training Loss: 1.2366%\n",
      "Epoch [7/300], Step [150/225], Training Accuracy: 39.9062%, Training Loss: 1.2362%\n",
      "Epoch [7/300], Step [151/225], Training Accuracy: 39.9524%, Training Loss: 1.2356%\n",
      "Epoch [7/300], Step [152/225], Training Accuracy: 39.9568%, Training Loss: 1.2355%\n",
      "Epoch [7/300], Step [153/225], Training Accuracy: 39.9510%, Training Loss: 1.2352%\n",
      "Epoch [7/300], Step [154/225], Training Accuracy: 39.9452%, Training Loss: 1.2354%\n",
      "Epoch [7/300], Step [155/225], Training Accuracy: 39.9597%, Training Loss: 1.2351%\n",
      "Epoch [7/300], Step [156/225], Training Accuracy: 39.9439%, Training Loss: 1.2356%\n",
      "Epoch [7/300], Step [157/225], Training Accuracy: 39.8985%, Training Loss: 1.2362%\n",
      "Epoch [7/300], Step [158/225], Training Accuracy: 39.8734%, Training Loss: 1.2363%\n",
      "Epoch [7/300], Step [159/225], Training Accuracy: 39.9371%, Training Loss: 1.2355%\n",
      "Epoch [7/300], Step [160/225], Training Accuracy: 39.9121%, Training Loss: 1.2360%\n",
      "Epoch [7/300], Step [161/225], Training Accuracy: 39.9942%, Training Loss: 1.2353%\n",
      "Epoch [7/300], Step [162/225], Training Accuracy: 40.0077%, Training Loss: 1.2353%\n",
      "Epoch [7/300], Step [163/225], Training Accuracy: 40.0498%, Training Loss: 1.2348%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/300], Step [164/225], Training Accuracy: 40.1105%, Training Loss: 1.2341%\n",
      "Epoch [7/300], Step [165/225], Training Accuracy: 40.0758%, Training Loss: 1.2348%\n",
      "Epoch [7/300], Step [166/225], Training Accuracy: 40.0602%, Training Loss: 1.2348%\n",
      "Epoch [7/300], Step [167/225], Training Accuracy: 40.1104%, Training Loss: 1.2343%\n",
      "Epoch [7/300], Step [168/225], Training Accuracy: 40.1042%, Training Loss: 1.2345%\n",
      "Epoch [7/300], Step [169/225], Training Accuracy: 40.0980%, Training Loss: 1.2341%\n",
      "Epoch [7/300], Step [170/225], Training Accuracy: 40.0919%, Training Loss: 1.2345%\n",
      "Epoch [7/300], Step [171/225], Training Accuracy: 40.1773%, Training Loss: 1.2334%\n",
      "Epoch [7/300], Step [172/225], Training Accuracy: 40.1344%, Training Loss: 1.2338%\n",
      "Epoch [7/300], Step [173/225], Training Accuracy: 40.1373%, Training Loss: 1.2337%\n",
      "Epoch [7/300], Step [174/225], Training Accuracy: 40.1401%, Training Loss: 1.2335%\n",
      "Epoch [7/300], Step [175/225], Training Accuracy: 40.0804%, Training Loss: 1.2343%\n",
      "Epoch [7/300], Step [176/225], Training Accuracy: 40.0391%, Training Loss: 1.2347%\n",
      "Epoch [7/300], Step [177/225], Training Accuracy: 40.0159%, Training Loss: 1.2346%\n",
      "Epoch [7/300], Step [178/225], Training Accuracy: 39.9930%, Training Loss: 1.2347%\n",
      "Epoch [7/300], Step [179/225], Training Accuracy: 40.0052%, Training Loss: 1.2349%\n",
      "Epoch [7/300], Step [180/225], Training Accuracy: 40.1042%, Training Loss: 1.2340%\n",
      "Epoch [7/300], Step [181/225], Training Accuracy: 40.0639%, Training Loss: 1.2339%\n",
      "Epoch [7/300], Step [182/225], Training Accuracy: 40.0927%, Training Loss: 1.2338%\n",
      "Epoch [7/300], Step [183/225], Training Accuracy: 40.0786%, Training Loss: 1.2336%\n",
      "Epoch [7/300], Step [184/225], Training Accuracy: 40.0900%, Training Loss: 1.2336%\n",
      "Epoch [7/300], Step [185/225], Training Accuracy: 40.1436%, Training Loss: 1.2332%\n",
      "Epoch [7/300], Step [186/225], Training Accuracy: 40.1546%, Training Loss: 1.2330%\n",
      "Epoch [7/300], Step [187/225], Training Accuracy: 40.2072%, Training Loss: 1.2327%\n",
      "Epoch [7/300], Step [188/225], Training Accuracy: 40.2427%, Training Loss: 1.2327%\n",
      "Epoch [7/300], Step [189/225], Training Accuracy: 40.2530%, Training Loss: 1.2320%\n",
      "Epoch [7/300], Step [190/225], Training Accuracy: 40.2385%, Training Loss: 1.2321%\n",
      "Epoch [7/300], Step [191/225], Training Accuracy: 40.2487%, Training Loss: 1.2323%\n",
      "Epoch [7/300], Step [192/225], Training Accuracy: 40.2588%, Training Loss: 1.2322%\n",
      "Epoch [7/300], Step [193/225], Training Accuracy: 40.2607%, Training Loss: 1.2323%\n",
      "Epoch [7/300], Step [194/225], Training Accuracy: 40.3351%, Training Loss: 1.2319%\n",
      "Epoch [7/300], Step [195/225], Training Accuracy: 40.3846%, Training Loss: 1.2313%\n",
      "Epoch [7/300], Step [196/225], Training Accuracy: 40.3300%, Training Loss: 1.2317%\n",
      "Epoch [7/300], Step [197/225], Training Accuracy: 40.3157%, Training Loss: 1.2317%\n",
      "Epoch [7/300], Step [198/225], Training Accuracy: 40.3725%, Training Loss: 1.2309%\n",
      "Epoch [7/300], Step [199/225], Training Accuracy: 40.3737%, Training Loss: 1.2306%\n",
      "Epoch [7/300], Step [200/225], Training Accuracy: 40.3750%, Training Loss: 1.2308%\n",
      "Epoch [7/300], Step [201/225], Training Accuracy: 40.3529%, Training Loss: 1.2308%\n",
      "Epoch [7/300], Step [202/225], Training Accuracy: 40.3620%, Training Loss: 1.2308%\n",
      "Epoch [7/300], Step [203/225], Training Accuracy: 40.3325%, Training Loss: 1.2309%\n",
      "Epoch [7/300], Step [204/225], Training Accuracy: 40.3646%, Training Loss: 1.2304%\n",
      "Epoch [7/300], Step [205/225], Training Accuracy: 40.3735%, Training Loss: 1.2304%\n",
      "Epoch [7/300], Step [206/225], Training Accuracy: 40.3747%, Training Loss: 1.2304%\n",
      "Epoch [7/300], Step [207/225], Training Accuracy: 40.3759%, Training Loss: 1.2302%\n",
      "Epoch [7/300], Step [208/225], Training Accuracy: 40.4372%, Training Loss: 1.2298%\n",
      "Epoch [7/300], Step [209/225], Training Accuracy: 40.4680%, Training Loss: 1.2297%\n",
      "Epoch [7/300], Step [210/225], Training Accuracy: 40.5134%, Training Loss: 1.2292%\n",
      "Epoch [7/300], Step [211/225], Training Accuracy: 40.5139%, Training Loss: 1.2287%\n",
      "Epoch [7/300], Step [212/225], Training Accuracy: 40.5218%, Training Loss: 1.2283%\n",
      "Epoch [7/300], Step [213/225], Training Accuracy: 40.4783%, Training Loss: 1.2282%\n",
      "Epoch [7/300], Step [214/225], Training Accuracy: 40.4644%, Training Loss: 1.2281%\n",
      "Epoch [7/300], Step [215/225], Training Accuracy: 40.4142%, Training Loss: 1.2283%\n",
      "Epoch [7/300], Step [216/225], Training Accuracy: 40.3573%, Training Loss: 1.2288%\n",
      "Epoch [7/300], Step [217/225], Training Accuracy: 40.3658%, Training Loss: 1.2286%\n",
      "Epoch [7/300], Step [218/225], Training Accuracy: 40.3813%, Training Loss: 1.2284%\n",
      "Epoch [7/300], Step [219/225], Training Accuracy: 40.4038%, Training Loss: 1.2280%\n",
      "Epoch [7/300], Step [220/225], Training Accuracy: 40.4474%, Training Loss: 1.2276%\n",
      "Epoch [7/300], Step [221/225], Training Accuracy: 40.4553%, Training Loss: 1.2274%\n",
      "Epoch [7/300], Step [222/225], Training Accuracy: 40.4842%, Training Loss: 1.2270%\n",
      "Epoch [7/300], Step [223/225], Training Accuracy: 40.5199%, Training Loss: 1.2270%\n",
      "Epoch [7/300], Step [224/225], Training Accuracy: 40.5483%, Training Loss: 1.2264%\n",
      "Epoch [7/300], Step [225/225], Training Accuracy: 40.5503%, Training Loss: 1.2265%\n",
      "Epoch [8/300], Step [1/225], Training Accuracy: 40.6250%, Training Loss: 1.3074%\n",
      "Epoch [8/300], Step [2/225], Training Accuracy: 36.7188%, Training Loss: 1.2587%\n",
      "Epoch [8/300], Step [3/225], Training Accuracy: 33.8542%, Training Loss: 1.2709%\n",
      "Epoch [8/300], Step [4/225], Training Accuracy: 35.9375%, Training Loss: 1.2474%\n",
      "Epoch [8/300], Step [5/225], Training Accuracy: 36.8750%, Training Loss: 1.2352%\n",
      "Epoch [8/300], Step [6/225], Training Accuracy: 37.5000%, Training Loss: 1.2289%\n",
      "Epoch [8/300], Step [7/225], Training Accuracy: 37.2768%, Training Loss: 1.2422%\n",
      "Epoch [8/300], Step [8/225], Training Accuracy: 37.1094%, Training Loss: 1.2396%\n",
      "Epoch [8/300], Step [9/225], Training Accuracy: 37.8472%, Training Loss: 1.2337%\n",
      "Epoch [8/300], Step [10/225], Training Accuracy: 37.8125%, Training Loss: 1.2380%\n",
      "Epoch [8/300], Step [11/225], Training Accuracy: 37.6420%, Training Loss: 1.2356%\n",
      "Epoch [8/300], Step [12/225], Training Accuracy: 37.3698%, Training Loss: 1.2332%\n",
      "Epoch [8/300], Step [13/225], Training Accuracy: 37.3798%, Training Loss: 1.2370%\n",
      "Epoch [8/300], Step [14/225], Training Accuracy: 38.0580%, Training Loss: 1.2335%\n",
      "Epoch [8/300], Step [15/225], Training Accuracy: 37.9167%, Training Loss: 1.2395%\n",
      "Epoch [8/300], Step [16/225], Training Accuracy: 37.8906%, Training Loss: 1.2402%\n",
      "Epoch [8/300], Step [17/225], Training Accuracy: 38.5110%, Training Loss: 1.2342%\n",
      "Epoch [8/300], Step [18/225], Training Accuracy: 38.7153%, Training Loss: 1.2368%\n",
      "Epoch [8/300], Step [19/225], Training Accuracy: 38.6513%, Training Loss: 1.2359%\n",
      "Epoch [8/300], Step [20/225], Training Accuracy: 38.8281%, Training Loss: 1.2314%\n",
      "Epoch [8/300], Step [21/225], Training Accuracy: 39.3601%, Training Loss: 1.2274%\n",
      "Epoch [8/300], Step [22/225], Training Accuracy: 39.5597%, Training Loss: 1.2269%\n",
      "Epoch [8/300], Step [23/225], Training Accuracy: 39.4701%, Training Loss: 1.2243%\n",
      "Epoch [8/300], Step [24/225], Training Accuracy: 39.7135%, Training Loss: 1.2198%\n",
      "Epoch [8/300], Step [25/225], Training Accuracy: 39.9375%, Training Loss: 1.2158%\n",
      "Epoch [8/300], Step [26/225], Training Accuracy: 39.7837%, Training Loss: 1.2174%\n",
      "Epoch [8/300], Step [27/225], Training Accuracy: 39.5255%, Training Loss: 1.2187%\n",
      "Epoch [8/300], Step [28/225], Training Accuracy: 39.8438%, Training Loss: 1.2155%\n",
      "Epoch [8/300], Step [29/225], Training Accuracy: 39.9246%, Training Loss: 1.2126%\n",
      "Epoch [8/300], Step [30/225], Training Accuracy: 40.0521%, Training Loss: 1.2115%\n",
      "Epoch [8/300], Step [31/225], Training Accuracy: 40.1210%, Training Loss: 1.2104%\n",
      "Epoch [8/300], Step [32/225], Training Accuracy: 40.1367%, Training Loss: 1.2084%\n",
      "Epoch [8/300], Step [33/225], Training Accuracy: 40.1989%, Training Loss: 1.2072%\n",
      "Epoch [8/300], Step [34/225], Training Accuracy: 40.2114%, Training Loss: 1.2087%\n",
      "Epoch [8/300], Step [35/225], Training Accuracy: 40.3571%, Training Loss: 1.2084%\n",
      "Epoch [8/300], Step [36/225], Training Accuracy: 40.5382%, Training Loss: 1.2095%\n",
      "Epoch [8/300], Step [37/225], Training Accuracy: 40.8784%, Training Loss: 1.2080%\n",
      "Epoch [8/300], Step [38/225], Training Accuracy: 41.0773%, Training Loss: 1.2071%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/300], Step [39/225], Training Accuracy: 40.8654%, Training Loss: 1.2061%\n",
      "Epoch [8/300], Step [40/225], Training Accuracy: 40.5859%, Training Loss: 1.2059%\n",
      "Epoch [8/300], Step [41/225], Training Accuracy: 40.3582%, Training Loss: 1.2074%\n",
      "Epoch [8/300], Step [42/225], Training Accuracy: 40.2902%, Training Loss: 1.2072%\n",
      "Epoch [8/300], Step [43/225], Training Accuracy: 40.3706%, Training Loss: 1.2079%\n",
      "Epoch [8/300], Step [44/225], Training Accuracy: 40.4119%, Training Loss: 1.2067%\n",
      "Epoch [8/300], Step [45/225], Training Accuracy: 40.8681%, Training Loss: 1.2037%\n",
      "Epoch [8/300], Step [46/225], Training Accuracy: 40.9647%, Training Loss: 1.2029%\n",
      "Epoch [8/300], Step [47/225], Training Accuracy: 40.9907%, Training Loss: 1.2026%\n",
      "Epoch [8/300], Step [48/225], Training Accuracy: 41.0482%, Training Loss: 1.2006%\n",
      "Epoch [8/300], Step [49/225], Training Accuracy: 40.9439%, Training Loss: 1.2025%\n",
      "Epoch [8/300], Step [50/225], Training Accuracy: 41.0312%, Training Loss: 1.2023%\n",
      "Epoch [8/300], Step [51/225], Training Accuracy: 41.1458%, Training Loss: 1.2022%\n",
      "Epoch [8/300], Step [52/225], Training Accuracy: 41.1358%, Training Loss: 1.2027%\n",
      "Epoch [8/300], Step [53/225], Training Accuracy: 41.1557%, Training Loss: 1.2035%\n",
      "Epoch [8/300], Step [54/225], Training Accuracy: 41.0012%, Training Loss: 1.2037%\n",
      "Epoch [8/300], Step [55/225], Training Accuracy: 40.8807%, Training Loss: 1.2045%\n",
      "Epoch [8/300], Step [56/225], Training Accuracy: 40.7645%, Training Loss: 1.2049%\n",
      "Epoch [8/300], Step [57/225], Training Accuracy: 40.9814%, Training Loss: 1.2034%\n",
      "Epoch [8/300], Step [58/225], Training Accuracy: 40.9483%, Training Loss: 1.2030%\n",
      "Epoch [8/300], Step [59/225], Training Accuracy: 40.8633%, Training Loss: 1.2036%\n",
      "Epoch [8/300], Step [60/225], Training Accuracy: 40.8854%, Training Loss: 1.2038%\n",
      "Epoch [8/300], Step [61/225], Training Accuracy: 40.9068%, Training Loss: 1.2030%\n",
      "Epoch [8/300], Step [62/225], Training Accuracy: 40.9778%, Training Loss: 1.2024%\n",
      "Epoch [8/300], Step [63/225], Training Accuracy: 40.8978%, Training Loss: 1.2028%\n",
      "Epoch [8/300], Step [64/225], Training Accuracy: 40.7715%, Training Loss: 1.2037%\n",
      "Epoch [8/300], Step [65/225], Training Accuracy: 40.6490%, Training Loss: 1.2053%\n",
      "Epoch [8/300], Step [66/225], Training Accuracy: 40.9328%, Training Loss: 1.2031%\n",
      "Epoch [8/300], Step [67/225], Training Accuracy: 40.9748%, Training Loss: 1.2018%\n",
      "Epoch [8/300], Step [68/225], Training Accuracy: 40.9926%, Training Loss: 1.2009%\n",
      "Epoch [8/300], Step [69/225], Training Accuracy: 41.1458%, Training Loss: 1.1988%\n",
      "Epoch [8/300], Step [70/225], Training Accuracy: 41.1607%, Training Loss: 1.1996%\n",
      "Epoch [8/300], Step [71/225], Training Accuracy: 41.1312%, Training Loss: 1.1993%\n",
      "Epoch [8/300], Step [72/225], Training Accuracy: 41.2326%, Training Loss: 1.2007%\n",
      "Epoch [8/300], Step [73/225], Training Accuracy: 41.2671%, Training Loss: 1.2016%\n",
      "Epoch [8/300], Step [74/225], Training Accuracy: 41.3218%, Training Loss: 1.2002%\n",
      "Epoch [8/300], Step [75/225], Training Accuracy: 41.3958%, Training Loss: 1.1987%\n",
      "Epoch [8/300], Step [76/225], Training Accuracy: 41.4268%, Training Loss: 1.1983%\n",
      "Epoch [8/300], Step [77/225], Training Accuracy: 41.3961%, Training Loss: 1.1983%\n",
      "Epoch [8/300], Step [78/225], Training Accuracy: 41.5064%, Training Loss: 1.1980%\n",
      "Epoch [8/300], Step [79/225], Training Accuracy: 41.4755%, Training Loss: 1.1980%\n",
      "Epoch [8/300], Step [80/225], Training Accuracy: 41.5234%, Training Loss: 1.1980%\n",
      "Epoch [8/300], Step [81/225], Training Accuracy: 41.5895%, Training Loss: 1.1984%\n",
      "Epoch [8/300], Step [82/225], Training Accuracy: 41.6349%, Training Loss: 1.1986%\n",
      "Epoch [8/300], Step [83/225], Training Accuracy: 41.6792%, Training Loss: 1.1981%\n",
      "Epoch [8/300], Step [84/225], Training Accuracy: 41.7039%, Training Loss: 1.1968%\n",
      "Epoch [8/300], Step [85/225], Training Accuracy: 41.7463%, Training Loss: 1.1962%\n",
      "Epoch [8/300], Step [86/225], Training Accuracy: 41.7878%, Training Loss: 1.1965%\n",
      "Epoch [8/300], Step [87/225], Training Accuracy: 41.8103%, Training Loss: 1.1970%\n",
      "Epoch [8/300], Step [88/225], Training Accuracy: 41.7436%, Training Loss: 1.1975%\n",
      "Epoch [8/300], Step [89/225], Training Accuracy: 41.6433%, Training Loss: 1.1987%\n",
      "Epoch [8/300], Step [90/225], Training Accuracy: 41.5972%, Training Loss: 1.1987%\n",
      "Epoch [8/300], Step [91/225], Training Accuracy: 41.6209%, Training Loss: 1.1995%\n",
      "Epoch [8/300], Step [92/225], Training Accuracy: 41.4742%, Training Loss: 1.1996%\n",
      "Epoch [8/300], Step [93/225], Training Accuracy: 41.4987%, Training Loss: 1.1998%\n",
      "Epoch [8/300], Step [94/225], Training Accuracy: 41.5891%, Training Loss: 1.1983%\n",
      "Epoch [8/300], Step [95/225], Training Accuracy: 41.5132%, Training Loss: 1.1993%\n",
      "Epoch [8/300], Step [96/225], Training Accuracy: 41.6178%, Training Loss: 1.1988%\n",
      "Epoch [8/300], Step [97/225], Training Accuracy: 41.7204%, Training Loss: 1.1976%\n",
      "Epoch [8/300], Step [98/225], Training Accuracy: 41.7570%, Training Loss: 1.1977%\n",
      "Epoch [8/300], Step [99/225], Training Accuracy: 41.8561%, Training Loss: 1.1975%\n",
      "Epoch [8/300], Step [100/225], Training Accuracy: 41.7812%, Training Loss: 1.1980%\n",
      "Epoch [8/300], Step [101/225], Training Accuracy: 41.8472%, Training Loss: 1.1977%\n",
      "Epoch [8/300], Step [102/225], Training Accuracy: 41.7739%, Training Loss: 1.1978%\n",
      "Epoch [8/300], Step [103/225], Training Accuracy: 41.7931%, Training Loss: 1.1981%\n",
      "Epoch [8/300], Step [104/225], Training Accuracy: 41.7518%, Training Loss: 1.1985%\n",
      "Epoch [8/300], Step [105/225], Training Accuracy: 41.7411%, Training Loss: 1.1982%\n",
      "Epoch [8/300], Step [106/225], Training Accuracy: 41.7895%, Training Loss: 1.1979%\n",
      "Epoch [8/300], Step [107/225], Training Accuracy: 41.7640%, Training Loss: 1.1979%\n",
      "Epoch [8/300], Step [108/225], Training Accuracy: 41.7101%, Training Loss: 1.1984%\n",
      "Epoch [8/300], Step [109/225], Training Accuracy: 41.7144%, Training Loss: 1.1980%\n",
      "Epoch [8/300], Step [110/225], Training Accuracy: 41.7614%, Training Loss: 1.1975%\n",
      "Epoch [8/300], Step [111/225], Training Accuracy: 41.8215%, Training Loss: 1.1974%\n",
      "Epoch [8/300], Step [112/225], Training Accuracy: 41.8248%, Training Loss: 1.1973%\n",
      "Epoch [8/300], Step [113/225], Training Accuracy: 41.8142%, Training Loss: 1.1980%\n",
      "Epoch [8/300], Step [114/225], Training Accuracy: 41.8311%, Training Loss: 1.1969%\n",
      "Epoch [8/300], Step [115/225], Training Accuracy: 41.9022%, Training Loss: 1.1965%\n",
      "Epoch [8/300], Step [116/225], Training Accuracy: 41.8642%, Training Loss: 1.1965%\n",
      "Epoch [8/300], Step [117/225], Training Accuracy: 41.8269%, Training Loss: 1.1975%\n",
      "Epoch [8/300], Step [118/225], Training Accuracy: 41.8432%, Training Loss: 1.1973%\n",
      "Epoch [8/300], Step [119/225], Training Accuracy: 41.8330%, Training Loss: 1.1973%\n",
      "Epoch [8/300], Step [120/225], Training Accuracy: 41.8099%, Training Loss: 1.1978%\n",
      "Epoch [8/300], Step [121/225], Training Accuracy: 41.8388%, Training Loss: 1.1972%\n",
      "Epoch [8/300], Step [122/225], Training Accuracy: 41.8673%, Training Loss: 1.1967%\n",
      "Epoch [8/300], Step [123/225], Training Accuracy: 41.9080%, Training Loss: 1.1967%\n",
      "Epoch [8/300], Step [124/225], Training Accuracy: 41.9859%, Training Loss: 1.1957%\n",
      "Epoch [8/300], Step [125/225], Training Accuracy: 41.9625%, Training Loss: 1.1961%\n",
      "Epoch [8/300], Step [126/225], Training Accuracy: 41.9643%, Training Loss: 1.1959%\n",
      "Epoch [8/300], Step [127/225], Training Accuracy: 41.8922%, Training Loss: 1.1962%\n",
      "Epoch [8/300], Step [128/225], Training Accuracy: 41.9312%, Training Loss: 1.1959%\n",
      "Epoch [8/300], Step [129/225], Training Accuracy: 41.9453%, Training Loss: 1.1956%\n",
      "Epoch [8/300], Step [130/225], Training Accuracy: 41.8510%, Training Loss: 1.1965%\n",
      "Epoch [8/300], Step [131/225], Training Accuracy: 41.8774%, Training Loss: 1.1963%\n",
      "Epoch [8/300], Step [132/225], Training Accuracy: 41.9271%, Training Loss: 1.1961%\n",
      "Epoch [8/300], Step [133/225], Training Accuracy: 41.9760%, Training Loss: 1.1952%\n",
      "Epoch [8/300], Step [134/225], Training Accuracy: 41.8960%, Training Loss: 1.1958%\n",
      "Epoch [8/300], Step [135/225], Training Accuracy: 41.9097%, Training Loss: 1.1958%\n",
      "Epoch [8/300], Step [136/225], Training Accuracy: 41.8773%, Training Loss: 1.1960%\n",
      "Epoch [8/300], Step [137/225], Training Accuracy: 41.9024%, Training Loss: 1.1953%\n",
      "Epoch [8/300], Step [138/225], Training Accuracy: 41.9837%, Training Loss: 1.1952%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/300], Step [139/225], Training Accuracy: 41.9852%, Training Loss: 1.1959%\n",
      "Epoch [8/300], Step [140/225], Training Accuracy: 41.9420%, Training Loss: 1.1964%\n",
      "Epoch [8/300], Step [141/225], Training Accuracy: 42.0324%, Training Loss: 1.1954%\n",
      "Epoch [8/300], Step [142/225], Training Accuracy: 42.0775%, Training Loss: 1.1947%\n",
      "Epoch [8/300], Step [143/225], Training Accuracy: 42.1329%, Training Loss: 1.1941%\n",
      "Epoch [8/300], Step [144/225], Training Accuracy: 42.0790%, Training Loss: 1.1951%\n",
      "Epoch [8/300], Step [145/225], Training Accuracy: 42.0797%, Training Loss: 1.1960%\n",
      "Epoch [8/300], Step [146/225], Training Accuracy: 42.0056%, Training Loss: 1.1965%\n",
      "Epoch [8/300], Step [147/225], Training Accuracy: 42.1025%, Training Loss: 1.1958%\n",
      "Epoch [8/300], Step [148/225], Training Accuracy: 42.1981%, Training Loss: 1.1951%\n",
      "Epoch [8/300], Step [149/225], Training Accuracy: 42.2190%, Training Loss: 1.1953%\n",
      "Epoch [8/300], Step [150/225], Training Accuracy: 42.2292%, Training Loss: 1.1950%\n",
      "Epoch [8/300], Step [151/225], Training Accuracy: 42.2806%, Training Loss: 1.1945%\n",
      "Epoch [8/300], Step [152/225], Training Accuracy: 42.2697%, Training Loss: 1.1945%\n",
      "Epoch [8/300], Step [153/225], Training Accuracy: 42.2386%, Training Loss: 1.1944%\n",
      "Epoch [8/300], Step [154/225], Training Accuracy: 42.2687%, Training Loss: 1.1945%\n",
      "Epoch [8/300], Step [155/225], Training Accuracy: 42.2782%, Training Loss: 1.1946%\n",
      "Epoch [8/300], Step [156/225], Training Accuracy: 42.2676%, Training Loss: 1.1952%\n",
      "Epoch [8/300], Step [157/225], Training Accuracy: 42.2074%, Training Loss: 1.1954%\n",
      "Epoch [8/300], Step [158/225], Training Accuracy: 42.1974%, Training Loss: 1.1956%\n",
      "Epoch [8/300], Step [159/225], Training Accuracy: 42.2661%, Training Loss: 1.1949%\n",
      "Epoch [8/300], Step [160/225], Training Accuracy: 42.2656%, Training Loss: 1.1952%\n",
      "Epoch [8/300], Step [161/225], Training Accuracy: 42.3331%, Training Loss: 1.1943%\n",
      "Epoch [8/300], Step [162/225], Training Accuracy: 42.3708%, Training Loss: 1.1937%\n",
      "Epoch [8/300], Step [163/225], Training Accuracy: 42.4080%, Training Loss: 1.1935%\n",
      "Epoch [8/300], Step [164/225], Training Accuracy: 42.4162%, Training Loss: 1.1933%\n",
      "Epoch [8/300], Step [165/225], Training Accuracy: 42.3485%, Training Loss: 1.1942%\n",
      "Epoch [8/300], Step [166/225], Training Accuracy: 42.3946%, Training Loss: 1.1942%\n",
      "Epoch [8/300], Step [167/225], Training Accuracy: 42.4308%, Training Loss: 1.1933%\n",
      "Epoch [8/300], Step [168/225], Training Accuracy: 42.3735%, Training Loss: 1.1934%\n",
      "Epoch [8/300], Step [169/225], Training Accuracy: 42.3447%, Training Loss: 1.1934%\n",
      "Epoch [8/300], Step [170/225], Training Accuracy: 42.3162%, Training Loss: 1.1936%\n",
      "Epoch [8/300], Step [171/225], Training Accuracy: 42.4068%, Training Loss: 1.1926%\n",
      "Epoch [8/300], Step [172/225], Training Accuracy: 42.3964%, Training Loss: 1.1924%\n",
      "Epoch [8/300], Step [173/225], Training Accuracy: 42.3681%, Training Loss: 1.1920%\n",
      "Epoch [8/300], Step [174/225], Training Accuracy: 42.3402%, Training Loss: 1.1923%\n",
      "Epoch [8/300], Step [175/225], Training Accuracy: 42.2768%, Training Loss: 1.1933%\n",
      "Epoch [8/300], Step [176/225], Training Accuracy: 42.2408%, Training Loss: 1.1939%\n",
      "Epoch [8/300], Step [177/225], Training Accuracy: 42.2581%, Training Loss: 1.1940%\n",
      "Epoch [8/300], Step [178/225], Training Accuracy: 42.2841%, Training Loss: 1.1937%\n",
      "Epoch [8/300], Step [179/225], Training Accuracy: 42.2486%, Training Loss: 1.1937%\n",
      "Epoch [8/300], Step [180/225], Training Accuracy: 42.3003%, Training Loss: 1.1928%\n",
      "Epoch [8/300], Step [181/225], Training Accuracy: 42.3084%, Training Loss: 1.1926%\n",
      "Epoch [8/300], Step [182/225], Training Accuracy: 42.3249%, Training Loss: 1.1922%\n",
      "Epoch [8/300], Step [183/225], Training Accuracy: 42.3327%, Training Loss: 1.1918%\n",
      "Epoch [8/300], Step [184/225], Training Accuracy: 42.3149%, Training Loss: 1.1918%\n",
      "Epoch [8/300], Step [185/225], Training Accuracy: 42.3649%, Training Loss: 1.1915%\n",
      "Epoch [8/300], Step [186/225], Training Accuracy: 42.4059%, Training Loss: 1.1910%\n",
      "Epoch [8/300], Step [187/225], Training Accuracy: 42.4716%, Training Loss: 1.1906%\n",
      "Epoch [8/300], Step [188/225], Training Accuracy: 42.5116%, Training Loss: 1.1901%\n",
      "Epoch [8/300], Step [189/225], Training Accuracy: 42.5678%, Training Loss: 1.1894%\n",
      "Epoch [8/300], Step [190/225], Training Accuracy: 42.5000%, Training Loss: 1.1902%\n",
      "Epoch [8/300], Step [191/225], Training Accuracy: 42.4984%, Training Loss: 1.1902%\n",
      "Epoch [8/300], Step [192/225], Training Accuracy: 42.5700%, Training Loss: 1.1898%\n",
      "Epoch [8/300], Step [193/225], Training Accuracy: 42.5275%, Training Loss: 1.1900%\n",
      "Epoch [8/300], Step [194/225], Training Accuracy: 42.5419%, Training Loss: 1.1898%\n",
      "Epoch [8/300], Step [195/225], Training Accuracy: 42.5721%, Training Loss: 1.1892%\n",
      "Epoch [8/300], Step [196/225], Training Accuracy: 42.5223%, Training Loss: 1.1898%\n",
      "Epoch [8/300], Step [197/225], Training Accuracy: 42.5365%, Training Loss: 1.1901%\n",
      "Epoch [8/300], Step [198/225], Training Accuracy: 42.5663%, Training Loss: 1.1894%\n",
      "Epoch [8/300], Step [199/225], Training Accuracy: 42.5722%, Training Loss: 1.1892%\n",
      "Epoch [8/300], Step [200/225], Training Accuracy: 42.5547%, Training Loss: 1.1897%\n",
      "Epoch [8/300], Step [201/225], Training Accuracy: 42.5606%, Training Loss: 1.1901%\n",
      "Epoch [8/300], Step [202/225], Training Accuracy: 42.5820%, Training Loss: 1.1899%\n",
      "Epoch [8/300], Step [203/225], Training Accuracy: 42.5570%, Training Loss: 1.1902%\n",
      "Epoch [8/300], Step [204/225], Training Accuracy: 42.5781%, Training Loss: 1.1901%\n",
      "Epoch [8/300], Step [205/225], Training Accuracy: 42.5838%, Training Loss: 1.1900%\n",
      "Epoch [8/300], Step [206/225], Training Accuracy: 42.5895%, Training Loss: 1.1904%\n",
      "Epoch [8/300], Step [207/225], Training Accuracy: 42.6027%, Training Loss: 1.1904%\n",
      "Epoch [8/300], Step [208/225], Training Accuracy: 42.6457%, Training Loss: 1.1899%\n",
      "Epoch [8/300], Step [209/225], Training Accuracy: 42.6585%, Training Loss: 1.1899%\n",
      "Epoch [8/300], Step [210/225], Training Accuracy: 42.6637%, Training Loss: 1.1899%\n",
      "Epoch [8/300], Step [211/225], Training Accuracy: 42.6762%, Training Loss: 1.1894%\n",
      "Epoch [8/300], Step [212/225], Training Accuracy: 42.6813%, Training Loss: 1.1894%\n",
      "Epoch [8/300], Step [213/225], Training Accuracy: 42.6570%, Training Loss: 1.1894%\n",
      "Epoch [8/300], Step [214/225], Training Accuracy: 42.6475%, Training Loss: 1.1892%\n",
      "Epoch [8/300], Step [215/225], Training Accuracy: 42.6235%, Training Loss: 1.1895%\n",
      "Epoch [8/300], Step [216/225], Training Accuracy: 42.5781%, Training Loss: 1.1899%\n",
      "Epoch [8/300], Step [217/225], Training Accuracy: 42.5979%, Training Loss: 1.1895%\n",
      "Epoch [8/300], Step [218/225], Training Accuracy: 42.6032%, Training Loss: 1.1895%\n",
      "Epoch [8/300], Step [219/225], Training Accuracy: 42.6084%, Training Loss: 1.1891%\n",
      "Epoch [8/300], Step [220/225], Training Accuracy: 42.6349%, Training Loss: 1.1888%\n",
      "Epoch [8/300], Step [221/225], Training Accuracy: 42.6471%, Training Loss: 1.1888%\n",
      "Epoch [8/300], Step [222/225], Training Accuracy: 42.6802%, Training Loss: 1.1883%\n",
      "Epoch [8/300], Step [223/225], Training Accuracy: 42.6990%, Training Loss: 1.1883%\n",
      "Epoch [8/300], Step [224/225], Training Accuracy: 42.7246%, Training Loss: 1.1878%\n",
      "Epoch [8/300], Step [225/225], Training Accuracy: 42.7251%, Training Loss: 1.1879%\n",
      "Epoch [9/300], Step [1/225], Training Accuracy: 43.7500%, Training Loss: 1.2690%\n",
      "Epoch [9/300], Step [2/225], Training Accuracy: 39.0625%, Training Loss: 1.2375%\n",
      "Epoch [9/300], Step [3/225], Training Accuracy: 38.5417%, Training Loss: 1.2301%\n",
      "Epoch [9/300], Step [4/225], Training Accuracy: 39.0625%, Training Loss: 1.2041%\n",
      "Epoch [9/300], Step [5/225], Training Accuracy: 40.0000%, Training Loss: 1.1908%\n",
      "Epoch [9/300], Step [6/225], Training Accuracy: 40.1042%, Training Loss: 1.1973%\n",
      "Epoch [9/300], Step [7/225], Training Accuracy: 39.2857%, Training Loss: 1.2169%\n",
      "Epoch [9/300], Step [8/225], Training Accuracy: 40.2344%, Training Loss: 1.2116%\n",
      "Epoch [9/300], Step [9/225], Training Accuracy: 41.3194%, Training Loss: 1.1962%\n",
      "Epoch [9/300], Step [10/225], Training Accuracy: 41.7188%, Training Loss: 1.1961%\n",
      "Epoch [9/300], Step [11/225], Training Accuracy: 41.7614%, Training Loss: 1.1978%\n",
      "Epoch [9/300], Step [12/225], Training Accuracy: 41.7969%, Training Loss: 1.1978%\n",
      "Epoch [9/300], Step [13/225], Training Accuracy: 43.0288%, Training Loss: 1.1931%\n",
      "Epoch [9/300], Step [14/225], Training Accuracy: 42.8571%, Training Loss: 1.1948%\n",
      "Epoch [9/300], Step [15/225], Training Accuracy: 43.0208%, Training Loss: 1.2005%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/300], Step [16/225], Training Accuracy: 43.3594%, Training Loss: 1.2011%\n",
      "Epoch [9/300], Step [17/225], Training Accuracy: 43.8419%, Training Loss: 1.1952%\n",
      "Epoch [9/300], Step [18/225], Training Accuracy: 43.4896%, Training Loss: 1.1975%\n",
      "Epoch [9/300], Step [19/225], Training Accuracy: 43.5033%, Training Loss: 1.1975%\n",
      "Epoch [9/300], Step [20/225], Training Accuracy: 43.9062%, Training Loss: 1.1921%\n",
      "Epoch [9/300], Step [21/225], Training Accuracy: 44.3452%, Training Loss: 1.1890%\n",
      "Epoch [9/300], Step [22/225], Training Accuracy: 44.3892%, Training Loss: 1.1879%\n",
      "Epoch [9/300], Step [23/225], Training Accuracy: 44.1576%, Training Loss: 1.1878%\n",
      "Epoch [9/300], Step [24/225], Training Accuracy: 44.3359%, Training Loss: 1.1850%\n",
      "Epoch [9/300], Step [25/225], Training Accuracy: 44.1875%, Training Loss: 1.1837%\n",
      "Epoch [9/300], Step [26/225], Training Accuracy: 43.9904%, Training Loss: 1.1838%\n",
      "Epoch [9/300], Step [27/225], Training Accuracy: 43.7500%, Training Loss: 1.1844%\n",
      "Epoch [9/300], Step [28/225], Training Accuracy: 43.8616%, Training Loss: 1.1829%\n",
      "Epoch [9/300], Step [29/225], Training Accuracy: 44.0733%, Training Loss: 1.1795%\n",
      "Epoch [9/300], Step [30/225], Training Accuracy: 44.0625%, Training Loss: 1.1794%\n",
      "Epoch [9/300], Step [31/225], Training Accuracy: 44.0524%, Training Loss: 1.1807%\n",
      "Epoch [9/300], Step [32/225], Training Accuracy: 44.1895%, Training Loss: 1.1770%\n",
      "Epoch [9/300], Step [33/225], Training Accuracy: 43.9867%, Training Loss: 1.1764%\n",
      "Epoch [9/300], Step [34/225], Training Accuracy: 43.7040%, Training Loss: 1.1782%\n",
      "Epoch [9/300], Step [35/225], Training Accuracy: 43.8839%, Training Loss: 1.1796%\n",
      "Epoch [9/300], Step [36/225], Training Accuracy: 43.8368%, Training Loss: 1.1801%\n",
      "Epoch [9/300], Step [37/225], Training Accuracy: 44.2568%, Training Loss: 1.1769%\n",
      "Epoch [9/300], Step [38/225], Training Accuracy: 44.3257%, Training Loss: 1.1773%\n",
      "Epoch [9/300], Step [39/225], Training Accuracy: 44.1506%, Training Loss: 1.1775%\n",
      "Epoch [9/300], Step [40/225], Training Accuracy: 43.9844%, Training Loss: 1.1767%\n",
      "Epoch [9/300], Step [41/225], Training Accuracy: 43.7881%, Training Loss: 1.1783%\n",
      "Epoch [9/300], Step [42/225], Training Accuracy: 43.6384%, Training Loss: 1.1780%\n",
      "Epoch [9/300], Step [43/225], Training Accuracy: 43.8227%, Training Loss: 1.1758%\n",
      "Epoch [9/300], Step [44/225], Training Accuracy: 43.8210%, Training Loss: 1.1763%\n",
      "Epoch [9/300], Step [45/225], Training Accuracy: 44.0278%, Training Loss: 1.1722%\n",
      "Epoch [9/300], Step [46/225], Training Accuracy: 44.0217%, Training Loss: 1.1709%\n",
      "Epoch [9/300], Step [47/225], Training Accuracy: 43.9827%, Training Loss: 1.1715%\n",
      "Epoch [9/300], Step [48/225], Training Accuracy: 44.0430%, Training Loss: 1.1695%\n",
      "Epoch [9/300], Step [49/225], Training Accuracy: 43.9732%, Training Loss: 1.1708%\n",
      "Epoch [9/300], Step [50/225], Training Accuracy: 44.1250%, Training Loss: 1.1688%\n",
      "Epoch [9/300], Step [51/225], Training Accuracy: 44.1789%, Training Loss: 1.1692%\n",
      "Epoch [9/300], Step [52/225], Training Accuracy: 44.2007%, Training Loss: 1.1696%\n",
      "Epoch [9/300], Step [53/225], Training Accuracy: 44.2512%, Training Loss: 1.1697%\n",
      "Epoch [9/300], Step [54/225], Training Accuracy: 44.2419%, Training Loss: 1.1695%\n",
      "Epoch [9/300], Step [55/225], Training Accuracy: 44.2614%, Training Loss: 1.1695%\n",
      "Epoch [9/300], Step [56/225], Training Accuracy: 44.0848%, Training Loss: 1.1705%\n",
      "Epoch [9/300], Step [57/225], Training Accuracy: 44.1886%, Training Loss: 1.1693%\n",
      "Epoch [9/300], Step [58/225], Training Accuracy: 44.1272%, Training Loss: 1.1691%\n",
      "Epoch [9/300], Step [59/225], Training Accuracy: 44.0413%, Training Loss: 1.1684%\n",
      "Epoch [9/300], Step [60/225], Training Accuracy: 44.0625%, Training Loss: 1.1678%\n",
      "Epoch [9/300], Step [61/225], Training Accuracy: 43.9549%, Training Loss: 1.1682%\n",
      "Epoch [9/300], Step [62/225], Training Accuracy: 43.8760%, Training Loss: 1.1685%\n",
      "Epoch [9/300], Step [63/225], Training Accuracy: 43.7996%, Training Loss: 1.1697%\n",
      "Epoch [9/300], Step [64/225], Training Accuracy: 43.7500%, Training Loss: 1.1704%\n",
      "Epoch [9/300], Step [65/225], Training Accuracy: 43.6779%, Training Loss: 1.1720%\n",
      "Epoch [9/300], Step [66/225], Training Accuracy: 43.8210%, Training Loss: 1.1700%\n",
      "Epoch [9/300], Step [67/225], Training Accuracy: 43.8899%, Training Loss: 1.1688%\n",
      "Epoch [9/300], Step [68/225], Training Accuracy: 43.9338%, Training Loss: 1.1679%\n",
      "Epoch [9/300], Step [69/225], Training Accuracy: 43.8859%, Training Loss: 1.1671%\n",
      "Epoch [9/300], Step [70/225], Training Accuracy: 43.9062%, Training Loss: 1.1678%\n",
      "Epoch [9/300], Step [71/225], Training Accuracy: 43.9040%, Training Loss: 1.1670%\n",
      "Epoch [9/300], Step [72/225], Training Accuracy: 43.8368%, Training Loss: 1.1679%\n",
      "Epoch [9/300], Step [73/225], Training Accuracy: 43.7072%, Training Loss: 1.1690%\n",
      "Epoch [9/300], Step [74/225], Training Accuracy: 43.7922%, Training Loss: 1.1675%\n",
      "Epoch [9/300], Step [75/225], Training Accuracy: 43.8125%, Training Loss: 1.1665%\n",
      "Epoch [9/300], Step [76/225], Training Accuracy: 43.7706%, Training Loss: 1.1668%\n",
      "Epoch [9/300], Step [77/225], Training Accuracy: 43.7703%, Training Loss: 1.1668%\n",
      "Epoch [9/300], Step [78/225], Training Accuracy: 43.8702%, Training Loss: 1.1668%\n",
      "Epoch [9/300], Step [79/225], Training Accuracy: 43.8884%, Training Loss: 1.1669%\n",
      "Epoch [9/300], Step [80/225], Training Accuracy: 43.8281%, Training Loss: 1.1670%\n",
      "Epoch [9/300], Step [81/225], Training Accuracy: 44.0394%, Training Loss: 1.1667%\n",
      "Epoch [9/300], Step [82/225], Training Accuracy: 44.1502%, Training Loss: 1.1659%\n",
      "Epoch [9/300], Step [83/225], Training Accuracy: 44.2395%, Training Loss: 1.1643%\n",
      "Epoch [9/300], Step [84/225], Training Accuracy: 44.2894%, Training Loss: 1.1633%\n",
      "Epoch [9/300], Step [85/225], Training Accuracy: 44.4301%, Training Loss: 1.1621%\n",
      "Epoch [9/300], Step [86/225], Training Accuracy: 44.4767%, Training Loss: 1.1611%\n",
      "Epoch [9/300], Step [87/225], Training Accuracy: 44.5941%, Training Loss: 1.1601%\n",
      "Epoch [9/300], Step [88/225], Training Accuracy: 44.4780%, Training Loss: 1.1604%\n",
      "Epoch [9/300], Step [89/225], Training Accuracy: 44.4522%, Training Loss: 1.1616%\n",
      "Epoch [9/300], Step [90/225], Training Accuracy: 44.3576%, Training Loss: 1.1621%\n",
      "Epoch [9/300], Step [91/225], Training Accuracy: 44.3681%, Training Loss: 1.1619%\n",
      "Epoch [9/300], Step [92/225], Training Accuracy: 44.3444%, Training Loss: 1.1611%\n",
      "Epoch [9/300], Step [93/225], Training Accuracy: 44.4052%, Training Loss: 1.1607%\n",
      "Epoch [9/300], Step [94/225], Training Accuracy: 44.5146%, Training Loss: 1.1590%\n",
      "Epoch [9/300], Step [95/225], Training Accuracy: 44.4901%, Training Loss: 1.1594%\n",
      "Epoch [9/300], Step [96/225], Training Accuracy: 44.5801%, Training Loss: 1.1585%\n",
      "Epoch [9/300], Step [97/225], Training Accuracy: 44.6843%, Training Loss: 1.1572%\n",
      "Epoch [9/300], Step [98/225], Training Accuracy: 44.6110%, Training Loss: 1.1573%\n",
      "Epoch [9/300], Step [99/225], Training Accuracy: 44.5707%, Training Loss: 1.1573%\n",
      "Epoch [9/300], Step [100/225], Training Accuracy: 44.5312%, Training Loss: 1.1578%\n",
      "Epoch [9/300], Step [101/225], Training Accuracy: 44.5390%, Training Loss: 1.1576%\n",
      "Epoch [9/300], Step [102/225], Training Accuracy: 44.5159%, Training Loss: 1.1572%\n",
      "Epoch [9/300], Step [103/225], Training Accuracy: 44.5692%, Training Loss: 1.1573%\n",
      "Epoch [9/300], Step [104/225], Training Accuracy: 44.4712%, Training Loss: 1.1579%\n",
      "Epoch [9/300], Step [105/225], Training Accuracy: 44.4643%, Training Loss: 1.1581%\n",
      "Epoch [9/300], Step [106/225], Training Accuracy: 44.5018%, Training Loss: 1.1577%\n",
      "Epoch [9/300], Step [107/225], Training Accuracy: 44.5824%, Training Loss: 1.1572%\n",
      "Epoch [9/300], Step [108/225], Training Accuracy: 44.5457%, Training Loss: 1.1574%\n",
      "Epoch [9/300], Step [109/225], Training Accuracy: 44.5958%, Training Loss: 1.1570%\n",
      "Epoch [9/300], Step [110/225], Training Accuracy: 44.6165%, Training Loss: 1.1566%\n",
      "Epoch [9/300], Step [111/225], Training Accuracy: 44.6087%, Training Loss: 1.1565%\n",
      "Epoch [9/300], Step [112/225], Training Accuracy: 44.6150%, Training Loss: 1.1557%\n",
      "Epoch [9/300], Step [113/225], Training Accuracy: 44.6073%, Training Loss: 1.1553%\n",
      "Epoch [9/300], Step [114/225], Training Accuracy: 44.5724%, Training Loss: 1.1545%\n",
      "Epoch [9/300], Step [115/225], Training Accuracy: 44.6060%, Training Loss: 1.1541%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/300], Step [116/225], Training Accuracy: 44.6121%, Training Loss: 1.1541%\n",
      "Epoch [9/300], Step [117/225], Training Accuracy: 44.5913%, Training Loss: 1.1548%\n",
      "Epoch [9/300], Step [118/225], Training Accuracy: 44.6239%, Training Loss: 1.1546%\n",
      "Epoch [9/300], Step [119/225], Training Accuracy: 44.6035%, Training Loss: 1.1545%\n",
      "Epoch [9/300], Step [120/225], Training Accuracy: 44.6354%, Training Loss: 1.1543%\n",
      "Epoch [9/300], Step [121/225], Training Accuracy: 44.6152%, Training Loss: 1.1551%\n",
      "Epoch [9/300], Step [122/225], Training Accuracy: 44.6081%, Training Loss: 1.1547%\n",
      "Epoch [9/300], Step [123/225], Training Accuracy: 44.5884%, Training Loss: 1.1548%\n",
      "Epoch [9/300], Step [124/225], Training Accuracy: 44.6699%, Training Loss: 1.1538%\n",
      "Epoch [9/300], Step [125/225], Training Accuracy: 44.7125%, Training Loss: 1.1547%\n",
      "Epoch [9/300], Step [126/225], Training Accuracy: 44.7173%, Training Loss: 1.1548%\n",
      "Epoch [9/300], Step [127/225], Training Accuracy: 44.6112%, Training Loss: 1.1559%\n",
      "Epoch [9/300], Step [128/225], Training Accuracy: 44.5923%, Training Loss: 1.1556%\n",
      "Epoch [9/300], Step [129/225], Training Accuracy: 44.5979%, Training Loss: 1.1549%\n",
      "Epoch [9/300], Step [130/225], Training Accuracy: 44.5793%, Training Loss: 1.1553%\n",
      "Epoch [9/300], Step [131/225], Training Accuracy: 44.5372%, Training Loss: 1.1557%\n",
      "Epoch [9/300], Step [132/225], Training Accuracy: 44.4839%, Training Loss: 1.1564%\n",
      "Epoch [9/300], Step [133/225], Training Accuracy: 44.5136%, Training Loss: 1.1562%\n",
      "Epoch [9/300], Step [134/225], Training Accuracy: 44.3797%, Training Loss: 1.1577%\n",
      "Epoch [9/300], Step [135/225], Training Accuracy: 44.4097%, Training Loss: 1.1573%\n",
      "Epoch [9/300], Step [136/225], Training Accuracy: 44.3589%, Training Loss: 1.1574%\n",
      "Epoch [9/300], Step [137/225], Training Accuracy: 44.3431%, Training Loss: 1.1568%\n",
      "Epoch [9/300], Step [138/225], Training Accuracy: 44.3727%, Training Loss: 1.1565%\n",
      "Epoch [9/300], Step [139/225], Training Accuracy: 44.3570%, Training Loss: 1.1573%\n",
      "Epoch [9/300], Step [140/225], Training Accuracy: 44.3415%, Training Loss: 1.1578%\n",
      "Epoch [9/300], Step [141/225], Training Accuracy: 44.4149%, Training Loss: 1.1571%\n",
      "Epoch [9/300], Step [142/225], Training Accuracy: 44.4652%, Training Loss: 1.1566%\n",
      "Epoch [9/300], Step [143/225], Training Accuracy: 44.4602%, Training Loss: 1.1566%\n",
      "Epoch [9/300], Step [144/225], Training Accuracy: 44.3793%, Training Loss: 1.1572%\n",
      "Epoch [9/300], Step [145/225], Training Accuracy: 44.3642%, Training Loss: 1.1582%\n",
      "Epoch [9/300], Step [146/225], Training Accuracy: 44.2958%, Training Loss: 1.1592%\n",
      "Epoch [9/300], Step [147/225], Training Accuracy: 44.3665%, Training Loss: 1.1589%\n",
      "Epoch [9/300], Step [148/225], Training Accuracy: 44.4785%, Training Loss: 1.1581%\n",
      "Epoch [9/300], Step [149/225], Training Accuracy: 44.5155%, Training Loss: 1.1582%\n",
      "Epoch [9/300], Step [150/225], Training Accuracy: 44.5208%, Training Loss: 1.1578%\n",
      "Epoch [9/300], Step [151/225], Training Accuracy: 44.5364%, Training Loss: 1.1574%\n",
      "Epoch [9/300], Step [152/225], Training Accuracy: 44.5312%, Training Loss: 1.1572%\n",
      "Epoch [9/300], Step [153/225], Training Accuracy: 44.5364%, Training Loss: 1.1568%\n",
      "Epoch [9/300], Step [154/225], Training Accuracy: 44.5211%, Training Loss: 1.1568%\n",
      "Epoch [9/300], Step [155/225], Training Accuracy: 44.5665%, Training Loss: 1.1566%\n",
      "Epoch [9/300], Step [156/225], Training Accuracy: 44.4912%, Training Loss: 1.1570%\n",
      "Epoch [9/300], Step [157/225], Training Accuracy: 44.4666%, Training Loss: 1.1572%\n",
      "Epoch [9/300], Step [158/225], Training Accuracy: 44.4225%, Training Loss: 1.1574%\n",
      "Epoch [9/300], Step [159/225], Training Accuracy: 44.4084%, Training Loss: 1.1570%\n",
      "Epoch [9/300], Step [160/225], Training Accuracy: 44.3945%, Training Loss: 1.1573%\n",
      "Epoch [9/300], Step [161/225], Training Accuracy: 44.4391%, Training Loss: 1.1565%\n",
      "Epoch [9/300], Step [162/225], Training Accuracy: 44.3673%, Training Loss: 1.1567%\n",
      "Epoch [9/300], Step [163/225], Training Accuracy: 44.4306%, Training Loss: 1.1564%\n",
      "Epoch [9/300], Step [164/225], Training Accuracy: 44.4550%, Training Loss: 1.1563%\n",
      "Epoch [9/300], Step [165/225], Training Accuracy: 44.4318%, Training Loss: 1.1569%\n",
      "Epoch [9/300], Step [166/225], Training Accuracy: 44.4371%, Training Loss: 1.1571%\n",
      "Epoch [9/300], Step [167/225], Training Accuracy: 44.4704%, Training Loss: 1.1566%\n",
      "Epoch [9/300], Step [168/225], Training Accuracy: 44.4289%, Training Loss: 1.1567%\n",
      "Epoch [9/300], Step [169/225], Training Accuracy: 44.4249%, Training Loss: 1.1565%\n",
      "Epoch [9/300], Step [170/225], Training Accuracy: 44.4118%, Training Loss: 1.1568%\n",
      "Epoch [9/300], Step [171/225], Training Accuracy: 44.4353%, Training Loss: 1.1562%\n",
      "Epoch [9/300], Step [172/225], Training Accuracy: 44.4132%, Training Loss: 1.1563%\n",
      "Epoch [9/300], Step [173/225], Training Accuracy: 44.4093%, Training Loss: 1.1562%\n",
      "Epoch [9/300], Step [174/225], Training Accuracy: 44.4055%, Training Loss: 1.1559%\n",
      "Epoch [9/300], Step [175/225], Training Accuracy: 44.4107%, Training Loss: 1.1565%\n",
      "Epoch [9/300], Step [176/225], Training Accuracy: 44.3892%, Training Loss: 1.1571%\n",
      "Epoch [9/300], Step [177/225], Training Accuracy: 44.4032%, Training Loss: 1.1570%\n",
      "Epoch [9/300], Step [178/225], Training Accuracy: 44.4171%, Training Loss: 1.1572%\n",
      "Epoch [9/300], Step [179/225], Training Accuracy: 44.4221%, Training Loss: 1.1572%\n",
      "Epoch [9/300], Step [180/225], Training Accuracy: 44.4965%, Training Loss: 1.1564%\n",
      "Epoch [9/300], Step [181/225], Training Accuracy: 44.4924%, Training Loss: 1.1566%\n",
      "Epoch [9/300], Step [182/225], Training Accuracy: 44.4712%, Training Loss: 1.1567%\n",
      "Epoch [9/300], Step [183/225], Training Accuracy: 44.5099%, Training Loss: 1.1561%\n",
      "Epoch [9/300], Step [184/225], Training Accuracy: 44.5397%, Training Loss: 1.1559%\n",
      "Epoch [9/300], Step [185/225], Training Accuracy: 44.5861%, Training Loss: 1.1555%\n",
      "Epoch [9/300], Step [186/225], Training Accuracy: 44.5985%, Training Loss: 1.1548%\n",
      "Epoch [9/300], Step [187/225], Training Accuracy: 44.6524%, Training Loss: 1.1540%\n",
      "Epoch [9/300], Step [188/225], Training Accuracy: 44.6725%, Training Loss: 1.1534%\n",
      "Epoch [9/300], Step [189/225], Training Accuracy: 44.6925%, Training Loss: 1.1531%\n",
      "Epoch [9/300], Step [190/225], Training Accuracy: 44.6628%, Training Loss: 1.1536%\n",
      "Epoch [9/300], Step [191/225], Training Accuracy: 44.7153%, Training Loss: 1.1531%\n",
      "Epoch [9/300], Step [192/225], Training Accuracy: 44.7673%, Training Loss: 1.1529%\n",
      "Epoch [9/300], Step [193/225], Training Accuracy: 44.7215%, Training Loss: 1.1537%\n",
      "Epoch [9/300], Step [194/225], Training Accuracy: 44.7487%, Training Loss: 1.1536%\n",
      "Epoch [9/300], Step [195/225], Training Accuracy: 44.8157%, Training Loss: 1.1528%\n",
      "Epoch [9/300], Step [196/225], Training Accuracy: 44.8501%, Training Loss: 1.1529%\n",
      "Epoch [9/300], Step [197/225], Training Accuracy: 44.8207%, Training Loss: 1.1532%\n",
      "Epoch [9/300], Step [198/225], Training Accuracy: 44.8469%, Training Loss: 1.1525%\n",
      "Epoch [9/300], Step [199/225], Training Accuracy: 44.8728%, Training Loss: 1.1520%\n",
      "Epoch [9/300], Step [200/225], Training Accuracy: 44.8984%, Training Loss: 1.1522%\n",
      "Epoch [9/300], Step [201/225], Training Accuracy: 44.8539%, Training Loss: 1.1526%\n",
      "Epoch [9/300], Step [202/225], Training Accuracy: 44.8407%, Training Loss: 1.1526%\n",
      "Epoch [9/300], Step [203/225], Training Accuracy: 44.8353%, Training Loss: 1.1527%\n",
      "Epoch [9/300], Step [204/225], Training Accuracy: 44.8223%, Training Loss: 1.1531%\n",
      "Epoch [9/300], Step [205/225], Training Accuracy: 44.8323%, Training Loss: 1.1528%\n",
      "Epoch [9/300], Step [206/225], Training Accuracy: 44.8271%, Training Loss: 1.1530%\n",
      "Epoch [9/300], Step [207/225], Training Accuracy: 44.8747%, Training Loss: 1.1529%\n",
      "Epoch [9/300], Step [208/225], Training Accuracy: 44.9069%, Training Loss: 1.1526%\n",
      "Epoch [9/300], Step [209/225], Training Accuracy: 44.9312%, Training Loss: 1.1523%\n",
      "Epoch [9/300], Step [210/225], Training Accuracy: 44.9851%, Training Loss: 1.1522%\n",
      "Epoch [9/300], Step [211/225], Training Accuracy: 44.9941%, Training Loss: 1.1518%\n",
      "Epoch [9/300], Step [212/225], Training Accuracy: 45.0103%, Training Loss: 1.1517%\n",
      "Epoch [9/300], Step [213/225], Training Accuracy: 44.9531%, Training Loss: 1.1523%\n",
      "Epoch [9/300], Step [214/225], Training Accuracy: 44.9474%, Training Loss: 1.1521%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/300], Step [215/225], Training Accuracy: 44.8910%, Training Loss: 1.1524%\n",
      "Epoch [9/300], Step [216/225], Training Accuracy: 44.8278%, Training Loss: 1.1534%\n",
      "Epoch [9/300], Step [217/225], Training Accuracy: 44.8301%, Training Loss: 1.1531%\n",
      "Epoch [9/300], Step [218/225], Training Accuracy: 44.7964%, Training Loss: 1.1533%\n",
      "Epoch [9/300], Step [219/225], Training Accuracy: 44.7988%, Training Loss: 1.1527%\n",
      "Epoch [9/300], Step [220/225], Training Accuracy: 44.7869%, Training Loss: 1.1525%\n",
      "Epoch [9/300], Step [221/225], Training Accuracy: 44.7964%, Training Loss: 1.1528%\n",
      "Epoch [9/300], Step [222/225], Training Accuracy: 44.7917%, Training Loss: 1.1524%\n",
      "Epoch [9/300], Step [223/225], Training Accuracy: 44.8150%, Training Loss: 1.1523%\n",
      "Epoch [9/300], Step [224/225], Training Accuracy: 44.8172%, Training Loss: 1.1517%\n",
      "Epoch [9/300], Step [225/225], Training Accuracy: 44.8305%, Training Loss: 1.1518%\n",
      "Epoch [10/300], Step [1/225], Training Accuracy: 50.0000%, Training Loss: 1.1512%\n",
      "Epoch [10/300], Step [2/225], Training Accuracy: 41.4062%, Training Loss: 1.1529%\n",
      "Epoch [10/300], Step [3/225], Training Accuracy: 41.6667%, Training Loss: 1.1719%\n",
      "Epoch [10/300], Step [4/225], Training Accuracy: 42.5781%, Training Loss: 1.1584%\n",
      "Epoch [10/300], Step [5/225], Training Accuracy: 43.7500%, Training Loss: 1.1494%\n",
      "Epoch [10/300], Step [6/225], Training Accuracy: 44.5312%, Training Loss: 1.1537%\n",
      "Epoch [10/300], Step [7/225], Training Accuracy: 44.1964%, Training Loss: 1.1764%\n",
      "Epoch [10/300], Step [8/225], Training Accuracy: 44.5312%, Training Loss: 1.1756%\n",
      "Epoch [10/300], Step [9/225], Training Accuracy: 46.0069%, Training Loss: 1.1682%\n",
      "Epoch [10/300], Step [10/225], Training Accuracy: 45.9375%, Training Loss: 1.1665%\n",
      "Epoch [10/300], Step [11/225], Training Accuracy: 45.4545%, Training Loss: 1.1702%\n",
      "Epoch [10/300], Step [12/225], Training Accuracy: 45.8333%, Training Loss: 1.1672%\n",
      "Epoch [10/300], Step [13/225], Training Accuracy: 46.7548%, Training Loss: 1.1618%\n",
      "Epoch [10/300], Step [14/225], Training Accuracy: 46.5402%, Training Loss: 1.1637%\n",
      "Epoch [10/300], Step [15/225], Training Accuracy: 45.9375%, Training Loss: 1.1697%\n",
      "Epoch [10/300], Step [16/225], Training Accuracy: 45.8984%, Training Loss: 1.1707%\n",
      "Epoch [10/300], Step [17/225], Training Accuracy: 46.2316%, Training Loss: 1.1652%\n",
      "Epoch [10/300], Step [18/225], Training Accuracy: 45.9201%, Training Loss: 1.1672%\n",
      "Epoch [10/300], Step [19/225], Training Accuracy: 45.8882%, Training Loss: 1.1630%\n",
      "Epoch [10/300], Step [20/225], Training Accuracy: 45.8594%, Training Loss: 1.1576%\n",
      "Epoch [10/300], Step [21/225], Training Accuracy: 46.2054%, Training Loss: 1.1518%\n",
      "Epoch [10/300], Step [22/225], Training Accuracy: 45.7386%, Training Loss: 1.1529%\n",
      "Epoch [10/300], Step [23/225], Training Accuracy: 45.9239%, Training Loss: 1.1502%\n",
      "Epoch [10/300], Step [24/225], Training Accuracy: 46.2891%, Training Loss: 1.1459%\n",
      "Epoch [10/300], Step [25/225], Training Accuracy: 46.5000%, Training Loss: 1.1409%\n",
      "Epoch [10/300], Step [26/225], Training Accuracy: 46.5144%, Training Loss: 1.1403%\n",
      "Epoch [10/300], Step [27/225], Training Accuracy: 46.1806%, Training Loss: 1.1416%\n",
      "Epoch [10/300], Step [28/225], Training Accuracy: 46.4286%, Training Loss: 1.1389%\n",
      "Epoch [10/300], Step [29/225], Training Accuracy: 46.6595%, Training Loss: 1.1363%\n",
      "Epoch [10/300], Step [30/225], Training Accuracy: 46.8229%, Training Loss: 1.1352%\n",
      "Epoch [10/300], Step [31/225], Training Accuracy: 46.9254%, Training Loss: 1.1364%\n",
      "Epoch [10/300], Step [32/225], Training Accuracy: 46.9727%, Training Loss: 1.1323%\n",
      "Epoch [10/300], Step [33/225], Training Accuracy: 46.7330%, Training Loss: 1.1316%\n",
      "Epoch [10/300], Step [34/225], Training Accuracy: 46.3235%, Training Loss: 1.1371%\n",
      "Epoch [10/300], Step [35/225], Training Accuracy: 46.3393%, Training Loss: 1.1375%\n",
      "Epoch [10/300], Step [36/225], Training Accuracy: 46.2674%, Training Loss: 1.1369%\n",
      "Epoch [10/300], Step [37/225], Training Accuracy: 46.5794%, Training Loss: 1.1332%\n",
      "Epoch [10/300], Step [38/225], Training Accuracy: 46.6694%, Training Loss: 1.1308%\n",
      "Epoch [10/300], Step [39/225], Training Accuracy: 46.3942%, Training Loss: 1.1315%\n",
      "Epoch [10/300], Step [40/225], Training Accuracy: 46.1719%, Training Loss: 1.1311%\n",
      "Epoch [10/300], Step [41/225], Training Accuracy: 45.9223%, Training Loss: 1.1332%\n",
      "Epoch [10/300], Step [42/225], Training Accuracy: 45.9077%, Training Loss: 1.1335%\n",
      "Epoch [10/300], Step [43/225], Training Accuracy: 45.8939%, Training Loss: 1.1322%\n",
      "Epoch [10/300], Step [44/225], Training Accuracy: 46.0227%, Training Loss: 1.1304%\n",
      "Epoch [10/300], Step [45/225], Training Accuracy: 46.3194%, Training Loss: 1.1264%\n",
      "Epoch [10/300], Step [46/225], Training Accuracy: 46.3655%, Training Loss: 1.1240%\n",
      "Epoch [10/300], Step [47/225], Training Accuracy: 46.3431%, Training Loss: 1.1239%\n",
      "Epoch [10/300], Step [48/225], Training Accuracy: 46.2565%, Training Loss: 1.1233%\n",
      "Epoch [10/300], Step [49/225], Training Accuracy: 46.2054%, Training Loss: 1.1225%\n",
      "Epoch [10/300], Step [50/225], Training Accuracy: 46.2812%, Training Loss: 1.1194%\n",
      "Epoch [10/300], Step [51/225], Training Accuracy: 46.2623%, Training Loss: 1.1197%\n",
      "Epoch [10/300], Step [52/225], Training Accuracy: 46.2139%, Training Loss: 1.1210%\n",
      "Epoch [10/300], Step [53/225], Training Accuracy: 46.2854%, Training Loss: 1.1210%\n",
      "Epoch [10/300], Step [54/225], Training Accuracy: 46.3252%, Training Loss: 1.1216%\n",
      "Epoch [10/300], Step [55/225], Training Accuracy: 46.2500%, Training Loss: 1.1210%\n",
      "Epoch [10/300], Step [56/225], Training Accuracy: 46.0658%, Training Loss: 1.1213%\n",
      "Epoch [10/300], Step [57/225], Training Accuracy: 46.2445%, Training Loss: 1.1199%\n",
      "Epoch [10/300], Step [58/225], Training Accuracy: 46.0938%, Training Loss: 1.1196%\n",
      "Epoch [10/300], Step [59/225], Training Accuracy: 45.9481%, Training Loss: 1.1209%\n",
      "Epoch [10/300], Step [60/225], Training Accuracy: 45.9896%, Training Loss: 1.1206%\n",
      "Epoch [10/300], Step [61/225], Training Accuracy: 45.9529%, Training Loss: 1.1212%\n",
      "Epoch [10/300], Step [62/225], Training Accuracy: 46.0685%, Training Loss: 1.1209%\n",
      "Epoch [10/300], Step [63/225], Training Accuracy: 46.0069%, Training Loss: 1.1221%\n",
      "Epoch [10/300], Step [64/225], Training Accuracy: 46.0205%, Training Loss: 1.1225%\n",
      "Epoch [10/300], Step [65/225], Training Accuracy: 45.9135%, Training Loss: 1.1247%\n",
      "Epoch [10/300], Step [66/225], Training Accuracy: 46.0464%, Training Loss: 1.1229%\n",
      "Epoch [10/300], Step [67/225], Training Accuracy: 46.1054%, Training Loss: 1.1220%\n",
      "Epoch [10/300], Step [68/225], Training Accuracy: 46.1627%, Training Loss: 1.1219%\n",
      "Epoch [10/300], Step [69/225], Training Accuracy: 46.0145%, Training Loss: 1.1216%\n",
      "Epoch [10/300], Step [70/225], Training Accuracy: 46.0268%, Training Loss: 1.1220%\n",
      "Epoch [10/300], Step [71/225], Training Accuracy: 46.1708%, Training Loss: 1.1212%\n",
      "Epoch [10/300], Step [72/225], Training Accuracy: 46.1589%, Training Loss: 1.1223%\n",
      "Epoch [10/300], Step [73/225], Training Accuracy: 46.0830%, Training Loss: 1.1226%\n",
      "Epoch [10/300], Step [74/225], Training Accuracy: 46.0093%, Training Loss: 1.1222%\n",
      "Epoch [10/300], Step [75/225], Training Accuracy: 46.0208%, Training Loss: 1.1212%\n",
      "Epoch [10/300], Step [76/225], Training Accuracy: 45.9498%, Training Loss: 1.1213%\n",
      "Epoch [10/300], Step [77/225], Training Accuracy: 45.9821%, Training Loss: 1.1214%\n",
      "Epoch [10/300], Step [78/225], Training Accuracy: 45.8734%, Training Loss: 1.1213%\n",
      "Epoch [10/300], Step [79/225], Training Accuracy: 45.8465%, Training Loss: 1.1216%\n",
      "Epoch [10/300], Step [80/225], Training Accuracy: 45.7422%, Training Loss: 1.1221%\n",
      "Epoch [10/300], Step [81/225], Training Accuracy: 45.8140%, Training Loss: 1.1228%\n",
      "Epoch [10/300], Step [82/225], Training Accuracy: 45.9413%, Training Loss: 1.1227%\n",
      "Epoch [10/300], Step [83/225], Training Accuracy: 45.9714%, Training Loss: 1.1220%\n",
      "Epoch [10/300], Step [84/225], Training Accuracy: 46.0193%, Training Loss: 1.1209%\n",
      "Epoch [10/300], Step [85/225], Training Accuracy: 46.1581%, Training Loss: 1.1200%\n",
      "Epoch [10/300], Step [86/225], Training Accuracy: 46.2028%, Training Loss: 1.1191%\n",
      "Epoch [10/300], Step [87/225], Training Accuracy: 46.2105%, Training Loss: 1.1194%\n",
      "Epoch [10/300], Step [88/225], Training Accuracy: 46.0938%, Training Loss: 1.1196%\n",
      "Epoch [10/300], Step [89/225], Training Accuracy: 46.0499%, Training Loss: 1.1201%\n",
      "Epoch [10/300], Step [90/225], Training Accuracy: 45.9375%, Training Loss: 1.1202%\n",
      "Epoch [10/300], Step [91/225], Training Accuracy: 45.8791%, Training Loss: 1.1224%\n",
      "Epoch [10/300], Step [92/225], Training Accuracy: 45.7880%, Training Loss: 1.1234%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/300], Step [93/225], Training Accuracy: 45.9173%, Training Loss: 1.1229%\n",
      "Epoch [10/300], Step [94/225], Training Accuracy: 45.9774%, Training Loss: 1.1214%\n",
      "Epoch [10/300], Step [95/225], Training Accuracy: 45.8882%, Training Loss: 1.1223%\n",
      "Epoch [10/300], Step [96/225], Training Accuracy: 46.0449%, Training Loss: 1.1209%\n",
      "Epoch [10/300], Step [97/225], Training Accuracy: 46.1823%, Training Loss: 1.1195%\n",
      "Epoch [10/300], Step [98/225], Training Accuracy: 46.1575%, Training Loss: 1.1199%\n",
      "Epoch [10/300], Step [99/225], Training Accuracy: 46.1806%, Training Loss: 1.1196%\n",
      "Epoch [10/300], Step [100/225], Training Accuracy: 46.1406%, Training Loss: 1.1195%\n",
      "Epoch [10/300], Step [101/225], Training Accuracy: 46.1943%, Training Loss: 1.1185%\n",
      "Epoch [10/300], Step [102/225], Training Accuracy: 46.1244%, Training Loss: 1.1192%\n",
      "Epoch [10/300], Step [103/225], Training Accuracy: 46.1468%, Training Loss: 1.1194%\n",
      "Epoch [10/300], Step [104/225], Training Accuracy: 46.0637%, Training Loss: 1.1204%\n",
      "Epoch [10/300], Step [105/225], Training Accuracy: 46.0565%, Training Loss: 1.1204%\n",
      "Epoch [10/300], Step [106/225], Training Accuracy: 46.0643%, Training Loss: 1.1198%\n",
      "Epoch [10/300], Step [107/225], Training Accuracy: 46.0718%, Training Loss: 1.1196%\n",
      "Epoch [10/300], Step [108/225], Training Accuracy: 46.0938%, Training Loss: 1.1205%\n",
      "Epoch [10/300], Step [109/225], Training Accuracy: 46.1439%, Training Loss: 1.1201%\n",
      "Epoch [10/300], Step [110/225], Training Accuracy: 46.1932%, Training Loss: 1.1195%\n",
      "Epoch [10/300], Step [111/225], Training Accuracy: 46.2697%, Training Loss: 1.1190%\n",
      "Epoch [10/300], Step [112/225], Training Accuracy: 46.2891%, Training Loss: 1.1181%\n",
      "Epoch [10/300], Step [113/225], Training Accuracy: 46.3219%, Training Loss: 1.1172%\n",
      "Epoch [10/300], Step [114/225], Training Accuracy: 46.3268%, Training Loss: 1.1160%\n",
      "Epoch [10/300], Step [115/225], Training Accuracy: 46.3859%, Training Loss: 1.1152%\n",
      "Epoch [10/300], Step [116/225], Training Accuracy: 46.3631%, Training Loss: 1.1159%\n",
      "Epoch [10/300], Step [117/225], Training Accuracy: 46.2874%, Training Loss: 1.1166%\n",
      "Epoch [10/300], Step [118/225], Training Accuracy: 46.2924%, Training Loss: 1.1157%\n",
      "Epoch [10/300], Step [119/225], Training Accuracy: 46.2316%, Training Loss: 1.1163%\n",
      "Epoch [10/300], Step [120/225], Training Accuracy: 46.2500%, Training Loss: 1.1167%\n",
      "Epoch [10/300], Step [121/225], Training Accuracy: 46.1906%, Training Loss: 1.1168%\n",
      "Epoch [10/300], Step [122/225], Training Accuracy: 46.2346%, Training Loss: 1.1166%\n",
      "Epoch [10/300], Step [123/225], Training Accuracy: 46.1890%, Training Loss: 1.1165%\n",
      "Epoch [10/300], Step [124/225], Training Accuracy: 46.1820%, Training Loss: 1.1157%\n",
      "Epoch [10/300], Step [125/225], Training Accuracy: 46.1875%, Training Loss: 1.1163%\n",
      "Epoch [10/300], Step [126/225], Training Accuracy: 46.2302%, Training Loss: 1.1164%\n",
      "Epoch [10/300], Step [127/225], Training Accuracy: 46.1245%, Training Loss: 1.1171%\n",
      "Epoch [10/300], Step [128/225], Training Accuracy: 46.0815%, Training Loss: 1.1170%\n",
      "Epoch [10/300], Step [129/225], Training Accuracy: 46.0514%, Training Loss: 1.1172%\n",
      "Epoch [10/300], Step [130/225], Training Accuracy: 46.0697%, Training Loss: 1.1176%\n",
      "Epoch [10/300], Step [131/225], Training Accuracy: 46.0401%, Training Loss: 1.1178%\n",
      "Epoch [10/300], Step [132/225], Training Accuracy: 46.1174%, Training Loss: 1.1174%\n",
      "Epoch [10/300], Step [133/225], Training Accuracy: 46.1349%, Training Loss: 1.1168%\n",
      "Epoch [10/300], Step [134/225], Training Accuracy: 46.0238%, Training Loss: 1.1176%\n",
      "Epoch [10/300], Step [135/225], Training Accuracy: 46.0301%, Training Loss: 1.1173%\n",
      "Epoch [10/300], Step [136/225], Training Accuracy: 46.0478%, Training Loss: 1.1170%\n",
      "Epoch [10/300], Step [137/225], Training Accuracy: 46.0196%, Training Loss: 1.1166%\n",
      "Epoch [10/300], Step [138/225], Training Accuracy: 46.1164%, Training Loss: 1.1159%\n",
      "Epoch [10/300], Step [139/225], Training Accuracy: 46.1556%, Training Loss: 1.1161%\n",
      "Epoch [10/300], Step [140/225], Training Accuracy: 46.1496%, Training Loss: 1.1161%\n",
      "Epoch [10/300], Step [141/225], Training Accuracy: 46.2212%, Training Loss: 1.1151%\n",
      "Epoch [10/300], Step [142/225], Training Accuracy: 46.2588%, Training Loss: 1.1140%\n",
      "Epoch [10/300], Step [143/225], Training Accuracy: 46.2850%, Training Loss: 1.1139%\n",
      "Epoch [10/300], Step [144/225], Training Accuracy: 46.3216%, Training Loss: 1.1146%\n",
      "Epoch [10/300], Step [145/225], Training Accuracy: 46.3147%, Training Loss: 1.1146%\n",
      "Epoch [10/300], Step [146/225], Training Accuracy: 46.2650%, Training Loss: 1.1157%\n",
      "Epoch [10/300], Step [147/225], Training Accuracy: 46.2691%, Training Loss: 1.1154%\n",
      "Epoch [10/300], Step [148/225], Training Accuracy: 46.3577%, Training Loss: 1.1146%\n",
      "Epoch [10/300], Step [149/225], Training Accuracy: 46.3402%, Training Loss: 1.1147%\n",
      "Epoch [10/300], Step [150/225], Training Accuracy: 46.3646%, Training Loss: 1.1146%\n",
      "Epoch [10/300], Step [151/225], Training Accuracy: 46.4507%, Training Loss: 1.1145%\n",
      "Epoch [10/300], Step [152/225], Training Accuracy: 46.4741%, Training Loss: 1.1143%\n",
      "Epoch [10/300], Step [153/225], Training Accuracy: 46.4971%, Training Loss: 1.1138%\n",
      "Epoch [10/300], Step [154/225], Training Accuracy: 46.4590%, Training Loss: 1.1136%\n",
      "Epoch [10/300], Step [155/225], Training Accuracy: 46.4415%, Training Loss: 1.1136%\n",
      "Epoch [10/300], Step [156/225], Training Accuracy: 46.4042%, Training Loss: 1.1143%\n",
      "Epoch [10/300], Step [157/225], Training Accuracy: 46.4670%, Training Loss: 1.1140%\n",
      "Epoch [10/300], Step [158/225], Training Accuracy: 46.4399%, Training Loss: 1.1142%\n",
      "Epoch [10/300], Step [159/225], Training Accuracy: 46.4131%, Training Loss: 1.1142%\n",
      "Epoch [10/300], Step [160/225], Training Accuracy: 46.3965%, Training Loss: 1.1150%\n",
      "Epoch [10/300], Step [161/225], Training Accuracy: 46.4577%, Training Loss: 1.1140%\n",
      "Epoch [10/300], Step [162/225], Training Accuracy: 46.4699%, Training Loss: 1.1139%\n",
      "Epoch [10/300], Step [163/225], Training Accuracy: 46.4724%, Training Loss: 1.1138%\n",
      "Epoch [10/300], Step [164/225], Training Accuracy: 46.5034%, Training Loss: 1.1136%\n",
      "Epoch [10/300], Step [165/225], Training Accuracy: 46.4678%, Training Loss: 1.1145%\n",
      "Epoch [10/300], Step [166/225], Training Accuracy: 46.4703%, Training Loss: 1.1142%\n",
      "Epoch [10/300], Step [167/225], Training Accuracy: 46.5195%, Training Loss: 1.1133%\n",
      "Epoch [10/300], Step [168/225], Training Accuracy: 46.5030%, Training Loss: 1.1135%\n",
      "Epoch [10/300], Step [169/225], Training Accuracy: 46.5237%, Training Loss: 1.1130%\n",
      "Epoch [10/300], Step [170/225], Training Accuracy: 46.5257%, Training Loss: 1.1130%\n",
      "Epoch [10/300], Step [171/225], Training Accuracy: 46.5552%, Training Loss: 1.1123%\n",
      "Epoch [10/300], Step [172/225], Training Accuracy: 46.5207%, Training Loss: 1.1125%\n",
      "Epoch [10/300], Step [173/225], Training Accuracy: 46.5047%, Training Loss: 1.1122%\n",
      "Epoch [10/300], Step [174/225], Training Accuracy: 46.4799%, Training Loss: 1.1122%\n",
      "Epoch [10/300], Step [175/225], Training Accuracy: 46.4643%, Training Loss: 1.1126%\n",
      "Epoch [10/300], Step [176/225], Training Accuracy: 46.4134%, Training Loss: 1.1133%\n",
      "Epoch [10/300], Step [177/225], Training Accuracy: 46.4601%, Training Loss: 1.1132%\n",
      "Epoch [10/300], Step [178/225], Training Accuracy: 46.4624%, Training Loss: 1.1135%\n",
      "Epoch [10/300], Step [179/225], Training Accuracy: 46.4560%, Training Loss: 1.1140%\n",
      "Epoch [10/300], Step [180/225], Training Accuracy: 46.5191%, Training Loss: 1.1133%\n",
      "Epoch [10/300], Step [181/225], Training Accuracy: 46.4520%, Training Loss: 1.1142%\n",
      "Epoch [10/300], Step [182/225], Training Accuracy: 46.4200%, Training Loss: 1.1146%\n",
      "Epoch [10/300], Step [183/225], Training Accuracy: 46.4139%, Training Loss: 1.1141%\n",
      "Epoch [10/300], Step [184/225], Training Accuracy: 46.4079%, Training Loss: 1.1138%\n",
      "Epoch [10/300], Step [185/225], Training Accuracy: 46.4358%, Training Loss: 1.1139%\n",
      "Epoch [10/300], Step [186/225], Training Accuracy: 46.4298%, Training Loss: 1.1136%\n",
      "Epoch [10/300], Step [187/225], Training Accuracy: 46.5074%, Training Loss: 1.1131%\n",
      "Epoch [10/300], Step [188/225], Training Accuracy: 46.5342%, Training Loss: 1.1129%\n",
      "Epoch [10/300], Step [189/225], Training Accuracy: 46.5526%, Training Loss: 1.1124%\n",
      "Epoch [10/300], Step [190/225], Training Accuracy: 46.5625%, Training Loss: 1.1131%\n",
      "Epoch [10/300], Step [191/225], Training Accuracy: 46.6050%, Training Loss: 1.1130%\n",
      "Epoch [10/300], Step [192/225], Training Accuracy: 46.6309%, Training Loss: 1.1129%\n",
      "Epoch [10/300], Step [193/225], Training Accuracy: 46.6159%, Training Loss: 1.1134%\n",
      "Epoch [10/300], Step [194/225], Training Accuracy: 46.6656%, Training Loss: 1.1130%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/300], Step [195/225], Training Accuracy: 46.6987%, Training Loss: 1.1123%\n",
      "Epoch [10/300], Step [196/225], Training Accuracy: 46.6757%, Training Loss: 1.1131%\n",
      "Epoch [10/300], Step [197/225], Training Accuracy: 46.6529%, Training Loss: 1.1134%\n",
      "Epoch [10/300], Step [198/225], Training Accuracy: 46.7093%, Training Loss: 1.1128%\n",
      "Epoch [10/300], Step [199/225], Training Accuracy: 46.7572%, Training Loss: 1.1122%\n",
      "Epoch [10/300], Step [200/225], Training Accuracy: 46.7656%, Training Loss: 1.1127%\n",
      "Epoch [10/300], Step [201/225], Training Accuracy: 46.7584%, Training Loss: 1.1133%\n",
      "Epoch [10/300], Step [202/225], Training Accuracy: 46.7667%, Training Loss: 1.1133%\n",
      "Epoch [10/300], Step [203/225], Training Accuracy: 46.7057%, Training Loss: 1.1139%\n",
      "Epoch [10/300], Step [204/225], Training Accuracy: 46.6682%, Training Loss: 1.1144%\n",
      "Epoch [10/300], Step [205/225], Training Accuracy: 46.7530%, Training Loss: 1.1141%\n",
      "Epoch [10/300], Step [206/225], Training Accuracy: 46.7309%, Training Loss: 1.1142%\n",
      "Epoch [10/300], Step [207/225], Training Accuracy: 46.7467%, Training Loss: 1.1140%\n",
      "Epoch [10/300], Step [208/225], Training Accuracy: 46.7773%, Training Loss: 1.1137%\n",
      "Epoch [10/300], Step [209/225], Training Accuracy: 46.8002%, Training Loss: 1.1135%\n",
      "Epoch [10/300], Step [210/225], Training Accuracy: 46.7857%, Training Loss: 1.1134%\n",
      "Epoch [10/300], Step [211/225], Training Accuracy: 46.7787%, Training Loss: 1.1130%\n",
      "Epoch [10/300], Step [212/225], Training Accuracy: 46.7276%, Training Loss: 1.1132%\n",
      "Epoch [10/300], Step [213/225], Training Accuracy: 46.6769%, Training Loss: 1.1134%\n",
      "Epoch [10/300], Step [214/225], Training Accuracy: 46.6779%, Training Loss: 1.1131%\n",
      "Epoch [10/300], Step [215/225], Training Accuracy: 46.6570%, Training Loss: 1.1135%\n",
      "Epoch [10/300], Step [216/225], Training Accuracy: 46.6291%, Training Loss: 1.1141%\n",
      "Epoch [10/300], Step [217/225], Training Accuracy: 46.6230%, Training Loss: 1.1137%\n",
      "Epoch [10/300], Step [218/225], Training Accuracy: 46.6313%, Training Loss: 1.1137%\n",
      "Epoch [10/300], Step [219/225], Training Accuracy: 46.6396%, Training Loss: 1.1134%\n",
      "Epoch [10/300], Step [220/225], Training Accuracy: 46.6619%, Training Loss: 1.1132%\n",
      "Epoch [10/300], Step [221/225], Training Accuracy: 46.6205%, Training Loss: 1.1133%\n",
      "Epoch [10/300], Step [222/225], Training Accuracy: 46.6216%, Training Loss: 1.1128%\n",
      "Epoch [10/300], Step [223/225], Training Accuracy: 46.6017%, Training Loss: 1.1129%\n",
      "Epoch [10/300], Step [224/225], Training Accuracy: 46.6030%, Training Loss: 1.1125%\n",
      "Epoch [10/300], Step [225/225], Training Accuracy: 46.6092%, Training Loss: 1.1128%\n",
      "Epoch [11/300], Step [1/225], Training Accuracy: 54.6875%, Training Loss: 1.0829%\n",
      "Epoch [11/300], Step [2/225], Training Accuracy: 47.6562%, Training Loss: 1.1101%\n",
      "Epoch [11/300], Step [3/225], Training Accuracy: 45.3125%, Training Loss: 1.1200%\n",
      "Epoch [11/300], Step [4/225], Training Accuracy: 46.0938%, Training Loss: 1.1038%\n",
      "Epoch [11/300], Step [5/225], Training Accuracy: 48.1250%, Training Loss: 1.0949%\n",
      "Epoch [11/300], Step [6/225], Training Accuracy: 47.6562%, Training Loss: 1.1006%\n",
      "Epoch [11/300], Step [7/225], Training Accuracy: 46.4286%, Training Loss: 1.1172%\n",
      "Epoch [11/300], Step [8/225], Training Accuracy: 47.0703%, Training Loss: 1.1134%\n",
      "Epoch [11/300], Step [9/225], Training Accuracy: 47.0486%, Training Loss: 1.1157%\n",
      "Epoch [11/300], Step [10/225], Training Accuracy: 46.2500%, Training Loss: 1.1179%\n",
      "Epoch [11/300], Step [11/225], Training Accuracy: 46.5909%, Training Loss: 1.1205%\n",
      "Epoch [11/300], Step [12/225], Training Accuracy: 46.6146%, Training Loss: 1.1160%\n",
      "Epoch [11/300], Step [13/225], Training Accuracy: 47.8365%, Training Loss: 1.1057%\n",
      "Epoch [11/300], Step [14/225], Training Accuracy: 47.7679%, Training Loss: 1.1093%\n",
      "Epoch [11/300], Step [15/225], Training Accuracy: 47.1875%, Training Loss: 1.1134%\n",
      "Epoch [11/300], Step [16/225], Training Accuracy: 47.3633%, Training Loss: 1.1177%\n",
      "Epoch [11/300], Step [17/225], Training Accuracy: 47.7022%, Training Loss: 1.1133%\n",
      "Epoch [11/300], Step [18/225], Training Accuracy: 47.0486%, Training Loss: 1.1174%\n",
      "Epoch [11/300], Step [19/225], Training Accuracy: 47.4507%, Training Loss: 1.1143%\n",
      "Epoch [11/300], Step [20/225], Training Accuracy: 47.7344%, Training Loss: 1.1102%\n",
      "Epoch [11/300], Step [21/225], Training Accuracy: 47.6935%, Training Loss: 1.1070%\n",
      "Epoch [11/300], Step [22/225], Training Accuracy: 47.4432%, Training Loss: 1.1086%\n",
      "Epoch [11/300], Step [23/225], Training Accuracy: 47.4864%, Training Loss: 1.1091%\n",
      "Epoch [11/300], Step [24/225], Training Accuracy: 47.5911%, Training Loss: 1.1083%\n",
      "Epoch [11/300], Step [25/225], Training Accuracy: 47.9375%, Training Loss: 1.1028%\n",
      "Epoch [11/300], Step [26/225], Training Accuracy: 47.7764%, Training Loss: 1.1013%\n",
      "Epoch [11/300], Step [27/225], Training Accuracy: 47.6273%, Training Loss: 1.1021%\n",
      "Epoch [11/300], Step [28/225], Training Accuracy: 47.9353%, Training Loss: 1.0975%\n",
      "Epoch [11/300], Step [29/225], Training Accuracy: 48.1681%, Training Loss: 1.0943%\n",
      "Epoch [11/300], Step [30/225], Training Accuracy: 48.0729%, Training Loss: 1.0949%\n",
      "Epoch [11/300], Step [31/225], Training Accuracy: 47.9839%, Training Loss: 1.0971%\n",
      "Epoch [11/300], Step [32/225], Training Accuracy: 48.0957%, Training Loss: 1.0927%\n",
      "Epoch [11/300], Step [33/225], Training Accuracy: 47.8220%, Training Loss: 1.0928%\n",
      "Epoch [11/300], Step [34/225], Training Accuracy: 47.7482%, Training Loss: 1.0957%\n",
      "Epoch [11/300], Step [35/225], Training Accuracy: 47.8125%, Training Loss: 1.0969%\n",
      "Epoch [11/300], Step [36/225], Training Accuracy: 47.6128%, Training Loss: 1.0970%\n",
      "Epoch [11/300], Step [37/225], Training Accuracy: 48.0574%, Training Loss: 1.0948%\n",
      "Epoch [11/300], Step [38/225], Training Accuracy: 48.1908%, Training Loss: 1.0935%\n",
      "Epoch [11/300], Step [39/225], Training Accuracy: 47.9968%, Training Loss: 1.0941%\n",
      "Epoch [11/300], Step [40/225], Training Accuracy: 47.9297%, Training Loss: 1.0933%\n",
      "Epoch [11/300], Step [41/225], Training Accuracy: 47.9040%, Training Loss: 1.0949%\n",
      "Epoch [11/300], Step [42/225], Training Accuracy: 47.8795%, Training Loss: 1.0945%\n",
      "Epoch [11/300], Step [43/225], Training Accuracy: 47.9651%, Training Loss: 1.0919%\n",
      "Epoch [11/300], Step [44/225], Training Accuracy: 48.1179%, Training Loss: 1.0902%\n",
      "Epoch [11/300], Step [45/225], Training Accuracy: 48.4028%, Training Loss: 1.0863%\n",
      "Epoch [11/300], Step [46/225], Training Accuracy: 48.5734%, Training Loss: 1.0835%\n",
      "Epoch [11/300], Step [47/225], Training Accuracy: 48.4375%, Training Loss: 1.0841%\n",
      "Epoch [11/300], Step [48/225], Training Accuracy: 48.5026%, Training Loss: 1.0835%\n",
      "Epoch [11/300], Step [49/225], Training Accuracy: 48.4375%, Training Loss: 1.0834%\n",
      "Epoch [11/300], Step [50/225], Training Accuracy: 48.3750%, Training Loss: 1.0813%\n",
      "Epoch [11/300], Step [51/225], Training Accuracy: 48.5600%, Training Loss: 1.0798%\n",
      "Epoch [11/300], Step [52/225], Training Accuracy: 48.5877%, Training Loss: 1.0793%\n",
      "Epoch [11/300], Step [53/225], Training Accuracy: 48.5554%, Training Loss: 1.0817%\n",
      "Epoch [11/300], Step [54/225], Training Accuracy: 48.5822%, Training Loss: 1.0808%\n",
      "Epoch [11/300], Step [55/225], Training Accuracy: 48.5227%, Training Loss: 1.0811%\n",
      "Epoch [11/300], Step [56/225], Training Accuracy: 48.3259%, Training Loss: 1.0820%\n",
      "Epoch [11/300], Step [57/225], Training Accuracy: 48.3279%, Training Loss: 1.0805%\n",
      "Epoch [11/300], Step [58/225], Training Accuracy: 48.3297%, Training Loss: 1.0804%\n",
      "Epoch [11/300], Step [59/225], Training Accuracy: 48.3581%, Training Loss: 1.0790%\n",
      "Epoch [11/300], Step [60/225], Training Accuracy: 48.4115%, Training Loss: 1.0788%\n",
      "Epoch [11/300], Step [61/225], Training Accuracy: 48.3863%, Training Loss: 1.0794%\n",
      "Epoch [11/300], Step [62/225], Training Accuracy: 48.5887%, Training Loss: 1.0794%\n",
      "Epoch [11/300], Step [63/225], Training Accuracy: 48.4871%, Training Loss: 1.0800%\n",
      "Epoch [11/300], Step [64/225], Training Accuracy: 48.4619%, Training Loss: 1.0816%\n",
      "Epoch [11/300], Step [65/225], Training Accuracy: 48.4135%, Training Loss: 1.0832%\n",
      "Epoch [11/300], Step [66/225], Training Accuracy: 48.3665%, Training Loss: 1.0820%\n",
      "Epoch [11/300], Step [67/225], Training Accuracy: 48.4375%, Training Loss: 1.0806%\n",
      "Epoch [11/300], Step [68/225], Training Accuracy: 48.4835%, Training Loss: 1.0802%\n",
      "Epoch [11/300], Step [69/225], Training Accuracy: 48.4149%, Training Loss: 1.0798%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/300], Step [70/225], Training Accuracy: 48.4152%, Training Loss: 1.0802%\n",
      "Epoch [11/300], Step [71/225], Training Accuracy: 48.4375%, Training Loss: 1.0792%\n",
      "Epoch [11/300], Step [72/225], Training Accuracy: 48.4375%, Training Loss: 1.0803%\n",
      "Epoch [11/300], Step [73/225], Training Accuracy: 48.4589%, Training Loss: 1.0813%\n",
      "Epoch [11/300], Step [74/225], Training Accuracy: 48.5008%, Training Loss: 1.0799%\n",
      "Epoch [11/300], Step [75/225], Training Accuracy: 48.6042%, Training Loss: 1.0788%\n",
      "Epoch [11/300], Step [76/225], Training Accuracy: 48.6020%, Training Loss: 1.0793%\n",
      "Epoch [11/300], Step [77/225], Training Accuracy: 48.6404%, Training Loss: 1.0796%\n",
      "Epoch [11/300], Step [78/225], Training Accuracy: 48.6178%, Training Loss: 1.0799%\n",
      "Epoch [11/300], Step [79/225], Training Accuracy: 48.5562%, Training Loss: 1.0805%\n",
      "Epoch [11/300], Step [80/225], Training Accuracy: 48.3594%, Training Loss: 1.0813%\n",
      "Epoch [11/300], Step [81/225], Training Accuracy: 48.4375%, Training Loss: 1.0817%\n",
      "Epoch [11/300], Step [82/225], Training Accuracy: 48.4947%, Training Loss: 1.0819%\n",
      "Epoch [11/300], Step [83/225], Training Accuracy: 48.4752%, Training Loss: 1.0820%\n",
      "Epoch [11/300], Step [84/225], Training Accuracy: 48.4933%, Training Loss: 1.0812%\n",
      "Epoch [11/300], Step [85/225], Training Accuracy: 48.5294%, Training Loss: 1.0801%\n",
      "Epoch [11/300], Step [86/225], Training Accuracy: 48.6374%, Training Loss: 1.0801%\n",
      "Epoch [11/300], Step [87/225], Training Accuracy: 48.6351%, Training Loss: 1.0812%\n",
      "Epoch [11/300], Step [88/225], Training Accuracy: 48.5440%, Training Loss: 1.0820%\n",
      "Epoch [11/300], Step [89/225], Training Accuracy: 48.5253%, Training Loss: 1.0824%\n",
      "Epoch [11/300], Step [90/225], Training Accuracy: 48.4028%, Training Loss: 1.0836%\n",
      "Epoch [11/300], Step [91/225], Training Accuracy: 48.4203%, Training Loss: 1.0849%\n",
      "Epoch [11/300], Step [92/225], Training Accuracy: 48.3526%, Training Loss: 1.0860%\n",
      "Epoch [11/300], Step [93/225], Training Accuracy: 48.4711%, Training Loss: 1.0863%\n",
      "Epoch [11/300], Step [94/225], Training Accuracy: 48.5206%, Training Loss: 1.0860%\n",
      "Epoch [11/300], Step [95/225], Training Accuracy: 48.5855%, Training Loss: 1.0863%\n",
      "Epoch [11/300], Step [96/225], Training Accuracy: 48.7305%, Training Loss: 1.0862%\n",
      "Epoch [11/300], Step [97/225], Training Accuracy: 48.7919%, Training Loss: 1.0848%\n",
      "Epoch [11/300], Step [98/225], Training Accuracy: 48.7564%, Training Loss: 1.0851%\n",
      "Epoch [11/300], Step [99/225], Training Accuracy: 48.8163%, Training Loss: 1.0857%\n",
      "Epoch [11/300], Step [100/225], Training Accuracy: 48.7344%, Training Loss: 1.0867%\n",
      "Epoch [11/300], Step [101/225], Training Accuracy: 48.7005%, Training Loss: 1.0861%\n",
      "Epoch [11/300], Step [102/225], Training Accuracy: 48.6366%, Training Loss: 1.0865%\n",
      "Epoch [11/300], Step [103/225], Training Accuracy: 48.6802%, Training Loss: 1.0860%\n",
      "Epoch [11/300], Step [104/225], Training Accuracy: 48.5727%, Training Loss: 1.0867%\n",
      "Epoch [11/300], Step [105/225], Training Accuracy: 48.5714%, Training Loss: 1.0863%\n",
      "Epoch [11/300], Step [106/225], Training Accuracy: 48.5849%, Training Loss: 1.0861%\n",
      "Epoch [11/300], Step [107/225], Training Accuracy: 48.4959%, Training Loss: 1.0868%\n",
      "Epoch [11/300], Step [108/225], Training Accuracy: 48.4086%, Training Loss: 1.0869%\n",
      "Epoch [11/300], Step [109/225], Training Accuracy: 48.4662%, Training Loss: 1.0863%\n",
      "Epoch [11/300], Step [110/225], Training Accuracy: 48.5938%, Training Loss: 1.0856%\n",
      "Epoch [11/300], Step [111/225], Training Accuracy: 48.6909%, Training Loss: 1.0844%\n",
      "Epoch [11/300], Step [112/225], Training Accuracy: 48.6886%, Training Loss: 1.0837%\n",
      "Epoch [11/300], Step [113/225], Training Accuracy: 48.6311%, Training Loss: 1.0837%\n",
      "Epoch [11/300], Step [114/225], Training Accuracy: 48.5471%, Training Loss: 1.0829%\n",
      "Epoch [11/300], Step [115/225], Training Accuracy: 48.6005%, Training Loss: 1.0823%\n",
      "Epoch [11/300], Step [116/225], Training Accuracy: 48.5587%, Training Loss: 1.0825%\n",
      "Epoch [11/300], Step [117/225], Training Accuracy: 48.4642%, Training Loss: 1.0834%\n",
      "Epoch [11/300], Step [118/225], Training Accuracy: 48.4640%, Training Loss: 1.0829%\n",
      "Epoch [11/300], Step [119/225], Training Accuracy: 48.4375%, Training Loss: 1.0826%\n",
      "Epoch [11/300], Step [120/225], Training Accuracy: 48.4635%, Training Loss: 1.0828%\n",
      "Epoch [11/300], Step [121/225], Training Accuracy: 48.3858%, Training Loss: 1.0832%\n",
      "Epoch [11/300], Step [122/225], Training Accuracy: 48.4119%, Training Loss: 1.0828%\n",
      "Epoch [11/300], Step [123/225], Training Accuracy: 48.4756%, Training Loss: 1.0822%\n",
      "Epoch [11/300], Step [124/225], Training Accuracy: 48.5131%, Training Loss: 1.0814%\n",
      "Epoch [11/300], Step [125/225], Training Accuracy: 48.4875%, Training Loss: 1.0825%\n",
      "Epoch [11/300], Step [126/225], Training Accuracy: 48.4747%, Training Loss: 1.0828%\n",
      "Epoch [11/300], Step [127/225], Training Accuracy: 48.4129%, Training Loss: 1.0841%\n",
      "Epoch [11/300], Step [128/225], Training Accuracy: 48.3887%, Training Loss: 1.0841%\n",
      "Epoch [11/300], Step [129/225], Training Accuracy: 48.4133%, Training Loss: 1.0838%\n",
      "Epoch [11/300], Step [130/225], Training Accuracy: 48.4135%, Training Loss: 1.0838%\n",
      "Epoch [11/300], Step [131/225], Training Accuracy: 48.4017%, Training Loss: 1.0838%\n",
      "Epoch [11/300], Step [132/225], Training Accuracy: 48.4375%, Training Loss: 1.0836%\n",
      "Epoch [11/300], Step [133/225], Training Accuracy: 48.4727%, Training Loss: 1.0834%\n",
      "Epoch [11/300], Step [134/225], Training Accuracy: 48.3326%, Training Loss: 1.0848%\n",
      "Epoch [11/300], Step [135/225], Training Accuracy: 48.4028%, Training Loss: 1.0845%\n",
      "Epoch [11/300], Step [136/225], Training Accuracy: 48.4030%, Training Loss: 1.0840%\n",
      "Epoch [11/300], Step [137/225], Training Accuracy: 48.3577%, Training Loss: 1.0846%\n",
      "Epoch [11/300], Step [138/225], Training Accuracy: 48.3809%, Training Loss: 1.0841%\n",
      "Epoch [11/300], Step [139/225], Training Accuracy: 48.4038%, Training Loss: 1.0837%\n",
      "Epoch [11/300], Step [140/225], Training Accuracy: 48.4152%, Training Loss: 1.0841%\n",
      "Epoch [11/300], Step [141/225], Training Accuracy: 48.4486%, Training Loss: 1.0831%\n",
      "Epoch [11/300], Step [142/225], Training Accuracy: 48.5255%, Training Loss: 1.0823%\n",
      "Epoch [11/300], Step [143/225], Training Accuracy: 48.5249%, Training Loss: 1.0820%\n",
      "Epoch [11/300], Step [144/225], Training Accuracy: 48.5026%, Training Loss: 1.0823%\n",
      "Epoch [11/300], Step [145/225], Training Accuracy: 48.5129%, Training Loss: 1.0830%\n",
      "Epoch [11/300], Step [146/225], Training Accuracy: 48.4482%, Training Loss: 1.0841%\n",
      "Epoch [11/300], Step [147/225], Training Accuracy: 48.4694%, Training Loss: 1.0839%\n",
      "Epoch [11/300], Step [148/225], Training Accuracy: 48.5642%, Training Loss: 1.0831%\n",
      "Epoch [11/300], Step [149/225], Training Accuracy: 48.5214%, Training Loss: 1.0830%\n",
      "Epoch [11/300], Step [150/225], Training Accuracy: 48.5521%, Training Loss: 1.0824%\n",
      "Epoch [11/300], Step [151/225], Training Accuracy: 48.5513%, Training Loss: 1.0820%\n",
      "Epoch [11/300], Step [152/225], Training Accuracy: 48.5095%, Training Loss: 1.0822%\n",
      "Epoch [11/300], Step [153/225], Training Accuracy: 48.4988%, Training Loss: 1.0819%\n",
      "Epoch [11/300], Step [154/225], Training Accuracy: 48.4882%, Training Loss: 1.0817%\n",
      "Epoch [11/300], Step [155/225], Training Accuracy: 48.4577%, Training Loss: 1.0825%\n",
      "Epoch [11/300], Step [156/225], Training Accuracy: 48.4475%, Training Loss: 1.0829%\n",
      "Epoch [11/300], Step [157/225], Training Accuracy: 48.4375%, Training Loss: 1.0828%\n",
      "Epoch [11/300], Step [158/225], Training Accuracy: 48.4078%, Training Loss: 1.0829%\n",
      "Epoch [11/300], Step [159/225], Training Accuracy: 48.3687%, Training Loss: 1.0831%\n",
      "Epoch [11/300], Step [160/225], Training Accuracy: 48.3398%, Training Loss: 1.0841%\n",
      "Epoch [11/300], Step [161/225], Training Accuracy: 48.3987%, Training Loss: 1.0831%\n",
      "Epoch [11/300], Step [162/225], Training Accuracy: 48.4086%, Training Loss: 1.0830%\n",
      "Epoch [11/300], Step [163/225], Training Accuracy: 48.4471%, Training Loss: 1.0829%\n",
      "Epoch [11/300], Step [164/225], Training Accuracy: 48.4566%, Training Loss: 1.0822%\n",
      "Epoch [11/300], Step [165/225], Training Accuracy: 48.4375%, Training Loss: 1.0826%\n",
      "Epoch [11/300], Step [166/225], Training Accuracy: 48.4469%, Training Loss: 1.0824%\n",
      "Epoch [11/300], Step [167/225], Training Accuracy: 48.5030%, Training Loss: 1.0815%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/300], Step [168/225], Training Accuracy: 48.4933%, Training Loss: 1.0813%\n",
      "Epoch [11/300], Step [169/225], Training Accuracy: 48.5207%, Training Loss: 1.0807%\n",
      "Epoch [11/300], Step [170/225], Training Accuracy: 48.5662%, Training Loss: 1.0804%\n",
      "Epoch [11/300], Step [171/225], Training Accuracy: 48.5928%, Training Loss: 1.0798%\n",
      "Epoch [11/300], Step [172/225], Training Accuracy: 48.5828%, Training Loss: 1.0799%\n",
      "Epoch [11/300], Step [173/225], Training Accuracy: 48.6001%, Training Loss: 1.0798%\n",
      "Epoch [11/300], Step [174/225], Training Accuracy: 48.5991%, Training Loss: 1.0797%\n",
      "Epoch [11/300], Step [175/225], Training Accuracy: 48.6250%, Training Loss: 1.0798%\n",
      "Epoch [11/300], Step [176/225], Training Accuracy: 48.6151%, Training Loss: 1.0802%\n",
      "Epoch [11/300], Step [177/225], Training Accuracy: 48.6582%, Training Loss: 1.0798%\n",
      "Epoch [11/300], Step [178/225], Training Accuracy: 48.6482%, Training Loss: 1.0803%\n",
      "Epoch [11/300], Step [179/225], Training Accuracy: 48.6819%, Training Loss: 1.0797%\n",
      "Epoch [11/300], Step [180/225], Training Accuracy: 48.7760%, Training Loss: 1.0786%\n",
      "Epoch [11/300], Step [181/225], Training Accuracy: 48.6965%, Training Loss: 1.0797%\n",
      "Epoch [11/300], Step [182/225], Training Accuracy: 48.6865%, Training Loss: 1.0806%\n",
      "Epoch [11/300], Step [183/225], Training Accuracy: 48.6936%, Training Loss: 1.0799%\n",
      "Epoch [11/300], Step [184/225], Training Accuracy: 48.6668%, Training Loss: 1.0799%\n",
      "Epoch [11/300], Step [185/225], Training Accuracy: 48.7331%, Training Loss: 1.0798%\n",
      "Epoch [11/300], Step [186/225], Training Accuracy: 48.7651%, Training Loss: 1.0794%\n",
      "Epoch [11/300], Step [187/225], Training Accuracy: 48.8051%, Training Loss: 1.0788%\n",
      "Epoch [11/300], Step [188/225], Training Accuracy: 48.7949%, Training Loss: 1.0787%\n",
      "Epoch [11/300], Step [189/225], Training Accuracy: 48.8178%, Training Loss: 1.0783%\n",
      "Epoch [11/300], Step [190/225], Training Accuracy: 48.8158%, Training Loss: 1.0782%\n",
      "Epoch [11/300], Step [191/225], Training Accuracy: 48.8384%, Training Loss: 1.0781%\n",
      "Epoch [11/300], Step [192/225], Training Accuracy: 48.8607%, Training Loss: 1.0778%\n",
      "Epoch [11/300], Step [193/225], Training Accuracy: 48.8099%, Training Loss: 1.0783%\n",
      "Epoch [11/300], Step [194/225], Training Accuracy: 48.7919%, Training Loss: 1.0783%\n",
      "Epoch [11/300], Step [195/225], Training Accuracy: 48.7901%, Training Loss: 1.0777%\n",
      "Epoch [11/300], Step [196/225], Training Accuracy: 48.7962%, Training Loss: 1.0784%\n",
      "Epoch [11/300], Step [197/225], Training Accuracy: 48.7944%, Training Loss: 1.0788%\n",
      "Epoch [11/300], Step [198/225], Training Accuracy: 48.8400%, Training Loss: 1.0780%\n",
      "Epoch [11/300], Step [199/225], Training Accuracy: 48.8772%, Training Loss: 1.0774%\n",
      "Epoch [11/300], Step [200/225], Training Accuracy: 48.8906%, Training Loss: 1.0774%\n",
      "Epoch [11/300], Step [201/225], Training Accuracy: 48.9039%, Training Loss: 1.0777%\n",
      "Epoch [11/300], Step [202/225], Training Accuracy: 48.8939%, Training Loss: 1.0779%\n",
      "Epoch [11/300], Step [203/225], Training Accuracy: 48.8685%, Training Loss: 1.0784%\n",
      "Epoch [11/300], Step [204/225], Training Accuracy: 48.8358%, Training Loss: 1.0789%\n",
      "Epoch [11/300], Step [205/225], Training Accuracy: 48.8567%, Training Loss: 1.0785%\n",
      "Epoch [11/300], Step [206/225], Training Accuracy: 48.9078%, Training Loss: 1.0784%\n",
      "Epoch [11/300], Step [207/225], Training Accuracy: 48.9130%, Training Loss: 1.0783%\n",
      "Epoch [11/300], Step [208/225], Training Accuracy: 48.9333%, Training Loss: 1.0779%\n",
      "Epoch [11/300], Step [209/225], Training Accuracy: 48.9459%, Training Loss: 1.0777%\n",
      "Epoch [11/300], Step [210/225], Training Accuracy: 48.9732%, Training Loss: 1.0771%\n",
      "Epoch [11/300], Step [211/225], Training Accuracy: 48.9855%, Training Loss: 1.0767%\n",
      "Epoch [11/300], Step [212/225], Training Accuracy: 48.9829%, Training Loss: 1.0766%\n",
      "Epoch [11/300], Step [213/225], Training Accuracy: 48.9070%, Training Loss: 1.0776%\n",
      "Epoch [11/300], Step [214/225], Training Accuracy: 48.9413%, Training Loss: 1.0771%\n",
      "Epoch [11/300], Step [215/225], Training Accuracy: 48.9172%, Training Loss: 1.0771%\n",
      "Epoch [11/300], Step [216/225], Training Accuracy: 48.8788%, Training Loss: 1.0778%\n",
      "Epoch [11/300], Step [217/225], Training Accuracy: 48.8695%, Training Loss: 1.0775%\n",
      "Epoch [11/300], Step [218/225], Training Accuracy: 48.8675%, Training Loss: 1.0774%\n",
      "Epoch [11/300], Step [219/225], Training Accuracy: 48.8799%, Training Loss: 1.0766%\n",
      "Epoch [11/300], Step [220/225], Training Accuracy: 48.8920%, Training Loss: 1.0763%\n",
      "Epoch [11/300], Step [221/225], Training Accuracy: 48.8900%, Training Loss: 1.0761%\n",
      "Epoch [11/300], Step [222/225], Training Accuracy: 48.9161%, Training Loss: 1.0757%\n",
      "Epoch [11/300], Step [223/225], Training Accuracy: 48.8859%, Training Loss: 1.0758%\n",
      "Epoch [11/300], Step [224/225], Training Accuracy: 48.8770%, Training Loss: 1.0754%\n",
      "Epoch [11/300], Step [225/225], Training Accuracy: 48.8952%, Training Loss: 1.0752%\n",
      "Epoch [12/300], Step [1/225], Training Accuracy: 65.6250%, Training Loss: 0.9076%\n",
      "Epoch [12/300], Step [2/225], Training Accuracy: 55.4688%, Training Loss: 1.0254%\n",
      "Epoch [12/300], Step [3/225], Training Accuracy: 50.5208%, Training Loss: 1.0533%\n",
      "Epoch [12/300], Step [4/225], Training Accuracy: 51.5625%, Training Loss: 1.0204%\n",
      "Epoch [12/300], Step [5/225], Training Accuracy: 52.8125%, Training Loss: 1.0129%\n",
      "Epoch [12/300], Step [6/225], Training Accuracy: 52.6042%, Training Loss: 1.0181%\n",
      "Epoch [12/300], Step [7/225], Training Accuracy: 51.3393%, Training Loss: 1.0431%\n",
      "Epoch [12/300], Step [8/225], Training Accuracy: 50.9766%, Training Loss: 1.0542%\n",
      "Epoch [12/300], Step [9/225], Training Accuracy: 51.0417%, Training Loss: 1.0586%\n",
      "Epoch [12/300], Step [10/225], Training Accuracy: 49.8438%, Training Loss: 1.0640%\n",
      "Epoch [12/300], Step [11/225], Training Accuracy: 49.5739%, Training Loss: 1.0750%\n",
      "Epoch [12/300], Step [12/225], Training Accuracy: 49.8698%, Training Loss: 1.0748%\n",
      "Epoch [12/300], Step [13/225], Training Accuracy: 50.9615%, Training Loss: 1.0663%\n",
      "Epoch [12/300], Step [14/225], Training Accuracy: 50.1116%, Training Loss: 1.0730%\n",
      "Epoch [12/300], Step [15/225], Training Accuracy: 50.0000%, Training Loss: 1.0750%\n",
      "Epoch [12/300], Step [16/225], Training Accuracy: 49.7070%, Training Loss: 1.0761%\n",
      "Epoch [12/300], Step [17/225], Training Accuracy: 49.8162%, Training Loss: 1.0744%\n",
      "Epoch [12/300], Step [18/225], Training Accuracy: 49.0451%, Training Loss: 1.0814%\n",
      "Epoch [12/300], Step [19/225], Training Accuracy: 49.0132%, Training Loss: 1.0811%\n",
      "Epoch [12/300], Step [20/225], Training Accuracy: 49.2188%, Training Loss: 1.0751%\n",
      "Epoch [12/300], Step [21/225], Training Accuracy: 49.9256%, Training Loss: 1.0681%\n",
      "Epoch [12/300], Step [22/225], Training Accuracy: 49.7159%, Training Loss: 1.0696%\n",
      "Epoch [12/300], Step [23/225], Training Accuracy: 49.5245%, Training Loss: 1.0689%\n",
      "Epoch [12/300], Step [24/225], Training Accuracy: 49.4792%, Training Loss: 1.0694%\n",
      "Epoch [12/300], Step [25/225], Training Accuracy: 49.5625%, Training Loss: 1.0654%\n",
      "Epoch [12/300], Step [26/225], Training Accuracy: 49.3990%, Training Loss: 1.0660%\n",
      "Epoch [12/300], Step [27/225], Training Accuracy: 49.0741%, Training Loss: 1.0686%\n",
      "Epoch [12/300], Step [28/225], Training Accuracy: 49.3304%, Training Loss: 1.0632%\n",
      "Epoch [12/300], Step [29/225], Training Accuracy: 49.4612%, Training Loss: 1.0588%\n",
      "Epoch [12/300], Step [30/225], Training Accuracy: 49.4271%, Training Loss: 1.0585%\n",
      "Epoch [12/300], Step [31/225], Training Accuracy: 49.3952%, Training Loss: 1.0598%\n",
      "Epoch [12/300], Step [32/225], Training Accuracy: 49.5605%, Training Loss: 1.0549%\n",
      "Epoch [12/300], Step [33/225], Training Accuracy: 49.5265%, Training Loss: 1.0552%\n",
      "Epoch [12/300], Step [34/225], Training Accuracy: 49.4485%, Training Loss: 1.0566%\n",
      "Epoch [12/300], Step [35/225], Training Accuracy: 49.4196%, Training Loss: 1.0586%\n",
      "Epoch [12/300], Step [36/225], Training Accuracy: 49.3490%, Training Loss: 1.0574%\n",
      "Epoch [12/300], Step [37/225], Training Accuracy: 49.4932%, Training Loss: 1.0552%\n",
      "Epoch [12/300], Step [38/225], Training Accuracy: 49.4243%, Training Loss: 1.0542%\n",
      "Epoch [12/300], Step [39/225], Training Accuracy: 49.3590%, Training Loss: 1.0547%\n",
      "Epoch [12/300], Step [40/225], Training Accuracy: 49.2188%, Training Loss: 1.0543%\n",
      "Epoch [12/300], Step [41/225], Training Accuracy: 49.0473%, Training Loss: 1.0578%\n",
      "Epoch [12/300], Step [42/225], Training Accuracy: 48.8095%, Training Loss: 1.0578%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/300], Step [43/225], Training Accuracy: 48.8372%, Training Loss: 1.0553%\n",
      "Epoch [12/300], Step [44/225], Training Accuracy: 48.9347%, Training Loss: 1.0523%\n",
      "Epoch [12/300], Step [45/225], Training Accuracy: 49.2014%, Training Loss: 1.0501%\n",
      "Epoch [12/300], Step [46/225], Training Accuracy: 49.3546%, Training Loss: 1.0472%\n",
      "Epoch [12/300], Step [47/225], Training Accuracy: 49.1356%, Training Loss: 1.0464%\n",
      "Epoch [12/300], Step [48/225], Training Accuracy: 49.2188%, Training Loss: 1.0448%\n",
      "Epoch [12/300], Step [49/225], Training Accuracy: 49.2985%, Training Loss: 1.0445%\n",
      "Epoch [12/300], Step [50/225], Training Accuracy: 49.2500%, Training Loss: 1.0435%\n",
      "Epoch [12/300], Step [51/225], Training Accuracy: 49.3873%, Training Loss: 1.0413%\n",
      "Epoch [12/300], Step [52/225], Training Accuracy: 49.5493%, Training Loss: 1.0392%\n",
      "Epoch [12/300], Step [53/225], Training Accuracy: 49.6167%, Training Loss: 1.0412%\n",
      "Epoch [12/300], Step [54/225], Training Accuracy: 49.7975%, Training Loss: 1.0413%\n",
      "Epoch [12/300], Step [55/225], Training Accuracy: 49.6591%, Training Loss: 1.0425%\n",
      "Epoch [12/300], Step [56/225], Training Accuracy: 49.5536%, Training Loss: 1.0426%\n",
      "Epoch [12/300], Step [57/225], Training Accuracy: 49.5614%, Training Loss: 1.0415%\n",
      "Epoch [12/300], Step [58/225], Training Accuracy: 49.5420%, Training Loss: 1.0418%\n",
      "Epoch [12/300], Step [59/225], Training Accuracy: 49.3379%, Training Loss: 1.0429%\n",
      "Epoch [12/300], Step [60/225], Training Accuracy: 49.3750%, Training Loss: 1.0430%\n",
      "Epoch [12/300], Step [61/225], Training Accuracy: 49.3340%, Training Loss: 1.0425%\n",
      "Epoch [12/300], Step [62/225], Training Accuracy: 49.5464%, Training Loss: 1.0407%\n",
      "Epoch [12/300], Step [63/225], Training Accuracy: 49.5288%, Training Loss: 1.0410%\n",
      "Epoch [12/300], Step [64/225], Training Accuracy: 49.3408%, Training Loss: 1.0433%\n",
      "Epoch [12/300], Step [65/225], Training Accuracy: 49.3269%, Training Loss: 1.0447%\n",
      "Epoch [12/300], Step [66/225], Training Accuracy: 49.3845%, Training Loss: 1.0421%\n",
      "Epoch [12/300], Step [67/225], Training Accuracy: 49.5336%, Training Loss: 1.0409%\n",
      "Epoch [12/300], Step [68/225], Training Accuracy: 49.4945%, Training Loss: 1.0406%\n",
      "Epoch [12/300], Step [69/225], Training Accuracy: 49.4339%, Training Loss: 1.0404%\n",
      "Epoch [12/300], Step [70/225], Training Accuracy: 49.5089%, Training Loss: 1.0406%\n",
      "Epoch [12/300], Step [71/225], Training Accuracy: 49.4718%, Training Loss: 1.0403%\n",
      "Epoch [12/300], Step [72/225], Training Accuracy: 49.4358%, Training Loss: 1.0424%\n",
      "Epoch [12/300], Step [73/225], Training Accuracy: 49.4221%, Training Loss: 1.0420%\n",
      "Epoch [12/300], Step [74/225], Training Accuracy: 49.4510%, Training Loss: 1.0411%\n",
      "Epoch [12/300], Step [75/225], Training Accuracy: 49.4375%, Training Loss: 1.0409%\n",
      "Epoch [12/300], Step [76/225], Training Accuracy: 49.4449%, Training Loss: 1.0406%\n",
      "Epoch [12/300], Step [77/225], Training Accuracy: 49.4724%, Training Loss: 1.0406%\n",
      "Epoch [12/300], Step [78/225], Training Accuracy: 49.4591%, Training Loss: 1.0399%\n",
      "Epoch [12/300], Step [79/225], Training Accuracy: 49.4066%, Training Loss: 1.0411%\n",
      "Epoch [12/300], Step [80/225], Training Accuracy: 49.3359%, Training Loss: 1.0411%\n",
      "Epoch [12/300], Step [81/225], Training Accuracy: 49.2863%, Training Loss: 1.0423%\n",
      "Epoch [12/300], Step [82/225], Training Accuracy: 49.3902%, Training Loss: 1.0431%\n",
      "Epoch [12/300], Step [83/225], Training Accuracy: 49.3035%, Training Loss: 1.0427%\n",
      "Epoch [12/300], Step [84/225], Training Accuracy: 49.3676%, Training Loss: 1.0422%\n",
      "Epoch [12/300], Step [85/225], Training Accuracy: 49.3750%, Training Loss: 1.0409%\n",
      "Epoch [12/300], Step [86/225], Training Accuracy: 49.4549%, Training Loss: 1.0392%\n",
      "Epoch [12/300], Step [87/225], Training Accuracy: 49.5330%, Training Loss: 1.0392%\n",
      "Epoch [12/300], Step [88/225], Training Accuracy: 49.4318%, Training Loss: 1.0403%\n",
      "Epoch [12/300], Step [89/225], Training Accuracy: 49.4031%, Training Loss: 1.0416%\n",
      "Epoch [12/300], Step [90/225], Training Accuracy: 49.2708%, Training Loss: 1.0427%\n",
      "Epoch [12/300], Step [91/225], Training Accuracy: 49.3132%, Training Loss: 1.0428%\n",
      "Epoch [12/300], Step [92/225], Training Accuracy: 49.2188%, Training Loss: 1.0426%\n",
      "Epoch [12/300], Step [93/225], Training Accuracy: 49.3448%, Training Loss: 1.0413%\n",
      "Epoch [12/300], Step [94/225], Training Accuracy: 49.4515%, Training Loss: 1.0398%\n",
      "Epoch [12/300], Step [95/225], Training Accuracy: 49.4737%, Training Loss: 1.0406%\n",
      "Epoch [12/300], Step [96/225], Training Accuracy: 49.6745%, Training Loss: 1.0389%\n",
      "Epoch [12/300], Step [97/225], Training Accuracy: 49.8067%, Training Loss: 1.0373%\n",
      "Epoch [12/300], Step [98/225], Training Accuracy: 49.8087%, Training Loss: 1.0373%\n",
      "Epoch [12/300], Step [99/225], Training Accuracy: 49.9369%, Training Loss: 1.0372%\n",
      "Epoch [12/300], Step [100/225], Training Accuracy: 49.8906%, Training Loss: 1.0377%\n",
      "Epoch [12/300], Step [101/225], Training Accuracy: 49.9072%, Training Loss: 1.0368%\n",
      "Epoch [12/300], Step [102/225], Training Accuracy: 49.8621%, Training Loss: 1.0368%\n",
      "Epoch [12/300], Step [103/225], Training Accuracy: 49.9393%, Training Loss: 1.0356%\n",
      "Epoch [12/300], Step [104/225], Training Accuracy: 49.8648%, Training Loss: 1.0358%\n",
      "Epoch [12/300], Step [105/225], Training Accuracy: 49.9405%, Training Loss: 1.0346%\n",
      "Epoch [12/300], Step [106/225], Training Accuracy: 49.9853%, Training Loss: 1.0343%\n",
      "Epoch [12/300], Step [107/225], Training Accuracy: 50.0000%, Training Loss: 1.0341%\n",
      "Epoch [12/300], Step [108/225], Training Accuracy: 49.9421%, Training Loss: 1.0345%\n",
      "Epoch [12/300], Step [109/225], Training Accuracy: 49.9427%, Training Loss: 1.0334%\n",
      "Epoch [12/300], Step [110/225], Training Accuracy: 50.0000%, Training Loss: 1.0325%\n",
      "Epoch [12/300], Step [111/225], Training Accuracy: 50.0282%, Training Loss: 1.0320%\n",
      "Epoch [12/300], Step [112/225], Training Accuracy: 50.0558%, Training Loss: 1.0317%\n",
      "Epoch [12/300], Step [113/225], Training Accuracy: 50.0691%, Training Loss: 1.0317%\n",
      "Epoch [12/300], Step [114/225], Training Accuracy: 50.0685%, Training Loss: 1.0311%\n",
      "Epoch [12/300], Step [115/225], Training Accuracy: 50.1359%, Training Loss: 1.0300%\n",
      "Epoch [12/300], Step [116/225], Training Accuracy: 50.0808%, Training Loss: 1.0303%\n",
      "Epoch [12/300], Step [117/225], Training Accuracy: 50.0534%, Training Loss: 1.0314%\n",
      "Epoch [12/300], Step [118/225], Training Accuracy: 50.0530%, Training Loss: 1.0315%\n",
      "Epoch [12/300], Step [119/225], Training Accuracy: 50.0788%, Training Loss: 1.0312%\n",
      "Epoch [12/300], Step [120/225], Training Accuracy: 50.0911%, Training Loss: 1.0318%\n",
      "Epoch [12/300], Step [121/225], Training Accuracy: 49.9483%, Training Loss: 1.0335%\n",
      "Epoch [12/300], Step [122/225], Training Accuracy: 49.9360%, Training Loss: 1.0333%\n",
      "Epoch [12/300], Step [123/225], Training Accuracy: 49.9492%, Training Loss: 1.0328%\n",
      "Epoch [12/300], Step [124/225], Training Accuracy: 50.0000%, Training Loss: 1.0316%\n",
      "Epoch [12/300], Step [125/225], Training Accuracy: 49.9625%, Training Loss: 1.0332%\n",
      "Epoch [12/300], Step [126/225], Training Accuracy: 49.9132%, Training Loss: 1.0337%\n",
      "Epoch [12/300], Step [127/225], Training Accuracy: 49.8524%, Training Loss: 1.0343%\n",
      "Epoch [12/300], Step [128/225], Training Accuracy: 49.7803%, Training Loss: 1.0349%\n",
      "Epoch [12/300], Step [129/225], Training Accuracy: 49.7578%, Training Loss: 1.0348%\n",
      "Epoch [12/300], Step [130/225], Training Accuracy: 49.7476%, Training Loss: 1.0357%\n",
      "Epoch [12/300], Step [131/225], Training Accuracy: 49.6899%, Training Loss: 1.0365%\n",
      "Epoch [12/300], Step [132/225], Training Accuracy: 49.6922%, Training Loss: 1.0363%\n",
      "Epoch [12/300], Step [133/225], Training Accuracy: 49.7180%, Training Loss: 1.0359%\n",
      "Epoch [12/300], Step [134/225], Training Accuracy: 49.6385%, Training Loss: 1.0366%\n",
      "Epoch [12/300], Step [135/225], Training Accuracy: 49.6412%, Training Loss: 1.0360%\n",
      "Epoch [12/300], Step [136/225], Training Accuracy: 49.6783%, Training Loss: 1.0357%\n",
      "Epoch [12/300], Step [137/225], Training Accuracy: 49.6807%, Training Loss: 1.0355%\n",
      "Epoch [12/300], Step [138/225], Training Accuracy: 49.7396%, Training Loss: 1.0343%\n",
      "Epoch [12/300], Step [139/225], Training Accuracy: 49.7302%, Training Loss: 1.0341%\n",
      "Epoch [12/300], Step [140/225], Training Accuracy: 49.7991%, Training Loss: 1.0337%\n",
      "Epoch [12/300], Step [141/225], Training Accuracy: 49.8227%, Training Loss: 1.0326%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/300], Step [142/225], Training Accuracy: 49.9230%, Training Loss: 1.0316%\n",
      "Epoch [12/300], Step [143/225], Training Accuracy: 49.9235%, Training Loss: 1.0316%\n",
      "Epoch [12/300], Step [144/225], Training Accuracy: 49.9023%, Training Loss: 1.0316%\n",
      "Epoch [12/300], Step [145/225], Training Accuracy: 49.9030%, Training Loss: 1.0310%\n",
      "Epoch [12/300], Step [146/225], Training Accuracy: 49.8288%, Training Loss: 1.0326%\n",
      "Epoch [12/300], Step [147/225], Training Accuracy: 49.7555%, Training Loss: 1.0327%\n",
      "Epoch [12/300], Step [148/225], Training Accuracy: 49.8416%, Training Loss: 1.0319%\n",
      "Epoch [12/300], Step [149/225], Training Accuracy: 49.8217%, Training Loss: 1.0315%\n",
      "Epoch [12/300], Step [150/225], Training Accuracy: 49.8854%, Training Loss: 1.0307%\n",
      "Epoch [12/300], Step [151/225], Training Accuracy: 49.9069%, Training Loss: 1.0305%\n",
      "Epoch [12/300], Step [152/225], Training Accuracy: 49.8458%, Training Loss: 1.0308%\n",
      "Epoch [12/300], Step [153/225], Training Accuracy: 49.8979%, Training Loss: 1.0304%\n",
      "Epoch [12/300], Step [154/225], Training Accuracy: 49.8884%, Training Loss: 1.0305%\n",
      "Epoch [12/300], Step [155/225], Training Accuracy: 49.8589%, Training Loss: 1.0308%\n",
      "Epoch [12/300], Step [156/225], Training Accuracy: 49.7897%, Training Loss: 1.0314%\n",
      "Epoch [12/300], Step [157/225], Training Accuracy: 49.8209%, Training Loss: 1.0315%\n",
      "Epoch [12/300], Step [158/225], Training Accuracy: 49.8022%, Training Loss: 1.0317%\n",
      "Epoch [12/300], Step [159/225], Training Accuracy: 49.8231%, Training Loss: 1.0314%\n",
      "Epoch [12/300], Step [160/225], Training Accuracy: 49.8145%, Training Loss: 1.0318%\n",
      "Epoch [12/300], Step [161/225], Training Accuracy: 49.8544%, Training Loss: 1.0309%\n",
      "Epoch [12/300], Step [162/225], Training Accuracy: 49.8939%, Training Loss: 1.0308%\n",
      "Epoch [12/300], Step [163/225], Training Accuracy: 49.8850%, Training Loss: 1.0308%\n",
      "Epoch [12/300], Step [164/225], Training Accuracy: 49.9143%, Training Loss: 1.0302%\n",
      "Epoch [12/300], Step [165/225], Training Accuracy: 49.8580%, Training Loss: 1.0308%\n",
      "Epoch [12/300], Step [166/225], Training Accuracy: 49.8682%, Training Loss: 1.0303%\n",
      "Epoch [12/300], Step [167/225], Training Accuracy: 49.9345%, Training Loss: 1.0296%\n",
      "Epoch [12/300], Step [168/225], Training Accuracy: 49.9349%, Training Loss: 1.0293%\n",
      "Epoch [12/300], Step [169/225], Training Accuracy: 49.9723%, Training Loss: 1.0287%\n",
      "Epoch [12/300], Step [170/225], Training Accuracy: 50.0000%, Training Loss: 1.0286%\n",
      "Epoch [12/300], Step [171/225], Training Accuracy: 50.0183%, Training Loss: 1.0281%\n",
      "Epoch [12/300], Step [172/225], Training Accuracy: 49.9909%, Training Loss: 1.0280%\n",
      "Epoch [12/300], Step [173/225], Training Accuracy: 49.9910%, Training Loss: 1.0281%\n",
      "Epoch [12/300], Step [174/225], Training Accuracy: 50.0359%, Training Loss: 1.0280%\n",
      "Epoch [12/300], Step [175/225], Training Accuracy: 50.0536%, Training Loss: 1.0281%\n",
      "Epoch [12/300], Step [176/225], Training Accuracy: 50.0444%, Training Loss: 1.0281%\n",
      "Epoch [12/300], Step [177/225], Training Accuracy: 50.0706%, Training Loss: 1.0285%\n",
      "Epoch [12/300], Step [178/225], Training Accuracy: 50.0263%, Training Loss: 1.0287%\n",
      "Epoch [12/300], Step [179/225], Training Accuracy: 50.0786%, Training Loss: 1.0279%\n",
      "Epoch [12/300], Step [180/225], Training Accuracy: 50.1476%, Training Loss: 1.0268%\n",
      "Epoch [12/300], Step [181/225], Training Accuracy: 50.1209%, Training Loss: 1.0280%\n",
      "Epoch [12/300], Step [182/225], Training Accuracy: 50.1374%, Training Loss: 1.0281%\n",
      "Epoch [12/300], Step [183/225], Training Accuracy: 50.1281%, Training Loss: 1.0278%\n",
      "Epoch [12/300], Step [184/225], Training Accuracy: 50.1444%, Training Loss: 1.0280%\n",
      "Epoch [12/300], Step [185/225], Training Accuracy: 50.1520%, Training Loss: 1.0284%\n",
      "Epoch [12/300], Step [186/225], Training Accuracy: 50.1428%, Training Loss: 1.0285%\n",
      "Epoch [12/300], Step [187/225], Training Accuracy: 50.1922%, Training Loss: 1.0275%\n",
      "Epoch [12/300], Step [188/225], Training Accuracy: 50.2078%, Training Loss: 1.0274%\n",
      "Epoch [12/300], Step [189/225], Training Accuracy: 50.2728%, Training Loss: 1.0267%\n",
      "Epoch [12/300], Step [190/225], Training Accuracy: 50.2632%, Training Loss: 1.0270%\n",
      "Epoch [12/300], Step [191/225], Training Accuracy: 50.2700%, Training Loss: 1.0269%\n",
      "Epoch [12/300], Step [192/225], Training Accuracy: 50.3092%, Training Loss: 1.0265%\n",
      "Epoch [12/300], Step [193/225], Training Accuracy: 50.3157%, Training Loss: 1.0271%\n",
      "Epoch [12/300], Step [194/225], Training Accuracy: 50.3624%, Training Loss: 1.0271%\n",
      "Epoch [12/300], Step [195/225], Training Accuracy: 50.3926%, Training Loss: 1.0262%\n",
      "Epoch [12/300], Step [196/225], Training Accuracy: 50.4066%, Training Loss: 1.0265%\n",
      "Epoch [12/300], Step [197/225], Training Accuracy: 50.4283%, Training Loss: 1.0265%\n",
      "Epoch [12/300], Step [198/225], Training Accuracy: 50.4735%, Training Loss: 1.0258%\n",
      "Epoch [12/300], Step [199/225], Training Accuracy: 50.5104%, Training Loss: 1.0252%\n",
      "Epoch [12/300], Step [200/225], Training Accuracy: 50.5547%, Training Loss: 1.0250%\n",
      "Epoch [12/300], Step [201/225], Training Accuracy: 50.5208%, Training Loss: 1.0256%\n",
      "Epoch [12/300], Step [202/225], Training Accuracy: 50.5105%, Training Loss: 1.0258%\n",
      "Epoch [12/300], Step [203/225], Training Accuracy: 50.4849%, Training Loss: 1.0263%\n",
      "Epoch [12/300], Step [204/225], Training Accuracy: 50.5055%, Training Loss: 1.0261%\n",
      "Epoch [12/300], Step [205/225], Training Accuracy: 50.5107%, Training Loss: 1.0258%\n",
      "Epoch [12/300], Step [206/225], Training Accuracy: 50.5082%, Training Loss: 1.0262%\n",
      "Epoch [12/300], Step [207/225], Training Accuracy: 50.5133%, Training Loss: 1.0265%\n",
      "Epoch [12/300], Step [208/225], Training Accuracy: 50.5859%, Training Loss: 1.0260%\n",
      "Epoch [12/300], Step [209/225], Training Accuracy: 50.5757%, Training Loss: 1.0261%\n",
      "Epoch [12/300], Step [210/225], Training Accuracy: 50.5804%, Training Loss: 1.0259%\n",
      "Epoch [12/300], Step [211/225], Training Accuracy: 50.6146%, Training Loss: 1.0253%\n",
      "Epoch [12/300], Step [212/225], Training Accuracy: 50.5896%, Training Loss: 1.0254%\n",
      "Epoch [12/300], Step [213/225], Training Accuracy: 50.5282%, Training Loss: 1.0264%\n",
      "Epoch [12/300], Step [214/225], Training Accuracy: 50.5695%, Training Loss: 1.0261%\n",
      "Epoch [12/300], Step [215/225], Training Accuracy: 50.5887%, Training Loss: 1.0260%\n",
      "Epoch [12/300], Step [216/225], Training Accuracy: 50.5570%, Training Loss: 1.0267%\n",
      "Epoch [12/300], Step [217/225], Training Accuracy: 50.5472%, Training Loss: 1.0267%\n",
      "Epoch [12/300], Step [218/225], Training Accuracy: 50.5519%, Training Loss: 1.0266%\n",
      "Epoch [12/300], Step [219/225], Training Accuracy: 50.5636%, Training Loss: 1.0260%\n",
      "Epoch [12/300], Step [220/225], Training Accuracy: 50.5753%, Training Loss: 1.0256%\n",
      "Epoch [12/300], Step [221/225], Training Accuracy: 50.5444%, Training Loss: 1.0259%\n",
      "Epoch [12/300], Step [222/225], Training Accuracy: 50.5560%, Training Loss: 1.0255%\n",
      "Epoch [12/300], Step [223/225], Training Accuracy: 50.5395%, Training Loss: 1.0258%\n",
      "Epoch [12/300], Step [224/225], Training Accuracy: 50.5162%, Training Loss: 1.0255%\n",
      "Epoch [12/300], Step [225/225], Training Accuracy: 50.5211%, Training Loss: 1.0256%\n",
      "Epoch [13/300], Step [1/225], Training Accuracy: 67.1875%, Training Loss: 0.8598%\n",
      "Epoch [13/300], Step [2/225], Training Accuracy: 58.5938%, Training Loss: 0.9685%\n",
      "Epoch [13/300], Step [3/225], Training Accuracy: 53.6458%, Training Loss: 1.0150%\n",
      "Epoch [13/300], Step [4/225], Training Accuracy: 51.9531%, Training Loss: 1.0195%\n",
      "Epoch [13/300], Step [5/225], Training Accuracy: 52.8125%, Training Loss: 0.9994%\n",
      "Epoch [13/300], Step [6/225], Training Accuracy: 52.0833%, Training Loss: 0.9925%\n",
      "Epoch [13/300], Step [7/225], Training Accuracy: 50.8929%, Training Loss: 1.0119%\n",
      "Epoch [13/300], Step [8/225], Training Accuracy: 50.7812%, Training Loss: 1.0137%\n",
      "Epoch [13/300], Step [9/225], Training Accuracy: 51.3889%, Training Loss: 1.0095%\n",
      "Epoch [13/300], Step [10/225], Training Accuracy: 50.3125%, Training Loss: 1.0198%\n",
      "Epoch [13/300], Step [11/225], Training Accuracy: 50.4261%, Training Loss: 1.0225%\n",
      "Epoch [13/300], Step [12/225], Training Accuracy: 50.9115%, Training Loss: 1.0201%\n",
      "Epoch [13/300], Step [13/225], Training Accuracy: 52.0433%, Training Loss: 1.0074%\n",
      "Epoch [13/300], Step [14/225], Training Accuracy: 51.6741%, Training Loss: 1.0104%\n",
      "Epoch [13/300], Step [15/225], Training Accuracy: 51.3542%, Training Loss: 1.0116%\n",
      "Epoch [13/300], Step [16/225], Training Accuracy: 51.1719%, Training Loss: 1.0141%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/300], Step [17/225], Training Accuracy: 51.7463%, Training Loss: 1.0065%\n",
      "Epoch [13/300], Step [18/225], Training Accuracy: 51.1285%, Training Loss: 1.0154%\n",
      "Epoch [13/300], Step [19/225], Training Accuracy: 51.1513%, Training Loss: 1.0133%\n",
      "Epoch [13/300], Step [20/225], Training Accuracy: 51.9531%, Training Loss: 1.0065%\n",
      "Epoch [13/300], Step [21/225], Training Accuracy: 52.0833%, Training Loss: 1.0040%\n",
      "Epoch [13/300], Step [22/225], Training Accuracy: 51.6335%, Training Loss: 1.0089%\n",
      "Epoch [13/300], Step [23/225], Training Accuracy: 51.9701%, Training Loss: 1.0041%\n",
      "Epoch [13/300], Step [24/225], Training Accuracy: 51.8229%, Training Loss: 1.0066%\n",
      "Epoch [13/300], Step [25/225], Training Accuracy: 52.0000%, Training Loss: 1.0001%\n",
      "Epoch [13/300], Step [26/225], Training Accuracy: 51.8630%, Training Loss: 0.9977%\n",
      "Epoch [13/300], Step [27/225], Training Accuracy: 51.7940%, Training Loss: 1.0016%\n",
      "Epoch [13/300], Step [28/225], Training Accuracy: 52.3438%, Training Loss: 0.9929%\n",
      "Epoch [13/300], Step [29/225], Training Accuracy: 52.3168%, Training Loss: 0.9912%\n",
      "Epoch [13/300], Step [30/225], Training Accuracy: 51.9792%, Training Loss: 0.9945%\n",
      "Epoch [13/300], Step [31/225], Training Accuracy: 51.9657%, Training Loss: 0.9971%\n",
      "Epoch [13/300], Step [32/225], Training Accuracy: 52.0508%, Training Loss: 0.9911%\n",
      "Epoch [13/300], Step [33/225], Training Accuracy: 52.0360%, Training Loss: 0.9904%\n",
      "Epoch [13/300], Step [34/225], Training Accuracy: 51.9301%, Training Loss: 0.9911%\n",
      "Epoch [13/300], Step [35/225], Training Accuracy: 51.8304%, Training Loss: 0.9960%\n",
      "Epoch [13/300], Step [36/225], Training Accuracy: 51.6927%, Training Loss: 0.9981%\n",
      "Epoch [13/300], Step [37/225], Training Accuracy: 51.9003%, Training Loss: 0.9954%\n",
      "Epoch [13/300], Step [38/225], Training Accuracy: 52.0148%, Training Loss: 0.9937%\n",
      "Epoch [13/300], Step [39/225], Training Accuracy: 51.9631%, Training Loss: 0.9929%\n",
      "Epoch [13/300], Step [40/225], Training Accuracy: 51.6797%, Training Loss: 0.9936%\n",
      "Epoch [13/300], Step [41/225], Training Accuracy: 51.4101%, Training Loss: 0.9987%\n",
      "Epoch [13/300], Step [42/225], Training Accuracy: 51.3393%, Training Loss: 0.9959%\n",
      "Epoch [13/300], Step [43/225], Training Accuracy: 51.4535%, Training Loss: 0.9951%\n",
      "Epoch [13/300], Step [44/225], Training Accuracy: 51.4915%, Training Loss: 0.9933%\n",
      "Epoch [13/300], Step [45/225], Training Accuracy: 51.5278%, Training Loss: 0.9923%\n",
      "Epoch [13/300], Step [46/225], Training Accuracy: 51.6304%, Training Loss: 0.9910%\n",
      "Epoch [13/300], Step [47/225], Training Accuracy: 51.5625%, Training Loss: 0.9904%\n",
      "Epoch [13/300], Step [48/225], Training Accuracy: 51.6276%, Training Loss: 0.9899%\n",
      "Epoch [13/300], Step [49/225], Training Accuracy: 51.5944%, Training Loss: 0.9910%\n",
      "Epoch [13/300], Step [50/225], Training Accuracy: 51.8750%, Training Loss: 0.9888%\n",
      "Epoch [13/300], Step [51/225], Training Accuracy: 51.9914%, Training Loss: 0.9859%\n",
      "Epoch [13/300], Step [52/225], Training Accuracy: 52.1034%, Training Loss: 0.9847%\n",
      "Epoch [13/300], Step [53/225], Training Accuracy: 52.1521%, Training Loss: 0.9858%\n",
      "Epoch [13/300], Step [54/225], Training Accuracy: 52.2280%, Training Loss: 0.9874%\n",
      "Epoch [13/300], Step [55/225], Training Accuracy: 52.0739%, Training Loss: 0.9893%\n",
      "Epoch [13/300], Step [56/225], Training Accuracy: 51.8973%, Training Loss: 0.9892%\n",
      "Epoch [13/300], Step [57/225], Training Accuracy: 51.9463%, Training Loss: 0.9881%\n",
      "Epoch [13/300], Step [58/225], Training Accuracy: 51.9127%, Training Loss: 0.9882%\n",
      "Epoch [13/300], Step [59/225], Training Accuracy: 51.9068%, Training Loss: 0.9888%\n",
      "Epoch [13/300], Step [60/225], Training Accuracy: 51.8490%, Training Loss: 0.9891%\n",
      "Epoch [13/300], Step [61/225], Training Accuracy: 51.9211%, Training Loss: 0.9885%\n",
      "Epoch [13/300], Step [62/225], Training Accuracy: 51.9405%, Training Loss: 0.9876%\n",
      "Epoch [13/300], Step [63/225], Training Accuracy: 51.7857%, Training Loss: 0.9892%\n",
      "Epoch [13/300], Step [64/225], Training Accuracy: 51.6357%, Training Loss: 0.9914%\n",
      "Epoch [13/300], Step [65/225], Training Accuracy: 51.6106%, Training Loss: 0.9926%\n",
      "Epoch [13/300], Step [66/225], Training Accuracy: 51.7756%, Training Loss: 0.9902%\n",
      "Epoch [13/300], Step [67/225], Training Accuracy: 51.7724%, Training Loss: 0.9899%\n",
      "Epoch [13/300], Step [68/225], Training Accuracy: 51.7693%, Training Loss: 0.9906%\n",
      "Epoch [13/300], Step [69/225], Training Accuracy: 51.6531%, Training Loss: 0.9908%\n",
      "Epoch [13/300], Step [70/225], Training Accuracy: 51.5848%, Training Loss: 0.9911%\n",
      "Epoch [13/300], Step [71/225], Training Accuracy: 51.6505%, Training Loss: 0.9915%\n",
      "Epoch [13/300], Step [72/225], Training Accuracy: 51.6710%, Training Loss: 0.9937%\n",
      "Epoch [13/300], Step [73/225], Training Accuracy: 51.6481%, Training Loss: 0.9942%\n",
      "Epoch [13/300], Step [74/225], Training Accuracy: 51.7948%, Training Loss: 0.9920%\n",
      "Epoch [13/300], Step [75/225], Training Accuracy: 51.7292%, Training Loss: 0.9921%\n",
      "Epoch [13/300], Step [76/225], Training Accuracy: 51.7681%, Training Loss: 0.9913%\n",
      "Epoch [13/300], Step [77/225], Training Accuracy: 51.8060%, Training Loss: 0.9912%\n",
      "Epoch [13/300], Step [78/225], Training Accuracy: 51.8029%, Training Loss: 0.9913%\n",
      "Epoch [13/300], Step [79/225], Training Accuracy: 51.7207%, Training Loss: 0.9923%\n",
      "Epoch [13/300], Step [80/225], Training Accuracy: 51.5820%, Training Loss: 0.9934%\n",
      "Epoch [13/300], Step [81/225], Training Accuracy: 51.4853%, Training Loss: 0.9952%\n",
      "Epoch [13/300], Step [82/225], Training Accuracy: 51.5434%, Training Loss: 0.9957%\n",
      "Epoch [13/300], Step [83/225], Training Accuracy: 51.5813%, Training Loss: 0.9953%\n",
      "Epoch [13/300], Step [84/225], Training Accuracy: 51.6369%, Training Loss: 0.9940%\n",
      "Epoch [13/300], Step [85/225], Training Accuracy: 51.7463%, Training Loss: 0.9927%\n",
      "Epoch [13/300], Step [86/225], Training Accuracy: 51.7624%, Training Loss: 0.9922%\n",
      "Epoch [13/300], Step [87/225], Training Accuracy: 51.7780%, Training Loss: 0.9923%\n",
      "Epoch [13/300], Step [88/225], Training Accuracy: 51.6335%, Training Loss: 0.9924%\n",
      "Epoch [13/300], Step [89/225], Training Accuracy: 51.6503%, Training Loss: 0.9944%\n",
      "Epoch [13/300], Step [90/225], Training Accuracy: 51.4931%, Training Loss: 0.9957%\n",
      "Epoch [13/300], Step [91/225], Training Accuracy: 51.5110%, Training Loss: 0.9962%\n",
      "Epoch [13/300], Step [92/225], Training Accuracy: 51.4946%, Training Loss: 0.9974%\n",
      "Epoch [13/300], Step [93/225], Training Accuracy: 51.6297%, Training Loss: 0.9960%\n",
      "Epoch [13/300], Step [94/225], Training Accuracy: 51.7121%, Training Loss: 0.9946%\n",
      "Epoch [13/300], Step [95/225], Training Accuracy: 51.7763%, Training Loss: 0.9946%\n",
      "Epoch [13/300], Step [96/225], Training Accuracy: 51.9206%, Training Loss: 0.9932%\n",
      "Epoch [13/300], Step [97/225], Training Accuracy: 51.9652%, Training Loss: 0.9924%\n",
      "Epoch [13/300], Step [98/225], Training Accuracy: 51.9452%, Training Loss: 0.9925%\n",
      "Epoch [13/300], Step [99/225], Training Accuracy: 51.9729%, Training Loss: 0.9926%\n",
      "Epoch [13/300], Step [100/225], Training Accuracy: 51.9375%, Training Loss: 0.9933%\n",
      "Epoch [13/300], Step [101/225], Training Accuracy: 51.9802%, Training Loss: 0.9921%\n",
      "Epoch [13/300], Step [102/225], Training Accuracy: 51.8995%, Training Loss: 0.9927%\n",
      "Epoch [13/300], Step [103/225], Training Accuracy: 51.9114%, Training Loss: 0.9916%\n",
      "Epoch [13/300], Step [104/225], Training Accuracy: 51.8179%, Training Loss: 0.9921%\n",
      "Epoch [13/300], Step [105/225], Training Accuracy: 51.9196%, Training Loss: 0.9925%\n",
      "Epoch [13/300], Step [106/225], Training Accuracy: 51.9310%, Training Loss: 0.9918%\n",
      "Epoch [13/300], Step [107/225], Training Accuracy: 51.8838%, Training Loss: 0.9926%\n",
      "Epoch [13/300], Step [108/225], Training Accuracy: 51.7795%, Training Loss: 0.9933%\n",
      "Epoch [13/300], Step [109/225], Training Accuracy: 51.8492%, Training Loss: 0.9923%\n",
      "Epoch [13/300], Step [110/225], Training Accuracy: 51.9176%, Training Loss: 0.9914%\n",
      "Epoch [13/300], Step [111/225], Training Accuracy: 52.0130%, Training Loss: 0.9908%\n",
      "Epoch [13/300], Step [112/225], Training Accuracy: 52.0368%, Training Loss: 0.9895%\n",
      "Epoch [13/300], Step [113/225], Training Accuracy: 51.9773%, Training Loss: 0.9894%\n",
      "Epoch [13/300], Step [114/225], Training Accuracy: 51.9737%, Training Loss: 0.9883%\n",
      "Epoch [13/300], Step [115/225], Training Accuracy: 51.9837%, Training Loss: 0.9874%\n",
      "Epoch [13/300], Step [116/225], Training Accuracy: 51.9262%, Training Loss: 0.9877%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/300], Step [117/225], Training Accuracy: 51.8429%, Training Loss: 0.9893%\n",
      "Epoch [13/300], Step [118/225], Training Accuracy: 51.8273%, Training Loss: 0.9884%\n",
      "Epoch [13/300], Step [119/225], Training Accuracy: 51.9170%, Training Loss: 0.9874%\n",
      "Epoch [13/300], Step [120/225], Training Accuracy: 51.9661%, Training Loss: 0.9874%\n",
      "Epoch [13/300], Step [121/225], Training Accuracy: 51.8466%, Training Loss: 0.9889%\n",
      "Epoch [13/300], Step [122/225], Training Accuracy: 51.8955%, Training Loss: 0.9883%\n",
      "Epoch [13/300], Step [123/225], Training Accuracy: 51.9309%, Training Loss: 0.9872%\n",
      "Epoch [13/300], Step [124/225], Training Accuracy: 51.9657%, Training Loss: 0.9862%\n",
      "Epoch [13/300], Step [125/225], Training Accuracy: 51.9250%, Training Loss: 0.9879%\n",
      "Epoch [13/300], Step [126/225], Training Accuracy: 51.9221%, Training Loss: 0.9877%\n",
      "Epoch [13/300], Step [127/225], Training Accuracy: 51.8578%, Training Loss: 0.9883%\n",
      "Epoch [13/300], Step [128/225], Training Accuracy: 51.7578%, Training Loss: 0.9888%\n",
      "Epoch [13/300], Step [129/225], Training Accuracy: 51.8047%, Training Loss: 0.9885%\n",
      "Epoch [13/300], Step [130/225], Training Accuracy: 51.7428%, Training Loss: 0.9894%\n",
      "Epoch [13/300], Step [131/225], Training Accuracy: 51.7176%, Training Loss: 0.9898%\n",
      "Epoch [13/300], Step [132/225], Training Accuracy: 51.6690%, Training Loss: 0.9904%\n",
      "Epoch [13/300], Step [133/225], Training Accuracy: 51.6800%, Training Loss: 0.9901%\n",
      "Epoch [13/300], Step [134/225], Training Accuracy: 51.5508%, Training Loss: 0.9913%\n",
      "Epoch [13/300], Step [135/225], Training Accuracy: 51.5394%, Training Loss: 0.9905%\n",
      "Epoch [13/300], Step [136/225], Training Accuracy: 51.5855%, Training Loss: 0.9905%\n",
      "Epoch [13/300], Step [137/225], Training Accuracy: 51.5967%, Training Loss: 0.9902%\n",
      "Epoch [13/300], Step [138/225], Training Accuracy: 51.6757%, Training Loss: 0.9890%\n",
      "Epoch [13/300], Step [139/225], Training Accuracy: 51.6862%, Training Loss: 0.9888%\n",
      "Epoch [13/300], Step [140/225], Training Accuracy: 51.7076%, Training Loss: 0.9892%\n",
      "Epoch [13/300], Step [141/225], Training Accuracy: 51.7509%, Training Loss: 0.9881%\n",
      "Epoch [13/300], Step [142/225], Training Accuracy: 51.8156%, Training Loss: 0.9877%\n",
      "Epoch [13/300], Step [143/225], Training Accuracy: 51.8138%, Training Loss: 0.9878%\n",
      "Epoch [13/300], Step [144/225], Training Accuracy: 51.7578%, Training Loss: 0.9884%\n",
      "Epoch [13/300], Step [145/225], Training Accuracy: 51.8211%, Training Loss: 0.9879%\n",
      "Epoch [13/300], Step [146/225], Training Accuracy: 51.7872%, Training Loss: 0.9888%\n",
      "Epoch [13/300], Step [147/225], Training Accuracy: 51.7538%, Training Loss: 0.9886%\n",
      "Epoch [13/300], Step [148/225], Training Accuracy: 51.8159%, Training Loss: 0.9876%\n",
      "Epoch [13/300], Step [149/225], Training Accuracy: 51.7303%, Training Loss: 0.9880%\n",
      "Epoch [13/300], Step [150/225], Training Accuracy: 51.7917%, Training Loss: 0.9871%\n",
      "Epoch [13/300], Step [151/225], Training Accuracy: 51.7901%, Training Loss: 0.9870%\n",
      "Epoch [13/300], Step [152/225], Training Accuracy: 51.7887%, Training Loss: 0.9868%\n",
      "Epoch [13/300], Step [153/225], Training Accuracy: 51.7463%, Training Loss: 0.9868%\n",
      "Epoch [13/300], Step [154/225], Training Accuracy: 51.7451%, Training Loss: 0.9871%\n",
      "Epoch [13/300], Step [155/225], Training Accuracy: 51.7238%, Training Loss: 0.9874%\n",
      "Epoch [13/300], Step [156/225], Training Accuracy: 51.7328%, Training Loss: 0.9879%\n",
      "Epoch [13/300], Step [157/225], Training Accuracy: 51.7814%, Training Loss: 0.9875%\n",
      "Epoch [13/300], Step [158/225], Training Accuracy: 51.7108%, Training Loss: 0.9879%\n",
      "Epoch [13/300], Step [159/225], Training Accuracy: 51.7001%, Training Loss: 0.9879%\n",
      "Epoch [13/300], Step [160/225], Training Accuracy: 51.6504%, Training Loss: 0.9886%\n",
      "Epoch [13/300], Step [161/225], Training Accuracy: 51.7081%, Training Loss: 0.9880%\n",
      "Epoch [13/300], Step [162/225], Training Accuracy: 51.7072%, Training Loss: 0.9884%\n",
      "Epoch [13/300], Step [163/225], Training Accuracy: 51.7159%, Training Loss: 0.9880%\n",
      "Epoch [13/300], Step [164/225], Training Accuracy: 51.7530%, Training Loss: 0.9878%\n",
      "Epoch [13/300], Step [165/225], Training Accuracy: 51.7045%, Training Loss: 0.9889%\n",
      "Epoch [13/300], Step [166/225], Training Accuracy: 51.7037%, Training Loss: 0.9884%\n",
      "Epoch [13/300], Step [167/225], Training Accuracy: 51.7309%, Training Loss: 0.9882%\n",
      "Epoch [13/300], Step [168/225], Training Accuracy: 51.7578%, Training Loss: 0.9877%\n",
      "Epoch [13/300], Step [169/225], Training Accuracy: 51.7936%, Training Loss: 0.9871%\n",
      "Epoch [13/300], Step [170/225], Training Accuracy: 51.7647%, Training Loss: 0.9875%\n",
      "Epoch [13/300], Step [171/225], Training Accuracy: 51.7635%, Training Loss: 0.9873%\n",
      "Epoch [13/300], Step [172/225], Training Accuracy: 51.7260%, Training Loss: 0.9876%\n",
      "Epoch [13/300], Step [173/225], Training Accuracy: 51.7702%, Training Loss: 0.9882%\n",
      "Epoch [13/300], Step [174/225], Training Accuracy: 51.7780%, Training Loss: 0.9884%\n",
      "Epoch [13/300], Step [175/225], Training Accuracy: 51.8304%, Training Loss: 0.9885%\n",
      "Epoch [13/300], Step [176/225], Training Accuracy: 51.7933%, Training Loss: 0.9890%\n",
      "Epoch [13/300], Step [177/225], Training Accuracy: 51.8008%, Training Loss: 0.9891%\n",
      "Epoch [13/300], Step [178/225], Training Accuracy: 51.7468%, Training Loss: 0.9896%\n",
      "Epoch [13/300], Step [179/225], Training Accuracy: 51.8156%, Training Loss: 0.9888%\n",
      "Epoch [13/300], Step [180/225], Training Accuracy: 51.8490%, Training Loss: 0.9879%\n",
      "Epoch [13/300], Step [181/225], Training Accuracy: 51.7869%, Training Loss: 0.9890%\n",
      "Epoch [13/300], Step [182/225], Training Accuracy: 51.7943%, Training Loss: 0.9890%\n",
      "Epoch [13/300], Step [183/225], Training Accuracy: 51.7760%, Training Loss: 0.9884%\n",
      "Epoch [13/300], Step [184/225], Training Accuracy: 51.7578%, Training Loss: 0.9881%\n",
      "Epoch [13/300], Step [185/225], Training Accuracy: 51.7905%, Training Loss: 0.9884%\n",
      "Epoch [13/300], Step [186/225], Training Accuracy: 51.8397%, Training Loss: 0.9882%\n",
      "Epoch [13/300], Step [187/225], Training Accuracy: 51.8800%, Training Loss: 0.9875%\n",
      "Epoch [13/300], Step [188/225], Training Accuracy: 51.8700%, Training Loss: 0.9876%\n",
      "Epoch [13/300], Step [189/225], Training Accuracy: 51.8849%, Training Loss: 0.9870%\n",
      "Epoch [13/300], Step [190/225], Training Accuracy: 51.9161%, Training Loss: 0.9871%\n",
      "Epoch [13/300], Step [191/225], Training Accuracy: 51.9224%, Training Loss: 0.9872%\n",
      "Epoch [13/300], Step [192/225], Training Accuracy: 51.9613%, Training Loss: 0.9869%\n",
      "Epoch [13/300], Step [193/225], Training Accuracy: 51.8863%, Training Loss: 0.9873%\n",
      "Epoch [13/300], Step [194/225], Training Accuracy: 51.8444%, Training Loss: 0.9874%\n",
      "Epoch [13/300], Step [195/225], Training Accuracy: 51.8910%, Training Loss: 0.9869%\n",
      "Epoch [13/300], Step [196/225], Training Accuracy: 51.8335%, Training Loss: 0.9875%\n",
      "Epoch [13/300], Step [197/225], Training Accuracy: 51.8163%, Training Loss: 0.9876%\n",
      "Epoch [13/300], Step [198/225], Training Accuracy: 51.8782%, Training Loss: 0.9863%\n",
      "Epoch [13/300], Step [199/225], Training Accuracy: 51.8766%, Training Loss: 0.9860%\n",
      "Epoch [13/300], Step [200/225], Training Accuracy: 51.8828%, Training Loss: 0.9859%\n",
      "Epoch [13/300], Step [201/225], Training Accuracy: 51.8657%, Training Loss: 0.9862%\n",
      "Epoch [13/300], Step [202/225], Training Accuracy: 51.8642%, Training Loss: 0.9864%\n",
      "Epoch [13/300], Step [203/225], Training Accuracy: 51.8781%, Training Loss: 0.9865%\n",
      "Epoch [13/300], Step [204/225], Training Accuracy: 51.8919%, Training Loss: 0.9866%\n",
      "Epoch [13/300], Step [205/225], Training Accuracy: 51.8979%, Training Loss: 0.9867%\n",
      "Epoch [13/300], Step [206/225], Training Accuracy: 51.9038%, Training Loss: 0.9869%\n",
      "Epoch [13/300], Step [207/225], Training Accuracy: 51.9097%, Training Loss: 0.9869%\n",
      "Epoch [13/300], Step [208/225], Training Accuracy: 51.9306%, Training Loss: 0.9861%\n",
      "Epoch [13/300], Step [209/225], Training Accuracy: 51.8989%, Training Loss: 0.9867%\n",
      "Epoch [13/300], Step [210/225], Training Accuracy: 51.8824%, Training Loss: 0.9869%\n",
      "Epoch [13/300], Step [211/225], Training Accuracy: 51.8661%, Training Loss: 0.9864%\n",
      "Epoch [13/300], Step [212/225], Training Accuracy: 51.8573%, Training Loss: 0.9867%\n",
      "Epoch [13/300], Step [213/225], Training Accuracy: 51.7679%, Training Loss: 0.9879%\n",
      "Epoch [13/300], Step [214/225], Training Accuracy: 51.7888%, Training Loss: 0.9876%\n",
      "Epoch [13/300], Step [215/225], Training Accuracy: 51.7515%, Training Loss: 0.9882%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/300], Step [216/225], Training Accuracy: 51.7433%, Training Loss: 0.9888%\n",
      "Epoch [13/300], Step [217/225], Training Accuracy: 51.7209%, Training Loss: 0.9886%\n",
      "Epoch [13/300], Step [218/225], Training Accuracy: 51.6987%, Training Loss: 0.9889%\n",
      "Epoch [13/300], Step [219/225], Training Accuracy: 51.6981%, Training Loss: 0.9887%\n",
      "Epoch [13/300], Step [220/225], Training Accuracy: 51.7614%, Training Loss: 0.9882%\n",
      "Epoch [13/300], Step [221/225], Training Accuracy: 51.7605%, Training Loss: 0.9884%\n",
      "Epoch [13/300], Step [222/225], Training Accuracy: 51.7807%, Training Loss: 0.9880%\n",
      "Epoch [13/300], Step [223/225], Training Accuracy: 51.7587%, Training Loss: 0.9885%\n",
      "Epoch [13/300], Step [224/225], Training Accuracy: 51.7439%, Training Loss: 0.9882%\n",
      "Epoch [13/300], Step [225/225], Training Accuracy: 51.7510%, Training Loss: 0.9882%\n",
      "Epoch [14/300], Step [1/225], Training Accuracy: 73.4375%, Training Loss: 0.7960%\n",
      "Epoch [14/300], Step [2/225], Training Accuracy: 66.4062%, Training Loss: 0.8827%\n",
      "Epoch [14/300], Step [3/225], Training Accuracy: 61.4583%, Training Loss: 0.9288%\n",
      "Epoch [14/300], Step [4/225], Training Accuracy: 60.9375%, Training Loss: 0.9258%\n",
      "Epoch [14/300], Step [5/225], Training Accuracy: 60.0000%, Training Loss: 0.9240%\n",
      "Epoch [14/300], Step [6/225], Training Accuracy: 59.1146%, Training Loss: 0.9369%\n",
      "Epoch [14/300], Step [7/225], Training Accuracy: 58.0357%, Training Loss: 0.9506%\n",
      "Epoch [14/300], Step [8/225], Training Accuracy: 57.2266%, Training Loss: 0.9537%\n",
      "Epoch [14/300], Step [9/225], Training Accuracy: 57.2917%, Training Loss: 0.9569%\n",
      "Epoch [14/300], Step [10/225], Training Accuracy: 55.9375%, Training Loss: 0.9766%\n",
      "Epoch [14/300], Step [11/225], Training Accuracy: 55.1136%, Training Loss: 0.9840%\n",
      "Epoch [14/300], Step [12/225], Training Accuracy: 55.7292%, Training Loss: 0.9846%\n",
      "Epoch [14/300], Step [13/225], Training Accuracy: 56.8510%, Training Loss: 0.9660%\n",
      "Epoch [14/300], Step [14/225], Training Accuracy: 56.4732%, Training Loss: 0.9711%\n",
      "Epoch [14/300], Step [15/225], Training Accuracy: 56.1458%, Training Loss: 0.9724%\n",
      "Epoch [14/300], Step [16/225], Training Accuracy: 55.7617%, Training Loss: 0.9754%\n",
      "Epoch [14/300], Step [17/225], Training Accuracy: 55.8824%, Training Loss: 0.9692%\n",
      "Epoch [14/300], Step [18/225], Training Accuracy: 54.7743%, Training Loss: 0.9745%\n",
      "Epoch [14/300], Step [19/225], Training Accuracy: 54.5230%, Training Loss: 0.9754%\n",
      "Epoch [14/300], Step [20/225], Training Accuracy: 54.7656%, Training Loss: 0.9695%\n",
      "Epoch [14/300], Step [21/225], Training Accuracy: 54.7619%, Training Loss: 0.9653%\n",
      "Epoch [14/300], Step [22/225], Training Accuracy: 54.4744%, Training Loss: 0.9676%\n",
      "Epoch [14/300], Step [23/225], Training Accuracy: 54.6196%, Training Loss: 0.9648%\n",
      "Epoch [14/300], Step [24/225], Training Accuracy: 54.2318%, Training Loss: 0.9687%\n",
      "Epoch [14/300], Step [25/225], Training Accuracy: 54.0625%, Training Loss: 0.9676%\n",
      "Epoch [14/300], Step [26/225], Training Accuracy: 53.9062%, Training Loss: 0.9664%\n",
      "Epoch [14/300], Step [27/225], Training Accuracy: 53.4722%, Training Loss: 0.9710%\n",
      "Epoch [14/300], Step [28/225], Training Accuracy: 53.6830%, Training Loss: 0.9668%\n",
      "Epoch [14/300], Step [29/225], Training Accuracy: 53.6099%, Training Loss: 0.9652%\n",
      "Epoch [14/300], Step [30/225], Training Accuracy: 53.4896%, Training Loss: 0.9660%\n",
      "Epoch [14/300], Step [31/225], Training Accuracy: 53.3266%, Training Loss: 0.9695%\n",
      "Epoch [14/300], Step [32/225], Training Accuracy: 53.3691%, Training Loss: 0.9652%\n",
      "Epoch [14/300], Step [33/225], Training Accuracy: 53.3144%, Training Loss: 0.9641%\n",
      "Epoch [14/300], Step [34/225], Training Accuracy: 53.1710%, Training Loss: 0.9658%\n",
      "Epoch [14/300], Step [35/225], Training Accuracy: 52.9911%, Training Loss: 0.9668%\n",
      "Epoch [14/300], Step [36/225], Training Accuracy: 52.8212%, Training Loss: 0.9676%\n",
      "Epoch [14/300], Step [37/225], Training Accuracy: 53.0828%, Training Loss: 0.9666%\n",
      "Epoch [14/300], Step [38/225], Training Accuracy: 53.1250%, Training Loss: 0.9658%\n",
      "Epoch [14/300], Step [39/225], Training Accuracy: 53.0449%, Training Loss: 0.9670%\n",
      "Epoch [14/300], Step [40/225], Training Accuracy: 52.9688%, Training Loss: 0.9681%\n",
      "Epoch [14/300], Step [41/225], Training Accuracy: 52.7439%, Training Loss: 0.9721%\n",
      "Epoch [14/300], Step [42/225], Training Accuracy: 52.7158%, Training Loss: 0.9712%\n",
      "Epoch [14/300], Step [43/225], Training Accuracy: 52.5799%, Training Loss: 0.9702%\n",
      "Epoch [14/300], Step [44/225], Training Accuracy: 52.5213%, Training Loss: 0.9699%\n",
      "Epoch [14/300], Step [45/225], Training Accuracy: 52.6736%, Training Loss: 0.9671%\n",
      "Epoch [14/300], Step [46/225], Training Accuracy: 52.8533%, Training Loss: 0.9651%\n",
      "Epoch [14/300], Step [47/225], Training Accuracy: 52.8258%, Training Loss: 0.9655%\n",
      "Epoch [14/300], Step [48/225], Training Accuracy: 52.7995%, Training Loss: 0.9656%\n",
      "Epoch [14/300], Step [49/225], Training Accuracy: 52.9656%, Training Loss: 0.9648%\n",
      "Epoch [14/300], Step [50/225], Training Accuracy: 53.0000%, Training Loss: 0.9641%\n",
      "Epoch [14/300], Step [51/225], Training Accuracy: 53.0637%, Training Loss: 0.9613%\n",
      "Epoch [14/300], Step [52/225], Training Accuracy: 53.0349%, Training Loss: 0.9597%\n",
      "Epoch [14/300], Step [53/225], Training Accuracy: 53.0366%, Training Loss: 0.9624%\n",
      "Epoch [14/300], Step [54/225], Training Accuracy: 52.9514%, Training Loss: 0.9636%\n",
      "Epoch [14/300], Step [55/225], Training Accuracy: 52.7841%, Training Loss: 0.9647%\n",
      "Epoch [14/300], Step [56/225], Training Accuracy: 52.7344%, Training Loss: 0.9645%\n",
      "Epoch [14/300], Step [57/225], Training Accuracy: 52.7686%, Training Loss: 0.9631%\n",
      "Epoch [14/300], Step [58/225], Training Accuracy: 52.9903%, Training Loss: 0.9627%\n",
      "Epoch [14/300], Step [59/225], Training Accuracy: 52.9396%, Training Loss: 0.9636%\n",
      "Epoch [14/300], Step [60/225], Training Accuracy: 52.8906%, Training Loss: 0.9643%\n",
      "Epoch [14/300], Step [61/225], Training Accuracy: 52.9201%, Training Loss: 0.9637%\n",
      "Epoch [14/300], Step [62/225], Training Accuracy: 52.9990%, Training Loss: 0.9641%\n",
      "Epoch [14/300], Step [63/225], Training Accuracy: 53.0258%, Training Loss: 0.9647%\n",
      "Epoch [14/300], Step [64/225], Training Accuracy: 52.9297%, Training Loss: 0.9671%\n",
      "Epoch [14/300], Step [65/225], Training Accuracy: 52.8846%, Training Loss: 0.9686%\n",
      "Epoch [14/300], Step [66/225], Training Accuracy: 52.9830%, Training Loss: 0.9669%\n",
      "Epoch [14/300], Step [67/225], Training Accuracy: 52.9618%, Training Loss: 0.9664%\n",
      "Epoch [14/300], Step [68/225], Training Accuracy: 53.0101%, Training Loss: 0.9661%\n",
      "Epoch [14/300], Step [69/225], Training Accuracy: 52.9438%, Training Loss: 0.9655%\n",
      "Epoch [14/300], Step [70/225], Training Accuracy: 52.9241%, Training Loss: 0.9668%\n",
      "Epoch [14/300], Step [71/225], Training Accuracy: 52.9489%, Training Loss: 0.9656%\n",
      "Epoch [14/300], Step [72/225], Training Accuracy: 52.8646%, Training Loss: 0.9683%\n",
      "Epoch [14/300], Step [73/225], Training Accuracy: 52.9538%, Training Loss: 0.9679%\n",
      "Epoch [14/300], Step [74/225], Training Accuracy: 53.1039%, Training Loss: 0.9652%\n",
      "Epoch [14/300], Step [75/225], Training Accuracy: 53.0208%, Training Loss: 0.9655%\n",
      "Epoch [14/300], Step [76/225], Training Accuracy: 53.0222%, Training Loss: 0.9660%\n",
      "Epoch [14/300], Step [77/225], Training Accuracy: 53.1047%, Training Loss: 0.9659%\n",
      "Epoch [14/300], Step [78/225], Training Accuracy: 53.0849%, Training Loss: 0.9664%\n",
      "Epoch [14/300], Step [79/225], Training Accuracy: 53.0063%, Training Loss: 0.9671%\n",
      "Epoch [14/300], Step [80/225], Training Accuracy: 52.9297%, Training Loss: 0.9677%\n",
      "Epoch [14/300], Step [81/225], Training Accuracy: 52.8742%, Training Loss: 0.9684%\n",
      "Epoch [14/300], Step [82/225], Training Accuracy: 52.9535%, Training Loss: 0.9694%\n",
      "Epoch [14/300], Step [83/225], Training Accuracy: 52.9932%, Training Loss: 0.9697%\n",
      "Epoch [14/300], Step [84/225], Training Accuracy: 53.0506%, Training Loss: 0.9690%\n",
      "Epoch [14/300], Step [85/225], Training Accuracy: 53.0882%, Training Loss: 0.9676%\n",
      "Epoch [14/300], Step [86/225], Training Accuracy: 53.0887%, Training Loss: 0.9670%\n",
      "Epoch [14/300], Step [87/225], Training Accuracy: 53.1250%, Training Loss: 0.9681%\n",
      "Epoch [14/300], Step [88/225], Training Accuracy: 52.9830%, Training Loss: 0.9686%\n",
      "Epoch [14/300], Step [89/225], Training Accuracy: 52.9319%, Training Loss: 0.9699%\n",
      "Epoch [14/300], Step [90/225], Training Accuracy: 52.8125%, Training Loss: 0.9712%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/300], Step [91/225], Training Accuracy: 52.8503%, Training Loss: 0.9707%\n",
      "Epoch [14/300], Step [92/225], Training Accuracy: 52.7683%, Training Loss: 0.9720%\n",
      "Epoch [14/300], Step [93/225], Training Accuracy: 52.8898%, Training Loss: 0.9708%\n",
      "Epoch [14/300], Step [94/225], Training Accuracy: 52.9089%, Training Loss: 0.9698%\n",
      "Epoch [14/300], Step [95/225], Training Accuracy: 52.9605%, Training Loss: 0.9698%\n",
      "Epoch [14/300], Step [96/225], Training Accuracy: 53.1087%, Training Loss: 0.9679%\n",
      "Epoch [14/300], Step [97/225], Training Accuracy: 53.1894%, Training Loss: 0.9665%\n",
      "Epoch [14/300], Step [98/225], Training Accuracy: 53.1888%, Training Loss: 0.9657%\n",
      "Epoch [14/300], Step [99/225], Training Accuracy: 53.2039%, Training Loss: 0.9660%\n",
      "Epoch [14/300], Step [100/225], Training Accuracy: 53.1719%, Training Loss: 0.9667%\n",
      "Epoch [14/300], Step [101/225], Training Accuracy: 53.1869%, Training Loss: 0.9661%\n",
      "Epoch [14/300], Step [102/225], Training Accuracy: 53.2016%, Training Loss: 0.9662%\n",
      "Epoch [14/300], Step [103/225], Training Accuracy: 53.2615%, Training Loss: 0.9652%\n",
      "Epoch [14/300], Step [104/225], Training Accuracy: 53.2452%, Training Loss: 0.9658%\n",
      "Epoch [14/300], Step [105/225], Training Accuracy: 53.3482%, Training Loss: 0.9646%\n",
      "Epoch [14/300], Step [106/225], Training Accuracy: 53.2724%, Training Loss: 0.9643%\n",
      "Epoch [14/300], Step [107/225], Training Accuracy: 53.1834%, Training Loss: 0.9650%\n",
      "Epoch [14/300], Step [108/225], Training Accuracy: 53.0961%, Training Loss: 0.9657%\n",
      "Epoch [14/300], Step [109/225], Training Accuracy: 53.1250%, Training Loss: 0.9648%\n",
      "Epoch [14/300], Step [110/225], Training Accuracy: 53.1392%, Training Loss: 0.9641%\n",
      "Epoch [14/300], Step [111/225], Training Accuracy: 53.2235%, Training Loss: 0.9631%\n",
      "Epoch [14/300], Step [112/225], Training Accuracy: 53.2785%, Training Loss: 0.9623%\n",
      "Epoch [14/300], Step [113/225], Training Accuracy: 53.2909%, Training Loss: 0.9620%\n",
      "Epoch [14/300], Step [114/225], Training Accuracy: 53.3306%, Training Loss: 0.9609%\n",
      "Epoch [14/300], Step [115/225], Training Accuracy: 53.3560%, Training Loss: 0.9595%\n",
      "Epoch [14/300], Step [116/225], Training Accuracy: 53.3270%, Training Loss: 0.9605%\n",
      "Epoch [14/300], Step [117/225], Training Accuracy: 53.3387%, Training Loss: 0.9611%\n",
      "Epoch [14/300], Step [118/225], Training Accuracy: 53.3898%, Training Loss: 0.9603%\n",
      "Epoch [14/300], Step [119/225], Training Accuracy: 53.3876%, Training Loss: 0.9602%\n",
      "Epoch [14/300], Step [120/225], Training Accuracy: 53.4115%, Training Loss: 0.9602%\n",
      "Epoch [14/300], Step [121/225], Training Accuracy: 53.3316%, Training Loss: 0.9617%\n",
      "Epoch [14/300], Step [122/225], Training Accuracy: 53.4324%, Training Loss: 0.9610%\n",
      "Epoch [14/300], Step [123/225], Training Accuracy: 53.4680%, Training Loss: 0.9599%\n",
      "Epoch [14/300], Step [124/225], Training Accuracy: 53.4652%, Training Loss: 0.9587%\n",
      "Epoch [14/300], Step [125/225], Training Accuracy: 53.4500%, Training Loss: 0.9598%\n",
      "Epoch [14/300], Step [126/225], Training Accuracy: 53.3482%, Training Loss: 0.9602%\n",
      "Epoch [14/300], Step [127/225], Training Accuracy: 53.2972%, Training Loss: 0.9615%\n",
      "Epoch [14/300], Step [128/225], Training Accuracy: 53.2471%, Training Loss: 0.9621%\n",
      "Epoch [14/300], Step [129/225], Training Accuracy: 53.2219%, Training Loss: 0.9623%\n",
      "Epoch [14/300], Step [130/225], Training Accuracy: 53.1370%, Training Loss: 0.9635%\n",
      "Epoch [14/300], Step [131/225], Training Accuracy: 53.1369%, Training Loss: 0.9634%\n",
      "Epoch [14/300], Step [132/225], Training Accuracy: 53.1487%, Training Loss: 0.9637%\n",
      "Epoch [14/300], Step [133/225], Training Accuracy: 53.1250%, Training Loss: 0.9643%\n",
      "Epoch [14/300], Step [134/225], Training Accuracy: 53.0434%, Training Loss: 0.9659%\n",
      "Epoch [14/300], Step [135/225], Training Accuracy: 53.0093%, Training Loss: 0.9656%\n",
      "Epoch [14/300], Step [136/225], Training Accuracy: 53.0216%, Training Loss: 0.9651%\n",
      "Epoch [14/300], Step [137/225], Training Accuracy: 52.9995%, Training Loss: 0.9655%\n",
      "Epoch [14/300], Step [138/225], Training Accuracy: 53.0797%, Training Loss: 0.9646%\n",
      "Epoch [14/300], Step [139/225], Training Accuracy: 53.0688%, Training Loss: 0.9642%\n",
      "Epoch [14/300], Step [140/225], Training Accuracy: 53.1473%, Training Loss: 0.9638%\n",
      "Epoch [14/300], Step [141/225], Training Accuracy: 53.2247%, Training Loss: 0.9626%\n",
      "Epoch [14/300], Step [142/225], Training Accuracy: 53.2240%, Training Loss: 0.9620%\n",
      "Epoch [14/300], Step [143/225], Training Accuracy: 53.2452%, Training Loss: 0.9619%\n",
      "Epoch [14/300], Step [144/225], Training Accuracy: 53.1901%, Training Loss: 0.9617%\n",
      "Epoch [14/300], Step [145/225], Training Accuracy: 53.2328%, Training Loss: 0.9608%\n",
      "Epoch [14/300], Step [146/225], Training Accuracy: 53.1464%, Training Loss: 0.9613%\n",
      "Epoch [14/300], Step [147/225], Training Accuracy: 53.1569%, Training Loss: 0.9608%\n",
      "Epoch [14/300], Step [148/225], Training Accuracy: 53.2200%, Training Loss: 0.9603%\n",
      "Epoch [14/300], Step [149/225], Training Accuracy: 53.2089%, Training Loss: 0.9602%\n",
      "Epoch [14/300], Step [150/225], Training Accuracy: 53.1771%, Training Loss: 0.9607%\n",
      "Epoch [14/300], Step [151/225], Training Accuracy: 53.1974%, Training Loss: 0.9605%\n",
      "Epoch [14/300], Step [152/225], Training Accuracy: 53.1764%, Training Loss: 0.9607%\n",
      "Epoch [14/300], Step [153/225], Training Accuracy: 53.1454%, Training Loss: 0.9602%\n",
      "Epoch [14/300], Step [154/225], Training Accuracy: 53.1250%, Training Loss: 0.9605%\n",
      "Epoch [14/300], Step [155/225], Training Accuracy: 53.0444%, Training Loss: 0.9612%\n",
      "Epoch [14/300], Step [156/225], Training Accuracy: 53.0048%, Training Loss: 0.9621%\n",
      "Epoch [14/300], Step [157/225], Training Accuracy: 53.0354%, Training Loss: 0.9621%\n",
      "Epoch [14/300], Step [158/225], Training Accuracy: 53.0063%, Training Loss: 0.9626%\n",
      "Epoch [14/300], Step [159/225], Training Accuracy: 52.9579%, Training Loss: 0.9626%\n",
      "Epoch [14/300], Step [160/225], Training Accuracy: 52.9785%, Training Loss: 0.9625%\n",
      "Epoch [14/300], Step [161/225], Training Accuracy: 53.0280%, Training Loss: 0.9626%\n",
      "Epoch [14/300], Step [162/225], Training Accuracy: 53.0671%, Training Loss: 0.9635%\n",
      "Epoch [14/300], Step [163/225], Training Accuracy: 53.0579%, Training Loss: 0.9637%\n",
      "Epoch [14/300], Step [164/225], Training Accuracy: 53.1536%, Training Loss: 0.9627%\n",
      "Epoch [14/300], Step [165/225], Training Accuracy: 53.1345%, Training Loss: 0.9633%\n",
      "Epoch [14/300], Step [166/225], Training Accuracy: 53.1344%, Training Loss: 0.9635%\n",
      "Epoch [14/300], Step [167/225], Training Accuracy: 53.1437%, Training Loss: 0.9632%\n",
      "Epoch [14/300], Step [168/225], Training Accuracy: 53.1157%, Training Loss: 0.9629%\n",
      "Epoch [14/300], Step [169/225], Training Accuracy: 53.1620%, Training Loss: 0.9624%\n",
      "Epoch [14/300], Step [170/225], Training Accuracy: 53.1618%, Training Loss: 0.9621%\n",
      "Epoch [14/300], Step [171/225], Training Accuracy: 53.2164%, Training Loss: 0.9614%\n",
      "Epoch [14/300], Step [172/225], Training Accuracy: 53.1795%, Training Loss: 0.9614%\n",
      "Epoch [14/300], Step [173/225], Training Accuracy: 53.1702%, Training Loss: 0.9614%\n",
      "Epoch [14/300], Step [174/225], Training Accuracy: 53.1519%, Training Loss: 0.9619%\n",
      "Epoch [14/300], Step [175/225], Training Accuracy: 53.1607%, Training Loss: 0.9619%\n",
      "Epoch [14/300], Step [176/225], Training Accuracy: 53.1605%, Training Loss: 0.9619%\n",
      "Epoch [14/300], Step [177/225], Training Accuracy: 53.2133%, Training Loss: 0.9616%\n",
      "Epoch [14/300], Step [178/225], Training Accuracy: 53.1601%, Training Loss: 0.9624%\n",
      "Epoch [14/300], Step [179/225], Training Accuracy: 53.2036%, Training Loss: 0.9618%\n",
      "Epoch [14/300], Step [180/225], Training Accuracy: 53.2899%, Training Loss: 0.9605%\n",
      "Epoch [14/300], Step [181/225], Training Accuracy: 53.2631%, Training Loss: 0.9613%\n",
      "Epoch [14/300], Step [182/225], Training Accuracy: 53.2881%, Training Loss: 0.9609%\n",
      "Epoch [14/300], Step [183/225], Training Accuracy: 53.2787%, Training Loss: 0.9606%\n",
      "Epoch [14/300], Step [184/225], Training Accuracy: 53.2863%, Training Loss: 0.9605%\n",
      "Epoch [14/300], Step [185/225], Training Accuracy: 53.3108%, Training Loss: 0.9605%\n",
      "Epoch [14/300], Step [186/225], Training Accuracy: 53.3602%, Training Loss: 0.9595%\n",
      "Epoch [14/300], Step [187/225], Training Accuracy: 53.4174%, Training Loss: 0.9585%\n",
      "Epoch [14/300], Step [188/225], Training Accuracy: 53.4325%, Training Loss: 0.9584%\n",
      "Epoch [14/300], Step [189/225], Training Accuracy: 53.4640%, Training Loss: 0.9576%\n",
      "Epoch [14/300], Step [190/225], Training Accuracy: 53.4293%, Training Loss: 0.9588%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/300], Step [191/225], Training Accuracy: 53.3950%, Training Loss: 0.9586%\n",
      "Epoch [14/300], Step [192/225], Training Accuracy: 53.4017%, Training Loss: 0.9583%\n",
      "Epoch [14/300], Step [193/225], Training Accuracy: 53.4245%, Training Loss: 0.9580%\n",
      "Epoch [14/300], Step [194/225], Training Accuracy: 53.3827%, Training Loss: 0.9580%\n",
      "Epoch [14/300], Step [195/225], Training Accuracy: 53.4054%, Training Loss: 0.9574%\n",
      "Epoch [14/300], Step [196/225], Training Accuracy: 53.4200%, Training Loss: 0.9574%\n",
      "Epoch [14/300], Step [197/225], Training Accuracy: 53.4264%, Training Loss: 0.9572%\n",
      "Epoch [14/300], Step [198/225], Training Accuracy: 53.4643%, Training Loss: 0.9561%\n",
      "Epoch [14/300], Step [199/225], Training Accuracy: 53.4862%, Training Loss: 0.9555%\n",
      "Epoch [14/300], Step [200/225], Training Accuracy: 53.5312%, Training Loss: 0.9551%\n",
      "Epoch [14/300], Step [201/225], Training Accuracy: 53.4904%, Training Loss: 0.9555%\n",
      "Epoch [14/300], Step [202/225], Training Accuracy: 53.5118%, Training Loss: 0.9560%\n",
      "Epoch [14/300], Step [203/225], Training Accuracy: 53.5560%, Training Loss: 0.9558%\n",
      "Epoch [14/300], Step [204/225], Training Accuracy: 53.5692%, Training Loss: 0.9558%\n",
      "Epoch [14/300], Step [205/225], Training Accuracy: 53.5899%, Training Loss: 0.9552%\n",
      "Epoch [14/300], Step [206/225], Training Accuracy: 53.5953%, Training Loss: 0.9556%\n",
      "Epoch [14/300], Step [207/225], Training Accuracy: 53.5854%, Training Loss: 0.9558%\n",
      "Epoch [14/300], Step [208/225], Training Accuracy: 53.6208%, Training Loss: 0.9553%\n",
      "Epoch [14/300], Step [209/225], Training Accuracy: 53.6184%, Training Loss: 0.9562%\n",
      "Epoch [14/300], Step [210/225], Training Accuracy: 53.6310%, Training Loss: 0.9563%\n",
      "Epoch [14/300], Step [211/225], Training Accuracy: 53.6211%, Training Loss: 0.9563%\n",
      "Epoch [14/300], Step [212/225], Training Accuracy: 53.5525%, Training Loss: 0.9567%\n",
      "Epoch [14/300], Step [213/225], Training Accuracy: 53.5138%, Training Loss: 0.9580%\n",
      "Epoch [14/300], Step [214/225], Training Accuracy: 53.4974%, Training Loss: 0.9576%\n",
      "Epoch [14/300], Step [215/225], Training Accuracy: 53.4884%, Training Loss: 0.9577%\n",
      "Epoch [14/300], Step [216/225], Training Accuracy: 53.5156%, Training Loss: 0.9580%\n",
      "Epoch [14/300], Step [217/225], Training Accuracy: 53.4922%, Training Loss: 0.9580%\n",
      "Epoch [14/300], Step [218/225], Training Accuracy: 53.4977%, Training Loss: 0.9580%\n",
      "Epoch [14/300], Step [219/225], Training Accuracy: 53.4603%, Training Loss: 0.9578%\n",
      "Epoch [14/300], Step [220/225], Training Accuracy: 53.4801%, Training Loss: 0.9577%\n",
      "Epoch [14/300], Step [221/225], Training Accuracy: 53.4219%, Training Loss: 0.9582%\n",
      "Epoch [14/300], Step [222/225], Training Accuracy: 53.4136%, Training Loss: 0.9580%\n",
      "Epoch [14/300], Step [223/225], Training Accuracy: 53.3913%, Training Loss: 0.9582%\n",
      "Epoch [14/300], Step [224/225], Training Accuracy: 53.3691%, Training Loss: 0.9580%\n",
      "Epoch [14/300], Step [225/225], Training Accuracy: 53.3421%, Training Loss: 0.9584%\n",
      "Epoch [15/300], Step [1/225], Training Accuracy: 70.3125%, Training Loss: 0.8061%\n",
      "Epoch [15/300], Step [2/225], Training Accuracy: 60.9375%, Training Loss: 0.8830%\n",
      "Epoch [15/300], Step [3/225], Training Accuracy: 59.3750%, Training Loss: 0.9176%\n",
      "Epoch [15/300], Step [4/225], Training Accuracy: 57.8125%, Training Loss: 0.9261%\n",
      "Epoch [15/300], Step [5/225], Training Accuracy: 58.7500%, Training Loss: 0.9200%\n",
      "Epoch [15/300], Step [6/225], Training Accuracy: 58.3333%, Training Loss: 0.9226%\n",
      "Epoch [15/300], Step [7/225], Training Accuracy: 57.3661%, Training Loss: 0.9375%\n",
      "Epoch [15/300], Step [8/225], Training Accuracy: 55.8594%, Training Loss: 0.9450%\n",
      "Epoch [15/300], Step [9/225], Training Accuracy: 56.0764%, Training Loss: 0.9362%\n",
      "Epoch [15/300], Step [10/225], Training Accuracy: 54.6875%, Training Loss: 0.9502%\n",
      "Epoch [15/300], Step [11/225], Training Accuracy: 54.5455%, Training Loss: 0.9521%\n",
      "Epoch [15/300], Step [12/225], Training Accuracy: 55.0781%, Training Loss: 0.9409%\n",
      "Epoch [15/300], Step [13/225], Training Accuracy: 55.8894%, Training Loss: 0.9293%\n",
      "Epoch [15/300], Step [14/225], Training Accuracy: 55.6920%, Training Loss: 0.9303%\n",
      "Epoch [15/300], Step [15/225], Training Accuracy: 54.8958%, Training Loss: 0.9372%\n",
      "Epoch [15/300], Step [16/225], Training Accuracy: 54.8828%, Training Loss: 0.9336%\n",
      "Epoch [15/300], Step [17/225], Training Accuracy: 55.2390%, Training Loss: 0.9295%\n",
      "Epoch [15/300], Step [18/225], Training Accuracy: 54.6007%, Training Loss: 0.9335%\n",
      "Epoch [15/300], Step [19/225], Training Accuracy: 54.9342%, Training Loss: 0.9314%\n",
      "Epoch [15/300], Step [20/225], Training Accuracy: 55.1562%, Training Loss: 0.9268%\n",
      "Epoch [15/300], Step [21/225], Training Accuracy: 55.3571%, Training Loss: 0.9226%\n",
      "Epoch [15/300], Step [22/225], Training Accuracy: 54.7585%, Training Loss: 0.9290%\n",
      "Epoch [15/300], Step [23/225], Training Accuracy: 54.8234%, Training Loss: 0.9292%\n",
      "Epoch [15/300], Step [24/225], Training Accuracy: 54.6875%, Training Loss: 0.9337%\n",
      "Epoch [15/300], Step [25/225], Training Accuracy: 55.1250%, Training Loss: 0.9281%\n",
      "Epoch [15/300], Step [26/225], Training Accuracy: 54.9880%, Training Loss: 0.9265%\n",
      "Epoch [15/300], Step [27/225], Training Accuracy: 54.6875%, Training Loss: 0.9339%\n",
      "Epoch [15/300], Step [28/225], Training Accuracy: 54.6875%, Training Loss: 0.9295%\n",
      "Epoch [15/300], Step [29/225], Training Accuracy: 54.3642%, Training Loss: 0.9279%\n",
      "Epoch [15/300], Step [30/225], Training Accuracy: 54.3750%, Training Loss: 0.9277%\n",
      "Epoch [15/300], Step [31/225], Training Accuracy: 54.6875%, Training Loss: 0.9271%\n",
      "Epoch [15/300], Step [32/225], Training Accuracy: 54.6875%, Training Loss: 0.9253%\n",
      "Epoch [15/300], Step [33/225], Training Accuracy: 54.7348%, Training Loss: 0.9260%\n",
      "Epoch [15/300], Step [34/225], Training Accuracy: 54.5037%, Training Loss: 0.9305%\n",
      "Epoch [15/300], Step [35/225], Training Accuracy: 54.3304%, Training Loss: 0.9332%\n",
      "Epoch [15/300], Step [36/225], Training Accuracy: 54.2969%, Training Loss: 0.9331%\n",
      "Epoch [15/300], Step [37/225], Training Accuracy: 54.3919%, Training Loss: 0.9290%\n",
      "Epoch [15/300], Step [38/225], Training Accuracy: 54.4408%, Training Loss: 0.9294%\n",
      "Epoch [15/300], Step [39/225], Training Accuracy: 54.4071%, Training Loss: 0.9313%\n",
      "Epoch [15/300], Step [40/225], Training Accuracy: 54.2578%, Training Loss: 0.9336%\n",
      "Epoch [15/300], Step [41/225], Training Accuracy: 53.8872%, Training Loss: 0.9363%\n",
      "Epoch [15/300], Step [42/225], Training Accuracy: 53.9807%, Training Loss: 0.9357%\n",
      "Epoch [15/300], Step [43/225], Training Accuracy: 54.1424%, Training Loss: 0.9343%\n",
      "Epoch [15/300], Step [44/225], Training Accuracy: 54.2969%, Training Loss: 0.9317%\n",
      "Epoch [15/300], Step [45/225], Training Accuracy: 54.3403%, Training Loss: 0.9301%\n",
      "Epoch [15/300], Step [46/225], Training Accuracy: 54.4497%, Training Loss: 0.9273%\n",
      "Epoch [15/300], Step [47/225], Training Accuracy: 54.3218%, Training Loss: 0.9288%\n",
      "Epoch [15/300], Step [48/225], Training Accuracy: 54.1992%, Training Loss: 0.9300%\n",
      "Epoch [15/300], Step [49/225], Training Accuracy: 54.1773%, Training Loss: 0.9296%\n",
      "Epoch [15/300], Step [50/225], Training Accuracy: 54.1875%, Training Loss: 0.9285%\n",
      "Epoch [15/300], Step [51/225], Training Accuracy: 54.2279%, Training Loss: 0.9268%\n",
      "Epoch [15/300], Step [52/225], Training Accuracy: 54.2969%, Training Loss: 0.9244%\n",
      "Epoch [15/300], Step [53/225], Training Accuracy: 54.2748%, Training Loss: 0.9258%\n",
      "Epoch [15/300], Step [54/225], Training Accuracy: 54.1377%, Training Loss: 0.9273%\n",
      "Epoch [15/300], Step [55/225], Training Accuracy: 53.9489%, Training Loss: 0.9286%\n",
      "Epoch [15/300], Step [56/225], Training Accuracy: 53.7388%, Training Loss: 0.9300%\n",
      "Epoch [15/300], Step [57/225], Training Accuracy: 53.7555%, Training Loss: 0.9286%\n",
      "Epoch [15/300], Step [58/225], Training Accuracy: 53.9062%, Training Loss: 0.9278%\n",
      "Epoch [15/300], Step [59/225], Training Accuracy: 54.0784%, Training Loss: 0.9255%\n",
      "Epoch [15/300], Step [60/225], Training Accuracy: 54.1146%, Training Loss: 0.9251%\n",
      "Epoch [15/300], Step [61/225], Training Accuracy: 53.9959%, Training Loss: 0.9254%\n",
      "Epoch [15/300], Step [62/225], Training Accuracy: 54.1331%, Training Loss: 0.9241%\n",
      "Epoch [15/300], Step [63/225], Training Accuracy: 54.0675%, Training Loss: 0.9256%\n",
      "Epoch [15/300], Step [64/225], Training Accuracy: 53.9795%, Training Loss: 0.9293%\n",
      "Epoch [15/300], Step [65/225], Training Accuracy: 53.9663%, Training Loss: 0.9304%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/300], Step [66/225], Training Accuracy: 54.0720%, Training Loss: 0.9282%\n",
      "Epoch [15/300], Step [67/225], Training Accuracy: 54.1278%, Training Loss: 0.9278%\n",
      "Epoch [15/300], Step [68/225], Training Accuracy: 54.2279%, Training Loss: 0.9278%\n",
      "Epoch [15/300], Step [69/225], Training Accuracy: 54.1440%, Training Loss: 0.9282%\n",
      "Epoch [15/300], Step [70/225], Training Accuracy: 54.1295%, Training Loss: 0.9281%\n",
      "Epoch [15/300], Step [71/225], Training Accuracy: 54.2474%, Training Loss: 0.9290%\n",
      "Epoch [15/300], Step [72/225], Training Accuracy: 54.2535%, Training Loss: 0.9301%\n",
      "Epoch [15/300], Step [73/225], Training Accuracy: 54.1952%, Training Loss: 0.9316%\n",
      "Epoch [15/300], Step [74/225], Training Accuracy: 54.2019%, Training Loss: 0.9304%\n",
      "Epoch [15/300], Step [75/225], Training Accuracy: 54.1250%, Training Loss: 0.9313%\n",
      "Epoch [15/300], Step [76/225], Training Accuracy: 54.0913%, Training Loss: 0.9313%\n",
      "Epoch [15/300], Step [77/225], Training Accuracy: 54.0990%, Training Loss: 0.9311%\n",
      "Epoch [15/300], Step [78/225], Training Accuracy: 54.1667%, Training Loss: 0.9302%\n",
      "Epoch [15/300], Step [79/225], Training Accuracy: 54.0744%, Training Loss: 0.9309%\n",
      "Epoch [15/300], Step [80/225], Training Accuracy: 53.9453%, Training Loss: 0.9314%\n",
      "Epoch [15/300], Step [81/225], Training Accuracy: 53.9352%, Training Loss: 0.9324%\n",
      "Epoch [15/300], Step [82/225], Training Accuracy: 53.9253%, Training Loss: 0.9332%\n",
      "Epoch [15/300], Step [83/225], Training Accuracy: 53.9533%, Training Loss: 0.9338%\n",
      "Epoch [15/300], Step [84/225], Training Accuracy: 53.9993%, Training Loss: 0.9329%\n",
      "Epoch [15/300], Step [85/225], Training Accuracy: 54.0993%, Training Loss: 0.9323%\n",
      "Epoch [15/300], Step [86/225], Training Accuracy: 54.1424%, Training Loss: 0.9329%\n",
      "Epoch [15/300], Step [87/225], Training Accuracy: 54.1307%, Training Loss: 0.9339%\n",
      "Epoch [15/300], Step [88/225], Training Accuracy: 54.0128%, Training Loss: 0.9347%\n",
      "Epoch [15/300], Step [89/225], Training Accuracy: 54.0028%, Training Loss: 0.9360%\n",
      "Epoch [15/300], Step [90/225], Training Accuracy: 53.9062%, Training Loss: 0.9377%\n",
      "Epoch [15/300], Step [91/225], Training Accuracy: 53.8633%, Training Loss: 0.9378%\n",
      "Epoch [15/300], Step [92/225], Training Accuracy: 53.8383%, Training Loss: 0.9391%\n",
      "Epoch [15/300], Step [93/225], Training Accuracy: 53.9315%, Training Loss: 0.9384%\n",
      "Epoch [15/300], Step [94/225], Training Accuracy: 53.9894%, Training Loss: 0.9378%\n",
      "Epoch [15/300], Step [95/225], Training Accuracy: 53.9803%, Training Loss: 0.9391%\n",
      "Epoch [15/300], Step [96/225], Training Accuracy: 54.0690%, Training Loss: 0.9384%\n",
      "Epoch [15/300], Step [97/225], Training Accuracy: 54.0915%, Training Loss: 0.9377%\n",
      "Epoch [15/300], Step [98/225], Training Accuracy: 53.9860%, Training Loss: 0.9380%\n",
      "Epoch [15/300], Step [99/225], Training Accuracy: 53.9457%, Training Loss: 0.9389%\n",
      "Epoch [15/300], Step [100/225], Training Accuracy: 53.9062%, Training Loss: 0.9392%\n",
      "Epoch [15/300], Step [101/225], Training Accuracy: 53.9604%, Training Loss: 0.9386%\n",
      "Epoch [15/300], Step [102/225], Training Accuracy: 53.9062%, Training Loss: 0.9397%\n",
      "Epoch [15/300], Step [103/225], Training Accuracy: 53.9897%, Training Loss: 0.9388%\n",
      "Epoch [15/300], Step [104/225], Training Accuracy: 54.0715%, Training Loss: 0.9385%\n",
      "Epoch [15/300], Step [105/225], Training Accuracy: 54.1071%, Training Loss: 0.9376%\n",
      "Epoch [15/300], Step [106/225], Training Accuracy: 54.1421%, Training Loss: 0.9373%\n",
      "Epoch [15/300], Step [107/225], Training Accuracy: 54.1180%, Training Loss: 0.9385%\n",
      "Epoch [15/300], Step [108/225], Training Accuracy: 54.0654%, Training Loss: 0.9399%\n",
      "Epoch [15/300], Step [109/225], Training Accuracy: 54.1141%, Training Loss: 0.9388%\n",
      "Epoch [15/300], Step [110/225], Training Accuracy: 54.1335%, Training Loss: 0.9385%\n",
      "Epoch [15/300], Step [111/225], Training Accuracy: 54.2089%, Training Loss: 0.9379%\n",
      "Epoch [15/300], Step [112/225], Training Accuracy: 54.2411%, Training Loss: 0.9374%\n",
      "Epoch [15/300], Step [113/225], Training Accuracy: 54.2312%, Training Loss: 0.9369%\n",
      "Epoch [15/300], Step [114/225], Training Accuracy: 54.2763%, Training Loss: 0.9360%\n",
      "Epoch [15/300], Step [115/225], Training Accuracy: 54.3207%, Training Loss: 0.9345%\n",
      "Epoch [15/300], Step [116/225], Training Accuracy: 54.2295%, Training Loss: 0.9348%\n",
      "Epoch [15/300], Step [117/225], Training Accuracy: 54.2067%, Training Loss: 0.9358%\n",
      "Epoch [15/300], Step [118/225], Training Accuracy: 54.2240%, Training Loss: 0.9345%\n",
      "Epoch [15/300], Step [119/225], Training Accuracy: 54.2542%, Training Loss: 0.9339%\n",
      "Epoch [15/300], Step [120/225], Training Accuracy: 54.2839%, Training Loss: 0.9339%\n",
      "Epoch [15/300], Step [121/225], Training Accuracy: 54.2097%, Training Loss: 0.9349%\n",
      "Epoch [15/300], Step [122/225], Training Accuracy: 54.2392%, Training Loss: 0.9342%\n",
      "Epoch [15/300], Step [123/225], Training Accuracy: 54.1921%, Training Loss: 0.9338%\n",
      "Epoch [15/300], Step [124/225], Training Accuracy: 54.1961%, Training Loss: 0.9332%\n",
      "Epoch [15/300], Step [125/225], Training Accuracy: 54.2000%, Training Loss: 0.9352%\n",
      "Epoch [15/300], Step [126/225], Training Accuracy: 54.2039%, Training Loss: 0.9360%\n",
      "Epoch [15/300], Step [127/225], Training Accuracy: 54.1093%, Training Loss: 0.9365%\n",
      "Epoch [15/300], Step [128/225], Training Accuracy: 54.0527%, Training Loss: 0.9370%\n",
      "Epoch [15/300], Step [129/225], Training Accuracy: 54.0455%, Training Loss: 0.9370%\n",
      "Epoch [15/300], Step [130/225], Training Accuracy: 54.0024%, Training Loss: 0.9378%\n",
      "Epoch [15/300], Step [131/225], Training Accuracy: 53.9361%, Training Loss: 0.9382%\n",
      "Epoch [15/300], Step [132/225], Training Accuracy: 53.9418%, Training Loss: 0.9380%\n",
      "Epoch [15/300], Step [133/225], Training Accuracy: 53.9239%, Training Loss: 0.9388%\n",
      "Epoch [15/300], Step [134/225], Training Accuracy: 53.7663%, Training Loss: 0.9406%\n",
      "Epoch [15/300], Step [135/225], Training Accuracy: 53.8310%, Training Loss: 0.9400%\n",
      "Epoch [15/300], Step [136/225], Training Accuracy: 53.8833%, Training Loss: 0.9394%\n",
      "Epoch [15/300], Step [137/225], Training Accuracy: 53.8663%, Training Loss: 0.9395%\n",
      "Epoch [15/300], Step [138/225], Training Accuracy: 53.9742%, Training Loss: 0.9384%\n",
      "Epoch [15/300], Step [139/225], Training Accuracy: 53.9793%, Training Loss: 0.9381%\n",
      "Epoch [15/300], Step [140/225], Training Accuracy: 54.0179%, Training Loss: 0.9378%\n",
      "Epoch [15/300], Step [141/225], Training Accuracy: 54.0780%, Training Loss: 0.9372%\n",
      "Epoch [15/300], Step [142/225], Training Accuracy: 54.1593%, Training Loss: 0.9364%\n",
      "Epoch [15/300], Step [143/225], Training Accuracy: 54.1630%, Training Loss: 0.9363%\n",
      "Epoch [15/300], Step [144/225], Training Accuracy: 54.0907%, Training Loss: 0.9360%\n",
      "Epoch [15/300], Step [145/225], Training Accuracy: 54.1272%, Training Loss: 0.9349%\n",
      "Epoch [15/300], Step [146/225], Training Accuracy: 54.0668%, Training Loss: 0.9355%\n",
      "Epoch [15/300], Step [147/225], Training Accuracy: 54.0497%, Training Loss: 0.9354%\n",
      "Epoch [15/300], Step [148/225], Training Accuracy: 54.0435%, Training Loss: 0.9347%\n",
      "Epoch [15/300], Step [149/225], Training Accuracy: 54.0688%, Training Loss: 0.9346%\n",
      "Epoch [15/300], Step [150/225], Training Accuracy: 54.0938%, Training Loss: 0.9337%\n",
      "Epoch [15/300], Step [151/225], Training Accuracy: 54.1184%, Training Loss: 0.9334%\n",
      "Epoch [15/300], Step [152/225], Training Accuracy: 54.1324%, Training Loss: 0.9335%\n",
      "Epoch [15/300], Step [153/225], Training Accuracy: 54.1462%, Training Loss: 0.9329%\n",
      "Epoch [15/300], Step [154/225], Training Accuracy: 54.1295%, Training Loss: 0.9330%\n",
      "Epoch [15/300], Step [155/225], Training Accuracy: 54.0927%, Training Loss: 0.9337%\n",
      "Epoch [15/300], Step [156/225], Training Accuracy: 54.0565%, Training Loss: 0.9343%\n",
      "Epoch [15/300], Step [157/225], Training Accuracy: 54.1103%, Training Loss: 0.9331%\n",
      "Epoch [15/300], Step [158/225], Training Accuracy: 54.0051%, Training Loss: 0.9341%\n",
      "Epoch [15/300], Step [159/225], Training Accuracy: 53.9603%, Training Loss: 0.9340%\n",
      "Epoch [15/300], Step [160/225], Training Accuracy: 53.9844%, Training Loss: 0.9338%\n",
      "Epoch [15/300], Step [161/225], Training Accuracy: 54.0082%, Training Loss: 0.9339%\n",
      "Epoch [15/300], Step [162/225], Training Accuracy: 53.9931%, Training Loss: 0.9342%\n",
      "Epoch [15/300], Step [163/225], Training Accuracy: 54.0261%, Training Loss: 0.9339%\n",
      "Epoch [15/300], Step [164/225], Training Accuracy: 54.0492%, Training Loss: 0.9337%\n",
      "Epoch [15/300], Step [165/225], Training Accuracy: 54.0341%, Training Loss: 0.9339%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/300], Step [166/225], Training Accuracy: 54.0380%, Training Loss: 0.9334%\n",
      "Epoch [15/300], Step [167/225], Training Accuracy: 54.0606%, Training Loss: 0.9329%\n",
      "Epoch [15/300], Step [168/225], Training Accuracy: 54.0458%, Training Loss: 0.9329%\n",
      "Epoch [15/300], Step [169/225], Training Accuracy: 54.0865%, Training Loss: 0.9322%\n",
      "Epoch [15/300], Step [170/225], Training Accuracy: 54.0901%, Training Loss: 0.9323%\n",
      "Epoch [15/300], Step [171/225], Training Accuracy: 54.0844%, Training Loss: 0.9321%\n",
      "Epoch [15/300], Step [172/225], Training Accuracy: 54.0516%, Training Loss: 0.9326%\n",
      "Epoch [15/300], Step [173/225], Training Accuracy: 54.0462%, Training Loss: 0.9327%\n",
      "Epoch [15/300], Step [174/225], Training Accuracy: 54.0050%, Training Loss: 0.9333%\n",
      "Epoch [15/300], Step [175/225], Training Accuracy: 53.9911%, Training Loss: 0.9333%\n",
      "Epoch [15/300], Step [176/225], Training Accuracy: 53.9595%, Training Loss: 0.9335%\n",
      "Epoch [15/300], Step [177/225], Training Accuracy: 54.0078%, Training Loss: 0.9334%\n",
      "Epoch [15/300], Step [178/225], Training Accuracy: 53.9414%, Training Loss: 0.9343%\n",
      "Epoch [15/300], Step [179/225], Training Accuracy: 53.9892%, Training Loss: 0.9338%\n",
      "Epoch [15/300], Step [180/225], Training Accuracy: 54.0799%, Training Loss: 0.9325%\n",
      "Epoch [15/300], Step [181/225], Training Accuracy: 54.0142%, Training Loss: 0.9339%\n",
      "Epoch [15/300], Step [182/225], Training Accuracy: 54.0436%, Training Loss: 0.9340%\n",
      "Epoch [15/300], Step [183/225], Training Accuracy: 53.9959%, Training Loss: 0.9348%\n",
      "Epoch [15/300], Step [184/225], Training Accuracy: 53.9912%, Training Loss: 0.9348%\n",
      "Epoch [15/300], Step [185/225], Training Accuracy: 54.0372%, Training Loss: 0.9347%\n",
      "Epoch [15/300], Step [186/225], Training Accuracy: 54.0659%, Training Loss: 0.9339%\n",
      "Epoch [15/300], Step [187/225], Training Accuracy: 54.1193%, Training Loss: 0.9332%\n",
      "Epoch [15/300], Step [188/225], Training Accuracy: 54.1140%, Training Loss: 0.9337%\n",
      "Epoch [15/300], Step [189/225], Training Accuracy: 54.1336%, Training Loss: 0.9329%\n",
      "Epoch [15/300], Step [190/225], Training Accuracy: 54.1365%, Training Loss: 0.9330%\n",
      "Epoch [15/300], Step [191/225], Training Accuracy: 54.1230%, Training Loss: 0.9328%\n",
      "Epoch [15/300], Step [192/225], Training Accuracy: 54.1748%, Training Loss: 0.9322%\n",
      "Epoch [15/300], Step [193/225], Training Accuracy: 54.1370%, Training Loss: 0.9331%\n",
      "Epoch [15/300], Step [194/225], Training Accuracy: 54.0915%, Training Loss: 0.9336%\n",
      "Epoch [15/300], Step [195/225], Training Accuracy: 54.1026%, Training Loss: 0.9329%\n",
      "Epoch [15/300], Step [196/225], Training Accuracy: 54.1374%, Training Loss: 0.9330%\n",
      "Epoch [15/300], Step [197/225], Training Accuracy: 54.1323%, Training Loss: 0.9332%\n",
      "Epoch [15/300], Step [198/225], Training Accuracy: 54.1193%, Training Loss: 0.9329%\n",
      "Epoch [15/300], Step [199/225], Training Accuracy: 54.0672%, Training Loss: 0.9330%\n",
      "Epoch [15/300], Step [200/225], Training Accuracy: 54.1250%, Training Loss: 0.9325%\n",
      "Epoch [15/300], Step [201/225], Training Accuracy: 54.1278%, Training Loss: 0.9325%\n",
      "Epoch [15/300], Step [202/225], Training Accuracy: 54.1383%, Training Loss: 0.9323%\n",
      "Epoch [15/300], Step [203/225], Training Accuracy: 54.1333%, Training Loss: 0.9327%\n",
      "Epoch [15/300], Step [204/225], Training Accuracy: 54.1360%, Training Loss: 0.9329%\n",
      "Epoch [15/300], Step [205/225], Training Accuracy: 54.1159%, Training Loss: 0.9330%\n",
      "Epoch [15/300], Step [206/225], Training Accuracy: 54.1262%, Training Loss: 0.9329%\n",
      "Epoch [15/300], Step [207/225], Training Accuracy: 54.0987%, Training Loss: 0.9331%\n",
      "Epoch [15/300], Step [208/225], Training Accuracy: 54.1166%, Training Loss: 0.9324%\n",
      "Epoch [15/300], Step [209/225], Training Accuracy: 54.1343%, Training Loss: 0.9327%\n",
      "Epoch [15/300], Step [210/225], Training Accuracy: 54.1220%, Training Loss: 0.9327%\n",
      "Epoch [15/300], Step [211/225], Training Accuracy: 54.1321%, Training Loss: 0.9321%\n",
      "Epoch [15/300], Step [212/225], Training Accuracy: 54.1200%, Training Loss: 0.9325%\n",
      "Epoch [15/300], Step [213/225], Training Accuracy: 54.0713%, Training Loss: 0.9334%\n",
      "Epoch [15/300], Step [214/225], Training Accuracy: 54.0450%, Training Loss: 0.9331%\n",
      "Epoch [15/300], Step [215/225], Training Accuracy: 54.0552%, Training Loss: 0.9333%\n",
      "Epoch [15/300], Step [216/225], Training Accuracy: 54.0003%, Training Loss: 0.9340%\n",
      "Epoch [15/300], Step [217/225], Training Accuracy: 54.0035%, Training Loss: 0.9340%\n",
      "Epoch [15/300], Step [218/225], Training Accuracy: 53.9994%, Training Loss: 0.9341%\n",
      "Epoch [15/300], Step [219/225], Training Accuracy: 54.0097%, Training Loss: 0.9337%\n",
      "Epoch [15/300], Step [220/225], Training Accuracy: 54.0199%, Training Loss: 0.9332%\n",
      "Epoch [15/300], Step [221/225], Training Accuracy: 53.9593%, Training Loss: 0.9338%\n",
      "Epoch [15/300], Step [222/225], Training Accuracy: 53.9696%, Training Loss: 0.9336%\n",
      "Epoch [15/300], Step [223/225], Training Accuracy: 53.9518%, Training Loss: 0.9345%\n",
      "Epoch [15/300], Step [224/225], Training Accuracy: 53.9411%, Training Loss: 0.9340%\n",
      "Epoch [15/300], Step [225/225], Training Accuracy: 53.9049%, Training Loss: 0.9343%\n",
      "Epoch [16/300], Step [1/225], Training Accuracy: 76.5625%, Training Loss: 0.6728%\n",
      "Epoch [16/300], Step [2/225], Training Accuracy: 69.5312%, Training Loss: 0.7731%\n",
      "Epoch [16/300], Step [3/225], Training Accuracy: 65.6250%, Training Loss: 0.8473%\n",
      "Epoch [16/300], Step [4/225], Training Accuracy: 63.2812%, Training Loss: 0.8589%\n",
      "Epoch [16/300], Step [5/225], Training Accuracy: 64.6875%, Training Loss: 0.8505%\n",
      "Epoch [16/300], Step [6/225], Training Accuracy: 63.2812%, Training Loss: 0.8547%\n",
      "Epoch [16/300], Step [7/225], Training Accuracy: 61.8304%, Training Loss: 0.8686%\n",
      "Epoch [16/300], Step [8/225], Training Accuracy: 60.3516%, Training Loss: 0.8797%\n",
      "Epoch [16/300], Step [9/225], Training Accuracy: 59.0278%, Training Loss: 0.8937%\n",
      "Epoch [16/300], Step [10/225], Training Accuracy: 57.3438%, Training Loss: 0.9094%\n",
      "Epoch [16/300], Step [11/225], Training Accuracy: 57.5284%, Training Loss: 0.9151%\n",
      "Epoch [16/300], Step [12/225], Training Accuracy: 57.5521%, Training Loss: 0.9070%\n",
      "Epoch [16/300], Step [13/225], Training Accuracy: 58.2933%, Training Loss: 0.8917%\n",
      "Epoch [16/300], Step [14/225], Training Accuracy: 57.9241%, Training Loss: 0.9011%\n",
      "Epoch [16/300], Step [15/225], Training Accuracy: 57.3958%, Training Loss: 0.9011%\n",
      "Epoch [16/300], Step [16/225], Training Accuracy: 57.1289%, Training Loss: 0.9006%\n",
      "Epoch [16/300], Step [17/225], Training Accuracy: 57.5368%, Training Loss: 0.8952%\n",
      "Epoch [16/300], Step [18/225], Training Accuracy: 57.0312%, Training Loss: 0.9012%\n",
      "Epoch [16/300], Step [19/225], Training Accuracy: 56.9901%, Training Loss: 0.9004%\n",
      "Epoch [16/300], Step [20/225], Training Accuracy: 57.2656%, Training Loss: 0.8950%\n",
      "Epoch [16/300], Step [21/225], Training Accuracy: 56.9196%, Training Loss: 0.8952%\n",
      "Epoch [16/300], Step [22/225], Training Accuracy: 56.3920%, Training Loss: 0.9015%\n",
      "Epoch [16/300], Step [23/225], Training Accuracy: 56.5897%, Training Loss: 0.8988%\n",
      "Epoch [16/300], Step [24/225], Training Accuracy: 56.0547%, Training Loss: 0.9038%\n",
      "Epoch [16/300], Step [25/225], Training Accuracy: 56.1875%, Training Loss: 0.9018%\n",
      "Epoch [16/300], Step [26/225], Training Accuracy: 56.0096%, Training Loss: 0.9019%\n",
      "Epoch [16/300], Step [27/225], Training Accuracy: 56.0764%, Training Loss: 0.9062%\n",
      "Epoch [16/300], Step [28/225], Training Accuracy: 56.4174%, Training Loss: 0.9016%\n",
      "Epoch [16/300], Step [29/225], Training Accuracy: 56.5733%, Training Loss: 0.8977%\n",
      "Epoch [16/300], Step [30/225], Training Accuracy: 56.7188%, Training Loss: 0.8970%\n",
      "Epoch [16/300], Step [31/225], Training Accuracy: 56.6532%, Training Loss: 0.8989%\n",
      "Epoch [16/300], Step [32/225], Training Accuracy: 56.6895%, Training Loss: 0.8961%\n",
      "Epoch [16/300], Step [33/225], Training Accuracy: 56.7235%, Training Loss: 0.8941%\n",
      "Epoch [16/300], Step [34/225], Training Accuracy: 56.2500%, Training Loss: 0.9006%\n",
      "Epoch [16/300], Step [35/225], Training Accuracy: 56.1607%, Training Loss: 0.9047%\n",
      "Epoch [16/300], Step [36/225], Training Accuracy: 56.0330%, Training Loss: 0.9055%\n",
      "Epoch [16/300], Step [37/225], Training Accuracy: 56.2500%, Training Loss: 0.9036%\n",
      "Epoch [16/300], Step [38/225], Training Accuracy: 56.1266%, Training Loss: 0.9079%\n",
      "Epoch [16/300], Step [39/225], Training Accuracy: 55.8894%, Training Loss: 0.9104%\n",
      "Epoch [16/300], Step [40/225], Training Accuracy: 55.6250%, Training Loss: 0.9133%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/300], Step [41/225], Training Accuracy: 55.3735%, Training Loss: 0.9163%\n",
      "Epoch [16/300], Step [42/225], Training Accuracy: 55.3571%, Training Loss: 0.9164%\n",
      "Epoch [16/300], Step [43/225], Training Accuracy: 55.1599%, Training Loss: 0.9191%\n",
      "Epoch [16/300], Step [44/225], Training Accuracy: 55.1136%, Training Loss: 0.9191%\n",
      "Epoch [16/300], Step [45/225], Training Accuracy: 55.1389%, Training Loss: 0.9186%\n",
      "Epoch [16/300], Step [46/225], Training Accuracy: 55.1630%, Training Loss: 0.9179%\n",
      "Epoch [16/300], Step [47/225], Training Accuracy: 55.0199%, Training Loss: 0.9181%\n",
      "Epoch [16/300], Step [48/225], Training Accuracy: 55.0130%, Training Loss: 0.9188%\n",
      "Epoch [16/300], Step [49/225], Training Accuracy: 55.2615%, Training Loss: 0.9169%\n",
      "Epoch [16/300], Step [50/225], Training Accuracy: 55.4062%, Training Loss: 0.9148%\n",
      "Epoch [16/300], Step [51/225], Training Accuracy: 55.5453%, Training Loss: 0.9129%\n",
      "Epoch [16/300], Step [52/225], Training Accuracy: 55.8594%, Training Loss: 0.9103%\n",
      "Epoch [16/300], Step [53/225], Training Accuracy: 55.8962%, Training Loss: 0.9101%\n",
      "Epoch [16/300], Step [54/225], Training Accuracy: 55.8449%, Training Loss: 0.9110%\n",
      "Epoch [16/300], Step [55/225], Training Accuracy: 55.6534%, Training Loss: 0.9131%\n",
      "Epoch [16/300], Step [56/225], Training Accuracy: 55.5525%, Training Loss: 0.9138%\n",
      "Epoch [16/300], Step [57/225], Training Accuracy: 55.5921%, Training Loss: 0.9115%\n",
      "Epoch [16/300], Step [58/225], Training Accuracy: 55.6843%, Training Loss: 0.9109%\n",
      "Epoch [16/300], Step [59/225], Training Accuracy: 55.6674%, Training Loss: 0.9096%\n",
      "Epoch [16/300], Step [60/225], Training Accuracy: 55.7031%, Training Loss: 0.9087%\n",
      "Epoch [16/300], Step [61/225], Training Accuracy: 55.7377%, Training Loss: 0.9079%\n",
      "Epoch [16/300], Step [62/225], Training Accuracy: 55.9224%, Training Loss: 0.9067%\n",
      "Epoch [16/300], Step [63/225], Training Accuracy: 55.9028%, Training Loss: 0.9090%\n",
      "Epoch [16/300], Step [64/225], Training Accuracy: 55.8105%, Training Loss: 0.9107%\n",
      "Epoch [16/300], Step [65/225], Training Accuracy: 55.9135%, Training Loss: 0.9114%\n",
      "Epoch [16/300], Step [66/225], Training Accuracy: 55.9422%, Training Loss: 0.9089%\n",
      "Epoch [16/300], Step [67/225], Training Accuracy: 55.9002%, Training Loss: 0.9086%\n",
      "Epoch [16/300], Step [68/225], Training Accuracy: 55.9053%, Training Loss: 0.9086%\n",
      "Epoch [16/300], Step [69/225], Training Accuracy: 55.8197%, Training Loss: 0.9089%\n",
      "Epoch [16/300], Step [70/225], Training Accuracy: 55.6920%, Training Loss: 0.9119%\n",
      "Epoch [16/300], Step [71/225], Training Accuracy: 55.8319%, Training Loss: 0.9102%\n",
      "Epoch [16/300], Step [72/225], Training Accuracy: 55.7509%, Training Loss: 0.9121%\n",
      "Epoch [16/300], Step [73/225], Training Accuracy: 55.6293%, Training Loss: 0.9132%\n",
      "Epoch [16/300], Step [74/225], Training Accuracy: 55.7432%, Training Loss: 0.9105%\n",
      "Epoch [16/300], Step [75/225], Training Accuracy: 55.7292%, Training Loss: 0.9095%\n",
      "Epoch [16/300], Step [76/225], Training Accuracy: 55.6949%, Training Loss: 0.9101%\n",
      "Epoch [16/300], Step [77/225], Training Accuracy: 55.7427%, Training Loss: 0.9100%\n",
      "Epoch [16/300], Step [78/225], Training Accuracy: 55.7893%, Training Loss: 0.9101%\n",
      "Epoch [16/300], Step [79/225], Training Accuracy: 55.7358%, Training Loss: 0.9114%\n",
      "Epoch [16/300], Step [80/225], Training Accuracy: 55.6445%, Training Loss: 0.9116%\n",
      "Epoch [16/300], Step [81/225], Training Accuracy: 55.5941%, Training Loss: 0.9127%\n",
      "Epoch [16/300], Step [82/225], Training Accuracy: 55.5831%, Training Loss: 0.9146%\n",
      "Epoch [16/300], Step [83/225], Training Accuracy: 55.5911%, Training Loss: 0.9145%\n",
      "Epoch [16/300], Step [84/225], Training Accuracy: 55.6734%, Training Loss: 0.9137%\n",
      "Epoch [16/300], Step [85/225], Training Accuracy: 55.7353%, Training Loss: 0.9131%\n",
      "Epoch [16/300], Step [86/225], Training Accuracy: 55.8140%, Training Loss: 0.9118%\n",
      "Epoch [16/300], Step [87/225], Training Accuracy: 55.8010%, Training Loss: 0.9133%\n",
      "Epoch [16/300], Step [88/225], Training Accuracy: 55.7884%, Training Loss: 0.9137%\n",
      "Epoch [16/300], Step [89/225], Training Accuracy: 55.7935%, Training Loss: 0.9141%\n",
      "Epoch [16/300], Step [90/225], Training Accuracy: 55.6944%, Training Loss: 0.9157%\n",
      "Epoch [16/300], Step [91/225], Training Accuracy: 55.6319%, Training Loss: 0.9157%\n",
      "Epoch [16/300], Step [92/225], Training Accuracy: 55.4348%, Training Loss: 0.9193%\n",
      "Epoch [16/300], Step [93/225], Training Accuracy: 55.4940%, Training Loss: 0.9181%\n",
      "Epoch [16/300], Step [94/225], Training Accuracy: 55.5685%, Training Loss: 0.9172%\n",
      "Epoch [16/300], Step [95/225], Training Accuracy: 55.4770%, Training Loss: 0.9187%\n",
      "Epoch [16/300], Step [96/225], Training Accuracy: 55.5339%, Training Loss: 0.9181%\n",
      "Epoch [16/300], Step [97/225], Training Accuracy: 55.5251%, Training Loss: 0.9184%\n",
      "Epoch [16/300], Step [98/225], Training Accuracy: 55.5325%, Training Loss: 0.9181%\n",
      "Epoch [16/300], Step [99/225], Training Accuracy: 55.6503%, Training Loss: 0.9176%\n",
      "Epoch [16/300], Step [100/225], Training Accuracy: 55.5625%, Training Loss: 0.9187%\n",
      "Epoch [16/300], Step [101/225], Training Accuracy: 55.5384%, Training Loss: 0.9176%\n",
      "Epoch [16/300], Step [102/225], Training Accuracy: 55.5300%, Training Loss: 0.9178%\n",
      "Epoch [16/300], Step [103/225], Training Accuracy: 55.5977%, Training Loss: 0.9166%\n",
      "Epoch [16/300], Step [104/225], Training Accuracy: 55.5889%, Training Loss: 0.9170%\n",
      "Epoch [16/300], Step [105/225], Training Accuracy: 55.6548%, Training Loss: 0.9161%\n",
      "Epoch [16/300], Step [106/225], Training Accuracy: 55.7341%, Training Loss: 0.9158%\n",
      "Epoch [16/300], Step [107/225], Training Accuracy: 55.6951%, Training Loss: 0.9164%\n",
      "Epoch [16/300], Step [108/225], Training Accuracy: 55.6713%, Training Loss: 0.9165%\n",
      "Epoch [16/300], Step [109/225], Training Accuracy: 55.7769%, Training Loss: 0.9157%\n",
      "Epoch [16/300], Step [110/225], Training Accuracy: 55.7528%, Training Loss: 0.9150%\n",
      "Epoch [16/300], Step [111/225], Training Accuracy: 55.7573%, Training Loss: 0.9143%\n",
      "Epoch [16/300], Step [112/225], Training Accuracy: 55.8175%, Training Loss: 0.9131%\n",
      "Epoch [16/300], Step [113/225], Training Accuracy: 55.8213%, Training Loss: 0.9140%\n",
      "Epoch [16/300], Step [114/225], Training Accuracy: 55.7977%, Training Loss: 0.9135%\n",
      "Epoch [16/300], Step [115/225], Training Accuracy: 55.8288%, Training Loss: 0.9127%\n",
      "Epoch [16/300], Step [116/225], Training Accuracy: 55.7516%, Training Loss: 0.9130%\n",
      "Epoch [16/300], Step [117/225], Training Accuracy: 55.6624%, Training Loss: 0.9141%\n",
      "Epoch [16/300], Step [118/225], Training Accuracy: 55.7203%, Training Loss: 0.9135%\n",
      "Epoch [16/300], Step [119/225], Training Accuracy: 55.7904%, Training Loss: 0.9133%\n",
      "Epoch [16/300], Step [120/225], Training Accuracy: 55.8333%, Training Loss: 0.9131%\n",
      "Epoch [16/300], Step [121/225], Training Accuracy: 55.7335%, Training Loss: 0.9139%\n",
      "Epoch [16/300], Step [122/225], Training Accuracy: 55.7633%, Training Loss: 0.9130%\n",
      "Epoch [16/300], Step [123/225], Training Accuracy: 55.7292%, Training Loss: 0.9123%\n",
      "Epoch [16/300], Step [124/225], Training Accuracy: 55.6326%, Training Loss: 0.9115%\n",
      "Epoch [16/300], Step [125/225], Training Accuracy: 55.6750%, Training Loss: 0.9121%\n",
      "Epoch [16/300], Step [126/225], Training Accuracy: 55.6300%, Training Loss: 0.9128%\n",
      "Epoch [16/300], Step [127/225], Training Accuracy: 55.5610%, Training Loss: 0.9134%\n",
      "Epoch [16/300], Step [128/225], Training Accuracy: 55.5908%, Training Loss: 0.9137%\n",
      "Epoch [16/300], Step [129/225], Training Accuracy: 55.5717%, Training Loss: 0.9143%\n",
      "Epoch [16/300], Step [130/225], Training Accuracy: 55.5529%, Training Loss: 0.9159%\n",
      "Epoch [16/300], Step [131/225], Training Accuracy: 55.5344%, Training Loss: 0.9161%\n",
      "Epoch [16/300], Step [132/225], Training Accuracy: 55.5279%, Training Loss: 0.9163%\n",
      "Epoch [16/300], Step [133/225], Training Accuracy: 55.5099%, Training Loss: 0.9161%\n",
      "Epoch [16/300], Step [134/225], Training Accuracy: 55.3521%, Training Loss: 0.9174%\n",
      "Epoch [16/300], Step [135/225], Training Accuracy: 55.3241%, Training Loss: 0.9166%\n",
      "Epoch [16/300], Step [136/225], Training Accuracy: 55.3539%, Training Loss: 0.9164%\n",
      "Epoch [16/300], Step [137/225], Training Accuracy: 55.3490%, Training Loss: 0.9163%\n",
      "Epoch [16/300], Step [138/225], Training Accuracy: 55.4574%, Training Loss: 0.9148%\n",
      "Epoch [16/300], Step [139/225], Training Accuracy: 55.4182%, Training Loss: 0.9144%\n",
      "Epoch [16/300], Step [140/225], Training Accuracy: 55.4576%, Training Loss: 0.9139%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/300], Step [141/225], Training Accuracy: 55.4854%, Training Loss: 0.9130%\n",
      "Epoch [16/300], Step [142/225], Training Accuracy: 55.5018%, Training Loss: 0.9127%\n",
      "Epoch [16/300], Step [143/225], Training Accuracy: 55.5070%, Training Loss: 0.9127%\n",
      "Epoch [16/300], Step [144/225], Training Accuracy: 55.4362%, Training Loss: 0.9135%\n",
      "Epoch [16/300], Step [145/225], Training Accuracy: 55.4418%, Training Loss: 0.9127%\n",
      "Epoch [16/300], Step [146/225], Training Accuracy: 55.3938%, Training Loss: 0.9135%\n",
      "Epoch [16/300], Step [147/225], Training Accuracy: 55.3678%, Training Loss: 0.9138%\n",
      "Epoch [16/300], Step [148/225], Training Accuracy: 55.4054%, Training Loss: 0.9129%\n",
      "Epoch [16/300], Step [149/225], Training Accuracy: 55.4635%, Training Loss: 0.9124%\n",
      "Epoch [16/300], Step [150/225], Training Accuracy: 55.4167%, Training Loss: 0.9120%\n",
      "Epoch [16/300], Step [151/225], Training Accuracy: 55.4739%, Training Loss: 0.9114%\n",
      "Epoch [16/300], Step [152/225], Training Accuracy: 55.4893%, Training Loss: 0.9116%\n",
      "Epoch [16/300], Step [153/225], Training Accuracy: 55.4943%, Training Loss: 0.9110%\n",
      "Epoch [16/300], Step [154/225], Training Accuracy: 55.5093%, Training Loss: 0.9112%\n",
      "Epoch [16/300], Step [155/225], Training Accuracy: 55.4637%, Training Loss: 0.9113%\n",
      "Epoch [16/300], Step [156/225], Training Accuracy: 55.4788%, Training Loss: 0.9118%\n",
      "Epoch [16/300], Step [157/225], Training Accuracy: 55.5434%, Training Loss: 0.9108%\n",
      "Epoch [16/300], Step [158/225], Training Accuracy: 55.4391%, Training Loss: 0.9118%\n",
      "Epoch [16/300], Step [159/225], Training Accuracy: 55.3852%, Training Loss: 0.9118%\n",
      "Epoch [16/300], Step [160/225], Training Accuracy: 55.4102%, Training Loss: 0.9114%\n",
      "Epoch [16/300], Step [161/225], Training Accuracy: 55.4057%, Training Loss: 0.9117%\n",
      "Epoch [16/300], Step [162/225], Training Accuracy: 55.4205%, Training Loss: 0.9128%\n",
      "Epoch [16/300], Step [163/225], Training Accuracy: 55.4160%, Training Loss: 0.9128%\n",
      "Epoch [16/300], Step [164/225], Training Accuracy: 55.4688%, Training Loss: 0.9125%\n",
      "Epoch [16/300], Step [165/225], Training Accuracy: 55.4640%, Training Loss: 0.9127%\n",
      "Epoch [16/300], Step [166/225], Training Accuracy: 55.4688%, Training Loss: 0.9121%\n",
      "Epoch [16/300], Step [167/225], Training Accuracy: 55.5015%, Training Loss: 0.9115%\n",
      "Epoch [16/300], Step [168/225], Training Accuracy: 55.5153%, Training Loss: 0.9114%\n",
      "Epoch [16/300], Step [169/225], Training Accuracy: 55.5566%, Training Loss: 0.9105%\n",
      "Epoch [16/300], Step [170/225], Training Accuracy: 55.5790%, Training Loss: 0.9105%\n",
      "Epoch [16/300], Step [171/225], Training Accuracy: 55.6104%, Training Loss: 0.9101%\n",
      "Epoch [16/300], Step [172/225], Training Accuracy: 55.5778%, Training Loss: 0.9100%\n",
      "Epoch [16/300], Step [173/225], Training Accuracy: 55.5546%, Training Loss: 0.9102%\n",
      "Epoch [16/300], Step [174/225], Training Accuracy: 55.5855%, Training Loss: 0.9106%\n",
      "Epoch [16/300], Step [175/225], Training Accuracy: 55.5982%, Training Loss: 0.9105%\n",
      "Epoch [16/300], Step [176/225], Training Accuracy: 55.6108%, Training Loss: 0.9102%\n",
      "Epoch [16/300], Step [177/225], Training Accuracy: 55.6762%, Training Loss: 0.9093%\n",
      "Epoch [16/300], Step [178/225], Training Accuracy: 55.6180%, Training Loss: 0.9093%\n",
      "Epoch [16/300], Step [179/225], Training Accuracy: 55.6477%, Training Loss: 0.9088%\n",
      "Epoch [16/300], Step [180/225], Training Accuracy: 55.6944%, Training Loss: 0.9082%\n",
      "Epoch [16/300], Step [181/225], Training Accuracy: 55.6544%, Training Loss: 0.9094%\n",
      "Epoch [16/300], Step [182/225], Training Accuracy: 55.7091%, Training Loss: 0.9092%\n",
      "Epoch [16/300], Step [183/225], Training Accuracy: 55.6950%, Training Loss: 0.9094%\n",
      "Epoch [16/300], Step [184/225], Training Accuracy: 55.6895%, Training Loss: 0.9096%\n",
      "Epoch [16/300], Step [185/225], Training Accuracy: 55.7095%, Training Loss: 0.9099%\n",
      "Epoch [16/300], Step [186/225], Training Accuracy: 55.7208%, Training Loss: 0.9096%\n",
      "Epoch [16/300], Step [187/225], Training Accuracy: 55.7570%, Training Loss: 0.9091%\n",
      "Epoch [16/300], Step [188/225], Training Accuracy: 55.7513%, Training Loss: 0.9092%\n",
      "Epoch [16/300], Step [189/225], Training Accuracy: 55.7870%, Training Loss: 0.9084%\n",
      "Epoch [16/300], Step [190/225], Training Accuracy: 55.7812%, Training Loss: 0.9085%\n",
      "Epoch [16/300], Step [191/225], Training Accuracy: 55.7837%, Training Loss: 0.9083%\n",
      "Epoch [16/300], Step [192/225], Training Accuracy: 55.8187%, Training Loss: 0.9079%\n",
      "Epoch [16/300], Step [193/225], Training Accuracy: 55.7804%, Training Loss: 0.9079%\n",
      "Epoch [16/300], Step [194/225], Training Accuracy: 55.7426%, Training Loss: 0.9085%\n",
      "Epoch [16/300], Step [195/225], Training Accuracy: 55.7372%, Training Loss: 0.9082%\n",
      "Epoch [16/300], Step [196/225], Training Accuracy: 55.7159%, Training Loss: 0.9086%\n",
      "Epoch [16/300], Step [197/225], Training Accuracy: 55.7107%, Training Loss: 0.9089%\n",
      "Epoch [16/300], Step [198/225], Training Accuracy: 55.7607%, Training Loss: 0.9079%\n",
      "Epoch [16/300], Step [199/225], Training Accuracy: 55.7710%, Training Loss: 0.9075%\n",
      "Epoch [16/300], Step [200/225], Training Accuracy: 55.8047%, Training Loss: 0.9071%\n",
      "Epoch [16/300], Step [201/225], Training Accuracy: 55.7603%, Training Loss: 0.9075%\n",
      "Epoch [16/300], Step [202/225], Training Accuracy: 55.7163%, Training Loss: 0.9077%\n",
      "Epoch [16/300], Step [203/225], Training Accuracy: 55.7651%, Training Loss: 0.9071%\n",
      "Epoch [16/300], Step [204/225], Training Accuracy: 55.7675%, Training Loss: 0.9071%\n",
      "Epoch [16/300], Step [205/225], Training Accuracy: 55.7698%, Training Loss: 0.9066%\n",
      "Epoch [16/300], Step [206/225], Training Accuracy: 55.7342%, Training Loss: 0.9066%\n",
      "Epoch [16/300], Step [207/225], Training Accuracy: 55.7292%, Training Loss: 0.9067%\n",
      "Epoch [16/300], Step [208/225], Training Accuracy: 55.7467%, Training Loss: 0.9063%\n",
      "Epoch [16/300], Step [209/225], Training Accuracy: 55.7342%, Training Loss: 0.9063%\n",
      "Epoch [16/300], Step [210/225], Training Accuracy: 55.6994%, Training Loss: 0.9064%\n",
      "Epoch [16/300], Step [211/225], Training Accuracy: 55.7094%, Training Loss: 0.9060%\n",
      "Epoch [16/300], Step [212/225], Training Accuracy: 55.6972%, Training Loss: 0.9061%\n",
      "Epoch [16/300], Step [213/225], Training Accuracy: 55.6485%, Training Loss: 0.9071%\n",
      "Epoch [16/300], Step [214/225], Training Accuracy: 55.6951%, Training Loss: 0.9065%\n",
      "Epoch [16/300], Step [215/225], Training Accuracy: 55.6831%, Training Loss: 0.9062%\n",
      "Epoch [16/300], Step [216/225], Training Accuracy: 55.6641%, Training Loss: 0.9068%\n",
      "Epoch [16/300], Step [217/225], Training Accuracy: 55.6668%, Training Loss: 0.9068%\n",
      "Epoch [16/300], Step [218/225], Training Accuracy: 55.6838%, Training Loss: 0.9067%\n",
      "Epoch [16/300], Step [219/225], Training Accuracy: 55.6792%, Training Loss: 0.9069%\n",
      "Epoch [16/300], Step [220/225], Training Accuracy: 55.6747%, Training Loss: 0.9068%\n",
      "Epoch [16/300], Step [221/225], Training Accuracy: 55.6278%, Training Loss: 0.9070%\n",
      "Epoch [16/300], Step [222/225], Training Accuracy: 55.6447%, Training Loss: 0.9067%\n",
      "Epoch [16/300], Step [223/225], Training Accuracy: 55.6404%, Training Loss: 0.9071%\n",
      "Epoch [16/300], Step [224/225], Training Accuracy: 55.6501%, Training Loss: 0.9069%\n",
      "Epoch [16/300], Step [225/225], Training Accuracy: 55.6629%, Training Loss: 0.9072%\n",
      "Epoch [17/300], Step [1/225], Training Accuracy: 73.4375%, Training Loss: 0.6346%\n",
      "Epoch [17/300], Step [2/225], Training Accuracy: 65.6250%, Training Loss: 0.7801%\n",
      "Epoch [17/300], Step [3/225], Training Accuracy: 66.1458%, Training Loss: 0.8102%\n",
      "Epoch [17/300], Step [4/225], Training Accuracy: 62.5000%, Training Loss: 0.8368%\n",
      "Epoch [17/300], Step [5/225], Training Accuracy: 62.1875%, Training Loss: 0.8462%\n",
      "Epoch [17/300], Step [6/225], Training Accuracy: 61.7188%, Training Loss: 0.8538%\n",
      "Epoch [17/300], Step [7/225], Training Accuracy: 60.7143%, Training Loss: 0.8679%\n",
      "Epoch [17/300], Step [8/225], Training Accuracy: 59.5703%, Training Loss: 0.8779%\n",
      "Epoch [17/300], Step [9/225], Training Accuracy: 58.5069%, Training Loss: 0.8866%\n",
      "Epoch [17/300], Step [10/225], Training Accuracy: 57.1875%, Training Loss: 0.9144%\n",
      "Epoch [17/300], Step [11/225], Training Accuracy: 57.2443%, Training Loss: 0.9144%\n",
      "Epoch [17/300], Step [12/225], Training Accuracy: 57.8125%, Training Loss: 0.9079%\n",
      "Epoch [17/300], Step [13/225], Training Accuracy: 59.0144%, Training Loss: 0.8894%\n",
      "Epoch [17/300], Step [14/225], Training Accuracy: 58.4821%, Training Loss: 0.8941%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/300], Step [15/225], Training Accuracy: 58.6458%, Training Loss: 0.8912%\n",
      "Epoch [17/300], Step [16/225], Training Accuracy: 58.7891%, Training Loss: 0.8923%\n",
      "Epoch [17/300], Step [17/225], Training Accuracy: 58.7316%, Training Loss: 0.8890%\n",
      "Epoch [17/300], Step [18/225], Training Accuracy: 58.7674%, Training Loss: 0.8872%\n",
      "Epoch [17/300], Step [19/225], Training Accuracy: 58.7993%, Training Loss: 0.8884%\n",
      "Epoch [17/300], Step [20/225], Training Accuracy: 59.2969%, Training Loss: 0.8792%\n",
      "Epoch [17/300], Step [21/225], Training Accuracy: 59.1518%, Training Loss: 0.8754%\n",
      "Epoch [17/300], Step [22/225], Training Accuracy: 58.4517%, Training Loss: 0.8787%\n",
      "Epoch [17/300], Step [23/225], Training Accuracy: 58.3560%, Training Loss: 0.8765%\n",
      "Epoch [17/300], Step [24/225], Training Accuracy: 57.9427%, Training Loss: 0.8792%\n",
      "Epoch [17/300], Step [25/225], Training Accuracy: 58.4375%, Training Loss: 0.8740%\n",
      "Epoch [17/300], Step [26/225], Training Accuracy: 58.4736%, Training Loss: 0.8730%\n",
      "Epoch [17/300], Step [27/225], Training Accuracy: 58.5069%, Training Loss: 0.8769%\n",
      "Epoch [17/300], Step [28/225], Training Accuracy: 58.7054%, Training Loss: 0.8723%\n",
      "Epoch [17/300], Step [29/225], Training Accuracy: 59.0517%, Training Loss: 0.8713%\n",
      "Epoch [17/300], Step [30/225], Training Accuracy: 58.9583%, Training Loss: 0.8722%\n",
      "Epoch [17/300], Step [31/225], Training Accuracy: 59.1230%, Training Loss: 0.8727%\n",
      "Epoch [17/300], Step [32/225], Training Accuracy: 59.0820%, Training Loss: 0.8700%\n",
      "Epoch [17/300], Step [33/225], Training Accuracy: 59.0909%, Training Loss: 0.8675%\n",
      "Epoch [17/300], Step [34/225], Training Accuracy: 58.9614%, Training Loss: 0.8700%\n",
      "Epoch [17/300], Step [35/225], Training Accuracy: 58.5714%, Training Loss: 0.8782%\n",
      "Epoch [17/300], Step [36/225], Training Accuracy: 58.3767%, Training Loss: 0.8782%\n",
      "Epoch [17/300], Step [37/225], Training Accuracy: 58.7838%, Training Loss: 0.8742%\n",
      "Epoch [17/300], Step [38/225], Training Accuracy: 58.6349%, Training Loss: 0.8760%\n",
      "Epoch [17/300], Step [39/225], Training Accuracy: 58.6138%, Training Loss: 0.8757%\n",
      "Epoch [17/300], Step [40/225], Training Accuracy: 58.3594%, Training Loss: 0.8793%\n",
      "Epoch [17/300], Step [41/225], Training Accuracy: 58.0793%, Training Loss: 0.8819%\n",
      "Epoch [17/300], Step [42/225], Training Accuracy: 57.8497%, Training Loss: 0.8825%\n",
      "Epoch [17/300], Step [43/225], Training Accuracy: 57.5581%, Training Loss: 0.8835%\n",
      "Epoch [17/300], Step [44/225], Training Accuracy: 57.6349%, Training Loss: 0.8814%\n",
      "Epoch [17/300], Step [45/225], Training Accuracy: 57.6389%, Training Loss: 0.8807%\n",
      "Epoch [17/300], Step [46/225], Training Accuracy: 57.8465%, Training Loss: 0.8772%\n",
      "Epoch [17/300], Step [47/225], Training Accuracy: 57.7460%, Training Loss: 0.8780%\n",
      "Epoch [17/300], Step [48/225], Training Accuracy: 57.7474%, Training Loss: 0.8785%\n",
      "Epoch [17/300], Step [49/225], Training Accuracy: 57.8125%, Training Loss: 0.8787%\n",
      "Epoch [17/300], Step [50/225], Training Accuracy: 58.0000%, Training Loss: 0.8767%\n",
      "Epoch [17/300], Step [51/225], Training Accuracy: 58.2414%, Training Loss: 0.8746%\n",
      "Epoch [17/300], Step [52/225], Training Accuracy: 58.4135%, Training Loss: 0.8728%\n",
      "Epoch [17/300], Step [53/225], Training Accuracy: 58.4611%, Training Loss: 0.8743%\n",
      "Epoch [17/300], Step [54/225], Training Accuracy: 58.4201%, Training Loss: 0.8750%\n",
      "Epoch [17/300], Step [55/225], Training Accuracy: 58.2102%, Training Loss: 0.8773%\n",
      "Epoch [17/300], Step [56/225], Training Accuracy: 58.0915%, Training Loss: 0.8782%\n",
      "Epoch [17/300], Step [57/225], Training Accuracy: 58.0592%, Training Loss: 0.8768%\n",
      "Epoch [17/300], Step [58/225], Training Accuracy: 58.2166%, Training Loss: 0.8762%\n",
      "Epoch [17/300], Step [59/225], Training Accuracy: 58.2097%, Training Loss: 0.8744%\n",
      "Epoch [17/300], Step [60/225], Training Accuracy: 58.3594%, Training Loss: 0.8731%\n",
      "Epoch [17/300], Step [61/225], Training Accuracy: 58.3760%, Training Loss: 0.8727%\n",
      "Epoch [17/300], Step [62/225], Training Accuracy: 58.3669%, Training Loss: 0.8737%\n",
      "Epoch [17/300], Step [63/225], Training Accuracy: 58.2341%, Training Loss: 0.8752%\n",
      "Epoch [17/300], Step [64/225], Training Accuracy: 58.1787%, Training Loss: 0.8775%\n",
      "Epoch [17/300], Step [65/225], Training Accuracy: 58.2452%, Training Loss: 0.8778%\n",
      "Epoch [17/300], Step [66/225], Training Accuracy: 58.2623%, Training Loss: 0.8770%\n",
      "Epoch [17/300], Step [67/225], Training Accuracy: 58.3256%, Training Loss: 0.8764%\n",
      "Epoch [17/300], Step [68/225], Training Accuracy: 58.2491%, Training Loss: 0.8780%\n",
      "Epoch [17/300], Step [69/225], Training Accuracy: 58.1748%, Training Loss: 0.8789%\n",
      "Epoch [17/300], Step [70/225], Training Accuracy: 58.1027%, Training Loss: 0.8799%\n",
      "Epoch [17/300], Step [71/225], Training Accuracy: 58.1426%, Training Loss: 0.8786%\n",
      "Epoch [17/300], Step [72/225], Training Accuracy: 58.1163%, Training Loss: 0.8797%\n",
      "Epoch [17/300], Step [73/225], Training Accuracy: 58.0479%, Training Loss: 0.8807%\n",
      "Epoch [17/300], Step [74/225], Training Accuracy: 58.1503%, Training Loss: 0.8792%\n",
      "Epoch [17/300], Step [75/225], Training Accuracy: 58.0000%, Training Loss: 0.8806%\n",
      "Epoch [17/300], Step [76/225], Training Accuracy: 57.9770%, Training Loss: 0.8804%\n",
      "Epoch [17/300], Step [77/225], Training Accuracy: 58.1169%, Training Loss: 0.8798%\n",
      "Epoch [17/300], Step [78/225], Training Accuracy: 58.2131%, Training Loss: 0.8800%\n",
      "Epoch [17/300], Step [79/225], Training Accuracy: 58.2278%, Training Loss: 0.8809%\n",
      "Epoch [17/300], Step [80/225], Training Accuracy: 58.0273%, Training Loss: 0.8822%\n",
      "Epoch [17/300], Step [81/225], Training Accuracy: 57.9475%, Training Loss: 0.8843%\n",
      "Epoch [17/300], Step [82/225], Training Accuracy: 57.9459%, Training Loss: 0.8844%\n",
      "Epoch [17/300], Step [83/225], Training Accuracy: 57.9819%, Training Loss: 0.8837%\n",
      "Epoch [17/300], Step [84/225], Training Accuracy: 58.0543%, Training Loss: 0.8826%\n",
      "Epoch [17/300], Step [85/225], Training Accuracy: 58.1066%, Training Loss: 0.8832%\n",
      "Epoch [17/300], Step [86/225], Training Accuracy: 58.1214%, Training Loss: 0.8825%\n",
      "Epoch [17/300], Step [87/225], Training Accuracy: 58.1178%, Training Loss: 0.8832%\n",
      "Epoch [17/300], Step [88/225], Training Accuracy: 57.9723%, Training Loss: 0.8844%\n",
      "Epoch [17/300], Step [89/225], Training Accuracy: 57.9003%, Training Loss: 0.8856%\n",
      "Epoch [17/300], Step [90/225], Training Accuracy: 57.8472%, Training Loss: 0.8876%\n",
      "Epoch [17/300], Step [91/225], Training Accuracy: 57.7782%, Training Loss: 0.8870%\n",
      "Epoch [17/300], Step [92/225], Training Accuracy: 57.6766%, Training Loss: 0.8887%\n",
      "Epoch [17/300], Step [93/225], Training Accuracy: 57.7117%, Training Loss: 0.8876%\n",
      "Epoch [17/300], Step [94/225], Training Accuracy: 57.7626%, Training Loss: 0.8870%\n",
      "Epoch [17/300], Step [95/225], Training Accuracy: 57.7303%, Training Loss: 0.8874%\n",
      "Epoch [17/300], Step [96/225], Training Accuracy: 57.8451%, Training Loss: 0.8860%\n",
      "Epoch [17/300], Step [97/225], Training Accuracy: 57.8608%, Training Loss: 0.8850%\n",
      "Epoch [17/300], Step [98/225], Training Accuracy: 57.8763%, Training Loss: 0.8848%\n",
      "Epoch [17/300], Step [99/225], Training Accuracy: 57.9545%, Training Loss: 0.8846%\n",
      "Epoch [17/300], Step [100/225], Training Accuracy: 57.8750%, Training Loss: 0.8858%\n",
      "Epoch [17/300], Step [101/225], Training Accuracy: 57.8434%, Training Loss: 0.8856%\n",
      "Epoch [17/300], Step [102/225], Training Accuracy: 57.7512%, Training Loss: 0.8865%\n",
      "Epoch [17/300], Step [103/225], Training Accuracy: 57.8125%, Training Loss: 0.8847%\n",
      "Epoch [17/300], Step [104/225], Training Accuracy: 57.7674%, Training Loss: 0.8844%\n",
      "Epoch [17/300], Step [105/225], Training Accuracy: 57.8274%, Training Loss: 0.8839%\n",
      "Epoch [17/300], Step [106/225], Training Accuracy: 57.8567%, Training Loss: 0.8833%\n",
      "Epoch [17/300], Step [107/225], Training Accuracy: 57.8271%, Training Loss: 0.8838%\n",
      "Epoch [17/300], Step [108/225], Training Accuracy: 57.8270%, Training Loss: 0.8838%\n",
      "Epoch [17/300], Step [109/225], Training Accuracy: 57.8698%, Training Loss: 0.8832%\n",
      "Epoch [17/300], Step [110/225], Training Accuracy: 57.8551%, Training Loss: 0.8830%\n",
      "Epoch [17/300], Step [111/225], Training Accuracy: 57.8970%, Training Loss: 0.8821%\n",
      "Epoch [17/300], Step [112/225], Training Accuracy: 57.9520%, Training Loss: 0.8819%\n",
      "Epoch [17/300], Step [113/225], Training Accuracy: 57.9369%, Training Loss: 0.8815%\n",
      "Epoch [17/300], Step [114/225], Training Accuracy: 57.9084%, Training Loss: 0.8808%\n",
      "Epoch [17/300], Step [115/225], Training Accuracy: 57.8940%, Training Loss: 0.8802%\n",
      "Epoch [17/300], Step [116/225], Training Accuracy: 57.8394%, Training Loss: 0.8803%\n",
      "Epoch [17/300], Step [117/225], Training Accuracy: 57.7057%, Training Loss: 0.8809%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/300], Step [118/225], Training Accuracy: 57.7198%, Training Loss: 0.8803%\n",
      "Epoch [17/300], Step [119/225], Training Accuracy: 57.7337%, Training Loss: 0.8799%\n",
      "Epoch [17/300], Step [120/225], Training Accuracy: 57.7474%, Training Loss: 0.8791%\n",
      "Epoch [17/300], Step [121/225], Training Accuracy: 57.6317%, Training Loss: 0.8800%\n",
      "Epoch [17/300], Step [122/225], Training Accuracy: 57.6972%, Training Loss: 0.8792%\n",
      "Epoch [17/300], Step [123/225], Training Accuracy: 57.7109%, Training Loss: 0.8785%\n",
      "Epoch [17/300], Step [124/225], Training Accuracy: 57.6865%, Training Loss: 0.8778%\n",
      "Epoch [17/300], Step [125/225], Training Accuracy: 57.6000%, Training Loss: 0.8794%\n",
      "Epoch [17/300], Step [126/225], Training Accuracy: 57.5521%, Training Loss: 0.8802%\n",
      "Epoch [17/300], Step [127/225], Training Accuracy: 57.4926%, Training Loss: 0.8809%\n",
      "Epoch [17/300], Step [128/225], Training Accuracy: 57.4707%, Training Loss: 0.8810%\n",
      "Epoch [17/300], Step [129/225], Training Accuracy: 57.4612%, Training Loss: 0.8816%\n",
      "Epoch [17/300], Step [130/225], Training Accuracy: 57.3918%, Training Loss: 0.8833%\n",
      "Epoch [17/300], Step [131/225], Training Accuracy: 57.3473%, Training Loss: 0.8838%\n",
      "Epoch [17/300], Step [132/225], Training Accuracy: 57.3272%, Training Loss: 0.8846%\n",
      "Epoch [17/300], Step [133/225], Training Accuracy: 57.3543%, Training Loss: 0.8850%\n",
      "Epoch [17/300], Step [134/225], Training Accuracy: 57.1828%, Training Loss: 0.8864%\n",
      "Epoch [17/300], Step [135/225], Training Accuracy: 57.2222%, Training Loss: 0.8855%\n",
      "Epoch [17/300], Step [136/225], Training Accuracy: 57.2725%, Training Loss: 0.8851%\n",
      "Epoch [17/300], Step [137/225], Training Accuracy: 57.2879%, Training Loss: 0.8847%\n",
      "Epoch [17/300], Step [138/225], Training Accuracy: 57.3256%, Training Loss: 0.8838%\n",
      "Epoch [17/300], Step [139/225], Training Accuracy: 57.2954%, Training Loss: 0.8836%\n",
      "Epoch [17/300], Step [140/225], Training Accuracy: 57.3549%, Training Loss: 0.8833%\n",
      "Epoch [17/300], Step [141/225], Training Accuracy: 57.3914%, Training Loss: 0.8826%\n",
      "Epoch [17/300], Step [142/225], Training Accuracy: 57.3944%, Training Loss: 0.8822%\n",
      "Epoch [17/300], Step [143/225], Training Accuracy: 57.3536%, Training Loss: 0.8825%\n",
      "Epoch [17/300], Step [144/225], Training Accuracy: 57.2591%, Training Loss: 0.8827%\n",
      "Epoch [17/300], Step [145/225], Training Accuracy: 57.2414%, Training Loss: 0.8823%\n",
      "Epoch [17/300], Step [146/225], Training Accuracy: 57.1811%, Training Loss: 0.8830%\n",
      "Epoch [17/300], Step [147/225], Training Accuracy: 57.1960%, Training Loss: 0.8835%\n",
      "Epoch [17/300], Step [148/225], Training Accuracy: 57.2318%, Training Loss: 0.8834%\n",
      "Epoch [17/300], Step [149/225], Training Accuracy: 57.2043%, Training Loss: 0.8833%\n",
      "Epoch [17/300], Step [150/225], Training Accuracy: 57.1979%, Training Loss: 0.8834%\n",
      "Epoch [17/300], Step [151/225], Training Accuracy: 57.1709%, Training Loss: 0.8834%\n",
      "Epoch [17/300], Step [152/225], Training Accuracy: 57.1443%, Training Loss: 0.8835%\n",
      "Epoch [17/300], Step [153/225], Training Accuracy: 57.1691%, Training Loss: 0.8830%\n",
      "Epoch [17/300], Step [154/225], Training Accuracy: 57.1429%, Training Loss: 0.8828%\n",
      "Epoch [17/300], Step [155/225], Training Accuracy: 57.1371%, Training Loss: 0.8830%\n",
      "Epoch [17/300], Step [156/225], Training Accuracy: 57.1114%, Training Loss: 0.8840%\n",
      "Epoch [17/300], Step [157/225], Training Accuracy: 57.1258%, Training Loss: 0.8835%\n",
      "Epoch [17/300], Step [158/225], Training Accuracy: 57.0510%, Training Loss: 0.8848%\n",
      "Epoch [17/300], Step [159/225], Training Accuracy: 57.0362%, Training Loss: 0.8846%\n",
      "Epoch [17/300], Step [160/225], Training Accuracy: 57.0508%, Training Loss: 0.8848%\n",
      "Epoch [17/300], Step [161/225], Training Accuracy: 57.0943%, Training Loss: 0.8850%\n",
      "Epoch [17/300], Step [162/225], Training Accuracy: 57.1566%, Training Loss: 0.8854%\n",
      "Epoch [17/300], Step [163/225], Training Accuracy: 57.1702%, Training Loss: 0.8851%\n",
      "Epoch [17/300], Step [164/225], Training Accuracy: 57.1646%, Training Loss: 0.8848%\n",
      "Epoch [17/300], Step [165/225], Training Accuracy: 57.1402%, Training Loss: 0.8848%\n",
      "Epoch [17/300], Step [166/225], Training Accuracy: 57.1348%, Training Loss: 0.8847%\n",
      "Epoch [17/300], Step [167/225], Training Accuracy: 57.1576%, Training Loss: 0.8844%\n",
      "Epoch [17/300], Step [168/225], Training Accuracy: 57.1429%, Training Loss: 0.8852%\n",
      "Epoch [17/300], Step [169/225], Training Accuracy: 57.2485%, Training Loss: 0.8845%\n",
      "Epoch [17/300], Step [170/225], Training Accuracy: 57.2702%, Training Loss: 0.8844%\n",
      "Epoch [17/300], Step [171/225], Training Accuracy: 57.2734%, Training Loss: 0.8841%\n",
      "Epoch [17/300], Step [172/225], Training Accuracy: 57.2584%, Training Loss: 0.8842%\n",
      "Epoch [17/300], Step [173/225], Training Accuracy: 57.2435%, Training Loss: 0.8845%\n",
      "Epoch [17/300], Step [174/225], Training Accuracy: 57.2737%, Training Loss: 0.8849%\n",
      "Epoch [17/300], Step [175/225], Training Accuracy: 57.2857%, Training Loss: 0.8853%\n",
      "Epoch [17/300], Step [176/225], Training Accuracy: 57.2621%, Training Loss: 0.8853%\n",
      "Epoch [17/300], Step [177/225], Training Accuracy: 57.3005%, Training Loss: 0.8849%\n",
      "Epoch [17/300], Step [178/225], Training Accuracy: 57.2331%, Training Loss: 0.8855%\n",
      "Epoch [17/300], Step [179/225], Training Accuracy: 57.3149%, Training Loss: 0.8847%\n",
      "Epoch [17/300], Step [180/225], Training Accuracy: 57.3872%, Training Loss: 0.8840%\n",
      "Epoch [17/300], Step [181/225], Training Accuracy: 57.3204%, Training Loss: 0.8850%\n",
      "Epoch [17/300], Step [182/225], Training Accuracy: 57.3489%, Training Loss: 0.8846%\n",
      "Epoch [17/300], Step [183/225], Training Accuracy: 57.3173%, Training Loss: 0.8849%\n",
      "Epoch [17/300], Step [184/225], Training Accuracy: 57.3370%, Training Loss: 0.8849%\n",
      "Epoch [17/300], Step [185/225], Training Accuracy: 57.3226%, Training Loss: 0.8853%\n",
      "Epoch [17/300], Step [186/225], Training Accuracy: 57.3001%, Training Loss: 0.8849%\n",
      "Epoch [17/300], Step [187/225], Training Accuracy: 57.2945%, Training Loss: 0.8846%\n",
      "Epoch [17/300], Step [188/225], Training Accuracy: 57.2806%, Training Loss: 0.8848%\n",
      "Epoch [17/300], Step [189/225], Training Accuracy: 57.3165%, Training Loss: 0.8839%\n",
      "Epoch [17/300], Step [190/225], Training Accuracy: 57.2862%, Training Loss: 0.8839%\n",
      "Epoch [17/300], Step [191/225], Training Accuracy: 57.2808%, Training Loss: 0.8844%\n",
      "Epoch [17/300], Step [192/225], Training Accuracy: 57.2998%, Training Loss: 0.8840%\n",
      "Epoch [17/300], Step [193/225], Training Accuracy: 57.2458%, Training Loss: 0.8846%\n",
      "Epoch [17/300], Step [194/225], Training Accuracy: 57.2165%, Training Loss: 0.8851%\n",
      "Epoch [17/300], Step [195/225], Training Accuracy: 57.2196%, Training Loss: 0.8848%\n",
      "Epoch [17/300], Step [196/225], Training Accuracy: 57.1907%, Training Loss: 0.8847%\n",
      "Epoch [17/300], Step [197/225], Training Accuracy: 57.1859%, Training Loss: 0.8850%\n",
      "Epoch [17/300], Step [198/225], Training Accuracy: 57.1891%, Training Loss: 0.8846%\n",
      "Epoch [17/300], Step [199/225], Training Accuracy: 57.1844%, Training Loss: 0.8842%\n",
      "Epoch [17/300], Step [200/225], Training Accuracy: 57.1875%, Training Loss: 0.8839%\n",
      "Epoch [17/300], Step [201/225], Training Accuracy: 57.1595%, Training Loss: 0.8842%\n",
      "Epoch [17/300], Step [202/225], Training Accuracy: 57.1395%, Training Loss: 0.8845%\n",
      "Epoch [17/300], Step [203/225], Training Accuracy: 57.1583%, Training Loss: 0.8844%\n",
      "Epoch [17/300], Step [204/225], Training Accuracy: 57.1615%, Training Loss: 0.8847%\n",
      "Epoch [17/300], Step [205/225], Training Accuracy: 57.1646%, Training Loss: 0.8847%\n",
      "Epoch [17/300], Step [206/225], Training Accuracy: 57.1754%, Training Loss: 0.8847%\n",
      "Epoch [17/300], Step [207/225], Training Accuracy: 57.1633%, Training Loss: 0.8846%\n",
      "Epoch [17/300], Step [208/225], Training Accuracy: 57.1590%, Training Loss: 0.8843%\n",
      "Epoch [17/300], Step [209/225], Training Accuracy: 57.1621%, Training Loss: 0.8843%\n",
      "Epoch [17/300], Step [210/225], Training Accuracy: 57.1577%, Training Loss: 0.8842%\n",
      "Epoch [17/300], Step [211/225], Training Accuracy: 57.1460%, Training Loss: 0.8839%\n",
      "Epoch [17/300], Step [212/225], Training Accuracy: 57.1123%, Training Loss: 0.8841%\n",
      "Epoch [17/300], Step [213/225], Training Accuracy: 57.0496%, Training Loss: 0.8849%\n",
      "Epoch [17/300], Step [214/225], Training Accuracy: 57.0459%, Training Loss: 0.8846%\n",
      "Epoch [17/300], Step [215/225], Training Accuracy: 57.0640%, Training Loss: 0.8845%\n",
      "Epoch [17/300], Step [216/225], Training Accuracy: 57.0602%, Training Loss: 0.8852%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/300], Step [217/225], Training Accuracy: 57.0565%, Training Loss: 0.8852%\n",
      "Epoch [17/300], Step [218/225], Training Accuracy: 57.0312%, Training Loss: 0.8855%\n",
      "Epoch [17/300], Step [219/225], Training Accuracy: 57.0205%, Training Loss: 0.8854%\n",
      "Epoch [17/300], Step [220/225], Training Accuracy: 57.0241%, Training Loss: 0.8851%\n",
      "Epoch [17/300], Step [221/225], Training Accuracy: 57.0206%, Training Loss: 0.8850%\n",
      "Epoch [17/300], Step [222/225], Training Accuracy: 57.0312%, Training Loss: 0.8851%\n",
      "Epoch [17/300], Step [223/225], Training Accuracy: 56.9717%, Training Loss: 0.8856%\n",
      "Epoch [17/300], Step [224/225], Training Accuracy: 56.9824%, Training Loss: 0.8852%\n",
      "Epoch [17/300], Step [225/225], Training Accuracy: 56.9483%, Training Loss: 0.8857%\n",
      "Epoch [18/300], Step [1/225], Training Accuracy: 70.3125%, Training Loss: 0.6774%\n",
      "Epoch [18/300], Step [2/225], Training Accuracy: 60.9375%, Training Loss: 0.8121%\n",
      "Epoch [18/300], Step [3/225], Training Accuracy: 58.8542%, Training Loss: 0.8955%\n",
      "Epoch [18/300], Step [4/225], Training Accuracy: 58.2031%, Training Loss: 0.8950%\n",
      "Epoch [18/300], Step [5/225], Training Accuracy: 59.0625%, Training Loss: 0.8809%\n",
      "Epoch [18/300], Step [6/225], Training Accuracy: 58.0729%, Training Loss: 0.8859%\n",
      "Epoch [18/300], Step [7/225], Training Accuracy: 57.5893%, Training Loss: 0.9038%\n",
      "Epoch [18/300], Step [8/225], Training Accuracy: 57.2266%, Training Loss: 0.9178%\n",
      "Epoch [18/300], Step [9/225], Training Accuracy: 56.0764%, Training Loss: 0.9164%\n",
      "Epoch [18/300], Step [10/225], Training Accuracy: 55.7812%, Training Loss: 0.9240%\n",
      "Epoch [18/300], Step [11/225], Training Accuracy: 55.6818%, Training Loss: 0.9305%\n",
      "Epoch [18/300], Step [12/225], Training Accuracy: 56.3802%, Training Loss: 0.9183%\n",
      "Epoch [18/300], Step [13/225], Training Accuracy: 57.9327%, Training Loss: 0.8932%\n",
      "Epoch [18/300], Step [14/225], Training Accuracy: 57.3661%, Training Loss: 0.9051%\n",
      "Epoch [18/300], Step [15/225], Training Accuracy: 56.4583%, Training Loss: 0.9107%\n",
      "Epoch [18/300], Step [16/225], Training Accuracy: 56.5430%, Training Loss: 0.9123%\n",
      "Epoch [18/300], Step [17/225], Training Accuracy: 56.8934%, Training Loss: 0.9059%\n",
      "Epoch [18/300], Step [18/225], Training Accuracy: 56.5972%, Training Loss: 0.9065%\n",
      "Epoch [18/300], Step [19/225], Training Accuracy: 56.9079%, Training Loss: 0.9040%\n",
      "Epoch [18/300], Step [20/225], Training Accuracy: 57.2656%, Training Loss: 0.8950%\n",
      "Epoch [18/300], Step [21/225], Training Accuracy: 57.0685%, Training Loss: 0.8994%\n",
      "Epoch [18/300], Step [22/225], Training Accuracy: 56.6761%, Training Loss: 0.9039%\n",
      "Epoch [18/300], Step [23/225], Training Accuracy: 56.9293%, Training Loss: 0.8989%\n",
      "Epoch [18/300], Step [24/225], Training Accuracy: 56.7708%, Training Loss: 0.9029%\n",
      "Epoch [18/300], Step [25/225], Training Accuracy: 57.1250%, Training Loss: 0.8994%\n",
      "Epoch [18/300], Step [26/225], Training Accuracy: 57.3317%, Training Loss: 0.8972%\n",
      "Epoch [18/300], Step [27/225], Training Accuracy: 57.4074%, Training Loss: 0.8981%\n",
      "Epoch [18/300], Step [28/225], Training Accuracy: 57.6451%, Training Loss: 0.8917%\n",
      "Epoch [18/300], Step [29/225], Training Accuracy: 57.8125%, Training Loss: 0.8875%\n",
      "Epoch [18/300], Step [30/225], Training Accuracy: 57.7604%, Training Loss: 0.8877%\n",
      "Epoch [18/300], Step [31/225], Training Accuracy: 57.4597%, Training Loss: 0.8905%\n",
      "Epoch [18/300], Step [32/225], Training Accuracy: 57.3242%, Training Loss: 0.8893%\n",
      "Epoch [18/300], Step [33/225], Training Accuracy: 57.4337%, Training Loss: 0.8858%\n",
      "Epoch [18/300], Step [34/225], Training Accuracy: 57.2151%, Training Loss: 0.8923%\n",
      "Epoch [18/300], Step [35/225], Training Accuracy: 57.1429%, Training Loss: 0.8940%\n",
      "Epoch [18/300], Step [36/225], Training Accuracy: 57.0747%, Training Loss: 0.8942%\n",
      "Epoch [18/300], Step [37/225], Training Accuracy: 57.2213%, Training Loss: 0.8928%\n",
      "Epoch [18/300], Step [38/225], Training Accuracy: 57.3191%, Training Loss: 0.8922%\n",
      "Epoch [18/300], Step [39/225], Training Accuracy: 57.1715%, Training Loss: 0.8934%\n",
      "Epoch [18/300], Step [40/225], Training Accuracy: 56.8750%, Training Loss: 0.8965%\n",
      "Epoch [18/300], Step [41/225], Training Accuracy: 56.5168%, Training Loss: 0.9007%\n",
      "Epoch [18/300], Step [42/225], Training Accuracy: 56.4732%, Training Loss: 0.9000%\n",
      "Epoch [18/300], Step [43/225], Training Accuracy: 56.3953%, Training Loss: 0.8983%\n",
      "Epoch [18/300], Step [44/225], Training Accuracy: 56.4631%, Training Loss: 0.8965%\n",
      "Epoch [18/300], Step [45/225], Training Accuracy: 56.6667%, Training Loss: 0.8936%\n",
      "Epoch [18/300], Step [46/225], Training Accuracy: 56.7255%, Training Loss: 0.8905%\n",
      "Epoch [18/300], Step [47/225], Training Accuracy: 56.6489%, Training Loss: 0.8925%\n",
      "Epoch [18/300], Step [48/225], Training Accuracy: 56.5755%, Training Loss: 0.8932%\n",
      "Epoch [18/300], Step [49/225], Training Accuracy: 56.8240%, Training Loss: 0.8912%\n",
      "Epoch [18/300], Step [50/225], Training Accuracy: 57.0000%, Training Loss: 0.8898%\n",
      "Epoch [18/300], Step [51/225], Training Accuracy: 57.2917%, Training Loss: 0.8853%\n",
      "Epoch [18/300], Step [52/225], Training Accuracy: 57.5421%, Training Loss: 0.8826%\n",
      "Epoch [18/300], Step [53/225], Training Accuracy: 57.5472%, Training Loss: 0.8828%\n",
      "Epoch [18/300], Step [54/225], Training Accuracy: 57.4653%, Training Loss: 0.8828%\n",
      "Epoch [18/300], Step [55/225], Training Accuracy: 57.3011%, Training Loss: 0.8829%\n",
      "Epoch [18/300], Step [56/225], Training Accuracy: 57.2824%, Training Loss: 0.8819%\n",
      "Epoch [18/300], Step [57/225], Training Accuracy: 57.3465%, Training Loss: 0.8804%\n",
      "Epoch [18/300], Step [58/225], Training Accuracy: 57.4623%, Training Loss: 0.8796%\n",
      "Epoch [18/300], Step [59/225], Training Accuracy: 57.4947%, Training Loss: 0.8780%\n",
      "Epoch [18/300], Step [60/225], Training Accuracy: 57.6042%, Training Loss: 0.8762%\n",
      "Epoch [18/300], Step [61/225], Training Accuracy: 57.7100%, Training Loss: 0.8754%\n",
      "Epoch [18/300], Step [62/225], Training Accuracy: 57.8881%, Training Loss: 0.8731%\n",
      "Epoch [18/300], Step [63/225], Training Accuracy: 58.0109%, Training Loss: 0.8728%\n",
      "Epoch [18/300], Step [64/225], Training Accuracy: 58.0078%, Training Loss: 0.8749%\n",
      "Epoch [18/300], Step [65/225], Training Accuracy: 58.0769%, Training Loss: 0.8753%\n",
      "Epoch [18/300], Step [66/225], Training Accuracy: 58.1439%, Training Loss: 0.8729%\n",
      "Epoch [18/300], Step [67/225], Training Accuracy: 58.2090%, Training Loss: 0.8728%\n",
      "Epoch [18/300], Step [68/225], Training Accuracy: 58.2031%, Training Loss: 0.8730%\n",
      "Epoch [18/300], Step [69/225], Training Accuracy: 58.1522%, Training Loss: 0.8729%\n",
      "Epoch [18/300], Step [70/225], Training Accuracy: 58.1027%, Training Loss: 0.8740%\n",
      "Epoch [18/300], Step [71/225], Training Accuracy: 58.0986%, Training Loss: 0.8728%\n",
      "Epoch [18/300], Step [72/225], Training Accuracy: 58.0729%, Training Loss: 0.8740%\n",
      "Epoch [18/300], Step [73/225], Training Accuracy: 58.0051%, Training Loss: 0.8756%\n",
      "Epoch [18/300], Step [74/225], Training Accuracy: 58.2137%, Training Loss: 0.8723%\n",
      "Epoch [18/300], Step [75/225], Training Accuracy: 58.1667%, Training Loss: 0.8728%\n",
      "Epoch [18/300], Step [76/225], Training Accuracy: 58.1826%, Training Loss: 0.8728%\n",
      "Epoch [18/300], Step [77/225], Training Accuracy: 58.2792%, Training Loss: 0.8724%\n",
      "Epoch [18/300], Step [78/225], Training Accuracy: 58.3333%, Training Loss: 0.8725%\n",
      "Epoch [18/300], Step [79/225], Training Accuracy: 58.3267%, Training Loss: 0.8721%\n",
      "Epoch [18/300], Step [80/225], Training Accuracy: 58.2031%, Training Loss: 0.8728%\n",
      "Epoch [18/300], Step [81/225], Training Accuracy: 58.0633%, Training Loss: 0.8735%\n",
      "Epoch [18/300], Step [82/225], Training Accuracy: 58.0030%, Training Loss: 0.8747%\n",
      "Epoch [18/300], Step [83/225], Training Accuracy: 57.9255%, Training Loss: 0.8760%\n",
      "Epoch [18/300], Step [84/225], Training Accuracy: 58.0729%, Training Loss: 0.8751%\n",
      "Epoch [18/300], Step [85/225], Training Accuracy: 58.1434%, Training Loss: 0.8747%\n",
      "Epoch [18/300], Step [86/225], Training Accuracy: 58.2304%, Training Loss: 0.8739%\n",
      "Epoch [18/300], Step [87/225], Training Accuracy: 58.2435%, Training Loss: 0.8758%\n",
      "Epoch [18/300], Step [88/225], Training Accuracy: 58.1499%, Training Loss: 0.8774%\n",
      "Epoch [18/300], Step [89/225], Training Accuracy: 58.1110%, Training Loss: 0.8797%\n",
      "Epoch [18/300], Step [90/225], Training Accuracy: 58.0729%, Training Loss: 0.8800%\n",
      "Epoch [18/300], Step [91/225], Training Accuracy: 58.0529%, Training Loss: 0.8803%\n",
      "Epoch [18/300], Step [92/225], Training Accuracy: 57.9484%, Training Loss: 0.8831%\n",
      "Epoch [18/300], Step [93/225], Training Accuracy: 58.0477%, Training Loss: 0.8818%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/300], Step [94/225], Training Accuracy: 58.1117%, Training Loss: 0.8799%\n",
      "Epoch [18/300], Step [95/225], Training Accuracy: 58.0592%, Training Loss: 0.8803%\n",
      "Epoch [18/300], Step [96/225], Training Accuracy: 58.2194%, Training Loss: 0.8790%\n",
      "Epoch [18/300], Step [97/225], Training Accuracy: 58.2152%, Training Loss: 0.8786%\n",
      "Epoch [18/300], Step [98/225], Training Accuracy: 58.2430%, Training Loss: 0.8789%\n",
      "Epoch [18/300], Step [99/225], Training Accuracy: 58.3176%, Training Loss: 0.8781%\n",
      "Epoch [18/300], Step [100/225], Training Accuracy: 58.2812%, Training Loss: 0.8789%\n",
      "Epoch [18/300], Step [101/225], Training Accuracy: 58.2921%, Training Loss: 0.8783%\n",
      "Epoch [18/300], Step [102/225], Training Accuracy: 58.3027%, Training Loss: 0.8784%\n",
      "Epoch [18/300], Step [103/225], Training Accuracy: 58.3434%, Training Loss: 0.8784%\n",
      "Epoch [18/300], Step [104/225], Training Accuracy: 58.3233%, Training Loss: 0.8789%\n",
      "Epoch [18/300], Step [105/225], Training Accuracy: 58.3929%, Training Loss: 0.8776%\n",
      "Epoch [18/300], Step [106/225], Training Accuracy: 58.4021%, Training Loss: 0.8769%\n",
      "Epoch [18/300], Step [107/225], Training Accuracy: 58.3382%, Training Loss: 0.8782%\n",
      "Epoch [18/300], Step [108/225], Training Accuracy: 58.2755%, Training Loss: 0.8790%\n",
      "Epoch [18/300], Step [109/225], Training Accuracy: 58.3429%, Training Loss: 0.8789%\n",
      "Epoch [18/300], Step [110/225], Training Accuracy: 58.2955%, Training Loss: 0.8792%\n",
      "Epoch [18/300], Step [111/225], Training Accuracy: 58.3193%, Training Loss: 0.8787%\n",
      "Epoch [18/300], Step [112/225], Training Accuracy: 58.3845%, Training Loss: 0.8780%\n",
      "Epoch [18/300], Step [113/225], Training Accuracy: 58.3794%, Training Loss: 0.8782%\n",
      "Epoch [18/300], Step [114/225], Training Accuracy: 58.4019%, Training Loss: 0.8772%\n",
      "Epoch [18/300], Step [115/225], Training Accuracy: 58.4103%, Training Loss: 0.8764%\n",
      "Epoch [18/300], Step [116/225], Training Accuracy: 58.4186%, Training Loss: 0.8766%\n",
      "Epoch [18/300], Step [117/225], Training Accuracy: 58.3200%, Training Loss: 0.8778%\n",
      "Epoch [18/300], Step [118/225], Training Accuracy: 58.3289%, Training Loss: 0.8769%\n",
      "Epoch [18/300], Step [119/225], Training Accuracy: 58.3640%, Training Loss: 0.8767%\n",
      "Epoch [18/300], Step [120/225], Training Accuracy: 58.3464%, Training Loss: 0.8772%\n",
      "Epoch [18/300], Step [121/225], Training Accuracy: 58.1999%, Training Loss: 0.8785%\n",
      "Epoch [18/300], Step [122/225], Training Accuracy: 58.1967%, Training Loss: 0.8783%\n",
      "Epoch [18/300], Step [123/225], Training Accuracy: 58.2063%, Training Loss: 0.8779%\n",
      "Epoch [18/300], Step [124/225], Training Accuracy: 58.1905%, Training Loss: 0.8773%\n",
      "Epoch [18/300], Step [125/225], Training Accuracy: 58.1125%, Training Loss: 0.8793%\n",
      "Epoch [18/300], Step [126/225], Training Accuracy: 58.0605%, Training Loss: 0.8802%\n",
      "Epoch [18/300], Step [127/225], Training Accuracy: 57.9847%, Training Loss: 0.8805%\n",
      "Epoch [18/300], Step [128/225], Training Accuracy: 57.9712%, Training Loss: 0.8807%\n",
      "Epoch [18/300], Step [129/225], Training Accuracy: 57.9821%, Training Loss: 0.8807%\n",
      "Epoch [18/300], Step [130/225], Training Accuracy: 57.9087%, Training Loss: 0.8817%\n",
      "Epoch [18/300], Step [131/225], Training Accuracy: 57.8960%, Training Loss: 0.8823%\n",
      "Epoch [18/300], Step [132/225], Training Accuracy: 57.8717%, Training Loss: 0.8826%\n",
      "Epoch [18/300], Step [133/225], Training Accuracy: 57.9300%, Training Loss: 0.8823%\n",
      "Epoch [18/300], Step [134/225], Training Accuracy: 57.8358%, Training Loss: 0.8837%\n",
      "Epoch [18/300], Step [135/225], Training Accuracy: 57.8472%, Training Loss: 0.8837%\n",
      "Epoch [18/300], Step [136/225], Training Accuracy: 57.9044%, Training Loss: 0.8835%\n",
      "Epoch [18/300], Step [137/225], Training Accuracy: 57.9608%, Training Loss: 0.8836%\n",
      "Epoch [18/300], Step [138/225], Training Accuracy: 58.0389%, Training Loss: 0.8823%\n",
      "Epoch [18/300], Step [139/225], Training Accuracy: 58.0148%, Training Loss: 0.8819%\n",
      "Epoch [18/300], Step [140/225], Training Accuracy: 58.0469%, Training Loss: 0.8814%\n",
      "Epoch [18/300], Step [141/225], Training Accuracy: 58.0563%, Training Loss: 0.8811%\n",
      "Epoch [18/300], Step [142/225], Training Accuracy: 58.0876%, Training Loss: 0.8805%\n",
      "Epoch [18/300], Step [143/225], Training Accuracy: 58.0747%, Training Loss: 0.8804%\n",
      "Epoch [18/300], Step [144/225], Training Accuracy: 57.9970%, Training Loss: 0.8805%\n",
      "Epoch [18/300], Step [145/225], Training Accuracy: 58.0172%, Training Loss: 0.8797%\n",
      "Epoch [18/300], Step [146/225], Training Accuracy: 57.9409%, Training Loss: 0.8809%\n",
      "Epoch [18/300], Step [147/225], Training Accuracy: 57.9826%, Training Loss: 0.8804%\n",
      "Epoch [18/300], Step [148/225], Training Accuracy: 58.0131%, Training Loss: 0.8796%\n",
      "Epoch [18/300], Step [149/225], Training Accuracy: 58.0432%, Training Loss: 0.8792%\n",
      "Epoch [18/300], Step [150/225], Training Accuracy: 58.0208%, Training Loss: 0.8787%\n",
      "Epoch [18/300], Step [151/225], Training Accuracy: 58.0298%, Training Loss: 0.8784%\n",
      "Epoch [18/300], Step [152/225], Training Accuracy: 57.9564%, Training Loss: 0.8789%\n",
      "Epoch [18/300], Step [153/225], Training Accuracy: 57.9453%, Training Loss: 0.8786%\n",
      "Epoch [18/300], Step [154/225], Training Accuracy: 57.9545%, Training Loss: 0.8783%\n",
      "Epoch [18/300], Step [155/225], Training Accuracy: 57.9032%, Training Loss: 0.8787%\n",
      "Epoch [18/300], Step [156/225], Training Accuracy: 57.8726%, Training Loss: 0.8793%\n",
      "Epoch [18/300], Step [157/225], Training Accuracy: 57.9419%, Training Loss: 0.8783%\n",
      "Epoch [18/300], Step [158/225], Training Accuracy: 57.8718%, Training Loss: 0.8795%\n",
      "Epoch [18/300], Step [159/225], Training Accuracy: 57.8420%, Training Loss: 0.8793%\n",
      "Epoch [18/300], Step [160/225], Training Accuracy: 57.8613%, Training Loss: 0.8788%\n",
      "Epoch [18/300], Step [161/225], Training Accuracy: 57.8513%, Training Loss: 0.8793%\n",
      "Epoch [18/300], Step [162/225], Training Accuracy: 57.8607%, Training Loss: 0.8796%\n",
      "Epoch [18/300], Step [163/225], Training Accuracy: 57.8892%, Training Loss: 0.8794%\n",
      "Epoch [18/300], Step [164/225], Training Accuracy: 57.8792%, Training Loss: 0.8793%\n",
      "Epoch [18/300], Step [165/225], Training Accuracy: 57.8598%, Training Loss: 0.8793%\n",
      "Epoch [18/300], Step [166/225], Training Accuracy: 57.8502%, Training Loss: 0.8786%\n",
      "Epoch [18/300], Step [167/225], Training Accuracy: 57.8593%, Training Loss: 0.8782%\n",
      "Epoch [18/300], Step [168/225], Training Accuracy: 57.7939%, Training Loss: 0.8785%\n",
      "Epoch [18/300], Step [169/225], Training Accuracy: 57.9142%, Training Loss: 0.8776%\n",
      "Epoch [18/300], Step [170/225], Training Accuracy: 57.9228%, Training Loss: 0.8777%\n",
      "Epoch [18/300], Step [171/225], Training Accuracy: 57.9587%, Training Loss: 0.8772%\n",
      "Epoch [18/300], Step [172/225], Training Accuracy: 57.9488%, Training Loss: 0.8771%\n",
      "Epoch [18/300], Step [173/225], Training Accuracy: 57.9480%, Training Loss: 0.8770%\n",
      "Epoch [18/300], Step [174/225], Training Accuracy: 57.9921%, Training Loss: 0.8765%\n",
      "Epoch [18/300], Step [175/225], Training Accuracy: 58.0089%, Training Loss: 0.8764%\n",
      "Epoch [18/300], Step [176/225], Training Accuracy: 57.9723%, Training Loss: 0.8764%\n",
      "Epoch [18/300], Step [177/225], Training Accuracy: 58.0067%, Training Loss: 0.8760%\n",
      "Epoch [18/300], Step [178/225], Training Accuracy: 57.9793%, Training Loss: 0.8760%\n",
      "Epoch [18/300], Step [179/225], Training Accuracy: 58.0045%, Training Loss: 0.8753%\n",
      "Epoch [18/300], Step [180/225], Training Accuracy: 58.0642%, Training Loss: 0.8740%\n",
      "Epoch [18/300], Step [181/225], Training Accuracy: 58.0801%, Training Loss: 0.8743%\n",
      "Epoch [18/300], Step [182/225], Training Accuracy: 58.1044%, Training Loss: 0.8738%\n",
      "Epoch [18/300], Step [183/225], Training Accuracy: 58.1028%, Training Loss: 0.8739%\n",
      "Epoch [18/300], Step [184/225], Training Accuracy: 58.1267%, Training Loss: 0.8736%\n",
      "Epoch [18/300], Step [185/225], Training Accuracy: 58.1419%, Training Loss: 0.8740%\n",
      "Epoch [18/300], Step [186/225], Training Accuracy: 58.1233%, Training Loss: 0.8734%\n",
      "Epoch [18/300], Step [187/225], Training Accuracy: 58.1467%, Training Loss: 0.8727%\n",
      "Epoch [18/300], Step [188/225], Training Accuracy: 58.1616%, Training Loss: 0.8722%\n",
      "Epoch [18/300], Step [189/225], Training Accuracy: 58.1597%, Training Loss: 0.8719%\n",
      "Epoch [18/300], Step [190/225], Training Accuracy: 58.1332%, Training Loss: 0.8719%\n",
      "Epoch [18/300], Step [191/225], Training Accuracy: 58.1152%, Training Loss: 0.8717%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/300], Step [192/225], Training Accuracy: 58.1950%, Training Loss: 0.8704%\n",
      "Epoch [18/300], Step [193/225], Training Accuracy: 58.1525%, Training Loss: 0.8710%\n",
      "Epoch [18/300], Step [194/225], Training Accuracy: 58.1105%, Training Loss: 0.8716%\n",
      "Epoch [18/300], Step [195/225], Training Accuracy: 58.1651%, Training Loss: 0.8708%\n",
      "Epoch [18/300], Step [196/225], Training Accuracy: 58.1473%, Training Loss: 0.8712%\n",
      "Epoch [18/300], Step [197/225], Training Accuracy: 58.1694%, Training Loss: 0.8709%\n",
      "Epoch [18/300], Step [198/225], Training Accuracy: 58.1755%, Training Loss: 0.8701%\n",
      "Epoch [18/300], Step [199/225], Training Accuracy: 58.1737%, Training Loss: 0.8696%\n",
      "Epoch [18/300], Step [200/225], Training Accuracy: 58.1875%, Training Loss: 0.8692%\n",
      "Epoch [18/300], Step [201/225], Training Accuracy: 58.1312%, Training Loss: 0.8697%\n",
      "Epoch [18/300], Step [202/225], Training Accuracy: 58.1296%, Training Loss: 0.8696%\n",
      "Epoch [18/300], Step [203/225], Training Accuracy: 58.1743%, Training Loss: 0.8690%\n",
      "Epoch [18/300], Step [204/225], Training Accuracy: 58.1801%, Training Loss: 0.8693%\n",
      "Epoch [18/300], Step [205/225], Training Accuracy: 58.1936%, Training Loss: 0.8688%\n",
      "Epoch [18/300], Step [206/225], Training Accuracy: 58.1462%, Training Loss: 0.8695%\n",
      "Epoch [18/300], Step [207/225], Training Accuracy: 58.1446%, Training Loss: 0.8699%\n",
      "Epoch [18/300], Step [208/225], Training Accuracy: 58.2031%, Training Loss: 0.8693%\n",
      "Epoch [18/300], Step [209/225], Training Accuracy: 58.2237%, Training Loss: 0.8694%\n",
      "Epoch [18/300], Step [210/225], Training Accuracy: 58.2143%, Training Loss: 0.8694%\n",
      "Epoch [18/300], Step [211/225], Training Accuracy: 58.2198%, Training Loss: 0.8689%\n",
      "Epoch [18/300], Step [212/225], Training Accuracy: 58.2031%, Training Loss: 0.8693%\n",
      "Epoch [18/300], Step [213/225], Training Accuracy: 58.1793%, Training Loss: 0.8700%\n",
      "Epoch [18/300], Step [214/225], Training Accuracy: 58.1922%, Training Loss: 0.8693%\n",
      "Epoch [18/300], Step [215/225], Training Accuracy: 58.2049%, Training Loss: 0.8690%\n",
      "Epoch [18/300], Step [216/225], Training Accuracy: 58.2465%, Training Loss: 0.8690%\n",
      "Epoch [18/300], Step [217/225], Training Accuracy: 58.2157%, Training Loss: 0.8693%\n",
      "Epoch [18/300], Step [218/225], Training Accuracy: 58.2210%, Training Loss: 0.8698%\n",
      "Epoch [18/300], Step [219/225], Training Accuracy: 58.2049%, Training Loss: 0.8702%\n",
      "Epoch [18/300], Step [220/225], Training Accuracy: 58.2173%, Training Loss: 0.8699%\n",
      "Epoch [18/300], Step [221/225], Training Accuracy: 58.2508%, Training Loss: 0.8698%\n",
      "Epoch [18/300], Step [222/225], Training Accuracy: 58.2278%, Training Loss: 0.8694%\n",
      "Epoch [18/300], Step [223/225], Training Accuracy: 58.2539%, Training Loss: 0.8690%\n",
      "Epoch [18/300], Step [224/225], Training Accuracy: 58.2729%, Training Loss: 0.8685%\n",
      "Epoch [18/300], Step [225/225], Training Accuracy: 58.2893%, Training Loss: 0.8684%\n",
      "Epoch [19/300], Step [1/225], Training Accuracy: 76.5625%, Training Loss: 0.6197%\n",
      "Epoch [19/300], Step [2/225], Training Accuracy: 71.0938%, Training Loss: 0.7220%\n",
      "Epoch [19/300], Step [3/225], Training Accuracy: 64.5833%, Training Loss: 0.7968%\n",
      "Epoch [19/300], Step [4/225], Training Accuracy: 63.6719%, Training Loss: 0.8009%\n",
      "Epoch [19/300], Step [5/225], Training Accuracy: 64.3750%, Training Loss: 0.8076%\n",
      "Epoch [19/300], Step [6/225], Training Accuracy: 62.7604%, Training Loss: 0.8234%\n",
      "Epoch [19/300], Step [7/225], Training Accuracy: 61.8304%, Training Loss: 0.8378%\n",
      "Epoch [19/300], Step [8/225], Training Accuracy: 60.9375%, Training Loss: 0.8529%\n",
      "Epoch [19/300], Step [9/225], Training Accuracy: 60.5903%, Training Loss: 0.8506%\n",
      "Epoch [19/300], Step [10/225], Training Accuracy: 59.8438%, Training Loss: 0.8694%\n",
      "Epoch [19/300], Step [11/225], Training Accuracy: 59.6591%, Training Loss: 0.8736%\n",
      "Epoch [19/300], Step [12/225], Training Accuracy: 60.1562%, Training Loss: 0.8726%\n",
      "Epoch [19/300], Step [13/225], Training Accuracy: 61.0577%, Training Loss: 0.8527%\n",
      "Epoch [19/300], Step [14/225], Training Accuracy: 60.6027%, Training Loss: 0.8568%\n",
      "Epoch [19/300], Step [15/225], Training Accuracy: 60.6250%, Training Loss: 0.8556%\n",
      "Epoch [19/300], Step [16/225], Training Accuracy: 60.2539%, Training Loss: 0.8617%\n",
      "Epoch [19/300], Step [17/225], Training Accuracy: 60.0184%, Training Loss: 0.8621%\n",
      "Epoch [19/300], Step [18/225], Training Accuracy: 59.7222%, Training Loss: 0.8630%\n",
      "Epoch [19/300], Step [19/225], Training Accuracy: 60.0329%, Training Loss: 0.8584%\n",
      "Epoch [19/300], Step [20/225], Training Accuracy: 60.5469%, Training Loss: 0.8506%\n",
      "Epoch [19/300], Step [21/225], Training Accuracy: 60.4911%, Training Loss: 0.8519%\n",
      "Epoch [19/300], Step [22/225], Training Accuracy: 59.8011%, Training Loss: 0.8574%\n",
      "Epoch [19/300], Step [23/225], Training Accuracy: 59.9185%, Training Loss: 0.8540%\n",
      "Epoch [19/300], Step [24/225], Training Accuracy: 59.7656%, Training Loss: 0.8568%\n",
      "Epoch [19/300], Step [25/225], Training Accuracy: 59.8750%, Training Loss: 0.8569%\n",
      "Epoch [19/300], Step [26/225], Training Accuracy: 59.5553%, Training Loss: 0.8599%\n",
      "Epoch [19/300], Step [27/225], Training Accuracy: 59.4329%, Training Loss: 0.8647%\n",
      "Epoch [19/300], Step [28/225], Training Accuracy: 59.5982%, Training Loss: 0.8610%\n",
      "Epoch [19/300], Step [29/225], Training Accuracy: 59.6444%, Training Loss: 0.8576%\n",
      "Epoch [19/300], Step [30/225], Training Accuracy: 59.6354%, Training Loss: 0.8587%\n",
      "Epoch [19/300], Step [31/225], Training Accuracy: 59.5766%, Training Loss: 0.8596%\n",
      "Epoch [19/300], Step [32/225], Training Accuracy: 59.4727%, Training Loss: 0.8583%\n",
      "Epoch [19/300], Step [33/225], Training Accuracy: 59.4223%, Training Loss: 0.8554%\n",
      "Epoch [19/300], Step [34/225], Training Accuracy: 59.2831%, Training Loss: 0.8584%\n",
      "Epoch [19/300], Step [35/225], Training Accuracy: 59.1964%, Training Loss: 0.8607%\n",
      "Epoch [19/300], Step [36/225], Training Accuracy: 59.2882%, Training Loss: 0.8598%\n",
      "Epoch [19/300], Step [37/225], Training Accuracy: 59.4595%, Training Loss: 0.8570%\n",
      "Epoch [19/300], Step [38/225], Training Accuracy: 59.4161%, Training Loss: 0.8561%\n",
      "Epoch [19/300], Step [39/225], Training Accuracy: 59.3750%, Training Loss: 0.8579%\n",
      "Epoch [19/300], Step [40/225], Training Accuracy: 59.0625%, Training Loss: 0.8591%\n",
      "Epoch [19/300], Step [41/225], Training Accuracy: 58.8796%, Training Loss: 0.8638%\n",
      "Epoch [19/300], Step [42/225], Training Accuracy: 58.7798%, Training Loss: 0.8645%\n",
      "Epoch [19/300], Step [43/225], Training Accuracy: 58.9026%, Training Loss: 0.8620%\n",
      "Epoch [19/300], Step [44/225], Training Accuracy: 58.9134%, Training Loss: 0.8598%\n",
      "Epoch [19/300], Step [45/225], Training Accuracy: 59.0625%, Training Loss: 0.8582%\n",
      "Epoch [19/300], Step [46/225], Training Accuracy: 58.9674%, Training Loss: 0.8564%\n",
      "Epoch [19/300], Step [47/225], Training Accuracy: 58.8431%, Training Loss: 0.8577%\n",
      "Epoch [19/300], Step [48/225], Training Accuracy: 58.7240%, Training Loss: 0.8587%\n",
      "Epoch [19/300], Step [49/225], Training Accuracy: 59.0880%, Training Loss: 0.8555%\n",
      "Epoch [19/300], Step [50/225], Training Accuracy: 59.1250%, Training Loss: 0.8546%\n",
      "Epoch [19/300], Step [51/225], Training Accuracy: 59.3137%, Training Loss: 0.8510%\n",
      "Epoch [19/300], Step [52/225], Training Accuracy: 59.4351%, Training Loss: 0.8477%\n",
      "Epoch [19/300], Step [53/225], Training Accuracy: 59.6698%, Training Loss: 0.8477%\n",
      "Epoch [19/300], Step [54/225], Training Accuracy: 59.6354%, Training Loss: 0.8485%\n",
      "Epoch [19/300], Step [55/225], Training Accuracy: 59.5170%, Training Loss: 0.8496%\n",
      "Epoch [19/300], Step [56/225], Training Accuracy: 59.4587%, Training Loss: 0.8501%\n",
      "Epoch [19/300], Step [57/225], Training Accuracy: 59.4298%, Training Loss: 0.8490%\n",
      "Epoch [19/300], Step [58/225], Training Accuracy: 59.5636%, Training Loss: 0.8478%\n",
      "Epoch [19/300], Step [59/225], Training Accuracy: 59.6398%, Training Loss: 0.8463%\n",
      "Epoch [19/300], Step [60/225], Training Accuracy: 59.8177%, Training Loss: 0.8438%\n",
      "Epoch [19/300], Step [61/225], Training Accuracy: 59.8617%, Training Loss: 0.8428%\n",
      "Epoch [19/300], Step [62/225], Training Accuracy: 59.9042%, Training Loss: 0.8419%\n",
      "Epoch [19/300], Step [63/225], Training Accuracy: 59.8214%, Training Loss: 0.8440%\n",
      "Epoch [19/300], Step [64/225], Training Accuracy: 59.9365%, Training Loss: 0.8452%\n",
      "Epoch [19/300], Step [65/225], Training Accuracy: 60.0481%, Training Loss: 0.8443%\n",
      "Epoch [19/300], Step [66/225], Training Accuracy: 60.1326%, Training Loss: 0.8430%\n",
      "Epoch [19/300], Step [67/225], Training Accuracy: 60.0047%, Training Loss: 0.8446%\n",
      "Epoch [19/300], Step [68/225], Training Accuracy: 59.9494%, Training Loss: 0.8455%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/300], Step [69/225], Training Accuracy: 59.9185%, Training Loss: 0.8463%\n",
      "Epoch [19/300], Step [70/225], Training Accuracy: 59.6652%, Training Loss: 0.8500%\n",
      "Epoch [19/300], Step [71/225], Training Accuracy: 59.7931%, Training Loss: 0.8489%\n",
      "Epoch [19/300], Step [72/225], Training Accuracy: 59.6788%, Training Loss: 0.8503%\n",
      "Epoch [19/300], Step [73/225], Training Accuracy: 59.5890%, Training Loss: 0.8521%\n",
      "Epoch [19/300], Step [74/225], Training Accuracy: 59.7973%, Training Loss: 0.8490%\n",
      "Epoch [19/300], Step [75/225], Training Accuracy: 59.6875%, Training Loss: 0.8499%\n",
      "Epoch [19/300], Step [76/225], Training Accuracy: 59.7656%, Training Loss: 0.8497%\n",
      "Epoch [19/300], Step [77/225], Training Accuracy: 59.8011%, Training Loss: 0.8489%\n",
      "Epoch [19/300], Step [78/225], Training Accuracy: 59.7957%, Training Loss: 0.8493%\n",
      "Epoch [19/300], Step [79/225], Training Accuracy: 59.7706%, Training Loss: 0.8496%\n",
      "Epoch [19/300], Step [80/225], Training Accuracy: 59.6094%, Training Loss: 0.8516%\n",
      "Epoch [19/300], Step [81/225], Training Accuracy: 59.5872%, Training Loss: 0.8521%\n",
      "Epoch [19/300], Step [82/225], Training Accuracy: 59.6608%, Training Loss: 0.8510%\n",
      "Epoch [19/300], Step [83/225], Training Accuracy: 59.6197%, Training Loss: 0.8518%\n",
      "Epoch [19/300], Step [84/225], Training Accuracy: 59.6540%, Training Loss: 0.8516%\n",
      "Epoch [19/300], Step [85/225], Training Accuracy: 59.7610%, Training Loss: 0.8497%\n",
      "Epoch [19/300], Step [86/225], Training Accuracy: 59.8837%, Training Loss: 0.8482%\n",
      "Epoch [19/300], Step [87/225], Training Accuracy: 59.8779%, Training Loss: 0.8487%\n",
      "Epoch [19/300], Step [88/225], Training Accuracy: 59.8189%, Training Loss: 0.8493%\n",
      "Epoch [19/300], Step [89/225], Training Accuracy: 59.8666%, Training Loss: 0.8502%\n",
      "Epoch [19/300], Step [90/225], Training Accuracy: 59.8611%, Training Loss: 0.8505%\n",
      "Epoch [19/300], Step [91/225], Training Accuracy: 59.8214%, Training Loss: 0.8495%\n",
      "Epoch [19/300], Step [92/225], Training Accuracy: 59.8166%, Training Loss: 0.8498%\n",
      "Epoch [19/300], Step [93/225], Training Accuracy: 59.8622%, Training Loss: 0.8489%\n",
      "Epoch [19/300], Step [94/225], Training Accuracy: 59.9402%, Training Loss: 0.8472%\n",
      "Epoch [19/300], Step [95/225], Training Accuracy: 59.9178%, Training Loss: 0.8478%\n",
      "Epoch [19/300], Step [96/225], Training Accuracy: 60.0260%, Training Loss: 0.8460%\n",
      "Epoch [19/300], Step [97/225], Training Accuracy: 60.1321%, Training Loss: 0.8447%\n",
      "Epoch [19/300], Step [98/225], Training Accuracy: 60.1244%, Training Loss: 0.8442%\n",
      "Epoch [19/300], Step [99/225], Training Accuracy: 60.1168%, Training Loss: 0.8438%\n",
      "Epoch [19/300], Step [100/225], Training Accuracy: 60.0156%, Training Loss: 0.8456%\n",
      "Epoch [19/300], Step [101/225], Training Accuracy: 60.0093%, Training Loss: 0.8456%\n",
      "Epoch [19/300], Step [102/225], Training Accuracy: 60.0490%, Training Loss: 0.8458%\n",
      "Epoch [19/300], Step [103/225], Training Accuracy: 60.1183%, Training Loss: 0.8446%\n",
      "Epoch [19/300], Step [104/225], Training Accuracy: 60.1262%, Training Loss: 0.8440%\n",
      "Epoch [19/300], Step [105/225], Training Accuracy: 60.0595%, Training Loss: 0.8436%\n",
      "Epoch [19/300], Step [106/225], Training Accuracy: 60.0531%, Training Loss: 0.8430%\n",
      "Epoch [19/300], Step [107/225], Training Accuracy: 60.0029%, Training Loss: 0.8431%\n",
      "Epoch [19/300], Step [108/225], Training Accuracy: 59.9826%, Training Loss: 0.8431%\n",
      "Epoch [19/300], Step [109/225], Training Accuracy: 59.9914%, Training Loss: 0.8427%\n",
      "Epoch [19/300], Step [110/225], Training Accuracy: 60.0000%, Training Loss: 0.8420%\n",
      "Epoch [19/300], Step [111/225], Training Accuracy: 60.0366%, Training Loss: 0.8413%\n",
      "Epoch [19/300], Step [112/225], Training Accuracy: 60.0725%, Training Loss: 0.8413%\n",
      "Epoch [19/300], Step [113/225], Training Accuracy: 60.0525%, Training Loss: 0.8412%\n",
      "Epoch [19/300], Step [114/225], Training Accuracy: 60.0055%, Training Loss: 0.8406%\n",
      "Epoch [19/300], Step [115/225], Training Accuracy: 60.0679%, Training Loss: 0.8392%\n",
      "Epoch [19/300], Step [116/225], Training Accuracy: 60.0350%, Training Loss: 0.8394%\n",
      "Epoch [19/300], Step [117/225], Training Accuracy: 59.9626%, Training Loss: 0.8411%\n",
      "Epoch [19/300], Step [118/225], Training Accuracy: 59.9311%, Training Loss: 0.8406%\n",
      "Epoch [19/300], Step [119/225], Training Accuracy: 59.9396%, Training Loss: 0.8401%\n",
      "Epoch [19/300], Step [120/225], Training Accuracy: 59.9479%, Training Loss: 0.8399%\n",
      "Epoch [19/300], Step [121/225], Training Accuracy: 59.8657%, Training Loss: 0.8411%\n",
      "Epoch [19/300], Step [122/225], Training Accuracy: 59.9001%, Training Loss: 0.8404%\n",
      "Epoch [19/300], Step [123/225], Training Accuracy: 59.9466%, Training Loss: 0.8399%\n",
      "Epoch [19/300], Step [124/225], Training Accuracy: 59.8916%, Training Loss: 0.8399%\n",
      "Epoch [19/300], Step [125/225], Training Accuracy: 59.8375%, Training Loss: 0.8407%\n",
      "Epoch [19/300], Step [126/225], Training Accuracy: 59.7718%, Training Loss: 0.8420%\n",
      "Epoch [19/300], Step [127/225], Training Accuracy: 59.6826%, Training Loss: 0.8436%\n",
      "Epoch [19/300], Step [128/225], Training Accuracy: 59.6069%, Training Loss: 0.8444%\n",
      "Epoch [19/300], Step [129/225], Training Accuracy: 59.6294%, Training Loss: 0.8445%\n",
      "Epoch [19/300], Step [130/225], Training Accuracy: 59.6274%, Training Loss: 0.8449%\n",
      "Epoch [19/300], Step [131/225], Training Accuracy: 59.6493%, Training Loss: 0.8451%\n",
      "Epoch [19/300], Step [132/225], Training Accuracy: 59.5881%, Training Loss: 0.8458%\n",
      "Epoch [19/300], Step [133/225], Training Accuracy: 59.6100%, Training Loss: 0.8464%\n",
      "Epoch [19/300], Step [134/225], Training Accuracy: 59.5266%, Training Loss: 0.8481%\n",
      "Epoch [19/300], Step [135/225], Training Accuracy: 59.5255%, Training Loss: 0.8473%\n",
      "Epoch [19/300], Step [136/225], Training Accuracy: 59.5358%, Training Loss: 0.8475%\n",
      "Epoch [19/300], Step [137/225], Training Accuracy: 59.5461%, Training Loss: 0.8475%\n",
      "Epoch [19/300], Step [138/225], Training Accuracy: 59.5901%, Training Loss: 0.8467%\n",
      "Epoch [19/300], Step [139/225], Training Accuracy: 59.5211%, Training Loss: 0.8467%\n",
      "Epoch [19/300], Step [140/225], Training Accuracy: 59.5201%, Training Loss: 0.8466%\n",
      "Epoch [19/300], Step [141/225], Training Accuracy: 59.5301%, Training Loss: 0.8466%\n",
      "Epoch [19/300], Step [142/225], Training Accuracy: 59.4850%, Training Loss: 0.8474%\n",
      "Epoch [19/300], Step [143/225], Training Accuracy: 59.4624%, Training Loss: 0.8474%\n",
      "Epoch [19/300], Step [144/225], Training Accuracy: 59.3533%, Training Loss: 0.8488%\n",
      "Epoch [19/300], Step [145/225], Training Accuracy: 59.3427%, Training Loss: 0.8482%\n",
      "Epoch [19/300], Step [146/225], Training Accuracy: 59.3001%, Training Loss: 0.8496%\n",
      "Epoch [19/300], Step [147/225], Training Accuracy: 59.2581%, Training Loss: 0.8498%\n",
      "Epoch [19/300], Step [148/225], Training Accuracy: 59.2694%, Training Loss: 0.8491%\n",
      "Epoch [19/300], Step [149/225], Training Accuracy: 59.2596%, Training Loss: 0.8487%\n",
      "Epoch [19/300], Step [150/225], Training Accuracy: 59.2396%, Training Loss: 0.8480%\n",
      "Epoch [19/300], Step [151/225], Training Accuracy: 59.2922%, Training Loss: 0.8476%\n",
      "Epoch [19/300], Step [152/225], Training Accuracy: 59.2619%, Training Loss: 0.8484%\n",
      "Epoch [19/300], Step [153/225], Training Accuracy: 59.2320%, Training Loss: 0.8482%\n",
      "Epoch [19/300], Step [154/225], Training Accuracy: 59.2228%, Training Loss: 0.8480%\n",
      "Epoch [19/300], Step [155/225], Training Accuracy: 59.2036%, Training Loss: 0.8479%\n",
      "Epoch [19/300], Step [156/225], Training Accuracy: 59.1546%, Training Loss: 0.8491%\n",
      "Epoch [19/300], Step [157/225], Training Accuracy: 59.2158%, Training Loss: 0.8483%\n",
      "Epoch [19/300], Step [158/225], Training Accuracy: 59.1574%, Training Loss: 0.8493%\n",
      "Epoch [19/300], Step [159/225], Training Accuracy: 59.1686%, Training Loss: 0.8491%\n",
      "Epoch [19/300], Step [160/225], Training Accuracy: 59.1992%, Training Loss: 0.8487%\n",
      "Epoch [19/300], Step [161/225], Training Accuracy: 59.2488%, Training Loss: 0.8486%\n",
      "Epoch [19/300], Step [162/225], Training Accuracy: 59.3268%, Training Loss: 0.8482%\n",
      "Epoch [19/300], Step [163/225], Training Accuracy: 59.3654%, Training Loss: 0.8476%\n",
      "Epoch [19/300], Step [164/225], Training Accuracy: 59.3845%, Training Loss: 0.8474%\n",
      "Epoch [19/300], Step [165/225], Training Accuracy: 59.3561%, Training Loss: 0.8476%\n",
      "Epoch [19/300], Step [166/225], Training Accuracy: 59.3938%, Training Loss: 0.8468%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/300], Step [167/225], Training Accuracy: 59.4218%, Training Loss: 0.8465%\n",
      "Epoch [19/300], Step [168/225], Training Accuracy: 59.3564%, Training Loss: 0.8476%\n",
      "Epoch [19/300], Step [169/225], Training Accuracy: 59.4397%, Training Loss: 0.8465%\n",
      "Epoch [19/300], Step [170/225], Training Accuracy: 59.4669%, Training Loss: 0.8466%\n",
      "Epoch [19/300], Step [171/225], Training Accuracy: 59.5029%, Training Loss: 0.8462%\n",
      "Epoch [19/300], Step [172/225], Training Accuracy: 59.5022%, Training Loss: 0.8462%\n",
      "Epoch [19/300], Step [173/225], Training Accuracy: 59.5376%, Training Loss: 0.8457%\n",
      "Epoch [19/300], Step [174/225], Training Accuracy: 59.5815%, Training Loss: 0.8461%\n",
      "Epoch [19/300], Step [175/225], Training Accuracy: 59.5982%, Training Loss: 0.8460%\n",
      "Epoch [19/300], Step [176/225], Training Accuracy: 59.6147%, Training Loss: 0.8458%\n",
      "Epoch [19/300], Step [177/225], Training Accuracy: 59.6222%, Training Loss: 0.8454%\n",
      "Epoch [19/300], Step [178/225], Training Accuracy: 59.6208%, Training Loss: 0.8450%\n",
      "Epoch [19/300], Step [179/225], Training Accuracy: 59.6980%, Training Loss: 0.8440%\n",
      "Epoch [19/300], Step [180/225], Training Accuracy: 59.7222%, Training Loss: 0.8432%\n",
      "Epoch [19/300], Step [181/225], Training Accuracy: 59.6944%, Training Loss: 0.8439%\n",
      "Epoch [19/300], Step [182/225], Training Accuracy: 59.7871%, Training Loss: 0.8436%\n",
      "Epoch [19/300], Step [183/225], Training Accuracy: 59.7421%, Training Loss: 0.8439%\n",
      "Epoch [19/300], Step [184/225], Training Accuracy: 59.7571%, Training Loss: 0.8440%\n",
      "Epoch [19/300], Step [185/225], Training Accuracy: 59.7804%, Training Loss: 0.8438%\n",
      "Epoch [19/300], Step [186/225], Training Accuracy: 59.7698%, Training Loss: 0.8435%\n",
      "Epoch [19/300], Step [187/225], Training Accuracy: 59.7844%, Training Loss: 0.8427%\n",
      "Epoch [19/300], Step [188/225], Training Accuracy: 59.8072%, Training Loss: 0.8424%\n",
      "Epoch [19/300], Step [189/225], Training Accuracy: 59.8132%, Training Loss: 0.8415%\n",
      "Epoch [19/300], Step [190/225], Training Accuracy: 59.8602%, Training Loss: 0.8409%\n",
      "Epoch [19/300], Step [191/225], Training Accuracy: 59.8577%, Training Loss: 0.8407%\n",
      "Epoch [19/300], Step [192/225], Training Accuracy: 59.8796%, Training Loss: 0.8401%\n",
      "Epoch [19/300], Step [193/225], Training Accuracy: 59.8203%, Training Loss: 0.8405%\n",
      "Epoch [19/300], Step [194/225], Training Accuracy: 59.7777%, Training Loss: 0.8417%\n",
      "Epoch [19/300], Step [195/225], Training Accuracy: 59.8478%, Training Loss: 0.8411%\n",
      "Epoch [19/300], Step [196/225], Training Accuracy: 59.8693%, Training Loss: 0.8410%\n",
      "Epoch [19/300], Step [197/225], Training Accuracy: 59.8826%, Training Loss: 0.8414%\n",
      "Epoch [19/300], Step [198/225], Training Accuracy: 59.8958%, Training Loss: 0.8407%\n",
      "Epoch [19/300], Step [199/225], Training Accuracy: 59.8932%, Training Loss: 0.8403%\n",
      "Epoch [19/300], Step [200/225], Training Accuracy: 59.8750%, Training Loss: 0.8405%\n",
      "Epoch [19/300], Step [201/225], Training Accuracy: 59.8336%, Training Loss: 0.8408%\n",
      "Epoch [19/300], Step [202/225], Training Accuracy: 59.8855%, Training Loss: 0.8405%\n",
      "Epoch [19/300], Step [203/225], Training Accuracy: 59.9138%, Training Loss: 0.8401%\n",
      "Epoch [19/300], Step [204/225], Training Accuracy: 59.9265%, Training Loss: 0.8399%\n",
      "Epoch [19/300], Step [205/225], Training Accuracy: 59.9466%, Training Loss: 0.8395%\n",
      "Epoch [19/300], Step [206/225], Training Accuracy: 59.9515%, Training Loss: 0.8396%\n",
      "Epoch [19/300], Step [207/225], Training Accuracy: 59.9562%, Training Loss: 0.8397%\n",
      "Epoch [19/300], Step [208/225], Training Accuracy: 59.9534%, Training Loss: 0.8395%\n",
      "Epoch [19/300], Step [209/225], Training Accuracy: 59.9432%, Training Loss: 0.8397%\n",
      "Epoch [19/300], Step [210/225], Training Accuracy: 59.9182%, Training Loss: 0.8400%\n",
      "Epoch [19/300], Step [211/225], Training Accuracy: 59.9452%, Training Loss: 0.8395%\n",
      "Epoch [19/300], Step [212/225], Training Accuracy: 59.9130%, Training Loss: 0.8397%\n",
      "Epoch [19/300], Step [213/225], Training Accuracy: 59.8665%, Training Loss: 0.8406%\n",
      "Epoch [19/300], Step [214/225], Training Accuracy: 59.8715%, Training Loss: 0.8402%\n",
      "Epoch [19/300], Step [215/225], Training Accuracy: 59.8619%, Training Loss: 0.8401%\n",
      "Epoch [19/300], Step [216/225], Training Accuracy: 59.8597%, Training Loss: 0.8405%\n",
      "Epoch [19/300], Step [217/225], Training Accuracy: 59.8430%, Training Loss: 0.8406%\n",
      "Epoch [19/300], Step [218/225], Training Accuracy: 59.8481%, Training Loss: 0.8409%\n",
      "Epoch [19/300], Step [219/225], Training Accuracy: 59.8316%, Training Loss: 0.8410%\n",
      "Epoch [19/300], Step [220/225], Training Accuracy: 59.8366%, Training Loss: 0.8408%\n",
      "Epoch [19/300], Step [221/225], Training Accuracy: 59.8346%, Training Loss: 0.8408%\n",
      "Epoch [19/300], Step [222/225], Training Accuracy: 59.8395%, Training Loss: 0.8404%\n",
      "Epoch [19/300], Step [223/225], Training Accuracy: 59.7814%, Training Loss: 0.8405%\n",
      "Epoch [19/300], Step [224/225], Training Accuracy: 59.7866%, Training Loss: 0.8401%\n",
      "Epoch [19/300], Step [225/225], Training Accuracy: 59.7763%, Training Loss: 0.8402%\n",
      "Epoch [20/300], Step [1/225], Training Accuracy: 79.6875%, Training Loss: 0.5706%\n",
      "Epoch [20/300], Step [2/225], Training Accuracy: 71.0938%, Training Loss: 0.7301%\n",
      "Epoch [20/300], Step [3/225], Training Accuracy: 67.7083%, Training Loss: 0.7902%\n",
      "Epoch [20/300], Step [4/225], Training Accuracy: 66.0156%, Training Loss: 0.8067%\n",
      "Epoch [20/300], Step [5/225], Training Accuracy: 65.9375%, Training Loss: 0.8069%\n",
      "Epoch [20/300], Step [6/225], Training Accuracy: 64.5833%, Training Loss: 0.8055%\n",
      "Epoch [20/300], Step [7/225], Training Accuracy: 63.6161%, Training Loss: 0.8108%\n",
      "Epoch [20/300], Step [8/225], Training Accuracy: 62.6953%, Training Loss: 0.8386%\n",
      "Epoch [20/300], Step [9/225], Training Accuracy: 62.8472%, Training Loss: 0.8317%\n",
      "Epoch [20/300], Step [10/225], Training Accuracy: 61.4062%, Training Loss: 0.8517%\n",
      "Epoch [20/300], Step [11/225], Training Accuracy: 61.2216%, Training Loss: 0.8565%\n",
      "Epoch [20/300], Step [12/225], Training Accuracy: 61.1979%, Training Loss: 0.8545%\n",
      "Epoch [20/300], Step [13/225], Training Accuracy: 62.3798%, Training Loss: 0.8352%\n",
      "Epoch [20/300], Step [14/225], Training Accuracy: 61.8304%, Training Loss: 0.8393%\n",
      "Epoch [20/300], Step [15/225], Training Accuracy: 61.7708%, Training Loss: 0.8373%\n",
      "Epoch [20/300], Step [16/225], Training Accuracy: 61.7188%, Training Loss: 0.8416%\n",
      "Epoch [20/300], Step [17/225], Training Accuracy: 61.7647%, Training Loss: 0.8382%\n",
      "Epoch [20/300], Step [18/225], Training Accuracy: 61.7188%, Training Loss: 0.8388%\n",
      "Epoch [20/300], Step [19/225], Training Accuracy: 61.6776%, Training Loss: 0.8383%\n",
      "Epoch [20/300], Step [20/225], Training Accuracy: 61.9531%, Training Loss: 0.8322%\n",
      "Epoch [20/300], Step [21/225], Training Accuracy: 61.7560%, Training Loss: 0.8362%\n",
      "Epoch [20/300], Step [22/225], Training Accuracy: 60.8665%, Training Loss: 0.8448%\n",
      "Epoch [20/300], Step [23/225], Training Accuracy: 60.8696%, Training Loss: 0.8437%\n",
      "Epoch [20/300], Step [24/225], Training Accuracy: 60.6120%, Training Loss: 0.8448%\n",
      "Epoch [20/300], Step [25/225], Training Accuracy: 60.7500%, Training Loss: 0.8428%\n",
      "Epoch [20/300], Step [26/225], Training Accuracy: 60.8173%, Training Loss: 0.8385%\n",
      "Epoch [20/300], Step [27/225], Training Accuracy: 60.8796%, Training Loss: 0.8395%\n",
      "Epoch [20/300], Step [28/225], Training Accuracy: 60.9933%, Training Loss: 0.8370%\n",
      "Epoch [20/300], Step [29/225], Training Accuracy: 61.0991%, Training Loss: 0.8343%\n",
      "Epoch [20/300], Step [30/225], Training Accuracy: 61.2500%, Training Loss: 0.8343%\n",
      "Epoch [20/300], Step [31/225], Training Accuracy: 61.1391%, Training Loss: 0.8357%\n",
      "Epoch [20/300], Step [32/225], Training Accuracy: 61.0840%, Training Loss: 0.8340%\n",
      "Epoch [20/300], Step [33/225], Training Accuracy: 61.0795%, Training Loss: 0.8316%\n",
      "Epoch [20/300], Step [34/225], Training Accuracy: 60.7996%, Training Loss: 0.8369%\n",
      "Epoch [20/300], Step [35/225], Training Accuracy: 60.6250%, Training Loss: 0.8371%\n",
      "Epoch [20/300], Step [36/225], Training Accuracy: 60.4601%, Training Loss: 0.8380%\n",
      "Epoch [20/300], Step [37/225], Training Accuracy: 60.6419%, Training Loss: 0.8346%\n",
      "Epoch [20/300], Step [38/225], Training Accuracy: 60.6086%, Training Loss: 0.8348%\n",
      "Epoch [20/300], Step [39/225], Training Accuracy: 60.5769%, Training Loss: 0.8363%\n",
      "Epoch [20/300], Step [40/225], Training Accuracy: 60.3516%, Training Loss: 0.8402%\n",
      "Epoch [20/300], Step [41/225], Training Accuracy: 60.0991%, Training Loss: 0.8453%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/300], Step [42/225], Training Accuracy: 59.8586%, Training Loss: 0.8488%\n",
      "Epoch [20/300], Step [43/225], Training Accuracy: 59.8837%, Training Loss: 0.8464%\n",
      "Epoch [20/300], Step [44/225], Training Accuracy: 60.0497%, Training Loss: 0.8452%\n",
      "Epoch [20/300], Step [45/225], Training Accuracy: 60.1736%, Training Loss: 0.8465%\n",
      "Epoch [20/300], Step [46/225], Training Accuracy: 60.3261%, Training Loss: 0.8435%\n",
      "Epoch [20/300], Step [47/225], Training Accuracy: 60.4056%, Training Loss: 0.8438%\n",
      "Epoch [20/300], Step [48/225], Training Accuracy: 60.2214%, Training Loss: 0.8449%\n",
      "Epoch [20/300], Step [49/225], Training Accuracy: 60.4273%, Training Loss: 0.8422%\n",
      "Epoch [20/300], Step [50/225], Training Accuracy: 60.3750%, Training Loss: 0.8418%\n",
      "Epoch [20/300], Step [51/225], Training Accuracy: 60.5699%, Training Loss: 0.8382%\n",
      "Epoch [20/300], Step [52/225], Training Accuracy: 60.7873%, Training Loss: 0.8349%\n",
      "Epoch [20/300], Step [53/225], Training Accuracy: 60.7311%, Training Loss: 0.8366%\n",
      "Epoch [20/300], Step [54/225], Training Accuracy: 60.5613%, Training Loss: 0.8382%\n",
      "Epoch [20/300], Step [55/225], Training Accuracy: 60.5114%, Training Loss: 0.8399%\n",
      "Epoch [20/300], Step [56/225], Training Accuracy: 60.4911%, Training Loss: 0.8406%\n",
      "Epoch [20/300], Step [57/225], Training Accuracy: 60.6360%, Training Loss: 0.8380%\n",
      "Epoch [20/300], Step [58/225], Training Accuracy: 60.6142%, Training Loss: 0.8377%\n",
      "Epoch [20/300], Step [59/225], Training Accuracy: 60.6462%, Training Loss: 0.8373%\n",
      "Epoch [20/300], Step [60/225], Training Accuracy: 60.7292%, Training Loss: 0.8354%\n",
      "Epoch [20/300], Step [61/225], Training Accuracy: 60.7070%, Training Loss: 0.8355%\n",
      "Epoch [20/300], Step [62/225], Training Accuracy: 60.9375%, Training Loss: 0.8330%\n",
      "Epoch [20/300], Step [63/225], Training Accuracy: 60.8879%, Training Loss: 0.8351%\n",
      "Epoch [20/300], Step [64/225], Training Accuracy: 60.9375%, Training Loss: 0.8368%\n",
      "Epoch [20/300], Step [65/225], Training Accuracy: 60.8173%, Training Loss: 0.8374%\n",
      "Epoch [20/300], Step [66/225], Training Accuracy: 60.9375%, Training Loss: 0.8356%\n",
      "Epoch [20/300], Step [67/225], Training Accuracy: 60.9608%, Training Loss: 0.8354%\n",
      "Epoch [20/300], Step [68/225], Training Accuracy: 60.9835%, Training Loss: 0.8368%\n",
      "Epoch [20/300], Step [69/225], Training Accuracy: 60.8922%, Training Loss: 0.8374%\n",
      "Epoch [20/300], Step [70/225], Training Accuracy: 60.7589%, Training Loss: 0.8389%\n",
      "Epoch [20/300], Step [71/225], Training Accuracy: 60.7614%, Training Loss: 0.8377%\n",
      "Epoch [20/300], Step [72/225], Training Accuracy: 60.7422%, Training Loss: 0.8379%\n",
      "Epoch [20/300], Step [73/225], Training Accuracy: 60.6807%, Training Loss: 0.8382%\n",
      "Epoch [20/300], Step [74/225], Training Accuracy: 60.8953%, Training Loss: 0.8347%\n",
      "Epoch [20/300], Step [75/225], Training Accuracy: 60.7500%, Training Loss: 0.8353%\n",
      "Epoch [20/300], Step [76/225], Training Accuracy: 60.7319%, Training Loss: 0.8358%\n",
      "Epoch [20/300], Step [77/225], Training Accuracy: 60.7549%, Training Loss: 0.8359%\n",
      "Epoch [20/300], Step [78/225], Training Accuracy: 60.7772%, Training Loss: 0.8362%\n",
      "Epoch [20/300], Step [79/225], Training Accuracy: 60.7199%, Training Loss: 0.8365%\n",
      "Epoch [20/300], Step [80/225], Training Accuracy: 60.5664%, Training Loss: 0.8369%\n",
      "Epoch [20/300], Step [81/225], Training Accuracy: 60.5131%, Training Loss: 0.8383%\n",
      "Epoch [20/300], Step [82/225], Training Accuracy: 60.5183%, Training Loss: 0.8381%\n",
      "Epoch [20/300], Step [83/225], Training Accuracy: 60.5045%, Training Loss: 0.8378%\n",
      "Epoch [20/300], Step [84/225], Training Accuracy: 60.5097%, Training Loss: 0.8366%\n",
      "Epoch [20/300], Step [85/225], Training Accuracy: 60.4596%, Training Loss: 0.8377%\n",
      "Epoch [20/300], Step [86/225], Training Accuracy: 60.4469%, Training Loss: 0.8368%\n",
      "Epoch [20/300], Step [87/225], Training Accuracy: 60.4885%, Training Loss: 0.8378%\n",
      "Epoch [20/300], Step [88/225], Training Accuracy: 60.3693%, Training Loss: 0.8389%\n",
      "Epoch [20/300], Step [89/225], Training Accuracy: 60.2528%, Training Loss: 0.8410%\n",
      "Epoch [20/300], Step [90/225], Training Accuracy: 60.2778%, Training Loss: 0.8418%\n",
      "Epoch [20/300], Step [91/225], Training Accuracy: 60.2335%, Training Loss: 0.8427%\n",
      "Epoch [20/300], Step [92/225], Training Accuracy: 60.1393%, Training Loss: 0.8446%\n",
      "Epoch [20/300], Step [93/225], Training Accuracy: 60.1647%, Training Loss: 0.8441%\n",
      "Epoch [20/300], Step [94/225], Training Accuracy: 60.2560%, Training Loss: 0.8422%\n",
      "Epoch [20/300], Step [95/225], Training Accuracy: 60.2467%, Training Loss: 0.8424%\n",
      "Epoch [20/300], Step [96/225], Training Accuracy: 60.3841%, Training Loss: 0.8406%\n",
      "Epoch [20/300], Step [97/225], Training Accuracy: 60.4059%, Training Loss: 0.8395%\n",
      "Epoch [20/300], Step [98/225], Training Accuracy: 60.4114%, Training Loss: 0.8397%\n",
      "Epoch [20/300], Step [99/225], Training Accuracy: 60.4009%, Training Loss: 0.8396%\n",
      "Epoch [20/300], Step [100/225], Training Accuracy: 60.3281%, Training Loss: 0.8401%\n",
      "Epoch [20/300], Step [101/225], Training Accuracy: 60.3032%, Training Loss: 0.8398%\n",
      "Epoch [20/300], Step [102/225], Training Accuracy: 60.3094%, Training Loss: 0.8403%\n",
      "Epoch [20/300], Step [103/225], Training Accuracy: 60.3307%, Training Loss: 0.8399%\n",
      "Epoch [20/300], Step [104/225], Training Accuracy: 60.2915%, Training Loss: 0.8405%\n",
      "Epoch [20/300], Step [105/225], Training Accuracy: 60.2976%, Training Loss: 0.8397%\n",
      "Epoch [20/300], Step [106/225], Training Accuracy: 60.3479%, Training Loss: 0.8392%\n",
      "Epoch [20/300], Step [107/225], Training Accuracy: 60.2658%, Training Loss: 0.8395%\n",
      "Epoch [20/300], Step [108/225], Training Accuracy: 60.2431%, Training Loss: 0.8394%\n",
      "Epoch [20/300], Step [109/225], Training Accuracy: 60.2638%, Training Loss: 0.8386%\n",
      "Epoch [20/300], Step [110/225], Training Accuracy: 60.2699%, Training Loss: 0.8381%\n",
      "Epoch [20/300], Step [111/225], Training Accuracy: 60.2900%, Training Loss: 0.8377%\n",
      "Epoch [20/300], Step [112/225], Training Accuracy: 60.3376%, Training Loss: 0.8380%\n",
      "Epoch [20/300], Step [113/225], Training Accuracy: 60.3291%, Training Loss: 0.8374%\n",
      "Epoch [20/300], Step [114/225], Training Accuracy: 60.3207%, Training Loss: 0.8364%\n",
      "Epoch [20/300], Step [115/225], Training Accuracy: 60.4212%, Training Loss: 0.8348%\n",
      "Epoch [20/300], Step [116/225], Training Accuracy: 60.4526%, Training Loss: 0.8344%\n",
      "Epoch [20/300], Step [117/225], Training Accuracy: 60.3499%, Training Loss: 0.8351%\n",
      "Epoch [20/300], Step [118/225], Training Accuracy: 60.4343%, Training Loss: 0.8337%\n",
      "Epoch [20/300], Step [119/225], Training Accuracy: 60.4779%, Training Loss: 0.8330%\n",
      "Epoch [20/300], Step [120/225], Training Accuracy: 60.5469%, Training Loss: 0.8331%\n",
      "Epoch [20/300], Step [121/225], Training Accuracy: 60.4855%, Training Loss: 0.8342%\n",
      "Epoch [20/300], Step [122/225], Training Accuracy: 60.5020%, Training Loss: 0.8337%\n",
      "Epoch [20/300], Step [123/225], Training Accuracy: 60.5310%, Training Loss: 0.8337%\n",
      "Epoch [20/300], Step [124/225], Training Accuracy: 60.5217%, Training Loss: 0.8334%\n",
      "Epoch [20/300], Step [125/225], Training Accuracy: 60.5125%, Training Loss: 0.8336%\n",
      "Epoch [20/300], Step [126/225], Training Accuracy: 60.4539%, Training Loss: 0.8338%\n",
      "Epoch [20/300], Step [127/225], Training Accuracy: 60.4208%, Training Loss: 0.8342%\n",
      "Epoch [20/300], Step [128/225], Training Accuracy: 60.3394%, Training Loss: 0.8352%\n",
      "Epoch [20/300], Step [129/225], Training Accuracy: 60.3803%, Training Loss: 0.8355%\n",
      "Epoch [20/300], Step [130/225], Training Accuracy: 60.3486%, Training Loss: 0.8368%\n",
      "Epoch [20/300], Step [131/225], Training Accuracy: 60.3531%, Training Loss: 0.8368%\n",
      "Epoch [20/300], Step [132/225], Training Accuracy: 60.3220%, Training Loss: 0.8376%\n",
      "Epoch [20/300], Step [133/225], Training Accuracy: 60.3618%, Training Loss: 0.8374%\n",
      "Epoch [20/300], Step [134/225], Training Accuracy: 60.2612%, Training Loss: 0.8385%\n",
      "Epoch [20/300], Step [135/225], Training Accuracy: 60.2546%, Training Loss: 0.8386%\n",
      "Epoch [20/300], Step [136/225], Training Accuracy: 60.3056%, Training Loss: 0.8376%\n",
      "Epoch [20/300], Step [137/225], Training Accuracy: 60.3444%, Training Loss: 0.8373%\n",
      "Epoch [20/300], Step [138/225], Training Accuracy: 60.4053%, Training Loss: 0.8363%\n",
      "Epoch [20/300], Step [139/225], Training Accuracy: 60.4092%, Training Loss: 0.8362%\n",
      "Epoch [20/300], Step [140/225], Training Accuracy: 60.3906%, Training Loss: 0.8361%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/300], Step [141/225], Training Accuracy: 60.4277%, Training Loss: 0.8357%\n",
      "Epoch [20/300], Step [142/225], Training Accuracy: 60.3983%, Training Loss: 0.8368%\n",
      "Epoch [20/300], Step [143/225], Training Accuracy: 60.4021%, Training Loss: 0.8366%\n",
      "Epoch [20/300], Step [144/225], Training Accuracy: 60.3407%, Training Loss: 0.8376%\n",
      "Epoch [20/300], Step [145/225], Training Accuracy: 60.4095%, Training Loss: 0.8373%\n",
      "Epoch [20/300], Step [146/225], Training Accuracy: 60.3382%, Training Loss: 0.8378%\n",
      "Epoch [20/300], Step [147/225], Training Accuracy: 60.3529%, Training Loss: 0.8376%\n",
      "Epoch [20/300], Step [148/225], Training Accuracy: 60.4307%, Training Loss: 0.8367%\n",
      "Epoch [20/300], Step [149/225], Training Accuracy: 60.4446%, Training Loss: 0.8363%\n",
      "Epoch [20/300], Step [150/225], Training Accuracy: 60.4271%, Training Loss: 0.8360%\n",
      "Epoch [20/300], Step [151/225], Training Accuracy: 60.4098%, Training Loss: 0.8358%\n",
      "Epoch [20/300], Step [152/225], Training Accuracy: 60.3927%, Training Loss: 0.8358%\n",
      "Epoch [20/300], Step [153/225], Training Accuracy: 60.3554%, Training Loss: 0.8354%\n",
      "Epoch [20/300], Step [154/225], Training Accuracy: 60.2983%, Training Loss: 0.8356%\n",
      "Epoch [20/300], Step [155/225], Training Accuracy: 60.3125%, Training Loss: 0.8353%\n",
      "Epoch [20/300], Step [156/225], Training Accuracy: 60.2364%, Training Loss: 0.8357%\n",
      "Epoch [20/300], Step [157/225], Training Accuracy: 60.3304%, Training Loss: 0.8345%\n",
      "Epoch [20/300], Step [158/225], Training Accuracy: 60.2354%, Training Loss: 0.8363%\n",
      "Epoch [20/300], Step [159/225], Training Accuracy: 60.2201%, Training Loss: 0.8358%\n",
      "Epoch [20/300], Step [160/225], Training Accuracy: 60.2637%, Training Loss: 0.8349%\n",
      "Epoch [20/300], Step [161/225], Training Accuracy: 60.2679%, Training Loss: 0.8351%\n",
      "Epoch [20/300], Step [162/225], Training Accuracy: 60.3202%, Training Loss: 0.8356%\n",
      "Epoch [20/300], Step [163/225], Training Accuracy: 60.3144%, Training Loss: 0.8354%\n",
      "Epoch [20/300], Step [164/225], Training Accuracy: 60.3087%, Training Loss: 0.8353%\n",
      "Epoch [20/300], Step [165/225], Training Accuracy: 60.3314%, Training Loss: 0.8348%\n",
      "Epoch [20/300], Step [166/225], Training Accuracy: 60.3633%, Training Loss: 0.8345%\n",
      "Epoch [20/300], Step [167/225], Training Accuracy: 60.3761%, Training Loss: 0.8342%\n",
      "Epoch [20/300], Step [168/225], Training Accuracy: 60.3795%, Training Loss: 0.8343%\n",
      "Epoch [20/300], Step [169/225], Training Accuracy: 60.4105%, Training Loss: 0.8336%\n",
      "Epoch [20/300], Step [170/225], Training Accuracy: 60.3585%, Training Loss: 0.8338%\n",
      "Epoch [20/300], Step [171/225], Training Accuracy: 60.3527%, Training Loss: 0.8337%\n",
      "Epoch [20/300], Step [172/225], Training Accuracy: 60.3652%, Training Loss: 0.8335%\n",
      "Epoch [20/300], Step [173/225], Training Accuracy: 60.3324%, Training Loss: 0.8336%\n",
      "Epoch [20/300], Step [174/225], Training Accuracy: 60.3628%, Training Loss: 0.8333%\n",
      "Epoch [20/300], Step [175/225], Training Accuracy: 60.3661%, Training Loss: 0.8333%\n",
      "Epoch [20/300], Step [176/225], Training Accuracy: 60.3693%, Training Loss: 0.8328%\n",
      "Epoch [20/300], Step [177/225], Training Accuracy: 60.4167%, Training Loss: 0.8323%\n",
      "Epoch [20/300], Step [178/225], Training Accuracy: 60.4196%, Training Loss: 0.8321%\n",
      "Epoch [20/300], Step [179/225], Training Accuracy: 60.4574%, Training Loss: 0.8315%\n",
      "Epoch [20/300], Step [180/225], Training Accuracy: 60.5035%, Training Loss: 0.8304%\n",
      "Epoch [20/300], Step [181/225], Training Accuracy: 60.5059%, Training Loss: 0.8306%\n",
      "Epoch [20/300], Step [182/225], Training Accuracy: 60.5598%, Training Loss: 0.8303%\n",
      "Epoch [20/300], Step [183/225], Training Accuracy: 60.5362%, Training Loss: 0.8310%\n",
      "Epoch [20/300], Step [184/225], Training Accuracy: 60.5639%, Training Loss: 0.8314%\n",
      "Epoch [20/300], Step [185/225], Training Accuracy: 60.5828%, Training Loss: 0.8318%\n",
      "Epoch [20/300], Step [186/225], Training Accuracy: 60.6099%, Training Loss: 0.8316%\n",
      "Epoch [20/300], Step [187/225], Training Accuracy: 60.6116%, Training Loss: 0.8312%\n",
      "Epoch [20/300], Step [188/225], Training Accuracy: 60.6300%, Training Loss: 0.8309%\n",
      "Epoch [20/300], Step [189/225], Training Accuracy: 60.6647%, Training Loss: 0.8303%\n",
      "Epoch [20/300], Step [190/225], Training Accuracy: 60.6743%, Training Loss: 0.8305%\n",
      "Epoch [20/300], Step [191/225], Training Accuracy: 60.6675%, Training Loss: 0.8308%\n",
      "Epoch [20/300], Step [192/225], Training Accuracy: 60.7178%, Training Loss: 0.8298%\n",
      "Epoch [20/300], Step [193/225], Training Accuracy: 60.6784%, Training Loss: 0.8299%\n",
      "Epoch [20/300], Step [194/225], Training Accuracy: 60.6476%, Training Loss: 0.8304%\n",
      "Epoch [20/300], Step [195/225], Training Accuracy: 60.7212%, Training Loss: 0.8294%\n",
      "Epoch [20/300], Step [196/225], Training Accuracy: 60.7143%, Training Loss: 0.8297%\n",
      "Epoch [20/300], Step [197/225], Training Accuracy: 60.7313%, Training Loss: 0.8301%\n",
      "Epoch [20/300], Step [198/225], Training Accuracy: 60.7639%, Training Loss: 0.8292%\n",
      "Epoch [20/300], Step [199/225], Training Accuracy: 60.7334%, Training Loss: 0.8290%\n",
      "Epoch [20/300], Step [200/225], Training Accuracy: 60.7578%, Training Loss: 0.8290%\n",
      "Epoch [20/300], Step [201/225], Training Accuracy: 60.7354%, Training Loss: 0.8294%\n",
      "Epoch [20/300], Step [202/225], Training Accuracy: 60.7596%, Training Loss: 0.8288%\n",
      "Epoch [20/300], Step [203/225], Training Accuracy: 60.7990%, Training Loss: 0.8283%\n",
      "Epoch [20/300], Step [204/225], Training Accuracy: 60.7996%, Training Loss: 0.8283%\n",
      "Epoch [20/300], Step [205/225], Training Accuracy: 60.8079%, Training Loss: 0.8278%\n",
      "Epoch [20/300], Step [206/225], Training Accuracy: 60.7706%, Training Loss: 0.8286%\n",
      "Epoch [20/300], Step [207/225], Training Accuracy: 60.7563%, Training Loss: 0.8289%\n",
      "Epoch [20/300], Step [208/225], Training Accuracy: 60.7873%, Training Loss: 0.8281%\n",
      "Epoch [20/300], Step [209/225], Training Accuracy: 60.7955%, Training Loss: 0.8283%\n",
      "Epoch [20/300], Step [210/225], Training Accuracy: 60.8185%, Training Loss: 0.8283%\n",
      "Epoch [20/300], Step [211/225], Training Accuracy: 60.8264%, Training Loss: 0.8277%\n",
      "Epoch [20/300], Step [212/225], Training Accuracy: 60.7901%, Training Loss: 0.8286%\n",
      "Epoch [20/300], Step [213/225], Training Accuracy: 60.7541%, Training Loss: 0.8296%\n",
      "Epoch [20/300], Step [214/225], Training Accuracy: 60.7623%, Training Loss: 0.8292%\n",
      "Epoch [20/300], Step [215/225], Training Accuracy: 60.7922%, Training Loss: 0.8288%\n",
      "Epoch [20/300], Step [216/225], Training Accuracy: 60.7856%, Training Loss: 0.8292%\n",
      "Epoch [20/300], Step [217/225], Training Accuracy: 60.7359%, Training Loss: 0.8296%\n",
      "Epoch [20/300], Step [218/225], Training Accuracy: 60.7440%, Training Loss: 0.8298%\n",
      "Epoch [20/300], Step [219/225], Training Accuracy: 60.7377%, Training Loss: 0.8299%\n",
      "Epoch [20/300], Step [220/225], Training Accuracy: 60.7528%, Training Loss: 0.8298%\n",
      "Epoch [20/300], Step [221/225], Training Accuracy: 60.7537%, Training Loss: 0.8298%\n",
      "Epoch [20/300], Step [222/225], Training Accuracy: 60.7545%, Training Loss: 0.8300%\n",
      "Epoch [20/300], Step [223/225], Training Accuracy: 60.7063%, Training Loss: 0.8305%\n",
      "Epoch [20/300], Step [224/225], Training Accuracy: 60.6724%, Training Loss: 0.8307%\n",
      "Epoch [20/300], Step [225/225], Training Accuracy: 60.6587%, Training Loss: 0.8307%\n",
      "Epoch [21/300], Step [1/225], Training Accuracy: 78.1250%, Training Loss: 0.5819%\n",
      "Epoch [21/300], Step [2/225], Training Accuracy: 67.9688%, Training Loss: 0.7119%\n",
      "Epoch [21/300], Step [3/225], Training Accuracy: 66.6667%, Training Loss: 0.7699%\n",
      "Epoch [21/300], Step [4/225], Training Accuracy: 67.1875%, Training Loss: 0.7881%\n",
      "Epoch [21/300], Step [5/225], Training Accuracy: 66.2500%, Training Loss: 0.7824%\n",
      "Epoch [21/300], Step [6/225], Training Accuracy: 65.1042%, Training Loss: 0.8003%\n",
      "Epoch [21/300], Step [7/225], Training Accuracy: 62.7232%, Training Loss: 0.8127%\n",
      "Epoch [21/300], Step [8/225], Training Accuracy: 61.7188%, Training Loss: 0.8231%\n",
      "Epoch [21/300], Step [9/225], Training Accuracy: 60.9375%, Training Loss: 0.8358%\n",
      "Epoch [21/300], Step [10/225], Training Accuracy: 60.1562%, Training Loss: 0.8538%\n",
      "Epoch [21/300], Step [11/225], Training Accuracy: 60.3693%, Training Loss: 0.8553%\n",
      "Epoch [21/300], Step [12/225], Training Accuracy: 60.9375%, Training Loss: 0.8440%\n",
      "Epoch [21/300], Step [13/225], Training Accuracy: 62.0192%, Training Loss: 0.8265%\n",
      "Epoch [21/300], Step [14/225], Training Accuracy: 61.7188%, Training Loss: 0.8290%\n",
      "Epoch [21/300], Step [15/225], Training Accuracy: 61.9792%, Training Loss: 0.8243%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/300], Step [16/225], Training Accuracy: 61.5234%, Training Loss: 0.8314%\n",
      "Epoch [21/300], Step [17/225], Training Accuracy: 61.4890%, Training Loss: 0.8265%\n",
      "Epoch [21/300], Step [18/225], Training Accuracy: 61.5451%, Training Loss: 0.8304%\n",
      "Epoch [21/300], Step [19/225], Training Accuracy: 61.7599%, Training Loss: 0.8290%\n",
      "Epoch [21/300], Step [20/225], Training Accuracy: 62.1875%, Training Loss: 0.8213%\n",
      "Epoch [21/300], Step [21/225], Training Accuracy: 62.2768%, Training Loss: 0.8159%\n",
      "Epoch [21/300], Step [22/225], Training Accuracy: 62.5710%, Training Loss: 0.8131%\n",
      "Epoch [21/300], Step [23/225], Training Accuracy: 62.2283%, Training Loss: 0.8151%\n",
      "Epoch [21/300], Step [24/225], Training Accuracy: 62.1094%, Training Loss: 0.8184%\n",
      "Epoch [21/300], Step [25/225], Training Accuracy: 62.1875%, Training Loss: 0.8151%\n",
      "Epoch [21/300], Step [26/225], Training Accuracy: 62.1394%, Training Loss: 0.8128%\n",
      "Epoch [21/300], Step [27/225], Training Accuracy: 62.0949%, Training Loss: 0.8149%\n",
      "Epoch [21/300], Step [28/225], Training Accuracy: 62.3326%, Training Loss: 0.8081%\n",
      "Epoch [21/300], Step [29/225], Training Accuracy: 62.5000%, Training Loss: 0.8056%\n",
      "Epoch [21/300], Step [30/225], Training Accuracy: 62.6042%, Training Loss: 0.8039%\n",
      "Epoch [21/300], Step [31/225], Training Accuracy: 62.6512%, Training Loss: 0.8036%\n",
      "Epoch [21/300], Step [32/225], Training Accuracy: 62.7930%, Training Loss: 0.7999%\n",
      "Epoch [21/300], Step [33/225], Training Accuracy: 62.7367%, Training Loss: 0.7991%\n",
      "Epoch [21/300], Step [34/225], Training Accuracy: 62.6838%, Training Loss: 0.8054%\n",
      "Epoch [21/300], Step [35/225], Training Accuracy: 62.4554%, Training Loss: 0.8100%\n",
      "Epoch [21/300], Step [36/225], Training Accuracy: 62.4566%, Training Loss: 0.8127%\n",
      "Epoch [21/300], Step [37/225], Training Accuracy: 62.5422%, Training Loss: 0.8081%\n",
      "Epoch [21/300], Step [38/225], Training Accuracy: 62.4589%, Training Loss: 0.8090%\n",
      "Epoch [21/300], Step [39/225], Training Accuracy: 62.3397%, Training Loss: 0.8125%\n",
      "Epoch [21/300], Step [40/225], Training Accuracy: 61.9531%, Training Loss: 0.8154%\n",
      "Epoch [21/300], Step [41/225], Training Accuracy: 61.5473%, Training Loss: 0.8221%\n",
      "Epoch [21/300], Step [42/225], Training Accuracy: 61.4211%, Training Loss: 0.8218%\n",
      "Epoch [21/300], Step [43/225], Training Accuracy: 61.5552%, Training Loss: 0.8196%\n",
      "Epoch [21/300], Step [44/225], Training Accuracy: 61.6832%, Training Loss: 0.8201%\n",
      "Epoch [21/300], Step [45/225], Training Accuracy: 61.5972%, Training Loss: 0.8216%\n",
      "Epoch [21/300], Step [46/225], Training Accuracy: 61.5829%, Training Loss: 0.8201%\n",
      "Epoch [21/300], Step [47/225], Training Accuracy: 61.6024%, Training Loss: 0.8212%\n",
      "Epoch [21/300], Step [48/225], Training Accuracy: 61.6211%, Training Loss: 0.8212%\n",
      "Epoch [21/300], Step [49/225], Training Accuracy: 61.7347%, Training Loss: 0.8214%\n",
      "Epoch [21/300], Step [50/225], Training Accuracy: 61.5625%, Training Loss: 0.8243%\n",
      "Epoch [21/300], Step [51/225], Training Accuracy: 61.6115%, Training Loss: 0.8210%\n",
      "Epoch [21/300], Step [52/225], Training Accuracy: 61.9591%, Training Loss: 0.8172%\n",
      "Epoch [21/300], Step [53/225], Training Accuracy: 62.0283%, Training Loss: 0.8174%\n",
      "Epoch [21/300], Step [54/225], Training Accuracy: 61.7766%, Training Loss: 0.8188%\n",
      "Epoch [21/300], Step [55/225], Training Accuracy: 61.7330%, Training Loss: 0.8200%\n",
      "Epoch [21/300], Step [56/225], Training Accuracy: 61.7467%, Training Loss: 0.8193%\n",
      "Epoch [21/300], Step [57/225], Training Accuracy: 61.7873%, Training Loss: 0.8182%\n",
      "Epoch [21/300], Step [58/225], Training Accuracy: 61.8534%, Training Loss: 0.8180%\n",
      "Epoch [21/300], Step [59/225], Training Accuracy: 61.6790%, Training Loss: 0.8206%\n",
      "Epoch [21/300], Step [60/225], Training Accuracy: 61.7448%, Training Loss: 0.8195%\n",
      "Epoch [21/300], Step [61/225], Training Accuracy: 61.7828%, Training Loss: 0.8185%\n",
      "Epoch [21/300], Step [62/225], Training Accuracy: 61.9456%, Training Loss: 0.8174%\n",
      "Epoch [21/300], Step [63/225], Training Accuracy: 61.8800%, Training Loss: 0.8177%\n",
      "Epoch [21/300], Step [64/225], Training Accuracy: 61.8896%, Training Loss: 0.8193%\n",
      "Epoch [21/300], Step [65/225], Training Accuracy: 61.9712%, Training Loss: 0.8190%\n",
      "Epoch [21/300], Step [66/225], Training Accuracy: 62.0502%, Training Loss: 0.8177%\n",
      "Epoch [21/300], Step [67/225], Training Accuracy: 61.9170%, Training Loss: 0.8190%\n",
      "Epoch [21/300], Step [68/225], Training Accuracy: 61.7877%, Training Loss: 0.8201%\n",
      "Epoch [21/300], Step [69/225], Training Accuracy: 61.7301%, Training Loss: 0.8213%\n",
      "Epoch [21/300], Step [70/225], Training Accuracy: 61.6071%, Training Loss: 0.8221%\n",
      "Epoch [21/300], Step [71/225], Training Accuracy: 61.6857%, Training Loss: 0.8211%\n",
      "Epoch [21/300], Step [72/225], Training Accuracy: 61.7622%, Training Loss: 0.8202%\n",
      "Epoch [21/300], Step [73/225], Training Accuracy: 61.6224%, Training Loss: 0.8222%\n",
      "Epoch [21/300], Step [74/225], Training Accuracy: 61.7610%, Training Loss: 0.8197%\n",
      "Epoch [21/300], Step [75/225], Training Accuracy: 61.6667%, Training Loss: 0.8215%\n",
      "Epoch [21/300], Step [76/225], Training Accuracy: 61.5954%, Training Loss: 0.8219%\n",
      "Epoch [21/300], Step [77/225], Training Accuracy: 61.6071%, Training Loss: 0.8225%\n",
      "Epoch [21/300], Step [78/225], Training Accuracy: 61.5785%, Training Loss: 0.8234%\n",
      "Epoch [21/300], Step [79/225], Training Accuracy: 61.5704%, Training Loss: 0.8232%\n",
      "Epoch [21/300], Step [80/225], Training Accuracy: 61.5625%, Training Loss: 0.8237%\n",
      "Epoch [21/300], Step [81/225], Training Accuracy: 61.5934%, Training Loss: 0.8239%\n",
      "Epoch [21/300], Step [82/225], Training Accuracy: 61.6806%, Training Loss: 0.8225%\n",
      "Epoch [21/300], Step [83/225], Training Accuracy: 61.7470%, Training Loss: 0.8224%\n",
      "Epoch [21/300], Step [84/225], Training Accuracy: 61.7932%, Training Loss: 0.8214%\n",
      "Epoch [21/300], Step [85/225], Training Accuracy: 61.8934%, Training Loss: 0.8201%\n",
      "Epoch [21/300], Step [86/225], Training Accuracy: 62.0458%, Training Loss: 0.8185%\n",
      "Epoch [21/300], Step [87/225], Training Accuracy: 62.0690%, Training Loss: 0.8184%\n",
      "Epoch [21/300], Step [88/225], Training Accuracy: 62.0028%, Training Loss: 0.8192%\n",
      "Epoch [21/300], Step [89/225], Training Accuracy: 62.0260%, Training Loss: 0.8204%\n",
      "Epoch [21/300], Step [90/225], Training Accuracy: 62.0312%, Training Loss: 0.8208%\n",
      "Epoch [21/300], Step [91/225], Training Accuracy: 62.0021%, Training Loss: 0.8199%\n",
      "Epoch [21/300], Step [92/225], Training Accuracy: 61.9735%, Training Loss: 0.8212%\n",
      "Epoch [21/300], Step [93/225], Training Accuracy: 61.9960%, Training Loss: 0.8208%\n",
      "Epoch [21/300], Step [94/225], Training Accuracy: 62.0844%, Training Loss: 0.8196%\n",
      "Epoch [21/300], Step [95/225], Training Accuracy: 62.0230%, Training Loss: 0.8202%\n",
      "Epoch [21/300], Step [96/225], Training Accuracy: 62.1582%, Training Loss: 0.8186%\n",
      "Epoch [21/300], Step [97/225], Training Accuracy: 62.1134%, Training Loss: 0.8187%\n",
      "Epoch [21/300], Step [98/225], Training Accuracy: 62.1652%, Training Loss: 0.8184%\n",
      "Epoch [21/300], Step [99/225], Training Accuracy: 62.2159%, Training Loss: 0.8183%\n",
      "Epoch [21/300], Step [100/225], Training Accuracy: 62.1562%, Training Loss: 0.8192%\n",
      "Epoch [21/300], Step [101/225], Training Accuracy: 62.2061%, Training Loss: 0.8183%\n",
      "Epoch [21/300], Step [102/225], Training Accuracy: 62.1936%, Training Loss: 0.8180%\n",
      "Epoch [21/300], Step [103/225], Training Accuracy: 62.3028%, Training Loss: 0.8173%\n",
      "Epoch [21/300], Step [104/225], Training Accuracy: 62.3047%, Training Loss: 0.8171%\n",
      "Epoch [21/300], Step [105/225], Training Accuracy: 62.4107%, Training Loss: 0.8163%\n",
      "Epoch [21/300], Step [106/225], Training Accuracy: 62.4705%, Training Loss: 0.8157%\n",
      "Epoch [21/300], Step [107/225], Training Accuracy: 62.4416%, Training Loss: 0.8162%\n",
      "Epoch [21/300], Step [108/225], Training Accuracy: 62.3843%, Training Loss: 0.8167%\n",
      "Epoch [21/300], Step [109/225], Training Accuracy: 62.3710%, Training Loss: 0.8164%\n",
      "Epoch [21/300], Step [110/225], Training Accuracy: 62.3011%, Training Loss: 0.8162%\n",
      "Epoch [21/300], Step [111/225], Training Accuracy: 62.3029%, Training Loss: 0.8165%\n",
      "Epoch [21/300], Step [112/225], Training Accuracy: 62.3186%, Training Loss: 0.8156%\n",
      "Epoch [21/300], Step [113/225], Training Accuracy: 62.3341%, Training Loss: 0.8156%\n",
      "Epoch [21/300], Step [114/225], Training Accuracy: 62.3766%, Training Loss: 0.8144%\n",
      "Epoch [21/300], Step [115/225], Training Accuracy: 62.3641%, Training Loss: 0.8136%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/300], Step [116/225], Training Accuracy: 62.4461%, Training Loss: 0.8132%\n",
      "Epoch [21/300], Step [117/225], Training Accuracy: 62.3932%, Training Loss: 0.8136%\n",
      "Epoch [21/300], Step [118/225], Training Accuracy: 62.4338%, Training Loss: 0.8129%\n",
      "Epoch [21/300], Step [119/225], Training Accuracy: 62.4212%, Training Loss: 0.8125%\n",
      "Epoch [21/300], Step [120/225], Training Accuracy: 62.4479%, Training Loss: 0.8121%\n",
      "Epoch [21/300], Step [121/225], Training Accuracy: 62.4096%, Training Loss: 0.8120%\n",
      "Epoch [21/300], Step [122/225], Training Accuracy: 62.4360%, Training Loss: 0.8114%\n",
      "Epoch [21/300], Step [123/225], Training Accuracy: 62.4238%, Training Loss: 0.8114%\n",
      "Epoch [21/300], Step [124/225], Training Accuracy: 62.3740%, Training Loss: 0.8110%\n",
      "Epoch [21/300], Step [125/225], Training Accuracy: 62.4125%, Training Loss: 0.8113%\n",
      "Epoch [21/300], Step [126/225], Training Accuracy: 62.3884%, Training Loss: 0.8118%\n",
      "Epoch [21/300], Step [127/225], Training Accuracy: 62.3893%, Training Loss: 0.8121%\n",
      "Epoch [21/300], Step [128/225], Training Accuracy: 62.4023%, Training Loss: 0.8122%\n",
      "Epoch [21/300], Step [129/225], Training Accuracy: 62.4273%, Training Loss: 0.8121%\n",
      "Epoch [21/300], Step [130/225], Training Accuracy: 62.4159%, Training Loss: 0.8126%\n",
      "Epoch [21/300], Step [131/225], Training Accuracy: 62.4523%, Training Loss: 0.8123%\n",
      "Epoch [21/300], Step [132/225], Training Accuracy: 62.4171%, Training Loss: 0.8123%\n",
      "Epoch [21/300], Step [133/225], Training Accuracy: 62.4883%, Training Loss: 0.8114%\n",
      "Epoch [21/300], Step [134/225], Training Accuracy: 62.4184%, Training Loss: 0.8125%\n",
      "Epoch [21/300], Step [135/225], Training Accuracy: 62.4653%, Training Loss: 0.8113%\n",
      "Epoch [21/300], Step [136/225], Training Accuracy: 62.4885%, Training Loss: 0.8110%\n",
      "Epoch [21/300], Step [137/225], Training Accuracy: 62.4430%, Training Loss: 0.8111%\n",
      "Epoch [21/300], Step [138/225], Training Accuracy: 62.5453%, Training Loss: 0.8094%\n",
      "Epoch [21/300], Step [139/225], Training Accuracy: 62.5000%, Training Loss: 0.8095%\n",
      "Epoch [21/300], Step [140/225], Training Accuracy: 62.4665%, Training Loss: 0.8096%\n",
      "Epoch [21/300], Step [141/225], Training Accuracy: 62.4224%, Training Loss: 0.8100%\n",
      "Epoch [21/300], Step [142/225], Training Accuracy: 62.3900%, Training Loss: 0.8101%\n",
      "Epoch [21/300], Step [143/225], Training Accuracy: 62.4563%, Training Loss: 0.8097%\n",
      "Epoch [21/300], Step [144/225], Training Accuracy: 62.3806%, Training Loss: 0.8104%\n",
      "Epoch [21/300], Step [145/225], Training Accuracy: 62.3707%, Training Loss: 0.8102%\n",
      "Epoch [21/300], Step [146/225], Training Accuracy: 62.3074%, Training Loss: 0.8105%\n",
      "Epoch [21/300], Step [147/225], Training Accuracy: 62.2449%, Training Loss: 0.8110%\n",
      "Epoch [21/300], Step [148/225], Training Accuracy: 62.3416%, Training Loss: 0.8105%\n",
      "Epoch [21/300], Step [149/225], Training Accuracy: 62.3322%, Training Loss: 0.8103%\n",
      "Epoch [21/300], Step [150/225], Training Accuracy: 62.3229%, Training Loss: 0.8100%\n",
      "Epoch [21/300], Step [151/225], Training Accuracy: 62.2930%, Training Loss: 0.8103%\n",
      "Epoch [21/300], Step [152/225], Training Accuracy: 62.2430%, Training Loss: 0.8107%\n",
      "Epoch [21/300], Step [153/225], Training Accuracy: 62.2345%, Training Loss: 0.8104%\n",
      "Epoch [21/300], Step [154/225], Training Accuracy: 62.2159%, Training Loss: 0.8099%\n",
      "Epoch [21/300], Step [155/225], Training Accuracy: 62.2077%, Training Loss: 0.8095%\n",
      "Epoch [21/300], Step [156/225], Training Accuracy: 62.2196%, Training Loss: 0.8099%\n",
      "Epoch [21/300], Step [157/225], Training Accuracy: 62.2412%, Training Loss: 0.8094%\n",
      "Epoch [21/300], Step [158/225], Training Accuracy: 62.1539%, Training Loss: 0.8109%\n",
      "Epoch [21/300], Step [159/225], Training Accuracy: 62.0971%, Training Loss: 0.8113%\n",
      "Epoch [21/300], Step [160/225], Training Accuracy: 62.1387%, Training Loss: 0.8107%\n",
      "Epoch [21/300], Step [161/225], Training Accuracy: 62.1021%, Training Loss: 0.8105%\n",
      "Epoch [21/300], Step [162/225], Training Accuracy: 62.1335%, Training Loss: 0.8107%\n",
      "Epoch [21/300], Step [163/225], Training Accuracy: 62.1357%, Training Loss: 0.8100%\n",
      "Epoch [21/300], Step [164/225], Training Accuracy: 62.1570%, Training Loss: 0.8095%\n",
      "Epoch [21/300], Step [165/225], Training Accuracy: 62.1496%, Training Loss: 0.8098%\n",
      "Epoch [21/300], Step [166/225], Training Accuracy: 62.1800%, Training Loss: 0.8090%\n",
      "Epoch [21/300], Step [167/225], Training Accuracy: 62.1912%, Training Loss: 0.8085%\n",
      "Epoch [21/300], Step [168/225], Training Accuracy: 62.1559%, Training Loss: 0.8086%\n",
      "Epoch [21/300], Step [169/225], Training Accuracy: 62.1949%, Training Loss: 0.8081%\n",
      "Epoch [21/300], Step [170/225], Training Accuracy: 62.2151%, Training Loss: 0.8079%\n",
      "Epoch [21/300], Step [171/225], Training Accuracy: 62.2350%, Training Loss: 0.8075%\n",
      "Epoch [21/300], Step [172/225], Training Accuracy: 62.2275%, Training Loss: 0.8073%\n",
      "Epoch [21/300], Step [173/225], Training Accuracy: 62.2832%, Training Loss: 0.8069%\n",
      "Epoch [21/300], Step [174/225], Training Accuracy: 62.2755%, Training Loss: 0.8069%\n",
      "Epoch [21/300], Step [175/225], Training Accuracy: 62.3125%, Training Loss: 0.8066%\n",
      "Epoch [21/300], Step [176/225], Training Accuracy: 62.3757%, Training Loss: 0.8057%\n",
      "Epoch [21/300], Step [177/225], Training Accuracy: 62.3852%, Training Loss: 0.8052%\n",
      "Epoch [21/300], Step [178/225], Training Accuracy: 62.3508%, Training Loss: 0.8053%\n",
      "Epoch [21/300], Step [179/225], Training Accuracy: 62.3953%, Training Loss: 0.8045%\n",
      "Epoch [21/300], Step [180/225], Training Accuracy: 62.4132%, Training Loss: 0.8039%\n",
      "Epoch [21/300], Step [181/225], Training Accuracy: 62.4223%, Training Loss: 0.8042%\n",
      "Epoch [21/300], Step [182/225], Training Accuracy: 62.4914%, Training Loss: 0.8037%\n",
      "Epoch [21/300], Step [183/225], Training Accuracy: 62.4573%, Training Loss: 0.8041%\n",
      "Epoch [21/300], Step [184/225], Training Accuracy: 62.4745%, Training Loss: 0.8041%\n",
      "Epoch [21/300], Step [185/225], Training Accuracy: 62.4831%, Training Loss: 0.8040%\n",
      "Epoch [21/300], Step [186/225], Training Accuracy: 62.5336%, Training Loss: 0.8032%\n",
      "Epoch [21/300], Step [187/225], Training Accuracy: 62.5000%, Training Loss: 0.8035%\n",
      "Epoch [21/300], Step [188/225], Training Accuracy: 62.5332%, Training Loss: 0.8032%\n",
      "Epoch [21/300], Step [189/225], Training Accuracy: 62.5579%, Training Loss: 0.8023%\n",
      "Epoch [21/300], Step [190/225], Training Accuracy: 62.5658%, Training Loss: 0.8022%\n",
      "Epoch [21/300], Step [191/225], Training Accuracy: 62.5654%, Training Loss: 0.8019%\n",
      "Epoch [21/300], Step [192/225], Training Accuracy: 62.5977%, Training Loss: 0.8008%\n",
      "Epoch [21/300], Step [193/225], Training Accuracy: 62.5891%, Training Loss: 0.8010%\n",
      "Epoch [21/300], Step [194/225], Training Accuracy: 62.5403%, Training Loss: 0.8020%\n",
      "Epoch [21/300], Step [195/225], Training Accuracy: 62.5881%, Training Loss: 0.8011%\n",
      "Epoch [21/300], Step [196/225], Training Accuracy: 62.5877%, Training Loss: 0.8012%\n",
      "Epoch [21/300], Step [197/225], Training Accuracy: 62.5793%, Training Loss: 0.8021%\n",
      "Epoch [21/300], Step [198/225], Training Accuracy: 62.5868%, Training Loss: 0.8014%\n",
      "Epoch [21/300], Step [199/225], Training Accuracy: 62.5942%, Training Loss: 0.8012%\n",
      "Epoch [21/300], Step [200/225], Training Accuracy: 62.5547%, Training Loss: 0.8018%\n",
      "Epoch [21/300], Step [201/225], Training Accuracy: 62.5233%, Training Loss: 0.8023%\n",
      "Epoch [21/300], Step [202/225], Training Accuracy: 62.5541%, Training Loss: 0.8019%\n",
      "Epoch [21/300], Step [203/225], Training Accuracy: 62.5693%, Training Loss: 0.8019%\n",
      "Epoch [21/300], Step [204/225], Training Accuracy: 62.5536%, Training Loss: 0.8024%\n",
      "Epoch [21/300], Step [205/225], Training Accuracy: 62.5686%, Training Loss: 0.8020%\n",
      "Epoch [21/300], Step [206/225], Training Accuracy: 62.6062%, Training Loss: 0.8021%\n",
      "Epoch [21/300], Step [207/225], Training Accuracy: 62.5981%, Training Loss: 0.8021%\n",
      "Epoch [21/300], Step [208/225], Training Accuracy: 62.5751%, Training Loss: 0.8018%\n",
      "Epoch [21/300], Step [209/225], Training Accuracy: 62.5673%, Training Loss: 0.8022%\n",
      "Epoch [21/300], Step [210/225], Training Accuracy: 62.5521%, Training Loss: 0.8027%\n",
      "Epoch [21/300], Step [211/225], Training Accuracy: 62.5370%, Training Loss: 0.8026%\n",
      "Epoch [21/300], Step [212/225], Training Accuracy: 62.5221%, Training Loss: 0.8030%\n",
      "Epoch [21/300], Step [213/225], Training Accuracy: 62.4707%, Training Loss: 0.8040%\n",
      "Epoch [21/300], Step [214/225], Training Accuracy: 62.4708%, Training Loss: 0.8038%\n",
      "Epoch [21/300], Step [215/225], Training Accuracy: 62.4564%, Training Loss: 0.8044%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/300], Step [216/225], Training Accuracy: 62.4349%, Training Loss: 0.8050%\n",
      "Epoch [21/300], Step [217/225], Training Accuracy: 62.4136%, Training Loss: 0.8051%\n",
      "Epoch [21/300], Step [218/225], Training Accuracy: 62.4140%, Training Loss: 0.8057%\n",
      "Epoch [21/300], Step [219/225], Training Accuracy: 62.3858%, Training Loss: 0.8062%\n",
      "Epoch [21/300], Step [220/225], Training Accuracy: 62.3864%, Training Loss: 0.8058%\n",
      "Epoch [21/300], Step [221/225], Training Accuracy: 62.3869%, Training Loss: 0.8059%\n",
      "Epoch [21/300], Step [222/225], Training Accuracy: 62.3733%, Training Loss: 0.8059%\n",
      "Epoch [21/300], Step [223/225], Training Accuracy: 62.3318%, Training Loss: 0.8063%\n",
      "Epoch [21/300], Step [224/225], Training Accuracy: 62.3186%, Training Loss: 0.8060%\n",
      "Epoch [21/300], Step [225/225], Training Accuracy: 62.3263%, Training Loss: 0.8058%\n",
      "Epoch [22/300], Step [1/225], Training Accuracy: 71.8750%, Training Loss: 0.7171%\n",
      "Epoch [22/300], Step [2/225], Training Accuracy: 65.6250%, Training Loss: 0.7955%\n",
      "Epoch [22/300], Step [3/225], Training Accuracy: 63.0208%, Training Loss: 0.8087%\n",
      "Epoch [22/300], Step [4/225], Training Accuracy: 61.3281%, Training Loss: 0.8350%\n",
      "Epoch [22/300], Step [5/225], Training Accuracy: 62.5000%, Training Loss: 0.8207%\n",
      "Epoch [22/300], Step [6/225], Training Accuracy: 63.0208%, Training Loss: 0.8215%\n",
      "Epoch [22/300], Step [7/225], Training Accuracy: 62.2768%, Training Loss: 0.8353%\n",
      "Epoch [22/300], Step [8/225], Training Accuracy: 61.5234%, Training Loss: 0.8575%\n",
      "Epoch [22/300], Step [9/225], Training Accuracy: 62.3264%, Training Loss: 0.8468%\n",
      "Epoch [22/300], Step [10/225], Training Accuracy: 62.1875%, Training Loss: 0.8643%\n",
      "Epoch [22/300], Step [11/225], Training Accuracy: 62.2159%, Training Loss: 0.8640%\n",
      "Epoch [22/300], Step [12/225], Training Accuracy: 62.7604%, Training Loss: 0.8557%\n",
      "Epoch [22/300], Step [13/225], Training Accuracy: 63.4615%, Training Loss: 0.8408%\n",
      "Epoch [22/300], Step [14/225], Training Accuracy: 63.6161%, Training Loss: 0.8401%\n",
      "Epoch [22/300], Step [15/225], Training Accuracy: 63.6458%, Training Loss: 0.8351%\n",
      "Epoch [22/300], Step [16/225], Training Accuracy: 63.2812%, Training Loss: 0.8331%\n",
      "Epoch [22/300], Step [17/225], Training Accuracy: 63.4191%, Training Loss: 0.8265%\n",
      "Epoch [22/300], Step [18/225], Training Accuracy: 63.0208%, Training Loss: 0.8288%\n",
      "Epoch [22/300], Step [19/225], Training Accuracy: 63.0757%, Training Loss: 0.8285%\n",
      "Epoch [22/300], Step [20/225], Training Accuracy: 63.5938%, Training Loss: 0.8213%\n",
      "Epoch [22/300], Step [21/225], Training Accuracy: 63.9137%, Training Loss: 0.8190%\n",
      "Epoch [22/300], Step [22/225], Training Accuracy: 63.2102%, Training Loss: 0.8270%\n",
      "Epoch [22/300], Step [23/225], Training Accuracy: 63.3152%, Training Loss: 0.8247%\n",
      "Epoch [22/300], Step [24/225], Training Accuracy: 62.9557%, Training Loss: 0.8253%\n",
      "Epoch [22/300], Step [25/225], Training Accuracy: 63.2500%, Training Loss: 0.8221%\n",
      "Epoch [22/300], Step [26/225], Training Accuracy: 63.4014%, Training Loss: 0.8223%\n",
      "Epoch [22/300], Step [27/225], Training Accuracy: 63.5995%, Training Loss: 0.8216%\n",
      "Epoch [22/300], Step [28/225], Training Accuracy: 64.1741%, Training Loss: 0.8145%\n",
      "Epoch [22/300], Step [29/225], Training Accuracy: 64.4935%, Training Loss: 0.8083%\n",
      "Epoch [22/300], Step [30/225], Training Accuracy: 64.6875%, Training Loss: 0.8048%\n",
      "Epoch [22/300], Step [31/225], Training Accuracy: 64.7177%, Training Loss: 0.8054%\n",
      "Epoch [22/300], Step [32/225], Training Accuracy: 64.8438%, Training Loss: 0.8022%\n",
      "Epoch [22/300], Step [33/225], Training Accuracy: 64.9621%, Training Loss: 0.7999%\n",
      "Epoch [22/300], Step [34/225], Training Accuracy: 64.5680%, Training Loss: 0.8088%\n",
      "Epoch [22/300], Step [35/225], Training Accuracy: 64.2857%, Training Loss: 0.8183%\n",
      "Epoch [22/300], Step [36/225], Training Accuracy: 64.3229%, Training Loss: 0.8174%\n",
      "Epoch [22/300], Step [37/225], Training Accuracy: 64.2736%, Training Loss: 0.8165%\n",
      "Epoch [22/300], Step [38/225], Training Accuracy: 64.2681%, Training Loss: 0.8152%\n",
      "Epoch [22/300], Step [39/225], Training Accuracy: 64.1426%, Training Loss: 0.8143%\n",
      "Epoch [22/300], Step [40/225], Training Accuracy: 63.9453%, Training Loss: 0.8145%\n",
      "Epoch [22/300], Step [41/225], Training Accuracy: 63.7195%, Training Loss: 0.8177%\n",
      "Epoch [22/300], Step [42/225], Training Accuracy: 63.3929%, Training Loss: 0.8208%\n",
      "Epoch [22/300], Step [43/225], Training Accuracy: 63.4448%, Training Loss: 0.8199%\n",
      "Epoch [22/300], Step [44/225], Training Accuracy: 63.4943%, Training Loss: 0.8186%\n",
      "Epoch [22/300], Step [45/225], Training Accuracy: 63.5069%, Training Loss: 0.8181%\n",
      "Epoch [22/300], Step [46/225], Training Accuracy: 63.4511%, Training Loss: 0.8149%\n",
      "Epoch [22/300], Step [47/225], Training Accuracy: 63.3976%, Training Loss: 0.8150%\n",
      "Epoch [22/300], Step [48/225], Training Accuracy: 63.3464%, Training Loss: 0.8145%\n",
      "Epoch [22/300], Step [49/225], Training Accuracy: 63.4247%, Training Loss: 0.8145%\n",
      "Epoch [22/300], Step [50/225], Training Accuracy: 63.4062%, Training Loss: 0.8157%\n",
      "Epoch [22/300], Step [51/225], Training Accuracy: 63.5723%, Training Loss: 0.8126%\n",
      "Epoch [22/300], Step [52/225], Training Accuracy: 63.6719%, Training Loss: 0.8096%\n",
      "Epoch [22/300], Step [53/225], Training Accuracy: 63.5613%, Training Loss: 0.8122%\n",
      "Epoch [22/300], Step [54/225], Training Accuracy: 63.4549%, Training Loss: 0.8138%\n",
      "Epoch [22/300], Step [55/225], Training Accuracy: 63.3807%, Training Loss: 0.8156%\n",
      "Epoch [22/300], Step [56/225], Training Accuracy: 63.3929%, Training Loss: 0.8159%\n",
      "Epoch [22/300], Step [57/225], Training Accuracy: 63.3498%, Training Loss: 0.8147%\n",
      "Epoch [22/300], Step [58/225], Training Accuracy: 63.2004%, Training Loss: 0.8155%\n",
      "Epoch [22/300], Step [59/225], Training Accuracy: 63.0561%, Training Loss: 0.8162%\n",
      "Epoch [22/300], Step [60/225], Training Accuracy: 63.1771%, Training Loss: 0.8143%\n",
      "Epoch [22/300], Step [61/225], Training Accuracy: 63.1660%, Training Loss: 0.8127%\n",
      "Epoch [22/300], Step [62/225], Training Accuracy: 63.3821%, Training Loss: 0.8106%\n",
      "Epoch [22/300], Step [63/225], Training Accuracy: 63.3681%, Training Loss: 0.8105%\n",
      "Epoch [22/300], Step [64/225], Training Accuracy: 63.2080%, Training Loss: 0.8117%\n",
      "Epoch [22/300], Step [65/225], Training Accuracy: 63.4135%, Training Loss: 0.8103%\n",
      "Epoch [22/300], Step [66/225], Training Accuracy: 63.4706%, Training Loss: 0.8094%\n",
      "Epoch [22/300], Step [67/225], Training Accuracy: 63.4095%, Training Loss: 0.8094%\n",
      "Epoch [22/300], Step [68/225], Training Accuracy: 63.4191%, Training Loss: 0.8099%\n",
      "Epoch [22/300], Step [69/225], Training Accuracy: 63.4058%, Training Loss: 0.8107%\n",
      "Epoch [22/300], Step [70/225], Training Accuracy: 63.3482%, Training Loss: 0.8113%\n",
      "Epoch [22/300], Step [71/225], Training Accuracy: 63.3583%, Training Loss: 0.8102%\n",
      "Epoch [22/300], Step [72/225], Training Accuracy: 63.3030%, Training Loss: 0.8104%\n",
      "Epoch [22/300], Step [73/225], Training Accuracy: 63.3134%, Training Loss: 0.8124%\n",
      "Epoch [22/300], Step [74/225], Training Accuracy: 63.4079%, Training Loss: 0.8095%\n",
      "Epoch [22/300], Step [75/225], Training Accuracy: 63.2917%, Training Loss: 0.8099%\n",
      "Epoch [22/300], Step [76/225], Training Accuracy: 63.2607%, Training Loss: 0.8105%\n",
      "Epoch [22/300], Step [77/225], Training Accuracy: 63.2102%, Training Loss: 0.8118%\n",
      "Epoch [22/300], Step [78/225], Training Accuracy: 63.2612%, Training Loss: 0.8110%\n",
      "Epoch [22/300], Step [79/225], Training Accuracy: 63.1922%, Training Loss: 0.8122%\n",
      "Epoch [22/300], Step [80/225], Training Accuracy: 63.0664%, Training Loss: 0.8135%\n",
      "Epoch [22/300], Step [81/225], Training Accuracy: 63.1173%, Training Loss: 0.8126%\n",
      "Epoch [22/300], Step [82/225], Training Accuracy: 63.1098%, Training Loss: 0.8114%\n",
      "Epoch [22/300], Step [83/225], Training Accuracy: 62.9706%, Training Loss: 0.8119%\n",
      "Epoch [22/300], Step [84/225], Training Accuracy: 63.0022%, Training Loss: 0.8110%\n",
      "Epoch [22/300], Step [85/225], Training Accuracy: 62.9963%, Training Loss: 0.8104%\n",
      "Epoch [22/300], Step [86/225], Training Accuracy: 63.0814%, Training Loss: 0.8097%\n",
      "Epoch [22/300], Step [87/225], Training Accuracy: 63.0927%, Training Loss: 0.8100%\n",
      "Epoch [22/300], Step [88/225], Training Accuracy: 63.1392%, Training Loss: 0.8103%\n",
      "Epoch [22/300], Step [89/225], Training Accuracy: 63.1847%, Training Loss: 0.8113%\n",
      "Epoch [22/300], Step [90/225], Training Accuracy: 63.1250%, Training Loss: 0.8139%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/300], Step [91/225], Training Accuracy: 63.1868%, Training Loss: 0.8123%\n",
      "Epoch [22/300], Step [92/225], Training Accuracy: 63.2303%, Training Loss: 0.8120%\n",
      "Epoch [22/300], Step [93/225], Training Accuracy: 63.3569%, Training Loss: 0.8099%\n",
      "Epoch [22/300], Step [94/225], Training Accuracy: 63.3810%, Training Loss: 0.8086%\n",
      "Epoch [22/300], Step [95/225], Training Accuracy: 63.2730%, Training Loss: 0.8094%\n",
      "Epoch [22/300], Step [96/225], Training Accuracy: 63.3789%, Training Loss: 0.8073%\n",
      "Epoch [22/300], Step [97/225], Training Accuracy: 63.4021%, Training Loss: 0.8067%\n",
      "Epoch [22/300], Step [98/225], Training Accuracy: 63.4407%, Training Loss: 0.8054%\n",
      "Epoch [22/300], Step [99/225], Training Accuracy: 63.4628%, Training Loss: 0.8059%\n",
      "Epoch [22/300], Step [100/225], Training Accuracy: 63.4375%, Training Loss: 0.8066%\n",
      "Epoch [22/300], Step [101/225], Training Accuracy: 63.4282%, Training Loss: 0.8061%\n",
      "Epoch [22/300], Step [102/225], Training Accuracy: 63.3885%, Training Loss: 0.8069%\n",
      "Epoch [22/300], Step [103/225], Training Accuracy: 63.4557%, Training Loss: 0.8049%\n",
      "Epoch [22/300], Step [104/225], Training Accuracy: 63.4916%, Training Loss: 0.8045%\n",
      "Epoch [22/300], Step [105/225], Training Accuracy: 63.5268%, Training Loss: 0.8037%\n",
      "Epoch [22/300], Step [106/225], Training Accuracy: 63.6203%, Training Loss: 0.8020%\n",
      "Epoch [22/300], Step [107/225], Training Accuracy: 63.5806%, Training Loss: 0.8028%\n",
      "Epoch [22/300], Step [108/225], Training Accuracy: 63.5127%, Training Loss: 0.8035%\n",
      "Epoch [22/300], Step [109/225], Training Accuracy: 63.5464%, Training Loss: 0.8037%\n",
      "Epoch [22/300], Step [110/225], Training Accuracy: 63.6080%, Training Loss: 0.8028%\n",
      "Epoch [22/300], Step [111/225], Training Accuracy: 63.6120%, Training Loss: 0.8028%\n",
      "Epoch [22/300], Step [112/225], Training Accuracy: 63.6440%, Training Loss: 0.8018%\n",
      "Epoch [22/300], Step [113/225], Training Accuracy: 63.6062%, Training Loss: 0.8024%\n",
      "Epoch [22/300], Step [114/225], Training Accuracy: 63.5828%, Training Loss: 0.8015%\n",
      "Epoch [22/300], Step [115/225], Training Accuracy: 63.5462%, Training Loss: 0.8018%\n",
      "Epoch [22/300], Step [116/225], Training Accuracy: 63.5911%, Training Loss: 0.8013%\n",
      "Epoch [22/300], Step [117/225], Training Accuracy: 63.4882%, Training Loss: 0.8029%\n",
      "Epoch [22/300], Step [118/225], Training Accuracy: 63.4931%, Training Loss: 0.8023%\n",
      "Epoch [22/300], Step [119/225], Training Accuracy: 63.4979%, Training Loss: 0.8022%\n",
      "Epoch [22/300], Step [120/225], Training Accuracy: 63.4245%, Training Loss: 0.8024%\n",
      "Epoch [22/300], Step [121/225], Training Accuracy: 63.3910%, Training Loss: 0.8023%\n",
      "Epoch [22/300], Step [122/225], Training Accuracy: 63.3453%, Training Loss: 0.8021%\n",
      "Epoch [22/300], Step [123/225], Training Accuracy: 63.3511%, Training Loss: 0.8016%\n",
      "Epoch [22/300], Step [124/225], Training Accuracy: 63.3191%, Training Loss: 0.8011%\n",
      "Epoch [22/300], Step [125/225], Training Accuracy: 63.3250%, Training Loss: 0.8012%\n",
      "Epoch [22/300], Step [126/225], Training Accuracy: 63.3185%, Training Loss: 0.8015%\n",
      "Epoch [22/300], Step [127/225], Training Accuracy: 63.2874%, Training Loss: 0.8016%\n",
      "Epoch [22/300], Step [128/225], Training Accuracy: 63.2568%, Training Loss: 0.8029%\n",
      "Epoch [22/300], Step [129/225], Training Accuracy: 63.2873%, Training Loss: 0.8024%\n",
      "Epoch [22/300], Step [130/225], Training Accuracy: 63.3173%, Training Loss: 0.8022%\n",
      "Epoch [22/300], Step [131/225], Training Accuracy: 63.3349%, Training Loss: 0.8022%\n",
      "Epoch [22/300], Step [132/225], Training Accuracy: 63.3168%, Training Loss: 0.8023%\n",
      "Epoch [22/300], Step [133/225], Training Accuracy: 63.3224%, Training Loss: 0.8020%\n",
      "Epoch [22/300], Step [134/225], Training Accuracy: 63.2229%, Training Loss: 0.8027%\n",
      "Epoch [22/300], Step [135/225], Training Accuracy: 63.2639%, Training Loss: 0.8022%\n",
      "Epoch [22/300], Step [136/225], Training Accuracy: 63.2698%, Training Loss: 0.8015%\n",
      "Epoch [22/300], Step [137/225], Training Accuracy: 63.2527%, Training Loss: 0.8017%\n",
      "Epoch [22/300], Step [138/225], Training Accuracy: 63.2812%, Training Loss: 0.8006%\n",
      "Epoch [22/300], Step [139/225], Training Accuracy: 63.2644%, Training Loss: 0.8006%\n",
      "Epoch [22/300], Step [140/225], Training Accuracy: 63.2812%, Training Loss: 0.7996%\n",
      "Epoch [22/300], Step [141/225], Training Accuracy: 63.2868%, Training Loss: 0.7990%\n",
      "Epoch [22/300], Step [142/225], Training Accuracy: 63.2592%, Training Loss: 0.7987%\n",
      "Epoch [22/300], Step [143/225], Training Accuracy: 63.2212%, Training Loss: 0.7991%\n",
      "Epoch [22/300], Step [144/225], Training Accuracy: 63.1510%, Training Loss: 0.8000%\n",
      "Epoch [22/300], Step [145/225], Training Accuracy: 63.1897%, Training Loss: 0.7995%\n",
      "Epoch [22/300], Step [146/225], Training Accuracy: 63.1742%, Training Loss: 0.8002%\n",
      "Epoch [22/300], Step [147/225], Training Accuracy: 63.1590%, Training Loss: 0.7999%\n",
      "Epoch [22/300], Step [148/225], Training Accuracy: 63.2179%, Training Loss: 0.7990%\n",
      "Epoch [22/300], Step [149/225], Training Accuracy: 63.2445%, Training Loss: 0.7984%\n",
      "Epoch [22/300], Step [150/225], Training Accuracy: 63.2188%, Training Loss: 0.7986%\n",
      "Epoch [22/300], Step [151/225], Training Accuracy: 63.2140%, Training Loss: 0.7989%\n",
      "Epoch [22/300], Step [152/225], Training Accuracy: 63.1785%, Training Loss: 0.7991%\n",
      "Epoch [22/300], Step [153/225], Training Accuracy: 63.1842%, Training Loss: 0.7988%\n",
      "Epoch [22/300], Step [154/225], Training Accuracy: 63.1595%, Training Loss: 0.7983%\n",
      "Epoch [22/300], Step [155/225], Training Accuracy: 63.1149%, Training Loss: 0.7986%\n",
      "Epoch [22/300], Step [156/225], Training Accuracy: 63.0909%, Training Loss: 0.7992%\n",
      "Epoch [22/300], Step [157/225], Training Accuracy: 63.1469%, Training Loss: 0.7984%\n",
      "Epoch [22/300], Step [158/225], Training Accuracy: 63.1131%, Training Loss: 0.7998%\n",
      "Epoch [22/300], Step [159/225], Training Accuracy: 63.0700%, Training Loss: 0.8003%\n",
      "Epoch [22/300], Step [160/225], Training Accuracy: 63.0664%, Training Loss: 0.8000%\n",
      "Epoch [22/300], Step [161/225], Training Accuracy: 63.1017%, Training Loss: 0.7994%\n",
      "Epoch [22/300], Step [162/225], Training Accuracy: 63.1366%, Training Loss: 0.7994%\n",
      "Epoch [22/300], Step [163/225], Training Accuracy: 63.1518%, Training Loss: 0.7986%\n",
      "Epoch [22/300], Step [164/225], Training Accuracy: 63.1479%, Training Loss: 0.7987%\n",
      "Epoch [22/300], Step [165/225], Training Accuracy: 63.1534%, Training Loss: 0.7986%\n",
      "Epoch [22/300], Step [166/225], Training Accuracy: 63.1401%, Training Loss: 0.7984%\n",
      "Epoch [22/300], Step [167/225], Training Accuracy: 63.1362%, Training Loss: 0.7981%\n",
      "Epoch [22/300], Step [168/225], Training Accuracy: 63.1045%, Training Loss: 0.7983%\n",
      "Epoch [22/300], Step [169/225], Training Accuracy: 63.1287%, Training Loss: 0.7973%\n",
      "Epoch [22/300], Step [170/225], Training Accuracy: 63.1618%, Training Loss: 0.7972%\n",
      "Epoch [22/300], Step [171/225], Training Accuracy: 63.2036%, Training Loss: 0.7967%\n",
      "Epoch [22/300], Step [172/225], Training Accuracy: 63.1813%, Training Loss: 0.7967%\n",
      "Epoch [22/300], Step [173/225], Training Accuracy: 63.2316%, Training Loss: 0.7962%\n",
      "Epoch [22/300], Step [174/225], Training Accuracy: 63.2543%, Training Loss: 0.7960%\n",
      "Epoch [22/300], Step [175/225], Training Accuracy: 63.2589%, Training Loss: 0.7960%\n",
      "Epoch [22/300], Step [176/225], Training Accuracy: 63.3079%, Training Loss: 0.7952%\n",
      "Epoch [22/300], Step [177/225], Training Accuracy: 63.3475%, Training Loss: 0.7944%\n",
      "Epoch [22/300], Step [178/225], Training Accuracy: 63.3690%, Training Loss: 0.7942%\n",
      "Epoch [22/300], Step [179/225], Training Accuracy: 63.3904%, Training Loss: 0.7937%\n",
      "Epoch [22/300], Step [180/225], Training Accuracy: 63.4028%, Training Loss: 0.7930%\n",
      "Epoch [22/300], Step [181/225], Training Accuracy: 63.3805%, Training Loss: 0.7939%\n",
      "Epoch [22/300], Step [182/225], Training Accuracy: 63.4444%, Training Loss: 0.7940%\n",
      "Epoch [22/300], Step [183/225], Training Accuracy: 63.4307%, Training Loss: 0.7942%\n",
      "Epoch [22/300], Step [184/225], Training Accuracy: 63.4596%, Training Loss: 0.7940%\n",
      "Epoch [22/300], Step [185/225], Training Accuracy: 63.5135%, Training Loss: 0.7937%\n",
      "Epoch [22/300], Step [186/225], Training Accuracy: 63.5753%, Training Loss: 0.7928%\n",
      "Epoch [22/300], Step [187/225], Training Accuracy: 63.5862%, Training Loss: 0.7927%\n",
      "Epoch [22/300], Step [188/225], Training Accuracy: 63.6054%, Training Loss: 0.7921%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/300], Step [189/225], Training Accuracy: 63.6243%, Training Loss: 0.7911%\n",
      "Epoch [22/300], Step [190/225], Training Accuracy: 63.6431%, Training Loss: 0.7905%\n",
      "Epoch [22/300], Step [191/225], Training Accuracy: 63.6126%, Training Loss: 0.7911%\n",
      "Epoch [22/300], Step [192/225], Training Accuracy: 63.6719%, Training Loss: 0.7904%\n",
      "Epoch [22/300], Step [193/225], Training Accuracy: 63.6658%, Training Loss: 0.7908%\n",
      "Epoch [22/300], Step [194/225], Training Accuracy: 63.6437%, Training Loss: 0.7915%\n",
      "Epoch [22/300], Step [195/225], Training Accuracy: 63.7019%, Training Loss: 0.7905%\n",
      "Epoch [22/300], Step [196/225], Training Accuracy: 63.6958%, Training Loss: 0.7908%\n",
      "Epoch [22/300], Step [197/225], Training Accuracy: 63.6977%, Training Loss: 0.7910%\n",
      "Epoch [22/300], Step [198/225], Training Accuracy: 63.7074%, Training Loss: 0.7902%\n",
      "Epoch [22/300], Step [199/225], Training Accuracy: 63.7406%, Training Loss: 0.7899%\n",
      "Epoch [22/300], Step [200/225], Training Accuracy: 63.7344%, Training Loss: 0.7905%\n",
      "Epoch [22/300], Step [201/225], Training Accuracy: 63.7282%, Training Loss: 0.7907%\n",
      "Epoch [22/300], Step [202/225], Training Accuracy: 63.7299%, Training Loss: 0.7904%\n",
      "Epoch [22/300], Step [203/225], Training Accuracy: 63.7546%, Training Loss: 0.7897%\n",
      "Epoch [22/300], Step [204/225], Training Accuracy: 63.7255%, Training Loss: 0.7899%\n",
      "Epoch [22/300], Step [205/225], Training Accuracy: 63.7652%, Training Loss: 0.7892%\n",
      "Epoch [22/300], Step [206/225], Training Accuracy: 63.7667%, Training Loss: 0.7891%\n",
      "Epoch [22/300], Step [207/225], Training Accuracy: 63.8059%, Training Loss: 0.7890%\n",
      "Epoch [22/300], Step [208/225], Training Accuracy: 63.8146%, Training Loss: 0.7886%\n",
      "Epoch [22/300], Step [209/225], Training Accuracy: 63.8158%, Training Loss: 0.7883%\n",
      "Epoch [22/300], Step [210/225], Training Accuracy: 63.8095%, Training Loss: 0.7884%\n",
      "Epoch [22/300], Step [211/225], Training Accuracy: 63.7959%, Training Loss: 0.7878%\n",
      "Epoch [22/300], Step [212/225], Training Accuracy: 63.7898%, Training Loss: 0.7880%\n",
      "Epoch [22/300], Step [213/225], Training Accuracy: 63.7544%, Training Loss: 0.7883%\n",
      "Epoch [22/300], Step [214/225], Training Accuracy: 63.7777%, Training Loss: 0.7878%\n",
      "Epoch [22/300], Step [215/225], Training Accuracy: 63.7863%, Training Loss: 0.7874%\n",
      "Epoch [22/300], Step [216/225], Training Accuracy: 63.8093%, Training Loss: 0.7876%\n",
      "Epoch [22/300], Step [217/225], Training Accuracy: 63.7889%, Training Loss: 0.7879%\n",
      "Epoch [22/300], Step [218/225], Training Accuracy: 63.7973%, Training Loss: 0.7880%\n",
      "Epoch [22/300], Step [219/225], Training Accuracy: 63.8057%, Training Loss: 0.7885%\n",
      "Epoch [22/300], Step [220/225], Training Accuracy: 63.8068%, Training Loss: 0.7883%\n",
      "Epoch [22/300], Step [221/225], Training Accuracy: 63.8221%, Training Loss: 0.7882%\n",
      "Epoch [22/300], Step [222/225], Training Accuracy: 63.8232%, Training Loss: 0.7883%\n",
      "Epoch [22/300], Step [223/225], Training Accuracy: 63.7892%, Training Loss: 0.7884%\n",
      "Epoch [22/300], Step [224/225], Training Accuracy: 63.8114%, Training Loss: 0.7880%\n",
      "Epoch [22/300], Step [225/225], Training Accuracy: 63.7993%, Training Loss: 0.7882%\n",
      "Epoch [23/300], Step [1/225], Training Accuracy: 73.4375%, Training Loss: 0.6396%\n",
      "Epoch [23/300], Step [2/225], Training Accuracy: 67.9688%, Training Loss: 0.7144%\n",
      "Epoch [23/300], Step [3/225], Training Accuracy: 63.0208%, Training Loss: 0.8075%\n",
      "Epoch [23/300], Step [4/225], Training Accuracy: 64.4531%, Training Loss: 0.7798%\n",
      "Epoch [23/300], Step [5/225], Training Accuracy: 65.6250%, Training Loss: 0.7645%\n",
      "Epoch [23/300], Step [6/225], Training Accuracy: 66.6667%, Training Loss: 0.7577%\n",
      "Epoch [23/300], Step [7/225], Training Accuracy: 66.0714%, Training Loss: 0.7656%\n",
      "Epoch [23/300], Step [8/225], Training Accuracy: 65.0391%, Training Loss: 0.7759%\n",
      "Epoch [23/300], Step [9/225], Training Accuracy: 65.2778%, Training Loss: 0.7752%\n",
      "Epoch [23/300], Step [10/225], Training Accuracy: 64.2188%, Training Loss: 0.8052%\n",
      "Epoch [23/300], Step [11/225], Training Accuracy: 64.0625%, Training Loss: 0.8018%\n",
      "Epoch [23/300], Step [12/225], Training Accuracy: 64.0625%, Training Loss: 0.7950%\n",
      "Epoch [23/300], Step [13/225], Training Accuracy: 64.5433%, Training Loss: 0.7830%\n",
      "Epoch [23/300], Step [14/225], Training Accuracy: 64.7321%, Training Loss: 0.7828%\n",
      "Epoch [23/300], Step [15/225], Training Accuracy: 65.3125%, Training Loss: 0.7843%\n",
      "Epoch [23/300], Step [16/225], Training Accuracy: 64.8438%, Training Loss: 0.7880%\n",
      "Epoch [23/300], Step [17/225], Training Accuracy: 65.0735%, Training Loss: 0.7780%\n",
      "Epoch [23/300], Step [18/225], Training Accuracy: 65.7986%, Training Loss: 0.7695%\n",
      "Epoch [23/300], Step [19/225], Training Accuracy: 65.5428%, Training Loss: 0.7685%\n",
      "Epoch [23/300], Step [20/225], Training Accuracy: 66.0938%, Training Loss: 0.7612%\n",
      "Epoch [23/300], Step [21/225], Training Accuracy: 66.5179%, Training Loss: 0.7575%\n",
      "Epoch [23/300], Step [22/225], Training Accuracy: 66.0511%, Training Loss: 0.7608%\n",
      "Epoch [23/300], Step [23/225], Training Accuracy: 65.9647%, Training Loss: 0.7617%\n",
      "Epoch [23/300], Step [24/225], Training Accuracy: 65.6901%, Training Loss: 0.7627%\n",
      "Epoch [23/300], Step [25/225], Training Accuracy: 65.8750%, Training Loss: 0.7604%\n",
      "Epoch [23/300], Step [26/225], Training Accuracy: 65.8654%, Training Loss: 0.7579%\n",
      "Epoch [23/300], Step [27/225], Training Accuracy: 65.6250%, Training Loss: 0.7624%\n",
      "Epoch [23/300], Step [28/225], Training Accuracy: 65.7366%, Training Loss: 0.7594%\n",
      "Epoch [23/300], Step [29/225], Training Accuracy: 66.0022%, Training Loss: 0.7548%\n",
      "Epoch [23/300], Step [30/225], Training Accuracy: 65.9896%, Training Loss: 0.7571%\n",
      "Epoch [23/300], Step [31/225], Training Accuracy: 66.0282%, Training Loss: 0.7588%\n",
      "Epoch [23/300], Step [32/225], Training Accuracy: 66.1133%, Training Loss: 0.7565%\n",
      "Epoch [23/300], Step [33/225], Training Accuracy: 66.3352%, Training Loss: 0.7529%\n",
      "Epoch [23/300], Step [34/225], Training Accuracy: 65.9467%, Training Loss: 0.7603%\n",
      "Epoch [23/300], Step [35/225], Training Accuracy: 65.5804%, Training Loss: 0.7636%\n",
      "Epoch [23/300], Step [36/225], Training Accuracy: 65.5382%, Training Loss: 0.7627%\n",
      "Epoch [23/300], Step [37/225], Training Accuracy: 65.6250%, Training Loss: 0.7596%\n",
      "Epoch [23/300], Step [38/225], Training Accuracy: 65.7072%, Training Loss: 0.7584%\n",
      "Epoch [23/300], Step [39/225], Training Accuracy: 65.6250%, Training Loss: 0.7579%\n",
      "Epoch [23/300], Step [40/225], Training Accuracy: 65.3516%, Training Loss: 0.7617%\n",
      "Epoch [23/300], Step [41/225], Training Accuracy: 65.2439%, Training Loss: 0.7634%\n",
      "Epoch [23/300], Step [42/225], Training Accuracy: 64.7321%, Training Loss: 0.7706%\n",
      "Epoch [23/300], Step [43/225], Training Accuracy: 64.6076%, Training Loss: 0.7739%\n",
      "Epoch [23/300], Step [44/225], Training Accuracy: 64.6662%, Training Loss: 0.7751%\n",
      "Epoch [23/300], Step [45/225], Training Accuracy: 64.7917%, Training Loss: 0.7766%\n",
      "Epoch [23/300], Step [46/225], Training Accuracy: 64.7418%, Training Loss: 0.7750%\n",
      "Epoch [23/300], Step [47/225], Training Accuracy: 64.6941%, Training Loss: 0.7748%\n",
      "Epoch [23/300], Step [48/225], Training Accuracy: 64.5833%, Training Loss: 0.7757%\n",
      "Epoch [23/300], Step [49/225], Training Accuracy: 64.7321%, Training Loss: 0.7731%\n",
      "Epoch [23/300], Step [50/225], Training Accuracy: 64.7188%, Training Loss: 0.7730%\n",
      "Epoch [23/300], Step [51/225], Training Accuracy: 64.8897%, Training Loss: 0.7732%\n",
      "Epoch [23/300], Step [52/225], Training Accuracy: 65.0841%, Training Loss: 0.7713%\n",
      "Epoch [23/300], Step [53/225], Training Accuracy: 64.9764%, Training Loss: 0.7726%\n",
      "Epoch [23/300], Step [54/225], Training Accuracy: 64.7859%, Training Loss: 0.7754%\n",
      "Epoch [23/300], Step [55/225], Training Accuracy: 64.7443%, Training Loss: 0.7774%\n",
      "Epoch [23/300], Step [56/225], Training Accuracy: 64.6763%, Training Loss: 0.7786%\n",
      "Epoch [23/300], Step [57/225], Training Accuracy: 64.5833%, Training Loss: 0.7796%\n",
      "Epoch [23/300], Step [58/225], Training Accuracy: 64.6821%, Training Loss: 0.7788%\n",
      "Epoch [23/300], Step [59/225], Training Accuracy: 64.3273%, Training Loss: 0.7827%\n",
      "Epoch [23/300], Step [60/225], Training Accuracy: 64.2969%, Training Loss: 0.7823%\n",
      "Epoch [23/300], Step [61/225], Training Accuracy: 64.2674%, Training Loss: 0.7811%\n",
      "Epoch [23/300], Step [62/225], Training Accuracy: 64.2389%, Training Loss: 0.7802%\n",
      "Epoch [23/300], Step [63/225], Training Accuracy: 64.3105%, Training Loss: 0.7803%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/300], Step [64/225], Training Accuracy: 64.2334%, Training Loss: 0.7817%\n",
      "Epoch [23/300], Step [65/225], Training Accuracy: 64.3990%, Training Loss: 0.7808%\n",
      "Epoch [23/300], Step [66/225], Training Accuracy: 64.4650%, Training Loss: 0.7790%\n",
      "Epoch [23/300], Step [67/225], Training Accuracy: 64.3890%, Training Loss: 0.7797%\n",
      "Epoch [23/300], Step [68/225], Training Accuracy: 64.2923%, Training Loss: 0.7804%\n",
      "Epoch [23/300], Step [69/225], Training Accuracy: 64.2210%, Training Loss: 0.7808%\n",
      "Epoch [23/300], Step [70/225], Training Accuracy: 64.1071%, Training Loss: 0.7817%\n",
      "Epoch [23/300], Step [71/225], Training Accuracy: 64.1285%, Training Loss: 0.7802%\n",
      "Epoch [23/300], Step [72/225], Training Accuracy: 64.1710%, Training Loss: 0.7804%\n",
      "Epoch [23/300], Step [73/225], Training Accuracy: 64.1695%, Training Loss: 0.7809%\n",
      "Epoch [23/300], Step [74/225], Training Accuracy: 64.2948%, Training Loss: 0.7774%\n",
      "Epoch [23/300], Step [75/225], Training Accuracy: 64.2917%, Training Loss: 0.7761%\n",
      "Epoch [23/300], Step [76/225], Training Accuracy: 64.2475%, Training Loss: 0.7768%\n",
      "Epoch [23/300], Step [77/225], Training Accuracy: 64.3060%, Training Loss: 0.7758%\n",
      "Epoch [23/300], Step [78/225], Training Accuracy: 64.3630%, Training Loss: 0.7755%\n",
      "Epoch [23/300], Step [79/225], Training Accuracy: 64.4383%, Training Loss: 0.7747%\n",
      "Epoch [23/300], Step [80/225], Training Accuracy: 64.2969%, Training Loss: 0.7765%\n",
      "Epoch [23/300], Step [81/225], Training Accuracy: 64.1782%, Training Loss: 0.7780%\n",
      "Epoch [23/300], Step [82/225], Training Accuracy: 64.2721%, Training Loss: 0.7767%\n",
      "Epoch [23/300], Step [83/225], Training Accuracy: 64.2696%, Training Loss: 0.7764%\n",
      "Epoch [23/300], Step [84/225], Training Accuracy: 64.3601%, Training Loss: 0.7752%\n",
      "Epoch [23/300], Step [85/225], Training Accuracy: 64.4485%, Training Loss: 0.7733%\n",
      "Epoch [23/300], Step [86/225], Training Accuracy: 64.5349%, Training Loss: 0.7715%\n",
      "Epoch [23/300], Step [87/225], Training Accuracy: 64.4217%, Training Loss: 0.7718%\n",
      "Epoch [23/300], Step [88/225], Training Accuracy: 64.3288%, Training Loss: 0.7742%\n",
      "Epoch [23/300], Step [89/225], Training Accuracy: 64.3258%, Training Loss: 0.7750%\n",
      "Epoch [23/300], Step [90/225], Training Accuracy: 64.2882%, Training Loss: 0.7763%\n",
      "Epoch [23/300], Step [91/225], Training Accuracy: 64.3201%, Training Loss: 0.7755%\n",
      "Epoch [23/300], Step [92/225], Training Accuracy: 64.2833%, Training Loss: 0.7769%\n",
      "Epoch [23/300], Step [93/225], Training Accuracy: 64.3313%, Training Loss: 0.7759%\n",
      "Epoch [23/300], Step [94/225], Training Accuracy: 64.3949%, Training Loss: 0.7754%\n",
      "Epoch [23/300], Step [95/225], Training Accuracy: 64.4079%, Training Loss: 0.7752%\n",
      "Epoch [23/300], Step [96/225], Training Accuracy: 64.5345%, Training Loss: 0.7740%\n",
      "Epoch [23/300], Step [97/225], Training Accuracy: 64.5457%, Training Loss: 0.7736%\n",
      "Epoch [23/300], Step [98/225], Training Accuracy: 64.5089%, Training Loss: 0.7732%\n",
      "Epoch [23/300], Step [99/225], Training Accuracy: 64.5202%, Training Loss: 0.7726%\n",
      "Epoch [23/300], Step [100/225], Training Accuracy: 64.4062%, Training Loss: 0.7742%\n",
      "Epoch [23/300], Step [101/225], Training Accuracy: 64.4183%, Training Loss: 0.7739%\n",
      "Epoch [23/300], Step [102/225], Training Accuracy: 64.4455%, Training Loss: 0.7741%\n",
      "Epoch [23/300], Step [103/225], Training Accuracy: 64.5328%, Training Loss: 0.7723%\n",
      "Epoch [23/300], Step [104/225], Training Accuracy: 64.6484%, Training Loss: 0.7712%\n",
      "Epoch [23/300], Step [105/225], Training Accuracy: 64.6429%, Training Loss: 0.7707%\n",
      "Epoch [23/300], Step [106/225], Training Accuracy: 64.6669%, Training Loss: 0.7704%\n",
      "Epoch [23/300], Step [107/225], Training Accuracy: 64.6466%, Training Loss: 0.7709%\n",
      "Epoch [23/300], Step [108/225], Training Accuracy: 64.6412%, Training Loss: 0.7708%\n",
      "Epoch [23/300], Step [109/225], Training Accuracy: 64.7076%, Training Loss: 0.7703%\n",
      "Epoch [23/300], Step [110/225], Training Accuracy: 64.7443%, Training Loss: 0.7699%\n",
      "Epoch [23/300], Step [111/225], Training Accuracy: 64.7241%, Training Loss: 0.7707%\n",
      "Epoch [23/300], Step [112/225], Training Accuracy: 64.7740%, Training Loss: 0.7693%\n",
      "Epoch [23/300], Step [113/225], Training Accuracy: 64.7262%, Training Loss: 0.7700%\n",
      "Epoch [23/300], Step [114/225], Training Accuracy: 64.6519%, Training Loss: 0.7693%\n",
      "Epoch [23/300], Step [115/225], Training Accuracy: 64.5924%, Training Loss: 0.7697%\n",
      "Epoch [23/300], Step [116/225], Training Accuracy: 64.6417%, Training Loss: 0.7689%\n",
      "Epoch [23/300], Step [117/225], Training Accuracy: 64.5433%, Training Loss: 0.7700%\n",
      "Epoch [23/300], Step [118/225], Training Accuracy: 64.5789%, Training Loss: 0.7697%\n",
      "Epoch [23/300], Step [119/225], Training Accuracy: 64.6402%, Training Loss: 0.7691%\n",
      "Epoch [23/300], Step [120/225], Training Accuracy: 64.5964%, Training Loss: 0.7689%\n",
      "Epoch [23/300], Step [121/225], Training Accuracy: 64.5145%, Training Loss: 0.7692%\n",
      "Epoch [23/300], Step [122/225], Training Accuracy: 64.4980%, Training Loss: 0.7691%\n",
      "Epoch [23/300], Step [123/225], Training Accuracy: 64.5452%, Training Loss: 0.7687%\n",
      "Epoch [23/300], Step [124/225], Training Accuracy: 64.5539%, Training Loss: 0.7681%\n",
      "Epoch [23/300], Step [125/225], Training Accuracy: 64.4750%, Training Loss: 0.7696%\n",
      "Epoch [23/300], Step [126/225], Training Accuracy: 64.4097%, Training Loss: 0.7700%\n",
      "Epoch [23/300], Step [127/225], Training Accuracy: 64.3947%, Training Loss: 0.7711%\n",
      "Epoch [23/300], Step [128/225], Training Accuracy: 64.3433%, Training Loss: 0.7716%\n",
      "Epoch [23/300], Step [129/225], Training Accuracy: 64.4138%, Training Loss: 0.7719%\n",
      "Epoch [23/300], Step [130/225], Training Accuracy: 64.4351%, Training Loss: 0.7720%\n",
      "Epoch [23/300], Step [131/225], Training Accuracy: 64.4084%, Training Loss: 0.7720%\n",
      "Epoch [23/300], Step [132/225], Training Accuracy: 64.3111%, Training Loss: 0.7727%\n",
      "Epoch [23/300], Step [133/225], Training Accuracy: 64.2975%, Training Loss: 0.7720%\n",
      "Epoch [23/300], Step [134/225], Training Accuracy: 64.2374%, Training Loss: 0.7736%\n",
      "Epoch [23/300], Step [135/225], Training Accuracy: 64.2361%, Training Loss: 0.7730%\n",
      "Epoch [23/300], Step [136/225], Training Accuracy: 64.2693%, Training Loss: 0.7727%\n",
      "Epoch [23/300], Step [137/225], Training Accuracy: 64.3020%, Training Loss: 0.7721%\n",
      "Epoch [23/300], Step [138/225], Training Accuracy: 64.4022%, Training Loss: 0.7705%\n",
      "Epoch [23/300], Step [139/225], Training Accuracy: 64.4222%, Training Loss: 0.7701%\n",
      "Epoch [23/300], Step [140/225], Training Accuracy: 64.4531%, Training Loss: 0.7694%\n",
      "Epoch [23/300], Step [141/225], Training Accuracy: 64.4947%, Training Loss: 0.7687%\n",
      "Epoch [23/300], Step [142/225], Training Accuracy: 64.4586%, Training Loss: 0.7684%\n",
      "Epoch [23/300], Step [143/225], Training Accuracy: 64.4449%, Training Loss: 0.7685%\n",
      "Epoch [23/300], Step [144/225], Training Accuracy: 64.4640%, Training Loss: 0.7685%\n",
      "Epoch [23/300], Step [145/225], Training Accuracy: 64.4935%, Training Loss: 0.7676%\n",
      "Epoch [23/300], Step [146/225], Training Accuracy: 64.4264%, Training Loss: 0.7684%\n",
      "Epoch [23/300], Step [147/225], Training Accuracy: 64.4239%, Training Loss: 0.7690%\n",
      "Epoch [23/300], Step [148/225], Training Accuracy: 64.5059%, Training Loss: 0.7676%\n",
      "Epoch [23/300], Step [149/225], Training Accuracy: 64.5344%, Training Loss: 0.7671%\n",
      "Epoch [23/300], Step [150/225], Training Accuracy: 64.5521%, Training Loss: 0.7665%\n",
      "Epoch [23/300], Step [151/225], Training Accuracy: 64.5488%, Training Loss: 0.7666%\n",
      "Epoch [23/300], Step [152/225], Training Accuracy: 64.5456%, Training Loss: 0.7667%\n",
      "Epoch [23/300], Step [153/225], Training Accuracy: 64.5323%, Training Loss: 0.7667%\n",
      "Epoch [23/300], Step [154/225], Training Accuracy: 64.5191%, Training Loss: 0.7664%\n",
      "Epoch [23/300], Step [155/225], Training Accuracy: 64.5060%, Training Loss: 0.7670%\n",
      "Epoch [23/300], Step [156/225], Training Accuracy: 64.4932%, Training Loss: 0.7670%\n",
      "Epoch [23/300], Step [157/225], Training Accuracy: 64.5502%, Training Loss: 0.7658%\n",
      "Epoch [23/300], Step [158/225], Training Accuracy: 64.4877%, Training Loss: 0.7667%\n",
      "Epoch [23/300], Step [159/225], Training Accuracy: 64.4949%, Training Loss: 0.7669%\n",
      "Epoch [23/300], Step [160/225], Training Accuracy: 64.5020%, Training Loss: 0.7668%\n",
      "Epoch [23/300], Step [161/225], Training Accuracy: 64.5186%, Training Loss: 0.7669%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/300], Step [162/225], Training Accuracy: 64.5255%, Training Loss: 0.7672%\n",
      "Epoch [23/300], Step [163/225], Training Accuracy: 64.5514%, Training Loss: 0.7664%\n",
      "Epoch [23/300], Step [164/225], Training Accuracy: 64.5484%, Training Loss: 0.7664%\n",
      "Epoch [23/300], Step [165/225], Training Accuracy: 64.5644%, Training Loss: 0.7664%\n",
      "Epoch [23/300], Step [166/225], Training Accuracy: 64.5520%, Training Loss: 0.7665%\n",
      "Epoch [23/300], Step [167/225], Training Accuracy: 64.5865%, Training Loss: 0.7656%\n",
      "Epoch [23/300], Step [168/225], Training Accuracy: 64.5926%, Training Loss: 0.7659%\n",
      "Epoch [23/300], Step [169/225], Training Accuracy: 64.6357%, Training Loss: 0.7652%\n",
      "Epoch [23/300], Step [170/225], Training Accuracy: 64.6232%, Training Loss: 0.7652%\n",
      "Epoch [23/300], Step [171/225], Training Accuracy: 64.6656%, Training Loss: 0.7644%\n",
      "Epoch [23/300], Step [172/225], Training Accuracy: 64.6802%, Training Loss: 0.7643%\n",
      "Epoch [23/300], Step [173/225], Training Accuracy: 64.7038%, Training Loss: 0.7639%\n",
      "Epoch [23/300], Step [174/225], Training Accuracy: 64.7719%, Training Loss: 0.7632%\n",
      "Epoch [23/300], Step [175/225], Training Accuracy: 64.7321%, Training Loss: 0.7631%\n",
      "Epoch [23/300], Step [176/225], Training Accuracy: 64.7550%, Training Loss: 0.7627%\n",
      "Epoch [23/300], Step [177/225], Training Accuracy: 64.8040%, Training Loss: 0.7619%\n",
      "Epoch [23/300], Step [178/225], Training Accuracy: 64.8613%, Training Loss: 0.7613%\n",
      "Epoch [23/300], Step [179/225], Training Accuracy: 64.9441%, Training Loss: 0.7607%\n",
      "Epoch [23/300], Step [180/225], Training Accuracy: 64.9566%, Training Loss: 0.7607%\n",
      "Epoch [23/300], Step [181/225], Training Accuracy: 64.9862%, Training Loss: 0.7605%\n",
      "Epoch [23/300], Step [182/225], Training Accuracy: 65.0412%, Training Loss: 0.7598%\n",
      "Epoch [23/300], Step [183/225], Training Accuracy: 65.0273%, Training Loss: 0.7602%\n",
      "Epoch [23/300], Step [184/225], Training Accuracy: 64.9966%, Training Loss: 0.7604%\n",
      "Epoch [23/300], Step [185/225], Training Accuracy: 65.0084%, Training Loss: 0.7602%\n",
      "Epoch [23/300], Step [186/225], Training Accuracy: 65.0706%, Training Loss: 0.7593%\n",
      "Epoch [23/300], Step [187/225], Training Accuracy: 65.0735%, Training Loss: 0.7592%\n",
      "Epoch [23/300], Step [188/225], Training Accuracy: 65.0848%, Training Loss: 0.7593%\n",
      "Epoch [23/300], Step [189/225], Training Accuracy: 65.1290%, Training Loss: 0.7588%\n",
      "Epoch [23/300], Step [190/225], Training Accuracy: 65.1234%, Training Loss: 0.7589%\n",
      "Epoch [23/300], Step [191/225], Training Accuracy: 65.1178%, Training Loss: 0.7584%\n",
      "Epoch [23/300], Step [192/225], Training Accuracy: 65.1774%, Training Loss: 0.7576%\n",
      "Epoch [23/300], Step [193/225], Training Accuracy: 65.1878%, Training Loss: 0.7577%\n",
      "Epoch [23/300], Step [194/225], Training Accuracy: 65.1659%, Training Loss: 0.7582%\n",
      "Epoch [23/300], Step [195/225], Training Accuracy: 65.2083%, Training Loss: 0.7576%\n",
      "Epoch [23/300], Step [196/225], Training Accuracy: 65.2344%, Training Loss: 0.7577%\n",
      "Epoch [23/300], Step [197/225], Training Accuracy: 65.2284%, Training Loss: 0.7575%\n",
      "Epoch [23/300], Step [198/225], Training Accuracy: 65.2068%, Training Loss: 0.7575%\n",
      "Epoch [23/300], Step [199/225], Training Accuracy: 65.1774%, Training Loss: 0.7572%\n",
      "Epoch [23/300], Step [200/225], Training Accuracy: 65.1641%, Training Loss: 0.7574%\n",
      "Epoch [23/300], Step [201/225], Training Accuracy: 65.1275%, Training Loss: 0.7577%\n",
      "Epoch [23/300], Step [202/225], Training Accuracy: 65.1377%, Training Loss: 0.7575%\n",
      "Epoch [23/300], Step [203/225], Training Accuracy: 65.1709%, Training Loss: 0.7569%\n",
      "Epoch [23/300], Step [204/225], Training Accuracy: 65.1808%, Training Loss: 0.7574%\n",
      "Epoch [23/300], Step [205/225], Training Accuracy: 65.1829%, Training Loss: 0.7575%\n",
      "Epoch [23/300], Step [206/225], Training Accuracy: 65.2078%, Training Loss: 0.7573%\n",
      "Epoch [23/300], Step [207/225], Training Accuracy: 65.2400%, Training Loss: 0.7572%\n",
      "Epoch [23/300], Step [208/225], Training Accuracy: 65.2344%, Training Loss: 0.7566%\n",
      "Epoch [23/300], Step [209/225], Training Accuracy: 65.2213%, Training Loss: 0.7572%\n",
      "Epoch [23/300], Step [210/225], Training Accuracy: 65.2232%, Training Loss: 0.7575%\n",
      "Epoch [23/300], Step [211/225], Training Accuracy: 65.2621%, Training Loss: 0.7569%\n",
      "Epoch [23/300], Step [212/225], Training Accuracy: 65.2786%, Training Loss: 0.7570%\n",
      "Epoch [23/300], Step [213/225], Training Accuracy: 65.2435%, Training Loss: 0.7578%\n",
      "Epoch [23/300], Step [214/225], Training Accuracy: 65.2599%, Training Loss: 0.7572%\n",
      "Epoch [23/300], Step [215/225], Training Accuracy: 65.2834%, Training Loss: 0.7573%\n",
      "Epoch [23/300], Step [216/225], Training Accuracy: 65.2778%, Training Loss: 0.7576%\n",
      "Epoch [23/300], Step [217/225], Training Accuracy: 65.2362%, Training Loss: 0.7583%\n",
      "Epoch [23/300], Step [218/225], Training Accuracy: 65.2380%, Training Loss: 0.7585%\n",
      "Epoch [23/300], Step [219/225], Training Accuracy: 65.2397%, Training Loss: 0.7584%\n",
      "Epoch [23/300], Step [220/225], Training Accuracy: 65.2841%, Training Loss: 0.7578%\n",
      "Epoch [23/300], Step [221/225], Training Accuracy: 65.2644%, Training Loss: 0.7580%\n",
      "Epoch [23/300], Step [222/225], Training Accuracy: 65.2590%, Training Loss: 0.7583%\n",
      "Epoch [23/300], Step [223/225], Training Accuracy: 65.2186%, Training Loss: 0.7596%\n",
      "Epoch [23/300], Step [224/225], Training Accuracy: 65.2274%, Training Loss: 0.7594%\n",
      "Epoch [23/300], Step [225/225], Training Accuracy: 65.2307%, Training Loss: 0.7596%\n",
      "Epoch [24/300], Step [1/225], Training Accuracy: 71.8750%, Training Loss: 0.5912%\n",
      "Epoch [24/300], Step [2/225], Training Accuracy: 73.4375%, Training Loss: 0.6573%\n",
      "Epoch [24/300], Step [3/225], Training Accuracy: 67.1875%, Training Loss: 0.7584%\n",
      "Epoch [24/300], Step [4/225], Training Accuracy: 66.4062%, Training Loss: 0.7596%\n",
      "Epoch [24/300], Step [5/225], Training Accuracy: 68.1250%, Training Loss: 0.7266%\n",
      "Epoch [24/300], Step [6/225], Training Accuracy: 68.2292%, Training Loss: 0.7102%\n",
      "Epoch [24/300], Step [7/225], Training Accuracy: 66.2946%, Training Loss: 0.7356%\n",
      "Epoch [24/300], Step [8/225], Training Accuracy: 65.4297%, Training Loss: 0.7468%\n",
      "Epoch [24/300], Step [9/225], Training Accuracy: 65.4514%, Training Loss: 0.7457%\n",
      "Epoch [24/300], Step [10/225], Training Accuracy: 64.3750%, Training Loss: 0.7671%\n",
      "Epoch [24/300], Step [11/225], Training Accuracy: 64.2045%, Training Loss: 0.7728%\n",
      "Epoch [24/300], Step [12/225], Training Accuracy: 64.3229%, Training Loss: 0.7662%\n",
      "Epoch [24/300], Step [13/225], Training Accuracy: 65.0240%, Training Loss: 0.7489%\n",
      "Epoch [24/300], Step [14/225], Training Accuracy: 65.0670%, Training Loss: 0.7566%\n",
      "Epoch [24/300], Step [15/225], Training Accuracy: 65.1042%, Training Loss: 0.7548%\n",
      "Epoch [24/300], Step [16/225], Training Accuracy: 64.9414%, Training Loss: 0.7565%\n",
      "Epoch [24/300], Step [17/225], Training Accuracy: 64.9816%, Training Loss: 0.7521%\n",
      "Epoch [24/300], Step [18/225], Training Accuracy: 65.0174%, Training Loss: 0.7516%\n",
      "Epoch [24/300], Step [19/225], Training Accuracy: 65.1316%, Training Loss: 0.7567%\n",
      "Epoch [24/300], Step [20/225], Training Accuracy: 65.3906%, Training Loss: 0.7538%\n",
      "Epoch [24/300], Step [21/225], Training Accuracy: 65.3274%, Training Loss: 0.7538%\n",
      "Epoch [24/300], Step [22/225], Training Accuracy: 65.2699%, Training Loss: 0.7526%\n",
      "Epoch [24/300], Step [23/225], Training Accuracy: 65.5571%, Training Loss: 0.7510%\n",
      "Epoch [24/300], Step [24/225], Training Accuracy: 65.4948%, Training Loss: 0.7523%\n",
      "Epoch [24/300], Step [25/225], Training Accuracy: 65.6250%, Training Loss: 0.7487%\n",
      "Epoch [24/300], Step [26/225], Training Accuracy: 65.7452%, Training Loss: 0.7450%\n",
      "Epoch [24/300], Step [27/225], Training Accuracy: 65.7986%, Training Loss: 0.7465%\n",
      "Epoch [24/300], Step [28/225], Training Accuracy: 66.3504%, Training Loss: 0.7398%\n",
      "Epoch [24/300], Step [29/225], Training Accuracy: 66.3793%, Training Loss: 0.7357%\n",
      "Epoch [24/300], Step [30/225], Training Accuracy: 66.7708%, Training Loss: 0.7326%\n",
      "Epoch [24/300], Step [31/225], Training Accuracy: 66.5827%, Training Loss: 0.7353%\n",
      "Epoch [24/300], Step [32/225], Training Accuracy: 66.7969%, Training Loss: 0.7316%\n",
      "Epoch [24/300], Step [33/225], Training Accuracy: 66.9981%, Training Loss: 0.7300%\n",
      "Epoch [24/300], Step [34/225], Training Accuracy: 66.7279%, Training Loss: 0.7386%\n",
      "Epoch [24/300], Step [35/225], Training Accuracy: 66.5179%, Training Loss: 0.7466%\n",
      "Epoch [24/300], Step [36/225], Training Accuracy: 66.4062%, Training Loss: 0.7472%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/300], Step [37/225], Training Accuracy: 66.2584%, Training Loss: 0.7453%\n",
      "Epoch [24/300], Step [38/225], Training Accuracy: 66.3240%, Training Loss: 0.7437%\n",
      "Epoch [24/300], Step [39/225], Training Accuracy: 66.3061%, Training Loss: 0.7442%\n",
      "Epoch [24/300], Step [40/225], Training Accuracy: 66.0156%, Training Loss: 0.7469%\n",
      "Epoch [24/300], Step [41/225], Training Accuracy: 65.8537%, Training Loss: 0.7490%\n",
      "Epoch [24/300], Step [42/225], Training Accuracy: 65.6622%, Training Loss: 0.7508%\n",
      "Epoch [24/300], Step [43/225], Training Accuracy: 65.5160%, Training Loss: 0.7569%\n",
      "Epoch [24/300], Step [44/225], Training Accuracy: 65.5540%, Training Loss: 0.7552%\n",
      "Epoch [24/300], Step [45/225], Training Accuracy: 65.4514%, Training Loss: 0.7575%\n",
      "Epoch [24/300], Step [46/225], Training Accuracy: 65.5571%, Training Loss: 0.7562%\n",
      "Epoch [24/300], Step [47/225], Training Accuracy: 65.5918%, Training Loss: 0.7561%\n",
      "Epoch [24/300], Step [48/225], Training Accuracy: 65.4297%, Training Loss: 0.7570%\n",
      "Epoch [24/300], Step [49/225], Training Accuracy: 65.5931%, Training Loss: 0.7546%\n",
      "Epoch [24/300], Step [50/225], Training Accuracy: 65.4375%, Training Loss: 0.7561%\n",
      "Epoch [24/300], Step [51/225], Training Accuracy: 65.5025%, Training Loss: 0.7538%\n",
      "Epoch [24/300], Step [52/225], Training Accuracy: 65.6250%, Training Loss: 0.7510%\n",
      "Epoch [24/300], Step [53/225], Training Accuracy: 65.6545%, Training Loss: 0.7512%\n",
      "Epoch [24/300], Step [54/225], Training Accuracy: 65.4803%, Training Loss: 0.7546%\n",
      "Epoch [24/300], Step [55/225], Training Accuracy: 65.4830%, Training Loss: 0.7552%\n",
      "Epoch [24/300], Step [56/225], Training Accuracy: 65.4855%, Training Loss: 0.7550%\n",
      "Epoch [24/300], Step [57/225], Training Accuracy: 65.4605%, Training Loss: 0.7548%\n",
      "Epoch [24/300], Step [58/225], Training Accuracy: 65.4903%, Training Loss: 0.7536%\n",
      "Epoch [24/300], Step [59/225], Training Accuracy: 65.4131%, Training Loss: 0.7560%\n",
      "Epoch [24/300], Step [60/225], Training Accuracy: 65.3646%, Training Loss: 0.7555%\n",
      "Epoch [24/300], Step [61/225], Training Accuracy: 65.3432%, Training Loss: 0.7549%\n",
      "Epoch [24/300], Step [62/225], Training Accuracy: 65.3982%, Training Loss: 0.7554%\n",
      "Epoch [24/300], Step [63/225], Training Accuracy: 65.4514%, Training Loss: 0.7563%\n",
      "Epoch [24/300], Step [64/225], Training Accuracy: 65.3809%, Training Loss: 0.7585%\n",
      "Epoch [24/300], Step [65/225], Training Accuracy: 65.5288%, Training Loss: 0.7570%\n",
      "Epoch [24/300], Step [66/225], Training Accuracy: 65.6723%, Training Loss: 0.7547%\n",
      "Epoch [24/300], Step [67/225], Training Accuracy: 65.5317%, Training Loss: 0.7558%\n",
      "Epoch [24/300], Step [68/225], Training Accuracy: 65.4871%, Training Loss: 0.7565%\n",
      "Epoch [24/300], Step [69/225], Training Accuracy: 65.4212%, Training Loss: 0.7567%\n",
      "Epoch [24/300], Step [70/225], Training Accuracy: 65.2679%, Training Loss: 0.7583%\n",
      "Epoch [24/300], Step [71/225], Training Accuracy: 65.2949%, Training Loss: 0.7572%\n",
      "Epoch [24/300], Step [72/225], Training Accuracy: 65.2778%, Training Loss: 0.7571%\n",
      "Epoch [24/300], Step [73/225], Training Accuracy: 65.3253%, Training Loss: 0.7590%\n",
      "Epoch [24/300], Step [74/225], Training Accuracy: 65.4983%, Training Loss: 0.7567%\n",
      "Epoch [24/300], Step [75/225], Training Accuracy: 65.4583%, Training Loss: 0.7565%\n",
      "Epoch [24/300], Step [76/225], Training Accuracy: 65.3372%, Training Loss: 0.7580%\n",
      "Epoch [24/300], Step [77/225], Training Accuracy: 65.3409%, Training Loss: 0.7585%\n",
      "Epoch [24/300], Step [78/225], Training Accuracy: 65.4247%, Training Loss: 0.7572%\n",
      "Epoch [24/300], Step [79/225], Training Accuracy: 65.4866%, Training Loss: 0.7561%\n",
      "Epoch [24/300], Step [80/225], Training Accuracy: 65.4492%, Training Loss: 0.7564%\n",
      "Epoch [24/300], Step [81/225], Training Accuracy: 65.3935%, Training Loss: 0.7575%\n",
      "Epoch [24/300], Step [82/225], Training Accuracy: 65.4535%, Training Loss: 0.7571%\n",
      "Epoch [24/300], Step [83/225], Training Accuracy: 65.4556%, Training Loss: 0.7565%\n",
      "Epoch [24/300], Step [84/225], Training Accuracy: 65.5134%, Training Loss: 0.7553%\n",
      "Epoch [24/300], Step [85/225], Training Accuracy: 65.6434%, Training Loss: 0.7542%\n",
      "Epoch [24/300], Step [86/225], Training Accuracy: 65.7522%, Training Loss: 0.7528%\n",
      "Epoch [24/300], Step [87/225], Training Accuracy: 65.6968%, Training Loss: 0.7543%\n",
      "Epoch [24/300], Step [88/225], Training Accuracy: 65.6072%, Training Loss: 0.7557%\n",
      "Epoch [24/300], Step [89/225], Training Accuracy: 65.6250%, Training Loss: 0.7576%\n",
      "Epoch [24/300], Step [90/225], Training Accuracy: 65.5382%, Training Loss: 0.7598%\n",
      "Epoch [24/300], Step [91/225], Training Accuracy: 65.5220%, Training Loss: 0.7587%\n",
      "Epoch [24/300], Step [92/225], Training Accuracy: 65.5061%, Training Loss: 0.7596%\n",
      "Epoch [24/300], Step [93/225], Training Accuracy: 65.5578%, Training Loss: 0.7589%\n",
      "Epoch [24/300], Step [94/225], Training Accuracy: 65.5585%, Training Loss: 0.7589%\n",
      "Epoch [24/300], Step [95/225], Training Accuracy: 65.4770%, Training Loss: 0.7598%\n",
      "Epoch [24/300], Step [96/225], Training Accuracy: 65.5924%, Training Loss: 0.7584%\n",
      "Epoch [24/300], Step [97/225], Training Accuracy: 65.6572%, Training Loss: 0.7576%\n",
      "Epoch [24/300], Step [98/225], Training Accuracy: 65.6250%, Training Loss: 0.7581%\n",
      "Epoch [24/300], Step [99/225], Training Accuracy: 65.7670%, Training Loss: 0.7569%\n",
      "Epoch [24/300], Step [100/225], Training Accuracy: 65.7344%, Training Loss: 0.7582%\n",
      "Epoch [24/300], Step [101/225], Training Accuracy: 65.7488%, Training Loss: 0.7581%\n",
      "Epoch [24/300], Step [102/225], Training Accuracy: 65.7169%, Training Loss: 0.7593%\n",
      "Epoch [24/300], Step [103/225], Training Accuracy: 65.7160%, Training Loss: 0.7589%\n",
      "Epoch [24/300], Step [104/225], Training Accuracy: 65.5950%, Training Loss: 0.7598%\n",
      "Epoch [24/300], Step [105/225], Training Accuracy: 65.5804%, Training Loss: 0.7594%\n",
      "Epoch [24/300], Step [106/225], Training Accuracy: 65.6397%, Training Loss: 0.7583%\n",
      "Epoch [24/300], Step [107/225], Training Accuracy: 65.5666%, Training Loss: 0.7597%\n",
      "Epoch [24/300], Step [108/225], Training Accuracy: 65.5671%, Training Loss: 0.7603%\n",
      "Epoch [24/300], Step [109/225], Training Accuracy: 65.5963%, Training Loss: 0.7596%\n",
      "Epoch [24/300], Step [110/225], Training Accuracy: 65.6676%, Training Loss: 0.7590%\n",
      "Epoch [24/300], Step [111/225], Training Accuracy: 65.6532%, Training Loss: 0.7593%\n",
      "Epoch [24/300], Step [112/225], Training Accuracy: 65.6808%, Training Loss: 0.7584%\n",
      "Epoch [24/300], Step [113/225], Training Accuracy: 65.7218%, Training Loss: 0.7578%\n",
      "Epoch [24/300], Step [114/225], Training Accuracy: 65.7621%, Training Loss: 0.7566%\n",
      "Epoch [24/300], Step [115/225], Training Accuracy: 65.8016%, Training Loss: 0.7559%\n",
      "Epoch [24/300], Step [116/225], Training Accuracy: 65.8944%, Training Loss: 0.7548%\n",
      "Epoch [24/300], Step [117/225], Training Accuracy: 65.7853%, Training Loss: 0.7553%\n",
      "Epoch [24/300], Step [118/225], Training Accuracy: 65.8104%, Training Loss: 0.7548%\n",
      "Epoch [24/300], Step [119/225], Training Accuracy: 65.9007%, Training Loss: 0.7541%\n",
      "Epoch [24/300], Step [120/225], Training Accuracy: 65.8854%, Training Loss: 0.7542%\n",
      "Epoch [24/300], Step [121/225], Training Accuracy: 65.8833%, Training Loss: 0.7541%\n",
      "Epoch [24/300], Step [122/225], Training Accuracy: 65.8299%, Training Loss: 0.7549%\n",
      "Epoch [24/300], Step [123/225], Training Accuracy: 65.8537%, Training Loss: 0.7540%\n",
      "Epoch [24/300], Step [124/225], Training Accuracy: 65.8392%, Training Loss: 0.7537%\n",
      "Epoch [24/300], Step [125/225], Training Accuracy: 65.8125%, Training Loss: 0.7544%\n",
      "Epoch [24/300], Step [126/225], Training Accuracy: 65.8358%, Training Loss: 0.7538%\n",
      "Epoch [24/300], Step [127/225], Training Accuracy: 65.8095%, Training Loss: 0.7543%\n",
      "Epoch [24/300], Step [128/225], Training Accuracy: 65.7715%, Training Loss: 0.7545%\n",
      "Epoch [24/300], Step [129/225], Training Accuracy: 65.8794%, Training Loss: 0.7539%\n",
      "Epoch [24/300], Step [130/225], Training Accuracy: 65.9014%, Training Loss: 0.7543%\n",
      "Epoch [24/300], Step [131/225], Training Accuracy: 65.8516%, Training Loss: 0.7546%\n",
      "Epoch [24/300], Step [132/225], Training Accuracy: 65.8026%, Training Loss: 0.7547%\n",
      "Epoch [24/300], Step [133/225], Training Accuracy: 65.7895%, Training Loss: 0.7548%\n",
      "Epoch [24/300], Step [134/225], Training Accuracy: 65.7066%, Training Loss: 0.7566%\n",
      "Epoch [24/300], Step [135/225], Training Accuracy: 65.7407%, Training Loss: 0.7557%\n",
      "Epoch [24/300], Step [136/225], Training Accuracy: 65.7744%, Training Loss: 0.7552%\n",
      "Epoch [24/300], Step [137/225], Training Accuracy: 65.7733%, Training Loss: 0.7548%\n",
      "Epoch [24/300], Step [138/225], Training Accuracy: 65.8288%, Training Loss: 0.7535%\n",
      "Epoch [24/300], Step [139/225], Training Accuracy: 65.8498%, Training Loss: 0.7534%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/300], Step [140/225], Training Accuracy: 65.8371%, Training Loss: 0.7529%\n",
      "Epoch [24/300], Step [141/225], Training Accuracy: 65.8134%, Training Loss: 0.7528%\n",
      "Epoch [24/300], Step [142/225], Training Accuracy: 65.7901%, Training Loss: 0.7527%\n",
      "Epoch [24/300], Step [143/225], Training Accuracy: 65.7780%, Training Loss: 0.7535%\n",
      "Epoch [24/300], Step [144/225], Training Accuracy: 65.7335%, Training Loss: 0.7540%\n",
      "Epoch [24/300], Step [145/225], Training Accuracy: 65.7112%, Training Loss: 0.7534%\n",
      "Epoch [24/300], Step [146/225], Training Accuracy: 65.6785%, Training Loss: 0.7542%\n",
      "Epoch [24/300], Step [147/225], Training Accuracy: 65.6888%, Training Loss: 0.7546%\n",
      "Epoch [24/300], Step [148/225], Training Accuracy: 65.7306%, Training Loss: 0.7537%\n",
      "Epoch [24/300], Step [149/225], Training Accuracy: 65.7613%, Training Loss: 0.7534%\n",
      "Epoch [24/300], Step [150/225], Training Accuracy: 65.7917%, Training Loss: 0.7526%\n",
      "Epoch [24/300], Step [151/225], Training Accuracy: 65.8009%, Training Loss: 0.7528%\n",
      "Epoch [24/300], Step [152/225], Training Accuracy: 65.7998%, Training Loss: 0.7529%\n",
      "Epoch [24/300], Step [153/225], Training Accuracy: 65.8088%, Training Loss: 0.7525%\n",
      "Epoch [24/300], Step [154/225], Training Accuracy: 65.8279%, Training Loss: 0.7524%\n",
      "Epoch [24/300], Step [155/225], Training Accuracy: 65.8165%, Training Loss: 0.7523%\n",
      "Epoch [24/300], Step [156/225], Training Accuracy: 65.8053%, Training Loss: 0.7526%\n",
      "Epoch [24/300], Step [157/225], Training Accuracy: 65.8041%, Training Loss: 0.7522%\n",
      "Epoch [24/300], Step [158/225], Training Accuracy: 65.7437%, Training Loss: 0.7537%\n",
      "Epoch [24/300], Step [159/225], Training Accuracy: 65.7528%, Training Loss: 0.7536%\n",
      "Epoch [24/300], Step [160/225], Training Accuracy: 65.7617%, Training Loss: 0.7526%\n",
      "Epoch [24/300], Step [161/225], Training Accuracy: 65.7706%, Training Loss: 0.7524%\n",
      "Epoch [24/300], Step [162/225], Training Accuracy: 65.8179%, Training Loss: 0.7520%\n",
      "Epoch [24/300], Step [163/225], Training Accuracy: 65.8838%, Training Loss: 0.7511%\n",
      "Epoch [24/300], Step [164/225], Training Accuracy: 65.8727%, Training Loss: 0.7506%\n",
      "Epoch [24/300], Step [165/225], Training Accuracy: 65.8712%, Training Loss: 0.7504%\n",
      "Epoch [24/300], Step [166/225], Training Accuracy: 65.8509%, Training Loss: 0.7503%\n",
      "Epoch [24/300], Step [167/225], Training Accuracy: 65.8589%, Training Loss: 0.7505%\n",
      "Epoch [24/300], Step [168/225], Training Accuracy: 65.8575%, Training Loss: 0.7502%\n",
      "Epoch [24/300], Step [169/225], Training Accuracy: 65.9209%, Training Loss: 0.7494%\n",
      "Epoch [24/300], Step [170/225], Training Accuracy: 65.9651%, Training Loss: 0.7494%\n",
      "Epoch [24/300], Step [171/225], Training Accuracy: 65.9905%, Training Loss: 0.7491%\n",
      "Epoch [24/300], Step [172/225], Training Accuracy: 65.9702%, Training Loss: 0.7491%\n",
      "Epoch [24/300], Step [173/225], Training Accuracy: 65.9682%, Training Loss: 0.7488%\n",
      "Epoch [24/300], Step [174/225], Training Accuracy: 65.9752%, Training Loss: 0.7485%\n",
      "Epoch [24/300], Step [175/225], Training Accuracy: 65.9554%, Training Loss: 0.7482%\n",
      "Epoch [24/300], Step [176/225], Training Accuracy: 65.9890%, Training Loss: 0.7477%\n",
      "Epoch [24/300], Step [177/225], Training Accuracy: 66.0046%, Training Loss: 0.7475%\n",
      "Epoch [24/300], Step [178/225], Training Accuracy: 66.0112%, Training Loss: 0.7473%\n",
      "Epoch [24/300], Step [179/225], Training Accuracy: 66.0876%, Training Loss: 0.7464%\n",
      "Epoch [24/300], Step [180/225], Training Accuracy: 66.1285%, Training Loss: 0.7454%\n",
      "Epoch [24/300], Step [181/225], Training Accuracy: 66.1602%, Training Loss: 0.7450%\n",
      "Epoch [24/300], Step [182/225], Training Accuracy: 66.2002%, Training Loss: 0.7446%\n",
      "Epoch [24/300], Step [183/225], Training Accuracy: 66.1885%, Training Loss: 0.7448%\n",
      "Epoch [24/300], Step [184/225], Training Accuracy: 66.2024%, Training Loss: 0.7450%\n",
      "Epoch [24/300], Step [185/225], Training Accuracy: 66.2331%, Training Loss: 0.7448%\n",
      "Epoch [24/300], Step [186/225], Training Accuracy: 66.2382%, Training Loss: 0.7443%\n",
      "Epoch [24/300], Step [187/225], Training Accuracy: 66.2350%, Training Loss: 0.7445%\n",
      "Epoch [24/300], Step [188/225], Training Accuracy: 66.2483%, Training Loss: 0.7440%\n",
      "Epoch [24/300], Step [189/225], Training Accuracy: 66.2946%, Training Loss: 0.7434%\n",
      "Epoch [24/300], Step [190/225], Training Accuracy: 66.2829%, Training Loss: 0.7432%\n",
      "Epoch [24/300], Step [191/225], Training Accuracy: 66.3285%, Training Loss: 0.7424%\n",
      "Epoch [24/300], Step [192/225], Training Accuracy: 66.3574%, Training Loss: 0.7417%\n",
      "Epoch [24/300], Step [193/225], Training Accuracy: 66.3374%, Training Loss: 0.7422%\n",
      "Epoch [24/300], Step [194/225], Training Accuracy: 66.3257%, Training Loss: 0.7433%\n",
      "Epoch [24/300], Step [195/225], Training Accuracy: 66.3862%, Training Loss: 0.7429%\n",
      "Epoch [24/300], Step [196/225], Training Accuracy: 66.3664%, Training Loss: 0.7429%\n",
      "Epoch [24/300], Step [197/225], Training Accuracy: 66.3230%, Training Loss: 0.7439%\n",
      "Epoch [24/300], Step [198/225], Training Accuracy: 66.2958%, Training Loss: 0.7437%\n",
      "Epoch [24/300], Step [199/225], Training Accuracy: 66.3081%, Training Loss: 0.7437%\n",
      "Epoch [24/300], Step [200/225], Training Accuracy: 66.2734%, Training Loss: 0.7446%\n",
      "Epoch [24/300], Step [201/225], Training Accuracy: 66.2547%, Training Loss: 0.7448%\n",
      "Epoch [24/300], Step [202/225], Training Accuracy: 66.2748%, Training Loss: 0.7443%\n",
      "Epoch [24/300], Step [203/225], Training Accuracy: 66.3100%, Training Loss: 0.7437%\n",
      "Epoch [24/300], Step [204/225], Training Accuracy: 66.3220%, Training Loss: 0.7438%\n",
      "Epoch [24/300], Step [205/225], Training Accuracy: 66.3415%, Training Loss: 0.7436%\n",
      "Epoch [24/300], Step [206/225], Training Accuracy: 66.3607%, Training Loss: 0.7436%\n",
      "Epoch [24/300], Step [207/225], Training Accuracy: 66.3647%, Training Loss: 0.7434%\n",
      "Epoch [24/300], Step [208/225], Training Accuracy: 66.3762%, Training Loss: 0.7430%\n",
      "Epoch [24/300], Step [209/225], Training Accuracy: 66.3651%, Training Loss: 0.7428%\n",
      "Epoch [24/300], Step [210/225], Training Accuracy: 66.3393%, Training Loss: 0.7430%\n",
      "Epoch [24/300], Step [211/225], Training Accuracy: 66.3803%, Training Loss: 0.7423%\n",
      "Epoch [24/300], Step [212/225], Training Accuracy: 66.3915%, Training Loss: 0.7421%\n",
      "Epoch [24/300], Step [213/225], Training Accuracy: 66.3732%, Training Loss: 0.7428%\n",
      "Epoch [24/300], Step [214/225], Training Accuracy: 66.4136%, Training Loss: 0.7420%\n",
      "Epoch [24/300], Step [215/225], Training Accuracy: 66.4317%, Training Loss: 0.7422%\n",
      "Epoch [24/300], Step [216/225], Training Accuracy: 66.4135%, Training Loss: 0.7426%\n",
      "Epoch [24/300], Step [217/225], Training Accuracy: 66.4026%, Training Loss: 0.7430%\n",
      "Epoch [24/300], Step [218/225], Training Accuracy: 66.3991%, Training Loss: 0.7431%\n",
      "Epoch [24/300], Step [219/225], Training Accuracy: 66.4170%, Training Loss: 0.7428%\n",
      "Epoch [24/300], Step [220/225], Training Accuracy: 66.4062%, Training Loss: 0.7426%\n",
      "Epoch [24/300], Step [221/225], Training Accuracy: 66.3886%, Training Loss: 0.7429%\n",
      "Epoch [24/300], Step [222/225], Training Accuracy: 66.3570%, Training Loss: 0.7432%\n",
      "Epoch [24/300], Step [223/225], Training Accuracy: 66.2906%, Training Loss: 0.7439%\n",
      "Epoch [24/300], Step [224/225], Training Accuracy: 66.3435%, Training Loss: 0.7434%\n",
      "Epoch [24/300], Step [225/225], Training Accuracy: 66.3563%, Training Loss: 0.7433%\n",
      "Epoch [25/300], Step [1/225], Training Accuracy: 65.6250%, Training Loss: 0.6285%\n",
      "Epoch [25/300], Step [2/225], Training Accuracy: 66.4062%, Training Loss: 0.6759%\n",
      "Epoch [25/300], Step [3/225], Training Accuracy: 62.5000%, Training Loss: 0.7833%\n",
      "Epoch [25/300], Step [4/225], Training Accuracy: 63.2812%, Training Loss: 0.7938%\n",
      "Epoch [25/300], Step [5/225], Training Accuracy: 64.3750%, Training Loss: 0.7678%\n",
      "Epoch [25/300], Step [6/225], Training Accuracy: 65.3646%, Training Loss: 0.7555%\n",
      "Epoch [25/300], Step [7/225], Training Accuracy: 64.9554%, Training Loss: 0.7687%\n",
      "Epoch [25/300], Step [8/225], Training Accuracy: 64.6484%, Training Loss: 0.7845%\n",
      "Epoch [25/300], Step [9/225], Training Accuracy: 65.2778%, Training Loss: 0.7818%\n",
      "Epoch [25/300], Step [10/225], Training Accuracy: 64.6875%, Training Loss: 0.7987%\n",
      "Epoch [25/300], Step [11/225], Training Accuracy: 64.6307%, Training Loss: 0.7905%\n",
      "Epoch [25/300], Step [12/225], Training Accuracy: 65.4948%, Training Loss: 0.7770%\n",
      "Epoch [25/300], Step [13/225], Training Accuracy: 65.9856%, Training Loss: 0.7657%\n",
      "Epoch [25/300], Step [14/225], Training Accuracy: 66.2946%, Training Loss: 0.7594%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/300], Step [15/225], Training Accuracy: 66.3542%, Training Loss: 0.7676%\n",
      "Epoch [25/300], Step [16/225], Training Accuracy: 65.9180%, Training Loss: 0.7705%\n",
      "Epoch [25/300], Step [17/225], Training Accuracy: 66.2684%, Training Loss: 0.7622%\n",
      "Epoch [25/300], Step [18/225], Training Accuracy: 66.4062%, Training Loss: 0.7598%\n",
      "Epoch [25/300], Step [19/225], Training Accuracy: 67.1875%, Training Loss: 0.7502%\n",
      "Epoch [25/300], Step [20/225], Training Accuracy: 67.5781%, Training Loss: 0.7441%\n",
      "Epoch [25/300], Step [21/225], Training Accuracy: 67.9315%, Training Loss: 0.7383%\n",
      "Epoch [25/300], Step [22/225], Training Accuracy: 67.6847%, Training Loss: 0.7437%\n",
      "Epoch [25/300], Step [23/225], Training Accuracy: 67.5951%, Training Loss: 0.7442%\n",
      "Epoch [25/300], Step [24/225], Training Accuracy: 67.4479%, Training Loss: 0.7485%\n",
      "Epoch [25/300], Step [25/225], Training Accuracy: 67.5625%, Training Loss: 0.7471%\n",
      "Epoch [25/300], Step [26/225], Training Accuracy: 67.9087%, Training Loss: 0.7450%\n",
      "Epoch [25/300], Step [27/225], Training Accuracy: 67.7083%, Training Loss: 0.7493%\n",
      "Epoch [25/300], Step [28/225], Training Accuracy: 67.8013%, Training Loss: 0.7440%\n",
      "Epoch [25/300], Step [29/225], Training Accuracy: 67.7263%, Training Loss: 0.7392%\n",
      "Epoch [25/300], Step [30/225], Training Accuracy: 67.7604%, Training Loss: 0.7405%\n",
      "Epoch [25/300], Step [31/225], Training Accuracy: 67.8427%, Training Loss: 0.7415%\n",
      "Epoch [25/300], Step [32/225], Training Accuracy: 68.0664%, Training Loss: 0.7386%\n",
      "Epoch [25/300], Step [33/225], Training Accuracy: 68.0871%, Training Loss: 0.7355%\n",
      "Epoch [25/300], Step [34/225], Training Accuracy: 67.8768%, Training Loss: 0.7426%\n",
      "Epoch [25/300], Step [35/225], Training Accuracy: 67.8571%, Training Loss: 0.7504%\n",
      "Epoch [25/300], Step [36/225], Training Accuracy: 67.6649%, Training Loss: 0.7518%\n",
      "Epoch [25/300], Step [37/225], Training Accuracy: 67.9054%, Training Loss: 0.7459%\n",
      "Epoch [25/300], Step [38/225], Training Accuracy: 68.0510%, Training Loss: 0.7436%\n",
      "Epoch [25/300], Step [39/225], Training Accuracy: 67.5881%, Training Loss: 0.7496%\n",
      "Epoch [25/300], Step [40/225], Training Accuracy: 67.6562%, Training Loss: 0.7482%\n",
      "Epoch [25/300], Step [41/225], Training Accuracy: 67.5686%, Training Loss: 0.7498%\n",
      "Epoch [25/300], Step [42/225], Training Accuracy: 67.3363%, Training Loss: 0.7528%\n",
      "Epoch [25/300], Step [43/225], Training Accuracy: 67.2965%, Training Loss: 0.7531%\n",
      "Epoch [25/300], Step [44/225], Training Accuracy: 67.3295%, Training Loss: 0.7519%\n",
      "Epoch [25/300], Step [45/225], Training Accuracy: 67.3264%, Training Loss: 0.7526%\n",
      "Epoch [25/300], Step [46/225], Training Accuracy: 67.3573%, Training Loss: 0.7513%\n",
      "Epoch [25/300], Step [47/225], Training Accuracy: 67.2207%, Training Loss: 0.7514%\n",
      "Epoch [25/300], Step [48/225], Training Accuracy: 67.0573%, Training Loss: 0.7533%\n",
      "Epoch [25/300], Step [49/225], Training Accuracy: 67.1237%, Training Loss: 0.7509%\n",
      "Epoch [25/300], Step [50/225], Training Accuracy: 66.9688%, Training Loss: 0.7546%\n",
      "Epoch [25/300], Step [51/225], Training Accuracy: 67.1875%, Training Loss: 0.7494%\n",
      "Epoch [25/300], Step [52/225], Training Accuracy: 67.3077%, Training Loss: 0.7458%\n",
      "Epoch [25/300], Step [53/225], Training Accuracy: 67.3054%, Training Loss: 0.7463%\n",
      "Epoch [25/300], Step [54/225], Training Accuracy: 67.1586%, Training Loss: 0.7471%\n",
      "Epoch [25/300], Step [55/225], Training Accuracy: 67.0739%, Training Loss: 0.7492%\n",
      "Epoch [25/300], Step [56/225], Training Accuracy: 67.1038%, Training Loss: 0.7470%\n",
      "Epoch [25/300], Step [57/225], Training Accuracy: 67.2149%, Training Loss: 0.7443%\n",
      "Epoch [25/300], Step [58/225], Training Accuracy: 67.2953%, Training Loss: 0.7434%\n",
      "Epoch [25/300], Step [59/225], Training Accuracy: 66.9756%, Training Loss: 0.7465%\n",
      "Epoch [25/300], Step [60/225], Training Accuracy: 67.0573%, Training Loss: 0.7448%\n",
      "Epoch [25/300], Step [61/225], Training Accuracy: 67.1875%, Training Loss: 0.7433%\n",
      "Epoch [25/300], Step [62/225], Training Accuracy: 67.1623%, Training Loss: 0.7437%\n",
      "Epoch [25/300], Step [63/225], Training Accuracy: 67.2619%, Training Loss: 0.7439%\n",
      "Epoch [25/300], Step [64/225], Training Accuracy: 67.1387%, Training Loss: 0.7435%\n",
      "Epoch [25/300], Step [65/225], Training Accuracy: 67.1154%, Training Loss: 0.7428%\n",
      "Epoch [25/300], Step [66/225], Training Accuracy: 67.2585%, Training Loss: 0.7402%\n",
      "Epoch [25/300], Step [67/225], Training Accuracy: 67.2341%, Training Loss: 0.7410%\n",
      "Epoch [25/300], Step [68/225], Training Accuracy: 67.1186%, Training Loss: 0.7416%\n",
      "Epoch [25/300], Step [69/225], Training Accuracy: 67.0063%, Training Loss: 0.7420%\n",
      "Epoch [25/300], Step [70/225], Training Accuracy: 66.9866%, Training Loss: 0.7416%\n",
      "Epoch [25/300], Step [71/225], Training Accuracy: 67.0114%, Training Loss: 0.7410%\n",
      "Epoch [25/300], Step [72/225], Training Accuracy: 66.9705%, Training Loss: 0.7431%\n",
      "Epoch [25/300], Step [73/225], Training Accuracy: 66.9092%, Training Loss: 0.7432%\n",
      "Epoch [25/300], Step [74/225], Training Accuracy: 66.9975%, Training Loss: 0.7406%\n",
      "Epoch [25/300], Step [75/225], Training Accuracy: 66.8750%, Training Loss: 0.7415%\n",
      "Epoch [25/300], Step [76/225], Training Accuracy: 66.7558%, Training Loss: 0.7435%\n",
      "Epoch [25/300], Step [77/225], Training Accuracy: 66.6599%, Training Loss: 0.7446%\n",
      "Epoch [25/300], Step [78/225], Training Accuracy: 66.7468%, Training Loss: 0.7429%\n",
      "Epoch [25/300], Step [79/225], Training Accuracy: 66.8513%, Training Loss: 0.7422%\n",
      "Epoch [25/300], Step [80/225], Training Accuracy: 66.8555%, Training Loss: 0.7418%\n",
      "Epoch [25/300], Step [81/225], Training Accuracy: 66.7438%, Training Loss: 0.7421%\n",
      "Epoch [25/300], Step [82/225], Training Accuracy: 66.8064%, Training Loss: 0.7412%\n",
      "Epoch [25/300], Step [83/225], Training Accuracy: 66.7922%, Training Loss: 0.7412%\n",
      "Epoch [25/300], Step [84/225], Training Accuracy: 66.8341%, Training Loss: 0.7401%\n",
      "Epoch [25/300], Step [85/225], Training Accuracy: 66.8934%, Training Loss: 0.7387%\n",
      "Epoch [25/300], Step [86/225], Training Accuracy: 66.9150%, Training Loss: 0.7388%\n",
      "Epoch [25/300], Step [87/225], Training Accuracy: 66.8642%, Training Loss: 0.7399%\n",
      "Epoch [25/300], Step [88/225], Training Accuracy: 66.7791%, Training Loss: 0.7412%\n",
      "Epoch [25/300], Step [89/225], Training Accuracy: 66.7486%, Training Loss: 0.7430%\n",
      "Epoch [25/300], Step [90/225], Training Accuracy: 66.7188%, Training Loss: 0.7433%\n",
      "Epoch [25/300], Step [91/225], Training Accuracy: 66.7926%, Training Loss: 0.7420%\n",
      "Epoch [25/300], Step [92/225], Training Accuracy: 66.7799%, Training Loss: 0.7419%\n",
      "Epoch [25/300], Step [93/225], Training Accuracy: 66.7843%, Training Loss: 0.7411%\n",
      "Epoch [25/300], Step [94/225], Training Accuracy: 66.8384%, Training Loss: 0.7403%\n",
      "Epoch [25/300], Step [95/225], Training Accuracy: 66.7928%, Training Loss: 0.7402%\n",
      "Epoch [25/300], Step [96/225], Training Accuracy: 66.8783%, Training Loss: 0.7383%\n",
      "Epoch [25/300], Step [97/225], Training Accuracy: 66.8814%, Training Loss: 0.7378%\n",
      "Epoch [25/300], Step [98/225], Training Accuracy: 66.8367%, Training Loss: 0.7379%\n",
      "Epoch [25/300], Step [99/225], Training Accuracy: 66.9034%, Training Loss: 0.7388%\n",
      "Epoch [25/300], Step [100/225], Training Accuracy: 66.7969%, Training Loss: 0.7404%\n",
      "Epoch [25/300], Step [101/225], Training Accuracy: 66.8936%, Training Loss: 0.7393%\n",
      "Epoch [25/300], Step [102/225], Training Accuracy: 66.8505%, Training Loss: 0.7390%\n",
      "Epoch [25/300], Step [103/225], Training Accuracy: 66.8841%, Training Loss: 0.7387%\n",
      "Epoch [25/300], Step [104/225], Training Accuracy: 66.9020%, Training Loss: 0.7383%\n",
      "Epoch [25/300], Step [105/225], Training Accuracy: 66.9048%, Training Loss: 0.7377%\n",
      "Epoch [25/300], Step [106/225], Training Accuracy: 66.9517%, Training Loss: 0.7374%\n",
      "Epoch [25/300], Step [107/225], Training Accuracy: 66.9539%, Training Loss: 0.7377%\n",
      "Epoch [25/300], Step [108/225], Training Accuracy: 66.8837%, Training Loss: 0.7386%\n",
      "Epoch [25/300], Step [109/225], Training Accuracy: 66.9008%, Training Loss: 0.7376%\n",
      "Epoch [25/300], Step [110/225], Training Accuracy: 66.8608%, Training Loss: 0.7373%\n",
      "Epoch [25/300], Step [111/225], Training Accuracy: 66.8356%, Training Loss: 0.7374%\n",
      "Epoch [25/300], Step [112/225], Training Accuracy: 66.8387%, Training Loss: 0.7373%\n",
      "Epoch [25/300], Step [113/225], Training Accuracy: 66.7727%, Training Loss: 0.7380%\n",
      "Epoch [25/300], Step [114/225], Training Accuracy: 66.7489%, Training Loss: 0.7371%\n",
      "Epoch [25/300], Step [115/225], Training Accuracy: 66.8071%, Training Loss: 0.7357%\n",
      "Epoch [25/300], Step [116/225], Training Accuracy: 66.8238%, Training Loss: 0.7352%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/300], Step [117/225], Training Accuracy: 66.6800%, Training Loss: 0.7367%\n",
      "Epoch [25/300], Step [118/225], Training Accuracy: 66.6711%, Training Loss: 0.7364%\n",
      "Epoch [25/300], Step [119/225], Training Accuracy: 66.6360%, Training Loss: 0.7364%\n",
      "Epoch [25/300], Step [120/225], Training Accuracy: 66.5885%, Training Loss: 0.7369%\n",
      "Epoch [25/300], Step [121/225], Training Accuracy: 66.5160%, Training Loss: 0.7374%\n",
      "Epoch [25/300], Step [122/225], Training Accuracy: 66.5087%, Training Loss: 0.7373%\n",
      "Epoch [25/300], Step [123/225], Training Accuracy: 66.5396%, Training Loss: 0.7363%\n",
      "Epoch [25/300], Step [124/225], Training Accuracy: 66.5575%, Training Loss: 0.7356%\n",
      "Epoch [25/300], Step [125/225], Training Accuracy: 66.5625%, Training Loss: 0.7363%\n",
      "Epoch [25/300], Step [126/225], Training Accuracy: 66.5799%, Training Loss: 0.7364%\n",
      "Epoch [25/300], Step [127/225], Training Accuracy: 66.6093%, Training Loss: 0.7368%\n",
      "Epoch [25/300], Step [128/225], Training Accuracy: 66.6138%, Training Loss: 0.7368%\n",
      "Epoch [25/300], Step [129/225], Training Accuracy: 66.6546%, Training Loss: 0.7370%\n",
      "Epoch [25/300], Step [130/225], Training Accuracy: 66.7067%, Training Loss: 0.7369%\n",
      "Epoch [25/300], Step [131/225], Training Accuracy: 66.7462%, Training Loss: 0.7369%\n",
      "Epoch [25/300], Step [132/225], Training Accuracy: 66.6548%, Training Loss: 0.7385%\n",
      "Epoch [25/300], Step [133/225], Training Accuracy: 66.6706%, Training Loss: 0.7385%\n",
      "Epoch [25/300], Step [134/225], Training Accuracy: 66.6161%, Training Loss: 0.7397%\n",
      "Epoch [25/300], Step [135/225], Training Accuracy: 66.6782%, Training Loss: 0.7386%\n",
      "Epoch [25/300], Step [136/225], Training Accuracy: 66.6705%, Training Loss: 0.7381%\n",
      "Epoch [25/300], Step [137/225], Training Accuracy: 66.6515%, Training Loss: 0.7377%\n",
      "Epoch [25/300], Step [138/225], Training Accuracy: 66.6893%, Training Loss: 0.7359%\n",
      "Epoch [25/300], Step [139/225], Training Accuracy: 66.7154%, Training Loss: 0.7359%\n",
      "Epoch [25/300], Step [140/225], Training Accuracy: 66.6741%, Training Loss: 0.7356%\n",
      "Epoch [25/300], Step [141/225], Training Accuracy: 66.6777%, Training Loss: 0.7360%\n",
      "Epoch [25/300], Step [142/225], Training Accuracy: 66.6373%, Training Loss: 0.7355%\n",
      "Epoch [25/300], Step [143/225], Training Accuracy: 66.5975%, Training Loss: 0.7361%\n",
      "Epoch [25/300], Step [144/225], Training Accuracy: 66.5582%, Training Loss: 0.7367%\n",
      "Epoch [25/300], Step [145/225], Training Accuracy: 66.5625%, Training Loss: 0.7362%\n",
      "Epoch [25/300], Step [146/225], Training Accuracy: 66.5775%, Training Loss: 0.7366%\n",
      "Epoch [25/300], Step [147/225], Training Accuracy: 66.5497%, Training Loss: 0.7369%\n",
      "Epoch [25/300], Step [148/225], Training Accuracy: 66.5435%, Training Loss: 0.7363%\n",
      "Epoch [25/300], Step [149/225], Training Accuracy: 66.5373%, Training Loss: 0.7363%\n",
      "Epoch [25/300], Step [150/225], Training Accuracy: 66.5417%, Training Loss: 0.7357%\n",
      "Epoch [25/300], Step [151/225], Training Accuracy: 66.5666%, Training Loss: 0.7353%\n",
      "Epoch [25/300], Step [152/225], Training Accuracy: 66.5604%, Training Loss: 0.7353%\n",
      "Epoch [25/300], Step [153/225], Training Accuracy: 66.5645%, Training Loss: 0.7353%\n",
      "Epoch [25/300], Step [154/225], Training Accuracy: 66.5483%, Training Loss: 0.7350%\n",
      "Epoch [25/300], Step [155/225], Training Accuracy: 66.5625%, Training Loss: 0.7346%\n",
      "Epoch [25/300], Step [156/225], Training Accuracy: 66.5365%, Training Loss: 0.7351%\n",
      "Epoch [25/300], Step [157/225], Training Accuracy: 66.6401%, Training Loss: 0.7338%\n",
      "Epoch [25/300], Step [158/225], Training Accuracy: 66.6139%, Training Loss: 0.7346%\n",
      "Epoch [25/300], Step [159/225], Training Accuracy: 66.6175%, Training Loss: 0.7346%\n",
      "Epoch [25/300], Step [160/225], Training Accuracy: 66.6602%, Training Loss: 0.7339%\n",
      "Epoch [25/300], Step [161/225], Training Accuracy: 66.7023%, Training Loss: 0.7337%\n",
      "Epoch [25/300], Step [162/225], Training Accuracy: 66.7342%, Training Loss: 0.7334%\n",
      "Epoch [25/300], Step [163/225], Training Accuracy: 66.7561%, Training Loss: 0.7326%\n",
      "Epoch [25/300], Step [164/225], Training Accuracy: 66.8255%, Training Loss: 0.7318%\n",
      "Epoch [25/300], Step [165/225], Training Accuracy: 66.8277%, Training Loss: 0.7316%\n",
      "Epoch [25/300], Step [166/225], Training Accuracy: 66.8298%, Training Loss: 0.7315%\n",
      "Epoch [25/300], Step [167/225], Training Accuracy: 66.8320%, Training Loss: 0.7312%\n",
      "Epoch [25/300], Step [168/225], Training Accuracy: 66.8062%, Training Loss: 0.7319%\n",
      "Epoch [25/300], Step [169/225], Training Accuracy: 66.8547%, Training Loss: 0.7310%\n",
      "Epoch [25/300], Step [170/225], Training Accuracy: 66.8474%, Training Loss: 0.7312%\n",
      "Epoch [25/300], Step [171/225], Training Accuracy: 66.9042%, Training Loss: 0.7306%\n",
      "Epoch [25/300], Step [172/225], Training Accuracy: 66.9059%, Training Loss: 0.7303%\n",
      "Epoch [25/300], Step [173/225], Training Accuracy: 66.8624%, Training Loss: 0.7306%\n",
      "Epoch [25/300], Step [174/225], Training Accuracy: 66.9091%, Training Loss: 0.7302%\n",
      "Epoch [25/300], Step [175/225], Training Accuracy: 66.9286%, Training Loss: 0.7301%\n",
      "Epoch [25/300], Step [176/225], Training Accuracy: 66.9478%, Training Loss: 0.7300%\n",
      "Epoch [25/300], Step [177/225], Training Accuracy: 66.9492%, Training Loss: 0.7296%\n",
      "Epoch [25/300], Step [178/225], Training Accuracy: 66.9768%, Training Loss: 0.7292%\n",
      "Epoch [25/300], Step [179/225], Training Accuracy: 67.0304%, Training Loss: 0.7286%\n",
      "Epoch [25/300], Step [180/225], Training Accuracy: 67.0833%, Training Loss: 0.7283%\n",
      "Epoch [25/300], Step [181/225], Training Accuracy: 67.0839%, Training Loss: 0.7284%\n",
      "Epoch [25/300], Step [182/225], Training Accuracy: 67.0931%, Training Loss: 0.7283%\n",
      "Epoch [25/300], Step [183/225], Training Accuracy: 67.1021%, Training Loss: 0.7285%\n",
      "Epoch [25/300], Step [184/225], Training Accuracy: 67.1450%, Training Loss: 0.7282%\n",
      "Epoch [25/300], Step [185/225], Training Accuracy: 67.1622%, Training Loss: 0.7280%\n",
      "Epoch [25/300], Step [186/225], Training Accuracy: 67.2295%, Training Loss: 0.7270%\n",
      "Epoch [25/300], Step [187/225], Training Accuracy: 67.1959%, Training Loss: 0.7274%\n",
      "Epoch [25/300], Step [188/225], Training Accuracy: 67.2291%, Training Loss: 0.7268%\n",
      "Epoch [25/300], Step [189/225], Training Accuracy: 67.2536%, Training Loss: 0.7261%\n",
      "Epoch [25/300], Step [190/225], Training Accuracy: 67.2944%, Training Loss: 0.7261%\n",
      "Epoch [25/300], Step [191/225], Training Accuracy: 67.2938%, Training Loss: 0.7257%\n",
      "Epoch [25/300], Step [192/225], Training Accuracy: 67.3096%, Training Loss: 0.7255%\n",
      "Epoch [25/300], Step [193/225], Training Accuracy: 67.2927%, Training Loss: 0.7257%\n",
      "Epoch [25/300], Step [194/225], Training Accuracy: 67.3003%, Training Loss: 0.7255%\n",
      "Epoch [25/300], Step [195/225], Training Accuracy: 67.3397%, Training Loss: 0.7244%\n",
      "Epoch [25/300], Step [196/225], Training Accuracy: 67.3310%, Training Loss: 0.7243%\n",
      "Epoch [25/300], Step [197/225], Training Accuracy: 67.3144%, Training Loss: 0.7245%\n",
      "Epoch [25/300], Step [198/225], Training Accuracy: 67.3453%, Training Loss: 0.7238%\n",
      "Epoch [25/300], Step [199/225], Training Accuracy: 67.3602%, Training Loss: 0.7231%\n",
      "Epoch [25/300], Step [200/225], Training Accuracy: 67.3672%, Training Loss: 0.7230%\n",
      "Epoch [25/300], Step [201/225], Training Accuracy: 67.3663%, Training Loss: 0.7227%\n",
      "Epoch [25/300], Step [202/225], Training Accuracy: 67.4196%, Training Loss: 0.7220%\n",
      "Epoch [25/300], Step [203/225], Training Accuracy: 67.4492%, Training Loss: 0.7213%\n",
      "Epoch [25/300], Step [204/225], Training Accuracy: 67.4632%, Training Loss: 0.7210%\n",
      "Epoch [25/300], Step [205/225], Training Accuracy: 67.4924%, Training Loss: 0.7206%\n",
      "Epoch [25/300], Step [206/225], Training Accuracy: 67.4909%, Training Loss: 0.7202%\n",
      "Epoch [25/300], Step [207/225], Training Accuracy: 67.5045%, Training Loss: 0.7204%\n",
      "Epoch [25/300], Step [208/225], Training Accuracy: 67.5481%, Training Loss: 0.7196%\n",
      "Epoch [25/300], Step [209/225], Training Accuracy: 67.5688%, Training Loss: 0.7197%\n",
      "Epoch [25/300], Step [210/225], Training Accuracy: 67.5744%, Training Loss: 0.7197%\n",
      "Epoch [25/300], Step [211/225], Training Accuracy: 67.6170%, Training Loss: 0.7189%\n",
      "Epoch [25/300], Step [212/225], Training Accuracy: 67.5781%, Training Loss: 0.7193%\n",
      "Epoch [25/300], Step [213/225], Training Accuracy: 67.5396%, Training Loss: 0.7196%\n",
      "Epoch [25/300], Step [214/225], Training Accuracy: 67.5453%, Training Loss: 0.7194%\n",
      "Epoch [25/300], Step [215/225], Training Accuracy: 67.5581%, Training Loss: 0.7188%\n",
      "Epoch [25/300], Step [216/225], Training Accuracy: 67.5564%, Training Loss: 0.7189%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/300], Step [217/225], Training Accuracy: 67.5187%, Training Loss: 0.7188%\n",
      "Epoch [25/300], Step [218/225], Training Accuracy: 67.5172%, Training Loss: 0.7190%\n",
      "Epoch [25/300], Step [219/225], Training Accuracy: 67.5371%, Training Loss: 0.7190%\n",
      "Epoch [25/300], Step [220/225], Training Accuracy: 67.5639%, Training Loss: 0.7184%\n",
      "Epoch [25/300], Step [221/225], Training Accuracy: 67.5551%, Training Loss: 0.7183%\n",
      "Epoch [25/300], Step [222/225], Training Accuracy: 67.5676%, Training Loss: 0.7180%\n",
      "Epoch [25/300], Step [223/225], Training Accuracy: 67.5238%, Training Loss: 0.7185%\n",
      "Epoch [25/300], Step [224/225], Training Accuracy: 67.5363%, Training Loss: 0.7178%\n",
      "Epoch [25/300], Step [225/225], Training Accuracy: 67.5167%, Training Loss: 0.7181%\n",
      "Epoch [26/300], Step [1/225], Training Accuracy: 71.8750%, Training Loss: 0.5612%\n",
      "Epoch [26/300], Step [2/225], Training Accuracy: 69.5312%, Training Loss: 0.6333%\n",
      "Epoch [26/300], Step [3/225], Training Accuracy: 66.6667%, Training Loss: 0.6933%\n",
      "Epoch [26/300], Step [4/225], Training Accuracy: 66.7969%, Training Loss: 0.6842%\n",
      "Epoch [26/300], Step [5/225], Training Accuracy: 68.7500%, Training Loss: 0.6710%\n",
      "Epoch [26/300], Step [6/225], Training Accuracy: 69.0104%, Training Loss: 0.6548%\n",
      "Epoch [26/300], Step [7/225], Training Accuracy: 67.4107%, Training Loss: 0.6702%\n",
      "Epoch [26/300], Step [8/225], Training Accuracy: 66.9922%, Training Loss: 0.7040%\n",
      "Epoch [26/300], Step [9/225], Training Accuracy: 67.1875%, Training Loss: 0.7139%\n",
      "Epoch [26/300], Step [10/225], Training Accuracy: 66.5625%, Training Loss: 0.7328%\n",
      "Epoch [26/300], Step [11/225], Training Accuracy: 66.7614%, Training Loss: 0.7337%\n",
      "Epoch [26/300], Step [12/225], Training Accuracy: 66.9271%, Training Loss: 0.7338%\n",
      "Epoch [26/300], Step [13/225], Training Accuracy: 67.9087%, Training Loss: 0.7155%\n",
      "Epoch [26/300], Step [14/225], Training Accuracy: 68.1920%, Training Loss: 0.7125%\n",
      "Epoch [26/300], Step [15/225], Training Accuracy: 68.2292%, Training Loss: 0.7148%\n",
      "Epoch [26/300], Step [16/225], Training Accuracy: 67.9688%, Training Loss: 0.7174%\n",
      "Epoch [26/300], Step [17/225], Training Accuracy: 68.1066%, Training Loss: 0.7122%\n",
      "Epoch [26/300], Step [18/225], Training Accuracy: 68.4028%, Training Loss: 0.7106%\n",
      "Epoch [26/300], Step [19/225], Training Accuracy: 68.6678%, Training Loss: 0.7049%\n",
      "Epoch [26/300], Step [20/225], Training Accuracy: 68.9062%, Training Loss: 0.6990%\n",
      "Epoch [26/300], Step [21/225], Training Accuracy: 68.8988%, Training Loss: 0.7004%\n",
      "Epoch [26/300], Step [22/225], Training Accuracy: 68.4659%, Training Loss: 0.7095%\n",
      "Epoch [26/300], Step [23/225], Training Accuracy: 68.4783%, Training Loss: 0.7080%\n",
      "Epoch [26/300], Step [24/225], Training Accuracy: 68.2943%, Training Loss: 0.7103%\n",
      "Epoch [26/300], Step [25/225], Training Accuracy: 68.5625%, Training Loss: 0.7064%\n",
      "Epoch [26/300], Step [26/225], Training Accuracy: 68.3894%, Training Loss: 0.7082%\n",
      "Epoch [26/300], Step [27/225], Training Accuracy: 68.4606%, Training Loss: 0.7121%\n",
      "Epoch [26/300], Step [28/225], Training Accuracy: 68.4710%, Training Loss: 0.7098%\n",
      "Epoch [26/300], Step [29/225], Training Accuracy: 68.6422%, Training Loss: 0.7078%\n",
      "Epoch [26/300], Step [30/225], Training Accuracy: 68.9583%, Training Loss: 0.7038%\n",
      "Epoch [26/300], Step [31/225], Training Accuracy: 68.5988%, Training Loss: 0.7070%\n",
      "Epoch [26/300], Step [32/225], Training Accuracy: 68.6035%, Training Loss: 0.7058%\n",
      "Epoch [26/300], Step [33/225], Training Accuracy: 68.7973%, Training Loss: 0.7055%\n",
      "Epoch [26/300], Step [34/225], Training Accuracy: 68.5662%, Training Loss: 0.7081%\n",
      "Epoch [26/300], Step [35/225], Training Accuracy: 68.3036%, Training Loss: 0.7096%\n",
      "Epoch [26/300], Step [36/225], Training Accuracy: 68.0556%, Training Loss: 0.7143%\n",
      "Epoch [26/300], Step [37/225], Training Accuracy: 67.9476%, Training Loss: 0.7146%\n",
      "Epoch [26/300], Step [38/225], Training Accuracy: 68.0921%, Training Loss: 0.7121%\n",
      "Epoch [26/300], Step [39/225], Training Accuracy: 67.8686%, Training Loss: 0.7145%\n",
      "Epoch [26/300], Step [40/225], Training Accuracy: 67.7734%, Training Loss: 0.7154%\n",
      "Epoch [26/300], Step [41/225], Training Accuracy: 67.4543%, Training Loss: 0.7185%\n",
      "Epoch [26/300], Step [42/225], Training Accuracy: 67.2619%, Training Loss: 0.7210%\n",
      "Epoch [26/300], Step [43/225], Training Accuracy: 67.2965%, Training Loss: 0.7209%\n",
      "Epoch [26/300], Step [44/225], Training Accuracy: 67.3651%, Training Loss: 0.7208%\n",
      "Epoch [26/300], Step [45/225], Training Accuracy: 67.1875%, Training Loss: 0.7240%\n",
      "Epoch [26/300], Step [46/225], Training Accuracy: 67.2894%, Training Loss: 0.7224%\n",
      "Epoch [26/300], Step [47/225], Training Accuracy: 67.2540%, Training Loss: 0.7239%\n",
      "Epoch [26/300], Step [48/225], Training Accuracy: 67.2526%, Training Loss: 0.7248%\n",
      "Epoch [26/300], Step [49/225], Training Accuracy: 67.2513%, Training Loss: 0.7216%\n",
      "Epoch [26/300], Step [50/225], Training Accuracy: 67.1875%, Training Loss: 0.7233%\n",
      "Epoch [26/300], Step [51/225], Training Accuracy: 67.3407%, Training Loss: 0.7193%\n",
      "Epoch [26/300], Step [52/225], Training Accuracy: 67.4880%, Training Loss: 0.7157%\n",
      "Epoch [26/300], Step [53/225], Training Accuracy: 67.4528%, Training Loss: 0.7168%\n",
      "Epoch [26/300], Step [54/225], Training Accuracy: 67.3611%, Training Loss: 0.7187%\n",
      "Epoch [26/300], Step [55/225], Training Accuracy: 67.4148%, Training Loss: 0.7182%\n",
      "Epoch [26/300], Step [56/225], Training Accuracy: 67.3549%, Training Loss: 0.7185%\n",
      "Epoch [26/300], Step [57/225], Training Accuracy: 67.3794%, Training Loss: 0.7187%\n",
      "Epoch [26/300], Step [58/225], Training Accuracy: 67.4569%, Training Loss: 0.7170%\n",
      "Epoch [26/300], Step [59/225], Training Accuracy: 67.4788%, Training Loss: 0.7165%\n",
      "Epoch [26/300], Step [60/225], Training Accuracy: 67.6042%, Training Loss: 0.7162%\n",
      "Epoch [26/300], Step [61/225], Training Accuracy: 67.7766%, Training Loss: 0.7163%\n",
      "Epoch [26/300], Step [62/225], Training Accuracy: 67.8931%, Training Loss: 0.7153%\n",
      "Epoch [26/300], Step [63/225], Training Accuracy: 67.8571%, Training Loss: 0.7158%\n",
      "Epoch [26/300], Step [64/225], Training Accuracy: 67.7979%, Training Loss: 0.7158%\n",
      "Epoch [26/300], Step [65/225], Training Accuracy: 67.9087%, Training Loss: 0.7151%\n",
      "Epoch [26/300], Step [66/225], Training Accuracy: 67.9924%, Training Loss: 0.7124%\n",
      "Epoch [26/300], Step [67/225], Training Accuracy: 67.9804%, Training Loss: 0.7124%\n",
      "Epoch [26/300], Step [68/225], Training Accuracy: 68.0377%, Training Loss: 0.7124%\n",
      "Epoch [26/300], Step [69/225], Training Accuracy: 68.0480%, Training Loss: 0.7123%\n",
      "Epoch [26/300], Step [70/225], Training Accuracy: 68.0580%, Training Loss: 0.7125%\n",
      "Epoch [26/300], Step [71/225], Training Accuracy: 68.1118%, Training Loss: 0.7112%\n",
      "Epoch [26/300], Step [72/225], Training Accuracy: 68.0990%, Training Loss: 0.7108%\n",
      "Epoch [26/300], Step [73/225], Training Accuracy: 68.1507%, Training Loss: 0.7112%\n",
      "Epoch [26/300], Step [74/225], Training Accuracy: 68.3488%, Training Loss: 0.7074%\n",
      "Epoch [26/300], Step [75/225], Training Accuracy: 68.3125%, Training Loss: 0.7077%\n",
      "Epoch [26/300], Step [76/225], Training Accuracy: 68.2977%, Training Loss: 0.7093%\n",
      "Epoch [26/300], Step [77/225], Training Accuracy: 68.3442%, Training Loss: 0.7095%\n",
      "Epoch [26/300], Step [78/225], Training Accuracy: 68.4295%, Training Loss: 0.7076%\n",
      "Epoch [26/300], Step [79/225], Training Accuracy: 68.3940%, Training Loss: 0.7071%\n",
      "Epoch [26/300], Step [80/225], Training Accuracy: 68.3594%, Training Loss: 0.7076%\n",
      "Epoch [26/300], Step [81/225], Training Accuracy: 68.3835%, Training Loss: 0.7078%\n",
      "Epoch [26/300], Step [82/225], Training Accuracy: 68.3689%, Training Loss: 0.7085%\n",
      "Epoch [26/300], Step [83/225], Training Accuracy: 68.3170%, Training Loss: 0.7087%\n",
      "Epoch [26/300], Step [84/225], Training Accuracy: 68.3222%, Training Loss: 0.7076%\n",
      "Epoch [26/300], Step [85/225], Training Accuracy: 68.3272%, Training Loss: 0.7072%\n",
      "Epoch [26/300], Step [86/225], Training Accuracy: 68.3321%, Training Loss: 0.7067%\n",
      "Epoch [26/300], Step [87/225], Training Accuracy: 68.2830%, Training Loss: 0.7075%\n",
      "Epoch [26/300], Step [88/225], Training Accuracy: 68.2173%, Training Loss: 0.7090%\n",
      "Epoch [26/300], Step [89/225], Training Accuracy: 68.1180%, Training Loss: 0.7111%\n",
      "Epoch [26/300], Step [90/225], Training Accuracy: 68.0382%, Training Loss: 0.7123%\n",
      "Epoch [26/300], Step [91/225], Training Accuracy: 68.0460%, Training Loss: 0.7122%\n",
      "Epoch [26/300], Step [92/225], Training Accuracy: 68.0707%, Training Loss: 0.7131%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/300], Step [93/225], Training Accuracy: 68.0444%, Training Loss: 0.7125%\n",
      "Epoch [26/300], Step [94/225], Training Accuracy: 68.0519%, Training Loss: 0.7136%\n",
      "Epoch [26/300], Step [95/225], Training Accuracy: 68.0428%, Training Loss: 0.7141%\n",
      "Epoch [26/300], Step [96/225], Training Accuracy: 68.1478%, Training Loss: 0.7120%\n",
      "Epoch [26/300], Step [97/225], Training Accuracy: 68.2184%, Training Loss: 0.7112%\n",
      "Epoch [26/300], Step [98/225], Training Accuracy: 68.2239%, Training Loss: 0.7111%\n",
      "Epoch [26/300], Step [99/225], Training Accuracy: 68.3239%, Training Loss: 0.7103%\n",
      "Epoch [26/300], Step [100/225], Training Accuracy: 68.3125%, Training Loss: 0.7108%\n",
      "Epoch [26/300], Step [101/225], Training Accuracy: 68.3323%, Training Loss: 0.7102%\n",
      "Epoch [26/300], Step [102/225], Training Accuracy: 68.2292%, Training Loss: 0.7115%\n",
      "Epoch [26/300], Step [103/225], Training Accuracy: 68.2342%, Training Loss: 0.7114%\n",
      "Epoch [26/300], Step [104/225], Training Accuracy: 68.2091%, Training Loss: 0.7113%\n",
      "Epoch [26/300], Step [105/225], Training Accuracy: 68.3036%, Training Loss: 0.7098%\n",
      "Epoch [26/300], Step [106/225], Training Accuracy: 68.3078%, Training Loss: 0.7096%\n",
      "Epoch [26/300], Step [107/225], Training Accuracy: 68.2973%, Training Loss: 0.7107%\n",
      "Epoch [26/300], Step [108/225], Training Accuracy: 68.2292%, Training Loss: 0.7114%\n",
      "Epoch [26/300], Step [109/225], Training Accuracy: 68.2483%, Training Loss: 0.7110%\n",
      "Epoch [26/300], Step [110/225], Training Accuracy: 68.2244%, Training Loss: 0.7112%\n",
      "Epoch [26/300], Step [111/225], Training Accuracy: 68.2573%, Training Loss: 0.7104%\n",
      "Epoch [26/300], Step [112/225], Training Accuracy: 68.2617%, Training Loss: 0.7103%\n",
      "Epoch [26/300], Step [113/225], Training Accuracy: 68.2799%, Training Loss: 0.7100%\n",
      "Epoch [26/300], Step [114/225], Training Accuracy: 68.2429%, Training Loss: 0.7093%\n",
      "Epoch [26/300], Step [115/225], Training Accuracy: 68.2337%, Training Loss: 0.7088%\n",
      "Epoch [26/300], Step [116/225], Training Accuracy: 68.1843%, Training Loss: 0.7084%\n",
      "Epoch [26/300], Step [117/225], Training Accuracy: 68.1223%, Training Loss: 0.7103%\n",
      "Epoch [26/300], Step [118/225], Training Accuracy: 68.1541%, Training Loss: 0.7103%\n",
      "Epoch [26/300], Step [119/225], Training Accuracy: 68.1854%, Training Loss: 0.7102%\n",
      "Epoch [26/300], Step [120/225], Training Accuracy: 68.1380%, Training Loss: 0.7109%\n",
      "Epoch [26/300], Step [121/225], Training Accuracy: 68.0656%, Training Loss: 0.7117%\n",
      "Epoch [26/300], Step [122/225], Training Accuracy: 68.1481%, Training Loss: 0.7110%\n",
      "Epoch [26/300], Step [123/225], Training Accuracy: 68.1657%, Training Loss: 0.7108%\n",
      "Epoch [26/300], Step [124/225], Training Accuracy: 68.1326%, Training Loss: 0.7113%\n",
      "Epoch [26/300], Step [125/225], Training Accuracy: 68.1500%, Training Loss: 0.7117%\n",
      "Epoch [26/300], Step [126/225], Training Accuracy: 68.0928%, Training Loss: 0.7119%\n",
      "Epoch [26/300], Step [127/225], Training Accuracy: 68.1102%, Training Loss: 0.7118%\n",
      "Epoch [26/300], Step [128/225], Training Accuracy: 68.0420%, Training Loss: 0.7120%\n",
      "Epoch [26/300], Step [129/225], Training Accuracy: 67.9990%, Training Loss: 0.7122%\n",
      "Epoch [26/300], Step [130/225], Training Accuracy: 68.0048%, Training Loss: 0.7121%\n",
      "Epoch [26/300], Step [131/225], Training Accuracy: 68.0463%, Training Loss: 0.7118%\n",
      "Epoch [26/300], Step [132/225], Training Accuracy: 68.0161%, Training Loss: 0.7129%\n",
      "Epoch [26/300], Step [133/225], Training Accuracy: 68.0804%, Training Loss: 0.7123%\n",
      "Epoch [26/300], Step [134/225], Training Accuracy: 67.9688%, Training Loss: 0.7140%\n",
      "Epoch [26/300], Step [135/225], Training Accuracy: 67.9977%, Training Loss: 0.7133%\n",
      "Epoch [26/300], Step [136/225], Training Accuracy: 68.0262%, Training Loss: 0.7133%\n",
      "Epoch [26/300], Step [137/225], Training Accuracy: 68.0429%, Training Loss: 0.7133%\n",
      "Epoch [26/300], Step [138/225], Training Accuracy: 68.1159%, Training Loss: 0.7116%\n",
      "Epoch [26/300], Step [139/225], Training Accuracy: 68.1317%, Training Loss: 0.7110%\n",
      "Epoch [26/300], Step [140/225], Training Accuracy: 68.1585%, Training Loss: 0.7108%\n",
      "Epoch [26/300], Step [141/225], Training Accuracy: 68.1848%, Training Loss: 0.7106%\n",
      "Epoch [26/300], Step [142/225], Training Accuracy: 68.2108%, Training Loss: 0.7098%\n",
      "Epoch [26/300], Step [143/225], Training Accuracy: 68.1927%, Training Loss: 0.7100%\n",
      "Epoch [26/300], Step [144/225], Training Accuracy: 68.1641%, Training Loss: 0.7104%\n",
      "Epoch [26/300], Step [145/225], Training Accuracy: 68.1681%, Training Loss: 0.7096%\n",
      "Epoch [26/300], Step [146/225], Training Accuracy: 68.1293%, Training Loss: 0.7106%\n",
      "Epoch [26/300], Step [147/225], Training Accuracy: 68.1335%, Training Loss: 0.7105%\n",
      "Epoch [26/300], Step [148/225], Training Accuracy: 68.1377%, Training Loss: 0.7101%\n",
      "Epoch [26/300], Step [149/225], Training Accuracy: 68.1837%, Training Loss: 0.7095%\n",
      "Epoch [26/300], Step [150/225], Training Accuracy: 68.1979%, Training Loss: 0.7085%\n",
      "Epoch [26/300], Step [151/225], Training Accuracy: 68.1912%, Training Loss: 0.7084%\n",
      "Epoch [26/300], Step [152/225], Training Accuracy: 68.1127%, Training Loss: 0.7097%\n",
      "Epoch [26/300], Step [153/225], Training Accuracy: 68.0658%, Training Loss: 0.7101%\n",
      "Epoch [26/300], Step [154/225], Training Accuracy: 68.0601%, Training Loss: 0.7101%\n",
      "Epoch [26/300], Step [155/225], Training Accuracy: 68.0847%, Training Loss: 0.7096%\n",
      "Epoch [26/300], Step [156/225], Training Accuracy: 68.0288%, Training Loss: 0.7100%\n",
      "Epoch [26/300], Step [157/225], Training Accuracy: 68.0732%, Training Loss: 0.7091%\n",
      "Epoch [26/300], Step [158/225], Training Accuracy: 68.0380%, Training Loss: 0.7096%\n",
      "Epoch [26/300], Step [159/225], Training Accuracy: 67.9835%, Training Loss: 0.7103%\n",
      "Epoch [26/300], Step [160/225], Training Accuracy: 67.9980%, Training Loss: 0.7094%\n",
      "Epoch [26/300], Step [161/225], Training Accuracy: 68.0221%, Training Loss: 0.7090%\n",
      "Epoch [26/300], Step [162/225], Training Accuracy: 68.0363%, Training Loss: 0.7089%\n",
      "Epoch [26/300], Step [163/225], Training Accuracy: 68.0598%, Training Loss: 0.7081%\n",
      "Epoch [26/300], Step [164/225], Training Accuracy: 68.0545%, Training Loss: 0.7075%\n",
      "Epoch [26/300], Step [165/225], Training Accuracy: 68.0398%, Training Loss: 0.7074%\n",
      "Epoch [26/300], Step [166/225], Training Accuracy: 68.0252%, Training Loss: 0.7074%\n",
      "Epoch [26/300], Step [167/225], Training Accuracy: 68.0576%, Training Loss: 0.7074%\n",
      "Epoch [26/300], Step [168/225], Training Accuracy: 68.0432%, Training Loss: 0.7074%\n",
      "Epoch [26/300], Step [169/225], Training Accuracy: 68.0843%, Training Loss: 0.7067%\n",
      "Epoch [26/300], Step [170/225], Training Accuracy: 68.1526%, Training Loss: 0.7061%\n",
      "Epoch [26/300], Step [171/225], Training Accuracy: 68.1469%, Training Loss: 0.7056%\n",
      "Epoch [26/300], Step [172/225], Training Accuracy: 68.1232%, Training Loss: 0.7058%\n",
      "Epoch [26/300], Step [173/225], Training Accuracy: 68.1358%, Training Loss: 0.7064%\n",
      "Epoch [26/300], Step [174/225], Training Accuracy: 68.1304%, Training Loss: 0.7062%\n",
      "Epoch [26/300], Step [175/225], Training Accuracy: 68.1250%, Training Loss: 0.7061%\n",
      "Epoch [26/300], Step [176/225], Training Accuracy: 68.1286%, Training Loss: 0.7061%\n",
      "Epoch [26/300], Step [177/225], Training Accuracy: 68.1321%, Training Loss: 0.7060%\n",
      "Epoch [26/300], Step [178/225], Training Accuracy: 68.1180%, Training Loss: 0.7061%\n",
      "Epoch [26/300], Step [179/225], Training Accuracy: 68.1652%, Training Loss: 0.7061%\n",
      "Epoch [26/300], Step [180/225], Training Accuracy: 68.2031%, Training Loss: 0.7052%\n",
      "Epoch [26/300], Step [181/225], Training Accuracy: 68.2320%, Training Loss: 0.7050%\n",
      "Epoch [26/300], Step [182/225], Training Accuracy: 68.2349%, Training Loss: 0.7050%\n",
      "Epoch [26/300], Step [183/225], Training Accuracy: 68.2206%, Training Loss: 0.7047%\n",
      "Epoch [26/300], Step [184/225], Training Accuracy: 68.2405%, Training Loss: 0.7039%\n",
      "Epoch [26/300], Step [185/225], Training Accuracy: 68.2517%, Training Loss: 0.7043%\n",
      "Epoch [26/300], Step [186/225], Training Accuracy: 68.3300%, Training Loss: 0.7033%\n",
      "Epoch [26/300], Step [187/225], Training Accuracy: 68.3322%, Training Loss: 0.7037%\n",
      "Epoch [26/300], Step [188/225], Training Accuracy: 68.3677%, Training Loss: 0.7030%\n",
      "Epoch [26/300], Step [189/225], Training Accuracy: 68.4110%, Training Loss: 0.7021%\n",
      "Epoch [26/300], Step [190/225], Training Accuracy: 68.4293%, Training Loss: 0.7022%\n",
      "Epoch [26/300], Step [191/225], Training Accuracy: 68.4228%, Training Loss: 0.7024%\n",
      "Epoch [26/300], Step [192/225], Training Accuracy: 68.4733%, Training Loss: 0.7018%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/300], Step [193/225], Training Accuracy: 68.4505%, Training Loss: 0.7024%\n",
      "Epoch [26/300], Step [194/225], Training Accuracy: 68.4117%, Training Loss: 0.7032%\n",
      "Epoch [26/300], Step [195/225], Training Accuracy: 68.4696%, Training Loss: 0.7024%\n",
      "Epoch [26/300], Step [196/225], Training Accuracy: 68.4391%, Training Loss: 0.7028%\n",
      "Epoch [26/300], Step [197/225], Training Accuracy: 68.4486%, Training Loss: 0.7027%\n",
      "Epoch [26/300], Step [198/225], Training Accuracy: 68.4343%, Training Loss: 0.7023%\n",
      "Epoch [26/300], Step [199/225], Training Accuracy: 68.4359%, Training Loss: 0.7020%\n",
      "Epoch [26/300], Step [200/225], Training Accuracy: 68.4141%, Training Loss: 0.7030%\n",
      "Epoch [26/300], Step [201/225], Training Accuracy: 68.3846%, Training Loss: 0.7035%\n",
      "Epoch [26/300], Step [202/225], Training Accuracy: 68.4019%, Training Loss: 0.7030%\n",
      "Epoch [26/300], Step [203/225], Training Accuracy: 68.4113%, Training Loss: 0.7024%\n",
      "Epoch [26/300], Step [204/225], Training Accuracy: 68.4130%, Training Loss: 0.7023%\n",
      "Epoch [26/300], Step [205/225], Training Accuracy: 68.4223%, Training Loss: 0.7021%\n",
      "Epoch [26/300], Step [206/225], Training Accuracy: 68.4314%, Training Loss: 0.7026%\n",
      "Epoch [26/300], Step [207/225], Training Accuracy: 68.4632%, Training Loss: 0.7024%\n",
      "Epoch [26/300], Step [208/225], Training Accuracy: 68.5021%, Training Loss: 0.7016%\n",
      "Epoch [26/300], Step [209/225], Training Accuracy: 68.5182%, Training Loss: 0.7017%\n",
      "Epoch [26/300], Step [210/225], Training Accuracy: 68.5119%, Training Loss: 0.7021%\n",
      "Epoch [26/300], Step [211/225], Training Accuracy: 68.4982%, Training Loss: 0.7017%\n",
      "Epoch [26/300], Step [212/225], Training Accuracy: 68.4478%, Training Loss: 0.7021%\n",
      "Epoch [26/300], Step [213/225], Training Accuracy: 68.3906%, Training Loss: 0.7028%\n",
      "Epoch [26/300], Step [214/225], Training Accuracy: 68.4068%, Training Loss: 0.7023%\n",
      "Epoch [26/300], Step [215/225], Training Accuracy: 68.4157%, Training Loss: 0.7027%\n",
      "Epoch [26/300], Step [216/225], Training Accuracy: 68.3955%, Training Loss: 0.7032%\n",
      "Epoch [26/300], Step [217/225], Training Accuracy: 68.3468%, Training Loss: 0.7036%\n",
      "Epoch [26/300], Step [218/225], Training Accuracy: 68.3128%, Training Loss: 0.7038%\n",
      "Epoch [26/300], Step [219/225], Training Accuracy: 68.3005%, Training Loss: 0.7042%\n",
      "Epoch [26/300], Step [220/225], Training Accuracy: 68.2955%, Training Loss: 0.7039%\n",
      "Epoch [26/300], Step [221/225], Training Accuracy: 68.3187%, Training Loss: 0.7035%\n",
      "Epoch [26/300], Step [222/225], Training Accuracy: 68.3559%, Training Loss: 0.7033%\n",
      "Epoch [26/300], Step [223/225], Training Accuracy: 68.3296%, Training Loss: 0.7035%\n",
      "Epoch [26/300], Step [224/225], Training Accuracy: 68.3105%, Training Loss: 0.7034%\n",
      "Epoch [26/300], Step [225/225], Training Accuracy: 68.3157%, Training Loss: 0.7035%\n",
      "Epoch [27/300], Step [1/225], Training Accuracy: 75.0000%, Training Loss: 0.5393%\n",
      "Epoch [27/300], Step [2/225], Training Accuracy: 72.6562%, Training Loss: 0.6079%\n",
      "Epoch [27/300], Step [3/225], Training Accuracy: 68.2292%, Training Loss: 0.6878%\n",
      "Epoch [27/300], Step [4/225], Training Accuracy: 69.1406%, Training Loss: 0.6752%\n",
      "Epoch [27/300], Step [5/225], Training Accuracy: 70.6250%, Training Loss: 0.6813%\n",
      "Epoch [27/300], Step [6/225], Training Accuracy: 70.3125%, Training Loss: 0.6714%\n",
      "Epoch [27/300], Step [7/225], Training Accuracy: 70.3125%, Training Loss: 0.6867%\n",
      "Epoch [27/300], Step [8/225], Training Accuracy: 69.7266%, Training Loss: 0.6998%\n",
      "Epoch [27/300], Step [9/225], Training Accuracy: 69.9653%, Training Loss: 0.7008%\n",
      "Epoch [27/300], Step [10/225], Training Accuracy: 69.0625%, Training Loss: 0.7165%\n",
      "Epoch [27/300], Step [11/225], Training Accuracy: 68.7500%, Training Loss: 0.7155%\n",
      "Epoch [27/300], Step [12/225], Training Accuracy: 68.6198%, Training Loss: 0.7085%\n",
      "Epoch [27/300], Step [13/225], Training Accuracy: 69.2308%, Training Loss: 0.6976%\n",
      "Epoch [27/300], Step [14/225], Training Accuracy: 69.3080%, Training Loss: 0.6976%\n",
      "Epoch [27/300], Step [15/225], Training Accuracy: 68.5417%, Training Loss: 0.7080%\n",
      "Epoch [27/300], Step [16/225], Training Accuracy: 68.3594%, Training Loss: 0.7096%\n",
      "Epoch [27/300], Step [17/225], Training Accuracy: 68.8419%, Training Loss: 0.7025%\n",
      "Epoch [27/300], Step [18/225], Training Accuracy: 68.8368%, Training Loss: 0.7004%\n",
      "Epoch [27/300], Step [19/225], Training Accuracy: 68.8322%, Training Loss: 0.6956%\n",
      "Epoch [27/300], Step [20/225], Training Accuracy: 69.0625%, Training Loss: 0.6896%\n",
      "Epoch [27/300], Step [21/225], Training Accuracy: 69.3452%, Training Loss: 0.6831%\n",
      "Epoch [27/300], Step [22/225], Training Accuracy: 68.9631%, Training Loss: 0.6854%\n",
      "Epoch [27/300], Step [23/225], Training Accuracy: 68.9538%, Training Loss: 0.6852%\n",
      "Epoch [27/300], Step [24/225], Training Accuracy: 68.7500%, Training Loss: 0.6870%\n",
      "Epoch [27/300], Step [25/225], Training Accuracy: 69.0000%, Training Loss: 0.6829%\n",
      "Epoch [27/300], Step [26/225], Training Accuracy: 69.1707%, Training Loss: 0.6847%\n",
      "Epoch [27/300], Step [27/225], Training Accuracy: 69.0972%, Training Loss: 0.6854%\n",
      "Epoch [27/300], Step [28/225], Training Accuracy: 69.3638%, Training Loss: 0.6824%\n",
      "Epoch [27/300], Step [29/225], Training Accuracy: 69.6121%, Training Loss: 0.6798%\n",
      "Epoch [27/300], Step [30/225], Training Accuracy: 69.4792%, Training Loss: 0.6815%\n",
      "Epoch [27/300], Step [31/225], Training Accuracy: 69.4556%, Training Loss: 0.6819%\n",
      "Epoch [27/300], Step [32/225], Training Accuracy: 69.6289%, Training Loss: 0.6781%\n",
      "Epoch [27/300], Step [33/225], Training Accuracy: 69.7443%, Training Loss: 0.6783%\n",
      "Epoch [27/300], Step [34/225], Training Accuracy: 69.3934%, Training Loss: 0.6846%\n",
      "Epoch [27/300], Step [35/225], Training Accuracy: 69.1518%, Training Loss: 0.6911%\n",
      "Epoch [27/300], Step [36/225], Training Accuracy: 69.2274%, Training Loss: 0.6921%\n",
      "Epoch [27/300], Step [37/225], Training Accuracy: 69.4679%, Training Loss: 0.6889%\n",
      "Epoch [27/300], Step [38/225], Training Accuracy: 69.4901%, Training Loss: 0.6866%\n",
      "Epoch [27/300], Step [39/225], Training Accuracy: 69.5513%, Training Loss: 0.6877%\n",
      "Epoch [27/300], Step [40/225], Training Accuracy: 69.2188%, Training Loss: 0.6932%\n",
      "Epoch [27/300], Step [41/225], Training Accuracy: 69.0549%, Training Loss: 0.6953%\n",
      "Epoch [27/300], Step [42/225], Training Accuracy: 69.0476%, Training Loss: 0.6957%\n",
      "Epoch [27/300], Step [43/225], Training Accuracy: 68.9680%, Training Loss: 0.6970%\n",
      "Epoch [27/300], Step [44/225], Training Accuracy: 69.0696%, Training Loss: 0.6979%\n",
      "Epoch [27/300], Step [45/225], Training Accuracy: 69.0972%, Training Loss: 0.6986%\n",
      "Epoch [27/300], Step [46/225], Training Accuracy: 69.2595%, Training Loss: 0.6947%\n",
      "Epoch [27/300], Step [47/225], Training Accuracy: 69.1489%, Training Loss: 0.6939%\n",
      "Epoch [27/300], Step [48/225], Training Accuracy: 68.9128%, Training Loss: 0.6990%\n",
      "Epoch [27/300], Step [49/225], Training Accuracy: 68.9094%, Training Loss: 0.6973%\n",
      "Epoch [27/300], Step [50/225], Training Accuracy: 68.8750%, Training Loss: 0.6992%\n",
      "Epoch [27/300], Step [51/225], Training Accuracy: 69.0870%, Training Loss: 0.6953%\n",
      "Epoch [27/300], Step [52/225], Training Accuracy: 69.2909%, Training Loss: 0.6910%\n",
      "Epoch [27/300], Step [53/225], Training Accuracy: 69.3396%, Training Loss: 0.6920%\n",
      "Epoch [27/300], Step [54/225], Training Accuracy: 69.0972%, Training Loss: 0.6957%\n",
      "Epoch [27/300], Step [55/225], Training Accuracy: 68.9205%, Training Loss: 0.6977%\n",
      "Epoch [27/300], Step [56/225], Training Accuracy: 68.8895%, Training Loss: 0.6998%\n",
      "Epoch [27/300], Step [57/225], Training Accuracy: 68.8871%, Training Loss: 0.6995%\n",
      "Epoch [27/300], Step [58/225], Training Accuracy: 68.8847%, Training Loss: 0.6993%\n",
      "Epoch [27/300], Step [59/225], Training Accuracy: 68.5911%, Training Loss: 0.7034%\n",
      "Epoch [27/300], Step [60/225], Training Accuracy: 68.6198%, Training Loss: 0.7016%\n",
      "Epoch [27/300], Step [61/225], Training Accuracy: 68.6475%, Training Loss: 0.7013%\n",
      "Epoch [27/300], Step [62/225], Training Accuracy: 68.6996%, Training Loss: 0.7010%\n",
      "Epoch [27/300], Step [63/225], Training Accuracy: 68.7748%, Training Loss: 0.7005%\n",
      "Epoch [27/300], Step [64/225], Training Accuracy: 68.7256%, Training Loss: 0.7006%\n",
      "Epoch [27/300], Step [65/225], Training Accuracy: 68.8462%, Training Loss: 0.6999%\n",
      "Epoch [27/300], Step [66/225], Training Accuracy: 68.9394%, Training Loss: 0.6982%\n",
      "Epoch [27/300], Step [67/225], Training Accuracy: 68.9599%, Training Loss: 0.6977%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/300], Step [68/225], Training Accuracy: 68.9108%, Training Loss: 0.6991%\n",
      "Epoch [27/300], Step [69/225], Training Accuracy: 68.8859%, Training Loss: 0.6988%\n",
      "Epoch [27/300], Step [70/225], Training Accuracy: 68.9062%, Training Loss: 0.6974%\n",
      "Epoch [27/300], Step [71/225], Training Accuracy: 69.0361%, Training Loss: 0.6976%\n",
      "Epoch [27/300], Step [72/225], Training Accuracy: 69.1189%, Training Loss: 0.6962%\n",
      "Epoch [27/300], Step [73/225], Training Accuracy: 69.2851%, Training Loss: 0.6947%\n",
      "Epoch [27/300], Step [74/225], Training Accuracy: 69.4046%, Training Loss: 0.6916%\n",
      "Epoch [27/300], Step [75/225], Training Accuracy: 69.3542%, Training Loss: 0.6922%\n",
      "Epoch [27/300], Step [76/225], Training Accuracy: 69.3051%, Training Loss: 0.6935%\n",
      "Epoch [27/300], Step [77/225], Training Accuracy: 69.3791%, Training Loss: 0.6943%\n",
      "Epoch [27/300], Step [78/225], Training Accuracy: 69.3109%, Training Loss: 0.6936%\n",
      "Epoch [27/300], Step [79/225], Training Accuracy: 69.4027%, Training Loss: 0.6915%\n",
      "Epoch [27/300], Step [80/225], Training Accuracy: 69.3555%, Training Loss: 0.6916%\n",
      "Epoch [27/300], Step [81/225], Training Accuracy: 69.3866%, Training Loss: 0.6907%\n",
      "Epoch [27/300], Step [82/225], Training Accuracy: 69.4169%, Training Loss: 0.6883%\n",
      "Epoch [27/300], Step [83/225], Training Accuracy: 69.3336%, Training Loss: 0.6890%\n",
      "Epoch [27/300], Step [84/225], Training Accuracy: 69.4382%, Training Loss: 0.6882%\n",
      "Epoch [27/300], Step [85/225], Training Accuracy: 69.4853%, Training Loss: 0.6869%\n",
      "Epoch [27/300], Step [86/225], Training Accuracy: 69.5312%, Training Loss: 0.6863%\n",
      "Epoch [27/300], Step [87/225], Training Accuracy: 69.4684%, Training Loss: 0.6880%\n",
      "Epoch [27/300], Step [88/225], Training Accuracy: 69.4070%, Training Loss: 0.6881%\n",
      "Epoch [27/300], Step [89/225], Training Accuracy: 69.3820%, Training Loss: 0.6891%\n",
      "Epoch [27/300], Step [90/225], Training Accuracy: 69.3229%, Training Loss: 0.6899%\n",
      "Epoch [27/300], Step [91/225], Training Accuracy: 69.3166%, Training Loss: 0.6896%\n",
      "Epoch [27/300], Step [92/225], Training Accuracy: 69.2595%, Training Loss: 0.6904%\n",
      "Epoch [27/300], Step [93/225], Training Accuracy: 69.2540%, Training Loss: 0.6903%\n",
      "Epoch [27/300], Step [94/225], Training Accuracy: 69.2320%, Training Loss: 0.6900%\n",
      "Epoch [27/300], Step [95/225], Training Accuracy: 69.1941%, Training Loss: 0.6905%\n",
      "Epoch [27/300], Step [96/225], Training Accuracy: 69.2057%, Training Loss: 0.6897%\n",
      "Epoch [27/300], Step [97/225], Training Accuracy: 69.3138%, Training Loss: 0.6883%\n",
      "Epoch [27/300], Step [98/225], Training Accuracy: 69.2761%, Training Loss: 0.6891%\n",
      "Epoch [27/300], Step [99/225], Training Accuracy: 69.2235%, Training Loss: 0.6895%\n",
      "Epoch [27/300], Step [100/225], Training Accuracy: 69.1875%, Training Loss: 0.6906%\n",
      "Epoch [27/300], Step [101/225], Training Accuracy: 69.2296%, Training Loss: 0.6922%\n",
      "Epoch [27/300], Step [102/225], Training Accuracy: 69.1330%, Training Loss: 0.6924%\n",
      "Epoch [27/300], Step [103/225], Training Accuracy: 69.1292%, Training Loss: 0.6920%\n",
      "Epoch [27/300], Step [104/225], Training Accuracy: 69.1106%, Training Loss: 0.6920%\n",
      "Epoch [27/300], Step [105/225], Training Accuracy: 69.1220%, Training Loss: 0.6918%\n",
      "Epoch [27/300], Step [106/225], Training Accuracy: 68.9858%, Training Loss: 0.6919%\n",
      "Epoch [27/300], Step [107/225], Training Accuracy: 68.9398%, Training Loss: 0.6924%\n",
      "Epoch [27/300], Step [108/225], Training Accuracy: 68.9815%, Training Loss: 0.6915%\n",
      "Epoch [27/300], Step [109/225], Training Accuracy: 69.0224%, Training Loss: 0.6907%\n",
      "Epoch [27/300], Step [110/225], Training Accuracy: 68.9773%, Training Loss: 0.6911%\n",
      "Epoch [27/300], Step [111/225], Training Accuracy: 68.9893%, Training Loss: 0.6918%\n",
      "Epoch [27/300], Step [112/225], Training Accuracy: 69.0011%, Training Loss: 0.6916%\n",
      "Epoch [27/300], Step [113/225], Training Accuracy: 68.9989%, Training Loss: 0.6912%\n",
      "Epoch [27/300], Step [114/225], Training Accuracy: 69.0378%, Training Loss: 0.6901%\n",
      "Epoch [27/300], Step [115/225], Training Accuracy: 69.0489%, Training Loss: 0.6893%\n",
      "Epoch [27/300], Step [116/225], Training Accuracy: 69.0598%, Training Loss: 0.6890%\n",
      "Epoch [27/300], Step [117/225], Training Accuracy: 68.9637%, Training Loss: 0.6906%\n",
      "Epoch [27/300], Step [118/225], Training Accuracy: 68.9089%, Training Loss: 0.6904%\n",
      "Epoch [27/300], Step [119/225], Training Accuracy: 68.8550%, Training Loss: 0.6902%\n",
      "Epoch [27/300], Step [120/225], Training Accuracy: 68.7760%, Training Loss: 0.6915%\n",
      "Epoch [27/300], Step [121/225], Training Accuracy: 68.7887%, Training Loss: 0.6921%\n",
      "Epoch [27/300], Step [122/225], Training Accuracy: 68.8012%, Training Loss: 0.6915%\n",
      "Epoch [27/300], Step [123/225], Training Accuracy: 68.7627%, Training Loss: 0.6909%\n",
      "Epoch [27/300], Step [124/225], Training Accuracy: 68.7752%, Training Loss: 0.6903%\n",
      "Epoch [27/300], Step [125/225], Training Accuracy: 68.7750%, Training Loss: 0.6917%\n",
      "Epoch [27/300], Step [126/225], Training Accuracy: 68.7748%, Training Loss: 0.6915%\n",
      "Epoch [27/300], Step [127/225], Training Accuracy: 68.7623%, Training Loss: 0.6913%\n",
      "Epoch [27/300], Step [128/225], Training Accuracy: 68.7500%, Training Loss: 0.6915%\n",
      "Epoch [27/300], Step [129/225], Training Accuracy: 68.7621%, Training Loss: 0.6910%\n",
      "Epoch [27/300], Step [130/225], Training Accuracy: 68.7019%, Training Loss: 0.6919%\n",
      "Epoch [27/300], Step [131/225], Training Accuracy: 68.7381%, Training Loss: 0.6920%\n",
      "Epoch [27/300], Step [132/225], Training Accuracy: 68.6790%, Training Loss: 0.6924%\n",
      "Epoch [27/300], Step [133/225], Training Accuracy: 68.7030%, Training Loss: 0.6919%\n",
      "Epoch [27/300], Step [134/225], Training Accuracy: 68.5984%, Training Loss: 0.6933%\n",
      "Epoch [27/300], Step [135/225], Training Accuracy: 68.6227%, Training Loss: 0.6926%\n",
      "Epoch [27/300], Step [136/225], Training Accuracy: 68.6811%, Training Loss: 0.6921%\n",
      "Epoch [27/300], Step [137/225], Training Accuracy: 68.6588%, Training Loss: 0.6926%\n",
      "Epoch [27/300], Step [138/225], Training Accuracy: 68.7840%, Training Loss: 0.6906%\n",
      "Epoch [27/300], Step [139/225], Training Accuracy: 68.8062%, Training Loss: 0.6905%\n",
      "Epoch [27/300], Step [140/225], Training Accuracy: 68.7835%, Training Loss: 0.6902%\n",
      "Epoch [27/300], Step [141/225], Training Accuracy: 68.8054%, Training Loss: 0.6898%\n",
      "Epoch [27/300], Step [142/225], Training Accuracy: 68.7830%, Training Loss: 0.6895%\n",
      "Epoch [27/300], Step [143/225], Training Accuracy: 68.7609%, Training Loss: 0.6899%\n",
      "Epoch [27/300], Step [144/225], Training Accuracy: 68.7500%, Training Loss: 0.6904%\n",
      "Epoch [27/300], Step [145/225], Training Accuracy: 68.7177%, Training Loss: 0.6910%\n",
      "Epoch [27/300], Step [146/225], Training Accuracy: 68.7286%, Training Loss: 0.6913%\n",
      "Epoch [27/300], Step [147/225], Training Accuracy: 68.7075%, Training Loss: 0.6920%\n",
      "Epoch [27/300], Step [148/225], Training Accuracy: 68.7606%, Training Loss: 0.6909%\n",
      "Epoch [27/300], Step [149/225], Training Accuracy: 68.7395%, Training Loss: 0.6907%\n",
      "Epoch [27/300], Step [150/225], Training Accuracy: 68.8021%, Training Loss: 0.6893%\n",
      "Epoch [27/300], Step [151/225], Training Accuracy: 68.8224%, Training Loss: 0.6889%\n",
      "Epoch [27/300], Step [152/225], Training Accuracy: 68.8631%, Training Loss: 0.6882%\n",
      "Epoch [27/300], Step [153/225], Training Accuracy: 68.8521%, Training Loss: 0.6882%\n",
      "Epoch [27/300], Step [154/225], Training Accuracy: 68.8312%, Training Loss: 0.6887%\n",
      "Epoch [27/300], Step [155/225], Training Accuracy: 68.7702%, Training Loss: 0.6891%\n",
      "Epoch [27/300], Step [156/225], Training Accuracy: 68.7500%, Training Loss: 0.6898%\n",
      "Epoch [27/300], Step [157/225], Training Accuracy: 68.7400%, Training Loss: 0.6899%\n",
      "Epoch [27/300], Step [158/225], Training Accuracy: 68.6709%, Training Loss: 0.6912%\n",
      "Epoch [27/300], Step [159/225], Training Accuracy: 68.6616%, Training Loss: 0.6913%\n",
      "Epoch [27/300], Step [160/225], Training Accuracy: 68.6816%, Training Loss: 0.6910%\n",
      "Epoch [27/300], Step [161/225], Training Accuracy: 68.6432%, Training Loss: 0.6917%\n",
      "Epoch [27/300], Step [162/225], Training Accuracy: 68.7018%, Training Loss: 0.6913%\n",
      "Epoch [27/300], Step [163/225], Training Accuracy: 68.7117%, Training Loss: 0.6906%\n",
      "Epoch [27/300], Step [164/225], Training Accuracy: 68.7119%, Training Loss: 0.6907%\n",
      "Epoch [27/300], Step [165/225], Training Accuracy: 68.7027%, Training Loss: 0.6911%\n",
      "Epoch [27/300], Step [166/225], Training Accuracy: 68.6841%, Training Loss: 0.6909%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/300], Step [167/225], Training Accuracy: 68.6845%, Training Loss: 0.6903%\n",
      "Epoch [27/300], Step [168/225], Training Accuracy: 68.6291%, Training Loss: 0.6907%\n",
      "Epoch [27/300], Step [169/225], Training Accuracy: 68.6575%, Training Loss: 0.6899%\n",
      "Epoch [27/300], Step [170/225], Training Accuracy: 68.7224%, Training Loss: 0.6892%\n",
      "Epoch [27/300], Step [171/225], Training Accuracy: 68.7226%, Training Loss: 0.6896%\n",
      "Epoch [27/300], Step [172/225], Training Accuracy: 68.7318%, Training Loss: 0.6894%\n",
      "Epoch [27/300], Step [173/225], Training Accuracy: 68.7229%, Training Loss: 0.6898%\n",
      "Epoch [27/300], Step [174/225], Training Accuracy: 68.7769%, Training Loss: 0.6889%\n",
      "Epoch [27/300], Step [175/225], Training Accuracy: 68.7768%, Training Loss: 0.6888%\n",
      "Epoch [27/300], Step [176/225], Training Accuracy: 68.8565%, Training Loss: 0.6879%\n",
      "Epoch [27/300], Step [177/225], Training Accuracy: 68.9001%, Training Loss: 0.6872%\n",
      "Epoch [27/300], Step [178/225], Training Accuracy: 68.8817%, Training Loss: 0.6874%\n",
      "Epoch [27/300], Step [179/225], Training Accuracy: 68.9071%, Training Loss: 0.6868%\n",
      "Epoch [27/300], Step [180/225], Training Accuracy: 68.9323%, Training Loss: 0.6865%\n",
      "Epoch [27/300], Step [181/225], Training Accuracy: 68.9399%, Training Loss: 0.6872%\n",
      "Epoch [27/300], Step [182/225], Training Accuracy: 68.9389%, Training Loss: 0.6874%\n",
      "Epoch [27/300], Step [183/225], Training Accuracy: 68.9037%, Training Loss: 0.6879%\n",
      "Epoch [27/300], Step [184/225], Training Accuracy: 68.9538%, Training Loss: 0.6875%\n",
      "Epoch [27/300], Step [185/225], Training Accuracy: 68.9274%, Training Loss: 0.6876%\n",
      "Epoch [27/300], Step [186/225], Training Accuracy: 68.9516%, Training Loss: 0.6874%\n",
      "Epoch [27/300], Step [187/225], Training Accuracy: 68.9505%, Training Loss: 0.6876%\n",
      "Epoch [27/300], Step [188/225], Training Accuracy: 68.9328%, Training Loss: 0.6879%\n",
      "Epoch [27/300], Step [189/225], Training Accuracy: 68.9649%, Training Loss: 0.6871%\n",
      "Epoch [27/300], Step [190/225], Training Accuracy: 69.0378%, Training Loss: 0.6863%\n",
      "Epoch [27/300], Step [191/225], Training Accuracy: 69.0363%, Training Loss: 0.6863%\n",
      "Epoch [27/300], Step [192/225], Training Accuracy: 69.0837%, Training Loss: 0.6859%\n",
      "Epoch [27/300], Step [193/225], Training Accuracy: 69.0981%, Training Loss: 0.6858%\n",
      "Epoch [27/300], Step [194/225], Training Accuracy: 69.0641%, Training Loss: 0.6863%\n",
      "Epoch [27/300], Step [195/225], Training Accuracy: 69.1266%, Training Loss: 0.6853%\n",
      "Epoch [27/300], Step [196/225], Training Accuracy: 69.0928%, Training Loss: 0.6859%\n",
      "Epoch [27/300], Step [197/225], Training Accuracy: 69.0673%, Training Loss: 0.6862%\n",
      "Epoch [27/300], Step [198/225], Training Accuracy: 69.1051%, Training Loss: 0.6855%\n",
      "Epoch [27/300], Step [199/225], Training Accuracy: 69.1818%, Training Loss: 0.6846%\n",
      "Epoch [27/300], Step [200/225], Training Accuracy: 69.1641%, Training Loss: 0.6845%\n",
      "Epoch [27/300], Step [201/225], Training Accuracy: 69.1231%, Training Loss: 0.6848%\n",
      "Epoch [27/300], Step [202/225], Training Accuracy: 69.1677%, Training Loss: 0.6842%\n",
      "Epoch [27/300], Step [203/225], Training Accuracy: 69.2041%, Training Loss: 0.6837%\n",
      "Epoch [27/300], Step [204/225], Training Accuracy: 69.2249%, Training Loss: 0.6832%\n",
      "Epoch [27/300], Step [205/225], Training Accuracy: 69.2454%, Training Loss: 0.6829%\n",
      "Epoch [27/300], Step [206/225], Training Accuracy: 69.2279%, Training Loss: 0.6832%\n",
      "Epoch [27/300], Step [207/225], Training Accuracy: 69.2406%, Training Loss: 0.6832%\n",
      "Epoch [27/300], Step [208/225], Training Accuracy: 69.2683%, Training Loss: 0.6826%\n",
      "Epoch [27/300], Step [209/225], Training Accuracy: 69.2733%, Training Loss: 0.6828%\n",
      "Epoch [27/300], Step [210/225], Training Accuracy: 69.2634%, Training Loss: 0.6833%\n",
      "Epoch [27/300], Step [211/225], Training Accuracy: 69.2980%, Training Loss: 0.6828%\n",
      "Epoch [27/300], Step [212/225], Training Accuracy: 69.3028%, Training Loss: 0.6829%\n",
      "Epoch [27/300], Step [213/225], Training Accuracy: 69.2855%, Training Loss: 0.6833%\n",
      "Epoch [27/300], Step [214/225], Training Accuracy: 69.3122%, Training Loss: 0.6827%\n",
      "Epoch [27/300], Step [215/225], Training Accuracy: 69.3096%, Training Loss: 0.6824%\n",
      "Epoch [27/300], Step [216/225], Training Accuracy: 69.2853%, Training Loss: 0.6829%\n",
      "Epoch [27/300], Step [217/225], Training Accuracy: 69.2972%, Training Loss: 0.6827%\n",
      "Epoch [27/300], Step [218/225], Training Accuracy: 69.3162%, Training Loss: 0.6828%\n",
      "Epoch [27/300], Step [219/225], Training Accuracy: 69.2922%, Training Loss: 0.6833%\n",
      "Epoch [27/300], Step [220/225], Training Accuracy: 69.3111%, Training Loss: 0.6825%\n",
      "Epoch [27/300], Step [221/225], Training Accuracy: 69.3439%, Training Loss: 0.6820%\n",
      "Epoch [27/300], Step [222/225], Training Accuracy: 69.3271%, Training Loss: 0.6821%\n",
      "Epoch [27/300], Step [223/225], Training Accuracy: 69.2965%, Training Loss: 0.6819%\n",
      "Epoch [27/300], Step [224/225], Training Accuracy: 69.3150%, Training Loss: 0.6817%\n",
      "Epoch [27/300], Step [225/225], Training Accuracy: 69.3163%, Training Loss: 0.6820%\n",
      "Epoch [28/300], Step [1/225], Training Accuracy: 81.2500%, Training Loss: 0.4406%\n",
      "Epoch [28/300], Step [2/225], Training Accuracy: 77.3438%, Training Loss: 0.5252%\n",
      "Epoch [28/300], Step [3/225], Training Accuracy: 76.5625%, Training Loss: 0.5561%\n",
      "Epoch [28/300], Step [4/225], Training Accuracy: 73.4375%, Training Loss: 0.6042%\n",
      "Epoch [28/300], Step [5/225], Training Accuracy: 73.4375%, Training Loss: 0.6143%\n",
      "Epoch [28/300], Step [6/225], Training Accuracy: 73.1771%, Training Loss: 0.6116%\n",
      "Epoch [28/300], Step [7/225], Training Accuracy: 71.8750%, Training Loss: 0.6357%\n",
      "Epoch [28/300], Step [8/225], Training Accuracy: 71.6797%, Training Loss: 0.6477%\n",
      "Epoch [28/300], Step [9/225], Training Accuracy: 71.7014%, Training Loss: 0.6501%\n",
      "Epoch [28/300], Step [10/225], Training Accuracy: 70.3125%, Training Loss: 0.6606%\n",
      "Epoch [28/300], Step [11/225], Training Accuracy: 70.0284%, Training Loss: 0.6578%\n",
      "Epoch [28/300], Step [12/225], Training Accuracy: 69.9219%, Training Loss: 0.6510%\n",
      "Epoch [28/300], Step [13/225], Training Accuracy: 70.5529%, Training Loss: 0.6440%\n",
      "Epoch [28/300], Step [14/225], Training Accuracy: 70.0893%, Training Loss: 0.6567%\n",
      "Epoch [28/300], Step [15/225], Training Accuracy: 69.7917%, Training Loss: 0.6587%\n",
      "Epoch [28/300], Step [16/225], Training Accuracy: 69.8242%, Training Loss: 0.6589%\n",
      "Epoch [28/300], Step [17/225], Training Accuracy: 69.9449%, Training Loss: 0.6558%\n",
      "Epoch [28/300], Step [18/225], Training Accuracy: 70.3993%, Training Loss: 0.6576%\n",
      "Epoch [28/300], Step [19/225], Training Accuracy: 70.3947%, Training Loss: 0.6584%\n",
      "Epoch [28/300], Step [20/225], Training Accuracy: 70.7812%, Training Loss: 0.6548%\n",
      "Epoch [28/300], Step [21/225], Training Accuracy: 71.1310%, Training Loss: 0.6484%\n",
      "Epoch [28/300], Step [22/225], Training Accuracy: 70.8097%, Training Loss: 0.6534%\n",
      "Epoch [28/300], Step [23/225], Training Accuracy: 70.5842%, Training Loss: 0.6553%\n",
      "Epoch [28/300], Step [24/225], Training Accuracy: 70.3776%, Training Loss: 0.6603%\n",
      "Epoch [28/300], Step [25/225], Training Accuracy: 70.6250%, Training Loss: 0.6563%\n",
      "Epoch [28/300], Step [26/225], Training Accuracy: 70.6731%, Training Loss: 0.6572%\n",
      "Epoch [28/300], Step [27/225], Training Accuracy: 70.6019%, Training Loss: 0.6656%\n",
      "Epoch [28/300], Step [28/225], Training Accuracy: 70.7031%, Training Loss: 0.6632%\n",
      "Epoch [28/300], Step [29/225], Training Accuracy: 70.7435%, Training Loss: 0.6593%\n",
      "Epoch [28/300], Step [30/225], Training Accuracy: 70.9896%, Training Loss: 0.6572%\n",
      "Epoch [28/300], Step [31/225], Training Accuracy: 70.9173%, Training Loss: 0.6586%\n",
      "Epoch [28/300], Step [32/225], Training Accuracy: 70.9473%, Training Loss: 0.6559%\n",
      "Epoch [28/300], Step [33/225], Training Accuracy: 71.0701%, Training Loss: 0.6563%\n",
      "Epoch [28/300], Step [34/225], Training Accuracy: 70.7261%, Training Loss: 0.6594%\n",
      "Epoch [28/300], Step [35/225], Training Accuracy: 70.6696%, Training Loss: 0.6603%\n",
      "Epoch [28/300], Step [36/225], Training Accuracy: 70.4427%, Training Loss: 0.6645%\n",
      "Epoch [28/300], Step [37/225], Training Accuracy: 70.4814%, Training Loss: 0.6620%\n",
      "Epoch [28/300], Step [38/225], Training Accuracy: 70.4359%, Training Loss: 0.6628%\n",
      "Epoch [28/300], Step [39/225], Training Accuracy: 70.5929%, Training Loss: 0.6606%\n",
      "Epoch [28/300], Step [40/225], Training Accuracy: 70.4688%, Training Loss: 0.6606%\n",
      "Epoch [28/300], Step [41/225], Training Accuracy: 70.3506%, Training Loss: 0.6631%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/300], Step [42/225], Training Accuracy: 70.3497%, Training Loss: 0.6621%\n",
      "Epoch [28/300], Step [43/225], Training Accuracy: 70.2035%, Training Loss: 0.6624%\n",
      "Epoch [28/300], Step [44/225], Training Accuracy: 70.3480%, Training Loss: 0.6592%\n",
      "Epoch [28/300], Step [45/225], Training Accuracy: 70.2778%, Training Loss: 0.6595%\n",
      "Epoch [28/300], Step [46/225], Training Accuracy: 70.2785%, Training Loss: 0.6581%\n",
      "Epoch [28/300], Step [47/225], Training Accuracy: 70.3125%, Training Loss: 0.6582%\n",
      "Epoch [28/300], Step [48/225], Training Accuracy: 70.1823%, Training Loss: 0.6593%\n",
      "Epoch [28/300], Step [49/225], Training Accuracy: 70.2806%, Training Loss: 0.6590%\n",
      "Epoch [28/300], Step [50/225], Training Accuracy: 70.2812%, Training Loss: 0.6615%\n",
      "Epoch [28/300], Step [51/225], Training Accuracy: 70.4657%, Training Loss: 0.6580%\n",
      "Epoch [28/300], Step [52/225], Training Accuracy: 70.5829%, Training Loss: 0.6555%\n",
      "Epoch [28/300], Step [53/225], Training Accuracy: 70.5483%, Training Loss: 0.6557%\n",
      "Epoch [28/300], Step [54/225], Training Accuracy: 70.4861%, Training Loss: 0.6567%\n",
      "Epoch [28/300], Step [55/225], Training Accuracy: 70.3693%, Training Loss: 0.6620%\n",
      "Epoch [28/300], Step [56/225], Training Accuracy: 70.3962%, Training Loss: 0.6624%\n",
      "Epoch [28/300], Step [57/225], Training Accuracy: 70.4770%, Training Loss: 0.6606%\n",
      "Epoch [28/300], Step [58/225], Training Accuracy: 70.5280%, Training Loss: 0.6586%\n",
      "Epoch [28/300], Step [59/225], Training Accuracy: 70.3655%, Training Loss: 0.6597%\n",
      "Epoch [28/300], Step [60/225], Training Accuracy: 70.4427%, Training Loss: 0.6584%\n",
      "Epoch [28/300], Step [61/225], Training Accuracy: 70.3637%, Training Loss: 0.6588%\n",
      "Epoch [28/300], Step [62/225], Training Accuracy: 70.4385%, Training Loss: 0.6578%\n",
      "Epoch [28/300], Step [63/225], Training Accuracy: 70.5109%, Training Loss: 0.6575%\n",
      "Epoch [28/300], Step [64/225], Training Accuracy: 70.6787%, Training Loss: 0.6561%\n",
      "Epoch [28/300], Step [65/225], Training Accuracy: 70.7692%, Training Loss: 0.6554%\n",
      "Epoch [28/300], Step [66/225], Training Accuracy: 70.7860%, Training Loss: 0.6534%\n",
      "Epoch [28/300], Step [67/225], Training Accuracy: 70.6157%, Training Loss: 0.6550%\n",
      "Epoch [28/300], Step [68/225], Training Accuracy: 70.5423%, Training Loss: 0.6553%\n",
      "Epoch [28/300], Step [69/225], Training Accuracy: 70.5163%, Training Loss: 0.6551%\n",
      "Epoch [28/300], Step [70/225], Training Accuracy: 70.3571%, Training Loss: 0.6567%\n",
      "Epoch [28/300], Step [71/225], Training Accuracy: 70.2685%, Training Loss: 0.6570%\n",
      "Epoch [28/300], Step [72/225], Training Accuracy: 70.1823%, Training Loss: 0.6589%\n",
      "Epoch [28/300], Step [73/225], Training Accuracy: 70.1627%, Training Loss: 0.6578%\n",
      "Epoch [28/300], Step [74/225], Training Accuracy: 70.2492%, Training Loss: 0.6559%\n",
      "Epoch [28/300], Step [75/225], Training Accuracy: 70.2083%, Training Loss: 0.6561%\n",
      "Epoch [28/300], Step [76/225], Training Accuracy: 70.0658%, Training Loss: 0.6571%\n",
      "Epoch [28/300], Step [77/225], Training Accuracy: 70.0487%, Training Loss: 0.6573%\n",
      "Epoch [28/300], Step [78/225], Training Accuracy: 70.1322%, Training Loss: 0.6564%\n",
      "Epoch [28/300], Step [79/225], Training Accuracy: 70.2334%, Training Loss: 0.6547%\n",
      "Epoch [28/300], Step [80/225], Training Accuracy: 70.2148%, Training Loss: 0.6554%\n",
      "Epoch [28/300], Step [81/225], Training Accuracy: 70.2160%, Training Loss: 0.6544%\n",
      "Epoch [28/300], Step [82/225], Training Accuracy: 70.2172%, Training Loss: 0.6542%\n",
      "Epoch [28/300], Step [83/225], Training Accuracy: 70.2560%, Training Loss: 0.6541%\n",
      "Epoch [28/300], Step [84/225], Training Accuracy: 70.3125%, Training Loss: 0.6533%\n",
      "Epoch [28/300], Step [85/225], Training Accuracy: 70.4412%, Training Loss: 0.6519%\n",
      "Epoch [28/300], Step [86/225], Training Accuracy: 70.4578%, Training Loss: 0.6516%\n",
      "Epoch [28/300], Step [87/225], Training Accuracy: 70.4562%, Training Loss: 0.6523%\n",
      "Epoch [28/300], Step [88/225], Training Accuracy: 70.3835%, Training Loss: 0.6555%\n",
      "Epoch [28/300], Step [89/225], Training Accuracy: 70.2774%, Training Loss: 0.6579%\n",
      "Epoch [28/300], Step [90/225], Training Accuracy: 70.2431%, Training Loss: 0.6593%\n",
      "Epoch [28/300], Step [91/225], Training Accuracy: 70.2266%, Training Loss: 0.6606%\n",
      "Epoch [28/300], Step [92/225], Training Accuracy: 70.2276%, Training Loss: 0.6607%\n",
      "Epoch [28/300], Step [93/225], Training Accuracy: 70.2621%, Training Loss: 0.6606%\n",
      "Epoch [28/300], Step [94/225], Training Accuracy: 70.2793%, Training Loss: 0.6598%\n",
      "Epoch [28/300], Step [95/225], Training Accuracy: 70.1480%, Training Loss: 0.6614%\n",
      "Epoch [28/300], Step [96/225], Training Accuracy: 70.2148%, Training Loss: 0.6594%\n",
      "Epoch [28/300], Step [97/225], Training Accuracy: 70.1997%, Training Loss: 0.6594%\n",
      "Epoch [28/300], Step [98/225], Training Accuracy: 70.2009%, Training Loss: 0.6594%\n",
      "Epoch [28/300], Step [99/225], Training Accuracy: 70.3283%, Training Loss: 0.6584%\n",
      "Epoch [28/300], Step [100/225], Training Accuracy: 70.2344%, Training Loss: 0.6598%\n",
      "Epoch [28/300], Step [101/225], Training Accuracy: 70.1578%, Training Loss: 0.6610%\n",
      "Epoch [28/300], Step [102/225], Training Accuracy: 70.1746%, Training Loss: 0.6602%\n",
      "Epoch [28/300], Step [103/225], Training Accuracy: 70.1608%, Training Loss: 0.6605%\n",
      "Epoch [28/300], Step [104/225], Training Accuracy: 70.2073%, Training Loss: 0.6602%\n",
      "Epoch [28/300], Step [105/225], Training Accuracy: 70.2827%, Training Loss: 0.6591%\n",
      "Epoch [28/300], Step [106/225], Training Accuracy: 70.2978%, Training Loss: 0.6588%\n",
      "Epoch [28/300], Step [107/225], Training Accuracy: 70.2687%, Training Loss: 0.6596%\n",
      "Epoch [28/300], Step [108/225], Training Accuracy: 70.2691%, Training Loss: 0.6594%\n",
      "Epoch [28/300], Step [109/225], Training Accuracy: 70.2408%, Training Loss: 0.6598%\n",
      "Epoch [28/300], Step [110/225], Training Accuracy: 70.2699%, Training Loss: 0.6602%\n",
      "Epoch [28/300], Step [111/225], Training Accuracy: 70.3407%, Training Loss: 0.6598%\n",
      "Epoch [28/300], Step [112/225], Training Accuracy: 70.3962%, Training Loss: 0.6588%\n",
      "Epoch [28/300], Step [113/225], Training Accuracy: 70.3816%, Training Loss: 0.6587%\n",
      "Epoch [28/300], Step [114/225], Training Accuracy: 70.3947%, Training Loss: 0.6580%\n",
      "Epoch [28/300], Step [115/225], Training Accuracy: 70.4076%, Training Loss: 0.6580%\n",
      "Epoch [28/300], Step [116/225], Training Accuracy: 70.4337%, Training Loss: 0.6574%\n",
      "Epoch [28/300], Step [117/225], Training Accuracy: 70.3926%, Training Loss: 0.6578%\n",
      "Epoch [28/300], Step [118/225], Training Accuracy: 70.4052%, Training Loss: 0.6572%\n",
      "Epoch [28/300], Step [119/225], Training Accuracy: 70.4307%, Training Loss: 0.6564%\n",
      "Epoch [28/300], Step [120/225], Training Accuracy: 70.3906%, Training Loss: 0.6572%\n",
      "Epoch [28/300], Step [121/225], Training Accuracy: 70.2867%, Training Loss: 0.6580%\n",
      "Epoch [28/300], Step [122/225], Training Accuracy: 70.2485%, Training Loss: 0.6583%\n",
      "Epoch [28/300], Step [123/225], Training Accuracy: 70.2744%, Training Loss: 0.6577%\n",
      "Epoch [28/300], Step [124/225], Training Accuracy: 70.2243%, Training Loss: 0.6579%\n",
      "Epoch [28/300], Step [125/225], Training Accuracy: 70.2500%, Training Loss: 0.6580%\n",
      "Epoch [28/300], Step [126/225], Training Accuracy: 70.2381%, Training Loss: 0.6581%\n",
      "Epoch [28/300], Step [127/225], Training Accuracy: 70.2633%, Training Loss: 0.6579%\n",
      "Epoch [28/300], Step [128/225], Training Accuracy: 70.2637%, Training Loss: 0.6585%\n",
      "Epoch [28/300], Step [129/225], Training Accuracy: 70.2641%, Training Loss: 0.6590%\n",
      "Epoch [28/300], Step [130/225], Training Accuracy: 70.2404%, Training Loss: 0.6590%\n",
      "Epoch [28/300], Step [131/225], Training Accuracy: 70.2409%, Training Loss: 0.6588%\n",
      "Epoch [28/300], Step [132/225], Training Accuracy: 70.2415%, Training Loss: 0.6587%\n",
      "Epoch [28/300], Step [133/225], Training Accuracy: 70.2420%, Training Loss: 0.6589%\n",
      "Epoch [28/300], Step [134/225], Training Accuracy: 70.1143%, Training Loss: 0.6610%\n",
      "Epoch [28/300], Step [135/225], Training Accuracy: 70.1157%, Training Loss: 0.6604%\n",
      "Epoch [28/300], Step [136/225], Training Accuracy: 70.1287%, Training Loss: 0.6608%\n",
      "Epoch [28/300], Step [137/225], Training Accuracy: 70.1642%, Training Loss: 0.6602%\n",
      "Epoch [28/300], Step [138/225], Training Accuracy: 70.2219%, Training Loss: 0.6586%\n",
      "Epoch [28/300], Step [139/225], Training Accuracy: 70.2451%, Training Loss: 0.6580%\n",
      "Epoch [28/300], Step [140/225], Training Accuracy: 70.2009%, Training Loss: 0.6577%\n",
      "Epoch [28/300], Step [141/225], Training Accuracy: 70.1906%, Training Loss: 0.6582%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/300], Step [142/225], Training Accuracy: 70.1474%, Training Loss: 0.6586%\n",
      "Epoch [28/300], Step [143/225], Training Accuracy: 70.1595%, Training Loss: 0.6593%\n",
      "Epoch [28/300], Step [144/225], Training Accuracy: 70.1063%, Training Loss: 0.6598%\n",
      "Epoch [28/300], Step [145/225], Training Accuracy: 70.1401%, Training Loss: 0.6590%\n",
      "Epoch [28/300], Step [146/225], Training Accuracy: 70.1306%, Training Loss: 0.6598%\n",
      "Epoch [28/300], Step [147/225], Training Accuracy: 70.1105%, Training Loss: 0.6598%\n",
      "Epoch [28/300], Step [148/225], Training Accuracy: 70.1753%, Training Loss: 0.6587%\n",
      "Epoch [28/300], Step [149/225], Training Accuracy: 70.2076%, Training Loss: 0.6580%\n",
      "Epoch [28/300], Step [150/225], Training Accuracy: 70.2292%, Training Loss: 0.6575%\n",
      "Epoch [28/300], Step [151/225], Training Accuracy: 70.2194%, Training Loss: 0.6572%\n",
      "Epoch [28/300], Step [152/225], Training Accuracy: 70.2303%, Training Loss: 0.6568%\n",
      "Epoch [28/300], Step [153/225], Training Accuracy: 70.2104%, Training Loss: 0.6571%\n",
      "Epoch [28/300], Step [154/225], Training Accuracy: 70.2110%, Training Loss: 0.6570%\n",
      "Epoch [28/300], Step [155/225], Training Accuracy: 70.2117%, Training Loss: 0.6571%\n",
      "Epoch [28/300], Step [156/225], Training Accuracy: 70.1623%, Training Loss: 0.6574%\n",
      "Epoch [28/300], Step [157/225], Training Accuracy: 70.2030%, Training Loss: 0.6563%\n",
      "Epoch [28/300], Step [158/225], Training Accuracy: 70.1246%, Training Loss: 0.6579%\n",
      "Epoch [28/300], Step [159/225], Training Accuracy: 70.0865%, Training Loss: 0.6578%\n",
      "Epoch [28/300], Step [160/225], Training Accuracy: 70.0586%, Training Loss: 0.6576%\n",
      "Epoch [28/300], Step [161/225], Training Accuracy: 70.0214%, Training Loss: 0.6583%\n",
      "Epoch [28/300], Step [162/225], Training Accuracy: 70.0521%, Training Loss: 0.6587%\n",
      "Epoch [28/300], Step [163/225], Training Accuracy: 70.0920%, Training Loss: 0.6580%\n",
      "Epoch [28/300], Step [164/225], Training Accuracy: 70.1315%, Training Loss: 0.6571%\n",
      "Epoch [28/300], Step [165/225], Training Accuracy: 70.1420%, Training Loss: 0.6572%\n",
      "Epoch [28/300], Step [166/225], Training Accuracy: 70.1713%, Training Loss: 0.6567%\n",
      "Epoch [28/300], Step [167/225], Training Accuracy: 70.1909%, Training Loss: 0.6560%\n",
      "Epoch [28/300], Step [168/225], Training Accuracy: 70.1730%, Training Loss: 0.6559%\n",
      "Epoch [28/300], Step [169/225], Training Accuracy: 70.2200%, Training Loss: 0.6551%\n",
      "Epoch [28/300], Step [170/225], Training Accuracy: 70.2298%, Training Loss: 0.6549%\n",
      "Epoch [28/300], Step [171/225], Training Accuracy: 70.2120%, Training Loss: 0.6549%\n",
      "Epoch [28/300], Step [172/225], Training Accuracy: 70.1944%, Training Loss: 0.6552%\n",
      "Epoch [28/300], Step [173/225], Training Accuracy: 70.2222%, Training Loss: 0.6553%\n",
      "Epoch [28/300], Step [174/225], Training Accuracy: 70.2047%, Training Loss: 0.6552%\n",
      "Epoch [28/300], Step [175/225], Training Accuracy: 70.2411%, Training Loss: 0.6548%\n",
      "Epoch [28/300], Step [176/225], Training Accuracy: 70.2237%, Training Loss: 0.6548%\n",
      "Epoch [28/300], Step [177/225], Training Accuracy: 70.2242%, Training Loss: 0.6543%\n",
      "Epoch [28/300], Step [178/225], Training Accuracy: 70.1633%, Training Loss: 0.6554%\n",
      "Epoch [28/300], Step [179/225], Training Accuracy: 70.1990%, Training Loss: 0.6547%\n",
      "Epoch [28/300], Step [180/225], Training Accuracy: 70.2431%, Training Loss: 0.6538%\n",
      "Epoch [28/300], Step [181/225], Training Accuracy: 70.2607%, Training Loss: 0.6538%\n",
      "Epoch [28/300], Step [182/225], Training Accuracy: 70.2438%, Training Loss: 0.6545%\n",
      "Epoch [28/300], Step [183/225], Training Accuracy: 70.2442%, Training Loss: 0.6551%\n",
      "Epoch [28/300], Step [184/225], Training Accuracy: 70.2870%, Training Loss: 0.6544%\n",
      "Epoch [28/300], Step [185/225], Training Accuracy: 70.3294%, Training Loss: 0.6541%\n",
      "Epoch [28/300], Step [186/225], Training Accuracy: 70.3881%, Training Loss: 0.6532%\n",
      "Epoch [28/300], Step [187/225], Training Accuracy: 70.3961%, Training Loss: 0.6527%\n",
      "Epoch [28/300], Step [188/225], Training Accuracy: 70.4372%, Training Loss: 0.6520%\n",
      "Epoch [28/300], Step [189/225], Training Accuracy: 70.4696%, Training Loss: 0.6515%\n",
      "Epoch [28/300], Step [190/225], Training Accuracy: 70.5016%, Training Loss: 0.6513%\n",
      "Epoch [28/300], Step [191/225], Training Accuracy: 70.4843%, Training Loss: 0.6513%\n",
      "Epoch [28/300], Step [192/225], Training Accuracy: 70.5404%, Training Loss: 0.6507%\n",
      "Epoch [28/300], Step [193/225], Training Accuracy: 70.5635%, Training Loss: 0.6504%\n",
      "Epoch [28/300], Step [194/225], Training Accuracy: 70.5622%, Training Loss: 0.6505%\n",
      "Epoch [28/300], Step [195/225], Training Accuracy: 70.6010%, Training Loss: 0.6497%\n",
      "Epoch [28/300], Step [196/225], Training Accuracy: 70.6075%, Training Loss: 0.6498%\n",
      "Epoch [28/300], Step [197/225], Training Accuracy: 70.5980%, Training Loss: 0.6505%\n",
      "Epoch [28/300], Step [198/225], Training Accuracy: 70.5966%, Training Loss: 0.6504%\n",
      "Epoch [28/300], Step [199/225], Training Accuracy: 70.6266%, Training Loss: 0.6499%\n",
      "Epoch [28/300], Step [200/225], Training Accuracy: 70.6172%, Training Loss: 0.6501%\n",
      "Epoch [28/300], Step [201/225], Training Accuracy: 70.6079%, Training Loss: 0.6507%\n",
      "Epoch [28/300], Step [202/225], Training Accuracy: 70.6374%, Training Loss: 0.6504%\n",
      "Epoch [28/300], Step [203/225], Training Accuracy: 70.6820%, Training Loss: 0.6495%\n",
      "Epoch [28/300], Step [204/225], Training Accuracy: 70.6342%, Training Loss: 0.6496%\n",
      "Epoch [28/300], Step [205/225], Training Accuracy: 70.6098%, Training Loss: 0.6498%\n",
      "Epoch [28/300], Step [206/225], Training Accuracy: 70.6083%, Training Loss: 0.6499%\n",
      "Epoch [28/300], Step [207/225], Training Accuracy: 70.6446%, Training Loss: 0.6498%\n",
      "Epoch [28/300], Step [208/225], Training Accuracy: 70.6505%, Training Loss: 0.6492%\n",
      "Epoch [28/300], Step [209/225], Training Accuracy: 70.6564%, Training Loss: 0.6494%\n",
      "Epoch [28/300], Step [210/225], Training Accuracy: 70.6473%, Training Loss: 0.6497%\n",
      "Epoch [28/300], Step [211/225], Training Accuracy: 70.6902%, Training Loss: 0.6493%\n",
      "Epoch [28/300], Step [212/225], Training Accuracy: 70.6958%, Training Loss: 0.6497%\n",
      "Epoch [28/300], Step [213/225], Training Accuracy: 70.6719%, Training Loss: 0.6506%\n",
      "Epoch [28/300], Step [214/225], Training Accuracy: 70.6703%, Training Loss: 0.6506%\n",
      "Epoch [28/300], Step [215/225], Training Accuracy: 70.6686%, Training Loss: 0.6510%\n",
      "Epoch [28/300], Step [216/225], Training Accuracy: 70.6525%, Training Loss: 0.6511%\n",
      "Epoch [28/300], Step [217/225], Training Accuracy: 70.6077%, Training Loss: 0.6511%\n",
      "Epoch [28/300], Step [218/225], Training Accuracy: 70.6064%, Training Loss: 0.6511%\n",
      "Epoch [28/300], Step [219/225], Training Accuracy: 70.6122%, Training Loss: 0.6509%\n",
      "Epoch [28/300], Step [220/225], Training Accuracy: 70.6179%, Training Loss: 0.6507%\n",
      "Epoch [28/300], Step [221/225], Training Accuracy: 70.6377%, Training Loss: 0.6506%\n",
      "Epoch [28/300], Step [222/225], Training Accuracy: 70.6574%, Training Loss: 0.6507%\n",
      "Epoch [28/300], Step [223/225], Training Accuracy: 70.6698%, Training Loss: 0.6512%\n",
      "Epoch [28/300], Step [224/225], Training Accuracy: 70.6752%, Training Loss: 0.6510%\n",
      "Epoch [28/300], Step [225/225], Training Accuracy: 70.6573%, Training Loss: 0.6515%\n",
      "Epoch [29/300], Step [1/225], Training Accuracy: 71.8750%, Training Loss: 0.5592%\n",
      "Epoch [29/300], Step [2/225], Training Accuracy: 70.3125%, Training Loss: 0.6756%\n",
      "Epoch [29/300], Step [3/225], Training Accuracy: 70.8333%, Training Loss: 0.6762%\n",
      "Epoch [29/300], Step [4/225], Training Accuracy: 72.6562%, Training Loss: 0.6377%\n",
      "Epoch [29/300], Step [5/225], Training Accuracy: 73.1250%, Training Loss: 0.6221%\n",
      "Epoch [29/300], Step [6/225], Training Accuracy: 74.4792%, Training Loss: 0.6034%\n",
      "Epoch [29/300], Step [7/225], Training Accuracy: 73.4375%, Training Loss: 0.6216%\n",
      "Epoch [29/300], Step [8/225], Training Accuracy: 71.6797%, Training Loss: 0.6564%\n",
      "Epoch [29/300], Step [9/225], Training Accuracy: 71.5278%, Training Loss: 0.6607%\n",
      "Epoch [29/300], Step [10/225], Training Accuracy: 71.0938%, Training Loss: 0.6740%\n",
      "Epoch [29/300], Step [11/225], Training Accuracy: 70.8807%, Training Loss: 0.6824%\n",
      "Epoch [29/300], Step [12/225], Training Accuracy: 70.8333%, Training Loss: 0.6816%\n",
      "Epoch [29/300], Step [13/225], Training Accuracy: 71.6346%, Training Loss: 0.6650%\n",
      "Epoch [29/300], Step [14/225], Training Accuracy: 71.6518%, Training Loss: 0.6697%\n",
      "Epoch [29/300], Step [15/225], Training Accuracy: 71.5625%, Training Loss: 0.6625%\n",
      "Epoch [29/300], Step [16/225], Training Accuracy: 70.7031%, Training Loss: 0.6681%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/300], Step [17/225], Training Accuracy: 71.1397%, Training Loss: 0.6611%\n",
      "Epoch [29/300], Step [18/225], Training Accuracy: 70.9201%, Training Loss: 0.6600%\n",
      "Epoch [29/300], Step [19/225], Training Accuracy: 71.3816%, Training Loss: 0.6522%\n",
      "Epoch [29/300], Step [20/225], Training Accuracy: 71.7969%, Training Loss: 0.6467%\n",
      "Epoch [29/300], Step [21/225], Training Accuracy: 71.8750%, Training Loss: 0.6425%\n",
      "Epoch [29/300], Step [22/225], Training Accuracy: 71.0227%, Training Loss: 0.6517%\n",
      "Epoch [29/300], Step [23/225], Training Accuracy: 71.1957%, Training Loss: 0.6505%\n",
      "Epoch [29/300], Step [24/225], Training Accuracy: 70.7682%, Training Loss: 0.6542%\n",
      "Epoch [29/300], Step [25/225], Training Accuracy: 71.0000%, Training Loss: 0.6507%\n",
      "Epoch [29/300], Step [26/225], Training Accuracy: 71.0337%, Training Loss: 0.6492%\n",
      "Epoch [29/300], Step [27/225], Training Accuracy: 71.0648%, Training Loss: 0.6514%\n",
      "Epoch [29/300], Step [28/225], Training Accuracy: 71.4286%, Training Loss: 0.6473%\n",
      "Epoch [29/300], Step [29/225], Training Accuracy: 71.5517%, Training Loss: 0.6432%\n",
      "Epoch [29/300], Step [30/225], Training Accuracy: 71.6667%, Training Loss: 0.6399%\n",
      "Epoch [29/300], Step [31/225], Training Accuracy: 71.4718%, Training Loss: 0.6420%\n",
      "Epoch [29/300], Step [32/225], Training Accuracy: 71.5820%, Training Loss: 0.6398%\n",
      "Epoch [29/300], Step [33/225], Training Accuracy: 71.7803%, Training Loss: 0.6378%\n",
      "Epoch [29/300], Step [34/225], Training Accuracy: 71.5074%, Training Loss: 0.6436%\n",
      "Epoch [29/300], Step [35/225], Training Accuracy: 71.4732%, Training Loss: 0.6435%\n",
      "Epoch [29/300], Step [36/225], Training Accuracy: 71.2674%, Training Loss: 0.6461%\n",
      "Epoch [29/300], Step [37/225], Training Accuracy: 71.0726%, Training Loss: 0.6453%\n",
      "Epoch [29/300], Step [38/225], Training Accuracy: 71.2171%, Training Loss: 0.6425%\n",
      "Epoch [29/300], Step [39/225], Training Accuracy: 71.5144%, Training Loss: 0.6415%\n",
      "Epoch [29/300], Step [40/225], Training Accuracy: 71.6797%, Training Loss: 0.6418%\n",
      "Epoch [29/300], Step [41/225], Training Accuracy: 71.4939%, Training Loss: 0.6465%\n",
      "Epoch [29/300], Step [42/225], Training Accuracy: 71.3542%, Training Loss: 0.6470%\n",
      "Epoch [29/300], Step [43/225], Training Accuracy: 71.1846%, Training Loss: 0.6476%\n",
      "Epoch [29/300], Step [44/225], Training Accuracy: 71.3423%, Training Loss: 0.6446%\n",
      "Epoch [29/300], Step [45/225], Training Accuracy: 71.2847%, Training Loss: 0.6458%\n",
      "Epoch [29/300], Step [46/225], Training Accuracy: 71.3315%, Training Loss: 0.6458%\n",
      "Epoch [29/300], Step [47/225], Training Accuracy: 71.1436%, Training Loss: 0.6473%\n",
      "Epoch [29/300], Step [48/225], Training Accuracy: 70.9310%, Training Loss: 0.6498%\n",
      "Epoch [29/300], Step [49/225], Training Accuracy: 71.0140%, Training Loss: 0.6490%\n",
      "Epoch [29/300], Step [50/225], Training Accuracy: 71.1562%, Training Loss: 0.6487%\n",
      "Epoch [29/300], Step [51/225], Training Accuracy: 71.3235%, Training Loss: 0.6459%\n",
      "Epoch [29/300], Step [52/225], Training Accuracy: 71.5745%, Training Loss: 0.6411%\n",
      "Epoch [29/300], Step [53/225], Training Accuracy: 71.5212%, Training Loss: 0.6425%\n",
      "Epoch [29/300], Step [54/225], Training Accuracy: 71.2095%, Training Loss: 0.6478%\n",
      "Epoch [29/300], Step [55/225], Training Accuracy: 71.1080%, Training Loss: 0.6506%\n",
      "Epoch [29/300], Step [56/225], Training Accuracy: 71.2612%, Training Loss: 0.6501%\n",
      "Epoch [29/300], Step [57/225], Training Accuracy: 71.1623%, Training Loss: 0.6496%\n",
      "Epoch [29/300], Step [58/225], Training Accuracy: 71.1207%, Training Loss: 0.6498%\n",
      "Epoch [29/300], Step [59/225], Training Accuracy: 71.0275%, Training Loss: 0.6507%\n",
      "Epoch [29/300], Step [60/225], Training Accuracy: 71.0417%, Training Loss: 0.6507%\n",
      "Epoch [29/300], Step [61/225], Training Accuracy: 70.9273%, Training Loss: 0.6509%\n",
      "Epoch [29/300], Step [62/225], Training Accuracy: 71.1190%, Training Loss: 0.6489%\n",
      "Epoch [29/300], Step [63/225], Training Accuracy: 71.2054%, Training Loss: 0.6475%\n",
      "Epoch [29/300], Step [64/225], Training Accuracy: 71.0938%, Training Loss: 0.6486%\n",
      "Epoch [29/300], Step [65/225], Training Accuracy: 71.2019%, Training Loss: 0.6475%\n",
      "Epoch [29/300], Step [66/225], Training Accuracy: 71.2121%, Training Loss: 0.6468%\n",
      "Epoch [29/300], Step [67/225], Training Accuracy: 71.1287%, Training Loss: 0.6489%\n",
      "Epoch [29/300], Step [68/225], Training Accuracy: 70.9789%, Training Loss: 0.6493%\n",
      "Epoch [29/300], Step [69/225], Training Accuracy: 71.0598%, Training Loss: 0.6485%\n",
      "Epoch [29/300], Step [70/225], Training Accuracy: 71.0491%, Training Loss: 0.6484%\n",
      "Epoch [29/300], Step [71/225], Training Accuracy: 71.0607%, Training Loss: 0.6470%\n",
      "Epoch [29/300], Step [72/225], Training Accuracy: 71.0069%, Training Loss: 0.6471%\n",
      "Epoch [29/300], Step [73/225], Training Accuracy: 71.0616%, Training Loss: 0.6463%\n",
      "Epoch [29/300], Step [74/225], Training Accuracy: 71.2416%, Training Loss: 0.6437%\n",
      "Epoch [29/300], Step [75/225], Training Accuracy: 71.2917%, Training Loss: 0.6424%\n",
      "Epoch [29/300], Step [76/225], Training Accuracy: 71.2171%, Training Loss: 0.6440%\n",
      "Epoch [29/300], Step [77/225], Training Accuracy: 71.1648%, Training Loss: 0.6440%\n",
      "Epoch [29/300], Step [78/225], Training Accuracy: 71.2540%, Training Loss: 0.6420%\n",
      "Epoch [29/300], Step [79/225], Training Accuracy: 71.4597%, Training Loss: 0.6398%\n",
      "Epoch [29/300], Step [80/225], Training Accuracy: 71.4062%, Training Loss: 0.6395%\n",
      "Epoch [29/300], Step [81/225], Training Accuracy: 71.4506%, Training Loss: 0.6398%\n",
      "Epoch [29/300], Step [82/225], Training Accuracy: 71.4748%, Training Loss: 0.6393%\n",
      "Epoch [29/300], Step [83/225], Training Accuracy: 71.3855%, Training Loss: 0.6411%\n",
      "Epoch [29/300], Step [84/225], Training Accuracy: 71.4472%, Training Loss: 0.6397%\n",
      "Epoch [29/300], Step [85/225], Training Accuracy: 71.4338%, Training Loss: 0.6390%\n",
      "Epoch [29/300], Step [86/225], Training Accuracy: 71.5116%, Training Loss: 0.6376%\n",
      "Epoch [29/300], Step [87/225], Training Accuracy: 71.5876%, Training Loss: 0.6368%\n",
      "Epoch [29/300], Step [88/225], Training Accuracy: 71.5732%, Training Loss: 0.6374%\n",
      "Epoch [29/300], Step [89/225], Training Accuracy: 71.5590%, Training Loss: 0.6386%\n",
      "Epoch [29/300], Step [90/225], Training Accuracy: 71.5278%, Training Loss: 0.6398%\n",
      "Epoch [29/300], Step [91/225], Training Accuracy: 71.5659%, Training Loss: 0.6391%\n",
      "Epoch [29/300], Step [92/225], Training Accuracy: 71.5353%, Training Loss: 0.6401%\n",
      "Epoch [29/300], Step [93/225], Training Accuracy: 71.5222%, Training Loss: 0.6406%\n",
      "Epoch [29/300], Step [94/225], Training Accuracy: 71.5592%, Training Loss: 0.6406%\n",
      "Epoch [29/300], Step [95/225], Training Accuracy: 71.5954%, Training Loss: 0.6407%\n",
      "Epoch [29/300], Step [96/225], Training Accuracy: 71.6146%, Training Loss: 0.6399%\n",
      "Epoch [29/300], Step [97/225], Training Accuracy: 71.6978%, Training Loss: 0.6391%\n",
      "Epoch [29/300], Step [98/225], Training Accuracy: 71.6677%, Training Loss: 0.6391%\n",
      "Epoch [29/300], Step [99/225], Training Accuracy: 71.7172%, Training Loss: 0.6392%\n",
      "Epoch [29/300], Step [100/225], Training Accuracy: 71.6094%, Training Loss: 0.6404%\n",
      "Epoch [29/300], Step [101/225], Training Accuracy: 71.5811%, Training Loss: 0.6410%\n",
      "Epoch [29/300], Step [102/225], Training Accuracy: 71.5533%, Training Loss: 0.6413%\n",
      "Epoch [29/300], Step [103/225], Training Accuracy: 71.6323%, Training Loss: 0.6399%\n",
      "Epoch [29/300], Step [104/225], Training Accuracy: 71.6496%, Training Loss: 0.6395%\n",
      "Epoch [29/300], Step [105/225], Training Accuracy: 71.6667%, Training Loss: 0.6387%\n",
      "Epoch [29/300], Step [106/225], Training Accuracy: 71.6834%, Training Loss: 0.6384%\n",
      "Epoch [29/300], Step [107/225], Training Accuracy: 71.6121%, Training Loss: 0.6401%\n",
      "Epoch [29/300], Step [108/225], Training Accuracy: 71.6291%, Training Loss: 0.6404%\n",
      "Epoch [29/300], Step [109/225], Training Accuracy: 71.6600%, Training Loss: 0.6396%\n",
      "Epoch [29/300], Step [110/225], Training Accuracy: 71.6335%, Training Loss: 0.6394%\n",
      "Epoch [29/300], Step [111/225], Training Accuracy: 71.6216%, Training Loss: 0.6398%\n",
      "Epoch [29/300], Step [112/225], Training Accuracy: 71.6099%, Training Loss: 0.6402%\n",
      "Epoch [29/300], Step [113/225], Training Accuracy: 71.6123%, Training Loss: 0.6396%\n",
      "Epoch [29/300], Step [114/225], Training Accuracy: 71.5872%, Training Loss: 0.6392%\n",
      "Epoch [29/300], Step [115/225], Training Accuracy: 71.6304%, Training Loss: 0.6387%\n",
      "Epoch [29/300], Step [116/225], Training Accuracy: 71.6864%, Training Loss: 0.6388%\n",
      "Epoch [29/300], Step [117/225], Training Accuracy: 71.5812%, Training Loss: 0.6405%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/300], Step [118/225], Training Accuracy: 71.6102%, Training Loss: 0.6406%\n",
      "Epoch [29/300], Step [119/225], Training Accuracy: 71.5993%, Training Loss: 0.6400%\n",
      "Epoch [29/300], Step [120/225], Training Accuracy: 71.5755%, Training Loss: 0.6409%\n",
      "Epoch [29/300], Step [121/225], Training Accuracy: 71.5780%, Training Loss: 0.6413%\n",
      "Epoch [29/300], Step [122/225], Training Accuracy: 71.5292%, Training Loss: 0.6416%\n",
      "Epoch [29/300], Step [123/225], Training Accuracy: 71.5447%, Training Loss: 0.6410%\n",
      "Epoch [29/300], Step [124/225], Training Accuracy: 71.5096%, Training Loss: 0.6415%\n",
      "Epoch [29/300], Step [125/225], Training Accuracy: 71.5250%, Training Loss: 0.6418%\n",
      "Epoch [29/300], Step [126/225], Training Accuracy: 71.5154%, Training Loss: 0.6416%\n",
      "Epoch [29/300], Step [127/225], Training Accuracy: 71.5182%, Training Loss: 0.6413%\n",
      "Epoch [29/300], Step [128/225], Training Accuracy: 71.5088%, Training Loss: 0.6418%\n",
      "Epoch [29/300], Step [129/225], Training Accuracy: 71.5359%, Training Loss: 0.6412%\n",
      "Epoch [29/300], Step [130/225], Training Accuracy: 71.5385%, Training Loss: 0.6416%\n",
      "Epoch [29/300], Step [131/225], Training Accuracy: 71.4933%, Training Loss: 0.6425%\n",
      "Epoch [29/300], Step [132/225], Training Accuracy: 71.4725%, Training Loss: 0.6429%\n",
      "Epoch [29/300], Step [133/225], Training Accuracy: 71.4521%, Training Loss: 0.6425%\n",
      "Epoch [29/300], Step [134/225], Training Accuracy: 71.3386%, Training Loss: 0.6443%\n",
      "Epoch [29/300], Step [135/225], Training Accuracy: 71.3310%, Training Loss: 0.6443%\n",
      "Epoch [29/300], Step [136/225], Training Accuracy: 71.3580%, Training Loss: 0.6434%\n",
      "Epoch [29/300], Step [137/225], Training Accuracy: 71.3276%, Training Loss: 0.6438%\n",
      "Epoch [29/300], Step [138/225], Training Accuracy: 71.4221%, Training Loss: 0.6419%\n",
      "Epoch [29/300], Step [139/225], Training Accuracy: 71.4703%, Training Loss: 0.6412%\n",
      "Epoch [29/300], Step [140/225], Training Accuracy: 71.4955%, Training Loss: 0.6408%\n",
      "Epoch [29/300], Step [141/225], Training Accuracy: 71.4871%, Training Loss: 0.6410%\n",
      "Epoch [29/300], Step [142/225], Training Accuracy: 71.4129%, Training Loss: 0.6421%\n",
      "Epoch [29/300], Step [143/225], Training Accuracy: 71.4270%, Training Loss: 0.6428%\n",
      "Epoch [29/300], Step [144/225], Training Accuracy: 71.3976%, Training Loss: 0.6429%\n",
      "Epoch [29/300], Step [145/225], Training Accuracy: 71.3901%, Training Loss: 0.6425%\n",
      "Epoch [29/300], Step [146/225], Training Accuracy: 71.3827%, Training Loss: 0.6430%\n",
      "Epoch [29/300], Step [147/225], Training Accuracy: 71.4179%, Training Loss: 0.6432%\n",
      "Epoch [29/300], Step [148/225], Training Accuracy: 71.4844%, Training Loss: 0.6419%\n",
      "Epoch [29/300], Step [149/225], Training Accuracy: 71.4975%, Training Loss: 0.6417%\n",
      "Epoch [29/300], Step [150/225], Training Accuracy: 71.5312%, Training Loss: 0.6413%\n",
      "Epoch [29/300], Step [151/225], Training Accuracy: 71.5232%, Training Loss: 0.6420%\n",
      "Epoch [29/300], Step [152/225], Training Accuracy: 71.4947%, Training Loss: 0.6418%\n",
      "Epoch [29/300], Step [153/225], Training Accuracy: 71.4869%, Training Loss: 0.6423%\n",
      "Epoch [29/300], Step [154/225], Training Accuracy: 71.4894%, Training Loss: 0.6421%\n",
      "Epoch [29/300], Step [155/225], Training Accuracy: 71.5020%, Training Loss: 0.6420%\n",
      "Epoch [29/300], Step [156/225], Training Accuracy: 71.4543%, Training Loss: 0.6431%\n",
      "Epoch [29/300], Step [157/225], Training Accuracy: 71.4968%, Training Loss: 0.6427%\n",
      "Epoch [29/300], Step [158/225], Training Accuracy: 71.4399%, Training Loss: 0.6437%\n",
      "Epoch [29/300], Step [159/225], Training Accuracy: 71.4426%, Training Loss: 0.6433%\n",
      "Epoch [29/300], Step [160/225], Training Accuracy: 71.4453%, Training Loss: 0.6437%\n",
      "Epoch [29/300], Step [161/225], Training Accuracy: 71.3898%, Training Loss: 0.6441%\n",
      "Epoch [29/300], Step [162/225], Training Accuracy: 71.3542%, Training Loss: 0.6449%\n",
      "Epoch [29/300], Step [163/225], Training Accuracy: 71.2998%, Training Loss: 0.6454%\n",
      "Epoch [29/300], Step [164/225], Training Accuracy: 71.3605%, Training Loss: 0.6443%\n",
      "Epoch [29/300], Step [165/225], Training Accuracy: 71.3258%, Training Loss: 0.6454%\n",
      "Epoch [29/300], Step [166/225], Training Accuracy: 71.3102%, Training Loss: 0.6453%\n",
      "Epoch [29/300], Step [167/225], Training Accuracy: 71.2949%, Training Loss: 0.6452%\n",
      "Epoch [29/300], Step [168/225], Training Accuracy: 71.2333%, Training Loss: 0.6459%\n",
      "Epoch [29/300], Step [169/225], Training Accuracy: 71.2833%, Training Loss: 0.6452%\n",
      "Epoch [29/300], Step [170/225], Training Accuracy: 71.2960%, Training Loss: 0.6453%\n",
      "Epoch [29/300], Step [171/225], Training Accuracy: 71.2993%, Training Loss: 0.6452%\n",
      "Epoch [29/300], Step [172/225], Training Accuracy: 71.2028%, Training Loss: 0.6467%\n",
      "Epoch [29/300], Step [173/225], Training Accuracy: 71.2247%, Training Loss: 0.6468%\n",
      "Epoch [29/300], Step [174/225], Training Accuracy: 71.2554%, Training Loss: 0.6463%\n",
      "Epoch [29/300], Step [175/225], Training Accuracy: 71.2857%, Training Loss: 0.6461%\n",
      "Epoch [29/300], Step [176/225], Training Accuracy: 71.2802%, Training Loss: 0.6467%\n",
      "Epoch [29/300], Step [177/225], Training Accuracy: 71.2924%, Training Loss: 0.6462%\n",
      "Epoch [29/300], Step [178/225], Training Accuracy: 71.3132%, Training Loss: 0.6459%\n",
      "Epoch [29/300], Step [179/225], Training Accuracy: 71.3862%, Training Loss: 0.6451%\n",
      "Epoch [29/300], Step [180/225], Training Accuracy: 71.4497%, Training Loss: 0.6444%\n",
      "Epoch [29/300], Step [181/225], Training Accuracy: 71.5038%, Training Loss: 0.6438%\n",
      "Epoch [29/300], Step [182/225], Training Accuracy: 71.4973%, Training Loss: 0.6443%\n",
      "Epoch [29/300], Step [183/225], Training Accuracy: 71.4737%, Training Loss: 0.6444%\n",
      "Epoch [29/300], Step [184/225], Training Accuracy: 71.4759%, Training Loss: 0.6446%\n",
      "Epoch [29/300], Step [185/225], Training Accuracy: 71.4865%, Training Loss: 0.6444%\n",
      "Epoch [29/300], Step [186/225], Training Accuracy: 71.5306%, Training Loss: 0.6435%\n",
      "Epoch [29/300], Step [187/225], Training Accuracy: 71.5241%, Training Loss: 0.6431%\n",
      "Epoch [29/300], Step [188/225], Training Accuracy: 71.5841%, Training Loss: 0.6418%\n",
      "Epoch [29/300], Step [189/225], Training Accuracy: 71.5939%, Training Loss: 0.6416%\n",
      "Epoch [29/300], Step [190/225], Training Accuracy: 71.6201%, Training Loss: 0.6415%\n",
      "Epoch [29/300], Step [191/225], Training Accuracy: 71.6050%, Training Loss: 0.6414%\n",
      "Epoch [29/300], Step [192/225], Training Accuracy: 71.6553%, Training Loss: 0.6409%\n",
      "Epoch [29/300], Step [193/225], Training Accuracy: 71.6564%, Training Loss: 0.6409%\n",
      "Epoch [29/300], Step [194/225], Training Accuracy: 71.6334%, Training Loss: 0.6412%\n",
      "Epoch [29/300], Step [195/225], Training Accuracy: 71.6747%, Training Loss: 0.6405%\n",
      "Epoch [29/300], Step [196/225], Training Accuracy: 71.6438%, Training Loss: 0.6412%\n",
      "Epoch [29/300], Step [197/225], Training Accuracy: 71.6450%, Training Loss: 0.6414%\n",
      "Epoch [29/300], Step [198/225], Training Accuracy: 71.6304%, Training Loss: 0.6414%\n",
      "Epoch [29/300], Step [199/225], Training Accuracy: 71.6709%, Training Loss: 0.6404%\n",
      "Epoch [29/300], Step [200/225], Training Accuracy: 71.6484%, Training Loss: 0.6412%\n",
      "Epoch [29/300], Step [201/225], Training Accuracy: 71.6340%, Training Loss: 0.6417%\n",
      "Epoch [29/300], Step [202/225], Training Accuracy: 71.6197%, Training Loss: 0.6415%\n",
      "Epoch [29/300], Step [203/225], Training Accuracy: 71.6672%, Training Loss: 0.6406%\n",
      "Epoch [29/300], Step [204/225], Training Accuracy: 71.7065%, Training Loss: 0.6402%\n",
      "Epoch [29/300], Step [205/225], Training Accuracy: 71.7073%, Training Loss: 0.6400%\n",
      "Epoch [29/300], Step [206/225], Training Accuracy: 71.7233%, Training Loss: 0.6405%\n",
      "Epoch [29/300], Step [207/225], Training Accuracy: 71.7467%, Training Loss: 0.6403%\n",
      "Epoch [29/300], Step [208/225], Training Accuracy: 71.7999%, Training Loss: 0.6394%\n",
      "Epoch [29/300], Step [209/225], Training Accuracy: 71.8002%, Training Loss: 0.6395%\n",
      "Epoch [29/300], Step [210/225], Training Accuracy: 71.7560%, Training Loss: 0.6398%\n",
      "Epoch [29/300], Step [211/225], Training Accuracy: 71.7787%, Training Loss: 0.6395%\n",
      "Epoch [29/300], Step [212/225], Training Accuracy: 71.7866%, Training Loss: 0.6396%\n",
      "Epoch [29/300], Step [213/225], Training Accuracy: 71.8016%, Training Loss: 0.6396%\n",
      "Epoch [29/300], Step [214/225], Training Accuracy: 71.7947%, Training Loss: 0.6394%\n",
      "Epoch [29/300], Step [215/225], Training Accuracy: 71.8023%, Training Loss: 0.6393%\n",
      "Epoch [29/300], Step [216/225], Training Accuracy: 71.8244%, Training Loss: 0.6391%\n",
      "Epoch [29/300], Step [217/225], Training Accuracy: 71.7958%, Training Loss: 0.6393%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/300], Step [218/225], Training Accuracy: 71.7818%, Training Loss: 0.6396%\n",
      "Epoch [29/300], Step [219/225], Training Accuracy: 71.7822%, Training Loss: 0.6395%\n",
      "Epoch [29/300], Step [220/225], Training Accuracy: 71.7756%, Training Loss: 0.6390%\n",
      "Epoch [29/300], Step [221/225], Training Accuracy: 71.8326%, Training Loss: 0.6386%\n",
      "Epoch [29/300], Step [222/225], Training Accuracy: 71.8468%, Training Loss: 0.6384%\n",
      "Epoch [29/300], Step [223/225], Training Accuracy: 71.8330%, Training Loss: 0.6386%\n",
      "Epoch [29/300], Step [224/225], Training Accuracy: 71.8471%, Training Loss: 0.6385%\n",
      "Epoch [29/300], Step [225/225], Training Accuracy: 71.8038%, Training Loss: 0.6386%\n",
      "Epoch [30/300], Step [1/225], Training Accuracy: 76.5625%, Training Loss: 0.5054%\n",
      "Epoch [30/300], Step [2/225], Training Accuracy: 76.5625%, Training Loss: 0.5650%\n",
      "Epoch [30/300], Step [3/225], Training Accuracy: 71.3542%, Training Loss: 0.6536%\n",
      "Epoch [30/300], Step [4/225], Training Accuracy: 69.9219%, Training Loss: 0.6536%\n",
      "Epoch [30/300], Step [5/225], Training Accuracy: 72.5000%, Training Loss: 0.6310%\n",
      "Epoch [30/300], Step [6/225], Training Accuracy: 73.4375%, Training Loss: 0.6144%\n",
      "Epoch [30/300], Step [7/225], Training Accuracy: 72.5446%, Training Loss: 0.6158%\n",
      "Epoch [30/300], Step [8/225], Training Accuracy: 71.4844%, Training Loss: 0.6420%\n",
      "Epoch [30/300], Step [9/225], Training Accuracy: 71.5278%, Training Loss: 0.6373%\n",
      "Epoch [30/300], Step [10/225], Training Accuracy: 71.0938%, Training Loss: 0.6532%\n",
      "Epoch [30/300], Step [11/225], Training Accuracy: 72.0170%, Training Loss: 0.6507%\n",
      "Epoch [30/300], Step [12/225], Training Accuracy: 72.3958%, Training Loss: 0.6428%\n",
      "Epoch [30/300], Step [13/225], Training Accuracy: 72.7163%, Training Loss: 0.6308%\n",
      "Epoch [30/300], Step [14/225], Training Accuracy: 72.7679%, Training Loss: 0.6327%\n",
      "Epoch [30/300], Step [15/225], Training Accuracy: 72.3958%, Training Loss: 0.6367%\n",
      "Epoch [30/300], Step [16/225], Training Accuracy: 71.6797%, Training Loss: 0.6446%\n",
      "Epoch [30/300], Step [17/225], Training Accuracy: 71.5993%, Training Loss: 0.6426%\n",
      "Epoch [30/300], Step [18/225], Training Accuracy: 71.6146%, Training Loss: 0.6392%\n",
      "Epoch [30/300], Step [19/225], Training Accuracy: 71.7105%, Training Loss: 0.6405%\n",
      "Epoch [30/300], Step [20/225], Training Accuracy: 71.7969%, Training Loss: 0.6376%\n",
      "Epoch [30/300], Step [21/225], Training Accuracy: 71.5030%, Training Loss: 0.6378%\n",
      "Epoch [30/300], Step [22/225], Training Accuracy: 71.0227%, Training Loss: 0.6410%\n",
      "Epoch [30/300], Step [23/225], Training Accuracy: 71.1277%, Training Loss: 0.6410%\n",
      "Epoch [30/300], Step [24/225], Training Accuracy: 71.0286%, Training Loss: 0.6421%\n",
      "Epoch [30/300], Step [25/225], Training Accuracy: 71.0000%, Training Loss: 0.6389%\n",
      "Epoch [30/300], Step [26/225], Training Accuracy: 71.2139%, Training Loss: 0.6355%\n",
      "Epoch [30/300], Step [27/225], Training Accuracy: 71.0069%, Training Loss: 0.6403%\n",
      "Epoch [30/300], Step [28/225], Training Accuracy: 71.0379%, Training Loss: 0.6360%\n",
      "Epoch [30/300], Step [29/225], Training Accuracy: 71.1746%, Training Loss: 0.6347%\n",
      "Epoch [30/300], Step [30/225], Training Accuracy: 71.3542%, Training Loss: 0.6336%\n",
      "Epoch [30/300], Step [31/225], Training Accuracy: 71.2198%, Training Loss: 0.6386%\n",
      "Epoch [30/300], Step [32/225], Training Accuracy: 71.5332%, Training Loss: 0.6333%\n",
      "Epoch [30/300], Step [33/225], Training Accuracy: 71.6383%, Training Loss: 0.6313%\n",
      "Epoch [30/300], Step [34/225], Training Accuracy: 71.4614%, Training Loss: 0.6363%\n",
      "Epoch [30/300], Step [35/225], Training Accuracy: 71.4286%, Training Loss: 0.6378%\n",
      "Epoch [30/300], Step [36/225], Training Accuracy: 71.1372%, Training Loss: 0.6425%\n",
      "Epoch [30/300], Step [37/225], Training Accuracy: 71.1571%, Training Loss: 0.6400%\n",
      "Epoch [30/300], Step [38/225], Training Accuracy: 71.1349%, Training Loss: 0.6385%\n",
      "Epoch [30/300], Step [39/225], Training Accuracy: 71.0737%, Training Loss: 0.6389%\n",
      "Epoch [30/300], Step [40/225], Training Accuracy: 71.1719%, Training Loss: 0.6373%\n",
      "Epoch [30/300], Step [41/225], Training Accuracy: 70.9223%, Training Loss: 0.6417%\n",
      "Epoch [30/300], Step [42/225], Training Accuracy: 70.7961%, Training Loss: 0.6434%\n",
      "Epoch [30/300], Step [43/225], Training Accuracy: 70.8576%, Training Loss: 0.6416%\n",
      "Epoch [30/300], Step [44/225], Training Accuracy: 70.9162%, Training Loss: 0.6401%\n",
      "Epoch [30/300], Step [45/225], Training Accuracy: 70.9722%, Training Loss: 0.6390%\n",
      "Epoch [30/300], Step [46/225], Training Accuracy: 70.9918%, Training Loss: 0.6391%\n",
      "Epoch [30/300], Step [47/225], Training Accuracy: 71.0106%, Training Loss: 0.6396%\n",
      "Epoch [30/300], Step [48/225], Training Accuracy: 70.8659%, Training Loss: 0.6413%\n",
      "Epoch [30/300], Step [49/225], Training Accuracy: 70.9821%, Training Loss: 0.6404%\n",
      "Epoch [30/300], Step [50/225], Training Accuracy: 71.0625%, Training Loss: 0.6400%\n",
      "Epoch [30/300], Step [51/225], Training Accuracy: 71.2010%, Training Loss: 0.6360%\n",
      "Epoch [30/300], Step [52/225], Training Accuracy: 71.3642%, Training Loss: 0.6331%\n",
      "Epoch [30/300], Step [53/225], Training Accuracy: 71.4033%, Training Loss: 0.6323%\n",
      "Epoch [30/300], Step [54/225], Training Accuracy: 71.2674%, Training Loss: 0.6344%\n",
      "Epoch [30/300], Step [55/225], Training Accuracy: 71.2500%, Training Loss: 0.6357%\n",
      "Epoch [30/300], Step [56/225], Training Accuracy: 71.2891%, Training Loss: 0.6351%\n",
      "Epoch [30/300], Step [57/225], Training Accuracy: 71.2445%, Training Loss: 0.6345%\n",
      "Epoch [30/300], Step [58/225], Training Accuracy: 71.3093%, Training Loss: 0.6322%\n",
      "Epoch [30/300], Step [59/225], Training Accuracy: 71.3189%, Training Loss: 0.6339%\n",
      "Epoch [30/300], Step [60/225], Training Accuracy: 71.3021%, Training Loss: 0.6348%\n",
      "Epoch [30/300], Step [61/225], Training Accuracy: 71.2602%, Training Loss: 0.6363%\n",
      "Epoch [30/300], Step [62/225], Training Accuracy: 71.3962%, Training Loss: 0.6341%\n",
      "Epoch [30/300], Step [63/225], Training Accuracy: 71.5526%, Training Loss: 0.6334%\n",
      "Epoch [30/300], Step [64/225], Training Accuracy: 71.4600%, Training Loss: 0.6342%\n",
      "Epoch [30/300], Step [65/225], Training Accuracy: 71.5625%, Training Loss: 0.6335%\n",
      "Epoch [30/300], Step [66/225], Training Accuracy: 71.7330%, Training Loss: 0.6303%\n",
      "Epoch [30/300], Step [67/225], Training Accuracy: 71.6651%, Training Loss: 0.6299%\n",
      "Epoch [30/300], Step [68/225], Training Accuracy: 71.7142%, Training Loss: 0.6300%\n",
      "Epoch [30/300], Step [69/225], Training Accuracy: 71.7391%, Training Loss: 0.6296%\n",
      "Epoch [30/300], Step [70/225], Training Accuracy: 71.7188%, Training Loss: 0.6295%\n",
      "Epoch [30/300], Step [71/225], Training Accuracy: 71.7210%, Training Loss: 0.6283%\n",
      "Epoch [30/300], Step [72/225], Training Accuracy: 71.7882%, Training Loss: 0.6278%\n",
      "Epoch [30/300], Step [73/225], Training Accuracy: 71.7680%, Training Loss: 0.6271%\n",
      "Epoch [30/300], Step [74/225], Training Accuracy: 71.9172%, Training Loss: 0.6251%\n",
      "Epoch [30/300], Step [75/225], Training Accuracy: 71.8333%, Training Loss: 0.6255%\n",
      "Epoch [30/300], Step [76/225], Training Accuracy: 71.7516%, Training Loss: 0.6262%\n",
      "Epoch [30/300], Step [77/225], Training Accuracy: 71.7532%, Training Loss: 0.6264%\n",
      "Epoch [30/300], Step [78/225], Training Accuracy: 71.7548%, Training Loss: 0.6260%\n",
      "Epoch [30/300], Step [79/225], Training Accuracy: 71.9146%, Training Loss: 0.6244%\n",
      "Epoch [30/300], Step [80/225], Training Accuracy: 71.8945%, Training Loss: 0.6241%\n",
      "Epoch [30/300], Step [81/225], Training Accuracy: 71.9907%, Training Loss: 0.6238%\n",
      "Epoch [30/300], Step [82/225], Training Accuracy: 72.0465%, Training Loss: 0.6242%\n",
      "Epoch [30/300], Step [83/225], Training Accuracy: 72.0256%, Training Loss: 0.6253%\n",
      "Epoch [30/300], Step [84/225], Training Accuracy: 72.0610%, Training Loss: 0.6242%\n",
      "Epoch [30/300], Step [85/225], Training Accuracy: 72.0588%, Training Loss: 0.6232%\n",
      "Epoch [30/300], Step [86/225], Training Accuracy: 72.0567%, Training Loss: 0.6231%\n",
      "Epoch [30/300], Step [87/225], Training Accuracy: 71.9468%, Training Loss: 0.6240%\n",
      "Epoch [30/300], Step [88/225], Training Accuracy: 71.8572%, Training Loss: 0.6256%\n",
      "Epoch [30/300], Step [89/225], Training Accuracy: 71.7697%, Training Loss: 0.6273%\n",
      "Epoch [30/300], Step [90/225], Training Accuracy: 71.7188%, Training Loss: 0.6279%\n",
      "Epoch [30/300], Step [91/225], Training Accuracy: 71.7720%, Training Loss: 0.6270%\n",
      "Epoch [30/300], Step [92/225], Training Accuracy: 71.7561%, Training Loss: 0.6278%\n",
      "Epoch [30/300], Step [93/225], Training Accuracy: 71.8078%, Training Loss: 0.6269%\n",
      "Epoch [30/300], Step [94/225], Training Accuracy: 71.8085%, Training Loss: 0.6269%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/300], Step [95/225], Training Accuracy: 71.7434%, Training Loss: 0.6293%\n",
      "Epoch [30/300], Step [96/225], Training Accuracy: 71.7773%, Training Loss: 0.6284%\n",
      "Epoch [30/300], Step [97/225], Training Accuracy: 71.8106%, Training Loss: 0.6282%\n",
      "Epoch [30/300], Step [98/225], Training Accuracy: 71.8591%, Training Loss: 0.6290%\n",
      "Epoch [30/300], Step [99/225], Training Accuracy: 71.9066%, Training Loss: 0.6293%\n",
      "Epoch [30/300], Step [100/225], Training Accuracy: 71.8281%, Training Loss: 0.6302%\n",
      "Epoch [30/300], Step [101/225], Training Accuracy: 71.8441%, Training Loss: 0.6295%\n",
      "Epoch [30/300], Step [102/225], Training Accuracy: 71.7831%, Training Loss: 0.6302%\n",
      "Epoch [30/300], Step [103/225], Training Accuracy: 71.7992%, Training Loss: 0.6294%\n",
      "Epoch [30/300], Step [104/225], Training Accuracy: 71.8149%, Training Loss: 0.6298%\n",
      "Epoch [30/300], Step [105/225], Training Accuracy: 71.8601%, Training Loss: 0.6283%\n",
      "Epoch [30/300], Step [106/225], Training Accuracy: 71.7866%, Training Loss: 0.6289%\n",
      "Epoch [30/300], Step [107/225], Training Accuracy: 71.7728%, Training Loss: 0.6297%\n",
      "Epoch [30/300], Step [108/225], Training Accuracy: 71.8316%, Training Loss: 0.6298%\n",
      "Epoch [30/300], Step [109/225], Training Accuracy: 71.8177%, Training Loss: 0.6294%\n",
      "Epoch [30/300], Step [110/225], Training Accuracy: 71.8750%, Training Loss: 0.6286%\n",
      "Epoch [30/300], Step [111/225], Training Accuracy: 71.8468%, Training Loss: 0.6306%\n",
      "Epoch [30/300], Step [112/225], Training Accuracy: 71.8331%, Training Loss: 0.6317%\n",
      "Epoch [30/300], Step [113/225], Training Accuracy: 71.8197%, Training Loss: 0.6316%\n",
      "Epoch [30/300], Step [114/225], Training Accuracy: 71.8202%, Training Loss: 0.6315%\n",
      "Epoch [30/300], Step [115/225], Training Accuracy: 71.9158%, Training Loss: 0.6302%\n",
      "Epoch [30/300], Step [116/225], Training Accuracy: 71.9558%, Training Loss: 0.6296%\n",
      "Epoch [30/300], Step [117/225], Training Accuracy: 71.7815%, Training Loss: 0.6313%\n",
      "Epoch [30/300], Step [118/225], Training Accuracy: 71.7558%, Training Loss: 0.6307%\n",
      "Epoch [30/300], Step [119/225], Training Accuracy: 71.7568%, Training Loss: 0.6304%\n",
      "Epoch [30/300], Step [120/225], Training Accuracy: 71.7188%, Training Loss: 0.6310%\n",
      "Epoch [30/300], Step [121/225], Training Accuracy: 71.7459%, Training Loss: 0.6304%\n",
      "Epoch [30/300], Step [122/225], Training Accuracy: 71.6957%, Training Loss: 0.6313%\n",
      "Epoch [30/300], Step [123/225], Training Accuracy: 71.6972%, Training Loss: 0.6313%\n",
      "Epoch [30/300], Step [124/225], Training Accuracy: 71.6860%, Training Loss: 0.6321%\n",
      "Epoch [30/300], Step [125/225], Training Accuracy: 71.7000%, Training Loss: 0.6322%\n",
      "Epoch [30/300], Step [126/225], Training Accuracy: 71.6642%, Training Loss: 0.6337%\n",
      "Epoch [30/300], Step [127/225], Training Accuracy: 71.6658%, Training Loss: 0.6340%\n",
      "Epoch [30/300], Step [128/225], Training Accuracy: 71.6919%, Training Loss: 0.6340%\n",
      "Epoch [30/300], Step [129/225], Training Accuracy: 71.6812%, Training Loss: 0.6343%\n",
      "Epoch [30/300], Step [130/225], Training Accuracy: 71.6587%, Training Loss: 0.6364%\n",
      "Epoch [30/300], Step [131/225], Training Accuracy: 71.6126%, Training Loss: 0.6376%\n",
      "Epoch [30/300], Step [132/225], Training Accuracy: 71.5317%, Training Loss: 0.6388%\n",
      "Epoch [30/300], Step [133/225], Training Accuracy: 71.5108%, Training Loss: 0.6388%\n",
      "Epoch [30/300], Step [134/225], Training Accuracy: 71.3853%, Training Loss: 0.6402%\n",
      "Epoch [30/300], Step [135/225], Training Accuracy: 71.4583%, Training Loss: 0.6397%\n",
      "Epoch [30/300], Step [136/225], Training Accuracy: 71.4499%, Training Loss: 0.6399%\n",
      "Epoch [30/300], Step [137/225], Training Accuracy: 71.4416%, Training Loss: 0.6398%\n",
      "Epoch [30/300], Step [138/225], Training Accuracy: 71.5466%, Training Loss: 0.6388%\n",
      "Epoch [30/300], Step [139/225], Training Accuracy: 71.5153%, Training Loss: 0.6391%\n",
      "Epoch [30/300], Step [140/225], Training Accuracy: 71.5513%, Training Loss: 0.6385%\n",
      "Epoch [30/300], Step [141/225], Training Accuracy: 71.5758%, Training Loss: 0.6378%\n",
      "Epoch [30/300], Step [142/225], Training Accuracy: 71.5449%, Training Loss: 0.6384%\n",
      "Epoch [30/300], Step [143/225], Training Accuracy: 71.5581%, Training Loss: 0.6383%\n",
      "Epoch [30/300], Step [144/225], Training Accuracy: 71.5820%, Training Loss: 0.6377%\n",
      "Epoch [30/300], Step [145/225], Training Accuracy: 71.5086%, Training Loss: 0.6377%\n",
      "Epoch [30/300], Step [146/225], Training Accuracy: 71.4897%, Training Loss: 0.6386%\n",
      "Epoch [30/300], Step [147/225], Training Accuracy: 71.4923%, Training Loss: 0.6392%\n",
      "Epoch [30/300], Step [148/225], Training Accuracy: 71.5266%, Training Loss: 0.6392%\n",
      "Epoch [30/300], Step [149/225], Training Accuracy: 71.5499%, Training Loss: 0.6389%\n",
      "Epoch [30/300], Step [150/225], Training Accuracy: 71.5938%, Training Loss: 0.6382%\n",
      "Epoch [30/300], Step [151/225], Training Accuracy: 71.6163%, Training Loss: 0.6373%\n",
      "Epoch [30/300], Step [152/225], Training Accuracy: 71.6386%, Training Loss: 0.6372%\n",
      "Epoch [30/300], Step [153/225], Training Accuracy: 71.5788%, Training Loss: 0.6374%\n",
      "Epoch [30/300], Step [154/225], Training Accuracy: 71.5808%, Training Loss: 0.6370%\n",
      "Epoch [30/300], Step [155/225], Training Accuracy: 71.5726%, Training Loss: 0.6371%\n",
      "Epoch [30/300], Step [156/225], Training Accuracy: 71.5345%, Training Loss: 0.6373%\n",
      "Epoch [30/300], Step [157/225], Training Accuracy: 71.5665%, Training Loss: 0.6367%\n",
      "Epoch [30/300], Step [158/225], Training Accuracy: 71.5487%, Training Loss: 0.6373%\n",
      "Epoch [30/300], Step [159/225], Training Accuracy: 71.5507%, Training Loss: 0.6366%\n",
      "Epoch [30/300], Step [160/225], Training Accuracy: 71.5527%, Training Loss: 0.6361%\n",
      "Epoch [30/300], Step [161/225], Training Accuracy: 71.5159%, Training Loss: 0.6368%\n",
      "Epoch [30/300], Step [162/225], Training Accuracy: 71.5760%, Training Loss: 0.6361%\n",
      "Epoch [30/300], Step [163/225], Training Accuracy: 71.5970%, Training Loss: 0.6360%\n",
      "Epoch [30/300], Step [164/225], Training Accuracy: 71.6178%, Training Loss: 0.6357%\n",
      "Epoch [30/300], Step [165/225], Training Accuracy: 71.5814%, Training Loss: 0.6360%\n",
      "Epoch [30/300], Step [166/225], Training Accuracy: 71.6020%, Training Loss: 0.6357%\n",
      "Epoch [30/300], Step [167/225], Training Accuracy: 71.6224%, Training Loss: 0.6352%\n",
      "Epoch [30/300], Step [168/225], Training Accuracy: 71.5588%, Training Loss: 0.6362%\n",
      "Epoch [30/300], Step [169/225], Training Accuracy: 71.5791%, Training Loss: 0.6358%\n",
      "Epoch [30/300], Step [170/225], Training Accuracy: 71.5993%, Training Loss: 0.6359%\n",
      "Epoch [30/300], Step [171/225], Training Accuracy: 71.6009%, Training Loss: 0.6360%\n",
      "Epoch [30/300], Step [172/225], Training Accuracy: 71.5843%, Training Loss: 0.6362%\n",
      "Epoch [30/300], Step [173/225], Training Accuracy: 71.5408%, Training Loss: 0.6370%\n",
      "Epoch [30/300], Step [174/225], Training Accuracy: 71.5787%, Training Loss: 0.6368%\n",
      "Epoch [30/300], Step [175/225], Training Accuracy: 71.5982%, Training Loss: 0.6365%\n",
      "Epoch [30/300], Step [176/225], Training Accuracy: 71.5732%, Training Loss: 0.6365%\n",
      "Epoch [30/300], Step [177/225], Training Accuracy: 71.5395%, Training Loss: 0.6368%\n",
      "Epoch [30/300], Step [178/225], Training Accuracy: 71.5239%, Training Loss: 0.6374%\n",
      "Epoch [30/300], Step [179/225], Training Accuracy: 71.6044%, Training Loss: 0.6364%\n",
      "Epoch [30/300], Step [180/225], Training Accuracy: 71.6406%, Training Loss: 0.6356%\n",
      "Epoch [30/300], Step [181/225], Training Accuracy: 71.6333%, Training Loss: 0.6360%\n",
      "Epoch [30/300], Step [182/225], Training Accuracy: 71.6346%, Training Loss: 0.6363%\n",
      "Epoch [30/300], Step [183/225], Training Accuracy: 71.6189%, Training Loss: 0.6364%\n",
      "Epoch [30/300], Step [184/225], Training Accuracy: 71.6542%, Training Loss: 0.6360%\n",
      "Epoch [30/300], Step [185/225], Training Accuracy: 71.6554%, Training Loss: 0.6362%\n",
      "Epoch [30/300], Step [186/225], Training Accuracy: 71.6818%, Training Loss: 0.6354%\n",
      "Epoch [30/300], Step [187/225], Training Accuracy: 71.6828%, Training Loss: 0.6357%\n",
      "Epoch [30/300], Step [188/225], Training Accuracy: 71.6922%, Training Loss: 0.6352%\n",
      "Epoch [30/300], Step [189/225], Training Accuracy: 71.7097%, Training Loss: 0.6348%\n",
      "Epoch [30/300], Step [190/225], Training Accuracy: 71.7188%, Training Loss: 0.6345%\n",
      "Epoch [30/300], Step [191/225], Training Accuracy: 71.6950%, Training Loss: 0.6345%\n",
      "Epoch [30/300], Step [192/225], Training Accuracy: 71.7611%, Training Loss: 0.6339%\n",
      "Epoch [30/300], Step [193/225], Training Accuracy: 71.7859%, Training Loss: 0.6336%\n",
      "Epoch [30/300], Step [194/225], Training Accuracy: 71.7784%, Training Loss: 0.6335%\n",
      "Epoch [30/300], Step [195/225], Training Accuracy: 71.8109%, Training Loss: 0.6328%\n",
      "Epoch [30/300], Step [196/225], Training Accuracy: 71.8272%, Training Loss: 0.6327%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/300], Step [197/225], Training Accuracy: 71.8115%, Training Loss: 0.6326%\n",
      "Epoch [30/300], Step [198/225], Training Accuracy: 71.8040%, Training Loss: 0.6322%\n",
      "Epoch [30/300], Step [199/225], Training Accuracy: 71.7886%, Training Loss: 0.6319%\n",
      "Epoch [30/300], Step [200/225], Training Accuracy: 71.7734%, Training Loss: 0.6328%\n",
      "Epoch [30/300], Step [201/225], Training Accuracy: 71.7739%, Training Loss: 0.6329%\n",
      "Epoch [30/300], Step [202/225], Training Accuracy: 71.8131%, Training Loss: 0.6329%\n",
      "Epoch [30/300], Step [203/225], Training Accuracy: 71.8211%, Training Loss: 0.6329%\n",
      "Epoch [30/300], Step [204/225], Training Accuracy: 71.8137%, Training Loss: 0.6331%\n",
      "Epoch [30/300], Step [205/225], Training Accuracy: 71.8293%, Training Loss: 0.6327%\n",
      "Epoch [30/300], Step [206/225], Training Accuracy: 71.8295%, Training Loss: 0.6326%\n",
      "Epoch [30/300], Step [207/225], Training Accuracy: 71.8222%, Training Loss: 0.6330%\n",
      "Epoch [30/300], Step [208/225], Training Accuracy: 71.8750%, Training Loss: 0.6322%\n",
      "Epoch [30/300], Step [209/225], Training Accuracy: 71.8600%, Training Loss: 0.6324%\n",
      "Epoch [30/300], Step [210/225], Training Accuracy: 71.8378%, Training Loss: 0.6333%\n",
      "Epoch [30/300], Step [211/225], Training Accuracy: 71.8528%, Training Loss: 0.6329%\n",
      "Epoch [30/300], Step [212/225], Training Accuracy: 71.8455%, Training Loss: 0.6333%\n",
      "Epoch [30/300], Step [213/225], Training Accuracy: 71.7943%, Training Loss: 0.6342%\n",
      "Epoch [30/300], Step [214/225], Training Accuracy: 71.7655%, Training Loss: 0.6350%\n",
      "Epoch [30/300], Step [215/225], Training Accuracy: 71.7805%, Training Loss: 0.6349%\n",
      "Epoch [30/300], Step [216/225], Training Accuracy: 71.7593%, Training Loss: 0.6350%\n",
      "Epoch [30/300], Step [217/225], Training Accuracy: 71.7166%, Training Loss: 0.6354%\n",
      "Epoch [30/300], Step [218/225], Training Accuracy: 71.7173%, Training Loss: 0.6353%\n",
      "Epoch [30/300], Step [219/225], Training Accuracy: 71.7180%, Training Loss: 0.6356%\n",
      "Epoch [30/300], Step [220/225], Training Accuracy: 71.7045%, Training Loss: 0.6354%\n",
      "Epoch [30/300], Step [221/225], Training Accuracy: 71.6841%, Training Loss: 0.6363%\n",
      "Epoch [30/300], Step [222/225], Training Accuracy: 71.6990%, Training Loss: 0.6364%\n",
      "Epoch [30/300], Step [223/225], Training Accuracy: 71.6998%, Training Loss: 0.6367%\n",
      "Epoch [30/300], Step [224/225], Training Accuracy: 71.7146%, Training Loss: 0.6367%\n",
      "Epoch [30/300], Step [225/225], Training Accuracy: 71.6996%, Training Loss: 0.6367%\n",
      "Epoch [31/300], Step [1/225], Training Accuracy: 79.6875%, Training Loss: 0.5544%\n",
      "Epoch [31/300], Step [2/225], Training Accuracy: 77.3438%, Training Loss: 0.6210%\n",
      "Epoch [31/300], Step [3/225], Training Accuracy: 75.5208%, Training Loss: 0.6282%\n",
      "Epoch [31/300], Step [4/225], Training Accuracy: 75.3906%, Training Loss: 0.6344%\n",
      "Epoch [31/300], Step [5/225], Training Accuracy: 74.6875%, Training Loss: 0.6469%\n",
      "Epoch [31/300], Step [6/225], Training Accuracy: 75.2604%, Training Loss: 0.6300%\n",
      "Epoch [31/300], Step [7/225], Training Accuracy: 73.2143%, Training Loss: 0.6448%\n",
      "Epoch [31/300], Step [8/225], Training Accuracy: 71.6797%, Training Loss: 0.6742%\n",
      "Epoch [31/300], Step [9/225], Training Accuracy: 72.0486%, Training Loss: 0.6623%\n",
      "Epoch [31/300], Step [10/225], Training Accuracy: 71.7188%, Training Loss: 0.6754%\n",
      "Epoch [31/300], Step [11/225], Training Accuracy: 71.8750%, Training Loss: 0.6683%\n",
      "Epoch [31/300], Step [12/225], Training Accuracy: 72.2656%, Training Loss: 0.6558%\n",
      "Epoch [31/300], Step [13/225], Training Accuracy: 73.0769%, Training Loss: 0.6384%\n",
      "Epoch [31/300], Step [14/225], Training Accuracy: 72.6562%, Training Loss: 0.6344%\n",
      "Epoch [31/300], Step [15/225], Training Accuracy: 73.1250%, Training Loss: 0.6276%\n",
      "Epoch [31/300], Step [16/225], Training Accuracy: 72.2656%, Training Loss: 0.6439%\n",
      "Epoch [31/300], Step [17/225], Training Accuracy: 72.0588%, Training Loss: 0.6443%\n",
      "Epoch [31/300], Step [18/225], Training Accuracy: 72.2222%, Training Loss: 0.6379%\n",
      "Epoch [31/300], Step [19/225], Training Accuracy: 72.6974%, Training Loss: 0.6333%\n",
      "Epoch [31/300], Step [20/225], Training Accuracy: 72.5781%, Training Loss: 0.6319%\n",
      "Epoch [31/300], Step [21/225], Training Accuracy: 72.3214%, Training Loss: 0.6338%\n",
      "Epoch [31/300], Step [22/225], Training Accuracy: 71.8750%, Training Loss: 0.6398%\n",
      "Epoch [31/300], Step [23/225], Training Accuracy: 71.9429%, Training Loss: 0.6384%\n",
      "Epoch [31/300], Step [24/225], Training Accuracy: 71.7448%, Training Loss: 0.6397%\n",
      "Epoch [31/300], Step [25/225], Training Accuracy: 72.0000%, Training Loss: 0.6364%\n",
      "Epoch [31/300], Step [26/225], Training Accuracy: 71.9952%, Training Loss: 0.6353%\n",
      "Epoch [31/300], Step [27/225], Training Accuracy: 71.8750%, Training Loss: 0.6355%\n",
      "Epoch [31/300], Step [28/225], Training Accuracy: 72.1540%, Training Loss: 0.6310%\n",
      "Epoch [31/300], Step [29/225], Training Accuracy: 72.1983%, Training Loss: 0.6274%\n",
      "Epoch [31/300], Step [30/225], Training Accuracy: 72.2917%, Training Loss: 0.6247%\n",
      "Epoch [31/300], Step [31/225], Training Accuracy: 71.9758%, Training Loss: 0.6304%\n",
      "Epoch [31/300], Step [32/225], Training Accuracy: 72.1191%, Training Loss: 0.6259%\n",
      "Epoch [31/300], Step [33/225], Training Accuracy: 72.3485%, Training Loss: 0.6231%\n",
      "Epoch [31/300], Step [34/225], Training Accuracy: 72.1048%, Training Loss: 0.6299%\n",
      "Epoch [31/300], Step [35/225], Training Accuracy: 71.8750%, Training Loss: 0.6333%\n",
      "Epoch [31/300], Step [36/225], Training Accuracy: 71.5278%, Training Loss: 0.6411%\n",
      "Epoch [31/300], Step [37/225], Training Accuracy: 71.5794%, Training Loss: 0.6399%\n",
      "Epoch [31/300], Step [38/225], Training Accuracy: 71.7105%, Training Loss: 0.6379%\n",
      "Epoch [31/300], Step [39/225], Training Accuracy: 71.5545%, Training Loss: 0.6415%\n",
      "Epoch [31/300], Step [40/225], Training Accuracy: 71.6406%, Training Loss: 0.6400%\n",
      "Epoch [31/300], Step [41/225], Training Accuracy: 71.5320%, Training Loss: 0.6408%\n",
      "Epoch [31/300], Step [42/225], Training Accuracy: 71.4286%, Training Loss: 0.6408%\n",
      "Epoch [31/300], Step [43/225], Training Accuracy: 71.5116%, Training Loss: 0.6420%\n",
      "Epoch [31/300], Step [44/225], Training Accuracy: 71.5199%, Training Loss: 0.6414%\n",
      "Epoch [31/300], Step [45/225], Training Accuracy: 71.6319%, Training Loss: 0.6422%\n",
      "Epoch [31/300], Step [46/225], Training Accuracy: 71.8071%, Training Loss: 0.6392%\n",
      "Epoch [31/300], Step [47/225], Training Accuracy: 71.7088%, Training Loss: 0.6394%\n",
      "Epoch [31/300], Step [48/225], Training Accuracy: 71.7448%, Training Loss: 0.6380%\n",
      "Epoch [31/300], Step [49/225], Training Accuracy: 71.9707%, Training Loss: 0.6346%\n",
      "Epoch [31/300], Step [50/225], Training Accuracy: 72.0000%, Training Loss: 0.6351%\n",
      "Epoch [31/300], Step [51/225], Training Accuracy: 72.2426%, Training Loss: 0.6313%\n",
      "Epoch [31/300], Step [52/225], Training Accuracy: 72.3558%, Training Loss: 0.6285%\n",
      "Epoch [31/300], Step [53/225], Training Accuracy: 72.4351%, Training Loss: 0.6306%\n",
      "Epoch [31/300], Step [54/225], Training Accuracy: 72.3090%, Training Loss: 0.6336%\n",
      "Epoch [31/300], Step [55/225], Training Accuracy: 72.3011%, Training Loss: 0.6334%\n",
      "Epoch [31/300], Step [56/225], Training Accuracy: 72.3214%, Training Loss: 0.6319%\n",
      "Epoch [31/300], Step [57/225], Training Accuracy: 72.2314%, Training Loss: 0.6335%\n",
      "Epoch [31/300], Step [58/225], Training Accuracy: 72.3060%, Training Loss: 0.6321%\n",
      "Epoch [31/300], Step [59/225], Training Accuracy: 72.2193%, Training Loss: 0.6330%\n",
      "Epoch [31/300], Step [60/225], Training Accuracy: 72.2917%, Training Loss: 0.6304%\n",
      "Epoch [31/300], Step [61/225], Training Accuracy: 72.2080%, Training Loss: 0.6316%\n",
      "Epoch [31/300], Step [62/225], Training Accuracy: 72.3286%, Training Loss: 0.6309%\n",
      "Epoch [31/300], Step [63/225], Training Accuracy: 72.2222%, Training Loss: 0.6323%\n",
      "Epoch [31/300], Step [64/225], Training Accuracy: 72.0703%, Training Loss: 0.6335%\n",
      "Epoch [31/300], Step [65/225], Training Accuracy: 72.1394%, Training Loss: 0.6330%\n",
      "Epoch [31/300], Step [66/225], Training Accuracy: 72.3011%, Training Loss: 0.6301%\n",
      "Epoch [31/300], Step [67/225], Training Accuracy: 72.2948%, Training Loss: 0.6293%\n",
      "Epoch [31/300], Step [68/225], Training Accuracy: 72.1507%, Training Loss: 0.6312%\n",
      "Epoch [31/300], Step [69/225], Training Accuracy: 72.1467%, Training Loss: 0.6316%\n",
      "Epoch [31/300], Step [70/225], Training Accuracy: 72.1429%, Training Loss: 0.6316%\n",
      "Epoch [31/300], Step [71/225], Training Accuracy: 72.2051%, Training Loss: 0.6323%\n",
      "Epoch [31/300], Step [72/225], Training Accuracy: 72.2222%, Training Loss: 0.6321%\n",
      "Epoch [31/300], Step [73/225], Training Accuracy: 72.2389%, Training Loss: 0.6319%\n",
      "Epoch [31/300], Step [74/225], Training Accuracy: 72.3184%, Training Loss: 0.6299%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/300], Step [75/225], Training Accuracy: 72.3125%, Training Loss: 0.6296%\n",
      "Epoch [31/300], Step [76/225], Training Accuracy: 72.3684%, Training Loss: 0.6294%\n",
      "Epoch [31/300], Step [77/225], Training Accuracy: 72.3823%, Training Loss: 0.6295%\n",
      "Epoch [31/300], Step [78/225], Training Accuracy: 72.4960%, Training Loss: 0.6277%\n",
      "Epoch [31/300], Step [79/225], Training Accuracy: 72.7057%, Training Loss: 0.6246%\n",
      "Epoch [31/300], Step [80/225], Training Accuracy: 72.6562%, Training Loss: 0.6248%\n",
      "Epoch [31/300], Step [81/225], Training Accuracy: 72.7045%, Training Loss: 0.6253%\n",
      "Epoch [31/300], Step [82/225], Training Accuracy: 72.6753%, Training Loss: 0.6256%\n",
      "Epoch [31/300], Step [83/225], Training Accuracy: 72.6468%, Training Loss: 0.6267%\n",
      "Epoch [31/300], Step [84/225], Training Accuracy: 72.6935%, Training Loss: 0.6263%\n",
      "Epoch [31/300], Step [85/225], Training Accuracy: 72.7390%, Training Loss: 0.6254%\n",
      "Epoch [31/300], Step [86/225], Training Accuracy: 72.7834%, Training Loss: 0.6237%\n",
      "Epoch [31/300], Step [87/225], Training Accuracy: 72.7909%, Training Loss: 0.6237%\n",
      "Epoch [31/300], Step [88/225], Training Accuracy: 72.7628%, Training Loss: 0.6245%\n",
      "Epoch [31/300], Step [89/225], Training Accuracy: 72.7528%, Training Loss: 0.6241%\n",
      "Epoch [31/300], Step [90/225], Training Accuracy: 72.7604%, Training Loss: 0.6242%\n",
      "Epoch [31/300], Step [91/225], Training Accuracy: 72.7507%, Training Loss: 0.6251%\n",
      "Epoch [31/300], Step [92/225], Training Accuracy: 72.7582%, Training Loss: 0.6250%\n",
      "Epoch [31/300], Step [93/225], Training Accuracy: 72.7823%, Training Loss: 0.6245%\n",
      "Epoch [31/300], Step [94/225], Training Accuracy: 72.8059%, Training Loss: 0.6235%\n",
      "Epoch [31/300], Step [95/225], Training Accuracy: 72.8289%, Training Loss: 0.6232%\n",
      "Epoch [31/300], Step [96/225], Training Accuracy: 72.9004%, Training Loss: 0.6221%\n",
      "Epoch [31/300], Step [97/225], Training Accuracy: 72.9704%, Training Loss: 0.6207%\n",
      "Epoch [31/300], Step [98/225], Training Accuracy: 73.0070%, Training Loss: 0.6196%\n",
      "Epoch [31/300], Step [99/225], Training Accuracy: 73.0271%, Training Loss: 0.6190%\n",
      "Epoch [31/300], Step [100/225], Training Accuracy: 73.0469%, Training Loss: 0.6189%\n",
      "Epoch [31/300], Step [101/225], Training Accuracy: 73.0662%, Training Loss: 0.6183%\n",
      "Epoch [31/300], Step [102/225], Training Accuracy: 73.0239%, Training Loss: 0.6194%\n",
      "Epoch [31/300], Step [103/225], Training Accuracy: 73.0886%, Training Loss: 0.6182%\n",
      "Epoch [31/300], Step [104/225], Training Accuracy: 73.1370%, Training Loss: 0.6175%\n",
      "Epoch [31/300], Step [105/225], Training Accuracy: 73.2143%, Training Loss: 0.6153%\n",
      "Epoch [31/300], Step [106/225], Training Accuracy: 73.1279%, Training Loss: 0.6153%\n",
      "Epoch [31/300], Step [107/225], Training Accuracy: 73.1454%, Training Loss: 0.6157%\n",
      "Epoch [31/300], Step [108/225], Training Accuracy: 73.1337%, Training Loss: 0.6158%\n",
      "Epoch [31/300], Step [109/225], Training Accuracy: 73.2081%, Training Loss: 0.6157%\n",
      "Epoch [31/300], Step [110/225], Training Accuracy: 73.2244%, Training Loss: 0.6149%\n",
      "Epoch [31/300], Step [111/225], Training Accuracy: 73.1841%, Training Loss: 0.6161%\n",
      "Epoch [31/300], Step [112/225], Training Accuracy: 73.2143%, Training Loss: 0.6162%\n",
      "Epoch [31/300], Step [113/225], Training Accuracy: 73.1610%, Training Loss: 0.6167%\n",
      "Epoch [31/300], Step [114/225], Training Accuracy: 73.1223%, Training Loss: 0.6165%\n",
      "Epoch [31/300], Step [115/225], Training Accuracy: 73.1658%, Training Loss: 0.6152%\n",
      "Epoch [31/300], Step [116/225], Training Accuracy: 73.2085%, Training Loss: 0.6139%\n",
      "Epoch [31/300], Step [117/225], Training Accuracy: 73.1571%, Training Loss: 0.6156%\n",
      "Epoch [31/300], Step [118/225], Training Accuracy: 73.1859%, Training Loss: 0.6156%\n",
      "Epoch [31/300], Step [119/225], Training Accuracy: 73.2143%, Training Loss: 0.6153%\n",
      "Epoch [31/300], Step [120/225], Training Accuracy: 73.2552%, Training Loss: 0.6149%\n",
      "Epoch [31/300], Step [121/225], Training Accuracy: 73.2180%, Training Loss: 0.6154%\n",
      "Epoch [31/300], Step [122/225], Training Accuracy: 73.2454%, Training Loss: 0.6150%\n",
      "Epoch [31/300], Step [123/225], Training Accuracy: 73.2342%, Training Loss: 0.6149%\n",
      "Epoch [31/300], Step [124/225], Training Accuracy: 73.1981%, Training Loss: 0.6157%\n",
      "Epoch [31/300], Step [125/225], Training Accuracy: 73.1875%, Training Loss: 0.6164%\n",
      "Epoch [31/300], Step [126/225], Training Accuracy: 73.2639%, Training Loss: 0.6155%\n",
      "Epoch [31/300], Step [127/225], Training Accuracy: 73.2776%, Training Loss: 0.6162%\n",
      "Epoch [31/300], Step [128/225], Training Accuracy: 73.2178%, Training Loss: 0.6172%\n",
      "Epoch [31/300], Step [129/225], Training Accuracy: 73.2195%, Training Loss: 0.6168%\n",
      "Epoch [31/300], Step [130/225], Training Accuracy: 73.1731%, Training Loss: 0.6168%\n",
      "Epoch [31/300], Step [131/225], Training Accuracy: 73.1512%, Training Loss: 0.6170%\n",
      "Epoch [31/300], Step [132/225], Training Accuracy: 73.0469%, Training Loss: 0.6187%\n",
      "Epoch [31/300], Step [133/225], Training Accuracy: 73.0146%, Training Loss: 0.6190%\n",
      "Epoch [31/300], Step [134/225], Training Accuracy: 72.9011%, Training Loss: 0.6207%\n",
      "Epoch [31/300], Step [135/225], Training Accuracy: 72.9282%, Training Loss: 0.6201%\n",
      "Epoch [31/300], Step [136/225], Training Accuracy: 72.8975%, Training Loss: 0.6198%\n",
      "Epoch [31/300], Step [137/225], Training Accuracy: 72.9357%, Training Loss: 0.6194%\n",
      "Epoch [31/300], Step [138/225], Training Accuracy: 73.0186%, Training Loss: 0.6175%\n",
      "Epoch [31/300], Step [139/225], Training Accuracy: 73.0441%, Training Loss: 0.6173%\n",
      "Epoch [31/300], Step [140/225], Training Accuracy: 73.0692%, Training Loss: 0.6173%\n",
      "Epoch [31/300], Step [141/225], Training Accuracy: 73.1383%, Training Loss: 0.6163%\n",
      "Epoch [31/300], Step [142/225], Training Accuracy: 73.1074%, Training Loss: 0.6159%\n",
      "Epoch [31/300], Step [143/225], Training Accuracy: 73.0660%, Training Loss: 0.6171%\n",
      "Epoch [31/300], Step [144/225], Training Accuracy: 73.0469%, Training Loss: 0.6176%\n",
      "Epoch [31/300], Step [145/225], Training Accuracy: 73.0496%, Training Loss: 0.6171%\n",
      "Epoch [31/300], Step [146/225], Training Accuracy: 73.0094%, Training Loss: 0.6180%\n",
      "Epoch [31/300], Step [147/225], Training Accuracy: 72.9592%, Training Loss: 0.6193%\n",
      "Epoch [31/300], Step [148/225], Training Accuracy: 73.0152%, Training Loss: 0.6182%\n",
      "Epoch [31/300], Step [149/225], Training Accuracy: 72.9866%, Training Loss: 0.6184%\n",
      "Epoch [31/300], Step [150/225], Training Accuracy: 73.0000%, Training Loss: 0.6173%\n",
      "Epoch [31/300], Step [151/225], Training Accuracy: 73.0857%, Training Loss: 0.6164%\n",
      "Epoch [31/300], Step [152/225], Training Accuracy: 73.0058%, Training Loss: 0.6178%\n",
      "Epoch [31/300], Step [153/225], Training Accuracy: 73.0086%, Training Loss: 0.6178%\n",
      "Epoch [31/300], Step [154/225], Training Accuracy: 73.0215%, Training Loss: 0.6174%\n",
      "Epoch [31/300], Step [155/225], Training Accuracy: 72.9637%, Training Loss: 0.6182%\n",
      "Epoch [31/300], Step [156/225], Training Accuracy: 72.9367%, Training Loss: 0.6191%\n",
      "Epoch [31/300], Step [157/225], Training Accuracy: 72.9200%, Training Loss: 0.6187%\n",
      "Epoch [31/300], Step [158/225], Training Accuracy: 72.8145%, Training Loss: 0.6205%\n",
      "Epoch [31/300], Step [159/225], Training Accuracy: 72.8086%, Training Loss: 0.6204%\n",
      "Epoch [31/300], Step [160/225], Training Accuracy: 72.8125%, Training Loss: 0.6201%\n",
      "Epoch [31/300], Step [161/225], Training Accuracy: 72.7970%, Training Loss: 0.6203%\n",
      "Epoch [31/300], Step [162/225], Training Accuracy: 72.7913%, Training Loss: 0.6211%\n",
      "Epoch [31/300], Step [163/225], Training Accuracy: 72.8048%, Training Loss: 0.6207%\n",
      "Epoch [31/300], Step [164/225], Training Accuracy: 72.7992%, Training Loss: 0.6209%\n",
      "Epoch [31/300], Step [165/225], Training Accuracy: 72.7841%, Training Loss: 0.6213%\n",
      "Epoch [31/300], Step [166/225], Training Accuracy: 72.7598%, Training Loss: 0.6215%\n",
      "Epoch [31/300], Step [167/225], Training Accuracy: 72.7638%, Training Loss: 0.6216%\n",
      "Epoch [31/300], Step [168/225], Training Accuracy: 72.7679%, Training Loss: 0.6222%\n",
      "Epoch [31/300], Step [169/225], Training Accuracy: 72.7903%, Training Loss: 0.6216%\n",
      "Epoch [31/300], Step [170/225], Training Accuracy: 72.7757%, Training Loss: 0.6218%\n",
      "Epoch [31/300], Step [171/225], Training Accuracy: 72.7796%, Training Loss: 0.6221%\n",
      "Epoch [31/300], Step [172/225], Training Accuracy: 72.7834%, Training Loss: 0.6219%\n",
      "Epoch [31/300], Step [173/225], Training Accuracy: 72.7511%, Training Loss: 0.6222%\n",
      "Epoch [31/300], Step [174/225], Training Accuracy: 72.7191%, Training Loss: 0.6229%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/300], Step [175/225], Training Accuracy: 72.7232%, Training Loss: 0.6228%\n",
      "Epoch [31/300], Step [176/225], Training Accuracy: 72.7273%, Training Loss: 0.6225%\n",
      "Epoch [31/300], Step [177/225], Training Accuracy: 72.7225%, Training Loss: 0.6224%\n",
      "Epoch [31/300], Step [178/225], Training Accuracy: 72.7616%, Training Loss: 0.6222%\n",
      "Epoch [31/300], Step [179/225], Training Accuracy: 72.7916%, Training Loss: 0.6225%\n",
      "Epoch [31/300], Step [180/225], Training Accuracy: 72.8125%, Training Loss: 0.6218%\n",
      "Epoch [31/300], Step [181/225], Training Accuracy: 72.8073%, Training Loss: 0.6222%\n",
      "Epoch [31/300], Step [182/225], Training Accuracy: 72.7850%, Training Loss: 0.6224%\n",
      "Epoch [31/300], Step [183/225], Training Accuracy: 72.7203%, Training Loss: 0.6228%\n",
      "Epoch [31/300], Step [184/225], Training Accuracy: 72.7412%, Training Loss: 0.6223%\n",
      "Epoch [31/300], Step [185/225], Training Accuracy: 72.7280%, Training Loss: 0.6229%\n",
      "Epoch [31/300], Step [186/225], Training Accuracy: 72.7991%, Training Loss: 0.6218%\n",
      "Epoch [31/300], Step [187/225], Training Accuracy: 72.7523%, Training Loss: 0.6230%\n",
      "Epoch [31/300], Step [188/225], Training Accuracy: 72.7726%, Training Loss: 0.6228%\n",
      "Epoch [31/300], Step [189/225], Training Accuracy: 72.8257%, Training Loss: 0.6218%\n",
      "Epoch [31/300], Step [190/225], Training Accuracy: 72.8372%, Training Loss: 0.6219%\n",
      "Epoch [31/300], Step [191/225], Training Accuracy: 72.8730%, Training Loss: 0.6220%\n",
      "Epoch [31/300], Step [192/225], Training Accuracy: 72.8760%, Training Loss: 0.6220%\n",
      "Epoch [31/300], Step [193/225], Training Accuracy: 72.8951%, Training Loss: 0.6221%\n",
      "Epoch [31/300], Step [194/225], Training Accuracy: 72.8898%, Training Loss: 0.6223%\n",
      "Epoch [31/300], Step [195/225], Training Accuracy: 72.9487%, Training Loss: 0.6211%\n",
      "Epoch [31/300], Step [196/225], Training Accuracy: 72.9432%, Training Loss: 0.6218%\n",
      "Epoch [31/300], Step [197/225], Training Accuracy: 72.9616%, Training Loss: 0.6217%\n",
      "Epoch [31/300], Step [198/225], Training Accuracy: 72.9719%, Training Loss: 0.6213%\n",
      "Epoch [31/300], Step [199/225], Training Accuracy: 73.0057%, Training Loss: 0.6207%\n",
      "Epoch [31/300], Step [200/225], Training Accuracy: 73.0000%, Training Loss: 0.6208%\n",
      "Epoch [31/300], Step [201/225], Training Accuracy: 72.9866%, Training Loss: 0.6210%\n",
      "Epoch [31/300], Step [202/225], Training Accuracy: 72.9811%, Training Loss: 0.6208%\n",
      "Epoch [31/300], Step [203/225], Training Accuracy: 73.0219%, Training Loss: 0.6208%\n",
      "Epoch [31/300], Step [204/225], Training Accuracy: 73.0316%, Training Loss: 0.6210%\n",
      "Epoch [31/300], Step [205/225], Training Accuracy: 73.0183%, Training Loss: 0.6211%\n",
      "Epoch [31/300], Step [206/225], Training Accuracy: 73.0355%, Training Loss: 0.6210%\n",
      "Epoch [31/300], Step [207/225], Training Accuracy: 73.0601%, Training Loss: 0.6205%\n",
      "Epoch [31/300], Step [208/225], Training Accuracy: 73.0619%, Training Loss: 0.6199%\n",
      "Epoch [31/300], Step [209/225], Training Accuracy: 73.0338%, Training Loss: 0.6202%\n",
      "Epoch [31/300], Step [210/225], Training Accuracy: 73.0060%, Training Loss: 0.6209%\n",
      "Epoch [31/300], Step [211/225], Training Accuracy: 73.0376%, Training Loss: 0.6203%\n",
      "Epoch [31/300], Step [212/225], Training Accuracy: 73.0321%, Training Loss: 0.6208%\n",
      "Epoch [31/300], Step [213/225], Training Accuracy: 72.9974%, Training Loss: 0.6216%\n",
      "Epoch [31/300], Step [214/225], Training Accuracy: 73.0286%, Training Loss: 0.6210%\n",
      "Epoch [31/300], Step [215/225], Training Accuracy: 73.0378%, Training Loss: 0.6205%\n",
      "Epoch [31/300], Step [216/225], Training Accuracy: 73.0035%, Training Loss: 0.6210%\n",
      "Epoch [31/300], Step [217/225], Training Accuracy: 73.0199%, Training Loss: 0.6207%\n",
      "Epoch [31/300], Step [218/225], Training Accuracy: 73.0003%, Training Loss: 0.6213%\n",
      "Epoch [31/300], Step [219/225], Training Accuracy: 73.0023%, Training Loss: 0.6210%\n",
      "Epoch [31/300], Step [220/225], Training Accuracy: 73.0540%, Training Loss: 0.6203%\n",
      "Epoch [31/300], Step [221/225], Training Accuracy: 73.0769%, Training Loss: 0.6196%\n",
      "Epoch [31/300], Step [222/225], Training Accuracy: 73.0785%, Training Loss: 0.6194%\n",
      "Epoch [31/300], Step [223/225], Training Accuracy: 73.0521%, Training Loss: 0.6198%\n",
      "Epoch [31/300], Step [224/225], Training Accuracy: 73.0539%, Training Loss: 0.6196%\n",
      "Epoch [31/300], Step [225/225], Training Accuracy: 73.0128%, Training Loss: 0.6200%\n",
      "Epoch [32/300], Step [1/225], Training Accuracy: 85.9375%, Training Loss: 0.4266%\n",
      "Epoch [32/300], Step [2/225], Training Accuracy: 81.2500%, Training Loss: 0.5229%\n",
      "Epoch [32/300], Step [3/225], Training Accuracy: 78.6458%, Training Loss: 0.5777%\n",
      "Epoch [32/300], Step [4/225], Training Accuracy: 75.3906%, Training Loss: 0.5819%\n",
      "Epoch [32/300], Step [5/225], Training Accuracy: 75.3125%, Training Loss: 0.5944%\n",
      "Epoch [32/300], Step [6/225], Training Accuracy: 74.7396%, Training Loss: 0.5858%\n",
      "Epoch [32/300], Step [7/225], Training Accuracy: 73.8839%, Training Loss: 0.5887%\n",
      "Epoch [32/300], Step [8/225], Training Accuracy: 73.6328%, Training Loss: 0.6152%\n",
      "Epoch [32/300], Step [9/225], Training Accuracy: 73.6111%, Training Loss: 0.6084%\n",
      "Epoch [32/300], Step [10/225], Training Accuracy: 73.4375%, Training Loss: 0.6074%\n",
      "Epoch [32/300], Step [11/225], Training Accuracy: 73.5795%, Training Loss: 0.6002%\n",
      "Epoch [32/300], Step [12/225], Training Accuracy: 73.4375%, Training Loss: 0.6023%\n",
      "Epoch [32/300], Step [13/225], Training Accuracy: 73.9183%, Training Loss: 0.5900%\n",
      "Epoch [32/300], Step [14/225], Training Accuracy: 74.1071%, Training Loss: 0.5863%\n",
      "Epoch [32/300], Step [15/225], Training Accuracy: 74.2708%, Training Loss: 0.5925%\n",
      "Epoch [32/300], Step [16/225], Training Accuracy: 74.4141%, Training Loss: 0.5911%\n",
      "Epoch [32/300], Step [17/225], Training Accuracy: 74.2647%, Training Loss: 0.5873%\n",
      "Epoch [32/300], Step [18/225], Training Accuracy: 74.2188%, Training Loss: 0.5884%\n",
      "Epoch [32/300], Step [19/225], Training Accuracy: 74.5066%, Training Loss: 0.5822%\n",
      "Epoch [32/300], Step [20/225], Training Accuracy: 74.7656%, Training Loss: 0.5764%\n",
      "Epoch [32/300], Step [21/225], Training Accuracy: 74.6280%, Training Loss: 0.5788%\n",
      "Epoch [32/300], Step [22/225], Training Accuracy: 74.5028%, Training Loss: 0.5824%\n",
      "Epoch [32/300], Step [23/225], Training Accuracy: 74.3886%, Training Loss: 0.5839%\n",
      "Epoch [32/300], Step [24/225], Training Accuracy: 74.2188%, Training Loss: 0.5849%\n",
      "Epoch [32/300], Step [25/225], Training Accuracy: 74.2500%, Training Loss: 0.5805%\n",
      "Epoch [32/300], Step [26/225], Training Accuracy: 74.4591%, Training Loss: 0.5788%\n",
      "Epoch [32/300], Step [27/225], Training Accuracy: 74.6528%, Training Loss: 0.5781%\n",
      "Epoch [32/300], Step [28/225], Training Accuracy: 74.7768%, Training Loss: 0.5757%\n",
      "Epoch [32/300], Step [29/225], Training Accuracy: 74.7306%, Training Loss: 0.5763%\n",
      "Epoch [32/300], Step [30/225], Training Accuracy: 74.8438%, Training Loss: 0.5716%\n",
      "Epoch [32/300], Step [31/225], Training Accuracy: 74.7480%, Training Loss: 0.5741%\n",
      "Epoch [32/300], Step [32/225], Training Accuracy: 74.7070%, Training Loss: 0.5716%\n",
      "Epoch [32/300], Step [33/225], Training Accuracy: 74.6212%, Training Loss: 0.5794%\n",
      "Epoch [32/300], Step [34/225], Training Accuracy: 74.2188%, Training Loss: 0.5858%\n",
      "Epoch [32/300], Step [35/225], Training Accuracy: 74.0179%, Training Loss: 0.5893%\n",
      "Epoch [32/300], Step [36/225], Training Accuracy: 73.7413%, Training Loss: 0.5947%\n",
      "Epoch [32/300], Step [37/225], Training Accuracy: 73.9020%, Training Loss: 0.5904%\n",
      "Epoch [32/300], Step [38/225], Training Accuracy: 73.9720%, Training Loss: 0.5880%\n",
      "Epoch [32/300], Step [39/225], Training Accuracy: 73.9583%, Training Loss: 0.5883%\n",
      "Epoch [32/300], Step [40/225], Training Accuracy: 73.7891%, Training Loss: 0.5904%\n",
      "Epoch [32/300], Step [41/225], Training Accuracy: 73.5518%, Training Loss: 0.5944%\n",
      "Epoch [32/300], Step [42/225], Training Accuracy: 73.4375%, Training Loss: 0.5953%\n",
      "Epoch [32/300], Step [43/225], Training Accuracy: 73.4375%, Training Loss: 0.5970%\n",
      "Epoch [32/300], Step [44/225], Training Accuracy: 73.3665%, Training Loss: 0.5987%\n",
      "Epoch [32/300], Step [45/225], Training Accuracy: 73.3681%, Training Loss: 0.5969%\n",
      "Epoch [32/300], Step [46/225], Training Accuracy: 73.3356%, Training Loss: 0.5987%\n",
      "Epoch [32/300], Step [47/225], Training Accuracy: 73.3045%, Training Loss: 0.5999%\n",
      "Epoch [32/300], Step [48/225], Training Accuracy: 73.2747%, Training Loss: 0.6007%\n",
      "Epoch [32/300], Step [49/225], Training Accuracy: 73.3099%, Training Loss: 0.6003%\n",
      "Epoch [32/300], Step [50/225], Training Accuracy: 73.2188%, Training Loss: 0.6008%\n",
      "Epoch [32/300], Step [51/225], Training Accuracy: 73.2843%, Training Loss: 0.5995%\n",
      "Epoch [32/300], Step [52/225], Training Accuracy: 73.4675%, Training Loss: 0.5959%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/300], Step [53/225], Training Accuracy: 73.4375%, Training Loss: 0.5964%\n",
      "Epoch [32/300], Step [54/225], Training Accuracy: 73.3218%, Training Loss: 0.5999%\n",
      "Epoch [32/300], Step [55/225], Training Accuracy: 73.2386%, Training Loss: 0.6028%\n",
      "Epoch [32/300], Step [56/225], Training Accuracy: 73.2701%, Training Loss: 0.6028%\n",
      "Epoch [32/300], Step [57/225], Training Accuracy: 73.2456%, Training Loss: 0.6047%\n",
      "Epoch [32/300], Step [58/225], Training Accuracy: 73.2489%, Training Loss: 0.6034%\n",
      "Epoch [32/300], Step [59/225], Training Accuracy: 73.2256%, Training Loss: 0.6042%\n",
      "Epoch [32/300], Step [60/225], Training Accuracy: 73.2812%, Training Loss: 0.6040%\n",
      "Epoch [32/300], Step [61/225], Training Accuracy: 73.2582%, Training Loss: 0.6028%\n",
      "Epoch [32/300], Step [62/225], Training Accuracy: 73.2359%, Training Loss: 0.6032%\n",
      "Epoch [32/300], Step [63/225], Training Accuracy: 73.2887%, Training Loss: 0.6037%\n",
      "Epoch [32/300], Step [64/225], Training Accuracy: 73.2910%, Training Loss: 0.6045%\n",
      "Epoch [32/300], Step [65/225], Training Accuracy: 73.4856%, Training Loss: 0.6028%\n",
      "Epoch [32/300], Step [66/225], Training Accuracy: 73.5322%, Training Loss: 0.6019%\n",
      "Epoch [32/300], Step [67/225], Training Accuracy: 73.4608%, Training Loss: 0.6023%\n",
      "Epoch [32/300], Step [68/225], Training Accuracy: 73.4375%, Training Loss: 0.6024%\n",
      "Epoch [32/300], Step [69/225], Training Accuracy: 73.4601%, Training Loss: 0.6036%\n",
      "Epoch [32/300], Step [70/225], Training Accuracy: 73.4821%, Training Loss: 0.6029%\n",
      "Epoch [32/300], Step [71/225], Training Accuracy: 73.5035%, Training Loss: 0.6044%\n",
      "Epoch [32/300], Step [72/225], Training Accuracy: 73.5026%, Training Loss: 0.6044%\n",
      "Epoch [32/300], Step [73/225], Training Accuracy: 73.5017%, Training Loss: 0.6044%\n",
      "Epoch [32/300], Step [74/225], Training Accuracy: 73.5431%, Training Loss: 0.6024%\n",
      "Epoch [32/300], Step [75/225], Training Accuracy: 73.5625%, Training Loss: 0.6011%\n",
      "Epoch [32/300], Step [76/225], Training Accuracy: 73.3964%, Training Loss: 0.6036%\n",
      "Epoch [32/300], Step [77/225], Training Accuracy: 73.4375%, Training Loss: 0.6034%\n",
      "Epoch [32/300], Step [78/225], Training Accuracy: 73.5176%, Training Loss: 0.6025%\n",
      "Epoch [32/300], Step [79/225], Training Accuracy: 73.6748%, Training Loss: 0.5997%\n",
      "Epoch [32/300], Step [80/225], Training Accuracy: 73.5938%, Training Loss: 0.6005%\n",
      "Epoch [32/300], Step [81/225], Training Accuracy: 73.7461%, Training Loss: 0.5983%\n",
      "Epoch [32/300], Step [82/225], Training Accuracy: 73.8186%, Training Loss: 0.5970%\n",
      "Epoch [32/300], Step [83/225], Training Accuracy: 73.8893%, Training Loss: 0.5970%\n",
      "Epoch [32/300], Step [84/225], Training Accuracy: 73.9397%, Training Loss: 0.5953%\n",
      "Epoch [32/300], Step [85/225], Training Accuracy: 73.9706%, Training Loss: 0.5950%\n",
      "Epoch [32/300], Step [86/225], Training Accuracy: 73.9462%, Training Loss: 0.5941%\n",
      "Epoch [32/300], Step [87/225], Training Accuracy: 73.9045%, Training Loss: 0.5951%\n",
      "Epoch [32/300], Step [88/225], Training Accuracy: 73.7926%, Training Loss: 0.5972%\n",
      "Epoch [32/300], Step [89/225], Training Accuracy: 73.6833%, Training Loss: 0.5994%\n",
      "Epoch [32/300], Step [90/225], Training Accuracy: 73.6111%, Training Loss: 0.6006%\n",
      "Epoch [32/300], Step [91/225], Training Accuracy: 73.5405%, Training Loss: 0.6010%\n",
      "Epoch [32/300], Step [92/225], Training Accuracy: 73.4715%, Training Loss: 0.6022%\n",
      "Epoch [32/300], Step [93/225], Training Accuracy: 73.4879%, Training Loss: 0.6011%\n",
      "Epoch [32/300], Step [94/225], Training Accuracy: 73.5040%, Training Loss: 0.6010%\n",
      "Epoch [32/300], Step [95/225], Training Accuracy: 73.5855%, Training Loss: 0.6004%\n",
      "Epoch [32/300], Step [96/225], Training Accuracy: 73.6491%, Training Loss: 0.5995%\n",
      "Epoch [32/300], Step [97/225], Training Accuracy: 73.6791%, Training Loss: 0.5984%\n",
      "Epoch [32/300], Step [98/225], Training Accuracy: 73.7245%, Training Loss: 0.5983%\n",
      "Epoch [32/300], Step [99/225], Training Accuracy: 73.8321%, Training Loss: 0.5974%\n",
      "Epoch [32/300], Step [100/225], Training Accuracy: 73.7969%, Training Loss: 0.5982%\n",
      "Epoch [32/300], Step [101/225], Training Accuracy: 73.7933%, Training Loss: 0.5983%\n",
      "Epoch [32/300], Step [102/225], Training Accuracy: 73.7286%, Training Loss: 0.5990%\n",
      "Epoch [32/300], Step [103/225], Training Accuracy: 73.7561%, Training Loss: 0.5991%\n",
      "Epoch [32/300], Step [104/225], Training Accuracy: 73.7680%, Training Loss: 0.5990%\n",
      "Epoch [32/300], Step [105/225], Training Accuracy: 73.8542%, Training Loss: 0.5970%\n",
      "Epoch [32/300], Step [106/225], Training Accuracy: 73.8355%, Training Loss: 0.5962%\n",
      "Epoch [32/300], Step [107/225], Training Accuracy: 73.8172%, Training Loss: 0.5970%\n",
      "Epoch [32/300], Step [108/225], Training Accuracy: 73.7703%, Training Loss: 0.5975%\n",
      "Epoch [32/300], Step [109/225], Training Accuracy: 73.7242%, Training Loss: 0.5979%\n",
      "Epoch [32/300], Step [110/225], Training Accuracy: 73.6506%, Training Loss: 0.5986%\n",
      "Epoch [32/300], Step [111/225], Training Accuracy: 73.6064%, Training Loss: 0.5987%\n",
      "Epoch [32/300], Step [112/225], Training Accuracy: 73.6468%, Training Loss: 0.5990%\n",
      "Epoch [32/300], Step [113/225], Training Accuracy: 73.6864%, Training Loss: 0.5984%\n",
      "Epoch [32/300], Step [114/225], Training Accuracy: 73.6431%, Training Loss: 0.5979%\n",
      "Epoch [32/300], Step [115/225], Training Accuracy: 73.6821%, Training Loss: 0.5960%\n",
      "Epoch [32/300], Step [116/225], Training Accuracy: 73.7204%, Training Loss: 0.5968%\n",
      "Epoch [32/300], Step [117/225], Training Accuracy: 73.6378%, Training Loss: 0.5976%\n",
      "Epoch [32/300], Step [118/225], Training Accuracy: 73.6891%, Training Loss: 0.5965%\n",
      "Epoch [32/300], Step [119/225], Training Accuracy: 73.6607%, Training Loss: 0.5973%\n",
      "Epoch [32/300], Step [120/225], Training Accuracy: 73.6458%, Training Loss: 0.5971%\n",
      "Epoch [32/300], Step [121/225], Training Accuracy: 73.6183%, Training Loss: 0.5969%\n",
      "Epoch [32/300], Step [122/225], Training Accuracy: 73.6040%, Training Loss: 0.5967%\n",
      "Epoch [32/300], Step [123/225], Training Accuracy: 73.5645%, Training Loss: 0.5970%\n",
      "Epoch [32/300], Step [124/225], Training Accuracy: 73.5887%, Training Loss: 0.5961%\n",
      "Epoch [32/300], Step [125/225], Training Accuracy: 73.5625%, Training Loss: 0.5967%\n",
      "Epoch [32/300], Step [126/225], Training Accuracy: 73.6235%, Training Loss: 0.5965%\n",
      "Epoch [32/300], Step [127/225], Training Accuracy: 73.6467%, Training Loss: 0.5958%\n",
      "Epoch [32/300], Step [128/225], Training Accuracy: 73.6328%, Training Loss: 0.5966%\n",
      "Epoch [32/300], Step [129/225], Training Accuracy: 73.5950%, Training Loss: 0.5968%\n",
      "Epoch [32/300], Step [130/225], Training Accuracy: 73.6178%, Training Loss: 0.5969%\n",
      "Epoch [32/300], Step [131/225], Training Accuracy: 73.5687%, Training Loss: 0.5975%\n",
      "Epoch [32/300], Step [132/225], Training Accuracy: 73.5440%, Training Loss: 0.5985%\n",
      "Epoch [32/300], Step [133/225], Training Accuracy: 73.5197%, Training Loss: 0.5986%\n",
      "Epoch [32/300], Step [134/225], Training Accuracy: 73.4608%, Training Loss: 0.6002%\n",
      "Epoch [32/300], Step [135/225], Training Accuracy: 73.4954%, Training Loss: 0.5994%\n",
      "Epoch [32/300], Step [136/225], Training Accuracy: 73.5064%, Training Loss: 0.5989%\n",
      "Epoch [32/300], Step [137/225], Training Accuracy: 73.5173%, Training Loss: 0.5983%\n",
      "Epoch [32/300], Step [138/225], Training Accuracy: 73.5847%, Training Loss: 0.5972%\n",
      "Epoch [32/300], Step [139/225], Training Accuracy: 73.6174%, Training Loss: 0.5968%\n",
      "Epoch [32/300], Step [140/225], Training Accuracy: 73.6496%, Training Loss: 0.5962%\n",
      "Epoch [32/300], Step [141/225], Training Accuracy: 73.6480%, Training Loss: 0.5962%\n",
      "Epoch [32/300], Step [142/225], Training Accuracy: 73.6906%, Training Loss: 0.5958%\n",
      "Epoch [32/300], Step [143/225], Training Accuracy: 73.6779%, Training Loss: 0.5957%\n",
      "Epoch [32/300], Step [144/225], Training Accuracy: 73.7088%, Training Loss: 0.5957%\n",
      "Epoch [32/300], Step [145/225], Training Accuracy: 73.7069%, Training Loss: 0.5954%\n",
      "Epoch [32/300], Step [146/225], Training Accuracy: 73.7158%, Training Loss: 0.5955%\n",
      "Epoch [32/300], Step [147/225], Training Accuracy: 73.6501%, Training Loss: 0.5969%\n",
      "Epoch [32/300], Step [148/225], Training Accuracy: 73.6909%, Training Loss: 0.5962%\n",
      "Epoch [32/300], Step [149/225], Training Accuracy: 73.6472%, Training Loss: 0.5963%\n",
      "Epoch [32/300], Step [150/225], Training Accuracy: 73.6875%, Training Loss: 0.5950%\n",
      "Epoch [32/300], Step [151/225], Training Accuracy: 73.6445%, Training Loss: 0.5955%\n",
      "Epoch [32/300], Step [152/225], Training Accuracy: 73.6328%, Training Loss: 0.5957%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/300], Step [153/225], Training Accuracy: 73.5907%, Training Loss: 0.5965%\n",
      "Epoch [32/300], Step [154/225], Training Accuracy: 73.6100%, Training Loss: 0.5965%\n",
      "Epoch [32/300], Step [155/225], Training Accuracy: 73.6290%, Training Loss: 0.5961%\n",
      "Epoch [32/300], Step [156/225], Training Accuracy: 73.6378%, Training Loss: 0.5961%\n",
      "Epoch [32/300], Step [157/225], Training Accuracy: 73.6166%, Training Loss: 0.5960%\n",
      "Epoch [32/300], Step [158/225], Training Accuracy: 73.5661%, Training Loss: 0.5968%\n",
      "Epoch [32/300], Step [159/225], Training Accuracy: 73.5161%, Training Loss: 0.5975%\n",
      "Epoch [32/300], Step [160/225], Training Accuracy: 73.5547%, Training Loss: 0.5967%\n",
      "Epoch [32/300], Step [161/225], Training Accuracy: 73.5734%, Training Loss: 0.5973%\n",
      "Epoch [32/300], Step [162/225], Training Accuracy: 73.5918%, Training Loss: 0.5966%\n",
      "Epoch [32/300], Step [163/225], Training Accuracy: 73.6196%, Training Loss: 0.5960%\n",
      "Epoch [32/300], Step [164/225], Training Accuracy: 73.6185%, Training Loss: 0.5959%\n",
      "Epoch [32/300], Step [165/225], Training Accuracy: 73.5890%, Training Loss: 0.5964%\n",
      "Epoch [32/300], Step [166/225], Training Accuracy: 73.6069%, Training Loss: 0.5961%\n",
      "Epoch [32/300], Step [167/225], Training Accuracy: 73.5966%, Training Loss: 0.5962%\n",
      "Epoch [32/300], Step [168/225], Training Accuracy: 73.5677%, Training Loss: 0.5971%\n",
      "Epoch [32/300], Step [169/225], Training Accuracy: 73.6039%, Training Loss: 0.5960%\n",
      "Epoch [32/300], Step [170/225], Training Accuracy: 73.5846%, Training Loss: 0.5973%\n",
      "Epoch [32/300], Step [171/225], Training Accuracy: 73.5654%, Training Loss: 0.5975%\n",
      "Epoch [32/300], Step [172/225], Training Accuracy: 73.5828%, Training Loss: 0.5975%\n",
      "Epoch [32/300], Step [173/225], Training Accuracy: 73.6181%, Training Loss: 0.5972%\n",
      "Epoch [32/300], Step [174/225], Training Accuracy: 73.6440%, Training Loss: 0.5974%\n",
      "Epoch [32/300], Step [175/225], Training Accuracy: 73.6518%, Training Loss: 0.5971%\n",
      "Epoch [32/300], Step [176/225], Training Accuracy: 73.6328%, Training Loss: 0.5970%\n",
      "Epoch [32/300], Step [177/225], Training Accuracy: 73.6670%, Training Loss: 0.5961%\n",
      "Epoch [32/300], Step [178/225], Training Accuracy: 73.6745%, Training Loss: 0.5961%\n",
      "Epoch [32/300], Step [179/225], Training Accuracy: 73.6732%, Training Loss: 0.5963%\n",
      "Epoch [32/300], Step [180/225], Training Accuracy: 73.6545%, Training Loss: 0.5970%\n",
      "Epoch [32/300], Step [181/225], Training Accuracy: 73.6965%, Training Loss: 0.5967%\n",
      "Epoch [32/300], Step [182/225], Training Accuracy: 73.6951%, Training Loss: 0.5968%\n",
      "Epoch [32/300], Step [183/225], Training Accuracy: 73.6510%, Training Loss: 0.5973%\n",
      "Epoch [32/300], Step [184/225], Training Accuracy: 73.6923%, Training Loss: 0.5969%\n",
      "Epoch [32/300], Step [185/225], Training Accuracy: 73.6993%, Training Loss: 0.5973%\n",
      "Epoch [32/300], Step [186/225], Training Accuracy: 73.7651%, Training Loss: 0.5960%\n",
      "Epoch [32/300], Step [187/225], Training Accuracy: 73.7299%, Training Loss: 0.5965%\n",
      "Epoch [32/300], Step [188/225], Training Accuracy: 73.7616%, Training Loss: 0.5959%\n",
      "Epoch [32/300], Step [189/225], Training Accuracy: 73.7765%, Training Loss: 0.5957%\n",
      "Epoch [32/300], Step [190/225], Training Accuracy: 73.7747%, Training Loss: 0.5962%\n",
      "Epoch [32/300], Step [191/225], Training Accuracy: 73.7729%, Training Loss: 0.5963%\n",
      "Epoch [32/300], Step [192/225], Training Accuracy: 73.7956%, Training Loss: 0.5963%\n",
      "Epoch [32/300], Step [193/225], Training Accuracy: 73.7937%, Training Loss: 0.5966%\n",
      "Epoch [32/300], Step [194/225], Training Accuracy: 73.7838%, Training Loss: 0.5970%\n",
      "Epoch [32/300], Step [195/225], Training Accuracy: 73.8221%, Training Loss: 0.5963%\n",
      "Epoch [32/300], Step [196/225], Training Accuracy: 73.8042%, Training Loss: 0.5963%\n",
      "Epoch [32/300], Step [197/225], Training Accuracy: 73.7865%, Training Loss: 0.5969%\n",
      "Epoch [32/300], Step [198/225], Training Accuracy: 73.7689%, Training Loss: 0.5967%\n",
      "Epoch [32/300], Step [199/225], Training Accuracy: 73.7987%, Training Loss: 0.5966%\n",
      "Epoch [32/300], Step [200/225], Training Accuracy: 73.7812%, Training Loss: 0.5971%\n",
      "Epoch [32/300], Step [201/225], Training Accuracy: 73.7484%, Training Loss: 0.5977%\n",
      "Epoch [32/300], Step [202/225], Training Accuracy: 73.7546%, Training Loss: 0.5974%\n",
      "Epoch [32/300], Step [203/225], Training Accuracy: 73.7993%, Training Loss: 0.5968%\n",
      "Epoch [32/300], Step [204/225], Training Accuracy: 73.8205%, Training Loss: 0.5965%\n",
      "Epoch [32/300], Step [205/225], Training Accuracy: 73.8643%, Training Loss: 0.5962%\n",
      "Epoch [32/300], Step [206/225], Training Accuracy: 73.8926%, Training Loss: 0.5958%\n",
      "Epoch [32/300], Step [207/225], Training Accuracy: 73.8829%, Training Loss: 0.5958%\n",
      "Epoch [32/300], Step [208/225], Training Accuracy: 73.9483%, Training Loss: 0.5952%\n",
      "Epoch [32/300], Step [209/225], Training Accuracy: 73.9459%, Training Loss: 0.5955%\n",
      "Epoch [32/300], Step [210/225], Training Accuracy: 73.9062%, Training Loss: 0.5961%\n",
      "Epoch [32/300], Step [211/225], Training Accuracy: 73.9336%, Training Loss: 0.5960%\n",
      "Epoch [32/300], Step [212/225], Training Accuracy: 73.9460%, Training Loss: 0.5959%\n",
      "Epoch [32/300], Step [213/225], Training Accuracy: 73.9437%, Training Loss: 0.5958%\n",
      "Epoch [32/300], Step [214/225], Training Accuracy: 73.9559%, Training Loss: 0.5954%\n",
      "Epoch [32/300], Step [215/225], Training Accuracy: 73.9172%, Training Loss: 0.5964%\n",
      "Epoch [32/300], Step [216/225], Training Accuracy: 73.8860%, Training Loss: 0.5971%\n",
      "Epoch [32/300], Step [217/225], Training Accuracy: 73.8767%, Training Loss: 0.5976%\n",
      "Epoch [32/300], Step [218/225], Training Accuracy: 73.8604%, Training Loss: 0.5976%\n",
      "Epoch [32/300], Step [219/225], Training Accuracy: 73.8513%, Training Loss: 0.5980%\n",
      "Epoch [32/300], Step [220/225], Training Accuracy: 73.8565%, Training Loss: 0.5975%\n",
      "Epoch [32/300], Step [221/225], Training Accuracy: 73.8900%, Training Loss: 0.5968%\n",
      "Epoch [32/300], Step [222/225], Training Accuracy: 73.8880%, Training Loss: 0.5967%\n",
      "Epoch [32/300], Step [223/225], Training Accuracy: 73.8509%, Training Loss: 0.5974%\n",
      "Epoch [32/300], Step [224/225], Training Accuracy: 73.8630%, Training Loss: 0.5972%\n",
      "Epoch [32/300], Step [225/225], Training Accuracy: 73.8605%, Training Loss: 0.5970%\n",
      "Epoch [33/300], Step [1/225], Training Accuracy: 81.2500%, Training Loss: 0.4641%\n",
      "Epoch [33/300], Step [2/225], Training Accuracy: 78.9062%, Training Loss: 0.4940%\n",
      "Epoch [33/300], Step [3/225], Training Accuracy: 74.4792%, Training Loss: 0.5847%\n",
      "Epoch [33/300], Step [4/225], Training Accuracy: 72.6562%, Training Loss: 0.6029%\n",
      "Epoch [33/300], Step [5/225], Training Accuracy: 71.5625%, Training Loss: 0.6035%\n",
      "Epoch [33/300], Step [6/225], Training Accuracy: 72.3958%, Training Loss: 0.5972%\n",
      "Epoch [33/300], Step [7/225], Training Accuracy: 72.3214%, Training Loss: 0.5985%\n",
      "Epoch [33/300], Step [8/225], Training Accuracy: 71.6797%, Training Loss: 0.6136%\n",
      "Epoch [33/300], Step [9/225], Training Accuracy: 72.7431%, Training Loss: 0.6060%\n",
      "Epoch [33/300], Step [10/225], Training Accuracy: 72.0312%, Training Loss: 0.6261%\n",
      "Epoch [33/300], Step [11/225], Training Accuracy: 72.0170%, Training Loss: 0.6228%\n",
      "Epoch [33/300], Step [12/225], Training Accuracy: 72.2656%, Training Loss: 0.6106%\n",
      "Epoch [33/300], Step [13/225], Training Accuracy: 72.9567%, Training Loss: 0.6000%\n",
      "Epoch [33/300], Step [14/225], Training Accuracy: 72.8795%, Training Loss: 0.5964%\n",
      "Epoch [33/300], Step [15/225], Training Accuracy: 73.1250%, Training Loss: 0.5946%\n",
      "Epoch [33/300], Step [16/225], Training Accuracy: 72.9492%, Training Loss: 0.5961%\n",
      "Epoch [33/300], Step [17/225], Training Accuracy: 73.4375%, Training Loss: 0.5891%\n",
      "Epoch [33/300], Step [18/225], Training Accuracy: 73.7847%, Training Loss: 0.5941%\n",
      "Epoch [33/300], Step [19/225], Training Accuracy: 74.0954%, Training Loss: 0.5916%\n",
      "Epoch [33/300], Step [20/225], Training Accuracy: 74.6094%, Training Loss: 0.5836%\n",
      "Epoch [33/300], Step [21/225], Training Accuracy: 74.6280%, Training Loss: 0.5837%\n",
      "Epoch [33/300], Step [22/225], Training Accuracy: 74.3608%, Training Loss: 0.5863%\n",
      "Epoch [33/300], Step [23/225], Training Accuracy: 74.5245%, Training Loss: 0.5814%\n",
      "Epoch [33/300], Step [24/225], Training Accuracy: 74.8047%, Training Loss: 0.5781%\n",
      "Epoch [33/300], Step [25/225], Training Accuracy: 74.6875%, Training Loss: 0.5786%\n",
      "Epoch [33/300], Step [26/225], Training Accuracy: 74.8197%, Training Loss: 0.5771%\n",
      "Epoch [33/300], Step [27/225], Training Accuracy: 74.8264%, Training Loss: 0.5797%\n",
      "Epoch [33/300], Step [28/225], Training Accuracy: 75.0000%, Training Loss: 0.5767%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/300], Step [29/225], Training Accuracy: 75.1616%, Training Loss: 0.5724%\n",
      "Epoch [33/300], Step [30/225], Training Accuracy: 75.3125%, Training Loss: 0.5695%\n",
      "Epoch [33/300], Step [31/225], Training Accuracy: 75.1008%, Training Loss: 0.5725%\n",
      "Epoch [33/300], Step [32/225], Training Accuracy: 74.9512%, Training Loss: 0.5735%\n",
      "Epoch [33/300], Step [33/225], Training Accuracy: 75.1420%, Training Loss: 0.5710%\n",
      "Epoch [33/300], Step [34/225], Training Accuracy: 75.0460%, Training Loss: 0.5753%\n",
      "Epoch [33/300], Step [35/225], Training Accuracy: 74.8214%, Training Loss: 0.5777%\n",
      "Epoch [33/300], Step [36/225], Training Accuracy: 74.6094%, Training Loss: 0.5819%\n",
      "Epoch [33/300], Step [37/225], Training Accuracy: 74.4932%, Training Loss: 0.5816%\n",
      "Epoch [33/300], Step [38/225], Training Accuracy: 74.5888%, Training Loss: 0.5805%\n",
      "Epoch [33/300], Step [39/225], Training Accuracy: 74.4792%, Training Loss: 0.5847%\n",
      "Epoch [33/300], Step [40/225], Training Accuracy: 74.6484%, Training Loss: 0.5830%\n",
      "Epoch [33/300], Step [41/225], Training Accuracy: 74.5046%, Training Loss: 0.5851%\n",
      "Epoch [33/300], Step [42/225], Training Accuracy: 74.4048%, Training Loss: 0.5860%\n",
      "Epoch [33/300], Step [43/225], Training Accuracy: 74.4186%, Training Loss: 0.5863%\n",
      "Epoch [33/300], Step [44/225], Training Accuracy: 74.5739%, Training Loss: 0.5827%\n",
      "Epoch [33/300], Step [45/225], Training Accuracy: 74.6181%, Training Loss: 0.5826%\n",
      "Epoch [33/300], Step [46/225], Training Accuracy: 74.5245%, Training Loss: 0.5834%\n",
      "Epoch [33/300], Step [47/225], Training Accuracy: 74.4348%, Training Loss: 0.5877%\n",
      "Epoch [33/300], Step [48/225], Training Accuracy: 74.5117%, Training Loss: 0.5852%\n",
      "Epoch [33/300], Step [49/225], Training Accuracy: 74.4579%, Training Loss: 0.5839%\n",
      "Epoch [33/300], Step [50/225], Training Accuracy: 74.3125%, Training Loss: 0.5861%\n",
      "Epoch [33/300], Step [51/225], Training Accuracy: 74.4485%, Training Loss: 0.5860%\n",
      "Epoch [33/300], Step [52/225], Training Accuracy: 74.7296%, Training Loss: 0.5828%\n",
      "Epoch [33/300], Step [53/225], Training Accuracy: 74.6167%, Training Loss: 0.5849%\n",
      "Epoch [33/300], Step [54/225], Training Accuracy: 74.5949%, Training Loss: 0.5883%\n",
      "Epoch [33/300], Step [55/225], Training Accuracy: 74.5170%, Training Loss: 0.5913%\n",
      "Epoch [33/300], Step [56/225], Training Accuracy: 74.5536%, Training Loss: 0.5903%\n",
      "Epoch [33/300], Step [57/225], Training Accuracy: 74.4792%, Training Loss: 0.5900%\n",
      "Epoch [33/300], Step [58/225], Training Accuracy: 74.3265%, Training Loss: 0.5921%\n",
      "Epoch [33/300], Step [59/225], Training Accuracy: 74.1525%, Training Loss: 0.5946%\n",
      "Epoch [33/300], Step [60/225], Training Accuracy: 74.1406%, Training Loss: 0.5947%\n",
      "Epoch [33/300], Step [61/225], Training Accuracy: 73.9754%, Training Loss: 0.5954%\n",
      "Epoch [33/300], Step [62/225], Training Accuracy: 74.0927%, Training Loss: 0.5949%\n",
      "Epoch [33/300], Step [63/225], Training Accuracy: 74.0327%, Training Loss: 0.5958%\n",
      "Epoch [33/300], Step [64/225], Training Accuracy: 74.0967%, Training Loss: 0.5948%\n",
      "Epoch [33/300], Step [65/225], Training Accuracy: 74.0865%, Training Loss: 0.5948%\n",
      "Epoch [33/300], Step [66/225], Training Accuracy: 74.1241%, Training Loss: 0.5931%\n",
      "Epoch [33/300], Step [67/225], Training Accuracy: 73.9272%, Training Loss: 0.5953%\n",
      "Epoch [33/300], Step [68/225], Training Accuracy: 73.9890%, Training Loss: 0.5950%\n",
      "Epoch [33/300], Step [69/225], Training Accuracy: 73.9357%, Training Loss: 0.5961%\n",
      "Epoch [33/300], Step [70/225], Training Accuracy: 73.8616%, Training Loss: 0.5970%\n",
      "Epoch [33/300], Step [71/225], Training Accuracy: 73.7896%, Training Loss: 0.5965%\n",
      "Epoch [33/300], Step [72/225], Training Accuracy: 73.8064%, Training Loss: 0.5973%\n",
      "Epoch [33/300], Step [73/225], Training Accuracy: 73.8656%, Training Loss: 0.5957%\n",
      "Epoch [33/300], Step [74/225], Training Accuracy: 73.9865%, Training Loss: 0.5936%\n",
      "Epoch [33/300], Step [75/225], Training Accuracy: 73.8958%, Training Loss: 0.5949%\n",
      "Epoch [33/300], Step [76/225], Training Accuracy: 73.8076%, Training Loss: 0.5970%\n",
      "Epoch [33/300], Step [77/225], Training Accuracy: 73.9448%, Training Loss: 0.5958%\n",
      "Epoch [33/300], Step [78/225], Training Accuracy: 74.1186%, Training Loss: 0.5940%\n",
      "Epoch [33/300], Step [79/225], Training Accuracy: 74.2484%, Training Loss: 0.5917%\n",
      "Epoch [33/300], Step [80/225], Training Accuracy: 74.1797%, Training Loss: 0.5920%\n",
      "Epoch [33/300], Step [81/225], Training Accuracy: 74.1705%, Training Loss: 0.5917%\n",
      "Epoch [33/300], Step [82/225], Training Accuracy: 74.1425%, Training Loss: 0.5923%\n",
      "Epoch [33/300], Step [83/225], Training Accuracy: 74.0776%, Training Loss: 0.5938%\n",
      "Epoch [33/300], Step [84/225], Training Accuracy: 74.1443%, Training Loss: 0.5933%\n",
      "Epoch [33/300], Step [85/225], Training Accuracy: 74.1728%, Training Loss: 0.5939%\n",
      "Epoch [33/300], Step [86/225], Training Accuracy: 74.2914%, Training Loss: 0.5920%\n",
      "Epoch [33/300], Step [87/225], Training Accuracy: 74.2277%, Training Loss: 0.5934%\n",
      "Epoch [33/300], Step [88/225], Training Accuracy: 74.2365%, Training Loss: 0.5935%\n",
      "Epoch [33/300], Step [89/225], Training Accuracy: 74.1573%, Training Loss: 0.5942%\n",
      "Epoch [33/300], Step [90/225], Training Accuracy: 74.1146%, Training Loss: 0.5955%\n",
      "Epoch [33/300], Step [91/225], Training Accuracy: 74.1071%, Training Loss: 0.5951%\n",
      "Epoch [33/300], Step [92/225], Training Accuracy: 74.1168%, Training Loss: 0.5956%\n",
      "Epoch [33/300], Step [93/225], Training Accuracy: 74.2608%, Training Loss: 0.5930%\n",
      "Epoch [33/300], Step [94/225], Training Accuracy: 74.3019%, Training Loss: 0.5928%\n",
      "Epoch [33/300], Step [95/225], Training Accuracy: 74.2763%, Training Loss: 0.5936%\n",
      "Epoch [33/300], Step [96/225], Training Accuracy: 74.2676%, Training Loss: 0.5924%\n",
      "Epoch [33/300], Step [97/225], Training Accuracy: 74.2751%, Training Loss: 0.5921%\n",
      "Epoch [33/300], Step [98/225], Training Accuracy: 74.3463%, Training Loss: 0.5907%\n",
      "Epoch [33/300], Step [99/225], Training Accuracy: 74.3529%, Training Loss: 0.5900%\n",
      "Epoch [33/300], Step [100/225], Training Accuracy: 74.3125%, Training Loss: 0.5903%\n",
      "Epoch [33/300], Step [101/225], Training Accuracy: 74.3502%, Training Loss: 0.5897%\n",
      "Epoch [33/300], Step [102/225], Training Accuracy: 74.3566%, Training Loss: 0.5892%\n",
      "Epoch [33/300], Step [103/225], Training Accuracy: 74.4539%, Training Loss: 0.5881%\n",
      "Epoch [33/300], Step [104/225], Training Accuracy: 74.4141%, Training Loss: 0.5888%\n",
      "Epoch [33/300], Step [105/225], Training Accuracy: 74.4048%, Training Loss: 0.5881%\n",
      "Epoch [33/300], Step [106/225], Training Accuracy: 74.3809%, Training Loss: 0.5884%\n",
      "Epoch [33/300], Step [107/225], Training Accuracy: 74.3867%, Training Loss: 0.5883%\n",
      "Epoch [33/300], Step [108/225], Training Accuracy: 74.3924%, Training Loss: 0.5884%\n",
      "Epoch [33/300], Step [109/225], Training Accuracy: 74.3693%, Training Loss: 0.5879%\n",
      "Epoch [33/300], Step [110/225], Training Accuracy: 74.3750%, Training Loss: 0.5872%\n",
      "Epoch [33/300], Step [111/225], Training Accuracy: 74.4510%, Training Loss: 0.5864%\n",
      "Epoch [33/300], Step [112/225], Training Accuracy: 74.4280%, Training Loss: 0.5854%\n",
      "Epoch [33/300], Step [113/225], Training Accuracy: 74.4469%, Training Loss: 0.5855%\n",
      "Epoch [33/300], Step [114/225], Training Accuracy: 74.4518%, Training Loss: 0.5850%\n",
      "Epoch [33/300], Step [115/225], Training Accuracy: 74.4022%, Training Loss: 0.5852%\n",
      "Epoch [33/300], Step [116/225], Training Accuracy: 74.4073%, Training Loss: 0.5855%\n",
      "Epoch [33/300], Step [117/225], Training Accuracy: 74.3323%, Training Loss: 0.5872%\n",
      "Epoch [33/300], Step [118/225], Training Accuracy: 74.4174%, Training Loss: 0.5865%\n",
      "Epoch [33/300], Step [119/225], Training Accuracy: 74.4223%, Training Loss: 0.5862%\n",
      "Epoch [33/300], Step [120/225], Training Accuracy: 74.4010%, Training Loss: 0.5871%\n",
      "Epoch [33/300], Step [121/225], Training Accuracy: 74.3285%, Training Loss: 0.5876%\n",
      "Epoch [33/300], Step [122/225], Training Accuracy: 74.3596%, Training Loss: 0.5874%\n",
      "Epoch [33/300], Step [123/225], Training Accuracy: 74.3394%, Training Loss: 0.5882%\n",
      "Epoch [33/300], Step [124/225], Training Accuracy: 74.3196%, Training Loss: 0.5880%\n",
      "Epoch [33/300], Step [125/225], Training Accuracy: 74.2875%, Training Loss: 0.5882%\n",
      "Epoch [33/300], Step [126/225], Training Accuracy: 74.2684%, Training Loss: 0.5879%\n",
      "Epoch [33/300], Step [127/225], Training Accuracy: 74.3110%, Training Loss: 0.5871%\n",
      "Epoch [33/300], Step [128/225], Training Accuracy: 74.2920%, Training Loss: 0.5874%\n",
      "Epoch [33/300], Step [129/225], Training Accuracy: 74.3217%, Training Loss: 0.5871%\n",
      "Epoch [33/300], Step [130/225], Training Accuracy: 74.3630%, Training Loss: 0.5867%\n",
      "Epoch [33/300], Step [131/225], Training Accuracy: 74.3678%, Training Loss: 0.5875%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/300], Step [132/225], Training Accuracy: 74.2661%, Training Loss: 0.5890%\n",
      "Epoch [33/300], Step [133/225], Training Accuracy: 74.2599%, Training Loss: 0.5882%\n",
      "Epoch [33/300], Step [134/225], Training Accuracy: 74.1721%, Training Loss: 0.5898%\n",
      "Epoch [33/300], Step [135/225], Training Accuracy: 74.2014%, Training Loss: 0.5894%\n",
      "Epoch [33/300], Step [136/225], Training Accuracy: 74.1613%, Training Loss: 0.5897%\n",
      "Epoch [33/300], Step [137/225], Training Accuracy: 74.1560%, Training Loss: 0.5898%\n",
      "Epoch [33/300], Step [138/225], Training Accuracy: 74.2414%, Training Loss: 0.5881%\n",
      "Epoch [33/300], Step [139/225], Training Accuracy: 74.2244%, Training Loss: 0.5882%\n",
      "Epoch [33/300], Step [140/225], Training Accuracy: 74.2411%, Training Loss: 0.5880%\n",
      "Epoch [33/300], Step [141/225], Training Accuracy: 74.2908%, Training Loss: 0.5876%\n",
      "Epoch [33/300], Step [142/225], Training Accuracy: 74.3068%, Training Loss: 0.5870%\n",
      "Epoch [33/300], Step [143/225], Training Accuracy: 74.3116%, Training Loss: 0.5866%\n",
      "Epoch [33/300], Step [144/225], Training Accuracy: 74.3490%, Training Loss: 0.5862%\n",
      "Epoch [33/300], Step [145/225], Training Accuracy: 74.3319%, Training Loss: 0.5862%\n",
      "Epoch [33/300], Step [146/225], Training Accuracy: 74.3472%, Training Loss: 0.5861%\n",
      "Epoch [33/300], Step [147/225], Training Accuracy: 74.3304%, Training Loss: 0.5862%\n",
      "Epoch [33/300], Step [148/225], Training Accuracy: 74.4405%, Training Loss: 0.5845%\n",
      "Epoch [33/300], Step [149/225], Training Accuracy: 74.4862%, Training Loss: 0.5841%\n",
      "Epoch [33/300], Step [150/225], Training Accuracy: 74.5000%, Training Loss: 0.5836%\n",
      "Epoch [33/300], Step [151/225], Training Accuracy: 74.5240%, Training Loss: 0.5833%\n",
      "Epoch [33/300], Step [152/225], Training Accuracy: 74.5169%, Training Loss: 0.5832%\n",
      "Epoch [33/300], Step [153/225], Training Accuracy: 74.5098%, Training Loss: 0.5838%\n",
      "Epoch [33/300], Step [154/225], Training Accuracy: 74.4927%, Training Loss: 0.5838%\n",
      "Epoch [33/300], Step [155/225], Training Accuracy: 74.5262%, Training Loss: 0.5828%\n",
      "Epoch [33/300], Step [156/225], Training Accuracy: 74.5192%, Training Loss: 0.5829%\n",
      "Epoch [33/300], Step [157/225], Training Accuracy: 74.5223%, Training Loss: 0.5829%\n",
      "Epoch [33/300], Step [158/225], Training Accuracy: 74.5154%, Training Loss: 0.5835%\n",
      "Epoch [33/300], Step [159/225], Training Accuracy: 74.4595%, Training Loss: 0.5836%\n",
      "Epoch [33/300], Step [160/225], Training Accuracy: 74.4629%, Training Loss: 0.5836%\n",
      "Epoch [33/300], Step [161/225], Training Accuracy: 74.4371%, Training Loss: 0.5840%\n",
      "Epoch [33/300], Step [162/225], Training Accuracy: 74.4502%, Training Loss: 0.5846%\n",
      "Epoch [33/300], Step [163/225], Training Accuracy: 74.4153%, Training Loss: 0.5851%\n",
      "Epoch [33/300], Step [164/225], Training Accuracy: 74.4379%, Training Loss: 0.5843%\n",
      "Epoch [33/300], Step [165/225], Training Accuracy: 74.4413%, Training Loss: 0.5842%\n",
      "Epoch [33/300], Step [166/225], Training Accuracy: 74.4070%, Training Loss: 0.5845%\n",
      "Epoch [33/300], Step [167/225], Training Accuracy: 74.4106%, Training Loss: 0.5844%\n",
      "Epoch [33/300], Step [168/225], Training Accuracy: 74.4141%, Training Loss: 0.5846%\n",
      "Epoch [33/300], Step [169/225], Training Accuracy: 74.4453%, Training Loss: 0.5841%\n",
      "Epoch [33/300], Step [170/225], Training Accuracy: 74.4577%, Training Loss: 0.5837%\n",
      "Epoch [33/300], Step [171/225], Training Accuracy: 74.4518%, Training Loss: 0.5840%\n",
      "Epoch [33/300], Step [172/225], Training Accuracy: 74.4549%, Training Loss: 0.5842%\n",
      "Epoch [33/300], Step [173/225], Training Accuracy: 74.4762%, Training Loss: 0.5839%\n",
      "Epoch [33/300], Step [174/225], Training Accuracy: 74.4881%, Training Loss: 0.5835%\n",
      "Epoch [33/300], Step [175/225], Training Accuracy: 74.4732%, Training Loss: 0.5838%\n",
      "Epoch [33/300], Step [176/225], Training Accuracy: 74.5028%, Training Loss: 0.5832%\n",
      "Epoch [33/300], Step [177/225], Training Accuracy: 74.4703%, Training Loss: 0.5835%\n",
      "Epoch [33/300], Step [178/225], Training Accuracy: 74.4558%, Training Loss: 0.5838%\n",
      "Epoch [33/300], Step [179/225], Training Accuracy: 74.4588%, Training Loss: 0.5836%\n",
      "Epoch [33/300], Step [180/225], Training Accuracy: 74.4531%, Training Loss: 0.5840%\n",
      "Epoch [33/300], Step [181/225], Training Accuracy: 74.4561%, Training Loss: 0.5846%\n",
      "Epoch [33/300], Step [182/225], Training Accuracy: 74.4248%, Training Loss: 0.5856%\n",
      "Epoch [33/300], Step [183/225], Training Accuracy: 74.4365%, Training Loss: 0.5856%\n",
      "Epoch [33/300], Step [184/225], Training Accuracy: 74.4650%, Training Loss: 0.5847%\n",
      "Epoch [33/300], Step [185/225], Training Accuracy: 74.4679%, Training Loss: 0.5845%\n",
      "Epoch [33/300], Step [186/225], Training Accuracy: 74.5212%, Training Loss: 0.5836%\n",
      "Epoch [33/300], Step [187/225], Training Accuracy: 74.5237%, Training Loss: 0.5835%\n",
      "Epoch [33/300], Step [188/225], Training Accuracy: 74.5678%, Training Loss: 0.5828%\n",
      "Epoch [33/300], Step [189/225], Training Accuracy: 74.6032%, Training Loss: 0.5819%\n",
      "Epoch [33/300], Step [190/225], Training Accuracy: 74.6382%, Training Loss: 0.5818%\n",
      "Epoch [33/300], Step [191/225], Training Accuracy: 74.6073%, Training Loss: 0.5820%\n",
      "Epoch [33/300], Step [192/225], Training Accuracy: 74.6338%, Training Loss: 0.5817%\n",
      "Epoch [33/300], Step [193/225], Training Accuracy: 74.6438%, Training Loss: 0.5815%\n",
      "Epoch [33/300], Step [194/225], Training Accuracy: 74.6053%, Training Loss: 0.5821%\n",
      "Epoch [33/300], Step [195/225], Training Accuracy: 74.6554%, Training Loss: 0.5813%\n",
      "Epoch [33/300], Step [196/225], Training Accuracy: 74.6413%, Training Loss: 0.5816%\n",
      "Epoch [33/300], Step [197/225], Training Accuracy: 74.6034%, Training Loss: 0.5820%\n",
      "Epoch [33/300], Step [198/225], Training Accuracy: 74.6291%, Training Loss: 0.5815%\n",
      "Epoch [33/300], Step [199/225], Training Accuracy: 74.6231%, Training Loss: 0.5814%\n",
      "Epoch [33/300], Step [200/225], Training Accuracy: 74.6328%, Training Loss: 0.5819%\n",
      "Epoch [33/300], Step [201/225], Training Accuracy: 74.5802%, Training Loss: 0.5822%\n",
      "Epoch [33/300], Step [202/225], Training Accuracy: 74.5900%, Training Loss: 0.5821%\n",
      "Epoch [33/300], Step [203/225], Training Accuracy: 74.6228%, Training Loss: 0.5814%\n",
      "Epoch [33/300], Step [204/225], Training Accuracy: 74.6400%, Training Loss: 0.5812%\n",
      "Epoch [33/300], Step [205/225], Training Accuracy: 74.6723%, Training Loss: 0.5807%\n",
      "Epoch [33/300], Step [206/225], Training Accuracy: 74.6738%, Training Loss: 0.5807%\n",
      "Epoch [33/300], Step [207/225], Training Accuracy: 74.6830%, Training Loss: 0.5810%\n",
      "Epoch [33/300], Step [208/225], Training Accuracy: 74.7296%, Training Loss: 0.5803%\n",
      "Epoch [33/300], Step [209/225], Training Accuracy: 74.7159%, Training Loss: 0.5808%\n",
      "Epoch [33/300], Step [210/225], Training Accuracy: 74.6875%, Training Loss: 0.5815%\n",
      "Epoch [33/300], Step [211/225], Training Accuracy: 74.6964%, Training Loss: 0.5824%\n",
      "Epoch [33/300], Step [212/225], Training Accuracy: 74.6610%, Training Loss: 0.5827%\n",
      "Epoch [33/300], Step [213/225], Training Accuracy: 74.6332%, Training Loss: 0.5833%\n",
      "Epoch [33/300], Step [214/225], Training Accuracy: 74.6276%, Training Loss: 0.5835%\n",
      "Epoch [33/300], Step [215/225], Training Accuracy: 74.6366%, Training Loss: 0.5836%\n",
      "Epoch [33/300], Step [216/225], Training Accuracy: 74.6455%, Training Loss: 0.5833%\n",
      "Epoch [33/300], Step [217/225], Training Accuracy: 74.6256%, Training Loss: 0.5841%\n",
      "Epoch [33/300], Step [218/225], Training Accuracy: 74.5771%, Training Loss: 0.5852%\n",
      "Epoch [33/300], Step [219/225], Training Accuracy: 74.5434%, Training Loss: 0.5860%\n",
      "Epoch [33/300], Step [220/225], Training Accuracy: 74.5668%, Training Loss: 0.5853%\n",
      "Epoch [33/300], Step [221/225], Training Accuracy: 74.5758%, Training Loss: 0.5851%\n",
      "Epoch [33/300], Step [222/225], Training Accuracy: 74.5636%, Training Loss: 0.5856%\n",
      "Epoch [33/300], Step [223/225], Training Accuracy: 74.5516%, Training Loss: 0.5856%\n",
      "Epoch [33/300], Step [224/225], Training Accuracy: 74.5745%, Training Loss: 0.5853%\n",
      "Epoch [33/300], Step [225/225], Training Accuracy: 74.5623%, Training Loss: 0.5852%\n",
      "Epoch [34/300], Step [1/225], Training Accuracy: 68.7500%, Training Loss: 0.6515%\n",
      "Epoch [34/300], Step [2/225], Training Accuracy: 70.3125%, Training Loss: 0.6266%\n",
      "Epoch [34/300], Step [3/225], Training Accuracy: 70.3125%, Training Loss: 0.6854%\n",
      "Epoch [34/300], Step [4/225], Training Accuracy: 69.5312%, Training Loss: 0.7170%\n",
      "Epoch [34/300], Step [5/225], Training Accuracy: 71.2500%, Training Loss: 0.6733%\n",
      "Epoch [34/300], Step [6/225], Training Accuracy: 70.3125%, Training Loss: 0.6829%\n",
      "Epoch [34/300], Step [7/225], Training Accuracy: 70.0893%, Training Loss: 0.6795%\n",
      "Epoch [34/300], Step [8/225], Training Accuracy: 70.8984%, Training Loss: 0.6777%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/300], Step [9/225], Training Accuracy: 71.0069%, Training Loss: 0.6859%\n",
      "Epoch [34/300], Step [10/225], Training Accuracy: 69.8438%, Training Loss: 0.6888%\n",
      "Epoch [34/300], Step [11/225], Training Accuracy: 70.0284%, Training Loss: 0.6831%\n",
      "Epoch [34/300], Step [12/225], Training Accuracy: 70.4427%, Training Loss: 0.6748%\n",
      "Epoch [34/300], Step [13/225], Training Accuracy: 70.4327%, Training Loss: 0.6662%\n",
      "Epoch [34/300], Step [14/225], Training Accuracy: 70.6473%, Training Loss: 0.6683%\n",
      "Epoch [34/300], Step [15/225], Training Accuracy: 71.1458%, Training Loss: 0.6602%\n",
      "Epoch [34/300], Step [16/225], Training Accuracy: 70.9961%, Training Loss: 0.6570%\n",
      "Epoch [34/300], Step [17/225], Training Accuracy: 71.5993%, Training Loss: 0.6449%\n",
      "Epoch [34/300], Step [18/225], Training Accuracy: 71.8750%, Training Loss: 0.6435%\n",
      "Epoch [34/300], Step [19/225], Training Accuracy: 71.4638%, Training Loss: 0.6555%\n",
      "Epoch [34/300], Step [20/225], Training Accuracy: 72.2656%, Training Loss: 0.6445%\n",
      "Epoch [34/300], Step [21/225], Training Accuracy: 72.6935%, Training Loss: 0.6359%\n",
      "Epoch [34/300], Step [22/225], Training Accuracy: 72.7273%, Training Loss: 0.6370%\n",
      "Epoch [34/300], Step [23/225], Training Accuracy: 72.8261%, Training Loss: 0.6351%\n",
      "Epoch [34/300], Step [24/225], Training Accuracy: 72.9167%, Training Loss: 0.6359%\n",
      "Epoch [34/300], Step [25/225], Training Accuracy: 72.9375%, Training Loss: 0.6356%\n",
      "Epoch [34/300], Step [26/225], Training Accuracy: 72.8966%, Training Loss: 0.6328%\n",
      "Epoch [34/300], Step [27/225], Training Accuracy: 72.9167%, Training Loss: 0.6335%\n",
      "Epoch [34/300], Step [28/225], Training Accuracy: 72.7679%, Training Loss: 0.6356%\n",
      "Epoch [34/300], Step [29/225], Training Accuracy: 72.9526%, Training Loss: 0.6317%\n",
      "Epoch [34/300], Step [30/225], Training Accuracy: 73.0729%, Training Loss: 0.6298%\n",
      "Epoch [34/300], Step [31/225], Training Accuracy: 72.9839%, Training Loss: 0.6317%\n",
      "Epoch [34/300], Step [32/225], Training Accuracy: 72.9492%, Training Loss: 0.6305%\n",
      "Epoch [34/300], Step [33/225], Training Accuracy: 73.0587%, Training Loss: 0.6297%\n",
      "Epoch [34/300], Step [34/225], Training Accuracy: 72.6562%, Training Loss: 0.6386%\n",
      "Epoch [34/300], Step [35/225], Training Accuracy: 72.7232%, Training Loss: 0.6381%\n",
      "Epoch [34/300], Step [36/225], Training Accuracy: 72.6128%, Training Loss: 0.6415%\n",
      "Epoch [34/300], Step [37/225], Training Accuracy: 72.5929%, Training Loss: 0.6412%\n",
      "Epoch [34/300], Step [38/225], Training Accuracy: 72.6562%, Training Loss: 0.6394%\n",
      "Epoch [34/300], Step [39/225], Training Accuracy: 72.7163%, Training Loss: 0.6393%\n",
      "Epoch [34/300], Step [40/225], Training Accuracy: 72.7734%, Training Loss: 0.6352%\n",
      "Epoch [34/300], Step [41/225], Training Accuracy: 72.5610%, Training Loss: 0.6356%\n",
      "Epoch [34/300], Step [42/225], Training Accuracy: 72.3214%, Training Loss: 0.6392%\n",
      "Epoch [34/300], Step [43/225], Training Accuracy: 72.4564%, Training Loss: 0.6358%\n",
      "Epoch [34/300], Step [44/225], Training Accuracy: 72.7273%, Training Loss: 0.6323%\n",
      "Epoch [34/300], Step [45/225], Training Accuracy: 72.8472%, Training Loss: 0.6311%\n",
      "Epoch [34/300], Step [46/225], Training Accuracy: 72.9620%, Training Loss: 0.6280%\n",
      "Epoch [34/300], Step [47/225], Training Accuracy: 72.9388%, Training Loss: 0.6273%\n",
      "Epoch [34/300], Step [48/225], Training Accuracy: 73.0794%, Training Loss: 0.6250%\n",
      "Epoch [34/300], Step [49/225], Training Accuracy: 73.1186%, Training Loss: 0.6258%\n",
      "Epoch [34/300], Step [50/225], Training Accuracy: 73.2812%, Training Loss: 0.6233%\n",
      "Epoch [34/300], Step [51/225], Training Accuracy: 73.4375%, Training Loss: 0.6203%\n",
      "Epoch [34/300], Step [52/225], Training Accuracy: 73.6478%, Training Loss: 0.6157%\n",
      "Epoch [34/300], Step [53/225], Training Accuracy: 73.7323%, Training Loss: 0.6142%\n",
      "Epoch [34/300], Step [54/225], Training Accuracy: 73.7847%, Training Loss: 0.6140%\n",
      "Epoch [34/300], Step [55/225], Training Accuracy: 73.7500%, Training Loss: 0.6155%\n",
      "Epoch [34/300], Step [56/225], Training Accuracy: 73.7165%, Training Loss: 0.6169%\n",
      "Epoch [34/300], Step [57/225], Training Accuracy: 73.6020%, Training Loss: 0.6174%\n",
      "Epoch [34/300], Step [58/225], Training Accuracy: 73.5453%, Training Loss: 0.6196%\n",
      "Epoch [34/300], Step [59/225], Training Accuracy: 73.3581%, Training Loss: 0.6237%\n",
      "Epoch [34/300], Step [60/225], Training Accuracy: 73.4375%, Training Loss: 0.6228%\n",
      "Epoch [34/300], Step [61/225], Training Accuracy: 73.4119%, Training Loss: 0.6229%\n",
      "Epoch [34/300], Step [62/225], Training Accuracy: 73.5131%, Training Loss: 0.6210%\n",
      "Epoch [34/300], Step [63/225], Training Accuracy: 73.5863%, Training Loss: 0.6193%\n",
      "Epoch [34/300], Step [64/225], Training Accuracy: 73.7061%, Training Loss: 0.6163%\n",
      "Epoch [34/300], Step [65/225], Training Accuracy: 73.7981%, Training Loss: 0.6147%\n",
      "Epoch [34/300], Step [66/225], Training Accuracy: 73.7689%, Training Loss: 0.6147%\n",
      "Epoch [34/300], Step [67/225], Training Accuracy: 73.7407%, Training Loss: 0.6140%\n",
      "Epoch [34/300], Step [68/225], Training Accuracy: 73.6903%, Training Loss: 0.6141%\n",
      "Epoch [34/300], Step [69/225], Training Accuracy: 73.7092%, Training Loss: 0.6128%\n",
      "Epoch [34/300], Step [70/225], Training Accuracy: 73.6384%, Training Loss: 0.6135%\n",
      "Epoch [34/300], Step [71/225], Training Accuracy: 73.7236%, Training Loss: 0.6116%\n",
      "Epoch [34/300], Step [72/225], Training Accuracy: 73.7630%, Training Loss: 0.6101%\n",
      "Epoch [34/300], Step [73/225], Training Accuracy: 73.8442%, Training Loss: 0.6091%\n",
      "Epoch [34/300], Step [74/225], Training Accuracy: 73.9231%, Training Loss: 0.6073%\n",
      "Epoch [34/300], Step [75/225], Training Accuracy: 73.8542%, Training Loss: 0.6090%\n",
      "Epoch [34/300], Step [76/225], Training Accuracy: 73.8281%, Training Loss: 0.6095%\n",
      "Epoch [34/300], Step [77/225], Training Accuracy: 73.7419%, Training Loss: 0.6104%\n",
      "Epoch [34/300], Step [78/225], Training Accuracy: 73.8181%, Training Loss: 0.6082%\n",
      "Epoch [34/300], Step [79/225], Training Accuracy: 73.7540%, Training Loss: 0.6092%\n",
      "Epoch [34/300], Step [80/225], Training Accuracy: 73.7695%, Training Loss: 0.6083%\n",
      "Epoch [34/300], Step [81/225], Training Accuracy: 73.9390%, Training Loss: 0.6057%\n",
      "Epoch [34/300], Step [82/225], Training Accuracy: 74.0091%, Training Loss: 0.6041%\n",
      "Epoch [34/300], Step [83/225], Training Accuracy: 73.9646%, Training Loss: 0.6052%\n",
      "Epoch [34/300], Step [84/225], Training Accuracy: 73.9769%, Training Loss: 0.6041%\n",
      "Epoch [34/300], Step [85/225], Training Accuracy: 74.0074%, Training Loss: 0.6027%\n",
      "Epoch [34/300], Step [86/225], Training Accuracy: 74.0552%, Training Loss: 0.6017%\n",
      "Epoch [34/300], Step [87/225], Training Accuracy: 74.0122%, Training Loss: 0.6021%\n",
      "Epoch [34/300], Step [88/225], Training Accuracy: 74.0057%, Training Loss: 0.6032%\n",
      "Epoch [34/300], Step [89/225], Training Accuracy: 73.9993%, Training Loss: 0.6027%\n",
      "Epoch [34/300], Step [90/225], Training Accuracy: 73.9062%, Training Loss: 0.6042%\n",
      "Epoch [34/300], Step [91/225], Training Accuracy: 73.9011%, Training Loss: 0.6032%\n",
      "Epoch [34/300], Step [92/225], Training Accuracy: 73.8621%, Training Loss: 0.6044%\n",
      "Epoch [34/300], Step [93/225], Training Accuracy: 73.9415%, Training Loss: 0.6031%\n",
      "Epoch [34/300], Step [94/225], Training Accuracy: 74.0193%, Training Loss: 0.6022%\n",
      "Epoch [34/300], Step [95/225], Training Accuracy: 74.0789%, Training Loss: 0.6022%\n",
      "Epoch [34/300], Step [96/225], Training Accuracy: 74.0723%, Training Loss: 0.6015%\n",
      "Epoch [34/300], Step [97/225], Training Accuracy: 74.1302%, Training Loss: 0.6001%\n",
      "Epoch [34/300], Step [98/225], Training Accuracy: 74.2028%, Training Loss: 0.5993%\n",
      "Epoch [34/300], Step [99/225], Training Accuracy: 74.2424%, Training Loss: 0.5993%\n",
      "Epoch [34/300], Step [100/225], Training Accuracy: 74.2031%, Training Loss: 0.5997%\n",
      "Epoch [34/300], Step [101/225], Training Accuracy: 74.1801%, Training Loss: 0.6000%\n",
      "Epoch [34/300], Step [102/225], Training Accuracy: 74.1422%, Training Loss: 0.6008%\n",
      "Epoch [34/300], Step [103/225], Training Accuracy: 74.1808%, Training Loss: 0.6001%\n",
      "Epoch [34/300], Step [104/225], Training Accuracy: 74.1436%, Training Loss: 0.6003%\n",
      "Epoch [34/300], Step [105/225], Training Accuracy: 74.1815%, Training Loss: 0.5997%\n",
      "Epoch [34/300], Step [106/225], Training Accuracy: 74.0713%, Training Loss: 0.6010%\n",
      "Epoch [34/300], Step [107/225], Training Accuracy: 74.0654%, Training Loss: 0.6009%\n",
      "Epoch [34/300], Step [108/225], Training Accuracy: 74.1175%, Training Loss: 0.5999%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/300], Step [109/225], Training Accuracy: 74.0682%, Training Loss: 0.6003%\n",
      "Epoch [34/300], Step [110/225], Training Accuracy: 74.0625%, Training Loss: 0.6008%\n",
      "Epoch [34/300], Step [111/225], Training Accuracy: 74.0006%, Training Loss: 0.6014%\n",
      "Epoch [34/300], Step [112/225], Training Accuracy: 74.0095%, Training Loss: 0.6013%\n",
      "Epoch [34/300], Step [113/225], Training Accuracy: 74.0874%, Training Loss: 0.6010%\n",
      "Epoch [34/300], Step [114/225], Training Accuracy: 74.0954%, Training Loss: 0.6005%\n",
      "Epoch [34/300], Step [115/225], Training Accuracy: 74.0489%, Training Loss: 0.6017%\n",
      "Epoch [34/300], Step [116/225], Training Accuracy: 74.0436%, Training Loss: 0.6013%\n",
      "Epoch [34/300], Step [117/225], Training Accuracy: 73.9583%, Training Loss: 0.6022%\n",
      "Epoch [34/300], Step [118/225], Training Accuracy: 74.0201%, Training Loss: 0.6013%\n",
      "Epoch [34/300], Step [119/225], Training Accuracy: 74.0021%, Training Loss: 0.6009%\n",
      "Epoch [34/300], Step [120/225], Training Accuracy: 74.0104%, Training Loss: 0.6005%\n",
      "Epoch [34/300], Step [121/225], Training Accuracy: 74.0444%, Training Loss: 0.5999%\n",
      "Epoch [34/300], Step [122/225], Training Accuracy: 73.9882%, Training Loss: 0.6008%\n",
      "Epoch [34/300], Step [123/225], Training Accuracy: 73.9583%, Training Loss: 0.6009%\n",
      "Epoch [34/300], Step [124/225], Training Accuracy: 73.9541%, Training Loss: 0.6007%\n",
      "Epoch [34/300], Step [125/225], Training Accuracy: 73.9250%, Training Loss: 0.6016%\n",
      "Epoch [34/300], Step [126/225], Training Accuracy: 73.9459%, Training Loss: 0.6016%\n",
      "Epoch [34/300], Step [127/225], Training Accuracy: 73.9296%, Training Loss: 0.6017%\n",
      "Epoch [34/300], Step [128/225], Training Accuracy: 73.9136%, Training Loss: 0.6017%\n",
      "Epoch [34/300], Step [129/225], Training Accuracy: 73.9220%, Training Loss: 0.6012%\n",
      "Epoch [34/300], Step [130/225], Training Accuracy: 73.9062%, Training Loss: 0.6008%\n",
      "Epoch [34/300], Step [131/225], Training Accuracy: 73.8788%, Training Loss: 0.6010%\n",
      "Epoch [34/300], Step [132/225], Training Accuracy: 73.9228%, Training Loss: 0.6013%\n",
      "Epoch [34/300], Step [133/225], Training Accuracy: 73.9544%, Training Loss: 0.6011%\n",
      "Epoch [34/300], Step [134/225], Training Accuracy: 73.8456%, Training Loss: 0.6023%\n",
      "Epoch [34/300], Step [135/225], Training Accuracy: 73.8542%, Training Loss: 0.6018%\n",
      "Epoch [34/300], Step [136/225], Training Accuracy: 73.9085%, Training Loss: 0.6012%\n",
      "Epoch [34/300], Step [137/225], Training Accuracy: 73.8937%, Training Loss: 0.6018%\n",
      "Epoch [34/300], Step [138/225], Training Accuracy: 73.9583%, Training Loss: 0.6005%\n",
      "Epoch [34/300], Step [139/225], Training Accuracy: 73.9996%, Training Loss: 0.5999%\n",
      "Epoch [34/300], Step [140/225], Training Accuracy: 74.0402%, Training Loss: 0.5990%\n",
      "Epoch [34/300], Step [141/225], Training Accuracy: 74.0581%, Training Loss: 0.5983%\n",
      "Epoch [34/300], Step [142/225], Training Accuracy: 74.0537%, Training Loss: 0.5983%\n",
      "Epoch [34/300], Step [143/225], Training Accuracy: 74.0275%, Training Loss: 0.5987%\n",
      "Epoch [34/300], Step [144/225], Training Accuracy: 74.0234%, Training Loss: 0.5985%\n",
      "Epoch [34/300], Step [145/225], Training Accuracy: 74.0302%, Training Loss: 0.5983%\n",
      "Epoch [34/300], Step [146/225], Training Accuracy: 74.0047%, Training Loss: 0.5995%\n",
      "Epoch [34/300], Step [147/225], Training Accuracy: 73.9796%, Training Loss: 0.5998%\n",
      "Epoch [34/300], Step [148/225], Training Accuracy: 73.9759%, Training Loss: 0.5991%\n",
      "Epoch [34/300], Step [149/225], Training Accuracy: 73.9828%, Training Loss: 0.5994%\n",
      "Epoch [34/300], Step [150/225], Training Accuracy: 74.0104%, Training Loss: 0.5980%\n",
      "Epoch [34/300], Step [151/225], Training Accuracy: 74.0480%, Training Loss: 0.5974%\n",
      "Epoch [34/300], Step [152/225], Training Accuracy: 74.0646%, Training Loss: 0.5972%\n",
      "Epoch [34/300], Step [153/225], Training Accuracy: 74.0094%, Training Loss: 0.5977%\n",
      "Epoch [34/300], Step [154/225], Training Accuracy: 73.9854%, Training Loss: 0.5974%\n",
      "Epoch [34/300], Step [155/225], Training Accuracy: 74.0020%, Training Loss: 0.5976%\n",
      "Epoch [34/300], Step [156/225], Training Accuracy: 73.9784%, Training Loss: 0.5981%\n",
      "Epoch [34/300], Step [157/225], Training Accuracy: 73.9849%, Training Loss: 0.5977%\n",
      "Epoch [34/300], Step [158/225], Training Accuracy: 73.9814%, Training Loss: 0.5981%\n",
      "Epoch [34/300], Step [159/225], Training Accuracy: 73.9583%, Training Loss: 0.5989%\n",
      "Epoch [34/300], Step [160/225], Training Accuracy: 73.9551%, Training Loss: 0.5992%\n",
      "Epoch [34/300], Step [161/225], Training Accuracy: 73.9519%, Training Loss: 0.5989%\n",
      "Epoch [34/300], Step [162/225], Training Accuracy: 73.9969%, Training Loss: 0.5991%\n",
      "Epoch [34/300], Step [163/225], Training Accuracy: 74.0414%, Training Loss: 0.5983%\n",
      "Epoch [34/300], Step [164/225], Training Accuracy: 74.0377%, Training Loss: 0.5980%\n",
      "Epoch [34/300], Step [165/225], Training Accuracy: 74.0530%, Training Loss: 0.5983%\n",
      "Epoch [34/300], Step [166/225], Training Accuracy: 74.0399%, Training Loss: 0.5985%\n",
      "Epoch [34/300], Step [167/225], Training Accuracy: 74.0737%, Training Loss: 0.5977%\n",
      "Epoch [34/300], Step [168/225], Training Accuracy: 74.0699%, Training Loss: 0.5979%\n",
      "Epoch [34/300], Step [169/225], Training Accuracy: 74.1309%, Training Loss: 0.5965%\n",
      "Epoch [34/300], Step [170/225], Training Accuracy: 74.1544%, Training Loss: 0.5961%\n",
      "Epoch [34/300], Step [171/225], Training Accuracy: 74.1411%, Training Loss: 0.5959%\n",
      "Epoch [34/300], Step [172/225], Training Accuracy: 74.1097%, Training Loss: 0.5960%\n",
      "Epoch [34/300], Step [173/225], Training Accuracy: 74.1239%, Training Loss: 0.5968%\n",
      "Epoch [34/300], Step [174/225], Training Accuracy: 74.1200%, Training Loss: 0.5969%\n",
      "Epoch [34/300], Step [175/225], Training Accuracy: 74.1429%, Training Loss: 0.5967%\n",
      "Epoch [34/300], Step [176/225], Training Accuracy: 74.1566%, Training Loss: 0.5964%\n",
      "Epoch [34/300], Step [177/225], Training Accuracy: 74.1790%, Training Loss: 0.5961%\n",
      "Epoch [34/300], Step [178/225], Training Accuracy: 74.2012%, Training Loss: 0.5957%\n",
      "Epoch [34/300], Step [179/225], Training Accuracy: 74.2231%, Training Loss: 0.5951%\n",
      "Epoch [34/300], Step [180/225], Training Accuracy: 74.2795%, Training Loss: 0.5937%\n",
      "Epoch [34/300], Step [181/225], Training Accuracy: 74.2403%, Training Loss: 0.5941%\n",
      "Epoch [34/300], Step [182/225], Training Accuracy: 74.2703%, Training Loss: 0.5940%\n",
      "Epoch [34/300], Step [183/225], Training Accuracy: 74.2742%, Training Loss: 0.5940%\n",
      "Epoch [34/300], Step [184/225], Training Accuracy: 74.3122%, Training Loss: 0.5936%\n",
      "Epoch [34/300], Step [185/225], Training Accuracy: 74.3074%, Training Loss: 0.5934%\n",
      "Epoch [34/300], Step [186/225], Training Accuracy: 74.3364%, Training Loss: 0.5930%\n",
      "Epoch [34/300], Step [187/225], Training Accuracy: 74.3148%, Training Loss: 0.5933%\n",
      "Epoch [34/300], Step [188/225], Training Accuracy: 74.3517%, Training Loss: 0.5924%\n",
      "Epoch [34/300], Step [189/225], Training Accuracy: 74.3965%, Training Loss: 0.5915%\n",
      "Epoch [34/300], Step [190/225], Training Accuracy: 74.4326%, Training Loss: 0.5910%\n",
      "Epoch [34/300], Step [191/225], Training Accuracy: 74.4437%, Training Loss: 0.5913%\n",
      "Epoch [34/300], Step [192/225], Training Accuracy: 74.4385%, Training Loss: 0.5912%\n",
      "Epoch [34/300], Step [193/225], Training Accuracy: 74.4738%, Training Loss: 0.5908%\n",
      "Epoch [34/300], Step [194/225], Training Accuracy: 74.5006%, Training Loss: 0.5906%\n",
      "Epoch [34/300], Step [195/225], Training Accuracy: 74.5353%, Training Loss: 0.5900%\n",
      "Epoch [34/300], Step [196/225], Training Accuracy: 74.5057%, Training Loss: 0.5911%\n",
      "Epoch [34/300], Step [197/225], Training Accuracy: 74.5241%, Training Loss: 0.5911%\n",
      "Epoch [34/300], Step [198/225], Training Accuracy: 74.5581%, Training Loss: 0.5906%\n",
      "Epoch [34/300], Step [199/225], Training Accuracy: 74.5996%, Training Loss: 0.5898%\n",
      "Epoch [34/300], Step [200/225], Training Accuracy: 74.6094%, Training Loss: 0.5896%\n",
      "Epoch [34/300], Step [201/225], Training Accuracy: 74.5958%, Training Loss: 0.5896%\n",
      "Epoch [34/300], Step [202/225], Training Accuracy: 74.6210%, Training Loss: 0.5890%\n",
      "Epoch [34/300], Step [203/225], Training Accuracy: 74.6613%, Training Loss: 0.5883%\n",
      "Epoch [34/300], Step [204/225], Training Accuracy: 74.6860%, Training Loss: 0.5884%\n",
      "Epoch [34/300], Step [205/225], Training Accuracy: 74.6723%, Training Loss: 0.5886%\n",
      "Epoch [34/300], Step [206/225], Training Accuracy: 74.7042%, Training Loss: 0.5884%\n",
      "Epoch [34/300], Step [207/225], Training Accuracy: 74.7056%, Training Loss: 0.5882%\n",
      "Epoch [34/300], Step [208/225], Training Accuracy: 74.7446%, Training Loss: 0.5879%\n",
      "Epoch [34/300], Step [209/225], Training Accuracy: 74.7084%, Training Loss: 0.5887%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/300], Step [210/225], Training Accuracy: 74.7024%, Training Loss: 0.5886%\n",
      "Epoch [34/300], Step [211/225], Training Accuracy: 74.7260%, Training Loss: 0.5884%\n",
      "Epoch [34/300], Step [212/225], Training Accuracy: 74.7273%, Training Loss: 0.5887%\n",
      "Epoch [34/300], Step [213/225], Training Accuracy: 74.6992%, Training Loss: 0.5892%\n",
      "Epoch [34/300], Step [214/225], Training Accuracy: 74.7225%, Training Loss: 0.5887%\n",
      "Epoch [34/300], Step [215/225], Training Accuracy: 74.7384%, Training Loss: 0.5884%\n",
      "Epoch [34/300], Step [216/225], Training Accuracy: 74.7106%, Training Loss: 0.5887%\n",
      "Epoch [34/300], Step [217/225], Training Accuracy: 74.6904%, Training Loss: 0.5887%\n",
      "Epoch [34/300], Step [218/225], Training Accuracy: 74.6703%, Training Loss: 0.5891%\n",
      "Epoch [34/300], Step [219/225], Training Accuracy: 74.6433%, Training Loss: 0.5896%\n",
      "Epoch [34/300], Step [220/225], Training Accuracy: 74.6449%, Training Loss: 0.5891%\n",
      "Epoch [34/300], Step [221/225], Training Accuracy: 74.6536%, Training Loss: 0.5889%\n",
      "Epoch [34/300], Step [222/225], Training Accuracy: 74.6481%, Training Loss: 0.5895%\n",
      "Epoch [34/300], Step [223/225], Training Accuracy: 74.6427%, Training Loss: 0.5896%\n",
      "Epoch [34/300], Step [224/225], Training Accuracy: 74.6512%, Training Loss: 0.5891%\n",
      "Epoch [34/300], Step [225/225], Training Accuracy: 74.6595%, Training Loss: 0.5888%\n",
      "Epoch [35/300], Step [1/225], Training Accuracy: 73.4375%, Training Loss: 0.5684%\n",
      "Epoch [35/300], Step [2/225], Training Accuracy: 72.6562%, Training Loss: 0.6197%\n",
      "Epoch [35/300], Step [3/225], Training Accuracy: 73.4375%, Training Loss: 0.6197%\n",
      "Epoch [35/300], Step [4/225], Training Accuracy: 73.0469%, Training Loss: 0.5867%\n",
      "Epoch [35/300], Step [5/225], Training Accuracy: 74.3750%, Training Loss: 0.5714%\n",
      "Epoch [35/300], Step [6/225], Training Accuracy: 75.0000%, Training Loss: 0.5629%\n",
      "Epoch [35/300], Step [7/225], Training Accuracy: 75.2232%, Training Loss: 0.5606%\n",
      "Epoch [35/300], Step [8/225], Training Accuracy: 75.1953%, Training Loss: 0.5760%\n",
      "Epoch [35/300], Step [9/225], Training Accuracy: 75.8681%, Training Loss: 0.5786%\n",
      "Epoch [35/300], Step [10/225], Training Accuracy: 75.3125%, Training Loss: 0.5777%\n",
      "Epoch [35/300], Step [11/225], Training Accuracy: 74.7159%, Training Loss: 0.5772%\n",
      "Epoch [35/300], Step [12/225], Training Accuracy: 74.8698%, Training Loss: 0.5696%\n",
      "Epoch [35/300], Step [13/225], Training Accuracy: 75.3606%, Training Loss: 0.5593%\n",
      "Epoch [35/300], Step [14/225], Training Accuracy: 75.0000%, Training Loss: 0.5620%\n",
      "Epoch [35/300], Step [15/225], Training Accuracy: 75.4167%, Training Loss: 0.5627%\n",
      "Epoch [35/300], Step [16/225], Training Accuracy: 75.0000%, Training Loss: 0.5676%\n",
      "Epoch [35/300], Step [17/225], Training Accuracy: 74.9081%, Training Loss: 0.5635%\n",
      "Epoch [35/300], Step [18/225], Training Accuracy: 75.0868%, Training Loss: 0.5600%\n",
      "Epoch [35/300], Step [19/225], Training Accuracy: 75.0000%, Training Loss: 0.5605%\n",
      "Epoch [35/300], Step [20/225], Training Accuracy: 74.8438%, Training Loss: 0.5627%\n",
      "Epoch [35/300], Step [21/225], Training Accuracy: 75.0000%, Training Loss: 0.5565%\n",
      "Epoch [35/300], Step [22/225], Training Accuracy: 74.5028%, Training Loss: 0.5622%\n",
      "Epoch [35/300], Step [23/225], Training Accuracy: 74.5924%, Training Loss: 0.5593%\n",
      "Epoch [35/300], Step [24/225], Training Accuracy: 74.4141%, Training Loss: 0.5619%\n",
      "Epoch [35/300], Step [25/225], Training Accuracy: 74.5625%, Training Loss: 0.5603%\n",
      "Epoch [35/300], Step [26/225], Training Accuracy: 74.3389%, Training Loss: 0.5651%\n",
      "Epoch [35/300], Step [27/225], Training Accuracy: 74.4213%, Training Loss: 0.5654%\n",
      "Epoch [35/300], Step [28/225], Training Accuracy: 74.4978%, Training Loss: 0.5625%\n",
      "Epoch [35/300], Step [29/225], Training Accuracy: 74.6767%, Training Loss: 0.5606%\n",
      "Epoch [35/300], Step [30/225], Training Accuracy: 74.7396%, Training Loss: 0.5608%\n",
      "Epoch [35/300], Step [31/225], Training Accuracy: 74.9496%, Training Loss: 0.5604%\n",
      "Epoch [35/300], Step [32/225], Training Accuracy: 75.0000%, Training Loss: 0.5618%\n",
      "Epoch [35/300], Step [33/225], Training Accuracy: 74.9053%, Training Loss: 0.5640%\n",
      "Epoch [35/300], Step [34/225], Training Accuracy: 74.6324%, Training Loss: 0.5687%\n",
      "Epoch [35/300], Step [35/225], Training Accuracy: 74.5982%, Training Loss: 0.5680%\n",
      "Epoch [35/300], Step [36/225], Training Accuracy: 74.3056%, Training Loss: 0.5732%\n",
      "Epoch [35/300], Step [37/225], Training Accuracy: 74.3666%, Training Loss: 0.5711%\n",
      "Epoch [35/300], Step [38/225], Training Accuracy: 74.4243%, Training Loss: 0.5681%\n",
      "Epoch [35/300], Step [39/225], Training Accuracy: 74.2388%, Training Loss: 0.5709%\n",
      "Epoch [35/300], Step [40/225], Training Accuracy: 74.2969%, Training Loss: 0.5730%\n",
      "Epoch [35/300], Step [41/225], Training Accuracy: 74.0091%, Training Loss: 0.5787%\n",
      "Epoch [35/300], Step [42/225], Training Accuracy: 73.7723%, Training Loss: 0.5812%\n",
      "Epoch [35/300], Step [43/225], Training Accuracy: 73.8735%, Training Loss: 0.5790%\n",
      "Epoch [35/300], Step [44/225], Training Accuracy: 73.9347%, Training Loss: 0.5773%\n",
      "Epoch [35/300], Step [45/225], Training Accuracy: 74.1319%, Training Loss: 0.5750%\n",
      "Epoch [35/300], Step [46/225], Training Accuracy: 74.1508%, Training Loss: 0.5760%\n",
      "Epoch [35/300], Step [47/225], Training Accuracy: 74.1024%, Training Loss: 0.5759%\n",
      "Epoch [35/300], Step [48/225], Training Accuracy: 73.9909%, Training Loss: 0.5782%\n",
      "Epoch [35/300], Step [49/225], Training Accuracy: 74.1071%, Training Loss: 0.5761%\n",
      "Epoch [35/300], Step [50/225], Training Accuracy: 74.1250%, Training Loss: 0.5752%\n",
      "Epoch [35/300], Step [51/225], Training Accuracy: 74.2034%, Training Loss: 0.5745%\n",
      "Epoch [35/300], Step [52/225], Training Accuracy: 74.4892%, Training Loss: 0.5704%\n",
      "Epoch [35/300], Step [53/225], Training Accuracy: 74.3809%, Training Loss: 0.5723%\n",
      "Epoch [35/300], Step [54/225], Training Accuracy: 74.1898%, Training Loss: 0.5760%\n",
      "Epoch [35/300], Step [55/225], Training Accuracy: 74.2045%, Training Loss: 0.5782%\n",
      "Epoch [35/300], Step [56/225], Training Accuracy: 74.2746%, Training Loss: 0.5767%\n",
      "Epoch [35/300], Step [57/225], Training Accuracy: 74.3421%, Training Loss: 0.5768%\n",
      "Epoch [35/300], Step [58/225], Training Accuracy: 74.2996%, Training Loss: 0.5764%\n",
      "Epoch [35/300], Step [59/225], Training Accuracy: 74.2055%, Training Loss: 0.5783%\n",
      "Epoch [35/300], Step [60/225], Training Accuracy: 74.2708%, Training Loss: 0.5759%\n",
      "Epoch [35/300], Step [61/225], Training Accuracy: 74.2828%, Training Loss: 0.5760%\n",
      "Epoch [35/300], Step [62/225], Training Accuracy: 74.3700%, Training Loss: 0.5757%\n",
      "Epoch [35/300], Step [63/225], Training Accuracy: 74.5040%, Training Loss: 0.5735%\n",
      "Epoch [35/300], Step [64/225], Training Accuracy: 74.4385%, Training Loss: 0.5755%\n",
      "Epoch [35/300], Step [65/225], Training Accuracy: 74.4952%, Training Loss: 0.5749%\n",
      "Epoch [35/300], Step [66/225], Training Accuracy: 74.6449%, Training Loss: 0.5737%\n",
      "Epoch [35/300], Step [67/225], Training Accuracy: 74.6735%, Training Loss: 0.5741%\n",
      "Epoch [35/300], Step [68/225], Training Accuracy: 74.6094%, Training Loss: 0.5755%\n",
      "Epoch [35/300], Step [69/225], Training Accuracy: 74.5924%, Training Loss: 0.5759%\n",
      "Epoch [35/300], Step [70/225], Training Accuracy: 74.6429%, Training Loss: 0.5742%\n",
      "Epoch [35/300], Step [71/225], Training Accuracy: 74.6479%, Training Loss: 0.5737%\n",
      "Epoch [35/300], Step [72/225], Training Accuracy: 74.6745%, Training Loss: 0.5729%\n",
      "Epoch [35/300], Step [73/225], Training Accuracy: 74.7432%, Training Loss: 0.5716%\n",
      "Epoch [35/300], Step [74/225], Training Accuracy: 74.7466%, Training Loss: 0.5711%\n",
      "Epoch [35/300], Step [75/225], Training Accuracy: 74.7083%, Training Loss: 0.5710%\n",
      "Epoch [35/300], Step [76/225], Training Accuracy: 74.6711%, Training Loss: 0.5732%\n",
      "Epoch [35/300], Step [77/225], Training Accuracy: 74.6550%, Training Loss: 0.5743%\n",
      "Epoch [35/300], Step [78/225], Training Accuracy: 74.7196%, Training Loss: 0.5723%\n",
      "Epoch [35/300], Step [79/225], Training Accuracy: 74.8022%, Training Loss: 0.5715%\n",
      "Epoch [35/300], Step [80/225], Training Accuracy: 74.8828%, Training Loss: 0.5699%\n",
      "Epoch [35/300], Step [81/225], Training Accuracy: 74.8650%, Training Loss: 0.5709%\n",
      "Epoch [35/300], Step [82/225], Training Accuracy: 74.8476%, Training Loss: 0.5714%\n",
      "Epoch [35/300], Step [83/225], Training Accuracy: 74.7741%, Training Loss: 0.5724%\n",
      "Epoch [35/300], Step [84/225], Training Accuracy: 74.8698%, Training Loss: 0.5722%\n",
      "Epoch [35/300], Step [85/225], Training Accuracy: 74.9081%, Training Loss: 0.5727%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/300], Step [86/225], Training Accuracy: 75.0182%, Training Loss: 0.5714%\n",
      "Epoch [35/300], Step [87/225], Training Accuracy: 75.0539%, Training Loss: 0.5709%\n",
      "Epoch [35/300], Step [88/225], Training Accuracy: 74.9822%, Training Loss: 0.5730%\n",
      "Epoch [35/300], Step [89/225], Training Accuracy: 74.9298%, Training Loss: 0.5740%\n",
      "Epoch [35/300], Step [90/225], Training Accuracy: 74.9306%, Training Loss: 0.5748%\n",
      "Epoch [35/300], Step [91/225], Training Accuracy: 74.9313%, Training Loss: 0.5746%\n",
      "Epoch [35/300], Step [92/225], Training Accuracy: 74.8981%, Training Loss: 0.5742%\n",
      "Epoch [35/300], Step [93/225], Training Accuracy: 74.9664%, Training Loss: 0.5727%\n",
      "Epoch [35/300], Step [94/225], Training Accuracy: 75.0665%, Training Loss: 0.5713%\n",
      "Epoch [35/300], Step [95/225], Training Accuracy: 75.0658%, Training Loss: 0.5718%\n",
      "Epoch [35/300], Step [96/225], Training Accuracy: 75.1139%, Training Loss: 0.5707%\n",
      "Epoch [35/300], Step [97/225], Training Accuracy: 75.1772%, Training Loss: 0.5693%\n",
      "Epoch [35/300], Step [98/225], Training Accuracy: 75.1754%, Training Loss: 0.5700%\n",
      "Epoch [35/300], Step [99/225], Training Accuracy: 75.1263%, Training Loss: 0.5710%\n",
      "Epoch [35/300], Step [100/225], Training Accuracy: 75.1250%, Training Loss: 0.5712%\n",
      "Epoch [35/300], Step [101/225], Training Accuracy: 75.1702%, Training Loss: 0.5705%\n",
      "Epoch [35/300], Step [102/225], Training Accuracy: 75.1225%, Training Loss: 0.5708%\n",
      "Epoch [35/300], Step [103/225], Training Accuracy: 75.1517%, Training Loss: 0.5706%\n",
      "Epoch [35/300], Step [104/225], Training Accuracy: 75.1803%, Training Loss: 0.5700%\n",
      "Epoch [35/300], Step [105/225], Training Accuracy: 75.2232%, Training Loss: 0.5684%\n",
      "Epoch [35/300], Step [106/225], Training Accuracy: 75.2358%, Training Loss: 0.5684%\n",
      "Epoch [35/300], Step [107/225], Training Accuracy: 75.2044%, Training Loss: 0.5698%\n",
      "Epoch [35/300], Step [108/225], Training Accuracy: 75.1736%, Training Loss: 0.5717%\n",
      "Epoch [35/300], Step [109/225], Training Accuracy: 75.1864%, Training Loss: 0.5717%\n",
      "Epoch [35/300], Step [110/225], Training Accuracy: 75.1705%, Training Loss: 0.5711%\n",
      "Epoch [35/300], Step [111/225], Training Accuracy: 75.1689%, Training Loss: 0.5722%\n",
      "Epoch [35/300], Step [112/225], Training Accuracy: 75.1953%, Training Loss: 0.5724%\n",
      "Epoch [35/300], Step [113/225], Training Accuracy: 75.1798%, Training Loss: 0.5724%\n",
      "Epoch [35/300], Step [114/225], Training Accuracy: 75.1782%, Training Loss: 0.5723%\n",
      "Epoch [35/300], Step [115/225], Training Accuracy: 75.2038%, Training Loss: 0.5721%\n",
      "Epoch [35/300], Step [116/225], Training Accuracy: 75.1886%, Training Loss: 0.5735%\n",
      "Epoch [35/300], Step [117/225], Training Accuracy: 75.1469%, Training Loss: 0.5740%\n",
      "Epoch [35/300], Step [118/225], Training Accuracy: 75.1721%, Training Loss: 0.5738%\n",
      "Epoch [35/300], Step [119/225], Training Accuracy: 75.1444%, Training Loss: 0.5743%\n",
      "Epoch [35/300], Step [120/225], Training Accuracy: 75.1693%, Training Loss: 0.5743%\n",
      "Epoch [35/300], Step [121/225], Training Accuracy: 75.1550%, Training Loss: 0.5744%\n",
      "Epoch [35/300], Step [122/225], Training Accuracy: 75.1537%, Training Loss: 0.5747%\n",
      "Epoch [35/300], Step [123/225], Training Accuracy: 75.2033%, Training Loss: 0.5740%\n",
      "Epoch [35/300], Step [124/225], Training Accuracy: 75.1638%, Training Loss: 0.5751%\n",
      "Epoch [35/300], Step [125/225], Training Accuracy: 75.1875%, Training Loss: 0.5744%\n",
      "Epoch [35/300], Step [126/225], Training Accuracy: 75.1736%, Training Loss: 0.5744%\n",
      "Epoch [35/300], Step [127/225], Training Accuracy: 75.1969%, Training Loss: 0.5741%\n",
      "Epoch [35/300], Step [128/225], Training Accuracy: 75.2441%, Training Loss: 0.5738%\n",
      "Epoch [35/300], Step [129/225], Training Accuracy: 75.2422%, Training Loss: 0.5739%\n",
      "Epoch [35/300], Step [130/225], Training Accuracy: 75.2043%, Training Loss: 0.5741%\n",
      "Epoch [35/300], Step [131/225], Training Accuracy: 75.1551%, Training Loss: 0.5744%\n",
      "Epoch [35/300], Step [132/225], Training Accuracy: 75.1302%, Training Loss: 0.5748%\n",
      "Epoch [35/300], Step [133/225], Training Accuracy: 75.1762%, Training Loss: 0.5743%\n",
      "Epoch [35/300], Step [134/225], Training Accuracy: 75.1399%, Training Loss: 0.5756%\n",
      "Epoch [35/300], Step [135/225], Training Accuracy: 75.1389%, Training Loss: 0.5755%\n",
      "Epoch [35/300], Step [136/225], Training Accuracy: 75.1149%, Training Loss: 0.5753%\n",
      "Epoch [35/300], Step [137/225], Training Accuracy: 75.0912%, Training Loss: 0.5755%\n",
      "Epoch [35/300], Step [138/225], Training Accuracy: 75.1245%, Training Loss: 0.5744%\n",
      "Epoch [35/300], Step [139/225], Training Accuracy: 75.1461%, Training Loss: 0.5739%\n",
      "Epoch [35/300], Step [140/225], Training Accuracy: 75.1116%, Training Loss: 0.5740%\n",
      "Epoch [35/300], Step [141/225], Training Accuracy: 75.1330%, Training Loss: 0.5745%\n",
      "Epoch [35/300], Step [142/225], Training Accuracy: 75.1430%, Training Loss: 0.5739%\n",
      "Epoch [35/300], Step [143/225], Training Accuracy: 75.1858%, Training Loss: 0.5734%\n",
      "Epoch [35/300], Step [144/225], Training Accuracy: 75.1628%, Training Loss: 0.5739%\n",
      "Epoch [35/300], Step [145/225], Training Accuracy: 75.1616%, Training Loss: 0.5737%\n",
      "Epoch [35/300], Step [146/225], Training Accuracy: 75.0856%, Training Loss: 0.5754%\n",
      "Epoch [35/300], Step [147/225], Training Accuracy: 75.0531%, Training Loss: 0.5758%\n",
      "Epoch [35/300], Step [148/225], Training Accuracy: 75.0317%, Training Loss: 0.5757%\n",
      "Epoch [35/300], Step [149/225], Training Accuracy: 75.0419%, Training Loss: 0.5753%\n",
      "Epoch [35/300], Step [150/225], Training Accuracy: 75.0521%, Training Loss: 0.5743%\n",
      "Epoch [35/300], Step [151/225], Training Accuracy: 75.0621%, Training Loss: 0.5740%\n",
      "Epoch [35/300], Step [152/225], Training Accuracy: 75.1336%, Training Loss: 0.5728%\n",
      "Epoch [35/300], Step [153/225], Training Accuracy: 75.0919%, Training Loss: 0.5736%\n",
      "Epoch [35/300], Step [154/225], Training Accuracy: 75.0304%, Training Loss: 0.5743%\n",
      "Epoch [35/300], Step [155/225], Training Accuracy: 75.0605%, Training Loss: 0.5739%\n",
      "Epoch [35/300], Step [156/225], Training Accuracy: 75.0401%, Training Loss: 0.5744%\n",
      "Epoch [35/300], Step [157/225], Training Accuracy: 75.0597%, Training Loss: 0.5736%\n",
      "Epoch [35/300], Step [158/225], Training Accuracy: 75.0099%, Training Loss: 0.5741%\n",
      "Epoch [35/300], Step [159/225], Training Accuracy: 75.0295%, Training Loss: 0.5742%\n",
      "Epoch [35/300], Step [160/225], Training Accuracy: 75.0293%, Training Loss: 0.5737%\n",
      "Epoch [35/300], Step [161/225], Training Accuracy: 75.0194%, Training Loss: 0.5742%\n",
      "Epoch [35/300], Step [162/225], Training Accuracy: 75.0675%, Training Loss: 0.5737%\n",
      "Epoch [35/300], Step [163/225], Training Accuracy: 75.0575%, Training Loss: 0.5732%\n",
      "Epoch [35/300], Step [164/225], Training Accuracy: 75.0286%, Training Loss: 0.5734%\n",
      "Epoch [35/300], Step [165/225], Training Accuracy: 75.0473%, Training Loss: 0.5736%\n",
      "Epoch [35/300], Step [166/225], Training Accuracy: 75.0188%, Training Loss: 0.5732%\n",
      "Epoch [35/300], Step [167/225], Training Accuracy: 75.0094%, Training Loss: 0.5730%\n",
      "Epoch [35/300], Step [168/225], Training Accuracy: 75.0186%, Training Loss: 0.5729%\n",
      "Epoch [35/300], Step [169/225], Training Accuracy: 75.0925%, Training Loss: 0.5718%\n",
      "Epoch [35/300], Step [170/225], Training Accuracy: 75.1011%, Training Loss: 0.5717%\n",
      "Epoch [35/300], Step [171/225], Training Accuracy: 75.0731%, Training Loss: 0.5721%\n",
      "Epoch [35/300], Step [172/225], Training Accuracy: 75.0727%, Training Loss: 0.5722%\n",
      "Epoch [35/300], Step [173/225], Training Accuracy: 75.0632%, Training Loss: 0.5725%\n",
      "Epoch [35/300], Step [174/225], Training Accuracy: 75.0988%, Training Loss: 0.5724%\n",
      "Epoch [35/300], Step [175/225], Training Accuracy: 75.1250%, Training Loss: 0.5720%\n",
      "Epoch [35/300], Step [176/225], Training Accuracy: 75.1243%, Training Loss: 0.5720%\n",
      "Epoch [35/300], Step [177/225], Training Accuracy: 75.1589%, Training Loss: 0.5716%\n",
      "Epoch [35/300], Step [178/225], Training Accuracy: 75.1492%, Training Loss: 0.5720%\n",
      "Epoch [35/300], Step [179/225], Training Accuracy: 75.1833%, Training Loss: 0.5712%\n",
      "Epoch [35/300], Step [180/225], Training Accuracy: 75.1910%, Training Loss: 0.5707%\n",
      "Epoch [35/300], Step [181/225], Training Accuracy: 75.1813%, Training Loss: 0.5714%\n",
      "Epoch [35/300], Step [182/225], Training Accuracy: 75.2318%, Training Loss: 0.5707%\n",
      "Epoch [35/300], Step [183/225], Training Accuracy: 75.2220%, Training Loss: 0.5705%\n",
      "Epoch [35/300], Step [184/225], Training Accuracy: 75.2463%, Training Loss: 0.5704%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/300], Step [185/225], Training Accuracy: 75.2280%, Training Loss: 0.5720%\n",
      "Epoch [35/300], Step [186/225], Training Accuracy: 75.2940%, Training Loss: 0.5707%\n",
      "Epoch [35/300], Step [187/225], Training Accuracy: 75.2590%, Training Loss: 0.5721%\n",
      "Epoch [35/300], Step [188/225], Training Accuracy: 75.2743%, Training Loss: 0.5721%\n",
      "Epoch [35/300], Step [189/225], Training Accuracy: 75.2894%, Training Loss: 0.5716%\n",
      "Epoch [35/300], Step [190/225], Training Accuracy: 75.2714%, Training Loss: 0.5717%\n",
      "Epoch [35/300], Step [191/225], Training Accuracy: 75.2781%, Training Loss: 0.5714%\n",
      "Epoch [35/300], Step [192/225], Training Accuracy: 75.3092%, Training Loss: 0.5705%\n",
      "Epoch [35/300], Step [193/225], Training Accuracy: 75.2915%, Training Loss: 0.5707%\n",
      "Epoch [35/300], Step [194/225], Training Accuracy: 75.2658%, Training Loss: 0.5713%\n",
      "Epoch [35/300], Step [195/225], Training Accuracy: 75.3125%, Training Loss: 0.5701%\n",
      "Epoch [35/300], Step [196/225], Training Accuracy: 75.3029%, Training Loss: 0.5703%\n",
      "Epoch [35/300], Step [197/225], Training Accuracy: 75.2697%, Training Loss: 0.5707%\n",
      "Epoch [35/300], Step [198/225], Training Accuracy: 75.2604%, Training Loss: 0.5706%\n",
      "Epoch [35/300], Step [199/225], Training Accuracy: 75.2827%, Training Loss: 0.5704%\n",
      "Epoch [35/300], Step [200/225], Training Accuracy: 75.2578%, Training Loss: 0.5718%\n",
      "Epoch [35/300], Step [201/225], Training Accuracy: 75.2488%, Training Loss: 0.5720%\n",
      "Epoch [35/300], Step [202/225], Training Accuracy: 75.2553%, Training Loss: 0.5722%\n",
      "Epoch [35/300], Step [203/225], Training Accuracy: 75.2925%, Training Loss: 0.5715%\n",
      "Epoch [35/300], Step [204/225], Training Accuracy: 75.2757%, Training Loss: 0.5713%\n",
      "Epoch [35/300], Step [205/225], Training Accuracy: 75.2896%, Training Loss: 0.5714%\n",
      "Epoch [35/300], Step [206/225], Training Accuracy: 75.3489%, Training Loss: 0.5707%\n",
      "Epoch [35/300], Step [207/225], Training Accuracy: 75.3321%, Training Loss: 0.5705%\n",
      "Epoch [35/300], Step [208/225], Training Accuracy: 75.3305%, Training Loss: 0.5707%\n",
      "Epoch [35/300], Step [209/225], Training Accuracy: 75.3140%, Training Loss: 0.5711%\n",
      "Epoch [35/300], Step [210/225], Training Accuracy: 75.2902%, Training Loss: 0.5714%\n",
      "Epoch [35/300], Step [211/225], Training Accuracy: 75.2962%, Training Loss: 0.5711%\n",
      "Epoch [35/300], Step [212/225], Training Accuracy: 75.2801%, Training Loss: 0.5716%\n",
      "Epoch [35/300], Step [213/225], Training Accuracy: 75.2714%, Training Loss: 0.5719%\n",
      "Epoch [35/300], Step [214/225], Training Accuracy: 75.3140%, Training Loss: 0.5715%\n",
      "Epoch [35/300], Step [215/225], Training Accuracy: 75.3416%, Training Loss: 0.5710%\n",
      "Epoch [35/300], Step [216/225], Training Accuracy: 75.3183%, Training Loss: 0.5715%\n",
      "Epoch [35/300], Step [217/225], Training Accuracy: 75.3240%, Training Loss: 0.5713%\n",
      "Epoch [35/300], Step [218/225], Training Accuracy: 75.3082%, Training Loss: 0.5720%\n",
      "Epoch [35/300], Step [219/225], Training Accuracy: 75.2568%, Training Loss: 0.5723%\n",
      "Epoch [35/300], Step [220/225], Training Accuracy: 75.2841%, Training Loss: 0.5717%\n",
      "Epoch [35/300], Step [221/225], Training Accuracy: 75.3040%, Training Loss: 0.5715%\n",
      "Epoch [35/300], Step [222/225], Training Accuracy: 75.2956%, Training Loss: 0.5714%\n",
      "Epoch [35/300], Step [223/225], Training Accuracy: 75.2592%, Training Loss: 0.5715%\n",
      "Epoch [35/300], Step [224/225], Training Accuracy: 75.2860%, Training Loss: 0.5713%\n",
      "Epoch [35/300], Step [225/225], Training Accuracy: 75.2779%, Training Loss: 0.5712%\n",
      "Epoch [36/300], Step [1/225], Training Accuracy: 81.2500%, Training Loss: 0.4742%\n",
      "Epoch [36/300], Step [2/225], Training Accuracy: 78.9062%, Training Loss: 0.5218%\n",
      "Epoch [36/300], Step [3/225], Training Accuracy: 78.1250%, Training Loss: 0.5767%\n",
      "Epoch [36/300], Step [4/225], Training Accuracy: 77.3438%, Training Loss: 0.5898%\n",
      "Epoch [36/300], Step [5/225], Training Accuracy: 78.1250%, Training Loss: 0.5726%\n",
      "Epoch [36/300], Step [6/225], Training Accuracy: 78.6458%, Training Loss: 0.5648%\n",
      "Epoch [36/300], Step [7/225], Training Accuracy: 77.6786%, Training Loss: 0.5811%\n",
      "Epoch [36/300], Step [8/225], Training Accuracy: 76.9531%, Training Loss: 0.6069%\n",
      "Epoch [36/300], Step [9/225], Training Accuracy: 77.0833%, Training Loss: 0.6022%\n",
      "Epoch [36/300], Step [10/225], Training Accuracy: 76.4062%, Training Loss: 0.6004%\n",
      "Epoch [36/300], Step [11/225], Training Accuracy: 76.1364%, Training Loss: 0.5970%\n",
      "Epoch [36/300], Step [12/225], Training Accuracy: 76.0417%, Training Loss: 0.5912%\n",
      "Epoch [36/300], Step [13/225], Training Accuracy: 76.8029%, Training Loss: 0.5721%\n",
      "Epoch [36/300], Step [14/225], Training Accuracy: 76.8973%, Training Loss: 0.5667%\n",
      "Epoch [36/300], Step [15/225], Training Accuracy: 76.8750%, Training Loss: 0.5639%\n",
      "Epoch [36/300], Step [16/225], Training Accuracy: 76.5625%, Training Loss: 0.5664%\n",
      "Epoch [36/300], Step [17/225], Training Accuracy: 76.2868%, Training Loss: 0.5659%\n",
      "Epoch [36/300], Step [18/225], Training Accuracy: 76.3021%, Training Loss: 0.5640%\n",
      "Epoch [36/300], Step [19/225], Training Accuracy: 76.3158%, Training Loss: 0.5607%\n",
      "Epoch [36/300], Step [20/225], Training Accuracy: 76.7188%, Training Loss: 0.5534%\n",
      "Epoch [36/300], Step [21/225], Training Accuracy: 77.0089%, Training Loss: 0.5444%\n",
      "Epoch [36/300], Step [22/225], Training Accuracy: 76.7045%, Training Loss: 0.5511%\n",
      "Epoch [36/300], Step [23/225], Training Accuracy: 76.6984%, Training Loss: 0.5489%\n",
      "Epoch [36/300], Step [24/225], Training Accuracy: 76.4974%, Training Loss: 0.5507%\n",
      "Epoch [36/300], Step [25/225], Training Accuracy: 76.8125%, Training Loss: 0.5460%\n",
      "Epoch [36/300], Step [26/225], Training Accuracy: 76.7428%, Training Loss: 0.5501%\n",
      "Epoch [36/300], Step [27/225], Training Accuracy: 77.0833%, Training Loss: 0.5466%\n",
      "Epoch [36/300], Step [28/225], Training Accuracy: 77.2321%, Training Loss: 0.5426%\n",
      "Epoch [36/300], Step [29/225], Training Accuracy: 77.3168%, Training Loss: 0.5403%\n",
      "Epoch [36/300], Step [30/225], Training Accuracy: 77.2917%, Training Loss: 0.5426%\n",
      "Epoch [36/300], Step [31/225], Training Accuracy: 77.1169%, Training Loss: 0.5432%\n",
      "Epoch [36/300], Step [32/225], Training Accuracy: 77.1484%, Training Loss: 0.5410%\n",
      "Epoch [36/300], Step [33/225], Training Accuracy: 77.1780%, Training Loss: 0.5419%\n",
      "Epoch [36/300], Step [34/225], Training Accuracy: 76.7923%, Training Loss: 0.5512%\n",
      "Epoch [36/300], Step [35/225], Training Accuracy: 76.8304%, Training Loss: 0.5513%\n",
      "Epoch [36/300], Step [36/225], Training Accuracy: 76.7795%, Training Loss: 0.5515%\n",
      "Epoch [36/300], Step [37/225], Training Accuracy: 76.7314%, Training Loss: 0.5496%\n",
      "Epoch [36/300], Step [38/225], Training Accuracy: 76.6036%, Training Loss: 0.5519%\n",
      "Epoch [36/300], Step [39/225], Training Accuracy: 76.4022%, Training Loss: 0.5576%\n",
      "Epoch [36/300], Step [40/225], Training Accuracy: 76.0938%, Training Loss: 0.5594%\n",
      "Epoch [36/300], Step [41/225], Training Accuracy: 76.1052%, Training Loss: 0.5604%\n",
      "Epoch [36/300], Step [42/225], Training Accuracy: 75.8557%, Training Loss: 0.5668%\n",
      "Epoch [36/300], Step [43/225], Training Accuracy: 75.6177%, Training Loss: 0.5699%\n",
      "Epoch [36/300], Step [44/225], Training Accuracy: 75.6392%, Training Loss: 0.5687%\n",
      "Epoch [36/300], Step [45/225], Training Accuracy: 75.5556%, Training Loss: 0.5682%\n",
      "Epoch [36/300], Step [46/225], Training Accuracy: 75.6114%, Training Loss: 0.5677%\n",
      "Epoch [36/300], Step [47/225], Training Accuracy: 75.4322%, Training Loss: 0.5714%\n",
      "Epoch [36/300], Step [48/225], Training Accuracy: 75.1302%, Training Loss: 0.5772%\n",
      "Epoch [36/300], Step [49/225], Training Accuracy: 75.1276%, Training Loss: 0.5760%\n",
      "Epoch [36/300], Step [50/225], Training Accuracy: 75.0938%, Training Loss: 0.5771%\n",
      "Epoch [36/300], Step [51/225], Training Accuracy: 75.1532%, Training Loss: 0.5761%\n",
      "Epoch [36/300], Step [52/225], Training Accuracy: 75.2404%, Training Loss: 0.5738%\n",
      "Epoch [36/300], Step [53/225], Training Accuracy: 75.2653%, Training Loss: 0.5733%\n",
      "Epoch [36/300], Step [54/225], Training Accuracy: 75.0579%, Training Loss: 0.5801%\n",
      "Epoch [36/300], Step [55/225], Training Accuracy: 74.9432%, Training Loss: 0.5803%\n",
      "Epoch [36/300], Step [56/225], Training Accuracy: 74.9442%, Training Loss: 0.5811%\n",
      "Epoch [36/300], Step [57/225], Training Accuracy: 74.8904%, Training Loss: 0.5808%\n",
      "Epoch [36/300], Step [58/225], Training Accuracy: 74.7575%, Training Loss: 0.5835%\n",
      "Epoch [36/300], Step [59/225], Training Accuracy: 74.7352%, Training Loss: 0.5836%\n",
      "Epoch [36/300], Step [60/225], Training Accuracy: 74.7917%, Training Loss: 0.5826%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/300], Step [61/225], Training Accuracy: 74.6926%, Training Loss: 0.5842%\n",
      "Epoch [36/300], Step [62/225], Training Accuracy: 74.6472%, Training Loss: 0.5846%\n",
      "Epoch [36/300], Step [63/225], Training Accuracy: 74.5536%, Training Loss: 0.5864%\n",
      "Epoch [36/300], Step [64/225], Training Accuracy: 74.6094%, Training Loss: 0.5847%\n",
      "Epoch [36/300], Step [65/225], Training Accuracy: 74.5913%, Training Loss: 0.5829%\n",
      "Epoch [36/300], Step [66/225], Training Accuracy: 74.5739%, Training Loss: 0.5821%\n",
      "Epoch [36/300], Step [67/225], Training Accuracy: 74.5802%, Training Loss: 0.5815%\n",
      "Epoch [36/300], Step [68/225], Training Accuracy: 74.5404%, Training Loss: 0.5816%\n",
      "Epoch [36/300], Step [69/225], Training Accuracy: 74.6150%, Training Loss: 0.5815%\n",
      "Epoch [36/300], Step [70/225], Training Accuracy: 74.5982%, Training Loss: 0.5815%\n",
      "Epoch [36/300], Step [71/225], Training Accuracy: 74.5158%, Training Loss: 0.5823%\n",
      "Epoch [36/300], Step [72/225], Training Accuracy: 74.5877%, Training Loss: 0.5815%\n",
      "Epoch [36/300], Step [73/225], Training Accuracy: 74.6789%, Training Loss: 0.5797%\n",
      "Epoch [36/300], Step [74/225], Training Accuracy: 74.7044%, Training Loss: 0.5799%\n",
      "Epoch [36/300], Step [75/225], Training Accuracy: 74.6458%, Training Loss: 0.5807%\n",
      "Epoch [36/300], Step [76/225], Training Accuracy: 74.4038%, Training Loss: 0.5836%\n",
      "Epoch [36/300], Step [77/225], Training Accuracy: 74.3709%, Training Loss: 0.5838%\n",
      "Epoch [36/300], Step [78/225], Training Accuracy: 74.5593%, Training Loss: 0.5822%\n",
      "Epoch [36/300], Step [79/225], Training Accuracy: 74.6440%, Training Loss: 0.5809%\n",
      "Epoch [36/300], Step [80/225], Training Accuracy: 74.5898%, Training Loss: 0.5801%\n",
      "Epoch [36/300], Step [81/225], Training Accuracy: 74.6914%, Training Loss: 0.5783%\n",
      "Epoch [36/300], Step [82/225], Training Accuracy: 74.6189%, Training Loss: 0.5793%\n",
      "Epoch [36/300], Step [83/225], Training Accuracy: 74.5858%, Training Loss: 0.5795%\n",
      "Epoch [36/300], Step [84/225], Training Accuracy: 74.7024%, Training Loss: 0.5777%\n",
      "Epoch [36/300], Step [85/225], Training Accuracy: 74.7794%, Training Loss: 0.5754%\n",
      "Epoch [36/300], Step [86/225], Training Accuracy: 74.7820%, Training Loss: 0.5753%\n",
      "Epoch [36/300], Step [87/225], Training Accuracy: 74.8024%, Training Loss: 0.5752%\n",
      "Epoch [36/300], Step [88/225], Training Accuracy: 74.7159%, Training Loss: 0.5765%\n",
      "Epoch [36/300], Step [89/225], Training Accuracy: 74.7367%, Training Loss: 0.5762%\n",
      "Epoch [36/300], Step [90/225], Training Accuracy: 74.7222%, Training Loss: 0.5766%\n",
      "Epoch [36/300], Step [91/225], Training Accuracy: 74.7596%, Training Loss: 0.5765%\n",
      "Epoch [36/300], Step [92/225], Training Accuracy: 74.6773%, Training Loss: 0.5775%\n",
      "Epoch [36/300], Step [93/225], Training Accuracy: 74.7984%, Training Loss: 0.5767%\n",
      "Epoch [36/300], Step [94/225], Training Accuracy: 74.8836%, Training Loss: 0.5751%\n",
      "Epoch [36/300], Step [95/225], Training Accuracy: 74.9507%, Training Loss: 0.5740%\n",
      "Epoch [36/300], Step [96/225], Training Accuracy: 75.0000%, Training Loss: 0.5731%\n",
      "Epoch [36/300], Step [97/225], Training Accuracy: 75.0000%, Training Loss: 0.5734%\n",
      "Epoch [36/300], Step [98/225], Training Accuracy: 74.9841%, Training Loss: 0.5736%\n",
      "Epoch [36/300], Step [99/225], Training Accuracy: 74.9369%, Training Loss: 0.5740%\n",
      "Epoch [36/300], Step [100/225], Training Accuracy: 74.8594%, Training Loss: 0.5751%\n",
      "Epoch [36/300], Step [101/225], Training Accuracy: 74.9226%, Training Loss: 0.5743%\n",
      "Epoch [36/300], Step [102/225], Training Accuracy: 74.8621%, Training Loss: 0.5764%\n",
      "Epoch [36/300], Step [103/225], Training Accuracy: 74.9393%, Training Loss: 0.5749%\n",
      "Epoch [36/300], Step [104/225], Training Accuracy: 74.9249%, Training Loss: 0.5752%\n",
      "Epoch [36/300], Step [105/225], Training Accuracy: 74.9405%, Training Loss: 0.5740%\n",
      "Epoch [36/300], Step [106/225], Training Accuracy: 74.9705%, Training Loss: 0.5732%\n",
      "Epoch [36/300], Step [107/225], Training Accuracy: 75.0146%, Training Loss: 0.5725%\n",
      "Epoch [36/300], Step [108/225], Training Accuracy: 75.0289%, Training Loss: 0.5721%\n",
      "Epoch [36/300], Step [109/225], Training Accuracy: 74.9857%, Training Loss: 0.5724%\n",
      "Epoch [36/300], Step [110/225], Training Accuracy: 75.0000%, Training Loss: 0.5719%\n",
      "Epoch [36/300], Step [111/225], Training Accuracy: 75.0000%, Training Loss: 0.5720%\n",
      "Epoch [36/300], Step [112/225], Training Accuracy: 75.0419%, Training Loss: 0.5705%\n",
      "Epoch [36/300], Step [113/225], Training Accuracy: 75.0553%, Training Loss: 0.5711%\n",
      "Epoch [36/300], Step [114/225], Training Accuracy: 75.0411%, Training Loss: 0.5707%\n",
      "Epoch [36/300], Step [115/225], Training Accuracy: 75.0408%, Training Loss: 0.5698%\n",
      "Epoch [36/300], Step [116/225], Training Accuracy: 75.1078%, Training Loss: 0.5690%\n",
      "Epoch [36/300], Step [117/225], Training Accuracy: 75.0134%, Training Loss: 0.5716%\n",
      "Epoch [36/300], Step [118/225], Training Accuracy: 74.9735%, Training Loss: 0.5718%\n",
      "Epoch [36/300], Step [119/225], Training Accuracy: 74.9606%, Training Loss: 0.5721%\n",
      "Epoch [36/300], Step [120/225], Training Accuracy: 74.9479%, Training Loss: 0.5728%\n",
      "Epoch [36/300], Step [121/225], Training Accuracy: 74.8709%, Training Loss: 0.5733%\n",
      "Epoch [36/300], Step [122/225], Training Accuracy: 74.8207%, Training Loss: 0.5738%\n",
      "Epoch [36/300], Step [123/225], Training Accuracy: 74.8222%, Training Loss: 0.5743%\n",
      "Epoch [36/300], Step [124/225], Training Accuracy: 74.7984%, Training Loss: 0.5748%\n",
      "Epoch [36/300], Step [125/225], Training Accuracy: 74.8625%, Training Loss: 0.5743%\n",
      "Epoch [36/300], Step [126/225], Training Accuracy: 74.8884%, Training Loss: 0.5753%\n",
      "Epoch [36/300], Step [127/225], Training Accuracy: 74.9508%, Training Loss: 0.5743%\n",
      "Epoch [36/300], Step [128/225], Training Accuracy: 74.8901%, Training Loss: 0.5749%\n",
      "Epoch [36/300], Step [129/225], Training Accuracy: 74.9152%, Training Loss: 0.5747%\n",
      "Epoch [36/300], Step [130/225], Training Accuracy: 74.9038%, Training Loss: 0.5756%\n",
      "Epoch [36/300], Step [131/225], Training Accuracy: 74.9284%, Training Loss: 0.5758%\n",
      "Epoch [36/300], Step [132/225], Training Accuracy: 74.9645%, Training Loss: 0.5753%\n",
      "Epoch [36/300], Step [133/225], Training Accuracy: 74.9413%, Training Loss: 0.5756%\n",
      "Epoch [36/300], Step [134/225], Training Accuracy: 74.8484%, Training Loss: 0.5785%\n",
      "Epoch [36/300], Step [135/225], Training Accuracy: 74.8611%, Training Loss: 0.5783%\n",
      "Epoch [36/300], Step [136/225], Training Accuracy: 74.8966%, Training Loss: 0.5776%\n",
      "Epoch [36/300], Step [137/225], Training Accuracy: 74.8631%, Training Loss: 0.5778%\n",
      "Epoch [36/300], Step [138/225], Training Accuracy: 74.9321%, Training Loss: 0.5768%\n",
      "Epoch [36/300], Step [139/225], Training Accuracy: 74.9888%, Training Loss: 0.5767%\n",
      "Epoch [36/300], Step [140/225], Training Accuracy: 75.0000%, Training Loss: 0.5762%\n",
      "Epoch [36/300], Step [141/225], Training Accuracy: 75.0222%, Training Loss: 0.5763%\n",
      "Epoch [36/300], Step [142/225], Training Accuracy: 74.9780%, Training Loss: 0.5765%\n",
      "Epoch [36/300], Step [143/225], Training Accuracy: 74.9672%, Training Loss: 0.5774%\n",
      "Epoch [36/300], Step [144/225], Training Accuracy: 75.0543%, Training Loss: 0.5764%\n",
      "Epoch [36/300], Step [145/225], Training Accuracy: 75.0216%, Training Loss: 0.5774%\n",
      "Epoch [36/300], Step [146/225], Training Accuracy: 74.9679%, Training Loss: 0.5777%\n",
      "Epoch [36/300], Step [147/225], Training Accuracy: 74.9787%, Training Loss: 0.5783%\n",
      "Epoch [36/300], Step [148/225], Training Accuracy: 75.0422%, Training Loss: 0.5768%\n",
      "Epoch [36/300], Step [149/225], Training Accuracy: 75.0629%, Training Loss: 0.5764%\n",
      "Epoch [36/300], Step [150/225], Training Accuracy: 75.1354%, Training Loss: 0.5753%\n",
      "Epoch [36/300], Step [151/225], Training Accuracy: 75.1552%, Training Loss: 0.5751%\n",
      "Epoch [36/300], Step [152/225], Training Accuracy: 75.1234%, Training Loss: 0.5755%\n",
      "Epoch [36/300], Step [153/225], Training Accuracy: 75.1736%, Training Loss: 0.5746%\n",
      "Epoch [36/300], Step [154/225], Training Accuracy: 75.1623%, Training Loss: 0.5751%\n",
      "Epoch [36/300], Step [155/225], Training Accuracy: 75.1613%, Training Loss: 0.5751%\n",
      "Epoch [36/300], Step [156/225], Training Accuracy: 75.0601%, Training Loss: 0.5773%\n",
      "Epoch [36/300], Step [157/225], Training Accuracy: 75.0995%, Training Loss: 0.5766%\n",
      "Epoch [36/300], Step [158/225], Training Accuracy: 75.0099%, Training Loss: 0.5781%\n",
      "Epoch [36/300], Step [159/225], Training Accuracy: 74.9607%, Training Loss: 0.5784%\n",
      "Epoch [36/300], Step [160/225], Training Accuracy: 74.9902%, Training Loss: 0.5777%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/300], Step [161/225], Training Accuracy: 74.9709%, Training Loss: 0.5775%\n",
      "Epoch [36/300], Step [162/225], Training Accuracy: 75.0289%, Training Loss: 0.5766%\n",
      "Epoch [36/300], Step [163/225], Training Accuracy: 75.0288%, Training Loss: 0.5765%\n",
      "Epoch [36/300], Step [164/225], Training Accuracy: 75.0953%, Training Loss: 0.5750%\n",
      "Epoch [36/300], Step [165/225], Training Accuracy: 75.0473%, Training Loss: 0.5756%\n",
      "Epoch [36/300], Step [166/225], Training Accuracy: 75.0659%, Training Loss: 0.5753%\n",
      "Epoch [36/300], Step [167/225], Training Accuracy: 75.0749%, Training Loss: 0.5752%\n",
      "Epoch [36/300], Step [168/225], Training Accuracy: 75.0744%, Training Loss: 0.5748%\n",
      "Epoch [36/300], Step [169/225], Training Accuracy: 75.1294%, Training Loss: 0.5735%\n",
      "Epoch [36/300], Step [170/225], Training Accuracy: 75.1011%, Training Loss: 0.5739%\n",
      "Epoch [36/300], Step [171/225], Training Accuracy: 75.1005%, Training Loss: 0.5742%\n",
      "Epoch [36/300], Step [172/225], Training Accuracy: 75.1181%, Training Loss: 0.5743%\n",
      "Epoch [36/300], Step [173/225], Training Accuracy: 75.0813%, Training Loss: 0.5750%\n",
      "Epoch [36/300], Step [174/225], Training Accuracy: 75.0539%, Training Loss: 0.5754%\n",
      "Epoch [36/300], Step [175/225], Training Accuracy: 75.0357%, Training Loss: 0.5755%\n",
      "Epoch [36/300], Step [176/225], Training Accuracy: 75.0621%, Training Loss: 0.5750%\n",
      "Epoch [36/300], Step [177/225], Training Accuracy: 75.0706%, Training Loss: 0.5753%\n",
      "Epoch [36/300], Step [178/225], Training Accuracy: 75.0263%, Training Loss: 0.5753%\n",
      "Epoch [36/300], Step [179/225], Training Accuracy: 75.0698%, Training Loss: 0.5743%\n",
      "Epoch [36/300], Step [180/225], Training Accuracy: 75.0868%, Training Loss: 0.5741%\n",
      "Epoch [36/300], Step [181/225], Training Accuracy: 75.0863%, Training Loss: 0.5739%\n",
      "Epoch [36/300], Step [182/225], Training Accuracy: 75.1030%, Training Loss: 0.5735%\n",
      "Epoch [36/300], Step [183/225], Training Accuracy: 75.0939%, Training Loss: 0.5732%\n",
      "Epoch [36/300], Step [184/225], Training Accuracy: 75.1613%, Training Loss: 0.5723%\n",
      "Epoch [36/300], Step [185/225], Training Accuracy: 75.1520%, Training Loss: 0.5721%\n",
      "Epoch [36/300], Step [186/225], Training Accuracy: 75.1932%, Training Loss: 0.5712%\n",
      "Epoch [36/300], Step [187/225], Training Accuracy: 75.1838%, Training Loss: 0.5707%\n",
      "Epoch [36/300], Step [188/225], Training Accuracy: 75.2410%, Training Loss: 0.5701%\n",
      "Epoch [36/300], Step [189/225], Training Accuracy: 75.2811%, Training Loss: 0.5693%\n",
      "Epoch [36/300], Step [190/225], Training Accuracy: 75.2878%, Training Loss: 0.5695%\n",
      "Epoch [36/300], Step [191/225], Training Accuracy: 75.2618%, Training Loss: 0.5696%\n",
      "Epoch [36/300], Step [192/225], Training Accuracy: 75.2930%, Training Loss: 0.5690%\n",
      "Epoch [36/300], Step [193/225], Training Accuracy: 75.2753%, Training Loss: 0.5692%\n",
      "Epoch [36/300], Step [194/225], Training Accuracy: 75.2738%, Training Loss: 0.5689%\n",
      "Epoch [36/300], Step [195/225], Training Accuracy: 75.3365%, Training Loss: 0.5678%\n",
      "Epoch [36/300], Step [196/225], Training Accuracy: 75.3189%, Training Loss: 0.5681%\n",
      "Epoch [36/300], Step [197/225], Training Accuracy: 75.3093%, Training Loss: 0.5688%\n",
      "Epoch [36/300], Step [198/225], Training Accuracy: 75.3235%, Training Loss: 0.5683%\n",
      "Epoch [36/300], Step [199/225], Training Accuracy: 75.3612%, Training Loss: 0.5675%\n",
      "Epoch [36/300], Step [200/225], Training Accuracy: 75.3750%, Training Loss: 0.5670%\n",
      "Epoch [36/300], Step [201/225], Training Accuracy: 75.3654%, Training Loss: 0.5671%\n",
      "Epoch [36/300], Step [202/225], Training Accuracy: 75.3636%, Training Loss: 0.5670%\n",
      "Epoch [36/300], Step [203/225], Training Accuracy: 75.4156%, Training Loss: 0.5663%\n",
      "Epoch [36/300], Step [204/225], Training Accuracy: 75.4442%, Training Loss: 0.5658%\n",
      "Epoch [36/300], Step [205/225], Training Accuracy: 75.4573%, Training Loss: 0.5653%\n",
      "Epoch [36/300], Step [206/225], Training Accuracy: 75.4248%, Training Loss: 0.5660%\n",
      "Epoch [36/300], Step [207/225], Training Accuracy: 75.4378%, Training Loss: 0.5659%\n",
      "Epoch [36/300], Step [208/225], Training Accuracy: 75.4507%, Training Loss: 0.5658%\n",
      "Epoch [36/300], Step [209/225], Training Accuracy: 75.4486%, Training Loss: 0.5659%\n",
      "Epoch [36/300], Step [210/225], Training Accuracy: 75.4315%, Training Loss: 0.5663%\n",
      "Epoch [36/300], Step [211/225], Training Accuracy: 75.4369%, Training Loss: 0.5666%\n",
      "Epoch [36/300], Step [212/225], Training Accuracy: 75.4422%, Training Loss: 0.5667%\n",
      "Epoch [36/300], Step [213/225], Training Accuracy: 75.4401%, Training Loss: 0.5663%\n",
      "Epoch [36/300], Step [214/225], Training Accuracy: 75.4308%, Training Loss: 0.5662%\n",
      "Epoch [36/300], Step [215/225], Training Accuracy: 75.4288%, Training Loss: 0.5661%\n",
      "Epoch [36/300], Step [216/225], Training Accuracy: 75.4123%, Training Loss: 0.5662%\n",
      "Epoch [36/300], Step [217/225], Training Accuracy: 75.4320%, Training Loss: 0.5659%\n",
      "Epoch [36/300], Step [218/225], Training Accuracy: 75.4372%, Training Loss: 0.5661%\n",
      "Epoch [36/300], Step [219/225], Training Accuracy: 75.4424%, Training Loss: 0.5659%\n",
      "Epoch [36/300], Step [220/225], Training Accuracy: 75.4688%, Training Loss: 0.5651%\n",
      "Epoch [36/300], Step [221/225], Training Accuracy: 75.4666%, Training Loss: 0.5648%\n",
      "Epoch [36/300], Step [222/225], Training Accuracy: 75.4856%, Training Loss: 0.5644%\n",
      "Epoch [36/300], Step [223/225], Training Accuracy: 75.4695%, Training Loss: 0.5641%\n",
      "Epoch [36/300], Step [224/225], Training Accuracy: 75.4813%, Training Loss: 0.5636%\n",
      "Epoch [36/300], Step [225/225], Training Accuracy: 75.4725%, Training Loss: 0.5638%\n",
      "Epoch [37/300], Step [1/225], Training Accuracy: 78.1250%, Training Loss: 0.4337%\n",
      "Epoch [37/300], Step [2/225], Training Accuracy: 78.1250%, Training Loss: 0.4767%\n",
      "Epoch [37/300], Step [3/225], Training Accuracy: 78.1250%, Training Loss: 0.4967%\n",
      "Epoch [37/300], Step [4/225], Training Accuracy: 76.9531%, Training Loss: 0.5023%\n",
      "Epoch [37/300], Step [5/225], Training Accuracy: 77.1875%, Training Loss: 0.5158%\n",
      "Epoch [37/300], Step [6/225], Training Accuracy: 76.5625%, Training Loss: 0.5197%\n",
      "Epoch [37/300], Step [7/225], Training Accuracy: 76.7857%, Training Loss: 0.5154%\n",
      "Epoch [37/300], Step [8/225], Training Accuracy: 75.9766%, Training Loss: 0.5361%\n",
      "Epoch [37/300], Step [9/225], Training Accuracy: 76.5625%, Training Loss: 0.5346%\n",
      "Epoch [37/300], Step [10/225], Training Accuracy: 76.5625%, Training Loss: 0.5446%\n",
      "Epoch [37/300], Step [11/225], Training Accuracy: 76.8466%, Training Loss: 0.5343%\n",
      "Epoch [37/300], Step [12/225], Training Accuracy: 76.9531%, Training Loss: 0.5322%\n",
      "Epoch [37/300], Step [13/225], Training Accuracy: 77.4038%, Training Loss: 0.5227%\n",
      "Epoch [37/300], Step [14/225], Training Accuracy: 77.4554%, Training Loss: 0.5180%\n",
      "Epoch [37/300], Step [15/225], Training Accuracy: 77.8125%, Training Loss: 0.5161%\n",
      "Epoch [37/300], Step [16/225], Training Accuracy: 77.3438%, Training Loss: 0.5271%\n",
      "Epoch [37/300], Step [17/225], Training Accuracy: 77.6654%, Training Loss: 0.5236%\n",
      "Epoch [37/300], Step [18/225], Training Accuracy: 77.7778%, Training Loss: 0.5204%\n",
      "Epoch [37/300], Step [19/225], Training Accuracy: 77.7138%, Training Loss: 0.5214%\n",
      "Epoch [37/300], Step [20/225], Training Accuracy: 78.2031%, Training Loss: 0.5142%\n",
      "Epoch [37/300], Step [21/225], Training Accuracy: 78.1994%, Training Loss: 0.5107%\n",
      "Epoch [37/300], Step [22/225], Training Accuracy: 77.8409%, Training Loss: 0.5178%\n",
      "Epoch [37/300], Step [23/225], Training Accuracy: 77.5136%, Training Loss: 0.5197%\n",
      "Epoch [37/300], Step [24/225], Training Accuracy: 77.4740%, Training Loss: 0.5185%\n",
      "Epoch [37/300], Step [25/225], Training Accuracy: 77.4375%, Training Loss: 0.5189%\n",
      "Epoch [37/300], Step [26/225], Training Accuracy: 77.4639%, Training Loss: 0.5200%\n",
      "Epoch [37/300], Step [27/225], Training Accuracy: 77.3148%, Training Loss: 0.5228%\n",
      "Epoch [37/300], Step [28/225], Training Accuracy: 77.5670%, Training Loss: 0.5191%\n",
      "Epoch [37/300], Step [29/225], Training Accuracy: 77.7478%, Training Loss: 0.5143%\n",
      "Epoch [37/300], Step [30/225], Training Accuracy: 77.7083%, Training Loss: 0.5144%\n",
      "Epoch [37/300], Step [31/225], Training Accuracy: 77.5202%, Training Loss: 0.5184%\n",
      "Epoch [37/300], Step [32/225], Training Accuracy: 77.4414%, Training Loss: 0.5176%\n",
      "Epoch [37/300], Step [33/225], Training Accuracy: 77.6042%, Training Loss: 0.5178%\n",
      "Epoch [37/300], Step [34/225], Training Accuracy: 77.1599%, Training Loss: 0.5265%\n",
      "Epoch [37/300], Step [35/225], Training Accuracy: 77.1875%, Training Loss: 0.5285%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/300], Step [36/225], Training Accuracy: 77.2135%, Training Loss: 0.5265%\n",
      "Epoch [37/300], Step [37/225], Training Accuracy: 77.2382%, Training Loss: 0.5246%\n",
      "Epoch [37/300], Step [38/225], Training Accuracy: 77.2615%, Training Loss: 0.5231%\n",
      "Epoch [37/300], Step [39/225], Training Accuracy: 77.2837%, Training Loss: 0.5238%\n",
      "Epoch [37/300], Step [40/225], Training Accuracy: 77.2656%, Training Loss: 0.5242%\n",
      "Epoch [37/300], Step [41/225], Training Accuracy: 77.1341%, Training Loss: 0.5292%\n",
      "Epoch [37/300], Step [42/225], Training Accuracy: 76.8601%, Training Loss: 0.5343%\n",
      "Epoch [37/300], Step [43/225], Training Accuracy: 77.0349%, Training Loss: 0.5326%\n",
      "Epoch [37/300], Step [44/225], Training Accuracy: 77.2017%, Training Loss: 0.5308%\n",
      "Epoch [37/300], Step [45/225], Training Accuracy: 77.1181%, Training Loss: 0.5323%\n",
      "Epoch [37/300], Step [46/225], Training Accuracy: 77.0041%, Training Loss: 0.5341%\n",
      "Epoch [37/300], Step [47/225], Training Accuracy: 76.8285%, Training Loss: 0.5374%\n",
      "Epoch [37/300], Step [48/225], Training Accuracy: 76.5951%, Training Loss: 0.5393%\n",
      "Epoch [37/300], Step [49/225], Training Accuracy: 76.4987%, Training Loss: 0.5406%\n",
      "Epoch [37/300], Step [50/225], Training Accuracy: 76.3750%, Training Loss: 0.5417%\n",
      "Epoch [37/300], Step [51/225], Training Accuracy: 76.3787%, Training Loss: 0.5407%\n",
      "Epoch [37/300], Step [52/225], Training Accuracy: 76.5024%, Training Loss: 0.5394%\n",
      "Epoch [37/300], Step [53/225], Training Accuracy: 76.5035%, Training Loss: 0.5402%\n",
      "Epoch [37/300], Step [54/225], Training Accuracy: 76.4468%, Training Loss: 0.5414%\n",
      "Epoch [37/300], Step [55/225], Training Accuracy: 76.3068%, Training Loss: 0.5457%\n",
      "Epoch [37/300], Step [56/225], Training Accuracy: 76.2835%, Training Loss: 0.5455%\n",
      "Epoch [37/300], Step [57/225], Training Accuracy: 76.1513%, Training Loss: 0.5478%\n",
      "Epoch [37/300], Step [58/225], Training Accuracy: 76.2123%, Training Loss: 0.5468%\n",
      "Epoch [37/300], Step [59/225], Training Accuracy: 76.0858%, Training Loss: 0.5501%\n",
      "Epoch [37/300], Step [60/225], Training Accuracy: 76.1979%, Training Loss: 0.5480%\n",
      "Epoch [37/300], Step [61/225], Training Accuracy: 76.1783%, Training Loss: 0.5472%\n",
      "Epoch [37/300], Step [62/225], Training Accuracy: 76.2349%, Training Loss: 0.5459%\n",
      "Epoch [37/300], Step [63/225], Training Accuracy: 76.2401%, Training Loss: 0.5457%\n",
      "Epoch [37/300], Step [64/225], Training Accuracy: 76.1475%, Training Loss: 0.5467%\n",
      "Epoch [37/300], Step [65/225], Training Accuracy: 76.1538%, Training Loss: 0.5458%\n",
      "Epoch [37/300], Step [66/225], Training Accuracy: 76.1364%, Training Loss: 0.5458%\n",
      "Epoch [37/300], Step [67/225], Training Accuracy: 76.1660%, Training Loss: 0.5458%\n",
      "Epoch [37/300], Step [68/225], Training Accuracy: 76.1259%, Training Loss: 0.5449%\n",
      "Epoch [37/300], Step [69/225], Training Accuracy: 76.3134%, Training Loss: 0.5422%\n",
      "Epoch [37/300], Step [70/225], Training Accuracy: 76.3170%, Training Loss: 0.5423%\n",
      "Epoch [37/300], Step [71/225], Training Accuracy: 76.2324%, Training Loss: 0.5423%\n",
      "Epoch [37/300], Step [72/225], Training Accuracy: 76.3021%, Training Loss: 0.5412%\n",
      "Epoch [37/300], Step [73/225], Training Accuracy: 76.2842%, Training Loss: 0.5429%\n",
      "Epoch [37/300], Step [74/225], Training Accuracy: 76.3936%, Training Loss: 0.5406%\n",
      "Epoch [37/300], Step [75/225], Training Accuracy: 76.3125%, Training Loss: 0.5415%\n",
      "Epoch [37/300], Step [76/225], Training Accuracy: 76.2541%, Training Loss: 0.5427%\n",
      "Epoch [37/300], Step [77/225], Training Accuracy: 76.3190%, Training Loss: 0.5426%\n",
      "Epoch [37/300], Step [78/225], Training Accuracy: 76.4824%, Training Loss: 0.5406%\n",
      "Epoch [37/300], Step [79/225], Training Accuracy: 76.5427%, Training Loss: 0.5390%\n",
      "Epoch [37/300], Step [80/225], Training Accuracy: 76.4258%, Training Loss: 0.5399%\n",
      "Epoch [37/300], Step [81/225], Training Accuracy: 76.4853%, Training Loss: 0.5395%\n",
      "Epoch [37/300], Step [82/225], Training Accuracy: 76.5053%, Training Loss: 0.5398%\n",
      "Epoch [37/300], Step [83/225], Training Accuracy: 76.3931%, Training Loss: 0.5412%\n",
      "Epoch [37/300], Step [84/225], Training Accuracy: 76.4323%, Training Loss: 0.5402%\n",
      "Epoch [37/300], Step [85/225], Training Accuracy: 76.3603%, Training Loss: 0.5402%\n",
      "Epoch [37/300], Step [86/225], Training Accuracy: 76.3808%, Training Loss: 0.5391%\n",
      "Epoch [37/300], Step [87/225], Training Accuracy: 76.3829%, Training Loss: 0.5384%\n",
      "Epoch [37/300], Step [88/225], Training Accuracy: 76.2607%, Training Loss: 0.5403%\n",
      "Epoch [37/300], Step [89/225], Training Accuracy: 76.3343%, Training Loss: 0.5399%\n",
      "Epoch [37/300], Step [90/225], Training Accuracy: 76.2847%, Training Loss: 0.5410%\n",
      "Epoch [37/300], Step [91/225], Training Accuracy: 76.3221%, Training Loss: 0.5404%\n",
      "Epoch [37/300], Step [92/225], Training Accuracy: 76.3247%, Training Loss: 0.5404%\n",
      "Epoch [37/300], Step [93/225], Training Accuracy: 76.3945%, Training Loss: 0.5394%\n",
      "Epoch [37/300], Step [94/225], Training Accuracy: 76.4129%, Training Loss: 0.5386%\n",
      "Epoch [37/300], Step [95/225], Training Accuracy: 76.3980%, Training Loss: 0.5389%\n",
      "Epoch [37/300], Step [96/225], Training Accuracy: 76.4974%, Training Loss: 0.5375%\n",
      "Epoch [37/300], Step [97/225], Training Accuracy: 76.5142%, Training Loss: 0.5363%\n",
      "Epoch [37/300], Step [98/225], Training Accuracy: 76.5306%, Training Loss: 0.5361%\n",
      "Epoch [37/300], Step [99/225], Training Accuracy: 76.4678%, Training Loss: 0.5375%\n",
      "Epoch [37/300], Step [100/225], Training Accuracy: 76.4219%, Training Loss: 0.5387%\n",
      "Epoch [37/300], Step [101/225], Training Accuracy: 76.4851%, Training Loss: 0.5382%\n",
      "Epoch [37/300], Step [102/225], Training Accuracy: 76.4553%, Training Loss: 0.5393%\n",
      "Epoch [37/300], Step [103/225], Training Accuracy: 76.4411%, Training Loss: 0.5399%\n",
      "Epoch [37/300], Step [104/225], Training Accuracy: 76.3672%, Training Loss: 0.5407%\n",
      "Epoch [37/300], Step [105/225], Training Accuracy: 76.4286%, Training Loss: 0.5397%\n",
      "Epoch [37/300], Step [106/225], Training Accuracy: 76.4446%, Training Loss: 0.5397%\n",
      "Epoch [37/300], Step [107/225], Training Accuracy: 76.4019%, Training Loss: 0.5402%\n",
      "Epoch [37/300], Step [108/225], Training Accuracy: 76.4178%, Training Loss: 0.5408%\n",
      "Epoch [37/300], Step [109/225], Training Accuracy: 76.4048%, Training Loss: 0.5402%\n",
      "Epoch [37/300], Step [110/225], Training Accuracy: 76.3920%, Training Loss: 0.5415%\n",
      "Epoch [37/300], Step [111/225], Training Accuracy: 76.4217%, Training Loss: 0.5414%\n",
      "Epoch [37/300], Step [112/225], Training Accuracy: 76.3393%, Training Loss: 0.5417%\n",
      "Epoch [37/300], Step [113/225], Training Accuracy: 76.2860%, Training Loss: 0.5419%\n",
      "Epoch [37/300], Step [114/225], Training Accuracy: 76.3706%, Training Loss: 0.5406%\n",
      "Epoch [37/300], Step [115/225], Training Accuracy: 76.3723%, Training Loss: 0.5412%\n",
      "Epoch [37/300], Step [116/225], Training Accuracy: 76.3739%, Training Loss: 0.5418%\n",
      "Epoch [37/300], Step [117/225], Training Accuracy: 76.3889%, Training Loss: 0.5421%\n",
      "Epoch [37/300], Step [118/225], Training Accuracy: 76.4168%, Training Loss: 0.5419%\n",
      "Epoch [37/300], Step [119/225], Training Accuracy: 76.4049%, Training Loss: 0.5423%\n",
      "Epoch [37/300], Step [120/225], Training Accuracy: 76.3802%, Training Loss: 0.5428%\n",
      "Epoch [37/300], Step [121/225], Training Accuracy: 76.4075%, Training Loss: 0.5422%\n",
      "Epoch [37/300], Step [122/225], Training Accuracy: 76.3832%, Training Loss: 0.5427%\n",
      "Epoch [37/300], Step [123/225], Training Accuracy: 76.3720%, Training Loss: 0.5428%\n",
      "Epoch [37/300], Step [124/225], Training Accuracy: 76.3483%, Training Loss: 0.5433%\n",
      "Epoch [37/300], Step [125/225], Training Accuracy: 76.2750%, Training Loss: 0.5443%\n",
      "Epoch [37/300], Step [126/225], Training Accuracy: 76.3021%, Training Loss: 0.5440%\n",
      "Epoch [37/300], Step [127/225], Training Accuracy: 76.3656%, Training Loss: 0.5436%\n",
      "Epoch [37/300], Step [128/225], Training Accuracy: 76.3184%, Training Loss: 0.5441%\n",
      "Epoch [37/300], Step [129/225], Training Accuracy: 76.3203%, Training Loss: 0.5443%\n",
      "Epoch [37/300], Step [130/225], Training Accuracy: 76.2861%, Training Loss: 0.5448%\n",
      "Epoch [37/300], Step [131/225], Training Accuracy: 76.3001%, Training Loss: 0.5448%\n",
      "Epoch [37/300], Step [132/225], Training Accuracy: 76.3139%, Training Loss: 0.5448%\n",
      "Epoch [37/300], Step [133/225], Training Accuracy: 76.2923%, Training Loss: 0.5446%\n",
      "Epoch [37/300], Step [134/225], Training Accuracy: 76.2826%, Training Loss: 0.5455%\n",
      "Epoch [37/300], Step [135/225], Training Accuracy: 76.2963%, Training Loss: 0.5453%\n",
      "Epoch [37/300], Step [136/225], Training Accuracy: 76.3097%, Training Loss: 0.5452%\n",
      "Epoch [37/300], Step [137/225], Training Accuracy: 76.3116%, Training Loss: 0.5444%\n",
      "Epoch [37/300], Step [138/225], Training Accuracy: 76.4153%, Training Loss: 0.5430%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/300], Step [139/225], Training Accuracy: 76.4051%, Training Loss: 0.5427%\n",
      "Epoch [37/300], Step [140/225], Training Accuracy: 76.4397%, Training Loss: 0.5421%\n",
      "Epoch [37/300], Step [141/225], Training Accuracy: 76.4628%, Training Loss: 0.5424%\n",
      "Epoch [37/300], Step [142/225], Training Accuracy: 76.4525%, Training Loss: 0.5417%\n",
      "Epoch [37/300], Step [143/225], Training Accuracy: 76.4314%, Training Loss: 0.5420%\n",
      "Epoch [37/300], Step [144/225], Training Accuracy: 76.4214%, Training Loss: 0.5418%\n",
      "Epoch [37/300], Step [145/225], Training Accuracy: 76.3793%, Training Loss: 0.5431%\n",
      "Epoch [37/300], Step [146/225], Training Accuracy: 76.3378%, Training Loss: 0.5448%\n",
      "Epoch [37/300], Step [147/225], Training Accuracy: 76.3818%, Training Loss: 0.5443%\n",
      "Epoch [37/300], Step [148/225], Training Accuracy: 76.4253%, Training Loss: 0.5436%\n",
      "Epoch [37/300], Step [149/225], Training Accuracy: 76.4471%, Training Loss: 0.5434%\n",
      "Epoch [37/300], Step [150/225], Training Accuracy: 76.5104%, Training Loss: 0.5421%\n",
      "Epoch [37/300], Step [151/225], Training Accuracy: 76.4797%, Training Loss: 0.5425%\n",
      "Epoch [37/300], Step [152/225], Training Accuracy: 76.4597%, Training Loss: 0.5424%\n",
      "Epoch [37/300], Step [153/225], Training Accuracy: 76.4297%, Training Loss: 0.5430%\n",
      "Epoch [37/300], Step [154/225], Training Accuracy: 76.3697%, Training Loss: 0.5430%\n",
      "Epoch [37/300], Step [155/225], Training Accuracy: 76.4012%, Training Loss: 0.5433%\n",
      "Epoch [37/300], Step [156/225], Training Accuracy: 76.3522%, Training Loss: 0.5442%\n",
      "Epoch [37/300], Step [157/225], Training Accuracy: 76.3535%, Training Loss: 0.5442%\n",
      "Epoch [37/300], Step [158/225], Training Accuracy: 76.2955%, Training Loss: 0.5456%\n",
      "Epoch [37/300], Step [159/225], Training Accuracy: 76.2677%, Training Loss: 0.5465%\n",
      "Epoch [37/300], Step [160/225], Training Accuracy: 76.3184%, Training Loss: 0.5456%\n",
      "Epoch [37/300], Step [161/225], Training Accuracy: 76.3296%, Training Loss: 0.5450%\n",
      "Epoch [37/300], Step [162/225], Training Accuracy: 76.3503%, Training Loss: 0.5445%\n",
      "Epoch [37/300], Step [163/225], Training Accuracy: 76.3612%, Training Loss: 0.5442%\n",
      "Epoch [37/300], Step [164/225], Training Accuracy: 76.4005%, Training Loss: 0.5437%\n",
      "Epoch [37/300], Step [165/225], Training Accuracy: 76.4015%, Training Loss: 0.5437%\n",
      "Epoch [37/300], Step [166/225], Training Accuracy: 76.4401%, Training Loss: 0.5431%\n",
      "Epoch [37/300], Step [167/225], Training Accuracy: 76.4689%, Training Loss: 0.5432%\n",
      "Epoch [37/300], Step [168/225], Training Accuracy: 76.4323%, Training Loss: 0.5438%\n",
      "Epoch [37/300], Step [169/225], Training Accuracy: 76.4700%, Training Loss: 0.5429%\n",
      "Epoch [37/300], Step [170/225], Training Accuracy: 76.4430%, Training Loss: 0.5437%\n",
      "Epoch [37/300], Step [171/225], Training Accuracy: 76.4254%, Training Loss: 0.5440%\n",
      "Epoch [37/300], Step [172/225], Training Accuracy: 76.3899%, Training Loss: 0.5446%\n",
      "Epoch [37/300], Step [173/225], Training Accuracy: 76.3638%, Training Loss: 0.5457%\n",
      "Epoch [37/300], Step [174/225], Training Accuracy: 76.3739%, Training Loss: 0.5452%\n",
      "Epoch [37/300], Step [175/225], Training Accuracy: 76.3839%, Training Loss: 0.5449%\n",
      "Epoch [37/300], Step [176/225], Training Accuracy: 76.3672%, Training Loss: 0.5450%\n",
      "Epoch [37/300], Step [177/225], Training Accuracy: 76.3506%, Training Loss: 0.5455%\n",
      "Epoch [37/300], Step [178/225], Training Accuracy: 76.3343%, Training Loss: 0.5457%\n",
      "Epoch [37/300], Step [179/225], Training Accuracy: 76.3355%, Training Loss: 0.5452%\n",
      "Epoch [37/300], Step [180/225], Training Accuracy: 76.3628%, Training Loss: 0.5450%\n",
      "Epoch [37/300], Step [181/225], Training Accuracy: 76.3726%, Training Loss: 0.5460%\n",
      "Epoch [37/300], Step [182/225], Training Accuracy: 76.3393%, Training Loss: 0.5466%\n",
      "Epoch [37/300], Step [183/225], Training Accuracy: 76.3320%, Training Loss: 0.5468%\n",
      "Epoch [37/300], Step [184/225], Training Accuracy: 76.3757%, Training Loss: 0.5459%\n",
      "Epoch [37/300], Step [185/225], Training Accuracy: 76.3682%, Training Loss: 0.5459%\n",
      "Epoch [37/300], Step [186/225], Training Accuracy: 76.4281%, Training Loss: 0.5450%\n",
      "Epoch [37/300], Step [187/225], Training Accuracy: 76.4037%, Training Loss: 0.5448%\n",
      "Epoch [37/300], Step [188/225], Training Accuracy: 76.4295%, Training Loss: 0.5444%\n",
      "Epoch [37/300], Step [189/225], Training Accuracy: 76.4385%, Training Loss: 0.5438%\n",
      "Epoch [37/300], Step [190/225], Training Accuracy: 76.4145%, Training Loss: 0.5440%\n",
      "Epoch [37/300], Step [191/225], Training Accuracy: 76.4071%, Training Loss: 0.5437%\n",
      "Epoch [37/300], Step [192/225], Training Accuracy: 76.4323%, Training Loss: 0.5436%\n",
      "Epoch [37/300], Step [193/225], Training Accuracy: 76.4087%, Training Loss: 0.5437%\n",
      "Epoch [37/300], Step [194/225], Training Accuracy: 76.3934%, Training Loss: 0.5440%\n",
      "Epoch [37/300], Step [195/225], Training Accuracy: 76.4663%, Training Loss: 0.5445%\n",
      "Epoch [37/300], Step [196/225], Training Accuracy: 76.4190%, Training Loss: 0.5450%\n",
      "Epoch [37/300], Step [197/225], Training Accuracy: 76.4197%, Training Loss: 0.5450%\n",
      "Epoch [37/300], Step [198/225], Training Accuracy: 76.4520%, Training Loss: 0.5449%\n",
      "Epoch [37/300], Step [199/225], Training Accuracy: 76.4604%, Training Loss: 0.5448%\n",
      "Epoch [37/300], Step [200/225], Training Accuracy: 76.4844%, Training Loss: 0.5442%\n",
      "Epoch [37/300], Step [201/225], Training Accuracy: 76.4848%, Training Loss: 0.5445%\n",
      "Epoch [37/300], Step [202/225], Training Accuracy: 76.5238%, Training Loss: 0.5436%\n",
      "Epoch [37/300], Step [203/225], Training Accuracy: 76.5394%, Training Loss: 0.5430%\n",
      "Epoch [37/300], Step [204/225], Training Accuracy: 76.5472%, Training Loss: 0.5434%\n",
      "Epoch [37/300], Step [205/225], Training Accuracy: 76.5777%, Training Loss: 0.5432%\n",
      "Epoch [37/300], Step [206/225], Training Accuracy: 76.5701%, Training Loss: 0.5433%\n",
      "Epoch [37/300], Step [207/225], Training Accuracy: 76.5700%, Training Loss: 0.5433%\n",
      "Epoch [37/300], Step [208/225], Training Accuracy: 76.5550%, Training Loss: 0.5434%\n",
      "Epoch [37/300], Step [209/225], Training Accuracy: 76.5326%, Training Loss: 0.5434%\n",
      "Epoch [37/300], Step [210/225], Training Accuracy: 76.4658%, Training Loss: 0.5441%\n",
      "Epoch [37/300], Step [211/225], Training Accuracy: 76.4440%, Training Loss: 0.5441%\n",
      "Epoch [37/300], Step [212/225], Training Accuracy: 76.4372%, Training Loss: 0.5443%\n",
      "Epoch [37/300], Step [213/225], Training Accuracy: 76.4451%, Training Loss: 0.5444%\n",
      "Epoch [37/300], Step [214/225], Training Accuracy: 76.4603%, Training Loss: 0.5442%\n",
      "Epoch [37/300], Step [215/225], Training Accuracy: 76.4608%, Training Loss: 0.5440%\n",
      "Epoch [37/300], Step [216/225], Training Accuracy: 76.4685%, Training Loss: 0.5444%\n",
      "Epoch [37/300], Step [217/225], Training Accuracy: 76.4545%, Training Loss: 0.5443%\n",
      "Epoch [37/300], Step [218/225], Training Accuracy: 76.4478%, Training Loss: 0.5446%\n",
      "Epoch [37/300], Step [219/225], Training Accuracy: 76.4127%, Training Loss: 0.5452%\n",
      "Epoch [37/300], Step [220/225], Training Accuracy: 76.4773%, Training Loss: 0.5443%\n",
      "Epoch [37/300], Step [221/225], Training Accuracy: 76.5130%, Training Loss: 0.5440%\n",
      "Epoch [37/300], Step [222/225], Training Accuracy: 76.4780%, Training Loss: 0.5444%\n",
      "Epoch [37/300], Step [223/225], Training Accuracy: 76.5205%, Training Loss: 0.5438%\n",
      "Epoch [37/300], Step [224/225], Training Accuracy: 76.5346%, Training Loss: 0.5436%\n",
      "Epoch [37/300], Step [225/225], Training Accuracy: 76.5773%, Training Loss: 0.5429%\n",
      "Epoch [38/300], Step [1/225], Training Accuracy: 87.5000%, Training Loss: 0.4251%\n",
      "Epoch [38/300], Step [2/225], Training Accuracy: 84.3750%, Training Loss: 0.4642%\n",
      "Epoch [38/300], Step [3/225], Training Accuracy: 81.2500%, Training Loss: 0.4935%\n",
      "Epoch [38/300], Step [4/225], Training Accuracy: 80.4688%, Training Loss: 0.4960%\n",
      "Epoch [38/300], Step [5/225], Training Accuracy: 80.3125%, Training Loss: 0.5050%\n",
      "Epoch [38/300], Step [6/225], Training Accuracy: 80.2083%, Training Loss: 0.5000%\n",
      "Epoch [38/300], Step [7/225], Training Accuracy: 80.1339%, Training Loss: 0.4897%\n",
      "Epoch [38/300], Step [8/225], Training Accuracy: 78.7109%, Training Loss: 0.5133%\n",
      "Epoch [38/300], Step [9/225], Training Accuracy: 77.4306%, Training Loss: 0.5345%\n",
      "Epoch [38/300], Step [10/225], Training Accuracy: 76.4062%, Training Loss: 0.5506%\n",
      "Epoch [38/300], Step [11/225], Training Accuracy: 76.7045%, Training Loss: 0.5542%\n",
      "Epoch [38/300], Step [12/225], Training Accuracy: 76.8229%, Training Loss: 0.5598%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/300], Step [13/225], Training Accuracy: 77.4038%, Training Loss: 0.5476%\n",
      "Epoch [38/300], Step [14/225], Training Accuracy: 76.8973%, Training Loss: 0.5558%\n",
      "Epoch [38/300], Step [15/225], Training Accuracy: 76.7708%, Training Loss: 0.5611%\n",
      "Epoch [38/300], Step [16/225], Training Accuracy: 76.6602%, Training Loss: 0.5629%\n",
      "Epoch [38/300], Step [17/225], Training Accuracy: 76.8382%, Training Loss: 0.5564%\n",
      "Epoch [38/300], Step [18/225], Training Accuracy: 76.5625%, Training Loss: 0.5631%\n",
      "Epoch [38/300], Step [19/225], Training Accuracy: 76.5625%, Training Loss: 0.5617%\n",
      "Epoch [38/300], Step [20/225], Training Accuracy: 76.4062%, Training Loss: 0.5606%\n",
      "Epoch [38/300], Step [21/225], Training Accuracy: 76.8601%, Training Loss: 0.5516%\n",
      "Epoch [38/300], Step [22/225], Training Accuracy: 76.6335%, Training Loss: 0.5531%\n",
      "Epoch [38/300], Step [23/225], Training Accuracy: 76.4946%, Training Loss: 0.5514%\n",
      "Epoch [38/300], Step [24/225], Training Accuracy: 76.4974%, Training Loss: 0.5543%\n",
      "Epoch [38/300], Step [25/225], Training Accuracy: 76.5000%, Training Loss: 0.5559%\n",
      "Epoch [38/300], Step [26/225], Training Accuracy: 76.5024%, Training Loss: 0.5542%\n",
      "Epoch [38/300], Step [27/225], Training Accuracy: 76.3310%, Training Loss: 0.5550%\n",
      "Epoch [38/300], Step [28/225], Training Accuracy: 76.4509%, Training Loss: 0.5508%\n",
      "Epoch [38/300], Step [29/225], Training Accuracy: 76.6164%, Training Loss: 0.5506%\n",
      "Epoch [38/300], Step [30/225], Training Accuracy: 76.6667%, Training Loss: 0.5512%\n",
      "Epoch [38/300], Step [31/225], Training Accuracy: 76.7137%, Training Loss: 0.5542%\n",
      "Epoch [38/300], Step [32/225], Training Accuracy: 76.6113%, Training Loss: 0.5542%\n",
      "Epoch [38/300], Step [33/225], Training Accuracy: 76.6572%, Training Loss: 0.5514%\n",
      "Epoch [38/300], Step [34/225], Training Accuracy: 76.2868%, Training Loss: 0.5615%\n",
      "Epoch [38/300], Step [35/225], Training Accuracy: 76.0714%, Training Loss: 0.5663%\n",
      "Epoch [38/300], Step [36/225], Training Accuracy: 75.9115%, Training Loss: 0.5696%\n",
      "Epoch [38/300], Step [37/225], Training Accuracy: 75.9291%, Training Loss: 0.5700%\n",
      "Epoch [38/300], Step [38/225], Training Accuracy: 75.8224%, Training Loss: 0.5702%\n",
      "Epoch [38/300], Step [39/225], Training Accuracy: 75.8013%, Training Loss: 0.5716%\n",
      "Epoch [38/300], Step [40/225], Training Accuracy: 76.0156%, Training Loss: 0.5670%\n",
      "Epoch [38/300], Step [41/225], Training Accuracy: 75.5335%, Training Loss: 0.5744%\n",
      "Epoch [38/300], Step [42/225], Training Accuracy: 75.4836%, Training Loss: 0.5764%\n",
      "Epoch [38/300], Step [43/225], Training Accuracy: 75.5451%, Training Loss: 0.5752%\n",
      "Epoch [38/300], Step [44/225], Training Accuracy: 75.6747%, Training Loss: 0.5728%\n",
      "Epoch [38/300], Step [45/225], Training Accuracy: 75.6250%, Training Loss: 0.5720%\n",
      "Epoch [38/300], Step [46/225], Training Accuracy: 75.5774%, Training Loss: 0.5730%\n",
      "Epoch [38/300], Step [47/225], Training Accuracy: 75.4654%, Training Loss: 0.5732%\n",
      "Epoch [38/300], Step [48/225], Training Accuracy: 75.4232%, Training Loss: 0.5729%\n",
      "Epoch [38/300], Step [49/225], Training Accuracy: 75.4145%, Training Loss: 0.5704%\n",
      "Epoch [38/300], Step [50/225], Training Accuracy: 75.4062%, Training Loss: 0.5696%\n",
      "Epoch [38/300], Step [51/225], Training Accuracy: 75.5821%, Training Loss: 0.5686%\n",
      "Epoch [38/300], Step [52/225], Training Accuracy: 75.8113%, Training Loss: 0.5647%\n",
      "Epoch [38/300], Step [53/225], Training Accuracy: 75.9729%, Training Loss: 0.5626%\n",
      "Epoch [38/300], Step [54/225], Training Accuracy: 75.9549%, Training Loss: 0.5645%\n",
      "Epoch [38/300], Step [55/225], Training Accuracy: 75.9659%, Training Loss: 0.5645%\n",
      "Epoch [38/300], Step [56/225], Training Accuracy: 75.9487%, Training Loss: 0.5648%\n",
      "Epoch [38/300], Step [57/225], Training Accuracy: 75.9046%, Training Loss: 0.5648%\n",
      "Epoch [38/300], Step [58/225], Training Accuracy: 75.8351%, Training Loss: 0.5656%\n",
      "Epoch [38/300], Step [59/225], Training Accuracy: 75.8475%, Training Loss: 0.5663%\n",
      "Epoch [38/300], Step [60/225], Training Accuracy: 75.8854%, Training Loss: 0.5657%\n",
      "Epoch [38/300], Step [61/225], Training Accuracy: 75.9221%, Training Loss: 0.5645%\n",
      "Epoch [38/300], Step [62/225], Training Accuracy: 75.9577%, Training Loss: 0.5636%\n",
      "Epoch [38/300], Step [63/225], Training Accuracy: 75.7937%, Training Loss: 0.5655%\n",
      "Epoch [38/300], Step [64/225], Training Accuracy: 75.8301%, Training Loss: 0.5658%\n",
      "Epoch [38/300], Step [65/225], Training Accuracy: 75.8654%, Training Loss: 0.5643%\n",
      "Epoch [38/300], Step [66/225], Training Accuracy: 75.9233%, Training Loss: 0.5626%\n",
      "Epoch [38/300], Step [67/225], Training Accuracy: 75.9562%, Training Loss: 0.5633%\n",
      "Epoch [38/300], Step [68/225], Training Accuracy: 76.0110%, Training Loss: 0.5631%\n",
      "Epoch [38/300], Step [69/225], Training Accuracy: 75.9737%, Training Loss: 0.5634%\n",
      "Epoch [38/300], Step [70/225], Training Accuracy: 76.0491%, Training Loss: 0.5612%\n",
      "Epoch [38/300], Step [71/225], Training Accuracy: 76.0343%, Training Loss: 0.5615%\n",
      "Epoch [38/300], Step [72/225], Training Accuracy: 76.1068%, Training Loss: 0.5598%\n",
      "Epoch [38/300], Step [73/225], Training Accuracy: 76.1986%, Training Loss: 0.5583%\n",
      "Epoch [38/300], Step [74/225], Training Accuracy: 76.1824%, Training Loss: 0.5572%\n",
      "Epoch [38/300], Step [75/225], Training Accuracy: 76.1667%, Training Loss: 0.5573%\n",
      "Epoch [38/300], Step [76/225], Training Accuracy: 76.0074%, Training Loss: 0.5587%\n",
      "Epoch [38/300], Step [77/225], Training Accuracy: 76.0146%, Training Loss: 0.5594%\n",
      "Epoch [38/300], Step [78/225], Training Accuracy: 75.9215%, Training Loss: 0.5609%\n",
      "Epoch [38/300], Step [79/225], Training Accuracy: 75.8900%, Training Loss: 0.5614%\n",
      "Epoch [38/300], Step [80/225], Training Accuracy: 75.7422%, Training Loss: 0.5619%\n",
      "Epoch [38/300], Step [81/225], Training Accuracy: 75.8295%, Training Loss: 0.5597%\n",
      "Epoch [38/300], Step [82/225], Training Accuracy: 75.9337%, Training Loss: 0.5575%\n",
      "Epoch [38/300], Step [83/225], Training Accuracy: 75.8848%, Training Loss: 0.5592%\n",
      "Epoch [38/300], Step [84/225], Training Accuracy: 75.9859%, Training Loss: 0.5583%\n",
      "Epoch [38/300], Step [85/225], Training Accuracy: 76.0294%, Training Loss: 0.5575%\n",
      "Epoch [38/300], Step [86/225], Training Accuracy: 76.1083%, Training Loss: 0.5567%\n",
      "Epoch [38/300], Step [87/225], Training Accuracy: 76.0955%, Training Loss: 0.5556%\n",
      "Epoch [38/300], Step [88/225], Training Accuracy: 76.1009%, Training Loss: 0.5564%\n",
      "Epoch [38/300], Step [89/225], Training Accuracy: 76.1763%, Training Loss: 0.5567%\n",
      "Epoch [38/300], Step [90/225], Training Accuracy: 76.1632%, Training Loss: 0.5581%\n",
      "Epoch [38/300], Step [91/225], Training Accuracy: 76.2019%, Training Loss: 0.5565%\n",
      "Epoch [38/300], Step [92/225], Training Accuracy: 76.1379%, Training Loss: 0.5579%\n",
      "Epoch [38/300], Step [93/225], Training Accuracy: 76.2433%, Training Loss: 0.5569%\n",
      "Epoch [38/300], Step [94/225], Training Accuracy: 76.2633%, Training Loss: 0.5558%\n",
      "Epoch [38/300], Step [95/225], Training Accuracy: 76.2007%, Training Loss: 0.5574%\n",
      "Epoch [38/300], Step [96/225], Training Accuracy: 76.2695%, Training Loss: 0.5561%\n",
      "Epoch [38/300], Step [97/225], Training Accuracy: 76.4014%, Training Loss: 0.5538%\n",
      "Epoch [38/300], Step [98/225], Training Accuracy: 76.3074%, Training Loss: 0.5545%\n",
      "Epoch [38/300], Step [99/225], Training Accuracy: 76.2942%, Training Loss: 0.5549%\n",
      "Epoch [38/300], Step [100/225], Training Accuracy: 76.2031%, Training Loss: 0.5573%\n",
      "Epoch [38/300], Step [101/225], Training Accuracy: 76.2067%, Training Loss: 0.5584%\n",
      "Epoch [38/300], Step [102/225], Training Accuracy: 76.1642%, Training Loss: 0.5587%\n",
      "Epoch [38/300], Step [103/225], Training Accuracy: 76.2136%, Training Loss: 0.5572%\n",
      "Epoch [38/300], Step [104/225], Training Accuracy: 76.2770%, Training Loss: 0.5564%\n",
      "Epoch [38/300], Step [105/225], Training Accuracy: 76.3988%, Training Loss: 0.5545%\n",
      "Epoch [38/300], Step [106/225], Training Accuracy: 76.3709%, Training Loss: 0.5546%\n",
      "Epoch [38/300], Step [107/225], Training Accuracy: 76.4019%, Training Loss: 0.5544%\n",
      "Epoch [38/300], Step [108/225], Training Accuracy: 76.3744%, Training Loss: 0.5544%\n",
      "Epoch [38/300], Step [109/225], Training Accuracy: 76.3618%, Training Loss: 0.5537%\n",
      "Epoch [38/300], Step [110/225], Training Accuracy: 76.3636%, Training Loss: 0.5537%\n",
      "Epoch [38/300], Step [111/225], Training Accuracy: 76.4077%, Training Loss: 0.5542%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/300], Step [112/225], Training Accuracy: 76.4927%, Training Loss: 0.5527%\n",
      "Epoch [38/300], Step [113/225], Training Accuracy: 76.5072%, Training Loss: 0.5532%\n",
      "Epoch [38/300], Step [114/225], Training Accuracy: 76.4391%, Training Loss: 0.5536%\n",
      "Epoch [38/300], Step [115/225], Training Accuracy: 76.4810%, Training Loss: 0.5533%\n",
      "Epoch [38/300], Step [116/225], Training Accuracy: 76.4682%, Training Loss: 0.5536%\n",
      "Epoch [38/300], Step [117/225], Training Accuracy: 76.4290%, Training Loss: 0.5537%\n",
      "Epoch [38/300], Step [118/225], Training Accuracy: 76.4301%, Training Loss: 0.5534%\n",
      "Epoch [38/300], Step [119/225], Training Accuracy: 76.2999%, Training Loss: 0.5552%\n",
      "Epoch [38/300], Step [120/225], Training Accuracy: 76.2630%, Training Loss: 0.5559%\n",
      "Epoch [38/300], Step [121/225], Training Accuracy: 76.1622%, Training Loss: 0.5584%\n",
      "Epoch [38/300], Step [122/225], Training Accuracy: 76.1655%, Training Loss: 0.5583%\n",
      "Epoch [38/300], Step [123/225], Training Accuracy: 76.1433%, Training Loss: 0.5585%\n",
      "Epoch [38/300], Step [124/225], Training Accuracy: 76.1719%, Training Loss: 0.5586%\n",
      "Epoch [38/300], Step [125/225], Training Accuracy: 76.1250%, Training Loss: 0.5587%\n",
      "Epoch [38/300], Step [126/225], Training Accuracy: 76.0665%, Training Loss: 0.5593%\n",
      "Epoch [38/300], Step [127/225], Training Accuracy: 76.0581%, Training Loss: 0.5595%\n",
      "Epoch [38/300], Step [128/225], Training Accuracy: 76.0620%, Training Loss: 0.5599%\n",
      "Epoch [38/300], Step [129/225], Training Accuracy: 76.0780%, Training Loss: 0.5598%\n",
      "Epoch [38/300], Step [130/225], Training Accuracy: 76.0697%, Training Loss: 0.5599%\n",
      "Epoch [38/300], Step [131/225], Training Accuracy: 76.0615%, Training Loss: 0.5604%\n",
      "Epoch [38/300], Step [132/225], Training Accuracy: 75.9588%, Training Loss: 0.5614%\n",
      "Epoch [38/300], Step [133/225], Training Accuracy: 75.9751%, Training Loss: 0.5607%\n",
      "Epoch [38/300], Step [134/225], Training Accuracy: 75.8862%, Training Loss: 0.5618%\n",
      "Epoch [38/300], Step [135/225], Training Accuracy: 75.8796%, Training Loss: 0.5617%\n",
      "Epoch [38/300], Step [136/225], Training Accuracy: 75.8732%, Training Loss: 0.5618%\n",
      "Epoch [38/300], Step [137/225], Training Accuracy: 75.8896%, Training Loss: 0.5620%\n",
      "Epoch [38/300], Step [138/225], Training Accuracy: 75.9511%, Training Loss: 0.5605%\n",
      "Epoch [38/300], Step [139/225], Training Accuracy: 75.9555%, Training Loss: 0.5605%\n",
      "Epoch [38/300], Step [140/225], Training Accuracy: 75.9710%, Training Loss: 0.5603%\n",
      "Epoch [38/300], Step [141/225], Training Accuracy: 75.9752%, Training Loss: 0.5597%\n",
      "Epoch [38/300], Step [142/225], Training Accuracy: 75.9683%, Training Loss: 0.5594%\n",
      "Epoch [38/300], Step [143/225], Training Accuracy: 75.9397%, Training Loss: 0.5604%\n",
      "Epoch [38/300], Step [144/225], Training Accuracy: 75.9440%, Training Loss: 0.5606%\n",
      "Epoch [38/300], Step [145/225], Training Accuracy: 76.0022%, Training Loss: 0.5598%\n",
      "Epoch [38/300], Step [146/225], Training Accuracy: 76.0060%, Training Loss: 0.5598%\n",
      "Epoch [38/300], Step [147/225], Training Accuracy: 75.9991%, Training Loss: 0.5598%\n",
      "Epoch [38/300], Step [148/225], Training Accuracy: 76.0557%, Training Loss: 0.5594%\n",
      "Epoch [38/300], Step [149/225], Training Accuracy: 76.0801%, Training Loss: 0.5588%\n",
      "Epoch [38/300], Step [150/225], Training Accuracy: 76.1042%, Training Loss: 0.5578%\n",
      "Epoch [38/300], Step [151/225], Training Accuracy: 76.1382%, Training Loss: 0.5572%\n",
      "Epoch [38/300], Step [152/225], Training Accuracy: 76.2027%, Training Loss: 0.5565%\n",
      "Epoch [38/300], Step [153/225], Training Accuracy: 76.2051%, Training Loss: 0.5562%\n",
      "Epoch [38/300], Step [154/225], Training Accuracy: 76.1871%, Training Loss: 0.5563%\n",
      "Epoch [38/300], Step [155/225], Training Accuracy: 76.2298%, Training Loss: 0.5554%\n",
      "Epoch [38/300], Step [156/225], Training Accuracy: 76.2220%, Training Loss: 0.5565%\n",
      "Epoch [38/300], Step [157/225], Training Accuracy: 76.2440%, Training Loss: 0.5559%\n",
      "Epoch [38/300], Step [158/225], Training Accuracy: 76.2164%, Training Loss: 0.5570%\n",
      "Epoch [38/300], Step [159/225], Training Accuracy: 76.1989%, Training Loss: 0.5573%\n",
      "Epoch [38/300], Step [160/225], Training Accuracy: 76.2402%, Training Loss: 0.5568%\n",
      "Epoch [38/300], Step [161/225], Training Accuracy: 76.2131%, Training Loss: 0.5580%\n",
      "Epoch [38/300], Step [162/225], Training Accuracy: 76.1863%, Training Loss: 0.5582%\n",
      "Epoch [38/300], Step [163/225], Training Accuracy: 76.1982%, Training Loss: 0.5575%\n",
      "Epoch [38/300], Step [164/225], Training Accuracy: 76.2386%, Training Loss: 0.5565%\n",
      "Epoch [38/300], Step [165/225], Training Accuracy: 76.2500%, Training Loss: 0.5563%\n",
      "Epoch [38/300], Step [166/225], Training Accuracy: 76.2048%, Training Loss: 0.5563%\n",
      "Epoch [38/300], Step [167/225], Training Accuracy: 76.2350%, Training Loss: 0.5560%\n",
      "Epoch [38/300], Step [168/225], Training Accuracy: 76.2184%, Training Loss: 0.5561%\n",
      "Epoch [38/300], Step [169/225], Training Accuracy: 76.2759%, Training Loss: 0.5555%\n",
      "Epoch [38/300], Step [170/225], Training Accuracy: 76.2592%, Training Loss: 0.5557%\n",
      "Epoch [38/300], Step [171/225], Training Accuracy: 76.2336%, Training Loss: 0.5564%\n",
      "Epoch [38/300], Step [172/225], Training Accuracy: 76.1900%, Training Loss: 0.5577%\n",
      "Epoch [38/300], Step [173/225], Training Accuracy: 76.1922%, Training Loss: 0.5578%\n",
      "Epoch [38/300], Step [174/225], Training Accuracy: 76.1764%, Training Loss: 0.5587%\n",
      "Epoch [38/300], Step [175/225], Training Accuracy: 76.1607%, Training Loss: 0.5583%\n",
      "Epoch [38/300], Step [176/225], Training Accuracy: 76.1009%, Training Loss: 0.5591%\n",
      "Epoch [38/300], Step [177/225], Training Accuracy: 76.1123%, Training Loss: 0.5591%\n",
      "Epoch [38/300], Step [178/225], Training Accuracy: 76.0534%, Training Loss: 0.5604%\n",
      "Epoch [38/300], Step [179/225], Training Accuracy: 76.1173%, Training Loss: 0.5593%\n",
      "Epoch [38/300], Step [180/225], Training Accuracy: 76.1372%, Training Loss: 0.5593%\n",
      "Epoch [38/300], Step [181/225], Training Accuracy: 76.1913%, Training Loss: 0.5591%\n",
      "Epoch [38/300], Step [182/225], Training Accuracy: 76.1762%, Training Loss: 0.5593%\n",
      "Epoch [38/300], Step [183/225], Training Accuracy: 76.1783%, Training Loss: 0.5602%\n",
      "Epoch [38/300], Step [184/225], Training Accuracy: 76.1889%, Training Loss: 0.5599%\n",
      "Epoch [38/300], Step [185/225], Training Accuracy: 76.1993%, Training Loss: 0.5601%\n",
      "Epoch [38/300], Step [186/225], Training Accuracy: 76.2265%, Training Loss: 0.5594%\n",
      "Epoch [38/300], Step [187/225], Training Accuracy: 76.2032%, Training Loss: 0.5597%\n",
      "Epoch [38/300], Step [188/225], Training Accuracy: 76.2051%, Training Loss: 0.5596%\n",
      "Epoch [38/300], Step [189/225], Training Accuracy: 76.2235%, Training Loss: 0.5588%\n",
      "Epoch [38/300], Step [190/225], Training Accuracy: 76.2664%, Training Loss: 0.5580%\n",
      "Epoch [38/300], Step [191/225], Training Accuracy: 76.2762%, Training Loss: 0.5583%\n",
      "Epoch [38/300], Step [192/225], Training Accuracy: 76.3102%, Training Loss: 0.5575%\n",
      "Epoch [38/300], Step [193/225], Training Accuracy: 76.3196%, Training Loss: 0.5577%\n",
      "Epoch [38/300], Step [194/225], Training Accuracy: 76.3209%, Training Loss: 0.5575%\n",
      "Epoch [38/300], Step [195/225], Training Accuracy: 76.3862%, Training Loss: 0.5565%\n",
      "Epoch [38/300], Step [196/225], Training Accuracy: 76.3712%, Training Loss: 0.5565%\n",
      "Epoch [38/300], Step [197/225], Training Accuracy: 76.3563%, Training Loss: 0.5565%\n",
      "Epoch [38/300], Step [198/225], Training Accuracy: 76.3810%, Training Loss: 0.5560%\n",
      "Epoch [38/300], Step [199/225], Training Accuracy: 76.3741%, Training Loss: 0.5559%\n",
      "Epoch [38/300], Step [200/225], Training Accuracy: 76.4062%, Training Loss: 0.5557%\n",
      "Epoch [38/300], Step [201/225], Training Accuracy: 76.4070%, Training Loss: 0.5557%\n",
      "Epoch [38/300], Step [202/225], Training Accuracy: 76.3769%, Training Loss: 0.5561%\n",
      "Epoch [38/300], Step [203/225], Training Accuracy: 76.4240%, Training Loss: 0.5553%\n",
      "Epoch [38/300], Step [204/225], Training Accuracy: 76.3940%, Training Loss: 0.5551%\n",
      "Epoch [38/300], Step [205/225], Training Accuracy: 76.3796%, Training Loss: 0.5553%\n",
      "Epoch [38/300], Step [206/225], Training Accuracy: 76.4260%, Training Loss: 0.5550%\n",
      "Epoch [38/300], Step [207/225], Training Accuracy: 76.4342%, Training Loss: 0.5551%\n",
      "Epoch [38/300], Step [208/225], Training Accuracy: 76.4423%, Training Loss: 0.5547%\n",
      "Epoch [38/300], Step [209/225], Training Accuracy: 76.4279%, Training Loss: 0.5554%\n",
      "Epoch [38/300], Step [210/225], Training Accuracy: 76.4062%, Training Loss: 0.5565%\n",
      "Epoch [38/300], Step [211/225], Training Accuracy: 76.3626%, Training Loss: 0.5567%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/300], Step [212/225], Training Accuracy: 76.3414%, Training Loss: 0.5573%\n",
      "Epoch [38/300], Step [213/225], Training Accuracy: 76.3058%, Training Loss: 0.5581%\n",
      "Epoch [38/300], Step [214/225], Training Accuracy: 76.3070%, Training Loss: 0.5580%\n",
      "Epoch [38/300], Step [215/225], Training Accuracy: 76.2645%, Training Loss: 0.5585%\n",
      "Epoch [38/300], Step [216/225], Training Accuracy: 76.2731%, Training Loss: 0.5586%\n",
      "Epoch [38/300], Step [217/225], Training Accuracy: 76.3105%, Training Loss: 0.5580%\n",
      "Epoch [38/300], Step [218/225], Training Accuracy: 76.3045%, Training Loss: 0.5584%\n",
      "Epoch [38/300], Step [219/225], Training Accuracy: 76.3128%, Training Loss: 0.5583%\n",
      "Epoch [38/300], Step [220/225], Training Accuracy: 76.3352%, Training Loss: 0.5580%\n",
      "Epoch [38/300], Step [221/225], Training Accuracy: 76.3575%, Training Loss: 0.5576%\n",
      "Epoch [38/300], Step [222/225], Training Accuracy: 76.3795%, Training Loss: 0.5572%\n",
      "Epoch [38/300], Step [223/225], Training Accuracy: 76.3593%, Training Loss: 0.5577%\n",
      "Epoch [38/300], Step [224/225], Training Accuracy: 76.3742%, Training Loss: 0.5574%\n",
      "Epoch [38/300], Step [225/225], Training Accuracy: 76.3549%, Training Loss: 0.5578%\n",
      "Epoch [39/300], Step [1/225], Training Accuracy: 85.9375%, Training Loss: 0.4520%\n",
      "Epoch [39/300], Step [2/225], Training Accuracy: 82.0312%, Training Loss: 0.5024%\n",
      "Epoch [39/300], Step [3/225], Training Accuracy: 81.2500%, Training Loss: 0.5216%\n",
      "Epoch [39/300], Step [4/225], Training Accuracy: 78.1250%, Training Loss: 0.5653%\n",
      "Epoch [39/300], Step [5/225], Training Accuracy: 79.3750%, Training Loss: 0.5314%\n",
      "Epoch [39/300], Step [6/225], Training Accuracy: 78.3854%, Training Loss: 0.5285%\n",
      "Epoch [39/300], Step [7/225], Training Accuracy: 78.1250%, Training Loss: 0.5322%\n",
      "Epoch [39/300], Step [8/225], Training Accuracy: 78.9062%, Training Loss: 0.5431%\n",
      "Epoch [39/300], Step [9/225], Training Accuracy: 78.4722%, Training Loss: 0.5412%\n",
      "Epoch [39/300], Step [10/225], Training Accuracy: 78.2812%, Training Loss: 0.5523%\n",
      "Epoch [39/300], Step [11/225], Training Accuracy: 78.5511%, Training Loss: 0.5499%\n",
      "Epoch [39/300], Step [12/225], Training Accuracy: 79.1667%, Training Loss: 0.5368%\n",
      "Epoch [39/300], Step [13/225], Training Accuracy: 79.8077%, Training Loss: 0.5220%\n",
      "Epoch [39/300], Step [14/225], Training Accuracy: 79.6875%, Training Loss: 0.5171%\n",
      "Epoch [39/300], Step [15/225], Training Accuracy: 79.4792%, Training Loss: 0.5190%\n",
      "Epoch [39/300], Step [16/225], Training Accuracy: 79.1992%, Training Loss: 0.5270%\n",
      "Epoch [39/300], Step [17/225], Training Accuracy: 79.3199%, Training Loss: 0.5205%\n",
      "Epoch [39/300], Step [18/225], Training Accuracy: 79.3403%, Training Loss: 0.5152%\n",
      "Epoch [39/300], Step [19/225], Training Accuracy: 79.1941%, Training Loss: 0.5182%\n",
      "Epoch [39/300], Step [20/225], Training Accuracy: 79.4531%, Training Loss: 0.5116%\n",
      "Epoch [39/300], Step [21/225], Training Accuracy: 79.5387%, Training Loss: 0.5052%\n",
      "Epoch [39/300], Step [22/225], Training Accuracy: 79.1903%, Training Loss: 0.5117%\n",
      "Epoch [39/300], Step [23/225], Training Accuracy: 79.0761%, Training Loss: 0.5139%\n",
      "Epoch [39/300], Step [24/225], Training Accuracy: 78.7760%, Training Loss: 0.5179%\n",
      "Epoch [39/300], Step [25/225], Training Accuracy: 78.9375%, Training Loss: 0.5144%\n",
      "Epoch [39/300], Step [26/225], Training Accuracy: 78.9062%, Training Loss: 0.5150%\n",
      "Epoch [39/300], Step [27/225], Training Accuracy: 78.8773%, Training Loss: 0.5164%\n",
      "Epoch [39/300], Step [28/225], Training Accuracy: 79.0179%, Training Loss: 0.5114%\n",
      "Epoch [39/300], Step [29/225], Training Accuracy: 78.8793%, Training Loss: 0.5114%\n",
      "Epoch [39/300], Step [30/225], Training Accuracy: 78.6979%, Training Loss: 0.5160%\n",
      "Epoch [39/300], Step [31/225], Training Accuracy: 78.4778%, Training Loss: 0.5190%\n",
      "Epoch [39/300], Step [32/225], Training Accuracy: 78.7598%, Training Loss: 0.5131%\n",
      "Epoch [39/300], Step [33/225], Training Accuracy: 78.6458%, Training Loss: 0.5125%\n",
      "Epoch [39/300], Step [34/225], Training Accuracy: 78.3088%, Training Loss: 0.5214%\n",
      "Epoch [39/300], Step [35/225], Training Accuracy: 78.0357%, Training Loss: 0.5279%\n",
      "Epoch [39/300], Step [36/225], Training Accuracy: 78.0816%, Training Loss: 0.5277%\n",
      "Epoch [39/300], Step [37/225], Training Accuracy: 77.9561%, Training Loss: 0.5280%\n",
      "Epoch [39/300], Step [38/225], Training Accuracy: 77.8372%, Training Loss: 0.5279%\n",
      "Epoch [39/300], Step [39/225], Training Accuracy: 77.6843%, Training Loss: 0.5301%\n",
      "Epoch [39/300], Step [40/225], Training Accuracy: 77.6172%, Training Loss: 0.5333%\n",
      "Epoch [39/300], Step [41/225], Training Accuracy: 77.4771%, Training Loss: 0.5363%\n",
      "Epoch [39/300], Step [42/225], Training Accuracy: 77.3810%, Training Loss: 0.5392%\n",
      "Epoch [39/300], Step [43/225], Training Accuracy: 77.2166%, Training Loss: 0.5391%\n",
      "Epoch [39/300], Step [44/225], Training Accuracy: 77.2727%, Training Loss: 0.5379%\n",
      "Epoch [39/300], Step [45/225], Training Accuracy: 77.1875%, Training Loss: 0.5386%\n",
      "Epoch [39/300], Step [46/225], Training Accuracy: 77.1739%, Training Loss: 0.5395%\n",
      "Epoch [39/300], Step [47/225], Training Accuracy: 77.1609%, Training Loss: 0.5386%\n",
      "Epoch [39/300], Step [48/225], Training Accuracy: 77.0508%, Training Loss: 0.5412%\n",
      "Epoch [39/300], Step [49/225], Training Accuracy: 76.9133%, Training Loss: 0.5460%\n",
      "Epoch [39/300], Step [50/225], Training Accuracy: 76.8750%, Training Loss: 0.5460%\n",
      "Epoch [39/300], Step [51/225], Training Accuracy: 77.0527%, Training Loss: 0.5432%\n",
      "Epoch [39/300], Step [52/225], Training Accuracy: 77.1635%, Training Loss: 0.5411%\n",
      "Epoch [39/300], Step [53/225], Training Accuracy: 77.3585%, Training Loss: 0.5398%\n",
      "Epoch [39/300], Step [54/225], Training Accuracy: 77.1991%, Training Loss: 0.5435%\n",
      "Epoch [39/300], Step [55/225], Training Accuracy: 76.9886%, Training Loss: 0.5476%\n",
      "Epoch [39/300], Step [56/225], Training Accuracy: 76.9531%, Training Loss: 0.5488%\n",
      "Epoch [39/300], Step [57/225], Training Accuracy: 76.8366%, Training Loss: 0.5502%\n",
      "Epoch [39/300], Step [58/225], Training Accuracy: 76.8858%, Training Loss: 0.5486%\n",
      "Epoch [39/300], Step [59/225], Training Accuracy: 76.6419%, Training Loss: 0.5524%\n",
      "Epoch [39/300], Step [60/225], Training Accuracy: 76.6667%, Training Loss: 0.5512%\n",
      "Epoch [39/300], Step [61/225], Training Accuracy: 76.6650%, Training Loss: 0.5504%\n",
      "Epoch [39/300], Step [62/225], Training Accuracy: 76.7137%, Training Loss: 0.5507%\n",
      "Epoch [39/300], Step [63/225], Training Accuracy: 76.6865%, Training Loss: 0.5512%\n",
      "Epoch [39/300], Step [64/225], Training Accuracy: 76.6357%, Training Loss: 0.5512%\n",
      "Epoch [39/300], Step [65/225], Training Accuracy: 76.6587%, Training Loss: 0.5495%\n",
      "Epoch [39/300], Step [66/225], Training Accuracy: 76.7045%, Training Loss: 0.5485%\n",
      "Epoch [39/300], Step [67/225], Training Accuracy: 76.5625%, Training Loss: 0.5489%\n",
      "Epoch [39/300], Step [68/225], Training Accuracy: 76.5625%, Training Loss: 0.5482%\n",
      "Epoch [39/300], Step [69/225], Training Accuracy: 76.5625%, Training Loss: 0.5481%\n",
      "Epoch [39/300], Step [70/225], Training Accuracy: 76.5179%, Training Loss: 0.5494%\n",
      "Epoch [39/300], Step [71/225], Training Accuracy: 76.5625%, Training Loss: 0.5489%\n",
      "Epoch [39/300], Step [72/225], Training Accuracy: 76.5191%, Training Loss: 0.5481%\n",
      "Epoch [39/300], Step [73/225], Training Accuracy: 76.4769%, Training Loss: 0.5483%\n",
      "Epoch [39/300], Step [74/225], Training Accuracy: 76.5414%, Training Loss: 0.5458%\n",
      "Epoch [39/300], Step [75/225], Training Accuracy: 76.6042%, Training Loss: 0.5454%\n",
      "Epoch [39/300], Step [76/225], Training Accuracy: 76.5214%, Training Loss: 0.5464%\n",
      "Epoch [39/300], Step [77/225], Training Accuracy: 76.4205%, Training Loss: 0.5478%\n",
      "Epoch [39/300], Step [78/225], Training Accuracy: 76.4423%, Training Loss: 0.5465%\n",
      "Epoch [39/300], Step [79/225], Training Accuracy: 76.4834%, Training Loss: 0.5451%\n",
      "Epoch [39/300], Step [80/225], Training Accuracy: 76.4844%, Training Loss: 0.5450%\n",
      "Epoch [39/300], Step [81/225], Training Accuracy: 76.5046%, Training Loss: 0.5449%\n",
      "Epoch [39/300], Step [82/225], Training Accuracy: 76.6197%, Training Loss: 0.5429%\n",
      "Epoch [39/300], Step [83/225], Training Accuracy: 76.6943%, Training Loss: 0.5437%\n",
      "Epoch [39/300], Step [84/225], Training Accuracy: 76.8229%, Training Loss: 0.5416%\n",
      "Epoch [39/300], Step [85/225], Training Accuracy: 76.8750%, Training Loss: 0.5408%\n",
      "Epoch [39/300], Step [86/225], Training Accuracy: 76.8895%, Training Loss: 0.5398%\n",
      "Epoch [39/300], Step [87/225], Training Accuracy: 76.8139%, Training Loss: 0.5399%\n",
      "Epoch [39/300], Step [88/225], Training Accuracy: 76.7933%, Training Loss: 0.5408%\n",
      "Epoch [39/300], Step [89/225], Training Accuracy: 76.7907%, Training Loss: 0.5413%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/300], Step [90/225], Training Accuracy: 76.7361%, Training Loss: 0.5426%\n",
      "Epoch [39/300], Step [91/225], Training Accuracy: 76.7170%, Training Loss: 0.5428%\n",
      "Epoch [39/300], Step [92/225], Training Accuracy: 76.6304%, Training Loss: 0.5441%\n",
      "Epoch [39/300], Step [93/225], Training Accuracy: 76.6633%, Training Loss: 0.5431%\n",
      "Epoch [39/300], Step [94/225], Training Accuracy: 76.7453%, Training Loss: 0.5423%\n",
      "Epoch [39/300], Step [95/225], Training Accuracy: 76.7434%, Training Loss: 0.5416%\n",
      "Epoch [39/300], Step [96/225], Training Accuracy: 76.8392%, Training Loss: 0.5396%\n",
      "Epoch [39/300], Step [97/225], Training Accuracy: 76.8524%, Training Loss: 0.5393%\n",
      "Epoch [39/300], Step [98/225], Training Accuracy: 76.8654%, Training Loss: 0.5385%\n",
      "Epoch [39/300], Step [99/225], Training Accuracy: 76.8782%, Training Loss: 0.5386%\n",
      "Epoch [39/300], Step [100/225], Training Accuracy: 76.8906%, Training Loss: 0.5385%\n",
      "Epoch [39/300], Step [101/225], Training Accuracy: 76.9493%, Training Loss: 0.5372%\n",
      "Epoch [39/300], Step [102/225], Training Accuracy: 76.9148%, Training Loss: 0.5375%\n",
      "Epoch [39/300], Step [103/225], Training Accuracy: 76.9266%, Training Loss: 0.5374%\n",
      "Epoch [39/300], Step [104/225], Training Accuracy: 76.8930%, Training Loss: 0.5394%\n",
      "Epoch [39/300], Step [105/225], Training Accuracy: 76.9643%, Training Loss: 0.5378%\n",
      "Epoch [39/300], Step [106/225], Training Accuracy: 76.8868%, Training Loss: 0.5395%\n",
      "Epoch [39/300], Step [107/225], Training Accuracy: 76.9130%, Training Loss: 0.5398%\n",
      "Epoch [39/300], Step [108/225], Training Accuracy: 76.9387%, Training Loss: 0.5399%\n",
      "Epoch [39/300], Step [109/225], Training Accuracy: 76.9639%, Training Loss: 0.5393%\n",
      "Epoch [39/300], Step [110/225], Training Accuracy: 76.9602%, Training Loss: 0.5389%\n",
      "Epoch [39/300], Step [111/225], Training Accuracy: 76.8863%, Training Loss: 0.5406%\n",
      "Epoch [39/300], Step [112/225], Training Accuracy: 76.8973%, Training Loss: 0.5404%\n",
      "Epoch [39/300], Step [113/225], Training Accuracy: 76.8390%, Training Loss: 0.5409%\n",
      "Epoch [39/300], Step [114/225], Training Accuracy: 76.7818%, Training Loss: 0.5407%\n",
      "Epoch [39/300], Step [115/225], Training Accuracy: 76.8478%, Training Loss: 0.5396%\n",
      "Epoch [39/300], Step [116/225], Training Accuracy: 76.8992%, Training Loss: 0.5389%\n",
      "Epoch [39/300], Step [117/225], Training Accuracy: 76.8296%, Training Loss: 0.5395%\n",
      "Epoch [39/300], Step [118/225], Training Accuracy: 76.8273%, Training Loss: 0.5400%\n",
      "Epoch [39/300], Step [119/225], Training Accuracy: 76.8382%, Training Loss: 0.5395%\n",
      "Epoch [39/300], Step [120/225], Training Accuracy: 76.8099%, Training Loss: 0.5402%\n",
      "Epoch [39/300], Step [121/225], Training Accuracy: 76.7691%, Training Loss: 0.5408%\n",
      "Epoch [39/300], Step [122/225], Training Accuracy: 76.7674%, Training Loss: 0.5412%\n",
      "Epoch [39/300], Step [123/225], Training Accuracy: 76.7912%, Training Loss: 0.5401%\n",
      "Epoch [39/300], Step [124/225], Training Accuracy: 76.8145%, Training Loss: 0.5401%\n",
      "Epoch [39/300], Step [125/225], Training Accuracy: 76.8625%, Training Loss: 0.5397%\n",
      "Epoch [39/300], Step [126/225], Training Accuracy: 76.9345%, Training Loss: 0.5395%\n",
      "Epoch [39/300], Step [127/225], Training Accuracy: 76.9439%, Training Loss: 0.5391%\n",
      "Epoch [39/300], Step [128/225], Training Accuracy: 76.9287%, Training Loss: 0.5396%\n",
      "Epoch [39/300], Step [129/225], Training Accuracy: 77.0228%, Training Loss: 0.5384%\n",
      "Epoch [39/300], Step [130/225], Training Accuracy: 77.0553%, Training Loss: 0.5376%\n",
      "Epoch [39/300], Step [131/225], Training Accuracy: 77.0635%, Training Loss: 0.5375%\n",
      "Epoch [39/300], Step [132/225], Training Accuracy: 77.0597%, Training Loss: 0.5388%\n",
      "Epoch [39/300], Step [133/225], Training Accuracy: 77.0677%, Training Loss: 0.5391%\n",
      "Epoch [39/300], Step [134/225], Training Accuracy: 77.0522%, Training Loss: 0.5403%\n",
      "Epoch [39/300], Step [135/225], Training Accuracy: 77.0602%, Training Loss: 0.5400%\n",
      "Epoch [39/300], Step [136/225], Training Accuracy: 77.1140%, Training Loss: 0.5391%\n",
      "Epoch [39/300], Step [137/225], Training Accuracy: 77.1099%, Training Loss: 0.5384%\n",
      "Epoch [39/300], Step [138/225], Training Accuracy: 77.1513%, Training Loss: 0.5373%\n",
      "Epoch [39/300], Step [139/225], Training Accuracy: 77.2032%, Training Loss: 0.5369%\n",
      "Epoch [39/300], Step [140/225], Training Accuracy: 77.1540%, Training Loss: 0.5374%\n",
      "Epoch [39/300], Step [141/225], Training Accuracy: 77.1498%, Training Loss: 0.5373%\n",
      "Epoch [39/300], Step [142/225], Training Accuracy: 77.1567%, Training Loss: 0.5368%\n",
      "Epoch [39/300], Step [143/225], Training Accuracy: 77.1416%, Training Loss: 0.5379%\n",
      "Epoch [39/300], Step [144/225], Training Accuracy: 77.1050%, Training Loss: 0.5386%\n",
      "Epoch [39/300], Step [145/225], Training Accuracy: 77.0366%, Training Loss: 0.5396%\n",
      "Epoch [39/300], Step [146/225], Training Accuracy: 77.0441%, Training Loss: 0.5396%\n",
      "Epoch [39/300], Step [147/225], Training Accuracy: 77.0833%, Training Loss: 0.5387%\n",
      "Epoch [39/300], Step [148/225], Training Accuracy: 77.1643%, Training Loss: 0.5370%\n",
      "Epoch [39/300], Step [149/225], Training Accuracy: 77.1707%, Training Loss: 0.5365%\n",
      "Epoch [39/300], Step [150/225], Training Accuracy: 77.1771%, Training Loss: 0.5368%\n",
      "Epoch [39/300], Step [151/225], Training Accuracy: 77.1523%, Training Loss: 0.5369%\n",
      "Epoch [39/300], Step [152/225], Training Accuracy: 77.1690%, Training Loss: 0.5366%\n",
      "Epoch [39/300], Step [153/225], Training Accuracy: 77.1344%, Training Loss: 0.5369%\n",
      "Epoch [39/300], Step [154/225], Training Accuracy: 77.1408%, Training Loss: 0.5364%\n",
      "Epoch [39/300], Step [155/225], Training Accuracy: 77.1169%, Training Loss: 0.5370%\n",
      "Epoch [39/300], Step [156/225], Training Accuracy: 77.1034%, Training Loss: 0.5374%\n",
      "Epoch [39/300], Step [157/225], Training Accuracy: 77.1198%, Training Loss: 0.5374%\n",
      "Epoch [39/300], Step [158/225], Training Accuracy: 77.0570%, Training Loss: 0.5389%\n",
      "Epoch [39/300], Step [159/225], Training Accuracy: 77.0047%, Training Loss: 0.5395%\n",
      "Epoch [39/300], Step [160/225], Training Accuracy: 77.0215%, Training Loss: 0.5391%\n",
      "Epoch [39/300], Step [161/225], Training Accuracy: 77.0089%, Training Loss: 0.5394%\n",
      "Epoch [39/300], Step [162/225], Training Accuracy: 77.0737%, Training Loss: 0.5386%\n",
      "Epoch [39/300], Step [163/225], Training Accuracy: 77.0897%, Training Loss: 0.5383%\n",
      "Epoch [39/300], Step [164/225], Training Accuracy: 77.1056%, Training Loss: 0.5381%\n",
      "Epoch [39/300], Step [165/225], Training Accuracy: 77.0833%, Training Loss: 0.5384%\n",
      "Epoch [39/300], Step [166/225], Training Accuracy: 77.0802%, Training Loss: 0.5383%\n",
      "Epoch [39/300], Step [167/225], Training Accuracy: 77.0397%, Training Loss: 0.5386%\n",
      "Epoch [39/300], Step [168/225], Training Accuracy: 77.0368%, Training Loss: 0.5383%\n",
      "Epoch [39/300], Step [169/225], Training Accuracy: 77.0710%, Training Loss: 0.5379%\n",
      "Epoch [39/300], Step [170/225], Training Accuracy: 77.0404%, Training Loss: 0.5400%\n",
      "Epoch [39/300], Step [171/225], Training Accuracy: 77.0194%, Training Loss: 0.5403%\n",
      "Epoch [39/300], Step [172/225], Training Accuracy: 76.9985%, Training Loss: 0.5405%\n",
      "Epoch [39/300], Step [173/225], Training Accuracy: 76.9689%, Training Loss: 0.5408%\n",
      "Epoch [39/300], Step [174/225], Training Accuracy: 77.0295%, Training Loss: 0.5402%\n",
      "Epoch [39/300], Step [175/225], Training Accuracy: 77.0268%, Training Loss: 0.5405%\n",
      "Epoch [39/300], Step [176/225], Training Accuracy: 77.0508%, Training Loss: 0.5398%\n",
      "Epoch [39/300], Step [177/225], Training Accuracy: 77.0039%, Training Loss: 0.5401%\n",
      "Epoch [39/300], Step [178/225], Training Accuracy: 76.9751%, Training Loss: 0.5410%\n",
      "Epoch [39/300], Step [179/225], Training Accuracy: 76.9990%, Training Loss: 0.5406%\n",
      "Epoch [39/300], Step [180/225], Training Accuracy: 77.0052%, Training Loss: 0.5398%\n",
      "Epoch [39/300], Step [181/225], Training Accuracy: 77.0028%, Training Loss: 0.5398%\n",
      "Epoch [39/300], Step [182/225], Training Accuracy: 77.0175%, Training Loss: 0.5399%\n",
      "Epoch [39/300], Step [183/225], Training Accuracy: 77.0321%, Training Loss: 0.5400%\n",
      "Epoch [39/300], Step [184/225], Training Accuracy: 77.0720%, Training Loss: 0.5404%\n",
      "Epoch [39/300], Step [185/225], Training Accuracy: 77.0693%, Training Loss: 0.5406%\n",
      "Epoch [39/300], Step [186/225], Training Accuracy: 77.0917%, Training Loss: 0.5398%\n",
      "Epoch [39/300], Step [187/225], Training Accuracy: 77.0638%, Training Loss: 0.5400%\n",
      "Epoch [39/300], Step [188/225], Training Accuracy: 77.0529%, Training Loss: 0.5404%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/300], Step [189/225], Training Accuracy: 77.0751%, Training Loss: 0.5396%\n",
      "Epoch [39/300], Step [190/225], Training Accuracy: 77.1053%, Training Loss: 0.5394%\n",
      "Epoch [39/300], Step [191/225], Training Accuracy: 77.1106%, Training Loss: 0.5392%\n",
      "Epoch [39/300], Step [192/225], Training Accuracy: 77.1322%, Training Loss: 0.5386%\n",
      "Epoch [39/300], Step [193/225], Training Accuracy: 77.1697%, Training Loss: 0.5383%\n",
      "Epoch [39/300], Step [194/225], Training Accuracy: 77.1424%, Training Loss: 0.5384%\n",
      "Epoch [39/300], Step [195/225], Training Accuracy: 77.1715%, Training Loss: 0.5375%\n",
      "Epoch [39/300], Step [196/225], Training Accuracy: 77.1285%, Training Loss: 0.5377%\n",
      "Epoch [39/300], Step [197/225], Training Accuracy: 77.0860%, Training Loss: 0.5382%\n",
      "Epoch [39/300], Step [198/225], Training Accuracy: 77.0912%, Training Loss: 0.5379%\n",
      "Epoch [39/300], Step [199/225], Training Accuracy: 77.1278%, Training Loss: 0.5372%\n",
      "Epoch [39/300], Step [200/225], Training Accuracy: 77.1250%, Training Loss: 0.5372%\n",
      "Epoch [39/300], Step [201/225], Training Accuracy: 77.1144%, Training Loss: 0.5373%\n",
      "Epoch [39/300], Step [202/225], Training Accuracy: 77.0962%, Training Loss: 0.5375%\n",
      "Epoch [39/300], Step [203/225], Training Accuracy: 77.1321%, Training Loss: 0.5370%\n",
      "Epoch [39/300], Step [204/225], Training Accuracy: 77.1293%, Training Loss: 0.5375%\n",
      "Epoch [39/300], Step [205/225], Training Accuracy: 77.1113%, Training Loss: 0.5379%\n",
      "Epoch [39/300], Step [206/225], Training Accuracy: 77.1010%, Training Loss: 0.5374%\n",
      "Epoch [39/300], Step [207/225], Training Accuracy: 77.1437%, Training Loss: 0.5367%\n",
      "Epoch [39/300], Step [208/225], Training Accuracy: 77.1334%, Training Loss: 0.5368%\n",
      "Epoch [39/300], Step [209/225], Training Accuracy: 77.1307%, Training Loss: 0.5368%\n",
      "Epoch [39/300], Step [210/225], Training Accuracy: 77.1280%, Training Loss: 0.5369%\n",
      "Epoch [39/300], Step [211/225], Training Accuracy: 77.1179%, Training Loss: 0.5370%\n",
      "Epoch [39/300], Step [212/225], Training Accuracy: 77.1153%, Training Loss: 0.5376%\n",
      "Epoch [39/300], Step [213/225], Training Accuracy: 77.1127%, Training Loss: 0.5381%\n",
      "Epoch [39/300], Step [214/225], Training Accuracy: 77.1101%, Training Loss: 0.5383%\n",
      "Epoch [39/300], Step [215/225], Training Accuracy: 77.1003%, Training Loss: 0.5389%\n",
      "Epoch [39/300], Step [216/225], Training Accuracy: 77.0978%, Training Loss: 0.5390%\n",
      "Epoch [39/300], Step [217/225], Training Accuracy: 77.0809%, Training Loss: 0.5393%\n",
      "Epoch [39/300], Step [218/225], Training Accuracy: 77.0714%, Training Loss: 0.5396%\n",
      "Epoch [39/300], Step [219/225], Training Accuracy: 77.0833%, Training Loss: 0.5399%\n",
      "Epoch [39/300], Step [220/225], Training Accuracy: 77.1307%, Training Loss: 0.5391%\n",
      "Epoch [39/300], Step [221/225], Training Accuracy: 77.1423%, Training Loss: 0.5388%\n",
      "Epoch [39/300], Step [222/225], Training Accuracy: 77.1467%, Training Loss: 0.5388%\n",
      "Epoch [39/300], Step [223/225], Training Accuracy: 77.1441%, Training Loss: 0.5387%\n",
      "Epoch [39/300], Step [224/225], Training Accuracy: 77.1694%, Training Loss: 0.5384%\n",
      "Epoch [39/300], Step [225/225], Training Accuracy: 77.1748%, Training Loss: 0.5384%\n",
      "Epoch [40/300], Step [1/225], Training Accuracy: 78.1250%, Training Loss: 0.4701%\n",
      "Epoch [40/300], Step [2/225], Training Accuracy: 73.4375%, Training Loss: 0.5392%\n",
      "Epoch [40/300], Step [3/225], Training Accuracy: 73.4375%, Training Loss: 0.5814%\n",
      "Epoch [40/300], Step [4/225], Training Accuracy: 75.0000%, Training Loss: 0.5365%\n",
      "Epoch [40/300], Step [5/225], Training Accuracy: 76.2500%, Training Loss: 0.5384%\n",
      "Epoch [40/300], Step [6/225], Training Accuracy: 76.5625%, Training Loss: 0.5250%\n",
      "Epoch [40/300], Step [7/225], Training Accuracy: 75.6696%, Training Loss: 0.5247%\n",
      "Epoch [40/300], Step [8/225], Training Accuracy: 75.3906%, Training Loss: 0.5374%\n",
      "Epoch [40/300], Step [9/225], Training Accuracy: 76.5625%, Training Loss: 0.5242%\n",
      "Epoch [40/300], Step [10/225], Training Accuracy: 75.9375%, Training Loss: 0.5384%\n",
      "Epoch [40/300], Step [11/225], Training Accuracy: 75.2841%, Training Loss: 0.5516%\n",
      "Epoch [40/300], Step [12/225], Training Accuracy: 75.5208%, Training Loss: 0.5553%\n",
      "Epoch [40/300], Step [13/225], Training Accuracy: 76.3221%, Training Loss: 0.5458%\n",
      "Epoch [40/300], Step [14/225], Training Accuracy: 76.5625%, Training Loss: 0.5495%\n",
      "Epoch [40/300], Step [15/225], Training Accuracy: 76.7708%, Training Loss: 0.5421%\n",
      "Epoch [40/300], Step [16/225], Training Accuracy: 76.3672%, Training Loss: 0.5472%\n",
      "Epoch [40/300], Step [17/225], Training Accuracy: 76.6544%, Training Loss: 0.5421%\n",
      "Epoch [40/300], Step [18/225], Training Accuracy: 76.8229%, Training Loss: 0.5381%\n",
      "Epoch [40/300], Step [19/225], Training Accuracy: 77.0559%, Training Loss: 0.5324%\n",
      "Epoch [40/300], Step [20/225], Training Accuracy: 77.0312%, Training Loss: 0.5378%\n",
      "Epoch [40/300], Step [21/225], Training Accuracy: 77.2321%, Training Loss: 0.5326%\n",
      "Epoch [40/300], Step [22/225], Training Accuracy: 77.0597%, Training Loss: 0.5362%\n",
      "Epoch [40/300], Step [23/225], Training Accuracy: 77.0380%, Training Loss: 0.5338%\n",
      "Epoch [40/300], Step [24/225], Training Accuracy: 76.9531%, Training Loss: 0.5338%\n",
      "Epoch [40/300], Step [25/225], Training Accuracy: 77.3750%, Training Loss: 0.5284%\n",
      "Epoch [40/300], Step [26/225], Training Accuracy: 77.5240%, Training Loss: 0.5257%\n",
      "Epoch [40/300], Step [27/225], Training Accuracy: 77.3148%, Training Loss: 0.5294%\n",
      "Epoch [40/300], Step [28/225], Training Accuracy: 77.0647%, Training Loss: 0.5282%\n",
      "Epoch [40/300], Step [29/225], Training Accuracy: 77.2629%, Training Loss: 0.5261%\n",
      "Epoch [40/300], Step [30/225], Training Accuracy: 77.4479%, Training Loss: 0.5251%\n",
      "Epoch [40/300], Step [31/225], Training Accuracy: 77.3185%, Training Loss: 0.5310%\n",
      "Epoch [40/300], Step [32/225], Training Accuracy: 77.6367%, Training Loss: 0.5254%\n",
      "Epoch [40/300], Step [33/225], Training Accuracy: 77.6989%, Training Loss: 0.5239%\n",
      "Epoch [40/300], Step [34/225], Training Accuracy: 77.2518%, Training Loss: 0.5317%\n",
      "Epoch [40/300], Step [35/225], Training Accuracy: 77.0089%, Training Loss: 0.5357%\n",
      "Epoch [40/300], Step [36/225], Training Accuracy: 76.9531%, Training Loss: 0.5383%\n",
      "Epoch [40/300], Step [37/225], Training Accuracy: 77.0693%, Training Loss: 0.5334%\n",
      "Epoch [40/300], Step [38/225], Training Accuracy: 76.9737%, Training Loss: 0.5362%\n",
      "Epoch [40/300], Step [39/225], Training Accuracy: 76.9231%, Training Loss: 0.5384%\n",
      "Epoch [40/300], Step [40/225], Training Accuracy: 77.1875%, Training Loss: 0.5350%\n",
      "Epoch [40/300], Step [41/225], Training Accuracy: 76.9436%, Training Loss: 0.5398%\n",
      "Epoch [40/300], Step [42/225], Training Accuracy: 76.9717%, Training Loss: 0.5384%\n",
      "Epoch [40/300], Step [43/225], Training Accuracy: 77.1076%, Training Loss: 0.5361%\n",
      "Epoch [40/300], Step [44/225], Training Accuracy: 76.9886%, Training Loss: 0.5379%\n",
      "Epoch [40/300], Step [45/225], Training Accuracy: 76.9444%, Training Loss: 0.5407%\n",
      "Epoch [40/300], Step [46/225], Training Accuracy: 77.1060%, Training Loss: 0.5393%\n",
      "Epoch [40/300], Step [47/225], Training Accuracy: 76.9614%, Training Loss: 0.5414%\n",
      "Epoch [40/300], Step [48/225], Training Accuracy: 76.9857%, Training Loss: 0.5429%\n",
      "Epoch [40/300], Step [49/225], Training Accuracy: 77.2003%, Training Loss: 0.5397%\n",
      "Epoch [40/300], Step [50/225], Training Accuracy: 76.9688%, Training Loss: 0.5432%\n",
      "Epoch [40/300], Step [51/225], Training Accuracy: 76.9914%, Training Loss: 0.5426%\n",
      "Epoch [40/300], Step [52/225], Training Accuracy: 77.1635%, Training Loss: 0.5401%\n",
      "Epoch [40/300], Step [53/225], Training Accuracy: 77.0342%, Training Loss: 0.5396%\n",
      "Epoch [40/300], Step [54/225], Training Accuracy: 76.9387%, Training Loss: 0.5398%\n",
      "Epoch [40/300], Step [55/225], Training Accuracy: 76.8466%, Training Loss: 0.5430%\n",
      "Epoch [40/300], Step [56/225], Training Accuracy: 76.9252%, Training Loss: 0.5414%\n",
      "Epoch [40/300], Step [57/225], Training Accuracy: 76.8366%, Training Loss: 0.5431%\n",
      "Epoch [40/300], Step [58/225], Training Accuracy: 76.8858%, Training Loss: 0.5413%\n",
      "Epoch [40/300], Step [59/225], Training Accuracy: 76.7479%, Training Loss: 0.5438%\n",
      "Epoch [40/300], Step [60/225], Training Accuracy: 76.7969%, Training Loss: 0.5416%\n",
      "Epoch [40/300], Step [61/225], Training Accuracy: 76.8186%, Training Loss: 0.5413%\n",
      "Epoch [40/300], Step [62/225], Training Accuracy: 76.9657%, Training Loss: 0.5388%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/300], Step [63/225], Training Accuracy: 76.9593%, Training Loss: 0.5386%\n",
      "Epoch [40/300], Step [64/225], Training Accuracy: 76.9287%, Training Loss: 0.5392%\n",
      "Epoch [40/300], Step [65/225], Training Accuracy: 77.0192%, Training Loss: 0.5377%\n",
      "Epoch [40/300], Step [66/225], Training Accuracy: 77.0360%, Training Loss: 0.5394%\n",
      "Epoch [40/300], Step [67/225], Training Accuracy: 77.0289%, Training Loss: 0.5402%\n",
      "Epoch [40/300], Step [68/225], Training Accuracy: 76.9991%, Training Loss: 0.5404%\n",
      "Epoch [40/300], Step [69/225], Training Accuracy: 76.9701%, Training Loss: 0.5401%\n",
      "Epoch [40/300], Step [70/225], Training Accuracy: 77.0312%, Training Loss: 0.5391%\n",
      "Epoch [40/300], Step [71/225], Training Accuracy: 77.1127%, Training Loss: 0.5376%\n",
      "Epoch [40/300], Step [72/225], Training Accuracy: 77.1484%, Training Loss: 0.5367%\n",
      "Epoch [40/300], Step [73/225], Training Accuracy: 77.1404%, Training Loss: 0.5364%\n",
      "Epoch [40/300], Step [74/225], Training Accuracy: 77.1959%, Training Loss: 0.5346%\n",
      "Epoch [40/300], Step [75/225], Training Accuracy: 77.2708%, Training Loss: 0.5345%\n",
      "Epoch [40/300], Step [76/225], Training Accuracy: 77.1587%, Training Loss: 0.5366%\n",
      "Epoch [40/300], Step [77/225], Training Accuracy: 77.2321%, Training Loss: 0.5355%\n",
      "Epoch [40/300], Step [78/225], Training Accuracy: 77.3237%, Training Loss: 0.5342%\n",
      "Epoch [40/300], Step [79/225], Training Accuracy: 77.4525%, Training Loss: 0.5323%\n",
      "Epoch [40/300], Step [80/225], Training Accuracy: 77.4219%, Training Loss: 0.5316%\n",
      "Epoch [40/300], Step [81/225], Training Accuracy: 77.5077%, Training Loss: 0.5306%\n",
      "Epoch [40/300], Step [82/225], Training Accuracy: 77.4581%, Training Loss: 0.5304%\n",
      "Epoch [40/300], Step [83/225], Training Accuracy: 77.4096%, Training Loss: 0.5319%\n",
      "Epoch [40/300], Step [84/225], Training Accuracy: 77.5112%, Training Loss: 0.5300%\n",
      "Epoch [40/300], Step [85/225], Training Accuracy: 77.6287%, Training Loss: 0.5287%\n",
      "Epoch [40/300], Step [86/225], Training Accuracy: 77.6708%, Training Loss: 0.5275%\n",
      "Epoch [40/300], Step [87/225], Training Accuracy: 77.5682%, Training Loss: 0.5283%\n",
      "Epoch [40/300], Step [88/225], Training Accuracy: 77.5036%, Training Loss: 0.5283%\n",
      "Epoch [40/300], Step [89/225], Training Accuracy: 77.4403%, Training Loss: 0.5296%\n",
      "Epoch [40/300], Step [90/225], Training Accuracy: 77.4479%, Training Loss: 0.5295%\n",
      "Epoch [40/300], Step [91/225], Training Accuracy: 77.5069%, Training Loss: 0.5287%\n",
      "Epoch [40/300], Step [92/225], Training Accuracy: 77.4626%, Training Loss: 0.5295%\n",
      "Epoch [40/300], Step [93/225], Training Accuracy: 77.5370%, Training Loss: 0.5283%\n",
      "Epoch [40/300], Step [94/225], Training Accuracy: 77.5931%, Training Loss: 0.5270%\n",
      "Epoch [40/300], Step [95/225], Training Accuracy: 77.5987%, Training Loss: 0.5263%\n",
      "Epoch [40/300], Step [96/225], Training Accuracy: 77.6693%, Training Loss: 0.5243%\n",
      "Epoch [40/300], Step [97/225], Training Accuracy: 77.6740%, Training Loss: 0.5236%\n",
      "Epoch [40/300], Step [98/225], Training Accuracy: 77.6945%, Training Loss: 0.5241%\n",
      "Epoch [40/300], Step [99/225], Training Accuracy: 77.6989%, Training Loss: 0.5243%\n",
      "Epoch [40/300], Step [100/225], Training Accuracy: 77.6406%, Training Loss: 0.5252%\n",
      "Epoch [40/300], Step [101/225], Training Accuracy: 77.6454%, Training Loss: 0.5249%\n",
      "Epoch [40/300], Step [102/225], Training Accuracy: 77.6042%, Training Loss: 0.5248%\n",
      "Epoch [40/300], Step [103/225], Training Accuracy: 77.5941%, Training Loss: 0.5241%\n",
      "Epoch [40/300], Step [104/225], Training Accuracy: 77.5841%, Training Loss: 0.5241%\n",
      "Epoch [40/300], Step [105/225], Training Accuracy: 77.6786%, Training Loss: 0.5222%\n",
      "Epoch [40/300], Step [106/225], Training Accuracy: 77.6680%, Training Loss: 0.5221%\n",
      "Epoch [40/300], Step [107/225], Training Accuracy: 77.7015%, Training Loss: 0.5219%\n",
      "Epoch [40/300], Step [108/225], Training Accuracy: 77.6765%, Training Loss: 0.5218%\n",
      "Epoch [40/300], Step [109/225], Training Accuracy: 77.6806%, Training Loss: 0.5214%\n",
      "Epoch [40/300], Step [110/225], Training Accuracy: 77.6420%, Training Loss: 0.5219%\n",
      "Epoch [40/300], Step [111/225], Training Accuracy: 77.6745%, Training Loss: 0.5220%\n",
      "Epoch [40/300], Step [112/225], Training Accuracy: 77.6367%, Training Loss: 0.5223%\n",
      "Epoch [40/300], Step [113/225], Training Accuracy: 77.6410%, Training Loss: 0.5244%\n",
      "Epoch [40/300], Step [114/225], Training Accuracy: 77.6590%, Training Loss: 0.5238%\n",
      "Epoch [40/300], Step [115/225], Training Accuracy: 77.6766%, Training Loss: 0.5235%\n",
      "Epoch [40/300], Step [116/225], Training Accuracy: 77.7344%, Training Loss: 0.5229%\n",
      "Epoch [40/300], Step [117/225], Training Accuracy: 77.6175%, Training Loss: 0.5234%\n",
      "Epoch [40/300], Step [118/225], Training Accuracy: 77.5821%, Training Loss: 0.5237%\n",
      "Epoch [40/300], Step [119/225], Training Accuracy: 77.5473%, Training Loss: 0.5236%\n",
      "Epoch [40/300], Step [120/225], Training Accuracy: 77.5521%, Training Loss: 0.5231%\n",
      "Epoch [40/300], Step [121/225], Training Accuracy: 77.4535%, Training Loss: 0.5244%\n",
      "Epoch [40/300], Step [122/225], Training Accuracy: 77.4462%, Training Loss: 0.5241%\n",
      "Epoch [40/300], Step [123/225], Training Accuracy: 77.4136%, Training Loss: 0.5240%\n",
      "Epoch [40/300], Step [124/225], Training Accuracy: 77.5076%, Training Loss: 0.5229%\n",
      "Epoch [40/300], Step [125/225], Training Accuracy: 77.5375%, Training Loss: 0.5225%\n",
      "Epoch [40/300], Step [126/225], Training Accuracy: 77.5050%, Training Loss: 0.5228%\n",
      "Epoch [40/300], Step [127/225], Training Accuracy: 77.5344%, Training Loss: 0.5223%\n",
      "Epoch [40/300], Step [128/225], Training Accuracy: 77.5269%, Training Loss: 0.5225%\n",
      "Epoch [40/300], Step [129/225], Training Accuracy: 77.4952%, Training Loss: 0.5225%\n",
      "Epoch [40/300], Step [130/225], Training Accuracy: 77.4639%, Training Loss: 0.5226%\n",
      "Epoch [40/300], Step [131/225], Training Accuracy: 77.4451%, Training Loss: 0.5225%\n",
      "Epoch [40/300], Step [132/225], Training Accuracy: 77.4976%, Training Loss: 0.5217%\n",
      "Epoch [40/300], Step [133/225], Training Accuracy: 77.5258%, Training Loss: 0.5208%\n",
      "Epoch [40/300], Step [134/225], Training Accuracy: 77.4720%, Training Loss: 0.5218%\n",
      "Epoch [40/300], Step [135/225], Training Accuracy: 77.4537%, Training Loss: 0.5224%\n",
      "Epoch [40/300], Step [136/225], Training Accuracy: 77.4357%, Training Loss: 0.5229%\n",
      "Epoch [40/300], Step [137/225], Training Accuracy: 77.4863%, Training Loss: 0.5222%\n",
      "Epoch [40/300], Step [138/225], Training Accuracy: 77.5249%, Training Loss: 0.5213%\n",
      "Epoch [40/300], Step [139/225], Training Accuracy: 77.4955%, Training Loss: 0.5217%\n",
      "Epoch [40/300], Step [140/225], Training Accuracy: 77.5223%, Training Loss: 0.5211%\n",
      "Epoch [40/300], Step [141/225], Training Accuracy: 77.5155%, Training Loss: 0.5214%\n",
      "Epoch [40/300], Step [142/225], Training Accuracy: 77.5088%, Training Loss: 0.5208%\n",
      "Epoch [40/300], Step [143/225], Training Accuracy: 77.4476%, Training Loss: 0.5222%\n",
      "Epoch [40/300], Step [144/225], Training Accuracy: 77.4306%, Training Loss: 0.5223%\n",
      "Epoch [40/300], Step [145/225], Training Accuracy: 77.4030%, Training Loss: 0.5229%\n",
      "Epoch [40/300], Step [146/225], Training Accuracy: 77.3759%, Training Loss: 0.5236%\n",
      "Epoch [40/300], Step [147/225], Training Accuracy: 77.4022%, Training Loss: 0.5232%\n",
      "Epoch [40/300], Step [148/225], Training Accuracy: 77.3965%, Training Loss: 0.5226%\n",
      "Epoch [40/300], Step [149/225], Training Accuracy: 77.4014%, Training Loss: 0.5225%\n",
      "Epoch [40/300], Step [150/225], Training Accuracy: 77.4167%, Training Loss: 0.5217%\n",
      "Epoch [40/300], Step [151/225], Training Accuracy: 77.4317%, Training Loss: 0.5219%\n",
      "Epoch [40/300], Step [152/225], Training Accuracy: 77.4157%, Training Loss: 0.5224%\n",
      "Epoch [40/300], Step [153/225], Training Accuracy: 77.4203%, Training Loss: 0.5225%\n",
      "Epoch [40/300], Step [154/225], Training Accuracy: 77.4148%, Training Loss: 0.5225%\n",
      "Epoch [40/300], Step [155/225], Training Accuracy: 77.4698%, Training Loss: 0.5222%\n",
      "Epoch [40/300], Step [156/225], Training Accuracy: 77.4339%, Training Loss: 0.5227%\n",
      "Epoch [40/300], Step [157/225], Training Accuracy: 77.4582%, Training Loss: 0.5221%\n",
      "Epoch [40/300], Step [158/225], Training Accuracy: 77.4328%, Training Loss: 0.5233%\n",
      "Epoch [40/300], Step [159/225], Training Accuracy: 77.3487%, Training Loss: 0.5244%\n",
      "Epoch [40/300], Step [160/225], Training Accuracy: 77.3828%, Training Loss: 0.5239%\n",
      "Epoch [40/300], Step [161/225], Training Accuracy: 77.3680%, Training Loss: 0.5240%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/300], Step [162/225], Training Accuracy: 77.3727%, Training Loss: 0.5243%\n",
      "Epoch [40/300], Step [163/225], Training Accuracy: 77.4061%, Training Loss: 0.5237%\n",
      "Epoch [40/300], Step [164/225], Training Accuracy: 77.3914%, Training Loss: 0.5232%\n",
      "Epoch [40/300], Step [165/225], Training Accuracy: 77.3864%, Training Loss: 0.5233%\n",
      "Epoch [40/300], Step [166/225], Training Accuracy: 77.3720%, Training Loss: 0.5242%\n",
      "Epoch [40/300], Step [167/225], Training Accuracy: 77.3391%, Training Loss: 0.5244%\n",
      "Epoch [40/300], Step [168/225], Training Accuracy: 77.2972%, Training Loss: 0.5251%\n",
      "Epoch [40/300], Step [169/225], Training Accuracy: 77.3299%, Training Loss: 0.5245%\n",
      "Epoch [40/300], Step [170/225], Training Accuracy: 77.3346%, Training Loss: 0.5246%\n",
      "Epoch [40/300], Step [171/225], Training Accuracy: 77.3118%, Training Loss: 0.5247%\n",
      "Epoch [40/300], Step [172/225], Training Accuracy: 77.2983%, Training Loss: 0.5249%\n",
      "Epoch [40/300], Step [173/225], Training Accuracy: 77.3031%, Training Loss: 0.5248%\n",
      "Epoch [40/300], Step [174/225], Training Accuracy: 77.3348%, Training Loss: 0.5242%\n",
      "Epoch [40/300], Step [175/225], Training Accuracy: 77.3482%, Training Loss: 0.5238%\n",
      "Epoch [40/300], Step [176/225], Training Accuracy: 77.3793%, Training Loss: 0.5235%\n",
      "Epoch [40/300], Step [177/225], Training Accuracy: 77.3923%, Training Loss: 0.5233%\n",
      "Epoch [40/300], Step [178/225], Training Accuracy: 77.4140%, Training Loss: 0.5228%\n",
      "Epoch [40/300], Step [179/225], Training Accuracy: 77.4441%, Training Loss: 0.5228%\n",
      "Epoch [40/300], Step [180/225], Training Accuracy: 77.4566%, Training Loss: 0.5224%\n",
      "Epoch [40/300], Step [181/225], Training Accuracy: 77.4862%, Training Loss: 0.5223%\n",
      "Epoch [40/300], Step [182/225], Training Accuracy: 77.4811%, Training Loss: 0.5225%\n",
      "Epoch [40/300], Step [183/225], Training Accuracy: 77.4419%, Training Loss: 0.5230%\n",
      "Epoch [40/300], Step [184/225], Training Accuracy: 77.4541%, Training Loss: 0.5226%\n",
      "Epoch [40/300], Step [185/225], Training Accuracy: 77.4831%, Training Loss: 0.5220%\n",
      "Epoch [40/300], Step [186/225], Training Accuracy: 77.4782%, Training Loss: 0.5218%\n",
      "Epoch [40/300], Step [187/225], Training Accuracy: 77.4900%, Training Loss: 0.5215%\n",
      "Epoch [40/300], Step [188/225], Training Accuracy: 77.5183%, Training Loss: 0.5210%\n",
      "Epoch [40/300], Step [189/225], Training Accuracy: 77.5380%, Training Loss: 0.5212%\n",
      "Epoch [40/300], Step [190/225], Training Accuracy: 77.5329%, Training Loss: 0.5211%\n",
      "Epoch [40/300], Step [191/225], Training Accuracy: 77.4951%, Training Loss: 0.5218%\n",
      "Epoch [40/300], Step [192/225], Training Accuracy: 77.5146%, Training Loss: 0.5214%\n",
      "Epoch [40/300], Step [193/225], Training Accuracy: 77.5016%, Training Loss: 0.5218%\n",
      "Epoch [40/300], Step [194/225], Training Accuracy: 77.4887%, Training Loss: 0.5222%\n",
      "Epoch [40/300], Step [195/225], Training Accuracy: 77.5080%, Training Loss: 0.5218%\n",
      "Epoch [40/300], Step [196/225], Training Accuracy: 77.4952%, Training Loss: 0.5216%\n",
      "Epoch [40/300], Step [197/225], Training Accuracy: 77.4826%, Training Loss: 0.5217%\n",
      "Epoch [40/300], Step [198/225], Training Accuracy: 77.4858%, Training Loss: 0.5213%\n",
      "Epoch [40/300], Step [199/225], Training Accuracy: 77.5283%, Training Loss: 0.5208%\n",
      "Epoch [40/300], Step [200/225], Training Accuracy: 77.4844%, Training Loss: 0.5211%\n",
      "Epoch [40/300], Step [201/225], Training Accuracy: 77.4876%, Training Loss: 0.5210%\n",
      "Epoch [40/300], Step [202/225], Training Accuracy: 77.5139%, Training Loss: 0.5210%\n",
      "Epoch [40/300], Step [203/225], Training Accuracy: 77.5092%, Training Loss: 0.5210%\n",
      "Epoch [40/300], Step [204/225], Training Accuracy: 77.5046%, Training Loss: 0.5214%\n",
      "Epoch [40/300], Step [205/225], Training Accuracy: 77.5229%, Training Loss: 0.5211%\n",
      "Epoch [40/300], Step [206/225], Training Accuracy: 77.5410%, Training Loss: 0.5213%\n",
      "Epoch [40/300], Step [207/225], Training Accuracy: 77.5287%, Training Loss: 0.5210%\n",
      "Epoch [40/300], Step [208/225], Training Accuracy: 77.5466%, Training Loss: 0.5205%\n",
      "Epoch [40/300], Step [209/225], Training Accuracy: 77.5493%, Training Loss: 0.5205%\n",
      "Epoch [40/300], Step [210/225], Training Accuracy: 77.5372%, Training Loss: 0.5209%\n",
      "Epoch [40/300], Step [211/225], Training Accuracy: 77.5326%, Training Loss: 0.5211%\n",
      "Epoch [40/300], Step [212/225], Training Accuracy: 77.5501%, Training Loss: 0.5210%\n",
      "Epoch [40/300], Step [213/225], Training Accuracy: 77.5161%, Training Loss: 0.5214%\n",
      "Epoch [40/300], Step [214/225], Training Accuracy: 77.5044%, Training Loss: 0.5212%\n",
      "Epoch [40/300], Step [215/225], Training Accuracy: 77.5291%, Training Loss: 0.5211%\n",
      "Epoch [40/300], Step [216/225], Training Accuracy: 77.5029%, Training Loss: 0.5220%\n",
      "Epoch [40/300], Step [217/225], Training Accuracy: 77.5202%, Training Loss: 0.5221%\n",
      "Epoch [40/300], Step [218/225], Training Accuracy: 77.4943%, Training Loss: 0.5226%\n",
      "Epoch [40/300], Step [219/225], Training Accuracy: 77.5043%, Training Loss: 0.5226%\n",
      "Epoch [40/300], Step [220/225], Training Accuracy: 77.5142%, Training Loss: 0.5228%\n",
      "Epoch [40/300], Step [221/225], Training Accuracy: 77.4958%, Training Loss: 0.5231%\n",
      "Epoch [40/300], Step [222/225], Training Accuracy: 77.5127%, Training Loss: 0.5230%\n",
      "Epoch [40/300], Step [223/225], Training Accuracy: 77.4804%, Training Loss: 0.5236%\n",
      "Epoch [40/300], Step [224/225], Training Accuracy: 77.4972%, Training Loss: 0.5232%\n",
      "Epoch [40/300], Step [225/225], Training Accuracy: 77.5153%, Training Loss: 0.5230%\n",
      "Epoch [41/300], Step [1/225], Training Accuracy: 78.1250%, Training Loss: 0.3955%\n",
      "Epoch [41/300], Step [2/225], Training Accuracy: 78.9062%, Training Loss: 0.5111%\n",
      "Epoch [41/300], Step [3/225], Training Accuracy: 77.6042%, Training Loss: 0.5664%\n",
      "Epoch [41/300], Step [4/225], Training Accuracy: 75.3906%, Training Loss: 0.5781%\n",
      "Epoch [41/300], Step [5/225], Training Accuracy: 75.6250%, Training Loss: 0.5742%\n",
      "Epoch [41/300], Step [6/225], Training Accuracy: 75.7812%, Training Loss: 0.5664%\n",
      "Epoch [41/300], Step [7/225], Training Accuracy: 76.5625%, Training Loss: 0.5478%\n",
      "Epoch [41/300], Step [8/225], Training Accuracy: 75.3906%, Training Loss: 0.5601%\n",
      "Epoch [41/300], Step [9/225], Training Accuracy: 75.3472%, Training Loss: 0.5690%\n",
      "Epoch [41/300], Step [10/225], Training Accuracy: 75.4688%, Training Loss: 0.5687%\n",
      "Epoch [41/300], Step [11/225], Training Accuracy: 75.0000%, Training Loss: 0.5827%\n",
      "Epoch [41/300], Step [12/225], Training Accuracy: 75.3906%, Training Loss: 0.5701%\n",
      "Epoch [41/300], Step [13/225], Training Accuracy: 76.2019%, Training Loss: 0.5531%\n",
      "Epoch [41/300], Step [14/225], Training Accuracy: 76.0045%, Training Loss: 0.5518%\n",
      "Epoch [41/300], Step [15/225], Training Accuracy: 75.8333%, Training Loss: 0.5521%\n",
      "Epoch [41/300], Step [16/225], Training Accuracy: 75.8789%, Training Loss: 0.5507%\n",
      "Epoch [41/300], Step [17/225], Training Accuracy: 76.3787%, Training Loss: 0.5436%\n",
      "Epoch [41/300], Step [18/225], Training Accuracy: 76.8229%, Training Loss: 0.5376%\n",
      "Epoch [41/300], Step [19/225], Training Accuracy: 76.8092%, Training Loss: 0.5450%\n",
      "Epoch [41/300], Step [20/225], Training Accuracy: 77.1094%, Training Loss: 0.5412%\n",
      "Epoch [41/300], Step [21/225], Training Accuracy: 77.2321%, Training Loss: 0.5368%\n",
      "Epoch [41/300], Step [22/225], Training Accuracy: 76.9886%, Training Loss: 0.5473%\n",
      "Epoch [41/300], Step [23/225], Training Accuracy: 77.2418%, Training Loss: 0.5426%\n",
      "Epoch [41/300], Step [24/225], Training Accuracy: 77.0833%, Training Loss: 0.5417%\n",
      "Epoch [41/300], Step [25/225], Training Accuracy: 77.3750%, Training Loss: 0.5360%\n",
      "Epoch [41/300], Step [26/225], Training Accuracy: 77.5841%, Training Loss: 0.5345%\n",
      "Epoch [41/300], Step [27/225], Training Accuracy: 77.5463%, Training Loss: 0.5336%\n",
      "Epoch [41/300], Step [28/225], Training Accuracy: 77.7344%, Training Loss: 0.5285%\n",
      "Epoch [41/300], Step [29/225], Training Accuracy: 77.6401%, Training Loss: 0.5286%\n",
      "Epoch [41/300], Step [30/225], Training Accuracy: 77.7604%, Training Loss: 0.5284%\n",
      "Epoch [41/300], Step [31/225], Training Accuracy: 77.8226%, Training Loss: 0.5266%\n",
      "Epoch [41/300], Step [32/225], Training Accuracy: 77.6367%, Training Loss: 0.5304%\n",
      "Epoch [41/300], Step [33/225], Training Accuracy: 77.6989%, Training Loss: 0.5302%\n",
      "Epoch [41/300], Step [34/225], Training Accuracy: 77.4816%, Training Loss: 0.5356%\n",
      "Epoch [41/300], Step [35/225], Training Accuracy: 77.3661%, Training Loss: 0.5349%\n",
      "Epoch [41/300], Step [36/225], Training Accuracy: 77.5174%, Training Loss: 0.5343%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/300], Step [37/225], Training Accuracy: 77.7872%, Training Loss: 0.5284%\n",
      "Epoch [41/300], Step [38/225], Training Accuracy: 77.8372%, Training Loss: 0.5268%\n",
      "Epoch [41/300], Step [39/225], Training Accuracy: 77.6843%, Training Loss: 0.5284%\n",
      "Epoch [41/300], Step [40/225], Training Accuracy: 77.6953%, Training Loss: 0.5267%\n",
      "Epoch [41/300], Step [41/225], Training Accuracy: 77.4771%, Training Loss: 0.5317%\n",
      "Epoch [41/300], Step [42/225], Training Accuracy: 77.3438%, Training Loss: 0.5350%\n",
      "Epoch [41/300], Step [43/225], Training Accuracy: 77.3619%, Training Loss: 0.5348%\n",
      "Epoch [41/300], Step [44/225], Training Accuracy: 77.5213%, Training Loss: 0.5315%\n",
      "Epoch [41/300], Step [45/225], Training Accuracy: 77.6389%, Training Loss: 0.5292%\n",
      "Epoch [41/300], Step [46/225], Training Accuracy: 77.7174%, Training Loss: 0.5304%\n",
      "Epoch [41/300], Step [47/225], Training Accuracy: 77.6596%, Training Loss: 0.5342%\n",
      "Epoch [41/300], Step [48/225], Training Accuracy: 77.6367%, Training Loss: 0.5336%\n",
      "Epoch [41/300], Step [49/225], Training Accuracy: 77.6467%, Training Loss: 0.5320%\n",
      "Epoch [41/300], Step [50/225], Training Accuracy: 77.5000%, Training Loss: 0.5353%\n",
      "Epoch [41/300], Step [51/225], Training Accuracy: 77.7267%, Training Loss: 0.5322%\n",
      "Epoch [41/300], Step [52/225], Training Accuracy: 77.8846%, Training Loss: 0.5290%\n",
      "Epoch [41/300], Step [53/225], Training Accuracy: 78.0366%, Training Loss: 0.5275%\n",
      "Epoch [41/300], Step [54/225], Training Accuracy: 78.0382%, Training Loss: 0.5281%\n",
      "Epoch [41/300], Step [55/225], Training Accuracy: 77.9545%, Training Loss: 0.5287%\n",
      "Epoch [41/300], Step [56/225], Training Accuracy: 77.9297%, Training Loss: 0.5297%\n",
      "Epoch [41/300], Step [57/225], Training Accuracy: 77.9057%, Training Loss: 0.5310%\n",
      "Epoch [41/300], Step [58/225], Training Accuracy: 77.9095%, Training Loss: 0.5310%\n",
      "Epoch [41/300], Step [59/225], Training Accuracy: 77.7807%, Training Loss: 0.5340%\n",
      "Epoch [41/300], Step [60/225], Training Accuracy: 77.7344%, Training Loss: 0.5348%\n",
      "Epoch [41/300], Step [61/225], Training Accuracy: 77.6639%, Training Loss: 0.5350%\n",
      "Epoch [41/300], Step [62/225], Training Accuracy: 77.7218%, Training Loss: 0.5345%\n",
      "Epoch [41/300], Step [63/225], Training Accuracy: 77.6786%, Training Loss: 0.5345%\n",
      "Epoch [41/300], Step [64/225], Training Accuracy: 77.6855%, Training Loss: 0.5357%\n",
      "Epoch [41/300], Step [65/225], Training Accuracy: 77.7885%, Training Loss: 0.5334%\n",
      "Epoch [41/300], Step [66/225], Training Accuracy: 77.7699%, Training Loss: 0.5338%\n",
      "Epoch [41/300], Step [67/225], Training Accuracy: 77.7285%, Training Loss: 0.5340%\n",
      "Epoch [41/300], Step [68/225], Training Accuracy: 77.6884%, Training Loss: 0.5360%\n",
      "Epoch [41/300], Step [69/225], Training Accuracy: 77.7400%, Training Loss: 0.5335%\n",
      "Epoch [41/300], Step [70/225], Training Accuracy: 77.8125%, Training Loss: 0.5327%\n",
      "Epoch [41/300], Step [71/225], Training Accuracy: 77.6849%, Training Loss: 0.5339%\n",
      "Epoch [41/300], Step [72/225], Training Accuracy: 77.7995%, Training Loss: 0.5325%\n",
      "Epoch [41/300], Step [73/225], Training Accuracy: 77.9110%, Training Loss: 0.5328%\n",
      "Epoch [41/300], Step [74/225], Training Accuracy: 77.8083%, Training Loss: 0.5323%\n",
      "Epoch [41/300], Step [75/225], Training Accuracy: 77.7917%, Training Loss: 0.5313%\n",
      "Epoch [41/300], Step [76/225], Training Accuracy: 77.8372%, Training Loss: 0.5311%\n",
      "Epoch [41/300], Step [77/225], Training Accuracy: 77.8206%, Training Loss: 0.5309%\n",
      "Epoch [41/300], Step [78/225], Training Accuracy: 77.8045%, Training Loss: 0.5310%\n",
      "Epoch [41/300], Step [79/225], Training Accuracy: 77.8877%, Training Loss: 0.5291%\n",
      "Epoch [41/300], Step [80/225], Training Accuracy: 77.8711%, Training Loss: 0.5290%\n",
      "Epoch [41/300], Step [81/225], Training Accuracy: 77.9321%, Training Loss: 0.5287%\n",
      "Epoch [41/300], Step [82/225], Training Accuracy: 77.8392%, Training Loss: 0.5289%\n",
      "Epoch [41/300], Step [83/225], Training Accuracy: 77.8238%, Training Loss: 0.5298%\n",
      "Epoch [41/300], Step [84/225], Training Accuracy: 77.8832%, Training Loss: 0.5288%\n",
      "Epoch [41/300], Step [85/225], Training Accuracy: 77.9044%, Training Loss: 0.5286%\n",
      "Epoch [41/300], Step [86/225], Training Accuracy: 77.9433%, Training Loss: 0.5274%\n",
      "Epoch [41/300], Step [87/225], Training Accuracy: 77.8556%, Training Loss: 0.5276%\n",
      "Epoch [41/300], Step [88/225], Training Accuracy: 77.8764%, Training Loss: 0.5281%\n",
      "Epoch [41/300], Step [89/225], Training Accuracy: 77.9319%, Training Loss: 0.5267%\n",
      "Epoch [41/300], Step [90/225], Training Accuracy: 77.9514%, Training Loss: 0.5264%\n",
      "Epoch [41/300], Step [91/225], Training Accuracy: 78.0048%, Training Loss: 0.5253%\n",
      "Epoch [41/300], Step [92/225], Training Accuracy: 77.9891%, Training Loss: 0.5255%\n",
      "Epoch [41/300], Step [93/225], Training Accuracy: 77.9906%, Training Loss: 0.5249%\n",
      "Epoch [41/300], Step [94/225], Training Accuracy: 78.0751%, Training Loss: 0.5238%\n",
      "Epoch [41/300], Step [95/225], Training Accuracy: 78.0757%, Training Loss: 0.5246%\n",
      "Epoch [41/300], Step [96/225], Training Accuracy: 78.2227%, Training Loss: 0.5228%\n",
      "Epoch [41/300], Step [97/225], Training Accuracy: 78.2700%, Training Loss: 0.5213%\n",
      "Epoch [41/300], Step [98/225], Training Accuracy: 78.2366%, Training Loss: 0.5213%\n",
      "Epoch [41/300], Step [99/225], Training Accuracy: 78.1566%, Training Loss: 0.5227%\n",
      "Epoch [41/300], Step [100/225], Training Accuracy: 78.1094%, Training Loss: 0.5246%\n",
      "Epoch [41/300], Step [101/225], Training Accuracy: 78.2178%, Training Loss: 0.5230%\n",
      "Epoch [41/300], Step [102/225], Training Accuracy: 78.1863%, Training Loss: 0.5229%\n",
      "Epoch [41/300], Step [103/225], Training Accuracy: 78.2160%, Training Loss: 0.5223%\n",
      "Epoch [41/300], Step [104/225], Training Accuracy: 78.2151%, Training Loss: 0.5221%\n",
      "Epoch [41/300], Step [105/225], Training Accuracy: 78.2292%, Training Loss: 0.5219%\n",
      "Epoch [41/300], Step [106/225], Training Accuracy: 78.2282%, Training Loss: 0.5224%\n",
      "Epoch [41/300], Step [107/225], Training Accuracy: 78.2126%, Training Loss: 0.5230%\n",
      "Epoch [41/300], Step [108/225], Training Accuracy: 78.1250%, Training Loss: 0.5238%\n",
      "Epoch [41/300], Step [109/225], Training Accuracy: 78.1680%, Training Loss: 0.5229%\n",
      "Epoch [41/300], Step [110/225], Training Accuracy: 78.1818%, Training Loss: 0.5218%\n",
      "Epoch [41/300], Step [111/225], Training Accuracy: 78.2095%, Training Loss: 0.5211%\n",
      "Epoch [41/300], Step [112/225], Training Accuracy: 78.2506%, Training Loss: 0.5203%\n",
      "Epoch [41/300], Step [113/225], Training Accuracy: 78.1941%, Training Loss: 0.5205%\n",
      "Epoch [41/300], Step [114/225], Training Accuracy: 78.2209%, Training Loss: 0.5202%\n",
      "Epoch [41/300], Step [115/225], Training Accuracy: 78.3016%, Training Loss: 0.5184%\n",
      "Epoch [41/300], Step [116/225], Training Accuracy: 78.2866%, Training Loss: 0.5191%\n",
      "Epoch [41/300], Step [117/225], Training Accuracy: 78.2585%, Training Loss: 0.5190%\n",
      "Epoch [41/300], Step [118/225], Training Accuracy: 78.2971%, Training Loss: 0.5183%\n",
      "Epoch [41/300], Step [119/225], Training Accuracy: 78.2038%, Training Loss: 0.5201%\n",
      "Epoch [41/300], Step [120/225], Training Accuracy: 78.1641%, Training Loss: 0.5208%\n",
      "Epoch [41/300], Step [121/225], Training Accuracy: 78.1121%, Training Loss: 0.5232%\n",
      "Epoch [41/300], Step [122/225], Training Accuracy: 78.1250%, Training Loss: 0.5229%\n",
      "Epoch [41/300], Step [123/225], Training Accuracy: 78.0996%, Training Loss: 0.5237%\n",
      "Epoch [41/300], Step [124/225], Training Accuracy: 78.0494%, Training Loss: 0.5240%\n",
      "Epoch [41/300], Step [125/225], Training Accuracy: 78.0875%, Training Loss: 0.5232%\n",
      "Epoch [41/300], Step [126/225], Training Accuracy: 78.0630%, Training Loss: 0.5235%\n",
      "Epoch [41/300], Step [127/225], Training Accuracy: 78.1127%, Training Loss: 0.5222%\n",
      "Epoch [41/300], Step [128/225], Training Accuracy: 78.0518%, Training Loss: 0.5229%\n",
      "Epoch [41/300], Step [129/225], Training Accuracy: 78.0402%, Training Loss: 0.5229%\n",
      "Epoch [41/300], Step [130/225], Training Accuracy: 77.9688%, Training Loss: 0.5234%\n",
      "Epoch [41/300], Step [131/225], Training Accuracy: 77.9580%, Training Loss: 0.5234%\n",
      "Epoch [41/300], Step [132/225], Training Accuracy: 77.8409%, Training Loss: 0.5251%\n",
      "Epoch [41/300], Step [133/225], Training Accuracy: 77.8078%, Training Loss: 0.5253%\n",
      "Epoch [41/300], Step [134/225], Training Accuracy: 77.7285%, Training Loss: 0.5271%\n",
      "Epoch [41/300], Step [135/225], Training Accuracy: 77.7199%, Training Loss: 0.5271%\n",
      "Epoch [41/300], Step [136/225], Training Accuracy: 77.6540%, Training Loss: 0.5279%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/300], Step [137/225], Training Accuracy: 77.6346%, Training Loss: 0.5280%\n",
      "Epoch [41/300], Step [138/225], Training Accuracy: 77.6721%, Training Loss: 0.5274%\n",
      "Epoch [41/300], Step [139/225], Training Accuracy: 77.6641%, Training Loss: 0.5275%\n",
      "Epoch [41/300], Step [140/225], Training Accuracy: 77.6339%, Training Loss: 0.5281%\n",
      "Epoch [41/300], Step [141/225], Training Accuracy: 77.6485%, Training Loss: 0.5278%\n",
      "Epoch [41/300], Step [142/225], Training Accuracy: 77.6298%, Training Loss: 0.5287%\n",
      "Epoch [41/300], Step [143/225], Training Accuracy: 77.6224%, Training Loss: 0.5287%\n",
      "Epoch [41/300], Step [144/225], Training Accuracy: 77.5933%, Training Loss: 0.5291%\n",
      "Epoch [41/300], Step [145/225], Training Accuracy: 77.6078%, Training Loss: 0.5295%\n",
      "Epoch [41/300], Step [146/225], Training Accuracy: 77.5792%, Training Loss: 0.5308%\n",
      "Epoch [41/300], Step [147/225], Training Accuracy: 77.6042%, Training Loss: 0.5303%\n",
      "Epoch [41/300], Step [148/225], Training Accuracy: 77.6499%, Training Loss: 0.5297%\n",
      "Epoch [41/300], Step [149/225], Training Accuracy: 77.6216%, Training Loss: 0.5297%\n",
      "Epoch [41/300], Step [150/225], Training Accuracy: 77.6771%, Training Loss: 0.5286%\n",
      "Epoch [41/300], Step [151/225], Training Accuracy: 77.6800%, Training Loss: 0.5286%\n",
      "Epoch [41/300], Step [152/225], Training Accuracy: 77.6830%, Training Loss: 0.5283%\n",
      "Epoch [41/300], Step [153/225], Training Accuracy: 77.6348%, Training Loss: 0.5289%\n",
      "Epoch [41/300], Step [154/225], Training Accuracy: 77.6278%, Training Loss: 0.5290%\n",
      "Epoch [41/300], Step [155/225], Training Accuracy: 77.6109%, Training Loss: 0.5286%\n",
      "Epoch [41/300], Step [156/225], Training Accuracy: 77.5541%, Training Loss: 0.5298%\n",
      "Epoch [41/300], Step [157/225], Training Accuracy: 77.5677%, Training Loss: 0.5299%\n",
      "Epoch [41/300], Step [158/225], Training Accuracy: 77.5119%, Training Loss: 0.5306%\n",
      "Epoch [41/300], Step [159/225], Training Accuracy: 77.5059%, Training Loss: 0.5314%\n",
      "Epoch [41/300], Step [160/225], Training Accuracy: 77.4805%, Training Loss: 0.5314%\n",
      "Epoch [41/300], Step [161/225], Training Accuracy: 77.4457%, Training Loss: 0.5325%\n",
      "Epoch [41/300], Step [162/225], Training Accuracy: 77.4788%, Training Loss: 0.5322%\n",
      "Epoch [41/300], Step [163/225], Training Accuracy: 77.5019%, Training Loss: 0.5317%\n",
      "Epoch [41/300], Step [164/225], Training Accuracy: 77.5248%, Training Loss: 0.5310%\n",
      "Epoch [41/300], Step [165/225], Training Accuracy: 77.5189%, Training Loss: 0.5314%\n",
      "Epoch [41/300], Step [166/225], Training Accuracy: 77.5038%, Training Loss: 0.5321%\n",
      "Epoch [41/300], Step [167/225], Training Accuracy: 77.4888%, Training Loss: 0.5323%\n",
      "Epoch [41/300], Step [168/225], Training Accuracy: 77.4833%, Training Loss: 0.5321%\n",
      "Epoch [41/300], Step [169/225], Training Accuracy: 77.4963%, Training Loss: 0.5316%\n",
      "Epoch [41/300], Step [170/225], Training Accuracy: 77.4908%, Training Loss: 0.5315%\n",
      "Epoch [41/300], Step [171/225], Training Accuracy: 77.4671%, Training Loss: 0.5320%\n",
      "Epoch [41/300], Step [172/225], Training Accuracy: 77.4618%, Training Loss: 0.5317%\n",
      "Epoch [41/300], Step [173/225], Training Accuracy: 77.4296%, Training Loss: 0.5328%\n",
      "Epoch [41/300], Step [174/225], Training Accuracy: 77.4066%, Training Loss: 0.5328%\n",
      "Epoch [41/300], Step [175/225], Training Accuracy: 77.4643%, Training Loss: 0.5318%\n",
      "Epoch [41/300], Step [176/225], Training Accuracy: 77.4414%, Training Loss: 0.5322%\n",
      "Epoch [41/300], Step [177/225], Training Accuracy: 77.4364%, Training Loss: 0.5323%\n",
      "Epoch [41/300], Step [178/225], Training Accuracy: 77.3789%, Training Loss: 0.5328%\n",
      "Epoch [41/300], Step [179/225], Training Accuracy: 77.3568%, Training Loss: 0.5329%\n",
      "Epoch [41/300], Step [180/225], Training Accuracy: 77.3958%, Training Loss: 0.5324%\n",
      "Epoch [41/300], Step [181/225], Training Accuracy: 77.3912%, Training Loss: 0.5327%\n",
      "Epoch [41/300], Step [182/225], Training Accuracy: 77.4210%, Training Loss: 0.5326%\n",
      "Epoch [41/300], Step [183/225], Training Accuracy: 77.3992%, Training Loss: 0.5330%\n",
      "Epoch [41/300], Step [184/225], Training Accuracy: 77.4711%, Training Loss: 0.5324%\n",
      "Epoch [41/300], Step [185/225], Training Accuracy: 77.4662%, Training Loss: 0.5326%\n",
      "Epoch [41/300], Step [186/225], Training Accuracy: 77.5454%, Training Loss: 0.5314%\n",
      "Epoch [41/300], Step [187/225], Training Accuracy: 77.5485%, Training Loss: 0.5320%\n",
      "Epoch [41/300], Step [188/225], Training Accuracy: 77.5765%, Training Loss: 0.5314%\n",
      "Epoch [41/300], Step [189/225], Training Accuracy: 77.5794%, Training Loss: 0.5312%\n",
      "Epoch [41/300], Step [190/225], Training Accuracy: 77.6069%, Training Loss: 0.5310%\n",
      "Epoch [41/300], Step [191/225], Training Accuracy: 77.5605%, Training Loss: 0.5312%\n",
      "Epoch [41/300], Step [192/225], Training Accuracy: 77.5635%, Training Loss: 0.5315%\n",
      "Epoch [41/300], Step [193/225], Training Accuracy: 77.5502%, Training Loss: 0.5317%\n",
      "Epoch [41/300], Step [194/225], Training Accuracy: 77.5532%, Training Loss: 0.5316%\n",
      "Epoch [41/300], Step [195/225], Training Accuracy: 77.5801%, Training Loss: 0.5309%\n",
      "Epoch [41/300], Step [196/225], Training Accuracy: 77.5829%, Training Loss: 0.5308%\n",
      "Epoch [41/300], Step [197/225], Training Accuracy: 77.5777%, Training Loss: 0.5308%\n",
      "Epoch [41/300], Step [198/225], Training Accuracy: 77.6121%, Training Loss: 0.5304%\n",
      "Epoch [41/300], Step [199/225], Training Accuracy: 77.6068%, Training Loss: 0.5299%\n",
      "Epoch [41/300], Step [200/225], Training Accuracy: 77.5859%, Training Loss: 0.5309%\n",
      "Epoch [41/300], Step [201/225], Training Accuracy: 77.5653%, Training Loss: 0.5310%\n",
      "Epoch [41/300], Step [202/225], Training Accuracy: 77.5603%, Training Loss: 0.5313%\n",
      "Epoch [41/300], Step [203/225], Training Accuracy: 77.6016%, Training Loss: 0.5308%\n",
      "Epoch [41/300], Step [204/225], Training Accuracy: 77.6118%, Training Loss: 0.5307%\n",
      "Epoch [41/300], Step [205/225], Training Accuracy: 77.5915%, Training Loss: 0.5304%\n",
      "Epoch [41/300], Step [206/225], Training Accuracy: 77.5561%, Training Loss: 0.5309%\n",
      "Epoch [41/300], Step [207/225], Training Accuracy: 77.5287%, Training Loss: 0.5310%\n",
      "Epoch [41/300], Step [208/225], Training Accuracy: 77.5391%, Training Loss: 0.5304%\n",
      "Epoch [41/300], Step [209/225], Training Accuracy: 77.5120%, Training Loss: 0.5306%\n",
      "Epoch [41/300], Step [210/225], Training Accuracy: 77.5223%, Training Loss: 0.5307%\n",
      "Epoch [41/300], Step [211/225], Training Accuracy: 77.5252%, Training Loss: 0.5303%\n",
      "Epoch [41/300], Step [212/225], Training Accuracy: 77.5133%, Training Loss: 0.5307%\n",
      "Epoch [41/300], Step [213/225], Training Accuracy: 77.5161%, Training Loss: 0.5310%\n",
      "Epoch [41/300], Step [214/225], Training Accuracy: 77.5263%, Training Loss: 0.5303%\n",
      "Epoch [41/300], Step [215/225], Training Accuracy: 77.5581%, Training Loss: 0.5300%\n",
      "Epoch [41/300], Step [216/225], Training Accuracy: 77.5535%, Training Loss: 0.5300%\n",
      "Epoch [41/300], Step [217/225], Training Accuracy: 77.5130%, Training Loss: 0.5304%\n",
      "Epoch [41/300], Step [218/225], Training Accuracy: 77.4943%, Training Loss: 0.5311%\n",
      "Epoch [41/300], Step [219/225], Training Accuracy: 77.4757%, Training Loss: 0.5321%\n",
      "Epoch [41/300], Step [220/225], Training Accuracy: 77.5213%, Training Loss: 0.5311%\n",
      "Epoch [41/300], Step [221/225], Training Accuracy: 77.5735%, Training Loss: 0.5305%\n",
      "Epoch [41/300], Step [222/225], Training Accuracy: 77.5549%, Training Loss: 0.5309%\n",
      "Epoch [41/300], Step [223/225], Training Accuracy: 77.5715%, Training Loss: 0.5307%\n",
      "Epoch [41/300], Step [224/225], Training Accuracy: 77.5949%, Training Loss: 0.5300%\n",
      "Epoch [41/300], Step [225/225], Training Accuracy: 77.6056%, Training Loss: 0.5295%\n",
      "Epoch [42/300], Step [1/225], Training Accuracy: 82.8125%, Training Loss: 0.4294%\n",
      "Epoch [42/300], Step [2/225], Training Accuracy: 80.4688%, Training Loss: 0.5009%\n",
      "Epoch [42/300], Step [3/225], Training Accuracy: 79.6875%, Training Loss: 0.5233%\n",
      "Epoch [42/300], Step [4/225], Training Accuracy: 80.0781%, Training Loss: 0.5204%\n",
      "Epoch [42/300], Step [5/225], Training Accuracy: 80.9375%, Training Loss: 0.5025%\n",
      "Epoch [42/300], Step [6/225], Training Accuracy: 80.4688%, Training Loss: 0.4910%\n",
      "Epoch [42/300], Step [7/225], Training Accuracy: 80.5804%, Training Loss: 0.4802%\n",
      "Epoch [42/300], Step [8/225], Training Accuracy: 80.2734%, Training Loss: 0.4898%\n",
      "Epoch [42/300], Step [9/225], Training Accuracy: 80.0347%, Training Loss: 0.4880%\n",
      "Epoch [42/300], Step [10/225], Training Accuracy: 79.6875%, Training Loss: 0.4905%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/300], Step [11/225], Training Accuracy: 79.2614%, Training Loss: 0.4891%\n",
      "Epoch [42/300], Step [12/225], Training Accuracy: 78.9062%, Training Loss: 0.4892%\n",
      "Epoch [42/300], Step [13/225], Training Accuracy: 79.6875%, Training Loss: 0.4779%\n",
      "Epoch [42/300], Step [14/225], Training Accuracy: 79.5759%, Training Loss: 0.4815%\n",
      "Epoch [42/300], Step [15/225], Training Accuracy: 79.0625%, Training Loss: 0.4817%\n",
      "Epoch [42/300], Step [16/225], Training Accuracy: 78.4180%, Training Loss: 0.4935%\n",
      "Epoch [42/300], Step [17/225], Training Accuracy: 78.7684%, Training Loss: 0.4914%\n",
      "Epoch [42/300], Step [18/225], Training Accuracy: 78.7326%, Training Loss: 0.4908%\n",
      "Epoch [42/300], Step [19/225], Training Accuracy: 78.6184%, Training Loss: 0.4880%\n",
      "Epoch [42/300], Step [20/225], Training Accuracy: 78.8281%, Training Loss: 0.4842%\n",
      "Epoch [42/300], Step [21/225], Training Accuracy: 79.1667%, Training Loss: 0.4799%\n",
      "Epoch [42/300], Step [22/225], Training Accuracy: 78.9773%, Training Loss: 0.4830%\n",
      "Epoch [42/300], Step [23/225], Training Accuracy: 79.4837%, Training Loss: 0.4796%\n",
      "Epoch [42/300], Step [24/225], Training Accuracy: 79.4271%, Training Loss: 0.4802%\n",
      "Epoch [42/300], Step [25/225], Training Accuracy: 79.4375%, Training Loss: 0.4832%\n",
      "Epoch [42/300], Step [26/225], Training Accuracy: 79.2668%, Training Loss: 0.4878%\n",
      "Epoch [42/300], Step [27/225], Training Accuracy: 79.4560%, Training Loss: 0.4857%\n",
      "Epoch [42/300], Step [28/225], Training Accuracy: 79.5759%, Training Loss: 0.4823%\n",
      "Epoch [42/300], Step [29/225], Training Accuracy: 79.6875%, Training Loss: 0.4823%\n",
      "Epoch [42/300], Step [30/225], Training Accuracy: 79.8958%, Training Loss: 0.4810%\n",
      "Epoch [42/300], Step [31/225], Training Accuracy: 79.9395%, Training Loss: 0.4809%\n",
      "Epoch [42/300], Step [32/225], Training Accuracy: 79.7363%, Training Loss: 0.4841%\n",
      "Epoch [42/300], Step [33/225], Training Accuracy: 79.7348%, Training Loss: 0.4829%\n",
      "Epoch [42/300], Step [34/225], Training Accuracy: 79.3199%, Training Loss: 0.4907%\n",
      "Epoch [42/300], Step [35/225], Training Accuracy: 79.1518%, Training Loss: 0.4927%\n",
      "Epoch [42/300], Step [36/225], Training Accuracy: 79.1667%, Training Loss: 0.4948%\n",
      "Epoch [42/300], Step [37/225], Training Accuracy: 79.3497%, Training Loss: 0.4903%\n",
      "Epoch [42/300], Step [38/225], Training Accuracy: 79.3174%, Training Loss: 0.4892%\n",
      "Epoch [42/300], Step [39/225], Training Accuracy: 79.2869%, Training Loss: 0.4917%\n",
      "Epoch [42/300], Step [40/225], Training Accuracy: 78.9453%, Training Loss: 0.5000%\n",
      "Epoch [42/300], Step [41/225], Training Accuracy: 78.7348%, Training Loss: 0.5043%\n",
      "Epoch [42/300], Step [42/225], Training Accuracy: 78.7202%, Training Loss: 0.5033%\n",
      "Epoch [42/300], Step [43/225], Training Accuracy: 78.8154%, Training Loss: 0.5026%\n",
      "Epoch [42/300], Step [44/225], Training Accuracy: 78.9062%, Training Loss: 0.5004%\n",
      "Epoch [42/300], Step [45/225], Training Accuracy: 78.8542%, Training Loss: 0.5020%\n",
      "Epoch [42/300], Step [46/225], Training Accuracy: 78.7364%, Training Loss: 0.5055%\n",
      "Epoch [42/300], Step [47/225], Training Accuracy: 78.3910%, Training Loss: 0.5154%\n",
      "Epoch [42/300], Step [48/225], Training Accuracy: 78.2878%, Training Loss: 0.5176%\n",
      "Epoch [42/300], Step [49/225], Training Accuracy: 78.4758%, Training Loss: 0.5155%\n",
      "Epoch [42/300], Step [50/225], Training Accuracy: 78.2812%, Training Loss: 0.5180%\n",
      "Epoch [42/300], Step [51/225], Training Accuracy: 78.3395%, Training Loss: 0.5161%\n",
      "Epoch [42/300], Step [52/225], Training Accuracy: 78.4555%, Training Loss: 0.5131%\n",
      "Epoch [42/300], Step [53/225], Training Accuracy: 78.5967%, Training Loss: 0.5134%\n",
      "Epoch [42/300], Step [54/225], Training Accuracy: 78.5880%, Training Loss: 0.5153%\n",
      "Epoch [42/300], Step [55/225], Training Accuracy: 78.4659%, Training Loss: 0.5181%\n",
      "Epoch [42/300], Step [56/225], Training Accuracy: 78.5714%, Training Loss: 0.5161%\n",
      "Epoch [42/300], Step [57/225], Training Accuracy: 78.5910%, Training Loss: 0.5151%\n",
      "Epoch [42/300], Step [58/225], Training Accuracy: 78.4213%, Training Loss: 0.5162%\n",
      "Epoch [42/300], Step [59/225], Training Accuracy: 78.2839%, Training Loss: 0.5186%\n",
      "Epoch [42/300], Step [60/225], Training Accuracy: 78.1510%, Training Loss: 0.5191%\n",
      "Epoch [42/300], Step [61/225], Training Accuracy: 78.0482%, Training Loss: 0.5202%\n",
      "Epoch [42/300], Step [62/225], Training Accuracy: 78.1502%, Training Loss: 0.5183%\n",
      "Epoch [42/300], Step [63/225], Training Accuracy: 78.2242%, Training Loss: 0.5173%\n",
      "Epoch [42/300], Step [64/225], Training Accuracy: 78.2715%, Training Loss: 0.5171%\n",
      "Epoch [42/300], Step [65/225], Training Accuracy: 78.2212%, Training Loss: 0.5177%\n",
      "Epoch [42/300], Step [66/225], Training Accuracy: 78.2434%, Training Loss: 0.5170%\n",
      "Epoch [42/300], Step [67/225], Training Accuracy: 78.1250%, Training Loss: 0.5185%\n",
      "Epoch [42/300], Step [68/225], Training Accuracy: 78.0561%, Training Loss: 0.5196%\n",
      "Epoch [42/300], Step [69/225], Training Accuracy: 78.0571%, Training Loss: 0.5184%\n",
      "Epoch [42/300], Step [70/225], Training Accuracy: 78.0580%, Training Loss: 0.5183%\n",
      "Epoch [42/300], Step [71/225], Training Accuracy: 78.0810%, Training Loss: 0.5171%\n",
      "Epoch [42/300], Step [72/225], Training Accuracy: 78.0599%, Training Loss: 0.5187%\n",
      "Epoch [42/300], Step [73/225], Training Accuracy: 78.0822%, Training Loss: 0.5181%\n",
      "Epoch [42/300], Step [74/225], Training Accuracy: 78.2517%, Training Loss: 0.5161%\n",
      "Epoch [42/300], Step [75/225], Training Accuracy: 78.1875%, Training Loss: 0.5164%\n",
      "Epoch [42/300], Step [76/225], Training Accuracy: 78.1661%, Training Loss: 0.5177%\n",
      "Epoch [42/300], Step [77/225], Training Accuracy: 78.1656%, Training Loss: 0.5180%\n",
      "Epoch [42/300], Step [78/225], Training Accuracy: 78.1851%, Training Loss: 0.5184%\n",
      "Epoch [42/300], Step [79/225], Training Accuracy: 78.1052%, Training Loss: 0.5195%\n",
      "Epoch [42/300], Step [80/225], Training Accuracy: 78.1055%, Training Loss: 0.5201%\n",
      "Epoch [42/300], Step [81/225], Training Accuracy: 78.1829%, Training Loss: 0.5197%\n",
      "Epoch [42/300], Step [82/225], Training Accuracy: 78.1059%, Training Loss: 0.5196%\n",
      "Epoch [42/300], Step [83/225], Training Accuracy: 78.0120%, Training Loss: 0.5204%\n",
      "Epoch [42/300], Step [84/225], Training Accuracy: 78.0878%, Training Loss: 0.5187%\n",
      "Epoch [42/300], Step [85/225], Training Accuracy: 78.1250%, Training Loss: 0.5179%\n",
      "Epoch [42/300], Step [86/225], Training Accuracy: 78.1977%, Training Loss: 0.5157%\n",
      "Epoch [42/300], Step [87/225], Training Accuracy: 78.1609%, Training Loss: 0.5158%\n",
      "Epoch [42/300], Step [88/225], Training Accuracy: 78.1250%, Training Loss: 0.5176%\n",
      "Epoch [42/300], Step [89/225], Training Accuracy: 78.1250%, Training Loss: 0.5184%\n",
      "Epoch [42/300], Step [90/225], Training Accuracy: 78.0382%, Training Loss: 0.5188%\n",
      "Epoch [42/300], Step [91/225], Training Accuracy: 78.0220%, Training Loss: 0.5187%\n",
      "Epoch [42/300], Step [92/225], Training Accuracy: 77.9382%, Training Loss: 0.5193%\n",
      "Epoch [42/300], Step [93/225], Training Accuracy: 78.0410%, Training Loss: 0.5171%\n",
      "Epoch [42/300], Step [94/225], Training Accuracy: 78.0918%, Training Loss: 0.5166%\n",
      "Epoch [42/300], Step [95/225], Training Accuracy: 78.0757%, Training Loss: 0.5170%\n",
      "Epoch [42/300], Step [96/225], Training Accuracy: 78.2389%, Training Loss: 0.5143%\n",
      "Epoch [42/300], Step [97/225], Training Accuracy: 78.2378%, Training Loss: 0.5137%\n",
      "Epoch [42/300], Step [98/225], Training Accuracy: 78.2685%, Training Loss: 0.5128%\n",
      "Epoch [42/300], Step [99/225], Training Accuracy: 78.2828%, Training Loss: 0.5127%\n",
      "Epoch [42/300], Step [100/225], Training Accuracy: 78.2500%, Training Loss: 0.5136%\n",
      "Epoch [42/300], Step [101/225], Training Accuracy: 78.2333%, Training Loss: 0.5131%\n",
      "Epoch [42/300], Step [102/225], Training Accuracy: 78.1403%, Training Loss: 0.5151%\n",
      "Epoch [42/300], Step [103/225], Training Accuracy: 78.1705%, Training Loss: 0.5145%\n",
      "Epoch [42/300], Step [104/225], Training Accuracy: 78.1400%, Training Loss: 0.5146%\n",
      "Epoch [42/300], Step [105/225], Training Accuracy: 78.1696%, Training Loss: 0.5131%\n",
      "Epoch [42/300], Step [106/225], Training Accuracy: 78.0955%, Training Loss: 0.5140%\n",
      "Epoch [42/300], Step [107/225], Training Accuracy: 78.0812%, Training Loss: 0.5145%\n",
      "Epoch [42/300], Step [108/225], Training Accuracy: 78.0816%, Training Loss: 0.5151%\n",
      "Epoch [42/300], Step [109/225], Training Accuracy: 78.0390%, Training Loss: 0.5155%\n",
      "Epoch [42/300], Step [110/225], Training Accuracy: 77.9830%, Training Loss: 0.5157%\n",
      "Epoch [42/300], Step [111/225], Training Accuracy: 77.9420%, Training Loss: 0.5175%\n",
      "Epoch [42/300], Step [112/225], Training Accuracy: 77.9855%, Training Loss: 0.5166%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/300], Step [113/225], Training Accuracy: 77.9038%, Training Loss: 0.5176%\n",
      "Epoch [42/300], Step [114/225], Training Accuracy: 77.9605%, Training Loss: 0.5179%\n",
      "Epoch [42/300], Step [115/225], Training Accuracy: 77.9620%, Training Loss: 0.5177%\n",
      "Epoch [42/300], Step [116/225], Training Accuracy: 77.9634%, Training Loss: 0.5169%\n",
      "Epoch [42/300], Step [117/225], Training Accuracy: 77.9113%, Training Loss: 0.5178%\n",
      "Epoch [42/300], Step [118/225], Training Accuracy: 77.9661%, Training Loss: 0.5173%\n",
      "Epoch [42/300], Step [119/225], Training Accuracy: 77.9280%, Training Loss: 0.5180%\n",
      "Epoch [42/300], Step [120/225], Training Accuracy: 77.8906%, Training Loss: 0.5198%\n",
      "Epoch [42/300], Step [121/225], Training Accuracy: 77.8926%, Training Loss: 0.5198%\n",
      "Epoch [42/300], Step [122/225], Training Accuracy: 77.8560%, Training Loss: 0.5204%\n",
      "Epoch [42/300], Step [123/225], Training Accuracy: 77.8582%, Training Loss: 0.5197%\n",
      "Epoch [42/300], Step [124/225], Training Accuracy: 77.8982%, Training Loss: 0.5195%\n",
      "Epoch [42/300], Step [125/225], Training Accuracy: 77.8250%, Training Loss: 0.5219%\n",
      "Epoch [42/300], Step [126/225], Training Accuracy: 77.7282%, Training Loss: 0.5231%\n",
      "Epoch [42/300], Step [127/225], Training Accuracy: 77.6698%, Training Loss: 0.5246%\n",
      "Epoch [42/300], Step [128/225], Training Accuracy: 77.6245%, Training Loss: 0.5256%\n",
      "Epoch [42/300], Step [129/225], Training Accuracy: 77.5921%, Training Loss: 0.5256%\n",
      "Epoch [42/300], Step [130/225], Training Accuracy: 77.6322%, Training Loss: 0.5251%\n",
      "Epoch [42/300], Step [131/225], Training Accuracy: 77.5763%, Training Loss: 0.5260%\n",
      "Epoch [42/300], Step [132/225], Training Accuracy: 77.4976%, Training Loss: 0.5272%\n",
      "Epoch [42/300], Step [133/225], Training Accuracy: 77.5023%, Training Loss: 0.5269%\n",
      "Epoch [42/300], Step [134/225], Training Accuracy: 77.4254%, Training Loss: 0.5293%\n",
      "Epoch [42/300], Step [135/225], Training Accuracy: 77.3611%, Training Loss: 0.5298%\n",
      "Epoch [42/300], Step [136/225], Training Accuracy: 77.3552%, Training Loss: 0.5302%\n",
      "Epoch [42/300], Step [137/225], Training Accuracy: 77.3152%, Training Loss: 0.5305%\n",
      "Epoch [42/300], Step [138/225], Training Accuracy: 77.3551%, Training Loss: 0.5295%\n",
      "Epoch [42/300], Step [139/225], Training Accuracy: 77.4056%, Training Loss: 0.5291%\n",
      "Epoch [42/300], Step [140/225], Training Accuracy: 77.4442%, Training Loss: 0.5287%\n",
      "Epoch [42/300], Step [141/225], Training Accuracy: 77.4490%, Training Loss: 0.5285%\n",
      "Epoch [42/300], Step [142/225], Training Accuracy: 77.4208%, Training Loss: 0.5287%\n",
      "Epoch [42/300], Step [143/225], Training Accuracy: 77.4148%, Training Loss: 0.5288%\n",
      "Epoch [42/300], Step [144/225], Training Accuracy: 77.4197%, Training Loss: 0.5286%\n",
      "Epoch [42/300], Step [145/225], Training Accuracy: 77.4677%, Training Loss: 0.5286%\n",
      "Epoch [42/300], Step [146/225], Training Accuracy: 77.4722%, Training Loss: 0.5286%\n",
      "Epoch [42/300], Step [147/225], Training Accuracy: 77.4554%, Training Loss: 0.5286%\n",
      "Epoch [42/300], Step [148/225], Training Accuracy: 77.5338%, Training Loss: 0.5272%\n",
      "Epoch [42/300], Step [149/225], Training Accuracy: 77.5482%, Training Loss: 0.5269%\n",
      "Epoch [42/300], Step [150/225], Training Accuracy: 77.6042%, Training Loss: 0.5258%\n",
      "Epoch [42/300], Step [151/225], Training Accuracy: 77.5662%, Training Loss: 0.5256%\n",
      "Epoch [42/300], Step [152/225], Training Accuracy: 77.5802%, Training Loss: 0.5251%\n",
      "Epoch [42/300], Step [153/225], Training Accuracy: 77.5735%, Training Loss: 0.5256%\n",
      "Epoch [42/300], Step [154/225], Training Accuracy: 77.5771%, Training Loss: 0.5251%\n",
      "Epoch [42/300], Step [155/225], Training Accuracy: 77.5706%, Training Loss: 0.5250%\n",
      "Epoch [42/300], Step [156/225], Training Accuracy: 77.5240%, Training Loss: 0.5257%\n",
      "Epoch [42/300], Step [157/225], Training Accuracy: 77.5080%, Training Loss: 0.5260%\n",
      "Epoch [42/300], Step [158/225], Training Accuracy: 77.4426%, Training Loss: 0.5277%\n",
      "Epoch [42/300], Step [159/225], Training Accuracy: 77.4371%, Training Loss: 0.5276%\n",
      "Epoch [42/300], Step [160/225], Training Accuracy: 77.4707%, Training Loss: 0.5268%\n",
      "Epoch [42/300], Step [161/225], Training Accuracy: 77.4554%, Training Loss: 0.5270%\n",
      "Epoch [42/300], Step [162/225], Training Accuracy: 77.4788%, Training Loss: 0.5267%\n",
      "Epoch [42/300], Step [163/225], Training Accuracy: 77.4923%, Training Loss: 0.5269%\n",
      "Epoch [42/300], Step [164/225], Training Accuracy: 77.4581%, Training Loss: 0.5275%\n",
      "Epoch [42/300], Step [165/225], Training Accuracy: 77.4527%, Training Loss: 0.5274%\n",
      "Epoch [42/300], Step [166/225], Training Accuracy: 77.4002%, Training Loss: 0.5285%\n",
      "Epoch [42/300], Step [167/225], Training Accuracy: 77.4233%, Training Loss: 0.5281%\n",
      "Epoch [42/300], Step [168/225], Training Accuracy: 77.3996%, Training Loss: 0.5280%\n",
      "Epoch [42/300], Step [169/225], Training Accuracy: 77.4223%, Training Loss: 0.5279%\n",
      "Epoch [42/300], Step [170/225], Training Accuracy: 77.4357%, Training Loss: 0.5272%\n",
      "Epoch [42/300], Step [171/225], Training Accuracy: 77.3940%, Training Loss: 0.5277%\n",
      "Epoch [42/300], Step [172/225], Training Accuracy: 77.3619%, Training Loss: 0.5278%\n",
      "Epoch [42/300], Step [173/225], Training Accuracy: 77.3212%, Training Loss: 0.5284%\n",
      "Epoch [42/300], Step [174/225], Training Accuracy: 77.2899%, Training Loss: 0.5288%\n",
      "Epoch [42/300], Step [175/225], Training Accuracy: 77.3482%, Training Loss: 0.5280%\n",
      "Epoch [42/300], Step [176/225], Training Accuracy: 77.3615%, Training Loss: 0.5280%\n",
      "Epoch [42/300], Step [177/225], Training Accuracy: 77.3658%, Training Loss: 0.5291%\n",
      "Epoch [42/300], Step [178/225], Training Accuracy: 77.3350%, Training Loss: 0.5294%\n",
      "Epoch [42/300], Step [179/225], Training Accuracy: 77.3394%, Training Loss: 0.5295%\n",
      "Epoch [42/300], Step [180/225], Training Accuracy: 77.3698%, Training Loss: 0.5288%\n",
      "Epoch [42/300], Step [181/225], Training Accuracy: 77.3481%, Training Loss: 0.5293%\n",
      "Epoch [42/300], Step [182/225], Training Accuracy: 77.3523%, Training Loss: 0.5297%\n",
      "Epoch [42/300], Step [183/225], Training Accuracy: 77.3309%, Training Loss: 0.5304%\n",
      "Epoch [42/300], Step [184/225], Training Accuracy: 77.3353%, Training Loss: 0.5306%\n",
      "Epoch [42/300], Step [185/225], Training Accuracy: 77.3564%, Training Loss: 0.5302%\n",
      "Epoch [42/300], Step [186/225], Training Accuracy: 77.4026%, Training Loss: 0.5293%\n",
      "Epoch [42/300], Step [187/225], Training Accuracy: 77.3563%, Training Loss: 0.5302%\n",
      "Epoch [42/300], Step [188/225], Training Accuracy: 77.3770%, Training Loss: 0.5298%\n",
      "Epoch [42/300], Step [189/225], Training Accuracy: 77.3727%, Training Loss: 0.5298%\n",
      "Epoch [42/300], Step [190/225], Training Accuracy: 77.3684%, Training Loss: 0.5300%\n",
      "Epoch [42/300], Step [191/225], Training Accuracy: 77.3969%, Training Loss: 0.5295%\n",
      "Epoch [42/300], Step [192/225], Training Accuracy: 77.3844%, Training Loss: 0.5292%\n",
      "Epoch [42/300], Step [193/225], Training Accuracy: 77.3478%, Training Loss: 0.5297%\n",
      "Epoch [42/300], Step [194/225], Training Accuracy: 77.3276%, Training Loss: 0.5301%\n",
      "Epoch [42/300], Step [195/225], Training Accuracy: 77.3718%, Training Loss: 0.5290%\n",
      "Epoch [42/300], Step [196/225], Training Accuracy: 77.3358%, Training Loss: 0.5302%\n",
      "Epoch [42/300], Step [197/225], Training Accuracy: 77.3398%, Training Loss: 0.5299%\n",
      "Epoch [42/300], Step [198/225], Training Accuracy: 77.3438%, Training Loss: 0.5296%\n",
      "Epoch [42/300], Step [199/225], Training Accuracy: 77.3791%, Training Loss: 0.5288%\n",
      "Epoch [42/300], Step [200/225], Training Accuracy: 77.3594%, Training Loss: 0.5288%\n",
      "Epoch [42/300], Step [201/225], Training Accuracy: 77.3554%, Training Loss: 0.5287%\n",
      "Epoch [42/300], Step [202/225], Training Accuracy: 77.3515%, Training Loss: 0.5289%\n",
      "Epoch [42/300], Step [203/225], Training Accuracy: 77.3707%, Training Loss: 0.5285%\n",
      "Epoch [42/300], Step [204/225], Training Accuracy: 77.3820%, Training Loss: 0.5281%\n",
      "Epoch [42/300], Step [205/225], Training Accuracy: 77.4238%, Training Loss: 0.5276%\n",
      "Epoch [42/300], Step [206/225], Training Accuracy: 77.4044%, Training Loss: 0.5280%\n",
      "Epoch [42/300], Step [207/225], Training Accuracy: 77.4230%, Training Loss: 0.5275%\n",
      "Epoch [42/300], Step [208/225], Training Accuracy: 77.4564%, Training Loss: 0.5269%\n",
      "Epoch [42/300], Step [209/225], Training Accuracy: 77.4821%, Training Loss: 0.5265%\n",
      "Epoch [42/300], Step [210/225], Training Accuracy: 77.4702%, Training Loss: 0.5269%\n",
      "Epoch [42/300], Step [211/225], Training Accuracy: 77.4437%, Training Loss: 0.5274%\n",
      "Epoch [42/300], Step [212/225], Training Accuracy: 77.4543%, Training Loss: 0.5269%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/300], Step [213/225], Training Accuracy: 77.4354%, Training Loss: 0.5271%\n",
      "Epoch [42/300], Step [214/225], Training Accuracy: 77.4825%, Training Loss: 0.5266%\n",
      "Epoch [42/300], Step [215/225], Training Accuracy: 77.4637%, Training Loss: 0.5272%\n",
      "Epoch [42/300], Step [216/225], Training Accuracy: 77.4595%, Training Loss: 0.5274%\n",
      "Epoch [42/300], Step [217/225], Training Accuracy: 77.4626%, Training Loss: 0.5275%\n",
      "Epoch [42/300], Step [218/225], Training Accuracy: 77.4656%, Training Loss: 0.5280%\n",
      "Epoch [42/300], Step [219/225], Training Accuracy: 77.4615%, Training Loss: 0.5280%\n",
      "Epoch [42/300], Step [220/225], Training Accuracy: 77.4929%, Training Loss: 0.5274%\n",
      "Epoch [42/300], Step [221/225], Training Accuracy: 77.5311%, Training Loss: 0.5268%\n",
      "Epoch [42/300], Step [222/225], Training Accuracy: 77.5408%, Training Loss: 0.5267%\n",
      "Epoch [42/300], Step [223/225], Training Accuracy: 77.5294%, Training Loss: 0.5272%\n",
      "Epoch [42/300], Step [224/225], Training Accuracy: 77.5391%, Training Loss: 0.5269%\n",
      "Epoch [42/300], Step [225/225], Training Accuracy: 77.5639%, Training Loss: 0.5262%\n",
      "Epoch [43/300], Step [1/225], Training Accuracy: 79.6875%, Training Loss: 0.4265%\n",
      "Epoch [43/300], Step [2/225], Training Accuracy: 79.6875%, Training Loss: 0.4451%\n",
      "Epoch [43/300], Step [3/225], Training Accuracy: 79.6875%, Training Loss: 0.4891%\n",
      "Epoch [43/300], Step [4/225], Training Accuracy: 78.9062%, Training Loss: 0.5078%\n",
      "Epoch [43/300], Step [5/225], Training Accuracy: 78.4375%, Training Loss: 0.4992%\n",
      "Epoch [43/300], Step [6/225], Training Accuracy: 79.1667%, Training Loss: 0.4838%\n",
      "Epoch [43/300], Step [7/225], Training Accuracy: 79.9107%, Training Loss: 0.4711%\n",
      "Epoch [43/300], Step [8/225], Training Accuracy: 78.7109%, Training Loss: 0.5026%\n",
      "Epoch [43/300], Step [9/225], Training Accuracy: 78.4722%, Training Loss: 0.5010%\n",
      "Epoch [43/300], Step [10/225], Training Accuracy: 77.8125%, Training Loss: 0.5158%\n",
      "Epoch [43/300], Step [11/225], Training Accuracy: 78.1250%, Training Loss: 0.5118%\n",
      "Epoch [43/300], Step [12/225], Training Accuracy: 78.5156%, Training Loss: 0.5066%\n",
      "Epoch [43/300], Step [13/225], Training Accuracy: 78.9663%, Training Loss: 0.4975%\n",
      "Epoch [43/300], Step [14/225], Training Accuracy: 78.7946%, Training Loss: 0.5027%\n",
      "Epoch [43/300], Step [15/225], Training Accuracy: 78.7500%, Training Loss: 0.5006%\n",
      "Epoch [43/300], Step [16/225], Training Accuracy: 78.0273%, Training Loss: 0.5089%\n",
      "Epoch [43/300], Step [17/225], Training Accuracy: 78.1250%, Training Loss: 0.5082%\n",
      "Epoch [43/300], Step [18/225], Training Accuracy: 78.2986%, Training Loss: 0.5027%\n",
      "Epoch [43/300], Step [19/225], Training Accuracy: 78.4539%, Training Loss: 0.4987%\n",
      "Epoch [43/300], Step [20/225], Training Accuracy: 78.5156%, Training Loss: 0.4958%\n",
      "Epoch [43/300], Step [21/225], Training Accuracy: 78.8690%, Training Loss: 0.4907%\n",
      "Epoch [43/300], Step [22/225], Training Accuracy: 78.6932%, Training Loss: 0.4935%\n",
      "Epoch [43/300], Step [23/225], Training Accuracy: 78.6005%, Training Loss: 0.4924%\n",
      "Epoch [43/300], Step [24/225], Training Accuracy: 78.7109%, Training Loss: 0.4910%\n",
      "Epoch [43/300], Step [25/225], Training Accuracy: 78.8125%, Training Loss: 0.4863%\n",
      "Epoch [43/300], Step [26/225], Training Accuracy: 78.8462%, Training Loss: 0.4866%\n",
      "Epoch [43/300], Step [27/225], Training Accuracy: 78.8194%, Training Loss: 0.4848%\n",
      "Epoch [43/300], Step [28/225], Training Accuracy: 79.2411%, Training Loss: 0.4775%\n",
      "Epoch [43/300], Step [29/225], Training Accuracy: 79.3103%, Training Loss: 0.4734%\n",
      "Epoch [43/300], Step [30/225], Training Accuracy: 79.3750%, Training Loss: 0.4759%\n",
      "Epoch [43/300], Step [31/225], Training Accuracy: 79.2339%, Training Loss: 0.4796%\n",
      "Epoch [43/300], Step [32/225], Training Accuracy: 79.0527%, Training Loss: 0.4821%\n",
      "Epoch [43/300], Step [33/225], Training Accuracy: 79.2140%, Training Loss: 0.4802%\n",
      "Epoch [43/300], Step [34/225], Training Accuracy: 78.9062%, Training Loss: 0.4892%\n",
      "Epoch [43/300], Step [35/225], Training Accuracy: 79.0179%, Training Loss: 0.4885%\n",
      "Epoch [43/300], Step [36/225], Training Accuracy: 78.7760%, Training Loss: 0.4950%\n",
      "Epoch [43/300], Step [37/225], Training Accuracy: 78.8429%, Training Loss: 0.4934%\n",
      "Epoch [43/300], Step [38/225], Training Accuracy: 78.7829%, Training Loss: 0.4916%\n",
      "Epoch [43/300], Step [39/225], Training Accuracy: 78.7260%, Training Loss: 0.4938%\n",
      "Epoch [43/300], Step [40/225], Training Accuracy: 78.7500%, Training Loss: 0.4921%\n",
      "Epoch [43/300], Step [41/225], Training Accuracy: 78.6204%, Training Loss: 0.4985%\n",
      "Epoch [43/300], Step [42/225], Training Accuracy: 78.6086%, Training Loss: 0.4994%\n",
      "Epoch [43/300], Step [43/225], Training Accuracy: 78.5974%, Training Loss: 0.5008%\n",
      "Epoch [43/300], Step [44/225], Training Accuracy: 78.5511%, Training Loss: 0.5002%\n",
      "Epoch [43/300], Step [45/225], Training Accuracy: 78.4722%, Training Loss: 0.5006%\n",
      "Epoch [43/300], Step [46/225], Training Accuracy: 78.5326%, Training Loss: 0.5011%\n",
      "Epoch [43/300], Step [47/225], Training Accuracy: 78.3910%, Training Loss: 0.5017%\n",
      "Epoch [43/300], Step [48/225], Training Accuracy: 78.2878%, Training Loss: 0.5023%\n",
      "Epoch [43/300], Step [49/225], Training Accuracy: 78.3801%, Training Loss: 0.5004%\n",
      "Epoch [43/300], Step [50/225], Training Accuracy: 78.3750%, Training Loss: 0.5028%\n",
      "Epoch [43/300], Step [51/225], Training Accuracy: 78.3395%, Training Loss: 0.5025%\n",
      "Epoch [43/300], Step [52/225], Training Accuracy: 78.4856%, Training Loss: 0.4986%\n",
      "Epoch [43/300], Step [53/225], Training Accuracy: 78.4198%, Training Loss: 0.5010%\n",
      "Epoch [43/300], Step [54/225], Training Accuracy: 78.2118%, Training Loss: 0.5055%\n",
      "Epoch [43/300], Step [55/225], Training Accuracy: 78.0398%, Training Loss: 0.5085%\n",
      "Epoch [43/300], Step [56/225], Training Accuracy: 78.0134%, Training Loss: 0.5090%\n",
      "Epoch [43/300], Step [57/225], Training Accuracy: 77.9605%, Training Loss: 0.5099%\n",
      "Epoch [43/300], Step [58/225], Training Accuracy: 77.9634%, Training Loss: 0.5104%\n",
      "Epoch [43/300], Step [59/225], Training Accuracy: 77.8337%, Training Loss: 0.5117%\n",
      "Epoch [43/300], Step [60/225], Training Accuracy: 77.8906%, Training Loss: 0.5097%\n",
      "Epoch [43/300], Step [61/225], Training Accuracy: 77.9713%, Training Loss: 0.5089%\n",
      "Epoch [43/300], Step [62/225], Training Accuracy: 78.0242%, Training Loss: 0.5080%\n",
      "Epoch [43/300], Step [63/225], Training Accuracy: 77.9266%, Training Loss: 0.5102%\n",
      "Epoch [43/300], Step [64/225], Training Accuracy: 78.0762%, Training Loss: 0.5072%\n",
      "Epoch [43/300], Step [65/225], Training Accuracy: 78.1490%, Training Loss: 0.5064%\n",
      "Epoch [43/300], Step [66/225], Training Accuracy: 78.1723%, Training Loss: 0.5050%\n",
      "Epoch [43/300], Step [67/225], Training Accuracy: 78.2416%, Training Loss: 0.5027%\n",
      "Epoch [43/300], Step [68/225], Training Accuracy: 78.3088%, Training Loss: 0.5015%\n",
      "Epoch [43/300], Step [69/225], Training Accuracy: 78.2835%, Training Loss: 0.5030%\n",
      "Epoch [43/300], Step [70/225], Training Accuracy: 78.2812%, Training Loss: 0.5033%\n",
      "Epoch [43/300], Step [71/225], Training Accuracy: 78.3011%, Training Loss: 0.5027%\n",
      "Epoch [43/300], Step [72/225], Training Accuracy: 78.3203%, Training Loss: 0.5027%\n",
      "Epoch [43/300], Step [73/225], Training Accuracy: 78.3390%, Training Loss: 0.5017%\n",
      "Epoch [43/300], Step [74/225], Training Accuracy: 78.4628%, Training Loss: 0.4991%\n",
      "Epoch [43/300], Step [75/225], Training Accuracy: 78.4583%, Training Loss: 0.4985%\n",
      "Epoch [43/300], Step [76/225], Training Accuracy: 78.4334%, Training Loss: 0.4991%\n",
      "Epoch [43/300], Step [77/225], Training Accuracy: 78.4497%, Training Loss: 0.5003%\n",
      "Epoch [43/300], Step [78/225], Training Accuracy: 78.4054%, Training Loss: 0.5016%\n",
      "Epoch [43/300], Step [79/225], Training Accuracy: 78.5008%, Training Loss: 0.5005%\n",
      "Epoch [43/300], Step [80/225], Training Accuracy: 78.5352%, Training Loss: 0.5003%\n",
      "Epoch [43/300], Step [81/225], Training Accuracy: 78.5108%, Training Loss: 0.5002%\n",
      "Epoch [43/300], Step [82/225], Training Accuracy: 78.5442%, Training Loss: 0.4998%\n",
      "Epoch [43/300], Step [83/225], Training Accuracy: 78.5580%, Training Loss: 0.5005%\n",
      "Epoch [43/300], Step [84/225], Training Accuracy: 78.6644%, Training Loss: 0.4989%\n",
      "Epoch [43/300], Step [85/225], Training Accuracy: 78.6949%, Training Loss: 0.4975%\n",
      "Epoch [43/300], Step [86/225], Training Accuracy: 78.7064%, Training Loss: 0.4979%\n",
      "Epoch [43/300], Step [87/225], Training Accuracy: 78.6997%, Training Loss: 0.4979%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/300], Step [88/225], Training Accuracy: 78.6044%, Training Loss: 0.5007%\n",
      "Epoch [43/300], Step [89/225], Training Accuracy: 78.6166%, Training Loss: 0.5005%\n",
      "Epoch [43/300], Step [90/225], Training Accuracy: 78.4549%, Training Loss: 0.5051%\n",
      "Epoch [43/300], Step [91/225], Training Accuracy: 78.5027%, Training Loss: 0.5045%\n",
      "Epoch [43/300], Step [92/225], Training Accuracy: 78.4477%, Training Loss: 0.5051%\n",
      "Epoch [43/300], Step [93/225], Training Accuracy: 78.5282%, Training Loss: 0.5036%\n",
      "Epoch [43/300], Step [94/225], Training Accuracy: 78.5406%, Training Loss: 0.5042%\n",
      "Epoch [43/300], Step [95/225], Training Accuracy: 78.4704%, Training Loss: 0.5045%\n",
      "Epoch [43/300], Step [96/225], Training Accuracy: 78.5645%, Training Loss: 0.5025%\n",
      "Epoch [43/300], Step [97/225], Training Accuracy: 78.5760%, Training Loss: 0.5022%\n",
      "Epoch [43/300], Step [98/225], Training Accuracy: 78.5714%, Training Loss: 0.5025%\n",
      "Epoch [43/300], Step [99/225], Training Accuracy: 78.5827%, Training Loss: 0.5028%\n",
      "Epoch [43/300], Step [100/225], Training Accuracy: 78.5938%, Training Loss: 0.5042%\n",
      "Epoch [43/300], Step [101/225], Training Accuracy: 78.6355%, Training Loss: 0.5039%\n",
      "Epoch [43/300], Step [102/225], Training Accuracy: 78.6458%, Training Loss: 0.5040%\n",
      "Epoch [43/300], Step [103/225], Training Accuracy: 78.6559%, Training Loss: 0.5036%\n",
      "Epoch [43/300], Step [104/225], Training Accuracy: 78.6809%, Training Loss: 0.5032%\n",
      "Epoch [43/300], Step [105/225], Training Accuracy: 78.7500%, Training Loss: 0.5018%\n",
      "Epoch [43/300], Step [106/225], Training Accuracy: 78.6409%, Training Loss: 0.5027%\n",
      "Epoch [43/300], Step [107/225], Training Accuracy: 78.6215%, Training Loss: 0.5034%\n",
      "Epoch [43/300], Step [108/225], Training Accuracy: 78.5880%, Training Loss: 0.5038%\n",
      "Epoch [43/300], Step [109/225], Training Accuracy: 78.5120%, Training Loss: 0.5061%\n",
      "Epoch [43/300], Step [110/225], Training Accuracy: 78.5227%, Training Loss: 0.5053%\n",
      "Epoch [43/300], Step [111/225], Training Accuracy: 78.5191%, Training Loss: 0.5060%\n",
      "Epoch [43/300], Step [112/225], Training Accuracy: 78.5575%, Training Loss: 0.5063%\n",
      "Epoch [43/300], Step [113/225], Training Accuracy: 78.5813%, Training Loss: 0.5060%\n",
      "Epoch [43/300], Step [114/225], Training Accuracy: 78.5636%, Training Loss: 0.5058%\n",
      "Epoch [43/300], Step [115/225], Training Accuracy: 78.5734%, Training Loss: 0.5063%\n",
      "Epoch [43/300], Step [116/225], Training Accuracy: 78.5830%, Training Loss: 0.5063%\n",
      "Epoch [43/300], Step [117/225], Training Accuracy: 78.5256%, Training Loss: 0.5063%\n",
      "Epoch [43/300], Step [118/225], Training Accuracy: 78.5355%, Training Loss: 0.5059%\n",
      "Epoch [43/300], Step [119/225], Training Accuracy: 78.5058%, Training Loss: 0.5057%\n",
      "Epoch [43/300], Step [120/225], Training Accuracy: 78.5677%, Training Loss: 0.5056%\n",
      "Epoch [43/300], Step [121/225], Training Accuracy: 78.5511%, Training Loss: 0.5057%\n",
      "Epoch [43/300], Step [122/225], Training Accuracy: 78.5605%, Training Loss: 0.5059%\n",
      "Epoch [43/300], Step [123/225], Training Accuracy: 78.5569%, Training Loss: 0.5059%\n",
      "Epoch [43/300], Step [124/225], Training Accuracy: 78.5534%, Training Loss: 0.5060%\n",
      "Epoch [43/300], Step [125/225], Training Accuracy: 78.5750%, Training Loss: 0.5053%\n",
      "Epoch [43/300], Step [126/225], Training Accuracy: 78.5590%, Training Loss: 0.5053%\n",
      "Epoch [43/300], Step [127/225], Training Accuracy: 78.5433%, Training Loss: 0.5053%\n",
      "Epoch [43/300], Step [128/225], Training Accuracy: 78.5889%, Training Loss: 0.5050%\n",
      "Epoch [43/300], Step [129/225], Training Accuracy: 78.6337%, Training Loss: 0.5046%\n",
      "Epoch [43/300], Step [130/225], Training Accuracy: 78.6058%, Training Loss: 0.5051%\n",
      "Epoch [43/300], Step [131/225], Training Accuracy: 78.5544%, Training Loss: 0.5066%\n",
      "Epoch [43/300], Step [132/225], Training Accuracy: 78.5511%, Training Loss: 0.5069%\n",
      "Epoch [43/300], Step [133/225], Training Accuracy: 78.5362%, Training Loss: 0.5067%\n",
      "Epoch [43/300], Step [134/225], Training Accuracy: 78.4282%, Training Loss: 0.5089%\n",
      "Epoch [43/300], Step [135/225], Training Accuracy: 78.4606%, Training Loss: 0.5084%\n",
      "Epoch [43/300], Step [136/225], Training Accuracy: 78.4237%, Training Loss: 0.5085%\n",
      "Epoch [43/300], Step [137/225], Training Accuracy: 78.4443%, Training Loss: 0.5085%\n",
      "Epoch [43/300], Step [138/225], Training Accuracy: 78.5326%, Training Loss: 0.5067%\n",
      "Epoch [43/300], Step [139/225], Training Accuracy: 78.5409%, Training Loss: 0.5070%\n",
      "Epoch [43/300], Step [140/225], Training Accuracy: 78.5156%, Training Loss: 0.5077%\n",
      "Epoch [43/300], Step [141/225], Training Accuracy: 78.5239%, Training Loss: 0.5078%\n",
      "Epoch [43/300], Step [142/225], Training Accuracy: 78.5431%, Training Loss: 0.5073%\n",
      "Epoch [43/300], Step [143/225], Training Accuracy: 78.5184%, Training Loss: 0.5072%\n",
      "Epoch [43/300], Step [144/225], Training Accuracy: 78.4505%, Training Loss: 0.5077%\n",
      "Epoch [43/300], Step [145/225], Training Accuracy: 78.4483%, Training Loss: 0.5081%\n",
      "Epoch [43/300], Step [146/225], Training Accuracy: 78.4568%, Training Loss: 0.5080%\n",
      "Epoch [43/300], Step [147/225], Training Accuracy: 78.4651%, Training Loss: 0.5082%\n",
      "Epoch [43/300], Step [148/225], Training Accuracy: 78.5473%, Training Loss: 0.5068%\n",
      "Epoch [43/300], Step [149/225], Training Accuracy: 78.5654%, Training Loss: 0.5065%\n",
      "Epoch [43/300], Step [150/225], Training Accuracy: 78.5625%, Training Loss: 0.5060%\n",
      "Epoch [43/300], Step [151/225], Training Accuracy: 78.6217%, Training Loss: 0.5050%\n",
      "Epoch [43/300], Step [152/225], Training Accuracy: 78.5876%, Training Loss: 0.5051%\n",
      "Epoch [43/300], Step [153/225], Training Accuracy: 78.6152%, Training Loss: 0.5044%\n",
      "Epoch [43/300], Step [154/225], Training Accuracy: 78.5613%, Training Loss: 0.5053%\n",
      "Epoch [43/300], Step [155/225], Training Accuracy: 78.6190%, Training Loss: 0.5045%\n",
      "Epoch [43/300], Step [156/225], Training Accuracy: 78.5757%, Training Loss: 0.5048%\n",
      "Epoch [43/300], Step [157/225], Training Accuracy: 78.5430%, Training Loss: 0.5051%\n",
      "Epoch [43/300], Step [158/225], Training Accuracy: 78.4810%, Training Loss: 0.5068%\n",
      "Epoch [43/300], Step [159/225], Training Accuracy: 78.4493%, Training Loss: 0.5073%\n",
      "Epoch [43/300], Step [160/225], Training Accuracy: 78.4180%, Training Loss: 0.5072%\n",
      "Epoch [43/300], Step [161/225], Training Accuracy: 78.3579%, Training Loss: 0.5078%\n",
      "Epoch [43/300], Step [162/225], Training Accuracy: 78.3661%, Training Loss: 0.5078%\n",
      "Epoch [43/300], Step [163/225], Training Accuracy: 78.3838%, Training Loss: 0.5077%\n",
      "Epoch [43/300], Step [164/225], Training Accuracy: 78.4108%, Training Loss: 0.5084%\n",
      "Epoch [43/300], Step [165/225], Training Accuracy: 78.4470%, Training Loss: 0.5079%\n",
      "Epoch [43/300], Step [166/225], Training Accuracy: 78.4733%, Training Loss: 0.5073%\n",
      "Epoch [43/300], Step [167/225], Training Accuracy: 78.4431%, Training Loss: 0.5078%\n",
      "Epoch [43/300], Step [168/225], Training Accuracy: 78.4598%, Training Loss: 0.5080%\n",
      "Epoch [43/300], Step [169/225], Training Accuracy: 78.4856%, Training Loss: 0.5074%\n",
      "Epoch [43/300], Step [170/225], Training Accuracy: 78.4743%, Training Loss: 0.5076%\n",
      "Epoch [43/300], Step [171/225], Training Accuracy: 78.4814%, Training Loss: 0.5076%\n",
      "Epoch [43/300], Step [172/225], Training Accuracy: 78.4611%, Training Loss: 0.5076%\n",
      "Epoch [43/300], Step [173/225], Training Accuracy: 78.4501%, Training Loss: 0.5080%\n",
      "Epoch [43/300], Step [174/225], Training Accuracy: 78.4662%, Training Loss: 0.5085%\n",
      "Epoch [43/300], Step [175/225], Training Accuracy: 78.4375%, Training Loss: 0.5087%\n",
      "Epoch [43/300], Step [176/225], Training Accuracy: 78.4801%, Training Loss: 0.5084%\n",
      "Epoch [43/300], Step [177/225], Training Accuracy: 78.4781%, Training Loss: 0.5083%\n",
      "Epoch [43/300], Step [178/225], Training Accuracy: 78.5025%, Training Loss: 0.5080%\n",
      "Epoch [43/300], Step [179/225], Training Accuracy: 78.5353%, Training Loss: 0.5069%\n",
      "Epoch [43/300], Step [180/225], Training Accuracy: 78.5590%, Training Loss: 0.5062%\n",
      "Epoch [43/300], Step [181/225], Training Accuracy: 78.5653%, Training Loss: 0.5061%\n",
      "Epoch [43/300], Step [182/225], Training Accuracy: 78.5972%, Training Loss: 0.5054%\n",
      "Epoch [43/300], Step [183/225], Training Accuracy: 78.5861%, Training Loss: 0.5051%\n",
      "Epoch [43/300], Step [184/225], Training Accuracy: 78.5921%, Training Loss: 0.5046%\n",
      "Epoch [43/300], Step [185/225], Training Accuracy: 78.5726%, Training Loss: 0.5049%\n",
      "Epoch [43/300], Step [186/225], Training Accuracy: 78.5198%, Training Loss: 0.5054%\n",
      "Epoch [43/300], Step [187/225], Training Accuracy: 78.5094%, Training Loss: 0.5052%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/300], Step [188/225], Training Accuracy: 78.5073%, Training Loss: 0.5047%\n",
      "Epoch [43/300], Step [189/225], Training Accuracy: 78.5136%, Training Loss: 0.5043%\n",
      "Epoch [43/300], Step [190/225], Training Accuracy: 78.5526%, Training Loss: 0.5037%\n",
      "Epoch [43/300], Step [191/225], Training Accuracy: 78.5422%, Training Loss: 0.5038%\n",
      "Epoch [43/300], Step [192/225], Training Accuracy: 78.5400%, Training Loss: 0.5039%\n",
      "Epoch [43/300], Step [193/225], Training Accuracy: 78.5298%, Training Loss: 0.5046%\n",
      "Epoch [43/300], Step [194/225], Training Accuracy: 78.5438%, Training Loss: 0.5043%\n",
      "Epoch [43/300], Step [195/225], Training Accuracy: 78.5817%, Training Loss: 0.5034%\n",
      "Epoch [43/300], Step [196/225], Training Accuracy: 78.5714%, Training Loss: 0.5039%\n",
      "Epoch [43/300], Step [197/225], Training Accuracy: 78.5374%, Training Loss: 0.5040%\n",
      "Epoch [43/300], Step [198/225], Training Accuracy: 78.5196%, Training Loss: 0.5045%\n",
      "Epoch [43/300], Step [199/225], Training Accuracy: 78.5726%, Training Loss: 0.5035%\n",
      "Epoch [43/300], Step [200/225], Training Accuracy: 78.5859%, Training Loss: 0.5034%\n",
      "Epoch [43/300], Step [201/225], Training Accuracy: 78.5681%, Training Loss: 0.5037%\n",
      "Epoch [43/300], Step [202/225], Training Accuracy: 78.6046%, Training Loss: 0.5030%\n",
      "Epoch [43/300], Step [203/225], Training Accuracy: 78.6407%, Training Loss: 0.5024%\n",
      "Epoch [43/300], Step [204/225], Training Accuracy: 78.6612%, Training Loss: 0.5023%\n",
      "Epoch [43/300], Step [205/225], Training Accuracy: 78.6662%, Training Loss: 0.5017%\n",
      "Epoch [43/300], Step [206/225], Training Accuracy: 78.6559%, Training Loss: 0.5019%\n",
      "Epoch [43/300], Step [207/225], Training Accuracy: 78.6987%, Training Loss: 0.5014%\n",
      "Epoch [43/300], Step [208/225], Training Accuracy: 78.6884%, Training Loss: 0.5015%\n",
      "Epoch [43/300], Step [209/225], Training Accuracy: 78.6857%, Training Loss: 0.5020%\n",
      "Epoch [43/300], Step [210/225], Training Accuracy: 78.6756%, Training Loss: 0.5022%\n",
      "Epoch [43/300], Step [211/225], Training Accuracy: 78.6730%, Training Loss: 0.5019%\n",
      "Epoch [43/300], Step [212/225], Training Accuracy: 78.6557%, Training Loss: 0.5022%\n",
      "Epoch [43/300], Step [213/225], Training Accuracy: 78.6532%, Training Loss: 0.5023%\n",
      "Epoch [43/300], Step [214/225], Training Accuracy: 78.6434%, Training Loss: 0.5021%\n",
      "Epoch [43/300], Step [215/225], Training Accuracy: 78.6192%, Training Loss: 0.5022%\n",
      "Epoch [43/300], Step [216/225], Training Accuracy: 78.6097%, Training Loss: 0.5025%\n",
      "Epoch [43/300], Step [217/225], Training Accuracy: 78.6146%, Training Loss: 0.5025%\n",
      "Epoch [43/300], Step [218/225], Training Accuracy: 78.5765%, Training Loss: 0.5032%\n",
      "Epoch [43/300], Step [219/225], Training Accuracy: 78.5531%, Training Loss: 0.5037%\n",
      "Epoch [43/300], Step [220/225], Training Accuracy: 78.5795%, Training Loss: 0.5030%\n",
      "Epoch [43/300], Step [221/225], Training Accuracy: 78.5987%, Training Loss: 0.5026%\n",
      "Epoch [43/300], Step [222/225], Training Accuracy: 78.6106%, Training Loss: 0.5028%\n",
      "Epoch [43/300], Step [223/225], Training Accuracy: 78.6155%, Training Loss: 0.5025%\n",
      "Epoch [43/300], Step [224/225], Training Accuracy: 78.6342%, Training Loss: 0.5020%\n",
      "Epoch [43/300], Step [225/225], Training Accuracy: 78.6548%, Training Loss: 0.5011%\n",
      "Epoch [44/300], Step [1/225], Training Accuracy: 82.8125%, Training Loss: 0.3805%\n",
      "Epoch [44/300], Step [2/225], Training Accuracy: 80.4688%, Training Loss: 0.4529%\n",
      "Epoch [44/300], Step [3/225], Training Accuracy: 79.6875%, Training Loss: 0.4538%\n",
      "Epoch [44/300], Step [4/225], Training Accuracy: 80.0781%, Training Loss: 0.4583%\n",
      "Epoch [44/300], Step [5/225], Training Accuracy: 81.8750%, Training Loss: 0.4458%\n",
      "Epoch [44/300], Step [6/225], Training Accuracy: 81.5104%, Training Loss: 0.4452%\n",
      "Epoch [44/300], Step [7/225], Training Accuracy: 80.8036%, Training Loss: 0.4748%\n",
      "Epoch [44/300], Step [8/225], Training Accuracy: 79.2969%, Training Loss: 0.4959%\n",
      "Epoch [44/300], Step [9/225], Training Accuracy: 79.6875%, Training Loss: 0.4882%\n",
      "Epoch [44/300], Step [10/225], Training Accuracy: 79.2188%, Training Loss: 0.5058%\n",
      "Epoch [44/300], Step [11/225], Training Accuracy: 79.4034%, Training Loss: 0.5090%\n",
      "Epoch [44/300], Step [12/225], Training Accuracy: 79.8177%, Training Loss: 0.4985%\n",
      "Epoch [44/300], Step [13/225], Training Accuracy: 80.1683%, Training Loss: 0.4935%\n",
      "Epoch [44/300], Step [14/225], Training Accuracy: 80.6920%, Training Loss: 0.4868%\n",
      "Epoch [44/300], Step [15/225], Training Accuracy: 80.7292%, Training Loss: 0.4853%\n",
      "Epoch [44/300], Step [16/225], Training Accuracy: 80.6641%, Training Loss: 0.4855%\n",
      "Epoch [44/300], Step [17/225], Training Accuracy: 81.1581%, Training Loss: 0.4814%\n",
      "Epoch [44/300], Step [18/225], Training Accuracy: 81.5972%, Training Loss: 0.4751%\n",
      "Epoch [44/300], Step [19/225], Training Accuracy: 81.5789%, Training Loss: 0.4687%\n",
      "Epoch [44/300], Step [20/225], Training Accuracy: 81.6406%, Training Loss: 0.4610%\n",
      "Epoch [44/300], Step [21/225], Training Accuracy: 81.7708%, Training Loss: 0.4576%\n",
      "Epoch [44/300], Step [22/225], Training Accuracy: 81.3210%, Training Loss: 0.4660%\n",
      "Epoch [44/300], Step [23/225], Training Accuracy: 81.5217%, Training Loss: 0.4658%\n",
      "Epoch [44/300], Step [24/225], Training Accuracy: 81.1198%, Training Loss: 0.4718%\n",
      "Epoch [44/300], Step [25/225], Training Accuracy: 81.3125%, Training Loss: 0.4664%\n",
      "Epoch [44/300], Step [26/225], Training Accuracy: 81.2500%, Training Loss: 0.4649%\n",
      "Epoch [44/300], Step [27/225], Training Accuracy: 81.1921%, Training Loss: 0.4635%\n",
      "Epoch [44/300], Step [28/225], Training Accuracy: 81.1942%, Training Loss: 0.4655%\n",
      "Epoch [44/300], Step [29/225], Training Accuracy: 81.4116%, Training Loss: 0.4629%\n",
      "Epoch [44/300], Step [30/225], Training Accuracy: 81.4062%, Training Loss: 0.4618%\n",
      "Epoch [44/300], Step [31/225], Training Accuracy: 81.1492%, Training Loss: 0.4660%\n",
      "Epoch [44/300], Step [32/225], Training Accuracy: 81.3965%, Training Loss: 0.4601%\n",
      "Epoch [44/300], Step [33/225], Training Accuracy: 81.4394%, Training Loss: 0.4600%\n",
      "Epoch [44/300], Step [34/225], Training Accuracy: 81.0202%, Training Loss: 0.4724%\n",
      "Epoch [44/300], Step [35/225], Training Accuracy: 80.8482%, Training Loss: 0.4741%\n",
      "Epoch [44/300], Step [36/225], Training Accuracy: 80.8160%, Training Loss: 0.4755%\n",
      "Epoch [44/300], Step [37/225], Training Accuracy: 80.8277%, Training Loss: 0.4738%\n",
      "Epoch [44/300], Step [38/225], Training Accuracy: 80.6332%, Training Loss: 0.4769%\n",
      "Epoch [44/300], Step [39/225], Training Accuracy: 80.4087%, Training Loss: 0.4787%\n",
      "Epoch [44/300], Step [40/225], Training Accuracy: 80.3125%, Training Loss: 0.4810%\n",
      "Epoch [44/300], Step [41/225], Training Accuracy: 79.9924%, Training Loss: 0.4859%\n",
      "Epoch [44/300], Step [42/225], Training Accuracy: 79.7247%, Training Loss: 0.4902%\n",
      "Epoch [44/300], Step [43/225], Training Accuracy: 79.5422%, Training Loss: 0.4926%\n",
      "Epoch [44/300], Step [44/225], Training Accuracy: 79.4744%, Training Loss: 0.4932%\n",
      "Epoch [44/300], Step [45/225], Training Accuracy: 79.3403%, Training Loss: 0.4943%\n",
      "Epoch [44/300], Step [46/225], Training Accuracy: 79.4158%, Training Loss: 0.4937%\n",
      "Epoch [44/300], Step [47/225], Training Accuracy: 79.3551%, Training Loss: 0.4944%\n",
      "Epoch [44/300], Step [48/225], Training Accuracy: 79.2643%, Training Loss: 0.4960%\n",
      "Epoch [44/300], Step [49/225], Training Accuracy: 79.3048%, Training Loss: 0.4947%\n",
      "Epoch [44/300], Step [50/225], Training Accuracy: 79.2812%, Training Loss: 0.4952%\n",
      "Epoch [44/300], Step [51/225], Training Accuracy: 79.3505%, Training Loss: 0.4943%\n",
      "Epoch [44/300], Step [52/225], Training Accuracy: 79.4171%, Training Loss: 0.4928%\n",
      "Epoch [44/300], Step [53/225], Training Accuracy: 79.4811%, Training Loss: 0.4918%\n",
      "Epoch [44/300], Step [54/225], Training Accuracy: 79.3981%, Training Loss: 0.4932%\n",
      "Epoch [44/300], Step [55/225], Training Accuracy: 79.3466%, Training Loss: 0.4943%\n",
      "Epoch [44/300], Step [56/225], Training Accuracy: 79.3248%, Training Loss: 0.4943%\n",
      "Epoch [44/300], Step [57/225], Training Accuracy: 79.1941%, Training Loss: 0.4974%\n",
      "Epoch [44/300], Step [58/225], Training Accuracy: 78.9332%, Training Loss: 0.4990%\n",
      "Epoch [44/300], Step [59/225], Training Accuracy: 78.8400%, Training Loss: 0.5005%\n",
      "Epoch [44/300], Step [60/225], Training Accuracy: 78.9844%, Training Loss: 0.4983%\n",
      "Epoch [44/300], Step [61/225], Training Accuracy: 78.9959%, Training Loss: 0.4969%\n",
      "Epoch [44/300], Step [62/225], Training Accuracy: 79.1079%, Training Loss: 0.4948%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/300], Step [63/225], Training Accuracy: 79.1171%, Training Loss: 0.4954%\n",
      "Epoch [44/300], Step [64/225], Training Accuracy: 79.1504%, Training Loss: 0.4939%\n",
      "Epoch [44/300], Step [65/225], Training Accuracy: 79.2308%, Training Loss: 0.4928%\n",
      "Epoch [44/300], Step [66/225], Training Accuracy: 79.1430%, Training Loss: 0.4968%\n",
      "Epoch [44/300], Step [67/225], Training Accuracy: 79.1278%, Training Loss: 0.4967%\n",
      "Epoch [44/300], Step [68/225], Training Accuracy: 79.2050%, Training Loss: 0.4965%\n",
      "Epoch [44/300], Step [69/225], Training Accuracy: 79.2346%, Training Loss: 0.4962%\n",
      "Epoch [44/300], Step [70/225], Training Accuracy: 79.1071%, Training Loss: 0.4990%\n",
      "Epoch [44/300], Step [71/225], Training Accuracy: 79.0713%, Training Loss: 0.4986%\n",
      "Epoch [44/300], Step [72/225], Training Accuracy: 79.0148%, Training Loss: 0.4993%\n",
      "Epoch [44/300], Step [73/225], Training Accuracy: 78.9170%, Training Loss: 0.4996%\n",
      "Epoch [44/300], Step [74/225], Training Accuracy: 78.8851%, Training Loss: 0.5002%\n",
      "Epoch [44/300], Step [75/225], Training Accuracy: 78.8958%, Training Loss: 0.5003%\n",
      "Epoch [44/300], Step [76/225], Training Accuracy: 78.8651%, Training Loss: 0.5014%\n",
      "Epoch [44/300], Step [77/225], Training Accuracy: 78.8758%, Training Loss: 0.5012%\n",
      "Epoch [44/300], Step [78/225], Training Accuracy: 78.9463%, Training Loss: 0.4996%\n",
      "Epoch [44/300], Step [79/225], Training Accuracy: 79.0348%, Training Loss: 0.4977%\n",
      "Epoch [44/300], Step [80/225], Training Accuracy: 79.0039%, Training Loss: 0.4985%\n",
      "Epoch [44/300], Step [81/225], Training Accuracy: 79.0702%, Training Loss: 0.4968%\n",
      "Epoch [44/300], Step [82/225], Training Accuracy: 79.1540%, Training Loss: 0.4960%\n",
      "Epoch [44/300], Step [83/225], Training Accuracy: 79.0474%, Training Loss: 0.4971%\n",
      "Epoch [44/300], Step [84/225], Training Accuracy: 79.0923%, Training Loss: 0.4956%\n",
      "Epoch [44/300], Step [85/225], Training Accuracy: 79.0257%, Training Loss: 0.4976%\n",
      "Epoch [44/300], Step [86/225], Training Accuracy: 79.0516%, Training Loss: 0.4964%\n",
      "Epoch [44/300], Step [87/225], Training Accuracy: 79.0409%, Training Loss: 0.4960%\n",
      "Epoch [44/300], Step [88/225], Training Accuracy: 78.9595%, Training Loss: 0.4972%\n",
      "Epoch [44/300], Step [89/225], Training Accuracy: 79.0730%, Training Loss: 0.4960%\n",
      "Epoch [44/300], Step [90/225], Training Accuracy: 79.0625%, Training Loss: 0.4968%\n",
      "Epoch [44/300], Step [91/225], Training Accuracy: 79.0865%, Training Loss: 0.4970%\n",
      "Epoch [44/300], Step [92/225], Training Accuracy: 79.0421%, Training Loss: 0.4986%\n",
      "Epoch [44/300], Step [93/225], Training Accuracy: 79.1331%, Training Loss: 0.4968%\n",
      "Epoch [44/300], Step [94/225], Training Accuracy: 79.1390%, Training Loss: 0.4964%\n",
      "Epoch [44/300], Step [95/225], Training Accuracy: 79.0461%, Training Loss: 0.4993%\n",
      "Epoch [44/300], Step [96/225], Training Accuracy: 79.1178%, Training Loss: 0.4986%\n",
      "Epoch [44/300], Step [97/225], Training Accuracy: 79.1076%, Training Loss: 0.4988%\n",
      "Epoch [44/300], Step [98/225], Training Accuracy: 79.1614%, Training Loss: 0.4973%\n",
      "Epoch [44/300], Step [99/225], Training Accuracy: 79.1509%, Training Loss: 0.4974%\n",
      "Epoch [44/300], Step [100/225], Training Accuracy: 79.1094%, Training Loss: 0.4980%\n",
      "Epoch [44/300], Step [101/225], Training Accuracy: 79.0532%, Training Loss: 0.4988%\n",
      "Epoch [44/300], Step [102/225], Training Accuracy: 79.1207%, Training Loss: 0.4984%\n",
      "Epoch [44/300], Step [103/225], Training Accuracy: 79.0655%, Training Loss: 0.4981%\n",
      "Epoch [44/300], Step [104/225], Training Accuracy: 79.1016%, Training Loss: 0.4972%\n",
      "Epoch [44/300], Step [105/225], Training Accuracy: 79.0923%, Training Loss: 0.4966%\n",
      "Epoch [44/300], Step [106/225], Training Accuracy: 79.1126%, Training Loss: 0.4968%\n",
      "Epoch [44/300], Step [107/225], Training Accuracy: 79.1180%, Training Loss: 0.4978%\n",
      "Epoch [44/300], Step [108/225], Training Accuracy: 79.1377%, Training Loss: 0.4991%\n",
      "Epoch [44/300], Step [109/225], Training Accuracy: 79.0711%, Training Loss: 0.4998%\n",
      "Epoch [44/300], Step [110/225], Training Accuracy: 79.1619%, Training Loss: 0.4984%\n",
      "Epoch [44/300], Step [111/225], Training Accuracy: 79.1104%, Training Loss: 0.4990%\n",
      "Epoch [44/300], Step [112/225], Training Accuracy: 79.1434%, Training Loss: 0.4986%\n",
      "Epoch [44/300], Step [113/225], Training Accuracy: 79.1482%, Training Loss: 0.4983%\n",
      "Epoch [44/300], Step [114/225], Training Accuracy: 79.1530%, Training Loss: 0.4979%\n",
      "Epoch [44/300], Step [115/225], Training Accuracy: 79.2527%, Training Loss: 0.4965%\n",
      "Epoch [44/300], Step [116/225], Training Accuracy: 79.2834%, Training Loss: 0.4959%\n",
      "Epoch [44/300], Step [117/225], Training Accuracy: 79.2735%, Training Loss: 0.4961%\n",
      "Epoch [44/300], Step [118/225], Training Accuracy: 79.3829%, Training Loss: 0.4944%\n",
      "Epoch [44/300], Step [119/225], Training Accuracy: 79.3724%, Training Loss: 0.4946%\n",
      "Epoch [44/300], Step [120/225], Training Accuracy: 79.3229%, Training Loss: 0.4952%\n",
      "Epoch [44/300], Step [121/225], Training Accuracy: 79.3647%, Training Loss: 0.4950%\n",
      "Epoch [44/300], Step [122/225], Training Accuracy: 79.3161%, Training Loss: 0.4954%\n",
      "Epoch [44/300], Step [123/225], Training Accuracy: 79.2810%, Training Loss: 0.4953%\n",
      "Epoch [44/300], Step [124/225], Training Accuracy: 79.2843%, Training Loss: 0.4953%\n",
      "Epoch [44/300], Step [125/225], Training Accuracy: 79.3125%, Training Loss: 0.4946%\n",
      "Epoch [44/300], Step [126/225], Training Accuracy: 79.2907%, Training Loss: 0.4963%\n",
      "Epoch [44/300], Step [127/225], Training Accuracy: 79.2938%, Training Loss: 0.4969%\n",
      "Epoch [44/300], Step [128/225], Training Accuracy: 79.2969%, Training Loss: 0.4972%\n",
      "Epoch [44/300], Step [129/225], Training Accuracy: 79.3120%, Training Loss: 0.4969%\n",
      "Epoch [44/300], Step [130/225], Training Accuracy: 79.2308%, Training Loss: 0.4977%\n",
      "Epoch [44/300], Step [131/225], Training Accuracy: 79.2223%, Training Loss: 0.4976%\n",
      "Epoch [44/300], Step [132/225], Training Accuracy: 79.2259%, Training Loss: 0.4977%\n",
      "Epoch [44/300], Step [133/225], Training Accuracy: 79.2058%, Training Loss: 0.4981%\n",
      "Epoch [44/300], Step [134/225], Training Accuracy: 79.1511%, Training Loss: 0.4987%\n",
      "Epoch [44/300], Step [135/225], Training Accuracy: 79.1782%, Training Loss: 0.4987%\n",
      "Epoch [44/300], Step [136/225], Training Accuracy: 79.2050%, Training Loss: 0.4981%\n",
      "Epoch [44/300], Step [137/225], Training Accuracy: 79.2199%, Training Loss: 0.4975%\n",
      "Epoch [44/300], Step [138/225], Training Accuracy: 79.3025%, Training Loss: 0.4959%\n",
      "Epoch [44/300], Step [139/225], Training Accuracy: 79.3165%, Training Loss: 0.4955%\n",
      "Epoch [44/300], Step [140/225], Training Accuracy: 79.3527%, Training Loss: 0.4951%\n",
      "Epoch [44/300], Step [141/225], Training Accuracy: 79.2886%, Training Loss: 0.4955%\n",
      "Epoch [44/300], Step [142/225], Training Accuracy: 79.2364%, Training Loss: 0.4963%\n",
      "Epoch [44/300], Step [143/225], Training Accuracy: 79.1630%, Training Loss: 0.4976%\n",
      "Epoch [44/300], Step [144/225], Training Accuracy: 79.1884%, Training Loss: 0.4971%\n",
      "Epoch [44/300], Step [145/225], Training Accuracy: 79.1595%, Training Loss: 0.4974%\n",
      "Epoch [44/300], Step [146/225], Training Accuracy: 79.2166%, Training Loss: 0.4964%\n",
      "Epoch [44/300], Step [147/225], Training Accuracy: 79.2517%, Training Loss: 0.4960%\n",
      "Epoch [44/300], Step [148/225], Training Accuracy: 79.2758%, Training Loss: 0.4959%\n",
      "Epoch [44/300], Step [149/225], Training Accuracy: 79.2995%, Training Loss: 0.4954%\n",
      "Epoch [44/300], Step [150/225], Training Accuracy: 79.3333%, Training Loss: 0.4955%\n",
      "Epoch [44/300], Step [151/225], Training Accuracy: 79.2943%, Training Loss: 0.4954%\n",
      "Epoch [44/300], Step [152/225], Training Accuracy: 79.3072%, Training Loss: 0.4952%\n",
      "Epoch [44/300], Step [153/225], Training Accuracy: 79.3096%, Training Loss: 0.4953%\n",
      "Epoch [44/300], Step [154/225], Training Accuracy: 79.2918%, Training Loss: 0.4953%\n",
      "Epoch [44/300], Step [155/225], Training Accuracy: 79.2742%, Training Loss: 0.4953%\n",
      "Epoch [44/300], Step [156/225], Training Accuracy: 79.2468%, Training Loss: 0.4964%\n",
      "Epoch [44/300], Step [157/225], Training Accuracy: 79.2795%, Training Loss: 0.4956%\n",
      "Epoch [44/300], Step [158/225], Training Accuracy: 79.3018%, Training Loss: 0.4958%\n",
      "Epoch [44/300], Step [159/225], Training Accuracy: 79.2748%, Training Loss: 0.4959%\n",
      "Epoch [44/300], Step [160/225], Training Accuracy: 79.3066%, Training Loss: 0.4953%\n",
      "Epoch [44/300], Step [161/225], Training Accuracy: 79.2993%, Training Loss: 0.4954%\n",
      "Epoch [44/300], Step [162/225], Training Accuracy: 79.3210%, Training Loss: 0.4948%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/300], Step [163/225], Training Accuracy: 79.3232%, Training Loss: 0.4945%\n",
      "Epoch [44/300], Step [164/225], Training Accuracy: 79.2969%, Training Loss: 0.4949%\n",
      "Epoch [44/300], Step [165/225], Training Accuracy: 79.2992%, Training Loss: 0.4947%\n",
      "Epoch [44/300], Step [166/225], Training Accuracy: 79.2545%, Training Loss: 0.4956%\n",
      "Epoch [44/300], Step [167/225], Training Accuracy: 79.2384%, Training Loss: 0.4956%\n",
      "Epoch [44/300], Step [168/225], Training Accuracy: 79.2504%, Training Loss: 0.4956%\n",
      "Epoch [44/300], Step [169/225], Training Accuracy: 79.2714%, Training Loss: 0.4951%\n",
      "Epoch [44/300], Step [170/225], Training Accuracy: 79.2096%, Training Loss: 0.4970%\n",
      "Epoch [44/300], Step [171/225], Training Accuracy: 79.1849%, Training Loss: 0.4977%\n",
      "Epoch [44/300], Step [172/225], Training Accuracy: 79.1697%, Training Loss: 0.4985%\n",
      "Epoch [44/300], Step [173/225], Training Accuracy: 79.2088%, Training Loss: 0.4982%\n",
      "Epoch [44/300], Step [174/225], Training Accuracy: 79.2295%, Training Loss: 0.4977%\n",
      "Epoch [44/300], Step [175/225], Training Accuracy: 79.2321%, Training Loss: 0.4974%\n",
      "Epoch [44/300], Step [176/225], Training Accuracy: 79.2259%, Training Loss: 0.4974%\n",
      "Epoch [44/300], Step [177/225], Training Accuracy: 79.2020%, Training Loss: 0.4976%\n",
      "Epoch [44/300], Step [178/225], Training Accuracy: 79.1871%, Training Loss: 0.4978%\n",
      "Epoch [44/300], Step [179/225], Training Accuracy: 79.2074%, Training Loss: 0.4977%\n",
      "Epoch [44/300], Step [180/225], Training Accuracy: 79.2101%, Training Loss: 0.4977%\n",
      "Epoch [44/300], Step [181/225], Training Accuracy: 79.2127%, Training Loss: 0.4979%\n",
      "Epoch [44/300], Step [182/225], Training Accuracy: 79.1896%, Training Loss: 0.4981%\n",
      "Epoch [44/300], Step [183/225], Training Accuracy: 79.1837%, Training Loss: 0.4982%\n",
      "Epoch [44/300], Step [184/225], Training Accuracy: 79.2289%, Training Loss: 0.4975%\n",
      "Epoch [44/300], Step [185/225], Training Accuracy: 79.2061%, Training Loss: 0.4983%\n",
      "Epoch [44/300], Step [186/225], Training Accuracy: 79.2759%, Training Loss: 0.4968%\n",
      "Epoch [44/300], Step [187/225], Training Accuracy: 79.2279%, Training Loss: 0.4968%\n",
      "Epoch [44/300], Step [188/225], Training Accuracy: 79.2553%, Training Loss: 0.4962%\n",
      "Epoch [44/300], Step [189/225], Training Accuracy: 79.2411%, Training Loss: 0.4962%\n",
      "Epoch [44/300], Step [190/225], Training Accuracy: 79.2763%, Training Loss: 0.4953%\n",
      "Epoch [44/300], Step [191/225], Training Accuracy: 79.3276%, Training Loss: 0.4948%\n",
      "Epoch [44/300], Step [192/225], Training Accuracy: 79.3864%, Training Loss: 0.4942%\n",
      "Epoch [44/300], Step [193/225], Training Accuracy: 79.4284%, Training Loss: 0.4937%\n",
      "Epoch [44/300], Step [194/225], Training Accuracy: 79.4137%, Training Loss: 0.4935%\n",
      "Epoch [44/300], Step [195/225], Training Accuracy: 79.4471%, Training Loss: 0.4932%\n",
      "Epoch [44/300], Step [196/225], Training Accuracy: 79.4085%, Training Loss: 0.4933%\n",
      "Epoch [44/300], Step [197/225], Training Accuracy: 79.4337%, Training Loss: 0.4930%\n",
      "Epoch [44/300], Step [198/225], Training Accuracy: 79.4429%, Training Loss: 0.4927%\n",
      "Epoch [44/300], Step [199/225], Training Accuracy: 79.4519%, Training Loss: 0.4920%\n",
      "Epoch [44/300], Step [200/225], Training Accuracy: 79.4453%, Training Loss: 0.4920%\n",
      "Epoch [44/300], Step [201/225], Training Accuracy: 79.4698%, Training Loss: 0.4921%\n",
      "Epoch [44/300], Step [202/225], Training Accuracy: 79.4554%, Training Loss: 0.4924%\n",
      "Epoch [44/300], Step [203/225], Training Accuracy: 79.4720%, Training Loss: 0.4919%\n",
      "Epoch [44/300], Step [204/225], Training Accuracy: 79.4654%, Training Loss: 0.4920%\n",
      "Epoch [44/300], Step [205/225], Training Accuracy: 79.5046%, Training Loss: 0.4915%\n",
      "Epoch [44/300], Step [206/225], Training Accuracy: 79.4751%, Training Loss: 0.4919%\n",
      "Epoch [44/300], Step [207/225], Training Accuracy: 79.4837%, Training Loss: 0.4921%\n",
      "Epoch [44/300], Step [208/225], Training Accuracy: 79.5222%, Training Loss: 0.4914%\n",
      "Epoch [44/300], Step [209/225], Training Accuracy: 79.5006%, Training Loss: 0.4917%\n",
      "Epoch [44/300], Step [210/225], Training Accuracy: 79.4717%, Training Loss: 0.4917%\n",
      "Epoch [44/300], Step [211/225], Training Accuracy: 79.4802%, Training Loss: 0.4920%\n",
      "Epoch [44/300], Step [212/225], Training Accuracy: 79.4885%, Training Loss: 0.4922%\n",
      "Epoch [44/300], Step [213/225], Training Accuracy: 79.5114%, Training Loss: 0.4919%\n",
      "Epoch [44/300], Step [214/225], Training Accuracy: 79.5196%, Training Loss: 0.4917%\n",
      "Epoch [44/300], Step [215/225], Training Accuracy: 79.5131%, Training Loss: 0.4916%\n",
      "Epoch [44/300], Step [216/225], Training Accuracy: 79.5067%, Training Loss: 0.4919%\n",
      "Epoch [44/300], Step [217/225], Training Accuracy: 79.5147%, Training Loss: 0.4916%\n",
      "Epoch [44/300], Step [218/225], Training Accuracy: 79.5011%, Training Loss: 0.4921%\n",
      "Epoch [44/300], Step [219/225], Training Accuracy: 79.4735%, Training Loss: 0.4925%\n",
      "Epoch [44/300], Step [220/225], Training Accuracy: 79.4957%, Training Loss: 0.4920%\n",
      "Epoch [44/300], Step [221/225], Training Accuracy: 79.5037%, Training Loss: 0.4914%\n",
      "Epoch [44/300], Step [222/225], Training Accuracy: 79.4975%, Training Loss: 0.4918%\n",
      "Epoch [44/300], Step [223/225], Training Accuracy: 79.4773%, Training Loss: 0.4924%\n",
      "Epoch [44/300], Step [224/225], Training Accuracy: 79.4713%, Training Loss: 0.4920%\n",
      "Epoch [44/300], Step [225/225], Training Accuracy: 79.4886%, Training Loss: 0.4914%\n",
      "Epoch [45/300], Step [1/225], Training Accuracy: 78.1250%, Training Loss: 0.4737%\n",
      "Epoch [45/300], Step [2/225], Training Accuracy: 80.4688%, Training Loss: 0.4589%\n",
      "Epoch [45/300], Step [3/225], Training Accuracy: 78.6458%, Training Loss: 0.4682%\n",
      "Epoch [45/300], Step [4/225], Training Accuracy: 78.1250%, Training Loss: 0.4899%\n",
      "Epoch [45/300], Step [5/225], Training Accuracy: 78.1250%, Training Loss: 0.4822%\n",
      "Epoch [45/300], Step [6/225], Training Accuracy: 78.6458%, Training Loss: 0.4877%\n",
      "Epoch [45/300], Step [7/225], Training Accuracy: 79.2411%, Training Loss: 0.4803%\n",
      "Epoch [45/300], Step [8/225], Training Accuracy: 78.9062%, Training Loss: 0.4836%\n",
      "Epoch [45/300], Step [9/225], Training Accuracy: 79.1667%, Training Loss: 0.4786%\n",
      "Epoch [45/300], Step [10/225], Training Accuracy: 79.6875%, Training Loss: 0.4760%\n",
      "Epoch [45/300], Step [11/225], Training Accuracy: 79.1193%, Training Loss: 0.4830%\n",
      "Epoch [45/300], Step [12/225], Training Accuracy: 78.6458%, Training Loss: 0.4935%\n",
      "Epoch [45/300], Step [13/225], Training Accuracy: 78.8462%, Training Loss: 0.4821%\n",
      "Epoch [45/300], Step [14/225], Training Accuracy: 79.0179%, Training Loss: 0.4817%\n",
      "Epoch [45/300], Step [15/225], Training Accuracy: 79.0625%, Training Loss: 0.4770%\n",
      "Epoch [45/300], Step [16/225], Training Accuracy: 79.0039%, Training Loss: 0.4740%\n",
      "Epoch [45/300], Step [17/225], Training Accuracy: 78.4926%, Training Loss: 0.4807%\n",
      "Epoch [45/300], Step [18/225], Training Accuracy: 78.4722%, Training Loss: 0.4773%\n",
      "Epoch [45/300], Step [19/225], Training Accuracy: 78.6184%, Training Loss: 0.4723%\n",
      "Epoch [45/300], Step [20/225], Training Accuracy: 78.6719%, Training Loss: 0.4687%\n",
      "Epoch [45/300], Step [21/225], Training Accuracy: 78.9435%, Training Loss: 0.4631%\n",
      "Epoch [45/300], Step [22/225], Training Accuracy: 78.6222%, Training Loss: 0.4723%\n",
      "Epoch [45/300], Step [23/225], Training Accuracy: 78.4647%, Training Loss: 0.4758%\n",
      "Epoch [45/300], Step [24/225], Training Accuracy: 78.5807%, Training Loss: 0.4760%\n",
      "Epoch [45/300], Step [25/225], Training Accuracy: 78.6875%, Training Loss: 0.4752%\n",
      "Epoch [45/300], Step [26/225], Training Accuracy: 78.9062%, Training Loss: 0.4721%\n",
      "Epoch [45/300], Step [27/225], Training Accuracy: 79.0509%, Training Loss: 0.4702%\n",
      "Epoch [45/300], Step [28/225], Training Accuracy: 79.0737%, Training Loss: 0.4689%\n",
      "Epoch [45/300], Step [29/225], Training Accuracy: 78.9871%, Training Loss: 0.4674%\n",
      "Epoch [45/300], Step [30/225], Training Accuracy: 79.2188%, Training Loss: 0.4631%\n",
      "Epoch [45/300], Step [31/225], Training Accuracy: 79.1835%, Training Loss: 0.4626%\n",
      "Epoch [45/300], Step [32/225], Training Accuracy: 79.3457%, Training Loss: 0.4619%\n",
      "Epoch [45/300], Step [33/225], Training Accuracy: 79.4981%, Training Loss: 0.4594%\n",
      "Epoch [45/300], Step [34/225], Training Accuracy: 79.1820%, Training Loss: 0.4696%\n",
      "Epoch [45/300], Step [35/225], Training Accuracy: 79.0625%, Training Loss: 0.4679%\n",
      "Epoch [45/300], Step [36/225], Training Accuracy: 79.0799%, Training Loss: 0.4693%\n",
      "Epoch [45/300], Step [37/225], Training Accuracy: 79.3074%, Training Loss: 0.4651%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/300], Step [38/225], Training Accuracy: 79.3174%, Training Loss: 0.4660%\n",
      "Epoch [45/300], Step [39/225], Training Accuracy: 79.1266%, Training Loss: 0.4715%\n",
      "Epoch [45/300], Step [40/225], Training Accuracy: 79.1016%, Training Loss: 0.4705%\n",
      "Epoch [45/300], Step [41/225], Training Accuracy: 79.1540%, Training Loss: 0.4715%\n",
      "Epoch [45/300], Step [42/225], Training Accuracy: 79.0551%, Training Loss: 0.4756%\n",
      "Epoch [45/300], Step [43/225], Training Accuracy: 79.2515%, Training Loss: 0.4740%\n",
      "Epoch [45/300], Step [44/225], Training Accuracy: 79.4744%, Training Loss: 0.4713%\n",
      "Epoch [45/300], Step [45/225], Training Accuracy: 79.6528%, Training Loss: 0.4689%\n",
      "Epoch [45/300], Step [46/225], Training Accuracy: 79.6875%, Training Loss: 0.4686%\n",
      "Epoch [45/300], Step [47/225], Training Accuracy: 79.5878%, Training Loss: 0.4704%\n",
      "Epoch [45/300], Step [48/225], Training Accuracy: 79.6224%, Training Loss: 0.4675%\n",
      "Epoch [45/300], Step [49/225], Training Accuracy: 79.6237%, Training Loss: 0.4680%\n",
      "Epoch [45/300], Step [50/225], Training Accuracy: 79.5312%, Training Loss: 0.4698%\n",
      "Epoch [45/300], Step [51/225], Training Accuracy: 79.6262%, Training Loss: 0.4681%\n",
      "Epoch [45/300], Step [52/225], Training Accuracy: 79.7776%, Training Loss: 0.4646%\n",
      "Epoch [45/300], Step [53/225], Training Accuracy: 79.7759%, Training Loss: 0.4659%\n",
      "Epoch [45/300], Step [54/225], Training Accuracy: 79.6007%, Training Loss: 0.4668%\n",
      "Epoch [45/300], Step [55/225], Training Accuracy: 79.5170%, Training Loss: 0.4704%\n",
      "Epoch [45/300], Step [56/225], Training Accuracy: 79.5480%, Training Loss: 0.4732%\n",
      "Epoch [45/300], Step [57/225], Training Accuracy: 79.5230%, Training Loss: 0.4740%\n",
      "Epoch [45/300], Step [58/225], Training Accuracy: 79.5259%, Training Loss: 0.4738%\n",
      "Epoch [45/300], Step [59/225], Training Accuracy: 79.4227%, Training Loss: 0.4747%\n",
      "Epoch [45/300], Step [60/225], Training Accuracy: 79.3490%, Training Loss: 0.4757%\n",
      "Epoch [45/300], Step [61/225], Training Accuracy: 79.2777%, Training Loss: 0.4759%\n",
      "Epoch [45/300], Step [62/225], Training Accuracy: 79.2843%, Training Loss: 0.4752%\n",
      "Epoch [45/300], Step [63/225], Training Accuracy: 79.1667%, Training Loss: 0.4768%\n",
      "Epoch [45/300], Step [64/225], Training Accuracy: 79.1260%, Training Loss: 0.4790%\n",
      "Epoch [45/300], Step [65/225], Training Accuracy: 79.1827%, Training Loss: 0.4779%\n",
      "Epoch [45/300], Step [66/225], Training Accuracy: 79.1193%, Training Loss: 0.4775%\n",
      "Epoch [45/300], Step [67/225], Training Accuracy: 79.1045%, Training Loss: 0.4777%\n",
      "Epoch [45/300], Step [68/225], Training Accuracy: 79.0211%, Training Loss: 0.4790%\n",
      "Epoch [45/300], Step [69/225], Training Accuracy: 79.0987%, Training Loss: 0.4807%\n",
      "Epoch [45/300], Step [70/225], Training Accuracy: 79.0179%, Training Loss: 0.4820%\n",
      "Epoch [45/300], Step [71/225], Training Accuracy: 78.9833%, Training Loss: 0.4818%\n",
      "Epoch [45/300], Step [72/225], Training Accuracy: 79.0582%, Training Loss: 0.4810%\n",
      "Epoch [45/300], Step [73/225], Training Accuracy: 79.0668%, Training Loss: 0.4811%\n",
      "Epoch [45/300], Step [74/225], Training Accuracy: 79.0752%, Training Loss: 0.4809%\n",
      "Epoch [45/300], Step [75/225], Training Accuracy: 79.0417%, Training Loss: 0.4815%\n",
      "Epoch [45/300], Step [76/225], Training Accuracy: 78.9679%, Training Loss: 0.4839%\n",
      "Epoch [45/300], Step [77/225], Training Accuracy: 78.9570%, Training Loss: 0.4859%\n",
      "Epoch [45/300], Step [78/225], Training Accuracy: 78.9463%, Training Loss: 0.4862%\n",
      "Epoch [45/300], Step [79/225], Training Accuracy: 78.9953%, Training Loss: 0.4852%\n",
      "Epoch [45/300], Step [80/225], Training Accuracy: 79.0039%, Training Loss: 0.4853%\n",
      "Epoch [45/300], Step [81/225], Training Accuracy: 79.0123%, Training Loss: 0.4847%\n",
      "Epoch [45/300], Step [82/225], Training Accuracy: 79.1349%, Training Loss: 0.4830%\n",
      "Epoch [45/300], Step [83/225], Training Accuracy: 79.0663%, Training Loss: 0.4834%\n",
      "Epoch [45/300], Step [84/225], Training Accuracy: 79.1109%, Training Loss: 0.4835%\n",
      "Epoch [45/300], Step [85/225], Training Accuracy: 79.0993%, Training Loss: 0.4829%\n",
      "Epoch [45/300], Step [86/225], Training Accuracy: 79.1061%, Training Loss: 0.4831%\n",
      "Epoch [45/300], Step [87/225], Training Accuracy: 79.0769%, Training Loss: 0.4833%\n",
      "Epoch [45/300], Step [88/225], Training Accuracy: 79.0305%, Training Loss: 0.4844%\n",
      "Epoch [45/300], Step [89/225], Training Accuracy: 79.0555%, Training Loss: 0.4837%\n",
      "Epoch [45/300], Step [90/225], Training Accuracy: 79.0278%, Training Loss: 0.4848%\n",
      "Epoch [45/300], Step [91/225], Training Accuracy: 79.1209%, Training Loss: 0.4834%\n",
      "Epoch [45/300], Step [92/225], Training Accuracy: 79.1101%, Training Loss: 0.4841%\n",
      "Epoch [45/300], Step [93/225], Training Accuracy: 79.1331%, Training Loss: 0.4838%\n",
      "Epoch [45/300], Step [94/225], Training Accuracy: 79.1057%, Training Loss: 0.4840%\n",
      "Epoch [45/300], Step [95/225], Training Accuracy: 79.0954%, Training Loss: 0.4841%\n",
      "Epoch [45/300], Step [96/225], Training Accuracy: 79.1341%, Training Loss: 0.4835%\n",
      "Epoch [45/300], Step [97/225], Training Accuracy: 79.1559%, Training Loss: 0.4835%\n",
      "Epoch [45/300], Step [98/225], Training Accuracy: 79.0497%, Training Loss: 0.4851%\n",
      "Epoch [45/300], Step [99/225], Training Accuracy: 79.0878%, Training Loss: 0.4846%\n",
      "Epoch [45/300], Step [100/225], Training Accuracy: 79.0781%, Training Loss: 0.4854%\n",
      "Epoch [45/300], Step [101/225], Training Accuracy: 79.0377%, Training Loss: 0.4862%\n",
      "Epoch [45/300], Step [102/225], Training Accuracy: 79.0748%, Training Loss: 0.4859%\n",
      "Epoch [45/300], Step [103/225], Training Accuracy: 79.1262%, Training Loss: 0.4851%\n",
      "Epoch [45/300], Step [104/225], Training Accuracy: 79.1316%, Training Loss: 0.4850%\n",
      "Epoch [45/300], Step [105/225], Training Accuracy: 79.1518%, Training Loss: 0.4842%\n",
      "Epoch [45/300], Step [106/225], Training Accuracy: 79.1421%, Training Loss: 0.4842%\n",
      "Epoch [45/300], Step [107/225], Training Accuracy: 79.1910%, Training Loss: 0.4841%\n",
      "Epoch [45/300], Step [108/225], Training Accuracy: 79.1522%, Training Loss: 0.4843%\n",
      "Epoch [45/300], Step [109/225], Training Accuracy: 79.0998%, Training Loss: 0.4844%\n",
      "Epoch [45/300], Step [110/225], Training Accuracy: 79.0909%, Training Loss: 0.4848%\n",
      "Epoch [45/300], Step [111/225], Training Accuracy: 79.1526%, Training Loss: 0.4840%\n",
      "Epoch [45/300], Step [112/225], Training Accuracy: 79.2132%, Training Loss: 0.4829%\n",
      "Epoch [45/300], Step [113/225], Training Accuracy: 79.2312%, Training Loss: 0.4833%\n",
      "Epoch [45/300], Step [114/225], Training Accuracy: 79.1804%, Training Loss: 0.4833%\n",
      "Epoch [45/300], Step [115/225], Training Accuracy: 79.1576%, Training Loss: 0.4840%\n",
      "Epoch [45/300], Step [116/225], Training Accuracy: 79.1487%, Training Loss: 0.4843%\n",
      "Epoch [45/300], Step [117/225], Training Accuracy: 79.1266%, Training Loss: 0.4853%\n",
      "Epoch [45/300], Step [118/225], Training Accuracy: 79.1314%, Training Loss: 0.4844%\n",
      "Epoch [45/300], Step [119/225], Training Accuracy: 79.1098%, Training Loss: 0.4854%\n",
      "Epoch [45/300], Step [120/225], Training Accuracy: 79.0885%, Training Loss: 0.4857%\n",
      "Epoch [45/300], Step [121/225], Training Accuracy: 79.0935%, Training Loss: 0.4854%\n",
      "Epoch [45/300], Step [122/225], Training Accuracy: 79.0727%, Training Loss: 0.4855%\n",
      "Epoch [45/300], Step [123/225], Training Accuracy: 79.0650%, Training Loss: 0.4846%\n",
      "Epoch [45/300], Step [124/225], Training Accuracy: 79.0449%, Training Loss: 0.4846%\n",
      "Epoch [45/300], Step [125/225], Training Accuracy: 79.0250%, Training Loss: 0.4846%\n",
      "Epoch [45/300], Step [126/225], Training Accuracy: 78.9559%, Training Loss: 0.4855%\n",
      "Epoch [45/300], Step [127/225], Training Accuracy: 78.9247%, Training Loss: 0.4860%\n",
      "Epoch [45/300], Step [128/225], Training Accuracy: 78.9185%, Training Loss: 0.4863%\n",
      "Epoch [45/300], Step [129/225], Training Accuracy: 78.9486%, Training Loss: 0.4859%\n",
      "Epoch [45/300], Step [130/225], Training Accuracy: 78.9423%, Training Loss: 0.4856%\n",
      "Epoch [45/300], Step [131/225], Training Accuracy: 78.9361%, Training Loss: 0.4867%\n",
      "Epoch [45/300], Step [132/225], Training Accuracy: 78.8707%, Training Loss: 0.4876%\n",
      "Epoch [45/300], Step [133/225], Training Accuracy: 78.8534%, Training Loss: 0.4874%\n",
      "Epoch [45/300], Step [134/225], Training Accuracy: 78.8013%, Training Loss: 0.4885%\n",
      "Epoch [45/300], Step [135/225], Training Accuracy: 78.7500%, Training Loss: 0.4891%\n",
      "Epoch [45/300], Step [136/225], Training Accuracy: 78.7224%, Training Loss: 0.4893%\n",
      "Epoch [45/300], Step [137/225], Training Accuracy: 78.7067%, Training Loss: 0.4890%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/300], Step [138/225], Training Accuracy: 78.7817%, Training Loss: 0.4880%\n",
      "Epoch [45/300], Step [139/225], Training Accuracy: 78.7995%, Training Loss: 0.4877%\n",
      "Epoch [45/300], Step [140/225], Training Accuracy: 78.8616%, Training Loss: 0.4874%\n",
      "Epoch [45/300], Step [141/225], Training Accuracy: 78.8675%, Training Loss: 0.4876%\n",
      "Epoch [45/300], Step [142/225], Training Accuracy: 78.9173%, Training Loss: 0.4869%\n",
      "Epoch [45/300], Step [143/225], Training Accuracy: 78.8899%, Training Loss: 0.4874%\n",
      "Epoch [45/300], Step [144/225], Training Accuracy: 78.8737%, Training Loss: 0.4873%\n",
      "Epoch [45/300], Step [145/225], Training Accuracy: 78.8793%, Training Loss: 0.4872%\n",
      "Epoch [45/300], Step [146/225], Training Accuracy: 78.8527%, Training Loss: 0.4882%\n",
      "Epoch [45/300], Step [147/225], Training Accuracy: 78.8478%, Training Loss: 0.4880%\n",
      "Epoch [45/300], Step [148/225], Training Accuracy: 78.8323%, Training Loss: 0.4878%\n",
      "Epoch [45/300], Step [149/225], Training Accuracy: 78.8695%, Training Loss: 0.4874%\n",
      "Epoch [45/300], Step [150/225], Training Accuracy: 78.9167%, Training Loss: 0.4865%\n",
      "Epoch [45/300], Step [151/225], Training Accuracy: 78.8700%, Training Loss: 0.4866%\n",
      "Epoch [45/300], Step [152/225], Training Accuracy: 78.8651%, Training Loss: 0.4867%\n",
      "Epoch [45/300], Step [153/225], Training Accuracy: 78.8705%, Training Loss: 0.4864%\n",
      "Epoch [45/300], Step [154/225], Training Accuracy: 78.8454%, Training Loss: 0.4863%\n",
      "Epoch [45/300], Step [155/225], Training Accuracy: 78.8508%, Training Loss: 0.4865%\n",
      "Epoch [45/300], Step [156/225], Training Accuracy: 78.8361%, Training Loss: 0.4870%\n",
      "Epoch [45/300], Step [157/225], Training Accuracy: 78.8515%, Training Loss: 0.4867%\n",
      "Epoch [45/300], Step [158/225], Training Accuracy: 78.8568%, Training Loss: 0.4876%\n",
      "Epoch [45/300], Step [159/225], Training Accuracy: 78.8227%, Training Loss: 0.4883%\n",
      "Epoch [45/300], Step [160/225], Training Accuracy: 78.8086%, Training Loss: 0.4883%\n",
      "Epoch [45/300], Step [161/225], Training Accuracy: 78.7946%, Training Loss: 0.4885%\n",
      "Epoch [45/300], Step [162/225], Training Accuracy: 78.8098%, Training Loss: 0.4887%\n",
      "Epoch [45/300], Step [163/225], Training Accuracy: 78.7960%, Training Loss: 0.4888%\n",
      "Epoch [45/300], Step [164/225], Training Accuracy: 78.8300%, Training Loss: 0.4881%\n",
      "Epoch [45/300], Step [165/225], Training Accuracy: 78.7973%, Training Loss: 0.4887%\n",
      "Epoch [45/300], Step [166/225], Training Accuracy: 78.7839%, Training Loss: 0.4885%\n",
      "Epoch [45/300], Step [167/225], Training Accuracy: 78.7987%, Training Loss: 0.4882%\n",
      "Epoch [45/300], Step [168/225], Training Accuracy: 78.7760%, Training Loss: 0.4889%\n",
      "Epoch [45/300], Step [169/225], Training Accuracy: 78.8092%, Training Loss: 0.4882%\n",
      "Epoch [45/300], Step [170/225], Training Accuracy: 78.8235%, Training Loss: 0.4877%\n",
      "Epoch [45/300], Step [171/225], Training Accuracy: 78.8286%, Training Loss: 0.4879%\n",
      "Epoch [45/300], Step [172/225], Training Accuracy: 78.8517%, Training Loss: 0.4876%\n",
      "Epoch [45/300], Step [173/225], Training Accuracy: 78.8385%, Training Loss: 0.4881%\n",
      "Epoch [45/300], Step [174/225], Training Accuracy: 78.8254%, Training Loss: 0.4880%\n",
      "Epoch [45/300], Step [175/225], Training Accuracy: 78.8661%, Training Loss: 0.4877%\n",
      "Epoch [45/300], Step [176/225], Training Accuracy: 78.8619%, Training Loss: 0.4876%\n",
      "Epoch [45/300], Step [177/225], Training Accuracy: 78.9195%, Training Loss: 0.4868%\n",
      "Epoch [45/300], Step [178/225], Training Accuracy: 78.9238%, Training Loss: 0.4871%\n",
      "Epoch [45/300], Step [179/225], Training Accuracy: 78.9455%, Training Loss: 0.4868%\n",
      "Epoch [45/300], Step [180/225], Training Accuracy: 78.9583%, Training Loss: 0.4865%\n",
      "Epoch [45/300], Step [181/225], Training Accuracy: 78.9624%, Training Loss: 0.4870%\n",
      "Epoch [45/300], Step [182/225], Training Accuracy: 78.9835%, Training Loss: 0.4866%\n",
      "Epoch [45/300], Step [183/225], Training Accuracy: 78.9959%, Training Loss: 0.4867%\n",
      "Epoch [45/300], Step [184/225], Training Accuracy: 79.0336%, Training Loss: 0.4862%\n",
      "Epoch [45/300], Step [185/225], Training Accuracy: 79.0034%, Training Loss: 0.4865%\n",
      "Epoch [45/300], Step [186/225], Training Accuracy: 79.0239%, Training Loss: 0.4855%\n",
      "Epoch [45/300], Step [187/225], Training Accuracy: 79.0525%, Training Loss: 0.4855%\n",
      "Epoch [45/300], Step [188/225], Training Accuracy: 79.0475%, Training Loss: 0.4855%\n",
      "Epoch [45/300], Step [189/225], Training Accuracy: 79.0757%, Training Loss: 0.4846%\n",
      "Epoch [45/300], Step [190/225], Training Accuracy: 79.0707%, Training Loss: 0.4854%\n",
      "Epoch [45/300], Step [191/225], Training Accuracy: 79.0249%, Training Loss: 0.4859%\n",
      "Epoch [45/300], Step [192/225], Training Accuracy: 79.0771%, Training Loss: 0.4846%\n",
      "Epoch [45/300], Step [193/225], Training Accuracy: 79.1127%, Training Loss: 0.4841%\n",
      "Epoch [45/300], Step [194/225], Training Accuracy: 79.1076%, Training Loss: 0.4845%\n",
      "Epoch [45/300], Step [195/225], Training Accuracy: 79.1026%, Training Loss: 0.4840%\n",
      "Epoch [45/300], Step [196/225], Training Accuracy: 79.0657%, Training Loss: 0.4851%\n",
      "Epoch [45/300], Step [197/225], Training Accuracy: 79.1006%, Training Loss: 0.4847%\n",
      "Epoch [45/300], Step [198/225], Training Accuracy: 79.1193%, Training Loss: 0.4842%\n",
      "Epoch [45/300], Step [199/225], Training Accuracy: 79.1379%, Training Loss: 0.4837%\n",
      "Epoch [45/300], Step [200/225], Training Accuracy: 79.1172%, Training Loss: 0.4839%\n",
      "Epoch [45/300], Step [201/225], Training Accuracy: 79.1200%, Training Loss: 0.4842%\n",
      "Epoch [45/300], Step [202/225], Training Accuracy: 79.1460%, Training Loss: 0.4842%\n",
      "Epoch [45/300], Step [203/225], Training Accuracy: 79.1795%, Training Loss: 0.4835%\n",
      "Epoch [45/300], Step [204/225], Training Accuracy: 79.2126%, Training Loss: 0.4830%\n",
      "Epoch [45/300], Step [205/225], Training Accuracy: 79.2454%, Training Loss: 0.4829%\n",
      "Epoch [45/300], Step [206/225], Training Accuracy: 79.2324%, Training Loss: 0.4833%\n",
      "Epoch [45/300], Step [207/225], Training Accuracy: 79.2346%, Training Loss: 0.4832%\n",
      "Epoch [45/300], Step [208/225], Training Accuracy: 79.2593%, Training Loss: 0.4828%\n",
      "Epoch [45/300], Step [209/225], Training Accuracy: 79.2913%, Training Loss: 0.4826%\n",
      "Epoch [45/300], Step [210/225], Training Accuracy: 79.2634%, Training Loss: 0.4837%\n",
      "Epoch [45/300], Step [211/225], Training Accuracy: 79.2654%, Training Loss: 0.4840%\n",
      "Epoch [45/300], Step [212/225], Training Accuracy: 79.2600%, Training Loss: 0.4840%\n",
      "Epoch [45/300], Step [213/225], Training Accuracy: 79.2694%, Training Loss: 0.4841%\n",
      "Epoch [45/300], Step [214/225], Training Accuracy: 79.2567%, Training Loss: 0.4841%\n",
      "Epoch [45/300], Step [215/225], Training Accuracy: 79.2515%, Training Loss: 0.4838%\n",
      "Epoch [45/300], Step [216/225], Training Accuracy: 79.2390%, Training Loss: 0.4843%\n",
      "Epoch [45/300], Step [217/225], Training Accuracy: 79.2195%, Training Loss: 0.4845%\n",
      "Epoch [45/300], Step [218/225], Training Accuracy: 79.2073%, Training Loss: 0.4851%\n",
      "Epoch [45/300], Step [219/225], Training Accuracy: 79.1881%, Training Loss: 0.4850%\n",
      "Epoch [45/300], Step [220/225], Training Accuracy: 79.2116%, Training Loss: 0.4847%\n",
      "Epoch [45/300], Step [221/225], Training Accuracy: 79.1926%, Training Loss: 0.4846%\n",
      "Epoch [45/300], Step [222/225], Training Accuracy: 79.1667%, Training Loss: 0.4850%\n",
      "Epoch [45/300], Step [223/225], Training Accuracy: 79.1690%, Training Loss: 0.4852%\n",
      "Epoch [45/300], Step [224/225], Training Accuracy: 79.1643%, Training Loss: 0.4850%\n",
      "Epoch [45/300], Step [225/225], Training Accuracy: 79.1551%, Training Loss: 0.4852%\n",
      "Epoch [46/300], Step [1/225], Training Accuracy: 85.9375%, Training Loss: 0.3975%\n",
      "Epoch [46/300], Step [2/225], Training Accuracy: 82.8125%, Training Loss: 0.4774%\n",
      "Epoch [46/300], Step [3/225], Training Accuracy: 81.2500%, Training Loss: 0.4954%\n",
      "Epoch [46/300], Step [4/225], Training Accuracy: 80.0781%, Training Loss: 0.4888%\n",
      "Epoch [46/300], Step [5/225], Training Accuracy: 80.0000%, Training Loss: 0.4999%\n",
      "Epoch [46/300], Step [6/225], Training Accuracy: 80.2083%, Training Loss: 0.4836%\n",
      "Epoch [46/300], Step [7/225], Training Accuracy: 79.6875%, Training Loss: 0.4766%\n",
      "Epoch [46/300], Step [8/225], Training Accuracy: 79.2969%, Training Loss: 0.4877%\n",
      "Epoch [46/300], Step [9/225], Training Accuracy: 79.6875%, Training Loss: 0.4843%\n",
      "Epoch [46/300], Step [10/225], Training Accuracy: 78.4375%, Training Loss: 0.5096%\n",
      "Epoch [46/300], Step [11/225], Training Accuracy: 79.1193%, Training Loss: 0.4976%\n",
      "Epoch [46/300], Step [12/225], Training Accuracy: 79.9479%, Training Loss: 0.4863%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/300], Step [13/225], Training Accuracy: 80.2885%, Training Loss: 0.4762%\n",
      "Epoch [46/300], Step [14/225], Training Accuracy: 79.2411%, Training Loss: 0.4982%\n",
      "Epoch [46/300], Step [15/225], Training Accuracy: 79.4792%, Training Loss: 0.4940%\n",
      "Epoch [46/300], Step [16/225], Training Accuracy: 79.0039%, Training Loss: 0.5047%\n",
      "Epoch [46/300], Step [17/225], Training Accuracy: 78.7684%, Training Loss: 0.5019%\n",
      "Epoch [46/300], Step [18/225], Training Accuracy: 79.1667%, Training Loss: 0.4951%\n",
      "Epoch [46/300], Step [19/225], Training Accuracy: 79.4408%, Training Loss: 0.4904%\n",
      "Epoch [46/300], Step [20/225], Training Accuracy: 79.8438%, Training Loss: 0.4851%\n",
      "Epoch [46/300], Step [21/225], Training Accuracy: 80.0595%, Training Loss: 0.4771%\n",
      "Epoch [46/300], Step [22/225], Training Accuracy: 79.7585%, Training Loss: 0.4865%\n",
      "Epoch [46/300], Step [23/225], Training Accuracy: 79.9592%, Training Loss: 0.4802%\n",
      "Epoch [46/300], Step [24/225], Training Accuracy: 79.9479%, Training Loss: 0.4815%\n",
      "Epoch [46/300], Step [25/225], Training Accuracy: 80.1250%, Training Loss: 0.4769%\n",
      "Epoch [46/300], Step [26/225], Training Accuracy: 80.1683%, Training Loss: 0.4827%\n",
      "Epoch [46/300], Step [27/225], Training Accuracy: 80.1505%, Training Loss: 0.4814%\n",
      "Epoch [46/300], Step [28/225], Training Accuracy: 80.2455%, Training Loss: 0.4768%\n",
      "Epoch [46/300], Step [29/225], Training Accuracy: 80.0647%, Training Loss: 0.4761%\n",
      "Epoch [46/300], Step [30/225], Training Accuracy: 79.9479%, Training Loss: 0.4777%\n",
      "Epoch [46/300], Step [31/225], Training Accuracy: 79.5867%, Training Loss: 0.4832%\n",
      "Epoch [46/300], Step [32/225], Training Accuracy: 79.4922%, Training Loss: 0.4830%\n",
      "Epoch [46/300], Step [33/225], Training Accuracy: 79.5455%, Training Loss: 0.4827%\n",
      "Epoch [46/300], Step [34/225], Training Accuracy: 79.2739%, Training Loss: 0.4939%\n",
      "Epoch [46/300], Step [35/225], Training Accuracy: 79.2411%, Training Loss: 0.4984%\n",
      "Epoch [46/300], Step [36/225], Training Accuracy: 78.8194%, Training Loss: 0.5035%\n",
      "Epoch [46/300], Step [37/225], Training Accuracy: 78.9696%, Training Loss: 0.4995%\n",
      "Epoch [46/300], Step [38/225], Training Accuracy: 78.8651%, Training Loss: 0.5000%\n",
      "Epoch [46/300], Step [39/225], Training Accuracy: 78.6859%, Training Loss: 0.5009%\n",
      "Epoch [46/300], Step [40/225], Training Accuracy: 78.7109%, Training Loss: 0.5034%\n",
      "Epoch [46/300], Step [41/225], Training Accuracy: 78.5823%, Training Loss: 0.5073%\n",
      "Epoch [46/300], Step [42/225], Training Accuracy: 78.3482%, Training Loss: 0.5127%\n",
      "Epoch [46/300], Step [43/225], Training Accuracy: 78.3430%, Training Loss: 0.5130%\n",
      "Epoch [46/300], Step [44/225], Training Accuracy: 78.4446%, Training Loss: 0.5155%\n",
      "Epoch [46/300], Step [45/225], Training Accuracy: 78.5764%, Training Loss: 0.5136%\n",
      "Epoch [46/300], Step [46/225], Training Accuracy: 78.3967%, Training Loss: 0.5176%\n",
      "Epoch [46/300], Step [47/225], Training Accuracy: 78.2912%, Training Loss: 0.5188%\n",
      "Epoch [46/300], Step [48/225], Training Accuracy: 78.1250%, Training Loss: 0.5214%\n",
      "Epoch [46/300], Step [49/225], Training Accuracy: 78.2844%, Training Loss: 0.5185%\n",
      "Epoch [46/300], Step [50/225], Training Accuracy: 78.2188%, Training Loss: 0.5198%\n",
      "Epoch [46/300], Step [51/225], Training Accuracy: 78.3395%, Training Loss: 0.5173%\n",
      "Epoch [46/300], Step [52/225], Training Accuracy: 78.4555%, Training Loss: 0.5148%\n",
      "Epoch [46/300], Step [53/225], Training Accuracy: 78.3903%, Training Loss: 0.5160%\n",
      "Epoch [46/300], Step [54/225], Training Accuracy: 78.3854%, Training Loss: 0.5155%\n",
      "Epoch [46/300], Step [55/225], Training Accuracy: 78.2670%, Training Loss: 0.5214%\n",
      "Epoch [46/300], Step [56/225], Training Accuracy: 78.3203%, Training Loss: 0.5195%\n",
      "Epoch [46/300], Step [57/225], Training Accuracy: 78.2346%, Training Loss: 0.5183%\n",
      "Epoch [46/300], Step [58/225], Training Accuracy: 78.2866%, Training Loss: 0.5157%\n",
      "Epoch [46/300], Step [59/225], Training Accuracy: 78.3633%, Training Loss: 0.5142%\n",
      "Epoch [46/300], Step [60/225], Training Accuracy: 78.4115%, Training Loss: 0.5129%\n",
      "Epoch [46/300], Step [61/225], Training Accuracy: 78.4580%, Training Loss: 0.5128%\n",
      "Epoch [46/300], Step [62/225], Training Accuracy: 78.5534%, Training Loss: 0.5104%\n",
      "Epoch [46/300], Step [63/225], Training Accuracy: 78.6210%, Training Loss: 0.5088%\n",
      "Epoch [46/300], Step [64/225], Training Accuracy: 78.6377%, Training Loss: 0.5091%\n",
      "Epoch [46/300], Step [65/225], Training Accuracy: 78.7260%, Training Loss: 0.5077%\n",
      "Epoch [46/300], Step [66/225], Training Accuracy: 78.7642%, Training Loss: 0.5054%\n",
      "Epoch [46/300], Step [67/225], Training Accuracy: 78.7313%, Training Loss: 0.5067%\n",
      "Epoch [46/300], Step [68/225], Training Accuracy: 78.6535%, Training Loss: 0.5064%\n",
      "Epoch [46/300], Step [69/225], Training Accuracy: 78.5779%, Training Loss: 0.5077%\n",
      "Epoch [46/300], Step [70/225], Training Accuracy: 78.6384%, Training Loss: 0.5060%\n",
      "Epoch [46/300], Step [71/225], Training Accuracy: 78.5871%, Training Loss: 0.5053%\n",
      "Epoch [46/300], Step [72/225], Training Accuracy: 78.7326%, Training Loss: 0.5027%\n",
      "Epoch [46/300], Step [73/225], Training Accuracy: 78.7671%, Training Loss: 0.5025%\n",
      "Epoch [46/300], Step [74/225], Training Accuracy: 78.9062%, Training Loss: 0.5002%\n",
      "Epoch [46/300], Step [75/225], Training Accuracy: 78.8750%, Training Loss: 0.5001%\n",
      "Epoch [46/300], Step [76/225], Training Accuracy: 78.7623%, Training Loss: 0.5013%\n",
      "Epoch [46/300], Step [77/225], Training Accuracy: 78.7338%, Training Loss: 0.5018%\n",
      "Epoch [46/300], Step [78/225], Training Accuracy: 78.7660%, Training Loss: 0.5016%\n",
      "Epoch [46/300], Step [79/225], Training Accuracy: 78.7975%, Training Loss: 0.5010%\n",
      "Epoch [46/300], Step [80/225], Training Accuracy: 78.7891%, Training Loss: 0.5013%\n",
      "Epoch [46/300], Step [81/225], Training Accuracy: 78.8002%, Training Loss: 0.5023%\n",
      "Epoch [46/300], Step [82/225], Training Accuracy: 78.8681%, Training Loss: 0.5007%\n",
      "Epoch [46/300], Step [83/225], Training Accuracy: 78.8592%, Training Loss: 0.5002%\n",
      "Epoch [46/300], Step [84/225], Training Accuracy: 78.9993%, Training Loss: 0.4984%\n",
      "Epoch [46/300], Step [85/225], Training Accuracy: 79.0074%, Training Loss: 0.4981%\n",
      "Epoch [46/300], Step [86/225], Training Accuracy: 79.0334%, Training Loss: 0.4981%\n",
      "Epoch [46/300], Step [87/225], Training Accuracy: 78.9871%, Training Loss: 0.4978%\n",
      "Epoch [46/300], Step [88/225], Training Accuracy: 78.9240%, Training Loss: 0.4988%\n",
      "Epoch [46/300], Step [89/225], Training Accuracy: 78.9326%, Training Loss: 0.4984%\n",
      "Epoch [46/300], Step [90/225], Training Accuracy: 78.9062%, Training Loss: 0.4998%\n",
      "Epoch [46/300], Step [91/225], Training Accuracy: 78.8977%, Training Loss: 0.4998%\n",
      "Epoch [46/300], Step [92/225], Training Accuracy: 78.8723%, Training Loss: 0.4999%\n",
      "Epoch [46/300], Step [93/225], Training Accuracy: 78.8978%, Training Loss: 0.4991%\n",
      "Epoch [46/300], Step [94/225], Training Accuracy: 78.9561%, Training Loss: 0.4984%\n",
      "Epoch [46/300], Step [95/225], Training Accuracy: 78.9309%, Training Loss: 0.4995%\n",
      "Epoch [46/300], Step [96/225], Training Accuracy: 78.9876%, Training Loss: 0.4989%\n",
      "Epoch [46/300], Step [97/225], Training Accuracy: 79.0432%, Training Loss: 0.4984%\n",
      "Epoch [46/300], Step [98/225], Training Accuracy: 78.9381%, Training Loss: 0.5002%\n",
      "Epoch [46/300], Step [99/225], Training Accuracy: 79.0088%, Training Loss: 0.4996%\n",
      "Epoch [46/300], Step [100/225], Training Accuracy: 78.9844%, Training Loss: 0.5007%\n",
      "Epoch [46/300], Step [101/225], Training Accuracy: 78.9604%, Training Loss: 0.5008%\n",
      "Epoch [46/300], Step [102/225], Training Accuracy: 78.9828%, Training Loss: 0.5017%\n",
      "Epoch [46/300], Step [103/225], Training Accuracy: 78.9290%, Training Loss: 0.5021%\n",
      "Epoch [46/300], Step [104/225], Training Accuracy: 78.9363%, Training Loss: 0.5014%\n",
      "Epoch [46/300], Step [105/225], Training Accuracy: 78.9732%, Training Loss: 0.5010%\n",
      "Epoch [46/300], Step [106/225], Training Accuracy: 78.9947%, Training Loss: 0.5001%\n",
      "Epoch [46/300], Step [107/225], Training Accuracy: 78.9720%, Training Loss: 0.5012%\n",
      "Epoch [46/300], Step [108/225], Training Accuracy: 78.8773%, Training Loss: 0.5035%\n",
      "Epoch [46/300], Step [109/225], Training Accuracy: 78.8131%, Training Loss: 0.5040%\n",
      "Epoch [46/300], Step [110/225], Training Accuracy: 78.8068%, Training Loss: 0.5036%\n",
      "Epoch [46/300], Step [111/225], Training Accuracy: 78.7866%, Training Loss: 0.5037%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/300], Step [112/225], Training Accuracy: 78.8086%, Training Loss: 0.5032%\n",
      "Epoch [46/300], Step [113/225], Training Accuracy: 78.8025%, Training Loss: 0.5037%\n",
      "Epoch [46/300], Step [114/225], Training Accuracy: 78.7555%, Training Loss: 0.5041%\n",
      "Epoch [46/300], Step [115/225], Training Accuracy: 78.7908%, Training Loss: 0.5030%\n",
      "Epoch [46/300], Step [116/225], Training Accuracy: 78.7985%, Training Loss: 0.5034%\n",
      "Epoch [46/300], Step [117/225], Training Accuracy: 78.8328%, Training Loss: 0.5036%\n",
      "Epoch [46/300], Step [118/225], Training Accuracy: 78.8798%, Training Loss: 0.5032%\n",
      "Epoch [46/300], Step [119/225], Training Accuracy: 78.8734%, Training Loss: 0.5029%\n",
      "Epoch [46/300], Step [120/225], Training Accuracy: 78.8542%, Training Loss: 0.5034%\n",
      "Epoch [46/300], Step [121/225], Training Accuracy: 78.8094%, Training Loss: 0.5039%\n",
      "Epoch [46/300], Step [122/225], Training Accuracy: 78.8166%, Training Loss: 0.5044%\n",
      "Epoch [46/300], Step [123/225], Training Accuracy: 78.8618%, Training Loss: 0.5031%\n",
      "Epoch [46/300], Step [124/225], Training Accuracy: 78.9441%, Training Loss: 0.5019%\n",
      "Epoch [46/300], Step [125/225], Training Accuracy: 78.9750%, Training Loss: 0.5027%\n",
      "Epoch [46/300], Step [126/225], Training Accuracy: 78.9062%, Training Loss: 0.5032%\n",
      "Epoch [46/300], Step [127/225], Training Accuracy: 78.8878%, Training Loss: 0.5044%\n",
      "Epoch [46/300], Step [128/225], Training Accuracy: 78.8940%, Training Loss: 0.5050%\n",
      "Epoch [46/300], Step [129/225], Training Accuracy: 78.9486%, Training Loss: 0.5042%\n",
      "Epoch [46/300], Step [130/225], Training Accuracy: 78.9423%, Training Loss: 0.5040%\n",
      "Epoch [46/300], Step [131/225], Training Accuracy: 78.9003%, Training Loss: 0.5043%\n",
      "Epoch [46/300], Step [132/225], Training Accuracy: 78.9062%, Training Loss: 0.5038%\n",
      "Epoch [46/300], Step [133/225], Training Accuracy: 78.9356%, Training Loss: 0.5037%\n",
      "Epoch [46/300], Step [134/225], Training Accuracy: 78.8713%, Training Loss: 0.5063%\n",
      "Epoch [46/300], Step [135/225], Training Accuracy: 78.8657%, Training Loss: 0.5064%\n",
      "Epoch [46/300], Step [136/225], Training Accuracy: 78.8143%, Training Loss: 0.5071%\n",
      "Epoch [46/300], Step [137/225], Training Accuracy: 78.8435%, Training Loss: 0.5067%\n",
      "Epoch [46/300], Step [138/225], Training Accuracy: 78.9402%, Training Loss: 0.5060%\n",
      "Epoch [46/300], Step [139/225], Training Accuracy: 78.9231%, Training Loss: 0.5056%\n",
      "Epoch [46/300], Step [140/225], Training Accuracy: 78.9286%, Training Loss: 0.5057%\n",
      "Epoch [46/300], Step [141/225], Training Accuracy: 78.9118%, Training Loss: 0.5065%\n",
      "Epoch [46/300], Step [142/225], Training Accuracy: 78.9283%, Training Loss: 0.5058%\n",
      "Epoch [46/300], Step [143/225], Training Accuracy: 78.9336%, Training Loss: 0.5057%\n",
      "Epoch [46/300], Step [144/225], Training Accuracy: 78.9171%, Training Loss: 0.5051%\n",
      "Epoch [46/300], Step [145/225], Training Accuracy: 78.9009%, Training Loss: 0.5051%\n",
      "Epoch [46/300], Step [146/225], Training Accuracy: 78.8634%, Training Loss: 0.5054%\n",
      "Epoch [46/300], Step [147/225], Training Accuracy: 78.8478%, Training Loss: 0.5057%\n",
      "Epoch [46/300], Step [148/225], Training Accuracy: 78.8851%, Training Loss: 0.5049%\n",
      "Epoch [46/300], Step [149/225], Training Accuracy: 78.8905%, Training Loss: 0.5047%\n",
      "Epoch [46/300], Step [150/225], Training Accuracy: 78.9583%, Training Loss: 0.5034%\n",
      "Epoch [46/300], Step [151/225], Training Accuracy: 78.9942%, Training Loss: 0.5026%\n",
      "Epoch [46/300], Step [152/225], Training Accuracy: 79.0193%, Training Loss: 0.5026%\n",
      "Epoch [46/300], Step [153/225], Training Accuracy: 79.0033%, Training Loss: 0.5026%\n",
      "Epoch [46/300], Step [154/225], Training Accuracy: 78.9773%, Training Loss: 0.5026%\n",
      "Epoch [46/300], Step [155/225], Training Accuracy: 78.9919%, Training Loss: 0.5020%\n",
      "Epoch [46/300], Step [156/225], Training Accuracy: 78.9864%, Training Loss: 0.5022%\n",
      "Epoch [46/300], Step [157/225], Training Accuracy: 79.0107%, Training Loss: 0.5026%\n",
      "Epoch [46/300], Step [158/225], Training Accuracy: 78.9656%, Training Loss: 0.5040%\n",
      "Epoch [46/300], Step [159/225], Training Accuracy: 78.9603%, Training Loss: 0.5040%\n",
      "Epoch [46/300], Step [160/225], Training Accuracy: 78.9453%, Training Loss: 0.5037%\n",
      "Epoch [46/300], Step [161/225], Training Accuracy: 78.9208%, Training Loss: 0.5042%\n",
      "Epoch [46/300], Step [162/225], Training Accuracy: 78.8870%, Training Loss: 0.5041%\n",
      "Epoch [46/300], Step [163/225], Training Accuracy: 78.9206%, Training Loss: 0.5035%\n",
      "Epoch [46/300], Step [164/225], Training Accuracy: 78.9253%, Training Loss: 0.5036%\n",
      "Epoch [46/300], Step [165/225], Training Accuracy: 78.9015%, Training Loss: 0.5037%\n",
      "Epoch [46/300], Step [166/225], Training Accuracy: 78.9251%, Training Loss: 0.5031%\n",
      "Epoch [46/300], Step [167/225], Training Accuracy: 78.9390%, Training Loss: 0.5026%\n",
      "Epoch [46/300], Step [168/225], Training Accuracy: 78.9435%, Training Loss: 0.5023%\n",
      "Epoch [46/300], Step [169/225], Training Accuracy: 78.9571%, Training Loss: 0.5022%\n",
      "Epoch [46/300], Step [170/225], Training Accuracy: 78.9062%, Training Loss: 0.5026%\n",
      "Epoch [46/300], Step [171/225], Training Accuracy: 78.8560%, Training Loss: 0.5035%\n",
      "Epoch [46/300], Step [172/225], Training Accuracy: 78.8063%, Training Loss: 0.5037%\n",
      "Epoch [46/300], Step [173/225], Training Accuracy: 78.8204%, Training Loss: 0.5035%\n",
      "Epoch [46/300], Step [174/225], Training Accuracy: 78.8524%, Training Loss: 0.5027%\n",
      "Epoch [46/300], Step [175/225], Training Accuracy: 78.8929%, Training Loss: 0.5019%\n",
      "Epoch [46/300], Step [176/225], Training Accuracy: 78.8796%, Training Loss: 0.5021%\n",
      "Epoch [46/300], Step [177/225], Training Accuracy: 78.8842%, Training Loss: 0.5022%\n",
      "Epoch [46/300], Step [178/225], Training Accuracy: 78.8799%, Training Loss: 0.5023%\n",
      "Epoch [46/300], Step [179/225], Training Accuracy: 78.9193%, Training Loss: 0.5014%\n",
      "Epoch [46/300], Step [180/225], Training Accuracy: 78.9931%, Training Loss: 0.4999%\n",
      "Epoch [46/300], Step [181/225], Training Accuracy: 78.9969%, Training Loss: 0.5000%\n",
      "Epoch [46/300], Step [182/225], Training Accuracy: 78.9921%, Training Loss: 0.4999%\n",
      "Epoch [46/300], Step [183/225], Training Accuracy: 78.9874%, Training Loss: 0.5001%\n",
      "Epoch [46/300], Step [184/225], Training Accuracy: 78.9912%, Training Loss: 0.5000%\n",
      "Epoch [46/300], Step [185/225], Training Accuracy: 78.9865%, Training Loss: 0.4998%\n",
      "Epoch [46/300], Step [186/225], Training Accuracy: 78.9903%, Training Loss: 0.4998%\n",
      "Epoch [46/300], Step [187/225], Training Accuracy: 78.9940%, Training Loss: 0.4994%\n",
      "Epoch [46/300], Step [188/225], Training Accuracy: 79.0143%, Training Loss: 0.4990%\n",
      "Epoch [46/300], Step [189/225], Training Accuracy: 79.0179%, Training Loss: 0.4985%\n",
      "Epoch [46/300], Step [190/225], Training Accuracy: 79.0214%, Training Loss: 0.4981%\n",
      "Epoch [46/300], Step [191/225], Training Accuracy: 79.0576%, Training Loss: 0.4978%\n",
      "Epoch [46/300], Step [192/225], Training Accuracy: 79.0690%, Training Loss: 0.4973%\n",
      "Epoch [46/300], Step [193/225], Training Accuracy: 79.0965%, Training Loss: 0.4967%\n",
      "Epoch [46/300], Step [194/225], Training Accuracy: 79.0915%, Training Loss: 0.4965%\n",
      "Epoch [46/300], Step [195/225], Training Accuracy: 79.1346%, Training Loss: 0.4953%\n",
      "Epoch [46/300], Step [196/225], Training Accuracy: 79.0976%, Training Loss: 0.4958%\n",
      "Epoch [46/300], Step [197/225], Training Accuracy: 79.1006%, Training Loss: 0.4965%\n",
      "Epoch [46/300], Step [198/225], Training Accuracy: 79.1430%, Training Loss: 0.4958%\n",
      "Epoch [46/300], Step [199/225], Training Accuracy: 79.1771%, Training Loss: 0.4953%\n",
      "Epoch [46/300], Step [200/225], Training Accuracy: 79.1875%, Training Loss: 0.4953%\n",
      "Epoch [46/300], Step [201/225], Training Accuracy: 79.2211%, Training Loss: 0.4948%\n",
      "Epoch [46/300], Step [202/225], Training Accuracy: 79.2311%, Training Loss: 0.4947%\n",
      "Epoch [46/300], Step [203/225], Training Accuracy: 79.2719%, Training Loss: 0.4938%\n",
      "Epoch [46/300], Step [204/225], Training Accuracy: 79.2892%, Training Loss: 0.4942%\n",
      "Epoch [46/300], Step [205/225], Training Accuracy: 79.2759%, Training Loss: 0.4939%\n",
      "Epoch [46/300], Step [206/225], Training Accuracy: 79.3007%, Training Loss: 0.4935%\n",
      "Epoch [46/300], Step [207/225], Training Accuracy: 79.3252%, Training Loss: 0.4928%\n",
      "Epoch [46/300], Step [208/225], Training Accuracy: 79.2894%, Training Loss: 0.4930%\n",
      "Epoch [46/300], Step [209/225], Training Accuracy: 79.2389%, Training Loss: 0.4933%\n",
      "Epoch [46/300], Step [210/225], Training Accuracy: 79.2188%, Training Loss: 0.4935%\n",
      "Epoch [46/300], Step [211/225], Training Accuracy: 79.2210%, Training Loss: 0.4938%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/300], Step [212/225], Training Accuracy: 79.2158%, Training Loss: 0.4939%\n",
      "Epoch [46/300], Step [213/225], Training Accuracy: 79.1593%, Training Loss: 0.4947%\n",
      "Epoch [46/300], Step [214/225], Training Accuracy: 79.1983%, Training Loss: 0.4939%\n",
      "Epoch [46/300], Step [215/225], Training Accuracy: 79.2224%, Training Loss: 0.4935%\n",
      "Epoch [46/300], Step [216/225], Training Accuracy: 79.2245%, Training Loss: 0.4936%\n",
      "Epoch [46/300], Step [217/225], Training Accuracy: 79.1979%, Training Loss: 0.4936%\n",
      "Epoch [46/300], Step [218/225], Training Accuracy: 79.1858%, Training Loss: 0.4939%\n",
      "Epoch [46/300], Step [219/225], Training Accuracy: 79.1595%, Training Loss: 0.4943%\n",
      "Epoch [46/300], Step [220/225], Training Accuracy: 79.1832%, Training Loss: 0.4938%\n",
      "Epoch [46/300], Step [221/225], Training Accuracy: 79.1855%, Training Loss: 0.4936%\n",
      "Epoch [46/300], Step [222/225], Training Accuracy: 79.1878%, Training Loss: 0.4937%\n",
      "Epoch [46/300], Step [223/225], Training Accuracy: 79.1690%, Training Loss: 0.4939%\n",
      "Epoch [46/300], Step [224/225], Training Accuracy: 79.1783%, Training Loss: 0.4936%\n",
      "Epoch [46/300], Step [225/225], Training Accuracy: 79.1968%, Training Loss: 0.4934%\n",
      "Epoch [47/300], Step [1/225], Training Accuracy: 87.5000%, Training Loss: 0.4183%\n",
      "Epoch [47/300], Step [2/225], Training Accuracy: 82.0312%, Training Loss: 0.4548%\n",
      "Epoch [47/300], Step [3/225], Training Accuracy: 81.7708%, Training Loss: 0.4435%\n",
      "Epoch [47/300], Step [4/225], Training Accuracy: 80.8594%, Training Loss: 0.4525%\n",
      "Epoch [47/300], Step [5/225], Training Accuracy: 80.6250%, Training Loss: 0.4802%\n",
      "Epoch [47/300], Step [6/225], Training Accuracy: 79.6875%, Training Loss: 0.4982%\n",
      "Epoch [47/300], Step [7/225], Training Accuracy: 79.0179%, Training Loss: 0.4919%\n",
      "Epoch [47/300], Step [8/225], Training Accuracy: 78.5156%, Training Loss: 0.4999%\n",
      "Epoch [47/300], Step [9/225], Training Accuracy: 78.1250%, Training Loss: 0.5127%\n",
      "Epoch [47/300], Step [10/225], Training Accuracy: 77.5000%, Training Loss: 0.5188%\n",
      "Epoch [47/300], Step [11/225], Training Accuracy: 76.8466%, Training Loss: 0.5310%\n",
      "Epoch [47/300], Step [12/225], Training Accuracy: 76.8229%, Training Loss: 0.5261%\n",
      "Epoch [47/300], Step [13/225], Training Accuracy: 77.4038%, Training Loss: 0.5118%\n",
      "Epoch [47/300], Step [14/225], Training Accuracy: 77.2321%, Training Loss: 0.5120%\n",
      "Epoch [47/300], Step [15/225], Training Accuracy: 76.8750%, Training Loss: 0.5185%\n",
      "Epoch [47/300], Step [16/225], Training Accuracy: 77.3438%, Training Loss: 0.5203%\n",
      "Epoch [47/300], Step [17/225], Training Accuracy: 77.5735%, Training Loss: 0.5172%\n",
      "Epoch [47/300], Step [18/225], Training Accuracy: 77.8646%, Training Loss: 0.5139%\n",
      "Epoch [47/300], Step [19/225], Training Accuracy: 77.9605%, Training Loss: 0.5130%\n",
      "Epoch [47/300], Step [20/225], Training Accuracy: 78.2031%, Training Loss: 0.5091%\n",
      "Epoch [47/300], Step [21/225], Training Accuracy: 78.6458%, Training Loss: 0.5003%\n",
      "Epoch [47/300], Step [22/225], Training Accuracy: 78.6932%, Training Loss: 0.5059%\n",
      "Epoch [47/300], Step [23/225], Training Accuracy: 78.8723%, Training Loss: 0.5017%\n",
      "Epoch [47/300], Step [24/225], Training Accuracy: 78.8411%, Training Loss: 0.5011%\n",
      "Epoch [47/300], Step [25/225], Training Accuracy: 78.8125%, Training Loss: 0.4979%\n",
      "Epoch [47/300], Step [26/225], Training Accuracy: 78.7861%, Training Loss: 0.5004%\n",
      "Epoch [47/300], Step [27/225], Training Accuracy: 78.8194%, Training Loss: 0.4987%\n",
      "Epoch [47/300], Step [28/225], Training Accuracy: 78.8504%, Training Loss: 0.4956%\n",
      "Epoch [47/300], Step [29/225], Training Accuracy: 78.8793%, Training Loss: 0.4953%\n",
      "Epoch [47/300], Step [30/225], Training Accuracy: 79.0104%, Training Loss: 0.4933%\n",
      "Epoch [47/300], Step [31/225], Training Accuracy: 78.8306%, Training Loss: 0.4968%\n",
      "Epoch [47/300], Step [32/225], Training Accuracy: 78.7598%, Training Loss: 0.4949%\n",
      "Epoch [47/300], Step [33/225], Training Accuracy: 78.6458%, Training Loss: 0.4973%\n",
      "Epoch [47/300], Step [34/225], Training Accuracy: 78.4007%, Training Loss: 0.5046%\n",
      "Epoch [47/300], Step [35/225], Training Accuracy: 78.1696%, Training Loss: 0.5108%\n",
      "Epoch [47/300], Step [36/225], Training Accuracy: 78.1684%, Training Loss: 0.5131%\n",
      "Epoch [47/300], Step [37/225], Training Accuracy: 78.2939%, Training Loss: 0.5092%\n",
      "Epoch [47/300], Step [38/225], Training Accuracy: 78.2895%, Training Loss: 0.5084%\n",
      "Epoch [47/300], Step [39/225], Training Accuracy: 78.2853%, Training Loss: 0.5087%\n",
      "Epoch [47/300], Step [40/225], Training Accuracy: 78.2422%, Training Loss: 0.5094%\n",
      "Epoch [47/300], Step [41/225], Training Accuracy: 78.2012%, Training Loss: 0.5108%\n",
      "Epoch [47/300], Step [42/225], Training Accuracy: 78.1622%, Training Loss: 0.5107%\n",
      "Epoch [47/300], Step [43/225], Training Accuracy: 78.2703%, Training Loss: 0.5084%\n",
      "Epoch [47/300], Step [44/225], Training Accuracy: 78.2315%, Training Loss: 0.5083%\n",
      "Epoch [47/300], Step [45/225], Training Accuracy: 78.0903%, Training Loss: 0.5086%\n",
      "Epoch [47/300], Step [46/225], Training Accuracy: 78.2269%, Training Loss: 0.5062%\n",
      "Epoch [47/300], Step [47/225], Training Accuracy: 78.1582%, Training Loss: 0.5076%\n",
      "Epoch [47/300], Step [48/225], Training Accuracy: 78.0599%, Training Loss: 0.5101%\n",
      "Epoch [47/300], Step [49/225], Training Accuracy: 78.1888%, Training Loss: 0.5069%\n",
      "Epoch [47/300], Step [50/225], Training Accuracy: 78.1562%, Training Loss: 0.5074%\n",
      "Epoch [47/300], Step [51/225], Training Accuracy: 78.2782%, Training Loss: 0.5041%\n",
      "Epoch [47/300], Step [52/225], Training Accuracy: 78.3954%, Training Loss: 0.5004%\n",
      "Epoch [47/300], Step [53/225], Training Accuracy: 78.3019%, Training Loss: 0.5010%\n",
      "Epoch [47/300], Step [54/225], Training Accuracy: 78.2986%, Training Loss: 0.5008%\n",
      "Epoch [47/300], Step [55/225], Training Accuracy: 78.2670%, Training Loss: 0.5029%\n",
      "Epoch [47/300], Step [56/225], Training Accuracy: 78.2087%, Training Loss: 0.5028%\n",
      "Epoch [47/300], Step [57/225], Training Accuracy: 78.0702%, Training Loss: 0.5026%\n",
      "Epoch [47/300], Step [58/225], Training Accuracy: 78.1519%, Training Loss: 0.5015%\n",
      "Epoch [47/300], Step [59/225], Training Accuracy: 78.0985%, Training Loss: 0.5012%\n",
      "Epoch [47/300], Step [60/225], Training Accuracy: 78.1771%, Training Loss: 0.5015%\n",
      "Epoch [47/300], Step [61/225], Training Accuracy: 78.0738%, Training Loss: 0.5038%\n",
      "Epoch [47/300], Step [62/225], Training Accuracy: 78.0494%, Training Loss: 0.5050%\n",
      "Epoch [47/300], Step [63/225], Training Accuracy: 78.1250%, Training Loss: 0.5041%\n",
      "Epoch [47/300], Step [64/225], Training Accuracy: 78.1494%, Training Loss: 0.5029%\n",
      "Epoch [47/300], Step [65/225], Training Accuracy: 78.1490%, Training Loss: 0.5053%\n",
      "Epoch [47/300], Step [66/225], Training Accuracy: 78.2434%, Training Loss: 0.5047%\n",
      "Epoch [47/300], Step [67/225], Training Accuracy: 78.3116%, Training Loss: 0.5029%\n",
      "Epoch [47/300], Step [68/225], Training Accuracy: 78.3778%, Training Loss: 0.5032%\n",
      "Epoch [47/300], Step [69/225], Training Accuracy: 78.4194%, Training Loss: 0.5040%\n",
      "Epoch [47/300], Step [70/225], Training Accuracy: 78.3259%, Training Loss: 0.5041%\n",
      "Epoch [47/300], Step [71/225], Training Accuracy: 78.2350%, Training Loss: 0.5043%\n",
      "Epoch [47/300], Step [72/225], Training Accuracy: 78.2986%, Training Loss: 0.5031%\n",
      "Epoch [47/300], Step [73/225], Training Accuracy: 78.3176%, Training Loss: 0.5022%\n",
      "Epoch [47/300], Step [74/225], Training Accuracy: 78.4840%, Training Loss: 0.4990%\n",
      "Epoch [47/300], Step [75/225], Training Accuracy: 78.5000%, Training Loss: 0.4981%\n",
      "Epoch [47/300], Step [76/225], Training Accuracy: 78.4128%, Training Loss: 0.4994%\n",
      "Epoch [47/300], Step [77/225], Training Accuracy: 78.4294%, Training Loss: 0.4995%\n",
      "Epoch [47/300], Step [78/225], Training Accuracy: 78.4255%, Training Loss: 0.4988%\n",
      "Epoch [47/300], Step [79/225], Training Accuracy: 78.5206%, Training Loss: 0.4971%\n",
      "Epoch [47/300], Step [80/225], Training Accuracy: 78.5938%, Training Loss: 0.4958%\n",
      "Epoch [47/300], Step [81/225], Training Accuracy: 78.7037%, Training Loss: 0.4941%\n",
      "Epoch [47/300], Step [82/225], Training Accuracy: 78.7157%, Training Loss: 0.4934%\n",
      "Epoch [47/300], Step [83/225], Training Accuracy: 78.7086%, Training Loss: 0.4945%\n",
      "Epoch [47/300], Step [84/225], Training Accuracy: 78.7946%, Training Loss: 0.4932%\n",
      "Epoch [47/300], Step [85/225], Training Accuracy: 78.8419%, Training Loss: 0.4920%\n",
      "Epoch [47/300], Step [86/225], Training Accuracy: 78.8517%, Training Loss: 0.4921%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/300], Step [87/225], Training Accuracy: 78.7716%, Training Loss: 0.4937%\n",
      "Epoch [47/300], Step [88/225], Training Accuracy: 78.6754%, Training Loss: 0.4960%\n",
      "Epoch [47/300], Step [89/225], Training Accuracy: 78.7746%, Training Loss: 0.4951%\n",
      "Epoch [47/300], Step [90/225], Training Accuracy: 78.7153%, Training Loss: 0.4954%\n",
      "Epoch [47/300], Step [91/225], Training Accuracy: 78.7088%, Training Loss: 0.4949%\n",
      "Epoch [47/300], Step [92/225], Training Accuracy: 78.7534%, Training Loss: 0.4957%\n",
      "Epoch [47/300], Step [93/225], Training Accuracy: 78.8474%, Training Loss: 0.4951%\n",
      "Epoch [47/300], Step [94/225], Training Accuracy: 78.8231%, Training Loss: 0.4949%\n",
      "Epoch [47/300], Step [95/225], Training Accuracy: 78.8322%, Training Loss: 0.4952%\n",
      "Epoch [47/300], Step [96/225], Training Accuracy: 78.9225%, Training Loss: 0.4933%\n",
      "Epoch [47/300], Step [97/225], Training Accuracy: 78.9626%, Training Loss: 0.4918%\n",
      "Epoch [47/300], Step [98/225], Training Accuracy: 78.9222%, Training Loss: 0.4920%\n",
      "Epoch [47/300], Step [99/225], Training Accuracy: 79.0404%, Training Loss: 0.4916%\n",
      "Epoch [47/300], Step [100/225], Training Accuracy: 78.9688%, Training Loss: 0.4932%\n",
      "Epoch [47/300], Step [101/225], Training Accuracy: 79.0377%, Training Loss: 0.4916%\n",
      "Epoch [47/300], Step [102/225], Training Accuracy: 78.9828%, Training Loss: 0.4935%\n",
      "Epoch [47/300], Step [103/225], Training Accuracy: 78.9897%, Training Loss: 0.4936%\n",
      "Epoch [47/300], Step [104/225], Training Accuracy: 78.9363%, Training Loss: 0.4939%\n",
      "Epoch [47/300], Step [105/225], Training Accuracy: 78.9286%, Training Loss: 0.4949%\n",
      "Epoch [47/300], Step [106/225], Training Accuracy: 78.9652%, Training Loss: 0.4945%\n",
      "Epoch [47/300], Step [107/225], Training Accuracy: 78.8843%, Training Loss: 0.4958%\n",
      "Epoch [47/300], Step [108/225], Training Accuracy: 78.9497%, Training Loss: 0.4949%\n",
      "Epoch [47/300], Step [109/225], Training Accuracy: 78.9994%, Training Loss: 0.4949%\n",
      "Epoch [47/300], Step [110/225], Training Accuracy: 79.0199%, Training Loss: 0.4940%\n",
      "Epoch [47/300], Step [111/225], Training Accuracy: 79.0681%, Training Loss: 0.4939%\n",
      "Epoch [47/300], Step [112/225], Training Accuracy: 79.1155%, Training Loss: 0.4932%\n",
      "Epoch [47/300], Step [113/225], Training Accuracy: 79.1206%, Training Loss: 0.4928%\n",
      "Epoch [47/300], Step [114/225], Training Accuracy: 79.0981%, Training Loss: 0.4932%\n",
      "Epoch [47/300], Step [115/225], Training Accuracy: 79.1168%, Training Loss: 0.4929%\n",
      "Epoch [47/300], Step [116/225], Training Accuracy: 79.1756%, Training Loss: 0.4922%\n",
      "Epoch [47/300], Step [117/225], Training Accuracy: 79.1667%, Training Loss: 0.4925%\n",
      "Epoch [47/300], Step [118/225], Training Accuracy: 79.2108%, Training Loss: 0.4912%\n",
      "Epoch [47/300], Step [119/225], Training Accuracy: 79.2148%, Training Loss: 0.4909%\n",
      "Epoch [47/300], Step [120/225], Training Accuracy: 79.2057%, Training Loss: 0.4909%\n",
      "Epoch [47/300], Step [121/225], Training Accuracy: 79.2743%, Training Loss: 0.4900%\n",
      "Epoch [47/300], Step [122/225], Training Accuracy: 79.2520%, Training Loss: 0.4904%\n",
      "Epoch [47/300], Step [123/225], Training Accuracy: 79.2937%, Training Loss: 0.4891%\n",
      "Epoch [47/300], Step [124/225], Training Accuracy: 79.3221%, Training Loss: 0.4886%\n",
      "Epoch [47/300], Step [125/225], Training Accuracy: 79.3500%, Training Loss: 0.4883%\n",
      "Epoch [47/300], Step [126/225], Training Accuracy: 79.3155%, Training Loss: 0.4883%\n",
      "Epoch [47/300], Step [127/225], Training Accuracy: 79.3553%, Training Loss: 0.4880%\n",
      "Epoch [47/300], Step [128/225], Training Accuracy: 79.3579%, Training Loss: 0.4881%\n",
      "Epoch [47/300], Step [129/225], Training Accuracy: 79.3847%, Training Loss: 0.4878%\n",
      "Epoch [47/300], Step [130/225], Training Accuracy: 79.3870%, Training Loss: 0.4872%\n",
      "Epoch [47/300], Step [131/225], Training Accuracy: 79.3774%, Training Loss: 0.4876%\n",
      "Epoch [47/300], Step [132/225], Training Accuracy: 79.3087%, Training Loss: 0.4877%\n",
      "Epoch [47/300], Step [133/225], Training Accuracy: 79.3233%, Training Loss: 0.4873%\n",
      "Epoch [47/300], Step [134/225], Training Accuracy: 79.2561%, Training Loss: 0.4892%\n",
      "Epoch [47/300], Step [135/225], Training Accuracy: 79.2130%, Training Loss: 0.4900%\n",
      "Epoch [47/300], Step [136/225], Training Accuracy: 79.2165%, Training Loss: 0.4895%\n",
      "Epoch [47/300], Step [137/225], Training Accuracy: 79.2313%, Training Loss: 0.4890%\n",
      "Epoch [47/300], Step [138/225], Training Accuracy: 79.3025%, Training Loss: 0.4877%\n",
      "Epoch [47/300], Step [139/225], Training Accuracy: 79.2716%, Training Loss: 0.4882%\n",
      "Epoch [47/300], Step [140/225], Training Accuracy: 79.3415%, Training Loss: 0.4874%\n",
      "Epoch [47/300], Step [141/225], Training Accuracy: 79.3661%, Training Loss: 0.4871%\n",
      "Epoch [47/300], Step [142/225], Training Accuracy: 79.3574%, Training Loss: 0.4866%\n",
      "Epoch [47/300], Step [143/225], Training Accuracy: 79.3051%, Training Loss: 0.4868%\n",
      "Epoch [47/300], Step [144/225], Training Accuracy: 79.3403%, Training Loss: 0.4863%\n",
      "Epoch [47/300], Step [145/225], Training Accuracy: 79.3750%, Training Loss: 0.4861%\n",
      "Epoch [47/300], Step [146/225], Training Accuracy: 79.3450%, Training Loss: 0.4865%\n",
      "Epoch [47/300], Step [147/225], Training Accuracy: 79.3686%, Training Loss: 0.4864%\n",
      "Epoch [47/300], Step [148/225], Training Accuracy: 79.4447%, Training Loss: 0.4848%\n",
      "Epoch [47/300], Step [149/225], Training Accuracy: 79.4568%, Training Loss: 0.4845%\n",
      "Epoch [47/300], Step [150/225], Training Accuracy: 79.5208%, Training Loss: 0.4833%\n",
      "Epoch [47/300], Step [151/225], Training Accuracy: 79.5219%, Training Loss: 0.4831%\n",
      "Epoch [47/300], Step [152/225], Training Accuracy: 79.4716%, Training Loss: 0.4836%\n",
      "Epoch [47/300], Step [153/225], Training Accuracy: 79.4935%, Training Loss: 0.4831%\n",
      "Epoch [47/300], Step [154/225], Training Accuracy: 79.4846%, Training Loss: 0.4828%\n",
      "Epoch [47/300], Step [155/225], Training Accuracy: 79.5262%, Training Loss: 0.4825%\n",
      "Epoch [47/300], Step [156/225], Training Accuracy: 79.5172%, Training Loss: 0.4830%\n",
      "Epoch [47/300], Step [157/225], Training Accuracy: 79.5183%, Training Loss: 0.4827%\n",
      "Epoch [47/300], Step [158/225], Training Accuracy: 79.4897%, Training Loss: 0.4837%\n",
      "Epoch [47/300], Step [159/225], Training Accuracy: 79.4615%, Training Loss: 0.4839%\n",
      "Epoch [47/300], Step [160/225], Training Accuracy: 79.4531%, Training Loss: 0.4835%\n",
      "Epoch [47/300], Step [161/225], Training Accuracy: 79.4352%, Training Loss: 0.4844%\n",
      "Epoch [47/300], Step [162/225], Training Accuracy: 79.4271%, Training Loss: 0.4850%\n",
      "Epoch [47/300], Step [163/225], Training Accuracy: 79.4479%, Training Loss: 0.4846%\n",
      "Epoch [47/300], Step [164/225], Training Accuracy: 79.4684%, Training Loss: 0.4838%\n",
      "Epoch [47/300], Step [165/225], Training Accuracy: 79.4508%, Training Loss: 0.4844%\n",
      "Epoch [47/300], Step [166/225], Training Accuracy: 79.4428%, Training Loss: 0.4840%\n",
      "Epoch [47/300], Step [167/225], Training Accuracy: 79.4536%, Training Loss: 0.4841%\n",
      "Epoch [47/300], Step [168/225], Training Accuracy: 79.4178%, Training Loss: 0.4853%\n",
      "Epoch [47/300], Step [169/225], Training Accuracy: 79.4564%, Training Loss: 0.4855%\n",
      "Epoch [47/300], Step [170/225], Training Accuracy: 79.4669%, Training Loss: 0.4849%\n",
      "Epoch [47/300], Step [171/225], Training Accuracy: 79.4408%, Training Loss: 0.4862%\n",
      "Epoch [47/300], Step [172/225], Training Accuracy: 79.4150%, Training Loss: 0.4866%\n",
      "Epoch [47/300], Step [173/225], Training Accuracy: 79.4075%, Training Loss: 0.4867%\n",
      "Epoch [47/300], Step [174/225], Training Accuracy: 79.3912%, Training Loss: 0.4871%\n",
      "Epoch [47/300], Step [175/225], Training Accuracy: 79.3839%, Training Loss: 0.4872%\n",
      "Epoch [47/300], Step [176/225], Training Accuracy: 79.4034%, Training Loss: 0.4867%\n",
      "Epoch [47/300], Step [177/225], Training Accuracy: 79.3520%, Training Loss: 0.4879%\n",
      "Epoch [47/300], Step [178/225], Training Accuracy: 79.3276%, Training Loss: 0.4885%\n",
      "Epoch [47/300], Step [179/225], Training Accuracy: 79.3296%, Training Loss: 0.4883%\n",
      "Epoch [47/300], Step [180/225], Training Accuracy: 79.3142%, Training Loss: 0.4883%\n",
      "Epoch [47/300], Step [181/225], Training Accuracy: 79.3249%, Training Loss: 0.4884%\n",
      "Epoch [47/300], Step [182/225], Training Accuracy: 79.3183%, Training Loss: 0.4886%\n",
      "Epoch [47/300], Step [183/225], Training Accuracy: 79.3289%, Training Loss: 0.4888%\n",
      "Epoch [47/300], Step [184/225], Training Accuracy: 79.3478%, Training Loss: 0.4882%\n",
      "Epoch [47/300], Step [185/225], Training Accuracy: 79.3750%, Training Loss: 0.4878%\n",
      "Epoch [47/300], Step [186/225], Training Accuracy: 79.4019%, Training Loss: 0.4871%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/300], Step [187/225], Training Accuracy: 79.3783%, Training Loss: 0.4876%\n",
      "Epoch [47/300], Step [188/225], Training Accuracy: 79.4215%, Training Loss: 0.4871%\n",
      "Epoch [47/300], Step [189/225], Training Accuracy: 79.3981%, Training Loss: 0.4873%\n",
      "Epoch [47/300], Step [190/225], Training Accuracy: 79.3914%, Training Loss: 0.4875%\n",
      "Epoch [47/300], Step [191/225], Training Accuracy: 79.3848%, Training Loss: 0.4879%\n",
      "Epoch [47/300], Step [192/225], Training Accuracy: 79.4271%, Training Loss: 0.4871%\n",
      "Epoch [47/300], Step [193/225], Training Accuracy: 79.4203%, Training Loss: 0.4870%\n",
      "Epoch [47/300], Step [194/225], Training Accuracy: 79.4298%, Training Loss: 0.4871%\n",
      "Epoch [47/300], Step [195/225], Training Accuracy: 79.4712%, Training Loss: 0.4863%\n",
      "Epoch [47/300], Step [196/225], Training Accuracy: 79.4643%, Training Loss: 0.4866%\n",
      "Epoch [47/300], Step [197/225], Training Accuracy: 79.4099%, Training Loss: 0.4879%\n",
      "Epoch [47/300], Step [198/225], Training Accuracy: 79.3797%, Training Loss: 0.4880%\n",
      "Epoch [47/300], Step [199/225], Training Accuracy: 79.3970%, Training Loss: 0.4876%\n",
      "Epoch [47/300], Step [200/225], Training Accuracy: 79.3984%, Training Loss: 0.4876%\n",
      "Epoch [47/300], Step [201/225], Training Accuracy: 79.3999%, Training Loss: 0.4873%\n",
      "Epoch [47/300], Step [202/225], Training Accuracy: 79.4013%, Training Loss: 0.4875%\n",
      "Epoch [47/300], Step [203/225], Training Accuracy: 79.4335%, Training Loss: 0.4869%\n",
      "Epoch [47/300], Step [204/225], Training Accuracy: 79.4577%, Training Loss: 0.4862%\n",
      "Epoch [47/300], Step [205/225], Training Accuracy: 79.4665%, Training Loss: 0.4862%\n",
      "Epoch [47/300], Step [206/225], Training Accuracy: 79.4751%, Training Loss: 0.4861%\n",
      "Epoch [47/300], Step [207/225], Training Accuracy: 79.4611%, Training Loss: 0.4859%\n",
      "Epoch [47/300], Step [208/225], Training Accuracy: 79.4697%, Training Loss: 0.4857%\n",
      "Epoch [47/300], Step [209/225], Training Accuracy: 79.4258%, Training Loss: 0.4860%\n",
      "Epoch [47/300], Step [210/225], Training Accuracy: 79.4122%, Training Loss: 0.4862%\n",
      "Epoch [47/300], Step [211/225], Training Accuracy: 79.3765%, Training Loss: 0.4868%\n",
      "Epoch [47/300], Step [212/225], Training Accuracy: 79.3779%, Training Loss: 0.4867%\n",
      "Epoch [47/300], Step [213/225], Training Accuracy: 79.4014%, Training Loss: 0.4863%\n",
      "Epoch [47/300], Step [214/225], Training Accuracy: 79.4173%, Training Loss: 0.4857%\n",
      "Epoch [47/300], Step [215/225], Training Accuracy: 79.3750%, Training Loss: 0.4867%\n",
      "Epoch [47/300], Step [216/225], Training Accuracy: 79.3041%, Training Loss: 0.4878%\n",
      "Epoch [47/300], Step [217/225], Training Accuracy: 79.3131%, Training Loss: 0.4877%\n",
      "Epoch [47/300], Step [218/225], Training Accuracy: 79.2646%, Training Loss: 0.4888%\n",
      "Epoch [47/300], Step [219/225], Training Accuracy: 79.2309%, Training Loss: 0.4888%\n",
      "Epoch [47/300], Step [220/225], Training Accuracy: 79.2472%, Training Loss: 0.4884%\n",
      "Epoch [47/300], Step [221/225], Training Accuracy: 79.2562%, Training Loss: 0.4883%\n",
      "Epoch [47/300], Step [222/225], Training Accuracy: 79.2793%, Training Loss: 0.4881%\n",
      "Epoch [47/300], Step [223/225], Training Accuracy: 79.2671%, Training Loss: 0.4881%\n",
      "Epoch [47/300], Step [224/225], Training Accuracy: 79.3178%, Training Loss: 0.4872%\n",
      "Epoch [47/300], Step [225/225], Training Accuracy: 79.3218%, Training Loss: 0.4874%\n",
      "Epoch [48/300], Step [1/225], Training Accuracy: 82.8125%, Training Loss: 0.3722%\n",
      "Epoch [48/300], Step [2/225], Training Accuracy: 81.2500%, Training Loss: 0.4122%\n",
      "Epoch [48/300], Step [3/225], Training Accuracy: 79.6875%, Training Loss: 0.4985%\n",
      "Epoch [48/300], Step [4/225], Training Accuracy: 79.6875%, Training Loss: 0.4832%\n",
      "Epoch [48/300], Step [5/225], Training Accuracy: 81.5625%, Training Loss: 0.4602%\n",
      "Epoch [48/300], Step [6/225], Training Accuracy: 80.4688%, Training Loss: 0.4593%\n",
      "Epoch [48/300], Step [7/225], Training Accuracy: 80.8036%, Training Loss: 0.4495%\n",
      "Epoch [48/300], Step [8/225], Training Accuracy: 80.8594%, Training Loss: 0.4506%\n",
      "Epoch [48/300], Step [9/225], Training Accuracy: 81.0764%, Training Loss: 0.4541%\n",
      "Epoch [48/300], Step [10/225], Training Accuracy: 80.6250%, Training Loss: 0.4658%\n",
      "Epoch [48/300], Step [11/225], Training Accuracy: 80.5398%, Training Loss: 0.4724%\n",
      "Epoch [48/300], Step [12/225], Training Accuracy: 80.5990%, Training Loss: 0.4702%\n",
      "Epoch [48/300], Step [13/225], Training Accuracy: 80.8894%, Training Loss: 0.4599%\n",
      "Epoch [48/300], Step [14/225], Training Accuracy: 80.9152%, Training Loss: 0.4622%\n",
      "Epoch [48/300], Step [15/225], Training Accuracy: 80.9375%, Training Loss: 0.4649%\n",
      "Epoch [48/300], Step [16/225], Training Accuracy: 81.2500%, Training Loss: 0.4624%\n",
      "Epoch [48/300], Step [17/225], Training Accuracy: 81.1581%, Training Loss: 0.4594%\n",
      "Epoch [48/300], Step [18/225], Training Accuracy: 81.1632%, Training Loss: 0.4595%\n",
      "Epoch [48/300], Step [19/225], Training Accuracy: 81.2500%, Training Loss: 0.4625%\n",
      "Epoch [48/300], Step [20/225], Training Accuracy: 81.1719%, Training Loss: 0.4614%\n",
      "Epoch [48/300], Step [21/225], Training Accuracy: 81.4732%, Training Loss: 0.4554%\n",
      "Epoch [48/300], Step [22/225], Training Accuracy: 81.3920%, Training Loss: 0.4581%\n",
      "Epoch [48/300], Step [23/225], Training Accuracy: 81.5217%, Training Loss: 0.4590%\n",
      "Epoch [48/300], Step [24/225], Training Accuracy: 81.3151%, Training Loss: 0.4629%\n",
      "Epoch [48/300], Step [25/225], Training Accuracy: 81.2500%, Training Loss: 0.4627%\n",
      "Epoch [48/300], Step [26/225], Training Accuracy: 81.0096%, Training Loss: 0.4629%\n",
      "Epoch [48/300], Step [27/225], Training Accuracy: 81.0185%, Training Loss: 0.4636%\n",
      "Epoch [48/300], Step [28/225], Training Accuracy: 81.1384%, Training Loss: 0.4597%\n",
      "Epoch [48/300], Step [29/225], Training Accuracy: 80.9806%, Training Loss: 0.4575%\n",
      "Epoch [48/300], Step [30/225], Training Accuracy: 80.9375%, Training Loss: 0.4552%\n",
      "Epoch [48/300], Step [31/225], Training Accuracy: 80.6956%, Training Loss: 0.4580%\n",
      "Epoch [48/300], Step [32/225], Training Accuracy: 80.7617%, Training Loss: 0.4564%\n",
      "Epoch [48/300], Step [33/225], Training Accuracy: 80.7765%, Training Loss: 0.4565%\n",
      "Epoch [48/300], Step [34/225], Training Accuracy: 80.3309%, Training Loss: 0.4670%\n",
      "Epoch [48/300], Step [35/225], Training Accuracy: 80.3571%, Training Loss: 0.4679%\n",
      "Epoch [48/300], Step [36/225], Training Accuracy: 80.2083%, Training Loss: 0.4755%\n",
      "Epoch [48/300], Step [37/225], Training Accuracy: 80.2787%, Training Loss: 0.4728%\n",
      "Epoch [48/300], Step [38/225], Training Accuracy: 80.1809%, Training Loss: 0.4759%\n",
      "Epoch [48/300], Step [39/225], Training Accuracy: 79.9279%, Training Loss: 0.4802%\n",
      "Epoch [48/300], Step [40/225], Training Accuracy: 79.9219%, Training Loss: 0.4806%\n",
      "Epoch [48/300], Step [41/225], Training Accuracy: 79.6113%, Training Loss: 0.4850%\n",
      "Epoch [48/300], Step [42/225], Training Accuracy: 79.6131%, Training Loss: 0.4854%\n",
      "Epoch [48/300], Step [43/225], Training Accuracy: 79.6875%, Training Loss: 0.4836%\n",
      "Epoch [48/300], Step [44/225], Training Accuracy: 79.6165%, Training Loss: 0.4830%\n",
      "Epoch [48/300], Step [45/225], Training Accuracy: 79.4792%, Training Loss: 0.4853%\n",
      "Epoch [48/300], Step [46/225], Training Accuracy: 79.4497%, Training Loss: 0.4844%\n",
      "Epoch [48/300], Step [47/225], Training Accuracy: 79.2221%, Training Loss: 0.4864%\n",
      "Epoch [48/300], Step [48/225], Training Accuracy: 79.1341%, Training Loss: 0.4885%\n",
      "Epoch [48/300], Step [49/225], Training Accuracy: 79.3048%, Training Loss: 0.4866%\n",
      "Epoch [48/300], Step [50/225], Training Accuracy: 79.3750%, Training Loss: 0.4856%\n",
      "Epoch [48/300], Step [51/225], Training Accuracy: 79.3505%, Training Loss: 0.4843%\n",
      "Epoch [48/300], Step [52/225], Training Accuracy: 79.5072%, Training Loss: 0.4824%\n",
      "Epoch [48/300], Step [53/225], Training Accuracy: 79.4222%, Training Loss: 0.4860%\n",
      "Epoch [48/300], Step [54/225], Training Accuracy: 79.3692%, Training Loss: 0.4894%\n",
      "Epoch [48/300], Step [55/225], Training Accuracy: 79.2898%, Training Loss: 0.4926%\n",
      "Epoch [48/300], Step [56/225], Training Accuracy: 79.3248%, Training Loss: 0.4907%\n",
      "Epoch [48/300], Step [57/225], Training Accuracy: 79.2763%, Training Loss: 0.4907%\n",
      "Epoch [48/300], Step [58/225], Training Accuracy: 79.3642%, Training Loss: 0.4895%\n",
      "Epoch [48/300], Step [59/225], Training Accuracy: 79.2373%, Training Loss: 0.4914%\n",
      "Epoch [48/300], Step [60/225], Training Accuracy: 79.1146%, Training Loss: 0.4948%\n",
      "Epoch [48/300], Step [61/225], Training Accuracy: 79.1752%, Training Loss: 0.4957%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/300], Step [62/225], Training Accuracy: 79.2087%, Training Loss: 0.4966%\n",
      "Epoch [48/300], Step [63/225], Training Accuracy: 79.1667%, Training Loss: 0.4977%\n",
      "Epoch [48/300], Step [64/225], Training Accuracy: 79.2236%, Training Loss: 0.4978%\n",
      "Epoch [48/300], Step [65/225], Training Accuracy: 79.1106%, Training Loss: 0.4983%\n",
      "Epoch [48/300], Step [66/225], Training Accuracy: 79.1903%, Training Loss: 0.4962%\n",
      "Epoch [48/300], Step [67/225], Training Accuracy: 79.1978%, Training Loss: 0.4964%\n",
      "Epoch [48/300], Step [68/225], Training Accuracy: 79.2739%, Training Loss: 0.4951%\n",
      "Epoch [48/300], Step [69/225], Training Accuracy: 79.2799%, Training Loss: 0.4937%\n",
      "Epoch [48/300], Step [70/225], Training Accuracy: 79.2857%, Training Loss: 0.4935%\n",
      "Epoch [48/300], Step [71/225], Training Accuracy: 79.2694%, Training Loss: 0.4947%\n",
      "Epoch [48/300], Step [72/225], Training Accuracy: 79.2101%, Training Loss: 0.4965%\n",
      "Epoch [48/300], Step [73/225], Training Accuracy: 79.1952%, Training Loss: 0.4958%\n",
      "Epoch [48/300], Step [74/225], Training Accuracy: 79.3285%, Training Loss: 0.4939%\n",
      "Epoch [48/300], Step [75/225], Training Accuracy: 79.2500%, Training Loss: 0.4959%\n",
      "Epoch [48/300], Step [76/225], Training Accuracy: 79.0913%, Training Loss: 0.4978%\n",
      "Epoch [48/300], Step [77/225], Training Accuracy: 78.9367%, Training Loss: 0.5003%\n",
      "Epoch [48/300], Step [78/225], Training Accuracy: 78.9263%, Training Loss: 0.4998%\n",
      "Epoch [48/300], Step [79/225], Training Accuracy: 79.0546%, Training Loss: 0.4986%\n",
      "Epoch [48/300], Step [80/225], Training Accuracy: 79.0234%, Training Loss: 0.4988%\n",
      "Epoch [48/300], Step [81/225], Training Accuracy: 79.1474%, Training Loss: 0.4979%\n",
      "Epoch [48/300], Step [82/225], Training Accuracy: 79.1921%, Training Loss: 0.4971%\n",
      "Epoch [48/300], Step [83/225], Training Accuracy: 79.1604%, Training Loss: 0.4974%\n",
      "Epoch [48/300], Step [84/225], Training Accuracy: 79.2411%, Training Loss: 0.4959%\n",
      "Epoch [48/300], Step [85/225], Training Accuracy: 79.2096%, Training Loss: 0.4961%\n",
      "Epoch [48/300], Step [86/225], Training Accuracy: 79.3060%, Training Loss: 0.4955%\n",
      "Epoch [48/300], Step [87/225], Training Accuracy: 79.2385%, Training Loss: 0.4961%\n",
      "Epoch [48/300], Step [88/225], Training Accuracy: 79.1726%, Training Loss: 0.4975%\n",
      "Epoch [48/300], Step [89/225], Training Accuracy: 79.1784%, Training Loss: 0.4972%\n",
      "Epoch [48/300], Step [90/225], Training Accuracy: 79.0278%, Training Loss: 0.4999%\n",
      "Epoch [48/300], Step [91/225], Training Accuracy: 79.0350%, Training Loss: 0.4991%\n",
      "Epoch [48/300], Step [92/225], Training Accuracy: 79.0251%, Training Loss: 0.4994%\n",
      "Epoch [48/300], Step [93/225], Training Accuracy: 79.0827%, Training Loss: 0.4981%\n",
      "Epoch [48/300], Step [94/225], Training Accuracy: 79.0226%, Training Loss: 0.4996%\n",
      "Epoch [48/300], Step [95/225], Training Accuracy: 78.9967%, Training Loss: 0.4994%\n",
      "Epoch [48/300], Step [96/225], Training Accuracy: 79.0365%, Training Loss: 0.4986%\n",
      "Epoch [48/300], Step [97/225], Training Accuracy: 79.0593%, Training Loss: 0.4982%\n",
      "Epoch [48/300], Step [98/225], Training Accuracy: 79.0179%, Training Loss: 0.4988%\n",
      "Epoch [48/300], Step [99/225], Training Accuracy: 79.0404%, Training Loss: 0.4986%\n",
      "Epoch [48/300], Step [100/225], Training Accuracy: 79.0469%, Training Loss: 0.4987%\n",
      "Epoch [48/300], Step [101/225], Training Accuracy: 79.0223%, Training Loss: 0.4991%\n",
      "Epoch [48/300], Step [102/225], Training Accuracy: 79.0748%, Training Loss: 0.5000%\n",
      "Epoch [48/300], Step [103/225], Training Accuracy: 79.1110%, Training Loss: 0.4995%\n",
      "Epoch [48/300], Step [104/225], Training Accuracy: 78.9964%, Training Loss: 0.5009%\n",
      "Epoch [48/300], Step [105/225], Training Accuracy: 79.0476%, Training Loss: 0.4993%\n",
      "Epoch [48/300], Step [106/225], Training Accuracy: 78.9652%, Training Loss: 0.5002%\n",
      "Epoch [48/300], Step [107/225], Training Accuracy: 78.9720%, Training Loss: 0.4997%\n",
      "Epoch [48/300], Step [108/225], Training Accuracy: 78.9641%, Training Loss: 0.4996%\n",
      "Epoch [48/300], Step [109/225], Training Accuracy: 78.9564%, Training Loss: 0.4995%\n",
      "Epoch [48/300], Step [110/225], Training Accuracy: 78.9773%, Training Loss: 0.4990%\n",
      "Epoch [48/300], Step [111/225], Training Accuracy: 78.9837%, Training Loss: 0.4994%\n",
      "Epoch [48/300], Step [112/225], Training Accuracy: 78.9621%, Training Loss: 0.5001%\n",
      "Epoch [48/300], Step [113/225], Training Accuracy: 78.9685%, Training Loss: 0.4994%\n",
      "Epoch [48/300], Step [114/225], Training Accuracy: 79.0022%, Training Loss: 0.4986%\n",
      "Epoch [48/300], Step [115/225], Training Accuracy: 79.0082%, Training Loss: 0.4992%\n",
      "Epoch [48/300], Step [116/225], Training Accuracy: 79.0275%, Training Loss: 0.4989%\n",
      "Epoch [48/300], Step [117/225], Training Accuracy: 79.0198%, Training Loss: 0.4997%\n",
      "Epoch [48/300], Step [118/225], Training Accuracy: 79.0254%, Training Loss: 0.4993%\n",
      "Epoch [48/300], Step [119/225], Training Accuracy: 78.9653%, Training Loss: 0.4994%\n",
      "Epoch [48/300], Step [120/225], Training Accuracy: 78.9453%, Training Loss: 0.4996%\n",
      "Epoch [48/300], Step [121/225], Training Accuracy: 78.8611%, Training Loss: 0.5010%\n",
      "Epoch [48/300], Step [122/225], Training Accuracy: 78.8294%, Training Loss: 0.5015%\n",
      "Epoch [48/300], Step [123/225], Training Accuracy: 78.8110%, Training Loss: 0.5016%\n",
      "Epoch [48/300], Step [124/225], Training Accuracy: 78.8432%, Training Loss: 0.5017%\n",
      "Epoch [48/300], Step [125/225], Training Accuracy: 78.9125%, Training Loss: 0.5004%\n",
      "Epoch [48/300], Step [126/225], Training Accuracy: 78.9062%, Training Loss: 0.5008%\n",
      "Epoch [48/300], Step [127/225], Training Accuracy: 78.9124%, Training Loss: 0.5014%\n",
      "Epoch [48/300], Step [128/225], Training Accuracy: 78.8818%, Training Loss: 0.5013%\n",
      "Epoch [48/300], Step [129/225], Training Accuracy: 78.9002%, Training Loss: 0.5026%\n",
      "Epoch [48/300], Step [130/225], Training Accuracy: 78.8822%, Training Loss: 0.5036%\n",
      "Epoch [48/300], Step [131/225], Training Accuracy: 78.8526%, Training Loss: 0.5041%\n",
      "Epoch [48/300], Step [132/225], Training Accuracy: 78.8471%, Training Loss: 0.5038%\n",
      "Epoch [48/300], Step [133/225], Training Accuracy: 78.8416%, Training Loss: 0.5039%\n",
      "Epoch [48/300], Step [134/225], Training Accuracy: 78.8013%, Training Loss: 0.5049%\n",
      "Epoch [48/300], Step [135/225], Training Accuracy: 78.7963%, Training Loss: 0.5051%\n",
      "Epoch [48/300], Step [136/225], Training Accuracy: 78.8488%, Training Loss: 0.5050%\n",
      "Epoch [48/300], Step [137/225], Training Accuracy: 78.8663%, Training Loss: 0.5045%\n",
      "Epoch [48/300], Step [138/225], Training Accuracy: 78.8723%, Training Loss: 0.5035%\n",
      "Epoch [48/300], Step [139/225], Training Accuracy: 78.8781%, Training Loss: 0.5033%\n",
      "Epoch [48/300], Step [140/225], Training Accuracy: 78.8504%, Training Loss: 0.5047%\n",
      "Epoch [48/300], Step [141/225], Training Accuracy: 78.8342%, Training Loss: 0.5061%\n",
      "Epoch [48/300], Step [142/225], Training Accuracy: 78.8622%, Training Loss: 0.5059%\n",
      "Epoch [48/300], Step [143/225], Training Accuracy: 78.8462%, Training Loss: 0.5068%\n",
      "Epoch [48/300], Step [144/225], Training Accuracy: 78.8194%, Training Loss: 0.5074%\n",
      "Epoch [48/300], Step [145/225], Training Accuracy: 78.8147%, Training Loss: 0.5090%\n",
      "Epoch [48/300], Step [146/225], Training Accuracy: 78.8420%, Training Loss: 0.5100%\n",
      "Epoch [48/300], Step [147/225], Training Accuracy: 78.8478%, Training Loss: 0.5099%\n",
      "Epoch [48/300], Step [148/225], Training Accuracy: 78.8746%, Training Loss: 0.5091%\n",
      "Epoch [48/300], Step [149/225], Training Accuracy: 78.8905%, Training Loss: 0.5087%\n",
      "Epoch [48/300], Step [150/225], Training Accuracy: 78.9271%, Training Loss: 0.5080%\n",
      "Epoch [48/300], Step [151/225], Training Accuracy: 78.9321%, Training Loss: 0.5080%\n",
      "Epoch [48/300], Step [152/225], Training Accuracy: 78.8960%, Training Loss: 0.5087%\n",
      "Epoch [48/300], Step [153/225], Training Accuracy: 78.8909%, Training Loss: 0.5085%\n",
      "Epoch [48/300], Step [154/225], Training Accuracy: 78.9367%, Training Loss: 0.5080%\n",
      "Epoch [48/300], Step [155/225], Training Accuracy: 78.9516%, Training Loss: 0.5079%\n",
      "Epoch [48/300], Step [156/225], Training Accuracy: 78.8962%, Training Loss: 0.5085%\n",
      "Epoch [48/300], Step [157/225], Training Accuracy: 78.8714%, Training Loss: 0.5085%\n",
      "Epoch [48/300], Step [158/225], Training Accuracy: 78.8469%, Training Loss: 0.5096%\n",
      "Epoch [48/300], Step [159/225], Training Accuracy: 78.8424%, Training Loss: 0.5097%\n",
      "Epoch [48/300], Step [160/225], Training Accuracy: 78.8965%, Training Loss: 0.5089%\n",
      "Epoch [48/300], Step [161/225], Training Accuracy: 78.9014%, Training Loss: 0.5092%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/300], Step [162/225], Training Accuracy: 78.9255%, Training Loss: 0.5085%\n",
      "Epoch [48/300], Step [163/225], Training Accuracy: 78.8919%, Training Loss: 0.5085%\n",
      "Epoch [48/300], Step [164/225], Training Accuracy: 78.8967%, Training Loss: 0.5086%\n",
      "Epoch [48/300], Step [165/225], Training Accuracy: 78.8920%, Training Loss: 0.5091%\n",
      "Epoch [48/300], Step [166/225], Training Accuracy: 78.9345%, Training Loss: 0.5080%\n",
      "Epoch [48/300], Step [167/225], Training Accuracy: 78.9484%, Training Loss: 0.5074%\n",
      "Epoch [48/300], Step [168/225], Training Accuracy: 78.9528%, Training Loss: 0.5069%\n",
      "Epoch [48/300], Step [169/225], Training Accuracy: 79.0126%, Training Loss: 0.5061%\n",
      "Epoch [48/300], Step [170/225], Training Accuracy: 79.0074%, Training Loss: 0.5065%\n",
      "Epoch [48/300], Step [171/225], Training Accuracy: 78.9748%, Training Loss: 0.5071%\n",
      "Epoch [48/300], Step [172/225], Training Accuracy: 78.9517%, Training Loss: 0.5072%\n",
      "Epoch [48/300], Step [173/225], Training Accuracy: 78.9469%, Training Loss: 0.5078%\n",
      "Epoch [48/300], Step [174/225], Training Accuracy: 78.9691%, Training Loss: 0.5079%\n",
      "Epoch [48/300], Step [175/225], Training Accuracy: 78.9911%, Training Loss: 0.5072%\n",
      "Epoch [48/300], Step [176/225], Training Accuracy: 79.0394%, Training Loss: 0.5066%\n",
      "Epoch [48/300], Step [177/225], Training Accuracy: 79.0431%, Training Loss: 0.5066%\n",
      "Epoch [48/300], Step [178/225], Training Accuracy: 79.0291%, Training Loss: 0.5067%\n",
      "Epoch [48/300], Step [179/225], Training Accuracy: 79.0503%, Training Loss: 0.5072%\n",
      "Epoch [48/300], Step [180/225], Training Accuracy: 79.0365%, Training Loss: 0.5069%\n",
      "Epoch [48/300], Step [181/225], Training Accuracy: 79.0055%, Training Loss: 0.5083%\n",
      "Epoch [48/300], Step [182/225], Training Accuracy: 79.0093%, Training Loss: 0.5082%\n",
      "Epoch [48/300], Step [183/225], Training Accuracy: 79.0215%, Training Loss: 0.5080%\n",
      "Epoch [48/300], Step [184/225], Training Accuracy: 79.0336%, Training Loss: 0.5078%\n",
      "Epoch [48/300], Step [185/225], Training Accuracy: 79.0118%, Training Loss: 0.5078%\n",
      "Epoch [48/300], Step [186/225], Training Accuracy: 79.0323%, Training Loss: 0.5077%\n",
      "Epoch [48/300], Step [187/225], Training Accuracy: 79.0608%, Training Loss: 0.5071%\n",
      "Epoch [48/300], Step [188/225], Training Accuracy: 79.0725%, Training Loss: 0.5067%\n",
      "Epoch [48/300], Step [189/225], Training Accuracy: 79.0757%, Training Loss: 0.5060%\n",
      "Epoch [48/300], Step [190/225], Training Accuracy: 79.1118%, Training Loss: 0.5055%\n",
      "Epoch [48/300], Step [191/225], Training Accuracy: 79.0494%, Training Loss: 0.5062%\n",
      "Epoch [48/300], Step [192/225], Training Accuracy: 79.0609%, Training Loss: 0.5057%\n",
      "Epoch [48/300], Step [193/225], Training Accuracy: 79.0155%, Training Loss: 0.5071%\n",
      "Epoch [48/300], Step [194/225], Training Accuracy: 78.9868%, Training Loss: 0.5080%\n",
      "Epoch [48/300], Step [195/225], Training Accuracy: 79.0304%, Training Loss: 0.5072%\n",
      "Epoch [48/300], Step [196/225], Training Accuracy: 79.0099%, Training Loss: 0.5077%\n",
      "Epoch [48/300], Step [197/225], Training Accuracy: 79.0371%, Training Loss: 0.5074%\n",
      "Epoch [48/300], Step [198/225], Training Accuracy: 79.0246%, Training Loss: 0.5073%\n",
      "Epoch [48/300], Step [199/225], Training Accuracy: 79.0044%, Training Loss: 0.5075%\n",
      "Epoch [48/300], Step [200/225], Training Accuracy: 79.0312%, Training Loss: 0.5069%\n",
      "Epoch [48/300], Step [201/225], Training Accuracy: 78.9956%, Training Loss: 0.5075%\n",
      "Epoch [48/300], Step [202/225], Training Accuracy: 78.9991%, Training Loss: 0.5078%\n",
      "Epoch [48/300], Step [203/225], Training Accuracy: 79.0486%, Training Loss: 0.5069%\n",
      "Epoch [48/300], Step [204/225], Training Accuracy: 79.1054%, Training Loss: 0.5060%\n",
      "Epoch [48/300], Step [205/225], Training Accuracy: 79.1006%, Training Loss: 0.5059%\n",
      "Epoch [48/300], Step [206/225], Training Accuracy: 79.0655%, Training Loss: 0.5061%\n",
      "Epoch [48/300], Step [207/225], Training Accuracy: 79.0836%, Training Loss: 0.5056%\n",
      "Epoch [48/300], Step [208/225], Training Accuracy: 79.0790%, Training Loss: 0.5055%\n",
      "Epoch [48/300], Step [209/225], Training Accuracy: 79.1044%, Training Loss: 0.5054%\n",
      "Epoch [48/300], Step [210/225], Training Accuracy: 79.0997%, Training Loss: 0.5055%\n",
      "Epoch [48/300], Step [211/225], Training Accuracy: 79.0655%, Training Loss: 0.5056%\n",
      "Epoch [48/300], Step [212/225], Training Accuracy: 79.0315%, Training Loss: 0.5062%\n",
      "Epoch [48/300], Step [213/225], Training Accuracy: 79.0493%, Training Loss: 0.5056%\n",
      "Epoch [48/300], Step [214/225], Training Accuracy: 79.0742%, Training Loss: 0.5049%\n",
      "Epoch [48/300], Step [215/225], Training Accuracy: 79.0916%, Training Loss: 0.5046%\n",
      "Epoch [48/300], Step [216/225], Training Accuracy: 79.0799%, Training Loss: 0.5047%\n",
      "Epoch [48/300], Step [217/225], Training Accuracy: 79.0827%, Training Loss: 0.5046%\n",
      "Epoch [48/300], Step [218/225], Training Accuracy: 79.0568%, Training Loss: 0.5055%\n",
      "Epoch [48/300], Step [219/225], Training Accuracy: 79.0882%, Training Loss: 0.5051%\n",
      "Epoch [48/300], Step [220/225], Training Accuracy: 79.1193%, Training Loss: 0.5045%\n",
      "Epoch [48/300], Step [221/225], Training Accuracy: 79.1431%, Training Loss: 0.5037%\n",
      "Epoch [48/300], Step [222/225], Training Accuracy: 79.1456%, Training Loss: 0.5033%\n",
      "Epoch [48/300], Step [223/225], Training Accuracy: 79.1340%, Training Loss: 0.5039%\n",
      "Epoch [48/300], Step [224/225], Training Accuracy: 79.1504%, Training Loss: 0.5034%\n",
      "Epoch [48/300], Step [225/225], Training Accuracy: 79.1481%, Training Loss: 0.5032%\n",
      "Epoch [49/300], Step [1/225], Training Accuracy: 82.8125%, Training Loss: 0.5241%\n",
      "Epoch [49/300], Step [2/225], Training Accuracy: 82.0312%, Training Loss: 0.5627%\n",
      "Epoch [49/300], Step [3/225], Training Accuracy: 85.4167%, Training Loss: 0.5074%\n",
      "Epoch [49/300], Step [4/225], Training Accuracy: 84.3750%, Training Loss: 0.4861%\n",
      "Epoch [49/300], Step [5/225], Training Accuracy: 83.4375%, Training Loss: 0.4773%\n",
      "Epoch [49/300], Step [6/225], Training Accuracy: 83.0729%, Training Loss: 0.4644%\n",
      "Epoch [49/300], Step [7/225], Training Accuracy: 83.4821%, Training Loss: 0.4515%\n",
      "Epoch [49/300], Step [8/225], Training Accuracy: 83.0078%, Training Loss: 0.4573%\n",
      "Epoch [49/300], Step [9/225], Training Accuracy: 83.5069%, Training Loss: 0.4532%\n",
      "Epoch [49/300], Step [10/225], Training Accuracy: 83.1250%, Training Loss: 0.4582%\n",
      "Epoch [49/300], Step [11/225], Training Accuracy: 82.1023%, Training Loss: 0.4587%\n",
      "Epoch [49/300], Step [12/225], Training Accuracy: 82.2917%, Training Loss: 0.4510%\n",
      "Epoch [49/300], Step [13/225], Training Accuracy: 82.6923%, Training Loss: 0.4429%\n",
      "Epoch [49/300], Step [14/225], Training Accuracy: 82.0312%, Training Loss: 0.4509%\n",
      "Epoch [49/300], Step [15/225], Training Accuracy: 81.4583%, Training Loss: 0.4570%\n",
      "Epoch [49/300], Step [16/225], Training Accuracy: 80.9570%, Training Loss: 0.4571%\n",
      "Epoch [49/300], Step [17/225], Training Accuracy: 81.0662%, Training Loss: 0.4507%\n",
      "Epoch [49/300], Step [18/225], Training Accuracy: 80.9896%, Training Loss: 0.4499%\n",
      "Epoch [49/300], Step [19/225], Training Accuracy: 81.0855%, Training Loss: 0.4500%\n",
      "Epoch [49/300], Step [20/225], Training Accuracy: 81.3281%, Training Loss: 0.4463%\n",
      "Epoch [49/300], Step [21/225], Training Accuracy: 81.3988%, Training Loss: 0.4431%\n",
      "Epoch [49/300], Step [22/225], Training Accuracy: 80.8239%, Training Loss: 0.4529%\n",
      "Epoch [49/300], Step [23/225], Training Accuracy: 80.5027%, Training Loss: 0.4581%\n",
      "Epoch [49/300], Step [24/225], Training Accuracy: 80.5339%, Training Loss: 0.4597%\n",
      "Epoch [49/300], Step [25/225], Training Accuracy: 80.8750%, Training Loss: 0.4532%\n",
      "Epoch [49/300], Step [26/225], Training Accuracy: 81.0697%, Training Loss: 0.4526%\n",
      "Epoch [49/300], Step [27/225], Training Accuracy: 81.1343%, Training Loss: 0.4519%\n",
      "Epoch [49/300], Step [28/225], Training Accuracy: 81.1942%, Training Loss: 0.4503%\n",
      "Epoch [49/300], Step [29/225], Training Accuracy: 81.1422%, Training Loss: 0.4501%\n",
      "Epoch [49/300], Step [30/225], Training Accuracy: 80.9375%, Training Loss: 0.4525%\n",
      "Epoch [49/300], Step [31/225], Training Accuracy: 80.8468%, Training Loss: 0.4525%\n",
      "Epoch [49/300], Step [32/225], Training Accuracy: 80.8594%, Training Loss: 0.4530%\n",
      "Epoch [49/300], Step [33/225], Training Accuracy: 80.7765%, Training Loss: 0.4543%\n",
      "Epoch [49/300], Step [34/225], Training Accuracy: 80.5607%, Training Loss: 0.4592%\n",
      "Epoch [49/300], Step [35/225], Training Accuracy: 80.4018%, Training Loss: 0.4630%\n",
      "Epoch [49/300], Step [36/225], Training Accuracy: 80.2517%, Training Loss: 0.4655%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/300], Step [37/225], Training Accuracy: 80.2787%, Training Loss: 0.4636%\n",
      "Epoch [49/300], Step [38/225], Training Accuracy: 80.3454%, Training Loss: 0.4624%\n",
      "Epoch [49/300], Step [39/225], Training Accuracy: 80.3285%, Training Loss: 0.4612%\n",
      "Epoch [49/300], Step [40/225], Training Accuracy: 80.3125%, Training Loss: 0.4626%\n",
      "Epoch [49/300], Step [41/225], Training Accuracy: 80.0686%, Training Loss: 0.4678%\n",
      "Epoch [49/300], Step [42/225], Training Accuracy: 80.0967%, Training Loss: 0.4665%\n",
      "Epoch [49/300], Step [43/225], Training Accuracy: 80.0145%, Training Loss: 0.4674%\n",
      "Epoch [49/300], Step [44/225], Training Accuracy: 80.0426%, Training Loss: 0.4678%\n",
      "Epoch [49/300], Step [45/225], Training Accuracy: 80.1042%, Training Loss: 0.4668%\n",
      "Epoch [49/300], Step [46/225], Training Accuracy: 80.0951%, Training Loss: 0.4682%\n",
      "Epoch [49/300], Step [47/225], Training Accuracy: 79.8870%, Training Loss: 0.4701%\n",
      "Epoch [49/300], Step [48/225], Training Accuracy: 79.8503%, Training Loss: 0.4691%\n",
      "Epoch [49/300], Step [49/225], Training Accuracy: 79.9107%, Training Loss: 0.4667%\n",
      "Epoch [49/300], Step [50/225], Training Accuracy: 79.8750%, Training Loss: 0.4666%\n",
      "Epoch [49/300], Step [51/225], Training Accuracy: 79.9326%, Training Loss: 0.4656%\n",
      "Epoch [49/300], Step [52/225], Training Accuracy: 80.1382%, Training Loss: 0.4630%\n",
      "Epoch [49/300], Step [53/225], Training Accuracy: 80.2771%, Training Loss: 0.4602%\n",
      "Epoch [49/300], Step [54/225], Training Accuracy: 80.3241%, Training Loss: 0.4598%\n",
      "Epoch [49/300], Step [55/225], Training Accuracy: 80.2557%, Training Loss: 0.4624%\n",
      "Epoch [49/300], Step [56/225], Training Accuracy: 80.2455%, Training Loss: 0.4625%\n",
      "Epoch [49/300], Step [57/225], Training Accuracy: 80.2632%, Training Loss: 0.4627%\n",
      "Epoch [49/300], Step [58/225], Training Accuracy: 80.2532%, Training Loss: 0.4620%\n",
      "Epoch [49/300], Step [59/225], Training Accuracy: 80.1907%, Training Loss: 0.4626%\n",
      "Epoch [49/300], Step [60/225], Training Accuracy: 80.2344%, Training Loss: 0.4607%\n",
      "Epoch [49/300], Step [61/225], Training Accuracy: 80.2510%, Training Loss: 0.4609%\n",
      "Epoch [49/300], Step [62/225], Training Accuracy: 80.2671%, Training Loss: 0.4607%\n",
      "Epoch [49/300], Step [63/225], Training Accuracy: 80.2579%, Training Loss: 0.4620%\n",
      "Epoch [49/300], Step [64/225], Training Accuracy: 80.2490%, Training Loss: 0.4610%\n",
      "Epoch [49/300], Step [65/225], Training Accuracy: 80.3365%, Training Loss: 0.4607%\n",
      "Epoch [49/300], Step [66/225], Training Accuracy: 80.3741%, Training Loss: 0.4596%\n",
      "Epoch [49/300], Step [67/225], Training Accuracy: 80.3638%, Training Loss: 0.4590%\n",
      "Epoch [49/300], Step [68/225], Training Accuracy: 80.4458%, Training Loss: 0.4585%\n",
      "Epoch [49/300], Step [69/225], Training Accuracy: 80.4121%, Training Loss: 0.4600%\n",
      "Epoch [49/300], Step [70/225], Training Accuracy: 80.4018%, Training Loss: 0.4592%\n",
      "Epoch [49/300], Step [71/225], Training Accuracy: 80.3697%, Training Loss: 0.4601%\n",
      "Epoch [49/300], Step [72/225], Training Accuracy: 80.5122%, Training Loss: 0.4576%\n",
      "Epoch [49/300], Step [73/225], Training Accuracy: 80.4795%, Training Loss: 0.4579%\n",
      "Epoch [49/300], Step [74/225], Training Accuracy: 80.5532%, Training Loss: 0.4562%\n",
      "Epoch [49/300], Step [75/225], Training Accuracy: 80.4583%, Training Loss: 0.4581%\n",
      "Epoch [49/300], Step [76/225], Training Accuracy: 80.3660%, Training Loss: 0.4603%\n",
      "Epoch [49/300], Step [77/225], Training Accuracy: 80.3166%, Training Loss: 0.4620%\n",
      "Epoch [49/300], Step [78/225], Training Accuracy: 80.3886%, Training Loss: 0.4610%\n",
      "Epoch [49/300], Step [79/225], Training Accuracy: 80.4391%, Training Loss: 0.4600%\n",
      "Epoch [49/300], Step [80/225], Training Accuracy: 80.3906%, Training Loss: 0.4609%\n",
      "Epoch [49/300], Step [81/225], Training Accuracy: 80.4977%, Training Loss: 0.4588%\n",
      "Epoch [49/300], Step [82/225], Training Accuracy: 80.5259%, Training Loss: 0.4584%\n",
      "Epoch [49/300], Step [83/225], Training Accuracy: 80.4593%, Training Loss: 0.4593%\n",
      "Epoch [49/300], Step [84/225], Training Accuracy: 80.5618%, Training Loss: 0.4577%\n",
      "Epoch [49/300], Step [85/225], Training Accuracy: 80.6250%, Training Loss: 0.4561%\n",
      "Epoch [49/300], Step [86/225], Training Accuracy: 80.6868%, Training Loss: 0.4549%\n",
      "Epoch [49/300], Step [87/225], Training Accuracy: 80.6753%, Training Loss: 0.4558%\n",
      "Epoch [49/300], Step [88/225], Training Accuracy: 80.6286%, Training Loss: 0.4569%\n",
      "Epoch [49/300], Step [89/225], Training Accuracy: 80.6355%, Training Loss: 0.4561%\n",
      "Epoch [49/300], Step [90/225], Training Accuracy: 80.5729%, Training Loss: 0.4582%\n",
      "Epoch [49/300], Step [91/225], Training Accuracy: 80.6147%, Training Loss: 0.4573%\n",
      "Epoch [49/300], Step [92/225], Training Accuracy: 80.5367%, Training Loss: 0.4581%\n",
      "Epoch [49/300], Step [93/225], Training Accuracy: 80.6788%, Training Loss: 0.4561%\n",
      "Epoch [49/300], Step [94/225], Training Accuracy: 80.7181%, Training Loss: 0.4549%\n",
      "Epoch [49/300], Step [95/225], Training Accuracy: 80.7895%, Training Loss: 0.4539%\n",
      "Epoch [49/300], Step [96/225], Training Accuracy: 80.7943%, Training Loss: 0.4535%\n",
      "Epoch [49/300], Step [97/225], Training Accuracy: 80.8795%, Training Loss: 0.4525%\n",
      "Epoch [49/300], Step [98/225], Training Accuracy: 80.8673%, Training Loss: 0.4534%\n",
      "Epoch [49/300], Step [99/225], Training Accuracy: 80.8712%, Training Loss: 0.4533%\n",
      "Epoch [49/300], Step [100/225], Training Accuracy: 80.8906%, Training Loss: 0.4537%\n",
      "Epoch [49/300], Step [101/225], Training Accuracy: 80.8942%, Training Loss: 0.4536%\n",
      "Epoch [49/300], Step [102/225], Training Accuracy: 80.9283%, Training Loss: 0.4548%\n",
      "Epoch [49/300], Step [103/225], Training Accuracy: 80.9618%, Training Loss: 0.4542%\n",
      "Epoch [49/300], Step [104/225], Training Accuracy: 80.9495%, Training Loss: 0.4549%\n",
      "Epoch [49/300], Step [105/225], Training Accuracy: 80.9673%, Training Loss: 0.4538%\n",
      "Epoch [49/300], Step [106/225], Training Accuracy: 80.9404%, Training Loss: 0.4541%\n",
      "Epoch [49/300], Step [107/225], Training Accuracy: 80.9871%, Training Loss: 0.4547%\n",
      "Epoch [49/300], Step [108/225], Training Accuracy: 80.9462%, Training Loss: 0.4550%\n",
      "Epoch [49/300], Step [109/225], Training Accuracy: 80.9346%, Training Loss: 0.4552%\n",
      "Epoch [49/300], Step [110/225], Training Accuracy: 80.9233%, Training Loss: 0.4552%\n",
      "Epoch [49/300], Step [111/225], Training Accuracy: 80.9685%, Training Loss: 0.4546%\n",
      "Epoch [49/300], Step [112/225], Training Accuracy: 80.9431%, Training Loss: 0.4550%\n",
      "Epoch [49/300], Step [113/225], Training Accuracy: 80.8490%, Training Loss: 0.4563%\n",
      "Epoch [49/300], Step [114/225], Training Accuracy: 80.8251%, Training Loss: 0.4560%\n",
      "Epoch [49/300], Step [115/225], Training Accuracy: 80.8560%, Training Loss: 0.4550%\n",
      "Epoch [49/300], Step [116/225], Training Accuracy: 80.8324%, Training Loss: 0.4554%\n",
      "Epoch [49/300], Step [117/225], Training Accuracy: 80.8093%, Training Loss: 0.4562%\n",
      "Epoch [49/300], Step [118/225], Training Accuracy: 80.7998%, Training Loss: 0.4564%\n",
      "Epoch [49/300], Step [119/225], Training Accuracy: 80.7642%, Training Loss: 0.4579%\n",
      "Epoch [49/300], Step [120/225], Training Accuracy: 80.7552%, Training Loss: 0.4580%\n",
      "Epoch [49/300], Step [121/225], Training Accuracy: 80.6818%, Training Loss: 0.4587%\n",
      "Epoch [49/300], Step [122/225], Training Accuracy: 80.5712%, Training Loss: 0.4594%\n",
      "Epoch [49/300], Step [123/225], Training Accuracy: 80.5513%, Training Loss: 0.4597%\n",
      "Epoch [49/300], Step [124/225], Training Accuracy: 80.5192%, Training Loss: 0.4600%\n",
      "Epoch [49/300], Step [125/225], Training Accuracy: 80.5750%, Training Loss: 0.4591%\n",
      "Epoch [49/300], Step [126/225], Training Accuracy: 80.5680%, Training Loss: 0.4591%\n",
      "Epoch [49/300], Step [127/225], Training Accuracy: 80.6225%, Training Loss: 0.4588%\n",
      "Epoch [49/300], Step [128/225], Training Accuracy: 80.6274%, Training Loss: 0.4583%\n",
      "Epoch [49/300], Step [129/225], Training Accuracy: 80.5717%, Training Loss: 0.4589%\n",
      "Epoch [49/300], Step [130/225], Training Accuracy: 80.5288%, Training Loss: 0.4600%\n",
      "Epoch [49/300], Step [131/225], Training Accuracy: 80.5105%, Training Loss: 0.4606%\n",
      "Epoch [49/300], Step [132/225], Training Accuracy: 80.5161%, Training Loss: 0.4602%\n",
      "Epoch [49/300], Step [133/225], Training Accuracy: 80.4981%, Training Loss: 0.4606%\n",
      "Epoch [49/300], Step [134/225], Training Accuracy: 80.4454%, Training Loss: 0.4615%\n",
      "Epoch [49/300], Step [135/225], Training Accuracy: 80.4861%, Training Loss: 0.4612%\n",
      "Epoch [49/300], Step [136/225], Training Accuracy: 80.4917%, Training Loss: 0.4610%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/300], Step [137/225], Training Accuracy: 80.4973%, Training Loss: 0.4612%\n",
      "Epoch [49/300], Step [138/225], Training Accuracy: 80.5593%, Training Loss: 0.4598%\n",
      "Epoch [49/300], Step [139/225], Training Accuracy: 80.5306%, Training Loss: 0.4600%\n",
      "Epoch [49/300], Step [140/225], Training Accuracy: 80.5246%, Training Loss: 0.4598%\n",
      "Epoch [49/300], Step [141/225], Training Accuracy: 80.5075%, Training Loss: 0.4601%\n",
      "Epoch [49/300], Step [142/225], Training Accuracy: 80.5568%, Training Loss: 0.4595%\n",
      "Epoch [49/300], Step [143/225], Training Accuracy: 80.5398%, Training Loss: 0.4603%\n",
      "Epoch [49/300], Step [144/225], Training Accuracy: 80.5013%, Training Loss: 0.4605%\n",
      "Epoch [49/300], Step [145/225], Training Accuracy: 80.4849%, Training Loss: 0.4612%\n",
      "Epoch [49/300], Step [146/225], Training Accuracy: 80.4902%, Training Loss: 0.4608%\n",
      "Epoch [49/300], Step [147/225], Training Accuracy: 80.4528%, Training Loss: 0.4610%\n",
      "Epoch [49/300], Step [148/225], Training Accuracy: 80.4582%, Training Loss: 0.4608%\n",
      "Epoch [49/300], Step [149/225], Training Accuracy: 80.4111%, Training Loss: 0.4611%\n",
      "Epoch [49/300], Step [150/225], Training Accuracy: 80.4896%, Training Loss: 0.4596%\n",
      "Epoch [49/300], Step [151/225], Training Accuracy: 80.4739%, Training Loss: 0.4598%\n",
      "Epoch [49/300], Step [152/225], Training Accuracy: 80.4482%, Training Loss: 0.4599%\n",
      "Epoch [49/300], Step [153/225], Training Accuracy: 80.3922%, Training Loss: 0.4612%\n",
      "Epoch [49/300], Step [154/225], Training Accuracy: 80.3470%, Training Loss: 0.4617%\n",
      "Epoch [49/300], Step [155/225], Training Accuracy: 80.3831%, Training Loss: 0.4614%\n",
      "Epoch [49/300], Step [156/225], Training Accuracy: 80.3486%, Training Loss: 0.4621%\n",
      "Epoch [49/300], Step [157/225], Training Accuracy: 80.3443%, Training Loss: 0.4622%\n",
      "Epoch [49/300], Step [158/225], Training Accuracy: 80.2809%, Training Loss: 0.4640%\n",
      "Epoch [49/300], Step [159/225], Training Accuracy: 80.2476%, Training Loss: 0.4650%\n",
      "Epoch [49/300], Step [160/225], Training Accuracy: 80.2832%, Training Loss: 0.4650%\n",
      "Epoch [49/300], Step [161/225], Training Accuracy: 80.2698%, Training Loss: 0.4651%\n",
      "Epoch [49/300], Step [162/225], Training Accuracy: 80.2951%, Training Loss: 0.4645%\n",
      "Epoch [49/300], Step [163/225], Training Accuracy: 80.3106%, Training Loss: 0.4641%\n",
      "Epoch [49/300], Step [164/225], Training Accuracy: 80.3163%, Training Loss: 0.4640%\n",
      "Epoch [49/300], Step [165/225], Training Accuracy: 80.3030%, Training Loss: 0.4643%\n",
      "Epoch [49/300], Step [166/225], Training Accuracy: 80.3087%, Training Loss: 0.4642%\n",
      "Epoch [49/300], Step [167/225], Training Accuracy: 80.3050%, Training Loss: 0.4642%\n",
      "Epoch [49/300], Step [168/225], Training Accuracy: 80.2641%, Training Loss: 0.4651%\n",
      "Epoch [49/300], Step [169/225], Training Accuracy: 80.2515%, Training Loss: 0.4652%\n",
      "Epoch [49/300], Step [170/225], Training Accuracy: 80.2114%, Training Loss: 0.4665%\n",
      "Epoch [49/300], Step [171/225], Training Accuracy: 80.1444%, Training Loss: 0.4678%\n",
      "Epoch [49/300], Step [172/225], Training Accuracy: 80.1054%, Training Loss: 0.4681%\n",
      "Epoch [49/300], Step [173/225], Training Accuracy: 80.1301%, Training Loss: 0.4678%\n",
      "Epoch [49/300], Step [174/225], Training Accuracy: 80.1096%, Training Loss: 0.4680%\n",
      "Epoch [49/300], Step [175/225], Training Accuracy: 80.1339%, Training Loss: 0.4680%\n",
      "Epoch [49/300], Step [176/225], Training Accuracy: 80.1314%, Training Loss: 0.4682%\n",
      "Epoch [49/300], Step [177/225], Training Accuracy: 80.1289%, Training Loss: 0.4683%\n",
      "Epoch [49/300], Step [178/225], Training Accuracy: 80.1264%, Training Loss: 0.4678%\n",
      "Epoch [49/300], Step [179/225], Training Accuracy: 80.1414%, Training Loss: 0.4673%\n",
      "Epoch [49/300], Step [180/225], Training Accuracy: 80.1302%, Training Loss: 0.4672%\n",
      "Epoch [49/300], Step [181/225], Training Accuracy: 80.1709%, Training Loss: 0.4667%\n",
      "Epoch [49/300], Step [182/225], Training Accuracy: 80.1683%, Training Loss: 0.4667%\n",
      "Epoch [49/300], Step [183/225], Training Accuracy: 80.1742%, Training Loss: 0.4670%\n",
      "Epoch [49/300], Step [184/225], Training Accuracy: 80.1885%, Training Loss: 0.4666%\n",
      "Epoch [49/300], Step [185/225], Training Accuracy: 80.1774%, Training Loss: 0.4672%\n",
      "Epoch [49/300], Step [186/225], Training Accuracy: 80.2335%, Training Loss: 0.4664%\n",
      "Epoch [49/300], Step [187/225], Training Accuracy: 80.2640%, Training Loss: 0.4661%\n",
      "Epoch [49/300], Step [188/225], Training Accuracy: 80.2610%, Training Loss: 0.4657%\n",
      "Epoch [49/300], Step [189/225], Training Accuracy: 80.2662%, Training Loss: 0.4654%\n",
      "Epoch [49/300], Step [190/225], Training Accuracy: 80.2632%, Training Loss: 0.4659%\n",
      "Epoch [49/300], Step [191/225], Training Accuracy: 80.2601%, Training Loss: 0.4658%\n",
      "Epoch [49/300], Step [192/225], Training Accuracy: 80.3141%, Training Loss: 0.4651%\n",
      "Epoch [49/300], Step [193/225], Training Accuracy: 80.2866%, Training Loss: 0.4658%\n",
      "Epoch [49/300], Step [194/225], Training Accuracy: 80.2916%, Training Loss: 0.4658%\n",
      "Epoch [49/300], Step [195/225], Training Accuracy: 80.3045%, Training Loss: 0.4653%\n",
      "Epoch [49/300], Step [196/225], Training Accuracy: 80.2854%, Training Loss: 0.4654%\n",
      "Epoch [49/300], Step [197/225], Training Accuracy: 80.2824%, Training Loss: 0.4654%\n",
      "Epoch [49/300], Step [198/225], Training Accuracy: 80.2636%, Training Loss: 0.4655%\n",
      "Epoch [49/300], Step [199/225], Training Accuracy: 80.2842%, Training Loss: 0.4653%\n",
      "Epoch [49/300], Step [200/225], Training Accuracy: 80.2969%, Training Loss: 0.4650%\n",
      "Epoch [49/300], Step [201/225], Training Accuracy: 80.2861%, Training Loss: 0.4654%\n",
      "Epoch [49/300], Step [202/225], Training Accuracy: 80.3373%, Training Loss: 0.4648%\n",
      "Epoch [49/300], Step [203/225], Training Accuracy: 80.3725%, Training Loss: 0.4642%\n",
      "Epoch [49/300], Step [204/225], Training Accuracy: 80.3998%, Training Loss: 0.4641%\n",
      "Epoch [49/300], Step [205/225], Training Accuracy: 80.3887%, Training Loss: 0.4638%\n",
      "Epoch [49/300], Step [206/225], Training Accuracy: 80.4081%, Training Loss: 0.4635%\n",
      "Epoch [49/300], Step [207/225], Training Accuracy: 80.4272%, Training Loss: 0.4635%\n",
      "Epoch [49/300], Step [208/225], Training Accuracy: 80.4688%, Training Loss: 0.4628%\n",
      "Epoch [49/300], Step [209/225], Training Accuracy: 80.4800%, Training Loss: 0.4629%\n",
      "Epoch [49/300], Step [210/225], Training Accuracy: 80.4688%, Training Loss: 0.4633%\n",
      "Epoch [49/300], Step [211/225], Training Accuracy: 80.5021%, Training Loss: 0.4627%\n",
      "Epoch [49/300], Step [212/225], Training Accuracy: 80.5203%, Training Loss: 0.4625%\n",
      "Epoch [49/300], Step [213/225], Training Accuracy: 80.5091%, Training Loss: 0.4624%\n",
      "Epoch [49/300], Step [214/225], Training Accuracy: 80.5199%, Training Loss: 0.4621%\n",
      "Epoch [49/300], Step [215/225], Training Accuracy: 80.5015%, Training Loss: 0.4623%\n",
      "Epoch [49/300], Step [216/225], Training Accuracy: 80.5049%, Training Loss: 0.4622%\n",
      "Epoch [49/300], Step [217/225], Training Accuracy: 80.5156%, Training Loss: 0.4619%\n",
      "Epoch [49/300], Step [218/225], Training Accuracy: 80.4759%, Training Loss: 0.4627%\n",
      "Epoch [49/300], Step [219/225], Training Accuracy: 80.4438%, Training Loss: 0.4632%\n",
      "Epoch [49/300], Step [220/225], Training Accuracy: 80.4616%, Training Loss: 0.4627%\n",
      "Epoch [49/300], Step [221/225], Training Accuracy: 80.4652%, Training Loss: 0.4629%\n",
      "Epoch [49/300], Step [222/225], Training Accuracy: 80.4617%, Training Loss: 0.4626%\n",
      "Epoch [49/300], Step [223/225], Training Accuracy: 80.4582%, Training Loss: 0.4624%\n",
      "Epoch [49/300], Step [224/225], Training Accuracy: 80.4827%, Training Loss: 0.4618%\n",
      "Epoch [49/300], Step [225/225], Training Accuracy: 80.4961%, Training Loss: 0.4612%\n",
      "Epoch [50/300], Step [1/225], Training Accuracy: 85.9375%, Training Loss: 0.3429%\n",
      "Epoch [50/300], Step [2/225], Training Accuracy: 84.3750%, Training Loss: 0.3973%\n",
      "Epoch [50/300], Step [3/225], Training Accuracy: 82.8125%, Training Loss: 0.4421%\n",
      "Epoch [50/300], Step [4/225], Training Accuracy: 81.6406%, Training Loss: 0.4761%\n",
      "Epoch [50/300], Step [5/225], Training Accuracy: 81.5625%, Training Loss: 0.4893%\n",
      "Epoch [50/300], Step [6/225], Training Accuracy: 81.7708%, Training Loss: 0.4792%\n",
      "Epoch [50/300], Step [7/225], Training Accuracy: 81.9196%, Training Loss: 0.4624%\n",
      "Epoch [50/300], Step [8/225], Training Accuracy: 82.0312%, Training Loss: 0.4671%\n",
      "Epoch [50/300], Step [9/225], Training Accuracy: 81.9444%, Training Loss: 0.4572%\n",
      "Epoch [50/300], Step [10/225], Training Accuracy: 81.8750%, Training Loss: 0.4556%\n",
      "Epoch [50/300], Step [11/225], Training Accuracy: 81.5341%, Training Loss: 0.4533%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/300], Step [12/225], Training Accuracy: 81.5104%, Training Loss: 0.4538%\n",
      "Epoch [50/300], Step [13/225], Training Accuracy: 81.8510%, Training Loss: 0.4441%\n",
      "Epoch [50/300], Step [14/225], Training Accuracy: 81.3616%, Training Loss: 0.4525%\n",
      "Epoch [50/300], Step [15/225], Training Accuracy: 81.2500%, Training Loss: 0.4524%\n",
      "Epoch [50/300], Step [16/225], Training Accuracy: 80.8594%, Training Loss: 0.4654%\n",
      "Epoch [50/300], Step [17/225], Training Accuracy: 80.5147%, Training Loss: 0.4671%\n",
      "Epoch [50/300], Step [18/225], Training Accuracy: 80.8160%, Training Loss: 0.4626%\n",
      "Epoch [50/300], Step [19/225], Training Accuracy: 80.7566%, Training Loss: 0.4635%\n",
      "Epoch [50/300], Step [20/225], Training Accuracy: 80.7812%, Training Loss: 0.4599%\n",
      "Epoch [50/300], Step [21/225], Training Accuracy: 81.1756%, Training Loss: 0.4510%\n",
      "Epoch [50/300], Step [22/225], Training Accuracy: 80.6818%, Training Loss: 0.4667%\n",
      "Epoch [50/300], Step [23/225], Training Accuracy: 80.3668%, Training Loss: 0.4670%\n",
      "Epoch [50/300], Step [24/225], Training Accuracy: 80.1432%, Training Loss: 0.4695%\n",
      "Epoch [50/300], Step [25/225], Training Accuracy: 80.3125%, Training Loss: 0.4654%\n",
      "Epoch [50/300], Step [26/225], Training Accuracy: 80.4688%, Training Loss: 0.4663%\n",
      "Epoch [50/300], Step [27/225], Training Accuracy: 80.7292%, Training Loss: 0.4648%\n",
      "Epoch [50/300], Step [28/225], Training Accuracy: 80.7478%, Training Loss: 0.4607%\n",
      "Epoch [50/300], Step [29/225], Training Accuracy: 80.7112%, Training Loss: 0.4598%\n",
      "Epoch [50/300], Step [30/225], Training Accuracy: 80.8854%, Training Loss: 0.4561%\n",
      "Epoch [50/300], Step [31/225], Training Accuracy: 80.8972%, Training Loss: 0.4569%\n",
      "Epoch [50/300], Step [32/225], Training Accuracy: 81.2012%, Training Loss: 0.4511%\n",
      "Epoch [50/300], Step [33/225], Training Accuracy: 81.3447%, Training Loss: 0.4480%\n",
      "Epoch [50/300], Step [34/225], Training Accuracy: 80.9283%, Training Loss: 0.4565%\n",
      "Epoch [50/300], Step [35/225], Training Accuracy: 80.8929%, Training Loss: 0.4564%\n",
      "Epoch [50/300], Step [36/225], Training Accuracy: 80.5556%, Training Loss: 0.4630%\n",
      "Epoch [50/300], Step [37/225], Training Accuracy: 80.5743%, Training Loss: 0.4627%\n",
      "Epoch [50/300], Step [38/225], Training Accuracy: 80.4276%, Training Loss: 0.4641%\n",
      "Epoch [50/300], Step [39/225], Training Accuracy: 80.2885%, Training Loss: 0.4664%\n",
      "Epoch [50/300], Step [40/225], Training Accuracy: 80.5078%, Training Loss: 0.4642%\n",
      "Epoch [50/300], Step [41/225], Training Accuracy: 80.2973%, Training Loss: 0.4669%\n",
      "Epoch [50/300], Step [42/225], Training Accuracy: 80.1339%, Training Loss: 0.4685%\n",
      "Epoch [50/300], Step [43/225], Training Accuracy: 80.2689%, Training Loss: 0.4668%\n",
      "Epoch [50/300], Step [44/225], Training Accuracy: 80.3267%, Training Loss: 0.4656%\n",
      "Epoch [50/300], Step [45/225], Training Accuracy: 80.3819%, Training Loss: 0.4648%\n",
      "Epoch [50/300], Step [46/225], Training Accuracy: 80.5367%, Training Loss: 0.4618%\n",
      "Epoch [50/300], Step [47/225], Training Accuracy: 80.4521%, Training Loss: 0.4622%\n",
      "Epoch [50/300], Step [48/225], Training Accuracy: 80.4362%, Training Loss: 0.4611%\n",
      "Epoch [50/300], Step [49/225], Training Accuracy: 80.5485%, Training Loss: 0.4579%\n",
      "Epoch [50/300], Step [50/225], Training Accuracy: 80.5625%, Training Loss: 0.4566%\n",
      "Epoch [50/300], Step [51/225], Training Accuracy: 80.7598%, Training Loss: 0.4551%\n",
      "Epoch [50/300], Step [52/225], Training Accuracy: 80.9495%, Training Loss: 0.4514%\n",
      "Epoch [50/300], Step [53/225], Training Accuracy: 80.9257%, Training Loss: 0.4548%\n",
      "Epoch [50/300], Step [54/225], Training Accuracy: 80.9606%, Training Loss: 0.4537%\n",
      "Epoch [50/300], Step [55/225], Training Accuracy: 80.9659%, Training Loss: 0.4533%\n",
      "Epoch [50/300], Step [56/225], Training Accuracy: 80.9431%, Training Loss: 0.4525%\n",
      "Epoch [50/300], Step [57/225], Training Accuracy: 81.0581%, Training Loss: 0.4506%\n",
      "Epoch [50/300], Step [58/225], Training Accuracy: 81.0345%, Training Loss: 0.4519%\n",
      "Epoch [50/300], Step [59/225], Training Accuracy: 81.0381%, Training Loss: 0.4520%\n",
      "Epoch [50/300], Step [60/225], Training Accuracy: 81.0677%, Training Loss: 0.4512%\n",
      "Epoch [50/300], Step [61/225], Training Accuracy: 81.0451%, Training Loss: 0.4507%\n",
      "Epoch [50/300], Step [62/225], Training Accuracy: 81.1240%, Training Loss: 0.4492%\n",
      "Epoch [50/300], Step [63/225], Training Accuracy: 81.1012%, Training Loss: 0.4493%\n",
      "Epoch [50/300], Step [64/225], Training Accuracy: 81.1035%, Training Loss: 0.4495%\n",
      "Epoch [50/300], Step [65/225], Training Accuracy: 81.1058%, Training Loss: 0.4502%\n",
      "Epoch [50/300], Step [66/225], Training Accuracy: 81.1790%, Training Loss: 0.4497%\n",
      "Epoch [50/300], Step [67/225], Training Accuracy: 81.1800%, Training Loss: 0.4498%\n",
      "Epoch [50/300], Step [68/225], Training Accuracy: 81.1581%, Training Loss: 0.4515%\n",
      "Epoch [50/300], Step [69/225], Training Accuracy: 81.0915%, Training Loss: 0.4509%\n",
      "Epoch [50/300], Step [70/225], Training Accuracy: 81.1384%, Training Loss: 0.4501%\n",
      "Epoch [50/300], Step [71/225], Training Accuracy: 81.1840%, Training Loss: 0.4514%\n",
      "Epoch [50/300], Step [72/225], Training Accuracy: 81.2283%, Training Loss: 0.4499%\n",
      "Epoch [50/300], Step [73/225], Training Accuracy: 81.2286%, Training Loss: 0.4488%\n",
      "Epoch [50/300], Step [74/225], Training Accuracy: 81.2711%, Training Loss: 0.4484%\n",
      "Epoch [50/300], Step [75/225], Training Accuracy: 81.2083%, Training Loss: 0.4496%\n",
      "Epoch [50/300], Step [76/225], Training Accuracy: 81.2089%, Training Loss: 0.4499%\n",
      "Epoch [50/300], Step [77/225], Training Accuracy: 81.1891%, Training Loss: 0.4500%\n",
      "Epoch [50/300], Step [78/225], Training Accuracy: 81.2700%, Training Loss: 0.4486%\n",
      "Epoch [50/300], Step [79/225], Training Accuracy: 81.2104%, Training Loss: 0.4486%\n",
      "Epoch [50/300], Step [80/225], Training Accuracy: 81.1914%, Training Loss: 0.4477%\n",
      "Epoch [50/300], Step [81/225], Training Accuracy: 81.3079%, Training Loss: 0.4466%\n",
      "Epoch [50/300], Step [82/225], Training Accuracy: 81.4024%, Training Loss: 0.4453%\n",
      "Epoch [50/300], Step [83/225], Training Accuracy: 81.4194%, Training Loss: 0.4455%\n",
      "Epoch [50/300], Step [84/225], Training Accuracy: 81.5290%, Training Loss: 0.4439%\n",
      "Epoch [50/300], Step [85/225], Training Accuracy: 81.5809%, Training Loss: 0.4431%\n",
      "Epoch [50/300], Step [86/225], Training Accuracy: 81.6315%, Training Loss: 0.4417%\n",
      "Epoch [50/300], Step [87/225], Training Accuracy: 81.5194%, Training Loss: 0.4441%\n",
      "Epoch [50/300], Step [88/225], Training Accuracy: 81.4276%, Training Loss: 0.4464%\n",
      "Epoch [50/300], Step [89/225], Training Accuracy: 81.4607%, Training Loss: 0.4451%\n",
      "Epoch [50/300], Step [90/225], Training Accuracy: 81.3889%, Training Loss: 0.4458%\n",
      "Epoch [50/300], Step [91/225], Training Accuracy: 81.4217%, Training Loss: 0.4454%\n",
      "Epoch [50/300], Step [92/225], Training Accuracy: 81.4708%, Training Loss: 0.4451%\n",
      "Epoch [50/300], Step [93/225], Training Accuracy: 81.4684%, Training Loss: 0.4448%\n",
      "Epoch [50/300], Step [94/225], Training Accuracy: 81.4495%, Training Loss: 0.4462%\n",
      "Epoch [50/300], Step [95/225], Training Accuracy: 81.4145%, Training Loss: 0.4464%\n",
      "Epoch [50/300], Step [96/225], Training Accuracy: 81.4779%, Training Loss: 0.4452%\n",
      "Epoch [50/300], Step [97/225], Training Accuracy: 81.5399%, Training Loss: 0.4439%\n",
      "Epoch [50/300], Step [98/225], Training Accuracy: 81.5210%, Training Loss: 0.4436%\n",
      "Epoch [50/300], Step [99/225], Training Accuracy: 81.5499%, Training Loss: 0.4430%\n",
      "Epoch [50/300], Step [100/225], Training Accuracy: 81.5312%, Training Loss: 0.4432%\n",
      "Epoch [50/300], Step [101/225], Training Accuracy: 81.5130%, Training Loss: 0.4427%\n",
      "Epoch [50/300], Step [102/225], Training Accuracy: 81.4338%, Training Loss: 0.4443%\n",
      "Epoch [50/300], Step [103/225], Training Accuracy: 81.4472%, Training Loss: 0.4448%\n",
      "Epoch [50/300], Step [104/225], Training Accuracy: 81.5204%, Training Loss: 0.4445%\n",
      "Epoch [50/300], Step [105/225], Training Accuracy: 81.5327%, Training Loss: 0.4432%\n",
      "Epoch [50/300], Step [106/225], Training Accuracy: 81.5006%, Training Loss: 0.4433%\n",
      "Epoch [50/300], Step [107/225], Training Accuracy: 81.4982%, Training Loss: 0.4438%\n",
      "Epoch [50/300], Step [108/225], Training Accuracy: 81.4525%, Training Loss: 0.4443%\n",
      "Epoch [50/300], Step [109/225], Training Accuracy: 81.4220%, Training Loss: 0.4447%\n",
      "Epoch [50/300], Step [110/225], Training Accuracy: 81.4489%, Training Loss: 0.4440%\n",
      "Epoch [50/300], Step [111/225], Training Accuracy: 81.5175%, Training Loss: 0.4431%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/300], Step [112/225], Training Accuracy: 81.5011%, Training Loss: 0.4429%\n",
      "Epoch [50/300], Step [113/225], Training Accuracy: 81.5819%, Training Loss: 0.4417%\n",
      "Epoch [50/300], Step [114/225], Training Accuracy: 81.5927%, Training Loss: 0.4412%\n",
      "Epoch [50/300], Step [115/225], Training Accuracy: 81.6304%, Training Loss: 0.4406%\n",
      "Epoch [50/300], Step [116/225], Training Accuracy: 81.6810%, Training Loss: 0.4405%\n",
      "Epoch [50/300], Step [117/225], Training Accuracy: 81.6239%, Training Loss: 0.4414%\n",
      "Epoch [50/300], Step [118/225], Training Accuracy: 81.6737%, Training Loss: 0.4414%\n",
      "Epoch [50/300], Step [119/225], Training Accuracy: 81.6176%, Training Loss: 0.4423%\n",
      "Epoch [50/300], Step [120/225], Training Accuracy: 81.5625%, Training Loss: 0.4430%\n",
      "Epoch [50/300], Step [121/225], Training Accuracy: 81.4695%, Training Loss: 0.4463%\n",
      "Epoch [50/300], Step [122/225], Training Accuracy: 81.4933%, Training Loss: 0.4461%\n",
      "Epoch [50/300], Step [123/225], Training Accuracy: 81.5549%, Training Loss: 0.4457%\n",
      "Epoch [50/300], Step [124/225], Training Accuracy: 81.6280%, Training Loss: 0.4444%\n",
      "Epoch [50/300], Step [125/225], Training Accuracy: 81.6250%, Training Loss: 0.4451%\n",
      "Epoch [50/300], Step [126/225], Training Accuracy: 81.6220%, Training Loss: 0.4451%\n",
      "Epoch [50/300], Step [127/225], Training Accuracy: 81.6683%, Training Loss: 0.4443%\n",
      "Epoch [50/300], Step [128/225], Training Accuracy: 81.6528%, Training Loss: 0.4444%\n",
      "Epoch [50/300], Step [129/225], Training Accuracy: 81.6255%, Training Loss: 0.4443%\n",
      "Epoch [50/300], Step [130/225], Training Accuracy: 81.5745%, Training Loss: 0.4448%\n",
      "Epoch [50/300], Step [131/225], Training Accuracy: 81.5243%, Training Loss: 0.4451%\n",
      "Epoch [50/300], Step [132/225], Training Accuracy: 81.4867%, Training Loss: 0.4468%\n",
      "Epoch [50/300], Step [133/225], Training Accuracy: 81.4967%, Training Loss: 0.4469%\n",
      "Epoch [50/300], Step [134/225], Training Accuracy: 81.4132%, Training Loss: 0.4487%\n",
      "Epoch [50/300], Step [135/225], Training Accuracy: 81.4352%, Training Loss: 0.4485%\n",
      "Epoch [50/300], Step [136/225], Training Accuracy: 81.3764%, Training Loss: 0.4495%\n",
      "Epoch [50/300], Step [137/225], Training Accuracy: 81.3641%, Training Loss: 0.4499%\n",
      "Epoch [50/300], Step [138/225], Training Accuracy: 81.3632%, Training Loss: 0.4500%\n",
      "Epoch [50/300], Step [139/225], Training Accuracy: 81.2837%, Training Loss: 0.4508%\n",
      "Epoch [50/300], Step [140/225], Training Accuracy: 81.2388%, Training Loss: 0.4518%\n",
      "Epoch [50/300], Step [141/225], Training Accuracy: 81.1946%, Training Loss: 0.4522%\n",
      "Epoch [50/300], Step [142/225], Training Accuracy: 81.1400%, Training Loss: 0.4528%\n",
      "Epoch [50/300], Step [143/225], Training Accuracy: 81.1189%, Training Loss: 0.4534%\n",
      "Epoch [50/300], Step [144/225], Training Accuracy: 81.0981%, Training Loss: 0.4545%\n",
      "Epoch [50/300], Step [145/225], Training Accuracy: 81.0668%, Training Loss: 0.4550%\n",
      "Epoch [50/300], Step [146/225], Training Accuracy: 81.0467%, Training Loss: 0.4555%\n",
      "Epoch [50/300], Step [147/225], Training Accuracy: 81.0799%, Training Loss: 0.4552%\n",
      "Epoch [50/300], Step [148/225], Training Accuracy: 81.0916%, Training Loss: 0.4548%\n",
      "Epoch [50/300], Step [149/225], Training Accuracy: 81.0927%, Training Loss: 0.4546%\n",
      "Epoch [50/300], Step [150/225], Training Accuracy: 81.1667%, Training Loss: 0.4535%\n",
      "Epoch [50/300], Step [151/225], Training Accuracy: 81.2190%, Training Loss: 0.4531%\n",
      "Epoch [50/300], Step [152/225], Training Accuracy: 81.1883%, Training Loss: 0.4533%\n",
      "Epoch [50/300], Step [153/225], Training Accuracy: 81.1581%, Training Loss: 0.4533%\n",
      "Epoch [50/300], Step [154/225], Training Accuracy: 81.1384%, Training Loss: 0.4540%\n",
      "Epoch [50/300], Step [155/225], Training Accuracy: 81.0887%, Training Loss: 0.4544%\n",
      "Epoch [50/300], Step [156/225], Training Accuracy: 81.0797%, Training Loss: 0.4541%\n",
      "Epoch [50/300], Step [157/225], Training Accuracy: 81.0410%, Training Loss: 0.4548%\n",
      "Epoch [50/300], Step [158/225], Training Accuracy: 81.0225%, Training Loss: 0.4558%\n",
      "Epoch [50/300], Step [159/225], Training Accuracy: 80.9945%, Training Loss: 0.4563%\n",
      "Epoch [50/300], Step [160/225], Training Accuracy: 80.9961%, Training Loss: 0.4560%\n",
      "Epoch [50/300], Step [161/225], Training Accuracy: 81.0074%, Training Loss: 0.4557%\n",
      "Epoch [50/300], Step [162/225], Training Accuracy: 81.0089%, Training Loss: 0.4559%\n",
      "Epoch [50/300], Step [163/225], Training Accuracy: 81.0008%, Training Loss: 0.4562%\n",
      "Epoch [50/300], Step [164/225], Training Accuracy: 80.9928%, Training Loss: 0.4558%\n",
      "Epoch [50/300], Step [165/225], Training Accuracy: 80.9754%, Training Loss: 0.4559%\n",
      "Epoch [50/300], Step [166/225], Training Accuracy: 80.9488%, Training Loss: 0.4561%\n",
      "Epoch [50/300], Step [167/225], Training Accuracy: 80.9693%, Training Loss: 0.4557%\n",
      "Epoch [50/300], Step [168/225], Training Accuracy: 80.9803%, Training Loss: 0.4555%\n",
      "Epoch [50/300], Step [169/225], Training Accuracy: 81.0004%, Training Loss: 0.4551%\n",
      "Epoch [50/300], Step [170/225], Training Accuracy: 81.0202%, Training Loss: 0.4546%\n",
      "Epoch [50/300], Step [171/225], Training Accuracy: 80.9667%, Training Loss: 0.4552%\n",
      "Epoch [50/300], Step [172/225], Training Accuracy: 80.9502%, Training Loss: 0.4551%\n",
      "Epoch [50/300], Step [173/225], Training Accuracy: 80.9339%, Training Loss: 0.4555%\n",
      "Epoch [50/300], Step [174/225], Training Accuracy: 80.9088%, Training Loss: 0.4555%\n",
      "Epoch [50/300], Step [175/225], Training Accuracy: 80.9196%, Training Loss: 0.4551%\n",
      "Epoch [50/300], Step [176/225], Training Accuracy: 80.9393%, Training Loss: 0.4547%\n",
      "Epoch [50/300], Step [177/225], Training Accuracy: 80.9234%, Training Loss: 0.4544%\n",
      "Epoch [50/300], Step [178/225], Training Accuracy: 80.9515%, Training Loss: 0.4541%\n",
      "Epoch [50/300], Step [179/225], Training Accuracy: 80.9619%, Training Loss: 0.4540%\n",
      "Epoch [50/300], Step [180/225], Training Accuracy: 80.9809%, Training Loss: 0.4536%\n",
      "Epoch [50/300], Step [181/225], Training Accuracy: 80.9910%, Training Loss: 0.4538%\n",
      "Epoch [50/300], Step [182/225], Training Accuracy: 81.0268%, Training Loss: 0.4532%\n",
      "Epoch [50/300], Step [183/225], Training Accuracy: 80.9939%, Training Loss: 0.4540%\n",
      "Epoch [50/300], Step [184/225], Training Accuracy: 81.0462%, Training Loss: 0.4537%\n",
      "Epoch [50/300], Step [185/225], Training Accuracy: 81.0220%, Training Loss: 0.4538%\n",
      "Epoch [50/300], Step [186/225], Training Accuracy: 81.0568%, Training Loss: 0.4530%\n",
      "Epoch [50/300], Step [187/225], Training Accuracy: 81.1080%, Training Loss: 0.4521%\n",
      "Epoch [50/300], Step [188/225], Training Accuracy: 81.1170%, Training Loss: 0.4517%\n",
      "Epoch [50/300], Step [189/225], Training Accuracy: 81.1177%, Training Loss: 0.4514%\n",
      "Epoch [50/300], Step [190/225], Training Accuracy: 81.0938%, Training Loss: 0.4512%\n",
      "Epoch [50/300], Step [191/225], Training Accuracy: 81.0864%, Training Loss: 0.4521%\n",
      "Epoch [50/300], Step [192/225], Training Accuracy: 81.1361%, Training Loss: 0.4516%\n",
      "Epoch [50/300], Step [193/225], Training Accuracy: 81.1448%, Training Loss: 0.4514%\n",
      "Epoch [50/300], Step [194/225], Training Accuracy: 81.1372%, Training Loss: 0.4517%\n",
      "Epoch [50/300], Step [195/225], Training Accuracy: 81.1699%, Training Loss: 0.4508%\n",
      "Epoch [50/300], Step [196/225], Training Accuracy: 81.1304%, Training Loss: 0.4517%\n",
      "Epoch [50/300], Step [197/225], Training Accuracy: 81.1390%, Training Loss: 0.4512%\n",
      "Epoch [50/300], Step [198/225], Training Accuracy: 81.1553%, Training Loss: 0.4509%\n",
      "Epoch [50/300], Step [199/225], Training Accuracy: 81.1322%, Training Loss: 0.4513%\n",
      "Epoch [50/300], Step [200/225], Training Accuracy: 81.1172%, Training Loss: 0.4510%\n",
      "Epoch [50/300], Step [201/225], Training Accuracy: 81.1334%, Training Loss: 0.4509%\n",
      "Epoch [50/300], Step [202/225], Training Accuracy: 81.1494%, Training Loss: 0.4508%\n",
      "Epoch [50/300], Step [203/225], Training Accuracy: 81.2115%, Training Loss: 0.4499%\n",
      "Epoch [50/300], Step [204/225], Training Accuracy: 81.2347%, Training Loss: 0.4496%\n",
      "Epoch [50/300], Step [205/225], Training Accuracy: 81.1890%, Training Loss: 0.4502%\n",
      "Epoch [50/300], Step [206/225], Training Accuracy: 81.1742%, Training Loss: 0.4504%\n",
      "Epoch [50/300], Step [207/225], Training Accuracy: 81.1594%, Training Loss: 0.4501%\n",
      "Epoch [50/300], Step [208/225], Training Accuracy: 81.1523%, Training Loss: 0.4505%\n",
      "Epoch [50/300], Step [209/225], Training Accuracy: 81.1752%, Training Loss: 0.4506%\n",
      "Epoch [50/300], Step [210/225], Training Accuracy: 81.1533%, Training Loss: 0.4513%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/300], Step [211/225], Training Accuracy: 81.1611%, Training Loss: 0.4513%\n",
      "Epoch [50/300], Step [212/225], Training Accuracy: 81.1689%, Training Loss: 0.4508%\n",
      "Epoch [50/300], Step [213/225], Training Accuracy: 81.2060%, Training Loss: 0.4505%\n",
      "Epoch [50/300], Step [214/225], Training Accuracy: 81.1624%, Training Loss: 0.4512%\n",
      "Epoch [50/300], Step [215/225], Training Accuracy: 81.1410%, Training Loss: 0.4519%\n",
      "Epoch [50/300], Step [216/225], Training Accuracy: 81.0909%, Training Loss: 0.4525%\n",
      "Epoch [50/300], Step [217/225], Training Accuracy: 81.0772%, Training Loss: 0.4530%\n",
      "Epoch [50/300], Step [218/225], Training Accuracy: 81.0350%, Training Loss: 0.4543%\n",
      "Epoch [50/300], Step [219/225], Training Accuracy: 81.0431%, Training Loss: 0.4540%\n",
      "Epoch [50/300], Step [220/225], Training Accuracy: 81.0227%, Training Loss: 0.4542%\n",
      "Epoch [50/300], Step [221/225], Training Accuracy: 81.0167%, Training Loss: 0.4542%\n",
      "Epoch [50/300], Step [222/225], Training Accuracy: 81.0177%, Training Loss: 0.4542%\n",
      "Epoch [50/300], Step [223/225], Training Accuracy: 81.0048%, Training Loss: 0.4549%\n",
      "Epoch [50/300], Step [224/225], Training Accuracy: 81.0198%, Training Loss: 0.4544%\n",
      "Epoch [50/300], Step [225/225], Training Accuracy: 81.0172%, Training Loss: 0.4542%\n",
      "Epoch [51/300], Step [1/225], Training Accuracy: 85.9375%, Training Loss: 0.4053%\n",
      "Epoch [51/300], Step [2/225], Training Accuracy: 83.5938%, Training Loss: 0.4478%\n",
      "Epoch [51/300], Step [3/225], Training Accuracy: 82.8125%, Training Loss: 0.4758%\n",
      "Epoch [51/300], Step [4/225], Training Accuracy: 81.2500%, Training Loss: 0.4764%\n",
      "Epoch [51/300], Step [5/225], Training Accuracy: 81.8750%, Training Loss: 0.4395%\n",
      "Epoch [51/300], Step [6/225], Training Accuracy: 82.2917%, Training Loss: 0.4308%\n",
      "Epoch [51/300], Step [7/225], Training Accuracy: 82.5893%, Training Loss: 0.4241%\n",
      "Epoch [51/300], Step [8/225], Training Accuracy: 81.4453%, Training Loss: 0.4555%\n",
      "Epoch [51/300], Step [9/225], Training Accuracy: 81.9444%, Training Loss: 0.4454%\n",
      "Epoch [51/300], Step [10/225], Training Accuracy: 81.7188%, Training Loss: 0.4559%\n",
      "Epoch [51/300], Step [11/225], Training Accuracy: 81.2500%, Training Loss: 0.4551%\n",
      "Epoch [51/300], Step [12/225], Training Accuracy: 81.6406%, Training Loss: 0.4520%\n",
      "Epoch [51/300], Step [13/225], Training Accuracy: 82.0913%, Training Loss: 0.4404%\n",
      "Epoch [51/300], Step [14/225], Training Accuracy: 81.8080%, Training Loss: 0.4411%\n",
      "Epoch [51/300], Step [15/225], Training Accuracy: 81.7708%, Training Loss: 0.4348%\n",
      "Epoch [51/300], Step [16/225], Training Accuracy: 81.6406%, Training Loss: 0.4323%\n",
      "Epoch [51/300], Step [17/225], Training Accuracy: 81.6176%, Training Loss: 0.4296%\n",
      "Epoch [51/300], Step [18/225], Training Accuracy: 81.9444%, Training Loss: 0.4271%\n",
      "Epoch [51/300], Step [19/225], Training Accuracy: 81.8257%, Training Loss: 0.4281%\n",
      "Epoch [51/300], Step [20/225], Training Accuracy: 81.7188%, Training Loss: 0.4281%\n",
      "Epoch [51/300], Step [21/225], Training Accuracy: 81.9196%, Training Loss: 0.4230%\n",
      "Epoch [51/300], Step [22/225], Training Accuracy: 81.8892%, Training Loss: 0.4236%\n",
      "Epoch [51/300], Step [23/225], Training Accuracy: 81.8614%, Training Loss: 0.4220%\n",
      "Epoch [51/300], Step [24/225], Training Accuracy: 81.9661%, Training Loss: 0.4221%\n",
      "Epoch [51/300], Step [25/225], Training Accuracy: 82.3125%, Training Loss: 0.4178%\n",
      "Epoch [51/300], Step [26/225], Training Accuracy: 82.2115%, Training Loss: 0.4174%\n",
      "Epoch [51/300], Step [27/225], Training Accuracy: 82.4653%, Training Loss: 0.4145%\n",
      "Epoch [51/300], Step [28/225], Training Accuracy: 82.4777%, Training Loss: 0.4121%\n",
      "Epoch [51/300], Step [29/225], Training Accuracy: 82.4353%, Training Loss: 0.4118%\n",
      "Epoch [51/300], Step [30/225], Training Accuracy: 82.7083%, Training Loss: 0.4088%\n",
      "Epoch [51/300], Step [31/225], Training Accuracy: 82.3589%, Training Loss: 0.4095%\n",
      "Epoch [51/300], Step [32/225], Training Accuracy: 82.4707%, Training Loss: 0.4081%\n",
      "Epoch [51/300], Step [33/225], Training Accuracy: 82.3864%, Training Loss: 0.4104%\n",
      "Epoch [51/300], Step [34/225], Training Accuracy: 82.2610%, Training Loss: 0.4150%\n",
      "Epoch [51/300], Step [35/225], Training Accuracy: 82.3214%, Training Loss: 0.4160%\n",
      "Epoch [51/300], Step [36/225], Training Accuracy: 82.3785%, Training Loss: 0.4157%\n",
      "Epoch [51/300], Step [37/225], Training Accuracy: 82.4747%, Training Loss: 0.4136%\n",
      "Epoch [51/300], Step [38/225], Training Accuracy: 82.4836%, Training Loss: 0.4130%\n",
      "Epoch [51/300], Step [39/225], Training Accuracy: 82.4920%, Training Loss: 0.4131%\n",
      "Epoch [51/300], Step [40/225], Training Accuracy: 82.4609%, Training Loss: 0.4125%\n",
      "Epoch [51/300], Step [41/225], Training Accuracy: 82.3171%, Training Loss: 0.4138%\n",
      "Epoch [51/300], Step [42/225], Training Accuracy: 82.3289%, Training Loss: 0.4142%\n",
      "Epoch [51/300], Step [43/225], Training Accuracy: 82.3038%, Training Loss: 0.4158%\n",
      "Epoch [51/300], Step [44/225], Training Accuracy: 82.3153%, Training Loss: 0.4158%\n",
      "Epoch [51/300], Step [45/225], Training Accuracy: 82.5000%, Training Loss: 0.4136%\n",
      "Epoch [51/300], Step [46/225], Training Accuracy: 82.5747%, Training Loss: 0.4110%\n",
      "Epoch [51/300], Step [47/225], Training Accuracy: 82.4801%, Training Loss: 0.4133%\n",
      "Epoch [51/300], Step [48/225], Training Accuracy: 82.4544%, Training Loss: 0.4141%\n",
      "Epoch [51/300], Step [49/225], Training Accuracy: 82.5574%, Training Loss: 0.4132%\n",
      "Epoch [51/300], Step [50/225], Training Accuracy: 82.6250%, Training Loss: 0.4120%\n",
      "Epoch [51/300], Step [51/225], Training Accuracy: 82.7819%, Training Loss: 0.4094%\n",
      "Epoch [51/300], Step [52/225], Training Accuracy: 82.8726%, Training Loss: 0.4073%\n",
      "Epoch [51/300], Step [53/225], Training Accuracy: 82.9599%, Training Loss: 0.4059%\n",
      "Epoch [51/300], Step [54/225], Training Accuracy: 82.8125%, Training Loss: 0.4068%\n",
      "Epoch [51/300], Step [55/225], Training Accuracy: 82.8125%, Training Loss: 0.4068%\n",
      "Epoch [51/300], Step [56/225], Training Accuracy: 82.8962%, Training Loss: 0.4054%\n",
      "Epoch [51/300], Step [57/225], Training Accuracy: 82.8125%, Training Loss: 0.4064%\n",
      "Epoch [51/300], Step [58/225], Training Accuracy: 82.8664%, Training Loss: 0.4058%\n",
      "Epoch [51/300], Step [59/225], Training Accuracy: 82.7595%, Training Loss: 0.4061%\n",
      "Epoch [51/300], Step [60/225], Training Accuracy: 82.7344%, Training Loss: 0.4057%\n",
      "Epoch [51/300], Step [61/225], Training Accuracy: 82.7613%, Training Loss: 0.4062%\n",
      "Epoch [51/300], Step [62/225], Training Accuracy: 82.8629%, Training Loss: 0.4041%\n",
      "Epoch [51/300], Step [63/225], Training Accuracy: 82.9365%, Training Loss: 0.4043%\n",
      "Epoch [51/300], Step [64/225], Training Accuracy: 82.9590%, Training Loss: 0.4035%\n",
      "Epoch [51/300], Step [65/225], Training Accuracy: 82.8846%, Training Loss: 0.4041%\n",
      "Epoch [51/300], Step [66/225], Training Accuracy: 82.9782%, Training Loss: 0.4027%\n",
      "Epoch [51/300], Step [67/225], Training Accuracy: 82.9524%, Training Loss: 0.4026%\n",
      "Epoch [51/300], Step [68/225], Training Accuracy: 82.9274%, Training Loss: 0.4029%\n",
      "Epoch [51/300], Step [69/225], Training Accuracy: 82.9937%, Training Loss: 0.4016%\n",
      "Epoch [51/300], Step [70/225], Training Accuracy: 83.0580%, Training Loss: 0.4015%\n",
      "Epoch [51/300], Step [71/225], Training Accuracy: 83.0766%, Training Loss: 0.4010%\n",
      "Epoch [51/300], Step [72/225], Training Accuracy: 83.0946%, Training Loss: 0.4004%\n",
      "Epoch [51/300], Step [73/225], Training Accuracy: 83.0479%, Training Loss: 0.3992%\n",
      "Epoch [51/300], Step [74/225], Training Accuracy: 83.1081%, Training Loss: 0.3987%\n",
      "Epoch [51/300], Step [75/225], Training Accuracy: 83.1250%, Training Loss: 0.3976%\n",
      "Epoch [51/300], Step [76/225], Training Accuracy: 83.0387%, Training Loss: 0.3993%\n",
      "Epoch [51/300], Step [77/225], Training Accuracy: 83.0966%, Training Loss: 0.3990%\n",
      "Epoch [51/300], Step [78/225], Training Accuracy: 83.1530%, Training Loss: 0.3987%\n",
      "Epoch [51/300], Step [79/225], Training Accuracy: 83.2278%, Training Loss: 0.3974%\n",
      "Epoch [51/300], Step [80/225], Training Accuracy: 83.2812%, Training Loss: 0.3965%\n",
      "Epoch [51/300], Step [81/225], Training Accuracy: 83.3140%, Training Loss: 0.3962%\n",
      "Epoch [51/300], Step [82/225], Training Accuracy: 83.3651%, Training Loss: 0.3952%\n",
      "Epoch [51/300], Step [83/225], Training Accuracy: 83.4714%, Training Loss: 0.3934%\n",
      "Epoch [51/300], Step [84/225], Training Accuracy: 83.4263%, Training Loss: 0.3933%\n",
      "Epoch [51/300], Step [85/225], Training Accuracy: 83.4375%, Training Loss: 0.3932%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/300], Step [86/225], Training Accuracy: 83.4666%, Training Loss: 0.3928%\n",
      "Epoch [51/300], Step [87/225], Training Accuracy: 83.4770%, Training Loss: 0.3926%\n",
      "Epoch [51/300], Step [88/225], Training Accuracy: 83.4872%, Training Loss: 0.3934%\n",
      "Epoch [51/300], Step [89/225], Training Accuracy: 83.5323%, Training Loss: 0.3929%\n",
      "Epoch [51/300], Step [90/225], Training Accuracy: 83.5764%, Training Loss: 0.3920%\n",
      "Epoch [51/300], Step [91/225], Training Accuracy: 83.6882%, Training Loss: 0.3907%\n",
      "Epoch [51/300], Step [92/225], Training Accuracy: 83.6617%, Training Loss: 0.3909%\n",
      "Epoch [51/300], Step [93/225], Training Accuracy: 83.6862%, Training Loss: 0.3900%\n",
      "Epoch [51/300], Step [94/225], Training Accuracy: 83.6602%, Training Loss: 0.3901%\n",
      "Epoch [51/300], Step [95/225], Training Accuracy: 83.7007%, Training Loss: 0.3894%\n",
      "Epoch [51/300], Step [96/225], Training Accuracy: 83.7402%, Training Loss: 0.3885%\n",
      "Epoch [51/300], Step [97/225], Training Accuracy: 83.7790%, Training Loss: 0.3875%\n",
      "Epoch [51/300], Step [98/225], Training Accuracy: 83.7691%, Training Loss: 0.3879%\n",
      "Epoch [51/300], Step [99/225], Training Accuracy: 83.8226%, Training Loss: 0.3870%\n",
      "Epoch [51/300], Step [100/225], Training Accuracy: 83.8125%, Training Loss: 0.3869%\n",
      "Epoch [51/300], Step [101/225], Training Accuracy: 83.8181%, Training Loss: 0.3873%\n",
      "Epoch [51/300], Step [102/225], Training Accuracy: 83.7469%, Training Loss: 0.3889%\n",
      "Epoch [51/300], Step [103/225], Training Accuracy: 83.7985%, Training Loss: 0.3879%\n",
      "Epoch [51/300], Step [104/225], Training Accuracy: 83.7891%, Training Loss: 0.3881%\n",
      "Epoch [51/300], Step [105/225], Training Accuracy: 83.8542%, Training Loss: 0.3867%\n",
      "Epoch [51/300], Step [106/225], Training Accuracy: 83.8149%, Training Loss: 0.3870%\n",
      "Epoch [51/300], Step [107/225], Training Accuracy: 83.8055%, Training Loss: 0.3869%\n",
      "Epoch [51/300], Step [108/225], Training Accuracy: 83.7529%, Training Loss: 0.3873%\n",
      "Epoch [51/300], Step [109/225], Training Accuracy: 83.7586%, Training Loss: 0.3875%\n",
      "Epoch [51/300], Step [110/225], Training Accuracy: 83.7926%, Training Loss: 0.3868%\n",
      "Epoch [51/300], Step [111/225], Training Accuracy: 83.8260%, Training Loss: 0.3862%\n",
      "Epoch [51/300], Step [112/225], Training Accuracy: 83.8588%, Training Loss: 0.3861%\n",
      "Epoch [51/300], Step [113/225], Training Accuracy: 83.8634%, Training Loss: 0.3859%\n",
      "Epoch [51/300], Step [114/225], Training Accuracy: 83.8130%, Training Loss: 0.3863%\n",
      "Epoch [51/300], Step [115/225], Training Accuracy: 83.8995%, Training Loss: 0.3851%\n",
      "Epoch [51/300], Step [116/225], Training Accuracy: 83.8901%, Training Loss: 0.3849%\n",
      "Epoch [51/300], Step [117/225], Training Accuracy: 83.8942%, Training Loss: 0.3849%\n",
      "Epoch [51/300], Step [118/225], Training Accuracy: 83.8718%, Training Loss: 0.3850%\n",
      "Epoch [51/300], Step [119/225], Training Accuracy: 83.8235%, Training Loss: 0.3855%\n",
      "Epoch [51/300], Step [120/225], Training Accuracy: 83.8411%, Training Loss: 0.3852%\n",
      "Epoch [51/300], Step [121/225], Training Accuracy: 83.8714%, Training Loss: 0.3850%\n",
      "Epoch [51/300], Step [122/225], Training Accuracy: 83.8371%, Training Loss: 0.3852%\n",
      "Epoch [51/300], Step [123/225], Training Accuracy: 83.8161%, Training Loss: 0.3853%\n",
      "Epoch [51/300], Step [124/225], Training Accuracy: 83.8584%, Training Loss: 0.3847%\n",
      "Epoch [51/300], Step [125/225], Training Accuracy: 83.9000%, Training Loss: 0.3837%\n",
      "Epoch [51/300], Step [126/225], Training Accuracy: 83.8914%, Training Loss: 0.3838%\n",
      "Epoch [51/300], Step [127/225], Training Accuracy: 83.9075%, Training Loss: 0.3837%\n",
      "Epoch [51/300], Step [128/225], Training Accuracy: 83.9111%, Training Loss: 0.3842%\n",
      "Epoch [51/300], Step [129/225], Training Accuracy: 83.9390%, Training Loss: 0.3840%\n",
      "Epoch [51/300], Step [130/225], Training Accuracy: 83.9303%, Training Loss: 0.3843%\n",
      "Epoch [51/300], Step [131/225], Training Accuracy: 83.9337%, Training Loss: 0.3839%\n",
      "Epoch [51/300], Step [132/225], Training Accuracy: 83.9844%, Training Loss: 0.3834%\n",
      "Epoch [51/300], Step [133/225], Training Accuracy: 83.9403%, Training Loss: 0.3839%\n",
      "Epoch [51/300], Step [134/225], Training Accuracy: 83.9785%, Training Loss: 0.3836%\n",
      "Epoch [51/300], Step [135/225], Training Accuracy: 84.0162%, Training Loss: 0.3827%\n",
      "Epoch [51/300], Step [136/225], Training Accuracy: 84.0418%, Training Loss: 0.3824%\n",
      "Epoch [51/300], Step [137/225], Training Accuracy: 84.0557%, Training Loss: 0.3821%\n",
      "Epoch [51/300], Step [138/225], Training Accuracy: 84.1599%, Training Loss: 0.3805%\n",
      "Epoch [51/300], Step [139/225], Training Accuracy: 84.1502%, Training Loss: 0.3803%\n",
      "Epoch [51/300], Step [140/225], Training Accuracy: 84.1964%, Training Loss: 0.3797%\n",
      "Epoch [51/300], Step [141/225], Training Accuracy: 84.2088%, Training Loss: 0.3800%\n",
      "Epoch [51/300], Step [142/225], Training Accuracy: 84.2430%, Training Loss: 0.3790%\n",
      "Epoch [51/300], Step [143/225], Training Accuracy: 84.2548%, Training Loss: 0.3787%\n",
      "Epoch [51/300], Step [144/225], Training Accuracy: 84.2448%, Training Loss: 0.3790%\n",
      "Epoch [51/300], Step [145/225], Training Accuracy: 84.2349%, Training Loss: 0.3796%\n",
      "Epoch [51/300], Step [146/225], Training Accuracy: 84.2145%, Training Loss: 0.3802%\n",
      "Epoch [51/300], Step [147/225], Training Accuracy: 84.2581%, Training Loss: 0.3793%\n",
      "Epoch [51/300], Step [148/225], Training Accuracy: 84.2483%, Training Loss: 0.3790%\n",
      "Epoch [51/300], Step [149/225], Training Accuracy: 84.2701%, Training Loss: 0.3786%\n",
      "Epoch [51/300], Step [150/225], Training Accuracy: 84.3229%, Training Loss: 0.3776%\n",
      "Epoch [51/300], Step [151/225], Training Accuracy: 84.3336%, Training Loss: 0.3777%\n",
      "Epoch [51/300], Step [152/225], Training Accuracy: 84.3442%, Training Loss: 0.3773%\n",
      "Epoch [51/300], Step [153/225], Training Accuracy: 84.3750%, Training Loss: 0.3770%\n",
      "Epoch [51/300], Step [154/225], Training Accuracy: 84.3750%, Training Loss: 0.3772%\n",
      "Epoch [51/300], Step [155/225], Training Accuracy: 84.4052%, Training Loss: 0.3770%\n",
      "Epoch [51/300], Step [156/225], Training Accuracy: 84.4050%, Training Loss: 0.3769%\n",
      "Epoch [51/300], Step [157/225], Training Accuracy: 84.4049%, Training Loss: 0.3773%\n",
      "Epoch [51/300], Step [158/225], Training Accuracy: 84.4244%, Training Loss: 0.3773%\n",
      "Epoch [51/300], Step [159/225], Training Accuracy: 84.4241%, Training Loss: 0.3772%\n",
      "Epoch [51/300], Step [160/225], Training Accuracy: 84.4238%, Training Loss: 0.3774%\n",
      "Epoch [51/300], Step [161/225], Training Accuracy: 84.4235%, Training Loss: 0.3777%\n",
      "Epoch [51/300], Step [162/225], Training Accuracy: 84.4329%, Training Loss: 0.3777%\n",
      "Epoch [51/300], Step [163/225], Training Accuracy: 84.4325%, Training Loss: 0.3773%\n",
      "Epoch [51/300], Step [164/225], Training Accuracy: 84.4607%, Training Loss: 0.3767%\n",
      "Epoch [51/300], Step [165/225], Training Accuracy: 84.4602%, Training Loss: 0.3770%\n",
      "Epoch [51/300], Step [166/225], Training Accuracy: 84.4785%, Training Loss: 0.3769%\n",
      "Epoch [51/300], Step [167/225], Training Accuracy: 84.4873%, Training Loss: 0.3766%\n",
      "Epoch [51/300], Step [168/225], Training Accuracy: 84.4587%, Training Loss: 0.3770%\n",
      "Epoch [51/300], Step [169/225], Training Accuracy: 84.4582%, Training Loss: 0.3771%\n",
      "Epoch [51/300], Step [170/225], Training Accuracy: 84.4669%, Training Loss: 0.3768%\n",
      "Epoch [51/300], Step [171/225], Training Accuracy: 84.4207%, Training Loss: 0.3773%\n",
      "Epoch [51/300], Step [172/225], Training Accuracy: 84.4386%, Training Loss: 0.3772%\n",
      "Epoch [51/300], Step [173/225], Training Accuracy: 84.4743%, Training Loss: 0.3767%\n",
      "Epoch [51/300], Step [174/225], Training Accuracy: 84.5007%, Training Loss: 0.3765%\n",
      "Epoch [51/300], Step [175/225], Training Accuracy: 84.5179%, Training Loss: 0.3764%\n",
      "Epoch [51/300], Step [176/225], Training Accuracy: 84.5348%, Training Loss: 0.3761%\n",
      "Epoch [51/300], Step [177/225], Training Accuracy: 84.5516%, Training Loss: 0.3762%\n",
      "Epoch [51/300], Step [178/225], Training Accuracy: 84.5242%, Training Loss: 0.3762%\n",
      "Epoch [51/300], Step [179/225], Training Accuracy: 84.5321%, Training Loss: 0.3760%\n",
      "Epoch [51/300], Step [180/225], Training Accuracy: 84.5399%, Training Loss: 0.3755%\n",
      "Epoch [51/300], Step [181/225], Training Accuracy: 84.5390%, Training Loss: 0.3752%\n",
      "Epoch [51/300], Step [182/225], Training Accuracy: 84.5553%, Training Loss: 0.3754%\n",
      "Epoch [51/300], Step [183/225], Training Accuracy: 84.5202%, Training Loss: 0.3755%\n",
      "Epoch [51/300], Step [184/225], Training Accuracy: 84.5618%, Training Loss: 0.3749%\n",
      "Epoch [51/300], Step [185/225], Training Accuracy: 84.5693%, Training Loss: 0.3745%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/300], Step [186/225], Training Accuracy: 84.6270%, Training Loss: 0.3733%\n",
      "Epoch [51/300], Step [187/225], Training Accuracy: 84.6591%, Training Loss: 0.3729%\n",
      "Epoch [51/300], Step [188/225], Training Accuracy: 84.6908%, Training Loss: 0.3725%\n",
      "Epoch [51/300], Step [189/225], Training Accuracy: 84.7305%, Training Loss: 0.3721%\n",
      "Epoch [51/300], Step [190/225], Training Accuracy: 84.7368%, Training Loss: 0.3716%\n",
      "Epoch [51/300], Step [191/225], Training Accuracy: 84.7513%, Training Loss: 0.3714%\n",
      "Epoch [51/300], Step [192/225], Training Accuracy: 84.7819%, Training Loss: 0.3707%\n",
      "Epoch [51/300], Step [193/225], Training Accuracy: 84.7636%, Training Loss: 0.3712%\n",
      "Epoch [51/300], Step [194/225], Training Accuracy: 84.7294%, Training Loss: 0.3716%\n",
      "Epoch [51/300], Step [195/225], Training Accuracy: 84.7596%, Training Loss: 0.3709%\n",
      "Epoch [51/300], Step [196/225], Training Accuracy: 84.7417%, Training Loss: 0.3711%\n",
      "Epoch [51/300], Step [197/225], Training Accuracy: 84.7398%, Training Loss: 0.3710%\n",
      "Epoch [51/300], Step [198/225], Training Accuracy: 84.7617%, Training Loss: 0.3707%\n",
      "Epoch [51/300], Step [199/225], Training Accuracy: 84.7833%, Training Loss: 0.3703%\n",
      "Epoch [51/300], Step [200/225], Training Accuracy: 84.7891%, Training Loss: 0.3700%\n",
      "Epoch [51/300], Step [201/225], Training Accuracy: 84.7481%, Training Loss: 0.3701%\n",
      "Epoch [51/300], Step [202/225], Training Accuracy: 84.7618%, Training Loss: 0.3697%\n",
      "Epoch [51/300], Step [203/225], Training Accuracy: 84.7599%, Training Loss: 0.3693%\n",
      "Epoch [51/300], Step [204/225], Training Accuracy: 84.7733%, Training Loss: 0.3689%\n",
      "Epoch [51/300], Step [205/225], Training Accuracy: 84.7637%, Training Loss: 0.3689%\n",
      "Epoch [51/300], Step [206/225], Training Accuracy: 84.7846%, Training Loss: 0.3686%\n",
      "Epoch [51/300], Step [207/225], Training Accuracy: 84.7902%, Training Loss: 0.3685%\n",
      "Epoch [51/300], Step [208/225], Training Accuracy: 84.8032%, Training Loss: 0.3680%\n",
      "Epoch [51/300], Step [209/225], Training Accuracy: 84.7787%, Training Loss: 0.3686%\n",
      "Epoch [51/300], Step [210/225], Training Accuracy: 84.7693%, Training Loss: 0.3688%\n",
      "Epoch [51/300], Step [211/225], Training Accuracy: 84.7823%, Training Loss: 0.3686%\n",
      "Epoch [51/300], Step [212/225], Training Accuracy: 84.7877%, Training Loss: 0.3683%\n",
      "Epoch [51/300], Step [213/225], Training Accuracy: 84.8298%, Training Loss: 0.3678%\n",
      "Epoch [51/300], Step [214/225], Training Accuracy: 84.8350%, Training Loss: 0.3674%\n",
      "Epoch [51/300], Step [215/225], Training Accuracy: 84.8110%, Training Loss: 0.3675%\n",
      "Epoch [51/300], Step [216/225], Training Accuracy: 84.7946%, Training Loss: 0.3678%\n",
      "Epoch [51/300], Step [217/225], Training Accuracy: 84.7998%, Training Loss: 0.3679%\n",
      "Epoch [51/300], Step [218/225], Training Accuracy: 84.7979%, Training Loss: 0.3679%\n",
      "Epoch [51/300], Step [219/225], Training Accuracy: 84.8316%, Training Loss: 0.3674%\n",
      "Epoch [51/300], Step [220/225], Training Accuracy: 84.8438%, Training Loss: 0.3670%\n",
      "Epoch [51/300], Step [221/225], Training Accuracy: 84.8628%, Training Loss: 0.3665%\n",
      "Epoch [51/300], Step [222/225], Training Accuracy: 84.8677%, Training Loss: 0.3663%\n",
      "Epoch [51/300], Step [223/225], Training Accuracy: 84.8304%, Training Loss: 0.3676%\n",
      "Epoch [51/300], Step [224/225], Training Accuracy: 84.8354%, Training Loss: 0.3674%\n",
      "Epoch [51/300], Step [225/225], Training Accuracy: 84.8388%, Training Loss: 0.3674%\n",
      "Epoch [52/300], Step [1/225], Training Accuracy: 89.0625%, Training Loss: 0.3095%\n",
      "Epoch [52/300], Step [2/225], Training Accuracy: 87.5000%, Training Loss: 0.3286%\n",
      "Epoch [52/300], Step [3/225], Training Accuracy: 87.5000%, Training Loss: 0.3276%\n",
      "Epoch [52/300], Step [4/225], Training Accuracy: 85.5469%, Training Loss: 0.3342%\n",
      "Epoch [52/300], Step [5/225], Training Accuracy: 85.9375%, Training Loss: 0.3326%\n",
      "Epoch [52/300], Step [6/225], Training Accuracy: 86.1979%, Training Loss: 0.3401%\n",
      "Epoch [52/300], Step [7/225], Training Accuracy: 85.2679%, Training Loss: 0.3500%\n",
      "Epoch [52/300], Step [8/225], Training Accuracy: 84.1797%, Training Loss: 0.3700%\n",
      "Epoch [52/300], Step [9/225], Training Accuracy: 84.8958%, Training Loss: 0.3590%\n",
      "Epoch [52/300], Step [10/225], Training Accuracy: 84.2188%, Training Loss: 0.3759%\n",
      "Epoch [52/300], Step [11/225], Training Accuracy: 84.0909%, Training Loss: 0.3707%\n",
      "Epoch [52/300], Step [12/225], Training Accuracy: 84.5052%, Training Loss: 0.3651%\n",
      "Epoch [52/300], Step [13/225], Training Accuracy: 84.8558%, Training Loss: 0.3602%\n",
      "Epoch [52/300], Step [14/225], Training Accuracy: 84.8214%, Training Loss: 0.3692%\n",
      "Epoch [52/300], Step [15/225], Training Accuracy: 84.4792%, Training Loss: 0.3706%\n",
      "Epoch [52/300], Step [16/225], Training Accuracy: 83.4961%, Training Loss: 0.3851%\n",
      "Epoch [52/300], Step [17/225], Training Accuracy: 83.1801%, Training Loss: 0.3822%\n",
      "Epoch [52/300], Step [18/225], Training Accuracy: 83.2465%, Training Loss: 0.3807%\n",
      "Epoch [52/300], Step [19/225], Training Accuracy: 83.3059%, Training Loss: 0.3824%\n",
      "Epoch [52/300], Step [20/225], Training Accuracy: 83.3594%, Training Loss: 0.3821%\n",
      "Epoch [52/300], Step [21/225], Training Accuracy: 83.8542%, Training Loss: 0.3763%\n",
      "Epoch [52/300], Step [22/225], Training Accuracy: 83.4517%, Training Loss: 0.3808%\n",
      "Epoch [52/300], Step [23/225], Training Accuracy: 83.6957%, Training Loss: 0.3812%\n",
      "Epoch [52/300], Step [24/225], Training Accuracy: 83.5286%, Training Loss: 0.3867%\n",
      "Epoch [52/300], Step [25/225], Training Accuracy: 83.5625%, Training Loss: 0.3845%\n",
      "Epoch [52/300], Step [26/225], Training Accuracy: 83.5938%, Training Loss: 0.3862%\n",
      "Epoch [52/300], Step [27/225], Training Accuracy: 83.5648%, Training Loss: 0.3876%\n",
      "Epoch [52/300], Step [28/225], Training Accuracy: 83.6496%, Training Loss: 0.3834%\n",
      "Epoch [52/300], Step [29/225], Training Accuracy: 83.9440%, Training Loss: 0.3792%\n",
      "Epoch [52/300], Step [30/225], Training Accuracy: 83.8021%, Training Loss: 0.3826%\n",
      "Epoch [52/300], Step [31/225], Training Accuracy: 84.0222%, Training Loss: 0.3804%\n",
      "Epoch [52/300], Step [32/225], Training Accuracy: 84.1309%, Training Loss: 0.3789%\n",
      "Epoch [52/300], Step [33/225], Training Accuracy: 84.2330%, Training Loss: 0.3776%\n",
      "Epoch [52/300], Step [34/225], Training Accuracy: 84.1452%, Training Loss: 0.3779%\n",
      "Epoch [52/300], Step [35/225], Training Accuracy: 84.1071%, Training Loss: 0.3781%\n",
      "Epoch [52/300], Step [36/225], Training Accuracy: 84.2014%, Training Loss: 0.3765%\n",
      "Epoch [52/300], Step [37/225], Training Accuracy: 84.2061%, Training Loss: 0.3745%\n",
      "Epoch [52/300], Step [38/225], Training Accuracy: 84.1283%, Training Loss: 0.3746%\n",
      "Epoch [52/300], Step [39/225], Training Accuracy: 84.0144%, Training Loss: 0.3751%\n",
      "Epoch [52/300], Step [40/225], Training Accuracy: 84.1797%, Training Loss: 0.3736%\n",
      "Epoch [52/300], Step [41/225], Training Accuracy: 84.0701%, Training Loss: 0.3755%\n",
      "Epoch [52/300], Step [42/225], Training Accuracy: 84.1518%, Training Loss: 0.3770%\n",
      "Epoch [52/300], Step [43/225], Training Accuracy: 84.2297%, Training Loss: 0.3756%\n",
      "Epoch [52/300], Step [44/225], Training Accuracy: 84.3395%, Training Loss: 0.3737%\n",
      "Epoch [52/300], Step [45/225], Training Accuracy: 84.4097%, Training Loss: 0.3731%\n",
      "Epoch [52/300], Step [46/225], Training Accuracy: 84.5448%, Training Loss: 0.3721%\n",
      "Epoch [52/300], Step [47/225], Training Accuracy: 84.4415%, Training Loss: 0.3728%\n",
      "Epoch [52/300], Step [48/225], Training Accuracy: 84.4076%, Training Loss: 0.3719%\n",
      "Epoch [52/300], Step [49/225], Training Accuracy: 84.5663%, Training Loss: 0.3702%\n",
      "Epoch [52/300], Step [50/225], Training Accuracy: 84.6250%, Training Loss: 0.3699%\n",
      "Epoch [52/300], Step [51/225], Training Accuracy: 84.7120%, Training Loss: 0.3679%\n",
      "Epoch [52/300], Step [52/225], Training Accuracy: 84.8558%, Training Loss: 0.3654%\n",
      "Epoch [52/300], Step [53/225], Training Accuracy: 84.8467%, Training Loss: 0.3651%\n",
      "Epoch [52/300], Step [54/225], Training Accuracy: 84.8090%, Training Loss: 0.3654%\n",
      "Epoch [52/300], Step [55/225], Training Accuracy: 84.8580%, Training Loss: 0.3640%\n",
      "Epoch [52/300], Step [56/225], Training Accuracy: 84.9051%, Training Loss: 0.3620%\n",
      "Epoch [52/300], Step [57/225], Training Accuracy: 84.8684%, Training Loss: 0.3626%\n",
      "Epoch [52/300], Step [58/225], Training Accuracy: 84.9946%, Training Loss: 0.3612%\n",
      "Epoch [52/300], Step [59/225], Training Accuracy: 85.0900%, Training Loss: 0.3604%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/300], Step [60/225], Training Accuracy: 85.0521%, Training Loss: 0.3594%\n",
      "Epoch [52/300], Step [61/225], Training Accuracy: 85.0154%, Training Loss: 0.3610%\n",
      "Epoch [52/300], Step [62/225], Training Accuracy: 85.0050%, Training Loss: 0.3603%\n",
      "Epoch [52/300], Step [63/225], Training Accuracy: 84.9454%, Training Loss: 0.3613%\n",
      "Epoch [52/300], Step [64/225], Training Accuracy: 85.0342%, Training Loss: 0.3599%\n",
      "Epoch [52/300], Step [65/225], Training Accuracy: 85.0240%, Training Loss: 0.3592%\n",
      "Epoch [52/300], Step [66/225], Training Accuracy: 85.1089%, Training Loss: 0.3576%\n",
      "Epoch [52/300], Step [67/225], Training Accuracy: 85.1679%, Training Loss: 0.3564%\n",
      "Epoch [52/300], Step [68/225], Training Accuracy: 85.0873%, Training Loss: 0.3583%\n",
      "Epoch [52/300], Step [69/225], Training Accuracy: 85.1676%, Training Loss: 0.3564%\n",
      "Epoch [52/300], Step [70/225], Training Accuracy: 85.0893%, Training Loss: 0.3575%\n",
      "Epoch [52/300], Step [71/225], Training Accuracy: 85.1673%, Training Loss: 0.3565%\n",
      "Epoch [52/300], Step [72/225], Training Accuracy: 85.1562%, Training Loss: 0.3560%\n",
      "Epoch [52/300], Step [73/225], Training Accuracy: 85.1027%, Training Loss: 0.3570%\n",
      "Epoch [52/300], Step [74/225], Training Accuracy: 85.1351%, Training Loss: 0.3561%\n",
      "Epoch [52/300], Step [75/225], Training Accuracy: 85.1875%, Training Loss: 0.3551%\n",
      "Epoch [52/300], Step [76/225], Training Accuracy: 85.0946%, Training Loss: 0.3564%\n",
      "Epoch [52/300], Step [77/225], Training Accuracy: 85.0852%, Training Loss: 0.3576%\n",
      "Epoch [52/300], Step [78/225], Training Accuracy: 85.0561%, Training Loss: 0.3571%\n",
      "Epoch [52/300], Step [79/225], Training Accuracy: 85.1859%, Training Loss: 0.3552%\n",
      "Epoch [52/300], Step [80/225], Training Accuracy: 85.1562%, Training Loss: 0.3553%\n",
      "Epoch [52/300], Step [81/225], Training Accuracy: 85.2238%, Training Loss: 0.3550%\n",
      "Epoch [52/300], Step [82/225], Training Accuracy: 85.3087%, Training Loss: 0.3538%\n",
      "Epoch [52/300], Step [83/225], Training Accuracy: 85.2974%, Training Loss: 0.3540%\n",
      "Epoch [52/300], Step [84/225], Training Accuracy: 85.3981%, Training Loss: 0.3523%\n",
      "Epoch [52/300], Step [85/225], Training Accuracy: 85.4963%, Training Loss: 0.3510%\n",
      "Epoch [52/300], Step [86/225], Training Accuracy: 85.5560%, Training Loss: 0.3496%\n",
      "Epoch [52/300], Step [87/225], Training Accuracy: 85.5424%, Training Loss: 0.3503%\n",
      "Epoch [52/300], Step [88/225], Training Accuracy: 85.4581%, Training Loss: 0.3520%\n",
      "Epoch [52/300], Step [89/225], Training Accuracy: 85.4284%, Training Loss: 0.3539%\n",
      "Epoch [52/300], Step [90/225], Training Accuracy: 85.4340%, Training Loss: 0.3541%\n",
      "Epoch [52/300], Step [91/225], Training Accuracy: 85.4396%, Training Loss: 0.3541%\n",
      "Epoch [52/300], Step [92/225], Training Accuracy: 85.3940%, Training Loss: 0.3546%\n",
      "Epoch [52/300], Step [93/225], Training Accuracy: 85.3999%, Training Loss: 0.3539%\n",
      "Epoch [52/300], Step [94/225], Training Accuracy: 85.4056%, Training Loss: 0.3535%\n",
      "Epoch [52/300], Step [95/225], Training Accuracy: 85.4112%, Training Loss: 0.3534%\n",
      "Epoch [52/300], Step [96/225], Training Accuracy: 85.4167%, Training Loss: 0.3522%\n",
      "Epoch [52/300], Step [97/225], Training Accuracy: 85.4704%, Training Loss: 0.3511%\n",
      "Epoch [52/300], Step [98/225], Training Accuracy: 85.4592%, Training Loss: 0.3515%\n",
      "Epoch [52/300], Step [99/225], Training Accuracy: 85.4798%, Training Loss: 0.3505%\n",
      "Epoch [52/300], Step [100/225], Training Accuracy: 85.4531%, Training Loss: 0.3508%\n",
      "Epoch [52/300], Step [101/225], Training Accuracy: 85.4115%, Training Loss: 0.3512%\n",
      "Epoch [52/300], Step [102/225], Training Accuracy: 85.3860%, Training Loss: 0.3516%\n",
      "Epoch [52/300], Step [103/225], Training Accuracy: 85.4217%, Training Loss: 0.3506%\n",
      "Epoch [52/300], Step [104/225], Training Accuracy: 85.3365%, Training Loss: 0.3522%\n",
      "Epoch [52/300], Step [105/225], Training Accuracy: 85.3423%, Training Loss: 0.3518%\n",
      "Epoch [52/300], Step [106/225], Training Accuracy: 85.3331%, Training Loss: 0.3513%\n",
      "Epoch [52/300], Step [107/225], Training Accuracy: 85.3242%, Training Loss: 0.3532%\n",
      "Epoch [52/300], Step [108/225], Training Accuracy: 85.4022%, Training Loss: 0.3521%\n",
      "Epoch [52/300], Step [109/225], Training Accuracy: 85.3641%, Training Loss: 0.3531%\n",
      "Epoch [52/300], Step [110/225], Training Accuracy: 85.4119%, Training Loss: 0.3527%\n",
      "Epoch [52/300], Step [111/225], Training Accuracy: 85.4730%, Training Loss: 0.3516%\n",
      "Epoch [52/300], Step [112/225], Training Accuracy: 85.4492%, Training Loss: 0.3525%\n",
      "Epoch [52/300], Step [113/225], Training Accuracy: 85.4259%, Training Loss: 0.3532%\n",
      "Epoch [52/300], Step [114/225], Training Accuracy: 85.4030%, Training Loss: 0.3533%\n",
      "Epoch [52/300], Step [115/225], Training Accuracy: 85.4620%, Training Loss: 0.3529%\n",
      "Epoch [52/300], Step [116/225], Training Accuracy: 85.4661%, Training Loss: 0.3535%\n",
      "Epoch [52/300], Step [117/225], Training Accuracy: 85.5101%, Training Loss: 0.3531%\n",
      "Epoch [52/300], Step [118/225], Training Accuracy: 85.5270%, Training Loss: 0.3528%\n",
      "Epoch [52/300], Step [119/225], Training Accuracy: 85.5173%, Training Loss: 0.3527%\n",
      "Epoch [52/300], Step [120/225], Training Accuracy: 85.5339%, Training Loss: 0.3527%\n",
      "Epoch [52/300], Step [121/225], Training Accuracy: 85.5372%, Training Loss: 0.3530%\n",
      "Epoch [52/300], Step [122/225], Training Accuracy: 85.5661%, Training Loss: 0.3528%\n",
      "Epoch [52/300], Step [123/225], Training Accuracy: 85.5564%, Training Loss: 0.3540%\n",
      "Epoch [52/300], Step [124/225], Training Accuracy: 85.5469%, Training Loss: 0.3538%\n",
      "Epoch [52/300], Step [125/225], Training Accuracy: 85.5875%, Training Loss: 0.3529%\n",
      "Epoch [52/300], Step [126/225], Training Accuracy: 85.5655%, Training Loss: 0.3525%\n",
      "Epoch [52/300], Step [127/225], Training Accuracy: 85.5807%, Training Loss: 0.3526%\n",
      "Epoch [52/300], Step [128/225], Training Accuracy: 85.6079%, Training Loss: 0.3523%\n",
      "Epoch [52/300], Step [129/225], Training Accuracy: 85.5741%, Training Loss: 0.3522%\n",
      "Epoch [52/300], Step [130/225], Training Accuracy: 85.5168%, Training Loss: 0.3531%\n",
      "Epoch [52/300], Step [131/225], Training Accuracy: 85.4962%, Training Loss: 0.3538%\n",
      "Epoch [52/300], Step [132/225], Training Accuracy: 85.4995%, Training Loss: 0.3538%\n",
      "Epoch [52/300], Step [133/225], Training Accuracy: 85.4793%, Training Loss: 0.3539%\n",
      "Epoch [52/300], Step [134/225], Training Accuracy: 85.4244%, Training Loss: 0.3544%\n",
      "Epoch [52/300], Step [135/225], Training Accuracy: 85.4282%, Training Loss: 0.3539%\n",
      "Epoch [52/300], Step [136/225], Training Accuracy: 85.4435%, Training Loss: 0.3546%\n",
      "Epoch [52/300], Step [137/225], Training Accuracy: 85.4471%, Training Loss: 0.3540%\n",
      "Epoch [52/300], Step [138/225], Training Accuracy: 85.4733%, Training Loss: 0.3530%\n",
      "Epoch [52/300], Step [139/225], Training Accuracy: 85.4766%, Training Loss: 0.3529%\n",
      "Epoch [52/300], Step [140/225], Training Accuracy: 85.5246%, Training Loss: 0.3523%\n",
      "Epoch [52/300], Step [141/225], Training Accuracy: 85.5164%, Training Loss: 0.3526%\n",
      "Epoch [52/300], Step [142/225], Training Accuracy: 85.5634%, Training Loss: 0.3519%\n",
      "Epoch [52/300], Step [143/225], Training Accuracy: 85.5223%, Training Loss: 0.3525%\n",
      "Epoch [52/300], Step [144/225], Training Accuracy: 85.4926%, Training Loss: 0.3525%\n",
      "Epoch [52/300], Step [145/225], Training Accuracy: 85.4957%, Training Loss: 0.3523%\n",
      "Epoch [52/300], Step [146/225], Training Accuracy: 85.4773%, Training Loss: 0.3528%\n",
      "Epoch [52/300], Step [147/225], Training Accuracy: 85.4592%, Training Loss: 0.3531%\n",
      "Epoch [52/300], Step [148/225], Training Accuracy: 85.5046%, Training Loss: 0.3525%\n",
      "Epoch [52/300], Step [149/225], Training Accuracy: 85.5076%, Training Loss: 0.3522%\n",
      "Epoch [52/300], Step [150/225], Training Accuracy: 85.5417%, Training Loss: 0.3511%\n",
      "Epoch [52/300], Step [151/225], Training Accuracy: 85.5546%, Training Loss: 0.3506%\n",
      "Epoch [52/300], Step [152/225], Training Accuracy: 85.6086%, Training Loss: 0.3498%\n",
      "Epoch [52/300], Step [153/225], Training Accuracy: 85.6107%, Training Loss: 0.3496%\n",
      "Epoch [52/300], Step [154/225], Training Accuracy: 85.6433%, Training Loss: 0.3496%\n",
      "Epoch [52/300], Step [155/225], Training Accuracy: 85.6452%, Training Loss: 0.3498%\n",
      "Epoch [52/300], Step [156/225], Training Accuracy: 85.6270%, Training Loss: 0.3506%\n",
      "Epoch [52/300], Step [157/225], Training Accuracy: 85.5991%, Training Loss: 0.3513%\n",
      "Epoch [52/300], Step [158/225], Training Accuracy: 85.6210%, Training Loss: 0.3509%\n",
      "Epoch [52/300], Step [159/225], Training Accuracy: 85.6230%, Training Loss: 0.3516%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/300], Step [160/225], Training Accuracy: 85.6543%, Training Loss: 0.3510%\n",
      "Epoch [52/300], Step [161/225], Training Accuracy: 85.5978%, Training Loss: 0.3520%\n",
      "Epoch [52/300], Step [162/225], Training Accuracy: 85.6096%, Training Loss: 0.3517%\n",
      "Epoch [52/300], Step [163/225], Training Accuracy: 85.6308%, Training Loss: 0.3512%\n",
      "Epoch [52/300], Step [164/225], Training Accuracy: 85.6421%, Training Loss: 0.3507%\n",
      "Epoch [52/300], Step [165/225], Training Accuracy: 85.6439%, Training Loss: 0.3507%\n",
      "Epoch [52/300], Step [166/225], Training Accuracy: 85.6363%, Training Loss: 0.3505%\n",
      "Epoch [52/300], Step [167/225], Training Accuracy: 85.6475%, Training Loss: 0.3503%\n",
      "Epoch [52/300], Step [168/225], Training Accuracy: 85.6585%, Training Loss: 0.3505%\n",
      "Epoch [52/300], Step [169/225], Training Accuracy: 85.6879%, Training Loss: 0.3500%\n",
      "Epoch [52/300], Step [170/225], Training Accuracy: 85.7077%, Training Loss: 0.3497%\n",
      "Epoch [52/300], Step [171/225], Training Accuracy: 85.6817%, Training Loss: 0.3501%\n",
      "Epoch [52/300], Step [172/225], Training Accuracy: 85.6559%, Training Loss: 0.3504%\n",
      "Epoch [52/300], Step [173/225], Training Accuracy: 85.6665%, Training Loss: 0.3500%\n",
      "Epoch [52/300], Step [174/225], Training Accuracy: 85.6681%, Training Loss: 0.3502%\n",
      "Epoch [52/300], Step [175/225], Training Accuracy: 85.6696%, Training Loss: 0.3499%\n",
      "Epoch [52/300], Step [176/225], Training Accuracy: 85.6623%, Training Loss: 0.3497%\n",
      "Epoch [52/300], Step [177/225], Training Accuracy: 85.6992%, Training Loss: 0.3490%\n",
      "Epoch [52/300], Step [178/225], Training Accuracy: 85.7356%, Training Loss: 0.3488%\n",
      "Epoch [52/300], Step [179/225], Training Accuracy: 85.7629%, Training Loss: 0.3482%\n",
      "Epoch [52/300], Step [180/225], Training Accuracy: 85.7639%, Training Loss: 0.3483%\n",
      "Epoch [52/300], Step [181/225], Training Accuracy: 85.7562%, Training Loss: 0.3486%\n",
      "Epoch [52/300], Step [182/225], Training Accuracy: 85.8001%, Training Loss: 0.3477%\n",
      "Epoch [52/300], Step [183/225], Training Accuracy: 85.7667%, Training Loss: 0.3481%\n",
      "Epoch [52/300], Step [184/225], Training Accuracy: 85.7677%, Training Loss: 0.3477%\n",
      "Epoch [52/300], Step [185/225], Training Accuracy: 85.7855%, Training Loss: 0.3473%\n",
      "Epoch [52/300], Step [186/225], Training Accuracy: 85.8283%, Training Loss: 0.3464%\n",
      "Epoch [52/300], Step [187/225], Training Accuracy: 85.8539%, Training Loss: 0.3458%\n",
      "Epoch [52/300], Step [188/225], Training Accuracy: 85.8710%, Training Loss: 0.3454%\n",
      "Epoch [52/300], Step [189/225], Training Accuracy: 85.8962%, Training Loss: 0.3448%\n",
      "Epoch [52/300], Step [190/225], Training Accuracy: 85.9457%, Training Loss: 0.3441%\n",
      "Epoch [52/300], Step [191/225], Training Accuracy: 85.9211%, Training Loss: 0.3450%\n",
      "Epoch [52/300], Step [192/225], Training Accuracy: 85.9294%, Training Loss: 0.3451%\n",
      "Epoch [52/300], Step [193/225], Training Accuracy: 85.9213%, Training Loss: 0.3453%\n",
      "Epoch [52/300], Step [194/225], Training Accuracy: 85.8972%, Training Loss: 0.3455%\n",
      "Epoch [52/300], Step [195/225], Training Accuracy: 85.9375%, Training Loss: 0.3449%\n",
      "Epoch [52/300], Step [196/225], Training Accuracy: 85.9216%, Training Loss: 0.3449%\n",
      "Epoch [52/300], Step [197/225], Training Accuracy: 85.9137%, Training Loss: 0.3447%\n",
      "Epoch [52/300], Step [198/225], Training Accuracy: 85.9375%, Training Loss: 0.3445%\n",
      "Epoch [52/300], Step [199/225], Training Accuracy: 85.9375%, Training Loss: 0.3441%\n",
      "Epoch [52/300], Step [200/225], Training Accuracy: 85.9688%, Training Loss: 0.3437%\n",
      "Epoch [52/300], Step [201/225], Training Accuracy: 85.9453%, Training Loss: 0.3440%\n",
      "Epoch [52/300], Step [202/225], Training Accuracy: 85.9684%, Training Loss: 0.3436%\n",
      "Epoch [52/300], Step [203/225], Training Accuracy: 85.9837%, Training Loss: 0.3436%\n",
      "Epoch [52/300], Step [204/225], Training Accuracy: 85.9758%, Training Loss: 0.3435%\n",
      "Epoch [52/300], Step [205/225], Training Accuracy: 85.9527%, Training Loss: 0.3436%\n",
      "Epoch [52/300], Step [206/225], Training Accuracy: 85.9754%, Training Loss: 0.3430%\n",
      "Epoch [52/300], Step [207/225], Training Accuracy: 85.9828%, Training Loss: 0.3429%\n",
      "Epoch [52/300], Step [208/225], Training Accuracy: 85.9976%, Training Loss: 0.3426%\n",
      "Epoch [52/300], Step [209/225], Training Accuracy: 85.9973%, Training Loss: 0.3432%\n",
      "Epoch [52/300], Step [210/225], Training Accuracy: 85.9673%, Training Loss: 0.3434%\n",
      "Epoch [52/300], Step [211/225], Training Accuracy: 85.9967%, Training Loss: 0.3427%\n",
      "Epoch [52/300], Step [212/225], Training Accuracy: 85.9965%, Training Loss: 0.3426%\n",
      "Epoch [52/300], Step [213/225], Training Accuracy: 86.0255%, Training Loss: 0.3421%\n",
      "Epoch [52/300], Step [214/225], Training Accuracy: 86.0178%, Training Loss: 0.3421%\n",
      "Epoch [52/300], Step [215/225], Training Accuracy: 86.0320%, Training Loss: 0.3417%\n",
      "Epoch [52/300], Step [216/225], Training Accuracy: 86.0388%, Training Loss: 0.3421%\n",
      "Epoch [52/300], Step [217/225], Training Accuracy: 86.0311%, Training Loss: 0.3421%\n",
      "Epoch [52/300], Step [218/225], Training Accuracy: 86.0307%, Training Loss: 0.3421%\n",
      "Epoch [52/300], Step [219/225], Training Accuracy: 86.0088%, Training Loss: 0.3423%\n",
      "Epoch [52/300], Step [220/225], Training Accuracy: 86.0156%, Training Loss: 0.3419%\n",
      "Epoch [52/300], Step [221/225], Training Accuracy: 86.0577%, Training Loss: 0.3412%\n",
      "Epoch [52/300], Step [222/225], Training Accuracy: 86.0642%, Training Loss: 0.3409%\n",
      "Epoch [52/300], Step [223/225], Training Accuracy: 86.0426%, Training Loss: 0.3421%\n",
      "Epoch [52/300], Step [224/225], Training Accuracy: 86.0700%, Training Loss: 0.3416%\n",
      "Epoch [52/300], Step [225/225], Training Accuracy: 86.0895%, Training Loss: 0.3412%\n",
      "Epoch [53/300], Step [1/225], Training Accuracy: 89.0625%, Training Loss: 0.3201%\n",
      "Epoch [53/300], Step [2/225], Training Accuracy: 88.2812%, Training Loss: 0.2963%\n",
      "Epoch [53/300], Step [3/225], Training Accuracy: 85.9375%, Training Loss: 0.3073%\n",
      "Epoch [53/300], Step [4/225], Training Accuracy: 84.3750%, Training Loss: 0.3244%\n",
      "Epoch [53/300], Step [5/225], Training Accuracy: 84.6875%, Training Loss: 0.3483%\n",
      "Epoch [53/300], Step [6/225], Training Accuracy: 84.8958%, Training Loss: 0.3460%\n",
      "Epoch [53/300], Step [7/225], Training Accuracy: 85.4911%, Training Loss: 0.3363%\n",
      "Epoch [53/300], Step [8/225], Training Accuracy: 85.3516%, Training Loss: 0.3454%\n",
      "Epoch [53/300], Step [9/225], Training Accuracy: 86.1111%, Training Loss: 0.3328%\n",
      "Epoch [53/300], Step [10/225], Training Accuracy: 86.5625%, Training Loss: 0.3310%\n",
      "Epoch [53/300], Step [11/225], Training Accuracy: 85.9375%, Training Loss: 0.3393%\n",
      "Epoch [53/300], Step [12/225], Training Accuracy: 86.0677%, Training Loss: 0.3407%\n",
      "Epoch [53/300], Step [13/225], Training Accuracy: 86.1779%, Training Loss: 0.3331%\n",
      "Epoch [53/300], Step [14/225], Training Accuracy: 86.3839%, Training Loss: 0.3284%\n",
      "Epoch [53/300], Step [15/225], Training Accuracy: 86.4583%, Training Loss: 0.3278%\n",
      "Epoch [53/300], Step [16/225], Training Accuracy: 86.2305%, Training Loss: 0.3305%\n",
      "Epoch [53/300], Step [17/225], Training Accuracy: 86.2132%, Training Loss: 0.3290%\n",
      "Epoch [53/300], Step [18/225], Training Accuracy: 86.1979%, Training Loss: 0.3276%\n",
      "Epoch [53/300], Step [19/225], Training Accuracy: 86.3487%, Training Loss: 0.3265%\n",
      "Epoch [53/300], Step [20/225], Training Accuracy: 85.9375%, Training Loss: 0.3354%\n",
      "Epoch [53/300], Step [21/225], Training Accuracy: 86.1607%, Training Loss: 0.3290%\n",
      "Epoch [53/300], Step [22/225], Training Accuracy: 86.2216%, Training Loss: 0.3327%\n",
      "Epoch [53/300], Step [23/225], Training Accuracy: 86.3451%, Training Loss: 0.3295%\n",
      "Epoch [53/300], Step [24/225], Training Accuracy: 85.9375%, Training Loss: 0.3354%\n",
      "Epoch [53/300], Step [25/225], Training Accuracy: 86.0000%, Training Loss: 0.3332%\n",
      "Epoch [53/300], Step [26/225], Training Accuracy: 85.9375%, Training Loss: 0.3353%\n",
      "Epoch [53/300], Step [27/225], Training Accuracy: 85.8218%, Training Loss: 0.3351%\n",
      "Epoch [53/300], Step [28/225], Training Accuracy: 86.0491%, Training Loss: 0.3306%\n",
      "Epoch [53/300], Step [29/225], Training Accuracy: 86.0453%, Training Loss: 0.3320%\n",
      "Epoch [53/300], Step [30/225], Training Accuracy: 85.8854%, Training Loss: 0.3325%\n",
      "Epoch [53/300], Step [31/225], Training Accuracy: 85.7863%, Training Loss: 0.3330%\n",
      "Epoch [53/300], Step [32/225], Training Accuracy: 85.6934%, Training Loss: 0.3345%\n",
      "Epoch [53/300], Step [33/225], Training Accuracy: 85.6534%, Training Loss: 0.3343%\n",
      "Epoch [53/300], Step [34/225], Training Accuracy: 85.3860%, Training Loss: 0.3376%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/300], Step [35/225], Training Accuracy: 85.4464%, Training Loss: 0.3367%\n",
      "Epoch [53/300], Step [36/225], Training Accuracy: 85.4167%, Training Loss: 0.3375%\n",
      "Epoch [53/300], Step [37/225], Training Accuracy: 85.6419%, Training Loss: 0.3347%\n",
      "Epoch [53/300], Step [38/225], Training Accuracy: 85.6086%, Training Loss: 0.3350%\n",
      "Epoch [53/300], Step [39/225], Training Accuracy: 85.4567%, Training Loss: 0.3382%\n",
      "Epoch [53/300], Step [40/225], Training Accuracy: 85.4688%, Training Loss: 0.3376%\n",
      "Epoch [53/300], Step [41/225], Training Accuracy: 85.6326%, Training Loss: 0.3368%\n",
      "Epoch [53/300], Step [42/225], Training Accuracy: 85.6771%, Training Loss: 0.3366%\n",
      "Epoch [53/300], Step [43/225], Training Accuracy: 85.7195%, Training Loss: 0.3353%\n",
      "Epoch [53/300], Step [44/225], Training Accuracy: 85.7599%, Training Loss: 0.3350%\n",
      "Epoch [53/300], Step [45/225], Training Accuracy: 85.7986%, Training Loss: 0.3337%\n",
      "Epoch [53/300], Step [46/225], Training Accuracy: 85.8016%, Training Loss: 0.3330%\n",
      "Epoch [53/300], Step [47/225], Training Accuracy: 85.6383%, Training Loss: 0.3353%\n",
      "Epoch [53/300], Step [48/225], Training Accuracy: 85.7096%, Training Loss: 0.3349%\n",
      "Epoch [53/300], Step [49/225], Training Accuracy: 85.7781%, Training Loss: 0.3332%\n",
      "Epoch [53/300], Step [50/225], Training Accuracy: 85.8125%, Training Loss: 0.3342%\n",
      "Epoch [53/300], Step [51/225], Training Accuracy: 85.9375%, Training Loss: 0.3314%\n",
      "Epoch [53/300], Step [52/225], Training Accuracy: 86.0577%, Training Loss: 0.3288%\n",
      "Epoch [53/300], Step [53/225], Training Accuracy: 86.0554%, Training Loss: 0.3277%\n",
      "Epoch [53/300], Step [54/225], Training Accuracy: 86.0822%, Training Loss: 0.3272%\n",
      "Epoch [53/300], Step [55/225], Training Accuracy: 85.9091%, Training Loss: 0.3287%\n",
      "Epoch [53/300], Step [56/225], Training Accuracy: 85.9933%, Training Loss: 0.3273%\n",
      "Epoch [53/300], Step [57/225], Training Accuracy: 86.0197%, Training Loss: 0.3281%\n",
      "Epoch [53/300], Step [58/225], Training Accuracy: 86.0183%, Training Loss: 0.3285%\n",
      "Epoch [53/300], Step [59/225], Training Accuracy: 85.9905%, Training Loss: 0.3287%\n",
      "Epoch [53/300], Step [60/225], Training Accuracy: 86.0156%, Training Loss: 0.3285%\n",
      "Epoch [53/300], Step [61/225], Training Accuracy: 85.9631%, Training Loss: 0.3295%\n",
      "Epoch [53/300], Step [62/225], Training Accuracy: 86.0383%, Training Loss: 0.3283%\n",
      "Epoch [53/300], Step [63/225], Training Accuracy: 85.9871%, Training Loss: 0.3295%\n",
      "Epoch [53/300], Step [64/225], Training Accuracy: 86.0107%, Training Loss: 0.3300%\n",
      "Epoch [53/300], Step [65/225], Training Accuracy: 86.0337%, Training Loss: 0.3296%\n",
      "Epoch [53/300], Step [66/225], Training Accuracy: 86.0795%, Training Loss: 0.3286%\n",
      "Epoch [53/300], Step [67/225], Training Accuracy: 86.1007%, Training Loss: 0.3282%\n",
      "Epoch [53/300], Step [68/225], Training Accuracy: 86.0064%, Training Loss: 0.3295%\n",
      "Epoch [53/300], Step [69/225], Training Accuracy: 86.0734%, Training Loss: 0.3284%\n",
      "Epoch [53/300], Step [70/225], Training Accuracy: 86.0491%, Training Loss: 0.3287%\n",
      "Epoch [53/300], Step [71/225], Training Accuracy: 86.0915%, Training Loss: 0.3282%\n",
      "Epoch [53/300], Step [72/225], Training Accuracy: 86.1111%, Training Loss: 0.3282%\n",
      "Epoch [53/300], Step [73/225], Training Accuracy: 86.0659%, Training Loss: 0.3289%\n",
      "Epoch [53/300], Step [74/225], Training Accuracy: 86.1064%, Training Loss: 0.3280%\n",
      "Epoch [53/300], Step [75/225], Training Accuracy: 86.1458%, Training Loss: 0.3273%\n",
      "Epoch [53/300], Step [76/225], Training Accuracy: 86.1225%, Training Loss: 0.3288%\n",
      "Epoch [53/300], Step [77/225], Training Accuracy: 86.1810%, Training Loss: 0.3283%\n",
      "Epoch [53/300], Step [78/225], Training Accuracy: 86.1979%, Training Loss: 0.3282%\n",
      "Epoch [53/300], Step [79/225], Training Accuracy: 86.3133%, Training Loss: 0.3260%\n",
      "Epoch [53/300], Step [80/225], Training Accuracy: 86.3281%, Training Loss: 0.3260%\n",
      "Epoch [53/300], Step [81/225], Training Accuracy: 86.4005%, Training Loss: 0.3250%\n",
      "Epoch [53/300], Step [82/225], Training Accuracy: 86.4329%, Training Loss: 0.3237%\n",
      "Epoch [53/300], Step [83/225], Training Accuracy: 86.4646%, Training Loss: 0.3242%\n",
      "Epoch [53/300], Step [84/225], Training Accuracy: 86.4397%, Training Loss: 0.3241%\n",
      "Epoch [53/300], Step [85/225], Training Accuracy: 86.4522%, Training Loss: 0.3235%\n",
      "Epoch [53/300], Step [86/225], Training Accuracy: 86.4644%, Training Loss: 0.3229%\n",
      "Epoch [53/300], Step [87/225], Training Accuracy: 86.4224%, Training Loss: 0.3238%\n",
      "Epoch [53/300], Step [88/225], Training Accuracy: 86.2571%, Training Loss: 0.3260%\n",
      "Epoch [53/300], Step [89/225], Training Accuracy: 86.2886%, Training Loss: 0.3249%\n",
      "Epoch [53/300], Step [90/225], Training Accuracy: 86.2500%, Training Loss: 0.3256%\n",
      "Epoch [53/300], Step [91/225], Training Accuracy: 86.2637%, Training Loss: 0.3250%\n",
      "Epoch [53/300], Step [92/225], Training Accuracy: 86.2432%, Training Loss: 0.3251%\n",
      "Epoch [53/300], Step [93/225], Training Accuracy: 86.2735%, Training Loss: 0.3247%\n",
      "Epoch [53/300], Step [94/225], Training Accuracy: 86.3198%, Training Loss: 0.3243%\n",
      "Epoch [53/300], Step [95/225], Training Accuracy: 86.3816%, Training Loss: 0.3229%\n",
      "Epoch [53/300], Step [96/225], Training Accuracy: 86.3770%, Training Loss: 0.3224%\n",
      "Epoch [53/300], Step [97/225], Training Accuracy: 86.4369%, Training Loss: 0.3215%\n",
      "Epoch [53/300], Step [98/225], Training Accuracy: 86.4477%, Training Loss: 0.3208%\n",
      "Epoch [53/300], Step [99/225], Training Accuracy: 86.5372%, Training Loss: 0.3193%\n",
      "Epoch [53/300], Step [100/225], Training Accuracy: 86.5312%, Training Loss: 0.3196%\n",
      "Epoch [53/300], Step [101/225], Training Accuracy: 86.5718%, Training Loss: 0.3187%\n",
      "Epoch [53/300], Step [102/225], Training Accuracy: 86.5502%, Training Loss: 0.3196%\n",
      "Epoch [53/300], Step [103/225], Training Accuracy: 86.5595%, Training Loss: 0.3196%\n",
      "Epoch [53/300], Step [104/225], Training Accuracy: 86.4784%, Training Loss: 0.3213%\n",
      "Epoch [53/300], Step [105/225], Training Accuracy: 86.5030%, Training Loss: 0.3215%\n",
      "Epoch [53/300], Step [106/225], Training Accuracy: 86.5124%, Training Loss: 0.3218%\n",
      "Epoch [53/300], Step [107/225], Training Accuracy: 86.4778%, Training Loss: 0.3221%\n",
      "Epoch [53/300], Step [108/225], Training Accuracy: 86.4583%, Training Loss: 0.3233%\n",
      "Epoch [53/300], Step [109/225], Training Accuracy: 86.3819%, Training Loss: 0.3248%\n",
      "Epoch [53/300], Step [110/225], Training Accuracy: 86.4062%, Training Loss: 0.3244%\n",
      "Epoch [53/300], Step [111/225], Training Accuracy: 86.4020%, Training Loss: 0.3243%\n",
      "Epoch [53/300], Step [112/225], Training Accuracy: 86.3839%, Training Loss: 0.3250%\n",
      "Epoch [53/300], Step [113/225], Training Accuracy: 86.3800%, Training Loss: 0.3252%\n",
      "Epoch [53/300], Step [114/225], Training Accuracy: 86.3624%, Training Loss: 0.3259%\n",
      "Epoch [53/300], Step [115/225], Training Accuracy: 86.3859%, Training Loss: 0.3260%\n",
      "Epoch [53/300], Step [116/225], Training Accuracy: 86.3685%, Training Loss: 0.3267%\n",
      "Epoch [53/300], Step [117/225], Training Accuracy: 86.2847%, Training Loss: 0.3281%\n",
      "Epoch [53/300], Step [118/225], Training Accuracy: 86.2553%, Training Loss: 0.3287%\n",
      "Epoch [53/300], Step [119/225], Training Accuracy: 86.2526%, Training Loss: 0.3288%\n",
      "Epoch [53/300], Step [120/225], Training Accuracy: 86.2500%, Training Loss: 0.3287%\n",
      "Epoch [53/300], Step [121/225], Training Accuracy: 86.2474%, Training Loss: 0.3285%\n",
      "Epoch [53/300], Step [122/225], Training Accuracy: 86.1808%, Training Loss: 0.3291%\n",
      "Epoch [53/300], Step [123/225], Training Accuracy: 86.1789%, Training Loss: 0.3290%\n",
      "Epoch [53/300], Step [124/225], Training Accuracy: 86.2147%, Training Loss: 0.3288%\n",
      "Epoch [53/300], Step [125/225], Training Accuracy: 86.2000%, Training Loss: 0.3293%\n",
      "Epoch [53/300], Step [126/225], Training Accuracy: 86.1731%, Training Loss: 0.3295%\n",
      "Epoch [53/300], Step [127/225], Training Accuracy: 86.1590%, Training Loss: 0.3297%\n",
      "Epoch [53/300], Step [128/225], Training Accuracy: 86.1206%, Training Loss: 0.3305%\n",
      "Epoch [53/300], Step [129/225], Training Accuracy: 86.0950%, Training Loss: 0.3310%\n",
      "Epoch [53/300], Step [130/225], Training Accuracy: 86.0817%, Training Loss: 0.3312%\n",
      "Epoch [53/300], Step [131/225], Training Accuracy: 86.1164%, Training Loss: 0.3309%\n",
      "Epoch [53/300], Step [132/225], Training Accuracy: 86.1387%, Training Loss: 0.3312%\n",
      "Epoch [53/300], Step [133/225], Training Accuracy: 86.0550%, Training Loss: 0.3323%\n",
      "Epoch [53/300], Step [134/225], Training Accuracy: 85.9492%, Training Loss: 0.3334%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/300], Step [135/225], Training Accuracy: 85.9606%, Training Loss: 0.3330%\n",
      "Epoch [53/300], Step [136/225], Training Accuracy: 85.9260%, Training Loss: 0.3331%\n",
      "Epoch [53/300], Step [137/225], Training Accuracy: 85.9375%, Training Loss: 0.3332%\n",
      "Epoch [53/300], Step [138/225], Training Accuracy: 86.0054%, Training Loss: 0.3321%\n",
      "Epoch [53/300], Step [139/225], Training Accuracy: 86.0049%, Training Loss: 0.3317%\n",
      "Epoch [53/300], Step [140/225], Training Accuracy: 86.0491%, Training Loss: 0.3310%\n",
      "Epoch [53/300], Step [141/225], Training Accuracy: 86.0151%, Training Loss: 0.3314%\n",
      "Epoch [53/300], Step [142/225], Training Accuracy: 86.0255%, Training Loss: 0.3307%\n",
      "Epoch [53/300], Step [143/225], Training Accuracy: 86.0249%, Training Loss: 0.3304%\n",
      "Epoch [53/300], Step [144/225], Training Accuracy: 86.0460%, Training Loss: 0.3304%\n",
      "Epoch [53/300], Step [145/225], Training Accuracy: 86.0453%, Training Loss: 0.3304%\n",
      "Epoch [53/300], Step [146/225], Training Accuracy: 86.0552%, Training Loss: 0.3304%\n",
      "Epoch [53/300], Step [147/225], Training Accuracy: 86.0969%, Training Loss: 0.3300%\n",
      "Epoch [53/300], Step [148/225], Training Accuracy: 86.0959%, Training Loss: 0.3301%\n",
      "Epoch [53/300], Step [149/225], Training Accuracy: 86.1158%, Training Loss: 0.3298%\n",
      "Epoch [53/300], Step [150/225], Training Accuracy: 86.1771%, Training Loss: 0.3287%\n",
      "Epoch [53/300], Step [151/225], Training Accuracy: 86.2065%, Training Loss: 0.3288%\n",
      "Epoch [53/300], Step [152/225], Training Accuracy: 86.1739%, Training Loss: 0.3287%\n",
      "Epoch [53/300], Step [153/225], Training Accuracy: 86.2132%, Training Loss: 0.3282%\n",
      "Epoch [53/300], Step [154/225], Training Accuracy: 86.2317%, Training Loss: 0.3280%\n",
      "Epoch [53/300], Step [155/225], Training Accuracy: 86.2903%, Training Loss: 0.3273%\n",
      "Epoch [53/300], Step [156/225], Training Accuracy: 86.2981%, Training Loss: 0.3276%\n",
      "Epoch [53/300], Step [157/225], Training Accuracy: 86.2858%, Training Loss: 0.3275%\n",
      "Epoch [53/300], Step [158/225], Training Accuracy: 86.2737%, Training Loss: 0.3278%\n",
      "Epoch [53/300], Step [159/225], Training Accuracy: 86.2814%, Training Loss: 0.3279%\n",
      "Epoch [53/300], Step [160/225], Training Accuracy: 86.2793%, Training Loss: 0.3277%\n",
      "Epoch [53/300], Step [161/225], Training Accuracy: 86.2092%, Training Loss: 0.3291%\n",
      "Epoch [53/300], Step [162/225], Training Accuracy: 86.2076%, Training Loss: 0.3290%\n",
      "Epoch [53/300], Step [163/225], Training Accuracy: 86.2251%, Training Loss: 0.3292%\n",
      "Epoch [53/300], Step [164/225], Training Accuracy: 86.2233%, Training Loss: 0.3290%\n",
      "Epoch [53/300], Step [165/225], Training Accuracy: 86.2405%, Training Loss: 0.3290%\n",
      "Epoch [53/300], Step [166/225], Training Accuracy: 86.2293%, Training Loss: 0.3291%\n",
      "Epoch [53/300], Step [167/225], Training Accuracy: 86.2369%, Training Loss: 0.3291%\n",
      "Epoch [53/300], Step [168/225], Training Accuracy: 86.2537%, Training Loss: 0.3295%\n",
      "Epoch [53/300], Step [169/225], Training Accuracy: 86.2334%, Training Loss: 0.3297%\n",
      "Epoch [53/300], Step [170/225], Training Accuracy: 86.2500%, Training Loss: 0.3298%\n",
      "Epoch [53/300], Step [171/225], Training Accuracy: 86.2573%, Training Loss: 0.3299%\n",
      "Epoch [53/300], Step [172/225], Training Accuracy: 86.2645%, Training Loss: 0.3299%\n",
      "Epoch [53/300], Step [173/225], Training Accuracy: 86.2717%, Training Loss: 0.3298%\n",
      "Epoch [53/300], Step [174/225], Training Accuracy: 86.2428%, Training Loss: 0.3297%\n",
      "Epoch [53/300], Step [175/225], Training Accuracy: 86.2321%, Training Loss: 0.3298%\n",
      "Epoch [53/300], Step [176/225], Training Accuracy: 86.2393%, Training Loss: 0.3298%\n",
      "Epoch [53/300], Step [177/225], Training Accuracy: 86.2818%, Training Loss: 0.3290%\n",
      "Epoch [53/300], Step [178/225], Training Accuracy: 86.2798%, Training Loss: 0.3290%\n",
      "Epoch [53/300], Step [179/225], Training Accuracy: 86.2954%, Training Loss: 0.3287%\n",
      "Epoch [53/300], Step [180/225], Training Accuracy: 86.3108%, Training Loss: 0.3285%\n",
      "Epoch [53/300], Step [181/225], Training Accuracy: 86.3173%, Training Loss: 0.3283%\n",
      "Epoch [53/300], Step [182/225], Training Accuracy: 86.2895%, Training Loss: 0.3282%\n",
      "Epoch [53/300], Step [183/225], Training Accuracy: 86.2620%, Training Loss: 0.3287%\n",
      "Epoch [53/300], Step [184/225], Training Accuracy: 86.2687%, Training Loss: 0.3284%\n",
      "Epoch [53/300], Step [185/225], Training Accuracy: 86.2838%, Training Loss: 0.3281%\n",
      "Epoch [53/300], Step [186/225], Training Accuracy: 86.2819%, Training Loss: 0.3278%\n",
      "Epoch [53/300], Step [187/225], Training Accuracy: 86.2801%, Training Loss: 0.3279%\n",
      "Epoch [53/300], Step [188/225], Training Accuracy: 86.3032%, Training Loss: 0.3278%\n",
      "Epoch [53/300], Step [189/225], Training Accuracy: 86.3426%, Training Loss: 0.3272%\n",
      "Epoch [53/300], Step [190/225], Training Accuracy: 86.3322%, Training Loss: 0.3270%\n",
      "Epoch [53/300], Step [191/225], Training Accuracy: 86.2893%, Training Loss: 0.3282%\n",
      "Epoch [53/300], Step [192/225], Training Accuracy: 86.3200%, Training Loss: 0.3279%\n",
      "Epoch [53/300], Step [193/225], Training Accuracy: 86.3180%, Training Loss: 0.3284%\n",
      "Epoch [53/300], Step [194/225], Training Accuracy: 86.2999%, Training Loss: 0.3286%\n",
      "Epoch [53/300], Step [195/225], Training Accuracy: 86.3221%, Training Loss: 0.3282%\n",
      "Epoch [53/300], Step [196/225], Training Accuracy: 86.3122%, Training Loss: 0.3285%\n",
      "Epoch [53/300], Step [197/225], Training Accuracy: 86.3579%, Training Loss: 0.3280%\n",
      "Epoch [53/300], Step [198/225], Training Accuracy: 86.3873%, Training Loss: 0.3273%\n",
      "Epoch [53/300], Step [199/225], Training Accuracy: 86.4008%, Training Loss: 0.3271%\n",
      "Epoch [53/300], Step [200/225], Training Accuracy: 86.4141%, Training Loss: 0.3268%\n",
      "Epoch [53/300], Step [201/225], Training Accuracy: 86.3961%, Training Loss: 0.3271%\n",
      "Epoch [53/300], Step [202/225], Training Accuracy: 86.4093%, Training Loss: 0.3271%\n",
      "Epoch [53/300], Step [203/225], Training Accuracy: 86.4224%, Training Loss: 0.3266%\n",
      "Epoch [53/300], Step [204/225], Training Accuracy: 86.4430%, Training Loss: 0.3265%\n",
      "Epoch [53/300], Step [205/225], Training Accuracy: 86.4405%, Training Loss: 0.3265%\n",
      "Epoch [53/300], Step [206/225], Training Accuracy: 86.4457%, Training Loss: 0.3266%\n",
      "Epoch [53/300], Step [207/225], Training Accuracy: 86.4508%, Training Loss: 0.3263%\n",
      "Epoch [53/300], Step [208/225], Training Accuracy: 86.4709%, Training Loss: 0.3261%\n",
      "Epoch [53/300], Step [209/225], Training Accuracy: 86.4907%, Training Loss: 0.3259%\n",
      "Epoch [53/300], Step [210/225], Training Accuracy: 86.4881%, Training Loss: 0.3261%\n",
      "Epoch [53/300], Step [211/225], Training Accuracy: 86.4781%, Training Loss: 0.3258%\n",
      "Epoch [53/300], Step [212/225], Training Accuracy: 86.4608%, Training Loss: 0.3258%\n",
      "Epoch [53/300], Step [213/225], Training Accuracy: 86.4803%, Training Loss: 0.3255%\n",
      "Epoch [53/300], Step [214/225], Training Accuracy: 86.4851%, Training Loss: 0.3254%\n",
      "Epoch [53/300], Step [215/225], Training Accuracy: 86.5116%, Training Loss: 0.3250%\n",
      "Epoch [53/300], Step [216/225], Training Accuracy: 86.5162%, Training Loss: 0.3250%\n",
      "Epoch [53/300], Step [217/225], Training Accuracy: 86.5351%, Training Loss: 0.3249%\n",
      "Epoch [53/300], Step [218/225], Training Accuracy: 86.5611%, Training Loss: 0.3248%\n",
      "Epoch [53/300], Step [219/225], Training Accuracy: 86.5725%, Training Loss: 0.3247%\n",
      "Epoch [53/300], Step [220/225], Training Accuracy: 86.5412%, Training Loss: 0.3249%\n",
      "Epoch [53/300], Step [221/225], Training Accuracy: 86.5667%, Training Loss: 0.3244%\n",
      "Epoch [53/300], Step [222/225], Training Accuracy: 86.5639%, Training Loss: 0.3245%\n",
      "Epoch [53/300], Step [223/225], Training Accuracy: 86.5541%, Training Loss: 0.3246%\n",
      "Epoch [53/300], Step [224/225], Training Accuracy: 86.5234%, Training Loss: 0.3249%\n",
      "Epoch [53/300], Step [225/225], Training Accuracy: 86.5064%, Training Loss: 0.3249%\n",
      "Epoch [54/300], Step [1/225], Training Accuracy: 95.3125%, Training Loss: 0.2873%\n",
      "Epoch [54/300], Step [2/225], Training Accuracy: 93.7500%, Training Loss: 0.2645%\n",
      "Epoch [54/300], Step [3/225], Training Accuracy: 92.7083%, Training Loss: 0.2648%\n",
      "Epoch [54/300], Step [4/225], Training Accuracy: 92.5781%, Training Loss: 0.2609%\n",
      "Epoch [54/300], Step [5/225], Training Accuracy: 92.1875%, Training Loss: 0.2584%\n",
      "Epoch [54/300], Step [6/225], Training Accuracy: 91.4062%, Training Loss: 0.2591%\n",
      "Epoch [54/300], Step [7/225], Training Accuracy: 91.2946%, Training Loss: 0.2586%\n",
      "Epoch [54/300], Step [8/225], Training Accuracy: 89.6484%, Training Loss: 0.2831%\n",
      "Epoch [54/300], Step [9/225], Training Accuracy: 89.7569%, Training Loss: 0.2760%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/300], Step [10/225], Training Accuracy: 89.5312%, Training Loss: 0.2843%\n",
      "Epoch [54/300], Step [11/225], Training Accuracy: 89.0625%, Training Loss: 0.2966%\n",
      "Epoch [54/300], Step [12/225], Training Accuracy: 88.6719%, Training Loss: 0.3021%\n",
      "Epoch [54/300], Step [13/225], Training Accuracy: 88.9423%, Training Loss: 0.2930%\n",
      "Epoch [54/300], Step [14/225], Training Accuracy: 88.8393%, Training Loss: 0.2906%\n",
      "Epoch [54/300], Step [15/225], Training Accuracy: 88.8542%, Training Loss: 0.2972%\n",
      "Epoch [54/300], Step [16/225], Training Accuracy: 89.0625%, Training Loss: 0.2959%\n",
      "Epoch [54/300], Step [17/225], Training Accuracy: 88.8787%, Training Loss: 0.2948%\n",
      "Epoch [54/300], Step [18/225], Training Accuracy: 88.6285%, Training Loss: 0.2955%\n",
      "Epoch [54/300], Step [19/225], Training Accuracy: 88.7336%, Training Loss: 0.2929%\n",
      "Epoch [54/300], Step [20/225], Training Accuracy: 88.4375%, Training Loss: 0.2949%\n",
      "Epoch [54/300], Step [21/225], Training Accuracy: 88.4673%, Training Loss: 0.2911%\n",
      "Epoch [54/300], Step [22/225], Training Accuracy: 88.1392%, Training Loss: 0.2950%\n",
      "Epoch [54/300], Step [23/225], Training Accuracy: 88.1793%, Training Loss: 0.2944%\n",
      "Epoch [54/300], Step [24/225], Training Accuracy: 88.1510%, Training Loss: 0.2962%\n",
      "Epoch [54/300], Step [25/225], Training Accuracy: 88.3750%, Training Loss: 0.2914%\n",
      "Epoch [54/300], Step [26/225], Training Accuracy: 88.2812%, Training Loss: 0.2915%\n",
      "Epoch [54/300], Step [27/225], Training Accuracy: 88.0787%, Training Loss: 0.2948%\n",
      "Epoch [54/300], Step [28/225], Training Accuracy: 88.2254%, Training Loss: 0.2922%\n",
      "Epoch [54/300], Step [29/225], Training Accuracy: 88.2004%, Training Loss: 0.2916%\n",
      "Epoch [54/300], Step [30/225], Training Accuracy: 88.2292%, Training Loss: 0.2899%\n",
      "Epoch [54/300], Step [31/225], Training Accuracy: 88.2056%, Training Loss: 0.2903%\n",
      "Epoch [54/300], Step [32/225], Training Accuracy: 88.2812%, Training Loss: 0.2892%\n",
      "Epoch [54/300], Step [33/225], Training Accuracy: 88.2576%, Training Loss: 0.2887%\n",
      "Epoch [54/300], Step [34/225], Training Accuracy: 88.3732%, Training Loss: 0.2873%\n",
      "Epoch [54/300], Step [35/225], Training Accuracy: 88.3482%, Training Loss: 0.2891%\n",
      "Epoch [54/300], Step [36/225], Training Accuracy: 88.2812%, Training Loss: 0.2891%\n",
      "Epoch [54/300], Step [37/225], Training Accuracy: 88.3446%, Training Loss: 0.2867%\n",
      "Epoch [54/300], Step [38/225], Training Accuracy: 88.2401%, Training Loss: 0.2877%\n",
      "Epoch [54/300], Step [39/225], Training Accuracy: 88.1410%, Training Loss: 0.2891%\n",
      "Epoch [54/300], Step [40/225], Training Accuracy: 88.1250%, Training Loss: 0.2890%\n",
      "Epoch [54/300], Step [41/225], Training Accuracy: 88.0335%, Training Loss: 0.2927%\n",
      "Epoch [54/300], Step [42/225], Training Accuracy: 87.8720%, Training Loss: 0.2920%\n",
      "Epoch [54/300], Step [43/225], Training Accuracy: 87.8997%, Training Loss: 0.2918%\n",
      "Epoch [54/300], Step [44/225], Training Accuracy: 87.8551%, Training Loss: 0.2918%\n",
      "Epoch [54/300], Step [45/225], Training Accuracy: 87.9514%, Training Loss: 0.2911%\n",
      "Epoch [54/300], Step [46/225], Training Accuracy: 87.9076%, Training Loss: 0.2921%\n",
      "Epoch [54/300], Step [47/225], Training Accuracy: 87.7327%, Training Loss: 0.2952%\n",
      "Epoch [54/300], Step [48/225], Training Accuracy: 87.6953%, Training Loss: 0.2944%\n",
      "Epoch [54/300], Step [49/225], Training Accuracy: 87.7232%, Training Loss: 0.2926%\n",
      "Epoch [54/300], Step [50/225], Training Accuracy: 87.8125%, Training Loss: 0.2916%\n",
      "Epoch [54/300], Step [51/225], Training Accuracy: 87.8064%, Training Loss: 0.2917%\n",
      "Epoch [54/300], Step [52/225], Training Accuracy: 87.8906%, Training Loss: 0.2906%\n",
      "Epoch [54/300], Step [53/225], Training Accuracy: 87.9717%, Training Loss: 0.2903%\n",
      "Epoch [54/300], Step [54/225], Training Accuracy: 87.9919%, Training Loss: 0.2919%\n",
      "Epoch [54/300], Step [55/225], Training Accuracy: 87.8125%, Training Loss: 0.2944%\n",
      "Epoch [54/300], Step [56/225], Training Accuracy: 87.9185%, Training Loss: 0.2929%\n",
      "Epoch [54/300], Step [57/225], Training Accuracy: 87.9112%, Training Loss: 0.2936%\n",
      "Epoch [54/300], Step [58/225], Training Accuracy: 87.9849%, Training Loss: 0.2933%\n",
      "Epoch [54/300], Step [59/225], Training Accuracy: 87.9237%, Training Loss: 0.2948%\n",
      "Epoch [54/300], Step [60/225], Training Accuracy: 87.8906%, Training Loss: 0.2953%\n",
      "Epoch [54/300], Step [61/225], Training Accuracy: 87.9098%, Training Loss: 0.2952%\n",
      "Epoch [54/300], Step [62/225], Training Accuracy: 87.9284%, Training Loss: 0.2941%\n",
      "Epoch [54/300], Step [63/225], Training Accuracy: 87.8968%, Training Loss: 0.2957%\n",
      "Epoch [54/300], Step [64/225], Training Accuracy: 87.9150%, Training Loss: 0.2951%\n",
      "Epoch [54/300], Step [65/225], Training Accuracy: 87.8846%, Training Loss: 0.2952%\n",
      "Epoch [54/300], Step [66/225], Training Accuracy: 88.0208%, Training Loss: 0.2935%\n",
      "Epoch [54/300], Step [67/225], Training Accuracy: 87.9897%, Training Loss: 0.2937%\n",
      "Epoch [54/300], Step [68/225], Training Accuracy: 87.9366%, Training Loss: 0.2954%\n",
      "Epoch [54/300], Step [69/225], Training Accuracy: 88.0435%, Training Loss: 0.2944%\n",
      "Epoch [54/300], Step [70/225], Training Accuracy: 87.9911%, Training Loss: 0.2955%\n",
      "Epoch [54/300], Step [71/225], Training Accuracy: 88.0062%, Training Loss: 0.2957%\n",
      "Epoch [54/300], Step [72/225], Training Accuracy: 87.9340%, Training Loss: 0.2965%\n",
      "Epoch [54/300], Step [73/225], Training Accuracy: 87.8639%, Training Loss: 0.2971%\n",
      "Epoch [54/300], Step [74/225], Training Accuracy: 87.8167%, Training Loss: 0.2976%\n",
      "Epoch [54/300], Step [75/225], Training Accuracy: 87.8542%, Training Loss: 0.2971%\n",
      "Epoch [54/300], Step [76/225], Training Accuracy: 87.7056%, Training Loss: 0.2998%\n",
      "Epoch [54/300], Step [77/225], Training Accuracy: 87.7232%, Training Loss: 0.3003%\n",
      "Epoch [54/300], Step [78/225], Training Accuracy: 87.7604%, Training Loss: 0.2997%\n",
      "Epoch [54/300], Step [79/225], Training Accuracy: 87.8165%, Training Loss: 0.2990%\n",
      "Epoch [54/300], Step [80/225], Training Accuracy: 87.7734%, Training Loss: 0.3004%\n",
      "Epoch [54/300], Step [81/225], Training Accuracy: 87.8472%, Training Loss: 0.2991%\n",
      "Epoch [54/300], Step [82/225], Training Accuracy: 87.9192%, Training Loss: 0.2979%\n",
      "Epoch [54/300], Step [83/225], Training Accuracy: 87.8012%, Training Loss: 0.2995%\n",
      "Epoch [54/300], Step [84/225], Training Accuracy: 87.8534%, Training Loss: 0.2984%\n",
      "Epoch [54/300], Step [85/225], Training Accuracy: 87.8676%, Training Loss: 0.2989%\n",
      "Epoch [54/300], Step [86/225], Training Accuracy: 87.9360%, Training Loss: 0.2980%\n",
      "Epoch [54/300], Step [87/225], Training Accuracy: 87.9670%, Training Loss: 0.2977%\n",
      "Epoch [54/300], Step [88/225], Training Accuracy: 87.8196%, Training Loss: 0.3003%\n",
      "Epoch [54/300], Step [89/225], Training Accuracy: 87.8336%, Training Loss: 0.3000%\n",
      "Epoch [54/300], Step [90/225], Training Accuracy: 87.8125%, Training Loss: 0.3004%\n",
      "Epoch [54/300], Step [91/225], Training Accuracy: 87.8434%, Training Loss: 0.2997%\n",
      "Epoch [54/300], Step [92/225], Training Accuracy: 87.8057%, Training Loss: 0.3002%\n",
      "Epoch [54/300], Step [93/225], Training Accuracy: 87.8528%, Training Loss: 0.3001%\n",
      "Epoch [54/300], Step [94/225], Training Accuracy: 87.8324%, Training Loss: 0.2999%\n",
      "Epoch [54/300], Step [95/225], Training Accuracy: 87.8125%, Training Loss: 0.3005%\n",
      "Epoch [54/300], Step [96/225], Training Accuracy: 87.8418%, Training Loss: 0.3006%\n",
      "Epoch [54/300], Step [97/225], Training Accuracy: 87.9027%, Training Loss: 0.2994%\n",
      "Epoch [54/300], Step [98/225], Training Accuracy: 87.9305%, Training Loss: 0.2988%\n",
      "Epoch [54/300], Step [99/225], Training Accuracy: 87.9577%, Training Loss: 0.2983%\n",
      "Epoch [54/300], Step [100/225], Training Accuracy: 88.0000%, Training Loss: 0.2982%\n",
      "Epoch [54/300], Step [101/225], Training Accuracy: 88.0105%, Training Loss: 0.2983%\n",
      "Epoch [54/300], Step [102/225], Training Accuracy: 87.9596%, Training Loss: 0.2990%\n",
      "Epoch [54/300], Step [103/225], Training Accuracy: 87.9551%, Training Loss: 0.2991%\n",
      "Epoch [54/300], Step [104/225], Training Accuracy: 87.9657%, Training Loss: 0.2994%\n",
      "Epoch [54/300], Step [105/225], Training Accuracy: 87.9315%, Training Loss: 0.2992%\n",
      "Epoch [54/300], Step [106/225], Training Accuracy: 87.8390%, Training Loss: 0.3010%\n",
      "Epoch [54/300], Step [107/225], Training Accuracy: 87.8505%, Training Loss: 0.3006%\n",
      "Epoch [54/300], Step [108/225], Training Accuracy: 87.7749%, Training Loss: 0.3027%\n",
      "Epoch [54/300], Step [109/225], Training Accuracy: 87.6864%, Training Loss: 0.3038%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/300], Step [110/225], Training Accuracy: 87.7273%, Training Loss: 0.3037%\n",
      "Epoch [54/300], Step [111/225], Training Accuracy: 87.6971%, Training Loss: 0.3037%\n",
      "Epoch [54/300], Step [112/225], Training Accuracy: 87.6674%, Training Loss: 0.3045%\n",
      "Epoch [54/300], Step [113/225], Training Accuracy: 87.6521%, Training Loss: 0.3044%\n",
      "Epoch [54/300], Step [114/225], Training Accuracy: 87.6782%, Training Loss: 0.3040%\n",
      "Epoch [54/300], Step [115/225], Training Accuracy: 87.6359%, Training Loss: 0.3042%\n",
      "Epoch [54/300], Step [116/225], Training Accuracy: 87.5943%, Training Loss: 0.3046%\n",
      "Epoch [54/300], Step [117/225], Training Accuracy: 87.5801%, Training Loss: 0.3050%\n",
      "Epoch [54/300], Step [118/225], Training Accuracy: 87.5530%, Training Loss: 0.3056%\n",
      "Epoch [54/300], Step [119/225], Training Accuracy: 87.5263%, Training Loss: 0.3058%\n",
      "Epoch [54/300], Step [120/225], Training Accuracy: 87.5391%, Training Loss: 0.3060%\n",
      "Epoch [54/300], Step [121/225], Training Accuracy: 87.5129%, Training Loss: 0.3058%\n",
      "Epoch [54/300], Step [122/225], Training Accuracy: 87.5128%, Training Loss: 0.3058%\n",
      "Epoch [54/300], Step [123/225], Training Accuracy: 87.4873%, Training Loss: 0.3063%\n",
      "Epoch [54/300], Step [124/225], Training Accuracy: 87.5000%, Training Loss: 0.3058%\n",
      "Epoch [54/300], Step [125/225], Training Accuracy: 87.4875%, Training Loss: 0.3053%\n",
      "Epoch [54/300], Step [126/225], Training Accuracy: 87.4628%, Training Loss: 0.3060%\n",
      "Epoch [54/300], Step [127/225], Training Accuracy: 87.4385%, Training Loss: 0.3067%\n",
      "Epoch [54/300], Step [128/225], Training Accuracy: 87.4023%, Training Loss: 0.3076%\n",
      "Epoch [54/300], Step [129/225], Training Accuracy: 87.4031%, Training Loss: 0.3082%\n",
      "Epoch [54/300], Step [130/225], Training Accuracy: 87.4279%, Training Loss: 0.3080%\n",
      "Epoch [54/300], Step [131/225], Training Accuracy: 87.3927%, Training Loss: 0.3082%\n",
      "Epoch [54/300], Step [132/225], Training Accuracy: 87.3816%, Training Loss: 0.3086%\n",
      "Epoch [54/300], Step [133/225], Training Accuracy: 87.3708%, Training Loss: 0.3085%\n",
      "Epoch [54/300], Step [134/225], Training Accuracy: 87.3717%, Training Loss: 0.3087%\n",
      "Epoch [54/300], Step [135/225], Training Accuracy: 87.3380%, Training Loss: 0.3091%\n",
      "Epoch [54/300], Step [136/225], Training Accuracy: 87.3392%, Training Loss: 0.3092%\n",
      "Epoch [54/300], Step [137/225], Training Accuracy: 87.3517%, Training Loss: 0.3088%\n",
      "Epoch [54/300], Step [138/225], Training Accuracy: 87.3641%, Training Loss: 0.3084%\n",
      "Epoch [54/300], Step [139/225], Training Accuracy: 87.3876%, Training Loss: 0.3078%\n",
      "Epoch [54/300], Step [140/225], Training Accuracy: 87.3996%, Training Loss: 0.3075%\n",
      "Epoch [54/300], Step [141/225], Training Accuracy: 87.3449%, Training Loss: 0.3083%\n",
      "Epoch [54/300], Step [142/225], Training Accuracy: 87.3349%, Training Loss: 0.3079%\n",
      "Epoch [54/300], Step [143/225], Training Accuracy: 87.3580%, Training Loss: 0.3077%\n",
      "Epoch [54/300], Step [144/225], Training Accuracy: 87.3698%, Training Loss: 0.3073%\n",
      "Epoch [54/300], Step [145/225], Training Accuracy: 87.3599%, Training Loss: 0.3076%\n",
      "Epoch [54/300], Step [146/225], Training Accuracy: 87.3181%, Training Loss: 0.3082%\n",
      "Epoch [54/300], Step [147/225], Training Accuracy: 87.3193%, Training Loss: 0.3083%\n",
      "Epoch [54/300], Step [148/225], Training Accuracy: 87.3311%, Training Loss: 0.3081%\n",
      "Epoch [54/300], Step [149/225], Training Accuracy: 87.3532%, Training Loss: 0.3076%\n",
      "Epoch [54/300], Step [150/225], Training Accuracy: 87.3854%, Training Loss: 0.3069%\n",
      "Epoch [54/300], Step [151/225], Training Accuracy: 87.3965%, Training Loss: 0.3068%\n",
      "Epoch [54/300], Step [152/225], Training Accuracy: 87.3869%, Training Loss: 0.3064%\n",
      "Epoch [54/300], Step [153/225], Training Accuracy: 87.4081%, Training Loss: 0.3059%\n",
      "Epoch [54/300], Step [154/225], Training Accuracy: 87.4087%, Training Loss: 0.3063%\n",
      "Epoch [54/300], Step [155/225], Training Accuracy: 87.3992%, Training Loss: 0.3066%\n",
      "Epoch [54/300], Step [156/225], Training Accuracy: 87.3998%, Training Loss: 0.3064%\n",
      "Epoch [54/300], Step [157/225], Training Accuracy: 87.4005%, Training Loss: 0.3065%\n",
      "Epoch [54/300], Step [158/225], Training Accuracy: 87.3912%, Training Loss: 0.3064%\n",
      "Epoch [54/300], Step [159/225], Training Accuracy: 87.3722%, Training Loss: 0.3068%\n",
      "Epoch [54/300], Step [160/225], Training Accuracy: 87.3828%, Training Loss: 0.3061%\n",
      "Epoch [54/300], Step [161/225], Training Accuracy: 87.3447%, Training Loss: 0.3068%\n",
      "Epoch [54/300], Step [162/225], Training Accuracy: 87.3553%, Training Loss: 0.3067%\n",
      "Epoch [54/300], Step [163/225], Training Accuracy: 87.3466%, Training Loss: 0.3071%\n",
      "Epoch [54/300], Step [164/225], Training Accuracy: 87.3476%, Training Loss: 0.3074%\n",
      "Epoch [54/300], Step [165/225], Training Accuracy: 87.3390%, Training Loss: 0.3075%\n",
      "Epoch [54/300], Step [166/225], Training Accuracy: 87.3117%, Training Loss: 0.3077%\n",
      "Epoch [54/300], Step [167/225], Training Accuracy: 87.2942%, Training Loss: 0.3078%\n",
      "Epoch [54/300], Step [168/225], Training Accuracy: 87.2582%, Training Loss: 0.3087%\n",
      "Epoch [54/300], Step [169/225], Training Accuracy: 87.2781%, Training Loss: 0.3084%\n",
      "Epoch [54/300], Step [170/225], Training Accuracy: 87.2426%, Training Loss: 0.3089%\n",
      "Epoch [54/300], Step [171/225], Training Accuracy: 87.1985%, Training Loss: 0.3097%\n",
      "Epoch [54/300], Step [172/225], Training Accuracy: 87.1820%, Training Loss: 0.3099%\n",
      "Epoch [54/300], Step [173/225], Training Accuracy: 87.1749%, Training Loss: 0.3102%\n",
      "Epoch [54/300], Step [174/225], Training Accuracy: 87.1318%, Training Loss: 0.3104%\n",
      "Epoch [54/300], Step [175/225], Training Accuracy: 87.1875%, Training Loss: 0.3098%\n",
      "Epoch [54/300], Step [176/225], Training Accuracy: 87.1893%, Training Loss: 0.3095%\n",
      "Epoch [54/300], Step [177/225], Training Accuracy: 87.1910%, Training Loss: 0.3094%\n",
      "Epoch [54/300], Step [178/225], Training Accuracy: 87.2191%, Training Loss: 0.3092%\n",
      "Epoch [54/300], Step [179/225], Training Accuracy: 87.2818%, Training Loss: 0.3084%\n",
      "Epoch [54/300], Step [180/225], Training Accuracy: 87.2743%, Training Loss: 0.3084%\n",
      "Epoch [54/300], Step [181/225], Training Accuracy: 87.2842%, Training Loss: 0.3084%\n",
      "Epoch [54/300], Step [182/225], Training Accuracy: 87.2682%, Training Loss: 0.3092%\n",
      "Epoch [54/300], Step [183/225], Training Accuracy: 87.2524%, Training Loss: 0.3099%\n",
      "Epoch [54/300], Step [184/225], Training Accuracy: 87.2622%, Training Loss: 0.3096%\n",
      "Epoch [54/300], Step [185/225], Training Accuracy: 87.3057%, Training Loss: 0.3091%\n",
      "Epoch [54/300], Step [186/225], Training Accuracy: 87.3404%, Training Loss: 0.3086%\n",
      "Epoch [54/300], Step [187/225], Training Accuracy: 87.3329%, Training Loss: 0.3086%\n",
      "Epoch [54/300], Step [188/225], Training Accuracy: 87.3504%, Training Loss: 0.3081%\n",
      "Epoch [54/300], Step [189/225], Training Accuracy: 87.3595%, Training Loss: 0.3078%\n",
      "Epoch [54/300], Step [190/225], Training Accuracy: 87.3602%, Training Loss: 0.3080%\n",
      "Epoch [54/300], Step [191/225], Training Accuracy: 87.3691%, Training Loss: 0.3081%\n",
      "Epoch [54/300], Step [192/225], Training Accuracy: 87.3698%, Training Loss: 0.3082%\n",
      "Epoch [54/300], Step [193/225], Training Accuracy: 87.3867%, Training Loss: 0.3079%\n",
      "Epoch [54/300], Step [194/225], Training Accuracy: 87.3389%, Training Loss: 0.3087%\n",
      "Epoch [54/300], Step [195/225], Training Accuracy: 87.3397%, Training Loss: 0.3084%\n",
      "Epoch [54/300], Step [196/225], Training Accuracy: 87.3485%, Training Loss: 0.3083%\n",
      "Epoch [54/300], Step [197/225], Training Accuracy: 87.3255%, Training Loss: 0.3083%\n",
      "Epoch [54/300], Step [198/225], Training Accuracy: 87.3264%, Training Loss: 0.3082%\n",
      "Epoch [54/300], Step [199/225], Training Accuracy: 87.3194%, Training Loss: 0.3081%\n",
      "Epoch [54/300], Step [200/225], Training Accuracy: 87.3516%, Training Loss: 0.3075%\n",
      "Epoch [54/300], Step [201/225], Training Accuracy: 87.3601%, Training Loss: 0.3075%\n",
      "Epoch [54/300], Step [202/225], Training Accuracy: 87.3840%, Training Loss: 0.3076%\n",
      "Epoch [54/300], Step [203/225], Training Accuracy: 87.4153%, Training Loss: 0.3070%\n",
      "Epoch [54/300], Step [204/225], Training Accuracy: 87.4387%, Training Loss: 0.3064%\n",
      "Epoch [54/300], Step [205/225], Training Accuracy: 87.4543%, Training Loss: 0.3064%\n",
      "Epoch [54/300], Step [206/225], Training Accuracy: 87.4621%, Training Loss: 0.3062%\n",
      "Epoch [54/300], Step [207/225], Training Accuracy: 87.4925%, Training Loss: 0.3058%\n",
      "Epoch [54/300], Step [208/225], Training Accuracy: 87.4925%, Training Loss: 0.3062%\n",
      "Epoch [54/300], Step [209/225], Training Accuracy: 87.4402%, Training Loss: 0.3066%\n",
      "Epoch [54/300], Step [210/225], Training Accuracy: 87.4182%, Training Loss: 0.3073%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/300], Step [211/225], Training Accuracy: 87.4111%, Training Loss: 0.3074%\n",
      "Epoch [54/300], Step [212/225], Training Accuracy: 87.3968%, Training Loss: 0.3076%\n",
      "Epoch [54/300], Step [213/225], Training Accuracy: 87.4340%, Training Loss: 0.3070%\n",
      "Epoch [54/300], Step [214/225], Training Accuracy: 87.4270%, Training Loss: 0.3070%\n",
      "Epoch [54/300], Step [215/225], Training Accuracy: 87.4128%, Training Loss: 0.3070%\n",
      "Epoch [54/300], Step [216/225], Training Accuracy: 87.3987%, Training Loss: 0.3073%\n",
      "Epoch [54/300], Step [217/225], Training Accuracy: 87.4064%, Training Loss: 0.3071%\n",
      "Epoch [54/300], Step [218/225], Training Accuracy: 87.4140%, Training Loss: 0.3072%\n",
      "Epoch [54/300], Step [219/225], Training Accuracy: 87.4072%, Training Loss: 0.3072%\n",
      "Epoch [54/300], Step [220/225], Training Accuracy: 87.4077%, Training Loss: 0.3069%\n",
      "Epoch [54/300], Step [221/225], Training Accuracy: 87.4364%, Training Loss: 0.3063%\n",
      "Epoch [54/300], Step [222/225], Training Accuracy: 87.4578%, Training Loss: 0.3063%\n",
      "Epoch [54/300], Step [223/225], Training Accuracy: 87.4720%, Training Loss: 0.3061%\n",
      "Epoch [54/300], Step [224/225], Training Accuracy: 87.4791%, Training Loss: 0.3058%\n",
      "Epoch [54/300], Step [225/225], Training Accuracy: 87.4792%, Training Loss: 0.3057%\n",
      "Epoch [55/300], Step [1/225], Training Accuracy: 84.3750%, Training Loss: 0.3287%\n",
      "Epoch [55/300], Step [2/225], Training Accuracy: 86.7188%, Training Loss: 0.2934%\n",
      "Epoch [55/300], Step [3/225], Training Accuracy: 89.0625%, Training Loss: 0.2939%\n",
      "Epoch [55/300], Step [4/225], Training Accuracy: 88.6719%, Training Loss: 0.3220%\n",
      "Epoch [55/300], Step [5/225], Training Accuracy: 89.0625%, Training Loss: 0.3097%\n",
      "Epoch [55/300], Step [6/225], Training Accuracy: 89.5833%, Training Loss: 0.2991%\n",
      "Epoch [55/300], Step [7/225], Training Accuracy: 89.7321%, Training Loss: 0.2936%\n",
      "Epoch [55/300], Step [8/225], Training Accuracy: 89.0625%, Training Loss: 0.3011%\n",
      "Epoch [55/300], Step [9/225], Training Accuracy: 89.0625%, Training Loss: 0.3042%\n",
      "Epoch [55/300], Step [10/225], Training Accuracy: 88.1250%, Training Loss: 0.3207%\n",
      "Epoch [55/300], Step [11/225], Training Accuracy: 88.4943%, Training Loss: 0.3181%\n",
      "Epoch [55/300], Step [12/225], Training Accuracy: 88.6719%, Training Loss: 0.3193%\n",
      "Epoch [55/300], Step [13/225], Training Accuracy: 89.1827%, Training Loss: 0.3067%\n",
      "Epoch [55/300], Step [14/225], Training Accuracy: 88.5045%, Training Loss: 0.3126%\n",
      "Epoch [55/300], Step [15/225], Training Accuracy: 88.2292%, Training Loss: 0.3149%\n",
      "Epoch [55/300], Step [16/225], Training Accuracy: 88.0859%, Training Loss: 0.3171%\n",
      "Epoch [55/300], Step [17/225], Training Accuracy: 88.0515%, Training Loss: 0.3210%\n",
      "Epoch [55/300], Step [18/225], Training Accuracy: 88.0208%, Training Loss: 0.3187%\n",
      "Epoch [55/300], Step [19/225], Training Accuracy: 87.5822%, Training Loss: 0.3212%\n",
      "Epoch [55/300], Step [20/225], Training Accuracy: 87.2656%, Training Loss: 0.3226%\n",
      "Epoch [55/300], Step [21/225], Training Accuracy: 87.5000%, Training Loss: 0.3162%\n",
      "Epoch [55/300], Step [22/225], Training Accuracy: 87.6420%, Training Loss: 0.3140%\n",
      "Epoch [55/300], Step [23/225], Training Accuracy: 87.6359%, Training Loss: 0.3149%\n",
      "Epoch [55/300], Step [24/225], Training Accuracy: 87.2396%, Training Loss: 0.3185%\n",
      "Epoch [55/300], Step [25/225], Training Accuracy: 87.3750%, Training Loss: 0.3132%\n",
      "Epoch [55/300], Step [26/225], Training Accuracy: 87.1995%, Training Loss: 0.3124%\n",
      "Epoch [55/300], Step [27/225], Training Accuracy: 87.1528%, Training Loss: 0.3128%\n",
      "Epoch [55/300], Step [28/225], Training Accuracy: 87.2768%, Training Loss: 0.3096%\n",
      "Epoch [55/300], Step [29/225], Training Accuracy: 87.2306%, Training Loss: 0.3108%\n",
      "Epoch [55/300], Step [30/225], Training Accuracy: 87.1354%, Training Loss: 0.3117%\n",
      "Epoch [55/300], Step [31/225], Training Accuracy: 86.9960%, Training Loss: 0.3125%\n",
      "Epoch [55/300], Step [32/225], Training Accuracy: 87.0605%, Training Loss: 0.3099%\n",
      "Epoch [55/300], Step [33/225], Training Accuracy: 87.0739%, Training Loss: 0.3102%\n",
      "Epoch [55/300], Step [34/225], Training Accuracy: 86.9485%, Training Loss: 0.3124%\n",
      "Epoch [55/300], Step [35/225], Training Accuracy: 86.9643%, Training Loss: 0.3116%\n",
      "Epoch [55/300], Step [36/225], Training Accuracy: 86.9792%, Training Loss: 0.3105%\n",
      "Epoch [55/300], Step [37/225], Training Accuracy: 87.0777%, Training Loss: 0.3098%\n",
      "Epoch [55/300], Step [38/225], Training Accuracy: 87.1711%, Training Loss: 0.3080%\n",
      "Epoch [55/300], Step [39/225], Training Accuracy: 87.1394%, Training Loss: 0.3064%\n",
      "Epoch [55/300], Step [40/225], Training Accuracy: 87.1875%, Training Loss: 0.3050%\n",
      "Epoch [55/300], Step [41/225], Training Accuracy: 87.0427%, Training Loss: 0.3087%\n",
      "Epoch [55/300], Step [42/225], Training Accuracy: 87.0164%, Training Loss: 0.3084%\n",
      "Epoch [55/300], Step [43/225], Training Accuracy: 87.1730%, Training Loss: 0.3061%\n",
      "Epoch [55/300], Step [44/225], Training Accuracy: 87.2159%, Training Loss: 0.3063%\n",
      "Epoch [55/300], Step [45/225], Training Accuracy: 87.1875%, Training Loss: 0.3058%\n",
      "Epoch [55/300], Step [46/225], Training Accuracy: 87.2283%, Training Loss: 0.3055%\n",
      "Epoch [55/300], Step [47/225], Training Accuracy: 87.0346%, Training Loss: 0.3088%\n",
      "Epoch [55/300], Step [48/225], Training Accuracy: 87.1094%, Training Loss: 0.3080%\n",
      "Epoch [55/300], Step [49/225], Training Accuracy: 87.2449%, Training Loss: 0.3046%\n",
      "Epoch [55/300], Step [50/225], Training Accuracy: 87.3750%, Training Loss: 0.3035%\n",
      "Epoch [55/300], Step [51/225], Training Accuracy: 87.4694%, Training Loss: 0.3030%\n",
      "Epoch [55/300], Step [52/225], Training Accuracy: 87.5601%, Training Loss: 0.3004%\n",
      "Epoch [55/300], Step [53/225], Training Accuracy: 87.5590%, Training Loss: 0.3011%\n",
      "Epoch [55/300], Step [54/225], Training Accuracy: 87.5579%, Training Loss: 0.3009%\n",
      "Epoch [55/300], Step [55/225], Training Accuracy: 87.4432%, Training Loss: 0.3035%\n",
      "Epoch [55/300], Step [56/225], Training Accuracy: 87.5558%, Training Loss: 0.3018%\n",
      "Epoch [55/300], Step [57/225], Training Accuracy: 87.5274%, Training Loss: 0.3040%\n",
      "Epoch [55/300], Step [58/225], Training Accuracy: 87.5269%, Training Loss: 0.3042%\n",
      "Epoch [55/300], Step [59/225], Training Accuracy: 87.5000%, Training Loss: 0.3037%\n",
      "Epoch [55/300], Step [60/225], Training Accuracy: 87.5781%, Training Loss: 0.3022%\n",
      "Epoch [55/300], Step [61/225], Training Accuracy: 87.5512%, Training Loss: 0.3026%\n",
      "Epoch [55/300], Step [62/225], Training Accuracy: 87.5252%, Training Loss: 0.3038%\n",
      "Epoch [55/300], Step [63/225], Training Accuracy: 87.5248%, Training Loss: 0.3044%\n",
      "Epoch [55/300], Step [64/225], Training Accuracy: 87.5000%, Training Loss: 0.3051%\n",
      "Epoch [55/300], Step [65/225], Training Accuracy: 87.5000%, Training Loss: 0.3052%\n",
      "Epoch [55/300], Step [66/225], Training Accuracy: 87.4763%, Training Loss: 0.3055%\n",
      "Epoch [55/300], Step [67/225], Training Accuracy: 87.5466%, Training Loss: 0.3043%\n",
      "Epoch [55/300], Step [68/225], Training Accuracy: 87.5460%, Training Loss: 0.3067%\n",
      "Epoch [55/300], Step [69/225], Training Accuracy: 87.5679%, Training Loss: 0.3058%\n",
      "Epoch [55/300], Step [70/225], Training Accuracy: 87.5893%, Training Loss: 0.3056%\n",
      "Epoch [55/300], Step [71/225], Training Accuracy: 87.5660%, Training Loss: 0.3065%\n",
      "Epoch [55/300], Step [72/225], Training Accuracy: 87.5000%, Training Loss: 0.3074%\n",
      "Epoch [55/300], Step [73/225], Training Accuracy: 87.5000%, Training Loss: 0.3073%\n",
      "Epoch [55/300], Step [74/225], Training Accuracy: 87.5211%, Training Loss: 0.3072%\n",
      "Epoch [55/300], Step [75/225], Training Accuracy: 87.4583%, Training Loss: 0.3077%\n",
      "Epoch [55/300], Step [76/225], Training Accuracy: 87.2944%, Training Loss: 0.3100%\n",
      "Epoch [55/300], Step [77/225], Training Accuracy: 87.2768%, Training Loss: 0.3098%\n",
      "Epoch [55/300], Step [78/225], Training Accuracy: 87.3798%, Training Loss: 0.3083%\n",
      "Epoch [55/300], Step [79/225], Training Accuracy: 87.5000%, Training Loss: 0.3062%\n",
      "Epoch [55/300], Step [80/225], Training Accuracy: 87.5586%, Training Loss: 0.3056%\n",
      "Epoch [55/300], Step [81/225], Training Accuracy: 87.5579%, Training Loss: 0.3051%\n",
      "Epoch [55/300], Step [82/225], Training Accuracy: 87.5381%, Training Loss: 0.3054%\n",
      "Epoch [55/300], Step [83/225], Training Accuracy: 87.5565%, Training Loss: 0.3046%\n",
      "Epoch [55/300], Step [84/225], Training Accuracy: 87.5930%, Training Loss: 0.3036%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/300], Step [85/225], Training Accuracy: 87.6103%, Training Loss: 0.3026%\n",
      "Epoch [55/300], Step [86/225], Training Accuracy: 87.6453%, Training Loss: 0.3018%\n",
      "Epoch [55/300], Step [87/225], Training Accuracy: 87.5718%, Training Loss: 0.3037%\n",
      "Epoch [55/300], Step [88/225], Training Accuracy: 87.5000%, Training Loss: 0.3060%\n",
      "Epoch [55/300], Step [89/225], Training Accuracy: 87.4824%, Training Loss: 0.3055%\n",
      "Epoch [55/300], Step [90/225], Training Accuracy: 87.5347%, Training Loss: 0.3051%\n",
      "Epoch [55/300], Step [91/225], Training Accuracy: 87.5687%, Training Loss: 0.3044%\n",
      "Epoch [55/300], Step [92/225], Training Accuracy: 87.5849%, Training Loss: 0.3043%\n",
      "Epoch [55/300], Step [93/225], Training Accuracy: 87.6008%, Training Loss: 0.3039%\n",
      "Epoch [55/300], Step [94/225], Training Accuracy: 87.5665%, Training Loss: 0.3036%\n",
      "Epoch [55/300], Step [95/225], Training Accuracy: 87.5493%, Training Loss: 0.3034%\n",
      "Epoch [55/300], Step [96/225], Training Accuracy: 87.5814%, Training Loss: 0.3025%\n",
      "Epoch [55/300], Step [97/225], Training Accuracy: 87.5483%, Training Loss: 0.3025%\n",
      "Epoch [55/300], Step [98/225], Training Accuracy: 87.5319%, Training Loss: 0.3024%\n",
      "Epoch [55/300], Step [99/225], Training Accuracy: 87.5000%, Training Loss: 0.3026%\n",
      "Epoch [55/300], Step [100/225], Training Accuracy: 87.4375%, Training Loss: 0.3040%\n",
      "Epoch [55/300], Step [101/225], Training Accuracy: 87.3762%, Training Loss: 0.3051%\n",
      "Epoch [55/300], Step [102/225], Training Accuracy: 87.3775%, Training Loss: 0.3057%\n",
      "Epoch [55/300], Step [103/225], Training Accuracy: 87.4242%, Training Loss: 0.3050%\n",
      "Epoch [55/300], Step [104/225], Training Accuracy: 87.3948%, Training Loss: 0.3056%\n",
      "Epoch [55/300], Step [105/225], Training Accuracy: 87.4256%, Training Loss: 0.3050%\n",
      "Epoch [55/300], Step [106/225], Training Accuracy: 87.4410%, Training Loss: 0.3048%\n",
      "Epoch [55/300], Step [107/225], Training Accuracy: 87.4854%, Training Loss: 0.3042%\n",
      "Epoch [55/300], Step [108/225], Training Accuracy: 87.4711%, Training Loss: 0.3048%\n",
      "Epoch [55/300], Step [109/225], Training Accuracy: 87.5143%, Training Loss: 0.3045%\n",
      "Epoch [55/300], Step [110/225], Training Accuracy: 87.5568%, Training Loss: 0.3042%\n",
      "Epoch [55/300], Step [111/225], Training Accuracy: 87.5985%, Training Loss: 0.3037%\n",
      "Epoch [55/300], Step [112/225], Training Accuracy: 87.5977%, Training Loss: 0.3034%\n",
      "Epoch [55/300], Step [113/225], Training Accuracy: 87.6106%, Training Loss: 0.3035%\n",
      "Epoch [55/300], Step [114/225], Training Accuracy: 87.6645%, Training Loss: 0.3030%\n",
      "Epoch [55/300], Step [115/225], Training Accuracy: 87.6087%, Training Loss: 0.3035%\n",
      "Epoch [55/300], Step [116/225], Training Accuracy: 87.5808%, Training Loss: 0.3040%\n",
      "Epoch [55/300], Step [117/225], Training Accuracy: 87.5668%, Training Loss: 0.3042%\n",
      "Epoch [55/300], Step [118/225], Training Accuracy: 87.6324%, Training Loss: 0.3038%\n",
      "Epoch [55/300], Step [119/225], Training Accuracy: 87.6182%, Training Loss: 0.3045%\n",
      "Epoch [55/300], Step [120/225], Training Accuracy: 87.6042%, Training Loss: 0.3048%\n",
      "Epoch [55/300], Step [121/225], Training Accuracy: 87.6291%, Training Loss: 0.3040%\n",
      "Epoch [55/300], Step [122/225], Training Accuracy: 87.6409%, Training Loss: 0.3035%\n",
      "Epoch [55/300], Step [123/225], Training Accuracy: 87.6524%, Training Loss: 0.3033%\n",
      "Epoch [55/300], Step [124/225], Training Accuracy: 87.6638%, Training Loss: 0.3027%\n",
      "Epoch [55/300], Step [125/225], Training Accuracy: 87.6625%, Training Loss: 0.3032%\n",
      "Epoch [55/300], Step [126/225], Training Accuracy: 87.6860%, Training Loss: 0.3027%\n",
      "Epoch [55/300], Step [127/225], Training Accuracy: 87.7092%, Training Loss: 0.3022%\n",
      "Epoch [55/300], Step [128/225], Training Accuracy: 87.6709%, Training Loss: 0.3029%\n",
      "Epoch [55/300], Step [129/225], Training Accuracy: 87.6575%, Training Loss: 0.3028%\n",
      "Epoch [55/300], Step [130/225], Training Accuracy: 87.6803%, Training Loss: 0.3027%\n",
      "Epoch [55/300], Step [131/225], Training Accuracy: 87.6789%, Training Loss: 0.3030%\n",
      "Epoch [55/300], Step [132/225], Training Accuracy: 87.6776%, Training Loss: 0.3030%\n",
      "Epoch [55/300], Step [133/225], Training Accuracy: 87.7115%, Training Loss: 0.3026%\n",
      "Epoch [55/300], Step [134/225], Training Accuracy: 87.6866%, Training Loss: 0.3029%\n",
      "Epoch [55/300], Step [135/225], Training Accuracy: 87.7083%, Training Loss: 0.3031%\n",
      "Epoch [55/300], Step [136/225], Training Accuracy: 87.7068%, Training Loss: 0.3030%\n",
      "Epoch [55/300], Step [137/225], Training Accuracy: 87.7281%, Training Loss: 0.3025%\n",
      "Epoch [55/300], Step [138/225], Training Accuracy: 87.7604%, Training Loss: 0.3017%\n",
      "Epoch [55/300], Step [139/225], Training Accuracy: 87.7923%, Training Loss: 0.3013%\n",
      "Epoch [55/300], Step [140/225], Training Accuracy: 87.8125%, Training Loss: 0.3006%\n",
      "Epoch [55/300], Step [141/225], Training Accuracy: 87.7549%, Training Loss: 0.3019%\n",
      "Epoch [55/300], Step [142/225], Training Accuracy: 87.7531%, Training Loss: 0.3016%\n",
      "Epoch [55/300], Step [143/225], Training Accuracy: 87.7295%, Training Loss: 0.3017%\n",
      "Epoch [55/300], Step [144/225], Training Accuracy: 87.6953%, Training Loss: 0.3022%\n",
      "Epoch [55/300], Step [145/225], Training Accuracy: 87.6832%, Training Loss: 0.3025%\n",
      "Epoch [55/300], Step [146/225], Training Accuracy: 87.6605%, Training Loss: 0.3038%\n",
      "Epoch [55/300], Step [147/225], Training Accuracy: 87.6488%, Training Loss: 0.3038%\n",
      "Epoch [55/300], Step [148/225], Training Accuracy: 87.6584%, Training Loss: 0.3032%\n",
      "Epoch [55/300], Step [149/225], Training Accuracy: 87.6573%, Training Loss: 0.3029%\n",
      "Epoch [55/300], Step [150/225], Training Accuracy: 87.7083%, Training Loss: 0.3018%\n",
      "Epoch [55/300], Step [151/225], Training Accuracy: 87.7276%, Training Loss: 0.3017%\n",
      "Epoch [55/300], Step [152/225], Training Accuracy: 87.7364%, Training Loss: 0.3014%\n",
      "Epoch [55/300], Step [153/225], Training Accuracy: 87.6940%, Training Loss: 0.3016%\n",
      "Epoch [55/300], Step [154/225], Training Accuracy: 87.7029%, Training Loss: 0.3016%\n",
      "Epoch [55/300], Step [155/225], Training Accuracy: 87.7218%, Training Loss: 0.3016%\n",
      "Epoch [55/300], Step [156/225], Training Accuracy: 87.7304%, Training Loss: 0.3018%\n",
      "Epoch [55/300], Step [157/225], Training Accuracy: 87.7189%, Training Loss: 0.3019%\n",
      "Epoch [55/300], Step [158/225], Training Accuracy: 87.6780%, Training Loss: 0.3024%\n",
      "Epoch [55/300], Step [159/225], Training Accuracy: 87.6572%, Training Loss: 0.3022%\n",
      "Epoch [55/300], Step [160/225], Training Accuracy: 87.6660%, Training Loss: 0.3023%\n",
      "Epoch [55/300], Step [161/225], Training Accuracy: 87.6262%, Training Loss: 0.3028%\n",
      "Epoch [55/300], Step [162/225], Training Accuracy: 87.6157%, Training Loss: 0.3030%\n",
      "Epoch [55/300], Step [163/225], Training Accuracy: 87.6054%, Training Loss: 0.3031%\n",
      "Epoch [55/300], Step [164/225], Training Accuracy: 87.6143%, Training Loss: 0.3030%\n",
      "Epoch [55/300], Step [165/225], Training Accuracy: 87.6420%, Training Loss: 0.3029%\n",
      "Epoch [55/300], Step [166/225], Training Accuracy: 87.6412%, Training Loss: 0.3031%\n",
      "Epoch [55/300], Step [167/225], Training Accuracy: 87.6310%, Training Loss: 0.3036%\n",
      "Epoch [55/300], Step [168/225], Training Accuracy: 87.6395%, Training Loss: 0.3034%\n",
      "Epoch [55/300], Step [169/225], Training Accuracy: 87.6294%, Training Loss: 0.3034%\n",
      "Epoch [55/300], Step [170/225], Training Accuracy: 87.6471%, Training Loss: 0.3034%\n",
      "Epoch [55/300], Step [171/225], Training Accuracy: 87.6096%, Training Loss: 0.3042%\n",
      "Epoch [55/300], Step [172/225], Training Accuracy: 87.5727%, Training Loss: 0.3044%\n",
      "Epoch [55/300], Step [173/225], Training Accuracy: 87.5361%, Training Loss: 0.3050%\n",
      "Epoch [55/300], Step [174/225], Training Accuracy: 87.5359%, Training Loss: 0.3050%\n",
      "Epoch [55/300], Step [175/225], Training Accuracy: 87.5625%, Training Loss: 0.3047%\n",
      "Epoch [55/300], Step [176/225], Training Accuracy: 87.5355%, Training Loss: 0.3049%\n",
      "Epoch [55/300], Step [177/225], Training Accuracy: 87.5088%, Training Loss: 0.3056%\n",
      "Epoch [55/300], Step [178/225], Training Accuracy: 87.4386%, Training Loss: 0.3068%\n",
      "Epoch [55/300], Step [179/225], Training Accuracy: 87.4302%, Training Loss: 0.3071%\n",
      "Epoch [55/300], Step [180/225], Training Accuracy: 87.4132%, Training Loss: 0.3076%\n",
      "Epoch [55/300], Step [181/225], Training Accuracy: 87.4050%, Training Loss: 0.3080%\n",
      "Epoch [55/300], Step [182/225], Training Accuracy: 87.3541%, Training Loss: 0.3081%\n",
      "Epoch [55/300], Step [183/225], Training Accuracy: 87.3207%, Training Loss: 0.3085%\n",
      "Epoch [55/300], Step [184/225], Training Accuracy: 87.3302%, Training Loss: 0.3080%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/300], Step [185/225], Training Accuracy: 87.3395%, Training Loss: 0.3079%\n",
      "Epoch [55/300], Step [186/225], Training Accuracy: 87.3656%, Training Loss: 0.3072%\n",
      "Epoch [55/300], Step [187/225], Training Accuracy: 87.3496%, Training Loss: 0.3073%\n",
      "Epoch [55/300], Step [188/225], Training Accuracy: 87.3504%, Training Loss: 0.3076%\n",
      "Epoch [55/300], Step [189/225], Training Accuracy: 87.3595%, Training Loss: 0.3073%\n",
      "Epoch [55/300], Step [190/225], Training Accuracy: 87.3766%, Training Loss: 0.3069%\n",
      "Epoch [55/300], Step [191/225], Training Accuracy: 87.3527%, Training Loss: 0.3073%\n",
      "Epoch [55/300], Step [192/225], Training Accuracy: 87.3698%, Training Loss: 0.3075%\n",
      "Epoch [55/300], Step [193/225], Training Accuracy: 87.3705%, Training Loss: 0.3078%\n",
      "Epoch [55/300], Step [194/225], Training Accuracy: 87.3792%, Training Loss: 0.3080%\n",
      "Epoch [55/300], Step [195/225], Training Accuracy: 87.4038%, Training Loss: 0.3073%\n",
      "Epoch [55/300], Step [196/225], Training Accuracy: 87.3804%, Training Loss: 0.3078%\n",
      "Epoch [55/300], Step [197/225], Training Accuracy: 87.3652%, Training Loss: 0.3082%\n",
      "Epoch [55/300], Step [198/225], Training Accuracy: 87.3737%, Training Loss: 0.3081%\n",
      "Epoch [55/300], Step [199/225], Training Accuracy: 87.3665%, Training Loss: 0.3080%\n",
      "Epoch [55/300], Step [200/225], Training Accuracy: 87.3750%, Training Loss: 0.3075%\n",
      "Epoch [55/300], Step [201/225], Training Accuracy: 87.3834%, Training Loss: 0.3077%\n",
      "Epoch [55/300], Step [202/225], Training Accuracy: 87.3685%, Training Loss: 0.3082%\n",
      "Epoch [55/300], Step [203/225], Training Accuracy: 87.3768%, Training Loss: 0.3079%\n",
      "Epoch [55/300], Step [204/225], Training Accuracy: 87.4004%, Training Loss: 0.3077%\n",
      "Epoch [55/300], Step [205/225], Training Accuracy: 87.4238%, Training Loss: 0.3073%\n",
      "Epoch [55/300], Step [206/225], Training Accuracy: 87.4393%, Training Loss: 0.3069%\n",
      "Epoch [55/300], Step [207/225], Training Accuracy: 87.4472%, Training Loss: 0.3069%\n",
      "Epoch [55/300], Step [208/225], Training Accuracy: 87.4624%, Training Loss: 0.3068%\n",
      "Epoch [55/300], Step [209/225], Training Accuracy: 87.4477%, Training Loss: 0.3072%\n",
      "Epoch [55/300], Step [210/225], Training Accuracy: 87.4330%, Training Loss: 0.3076%\n",
      "Epoch [55/300], Step [211/225], Training Accuracy: 87.4185%, Training Loss: 0.3079%\n",
      "Epoch [55/300], Step [212/225], Training Accuracy: 87.4263%, Training Loss: 0.3080%\n",
      "Epoch [55/300], Step [213/225], Training Accuracy: 87.4340%, Training Loss: 0.3077%\n",
      "Epoch [55/300], Step [214/225], Training Accuracy: 87.4416%, Training Loss: 0.3077%\n",
      "Epoch [55/300], Step [215/225], Training Accuracy: 87.4564%, Training Loss: 0.3078%\n",
      "Epoch [55/300], Step [216/225], Training Accuracy: 87.4566%, Training Loss: 0.3084%\n",
      "Epoch [55/300], Step [217/225], Training Accuracy: 87.4496%, Training Loss: 0.3087%\n",
      "Epoch [55/300], Step [218/225], Training Accuracy: 87.4355%, Training Loss: 0.3088%\n",
      "Epoch [55/300], Step [219/225], Training Accuracy: 87.4429%, Training Loss: 0.3087%\n",
      "Epoch [55/300], Step [220/225], Training Accuracy: 87.4361%, Training Loss: 0.3086%\n",
      "Epoch [55/300], Step [221/225], Training Accuracy: 87.4576%, Training Loss: 0.3083%\n",
      "Epoch [55/300], Step [222/225], Training Accuracy: 87.4648%, Training Loss: 0.3080%\n",
      "Epoch [55/300], Step [223/225], Training Accuracy: 87.4439%, Training Loss: 0.3083%\n",
      "Epoch [55/300], Step [224/225], Training Accuracy: 87.4581%, Training Loss: 0.3081%\n",
      "Epoch [55/300], Step [225/225], Training Accuracy: 87.4653%, Training Loss: 0.3081%\n",
      "Epoch [56/300], Step [1/225], Training Accuracy: 90.6250%, Training Loss: 0.2360%\n",
      "Epoch [56/300], Step [2/225], Training Accuracy: 89.0625%, Training Loss: 0.2679%\n",
      "Epoch [56/300], Step [3/225], Training Accuracy: 88.0208%, Training Loss: 0.2764%\n",
      "Epoch [56/300], Step [4/225], Training Accuracy: 87.8906%, Training Loss: 0.2795%\n",
      "Epoch [56/300], Step [5/225], Training Accuracy: 87.8125%, Training Loss: 0.2761%\n",
      "Epoch [56/300], Step [6/225], Training Accuracy: 88.2812%, Training Loss: 0.2754%\n",
      "Epoch [56/300], Step [7/225], Training Accuracy: 87.9464%, Training Loss: 0.2806%\n",
      "Epoch [56/300], Step [8/225], Training Accuracy: 87.6953%, Training Loss: 0.2932%\n",
      "Epoch [56/300], Step [9/225], Training Accuracy: 88.3681%, Training Loss: 0.2839%\n",
      "Epoch [56/300], Step [10/225], Training Accuracy: 87.9688%, Training Loss: 0.2935%\n",
      "Epoch [56/300], Step [11/225], Training Accuracy: 87.3580%, Training Loss: 0.3058%\n",
      "Epoch [56/300], Step [12/225], Training Accuracy: 87.3698%, Training Loss: 0.3084%\n",
      "Epoch [56/300], Step [13/225], Training Accuracy: 87.3798%, Training Loss: 0.3058%\n",
      "Epoch [56/300], Step [14/225], Training Accuracy: 87.1652%, Training Loss: 0.3082%\n",
      "Epoch [56/300], Step [15/225], Training Accuracy: 87.1875%, Training Loss: 0.3175%\n",
      "Epoch [56/300], Step [16/225], Training Accuracy: 87.2070%, Training Loss: 0.3169%\n",
      "Epoch [56/300], Step [17/225], Training Accuracy: 87.5000%, Training Loss: 0.3116%\n",
      "Epoch [56/300], Step [18/225], Training Accuracy: 87.7604%, Training Loss: 0.3084%\n",
      "Epoch [56/300], Step [19/225], Training Accuracy: 87.8289%, Training Loss: 0.3099%\n",
      "Epoch [56/300], Step [20/225], Training Accuracy: 87.8125%, Training Loss: 0.3074%\n",
      "Epoch [56/300], Step [21/225], Training Accuracy: 87.7232%, Training Loss: 0.3025%\n",
      "Epoch [56/300], Step [22/225], Training Accuracy: 87.2159%, Training Loss: 0.3079%\n",
      "Epoch [56/300], Step [23/225], Training Accuracy: 87.3641%, Training Loss: 0.3085%\n",
      "Epoch [56/300], Step [24/225], Training Accuracy: 87.3047%, Training Loss: 0.3109%\n",
      "Epoch [56/300], Step [25/225], Training Accuracy: 87.4375%, Training Loss: 0.3097%\n",
      "Epoch [56/300], Step [26/225], Training Accuracy: 87.6803%, Training Loss: 0.3065%\n",
      "Epoch [56/300], Step [27/225], Training Accuracy: 87.6157%, Training Loss: 0.3167%\n",
      "Epoch [56/300], Step [28/225], Training Accuracy: 87.8348%, Training Loss: 0.3118%\n",
      "Epoch [56/300], Step [29/225], Training Accuracy: 87.8772%, Training Loss: 0.3091%\n",
      "Epoch [56/300], Step [30/225], Training Accuracy: 87.9688%, Training Loss: 0.3092%\n",
      "Epoch [56/300], Step [31/225], Training Accuracy: 87.7520%, Training Loss: 0.3124%\n",
      "Epoch [56/300], Step [32/225], Training Accuracy: 87.8418%, Training Loss: 0.3117%\n",
      "Epoch [56/300], Step [33/225], Training Accuracy: 88.0208%, Training Loss: 0.3098%\n",
      "Epoch [56/300], Step [34/225], Training Accuracy: 87.6838%, Training Loss: 0.3149%\n",
      "Epoch [56/300], Step [35/225], Training Accuracy: 87.5893%, Training Loss: 0.3173%\n",
      "Epoch [56/300], Step [36/225], Training Accuracy: 87.3698%, Training Loss: 0.3207%\n",
      "Epoch [56/300], Step [37/225], Training Accuracy: 87.5000%, Training Loss: 0.3184%\n",
      "Epoch [56/300], Step [38/225], Training Accuracy: 87.4589%, Training Loss: 0.3190%\n",
      "Epoch [56/300], Step [39/225], Training Accuracy: 87.2997%, Training Loss: 0.3222%\n",
      "Epoch [56/300], Step [40/225], Training Accuracy: 87.2656%, Training Loss: 0.3223%\n",
      "Epoch [56/300], Step [41/225], Training Accuracy: 87.0046%, Training Loss: 0.3274%\n",
      "Epoch [56/300], Step [42/225], Training Accuracy: 86.9048%, Training Loss: 0.3284%\n",
      "Epoch [56/300], Step [43/225], Training Accuracy: 86.7733%, Training Loss: 0.3292%\n",
      "Epoch [56/300], Step [44/225], Training Accuracy: 86.6477%, Training Loss: 0.3286%\n",
      "Epoch [56/300], Step [45/225], Training Accuracy: 86.5972%, Training Loss: 0.3297%\n",
      "Epoch [56/300], Step [46/225], Training Accuracy: 86.5149%, Training Loss: 0.3304%\n",
      "Epoch [56/300], Step [47/225], Training Accuracy: 86.4029%, Training Loss: 0.3323%\n",
      "Epoch [56/300], Step [48/225], Training Accuracy: 86.4258%, Training Loss: 0.3320%\n",
      "Epoch [56/300], Step [49/225], Training Accuracy: 86.5115%, Training Loss: 0.3299%\n",
      "Epoch [56/300], Step [50/225], Training Accuracy: 86.5312%, Training Loss: 0.3295%\n",
      "Epoch [56/300], Step [51/225], Training Accuracy: 86.5809%, Training Loss: 0.3297%\n",
      "Epoch [56/300], Step [52/225], Training Accuracy: 86.6887%, Training Loss: 0.3271%\n",
      "Epoch [56/300], Step [53/225], Training Accuracy: 86.7040%, Training Loss: 0.3262%\n",
      "Epoch [56/300], Step [54/225], Training Accuracy: 86.7188%, Training Loss: 0.3254%\n",
      "Epoch [56/300], Step [55/225], Training Accuracy: 86.7898%, Training Loss: 0.3249%\n",
      "Epoch [56/300], Step [56/225], Training Accuracy: 86.8862%, Training Loss: 0.3225%\n",
      "Epoch [56/300], Step [57/225], Training Accuracy: 86.8421%, Training Loss: 0.3239%\n",
      "Epoch [56/300], Step [58/225], Training Accuracy: 86.8804%, Training Loss: 0.3239%\n",
      "Epoch [56/300], Step [59/225], Training Accuracy: 86.8909%, Training Loss: 0.3233%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/300], Step [60/225], Training Accuracy: 86.9531%, Training Loss: 0.3226%\n",
      "Epoch [56/300], Step [61/225], Training Accuracy: 86.8596%, Training Loss: 0.3238%\n",
      "Epoch [56/300], Step [62/225], Training Accuracy: 86.8196%, Training Loss: 0.3241%\n",
      "Epoch [56/300], Step [63/225], Training Accuracy: 86.8800%, Training Loss: 0.3233%\n",
      "Epoch [56/300], Step [64/225], Training Accuracy: 86.8652%, Training Loss: 0.3239%\n",
      "Epoch [56/300], Step [65/225], Training Accuracy: 86.9471%, Training Loss: 0.3229%\n",
      "Epoch [56/300], Step [66/225], Training Accuracy: 86.9555%, Training Loss: 0.3225%\n",
      "Epoch [56/300], Step [67/225], Training Accuracy: 86.9636%, Training Loss: 0.3216%\n",
      "Epoch [56/300], Step [68/225], Training Accuracy: 86.9945%, Training Loss: 0.3216%\n",
      "Epoch [56/300], Step [69/225], Training Accuracy: 87.0471%, Training Loss: 0.3204%\n",
      "Epoch [56/300], Step [70/225], Training Accuracy: 87.0312%, Training Loss: 0.3197%\n",
      "Epoch [56/300], Step [71/225], Training Accuracy: 86.9938%, Training Loss: 0.3204%\n",
      "Epoch [56/300], Step [72/225], Training Accuracy: 86.9358%, Training Loss: 0.3198%\n",
      "Epoch [56/300], Step [73/225], Training Accuracy: 86.9221%, Training Loss: 0.3200%\n",
      "Epoch [56/300], Step [74/225], Training Accuracy: 86.9721%, Training Loss: 0.3191%\n",
      "Epoch [56/300], Step [75/225], Training Accuracy: 86.9583%, Training Loss: 0.3192%\n",
      "Epoch [56/300], Step [76/225], Training Accuracy: 86.9038%, Training Loss: 0.3199%\n",
      "Epoch [56/300], Step [77/225], Training Accuracy: 86.9318%, Training Loss: 0.3196%\n",
      "Epoch [56/300], Step [78/225], Training Accuracy: 86.9992%, Training Loss: 0.3188%\n",
      "Epoch [56/300], Step [79/225], Training Accuracy: 87.0253%, Training Loss: 0.3179%\n",
      "Epoch [56/300], Step [80/225], Training Accuracy: 86.9531%, Training Loss: 0.3184%\n",
      "Epoch [56/300], Step [81/225], Training Accuracy: 86.9985%, Training Loss: 0.3176%\n",
      "Epoch [56/300], Step [82/225], Training Accuracy: 86.9855%, Training Loss: 0.3171%\n",
      "Epoch [56/300], Step [83/225], Training Accuracy: 87.0294%, Training Loss: 0.3160%\n",
      "Epoch [56/300], Step [84/225], Training Accuracy: 87.1094%, Training Loss: 0.3149%\n",
      "Epoch [56/300], Step [85/225], Training Accuracy: 87.1324%, Training Loss: 0.3150%\n",
      "Epoch [56/300], Step [86/225], Training Accuracy: 87.1548%, Training Loss: 0.3152%\n",
      "Epoch [56/300], Step [87/225], Training Accuracy: 87.1228%, Training Loss: 0.3152%\n",
      "Epoch [56/300], Step [88/225], Training Accuracy: 87.0916%, Training Loss: 0.3158%\n",
      "Epoch [56/300], Step [89/225], Training Accuracy: 87.1313%, Training Loss: 0.3154%\n",
      "Epoch [56/300], Step [90/225], Training Accuracy: 87.0833%, Training Loss: 0.3159%\n",
      "Epoch [56/300], Step [91/225], Training Accuracy: 87.1223%, Training Loss: 0.3158%\n",
      "Epoch [56/300], Step [92/225], Training Accuracy: 87.0754%, Training Loss: 0.3164%\n",
      "Epoch [56/300], Step [93/225], Training Accuracy: 87.0968%, Training Loss: 0.3156%\n",
      "Epoch [56/300], Step [94/225], Training Accuracy: 87.1177%, Training Loss: 0.3158%\n",
      "Epoch [56/300], Step [95/225], Training Accuracy: 87.1053%, Training Loss: 0.3162%\n",
      "Epoch [56/300], Step [96/225], Training Accuracy: 87.1419%, Training Loss: 0.3152%\n",
      "Epoch [56/300], Step [97/225], Training Accuracy: 87.1456%, Training Loss: 0.3155%\n",
      "Epoch [56/300], Step [98/225], Training Accuracy: 87.1333%, Training Loss: 0.3165%\n",
      "Epoch [56/300], Step [99/225], Training Accuracy: 87.2159%, Training Loss: 0.3151%\n",
      "Epoch [56/300], Step [100/225], Training Accuracy: 87.1562%, Training Loss: 0.3160%\n",
      "Epoch [56/300], Step [101/225], Training Accuracy: 87.1287%, Training Loss: 0.3167%\n",
      "Epoch [56/300], Step [102/225], Training Accuracy: 87.1017%, Training Loss: 0.3184%\n",
      "Epoch [56/300], Step [103/225], Training Accuracy: 87.1663%, Training Loss: 0.3170%\n",
      "Epoch [56/300], Step [104/225], Training Accuracy: 87.1845%, Training Loss: 0.3165%\n",
      "Epoch [56/300], Step [105/225], Training Accuracy: 87.1429%, Training Loss: 0.3175%\n",
      "Epoch [56/300], Step [106/225], Training Accuracy: 87.1315%, Training Loss: 0.3175%\n",
      "Epoch [56/300], Step [107/225], Training Accuracy: 87.1495%, Training Loss: 0.3175%\n",
      "Epoch [56/300], Step [108/225], Training Accuracy: 87.1528%, Training Loss: 0.3179%\n",
      "Epoch [56/300], Step [109/225], Training Accuracy: 87.0986%, Training Loss: 0.3185%\n",
      "Epoch [56/300], Step [110/225], Training Accuracy: 87.0739%, Training Loss: 0.3183%\n",
      "Epoch [56/300], Step [111/225], Training Accuracy: 87.1059%, Training Loss: 0.3177%\n",
      "Epoch [56/300], Step [112/225], Training Accuracy: 87.1233%, Training Loss: 0.3172%\n",
      "Epoch [56/300], Step [113/225], Training Accuracy: 87.1543%, Training Loss: 0.3171%\n",
      "Epoch [56/300], Step [114/225], Training Accuracy: 87.1711%, Training Loss: 0.3171%\n",
      "Epoch [56/300], Step [115/225], Training Accuracy: 87.2011%, Training Loss: 0.3163%\n",
      "Epoch [56/300], Step [116/225], Training Accuracy: 87.1902%, Training Loss: 0.3168%\n",
      "Epoch [56/300], Step [117/225], Training Accuracy: 87.1261%, Training Loss: 0.3178%\n",
      "Epoch [56/300], Step [118/225], Training Accuracy: 87.1292%, Training Loss: 0.3180%\n",
      "Epoch [56/300], Step [119/225], Training Accuracy: 87.1455%, Training Loss: 0.3177%\n",
      "Epoch [56/300], Step [120/225], Training Accuracy: 87.1484%, Training Loss: 0.3178%\n",
      "Epoch [56/300], Step [121/225], Training Accuracy: 87.1772%, Training Loss: 0.3174%\n",
      "Epoch [56/300], Step [122/225], Training Accuracy: 87.1926%, Training Loss: 0.3173%\n",
      "Epoch [56/300], Step [123/225], Training Accuracy: 87.1062%, Training Loss: 0.3190%\n",
      "Epoch [56/300], Step [124/225], Training Accuracy: 87.1220%, Training Loss: 0.3181%\n",
      "Epoch [56/300], Step [125/225], Training Accuracy: 87.1250%, Training Loss: 0.3180%\n",
      "Epoch [56/300], Step [126/225], Training Accuracy: 87.0908%, Training Loss: 0.3179%\n",
      "Epoch [56/300], Step [127/225], Training Accuracy: 87.0694%, Training Loss: 0.3181%\n",
      "Epoch [56/300], Step [128/225], Training Accuracy: 87.0117%, Training Loss: 0.3183%\n",
      "Epoch [56/300], Step [129/225], Training Accuracy: 86.9671%, Training Loss: 0.3193%\n",
      "Epoch [56/300], Step [130/225], Training Accuracy: 86.9351%, Training Loss: 0.3200%\n",
      "Epoch [56/300], Step [131/225], Training Accuracy: 86.8917%, Training Loss: 0.3209%\n",
      "Epoch [56/300], Step [132/225], Training Accuracy: 86.8845%, Training Loss: 0.3215%\n",
      "Epoch [56/300], Step [133/225], Training Accuracy: 86.8539%, Training Loss: 0.3218%\n",
      "Epoch [56/300], Step [134/225], Training Accuracy: 86.8120%, Training Loss: 0.3222%\n",
      "Epoch [56/300], Step [135/225], Training Accuracy: 86.7940%, Training Loss: 0.3218%\n",
      "Epoch [56/300], Step [136/225], Training Accuracy: 86.7532%, Training Loss: 0.3217%\n",
      "Epoch [56/300], Step [137/225], Training Accuracy: 86.7473%, Training Loss: 0.3219%\n",
      "Epoch [56/300], Step [138/225], Training Accuracy: 86.7867%, Training Loss: 0.3209%\n",
      "Epoch [56/300], Step [139/225], Training Accuracy: 86.8143%, Training Loss: 0.3207%\n",
      "Epoch [56/300], Step [140/225], Training Accuracy: 86.7522%, Training Loss: 0.3212%\n",
      "Epoch [56/300], Step [141/225], Training Accuracy: 86.7575%, Training Loss: 0.3211%\n",
      "Epoch [56/300], Step [142/225], Training Accuracy: 86.7738%, Training Loss: 0.3209%\n",
      "Epoch [56/300], Step [143/225], Training Accuracy: 86.7679%, Training Loss: 0.3212%\n",
      "Epoch [56/300], Step [144/225], Training Accuracy: 86.7730%, Training Loss: 0.3208%\n",
      "Epoch [56/300], Step [145/225], Training Accuracy: 86.7672%, Training Loss: 0.3208%\n",
      "Epoch [56/300], Step [146/225], Training Accuracy: 86.7723%, Training Loss: 0.3208%\n",
      "Epoch [56/300], Step [147/225], Training Accuracy: 86.7772%, Training Loss: 0.3206%\n",
      "Epoch [56/300], Step [148/225], Training Accuracy: 86.8032%, Training Loss: 0.3198%\n",
      "Epoch [56/300], Step [149/225], Training Accuracy: 86.8184%, Training Loss: 0.3193%\n",
      "Epoch [56/300], Step [150/225], Training Accuracy: 86.8854%, Training Loss: 0.3181%\n",
      "Epoch [56/300], Step [151/225], Training Accuracy: 86.9619%, Training Loss: 0.3168%\n",
      "Epoch [56/300], Step [152/225], Training Accuracy: 86.9860%, Training Loss: 0.3166%\n",
      "Epoch [56/300], Step [153/225], Training Accuracy: 87.0098%, Training Loss: 0.3162%\n",
      "Epoch [56/300], Step [154/225], Training Accuracy: 87.0231%, Training Loss: 0.3162%\n",
      "Epoch [56/300], Step [155/225], Training Accuracy: 87.0565%, Training Loss: 0.3157%\n",
      "Epoch [56/300], Step [156/225], Training Accuracy: 87.0292%, Training Loss: 0.3155%\n",
      "Epoch [56/300], Step [157/225], Training Accuracy: 87.0422%, Training Loss: 0.3153%\n",
      "Epoch [56/300], Step [158/225], Training Accuracy: 87.0550%, Training Loss: 0.3153%\n",
      "Epoch [56/300], Step [159/225], Training Accuracy: 87.0381%, Training Loss: 0.3163%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/300], Step [160/225], Training Accuracy: 87.0801%, Training Loss: 0.3159%\n",
      "Epoch [56/300], Step [161/225], Training Accuracy: 87.0730%, Training Loss: 0.3163%\n",
      "Epoch [56/300], Step [162/225], Training Accuracy: 87.0949%, Training Loss: 0.3159%\n",
      "Epoch [56/300], Step [163/225], Training Accuracy: 87.1070%, Training Loss: 0.3159%\n",
      "Epoch [56/300], Step [164/225], Training Accuracy: 87.0903%, Training Loss: 0.3161%\n",
      "Epoch [56/300], Step [165/225], Training Accuracy: 87.0549%, Training Loss: 0.3164%\n",
      "Epoch [56/300], Step [166/225], Training Accuracy: 87.0764%, Training Loss: 0.3162%\n",
      "Epoch [56/300], Step [167/225], Training Accuracy: 87.0790%, Training Loss: 0.3160%\n",
      "Epoch [56/300], Step [168/225], Training Accuracy: 87.0536%, Training Loss: 0.3167%\n",
      "Epoch [56/300], Step [169/225], Training Accuracy: 87.0562%, Training Loss: 0.3165%\n",
      "Epoch [56/300], Step [170/225], Training Accuracy: 87.0496%, Training Loss: 0.3165%\n",
      "Epoch [56/300], Step [171/225], Training Accuracy: 87.0066%, Training Loss: 0.3172%\n",
      "Epoch [56/300], Step [172/225], Training Accuracy: 87.0185%, Training Loss: 0.3172%\n",
      "Epoch [56/300], Step [173/225], Training Accuracy: 87.0123%, Training Loss: 0.3170%\n",
      "Epoch [56/300], Step [174/225], Training Accuracy: 87.0151%, Training Loss: 0.3168%\n",
      "Epoch [56/300], Step [175/225], Training Accuracy: 87.0000%, Training Loss: 0.3172%\n",
      "Epoch [56/300], Step [176/225], Training Accuracy: 87.0206%, Training Loss: 0.3167%\n",
      "Epoch [56/300], Step [177/225], Training Accuracy: 87.0410%, Training Loss: 0.3163%\n",
      "Epoch [56/300], Step [178/225], Training Accuracy: 87.0348%, Training Loss: 0.3162%\n",
      "Epoch [56/300], Step [179/225], Training Accuracy: 87.0635%, Training Loss: 0.3157%\n",
      "Epoch [56/300], Step [180/225], Training Accuracy: 87.0660%, Training Loss: 0.3153%\n",
      "Epoch [56/300], Step [181/225], Training Accuracy: 87.0770%, Training Loss: 0.3153%\n",
      "Epoch [56/300], Step [182/225], Training Accuracy: 87.0707%, Training Loss: 0.3153%\n",
      "Epoch [56/300], Step [183/225], Training Accuracy: 87.0816%, Training Loss: 0.3152%\n",
      "Epoch [56/300], Step [184/225], Training Accuracy: 87.0924%, Training Loss: 0.3148%\n",
      "Epoch [56/300], Step [185/225], Training Accuracy: 87.0946%, Training Loss: 0.3151%\n",
      "Epoch [56/300], Step [186/225], Training Accuracy: 87.1388%, Training Loss: 0.3142%\n",
      "Epoch [56/300], Step [187/225], Training Accuracy: 87.1407%, Training Loss: 0.3139%\n",
      "Epoch [56/300], Step [188/225], Training Accuracy: 87.1842%, Training Loss: 0.3131%\n",
      "Epoch [56/300], Step [189/225], Training Accuracy: 87.2024%, Training Loss: 0.3127%\n",
      "Epoch [56/300], Step [190/225], Training Accuracy: 87.2286%, Training Loss: 0.3120%\n",
      "Epoch [56/300], Step [191/225], Training Accuracy: 87.2137%, Training Loss: 0.3123%\n",
      "Epoch [56/300], Step [192/225], Training Accuracy: 87.1989%, Training Loss: 0.3124%\n",
      "Epoch [56/300], Step [193/225], Training Accuracy: 87.1924%, Training Loss: 0.3126%\n",
      "Epoch [56/300], Step [194/225], Training Accuracy: 87.1939%, Training Loss: 0.3126%\n",
      "Epoch [56/300], Step [195/225], Training Accuracy: 87.2436%, Training Loss: 0.3120%\n",
      "Epoch [56/300], Step [196/225], Training Accuracy: 87.2050%, Training Loss: 0.3123%\n",
      "Epoch [56/300], Step [197/225], Training Accuracy: 87.2065%, Training Loss: 0.3120%\n",
      "Epoch [56/300], Step [198/225], Training Accuracy: 87.2317%, Training Loss: 0.3113%\n",
      "Epoch [56/300], Step [199/225], Training Accuracy: 87.2330%, Training Loss: 0.3114%\n",
      "Epoch [56/300], Step [200/225], Training Accuracy: 87.2500%, Training Loss: 0.3109%\n",
      "Epoch [56/300], Step [201/225], Training Accuracy: 87.2435%, Training Loss: 0.3110%\n",
      "Epoch [56/300], Step [202/225], Training Accuracy: 87.2757%, Training Loss: 0.3109%\n",
      "Epoch [56/300], Step [203/225], Training Accuracy: 87.2999%, Training Loss: 0.3101%\n",
      "Epoch [56/300], Step [204/225], Training Accuracy: 87.2855%, Training Loss: 0.3104%\n",
      "Epoch [56/300], Step [205/225], Training Accuracy: 87.2637%, Training Loss: 0.3105%\n",
      "Epoch [56/300], Step [206/225], Training Accuracy: 87.2421%, Training Loss: 0.3104%\n",
      "Epoch [56/300], Step [207/225], Training Accuracy: 87.2358%, Training Loss: 0.3106%\n",
      "Epoch [56/300], Step [208/225], Training Accuracy: 87.2446%, Training Loss: 0.3107%\n",
      "Epoch [56/300], Step [209/225], Training Accuracy: 87.2159%, Training Loss: 0.3115%\n",
      "Epoch [56/300], Step [210/225], Training Accuracy: 87.1949%, Training Loss: 0.3117%\n",
      "Epoch [56/300], Step [211/225], Training Accuracy: 87.1890%, Training Loss: 0.3121%\n",
      "Epoch [56/300], Step [212/225], Training Accuracy: 87.1757%, Training Loss: 0.3126%\n",
      "Epoch [56/300], Step [213/225], Training Accuracy: 87.1992%, Training Loss: 0.3122%\n",
      "Epoch [56/300], Step [214/225], Training Accuracy: 87.1933%, Training Loss: 0.3123%\n",
      "Epoch [56/300], Step [215/225], Training Accuracy: 87.1730%, Training Loss: 0.3126%\n",
      "Epoch [56/300], Step [216/225], Training Accuracy: 87.1962%, Training Loss: 0.3125%\n",
      "Epoch [56/300], Step [217/225], Training Accuracy: 87.2120%, Training Loss: 0.3123%\n",
      "Epoch [56/300], Step [218/225], Training Accuracy: 87.2133%, Training Loss: 0.3123%\n",
      "Epoch [56/300], Step [219/225], Training Accuracy: 87.1932%, Training Loss: 0.3124%\n",
      "Epoch [56/300], Step [220/225], Training Accuracy: 87.1733%, Training Loss: 0.3126%\n",
      "Epoch [56/300], Step [221/225], Training Accuracy: 87.2101%, Training Loss: 0.3119%\n",
      "Epoch [56/300], Step [222/225], Training Accuracy: 87.2255%, Training Loss: 0.3116%\n",
      "Epoch [56/300], Step [223/225], Training Accuracy: 87.2127%, Training Loss: 0.3120%\n",
      "Epoch [56/300], Step [224/225], Training Accuracy: 87.1931%, Training Loss: 0.3121%\n",
      "Epoch [56/300], Step [225/225], Training Accuracy: 87.2082%, Training Loss: 0.3116%\n",
      "Epoch [57/300], Step [1/225], Training Accuracy: 87.5000%, Training Loss: 0.3293%\n",
      "Epoch [57/300], Step [2/225], Training Accuracy: 89.8438%, Training Loss: 0.2729%\n",
      "Epoch [57/300], Step [3/225], Training Accuracy: 88.5417%, Training Loss: 0.3202%\n",
      "Epoch [57/300], Step [4/225], Training Accuracy: 88.2812%, Training Loss: 0.3092%\n",
      "Epoch [57/300], Step [5/225], Training Accuracy: 88.1250%, Training Loss: 0.3092%\n",
      "Epoch [57/300], Step [6/225], Training Accuracy: 88.0208%, Training Loss: 0.3112%\n",
      "Epoch [57/300], Step [7/225], Training Accuracy: 88.3929%, Training Loss: 0.3025%\n",
      "Epoch [57/300], Step [8/225], Training Accuracy: 87.1094%, Training Loss: 0.3254%\n",
      "Epoch [57/300], Step [9/225], Training Accuracy: 86.8056%, Training Loss: 0.3296%\n",
      "Epoch [57/300], Step [10/225], Training Accuracy: 85.9375%, Training Loss: 0.3482%\n",
      "Epoch [57/300], Step [11/225], Training Accuracy: 85.9375%, Training Loss: 0.3485%\n",
      "Epoch [57/300], Step [12/225], Training Accuracy: 85.6771%, Training Loss: 0.3515%\n",
      "Epoch [57/300], Step [13/225], Training Accuracy: 86.2981%, Training Loss: 0.3369%\n",
      "Epoch [57/300], Step [14/225], Training Accuracy: 86.1607%, Training Loss: 0.3374%\n",
      "Epoch [57/300], Step [15/225], Training Accuracy: 86.0417%, Training Loss: 0.3364%\n",
      "Epoch [57/300], Step [16/225], Training Accuracy: 85.9375%, Training Loss: 0.3350%\n",
      "Epoch [57/300], Step [17/225], Training Accuracy: 85.8456%, Training Loss: 0.3336%\n",
      "Epoch [57/300], Step [18/225], Training Accuracy: 85.8507%, Training Loss: 0.3329%\n",
      "Epoch [57/300], Step [19/225], Training Accuracy: 86.1020%, Training Loss: 0.3287%\n",
      "Epoch [57/300], Step [20/225], Training Accuracy: 86.4844%, Training Loss: 0.3225%\n",
      "Epoch [57/300], Step [21/225], Training Accuracy: 86.6071%, Training Loss: 0.3197%\n",
      "Epoch [57/300], Step [22/225], Training Accuracy: 86.5767%, Training Loss: 0.3206%\n",
      "Epoch [57/300], Step [23/225], Training Accuracy: 86.6848%, Training Loss: 0.3205%\n",
      "Epoch [57/300], Step [24/225], Training Accuracy: 86.7839%, Training Loss: 0.3180%\n",
      "Epoch [57/300], Step [25/225], Training Accuracy: 86.9375%, Training Loss: 0.3147%\n",
      "Epoch [57/300], Step [26/225], Training Accuracy: 87.0793%, Training Loss: 0.3133%\n",
      "Epoch [57/300], Step [27/225], Training Accuracy: 87.0949%, Training Loss: 0.3109%\n",
      "Epoch [57/300], Step [28/225], Training Accuracy: 87.3326%, Training Loss: 0.3066%\n",
      "Epoch [57/300], Step [29/225], Training Accuracy: 87.3922%, Training Loss: 0.3039%\n",
      "Epoch [57/300], Step [30/225], Training Accuracy: 87.5000%, Training Loss: 0.3035%\n",
      "Epoch [57/300], Step [31/225], Training Accuracy: 87.1976%, Training Loss: 0.3063%\n",
      "Epoch [57/300], Step [32/225], Training Accuracy: 87.4023%, Training Loss: 0.3033%\n",
      "Epoch [57/300], Step [33/225], Training Accuracy: 87.4527%, Training Loss: 0.3035%\n",
      "Epoch [57/300], Step [34/225], Training Accuracy: 87.3621%, Training Loss: 0.3074%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/300], Step [35/225], Training Accuracy: 87.0536%, Training Loss: 0.3143%\n",
      "Epoch [57/300], Step [36/225], Training Accuracy: 87.1094%, Training Loss: 0.3133%\n",
      "Epoch [57/300], Step [37/225], Training Accuracy: 87.2889%, Training Loss: 0.3103%\n",
      "Epoch [57/300], Step [38/225], Training Accuracy: 87.3355%, Training Loss: 0.3099%\n",
      "Epoch [57/300], Step [39/225], Training Accuracy: 87.3798%, Training Loss: 0.3127%\n",
      "Epoch [57/300], Step [40/225], Training Accuracy: 87.3828%, Training Loss: 0.3142%\n",
      "Epoch [57/300], Step [41/225], Training Accuracy: 87.3857%, Training Loss: 0.3155%\n",
      "Epoch [57/300], Step [42/225], Training Accuracy: 87.5000%, Training Loss: 0.3126%\n",
      "Epoch [57/300], Step [43/225], Training Accuracy: 87.5000%, Training Loss: 0.3139%\n",
      "Epoch [57/300], Step [44/225], Training Accuracy: 87.5000%, Training Loss: 0.3144%\n",
      "Epoch [57/300], Step [45/225], Training Accuracy: 87.3958%, Training Loss: 0.3144%\n",
      "Epoch [57/300], Step [46/225], Training Accuracy: 87.3981%, Training Loss: 0.3148%\n",
      "Epoch [57/300], Step [47/225], Training Accuracy: 87.3338%, Training Loss: 0.3179%\n",
      "Epoch [57/300], Step [48/225], Training Accuracy: 87.4023%, Training Loss: 0.3169%\n",
      "Epoch [57/300], Step [49/225], Training Accuracy: 87.5319%, Training Loss: 0.3160%\n",
      "Epoch [57/300], Step [50/225], Training Accuracy: 87.5000%, Training Loss: 0.3162%\n",
      "Epoch [57/300], Step [51/225], Training Accuracy: 87.5613%, Training Loss: 0.3143%\n",
      "Epoch [57/300], Step [52/225], Training Accuracy: 87.7103%, Training Loss: 0.3104%\n",
      "Epoch [57/300], Step [53/225], Training Accuracy: 87.7948%, Training Loss: 0.3083%\n",
      "Epoch [57/300], Step [54/225], Training Accuracy: 87.7315%, Training Loss: 0.3099%\n",
      "Epoch [57/300], Step [55/225], Training Accuracy: 87.7841%, Training Loss: 0.3101%\n",
      "Epoch [57/300], Step [56/225], Training Accuracy: 87.7232%, Training Loss: 0.3119%\n",
      "Epoch [57/300], Step [57/225], Training Accuracy: 87.6645%, Training Loss: 0.3128%\n",
      "Epoch [57/300], Step [58/225], Training Accuracy: 87.7425%, Training Loss: 0.3117%\n",
      "Epoch [57/300], Step [59/225], Training Accuracy: 87.8178%, Training Loss: 0.3104%\n",
      "Epoch [57/300], Step [60/225], Training Accuracy: 87.9427%, Training Loss: 0.3080%\n",
      "Epoch [57/300], Step [61/225], Training Accuracy: 87.9611%, Training Loss: 0.3077%\n",
      "Epoch [57/300], Step [62/225], Training Accuracy: 88.0544%, Training Loss: 0.3061%\n",
      "Epoch [57/300], Step [63/225], Training Accuracy: 87.9712%, Training Loss: 0.3073%\n",
      "Epoch [57/300], Step [64/225], Training Accuracy: 88.0127%, Training Loss: 0.3063%\n",
      "Epoch [57/300], Step [65/225], Training Accuracy: 88.0048%, Training Loss: 0.3058%\n",
      "Epoch [57/300], Step [66/225], Training Accuracy: 88.0682%, Training Loss: 0.3046%\n",
      "Epoch [57/300], Step [67/225], Training Accuracy: 88.0830%, Training Loss: 0.3040%\n",
      "Epoch [57/300], Step [68/225], Training Accuracy: 87.9136%, Training Loss: 0.3059%\n",
      "Epoch [57/300], Step [69/225], Training Accuracy: 87.8623%, Training Loss: 0.3059%\n",
      "Epoch [57/300], Step [70/225], Training Accuracy: 87.9018%, Training Loss: 0.3053%\n",
      "Epoch [57/300], Step [71/225], Training Accuracy: 87.9621%, Training Loss: 0.3042%\n",
      "Epoch [57/300], Step [72/225], Training Accuracy: 87.9557%, Training Loss: 0.3048%\n",
      "Epoch [57/300], Step [73/225], Training Accuracy: 87.8639%, Training Loss: 0.3054%\n",
      "Epoch [57/300], Step [74/225], Training Accuracy: 87.8801%, Training Loss: 0.3051%\n",
      "Epoch [57/300], Step [75/225], Training Accuracy: 87.8958%, Training Loss: 0.3044%\n",
      "Epoch [57/300], Step [76/225], Training Accuracy: 87.8084%, Training Loss: 0.3059%\n",
      "Epoch [57/300], Step [77/225], Training Accuracy: 87.7841%, Training Loss: 0.3067%\n",
      "Epoch [57/300], Step [78/225], Training Accuracy: 87.7604%, Training Loss: 0.3069%\n",
      "Epoch [57/300], Step [79/225], Training Accuracy: 87.7967%, Training Loss: 0.3060%\n",
      "Epoch [57/300], Step [80/225], Training Accuracy: 87.6953%, Training Loss: 0.3074%\n",
      "Epoch [57/300], Step [81/225], Training Accuracy: 87.7315%, Training Loss: 0.3061%\n",
      "Epoch [57/300], Step [82/225], Training Accuracy: 87.7668%, Training Loss: 0.3061%\n",
      "Epoch [57/300], Step [83/225], Training Accuracy: 87.6694%, Training Loss: 0.3076%\n",
      "Epoch [57/300], Step [84/225], Training Accuracy: 87.7046%, Training Loss: 0.3069%\n",
      "Epoch [57/300], Step [85/225], Training Accuracy: 87.7757%, Training Loss: 0.3065%\n",
      "Epoch [57/300], Step [86/225], Training Accuracy: 87.7907%, Training Loss: 0.3059%\n",
      "Epoch [57/300], Step [87/225], Training Accuracy: 87.7874%, Training Loss: 0.3058%\n",
      "Epoch [57/300], Step [88/225], Training Accuracy: 87.6776%, Training Loss: 0.3079%\n",
      "Epoch [57/300], Step [89/225], Training Accuracy: 87.6053%, Training Loss: 0.3082%\n",
      "Epoch [57/300], Step [90/225], Training Accuracy: 87.6736%, Training Loss: 0.3080%\n",
      "Epoch [57/300], Step [91/225], Training Accuracy: 87.7404%, Training Loss: 0.3064%\n",
      "Epoch [57/300], Step [92/225], Training Accuracy: 87.7548%, Training Loss: 0.3067%\n",
      "Epoch [57/300], Step [93/225], Training Accuracy: 87.7184%, Training Loss: 0.3063%\n",
      "Epoch [57/300], Step [94/225], Training Accuracy: 87.7493%, Training Loss: 0.3056%\n",
      "Epoch [57/300], Step [95/225], Training Accuracy: 87.7303%, Training Loss: 0.3063%\n",
      "Epoch [57/300], Step [96/225], Training Accuracy: 87.7767%, Training Loss: 0.3056%\n",
      "Epoch [57/300], Step [97/225], Training Accuracy: 87.8383%, Training Loss: 0.3045%\n",
      "Epoch [57/300], Step [98/225], Training Accuracy: 87.7392%, Training Loss: 0.3053%\n",
      "Epoch [57/300], Step [99/225], Training Accuracy: 87.7683%, Training Loss: 0.3045%\n",
      "Epoch [57/300], Step [100/225], Training Accuracy: 87.6719%, Training Loss: 0.3063%\n",
      "Epoch [57/300], Step [101/225], Training Accuracy: 87.6547%, Training Loss: 0.3071%\n",
      "Epoch [57/300], Step [102/225], Training Accuracy: 87.6072%, Training Loss: 0.3082%\n",
      "Epoch [57/300], Step [103/225], Training Accuracy: 87.6214%, Training Loss: 0.3075%\n",
      "Epoch [57/300], Step [104/225], Training Accuracy: 87.6052%, Training Loss: 0.3080%\n",
      "Epoch [57/300], Step [105/225], Training Accuracy: 87.6339%, Training Loss: 0.3074%\n",
      "Epoch [57/300], Step [106/225], Training Accuracy: 87.6179%, Training Loss: 0.3079%\n",
      "Epoch [57/300], Step [107/225], Training Accuracy: 87.6022%, Training Loss: 0.3085%\n",
      "Epoch [57/300], Step [108/225], Training Accuracy: 87.6013%, Training Loss: 0.3082%\n",
      "Epoch [57/300], Step [109/225], Training Accuracy: 87.6147%, Training Loss: 0.3083%\n",
      "Epoch [57/300], Step [110/225], Training Accuracy: 87.5852%, Training Loss: 0.3085%\n",
      "Epoch [57/300], Step [111/225], Training Accuracy: 87.6689%, Training Loss: 0.3076%\n",
      "Epoch [57/300], Step [112/225], Training Accuracy: 87.6535%, Training Loss: 0.3072%\n",
      "Epoch [57/300], Step [113/225], Training Accuracy: 87.6383%, Training Loss: 0.3074%\n",
      "Epoch [57/300], Step [114/225], Training Accuracy: 87.6645%, Training Loss: 0.3071%\n",
      "Epoch [57/300], Step [115/225], Training Accuracy: 87.6902%, Training Loss: 0.3068%\n",
      "Epoch [57/300], Step [116/225], Training Accuracy: 87.6886%, Training Loss: 0.3069%\n",
      "Epoch [57/300], Step [117/225], Training Accuracy: 87.7137%, Training Loss: 0.3069%\n",
      "Epoch [57/300], Step [118/225], Training Accuracy: 87.7251%, Training Loss: 0.3066%\n",
      "Epoch [57/300], Step [119/225], Training Accuracy: 87.7626%, Training Loss: 0.3060%\n",
      "Epoch [57/300], Step [120/225], Training Accuracy: 87.7604%, Training Loss: 0.3057%\n",
      "Epoch [57/300], Step [121/225], Training Accuracy: 87.7841%, Training Loss: 0.3055%\n",
      "Epoch [57/300], Step [122/225], Training Accuracy: 87.7305%, Training Loss: 0.3068%\n",
      "Epoch [57/300], Step [123/225], Training Accuracy: 87.7033%, Training Loss: 0.3065%\n",
      "Epoch [57/300], Step [124/225], Training Accuracy: 87.6638%, Training Loss: 0.3069%\n",
      "Epoch [57/300], Step [125/225], Training Accuracy: 87.7250%, Training Loss: 0.3061%\n",
      "Epoch [57/300], Step [126/225], Training Accuracy: 87.7356%, Training Loss: 0.3060%\n",
      "Epoch [57/300], Step [127/225], Training Accuracy: 87.7338%, Training Loss: 0.3064%\n",
      "Epoch [57/300], Step [128/225], Training Accuracy: 87.7441%, Training Loss: 0.3070%\n",
      "Epoch [57/300], Step [129/225], Training Accuracy: 87.7665%, Training Loss: 0.3066%\n",
      "Epoch [57/300], Step [130/225], Training Accuracy: 87.6923%, Training Loss: 0.3081%\n",
      "Epoch [57/300], Step [131/225], Training Accuracy: 87.7385%, Training Loss: 0.3072%\n",
      "Epoch [57/300], Step [132/225], Training Accuracy: 87.7486%, Training Loss: 0.3075%\n",
      "Epoch [57/300], Step [133/225], Training Accuracy: 87.6880%, Training Loss: 0.3087%\n",
      "Epoch [57/300], Step [134/225], Training Accuracy: 87.6516%, Training Loss: 0.3100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/300], Step [135/225], Training Accuracy: 87.6620%, Training Loss: 0.3097%\n",
      "Epoch [57/300], Step [136/225], Training Accuracy: 87.6723%, Training Loss: 0.3094%\n",
      "Epoch [57/300], Step [137/225], Training Accuracy: 87.6483%, Training Loss: 0.3096%\n",
      "Epoch [57/300], Step [138/225], Training Accuracy: 87.6925%, Training Loss: 0.3082%\n",
      "Epoch [57/300], Step [139/225], Training Accuracy: 87.7023%, Training Loss: 0.3079%\n",
      "Epoch [57/300], Step [140/225], Training Accuracy: 87.7009%, Training Loss: 0.3077%\n",
      "Epoch [57/300], Step [141/225], Training Accuracy: 87.7105%, Training Loss: 0.3073%\n",
      "Epoch [57/300], Step [142/225], Training Accuracy: 87.7311%, Training Loss: 0.3070%\n",
      "Epoch [57/300], Step [143/225], Training Accuracy: 87.6858%, Training Loss: 0.3078%\n",
      "Epoch [57/300], Step [144/225], Training Accuracy: 87.6953%, Training Loss: 0.3076%\n",
      "Epoch [57/300], Step [145/225], Training Accuracy: 87.6832%, Training Loss: 0.3080%\n",
      "Epoch [57/300], Step [146/225], Training Accuracy: 87.6712%, Training Loss: 0.3080%\n",
      "Epoch [57/300], Step [147/225], Training Accuracy: 87.6701%, Training Loss: 0.3083%\n",
      "Epoch [57/300], Step [148/225], Training Accuracy: 87.7111%, Training Loss: 0.3075%\n",
      "Epoch [57/300], Step [149/225], Training Accuracy: 87.7412%, Training Loss: 0.3072%\n",
      "Epoch [57/300], Step [150/225], Training Accuracy: 87.7604%, Training Loss: 0.3065%\n",
      "Epoch [57/300], Step [151/225], Training Accuracy: 87.7897%, Training Loss: 0.3059%\n",
      "Epoch [57/300], Step [152/225], Training Accuracy: 87.8598%, Training Loss: 0.3051%\n",
      "Epoch [57/300], Step [153/225], Training Accuracy: 87.8574%, Training Loss: 0.3052%\n",
      "Epoch [57/300], Step [154/225], Training Accuracy: 87.7841%, Training Loss: 0.3057%\n",
      "Epoch [57/300], Step [155/225], Training Accuracy: 87.7419%, Training Loss: 0.3056%\n",
      "Epoch [57/300], Step [156/225], Training Accuracy: 87.7204%, Training Loss: 0.3057%\n",
      "Epoch [57/300], Step [157/225], Training Accuracy: 87.6990%, Training Loss: 0.3059%\n",
      "Epoch [57/300], Step [158/225], Training Accuracy: 87.6978%, Training Loss: 0.3057%\n",
      "Epoch [57/300], Step [159/225], Training Accuracy: 87.7358%, Training Loss: 0.3053%\n",
      "Epoch [57/300], Step [160/225], Training Accuracy: 87.7051%, Training Loss: 0.3059%\n",
      "Epoch [57/300], Step [161/225], Training Accuracy: 87.7038%, Training Loss: 0.3067%\n",
      "Epoch [57/300], Step [162/225], Training Accuracy: 87.7411%, Training Loss: 0.3059%\n",
      "Epoch [57/300], Step [163/225], Training Accuracy: 87.7492%, Training Loss: 0.3058%\n",
      "Epoch [57/300], Step [164/225], Training Accuracy: 87.7668%, Training Loss: 0.3056%\n",
      "Epoch [57/300], Step [165/225], Training Accuracy: 87.7557%, Training Loss: 0.3063%\n",
      "Epoch [57/300], Step [166/225], Training Accuracy: 87.7447%, Training Loss: 0.3062%\n",
      "Epoch [57/300], Step [167/225], Training Accuracy: 87.7339%, Training Loss: 0.3060%\n",
      "Epoch [57/300], Step [168/225], Training Accuracy: 87.7232%, Training Loss: 0.3065%\n",
      "Epoch [57/300], Step [169/225], Training Accuracy: 87.7496%, Training Loss: 0.3058%\n",
      "Epoch [57/300], Step [170/225], Training Accuracy: 87.7574%, Training Loss: 0.3060%\n",
      "Epoch [57/300], Step [171/225], Training Accuracy: 87.7284%, Training Loss: 0.3067%\n",
      "Epoch [57/300], Step [172/225], Training Accuracy: 87.7453%, Training Loss: 0.3066%\n",
      "Epoch [57/300], Step [173/225], Training Accuracy: 87.7439%, Training Loss: 0.3065%\n",
      "Epoch [57/300], Step [174/225], Training Accuracy: 87.7514%, Training Loss: 0.3060%\n",
      "Epoch [57/300], Step [175/225], Training Accuracy: 87.7589%, Training Loss: 0.3061%\n",
      "Epoch [57/300], Step [176/225], Training Accuracy: 87.7486%, Training Loss: 0.3064%\n",
      "Epoch [57/300], Step [177/225], Training Accuracy: 87.7207%, Training Loss: 0.3069%\n",
      "Epoch [57/300], Step [178/225], Training Accuracy: 87.7195%, Training Loss: 0.3071%\n",
      "Epoch [57/300], Step [179/225], Training Accuracy: 87.7182%, Training Loss: 0.3070%\n",
      "Epoch [57/300], Step [180/225], Training Accuracy: 87.7170%, Training Loss: 0.3067%\n",
      "Epoch [57/300], Step [181/225], Training Accuracy: 87.6640%, Training Loss: 0.3074%\n",
      "Epoch [57/300], Step [182/225], Training Accuracy: 87.6975%, Training Loss: 0.3070%\n",
      "Epoch [57/300], Step [183/225], Training Accuracy: 87.7135%, Training Loss: 0.3072%\n",
      "Epoch [57/300], Step [184/225], Training Accuracy: 87.7123%, Training Loss: 0.3072%\n",
      "Epoch [57/300], Step [185/225], Training Accuracy: 87.7280%, Training Loss: 0.3070%\n",
      "Epoch [57/300], Step [186/225], Training Accuracy: 87.7604%, Training Loss: 0.3063%\n",
      "Epoch [57/300], Step [187/225], Training Accuracy: 87.7340%, Training Loss: 0.3068%\n",
      "Epoch [57/300], Step [188/225], Training Accuracy: 87.7576%, Training Loss: 0.3063%\n",
      "Epoch [57/300], Step [189/225], Training Accuracy: 87.7728%, Training Loss: 0.3062%\n",
      "Epoch [57/300], Step [190/225], Training Accuracy: 87.8043%, Training Loss: 0.3054%\n",
      "Epoch [57/300], Step [191/225], Training Accuracy: 87.8027%, Training Loss: 0.3054%\n",
      "Epoch [57/300], Step [192/225], Training Accuracy: 87.8174%, Training Loss: 0.3052%\n",
      "Epoch [57/300], Step [193/225], Training Accuracy: 87.7995%, Training Loss: 0.3057%\n",
      "Epoch [57/300], Step [194/225], Training Accuracy: 87.7738%, Training Loss: 0.3062%\n",
      "Epoch [57/300], Step [195/225], Training Accuracy: 87.7804%, Training Loss: 0.3061%\n",
      "Epoch [57/300], Step [196/225], Training Accuracy: 87.7471%, Training Loss: 0.3064%\n",
      "Epoch [57/300], Step [197/225], Training Accuracy: 87.7617%, Training Loss: 0.3064%\n",
      "Epoch [57/300], Step [198/225], Training Accuracy: 87.7446%, Training Loss: 0.3071%\n",
      "Epoch [57/300], Step [199/225], Training Accuracy: 87.7041%, Training Loss: 0.3080%\n",
      "Epoch [57/300], Step [200/225], Training Accuracy: 87.7031%, Training Loss: 0.3081%\n",
      "Epoch [57/300], Step [201/225], Training Accuracy: 87.6943%, Training Loss: 0.3088%\n",
      "Epoch [57/300], Step [202/225], Training Accuracy: 87.7088%, Training Loss: 0.3084%\n",
      "Epoch [57/300], Step [203/225], Training Accuracy: 87.7463%, Training Loss: 0.3078%\n",
      "Epoch [57/300], Step [204/225], Training Accuracy: 87.7681%, Training Loss: 0.3076%\n",
      "Epoch [57/300], Step [205/225], Training Accuracy: 87.7820%, Training Loss: 0.3073%\n",
      "Epoch [57/300], Step [206/225], Training Accuracy: 87.7882%, Training Loss: 0.3068%\n",
      "Epoch [57/300], Step [207/225], Training Accuracy: 87.7944%, Training Loss: 0.3068%\n",
      "Epoch [57/300], Step [208/225], Training Accuracy: 87.8005%, Training Loss: 0.3069%\n",
      "Epoch [57/300], Step [209/225], Training Accuracy: 87.7691%, Training Loss: 0.3077%\n",
      "Epoch [57/300], Step [210/225], Training Accuracy: 87.7530%, Training Loss: 0.3078%\n",
      "Epoch [57/300], Step [211/225], Training Accuracy: 87.7518%, Training Loss: 0.3077%\n",
      "Epoch [57/300], Step [212/225], Training Accuracy: 87.7432%, Training Loss: 0.3076%\n",
      "Epoch [57/300], Step [213/225], Training Accuracy: 87.7641%, Training Loss: 0.3074%\n",
      "Epoch [57/300], Step [214/225], Training Accuracy: 87.7848%, Training Loss: 0.3072%\n",
      "Epoch [57/300], Step [215/225], Training Accuracy: 87.7834%, Training Loss: 0.3073%\n",
      "Epoch [57/300], Step [216/225], Training Accuracy: 87.7677%, Training Loss: 0.3076%\n",
      "Epoch [57/300], Step [217/225], Training Accuracy: 87.7664%, Training Loss: 0.3074%\n",
      "Epoch [57/300], Step [218/225], Training Accuracy: 87.7795%, Training Loss: 0.3075%\n",
      "Epoch [57/300], Step [219/225], Training Accuracy: 87.7854%, Training Loss: 0.3072%\n",
      "Epoch [57/300], Step [220/225], Training Accuracy: 87.7841%, Training Loss: 0.3071%\n",
      "Epoch [57/300], Step [221/225], Training Accuracy: 87.7969%, Training Loss: 0.3071%\n",
      "Epoch [57/300], Step [222/225], Training Accuracy: 87.8026%, Training Loss: 0.3068%\n",
      "Epoch [57/300], Step [223/225], Training Accuracy: 87.8013%, Training Loss: 0.3067%\n",
      "Epoch [57/300], Step [224/225], Training Accuracy: 87.7930%, Training Loss: 0.3067%\n",
      "Epoch [57/300], Step [225/225], Training Accuracy: 87.7710%, Training Loss: 0.3067%\n",
      "Epoch [58/300], Step [1/225], Training Accuracy: 92.1875%, Training Loss: 0.2079%\n",
      "Epoch [58/300], Step [2/225], Training Accuracy: 90.6250%, Training Loss: 0.2515%\n",
      "Epoch [58/300], Step [3/225], Training Accuracy: 89.0625%, Training Loss: 0.2873%\n",
      "Epoch [58/300], Step [4/225], Training Accuracy: 88.6719%, Training Loss: 0.2823%\n",
      "Epoch [58/300], Step [5/225], Training Accuracy: 89.0625%, Training Loss: 0.2819%\n",
      "Epoch [58/300], Step [6/225], Training Accuracy: 88.0208%, Training Loss: 0.2939%\n",
      "Epoch [58/300], Step [7/225], Training Accuracy: 88.3929%, Training Loss: 0.2837%\n",
      "Epoch [58/300], Step [8/225], Training Accuracy: 87.6953%, Training Loss: 0.2987%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/300], Step [9/225], Training Accuracy: 87.8472%, Training Loss: 0.2965%\n",
      "Epoch [58/300], Step [10/225], Training Accuracy: 88.1250%, Training Loss: 0.2921%\n",
      "Epoch [58/300], Step [11/225], Training Accuracy: 87.7841%, Training Loss: 0.3037%\n",
      "Epoch [58/300], Step [12/225], Training Accuracy: 87.7604%, Training Loss: 0.3020%\n",
      "Epoch [58/300], Step [13/225], Training Accuracy: 87.6202%, Training Loss: 0.3059%\n",
      "Epoch [58/300], Step [14/225], Training Accuracy: 87.5000%, Training Loss: 0.3036%\n",
      "Epoch [58/300], Step [15/225], Training Accuracy: 87.5000%, Training Loss: 0.3061%\n",
      "Epoch [58/300], Step [16/225], Training Accuracy: 87.0117%, Training Loss: 0.3124%\n",
      "Epoch [58/300], Step [17/225], Training Accuracy: 86.5809%, Training Loss: 0.3217%\n",
      "Epoch [58/300], Step [18/225], Training Accuracy: 86.6319%, Training Loss: 0.3180%\n",
      "Epoch [58/300], Step [19/225], Training Accuracy: 86.7599%, Training Loss: 0.3158%\n",
      "Epoch [58/300], Step [20/225], Training Accuracy: 87.0312%, Training Loss: 0.3157%\n",
      "Epoch [58/300], Step [21/225], Training Accuracy: 86.9792%, Training Loss: 0.3160%\n",
      "Epoch [58/300], Step [22/225], Training Accuracy: 86.9318%, Training Loss: 0.3193%\n",
      "Epoch [58/300], Step [23/225], Training Accuracy: 86.9565%, Training Loss: 0.3163%\n",
      "Epoch [58/300], Step [24/225], Training Accuracy: 86.9141%, Training Loss: 0.3176%\n",
      "Epoch [58/300], Step [25/225], Training Accuracy: 86.8750%, Training Loss: 0.3159%\n",
      "Epoch [58/300], Step [26/225], Training Accuracy: 86.8990%, Training Loss: 0.3182%\n",
      "Epoch [58/300], Step [27/225], Training Accuracy: 87.0370%, Training Loss: 0.3180%\n",
      "Epoch [58/300], Step [28/225], Training Accuracy: 87.2210%, Training Loss: 0.3135%\n",
      "Epoch [58/300], Step [29/225], Training Accuracy: 87.0690%, Training Loss: 0.3162%\n",
      "Epoch [58/300], Step [30/225], Training Accuracy: 87.0833%, Training Loss: 0.3185%\n",
      "Epoch [58/300], Step [31/225], Training Accuracy: 87.0464%, Training Loss: 0.3186%\n",
      "Epoch [58/300], Step [32/225], Training Accuracy: 87.1582%, Training Loss: 0.3162%\n",
      "Epoch [58/300], Step [33/225], Training Accuracy: 87.2633%, Training Loss: 0.3163%\n",
      "Epoch [58/300], Step [34/225], Training Accuracy: 87.1783%, Training Loss: 0.3180%\n",
      "Epoch [58/300], Step [35/225], Training Accuracy: 87.1429%, Training Loss: 0.3190%\n",
      "Epoch [58/300], Step [36/225], Training Accuracy: 87.3698%, Training Loss: 0.3155%\n",
      "Epoch [58/300], Step [37/225], Training Accuracy: 87.4578%, Training Loss: 0.3149%\n",
      "Epoch [58/300], Step [38/225], Training Accuracy: 87.3355%, Training Loss: 0.3169%\n",
      "Epoch [58/300], Step [39/225], Training Accuracy: 87.2997%, Training Loss: 0.3184%\n",
      "Epoch [58/300], Step [40/225], Training Accuracy: 87.3438%, Training Loss: 0.3170%\n",
      "Epoch [58/300], Step [41/225], Training Accuracy: 87.3095%, Training Loss: 0.3175%\n",
      "Epoch [58/300], Step [42/225], Training Accuracy: 87.2024%, Training Loss: 0.3180%\n",
      "Epoch [58/300], Step [43/225], Training Accuracy: 87.2820%, Training Loss: 0.3180%\n",
      "Epoch [58/300], Step [44/225], Training Accuracy: 87.2869%, Training Loss: 0.3181%\n",
      "Epoch [58/300], Step [45/225], Training Accuracy: 87.3611%, Training Loss: 0.3183%\n",
      "Epoch [58/300], Step [46/225], Training Accuracy: 87.4321%, Training Loss: 0.3177%\n",
      "Epoch [58/300], Step [47/225], Training Accuracy: 87.3670%, Training Loss: 0.3200%\n",
      "Epoch [58/300], Step [48/225], Training Accuracy: 87.3372%, Training Loss: 0.3188%\n",
      "Epoch [58/300], Step [49/225], Training Accuracy: 87.5000%, Training Loss: 0.3162%\n",
      "Epoch [58/300], Step [50/225], Training Accuracy: 87.5938%, Training Loss: 0.3149%\n",
      "Epoch [58/300], Step [51/225], Training Accuracy: 87.7451%, Training Loss: 0.3123%\n",
      "Epoch [58/300], Step [52/225], Training Accuracy: 87.8606%, Training Loss: 0.3100%\n",
      "Epoch [58/300], Step [53/225], Training Accuracy: 87.7653%, Training Loss: 0.3116%\n",
      "Epoch [58/300], Step [54/225], Training Accuracy: 87.7604%, Training Loss: 0.3125%\n",
      "Epoch [58/300], Step [55/225], Training Accuracy: 87.6989%, Training Loss: 0.3131%\n",
      "Epoch [58/300], Step [56/225], Training Accuracy: 87.6953%, Training Loss: 0.3124%\n",
      "Epoch [58/300], Step [57/225], Training Accuracy: 87.6919%, Training Loss: 0.3118%\n",
      "Epoch [58/300], Step [58/225], Training Accuracy: 87.7694%, Training Loss: 0.3104%\n",
      "Epoch [58/300], Step [59/225], Training Accuracy: 87.7913%, Training Loss: 0.3089%\n",
      "Epoch [58/300], Step [60/225], Training Accuracy: 87.7083%, Training Loss: 0.3106%\n",
      "Epoch [58/300], Step [61/225], Training Accuracy: 87.7561%, Training Loss: 0.3106%\n",
      "Epoch [58/300], Step [62/225], Training Accuracy: 87.8276%, Training Loss: 0.3090%\n",
      "Epoch [58/300], Step [63/225], Training Accuracy: 87.8224%, Training Loss: 0.3091%\n",
      "Epoch [58/300], Step [64/225], Training Accuracy: 87.7441%, Training Loss: 0.3115%\n",
      "Epoch [58/300], Step [65/225], Training Accuracy: 87.7644%, Training Loss: 0.3115%\n",
      "Epoch [58/300], Step [66/225], Training Accuracy: 87.7841%, Training Loss: 0.3118%\n",
      "Epoch [58/300], Step [67/225], Training Accuracy: 87.7099%, Training Loss: 0.3121%\n",
      "Epoch [58/300], Step [68/225], Training Accuracy: 87.6608%, Training Loss: 0.3140%\n",
      "Epoch [58/300], Step [69/225], Training Accuracy: 87.7717%, Training Loss: 0.3125%\n",
      "Epoch [58/300], Step [70/225], Training Accuracy: 87.8571%, Training Loss: 0.3117%\n",
      "Epoch [58/300], Step [71/225], Training Accuracy: 87.8521%, Training Loss: 0.3112%\n",
      "Epoch [58/300], Step [72/225], Training Accuracy: 87.8038%, Training Loss: 0.3121%\n",
      "Epoch [58/300], Step [73/225], Training Accuracy: 87.7997%, Training Loss: 0.3118%\n",
      "Epoch [58/300], Step [74/225], Training Accuracy: 87.8167%, Training Loss: 0.3102%\n",
      "Epoch [58/300], Step [75/225], Training Accuracy: 87.7292%, Training Loss: 0.3117%\n",
      "Epoch [58/300], Step [76/225], Training Accuracy: 87.6645%, Training Loss: 0.3128%\n",
      "Epoch [58/300], Step [77/225], Training Accuracy: 87.7435%, Training Loss: 0.3117%\n",
      "Epoch [58/300], Step [78/225], Training Accuracy: 87.7404%, Training Loss: 0.3115%\n",
      "Epoch [58/300], Step [79/225], Training Accuracy: 87.7571%, Training Loss: 0.3110%\n",
      "Epoch [58/300], Step [80/225], Training Accuracy: 87.7344%, Training Loss: 0.3118%\n",
      "Epoch [58/300], Step [81/225], Training Accuracy: 87.6736%, Training Loss: 0.3121%\n",
      "Epoch [58/300], Step [82/225], Training Accuracy: 87.7477%, Training Loss: 0.3113%\n",
      "Epoch [58/300], Step [83/225], Training Accuracy: 87.7447%, Training Loss: 0.3107%\n",
      "Epoch [58/300], Step [84/225], Training Accuracy: 87.8906%, Training Loss: 0.3087%\n",
      "Epoch [58/300], Step [85/225], Training Accuracy: 87.8860%, Training Loss: 0.3086%\n",
      "Epoch [58/300], Step [86/225], Training Accuracy: 87.9179%, Training Loss: 0.3079%\n",
      "Epoch [58/300], Step [87/225], Training Accuracy: 87.8412%, Training Loss: 0.3093%\n",
      "Epoch [58/300], Step [88/225], Training Accuracy: 87.6598%, Training Loss: 0.3117%\n",
      "Epoch [58/300], Step [89/225], Training Accuracy: 87.6931%, Training Loss: 0.3113%\n",
      "Epoch [58/300], Step [90/225], Training Accuracy: 87.6562%, Training Loss: 0.3128%\n",
      "Epoch [58/300], Step [91/225], Training Accuracy: 87.7232%, Training Loss: 0.3114%\n",
      "Epoch [58/300], Step [92/225], Training Accuracy: 87.6529%, Training Loss: 0.3135%\n",
      "Epoch [58/300], Step [93/225], Training Accuracy: 87.6848%, Training Loss: 0.3126%\n",
      "Epoch [58/300], Step [94/225], Training Accuracy: 87.7161%, Training Loss: 0.3117%\n",
      "Epoch [58/300], Step [95/225], Training Accuracy: 87.7138%, Training Loss: 0.3119%\n",
      "Epoch [58/300], Step [96/225], Training Accuracy: 87.7279%, Training Loss: 0.3114%\n",
      "Epoch [58/300], Step [97/225], Training Accuracy: 87.7899%, Training Loss: 0.3103%\n",
      "Epoch [58/300], Step [98/225], Training Accuracy: 87.8189%, Training Loss: 0.3096%\n",
      "Epoch [58/300], Step [99/225], Training Accuracy: 87.8472%, Training Loss: 0.3087%\n",
      "Epoch [58/300], Step [100/225], Training Accuracy: 87.8438%, Training Loss: 0.3088%\n",
      "Epoch [58/300], Step [101/225], Training Accuracy: 87.8403%, Training Loss: 0.3086%\n",
      "Epoch [58/300], Step [102/225], Training Accuracy: 87.8370%, Training Loss: 0.3087%\n",
      "Epoch [58/300], Step [103/225], Training Accuracy: 87.8489%, Training Loss: 0.3081%\n",
      "Epoch [58/300], Step [104/225], Training Accuracy: 87.8906%, Training Loss: 0.3080%\n",
      "Epoch [58/300], Step [105/225], Training Accuracy: 87.8720%, Training Loss: 0.3080%\n",
      "Epoch [58/300], Step [106/225], Training Accuracy: 87.8980%, Training Loss: 0.3084%\n",
      "Epoch [58/300], Step [107/225], Training Accuracy: 87.8797%, Training Loss: 0.3084%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/300], Step [108/225], Training Accuracy: 87.8183%, Training Loss: 0.3088%\n",
      "Epoch [58/300], Step [109/225], Training Accuracy: 87.7724%, Training Loss: 0.3089%\n",
      "Epoch [58/300], Step [110/225], Training Accuracy: 87.8125%, Training Loss: 0.3077%\n",
      "Epoch [58/300], Step [111/225], Training Accuracy: 87.7956%, Training Loss: 0.3081%\n",
      "Epoch [58/300], Step [112/225], Training Accuracy: 87.7651%, Training Loss: 0.3085%\n",
      "Epoch [58/300], Step [113/225], Training Accuracy: 87.7765%, Training Loss: 0.3081%\n",
      "Epoch [58/300], Step [114/225], Training Accuracy: 87.8289%, Training Loss: 0.3074%\n",
      "Epoch [58/300], Step [115/225], Training Accuracy: 87.8125%, Training Loss: 0.3081%\n",
      "Epoch [58/300], Step [116/225], Training Accuracy: 87.8233%, Training Loss: 0.3078%\n",
      "Epoch [58/300], Step [117/225], Training Accuracy: 87.8606%, Training Loss: 0.3068%\n",
      "Epoch [58/300], Step [118/225], Training Accuracy: 87.8046%, Training Loss: 0.3074%\n",
      "Epoch [58/300], Step [119/225], Training Accuracy: 87.8020%, Training Loss: 0.3073%\n",
      "Epoch [58/300], Step [120/225], Training Accuracy: 87.7865%, Training Loss: 0.3076%\n",
      "Epoch [58/300], Step [121/225], Training Accuracy: 87.7841%, Training Loss: 0.3073%\n",
      "Epoch [58/300], Step [122/225], Training Accuracy: 87.7690%, Training Loss: 0.3077%\n",
      "Epoch [58/300], Step [123/225], Training Accuracy: 87.7160%, Training Loss: 0.3076%\n",
      "Epoch [58/300], Step [124/225], Training Accuracy: 87.7268%, Training Loss: 0.3070%\n",
      "Epoch [58/300], Step [125/225], Training Accuracy: 87.7375%, Training Loss: 0.3069%\n",
      "Epoch [58/300], Step [126/225], Training Accuracy: 87.7604%, Training Loss: 0.3065%\n",
      "Epoch [58/300], Step [127/225], Training Accuracy: 87.7584%, Training Loss: 0.3071%\n",
      "Epoch [58/300], Step [128/225], Training Accuracy: 87.7930%, Training Loss: 0.3066%\n",
      "Epoch [58/300], Step [129/225], Training Accuracy: 87.8391%, Training Loss: 0.3055%\n",
      "Epoch [58/300], Step [130/225], Training Accuracy: 87.7885%, Training Loss: 0.3060%\n",
      "Epoch [58/300], Step [131/225], Training Accuracy: 87.8101%, Training Loss: 0.3059%\n",
      "Epoch [58/300], Step [132/225], Training Accuracy: 87.8788%, Training Loss: 0.3050%\n",
      "Epoch [58/300], Step [133/225], Training Accuracy: 87.8877%, Training Loss: 0.3050%\n",
      "Epoch [58/300], Step [134/225], Training Accuracy: 87.8965%, Training Loss: 0.3052%\n",
      "Epoch [58/300], Step [135/225], Training Accuracy: 87.8704%, Training Loss: 0.3052%\n",
      "Epoch [58/300], Step [136/225], Training Accuracy: 87.8791%, Training Loss: 0.3051%\n",
      "Epoch [58/300], Step [137/225], Training Accuracy: 87.8650%, Training Loss: 0.3051%\n",
      "Epoch [58/300], Step [138/225], Training Accuracy: 87.8850%, Training Loss: 0.3047%\n",
      "Epoch [58/300], Step [139/225], Training Accuracy: 87.8934%, Training Loss: 0.3044%\n",
      "Epoch [58/300], Step [140/225], Training Accuracy: 87.8571%, Training Loss: 0.3046%\n",
      "Epoch [58/300], Step [141/225], Training Accuracy: 87.8103%, Training Loss: 0.3052%\n",
      "Epoch [58/300], Step [142/225], Training Accuracy: 87.8191%, Training Loss: 0.3047%\n",
      "Epoch [58/300], Step [143/225], Training Accuracy: 87.7950%, Training Loss: 0.3050%\n",
      "Epoch [58/300], Step [144/225], Training Accuracy: 87.7496%, Training Loss: 0.3053%\n",
      "Epoch [58/300], Step [145/225], Training Accuracy: 87.6832%, Training Loss: 0.3063%\n",
      "Epoch [58/300], Step [146/225], Training Accuracy: 87.6712%, Training Loss: 0.3065%\n",
      "Epoch [58/300], Step [147/225], Training Accuracy: 87.6594%, Training Loss: 0.3063%\n",
      "Epoch [58/300], Step [148/225], Training Accuracy: 87.6900%, Training Loss: 0.3056%\n",
      "Epoch [58/300], Step [149/225], Training Accuracy: 87.7097%, Training Loss: 0.3053%\n",
      "Epoch [58/300], Step [150/225], Training Accuracy: 87.7708%, Training Loss: 0.3042%\n",
      "Epoch [58/300], Step [151/225], Training Accuracy: 87.7794%, Training Loss: 0.3041%\n",
      "Epoch [58/300], Step [152/225], Training Accuracy: 87.7981%, Training Loss: 0.3038%\n",
      "Epoch [58/300], Step [153/225], Training Accuracy: 87.7859%, Training Loss: 0.3036%\n",
      "Epoch [58/300], Step [154/225], Training Accuracy: 87.8044%, Training Loss: 0.3032%\n",
      "Epoch [58/300], Step [155/225], Training Accuracy: 87.8125%, Training Loss: 0.3030%\n",
      "Epoch [58/300], Step [156/225], Training Accuracy: 87.8205%, Training Loss: 0.3029%\n",
      "Epoch [58/300], Step [157/225], Training Accuracy: 87.7986%, Training Loss: 0.3036%\n",
      "Epoch [58/300], Step [158/225], Training Accuracy: 87.8263%, Training Loss: 0.3032%\n",
      "Epoch [58/300], Step [159/225], Training Accuracy: 87.7948%, Training Loss: 0.3041%\n",
      "Epoch [58/300], Step [160/225], Training Accuracy: 87.7637%, Training Loss: 0.3047%\n",
      "Epoch [58/300], Step [161/225], Training Accuracy: 87.7038%, Training Loss: 0.3055%\n",
      "Epoch [58/300], Step [162/225], Training Accuracy: 87.7122%, Training Loss: 0.3052%\n",
      "Epoch [58/300], Step [163/225], Training Accuracy: 87.7205%, Training Loss: 0.3050%\n",
      "Epoch [58/300], Step [164/225], Training Accuracy: 87.7287%, Training Loss: 0.3046%\n",
      "Epoch [58/300], Step [165/225], Training Accuracy: 87.7273%, Training Loss: 0.3044%\n",
      "Epoch [58/300], Step [166/225], Training Accuracy: 87.7353%, Training Loss: 0.3041%\n",
      "Epoch [58/300], Step [167/225], Training Accuracy: 87.6871%, Training Loss: 0.3044%\n",
      "Epoch [58/300], Step [168/225], Training Accuracy: 87.6488%, Training Loss: 0.3052%\n",
      "Epoch [58/300], Step [169/225], Training Accuracy: 87.6942%, Training Loss: 0.3044%\n",
      "Epoch [58/300], Step [170/225], Training Accuracy: 87.6654%, Training Loss: 0.3051%\n",
      "Epoch [58/300], Step [171/225], Training Accuracy: 87.6462%, Training Loss: 0.3053%\n",
      "Epoch [58/300], Step [172/225], Training Accuracy: 87.6544%, Training Loss: 0.3050%\n",
      "Epoch [58/300], Step [173/225], Training Accuracy: 87.6806%, Training Loss: 0.3049%\n",
      "Epoch [58/300], Step [174/225], Training Accuracy: 87.6976%, Training Loss: 0.3045%\n",
      "Epoch [58/300], Step [175/225], Training Accuracy: 87.7232%, Training Loss: 0.3039%\n",
      "Epoch [58/300], Step [176/225], Training Accuracy: 87.7308%, Training Loss: 0.3038%\n",
      "Epoch [58/300], Step [177/225], Training Accuracy: 87.7295%, Training Loss: 0.3038%\n",
      "Epoch [58/300], Step [178/225], Training Accuracy: 87.7195%, Training Loss: 0.3039%\n",
      "Epoch [58/300], Step [179/225], Training Accuracy: 87.7444%, Training Loss: 0.3034%\n",
      "Epoch [58/300], Step [180/225], Training Accuracy: 87.7604%, Training Loss: 0.3030%\n",
      "Epoch [58/300], Step [181/225], Training Accuracy: 87.7503%, Training Loss: 0.3034%\n",
      "Epoch [58/300], Step [182/225], Training Accuracy: 87.7404%, Training Loss: 0.3034%\n",
      "Epoch [58/300], Step [183/225], Training Accuracy: 87.6964%, Training Loss: 0.3038%\n",
      "Epoch [58/300], Step [184/225], Training Accuracy: 87.7123%, Training Loss: 0.3036%\n",
      "Epoch [58/300], Step [185/225], Training Accuracy: 87.7111%, Training Loss: 0.3036%\n",
      "Epoch [58/300], Step [186/225], Training Accuracy: 87.7520%, Training Loss: 0.3027%\n",
      "Epoch [58/300], Step [187/225], Training Accuracy: 87.7841%, Training Loss: 0.3022%\n",
      "Epoch [58/300], Step [188/225], Training Accuracy: 87.7743%, Training Loss: 0.3020%\n",
      "Epoch [58/300], Step [189/225], Training Accuracy: 87.8142%, Training Loss: 0.3013%\n",
      "Epoch [58/300], Step [190/225], Training Accuracy: 87.8207%, Training Loss: 0.3017%\n",
      "Epoch [58/300], Step [191/225], Training Accuracy: 87.7945%, Training Loss: 0.3026%\n",
      "Epoch [58/300], Step [192/225], Training Accuracy: 87.7930%, Training Loss: 0.3025%\n",
      "Epoch [58/300], Step [193/225], Training Accuracy: 87.7753%, Training Loss: 0.3031%\n",
      "Epoch [58/300], Step [194/225], Training Accuracy: 87.7577%, Training Loss: 0.3034%\n",
      "Epoch [58/300], Step [195/225], Training Accuracy: 87.7644%, Training Loss: 0.3031%\n",
      "Epoch [58/300], Step [196/225], Training Accuracy: 87.7631%, Training Loss: 0.3033%\n",
      "Epoch [58/300], Step [197/225], Training Accuracy: 87.7855%, Training Loss: 0.3031%\n",
      "Epoch [58/300], Step [198/225], Training Accuracy: 87.8078%, Training Loss: 0.3024%\n",
      "Epoch [58/300], Step [199/225], Training Accuracy: 87.8298%, Training Loss: 0.3019%\n",
      "Epoch [58/300], Step [200/225], Training Accuracy: 87.8672%, Training Loss: 0.3014%\n",
      "Epoch [58/300], Step [201/225], Training Accuracy: 87.8498%, Training Loss: 0.3020%\n",
      "Epoch [58/300], Step [202/225], Training Accuracy: 87.8713%, Training Loss: 0.3018%\n",
      "Epoch [58/300], Step [203/225], Training Accuracy: 87.9079%, Training Loss: 0.3013%\n",
      "Epoch [58/300], Step [204/225], Training Accuracy: 87.9213%, Training Loss: 0.3010%\n",
      "Epoch [58/300], Step [205/225], Training Accuracy: 87.9116%, Training Loss: 0.3009%\n",
      "Epoch [58/300], Step [206/225], Training Accuracy: 87.9096%, Training Loss: 0.3008%\n",
      "Epoch [58/300], Step [207/225], Training Accuracy: 87.8623%, Training Loss: 0.3013%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/300], Step [208/225], Training Accuracy: 87.8681%, Training Loss: 0.3009%\n",
      "Epoch [58/300], Step [209/225], Training Accuracy: 87.8589%, Training Loss: 0.3013%\n",
      "Epoch [58/300], Step [210/225], Training Accuracy: 87.8423%, Training Loss: 0.3017%\n",
      "Epoch [58/300], Step [211/225], Training Accuracy: 87.8184%, Training Loss: 0.3017%\n",
      "Epoch [58/300], Step [212/225], Training Accuracy: 87.8022%, Training Loss: 0.3017%\n",
      "Epoch [58/300], Step [213/225], Training Accuracy: 87.8374%, Training Loss: 0.3011%\n",
      "Epoch [58/300], Step [214/225], Training Accuracy: 87.8651%, Training Loss: 0.3006%\n",
      "Epoch [58/300], Step [215/225], Training Accuracy: 87.8561%, Training Loss: 0.3007%\n",
      "Epoch [58/300], Step [216/225], Training Accuracy: 87.8689%, Training Loss: 0.3006%\n",
      "Epoch [58/300], Step [217/225], Training Accuracy: 87.8816%, Training Loss: 0.3002%\n",
      "Epoch [58/300], Step [218/225], Training Accuracy: 87.8655%, Training Loss: 0.3008%\n",
      "Epoch [58/300], Step [219/225], Training Accuracy: 87.8781%, Training Loss: 0.3008%\n",
      "Epoch [58/300], Step [220/225], Training Accuracy: 87.9048%, Training Loss: 0.3008%\n",
      "Epoch [58/300], Step [221/225], Training Accuracy: 87.9383%, Training Loss: 0.3003%\n",
      "Epoch [58/300], Step [222/225], Training Accuracy: 87.9434%, Training Loss: 0.3004%\n",
      "Epoch [58/300], Step [223/225], Training Accuracy: 87.9204%, Training Loss: 0.3008%\n",
      "Epoch [58/300], Step [224/225], Training Accuracy: 87.9185%, Training Loss: 0.3007%\n",
      "Epoch [58/300], Step [225/225], Training Accuracy: 87.9377%, Training Loss: 0.3002%\n",
      "Epoch [59/300], Step [1/225], Training Accuracy: 89.0625%, Training Loss: 0.2359%\n",
      "Epoch [59/300], Step [2/225], Training Accuracy: 86.7188%, Training Loss: 0.3391%\n",
      "Epoch [59/300], Step [3/225], Training Accuracy: 86.4583%, Training Loss: 0.3607%\n",
      "Epoch [59/300], Step [4/225], Training Accuracy: 86.3281%, Training Loss: 0.3432%\n",
      "Epoch [59/300], Step [5/225], Training Accuracy: 86.8750%, Training Loss: 0.3205%\n",
      "Epoch [59/300], Step [6/225], Training Accuracy: 88.0208%, Training Loss: 0.2942%\n",
      "Epoch [59/300], Step [7/225], Training Accuracy: 88.3929%, Training Loss: 0.2820%\n",
      "Epoch [59/300], Step [8/225], Training Accuracy: 87.5000%, Training Loss: 0.2984%\n",
      "Epoch [59/300], Step [9/225], Training Accuracy: 87.3264%, Training Loss: 0.3012%\n",
      "Epoch [59/300], Step [10/225], Training Accuracy: 86.5625%, Training Loss: 0.3211%\n",
      "Epoch [59/300], Step [11/225], Training Accuracy: 86.0795%, Training Loss: 0.3241%\n",
      "Epoch [59/300], Step [12/225], Training Accuracy: 86.3281%, Training Loss: 0.3217%\n",
      "Epoch [59/300], Step [13/225], Training Accuracy: 86.7788%, Training Loss: 0.3122%\n",
      "Epoch [59/300], Step [14/225], Training Accuracy: 87.0536%, Training Loss: 0.3132%\n",
      "Epoch [59/300], Step [15/225], Training Accuracy: 87.1875%, Training Loss: 0.3113%\n",
      "Epoch [59/300], Step [16/225], Training Accuracy: 87.2070%, Training Loss: 0.3122%\n",
      "Epoch [59/300], Step [17/225], Training Accuracy: 86.8566%, Training Loss: 0.3180%\n",
      "Epoch [59/300], Step [18/225], Training Accuracy: 86.8056%, Training Loss: 0.3180%\n",
      "Epoch [59/300], Step [19/225], Training Accuracy: 86.8421%, Training Loss: 0.3199%\n",
      "Epoch [59/300], Step [20/225], Training Accuracy: 86.9531%, Training Loss: 0.3182%\n",
      "Epoch [59/300], Step [21/225], Training Accuracy: 87.2024%, Training Loss: 0.3151%\n",
      "Epoch [59/300], Step [22/225], Training Accuracy: 86.7898%, Training Loss: 0.3211%\n",
      "Epoch [59/300], Step [23/225], Training Accuracy: 86.9565%, Training Loss: 0.3174%\n",
      "Epoch [59/300], Step [24/225], Training Accuracy: 86.9792%, Training Loss: 0.3206%\n",
      "Epoch [59/300], Step [25/225], Training Accuracy: 87.0625%, Training Loss: 0.3161%\n",
      "Epoch [59/300], Step [26/225], Training Accuracy: 86.8990%, Training Loss: 0.3162%\n",
      "Epoch [59/300], Step [27/225], Training Accuracy: 86.8056%, Training Loss: 0.3145%\n",
      "Epoch [59/300], Step [28/225], Training Accuracy: 86.8862%, Training Loss: 0.3123%\n",
      "Epoch [59/300], Step [29/225], Training Accuracy: 86.7457%, Training Loss: 0.3153%\n",
      "Epoch [59/300], Step [30/225], Training Accuracy: 86.6667%, Training Loss: 0.3166%\n",
      "Epoch [59/300], Step [31/225], Training Accuracy: 86.9960%, Training Loss: 0.3123%\n",
      "Epoch [59/300], Step [32/225], Training Accuracy: 87.0605%, Training Loss: 0.3105%\n",
      "Epoch [59/300], Step [33/225], Training Accuracy: 87.1212%, Training Loss: 0.3094%\n",
      "Epoch [59/300], Step [34/225], Training Accuracy: 86.9026%, Training Loss: 0.3154%\n",
      "Epoch [59/300], Step [35/225], Training Accuracy: 86.8304%, Training Loss: 0.3174%\n",
      "Epoch [59/300], Step [36/225], Training Accuracy: 86.8490%, Training Loss: 0.3179%\n",
      "Epoch [59/300], Step [37/225], Training Accuracy: 86.9932%, Training Loss: 0.3146%\n",
      "Epoch [59/300], Step [38/225], Training Accuracy: 87.0477%, Training Loss: 0.3142%\n",
      "Epoch [59/300], Step [39/225], Training Accuracy: 87.0192%, Training Loss: 0.3138%\n",
      "Epoch [59/300], Step [40/225], Training Accuracy: 87.0703%, Training Loss: 0.3135%\n",
      "Epoch [59/300], Step [41/225], Training Accuracy: 86.8521%, Training Loss: 0.3182%\n",
      "Epoch [59/300], Step [42/225], Training Accuracy: 86.7188%, Training Loss: 0.3203%\n",
      "Epoch [59/300], Step [43/225], Training Accuracy: 86.8096%, Training Loss: 0.3200%\n",
      "Epoch [59/300], Step [44/225], Training Accuracy: 86.8963%, Training Loss: 0.3194%\n",
      "Epoch [59/300], Step [45/225], Training Accuracy: 86.9792%, Training Loss: 0.3184%\n",
      "Epoch [59/300], Step [46/225], Training Accuracy: 86.9905%, Training Loss: 0.3172%\n",
      "Epoch [59/300], Step [47/225], Training Accuracy: 86.8351%, Training Loss: 0.3218%\n",
      "Epoch [59/300], Step [48/225], Training Accuracy: 86.8815%, Training Loss: 0.3221%\n",
      "Epoch [59/300], Step [49/225], Training Accuracy: 87.0536%, Training Loss: 0.3197%\n",
      "Epoch [59/300], Step [50/225], Training Accuracy: 87.0625%, Training Loss: 0.3195%\n",
      "Epoch [59/300], Step [51/225], Training Accuracy: 87.1324%, Training Loss: 0.3178%\n",
      "Epoch [59/300], Step [52/225], Training Accuracy: 87.1995%, Training Loss: 0.3155%\n",
      "Epoch [59/300], Step [53/225], Training Accuracy: 87.2642%, Training Loss: 0.3145%\n",
      "Epoch [59/300], Step [54/225], Training Accuracy: 87.2685%, Training Loss: 0.3159%\n",
      "Epoch [59/300], Step [55/225], Training Accuracy: 87.3011%, Training Loss: 0.3161%\n",
      "Epoch [59/300], Step [56/225], Training Accuracy: 87.3047%, Training Loss: 0.3156%\n",
      "Epoch [59/300], Step [57/225], Training Accuracy: 87.3081%, Training Loss: 0.3155%\n",
      "Epoch [59/300], Step [58/225], Training Accuracy: 87.3384%, Training Loss: 0.3146%\n",
      "Epoch [59/300], Step [59/225], Training Accuracy: 87.1822%, Training Loss: 0.3156%\n",
      "Epoch [59/300], Step [60/225], Training Accuracy: 87.2656%, Training Loss: 0.3140%\n",
      "Epoch [59/300], Step [61/225], Training Accuracy: 87.3207%, Training Loss: 0.3134%\n",
      "Epoch [59/300], Step [62/225], Training Accuracy: 87.2732%, Training Loss: 0.3142%\n",
      "Epoch [59/300], Step [63/225], Training Accuracy: 87.2768%, Training Loss: 0.3138%\n",
      "Epoch [59/300], Step [64/225], Training Accuracy: 87.3779%, Training Loss: 0.3116%\n",
      "Epoch [59/300], Step [65/225], Training Accuracy: 87.3798%, Training Loss: 0.3107%\n",
      "Epoch [59/300], Step [66/225], Training Accuracy: 87.4290%, Training Loss: 0.3092%\n",
      "Epoch [59/300], Step [67/225], Training Accuracy: 87.4767%, Training Loss: 0.3092%\n",
      "Epoch [59/300], Step [68/225], Training Accuracy: 87.5000%, Training Loss: 0.3097%\n",
      "Epoch [59/300], Step [69/225], Training Accuracy: 87.5453%, Training Loss: 0.3091%\n",
      "Epoch [59/300], Step [70/225], Training Accuracy: 87.5446%, Training Loss: 0.3106%\n",
      "Epoch [59/300], Step [71/225], Training Accuracy: 87.6320%, Training Loss: 0.3090%\n",
      "Epoch [59/300], Step [72/225], Training Accuracy: 87.6302%, Training Loss: 0.3079%\n",
      "Epoch [59/300], Step [73/225], Training Accuracy: 87.5856%, Training Loss: 0.3074%\n",
      "Epoch [59/300], Step [74/225], Training Accuracy: 87.5633%, Training Loss: 0.3071%\n",
      "Epoch [59/300], Step [75/225], Training Accuracy: 87.5417%, Training Loss: 0.3077%\n",
      "Epoch [59/300], Step [76/225], Training Accuracy: 87.5206%, Training Loss: 0.3082%\n",
      "Epoch [59/300], Step [77/225], Training Accuracy: 87.5609%, Training Loss: 0.3075%\n",
      "Epoch [59/300], Step [78/225], Training Accuracy: 87.7003%, Training Loss: 0.3055%\n",
      "Epoch [59/300], Step [79/225], Training Accuracy: 87.7967%, Training Loss: 0.3038%\n",
      "Epoch [59/300], Step [80/225], Training Accuracy: 87.7344%, Training Loss: 0.3047%\n",
      "Epoch [59/300], Step [81/225], Training Accuracy: 87.7894%, Training Loss: 0.3037%\n",
      "Epoch [59/300], Step [82/225], Training Accuracy: 87.8239%, Training Loss: 0.3023%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/300], Step [83/225], Training Accuracy: 87.8389%, Training Loss: 0.3022%\n",
      "Epoch [59/300], Step [84/225], Training Accuracy: 87.8534%, Training Loss: 0.3017%\n",
      "Epoch [59/300], Step [85/225], Training Accuracy: 87.9044%, Training Loss: 0.3019%\n",
      "Epoch [59/300], Step [86/225], Training Accuracy: 87.9542%, Training Loss: 0.3011%\n",
      "Epoch [59/300], Step [87/225], Training Accuracy: 87.9131%, Training Loss: 0.3034%\n",
      "Epoch [59/300], Step [88/225], Training Accuracy: 87.8906%, Training Loss: 0.3041%\n",
      "Epoch [59/300], Step [89/225], Training Accuracy: 87.9213%, Training Loss: 0.3036%\n",
      "Epoch [59/300], Step [90/225], Training Accuracy: 87.8993%, Training Loss: 0.3045%\n",
      "Epoch [59/300], Step [91/225], Training Accuracy: 87.9464%, Training Loss: 0.3035%\n",
      "Epoch [59/300], Step [92/225], Training Accuracy: 87.8906%, Training Loss: 0.3042%\n",
      "Epoch [59/300], Step [93/225], Training Accuracy: 87.8864%, Training Loss: 0.3037%\n",
      "Epoch [59/300], Step [94/225], Training Accuracy: 87.9322%, Training Loss: 0.3031%\n",
      "Epoch [59/300], Step [95/225], Training Accuracy: 87.9441%, Training Loss: 0.3026%\n",
      "Epoch [59/300], Step [96/225], Training Accuracy: 87.9883%, Training Loss: 0.3012%\n",
      "Epoch [59/300], Step [97/225], Training Accuracy: 88.0316%, Training Loss: 0.3008%\n",
      "Epoch [59/300], Step [98/225], Training Accuracy: 87.9943%, Training Loss: 0.3014%\n",
      "Epoch [59/300], Step [99/225], Training Accuracy: 87.9735%, Training Loss: 0.3016%\n",
      "Epoch [59/300], Step [100/225], Training Accuracy: 87.9062%, Training Loss: 0.3023%\n",
      "Epoch [59/300], Step [101/225], Training Accuracy: 87.8713%, Training Loss: 0.3022%\n",
      "Epoch [59/300], Step [102/225], Training Accuracy: 87.8523%, Training Loss: 0.3028%\n",
      "Epoch [59/300], Step [103/225], Training Accuracy: 87.8489%, Training Loss: 0.3027%\n",
      "Epoch [59/300], Step [104/225], Training Accuracy: 87.8456%, Training Loss: 0.3027%\n",
      "Epoch [59/300], Step [105/225], Training Accuracy: 87.9018%, Training Loss: 0.3015%\n",
      "Epoch [59/300], Step [106/225], Training Accuracy: 87.9275%, Training Loss: 0.3018%\n",
      "Epoch [59/300], Step [107/225], Training Accuracy: 87.9235%, Training Loss: 0.3022%\n",
      "Epoch [59/300], Step [108/225], Training Accuracy: 87.8762%, Training Loss: 0.3024%\n",
      "Epoch [59/300], Step [109/225], Training Accuracy: 87.8440%, Training Loss: 0.3026%\n",
      "Epoch [59/300], Step [110/225], Training Accuracy: 87.8267%, Training Loss: 0.3023%\n",
      "Epoch [59/300], Step [111/225], Training Accuracy: 87.8801%, Training Loss: 0.3014%\n",
      "Epoch [59/300], Step [112/225], Training Accuracy: 87.9464%, Training Loss: 0.3005%\n",
      "Epoch [59/300], Step [113/225], Training Accuracy: 87.9701%, Training Loss: 0.3005%\n",
      "Epoch [59/300], Step [114/225], Training Accuracy: 87.9797%, Training Loss: 0.2999%\n",
      "Epoch [59/300], Step [115/225], Training Accuracy: 87.9212%, Training Loss: 0.3010%\n",
      "Epoch [59/300], Step [116/225], Training Accuracy: 87.9445%, Training Loss: 0.3010%\n",
      "Epoch [59/300], Step [117/225], Training Accuracy: 87.9674%, Training Loss: 0.3010%\n",
      "Epoch [59/300], Step [118/225], Training Accuracy: 87.9635%, Training Loss: 0.3017%\n",
      "Epoch [59/300], Step [119/225], Training Accuracy: 87.9333%, Training Loss: 0.3020%\n",
      "Epoch [59/300], Step [120/225], Training Accuracy: 87.8906%, Training Loss: 0.3030%\n",
      "Epoch [59/300], Step [121/225], Training Accuracy: 87.8616%, Training Loss: 0.3028%\n",
      "Epoch [59/300], Step [122/225], Training Accuracy: 87.8202%, Training Loss: 0.3029%\n",
      "Epoch [59/300], Step [123/225], Training Accuracy: 87.8303%, Training Loss: 0.3031%\n",
      "Epoch [59/300], Step [124/225], Training Accuracy: 87.8906%, Training Loss: 0.3017%\n",
      "Epoch [59/300], Step [125/225], Training Accuracy: 87.9250%, Training Loss: 0.3009%\n",
      "Epoch [59/300], Step [126/225], Training Accuracy: 87.8720%, Training Loss: 0.3016%\n",
      "Epoch [59/300], Step [127/225], Training Accuracy: 87.8937%, Training Loss: 0.3011%\n",
      "Epoch [59/300], Step [128/225], Training Accuracy: 87.8662%, Training Loss: 0.3011%\n",
      "Epoch [59/300], Step [129/225], Training Accuracy: 87.8876%, Training Loss: 0.3007%\n",
      "Epoch [59/300], Step [130/225], Training Accuracy: 87.9087%, Training Loss: 0.3007%\n",
      "Epoch [59/300], Step [131/225], Training Accuracy: 87.9055%, Training Loss: 0.3008%\n",
      "Epoch [59/300], Step [132/225], Training Accuracy: 87.8670%, Training Loss: 0.3016%\n",
      "Epoch [59/300], Step [133/225], Training Accuracy: 87.8877%, Training Loss: 0.3013%\n",
      "Epoch [59/300], Step [134/225], Training Accuracy: 87.8731%, Training Loss: 0.3020%\n",
      "Epoch [59/300], Step [135/225], Training Accuracy: 87.9051%, Training Loss: 0.3018%\n",
      "Epoch [59/300], Step [136/225], Training Accuracy: 87.8562%, Training Loss: 0.3021%\n",
      "Epoch [59/300], Step [137/225], Training Accuracy: 87.8878%, Training Loss: 0.3016%\n",
      "Epoch [59/300], Step [138/225], Training Accuracy: 87.8736%, Training Loss: 0.3014%\n",
      "Epoch [59/300], Step [139/225], Training Accuracy: 87.9047%, Training Loss: 0.3007%\n",
      "Epoch [59/300], Step [140/225], Training Accuracy: 87.9464%, Training Loss: 0.3002%\n",
      "Epoch [59/300], Step [141/225], Training Accuracy: 87.9211%, Training Loss: 0.3004%\n",
      "Epoch [59/300], Step [142/225], Training Accuracy: 87.9291%, Training Loss: 0.2998%\n",
      "Epoch [59/300], Step [143/225], Training Accuracy: 87.9261%, Training Loss: 0.2999%\n",
      "Epoch [59/300], Step [144/225], Training Accuracy: 87.9015%, Training Loss: 0.3003%\n",
      "Epoch [59/300], Step [145/225], Training Accuracy: 87.9095%, Training Loss: 0.3000%\n",
      "Epoch [59/300], Step [146/225], Training Accuracy: 87.9174%, Training Loss: 0.2999%\n",
      "Epoch [59/300], Step [147/225], Training Accuracy: 87.9145%, Training Loss: 0.3000%\n",
      "Epoch [59/300], Step [148/225], Training Accuracy: 87.9434%, Training Loss: 0.2992%\n",
      "Epoch [59/300], Step [149/225], Training Accuracy: 87.9614%, Training Loss: 0.2985%\n",
      "Epoch [59/300], Step [150/225], Training Accuracy: 87.9792%, Training Loss: 0.2980%\n",
      "Epoch [59/300], Step [151/225], Training Accuracy: 87.9863%, Training Loss: 0.2977%\n",
      "Epoch [59/300], Step [152/225], Training Accuracy: 88.0037%, Training Loss: 0.2978%\n",
      "Epoch [59/300], Step [153/225], Training Accuracy: 87.9596%, Training Loss: 0.2983%\n",
      "Epoch [59/300], Step [154/225], Training Accuracy: 87.9667%, Training Loss: 0.2981%\n",
      "Epoch [59/300], Step [155/225], Training Accuracy: 87.9637%, Training Loss: 0.2980%\n",
      "Epoch [59/300], Step [156/225], Training Accuracy: 87.9908%, Training Loss: 0.2977%\n",
      "Epoch [59/300], Step [157/225], Training Accuracy: 87.9678%, Training Loss: 0.2977%\n",
      "Epoch [59/300], Step [158/225], Training Accuracy: 87.9153%, Training Loss: 0.2982%\n",
      "Epoch [59/300], Step [159/225], Training Accuracy: 87.9029%, Training Loss: 0.2986%\n",
      "Epoch [59/300], Step [160/225], Training Accuracy: 87.9102%, Training Loss: 0.2986%\n",
      "Epoch [59/300], Step [161/225], Training Accuracy: 87.9561%, Training Loss: 0.2980%\n",
      "Epoch [59/300], Step [162/225], Training Accuracy: 87.9630%, Training Loss: 0.2979%\n",
      "Epoch [59/300], Step [163/225], Training Accuracy: 87.9793%, Training Loss: 0.2976%\n",
      "Epoch [59/300], Step [164/225], Training Accuracy: 87.9859%, Training Loss: 0.2973%\n",
      "Epoch [59/300], Step [165/225], Training Accuracy: 87.9640%, Training Loss: 0.2977%\n",
      "Epoch [59/300], Step [166/225], Training Accuracy: 87.9424%, Training Loss: 0.2983%\n",
      "Epoch [59/300], Step [167/225], Training Accuracy: 87.9304%, Training Loss: 0.2991%\n",
      "Epoch [59/300], Step [168/225], Training Accuracy: 87.9092%, Training Loss: 0.2994%\n",
      "Epoch [59/300], Step [169/225], Training Accuracy: 87.9161%, Training Loss: 0.2988%\n",
      "Epoch [59/300], Step [170/225], Training Accuracy: 87.9228%, Training Loss: 0.2988%\n",
      "Epoch [59/300], Step [171/225], Training Accuracy: 87.9112%, Training Loss: 0.2991%\n",
      "Epoch [59/300], Step [172/225], Training Accuracy: 87.9179%, Training Loss: 0.2988%\n",
      "Epoch [59/300], Step [173/225], Training Accuracy: 87.9155%, Training Loss: 0.2997%\n",
      "Epoch [59/300], Step [174/225], Training Accuracy: 87.9221%, Training Loss: 0.2999%\n",
      "Epoch [59/300], Step [175/225], Training Accuracy: 87.9286%, Training Loss: 0.3000%\n",
      "Epoch [59/300], Step [176/225], Training Accuracy: 87.8817%, Training Loss: 0.3004%\n",
      "Epoch [59/300], Step [177/225], Training Accuracy: 87.8796%, Training Loss: 0.3004%\n",
      "Epoch [59/300], Step [178/225], Training Accuracy: 87.8423%, Training Loss: 0.3009%\n",
      "Epoch [59/300], Step [179/225], Training Accuracy: 87.8579%, Training Loss: 0.3007%\n",
      "Epoch [59/300], Step [180/225], Training Accuracy: 87.8819%, Training Loss: 0.3002%\n",
      "Epoch [59/300], Step [181/225], Training Accuracy: 87.8626%, Training Loss: 0.3005%\n",
      "Epoch [59/300], Step [182/225], Training Accuracy: 87.8777%, Training Loss: 0.3002%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/300], Step [183/225], Training Accuracy: 87.9098%, Training Loss: 0.2999%\n",
      "Epoch [59/300], Step [184/225], Training Accuracy: 87.9161%, Training Loss: 0.2998%\n",
      "Epoch [59/300], Step [185/225], Training Accuracy: 87.9223%, Training Loss: 0.2996%\n",
      "Epoch [59/300], Step [186/225], Training Accuracy: 87.9536%, Training Loss: 0.2989%\n",
      "Epoch [59/300], Step [187/225], Training Accuracy: 87.9512%, Training Loss: 0.2986%\n",
      "Epoch [59/300], Step [188/225], Training Accuracy: 87.9322%, Training Loss: 0.2985%\n",
      "Epoch [59/300], Step [189/225], Training Accuracy: 87.9547%, Training Loss: 0.2984%\n",
      "Epoch [59/300], Step [190/225], Training Accuracy: 87.9934%, Training Loss: 0.2979%\n",
      "Epoch [59/300], Step [191/225], Training Accuracy: 87.9827%, Training Loss: 0.2981%\n",
      "Epoch [59/300], Step [192/225], Training Accuracy: 88.0046%, Training Loss: 0.2974%\n",
      "Epoch [59/300], Step [193/225], Training Accuracy: 88.0100%, Training Loss: 0.2974%\n",
      "Epoch [59/300], Step [194/225], Training Accuracy: 88.0074%, Training Loss: 0.2976%\n",
      "Epoch [59/300], Step [195/225], Training Accuracy: 88.0369%, Training Loss: 0.2971%\n",
      "Epoch [59/300], Step [196/225], Training Accuracy: 88.0261%, Training Loss: 0.2973%\n",
      "Epoch [59/300], Step [197/225], Training Accuracy: 88.0076%, Training Loss: 0.2978%\n",
      "Epoch [59/300], Step [198/225], Training Accuracy: 88.0129%, Training Loss: 0.2980%\n",
      "Epoch [59/300], Step [199/225], Training Accuracy: 88.0104%, Training Loss: 0.2979%\n",
      "Epoch [59/300], Step [200/225], Training Accuracy: 88.0156%, Training Loss: 0.2982%\n",
      "Epoch [59/300], Step [201/225], Training Accuracy: 88.0208%, Training Loss: 0.2980%\n",
      "Epoch [59/300], Step [202/225], Training Accuracy: 88.0183%, Training Loss: 0.2983%\n",
      "Epoch [59/300], Step [203/225], Training Accuracy: 88.0388%, Training Loss: 0.2983%\n",
      "Epoch [59/300], Step [204/225], Training Accuracy: 88.0438%, Training Loss: 0.2979%\n",
      "Epoch [59/300], Step [205/225], Training Accuracy: 88.0640%, Training Loss: 0.2976%\n",
      "Epoch [59/300], Step [206/225], Training Accuracy: 88.0537%, Training Loss: 0.2981%\n",
      "Epoch [59/300], Step [207/225], Training Accuracy: 88.0661%, Training Loss: 0.2980%\n",
      "Epoch [59/300], Step [208/225], Training Accuracy: 88.0334%, Training Loss: 0.2985%\n",
      "Epoch [59/300], Step [209/225], Training Accuracy: 87.9934%, Training Loss: 0.2995%\n",
      "Epoch [59/300], Step [210/225], Training Accuracy: 87.9762%, Training Loss: 0.2996%\n",
      "Epoch [59/300], Step [211/225], Training Accuracy: 87.9739%, Training Loss: 0.3000%\n",
      "Epoch [59/300], Step [212/225], Training Accuracy: 87.9643%, Training Loss: 0.3003%\n",
      "Epoch [59/300], Step [213/225], Training Accuracy: 87.9842%, Training Loss: 0.2998%\n",
      "Epoch [59/300], Step [214/225], Training Accuracy: 87.9673%, Training Loss: 0.3002%\n",
      "Epoch [59/300], Step [215/225], Training Accuracy: 87.9724%, Training Loss: 0.3004%\n",
      "Epoch [59/300], Step [216/225], Training Accuracy: 87.9702%, Training Loss: 0.3004%\n",
      "Epoch [59/300], Step [217/225], Training Accuracy: 87.9968%, Training Loss: 0.2999%\n",
      "Epoch [59/300], Step [218/225], Training Accuracy: 87.9946%, Training Loss: 0.3000%\n",
      "Epoch [59/300], Step [219/225], Training Accuracy: 87.9852%, Training Loss: 0.3000%\n",
      "Epoch [59/300], Step [220/225], Training Accuracy: 87.9688%, Training Loss: 0.3002%\n",
      "Epoch [59/300], Step [221/225], Training Accuracy: 87.9878%, Training Loss: 0.2998%\n",
      "Epoch [59/300], Step [222/225], Training Accuracy: 87.9856%, Training Loss: 0.3000%\n",
      "Epoch [59/300], Step [223/225], Training Accuracy: 87.9835%, Training Loss: 0.3000%\n",
      "Epoch [59/300], Step [224/225], Training Accuracy: 87.9743%, Training Loss: 0.2999%\n",
      "Epoch [59/300], Step [225/225], Training Accuracy: 87.9655%, Training Loss: 0.2998%\n",
      "Epoch [60/300], Step [1/225], Training Accuracy: 93.7500%, Training Loss: 0.2805%\n",
      "Epoch [60/300], Step [2/225], Training Accuracy: 89.8438%, Training Loss: 0.3163%\n",
      "Epoch [60/300], Step [3/225], Training Accuracy: 89.5833%, Training Loss: 0.3249%\n",
      "Epoch [60/300], Step [4/225], Training Accuracy: 87.8906%, Training Loss: 0.3417%\n",
      "Epoch [60/300], Step [5/225], Training Accuracy: 88.4375%, Training Loss: 0.3119%\n",
      "Epoch [60/300], Step [6/225], Training Accuracy: 88.8021%, Training Loss: 0.2942%\n",
      "Epoch [60/300], Step [7/225], Training Accuracy: 89.5089%, Training Loss: 0.2822%\n",
      "Epoch [60/300], Step [8/225], Training Accuracy: 88.8672%, Training Loss: 0.3084%\n",
      "Epoch [60/300], Step [9/225], Training Accuracy: 89.5833%, Training Loss: 0.2972%\n",
      "Epoch [60/300], Step [10/225], Training Accuracy: 88.7500%, Training Loss: 0.3141%\n",
      "Epoch [60/300], Step [11/225], Training Accuracy: 88.7784%, Training Loss: 0.3088%\n",
      "Epoch [60/300], Step [12/225], Training Accuracy: 88.4115%, Training Loss: 0.3133%\n",
      "Epoch [60/300], Step [13/225], Training Accuracy: 88.8221%, Training Loss: 0.3042%\n",
      "Epoch [60/300], Step [14/225], Training Accuracy: 88.8393%, Training Loss: 0.3053%\n",
      "Epoch [60/300], Step [15/225], Training Accuracy: 88.8542%, Training Loss: 0.3019%\n",
      "Epoch [60/300], Step [16/225], Training Accuracy: 88.5742%, Training Loss: 0.3055%\n",
      "Epoch [60/300], Step [17/225], Training Accuracy: 88.7868%, Training Loss: 0.3033%\n",
      "Epoch [60/300], Step [18/225], Training Accuracy: 88.8889%, Training Loss: 0.2986%\n",
      "Epoch [60/300], Step [19/225], Training Accuracy: 88.8980%, Training Loss: 0.2975%\n",
      "Epoch [60/300], Step [20/225], Training Accuracy: 89.0625%, Training Loss: 0.2949%\n",
      "Epoch [60/300], Step [21/225], Training Accuracy: 89.0625%, Training Loss: 0.2920%\n",
      "Epoch [60/300], Step [22/225], Training Accuracy: 88.9915%, Training Loss: 0.2930%\n",
      "Epoch [60/300], Step [23/225], Training Accuracy: 89.1984%, Training Loss: 0.2912%\n",
      "Epoch [60/300], Step [24/225], Training Accuracy: 89.1276%, Training Loss: 0.2939%\n",
      "Epoch [60/300], Step [25/225], Training Accuracy: 89.2500%, Training Loss: 0.2912%\n",
      "Epoch [60/300], Step [26/225], Training Accuracy: 89.0625%, Training Loss: 0.2935%\n",
      "Epoch [60/300], Step [27/225], Training Accuracy: 89.1204%, Training Loss: 0.2957%\n",
      "Epoch [60/300], Step [28/225], Training Accuracy: 89.2857%, Training Loss: 0.2950%\n",
      "Epoch [60/300], Step [29/225], Training Accuracy: 89.3858%, Training Loss: 0.2922%\n",
      "Epoch [60/300], Step [30/225], Training Accuracy: 89.3750%, Training Loss: 0.2896%\n",
      "Epoch [60/300], Step [31/225], Training Accuracy: 89.1633%, Training Loss: 0.2909%\n",
      "Epoch [60/300], Step [32/225], Training Accuracy: 89.1113%, Training Loss: 0.2906%\n",
      "Epoch [60/300], Step [33/225], Training Accuracy: 89.1098%, Training Loss: 0.2909%\n",
      "Epoch [60/300], Step [34/225], Training Accuracy: 89.1544%, Training Loss: 0.2927%\n",
      "Epoch [60/300], Step [35/225], Training Accuracy: 89.1071%, Training Loss: 0.2927%\n",
      "Epoch [60/300], Step [36/225], Training Accuracy: 89.1059%, Training Loss: 0.2936%\n",
      "Epoch [60/300], Step [37/225], Training Accuracy: 89.1470%, Training Loss: 0.2941%\n",
      "Epoch [60/300], Step [38/225], Training Accuracy: 89.1447%, Training Loss: 0.2940%\n",
      "Epoch [60/300], Step [39/225], Training Accuracy: 88.8622%, Training Loss: 0.2968%\n",
      "Epoch [60/300], Step [40/225], Training Accuracy: 88.8672%, Training Loss: 0.2960%\n",
      "Epoch [60/300], Step [41/225], Training Accuracy: 88.7957%, Training Loss: 0.2970%\n",
      "Epoch [60/300], Step [42/225], Training Accuracy: 88.6905%, Training Loss: 0.2972%\n",
      "Epoch [60/300], Step [43/225], Training Accuracy: 88.8081%, Training Loss: 0.2960%\n",
      "Epoch [60/300], Step [44/225], Training Accuracy: 88.6009%, Training Loss: 0.2967%\n",
      "Epoch [60/300], Step [45/225], Training Accuracy: 88.5069%, Training Loss: 0.2961%\n",
      "Epoch [60/300], Step [46/225], Training Accuracy: 88.4511%, Training Loss: 0.2960%\n",
      "Epoch [60/300], Step [47/225], Training Accuracy: 88.2314%, Training Loss: 0.2990%\n",
      "Epoch [60/300], Step [48/225], Training Accuracy: 88.2812%, Training Loss: 0.2985%\n",
      "Epoch [60/300], Step [49/225], Training Accuracy: 88.3610%, Training Loss: 0.2967%\n",
      "Epoch [60/300], Step [50/225], Training Accuracy: 88.3125%, Training Loss: 0.2960%\n",
      "Epoch [60/300], Step [51/225], Training Accuracy: 88.3885%, Training Loss: 0.2940%\n",
      "Epoch [60/300], Step [52/225], Training Accuracy: 88.5517%, Training Loss: 0.2904%\n",
      "Epoch [60/300], Step [53/225], Training Accuracy: 88.5908%, Training Loss: 0.2890%\n",
      "Epoch [60/300], Step [54/225], Training Accuracy: 88.3970%, Training Loss: 0.2919%\n",
      "Epoch [60/300], Step [55/225], Training Accuracy: 88.3523%, Training Loss: 0.2920%\n",
      "Epoch [60/300], Step [56/225], Training Accuracy: 88.4208%, Training Loss: 0.2912%\n",
      "Epoch [60/300], Step [57/225], Training Accuracy: 88.3772%, Training Loss: 0.2924%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/300], Step [58/225], Training Accuracy: 88.2812%, Training Loss: 0.2929%\n",
      "Epoch [60/300], Step [59/225], Training Accuracy: 88.1621%, Training Loss: 0.2950%\n",
      "Epoch [60/300], Step [60/225], Training Accuracy: 88.1771%, Training Loss: 0.2939%\n",
      "Epoch [60/300], Step [61/225], Training Accuracy: 88.1148%, Training Loss: 0.2952%\n",
      "Epoch [60/300], Step [62/225], Training Accuracy: 88.1552%, Training Loss: 0.2937%\n",
      "Epoch [60/300], Step [63/225], Training Accuracy: 88.1696%, Training Loss: 0.2955%\n",
      "Epoch [60/300], Step [64/225], Training Accuracy: 88.1104%, Training Loss: 0.2958%\n",
      "Epoch [60/300], Step [65/225], Training Accuracy: 88.1490%, Training Loss: 0.2953%\n",
      "Epoch [60/300], Step [66/225], Training Accuracy: 88.2339%, Training Loss: 0.2937%\n",
      "Epoch [60/300], Step [67/225], Training Accuracy: 88.2229%, Training Loss: 0.2937%\n",
      "Epoch [60/300], Step [68/225], Training Accuracy: 88.1204%, Training Loss: 0.2955%\n",
      "Epoch [60/300], Step [69/225], Training Accuracy: 88.1341%, Training Loss: 0.2952%\n",
      "Epoch [60/300], Step [70/225], Training Accuracy: 88.2143%, Training Loss: 0.2946%\n",
      "Epoch [60/300], Step [71/225], Training Accuracy: 88.2042%, Training Loss: 0.2949%\n",
      "Epoch [60/300], Step [72/225], Training Accuracy: 88.1293%, Training Loss: 0.2968%\n",
      "Epoch [60/300], Step [73/225], Training Accuracy: 88.1207%, Training Loss: 0.2974%\n",
      "Epoch [60/300], Step [74/225], Training Accuracy: 88.1546%, Training Loss: 0.2962%\n",
      "Epoch [60/300], Step [75/225], Training Accuracy: 88.0208%, Training Loss: 0.2976%\n",
      "Epoch [60/300], Step [76/225], Training Accuracy: 87.9317%, Training Loss: 0.2998%\n",
      "Epoch [60/300], Step [77/225], Training Accuracy: 87.9058%, Training Loss: 0.2997%\n",
      "Epoch [60/300], Step [78/225], Training Accuracy: 87.9207%, Training Loss: 0.2993%\n",
      "Epoch [60/300], Step [79/225], Training Accuracy: 87.9351%, Training Loss: 0.2989%\n",
      "Epoch [60/300], Step [80/225], Training Accuracy: 87.9102%, Training Loss: 0.3005%\n",
      "Epoch [60/300], Step [81/225], Training Accuracy: 87.9630%, Training Loss: 0.2995%\n",
      "Epoch [60/300], Step [82/225], Training Accuracy: 88.0145%, Training Loss: 0.2990%\n",
      "Epoch [60/300], Step [83/225], Training Accuracy: 87.9330%, Training Loss: 0.2998%\n",
      "Epoch [60/300], Step [84/225], Training Accuracy: 87.9650%, Training Loss: 0.2989%\n",
      "Epoch [60/300], Step [85/225], Training Accuracy: 87.9963%, Training Loss: 0.2984%\n",
      "Epoch [60/300], Step [86/225], Training Accuracy: 88.0269%, Training Loss: 0.2976%\n",
      "Epoch [60/300], Step [87/225], Training Accuracy: 87.9670%, Training Loss: 0.2983%\n",
      "Epoch [60/300], Step [88/225], Training Accuracy: 87.9261%, Training Loss: 0.2994%\n",
      "Epoch [60/300], Step [89/225], Training Accuracy: 87.8687%, Training Loss: 0.3010%\n",
      "Epoch [60/300], Step [90/225], Training Accuracy: 87.8299%, Training Loss: 0.3017%\n",
      "Epoch [60/300], Step [91/225], Training Accuracy: 87.8434%, Training Loss: 0.3015%\n",
      "Epoch [60/300], Step [92/225], Training Accuracy: 87.8567%, Training Loss: 0.3013%\n",
      "Epoch [60/300], Step [93/225], Training Accuracy: 87.8696%, Training Loss: 0.3006%\n",
      "Epoch [60/300], Step [94/225], Training Accuracy: 87.8657%, Training Loss: 0.2997%\n",
      "Epoch [60/300], Step [95/225], Training Accuracy: 87.9441%, Training Loss: 0.2984%\n",
      "Epoch [60/300], Step [96/225], Training Accuracy: 87.9883%, Training Loss: 0.2978%\n",
      "Epoch [60/300], Step [97/225], Training Accuracy: 87.9832%, Training Loss: 0.2971%\n",
      "Epoch [60/300], Step [98/225], Training Accuracy: 87.9624%, Training Loss: 0.2977%\n",
      "Epoch [60/300], Step [99/225], Training Accuracy: 87.9893%, Training Loss: 0.2973%\n",
      "Epoch [60/300], Step [100/225], Training Accuracy: 87.9375%, Training Loss: 0.2977%\n",
      "Epoch [60/300], Step [101/225], Training Accuracy: 87.9177%, Training Loss: 0.2977%\n",
      "Epoch [60/300], Step [102/225], Training Accuracy: 87.8523%, Training Loss: 0.2978%\n",
      "Epoch [60/300], Step [103/225], Training Accuracy: 87.8034%, Training Loss: 0.2986%\n",
      "Epoch [60/300], Step [104/225], Training Accuracy: 87.8305%, Training Loss: 0.2984%\n",
      "Epoch [60/300], Step [105/225], Training Accuracy: 87.8720%, Training Loss: 0.2977%\n",
      "Epoch [60/300], Step [106/225], Training Accuracy: 87.9127%, Training Loss: 0.2974%\n",
      "Epoch [60/300], Step [107/225], Training Accuracy: 87.8943%, Training Loss: 0.2986%\n",
      "Epoch [60/300], Step [108/225], Training Accuracy: 87.8906%, Training Loss: 0.2984%\n",
      "Epoch [60/300], Step [109/225], Training Accuracy: 87.8727%, Training Loss: 0.2985%\n",
      "Epoch [60/300], Step [110/225], Training Accuracy: 87.8693%, Training Loss: 0.2987%\n",
      "Epoch [60/300], Step [111/225], Training Accuracy: 87.8801%, Training Loss: 0.2986%\n",
      "Epoch [60/300], Step [112/225], Training Accuracy: 87.8348%, Training Loss: 0.2994%\n",
      "Epoch [60/300], Step [113/225], Training Accuracy: 87.8457%, Training Loss: 0.2992%\n",
      "Epoch [60/300], Step [114/225], Training Accuracy: 87.8427%, Training Loss: 0.2986%\n",
      "Epoch [60/300], Step [115/225], Training Accuracy: 87.8804%, Training Loss: 0.2979%\n",
      "Epoch [60/300], Step [116/225], Training Accuracy: 87.8502%, Training Loss: 0.2981%\n",
      "Epoch [60/300], Step [117/225], Training Accuracy: 87.8606%, Training Loss: 0.2983%\n",
      "Epoch [60/300], Step [118/225], Training Accuracy: 87.8310%, Training Loss: 0.2994%\n",
      "Epoch [60/300], Step [119/225], Training Accuracy: 87.8283%, Training Loss: 0.2997%\n",
      "Epoch [60/300], Step [120/225], Training Accuracy: 87.8255%, Training Loss: 0.2996%\n",
      "Epoch [60/300], Step [121/225], Training Accuracy: 87.8616%, Training Loss: 0.2991%\n",
      "Epoch [60/300], Step [122/225], Training Accuracy: 87.8714%, Training Loss: 0.2990%\n",
      "Epoch [60/300], Step [123/225], Training Accuracy: 87.8557%, Training Loss: 0.2991%\n",
      "Epoch [60/300], Step [124/225], Training Accuracy: 87.8654%, Training Loss: 0.2984%\n",
      "Epoch [60/300], Step [125/225], Training Accuracy: 87.8875%, Training Loss: 0.2982%\n",
      "Epoch [60/300], Step [126/225], Training Accuracy: 87.8596%, Training Loss: 0.2984%\n",
      "Epoch [60/300], Step [127/225], Training Accuracy: 87.8199%, Training Loss: 0.2983%\n",
      "Epoch [60/300], Step [128/225], Training Accuracy: 87.8540%, Training Loss: 0.2976%\n",
      "Epoch [60/300], Step [129/225], Training Accuracy: 87.8755%, Training Loss: 0.2970%\n",
      "Epoch [60/300], Step [130/225], Training Accuracy: 87.8606%, Training Loss: 0.2970%\n",
      "Epoch [60/300], Step [131/225], Training Accuracy: 87.8578%, Training Loss: 0.2975%\n",
      "Epoch [60/300], Step [132/225], Training Accuracy: 87.8433%, Training Loss: 0.2976%\n",
      "Epoch [60/300], Step [133/225], Training Accuracy: 87.8524%, Training Loss: 0.2979%\n",
      "Epoch [60/300], Step [134/225], Training Accuracy: 87.8382%, Training Loss: 0.2979%\n",
      "Epoch [60/300], Step [135/225], Training Accuracy: 87.8356%, Training Loss: 0.2979%\n",
      "Epoch [60/300], Step [136/225], Training Accuracy: 87.8562%, Training Loss: 0.2972%\n",
      "Epoch [60/300], Step [137/225], Training Accuracy: 87.8992%, Training Loss: 0.2966%\n",
      "Epoch [60/300], Step [138/225], Training Accuracy: 87.9076%, Training Loss: 0.2962%\n",
      "Epoch [60/300], Step [139/225], Training Accuracy: 87.9272%, Training Loss: 0.2956%\n",
      "Epoch [60/300], Step [140/225], Training Accuracy: 87.9799%, Training Loss: 0.2950%\n",
      "Epoch [60/300], Step [141/225], Training Accuracy: 88.0098%, Training Loss: 0.2949%\n",
      "Epoch [60/300], Step [142/225], Training Accuracy: 88.0172%, Training Loss: 0.2941%\n",
      "Epoch [60/300], Step [143/225], Training Accuracy: 87.9589%, Training Loss: 0.2953%\n",
      "Epoch [60/300], Step [144/225], Training Accuracy: 87.9666%, Training Loss: 0.2951%\n",
      "Epoch [60/300], Step [145/225], Training Accuracy: 87.9634%, Training Loss: 0.2951%\n",
      "Epoch [60/300], Step [146/225], Training Accuracy: 87.9067%, Training Loss: 0.2956%\n",
      "Epoch [60/300], Step [147/225], Training Accuracy: 87.9145%, Training Loss: 0.2953%\n",
      "Epoch [60/300], Step [148/225], Training Accuracy: 87.9223%, Training Loss: 0.2948%\n",
      "Epoch [60/300], Step [149/225], Training Accuracy: 87.9404%, Training Loss: 0.2948%\n",
      "Epoch [60/300], Step [150/225], Training Accuracy: 87.9688%, Training Loss: 0.2941%\n",
      "Epoch [60/300], Step [151/225], Training Accuracy: 87.9139%, Training Loss: 0.2945%\n",
      "Epoch [60/300], Step [152/225], Training Accuracy: 87.9215%, Training Loss: 0.2942%\n",
      "Epoch [60/300], Step [153/225], Training Accuracy: 87.9391%, Training Loss: 0.2937%\n",
      "Epoch [60/300], Step [154/225], Training Accuracy: 87.9363%, Training Loss: 0.2934%\n",
      "Epoch [60/300], Step [155/225], Training Accuracy: 87.9839%, Training Loss: 0.2929%\n",
      "Epoch [60/300], Step [156/225], Training Accuracy: 87.9708%, Training Loss: 0.2930%\n",
      "Epoch [60/300], Step [157/225], Training Accuracy: 87.9578%, Training Loss: 0.2934%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/300], Step [158/225], Training Accuracy: 87.9351%, Training Loss: 0.2931%\n",
      "Epoch [60/300], Step [159/225], Training Accuracy: 87.9226%, Training Loss: 0.2931%\n",
      "Epoch [60/300], Step [160/225], Training Accuracy: 87.9199%, Training Loss: 0.2928%\n",
      "Epoch [60/300], Step [161/225], Training Accuracy: 87.9561%, Training Loss: 0.2926%\n",
      "Epoch [60/300], Step [162/225], Training Accuracy: 87.9340%, Training Loss: 0.2924%\n",
      "Epoch [60/300], Step [163/225], Training Accuracy: 87.9314%, Training Loss: 0.2924%\n",
      "Epoch [60/300], Step [164/225], Training Accuracy: 87.9573%, Training Loss: 0.2916%\n",
      "Epoch [60/300], Step [165/225], Training Accuracy: 87.9545%, Training Loss: 0.2917%\n",
      "Epoch [60/300], Step [166/225], Training Accuracy: 87.9706%, Training Loss: 0.2915%\n",
      "Epoch [60/300], Step [167/225], Training Accuracy: 87.9585%, Training Loss: 0.2916%\n",
      "Epoch [60/300], Step [168/225], Training Accuracy: 87.9650%, Training Loss: 0.2917%\n",
      "Epoch [60/300], Step [169/225], Training Accuracy: 87.9993%, Training Loss: 0.2910%\n",
      "Epoch [60/300], Step [170/225], Training Accuracy: 87.9688%, Training Loss: 0.2912%\n",
      "Epoch [60/300], Step [171/225], Training Accuracy: 87.9660%, Training Loss: 0.2914%\n",
      "Epoch [60/300], Step [172/225], Training Accuracy: 87.9815%, Training Loss: 0.2910%\n",
      "Epoch [60/300], Step [173/225], Training Accuracy: 87.9697%, Training Loss: 0.2913%\n",
      "Epoch [60/300], Step [174/225], Training Accuracy: 87.9580%, Training Loss: 0.2913%\n",
      "Epoch [60/300], Step [175/225], Training Accuracy: 87.9732%, Training Loss: 0.2912%\n",
      "Epoch [60/300], Step [176/225], Training Accuracy: 87.9616%, Training Loss: 0.2911%\n",
      "Epoch [60/300], Step [177/225], Training Accuracy: 87.9855%, Training Loss: 0.2908%\n",
      "Epoch [60/300], Step [178/225], Training Accuracy: 87.9828%, Training Loss: 0.2907%\n",
      "Epoch [60/300], Step [179/225], Training Accuracy: 87.9976%, Training Loss: 0.2902%\n",
      "Epoch [60/300], Step [180/225], Training Accuracy: 88.0122%, Training Loss: 0.2901%\n",
      "Epoch [60/300], Step [181/225], Training Accuracy: 88.0439%, Training Loss: 0.2900%\n",
      "Epoch [60/300], Step [182/225], Training Accuracy: 88.0752%, Training Loss: 0.2897%\n",
      "Epoch [60/300], Step [183/225], Training Accuracy: 88.0550%, Training Loss: 0.2899%\n",
      "Epoch [60/300], Step [184/225], Training Accuracy: 88.0690%, Training Loss: 0.2900%\n",
      "Epoch [60/300], Step [185/225], Training Accuracy: 88.0405%, Training Loss: 0.2900%\n",
      "Epoch [60/300], Step [186/225], Training Accuracy: 88.0712%, Training Loss: 0.2892%\n",
      "Epoch [60/300], Step [187/225], Training Accuracy: 88.0932%, Training Loss: 0.2890%\n",
      "Epoch [60/300], Step [188/225], Training Accuracy: 88.0984%, Training Loss: 0.2894%\n",
      "Epoch [60/300], Step [189/225], Training Accuracy: 88.1283%, Training Loss: 0.2887%\n",
      "Epoch [60/300], Step [190/225], Training Accuracy: 88.1414%, Training Loss: 0.2884%\n",
      "Epoch [60/300], Step [191/225], Training Accuracy: 88.1299%, Training Loss: 0.2885%\n",
      "Epoch [60/300], Step [192/225], Training Accuracy: 88.1510%, Training Loss: 0.2883%\n",
      "Epoch [60/300], Step [193/225], Training Accuracy: 88.1477%, Training Loss: 0.2885%\n",
      "Epoch [60/300], Step [194/225], Training Accuracy: 88.1202%, Training Loss: 0.2890%\n",
      "Epoch [60/300], Step [195/225], Training Accuracy: 88.0929%, Training Loss: 0.2894%\n",
      "Epoch [60/300], Step [196/225], Training Accuracy: 88.0421%, Training Loss: 0.2897%\n",
      "Epoch [60/300], Step [197/225], Training Accuracy: 88.0473%, Training Loss: 0.2897%\n",
      "Epoch [60/300], Step [198/225], Training Accuracy: 88.0445%, Training Loss: 0.2897%\n",
      "Epoch [60/300], Step [199/225], Training Accuracy: 88.0182%, Training Loss: 0.2900%\n",
      "Epoch [60/300], Step [200/225], Training Accuracy: 88.0391%, Training Loss: 0.2897%\n",
      "Epoch [60/300], Step [201/225], Training Accuracy: 88.0364%, Training Loss: 0.2899%\n",
      "Epoch [60/300], Step [202/225], Training Accuracy: 88.0260%, Training Loss: 0.2898%\n",
      "Epoch [60/300], Step [203/225], Training Accuracy: 88.0465%, Training Loss: 0.2893%\n",
      "Epoch [60/300], Step [204/225], Training Accuracy: 88.0591%, Training Loss: 0.2889%\n",
      "Epoch [60/300], Step [205/225], Training Accuracy: 88.0640%, Training Loss: 0.2889%\n",
      "Epoch [60/300], Step [206/225], Training Accuracy: 88.0689%, Training Loss: 0.2891%\n",
      "Epoch [60/300], Step [207/225], Training Accuracy: 88.0586%, Training Loss: 0.2891%\n",
      "Epoch [60/300], Step [208/225], Training Accuracy: 88.0634%, Training Loss: 0.2888%\n",
      "Epoch [60/300], Step [209/225], Training Accuracy: 88.0532%, Training Loss: 0.2887%\n",
      "Epoch [60/300], Step [210/225], Training Accuracy: 88.0283%, Training Loss: 0.2892%\n",
      "Epoch [60/300], Step [211/225], Training Accuracy: 88.0184%, Training Loss: 0.2893%\n",
      "Epoch [60/300], Step [212/225], Training Accuracy: 88.0012%, Training Loss: 0.2898%\n",
      "Epoch [60/300], Step [213/225], Training Accuracy: 88.0355%, Training Loss: 0.2891%\n",
      "Epoch [60/300], Step [214/225], Training Accuracy: 88.0257%, Training Loss: 0.2893%\n",
      "Epoch [60/300], Step [215/225], Training Accuracy: 88.0305%, Training Loss: 0.2894%\n",
      "Epoch [60/300], Step [216/225], Training Accuracy: 88.0281%, Training Loss: 0.2897%\n",
      "Epoch [60/300], Step [217/225], Training Accuracy: 88.0256%, Training Loss: 0.2897%\n",
      "Epoch [60/300], Step [218/225], Training Accuracy: 88.0017%, Training Loss: 0.2902%\n",
      "Epoch [60/300], Step [219/225], Training Accuracy: 87.9780%, Training Loss: 0.2907%\n",
      "Epoch [60/300], Step [220/225], Training Accuracy: 87.9759%, Training Loss: 0.2907%\n",
      "Epoch [60/300], Step [221/225], Training Accuracy: 88.0020%, Training Loss: 0.2908%\n",
      "Epoch [60/300], Step [222/225], Training Accuracy: 88.0208%, Training Loss: 0.2904%\n",
      "Epoch [60/300], Step [223/225], Training Accuracy: 88.0325%, Training Loss: 0.2904%\n",
      "Epoch [60/300], Step [224/225], Training Accuracy: 88.0511%, Training Loss: 0.2901%\n",
      "Epoch [60/300], Step [225/225], Training Accuracy: 88.0628%, Training Loss: 0.2898%\n",
      "Epoch [61/300], Step [1/225], Training Accuracy: 87.5000%, Training Loss: 0.2760%\n",
      "Epoch [61/300], Step [2/225], Training Accuracy: 89.0625%, Training Loss: 0.2837%\n",
      "Epoch [61/300], Step [3/225], Training Accuracy: 88.5417%, Training Loss: 0.3001%\n",
      "Epoch [61/300], Step [4/225], Training Accuracy: 88.6719%, Training Loss: 0.2992%\n",
      "Epoch [61/300], Step [5/225], Training Accuracy: 89.0625%, Training Loss: 0.2787%\n",
      "Epoch [61/300], Step [6/225], Training Accuracy: 88.2812%, Training Loss: 0.2888%\n",
      "Epoch [61/300], Step [7/225], Training Accuracy: 88.1696%, Training Loss: 0.2913%\n",
      "Epoch [61/300], Step [8/225], Training Accuracy: 87.3047%, Training Loss: 0.2959%\n",
      "Epoch [61/300], Step [9/225], Training Accuracy: 86.8056%, Training Loss: 0.3067%\n",
      "Epoch [61/300], Step [10/225], Training Accuracy: 87.1875%, Training Loss: 0.3069%\n",
      "Epoch [61/300], Step [11/225], Training Accuracy: 86.5057%, Training Loss: 0.3260%\n",
      "Epoch [61/300], Step [12/225], Training Accuracy: 86.4583%, Training Loss: 0.3307%\n",
      "Epoch [61/300], Step [13/225], Training Accuracy: 86.8990%, Training Loss: 0.3282%\n",
      "Epoch [61/300], Step [14/225], Training Accuracy: 86.8304%, Training Loss: 0.3308%\n",
      "Epoch [61/300], Step [15/225], Training Accuracy: 87.0833%, Training Loss: 0.3297%\n",
      "Epoch [61/300], Step [16/225], Training Accuracy: 87.0117%, Training Loss: 0.3339%\n",
      "Epoch [61/300], Step [17/225], Training Accuracy: 87.1324%, Training Loss: 0.3259%\n",
      "Epoch [61/300], Step [18/225], Training Accuracy: 87.3264%, Training Loss: 0.3208%\n",
      "Epoch [61/300], Step [19/225], Training Accuracy: 87.0888%, Training Loss: 0.3236%\n",
      "Epoch [61/300], Step [20/225], Training Accuracy: 87.1875%, Training Loss: 0.3198%\n",
      "Epoch [61/300], Step [21/225], Training Accuracy: 87.0536%, Training Loss: 0.3168%\n",
      "Epoch [61/300], Step [22/225], Training Accuracy: 86.7898%, Training Loss: 0.3209%\n",
      "Epoch [61/300], Step [23/225], Training Accuracy: 86.6848%, Training Loss: 0.3202%\n",
      "Epoch [61/300], Step [24/225], Training Accuracy: 86.6536%, Training Loss: 0.3196%\n",
      "Epoch [61/300], Step [25/225], Training Accuracy: 86.8750%, Training Loss: 0.3159%\n",
      "Epoch [61/300], Step [26/225], Training Accuracy: 87.0192%, Training Loss: 0.3128%\n",
      "Epoch [61/300], Step [27/225], Training Accuracy: 87.1528%, Training Loss: 0.3094%\n",
      "Epoch [61/300], Step [28/225], Training Accuracy: 87.2210%, Training Loss: 0.3072%\n",
      "Epoch [61/300], Step [29/225], Training Accuracy: 87.3922%, Training Loss: 0.3065%\n",
      "Epoch [61/300], Step [30/225], Training Accuracy: 87.2917%, Training Loss: 0.3098%\n",
      "Epoch [61/300], Step [31/225], Training Accuracy: 87.2480%, Training Loss: 0.3100%\n",
      "Epoch [61/300], Step [32/225], Training Accuracy: 87.5000%, Training Loss: 0.3059%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/300], Step [33/225], Training Accuracy: 87.5000%, Training Loss: 0.3057%\n",
      "Epoch [61/300], Step [34/225], Training Accuracy: 87.1783%, Training Loss: 0.3122%\n",
      "Epoch [61/300], Step [35/225], Training Accuracy: 87.0982%, Training Loss: 0.3143%\n",
      "Epoch [61/300], Step [36/225], Training Accuracy: 87.1962%, Training Loss: 0.3123%\n",
      "Epoch [61/300], Step [37/225], Training Accuracy: 87.2044%, Training Loss: 0.3109%\n",
      "Epoch [61/300], Step [38/225], Training Accuracy: 87.2533%, Training Loss: 0.3090%\n",
      "Epoch [61/300], Step [39/225], Training Accuracy: 87.1795%, Training Loss: 0.3089%\n",
      "Epoch [61/300], Step [40/225], Training Accuracy: 87.1875%, Training Loss: 0.3092%\n",
      "Epoch [61/300], Step [41/225], Training Accuracy: 87.1189%, Training Loss: 0.3105%\n",
      "Epoch [61/300], Step [42/225], Training Accuracy: 87.2024%, Training Loss: 0.3095%\n",
      "Epoch [61/300], Step [43/225], Training Accuracy: 87.3183%, Training Loss: 0.3090%\n",
      "Epoch [61/300], Step [44/225], Training Accuracy: 87.3224%, Training Loss: 0.3090%\n",
      "Epoch [61/300], Step [45/225], Training Accuracy: 87.2222%, Training Loss: 0.3087%\n",
      "Epoch [61/300], Step [46/225], Training Accuracy: 87.1943%, Training Loss: 0.3096%\n",
      "Epoch [61/300], Step [47/225], Training Accuracy: 87.1676%, Training Loss: 0.3100%\n",
      "Epoch [61/300], Step [48/225], Training Accuracy: 87.3047%, Training Loss: 0.3096%\n",
      "Epoch [61/300], Step [49/225], Training Accuracy: 87.3724%, Training Loss: 0.3072%\n",
      "Epoch [61/300], Step [50/225], Training Accuracy: 87.3125%, Training Loss: 0.3086%\n",
      "Epoch [61/300], Step [51/225], Training Accuracy: 87.3775%, Training Loss: 0.3067%\n",
      "Epoch [61/300], Step [52/225], Training Accuracy: 87.4700%, Training Loss: 0.3049%\n",
      "Epoch [61/300], Step [53/225], Training Accuracy: 87.4116%, Training Loss: 0.3077%\n",
      "Epoch [61/300], Step [54/225], Training Accuracy: 87.5579%, Training Loss: 0.3059%\n",
      "Epoch [61/300], Step [55/225], Training Accuracy: 87.6136%, Training Loss: 0.3059%\n",
      "Epoch [61/300], Step [56/225], Training Accuracy: 87.5279%, Training Loss: 0.3057%\n",
      "Epoch [61/300], Step [57/225], Training Accuracy: 87.5274%, Training Loss: 0.3062%\n",
      "Epoch [61/300], Step [58/225], Training Accuracy: 87.5000%, Training Loss: 0.3068%\n",
      "Epoch [61/300], Step [59/225], Training Accuracy: 87.5265%, Training Loss: 0.3056%\n",
      "Epoch [61/300], Step [60/225], Training Accuracy: 87.6042%, Training Loss: 0.3048%\n",
      "Epoch [61/300], Step [61/225], Training Accuracy: 87.5512%, Training Loss: 0.3077%\n",
      "Epoch [61/300], Step [62/225], Training Accuracy: 87.5504%, Training Loss: 0.3066%\n",
      "Epoch [61/300], Step [63/225], Training Accuracy: 87.4752%, Training Loss: 0.3072%\n",
      "Epoch [61/300], Step [64/225], Training Accuracy: 87.4268%, Training Loss: 0.3075%\n",
      "Epoch [61/300], Step [65/225], Training Accuracy: 87.4519%, Training Loss: 0.3070%\n",
      "Epoch [61/300], Step [66/225], Training Accuracy: 87.5000%, Training Loss: 0.3056%\n",
      "Epoch [61/300], Step [67/225], Training Accuracy: 87.5233%, Training Loss: 0.3060%\n",
      "Epoch [61/300], Step [68/225], Training Accuracy: 87.4770%, Training Loss: 0.3061%\n",
      "Epoch [61/300], Step [69/225], Training Accuracy: 87.4774%, Training Loss: 0.3060%\n",
      "Epoch [61/300], Step [70/225], Training Accuracy: 87.5223%, Training Loss: 0.3048%\n",
      "Epoch [61/300], Step [71/225], Training Accuracy: 87.4120%, Training Loss: 0.3048%\n",
      "Epoch [61/300], Step [72/225], Training Accuracy: 87.5651%, Training Loss: 0.3026%\n",
      "Epoch [61/300], Step [73/225], Training Accuracy: 87.5214%, Training Loss: 0.3022%\n",
      "Epoch [61/300], Step [74/225], Training Accuracy: 87.5422%, Training Loss: 0.3014%\n",
      "Epoch [61/300], Step [75/225], Training Accuracy: 87.5833%, Training Loss: 0.3012%\n",
      "Epoch [61/300], Step [76/225], Training Accuracy: 87.5822%, Training Loss: 0.3026%\n",
      "Epoch [61/300], Step [77/225], Training Accuracy: 87.6420%, Training Loss: 0.3021%\n",
      "Epoch [61/300], Step [78/225], Training Accuracy: 87.7003%, Training Loss: 0.3009%\n",
      "Epoch [61/300], Step [79/225], Training Accuracy: 87.7571%, Training Loss: 0.3001%\n",
      "Epoch [61/300], Step [80/225], Training Accuracy: 87.7734%, Training Loss: 0.2992%\n",
      "Epoch [61/300], Step [81/225], Training Accuracy: 87.8279%, Training Loss: 0.2986%\n",
      "Epoch [61/300], Step [82/225], Training Accuracy: 87.8811%, Training Loss: 0.2976%\n",
      "Epoch [61/300], Step [83/225], Training Accuracy: 87.9518%, Training Loss: 0.2968%\n",
      "Epoch [61/300], Step [84/225], Training Accuracy: 87.9464%, Training Loss: 0.2967%\n",
      "Epoch [61/300], Step [85/225], Training Accuracy: 87.9412%, Training Loss: 0.2971%\n",
      "Epoch [61/300], Step [86/225], Training Accuracy: 87.9724%, Training Loss: 0.2967%\n",
      "Epoch [61/300], Step [87/225], Training Accuracy: 87.8951%, Training Loss: 0.2977%\n",
      "Epoch [61/300], Step [88/225], Training Accuracy: 87.8018%, Training Loss: 0.2990%\n",
      "Epoch [61/300], Step [89/225], Training Accuracy: 87.8336%, Training Loss: 0.2987%\n",
      "Epoch [61/300], Step [90/225], Training Accuracy: 87.8125%, Training Loss: 0.3000%\n",
      "Epoch [61/300], Step [91/225], Training Accuracy: 87.8949%, Training Loss: 0.2987%\n",
      "Epoch [61/300], Step [92/225], Training Accuracy: 87.8736%, Training Loss: 0.3002%\n",
      "Epoch [61/300], Step [93/225], Training Accuracy: 87.8696%, Training Loss: 0.3004%\n",
      "Epoch [61/300], Step [94/225], Training Accuracy: 87.8989%, Training Loss: 0.2995%\n",
      "Epoch [61/300], Step [95/225], Training Accuracy: 87.9276%, Training Loss: 0.2993%\n",
      "Epoch [61/300], Step [96/225], Training Accuracy: 87.8581%, Training Loss: 0.3003%\n",
      "Epoch [61/300], Step [97/225], Training Accuracy: 87.8866%, Training Loss: 0.2998%\n",
      "Epoch [61/300], Step [98/225], Training Accuracy: 87.8508%, Training Loss: 0.3003%\n",
      "Epoch [61/300], Step [99/225], Training Accuracy: 87.8157%, Training Loss: 0.3005%\n",
      "Epoch [61/300], Step [100/225], Training Accuracy: 87.7812%, Training Loss: 0.3013%\n",
      "Epoch [61/300], Step [101/225], Training Accuracy: 87.7785%, Training Loss: 0.3011%\n",
      "Epoch [61/300], Step [102/225], Training Accuracy: 87.6991%, Training Loss: 0.3027%\n",
      "Epoch [61/300], Step [103/225], Training Accuracy: 87.7275%, Training Loss: 0.3019%\n",
      "Epoch [61/300], Step [104/225], Training Accuracy: 87.7404%, Training Loss: 0.3014%\n",
      "Epoch [61/300], Step [105/225], Training Accuracy: 87.7083%, Training Loss: 0.3012%\n",
      "Epoch [61/300], Step [106/225], Training Accuracy: 87.6916%, Training Loss: 0.3018%\n",
      "Epoch [61/300], Step [107/225], Training Accuracy: 87.7044%, Training Loss: 0.3009%\n",
      "Epoch [61/300], Step [108/225], Training Accuracy: 87.7604%, Training Loss: 0.3000%\n",
      "Epoch [61/300], Step [109/225], Training Accuracy: 87.7437%, Training Loss: 0.3001%\n",
      "Epoch [61/300], Step [110/225], Training Accuracy: 87.7557%, Training Loss: 0.2993%\n",
      "Epoch [61/300], Step [111/225], Training Accuracy: 87.7675%, Training Loss: 0.2990%\n",
      "Epoch [61/300], Step [112/225], Training Accuracy: 87.7511%, Training Loss: 0.2994%\n",
      "Epoch [61/300], Step [113/225], Training Accuracy: 87.7765%, Training Loss: 0.2989%\n",
      "Epoch [61/300], Step [114/225], Training Accuracy: 87.7604%, Training Loss: 0.2990%\n",
      "Epoch [61/300], Step [115/225], Training Accuracy: 87.7446%, Training Loss: 0.2983%\n",
      "Epoch [61/300], Step [116/225], Training Accuracy: 87.7155%, Training Loss: 0.2983%\n",
      "Epoch [61/300], Step [117/225], Training Accuracy: 87.7270%, Training Loss: 0.2981%\n",
      "Epoch [61/300], Step [118/225], Training Accuracy: 87.7251%, Training Loss: 0.2977%\n",
      "Epoch [61/300], Step [119/225], Training Accuracy: 87.7495%, Training Loss: 0.2977%\n",
      "Epoch [61/300], Step [120/225], Training Accuracy: 87.7995%, Training Loss: 0.2969%\n",
      "Epoch [61/300], Step [121/225], Training Accuracy: 87.7454%, Training Loss: 0.2971%\n",
      "Epoch [61/300], Step [122/225], Training Accuracy: 87.6921%, Training Loss: 0.2976%\n",
      "Epoch [61/300], Step [123/225], Training Accuracy: 87.7287%, Training Loss: 0.2973%\n",
      "Epoch [61/300], Step [124/225], Training Accuracy: 87.7394%, Training Loss: 0.2977%\n",
      "Epoch [61/300], Step [125/225], Training Accuracy: 87.7500%, Training Loss: 0.2974%\n",
      "Epoch [61/300], Step [126/225], Training Accuracy: 87.7232%, Training Loss: 0.2979%\n",
      "Epoch [61/300], Step [127/225], Training Accuracy: 87.6353%, Training Loss: 0.2991%\n",
      "Epoch [61/300], Step [128/225], Training Accuracy: 87.6465%, Training Loss: 0.2989%\n",
      "Epoch [61/300], Step [129/225], Training Accuracy: 87.6575%, Training Loss: 0.2985%\n",
      "Epoch [61/300], Step [130/225], Training Accuracy: 87.6803%, Training Loss: 0.2978%\n",
      "Epoch [61/300], Step [131/225], Training Accuracy: 87.6312%, Training Loss: 0.2985%\n",
      "Epoch [61/300], Step [132/225], Training Accuracy: 87.6420%, Training Loss: 0.2989%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/300], Step [133/225], Training Accuracy: 87.6175%, Training Loss: 0.2993%\n",
      "Epoch [61/300], Step [134/225], Training Accuracy: 87.6399%, Training Loss: 0.2991%\n",
      "Epoch [61/300], Step [135/225], Training Accuracy: 87.6505%, Training Loss: 0.2990%\n",
      "Epoch [61/300], Step [136/225], Training Accuracy: 87.6608%, Training Loss: 0.2991%\n",
      "Epoch [61/300], Step [137/225], Training Accuracy: 87.6483%, Training Loss: 0.2990%\n",
      "Epoch [61/300], Step [138/225], Training Accuracy: 87.6359%, Training Loss: 0.2987%\n",
      "Epoch [61/300], Step [139/225], Training Accuracy: 87.6461%, Training Loss: 0.2988%\n",
      "Epoch [61/300], Step [140/225], Training Accuracy: 87.6562%, Training Loss: 0.2983%\n",
      "Epoch [61/300], Step [141/225], Training Accuracy: 87.5997%, Training Loss: 0.2997%\n",
      "Epoch [61/300], Step [142/225], Training Accuracy: 87.6430%, Training Loss: 0.2988%\n",
      "Epoch [61/300], Step [143/225], Training Accuracy: 87.6202%, Training Loss: 0.3001%\n",
      "Epoch [61/300], Step [144/225], Training Accuracy: 87.5868%, Training Loss: 0.3004%\n",
      "Epoch [61/300], Step [145/225], Training Accuracy: 87.5970%, Training Loss: 0.3002%\n",
      "Epoch [61/300], Step [146/225], Training Accuracy: 87.5749%, Training Loss: 0.3005%\n",
      "Epoch [61/300], Step [147/225], Training Accuracy: 87.6382%, Training Loss: 0.2996%\n",
      "Epoch [61/300], Step [148/225], Training Accuracy: 87.6795%, Training Loss: 0.2988%\n",
      "Epoch [61/300], Step [149/225], Training Accuracy: 87.7412%, Training Loss: 0.2977%\n",
      "Epoch [61/300], Step [150/225], Training Accuracy: 87.7812%, Training Loss: 0.2967%\n",
      "Epoch [61/300], Step [151/225], Training Accuracy: 87.8208%, Training Loss: 0.2962%\n",
      "Epoch [61/300], Step [152/225], Training Accuracy: 87.8701%, Training Loss: 0.2953%\n",
      "Epoch [61/300], Step [153/225], Training Accuracy: 87.8472%, Training Loss: 0.2955%\n",
      "Epoch [61/300], Step [154/225], Training Accuracy: 87.8957%, Training Loss: 0.2947%\n",
      "Epoch [61/300], Step [155/225], Training Accuracy: 87.8931%, Training Loss: 0.2949%\n",
      "Epoch [61/300], Step [156/225], Training Accuracy: 87.9407%, Training Loss: 0.2943%\n",
      "Epoch [61/300], Step [157/225], Training Accuracy: 87.9379%, Training Loss: 0.2946%\n",
      "Epoch [61/300], Step [158/225], Training Accuracy: 87.9450%, Training Loss: 0.2950%\n",
      "Epoch [61/300], Step [159/225], Training Accuracy: 87.9324%, Training Loss: 0.2954%\n",
      "Epoch [61/300], Step [160/225], Training Accuracy: 87.9395%, Training Loss: 0.2957%\n",
      "Epoch [61/300], Step [161/225], Training Accuracy: 87.9076%, Training Loss: 0.2961%\n",
      "Epoch [61/300], Step [162/225], Training Accuracy: 87.9437%, Training Loss: 0.2963%\n",
      "Epoch [61/300], Step [163/225], Training Accuracy: 87.9793%, Training Loss: 0.2957%\n",
      "Epoch [61/300], Step [164/225], Training Accuracy: 88.0240%, Training Loss: 0.2949%\n",
      "Epoch [61/300], Step [165/225], Training Accuracy: 88.0019%, Training Loss: 0.2949%\n",
      "Epoch [61/300], Step [166/225], Training Accuracy: 88.0177%, Training Loss: 0.2948%\n",
      "Epoch [61/300], Step [167/225], Training Accuracy: 88.0240%, Training Loss: 0.2947%\n",
      "Epoch [61/300], Step [168/225], Training Accuracy: 87.9929%, Training Loss: 0.2950%\n",
      "Epoch [61/300], Step [169/225], Training Accuracy: 87.9993%, Training Loss: 0.2949%\n",
      "Epoch [61/300], Step [170/225], Training Accuracy: 87.9779%, Training Loss: 0.2954%\n",
      "Epoch [61/300], Step [171/225], Training Accuracy: 87.9569%, Training Loss: 0.2960%\n",
      "Epoch [61/300], Step [172/225], Training Accuracy: 87.9633%, Training Loss: 0.2958%\n",
      "Epoch [61/300], Step [173/225], Training Accuracy: 87.9967%, Training Loss: 0.2955%\n",
      "Epoch [61/300], Step [174/225], Training Accuracy: 87.9939%, Training Loss: 0.2958%\n",
      "Epoch [61/300], Step [175/225], Training Accuracy: 88.0268%, Training Loss: 0.2954%\n",
      "Epoch [61/300], Step [176/225], Training Accuracy: 88.0327%, Training Loss: 0.2950%\n",
      "Epoch [61/300], Step [177/225], Training Accuracy: 88.0561%, Training Loss: 0.2944%\n",
      "Epoch [61/300], Step [178/225], Training Accuracy: 88.0618%, Training Loss: 0.2940%\n",
      "Epoch [61/300], Step [179/225], Training Accuracy: 88.0761%, Training Loss: 0.2934%\n",
      "Epoch [61/300], Step [180/225], Training Accuracy: 88.0816%, Training Loss: 0.2935%\n",
      "Epoch [61/300], Step [181/225], Training Accuracy: 88.0611%, Training Loss: 0.2938%\n",
      "Epoch [61/300], Step [182/225], Training Accuracy: 88.0580%, Training Loss: 0.2938%\n",
      "Epoch [61/300], Step [183/225], Training Accuracy: 88.0379%, Training Loss: 0.2940%\n",
      "Epoch [61/300], Step [184/225], Training Accuracy: 88.0605%, Training Loss: 0.2936%\n",
      "Epoch [61/300], Step [185/225], Training Accuracy: 88.0405%, Training Loss: 0.2935%\n",
      "Epoch [61/300], Step [186/225], Training Accuracy: 88.0124%, Training Loss: 0.2938%\n",
      "Epoch [61/300], Step [187/225], Training Accuracy: 88.0515%, Training Loss: 0.2933%\n",
      "Epoch [61/300], Step [188/225], Training Accuracy: 88.0818%, Training Loss: 0.2930%\n",
      "Epoch [61/300], Step [189/225], Training Accuracy: 88.1118%, Training Loss: 0.2930%\n",
      "Epoch [61/300], Step [190/225], Training Accuracy: 88.1414%, Training Loss: 0.2924%\n",
      "Epoch [61/300], Step [191/225], Training Accuracy: 88.1217%, Training Loss: 0.2930%\n",
      "Epoch [61/300], Step [192/225], Training Accuracy: 88.1510%, Training Loss: 0.2924%\n",
      "Epoch [61/300], Step [193/225], Training Accuracy: 88.1881%, Training Loss: 0.2922%\n",
      "Epoch [61/300], Step [194/225], Training Accuracy: 88.1846%, Training Loss: 0.2924%\n",
      "Epoch [61/300], Step [195/225], Training Accuracy: 88.2212%, Training Loss: 0.2918%\n",
      "Epoch [61/300], Step [196/225], Training Accuracy: 88.2095%, Training Loss: 0.2924%\n",
      "Epoch [61/300], Step [197/225], Training Accuracy: 88.2218%, Training Loss: 0.2919%\n",
      "Epoch [61/300], Step [198/225], Training Accuracy: 88.2260%, Training Loss: 0.2917%\n",
      "Epoch [61/300], Step [199/225], Training Accuracy: 88.1674%, Training Loss: 0.2927%\n",
      "Epoch [61/300], Step [200/225], Training Accuracy: 88.1484%, Training Loss: 0.2931%\n",
      "Epoch [61/300], Step [201/225], Training Accuracy: 88.1141%, Training Loss: 0.2940%\n",
      "Epoch [61/300], Step [202/225], Training Accuracy: 88.1420%, Training Loss: 0.2933%\n",
      "Epoch [61/300], Step [203/225], Training Accuracy: 88.1850%, Training Loss: 0.2927%\n",
      "Epoch [61/300], Step [204/225], Training Accuracy: 88.2200%, Training Loss: 0.2921%\n",
      "Epoch [61/300], Step [205/225], Training Accuracy: 88.1936%, Training Loss: 0.2925%\n",
      "Epoch [61/300], Step [206/225], Training Accuracy: 88.2054%, Training Loss: 0.2925%\n",
      "Epoch [61/300], Step [207/225], Training Accuracy: 88.2020%, Training Loss: 0.2924%\n",
      "Epoch [61/300], Step [208/225], Training Accuracy: 88.1986%, Training Loss: 0.2924%\n",
      "Epoch [61/300], Step [209/225], Training Accuracy: 88.1579%, Training Loss: 0.2928%\n",
      "Epoch [61/300], Step [210/225], Training Accuracy: 88.1548%, Training Loss: 0.2928%\n",
      "Epoch [61/300], Step [211/225], Training Accuracy: 88.1443%, Training Loss: 0.2928%\n",
      "Epoch [61/300], Step [212/225], Training Accuracy: 88.1412%, Training Loss: 0.2928%\n",
      "Epoch [61/300], Step [213/225], Training Accuracy: 88.1455%, Training Loss: 0.2930%\n",
      "Epoch [61/300], Step [214/225], Training Accuracy: 88.1498%, Training Loss: 0.2930%\n",
      "Epoch [61/300], Step [215/225], Training Accuracy: 88.1759%, Training Loss: 0.2925%\n",
      "Epoch [61/300], Step [216/225], Training Accuracy: 88.2017%, Training Loss: 0.2922%\n",
      "Epoch [61/300], Step [217/225], Training Accuracy: 88.1624%, Training Loss: 0.2926%\n",
      "Epoch [61/300], Step [218/225], Training Accuracy: 88.1522%, Training Loss: 0.2926%\n",
      "Epoch [61/300], Step [219/225], Training Accuracy: 88.1564%, Training Loss: 0.2925%\n",
      "Epoch [61/300], Step [220/225], Training Accuracy: 88.1676%, Training Loss: 0.2923%\n",
      "Epoch [61/300], Step [221/225], Training Accuracy: 88.1575%, Training Loss: 0.2922%\n",
      "Epoch [61/300], Step [222/225], Training Accuracy: 88.1475%, Training Loss: 0.2925%\n",
      "Epoch [61/300], Step [223/225], Training Accuracy: 88.1586%, Training Loss: 0.2923%\n",
      "Epoch [61/300], Step [224/225], Training Accuracy: 88.1627%, Training Loss: 0.2919%\n",
      "Epoch [61/300], Step [225/225], Training Accuracy: 88.1740%, Training Loss: 0.2917%\n",
      "Epoch [62/300], Step [1/225], Training Accuracy: 92.1875%, Training Loss: 0.2656%\n",
      "Epoch [62/300], Step [2/225], Training Accuracy: 90.6250%, Training Loss: 0.2374%\n",
      "Epoch [62/300], Step [3/225], Training Accuracy: 89.5833%, Training Loss: 0.2811%\n",
      "Epoch [62/300], Step [4/225], Training Accuracy: 89.4531%, Training Loss: 0.2811%\n",
      "Epoch [62/300], Step [5/225], Training Accuracy: 89.3750%, Training Loss: 0.2770%\n",
      "Epoch [62/300], Step [6/225], Training Accuracy: 89.8438%, Training Loss: 0.2628%\n",
      "Epoch [62/300], Step [7/225], Training Accuracy: 89.2857%, Training Loss: 0.2624%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/300], Step [8/225], Training Accuracy: 88.8672%, Training Loss: 0.2703%\n",
      "Epoch [62/300], Step [9/225], Training Accuracy: 89.7569%, Training Loss: 0.2623%\n",
      "Epoch [62/300], Step [10/225], Training Accuracy: 89.3750%, Training Loss: 0.2685%\n",
      "Epoch [62/300], Step [11/225], Training Accuracy: 88.0682%, Training Loss: 0.2764%\n",
      "Epoch [62/300], Step [12/225], Training Accuracy: 88.2812%, Training Loss: 0.2756%\n",
      "Epoch [62/300], Step [13/225], Training Accuracy: 88.2212%, Training Loss: 0.2717%\n",
      "Epoch [62/300], Step [14/225], Training Accuracy: 88.2812%, Training Loss: 0.2666%\n",
      "Epoch [62/300], Step [15/225], Training Accuracy: 88.3333%, Training Loss: 0.2674%\n",
      "Epoch [62/300], Step [16/225], Training Accuracy: 88.2812%, Training Loss: 0.2676%\n",
      "Epoch [62/300], Step [17/225], Training Accuracy: 88.1434%, Training Loss: 0.2706%\n",
      "Epoch [62/300], Step [18/225], Training Accuracy: 88.2812%, Training Loss: 0.2696%\n",
      "Epoch [62/300], Step [19/225], Training Accuracy: 88.4868%, Training Loss: 0.2653%\n",
      "Epoch [62/300], Step [20/225], Training Accuracy: 88.2031%, Training Loss: 0.2687%\n",
      "Epoch [62/300], Step [21/225], Training Accuracy: 88.3929%, Training Loss: 0.2665%\n",
      "Epoch [62/300], Step [22/225], Training Accuracy: 88.4943%, Training Loss: 0.2675%\n",
      "Epoch [62/300], Step [23/225], Training Accuracy: 88.7228%, Training Loss: 0.2661%\n",
      "Epoch [62/300], Step [24/225], Training Accuracy: 88.4766%, Training Loss: 0.2710%\n",
      "Epoch [62/300], Step [25/225], Training Accuracy: 88.6875%, Training Loss: 0.2666%\n",
      "Epoch [62/300], Step [26/225], Training Accuracy: 88.8221%, Training Loss: 0.2642%\n",
      "Epoch [62/300], Step [27/225], Training Accuracy: 88.8889%, Training Loss: 0.2627%\n",
      "Epoch [62/300], Step [28/225], Training Accuracy: 89.0067%, Training Loss: 0.2639%\n",
      "Epoch [62/300], Step [29/225], Training Accuracy: 89.1164%, Training Loss: 0.2627%\n",
      "Epoch [62/300], Step [30/225], Training Accuracy: 89.0625%, Training Loss: 0.2626%\n",
      "Epoch [62/300], Step [31/225], Training Accuracy: 89.0625%, Training Loss: 0.2643%\n",
      "Epoch [62/300], Step [32/225], Training Accuracy: 88.8672%, Training Loss: 0.2676%\n",
      "Epoch [62/300], Step [33/225], Training Accuracy: 88.6837%, Training Loss: 0.2715%\n",
      "Epoch [62/300], Step [34/225], Training Accuracy: 88.5110%, Training Loss: 0.2739%\n",
      "Epoch [62/300], Step [35/225], Training Accuracy: 88.6607%, Training Loss: 0.2716%\n",
      "Epoch [62/300], Step [36/225], Training Accuracy: 88.7587%, Training Loss: 0.2704%\n",
      "Epoch [62/300], Step [37/225], Training Accuracy: 88.8514%, Training Loss: 0.2677%\n",
      "Epoch [62/300], Step [38/225], Training Accuracy: 88.7336%, Training Loss: 0.2715%\n",
      "Epoch [62/300], Step [39/225], Training Accuracy: 88.7420%, Training Loss: 0.2713%\n",
      "Epoch [62/300], Step [40/225], Training Accuracy: 88.7891%, Training Loss: 0.2698%\n",
      "Epoch [62/300], Step [41/225], Training Accuracy: 88.7576%, Training Loss: 0.2744%\n",
      "Epoch [62/300], Step [42/225], Training Accuracy: 88.8021%, Training Loss: 0.2745%\n",
      "Epoch [62/300], Step [43/225], Training Accuracy: 88.8081%, Training Loss: 0.2751%\n",
      "Epoch [62/300], Step [44/225], Training Accuracy: 88.6719%, Training Loss: 0.2765%\n",
      "Epoch [62/300], Step [45/225], Training Accuracy: 88.7500%, Training Loss: 0.2748%\n",
      "Epoch [62/300], Step [46/225], Training Accuracy: 88.7228%, Training Loss: 0.2738%\n",
      "Epoch [62/300], Step [47/225], Training Accuracy: 88.6303%, Training Loss: 0.2760%\n",
      "Epoch [62/300], Step [48/225], Training Accuracy: 88.6393%, Training Loss: 0.2761%\n",
      "Epoch [62/300], Step [49/225], Training Accuracy: 88.8074%, Training Loss: 0.2736%\n",
      "Epoch [62/300], Step [50/225], Training Accuracy: 88.8438%, Training Loss: 0.2747%\n",
      "Epoch [62/300], Step [51/225], Training Accuracy: 88.8787%, Training Loss: 0.2732%\n",
      "Epoch [62/300], Step [52/225], Training Accuracy: 89.0325%, Training Loss: 0.2702%\n",
      "Epoch [62/300], Step [53/225], Training Accuracy: 89.0330%, Training Loss: 0.2697%\n",
      "Epoch [62/300], Step [54/225], Training Accuracy: 88.9178%, Training Loss: 0.2723%\n",
      "Epoch [62/300], Step [55/225], Training Accuracy: 88.8636%, Training Loss: 0.2732%\n",
      "Epoch [62/300], Step [56/225], Training Accuracy: 88.9230%, Training Loss: 0.2718%\n",
      "Epoch [62/300], Step [57/225], Training Accuracy: 88.8980%, Training Loss: 0.2718%\n",
      "Epoch [62/300], Step [58/225], Training Accuracy: 88.8739%, Training Loss: 0.2713%\n",
      "Epoch [62/300], Step [59/225], Training Accuracy: 88.8506%, Training Loss: 0.2712%\n",
      "Epoch [62/300], Step [60/225], Training Accuracy: 88.7500%, Training Loss: 0.2719%\n",
      "Epoch [62/300], Step [61/225], Training Accuracy: 88.8064%, Training Loss: 0.2719%\n",
      "Epoch [62/300], Step [62/225], Training Accuracy: 88.8609%, Training Loss: 0.2708%\n",
      "Epoch [62/300], Step [63/225], Training Accuracy: 88.7649%, Training Loss: 0.2750%\n",
      "Epoch [62/300], Step [64/225], Training Accuracy: 88.7207%, Training Loss: 0.2762%\n",
      "Epoch [62/300], Step [65/225], Training Accuracy: 88.6779%, Training Loss: 0.2769%\n",
      "Epoch [62/300], Step [66/225], Training Accuracy: 88.6127%, Training Loss: 0.2776%\n",
      "Epoch [62/300], Step [67/225], Training Accuracy: 88.6894%, Training Loss: 0.2759%\n",
      "Epoch [62/300], Step [68/225], Training Accuracy: 88.6949%, Training Loss: 0.2760%\n",
      "Epoch [62/300], Step [69/225], Training Accuracy: 88.6096%, Training Loss: 0.2777%\n",
      "Epoch [62/300], Step [70/225], Training Accuracy: 88.6830%, Training Loss: 0.2760%\n",
      "Epoch [62/300], Step [71/225], Training Accuracy: 88.7104%, Training Loss: 0.2754%\n",
      "Epoch [62/300], Step [72/225], Training Accuracy: 88.7587%, Training Loss: 0.2747%\n",
      "Epoch [62/300], Step [73/225], Training Accuracy: 88.7200%, Training Loss: 0.2766%\n",
      "Epoch [62/300], Step [74/225], Training Accuracy: 88.7035%, Training Loss: 0.2770%\n",
      "Epoch [62/300], Step [75/225], Training Accuracy: 88.6458%, Training Loss: 0.2777%\n",
      "Epoch [62/300], Step [76/225], Training Accuracy: 88.6513%, Training Loss: 0.2776%\n",
      "Epoch [62/300], Step [77/225], Training Accuracy: 88.6364%, Training Loss: 0.2777%\n",
      "Epoch [62/300], Step [78/225], Training Accuracy: 88.6418%, Training Loss: 0.2775%\n",
      "Epoch [62/300], Step [79/225], Training Accuracy: 88.6472%, Training Loss: 0.2765%\n",
      "Epoch [62/300], Step [80/225], Training Accuracy: 88.6133%, Training Loss: 0.2774%\n",
      "Epoch [62/300], Step [81/225], Training Accuracy: 88.6381%, Training Loss: 0.2776%\n",
      "Epoch [62/300], Step [82/225], Training Accuracy: 88.6623%, Training Loss: 0.2765%\n",
      "Epoch [62/300], Step [83/225], Training Accuracy: 88.6860%, Training Loss: 0.2761%\n",
      "Epoch [62/300], Step [84/225], Training Accuracy: 88.7091%, Training Loss: 0.2751%\n",
      "Epoch [62/300], Step [85/225], Training Accuracy: 88.6765%, Training Loss: 0.2758%\n",
      "Epoch [62/300], Step [86/225], Training Accuracy: 88.6628%, Training Loss: 0.2755%\n",
      "Epoch [62/300], Step [87/225], Training Accuracy: 88.6494%, Training Loss: 0.2763%\n",
      "Epoch [62/300], Step [88/225], Training Accuracy: 88.5121%, Training Loss: 0.2788%\n",
      "Epoch [62/300], Step [89/225], Training Accuracy: 88.5007%, Training Loss: 0.2790%\n",
      "Epoch [62/300], Step [90/225], Training Accuracy: 88.4375%, Training Loss: 0.2803%\n",
      "Epoch [62/300], Step [91/225], Training Accuracy: 88.4615%, Training Loss: 0.2796%\n",
      "Epoch [62/300], Step [92/225], Training Accuracy: 88.4341%, Training Loss: 0.2797%\n",
      "Epoch [62/300], Step [93/225], Training Accuracy: 88.4745%, Training Loss: 0.2799%\n",
      "Epoch [62/300], Step [94/225], Training Accuracy: 88.4807%, Training Loss: 0.2797%\n",
      "Epoch [62/300], Step [95/225], Training Accuracy: 88.4704%, Training Loss: 0.2797%\n",
      "Epoch [62/300], Step [96/225], Training Accuracy: 88.5254%, Training Loss: 0.2788%\n",
      "Epoch [62/300], Step [97/225], Training Accuracy: 88.4665%, Training Loss: 0.2787%\n",
      "Epoch [62/300], Step [98/225], Training Accuracy: 88.4726%, Training Loss: 0.2784%\n",
      "Epoch [62/300], Step [99/225], Training Accuracy: 88.4785%, Training Loss: 0.2778%\n",
      "Epoch [62/300], Step [100/225], Training Accuracy: 88.3906%, Training Loss: 0.2800%\n",
      "Epoch [62/300], Step [101/225], Training Accuracy: 88.2890%, Training Loss: 0.2814%\n",
      "Epoch [62/300], Step [102/225], Training Accuracy: 88.3578%, Training Loss: 0.2808%\n",
      "Epoch [62/300], Step [103/225], Training Accuracy: 88.3950%, Training Loss: 0.2800%\n",
      "Epoch [62/300], Step [104/225], Training Accuracy: 88.4014%, Training Loss: 0.2796%\n",
      "Epoch [62/300], Step [105/225], Training Accuracy: 88.4077%, Training Loss: 0.2791%\n",
      "Epoch [62/300], Step [106/225], Training Accuracy: 88.3402%, Training Loss: 0.2801%\n",
      "Epoch [62/300], Step [107/225], Training Accuracy: 88.3178%, Training Loss: 0.2811%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/300], Step [108/225], Training Accuracy: 88.3247%, Training Loss: 0.2808%\n",
      "Epoch [62/300], Step [109/225], Training Accuracy: 88.3458%, Training Loss: 0.2806%\n",
      "Epoch [62/300], Step [110/225], Training Accuracy: 88.3097%, Training Loss: 0.2806%\n",
      "Epoch [62/300], Step [111/225], Training Accuracy: 88.3164%, Training Loss: 0.2802%\n",
      "Epoch [62/300], Step [112/225], Training Accuracy: 88.2952%, Training Loss: 0.2808%\n",
      "Epoch [62/300], Step [113/225], Training Accuracy: 88.3435%, Training Loss: 0.2799%\n",
      "Epoch [62/300], Step [114/225], Training Accuracy: 88.3498%, Training Loss: 0.2801%\n",
      "Epoch [62/300], Step [115/225], Training Accuracy: 88.3967%, Training Loss: 0.2790%\n",
      "Epoch [62/300], Step [116/225], Training Accuracy: 88.3890%, Training Loss: 0.2797%\n",
      "Epoch [62/300], Step [117/225], Training Accuracy: 88.3948%, Training Loss: 0.2800%\n",
      "Epoch [62/300], Step [118/225], Training Accuracy: 88.3475%, Training Loss: 0.2808%\n",
      "Epoch [62/300], Step [119/225], Training Accuracy: 88.3272%, Training Loss: 0.2809%\n",
      "Epoch [62/300], Step [120/225], Training Accuracy: 88.3203%, Training Loss: 0.2809%\n",
      "Epoch [62/300], Step [121/225], Training Accuracy: 88.2748%, Training Loss: 0.2813%\n",
      "Epoch [62/300], Step [122/225], Training Accuracy: 88.2684%, Training Loss: 0.2815%\n",
      "Epoch [62/300], Step [123/225], Training Accuracy: 88.2749%, Training Loss: 0.2819%\n",
      "Epoch [62/300], Step [124/225], Training Accuracy: 88.3065%, Training Loss: 0.2812%\n",
      "Epoch [62/300], Step [125/225], Training Accuracy: 88.3000%, Training Loss: 0.2815%\n",
      "Epoch [62/300], Step [126/225], Training Accuracy: 88.3185%, Training Loss: 0.2814%\n",
      "Epoch [62/300], Step [127/225], Training Accuracy: 88.2997%, Training Loss: 0.2815%\n",
      "Epoch [62/300], Step [128/225], Training Accuracy: 88.3057%, Training Loss: 0.2813%\n",
      "Epoch [62/300], Step [129/225], Training Accuracy: 88.3479%, Training Loss: 0.2807%\n",
      "Epoch [62/300], Step [130/225], Training Accuracy: 88.3053%, Training Loss: 0.2811%\n",
      "Epoch [62/300], Step [131/225], Training Accuracy: 88.3111%, Training Loss: 0.2813%\n",
      "Epoch [62/300], Step [132/225], Training Accuracy: 88.2931%, Training Loss: 0.2816%\n",
      "Epoch [62/300], Step [133/225], Training Accuracy: 88.2754%, Training Loss: 0.2822%\n",
      "Epoch [62/300], Step [134/225], Training Accuracy: 88.2229%, Training Loss: 0.2832%\n",
      "Epoch [62/300], Step [135/225], Training Accuracy: 88.2292%, Training Loss: 0.2827%\n",
      "Epoch [62/300], Step [136/225], Training Accuracy: 88.2008%, Training Loss: 0.2837%\n",
      "Epoch [62/300], Step [137/225], Training Accuracy: 88.1615%, Training Loss: 0.2841%\n",
      "Epoch [62/300], Step [138/225], Training Accuracy: 88.1793%, Training Loss: 0.2838%\n",
      "Epoch [62/300], Step [139/225], Training Accuracy: 88.1969%, Training Loss: 0.2837%\n",
      "Epoch [62/300], Step [140/225], Training Accuracy: 88.2143%, Training Loss: 0.2834%\n",
      "Epoch [62/300], Step [141/225], Training Accuracy: 88.2425%, Training Loss: 0.2831%\n",
      "Epoch [62/300], Step [142/225], Training Accuracy: 88.2482%, Training Loss: 0.2829%\n",
      "Epoch [62/300], Step [143/225], Training Accuracy: 88.2212%, Training Loss: 0.2836%\n",
      "Epoch [62/300], Step [144/225], Training Accuracy: 88.1836%, Training Loss: 0.2842%\n",
      "Epoch [62/300], Step [145/225], Training Accuracy: 88.1358%, Training Loss: 0.2845%\n",
      "Epoch [62/300], Step [146/225], Training Accuracy: 88.1421%, Training Loss: 0.2845%\n",
      "Epoch [62/300], Step [147/225], Training Accuracy: 88.1696%, Training Loss: 0.2845%\n",
      "Epoch [62/300], Step [148/225], Training Accuracy: 88.2073%, Training Loss: 0.2842%\n",
      "Epoch [62/300], Step [149/225], Training Accuracy: 88.2236%, Training Loss: 0.2837%\n",
      "Epoch [62/300], Step [150/225], Training Accuracy: 88.2708%, Training Loss: 0.2828%\n",
      "Epoch [62/300], Step [151/225], Training Accuracy: 88.2554%, Training Loss: 0.2826%\n",
      "Epoch [62/300], Step [152/225], Training Accuracy: 88.2915%, Training Loss: 0.2819%\n",
      "Epoch [62/300], Step [153/225], Training Accuracy: 88.2864%, Training Loss: 0.2819%\n",
      "Epoch [62/300], Step [154/225], Training Accuracy: 88.2711%, Training Loss: 0.2818%\n",
      "Epoch [62/300], Step [155/225], Training Accuracy: 88.2863%, Training Loss: 0.2815%\n",
      "Epoch [62/300], Step [156/225], Training Accuracy: 88.2812%, Training Loss: 0.2816%\n",
      "Epoch [62/300], Step [157/225], Training Accuracy: 88.2862%, Training Loss: 0.2815%\n",
      "Epoch [62/300], Step [158/225], Training Accuracy: 88.3208%, Training Loss: 0.2813%\n",
      "Epoch [62/300], Step [159/225], Training Accuracy: 88.3353%, Training Loss: 0.2817%\n",
      "Epoch [62/300], Step [160/225], Training Accuracy: 88.3594%, Training Loss: 0.2811%\n",
      "Epoch [62/300], Step [161/225], Training Accuracy: 88.3540%, Training Loss: 0.2816%\n",
      "Epoch [62/300], Step [162/225], Training Accuracy: 88.3584%, Training Loss: 0.2815%\n",
      "Epoch [62/300], Step [163/225], Training Accuracy: 88.3723%, Training Loss: 0.2812%\n",
      "Epoch [62/300], Step [164/225], Training Accuracy: 88.3861%, Training Loss: 0.2812%\n",
      "Epoch [62/300], Step [165/225], Training Accuracy: 88.3144%, Training Loss: 0.2824%\n",
      "Epoch [62/300], Step [166/225], Training Accuracy: 88.3566%, Training Loss: 0.2818%\n",
      "Epoch [62/300], Step [167/225], Training Accuracy: 88.3701%, Training Loss: 0.2816%\n",
      "Epoch [62/300], Step [168/225], Training Accuracy: 88.3836%, Training Loss: 0.2815%\n",
      "Epoch [62/300], Step [169/225], Training Accuracy: 88.3598%, Training Loss: 0.2820%\n",
      "Epoch [62/300], Step [170/225], Training Accuracy: 88.3732%, Training Loss: 0.2820%\n",
      "Epoch [62/300], Step [171/225], Training Accuracy: 88.3589%, Training Loss: 0.2826%\n",
      "Epoch [62/300], Step [172/225], Training Accuracy: 88.3267%, Training Loss: 0.2831%\n",
      "Epoch [62/300], Step [173/225], Training Accuracy: 88.3219%, Training Loss: 0.2830%\n",
      "Epoch [62/300], Step [174/225], Training Accuracy: 88.3261%, Training Loss: 0.2833%\n",
      "Epoch [62/300], Step [175/225], Training Accuracy: 88.3125%, Training Loss: 0.2837%\n",
      "Epoch [62/300], Step [176/225], Training Accuracy: 88.3256%, Training Loss: 0.2835%\n",
      "Epoch [62/300], Step [177/225], Training Accuracy: 88.3121%, Training Loss: 0.2835%\n",
      "Epoch [62/300], Step [178/225], Training Accuracy: 88.3251%, Training Loss: 0.2833%\n",
      "Epoch [62/300], Step [179/225], Training Accuracy: 88.3380%, Training Loss: 0.2830%\n",
      "Epoch [62/300], Step [180/225], Training Accuracy: 88.3681%, Training Loss: 0.2823%\n",
      "Epoch [62/300], Step [181/225], Training Accuracy: 88.3115%, Training Loss: 0.2831%\n",
      "Epoch [62/300], Step [182/225], Training Accuracy: 88.3328%, Training Loss: 0.2826%\n",
      "Epoch [62/300], Step [183/225], Training Accuracy: 88.3111%, Training Loss: 0.2828%\n",
      "Epoch [62/300], Step [184/225], Training Accuracy: 88.3237%, Training Loss: 0.2826%\n",
      "Epoch [62/300], Step [185/225], Training Accuracy: 88.3193%, Training Loss: 0.2829%\n",
      "Epoch [62/300], Step [186/225], Training Accuracy: 88.3401%, Training Loss: 0.2824%\n",
      "Epoch [62/300], Step [187/225], Training Accuracy: 88.3773%, Training Loss: 0.2817%\n",
      "Epoch [62/300], Step [188/225], Training Accuracy: 88.3893%, Training Loss: 0.2812%\n",
      "Epoch [62/300], Step [189/225], Training Accuracy: 88.4259%, Training Loss: 0.2805%\n",
      "Epoch [62/300], Step [190/225], Training Accuracy: 88.4457%, Training Loss: 0.2802%\n",
      "Epoch [62/300], Step [191/225], Training Accuracy: 88.4326%, Training Loss: 0.2805%\n",
      "Epoch [62/300], Step [192/225], Training Accuracy: 88.4440%, Training Loss: 0.2804%\n",
      "Epoch [62/300], Step [193/225], Training Accuracy: 88.4391%, Training Loss: 0.2804%\n",
      "Epoch [62/300], Step [194/225], Training Accuracy: 88.4343%, Training Loss: 0.2808%\n",
      "Epoch [62/300], Step [195/225], Training Accuracy: 88.4535%, Training Loss: 0.2804%\n",
      "Epoch [62/300], Step [196/225], Training Accuracy: 88.4247%, Training Loss: 0.2809%\n",
      "Epoch [62/300], Step [197/225], Training Accuracy: 88.4359%, Training Loss: 0.2807%\n",
      "Epoch [62/300], Step [198/225], Training Accuracy: 88.4391%, Training Loss: 0.2804%\n",
      "Epoch [62/300], Step [199/225], Training Accuracy: 88.4187%, Training Loss: 0.2804%\n",
      "Epoch [62/300], Step [200/225], Training Accuracy: 88.4375%, Training Loss: 0.2801%\n",
      "Epoch [62/300], Step [201/225], Training Accuracy: 88.4406%, Training Loss: 0.2801%\n",
      "Epoch [62/300], Step [202/225], Training Accuracy: 88.4514%, Training Loss: 0.2797%\n",
      "Epoch [62/300], Step [203/225], Training Accuracy: 88.4698%, Training Loss: 0.2793%\n",
      "Epoch [62/300], Step [204/225], Training Accuracy: 88.4727%, Training Loss: 0.2793%\n",
      "Epoch [62/300], Step [205/225], Training Accuracy: 88.4756%, Training Loss: 0.2797%\n",
      "Epoch [62/300], Step [206/225], Training Accuracy: 88.4860%, Training Loss: 0.2798%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/300], Step [207/225], Training Accuracy: 88.4737%, Training Loss: 0.2801%\n",
      "Epoch [62/300], Step [208/225], Training Accuracy: 88.4991%, Training Loss: 0.2799%\n",
      "Epoch [62/300], Step [209/225], Training Accuracy: 88.4719%, Training Loss: 0.2802%\n",
      "Epoch [62/300], Step [210/225], Training Accuracy: 88.4821%, Training Loss: 0.2801%\n",
      "Epoch [62/300], Step [211/225], Training Accuracy: 88.4775%, Training Loss: 0.2805%\n",
      "Epoch [62/300], Step [212/225], Training Accuracy: 88.4950%, Training Loss: 0.2803%\n",
      "Epoch [62/300], Step [213/225], Training Accuracy: 88.4977%, Training Loss: 0.2805%\n",
      "Epoch [62/300], Step [214/225], Training Accuracy: 88.5076%, Training Loss: 0.2801%\n",
      "Epoch [62/300], Step [215/225], Training Accuracy: 88.5247%, Training Loss: 0.2799%\n",
      "Epoch [62/300], Step [216/225], Training Accuracy: 88.5344%, Training Loss: 0.2800%\n",
      "Epoch [62/300], Step [217/225], Training Accuracy: 88.5441%, Training Loss: 0.2801%\n",
      "Epoch [62/300], Step [218/225], Training Accuracy: 88.5608%, Training Loss: 0.2798%\n",
      "Epoch [62/300], Step [219/225], Training Accuracy: 88.5488%, Training Loss: 0.2796%\n",
      "Epoch [62/300], Step [220/225], Training Accuracy: 88.5653%, Training Loss: 0.2793%\n",
      "Epoch [62/300], Step [221/225], Training Accuracy: 88.5747%, Training Loss: 0.2792%\n",
      "Epoch [62/300], Step [222/225], Training Accuracy: 88.5909%, Training Loss: 0.2794%\n",
      "Epoch [62/300], Step [223/225], Training Accuracy: 88.5720%, Training Loss: 0.2795%\n",
      "Epoch [62/300], Step [224/225], Training Accuracy: 88.5882%, Training Loss: 0.2792%\n",
      "Epoch [62/300], Step [225/225], Training Accuracy: 88.5978%, Training Loss: 0.2788%\n",
      "Epoch [63/300], Step [1/225], Training Accuracy: 89.0625%, Training Loss: 0.2284%\n",
      "Epoch [63/300], Step [2/225], Training Accuracy: 90.6250%, Training Loss: 0.2309%\n",
      "Epoch [63/300], Step [3/225], Training Accuracy: 90.6250%, Training Loss: 0.2489%\n",
      "Epoch [63/300], Step [4/225], Training Accuracy: 89.4531%, Training Loss: 0.2857%\n",
      "Epoch [63/300], Step [5/225], Training Accuracy: 90.0000%, Training Loss: 0.2703%\n",
      "Epoch [63/300], Step [6/225], Training Accuracy: 88.8021%, Training Loss: 0.2727%\n",
      "Epoch [63/300], Step [7/225], Training Accuracy: 88.6161%, Training Loss: 0.2809%\n",
      "Epoch [63/300], Step [8/225], Training Accuracy: 87.8906%, Training Loss: 0.3280%\n",
      "Epoch [63/300], Step [9/225], Training Accuracy: 88.0208%, Training Loss: 0.3207%\n",
      "Epoch [63/300], Step [10/225], Training Accuracy: 87.8125%, Training Loss: 0.3296%\n",
      "Epoch [63/300], Step [11/225], Training Accuracy: 87.3580%, Training Loss: 0.3334%\n",
      "Epoch [63/300], Step [12/225], Training Accuracy: 87.5000%, Training Loss: 0.3248%\n",
      "Epoch [63/300], Step [13/225], Training Accuracy: 88.1010%, Training Loss: 0.3136%\n",
      "Epoch [63/300], Step [14/225], Training Accuracy: 88.2812%, Training Loss: 0.3146%\n",
      "Epoch [63/300], Step [15/225], Training Accuracy: 88.3333%, Training Loss: 0.3117%\n",
      "Epoch [63/300], Step [16/225], Training Accuracy: 88.3789%, Training Loss: 0.3153%\n",
      "Epoch [63/300], Step [17/225], Training Accuracy: 88.6029%, Training Loss: 0.3083%\n",
      "Epoch [63/300], Step [18/225], Training Accuracy: 88.4549%, Training Loss: 0.3078%\n",
      "Epoch [63/300], Step [19/225], Training Accuracy: 88.4046%, Training Loss: 0.3066%\n",
      "Epoch [63/300], Step [20/225], Training Accuracy: 88.5938%, Training Loss: 0.3041%\n",
      "Epoch [63/300], Step [21/225], Training Accuracy: 88.6905%, Training Loss: 0.2989%\n",
      "Epoch [63/300], Step [22/225], Training Accuracy: 88.7074%, Training Loss: 0.2977%\n",
      "Epoch [63/300], Step [23/225], Training Accuracy: 88.5190%, Training Loss: 0.2993%\n",
      "Epoch [63/300], Step [24/225], Training Accuracy: 88.6068%, Training Loss: 0.2963%\n",
      "Epoch [63/300], Step [25/225], Training Accuracy: 88.9375%, Training Loss: 0.2903%\n",
      "Epoch [63/300], Step [26/225], Training Accuracy: 89.0625%, Training Loss: 0.2885%\n",
      "Epoch [63/300], Step [27/225], Training Accuracy: 89.3519%, Training Loss: 0.2853%\n",
      "Epoch [63/300], Step [28/225], Training Accuracy: 89.5089%, Training Loss: 0.2826%\n",
      "Epoch [63/300], Step [29/225], Training Accuracy: 89.5474%, Training Loss: 0.2811%\n",
      "Epoch [63/300], Step [30/225], Training Accuracy: 89.5833%, Training Loss: 0.2810%\n",
      "Epoch [63/300], Step [31/225], Training Accuracy: 89.2641%, Training Loss: 0.2897%\n",
      "Epoch [63/300], Step [32/225], Training Accuracy: 89.4043%, Training Loss: 0.2860%\n",
      "Epoch [63/300], Step [33/225], Training Accuracy: 89.3939%, Training Loss: 0.2845%\n",
      "Epoch [63/300], Step [34/225], Training Accuracy: 89.1085%, Training Loss: 0.2911%\n",
      "Epoch [63/300], Step [35/225], Training Accuracy: 88.7500%, Training Loss: 0.2947%\n",
      "Epoch [63/300], Step [36/225], Training Accuracy: 88.8021%, Training Loss: 0.2943%\n",
      "Epoch [63/300], Step [37/225], Training Accuracy: 88.8091%, Training Loss: 0.2943%\n",
      "Epoch [63/300], Step [38/225], Training Accuracy: 88.6924%, Training Loss: 0.2948%\n",
      "Epoch [63/300], Step [39/225], Training Accuracy: 88.7821%, Training Loss: 0.2934%\n",
      "Epoch [63/300], Step [40/225], Training Accuracy: 88.7500%, Training Loss: 0.2957%\n",
      "Epoch [63/300], Step [41/225], Training Accuracy: 88.6814%, Training Loss: 0.3002%\n",
      "Epoch [63/300], Step [42/225], Training Accuracy: 88.7649%, Training Loss: 0.2983%\n",
      "Epoch [63/300], Step [43/225], Training Accuracy: 88.6265%, Training Loss: 0.3020%\n",
      "Epoch [63/300], Step [44/225], Training Accuracy: 88.4943%, Training Loss: 0.3034%\n",
      "Epoch [63/300], Step [45/225], Training Accuracy: 88.5417%, Training Loss: 0.3014%\n",
      "Epoch [63/300], Step [46/225], Training Accuracy: 88.5870%, Training Loss: 0.2986%\n",
      "Epoch [63/300], Step [47/225], Training Accuracy: 88.3976%, Training Loss: 0.3010%\n",
      "Epoch [63/300], Step [48/225], Training Accuracy: 88.2487%, Training Loss: 0.3031%\n",
      "Epoch [63/300], Step [49/225], Training Accuracy: 88.3291%, Training Loss: 0.3014%\n",
      "Epoch [63/300], Step [50/225], Training Accuracy: 88.2812%, Training Loss: 0.3019%\n",
      "Epoch [63/300], Step [51/225], Training Accuracy: 88.3578%, Training Loss: 0.3001%\n",
      "Epoch [63/300], Step [52/225], Training Accuracy: 88.4615%, Training Loss: 0.2979%\n",
      "Epoch [63/300], Step [53/225], Training Accuracy: 88.4434%, Training Loss: 0.2981%\n",
      "Epoch [63/300], Step [54/225], Training Accuracy: 88.3681%, Training Loss: 0.2989%\n",
      "Epoch [63/300], Step [55/225], Training Accuracy: 88.2670%, Training Loss: 0.3018%\n",
      "Epoch [63/300], Step [56/225], Training Accuracy: 88.2533%, Training Loss: 0.3014%\n",
      "Epoch [63/300], Step [57/225], Training Accuracy: 88.2950%, Training Loss: 0.3021%\n",
      "Epoch [63/300], Step [58/225], Training Accuracy: 88.2812%, Training Loss: 0.3029%\n",
      "Epoch [63/300], Step [59/225], Training Accuracy: 88.2150%, Training Loss: 0.3045%\n",
      "Epoch [63/300], Step [60/225], Training Accuracy: 88.3333%, Training Loss: 0.3033%\n",
      "Epoch [63/300], Step [61/225], Training Accuracy: 88.3453%, Training Loss: 0.3021%\n",
      "Epoch [63/300], Step [62/225], Training Accuracy: 88.3317%, Training Loss: 0.3017%\n",
      "Epoch [63/300], Step [63/225], Training Accuracy: 88.3433%, Training Loss: 0.3008%\n",
      "Epoch [63/300], Step [64/225], Training Accuracy: 88.3545%, Training Loss: 0.3012%\n",
      "Epoch [63/300], Step [65/225], Training Accuracy: 88.3413%, Training Loss: 0.3002%\n",
      "Epoch [63/300], Step [66/225], Training Accuracy: 88.3049%, Training Loss: 0.2994%\n",
      "Epoch [63/300], Step [67/225], Training Accuracy: 88.3396%, Training Loss: 0.2986%\n",
      "Epoch [63/300], Step [68/225], Training Accuracy: 88.3272%, Training Loss: 0.2989%\n",
      "Epoch [63/300], Step [69/225], Training Accuracy: 88.3605%, Training Loss: 0.2980%\n",
      "Epoch [63/300], Step [70/225], Training Accuracy: 88.3929%, Training Loss: 0.2986%\n",
      "Epoch [63/300], Step [71/225], Training Accuracy: 88.4243%, Training Loss: 0.2979%\n",
      "Epoch [63/300], Step [72/225], Training Accuracy: 88.4983%, Training Loss: 0.2962%\n",
      "Epoch [63/300], Step [73/225], Training Accuracy: 88.4418%, Training Loss: 0.2968%\n",
      "Epoch [63/300], Step [74/225], Training Accuracy: 88.5135%, Training Loss: 0.2959%\n",
      "Epoch [63/300], Step [75/225], Training Accuracy: 88.5000%, Training Loss: 0.2961%\n",
      "Epoch [63/300], Step [76/225], Training Accuracy: 88.3840%, Training Loss: 0.2981%\n",
      "Epoch [63/300], Step [77/225], Training Accuracy: 88.3726%, Training Loss: 0.2988%\n",
      "Epoch [63/300], Step [78/225], Training Accuracy: 88.4415%, Training Loss: 0.2979%\n",
      "Epoch [63/300], Step [79/225], Training Accuracy: 88.4691%, Training Loss: 0.2970%\n",
      "Epoch [63/300], Step [80/225], Training Accuracy: 88.3789%, Training Loss: 0.2984%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/300], Step [81/225], Training Accuracy: 88.3873%, Training Loss: 0.2970%\n",
      "Epoch [63/300], Step [82/225], Training Accuracy: 88.3384%, Training Loss: 0.2971%\n",
      "Epoch [63/300], Step [83/225], Training Accuracy: 88.2907%, Training Loss: 0.2969%\n",
      "Epoch [63/300], Step [84/225], Training Accuracy: 88.3371%, Training Loss: 0.2962%\n",
      "Epoch [63/300], Step [85/225], Training Accuracy: 88.3824%, Training Loss: 0.2953%\n",
      "Epoch [63/300], Step [86/225], Training Accuracy: 88.4448%, Training Loss: 0.2937%\n",
      "Epoch [63/300], Step [87/225], Training Accuracy: 88.3800%, Training Loss: 0.2958%\n",
      "Epoch [63/300], Step [88/225], Training Accuracy: 88.2635%, Training Loss: 0.2979%\n",
      "Epoch [63/300], Step [89/225], Training Accuracy: 88.3076%, Training Loss: 0.2973%\n",
      "Epoch [63/300], Step [90/225], Training Accuracy: 88.3160%, Training Loss: 0.2983%\n",
      "Epoch [63/300], Step [91/225], Training Accuracy: 88.3929%, Training Loss: 0.2969%\n",
      "Epoch [63/300], Step [92/225], Training Accuracy: 88.3492%, Training Loss: 0.2976%\n",
      "Epoch [63/300], Step [93/225], Training Accuracy: 88.3569%, Training Loss: 0.2970%\n",
      "Epoch [63/300], Step [94/225], Training Accuracy: 88.4142%, Training Loss: 0.2963%\n",
      "Epoch [63/300], Step [95/225], Training Accuracy: 88.4539%, Training Loss: 0.2953%\n",
      "Epoch [63/300], Step [96/225], Training Accuracy: 88.5091%, Training Loss: 0.2942%\n",
      "Epoch [63/300], Step [97/225], Training Accuracy: 88.5309%, Training Loss: 0.2941%\n",
      "Epoch [63/300], Step [98/225], Training Accuracy: 88.5364%, Training Loss: 0.2935%\n",
      "Epoch [63/300], Step [99/225], Training Accuracy: 88.5417%, Training Loss: 0.2933%\n",
      "Epoch [63/300], Step [100/225], Training Accuracy: 88.5000%, Training Loss: 0.2937%\n",
      "Epoch [63/300], Step [101/225], Training Accuracy: 88.5056%, Training Loss: 0.2932%\n",
      "Epoch [63/300], Step [102/225], Training Accuracy: 88.4651%, Training Loss: 0.2936%\n",
      "Epoch [63/300], Step [103/225], Training Accuracy: 88.5316%, Training Loss: 0.2922%\n",
      "Epoch [63/300], Step [104/225], Training Accuracy: 88.4916%, Training Loss: 0.2917%\n",
      "Epoch [63/300], Step [105/225], Training Accuracy: 88.4970%, Training Loss: 0.2917%\n",
      "Epoch [63/300], Step [106/225], Training Accuracy: 88.4287%, Training Loss: 0.2924%\n",
      "Epoch [63/300], Step [107/225], Training Accuracy: 88.4346%, Training Loss: 0.2921%\n",
      "Epoch [63/300], Step [108/225], Training Accuracy: 88.4404%, Training Loss: 0.2913%\n",
      "Epoch [63/300], Step [109/225], Training Accuracy: 88.3744%, Training Loss: 0.2918%\n",
      "Epoch [63/300], Step [110/225], Training Accuracy: 88.3807%, Training Loss: 0.2917%\n",
      "Epoch [63/300], Step [111/225], Training Accuracy: 88.3868%, Training Loss: 0.2914%\n",
      "Epoch [63/300], Step [112/225], Training Accuracy: 88.3789%, Training Loss: 0.2911%\n",
      "Epoch [63/300], Step [113/225], Training Accuracy: 88.3435%, Training Loss: 0.2911%\n",
      "Epoch [63/300], Step [114/225], Training Accuracy: 88.3498%, Training Loss: 0.2913%\n",
      "Epoch [63/300], Step [115/225], Training Accuracy: 88.3696%, Training Loss: 0.2912%\n",
      "Epoch [63/300], Step [116/225], Training Accuracy: 88.3755%, Training Loss: 0.2910%\n",
      "Epoch [63/300], Step [117/225], Training Accuracy: 88.3547%, Training Loss: 0.2914%\n",
      "Epoch [63/300], Step [118/225], Training Accuracy: 88.3872%, Training Loss: 0.2911%\n",
      "Epoch [63/300], Step [119/225], Training Accuracy: 88.3797%, Training Loss: 0.2906%\n",
      "Epoch [63/300], Step [120/225], Training Accuracy: 88.3464%, Training Loss: 0.2909%\n",
      "Epoch [63/300], Step [121/225], Training Accuracy: 88.3652%, Training Loss: 0.2903%\n",
      "Epoch [63/300], Step [122/225], Training Accuracy: 88.3325%, Training Loss: 0.2910%\n",
      "Epoch [63/300], Step [123/225], Training Accuracy: 88.3384%, Training Loss: 0.2909%\n",
      "Epoch [63/300], Step [124/225], Training Accuracy: 88.3065%, Training Loss: 0.2908%\n",
      "Epoch [63/300], Step [125/225], Training Accuracy: 88.2875%, Training Loss: 0.2917%\n",
      "Epoch [63/300], Step [126/225], Training Accuracy: 88.2937%, Training Loss: 0.2917%\n",
      "Epoch [63/300], Step [127/225], Training Accuracy: 88.3243%, Training Loss: 0.2909%\n",
      "Epoch [63/300], Step [128/225], Training Accuracy: 88.3545%, Training Loss: 0.2901%\n",
      "Epoch [63/300], Step [129/225], Training Accuracy: 88.3600%, Training Loss: 0.2898%\n",
      "Epoch [63/300], Step [130/225], Training Accuracy: 88.3534%, Training Loss: 0.2897%\n",
      "Epoch [63/300], Step [131/225], Training Accuracy: 88.3469%, Training Loss: 0.2898%\n",
      "Epoch [63/300], Step [132/225], Training Accuracy: 88.3404%, Training Loss: 0.2895%\n",
      "Epoch [63/300], Step [133/225], Training Accuracy: 88.3224%, Training Loss: 0.2900%\n",
      "Epoch [63/300], Step [134/225], Training Accuracy: 88.2579%, Training Loss: 0.2909%\n",
      "Epoch [63/300], Step [135/225], Training Accuracy: 88.2755%, Training Loss: 0.2907%\n",
      "Epoch [63/300], Step [136/225], Training Accuracy: 88.2583%, Training Loss: 0.2909%\n",
      "Epoch [63/300], Step [137/225], Training Accuracy: 88.2984%, Training Loss: 0.2901%\n",
      "Epoch [63/300], Step [138/225], Training Accuracy: 88.3265%, Training Loss: 0.2895%\n",
      "Epoch [63/300], Step [139/225], Training Accuracy: 88.3318%, Training Loss: 0.2890%\n",
      "Epoch [63/300], Step [140/225], Training Accuracy: 88.3594%, Training Loss: 0.2884%\n",
      "Epoch [63/300], Step [141/225], Training Accuracy: 88.3422%, Training Loss: 0.2883%\n",
      "Epoch [63/300], Step [142/225], Training Accuracy: 88.3253%, Training Loss: 0.2880%\n",
      "Epoch [63/300], Step [143/225], Training Accuracy: 88.3413%, Training Loss: 0.2878%\n",
      "Epoch [63/300], Step [144/225], Training Accuracy: 88.3681%, Training Loss: 0.2874%\n",
      "Epoch [63/300], Step [145/225], Training Accuracy: 88.3728%, Training Loss: 0.2871%\n",
      "Epoch [63/300], Step [146/225], Training Accuracy: 88.3669%, Training Loss: 0.2870%\n",
      "Epoch [63/300], Step [147/225], Training Accuracy: 88.3822%, Training Loss: 0.2872%\n",
      "Epoch [63/300], Step [148/225], Training Accuracy: 88.3552%, Training Loss: 0.2876%\n",
      "Epoch [63/300], Step [149/225], Training Accuracy: 88.4018%, Training Loss: 0.2869%\n",
      "Epoch [63/300], Step [150/225], Training Accuracy: 88.4375%, Training Loss: 0.2860%\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    correct=0\n",
    "    total=0\n",
    "    running_loss = 0\n",
    "    for i, (X, Y) in enumerate(train_loader):\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, Y)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        #scheduler.step() \n",
    "        #print(scheduler.get_last_lr()[0])\n",
    "      \n",
    "        optimizer.step()\n",
    "        scheduler.step() \n",
    "        #print(optimizer.param_groups[0][\"lr\"])\n",
    "        \n",
    "        _, predicted = outputs.max(1)\n",
    "        total += Y.size(0)\n",
    "        correct += predicted.eq(Y).sum().item()\n",
    "        running_loss += loss.item()\n",
    "        accu=100.*correct/total\n",
    "        train_loss = running_loss/(i+1)\n",
    "        print ('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.4f}%, Training Loss: {:.4f}%'.format(epoch+1, num_epochs, i+1, total_step, accu, train_loss))\n",
    "    \n",
    "   \n",
    "        #writer.add_scalar(f'train/accuracy', accu, epoch)\n",
    "        #writer.add_scalar(f'train/loss', train_loss, epoch)\n",
    "        writer.add_scalars(f'train/accuracy_loss', {\n",
    "            'accuracy': accu,\n",
    "            'loss': train_loss,\n",
    "        }, epoch)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d5f4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for X, Y in test_loader:\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += Y.size(0)\n",
    "        correct += (predicted == Y).sum().item()\n",
    "\n",
    "    print('Test Accuracy : {} %'.format(100 * correct / total))\n",
    "\n",
    "# Save the model checkpoint\n",
    "#torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce71586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d066157a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
