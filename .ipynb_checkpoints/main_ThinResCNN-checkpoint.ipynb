{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce5e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f58eded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8a3116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"data/final_format/train_set.csv\",header=None).to_numpy()\n",
    "train_label = pd.read_csv(\"data/final_format/train_label.csv\",header=None).to_numpy()\n",
    "test_set = pd.read_csv(\"data/final_format/test_set.csv\",header=None).to_numpy()\n",
    "test_label = pd.read_csv(\"data/final_format/test_label.csv\",header=None).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37f64e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14393, 4096) (14393, 1) (3599, 4096) (3599, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_set.shape, train_label.shape, test_set.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27d522cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14392, 4096) (14392, 1) (3598, 4096) (3598, 1)\n"
     ]
    }
   ],
   "source": [
    "#delet first row data\n",
    "train_set = train_set[1:]\n",
    "train_label = train_label[1:]\n",
    "test_set = test_set[1:]\n",
    "test_label = test_label[1:]\n",
    "print(train_set.shape, train_label.shape, test_set.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a84a2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14392, 1, 64, 64) (14392, 1) (3598, 1, 64, 64) (3598, 1)\n"
     ]
    }
   ],
   "source": [
    "train_set = train_set.reshape((-1,1,64,64))\n",
    "test_set = test_set.reshape((-1,1,64,64))\n",
    "print(train_set.shape, train_label.shape, test_set.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53e23a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14392, 1, 64, 64) (14392,) (3598, 1, 64, 64) (3598,)\n"
     ]
    }
   ],
   "source": [
    "train_label = train_label.reshape(-1)\n",
    "test_label = test_label.reshape(-1)\n",
    "\n",
    "print(train_set.shape, train_label.shape, test_set.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f62253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 300\n",
    "num_classes = 4\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d66b9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_tensor = Tensor(train_set) \n",
    "train_label_tensor = Tensor(train_label).type(torch.LongTensor)\n",
    "\n",
    "train_dataset = TensorDataset(train_set_tensor,train_label_tensor) \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size) \n",
    "\n",
    "test_set_tensor = Tensor(test_set) \n",
    "test_label_tensor = Tensor(test_label).type(torch.LongTensor)\n",
    "\n",
    "test_dataset = TensorDataset(test_set_tensor,test_label_tensor) \n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33820b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd6f6295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional neural network (two convolutional layers)\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.c1 = nn.Conv2d(1, 48, kernel_size=1, padding='same')\n",
    "        self.c2 = nn.Conv2d(48, 48, kernel_size=3,padding='same')\n",
    "        self.c3 = nn.Conv2d(48, 96, kernel_size=1,padding='same') \n",
    "        self.c4 = nn.Conv2d(97, 96, kernel_size=1, padding='same')\n",
    "        self.c5 = nn.Conv2d(96, 96, kernel_size=3,padding='same')\n",
    "        self.c6 = nn.Conv2d(96, 128, kernel_size=1, padding='same')\n",
    "        self.c7 = nn.Conv2d(225, 128, kernel_size=3, padding='same')\n",
    "        self.c8 = nn.Conv2d(128, 128, kernel_size=3,padding='same')\n",
    "        self.c9 = nn.Conv2d(128, 256, kernel_size=3, padding='same')\n",
    "        \n",
    "        self.d1 = nn.Dropout(p=0.25)\n",
    "        self.d2 = nn.Dropout(p=0.25)\n",
    "        self.d3 = nn.Dropout(p=0.25)\n",
    "        self.d4 = nn.Dropout(p=0.25)\n",
    "        self.d5 = nn.Dropout(p=0.25)\n",
    "        self.d6 = nn.Dropout(p=0.25) \n",
    "        self.d7 = nn.Dropout(p=0.25)\n",
    "        self.d8 = nn.Dropout(p=0.25)\n",
    "        self.d9 = nn.Dropout(p=0.25) \n",
    "        \n",
    "        self.bn1 =  nn.BatchNorm2d(1)\n",
    "        self.bn2 =  nn.BatchNorm2d(48)\n",
    "        self.bn3 =  nn.BatchNorm2d(48)\n",
    "        self.bn4 =  nn.BatchNorm2d(97)\n",
    "        self.bn5 =  nn.BatchNorm2d(96)\n",
    "        self.bn6 =  nn.BatchNorm2d(96)\n",
    "        self.bn7 =  nn.BatchNorm2d(225)\n",
    "        self.bn8 =  nn.BatchNorm2d(128)\n",
    "        self.bn9 =  nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.fc1 = nn.Linear(481*8*8, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        C1 = self.c1(self.bn1(x))\n",
    "        C1 = F.leaky_relu(C1,0.2)\n",
    "        C1 = self.d1(C1)\n",
    "        C2 = self.c2(self.bn2(C1))\n",
    "        C2 = F.leaky_relu(C2,0.2)\n",
    "        C2 = self.d2(C2)\n",
    "        C3 = self.c3(self.bn3(C2))\n",
    "        sum1 = torch.cat((x, C3), dim=1)\n",
    "        sum1 = F.leaky_relu(sum1,0.2)\n",
    "        sum1 = self.d3(sum1)\n",
    "        M1 = F.max_pool2d(sum1, kernel_size=2, stride=2)\n",
    "         \n",
    "        C4 = self.c4(self.bn4(M1))\n",
    "        C4 = F.leaky_relu(C4,0.2)\n",
    "        C4 = self.d4(C4)\n",
    "        C5 = self.c5(self.bn5(C4))\n",
    "        C5 = F.leaky_relu(C5,0.2)\n",
    "        C5 = self.d5(C5)\n",
    "        C6 = self.c6(self.bn6(C5))\n",
    "        sum2 = torch.cat((M1, C6), dim=1)\n",
    "        sum2 = F.leaky_relu(sum2,0.2)\n",
    "        sum2 = self.d6(sum2)\n",
    "        M2 = F.max_pool2d(sum2, kernel_size=2, stride=2)\n",
    "        \n",
    "        C7 = self.c7(self.bn7(M2))\n",
    "        C7 = F.leaky_relu(C7,0.2)\n",
    "        C7 = self.d7(C7)\n",
    "        C8 = self.c8(self.bn8(C7))\n",
    "        C8 = F.leaky_relu(C8,0.2)\n",
    "        C8 = self.d8(C8)\n",
    "        C9 = self.c9(self.bn9(C8))\n",
    "        sum3 = torch.cat((M2, C9), dim=1)\n",
    "        sum3 = F.leaky_relu(sum3,0.2)\n",
    "        sum3 = self.d9(sum3)\n",
    "        M3 = F.max_pool2d(sum3, kernel_size=2, stride=2)\n",
    "        \n",
    "\n",
    "        F1 = M3.reshape(M3.size(0), -1)\n",
    "        Fc1 = self.fc1(F1)\n",
    "        Fc2 = self.fc2(Fc1)\n",
    "       \n",
    "        return Fc2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "901366a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45ae0d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-3) \n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "milestones = [50,100,150,200,250]\n",
    "milestones = [a * len(train_loader) for a in milestones]\n",
    "scheduler = MultiStepLR(optimizer, milestones=milestones, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b03775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Step [1/225], Training Accuracy: 28.1250%, Training Loss: 1.5506%\n",
      "Epoch [1/300], Step [2/225], Training Accuracy: 28.9062%, Training Loss: 56.4850%\n",
      "Epoch [1/300], Step [3/225], Training Accuracy: 27.0833%, Training Loss: 61.9703%\n",
      "Epoch [1/300], Step [4/225], Training Accuracy: 27.3438%, Training Loss: 51.3761%\n",
      "Epoch [1/300], Step [5/225], Training Accuracy: 25.9375%, Training Loss: 47.2340%\n",
      "Epoch [1/300], Step [6/225], Training Accuracy: 26.0417%, Training Loss: 43.9296%\n",
      "Epoch [1/300], Step [7/225], Training Accuracy: 25.0000%, Training Loss: 43.5640%\n",
      "Epoch [1/300], Step [8/225], Training Accuracy: 25.1953%, Training Loss: 40.9122%\n",
      "Epoch [1/300], Step [9/225], Training Accuracy: 25.0000%, Training Loss: 39.9092%\n",
      "Epoch [1/300], Step [10/225], Training Accuracy: 25.9375%, Training Loss: 38.0317%\n",
      "Epoch [1/300], Step [11/225], Training Accuracy: 26.1364%, Training Loss: 37.0273%\n",
      "Epoch [1/300], Step [12/225], Training Accuracy: 26.0417%, Training Loss: 35.8446%\n",
      "Epoch [1/300], Step [13/225], Training Accuracy: 26.2019%, Training Loss: 34.2437%\n",
      "Epoch [1/300], Step [14/225], Training Accuracy: 26.1161%, Training Loss: 33.0276%\n",
      "Epoch [1/300], Step [15/225], Training Accuracy: 26.2500%, Training Loss: 31.3964%\n",
      "Epoch [1/300], Step [16/225], Training Accuracy: 26.5625%, Training Loss: 29.7761%\n",
      "Epoch [1/300], Step [17/225], Training Accuracy: 26.8382%, Training Loss: 28.5485%\n",
      "Epoch [1/300], Step [18/225], Training Accuracy: 26.6493%, Training Loss: 27.7551%\n",
      "Epoch [1/300], Step [19/225], Training Accuracy: 26.4803%, Training Loss: 26.9954%\n",
      "Epoch [1/300], Step [20/225], Training Accuracy: 26.2500%, Training Loss: 26.2155%\n",
      "Epoch [1/300], Step [21/225], Training Accuracy: 26.0417%, Training Loss: 25.3033%\n",
      "Epoch [1/300], Step [22/225], Training Accuracy: 25.8523%, Training Loss: 24.3709%\n",
      "Epoch [1/300], Step [23/225], Training Accuracy: 25.7473%, Training Loss: 23.6028%\n",
      "Epoch [1/300], Step [24/225], Training Accuracy: 25.9115%, Training Loss: 22.8716%\n",
      "Epoch [1/300], Step [25/225], Training Accuracy: 25.9375%, Training Loss: 22.1994%\n",
      "Epoch [1/300], Step [26/225], Training Accuracy: 25.9014%, Training Loss: 21.5668%\n",
      "Epoch [1/300], Step [27/225], Training Accuracy: 25.6944%, Training Loss: 21.0161%\n",
      "Epoch [1/300], Step [28/225], Training Accuracy: 25.5580%, Training Loss: 20.3889%\n",
      "Epoch [1/300], Step [29/225], Training Accuracy: 25.7004%, Training Loss: 19.7992%\n",
      "Epoch [1/300], Step [30/225], Training Accuracy: 25.9375%, Training Loss: 19.2473%\n",
      "Epoch [1/300], Step [31/225], Training Accuracy: 26.2601%, Training Loss: 18.6988%\n",
      "Epoch [1/300], Step [32/225], Training Accuracy: 26.5137%, Training Loss: 18.2006%\n",
      "Epoch [1/300], Step [33/225], Training Accuracy: 26.4678%, Training Loss: 17.7680%\n",
      "Epoch [1/300], Step [34/225], Training Accuracy: 26.3327%, Training Loss: 17.3577%\n",
      "Epoch [1/300], Step [35/225], Training Accuracy: 26.2500%, Training Loss: 16.9723%\n",
      "Epoch [1/300], Step [36/225], Training Accuracy: 26.1285%, Training Loss: 16.6044%\n",
      "Epoch [1/300], Step [37/225], Training Accuracy: 26.1402%, Training Loss: 16.2437%\n",
      "Epoch [1/300], Step [38/225], Training Accuracy: 25.9868%, Training Loss: 15.8963%\n",
      "Epoch [1/300], Step [39/225], Training Accuracy: 25.7612%, Training Loss: 15.5772%\n",
      "Epoch [1/300], Step [40/225], Training Accuracy: 25.8594%, Training Loss: 15.2532%\n",
      "Epoch [1/300], Step [41/225], Training Accuracy: 25.9527%, Training Loss: 14.9491%\n",
      "Epoch [1/300], Step [42/225], Training Accuracy: 26.0417%, Training Loss: 14.6520%\n",
      "Epoch [1/300], Step [43/225], Training Accuracy: 26.0901%, Training Loss: 14.3733%\n",
      "Epoch [1/300], Step [44/225], Training Accuracy: 26.2074%, Training Loss: 14.1318%\n",
      "Epoch [1/300], Step [45/225], Training Accuracy: 26.2847%, Training Loss: 13.8647%\n",
      "Epoch [1/300], Step [46/225], Training Accuracy: 26.2228%, Training Loss: 13.6082%\n",
      "Epoch [1/300], Step [47/225], Training Accuracy: 26.2633%, Training Loss: 13.3568%\n",
      "Epoch [1/300], Step [48/225], Training Accuracy: 26.3997%, Training Loss: 13.1317%\n",
      "Epoch [1/300], Step [49/225], Training Accuracy: 26.5306%, Training Loss: 12.9050%\n",
      "Epoch [1/300], Step [50/225], Training Accuracy: 26.4375%, Training Loss: 12.6939%\n",
      "Epoch [1/300], Step [51/225], Training Accuracy: 26.5012%, Training Loss: 12.4920%\n",
      "Epoch [1/300], Step [52/225], Training Accuracy: 26.4423%, Training Loss: 12.2962%\n",
      "Epoch [1/300], Step [53/225], Training Accuracy: 26.6804%, Training Loss: 12.0927%\n",
      "Epoch [1/300], Step [54/225], Training Accuracy: 26.7650%, Training Loss: 11.9006%\n",
      "Epoch [1/300], Step [55/225], Training Accuracy: 26.6761%, Training Loss: 11.7212%\n",
      "Epoch [1/300], Step [56/225], Training Accuracy: 26.7020%, Training Loss: 11.5405%\n",
      "Epoch [1/300], Step [57/225], Training Accuracy: 26.8640%, Training Loss: 11.3637%\n",
      "Epoch [1/300], Step [58/225], Training Accuracy: 26.7780%, Training Loss: 11.2054%\n",
      "Epoch [1/300], Step [59/225], Training Accuracy: 26.8273%, Training Loss: 11.0446%\n",
      "Epoch [1/300], Step [60/225], Training Accuracy: 26.9010%, Training Loss: 10.9030%\n",
      "Epoch [1/300], Step [61/225], Training Accuracy: 26.7674%, Training Loss: 10.7583%\n",
      "Epoch [1/300], Step [62/225], Training Accuracy: 26.7137%, Training Loss: 10.6197%\n",
      "Epoch [1/300], Step [63/225], Training Accuracy: 26.7113%, Training Loss: 10.4829%\n",
      "Epoch [1/300], Step [64/225], Training Accuracy: 26.7822%, Training Loss: 10.3573%\n",
      "Epoch [1/300], Step [65/225], Training Accuracy: 26.8750%, Training Loss: 10.2298%\n",
      "Epoch [1/300], Step [66/225], Training Accuracy: 26.7282%, Training Loss: 10.1058%\n",
      "Epoch [1/300], Step [67/225], Training Accuracy: 26.7724%, Training Loss: 9.9839%\n",
      "Epoch [1/300], Step [68/225], Training Accuracy: 26.7693%, Training Loss: 9.8677%\n",
      "Epoch [1/300], Step [69/225], Training Accuracy: 26.7437%, Training Loss: 9.7580%\n",
      "Epoch [1/300], Step [70/225], Training Accuracy: 26.6964%, Training Loss: 9.6471%\n",
      "Epoch [1/300], Step [71/225], Training Accuracy: 26.7165%, Training Loss: 9.5393%\n",
      "Epoch [1/300], Step [72/225], Training Accuracy: 26.8229%, Training Loss: 9.4330%\n",
      "Epoch [1/300], Step [73/225], Training Accuracy: 26.8836%, Training Loss: 9.3243%\n",
      "Epoch [1/300], Step [74/225], Training Accuracy: 26.8159%, Training Loss: 9.2199%\n",
      "Epoch [1/300], Step [75/225], Training Accuracy: 26.8542%, Training Loss: 9.1182%\n",
      "Epoch [1/300], Step [76/225], Training Accuracy: 26.8914%, Training Loss: 9.0184%\n",
      "Epoch [1/300], Step [77/225], Training Accuracy: 26.8263%, Training Loss: 8.9225%\n",
      "Epoch [1/300], Step [78/225], Training Accuracy: 26.9030%, Training Loss: 8.8303%\n",
      "Epoch [1/300], Step [79/225], Training Accuracy: 26.8790%, Training Loss: 8.7371%\n",
      "Epoch [1/300], Step [80/225], Training Accuracy: 26.9336%, Training Loss: 8.6478%\n",
      "Epoch [1/300], Step [81/225], Training Accuracy: 26.9483%, Training Loss: 8.5635%\n",
      "Epoch [1/300], Step [82/225], Training Accuracy: 26.9245%, Training Loss: 8.4807%\n",
      "Epoch [1/300], Step [83/225], Training Accuracy: 26.9578%, Training Loss: 8.3995%\n",
      "Epoch [1/300], Step [84/225], Training Accuracy: 26.8601%, Training Loss: 8.3272%\n",
      "Epoch [1/300], Step [85/225], Training Accuracy: 26.8750%, Training Loss: 8.2540%\n",
      "Epoch [1/300], Step [86/225], Training Accuracy: 26.9622%, Training Loss: 8.1751%\n",
      "Epoch [1/300], Step [87/225], Training Accuracy: 27.0654%, Training Loss: 8.1010%\n",
      "Epoch [1/300], Step [88/225], Training Accuracy: 27.0419%, Training Loss: 8.0281%\n",
      "Epoch [1/300], Step [89/225], Training Accuracy: 27.1067%, Training Loss: 7.9613%\n",
      "Epoch [1/300], Step [90/225], Training Accuracy: 27.2049%, Training Loss: 7.8915%\n",
      "Epoch [1/300], Step [91/225], Training Accuracy: 27.1463%, Training Loss: 7.8236%\n",
      "Epoch [1/300], Step [92/225], Training Accuracy: 27.1230%, Training Loss: 7.7626%\n",
      "Epoch [1/300], Step [93/225], Training Accuracy: 27.0665%, Training Loss: 7.7022%\n",
      "Epoch [1/300], Step [94/225], Training Accuracy: 27.1609%, Training Loss: 7.6378%\n",
      "Epoch [1/300], Step [95/225], Training Accuracy: 27.1875%, Training Loss: 7.5771%\n",
      "Epoch [1/300], Step [96/225], Training Accuracy: 27.1973%, Training Loss: 7.5143%\n",
      "Epoch [1/300], Step [97/225], Training Accuracy: 27.1424%, Training Loss: 7.4558%\n",
      "Epoch [1/300], Step [98/225], Training Accuracy: 27.1205%, Training Loss: 7.4002%\n",
      "Epoch [1/300], Step [99/225], Training Accuracy: 27.2254%, Training Loss: 7.3406%\n",
      "Epoch [1/300], Step [100/225], Training Accuracy: 27.2188%, Training Loss: 7.2826%\n",
      "Epoch [1/300], Step [101/225], Training Accuracy: 27.2277%, Training Loss: 7.2285%\n",
      "Epoch [1/300], Step [102/225], Training Accuracy: 27.1906%, Training Loss: 7.1779%\n",
      "Epoch [1/300], Step [103/225], Training Accuracy: 27.2148%, Training Loss: 7.1221%\n",
      "Epoch [1/300], Step [104/225], Training Accuracy: 27.2236%, Training Loss: 7.0678%\n",
      "Epoch [1/300], Step [105/225], Training Accuracy: 27.2024%, Training Loss: 7.0208%\n",
      "Epoch [1/300], Step [106/225], Training Accuracy: 27.2848%, Training Loss: 6.9678%\n",
      "Epoch [1/300], Step [107/225], Training Accuracy: 27.3072%, Training Loss: 6.9202%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Step [108/225], Training Accuracy: 27.3582%, Training Loss: 6.8720%\n",
      "Epoch [1/300], Step [109/225], Training Accuracy: 27.4943%, Training Loss: 6.8235%\n",
      "Epoch [1/300], Step [110/225], Training Accuracy: 27.4716%, Training Loss: 6.7821%\n",
      "Epoch [1/300], Step [111/225], Training Accuracy: 27.5056%, Training Loss: 6.7357%\n",
      "Epoch [1/300], Step [112/225], Training Accuracy: 27.5251%, Training Loss: 6.6899%\n",
      "Epoch [1/300], Step [113/225], Training Accuracy: 27.5581%, Training Loss: 6.6462%\n",
      "Epoch [1/300], Step [114/225], Training Accuracy: 27.5630%, Training Loss: 6.6014%\n",
      "Epoch [1/300], Step [115/225], Training Accuracy: 27.5408%, Training Loss: 6.5603%\n",
      "Epoch [1/300], Step [116/225], Training Accuracy: 27.6401%, Training Loss: 6.5169%\n",
      "Epoch [1/300], Step [117/225], Training Accuracy: 27.5507%, Training Loss: 6.4766%\n",
      "Epoch [1/300], Step [118/225], Training Accuracy: 27.5291%, Training Loss: 6.4370%\n",
      "Epoch [1/300], Step [119/225], Training Accuracy: 27.5867%, Training Loss: 6.3982%\n",
      "Epoch [1/300], Step [120/225], Training Accuracy: 27.5130%, Training Loss: 6.3591%\n",
      "Epoch [1/300], Step [121/225], Training Accuracy: 27.5052%, Training Loss: 6.3196%\n",
      "Epoch [1/300], Step [122/225], Training Accuracy: 27.5102%, Training Loss: 6.2831%\n",
      "Epoch [1/300], Step [123/225], Training Accuracy: 27.4644%, Training Loss: 6.2463%\n",
      "Epoch [1/300], Step [124/225], Training Accuracy: 27.5328%, Training Loss: 6.2081%\n",
      "Epoch [1/300], Step [125/225], Training Accuracy: 27.4375%, Training Loss: 6.1771%\n",
      "Epoch [1/300], Step [126/225], Training Accuracy: 27.4182%, Training Loss: 6.1405%\n",
      "Epoch [1/300], Step [127/225], Training Accuracy: 27.4483%, Training Loss: 6.1085%\n",
      "Epoch [1/300], Step [128/225], Training Accuracy: 27.4658%, Training Loss: 6.0745%\n",
      "Epoch [1/300], Step [129/225], Training Accuracy: 27.4952%, Training Loss: 6.0390%\n",
      "Epoch [1/300], Step [130/225], Training Accuracy: 27.5481%, Training Loss: 6.0073%\n",
      "Epoch [1/300], Step [131/225], Training Accuracy: 27.6121%, Training Loss: 5.9733%\n",
      "Epoch [1/300], Step [132/225], Training Accuracy: 27.5568%, Training Loss: 5.9472%\n",
      "Epoch [1/300], Step [133/225], Training Accuracy: 27.5611%, Training Loss: 5.9147%\n",
      "Epoch [1/300], Step [134/225], Training Accuracy: 27.5187%, Training Loss: 5.8898%\n",
      "Epoch [1/300], Step [135/225], Training Accuracy: 27.5347%, Training Loss: 5.8612%\n",
      "Epoch [1/300], Step [136/225], Training Accuracy: 27.5965%, Training Loss: 5.8300%\n",
      "Epoch [1/300], Step [137/225], Training Accuracy: 27.6574%, Training Loss: 5.7998%\n",
      "Epoch [1/300], Step [138/225], Training Accuracy: 27.6495%, Training Loss: 5.7721%\n",
      "Epoch [1/300], Step [139/225], Training Accuracy: 27.6641%, Training Loss: 5.7406%\n",
      "Epoch [1/300], Step [140/225], Training Accuracy: 27.6786%, Training Loss: 5.7103%\n",
      "Epoch [1/300], Step [141/225], Training Accuracy: 27.7039%, Training Loss: 5.6875%\n",
      "Epoch [1/300], Step [142/225], Training Accuracy: 27.7289%, Training Loss: 5.6622%\n",
      "Epoch [1/300], Step [143/225], Training Accuracy: 27.7207%, Training Loss: 5.6355%\n",
      "Epoch [1/300], Step [144/225], Training Accuracy: 27.7561%, Training Loss: 5.6131%\n",
      "Epoch [1/300], Step [145/225], Training Accuracy: 27.8017%, Training Loss: 5.5895%\n",
      "Epoch [1/300], Step [146/225], Training Accuracy: 27.8253%, Training Loss: 5.5643%\n",
      "Epoch [1/300], Step [147/225], Training Accuracy: 27.8168%, Training Loss: 5.5401%\n",
      "Epoch [1/300], Step [148/225], Training Accuracy: 27.7344%, Training Loss: 5.5219%\n",
      "Epoch [1/300], Step [149/225], Training Accuracy: 27.7580%, Training Loss: 5.4951%\n",
      "Epoch [1/300], Step [150/225], Training Accuracy: 27.7812%, Training Loss: 5.4729%\n",
      "Epoch [1/300], Step [151/225], Training Accuracy: 27.7628%, Training Loss: 5.4506%\n",
      "Epoch [1/300], Step [152/225], Training Accuracy: 27.7858%, Training Loss: 5.4293%\n",
      "Epoch [1/300], Step [153/225], Training Accuracy: 27.7778%, Training Loss: 5.4084%\n",
      "Epoch [1/300], Step [154/225], Training Accuracy: 27.7902%, Training Loss: 5.3876%\n",
      "Epoch [1/300], Step [155/225], Training Accuracy: 27.8024%, Training Loss: 5.3648%\n",
      "Epoch [1/300], Step [156/225], Training Accuracy: 27.7845%, Training Loss: 5.3450%\n",
      "Epoch [1/300], Step [157/225], Training Accuracy: 27.7966%, Training Loss: 5.3245%\n",
      "Epoch [1/300], Step [158/225], Training Accuracy: 27.7987%, Training Loss: 5.3000%\n",
      "Epoch [1/300], Step [159/225], Training Accuracy: 27.8892%, Training Loss: 5.2762%\n",
      "Epoch [1/300], Step [160/225], Training Accuracy: 27.8906%, Training Loss: 5.2559%\n",
      "Epoch [1/300], Step [161/225], Training Accuracy: 27.8921%, Training Loss: 5.2340%\n",
      "Epoch [1/300], Step [162/225], Training Accuracy: 27.9514%, Training Loss: 5.2105%\n",
      "Epoch [1/300], Step [163/225], Training Accuracy: 27.9237%, Training Loss: 5.1934%\n",
      "Epoch [1/300], Step [164/225], Training Accuracy: 28.0011%, Training Loss: 5.1722%\n",
      "Epoch [1/300], Step [165/225], Training Accuracy: 27.9451%, Training Loss: 5.1523%\n",
      "Epoch [1/300], Step [166/225], Training Accuracy: 28.0215%, Training Loss: 5.1304%\n",
      "Epoch [1/300], Step [167/225], Training Accuracy: 28.0314%, Training Loss: 5.1080%\n",
      "Epoch [1/300], Step [168/225], Training Accuracy: 28.0041%, Training Loss: 5.0882%\n",
      "Epoch [1/300], Step [169/225], Training Accuracy: 27.9216%, Training Loss: 5.0706%\n",
      "Epoch [1/300], Step [170/225], Training Accuracy: 27.9596%, Training Loss: 5.0486%\n",
      "Epoch [1/300], Step [171/225], Training Accuracy: 27.9423%, Training Loss: 5.0288%\n",
      "Epoch [1/300], Step [172/225], Training Accuracy: 27.9342%, Training Loss: 5.0119%\n",
      "Epoch [1/300], Step [173/225], Training Accuracy: 27.9173%, Training Loss: 4.9928%\n",
      "Epoch [1/300], Step [174/225], Training Accuracy: 27.9095%, Training Loss: 4.9749%\n",
      "Epoch [1/300], Step [175/225], Training Accuracy: 27.9018%, Training Loss: 4.9548%\n",
      "Epoch [1/300], Step [176/225], Training Accuracy: 27.8853%, Training Loss: 4.9369%\n",
      "Epoch [1/300], Step [177/225], Training Accuracy: 27.8867%, Training Loss: 4.9191%\n",
      "Epoch [1/300], Step [178/225], Training Accuracy: 27.9055%, Training Loss: 4.9005%\n",
      "Epoch [1/300], Step [179/225], Training Accuracy: 27.9242%, Training Loss: 4.8814%\n",
      "Epoch [1/300], Step [180/225], Training Accuracy: 27.9167%, Training Loss: 4.8632%\n",
      "Epoch [1/300], Step [181/225], Training Accuracy: 27.9265%, Training Loss: 4.8446%\n",
      "Epoch [1/300], Step [182/225], Training Accuracy: 27.9018%, Training Loss: 4.8275%\n",
      "Epoch [1/300], Step [183/225], Training Accuracy: 27.8603%, Training Loss: 4.8100%\n",
      "Epoch [1/300], Step [184/225], Training Accuracy: 27.8618%, Training Loss: 4.7927%\n",
      "Epoch [1/300], Step [185/225], Training Accuracy: 27.8885%, Training Loss: 4.7740%\n",
      "Epoch [1/300], Step [186/225], Training Accuracy: 27.9318%, Training Loss: 4.7558%\n",
      "Epoch [1/300], Step [187/225], Training Accuracy: 27.8827%, Training Loss: 4.7389%\n",
      "Epoch [1/300], Step [188/225], Training Accuracy: 27.8590%, Training Loss: 4.7221%\n",
      "Epoch [1/300], Step [189/225], Training Accuracy: 27.9431%, Training Loss: 4.7038%\n",
      "Epoch [1/300], Step [190/225], Training Accuracy: 27.9441%, Training Loss: 4.6878%\n",
      "Epoch [1/300], Step [191/225], Training Accuracy: 27.9287%, Training Loss: 4.6717%\n",
      "Epoch [1/300], Step [192/225], Training Accuracy: 28.0192%, Training Loss: 4.6553%\n",
      "Epoch [1/300], Step [193/225], Training Accuracy: 27.9631%, Training Loss: 4.6400%\n",
      "Epoch [1/300], Step [194/225], Training Accuracy: 27.9478%, Training Loss: 4.6234%\n",
      "Epoch [1/300], Step [195/225], Training Accuracy: 27.9487%, Training Loss: 4.6076%\n",
      "Epoch [1/300], Step [196/225], Training Accuracy: 27.9576%, Training Loss: 4.5922%\n",
      "Epoch [1/300], Step [197/225], Training Accuracy: 27.9505%, Training Loss: 4.5773%\n",
      "Epoch [1/300], Step [198/225], Training Accuracy: 27.9356%, Training Loss: 4.5621%\n",
      "Epoch [1/300], Step [199/225], Training Accuracy: 27.9287%, Training Loss: 4.5468%\n",
      "Epoch [1/300], Step [200/225], Training Accuracy: 27.9219%, Training Loss: 4.5312%\n",
      "Epoch [1/300], Step [201/225], Training Accuracy: 27.9462%, Training Loss: 4.5158%\n",
      "Epoch [1/300], Step [202/225], Training Accuracy: 27.9626%, Training Loss: 4.5005%\n",
      "Epoch [1/300], Step [203/225], Training Accuracy: 27.9557%, Training Loss: 4.4856%\n",
      "Epoch [1/300], Step [204/225], Training Accuracy: 27.9795%, Training Loss: 4.4703%\n",
      "Epoch [1/300], Step [205/225], Training Accuracy: 28.0412%, Training Loss: 4.4551%\n",
      "Epoch [1/300], Step [206/225], Training Accuracy: 28.0567%, Training Loss: 4.4412%\n",
      "Epoch [1/300], Step [207/225], Training Accuracy: 28.0873%, Training Loss: 4.4269%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Step [208/225], Training Accuracy: 28.1100%, Training Loss: 4.4127%\n",
      "Epoch [1/300], Step [209/225], Training Accuracy: 28.1175%, Training Loss: 4.3985%\n",
      "Epoch [1/300], Step [210/225], Training Accuracy: 28.0804%, Training Loss: 4.3853%\n",
      "Epoch [1/300], Step [211/225], Training Accuracy: 28.0880%, Training Loss: 4.3711%\n",
      "Epoch [1/300], Step [212/225], Training Accuracy: 28.0808%, Training Loss: 4.3570%\n",
      "Epoch [1/300], Step [213/225], Training Accuracy: 28.1030%, Training Loss: 4.3435%\n",
      "Epoch [1/300], Step [214/225], Training Accuracy: 28.0958%, Training Loss: 4.3301%\n",
      "Epoch [1/300], Step [215/225], Training Accuracy: 28.0160%, Training Loss: 4.3178%\n",
      "Epoch [1/300], Step [216/225], Training Accuracy: 28.0744%, Training Loss: 4.3042%\n",
      "Epoch [1/300], Step [217/225], Training Accuracy: 28.1250%, Training Loss: 4.2902%\n",
      "Epoch [1/300], Step [218/225], Training Accuracy: 28.1537%, Training Loss: 4.2781%\n",
      "Epoch [1/300], Step [219/225], Training Accuracy: 28.1393%, Training Loss: 4.2661%\n",
      "Epoch [1/300], Step [220/225], Training Accuracy: 28.1605%, Training Loss: 4.2536%\n",
      "Epoch [1/300], Step [221/225], Training Accuracy: 28.1250%, Training Loss: 4.2414%\n",
      "Epoch [1/300], Step [222/225], Training Accuracy: 28.1391%, Training Loss: 4.2298%\n",
      "Epoch [1/300], Step [223/225], Training Accuracy: 28.1530%, Training Loss: 4.2181%\n",
      "Epoch [1/300], Step [224/225], Training Accuracy: 28.1808%, Training Loss: 4.2055%\n",
      "Epoch [1/300], Step [225/225], Training Accuracy: 28.1754%, Training Loss: 4.1936%\n",
      "Epoch [2/300], Step [1/225], Training Accuracy: 23.4375%, Training Loss: 1.5052%\n",
      "Epoch [2/300], Step [2/225], Training Accuracy: 25.0000%, Training Loss: 1.4617%\n",
      "Epoch [2/300], Step [3/225], Training Accuracy: 26.0417%, Training Loss: 1.4806%\n",
      "Epoch [2/300], Step [4/225], Training Accuracy: 29.2969%, Training Loss: 1.4709%\n",
      "Epoch [2/300], Step [5/225], Training Accuracy: 29.6875%, Training Loss: 1.4762%\n",
      "Epoch [2/300], Step [6/225], Training Accuracy: 30.2083%, Training Loss: 1.4778%\n",
      "Epoch [2/300], Step [7/225], Training Accuracy: 29.9107%, Training Loss: 1.5275%\n",
      "Epoch [2/300], Step [8/225], Training Accuracy: 29.8828%, Training Loss: 1.5225%\n",
      "Epoch [2/300], Step [9/225], Training Accuracy: 30.2083%, Training Loss: 1.5038%\n",
      "Epoch [2/300], Step [10/225], Training Accuracy: 30.1562%, Training Loss: 1.4902%\n",
      "Epoch [2/300], Step [11/225], Training Accuracy: 29.5455%, Training Loss: 1.4884%\n",
      "Epoch [2/300], Step [12/225], Training Accuracy: 29.9479%, Training Loss: 1.4821%\n",
      "Epoch [2/300], Step [13/225], Training Accuracy: 29.4471%, Training Loss: 1.4804%\n",
      "Epoch [2/300], Step [14/225], Training Accuracy: 29.2411%, Training Loss: 1.4756%\n",
      "Epoch [2/300], Step [15/225], Training Accuracy: 28.6458%, Training Loss: 1.4815%\n",
      "Epoch [2/300], Step [16/225], Training Accuracy: 28.3203%, Training Loss: 1.4818%\n",
      "Epoch [2/300], Step [17/225], Training Accuracy: 28.5846%, Training Loss: 1.4730%\n",
      "Epoch [2/300], Step [18/225], Training Accuracy: 28.2986%, Training Loss: 1.4713%\n",
      "Epoch [2/300], Step [19/225], Training Accuracy: 28.3717%, Training Loss: 1.4680%\n",
      "Epoch [2/300], Step [20/225], Training Accuracy: 28.4375%, Training Loss: 1.4682%\n",
      "Epoch [2/300], Step [21/225], Training Accuracy: 28.1250%, Training Loss: 1.4661%\n",
      "Epoch [2/300], Step [22/225], Training Accuracy: 28.4091%, Training Loss: 1.4591%\n",
      "Epoch [2/300], Step [23/225], Training Accuracy: 28.3967%, Training Loss: 1.4574%\n",
      "Epoch [2/300], Step [24/225], Training Accuracy: 28.5807%, Training Loss: 1.4562%\n",
      "Epoch [2/300], Step [25/225], Training Accuracy: 28.6250%, Training Loss: 1.4556%\n",
      "Epoch [2/300], Step [26/225], Training Accuracy: 28.4255%, Training Loss: 1.4569%\n",
      "Epoch [2/300], Step [27/225], Training Accuracy: 28.1829%, Training Loss: 1.4596%\n",
      "Epoch [2/300], Step [28/225], Training Accuracy: 28.6830%, Training Loss: 1.4540%\n",
      "Epoch [2/300], Step [29/225], Training Accuracy: 28.9332%, Training Loss: 1.4507%\n",
      "Epoch [2/300], Step [30/225], Training Accuracy: 29.1146%, Training Loss: 1.4519%\n",
      "Epoch [2/300], Step [31/225], Training Accuracy: 29.3347%, Training Loss: 1.4508%\n",
      "Epoch [2/300], Step [32/225], Training Accuracy: 29.1016%, Training Loss: 1.4535%\n",
      "Epoch [2/300], Step [33/225], Training Accuracy: 29.2140%, Training Loss: 1.4501%\n",
      "Epoch [2/300], Step [34/225], Training Accuracy: 28.9982%, Training Loss: 1.4507%\n",
      "Epoch [2/300], Step [35/225], Training Accuracy: 28.8839%, Training Loss: 1.4512%\n",
      "Epoch [2/300], Step [36/225], Training Accuracy: 28.6892%, Training Loss: 1.4589%\n",
      "Epoch [2/300], Step [37/225], Training Accuracy: 28.6740%, Training Loss: 1.4595%\n",
      "Epoch [2/300], Step [38/225], Training Accuracy: 29.1530%, Training Loss: 1.4546%\n",
      "Epoch [2/300], Step [39/225], Training Accuracy: 28.9663%, Training Loss: 1.4568%\n",
      "Epoch [2/300], Step [40/225], Training Accuracy: 28.7500%, Training Loss: 1.4576%\n",
      "Epoch [2/300], Step [41/225], Training Accuracy: 28.8110%, Training Loss: 1.4567%\n",
      "Epoch [2/300], Step [42/225], Training Accuracy: 28.5714%, Training Loss: 1.4553%\n",
      "Epoch [2/300], Step [43/225], Training Accuracy: 28.7427%, Training Loss: 1.4539%\n",
      "Epoch [2/300], Step [44/225], Training Accuracy: 28.6222%, Training Loss: 1.4522%\n",
      "Epoch [2/300], Step [45/225], Training Accuracy: 28.8194%, Training Loss: 1.4495%\n",
      "Epoch [2/300], Step [46/225], Training Accuracy: 28.9062%, Training Loss: 1.4474%\n",
      "Epoch [2/300], Step [47/225], Training Accuracy: 29.0891%, Training Loss: 1.4447%\n",
      "Epoch [2/300], Step [48/225], Training Accuracy: 29.0039%, Training Loss: 1.4443%\n",
      "Epoch [2/300], Step [49/225], Training Accuracy: 29.0497%, Training Loss: 1.4427%\n",
      "Epoch [2/300], Step [50/225], Training Accuracy: 29.0938%, Training Loss: 1.4416%\n",
      "Epoch [2/300], Step [51/225], Training Accuracy: 29.2279%, Training Loss: 1.4394%\n",
      "Epoch [2/300], Step [52/225], Training Accuracy: 29.1767%, Training Loss: 1.4387%\n",
      "Epoch [2/300], Step [53/225], Training Accuracy: 29.2748%, Training Loss: 1.4375%\n",
      "Epoch [2/300], Step [54/225], Training Accuracy: 29.4850%, Training Loss: 1.4360%\n",
      "Epoch [2/300], Step [55/225], Training Accuracy: 29.4034%, Training Loss: 1.4349%\n",
      "Epoch [2/300], Step [56/225], Training Accuracy: 29.3527%, Training Loss: 1.4361%\n",
      "Epoch [2/300], Step [57/225], Training Accuracy: 29.4134%, Training Loss: 1.4340%\n",
      "Epoch [2/300], Step [58/225], Training Accuracy: 29.4450%, Training Loss: 1.4327%\n",
      "Epoch [2/300], Step [59/225], Training Accuracy: 29.3962%, Training Loss: 1.4310%\n",
      "Epoch [2/300], Step [60/225], Training Accuracy: 29.5052%, Training Loss: 1.4294%\n",
      "Epoch [2/300], Step [61/225], Training Accuracy: 29.5082%, Training Loss: 1.4325%\n",
      "Epoch [2/300], Step [62/225], Training Accuracy: 29.7127%, Training Loss: 1.4314%\n",
      "Epoch [2/300], Step [63/225], Training Accuracy: 29.6875%, Training Loss: 1.4305%\n",
      "Epoch [2/300], Step [64/225], Training Accuracy: 29.6387%, Training Loss: 1.4311%\n",
      "Epoch [2/300], Step [65/225], Training Accuracy: 29.7596%, Training Loss: 1.4292%\n",
      "Epoch [2/300], Step [66/225], Training Accuracy: 29.6402%, Training Loss: 1.4295%\n",
      "Epoch [2/300], Step [67/225], Training Accuracy: 29.6642%, Training Loss: 1.4275%\n",
      "Epoch [2/300], Step [68/225], Training Accuracy: 29.8483%, Training Loss: 1.4256%\n",
      "Epoch [2/300], Step [69/225], Training Accuracy: 29.8234%, Training Loss: 1.4243%\n",
      "Epoch [2/300], Step [70/225], Training Accuracy: 29.8884%, Training Loss: 1.4243%\n",
      "Epoch [2/300], Step [71/225], Training Accuracy: 29.9736%, Training Loss: 1.4240%\n",
      "Epoch [2/300], Step [72/225], Training Accuracy: 29.8828%, Training Loss: 1.4236%\n",
      "Epoch [2/300], Step [73/225], Training Accuracy: 29.9229%, Training Loss: 1.4235%\n",
      "Epoch [2/300], Step [74/225], Training Accuracy: 30.1309%, Training Loss: 1.4210%\n",
      "Epoch [2/300], Step [75/225], Training Accuracy: 30.2292%, Training Loss: 1.4196%\n",
      "Epoch [2/300], Step [76/225], Training Accuracy: 30.2426%, Training Loss: 1.4187%\n",
      "Epoch [2/300], Step [77/225], Training Accuracy: 30.1948%, Training Loss: 1.4188%\n",
      "Epoch [2/300], Step [78/225], Training Accuracy: 30.3486%, Training Loss: 1.4172%\n",
      "Epoch [2/300], Step [79/225], Training Accuracy: 30.4193%, Training Loss: 1.4161%\n",
      "Epoch [2/300], Step [80/225], Training Accuracy: 30.3906%, Training Loss: 1.4162%\n",
      "Epoch [2/300], Step [81/225], Training Accuracy: 30.3434%, Training Loss: 1.4162%\n",
      "Epoch [2/300], Step [82/225], Training Accuracy: 30.4306%, Training Loss: 1.4181%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/300], Step [83/225], Training Accuracy: 30.4405%, Training Loss: 1.4179%\n",
      "Epoch [2/300], Step [84/225], Training Accuracy: 30.4688%, Training Loss: 1.4166%\n",
      "Epoch [2/300], Step [85/225], Training Accuracy: 30.4963%, Training Loss: 1.4166%\n",
      "Epoch [2/300], Step [86/225], Training Accuracy: 30.5414%, Training Loss: 1.4155%\n",
      "Epoch [2/300], Step [87/225], Training Accuracy: 30.5496%, Training Loss: 1.4170%\n",
      "Epoch [2/300], Step [88/225], Training Accuracy: 30.4510%, Training Loss: 1.4179%\n",
      "Epoch [2/300], Step [89/225], Training Accuracy: 30.4249%, Training Loss: 1.4185%\n",
      "Epoch [2/300], Step [90/225], Training Accuracy: 30.4167%, Training Loss: 1.4185%\n",
      "Epoch [2/300], Step [91/225], Training Accuracy: 30.3400%, Training Loss: 1.4253%\n",
      "Epoch [2/300], Step [92/225], Training Accuracy: 30.2310%, Training Loss: 1.4305%\n",
      "Epoch [2/300], Step [93/225], Training Accuracy: 30.2923%, Training Loss: 1.4323%\n",
      "Epoch [2/300], Step [94/225], Training Accuracy: 30.3191%, Training Loss: 1.4309%\n",
      "Epoch [2/300], Step [95/225], Training Accuracy: 30.3289%, Training Loss: 1.4319%\n",
      "Epoch [2/300], Step [96/225], Training Accuracy: 30.3223%, Training Loss: 1.4331%\n",
      "Epoch [2/300], Step [97/225], Training Accuracy: 30.3963%, Training Loss: 1.4350%\n",
      "Epoch [2/300], Step [98/225], Training Accuracy: 30.4050%, Training Loss: 1.4357%\n",
      "Epoch [2/300], Step [99/225], Training Accuracy: 30.4293%, Training Loss: 1.4353%\n",
      "Epoch [2/300], Step [100/225], Training Accuracy: 30.4062%, Training Loss: 1.4351%\n",
      "Epoch [2/300], Step [101/225], Training Accuracy: 30.4610%, Training Loss: 1.4356%\n",
      "Epoch [2/300], Step [102/225], Training Accuracy: 30.5760%, Training Loss: 1.4360%\n",
      "Epoch [2/300], Step [103/225], Training Accuracy: 30.4612%, Training Loss: 1.4380%\n",
      "Epoch [2/300], Step [104/225], Training Accuracy: 30.4537%, Training Loss: 1.4366%\n",
      "Epoch [2/300], Step [105/225], Training Accuracy: 30.4167%, Training Loss: 1.4371%\n",
      "Epoch [2/300], Step [106/225], Training Accuracy: 30.3950%, Training Loss: 1.4357%\n",
      "Epoch [2/300], Step [107/225], Training Accuracy: 30.4468%, Training Loss: 1.4357%\n",
      "Epoch [2/300], Step [108/225], Training Accuracy: 30.6134%, Training Loss: 1.4343%\n",
      "Epoch [2/300], Step [109/225], Training Accuracy: 30.5476%, Training Loss: 1.4346%\n",
      "Epoch [2/300], Step [110/225], Training Accuracy: 30.5682%, Training Loss: 1.4341%\n",
      "Epoch [2/300], Step [111/225], Training Accuracy: 30.6306%, Training Loss: 1.4331%\n",
      "Epoch [2/300], Step [112/225], Training Accuracy: 30.6780%, Training Loss: 1.4319%\n",
      "Epoch [2/300], Step [113/225], Training Accuracy: 30.6001%, Training Loss: 1.4315%\n",
      "Epoch [2/300], Step [114/225], Training Accuracy: 30.6332%, Training Loss: 1.4309%\n",
      "Epoch [2/300], Step [115/225], Training Accuracy: 30.6929%, Training Loss: 1.4300%\n",
      "Epoch [2/300], Step [116/225], Training Accuracy: 30.7516%, Training Loss: 1.4290%\n",
      "Epoch [2/300], Step [117/225], Training Accuracy: 30.6624%, Training Loss: 1.4296%\n",
      "Epoch [2/300], Step [118/225], Training Accuracy: 30.5879%, Training Loss: 1.4294%\n",
      "Epoch [2/300], Step [119/225], Training Accuracy: 30.5804%, Training Loss: 1.4288%\n",
      "Epoch [2/300], Step [120/225], Training Accuracy: 30.6771%, Training Loss: 1.4283%\n",
      "Epoch [2/300], Step [121/225], Training Accuracy: 30.6947%, Training Loss: 1.4276%\n",
      "Epoch [2/300], Step [122/225], Training Accuracy: 30.6737%, Training Loss: 1.4274%\n",
      "Epoch [2/300], Step [123/225], Training Accuracy: 30.6911%, Training Loss: 1.4271%\n",
      "Epoch [2/300], Step [124/225], Training Accuracy: 30.7082%, Training Loss: 1.4275%\n",
      "Epoch [2/300], Step [125/225], Training Accuracy: 30.7125%, Training Loss: 1.4279%\n",
      "Epoch [2/300], Step [126/225], Training Accuracy: 30.6176%, Training Loss: 1.4283%\n",
      "Epoch [2/300], Step [127/225], Training Accuracy: 30.6471%, Training Loss: 1.4281%\n",
      "Epoch [2/300], Step [128/225], Training Accuracy: 30.6396%, Training Loss: 1.4280%\n",
      "Epoch [2/300], Step [129/225], Training Accuracy: 30.6323%, Training Loss: 1.4284%\n",
      "Epoch [2/300], Step [130/225], Training Accuracy: 30.6731%, Training Loss: 1.4279%\n",
      "Epoch [2/300], Step [131/225], Training Accuracy: 30.7013%, Training Loss: 1.4272%\n",
      "Epoch [2/300], Step [132/225], Training Accuracy: 30.6937%, Training Loss: 1.4261%\n",
      "Epoch [2/300], Step [133/225], Training Accuracy: 30.6743%, Training Loss: 1.4259%\n",
      "Epoch [2/300], Step [134/225], Training Accuracy: 30.6670%, Training Loss: 1.4252%\n",
      "Epoch [2/300], Step [135/225], Training Accuracy: 30.6366%, Training Loss: 1.4256%\n",
      "Epoch [2/300], Step [136/225], Training Accuracy: 30.6411%, Training Loss: 1.4252%\n",
      "Epoch [2/300], Step [137/225], Training Accuracy: 30.6911%, Training Loss: 1.4241%\n",
      "Epoch [2/300], Step [138/225], Training Accuracy: 30.7631%, Training Loss: 1.4231%\n",
      "Epoch [2/300], Step [139/225], Training Accuracy: 30.7329%, Training Loss: 1.4235%\n",
      "Epoch [2/300], Step [140/225], Training Accuracy: 30.7589%, Training Loss: 1.4230%\n",
      "Epoch [2/300], Step [141/225], Training Accuracy: 30.7957%, Training Loss: 1.4220%\n",
      "Epoch [2/300], Step [142/225], Training Accuracy: 30.7989%, Training Loss: 1.4215%\n",
      "Epoch [2/300], Step [143/225], Training Accuracy: 30.8348%, Training Loss: 1.4209%\n",
      "Epoch [2/300], Step [144/225], Training Accuracy: 30.7943%, Training Loss: 1.4211%\n",
      "Epoch [2/300], Step [145/225], Training Accuracy: 30.8405%, Training Loss: 1.4210%\n",
      "Epoch [2/300], Step [146/225], Training Accuracy: 30.9289%, Training Loss: 1.4200%\n",
      "Epoch [2/300], Step [147/225], Training Accuracy: 30.9843%, Training Loss: 1.4190%\n",
      "Epoch [2/300], Step [148/225], Training Accuracy: 30.9966%, Training Loss: 1.4190%\n",
      "Epoch [2/300], Step [149/225], Training Accuracy: 31.0298%, Training Loss: 1.4188%\n",
      "Epoch [2/300], Step [150/225], Training Accuracy: 31.0521%, Training Loss: 1.4186%\n",
      "Epoch [2/300], Step [151/225], Training Accuracy: 31.0948%, Training Loss: 1.4177%\n",
      "Epoch [2/300], Step [152/225], Training Accuracy: 31.1472%, Training Loss: 1.4172%\n",
      "Epoch [2/300], Step [153/225], Training Accuracy: 31.1785%, Training Loss: 1.4164%\n",
      "Epoch [2/300], Step [154/225], Training Accuracy: 31.1485%, Training Loss: 1.4168%\n",
      "Epoch [2/300], Step [155/225], Training Accuracy: 31.1290%, Training Loss: 1.4171%\n",
      "Epoch [2/300], Step [156/225], Training Accuracy: 31.1198%, Training Loss: 1.4172%\n",
      "Epoch [2/300], Step [157/225], Training Accuracy: 31.1803%, Training Loss: 1.4170%\n",
      "Epoch [2/300], Step [158/225], Training Accuracy: 31.2302%, Training Loss: 1.4161%\n",
      "Epoch [2/300], Step [159/225], Training Accuracy: 31.2697%, Training Loss: 1.4154%\n",
      "Epoch [2/300], Step [160/225], Training Accuracy: 31.2402%, Training Loss: 1.4150%\n",
      "Epoch [2/300], Step [161/225], Training Accuracy: 31.2694%, Training Loss: 1.4148%\n",
      "Epoch [2/300], Step [162/225], Training Accuracy: 31.2596%, Training Loss: 1.4148%\n",
      "Epoch [2/300], Step [163/225], Training Accuracy: 31.2788%, Training Loss: 1.4140%\n",
      "Epoch [2/300], Step [164/225], Training Accuracy: 31.3453%, Training Loss: 1.4136%\n",
      "Epoch [2/300], Step [165/225], Training Accuracy: 31.2973%, Training Loss: 1.4140%\n",
      "Epoch [2/300], Step [166/225], Training Accuracy: 31.3159%, Training Loss: 1.4135%\n",
      "Epoch [2/300], Step [167/225], Training Accuracy: 31.3061%, Training Loss: 1.4132%\n",
      "Epoch [2/300], Step [168/225], Training Accuracy: 31.3616%, Training Loss: 1.4126%\n",
      "Epoch [2/300], Step [169/225], Training Accuracy: 31.3702%, Training Loss: 1.4121%\n",
      "Epoch [2/300], Step [170/225], Training Accuracy: 31.4062%, Training Loss: 1.4114%\n",
      "Epoch [2/300], Step [171/225], Training Accuracy: 31.4510%, Training Loss: 1.4110%\n",
      "Epoch [2/300], Step [172/225], Training Accuracy: 31.4862%, Training Loss: 1.4102%\n",
      "Epoch [2/300], Step [173/225], Training Accuracy: 31.4848%, Training Loss: 1.4097%\n",
      "Epoch [2/300], Step [174/225], Training Accuracy: 31.5014%, Training Loss: 1.4092%\n",
      "Epoch [2/300], Step [175/225], Training Accuracy: 31.5000%, Training Loss: 1.4097%\n",
      "Epoch [2/300], Step [176/225], Training Accuracy: 31.4986%, Training Loss: 1.4096%\n",
      "Epoch [2/300], Step [177/225], Training Accuracy: 31.5148%, Training Loss: 1.4103%\n",
      "Epoch [2/300], Step [178/225], Training Accuracy: 31.4870%, Training Loss: 1.4101%\n",
      "Epoch [2/300], Step [179/225], Training Accuracy: 31.5031%, Training Loss: 1.4094%\n",
      "Epoch [2/300], Step [180/225], Training Accuracy: 31.5885%, Training Loss: 1.4084%\n",
      "Epoch [2/300], Step [181/225], Training Accuracy: 31.5608%, Training Loss: 1.4083%\n",
      "Epoch [2/300], Step [182/225], Training Accuracy: 31.5505%, Training Loss: 1.4085%\n",
      "Epoch [2/300], Step [183/225], Training Accuracy: 31.5318%, Training Loss: 1.4085%\n",
      "Epoch [2/300], Step [184/225], Training Accuracy: 31.5387%, Training Loss: 1.4080%\n",
      "Epoch [2/300], Step [185/225], Training Accuracy: 31.5456%, Training Loss: 1.4075%\n",
      "Epoch [2/300], Step [186/225], Training Accuracy: 31.5776%, Training Loss: 1.4076%\n",
      "Epoch [2/300], Step [187/225], Training Accuracy: 31.5926%, Training Loss: 1.4075%\n",
      "Epoch [2/300], Step [188/225], Training Accuracy: 31.5741%, Training Loss: 1.4073%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/300], Step [189/225], Training Accuracy: 31.5972%, Training Loss: 1.4062%\n",
      "Epoch [2/300], Step [190/225], Training Accuracy: 31.5461%, Training Loss: 1.4068%\n",
      "Epoch [2/300], Step [191/225], Training Accuracy: 31.4791%, Training Loss: 1.4076%\n",
      "Epoch [2/300], Step [192/225], Training Accuracy: 31.4860%, Training Loss: 1.4072%\n",
      "Epoch [2/300], Step [193/225], Training Accuracy: 31.5253%, Training Loss: 1.4066%\n",
      "Epoch [2/300], Step [194/225], Training Accuracy: 31.5802%, Training Loss: 1.4060%\n",
      "Epoch [2/300], Step [195/225], Training Accuracy: 31.5785%, Training Loss: 1.4058%\n",
      "Epoch [2/300], Step [196/225], Training Accuracy: 31.5370%, Training Loss: 1.4061%\n",
      "Epoch [2/300], Step [197/225], Training Accuracy: 31.4959%, Training Loss: 1.4067%\n",
      "Epoch [2/300], Step [198/225], Training Accuracy: 31.5025%, Training Loss: 1.4058%\n",
      "Epoch [2/300], Step [199/225], Training Accuracy: 31.4777%, Training Loss: 1.4057%\n",
      "Epoch [2/300], Step [200/225], Training Accuracy: 31.4844%, Training Loss: 1.4054%\n",
      "Epoch [2/300], Step [201/225], Training Accuracy: 31.4832%, Training Loss: 1.4048%\n",
      "Epoch [2/300], Step [202/225], Training Accuracy: 31.5285%, Training Loss: 1.4045%\n",
      "Epoch [2/300], Step [203/225], Training Accuracy: 31.5579%, Training Loss: 1.4041%\n",
      "Epoch [2/300], Step [204/225], Training Accuracy: 31.5947%, Training Loss: 1.4040%\n",
      "Epoch [2/300], Step [205/225], Training Accuracy: 31.6235%, Training Loss: 1.4036%\n",
      "Epoch [2/300], Step [206/225], Training Accuracy: 31.6520%, Training Loss: 1.4033%\n",
      "Epoch [2/300], Step [207/225], Training Accuracy: 31.6425%, Training Loss: 1.4030%\n",
      "Epoch [2/300], Step [208/225], Training Accuracy: 31.6857%, Training Loss: 1.4026%\n",
      "Epoch [2/300], Step [209/225], Training Accuracy: 31.7285%, Training Loss: 1.4023%\n",
      "Epoch [2/300], Step [210/225], Training Accuracy: 31.7188%, Training Loss: 1.4025%\n",
      "Epoch [2/300], Step [211/225], Training Accuracy: 31.7091%, Training Loss: 1.4020%\n",
      "Epoch [2/300], Step [212/225], Training Accuracy: 31.7070%, Training Loss: 1.4021%\n",
      "Epoch [2/300], Step [213/225], Training Accuracy: 31.6608%, Training Loss: 1.4022%\n",
      "Epoch [2/300], Step [214/225], Training Accuracy: 31.6297%, Training Loss: 1.4020%\n",
      "Epoch [2/300], Step [215/225], Training Accuracy: 31.6134%, Training Loss: 1.4026%\n",
      "Epoch [2/300], Step [216/225], Training Accuracy: 31.5755%, Training Loss: 1.4025%\n",
      "Epoch [2/300], Step [217/225], Training Accuracy: 31.6028%, Training Loss: 1.4018%\n",
      "Epoch [2/300], Step [218/225], Training Accuracy: 31.6370%, Training Loss: 1.4012%\n",
      "Epoch [2/300], Step [219/225], Training Accuracy: 31.6139%, Training Loss: 1.4011%\n",
      "Epoch [2/300], Step [220/225], Training Accuracy: 31.6122%, Training Loss: 1.4008%\n",
      "Epoch [2/300], Step [221/225], Training Accuracy: 31.5894%, Training Loss: 1.4012%\n",
      "Epoch [2/300], Step [222/225], Training Accuracy: 31.6019%, Training Loss: 1.4009%\n",
      "Epoch [2/300], Step [223/225], Training Accuracy: 31.6143%, Training Loss: 1.4008%\n",
      "Epoch [2/300], Step [224/225], Training Accuracy: 31.5988%, Training Loss: 1.4007%\n",
      "Epoch [2/300], Step [225/225], Training Accuracy: 31.6009%, Training Loss: 1.4005%\n",
      "Epoch [3/300], Step [1/225], Training Accuracy: 39.0625%, Training Loss: 1.2797%\n",
      "Epoch [3/300], Step [2/225], Training Accuracy: 35.9375%, Training Loss: 1.2890%\n",
      "Epoch [3/300], Step [3/225], Training Accuracy: 33.8542%, Training Loss: 1.3295%\n",
      "Epoch [3/300], Step [4/225], Training Accuracy: 34.3750%, Training Loss: 1.3307%\n",
      "Epoch [3/300], Step [5/225], Training Accuracy: 33.7500%, Training Loss: 1.3559%\n",
      "Epoch [3/300], Step [6/225], Training Accuracy: 34.6354%, Training Loss: 1.3521%\n",
      "Epoch [3/300], Step [7/225], Training Accuracy: 33.7054%, Training Loss: 1.3641%\n",
      "Epoch [3/300], Step [8/225], Training Accuracy: 33.9844%, Training Loss: 1.3743%\n",
      "Epoch [3/300], Step [9/225], Training Accuracy: 34.3750%, Training Loss: 1.3662%\n",
      "Epoch [3/300], Step [10/225], Training Accuracy: 33.5938%, Training Loss: 1.3663%\n",
      "Epoch [3/300], Step [11/225], Training Accuracy: 33.8068%, Training Loss: 1.3611%\n",
      "Epoch [3/300], Step [12/225], Training Accuracy: 33.9844%, Training Loss: 1.3548%\n",
      "Epoch [3/300], Step [13/225], Training Accuracy: 33.8942%, Training Loss: 1.3530%\n",
      "Epoch [3/300], Step [14/225], Training Accuracy: 33.2589%, Training Loss: 1.3538%\n",
      "Epoch [3/300], Step [15/225], Training Accuracy: 32.9167%, Training Loss: 1.3605%\n",
      "Epoch [3/300], Step [16/225], Training Accuracy: 32.7148%, Training Loss: 1.3603%\n",
      "Epoch [3/300], Step [17/225], Training Accuracy: 33.5478%, Training Loss: 1.3527%\n",
      "Epoch [3/300], Step [18/225], Training Accuracy: 33.3333%, Training Loss: 1.3502%\n",
      "Epoch [3/300], Step [19/225], Training Accuracy: 33.3882%, Training Loss: 1.3551%\n",
      "Epoch [3/300], Step [20/225], Training Accuracy: 34.0625%, Training Loss: 1.3472%\n",
      "Epoch [3/300], Step [21/225], Training Accuracy: 33.9286%, Training Loss: 1.3445%\n",
      "Epoch [3/300], Step [22/225], Training Accuracy: 34.2330%, Training Loss: 1.3424%\n",
      "Epoch [3/300], Step [23/225], Training Accuracy: 34.2391%, Training Loss: 1.3405%\n",
      "Epoch [3/300], Step [24/225], Training Accuracy: 34.5703%, Training Loss: 1.3404%\n",
      "Epoch [3/300], Step [25/225], Training Accuracy: 34.4375%, Training Loss: 1.3410%\n",
      "Epoch [3/300], Step [26/225], Training Accuracy: 34.1947%, Training Loss: 1.3418%\n",
      "Epoch [3/300], Step [27/225], Training Accuracy: 33.8542%, Training Loss: 1.3440%\n",
      "Epoch [3/300], Step [28/225], Training Accuracy: 33.9286%, Training Loss: 1.3418%\n",
      "Epoch [3/300], Step [29/225], Training Accuracy: 34.1056%, Training Loss: 1.3397%\n",
      "Epoch [3/300], Step [30/225], Training Accuracy: 34.2188%, Training Loss: 1.3405%\n",
      "Epoch [3/300], Step [31/225], Training Accuracy: 34.3246%, Training Loss: 1.3412%\n",
      "Epoch [3/300], Step [32/225], Training Accuracy: 34.4727%, Training Loss: 1.3386%\n",
      "Epoch [3/300], Step [33/225], Training Accuracy: 34.7538%, Training Loss: 1.3365%\n",
      "Epoch [3/300], Step [34/225], Training Accuracy: 34.8346%, Training Loss: 1.3375%\n",
      "Epoch [3/300], Step [35/225], Training Accuracy: 34.8214%, Training Loss: 1.3377%\n",
      "Epoch [3/300], Step [36/225], Training Accuracy: 34.6354%, Training Loss: 1.3407%\n",
      "Epoch [3/300], Step [37/225], Training Accuracy: 34.7551%, Training Loss: 1.3411%\n",
      "Epoch [3/300], Step [38/225], Training Accuracy: 35.0329%, Training Loss: 1.3397%\n",
      "Epoch [3/300], Step [39/225], Training Accuracy: 35.0561%, Training Loss: 1.3380%\n",
      "Epoch [3/300], Step [40/225], Training Accuracy: 34.8438%, Training Loss: 1.3430%\n",
      "Epoch [3/300], Step [41/225], Training Accuracy: 34.6418%, Training Loss: 1.3435%\n",
      "Epoch [3/300], Step [42/225], Training Accuracy: 34.4122%, Training Loss: 1.3445%\n",
      "Epoch [3/300], Step [43/225], Training Accuracy: 34.3750%, Training Loss: 1.3445%\n",
      "Epoch [3/300], Step [44/225], Training Accuracy: 34.2685%, Training Loss: 1.3446%\n",
      "Epoch [3/300], Step [45/225], Training Accuracy: 34.3056%, Training Loss: 1.3468%\n",
      "Epoch [3/300], Step [46/225], Training Accuracy: 34.3750%, Training Loss: 1.3464%\n",
      "Epoch [3/300], Step [47/225], Training Accuracy: 34.3085%, Training Loss: 1.3466%\n",
      "Epoch [3/300], Step [48/225], Training Accuracy: 34.2773%, Training Loss: 1.3463%\n",
      "Epoch [3/300], Step [49/225], Training Accuracy: 34.3112%, Training Loss: 1.3456%\n",
      "Epoch [3/300], Step [50/225], Training Accuracy: 34.2188%, Training Loss: 1.3468%\n",
      "Epoch [3/300], Step [51/225], Training Accuracy: 34.2218%, Training Loss: 1.3495%\n",
      "Epoch [3/300], Step [52/225], Training Accuracy: 34.2849%, Training Loss: 1.3524%\n",
      "Epoch [3/300], Step [53/225], Training Accuracy: 34.2571%, Training Loss: 1.3532%\n",
      "Epoch [3/300], Step [54/225], Training Accuracy: 34.1725%, Training Loss: 1.3521%\n",
      "Epoch [3/300], Step [55/225], Training Accuracy: 34.0909%, Training Loss: 1.3507%\n",
      "Epoch [3/300], Step [56/225], Training Accuracy: 33.8728%, Training Loss: 1.3527%\n",
      "Epoch [3/300], Step [57/225], Training Accuracy: 33.8816%, Training Loss: 1.3528%\n",
      "Epoch [3/300], Step [58/225], Training Accuracy: 33.9709%, Training Loss: 1.3511%\n",
      "Epoch [3/300], Step [59/225], Training Accuracy: 34.1102%, Training Loss: 1.3490%\n",
      "Epoch [3/300], Step [60/225], Training Accuracy: 34.0885%, Training Loss: 1.3474%\n",
      "Epoch [3/300], Step [61/225], Training Accuracy: 34.0420%, Training Loss: 1.3473%\n",
      "Epoch [3/300], Step [62/225], Training Accuracy: 34.1230%, Training Loss: 1.3469%\n",
      "Epoch [3/300], Step [63/225], Training Accuracy: 34.0526%, Training Loss: 1.3477%\n",
      "Epoch [3/300], Step [64/225], Training Accuracy: 34.0576%, Training Loss: 1.3511%\n",
      "Epoch [3/300], Step [65/225], Training Accuracy: 33.9904%, Training Loss: 1.3518%\n",
      "Epoch [3/300], Step [66/225], Training Accuracy: 34.0199%, Training Loss: 1.3512%\n",
      "Epoch [3/300], Step [67/225], Training Accuracy: 33.9785%, Training Loss: 1.3497%\n",
      "Epoch [3/300], Step [68/225], Training Accuracy: 34.1452%, Training Loss: 1.3482%\n",
      "Epoch [3/300], Step [69/225], Training Accuracy: 34.1938%, Training Loss: 1.3470%\n",
      "Epoch [3/300], Step [70/225], Training Accuracy: 34.1295%, Training Loss: 1.3484%\n",
      "Epoch [3/300], Step [71/225], Training Accuracy: 34.0669%, Training Loss: 1.3491%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/300], Step [72/225], Training Accuracy: 34.1146%, Training Loss: 1.3496%\n",
      "Epoch [3/300], Step [73/225], Training Accuracy: 34.1182%, Training Loss: 1.3496%\n",
      "Epoch [3/300], Step [74/225], Training Accuracy: 34.2483%, Training Loss: 1.3481%\n",
      "Epoch [3/300], Step [75/225], Training Accuracy: 34.2917%, Training Loss: 1.3466%\n",
      "Epoch [3/300], Step [76/225], Training Accuracy: 34.2722%, Training Loss: 1.3469%\n",
      "Epoch [3/300], Step [77/225], Training Accuracy: 34.2532%, Training Loss: 1.3474%\n",
      "Epoch [3/300], Step [78/225], Training Accuracy: 34.3149%, Training Loss: 1.3463%\n",
      "Epoch [3/300], Step [79/225], Training Accuracy: 34.3157%, Training Loss: 1.3462%\n",
      "Epoch [3/300], Step [80/225], Training Accuracy: 34.1602%, Training Loss: 1.3463%\n",
      "Epoch [3/300], Step [81/225], Training Accuracy: 34.2014%, Training Loss: 1.3460%\n",
      "Epoch [3/300], Step [82/225], Training Accuracy: 34.1845%, Training Loss: 1.3480%\n",
      "Epoch [3/300], Step [83/225], Training Accuracy: 34.1303%, Training Loss: 1.3486%\n",
      "Epoch [3/300], Step [84/225], Training Accuracy: 34.1332%, Training Loss: 1.3490%\n",
      "Epoch [3/300], Step [85/225], Training Accuracy: 34.0993%, Training Loss: 1.3493%\n",
      "Epoch [3/300], Step [86/225], Training Accuracy: 34.2478%, Training Loss: 1.3488%\n",
      "Epoch [3/300], Step [87/225], Training Accuracy: 34.3391%, Training Loss: 1.3478%\n",
      "Epoch [3/300], Step [88/225], Training Accuracy: 34.2685%, Training Loss: 1.3483%\n",
      "Epoch [3/300], Step [89/225], Training Accuracy: 34.1292%, Training Loss: 1.3512%\n",
      "Epoch [3/300], Step [90/225], Training Accuracy: 34.0104%, Training Loss: 1.3516%\n",
      "Epoch [3/300], Step [91/225], Training Accuracy: 33.9973%, Training Loss: 1.3510%\n",
      "Epoch [3/300], Step [92/225], Training Accuracy: 34.0183%, Training Loss: 1.3512%\n",
      "Epoch [3/300], Step [93/225], Training Accuracy: 34.0054%, Training Loss: 1.3511%\n",
      "Epoch [3/300], Step [94/225], Training Accuracy: 33.9761%, Training Loss: 1.3502%\n",
      "Epoch [3/300], Step [95/225], Training Accuracy: 33.9145%, Training Loss: 1.3507%\n",
      "Epoch [3/300], Step [96/225], Training Accuracy: 34.0007%, Training Loss: 1.3496%\n",
      "Epoch [3/300], Step [97/225], Training Accuracy: 34.0689%, Training Loss: 1.3483%\n",
      "Epoch [3/300], Step [98/225], Training Accuracy: 34.0402%, Training Loss: 1.3479%\n",
      "Epoch [3/300], Step [99/225], Training Accuracy: 34.1225%, Training Loss: 1.3469%\n",
      "Epoch [3/300], Step [100/225], Training Accuracy: 34.0938%, Training Loss: 1.3464%\n",
      "Epoch [3/300], Step [101/225], Training Accuracy: 34.2203%, Training Loss: 1.3467%\n",
      "Epoch [3/300], Step [102/225], Training Accuracy: 34.0993%, Training Loss: 1.3479%\n",
      "Epoch [3/300], Step [103/225], Training Accuracy: 34.1323%, Training Loss: 1.3476%\n",
      "Epoch [3/300], Step [104/225], Training Accuracy: 34.1496%, Training Loss: 1.3470%\n",
      "Epoch [3/300], Step [105/225], Training Accuracy: 34.1220%, Training Loss: 1.3466%\n",
      "Epoch [3/300], Step [106/225], Training Accuracy: 34.2129%, Training Loss: 1.3458%\n",
      "Epoch [3/300], Step [107/225], Training Accuracy: 34.3166%, Training Loss: 1.3452%\n",
      "Epoch [3/300], Step [108/225], Training Accuracy: 34.3750%, Training Loss: 1.3443%\n",
      "Epoch [3/300], Step [109/225], Training Accuracy: 34.4467%, Training Loss: 1.3438%\n",
      "Epoch [3/300], Step [110/225], Training Accuracy: 34.5312%, Training Loss: 1.3433%\n",
      "Epoch [3/300], Step [111/225], Training Accuracy: 34.4595%, Training Loss: 1.3429%\n",
      "Epoch [3/300], Step [112/225], Training Accuracy: 34.4448%, Training Loss: 1.3425%\n",
      "Epoch [3/300], Step [113/225], Training Accuracy: 34.3888%, Training Loss: 1.3428%\n",
      "Epoch [3/300], Step [114/225], Training Accuracy: 34.4846%, Training Loss: 1.3407%\n",
      "Epoch [3/300], Step [115/225], Training Accuracy: 34.4837%, Training Loss: 1.3403%\n",
      "Epoch [3/300], Step [116/225], Training Accuracy: 34.4962%, Training Loss: 1.3398%\n",
      "Epoch [3/300], Step [117/225], Training Accuracy: 34.4284%, Training Loss: 1.3410%\n",
      "Epoch [3/300], Step [118/225], Training Accuracy: 34.4280%, Training Loss: 1.3406%\n",
      "Epoch [3/300], Step [119/225], Training Accuracy: 34.4538%, Training Loss: 1.3403%\n",
      "Epoch [3/300], Step [120/225], Training Accuracy: 34.4661%, Training Loss: 1.3403%\n",
      "Epoch [3/300], Step [121/225], Training Accuracy: 34.5041%, Training Loss: 1.3413%\n",
      "Epoch [3/300], Step [122/225], Training Accuracy: 34.5799%, Training Loss: 1.3411%\n",
      "Epoch [3/300], Step [123/225], Training Accuracy: 34.5020%, Training Loss: 1.3415%\n",
      "Epoch [3/300], Step [124/225], Training Accuracy: 34.5514%, Training Loss: 1.3412%\n",
      "Epoch [3/300], Step [125/225], Training Accuracy: 34.5250%, Training Loss: 1.3416%\n",
      "Epoch [3/300], Step [126/225], Training Accuracy: 34.5362%, Training Loss: 1.3414%\n",
      "Epoch [3/300], Step [127/225], Training Accuracy: 34.4734%, Training Loss: 1.3419%\n",
      "Epoch [3/300], Step [128/225], Training Accuracy: 34.4238%, Training Loss: 1.3423%\n",
      "Epoch [3/300], Step [129/225], Training Accuracy: 34.3992%, Training Loss: 1.3421%\n",
      "Epoch [3/300], Step [130/225], Training Accuracy: 34.4111%, Training Loss: 1.3418%\n",
      "Epoch [3/300], Step [131/225], Training Accuracy: 34.3631%, Training Loss: 1.3416%\n",
      "Epoch [3/300], Step [132/225], Training Accuracy: 34.3868%, Training Loss: 1.3409%\n",
      "Epoch [3/300], Step [133/225], Training Accuracy: 34.3985%, Training Loss: 1.3403%\n",
      "Epoch [3/300], Step [134/225], Training Accuracy: 34.3983%, Training Loss: 1.3402%\n",
      "Epoch [3/300], Step [135/225], Training Accuracy: 34.3634%, Training Loss: 1.3409%\n",
      "Epoch [3/300], Step [136/225], Training Accuracy: 34.3405%, Training Loss: 1.3408%\n",
      "Epoch [3/300], Step [137/225], Training Accuracy: 34.3750%, Training Loss: 1.3403%\n",
      "Epoch [3/300], Step [138/225], Training Accuracy: 34.4203%, Training Loss: 1.3402%\n",
      "Epoch [3/300], Step [139/225], Training Accuracy: 34.4087%, Training Loss: 1.3403%\n",
      "Epoch [3/300], Step [140/225], Training Accuracy: 34.4196%, Training Loss: 1.3403%\n",
      "Epoch [3/300], Step [141/225], Training Accuracy: 34.4304%, Training Loss: 1.3398%\n",
      "Epoch [3/300], Step [142/225], Training Accuracy: 34.4630%, Training Loss: 1.3394%\n",
      "Epoch [3/300], Step [143/225], Training Accuracy: 34.4187%, Training Loss: 1.3392%\n",
      "Epoch [3/300], Step [144/225], Training Accuracy: 34.4184%, Training Loss: 1.3396%\n",
      "Epoch [3/300], Step [145/225], Training Accuracy: 34.4828%, Training Loss: 1.3390%\n",
      "Epoch [3/300], Step [146/225], Training Accuracy: 34.4713%, Training Loss: 1.3392%\n",
      "Epoch [3/300], Step [147/225], Training Accuracy: 34.4600%, Training Loss: 1.3387%\n",
      "Epoch [3/300], Step [148/225], Training Accuracy: 34.5228%, Training Loss: 1.3380%\n",
      "Epoch [3/300], Step [149/225], Training Accuracy: 34.5952%, Training Loss: 1.3372%\n",
      "Epoch [3/300], Step [150/225], Training Accuracy: 34.6458%, Training Loss: 1.3366%\n",
      "Epoch [3/300], Step [151/225], Training Accuracy: 34.6751%, Training Loss: 1.3362%\n",
      "Epoch [3/300], Step [152/225], Training Accuracy: 34.6731%, Training Loss: 1.3363%\n",
      "Epoch [3/300], Step [153/225], Training Accuracy: 34.6916%, Training Loss: 1.3360%\n",
      "Epoch [3/300], Step [154/225], Training Accuracy: 34.6388%, Training Loss: 1.3360%\n",
      "Epoch [3/300], Step [155/225], Training Accuracy: 34.6673%, Training Loss: 1.3362%\n",
      "Epoch [3/300], Step [156/225], Training Accuracy: 34.6254%, Training Loss: 1.3366%\n",
      "Epoch [3/300], Step [157/225], Training Accuracy: 34.6338%, Training Loss: 1.3369%\n",
      "Epoch [3/300], Step [158/225], Training Accuracy: 34.6321%, Training Loss: 1.3367%\n",
      "Epoch [3/300], Step [159/225], Training Accuracy: 34.6403%, Training Loss: 1.3367%\n",
      "Epoch [3/300], Step [160/225], Training Accuracy: 34.6777%, Training Loss: 1.3362%\n",
      "Epoch [3/300], Step [161/225], Training Accuracy: 34.7244%, Training Loss: 1.3354%\n",
      "Epoch [3/300], Step [162/225], Training Accuracy: 34.7512%, Training Loss: 1.3349%\n",
      "Epoch [3/300], Step [163/225], Training Accuracy: 34.7680%, Training Loss: 1.3342%\n",
      "Epoch [3/300], Step [164/225], Training Accuracy: 34.7085%, Training Loss: 1.3342%\n",
      "Epoch [3/300], Step [165/225], Training Accuracy: 34.6591%, Training Loss: 1.3345%\n",
      "Epoch [3/300], Step [166/225], Training Accuracy: 34.7139%, Training Loss: 1.3338%\n",
      "Epoch [3/300], Step [167/225], Training Accuracy: 34.7586%, Training Loss: 1.3331%\n",
      "Epoch [3/300], Step [168/225], Training Accuracy: 34.8307%, Training Loss: 1.3325%\n",
      "Epoch [3/300], Step [169/225], Training Accuracy: 34.8743%, Training Loss: 1.3319%\n",
      "Epoch [3/300], Step [170/225], Training Accuracy: 34.8438%, Training Loss: 1.3315%\n",
      "Epoch [3/300], Step [171/225], Training Accuracy: 34.9050%, Training Loss: 1.3311%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/300], Step [172/225], Training Accuracy: 34.9110%, Training Loss: 1.3308%\n",
      "Epoch [3/300], Step [173/225], Training Accuracy: 34.9530%, Training Loss: 1.3304%\n",
      "Epoch [3/300], Step [174/225], Training Accuracy: 34.9048%, Training Loss: 1.3301%\n",
      "Epoch [3/300], Step [175/225], Training Accuracy: 34.9375%, Training Loss: 1.3301%\n",
      "Epoch [3/300], Step [176/225], Training Accuracy: 34.9254%, Training Loss: 1.3303%\n",
      "Epoch [3/300], Step [177/225], Training Accuracy: 34.9311%, Training Loss: 1.3305%\n",
      "Epoch [3/300], Step [178/225], Training Accuracy: 34.9368%, Training Loss: 1.3302%\n",
      "Epoch [3/300], Step [179/225], Training Accuracy: 34.9511%, Training Loss: 1.3299%\n",
      "Epoch [3/300], Step [180/225], Training Accuracy: 35.0174%, Training Loss: 1.3292%\n",
      "Epoch [3/300], Step [181/225], Training Accuracy: 34.9879%, Training Loss: 1.3290%\n",
      "Epoch [3/300], Step [182/225], Training Accuracy: 34.9760%, Training Loss: 1.3286%\n",
      "Epoch [3/300], Step [183/225], Training Accuracy: 34.9556%, Training Loss: 1.3286%\n",
      "Epoch [3/300], Step [184/225], Training Accuracy: 34.9694%, Training Loss: 1.3285%\n",
      "Epoch [3/300], Step [185/225], Training Accuracy: 35.0253%, Training Loss: 1.3280%\n",
      "Epoch [3/300], Step [186/225], Training Accuracy: 35.0554%, Training Loss: 1.3280%\n",
      "Epoch [3/300], Step [187/225], Training Accuracy: 35.0936%, Training Loss: 1.3277%\n",
      "Epoch [3/300], Step [188/225], Training Accuracy: 35.1313%, Training Loss: 1.3273%\n",
      "Epoch [3/300], Step [189/225], Training Accuracy: 35.1521%, Training Loss: 1.3265%\n",
      "Epoch [3/300], Step [190/225], Training Accuracy: 35.1069%, Training Loss: 1.3270%\n",
      "Epoch [3/300], Step [191/225], Training Accuracy: 35.1113%, Training Loss: 1.3272%\n",
      "Epoch [3/300], Step [192/225], Training Accuracy: 35.0911%, Training Loss: 1.3268%\n",
      "Epoch [3/300], Step [193/225], Training Accuracy: 35.0793%, Training Loss: 1.3268%\n",
      "Epoch [3/300], Step [194/225], Training Accuracy: 35.0999%, Training Loss: 1.3264%\n",
      "Epoch [3/300], Step [195/225], Training Accuracy: 35.0962%, Training Loss: 1.3266%\n",
      "Epoch [3/300], Step [196/225], Training Accuracy: 35.0925%, Training Loss: 1.3265%\n",
      "Epoch [3/300], Step [197/225], Training Accuracy: 35.0730%, Training Loss: 1.3271%\n",
      "Epoch [3/300], Step [198/225], Training Accuracy: 35.0852%, Training Loss: 1.3263%\n",
      "Epoch [3/300], Step [199/225], Training Accuracy: 35.0817%, Training Loss: 1.3262%\n",
      "Epoch [3/300], Step [200/225], Training Accuracy: 35.0625%, Training Loss: 1.3261%\n",
      "Epoch [3/300], Step [201/225], Training Accuracy: 35.0824%, Training Loss: 1.3261%\n",
      "Epoch [3/300], Step [202/225], Training Accuracy: 35.1176%, Training Loss: 1.3261%\n",
      "Epoch [3/300], Step [203/225], Training Accuracy: 35.1062%, Training Loss: 1.3264%\n",
      "Epoch [3/300], Step [204/225], Training Accuracy: 35.0873%, Training Loss: 1.3266%\n",
      "Epoch [3/300], Step [205/225], Training Accuracy: 35.1220%, Training Loss: 1.3262%\n",
      "Epoch [3/300], Step [206/225], Training Accuracy: 35.1183%, Training Loss: 1.3261%\n",
      "Epoch [3/300], Step [207/225], Training Accuracy: 35.1298%, Training Loss: 1.3261%\n",
      "Epoch [3/300], Step [208/225], Training Accuracy: 35.1788%, Training Loss: 1.3258%\n",
      "Epoch [3/300], Step [209/225], Training Accuracy: 35.2048%, Training Loss: 1.3255%\n",
      "Epoch [3/300], Step [210/225], Training Accuracy: 35.2158%, Training Loss: 1.3255%\n",
      "Epoch [3/300], Step [211/225], Training Accuracy: 35.1896%, Training Loss: 1.3254%\n",
      "Epoch [3/300], Step [212/225], Training Accuracy: 35.1931%, Training Loss: 1.3251%\n",
      "Epoch [3/300], Step [213/225], Training Accuracy: 35.1673%, Training Loss: 1.3251%\n",
      "Epoch [3/300], Step [214/225], Training Accuracy: 35.1416%, Training Loss: 1.3250%\n",
      "Epoch [3/300], Step [215/225], Training Accuracy: 35.1599%, Training Loss: 1.3250%\n",
      "Epoch [3/300], Step [216/225], Training Accuracy: 35.1562%, Training Loss: 1.3251%\n",
      "Epoch [3/300], Step [217/225], Training Accuracy: 35.1743%, Training Loss: 1.3247%\n",
      "Epoch [3/300], Step [218/225], Training Accuracy: 35.1849%, Training Loss: 1.3247%\n",
      "Epoch [3/300], Step [219/225], Training Accuracy: 35.1455%, Training Loss: 1.3245%\n",
      "Epoch [3/300], Step [220/225], Training Accuracy: 35.1634%, Training Loss: 1.3242%\n",
      "Epoch [3/300], Step [221/225], Training Accuracy: 35.1386%, Training Loss: 1.3245%\n",
      "Epoch [3/300], Step [222/225], Training Accuracy: 35.1492%, Training Loss: 1.3244%\n",
      "Epoch [3/300], Step [223/225], Training Accuracy: 35.1808%, Training Loss: 1.3245%\n",
      "Epoch [3/300], Step [224/225], Training Accuracy: 35.2190%, Training Loss: 1.3242%\n",
      "Epoch [3/300], Step [225/225], Training Accuracy: 35.2349%, Training Loss: 1.3244%\n",
      "Epoch [4/300], Step [1/225], Training Accuracy: 34.3750%, Training Loss: 1.3423%\n",
      "Epoch [4/300], Step [2/225], Training Accuracy: 32.8125%, Training Loss: 1.3202%\n",
      "Epoch [4/300], Step [3/225], Training Accuracy: 33.8542%, Training Loss: 1.3104%\n",
      "Epoch [4/300], Step [4/225], Training Accuracy: 35.1562%, Training Loss: 1.2933%\n",
      "Epoch [4/300], Step [5/225], Training Accuracy: 33.7500%, Training Loss: 1.3041%\n",
      "Epoch [4/300], Step [6/225], Training Accuracy: 35.9375%, Training Loss: 1.2978%\n",
      "Epoch [4/300], Step [7/225], Training Accuracy: 35.9375%, Training Loss: 1.3082%\n",
      "Epoch [4/300], Step [8/225], Training Accuracy: 35.5469%, Training Loss: 1.3095%\n",
      "Epoch [4/300], Step [9/225], Training Accuracy: 35.5903%, Training Loss: 1.2985%\n",
      "Epoch [4/300], Step [10/225], Training Accuracy: 36.4062%, Training Loss: 1.2947%\n",
      "Epoch [4/300], Step [11/225], Training Accuracy: 36.2216%, Training Loss: 1.2924%\n",
      "Epoch [4/300], Step [12/225], Training Accuracy: 36.8490%, Training Loss: 1.2910%\n",
      "Epoch [4/300], Step [13/225], Training Accuracy: 36.8990%, Training Loss: 1.2915%\n",
      "Epoch [4/300], Step [14/225], Training Accuracy: 36.7188%, Training Loss: 1.2937%\n",
      "Epoch [4/300], Step [15/225], Training Accuracy: 36.1458%, Training Loss: 1.3024%\n",
      "Epoch [4/300], Step [16/225], Training Accuracy: 36.1328%, Training Loss: 1.3027%\n",
      "Epoch [4/300], Step [17/225], Training Accuracy: 36.5809%, Training Loss: 1.2993%\n",
      "Epoch [4/300], Step [18/225], Training Accuracy: 36.1979%, Training Loss: 1.3007%\n",
      "Epoch [4/300], Step [19/225], Training Accuracy: 36.0197%, Training Loss: 1.3014%\n",
      "Epoch [4/300], Step [20/225], Training Accuracy: 36.2500%, Training Loss: 1.2969%\n",
      "Epoch [4/300], Step [21/225], Training Accuracy: 36.2351%, Training Loss: 1.2943%\n",
      "Epoch [4/300], Step [22/225], Training Accuracy: 36.2216%, Training Loss: 1.2928%\n",
      "Epoch [4/300], Step [23/225], Training Accuracy: 36.5489%, Training Loss: 1.2899%\n",
      "Epoch [4/300], Step [24/225], Training Accuracy: 36.6536%, Training Loss: 1.2895%\n",
      "Epoch [4/300], Step [25/225], Training Accuracy: 36.6250%, Training Loss: 1.2891%\n",
      "Epoch [4/300], Step [26/225], Training Accuracy: 36.6587%, Training Loss: 1.2937%\n",
      "Epoch [4/300], Step [27/225], Training Accuracy: 36.2269%, Training Loss: 1.2956%\n",
      "Epoch [4/300], Step [28/225], Training Accuracy: 36.2723%, Training Loss: 1.2935%\n",
      "Epoch [4/300], Step [29/225], Training Accuracy: 36.5302%, Training Loss: 1.2910%\n",
      "Epoch [4/300], Step [30/225], Training Accuracy: 36.8229%, Training Loss: 1.2917%\n",
      "Epoch [4/300], Step [31/225], Training Accuracy: 36.8952%, Training Loss: 1.2929%\n",
      "Epoch [4/300], Step [32/225], Training Accuracy: 37.1094%, Training Loss: 1.2895%\n",
      "Epoch [4/300], Step [33/225], Training Accuracy: 37.2633%, Training Loss: 1.2879%\n",
      "Epoch [4/300], Step [34/225], Training Accuracy: 37.3162%, Training Loss: 1.2872%\n",
      "Epoch [4/300], Step [35/225], Training Accuracy: 37.3214%, Training Loss: 1.2863%\n",
      "Epoch [4/300], Step [36/225], Training Accuracy: 37.3698%, Training Loss: 1.2868%\n",
      "Epoch [4/300], Step [37/225], Training Accuracy: 37.2466%, Training Loss: 1.2885%\n",
      "Epoch [4/300], Step [38/225], Training Accuracy: 37.2944%, Training Loss: 1.2875%\n",
      "Epoch [4/300], Step [39/225], Training Accuracy: 37.2196%, Training Loss: 1.2866%\n",
      "Epoch [4/300], Step [40/225], Training Accuracy: 37.1875%, Training Loss: 1.2878%\n",
      "Epoch [4/300], Step [41/225], Training Accuracy: 37.2713%, Training Loss: 1.2877%\n",
      "Epoch [4/300], Step [42/225], Training Accuracy: 37.2396%, Training Loss: 1.2875%\n",
      "Epoch [4/300], Step [43/225], Training Accuracy: 37.2456%, Training Loss: 1.2879%\n",
      "Epoch [4/300], Step [44/225], Training Accuracy: 37.4645%, Training Loss: 1.2858%\n",
      "Epoch [4/300], Step [45/225], Training Accuracy: 37.6736%, Training Loss: 1.2840%\n",
      "Epoch [4/300], Step [46/225], Training Accuracy: 37.7038%, Training Loss: 1.2828%\n",
      "Epoch [4/300], Step [47/225], Training Accuracy: 37.6995%, Training Loss: 1.2822%\n",
      "Epoch [4/300], Step [48/225], Training Accuracy: 37.6302%, Training Loss: 1.2821%\n",
      "Epoch [4/300], Step [49/225], Training Accuracy: 37.5319%, Training Loss: 1.2838%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/300], Step [50/225], Training Accuracy: 37.4688%, Training Loss: 1.2841%\n",
      "Epoch [4/300], Step [51/225], Training Accuracy: 37.6225%, Training Loss: 1.2836%\n",
      "Epoch [4/300], Step [52/225], Training Accuracy: 37.7404%, Training Loss: 1.2834%\n",
      "Epoch [4/300], Step [53/225], Training Accuracy: 37.7358%, Training Loss: 1.2827%\n",
      "Epoch [4/300], Step [54/225], Training Accuracy: 37.8472%, Training Loss: 1.2819%\n",
      "Epoch [4/300], Step [55/225], Training Accuracy: 37.7557%, Training Loss: 1.2823%\n",
      "Epoch [4/300], Step [56/225], Training Accuracy: 37.6395%, Training Loss: 1.2823%\n",
      "Epoch [4/300], Step [57/225], Training Accuracy: 37.7741%, Training Loss: 1.2801%\n",
      "Epoch [4/300], Step [58/225], Training Accuracy: 37.7694%, Training Loss: 1.2794%\n",
      "Epoch [4/300], Step [59/225], Training Accuracy: 37.9237%, Training Loss: 1.2777%\n",
      "Epoch [4/300], Step [60/225], Training Accuracy: 37.8646%, Training Loss: 1.2768%\n",
      "Epoch [4/300], Step [61/225], Training Accuracy: 37.8330%, Training Loss: 1.2764%\n",
      "Epoch [4/300], Step [62/225], Training Accuracy: 38.0292%, Training Loss: 1.2754%\n",
      "Epoch [4/300], Step [63/225], Training Accuracy: 37.9216%, Training Loss: 1.2762%\n",
      "Epoch [4/300], Step [64/225], Training Accuracy: 37.7930%, Training Loss: 1.2804%\n",
      "Epoch [4/300], Step [65/225], Training Accuracy: 37.8606%, Training Loss: 1.2814%\n",
      "Epoch [4/300], Step [66/225], Training Accuracy: 37.8078%, Training Loss: 1.2805%\n",
      "Epoch [4/300], Step [67/225], Training Accuracy: 37.9431%, Training Loss: 1.2788%\n",
      "Epoch [4/300], Step [68/225], Training Accuracy: 38.0055%, Training Loss: 1.2782%\n",
      "Epoch [4/300], Step [69/225], Training Accuracy: 37.9982%, Training Loss: 1.2772%\n",
      "Epoch [4/300], Step [70/225], Training Accuracy: 37.9911%, Training Loss: 1.2775%\n",
      "Epoch [4/300], Step [71/225], Training Accuracy: 37.8741%, Training Loss: 1.2785%\n",
      "Epoch [4/300], Step [72/225], Training Accuracy: 37.9123%, Training Loss: 1.2796%\n",
      "Epoch [4/300], Step [73/225], Training Accuracy: 37.9709%, Training Loss: 1.2801%\n",
      "Epoch [4/300], Step [74/225], Training Accuracy: 37.9645%, Training Loss: 1.2796%\n",
      "Epoch [4/300], Step [75/225], Training Accuracy: 37.9792%, Training Loss: 1.2787%\n",
      "Epoch [4/300], Step [76/225], Training Accuracy: 38.0551%, Training Loss: 1.2784%\n",
      "Epoch [4/300], Step [77/225], Training Accuracy: 38.0885%, Training Loss: 1.2786%\n",
      "Epoch [4/300], Step [78/225], Training Accuracy: 38.1410%, Training Loss: 1.2776%\n",
      "Epoch [4/300], Step [79/225], Training Accuracy: 38.0934%, Training Loss: 1.2779%\n",
      "Epoch [4/300], Step [80/225], Training Accuracy: 37.9492%, Training Loss: 1.2784%\n",
      "Epoch [4/300], Step [81/225], Training Accuracy: 38.0401%, Training Loss: 1.2781%\n",
      "Epoch [4/300], Step [82/225], Training Accuracy: 37.9573%, Training Loss: 1.2794%\n",
      "Epoch [4/300], Step [83/225], Training Accuracy: 38.0459%, Training Loss: 1.2789%\n",
      "Epoch [4/300], Step [84/225], Training Accuracy: 38.0022%, Training Loss: 1.2789%\n",
      "Epoch [4/300], Step [85/225], Training Accuracy: 37.9412%, Training Loss: 1.2800%\n",
      "Epoch [4/300], Step [86/225], Training Accuracy: 37.9542%, Training Loss: 1.2795%\n",
      "Epoch [4/300], Step [87/225], Training Accuracy: 38.0029%, Training Loss: 1.2787%\n",
      "Epoch [4/300], Step [88/225], Training Accuracy: 37.9794%, Training Loss: 1.2792%\n",
      "Epoch [4/300], Step [89/225], Training Accuracy: 37.9038%, Training Loss: 1.2809%\n",
      "Epoch [4/300], Step [90/225], Training Accuracy: 37.8125%, Training Loss: 1.2808%\n",
      "Epoch [4/300], Step [91/225], Training Accuracy: 37.8262%, Training Loss: 1.2804%\n",
      "Epoch [4/300], Step [92/225], Training Accuracy: 37.8397%, Training Loss: 1.2802%\n",
      "Epoch [4/300], Step [93/225], Training Accuracy: 37.8192%, Training Loss: 1.2801%\n",
      "Epoch [4/300], Step [94/225], Training Accuracy: 37.9156%, Training Loss: 1.2785%\n",
      "Epoch [4/300], Step [95/225], Training Accuracy: 37.6809%, Training Loss: 1.2796%\n",
      "Epoch [4/300], Step [96/225], Training Accuracy: 37.7604%, Training Loss: 1.2787%\n",
      "Epoch [4/300], Step [97/225], Training Accuracy: 37.9027%, Training Loss: 1.2773%\n",
      "Epoch [4/300], Step [98/225], Training Accuracy: 37.9305%, Training Loss: 1.2770%\n",
      "Epoch [4/300], Step [99/225], Training Accuracy: 38.0524%, Training Loss: 1.2762%\n",
      "Epoch [4/300], Step [100/225], Training Accuracy: 38.0156%, Training Loss: 1.2760%\n",
      "Epoch [4/300], Step [101/225], Training Accuracy: 38.0879%, Training Loss: 1.2755%\n",
      "Epoch [4/300], Step [102/225], Training Accuracy: 37.9902%, Training Loss: 1.2760%\n",
      "Epoch [4/300], Step [103/225], Training Accuracy: 38.0158%, Training Loss: 1.2758%\n",
      "Epoch [4/300], Step [104/225], Training Accuracy: 38.0409%, Training Loss: 1.2757%\n",
      "Epoch [4/300], Step [105/225], Training Accuracy: 38.0357%, Training Loss: 1.2752%\n",
      "Epoch [4/300], Step [106/225], Training Accuracy: 38.0896%, Training Loss: 1.2745%\n",
      "Epoch [4/300], Step [107/225], Training Accuracy: 38.1133%, Training Loss: 1.2742%\n",
      "Epoch [4/300], Step [108/225], Training Accuracy: 38.0932%, Training Loss: 1.2735%\n",
      "Epoch [4/300], Step [109/225], Training Accuracy: 38.2024%, Training Loss: 1.2729%\n",
      "Epoch [4/300], Step [110/225], Training Accuracy: 38.3381%, Training Loss: 1.2725%\n",
      "Epoch [4/300], Step [111/225], Training Accuracy: 38.3868%, Training Loss: 1.2723%\n",
      "Epoch [4/300], Step [112/225], Training Accuracy: 38.4068%, Training Loss: 1.2719%\n",
      "Epoch [4/300], Step [113/225], Training Accuracy: 38.3435%, Training Loss: 1.2724%\n",
      "Epoch [4/300], Step [114/225], Training Accuracy: 38.3498%, Training Loss: 1.2710%\n",
      "Epoch [4/300], Step [115/225], Training Accuracy: 38.3560%, Training Loss: 1.2706%\n",
      "Epoch [4/300], Step [116/225], Training Accuracy: 38.3351%, Training Loss: 1.2708%\n",
      "Epoch [4/300], Step [117/225], Training Accuracy: 38.2612%, Training Loss: 1.2725%\n",
      "Epoch [4/300], Step [118/225], Training Accuracy: 38.3342%, Training Loss: 1.2720%\n",
      "Epoch [4/300], Step [119/225], Training Accuracy: 38.3666%, Training Loss: 1.2717%\n",
      "Epoch [4/300], Step [120/225], Training Accuracy: 38.3984%, Training Loss: 1.2716%\n",
      "Epoch [4/300], Step [121/225], Training Accuracy: 38.3523%, Training Loss: 1.2723%\n",
      "Epoch [4/300], Step [122/225], Training Accuracy: 38.3837%, Training Loss: 1.2721%\n",
      "Epoch [4/300], Step [123/225], Training Accuracy: 38.3257%, Training Loss: 1.2727%\n",
      "Epoch [4/300], Step [124/225], Training Accuracy: 38.3947%, Training Loss: 1.2720%\n",
      "Epoch [4/300], Step [125/225], Training Accuracy: 38.3875%, Training Loss: 1.2723%\n",
      "Epoch [4/300], Step [126/225], Training Accuracy: 38.3557%, Training Loss: 1.2724%\n",
      "Epoch [4/300], Step [127/225], Training Accuracy: 38.3120%, Training Loss: 1.2725%\n",
      "Epoch [4/300], Step [128/225], Training Accuracy: 38.2690%, Training Loss: 1.2725%\n",
      "Epoch [4/300], Step [129/225], Training Accuracy: 38.2873%, Training Loss: 1.2723%\n",
      "Epoch [4/300], Step [130/225], Training Accuracy: 38.2812%, Training Loss: 1.2722%\n",
      "Epoch [4/300], Step [131/225], Training Accuracy: 38.2872%, Training Loss: 1.2718%\n",
      "Epoch [4/300], Step [132/225], Training Accuracy: 38.2931%, Training Loss: 1.2714%\n",
      "Epoch [4/300], Step [133/225], Training Accuracy: 38.3224%, Training Loss: 1.2706%\n",
      "Epoch [4/300], Step [134/225], Training Accuracy: 38.2579%, Training Loss: 1.2711%\n",
      "Epoch [4/300], Step [135/225], Training Accuracy: 38.2292%, Training Loss: 1.2715%\n",
      "Epoch [4/300], Step [136/225], Training Accuracy: 38.2238%, Training Loss: 1.2715%\n",
      "Epoch [4/300], Step [137/225], Training Accuracy: 38.1957%, Training Loss: 1.2709%\n",
      "Epoch [4/300], Step [138/225], Training Accuracy: 38.2246%, Training Loss: 1.2709%\n",
      "Epoch [4/300], Step [139/225], Training Accuracy: 38.2419%, Training Loss: 1.2707%\n",
      "Epoch [4/300], Step [140/225], Training Accuracy: 38.2701%, Training Loss: 1.2706%\n",
      "Epoch [4/300], Step [141/225], Training Accuracy: 38.2314%, Training Loss: 1.2707%\n",
      "Epoch [4/300], Step [142/225], Training Accuracy: 38.2702%, Training Loss: 1.2703%\n",
      "Epoch [4/300], Step [143/225], Training Accuracy: 38.2649%, Training Loss: 1.2702%\n",
      "Epoch [4/300], Step [144/225], Training Accuracy: 38.3247%, Training Loss: 1.2704%\n",
      "Epoch [4/300], Step [145/225], Training Accuracy: 38.3405%, Training Loss: 1.2705%\n",
      "Epoch [4/300], Step [146/225], Training Accuracy: 38.3134%, Training Loss: 1.2706%\n",
      "Epoch [4/300], Step [147/225], Training Accuracy: 38.3822%, Training Loss: 1.2702%\n",
      "Epoch [4/300], Step [148/225], Training Accuracy: 38.4818%, Training Loss: 1.2694%\n",
      "Epoch [4/300], Step [149/225], Training Accuracy: 38.5277%, Training Loss: 1.2687%\n",
      "Epoch [4/300], Step [150/225], Training Accuracy: 38.5833%, Training Loss: 1.2682%\n",
      "Epoch [4/300], Step [151/225], Training Accuracy: 38.6072%, Training Loss: 1.2676%\n",
      "Epoch [4/300], Step [152/225], Training Accuracy: 38.5999%, Training Loss: 1.2676%\n",
      "Epoch [4/300], Step [153/225], Training Accuracy: 38.6029%, Training Loss: 1.2674%\n",
      "Epoch [4/300], Step [154/225], Training Accuracy: 38.5450%, Training Loss: 1.2676%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/300], Step [155/225], Training Accuracy: 38.5585%, Training Loss: 1.2678%\n",
      "Epoch [4/300], Step [156/225], Training Accuracy: 38.5216%, Training Loss: 1.2686%\n",
      "Epoch [4/300], Step [157/225], Training Accuracy: 38.5052%, Training Loss: 1.2686%\n",
      "Epoch [4/300], Step [158/225], Training Accuracy: 38.5384%, Training Loss: 1.2680%\n",
      "Epoch [4/300], Step [159/225], Training Accuracy: 38.5613%, Training Loss: 1.2680%\n",
      "Epoch [4/300], Step [160/225], Training Accuracy: 38.5840%, Training Loss: 1.2681%\n",
      "Epoch [4/300], Step [161/225], Training Accuracy: 38.6549%, Training Loss: 1.2675%\n",
      "Epoch [4/300], Step [162/225], Training Accuracy: 38.6671%, Training Loss: 1.2671%\n",
      "Epoch [4/300], Step [163/225], Training Accuracy: 38.7270%, Training Loss: 1.2663%\n",
      "Epoch [4/300], Step [164/225], Training Accuracy: 38.7671%, Training Loss: 1.2656%\n",
      "Epoch [4/300], Step [165/225], Training Accuracy: 38.7405%, Training Loss: 1.2667%\n",
      "Epoch [4/300], Step [166/225], Training Accuracy: 38.7707%, Training Loss: 1.2662%\n",
      "Epoch [4/300], Step [167/225], Training Accuracy: 38.8379%, Training Loss: 1.2656%\n",
      "Epoch [4/300], Step [168/225], Training Accuracy: 38.8393%, Training Loss: 1.2651%\n",
      "Epoch [4/300], Step [169/225], Training Accuracy: 38.8961%, Training Loss: 1.2645%\n",
      "Epoch [4/300], Step [170/225], Training Accuracy: 38.9062%, Training Loss: 1.2642%\n",
      "Epoch [4/300], Step [171/225], Training Accuracy: 38.9529%, Training Loss: 1.2635%\n",
      "Epoch [4/300], Step [172/225], Training Accuracy: 38.9081%, Training Loss: 1.2632%\n",
      "Epoch [4/300], Step [173/225], Training Accuracy: 38.9180%, Training Loss: 1.2634%\n",
      "Epoch [4/300], Step [174/225], Training Accuracy: 38.9278%, Training Loss: 1.2630%\n",
      "Epoch [4/300], Step [175/225], Training Accuracy: 38.8482%, Training Loss: 1.2632%\n",
      "Epoch [4/300], Step [176/225], Training Accuracy: 38.8494%, Training Loss: 1.2635%\n",
      "Epoch [4/300], Step [177/225], Training Accuracy: 38.8418%, Training Loss: 1.2631%\n",
      "Epoch [4/300], Step [178/225], Training Accuracy: 38.8430%, Training Loss: 1.2632%\n",
      "Epoch [4/300], Step [179/225], Training Accuracy: 38.8181%, Training Loss: 1.2635%\n",
      "Epoch [4/300], Step [180/225], Training Accuracy: 38.8715%, Training Loss: 1.2626%\n",
      "Epoch [4/300], Step [181/225], Training Accuracy: 38.8726%, Training Loss: 1.2630%\n",
      "Epoch [4/300], Step [182/225], Training Accuracy: 38.8908%, Training Loss: 1.2624%\n",
      "Epoch [4/300], Step [183/225], Training Accuracy: 38.8747%, Training Loss: 1.2623%\n",
      "Epoch [4/300], Step [184/225], Training Accuracy: 38.8672%, Training Loss: 1.2621%\n",
      "Epoch [4/300], Step [185/225], Training Accuracy: 38.9020%, Training Loss: 1.2615%\n",
      "Epoch [4/300], Step [186/225], Training Accuracy: 38.8945%, Training Loss: 1.2616%\n",
      "Epoch [4/300], Step [187/225], Training Accuracy: 38.8870%, Training Loss: 1.2616%\n",
      "Epoch [4/300], Step [188/225], Training Accuracy: 38.9046%, Training Loss: 1.2614%\n",
      "Epoch [4/300], Step [189/225], Training Accuracy: 38.9633%, Training Loss: 1.2606%\n",
      "Epoch [4/300], Step [190/225], Training Accuracy: 38.9638%, Training Loss: 1.2609%\n",
      "Epoch [4/300], Step [191/225], Training Accuracy: 38.9480%, Training Loss: 1.2610%\n",
      "Epoch [4/300], Step [192/225], Training Accuracy: 38.9648%, Training Loss: 1.2609%\n",
      "Epoch [4/300], Step [193/225], Training Accuracy: 38.9734%, Training Loss: 1.2607%\n",
      "Epoch [4/300], Step [194/225], Training Accuracy: 38.9739%, Training Loss: 1.2605%\n",
      "Epoch [4/300], Step [195/225], Training Accuracy: 39.0304%, Training Loss: 1.2599%\n",
      "Epoch [4/300], Step [196/225], Training Accuracy: 39.0386%, Training Loss: 1.2600%\n",
      "Epoch [4/300], Step [197/225], Training Accuracy: 39.0228%, Training Loss: 1.2604%\n",
      "Epoch [4/300], Step [198/225], Training Accuracy: 39.0862%, Training Loss: 1.2596%\n",
      "Epoch [4/300], Step [199/225], Training Accuracy: 39.1175%, Training Loss: 1.2592%\n",
      "Epoch [4/300], Step [200/225], Training Accuracy: 39.1016%, Training Loss: 1.2593%\n",
      "Epoch [4/300], Step [201/225], Training Accuracy: 39.1091%, Training Loss: 1.2591%\n",
      "Epoch [4/300], Step [202/225], Training Accuracy: 39.0934%, Training Loss: 1.2595%\n",
      "Epoch [4/300], Step [203/225], Training Accuracy: 39.0779%, Training Loss: 1.2596%\n",
      "Epoch [4/300], Step [204/225], Training Accuracy: 39.0625%, Training Loss: 1.2599%\n",
      "Epoch [4/300], Step [205/225], Training Accuracy: 39.0930%, Training Loss: 1.2597%\n",
      "Epoch [4/300], Step [206/225], Training Accuracy: 39.0777%, Training Loss: 1.2598%\n",
      "Epoch [4/300], Step [207/225], Training Accuracy: 39.0474%, Training Loss: 1.2598%\n",
      "Epoch [4/300], Step [208/225], Training Accuracy: 39.1226%, Training Loss: 1.2596%\n",
      "Epoch [4/300], Step [209/225], Training Accuracy: 39.1821%, Training Loss: 1.2592%\n",
      "Epoch [4/300], Step [210/225], Training Accuracy: 39.2039%, Training Loss: 1.2590%\n",
      "Epoch [4/300], Step [211/225], Training Accuracy: 39.1958%, Training Loss: 1.2588%\n",
      "Epoch [4/300], Step [212/225], Training Accuracy: 39.1952%, Training Loss: 1.2584%\n",
      "Epoch [4/300], Step [213/225], Training Accuracy: 39.1505%, Training Loss: 1.2588%\n",
      "Epoch [4/300], Step [214/225], Training Accuracy: 39.1282%, Training Loss: 1.2589%\n",
      "Epoch [4/300], Step [215/225], Training Accuracy: 39.1061%, Training Loss: 1.2592%\n",
      "Epoch [4/300], Step [216/225], Training Accuracy: 39.0480%, Training Loss: 1.2594%\n",
      "Epoch [4/300], Step [217/225], Training Accuracy: 39.0481%, Training Loss: 1.2588%\n",
      "Epoch [4/300], Step [218/225], Training Accuracy: 39.0338%, Training Loss: 1.2589%\n",
      "Epoch [4/300], Step [219/225], Training Accuracy: 39.0197%, Training Loss: 1.2584%\n",
      "Epoch [4/300], Step [220/225], Training Accuracy: 39.0270%, Training Loss: 1.2580%\n",
      "Epoch [4/300], Step [221/225], Training Accuracy: 39.0059%, Training Loss: 1.2583%\n",
      "Epoch [4/300], Step [222/225], Training Accuracy: 39.0273%, Training Loss: 1.2578%\n",
      "Epoch [4/300], Step [223/225], Training Accuracy: 39.0275%, Training Loss: 1.2578%\n",
      "Epoch [4/300], Step [224/225], Training Accuracy: 39.0416%, Training Loss: 1.2573%\n",
      "Epoch [4/300], Step [225/225], Training Accuracy: 39.0217%, Training Loss: 1.2581%\n",
      "Epoch [5/300], Step [1/225], Training Accuracy: 43.7500%, Training Loss: 1.2400%\n",
      "Epoch [5/300], Step [2/225], Training Accuracy: 40.6250%, Training Loss: 1.2504%\n",
      "Epoch [5/300], Step [3/225], Training Accuracy: 38.0208%, Training Loss: 1.2506%\n",
      "Epoch [5/300], Step [4/225], Training Accuracy: 40.6250%, Training Loss: 1.2267%\n",
      "Epoch [5/300], Step [5/225], Training Accuracy: 41.8750%, Training Loss: 1.2276%\n",
      "Epoch [5/300], Step [6/225], Training Accuracy: 42.1875%, Training Loss: 1.2305%\n",
      "Epoch [5/300], Step [7/225], Training Accuracy: 41.2946%, Training Loss: 1.2412%\n",
      "Epoch [5/300], Step [8/225], Training Accuracy: 41.2109%, Training Loss: 1.2441%\n",
      "Epoch [5/300], Step [9/225], Training Accuracy: 41.6667%, Training Loss: 1.2318%\n",
      "Epoch [5/300], Step [10/225], Training Accuracy: 41.2500%, Training Loss: 1.2337%\n",
      "Epoch [5/300], Step [11/225], Training Accuracy: 40.4830%, Training Loss: 1.2342%\n",
      "Epoch [5/300], Step [12/225], Training Accuracy: 40.6250%, Training Loss: 1.2333%\n",
      "Epoch [5/300], Step [13/225], Training Accuracy: 40.7452%, Training Loss: 1.2322%\n",
      "Epoch [5/300], Step [14/225], Training Accuracy: 41.1830%, Training Loss: 1.2287%\n",
      "Epoch [5/300], Step [15/225], Training Accuracy: 40.6250%, Training Loss: 1.2389%\n",
      "Epoch [5/300], Step [16/225], Training Accuracy: 40.7227%, Training Loss: 1.2393%\n",
      "Epoch [5/300], Step [17/225], Training Accuracy: 41.0846%, Training Loss: 1.2343%\n",
      "Epoch [5/300], Step [18/225], Training Accuracy: 40.7986%, Training Loss: 1.2369%\n",
      "Epoch [5/300], Step [19/225], Training Accuracy: 40.6250%, Training Loss: 1.2389%\n",
      "Epoch [5/300], Step [20/225], Training Accuracy: 40.6250%, Training Loss: 1.2350%\n",
      "Epoch [5/300], Step [21/225], Training Accuracy: 40.8482%, Training Loss: 1.2315%\n",
      "Epoch [5/300], Step [22/225], Training Accuracy: 40.6960%, Training Loss: 1.2303%\n",
      "Epoch [5/300], Step [23/225], Training Accuracy: 40.8288%, Training Loss: 1.2265%\n",
      "Epoch [5/300], Step [24/225], Training Accuracy: 41.1458%, Training Loss: 1.2238%\n",
      "Epoch [5/300], Step [25/225], Training Accuracy: 41.4375%, Training Loss: 1.2190%\n",
      "Epoch [5/300], Step [26/225], Training Accuracy: 41.2861%, Training Loss: 1.2224%\n",
      "Epoch [5/300], Step [27/225], Training Accuracy: 40.9144%, Training Loss: 1.2277%\n",
      "Epoch [5/300], Step [28/225], Training Accuracy: 40.6808%, Training Loss: 1.2302%\n",
      "Epoch [5/300], Step [29/225], Training Accuracy: 40.7866%, Training Loss: 1.2282%\n",
      "Epoch [5/300], Step [30/225], Training Accuracy: 40.9375%, Training Loss: 1.2269%\n",
      "Epoch [5/300], Step [31/225], Training Accuracy: 40.9274%, Training Loss: 1.2270%\n",
      "Epoch [5/300], Step [32/225], Training Accuracy: 40.7715%, Training Loss: 1.2242%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/300], Step [33/225], Training Accuracy: 40.8617%, Training Loss: 1.2221%\n",
      "Epoch [5/300], Step [34/225], Training Accuracy: 40.8548%, Training Loss: 1.2229%\n",
      "Epoch [5/300], Step [35/225], Training Accuracy: 40.7589%, Training Loss: 1.2225%\n",
      "Epoch [5/300], Step [36/225], Training Accuracy: 40.5816%, Training Loss: 1.2228%\n",
      "Epoch [5/300], Step [37/225], Training Accuracy: 40.6672%, Training Loss: 1.2217%\n",
      "Epoch [5/300], Step [38/225], Training Accuracy: 40.8717%, Training Loss: 1.2201%\n",
      "Epoch [5/300], Step [39/225], Training Accuracy: 41.0657%, Training Loss: 1.2178%\n",
      "Epoch [5/300], Step [40/225], Training Accuracy: 40.8203%, Training Loss: 1.2181%\n",
      "Epoch [5/300], Step [41/225], Training Accuracy: 40.8155%, Training Loss: 1.2172%\n",
      "Epoch [5/300], Step [42/225], Training Accuracy: 40.8854%, Training Loss: 1.2167%\n",
      "Epoch [5/300], Step [43/225], Training Accuracy: 40.9157%, Training Loss: 1.2157%\n",
      "Epoch [5/300], Step [44/225], Training Accuracy: 41.1222%, Training Loss: 1.2129%\n",
      "Epoch [5/300], Step [45/225], Training Accuracy: 41.4583%, Training Loss: 1.2111%\n",
      "Epoch [5/300], Step [46/225], Training Accuracy: 41.5761%, Training Loss: 1.2100%\n",
      "Epoch [5/300], Step [47/225], Training Accuracy: 41.6223%, Training Loss: 1.2092%\n",
      "Epoch [5/300], Step [48/225], Training Accuracy: 41.5039%, Training Loss: 1.2087%\n",
      "Epoch [5/300], Step [49/225], Training Accuracy: 41.3265%, Training Loss: 1.2110%\n",
      "Epoch [5/300], Step [50/225], Training Accuracy: 41.2500%, Training Loss: 1.2102%\n",
      "Epoch [5/300], Step [51/225], Training Accuracy: 41.3603%, Training Loss: 1.2092%\n",
      "Epoch [5/300], Step [52/225], Training Accuracy: 41.5264%, Training Loss: 1.2092%\n",
      "Epoch [5/300], Step [53/225], Training Accuracy: 41.4210%, Training Loss: 1.2115%\n",
      "Epoch [5/300], Step [54/225], Training Accuracy: 41.2326%, Training Loss: 1.2126%\n",
      "Epoch [5/300], Step [55/225], Training Accuracy: 41.2784%, Training Loss: 1.2119%\n",
      "Epoch [5/300], Step [56/225], Training Accuracy: 40.9877%, Training Loss: 1.2145%\n",
      "Epoch [5/300], Step [57/225], Training Accuracy: 40.9814%, Training Loss: 1.2142%\n",
      "Epoch [5/300], Step [58/225], Training Accuracy: 40.9213%, Training Loss: 1.2140%\n",
      "Epoch [5/300], Step [59/225], Training Accuracy: 40.8104%, Training Loss: 1.2133%\n",
      "Epoch [5/300], Step [60/225], Training Accuracy: 40.7552%, Training Loss: 1.2128%\n",
      "Epoch [5/300], Step [61/225], Training Accuracy: 40.8043%, Training Loss: 1.2122%\n",
      "Epoch [5/300], Step [62/225], Training Accuracy: 40.8014%, Training Loss: 1.2128%\n",
      "Epoch [5/300], Step [63/225], Training Accuracy: 40.6498%, Training Loss: 1.2152%\n",
      "Epoch [5/300], Step [64/225], Training Accuracy: 40.5762%, Training Loss: 1.2184%\n",
      "Epoch [5/300], Step [65/225], Training Accuracy: 40.5048%, Training Loss: 1.2206%\n",
      "Epoch [5/300], Step [66/225], Training Accuracy: 40.6487%, Training Loss: 1.2191%\n",
      "Epoch [5/300], Step [67/225], Training Accuracy: 40.7882%, Training Loss: 1.2178%\n",
      "Epoch [5/300], Step [68/225], Training Accuracy: 40.8318%, Training Loss: 1.2172%\n",
      "Epoch [5/300], Step [69/225], Training Accuracy: 40.7835%, Training Loss: 1.2167%\n",
      "Epoch [5/300], Step [70/225], Training Accuracy: 40.8929%, Training Loss: 1.2168%\n",
      "Epoch [5/300], Step [71/225], Training Accuracy: 40.8231%, Training Loss: 1.2174%\n",
      "Epoch [5/300], Step [72/225], Training Accuracy: 40.7986%, Training Loss: 1.2185%\n",
      "Epoch [5/300], Step [73/225], Training Accuracy: 40.7748%, Training Loss: 1.2194%\n",
      "Epoch [5/300], Step [74/225], Training Accuracy: 40.9206%, Training Loss: 1.2190%\n",
      "Epoch [5/300], Step [75/225], Training Accuracy: 40.9792%, Training Loss: 1.2179%\n",
      "Epoch [5/300], Step [76/225], Training Accuracy: 40.9745%, Training Loss: 1.2185%\n",
      "Epoch [5/300], Step [77/225], Training Accuracy: 40.9700%, Training Loss: 1.2183%\n",
      "Epoch [5/300], Step [78/225], Training Accuracy: 41.1058%, Training Loss: 1.2172%\n",
      "Epoch [5/300], Step [79/225], Training Accuracy: 41.0997%, Training Loss: 1.2171%\n",
      "Epoch [5/300], Step [80/225], Training Accuracy: 40.9766%, Training Loss: 1.2167%\n",
      "Epoch [5/300], Step [81/225], Training Accuracy: 40.9722%, Training Loss: 1.2169%\n",
      "Epoch [5/300], Step [82/225], Training Accuracy: 40.8727%, Training Loss: 1.2178%\n",
      "Epoch [5/300], Step [83/225], Training Accuracy: 40.8886%, Training Loss: 1.2178%\n",
      "Epoch [5/300], Step [84/225], Training Accuracy: 40.8110%, Training Loss: 1.2176%\n",
      "Epoch [5/300], Step [85/225], Training Accuracy: 40.7353%, Training Loss: 1.2175%\n",
      "Epoch [5/300], Step [86/225], Training Accuracy: 40.8430%, Training Loss: 1.2165%\n",
      "Epoch [5/300], Step [87/225], Training Accuracy: 40.8405%, Training Loss: 1.2164%\n",
      "Epoch [5/300], Step [88/225], Training Accuracy: 40.7493%, Training Loss: 1.2172%\n",
      "Epoch [5/300], Step [89/225], Training Accuracy: 40.6777%, Training Loss: 1.2182%\n",
      "Epoch [5/300], Step [90/225], Training Accuracy: 40.7292%, Training Loss: 1.2178%\n",
      "Epoch [5/300], Step [91/225], Training Accuracy: 40.7967%, Training Loss: 1.2169%\n",
      "Epoch [5/300], Step [92/225], Training Accuracy: 40.8458%, Training Loss: 1.2162%\n",
      "Epoch [5/300], Step [93/225], Training Accuracy: 40.8938%, Training Loss: 1.2157%\n",
      "Epoch [5/300], Step [94/225], Training Accuracy: 41.0073%, Training Loss: 1.2136%\n",
      "Epoch [5/300], Step [95/225], Training Accuracy: 40.9375%, Training Loss: 1.2139%\n",
      "Epoch [5/300], Step [96/225], Training Accuracy: 41.0156%, Training Loss: 1.2128%\n",
      "Epoch [5/300], Step [97/225], Training Accuracy: 41.1727%, Training Loss: 1.2119%\n",
      "Epoch [5/300], Step [98/225], Training Accuracy: 41.1511%, Training Loss: 1.2125%\n",
      "Epoch [5/300], Step [99/225], Training Accuracy: 41.1774%, Training Loss: 1.2120%\n",
      "Epoch [5/300], Step [100/225], Training Accuracy: 41.2188%, Training Loss: 1.2117%\n",
      "Epoch [5/300], Step [101/225], Training Accuracy: 41.2438%, Training Loss: 1.2113%\n",
      "Epoch [5/300], Step [102/225], Training Accuracy: 41.2224%, Training Loss: 1.2112%\n",
      "Epoch [5/300], Step [103/225], Training Accuracy: 41.2470%, Training Loss: 1.2109%\n",
      "Epoch [5/300], Step [104/225], Training Accuracy: 41.2410%, Training Loss: 1.2110%\n",
      "Epoch [5/300], Step [105/225], Training Accuracy: 41.3095%, Training Loss: 1.2100%\n",
      "Epoch [5/300], Step [106/225], Training Accuracy: 41.4062%, Training Loss: 1.2092%\n",
      "Epoch [5/300], Step [107/225], Training Accuracy: 41.3989%, Training Loss: 1.2089%\n",
      "Epoch [5/300], Step [108/225], Training Accuracy: 41.3194%, Training Loss: 1.2083%\n",
      "Epoch [5/300], Step [109/225], Training Accuracy: 41.3131%, Training Loss: 1.2081%\n",
      "Epoch [5/300], Step [110/225], Training Accuracy: 41.3494%, Training Loss: 1.2075%\n",
      "Epoch [5/300], Step [111/225], Training Accuracy: 41.3429%, Training Loss: 1.2077%\n",
      "Epoch [5/300], Step [112/225], Training Accuracy: 41.4621%, Training Loss: 1.2071%\n",
      "Epoch [5/300], Step [113/225], Training Accuracy: 41.4270%, Training Loss: 1.2074%\n",
      "Epoch [5/300], Step [114/225], Training Accuracy: 41.4200%, Training Loss: 1.2063%\n",
      "Epoch [5/300], Step [115/225], Training Accuracy: 41.5082%, Training Loss: 1.2056%\n",
      "Epoch [5/300], Step [116/225], Training Accuracy: 41.4332%, Training Loss: 1.2058%\n",
      "Epoch [5/300], Step [117/225], Training Accuracy: 41.3462%, Training Loss: 1.2066%\n",
      "Epoch [5/300], Step [118/225], Training Accuracy: 41.3533%, Training Loss: 1.2058%\n",
      "Epoch [5/300], Step [119/225], Training Accuracy: 41.2684%, Training Loss: 1.2055%\n",
      "Epoch [5/300], Step [120/225], Training Accuracy: 41.3151%, Training Loss: 1.2050%\n",
      "Epoch [5/300], Step [121/225], Training Accuracy: 41.3223%, Training Loss: 1.2046%\n",
      "Epoch [5/300], Step [122/225], Training Accuracy: 41.3550%, Training Loss: 1.2047%\n",
      "Epoch [5/300], Step [123/225], Training Accuracy: 41.2983%, Training Loss: 1.2047%\n",
      "Epoch [5/300], Step [124/225], Training Accuracy: 41.3306%, Training Loss: 1.2039%\n",
      "Epoch [5/300], Step [125/225], Training Accuracy: 41.2875%, Training Loss: 1.2048%\n",
      "Epoch [5/300], Step [126/225], Training Accuracy: 41.3070%, Training Loss: 1.2046%\n",
      "Epoch [5/300], Step [127/225], Training Accuracy: 41.2525%, Training Loss: 1.2047%\n",
      "Epoch [5/300], Step [128/225], Training Accuracy: 41.1987%, Training Loss: 1.2046%\n",
      "Epoch [5/300], Step [129/225], Training Accuracy: 41.1579%, Training Loss: 1.2042%\n",
      "Epoch [5/300], Step [130/225], Training Accuracy: 41.1298%, Training Loss: 1.2044%\n",
      "Epoch [5/300], Step [131/225], Training Accuracy: 41.1260%, Training Loss: 1.2047%\n",
      "Epoch [5/300], Step [132/225], Training Accuracy: 41.0866%, Training Loss: 1.2043%\n",
      "Epoch [5/300], Step [133/225], Training Accuracy: 41.1067%, Training Loss: 1.2041%\n",
      "Epoch [5/300], Step [134/225], Training Accuracy: 41.0098%, Training Loss: 1.2051%\n",
      "Epoch [5/300], Step [135/225], Training Accuracy: 41.0532%, Training Loss: 1.2052%\n",
      "Epoch [5/300], Step [136/225], Training Accuracy: 41.0041%, Training Loss: 1.2051%\n",
      "Epoch [5/300], Step [137/225], Training Accuracy: 41.0698%, Training Loss: 1.2046%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/300], Step [138/225], Training Accuracy: 41.0892%, Training Loss: 1.2045%\n",
      "Epoch [5/300], Step [139/225], Training Accuracy: 41.0746%, Training Loss: 1.2047%\n",
      "Epoch [5/300], Step [140/225], Training Accuracy: 41.0938%, Training Loss: 1.2052%\n",
      "Epoch [5/300], Step [141/225], Training Accuracy: 41.0793%, Training Loss: 1.2051%\n",
      "Epoch [5/300], Step [142/225], Training Accuracy: 41.1312%, Training Loss: 1.2048%\n",
      "Epoch [5/300], Step [143/225], Training Accuracy: 41.1713%, Training Loss: 1.2043%\n",
      "Epoch [5/300], Step [144/225], Training Accuracy: 41.2435%, Training Loss: 1.2042%\n",
      "Epoch [5/300], Step [145/225], Training Accuracy: 41.2392%, Training Loss: 1.2043%\n",
      "Epoch [5/300], Step [146/225], Training Accuracy: 41.2136%, Training Loss: 1.2047%\n",
      "Epoch [5/300], Step [147/225], Training Accuracy: 41.2521%, Training Loss: 1.2045%\n",
      "Epoch [5/300], Step [148/225], Training Accuracy: 41.3640%, Training Loss: 1.2038%\n",
      "Epoch [5/300], Step [149/225], Training Accuracy: 41.3591%, Training Loss: 1.2036%\n",
      "Epoch [5/300], Step [150/225], Training Accuracy: 41.4375%, Training Loss: 1.2028%\n",
      "Epoch [5/300], Step [151/225], Training Accuracy: 41.5046%, Training Loss: 1.2024%\n",
      "Epoch [5/300], Step [152/225], Training Accuracy: 41.5296%, Training Loss: 1.2022%\n",
      "Epoch [5/300], Step [153/225], Training Accuracy: 41.5441%, Training Loss: 1.2020%\n",
      "Epoch [5/300], Step [154/225], Training Accuracy: 41.5381%, Training Loss: 1.2018%\n",
      "Epoch [5/300], Step [155/225], Training Accuracy: 41.5222%, Training Loss: 1.2015%\n",
      "Epoch [5/300], Step [156/225], Training Accuracy: 41.5465%, Training Loss: 1.2021%\n",
      "Epoch [5/300], Step [157/225], Training Accuracy: 41.5207%, Training Loss: 1.2022%\n",
      "Epoch [5/300], Step [158/225], Training Accuracy: 41.4755%, Training Loss: 1.2020%\n",
      "Epoch [5/300], Step [159/225], Training Accuracy: 41.5291%, Training Loss: 1.2012%\n",
      "Epoch [5/300], Step [160/225], Training Accuracy: 41.5234%, Training Loss: 1.2015%\n",
      "Epoch [5/300], Step [161/225], Training Accuracy: 41.6537%, Training Loss: 1.2004%\n",
      "Epoch [5/300], Step [162/225], Training Accuracy: 41.7342%, Training Loss: 1.1995%\n",
      "Epoch [5/300], Step [163/225], Training Accuracy: 41.7465%, Training Loss: 1.1988%\n",
      "Epoch [5/300], Step [164/225], Training Accuracy: 41.7683%, Training Loss: 1.1983%\n",
      "Epoch [5/300], Step [165/225], Training Accuracy: 41.7898%, Training Loss: 1.1987%\n",
      "Epoch [5/300], Step [166/225], Training Accuracy: 41.8392%, Training Loss: 1.1980%\n",
      "Epoch [5/300], Step [167/225], Training Accuracy: 41.8507%, Training Loss: 1.1976%\n",
      "Epoch [5/300], Step [168/225], Training Accuracy: 41.8992%, Training Loss: 1.1969%\n",
      "Epoch [5/300], Step [169/225], Training Accuracy: 41.9009%, Training Loss: 1.1964%\n",
      "Epoch [5/300], Step [170/225], Training Accuracy: 41.8750%, Training Loss: 1.1960%\n",
      "Epoch [5/300], Step [171/225], Training Accuracy: 41.9225%, Training Loss: 1.1952%\n",
      "Epoch [5/300], Step [172/225], Training Accuracy: 41.9150%, Training Loss: 1.1948%\n",
      "Epoch [5/300], Step [173/225], Training Accuracy: 41.9436%, Training Loss: 1.1945%\n",
      "Epoch [5/300], Step [174/225], Training Accuracy: 41.9810%, Training Loss: 1.1941%\n",
      "Epoch [5/300], Step [175/225], Training Accuracy: 42.0536%, Training Loss: 1.1936%\n",
      "Epoch [5/300], Step [176/225], Training Accuracy: 42.0455%, Training Loss: 1.1938%\n",
      "Epoch [5/300], Step [177/225], Training Accuracy: 42.0904%, Training Loss: 1.1933%\n",
      "Epoch [5/300], Step [178/225], Training Accuracy: 42.0997%, Training Loss: 1.1932%\n",
      "Epoch [5/300], Step [179/225], Training Accuracy: 42.1264%, Training Loss: 1.1929%\n",
      "Epoch [5/300], Step [180/225], Training Accuracy: 42.1875%, Training Loss: 1.1923%\n",
      "Epoch [5/300], Step [181/225], Training Accuracy: 42.1530%, Training Loss: 1.1924%\n",
      "Epoch [5/300], Step [182/225], Training Accuracy: 42.1360%, Training Loss: 1.1925%\n",
      "Epoch [5/300], Step [183/225], Training Accuracy: 42.1533%, Training Loss: 1.1921%\n",
      "Epoch [5/300], Step [184/225], Training Accuracy: 42.1620%, Training Loss: 1.1916%\n",
      "Epoch [5/300], Step [185/225], Training Accuracy: 42.2044%, Training Loss: 1.1910%\n",
      "Epoch [5/300], Step [186/225], Training Accuracy: 42.1791%, Training Loss: 1.1910%\n",
      "Epoch [5/300], Step [187/225], Training Accuracy: 42.2042%, Training Loss: 1.1903%\n",
      "Epoch [5/300], Step [188/225], Training Accuracy: 42.2872%, Training Loss: 1.1894%\n",
      "Epoch [5/300], Step [189/225], Training Accuracy: 42.3115%, Training Loss: 1.1883%\n",
      "Epoch [5/300], Step [190/225], Training Accuracy: 42.3109%, Training Loss: 1.1893%\n",
      "Epoch [5/300], Step [191/225], Training Accuracy: 42.2775%, Training Loss: 1.1894%\n",
      "Epoch [5/300], Step [192/225], Training Accuracy: 42.3340%, Training Loss: 1.1890%\n",
      "Epoch [5/300], Step [193/225], Training Accuracy: 42.3089%, Training Loss: 1.1894%\n",
      "Epoch [5/300], Step [194/225], Training Accuracy: 42.3727%, Training Loss: 1.1887%\n",
      "Epoch [5/300], Step [195/225], Training Accuracy: 42.4519%, Training Loss: 1.1878%\n",
      "Epoch [5/300], Step [196/225], Training Accuracy: 42.4107%, Training Loss: 1.1884%\n",
      "Epoch [5/300], Step [197/225], Training Accuracy: 42.4175%, Training Loss: 1.1887%\n",
      "Epoch [5/300], Step [198/225], Training Accuracy: 42.5189%, Training Loss: 1.1875%\n",
      "Epoch [5/300], Step [199/225], Training Accuracy: 42.5722%, Training Loss: 1.1869%\n",
      "Epoch [5/300], Step [200/225], Training Accuracy: 42.5781%, Training Loss: 1.1869%\n",
      "Epoch [5/300], Step [201/225], Training Accuracy: 42.5684%, Training Loss: 1.1874%\n",
      "Epoch [5/300], Step [202/225], Training Accuracy: 42.5588%, Training Loss: 1.1879%\n",
      "Epoch [5/300], Step [203/225], Training Accuracy: 42.5416%, Training Loss: 1.1883%\n",
      "Epoch [5/300], Step [204/225], Training Accuracy: 42.5245%, Training Loss: 1.1884%\n",
      "Epoch [5/300], Step [205/225], Training Accuracy: 42.5534%, Training Loss: 1.1882%\n",
      "Epoch [5/300], Step [206/225], Training Accuracy: 42.5743%, Training Loss: 1.1883%\n",
      "Epoch [5/300], Step [207/225], Training Accuracy: 42.5725%, Training Loss: 1.1886%\n",
      "Epoch [5/300], Step [208/225], Training Accuracy: 42.5931%, Training Loss: 1.1882%\n",
      "Epoch [5/300], Step [209/225], Training Accuracy: 42.6435%, Training Loss: 1.1878%\n",
      "Epoch [5/300], Step [210/225], Training Accuracy: 42.6339%, Training Loss: 1.1877%\n",
      "Epoch [5/300], Step [211/225], Training Accuracy: 42.6096%, Training Loss: 1.1871%\n",
      "Epoch [5/300], Step [212/225], Training Accuracy: 42.6445%, Training Loss: 1.1866%\n",
      "Epoch [5/300], Step [213/225], Training Accuracy: 42.5983%, Training Loss: 1.1870%\n",
      "Epoch [5/300], Step [214/225], Training Accuracy: 42.6110%, Training Loss: 1.1871%\n",
      "Epoch [5/300], Step [215/225], Training Accuracy: 42.5872%, Training Loss: 1.1872%\n",
      "Epoch [5/300], Step [216/225], Training Accuracy: 42.5709%, Training Loss: 1.1873%\n",
      "Epoch [5/300], Step [217/225], Training Accuracy: 42.5619%, Training Loss: 1.1869%\n",
      "Epoch [5/300], Step [218/225], Training Accuracy: 42.5315%, Training Loss: 1.1870%\n",
      "Epoch [5/300], Step [219/225], Training Accuracy: 42.5157%, Training Loss: 1.1864%\n",
      "Epoch [5/300], Step [220/225], Training Accuracy: 42.5355%, Training Loss: 1.1861%\n",
      "Epoch [5/300], Step [221/225], Training Accuracy: 42.5057%, Training Loss: 1.1863%\n",
      "Epoch [5/300], Step [222/225], Training Accuracy: 42.5113%, Training Loss: 1.1858%\n",
      "Epoch [5/300], Step [223/225], Training Accuracy: 42.5308%, Training Loss: 1.1858%\n",
      "Epoch [5/300], Step [224/225], Training Accuracy: 42.5572%, Training Loss: 1.1851%\n",
      "Epoch [5/300], Step [225/225], Training Accuracy: 42.5514%, Training Loss: 1.1854%\n",
      "Epoch [6/300], Step [1/225], Training Accuracy: 53.1250%, Training Loss: 1.0959%\n",
      "Epoch [6/300], Step [2/225], Training Accuracy: 50.0000%, Training Loss: 1.1796%\n",
      "Epoch [6/300], Step [3/225], Training Accuracy: 44.7917%, Training Loss: 1.2083%\n",
      "Epoch [6/300], Step [4/225], Training Accuracy: 46.4844%, Training Loss: 1.1741%\n",
      "Epoch [6/300], Step [5/225], Training Accuracy: 45.9375%, Training Loss: 1.1697%\n",
      "Epoch [6/300], Step [6/225], Training Accuracy: 45.0521%, Training Loss: 1.1697%\n",
      "Epoch [6/300], Step [7/225], Training Accuracy: 44.8661%, Training Loss: 1.1730%\n",
      "Epoch [6/300], Step [8/225], Training Accuracy: 44.7266%, Training Loss: 1.1687%\n",
      "Epoch [6/300], Step [9/225], Training Accuracy: 44.4444%, Training Loss: 1.1619%\n",
      "Epoch [6/300], Step [10/225], Training Accuracy: 44.6875%, Training Loss: 1.1634%\n",
      "Epoch [6/300], Step [11/225], Training Accuracy: 44.1761%, Training Loss: 1.1619%\n",
      "Epoch [6/300], Step [12/225], Training Accuracy: 44.0104%, Training Loss: 1.1594%\n",
      "Epoch [6/300], Step [13/225], Training Accuracy: 45.0721%, Training Loss: 1.1515%\n",
      "Epoch [6/300], Step [14/225], Training Accuracy: 45.7589%, Training Loss: 1.1491%\n",
      "Epoch [6/300], Step [15/225], Training Accuracy: 45.3125%, Training Loss: 1.1563%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/300], Step [16/225], Training Accuracy: 45.0195%, Training Loss: 1.1631%\n",
      "Epoch [6/300], Step [17/225], Training Accuracy: 45.4044%, Training Loss: 1.1557%\n",
      "Epoch [6/300], Step [18/225], Training Accuracy: 44.7917%, Training Loss: 1.1565%\n",
      "Epoch [6/300], Step [19/225], Training Accuracy: 44.9836%, Training Loss: 1.1548%\n",
      "Epoch [6/300], Step [20/225], Training Accuracy: 44.7656%, Training Loss: 1.1560%\n",
      "Epoch [6/300], Step [21/225], Training Accuracy: 45.1637%, Training Loss: 1.1498%\n",
      "Epoch [6/300], Step [22/225], Training Accuracy: 45.0284%, Training Loss: 1.1507%\n",
      "Epoch [6/300], Step [23/225], Training Accuracy: 45.1087%, Training Loss: 1.1462%\n",
      "Epoch [6/300], Step [24/225], Training Accuracy: 45.1823%, Training Loss: 1.1446%\n",
      "Epoch [6/300], Step [25/225], Training Accuracy: 45.4375%, Training Loss: 1.1385%\n",
      "Epoch [6/300], Step [26/225], Training Accuracy: 45.4928%, Training Loss: 1.1371%\n",
      "Epoch [6/300], Step [27/225], Training Accuracy: 44.9653%, Training Loss: 1.1414%\n",
      "Epoch [6/300], Step [28/225], Training Accuracy: 44.9777%, Training Loss: 1.1423%\n",
      "Epoch [6/300], Step [29/225], Training Accuracy: 45.0970%, Training Loss: 1.1388%\n",
      "Epoch [6/300], Step [30/225], Training Accuracy: 45.0521%, Training Loss: 1.1391%\n",
      "Epoch [6/300], Step [31/225], Training Accuracy: 45.2117%, Training Loss: 1.1390%\n",
      "Epoch [6/300], Step [32/225], Training Accuracy: 45.0195%, Training Loss: 1.1378%\n",
      "Epoch [6/300], Step [33/225], Training Accuracy: 45.0758%, Training Loss: 1.1364%\n",
      "Epoch [6/300], Step [34/225], Training Accuracy: 44.8070%, Training Loss: 1.1419%\n",
      "Epoch [6/300], Step [35/225], Training Accuracy: 44.9107%, Training Loss: 1.1421%\n",
      "Epoch [6/300], Step [36/225], Training Accuracy: 44.8351%, Training Loss: 1.1415%\n",
      "Epoch [6/300], Step [37/225], Training Accuracy: 45.1014%, Training Loss: 1.1393%\n",
      "Epoch [6/300], Step [38/225], Training Accuracy: 45.1069%, Training Loss: 1.1376%\n",
      "Epoch [6/300], Step [39/225], Training Accuracy: 45.2324%, Training Loss: 1.1363%\n",
      "Epoch [6/300], Step [40/225], Training Accuracy: 45.0000%, Training Loss: 1.1378%\n",
      "Epoch [6/300], Step [41/225], Training Accuracy: 44.6646%, Training Loss: 1.1396%\n",
      "Epoch [6/300], Step [42/225], Training Accuracy: 44.6429%, Training Loss: 1.1396%\n",
      "Epoch [6/300], Step [43/225], Training Accuracy: 44.5858%, Training Loss: 1.1401%\n",
      "Epoch [6/300], Step [44/225], Training Accuracy: 44.8153%, Training Loss: 1.1388%\n",
      "Epoch [6/300], Step [45/225], Training Accuracy: 44.9653%, Training Loss: 1.1367%\n",
      "Epoch [6/300], Step [46/225], Training Accuracy: 45.2106%, Training Loss: 1.1337%\n",
      "Epoch [6/300], Step [47/225], Training Accuracy: 45.1463%, Training Loss: 1.1334%\n",
      "Epoch [6/300], Step [48/225], Training Accuracy: 45.2148%, Training Loss: 1.1325%\n",
      "Epoch [6/300], Step [49/225], Training Accuracy: 45.1849%, Training Loss: 1.1330%\n",
      "Epoch [6/300], Step [50/225], Training Accuracy: 45.2188%, Training Loss: 1.1315%\n",
      "Epoch [6/300], Step [51/225], Training Accuracy: 45.2819%, Training Loss: 1.1311%\n",
      "Epoch [6/300], Step [52/225], Training Accuracy: 45.4026%, Training Loss: 1.1307%\n",
      "Epoch [6/300], Step [53/225], Training Accuracy: 45.6368%, Training Loss: 1.1311%\n",
      "Epoch [6/300], Step [54/225], Training Accuracy: 45.3704%, Training Loss: 1.1313%\n",
      "Epoch [6/300], Step [55/225], Training Accuracy: 45.3977%, Training Loss: 1.1295%\n",
      "Epoch [6/300], Step [56/225], Training Accuracy: 45.1730%, Training Loss: 1.1319%\n",
      "Epoch [6/300], Step [57/225], Training Accuracy: 45.1480%, Training Loss: 1.1307%\n",
      "Epoch [6/300], Step [58/225], Training Accuracy: 45.0700%, Training Loss: 1.1306%\n",
      "Epoch [6/300], Step [59/225], Training Accuracy: 45.0742%, Training Loss: 1.1293%\n",
      "Epoch [6/300], Step [60/225], Training Accuracy: 45.0781%, Training Loss: 1.1276%\n",
      "Epoch [6/300], Step [61/225], Training Accuracy: 45.0820%, Training Loss: 1.1280%\n",
      "Epoch [6/300], Step [62/225], Training Accuracy: 44.9849%, Training Loss: 1.1289%\n",
      "Epoch [6/300], Step [63/225], Training Accuracy: 44.9405%, Training Loss: 1.1287%\n",
      "Epoch [6/300], Step [64/225], Training Accuracy: 44.8486%, Training Loss: 1.1311%\n",
      "Epoch [6/300], Step [65/225], Training Accuracy: 44.7596%, Training Loss: 1.1319%\n",
      "Epoch [6/300], Step [66/225], Training Accuracy: 44.9100%, Training Loss: 1.1301%\n",
      "Epoch [6/300], Step [67/225], Training Accuracy: 44.9394%, Training Loss: 1.1293%\n",
      "Epoch [6/300], Step [68/225], Training Accuracy: 44.9449%, Training Loss: 1.1285%\n",
      "Epoch [6/300], Step [69/225], Training Accuracy: 44.9275%, Training Loss: 1.1277%\n",
      "Epoch [6/300], Step [70/225], Training Accuracy: 45.0670%, Training Loss: 1.1276%\n",
      "Epoch [6/300], Step [71/225], Training Accuracy: 45.0264%, Training Loss: 1.1281%\n",
      "Epoch [6/300], Step [72/225], Training Accuracy: 44.9653%, Training Loss: 1.1292%\n",
      "Epoch [6/300], Step [73/225], Training Accuracy: 44.8844%, Training Loss: 1.1306%\n",
      "Epoch [6/300], Step [74/225], Training Accuracy: 45.0169%, Training Loss: 1.1291%\n",
      "Epoch [6/300], Step [75/225], Training Accuracy: 45.1250%, Training Loss: 1.1272%\n",
      "Epoch [6/300], Step [76/225], Training Accuracy: 45.0452%, Training Loss: 1.1267%\n",
      "Epoch [6/300], Step [77/225], Training Accuracy: 45.0081%, Training Loss: 1.1269%\n",
      "Epoch [6/300], Step [78/225], Training Accuracy: 45.0921%, Training Loss: 1.1260%\n",
      "Epoch [6/300], Step [79/225], Training Accuracy: 45.1543%, Training Loss: 1.1265%\n",
      "Epoch [6/300], Step [80/225], Training Accuracy: 45.0391%, Training Loss: 1.1266%\n",
      "Epoch [6/300], Step [81/225], Training Accuracy: 45.0617%, Training Loss: 1.1267%\n",
      "Epoch [6/300], Step [82/225], Training Accuracy: 45.1220%, Training Loss: 1.1254%\n",
      "Epoch [6/300], Step [83/225], Training Accuracy: 45.1807%, Training Loss: 1.1242%\n",
      "Epoch [6/300], Step [84/225], Training Accuracy: 45.1079%, Training Loss: 1.1241%\n",
      "Epoch [6/300], Step [85/225], Training Accuracy: 45.1287%, Training Loss: 1.1244%\n",
      "Epoch [6/300], Step [86/225], Training Accuracy: 45.1490%, Training Loss: 1.1230%\n",
      "Epoch [6/300], Step [87/225], Training Accuracy: 45.2227%, Training Loss: 1.1229%\n",
      "Epoch [6/300], Step [88/225], Training Accuracy: 45.0994%, Training Loss: 1.1242%\n",
      "Epoch [6/300], Step [89/225], Training Accuracy: 45.1896%, Training Loss: 1.1252%\n",
      "Epoch [6/300], Step [90/225], Training Accuracy: 45.1562%, Training Loss: 1.1246%\n",
      "Epoch [6/300], Step [91/225], Training Accuracy: 45.1236%, Training Loss: 1.1255%\n",
      "Epoch [6/300], Step [92/225], Training Accuracy: 45.0747%, Training Loss: 1.1262%\n",
      "Epoch [6/300], Step [93/225], Training Accuracy: 45.2453%, Training Loss: 1.1252%\n",
      "Epoch [6/300], Step [94/225], Training Accuracy: 45.3624%, Training Loss: 1.1234%\n",
      "Epoch [6/300], Step [95/225], Training Accuracy: 45.3289%, Training Loss: 1.1236%\n",
      "Epoch [6/300], Step [96/225], Training Accuracy: 45.3451%, Training Loss: 1.1234%\n",
      "Epoch [6/300], Step [97/225], Training Accuracy: 45.3286%, Training Loss: 1.1240%\n",
      "Epoch [6/300], Step [98/225], Training Accuracy: 45.2806%, Training Loss: 1.1245%\n",
      "Epoch [6/300], Step [99/225], Training Accuracy: 45.4072%, Training Loss: 1.1239%\n",
      "Epoch [6/300], Step [100/225], Training Accuracy: 45.3594%, Training Loss: 1.1239%\n",
      "Epoch [6/300], Step [101/225], Training Accuracy: 45.3899%, Training Loss: 1.1230%\n",
      "Epoch [6/300], Step [102/225], Training Accuracy: 45.3278%, Training Loss: 1.1242%\n",
      "Epoch [6/300], Step [103/225], Training Accuracy: 45.3580%, Training Loss: 1.1246%\n",
      "Epoch [6/300], Step [104/225], Training Accuracy: 45.2975%, Training Loss: 1.1251%\n",
      "Epoch [6/300], Step [105/225], Training Accuracy: 45.3720%, Training Loss: 1.1242%\n",
      "Epoch [6/300], Step [106/225], Training Accuracy: 45.4599%, Training Loss: 1.1240%\n",
      "Epoch [6/300], Step [107/225], Training Accuracy: 45.4147%, Training Loss: 1.1240%\n",
      "Epoch [6/300], Step [108/225], Training Accuracy: 45.3704%, Training Loss: 1.1238%\n",
      "Epoch [6/300], Step [109/225], Training Accuracy: 45.4128%, Training Loss: 1.1235%\n",
      "Epoch [6/300], Step [110/225], Training Accuracy: 45.4972%, Training Loss: 1.1229%\n",
      "Epoch [6/300], Step [111/225], Training Accuracy: 45.5236%, Training Loss: 1.1230%\n",
      "Epoch [6/300], Step [112/225], Training Accuracy: 45.5776%, Training Loss: 1.1230%\n",
      "Epoch [6/300], Step [113/225], Training Accuracy: 45.5199%, Training Loss: 1.1230%\n",
      "Epoch [6/300], Step [114/225], Training Accuracy: 45.5318%, Training Loss: 1.1226%\n",
      "Epoch [6/300], Step [115/225], Training Accuracy: 45.6114%, Training Loss: 1.1222%\n",
      "Epoch [6/300], Step [116/225], Training Accuracy: 45.5011%, Training Loss: 1.1227%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/300], Step [117/225], Training Accuracy: 45.3392%, Training Loss: 1.1243%\n",
      "Epoch [6/300], Step [118/225], Training Accuracy: 45.3655%, Training Loss: 1.1237%\n",
      "Epoch [6/300], Step [119/225], Training Accuracy: 45.3388%, Training Loss: 1.1231%\n",
      "Epoch [6/300], Step [120/225], Training Accuracy: 45.3646%, Training Loss: 1.1235%\n",
      "Epoch [6/300], Step [121/225], Training Accuracy: 45.3642%, Training Loss: 1.1238%\n",
      "Epoch [6/300], Step [122/225], Training Accuracy: 45.3765%, Training Loss: 1.1236%\n",
      "Epoch [6/300], Step [123/225], Training Accuracy: 45.3760%, Training Loss: 1.1232%\n",
      "Epoch [6/300], Step [124/225], Training Accuracy: 45.4007%, Training Loss: 1.1224%\n",
      "Epoch [6/300], Step [125/225], Training Accuracy: 45.4125%, Training Loss: 1.1230%\n",
      "Epoch [6/300], Step [126/225], Training Accuracy: 45.3745%, Training Loss: 1.1238%\n",
      "Epoch [6/300], Step [127/225], Training Accuracy: 45.2756%, Training Loss: 1.1242%\n",
      "Epoch [6/300], Step [128/225], Training Accuracy: 45.2393%, Training Loss: 1.1245%\n",
      "Epoch [6/300], Step [129/225], Training Accuracy: 45.2519%, Training Loss: 1.1241%\n",
      "Epoch [6/300], Step [130/225], Training Accuracy: 45.2284%, Training Loss: 1.1238%\n",
      "Epoch [6/300], Step [131/225], Training Accuracy: 45.2290%, Training Loss: 1.1238%\n",
      "Epoch [6/300], Step [132/225], Training Accuracy: 45.2770%, Training Loss: 1.1234%\n",
      "Epoch [6/300], Step [133/225], Training Accuracy: 45.2773%, Training Loss: 1.1231%\n",
      "Epoch [6/300], Step [134/225], Training Accuracy: 45.1726%, Training Loss: 1.1246%\n",
      "Epoch [6/300], Step [135/225], Training Accuracy: 45.1736%, Training Loss: 1.1243%\n",
      "Epoch [6/300], Step [136/225], Training Accuracy: 45.1517%, Training Loss: 1.1239%\n",
      "Epoch [6/300], Step [137/225], Training Accuracy: 45.1756%, Training Loss: 1.1235%\n",
      "Epoch [6/300], Step [138/225], Training Accuracy: 45.2446%, Training Loss: 1.1235%\n",
      "Epoch [6/300], Step [139/225], Training Accuracy: 45.2001%, Training Loss: 1.1236%\n",
      "Epoch [6/300], Step [140/225], Training Accuracy: 45.1897%, Training Loss: 1.1233%\n",
      "Epoch [6/300], Step [141/225], Training Accuracy: 45.2571%, Training Loss: 1.1230%\n",
      "Epoch [6/300], Step [142/225], Training Accuracy: 45.3235%, Training Loss: 1.1221%\n",
      "Epoch [6/300], Step [143/225], Training Accuracy: 45.4108%, Training Loss: 1.1216%\n",
      "Epoch [6/300], Step [144/225], Training Accuracy: 45.3559%, Training Loss: 1.1216%\n",
      "Epoch [6/300], Step [145/225], Training Accuracy: 45.3879%, Training Loss: 1.1215%\n",
      "Epoch [6/300], Step [146/225], Training Accuracy: 45.3339%, Training Loss: 1.1213%\n",
      "Epoch [6/300], Step [147/225], Training Accuracy: 45.3125%, Training Loss: 1.1212%\n",
      "Epoch [6/300], Step [148/225], Training Accuracy: 45.4075%, Training Loss: 1.1205%\n",
      "Epoch [6/300], Step [149/225], Training Accuracy: 45.3649%, Training Loss: 1.1208%\n",
      "Epoch [6/300], Step [150/225], Training Accuracy: 45.3646%, Training Loss: 1.1201%\n",
      "Epoch [6/300], Step [151/225], Training Accuracy: 45.4263%, Training Loss: 1.1196%\n",
      "Epoch [6/300], Step [152/225], Training Accuracy: 45.3639%, Training Loss: 1.1201%\n",
      "Epoch [6/300], Step [153/225], Training Accuracy: 45.3840%, Training Loss: 1.1201%\n",
      "Epoch [6/300], Step [154/225], Training Accuracy: 45.3937%, Training Loss: 1.1201%\n",
      "Epoch [6/300], Step [155/225], Training Accuracy: 45.3931%, Training Loss: 1.1199%\n",
      "Epoch [6/300], Step [156/225], Training Accuracy: 45.4327%, Training Loss: 1.1198%\n",
      "Epoch [6/300], Step [157/225], Training Accuracy: 45.4817%, Training Loss: 1.1190%\n",
      "Epoch [6/300], Step [158/225], Training Accuracy: 45.4707%, Training Loss: 1.1195%\n",
      "Epoch [6/300], Step [159/225], Training Accuracy: 45.4403%, Training Loss: 1.1192%\n",
      "Epoch [6/300], Step [160/225], Training Accuracy: 45.4395%, Training Loss: 1.1188%\n",
      "Epoch [6/300], Step [161/225], Training Accuracy: 45.5260%, Training Loss: 1.1177%\n",
      "Epoch [6/300], Step [162/225], Training Accuracy: 45.5633%, Training Loss: 1.1171%\n",
      "Epoch [6/300], Step [163/225], Training Accuracy: 45.5809%, Training Loss: 1.1165%\n",
      "Epoch [6/300], Step [164/225], Training Accuracy: 45.6364%, Training Loss: 1.1160%\n",
      "Epoch [6/300], Step [165/225], Training Accuracy: 45.6155%, Training Loss: 1.1165%\n",
      "Epoch [6/300], Step [166/225], Training Accuracy: 45.6702%, Training Loss: 1.1156%\n",
      "Epoch [6/300], Step [167/225], Training Accuracy: 45.7429%, Training Loss: 1.1151%\n",
      "Epoch [6/300], Step [168/225], Training Accuracy: 45.8147%, Training Loss: 1.1145%\n",
      "Epoch [6/300], Step [169/225], Training Accuracy: 45.8395%, Training Loss: 1.1140%\n",
      "Epoch [6/300], Step [170/225], Training Accuracy: 45.8272%, Training Loss: 1.1139%\n",
      "Epoch [6/300], Step [171/225], Training Accuracy: 45.8882%, Training Loss: 1.1132%\n",
      "Epoch [6/300], Step [172/225], Training Accuracy: 45.8757%, Training Loss: 1.1131%\n",
      "Epoch [6/300], Step [173/225], Training Accuracy: 45.8905%, Training Loss: 1.1131%\n",
      "Epoch [6/300], Step [174/225], Training Accuracy: 45.8513%, Training Loss: 1.1130%\n",
      "Epoch [6/300], Step [175/225], Training Accuracy: 45.9018%, Training Loss: 1.1128%\n",
      "Epoch [6/300], Step [176/225], Training Accuracy: 45.9339%, Training Loss: 1.1124%\n",
      "Epoch [6/300], Step [177/225], Training Accuracy: 45.9922%, Training Loss: 1.1117%\n",
      "Epoch [6/300], Step [178/225], Training Accuracy: 45.9972%, Training Loss: 1.1116%\n",
      "Epoch [6/300], Step [179/225], Training Accuracy: 46.0370%, Training Loss: 1.1107%\n",
      "Epoch [6/300], Step [180/225], Training Accuracy: 46.0851%, Training Loss: 1.1101%\n",
      "Epoch [6/300], Step [181/225], Training Accuracy: 46.0463%, Training Loss: 1.1108%\n",
      "Epoch [6/300], Step [182/225], Training Accuracy: 46.0422%, Training Loss: 1.1108%\n",
      "Epoch [6/300], Step [183/225], Training Accuracy: 46.0468%, Training Loss: 1.1106%\n",
      "Epoch [6/300], Step [184/225], Training Accuracy: 46.0683%, Training Loss: 1.1099%\n",
      "Epoch [6/300], Step [185/225], Training Accuracy: 46.0557%, Training Loss: 1.1096%\n",
      "Epoch [6/300], Step [186/225], Training Accuracy: 46.0433%, Training Loss: 1.1098%\n",
      "Epoch [6/300], Step [187/225], Training Accuracy: 46.0478%, Training Loss: 1.1095%\n",
      "Epoch [6/300], Step [188/225], Training Accuracy: 46.0688%, Training Loss: 1.1092%\n",
      "Epoch [6/300], Step [189/225], Training Accuracy: 46.0979%, Training Loss: 1.1081%\n",
      "Epoch [6/300], Step [190/225], Training Accuracy: 46.0938%, Training Loss: 1.1091%\n",
      "Epoch [6/300], Step [191/225], Training Accuracy: 46.0733%, Training Loss: 1.1091%\n",
      "Epoch [6/300], Step [192/225], Training Accuracy: 46.1507%, Training Loss: 1.1084%\n",
      "Epoch [6/300], Step [193/225], Training Accuracy: 46.0411%, Training Loss: 1.1094%\n",
      "Epoch [6/300], Step [194/225], Training Accuracy: 46.0213%, Training Loss: 1.1092%\n",
      "Epoch [6/300], Step [195/225], Training Accuracy: 46.0897%, Training Loss: 1.1089%\n",
      "Epoch [6/300], Step [196/225], Training Accuracy: 46.0140%, Training Loss: 1.1095%\n",
      "Epoch [6/300], Step [197/225], Training Accuracy: 45.9946%, Training Loss: 1.1100%\n",
      "Epoch [6/300], Step [198/225], Training Accuracy: 46.0701%, Training Loss: 1.1086%\n",
      "Epoch [6/300], Step [199/225], Training Accuracy: 46.0820%, Training Loss: 1.1084%\n",
      "Epoch [6/300], Step [200/225], Training Accuracy: 46.0703%, Training Loss: 1.1088%\n",
      "Epoch [6/300], Step [201/225], Training Accuracy: 46.0588%, Training Loss: 1.1090%\n",
      "Epoch [6/300], Step [202/225], Training Accuracy: 46.1015%, Training Loss: 1.1091%\n",
      "Epoch [6/300], Step [203/225], Training Accuracy: 46.0899%, Training Loss: 1.1090%\n",
      "Epoch [6/300], Step [204/225], Training Accuracy: 46.0555%, Training Loss: 1.1094%\n",
      "Epoch [6/300], Step [205/225], Training Accuracy: 46.0366%, Training Loss: 1.1099%\n",
      "Epoch [6/300], Step [206/225], Training Accuracy: 45.9876%, Training Loss: 1.1105%\n",
      "Epoch [6/300], Step [207/225], Training Accuracy: 45.9843%, Training Loss: 1.1104%\n",
      "Epoch [6/300], Step [208/225], Training Accuracy: 46.0186%, Training Loss: 1.1098%\n",
      "Epoch [6/300], Step [209/225], Training Accuracy: 46.0526%, Training Loss: 1.1098%\n",
      "Epoch [6/300], Step [210/225], Training Accuracy: 46.0268%, Training Loss: 1.1098%\n",
      "Epoch [6/300], Step [211/225], Training Accuracy: 46.0086%, Training Loss: 1.1093%\n",
      "Epoch [6/300], Step [212/225], Training Accuracy: 46.0348%, Training Loss: 1.1093%\n",
      "Epoch [6/300], Step [213/225], Training Accuracy: 45.9947%, Training Loss: 1.1095%\n",
      "Epoch [6/300], Step [214/225], Training Accuracy: 46.0207%, Training Loss: 1.1089%\n",
      "Epoch [6/300], Step [215/225], Training Accuracy: 45.9666%, Training Loss: 1.1093%\n",
      "Epoch [6/300], Step [216/225], Training Accuracy: 45.9418%, Training Loss: 1.1093%\n",
      "Epoch [6/300], Step [217/225], Training Accuracy: 45.9461%, Training Loss: 1.1091%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/300], Step [218/225], Training Accuracy: 45.9576%, Training Loss: 1.1093%\n",
      "Epoch [6/300], Step [219/225], Training Accuracy: 45.9618%, Training Loss: 1.1088%\n",
      "Epoch [6/300], Step [220/225], Training Accuracy: 46.0014%, Training Loss: 1.1086%\n",
      "Epoch [6/300], Step [221/225], Training Accuracy: 45.9771%, Training Loss: 1.1089%\n",
      "Epoch [6/300], Step [222/225], Training Accuracy: 45.9882%, Training Loss: 1.1084%\n",
      "Epoch [6/300], Step [223/225], Training Accuracy: 45.9851%, Training Loss: 1.1085%\n",
      "Epoch [6/300], Step [224/225], Training Accuracy: 45.9961%, Training Loss: 1.1078%\n",
      "Epoch [6/300], Step [225/225], Training Accuracy: 45.9700%, Training Loss: 1.1080%\n",
      "Epoch [7/300], Step [1/225], Training Accuracy: 57.8125%, Training Loss: 0.9899%\n",
      "Epoch [7/300], Step [2/225], Training Accuracy: 53.9062%, Training Loss: 1.1048%\n",
      "Epoch [7/300], Step [3/225], Training Accuracy: 50.0000%, Training Loss: 1.1208%\n",
      "Epoch [7/300], Step [4/225], Training Accuracy: 49.2188%, Training Loss: 1.1041%\n",
      "Epoch [7/300], Step [5/225], Training Accuracy: 49.3750%, Training Loss: 1.0873%\n",
      "Epoch [7/300], Step [6/225], Training Accuracy: 49.7396%, Training Loss: 1.0912%\n",
      "Epoch [7/300], Step [7/225], Training Accuracy: 49.3304%, Training Loss: 1.1016%\n",
      "Epoch [7/300], Step [8/225], Training Accuracy: 48.6328%, Training Loss: 1.0988%\n",
      "Epoch [7/300], Step [9/225], Training Accuracy: 49.3056%, Training Loss: 1.0917%\n",
      "Epoch [7/300], Step [10/225], Training Accuracy: 48.7500%, Training Loss: 1.0933%\n",
      "Epoch [7/300], Step [11/225], Training Accuracy: 48.8636%, Training Loss: 1.0919%\n",
      "Epoch [7/300], Step [12/225], Training Accuracy: 49.0885%, Training Loss: 1.0851%\n",
      "Epoch [7/300], Step [13/225], Training Accuracy: 49.8798%, Training Loss: 1.0739%\n",
      "Epoch [7/300], Step [14/225], Training Accuracy: 50.1116%, Training Loss: 1.0709%\n",
      "Epoch [7/300], Step [15/225], Training Accuracy: 49.3750%, Training Loss: 1.0765%\n",
      "Epoch [7/300], Step [16/225], Training Accuracy: 48.7305%, Training Loss: 1.0799%\n",
      "Epoch [7/300], Step [17/225], Training Accuracy: 49.2647%, Training Loss: 1.0712%\n",
      "Epoch [7/300], Step [18/225], Training Accuracy: 48.1771%, Training Loss: 1.0764%\n",
      "Epoch [7/300], Step [19/225], Training Accuracy: 47.9441%, Training Loss: 1.0785%\n",
      "Epoch [7/300], Step [20/225], Training Accuracy: 47.8906%, Training Loss: 1.0755%\n",
      "Epoch [7/300], Step [21/225], Training Accuracy: 48.2887%, Training Loss: 1.0708%\n",
      "Epoch [7/300], Step [22/225], Training Accuracy: 47.8693%, Training Loss: 1.0720%\n",
      "Epoch [7/300], Step [23/225], Training Accuracy: 48.1658%, Training Loss: 1.0676%\n",
      "Epoch [7/300], Step [24/225], Training Accuracy: 48.1771%, Training Loss: 1.0638%\n",
      "Epoch [7/300], Step [25/225], Training Accuracy: 48.2500%, Training Loss: 1.0595%\n",
      "Epoch [7/300], Step [26/225], Training Accuracy: 48.2572%, Training Loss: 1.0561%\n",
      "Epoch [7/300], Step [27/225], Training Accuracy: 47.9745%, Training Loss: 1.0593%\n",
      "Epoch [7/300], Step [28/225], Training Accuracy: 48.2701%, Training Loss: 1.0574%\n",
      "Epoch [7/300], Step [29/225], Training Accuracy: 48.4914%, Training Loss: 1.0564%\n",
      "Epoch [7/300], Step [30/225], Training Accuracy: 48.4896%, Training Loss: 1.0555%\n",
      "Epoch [7/300], Step [31/225], Training Accuracy: 48.6895%, Training Loss: 1.0540%\n",
      "Epoch [7/300], Step [32/225], Training Accuracy: 48.4863%, Training Loss: 1.0526%\n",
      "Epoch [7/300], Step [33/225], Training Accuracy: 48.7689%, Training Loss: 1.0528%\n",
      "Epoch [7/300], Step [34/225], Training Accuracy: 48.4375%, Training Loss: 1.0588%\n",
      "Epoch [7/300], Step [35/225], Training Accuracy: 48.4821%, Training Loss: 1.0606%\n",
      "Epoch [7/300], Step [36/225], Training Accuracy: 48.3941%, Training Loss: 1.0605%\n",
      "Epoch [7/300], Step [37/225], Training Accuracy: 48.5642%, Training Loss: 1.0598%\n",
      "Epoch [7/300], Step [38/225], Training Accuracy: 48.7664%, Training Loss: 1.0582%\n",
      "Epoch [7/300], Step [39/225], Training Accuracy: 48.3974%, Training Loss: 1.0614%\n",
      "Epoch [7/300], Step [40/225], Training Accuracy: 48.3984%, Training Loss: 1.0626%\n",
      "Epoch [7/300], Step [41/225], Training Accuracy: 48.1707%, Training Loss: 1.0653%\n",
      "Epoch [7/300], Step [42/225], Training Accuracy: 48.0655%, Training Loss: 1.0635%\n",
      "Epoch [7/300], Step [43/225], Training Accuracy: 48.1468%, Training Loss: 1.0620%\n",
      "Epoch [7/300], Step [44/225], Training Accuracy: 48.2599%, Training Loss: 1.0604%\n",
      "Epoch [7/300], Step [45/225], Training Accuracy: 48.4722%, Training Loss: 1.0577%\n",
      "Epoch [7/300], Step [46/225], Training Accuracy: 48.5054%, Training Loss: 1.0557%\n",
      "Epoch [7/300], Step [47/225], Training Accuracy: 48.3378%, Training Loss: 1.0562%\n",
      "Epoch [7/300], Step [48/225], Training Accuracy: 48.3398%, Training Loss: 1.0562%\n",
      "Epoch [7/300], Step [49/225], Training Accuracy: 48.2462%, Training Loss: 1.0600%\n",
      "Epoch [7/300], Step [50/225], Training Accuracy: 48.2812%, Training Loss: 1.0591%\n",
      "Epoch [7/300], Step [51/225], Training Accuracy: 48.3150%, Training Loss: 1.0585%\n",
      "Epoch [7/300], Step [52/225], Training Accuracy: 48.3774%, Training Loss: 1.0596%\n",
      "Epoch [7/300], Step [53/225], Training Accuracy: 48.3785%, Training Loss: 1.0603%\n",
      "Epoch [7/300], Step [54/225], Training Accuracy: 48.4664%, Training Loss: 1.0600%\n",
      "Epoch [7/300], Step [55/225], Training Accuracy: 48.5227%, Training Loss: 1.0593%\n",
      "Epoch [7/300], Step [56/225], Training Accuracy: 48.2701%, Training Loss: 1.0608%\n",
      "Epoch [7/300], Step [57/225], Training Accuracy: 48.3827%, Training Loss: 1.0606%\n",
      "Epoch [7/300], Step [58/225], Training Accuracy: 48.3297%, Training Loss: 1.0606%\n",
      "Epoch [7/300], Step [59/225], Training Accuracy: 48.1992%, Training Loss: 1.0609%\n",
      "Epoch [7/300], Step [60/225], Training Accuracy: 48.0990%, Training Loss: 1.0614%\n",
      "Epoch [7/300], Step [61/225], Training Accuracy: 48.0020%, Training Loss: 1.0625%\n",
      "Epoch [7/300], Step [62/225], Training Accuracy: 47.9587%, Training Loss: 1.0625%\n",
      "Epoch [7/300], Step [63/225], Training Accuracy: 47.8671%, Training Loss: 1.0642%\n",
      "Epoch [7/300], Step [64/225], Training Accuracy: 47.7295%, Training Loss: 1.0651%\n",
      "Epoch [7/300], Step [65/225], Training Accuracy: 47.6202%, Training Loss: 1.0662%\n",
      "Epoch [7/300], Step [66/225], Training Accuracy: 47.8220%, Training Loss: 1.0646%\n",
      "Epoch [7/300], Step [67/225], Training Accuracy: 47.8312%, Training Loss: 1.0641%\n",
      "Epoch [7/300], Step [68/225], Training Accuracy: 47.8401%, Training Loss: 1.0641%\n",
      "Epoch [7/300], Step [69/225], Training Accuracy: 47.8261%, Training Loss: 1.0625%\n",
      "Epoch [7/300], Step [70/225], Training Accuracy: 47.9464%, Training Loss: 1.0632%\n",
      "Epoch [7/300], Step [71/225], Training Accuracy: 47.9754%, Training Loss: 1.0615%\n",
      "Epoch [7/300], Step [72/225], Training Accuracy: 47.8733%, Training Loss: 1.0639%\n",
      "Epoch [7/300], Step [73/225], Training Accuracy: 47.7526%, Training Loss: 1.0652%\n",
      "Epoch [7/300], Step [74/225], Training Accuracy: 47.6985%, Training Loss: 1.0652%\n",
      "Epoch [7/300], Step [75/225], Training Accuracy: 47.8750%, Training Loss: 1.0637%\n",
      "Epoch [7/300], Step [76/225], Training Accuracy: 47.8413%, Training Loss: 1.0631%\n",
      "Epoch [7/300], Step [77/225], Training Accuracy: 47.7881%, Training Loss: 1.0633%\n",
      "Epoch [7/300], Step [78/225], Training Accuracy: 47.7564%, Training Loss: 1.0628%\n",
      "Epoch [7/300], Step [79/225], Training Accuracy: 47.8639%, Training Loss: 1.0627%\n",
      "Epoch [7/300], Step [80/225], Training Accuracy: 47.7930%, Training Loss: 1.0635%\n",
      "Epoch [7/300], Step [81/225], Training Accuracy: 47.7238%, Training Loss: 1.0637%\n",
      "Epoch [7/300], Step [82/225], Training Accuracy: 47.8277%, Training Loss: 1.0623%\n",
      "Epoch [7/300], Step [83/225], Training Accuracy: 47.8727%, Training Loss: 1.0612%\n",
      "Epoch [7/300], Step [84/225], Training Accuracy: 47.9353%, Training Loss: 1.0600%\n",
      "Epoch [7/300], Step [85/225], Training Accuracy: 48.0331%, Training Loss: 1.0594%\n",
      "Epoch [7/300], Step [86/225], Training Accuracy: 48.0741%, Training Loss: 1.0581%\n",
      "Epoch [7/300], Step [87/225], Training Accuracy: 48.1322%, Training Loss: 1.0580%\n",
      "Epoch [7/300], Step [88/225], Training Accuracy: 48.0291%, Training Loss: 1.0589%\n",
      "Epoch [7/300], Step [89/225], Training Accuracy: 48.0864%, Training Loss: 1.0595%\n",
      "Epoch [7/300], Step [90/225], Training Accuracy: 48.0903%, Training Loss: 1.0589%\n",
      "Epoch [7/300], Step [91/225], Training Accuracy: 48.0598%, Training Loss: 1.0598%\n",
      "Epoch [7/300], Step [92/225], Training Accuracy: 48.0469%, Training Loss: 1.0598%\n",
      "Epoch [7/300], Step [93/225], Training Accuracy: 48.1687%, Training Loss: 1.0581%\n",
      "Epoch [7/300], Step [94/225], Training Accuracy: 48.3045%, Training Loss: 1.0559%\n",
      "Epoch [7/300], Step [95/225], Training Accuracy: 48.3224%, Training Loss: 1.0555%\n",
      "Epoch [7/300], Step [96/225], Training Accuracy: 48.4701%, Training Loss: 1.0542%\n",
      "Epoch [7/300], Step [97/225], Training Accuracy: 48.5019%, Training Loss: 1.0537%\n",
      "Epoch [7/300], Step [98/225], Training Accuracy: 48.5332%, Training Loss: 1.0537%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/300], Step [99/225], Training Accuracy: 48.6269%, Training Loss: 1.0534%\n",
      "Epoch [7/300], Step [100/225], Training Accuracy: 48.6250%, Training Loss: 1.0533%\n",
      "Epoch [7/300], Step [101/225], Training Accuracy: 48.6850%, Training Loss: 1.0526%\n",
      "Epoch [7/300], Step [102/225], Training Accuracy: 48.6520%, Training Loss: 1.0536%\n",
      "Epoch [7/300], Step [103/225], Training Accuracy: 48.6802%, Training Loss: 1.0542%\n",
      "Epoch [7/300], Step [104/225], Training Accuracy: 48.7230%, Training Loss: 1.0543%\n",
      "Epoch [7/300], Step [105/225], Training Accuracy: 48.9286%, Training Loss: 1.0531%\n",
      "Epoch [7/300], Step [106/225], Training Accuracy: 48.9387%, Training Loss: 1.0527%\n",
      "Epoch [7/300], Step [107/225], Training Accuracy: 48.8756%, Training Loss: 1.0530%\n",
      "Epoch [7/300], Step [108/225], Training Accuracy: 48.8137%, Training Loss: 1.0529%\n",
      "Epoch [7/300], Step [109/225], Training Accuracy: 48.8245%, Training Loss: 1.0522%\n",
      "Epoch [7/300], Step [110/225], Training Accuracy: 48.7784%, Training Loss: 1.0522%\n",
      "Epoch [7/300], Step [111/225], Training Accuracy: 48.8457%, Training Loss: 1.0511%\n",
      "Epoch [7/300], Step [112/225], Training Accuracy: 48.9537%, Training Loss: 1.0499%\n",
      "Epoch [7/300], Step [113/225], Training Accuracy: 48.9076%, Training Loss: 1.0505%\n",
      "Epoch [7/300], Step [114/225], Training Accuracy: 48.9172%, Training Loss: 1.0504%\n",
      "Epoch [7/300], Step [115/225], Training Accuracy: 48.8859%, Training Loss: 1.0505%\n",
      "Epoch [7/300], Step [116/225], Training Accuracy: 48.7742%, Training Loss: 1.0507%\n",
      "Epoch [7/300], Step [117/225], Training Accuracy: 48.7313%, Training Loss: 1.0516%\n",
      "Epoch [7/300], Step [118/225], Training Accuracy: 48.7553%, Training Loss: 1.0516%\n",
      "Epoch [7/300], Step [119/225], Training Accuracy: 48.8445%, Training Loss: 1.0513%\n",
      "Epoch [7/300], Step [120/225], Training Accuracy: 48.8672%, Training Loss: 1.0518%\n",
      "Epoch [7/300], Step [121/225], Training Accuracy: 48.8249%, Training Loss: 1.0520%\n",
      "Epoch [7/300], Step [122/225], Training Accuracy: 48.9242%, Training Loss: 1.0514%\n",
      "Epoch [7/300], Step [123/225], Training Accuracy: 48.9329%, Training Loss: 1.0509%\n",
      "Epoch [7/300], Step [124/225], Training Accuracy: 48.9289%, Training Loss: 1.0498%\n",
      "Epoch [7/300], Step [125/225], Training Accuracy: 48.9500%, Training Loss: 1.0508%\n",
      "Epoch [7/300], Step [126/225], Training Accuracy: 48.9087%, Training Loss: 1.0510%\n",
      "Epoch [7/300], Step [127/225], Training Accuracy: 48.8066%, Training Loss: 1.0512%\n",
      "Epoch [7/300], Step [128/225], Training Accuracy: 48.8281%, Training Loss: 1.0513%\n",
      "Epoch [7/300], Step [129/225], Training Accuracy: 48.8493%, Training Loss: 1.0510%\n",
      "Epoch [7/300], Step [130/225], Training Accuracy: 48.7740%, Training Loss: 1.0519%\n",
      "Epoch [7/300], Step [131/225], Training Accuracy: 48.7595%, Training Loss: 1.0521%\n",
      "Epoch [7/300], Step [132/225], Training Accuracy: 48.7571%, Training Loss: 1.0520%\n",
      "Epoch [7/300], Step [133/225], Training Accuracy: 48.7195%, Training Loss: 1.0526%\n",
      "Epoch [7/300], Step [134/225], Training Accuracy: 48.6241%, Training Loss: 1.0545%\n",
      "Epoch [7/300], Step [135/225], Training Accuracy: 48.6111%, Training Loss: 1.0550%\n",
      "Epoch [7/300], Step [136/225], Training Accuracy: 48.6213%, Training Loss: 1.0542%\n",
      "Epoch [7/300], Step [137/225], Training Accuracy: 48.6542%, Training Loss: 1.0536%\n",
      "Epoch [7/300], Step [138/225], Training Accuracy: 48.7545%, Training Loss: 1.0521%\n",
      "Epoch [7/300], Step [139/225], Training Accuracy: 48.7073%, Training Loss: 1.0523%\n",
      "Epoch [7/300], Step [140/225], Training Accuracy: 48.7165%, Training Loss: 1.0524%\n",
      "Epoch [7/300], Step [141/225], Training Accuracy: 48.7699%, Training Loss: 1.0516%\n",
      "Epoch [7/300], Step [142/225], Training Accuracy: 48.8556%, Training Loss: 1.0506%\n",
      "Epoch [7/300], Step [143/225], Training Accuracy: 48.8746%, Training Loss: 1.0505%\n",
      "Epoch [7/300], Step [144/225], Training Accuracy: 48.7847%, Training Loss: 1.0512%\n",
      "Epoch [7/300], Step [145/225], Training Accuracy: 48.8147%, Training Loss: 1.0508%\n",
      "Epoch [7/300], Step [146/225], Training Accuracy: 48.8335%, Training Loss: 1.0508%\n",
      "Epoch [7/300], Step [147/225], Training Accuracy: 48.8202%, Training Loss: 1.0505%\n",
      "Epoch [7/300], Step [148/225], Training Accuracy: 48.8387%, Training Loss: 1.0503%\n",
      "Epoch [7/300], Step [149/225], Training Accuracy: 48.8255%, Training Loss: 1.0503%\n",
      "Epoch [7/300], Step [150/225], Training Accuracy: 48.8438%, Training Loss: 1.0495%\n",
      "Epoch [7/300], Step [151/225], Training Accuracy: 48.9031%, Training Loss: 1.0488%\n",
      "Epoch [7/300], Step [152/225], Training Accuracy: 48.8692%, Training Loss: 1.0493%\n",
      "Epoch [7/300], Step [153/225], Training Accuracy: 48.8868%, Training Loss: 1.0488%\n",
      "Epoch [7/300], Step [154/225], Training Accuracy: 48.8839%, Training Loss: 1.0486%\n",
      "Epoch [7/300], Step [155/225], Training Accuracy: 48.8609%, Training Loss: 1.0485%\n",
      "Epoch [7/300], Step [156/225], Training Accuracy: 48.8381%, Training Loss: 1.0490%\n",
      "Epoch [7/300], Step [157/225], Training Accuracy: 48.9351%, Training Loss: 1.0479%\n",
      "Epoch [7/300], Step [158/225], Training Accuracy: 48.8924%, Training Loss: 1.0487%\n",
      "Epoch [7/300], Step [159/225], Training Accuracy: 48.8699%, Training Loss: 1.0485%\n",
      "Epoch [7/300], Step [160/225], Training Accuracy: 48.8770%, Training Loss: 1.0481%\n",
      "Epoch [7/300], Step [161/225], Training Accuracy: 48.9810%, Training Loss: 1.0470%\n",
      "Epoch [7/300], Step [162/225], Training Accuracy: 48.9390%, Training Loss: 1.0467%\n",
      "Epoch [7/300], Step [163/225], Training Accuracy: 48.9264%, Training Loss: 1.0465%\n",
      "Epoch [7/300], Step [164/225], Training Accuracy: 49.0091%, Training Loss: 1.0457%\n",
      "Epoch [7/300], Step [165/225], Training Accuracy: 48.9962%, Training Loss: 1.0462%\n",
      "Epoch [7/300], Step [166/225], Training Accuracy: 48.9928%, Training Loss: 1.0454%\n",
      "Epoch [7/300], Step [167/225], Training Accuracy: 49.0457%, Training Loss: 1.0445%\n",
      "Epoch [7/300], Step [168/225], Training Accuracy: 49.0978%, Training Loss: 1.0438%\n",
      "Epoch [7/300], Step [169/225], Training Accuracy: 49.1402%, Training Loss: 1.0431%\n",
      "Epoch [7/300], Step [170/225], Training Accuracy: 49.1544%, Training Loss: 1.0433%\n",
      "Epoch [7/300], Step [171/225], Training Accuracy: 49.1502%, Training Loss: 1.0428%\n",
      "Epoch [7/300], Step [172/225], Training Accuracy: 49.1007%, Training Loss: 1.0427%\n",
      "Epoch [7/300], Step [173/225], Training Accuracy: 49.1059%, Training Loss: 1.0427%\n",
      "Epoch [7/300], Step [174/225], Training Accuracy: 49.0751%, Training Loss: 1.0431%\n",
      "Epoch [7/300], Step [175/225], Training Accuracy: 49.1518%, Training Loss: 1.0424%\n",
      "Epoch [7/300], Step [176/225], Training Accuracy: 49.1477%, Training Loss: 1.0421%\n",
      "Epoch [7/300], Step [177/225], Training Accuracy: 49.2055%, Training Loss: 1.0415%\n",
      "Epoch [7/300], Step [178/225], Training Accuracy: 49.1924%, Training Loss: 1.0417%\n",
      "Epoch [7/300], Step [179/225], Training Accuracy: 49.2406%, Training Loss: 1.0410%\n",
      "Epoch [7/300], Step [180/225], Training Accuracy: 49.3229%, Training Loss: 1.0402%\n",
      "Epoch [7/300], Step [181/225], Training Accuracy: 49.2490%, Training Loss: 1.0418%\n",
      "Epoch [7/300], Step [182/225], Training Accuracy: 49.2531%, Training Loss: 1.0421%\n",
      "Epoch [7/300], Step [183/225], Training Accuracy: 49.2486%, Training Loss: 1.0417%\n",
      "Epoch [7/300], Step [184/225], Training Accuracy: 49.2272%, Training Loss: 1.0412%\n",
      "Epoch [7/300], Step [185/225], Training Accuracy: 49.2314%, Training Loss: 1.0414%\n",
      "Epoch [7/300], Step [186/225], Training Accuracy: 49.2776%, Training Loss: 1.0404%\n",
      "Epoch [7/300], Step [187/225], Training Accuracy: 49.3148%, Training Loss: 1.0395%\n",
      "Epoch [7/300], Step [188/225], Training Accuracy: 49.3351%, Training Loss: 1.0391%\n",
      "Epoch [7/300], Step [189/225], Training Accuracy: 49.3717%, Training Loss: 1.0382%\n",
      "Epoch [7/300], Step [190/225], Training Accuracy: 49.3421%, Training Loss: 1.0390%\n",
      "Epoch [7/300], Step [191/225], Training Accuracy: 49.3128%, Training Loss: 1.0394%\n",
      "Epoch [7/300], Step [192/225], Training Accuracy: 49.3815%, Training Loss: 1.0387%\n",
      "Epoch [7/300], Step [193/225], Training Accuracy: 49.3038%, Training Loss: 1.0402%\n",
      "Epoch [7/300], Step [194/225], Training Accuracy: 49.2751%, Training Loss: 1.0404%\n",
      "Epoch [7/300], Step [195/225], Training Accuracy: 49.3109%, Training Loss: 1.0400%\n",
      "Epoch [7/300], Step [196/225], Training Accuracy: 49.2985%, Training Loss: 1.0406%\n",
      "Epoch [7/300], Step [197/225], Training Accuracy: 49.2703%, Training Loss: 1.0412%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/300], Step [198/225], Training Accuracy: 49.2977%, Training Loss: 1.0403%\n",
      "Epoch [7/300], Step [199/225], Training Accuracy: 49.2541%, Training Loss: 1.0403%\n",
      "Epoch [7/300], Step [200/225], Training Accuracy: 49.2656%, Training Loss: 1.0406%\n",
      "Epoch [7/300], Step [201/225], Training Accuracy: 49.2304%, Training Loss: 1.0413%\n",
      "Epoch [7/300], Step [202/225], Training Accuracy: 49.2265%, Training Loss: 1.0413%\n",
      "Epoch [7/300], Step [203/225], Training Accuracy: 49.2380%, Training Loss: 1.0412%\n",
      "Epoch [7/300], Step [204/225], Training Accuracy: 49.2494%, Training Loss: 1.0414%\n",
      "Epoch [7/300], Step [205/225], Training Accuracy: 49.2530%, Training Loss: 1.0414%\n",
      "Epoch [7/300], Step [206/225], Training Accuracy: 49.2036%, Training Loss: 1.0419%\n",
      "Epoch [7/300], Step [207/225], Training Accuracy: 49.1923%, Training Loss: 1.0423%\n",
      "Epoch [7/300], Step [208/225], Training Accuracy: 49.1962%, Training Loss: 1.0420%\n",
      "Epoch [7/300], Step [209/225], Training Accuracy: 49.2001%, Training Loss: 1.0424%\n",
      "Epoch [7/300], Step [210/225], Training Accuracy: 49.2113%, Training Loss: 1.0425%\n",
      "Epoch [7/300], Step [211/225], Training Accuracy: 49.2373%, Training Loss: 1.0423%\n",
      "Epoch [7/300], Step [212/225], Training Accuracy: 49.2335%, Training Loss: 1.0423%\n",
      "Epoch [7/300], Step [213/225], Training Accuracy: 49.2371%, Training Loss: 1.0430%\n",
      "Epoch [7/300], Step [214/225], Training Accuracy: 49.2261%, Training Loss: 1.0430%\n",
      "Epoch [7/300], Step [215/225], Training Accuracy: 49.1715%, Training Loss: 1.0437%\n",
      "Epoch [7/300], Step [216/225], Training Accuracy: 49.1681%, Training Loss: 1.0440%\n",
      "Epoch [7/300], Step [217/225], Training Accuracy: 49.1431%, Training Loss: 1.0444%\n",
      "Epoch [7/300], Step [218/225], Training Accuracy: 49.1829%, Training Loss: 1.0443%\n",
      "Epoch [7/300], Step [219/225], Training Accuracy: 49.1866%, Training Loss: 1.0442%\n",
      "Epoch [7/300], Step [220/225], Training Accuracy: 49.2116%, Training Loss: 1.0439%\n",
      "Epoch [7/300], Step [221/225], Training Accuracy: 49.1445%, Training Loss: 1.0447%\n",
      "Epoch [7/300], Step [222/225], Training Accuracy: 49.1484%, Training Loss: 1.0440%\n",
      "Epoch [7/300], Step [223/225], Training Accuracy: 49.1592%, Training Loss: 1.0442%\n",
      "Epoch [7/300], Step [224/225], Training Accuracy: 49.1629%, Training Loss: 1.0437%\n",
      "Epoch [7/300], Step [225/225], Training Accuracy: 49.1384%, Training Loss: 1.0439%\n",
      "Epoch [8/300], Step [1/225], Training Accuracy: 60.9375%, Training Loss: 0.9613%\n",
      "Epoch [8/300], Step [2/225], Training Accuracy: 52.3438%, Training Loss: 1.0246%\n",
      "Epoch [8/300], Step [3/225], Training Accuracy: 49.4792%, Training Loss: 1.0338%\n",
      "Epoch [8/300], Step [4/225], Training Accuracy: 51.1719%, Training Loss: 1.0121%\n",
      "Epoch [8/300], Step [5/225], Training Accuracy: 51.5625%, Training Loss: 1.0095%\n",
      "Epoch [8/300], Step [6/225], Training Accuracy: 51.8229%, Training Loss: 1.0174%\n",
      "Epoch [8/300], Step [7/225], Training Accuracy: 51.5625%, Training Loss: 1.0205%\n",
      "Epoch [8/300], Step [8/225], Training Accuracy: 50.5859%, Training Loss: 1.0199%\n",
      "Epoch [8/300], Step [9/225], Training Accuracy: 50.8681%, Training Loss: 1.0116%\n",
      "Epoch [8/300], Step [10/225], Training Accuracy: 50.6250%, Training Loss: 1.0113%\n",
      "Epoch [8/300], Step [11/225], Training Accuracy: 50.9943%, Training Loss: 1.0048%\n",
      "Epoch [8/300], Step [12/225], Training Accuracy: 51.9531%, Training Loss: 0.9967%\n",
      "Epoch [8/300], Step [13/225], Training Accuracy: 52.7644%, Training Loss: 0.9851%\n",
      "Epoch [8/300], Step [14/225], Training Accuracy: 52.7902%, Training Loss: 0.9866%\n",
      "Epoch [8/300], Step [15/225], Training Accuracy: 52.1875%, Training Loss: 0.9953%\n",
      "Epoch [8/300], Step [16/225], Training Accuracy: 52.2461%, Training Loss: 0.9976%\n",
      "Epoch [8/300], Step [17/225], Training Accuracy: 52.9412%, Training Loss: 0.9912%\n",
      "Epoch [8/300], Step [18/225], Training Accuracy: 53.0382%, Training Loss: 0.9918%\n",
      "Epoch [8/300], Step [19/225], Training Accuracy: 52.7138%, Training Loss: 0.9921%\n",
      "Epoch [8/300], Step [20/225], Training Accuracy: 52.9688%, Training Loss: 0.9896%\n",
      "Epoch [8/300], Step [21/225], Training Accuracy: 52.7530%, Training Loss: 0.9869%\n",
      "Epoch [8/300], Step [22/225], Training Accuracy: 52.4148%, Training Loss: 0.9880%\n",
      "Epoch [8/300], Step [23/225], Training Accuracy: 52.5136%, Training Loss: 0.9846%\n",
      "Epoch [8/300], Step [24/225], Training Accuracy: 52.6042%, Training Loss: 0.9821%\n",
      "Epoch [8/300], Step [25/225], Training Accuracy: 52.9375%, Training Loss: 0.9765%\n",
      "Epoch [8/300], Step [26/225], Training Accuracy: 53.1851%, Training Loss: 0.9723%\n",
      "Epoch [8/300], Step [27/225], Training Accuracy: 53.2986%, Training Loss: 0.9721%\n",
      "Epoch [8/300], Step [28/225], Training Accuracy: 53.5156%, Training Loss: 0.9689%\n",
      "Epoch [8/300], Step [29/225], Training Accuracy: 53.5022%, Training Loss: 0.9663%\n",
      "Epoch [8/300], Step [30/225], Training Accuracy: 53.4375%, Training Loss: 0.9686%\n",
      "Epoch [8/300], Step [31/225], Training Accuracy: 53.4778%, Training Loss: 0.9676%\n",
      "Epoch [8/300], Step [32/225], Training Accuracy: 53.4668%, Training Loss: 0.9662%\n",
      "Epoch [8/300], Step [33/225], Training Accuracy: 53.4091%, Training Loss: 0.9644%\n",
      "Epoch [8/300], Step [34/225], Training Accuracy: 53.1710%, Training Loss: 0.9702%\n",
      "Epoch [8/300], Step [35/225], Training Accuracy: 53.2143%, Training Loss: 0.9747%\n",
      "Epoch [8/300], Step [36/225], Training Accuracy: 52.9948%, Training Loss: 0.9800%\n",
      "Epoch [8/300], Step [37/225], Training Accuracy: 53.0405%, Training Loss: 0.9806%\n",
      "Epoch [8/300], Step [38/225], Training Accuracy: 52.7549%, Training Loss: 0.9840%\n",
      "Epoch [8/300], Step [39/225], Training Accuracy: 52.8446%, Training Loss: 0.9840%\n",
      "Epoch [8/300], Step [40/225], Training Accuracy: 52.6562%, Training Loss: 0.9850%\n",
      "Epoch [8/300], Step [41/225], Training Accuracy: 52.2104%, Training Loss: 0.9881%\n",
      "Epoch [8/300], Step [42/225], Training Accuracy: 52.2693%, Training Loss: 0.9877%\n",
      "Epoch [8/300], Step [43/225], Training Accuracy: 52.1802%, Training Loss: 0.9885%\n",
      "Epoch [8/300], Step [44/225], Training Accuracy: 52.0952%, Training Loss: 0.9900%\n",
      "Epoch [8/300], Step [45/225], Training Accuracy: 52.1528%, Training Loss: 0.9892%\n",
      "Epoch [8/300], Step [46/225], Training Accuracy: 52.3098%, Training Loss: 0.9887%\n",
      "Epoch [8/300], Step [47/225], Training Accuracy: 51.9947%, Training Loss: 0.9897%\n",
      "Epoch [8/300], Step [48/225], Training Accuracy: 51.8229%, Training Loss: 0.9924%\n",
      "Epoch [8/300], Step [49/225], Training Accuracy: 51.6263%, Training Loss: 0.9948%\n",
      "Epoch [8/300], Step [50/225], Training Accuracy: 51.4375%, Training Loss: 0.9958%\n",
      "Epoch [8/300], Step [51/225], Training Accuracy: 51.5319%, Training Loss: 0.9947%\n",
      "Epoch [8/300], Step [52/225], Training Accuracy: 51.5024%, Training Loss: 0.9970%\n",
      "Epoch [8/300], Step [53/225], Training Accuracy: 51.4741%, Training Loss: 0.9980%\n",
      "Epoch [8/300], Step [54/225], Training Accuracy: 51.4757%, Training Loss: 0.9974%\n",
      "Epoch [8/300], Step [55/225], Training Accuracy: 51.4773%, Training Loss: 0.9969%\n",
      "Epoch [8/300], Step [56/225], Training Accuracy: 51.1440%, Training Loss: 1.0005%\n",
      "Epoch [8/300], Step [57/225], Training Accuracy: 51.0965%, Training Loss: 1.0025%\n",
      "Epoch [8/300], Step [58/225], Training Accuracy: 51.0237%, Training Loss: 1.0027%\n",
      "Epoch [8/300], Step [59/225], Training Accuracy: 50.9269%, Training Loss: 1.0032%\n",
      "Epoch [8/300], Step [60/225], Training Accuracy: 50.9375%, Training Loss: 1.0039%\n",
      "Epoch [8/300], Step [61/225], Training Accuracy: 50.8453%, Training Loss: 1.0043%\n",
      "Epoch [8/300], Step [62/225], Training Accuracy: 50.8821%, Training Loss: 1.0042%\n",
      "Epoch [8/300], Step [63/225], Training Accuracy: 50.7192%, Training Loss: 1.0051%\n",
      "Epoch [8/300], Step [64/225], Training Accuracy: 50.6836%, Training Loss: 1.0069%\n",
      "Epoch [8/300], Step [65/225], Training Accuracy: 50.5529%, Training Loss: 1.0085%\n",
      "Epoch [8/300], Step [66/225], Training Accuracy: 50.6866%, Training Loss: 1.0069%\n",
      "Epoch [8/300], Step [67/225], Training Accuracy: 50.6763%, Training Loss: 1.0072%\n",
      "Epoch [8/300], Step [68/225], Training Accuracy: 50.6434%, Training Loss: 1.0087%\n",
      "Epoch [8/300], Step [69/225], Training Accuracy: 50.6341%, Training Loss: 1.0081%\n",
      "Epoch [8/300], Step [70/225], Training Accuracy: 50.6250%, Training Loss: 1.0088%\n",
      "Epoch [8/300], Step [71/225], Training Accuracy: 50.6162%, Training Loss: 1.0079%\n",
      "Epoch [8/300], Step [72/225], Training Accuracy: 50.4774%, Training Loss: 1.0089%\n",
      "Epoch [8/300], Step [73/225], Training Accuracy: 50.4281%, Training Loss: 1.0104%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/300], Step [74/225], Training Accuracy: 50.5068%, Training Loss: 1.0085%\n",
      "Epoch [8/300], Step [75/225], Training Accuracy: 50.6458%, Training Loss: 1.0069%\n",
      "Epoch [8/300], Step [76/225], Training Accuracy: 50.5345%, Training Loss: 1.0067%\n",
      "Epoch [8/300], Step [77/225], Training Accuracy: 50.5885%, Training Loss: 1.0071%\n",
      "Epoch [8/300], Step [78/225], Training Accuracy: 50.5609%, Training Loss: 1.0068%\n",
      "Epoch [8/300], Step [79/225], Training Accuracy: 50.4747%, Training Loss: 1.0075%\n",
      "Epoch [8/300], Step [80/225], Training Accuracy: 50.3906%, Training Loss: 1.0080%\n",
      "Epoch [8/300], Step [81/225], Training Accuracy: 50.3858%, Training Loss: 1.0087%\n",
      "Epoch [8/300], Step [82/225], Training Accuracy: 50.4192%, Training Loss: 1.0074%\n",
      "Epoch [8/300], Step [83/225], Training Accuracy: 50.4142%, Training Loss: 1.0066%\n",
      "Epoch [8/300], Step [84/225], Training Accuracy: 50.4278%, Training Loss: 1.0058%\n",
      "Epoch [8/300], Step [85/225], Training Accuracy: 50.4779%, Training Loss: 1.0052%\n",
      "Epoch [8/300], Step [86/225], Training Accuracy: 50.5087%, Training Loss: 1.0038%\n",
      "Epoch [8/300], Step [87/225], Training Accuracy: 50.6286%, Training Loss: 1.0033%\n",
      "Epoch [8/300], Step [88/225], Training Accuracy: 50.4794%, Training Loss: 1.0054%\n",
      "Epoch [8/300], Step [89/225], Training Accuracy: 50.4389%, Training Loss: 1.0063%\n",
      "Epoch [8/300], Step [90/225], Training Accuracy: 50.4167%, Training Loss: 1.0062%\n",
      "Epoch [8/300], Step [91/225], Training Accuracy: 50.3949%, Training Loss: 1.0060%\n",
      "Epoch [8/300], Step [92/225], Training Accuracy: 50.3397%, Training Loss: 1.0067%\n",
      "Epoch [8/300], Step [93/225], Training Accuracy: 50.4872%, Training Loss: 1.0056%\n",
      "Epoch [8/300], Step [94/225], Training Accuracy: 50.5818%, Training Loss: 1.0040%\n",
      "Epoch [8/300], Step [95/225], Training Accuracy: 50.6579%, Training Loss: 1.0041%\n",
      "Epoch [8/300], Step [96/225], Training Accuracy: 50.8138%, Training Loss: 1.0029%\n",
      "Epoch [8/300], Step [97/225], Training Accuracy: 50.8054%, Training Loss: 1.0029%\n",
      "Epoch [8/300], Step [98/225], Training Accuracy: 50.7972%, Training Loss: 1.0031%\n",
      "Epoch [8/300], Step [99/225], Training Accuracy: 50.8838%, Training Loss: 1.0030%\n",
      "Epoch [8/300], Step [100/225], Training Accuracy: 50.8594%, Training Loss: 1.0031%\n",
      "Epoch [8/300], Step [101/225], Training Accuracy: 50.9282%, Training Loss: 1.0024%\n",
      "Epoch [8/300], Step [102/225], Training Accuracy: 50.9038%, Training Loss: 1.0034%\n",
      "Epoch [8/300], Step [103/225], Training Accuracy: 50.9557%, Training Loss: 1.0025%\n",
      "Epoch [8/300], Step [104/225], Training Accuracy: 50.8714%, Training Loss: 1.0024%\n",
      "Epoch [8/300], Step [105/225], Training Accuracy: 51.0417%, Training Loss: 1.0010%\n",
      "Epoch [8/300], Step [106/225], Training Accuracy: 51.0171%, Training Loss: 1.0007%\n",
      "Epoch [8/300], Step [107/225], Training Accuracy: 50.9200%, Training Loss: 1.0015%\n",
      "Epoch [8/300], Step [108/225], Training Accuracy: 50.8536%, Training Loss: 1.0018%\n",
      "Epoch [8/300], Step [109/225], Training Accuracy: 50.9174%, Training Loss: 1.0010%\n",
      "Epoch [8/300], Step [110/225], Training Accuracy: 50.9375%, Training Loss: 1.0002%\n",
      "Epoch [8/300], Step [111/225], Training Accuracy: 50.9572%, Training Loss: 0.9997%\n",
      "Epoch [8/300], Step [112/225], Training Accuracy: 51.0184%, Training Loss: 0.9990%\n",
      "Epoch [8/300], Step [113/225], Training Accuracy: 51.0509%, Training Loss: 0.9986%\n",
      "Epoch [8/300], Step [114/225], Training Accuracy: 51.0417%, Training Loss: 0.9987%\n",
      "Epoch [8/300], Step [115/225], Training Accuracy: 51.0870%, Training Loss: 0.9976%\n",
      "Epoch [8/300], Step [116/225], Training Accuracy: 51.0372%, Training Loss: 0.9977%\n",
      "Epoch [8/300], Step [117/225], Training Accuracy: 50.9882%, Training Loss: 0.9992%\n",
      "Epoch [8/300], Step [118/225], Training Accuracy: 51.0593%, Training Loss: 0.9986%\n",
      "Epoch [8/300], Step [119/225], Training Accuracy: 51.1029%, Training Loss: 0.9981%\n",
      "Epoch [8/300], Step [120/225], Training Accuracy: 51.1068%, Training Loss: 0.9982%\n",
      "Epoch [8/300], Step [121/225], Training Accuracy: 51.0718%, Training Loss: 0.9985%\n",
      "Epoch [8/300], Step [122/225], Training Accuracy: 51.1142%, Training Loss: 0.9981%\n",
      "Epoch [8/300], Step [123/225], Training Accuracy: 51.1179%, Training Loss: 0.9977%\n",
      "Epoch [8/300], Step [124/225], Training Accuracy: 51.1215%, Training Loss: 0.9974%\n",
      "Epoch [8/300], Step [125/225], Training Accuracy: 51.1375%, Training Loss: 0.9994%\n",
      "Epoch [8/300], Step [126/225], Training Accuracy: 51.0789%, Training Loss: 1.0007%\n",
      "Epoch [8/300], Step [127/225], Training Accuracy: 51.0089%, Training Loss: 1.0012%\n",
      "Epoch [8/300], Step [128/225], Training Accuracy: 50.9155%, Training Loss: 1.0017%\n",
      "Epoch [8/300], Step [129/225], Training Accuracy: 50.8721%, Training Loss: 1.0015%\n",
      "Epoch [8/300], Step [130/225], Training Accuracy: 50.8293%, Training Loss: 1.0026%\n",
      "Epoch [8/300], Step [131/225], Training Accuracy: 50.8111%, Training Loss: 1.0037%\n",
      "Epoch [8/300], Step [132/225], Training Accuracy: 50.8286%, Training Loss: 1.0038%\n",
      "Epoch [8/300], Step [133/225], Training Accuracy: 50.7989%, Training Loss: 1.0046%\n",
      "Epoch [8/300], Step [134/225], Training Accuracy: 50.6880%, Training Loss: 1.0081%\n",
      "Epoch [8/300], Step [135/225], Training Accuracy: 50.6713%, Training Loss: 1.0091%\n",
      "Epoch [8/300], Step [136/225], Training Accuracy: 50.6893%, Training Loss: 1.0091%\n",
      "Epoch [8/300], Step [137/225], Training Accuracy: 50.6729%, Training Loss: 1.0086%\n",
      "Epoch [8/300], Step [138/225], Training Accuracy: 50.7586%, Training Loss: 1.0072%\n",
      "Epoch [8/300], Step [139/225], Training Accuracy: 50.6969%, Training Loss: 1.0078%\n",
      "Epoch [8/300], Step [140/225], Training Accuracy: 50.7701%, Training Loss: 1.0072%\n",
      "Epoch [8/300], Step [141/225], Training Accuracy: 50.8200%, Training Loss: 1.0062%\n",
      "Epoch [8/300], Step [142/225], Training Accuracy: 50.8363%, Training Loss: 1.0058%\n",
      "Epoch [8/300], Step [143/225], Training Accuracy: 50.7430%, Training Loss: 1.0062%\n",
      "Epoch [8/300], Step [144/225], Training Accuracy: 50.6619%, Training Loss: 1.0073%\n",
      "Epoch [8/300], Step [145/225], Training Accuracy: 50.6466%, Training Loss: 1.0078%\n",
      "Epoch [8/300], Step [146/225], Training Accuracy: 50.6207%, Training Loss: 1.0083%\n",
      "Epoch [8/300], Step [147/225], Training Accuracy: 50.5846%, Training Loss: 1.0082%\n",
      "Epoch [8/300], Step [148/225], Training Accuracy: 50.6018%, Training Loss: 1.0086%\n",
      "Epoch [8/300], Step [149/225], Training Accuracy: 50.5768%, Training Loss: 1.0090%\n",
      "Epoch [8/300], Step [150/225], Training Accuracy: 50.5729%, Training Loss: 1.0087%\n",
      "Epoch [8/300], Step [151/225], Training Accuracy: 50.5795%, Training Loss: 1.0079%\n",
      "Epoch [8/300], Step [152/225], Training Accuracy: 50.5757%, Training Loss: 1.0081%\n",
      "Epoch [8/300], Step [153/225], Training Accuracy: 50.6536%, Training Loss: 1.0070%\n",
      "Epoch [8/300], Step [154/225], Training Accuracy: 50.6392%, Training Loss: 1.0067%\n",
      "Epoch [8/300], Step [155/225], Training Accuracy: 50.5746%, Training Loss: 1.0070%\n",
      "Epoch [8/300], Step [156/225], Training Accuracy: 50.5308%, Training Loss: 1.0072%\n",
      "Epoch [8/300], Step [157/225], Training Accuracy: 50.6270%, Training Loss: 1.0063%\n",
      "Epoch [8/300], Step [158/225], Training Accuracy: 50.5241%, Training Loss: 1.0073%\n",
      "Epoch [8/300], Step [159/225], Training Accuracy: 50.5012%, Training Loss: 1.0073%\n",
      "Epoch [8/300], Step [160/225], Training Accuracy: 50.5078%, Training Loss: 1.0068%\n",
      "Epoch [8/300], Step [161/225], Training Accuracy: 50.5629%, Training Loss: 1.0064%\n",
      "Epoch [8/300], Step [162/225], Training Accuracy: 50.5883%, Training Loss: 1.0062%\n",
      "Epoch [8/300], Step [163/225], Training Accuracy: 50.5847%, Training Loss: 1.0058%\n",
      "Epoch [8/300], Step [164/225], Training Accuracy: 50.6383%, Training Loss: 1.0057%\n",
      "Epoch [8/300], Step [165/225], Training Accuracy: 50.6913%, Training Loss: 1.0055%\n",
      "Epoch [8/300], Step [166/225], Training Accuracy: 50.6965%, Training Loss: 1.0051%\n",
      "Epoch [8/300], Step [167/225], Training Accuracy: 50.7298%, Training Loss: 1.0044%\n",
      "Epoch [8/300], Step [168/225], Training Accuracy: 50.7254%, Training Loss: 1.0044%\n",
      "Epoch [8/300], Step [169/225], Training Accuracy: 50.8044%, Training Loss: 1.0032%\n",
      "Epoch [8/300], Step [170/225], Training Accuracy: 50.8272%, Training Loss: 1.0033%\n",
      "Epoch [8/300], Step [171/225], Training Accuracy: 50.8315%, Training Loss: 1.0029%\n",
      "Epoch [8/300], Step [172/225], Training Accuracy: 50.7994%, Training Loss: 1.0033%\n",
      "Epoch [8/300], Step [173/225], Training Accuracy: 50.8219%, Training Loss: 1.0026%\n",
      "Epoch [8/300], Step [174/225], Training Accuracy: 50.8710%, Training Loss: 1.0022%\n",
      "Epoch [8/300], Step [175/225], Training Accuracy: 50.9286%, Training Loss: 1.0020%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/300], Step [176/225], Training Accuracy: 50.9322%, Training Loss: 1.0016%\n",
      "Epoch [8/300], Step [177/225], Training Accuracy: 51.0152%, Training Loss: 1.0006%\n",
      "Epoch [8/300], Step [178/225], Training Accuracy: 50.9744%, Training Loss: 1.0010%\n",
      "Epoch [8/300], Step [179/225], Training Accuracy: 51.0213%, Training Loss: 1.0002%\n",
      "Epoch [8/300], Step [180/225], Training Accuracy: 51.1285%, Training Loss: 0.9992%\n",
      "Epoch [8/300], Step [181/225], Training Accuracy: 51.0791%, Training Loss: 1.0002%\n",
      "Epoch [8/300], Step [182/225], Training Accuracy: 51.1075%, Training Loss: 0.9997%\n",
      "Epoch [8/300], Step [183/225], Training Accuracy: 51.0758%, Training Loss: 0.9999%\n",
      "Epoch [8/300], Step [184/225], Training Accuracy: 51.0954%, Training Loss: 0.9992%\n",
      "Epoch [8/300], Step [185/225], Training Accuracy: 51.0895%, Training Loss: 0.9989%\n",
      "Epoch [8/300], Step [186/225], Training Accuracy: 51.1425%, Training Loss: 0.9979%\n",
      "Epoch [8/300], Step [187/225], Training Accuracy: 51.1531%, Training Loss: 0.9976%\n",
      "Epoch [8/300], Step [188/225], Training Accuracy: 51.1553%, Training Loss: 0.9972%\n",
      "Epoch [8/300], Step [189/225], Training Accuracy: 51.1739%, Training Loss: 0.9964%\n",
      "Epoch [8/300], Step [190/225], Training Accuracy: 51.1513%, Training Loss: 0.9972%\n",
      "Epoch [8/300], Step [191/225], Training Accuracy: 51.1371%, Training Loss: 0.9972%\n",
      "Epoch [8/300], Step [192/225], Training Accuracy: 51.2044%, Training Loss: 0.9963%\n",
      "Epoch [8/300], Step [193/225], Training Accuracy: 51.1658%, Training Loss: 0.9971%\n",
      "Epoch [8/300], Step [194/225], Training Accuracy: 51.1437%, Training Loss: 0.9971%\n",
      "Epoch [8/300], Step [195/225], Training Accuracy: 51.1859%, Training Loss: 0.9964%\n",
      "Epoch [8/300], Step [196/225], Training Accuracy: 51.1639%, Training Loss: 0.9969%\n",
      "Epoch [8/300], Step [197/225], Training Accuracy: 51.1501%, Training Loss: 0.9975%\n",
      "Epoch [8/300], Step [198/225], Training Accuracy: 51.1679%, Training Loss: 0.9967%\n",
      "Epoch [8/300], Step [199/225], Training Accuracy: 51.1464%, Training Loss: 0.9969%\n",
      "Epoch [8/300], Step [200/225], Training Accuracy: 51.1641%, Training Loss: 0.9970%\n",
      "Epoch [8/300], Step [201/225], Training Accuracy: 51.1427%, Training Loss: 0.9970%\n",
      "Epoch [8/300], Step [202/225], Training Accuracy: 51.1293%, Training Loss: 0.9971%\n",
      "Epoch [8/300], Step [203/225], Training Accuracy: 51.1546%, Training Loss: 0.9968%\n",
      "Epoch [8/300], Step [204/225], Training Accuracy: 51.1795%, Training Loss: 0.9975%\n",
      "Epoch [8/300], Step [205/225], Training Accuracy: 51.1357%, Training Loss: 0.9978%\n",
      "Epoch [8/300], Step [206/225], Training Accuracy: 51.1302%, Training Loss: 0.9981%\n",
      "Epoch [8/300], Step [207/225], Training Accuracy: 51.1096%, Training Loss: 0.9983%\n",
      "Epoch [8/300], Step [208/225], Training Accuracy: 51.1268%, Training Loss: 0.9977%\n",
      "Epoch [8/300], Step [209/225], Training Accuracy: 51.1438%, Training Loss: 0.9979%\n",
      "Epoch [8/300], Step [210/225], Training Accuracy: 51.1533%, Training Loss: 0.9977%\n",
      "Epoch [8/300], Step [211/225], Training Accuracy: 51.1996%, Training Loss: 0.9975%\n",
      "Epoch [8/300], Step [212/225], Training Accuracy: 51.2014%, Training Loss: 0.9973%\n",
      "Epoch [8/300], Step [213/225], Training Accuracy: 51.2104%, Training Loss: 0.9977%\n",
      "Epoch [8/300], Step [214/225], Training Accuracy: 51.2193%, Training Loss: 0.9974%\n",
      "Epoch [8/300], Step [215/225], Training Accuracy: 51.1555%, Training Loss: 0.9981%\n",
      "Epoch [8/300], Step [216/225], Training Accuracy: 51.1429%, Training Loss: 0.9984%\n",
      "Epoch [8/300], Step [217/225], Training Accuracy: 51.1377%, Training Loss: 0.9988%\n",
      "Epoch [8/300], Step [218/225], Training Accuracy: 51.1253%, Training Loss: 0.9994%\n",
      "Epoch [8/300], Step [219/225], Training Accuracy: 51.0845%, Training Loss: 0.9994%\n",
      "Epoch [8/300], Step [220/225], Training Accuracy: 51.0795%, Training Loss: 0.9992%\n",
      "Epoch [8/300], Step [221/225], Training Accuracy: 51.0181%, Training Loss: 0.9999%\n",
      "Epoch [8/300], Step [222/225], Training Accuracy: 51.0276%, Training Loss: 0.9997%\n",
      "Epoch [8/300], Step [223/225], Training Accuracy: 50.9950%, Training Loss: 0.9998%\n",
      "Epoch [8/300], Step [224/225], Training Accuracy: 50.9277%, Training Loss: 0.9996%\n",
      "Epoch [8/300], Step [225/225], Training Accuracy: 50.9033%, Training Loss: 1.0003%\n",
      "Epoch [9/300], Step [1/225], Training Accuracy: 60.9375%, Training Loss: 0.8873%\n",
      "Epoch [9/300], Step [2/225], Training Accuracy: 53.9062%, Training Loss: 0.9397%\n",
      "Epoch [9/300], Step [3/225], Training Accuracy: 50.0000%, Training Loss: 0.9700%\n",
      "Epoch [9/300], Step [4/225], Training Accuracy: 53.1250%, Training Loss: 0.9533%\n",
      "Epoch [9/300], Step [5/225], Training Accuracy: 53.7500%, Training Loss: 0.9415%\n",
      "Epoch [9/300], Step [6/225], Training Accuracy: 54.6875%, Training Loss: 0.9549%\n",
      "Epoch [9/300], Step [7/225], Training Accuracy: 53.7946%, Training Loss: 0.9658%\n",
      "Epoch [9/300], Step [8/225], Training Accuracy: 52.9297%, Training Loss: 0.9682%\n",
      "Epoch [9/300], Step [9/225], Training Accuracy: 53.4722%, Training Loss: 0.9581%\n",
      "Epoch [9/300], Step [10/225], Training Accuracy: 52.6562%, Training Loss: 0.9657%\n",
      "Epoch [9/300], Step [11/225], Training Accuracy: 52.6989%, Training Loss: 0.9656%\n",
      "Epoch [9/300], Step [12/225], Training Accuracy: 53.2552%, Training Loss: 0.9627%\n",
      "Epoch [9/300], Step [13/225], Training Accuracy: 54.0865%, Training Loss: 0.9514%\n",
      "Epoch [9/300], Step [14/225], Training Accuracy: 54.1295%, Training Loss: 0.9472%\n",
      "Epoch [9/300], Step [15/225], Training Accuracy: 53.5417%, Training Loss: 0.9544%\n",
      "Epoch [9/300], Step [16/225], Training Accuracy: 53.8086%, Training Loss: 0.9536%\n",
      "Epoch [9/300], Step [17/225], Training Accuracy: 54.3199%, Training Loss: 0.9464%\n",
      "Epoch [9/300], Step [18/225], Training Accuracy: 53.7326%, Training Loss: 0.9537%\n",
      "Epoch [9/300], Step [19/225], Training Accuracy: 54.0296%, Training Loss: 0.9537%\n",
      "Epoch [9/300], Step [20/225], Training Accuracy: 54.5312%, Training Loss: 0.9498%\n",
      "Epoch [9/300], Step [21/225], Training Accuracy: 54.5387%, Training Loss: 0.9432%\n",
      "Epoch [9/300], Step [22/225], Training Accuracy: 54.0483%, Training Loss: 0.9486%\n",
      "Epoch [9/300], Step [23/225], Training Accuracy: 54.1440%, Training Loss: 0.9471%\n",
      "Epoch [9/300], Step [24/225], Training Accuracy: 54.2318%, Training Loss: 0.9463%\n",
      "Epoch [9/300], Step [25/225], Training Accuracy: 54.4375%, Training Loss: 0.9419%\n",
      "Epoch [9/300], Step [26/225], Training Accuracy: 54.7476%, Training Loss: 0.9374%\n",
      "Epoch [9/300], Step [27/225], Training Accuracy: 54.8611%, Training Loss: 0.9385%\n",
      "Epoch [9/300], Step [28/225], Training Accuracy: 54.8549%, Training Loss: 0.9342%\n",
      "Epoch [9/300], Step [29/225], Training Accuracy: 54.9030%, Training Loss: 0.9320%\n",
      "Epoch [9/300], Step [30/225], Training Accuracy: 55.0521%, Training Loss: 0.9323%\n",
      "Epoch [9/300], Step [31/225], Training Accuracy: 55.0907%, Training Loss: 0.9316%\n",
      "Epoch [9/300], Step [32/225], Training Accuracy: 55.0293%, Training Loss: 0.9330%\n",
      "Epoch [9/300], Step [33/225], Training Accuracy: 55.1610%, Training Loss: 0.9296%\n",
      "Epoch [9/300], Step [34/225], Training Accuracy: 54.8254%, Training Loss: 0.9369%\n",
      "Epoch [9/300], Step [35/225], Training Accuracy: 54.9107%, Training Loss: 0.9384%\n",
      "Epoch [9/300], Step [36/225], Training Accuracy: 54.8611%, Training Loss: 0.9424%\n",
      "Epoch [9/300], Step [37/225], Training Accuracy: 54.6453%, Training Loss: 0.9423%\n",
      "Epoch [9/300], Step [38/225], Training Accuracy: 54.6053%, Training Loss: 0.9415%\n",
      "Epoch [9/300], Step [39/225], Training Accuracy: 54.5272%, Training Loss: 0.9427%\n",
      "Epoch [9/300], Step [40/225], Training Accuracy: 54.3750%, Training Loss: 0.9432%\n",
      "Epoch [9/300], Step [41/225], Training Accuracy: 54.0777%, Training Loss: 0.9473%\n",
      "Epoch [9/300], Step [42/225], Training Accuracy: 54.0923%, Training Loss: 0.9456%\n",
      "Epoch [9/300], Step [43/225], Training Accuracy: 54.0698%, Training Loss: 0.9467%\n",
      "Epoch [9/300], Step [44/225], Training Accuracy: 54.2259%, Training Loss: 0.9465%\n",
      "Epoch [9/300], Step [45/225], Training Accuracy: 54.1667%, Training Loss: 0.9452%\n",
      "Epoch [9/300], Step [46/225], Training Accuracy: 54.2459%, Training Loss: 0.9430%\n",
      "Epoch [9/300], Step [47/225], Training Accuracy: 54.0559%, Training Loss: 0.9446%\n",
      "Epoch [9/300], Step [48/225], Training Accuracy: 54.1016%, Training Loss: 0.9443%\n",
      "Epoch [9/300], Step [49/225], Training Accuracy: 54.1454%, Training Loss: 0.9452%\n",
      "Epoch [9/300], Step [50/225], Training Accuracy: 54.0625%, Training Loss: 0.9445%\n",
      "Epoch [9/300], Step [51/225], Training Accuracy: 54.0748%, Training Loss: 0.9430%\n",
      "Epoch [9/300], Step [52/225], Training Accuracy: 54.1466%, Training Loss: 0.9416%\n",
      "Epoch [9/300], Step [53/225], Training Accuracy: 54.0979%, Training Loss: 0.9423%\n",
      "Epoch [9/300], Step [54/225], Training Accuracy: 53.9641%, Training Loss: 0.9446%\n",
      "Epoch [9/300], Step [55/225], Training Accuracy: 53.9773%, Training Loss: 0.9452%\n",
      "Epoch [9/300], Step [56/225], Training Accuracy: 53.7667%, Training Loss: 0.9462%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/300], Step [57/225], Training Accuracy: 53.6732%, Training Loss: 0.9474%\n",
      "Epoch [9/300], Step [58/225], Training Accuracy: 53.6369%, Training Loss: 0.9481%\n",
      "Epoch [9/300], Step [59/225], Training Accuracy: 53.7341%, Training Loss: 0.9468%\n",
      "Epoch [9/300], Step [60/225], Training Accuracy: 53.6979%, Training Loss: 0.9493%\n",
      "Epoch [9/300], Step [61/225], Training Accuracy: 53.6885%, Training Loss: 0.9483%\n",
      "Epoch [9/300], Step [62/225], Training Accuracy: 53.6290%, Training Loss: 0.9493%\n",
      "Epoch [9/300], Step [63/225], Training Accuracy: 53.5714%, Training Loss: 0.9509%\n",
      "Epoch [9/300], Step [64/225], Training Accuracy: 53.4180%, Training Loss: 0.9554%\n",
      "Epoch [9/300], Step [65/225], Training Accuracy: 53.4135%, Training Loss: 0.9562%\n",
      "Epoch [9/300], Step [66/225], Training Accuracy: 53.5038%, Training Loss: 0.9555%\n",
      "Epoch [9/300], Step [67/225], Training Accuracy: 53.5215%, Training Loss: 0.9564%\n",
      "Epoch [9/300], Step [68/225], Training Accuracy: 53.4926%, Training Loss: 0.9575%\n",
      "Epoch [9/300], Step [69/225], Training Accuracy: 53.5100%, Training Loss: 0.9564%\n",
      "Epoch [9/300], Step [70/225], Training Accuracy: 53.5045%, Training Loss: 0.9578%\n",
      "Epoch [9/300], Step [71/225], Training Accuracy: 53.4111%, Training Loss: 0.9574%\n",
      "Epoch [9/300], Step [72/225], Training Accuracy: 53.2986%, Training Loss: 0.9586%\n",
      "Epoch [9/300], Step [73/225], Training Accuracy: 53.1892%, Training Loss: 0.9591%\n",
      "Epoch [9/300], Step [74/225], Training Accuracy: 53.2095%, Training Loss: 0.9572%\n",
      "Epoch [9/300], Step [75/225], Training Accuracy: 53.2708%, Training Loss: 0.9561%\n",
      "Epoch [9/300], Step [76/225], Training Accuracy: 53.2278%, Training Loss: 0.9557%\n",
      "Epoch [9/300], Step [77/225], Training Accuracy: 53.1656%, Training Loss: 0.9562%\n",
      "Epoch [9/300], Step [78/225], Training Accuracy: 53.1651%, Training Loss: 0.9554%\n",
      "Epoch [9/300], Step [79/225], Training Accuracy: 53.1250%, Training Loss: 0.9556%\n",
      "Epoch [9/300], Step [80/225], Training Accuracy: 52.9883%, Training Loss: 0.9565%\n",
      "Epoch [9/300], Step [81/225], Training Accuracy: 53.0093%, Training Loss: 0.9560%\n",
      "Epoch [9/300], Step [82/225], Training Accuracy: 53.0107%, Training Loss: 0.9571%\n",
      "Epoch [9/300], Step [83/225], Training Accuracy: 52.9367%, Training Loss: 0.9577%\n",
      "Epoch [9/300], Step [84/225], Training Accuracy: 52.9762%, Training Loss: 0.9565%\n",
      "Epoch [9/300], Step [85/225], Training Accuracy: 53.0515%, Training Loss: 0.9564%\n",
      "Epoch [9/300], Step [86/225], Training Accuracy: 53.1068%, Training Loss: 0.9552%\n",
      "Epoch [9/300], Step [87/225], Training Accuracy: 53.1070%, Training Loss: 0.9560%\n",
      "Epoch [9/300], Step [88/225], Training Accuracy: 53.0717%, Training Loss: 0.9580%\n",
      "Epoch [9/300], Step [89/225], Training Accuracy: 53.0548%, Training Loss: 0.9591%\n",
      "Epoch [9/300], Step [90/225], Training Accuracy: 53.0382%, Training Loss: 0.9588%\n",
      "Epoch [9/300], Step [91/225], Training Accuracy: 52.9876%, Training Loss: 0.9589%\n",
      "Epoch [9/300], Step [92/225], Training Accuracy: 52.8872%, Training Loss: 0.9606%\n",
      "Epoch [9/300], Step [93/225], Training Accuracy: 52.9570%, Training Loss: 0.9596%\n",
      "Epoch [9/300], Step [94/225], Training Accuracy: 53.0419%, Training Loss: 0.9580%\n",
      "Epoch [9/300], Step [95/225], Training Accuracy: 52.9441%, Training Loss: 0.9586%\n",
      "Epoch [9/300], Step [96/225], Training Accuracy: 53.0924%, Training Loss: 0.9572%\n",
      "Epoch [9/300], Step [97/225], Training Accuracy: 53.0928%, Training Loss: 0.9567%\n",
      "Epoch [9/300], Step [98/225], Training Accuracy: 53.1250%, Training Loss: 0.9562%\n",
      "Epoch [9/300], Step [99/225], Training Accuracy: 53.1723%, Training Loss: 0.9563%\n",
      "Epoch [9/300], Step [100/225], Training Accuracy: 53.1406%, Training Loss: 0.9558%\n",
      "Epoch [9/300], Step [101/225], Training Accuracy: 53.1559%, Training Loss: 0.9548%\n",
      "Epoch [9/300], Step [102/225], Training Accuracy: 53.1403%, Training Loss: 0.9551%\n",
      "Epoch [9/300], Step [103/225], Training Accuracy: 53.2008%, Training Loss: 0.9546%\n",
      "Epoch [9/300], Step [104/225], Training Accuracy: 53.1550%, Training Loss: 0.9545%\n",
      "Epoch [9/300], Step [105/225], Training Accuracy: 53.3036%, Training Loss: 0.9533%\n",
      "Epoch [9/300], Step [106/225], Training Accuracy: 53.2871%, Training Loss: 0.9533%\n",
      "Epoch [9/300], Step [107/225], Training Accuracy: 53.1980%, Training Loss: 0.9544%\n",
      "Epoch [9/300], Step [108/225], Training Accuracy: 53.2118%, Training Loss: 0.9538%\n",
      "Epoch [9/300], Step [109/225], Training Accuracy: 53.2110%, Training Loss: 0.9532%\n",
      "Epoch [9/300], Step [110/225], Training Accuracy: 53.2102%, Training Loss: 0.9532%\n",
      "Epoch [9/300], Step [111/225], Training Accuracy: 53.2095%, Training Loss: 0.9525%\n",
      "Epoch [9/300], Step [112/225], Training Accuracy: 53.2087%, Training Loss: 0.9519%\n",
      "Epoch [9/300], Step [113/225], Training Accuracy: 53.1665%, Training Loss: 0.9520%\n",
      "Epoch [9/300], Step [114/225], Training Accuracy: 53.1935%, Training Loss: 0.9519%\n",
      "Epoch [9/300], Step [115/225], Training Accuracy: 53.2609%, Training Loss: 0.9510%\n",
      "Epoch [9/300], Step [116/225], Training Accuracy: 53.2193%, Training Loss: 0.9519%\n",
      "Epoch [9/300], Step [117/225], Training Accuracy: 53.1116%, Training Loss: 0.9541%\n",
      "Epoch [9/300], Step [118/225], Training Accuracy: 53.1647%, Training Loss: 0.9527%\n",
      "Epoch [9/300], Step [119/225], Training Accuracy: 53.2038%, Training Loss: 0.9524%\n",
      "Epoch [9/300], Step [120/225], Training Accuracy: 53.2292%, Training Loss: 0.9526%\n",
      "Epoch [9/300], Step [121/225], Training Accuracy: 53.1637%, Training Loss: 0.9544%\n",
      "Epoch [9/300], Step [122/225], Training Accuracy: 53.1890%, Training Loss: 0.9540%\n",
      "Epoch [9/300], Step [123/225], Training Accuracy: 53.2012%, Training Loss: 0.9540%\n",
      "Epoch [9/300], Step [124/225], Training Accuracy: 53.1754%, Training Loss: 0.9536%\n",
      "Epoch [9/300], Step [125/225], Training Accuracy: 53.2000%, Training Loss: 0.9552%\n",
      "Epoch [9/300], Step [126/225], Training Accuracy: 53.2490%, Training Loss: 0.9550%\n",
      "Epoch [9/300], Step [127/225], Training Accuracy: 53.1619%, Training Loss: 0.9563%\n",
      "Epoch [9/300], Step [128/225], Training Accuracy: 53.1128%, Training Loss: 0.9570%\n",
      "Epoch [9/300], Step [129/225], Training Accuracy: 53.0523%, Training Loss: 0.9576%\n",
      "Epoch [9/300], Step [130/225], Training Accuracy: 52.9688%, Training Loss: 0.9584%\n",
      "Epoch [9/300], Step [131/225], Training Accuracy: 52.9103%, Training Loss: 0.9595%\n",
      "Epoch [9/300], Step [132/225], Training Accuracy: 52.7817%, Training Loss: 0.9600%\n",
      "Epoch [9/300], Step [133/225], Training Accuracy: 52.8195%, Training Loss: 0.9605%\n",
      "Epoch [9/300], Step [134/225], Training Accuracy: 52.6586%, Training Loss: 0.9629%\n",
      "Epoch [9/300], Step [135/225], Training Accuracy: 52.6620%, Training Loss: 0.9626%\n",
      "Epoch [9/300], Step [136/225], Training Accuracy: 52.6884%, Training Loss: 0.9623%\n",
      "Epoch [9/300], Step [137/225], Training Accuracy: 52.6688%, Training Loss: 0.9621%\n",
      "Epoch [9/300], Step [138/225], Training Accuracy: 52.7400%, Training Loss: 0.9616%\n",
      "Epoch [9/300], Step [139/225], Training Accuracy: 52.6978%, Training Loss: 0.9619%\n",
      "Epoch [9/300], Step [140/225], Training Accuracy: 52.7232%, Training Loss: 0.9619%\n",
      "Epoch [9/300], Step [141/225], Training Accuracy: 52.7815%, Training Loss: 0.9611%\n",
      "Epoch [9/300], Step [142/225], Training Accuracy: 52.8059%, Training Loss: 0.9607%\n",
      "Epoch [9/300], Step [143/225], Training Accuracy: 52.7863%, Training Loss: 0.9605%\n",
      "Epoch [9/300], Step [144/225], Training Accuracy: 52.7344%, Training Loss: 0.9610%\n",
      "Epoch [9/300], Step [145/225], Training Accuracy: 52.7478%, Training Loss: 0.9612%\n",
      "Epoch [9/300], Step [146/225], Training Accuracy: 52.7397%, Training Loss: 0.9612%\n",
      "Epoch [9/300], Step [147/225], Training Accuracy: 52.7636%, Training Loss: 0.9610%\n",
      "Epoch [9/300], Step [148/225], Training Accuracy: 52.7766%, Training Loss: 0.9605%\n",
      "Epoch [9/300], Step [149/225], Training Accuracy: 52.7265%, Training Loss: 0.9608%\n",
      "Epoch [9/300], Step [150/225], Training Accuracy: 52.7188%, Training Loss: 0.9602%\n",
      "Epoch [9/300], Step [151/225], Training Accuracy: 52.7628%, Training Loss: 0.9593%\n",
      "Epoch [9/300], Step [152/225], Training Accuracy: 52.7549%, Training Loss: 0.9592%\n",
      "Epoch [9/300], Step [153/225], Training Accuracy: 52.7880%, Training Loss: 0.9586%\n",
      "Epoch [9/300], Step [154/225], Training Accuracy: 52.8308%, Training Loss: 0.9583%\n",
      "Epoch [9/300], Step [155/225], Training Accuracy: 52.8024%, Training Loss: 0.9586%\n",
      "Epoch [9/300], Step [156/225], Training Accuracy: 52.7544%, Training Loss: 0.9590%\n",
      "Epoch [9/300], Step [157/225], Training Accuracy: 52.8165%, Training Loss: 0.9584%\n",
      "Epoch [9/300], Step [158/225], Training Accuracy: 52.7789%, Training Loss: 0.9593%\n",
      "Epoch [9/300], Step [159/225], Training Accuracy: 52.7417%, Training Loss: 0.9599%\n",
      "Epoch [9/300], Step [160/225], Training Accuracy: 52.7441%, Training Loss: 0.9597%\n",
      "Epoch [9/300], Step [161/225], Training Accuracy: 52.7756%, Training Loss: 0.9590%\n",
      "Epoch [9/300], Step [162/225], Training Accuracy: 52.8356%, Training Loss: 0.9582%\n",
      "Epoch [9/300], Step [163/225], Training Accuracy: 52.8470%, Training Loss: 0.9580%\n",
      "Epoch [9/300], Step [164/225], Training Accuracy: 52.8868%, Training Loss: 0.9574%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/300], Step [165/225], Training Accuracy: 52.9072%, Training Loss: 0.9576%\n",
      "Epoch [9/300], Step [166/225], Training Accuracy: 52.8897%, Training Loss: 0.9571%\n",
      "Epoch [9/300], Step [167/225], Training Accuracy: 52.9566%, Training Loss: 0.9563%\n",
      "Epoch [9/300], Step [168/225], Training Accuracy: 52.9762%, Training Loss: 0.9560%\n",
      "Epoch [9/300], Step [169/225], Training Accuracy: 53.0325%, Training Loss: 0.9548%\n",
      "Epoch [9/300], Step [170/225], Training Accuracy: 53.0331%, Training Loss: 0.9545%\n",
      "Epoch [9/300], Step [171/225], Training Accuracy: 53.0154%, Training Loss: 0.9545%\n",
      "Epoch [9/300], Step [172/225], Training Accuracy: 52.9615%, Training Loss: 0.9551%\n",
      "Epoch [9/300], Step [173/225], Training Accuracy: 52.9444%, Training Loss: 0.9551%\n",
      "Epoch [9/300], Step [174/225], Training Accuracy: 52.9903%, Training Loss: 0.9546%\n",
      "Epoch [9/300], Step [175/225], Training Accuracy: 53.0714%, Training Loss: 0.9540%\n",
      "Epoch [9/300], Step [176/225], Training Accuracy: 53.1161%, Training Loss: 0.9537%\n",
      "Epoch [9/300], Step [177/225], Training Accuracy: 53.1780%, Training Loss: 0.9531%\n",
      "Epoch [9/300], Step [178/225], Training Accuracy: 53.1952%, Training Loss: 0.9533%\n",
      "Epoch [9/300], Step [179/225], Training Accuracy: 53.2559%, Training Loss: 0.9529%\n",
      "Epoch [9/300], Step [180/225], Training Accuracy: 53.3247%, Training Loss: 0.9518%\n",
      "Epoch [9/300], Step [181/225], Training Accuracy: 53.2545%, Training Loss: 0.9528%\n",
      "Epoch [9/300], Step [182/225], Training Accuracy: 53.2709%, Training Loss: 0.9525%\n",
      "Epoch [9/300], Step [183/225], Training Accuracy: 53.2189%, Training Loss: 0.9523%\n",
      "Epoch [9/300], Step [184/225], Training Accuracy: 53.2184%, Training Loss: 0.9522%\n",
      "Epoch [9/300], Step [185/225], Training Accuracy: 53.2348%, Training Loss: 0.9525%\n",
      "Epoch [9/300], Step [186/225], Training Accuracy: 53.2594%, Training Loss: 0.9518%\n",
      "Epoch [9/300], Step [187/225], Training Accuracy: 53.3088%, Training Loss: 0.9510%\n",
      "Epoch [9/300], Step [188/225], Training Accuracy: 53.3577%, Training Loss: 0.9509%\n",
      "Epoch [9/300], Step [189/225], Training Accuracy: 53.4061%, Training Loss: 0.9498%\n",
      "Epoch [9/300], Step [190/225], Training Accuracy: 53.3964%, Training Loss: 0.9503%\n",
      "Epoch [9/300], Step [191/225], Training Accuracy: 53.3704%, Training Loss: 0.9509%\n",
      "Epoch [9/300], Step [192/225], Training Accuracy: 53.4505%, Training Loss: 0.9501%\n",
      "Epoch [9/300], Step [193/225], Training Accuracy: 53.4165%, Training Loss: 0.9509%\n",
      "Epoch [9/300], Step [194/225], Training Accuracy: 53.3908%, Training Loss: 0.9509%\n",
      "Epoch [9/300], Step [195/225], Training Accuracy: 53.4295%, Training Loss: 0.9505%\n",
      "Epoch [9/300], Step [196/225], Training Accuracy: 53.4359%, Training Loss: 0.9509%\n",
      "Epoch [9/300], Step [197/225], Training Accuracy: 53.4423%, Training Loss: 0.9507%\n",
      "Epoch [9/300], Step [198/225], Training Accuracy: 53.4485%, Training Loss: 0.9502%\n",
      "Epoch [9/300], Step [199/225], Training Accuracy: 53.4312%, Training Loss: 0.9499%\n",
      "Epoch [9/300], Step [200/225], Training Accuracy: 53.4688%, Training Loss: 0.9495%\n",
      "Epoch [9/300], Step [201/225], Training Accuracy: 53.4204%, Training Loss: 0.9502%\n",
      "Epoch [9/300], Step [202/225], Training Accuracy: 53.3957%, Training Loss: 0.9510%\n",
      "Epoch [9/300], Step [203/225], Training Accuracy: 53.4406%, Training Loss: 0.9509%\n",
      "Epoch [9/300], Step [204/225], Training Accuracy: 53.4467%, Training Loss: 0.9513%\n",
      "Epoch [9/300], Step [205/225], Training Accuracy: 53.4299%, Training Loss: 0.9520%\n",
      "Epoch [9/300], Step [206/225], Training Accuracy: 53.4284%, Training Loss: 0.9522%\n",
      "Epoch [9/300], Step [207/225], Training Accuracy: 53.4345%, Training Loss: 0.9527%\n",
      "Epoch [9/300], Step [208/225], Training Accuracy: 53.4931%, Training Loss: 0.9523%\n",
      "Epoch [9/300], Step [209/225], Training Accuracy: 53.5063%, Training Loss: 0.9524%\n",
      "Epoch [9/300], Step [210/225], Training Accuracy: 53.4970%, Training Loss: 0.9524%\n",
      "Epoch [9/300], Step [211/225], Training Accuracy: 53.5175%, Training Loss: 0.9523%\n",
      "Epoch [9/300], Step [212/225], Training Accuracy: 53.4935%, Training Loss: 0.9529%\n",
      "Epoch [9/300], Step [213/225], Training Accuracy: 53.4551%, Training Loss: 0.9538%\n",
      "Epoch [9/300], Step [214/225], Training Accuracy: 53.4828%, Training Loss: 0.9535%\n",
      "Epoch [9/300], Step [215/225], Training Accuracy: 53.4593%, Training Loss: 0.9542%\n",
      "Epoch [9/300], Step [216/225], Training Accuracy: 53.4433%, Training Loss: 0.9543%\n",
      "Epoch [9/300], Step [217/225], Training Accuracy: 53.3842%, Training Loss: 0.9550%\n",
      "Epoch [9/300], Step [218/225], Training Accuracy: 53.4045%, Training Loss: 0.9555%\n",
      "Epoch [9/300], Step [219/225], Training Accuracy: 53.3747%, Training Loss: 0.9555%\n",
      "Epoch [9/300], Step [220/225], Training Accuracy: 53.3736%, Training Loss: 0.9555%\n",
      "Epoch [9/300], Step [221/225], Training Accuracy: 53.3795%, Training Loss: 0.9556%\n",
      "Epoch [9/300], Step [222/225], Training Accuracy: 53.3784%, Training Loss: 0.9556%\n",
      "Epoch [9/300], Step [223/225], Training Accuracy: 53.3422%, Training Loss: 0.9559%\n",
      "Epoch [9/300], Step [224/225], Training Accuracy: 53.3412%, Training Loss: 0.9556%\n",
      "Epoch [9/300], Step [225/225], Training Accuracy: 53.3421%, Training Loss: 0.9559%\n",
      "Epoch [10/300], Step [1/225], Training Accuracy: 64.0625%, Training Loss: 0.7920%\n",
      "Epoch [10/300], Step [2/225], Training Accuracy: 60.1562%, Training Loss: 0.8834%\n",
      "Epoch [10/300], Step [3/225], Training Accuracy: 59.3750%, Training Loss: 0.9313%\n",
      "Epoch [10/300], Step [4/225], Training Accuracy: 57.0312%, Training Loss: 0.9356%\n",
      "Epoch [10/300], Step [5/225], Training Accuracy: 57.1875%, Training Loss: 0.9148%\n",
      "Epoch [10/300], Step [6/225], Training Accuracy: 57.2917%, Training Loss: 0.9255%\n",
      "Epoch [10/300], Step [7/225], Training Accuracy: 55.8036%, Training Loss: 0.9429%\n",
      "Epoch [10/300], Step [8/225], Training Accuracy: 54.8828%, Training Loss: 0.9492%\n",
      "Epoch [10/300], Step [9/225], Training Accuracy: 54.6875%, Training Loss: 0.9436%\n",
      "Epoch [10/300], Step [10/225], Training Accuracy: 53.1250%, Training Loss: 0.9596%\n",
      "Epoch [10/300], Step [11/225], Training Accuracy: 53.4091%, Training Loss: 0.9610%\n",
      "Epoch [10/300], Step [12/225], Training Accuracy: 54.2969%, Training Loss: 0.9529%\n",
      "Epoch [10/300], Step [13/225], Training Accuracy: 56.0096%, Training Loss: 0.9290%\n",
      "Epoch [10/300], Step [14/225], Training Accuracy: 56.0268%, Training Loss: 0.9213%\n",
      "Epoch [10/300], Step [15/225], Training Accuracy: 55.6250%, Training Loss: 0.9227%\n",
      "Epoch [10/300], Step [16/225], Training Accuracy: 55.5664%, Training Loss: 0.9181%\n",
      "Epoch [10/300], Step [17/225], Training Accuracy: 55.8824%, Training Loss: 0.9103%\n",
      "Epoch [10/300], Step [18/225], Training Accuracy: 55.3819%, Training Loss: 0.9153%\n",
      "Epoch [10/300], Step [19/225], Training Accuracy: 55.4276%, Training Loss: 0.9122%\n",
      "Epoch [10/300], Step [20/225], Training Accuracy: 55.3125%, Training Loss: 0.9122%\n",
      "Epoch [10/300], Step [21/225], Training Accuracy: 55.2083%, Training Loss: 0.9090%\n",
      "Epoch [10/300], Step [22/225], Training Accuracy: 54.4744%, Training Loss: 0.9141%\n",
      "Epoch [10/300], Step [23/225], Training Accuracy: 54.4158%, Training Loss: 0.9115%\n",
      "Epoch [10/300], Step [24/225], Training Accuracy: 54.6224%, Training Loss: 0.9119%\n",
      "Epoch [10/300], Step [25/225], Training Accuracy: 55.2500%, Training Loss: 0.9098%\n",
      "Epoch [10/300], Step [26/225], Training Accuracy: 55.2284%, Training Loss: 0.9086%\n",
      "Epoch [10/300], Step [27/225], Training Accuracy: 55.2083%, Training Loss: 0.9087%\n",
      "Epoch [10/300], Step [28/225], Training Accuracy: 55.5246%, Training Loss: 0.9033%\n",
      "Epoch [10/300], Step [29/225], Training Accuracy: 55.7651%, Training Loss: 0.9006%\n",
      "Epoch [10/300], Step [30/225], Training Accuracy: 55.6250%, Training Loss: 0.9022%\n",
      "Epoch [10/300], Step [31/225], Training Accuracy: 55.4435%, Training Loss: 0.9041%\n",
      "Epoch [10/300], Step [32/225], Training Accuracy: 55.3223%, Training Loss: 0.9034%\n",
      "Epoch [10/300], Step [33/225], Training Accuracy: 55.4451%, Training Loss: 0.9005%\n",
      "Epoch [10/300], Step [34/225], Training Accuracy: 55.1471%, Training Loss: 0.9086%\n",
      "Epoch [10/300], Step [35/225], Training Accuracy: 55.3571%, Training Loss: 0.9082%\n",
      "Epoch [10/300], Step [36/225], Training Accuracy: 55.3819%, Training Loss: 0.9125%\n",
      "Epoch [10/300], Step [37/225], Training Accuracy: 55.3209%, Training Loss: 0.9124%\n",
      "Epoch [10/300], Step [38/225], Training Accuracy: 55.3865%, Training Loss: 0.9114%\n",
      "Epoch [10/300], Step [39/225], Training Accuracy: 55.4087%, Training Loss: 0.9145%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/300], Step [40/225], Training Accuracy: 55.0391%, Training Loss: 0.9174%\n",
      "Epoch [10/300], Step [41/225], Training Accuracy: 54.8018%, Training Loss: 0.9197%\n",
      "Epoch [10/300], Step [42/225], Training Accuracy: 54.7991%, Training Loss: 0.9184%\n",
      "Epoch [10/300], Step [43/225], Training Accuracy: 54.6875%, Training Loss: 0.9175%\n",
      "Epoch [10/300], Step [44/225], Training Accuracy: 54.7940%, Training Loss: 0.9167%\n",
      "Epoch [10/300], Step [45/225], Training Accuracy: 54.6875%, Training Loss: 0.9168%\n",
      "Epoch [10/300], Step [46/225], Training Accuracy: 54.9932%, Training Loss: 0.9131%\n",
      "Epoch [10/300], Step [47/225], Training Accuracy: 54.7872%, Training Loss: 0.9151%\n",
      "Epoch [10/300], Step [48/225], Training Accuracy: 54.7526%, Training Loss: 0.9172%\n",
      "Epoch [10/300], Step [49/225], Training Accuracy: 54.7832%, Training Loss: 0.9184%\n",
      "Epoch [10/300], Step [50/225], Training Accuracy: 54.8438%, Training Loss: 0.9176%\n",
      "Epoch [10/300], Step [51/225], Training Accuracy: 54.8100%, Training Loss: 0.9182%\n",
      "Epoch [10/300], Step [52/225], Training Accuracy: 54.9279%, Training Loss: 0.9164%\n",
      "Epoch [10/300], Step [53/225], Training Accuracy: 55.0118%, Training Loss: 0.9175%\n",
      "Epoch [10/300], Step [54/225], Training Accuracy: 54.8900%, Training Loss: 0.9187%\n",
      "Epoch [10/300], Step [55/225], Training Accuracy: 54.8295%, Training Loss: 0.9210%\n",
      "Epoch [10/300], Step [56/225], Training Accuracy: 54.7154%, Training Loss: 0.9215%\n",
      "Epoch [10/300], Step [57/225], Training Accuracy: 54.7423%, Training Loss: 0.9201%\n",
      "Epoch [10/300], Step [58/225], Training Accuracy: 54.6067%, Training Loss: 0.9214%\n",
      "Epoch [10/300], Step [59/225], Training Accuracy: 54.6345%, Training Loss: 0.9216%\n",
      "Epoch [10/300], Step [60/225], Training Accuracy: 54.7396%, Training Loss: 0.9216%\n",
      "Epoch [10/300], Step [61/225], Training Accuracy: 54.8156%, Training Loss: 0.9206%\n",
      "Epoch [10/300], Step [62/225], Training Accuracy: 54.9143%, Training Loss: 0.9188%\n",
      "Epoch [10/300], Step [63/225], Training Accuracy: 54.8363%, Training Loss: 0.9204%\n",
      "Epoch [10/300], Step [64/225], Training Accuracy: 54.7119%, Training Loss: 0.9248%\n",
      "Epoch [10/300], Step [65/225], Training Accuracy: 54.5192%, Training Loss: 0.9265%\n",
      "Epoch [10/300], Step [66/225], Training Accuracy: 54.5455%, Training Loss: 0.9253%\n",
      "Epoch [10/300], Step [67/225], Training Accuracy: 54.5709%, Training Loss: 0.9264%\n",
      "Epoch [10/300], Step [68/225], Training Accuracy: 54.5267%, Training Loss: 0.9273%\n",
      "Epoch [10/300], Step [69/225], Training Accuracy: 54.5063%, Training Loss: 0.9270%\n",
      "Epoch [10/300], Step [70/225], Training Accuracy: 54.5089%, Training Loss: 0.9280%\n",
      "Epoch [10/300], Step [71/225], Training Accuracy: 54.4894%, Training Loss: 0.9269%\n",
      "Epoch [10/300], Step [72/225], Training Accuracy: 54.3837%, Training Loss: 0.9293%\n",
      "Epoch [10/300], Step [73/225], Training Accuracy: 54.3878%, Training Loss: 0.9291%\n",
      "Epoch [10/300], Step [74/225], Training Accuracy: 54.5819%, Training Loss: 0.9266%\n",
      "Epoch [10/300], Step [75/225], Training Accuracy: 54.5625%, Training Loss: 0.9265%\n",
      "Epoch [10/300], Step [76/225], Training Accuracy: 54.4408%, Training Loss: 0.9276%\n",
      "Epoch [10/300], Step [77/225], Training Accuracy: 54.3628%, Training Loss: 0.9292%\n",
      "Epoch [10/300], Step [78/225], Training Accuracy: 54.3269%, Training Loss: 0.9291%\n",
      "Epoch [10/300], Step [79/225], Training Accuracy: 54.3710%, Training Loss: 0.9294%\n",
      "Epoch [10/300], Step [80/225], Training Accuracy: 54.3164%, Training Loss: 0.9299%\n",
      "Epoch [10/300], Step [81/225], Training Accuracy: 54.3403%, Training Loss: 0.9308%\n",
      "Epoch [10/300], Step [82/225], Training Accuracy: 54.3064%, Training Loss: 0.9311%\n",
      "Epoch [10/300], Step [83/225], Training Accuracy: 54.2922%, Training Loss: 0.9320%\n",
      "Epoch [10/300], Step [84/225], Training Accuracy: 54.4271%, Training Loss: 0.9303%\n",
      "Epoch [10/300], Step [85/225], Training Accuracy: 54.5404%, Training Loss: 0.9294%\n",
      "Epoch [10/300], Step [86/225], Training Accuracy: 54.6512%, Training Loss: 0.9286%\n",
      "Epoch [10/300], Step [87/225], Training Accuracy: 54.6516%, Training Loss: 0.9301%\n",
      "Epoch [10/300], Step [88/225], Training Accuracy: 54.5099%, Training Loss: 0.9328%\n",
      "Epoch [10/300], Step [89/225], Training Accuracy: 54.5295%, Training Loss: 0.9340%\n",
      "Epoch [10/300], Step [90/225], Training Accuracy: 54.5312%, Training Loss: 0.9339%\n",
      "Epoch [10/300], Step [91/225], Training Accuracy: 54.4471%, Training Loss: 0.9353%\n",
      "Epoch [10/300], Step [92/225], Training Accuracy: 54.3478%, Training Loss: 0.9377%\n",
      "Epoch [10/300], Step [93/225], Training Accuracy: 54.3851%, Training Loss: 0.9367%\n",
      "Epoch [10/300], Step [94/225], Training Accuracy: 54.4714%, Training Loss: 0.9353%\n",
      "Epoch [10/300], Step [95/225], Training Accuracy: 54.4572%, Training Loss: 0.9362%\n",
      "Epoch [10/300], Step [96/225], Training Accuracy: 54.5898%, Training Loss: 0.9347%\n",
      "Epoch [10/300], Step [97/225], Training Accuracy: 54.5425%, Training Loss: 0.9351%\n",
      "Epoch [10/300], Step [98/225], Training Accuracy: 54.5440%, Training Loss: 0.9341%\n",
      "Epoch [10/300], Step [99/225], Training Accuracy: 54.5770%, Training Loss: 0.9340%\n",
      "Epoch [10/300], Step [100/225], Training Accuracy: 54.5312%, Training Loss: 0.9346%\n",
      "Epoch [10/300], Step [101/225], Training Accuracy: 54.5483%, Training Loss: 0.9344%\n",
      "Epoch [10/300], Step [102/225], Training Accuracy: 54.5956%, Training Loss: 0.9351%\n",
      "Epoch [10/300], Step [103/225], Training Accuracy: 54.5813%, Training Loss: 0.9350%\n",
      "Epoch [10/300], Step [104/225], Training Accuracy: 54.5072%, Training Loss: 0.9350%\n",
      "Epoch [10/300], Step [105/225], Training Accuracy: 54.5685%, Training Loss: 0.9343%\n",
      "Epoch [10/300], Step [106/225], Training Accuracy: 54.5106%, Training Loss: 0.9339%\n",
      "Epoch [10/300], Step [107/225], Training Accuracy: 54.4977%, Training Loss: 0.9340%\n",
      "Epoch [10/300], Step [108/225], Training Accuracy: 54.4705%, Training Loss: 0.9335%\n",
      "Epoch [10/300], Step [109/225], Training Accuracy: 54.5872%, Training Loss: 0.9327%\n",
      "Epoch [10/300], Step [110/225], Training Accuracy: 54.5739%, Training Loss: 0.9326%\n",
      "Epoch [10/300], Step [111/225], Training Accuracy: 54.6171%, Training Loss: 0.9315%\n",
      "Epoch [10/300], Step [112/225], Training Accuracy: 54.6875%, Training Loss: 0.9305%\n",
      "Epoch [10/300], Step [113/225], Training Accuracy: 54.6875%, Training Loss: 0.9304%\n",
      "Epoch [10/300], Step [114/225], Training Accuracy: 54.6738%, Training Loss: 0.9304%\n",
      "Epoch [10/300], Step [115/225], Training Accuracy: 54.7418%, Training Loss: 0.9289%\n",
      "Epoch [10/300], Step [116/225], Training Accuracy: 54.8357%, Training Loss: 0.9285%\n",
      "Epoch [10/300], Step [117/225], Training Accuracy: 54.6741%, Training Loss: 0.9306%\n",
      "Epoch [10/300], Step [118/225], Training Accuracy: 54.7537%, Training Loss: 0.9291%\n",
      "Epoch [10/300], Step [119/225], Training Accuracy: 54.7532%, Training Loss: 0.9290%\n",
      "Epoch [10/300], Step [120/225], Training Accuracy: 54.8177%, Training Loss: 0.9283%\n",
      "Epoch [10/300], Step [121/225], Training Accuracy: 54.7521%, Training Loss: 0.9283%\n",
      "Epoch [10/300], Step [122/225], Training Accuracy: 54.7643%, Training Loss: 0.9283%\n",
      "Epoch [10/300], Step [123/225], Training Accuracy: 54.8018%, Training Loss: 0.9275%\n",
      "Epoch [10/300], Step [124/225], Training Accuracy: 54.7883%, Training Loss: 0.9275%\n",
      "Epoch [10/300], Step [125/225], Training Accuracy: 54.7875%, Training Loss: 0.9291%\n",
      "Epoch [10/300], Step [126/225], Training Accuracy: 54.7619%, Training Loss: 0.9287%\n",
      "Epoch [10/300], Step [127/225], Training Accuracy: 54.7982%, Training Loss: 0.9289%\n",
      "Epoch [10/300], Step [128/225], Training Accuracy: 54.7241%, Training Loss: 0.9297%\n",
      "Epoch [10/300], Step [129/225], Training Accuracy: 54.6512%, Training Loss: 0.9303%\n",
      "Epoch [10/300], Step [130/225], Training Accuracy: 54.5913%, Training Loss: 0.9307%\n",
      "Epoch [10/300], Step [131/225], Training Accuracy: 54.5444%, Training Loss: 0.9309%\n",
      "Epoch [10/300], Step [132/225], Training Accuracy: 54.5099%, Training Loss: 0.9311%\n",
      "Epoch [10/300], Step [133/225], Training Accuracy: 54.5935%, Training Loss: 0.9300%\n",
      "Epoch [10/300], Step [134/225], Training Accuracy: 54.4660%, Training Loss: 0.9315%\n",
      "Epoch [10/300], Step [135/225], Training Accuracy: 54.4907%, Training Loss: 0.9309%\n",
      "Epoch [10/300], Step [136/225], Training Accuracy: 54.5841%, Training Loss: 0.9299%\n",
      "Epoch [10/300], Step [137/225], Training Accuracy: 54.6077%, Training Loss: 0.9297%\n",
      "Epoch [10/300], Step [138/225], Training Accuracy: 54.6649%, Training Loss: 0.9285%\n",
      "Epoch [10/300], Step [139/225], Training Accuracy: 54.6538%, Training Loss: 0.9288%\n",
      "Epoch [10/300], Step [140/225], Training Accuracy: 54.7433%, Training Loss: 0.9276%\n",
      "Epoch [10/300], Step [141/225], Training Accuracy: 54.7983%, Training Loss: 0.9268%\n",
      "Epoch [10/300], Step [142/225], Training Accuracy: 54.7865%, Training Loss: 0.9264%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/300], Step [143/225], Training Accuracy: 54.7531%, Training Loss: 0.9266%\n",
      "Epoch [10/300], Step [144/225], Training Accuracy: 54.7092%, Training Loss: 0.9268%\n",
      "Epoch [10/300], Step [145/225], Training Accuracy: 54.6444%, Training Loss: 0.9270%\n",
      "Epoch [10/300], Step [146/225], Training Accuracy: 54.6554%, Training Loss: 0.9277%\n",
      "Epoch [10/300], Step [147/225], Training Accuracy: 54.6237%, Training Loss: 0.9282%\n",
      "Epoch [10/300], Step [148/225], Training Accuracy: 54.6242%, Training Loss: 0.9281%\n",
      "Epoch [10/300], Step [149/225], Training Accuracy: 54.6036%, Training Loss: 0.9283%\n",
      "Epoch [10/300], Step [150/225], Training Accuracy: 54.6042%, Training Loss: 0.9278%\n",
      "Epoch [10/300], Step [151/225], Training Accuracy: 54.6254%, Training Loss: 0.9271%\n",
      "Epoch [10/300], Step [152/225], Training Accuracy: 54.6669%, Training Loss: 0.9266%\n",
      "Epoch [10/300], Step [153/225], Training Accuracy: 54.6977%, Training Loss: 0.9259%\n",
      "Epoch [10/300], Step [154/225], Training Accuracy: 54.7179%, Training Loss: 0.9255%\n",
      "Epoch [10/300], Step [155/225], Training Accuracy: 54.6875%, Training Loss: 0.9256%\n",
      "Epoch [10/300], Step [156/225], Training Accuracy: 54.6374%, Training Loss: 0.9267%\n",
      "Epoch [10/300], Step [157/225], Training Accuracy: 54.6975%, Training Loss: 0.9262%\n",
      "Epoch [10/300], Step [158/225], Training Accuracy: 54.6677%, Training Loss: 0.9267%\n",
      "Epoch [10/300], Step [159/225], Training Accuracy: 54.6777%, Training Loss: 0.9266%\n",
      "Epoch [10/300], Step [160/225], Training Accuracy: 54.6777%, Training Loss: 0.9264%\n",
      "Epoch [10/300], Step [161/225], Training Accuracy: 54.6875%, Training Loss: 0.9263%\n",
      "Epoch [10/300], Step [162/225], Training Accuracy: 54.6971%, Training Loss: 0.9262%\n",
      "Epoch [10/300], Step [163/225], Training Accuracy: 54.6875%, Training Loss: 0.9257%\n",
      "Epoch [10/300], Step [164/225], Training Accuracy: 54.7542%, Training Loss: 0.9252%\n",
      "Epoch [10/300], Step [165/225], Training Accuracy: 54.7822%, Training Loss: 0.9252%\n",
      "Epoch [10/300], Step [166/225], Training Accuracy: 54.8099%, Training Loss: 0.9252%\n",
      "Epoch [10/300], Step [167/225], Training Accuracy: 54.8091%, Training Loss: 0.9246%\n",
      "Epoch [10/300], Step [168/225], Training Accuracy: 54.8270%, Training Loss: 0.9247%\n",
      "Epoch [10/300], Step [169/225], Training Accuracy: 54.9186%, Training Loss: 0.9235%\n",
      "Epoch [10/300], Step [170/225], Training Accuracy: 54.9449%, Training Loss: 0.9234%\n",
      "Epoch [10/300], Step [171/225], Training Accuracy: 54.9251%, Training Loss: 0.9233%\n",
      "Epoch [10/300], Step [172/225], Training Accuracy: 54.9055%, Training Loss: 0.9234%\n",
      "Epoch [10/300], Step [173/225], Training Accuracy: 54.8862%, Training Loss: 0.9232%\n",
      "Epoch [10/300], Step [174/225], Training Accuracy: 54.9120%, Training Loss: 0.9231%\n",
      "Epoch [10/300], Step [175/225], Training Accuracy: 54.9643%, Training Loss: 0.9224%\n",
      "Epoch [10/300], Step [176/225], Training Accuracy: 54.9716%, Training Loss: 0.9219%\n",
      "Epoch [10/300], Step [177/225], Training Accuracy: 55.0230%, Training Loss: 0.9212%\n",
      "Epoch [10/300], Step [178/225], Training Accuracy: 55.0825%, Training Loss: 0.9208%\n",
      "Epoch [10/300], Step [179/225], Training Accuracy: 55.1327%, Training Loss: 0.9203%\n",
      "Epoch [10/300], Step [180/225], Training Accuracy: 55.2083%, Training Loss: 0.9195%\n",
      "Epoch [10/300], Step [181/225], Training Accuracy: 55.1709%, Training Loss: 0.9196%\n",
      "Epoch [10/300], Step [182/225], Training Accuracy: 55.1854%, Training Loss: 0.9193%\n",
      "Epoch [10/300], Step [183/225], Training Accuracy: 55.1656%, Training Loss: 0.9193%\n",
      "Epoch [10/300], Step [184/225], Training Accuracy: 55.1800%, Training Loss: 0.9189%\n",
      "Epoch [10/300], Step [185/225], Training Accuracy: 55.1858%, Training Loss: 0.9192%\n",
      "Epoch [10/300], Step [186/225], Training Accuracy: 55.1999%, Training Loss: 0.9184%\n",
      "Epoch [10/300], Step [187/225], Training Accuracy: 55.2557%, Training Loss: 0.9179%\n",
      "Epoch [10/300], Step [188/225], Training Accuracy: 55.3025%, Training Loss: 0.9172%\n",
      "Epoch [10/300], Step [189/225], Training Accuracy: 55.3571%, Training Loss: 0.9162%\n",
      "Epoch [10/300], Step [190/225], Training Accuracy: 55.3701%, Training Loss: 0.9167%\n",
      "Epoch [10/300], Step [191/225], Training Accuracy: 55.3338%, Training Loss: 0.9171%\n",
      "Epoch [10/300], Step [192/225], Training Accuracy: 55.4199%, Training Loss: 0.9163%\n",
      "Epoch [10/300], Step [193/225], Training Accuracy: 55.3918%, Training Loss: 0.9169%\n",
      "Epoch [10/300], Step [194/225], Training Accuracy: 55.3882%, Training Loss: 0.9172%\n",
      "Epoch [10/300], Step [195/225], Training Accuracy: 55.4487%, Training Loss: 0.9163%\n",
      "Epoch [10/300], Step [196/225], Training Accuracy: 55.4927%, Training Loss: 0.9166%\n",
      "Epoch [10/300], Step [197/225], Training Accuracy: 55.4965%, Training Loss: 0.9172%\n",
      "Epoch [10/300], Step [198/225], Training Accuracy: 55.5003%, Training Loss: 0.9166%\n",
      "Epoch [10/300], Step [199/225], Training Accuracy: 55.4805%, Training Loss: 0.9161%\n",
      "Epoch [10/300], Step [200/225], Training Accuracy: 55.5391%, Training Loss: 0.9156%\n",
      "Epoch [10/300], Step [201/225], Training Accuracy: 55.5426%, Training Loss: 0.9157%\n",
      "Epoch [10/300], Step [202/225], Training Accuracy: 55.5306%, Training Loss: 0.9160%\n",
      "Epoch [10/300], Step [203/225], Training Accuracy: 55.5804%, Training Loss: 0.9153%\n",
      "Epoch [10/300], Step [204/225], Training Accuracy: 55.5683%, Training Loss: 0.9158%\n",
      "Epoch [10/300], Step [205/225], Training Accuracy: 55.5335%, Training Loss: 0.9163%\n",
      "Epoch [10/300], Step [206/225], Training Accuracy: 55.5143%, Training Loss: 0.9167%\n",
      "Epoch [10/300], Step [207/225], Training Accuracy: 55.4801%, Training Loss: 0.9173%\n",
      "Epoch [10/300], Step [208/225], Training Accuracy: 55.5364%, Training Loss: 0.9167%\n",
      "Epoch [10/300], Step [209/225], Training Accuracy: 55.5248%, Training Loss: 0.9171%\n",
      "Epoch [10/300], Step [210/225], Training Accuracy: 55.5060%, Training Loss: 0.9172%\n",
      "Epoch [10/300], Step [211/225], Training Accuracy: 55.5317%, Training Loss: 0.9169%\n",
      "Epoch [10/300], Step [212/225], Training Accuracy: 55.5425%, Training Loss: 0.9173%\n",
      "Epoch [10/300], Step [213/225], Training Accuracy: 55.4944%, Training Loss: 0.9184%\n",
      "Epoch [10/300], Step [214/225], Training Accuracy: 55.4834%, Training Loss: 0.9180%\n",
      "Epoch [10/300], Step [215/225], Training Accuracy: 55.4070%, Training Loss: 0.9187%\n",
      "Epoch [10/300], Step [216/225], Training Accuracy: 55.3819%, Training Loss: 0.9189%\n",
      "Epoch [10/300], Step [217/225], Training Accuracy: 55.3643%, Training Loss: 0.9191%\n",
      "Epoch [10/300], Step [218/225], Training Accuracy: 55.3684%, Training Loss: 0.9193%\n",
      "Epoch [10/300], Step [219/225], Training Accuracy: 55.3724%, Training Loss: 0.9190%\n",
      "Epoch [10/300], Step [220/225], Training Accuracy: 55.3835%, Training Loss: 0.9188%\n",
      "Epoch [10/300], Step [221/225], Training Accuracy: 55.3167%, Training Loss: 0.9196%\n",
      "Epoch [10/300], Step [222/225], Training Accuracy: 55.3280%, Training Loss: 0.9195%\n",
      "Epoch [10/300], Step [223/225], Training Accuracy: 55.3041%, Training Loss: 0.9200%\n",
      "Epoch [10/300], Step [224/225], Training Accuracy: 55.3153%, Training Loss: 0.9198%\n",
      "Epoch [10/300], Step [225/225], Training Accuracy: 55.3016%, Training Loss: 0.9199%\n",
      "Epoch [11/300], Step [1/225], Training Accuracy: 67.1875%, Training Loss: 0.8331%\n",
      "Epoch [11/300], Step [2/225], Training Accuracy: 62.5000%, Training Loss: 0.8394%\n",
      "Epoch [11/300], Step [3/225], Training Accuracy: 60.9375%, Training Loss: 0.8737%\n",
      "Epoch [11/300], Step [4/225], Training Accuracy: 60.5469%, Training Loss: 0.8803%\n",
      "Epoch [11/300], Step [5/225], Training Accuracy: 60.9375%, Training Loss: 0.8775%\n",
      "Epoch [11/300], Step [6/225], Training Accuracy: 60.9375%, Training Loss: 0.8983%\n",
      "Epoch [11/300], Step [7/225], Training Accuracy: 59.5982%, Training Loss: 0.9023%\n",
      "Epoch [11/300], Step [8/225], Training Accuracy: 58.7891%, Training Loss: 0.9102%\n",
      "Epoch [11/300], Step [9/225], Training Accuracy: 57.8125%, Training Loss: 0.9050%\n",
      "Epoch [11/300], Step [10/225], Training Accuracy: 56.7188%, Training Loss: 0.9145%\n",
      "Epoch [11/300], Step [11/225], Training Accuracy: 56.8182%, Training Loss: 0.9132%\n",
      "Epoch [11/300], Step [12/225], Training Accuracy: 57.2917%, Training Loss: 0.9063%\n",
      "Epoch [11/300], Step [13/225], Training Accuracy: 58.1731%, Training Loss: 0.8962%\n",
      "Epoch [11/300], Step [14/225], Training Accuracy: 58.4821%, Training Loss: 0.8924%\n",
      "Epoch [11/300], Step [15/225], Training Accuracy: 57.8125%, Training Loss: 0.9041%\n",
      "Epoch [11/300], Step [16/225], Training Accuracy: 57.9102%, Training Loss: 0.9017%\n",
      "Epoch [11/300], Step [17/225], Training Accuracy: 58.3640%, Training Loss: 0.8933%\n",
      "Epoch [11/300], Step [18/225], Training Accuracy: 58.1597%, Training Loss: 0.8915%\n",
      "Epoch [11/300], Step [19/225], Training Accuracy: 57.8947%, Training Loss: 0.8934%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/300], Step [20/225], Training Accuracy: 58.2031%, Training Loss: 0.8899%\n",
      "Epoch [11/300], Step [21/225], Training Accuracy: 57.7381%, Training Loss: 0.8871%\n",
      "Epoch [11/300], Step [22/225], Training Accuracy: 57.1023%, Training Loss: 0.8890%\n",
      "Epoch [11/300], Step [23/225], Training Accuracy: 56.9973%, Training Loss: 0.8891%\n",
      "Epoch [11/300], Step [24/225], Training Accuracy: 57.0964%, Training Loss: 0.8893%\n",
      "Epoch [11/300], Step [25/225], Training Accuracy: 57.2500%, Training Loss: 0.8870%\n",
      "Epoch [11/300], Step [26/225], Training Accuracy: 57.2115%, Training Loss: 0.8844%\n",
      "Epoch [11/300], Step [27/225], Training Accuracy: 57.4653%, Training Loss: 0.8848%\n",
      "Epoch [11/300], Step [28/225], Training Accuracy: 57.5893%, Training Loss: 0.8798%\n",
      "Epoch [11/300], Step [29/225], Training Accuracy: 57.9203%, Training Loss: 0.8754%\n",
      "Epoch [11/300], Step [30/225], Training Accuracy: 57.7604%, Training Loss: 0.8740%\n",
      "Epoch [11/300], Step [31/225], Training Accuracy: 57.7621%, Training Loss: 0.8733%\n",
      "Epoch [11/300], Step [32/225], Training Accuracy: 57.8125%, Training Loss: 0.8719%\n",
      "Epoch [11/300], Step [33/225], Training Accuracy: 57.8598%, Training Loss: 0.8696%\n",
      "Epoch [11/300], Step [34/225], Training Accuracy: 57.5368%, Training Loss: 0.8817%\n",
      "Epoch [11/300], Step [35/225], Training Accuracy: 57.6786%, Training Loss: 0.8848%\n",
      "Epoch [11/300], Step [36/225], Training Accuracy: 57.7691%, Training Loss: 0.8831%\n",
      "Epoch [11/300], Step [37/225], Training Accuracy: 57.6436%, Training Loss: 0.8843%\n",
      "Epoch [11/300], Step [38/225], Training Accuracy: 57.6891%, Training Loss: 0.8817%\n",
      "Epoch [11/300], Step [39/225], Training Accuracy: 57.4920%, Training Loss: 0.8863%\n",
      "Epoch [11/300], Step [40/225], Training Accuracy: 57.2266%, Training Loss: 0.8905%\n",
      "Epoch [11/300], Step [41/225], Training Accuracy: 56.7454%, Training Loss: 0.8953%\n",
      "Epoch [11/300], Step [42/225], Training Accuracy: 56.5848%, Training Loss: 0.8973%\n",
      "Epoch [11/300], Step [43/225], Training Accuracy: 56.5407%, Training Loss: 0.8984%\n",
      "Epoch [11/300], Step [44/225], Training Accuracy: 56.5696%, Training Loss: 0.9000%\n",
      "Epoch [11/300], Step [45/225], Training Accuracy: 56.5972%, Training Loss: 0.9020%\n",
      "Epoch [11/300], Step [46/225], Training Accuracy: 56.7595%, Training Loss: 0.8986%\n",
      "Epoch [11/300], Step [47/225], Training Accuracy: 56.7154%, Training Loss: 0.8988%\n",
      "Epoch [11/300], Step [48/225], Training Accuracy: 56.4779%, Training Loss: 0.9008%\n",
      "Epoch [11/300], Step [49/225], Training Accuracy: 56.4732%, Training Loss: 0.9020%\n",
      "Epoch [11/300], Step [50/225], Training Accuracy: 56.4375%, Training Loss: 0.9052%\n",
      "Epoch [11/300], Step [51/225], Training Accuracy: 56.6176%, Training Loss: 0.9057%\n",
      "Epoch [11/300], Step [52/225], Training Accuracy: 56.7308%, Training Loss: 0.9043%\n",
      "Epoch [11/300], Step [53/225], Training Accuracy: 56.7512%, Training Loss: 0.9047%\n",
      "Epoch [11/300], Step [54/225], Training Accuracy: 56.5683%, Training Loss: 0.9068%\n",
      "Epoch [11/300], Step [55/225], Training Accuracy: 56.5057%, Training Loss: 0.9089%\n",
      "Epoch [11/300], Step [56/225], Training Accuracy: 56.3058%, Training Loss: 0.9128%\n",
      "Epoch [11/300], Step [57/225], Training Accuracy: 56.4419%, Training Loss: 0.9099%\n",
      "Epoch [11/300], Step [58/225], Training Accuracy: 56.3578%, Training Loss: 0.9125%\n",
      "Epoch [11/300], Step [59/225], Training Accuracy: 56.1706%, Training Loss: 0.9136%\n",
      "Epoch [11/300], Step [60/225], Training Accuracy: 56.1979%, Training Loss: 0.9150%\n",
      "Epoch [11/300], Step [61/225], Training Accuracy: 56.2500%, Training Loss: 0.9143%\n",
      "Epoch [11/300], Step [62/225], Training Accuracy: 56.3256%, Training Loss: 0.9134%\n",
      "Epoch [11/300], Step [63/225], Training Accuracy: 56.2252%, Training Loss: 0.9137%\n",
      "Epoch [11/300], Step [64/225], Training Accuracy: 56.1035%, Training Loss: 0.9158%\n",
      "Epoch [11/300], Step [65/225], Training Accuracy: 55.9856%, Training Loss: 0.9174%\n",
      "Epoch [11/300], Step [66/225], Training Accuracy: 55.9896%, Training Loss: 0.9173%\n",
      "Epoch [11/300], Step [67/225], Training Accuracy: 56.0168%, Training Loss: 0.9174%\n",
      "Epoch [11/300], Step [68/225], Training Accuracy: 56.0662%, Training Loss: 0.9184%\n",
      "Epoch [11/300], Step [69/225], Training Accuracy: 56.0236%, Training Loss: 0.9201%\n",
      "Epoch [11/300], Step [70/225], Training Accuracy: 55.9598%, Training Loss: 0.9212%\n",
      "Epoch [11/300], Step [71/225], Training Accuracy: 56.0079%, Training Loss: 0.9193%\n",
      "Epoch [11/300], Step [72/225], Training Accuracy: 55.8811%, Training Loss: 0.9201%\n",
      "Epoch [11/300], Step [73/225], Training Accuracy: 55.8647%, Training Loss: 0.9208%\n",
      "Epoch [11/300], Step [74/225], Training Accuracy: 55.9755%, Training Loss: 0.9186%\n",
      "Epoch [11/300], Step [75/225], Training Accuracy: 55.9375%, Training Loss: 0.9188%\n",
      "Epoch [11/300], Step [76/225], Training Accuracy: 55.9005%, Training Loss: 0.9187%\n",
      "Epoch [11/300], Step [77/225], Training Accuracy: 55.9050%, Training Loss: 0.9188%\n",
      "Epoch [11/300], Step [78/225], Training Accuracy: 55.9095%, Training Loss: 0.9190%\n",
      "Epoch [11/300], Step [79/225], Training Accuracy: 55.7951%, Training Loss: 0.9203%\n",
      "Epoch [11/300], Step [80/225], Training Accuracy: 55.6836%, Training Loss: 0.9208%\n",
      "Epoch [11/300], Step [81/225], Training Accuracy: 55.7485%, Training Loss: 0.9200%\n",
      "Epoch [11/300], Step [82/225], Training Accuracy: 55.8308%, Training Loss: 0.9181%\n",
      "Epoch [11/300], Step [83/225], Training Accuracy: 55.7982%, Training Loss: 0.9182%\n",
      "Epoch [11/300], Step [84/225], Training Accuracy: 55.8966%, Training Loss: 0.9166%\n",
      "Epoch [11/300], Step [85/225], Training Accuracy: 56.0110%, Training Loss: 0.9153%\n",
      "Epoch [11/300], Step [86/225], Training Accuracy: 56.1047%, Training Loss: 0.9138%\n",
      "Epoch [11/300], Step [87/225], Training Accuracy: 56.2320%, Training Loss: 0.9128%\n",
      "Epoch [11/300], Step [88/225], Training Accuracy: 56.2500%, Training Loss: 0.9129%\n",
      "Epoch [11/300], Step [89/225], Training Accuracy: 56.2500%, Training Loss: 0.9150%\n",
      "Epoch [11/300], Step [90/225], Training Accuracy: 56.2500%, Training Loss: 0.9148%\n",
      "Epoch [11/300], Step [91/225], Training Accuracy: 56.2500%, Training Loss: 0.9139%\n",
      "Epoch [11/300], Step [92/225], Training Accuracy: 56.1821%, Training Loss: 0.9161%\n",
      "Epoch [11/300], Step [93/225], Training Accuracy: 56.2500%, Training Loss: 0.9146%\n",
      "Epoch [11/300], Step [94/225], Training Accuracy: 56.3664%, Training Loss: 0.9124%\n",
      "Epoch [11/300], Step [95/225], Training Accuracy: 56.3980%, Training Loss: 0.9122%\n",
      "Epoch [11/300], Step [96/225], Training Accuracy: 56.5104%, Training Loss: 0.9109%\n",
      "Epoch [11/300], Step [97/225], Training Accuracy: 56.4755%, Training Loss: 0.9111%\n",
      "Epoch [11/300], Step [98/225], Training Accuracy: 56.4573%, Training Loss: 0.9113%\n",
      "Epoch [11/300], Step [99/225], Training Accuracy: 56.5025%, Training Loss: 0.9107%\n",
      "Epoch [11/300], Step [100/225], Training Accuracy: 56.4531%, Training Loss: 0.9114%\n",
      "Epoch [11/300], Step [101/225], Training Accuracy: 56.4047%, Training Loss: 0.9113%\n",
      "Epoch [11/300], Step [102/225], Training Accuracy: 56.4645%, Training Loss: 0.9113%\n",
      "Epoch [11/300], Step [103/225], Training Accuracy: 56.5231%, Training Loss: 0.9109%\n",
      "Epoch [11/300], Step [104/225], Training Accuracy: 56.4453%, Training Loss: 0.9119%\n",
      "Epoch [11/300], Step [105/225], Training Accuracy: 56.5030%, Training Loss: 0.9114%\n",
      "Epoch [11/300], Step [106/225], Training Accuracy: 56.5006%, Training Loss: 0.9108%\n",
      "Epoch [11/300], Step [107/225], Training Accuracy: 56.3814%, Training Loss: 0.9119%\n",
      "Epoch [11/300], Step [108/225], Training Accuracy: 56.3368%, Training Loss: 0.9113%\n",
      "Epoch [11/300], Step [109/225], Training Accuracy: 56.3933%, Training Loss: 0.9108%\n",
      "Epoch [11/300], Step [110/225], Training Accuracy: 56.3920%, Training Loss: 0.9115%\n",
      "Epoch [11/300], Step [111/225], Training Accuracy: 56.4611%, Training Loss: 0.9105%\n",
      "Epoch [11/300], Step [112/225], Training Accuracy: 56.5011%, Training Loss: 0.9094%\n",
      "Epoch [11/300], Step [113/225], Training Accuracy: 56.5542%, Training Loss: 0.9088%\n",
      "Epoch [11/300], Step [114/225], Training Accuracy: 56.5241%, Training Loss: 0.9092%\n",
      "Epoch [11/300], Step [115/225], Training Accuracy: 56.5625%, Training Loss: 0.9089%\n",
      "Epoch [11/300], Step [116/225], Training Accuracy: 56.5733%, Training Loss: 0.9087%\n",
      "Epoch [11/300], Step [117/225], Training Accuracy: 56.4370%, Training Loss: 0.9101%\n",
      "Epoch [11/300], Step [118/225], Training Accuracy: 56.5148%, Training Loss: 0.9087%\n",
      "Epoch [11/300], Step [119/225], Training Accuracy: 56.4863%, Training Loss: 0.9085%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/300], Step [120/225], Training Accuracy: 56.5365%, Training Loss: 0.9081%\n",
      "Epoch [11/300], Step [121/225], Training Accuracy: 56.4824%, Training Loss: 0.9083%\n",
      "Epoch [11/300], Step [122/225], Training Accuracy: 56.5574%, Training Loss: 0.9076%\n",
      "Epoch [11/300], Step [123/225], Training Accuracy: 56.6184%, Training Loss: 0.9065%\n",
      "Epoch [11/300], Step [124/225], Training Accuracy: 56.6154%, Training Loss: 0.9059%\n",
      "Epoch [11/300], Step [125/225], Training Accuracy: 56.6750%, Training Loss: 0.9083%\n",
      "Epoch [11/300], Step [126/225], Training Accuracy: 56.7212%, Training Loss: 0.9078%\n",
      "Epoch [11/300], Step [127/225], Training Accuracy: 56.7052%, Training Loss: 0.9080%\n",
      "Epoch [11/300], Step [128/225], Training Accuracy: 56.7139%, Training Loss: 0.9080%\n",
      "Epoch [11/300], Step [129/225], Training Accuracy: 56.6134%, Training Loss: 0.9098%\n",
      "Epoch [11/300], Step [130/225], Training Accuracy: 56.5385%, Training Loss: 0.9110%\n",
      "Epoch [11/300], Step [131/225], Training Accuracy: 56.5482%, Training Loss: 0.9111%\n",
      "Epoch [11/300], Step [132/225], Training Accuracy: 56.5341%, Training Loss: 0.9113%\n",
      "Epoch [11/300], Step [133/225], Training Accuracy: 56.6024%, Training Loss: 0.9104%\n",
      "Epoch [11/300], Step [134/225], Training Accuracy: 56.5182%, Training Loss: 0.9121%\n",
      "Epoch [11/300], Step [135/225], Training Accuracy: 56.5162%, Training Loss: 0.9119%\n",
      "Epoch [11/300], Step [136/225], Training Accuracy: 56.6291%, Training Loss: 0.9107%\n",
      "Epoch [11/300], Step [137/225], Training Accuracy: 56.5922%, Training Loss: 0.9107%\n",
      "Epoch [11/300], Step [138/225], Training Accuracy: 56.6576%, Training Loss: 0.9097%\n",
      "Epoch [11/300], Step [139/225], Training Accuracy: 56.6434%, Training Loss: 0.9101%\n",
      "Epoch [11/300], Step [140/225], Training Accuracy: 56.7076%, Training Loss: 0.9088%\n",
      "Epoch [11/300], Step [141/225], Training Accuracy: 56.7376%, Training Loss: 0.9076%\n",
      "Epoch [11/300], Step [142/225], Training Accuracy: 56.7672%, Training Loss: 0.9073%\n",
      "Epoch [11/300], Step [143/225], Training Accuracy: 56.7308%, Training Loss: 0.9077%\n",
      "Epoch [11/300], Step [144/225], Training Accuracy: 56.7166%, Training Loss: 0.9071%\n",
      "Epoch [11/300], Step [145/225], Training Accuracy: 56.7241%, Training Loss: 0.9062%\n",
      "Epoch [11/300], Step [146/225], Training Accuracy: 56.7316%, Training Loss: 0.9062%\n",
      "Epoch [11/300], Step [147/225], Training Accuracy: 56.7283%, Training Loss: 0.9064%\n",
      "Epoch [11/300], Step [148/225], Training Accuracy: 56.7251%, Training Loss: 0.9066%\n",
      "Epoch [11/300], Step [149/225], Training Accuracy: 56.6799%, Training Loss: 0.9064%\n",
      "Epoch [11/300], Step [150/225], Training Accuracy: 56.6875%, Training Loss: 0.9064%\n",
      "Epoch [11/300], Step [151/225], Training Accuracy: 56.6950%, Training Loss: 0.9058%\n",
      "Epoch [11/300], Step [152/225], Training Accuracy: 56.7023%, Training Loss: 0.9057%\n",
      "Epoch [11/300], Step [153/225], Training Accuracy: 56.7504%, Training Loss: 0.9048%\n",
      "Epoch [11/300], Step [154/225], Training Accuracy: 56.7877%, Training Loss: 0.9048%\n",
      "Epoch [11/300], Step [155/225], Training Accuracy: 56.6935%, Training Loss: 0.9055%\n",
      "Epoch [11/300], Step [156/225], Training Accuracy: 56.6506%, Training Loss: 0.9062%\n",
      "Epoch [11/300], Step [157/225], Training Accuracy: 56.6381%, Training Loss: 0.9061%\n",
      "Epoch [11/300], Step [158/225], Training Accuracy: 56.5763%, Training Loss: 0.9067%\n",
      "Epoch [11/300], Step [159/225], Training Accuracy: 56.5743%, Training Loss: 0.9067%\n",
      "Epoch [11/300], Step [160/225], Training Accuracy: 56.5625%, Training Loss: 0.9067%\n",
      "Epoch [11/300], Step [161/225], Training Accuracy: 56.5703%, Training Loss: 0.9068%\n",
      "Epoch [11/300], Step [162/225], Training Accuracy: 56.6165%, Training Loss: 0.9065%\n",
      "Epoch [11/300], Step [163/225], Training Accuracy: 56.5855%, Training Loss: 0.9065%\n",
      "Epoch [11/300], Step [164/225], Training Accuracy: 56.6120%, Training Loss: 0.9058%\n",
      "Epoch [11/300], Step [165/225], Training Accuracy: 56.6288%, Training Loss: 0.9055%\n",
      "Epoch [11/300], Step [166/225], Training Accuracy: 56.6077%, Training Loss: 0.9051%\n",
      "Epoch [11/300], Step [167/225], Training Accuracy: 56.6617%, Training Loss: 0.9038%\n",
      "Epoch [11/300], Step [168/225], Training Accuracy: 56.6778%, Training Loss: 0.9032%\n",
      "Epoch [11/300], Step [169/225], Training Accuracy: 56.7585%, Training Loss: 0.9024%\n",
      "Epoch [11/300], Step [170/225], Training Accuracy: 56.8290%, Training Loss: 0.9019%\n",
      "Epoch [11/300], Step [171/225], Training Accuracy: 56.8257%, Training Loss: 0.9015%\n",
      "Epoch [11/300], Step [172/225], Training Accuracy: 56.7406%, Training Loss: 0.9023%\n",
      "Epoch [11/300], Step [173/225], Training Accuracy: 56.7558%, Training Loss: 0.9018%\n",
      "Epoch [11/300], Step [174/225], Training Accuracy: 56.7708%, Training Loss: 0.9017%\n",
      "Epoch [11/300], Step [175/225], Training Accuracy: 56.8214%, Training Loss: 0.9012%\n",
      "Epoch [11/300], Step [176/225], Training Accuracy: 56.8359%, Training Loss: 0.9008%\n",
      "Epoch [11/300], Step [177/225], Training Accuracy: 56.8944%, Training Loss: 0.8999%\n",
      "Epoch [11/300], Step [178/225], Training Accuracy: 56.9610%, Training Loss: 0.8994%\n",
      "Epoch [11/300], Step [179/225], Training Accuracy: 57.0182%, Training Loss: 0.8986%\n",
      "Epoch [11/300], Step [180/225], Training Accuracy: 57.0573%, Training Loss: 0.8976%\n",
      "Epoch [11/300], Step [181/225], Training Accuracy: 57.0528%, Training Loss: 0.8980%\n",
      "Epoch [11/300], Step [182/225], Training Accuracy: 57.0742%, Training Loss: 0.8976%\n",
      "Epoch [11/300], Step [183/225], Training Accuracy: 57.0697%, Training Loss: 0.8978%\n",
      "Epoch [11/300], Step [184/225], Training Accuracy: 57.0822%, Training Loss: 0.8974%\n",
      "Epoch [11/300], Step [185/225], Training Accuracy: 57.1030%, Training Loss: 0.8975%\n",
      "Epoch [11/300], Step [186/225], Training Accuracy: 57.0985%, Training Loss: 0.8971%\n",
      "Epoch [11/300], Step [187/225], Training Accuracy: 57.0689%, Training Loss: 0.8968%\n",
      "Epoch [11/300], Step [188/225], Training Accuracy: 57.1393%, Training Loss: 0.8962%\n",
      "Epoch [11/300], Step [189/225], Training Accuracy: 57.1925%, Training Loss: 0.8950%\n",
      "Epoch [11/300], Step [190/225], Training Accuracy: 57.2039%, Training Loss: 0.8947%\n",
      "Epoch [11/300], Step [191/225], Training Accuracy: 57.1744%, Training Loss: 0.8952%\n",
      "Epoch [11/300], Step [192/225], Training Accuracy: 57.2591%, Training Loss: 0.8943%\n",
      "Epoch [11/300], Step [193/225], Training Accuracy: 57.2377%, Training Loss: 0.8945%\n",
      "Epoch [11/300], Step [194/225], Training Accuracy: 57.2407%, Training Loss: 0.8945%\n",
      "Epoch [11/300], Step [195/225], Training Accuracy: 57.3157%, Training Loss: 0.8938%\n",
      "Epoch [11/300], Step [196/225], Training Accuracy: 57.3342%, Training Loss: 0.8942%\n",
      "Epoch [11/300], Step [197/225], Training Accuracy: 57.3207%, Training Loss: 0.8949%\n",
      "Epoch [11/300], Step [198/225], Training Accuracy: 57.3311%, Training Loss: 0.8942%\n",
      "Epoch [11/300], Step [199/225], Training Accuracy: 57.3492%, Training Loss: 0.8936%\n",
      "Epoch [11/300], Step [200/225], Training Accuracy: 57.3438%, Training Loss: 0.8934%\n",
      "Epoch [11/300], Step [201/225], Training Accuracy: 57.3539%, Training Loss: 0.8933%\n",
      "Epoch [11/300], Step [202/225], Training Accuracy: 57.3561%, Training Loss: 0.8932%\n",
      "Epoch [11/300], Step [203/225], Training Accuracy: 57.4046%, Training Loss: 0.8923%\n",
      "Epoch [11/300], Step [204/225], Training Accuracy: 57.3836%, Training Loss: 0.8934%\n",
      "Epoch [11/300], Step [205/225], Training Accuracy: 57.3552%, Training Loss: 0.8940%\n",
      "Epoch [11/300], Step [206/225], Training Accuracy: 57.3498%, Training Loss: 0.8944%\n",
      "Epoch [11/300], Step [207/225], Training Accuracy: 57.3294%, Training Loss: 0.8951%\n",
      "Epoch [11/300], Step [208/225], Training Accuracy: 57.3618%, Training Loss: 0.8948%\n",
      "Epoch [11/300], Step [209/225], Training Accuracy: 57.3340%, Training Loss: 0.8949%\n",
      "Epoch [11/300], Step [210/225], Training Accuracy: 57.3140%, Training Loss: 0.8950%\n",
      "Epoch [11/300], Step [211/225], Training Accuracy: 57.3312%, Training Loss: 0.8947%\n",
      "Epoch [11/300], Step [212/225], Training Accuracy: 57.3629%, Training Loss: 0.8944%\n",
      "Epoch [11/300], Step [213/225], Training Accuracy: 57.3283%, Training Loss: 0.8951%\n",
      "Epoch [11/300], Step [214/225], Training Accuracy: 57.3817%, Training Loss: 0.8949%\n",
      "Epoch [11/300], Step [215/225], Training Accuracy: 57.3110%, Training Loss: 0.8957%\n",
      "Epoch [11/300], Step [216/225], Training Accuracy: 57.2989%, Training Loss: 0.8961%\n",
      "Epoch [11/300], Step [217/225], Training Accuracy: 57.2725%, Training Loss: 0.8963%\n",
      "Epoch [11/300], Step [218/225], Training Accuracy: 57.2964%, Training Loss: 0.8963%\n",
      "Epoch [11/300], Step [219/225], Training Accuracy: 57.2917%, Training Loss: 0.8966%\n",
      "Epoch [11/300], Step [220/225], Training Accuracy: 57.2514%, Training Loss: 0.8967%\n",
      "Epoch [11/300], Step [221/225], Training Accuracy: 57.1974%, Training Loss: 0.8974%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/300], Step [222/225], Training Accuracy: 57.2424%, Training Loss: 0.8971%\n",
      "Epoch [11/300], Step [223/225], Training Accuracy: 57.2520%, Training Loss: 0.8971%\n",
      "Epoch [11/300], Step [224/225], Training Accuracy: 57.2614%, Training Loss: 0.8967%\n",
      "Epoch [11/300], Step [225/225], Training Accuracy: 57.2610%, Training Loss: 0.8971%\n",
      "Epoch [12/300], Step [1/225], Training Accuracy: 64.0625%, Training Loss: 0.7767%\n",
      "Epoch [12/300], Step [2/225], Training Accuracy: 58.5938%, Training Loss: 0.8148%\n",
      "Epoch [12/300], Step [3/225], Training Accuracy: 58.3333%, Training Loss: 0.9088%\n",
      "Epoch [12/300], Step [4/225], Training Accuracy: 57.4219%, Training Loss: 0.9008%\n",
      "Epoch [12/300], Step [5/225], Training Accuracy: 59.0625%, Training Loss: 0.8737%\n",
      "Epoch [12/300], Step [6/225], Training Accuracy: 60.6771%, Training Loss: 0.8774%\n",
      "Epoch [12/300], Step [7/225], Training Accuracy: 58.9286%, Training Loss: 0.8821%\n",
      "Epoch [12/300], Step [8/225], Training Accuracy: 58.3984%, Training Loss: 0.8857%\n",
      "Epoch [12/300], Step [9/225], Training Accuracy: 57.8125%, Training Loss: 0.9007%\n",
      "Epoch [12/300], Step [10/225], Training Accuracy: 56.7188%, Training Loss: 0.9279%\n",
      "Epoch [12/300], Step [11/225], Training Accuracy: 56.6761%, Training Loss: 0.9258%\n",
      "Epoch [12/300], Step [12/225], Training Accuracy: 57.4219%, Training Loss: 0.9120%\n",
      "Epoch [12/300], Step [13/225], Training Accuracy: 58.1731%, Training Loss: 0.8985%\n",
      "Epoch [12/300], Step [14/225], Training Accuracy: 57.9241%, Training Loss: 0.9011%\n",
      "Epoch [12/300], Step [15/225], Training Accuracy: 57.8125%, Training Loss: 0.9018%\n",
      "Epoch [12/300], Step [16/225], Training Accuracy: 57.3242%, Training Loss: 0.9068%\n",
      "Epoch [12/300], Step [17/225], Training Accuracy: 57.8125%, Training Loss: 0.8989%\n",
      "Epoch [12/300], Step [18/225], Training Accuracy: 57.9861%, Training Loss: 0.8960%\n",
      "Epoch [12/300], Step [19/225], Training Accuracy: 58.2237%, Training Loss: 0.8944%\n",
      "Epoch [12/300], Step [20/225], Training Accuracy: 58.4375%, Training Loss: 0.8904%\n",
      "Epoch [12/300], Step [21/225], Training Accuracy: 58.4821%, Training Loss: 0.8837%\n",
      "Epoch [12/300], Step [22/225], Training Accuracy: 58.6648%, Training Loss: 0.8839%\n",
      "Epoch [12/300], Step [23/225], Training Accuracy: 58.4918%, Training Loss: 0.8813%\n",
      "Epoch [12/300], Step [24/225], Training Accuracy: 58.2682%, Training Loss: 0.8794%\n",
      "Epoch [12/300], Step [25/225], Training Accuracy: 58.2500%, Training Loss: 0.8750%\n",
      "Epoch [12/300], Step [26/225], Training Accuracy: 57.9327%, Training Loss: 0.8749%\n",
      "Epoch [12/300], Step [27/225], Training Accuracy: 58.0440%, Training Loss: 0.8768%\n",
      "Epoch [12/300], Step [28/225], Training Accuracy: 58.3705%, Training Loss: 0.8718%\n",
      "Epoch [12/300], Step [29/225], Training Accuracy: 58.6207%, Training Loss: 0.8660%\n",
      "Epoch [12/300], Step [30/225], Training Accuracy: 58.8542%, Training Loss: 0.8642%\n",
      "Epoch [12/300], Step [31/225], Training Accuracy: 58.8710%, Training Loss: 0.8645%\n",
      "Epoch [12/300], Step [32/225], Training Accuracy: 58.9355%, Training Loss: 0.8648%\n",
      "Epoch [12/300], Step [33/225], Training Accuracy: 59.1856%, Training Loss: 0.8603%\n",
      "Epoch [12/300], Step [34/225], Training Accuracy: 58.8695%, Training Loss: 0.8640%\n",
      "Epoch [12/300], Step [35/225], Training Accuracy: 59.0179%, Training Loss: 0.8649%\n",
      "Epoch [12/300], Step [36/225], Training Accuracy: 58.8976%, Training Loss: 0.8662%\n",
      "Epoch [12/300], Step [37/225], Training Accuracy: 58.9527%, Training Loss: 0.8661%\n",
      "Epoch [12/300], Step [38/225], Training Accuracy: 58.9227%, Training Loss: 0.8659%\n",
      "Epoch [12/300], Step [39/225], Training Accuracy: 58.7340%, Training Loss: 0.8691%\n",
      "Epoch [12/300], Step [40/225], Training Accuracy: 58.7891%, Training Loss: 0.8714%\n",
      "Epoch [12/300], Step [41/225], Training Accuracy: 58.4604%, Training Loss: 0.8737%\n",
      "Epoch [12/300], Step [42/225], Training Accuracy: 58.4077%, Training Loss: 0.8721%\n",
      "Epoch [12/300], Step [43/225], Training Accuracy: 58.4302%, Training Loss: 0.8721%\n",
      "Epoch [12/300], Step [44/225], Training Accuracy: 58.4517%, Training Loss: 0.8716%\n",
      "Epoch [12/300], Step [45/225], Training Accuracy: 58.5417%, Training Loss: 0.8695%\n",
      "Epoch [12/300], Step [46/225], Training Accuracy: 58.8315%, Training Loss: 0.8649%\n",
      "Epoch [12/300], Step [47/225], Training Accuracy: 59.0093%, Training Loss: 0.8616%\n",
      "Epoch [12/300], Step [48/225], Training Accuracy: 58.9193%, Training Loss: 0.8631%\n",
      "Epoch [12/300], Step [49/225], Training Accuracy: 58.8329%, Training Loss: 0.8645%\n",
      "Epoch [12/300], Step [50/225], Training Accuracy: 58.8438%, Training Loss: 0.8642%\n",
      "Epoch [12/300], Step [51/225], Training Accuracy: 59.0686%, Training Loss: 0.8607%\n",
      "Epoch [12/300], Step [52/225], Training Accuracy: 59.1346%, Training Loss: 0.8588%\n",
      "Epoch [12/300], Step [53/225], Training Accuracy: 59.1097%, Training Loss: 0.8579%\n",
      "Epoch [12/300], Step [54/225], Training Accuracy: 59.0567%, Training Loss: 0.8606%\n",
      "Epoch [12/300], Step [55/225], Training Accuracy: 58.9205%, Training Loss: 0.8632%\n",
      "Epoch [12/300], Step [56/225], Training Accuracy: 58.9286%, Training Loss: 0.8635%\n",
      "Epoch [12/300], Step [57/225], Training Accuracy: 59.0735%, Training Loss: 0.8624%\n",
      "Epoch [12/300], Step [58/225], Training Accuracy: 58.9170%, Training Loss: 0.8646%\n",
      "Epoch [12/300], Step [59/225], Training Accuracy: 58.6600%, Training Loss: 0.8674%\n",
      "Epoch [12/300], Step [60/225], Training Accuracy: 58.7760%, Training Loss: 0.8673%\n",
      "Epoch [12/300], Step [61/225], Training Accuracy: 58.6322%, Training Loss: 0.8671%\n",
      "Epoch [12/300], Step [62/225], Training Accuracy: 58.6694%, Training Loss: 0.8669%\n",
      "Epoch [12/300], Step [63/225], Training Accuracy: 58.5565%, Training Loss: 0.8696%\n",
      "Epoch [12/300], Step [64/225], Training Accuracy: 58.4473%, Training Loss: 0.8717%\n",
      "Epoch [12/300], Step [65/225], Training Accuracy: 58.4135%, Training Loss: 0.8715%\n",
      "Epoch [12/300], Step [66/225], Training Accuracy: 58.4754%, Training Loss: 0.8704%\n",
      "Epoch [12/300], Step [67/225], Training Accuracy: 58.4888%, Training Loss: 0.8701%\n",
      "Epoch [12/300], Step [68/225], Training Accuracy: 58.5938%, Training Loss: 0.8699%\n",
      "Epoch [12/300], Step [69/225], Training Accuracy: 58.5145%, Training Loss: 0.8699%\n",
      "Epoch [12/300], Step [70/225], Training Accuracy: 58.3929%, Training Loss: 0.8704%\n",
      "Epoch [12/300], Step [71/225], Training Accuracy: 58.4727%, Training Loss: 0.8698%\n",
      "Epoch [12/300], Step [72/225], Training Accuracy: 58.4852%, Training Loss: 0.8699%\n",
      "Epoch [12/300], Step [73/225], Training Accuracy: 58.5188%, Training Loss: 0.8691%\n",
      "Epoch [12/300], Step [74/225], Training Accuracy: 58.5726%, Training Loss: 0.8668%\n",
      "Epoch [12/300], Step [75/225], Training Accuracy: 58.5000%, Training Loss: 0.8664%\n",
      "Epoch [12/300], Step [76/225], Training Accuracy: 58.4704%, Training Loss: 0.8658%\n",
      "Epoch [12/300], Step [77/225], Training Accuracy: 58.4619%, Training Loss: 0.8663%\n",
      "Epoch [12/300], Step [78/225], Training Accuracy: 58.4736%, Training Loss: 0.8668%\n",
      "Epoch [12/300], Step [79/225], Training Accuracy: 58.3861%, Training Loss: 0.8671%\n",
      "Epoch [12/300], Step [80/225], Training Accuracy: 58.2812%, Training Loss: 0.8673%\n",
      "Epoch [12/300], Step [81/225], Training Accuracy: 58.1983%, Training Loss: 0.8679%\n",
      "Epoch [12/300], Step [82/225], Training Accuracy: 58.1555%, Training Loss: 0.8674%\n",
      "Epoch [12/300], Step [83/225], Training Accuracy: 58.0761%, Training Loss: 0.8678%\n",
      "Epoch [12/300], Step [84/225], Training Accuracy: 58.1101%, Training Loss: 0.8665%\n",
      "Epoch [12/300], Step [85/225], Training Accuracy: 58.2721%, Training Loss: 0.8649%\n",
      "Epoch [12/300], Step [86/225], Training Accuracy: 58.4302%, Training Loss: 0.8632%\n",
      "Epoch [12/300], Step [87/225], Training Accuracy: 58.3693%, Training Loss: 0.8654%\n",
      "Epoch [12/300], Step [88/225], Training Accuracy: 58.3452%, Training Loss: 0.8671%\n",
      "Epoch [12/300], Step [89/225], Training Accuracy: 58.2690%, Training Loss: 0.8684%\n",
      "Epoch [12/300], Step [90/225], Training Accuracy: 58.3160%, Training Loss: 0.8686%\n",
      "Epoch [12/300], Step [91/225], Training Accuracy: 58.2589%, Training Loss: 0.8688%\n",
      "Epoch [12/300], Step [92/225], Training Accuracy: 58.0842%, Training Loss: 0.8710%\n",
      "Epoch [12/300], Step [93/225], Training Accuracy: 58.1149%, Training Loss: 0.8703%\n",
      "Epoch [12/300], Step [94/225], Training Accuracy: 58.2945%, Training Loss: 0.8681%\n",
      "Epoch [12/300], Step [95/225], Training Accuracy: 58.2072%, Training Loss: 0.8698%\n",
      "Epoch [12/300], Step [96/225], Training Accuracy: 58.2845%, Training Loss: 0.8692%\n",
      "Epoch [12/300], Step [97/225], Training Accuracy: 58.2313%, Training Loss: 0.8694%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/300], Step [98/225], Training Accuracy: 58.1792%, Training Loss: 0.8692%\n",
      "Epoch [12/300], Step [99/225], Training Accuracy: 58.2071%, Training Loss: 0.8690%\n",
      "Epoch [12/300], Step [100/225], Training Accuracy: 58.1406%, Training Loss: 0.8705%\n",
      "Epoch [12/300], Step [101/225], Training Accuracy: 58.0600%, Training Loss: 0.8704%\n",
      "Epoch [12/300], Step [102/225], Training Accuracy: 58.0576%, Training Loss: 0.8720%\n",
      "Epoch [12/300], Step [103/225], Training Accuracy: 58.0552%, Training Loss: 0.8726%\n",
      "Epoch [12/300], Step [104/225], Training Accuracy: 57.9928%, Training Loss: 0.8730%\n",
      "Epoch [12/300], Step [105/225], Training Accuracy: 58.0506%, Training Loss: 0.8726%\n",
      "Epoch [12/300], Step [106/225], Training Accuracy: 58.0483%, Training Loss: 0.8723%\n",
      "Epoch [12/300], Step [107/225], Training Accuracy: 57.9585%, Training Loss: 0.8735%\n",
      "Epoch [12/300], Step [108/225], Training Accuracy: 57.8559%, Training Loss: 0.8732%\n",
      "Epoch [12/300], Step [109/225], Training Accuracy: 57.8842%, Training Loss: 0.8731%\n",
      "Epoch [12/300], Step [110/225], Training Accuracy: 57.8835%, Training Loss: 0.8725%\n",
      "Epoch [12/300], Step [111/225], Training Accuracy: 57.9392%, Training Loss: 0.8723%\n",
      "Epoch [12/300], Step [112/225], Training Accuracy: 57.9381%, Training Loss: 0.8716%\n",
      "Epoch [12/300], Step [113/225], Training Accuracy: 57.9508%, Training Loss: 0.8714%\n",
      "Epoch [12/300], Step [114/225], Training Accuracy: 57.9496%, Training Loss: 0.8712%\n",
      "Epoch [12/300], Step [115/225], Training Accuracy: 57.9891%, Training Loss: 0.8715%\n",
      "Epoch [12/300], Step [116/225], Training Accuracy: 58.0280%, Training Loss: 0.8714%\n",
      "Epoch [12/300], Step [117/225], Training Accuracy: 57.8659%, Training Loss: 0.8728%\n",
      "Epoch [12/300], Step [118/225], Training Accuracy: 57.8919%, Training Loss: 0.8714%\n",
      "Epoch [12/300], Step [119/225], Training Accuracy: 57.9175%, Training Loss: 0.8714%\n",
      "Epoch [12/300], Step [120/225], Training Accuracy: 57.9557%, Training Loss: 0.8714%\n",
      "Epoch [12/300], Step [121/225], Training Accuracy: 57.9545%, Training Loss: 0.8713%\n",
      "Epoch [12/300], Step [122/225], Training Accuracy: 57.9662%, Training Loss: 0.8716%\n",
      "Epoch [12/300], Step [123/225], Training Accuracy: 58.0030%, Training Loss: 0.8710%\n",
      "Epoch [12/300], Step [124/225], Training Accuracy: 58.0267%, Training Loss: 0.8710%\n",
      "Epoch [12/300], Step [125/225], Training Accuracy: 58.0625%, Training Loss: 0.8719%\n",
      "Epoch [12/300], Step [126/225], Training Accuracy: 58.1349%, Training Loss: 0.8712%\n",
      "Epoch [12/300], Step [127/225], Training Accuracy: 58.1078%, Training Loss: 0.8715%\n",
      "Epoch [12/300], Step [128/225], Training Accuracy: 58.0200%, Training Loss: 0.8721%\n",
      "Epoch [12/300], Step [129/225], Training Accuracy: 58.0305%, Training Loss: 0.8724%\n",
      "Epoch [12/300], Step [130/225], Training Accuracy: 58.0649%, Training Loss: 0.8728%\n",
      "Epoch [12/300], Step [131/225], Training Accuracy: 58.0272%, Training Loss: 0.8738%\n",
      "Epoch [12/300], Step [132/225], Training Accuracy: 57.9782%, Training Loss: 0.8744%\n",
      "Epoch [12/300], Step [133/225], Training Accuracy: 58.0122%, Training Loss: 0.8750%\n",
      "Epoch [12/300], Step [134/225], Training Accuracy: 57.9174%, Training Loss: 0.8767%\n",
      "Epoch [12/300], Step [135/225], Training Accuracy: 57.9051%, Training Loss: 0.8766%\n",
      "Epoch [12/300], Step [136/225], Training Accuracy: 57.9504%, Training Loss: 0.8758%\n",
      "Epoch [12/300], Step [137/225], Training Accuracy: 57.9950%, Training Loss: 0.8749%\n",
      "Epoch [12/300], Step [138/225], Training Accuracy: 58.1182%, Training Loss: 0.8735%\n",
      "Epoch [12/300], Step [139/225], Training Accuracy: 58.0823%, Training Loss: 0.8744%\n",
      "Epoch [12/300], Step [140/225], Training Accuracy: 58.1138%, Training Loss: 0.8736%\n",
      "Epoch [12/300], Step [141/225], Training Accuracy: 58.1228%, Training Loss: 0.8729%\n",
      "Epoch [12/300], Step [142/225], Training Accuracy: 58.1206%, Training Loss: 0.8730%\n",
      "Epoch [12/300], Step [143/225], Training Accuracy: 58.0747%, Training Loss: 0.8741%\n",
      "Epoch [12/300], Step [144/225], Training Accuracy: 57.9753%, Training Loss: 0.8745%\n",
      "Epoch [12/300], Step [145/225], Training Accuracy: 57.9203%, Training Loss: 0.8746%\n",
      "Epoch [12/300], Step [146/225], Training Accuracy: 57.8767%, Training Loss: 0.8750%\n",
      "Epoch [12/300], Step [147/225], Training Accuracy: 57.8763%, Training Loss: 0.8758%\n",
      "Epoch [12/300], Step [148/225], Training Accuracy: 57.8864%, Training Loss: 0.8756%\n",
      "Epoch [12/300], Step [149/225], Training Accuracy: 57.8754%, Training Loss: 0.8761%\n",
      "Epoch [12/300], Step [150/225], Training Accuracy: 57.9167%, Training Loss: 0.8752%\n",
      "Epoch [12/300], Step [151/225], Training Accuracy: 57.9263%, Training Loss: 0.8747%\n",
      "Epoch [12/300], Step [152/225], Training Accuracy: 57.9564%, Training Loss: 0.8744%\n",
      "Epoch [12/300], Step [153/225], Training Accuracy: 57.9759%, Training Loss: 0.8736%\n",
      "Epoch [12/300], Step [154/225], Training Accuracy: 57.9748%, Training Loss: 0.8734%\n",
      "Epoch [12/300], Step [155/225], Training Accuracy: 57.8931%, Training Loss: 0.8739%\n",
      "Epoch [12/300], Step [156/225], Training Accuracy: 57.8626%, Training Loss: 0.8741%\n",
      "Epoch [12/300], Step [157/225], Training Accuracy: 57.8523%, Training Loss: 0.8737%\n",
      "Epoch [12/300], Step [158/225], Training Accuracy: 57.7729%, Training Loss: 0.8747%\n",
      "Epoch [12/300], Step [159/225], Training Accuracy: 57.7928%, Training Loss: 0.8743%\n",
      "Epoch [12/300], Step [160/225], Training Accuracy: 57.7539%, Training Loss: 0.8751%\n",
      "Epoch [12/300], Step [161/225], Training Accuracy: 57.7543%, Training Loss: 0.8751%\n",
      "Epoch [12/300], Step [162/225], Training Accuracy: 57.8029%, Training Loss: 0.8743%\n",
      "Epoch [12/300], Step [163/225], Training Accuracy: 57.7550%, Training Loss: 0.8743%\n",
      "Epoch [12/300], Step [164/225], Training Accuracy: 57.7649%, Training Loss: 0.8738%\n",
      "Epoch [12/300], Step [165/225], Training Accuracy: 57.7841%, Training Loss: 0.8736%\n",
      "Epoch [12/300], Step [166/225], Training Accuracy: 57.7937%, Training Loss: 0.8733%\n",
      "Epoch [12/300], Step [167/225], Training Accuracy: 57.8499%, Training Loss: 0.8727%\n",
      "Epoch [12/300], Step [168/225], Training Accuracy: 57.9055%, Training Loss: 0.8722%\n",
      "Epoch [12/300], Step [169/225], Training Accuracy: 57.9604%, Training Loss: 0.8716%\n",
      "Epoch [12/300], Step [170/225], Training Accuracy: 57.9504%, Training Loss: 0.8720%\n",
      "Epoch [12/300], Step [171/225], Training Accuracy: 57.9039%, Training Loss: 0.8721%\n",
      "Epoch [12/300], Step [172/225], Training Accuracy: 57.8761%, Training Loss: 0.8721%\n",
      "Epoch [12/300], Step [173/225], Training Accuracy: 57.8125%, Training Loss: 0.8722%\n",
      "Epoch [12/300], Step [174/225], Training Accuracy: 57.8933%, Training Loss: 0.8718%\n",
      "Epoch [12/300], Step [175/225], Training Accuracy: 57.9196%, Training Loss: 0.8714%\n",
      "Epoch [12/300], Step [176/225], Training Accuracy: 57.9190%, Training Loss: 0.8713%\n",
      "Epoch [12/300], Step [177/225], Training Accuracy: 57.9273%, Training Loss: 0.8710%\n",
      "Epoch [12/300], Step [178/225], Training Accuracy: 57.9266%, Training Loss: 0.8709%\n",
      "Epoch [12/300], Step [179/225], Training Accuracy: 57.9784%, Training Loss: 0.8705%\n",
      "Epoch [12/300], Step [180/225], Training Accuracy: 58.0382%, Training Loss: 0.8697%\n",
      "Epoch [12/300], Step [181/225], Training Accuracy: 58.0456%, Training Loss: 0.8708%\n",
      "Epoch [12/300], Step [182/225], Training Accuracy: 58.0786%, Training Loss: 0.8702%\n",
      "Epoch [12/300], Step [183/225], Training Accuracy: 58.0601%, Training Loss: 0.8702%\n",
      "Epoch [12/300], Step [184/225], Training Accuracy: 58.0588%, Training Loss: 0.8702%\n",
      "Epoch [12/300], Step [185/225], Training Accuracy: 58.0743%, Training Loss: 0.8707%\n",
      "Epoch [12/300], Step [186/225], Training Accuracy: 58.1233%, Training Loss: 0.8699%\n",
      "Epoch [12/300], Step [187/225], Training Accuracy: 58.1049%, Training Loss: 0.8696%\n",
      "Epoch [12/300], Step [188/225], Training Accuracy: 58.1533%, Training Loss: 0.8688%\n",
      "Epoch [12/300], Step [189/225], Training Accuracy: 58.2011%, Training Loss: 0.8675%\n",
      "Epoch [12/300], Step [190/225], Training Accuracy: 58.1990%, Training Loss: 0.8673%\n",
      "Epoch [12/300], Step [191/225], Training Accuracy: 58.2215%, Training Loss: 0.8672%\n",
      "Epoch [12/300], Step [192/225], Training Accuracy: 58.2845%, Training Loss: 0.8663%\n",
      "Epoch [12/300], Step [193/225], Training Accuracy: 58.2740%, Training Loss: 0.8667%\n",
      "Epoch [12/300], Step [194/225], Training Accuracy: 58.2394%, Training Loss: 0.8674%\n",
      "Epoch [12/300], Step [195/225], Training Accuracy: 58.2772%, Training Loss: 0.8665%\n",
      "Epoch [12/300], Step [196/225], Training Accuracy: 58.2749%, Training Loss: 0.8674%\n",
      "Epoch [12/300], Step [197/225], Training Accuracy: 58.2567%, Training Loss: 0.8678%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/300], Step [198/225], Training Accuracy: 58.2702%, Training Loss: 0.8673%\n",
      "Epoch [12/300], Step [199/225], Training Accuracy: 58.2836%, Training Loss: 0.8666%\n",
      "Epoch [12/300], Step [200/225], Training Accuracy: 58.2891%, Training Loss: 0.8667%\n",
      "Epoch [12/300], Step [201/225], Training Accuracy: 58.2867%, Training Loss: 0.8666%\n",
      "Epoch [12/300], Step [202/225], Training Accuracy: 58.2766%, Training Loss: 0.8667%\n",
      "Epoch [12/300], Step [203/225], Training Accuracy: 58.3359%, Training Loss: 0.8662%\n",
      "Epoch [12/300], Step [204/225], Training Accuracy: 58.3487%, Training Loss: 0.8670%\n",
      "Epoch [12/300], Step [205/225], Training Accuracy: 58.3765%, Training Loss: 0.8669%\n",
      "Epoch [12/300], Step [206/225], Training Accuracy: 58.3359%, Training Loss: 0.8673%\n",
      "Epoch [12/300], Step [207/225], Training Accuracy: 58.3484%, Training Loss: 0.8675%\n",
      "Epoch [12/300], Step [208/225], Training Accuracy: 58.3984%, Training Loss: 0.8668%\n",
      "Epoch [12/300], Step [209/225], Training Accuracy: 58.3882%, Training Loss: 0.8671%\n",
      "Epoch [12/300], Step [210/225], Training Accuracy: 58.3185%, Training Loss: 0.8679%\n",
      "Epoch [12/300], Step [211/225], Training Accuracy: 58.3531%, Training Loss: 0.8676%\n",
      "Epoch [12/300], Step [212/225], Training Accuracy: 58.3800%, Training Loss: 0.8675%\n",
      "Epoch [12/300], Step [213/225], Training Accuracy: 58.3553%, Training Loss: 0.8681%\n",
      "Epoch [12/300], Step [214/225], Training Accuracy: 58.3674%, Training Loss: 0.8681%\n",
      "Epoch [12/300], Step [215/225], Training Accuracy: 58.3140%, Training Loss: 0.8685%\n",
      "Epoch [12/300], Step [216/225], Training Accuracy: 58.2899%, Training Loss: 0.8684%\n",
      "Epoch [12/300], Step [217/225], Training Accuracy: 58.2877%, Training Loss: 0.8688%\n",
      "Epoch [12/300], Step [218/225], Training Accuracy: 58.2712%, Training Loss: 0.8693%\n",
      "Epoch [12/300], Step [219/225], Training Accuracy: 58.2691%, Training Loss: 0.8695%\n",
      "Epoch [12/300], Step [220/225], Training Accuracy: 58.2457%, Training Loss: 0.8699%\n",
      "Epoch [12/300], Step [221/225], Training Accuracy: 58.1943%, Training Loss: 0.8704%\n",
      "Epoch [12/300], Step [222/225], Training Accuracy: 58.2207%, Training Loss: 0.8707%\n",
      "Epoch [12/300], Step [223/225], Training Accuracy: 58.2119%, Training Loss: 0.8704%\n",
      "Epoch [12/300], Step [224/225], Training Accuracy: 58.1892%, Training Loss: 0.8700%\n",
      "Epoch [12/300], Step [225/225], Training Accuracy: 58.1643%, Training Loss: 0.8703%\n",
      "Epoch [13/300], Step [1/225], Training Accuracy: 67.1875%, Training Loss: 0.6642%\n",
      "Epoch [13/300], Step [2/225], Training Accuracy: 66.4062%, Training Loss: 0.7763%\n",
      "Epoch [13/300], Step [3/225], Training Accuracy: 64.0625%, Training Loss: 0.8545%\n",
      "Epoch [13/300], Step [4/225], Training Accuracy: 64.0625%, Training Loss: 0.8753%\n",
      "Epoch [13/300], Step [5/225], Training Accuracy: 64.3750%, Training Loss: 0.8515%\n",
      "Epoch [13/300], Step [6/225], Training Accuracy: 63.8021%, Training Loss: 0.8667%\n",
      "Epoch [13/300], Step [7/225], Training Accuracy: 63.1696%, Training Loss: 0.8677%\n",
      "Epoch [13/300], Step [8/225], Training Accuracy: 61.5234%, Training Loss: 0.8727%\n",
      "Epoch [13/300], Step [9/225], Training Accuracy: 60.4167%, Training Loss: 0.8818%\n",
      "Epoch [13/300], Step [10/225], Training Accuracy: 58.7500%, Training Loss: 0.9044%\n",
      "Epoch [13/300], Step [11/225], Training Accuracy: 58.6648%, Training Loss: 0.9057%\n",
      "Epoch [13/300], Step [12/225], Training Accuracy: 59.3750%, Training Loss: 0.8987%\n",
      "Epoch [13/300], Step [13/225], Training Accuracy: 60.4567%, Training Loss: 0.8811%\n",
      "Epoch [13/300], Step [14/225], Training Accuracy: 60.6027%, Training Loss: 0.8741%\n",
      "Epoch [13/300], Step [15/225], Training Accuracy: 59.8958%, Training Loss: 0.8849%\n",
      "Epoch [13/300], Step [16/225], Training Accuracy: 59.9609%, Training Loss: 0.8823%\n",
      "Epoch [13/300], Step [17/225], Training Accuracy: 60.5699%, Training Loss: 0.8736%\n",
      "Epoch [13/300], Step [18/225], Training Accuracy: 60.8507%, Training Loss: 0.8679%\n",
      "Epoch [13/300], Step [19/225], Training Accuracy: 61.0197%, Training Loss: 0.8655%\n",
      "Epoch [13/300], Step [20/225], Training Accuracy: 61.2500%, Training Loss: 0.8614%\n",
      "Epoch [13/300], Step [21/225], Training Accuracy: 60.7887%, Training Loss: 0.8573%\n",
      "Epoch [13/300], Step [22/225], Training Accuracy: 60.4403%, Training Loss: 0.8598%\n",
      "Epoch [13/300], Step [23/225], Training Accuracy: 60.3261%, Training Loss: 0.8577%\n",
      "Epoch [13/300], Step [24/225], Training Accuracy: 60.0911%, Training Loss: 0.8611%\n",
      "Epoch [13/300], Step [25/225], Training Accuracy: 60.1250%, Training Loss: 0.8596%\n",
      "Epoch [13/300], Step [26/225], Training Accuracy: 59.6755%, Training Loss: 0.8572%\n",
      "Epoch [13/300], Step [27/225], Training Accuracy: 59.8380%, Training Loss: 0.8550%\n",
      "Epoch [13/300], Step [28/225], Training Accuracy: 60.1004%, Training Loss: 0.8474%\n",
      "Epoch [13/300], Step [29/225], Training Accuracy: 60.3987%, Training Loss: 0.8411%\n",
      "Epoch [13/300], Step [30/225], Training Accuracy: 60.5729%, Training Loss: 0.8392%\n",
      "Epoch [13/300], Step [31/225], Training Accuracy: 60.5343%, Training Loss: 0.8414%\n",
      "Epoch [13/300], Step [32/225], Training Accuracy: 60.6934%, Training Loss: 0.8410%\n",
      "Epoch [13/300], Step [33/225], Training Accuracy: 60.8902%, Training Loss: 0.8381%\n",
      "Epoch [13/300], Step [34/225], Training Accuracy: 60.5699%, Training Loss: 0.8437%\n",
      "Epoch [13/300], Step [35/225], Training Accuracy: 60.7589%, Training Loss: 0.8419%\n",
      "Epoch [13/300], Step [36/225], Training Accuracy: 60.5903%, Training Loss: 0.8440%\n",
      "Epoch [13/300], Step [37/225], Training Accuracy: 60.5574%, Training Loss: 0.8428%\n",
      "Epoch [13/300], Step [38/225], Training Accuracy: 60.6908%, Training Loss: 0.8398%\n",
      "Epoch [13/300], Step [39/225], Training Accuracy: 60.8974%, Training Loss: 0.8402%\n",
      "Epoch [13/300], Step [40/225], Training Accuracy: 60.9375%, Training Loss: 0.8400%\n",
      "Epoch [13/300], Step [41/225], Training Accuracy: 60.6326%, Training Loss: 0.8438%\n",
      "Epoch [13/300], Step [42/225], Training Accuracy: 60.3051%, Training Loss: 0.8468%\n",
      "Epoch [13/300], Step [43/225], Training Accuracy: 60.4288%, Training Loss: 0.8469%\n",
      "Epoch [13/300], Step [44/225], Training Accuracy: 60.5469%, Training Loss: 0.8450%\n",
      "Epoch [13/300], Step [45/225], Training Accuracy: 60.4861%, Training Loss: 0.8443%\n",
      "Epoch [13/300], Step [46/225], Training Accuracy: 60.6318%, Training Loss: 0.8402%\n",
      "Epoch [13/300], Step [47/225], Training Accuracy: 60.7380%, Training Loss: 0.8379%\n",
      "Epoch [13/300], Step [48/225], Training Accuracy: 60.5794%, Training Loss: 0.8403%\n",
      "Epoch [13/300], Step [49/225], Training Accuracy: 60.5230%, Training Loss: 0.8403%\n",
      "Epoch [13/300], Step [50/225], Training Accuracy: 60.5938%, Training Loss: 0.8394%\n",
      "Epoch [13/300], Step [51/225], Training Accuracy: 60.7230%, Training Loss: 0.8363%\n",
      "Epoch [13/300], Step [52/225], Training Accuracy: 60.8474%, Training Loss: 0.8341%\n",
      "Epoch [13/300], Step [53/225], Training Accuracy: 60.7017%, Training Loss: 0.8346%\n",
      "Epoch [13/300], Step [54/225], Training Accuracy: 60.5035%, Training Loss: 0.8358%\n",
      "Epoch [13/300], Step [55/225], Training Accuracy: 60.3977%, Training Loss: 0.8380%\n",
      "Epoch [13/300], Step [56/225], Training Accuracy: 60.2958%, Training Loss: 0.8393%\n",
      "Epoch [13/300], Step [57/225], Training Accuracy: 60.4167%, Training Loss: 0.8362%\n",
      "Epoch [13/300], Step [58/225], Training Accuracy: 60.1562%, Training Loss: 0.8397%\n",
      "Epoch [13/300], Step [59/225], Training Accuracy: 60.0900%, Training Loss: 0.8411%\n",
      "Epoch [13/300], Step [60/225], Training Accuracy: 60.1823%, Training Loss: 0.8397%\n",
      "Epoch [13/300], Step [61/225], Training Accuracy: 60.1691%, Training Loss: 0.8406%\n",
      "Epoch [13/300], Step [62/225], Training Accuracy: 60.2823%, Training Loss: 0.8395%\n",
      "Epoch [13/300], Step [63/225], Training Accuracy: 60.2183%, Training Loss: 0.8400%\n",
      "Epoch [13/300], Step [64/225], Training Accuracy: 60.3027%, Training Loss: 0.8390%\n",
      "Epoch [13/300], Step [65/225], Training Accuracy: 60.3125%, Training Loss: 0.8385%\n",
      "Epoch [13/300], Step [66/225], Training Accuracy: 60.4403%, Training Loss: 0.8366%\n",
      "Epoch [13/300], Step [67/225], Training Accuracy: 60.4011%, Training Loss: 0.8360%\n",
      "Epoch [13/300], Step [68/225], Training Accuracy: 60.3631%, Training Loss: 0.8361%\n",
      "Epoch [13/300], Step [69/225], Training Accuracy: 60.3034%, Training Loss: 0.8373%\n",
      "Epoch [13/300], Step [70/225], Training Accuracy: 60.2679%, Training Loss: 0.8374%\n",
      "Epoch [13/300], Step [71/225], Training Accuracy: 60.3873%, Training Loss: 0.8366%\n",
      "Epoch [13/300], Step [72/225], Training Accuracy: 60.3950%, Training Loss: 0.8371%\n",
      "Epoch [13/300], Step [73/225], Training Accuracy: 60.3168%, Training Loss: 0.8371%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/300], Step [74/225], Training Accuracy: 60.2829%, Training Loss: 0.8360%\n",
      "Epoch [13/300], Step [75/225], Training Accuracy: 60.2083%, Training Loss: 0.8362%\n",
      "Epoch [13/300], Step [76/225], Training Accuracy: 60.0535%, Training Loss: 0.8379%\n",
      "Epoch [13/300], Step [77/225], Training Accuracy: 60.0244%, Training Loss: 0.8393%\n",
      "Epoch [13/300], Step [78/225], Training Accuracy: 59.9960%, Training Loss: 0.8397%\n",
      "Epoch [13/300], Step [79/225], Training Accuracy: 59.9684%, Training Loss: 0.8399%\n",
      "Epoch [13/300], Step [80/225], Training Accuracy: 59.8047%, Training Loss: 0.8405%\n",
      "Epoch [13/300], Step [81/225], Training Accuracy: 59.7608%, Training Loss: 0.8417%\n",
      "Epoch [13/300], Step [82/225], Training Accuracy: 59.7180%, Training Loss: 0.8416%\n",
      "Epoch [13/300], Step [83/225], Training Accuracy: 59.7515%, Training Loss: 0.8416%\n",
      "Epoch [13/300], Step [84/225], Training Accuracy: 59.8214%, Training Loss: 0.8411%\n",
      "Epoch [13/300], Step [85/225], Training Accuracy: 59.9265%, Training Loss: 0.8398%\n",
      "Epoch [13/300], Step [86/225], Training Accuracy: 60.0472%, Training Loss: 0.8384%\n",
      "Epoch [13/300], Step [87/225], Training Accuracy: 59.8779%, Training Loss: 0.8403%\n",
      "Epoch [13/300], Step [88/225], Training Accuracy: 59.8366%, Training Loss: 0.8422%\n",
      "Epoch [13/300], Step [89/225], Training Accuracy: 59.7086%, Training Loss: 0.8444%\n",
      "Epoch [13/300], Step [90/225], Training Accuracy: 59.7396%, Training Loss: 0.8454%\n",
      "Epoch [13/300], Step [91/225], Training Accuracy: 59.7184%, Training Loss: 0.8452%\n",
      "Epoch [13/300], Step [92/225], Training Accuracy: 59.5958%, Training Loss: 0.8470%\n",
      "Epoch [13/300], Step [93/225], Training Accuracy: 59.5766%, Training Loss: 0.8473%\n",
      "Epoch [13/300], Step [94/225], Training Accuracy: 59.6908%, Training Loss: 0.8456%\n",
      "Epoch [13/300], Step [95/225], Training Accuracy: 59.6875%, Training Loss: 0.8453%\n",
      "Epoch [13/300], Step [96/225], Training Accuracy: 59.8307%, Training Loss: 0.8439%\n",
      "Epoch [13/300], Step [97/225], Training Accuracy: 59.7938%, Training Loss: 0.8452%\n",
      "Epoch [13/300], Step [98/225], Training Accuracy: 59.8533%, Training Loss: 0.8447%\n",
      "Epoch [13/300], Step [99/225], Training Accuracy: 59.8801%, Training Loss: 0.8449%\n",
      "Epoch [13/300], Step [100/225], Training Accuracy: 59.8594%, Training Loss: 0.8451%\n",
      "Epoch [13/300], Step [101/225], Training Accuracy: 59.7927%, Training Loss: 0.8444%\n",
      "Epoch [13/300], Step [102/225], Training Accuracy: 59.7120%, Training Loss: 0.8465%\n",
      "Epoch [13/300], Step [103/225], Training Accuracy: 59.7391%, Training Loss: 0.8466%\n",
      "Epoch [13/300], Step [104/225], Training Accuracy: 59.7506%, Training Loss: 0.8465%\n",
      "Epoch [13/300], Step [105/225], Training Accuracy: 59.8214%, Training Loss: 0.8456%\n",
      "Epoch [13/300], Step [106/225], Training Accuracy: 59.8172%, Training Loss: 0.8451%\n",
      "Epoch [13/300], Step [107/225], Training Accuracy: 59.7401%, Training Loss: 0.8463%\n",
      "Epoch [13/300], Step [108/225], Training Accuracy: 59.7078%, Training Loss: 0.8460%\n",
      "Epoch [13/300], Step [109/225], Training Accuracy: 59.6474%, Training Loss: 0.8462%\n",
      "Epoch [13/300], Step [110/225], Training Accuracy: 59.6307%, Training Loss: 0.8457%\n",
      "Epoch [13/300], Step [111/225], Training Accuracy: 59.6002%, Training Loss: 0.8458%\n",
      "Epoch [13/300], Step [112/225], Training Accuracy: 59.6122%, Training Loss: 0.8460%\n",
      "Epoch [13/300], Step [113/225], Training Accuracy: 59.6377%, Training Loss: 0.8457%\n",
      "Epoch [13/300], Step [114/225], Training Accuracy: 59.6491%, Training Loss: 0.8465%\n",
      "Epoch [13/300], Step [115/225], Training Accuracy: 59.7011%, Training Loss: 0.8450%\n",
      "Epoch [13/300], Step [116/225], Training Accuracy: 59.6983%, Training Loss: 0.8451%\n",
      "Epoch [13/300], Step [117/225], Training Accuracy: 59.5753%, Training Loss: 0.8462%\n",
      "Epoch [13/300], Step [118/225], Training Accuracy: 59.6001%, Training Loss: 0.8455%\n",
      "Epoch [13/300], Step [119/225], Training Accuracy: 59.6113%, Training Loss: 0.8453%\n",
      "Epoch [13/300], Step [120/225], Training Accuracy: 59.5833%, Training Loss: 0.8454%\n",
      "Epoch [13/300], Step [121/225], Training Accuracy: 59.5945%, Training Loss: 0.8449%\n",
      "Epoch [13/300], Step [122/225], Training Accuracy: 59.5799%, Training Loss: 0.8451%\n",
      "Epoch [13/300], Step [123/225], Training Accuracy: 59.6037%, Training Loss: 0.8447%\n",
      "Epoch [13/300], Step [124/225], Training Accuracy: 59.6270%, Training Loss: 0.8445%\n",
      "Epoch [13/300], Step [125/225], Training Accuracy: 59.6375%, Training Loss: 0.8455%\n",
      "Epoch [13/300], Step [126/225], Training Accuracy: 59.6478%, Training Loss: 0.8457%\n",
      "Epoch [13/300], Step [127/225], Training Accuracy: 59.6703%, Training Loss: 0.8460%\n",
      "Epoch [13/300], Step [128/225], Training Accuracy: 59.6069%, Training Loss: 0.8459%\n",
      "Epoch [13/300], Step [129/225], Training Accuracy: 59.6172%, Training Loss: 0.8456%\n",
      "Epoch [13/300], Step [130/225], Training Accuracy: 59.6154%, Training Loss: 0.8466%\n",
      "Epoch [13/300], Step [131/225], Training Accuracy: 59.6374%, Training Loss: 0.8472%\n",
      "Epoch [13/300], Step [132/225], Training Accuracy: 59.5644%, Training Loss: 0.8482%\n",
      "Epoch [13/300], Step [133/225], Training Accuracy: 59.5982%, Training Loss: 0.8477%\n",
      "Epoch [13/300], Step [134/225], Training Accuracy: 59.4799%, Training Loss: 0.8490%\n",
      "Epoch [13/300], Step [135/225], Training Accuracy: 59.4444%, Training Loss: 0.8488%\n",
      "Epoch [13/300], Step [136/225], Training Accuracy: 59.5014%, Training Loss: 0.8483%\n",
      "Epoch [13/300], Step [137/225], Training Accuracy: 59.6031%, Training Loss: 0.8474%\n",
      "Epoch [13/300], Step [138/225], Training Accuracy: 59.7034%, Training Loss: 0.8462%\n",
      "Epoch [13/300], Step [139/225], Training Accuracy: 59.6673%, Training Loss: 0.8465%\n",
      "Epoch [13/300], Step [140/225], Training Accuracy: 59.7768%, Training Loss: 0.8455%\n",
      "Epoch [13/300], Step [141/225], Training Accuracy: 59.7629%, Training Loss: 0.8449%\n",
      "Epoch [13/300], Step [142/225], Training Accuracy: 59.7601%, Training Loss: 0.8440%\n",
      "Epoch [13/300], Step [143/225], Training Accuracy: 59.7902%, Training Loss: 0.8444%\n",
      "Epoch [13/300], Step [144/225], Training Accuracy: 59.7548%, Training Loss: 0.8445%\n",
      "Epoch [13/300], Step [145/225], Training Accuracy: 59.7306%, Training Loss: 0.8441%\n",
      "Epoch [13/300], Step [146/225], Training Accuracy: 59.7068%, Training Loss: 0.8445%\n",
      "Epoch [13/300], Step [147/225], Training Accuracy: 59.7151%, Training Loss: 0.8448%\n",
      "Epoch [13/300], Step [148/225], Training Accuracy: 59.7234%, Training Loss: 0.8442%\n",
      "Epoch [13/300], Step [149/225], Training Accuracy: 59.7211%, Training Loss: 0.8443%\n",
      "Epoch [13/300], Step [150/225], Training Accuracy: 59.7188%, Training Loss: 0.8438%\n",
      "Epoch [13/300], Step [151/225], Training Accuracy: 59.6854%, Training Loss: 0.8437%\n",
      "Epoch [13/300], Step [152/225], Training Accuracy: 59.6320%, Training Loss: 0.8437%\n",
      "Epoch [13/300], Step [153/225], Training Accuracy: 59.6303%, Training Loss: 0.8433%\n",
      "Epoch [13/300], Step [154/225], Training Accuracy: 59.5881%, Training Loss: 0.8438%\n",
      "Epoch [13/300], Step [155/225], Training Accuracy: 59.5363%, Training Loss: 0.8440%\n",
      "Epoch [13/300], Step [156/225], Training Accuracy: 59.5453%, Training Loss: 0.8443%\n",
      "Epoch [13/300], Step [157/225], Training Accuracy: 59.6238%, Training Loss: 0.8433%\n",
      "Epoch [13/300], Step [158/225], Training Accuracy: 59.5728%, Training Loss: 0.8444%\n",
      "Epoch [13/300], Step [159/225], Training Accuracy: 59.5814%, Training Loss: 0.8442%\n",
      "Epoch [13/300], Step [160/225], Training Accuracy: 59.5801%, Training Loss: 0.8442%\n",
      "Epoch [13/300], Step [161/225], Training Accuracy: 59.5885%, Training Loss: 0.8444%\n",
      "Epoch [13/300], Step [162/225], Training Accuracy: 59.6451%, Training Loss: 0.8442%\n",
      "Epoch [13/300], Step [163/225], Training Accuracy: 59.6817%, Training Loss: 0.8437%\n",
      "Epoch [13/300], Step [164/225], Training Accuracy: 59.7085%, Training Loss: 0.8431%\n",
      "Epoch [13/300], Step [165/225], Training Accuracy: 59.7064%, Training Loss: 0.8435%\n",
      "Epoch [13/300], Step [166/225], Training Accuracy: 59.7233%, Training Loss: 0.8434%\n",
      "Epoch [13/300], Step [167/225], Training Accuracy: 59.7680%, Training Loss: 0.8428%\n",
      "Epoch [13/300], Step [168/225], Training Accuracy: 59.7563%, Training Loss: 0.8433%\n",
      "Epoch [13/300], Step [169/225], Training Accuracy: 59.8188%, Training Loss: 0.8423%\n",
      "Epoch [13/300], Step [170/225], Training Accuracy: 59.8346%, Training Loss: 0.8425%\n",
      "Epoch [13/300], Step [171/225], Training Accuracy: 59.8410%, Training Loss: 0.8424%\n",
      "Epoch [13/300], Step [172/225], Training Accuracy: 59.8292%, Training Loss: 0.8430%\n",
      "Epoch [13/300], Step [173/225], Training Accuracy: 59.7453%, Training Loss: 0.8436%\n",
      "Epoch [13/300], Step [174/225], Training Accuracy: 59.7611%, Training Loss: 0.8433%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/300], Step [175/225], Training Accuracy: 59.7768%, Training Loss: 0.8431%\n",
      "Epoch [13/300], Step [176/225], Training Accuracy: 59.8011%, Training Loss: 0.8425%\n",
      "Epoch [13/300], Step [177/225], Training Accuracy: 59.8694%, Training Loss: 0.8418%\n",
      "Epoch [13/300], Step [178/225], Training Accuracy: 59.8315%, Training Loss: 0.8422%\n",
      "Epoch [13/300], Step [179/225], Training Accuracy: 59.8638%, Training Loss: 0.8412%\n",
      "Epoch [13/300], Step [180/225], Training Accuracy: 59.9306%, Training Loss: 0.8406%\n",
      "Epoch [13/300], Step [181/225], Training Accuracy: 59.9275%, Training Loss: 0.8409%\n",
      "Epoch [13/300], Step [182/225], Training Accuracy: 59.9330%, Training Loss: 0.8403%\n",
      "Epoch [13/300], Step [183/225], Training Accuracy: 59.8702%, Training Loss: 0.8419%\n",
      "Epoch [13/300], Step [184/225], Training Accuracy: 59.9100%, Training Loss: 0.8413%\n",
      "Epoch [13/300], Step [185/225], Training Accuracy: 59.9324%, Training Loss: 0.8417%\n",
      "Epoch [13/300], Step [186/225], Training Accuracy: 59.9378%, Training Loss: 0.8410%\n",
      "Epoch [13/300], Step [187/225], Training Accuracy: 59.9265%, Training Loss: 0.8406%\n",
      "Epoch [13/300], Step [188/225], Training Accuracy: 59.9651%, Training Loss: 0.8401%\n",
      "Epoch [13/300], Step [189/225], Training Accuracy: 60.0033%, Training Loss: 0.8393%\n",
      "Epoch [13/300], Step [190/225], Training Accuracy: 60.0247%, Training Loss: 0.8387%\n",
      "Epoch [13/300], Step [191/225], Training Accuracy: 60.0295%, Training Loss: 0.8390%\n",
      "Epoch [13/300], Step [192/225], Training Accuracy: 60.1156%, Training Loss: 0.8379%\n",
      "Epoch [13/300], Step [193/225], Training Accuracy: 60.0470%, Training Loss: 0.8382%\n",
      "Epoch [13/300], Step [194/225], Training Accuracy: 60.0354%, Training Loss: 0.8384%\n",
      "Epoch [13/300], Step [195/225], Training Accuracy: 60.0721%, Training Loss: 0.8377%\n",
      "Epoch [13/300], Step [196/225], Training Accuracy: 60.0925%, Training Loss: 0.8381%\n",
      "Epoch [13/300], Step [197/225], Training Accuracy: 60.0809%, Training Loss: 0.8384%\n",
      "Epoch [13/300], Step [198/225], Training Accuracy: 60.1405%, Training Loss: 0.8375%\n",
      "Epoch [13/300], Step [199/225], Training Accuracy: 60.1916%, Training Loss: 0.8373%\n",
      "Epoch [13/300], Step [200/225], Training Accuracy: 60.1719%, Training Loss: 0.8372%\n",
      "Epoch [13/300], Step [201/225], Training Accuracy: 60.2068%, Training Loss: 0.8367%\n",
      "Epoch [13/300], Step [202/225], Training Accuracy: 60.2568%, Training Loss: 0.8362%\n",
      "Epoch [13/300], Step [203/225], Training Accuracy: 60.3063%, Training Loss: 0.8355%\n",
      "Epoch [13/300], Step [204/225], Training Accuracy: 60.2788%, Training Loss: 0.8360%\n",
      "Epoch [13/300], Step [205/225], Training Accuracy: 60.3125%, Training Loss: 0.8354%\n",
      "Epoch [13/300], Step [206/225], Training Accuracy: 60.2928%, Training Loss: 0.8357%\n",
      "Epoch [13/300], Step [207/225], Training Accuracy: 60.3412%, Training Loss: 0.8353%\n",
      "Epoch [13/300], Step [208/225], Training Accuracy: 60.4041%, Training Loss: 0.8344%\n",
      "Epoch [13/300], Step [209/225], Training Accuracy: 60.3992%, Training Loss: 0.8345%\n",
      "Epoch [13/300], Step [210/225], Training Accuracy: 60.3795%, Training Loss: 0.8350%\n",
      "Epoch [13/300], Step [211/225], Training Accuracy: 60.3969%, Training Loss: 0.8352%\n",
      "Epoch [13/300], Step [212/225], Training Accuracy: 60.4142%, Training Loss: 0.8354%\n",
      "Epoch [13/300], Step [213/225], Training Accuracy: 60.3800%, Training Loss: 0.8360%\n",
      "Epoch [13/300], Step [214/225], Training Accuracy: 60.4191%, Training Loss: 0.8357%\n",
      "Epoch [13/300], Step [215/225], Training Accuracy: 60.4142%, Training Loss: 0.8358%\n",
      "Epoch [13/300], Step [216/225], Training Accuracy: 60.4167%, Training Loss: 0.8357%\n",
      "Epoch [13/300], Step [217/225], Training Accuracy: 60.3759%, Training Loss: 0.8364%\n",
      "Epoch [13/300], Step [218/225], Training Accuracy: 60.3211%, Training Loss: 0.8375%\n",
      "Epoch [13/300], Step [219/225], Training Accuracy: 60.3096%, Training Loss: 0.8376%\n",
      "Epoch [13/300], Step [220/225], Training Accuracy: 60.2841%, Training Loss: 0.8381%\n",
      "Epoch [13/300], Step [221/225], Training Accuracy: 60.2658%, Training Loss: 0.8383%\n",
      "Epoch [13/300], Step [222/225], Training Accuracy: 60.2829%, Training Loss: 0.8385%\n",
      "Epoch [13/300], Step [223/225], Training Accuracy: 60.2719%, Training Loss: 0.8388%\n",
      "Epoch [13/300], Step [224/225], Training Accuracy: 60.2818%, Training Loss: 0.8384%\n",
      "Epoch [13/300], Step [225/225], Training Accuracy: 60.2835%, Training Loss: 0.8386%\n",
      "Epoch [14/300], Step [1/225], Training Accuracy: 73.4375%, Training Loss: 0.7130%\n",
      "Epoch [14/300], Step [2/225], Training Accuracy: 67.9688%, Training Loss: 0.7583%\n",
      "Epoch [14/300], Step [3/225], Training Accuracy: 63.0208%, Training Loss: 0.8265%\n",
      "Epoch [14/300], Step [4/225], Training Accuracy: 59.7656%, Training Loss: 0.8471%\n",
      "Epoch [14/300], Step [5/225], Training Accuracy: 61.5625%, Training Loss: 0.8293%\n",
      "Epoch [14/300], Step [6/225], Training Accuracy: 63.0208%, Training Loss: 0.8350%\n",
      "Epoch [14/300], Step [7/225], Training Accuracy: 62.0536%, Training Loss: 0.8407%\n",
      "Epoch [14/300], Step [8/225], Training Accuracy: 61.1328%, Training Loss: 0.8470%\n",
      "Epoch [14/300], Step [9/225], Training Accuracy: 60.2431%, Training Loss: 0.8656%\n",
      "Epoch [14/300], Step [10/225], Training Accuracy: 59.8438%, Training Loss: 0.8673%\n",
      "Epoch [14/300], Step [11/225], Training Accuracy: 59.9432%, Training Loss: 0.8706%\n",
      "Epoch [14/300], Step [12/225], Training Accuracy: 60.4167%, Training Loss: 0.8705%\n",
      "Epoch [14/300], Step [13/225], Training Accuracy: 60.9375%, Training Loss: 0.8539%\n",
      "Epoch [14/300], Step [14/225], Training Accuracy: 61.1607%, Training Loss: 0.8480%\n",
      "Epoch [14/300], Step [15/225], Training Accuracy: 61.1458%, Training Loss: 0.8601%\n",
      "Epoch [14/300], Step [16/225], Training Accuracy: 61.0352%, Training Loss: 0.8627%\n",
      "Epoch [14/300], Step [17/225], Training Accuracy: 61.1213%, Training Loss: 0.8563%\n",
      "Epoch [14/300], Step [18/225], Training Accuracy: 61.1979%, Training Loss: 0.8531%\n",
      "Epoch [14/300], Step [19/225], Training Accuracy: 61.4309%, Training Loss: 0.8487%\n",
      "Epoch [14/300], Step [20/225], Training Accuracy: 62.1094%, Training Loss: 0.8391%\n",
      "Epoch [14/300], Step [21/225], Training Accuracy: 62.0536%, Training Loss: 0.8325%\n",
      "Epoch [14/300], Step [22/225], Training Accuracy: 61.8608%, Training Loss: 0.8317%\n",
      "Epoch [14/300], Step [23/225], Training Accuracy: 61.6168%, Training Loss: 0.8359%\n",
      "Epoch [14/300], Step [24/225], Training Accuracy: 61.5885%, Training Loss: 0.8399%\n",
      "Epoch [14/300], Step [25/225], Training Accuracy: 61.6250%, Training Loss: 0.8382%\n",
      "Epoch [14/300], Step [26/225], Training Accuracy: 61.7788%, Training Loss: 0.8350%\n",
      "Epoch [14/300], Step [27/225], Training Accuracy: 61.5741%, Training Loss: 0.8374%\n",
      "Epoch [14/300], Step [28/225], Training Accuracy: 61.7746%, Training Loss: 0.8300%\n",
      "Epoch [14/300], Step [29/225], Training Accuracy: 61.8534%, Training Loss: 0.8254%\n",
      "Epoch [14/300], Step [30/225], Training Accuracy: 62.0312%, Training Loss: 0.8238%\n",
      "Epoch [14/300], Step [31/225], Training Accuracy: 61.7944%, Training Loss: 0.8247%\n",
      "Epoch [14/300], Step [32/225], Training Accuracy: 61.9629%, Training Loss: 0.8225%\n",
      "Epoch [14/300], Step [33/225], Training Accuracy: 62.1686%, Training Loss: 0.8180%\n",
      "Epoch [14/300], Step [34/225], Training Accuracy: 61.7647%, Training Loss: 0.8229%\n",
      "Epoch [14/300], Step [35/225], Training Accuracy: 61.7411%, Training Loss: 0.8236%\n",
      "Epoch [14/300], Step [36/225], Training Accuracy: 61.5885%, Training Loss: 0.8277%\n",
      "Epoch [14/300], Step [37/225], Training Accuracy: 61.5709%, Training Loss: 0.8266%\n",
      "Epoch [14/300], Step [38/225], Training Accuracy: 61.6365%, Training Loss: 0.8251%\n",
      "Epoch [14/300], Step [39/225], Training Accuracy: 61.4583%, Training Loss: 0.8270%\n",
      "Epoch [14/300], Step [40/225], Training Accuracy: 61.4062%, Training Loss: 0.8270%\n",
      "Epoch [14/300], Step [41/225], Training Accuracy: 61.1662%, Training Loss: 0.8284%\n",
      "Epoch [14/300], Step [42/225], Training Accuracy: 60.8631%, Training Loss: 0.8290%\n",
      "Epoch [14/300], Step [43/225], Training Accuracy: 61.0465%, Training Loss: 0.8279%\n",
      "Epoch [14/300], Step [44/225], Training Accuracy: 61.1861%, Training Loss: 0.8250%\n",
      "Epoch [14/300], Step [45/225], Training Accuracy: 61.1806%, Training Loss: 0.8232%\n",
      "Epoch [14/300], Step [46/225], Training Accuracy: 61.4810%, Training Loss: 0.8190%\n",
      "Epoch [14/300], Step [47/225], Training Accuracy: 61.6689%, Training Loss: 0.8173%\n",
      "Epoch [14/300], Step [48/225], Training Accuracy: 61.4583%, Training Loss: 0.8197%\n",
      "Epoch [14/300], Step [49/225], Training Accuracy: 61.4158%, Training Loss: 0.8194%\n",
      "Epoch [14/300], Step [50/225], Training Accuracy: 61.3750%, Training Loss: 0.8193%\n",
      "Epoch [14/300], Step [51/225], Training Accuracy: 61.4583%, Training Loss: 0.8154%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/300], Step [52/225], Training Accuracy: 61.6286%, Training Loss: 0.8120%\n",
      "Epoch [14/300], Step [53/225], Training Accuracy: 61.5271%, Training Loss: 0.8122%\n",
      "Epoch [14/300], Step [54/225], Training Accuracy: 61.3137%, Training Loss: 0.8142%\n",
      "Epoch [14/300], Step [55/225], Training Accuracy: 61.3068%, Training Loss: 0.8151%\n",
      "Epoch [14/300], Step [56/225], Training Accuracy: 61.2444%, Training Loss: 0.8147%\n",
      "Epoch [14/300], Step [57/225], Training Accuracy: 61.2664%, Training Loss: 0.8132%\n",
      "Epoch [14/300], Step [58/225], Training Accuracy: 61.2608%, Training Loss: 0.8141%\n",
      "Epoch [14/300], Step [59/225], Training Accuracy: 61.2818%, Training Loss: 0.8132%\n",
      "Epoch [14/300], Step [60/225], Training Accuracy: 61.4323%, Training Loss: 0.8124%\n",
      "Epoch [14/300], Step [61/225], Training Accuracy: 61.3473%, Training Loss: 0.8134%\n",
      "Epoch [14/300], Step [62/225], Training Accuracy: 61.4415%, Training Loss: 0.8122%\n",
      "Epoch [14/300], Step [63/225], Training Accuracy: 61.2847%, Training Loss: 0.8127%\n",
      "Epoch [14/300], Step [64/225], Training Accuracy: 61.2305%, Training Loss: 0.8166%\n",
      "Epoch [14/300], Step [65/225], Training Accuracy: 61.2981%, Training Loss: 0.8157%\n",
      "Epoch [14/300], Step [66/225], Training Accuracy: 61.3636%, Training Loss: 0.8154%\n",
      "Epoch [14/300], Step [67/225], Training Accuracy: 61.4039%, Training Loss: 0.8144%\n",
      "Epoch [14/300], Step [68/225], Training Accuracy: 61.3971%, Training Loss: 0.8151%\n",
      "Epoch [14/300], Step [69/225], Training Accuracy: 61.3451%, Training Loss: 0.8162%\n",
      "Epoch [14/300], Step [70/225], Training Accuracy: 61.3393%, Training Loss: 0.8176%\n",
      "Epoch [14/300], Step [71/225], Training Accuracy: 61.4657%, Training Loss: 0.8161%\n",
      "Epoch [14/300], Step [72/225], Training Accuracy: 61.3715%, Training Loss: 0.8182%\n",
      "Epoch [14/300], Step [73/225], Training Accuracy: 61.3228%, Training Loss: 0.8174%\n",
      "Epoch [14/300], Step [74/225], Training Accuracy: 61.3809%, Training Loss: 0.8155%\n",
      "Epoch [14/300], Step [75/225], Training Accuracy: 61.2917%, Training Loss: 0.8162%\n",
      "Epoch [14/300], Step [76/225], Training Accuracy: 61.2253%, Training Loss: 0.8168%\n",
      "Epoch [14/300], Step [77/225], Training Accuracy: 61.2216%, Training Loss: 0.8182%\n",
      "Epoch [14/300], Step [78/225], Training Accuracy: 61.2380%, Training Loss: 0.8180%\n",
      "Epoch [14/300], Step [79/225], Training Accuracy: 61.1748%, Training Loss: 0.8192%\n",
      "Epoch [14/300], Step [80/225], Training Accuracy: 60.9766%, Training Loss: 0.8206%\n",
      "Epoch [14/300], Step [81/225], Training Accuracy: 60.9568%, Training Loss: 0.8222%\n",
      "Epoch [14/300], Step [82/225], Training Accuracy: 60.9947%, Training Loss: 0.8222%\n",
      "Epoch [14/300], Step [83/225], Training Accuracy: 60.8998%, Training Loss: 0.8249%\n",
      "Epoch [14/300], Step [84/225], Training Accuracy: 61.0119%, Training Loss: 0.8232%\n",
      "Epoch [14/300], Step [85/225], Training Accuracy: 61.1581%, Training Loss: 0.8215%\n",
      "Epoch [14/300], Step [86/225], Training Accuracy: 61.1919%, Training Loss: 0.8201%\n",
      "Epoch [14/300], Step [87/225], Training Accuracy: 61.2069%, Training Loss: 0.8214%\n",
      "Epoch [14/300], Step [88/225], Training Accuracy: 61.0973%, Training Loss: 0.8244%\n",
      "Epoch [14/300], Step [89/225], Training Accuracy: 60.9726%, Training Loss: 0.8277%\n",
      "Epoch [14/300], Step [90/225], Training Accuracy: 60.9375%, Training Loss: 0.8287%\n",
      "Epoch [14/300], Step [91/225], Training Accuracy: 60.9375%, Training Loss: 0.8295%\n",
      "Epoch [14/300], Step [92/225], Training Accuracy: 60.8865%, Training Loss: 0.8312%\n",
      "Epoch [14/300], Step [93/225], Training Accuracy: 60.9039%, Training Loss: 0.8316%\n",
      "Epoch [14/300], Step [94/225], Training Accuracy: 60.9707%, Training Loss: 0.8301%\n",
      "Epoch [14/300], Step [95/225], Training Accuracy: 61.0033%, Training Loss: 0.8320%\n",
      "Epoch [14/300], Step [96/225], Training Accuracy: 61.0514%, Training Loss: 0.8314%\n",
      "Epoch [14/300], Step [97/225], Training Accuracy: 61.0825%, Training Loss: 0.8327%\n",
      "Epoch [14/300], Step [98/225], Training Accuracy: 61.0810%, Training Loss: 0.8327%\n",
      "Epoch [14/300], Step [99/225], Training Accuracy: 61.0164%, Training Loss: 0.8333%\n",
      "Epoch [14/300], Step [100/225], Training Accuracy: 60.9688%, Training Loss: 0.8345%\n",
      "Epoch [14/300], Step [101/225], Training Accuracy: 60.9220%, Training Loss: 0.8343%\n",
      "Epoch [14/300], Step [102/225], Training Accuracy: 60.9528%, Training Loss: 0.8355%\n",
      "Epoch [14/300], Step [103/225], Training Accuracy: 60.9678%, Training Loss: 0.8355%\n",
      "Epoch [14/300], Step [104/225], Training Accuracy: 60.9075%, Training Loss: 0.8359%\n",
      "Epoch [14/300], Step [105/225], Training Accuracy: 60.9970%, Training Loss: 0.8359%\n",
      "Epoch [14/300], Step [106/225], Training Accuracy: 61.0407%, Training Loss: 0.8357%\n",
      "Epoch [14/300], Step [107/225], Training Accuracy: 60.9375%, Training Loss: 0.8365%\n",
      "Epoch [14/300], Step [108/225], Training Accuracy: 60.9664%, Training Loss: 0.8362%\n",
      "Epoch [14/300], Step [109/225], Training Accuracy: 60.9232%, Training Loss: 0.8363%\n",
      "Epoch [14/300], Step [110/225], Training Accuracy: 60.9943%, Training Loss: 0.8354%\n",
      "Epoch [14/300], Step [111/225], Training Accuracy: 60.9516%, Training Loss: 0.8353%\n",
      "Epoch [14/300], Step [112/225], Training Accuracy: 60.9654%, Training Loss: 0.8345%\n",
      "Epoch [14/300], Step [113/225], Training Accuracy: 60.9652%, Training Loss: 0.8346%\n",
      "Epoch [14/300], Step [114/225], Training Accuracy: 60.9649%, Training Loss: 0.8342%\n",
      "Epoch [14/300], Step [115/225], Training Accuracy: 61.0326%, Training Loss: 0.8340%\n",
      "Epoch [14/300], Step [116/225], Training Accuracy: 61.0453%, Training Loss: 0.8346%\n",
      "Epoch [14/300], Step [117/225], Training Accuracy: 60.9375%, Training Loss: 0.8371%\n",
      "Epoch [14/300], Step [118/225], Training Accuracy: 60.8978%, Training Loss: 0.8378%\n",
      "Epoch [14/300], Step [119/225], Training Accuracy: 60.8587%, Training Loss: 0.8378%\n",
      "Epoch [14/300], Step [120/225], Training Accuracy: 60.8724%, Training Loss: 0.8373%\n",
      "Epoch [14/300], Step [121/225], Training Accuracy: 60.8213%, Training Loss: 0.8383%\n",
      "Epoch [14/300], Step [122/225], Training Accuracy: 60.7838%, Training Loss: 0.8384%\n",
      "Epoch [14/300], Step [123/225], Training Accuracy: 60.8105%, Training Loss: 0.8375%\n",
      "Epoch [14/300], Step [124/225], Training Accuracy: 60.8493%, Training Loss: 0.8370%\n",
      "Epoch [14/300], Step [125/225], Training Accuracy: 60.8125%, Training Loss: 0.8381%\n",
      "Epoch [14/300], Step [126/225], Training Accuracy: 60.8383%, Training Loss: 0.8382%\n",
      "Epoch [14/300], Step [127/225], Training Accuracy: 60.8637%, Training Loss: 0.8379%\n",
      "Epoch [14/300], Step [128/225], Training Accuracy: 60.7910%, Training Loss: 0.8389%\n",
      "Epoch [14/300], Step [129/225], Training Accuracy: 60.7922%, Training Loss: 0.8389%\n",
      "Epoch [14/300], Step [130/225], Training Accuracy: 60.7572%, Training Loss: 0.8389%\n",
      "Epoch [14/300], Step [131/225], Training Accuracy: 60.6870%, Training Loss: 0.8403%\n",
      "Epoch [14/300], Step [132/225], Training Accuracy: 60.5824%, Training Loss: 0.8413%\n",
      "Epoch [14/300], Step [133/225], Training Accuracy: 60.5851%, Training Loss: 0.8413%\n",
      "Epoch [14/300], Step [134/225], Training Accuracy: 60.4478%, Training Loss: 0.8438%\n",
      "Epoch [14/300], Step [135/225], Training Accuracy: 60.4630%, Training Loss: 0.8434%\n",
      "Epoch [14/300], Step [136/225], Training Accuracy: 60.4894%, Training Loss: 0.8429%\n",
      "Epoch [14/300], Step [137/225], Training Accuracy: 60.5155%, Training Loss: 0.8428%\n",
      "Epoch [14/300], Step [138/225], Training Accuracy: 60.5978%, Training Loss: 0.8415%\n",
      "Epoch [14/300], Step [139/225], Training Accuracy: 60.5890%, Training Loss: 0.8425%\n",
      "Epoch [14/300], Step [140/225], Training Accuracy: 60.6138%, Training Loss: 0.8417%\n",
      "Epoch [14/300], Step [141/225], Training Accuracy: 60.6161%, Training Loss: 0.8411%\n",
      "Epoch [14/300], Step [142/225], Training Accuracy: 60.5634%, Training Loss: 0.8413%\n",
      "Epoch [14/300], Step [143/225], Training Accuracy: 60.6206%, Training Loss: 0.8413%\n",
      "Epoch [14/300], Step [144/225], Training Accuracy: 60.5469%, Training Loss: 0.8419%\n",
      "Epoch [14/300], Step [145/225], Training Accuracy: 60.5280%, Training Loss: 0.8420%\n",
      "Epoch [14/300], Step [146/225], Training Accuracy: 60.5308%, Training Loss: 0.8420%\n",
      "Epoch [14/300], Step [147/225], Training Accuracy: 60.5017%, Training Loss: 0.8429%\n",
      "Epoch [14/300], Step [148/225], Training Accuracy: 60.5258%, Training Loss: 0.8430%\n",
      "Epoch [14/300], Step [149/225], Training Accuracy: 60.5495%, Training Loss: 0.8427%\n",
      "Epoch [14/300], Step [150/225], Training Accuracy: 60.5625%, Training Loss: 0.8426%\n",
      "Epoch [14/300], Step [151/225], Training Accuracy: 60.5857%, Training Loss: 0.8422%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/300], Step [152/225], Training Accuracy: 60.6086%, Training Loss: 0.8420%\n",
      "Epoch [14/300], Step [153/225], Training Accuracy: 60.6107%, Training Loss: 0.8414%\n",
      "Epoch [14/300], Step [154/225], Training Accuracy: 60.6027%, Training Loss: 0.8413%\n",
      "Epoch [14/300], Step [155/225], Training Accuracy: 60.5444%, Training Loss: 0.8418%\n",
      "Epoch [14/300], Step [156/225], Training Accuracy: 60.5369%, Training Loss: 0.8427%\n",
      "Epoch [14/300], Step [157/225], Training Accuracy: 60.5593%, Training Loss: 0.8422%\n",
      "Epoch [14/300], Step [158/225], Training Accuracy: 60.5024%, Training Loss: 0.8428%\n",
      "Epoch [14/300], Step [159/225], Training Accuracy: 60.5248%, Training Loss: 0.8429%\n",
      "Epoch [14/300], Step [160/225], Training Accuracy: 60.5762%, Training Loss: 0.8423%\n",
      "Epoch [14/300], Step [161/225], Training Accuracy: 60.5784%, Training Loss: 0.8423%\n",
      "Epoch [14/300], Step [162/225], Training Accuracy: 60.5324%, Training Loss: 0.8421%\n",
      "Epoch [14/300], Step [163/225], Training Accuracy: 60.5445%, Training Loss: 0.8415%\n",
      "Epoch [14/300], Step [164/225], Training Accuracy: 60.5755%, Training Loss: 0.8406%\n",
      "Epoch [14/300], Step [165/225], Training Accuracy: 60.5682%, Training Loss: 0.8407%\n",
      "Epoch [14/300], Step [166/225], Training Accuracy: 60.5328%, Training Loss: 0.8412%\n",
      "Epoch [14/300], Step [167/225], Training Accuracy: 60.5632%, Training Loss: 0.8407%\n",
      "Epoch [14/300], Step [168/225], Training Accuracy: 60.5190%, Training Loss: 0.8407%\n",
      "Epoch [14/300], Step [169/225], Training Accuracy: 60.5399%, Training Loss: 0.8405%\n",
      "Epoch [14/300], Step [170/225], Training Accuracy: 60.6066%, Training Loss: 0.8399%\n",
      "Epoch [14/300], Step [171/225], Training Accuracy: 60.6086%, Training Loss: 0.8398%\n",
      "Epoch [14/300], Step [172/225], Training Accuracy: 60.5923%, Training Loss: 0.8398%\n",
      "Epoch [14/300], Step [173/225], Training Accuracy: 60.6033%, Training Loss: 0.8393%\n",
      "Epoch [14/300], Step [174/225], Training Accuracy: 60.6681%, Training Loss: 0.8389%\n",
      "Epoch [14/300], Step [175/225], Training Accuracy: 60.7589%, Training Loss: 0.8379%\n",
      "Epoch [14/300], Step [176/225], Training Accuracy: 60.7777%, Training Loss: 0.8376%\n",
      "Epoch [14/300], Step [177/225], Training Accuracy: 60.7874%, Training Loss: 0.8367%\n",
      "Epoch [14/300], Step [178/225], Training Accuracy: 60.7795%, Training Loss: 0.8362%\n",
      "Epoch [14/300], Step [179/225], Training Accuracy: 60.8328%, Training Loss: 0.8354%\n",
      "Epoch [14/300], Step [180/225], Training Accuracy: 60.8854%, Training Loss: 0.8346%\n",
      "Epoch [14/300], Step [181/225], Training Accuracy: 60.8857%, Training Loss: 0.8347%\n",
      "Epoch [14/300], Step [182/225], Training Accuracy: 60.9117%, Training Loss: 0.8339%\n",
      "Epoch [14/300], Step [183/225], Training Accuracy: 60.8948%, Training Loss: 0.8344%\n",
      "Epoch [14/300], Step [184/225], Training Accuracy: 60.9290%, Training Loss: 0.8338%\n",
      "Epoch [14/300], Step [185/225], Training Accuracy: 60.9882%, Training Loss: 0.8331%\n",
      "Epoch [14/300], Step [186/225], Training Accuracy: 61.0467%, Training Loss: 0.8319%\n",
      "Epoch [14/300], Step [187/225], Training Accuracy: 61.0628%, Training Loss: 0.8316%\n",
      "Epoch [14/300], Step [188/225], Training Accuracy: 61.1536%, Training Loss: 0.8306%\n",
      "Epoch [14/300], Step [189/225], Training Accuracy: 61.2269%, Training Loss: 0.8296%\n",
      "Epoch [14/300], Step [190/225], Training Accuracy: 61.2253%, Training Loss: 0.8292%\n",
      "Epoch [14/300], Step [191/225], Training Accuracy: 61.2238%, Training Loss: 0.8291%\n",
      "Epoch [14/300], Step [192/225], Training Accuracy: 61.3281%, Training Loss: 0.8276%\n",
      "Epoch [14/300], Step [193/225], Training Accuracy: 61.3018%, Training Loss: 0.8281%\n",
      "Epoch [14/300], Step [194/225], Training Accuracy: 61.3241%, Training Loss: 0.8283%\n",
      "Epoch [14/300], Step [195/225], Training Accuracy: 61.3622%, Training Loss: 0.8273%\n",
      "Epoch [14/300], Step [196/225], Training Accuracy: 61.3760%, Training Loss: 0.8273%\n",
      "Epoch [14/300], Step [197/225], Training Accuracy: 61.3896%, Training Loss: 0.8277%\n",
      "Epoch [14/300], Step [198/225], Training Accuracy: 61.4189%, Training Loss: 0.8269%\n",
      "Epoch [14/300], Step [199/225], Training Accuracy: 61.4636%, Training Loss: 0.8267%\n",
      "Epoch [14/300], Step [200/225], Training Accuracy: 61.4688%, Training Loss: 0.8271%\n",
      "Epoch [14/300], Step [201/225], Training Accuracy: 61.5205%, Training Loss: 0.8269%\n",
      "Epoch [14/300], Step [202/225], Training Accuracy: 61.5022%, Training Loss: 0.8274%\n",
      "Epoch [14/300], Step [203/225], Training Accuracy: 61.5379%, Training Loss: 0.8269%\n",
      "Epoch [14/300], Step [204/225], Training Accuracy: 61.4890%, Training Loss: 0.8277%\n",
      "Epoch [14/300], Step [205/225], Training Accuracy: 61.5473%, Training Loss: 0.8269%\n",
      "Epoch [14/300], Step [206/225], Training Accuracy: 61.5291%, Training Loss: 0.8272%\n",
      "Epoch [14/300], Step [207/225], Training Accuracy: 61.5716%, Training Loss: 0.8273%\n",
      "Epoch [14/300], Step [208/225], Training Accuracy: 61.5910%, Training Loss: 0.8266%\n",
      "Epoch [14/300], Step [209/225], Training Accuracy: 61.6103%, Training Loss: 0.8268%\n",
      "Epoch [14/300], Step [210/225], Training Accuracy: 61.5923%, Training Loss: 0.8272%\n",
      "Epoch [14/300], Step [211/225], Training Accuracy: 61.6632%, Training Loss: 0.8263%\n",
      "Epoch [14/300], Step [212/225], Training Accuracy: 61.7040%, Training Loss: 0.8259%\n",
      "Epoch [14/300], Step [213/225], Training Accuracy: 61.6564%, Training Loss: 0.8270%\n",
      "Epoch [14/300], Step [214/225], Training Accuracy: 61.6822%, Training Loss: 0.8265%\n",
      "Epoch [14/300], Step [215/225], Training Accuracy: 61.7078%, Training Loss: 0.8261%\n",
      "Epoch [14/300], Step [216/225], Training Accuracy: 61.7043%, Training Loss: 0.8260%\n",
      "Epoch [14/300], Step [217/225], Training Accuracy: 61.6791%, Training Loss: 0.8264%\n",
      "Epoch [14/300], Step [218/225], Training Accuracy: 61.6901%, Training Loss: 0.8266%\n",
      "Epoch [14/300], Step [219/225], Training Accuracy: 61.6652%, Training Loss: 0.8268%\n",
      "Epoch [14/300], Step [220/225], Training Accuracy: 61.6548%, Training Loss: 0.8269%\n",
      "Epoch [14/300], Step [221/225], Training Accuracy: 61.6233%, Training Loss: 0.8272%\n",
      "Epoch [14/300], Step [222/225], Training Accuracy: 61.6343%, Training Loss: 0.8269%\n",
      "Epoch [14/300], Step [223/225], Training Accuracy: 61.6031%, Training Loss: 0.8276%\n",
      "Epoch [14/300], Step [224/225], Training Accuracy: 61.5792%, Training Loss: 0.8275%\n",
      "Epoch [14/300], Step [225/225], Training Accuracy: 61.5689%, Training Loss: 0.8273%\n",
      "Epoch [15/300], Step [1/225], Training Accuracy: 67.1875%, Training Loss: 0.7350%\n",
      "Epoch [15/300], Step [2/225], Training Accuracy: 64.8438%, Training Loss: 0.8010%\n",
      "Epoch [15/300], Step [3/225], Training Accuracy: 63.5417%, Training Loss: 0.8577%\n",
      "Epoch [15/300], Step [4/225], Training Accuracy: 62.8906%, Training Loss: 0.8804%\n",
      "Epoch [15/300], Step [5/225], Training Accuracy: 63.4375%, Training Loss: 0.8547%\n",
      "Epoch [15/300], Step [6/225], Training Accuracy: 63.5417%, Training Loss: 0.8356%\n",
      "Epoch [15/300], Step [7/225], Training Accuracy: 62.7232%, Training Loss: 0.8258%\n",
      "Epoch [15/300], Step [8/225], Training Accuracy: 63.0859%, Training Loss: 0.8299%\n",
      "Epoch [15/300], Step [9/225], Training Accuracy: 63.1944%, Training Loss: 0.8252%\n",
      "Epoch [15/300], Step [10/225], Training Accuracy: 61.5625%, Training Loss: 0.8480%\n",
      "Epoch [15/300], Step [11/225], Training Accuracy: 61.7898%, Training Loss: 0.8492%\n",
      "Epoch [15/300], Step [12/225], Training Accuracy: 62.2396%, Training Loss: 0.8454%\n",
      "Epoch [15/300], Step [13/225], Training Accuracy: 62.5000%, Training Loss: 0.8295%\n",
      "Epoch [15/300], Step [14/225], Training Accuracy: 63.1696%, Training Loss: 0.8220%\n",
      "Epoch [15/300], Step [15/225], Training Accuracy: 63.2292%, Training Loss: 0.8232%\n",
      "Epoch [15/300], Step [16/225], Training Accuracy: 63.2812%, Training Loss: 0.8259%\n",
      "Epoch [15/300], Step [17/225], Training Accuracy: 63.2353%, Training Loss: 0.8232%\n",
      "Epoch [15/300], Step [18/225], Training Accuracy: 63.1944%, Training Loss: 0.8237%\n",
      "Epoch [15/300], Step [19/225], Training Accuracy: 63.0757%, Training Loss: 0.8256%\n",
      "Epoch [15/300], Step [20/225], Training Accuracy: 63.6719%, Training Loss: 0.8150%\n",
      "Epoch [15/300], Step [21/225], Training Accuracy: 63.6161%, Training Loss: 0.8090%\n",
      "Epoch [15/300], Step [22/225], Training Accuracy: 63.2812%, Training Loss: 0.8135%\n",
      "Epoch [15/300], Step [23/225], Training Accuracy: 62.9755%, Training Loss: 0.8156%\n",
      "Epoch [15/300], Step [24/225], Training Accuracy: 62.6953%, Training Loss: 0.8224%\n",
      "Epoch [15/300], Step [25/225], Training Accuracy: 62.8750%, Training Loss: 0.8227%\n",
      "Epoch [15/300], Step [26/225], Training Accuracy: 62.8005%, Training Loss: 0.8258%\n",
      "Epoch [15/300], Step [27/225], Training Accuracy: 62.6736%, Training Loss: 0.8256%\n",
      "Epoch [15/300], Step [28/225], Training Accuracy: 63.3371%, Training Loss: 0.8168%\n",
      "Epoch [15/300], Step [29/225], Training Accuracy: 63.6315%, Training Loss: 0.8111%\n",
      "Epoch [15/300], Step [30/225], Training Accuracy: 63.6979%, Training Loss: 0.8097%\n",
      "Epoch [15/300], Step [31/225], Training Accuracy: 63.7601%, Training Loss: 0.8106%\n",
      "Epoch [15/300], Step [32/225], Training Accuracy: 63.8184%, Training Loss: 0.8057%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/300], Step [33/225], Training Accuracy: 63.7311%, Training Loss: 0.8087%\n",
      "Epoch [15/300], Step [34/225], Training Accuracy: 63.4191%, Training Loss: 0.8129%\n",
      "Epoch [15/300], Step [35/225], Training Accuracy: 63.1696%, Training Loss: 0.8130%\n",
      "Epoch [15/300], Step [36/225], Training Accuracy: 63.0642%, Training Loss: 0.8160%\n",
      "Epoch [15/300], Step [37/225], Training Accuracy: 62.9645%, Training Loss: 0.8167%\n",
      "Epoch [15/300], Step [38/225], Training Accuracy: 62.9523%, Training Loss: 0.8156%\n",
      "Epoch [15/300], Step [39/225], Training Accuracy: 62.9006%, Training Loss: 0.8171%\n",
      "Epoch [15/300], Step [40/225], Training Accuracy: 63.0469%, Training Loss: 0.8170%\n",
      "Epoch [15/300], Step [41/225], Training Accuracy: 62.8811%, Training Loss: 0.8183%\n",
      "Epoch [15/300], Step [42/225], Training Accuracy: 62.8720%, Training Loss: 0.8173%\n",
      "Epoch [15/300], Step [43/225], Training Accuracy: 62.7907%, Training Loss: 0.8177%\n",
      "Epoch [15/300], Step [44/225], Training Accuracy: 62.7841%, Training Loss: 0.8187%\n",
      "Epoch [15/300], Step [45/225], Training Accuracy: 62.5694%, Training Loss: 0.8210%\n",
      "Epoch [15/300], Step [46/225], Training Accuracy: 62.7717%, Training Loss: 0.8169%\n",
      "Epoch [15/300], Step [47/225], Training Accuracy: 62.7660%, Training Loss: 0.8170%\n",
      "Epoch [15/300], Step [48/225], Training Accuracy: 62.6628%, Training Loss: 0.8165%\n",
      "Epoch [15/300], Step [49/225], Training Accuracy: 62.6276%, Training Loss: 0.8160%\n",
      "Epoch [15/300], Step [50/225], Training Accuracy: 62.6562%, Training Loss: 0.8146%\n",
      "Epoch [15/300], Step [51/225], Training Accuracy: 62.8676%, Training Loss: 0.8132%\n",
      "Epoch [15/300], Step [52/225], Training Accuracy: 63.1310%, Training Loss: 0.8092%\n",
      "Epoch [15/300], Step [53/225], Training Accuracy: 62.9717%, Training Loss: 0.8115%\n",
      "Epoch [15/300], Step [54/225], Training Accuracy: 62.9919%, Training Loss: 0.8111%\n",
      "Epoch [15/300], Step [55/225], Training Accuracy: 62.8977%, Training Loss: 0.8154%\n",
      "Epoch [15/300], Step [56/225], Training Accuracy: 62.7511%, Training Loss: 0.8166%\n",
      "Epoch [15/300], Step [57/225], Training Accuracy: 62.8289%, Training Loss: 0.8154%\n",
      "Epoch [15/300], Step [58/225], Training Accuracy: 62.8502%, Training Loss: 0.8150%\n",
      "Epoch [15/300], Step [59/225], Training Accuracy: 62.8443%, Training Loss: 0.8149%\n",
      "Epoch [15/300], Step [60/225], Training Accuracy: 62.7865%, Training Loss: 0.8167%\n",
      "Epoch [15/300], Step [61/225], Training Accuracy: 62.8074%, Training Loss: 0.8173%\n",
      "Epoch [15/300], Step [62/225], Training Accuracy: 62.9788%, Training Loss: 0.8149%\n",
      "Epoch [15/300], Step [63/225], Training Accuracy: 62.9216%, Training Loss: 0.8151%\n",
      "Epoch [15/300], Step [64/225], Training Accuracy: 62.8662%, Training Loss: 0.8149%\n",
      "Epoch [15/300], Step [65/225], Training Accuracy: 62.8365%, Training Loss: 0.8144%\n",
      "Epoch [15/300], Step [66/225], Training Accuracy: 62.7604%, Training Loss: 0.8146%\n",
      "Epoch [15/300], Step [67/225], Training Accuracy: 62.8265%, Training Loss: 0.8149%\n",
      "Epoch [15/300], Step [68/225], Training Accuracy: 62.7528%, Training Loss: 0.8158%\n",
      "Epoch [15/300], Step [69/225], Training Accuracy: 62.7491%, Training Loss: 0.8168%\n",
      "Epoch [15/300], Step [70/225], Training Accuracy: 62.7679%, Training Loss: 0.8162%\n",
      "Epoch [15/300], Step [71/225], Training Accuracy: 62.8301%, Training Loss: 0.8144%\n",
      "Epoch [15/300], Step [72/225], Training Accuracy: 62.7604%, Training Loss: 0.8153%\n",
      "Epoch [15/300], Step [73/225], Training Accuracy: 62.7354%, Training Loss: 0.8150%\n",
      "Epoch [15/300], Step [74/225], Training Accuracy: 62.7111%, Training Loss: 0.8139%\n",
      "Epoch [15/300], Step [75/225], Training Accuracy: 62.7292%, Training Loss: 0.8131%\n",
      "Epoch [15/300], Step [76/225], Training Accuracy: 62.6234%, Training Loss: 0.8147%\n",
      "Epoch [15/300], Step [77/225], Training Accuracy: 62.6015%, Training Loss: 0.8146%\n",
      "Epoch [15/300], Step [78/225], Training Accuracy: 62.6803%, Training Loss: 0.8128%\n",
      "Epoch [15/300], Step [79/225], Training Accuracy: 62.8165%, Training Loss: 0.8120%\n",
      "Epoch [15/300], Step [80/225], Training Accuracy: 62.7539%, Training Loss: 0.8118%\n",
      "Epoch [15/300], Step [81/225], Training Accuracy: 62.8086%, Training Loss: 0.8111%\n",
      "Epoch [15/300], Step [82/225], Training Accuracy: 62.8430%, Training Loss: 0.8098%\n",
      "Epoch [15/300], Step [83/225], Training Accuracy: 62.8389%, Training Loss: 0.8094%\n",
      "Epoch [15/300], Step [84/225], Training Accuracy: 62.8348%, Training Loss: 0.8089%\n",
      "Epoch [15/300], Step [85/225], Training Accuracy: 62.9596%, Training Loss: 0.8065%\n",
      "Epoch [15/300], Step [86/225], Training Accuracy: 63.0269%, Training Loss: 0.8052%\n",
      "Epoch [15/300], Step [87/225], Training Accuracy: 62.9490%, Training Loss: 0.8063%\n",
      "Epoch [15/300], Step [88/225], Training Accuracy: 62.9794%, Training Loss: 0.8067%\n",
      "Epoch [15/300], Step [89/225], Training Accuracy: 62.9389%, Training Loss: 0.8088%\n",
      "Epoch [15/300], Step [90/225], Training Accuracy: 62.9167%, Training Loss: 0.8091%\n",
      "Epoch [15/300], Step [91/225], Training Accuracy: 62.9636%, Training Loss: 0.8083%\n",
      "Epoch [15/300], Step [92/225], Training Accuracy: 62.9586%, Training Loss: 0.8090%\n",
      "Epoch [15/300], Step [93/225], Training Accuracy: 62.9368%, Training Loss: 0.8092%\n",
      "Epoch [15/300], Step [94/225], Training Accuracy: 62.9488%, Training Loss: 0.8083%\n",
      "Epoch [15/300], Step [95/225], Training Accuracy: 62.8947%, Training Loss: 0.8106%\n",
      "Epoch [15/300], Step [96/225], Training Accuracy: 62.9557%, Training Loss: 0.8089%\n",
      "Epoch [15/300], Step [97/225], Training Accuracy: 62.9349%, Training Loss: 0.8098%\n",
      "Epoch [15/300], Step [98/225], Training Accuracy: 62.8667%, Training Loss: 0.8101%\n",
      "Epoch [15/300], Step [99/225], Training Accuracy: 62.8472%, Training Loss: 0.8101%\n",
      "Epoch [15/300], Step [100/225], Training Accuracy: 62.7188%, Training Loss: 0.8111%\n",
      "Epoch [15/300], Step [101/225], Training Accuracy: 62.6856%, Training Loss: 0.8116%\n",
      "Epoch [15/300], Step [102/225], Training Accuracy: 62.6532%, Training Loss: 0.8116%\n",
      "Epoch [15/300], Step [103/225], Training Accuracy: 62.7275%, Training Loss: 0.8115%\n",
      "Epoch [15/300], Step [104/225], Training Accuracy: 62.7704%, Training Loss: 0.8112%\n",
      "Epoch [15/300], Step [105/225], Training Accuracy: 62.7530%, Training Loss: 0.8104%\n",
      "Epoch [15/300], Step [106/225], Training Accuracy: 62.8980%, Training Loss: 0.8090%\n",
      "Epoch [15/300], Step [107/225], Training Accuracy: 62.7921%, Training Loss: 0.8098%\n",
      "Epoch [15/300], Step [108/225], Training Accuracy: 62.8906%, Training Loss: 0.8087%\n",
      "Epoch [15/300], Step [109/225], Training Accuracy: 62.9300%, Training Loss: 0.8087%\n",
      "Epoch [15/300], Step [110/225], Training Accuracy: 62.9830%, Training Loss: 0.8084%\n",
      "Epoch [15/300], Step [111/225], Training Accuracy: 63.0068%, Training Loss: 0.8073%\n",
      "Epoch [15/300], Step [112/225], Training Accuracy: 62.9883%, Training Loss: 0.8068%\n",
      "Epoch [15/300], Step [113/225], Training Accuracy: 63.0254%, Training Loss: 0.8068%\n",
      "Epoch [15/300], Step [114/225], Training Accuracy: 63.1579%, Training Loss: 0.8059%\n",
      "Epoch [15/300], Step [115/225], Training Accuracy: 63.1658%, Training Loss: 0.8055%\n",
      "Epoch [15/300], Step [116/225], Training Accuracy: 63.2139%, Training Loss: 0.8059%\n",
      "Epoch [15/300], Step [117/225], Training Accuracy: 63.0876%, Training Loss: 0.8087%\n",
      "Epoch [15/300], Step [118/225], Training Accuracy: 63.1224%, Training Loss: 0.8087%\n",
      "Epoch [15/300], Step [119/225], Training Accuracy: 63.1565%, Training Loss: 0.8082%\n",
      "Epoch [15/300], Step [120/225], Training Accuracy: 63.2031%, Training Loss: 0.8076%\n",
      "Epoch [15/300], Step [121/225], Training Accuracy: 63.1844%, Training Loss: 0.8078%\n",
      "Epoch [15/300], Step [122/225], Training Accuracy: 63.1404%, Training Loss: 0.8079%\n",
      "Epoch [15/300], Step [123/225], Training Accuracy: 63.2241%, Training Loss: 0.8068%\n",
      "Epoch [15/300], Step [124/225], Training Accuracy: 63.2812%, Training Loss: 0.8059%\n",
      "Epoch [15/300], Step [125/225], Training Accuracy: 63.2125%, Training Loss: 0.8076%\n",
      "Epoch [15/300], Step [126/225], Training Accuracy: 63.2440%, Training Loss: 0.8076%\n",
      "Epoch [15/300], Step [127/225], Training Accuracy: 63.2628%, Training Loss: 0.8080%\n",
      "Epoch [15/300], Step [128/225], Training Accuracy: 63.1958%, Training Loss: 0.8094%\n",
      "Epoch [15/300], Step [129/225], Training Accuracy: 63.1662%, Training Loss: 0.8096%\n",
      "Epoch [15/300], Step [130/225], Training Accuracy: 63.1490%, Training Loss: 0.8096%\n",
      "Epoch [15/300], Step [131/225], Training Accuracy: 63.1202%, Training Loss: 0.8110%\n",
      "Epoch [15/300], Step [132/225], Training Accuracy: 63.1274%, Training Loss: 0.8110%\n",
      "Epoch [15/300], Step [133/225], Training Accuracy: 63.2049%, Training Loss: 0.8095%\n",
      "Epoch [15/300], Step [134/225], Training Accuracy: 63.1880%, Training Loss: 0.8104%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/300], Step [135/225], Training Accuracy: 63.1597%, Training Loss: 0.8102%\n",
      "Epoch [15/300], Step [136/225], Training Accuracy: 63.1664%, Training Loss: 0.8101%\n",
      "Epoch [15/300], Step [137/225], Training Accuracy: 63.1843%, Training Loss: 0.8104%\n",
      "Epoch [15/300], Step [138/225], Training Accuracy: 63.3039%, Training Loss: 0.8089%\n",
      "Epoch [15/300], Step [139/225], Training Accuracy: 63.2756%, Training Loss: 0.8090%\n",
      "Epoch [15/300], Step [140/225], Training Accuracy: 63.3036%, Training Loss: 0.8082%\n",
      "Epoch [15/300], Step [141/225], Training Accuracy: 63.3311%, Training Loss: 0.8082%\n",
      "Epoch [15/300], Step [142/225], Training Accuracy: 63.3693%, Training Loss: 0.8082%\n",
      "Epoch [15/300], Step [143/225], Training Accuracy: 63.4288%, Training Loss: 0.8071%\n",
      "Epoch [15/300], Step [144/225], Training Accuracy: 63.4006%, Training Loss: 0.8069%\n",
      "Epoch [15/300], Step [145/225], Training Accuracy: 63.3728%, Training Loss: 0.8077%\n",
      "Epoch [15/300], Step [146/225], Training Accuracy: 63.3776%, Training Loss: 0.8089%\n",
      "Epoch [15/300], Step [147/225], Training Accuracy: 63.3503%, Training Loss: 0.8097%\n",
      "Epoch [15/300], Step [148/225], Training Accuracy: 63.3446%, Training Loss: 0.8086%\n",
      "Epoch [15/300], Step [149/225], Training Accuracy: 63.3494%, Training Loss: 0.8086%\n",
      "Epoch [15/300], Step [150/225], Training Accuracy: 63.3542%, Training Loss: 0.8080%\n",
      "Epoch [15/300], Step [151/225], Training Accuracy: 63.3692%, Training Loss: 0.8078%\n",
      "Epoch [15/300], Step [152/225], Training Accuracy: 63.3326%, Training Loss: 0.8082%\n",
      "Epoch [15/300], Step [153/225], Training Accuracy: 63.3170%, Training Loss: 0.8077%\n",
      "Epoch [15/300], Step [154/225], Training Accuracy: 63.2508%, Training Loss: 0.8084%\n",
      "Epoch [15/300], Step [155/225], Training Accuracy: 63.2258%, Training Loss: 0.8088%\n",
      "Epoch [15/300], Step [156/225], Training Accuracy: 63.1711%, Training Loss: 0.8095%\n",
      "Epoch [15/300], Step [157/225], Training Accuracy: 63.1867%, Training Loss: 0.8091%\n",
      "Epoch [15/300], Step [158/225], Training Accuracy: 63.1329%, Training Loss: 0.8097%\n",
      "Epoch [15/300], Step [159/225], Training Accuracy: 63.1388%, Training Loss: 0.8093%\n",
      "Epoch [15/300], Step [160/225], Training Accuracy: 63.1445%, Training Loss: 0.8084%\n",
      "Epoch [15/300], Step [161/225], Training Accuracy: 63.1793%, Training Loss: 0.8079%\n",
      "Epoch [15/300], Step [162/225], Training Accuracy: 63.2137%, Training Loss: 0.8072%\n",
      "Epoch [15/300], Step [163/225], Training Accuracy: 63.2285%, Training Loss: 0.8065%\n",
      "Epoch [15/300], Step [164/225], Training Accuracy: 63.2241%, Training Loss: 0.8069%\n",
      "Epoch [15/300], Step [165/225], Training Accuracy: 63.2292%, Training Loss: 0.8065%\n",
      "Epoch [15/300], Step [166/225], Training Accuracy: 63.2154%, Training Loss: 0.8066%\n",
      "Epoch [15/300], Step [167/225], Training Accuracy: 63.2391%, Training Loss: 0.8060%\n",
      "Epoch [15/300], Step [168/225], Training Accuracy: 63.1975%, Training Loss: 0.8065%\n",
      "Epoch [15/300], Step [169/225], Training Accuracy: 63.1749%, Training Loss: 0.8067%\n",
      "Epoch [15/300], Step [170/225], Training Accuracy: 63.1434%, Training Loss: 0.8072%\n",
      "Epoch [15/300], Step [171/225], Training Accuracy: 63.1031%, Training Loss: 0.8072%\n",
      "Epoch [15/300], Step [172/225], Training Accuracy: 63.0905%, Training Loss: 0.8073%\n",
      "Epoch [15/300], Step [173/225], Training Accuracy: 63.0871%, Training Loss: 0.8069%\n",
      "Epoch [15/300], Step [174/225], Training Accuracy: 63.1376%, Training Loss: 0.8064%\n",
      "Epoch [15/300], Step [175/225], Training Accuracy: 63.1518%, Training Loss: 0.8059%\n",
      "Epoch [15/300], Step [176/225], Training Accuracy: 63.1658%, Training Loss: 0.8057%\n",
      "Epoch [15/300], Step [177/225], Training Accuracy: 63.2062%, Training Loss: 0.8058%\n",
      "Epoch [15/300], Step [178/225], Training Accuracy: 63.1935%, Training Loss: 0.8056%\n",
      "Epoch [15/300], Step [179/225], Training Accuracy: 63.2594%, Training Loss: 0.8044%\n",
      "Epoch [15/300], Step [180/225], Training Accuracy: 63.3073%, Training Loss: 0.8041%\n",
      "Epoch [15/300], Step [181/225], Training Accuracy: 63.3201%, Training Loss: 0.8040%\n",
      "Epoch [15/300], Step [182/225], Training Accuracy: 63.3413%, Training Loss: 0.8037%\n",
      "Epoch [15/300], Step [183/225], Training Accuracy: 63.3282%, Training Loss: 0.8038%\n",
      "Epoch [15/300], Step [184/225], Training Accuracy: 63.3322%, Training Loss: 0.8039%\n",
      "Epoch [15/300], Step [185/225], Training Accuracy: 63.3699%, Training Loss: 0.8033%\n",
      "Epoch [15/300], Step [186/225], Training Accuracy: 63.4157%, Training Loss: 0.8023%\n",
      "Epoch [15/300], Step [187/225], Training Accuracy: 63.4442%, Training Loss: 0.8016%\n",
      "Epoch [15/300], Step [188/225], Training Accuracy: 63.4973%, Training Loss: 0.8010%\n",
      "Epoch [15/300], Step [189/225], Training Accuracy: 63.5251%, Training Loss: 0.8006%\n",
      "Epoch [15/300], Step [190/225], Training Accuracy: 63.5773%, Training Loss: 0.8000%\n",
      "Epoch [15/300], Step [191/225], Training Accuracy: 63.5880%, Training Loss: 0.7996%\n",
      "Epoch [15/300], Step [192/225], Training Accuracy: 63.6393%, Training Loss: 0.7986%\n",
      "Epoch [15/300], Step [193/225], Training Accuracy: 63.6658%, Training Loss: 0.7983%\n",
      "Epoch [15/300], Step [194/225], Training Accuracy: 63.6840%, Training Loss: 0.7981%\n",
      "Epoch [15/300], Step [195/225], Training Accuracy: 63.7179%, Training Loss: 0.7978%\n",
      "Epoch [15/300], Step [196/225], Training Accuracy: 63.7357%, Training Loss: 0.7973%\n",
      "Epoch [15/300], Step [197/225], Training Accuracy: 63.7373%, Training Loss: 0.7975%\n",
      "Epoch [15/300], Step [198/225], Training Accuracy: 63.7705%, Training Loss: 0.7966%\n",
      "Epoch [15/300], Step [199/225], Training Accuracy: 63.7641%, Training Loss: 0.7962%\n",
      "Epoch [15/300], Step [200/225], Training Accuracy: 63.7656%, Training Loss: 0.7966%\n",
      "Epoch [15/300], Step [201/225], Training Accuracy: 63.7982%, Training Loss: 0.7961%\n",
      "Epoch [15/300], Step [202/225], Training Accuracy: 63.7840%, Training Loss: 0.7958%\n",
      "Epoch [15/300], Step [203/225], Training Accuracy: 63.8085%, Training Loss: 0.7955%\n",
      "Epoch [15/300], Step [204/225], Training Accuracy: 63.8021%, Training Loss: 0.7960%\n",
      "Epoch [15/300], Step [205/225], Training Accuracy: 63.8415%, Training Loss: 0.7952%\n",
      "Epoch [15/300], Step [206/225], Training Accuracy: 63.7894%, Training Loss: 0.7957%\n",
      "Epoch [15/300], Step [207/225], Training Accuracy: 63.7757%, Training Loss: 0.7959%\n",
      "Epoch [15/300], Step [208/225], Training Accuracy: 63.7921%, Training Loss: 0.7952%\n",
      "Epoch [15/300], Step [209/225], Training Accuracy: 63.7709%, Training Loss: 0.7954%\n",
      "Epoch [15/300], Step [210/225], Training Accuracy: 63.7426%, Training Loss: 0.7960%\n",
      "Epoch [15/300], Step [211/225], Training Accuracy: 63.7811%, Training Loss: 0.7951%\n",
      "Epoch [15/300], Step [212/225], Training Accuracy: 63.7751%, Training Loss: 0.7947%\n",
      "Epoch [15/300], Step [213/225], Training Accuracy: 63.7544%, Training Loss: 0.7954%\n",
      "Epoch [15/300], Step [214/225], Training Accuracy: 63.7704%, Training Loss: 0.7949%\n",
      "Epoch [15/300], Step [215/225], Training Accuracy: 63.7573%, Training Loss: 0.7952%\n",
      "Epoch [15/300], Step [216/225], Training Accuracy: 63.7587%, Training Loss: 0.7952%\n",
      "Epoch [15/300], Step [217/225], Training Accuracy: 63.7313%, Training Loss: 0.7955%\n",
      "Epoch [15/300], Step [218/225], Training Accuracy: 63.7328%, Training Loss: 0.7954%\n",
      "Epoch [15/300], Step [219/225], Training Accuracy: 63.7129%, Training Loss: 0.7956%\n",
      "Epoch [15/300], Step [220/225], Training Accuracy: 63.7003%, Training Loss: 0.7959%\n",
      "Epoch [15/300], Step [221/225], Training Accuracy: 63.6595%, Training Loss: 0.7960%\n",
      "Epoch [15/300], Step [222/225], Training Accuracy: 63.6613%, Training Loss: 0.7961%\n",
      "Epoch [15/300], Step [223/225], Training Accuracy: 63.6211%, Training Loss: 0.7974%\n",
      "Epoch [15/300], Step [224/225], Training Accuracy: 63.5882%, Training Loss: 0.7977%\n",
      "Epoch [15/300], Step [225/225], Training Accuracy: 63.5909%, Training Loss: 0.7979%\n",
      "Epoch [16/300], Step [1/225], Training Accuracy: 71.8750%, Training Loss: 0.7628%\n",
      "Epoch [16/300], Step [2/225], Training Accuracy: 70.3125%, Training Loss: 0.8070%\n",
      "Epoch [16/300], Step [3/225], Training Accuracy: 69.2708%, Training Loss: 0.7770%\n",
      "Epoch [16/300], Step [4/225], Training Accuracy: 65.6250%, Training Loss: 0.8219%\n",
      "Epoch [16/300], Step [5/225], Training Accuracy: 65.6250%, Training Loss: 0.8058%\n",
      "Epoch [16/300], Step [6/225], Training Accuracy: 65.6250%, Training Loss: 0.7920%\n",
      "Epoch [16/300], Step [7/225], Training Accuracy: 65.8482%, Training Loss: 0.7887%\n",
      "Epoch [16/300], Step [8/225], Training Accuracy: 66.2109%, Training Loss: 0.7911%\n",
      "Epoch [16/300], Step [9/225], Training Accuracy: 65.6250%, Training Loss: 0.7796%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/300], Step [10/225], Training Accuracy: 64.8438%, Training Loss: 0.7977%\n",
      "Epoch [16/300], Step [11/225], Training Accuracy: 64.4886%, Training Loss: 0.7971%\n",
      "Epoch [16/300], Step [12/225], Training Accuracy: 64.0625%, Training Loss: 0.8002%\n",
      "Epoch [16/300], Step [13/225], Training Accuracy: 65.0240%, Training Loss: 0.7839%\n",
      "Epoch [16/300], Step [14/225], Training Accuracy: 64.8438%, Training Loss: 0.7881%\n",
      "Epoch [16/300], Step [15/225], Training Accuracy: 64.5833%, Training Loss: 0.7943%\n",
      "Epoch [16/300], Step [16/225], Training Accuracy: 65.0391%, Training Loss: 0.7911%\n",
      "Epoch [16/300], Step [17/225], Training Accuracy: 65.1654%, Training Loss: 0.7856%\n",
      "Epoch [16/300], Step [18/225], Training Accuracy: 64.9306%, Training Loss: 0.7897%\n",
      "Epoch [16/300], Step [19/225], Training Accuracy: 65.2138%, Training Loss: 0.7852%\n",
      "Epoch [16/300], Step [20/225], Training Accuracy: 65.3906%, Training Loss: 0.7829%\n",
      "Epoch [16/300], Step [21/225], Training Accuracy: 65.2530%, Training Loss: 0.7797%\n",
      "Epoch [16/300], Step [22/225], Training Accuracy: 64.8438%, Training Loss: 0.7856%\n",
      "Epoch [16/300], Step [23/225], Training Accuracy: 64.8098%, Training Loss: 0.7844%\n",
      "Epoch [16/300], Step [24/225], Training Accuracy: 64.5833%, Training Loss: 0.7866%\n",
      "Epoch [16/300], Step [25/225], Training Accuracy: 64.3125%, Training Loss: 0.7890%\n",
      "Epoch [16/300], Step [26/225], Training Accuracy: 64.5433%, Training Loss: 0.7832%\n",
      "Epoch [16/300], Step [27/225], Training Accuracy: 64.2361%, Training Loss: 0.7825%\n",
      "Epoch [16/300], Step [28/225], Training Accuracy: 64.3973%, Training Loss: 0.7792%\n",
      "Epoch [16/300], Step [29/225], Training Accuracy: 64.7091%, Training Loss: 0.7749%\n",
      "Epoch [16/300], Step [30/225], Training Accuracy: 64.9479%, Training Loss: 0.7739%\n",
      "Epoch [16/300], Step [31/225], Training Accuracy: 64.8185%, Training Loss: 0.7767%\n",
      "Epoch [16/300], Step [32/225], Training Accuracy: 64.9414%, Training Loss: 0.7738%\n",
      "Epoch [16/300], Step [33/225], Training Accuracy: 65.0568%, Training Loss: 0.7689%\n",
      "Epoch [16/300], Step [34/225], Training Accuracy: 64.7978%, Training Loss: 0.7763%\n",
      "Epoch [16/300], Step [35/225], Training Accuracy: 64.7768%, Training Loss: 0.7781%\n",
      "Epoch [16/300], Step [36/225], Training Accuracy: 64.8438%, Training Loss: 0.7786%\n",
      "Epoch [16/300], Step [37/225], Training Accuracy: 64.8226%, Training Loss: 0.7777%\n",
      "Epoch [16/300], Step [38/225], Training Accuracy: 64.8849%, Training Loss: 0.7788%\n",
      "Epoch [16/300], Step [39/225], Training Accuracy: 64.9038%, Training Loss: 0.7786%\n",
      "Epoch [16/300], Step [40/225], Training Accuracy: 64.8438%, Training Loss: 0.7799%\n",
      "Epoch [16/300], Step [41/225], Training Accuracy: 64.6341%, Training Loss: 0.7826%\n",
      "Epoch [16/300], Step [42/225], Training Accuracy: 64.4717%, Training Loss: 0.7851%\n",
      "Epoch [16/300], Step [43/225], Training Accuracy: 64.6076%, Training Loss: 0.7828%\n",
      "Epoch [16/300], Step [44/225], Training Accuracy: 64.8438%, Training Loss: 0.7792%\n",
      "Epoch [16/300], Step [45/225], Training Accuracy: 64.8264%, Training Loss: 0.7787%\n",
      "Epoch [16/300], Step [46/225], Training Accuracy: 65.0136%, Training Loss: 0.7748%\n",
      "Epoch [16/300], Step [47/225], Training Accuracy: 64.9601%, Training Loss: 0.7767%\n",
      "Epoch [16/300], Step [48/225], Training Accuracy: 64.6159%, Training Loss: 0.7810%\n",
      "Epoch [16/300], Step [49/225], Training Accuracy: 64.9235%, Training Loss: 0.7781%\n",
      "Epoch [16/300], Step [50/225], Training Accuracy: 64.8750%, Training Loss: 0.7770%\n",
      "Epoch [16/300], Step [51/225], Training Accuracy: 65.0735%, Training Loss: 0.7731%\n",
      "Epoch [16/300], Step [52/225], Training Accuracy: 65.3245%, Training Loss: 0.7696%\n",
      "Epoch [16/300], Step [53/225], Training Accuracy: 65.3007%, Training Loss: 0.7693%\n",
      "Epoch [16/300], Step [54/225], Training Accuracy: 65.2199%, Training Loss: 0.7698%\n",
      "Epoch [16/300], Step [55/225], Training Accuracy: 65.1705%, Training Loss: 0.7720%\n",
      "Epoch [16/300], Step [56/225], Training Accuracy: 65.0670%, Training Loss: 0.7732%\n",
      "Epoch [16/300], Step [57/225], Training Accuracy: 65.1590%, Training Loss: 0.7704%\n",
      "Epoch [16/300], Step [58/225], Training Accuracy: 65.0593%, Training Loss: 0.7719%\n",
      "Epoch [16/300], Step [59/225], Training Accuracy: 65.1748%, Training Loss: 0.7708%\n",
      "Epoch [16/300], Step [60/225], Training Accuracy: 65.2344%, Training Loss: 0.7689%\n",
      "Epoch [16/300], Step [61/225], Training Accuracy: 65.0359%, Training Loss: 0.7713%\n",
      "Epoch [16/300], Step [62/225], Training Accuracy: 65.0958%, Training Loss: 0.7703%\n",
      "Epoch [16/300], Step [63/225], Training Accuracy: 65.1290%, Training Loss: 0.7693%\n",
      "Epoch [16/300], Step [64/225], Training Accuracy: 65.0879%, Training Loss: 0.7696%\n",
      "Epoch [16/300], Step [65/225], Training Accuracy: 65.1202%, Training Loss: 0.7698%\n",
      "Epoch [16/300], Step [66/225], Training Accuracy: 65.1752%, Training Loss: 0.7686%\n",
      "Epoch [16/300], Step [67/225], Training Accuracy: 65.2752%, Training Loss: 0.7682%\n",
      "Epoch [16/300], Step [68/225], Training Accuracy: 65.1425%, Training Loss: 0.7689%\n",
      "Epoch [16/300], Step [69/225], Training Accuracy: 65.0136%, Training Loss: 0.7698%\n",
      "Epoch [16/300], Step [70/225], Training Accuracy: 64.9777%, Training Loss: 0.7701%\n",
      "Epoch [16/300], Step [71/225], Training Accuracy: 65.0748%, Training Loss: 0.7683%\n",
      "Epoch [16/300], Step [72/225], Training Accuracy: 64.9957%, Training Loss: 0.7690%\n",
      "Epoch [16/300], Step [73/225], Training Accuracy: 64.9187%, Training Loss: 0.7687%\n",
      "Epoch [16/300], Step [74/225], Training Accuracy: 64.9282%, Training Loss: 0.7666%\n",
      "Epoch [16/300], Step [75/225], Training Accuracy: 64.8750%, Training Loss: 0.7674%\n",
      "Epoch [16/300], Step [76/225], Training Accuracy: 64.7204%, Training Loss: 0.7687%\n",
      "Epoch [16/300], Step [77/225], Training Accuracy: 64.7524%, Training Loss: 0.7691%\n",
      "Epoch [16/300], Step [78/225], Training Accuracy: 64.8037%, Training Loss: 0.7682%\n",
      "Epoch [16/300], Step [79/225], Training Accuracy: 64.8141%, Training Loss: 0.7679%\n",
      "Epoch [16/300], Step [80/225], Training Accuracy: 64.8242%, Training Loss: 0.7670%\n",
      "Epoch [16/300], Step [81/225], Training Accuracy: 64.8148%, Training Loss: 0.7663%\n",
      "Epoch [16/300], Step [82/225], Training Accuracy: 64.8628%, Training Loss: 0.7665%\n",
      "Epoch [16/300], Step [83/225], Training Accuracy: 64.8343%, Training Loss: 0.7665%\n",
      "Epoch [16/300], Step [84/225], Training Accuracy: 64.8438%, Training Loss: 0.7663%\n",
      "Epoch [16/300], Step [85/225], Training Accuracy: 64.9265%, Training Loss: 0.7639%\n",
      "Epoch [16/300], Step [86/225], Training Accuracy: 65.0254%, Training Loss: 0.7629%\n",
      "Epoch [16/300], Step [87/225], Training Accuracy: 64.9605%, Training Loss: 0.7642%\n",
      "Epoch [16/300], Step [88/225], Training Accuracy: 64.9858%, Training Loss: 0.7644%\n",
      "Epoch [16/300], Step [89/225], Training Accuracy: 64.8350%, Training Loss: 0.7669%\n",
      "Epoch [16/300], Step [90/225], Training Accuracy: 64.8438%, Training Loss: 0.7676%\n",
      "Epoch [16/300], Step [91/225], Training Accuracy: 64.8523%, Training Loss: 0.7673%\n",
      "Epoch [16/300], Step [92/225], Training Accuracy: 64.8268%, Training Loss: 0.7692%\n",
      "Epoch [16/300], Step [93/225], Training Accuracy: 64.8185%, Training Loss: 0.7701%\n",
      "Epoch [16/300], Step [94/225], Training Accuracy: 64.8604%, Training Loss: 0.7684%\n",
      "Epoch [16/300], Step [95/225], Training Accuracy: 64.7533%, Training Loss: 0.7693%\n",
      "Epoch [16/300], Step [96/225], Training Accuracy: 64.9251%, Training Loss: 0.7676%\n",
      "Epoch [16/300], Step [97/225], Training Accuracy: 64.9323%, Training Loss: 0.7675%\n",
      "Epoch [16/300], Step [98/225], Training Accuracy: 64.9554%, Training Loss: 0.7671%\n",
      "Epoch [16/300], Step [99/225], Training Accuracy: 64.9621%, Training Loss: 0.7671%\n",
      "Epoch [16/300], Step [100/225], Training Accuracy: 64.8906%, Training Loss: 0.7687%\n",
      "Epoch [16/300], Step [101/225], Training Accuracy: 64.9288%, Training Loss: 0.7682%\n",
      "Epoch [16/300], Step [102/225], Training Accuracy: 64.8591%, Training Loss: 0.7686%\n",
      "Epoch [16/300], Step [103/225], Training Accuracy: 64.9272%, Training Loss: 0.7683%\n",
      "Epoch [16/300], Step [104/225], Training Accuracy: 64.8888%, Training Loss: 0.7691%\n",
      "Epoch [16/300], Step [105/225], Training Accuracy: 64.9554%, Training Loss: 0.7682%\n",
      "Epoch [16/300], Step [106/225], Training Accuracy: 65.0354%, Training Loss: 0.7673%\n",
      "Epoch [16/300], Step [107/225], Training Accuracy: 64.9825%, Training Loss: 0.7689%\n",
      "Epoch [16/300], Step [108/225], Training Accuracy: 65.0608%, Training Loss: 0.7683%\n",
      "Epoch [16/300], Step [109/225], Training Accuracy: 64.9513%, Training Loss: 0.7688%\n",
      "Epoch [16/300], Step [110/225], Training Accuracy: 64.9574%, Training Loss: 0.7687%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/300], Step [111/225], Training Accuracy: 64.8930%, Training Loss: 0.7691%\n",
      "Epoch [16/300], Step [112/225], Training Accuracy: 64.9554%, Training Loss: 0.7683%\n",
      "Epoch [16/300], Step [113/225], Training Accuracy: 64.9475%, Training Loss: 0.7684%\n",
      "Epoch [16/300], Step [114/225], Training Accuracy: 64.8986%, Training Loss: 0.7684%\n",
      "Epoch [16/300], Step [115/225], Training Accuracy: 65.0136%, Training Loss: 0.7671%\n",
      "Epoch [16/300], Step [116/225], Training Accuracy: 65.0323%, Training Loss: 0.7668%\n",
      "Epoch [16/300], Step [117/225], Training Accuracy: 64.9038%, Training Loss: 0.7697%\n",
      "Epoch [16/300], Step [118/225], Training Accuracy: 64.9364%, Training Loss: 0.7685%\n",
      "Epoch [16/300], Step [119/225], Training Accuracy: 64.9422%, Training Loss: 0.7681%\n",
      "Epoch [16/300], Step [120/225], Training Accuracy: 64.9349%, Training Loss: 0.7684%\n",
      "Epoch [16/300], Step [121/225], Training Accuracy: 64.8760%, Training Loss: 0.7686%\n",
      "Epoch [16/300], Step [122/225], Training Accuracy: 64.8181%, Training Loss: 0.7690%\n",
      "Epoch [16/300], Step [123/225], Training Accuracy: 64.8755%, Training Loss: 0.7682%\n",
      "Epoch [16/300], Step [124/225], Training Accuracy: 64.8564%, Training Loss: 0.7679%\n",
      "Epoch [16/300], Step [125/225], Training Accuracy: 64.8500%, Training Loss: 0.7689%\n",
      "Epoch [16/300], Step [126/225], Training Accuracy: 64.9182%, Training Loss: 0.7678%\n",
      "Epoch [16/300], Step [127/225], Training Accuracy: 64.8745%, Training Loss: 0.7685%\n",
      "Epoch [16/300], Step [128/225], Training Accuracy: 64.8193%, Training Loss: 0.7690%\n",
      "Epoch [16/300], Step [129/225], Training Accuracy: 64.8014%, Training Loss: 0.7686%\n",
      "Epoch [16/300], Step [130/225], Training Accuracy: 64.8317%, Training Loss: 0.7687%\n",
      "Epoch [16/300], Step [131/225], Training Accuracy: 64.8378%, Training Loss: 0.7688%\n",
      "Epoch [16/300], Step [132/225], Training Accuracy: 64.8201%, Training Loss: 0.7692%\n",
      "Epoch [16/300], Step [133/225], Training Accuracy: 64.9201%, Training Loss: 0.7677%\n",
      "Epoch [16/300], Step [134/225], Training Accuracy: 64.8088%, Training Loss: 0.7688%\n",
      "Epoch [16/300], Step [135/225], Training Accuracy: 64.8264%, Training Loss: 0.7682%\n",
      "Epoch [16/300], Step [136/225], Training Accuracy: 64.8552%, Training Loss: 0.7674%\n",
      "Epoch [16/300], Step [137/225], Training Accuracy: 64.8380%, Training Loss: 0.7671%\n",
      "Epoch [16/300], Step [138/225], Training Accuracy: 64.9230%, Training Loss: 0.7661%\n",
      "Epoch [16/300], Step [139/225], Training Accuracy: 64.8719%, Training Loss: 0.7677%\n",
      "Epoch [16/300], Step [140/225], Training Accuracy: 64.8772%, Training Loss: 0.7674%\n",
      "Epoch [16/300], Step [141/225], Training Accuracy: 64.9047%, Training Loss: 0.7670%\n",
      "Epoch [16/300], Step [142/225], Training Accuracy: 64.8438%, Training Loss: 0.7673%\n",
      "Epoch [16/300], Step [143/225], Training Accuracy: 64.8274%, Training Loss: 0.7674%\n",
      "Epoch [16/300], Step [144/225], Training Accuracy: 64.8438%, Training Loss: 0.7669%\n",
      "Epoch [16/300], Step [145/225], Training Accuracy: 64.8707%, Training Loss: 0.7668%\n",
      "Epoch [16/300], Step [146/225], Training Accuracy: 64.8652%, Training Loss: 0.7670%\n",
      "Epoch [16/300], Step [147/225], Training Accuracy: 64.8278%, Training Loss: 0.7668%\n",
      "Epoch [16/300], Step [148/225], Training Accuracy: 64.8965%, Training Loss: 0.7661%\n",
      "Epoch [16/300], Step [149/225], Training Accuracy: 64.8805%, Training Loss: 0.7663%\n",
      "Epoch [16/300], Step [150/225], Training Accuracy: 64.9375%, Training Loss: 0.7655%\n",
      "Epoch [16/300], Step [151/225], Training Accuracy: 64.9938%, Training Loss: 0.7645%\n",
      "Epoch [16/300], Step [152/225], Training Accuracy: 65.0493%, Training Loss: 0.7642%\n",
      "Epoch [16/300], Step [153/225], Training Accuracy: 65.0940%, Training Loss: 0.7638%\n",
      "Epoch [16/300], Step [154/225], Training Accuracy: 65.0771%, Training Loss: 0.7639%\n",
      "Epoch [16/300], Step [155/225], Training Accuracy: 65.0605%, Training Loss: 0.7638%\n",
      "Epoch [16/300], Step [156/225], Training Accuracy: 65.0240%, Training Loss: 0.7647%\n",
      "Epoch [16/300], Step [157/225], Training Accuracy: 65.0179%, Training Loss: 0.7646%\n",
      "Epoch [16/300], Step [158/225], Training Accuracy: 64.9031%, Training Loss: 0.7657%\n",
      "Epoch [16/300], Step [159/225], Training Accuracy: 64.8683%, Training Loss: 0.7659%\n",
      "Epoch [16/300], Step [160/225], Training Accuracy: 64.8535%, Training Loss: 0.7665%\n",
      "Epoch [16/300], Step [161/225], Training Accuracy: 64.8777%, Training Loss: 0.7661%\n",
      "Epoch [16/300], Step [162/225], Training Accuracy: 64.9113%, Training Loss: 0.7658%\n",
      "Epoch [16/300], Step [163/225], Training Accuracy: 64.8773%, Training Loss: 0.7657%\n",
      "Epoch [16/300], Step [164/225], Training Accuracy: 64.9295%, Training Loss: 0.7647%\n",
      "Epoch [16/300], Step [165/225], Training Accuracy: 64.9621%, Training Loss: 0.7644%\n",
      "Epoch [16/300], Step [166/225], Training Accuracy: 64.9755%, Training Loss: 0.7641%\n",
      "Epoch [16/300], Step [167/225], Training Accuracy: 64.9981%, Training Loss: 0.7634%\n",
      "Epoch [16/300], Step [168/225], Training Accuracy: 65.0205%, Training Loss: 0.7630%\n",
      "Epoch [16/300], Step [169/225], Training Accuracy: 65.0795%, Training Loss: 0.7622%\n",
      "Epoch [16/300], Step [170/225], Training Accuracy: 65.0827%, Training Loss: 0.7615%\n",
      "Epoch [16/300], Step [171/225], Training Accuracy: 65.1590%, Training Loss: 0.7608%\n",
      "Epoch [16/300], Step [172/225], Training Accuracy: 65.1980%, Training Loss: 0.7602%\n",
      "Epoch [16/300], Step [173/225], Training Accuracy: 65.1824%, Training Loss: 0.7606%\n",
      "Epoch [16/300], Step [174/225], Training Accuracy: 65.2478%, Training Loss: 0.7597%\n",
      "Epoch [16/300], Step [175/225], Training Accuracy: 65.3393%, Training Loss: 0.7586%\n",
      "Epoch [16/300], Step [176/225], Training Accuracy: 65.3054%, Training Loss: 0.7588%\n",
      "Epoch [16/300], Step [177/225], Training Accuracy: 65.3337%, Training Loss: 0.7585%\n",
      "Epoch [16/300], Step [178/225], Training Accuracy: 65.3529%, Training Loss: 0.7580%\n",
      "Epoch [16/300], Step [179/225], Training Accuracy: 65.3980%, Training Loss: 0.7568%\n",
      "Epoch [16/300], Step [180/225], Training Accuracy: 65.4601%, Training Loss: 0.7563%\n",
      "Epoch [16/300], Step [181/225], Training Accuracy: 65.5041%, Training Loss: 0.7561%\n",
      "Epoch [16/300], Step [182/225], Training Accuracy: 65.4876%, Training Loss: 0.7563%\n",
      "Epoch [16/300], Step [183/225], Training Accuracy: 65.4969%, Training Loss: 0.7560%\n",
      "Epoch [16/300], Step [184/225], Training Accuracy: 65.4976%, Training Loss: 0.7559%\n",
      "Epoch [16/300], Step [185/225], Training Accuracy: 65.5490%, Training Loss: 0.7556%\n",
      "Epoch [16/300], Step [186/225], Training Accuracy: 65.6082%, Training Loss: 0.7544%\n",
      "Epoch [16/300], Step [187/225], Training Accuracy: 65.6166%, Training Loss: 0.7539%\n",
      "Epoch [16/300], Step [188/225], Training Accuracy: 65.6333%, Training Loss: 0.7535%\n",
      "Epoch [16/300], Step [189/225], Training Accuracy: 65.6415%, Training Loss: 0.7528%\n",
      "Epoch [16/300], Step [190/225], Training Accuracy: 65.6826%, Training Loss: 0.7524%\n",
      "Epoch [16/300], Step [191/225], Training Accuracy: 65.6823%, Training Loss: 0.7520%\n",
      "Epoch [16/300], Step [192/225], Training Accuracy: 65.7145%, Training Loss: 0.7512%\n",
      "Epoch [16/300], Step [193/225], Training Accuracy: 65.7060%, Training Loss: 0.7518%\n",
      "Epoch [16/300], Step [194/225], Training Accuracy: 65.6975%, Training Loss: 0.7528%\n",
      "Epoch [16/300], Step [195/225], Training Accuracy: 65.7292%, Training Loss: 0.7525%\n",
      "Epoch [16/300], Step [196/225], Training Accuracy: 65.7366%, Training Loss: 0.7530%\n",
      "Epoch [16/300], Step [197/225], Training Accuracy: 65.7122%, Training Loss: 0.7541%\n",
      "Epoch [16/300], Step [198/225], Training Accuracy: 65.7513%, Training Loss: 0.7531%\n",
      "Epoch [16/300], Step [199/225], Training Accuracy: 65.7742%, Training Loss: 0.7527%\n",
      "Epoch [16/300], Step [200/225], Training Accuracy: 65.7422%, Training Loss: 0.7531%\n",
      "Epoch [16/300], Step [201/225], Training Accuracy: 65.7261%, Training Loss: 0.7535%\n",
      "Epoch [16/300], Step [202/225], Training Accuracy: 65.7256%, Training Loss: 0.7537%\n",
      "Epoch [16/300], Step [203/225], Training Accuracy: 65.7558%, Training Loss: 0.7533%\n",
      "Epoch [16/300], Step [204/225], Training Accuracy: 65.7246%, Training Loss: 0.7544%\n",
      "Epoch [16/300], Step [205/225], Training Accuracy: 65.7698%, Training Loss: 0.7540%\n",
      "Epoch [16/300], Step [206/225], Training Accuracy: 65.7615%, Training Loss: 0.7550%\n",
      "Epoch [16/300], Step [207/225], Training Accuracy: 65.7835%, Training Loss: 0.7551%\n",
      "Epoch [16/300], Step [208/225], Training Accuracy: 65.7903%, Training Loss: 0.7546%\n",
      "Epoch [16/300], Step [209/225], Training Accuracy: 65.8044%, Training Loss: 0.7547%\n",
      "Epoch [16/300], Step [210/225], Training Accuracy: 65.7440%, Training Loss: 0.7551%\n",
      "Epoch [16/300], Step [211/225], Training Accuracy: 65.7361%, Training Loss: 0.7548%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/300], Step [212/225], Training Accuracy: 65.7282%, Training Loss: 0.7552%\n",
      "Epoch [16/300], Step [213/225], Training Accuracy: 65.6910%, Training Loss: 0.7568%\n",
      "Epoch [16/300], Step [214/225], Training Accuracy: 65.7126%, Training Loss: 0.7565%\n",
      "Epoch [16/300], Step [215/225], Training Accuracy: 65.6686%, Training Loss: 0.7583%\n",
      "Epoch [16/300], Step [216/225], Training Accuracy: 65.6467%, Training Loss: 0.7583%\n",
      "Epoch [16/300], Step [217/225], Training Accuracy: 65.6394%, Training Loss: 0.7585%\n",
      "Epoch [16/300], Step [218/225], Training Accuracy: 65.6035%, Training Loss: 0.7588%\n",
      "Epoch [16/300], Step [219/225], Training Accuracy: 65.6036%, Training Loss: 0.7592%\n",
      "Epoch [16/300], Step [220/225], Training Accuracy: 65.6250%, Training Loss: 0.7589%\n",
      "Epoch [16/300], Step [221/225], Training Accuracy: 65.6391%, Training Loss: 0.7590%\n",
      "Epoch [16/300], Step [222/225], Training Accuracy: 65.6180%, Training Loss: 0.7589%\n",
      "Epoch [16/300], Step [223/225], Training Accuracy: 65.6250%, Training Loss: 0.7593%\n",
      "Epoch [16/300], Step [224/225], Training Accuracy: 65.5971%, Training Loss: 0.7596%\n",
      "Epoch [16/300], Step [225/225], Training Accuracy: 65.5989%, Training Loss: 0.7598%\n",
      "Epoch [17/300], Step [1/225], Training Accuracy: 73.4375%, Training Loss: 0.6493%\n",
      "Epoch [17/300], Step [2/225], Training Accuracy: 71.8750%, Training Loss: 0.7216%\n",
      "Epoch [17/300], Step [3/225], Training Accuracy: 70.3125%, Training Loss: 0.7360%\n",
      "Epoch [17/300], Step [4/225], Training Accuracy: 65.6250%, Training Loss: 0.7897%\n",
      "Epoch [17/300], Step [5/225], Training Accuracy: 66.2500%, Training Loss: 0.7784%\n",
      "Epoch [17/300], Step [6/225], Training Accuracy: 66.6667%, Training Loss: 0.7591%\n",
      "Epoch [17/300], Step [7/225], Training Accuracy: 67.6339%, Training Loss: 0.7467%\n",
      "Epoch [17/300], Step [8/225], Training Accuracy: 68.3594%, Training Loss: 0.7495%\n",
      "Epoch [17/300], Step [9/225], Training Accuracy: 67.8819%, Training Loss: 0.7561%\n",
      "Epoch [17/300], Step [10/225], Training Accuracy: 66.8750%, Training Loss: 0.7687%\n",
      "Epoch [17/300], Step [11/225], Training Accuracy: 66.9034%, Training Loss: 0.7707%\n",
      "Epoch [17/300], Step [12/225], Training Accuracy: 66.7969%, Training Loss: 0.7653%\n",
      "Epoch [17/300], Step [13/225], Training Accuracy: 67.3077%, Training Loss: 0.7462%\n",
      "Epoch [17/300], Step [14/225], Training Accuracy: 68.0804%, Training Loss: 0.7338%\n",
      "Epoch [17/300], Step [15/225], Training Accuracy: 67.6042%, Training Loss: 0.7379%\n",
      "Epoch [17/300], Step [16/225], Training Accuracy: 67.3828%, Training Loss: 0.7369%\n",
      "Epoch [17/300], Step [17/225], Training Accuracy: 67.1875%, Training Loss: 0.7344%\n",
      "Epoch [17/300], Step [18/225], Training Accuracy: 67.6215%, Training Loss: 0.7294%\n",
      "Epoch [17/300], Step [19/225], Training Accuracy: 67.5164%, Training Loss: 0.7253%\n",
      "Epoch [17/300], Step [20/225], Training Accuracy: 67.6562%, Training Loss: 0.7196%\n",
      "Epoch [17/300], Step [21/225], Training Accuracy: 67.5595%, Training Loss: 0.7183%\n",
      "Epoch [17/300], Step [22/225], Training Accuracy: 67.1165%, Training Loss: 0.7251%\n",
      "Epoch [17/300], Step [23/225], Training Accuracy: 66.7120%, Training Loss: 0.7249%\n",
      "Epoch [17/300], Step [24/225], Training Accuracy: 66.4714%, Training Loss: 0.7293%\n",
      "Epoch [17/300], Step [25/225], Training Accuracy: 66.6250%, Training Loss: 0.7318%\n",
      "Epoch [17/300], Step [26/225], Training Accuracy: 66.7668%, Training Loss: 0.7343%\n",
      "Epoch [17/300], Step [27/225], Training Accuracy: 66.8403%, Training Loss: 0.7353%\n",
      "Epoch [17/300], Step [28/225], Training Accuracy: 66.9085%, Training Loss: 0.7319%\n",
      "Epoch [17/300], Step [29/225], Training Accuracy: 66.9181%, Training Loss: 0.7328%\n",
      "Epoch [17/300], Step [30/225], Training Accuracy: 66.9271%, Training Loss: 0.7311%\n",
      "Epoch [17/300], Step [31/225], Training Accuracy: 66.8347%, Training Loss: 0.7400%\n",
      "Epoch [17/300], Step [32/225], Training Accuracy: 66.7480%, Training Loss: 0.7425%\n",
      "Epoch [17/300], Step [33/225], Training Accuracy: 66.8561%, Training Loss: 0.7417%\n",
      "Epoch [17/300], Step [34/225], Training Accuracy: 66.5441%, Training Loss: 0.7474%\n",
      "Epoch [17/300], Step [35/225], Training Accuracy: 66.3393%, Training Loss: 0.7492%\n",
      "Epoch [17/300], Step [36/225], Training Accuracy: 66.2760%, Training Loss: 0.7497%\n",
      "Epoch [17/300], Step [37/225], Training Accuracy: 66.1318%, Training Loss: 0.7520%\n",
      "Epoch [17/300], Step [38/225], Training Accuracy: 66.3240%, Training Loss: 0.7491%\n",
      "Epoch [17/300], Step [39/225], Training Accuracy: 66.1458%, Training Loss: 0.7520%\n",
      "Epoch [17/300], Step [40/225], Training Accuracy: 65.9766%, Training Loss: 0.7526%\n",
      "Epoch [17/300], Step [41/225], Training Accuracy: 65.7012%, Training Loss: 0.7555%\n",
      "Epoch [17/300], Step [42/225], Training Accuracy: 65.5134%, Training Loss: 0.7551%\n",
      "Epoch [17/300], Step [43/225], Training Accuracy: 65.4070%, Training Loss: 0.7548%\n",
      "Epoch [17/300], Step [44/225], Training Accuracy: 65.4830%, Training Loss: 0.7522%\n",
      "Epoch [17/300], Step [45/225], Training Accuracy: 65.4861%, Training Loss: 0.7520%\n",
      "Epoch [17/300], Step [46/225], Training Accuracy: 65.6590%, Training Loss: 0.7479%\n",
      "Epoch [17/300], Step [47/225], Training Accuracy: 65.5918%, Training Loss: 0.7496%\n",
      "Epoch [17/300], Step [48/225], Training Accuracy: 65.3646%, Training Loss: 0.7523%\n",
      "Epoch [17/300], Step [49/225], Training Accuracy: 65.4656%, Training Loss: 0.7509%\n",
      "Epoch [17/300], Step [50/225], Training Accuracy: 65.4688%, Training Loss: 0.7490%\n",
      "Epoch [17/300], Step [51/225], Training Accuracy: 65.6863%, Training Loss: 0.7471%\n",
      "Epoch [17/300], Step [52/225], Training Accuracy: 66.0156%, Training Loss: 0.7444%\n",
      "Epoch [17/300], Step [53/225], Training Accuracy: 66.0083%, Training Loss: 0.7438%\n",
      "Epoch [17/300], Step [54/225], Training Accuracy: 65.9433%, Training Loss: 0.7456%\n",
      "Epoch [17/300], Step [55/225], Training Accuracy: 65.9375%, Training Loss: 0.7482%\n",
      "Epoch [17/300], Step [56/225], Training Accuracy: 65.9598%, Training Loss: 0.7463%\n",
      "Epoch [17/300], Step [57/225], Training Accuracy: 65.9539%, Training Loss: 0.7459%\n",
      "Epoch [17/300], Step [58/225], Training Accuracy: 65.9213%, Training Loss: 0.7479%\n",
      "Epoch [17/300], Step [59/225], Training Accuracy: 65.8104%, Training Loss: 0.7492%\n",
      "Epoch [17/300], Step [60/225], Training Accuracy: 65.7812%, Training Loss: 0.7495%\n",
      "Epoch [17/300], Step [61/225], Training Accuracy: 65.8299%, Training Loss: 0.7487%\n",
      "Epoch [17/300], Step [62/225], Training Accuracy: 65.8518%, Training Loss: 0.7503%\n",
      "Epoch [17/300], Step [63/225], Training Accuracy: 65.8482%, Training Loss: 0.7529%\n",
      "Epoch [17/300], Step [64/225], Training Accuracy: 65.8691%, Training Loss: 0.7541%\n",
      "Epoch [17/300], Step [65/225], Training Accuracy: 65.7933%, Training Loss: 0.7558%\n",
      "Epoch [17/300], Step [66/225], Training Accuracy: 65.9801%, Training Loss: 0.7538%\n",
      "Epoch [17/300], Step [67/225], Training Accuracy: 65.9748%, Training Loss: 0.7538%\n",
      "Epoch [17/300], Step [68/225], Training Accuracy: 65.8318%, Training Loss: 0.7566%\n",
      "Epoch [17/300], Step [69/225], Training Accuracy: 65.8967%, Training Loss: 0.7560%\n",
      "Epoch [17/300], Step [70/225], Training Accuracy: 65.9152%, Training Loss: 0.7553%\n",
      "Epoch [17/300], Step [71/225], Training Accuracy: 65.9771%, Training Loss: 0.7533%\n",
      "Epoch [17/300], Step [72/225], Training Accuracy: 65.8854%, Training Loss: 0.7543%\n",
      "Epoch [17/300], Step [73/225], Training Accuracy: 65.8176%, Training Loss: 0.7536%\n",
      "Epoch [17/300], Step [74/225], Training Accuracy: 65.9628%, Training Loss: 0.7512%\n",
      "Epoch [17/300], Step [75/225], Training Accuracy: 65.8750%, Training Loss: 0.7520%\n",
      "Epoch [17/300], Step [76/225], Training Accuracy: 65.7895%, Training Loss: 0.7531%\n",
      "Epoch [17/300], Step [77/225], Training Accuracy: 65.8076%, Training Loss: 0.7533%\n",
      "Epoch [17/300], Step [78/225], Training Accuracy: 65.8253%, Training Loss: 0.7528%\n",
      "Epoch [17/300], Step [79/225], Training Accuracy: 65.7634%, Training Loss: 0.7530%\n",
      "Epoch [17/300], Step [80/225], Training Accuracy: 65.6836%, Training Loss: 0.7533%\n",
      "Epoch [17/300], Step [81/225], Training Accuracy: 65.7215%, Training Loss: 0.7517%\n",
      "Epoch [17/300], Step [82/225], Training Accuracy: 65.7965%, Training Loss: 0.7500%\n",
      "Epoch [17/300], Step [83/225], Training Accuracy: 65.7003%, Training Loss: 0.7528%\n",
      "Epoch [17/300], Step [84/225], Training Accuracy: 65.8110%, Training Loss: 0.7505%\n",
      "Epoch [17/300], Step [85/225], Training Accuracy: 65.8640%, Training Loss: 0.7493%\n",
      "Epoch [17/300], Step [86/225], Training Accuracy: 65.9339%, Training Loss: 0.7488%\n",
      "Epoch [17/300], Step [87/225], Training Accuracy: 65.9124%, Training Loss: 0.7494%\n",
      "Epoch [17/300], Step [88/225], Training Accuracy: 65.8558%, Training Loss: 0.7501%\n",
      "Epoch [17/300], Step [89/225], Training Accuracy: 65.8181%, Training Loss: 0.7512%\n",
      "Epoch [17/300], Step [90/225], Training Accuracy: 65.7812%, Training Loss: 0.7528%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/300], Step [91/225], Training Accuracy: 65.7624%, Training Loss: 0.7519%\n",
      "Epoch [17/300], Step [92/225], Training Accuracy: 65.7269%, Training Loss: 0.7520%\n",
      "Epoch [17/300], Step [93/225], Training Accuracy: 65.7426%, Training Loss: 0.7517%\n",
      "Epoch [17/300], Step [94/225], Training Accuracy: 65.8910%, Training Loss: 0.7492%\n",
      "Epoch [17/300], Step [95/225], Training Accuracy: 65.9211%, Training Loss: 0.7492%\n",
      "Epoch [17/300], Step [96/225], Training Accuracy: 66.0807%, Training Loss: 0.7473%\n",
      "Epoch [17/300], Step [97/225], Training Accuracy: 66.0921%, Training Loss: 0.7480%\n",
      "Epoch [17/300], Step [98/225], Training Accuracy: 66.0714%, Training Loss: 0.7483%\n",
      "Epoch [17/300], Step [99/225], Training Accuracy: 66.0196%, Training Loss: 0.7498%\n",
      "Epoch [17/300], Step [100/225], Training Accuracy: 65.9844%, Training Loss: 0.7501%\n",
      "Epoch [17/300], Step [101/225], Training Accuracy: 66.0427%, Training Loss: 0.7500%\n",
      "Epoch [17/300], Step [102/225], Training Accuracy: 65.9926%, Training Loss: 0.7499%\n",
      "Epoch [17/300], Step [103/225], Training Accuracy: 66.0649%, Training Loss: 0.7499%\n",
      "Epoch [17/300], Step [104/225], Training Accuracy: 66.0757%, Training Loss: 0.7497%\n",
      "Epoch [17/300], Step [105/225], Training Accuracy: 66.0565%, Training Loss: 0.7488%\n",
      "Epoch [17/300], Step [106/225], Training Accuracy: 66.0525%, Training Loss: 0.7482%\n",
      "Epoch [17/300], Step [107/225], Training Accuracy: 66.0047%, Training Loss: 0.7496%\n",
      "Epoch [17/300], Step [108/225], Training Accuracy: 66.0446%, Training Loss: 0.7487%\n",
      "Epoch [17/300], Step [109/225], Training Accuracy: 66.1124%, Training Loss: 0.7480%\n",
      "Epoch [17/300], Step [110/225], Training Accuracy: 66.1648%, Training Loss: 0.7478%\n",
      "Epoch [17/300], Step [111/225], Training Accuracy: 66.0755%, Training Loss: 0.7498%\n",
      "Epoch [17/300], Step [112/225], Training Accuracy: 66.1272%, Training Loss: 0.7492%\n",
      "Epoch [17/300], Step [113/225], Training Accuracy: 66.1643%, Training Loss: 0.7497%\n",
      "Epoch [17/300], Step [114/225], Training Accuracy: 66.2144%, Training Loss: 0.7484%\n",
      "Epoch [17/300], Step [115/225], Training Accuracy: 66.3179%, Training Loss: 0.7465%\n",
      "Epoch [17/300], Step [116/225], Training Accuracy: 66.3254%, Training Loss: 0.7471%\n",
      "Epoch [17/300], Step [117/225], Training Accuracy: 66.1592%, Training Loss: 0.7504%\n",
      "Epoch [17/300], Step [118/225], Training Accuracy: 66.1944%, Training Loss: 0.7491%\n",
      "Epoch [17/300], Step [119/225], Training Accuracy: 66.1502%, Training Loss: 0.7498%\n",
      "Epoch [17/300], Step [120/225], Training Accuracy: 66.1589%, Training Loss: 0.7495%\n",
      "Epoch [17/300], Step [121/225], Training Accuracy: 66.0770%, Training Loss: 0.7505%\n",
      "Epoch [17/300], Step [122/225], Training Accuracy: 66.0476%, Training Loss: 0.7507%\n",
      "Epoch [17/300], Step [123/225], Training Accuracy: 66.1077%, Training Loss: 0.7505%\n",
      "Epoch [17/300], Step [124/225], Training Accuracy: 66.1164%, Training Loss: 0.7504%\n",
      "Epoch [17/300], Step [125/225], Training Accuracy: 66.0875%, Training Loss: 0.7516%\n",
      "Epoch [17/300], Step [126/225], Training Accuracy: 66.0962%, Training Loss: 0.7516%\n",
      "Epoch [17/300], Step [127/225], Training Accuracy: 66.0925%, Training Loss: 0.7516%\n",
      "Epoch [17/300], Step [128/225], Training Accuracy: 66.0889%, Training Loss: 0.7519%\n",
      "Epoch [17/300], Step [129/225], Training Accuracy: 66.1579%, Training Loss: 0.7512%\n",
      "Epoch [17/300], Step [130/225], Training Accuracy: 66.1418%, Training Loss: 0.7516%\n",
      "Epoch [17/300], Step [131/225], Training Accuracy: 66.1260%, Training Loss: 0.7521%\n",
      "Epoch [17/300], Step [132/225], Training Accuracy: 66.1577%, Training Loss: 0.7520%\n",
      "Epoch [17/300], Step [133/225], Training Accuracy: 66.2477%, Training Loss: 0.7511%\n",
      "Epoch [17/300], Step [134/225], Training Accuracy: 66.1964%, Training Loss: 0.7518%\n",
      "Epoch [17/300], Step [135/225], Training Accuracy: 66.2500%, Training Loss: 0.7514%\n",
      "Epoch [17/300], Step [136/225], Training Accuracy: 66.2684%, Training Loss: 0.7509%\n",
      "Epoch [17/300], Step [137/225], Training Accuracy: 66.2865%, Training Loss: 0.7507%\n",
      "Epoch [17/300], Step [138/225], Training Accuracy: 66.3836%, Training Loss: 0.7489%\n",
      "Epoch [17/300], Step [139/225], Training Accuracy: 66.3219%, Training Loss: 0.7516%\n",
      "Epoch [17/300], Step [140/225], Training Accuracy: 66.3393%, Training Loss: 0.7512%\n",
      "Epoch [17/300], Step [141/225], Training Accuracy: 66.3453%, Training Loss: 0.7503%\n",
      "Epoch [17/300], Step [142/225], Training Accuracy: 66.3072%, Training Loss: 0.7510%\n",
      "Epoch [17/300], Step [143/225], Training Accuracy: 66.2806%, Training Loss: 0.7518%\n",
      "Epoch [17/300], Step [144/225], Training Accuracy: 66.2218%, Training Loss: 0.7535%\n",
      "Epoch [17/300], Step [145/225], Training Accuracy: 66.2931%, Training Loss: 0.7528%\n",
      "Epoch [17/300], Step [146/225], Training Accuracy: 66.2671%, Training Loss: 0.7549%\n",
      "Epoch [17/300], Step [147/225], Training Accuracy: 66.2521%, Training Loss: 0.7551%\n",
      "Epoch [17/300], Step [148/225], Training Accuracy: 66.2901%, Training Loss: 0.7546%\n",
      "Epoch [17/300], Step [149/225], Training Accuracy: 66.2857%, Training Loss: 0.7546%\n",
      "Epoch [17/300], Step [150/225], Training Accuracy: 66.2812%, Training Loss: 0.7539%\n",
      "Epoch [17/300], Step [151/225], Training Accuracy: 66.3183%, Training Loss: 0.7526%\n",
      "Epoch [17/300], Step [152/225], Training Accuracy: 66.2726%, Training Loss: 0.7528%\n",
      "Epoch [17/300], Step [153/225], Training Accuracy: 66.2990%, Training Loss: 0.7526%\n",
      "Epoch [17/300], Step [154/225], Training Accuracy: 66.2541%, Training Loss: 0.7530%\n",
      "Epoch [17/300], Step [155/225], Training Accuracy: 66.2601%, Training Loss: 0.7537%\n",
      "Epoch [17/300], Step [156/225], Training Accuracy: 66.2560%, Training Loss: 0.7546%\n",
      "Epoch [17/300], Step [157/225], Training Accuracy: 66.2321%, Training Loss: 0.7552%\n",
      "Epoch [17/300], Step [158/225], Training Accuracy: 66.1392%, Training Loss: 0.7570%\n",
      "Epoch [17/300], Step [159/225], Training Accuracy: 66.1164%, Training Loss: 0.7567%\n",
      "Epoch [17/300], Step [160/225], Training Accuracy: 66.1035%, Training Loss: 0.7569%\n",
      "Epoch [17/300], Step [161/225], Training Accuracy: 66.1297%, Training Loss: 0.7563%\n",
      "Epoch [17/300], Step [162/225], Training Accuracy: 66.1555%, Training Loss: 0.7570%\n",
      "Epoch [17/300], Step [163/225], Training Accuracy: 66.1426%, Training Loss: 0.7571%\n",
      "Epoch [17/300], Step [164/225], Training Accuracy: 66.1776%, Training Loss: 0.7564%\n",
      "Epoch [17/300], Step [165/225], Training Accuracy: 66.1648%, Training Loss: 0.7560%\n",
      "Epoch [17/300], Step [166/225], Training Accuracy: 66.1615%, Training Loss: 0.7562%\n",
      "Epoch [17/300], Step [167/225], Training Accuracy: 66.1957%, Training Loss: 0.7554%\n",
      "Epoch [17/300], Step [168/225], Training Accuracy: 66.1644%, Training Loss: 0.7554%\n",
      "Epoch [17/300], Step [169/225], Training Accuracy: 66.1982%, Training Loss: 0.7544%\n",
      "Epoch [17/300], Step [170/225], Training Accuracy: 66.1765%, Training Loss: 0.7545%\n",
      "Epoch [17/300], Step [171/225], Training Accuracy: 66.1824%, Training Loss: 0.7542%\n",
      "Epoch [17/300], Step [172/225], Training Accuracy: 66.1428%, Training Loss: 0.7543%\n",
      "Epoch [17/300], Step [173/225], Training Accuracy: 66.0766%, Training Loss: 0.7554%\n",
      "Epoch [17/300], Step [174/225], Training Accuracy: 66.1279%, Training Loss: 0.7544%\n",
      "Epoch [17/300], Step [175/225], Training Accuracy: 66.1786%, Training Loss: 0.7536%\n",
      "Epoch [17/300], Step [176/225], Training Accuracy: 66.1665%, Training Loss: 0.7544%\n",
      "Epoch [17/300], Step [177/225], Training Accuracy: 66.1811%, Training Loss: 0.7548%\n",
      "Epoch [17/300], Step [178/225], Training Accuracy: 66.1692%, Training Loss: 0.7547%\n",
      "Epoch [17/300], Step [179/225], Training Accuracy: 66.2622%, Training Loss: 0.7536%\n",
      "Epoch [17/300], Step [180/225], Training Accuracy: 66.3194%, Training Loss: 0.7525%\n",
      "Epoch [17/300], Step [181/225], Training Accuracy: 66.2897%, Training Loss: 0.7528%\n",
      "Epoch [17/300], Step [182/225], Training Accuracy: 66.3118%, Training Loss: 0.7526%\n",
      "Epoch [17/300], Step [183/225], Training Accuracy: 66.3081%, Training Loss: 0.7529%\n",
      "Epoch [17/300], Step [184/225], Training Accuracy: 66.3298%, Training Loss: 0.7528%\n",
      "Epoch [17/300], Step [185/225], Training Accuracy: 66.3767%, Training Loss: 0.7524%\n",
      "Epoch [17/300], Step [186/225], Training Accuracy: 66.4231%, Training Loss: 0.7515%\n",
      "Epoch [17/300], Step [187/225], Training Accuracy: 66.4188%, Training Loss: 0.7511%\n",
      "Epoch [17/300], Step [188/225], Training Accuracy: 66.4312%, Training Loss: 0.7505%\n",
      "Epoch [17/300], Step [189/225], Training Accuracy: 66.4187%, Training Loss: 0.7498%\n",
      "Epoch [17/300], Step [190/225], Training Accuracy: 66.4885%, Training Loss: 0.7488%\n",
      "Epoch [17/300], Step [191/225], Training Accuracy: 66.4676%, Training Loss: 0.7488%\n",
      "Epoch [17/300], Step [192/225], Training Accuracy: 66.5283%, Training Loss: 0.7477%\n",
      "Epoch [17/300], Step [193/225], Training Accuracy: 66.5236%, Training Loss: 0.7481%\n",
      "Epoch [17/300], Step [194/225], Training Accuracy: 66.5271%, Training Loss: 0.7484%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/300], Step [195/225], Training Accuracy: 66.5705%, Training Loss: 0.7473%\n",
      "Epoch [17/300], Step [196/225], Training Accuracy: 66.5896%, Training Loss: 0.7471%\n",
      "Epoch [17/300], Step [197/225], Training Accuracy: 66.5530%, Training Loss: 0.7471%\n",
      "Epoch [17/300], Step [198/225], Training Accuracy: 66.6035%, Training Loss: 0.7458%\n",
      "Epoch [17/300], Step [199/225], Training Accuracy: 66.6457%, Training Loss: 0.7453%\n",
      "Epoch [17/300], Step [200/225], Training Accuracy: 66.6953%, Training Loss: 0.7449%\n",
      "Epoch [17/300], Step [201/225], Training Accuracy: 66.6822%, Training Loss: 0.7446%\n",
      "Epoch [17/300], Step [202/225], Training Accuracy: 66.6925%, Training Loss: 0.7451%\n",
      "Epoch [17/300], Step [203/225], Training Accuracy: 66.7411%, Training Loss: 0.7440%\n",
      "Epoch [17/300], Step [204/225], Training Accuracy: 66.7279%, Training Loss: 0.7440%\n",
      "Epoch [17/300], Step [205/225], Training Accuracy: 66.7530%, Training Loss: 0.7441%\n",
      "Epoch [17/300], Step [206/225], Training Accuracy: 66.7476%, Training Loss: 0.7441%\n",
      "Epoch [17/300], Step [207/225], Training Accuracy: 66.7497%, Training Loss: 0.7441%\n",
      "Epoch [17/300], Step [208/225], Training Accuracy: 66.7894%, Training Loss: 0.7435%\n",
      "Epoch [17/300], Step [209/225], Training Accuracy: 66.7688%, Training Loss: 0.7441%\n",
      "Epoch [17/300], Step [210/225], Training Accuracy: 66.7188%, Training Loss: 0.7444%\n",
      "Epoch [17/300], Step [211/225], Training Accuracy: 66.7654%, Training Loss: 0.7437%\n",
      "Epoch [17/300], Step [212/225], Training Accuracy: 66.7969%, Training Loss: 0.7435%\n",
      "Epoch [17/300], Step [213/225], Training Accuracy: 66.8281%, Training Loss: 0.7435%\n",
      "Epoch [17/300], Step [214/225], Training Accuracy: 66.8370%, Training Loss: 0.7435%\n",
      "Epoch [17/300], Step [215/225], Training Accuracy: 66.8532%, Training Loss: 0.7431%\n",
      "Epoch [17/300], Step [216/225], Training Accuracy: 66.8403%, Training Loss: 0.7431%\n",
      "Epoch [17/300], Step [217/225], Training Accuracy: 66.8491%, Training Loss: 0.7426%\n",
      "Epoch [17/300], Step [218/225], Training Accuracy: 66.8291%, Training Loss: 0.7428%\n",
      "Epoch [17/300], Step [219/225], Training Accuracy: 66.8165%, Training Loss: 0.7421%\n",
      "Epoch [17/300], Step [220/225], Training Accuracy: 66.8182%, Training Loss: 0.7418%\n",
      "Epoch [17/300], Step [221/225], Training Accuracy: 66.7986%, Training Loss: 0.7425%\n",
      "Epoch [17/300], Step [222/225], Training Accuracy: 66.8004%, Training Loss: 0.7422%\n",
      "Epoch [17/300], Step [223/225], Training Accuracy: 66.7531%, Training Loss: 0.7436%\n",
      "Epoch [17/300], Step [224/225], Training Accuracy: 66.7341%, Training Loss: 0.7441%\n",
      "Epoch [17/300], Step [225/225], Training Accuracy: 66.6759%, Training Loss: 0.7447%\n",
      "Epoch [18/300], Step [1/225], Training Accuracy: 73.4375%, Training Loss: 0.6279%\n",
      "Epoch [18/300], Step [2/225], Training Accuracy: 71.8750%, Training Loss: 0.7131%\n",
      "Epoch [18/300], Step [3/225], Training Accuracy: 70.8333%, Training Loss: 0.7360%\n",
      "Epoch [18/300], Step [4/225], Training Accuracy: 68.3594%, Training Loss: 0.7596%\n",
      "Epoch [18/300], Step [5/225], Training Accuracy: 67.8125%, Training Loss: 0.7626%\n",
      "Epoch [18/300], Step [6/225], Training Accuracy: 68.2292%, Training Loss: 0.7568%\n",
      "Epoch [18/300], Step [7/225], Training Accuracy: 67.1875%, Training Loss: 0.7779%\n",
      "Epoch [18/300], Step [8/225], Training Accuracy: 67.9688%, Training Loss: 0.7643%\n",
      "Epoch [18/300], Step [9/225], Training Accuracy: 66.8403%, Training Loss: 0.7717%\n",
      "Epoch [18/300], Step [10/225], Training Accuracy: 65.9375%, Training Loss: 0.7814%\n",
      "Epoch [18/300], Step [11/225], Training Accuracy: 65.1989%, Training Loss: 0.7910%\n",
      "Epoch [18/300], Step [12/225], Training Accuracy: 64.9740%, Training Loss: 0.7973%\n",
      "Epoch [18/300], Step [13/225], Training Accuracy: 65.7452%, Training Loss: 0.7961%\n",
      "Epoch [18/300], Step [14/225], Training Accuracy: 66.0714%, Training Loss: 0.7880%\n",
      "Epoch [18/300], Step [15/225], Training Accuracy: 65.6250%, Training Loss: 0.7875%\n",
      "Epoch [18/300], Step [16/225], Training Accuracy: 65.8203%, Training Loss: 0.7815%\n",
      "Epoch [18/300], Step [17/225], Training Accuracy: 66.4522%, Training Loss: 0.7753%\n",
      "Epoch [18/300], Step [18/225], Training Accuracy: 65.6250%, Training Loss: 0.7901%\n",
      "Epoch [18/300], Step [19/225], Training Accuracy: 66.2007%, Training Loss: 0.7804%\n",
      "Epoch [18/300], Step [20/225], Training Accuracy: 66.4844%, Training Loss: 0.7726%\n",
      "Epoch [18/300], Step [21/225], Training Accuracy: 66.4435%, Training Loss: 0.7704%\n",
      "Epoch [18/300], Step [22/225], Training Accuracy: 66.0511%, Training Loss: 0.7747%\n",
      "Epoch [18/300], Step [23/225], Training Accuracy: 66.1005%, Training Loss: 0.7733%\n",
      "Epoch [18/300], Step [24/225], Training Accuracy: 65.9505%, Training Loss: 0.7803%\n",
      "Epoch [18/300], Step [25/225], Training Accuracy: 66.1875%, Training Loss: 0.7746%\n",
      "Epoch [18/300], Step [26/225], Training Accuracy: 66.2260%, Training Loss: 0.7712%\n",
      "Epoch [18/300], Step [27/225], Training Accuracy: 65.7986%, Training Loss: 0.7833%\n",
      "Epoch [18/300], Step [28/225], Training Accuracy: 65.9598%, Training Loss: 0.7803%\n",
      "Epoch [18/300], Step [29/225], Training Accuracy: 66.0560%, Training Loss: 0.7769%\n",
      "Epoch [18/300], Step [30/225], Training Accuracy: 66.0938%, Training Loss: 0.7755%\n",
      "Epoch [18/300], Step [31/225], Training Accuracy: 65.9274%, Training Loss: 0.7760%\n",
      "Epoch [18/300], Step [32/225], Training Accuracy: 65.9180%, Training Loss: 0.7749%\n",
      "Epoch [18/300], Step [33/225], Training Accuracy: 66.2879%, Training Loss: 0.7684%\n",
      "Epoch [18/300], Step [34/225], Training Accuracy: 66.1765%, Training Loss: 0.7722%\n",
      "Epoch [18/300], Step [35/225], Training Accuracy: 66.2054%, Training Loss: 0.7700%\n",
      "Epoch [18/300], Step [36/225], Training Accuracy: 66.1024%, Training Loss: 0.7693%\n",
      "Epoch [18/300], Step [37/225], Training Accuracy: 66.1740%, Training Loss: 0.7669%\n",
      "Epoch [18/300], Step [38/225], Training Accuracy: 66.2418%, Training Loss: 0.7626%\n",
      "Epoch [18/300], Step [39/225], Training Accuracy: 66.3061%, Training Loss: 0.7613%\n",
      "Epoch [18/300], Step [40/225], Training Accuracy: 66.2500%, Training Loss: 0.7639%\n",
      "Epoch [18/300], Step [41/225], Training Accuracy: 66.1204%, Training Loss: 0.7679%\n",
      "Epoch [18/300], Step [42/225], Training Accuracy: 66.0714%, Training Loss: 0.7667%\n",
      "Epoch [18/300], Step [43/225], Training Accuracy: 66.1337%, Training Loss: 0.7694%\n",
      "Epoch [18/300], Step [44/225], Training Accuracy: 66.2287%, Training Loss: 0.7653%\n",
      "Epoch [18/300], Step [45/225], Training Accuracy: 66.2500%, Training Loss: 0.7648%\n",
      "Epoch [18/300], Step [46/225], Training Accuracy: 66.3383%, Training Loss: 0.7598%\n",
      "Epoch [18/300], Step [47/225], Training Accuracy: 66.4229%, Training Loss: 0.7584%\n",
      "Epoch [18/300], Step [48/225], Training Accuracy: 66.3737%, Training Loss: 0.7583%\n",
      "Epoch [18/300], Step [49/225], Training Accuracy: 66.5816%, Training Loss: 0.7545%\n",
      "Epoch [18/300], Step [50/225], Training Accuracy: 66.5938%, Training Loss: 0.7550%\n",
      "Epoch [18/300], Step [51/225], Training Accuracy: 66.9424%, Training Loss: 0.7504%\n",
      "Epoch [18/300], Step [52/225], Training Accuracy: 67.3377%, Training Loss: 0.7458%\n",
      "Epoch [18/300], Step [53/225], Training Accuracy: 67.3939%, Training Loss: 0.7450%\n",
      "Epoch [18/300], Step [54/225], Training Accuracy: 67.3900%, Training Loss: 0.7442%\n",
      "Epoch [18/300], Step [55/225], Training Accuracy: 67.4716%, Training Loss: 0.7429%\n",
      "Epoch [18/300], Step [56/225], Training Accuracy: 67.6339%, Training Loss: 0.7395%\n",
      "Epoch [18/300], Step [57/225], Training Accuracy: 67.7357%, Training Loss: 0.7369%\n",
      "Epoch [18/300], Step [58/225], Training Accuracy: 67.9149%, Training Loss: 0.7351%\n",
      "Epoch [18/300], Step [59/225], Training Accuracy: 68.1674%, Training Loss: 0.7317%\n",
      "Epoch [18/300], Step [60/225], Training Accuracy: 68.1250%, Training Loss: 0.7316%\n",
      "Epoch [18/300], Step [61/225], Training Accuracy: 68.0328%, Training Loss: 0.7323%\n",
      "Epoch [18/300], Step [62/225], Training Accuracy: 68.1704%, Training Loss: 0.7298%\n",
      "Epoch [18/300], Step [63/225], Training Accuracy: 68.1548%, Training Loss: 0.7294%\n",
      "Epoch [18/300], Step [64/225], Training Accuracy: 68.2861%, Training Loss: 0.7284%\n",
      "Epoch [18/300], Step [65/225], Training Accuracy: 68.2452%, Training Loss: 0.7296%\n",
      "Epoch [18/300], Step [66/225], Training Accuracy: 68.3239%, Training Loss: 0.7275%\n",
      "Epoch [18/300], Step [67/225], Training Accuracy: 68.2369%, Training Loss: 0.7278%\n",
      "Epoch [18/300], Step [68/225], Training Accuracy: 68.1985%, Training Loss: 0.7267%\n",
      "Epoch [18/300], Step [69/225], Training Accuracy: 68.2971%, Training Loss: 0.7267%\n",
      "Epoch [18/300], Step [70/225], Training Accuracy: 68.3036%, Training Loss: 0.7273%\n",
      "Epoch [18/300], Step [71/225], Training Accuracy: 68.2438%, Training Loss: 0.7270%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/300], Step [72/225], Training Accuracy: 68.1207%, Training Loss: 0.7278%\n",
      "Epoch [18/300], Step [73/225], Training Accuracy: 68.1721%, Training Loss: 0.7271%\n",
      "Epoch [18/300], Step [74/225], Training Accuracy: 68.2432%, Training Loss: 0.7243%\n",
      "Epoch [18/300], Step [75/225], Training Accuracy: 68.1875%, Training Loss: 0.7241%\n",
      "Epoch [18/300], Step [76/225], Training Accuracy: 68.0921%, Training Loss: 0.7262%\n",
      "Epoch [18/300], Step [77/225], Training Accuracy: 68.0601%, Training Loss: 0.7273%\n",
      "Epoch [18/300], Step [78/225], Training Accuracy: 67.9888%, Training Loss: 0.7284%\n",
      "Epoch [18/300], Step [79/225], Training Accuracy: 67.9391%, Training Loss: 0.7288%\n",
      "Epoch [18/300], Step [80/225], Training Accuracy: 67.8125%, Training Loss: 0.7308%\n",
      "Epoch [18/300], Step [81/225], Training Accuracy: 67.6505%, Training Loss: 0.7316%\n",
      "Epoch [18/300], Step [82/225], Training Accuracy: 67.6639%, Training Loss: 0.7310%\n",
      "Epoch [18/300], Step [83/225], Training Accuracy: 67.5452%, Training Loss: 0.7317%\n",
      "Epoch [18/300], Step [84/225], Training Accuracy: 67.6153%, Training Loss: 0.7310%\n",
      "Epoch [18/300], Step [85/225], Training Accuracy: 67.7574%, Training Loss: 0.7291%\n",
      "Epoch [18/300], Step [86/225], Training Accuracy: 67.7689%, Training Loss: 0.7282%\n",
      "Epoch [18/300], Step [87/225], Training Accuracy: 67.8161%, Training Loss: 0.7292%\n",
      "Epoch [18/300], Step [88/225], Training Accuracy: 67.8622%, Training Loss: 0.7299%\n",
      "Epoch [18/300], Step [89/225], Training Accuracy: 67.8195%, Training Loss: 0.7314%\n",
      "Epoch [18/300], Step [90/225], Training Accuracy: 67.7604%, Training Loss: 0.7325%\n",
      "Epoch [18/300], Step [91/225], Training Accuracy: 67.8056%, Training Loss: 0.7310%\n",
      "Epoch [18/300], Step [92/225], Training Accuracy: 67.7989%, Training Loss: 0.7337%\n",
      "Epoch [18/300], Step [93/225], Training Accuracy: 67.8259%, Training Loss: 0.7327%\n",
      "Epoch [18/300], Step [94/225], Training Accuracy: 67.7859%, Training Loss: 0.7319%\n",
      "Epoch [18/300], Step [95/225], Training Accuracy: 67.7138%, Training Loss: 0.7344%\n",
      "Epoch [18/300], Step [96/225], Training Accuracy: 67.8385%, Training Loss: 0.7326%\n",
      "Epoch [18/300], Step [97/225], Training Accuracy: 67.7674%, Training Loss: 0.7338%\n",
      "Epoch [18/300], Step [98/225], Training Accuracy: 67.8093%, Training Loss: 0.7335%\n",
      "Epoch [18/300], Step [99/225], Training Accuracy: 67.7557%, Training Loss: 0.7340%\n",
      "Epoch [18/300], Step [100/225], Training Accuracy: 67.6250%, Training Loss: 0.7363%\n",
      "Epoch [18/300], Step [101/225], Training Accuracy: 67.6207%, Training Loss: 0.7353%\n",
      "Epoch [18/300], Step [102/225], Training Accuracy: 67.5551%, Training Loss: 0.7352%\n",
      "Epoch [18/300], Step [103/225], Training Accuracy: 67.5364%, Training Loss: 0.7348%\n",
      "Epoch [18/300], Step [104/225], Training Accuracy: 67.5331%, Training Loss: 0.7351%\n",
      "Epoch [18/300], Step [105/225], Training Accuracy: 67.6339%, Training Loss: 0.7336%\n",
      "Epoch [18/300], Step [106/225], Training Accuracy: 67.5265%, Training Loss: 0.7347%\n",
      "Epoch [18/300], Step [107/225], Training Accuracy: 67.4650%, Training Loss: 0.7363%\n",
      "Epoch [18/300], Step [108/225], Training Accuracy: 67.4913%, Training Loss: 0.7351%\n",
      "Epoch [18/300], Step [109/225], Training Accuracy: 67.4599%, Training Loss: 0.7352%\n",
      "Epoch [18/300], Step [110/225], Training Accuracy: 67.4858%, Training Loss: 0.7344%\n",
      "Epoch [18/300], Step [111/225], Training Accuracy: 67.4268%, Training Loss: 0.7355%\n",
      "Epoch [18/300], Step [112/225], Training Accuracy: 67.4944%, Training Loss: 0.7343%\n",
      "Epoch [18/300], Step [113/225], Training Accuracy: 67.5332%, Training Loss: 0.7344%\n",
      "Epoch [18/300], Step [114/225], Training Accuracy: 67.5850%, Training Loss: 0.7327%\n",
      "Epoch [18/300], Step [115/225], Training Accuracy: 67.5815%, Training Loss: 0.7328%\n",
      "Epoch [18/300], Step [116/225], Training Accuracy: 67.5916%, Training Loss: 0.7321%\n",
      "Epoch [18/300], Step [117/225], Training Accuracy: 67.4546%, Training Loss: 0.7353%\n",
      "Epoch [18/300], Step [118/225], Training Accuracy: 67.5185%, Training Loss: 0.7340%\n",
      "Epoch [18/300], Step [119/225], Training Accuracy: 67.5289%, Training Loss: 0.7337%\n",
      "Epoch [18/300], Step [120/225], Training Accuracy: 67.5000%, Training Loss: 0.7330%\n",
      "Epoch [18/300], Step [121/225], Training Accuracy: 67.4458%, Training Loss: 0.7328%\n",
      "Epoch [18/300], Step [122/225], Training Accuracy: 67.4436%, Training Loss: 0.7327%\n",
      "Epoch [18/300], Step [123/225], Training Accuracy: 67.4543%, Training Loss: 0.7322%\n",
      "Epoch [18/300], Step [124/225], Training Accuracy: 67.4395%, Training Loss: 0.7320%\n",
      "Epoch [18/300], Step [125/225], Training Accuracy: 67.3625%, Training Loss: 0.7349%\n",
      "Epoch [18/300], Step [126/225], Training Accuracy: 67.3859%, Training Loss: 0.7350%\n",
      "Epoch [18/300], Step [127/225], Training Accuracy: 67.3228%, Training Loss: 0.7358%\n",
      "Epoch [18/300], Step [128/225], Training Accuracy: 67.2974%, Training Loss: 0.7355%\n",
      "Epoch [18/300], Step [129/225], Training Accuracy: 67.3692%, Training Loss: 0.7347%\n",
      "Epoch [18/300], Step [130/225], Training Accuracy: 67.3918%, Training Loss: 0.7339%\n",
      "Epoch [18/300], Step [131/225], Training Accuracy: 67.2948%, Training Loss: 0.7356%\n",
      "Epoch [18/300], Step [132/225], Training Accuracy: 67.2822%, Training Loss: 0.7360%\n",
      "Epoch [18/300], Step [133/225], Training Accuracy: 67.3755%, Training Loss: 0.7348%\n",
      "Epoch [18/300], Step [134/225], Training Accuracy: 67.3158%, Training Loss: 0.7364%\n",
      "Epoch [18/300], Step [135/225], Training Accuracy: 67.3032%, Training Loss: 0.7365%\n",
      "Epoch [18/300], Step [136/225], Training Accuracy: 67.3369%, Training Loss: 0.7363%\n",
      "Epoch [18/300], Step [137/225], Training Accuracy: 67.3586%, Training Loss: 0.7370%\n",
      "Epoch [18/300], Step [138/225], Training Accuracy: 67.4366%, Training Loss: 0.7354%\n",
      "Epoch [18/300], Step [139/225], Training Accuracy: 67.4011%, Training Loss: 0.7361%\n",
      "Epoch [18/300], Step [140/225], Training Accuracy: 67.4330%, Training Loss: 0.7351%\n",
      "Epoch [18/300], Step [141/225], Training Accuracy: 67.4313%, Training Loss: 0.7349%\n",
      "Epoch [18/300], Step [142/225], Training Accuracy: 67.3966%, Training Loss: 0.7354%\n",
      "Epoch [18/300], Step [143/225], Training Accuracy: 67.4060%, Training Loss: 0.7350%\n",
      "Epoch [18/300], Step [144/225], Training Accuracy: 67.4262%, Training Loss: 0.7344%\n",
      "Epoch [18/300], Step [145/225], Training Accuracy: 67.4353%, Training Loss: 0.7340%\n",
      "Epoch [18/300], Step [146/225], Training Accuracy: 67.4443%, Training Loss: 0.7341%\n",
      "Epoch [18/300], Step [147/225], Training Accuracy: 67.4426%, Training Loss: 0.7342%\n",
      "Epoch [18/300], Step [148/225], Training Accuracy: 67.4937%, Training Loss: 0.7330%\n",
      "Epoch [18/300], Step [149/225], Training Accuracy: 67.4811%, Training Loss: 0.7335%\n",
      "Epoch [18/300], Step [150/225], Training Accuracy: 67.5000%, Training Loss: 0.7330%\n",
      "Epoch [18/300], Step [151/225], Training Accuracy: 67.5393%, Training Loss: 0.7323%\n",
      "Epoch [18/300], Step [152/225], Training Accuracy: 67.4856%, Training Loss: 0.7336%\n",
      "Epoch [18/300], Step [153/225], Training Accuracy: 67.4734%, Training Loss: 0.7330%\n",
      "Epoch [18/300], Step [154/225], Training Accuracy: 67.4716%, Training Loss: 0.7326%\n",
      "Epoch [18/300], Step [155/225], Training Accuracy: 67.4294%, Training Loss: 0.7327%\n",
      "Epoch [18/300], Step [156/225], Training Accuracy: 67.4279%, Training Loss: 0.7331%\n",
      "Epoch [18/300], Step [157/225], Training Accuracy: 67.4164%, Training Loss: 0.7330%\n",
      "Epoch [18/300], Step [158/225], Training Accuracy: 67.3754%, Training Loss: 0.7342%\n",
      "Epoch [18/300], Step [159/225], Training Accuracy: 67.3939%, Training Loss: 0.7339%\n",
      "Epoch [18/300], Step [160/225], Training Accuracy: 67.4121%, Training Loss: 0.7330%\n",
      "Epoch [18/300], Step [161/225], Training Accuracy: 67.4495%, Training Loss: 0.7321%\n",
      "Epoch [18/300], Step [162/225], Training Accuracy: 67.5058%, Training Loss: 0.7314%\n",
      "Epoch [18/300], Step [163/225], Training Accuracy: 67.5326%, Training Loss: 0.7314%\n",
      "Epoch [18/300], Step [164/225], Training Accuracy: 67.5686%, Training Loss: 0.7306%\n",
      "Epoch [18/300], Step [165/225], Training Accuracy: 67.5947%, Training Loss: 0.7307%\n",
      "Epoch [18/300], Step [166/225], Training Accuracy: 67.6017%, Training Loss: 0.7309%\n",
      "Epoch [18/300], Step [167/225], Training Accuracy: 67.5805%, Training Loss: 0.7308%\n",
      "Epoch [18/300], Step [168/225], Training Accuracy: 67.5502%, Training Loss: 0.7307%\n",
      "Epoch [18/300], Step [169/225], Training Accuracy: 67.5758%, Training Loss: 0.7302%\n",
      "Epoch [18/300], Step [170/225], Training Accuracy: 67.6011%, Training Loss: 0.7296%\n",
      "Epoch [18/300], Step [171/225], Training Accuracy: 67.6261%, Training Loss: 0.7300%\n",
      "Epoch [18/300], Step [172/225], Training Accuracy: 67.5872%, Training Loss: 0.7303%\n",
      "Epoch [18/300], Step [173/225], Training Accuracy: 67.5036%, Training Loss: 0.7315%\n",
      "Epoch [18/300], Step [174/225], Training Accuracy: 67.5467%, Training Loss: 0.7307%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/300], Step [175/225], Training Accuracy: 67.5982%, Training Loss: 0.7303%\n",
      "Epoch [18/300], Step [176/225], Training Accuracy: 67.5337%, Training Loss: 0.7304%\n",
      "Epoch [18/300], Step [177/225], Training Accuracy: 67.5318%, Training Loss: 0.7305%\n",
      "Epoch [18/300], Step [178/225], Training Accuracy: 67.6001%, Training Loss: 0.7297%\n",
      "Epoch [18/300], Step [179/225], Training Accuracy: 67.6763%, Training Loss: 0.7286%\n",
      "Epoch [18/300], Step [180/225], Training Accuracy: 67.6910%, Training Loss: 0.7283%\n",
      "Epoch [18/300], Step [181/225], Training Accuracy: 67.7055%, Training Loss: 0.7284%\n",
      "Epoch [18/300], Step [182/225], Training Accuracy: 67.7026%, Training Loss: 0.7279%\n",
      "Epoch [18/300], Step [183/225], Training Accuracy: 67.7254%, Training Loss: 0.7274%\n",
      "Epoch [18/300], Step [184/225], Training Accuracy: 67.7055%, Training Loss: 0.7278%\n",
      "Epoch [18/300], Step [185/225], Training Accuracy: 67.7365%, Training Loss: 0.7273%\n",
      "Epoch [18/300], Step [186/225], Training Accuracy: 67.7755%, Training Loss: 0.7268%\n",
      "Epoch [18/300], Step [187/225], Training Accuracy: 67.8225%, Training Loss: 0.7261%\n",
      "Epoch [18/300], Step [188/225], Training Accuracy: 67.8358%, Training Loss: 0.7256%\n",
      "Epoch [18/300], Step [189/225], Training Accuracy: 67.8241%, Training Loss: 0.7251%\n",
      "Epoch [18/300], Step [190/225], Training Accuracy: 67.8536%, Training Loss: 0.7240%\n",
      "Epoch [18/300], Step [191/225], Training Accuracy: 67.8665%, Training Loss: 0.7236%\n",
      "Epoch [18/300], Step [192/225], Training Accuracy: 67.9199%, Training Loss: 0.7225%\n",
      "Epoch [18/300], Step [193/225], Training Accuracy: 67.8999%, Training Loss: 0.7225%\n",
      "Epoch [18/300], Step [194/225], Training Accuracy: 67.8721%, Training Loss: 0.7230%\n",
      "Epoch [18/300], Step [195/225], Training Accuracy: 67.8846%, Training Loss: 0.7225%\n",
      "Epoch [18/300], Step [196/225], Training Accuracy: 67.8811%, Training Loss: 0.7227%\n",
      "Epoch [18/300], Step [197/225], Training Accuracy: 67.8775%, Training Loss: 0.7230%\n",
      "Epoch [18/300], Step [198/225], Training Accuracy: 67.8977%, Training Loss: 0.7222%\n",
      "Epoch [18/300], Step [199/225], Training Accuracy: 67.9099%, Training Loss: 0.7219%\n",
      "Epoch [18/300], Step [200/225], Training Accuracy: 67.9375%, Training Loss: 0.7220%\n",
      "Epoch [18/300], Step [201/225], Training Accuracy: 67.9338%, Training Loss: 0.7216%\n",
      "Epoch [18/300], Step [202/225], Training Accuracy: 67.9069%, Training Loss: 0.7220%\n",
      "Epoch [18/300], Step [203/225], Training Accuracy: 67.9649%, Training Loss: 0.7207%\n",
      "Epoch [18/300], Step [204/225], Training Accuracy: 67.9458%, Training Loss: 0.7213%\n",
      "Epoch [18/300], Step [205/225], Training Accuracy: 67.9802%, Training Loss: 0.7206%\n",
      "Epoch [18/300], Step [206/225], Training Accuracy: 67.9384%, Training Loss: 0.7214%\n",
      "Epoch [18/300], Step [207/225], Training Accuracy: 67.9423%, Training Loss: 0.7211%\n",
      "Epoch [18/300], Step [208/225], Training Accuracy: 67.9387%, Training Loss: 0.7208%\n",
      "Epoch [18/300], Step [209/225], Training Accuracy: 67.9426%, Training Loss: 0.7204%\n",
      "Epoch [18/300], Step [210/225], Training Accuracy: 67.9241%, Training Loss: 0.7206%\n",
      "Epoch [18/300], Step [211/225], Training Accuracy: 67.9650%, Training Loss: 0.7197%\n",
      "Epoch [18/300], Step [212/225], Training Accuracy: 67.9909%, Training Loss: 0.7196%\n",
      "Epoch [18/300], Step [213/225], Training Accuracy: 67.9431%, Training Loss: 0.7204%\n",
      "Epoch [18/300], Step [214/225], Training Accuracy: 67.9395%, Training Loss: 0.7200%\n",
      "Epoch [18/300], Step [215/225], Training Accuracy: 67.9070%, Training Loss: 0.7208%\n",
      "Epoch [18/300], Step [216/225], Training Accuracy: 67.9253%, Training Loss: 0.7206%\n",
      "Epoch [18/300], Step [217/225], Training Accuracy: 67.9075%, Training Loss: 0.7214%\n",
      "Epoch [18/300], Step [218/225], Training Accuracy: 67.8827%, Training Loss: 0.7218%\n",
      "Epoch [18/300], Step [219/225], Training Accuracy: 67.8796%, Training Loss: 0.7228%\n",
      "Epoch [18/300], Step [220/225], Training Accuracy: 67.9048%, Training Loss: 0.7224%\n",
      "Epoch [18/300], Step [221/225], Training Accuracy: 67.9087%, Training Loss: 0.7225%\n",
      "Epoch [18/300], Step [222/225], Training Accuracy: 67.9406%, Training Loss: 0.7223%\n",
      "Epoch [18/300], Step [223/225], Training Accuracy: 67.9232%, Training Loss: 0.7229%\n",
      "Epoch [18/300], Step [224/225], Training Accuracy: 67.9269%, Training Loss: 0.7229%\n",
      "Epoch [18/300], Step [225/225], Training Accuracy: 67.9058%, Training Loss: 0.7230%\n",
      "Epoch [19/300], Step [1/225], Training Accuracy: 70.3125%, Training Loss: 0.6315%\n",
      "Epoch [19/300], Step [2/225], Training Accuracy: 71.8750%, Training Loss: 0.6400%\n",
      "Epoch [19/300], Step [3/225], Training Accuracy: 72.3958%, Training Loss: 0.6569%\n",
      "Epoch [19/300], Step [4/225], Training Accuracy: 67.9688%, Training Loss: 0.7376%\n",
      "Epoch [19/300], Step [5/225], Training Accuracy: 68.1250%, Training Loss: 0.7113%\n",
      "Epoch [19/300], Step [6/225], Training Accuracy: 70.0521%, Training Loss: 0.6997%\n",
      "Epoch [19/300], Step [7/225], Training Accuracy: 68.7500%, Training Loss: 0.7231%\n",
      "Epoch [19/300], Step [8/225], Training Accuracy: 69.7266%, Training Loss: 0.7090%\n",
      "Epoch [19/300], Step [9/225], Training Accuracy: 69.6181%, Training Loss: 0.6959%\n",
      "Epoch [19/300], Step [10/225], Training Accuracy: 68.4375%, Training Loss: 0.7090%\n",
      "Epoch [19/300], Step [11/225], Training Accuracy: 68.3239%, Training Loss: 0.7041%\n",
      "Epoch [19/300], Step [12/225], Training Accuracy: 68.2292%, Training Loss: 0.7027%\n",
      "Epoch [19/300], Step [13/225], Training Accuracy: 68.2692%, Training Loss: 0.6979%\n",
      "Epoch [19/300], Step [14/225], Training Accuracy: 67.7455%, Training Loss: 0.6988%\n",
      "Epoch [19/300], Step [15/225], Training Accuracy: 67.7083%, Training Loss: 0.7025%\n",
      "Epoch [19/300], Step [16/225], Training Accuracy: 67.7734%, Training Loss: 0.7066%\n",
      "Epoch [19/300], Step [17/225], Training Accuracy: 67.5551%, Training Loss: 0.7120%\n",
      "Epoch [19/300], Step [18/225], Training Accuracy: 67.6215%, Training Loss: 0.7133%\n",
      "Epoch [19/300], Step [19/225], Training Accuracy: 67.5164%, Training Loss: 0.7221%\n",
      "Epoch [19/300], Step [20/225], Training Accuracy: 68.2031%, Training Loss: 0.7108%\n",
      "Epoch [19/300], Step [21/225], Training Accuracy: 68.0804%, Training Loss: 0.7055%\n",
      "Epoch [19/300], Step [22/225], Training Accuracy: 67.8977%, Training Loss: 0.7055%\n",
      "Epoch [19/300], Step [23/225], Training Accuracy: 67.5272%, Training Loss: 0.7089%\n",
      "Epoch [19/300], Step [24/225], Training Accuracy: 67.5130%, Training Loss: 0.7112%\n",
      "Epoch [19/300], Step [25/225], Training Accuracy: 67.7500%, Training Loss: 0.7109%\n",
      "Epoch [19/300], Step [26/225], Training Accuracy: 67.8486%, Training Loss: 0.7166%\n",
      "Epoch [19/300], Step [27/225], Training Accuracy: 67.7083%, Training Loss: 0.7190%\n",
      "Epoch [19/300], Step [28/225], Training Accuracy: 67.9688%, Training Loss: 0.7148%\n",
      "Epoch [19/300], Step [29/225], Training Accuracy: 68.2651%, Training Loss: 0.7121%\n",
      "Epoch [19/300], Step [30/225], Training Accuracy: 68.2292%, Training Loss: 0.7178%\n",
      "Epoch [19/300], Step [31/225], Training Accuracy: 67.9940%, Training Loss: 0.7250%\n",
      "Epoch [19/300], Step [32/225], Training Accuracy: 68.1641%, Training Loss: 0.7219%\n",
      "Epoch [19/300], Step [33/225], Training Accuracy: 68.2292%, Training Loss: 0.7209%\n",
      "Epoch [19/300], Step [34/225], Training Accuracy: 68.0607%, Training Loss: 0.7284%\n",
      "Epoch [19/300], Step [35/225], Training Accuracy: 68.0357%, Training Loss: 0.7362%\n",
      "Epoch [19/300], Step [36/225], Training Accuracy: 68.0990%, Training Loss: 0.7364%\n",
      "Epoch [19/300], Step [37/225], Training Accuracy: 67.9054%, Training Loss: 0.7409%\n",
      "Epoch [19/300], Step [38/225], Training Accuracy: 67.8454%, Training Loss: 0.7433%\n",
      "Epoch [19/300], Step [39/225], Training Accuracy: 67.8686%, Training Loss: 0.7413%\n",
      "Epoch [19/300], Step [40/225], Training Accuracy: 67.8125%, Training Loss: 0.7403%\n",
      "Epoch [19/300], Step [41/225], Training Accuracy: 67.6067%, Training Loss: 0.7442%\n",
      "Epoch [19/300], Step [42/225], Training Accuracy: 67.5223%, Training Loss: 0.7444%\n",
      "Epoch [19/300], Step [43/225], Training Accuracy: 67.5872%, Training Loss: 0.7471%\n",
      "Epoch [19/300], Step [44/225], Training Accuracy: 67.8977%, Training Loss: 0.7442%\n",
      "Epoch [19/300], Step [45/225], Training Accuracy: 67.7778%, Training Loss: 0.7444%\n",
      "Epoch [19/300], Step [46/225], Training Accuracy: 67.9688%, Training Loss: 0.7399%\n",
      "Epoch [19/300], Step [47/225], Training Accuracy: 67.7859%, Training Loss: 0.7416%\n",
      "Epoch [19/300], Step [48/225], Training Accuracy: 67.7409%, Training Loss: 0.7440%\n",
      "Epoch [19/300], Step [49/225], Training Accuracy: 67.7934%, Training Loss: 0.7425%\n",
      "Epoch [19/300], Step [50/225], Training Accuracy: 67.8438%, Training Loss: 0.7399%\n",
      "Epoch [19/300], Step [51/225], Training Accuracy: 68.0453%, Training Loss: 0.7380%\n",
      "Epoch [19/300], Step [52/225], Training Accuracy: 68.2692%, Training Loss: 0.7332%\n",
      "Epoch [19/300], Step [53/225], Training Accuracy: 68.3373%, Training Loss: 0.7338%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/300], Step [54/225], Training Accuracy: 68.3449%, Training Loss: 0.7340%\n",
      "Epoch [19/300], Step [55/225], Training Accuracy: 68.2955%, Training Loss: 0.7346%\n",
      "Epoch [19/300], Step [56/225], Training Accuracy: 68.2478%, Training Loss: 0.7343%\n",
      "Epoch [19/300], Step [57/225], Training Accuracy: 68.2840%, Training Loss: 0.7330%\n",
      "Epoch [19/300], Step [58/225], Training Accuracy: 68.2112%, Training Loss: 0.7337%\n",
      "Epoch [19/300], Step [59/225], Training Accuracy: 68.2998%, Training Loss: 0.7316%\n",
      "Epoch [19/300], Step [60/225], Training Accuracy: 68.2552%, Training Loss: 0.7330%\n",
      "Epoch [19/300], Step [61/225], Training Accuracy: 68.2377%, Training Loss: 0.7343%\n",
      "Epoch [19/300], Step [62/225], Training Accuracy: 68.4476%, Training Loss: 0.7317%\n",
      "Epoch [19/300], Step [63/225], Training Accuracy: 68.5764%, Training Loss: 0.7296%\n",
      "Epoch [19/300], Step [64/225], Training Accuracy: 68.6279%, Training Loss: 0.7296%\n",
      "Epoch [19/300], Step [65/225], Training Accuracy: 68.6298%, Training Loss: 0.7318%\n",
      "Epoch [19/300], Step [66/225], Training Accuracy: 68.7027%, Training Loss: 0.7295%\n",
      "Epoch [19/300], Step [67/225], Training Accuracy: 68.7500%, Training Loss: 0.7279%\n",
      "Epoch [19/300], Step [68/225], Training Accuracy: 68.7960%, Training Loss: 0.7272%\n",
      "Epoch [19/300], Step [69/225], Training Accuracy: 68.6821%, Training Loss: 0.7265%\n",
      "Epoch [19/300], Step [70/225], Training Accuracy: 68.7054%, Training Loss: 0.7261%\n",
      "Epoch [19/300], Step [71/225], Training Accuracy: 68.8160%, Training Loss: 0.7241%\n",
      "Epoch [19/300], Step [72/225], Training Accuracy: 68.8368%, Training Loss: 0.7246%\n",
      "Epoch [19/300], Step [73/225], Training Accuracy: 68.7928%, Training Loss: 0.7246%\n",
      "Epoch [19/300], Step [74/225], Training Accuracy: 68.8767%, Training Loss: 0.7230%\n",
      "Epoch [19/300], Step [75/225], Training Accuracy: 68.8542%, Training Loss: 0.7222%\n",
      "Epoch [19/300], Step [76/225], Training Accuracy: 68.8528%, Training Loss: 0.7228%\n",
      "Epoch [19/300], Step [77/225], Training Accuracy: 68.8920%, Training Loss: 0.7219%\n",
      "Epoch [19/300], Step [78/225], Training Accuracy: 68.9103%, Training Loss: 0.7222%\n",
      "Epoch [19/300], Step [79/225], Training Accuracy: 68.8687%, Training Loss: 0.7223%\n",
      "Epoch [19/300], Step [80/225], Training Accuracy: 68.7305%, Training Loss: 0.7234%\n",
      "Epoch [19/300], Step [81/225], Training Accuracy: 68.8272%, Training Loss: 0.7237%\n",
      "Epoch [19/300], Step [82/225], Training Accuracy: 68.8072%, Training Loss: 0.7235%\n",
      "Epoch [19/300], Step [83/225], Training Accuracy: 68.8253%, Training Loss: 0.7235%\n",
      "Epoch [19/300], Step [84/225], Training Accuracy: 68.8616%, Training Loss: 0.7228%\n",
      "Epoch [19/300], Step [85/225], Training Accuracy: 68.9338%, Training Loss: 0.7218%\n",
      "Epoch [19/300], Step [86/225], Training Accuracy: 69.0225%, Training Loss: 0.7202%\n",
      "Epoch [19/300], Step [87/225], Training Accuracy: 69.0014%, Training Loss: 0.7206%\n",
      "Epoch [19/300], Step [88/225], Training Accuracy: 68.9808%, Training Loss: 0.7207%\n",
      "Epoch [19/300], Step [89/225], Training Accuracy: 68.9431%, Training Loss: 0.7204%\n",
      "Epoch [19/300], Step [90/225], Training Accuracy: 68.9236%, Training Loss: 0.7220%\n",
      "Epoch [19/300], Step [91/225], Training Accuracy: 68.8359%, Training Loss: 0.7229%\n",
      "Epoch [19/300], Step [92/225], Training Accuracy: 68.7840%, Training Loss: 0.7235%\n",
      "Epoch [19/300], Step [93/225], Training Accuracy: 68.8172%, Training Loss: 0.7232%\n",
      "Epoch [19/300], Step [94/225], Training Accuracy: 68.8331%, Training Loss: 0.7224%\n",
      "Epoch [19/300], Step [95/225], Training Accuracy: 68.7171%, Training Loss: 0.7248%\n",
      "Epoch [19/300], Step [96/225], Training Accuracy: 68.8639%, Training Loss: 0.7223%\n",
      "Epoch [19/300], Step [97/225], Training Accuracy: 68.8950%, Training Loss: 0.7230%\n",
      "Epoch [19/300], Step [98/225], Training Accuracy: 68.9094%, Training Loss: 0.7225%\n",
      "Epoch [19/300], Step [99/225], Training Accuracy: 68.9867%, Training Loss: 0.7223%\n",
      "Epoch [19/300], Step [100/225], Training Accuracy: 68.8594%, Training Loss: 0.7228%\n",
      "Epoch [19/300], Step [101/225], Training Accuracy: 68.8119%, Training Loss: 0.7234%\n",
      "Epoch [19/300], Step [102/225], Training Accuracy: 68.7653%, Training Loss: 0.7239%\n",
      "Epoch [19/300], Step [103/225], Training Accuracy: 68.7652%, Training Loss: 0.7234%\n",
      "Epoch [19/300], Step [104/225], Training Accuracy: 68.6749%, Training Loss: 0.7252%\n",
      "Epoch [19/300], Step [105/225], Training Accuracy: 68.6756%, Training Loss: 0.7245%\n",
      "Epoch [19/300], Step [106/225], Training Accuracy: 68.7942%, Training Loss: 0.7227%\n",
      "Epoch [19/300], Step [107/225], Training Accuracy: 68.7354%, Training Loss: 0.7246%\n",
      "Epoch [19/300], Step [108/225], Training Accuracy: 68.7500%, Training Loss: 0.7241%\n",
      "Epoch [19/300], Step [109/225], Training Accuracy: 68.7213%, Training Loss: 0.7248%\n",
      "Epoch [19/300], Step [110/225], Training Accuracy: 68.7500%, Training Loss: 0.7231%\n",
      "Epoch [19/300], Step [111/225], Training Accuracy: 68.6655%, Training Loss: 0.7234%\n",
      "Epoch [19/300], Step [112/225], Training Accuracy: 68.6802%, Training Loss: 0.7225%\n",
      "Epoch [19/300], Step [113/225], Training Accuracy: 68.7085%, Training Loss: 0.7224%\n",
      "Epoch [19/300], Step [114/225], Training Accuracy: 68.6815%, Training Loss: 0.7226%\n",
      "Epoch [19/300], Step [115/225], Training Accuracy: 68.7500%, Training Loss: 0.7214%\n",
      "Epoch [19/300], Step [116/225], Training Accuracy: 68.7635%, Training Loss: 0.7209%\n",
      "Epoch [19/300], Step [117/225], Training Accuracy: 68.5630%, Training Loss: 0.7240%\n",
      "Epoch [19/300], Step [118/225], Training Accuracy: 68.5911%, Training Loss: 0.7239%\n",
      "Epoch [19/300], Step [119/225], Training Accuracy: 68.5793%, Training Loss: 0.7246%\n",
      "Epoch [19/300], Step [120/225], Training Accuracy: 68.4896%, Training Loss: 0.7252%\n",
      "Epoch [19/300], Step [121/225], Training Accuracy: 68.5046%, Training Loss: 0.7243%\n",
      "Epoch [19/300], Step [122/225], Training Accuracy: 68.4810%, Training Loss: 0.7241%\n",
      "Epoch [19/300], Step [123/225], Training Accuracy: 68.4832%, Training Loss: 0.7244%\n",
      "Epoch [19/300], Step [124/225], Training Accuracy: 68.5358%, Training Loss: 0.7230%\n",
      "Epoch [19/300], Step [125/225], Training Accuracy: 68.5375%, Training Loss: 0.7227%\n",
      "Epoch [19/300], Step [126/225], Training Accuracy: 68.5516%, Training Loss: 0.7220%\n",
      "Epoch [19/300], Step [127/225], Training Accuracy: 68.6147%, Training Loss: 0.7216%\n",
      "Epoch [19/300], Step [128/225], Training Accuracy: 68.5669%, Training Loss: 0.7218%\n",
      "Epoch [19/300], Step [129/225], Training Accuracy: 68.5925%, Training Loss: 0.7212%\n",
      "Epoch [19/300], Step [130/225], Training Accuracy: 68.5817%, Training Loss: 0.7212%\n",
      "Epoch [19/300], Step [131/225], Training Accuracy: 68.5592%, Training Loss: 0.7214%\n",
      "Epoch [19/300], Step [132/225], Training Accuracy: 68.5369%, Training Loss: 0.7214%\n",
      "Epoch [19/300], Step [133/225], Training Accuracy: 68.5855%, Training Loss: 0.7205%\n",
      "Epoch [19/300], Step [134/225], Training Accuracy: 68.5051%, Training Loss: 0.7216%\n",
      "Epoch [19/300], Step [135/225], Training Accuracy: 68.5301%, Training Loss: 0.7214%\n",
      "Epoch [19/300], Step [136/225], Training Accuracy: 68.5087%, Training Loss: 0.7211%\n",
      "Epoch [19/300], Step [137/225], Training Accuracy: 68.4877%, Training Loss: 0.7206%\n",
      "Epoch [19/300], Step [138/225], Training Accuracy: 68.5915%, Training Loss: 0.7191%\n",
      "Epoch [19/300], Step [139/225], Training Accuracy: 68.5589%, Training Loss: 0.7210%\n",
      "Epoch [19/300], Step [140/225], Training Accuracy: 68.5603%, Training Loss: 0.7205%\n",
      "Epoch [19/300], Step [141/225], Training Accuracy: 68.5395%, Training Loss: 0.7207%\n",
      "Epoch [19/300], Step [142/225], Training Accuracy: 68.4309%, Training Loss: 0.7229%\n",
      "Epoch [19/300], Step [143/225], Training Accuracy: 68.4987%, Training Loss: 0.7227%\n",
      "Epoch [19/300], Step [144/225], Training Accuracy: 68.5004%, Training Loss: 0.7235%\n",
      "Epoch [19/300], Step [145/225], Training Accuracy: 68.4914%, Training Loss: 0.7227%\n",
      "Epoch [19/300], Step [146/225], Training Accuracy: 68.4824%, Training Loss: 0.7232%\n",
      "Epoch [19/300], Step [147/225], Training Accuracy: 68.5480%, Training Loss: 0.7225%\n",
      "Epoch [19/300], Step [148/225], Training Accuracy: 68.6022%, Training Loss: 0.7209%\n",
      "Epoch [19/300], Step [149/225], Training Accuracy: 68.6032%, Training Loss: 0.7209%\n",
      "Epoch [19/300], Step [150/225], Training Accuracy: 68.6458%, Training Loss: 0.7201%\n",
      "Epoch [19/300], Step [151/225], Training Accuracy: 68.6465%, Training Loss: 0.7192%\n",
      "Epoch [19/300], Step [152/225], Training Accuracy: 68.6164%, Training Loss: 0.7190%\n",
      "Epoch [19/300], Step [153/225], Training Accuracy: 68.5764%, Training Loss: 0.7200%\n",
      "Epoch [19/300], Step [154/225], Training Accuracy: 68.5775%, Training Loss: 0.7194%\n",
      "Epoch [19/300], Step [155/225], Training Accuracy: 68.5685%, Training Loss: 0.7194%\n",
      "Epoch [19/300], Step [156/225], Training Accuracy: 68.5497%, Training Loss: 0.7203%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/300], Step [157/225], Training Accuracy: 68.5709%, Training Loss: 0.7203%\n",
      "Epoch [19/300], Step [158/225], Training Accuracy: 68.4929%, Training Loss: 0.7216%\n",
      "Epoch [19/300], Step [159/225], Training Accuracy: 68.4847%, Training Loss: 0.7217%\n",
      "Epoch [19/300], Step [160/225], Training Accuracy: 68.4961%, Training Loss: 0.7219%\n",
      "Epoch [19/300], Step [161/225], Training Accuracy: 68.5074%, Training Loss: 0.7217%\n",
      "Epoch [19/300], Step [162/225], Training Accuracy: 68.5571%, Training Loss: 0.7207%\n",
      "Epoch [19/300], Step [163/225], Training Accuracy: 68.5679%, Training Loss: 0.7198%\n",
      "Epoch [19/300], Step [164/225], Training Accuracy: 68.5976%, Training Loss: 0.7192%\n",
      "Epoch [19/300], Step [165/225], Training Accuracy: 68.6174%, Training Loss: 0.7187%\n",
      "Epoch [19/300], Step [166/225], Training Accuracy: 68.6465%, Training Loss: 0.7181%\n",
      "Epoch [19/300], Step [167/225], Training Accuracy: 68.6845%, Training Loss: 0.7173%\n",
      "Epoch [19/300], Step [168/225], Training Accuracy: 68.7035%, Training Loss: 0.7170%\n",
      "Epoch [19/300], Step [169/225], Training Accuracy: 68.7223%, Training Loss: 0.7164%\n",
      "Epoch [19/300], Step [170/225], Training Accuracy: 68.7408%, Training Loss: 0.7159%\n",
      "Epoch [19/300], Step [171/225], Training Accuracy: 68.7226%, Training Loss: 0.7159%\n",
      "Epoch [19/300], Step [172/225], Training Accuracy: 68.6955%, Training Loss: 0.7157%\n",
      "Epoch [19/300], Step [173/225], Training Accuracy: 68.6687%, Training Loss: 0.7156%\n",
      "Epoch [19/300], Step [174/225], Training Accuracy: 68.6961%, Training Loss: 0.7149%\n",
      "Epoch [19/300], Step [175/225], Training Accuracy: 68.7232%, Training Loss: 0.7142%\n",
      "Epoch [19/300], Step [176/225], Training Accuracy: 68.6967%, Training Loss: 0.7138%\n",
      "Epoch [19/300], Step [177/225], Training Accuracy: 68.7147%, Training Loss: 0.7139%\n",
      "Epoch [19/300], Step [178/225], Training Accuracy: 68.7237%, Training Loss: 0.7139%\n",
      "Epoch [19/300], Step [179/225], Training Accuracy: 68.7587%, Training Loss: 0.7136%\n",
      "Epoch [19/300], Step [180/225], Training Accuracy: 68.7587%, Training Loss: 0.7132%\n",
      "Epoch [19/300], Step [181/225], Training Accuracy: 68.7845%, Training Loss: 0.7128%\n",
      "Epoch [19/300], Step [182/225], Training Accuracy: 68.7586%, Training Loss: 0.7130%\n",
      "Epoch [19/300], Step [183/225], Training Accuracy: 68.7756%, Training Loss: 0.7125%\n",
      "Epoch [19/300], Step [184/225], Training Accuracy: 68.7840%, Training Loss: 0.7123%\n",
      "Epoch [19/300], Step [185/225], Training Accuracy: 68.8091%, Training Loss: 0.7119%\n",
      "Epoch [19/300], Step [186/225], Training Accuracy: 68.8508%, Training Loss: 0.7111%\n",
      "Epoch [19/300], Step [187/225], Training Accuracy: 68.8168%, Training Loss: 0.7112%\n",
      "Epoch [19/300], Step [188/225], Training Accuracy: 68.8747%, Training Loss: 0.7100%\n",
      "Epoch [19/300], Step [189/225], Training Accuracy: 68.9567%, Training Loss: 0.7087%\n",
      "Epoch [19/300], Step [190/225], Training Accuracy: 68.9803%, Training Loss: 0.7084%\n",
      "Epoch [19/300], Step [191/225], Training Accuracy: 68.9954%, Training Loss: 0.7085%\n",
      "Epoch [19/300], Step [192/225], Training Accuracy: 69.0592%, Training Loss: 0.7074%\n",
      "Epoch [19/300], Step [193/225], Training Accuracy: 69.1143%, Training Loss: 0.7067%\n",
      "Epoch [19/300], Step [194/225], Training Accuracy: 69.1124%, Training Loss: 0.7064%\n",
      "Epoch [19/300], Step [195/225], Training Accuracy: 69.1426%, Training Loss: 0.7056%\n",
      "Epoch [19/300], Step [196/225], Training Accuracy: 69.1566%, Training Loss: 0.7054%\n",
      "Epoch [19/300], Step [197/225], Training Accuracy: 69.1386%, Training Loss: 0.7061%\n",
      "Epoch [19/300], Step [198/225], Training Accuracy: 69.1525%, Training Loss: 0.7056%\n",
      "Epoch [19/300], Step [199/225], Training Accuracy: 69.1112%, Training Loss: 0.7053%\n",
      "Epoch [19/300], Step [200/225], Training Accuracy: 69.1172%, Training Loss: 0.7050%\n",
      "Epoch [19/300], Step [201/225], Training Accuracy: 69.1542%, Training Loss: 0.7046%\n",
      "Epoch [19/300], Step [202/225], Training Accuracy: 69.1986%, Training Loss: 0.7037%\n",
      "Epoch [19/300], Step [203/225], Training Accuracy: 69.1887%, Training Loss: 0.7043%\n",
      "Epoch [19/300], Step [204/225], Training Accuracy: 69.1636%, Training Loss: 0.7045%\n",
      "Epoch [19/300], Step [205/225], Training Accuracy: 69.1692%, Training Loss: 0.7041%\n",
      "Epoch [19/300], Step [206/225], Training Accuracy: 69.1520%, Training Loss: 0.7054%\n",
      "Epoch [19/300], Step [207/225], Training Accuracy: 69.1727%, Training Loss: 0.7051%\n",
      "Epoch [19/300], Step [208/225], Training Accuracy: 69.1782%, Training Loss: 0.7046%\n",
      "Epoch [19/300], Step [209/225], Training Accuracy: 69.1612%, Training Loss: 0.7050%\n",
      "Epoch [19/300], Step [210/225], Training Accuracy: 69.1369%, Training Loss: 0.7049%\n",
      "Epoch [19/300], Step [211/225], Training Accuracy: 69.1647%, Training Loss: 0.7042%\n",
      "Epoch [19/300], Step [212/225], Training Accuracy: 69.1922%, Training Loss: 0.7039%\n",
      "Epoch [19/300], Step [213/225], Training Accuracy: 69.2121%, Training Loss: 0.7040%\n",
      "Epoch [19/300], Step [214/225], Training Accuracy: 69.2392%, Training Loss: 0.7035%\n",
      "Epoch [19/300], Step [215/225], Training Accuracy: 69.2442%, Training Loss: 0.7034%\n",
      "Epoch [19/300], Step [216/225], Training Accuracy: 69.2274%, Training Loss: 0.7037%\n",
      "Epoch [19/300], Step [217/225], Training Accuracy: 69.2252%, Training Loss: 0.7035%\n",
      "Epoch [19/300], Step [218/225], Training Accuracy: 69.2087%, Training Loss: 0.7038%\n",
      "Epoch [19/300], Step [219/225], Training Accuracy: 69.2494%, Training Loss: 0.7032%\n",
      "Epoch [19/300], Step [220/225], Training Accuracy: 69.2614%, Training Loss: 0.7030%\n",
      "Epoch [19/300], Step [221/225], Training Accuracy: 69.2803%, Training Loss: 0.7032%\n",
      "Epoch [19/300], Step [222/225], Training Accuracy: 69.3131%, Training Loss: 0.7028%\n",
      "Epoch [19/300], Step [223/225], Training Accuracy: 69.3105%, Training Loss: 0.7036%\n",
      "Epoch [19/300], Step [224/225], Training Accuracy: 69.2941%, Training Loss: 0.7038%\n",
      "Epoch [19/300], Step [225/225], Training Accuracy: 69.3093%, Training Loss: 0.7035%\n",
      "Epoch [20/300], Step [1/225], Training Accuracy: 70.3125%, Training Loss: 0.7173%\n",
      "Epoch [20/300], Step [2/225], Training Accuracy: 67.9688%, Training Loss: 0.7375%\n",
      "Epoch [20/300], Step [3/225], Training Accuracy: 66.6667%, Training Loss: 0.7660%\n",
      "Epoch [20/300], Step [4/225], Training Accuracy: 66.0156%, Training Loss: 0.7637%\n",
      "Epoch [20/300], Step [5/225], Training Accuracy: 66.8750%, Training Loss: 0.7471%\n",
      "Epoch [20/300], Step [6/225], Training Accuracy: 65.3646%, Training Loss: 0.7633%\n",
      "Epoch [20/300], Step [7/225], Training Accuracy: 64.0625%, Training Loss: 0.7803%\n",
      "Epoch [20/300], Step [8/225], Training Accuracy: 64.6484%, Training Loss: 0.7699%\n",
      "Epoch [20/300], Step [9/225], Training Accuracy: 65.6250%, Training Loss: 0.7707%\n",
      "Epoch [20/300], Step [10/225], Training Accuracy: 65.0000%, Training Loss: 0.7772%\n",
      "Epoch [20/300], Step [11/225], Training Accuracy: 65.7670%, Training Loss: 0.7684%\n",
      "Epoch [20/300], Step [12/225], Training Accuracy: 66.2760%, Training Loss: 0.7606%\n",
      "Epoch [20/300], Step [13/225], Training Accuracy: 67.0673%, Training Loss: 0.7451%\n",
      "Epoch [20/300], Step [14/225], Training Accuracy: 67.4107%, Training Loss: 0.7425%\n",
      "Epoch [20/300], Step [15/225], Training Accuracy: 67.1875%, Training Loss: 0.7461%\n",
      "Epoch [20/300], Step [16/225], Training Accuracy: 67.1875%, Training Loss: 0.7420%\n",
      "Epoch [20/300], Step [17/225], Training Accuracy: 67.6471%, Training Loss: 0.7297%\n",
      "Epoch [20/300], Step [18/225], Training Accuracy: 67.6215%, Training Loss: 0.7278%\n",
      "Epoch [20/300], Step [19/225], Training Accuracy: 67.6809%, Training Loss: 0.7222%\n",
      "Epoch [20/300], Step [20/225], Training Accuracy: 67.7344%, Training Loss: 0.7211%\n",
      "Epoch [20/300], Step [21/225], Training Accuracy: 68.1548%, Training Loss: 0.7121%\n",
      "Epoch [20/300], Step [22/225], Training Accuracy: 67.4716%, Training Loss: 0.7175%\n",
      "Epoch [20/300], Step [23/225], Training Accuracy: 67.4592%, Training Loss: 0.7141%\n",
      "Epoch [20/300], Step [24/225], Training Accuracy: 67.6432%, Training Loss: 0.7123%\n",
      "Epoch [20/300], Step [25/225], Training Accuracy: 67.8750%, Training Loss: 0.7085%\n",
      "Epoch [20/300], Step [26/225], Training Accuracy: 68.3894%, Training Loss: 0.7012%\n",
      "Epoch [20/300], Step [27/225], Training Accuracy: 68.3449%, Training Loss: 0.7069%\n",
      "Epoch [20/300], Step [28/225], Training Accuracy: 68.6942%, Training Loss: 0.7041%\n",
      "Epoch [20/300], Step [29/225], Training Accuracy: 68.8578%, Training Loss: 0.7002%\n",
      "Epoch [20/300], Step [30/225], Training Accuracy: 68.8542%, Training Loss: 0.7065%\n",
      "Epoch [20/300], Step [31/225], Training Accuracy: 68.9012%, Training Loss: 0.7130%\n",
      "Epoch [20/300], Step [32/225], Training Accuracy: 68.9453%, Training Loss: 0.7117%\n",
      "Epoch [20/300], Step [33/225], Training Accuracy: 69.2708%, Training Loss: 0.7054%\n",
      "Epoch [20/300], Step [34/225], Training Accuracy: 69.3015%, Training Loss: 0.7072%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/300], Step [35/225], Training Accuracy: 69.0625%, Training Loss: 0.7114%\n",
      "Epoch [20/300], Step [36/225], Training Accuracy: 68.9670%, Training Loss: 0.7131%\n",
      "Epoch [20/300], Step [37/225], Training Accuracy: 69.2145%, Training Loss: 0.7105%\n",
      "Epoch [20/300], Step [38/225], Training Accuracy: 69.2434%, Training Loss: 0.7078%\n",
      "Epoch [20/300], Step [39/225], Training Accuracy: 69.4311%, Training Loss: 0.7044%\n",
      "Epoch [20/300], Step [40/225], Training Accuracy: 69.4141%, Training Loss: 0.7059%\n",
      "Epoch [20/300], Step [41/225], Training Accuracy: 69.0549%, Training Loss: 0.7118%\n",
      "Epoch [20/300], Step [42/225], Training Accuracy: 68.7500%, Training Loss: 0.7138%\n",
      "Epoch [20/300], Step [43/225], Training Accuracy: 68.6410%, Training Loss: 0.7156%\n",
      "Epoch [20/300], Step [44/225], Training Accuracy: 68.7500%, Training Loss: 0.7145%\n",
      "Epoch [20/300], Step [45/225], Training Accuracy: 68.8889%, Training Loss: 0.7138%\n",
      "Epoch [20/300], Step [46/225], Training Accuracy: 69.1236%, Training Loss: 0.7103%\n",
      "Epoch [20/300], Step [47/225], Training Accuracy: 69.1157%, Training Loss: 0.7090%\n",
      "Epoch [20/300], Step [48/225], Training Accuracy: 69.0755%, Training Loss: 0.7124%\n",
      "Epoch [20/300], Step [49/225], Training Accuracy: 69.1964%, Training Loss: 0.7086%\n",
      "Epoch [20/300], Step [50/225], Training Accuracy: 69.0312%, Training Loss: 0.7129%\n",
      "Epoch [20/300], Step [51/225], Training Accuracy: 69.3934%, Training Loss: 0.7062%\n",
      "Epoch [20/300], Step [52/225], Training Accuracy: 69.5913%, Training Loss: 0.7029%\n",
      "Epoch [20/300], Step [53/225], Training Accuracy: 69.6050%, Training Loss: 0.7031%\n",
      "Epoch [20/300], Step [54/225], Training Accuracy: 69.6759%, Training Loss: 0.7021%\n",
      "Epoch [20/300], Step [55/225], Training Accuracy: 69.7727%, Training Loss: 0.7023%\n",
      "Epoch [20/300], Step [56/225], Training Accuracy: 69.7824%, Training Loss: 0.7009%\n",
      "Epoch [20/300], Step [57/225], Training Accuracy: 69.7643%, Training Loss: 0.7004%\n",
      "Epoch [20/300], Step [58/225], Training Accuracy: 69.7198%, Training Loss: 0.7005%\n",
      "Epoch [20/300], Step [59/225], Training Accuracy: 69.6504%, Training Loss: 0.7009%\n",
      "Epoch [20/300], Step [60/225], Training Accuracy: 69.5573%, Training Loss: 0.7009%\n",
      "Epoch [20/300], Step [61/225], Training Accuracy: 69.3904%, Training Loss: 0.7050%\n",
      "Epoch [20/300], Step [62/225], Training Accuracy: 69.4556%, Training Loss: 0.7044%\n",
      "Epoch [20/300], Step [63/225], Training Accuracy: 69.4196%, Training Loss: 0.7036%\n",
      "Epoch [20/300], Step [64/225], Training Accuracy: 69.4580%, Training Loss: 0.7042%\n",
      "Epoch [20/300], Step [65/225], Training Accuracy: 69.3750%, Training Loss: 0.7062%\n",
      "Epoch [20/300], Step [66/225], Training Accuracy: 69.4366%, Training Loss: 0.7057%\n",
      "Epoch [20/300], Step [67/225], Training Accuracy: 69.2864%, Training Loss: 0.7071%\n",
      "Epoch [20/300], Step [68/225], Training Accuracy: 69.0487%, Training Loss: 0.7094%\n",
      "Epoch [20/300], Step [69/225], Training Accuracy: 68.9538%, Training Loss: 0.7129%\n",
      "Epoch [20/300], Step [70/225], Training Accuracy: 68.9955%, Training Loss: 0.7118%\n",
      "Epoch [20/300], Step [71/225], Training Accuracy: 69.0801%, Training Loss: 0.7110%\n",
      "Epoch [20/300], Step [72/225], Training Accuracy: 68.9453%, Training Loss: 0.7132%\n",
      "Epoch [20/300], Step [73/225], Training Accuracy: 69.0283%, Training Loss: 0.7115%\n",
      "Epoch [20/300], Step [74/225], Training Accuracy: 69.0034%, Training Loss: 0.7103%\n",
      "Epoch [20/300], Step [75/225], Training Accuracy: 68.9792%, Training Loss: 0.7110%\n",
      "Epoch [20/300], Step [76/225], Training Accuracy: 68.9145%, Training Loss: 0.7118%\n",
      "Epoch [20/300], Step [77/225], Training Accuracy: 69.0341%, Training Loss: 0.7114%\n",
      "Epoch [20/300], Step [78/225], Training Accuracy: 69.0905%, Training Loss: 0.7102%\n",
      "Epoch [20/300], Step [79/225], Training Accuracy: 69.1060%, Training Loss: 0.7097%\n",
      "Epoch [20/300], Step [80/225], Training Accuracy: 69.0234%, Training Loss: 0.7126%\n",
      "Epoch [20/300], Step [81/225], Training Accuracy: 69.0972%, Training Loss: 0.7113%\n",
      "Epoch [20/300], Step [82/225], Training Accuracy: 69.0930%, Training Loss: 0.7105%\n",
      "Epoch [20/300], Step [83/225], Training Accuracy: 69.0136%, Training Loss: 0.7122%\n",
      "Epoch [20/300], Step [84/225], Training Accuracy: 69.1406%, Training Loss: 0.7097%\n",
      "Epoch [20/300], Step [85/225], Training Accuracy: 69.1912%, Training Loss: 0.7087%\n",
      "Epoch [20/300], Step [86/225], Training Accuracy: 69.1497%, Training Loss: 0.7091%\n",
      "Epoch [20/300], Step [87/225], Training Accuracy: 69.0733%, Training Loss: 0.7133%\n",
      "Epoch [20/300], Step [88/225], Training Accuracy: 68.9631%, Training Loss: 0.7144%\n",
      "Epoch [20/300], Step [89/225], Training Accuracy: 68.8904%, Training Loss: 0.7172%\n",
      "Epoch [20/300], Step [90/225], Training Accuracy: 68.9236%, Training Loss: 0.7168%\n",
      "Epoch [20/300], Step [91/225], Training Accuracy: 68.9560%, Training Loss: 0.7188%\n",
      "Epoch [20/300], Step [92/225], Training Accuracy: 68.8179%, Training Loss: 0.7232%\n",
      "Epoch [20/300], Step [93/225], Training Accuracy: 68.8172%, Training Loss: 0.7226%\n",
      "Epoch [20/300], Step [94/225], Training Accuracy: 68.8497%, Training Loss: 0.7203%\n",
      "Epoch [20/300], Step [95/225], Training Accuracy: 68.7500%, Training Loss: 0.7214%\n",
      "Epoch [20/300], Step [96/225], Training Accuracy: 68.7826%, Training Loss: 0.7210%\n",
      "Epoch [20/300], Step [97/225], Training Accuracy: 68.7339%, Training Loss: 0.7229%\n",
      "Epoch [20/300], Step [98/225], Training Accuracy: 68.7659%, Training Loss: 0.7216%\n",
      "Epoch [20/300], Step [99/225], Training Accuracy: 68.8447%, Training Loss: 0.7202%\n",
      "Epoch [20/300], Step [100/225], Training Accuracy: 68.7500%, Training Loss: 0.7227%\n",
      "Epoch [20/300], Step [101/225], Training Accuracy: 68.7191%, Training Loss: 0.7237%\n",
      "Epoch [20/300], Step [102/225], Training Accuracy: 68.6887%, Training Loss: 0.7243%\n",
      "Epoch [20/300], Step [103/225], Training Accuracy: 68.6742%, Training Loss: 0.7237%\n",
      "Epoch [20/300], Step [104/225], Training Accuracy: 68.6599%, Training Loss: 0.7227%\n",
      "Epoch [20/300], Step [105/225], Training Accuracy: 68.6161%, Training Loss: 0.7230%\n",
      "Epoch [20/300], Step [106/225], Training Accuracy: 68.6616%, Training Loss: 0.7227%\n",
      "Epoch [20/300], Step [107/225], Training Accuracy: 68.5894%, Training Loss: 0.7239%\n",
      "Epoch [20/300], Step [108/225], Training Accuracy: 68.6343%, Training Loss: 0.7231%\n",
      "Epoch [20/300], Step [109/225], Training Accuracy: 68.6353%, Training Loss: 0.7233%\n",
      "Epoch [20/300], Step [110/225], Training Accuracy: 68.6222%, Training Loss: 0.7249%\n",
      "Epoch [20/300], Step [111/225], Training Accuracy: 68.5952%, Training Loss: 0.7244%\n",
      "Epoch [20/300], Step [112/225], Training Accuracy: 68.6105%, Training Loss: 0.7247%\n",
      "Epoch [20/300], Step [113/225], Training Accuracy: 68.6394%, Training Loss: 0.7234%\n",
      "Epoch [20/300], Step [114/225], Training Accuracy: 68.6404%, Training Loss: 0.7228%\n",
      "Epoch [20/300], Step [115/225], Training Accuracy: 68.6957%, Training Loss: 0.7222%\n",
      "Epoch [20/300], Step [116/225], Training Accuracy: 68.7231%, Training Loss: 0.7224%\n",
      "Epoch [20/300], Step [117/225], Training Accuracy: 68.6432%, Training Loss: 0.7232%\n",
      "Epoch [20/300], Step [118/225], Training Accuracy: 68.6573%, Training Loss: 0.7233%\n",
      "Epoch [20/300], Step [119/225], Training Accuracy: 68.6712%, Training Loss: 0.7222%\n",
      "Epoch [20/300], Step [120/225], Training Accuracy: 68.6849%, Training Loss: 0.7212%\n",
      "Epoch [20/300], Step [121/225], Training Accuracy: 68.6725%, Training Loss: 0.7212%\n",
      "Epoch [20/300], Step [122/225], Training Accuracy: 68.6860%, Training Loss: 0.7204%\n",
      "Epoch [20/300], Step [123/225], Training Accuracy: 68.6611%, Training Loss: 0.7200%\n",
      "Epoch [20/300], Step [124/225], Training Accuracy: 68.6870%, Training Loss: 0.7189%\n",
      "Epoch [20/300], Step [125/225], Training Accuracy: 68.7125%, Training Loss: 0.7184%\n",
      "Epoch [20/300], Step [126/225], Training Accuracy: 68.6880%, Training Loss: 0.7191%\n",
      "Epoch [20/300], Step [127/225], Training Accuracy: 68.6885%, Training Loss: 0.7193%\n",
      "Epoch [20/300], Step [128/225], Training Accuracy: 68.6768%, Training Loss: 0.7193%\n",
      "Epoch [20/300], Step [129/225], Training Accuracy: 68.6531%, Training Loss: 0.7190%\n",
      "Epoch [20/300], Step [130/225], Training Accuracy: 68.6659%, Training Loss: 0.7189%\n",
      "Epoch [20/300], Step [131/225], Training Accuracy: 68.6427%, Training Loss: 0.7195%\n",
      "Epoch [20/300], Step [132/225], Training Accuracy: 68.6316%, Training Loss: 0.7199%\n",
      "Epoch [20/300], Step [133/225], Training Accuracy: 68.6795%, Training Loss: 0.7191%\n",
      "Epoch [20/300], Step [134/225], Training Accuracy: 68.5984%, Training Loss: 0.7204%\n",
      "Epoch [20/300], Step [135/225], Training Accuracy: 68.6343%, Training Loss: 0.7203%\n",
      "Epoch [20/300], Step [136/225], Training Accuracy: 68.6351%, Training Loss: 0.7197%\n",
      "Epoch [20/300], Step [137/225], Training Accuracy: 68.6588%, Training Loss: 0.7189%\n",
      "Epoch [20/300], Step [138/225], Training Accuracy: 68.7953%, Training Loss: 0.7174%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/300], Step [139/225], Training Accuracy: 68.7950%, Training Loss: 0.7188%\n",
      "Epoch [20/300], Step [140/225], Training Accuracy: 68.7500%, Training Loss: 0.7187%\n",
      "Epoch [20/300], Step [141/225], Training Accuracy: 68.7832%, Training Loss: 0.7176%\n",
      "Epoch [20/300], Step [142/225], Training Accuracy: 68.7500%, Training Loss: 0.7183%\n",
      "Epoch [20/300], Step [143/225], Training Accuracy: 68.7609%, Training Loss: 0.7181%\n",
      "Epoch [20/300], Step [144/225], Training Accuracy: 68.7826%, Training Loss: 0.7172%\n",
      "Epoch [20/300], Step [145/225], Training Accuracy: 68.7284%, Training Loss: 0.7171%\n",
      "Epoch [20/300], Step [146/225], Training Accuracy: 68.7179%, Training Loss: 0.7171%\n",
      "Epoch [20/300], Step [147/225], Training Accuracy: 68.7181%, Training Loss: 0.7175%\n",
      "Epoch [20/300], Step [148/225], Training Accuracy: 68.8028%, Training Loss: 0.7163%\n",
      "Epoch [20/300], Step [149/225], Training Accuracy: 68.7815%, Training Loss: 0.7163%\n",
      "Epoch [20/300], Step [150/225], Training Accuracy: 68.8333%, Training Loss: 0.7160%\n",
      "Epoch [20/300], Step [151/225], Training Accuracy: 68.8535%, Training Loss: 0.7154%\n",
      "Epoch [20/300], Step [152/225], Training Accuracy: 68.8528%, Training Loss: 0.7159%\n",
      "Epoch [20/300], Step [153/225], Training Accuracy: 68.8521%, Training Loss: 0.7157%\n",
      "Epoch [20/300], Step [154/225], Training Accuracy: 68.8718%, Training Loss: 0.7159%\n",
      "Epoch [20/300], Step [155/225], Training Accuracy: 68.8810%, Training Loss: 0.7157%\n",
      "Epoch [20/300], Step [156/225], Training Accuracy: 68.9103%, Training Loss: 0.7163%\n",
      "Epoch [20/300], Step [157/225], Training Accuracy: 68.8993%, Training Loss: 0.7156%\n",
      "Epoch [20/300], Step [158/225], Training Accuracy: 68.8884%, Training Loss: 0.7159%\n",
      "Epoch [20/300], Step [159/225], Training Accuracy: 68.7893%, Training Loss: 0.7169%\n",
      "Epoch [20/300], Step [160/225], Training Accuracy: 68.8477%, Training Loss: 0.7160%\n",
      "Epoch [20/300], Step [161/225], Training Accuracy: 68.7791%, Training Loss: 0.7175%\n",
      "Epoch [20/300], Step [162/225], Training Accuracy: 68.7693%, Training Loss: 0.7177%\n",
      "Epoch [20/300], Step [163/225], Training Accuracy: 68.7883%, Training Loss: 0.7183%\n",
      "Epoch [20/300], Step [164/225], Training Accuracy: 68.7881%, Training Loss: 0.7187%\n",
      "Epoch [20/300], Step [165/225], Training Accuracy: 68.7595%, Training Loss: 0.7193%\n",
      "Epoch [20/300], Step [166/225], Training Accuracy: 68.7971%, Training Loss: 0.7197%\n",
      "Epoch [20/300], Step [167/225], Training Accuracy: 68.6939%, Training Loss: 0.7215%\n",
      "Epoch [20/300], Step [168/225], Training Accuracy: 68.7314%, Training Loss: 0.7205%\n",
      "Epoch [20/300], Step [169/225], Training Accuracy: 68.7592%, Training Loss: 0.7200%\n",
      "Epoch [20/300], Step [170/225], Training Accuracy: 68.7500%, Training Loss: 0.7198%\n",
      "Epoch [20/300], Step [171/225], Training Accuracy: 68.7591%, Training Loss: 0.7196%\n",
      "Epoch [20/300], Step [172/225], Training Accuracy: 68.7591%, Training Loss: 0.7195%\n",
      "Epoch [20/300], Step [173/225], Training Accuracy: 68.7771%, Training Loss: 0.7190%\n",
      "Epoch [20/300], Step [174/225], Training Accuracy: 68.8218%, Training Loss: 0.7183%\n",
      "Epoch [20/300], Step [175/225], Training Accuracy: 68.8393%, Training Loss: 0.7180%\n",
      "Epoch [20/300], Step [176/225], Training Accuracy: 68.9009%, Training Loss: 0.7171%\n",
      "Epoch [20/300], Step [177/225], Training Accuracy: 68.9442%, Training Loss: 0.7163%\n",
      "Epoch [20/300], Step [178/225], Training Accuracy: 68.9782%, Training Loss: 0.7155%\n",
      "Epoch [20/300], Step [179/225], Training Accuracy: 69.0293%, Training Loss: 0.7144%\n",
      "Epoch [20/300], Step [180/225], Training Accuracy: 69.0799%, Training Loss: 0.7135%\n",
      "Epoch [20/300], Step [181/225], Training Accuracy: 69.0521%, Training Loss: 0.7136%\n",
      "Epoch [20/300], Step [182/225], Training Accuracy: 69.0591%, Training Loss: 0.7134%\n",
      "Epoch [20/300], Step [183/225], Training Accuracy: 69.0745%, Training Loss: 0.7128%\n",
      "Epoch [20/300], Step [184/225], Training Accuracy: 69.1406%, Training Loss: 0.7118%\n",
      "Epoch [20/300], Step [185/225], Training Accuracy: 69.1807%, Training Loss: 0.7107%\n",
      "Epoch [20/300], Step [186/225], Training Accuracy: 69.2288%, Training Loss: 0.7098%\n",
      "Epoch [20/300], Step [187/225], Training Accuracy: 69.2096%, Training Loss: 0.7098%\n",
      "Epoch [20/300], Step [188/225], Training Accuracy: 69.2404%, Training Loss: 0.7087%\n",
      "Epoch [20/300], Step [189/225], Training Accuracy: 69.2708%, Training Loss: 0.7080%\n",
      "Epoch [20/300], Step [190/225], Training Accuracy: 69.3174%, Training Loss: 0.7076%\n",
      "Epoch [20/300], Step [191/225], Training Accuracy: 69.3635%, Training Loss: 0.7070%\n",
      "Epoch [20/300], Step [192/225], Training Accuracy: 69.4417%, Training Loss: 0.7055%\n",
      "Epoch [20/300], Step [193/225], Training Accuracy: 69.4543%, Training Loss: 0.7057%\n",
      "Epoch [20/300], Step [194/225], Training Accuracy: 69.4749%, Training Loss: 0.7052%\n",
      "Epoch [20/300], Step [195/225], Training Accuracy: 69.4952%, Training Loss: 0.7048%\n",
      "Epoch [20/300], Step [196/225], Training Accuracy: 69.4914%, Training Loss: 0.7045%\n",
      "Epoch [20/300], Step [197/225], Training Accuracy: 69.5114%, Training Loss: 0.7042%\n",
      "Epoch [20/300], Step [198/225], Training Accuracy: 69.5628%, Training Loss: 0.7031%\n",
      "Epoch [20/300], Step [199/225], Training Accuracy: 69.5980%, Training Loss: 0.7023%\n",
      "Epoch [20/300], Step [200/225], Training Accuracy: 69.5625%, Training Loss: 0.7039%\n",
      "Epoch [20/300], Step [201/225], Training Accuracy: 69.5351%, Training Loss: 0.7041%\n",
      "Epoch [20/300], Step [202/225], Training Accuracy: 69.5622%, Training Loss: 0.7034%\n",
      "Epoch [20/300], Step [203/225], Training Accuracy: 69.6121%, Training Loss: 0.7027%\n",
      "Epoch [20/300], Step [204/225], Training Accuracy: 69.5772%, Training Loss: 0.7027%\n",
      "Epoch [20/300], Step [205/225], Training Accuracy: 69.5884%, Training Loss: 0.7018%\n",
      "Epoch [20/300], Step [206/225], Training Accuracy: 69.6071%, Training Loss: 0.7014%\n",
      "Epoch [20/300], Step [207/225], Training Accuracy: 69.6482%, Training Loss: 0.7013%\n",
      "Epoch [20/300], Step [208/225], Training Accuracy: 69.6514%, Training Loss: 0.7006%\n",
      "Epoch [20/300], Step [209/225], Training Accuracy: 69.6471%, Training Loss: 0.7006%\n",
      "Epoch [20/300], Step [210/225], Training Accuracy: 69.6205%, Training Loss: 0.7008%\n",
      "Epoch [20/300], Step [211/225], Training Accuracy: 69.6386%, Training Loss: 0.7002%\n",
      "Epoch [20/300], Step [212/225], Training Accuracy: 69.6565%, Training Loss: 0.7001%\n",
      "Epoch [20/300], Step [213/225], Training Accuracy: 69.6743%, Training Loss: 0.6999%\n",
      "Epoch [20/300], Step [214/225], Training Accuracy: 69.7284%, Training Loss: 0.6992%\n",
      "Epoch [20/300], Step [215/225], Training Accuracy: 69.6802%, Training Loss: 0.6999%\n",
      "Epoch [20/300], Step [216/225], Training Accuracy: 69.6759%, Training Loss: 0.6999%\n",
      "Epoch [20/300], Step [217/225], Training Accuracy: 69.6717%, Training Loss: 0.6997%\n",
      "Epoch [20/300], Step [218/225], Training Accuracy: 69.6316%, Training Loss: 0.7001%\n",
      "Epoch [20/300], Step [219/225], Training Accuracy: 69.6775%, Training Loss: 0.6995%\n",
      "Epoch [20/300], Step [220/225], Training Accuracy: 69.6946%, Training Loss: 0.6993%\n",
      "Epoch [20/300], Step [221/225], Training Accuracy: 69.6974%, Training Loss: 0.6993%\n",
      "Epoch [20/300], Step [222/225], Training Accuracy: 69.6931%, Training Loss: 0.6989%\n",
      "Epoch [20/300], Step [223/225], Training Accuracy: 69.7029%, Training Loss: 0.6988%\n",
      "Epoch [20/300], Step [224/225], Training Accuracy: 69.6987%, Training Loss: 0.6988%\n",
      "Epoch [20/300], Step [225/225], Training Accuracy: 69.6984%, Training Loss: 0.6986%\n",
      "Epoch [21/300], Step [1/225], Training Accuracy: 76.5625%, Training Loss: 0.5589%\n",
      "Epoch [21/300], Step [2/225], Training Accuracy: 75.0000%, Training Loss: 0.6350%\n",
      "Epoch [21/300], Step [3/225], Training Accuracy: 71.3542%, Training Loss: 0.6585%\n",
      "Epoch [21/300], Step [4/225], Training Accuracy: 67.5781%, Training Loss: 0.6990%\n",
      "Epoch [21/300], Step [5/225], Training Accuracy: 68.1250%, Training Loss: 0.6799%\n",
      "Epoch [21/300], Step [6/225], Training Accuracy: 69.2708%, Training Loss: 0.6847%\n",
      "Epoch [21/300], Step [7/225], Training Accuracy: 70.9821%, Training Loss: 0.6561%\n",
      "Epoch [21/300], Step [8/225], Training Accuracy: 71.2891%, Training Loss: 0.6647%\n",
      "Epoch [21/300], Step [9/225], Training Accuracy: 70.4861%, Training Loss: 0.6641%\n",
      "Epoch [21/300], Step [10/225], Training Accuracy: 69.2188%, Training Loss: 0.6727%\n",
      "Epoch [21/300], Step [11/225], Training Accuracy: 69.0341%, Training Loss: 0.6835%\n",
      "Epoch [21/300], Step [12/225], Training Accuracy: 69.4010%, Training Loss: 0.6881%\n",
      "Epoch [21/300], Step [13/225], Training Accuracy: 70.0721%, Training Loss: 0.6708%\n",
      "Epoch [21/300], Step [14/225], Training Accuracy: 70.6473%, Training Loss: 0.6545%\n",
      "Epoch [21/300], Step [15/225], Training Accuracy: 71.2500%, Training Loss: 0.6476%\n",
      "Epoch [21/300], Step [16/225], Training Accuracy: 71.1914%, Training Loss: 0.6512%\n",
      "Epoch [21/300], Step [17/225], Training Accuracy: 70.7721%, Training Loss: 0.6533%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/300], Step [18/225], Training Accuracy: 70.9201%, Training Loss: 0.6509%\n",
      "Epoch [21/300], Step [19/225], Training Accuracy: 71.1349%, Training Loss: 0.6456%\n",
      "Epoch [21/300], Step [20/225], Training Accuracy: 71.4062%, Training Loss: 0.6365%\n",
      "Epoch [21/300], Step [21/225], Training Accuracy: 71.5774%, Training Loss: 0.6347%\n",
      "Epoch [21/300], Step [22/225], Training Accuracy: 71.0227%, Training Loss: 0.6391%\n",
      "Epoch [21/300], Step [23/225], Training Accuracy: 71.0598%, Training Loss: 0.6372%\n",
      "Epoch [21/300], Step [24/225], Training Accuracy: 71.0938%, Training Loss: 0.6379%\n",
      "Epoch [21/300], Step [25/225], Training Accuracy: 71.4375%, Training Loss: 0.6324%\n",
      "Epoch [21/300], Step [26/225], Training Accuracy: 71.3942%, Training Loss: 0.6288%\n",
      "Epoch [21/300], Step [27/225], Training Accuracy: 71.4699%, Training Loss: 0.6328%\n",
      "Epoch [21/300], Step [28/225], Training Accuracy: 71.9308%, Training Loss: 0.6245%\n",
      "Epoch [21/300], Step [29/225], Training Accuracy: 72.1983%, Training Loss: 0.6208%\n",
      "Epoch [21/300], Step [30/225], Training Accuracy: 72.1354%, Training Loss: 0.6199%\n",
      "Epoch [21/300], Step [31/225], Training Accuracy: 72.1270%, Training Loss: 0.6258%\n",
      "Epoch [21/300], Step [32/225], Training Accuracy: 71.9727%, Training Loss: 0.6313%\n",
      "Epoch [21/300], Step [33/225], Training Accuracy: 71.8277%, Training Loss: 0.6318%\n",
      "Epoch [21/300], Step [34/225], Training Accuracy: 71.7371%, Training Loss: 0.6342%\n",
      "Epoch [21/300], Step [35/225], Training Accuracy: 71.7857%, Training Loss: 0.6335%\n",
      "Epoch [21/300], Step [36/225], Training Accuracy: 71.8316%, Training Loss: 0.6339%\n",
      "Epoch [21/300], Step [37/225], Training Accuracy: 71.8328%, Training Loss: 0.6331%\n",
      "Epoch [21/300], Step [38/225], Training Accuracy: 71.7105%, Training Loss: 0.6346%\n",
      "Epoch [21/300], Step [39/225], Training Accuracy: 71.5545%, Training Loss: 0.6413%\n",
      "Epoch [21/300], Step [40/225], Training Accuracy: 71.5234%, Training Loss: 0.6435%\n",
      "Epoch [21/300], Step [41/225], Training Accuracy: 71.3034%, Training Loss: 0.6463%\n",
      "Epoch [21/300], Step [42/225], Training Accuracy: 71.3914%, Training Loss: 0.6444%\n",
      "Epoch [21/300], Step [43/225], Training Accuracy: 71.3299%, Training Loss: 0.6451%\n",
      "Epoch [21/300], Step [44/225], Training Accuracy: 71.4134%, Training Loss: 0.6435%\n",
      "Epoch [21/300], Step [45/225], Training Accuracy: 71.5278%, Training Loss: 0.6417%\n",
      "Epoch [21/300], Step [46/225], Training Accuracy: 71.4334%, Training Loss: 0.6441%\n",
      "Epoch [21/300], Step [47/225], Training Accuracy: 71.2766%, Training Loss: 0.6460%\n",
      "Epoch [21/300], Step [48/225], Training Accuracy: 71.1589%, Training Loss: 0.6531%\n",
      "Epoch [21/300], Step [49/225], Training Accuracy: 71.1416%, Training Loss: 0.6513%\n",
      "Epoch [21/300], Step [50/225], Training Accuracy: 71.1250%, Training Loss: 0.6516%\n",
      "Epoch [21/300], Step [51/225], Training Accuracy: 71.2623%, Training Loss: 0.6493%\n",
      "Epoch [21/300], Step [52/225], Training Accuracy: 71.3642%, Training Loss: 0.6490%\n",
      "Epoch [21/300], Step [53/225], Training Accuracy: 71.1675%, Training Loss: 0.6542%\n",
      "Epoch [21/300], Step [54/225], Training Accuracy: 71.0069%, Training Loss: 0.6577%\n",
      "Epoch [21/300], Step [55/225], Training Accuracy: 70.9091%, Training Loss: 0.6612%\n",
      "Epoch [21/300], Step [56/225], Training Accuracy: 70.8426%, Training Loss: 0.6619%\n",
      "Epoch [21/300], Step [57/225], Training Accuracy: 70.8059%, Training Loss: 0.6620%\n",
      "Epoch [21/300], Step [58/225], Training Accuracy: 70.7166%, Training Loss: 0.6666%\n",
      "Epoch [21/300], Step [59/225], Training Accuracy: 70.7362%, Training Loss: 0.6663%\n",
      "Epoch [21/300], Step [60/225], Training Accuracy: 70.6510%, Training Loss: 0.6682%\n",
      "Epoch [21/300], Step [61/225], Training Accuracy: 70.6199%, Training Loss: 0.6721%\n",
      "Epoch [21/300], Step [62/225], Training Accuracy: 70.6401%, Training Loss: 0.6703%\n",
      "Epoch [21/300], Step [63/225], Training Accuracy: 70.7341%, Training Loss: 0.6699%\n",
      "Epoch [21/300], Step [64/225], Training Accuracy: 70.8252%, Training Loss: 0.6676%\n",
      "Epoch [21/300], Step [65/225], Training Accuracy: 70.6971%, Training Loss: 0.6696%\n",
      "Epoch [21/300], Step [66/225], Training Accuracy: 70.7623%, Training Loss: 0.6686%\n",
      "Epoch [21/300], Step [67/225], Training Accuracy: 70.7789%, Training Loss: 0.6684%\n",
      "Epoch [21/300], Step [68/225], Training Accuracy: 70.6572%, Training Loss: 0.6697%\n",
      "Epoch [21/300], Step [69/225], Training Accuracy: 70.5163%, Training Loss: 0.6704%\n",
      "Epoch [21/300], Step [70/225], Training Accuracy: 70.5804%, Training Loss: 0.6699%\n",
      "Epoch [21/300], Step [71/225], Training Accuracy: 70.5766%, Training Loss: 0.6703%\n",
      "Epoch [21/300], Step [72/225], Training Accuracy: 70.5512%, Training Loss: 0.6711%\n",
      "Epoch [21/300], Step [73/225], Training Accuracy: 70.5693%, Training Loss: 0.6697%\n",
      "Epoch [21/300], Step [74/225], Training Accuracy: 70.5659%, Training Loss: 0.6681%\n",
      "Epoch [21/300], Step [75/225], Training Accuracy: 70.5208%, Training Loss: 0.6675%\n",
      "Epoch [21/300], Step [76/225], Training Accuracy: 70.3331%, Training Loss: 0.6718%\n",
      "Epoch [21/300], Step [77/225], Training Accuracy: 70.3937%, Training Loss: 0.6713%\n",
      "Epoch [21/300], Step [78/225], Training Accuracy: 70.3926%, Training Loss: 0.6711%\n",
      "Epoch [21/300], Step [79/225], Training Accuracy: 70.3916%, Training Loss: 0.6712%\n",
      "Epoch [21/300], Step [80/225], Training Accuracy: 70.5273%, Training Loss: 0.6680%\n",
      "Epoch [21/300], Step [81/225], Training Accuracy: 70.5054%, Training Loss: 0.6696%\n",
      "Epoch [21/300], Step [82/225], Training Accuracy: 70.5793%, Training Loss: 0.6686%\n",
      "Epoch [21/300], Step [83/225], Training Accuracy: 70.6325%, Training Loss: 0.6678%\n",
      "Epoch [21/300], Step [84/225], Training Accuracy: 70.7031%, Training Loss: 0.6663%\n",
      "Epoch [21/300], Step [85/225], Training Accuracy: 70.6985%, Training Loss: 0.6678%\n",
      "Epoch [21/300], Step [86/225], Training Accuracy: 70.7485%, Training Loss: 0.6668%\n",
      "Epoch [21/300], Step [87/225], Training Accuracy: 70.6717%, Training Loss: 0.6678%\n",
      "Epoch [21/300], Step [88/225], Training Accuracy: 70.6143%, Training Loss: 0.6685%\n",
      "Epoch [21/300], Step [89/225], Training Accuracy: 70.4705%, Training Loss: 0.6706%\n",
      "Epoch [21/300], Step [90/225], Training Accuracy: 70.3993%, Training Loss: 0.6709%\n",
      "Epoch [21/300], Step [91/225], Training Accuracy: 70.4155%, Training Loss: 0.6724%\n",
      "Epoch [21/300], Step [92/225], Training Accuracy: 70.3804%, Training Loss: 0.6742%\n",
      "Epoch [21/300], Step [93/225], Training Accuracy: 70.3629%, Training Loss: 0.6743%\n",
      "Epoch [21/300], Step [94/225], Training Accuracy: 70.3457%, Training Loss: 0.6740%\n",
      "Epoch [21/300], Step [95/225], Training Accuracy: 70.3618%, Training Loss: 0.6746%\n",
      "Epoch [21/300], Step [96/225], Training Accuracy: 70.4264%, Training Loss: 0.6738%\n",
      "Epoch [21/300], Step [97/225], Training Accuracy: 70.3769%, Training Loss: 0.6738%\n",
      "Epoch [21/300], Step [98/225], Training Accuracy: 70.3922%, Training Loss: 0.6732%\n",
      "Epoch [21/300], Step [99/225], Training Accuracy: 70.3756%, Training Loss: 0.6732%\n",
      "Epoch [21/300], Step [100/225], Training Accuracy: 70.3125%, Training Loss: 0.6747%\n",
      "Epoch [21/300], Step [101/225], Training Accuracy: 70.2816%, Training Loss: 0.6745%\n",
      "Epoch [21/300], Step [102/225], Training Accuracy: 70.3278%, Training Loss: 0.6741%\n",
      "Epoch [21/300], Step [103/225], Training Accuracy: 70.2670%, Training Loss: 0.6754%\n",
      "Epoch [21/300], Step [104/225], Training Accuracy: 70.2073%, Training Loss: 0.6772%\n",
      "Epoch [21/300], Step [105/225], Training Accuracy: 70.2827%, Training Loss: 0.6761%\n",
      "Epoch [21/300], Step [106/225], Training Accuracy: 70.2535%, Training Loss: 0.6763%\n",
      "Epoch [21/300], Step [107/225], Training Accuracy: 70.0789%, Training Loss: 0.6786%\n",
      "Epoch [21/300], Step [108/225], Training Accuracy: 70.1244%, Training Loss: 0.6794%\n",
      "Epoch [21/300], Step [109/225], Training Accuracy: 70.1405%, Training Loss: 0.6784%\n",
      "Epoch [21/300], Step [110/225], Training Accuracy: 70.1562%, Training Loss: 0.6786%\n",
      "Epoch [21/300], Step [111/225], Training Accuracy: 70.0873%, Training Loss: 0.6793%\n",
      "Epoch [21/300], Step [112/225], Training Accuracy: 70.0753%, Training Loss: 0.6796%\n",
      "Epoch [21/300], Step [113/225], Training Accuracy: 70.0636%, Training Loss: 0.6797%\n",
      "Epoch [21/300], Step [114/225], Training Accuracy: 70.0384%, Training Loss: 0.6802%\n",
      "Epoch [21/300], Step [115/225], Training Accuracy: 70.0951%, Training Loss: 0.6797%\n",
      "Epoch [21/300], Step [116/225], Training Accuracy: 70.0700%, Training Loss: 0.6800%\n",
      "Epoch [21/300], Step [117/225], Training Accuracy: 70.0187%, Training Loss: 0.6824%\n",
      "Epoch [21/300], Step [118/225], Training Accuracy: 70.0344%, Training Loss: 0.6813%\n",
      "Epoch [21/300], Step [119/225], Training Accuracy: 70.0893%, Training Loss: 0.6800%\n",
      "Epoch [21/300], Step [120/225], Training Accuracy: 70.0651%, Training Loss: 0.6799%\n",
      "Epoch [21/300], Step [121/225], Training Accuracy: 70.0542%, Training Loss: 0.6799%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/300], Step [122/225], Training Accuracy: 70.0435%, Training Loss: 0.6799%\n",
      "Epoch [21/300], Step [123/225], Training Accuracy: 70.0457%, Training Loss: 0.6791%\n",
      "Epoch [21/300], Step [124/225], Training Accuracy: 70.1109%, Training Loss: 0.6780%\n",
      "Epoch [21/300], Step [125/225], Training Accuracy: 70.1250%, Training Loss: 0.6783%\n",
      "Epoch [21/300], Step [126/225], Training Accuracy: 70.1389%, Training Loss: 0.6779%\n",
      "Epoch [21/300], Step [127/225], Training Accuracy: 70.1403%, Training Loss: 0.6781%\n",
      "Epoch [21/300], Step [128/225], Training Accuracy: 70.1294%, Training Loss: 0.6778%\n",
      "Epoch [21/300], Step [129/225], Training Accuracy: 70.1550%, Training Loss: 0.6776%\n",
      "Epoch [21/300], Step [130/225], Training Accuracy: 70.1322%, Training Loss: 0.6781%\n",
      "Epoch [21/300], Step [131/225], Training Accuracy: 70.0859%, Training Loss: 0.6787%\n",
      "Epoch [21/300], Step [132/225], Training Accuracy: 70.1113%, Training Loss: 0.6780%\n",
      "Epoch [21/300], Step [133/225], Training Accuracy: 70.1480%, Training Loss: 0.6777%\n",
      "Epoch [21/300], Step [134/225], Training Accuracy: 70.1726%, Training Loss: 0.6779%\n",
      "Epoch [21/300], Step [135/225], Training Accuracy: 70.2083%, Training Loss: 0.6771%\n",
      "Epoch [21/300], Step [136/225], Training Accuracy: 70.2321%, Training Loss: 0.6762%\n",
      "Epoch [21/300], Step [137/225], Training Accuracy: 70.2213%, Training Loss: 0.6760%\n",
      "Epoch [21/300], Step [138/225], Training Accuracy: 70.2672%, Training Loss: 0.6749%\n",
      "Epoch [21/300], Step [139/225], Training Accuracy: 70.3013%, Training Loss: 0.6753%\n",
      "Epoch [21/300], Step [140/225], Training Accuracy: 70.2902%, Training Loss: 0.6749%\n",
      "Epoch [21/300], Step [141/225], Training Accuracy: 70.3125%, Training Loss: 0.6749%\n",
      "Epoch [21/300], Step [142/225], Training Accuracy: 70.2465%, Training Loss: 0.6760%\n",
      "Epoch [21/300], Step [143/225], Training Accuracy: 70.2251%, Training Loss: 0.6759%\n",
      "Epoch [21/300], Step [144/225], Training Accuracy: 70.2257%, Training Loss: 0.6763%\n",
      "Epoch [21/300], Step [145/225], Training Accuracy: 70.2155%, Training Loss: 0.6765%\n",
      "Epoch [21/300], Step [146/225], Training Accuracy: 70.1948%, Training Loss: 0.6767%\n",
      "Epoch [21/300], Step [147/225], Training Accuracy: 70.2062%, Training Loss: 0.6763%\n",
      "Epoch [21/300], Step [148/225], Training Accuracy: 70.1753%, Training Loss: 0.6769%\n",
      "Epoch [21/300], Step [149/225], Training Accuracy: 70.1971%, Training Loss: 0.6767%\n",
      "Epoch [21/300], Step [150/225], Training Accuracy: 70.2292%, Training Loss: 0.6755%\n",
      "Epoch [21/300], Step [151/225], Training Accuracy: 70.2504%, Training Loss: 0.6743%\n",
      "Epoch [21/300], Step [152/225], Training Accuracy: 70.2611%, Training Loss: 0.6745%\n",
      "Epoch [21/300], Step [153/225], Training Accuracy: 70.2512%, Training Loss: 0.6746%\n",
      "Epoch [21/300], Step [154/225], Training Accuracy: 70.2922%, Training Loss: 0.6744%\n",
      "Epoch [21/300], Step [155/225], Training Accuracy: 70.2923%, Training Loss: 0.6746%\n",
      "Epoch [21/300], Step [156/225], Training Accuracy: 70.3025%, Training Loss: 0.6747%\n",
      "Epoch [21/300], Step [157/225], Training Accuracy: 70.3424%, Training Loss: 0.6741%\n",
      "Epoch [21/300], Step [158/225], Training Accuracy: 70.3422%, Training Loss: 0.6752%\n",
      "Epoch [21/300], Step [159/225], Training Accuracy: 70.3322%, Training Loss: 0.6751%\n",
      "Epoch [21/300], Step [160/225], Training Accuracy: 70.3516%, Training Loss: 0.6751%\n",
      "Epoch [21/300], Step [161/225], Training Accuracy: 70.3222%, Training Loss: 0.6758%\n",
      "Epoch [21/300], Step [162/225], Training Accuracy: 70.3125%, Training Loss: 0.6759%\n",
      "Epoch [21/300], Step [163/225], Training Accuracy: 70.3125%, Training Loss: 0.6757%\n",
      "Epoch [21/300], Step [164/225], Training Accuracy: 70.3697%, Training Loss: 0.6748%\n",
      "Epoch [21/300], Step [165/225], Training Accuracy: 70.3977%, Training Loss: 0.6749%\n",
      "Epoch [21/300], Step [166/225], Training Accuracy: 70.4066%, Training Loss: 0.6745%\n",
      "Epoch [21/300], Step [167/225], Training Accuracy: 70.4248%, Training Loss: 0.6741%\n",
      "Epoch [21/300], Step [168/225], Training Accuracy: 70.4427%, Training Loss: 0.6739%\n",
      "Epoch [21/300], Step [169/225], Training Accuracy: 70.5159%, Training Loss: 0.6729%\n",
      "Epoch [21/300], Step [170/225], Training Accuracy: 70.5515%, Training Loss: 0.6722%\n",
      "Epoch [21/300], Step [171/225], Training Accuracy: 70.5135%, Training Loss: 0.6723%\n",
      "Epoch [21/300], Step [172/225], Training Accuracy: 70.5396%, Training Loss: 0.6722%\n",
      "Epoch [21/300], Step [173/225], Training Accuracy: 70.5202%, Training Loss: 0.6722%\n",
      "Epoch [21/300], Step [174/225], Training Accuracy: 70.5460%, Training Loss: 0.6713%\n",
      "Epoch [21/300], Step [175/225], Training Accuracy: 70.5625%, Training Loss: 0.6705%\n",
      "Epoch [21/300], Step [176/225], Training Accuracy: 70.5788%, Training Loss: 0.6703%\n",
      "Epoch [21/300], Step [177/225], Training Accuracy: 70.6391%, Training Loss: 0.6697%\n",
      "Epoch [21/300], Step [178/225], Training Accuracy: 70.6812%, Training Loss: 0.6693%\n",
      "Epoch [21/300], Step [179/225], Training Accuracy: 70.7315%, Training Loss: 0.6681%\n",
      "Epoch [21/300], Step [180/225], Training Accuracy: 70.7726%, Training Loss: 0.6675%\n",
      "Epoch [21/300], Step [181/225], Training Accuracy: 70.7614%, Training Loss: 0.6683%\n",
      "Epoch [21/300], Step [182/225], Training Accuracy: 70.7847%, Training Loss: 0.6682%\n",
      "Epoch [21/300], Step [183/225], Training Accuracy: 70.7992%, Training Loss: 0.6677%\n",
      "Epoch [21/300], Step [184/225], Training Accuracy: 70.8135%, Training Loss: 0.6675%\n",
      "Epoch [21/300], Step [185/225], Training Accuracy: 70.8193%, Training Loss: 0.6669%\n",
      "Epoch [21/300], Step [186/225], Training Accuracy: 70.8585%, Training Loss: 0.6661%\n",
      "Epoch [21/300], Step [187/225], Training Accuracy: 70.8723%, Training Loss: 0.6653%\n",
      "Epoch [21/300], Step [188/225], Training Accuracy: 70.9525%, Training Loss: 0.6638%\n",
      "Epoch [21/300], Step [189/225], Training Accuracy: 70.9739%, Training Loss: 0.6632%\n",
      "Epoch [21/300], Step [190/225], Training Accuracy: 71.0115%, Training Loss: 0.6627%\n",
      "Epoch [21/300], Step [191/225], Training Accuracy: 70.9997%, Training Loss: 0.6626%\n",
      "Epoch [21/300], Step [192/225], Training Accuracy: 71.0124%, Training Loss: 0.6622%\n",
      "Epoch [21/300], Step [193/225], Training Accuracy: 71.0087%, Training Loss: 0.6621%\n",
      "Epoch [21/300], Step [194/225], Training Accuracy: 71.0213%, Training Loss: 0.6620%\n",
      "Epoch [21/300], Step [195/225], Training Accuracy: 71.0978%, Training Loss: 0.6606%\n",
      "Epoch [21/300], Step [196/225], Training Accuracy: 71.0858%, Training Loss: 0.6612%\n",
      "Epoch [21/300], Step [197/225], Training Accuracy: 71.0977%, Training Loss: 0.6612%\n",
      "Epoch [21/300], Step [198/225], Training Accuracy: 71.1411%, Training Loss: 0.6602%\n",
      "Epoch [21/300], Step [199/225], Training Accuracy: 71.1762%, Training Loss: 0.6595%\n",
      "Epoch [21/300], Step [200/225], Training Accuracy: 71.1484%, Training Loss: 0.6597%\n",
      "Epoch [21/300], Step [201/225], Training Accuracy: 71.1443%, Training Loss: 0.6595%\n",
      "Epoch [21/300], Step [202/225], Training Accuracy: 71.1402%, Training Loss: 0.6591%\n",
      "Epoch [21/300], Step [203/225], Training Accuracy: 71.2208%, Training Loss: 0.6577%\n",
      "Epoch [21/300], Step [204/225], Training Accuracy: 71.2469%, Training Loss: 0.6575%\n",
      "Epoch [21/300], Step [205/225], Training Accuracy: 71.2576%, Training Loss: 0.6568%\n",
      "Epoch [21/300], Step [206/225], Training Accuracy: 71.2454%, Training Loss: 0.6570%\n",
      "Epoch [21/300], Step [207/225], Training Accuracy: 71.2711%, Training Loss: 0.6562%\n",
      "Epoch [21/300], Step [208/225], Training Accuracy: 71.2891%, Training Loss: 0.6558%\n",
      "Epoch [21/300], Step [209/225], Training Accuracy: 71.2694%, Training Loss: 0.6558%\n",
      "Epoch [21/300], Step [210/225], Training Accuracy: 71.2574%, Training Loss: 0.6556%\n",
      "Epoch [21/300], Step [211/225], Training Accuracy: 71.2826%, Training Loss: 0.6552%\n",
      "Epoch [21/300], Step [212/225], Training Accuracy: 71.2927%, Training Loss: 0.6549%\n",
      "Epoch [21/300], Step [213/225], Training Accuracy: 71.3468%, Training Loss: 0.6546%\n",
      "Epoch [21/300], Step [214/225], Training Accuracy: 71.3785%, Training Loss: 0.6540%\n",
      "Epoch [21/300], Step [215/225], Training Accuracy: 71.3881%, Training Loss: 0.6538%\n",
      "Epoch [21/300], Step [216/225], Training Accuracy: 71.4193%, Training Loss: 0.6539%\n",
      "Epoch [21/300], Step [217/225], Training Accuracy: 71.4286%, Training Loss: 0.6537%\n",
      "Epoch [21/300], Step [218/225], Training Accuracy: 71.3948%, Training Loss: 0.6539%\n",
      "Epoch [21/300], Step [219/225], Training Accuracy: 71.3970%, Training Loss: 0.6534%\n",
      "Epoch [21/300], Step [220/225], Training Accuracy: 71.4347%, Training Loss: 0.6529%\n",
      "Epoch [21/300], Step [221/225], Training Accuracy: 71.4508%, Training Loss: 0.6522%\n",
      "Epoch [21/300], Step [222/225], Training Accuracy: 71.4527%, Training Loss: 0.6519%\n",
      "Epoch [21/300], Step [223/225], Training Accuracy: 71.4266%, Training Loss: 0.6525%\n",
      "Epoch [21/300], Step [224/225], Training Accuracy: 71.4355%, Training Loss: 0.6523%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/300], Step [225/225], Training Accuracy: 71.4355%, Training Loss: 0.6520%\n",
      "Epoch [22/300], Step [1/225], Training Accuracy: 79.6875%, Training Loss: 0.4935%\n",
      "Epoch [22/300], Step [2/225], Training Accuracy: 75.0000%, Training Loss: 0.5689%\n",
      "Epoch [22/300], Step [3/225], Training Accuracy: 72.3958%, Training Loss: 0.6526%\n",
      "Epoch [22/300], Step [4/225], Training Accuracy: 71.8750%, Training Loss: 0.6621%\n",
      "Epoch [22/300], Step [5/225], Training Accuracy: 70.3125%, Training Loss: 0.7123%\n",
      "Epoch [22/300], Step [6/225], Training Accuracy: 71.8750%, Training Loss: 0.6741%\n",
      "Epoch [22/300], Step [7/225], Training Accuracy: 71.6518%, Training Loss: 0.6622%\n",
      "Epoch [22/300], Step [8/225], Training Accuracy: 73.0469%, Training Loss: 0.6487%\n",
      "Epoch [22/300], Step [9/225], Training Accuracy: 73.0903%, Training Loss: 0.6388%\n",
      "Epoch [22/300], Step [10/225], Training Accuracy: 72.6562%, Training Loss: 0.6510%\n",
      "Epoch [22/300], Step [11/225], Training Accuracy: 72.8693%, Training Loss: 0.6503%\n",
      "Epoch [22/300], Step [12/225], Training Accuracy: 72.3958%, Training Loss: 0.6646%\n",
      "Epoch [22/300], Step [13/225], Training Accuracy: 73.3173%, Training Loss: 0.6415%\n",
      "Epoch [22/300], Step [14/225], Training Accuracy: 73.2143%, Training Loss: 0.6506%\n",
      "Epoch [22/300], Step [15/225], Training Accuracy: 73.0208%, Training Loss: 0.6537%\n",
      "Epoch [22/300], Step [16/225], Training Accuracy: 72.9492%, Training Loss: 0.6530%\n",
      "Epoch [22/300], Step [17/225], Training Accuracy: 72.8860%, Training Loss: 0.6514%\n",
      "Epoch [22/300], Step [18/225], Training Accuracy: 72.7431%, Training Loss: 0.6515%\n",
      "Epoch [22/300], Step [19/225], Training Accuracy: 73.0263%, Training Loss: 0.6453%\n",
      "Epoch [22/300], Step [20/225], Training Accuracy: 73.3594%, Training Loss: 0.6395%\n",
      "Epoch [22/300], Step [21/225], Training Accuracy: 73.2143%, Training Loss: 0.6384%\n",
      "Epoch [22/300], Step [22/225], Training Accuracy: 73.0114%, Training Loss: 0.6404%\n",
      "Epoch [22/300], Step [23/225], Training Accuracy: 72.8261%, Training Loss: 0.6435%\n",
      "Epoch [22/300], Step [24/225], Training Accuracy: 73.0469%, Training Loss: 0.6399%\n",
      "Epoch [22/300], Step [25/225], Training Accuracy: 73.2500%, Training Loss: 0.6349%\n",
      "Epoch [22/300], Step [26/225], Training Accuracy: 73.4375%, Training Loss: 0.6321%\n",
      "Epoch [22/300], Step [27/225], Training Accuracy: 73.5532%, Training Loss: 0.6280%\n",
      "Epoch [22/300], Step [28/225], Training Accuracy: 73.7165%, Training Loss: 0.6220%\n",
      "Epoch [22/300], Step [29/225], Training Accuracy: 73.8147%, Training Loss: 0.6195%\n",
      "Epoch [22/300], Step [30/225], Training Accuracy: 73.9583%, Training Loss: 0.6171%\n",
      "Epoch [22/300], Step [31/225], Training Accuracy: 73.8407%, Training Loss: 0.6251%\n",
      "Epoch [22/300], Step [32/225], Training Accuracy: 73.7793%, Training Loss: 0.6270%\n",
      "Epoch [22/300], Step [33/225], Training Accuracy: 73.7689%, Training Loss: 0.6294%\n",
      "Epoch [22/300], Step [34/225], Training Accuracy: 73.6213%, Training Loss: 0.6345%\n",
      "Epoch [22/300], Step [35/225], Training Accuracy: 73.4821%, Training Loss: 0.6368%\n",
      "Epoch [22/300], Step [36/225], Training Accuracy: 73.6111%, Training Loss: 0.6340%\n",
      "Epoch [22/300], Step [37/225], Training Accuracy: 73.4375%, Training Loss: 0.6346%\n",
      "Epoch [22/300], Step [38/225], Training Accuracy: 73.4375%, Training Loss: 0.6340%\n",
      "Epoch [22/300], Step [39/225], Training Accuracy: 73.3574%, Training Loss: 0.6349%\n",
      "Epoch [22/300], Step [40/225], Training Accuracy: 73.3594%, Training Loss: 0.6355%\n",
      "Epoch [22/300], Step [41/225], Training Accuracy: 73.3232%, Training Loss: 0.6365%\n",
      "Epoch [22/300], Step [42/225], Training Accuracy: 73.0655%, Training Loss: 0.6421%\n",
      "Epoch [22/300], Step [43/225], Training Accuracy: 72.8198%, Training Loss: 0.6431%\n",
      "Epoch [22/300], Step [44/225], Training Accuracy: 73.0824%, Training Loss: 0.6396%\n",
      "Epoch [22/300], Step [45/225], Training Accuracy: 73.0903%, Training Loss: 0.6407%\n",
      "Epoch [22/300], Step [46/225], Training Accuracy: 73.1658%, Training Loss: 0.6378%\n",
      "Epoch [22/300], Step [47/225], Training Accuracy: 73.2048%, Training Loss: 0.6375%\n",
      "Epoch [22/300], Step [48/225], Training Accuracy: 73.1445%, Training Loss: 0.6372%\n",
      "Epoch [22/300], Step [49/225], Training Accuracy: 73.3099%, Training Loss: 0.6353%\n",
      "Epoch [22/300], Step [50/225], Training Accuracy: 73.3750%, Training Loss: 0.6344%\n",
      "Epoch [22/300], Step [51/225], Training Accuracy: 73.4375%, Training Loss: 0.6314%\n",
      "Epoch [22/300], Step [52/225], Training Accuracy: 73.7680%, Training Loss: 0.6257%\n",
      "Epoch [22/300], Step [53/225], Training Accuracy: 73.7028%, Training Loss: 0.6257%\n",
      "Epoch [22/300], Step [54/225], Training Accuracy: 73.7558%, Training Loss: 0.6276%\n",
      "Epoch [22/300], Step [55/225], Training Accuracy: 73.5795%, Training Loss: 0.6296%\n",
      "Epoch [22/300], Step [56/225], Training Accuracy: 73.6328%, Training Loss: 0.6297%\n",
      "Epoch [22/300], Step [57/225], Training Accuracy: 73.5471%, Training Loss: 0.6291%\n",
      "Epoch [22/300], Step [58/225], Training Accuracy: 73.4914%, Training Loss: 0.6309%\n",
      "Epoch [22/300], Step [59/225], Training Accuracy: 73.3845%, Training Loss: 0.6318%\n",
      "Epoch [22/300], Step [60/225], Training Accuracy: 73.3854%, Training Loss: 0.6308%\n",
      "Epoch [22/300], Step [61/225], Training Accuracy: 73.3094%, Training Loss: 0.6307%\n",
      "Epoch [22/300], Step [62/225], Training Accuracy: 73.4123%, Training Loss: 0.6296%\n",
      "Epoch [22/300], Step [63/225], Training Accuracy: 73.3879%, Training Loss: 0.6304%\n",
      "Epoch [22/300], Step [64/225], Training Accuracy: 73.3398%, Training Loss: 0.6304%\n",
      "Epoch [22/300], Step [65/225], Training Accuracy: 73.2933%, Training Loss: 0.6321%\n",
      "Epoch [22/300], Step [66/225], Training Accuracy: 73.4375%, Training Loss: 0.6310%\n",
      "Epoch [22/300], Step [67/225], Training Accuracy: 73.4142%, Training Loss: 0.6299%\n",
      "Epoch [22/300], Step [68/225], Training Accuracy: 73.3686%, Training Loss: 0.6304%\n",
      "Epoch [22/300], Step [69/225], Training Accuracy: 73.3922%, Training Loss: 0.6290%\n",
      "Epoch [22/300], Step [70/225], Training Accuracy: 73.4152%, Training Loss: 0.6292%\n",
      "Epoch [22/300], Step [71/225], Training Accuracy: 73.4815%, Training Loss: 0.6281%\n",
      "Epoch [22/300], Step [72/225], Training Accuracy: 73.4158%, Training Loss: 0.6300%\n",
      "Epoch [22/300], Step [73/225], Training Accuracy: 73.3733%, Training Loss: 0.6300%\n",
      "Epoch [22/300], Step [74/225], Training Accuracy: 73.4797%, Training Loss: 0.6288%\n",
      "Epoch [22/300], Step [75/225], Training Accuracy: 73.4583%, Training Loss: 0.6293%\n",
      "Epoch [22/300], Step [76/225], Training Accuracy: 73.3347%, Training Loss: 0.6320%\n",
      "Epoch [22/300], Step [77/225], Training Accuracy: 73.3157%, Training Loss: 0.6326%\n",
      "Epoch [22/300], Step [78/225], Training Accuracy: 73.1771%, Training Loss: 0.6335%\n",
      "Epoch [22/300], Step [79/225], Training Accuracy: 73.2397%, Training Loss: 0.6319%\n",
      "Epoch [22/300], Step [80/225], Training Accuracy: 73.0859%, Training Loss: 0.6362%\n",
      "Epoch [22/300], Step [81/225], Training Accuracy: 73.1096%, Training Loss: 0.6353%\n",
      "Epoch [22/300], Step [82/225], Training Accuracy: 73.1517%, Training Loss: 0.6335%\n",
      "Epoch [22/300], Step [83/225], Training Accuracy: 73.0045%, Training Loss: 0.6366%\n",
      "Epoch [22/300], Step [84/225], Training Accuracy: 73.0655%, Training Loss: 0.6347%\n",
      "Epoch [22/300], Step [85/225], Training Accuracy: 73.0147%, Training Loss: 0.6347%\n",
      "Epoch [22/300], Step [86/225], Training Accuracy: 73.0378%, Training Loss: 0.6342%\n",
      "Epoch [22/300], Step [87/225], Training Accuracy: 72.9705%, Training Loss: 0.6362%\n",
      "Epoch [22/300], Step [88/225], Training Accuracy: 72.9048%, Training Loss: 0.6381%\n",
      "Epoch [22/300], Step [89/225], Training Accuracy: 72.8757%, Training Loss: 0.6376%\n",
      "Epoch [22/300], Step [90/225], Training Accuracy: 72.7431%, Training Loss: 0.6394%\n",
      "Epoch [22/300], Step [91/225], Training Accuracy: 72.6820%, Training Loss: 0.6399%\n",
      "Epoch [22/300], Step [92/225], Training Accuracy: 72.6902%, Training Loss: 0.6401%\n",
      "Epoch [22/300], Step [93/225], Training Accuracy: 72.7151%, Training Loss: 0.6400%\n",
      "Epoch [22/300], Step [94/225], Training Accuracy: 72.6895%, Training Loss: 0.6414%\n",
      "Epoch [22/300], Step [95/225], Training Accuracy: 72.5329%, Training Loss: 0.6458%\n",
      "Epoch [22/300], Step [96/225], Training Accuracy: 72.6237%, Training Loss: 0.6441%\n",
      "Epoch [22/300], Step [97/225], Training Accuracy: 72.5677%, Training Loss: 0.6461%\n",
      "Epoch [22/300], Step [98/225], Training Accuracy: 72.5128%, Training Loss: 0.6482%\n",
      "Epoch [22/300], Step [99/225], Training Accuracy: 72.4432%, Training Loss: 0.6519%\n",
      "Epoch [22/300], Step [100/225], Training Accuracy: 72.2969%, Training Loss: 0.6558%\n",
      "Epoch [22/300], Step [101/225], Training Accuracy: 72.2308%, Training Loss: 0.6554%\n",
      "Epoch [22/300], Step [102/225], Training Accuracy: 72.1967%, Training Loss: 0.6565%\n",
      "Epoch [22/300], Step [103/225], Training Accuracy: 72.0570%, Training Loss: 0.6582%\n",
      "Epoch [22/300], Step [104/225], Training Accuracy: 71.9501%, Training Loss: 0.6609%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/300], Step [105/225], Training Accuracy: 71.9494%, Training Loss: 0.6612%\n",
      "Epoch [22/300], Step [106/225], Training Accuracy: 71.8603%, Training Loss: 0.6626%\n",
      "Epoch [22/300], Step [107/225], Training Accuracy: 71.8750%, Training Loss: 0.6634%\n",
      "Epoch [22/300], Step [108/225], Training Accuracy: 71.8461%, Training Loss: 0.6637%\n",
      "Epoch [22/300], Step [109/225], Training Accuracy: 71.8033%, Training Loss: 0.6636%\n",
      "Epoch [22/300], Step [110/225], Training Accuracy: 71.8182%, Training Loss: 0.6629%\n",
      "Epoch [22/300], Step [111/225], Training Accuracy: 71.7765%, Training Loss: 0.6645%\n",
      "Epoch [22/300], Step [112/225], Training Accuracy: 71.7773%, Training Loss: 0.6634%\n",
      "Epoch [22/300], Step [113/225], Training Accuracy: 71.7782%, Training Loss: 0.6634%\n",
      "Epoch [22/300], Step [114/225], Training Accuracy: 71.7516%, Training Loss: 0.6631%\n",
      "Epoch [22/300], Step [115/225], Training Accuracy: 71.7935%, Training Loss: 0.6623%\n",
      "Epoch [22/300], Step [116/225], Training Accuracy: 71.8211%, Training Loss: 0.6629%\n",
      "Epoch [22/300], Step [117/225], Training Accuracy: 71.7281%, Training Loss: 0.6650%\n",
      "Epoch [22/300], Step [118/225], Training Accuracy: 71.7823%, Training Loss: 0.6641%\n",
      "Epoch [22/300], Step [119/225], Training Accuracy: 71.7962%, Training Loss: 0.6639%\n",
      "Epoch [22/300], Step [120/225], Training Accuracy: 71.7708%, Training Loss: 0.6638%\n",
      "Epoch [22/300], Step [121/225], Training Accuracy: 71.7200%, Training Loss: 0.6669%\n",
      "Epoch [22/300], Step [122/225], Training Accuracy: 71.7213%, Training Loss: 0.6674%\n",
      "Epoch [22/300], Step [123/225], Training Accuracy: 71.7734%, Training Loss: 0.6672%\n",
      "Epoch [22/300], Step [124/225], Training Accuracy: 71.8120%, Training Loss: 0.6660%\n",
      "Epoch [22/300], Step [125/225], Training Accuracy: 71.8750%, Training Loss: 0.6651%\n",
      "Epoch [22/300], Step [126/225], Training Accuracy: 71.8750%, Training Loss: 0.6649%\n",
      "Epoch [22/300], Step [127/225], Training Accuracy: 71.8381%, Training Loss: 0.6651%\n",
      "Epoch [22/300], Step [128/225], Training Accuracy: 71.8750%, Training Loss: 0.6647%\n",
      "Epoch [22/300], Step [129/225], Training Accuracy: 71.8508%, Training Loss: 0.6656%\n",
      "Epoch [22/300], Step [130/225], Training Accuracy: 71.8389%, Training Loss: 0.6660%\n",
      "Epoch [22/300], Step [131/225], Training Accuracy: 71.7796%, Training Loss: 0.6673%\n",
      "Epoch [22/300], Step [132/225], Training Accuracy: 71.7211%, Training Loss: 0.6679%\n",
      "Epoch [22/300], Step [133/225], Training Accuracy: 71.7693%, Training Loss: 0.6679%\n",
      "Epoch [22/300], Step [134/225], Training Accuracy: 71.6768%, Training Loss: 0.6703%\n",
      "Epoch [22/300], Step [135/225], Training Accuracy: 71.6898%, Training Loss: 0.6699%\n",
      "Epoch [22/300], Step [136/225], Training Accuracy: 71.6452%, Training Loss: 0.6699%\n",
      "Epoch [22/300], Step [137/225], Training Accuracy: 71.6697%, Training Loss: 0.6695%\n",
      "Epoch [22/300], Step [138/225], Training Accuracy: 71.7278%, Training Loss: 0.6684%\n",
      "Epoch [22/300], Step [139/225], Training Accuracy: 71.7176%, Training Loss: 0.6690%\n",
      "Epoch [22/300], Step [140/225], Training Accuracy: 71.7299%, Training Loss: 0.6689%\n",
      "Epoch [22/300], Step [141/225], Training Accuracy: 71.7420%, Training Loss: 0.6681%\n",
      "Epoch [22/300], Step [142/225], Training Accuracy: 71.7650%, Training Loss: 0.6674%\n",
      "Epoch [22/300], Step [143/225], Training Accuracy: 71.7767%, Training Loss: 0.6673%\n",
      "Epoch [22/300], Step [144/225], Training Accuracy: 71.7773%, Training Loss: 0.6671%\n",
      "Epoch [22/300], Step [145/225], Training Accuracy: 71.7457%, Training Loss: 0.6675%\n",
      "Epoch [22/300], Step [146/225], Training Accuracy: 71.7680%, Training Loss: 0.6672%\n",
      "Epoch [22/300], Step [147/225], Training Accuracy: 71.7581%, Training Loss: 0.6670%\n",
      "Epoch [22/300], Step [148/225], Training Accuracy: 71.7483%, Training Loss: 0.6671%\n",
      "Epoch [22/300], Step [149/225], Training Accuracy: 71.7177%, Training Loss: 0.6670%\n",
      "Epoch [22/300], Step [150/225], Training Accuracy: 71.7812%, Training Loss: 0.6657%\n",
      "Epoch [22/300], Step [151/225], Training Accuracy: 71.7819%, Training Loss: 0.6653%\n",
      "Epoch [22/300], Step [152/225], Training Accuracy: 71.7722%, Training Loss: 0.6651%\n",
      "Epoch [22/300], Step [153/225], Training Accuracy: 71.7627%, Training Loss: 0.6652%\n",
      "Epoch [22/300], Step [154/225], Training Accuracy: 71.7532%, Training Loss: 0.6657%\n",
      "Epoch [22/300], Step [155/225], Training Accuracy: 71.8044%, Training Loss: 0.6651%\n",
      "Epoch [22/300], Step [156/225], Training Accuracy: 71.7548%, Training Loss: 0.6668%\n",
      "Epoch [22/300], Step [157/225], Training Accuracy: 71.7158%, Training Loss: 0.6672%\n",
      "Epoch [22/300], Step [158/225], Training Accuracy: 71.7563%, Training Loss: 0.6673%\n",
      "Epoch [22/300], Step [159/225], Training Accuracy: 71.7669%, Training Loss: 0.6670%\n",
      "Epoch [22/300], Step [160/225], Training Accuracy: 71.7480%, Training Loss: 0.6668%\n",
      "Epoch [22/300], Step [161/225], Training Accuracy: 71.7391%, Training Loss: 0.6663%\n",
      "Epoch [22/300], Step [162/225], Training Accuracy: 71.7400%, Training Loss: 0.6655%\n",
      "Epoch [22/300], Step [163/225], Training Accuracy: 71.7600%, Training Loss: 0.6650%\n",
      "Epoch [22/300], Step [164/225], Training Accuracy: 71.7511%, Training Loss: 0.6658%\n",
      "Epoch [22/300], Step [165/225], Training Accuracy: 71.7235%, Training Loss: 0.6664%\n",
      "Epoch [22/300], Step [166/225], Training Accuracy: 71.6962%, Training Loss: 0.6657%\n",
      "Epoch [22/300], Step [167/225], Training Accuracy: 71.6879%, Training Loss: 0.6661%\n",
      "Epoch [22/300], Step [168/225], Training Accuracy: 71.6704%, Training Loss: 0.6665%\n",
      "Epoch [22/300], Step [169/225], Training Accuracy: 71.7456%, Training Loss: 0.6651%\n",
      "Epoch [22/300], Step [170/225], Training Accuracy: 71.7647%, Training Loss: 0.6649%\n",
      "Epoch [22/300], Step [171/225], Training Accuracy: 71.7197%, Training Loss: 0.6654%\n",
      "Epoch [22/300], Step [172/225], Training Accuracy: 71.7297%, Training Loss: 0.6651%\n",
      "Epoch [22/300], Step [173/225], Training Accuracy: 71.7215%, Training Loss: 0.6653%\n",
      "Epoch [22/300], Step [174/225], Training Accuracy: 71.7852%, Training Loss: 0.6645%\n",
      "Epoch [22/300], Step [175/225], Training Accuracy: 71.8125%, Training Loss: 0.6637%\n",
      "Epoch [22/300], Step [176/225], Training Accuracy: 71.8661%, Training Loss: 0.6628%\n",
      "Epoch [22/300], Step [177/225], Training Accuracy: 71.9544%, Training Loss: 0.6617%\n",
      "Epoch [22/300], Step [178/225], Training Accuracy: 72.0067%, Training Loss: 0.6604%\n",
      "Epoch [22/300], Step [179/225], Training Accuracy: 72.0670%, Training Loss: 0.6592%\n",
      "Epoch [22/300], Step [180/225], Training Accuracy: 72.1181%, Training Loss: 0.6586%\n",
      "Epoch [22/300], Step [181/225], Training Accuracy: 72.1081%, Training Loss: 0.6587%\n",
      "Epoch [22/300], Step [182/225], Training Accuracy: 72.1669%, Training Loss: 0.6577%\n",
      "Epoch [22/300], Step [183/225], Training Accuracy: 72.1568%, Training Loss: 0.6578%\n",
      "Epoch [22/300], Step [184/225], Training Accuracy: 72.1722%, Training Loss: 0.6577%\n",
      "Epoch [22/300], Step [185/225], Training Accuracy: 72.2382%, Training Loss: 0.6562%\n",
      "Epoch [22/300], Step [186/225], Training Accuracy: 72.3034%, Training Loss: 0.6546%\n",
      "Epoch [22/300], Step [187/225], Training Accuracy: 72.3346%, Training Loss: 0.6539%\n",
      "Epoch [22/300], Step [188/225], Training Accuracy: 72.3570%, Training Loss: 0.6534%\n",
      "Epoch [22/300], Step [189/225], Training Accuracy: 72.3958%, Training Loss: 0.6521%\n",
      "Epoch [22/300], Step [190/225], Training Accuracy: 72.4342%, Training Loss: 0.6514%\n",
      "Epoch [22/300], Step [191/225], Training Accuracy: 72.4476%, Training Loss: 0.6506%\n",
      "Epoch [22/300], Step [192/225], Training Accuracy: 72.5098%, Training Loss: 0.6496%\n",
      "Epoch [22/300], Step [193/225], Training Accuracy: 72.4822%, Training Loss: 0.6501%\n",
      "Epoch [22/300], Step [194/225], Training Accuracy: 72.4871%, Training Loss: 0.6501%\n",
      "Epoch [22/300], Step [195/225], Training Accuracy: 72.5160%, Training Loss: 0.6493%\n",
      "Epoch [22/300], Step [196/225], Training Accuracy: 72.5606%, Training Loss: 0.6488%\n",
      "Epoch [22/300], Step [197/225], Training Accuracy: 72.5650%, Training Loss: 0.6485%\n",
      "Epoch [22/300], Step [198/225], Training Accuracy: 72.5694%, Training Loss: 0.6477%\n",
      "Epoch [22/300], Step [199/225], Training Accuracy: 72.6209%, Training Loss: 0.6467%\n",
      "Epoch [22/300], Step [200/225], Training Accuracy: 72.6016%, Training Loss: 0.6466%\n",
      "Epoch [22/300], Step [201/225], Training Accuracy: 72.6057%, Training Loss: 0.6461%\n",
      "Epoch [22/300], Step [202/225], Training Accuracy: 72.6021%, Training Loss: 0.6459%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/300], Step [203/225], Training Accuracy: 72.6678%, Training Loss: 0.6445%\n",
      "Epoch [22/300], Step [204/225], Training Accuracy: 72.6869%, Training Loss: 0.6440%\n",
      "Epoch [22/300], Step [205/225], Training Accuracy: 72.7287%, Training Loss: 0.6433%\n",
      "Epoch [22/300], Step [206/225], Training Accuracy: 72.7093%, Training Loss: 0.6431%\n",
      "Epoch [22/300], Step [207/225], Training Accuracy: 72.7431%, Training Loss: 0.6423%\n",
      "Epoch [22/300], Step [208/225], Training Accuracy: 72.7239%, Training Loss: 0.6421%\n",
      "Epoch [22/300], Step [209/225], Training Accuracy: 72.6824%, Training Loss: 0.6422%\n",
      "Epoch [22/300], Step [210/225], Training Accuracy: 72.6414%, Training Loss: 0.6425%\n",
      "Epoch [22/300], Step [211/225], Training Accuracy: 72.6748%, Training Loss: 0.6421%\n",
      "Epoch [22/300], Step [212/225], Training Accuracy: 72.7226%, Training Loss: 0.6412%\n",
      "Epoch [22/300], Step [213/225], Training Accuracy: 72.7039%, Training Loss: 0.6412%\n",
      "Epoch [22/300], Step [214/225], Training Accuracy: 72.7074%, Training Loss: 0.6406%\n",
      "Epoch [22/300], Step [215/225], Training Accuracy: 72.7326%, Training Loss: 0.6400%\n",
      "Epoch [22/300], Step [216/225], Training Accuracy: 72.7575%, Training Loss: 0.6398%\n",
      "Epoch [22/300], Step [217/225], Training Accuracy: 72.7535%, Training Loss: 0.6396%\n",
      "Epoch [22/300], Step [218/225], Training Accuracy: 72.7208%, Training Loss: 0.6401%\n",
      "Epoch [22/300], Step [219/225], Training Accuracy: 72.7312%, Training Loss: 0.6397%\n",
      "Epoch [22/300], Step [220/225], Training Accuracy: 72.7344%, Training Loss: 0.6394%\n",
      "Epoch [22/300], Step [221/225], Training Accuracy: 72.7729%, Training Loss: 0.6388%\n",
      "Epoch [22/300], Step [222/225], Training Accuracy: 72.7829%, Training Loss: 0.6388%\n",
      "Epoch [22/300], Step [223/225], Training Accuracy: 72.7789%, Training Loss: 0.6385%\n",
      "Epoch [22/300], Step [224/225], Training Accuracy: 72.7888%, Training Loss: 0.6382%\n",
      "Epoch [22/300], Step [225/225], Training Accuracy: 72.7974%, Training Loss: 0.6382%\n",
      "Epoch [23/300], Step [1/225], Training Accuracy: 71.8750%, Training Loss: 0.6576%\n",
      "Epoch [23/300], Step [2/225], Training Accuracy: 71.0938%, Training Loss: 0.6638%\n",
      "Epoch [23/300], Step [3/225], Training Accuracy: 73.9583%, Training Loss: 0.6121%\n",
      "Epoch [23/300], Step [4/225], Training Accuracy: 73.4375%, Training Loss: 0.6244%\n",
      "Epoch [23/300], Step [5/225], Training Accuracy: 74.3750%, Training Loss: 0.6137%\n",
      "Epoch [23/300], Step [6/225], Training Accuracy: 75.2604%, Training Loss: 0.5923%\n",
      "Epoch [23/300], Step [7/225], Training Accuracy: 74.5536%, Training Loss: 0.5930%\n",
      "Epoch [23/300], Step [8/225], Training Accuracy: 74.8047%, Training Loss: 0.5949%\n",
      "Epoch [23/300], Step [9/225], Training Accuracy: 74.3056%, Training Loss: 0.5967%\n",
      "Epoch [23/300], Step [10/225], Training Accuracy: 72.8125%, Training Loss: 0.6153%\n",
      "Epoch [23/300], Step [11/225], Training Accuracy: 72.7273%, Training Loss: 0.6067%\n",
      "Epoch [23/300], Step [12/225], Training Accuracy: 72.9167%, Training Loss: 0.6101%\n",
      "Epoch [23/300], Step [13/225], Training Accuracy: 73.3173%, Training Loss: 0.5943%\n",
      "Epoch [23/300], Step [14/225], Training Accuracy: 74.1071%, Training Loss: 0.5841%\n",
      "Epoch [23/300], Step [15/225], Training Accuracy: 74.1667%, Training Loss: 0.5801%\n",
      "Epoch [23/300], Step [16/225], Training Accuracy: 74.2188%, Training Loss: 0.5750%\n",
      "Epoch [23/300], Step [17/225], Training Accuracy: 74.4485%, Training Loss: 0.5687%\n",
      "Epoch [23/300], Step [18/225], Training Accuracy: 74.5660%, Training Loss: 0.5704%\n",
      "Epoch [23/300], Step [19/225], Training Accuracy: 74.2599%, Training Loss: 0.5746%\n",
      "Epoch [23/300], Step [20/225], Training Accuracy: 74.5312%, Training Loss: 0.5671%\n",
      "Epoch [23/300], Step [21/225], Training Accuracy: 74.5536%, Training Loss: 0.5676%\n",
      "Epoch [23/300], Step [22/225], Training Accuracy: 74.3608%, Training Loss: 0.5728%\n",
      "Epoch [23/300], Step [23/225], Training Accuracy: 73.9130%, Training Loss: 0.5808%\n",
      "Epoch [23/300], Step [24/225], Training Accuracy: 73.6979%, Training Loss: 0.5857%\n",
      "Epoch [23/300], Step [25/225], Training Accuracy: 73.6875%, Training Loss: 0.5845%\n",
      "Epoch [23/300], Step [26/225], Training Accuracy: 73.8582%, Training Loss: 0.5816%\n",
      "Epoch [23/300], Step [27/225], Training Accuracy: 73.7847%, Training Loss: 0.5806%\n",
      "Epoch [23/300], Step [28/225], Training Accuracy: 74.1629%, Training Loss: 0.5728%\n",
      "Epoch [23/300], Step [29/225], Training Accuracy: 74.4073%, Training Loss: 0.5693%\n",
      "Epoch [23/300], Step [30/225], Training Accuracy: 74.2708%, Training Loss: 0.5770%\n",
      "Epoch [23/300], Step [31/225], Training Accuracy: 74.2440%, Training Loss: 0.5778%\n",
      "Epoch [23/300], Step [32/225], Training Accuracy: 74.2676%, Training Loss: 0.5785%\n",
      "Epoch [23/300], Step [33/225], Training Accuracy: 74.2898%, Training Loss: 0.5775%\n",
      "Epoch [23/300], Step [34/225], Training Accuracy: 74.0809%, Training Loss: 0.5856%\n",
      "Epoch [23/300], Step [35/225], Training Accuracy: 73.7946%, Training Loss: 0.5910%\n",
      "Epoch [23/300], Step [36/225], Training Accuracy: 73.8281%, Training Loss: 0.5912%\n",
      "Epoch [23/300], Step [37/225], Training Accuracy: 73.6486%, Training Loss: 0.5963%\n",
      "Epoch [23/300], Step [38/225], Training Accuracy: 73.6431%, Training Loss: 0.5966%\n",
      "Epoch [23/300], Step [39/225], Training Accuracy: 73.4375%, Training Loss: 0.6008%\n",
      "Epoch [23/300], Step [40/225], Training Accuracy: 73.4375%, Training Loss: 0.6000%\n",
      "Epoch [23/300], Step [41/225], Training Accuracy: 73.3232%, Training Loss: 0.6031%\n",
      "Epoch [23/300], Step [42/225], Training Accuracy: 73.1771%, Training Loss: 0.6044%\n",
      "Epoch [23/300], Step [43/225], Training Accuracy: 73.2558%, Training Loss: 0.6032%\n",
      "Epoch [23/300], Step [44/225], Training Accuracy: 73.4375%, Training Loss: 0.6001%\n",
      "Epoch [23/300], Step [45/225], Training Accuracy: 73.2639%, Training Loss: 0.6023%\n",
      "Epoch [23/300], Step [46/225], Training Accuracy: 73.4715%, Training Loss: 0.5988%\n",
      "Epoch [23/300], Step [47/225], Training Accuracy: 73.4043%, Training Loss: 0.6013%\n",
      "Epoch [23/300], Step [48/225], Training Accuracy: 73.3073%, Training Loss: 0.6060%\n",
      "Epoch [23/300], Step [49/225], Training Accuracy: 73.4056%, Training Loss: 0.6028%\n",
      "Epoch [23/300], Step [50/225], Training Accuracy: 73.3125%, Training Loss: 0.6044%\n",
      "Epoch [23/300], Step [51/225], Training Accuracy: 73.5600%, Training Loss: 0.5992%\n",
      "Epoch [23/300], Step [52/225], Training Accuracy: 73.6779%, Training Loss: 0.5961%\n",
      "Epoch [23/300], Step [53/225], Training Accuracy: 73.7028%, Training Loss: 0.5968%\n",
      "Epoch [23/300], Step [54/225], Training Accuracy: 73.6979%, Training Loss: 0.5975%\n",
      "Epoch [23/300], Step [55/225], Training Accuracy: 73.6364%, Training Loss: 0.5984%\n",
      "Epoch [23/300], Step [56/225], Training Accuracy: 73.5770%, Training Loss: 0.5990%\n",
      "Epoch [23/300], Step [57/225], Training Accuracy: 73.4923%, Training Loss: 0.5989%\n",
      "Epoch [23/300], Step [58/225], Training Accuracy: 73.5453%, Training Loss: 0.5990%\n",
      "Epoch [23/300], Step [59/225], Training Accuracy: 73.6229%, Training Loss: 0.5971%\n",
      "Epoch [23/300], Step [60/225], Training Accuracy: 73.4896%, Training Loss: 0.5983%\n",
      "Epoch [23/300], Step [61/225], Training Accuracy: 73.4887%, Training Loss: 0.5990%\n",
      "Epoch [23/300], Step [62/225], Training Accuracy: 73.5635%, Training Loss: 0.5980%\n",
      "Epoch [23/300], Step [63/225], Training Accuracy: 73.4871%, Training Loss: 0.5998%\n",
      "Epoch [23/300], Step [64/225], Training Accuracy: 73.4863%, Training Loss: 0.5999%\n",
      "Epoch [23/300], Step [65/225], Training Accuracy: 73.6058%, Training Loss: 0.5990%\n",
      "Epoch [23/300], Step [66/225], Training Accuracy: 73.6979%, Training Loss: 0.5973%\n",
      "Epoch [23/300], Step [67/225], Training Accuracy: 73.7640%, Training Loss: 0.5968%\n",
      "Epoch [23/300], Step [68/225], Training Accuracy: 73.5983%, Training Loss: 0.5988%\n",
      "Epoch [23/300], Step [69/225], Training Accuracy: 73.6639%, Training Loss: 0.5991%\n",
      "Epoch [23/300], Step [70/225], Training Accuracy: 73.6830%, Training Loss: 0.5983%\n",
      "Epoch [23/300], Step [71/225], Training Accuracy: 73.7016%, Training Loss: 0.5995%\n",
      "Epoch [23/300], Step [72/225], Training Accuracy: 73.6979%, Training Loss: 0.5988%\n",
      "Epoch [23/300], Step [73/225], Training Accuracy: 73.6301%, Training Loss: 0.5996%\n",
      "Epoch [23/300], Step [74/225], Training Accuracy: 73.7753%, Training Loss: 0.5976%\n",
      "Epoch [23/300], Step [75/225], Training Accuracy: 73.7292%, Training Loss: 0.5967%\n",
      "Epoch [23/300], Step [76/225], Training Accuracy: 73.5197%, Training Loss: 0.6001%\n",
      "Epoch [23/300], Step [77/225], Training Accuracy: 73.4984%, Training Loss: 0.6026%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/300], Step [78/225], Training Accuracy: 73.5577%, Training Loss: 0.6016%\n",
      "Epoch [23/300], Step [79/225], Training Accuracy: 73.5759%, Training Loss: 0.6006%\n",
      "Epoch [23/300], Step [80/225], Training Accuracy: 73.5742%, Training Loss: 0.5993%\n",
      "Epoch [23/300], Step [81/225], Training Accuracy: 73.5725%, Training Loss: 0.5985%\n",
      "Epoch [23/300], Step [82/225], Training Accuracy: 73.6662%, Training Loss: 0.5976%\n",
      "Epoch [23/300], Step [83/225], Training Accuracy: 73.5881%, Training Loss: 0.5995%\n",
      "Epoch [23/300], Step [84/225], Training Accuracy: 73.6793%, Training Loss: 0.5978%\n",
      "Epoch [23/300], Step [85/225], Training Accuracy: 73.6765%, Training Loss: 0.5966%\n",
      "Epoch [23/300], Step [86/225], Training Accuracy: 73.7282%, Training Loss: 0.5958%\n",
      "Epoch [23/300], Step [87/225], Training Accuracy: 73.6710%, Training Loss: 0.5968%\n",
      "Epoch [23/300], Step [88/225], Training Accuracy: 73.6683%, Training Loss: 0.5974%\n",
      "Epoch [23/300], Step [89/225], Training Accuracy: 73.7008%, Training Loss: 0.5972%\n",
      "Epoch [23/300], Step [90/225], Training Accuracy: 73.5938%, Training Loss: 0.5991%\n",
      "Epoch [23/300], Step [91/225], Training Accuracy: 73.6435%, Training Loss: 0.5986%\n",
      "Epoch [23/300], Step [92/225], Training Accuracy: 73.6583%, Training Loss: 0.5991%\n",
      "Epoch [23/300], Step [93/225], Training Accuracy: 73.7399%, Training Loss: 0.5970%\n",
      "Epoch [23/300], Step [94/225], Training Accuracy: 73.7866%, Training Loss: 0.5963%\n",
      "Epoch [23/300], Step [95/225], Training Accuracy: 73.7993%, Training Loss: 0.5965%\n",
      "Epoch [23/300], Step [96/225], Training Accuracy: 73.9258%, Training Loss: 0.5950%\n",
      "Epoch [23/300], Step [97/225], Training Accuracy: 73.9369%, Training Loss: 0.5950%\n",
      "Epoch [23/300], Step [98/225], Training Accuracy: 73.8999%, Training Loss: 0.5951%\n",
      "Epoch [23/300], Step [99/225], Training Accuracy: 73.9268%, Training Loss: 0.5938%\n",
      "Epoch [23/300], Step [100/225], Training Accuracy: 73.8281%, Training Loss: 0.5973%\n",
      "Epoch [23/300], Step [101/225], Training Accuracy: 73.8707%, Training Loss: 0.5992%\n",
      "Epoch [23/300], Step [102/225], Training Accuracy: 73.8358%, Training Loss: 0.5997%\n",
      "Epoch [23/300], Step [103/225], Training Accuracy: 73.8774%, Training Loss: 0.5989%\n",
      "Epoch [23/300], Step [104/225], Training Accuracy: 73.8131%, Training Loss: 0.5993%\n",
      "Epoch [23/300], Step [105/225], Training Accuracy: 73.7946%, Training Loss: 0.6000%\n",
      "Epoch [23/300], Step [106/225], Training Accuracy: 73.7765%, Training Loss: 0.6005%\n",
      "Epoch [23/300], Step [107/225], Training Accuracy: 73.7734%, Training Loss: 0.6015%\n",
      "Epoch [23/300], Step [108/225], Training Accuracy: 73.6979%, Training Loss: 0.6034%\n",
      "Epoch [23/300], Step [109/225], Training Accuracy: 73.6382%, Training Loss: 0.6043%\n",
      "Epoch [23/300], Step [110/225], Training Accuracy: 73.6506%, Training Loss: 0.6042%\n",
      "Epoch [23/300], Step [111/225], Training Accuracy: 73.6346%, Training Loss: 0.6055%\n",
      "Epoch [23/300], Step [112/225], Training Accuracy: 73.6189%, Training Loss: 0.6061%\n",
      "Epoch [23/300], Step [113/225], Training Accuracy: 73.5619%, Training Loss: 0.6092%\n",
      "Epoch [23/300], Step [114/225], Training Accuracy: 73.5883%, Training Loss: 0.6088%\n",
      "Epoch [23/300], Step [115/225], Training Accuracy: 73.6005%, Training Loss: 0.6091%\n",
      "Epoch [23/300], Step [116/225], Training Accuracy: 73.5857%, Training Loss: 0.6099%\n",
      "Epoch [23/300], Step [117/225], Training Accuracy: 73.5577%, Training Loss: 0.6106%\n",
      "Epoch [23/300], Step [118/225], Training Accuracy: 73.5832%, Training Loss: 0.6107%\n",
      "Epoch [23/300], Step [119/225], Training Accuracy: 73.5425%, Training Loss: 0.6116%\n",
      "Epoch [23/300], Step [120/225], Training Accuracy: 73.4896%, Training Loss: 0.6120%\n",
      "Epoch [23/300], Step [121/225], Training Accuracy: 73.4504%, Training Loss: 0.6126%\n",
      "Epoch [23/300], Step [122/225], Training Accuracy: 73.3863%, Training Loss: 0.6128%\n",
      "Epoch [23/300], Step [123/225], Training Accuracy: 73.3740%, Training Loss: 0.6132%\n",
      "Epoch [23/300], Step [124/225], Training Accuracy: 73.3619%, Training Loss: 0.6130%\n",
      "Epoch [23/300], Step [125/225], Training Accuracy: 73.3375%, Training Loss: 0.6140%\n",
      "Epoch [23/300], Step [126/225], Training Accuracy: 73.3383%, Training Loss: 0.6142%\n",
      "Epoch [23/300], Step [127/225], Training Accuracy: 73.3145%, Training Loss: 0.6143%\n",
      "Epoch [23/300], Step [128/225], Training Accuracy: 73.2910%, Training Loss: 0.6153%\n",
      "Epoch [23/300], Step [129/225], Training Accuracy: 73.2558%, Training Loss: 0.6163%\n",
      "Epoch [23/300], Step [130/225], Training Accuracy: 73.2332%, Training Loss: 0.6164%\n",
      "Epoch [23/300], Step [131/225], Training Accuracy: 73.1870%, Training Loss: 0.6170%\n",
      "Epoch [23/300], Step [132/225], Training Accuracy: 73.1297%, Training Loss: 0.6176%\n",
      "Epoch [23/300], Step [133/225], Training Accuracy: 73.1555%, Training Loss: 0.6173%\n",
      "Epoch [23/300], Step [134/225], Training Accuracy: 73.0410%, Training Loss: 0.6194%\n",
      "Epoch [23/300], Step [135/225], Training Accuracy: 73.0556%, Training Loss: 0.6197%\n",
      "Epoch [23/300], Step [136/225], Training Accuracy: 73.0813%, Training Loss: 0.6194%\n",
      "Epoch [23/300], Step [137/225], Training Accuracy: 73.1182%, Training Loss: 0.6187%\n",
      "Epoch [23/300], Step [138/225], Training Accuracy: 73.1997%, Training Loss: 0.6170%\n",
      "Epoch [23/300], Step [139/225], Training Accuracy: 73.2014%, Training Loss: 0.6167%\n",
      "Epoch [23/300], Step [140/225], Training Accuracy: 73.2254%, Training Loss: 0.6162%\n",
      "Epoch [23/300], Step [141/225], Training Accuracy: 73.2380%, Training Loss: 0.6156%\n",
      "Epoch [23/300], Step [142/225], Training Accuracy: 73.1844%, Training Loss: 0.6157%\n",
      "Epoch [23/300], Step [143/225], Training Accuracy: 73.1316%, Training Loss: 0.6161%\n",
      "Epoch [23/300], Step [144/225], Training Accuracy: 73.1337%, Training Loss: 0.6159%\n",
      "Epoch [23/300], Step [145/225], Training Accuracy: 73.0819%, Training Loss: 0.6163%\n",
      "Epoch [23/300], Step [146/225], Training Accuracy: 73.0843%, Training Loss: 0.6161%\n",
      "Epoch [23/300], Step [147/225], Training Accuracy: 73.0230%, Training Loss: 0.6174%\n",
      "Epoch [23/300], Step [148/225], Training Accuracy: 73.0785%, Training Loss: 0.6168%\n",
      "Epoch [23/300], Step [149/225], Training Accuracy: 73.0600%, Training Loss: 0.6176%\n",
      "Epoch [23/300], Step [150/225], Training Accuracy: 73.1146%, Training Loss: 0.6166%\n",
      "Epoch [23/300], Step [151/225], Training Accuracy: 73.1374%, Training Loss: 0.6158%\n",
      "Epoch [23/300], Step [152/225], Training Accuracy: 73.1394%, Training Loss: 0.6160%\n",
      "Epoch [23/300], Step [153/225], Training Accuracy: 73.1311%, Training Loss: 0.6169%\n",
      "Epoch [23/300], Step [154/225], Training Accuracy: 73.1027%, Training Loss: 0.6175%\n",
      "Epoch [23/300], Step [155/225], Training Accuracy: 73.1552%, Training Loss: 0.6172%\n",
      "Epoch [23/300], Step [156/225], Training Accuracy: 73.1170%, Training Loss: 0.6181%\n",
      "Epoch [23/300], Step [157/225], Training Accuracy: 73.0792%, Training Loss: 0.6182%\n",
      "Epoch [23/300], Step [158/225], Training Accuracy: 73.0518%, Training Loss: 0.6197%\n",
      "Epoch [23/300], Step [159/225], Training Accuracy: 73.0542%, Training Loss: 0.6196%\n",
      "Epoch [23/300], Step [160/225], Training Accuracy: 73.0273%, Training Loss: 0.6199%\n",
      "Epoch [23/300], Step [161/225], Training Accuracy: 72.9717%, Training Loss: 0.6202%\n",
      "Epoch [23/300], Step [162/225], Training Accuracy: 72.9938%, Training Loss: 0.6195%\n",
      "Epoch [23/300], Step [163/225], Training Accuracy: 72.9870%, Training Loss: 0.6197%\n",
      "Epoch [23/300], Step [164/225], Training Accuracy: 72.9611%, Training Loss: 0.6206%\n",
      "Epoch [23/300], Step [165/225], Training Accuracy: 72.9640%, Training Loss: 0.6206%\n",
      "Epoch [23/300], Step [166/225], Training Accuracy: 72.9763%, Training Loss: 0.6203%\n",
      "Epoch [23/300], Step [167/225], Training Accuracy: 72.9884%, Training Loss: 0.6204%\n",
      "Epoch [23/300], Step [168/225], Training Accuracy: 72.9725%, Training Loss: 0.6202%\n",
      "Epoch [23/300], Step [169/225], Training Accuracy: 73.0122%, Training Loss: 0.6194%\n",
      "Epoch [23/300], Step [170/225], Training Accuracy: 73.1066%, Training Loss: 0.6183%\n",
      "Epoch [23/300], Step [171/225], Training Accuracy: 73.1451%, Training Loss: 0.6178%\n",
      "Epoch [23/300], Step [172/225], Training Accuracy: 73.1650%, Training Loss: 0.6178%\n",
      "Epoch [23/300], Step [173/225], Training Accuracy: 73.1756%, Training Loss: 0.6178%\n",
      "Epoch [23/300], Step [174/225], Training Accuracy: 73.1591%, Training Loss: 0.6178%\n",
      "Epoch [23/300], Step [175/225], Training Accuracy: 73.1875%, Training Loss: 0.6173%\n",
      "Epoch [23/300], Step [176/225], Training Accuracy: 73.1712%, Training Loss: 0.6177%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/300], Step [177/225], Training Accuracy: 73.1815%, Training Loss: 0.6185%\n",
      "Epoch [23/300], Step [178/225], Training Accuracy: 73.2268%, Training Loss: 0.6175%\n",
      "Epoch [23/300], Step [179/225], Training Accuracy: 73.2455%, Training Loss: 0.6173%\n",
      "Epoch [23/300], Step [180/225], Training Accuracy: 73.2726%, Training Loss: 0.6166%\n",
      "Epoch [23/300], Step [181/225], Training Accuracy: 73.2907%, Training Loss: 0.6166%\n",
      "Epoch [23/300], Step [182/225], Training Accuracy: 73.2830%, Training Loss: 0.6165%\n",
      "Epoch [23/300], Step [183/225], Training Accuracy: 73.2838%, Training Loss: 0.6164%\n",
      "Epoch [23/300], Step [184/225], Training Accuracy: 73.2931%, Training Loss: 0.6160%\n",
      "Epoch [23/300], Step [185/225], Training Accuracy: 73.3361%, Training Loss: 0.6156%\n",
      "Epoch [23/300], Step [186/225], Training Accuracy: 73.4039%, Training Loss: 0.6147%\n",
      "Epoch [23/300], Step [187/225], Training Accuracy: 73.4041%, Training Loss: 0.6147%\n",
      "Epoch [23/300], Step [188/225], Training Accuracy: 73.4707%, Training Loss: 0.6136%\n",
      "Epoch [23/300], Step [189/225], Training Accuracy: 73.5119%, Training Loss: 0.6128%\n",
      "Epoch [23/300], Step [190/225], Training Accuracy: 73.5444%, Training Loss: 0.6124%\n",
      "Epoch [23/300], Step [191/225], Training Accuracy: 73.5357%, Training Loss: 0.6121%\n",
      "Epoch [23/300], Step [192/225], Training Accuracy: 73.5352%, Training Loss: 0.6113%\n",
      "Epoch [23/300], Step [193/225], Training Accuracy: 73.5185%, Training Loss: 0.6115%\n",
      "Epoch [23/300], Step [194/225], Training Accuracy: 73.4778%, Training Loss: 0.6121%\n",
      "Epoch [23/300], Step [195/225], Training Accuracy: 73.5096%, Training Loss: 0.6118%\n",
      "Epoch [23/300], Step [196/225], Training Accuracy: 73.4774%, Training Loss: 0.6127%\n",
      "Epoch [23/300], Step [197/225], Training Accuracy: 73.4692%, Training Loss: 0.6124%\n",
      "Epoch [23/300], Step [198/225], Training Accuracy: 73.5401%, Training Loss: 0.6110%\n",
      "Epoch [23/300], Step [199/225], Training Accuracy: 73.5553%, Training Loss: 0.6105%\n",
      "Epoch [23/300], Step [200/225], Training Accuracy: 73.5234%, Training Loss: 0.6120%\n",
      "Epoch [23/300], Step [201/225], Training Accuracy: 73.5386%, Training Loss: 0.6116%\n",
      "Epoch [23/300], Step [202/225], Training Accuracy: 73.5071%, Training Loss: 0.6120%\n",
      "Epoch [23/300], Step [203/225], Training Accuracy: 73.5145%, Training Loss: 0.6120%\n",
      "Epoch [23/300], Step [204/225], Training Accuracy: 73.5064%, Training Loss: 0.6120%\n",
      "Epoch [23/300], Step [205/225], Training Accuracy: 73.5366%, Training Loss: 0.6116%\n",
      "Epoch [23/300], Step [206/225], Training Accuracy: 73.5361%, Training Loss: 0.6120%\n",
      "Epoch [23/300], Step [207/225], Training Accuracy: 73.5658%, Training Loss: 0.6117%\n",
      "Epoch [23/300], Step [208/225], Training Accuracy: 73.5877%, Training Loss: 0.6116%\n",
      "Epoch [23/300], Step [209/225], Training Accuracy: 73.6020%, Training Loss: 0.6118%\n",
      "Epoch [23/300], Step [210/225], Training Accuracy: 73.6086%, Training Loss: 0.6118%\n",
      "Epoch [23/300], Step [211/225], Training Accuracy: 73.6152%, Training Loss: 0.6115%\n",
      "Epoch [23/300], Step [212/225], Training Accuracy: 73.6144%, Training Loss: 0.6110%\n",
      "Epoch [23/300], Step [213/225], Training Accuracy: 73.6136%, Training Loss: 0.6109%\n",
      "Epoch [23/300], Step [214/225], Training Accuracy: 73.6711%, Training Loss: 0.6100%\n",
      "Epoch [23/300], Step [215/225], Training Accuracy: 73.6991%, Training Loss: 0.6096%\n",
      "Epoch [23/300], Step [216/225], Training Accuracy: 73.6617%, Training Loss: 0.6100%\n",
      "Epoch [23/300], Step [217/225], Training Accuracy: 73.5959%, Training Loss: 0.6109%\n",
      "Epoch [23/300], Step [218/225], Training Accuracy: 73.5522%, Training Loss: 0.6120%\n",
      "Epoch [23/300], Step [219/225], Training Accuracy: 73.5445%, Training Loss: 0.6125%\n",
      "Epoch [23/300], Step [220/225], Training Accuracy: 73.5369%, Training Loss: 0.6127%\n",
      "Epoch [23/300], Step [221/225], Training Accuracy: 73.5506%, Training Loss: 0.6122%\n",
      "Epoch [23/300], Step [222/225], Training Accuracy: 73.5783%, Training Loss: 0.6124%\n",
      "Epoch [23/300], Step [223/225], Training Accuracy: 73.5146%, Training Loss: 0.6128%\n",
      "Epoch [23/300], Step [224/225], Training Accuracy: 73.4863%, Training Loss: 0.6128%\n",
      "Epoch [23/300], Step [225/225], Training Accuracy: 73.4922%, Training Loss: 0.6122%\n",
      "Epoch [24/300], Step [1/225], Training Accuracy: 73.4375%, Training Loss: 0.5106%\n",
      "Epoch [24/300], Step [2/225], Training Accuracy: 69.5312%, Training Loss: 0.6639%\n",
      "Epoch [24/300], Step [3/225], Training Accuracy: 70.3125%, Training Loss: 0.6631%\n",
      "Epoch [24/300], Step [4/225], Training Accuracy: 69.1406%, Training Loss: 0.6769%\n",
      "Epoch [24/300], Step [5/225], Training Accuracy: 69.6875%, Training Loss: 0.6842%\n",
      "Epoch [24/300], Step [6/225], Training Accuracy: 70.8333%, Training Loss: 0.6470%\n",
      "Epoch [24/300], Step [7/225], Training Accuracy: 70.3125%, Training Loss: 0.6467%\n",
      "Epoch [24/300], Step [8/225], Training Accuracy: 70.1172%, Training Loss: 0.6407%\n",
      "Epoch [24/300], Step [9/225], Training Accuracy: 70.6597%, Training Loss: 0.6318%\n",
      "Epoch [24/300], Step [10/225], Training Accuracy: 69.0625%, Training Loss: 0.6519%\n",
      "Epoch [24/300], Step [11/225], Training Accuracy: 70.4545%, Training Loss: 0.6379%\n",
      "Epoch [24/300], Step [12/225], Training Accuracy: 70.8333%, Training Loss: 0.6294%\n",
      "Epoch [24/300], Step [13/225], Training Accuracy: 71.9952%, Training Loss: 0.6117%\n",
      "Epoch [24/300], Step [14/225], Training Accuracy: 72.0982%, Training Loss: 0.6087%\n",
      "Epoch [24/300], Step [15/225], Training Accuracy: 72.5000%, Training Loss: 0.6099%\n",
      "Epoch [24/300], Step [16/225], Training Accuracy: 72.9492%, Training Loss: 0.6053%\n",
      "Epoch [24/300], Step [17/225], Training Accuracy: 72.7941%, Training Loss: 0.6065%\n",
      "Epoch [24/300], Step [18/225], Training Accuracy: 72.3958%, Training Loss: 0.6170%\n",
      "Epoch [24/300], Step [19/225], Training Accuracy: 72.6151%, Training Loss: 0.6100%\n",
      "Epoch [24/300], Step [20/225], Training Accuracy: 72.8906%, Training Loss: 0.6051%\n",
      "Epoch [24/300], Step [21/225], Training Accuracy: 73.3631%, Training Loss: 0.5955%\n",
      "Epoch [24/300], Step [22/225], Training Accuracy: 73.2955%, Training Loss: 0.5989%\n",
      "Epoch [24/300], Step [23/225], Training Accuracy: 73.0299%, Training Loss: 0.6034%\n",
      "Epoch [24/300], Step [24/225], Training Accuracy: 73.0469%, Training Loss: 0.6002%\n",
      "Epoch [24/300], Step [25/225], Training Accuracy: 72.9375%, Training Loss: 0.6005%\n",
      "Epoch [24/300], Step [26/225], Training Accuracy: 73.1370%, Training Loss: 0.5994%\n",
      "Epoch [24/300], Step [27/225], Training Accuracy: 73.0324%, Training Loss: 0.6007%\n",
      "Epoch [24/300], Step [28/225], Training Accuracy: 73.3259%, Training Loss: 0.5950%\n",
      "Epoch [24/300], Step [29/225], Training Accuracy: 73.3836%, Training Loss: 0.5930%\n",
      "Epoch [24/300], Step [30/225], Training Accuracy: 73.5417%, Training Loss: 0.5890%\n",
      "Epoch [24/300], Step [31/225], Training Accuracy: 73.5383%, Training Loss: 0.5913%\n",
      "Epoch [24/300], Step [32/225], Training Accuracy: 73.7305%, Training Loss: 0.5863%\n",
      "Epoch [24/300], Step [33/225], Training Accuracy: 73.8636%, Training Loss: 0.5831%\n",
      "Epoch [24/300], Step [34/225], Training Accuracy: 73.6673%, Training Loss: 0.5872%\n",
      "Epoch [24/300], Step [35/225], Training Accuracy: 73.8839%, Training Loss: 0.5844%\n",
      "Epoch [24/300], Step [36/225], Training Accuracy: 73.8715%, Training Loss: 0.5847%\n",
      "Epoch [24/300], Step [37/225], Training Accuracy: 73.8176%, Training Loss: 0.5859%\n",
      "Epoch [24/300], Step [38/225], Training Accuracy: 74.1365%, Training Loss: 0.5822%\n",
      "Epoch [24/300], Step [39/225], Training Accuracy: 74.1587%, Training Loss: 0.5831%\n",
      "Epoch [24/300], Step [40/225], Training Accuracy: 74.1016%, Training Loss: 0.5839%\n",
      "Epoch [24/300], Step [41/225], Training Accuracy: 73.9329%, Training Loss: 0.5853%\n",
      "Epoch [24/300], Step [42/225], Training Accuracy: 73.8467%, Training Loss: 0.5850%\n",
      "Epoch [24/300], Step [43/225], Training Accuracy: 73.9099%, Training Loss: 0.5849%\n",
      "Epoch [24/300], Step [44/225], Training Accuracy: 74.0412%, Training Loss: 0.5815%\n",
      "Epoch [24/300], Step [45/225], Training Accuracy: 74.1319%, Training Loss: 0.5808%\n",
      "Epoch [24/300], Step [46/225], Training Accuracy: 74.2867%, Training Loss: 0.5787%\n",
      "Epoch [24/300], Step [47/225], Training Accuracy: 74.2686%, Training Loss: 0.5810%\n",
      "Epoch [24/300], Step [48/225], Training Accuracy: 73.9583%, Training Loss: 0.5846%\n",
      "Epoch [24/300], Step [49/225], Training Accuracy: 74.1390%, Training Loss: 0.5823%\n",
      "Epoch [24/300], Step [50/225], Training Accuracy: 74.2500%, Training Loss: 0.5806%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/300], Step [51/225], Training Accuracy: 74.3566%, Training Loss: 0.5772%\n",
      "Epoch [24/300], Step [52/225], Training Accuracy: 74.5793%, Training Loss: 0.5739%\n",
      "Epoch [24/300], Step [53/225], Training Accuracy: 74.3219%, Training Loss: 0.5773%\n",
      "Epoch [24/300], Step [54/225], Training Accuracy: 74.3924%, Training Loss: 0.5777%\n",
      "Epoch [24/300], Step [55/225], Training Accuracy: 74.3182%, Training Loss: 0.5787%\n",
      "Epoch [24/300], Step [56/225], Training Accuracy: 74.4699%, Training Loss: 0.5754%\n",
      "Epoch [24/300], Step [57/225], Training Accuracy: 74.4243%, Training Loss: 0.5744%\n",
      "Epoch [24/300], Step [58/225], Training Accuracy: 74.4343%, Training Loss: 0.5752%\n",
      "Epoch [24/300], Step [59/225], Training Accuracy: 74.3114%, Training Loss: 0.5768%\n",
      "Epoch [24/300], Step [60/225], Training Accuracy: 74.2969%, Training Loss: 0.5775%\n",
      "Epoch [24/300], Step [61/225], Training Accuracy: 74.2059%, Training Loss: 0.5794%\n",
      "Epoch [24/300], Step [62/225], Training Accuracy: 74.2692%, Training Loss: 0.5786%\n",
      "Epoch [24/300], Step [63/225], Training Accuracy: 74.2560%, Training Loss: 0.5792%\n",
      "Epoch [24/300], Step [64/225], Training Accuracy: 74.2432%, Training Loss: 0.5788%\n",
      "Epoch [24/300], Step [65/225], Training Accuracy: 74.3510%, Training Loss: 0.5778%\n",
      "Epoch [24/300], Step [66/225], Training Accuracy: 74.4792%, Training Loss: 0.5771%\n",
      "Epoch [24/300], Step [67/225], Training Accuracy: 74.3937%, Training Loss: 0.5780%\n",
      "Epoch [24/300], Step [68/225], Training Accuracy: 74.2877%, Training Loss: 0.5805%\n",
      "Epoch [24/300], Step [69/225], Training Accuracy: 74.2074%, Training Loss: 0.5818%\n",
      "Epoch [24/300], Step [70/225], Training Accuracy: 74.3304%, Training Loss: 0.5796%\n",
      "Epoch [24/300], Step [71/225], Training Accuracy: 74.4498%, Training Loss: 0.5774%\n",
      "Epoch [24/300], Step [72/225], Training Accuracy: 74.4575%, Training Loss: 0.5784%\n",
      "Epoch [24/300], Step [73/225], Training Accuracy: 74.4649%, Training Loss: 0.5789%\n",
      "Epoch [24/300], Step [74/225], Training Accuracy: 74.4721%, Training Loss: 0.5776%\n",
      "Epoch [24/300], Step [75/225], Training Accuracy: 74.5625%, Training Loss: 0.5761%\n",
      "Epoch [24/300], Step [76/225], Training Accuracy: 74.4449%, Training Loss: 0.5776%\n",
      "Epoch [24/300], Step [77/225], Training Accuracy: 74.5333%, Training Loss: 0.5769%\n",
      "Epoch [24/300], Step [78/225], Training Accuracy: 74.3990%, Training Loss: 0.5810%\n",
      "Epoch [24/300], Step [79/225], Training Accuracy: 74.3869%, Training Loss: 0.5816%\n",
      "Epoch [24/300], Step [80/225], Training Accuracy: 74.3164%, Training Loss: 0.5823%\n",
      "Epoch [24/300], Step [81/225], Training Accuracy: 74.3827%, Training Loss: 0.5815%\n",
      "Epoch [24/300], Step [82/225], Training Accuracy: 74.3712%, Training Loss: 0.5813%\n",
      "Epoch [24/300], Step [83/225], Training Accuracy: 74.3035%, Training Loss: 0.5839%\n",
      "Epoch [24/300], Step [84/225], Training Accuracy: 74.3862%, Training Loss: 0.5827%\n",
      "Epoch [24/300], Step [85/225], Training Accuracy: 74.4118%, Training Loss: 0.5827%\n",
      "Epoch [24/300], Step [86/225], Training Accuracy: 74.4913%, Training Loss: 0.5812%\n",
      "Epoch [24/300], Step [87/225], Training Accuracy: 74.4253%, Training Loss: 0.5821%\n",
      "Epoch [24/300], Step [88/225], Training Accuracy: 74.4851%, Training Loss: 0.5826%\n",
      "Epoch [24/300], Step [89/225], Training Accuracy: 74.5260%, Training Loss: 0.5832%\n",
      "Epoch [24/300], Step [90/225], Training Accuracy: 74.5660%, Training Loss: 0.5835%\n",
      "Epoch [24/300], Step [91/225], Training Accuracy: 74.5879%, Training Loss: 0.5836%\n",
      "Epoch [24/300], Step [92/225], Training Accuracy: 74.6264%, Training Loss: 0.5826%\n",
      "Epoch [24/300], Step [93/225], Training Accuracy: 74.7312%, Training Loss: 0.5804%\n",
      "Epoch [24/300], Step [94/225], Training Accuracy: 74.7340%, Training Loss: 0.5806%\n",
      "Epoch [24/300], Step [95/225], Training Accuracy: 74.7039%, Training Loss: 0.5809%\n",
      "Epoch [24/300], Step [96/225], Training Accuracy: 74.7070%, Training Loss: 0.5805%\n",
      "Epoch [24/300], Step [97/225], Training Accuracy: 74.7584%, Training Loss: 0.5802%\n",
      "Epoch [24/300], Step [98/225], Training Accuracy: 74.8406%, Training Loss: 0.5795%\n",
      "Epoch [24/300], Step [99/225], Training Accuracy: 74.8422%, Training Loss: 0.5808%\n",
      "Epoch [24/300], Step [100/225], Training Accuracy: 74.7188%, Training Loss: 0.5841%\n",
      "Epoch [24/300], Step [101/225], Training Accuracy: 74.6751%, Training Loss: 0.5846%\n",
      "Epoch [24/300], Step [102/225], Training Accuracy: 74.6477%, Training Loss: 0.5855%\n",
      "Epoch [24/300], Step [103/225], Training Accuracy: 74.5752%, Training Loss: 0.5865%\n",
      "Epoch [24/300], Step [104/225], Training Accuracy: 74.5343%, Training Loss: 0.5860%\n",
      "Epoch [24/300], Step [105/225], Training Accuracy: 74.5982%, Training Loss: 0.5846%\n",
      "Epoch [24/300], Step [106/225], Training Accuracy: 74.6020%, Training Loss: 0.5846%\n",
      "Epoch [24/300], Step [107/225], Training Accuracy: 74.5035%, Training Loss: 0.5858%\n",
      "Epoch [24/300], Step [108/225], Training Accuracy: 74.4647%, Training Loss: 0.5871%\n",
      "Epoch [24/300], Step [109/225], Training Accuracy: 74.4553%, Training Loss: 0.5875%\n",
      "Epoch [24/300], Step [110/225], Training Accuracy: 74.4744%, Training Loss: 0.5874%\n",
      "Epoch [24/300], Step [111/225], Training Accuracy: 74.4510%, Training Loss: 0.5877%\n",
      "Epoch [24/300], Step [112/225], Training Accuracy: 74.4141%, Training Loss: 0.5888%\n",
      "Epoch [24/300], Step [113/225], Training Accuracy: 74.3501%, Training Loss: 0.5918%\n",
      "Epoch [24/300], Step [114/225], Training Accuracy: 74.3421%, Training Loss: 0.5913%\n",
      "Epoch [24/300], Step [115/225], Training Accuracy: 74.3886%, Training Loss: 0.5908%\n",
      "Epoch [24/300], Step [116/225], Training Accuracy: 74.3669%, Training Loss: 0.5923%\n",
      "Epoch [24/300], Step [117/225], Training Accuracy: 74.2922%, Training Loss: 0.5939%\n",
      "Epoch [24/300], Step [118/225], Training Accuracy: 74.2585%, Training Loss: 0.5951%\n",
      "Epoch [24/300], Step [119/225], Training Accuracy: 74.2384%, Training Loss: 0.5946%\n",
      "Epoch [24/300], Step [120/225], Training Accuracy: 74.2318%, Training Loss: 0.5946%\n",
      "Epoch [24/300], Step [121/225], Training Accuracy: 74.2639%, Training Loss: 0.5938%\n",
      "Epoch [24/300], Step [122/225], Training Accuracy: 74.2188%, Training Loss: 0.5943%\n",
      "Epoch [24/300], Step [123/225], Training Accuracy: 74.2759%, Training Loss: 0.5936%\n",
      "Epoch [24/300], Step [124/225], Training Accuracy: 74.3196%, Training Loss: 0.5923%\n",
      "Epoch [24/300], Step [125/225], Training Accuracy: 74.3125%, Training Loss: 0.5932%\n",
      "Epoch [24/300], Step [126/225], Training Accuracy: 74.2932%, Training Loss: 0.5933%\n",
      "Epoch [24/300], Step [127/225], Training Accuracy: 74.2741%, Training Loss: 0.5937%\n",
      "Epoch [24/300], Step [128/225], Training Accuracy: 74.2432%, Training Loss: 0.5940%\n",
      "Epoch [24/300], Step [129/225], Training Accuracy: 74.2490%, Training Loss: 0.5936%\n",
      "Epoch [24/300], Step [130/225], Training Accuracy: 74.3269%, Training Loss: 0.5931%\n",
      "Epoch [24/300], Step [131/225], Training Accuracy: 74.2844%, Training Loss: 0.5945%\n",
      "Epoch [24/300], Step [132/225], Training Accuracy: 74.2898%, Training Loss: 0.5952%\n",
      "Epoch [24/300], Step [133/225], Training Accuracy: 74.3421%, Training Loss: 0.5946%\n",
      "Epoch [24/300], Step [134/225], Training Accuracy: 74.2537%, Training Loss: 0.5967%\n",
      "Epoch [24/300], Step [135/225], Training Accuracy: 74.2593%, Training Loss: 0.5959%\n",
      "Epoch [24/300], Step [136/225], Training Accuracy: 74.2532%, Training Loss: 0.5953%\n",
      "Epoch [24/300], Step [137/225], Training Accuracy: 74.3157%, Training Loss: 0.5946%\n",
      "Epoch [24/300], Step [138/225], Training Accuracy: 74.3773%, Training Loss: 0.5935%\n",
      "Epoch [24/300], Step [139/225], Training Accuracy: 74.3368%, Training Loss: 0.5939%\n",
      "Epoch [24/300], Step [140/225], Training Accuracy: 74.3304%, Training Loss: 0.5942%\n",
      "Epoch [24/300], Step [141/225], Training Accuracy: 74.3462%, Training Loss: 0.5943%\n",
      "Epoch [24/300], Step [142/225], Training Accuracy: 74.3068%, Training Loss: 0.5946%\n",
      "Epoch [24/300], Step [143/225], Training Accuracy: 74.2788%, Training Loss: 0.5945%\n",
      "Epoch [24/300], Step [144/225], Training Accuracy: 74.2513%, Training Loss: 0.5958%\n",
      "Epoch [24/300], Step [145/225], Training Accuracy: 74.2565%, Training Loss: 0.5955%\n",
      "Epoch [24/300], Step [146/225], Training Accuracy: 74.3044%, Training Loss: 0.5953%\n",
      "Epoch [24/300], Step [147/225], Training Accuracy: 74.3091%, Training Loss: 0.5961%\n",
      "Epoch [24/300], Step [148/225], Training Accuracy: 74.3560%, Training Loss: 0.5949%\n",
      "Epoch [24/300], Step [149/225], Training Accuracy: 74.3708%, Training Loss: 0.5947%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/300], Step [150/225], Training Accuracy: 74.4062%, Training Loss: 0.5942%\n",
      "Epoch [24/300], Step [151/225], Training Accuracy: 74.3791%, Training Loss: 0.5946%\n",
      "Epoch [24/300], Step [152/225], Training Accuracy: 74.4346%, Training Loss: 0.5947%\n",
      "Epoch [24/300], Step [153/225], Training Accuracy: 74.4587%, Training Loss: 0.5942%\n",
      "Epoch [24/300], Step [154/225], Training Accuracy: 74.4014%, Training Loss: 0.5954%\n",
      "Epoch [24/300], Step [155/225], Training Accuracy: 74.3649%, Training Loss: 0.5957%\n",
      "Epoch [24/300], Step [156/225], Training Accuracy: 74.3189%, Training Loss: 0.5968%\n",
      "Epoch [24/300], Step [157/225], Training Accuracy: 74.2834%, Training Loss: 0.5968%\n",
      "Epoch [24/300], Step [158/225], Training Accuracy: 74.1990%, Training Loss: 0.5989%\n",
      "Epoch [24/300], Step [159/225], Training Accuracy: 74.1942%, Training Loss: 0.5989%\n",
      "Epoch [24/300], Step [160/225], Training Accuracy: 74.1992%, Training Loss: 0.5985%\n",
      "Epoch [24/300], Step [161/225], Training Accuracy: 74.1654%, Training Loss: 0.5985%\n",
      "Epoch [24/300], Step [162/225], Training Accuracy: 74.1898%, Training Loss: 0.5981%\n",
      "Epoch [24/300], Step [163/225], Training Accuracy: 74.1852%, Training Loss: 0.5983%\n",
      "Epoch [24/300], Step [164/225], Training Accuracy: 74.2188%, Training Loss: 0.5975%\n",
      "Epoch [24/300], Step [165/225], Training Accuracy: 74.1572%, Training Loss: 0.5978%\n",
      "Epoch [24/300], Step [166/225], Training Accuracy: 74.1434%, Training Loss: 0.5980%\n",
      "Epoch [24/300], Step [167/225], Training Accuracy: 74.1860%, Training Loss: 0.5969%\n",
      "Epoch [24/300], Step [168/225], Training Accuracy: 74.2094%, Training Loss: 0.5971%\n",
      "Epoch [24/300], Step [169/225], Training Accuracy: 74.2419%, Training Loss: 0.5967%\n",
      "Epoch [24/300], Step [170/225], Training Accuracy: 74.2096%, Training Loss: 0.5973%\n",
      "Epoch [24/300], Step [171/225], Training Accuracy: 74.1502%, Training Loss: 0.5986%\n",
      "Epoch [24/300], Step [172/225], Training Accuracy: 74.2006%, Training Loss: 0.5979%\n",
      "Epoch [24/300], Step [173/225], Training Accuracy: 74.2413%, Training Loss: 0.5978%\n",
      "Epoch [24/300], Step [174/225], Training Accuracy: 74.3085%, Training Loss: 0.5966%\n",
      "Epoch [24/300], Step [175/225], Training Accuracy: 74.2946%, Training Loss: 0.5964%\n",
      "Epoch [24/300], Step [176/225], Training Accuracy: 74.2720%, Training Loss: 0.5961%\n",
      "Epoch [24/300], Step [177/225], Training Accuracy: 74.2850%, Training Loss: 0.5959%\n",
      "Epoch [24/300], Step [178/225], Training Accuracy: 74.3416%, Training Loss: 0.5952%\n",
      "Epoch [24/300], Step [179/225], Training Accuracy: 74.3802%, Training Loss: 0.5944%\n",
      "Epoch [24/300], Step [180/225], Training Accuracy: 74.3663%, Training Loss: 0.5944%\n",
      "Epoch [24/300], Step [181/225], Training Accuracy: 74.3612%, Training Loss: 0.5951%\n",
      "Epoch [24/300], Step [182/225], Training Accuracy: 74.3561%, Training Loss: 0.5944%\n",
      "Epoch [24/300], Step [183/225], Training Accuracy: 74.3682%, Training Loss: 0.5940%\n",
      "Epoch [24/300], Step [184/225], Training Accuracy: 74.3886%, Training Loss: 0.5946%\n",
      "Epoch [24/300], Step [185/225], Training Accuracy: 74.4257%, Training Loss: 0.5937%\n",
      "Epoch [24/300], Step [186/225], Training Accuracy: 74.4624%, Training Loss: 0.5928%\n",
      "Epoch [24/300], Step [187/225], Training Accuracy: 74.4652%, Training Loss: 0.5930%\n",
      "Epoch [24/300], Step [188/225], Training Accuracy: 74.5096%, Training Loss: 0.5923%\n",
      "Epoch [24/300], Step [189/225], Training Accuracy: 74.5618%, Training Loss: 0.5915%\n",
      "Epoch [24/300], Step [190/225], Training Accuracy: 74.5641%, Training Loss: 0.5913%\n",
      "Epoch [24/300], Step [191/225], Training Accuracy: 74.5501%, Training Loss: 0.5910%\n",
      "Epoch [24/300], Step [192/225], Training Accuracy: 74.5768%, Training Loss: 0.5904%\n",
      "Epoch [24/300], Step [193/225], Training Accuracy: 74.5385%, Training Loss: 0.5912%\n",
      "Epoch [24/300], Step [194/225], Training Accuracy: 74.5409%, Training Loss: 0.5915%\n",
      "Epoch [24/300], Step [195/225], Training Accuracy: 74.6394%, Training Loss: 0.5900%\n",
      "Epoch [24/300], Step [196/225], Training Accuracy: 74.6173%, Training Loss: 0.5898%\n",
      "Epoch [24/300], Step [197/225], Training Accuracy: 74.6431%, Training Loss: 0.5903%\n",
      "Epoch [24/300], Step [198/225], Training Accuracy: 74.7080%, Training Loss: 0.5890%\n",
      "Epoch [24/300], Step [199/225], Training Accuracy: 74.7095%, Training Loss: 0.5887%\n",
      "Epoch [24/300], Step [200/225], Training Accuracy: 74.6719%, Training Loss: 0.5901%\n",
      "Epoch [24/300], Step [201/225], Training Accuracy: 74.7046%, Training Loss: 0.5893%\n",
      "Epoch [24/300], Step [202/225], Training Accuracy: 74.6519%, Training Loss: 0.5898%\n",
      "Epoch [24/300], Step [203/225], Training Accuracy: 74.6767%, Training Loss: 0.5894%\n",
      "Epoch [24/300], Step [204/225], Training Accuracy: 74.6553%, Training Loss: 0.5896%\n",
      "Epoch [24/300], Step [205/225], Training Accuracy: 74.6875%, Training Loss: 0.5893%\n",
      "Epoch [24/300], Step [206/225], Training Accuracy: 74.7194%, Training Loss: 0.5888%\n",
      "Epoch [24/300], Step [207/225], Training Accuracy: 74.6679%, Training Loss: 0.5899%\n",
      "Epoch [24/300], Step [208/225], Training Accuracy: 74.6695%, Training Loss: 0.5892%\n",
      "Epoch [24/300], Step [209/225], Training Accuracy: 74.6636%, Training Loss: 0.5890%\n",
      "Epoch [24/300], Step [210/225], Training Accuracy: 74.6726%, Training Loss: 0.5890%\n",
      "Epoch [24/300], Step [211/225], Training Accuracy: 74.6742%, Training Loss: 0.5888%\n",
      "Epoch [24/300], Step [212/225], Training Accuracy: 74.6904%, Training Loss: 0.5886%\n",
      "Epoch [24/300], Step [213/225], Training Accuracy: 74.6479%, Training Loss: 0.5891%\n",
      "Epoch [24/300], Step [214/225], Training Accuracy: 74.7152%, Training Loss: 0.5880%\n",
      "Epoch [24/300], Step [215/225], Training Accuracy: 74.6584%, Training Loss: 0.5889%\n",
      "Epoch [24/300], Step [216/225], Training Accuracy: 74.6383%, Training Loss: 0.5895%\n",
      "Epoch [24/300], Step [217/225], Training Accuracy: 74.6472%, Training Loss: 0.5893%\n",
      "Epoch [24/300], Step [218/225], Training Accuracy: 74.6416%, Training Loss: 0.5901%\n",
      "Epoch [24/300], Step [219/225], Training Accuracy: 74.6433%, Training Loss: 0.5900%\n",
      "Epoch [24/300], Step [220/225], Training Accuracy: 74.6449%, Training Loss: 0.5900%\n",
      "Epoch [24/300], Step [221/225], Training Accuracy: 74.6960%, Training Loss: 0.5894%\n",
      "Epoch [24/300], Step [222/225], Training Accuracy: 74.7114%, Training Loss: 0.5890%\n",
      "Epoch [24/300], Step [223/225], Training Accuracy: 74.6847%, Training Loss: 0.5894%\n",
      "Epoch [24/300], Step [224/225], Training Accuracy: 74.6443%, Training Loss: 0.5904%\n",
      "Epoch [24/300], Step [225/225], Training Accuracy: 74.6665%, Training Loss: 0.5899%\n",
      "Epoch [25/300], Step [1/225], Training Accuracy: 79.6875%, Training Loss: 0.4921%\n",
      "Epoch [25/300], Step [2/225], Training Accuracy: 78.1250%, Training Loss: 0.5280%\n",
      "Epoch [25/300], Step [3/225], Training Accuracy: 75.0000%, Training Loss: 0.5812%\n",
      "Epoch [25/300], Step [4/225], Training Accuracy: 76.5625%, Training Loss: 0.5642%\n",
      "Epoch [25/300], Step [5/225], Training Accuracy: 75.6250%, Training Loss: 0.6034%\n",
      "Epoch [25/300], Step [6/225], Training Accuracy: 75.7812%, Training Loss: 0.5979%\n",
      "Epoch [25/300], Step [7/225], Training Accuracy: 75.8929%, Training Loss: 0.5963%\n",
      "Epoch [25/300], Step [8/225], Training Accuracy: 75.9766%, Training Loss: 0.5922%\n",
      "Epoch [25/300], Step [9/225], Training Accuracy: 75.5208%, Training Loss: 0.6036%\n",
      "Epoch [25/300], Step [10/225], Training Accuracy: 75.1562%, Training Loss: 0.6136%\n",
      "Epoch [25/300], Step [11/225], Training Accuracy: 75.5682%, Training Loss: 0.6043%\n",
      "Epoch [25/300], Step [12/225], Training Accuracy: 75.6510%, Training Loss: 0.5966%\n",
      "Epoch [25/300], Step [13/225], Training Accuracy: 75.8413%, Training Loss: 0.5840%\n",
      "Epoch [25/300], Step [14/225], Training Accuracy: 76.5625%, Training Loss: 0.5767%\n",
      "Epoch [25/300], Step [15/225], Training Accuracy: 76.4583%, Training Loss: 0.5734%\n",
      "Epoch [25/300], Step [16/225], Training Accuracy: 76.5625%, Training Loss: 0.5750%\n",
      "Epoch [25/300], Step [17/225], Training Accuracy: 76.2868%, Training Loss: 0.5743%\n",
      "Epoch [25/300], Step [18/225], Training Accuracy: 76.0417%, Training Loss: 0.5755%\n",
      "Epoch [25/300], Step [19/225], Training Accuracy: 75.6579%, Training Loss: 0.5779%\n",
      "Epoch [25/300], Step [20/225], Training Accuracy: 75.7812%, Training Loss: 0.5783%\n",
      "Epoch [25/300], Step [21/225], Training Accuracy: 76.1905%, Training Loss: 0.5781%\n",
      "Epoch [25/300], Step [22/225], Training Accuracy: 75.7102%, Training Loss: 0.5819%\n",
      "Epoch [25/300], Step [23/225], Training Accuracy: 75.8832%, Training Loss: 0.5809%\n",
      "Epoch [25/300], Step [24/225], Training Accuracy: 75.7161%, Training Loss: 0.5818%\n",
      "Epoch [25/300], Step [25/225], Training Accuracy: 75.6250%, Training Loss: 0.5876%\n",
      "Epoch [25/300], Step [26/225], Training Accuracy: 75.4808%, Training Loss: 0.5834%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/300], Step [27/225], Training Accuracy: 75.5787%, Training Loss: 0.5767%\n",
      "Epoch [25/300], Step [28/225], Training Accuracy: 75.8929%, Training Loss: 0.5713%\n",
      "Epoch [25/300], Step [29/225], Training Accuracy: 75.9698%, Training Loss: 0.5736%\n",
      "Epoch [25/300], Step [30/225], Training Accuracy: 76.0938%, Training Loss: 0.5742%\n",
      "Epoch [25/300], Step [31/225], Training Accuracy: 75.9073%, Training Loss: 0.5787%\n",
      "Epoch [25/300], Step [32/225], Training Accuracy: 75.7324%, Training Loss: 0.5794%\n",
      "Epoch [25/300], Step [33/225], Training Accuracy: 75.7102%, Training Loss: 0.5814%\n",
      "Epoch [25/300], Step [34/225], Training Accuracy: 75.3676%, Training Loss: 0.5916%\n",
      "Epoch [25/300], Step [35/225], Training Accuracy: 75.4464%, Training Loss: 0.5889%\n",
      "Epoch [25/300], Step [36/225], Training Accuracy: 75.2604%, Training Loss: 0.5916%\n",
      "Epoch [25/300], Step [37/225], Training Accuracy: 75.1689%, Training Loss: 0.5908%\n",
      "Epoch [25/300], Step [38/225], Training Accuracy: 75.1645%, Training Loss: 0.5903%\n",
      "Epoch [25/300], Step [39/225], Training Accuracy: 75.0401%, Training Loss: 0.5897%\n",
      "Epoch [25/300], Step [40/225], Training Accuracy: 75.1172%, Training Loss: 0.5870%\n",
      "Epoch [25/300], Step [41/225], Training Accuracy: 74.9238%, Training Loss: 0.5897%\n",
      "Epoch [25/300], Step [42/225], Training Accuracy: 74.7768%, Training Loss: 0.5905%\n",
      "Epoch [25/300], Step [43/225], Training Accuracy: 74.7093%, Training Loss: 0.5905%\n",
      "Epoch [25/300], Step [44/225], Training Accuracy: 74.8935%, Training Loss: 0.5864%\n",
      "Epoch [25/300], Step [45/225], Training Accuracy: 74.8958%, Training Loss: 0.5857%\n",
      "Epoch [25/300], Step [46/225], Training Accuracy: 75.1698%, Training Loss: 0.5836%\n",
      "Epoch [25/300], Step [47/225], Training Accuracy: 75.0332%, Training Loss: 0.5835%\n",
      "Epoch [25/300], Step [48/225], Training Accuracy: 75.0651%, Training Loss: 0.5814%\n",
      "Epoch [25/300], Step [49/225], Training Accuracy: 75.0319%, Training Loss: 0.5840%\n",
      "Epoch [25/300], Step [50/225], Training Accuracy: 74.9688%, Training Loss: 0.5860%\n",
      "Epoch [25/300], Step [51/225], Training Accuracy: 75.1225%, Training Loss: 0.5828%\n",
      "Epoch [25/300], Step [52/225], Training Accuracy: 75.1502%, Training Loss: 0.5837%\n",
      "Epoch [25/300], Step [53/225], Training Accuracy: 75.0884%, Training Loss: 0.5847%\n",
      "Epoch [25/300], Step [54/225], Training Accuracy: 74.9132%, Training Loss: 0.5875%\n",
      "Epoch [25/300], Step [55/225], Training Accuracy: 74.8864%, Training Loss: 0.5896%\n",
      "Epoch [25/300], Step [56/225], Training Accuracy: 74.9721%, Training Loss: 0.5883%\n",
      "Epoch [25/300], Step [57/225], Training Accuracy: 75.0822%, Training Loss: 0.5865%\n",
      "Epoch [25/300], Step [58/225], Training Accuracy: 75.1078%, Training Loss: 0.5854%\n",
      "Epoch [25/300], Step [59/225], Training Accuracy: 74.9735%, Training Loss: 0.5870%\n",
      "Epoch [25/300], Step [60/225], Training Accuracy: 75.0781%, Training Loss: 0.5862%\n",
      "Epoch [25/300], Step [61/225], Training Accuracy: 75.1793%, Training Loss: 0.5851%\n",
      "Epoch [25/300], Step [62/225], Training Accuracy: 75.2772%, Training Loss: 0.5825%\n",
      "Epoch [25/300], Step [63/225], Training Accuracy: 75.3224%, Training Loss: 0.5810%\n",
      "Epoch [25/300], Step [64/225], Training Accuracy: 75.2930%, Training Loss: 0.5816%\n",
      "Epoch [25/300], Step [65/225], Training Accuracy: 75.2885%, Training Loss: 0.5833%\n",
      "Epoch [25/300], Step [66/225], Training Accuracy: 75.3078%, Training Loss: 0.5840%\n",
      "Epoch [25/300], Step [67/225], Training Accuracy: 75.2799%, Training Loss: 0.5858%\n",
      "Epoch [25/300], Step [68/225], Training Accuracy: 75.1838%, Training Loss: 0.5860%\n",
      "Epoch [25/300], Step [69/225], Training Accuracy: 75.1812%, Training Loss: 0.5861%\n",
      "Epoch [25/300], Step [70/225], Training Accuracy: 75.2009%, Training Loss: 0.5857%\n",
      "Epoch [25/300], Step [71/225], Training Accuracy: 75.1540%, Training Loss: 0.5868%\n",
      "Epoch [25/300], Step [72/225], Training Accuracy: 75.0868%, Training Loss: 0.5879%\n",
      "Epoch [25/300], Step [73/225], Training Accuracy: 75.0642%, Training Loss: 0.5873%\n",
      "Epoch [25/300], Step [74/225], Training Accuracy: 75.0633%, Training Loss: 0.5861%\n",
      "Epoch [25/300], Step [75/225], Training Accuracy: 74.9583%, Training Loss: 0.5875%\n",
      "Epoch [25/300], Step [76/225], Training Accuracy: 74.9178%, Training Loss: 0.5890%\n",
      "Epoch [25/300], Step [77/225], Training Accuracy: 74.8782%, Training Loss: 0.5899%\n",
      "Epoch [25/300], Step [78/225], Training Accuracy: 74.7997%, Training Loss: 0.5916%\n",
      "Epoch [25/300], Step [79/225], Training Accuracy: 74.8022%, Training Loss: 0.5930%\n",
      "Epoch [25/300], Step [80/225], Training Accuracy: 74.8828%, Training Loss: 0.5912%\n",
      "Epoch [25/300], Step [81/225], Training Accuracy: 74.9614%, Training Loss: 0.5891%\n",
      "Epoch [25/300], Step [82/225], Training Accuracy: 74.9809%, Training Loss: 0.5886%\n",
      "Epoch [25/300], Step [83/225], Training Accuracy: 74.9247%, Training Loss: 0.5894%\n",
      "Epoch [25/300], Step [84/225], Training Accuracy: 75.0000%, Training Loss: 0.5873%\n",
      "Epoch [25/300], Step [85/225], Training Accuracy: 75.1103%, Training Loss: 0.5853%\n",
      "Epoch [25/300], Step [86/225], Training Accuracy: 75.2180%, Training Loss: 0.5833%\n",
      "Epoch [25/300], Step [87/225], Training Accuracy: 75.2335%, Training Loss: 0.5839%\n",
      "Epoch [25/300], Step [88/225], Training Accuracy: 75.2308%, Training Loss: 0.5842%\n",
      "Epoch [25/300], Step [89/225], Training Accuracy: 75.1229%, Training Loss: 0.5848%\n",
      "Epoch [25/300], Step [90/225], Training Accuracy: 75.1562%, Training Loss: 0.5842%\n",
      "Epoch [25/300], Step [91/225], Training Accuracy: 75.1374%, Training Loss: 0.5839%\n",
      "Epoch [25/300], Step [92/225], Training Accuracy: 75.0849%, Training Loss: 0.5859%\n",
      "Epoch [25/300], Step [93/225], Training Accuracy: 75.1008%, Training Loss: 0.5852%\n",
      "Epoch [25/300], Step [94/225], Training Accuracy: 75.0831%, Training Loss: 0.5853%\n",
      "Epoch [25/300], Step [95/225], Training Accuracy: 75.0987%, Training Loss: 0.5858%\n",
      "Epoch [25/300], Step [96/225], Training Accuracy: 75.1790%, Training Loss: 0.5848%\n",
      "Epoch [25/300], Step [97/225], Training Accuracy: 75.1611%, Training Loss: 0.5867%\n",
      "Epoch [25/300], Step [98/225], Training Accuracy: 75.1754%, Training Loss: 0.5857%\n",
      "Epoch [25/300], Step [99/225], Training Accuracy: 75.2210%, Training Loss: 0.5866%\n",
      "Epoch [25/300], Step [100/225], Training Accuracy: 75.0625%, Training Loss: 0.5891%\n",
      "Epoch [25/300], Step [101/225], Training Accuracy: 75.0000%, Training Loss: 0.5898%\n",
      "Epoch [25/300], Step [102/225], Training Accuracy: 75.0000%, Training Loss: 0.5898%\n",
      "Epoch [25/300], Step [103/225], Training Accuracy: 74.9848%, Training Loss: 0.5893%\n",
      "Epoch [25/300], Step [104/225], Training Accuracy: 75.0751%, Training Loss: 0.5885%\n",
      "Epoch [25/300], Step [105/225], Training Accuracy: 75.1190%, Training Loss: 0.5893%\n",
      "Epoch [25/300], Step [106/225], Training Accuracy: 75.1916%, Training Loss: 0.5893%\n",
      "Epoch [25/300], Step [107/225], Training Accuracy: 75.1752%, Training Loss: 0.5899%\n",
      "Epoch [25/300], Step [108/225], Training Accuracy: 75.1736%, Training Loss: 0.5906%\n",
      "Epoch [25/300], Step [109/225], Training Accuracy: 75.2150%, Training Loss: 0.5911%\n",
      "Epoch [25/300], Step [110/225], Training Accuracy: 75.2415%, Training Loss: 0.5908%\n",
      "Epoch [25/300], Step [111/225], Training Accuracy: 75.1830%, Training Loss: 0.5914%\n",
      "Epoch [25/300], Step [112/225], Training Accuracy: 75.1256%, Training Loss: 0.5919%\n",
      "Epoch [25/300], Step [113/225], Training Accuracy: 75.0968%, Training Loss: 0.5931%\n",
      "Epoch [25/300], Step [114/225], Training Accuracy: 75.1234%, Training Loss: 0.5919%\n",
      "Epoch [25/300], Step [115/225], Training Accuracy: 75.1902%, Training Loss: 0.5907%\n",
      "Epoch [25/300], Step [116/225], Training Accuracy: 75.1078%, Training Loss: 0.5923%\n",
      "Epoch [25/300], Step [117/225], Training Accuracy: 75.0000%, Training Loss: 0.5955%\n",
      "Epoch [25/300], Step [118/225], Training Accuracy: 75.0000%, Training Loss: 0.5948%\n",
      "Epoch [25/300], Step [119/225], Training Accuracy: 75.0131%, Training Loss: 0.5936%\n",
      "Epoch [25/300], Step [120/225], Training Accuracy: 74.9609%, Training Loss: 0.5947%\n",
      "Epoch [25/300], Step [121/225], Training Accuracy: 74.9742%, Training Loss: 0.5946%\n",
      "Epoch [25/300], Step [122/225], Training Accuracy: 74.9488%, Training Loss: 0.5941%\n",
      "Epoch [25/300], Step [123/225], Training Accuracy: 75.0254%, Training Loss: 0.5927%\n",
      "Epoch [25/300], Step [124/225], Training Accuracy: 75.0126%, Training Loss: 0.5920%\n",
      "Epoch [25/300], Step [125/225], Training Accuracy: 75.0500%, Training Loss: 0.5913%\n",
      "Epoch [25/300], Step [126/225], Training Accuracy: 75.1240%, Training Loss: 0.5903%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/300], Step [127/225], Training Accuracy: 75.0861%, Training Loss: 0.5903%\n",
      "Epoch [25/300], Step [128/225], Training Accuracy: 75.0732%, Training Loss: 0.5904%\n",
      "Epoch [25/300], Step [129/225], Training Accuracy: 75.0242%, Training Loss: 0.5908%\n",
      "Epoch [25/300], Step [130/225], Training Accuracy: 75.0120%, Training Loss: 0.5915%\n",
      "Epoch [25/300], Step [131/225], Training Accuracy: 75.0239%, Training Loss: 0.5919%\n",
      "Epoch [25/300], Step [132/225], Training Accuracy: 75.0473%, Training Loss: 0.5918%\n",
      "Epoch [25/300], Step [133/225], Training Accuracy: 75.0705%, Training Loss: 0.5921%\n",
      "Epoch [25/300], Step [134/225], Training Accuracy: 75.0233%, Training Loss: 0.5927%\n",
      "Epoch [25/300], Step [135/225], Training Accuracy: 75.0347%, Training Loss: 0.5937%\n",
      "Epoch [25/300], Step [136/225], Training Accuracy: 75.0345%, Training Loss: 0.5945%\n",
      "Epoch [25/300], Step [137/225], Training Accuracy: 75.0000%, Training Loss: 0.5950%\n",
      "Epoch [25/300], Step [138/225], Training Accuracy: 75.0566%, Training Loss: 0.5934%\n",
      "Epoch [25/300], Step [139/225], Training Accuracy: 75.0337%, Training Loss: 0.5941%\n",
      "Epoch [25/300], Step [140/225], Training Accuracy: 74.9888%, Training Loss: 0.5938%\n",
      "Epoch [25/300], Step [141/225], Training Accuracy: 74.9557%, Training Loss: 0.5940%\n",
      "Epoch [25/300], Step [142/225], Training Accuracy: 74.9560%, Training Loss: 0.5939%\n",
      "Epoch [25/300], Step [143/225], Training Accuracy: 74.9672%, Training Loss: 0.5942%\n",
      "Epoch [25/300], Step [144/225], Training Accuracy: 74.9566%, Training Loss: 0.5946%\n",
      "Epoch [25/300], Step [145/225], Training Accuracy: 74.9246%, Training Loss: 0.5945%\n",
      "Epoch [25/300], Step [146/225], Training Accuracy: 74.9465%, Training Loss: 0.5942%\n",
      "Epoch [25/300], Step [147/225], Training Accuracy: 74.9681%, Training Loss: 0.5940%\n",
      "Epoch [25/300], Step [148/225], Training Accuracy: 74.9578%, Training Loss: 0.5946%\n",
      "Epoch [25/300], Step [149/225], Training Accuracy: 74.9685%, Training Loss: 0.5944%\n",
      "Epoch [25/300], Step [150/225], Training Accuracy: 74.9792%, Training Loss: 0.5942%\n",
      "Epoch [25/300], Step [151/225], Training Accuracy: 74.9586%, Training Loss: 0.5940%\n",
      "Epoch [25/300], Step [152/225], Training Accuracy: 74.9280%, Training Loss: 0.5944%\n",
      "Epoch [25/300], Step [153/225], Training Accuracy: 74.9183%, Training Loss: 0.5942%\n",
      "Epoch [25/300], Step [154/225], Training Accuracy: 74.9290%, Training Loss: 0.5935%\n",
      "Epoch [25/300], Step [155/225], Training Accuracy: 74.9093%, Training Loss: 0.5936%\n",
      "Epoch [25/300], Step [156/225], Training Accuracy: 74.8998%, Training Loss: 0.5942%\n",
      "Epoch [25/300], Step [157/225], Training Accuracy: 74.8507%, Training Loss: 0.5949%\n",
      "Epoch [25/300], Step [158/225], Training Accuracy: 74.8220%, Training Loss: 0.5962%\n",
      "Epoch [25/300], Step [159/225], Training Accuracy: 74.7936%, Training Loss: 0.5965%\n",
      "Epoch [25/300], Step [160/225], Training Accuracy: 74.8145%, Training Loss: 0.5963%\n",
      "Epoch [25/300], Step [161/225], Training Accuracy: 74.8059%, Training Loss: 0.5967%\n",
      "Epoch [25/300], Step [162/225], Training Accuracy: 74.8071%, Training Loss: 0.5962%\n",
      "Epoch [25/300], Step [163/225], Training Accuracy: 74.7699%, Training Loss: 0.5962%\n",
      "Epoch [25/300], Step [164/225], Training Accuracy: 74.7904%, Training Loss: 0.5958%\n",
      "Epoch [25/300], Step [165/225], Training Accuracy: 74.8106%, Training Loss: 0.5957%\n",
      "Epoch [25/300], Step [166/225], Training Accuracy: 74.8306%, Training Loss: 0.5950%\n",
      "Epoch [25/300], Step [167/225], Training Accuracy: 74.8690%, Training Loss: 0.5948%\n",
      "Epoch [25/300], Step [168/225], Training Accuracy: 74.8512%, Training Loss: 0.5952%\n",
      "Epoch [25/300], Step [169/225], Training Accuracy: 74.9260%, Training Loss: 0.5944%\n",
      "Epoch [25/300], Step [170/225], Training Accuracy: 74.9449%, Training Loss: 0.5944%\n",
      "Epoch [25/300], Step [171/225], Training Accuracy: 74.9178%, Training Loss: 0.5945%\n",
      "Epoch [25/300], Step [172/225], Training Accuracy: 74.9182%, Training Loss: 0.5946%\n",
      "Epoch [25/300], Step [173/225], Training Accuracy: 74.9277%, Training Loss: 0.5944%\n",
      "Epoch [25/300], Step [174/225], Training Accuracy: 74.9461%, Training Loss: 0.5941%\n",
      "Epoch [25/300], Step [175/225], Training Accuracy: 74.9018%, Training Loss: 0.5946%\n",
      "Epoch [25/300], Step [176/225], Training Accuracy: 74.8846%, Training Loss: 0.5957%\n",
      "Epoch [25/300], Step [177/225], Training Accuracy: 74.9117%, Training Loss: 0.5953%\n",
      "Epoch [25/300], Step [178/225], Training Accuracy: 74.9561%, Training Loss: 0.5941%\n",
      "Epoch [25/300], Step [179/225], Training Accuracy: 75.0000%, Training Loss: 0.5935%\n",
      "Epoch [25/300], Step [180/225], Training Accuracy: 75.0000%, Training Loss: 0.5931%\n",
      "Epoch [25/300], Step [181/225], Training Accuracy: 74.9741%, Training Loss: 0.5933%\n",
      "Epoch [25/300], Step [182/225], Training Accuracy: 74.9742%, Training Loss: 0.5931%\n",
      "Epoch [25/300], Step [183/225], Training Accuracy: 74.9744%, Training Loss: 0.5926%\n",
      "Epoch [25/300], Step [184/225], Training Accuracy: 74.9660%, Training Loss: 0.5922%\n",
      "Epoch [25/300], Step [185/225], Training Accuracy: 74.9831%, Training Loss: 0.5921%\n",
      "Epoch [25/300], Step [186/225], Training Accuracy: 74.9832%, Training Loss: 0.5924%\n",
      "Epoch [25/300], Step [187/225], Training Accuracy: 74.9916%, Training Loss: 0.5924%\n",
      "Epoch [25/300], Step [188/225], Training Accuracy: 75.0000%, Training Loss: 0.5919%\n",
      "Epoch [25/300], Step [189/225], Training Accuracy: 75.0579%, Training Loss: 0.5906%\n",
      "Epoch [25/300], Step [190/225], Training Accuracy: 75.0987%, Training Loss: 0.5898%\n",
      "Epoch [25/300], Step [191/225], Training Accuracy: 75.0818%, Training Loss: 0.5895%\n",
      "Epoch [25/300], Step [192/225], Training Accuracy: 75.1302%, Training Loss: 0.5886%\n",
      "Epoch [25/300], Step [193/225], Training Accuracy: 75.1295%, Training Loss: 0.5888%\n",
      "Epoch [25/300], Step [194/225], Training Accuracy: 75.1128%, Training Loss: 0.5893%\n",
      "Epoch [25/300], Step [195/225], Training Accuracy: 75.1683%, Training Loss: 0.5884%\n",
      "Epoch [25/300], Step [196/225], Training Accuracy: 75.1515%, Training Loss: 0.5888%\n",
      "Epoch [25/300], Step [197/225], Training Accuracy: 75.1586%, Training Loss: 0.5889%\n",
      "Epoch [25/300], Step [198/225], Training Accuracy: 75.1894%, Training Loss: 0.5880%\n",
      "Epoch [25/300], Step [199/225], Training Accuracy: 75.2041%, Training Loss: 0.5873%\n",
      "Epoch [25/300], Step [200/225], Training Accuracy: 75.2031%, Training Loss: 0.5873%\n",
      "Epoch [25/300], Step [201/225], Training Accuracy: 75.2099%, Training Loss: 0.5873%\n",
      "Epoch [25/300], Step [202/225], Training Accuracy: 75.1702%, Training Loss: 0.5878%\n",
      "Epoch [25/300], Step [203/225], Training Accuracy: 75.2078%, Training Loss: 0.5872%\n",
      "Epoch [25/300], Step [204/225], Training Accuracy: 75.2221%, Training Loss: 0.5868%\n",
      "Epoch [25/300], Step [205/225], Training Accuracy: 75.2591%, Training Loss: 0.5859%\n",
      "Epoch [25/300], Step [206/225], Training Accuracy: 75.2427%, Training Loss: 0.5866%\n",
      "Epoch [25/300], Step [207/225], Training Accuracy: 75.2793%, Training Loss: 0.5855%\n",
      "Epoch [25/300], Step [208/225], Training Accuracy: 75.3080%, Training Loss: 0.5847%\n",
      "Epoch [25/300], Step [209/225], Training Accuracy: 75.3215%, Training Loss: 0.5846%\n",
      "Epoch [25/300], Step [210/225], Training Accuracy: 75.2753%, Training Loss: 0.5849%\n",
      "Epoch [25/300], Step [211/225], Training Accuracy: 75.2814%, Training Loss: 0.5846%\n",
      "Epoch [25/300], Step [212/225], Training Accuracy: 75.2948%, Training Loss: 0.5844%\n",
      "Epoch [25/300], Step [213/225], Training Accuracy: 75.2714%, Training Loss: 0.5849%\n",
      "Epoch [25/300], Step [214/225], Training Accuracy: 75.3067%, Training Loss: 0.5843%\n",
      "Epoch [25/300], Step [215/225], Training Accuracy: 75.3198%, Training Loss: 0.5839%\n",
      "Epoch [25/300], Step [216/225], Training Accuracy: 75.3255%, Training Loss: 0.5836%\n",
      "Epoch [25/300], Step [217/225], Training Accuracy: 75.3096%, Training Loss: 0.5836%\n",
      "Epoch [25/300], Step [218/225], Training Accuracy: 75.2867%, Training Loss: 0.5843%\n",
      "Epoch [25/300], Step [219/225], Training Accuracy: 75.2854%, Training Loss: 0.5840%\n",
      "Epoch [25/300], Step [220/225], Training Accuracy: 75.2770%, Training Loss: 0.5835%\n",
      "Epoch [25/300], Step [221/225], Training Accuracy: 75.2687%, Training Loss: 0.5832%\n",
      "Epoch [25/300], Step [222/225], Training Accuracy: 75.3449%, Training Loss: 0.5824%\n",
      "Epoch [25/300], Step [223/225], Training Accuracy: 75.3153%, Training Loss: 0.5825%\n",
      "Epoch [25/300], Step [224/225], Training Accuracy: 75.3348%, Training Loss: 0.5822%\n",
      "Epoch [25/300], Step [225/225], Training Accuracy: 75.3683%, Training Loss: 0.5815%\n",
      "Epoch [26/300], Step [1/225], Training Accuracy: 76.5625%, Training Loss: 0.4859%\n",
      "Epoch [26/300], Step [2/225], Training Accuracy: 75.7812%, Training Loss: 0.5928%\n",
      "Epoch [26/300], Step [3/225], Training Accuracy: 75.5208%, Training Loss: 0.5484%\n",
      "Epoch [26/300], Step [4/225], Training Accuracy: 75.0000%, Training Loss: 0.5555%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/300], Step [5/225], Training Accuracy: 74.6875%, Training Loss: 0.5854%\n",
      "Epoch [26/300], Step [6/225], Training Accuracy: 75.5208%, Training Loss: 0.5665%\n",
      "Epoch [26/300], Step [7/225], Training Accuracy: 76.5625%, Training Loss: 0.5681%\n",
      "Epoch [26/300], Step [8/225], Training Accuracy: 76.3672%, Training Loss: 0.5720%\n",
      "Epoch [26/300], Step [9/225], Training Accuracy: 75.6944%, Training Loss: 0.5751%\n",
      "Epoch [26/300], Step [10/225], Training Accuracy: 75.3125%, Training Loss: 0.5917%\n",
      "Epoch [26/300], Step [11/225], Training Accuracy: 75.2841%, Training Loss: 0.5973%\n",
      "Epoch [26/300], Step [12/225], Training Accuracy: 76.1719%, Training Loss: 0.5790%\n",
      "Epoch [26/300], Step [13/225], Training Accuracy: 76.9231%, Training Loss: 0.5654%\n",
      "Epoch [26/300], Step [14/225], Training Accuracy: 77.3438%, Training Loss: 0.5610%\n",
      "Epoch [26/300], Step [15/225], Training Accuracy: 77.2917%, Training Loss: 0.5577%\n",
      "Epoch [26/300], Step [16/225], Training Accuracy: 77.1484%, Training Loss: 0.5586%\n",
      "Epoch [26/300], Step [17/225], Training Accuracy: 77.2059%, Training Loss: 0.5578%\n",
      "Epoch [26/300], Step [18/225], Training Accuracy: 76.8229%, Training Loss: 0.5614%\n",
      "Epoch [26/300], Step [19/225], Training Accuracy: 76.8092%, Training Loss: 0.5603%\n",
      "Epoch [26/300], Step [20/225], Training Accuracy: 77.0312%, Training Loss: 0.5547%\n",
      "Epoch [26/300], Step [21/225], Training Accuracy: 77.6042%, Training Loss: 0.5467%\n",
      "Epoch [26/300], Step [22/225], Training Accuracy: 77.2017%, Training Loss: 0.5506%\n",
      "Epoch [26/300], Step [23/225], Training Accuracy: 76.9022%, Training Loss: 0.5549%\n",
      "Epoch [26/300], Step [24/225], Training Accuracy: 76.8880%, Training Loss: 0.5654%\n",
      "Epoch [26/300], Step [25/225], Training Accuracy: 77.1250%, Training Loss: 0.5576%\n",
      "Epoch [26/300], Step [26/225], Training Accuracy: 77.1034%, Training Loss: 0.5635%\n",
      "Epoch [26/300], Step [27/225], Training Accuracy: 77.2569%, Training Loss: 0.5583%\n",
      "Epoch [26/300], Step [28/225], Training Accuracy: 77.5670%, Training Loss: 0.5506%\n",
      "Epoch [26/300], Step [29/225], Training Accuracy: 77.5323%, Training Loss: 0.5469%\n",
      "Epoch [26/300], Step [30/225], Training Accuracy: 77.7083%, Training Loss: 0.5417%\n",
      "Epoch [26/300], Step [31/225], Training Accuracy: 77.5202%, Training Loss: 0.5473%\n",
      "Epoch [26/300], Step [32/225], Training Accuracy: 77.4902%, Training Loss: 0.5479%\n",
      "Epoch [26/300], Step [33/225], Training Accuracy: 77.6515%, Training Loss: 0.5460%\n",
      "Epoch [26/300], Step [34/225], Training Accuracy: 77.5276%, Training Loss: 0.5480%\n",
      "Epoch [26/300], Step [35/225], Training Accuracy: 77.6786%, Training Loss: 0.5433%\n",
      "Epoch [26/300], Step [36/225], Training Accuracy: 77.7344%, Training Loss: 0.5431%\n",
      "Epoch [26/300], Step [37/225], Training Accuracy: 77.6605%, Training Loss: 0.5464%\n",
      "Epoch [26/300], Step [38/225], Training Accuracy: 77.6727%, Training Loss: 0.5444%\n",
      "Epoch [26/300], Step [39/225], Training Accuracy: 77.6442%, Training Loss: 0.5468%\n",
      "Epoch [26/300], Step [40/225], Training Accuracy: 77.6172%, Training Loss: 0.5476%\n",
      "Epoch [26/300], Step [41/225], Training Accuracy: 77.4009%, Training Loss: 0.5526%\n",
      "Epoch [26/300], Step [42/225], Training Accuracy: 77.1577%, Training Loss: 0.5570%\n",
      "Epoch [26/300], Step [43/225], Training Accuracy: 77.2529%, Training Loss: 0.5553%\n",
      "Epoch [26/300], Step [44/225], Training Accuracy: 77.2727%, Training Loss: 0.5543%\n",
      "Epoch [26/300], Step [45/225], Training Accuracy: 77.1181%, Training Loss: 0.5543%\n",
      "Epoch [26/300], Step [46/225], Training Accuracy: 77.2758%, Training Loss: 0.5523%\n",
      "Epoch [26/300], Step [47/225], Training Accuracy: 77.0944%, Training Loss: 0.5525%\n",
      "Epoch [26/300], Step [48/225], Training Accuracy: 76.9857%, Training Loss: 0.5540%\n",
      "Epoch [26/300], Step [49/225], Training Accuracy: 76.9770%, Training Loss: 0.5550%\n",
      "Epoch [26/300], Step [50/225], Training Accuracy: 76.9375%, Training Loss: 0.5558%\n",
      "Epoch [26/300], Step [51/225], Training Accuracy: 77.1140%, Training Loss: 0.5530%\n",
      "Epoch [26/300], Step [52/225], Training Accuracy: 77.4038%, Training Loss: 0.5471%\n",
      "Epoch [26/300], Step [53/225], Training Accuracy: 77.3880%, Training Loss: 0.5464%\n",
      "Epoch [26/300], Step [54/225], Training Accuracy: 77.2569%, Training Loss: 0.5497%\n",
      "Epoch [26/300], Step [55/225], Training Accuracy: 77.0739%, Training Loss: 0.5531%\n",
      "Epoch [26/300], Step [56/225], Training Accuracy: 77.1763%, Training Loss: 0.5505%\n",
      "Epoch [26/300], Step [57/225], Training Accuracy: 77.1656%, Training Loss: 0.5493%\n",
      "Epoch [26/300], Step [58/225], Training Accuracy: 77.1282%, Training Loss: 0.5508%\n",
      "Epoch [26/300], Step [59/225], Training Accuracy: 76.9597%, Training Loss: 0.5545%\n",
      "Epoch [26/300], Step [60/225], Training Accuracy: 76.9271%, Training Loss: 0.5541%\n",
      "Epoch [26/300], Step [61/225], Training Accuracy: 76.8186%, Training Loss: 0.5570%\n",
      "Epoch [26/300], Step [62/225], Training Accuracy: 76.9405%, Training Loss: 0.5554%\n",
      "Epoch [26/300], Step [63/225], Training Accuracy: 76.9097%, Training Loss: 0.5565%\n",
      "Epoch [26/300], Step [64/225], Training Accuracy: 76.9287%, Training Loss: 0.5565%\n",
      "Epoch [26/300], Step [65/225], Training Accuracy: 77.0192%, Training Loss: 0.5553%\n",
      "Epoch [26/300], Step [66/225], Training Accuracy: 77.2017%, Training Loss: 0.5535%\n",
      "Epoch [26/300], Step [67/225], Training Accuracy: 77.1222%, Training Loss: 0.5544%\n",
      "Epoch [26/300], Step [68/225], Training Accuracy: 77.0680%, Training Loss: 0.5550%\n",
      "Epoch [26/300], Step [69/225], Training Accuracy: 77.0380%, Training Loss: 0.5545%\n",
      "Epoch [26/300], Step [70/225], Training Accuracy: 77.1205%, Training Loss: 0.5529%\n",
      "Epoch [26/300], Step [71/225], Training Accuracy: 77.0907%, Training Loss: 0.5507%\n",
      "Epoch [26/300], Step [72/225], Training Accuracy: 76.9965%, Training Loss: 0.5517%\n",
      "Epoch [26/300], Step [73/225], Training Accuracy: 77.0548%, Training Loss: 0.5501%\n",
      "Epoch [26/300], Step [74/225], Training Accuracy: 77.1537%, Training Loss: 0.5486%\n",
      "Epoch [26/300], Step [75/225], Training Accuracy: 77.1250%, Training Loss: 0.5477%\n",
      "Epoch [26/300], Step [76/225], Training Accuracy: 76.8914%, Training Loss: 0.5518%\n",
      "Epoch [26/300], Step [77/225], Training Accuracy: 76.9278%, Training Loss: 0.5516%\n",
      "Epoch [26/300], Step [78/225], Training Accuracy: 76.8830%, Training Loss: 0.5529%\n",
      "Epoch [26/300], Step [79/225], Training Accuracy: 76.9581%, Training Loss: 0.5513%\n",
      "Epoch [26/300], Step [80/225], Training Accuracy: 76.9531%, Training Loss: 0.5505%\n",
      "Epoch [26/300], Step [81/225], Training Accuracy: 77.0255%, Training Loss: 0.5497%\n",
      "Epoch [26/300], Step [82/225], Training Accuracy: 77.0960%, Training Loss: 0.5484%\n",
      "Epoch [26/300], Step [83/225], Training Accuracy: 77.0896%, Training Loss: 0.5484%\n",
      "Epoch [26/300], Step [84/225], Training Accuracy: 77.1763%, Training Loss: 0.5464%\n",
      "Epoch [26/300], Step [85/225], Training Accuracy: 77.1691%, Training Loss: 0.5463%\n",
      "Epoch [26/300], Step [86/225], Training Accuracy: 77.2711%, Training Loss: 0.5450%\n",
      "Epoch [26/300], Step [87/225], Training Accuracy: 77.1911%, Training Loss: 0.5451%\n",
      "Epoch [26/300], Step [88/225], Training Accuracy: 77.2195%, Training Loss: 0.5464%\n",
      "Epoch [26/300], Step [89/225], Training Accuracy: 77.1770%, Training Loss: 0.5462%\n",
      "Epoch [26/300], Step [90/225], Training Accuracy: 77.0486%, Training Loss: 0.5486%\n",
      "Epoch [26/300], Step [91/225], Training Accuracy: 77.0261%, Training Loss: 0.5486%\n",
      "Epoch [26/300], Step [92/225], Training Accuracy: 77.0720%, Training Loss: 0.5483%\n",
      "Epoch [26/300], Step [93/225], Training Accuracy: 77.1337%, Training Loss: 0.5467%\n",
      "Epoch [26/300], Step [94/225], Training Accuracy: 77.0944%, Training Loss: 0.5479%\n",
      "Epoch [26/300], Step [95/225], Training Accuracy: 77.0395%, Training Loss: 0.5495%\n",
      "Epoch [26/300], Step [96/225], Training Accuracy: 77.0671%, Training Loss: 0.5496%\n",
      "Epoch [26/300], Step [97/225], Training Accuracy: 77.0941%, Training Loss: 0.5486%\n",
      "Epoch [26/300], Step [98/225], Training Accuracy: 77.0249%, Training Loss: 0.5490%\n",
      "Epoch [26/300], Step [99/225], Training Accuracy: 77.0202%, Training Loss: 0.5501%\n",
      "Epoch [26/300], Step [100/225], Training Accuracy: 76.9219%, Training Loss: 0.5520%\n",
      "Epoch [26/300], Step [101/225], Training Accuracy: 76.9802%, Training Loss: 0.5509%\n",
      "Epoch [26/300], Step [102/225], Training Accuracy: 76.8536%, Training Loss: 0.5543%\n",
      "Epoch [26/300], Step [103/225], Training Accuracy: 76.8659%, Training Loss: 0.5543%\n",
      "Epoch [26/300], Step [104/225], Training Accuracy: 76.7879%, Training Loss: 0.5548%\n",
      "Epoch [26/300], Step [105/225], Training Accuracy: 76.7708%, Training Loss: 0.5545%\n",
      "Epoch [26/300], Step [106/225], Training Accuracy: 76.7099%, Training Loss: 0.5546%\n",
      "Epoch [26/300], Step [107/225], Training Accuracy: 76.6063%, Training Loss: 0.5586%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/300], Step [108/225], Training Accuracy: 76.5191%, Training Loss: 0.5603%\n",
      "Epoch [26/300], Step [109/225], Training Accuracy: 76.5625%, Training Loss: 0.5599%\n",
      "Epoch [26/300], Step [110/225], Training Accuracy: 76.5625%, Training Loss: 0.5588%\n",
      "Epoch [26/300], Step [111/225], Training Accuracy: 76.5343%, Training Loss: 0.5597%\n",
      "Epoch [26/300], Step [112/225], Training Accuracy: 76.5206%, Training Loss: 0.5608%\n",
      "Epoch [26/300], Step [113/225], Training Accuracy: 76.4934%, Training Loss: 0.5631%\n",
      "Epoch [26/300], Step [114/225], Training Accuracy: 76.4940%, Training Loss: 0.5629%\n",
      "Epoch [26/300], Step [115/225], Training Accuracy: 76.5217%, Training Loss: 0.5625%\n",
      "Epoch [26/300], Step [116/225], Training Accuracy: 76.4817%, Training Loss: 0.5633%\n",
      "Epoch [26/300], Step [117/225], Training Accuracy: 76.4156%, Training Loss: 0.5650%\n",
      "Epoch [26/300], Step [118/225], Training Accuracy: 76.4036%, Training Loss: 0.5653%\n",
      "Epoch [26/300], Step [119/225], Training Accuracy: 76.4181%, Training Loss: 0.5661%\n",
      "Epoch [26/300], Step [120/225], Training Accuracy: 76.4583%, Training Loss: 0.5652%\n",
      "Epoch [26/300], Step [121/225], Training Accuracy: 76.4592%, Training Loss: 0.5653%\n",
      "Epoch [26/300], Step [122/225], Training Accuracy: 76.4600%, Training Loss: 0.5653%\n",
      "Epoch [26/300], Step [123/225], Training Accuracy: 76.4609%, Training Loss: 0.5658%\n",
      "Epoch [26/300], Step [124/225], Training Accuracy: 76.4995%, Training Loss: 0.5654%\n",
      "Epoch [26/300], Step [125/225], Training Accuracy: 76.5375%, Training Loss: 0.5645%\n",
      "Epoch [26/300], Step [126/225], Training Accuracy: 76.5253%, Training Loss: 0.5641%\n",
      "Epoch [26/300], Step [127/225], Training Accuracy: 76.6117%, Training Loss: 0.5637%\n",
      "Epoch [26/300], Step [128/225], Training Accuracy: 76.6113%, Training Loss: 0.5644%\n",
      "Epoch [26/300], Step [129/225], Training Accuracy: 76.5383%, Training Loss: 0.5647%\n",
      "Epoch [26/300], Step [130/225], Training Accuracy: 76.5625%, Training Loss: 0.5640%\n",
      "Epoch [26/300], Step [131/225], Training Accuracy: 76.5386%, Training Loss: 0.5641%\n",
      "Epoch [26/300], Step [132/225], Training Accuracy: 76.5270%, Training Loss: 0.5641%\n",
      "Epoch [26/300], Step [133/225], Training Accuracy: 76.5742%, Training Loss: 0.5628%\n",
      "Epoch [26/300], Step [134/225], Training Accuracy: 76.4925%, Training Loss: 0.5640%\n",
      "Epoch [26/300], Step [135/225], Training Accuracy: 76.4931%, Training Loss: 0.5638%\n",
      "Epoch [26/300], Step [136/225], Training Accuracy: 76.4476%, Training Loss: 0.5641%\n",
      "Epoch [26/300], Step [137/225], Training Accuracy: 76.4827%, Training Loss: 0.5632%\n",
      "Epoch [26/300], Step [138/225], Training Accuracy: 76.5625%, Training Loss: 0.5613%\n",
      "Epoch [26/300], Step [139/225], Training Accuracy: 76.5513%, Training Loss: 0.5616%\n",
      "Epoch [26/300], Step [140/225], Training Accuracy: 76.5402%, Training Loss: 0.5617%\n",
      "Epoch [26/300], Step [141/225], Training Accuracy: 76.5293%, Training Loss: 0.5618%\n",
      "Epoch [26/300], Step [142/225], Training Accuracy: 76.5405%, Training Loss: 0.5607%\n",
      "Epoch [26/300], Step [143/225], Training Accuracy: 76.5406%, Training Loss: 0.5604%\n",
      "Epoch [26/300], Step [144/225], Training Accuracy: 76.5191%, Training Loss: 0.5604%\n",
      "Epoch [26/300], Step [145/225], Training Accuracy: 76.4978%, Training Loss: 0.5601%\n",
      "Epoch [26/300], Step [146/225], Training Accuracy: 76.5090%, Training Loss: 0.5600%\n",
      "Epoch [26/300], Step [147/225], Training Accuracy: 76.4137%, Training Loss: 0.5619%\n",
      "Epoch [26/300], Step [148/225], Training Accuracy: 76.4675%, Training Loss: 0.5602%\n",
      "Epoch [26/300], Step [149/225], Training Accuracy: 76.4367%, Training Loss: 0.5602%\n",
      "Epoch [26/300], Step [150/225], Training Accuracy: 76.4479%, Training Loss: 0.5591%\n",
      "Epoch [26/300], Step [151/225], Training Accuracy: 76.4383%, Training Loss: 0.5592%\n",
      "Epoch [26/300], Step [152/225], Training Accuracy: 76.3877%, Training Loss: 0.5594%\n",
      "Epoch [26/300], Step [153/225], Training Accuracy: 76.4093%, Training Loss: 0.5594%\n",
      "Epoch [26/300], Step [154/225], Training Accuracy: 76.4205%, Training Loss: 0.5604%\n",
      "Epoch [26/300], Step [155/225], Training Accuracy: 76.4113%, Training Loss: 0.5613%\n",
      "Epoch [26/300], Step [156/225], Training Accuracy: 76.3421%, Training Loss: 0.5622%\n",
      "Epoch [26/300], Step [157/225], Training Accuracy: 76.3535%, Training Loss: 0.5621%\n",
      "Epoch [26/300], Step [158/225], Training Accuracy: 76.3350%, Training Loss: 0.5631%\n",
      "Epoch [26/300], Step [159/225], Training Accuracy: 76.3758%, Training Loss: 0.5634%\n",
      "Epoch [26/300], Step [160/225], Training Accuracy: 76.4062%, Training Loss: 0.5631%\n",
      "Epoch [26/300], Step [161/225], Training Accuracy: 76.3781%, Training Loss: 0.5632%\n",
      "Epoch [26/300], Step [162/225], Training Accuracy: 76.4371%, Training Loss: 0.5624%\n",
      "Epoch [26/300], Step [163/225], Training Accuracy: 76.4475%, Training Loss: 0.5618%\n",
      "Epoch [26/300], Step [164/225], Training Accuracy: 76.5053%, Training Loss: 0.5606%\n",
      "Epoch [26/300], Step [165/225], Training Accuracy: 76.5057%, Training Loss: 0.5607%\n",
      "Epoch [26/300], Step [166/225], Training Accuracy: 76.4966%, Training Loss: 0.5600%\n",
      "Epoch [26/300], Step [167/225], Training Accuracy: 76.5157%, Training Loss: 0.5593%\n",
      "Epoch [26/300], Step [168/225], Training Accuracy: 76.5439%, Training Loss: 0.5594%\n",
      "Epoch [26/300], Step [169/225], Training Accuracy: 76.5902%, Training Loss: 0.5589%\n",
      "Epoch [26/300], Step [170/225], Training Accuracy: 76.5993%, Training Loss: 0.5592%\n",
      "Epoch [26/300], Step [171/225], Training Accuracy: 76.5442%, Training Loss: 0.5602%\n",
      "Epoch [26/300], Step [172/225], Training Accuracy: 76.5443%, Training Loss: 0.5604%\n",
      "Epoch [26/300], Step [173/225], Training Accuracy: 76.5083%, Training Loss: 0.5609%\n",
      "Epoch [26/300], Step [174/225], Training Accuracy: 76.5894%, Training Loss: 0.5596%\n",
      "Epoch [26/300], Step [175/225], Training Accuracy: 76.5804%, Training Loss: 0.5610%\n",
      "Epoch [26/300], Step [176/225], Training Accuracy: 76.5891%, Training Loss: 0.5610%\n",
      "Epoch [26/300], Step [177/225], Training Accuracy: 76.5625%, Training Loss: 0.5620%\n",
      "Epoch [26/300], Step [178/225], Training Accuracy: 76.5362%, Training Loss: 0.5617%\n",
      "Epoch [26/300], Step [179/225], Training Accuracy: 76.5450%, Training Loss: 0.5618%\n",
      "Epoch [26/300], Step [180/225], Training Accuracy: 76.5538%, Training Loss: 0.5616%\n",
      "Epoch [26/300], Step [181/225], Training Accuracy: 76.5193%, Training Loss: 0.5621%\n",
      "Epoch [26/300], Step [182/225], Training Accuracy: 76.5453%, Training Loss: 0.5615%\n",
      "Epoch [26/300], Step [183/225], Training Accuracy: 76.5454%, Training Loss: 0.5612%\n",
      "Epoch [26/300], Step [184/225], Training Accuracy: 76.5455%, Training Loss: 0.5611%\n",
      "Epoch [26/300], Step [185/225], Training Accuracy: 76.5963%, Training Loss: 0.5600%\n",
      "Epoch [26/300], Step [186/225], Training Accuracy: 76.6549%, Training Loss: 0.5591%\n",
      "Epoch [26/300], Step [187/225], Training Accuracy: 76.6628%, Training Loss: 0.5593%\n",
      "Epoch [26/300], Step [188/225], Training Accuracy: 76.6622%, Training Loss: 0.5591%\n",
      "Epoch [26/300], Step [189/225], Training Accuracy: 76.6948%, Training Loss: 0.5584%\n",
      "Epoch [26/300], Step [190/225], Training Accuracy: 76.7270%, Training Loss: 0.5578%\n",
      "Epoch [26/300], Step [191/225], Training Accuracy: 76.6934%, Training Loss: 0.5585%\n",
      "Epoch [26/300], Step [192/225], Training Accuracy: 76.7090%, Training Loss: 0.5588%\n",
      "Epoch [26/300], Step [193/225], Training Accuracy: 76.7325%, Training Loss: 0.5583%\n",
      "Epoch [26/300], Step [194/225], Training Accuracy: 76.6914%, Training Loss: 0.5594%\n",
      "Epoch [26/300], Step [195/225], Training Accuracy: 76.7228%, Training Loss: 0.5592%\n",
      "Epoch [26/300], Step [196/225], Training Accuracy: 76.7219%, Training Loss: 0.5589%\n",
      "Epoch [26/300], Step [197/225], Training Accuracy: 76.7053%, Training Loss: 0.5594%\n",
      "Epoch [26/300], Step [198/225], Training Accuracy: 76.6651%, Training Loss: 0.5601%\n",
      "Epoch [26/300], Step [199/225], Training Accuracy: 76.6489%, Training Loss: 0.5600%\n",
      "Epoch [26/300], Step [200/225], Training Accuracy: 76.6719%, Training Loss: 0.5596%\n",
      "Epoch [26/300], Step [201/225], Training Accuracy: 76.7024%, Training Loss: 0.5589%\n",
      "Epoch [26/300], Step [202/225], Training Accuracy: 76.7095%, Training Loss: 0.5588%\n",
      "Epoch [26/300], Step [203/225], Training Accuracy: 76.7626%, Training Loss: 0.5582%\n",
      "Epoch [26/300], Step [204/225], Training Accuracy: 76.7770%, Training Loss: 0.5594%\n",
      "Epoch [26/300], Step [205/225], Training Accuracy: 76.7835%, Training Loss: 0.5588%\n",
      "Epoch [26/300], Step [206/225], Training Accuracy: 76.7900%, Training Loss: 0.5589%\n",
      "Epoch [26/300], Step [207/225], Training Accuracy: 76.8040%, Training Loss: 0.5587%\n",
      "Epoch [26/300], Step [208/225], Training Accuracy: 76.8555%, Training Loss: 0.5581%\n",
      "Epoch [26/300], Step [209/225], Training Accuracy: 76.8167%, Training Loss: 0.5586%\n",
      "Epoch [26/300], Step [210/225], Training Accuracy: 76.8229%, Training Loss: 0.5583%\n",
      "Epoch [26/300], Step [211/225], Training Accuracy: 76.7995%, Training Loss: 0.5589%\n",
      "Epoch [26/300], Step [212/225], Training Accuracy: 76.8131%, Training Loss: 0.5589%\n",
      "Epoch [26/300], Step [213/225], Training Accuracy: 76.8192%, Training Loss: 0.5597%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/300], Step [214/225], Training Accuracy: 76.8546%, Training Loss: 0.5590%\n",
      "Epoch [26/300], Step [215/225], Training Accuracy: 76.8750%, Training Loss: 0.5586%\n",
      "Epoch [26/300], Step [216/225], Training Accuracy: 76.9097%, Training Loss: 0.5581%\n",
      "Epoch [26/300], Step [217/225], Training Accuracy: 76.8793%, Training Loss: 0.5582%\n",
      "Epoch [26/300], Step [218/225], Training Accuracy: 76.8349%, Training Loss: 0.5595%\n",
      "Epoch [26/300], Step [219/225], Training Accuracy: 76.8408%, Training Loss: 0.5596%\n",
      "Epoch [26/300], Step [220/225], Training Accuracy: 76.8963%, Training Loss: 0.5588%\n",
      "Epoch [26/300], Step [221/225], Training Accuracy: 76.9089%, Training Loss: 0.5580%\n",
      "Epoch [26/300], Step [222/225], Training Accuracy: 76.8792%, Training Loss: 0.5580%\n",
      "Epoch [26/300], Step [223/225], Training Accuracy: 76.8708%, Training Loss: 0.5583%\n",
      "Epoch [26/300], Step [224/225], Training Accuracy: 76.8834%, Training Loss: 0.5578%\n",
      "Epoch [26/300], Step [225/225], Training Accuracy: 76.8830%, Training Loss: 0.5575%\n",
      "Epoch [27/300], Step [1/225], Training Accuracy: 78.1250%, Training Loss: 0.4979%\n",
      "Epoch [27/300], Step [2/225], Training Accuracy: 77.3438%, Training Loss: 0.5228%\n",
      "Epoch [27/300], Step [3/225], Training Accuracy: 78.1250%, Training Loss: 0.5012%\n",
      "Epoch [27/300], Step [4/225], Training Accuracy: 76.5625%, Training Loss: 0.5404%\n",
      "Epoch [27/300], Step [5/225], Training Accuracy: 76.5625%, Training Loss: 0.5516%\n",
      "Epoch [27/300], Step [6/225], Training Accuracy: 76.0417%, Training Loss: 0.5509%\n",
      "Epoch [27/300], Step [7/225], Training Accuracy: 75.6696%, Training Loss: 0.5578%\n",
      "Epoch [27/300], Step [8/225], Training Accuracy: 75.5859%, Training Loss: 0.5720%\n",
      "Epoch [27/300], Step [9/225], Training Accuracy: 75.3472%, Training Loss: 0.5869%\n",
      "Epoch [27/300], Step [10/225], Training Accuracy: 75.1562%, Training Loss: 0.5872%\n",
      "Epoch [27/300], Step [11/225], Training Accuracy: 74.8580%, Training Loss: 0.5838%\n",
      "Epoch [27/300], Step [12/225], Training Accuracy: 74.6094%, Training Loss: 0.5848%\n",
      "Epoch [27/300], Step [13/225], Training Accuracy: 74.8798%, Training Loss: 0.5723%\n",
      "Epoch [27/300], Step [14/225], Training Accuracy: 74.5536%, Training Loss: 0.5756%\n",
      "Epoch [27/300], Step [15/225], Training Accuracy: 74.0625%, Training Loss: 0.5782%\n",
      "Epoch [27/300], Step [16/225], Training Accuracy: 74.3164%, Training Loss: 0.5725%\n",
      "Epoch [27/300], Step [17/225], Training Accuracy: 73.8971%, Training Loss: 0.5752%\n",
      "Epoch [27/300], Step [18/225], Training Accuracy: 73.6979%, Training Loss: 0.5761%\n",
      "Epoch [27/300], Step [19/225], Training Accuracy: 73.5197%, Training Loss: 0.5821%\n",
      "Epoch [27/300], Step [20/225], Training Accuracy: 73.5156%, Training Loss: 0.5767%\n",
      "Epoch [27/300], Step [21/225], Training Accuracy: 73.8839%, Training Loss: 0.5657%\n",
      "Epoch [27/300], Step [22/225], Training Accuracy: 73.7216%, Training Loss: 0.5703%\n",
      "Epoch [27/300], Step [23/225], Training Accuracy: 73.8451%, Training Loss: 0.5701%\n",
      "Epoch [27/300], Step [24/225], Training Accuracy: 74.4141%, Training Loss: 0.5620%\n",
      "Epoch [27/300], Step [25/225], Training Accuracy: 74.9375%, Training Loss: 0.5562%\n",
      "Epoch [27/300], Step [26/225], Training Accuracy: 74.7596%, Training Loss: 0.5596%\n",
      "Epoch [27/300], Step [27/225], Training Accuracy: 74.3634%, Training Loss: 0.5743%\n",
      "Epoch [27/300], Step [28/225], Training Accuracy: 74.7210%, Training Loss: 0.5663%\n",
      "Epoch [27/300], Step [29/225], Training Accuracy: 74.9461%, Training Loss: 0.5612%\n",
      "Epoch [27/300], Step [30/225], Training Accuracy: 75.0521%, Training Loss: 0.5610%\n",
      "Epoch [27/300], Step [31/225], Training Accuracy: 75.2016%, Training Loss: 0.5644%\n",
      "Epoch [27/300], Step [32/225], Training Accuracy: 75.0977%, Training Loss: 0.5658%\n",
      "Epoch [27/300], Step [33/225], Training Accuracy: 75.2367%, Training Loss: 0.5657%\n",
      "Epoch [27/300], Step [34/225], Training Accuracy: 74.9540%, Training Loss: 0.5718%\n",
      "Epoch [27/300], Step [35/225], Training Accuracy: 75.0893%, Training Loss: 0.5712%\n",
      "Epoch [27/300], Step [36/225], Training Accuracy: 74.5660%, Training Loss: 0.5781%\n",
      "Epoch [27/300], Step [37/225], Training Accuracy: 74.5355%, Training Loss: 0.5803%\n",
      "Epoch [27/300], Step [38/225], Training Accuracy: 74.6299%, Training Loss: 0.5775%\n",
      "Epoch [27/300], Step [39/225], Training Accuracy: 74.7596%, Training Loss: 0.5772%\n",
      "Epoch [27/300], Step [40/225], Training Accuracy: 74.9609%, Training Loss: 0.5733%\n",
      "Epoch [27/300], Step [41/225], Training Accuracy: 74.7332%, Training Loss: 0.5794%\n",
      "Epoch [27/300], Step [42/225], Training Accuracy: 74.7024%, Training Loss: 0.5821%\n",
      "Epoch [27/300], Step [43/225], Training Accuracy: 74.8183%, Training Loss: 0.5800%\n",
      "Epoch [27/300], Step [44/225], Training Accuracy: 75.0710%, Training Loss: 0.5755%\n",
      "Epoch [27/300], Step [45/225], Training Accuracy: 75.1042%, Training Loss: 0.5775%\n",
      "Epoch [27/300], Step [46/225], Training Accuracy: 75.2717%, Training Loss: 0.5729%\n",
      "Epoch [27/300], Step [47/225], Training Accuracy: 75.1995%, Training Loss: 0.5720%\n",
      "Epoch [27/300], Step [48/225], Training Accuracy: 74.8372%, Training Loss: 0.5772%\n",
      "Epoch [27/300], Step [49/225], Training Accuracy: 74.9362%, Training Loss: 0.5745%\n",
      "Epoch [27/300], Step [50/225], Training Accuracy: 75.0312%, Training Loss: 0.5714%\n",
      "Epoch [27/300], Step [51/225], Training Accuracy: 75.2451%, Training Loss: 0.5684%\n",
      "Epoch [27/300], Step [52/225], Training Accuracy: 75.3906%, Training Loss: 0.5636%\n",
      "Epoch [27/300], Step [53/225], Training Accuracy: 75.3833%, Training Loss: 0.5668%\n",
      "Epoch [27/300], Step [54/225], Training Accuracy: 75.4051%, Training Loss: 0.5672%\n",
      "Epoch [27/300], Step [55/225], Training Accuracy: 75.4261%, Training Loss: 0.5698%\n",
      "Epoch [27/300], Step [56/225], Training Accuracy: 75.5859%, Training Loss: 0.5684%\n",
      "Epoch [27/300], Step [57/225], Training Accuracy: 75.7675%, Training Loss: 0.5655%\n",
      "Epoch [27/300], Step [58/225], Training Accuracy: 75.7812%, Training Loss: 0.5648%\n",
      "Epoch [27/300], Step [59/225], Training Accuracy: 75.7150%, Training Loss: 0.5662%\n",
      "Epoch [27/300], Step [60/225], Training Accuracy: 75.8073%, Training Loss: 0.5649%\n",
      "Epoch [27/300], Step [61/225], Training Accuracy: 75.7684%, Training Loss: 0.5657%\n",
      "Epoch [27/300], Step [62/225], Training Accuracy: 75.8065%, Training Loss: 0.5649%\n",
      "Epoch [27/300], Step [63/225], Training Accuracy: 75.8185%, Training Loss: 0.5636%\n",
      "Epoch [27/300], Step [64/225], Training Accuracy: 75.9766%, Training Loss: 0.5620%\n",
      "Epoch [27/300], Step [65/225], Training Accuracy: 76.0577%, Training Loss: 0.5606%\n",
      "Epoch [27/300], Step [66/225], Training Accuracy: 76.1600%, Training Loss: 0.5582%\n",
      "Epoch [27/300], Step [67/225], Training Accuracy: 76.1427%, Training Loss: 0.5583%\n",
      "Epoch [27/300], Step [68/225], Training Accuracy: 76.1259%, Training Loss: 0.5592%\n",
      "Epoch [27/300], Step [69/225], Training Accuracy: 76.1549%, Training Loss: 0.5594%\n",
      "Epoch [27/300], Step [70/225], Training Accuracy: 76.2054%, Training Loss: 0.5583%\n",
      "Epoch [27/300], Step [71/225], Training Accuracy: 76.2324%, Training Loss: 0.5571%\n",
      "Epoch [27/300], Step [72/225], Training Accuracy: 76.1719%, Training Loss: 0.5576%\n",
      "Epoch [27/300], Step [73/225], Training Accuracy: 76.1130%, Training Loss: 0.5585%\n",
      "Epoch [27/300], Step [74/225], Training Accuracy: 76.2035%, Training Loss: 0.5573%\n",
      "Epoch [27/300], Step [75/225], Training Accuracy: 76.2708%, Training Loss: 0.5552%\n",
      "Epoch [27/300], Step [76/225], Training Accuracy: 76.1719%, Training Loss: 0.5571%\n",
      "Epoch [27/300], Step [77/225], Training Accuracy: 76.1364%, Training Loss: 0.5575%\n",
      "Epoch [27/300], Step [78/225], Training Accuracy: 76.0216%, Training Loss: 0.5592%\n",
      "Epoch [27/300], Step [79/225], Training Accuracy: 76.0483%, Training Loss: 0.5575%\n",
      "Epoch [27/300], Step [80/225], Training Accuracy: 76.1719%, Training Loss: 0.5561%\n",
      "Epoch [27/300], Step [81/225], Training Accuracy: 76.2924%, Training Loss: 0.5543%\n",
      "Epoch [27/300], Step [82/225], Training Accuracy: 76.3148%, Training Loss: 0.5538%\n",
      "Epoch [27/300], Step [83/225], Training Accuracy: 76.3178%, Training Loss: 0.5535%\n",
      "Epoch [27/300], Step [84/225], Training Accuracy: 76.4695%, Training Loss: 0.5504%\n",
      "Epoch [27/300], Step [85/225], Training Accuracy: 76.6176%, Training Loss: 0.5478%\n",
      "Epoch [27/300], Step [86/225], Training Accuracy: 76.6170%, Training Loss: 0.5471%\n",
      "Epoch [27/300], Step [87/225], Training Accuracy: 76.5445%, Training Loss: 0.5483%\n",
      "Epoch [27/300], Step [88/225], Training Accuracy: 76.5092%, Training Loss: 0.5476%\n",
      "Epoch [27/300], Step [89/225], Training Accuracy: 76.5098%, Training Loss: 0.5502%\n",
      "Epoch [27/300], Step [90/225], Training Accuracy: 76.4931%, Training Loss: 0.5502%\n",
      "Epoch [27/300], Step [91/225], Training Accuracy: 76.5282%, Training Loss: 0.5499%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/300], Step [92/225], Training Accuracy: 76.4946%, Training Loss: 0.5534%\n",
      "Epoch [27/300], Step [93/225], Training Accuracy: 76.5289%, Training Loss: 0.5526%\n",
      "Epoch [27/300], Step [94/225], Training Accuracy: 76.5625%, Training Loss: 0.5508%\n",
      "Epoch [27/300], Step [95/225], Training Accuracy: 76.6118%, Training Loss: 0.5502%\n",
      "Epoch [27/300], Step [96/225], Training Accuracy: 76.6602%, Training Loss: 0.5483%\n",
      "Epoch [27/300], Step [97/225], Training Accuracy: 76.5464%, Training Loss: 0.5502%\n",
      "Epoch [27/300], Step [98/225], Training Accuracy: 76.5944%, Training Loss: 0.5505%\n",
      "Epoch [27/300], Step [99/225], Training Accuracy: 76.6414%, Training Loss: 0.5502%\n",
      "Epoch [27/300], Step [100/225], Training Accuracy: 76.5156%, Training Loss: 0.5526%\n",
      "Epoch [27/300], Step [101/225], Training Accuracy: 76.5625%, Training Loss: 0.5513%\n",
      "Epoch [27/300], Step [102/225], Training Accuracy: 76.6391%, Training Loss: 0.5508%\n",
      "Epoch [27/300], Step [103/225], Training Accuracy: 76.7294%, Training Loss: 0.5498%\n",
      "Epoch [27/300], Step [104/225], Training Accuracy: 76.7127%, Training Loss: 0.5496%\n",
      "Epoch [27/300], Step [105/225], Training Accuracy: 76.7560%, Training Loss: 0.5497%\n",
      "Epoch [27/300], Step [106/225], Training Accuracy: 76.8131%, Training Loss: 0.5491%\n",
      "Epoch [27/300], Step [107/225], Training Accuracy: 76.8254%, Training Loss: 0.5493%\n",
      "Epoch [27/300], Step [108/225], Training Accuracy: 76.8663%, Training Loss: 0.5486%\n",
      "Epoch [27/300], Step [109/225], Training Accuracy: 76.8922%, Training Loss: 0.5481%\n",
      "Epoch [27/300], Step [110/225], Training Accuracy: 76.9460%, Training Loss: 0.5466%\n",
      "Epoch [27/300], Step [111/225], Training Accuracy: 76.9566%, Training Loss: 0.5465%\n",
      "Epoch [27/300], Step [112/225], Training Accuracy: 77.0089%, Training Loss: 0.5456%\n",
      "Epoch [27/300], Step [113/225], Training Accuracy: 76.9912%, Training Loss: 0.5466%\n",
      "Epoch [27/300], Step [114/225], Training Accuracy: 77.0285%, Training Loss: 0.5457%\n",
      "Epoch [27/300], Step [115/225], Training Accuracy: 77.0380%, Training Loss: 0.5454%\n",
      "Epoch [27/300], Step [116/225], Training Accuracy: 77.0205%, Training Loss: 0.5467%\n",
      "Epoch [27/300], Step [117/225], Training Accuracy: 76.9899%, Training Loss: 0.5470%\n",
      "Epoch [27/300], Step [118/225], Training Accuracy: 76.9597%, Training Loss: 0.5469%\n",
      "Epoch [27/300], Step [119/225], Training Accuracy: 76.9827%, Training Loss: 0.5462%\n",
      "Epoch [27/300], Step [120/225], Training Accuracy: 77.0052%, Training Loss: 0.5458%\n",
      "Epoch [27/300], Step [121/225], Training Accuracy: 77.0015%, Training Loss: 0.5460%\n",
      "Epoch [27/300], Step [122/225], Training Accuracy: 77.0620%, Training Loss: 0.5452%\n",
      "Epoch [27/300], Step [123/225], Training Accuracy: 77.0706%, Training Loss: 0.5464%\n",
      "Epoch [27/300], Step [124/225], Training Accuracy: 77.0791%, Training Loss: 0.5458%\n",
      "Epoch [27/300], Step [125/225], Training Accuracy: 77.1500%, Training Loss: 0.5446%\n",
      "Epoch [27/300], Step [126/225], Training Accuracy: 77.1577%, Training Loss: 0.5447%\n",
      "Epoch [27/300], Step [127/225], Training Accuracy: 77.1407%, Training Loss: 0.5448%\n",
      "Epoch [27/300], Step [128/225], Training Accuracy: 77.1118%, Training Loss: 0.5463%\n",
      "Epoch [27/300], Step [129/225], Training Accuracy: 77.1318%, Training Loss: 0.5459%\n",
      "Epoch [27/300], Step [130/225], Training Accuracy: 77.0913%, Training Loss: 0.5471%\n",
      "Epoch [27/300], Step [131/225], Training Accuracy: 77.0873%, Training Loss: 0.5481%\n",
      "Epoch [27/300], Step [132/225], Training Accuracy: 77.0360%, Training Loss: 0.5494%\n",
      "Epoch [27/300], Step [133/225], Training Accuracy: 77.0442%, Training Loss: 0.5491%\n",
      "Epoch [27/300], Step [134/225], Training Accuracy: 76.9939%, Training Loss: 0.5505%\n",
      "Epoch [27/300], Step [135/225], Training Accuracy: 77.0023%, Training Loss: 0.5502%\n",
      "Epoch [27/300], Step [136/225], Training Accuracy: 77.0106%, Training Loss: 0.5501%\n",
      "Epoch [27/300], Step [137/225], Training Accuracy: 77.0643%, Training Loss: 0.5502%\n",
      "Epoch [27/300], Step [138/225], Training Accuracy: 77.0947%, Training Loss: 0.5496%\n",
      "Epoch [27/300], Step [139/225], Training Accuracy: 77.1021%, Training Loss: 0.5494%\n",
      "Epoch [27/300], Step [140/225], Training Accuracy: 77.1094%, Training Loss: 0.5489%\n",
      "Epoch [27/300], Step [141/225], Training Accuracy: 77.1277%, Training Loss: 0.5489%\n",
      "Epoch [27/300], Step [142/225], Training Accuracy: 77.1677%, Training Loss: 0.5482%\n",
      "Epoch [27/300], Step [143/225], Training Accuracy: 77.1744%, Training Loss: 0.5475%\n",
      "Epoch [27/300], Step [144/225], Training Accuracy: 77.2027%, Training Loss: 0.5468%\n",
      "Epoch [27/300], Step [145/225], Training Accuracy: 77.1767%, Training Loss: 0.5472%\n",
      "Epoch [27/300], Step [146/225], Training Accuracy: 77.2153%, Training Loss: 0.5466%\n",
      "Epoch [27/300], Step [147/225], Training Accuracy: 77.2109%, Training Loss: 0.5465%\n",
      "Epoch [27/300], Step [148/225], Training Accuracy: 77.2698%, Training Loss: 0.5455%\n",
      "Epoch [27/300], Step [149/225], Training Accuracy: 77.2441%, Training Loss: 0.5459%\n",
      "Epoch [27/300], Step [150/225], Training Accuracy: 77.3021%, Training Loss: 0.5446%\n",
      "Epoch [27/300], Step [151/225], Training Accuracy: 77.3075%, Training Loss: 0.5443%\n",
      "Epoch [27/300], Step [152/225], Training Accuracy: 77.3026%, Training Loss: 0.5448%\n",
      "Epoch [27/300], Step [153/225], Training Accuracy: 77.2774%, Training Loss: 0.5449%\n",
      "Epoch [27/300], Step [154/225], Training Accuracy: 77.2829%, Training Loss: 0.5446%\n",
      "Epoch [27/300], Step [155/225], Training Accuracy: 77.2480%, Training Loss: 0.5455%\n",
      "Epoch [27/300], Step [156/225], Training Accuracy: 77.1935%, Training Loss: 0.5468%\n",
      "Epoch [27/300], Step [157/225], Training Accuracy: 77.1497%, Training Loss: 0.5465%\n",
      "Epoch [27/300], Step [158/225], Training Accuracy: 77.0669%, Training Loss: 0.5473%\n",
      "Epoch [27/300], Step [159/225], Training Accuracy: 77.0244%, Training Loss: 0.5475%\n",
      "Epoch [27/300], Step [160/225], Training Accuracy: 77.0410%, Training Loss: 0.5471%\n",
      "Epoch [27/300], Step [161/225], Training Accuracy: 77.0477%, Training Loss: 0.5462%\n",
      "Epoch [27/300], Step [162/225], Training Accuracy: 77.0640%, Training Loss: 0.5459%\n",
      "Epoch [27/300], Step [163/225], Training Accuracy: 77.0514%, Training Loss: 0.5460%\n",
      "Epoch [27/300], Step [164/225], Training Accuracy: 77.1056%, Training Loss: 0.5455%\n",
      "Epoch [27/300], Step [165/225], Training Accuracy: 77.0739%, Training Loss: 0.5456%\n",
      "Epoch [27/300], Step [166/225], Training Accuracy: 77.0896%, Training Loss: 0.5458%\n",
      "Epoch [27/300], Step [167/225], Training Accuracy: 77.1332%, Training Loss: 0.5447%\n",
      "Epoch [27/300], Step [168/225], Training Accuracy: 77.1763%, Training Loss: 0.5438%\n",
      "Epoch [27/300], Step [169/225], Training Accuracy: 77.2097%, Training Loss: 0.5434%\n",
      "Epoch [27/300], Step [170/225], Training Accuracy: 77.2243%, Training Loss: 0.5434%\n",
      "Epoch [27/300], Step [171/225], Training Accuracy: 77.2113%, Training Loss: 0.5433%\n",
      "Epoch [27/300], Step [172/225], Training Accuracy: 77.2166%, Training Loss: 0.5432%\n",
      "Epoch [27/300], Step [173/225], Training Accuracy: 77.2670%, Training Loss: 0.5426%\n",
      "Epoch [27/300], Step [174/225], Training Accuracy: 77.2629%, Training Loss: 0.5422%\n",
      "Epoch [27/300], Step [175/225], Training Accuracy: 77.2679%, Training Loss: 0.5416%\n",
      "Epoch [27/300], Step [176/225], Training Accuracy: 77.2816%, Training Loss: 0.5418%\n",
      "Epoch [27/300], Step [177/225], Training Accuracy: 77.2864%, Training Loss: 0.5414%\n",
      "Epoch [27/300], Step [178/225], Training Accuracy: 77.2999%, Training Loss: 0.5413%\n",
      "Epoch [27/300], Step [179/225], Training Accuracy: 77.3132%, Training Loss: 0.5405%\n",
      "Epoch [27/300], Step [180/225], Training Accuracy: 77.3351%, Training Loss: 0.5405%\n",
      "Epoch [27/300], Step [181/225], Training Accuracy: 77.3481%, Training Loss: 0.5406%\n",
      "Epoch [27/300], Step [182/225], Training Accuracy: 77.3352%, Training Loss: 0.5408%\n",
      "Epoch [27/300], Step [183/225], Training Accuracy: 77.3139%, Training Loss: 0.5409%\n",
      "Epoch [27/300], Step [184/225], Training Accuracy: 77.3353%, Training Loss: 0.5404%\n",
      "Epoch [27/300], Step [185/225], Training Accuracy: 77.3818%, Training Loss: 0.5394%\n",
      "Epoch [27/300], Step [186/225], Training Accuracy: 77.4614%, Training Loss: 0.5380%\n",
      "Epoch [27/300], Step [187/225], Training Accuracy: 77.4315%, Training Loss: 0.5384%\n",
      "Epoch [27/300], Step [188/225], Training Accuracy: 77.4684%, Training Loss: 0.5378%\n",
      "Epoch [27/300], Step [189/225], Training Accuracy: 77.4802%, Training Loss: 0.5374%\n",
      "Epoch [27/300], Step [190/225], Training Accuracy: 77.5000%, Training Loss: 0.5371%\n",
      "Epoch [27/300], Step [191/225], Training Accuracy: 77.5278%, Training Loss: 0.5366%\n",
      "Epoch [27/300], Step [192/225], Training Accuracy: 77.5391%, Training Loss: 0.5364%\n",
      "Epoch [27/300], Step [193/225], Training Accuracy: 77.5502%, Training Loss: 0.5362%\n",
      "Epoch [27/300], Step [194/225], Training Accuracy: 77.5532%, Training Loss: 0.5362%\n",
      "Epoch [27/300], Step [195/225], Training Accuracy: 77.5881%, Training Loss: 0.5354%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/300], Step [196/225], Training Accuracy: 77.5590%, Training Loss: 0.5355%\n",
      "Epoch [27/300], Step [197/225], Training Accuracy: 77.5857%, Training Loss: 0.5354%\n",
      "Epoch [27/300], Step [198/225], Training Accuracy: 77.6121%, Training Loss: 0.5348%\n",
      "Epoch [27/300], Step [199/225], Training Accuracy: 77.6382%, Training Loss: 0.5341%\n",
      "Epoch [27/300], Step [200/225], Training Accuracy: 77.6641%, Training Loss: 0.5337%\n",
      "Epoch [27/300], Step [201/225], Training Accuracy: 77.7052%, Training Loss: 0.5328%\n",
      "Epoch [27/300], Step [202/225], Training Accuracy: 77.7537%, Training Loss: 0.5320%\n",
      "Epoch [27/300], Step [203/225], Training Accuracy: 77.7709%, Training Loss: 0.5323%\n",
      "Epoch [27/300], Step [204/225], Training Accuracy: 77.7956%, Training Loss: 0.5316%\n",
      "Epoch [27/300], Step [205/225], Training Accuracy: 77.7973%, Training Loss: 0.5316%\n",
      "Epoch [27/300], Step [206/225], Training Accuracy: 77.7988%, Training Loss: 0.5314%\n",
      "Epoch [27/300], Step [207/225], Training Accuracy: 77.7853%, Training Loss: 0.5317%\n",
      "Epoch [27/300], Step [208/225], Training Accuracy: 77.7794%, Training Loss: 0.5314%\n",
      "Epoch [27/300], Step [209/225], Training Accuracy: 77.7736%, Training Loss: 0.5313%\n",
      "Epoch [27/300], Step [210/225], Training Accuracy: 77.7679%, Training Loss: 0.5311%\n",
      "Epoch [27/300], Step [211/225], Training Accuracy: 77.8066%, Training Loss: 0.5306%\n",
      "Epoch [27/300], Step [212/225], Training Accuracy: 77.8081%, Training Loss: 0.5310%\n",
      "Epoch [27/300], Step [213/225], Training Accuracy: 77.7949%, Training Loss: 0.5313%\n",
      "Epoch [27/300], Step [214/225], Training Accuracy: 77.8037%, Training Loss: 0.5309%\n",
      "Epoch [27/300], Step [215/225], Training Accuracy: 77.7834%, Training Loss: 0.5312%\n",
      "Epoch [27/300], Step [216/225], Training Accuracy: 77.8067%, Training Loss: 0.5309%\n",
      "Epoch [27/300], Step [217/225], Training Accuracy: 77.7938%, Training Loss: 0.5308%\n",
      "Epoch [27/300], Step [218/225], Training Accuracy: 77.7881%, Training Loss: 0.5316%\n",
      "Epoch [27/300], Step [219/225], Training Accuracy: 77.7683%, Training Loss: 0.5327%\n",
      "Epoch [27/300], Step [220/225], Training Accuracy: 77.7415%, Training Loss: 0.5326%\n",
      "Epoch [27/300], Step [221/225], Training Accuracy: 77.7149%, Training Loss: 0.5331%\n",
      "Epoch [27/300], Step [222/225], Training Accuracy: 77.7097%, Training Loss: 0.5331%\n",
      "Epoch [27/300], Step [223/225], Training Accuracy: 77.7256%, Training Loss: 0.5328%\n",
      "Epoch [27/300], Step [224/225], Training Accuracy: 77.7065%, Training Loss: 0.5330%\n",
      "Epoch [27/300], Step [225/225], Training Accuracy: 77.7168%, Training Loss: 0.5328%\n",
      "Epoch [28/300], Step [1/225], Training Accuracy: 85.9375%, Training Loss: 0.4890%\n",
      "Epoch [28/300], Step [2/225], Training Accuracy: 79.6875%, Training Loss: 0.5662%\n",
      "Epoch [28/300], Step [3/225], Training Accuracy: 79.1667%, Training Loss: 0.5699%\n",
      "Epoch [28/300], Step [4/225], Training Accuracy: 75.0000%, Training Loss: 0.6239%\n",
      "Epoch [28/300], Step [5/225], Training Accuracy: 75.9375%, Training Loss: 0.6033%\n",
      "Epoch [28/300], Step [6/225], Training Accuracy: 76.0417%, Training Loss: 0.5937%\n",
      "Epoch [28/300], Step [7/225], Training Accuracy: 75.6696%, Training Loss: 0.6193%\n",
      "Epoch [28/300], Step [8/225], Training Accuracy: 74.6094%, Training Loss: 0.6453%\n",
      "Epoch [28/300], Step [9/225], Training Accuracy: 74.8264%, Training Loss: 0.6287%\n",
      "Epoch [28/300], Step [10/225], Training Accuracy: 74.3750%, Training Loss: 0.6349%\n",
      "Epoch [28/300], Step [11/225], Training Accuracy: 74.4318%, Training Loss: 0.6286%\n",
      "Epoch [28/300], Step [12/225], Training Accuracy: 74.8698%, Training Loss: 0.6211%\n",
      "Epoch [28/300], Step [13/225], Training Accuracy: 75.7212%, Training Loss: 0.5989%\n",
      "Epoch [28/300], Step [14/225], Training Accuracy: 75.7812%, Training Loss: 0.5969%\n",
      "Epoch [28/300], Step [15/225], Training Accuracy: 76.4583%, Training Loss: 0.5907%\n",
      "Epoch [28/300], Step [16/225], Training Accuracy: 76.0742%, Training Loss: 0.5971%\n",
      "Epoch [28/300], Step [17/225], Training Accuracy: 75.9191%, Training Loss: 0.5929%\n",
      "Epoch [28/300], Step [18/225], Training Accuracy: 75.6944%, Training Loss: 0.5923%\n",
      "Epoch [28/300], Step [19/225], Training Accuracy: 75.5757%, Training Loss: 0.5917%\n",
      "Epoch [28/300], Step [20/225], Training Accuracy: 75.8594%, Training Loss: 0.5829%\n",
      "Epoch [28/300], Step [21/225], Training Accuracy: 76.4881%, Training Loss: 0.5704%\n",
      "Epoch [28/300], Step [22/225], Training Accuracy: 75.9943%, Training Loss: 0.5710%\n",
      "Epoch [28/300], Step [23/225], Training Accuracy: 75.7473%, Training Loss: 0.5700%\n",
      "Epoch [28/300], Step [24/225], Training Accuracy: 75.9766%, Training Loss: 0.5679%\n",
      "Epoch [28/300], Step [25/225], Training Accuracy: 76.3125%, Training Loss: 0.5594%\n",
      "Epoch [28/300], Step [26/225], Training Accuracy: 76.5625%, Training Loss: 0.5558%\n",
      "Epoch [28/300], Step [27/225], Training Accuracy: 77.0255%, Training Loss: 0.5459%\n",
      "Epoch [28/300], Step [28/225], Training Accuracy: 77.5670%, Training Loss: 0.5363%\n",
      "Epoch [28/300], Step [29/225], Training Accuracy: 77.5862%, Training Loss: 0.5350%\n",
      "Epoch [28/300], Step [30/225], Training Accuracy: 77.7604%, Training Loss: 0.5362%\n",
      "Epoch [28/300], Step [31/225], Training Accuracy: 78.1250%, Training Loss: 0.5355%\n",
      "Epoch [28/300], Step [32/225], Training Accuracy: 77.9297%, Training Loss: 0.5422%\n",
      "Epoch [28/300], Step [33/225], Training Accuracy: 78.1250%, Training Loss: 0.5394%\n",
      "Epoch [28/300], Step [34/225], Training Accuracy: 77.8493%, Training Loss: 0.5461%\n",
      "Epoch [28/300], Step [35/225], Training Accuracy: 77.9464%, Training Loss: 0.5452%\n",
      "Epoch [28/300], Step [36/225], Training Accuracy: 77.8646%, Training Loss: 0.5471%\n",
      "Epoch [28/300], Step [37/225], Training Accuracy: 77.9561%, Training Loss: 0.5440%\n",
      "Epoch [28/300], Step [38/225], Training Accuracy: 77.9605%, Training Loss: 0.5427%\n",
      "Epoch [28/300], Step [39/225], Training Accuracy: 77.9247%, Training Loss: 0.5425%\n",
      "Epoch [28/300], Step [40/225], Training Accuracy: 77.8125%, Training Loss: 0.5457%\n",
      "Epoch [28/300], Step [41/225], Training Accuracy: 77.8201%, Training Loss: 0.5481%\n",
      "Epoch [28/300], Step [42/225], Training Accuracy: 77.8274%, Training Loss: 0.5473%\n",
      "Epoch [28/300], Step [43/225], Training Accuracy: 77.7980%, Training Loss: 0.5472%\n",
      "Epoch [28/300], Step [44/225], Training Accuracy: 77.8764%, Training Loss: 0.5444%\n",
      "Epoch [28/300], Step [45/225], Training Accuracy: 77.8125%, Training Loss: 0.5465%\n",
      "Epoch [28/300], Step [46/225], Training Accuracy: 77.9552%, Training Loss: 0.5441%\n",
      "Epoch [28/300], Step [47/225], Training Accuracy: 77.8258%, Training Loss: 0.5455%\n",
      "Epoch [28/300], Step [48/225], Training Accuracy: 77.5716%, Training Loss: 0.5487%\n",
      "Epoch [28/300], Step [49/225], Training Accuracy: 77.6467%, Training Loss: 0.5476%\n",
      "Epoch [28/300], Step [50/225], Training Accuracy: 77.6250%, Training Loss: 0.5478%\n",
      "Epoch [28/300], Step [51/225], Training Accuracy: 77.7880%, Training Loss: 0.5464%\n",
      "Epoch [28/300], Step [52/225], Training Accuracy: 77.8846%, Training Loss: 0.5439%\n",
      "Epoch [28/300], Step [53/225], Training Accuracy: 77.7712%, Training Loss: 0.5495%\n",
      "Epoch [28/300], Step [54/225], Training Accuracy: 77.8067%, Training Loss: 0.5481%\n",
      "Epoch [28/300], Step [55/225], Training Accuracy: 77.6989%, Training Loss: 0.5500%\n",
      "Epoch [28/300], Step [56/225], Training Accuracy: 77.6786%, Training Loss: 0.5486%\n",
      "Epoch [28/300], Step [57/225], Training Accuracy: 77.4671%, Training Loss: 0.5534%\n",
      "Epoch [28/300], Step [58/225], Training Accuracy: 77.6401%, Training Loss: 0.5502%\n",
      "Epoch [28/300], Step [59/225], Training Accuracy: 77.6748%, Training Loss: 0.5478%\n",
      "Epoch [28/300], Step [60/225], Training Accuracy: 77.5781%, Training Loss: 0.5499%\n",
      "Epoch [28/300], Step [61/225], Training Accuracy: 77.6127%, Training Loss: 0.5480%\n",
      "Epoch [28/300], Step [62/225], Training Accuracy: 77.7722%, Training Loss: 0.5439%\n",
      "Epoch [28/300], Step [63/225], Training Accuracy: 77.7282%, Training Loss: 0.5436%\n",
      "Epoch [28/300], Step [64/225], Training Accuracy: 77.7344%, Training Loss: 0.5439%\n",
      "Epoch [28/300], Step [65/225], Training Accuracy: 77.7644%, Training Loss: 0.5426%\n",
      "Epoch [28/300], Step [66/225], Training Accuracy: 77.8883%, Training Loss: 0.5400%\n",
      "Epoch [28/300], Step [67/225], Training Accuracy: 77.8451%, Training Loss: 0.5397%\n",
      "Epoch [28/300], Step [68/225], Training Accuracy: 77.8033%, Training Loss: 0.5409%\n",
      "Epoch [28/300], Step [69/225], Training Accuracy: 77.7627%, Training Loss: 0.5423%\n",
      "Epoch [28/300], Step [70/225], Training Accuracy: 77.7009%, Training Loss: 0.5420%\n",
      "Epoch [28/300], Step [71/225], Training Accuracy: 77.7509%, Training Loss: 0.5411%\n",
      "Epoch [28/300], Step [72/225], Training Accuracy: 77.8429%, Training Loss: 0.5399%\n",
      "Epoch [28/300], Step [73/225], Training Accuracy: 77.7611%, Training Loss: 0.5402%\n",
      "Epoch [28/300], Step [74/225], Training Accuracy: 77.7449%, Training Loss: 0.5385%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/300], Step [75/225], Training Accuracy: 77.6875%, Training Loss: 0.5387%\n",
      "Epoch [28/300], Step [76/225], Training Accuracy: 77.6727%, Training Loss: 0.5386%\n",
      "Epoch [28/300], Step [77/225], Training Accuracy: 77.6583%, Training Loss: 0.5390%\n",
      "Epoch [28/300], Step [78/225], Training Accuracy: 77.7043%, Training Loss: 0.5386%\n",
      "Epoch [28/300], Step [79/225], Training Accuracy: 77.7888%, Training Loss: 0.5363%\n",
      "Epoch [28/300], Step [80/225], Training Accuracy: 77.8906%, Training Loss: 0.5350%\n",
      "Epoch [28/300], Step [81/225], Training Accuracy: 78.0093%, Training Loss: 0.5331%\n",
      "Epoch [28/300], Step [82/225], Training Accuracy: 78.0869%, Training Loss: 0.5312%\n",
      "Epoch [28/300], Step [83/225], Training Accuracy: 78.1062%, Training Loss: 0.5308%\n",
      "Epoch [28/300], Step [84/225], Training Accuracy: 78.1808%, Training Loss: 0.5294%\n",
      "Epoch [28/300], Step [85/225], Training Accuracy: 78.2904%, Training Loss: 0.5272%\n",
      "Epoch [28/300], Step [86/225], Training Accuracy: 78.3612%, Training Loss: 0.5261%\n",
      "Epoch [28/300], Step [87/225], Training Accuracy: 78.3585%, Training Loss: 0.5257%\n",
      "Epoch [28/300], Step [88/225], Training Accuracy: 78.2493%, Training Loss: 0.5264%\n",
      "Epoch [28/300], Step [89/225], Training Accuracy: 78.2830%, Training Loss: 0.5279%\n",
      "Epoch [28/300], Step [90/225], Training Accuracy: 78.2292%, Training Loss: 0.5281%\n",
      "Epoch [28/300], Step [91/225], Training Accuracy: 78.1937%, Training Loss: 0.5291%\n",
      "Epoch [28/300], Step [92/225], Training Accuracy: 78.2099%, Training Loss: 0.5290%\n",
      "Epoch [28/300], Step [93/225], Training Accuracy: 78.2090%, Training Loss: 0.5281%\n",
      "Epoch [28/300], Step [94/225], Training Accuracy: 78.2247%, Training Loss: 0.5288%\n",
      "Epoch [28/300], Step [95/225], Training Accuracy: 78.2072%, Training Loss: 0.5285%\n",
      "Epoch [28/300], Step [96/225], Training Accuracy: 78.2227%, Training Loss: 0.5283%\n",
      "Epoch [28/300], Step [97/225], Training Accuracy: 78.2861%, Training Loss: 0.5273%\n",
      "Epoch [28/300], Step [98/225], Training Accuracy: 78.3004%, Training Loss: 0.5269%\n",
      "Epoch [28/300], Step [99/225], Training Accuracy: 78.2039%, Training Loss: 0.5283%\n",
      "Epoch [28/300], Step [100/225], Training Accuracy: 78.0469%, Training Loss: 0.5307%\n",
      "Epoch [28/300], Step [101/225], Training Accuracy: 77.9858%, Training Loss: 0.5318%\n",
      "Epoch [28/300], Step [102/225], Training Accuracy: 77.9259%, Training Loss: 0.5327%\n",
      "Epoch [28/300], Step [103/225], Training Accuracy: 77.9581%, Training Loss: 0.5325%\n",
      "Epoch [28/300], Step [104/225], Training Accuracy: 77.9898%, Training Loss: 0.5323%\n",
      "Epoch [28/300], Step [105/225], Training Accuracy: 77.9911%, Training Loss: 0.5330%\n",
      "Epoch [28/300], Step [106/225], Training Accuracy: 78.0366%, Training Loss: 0.5325%\n",
      "Epoch [28/300], Step [107/225], Training Accuracy: 77.9936%, Training Loss: 0.5342%\n",
      "Epoch [28/300], Step [108/225], Training Accuracy: 77.9369%, Training Loss: 0.5347%\n",
      "Epoch [28/300], Step [109/225], Training Accuracy: 77.9243%, Training Loss: 0.5346%\n",
      "Epoch [28/300], Step [110/225], Training Accuracy: 77.8693%, Training Loss: 0.5356%\n",
      "Epoch [28/300], Step [111/225], Training Accuracy: 77.8294%, Training Loss: 0.5363%\n",
      "Epoch [28/300], Step [112/225], Training Accuracy: 77.8599%, Training Loss: 0.5360%\n",
      "Epoch [28/300], Step [113/225], Training Accuracy: 77.7931%, Training Loss: 0.5368%\n",
      "Epoch [28/300], Step [114/225], Training Accuracy: 77.8372%, Training Loss: 0.5364%\n",
      "Epoch [28/300], Step [115/225], Training Accuracy: 77.8804%, Training Loss: 0.5354%\n",
      "Epoch [28/300], Step [116/225], Training Accuracy: 77.8825%, Training Loss: 0.5364%\n",
      "Epoch [28/300], Step [117/225], Training Accuracy: 77.8312%, Training Loss: 0.5374%\n",
      "Epoch [28/300], Step [118/225], Training Accuracy: 77.8072%, Training Loss: 0.5378%\n",
      "Epoch [28/300], Step [119/225], Training Accuracy: 77.8493%, Training Loss: 0.5371%\n",
      "Epoch [28/300], Step [120/225], Training Accuracy: 77.8906%, Training Loss: 0.5361%\n",
      "Epoch [28/300], Step [121/225], Training Accuracy: 77.8926%, Training Loss: 0.5357%\n",
      "Epoch [28/300], Step [122/225], Training Accuracy: 77.9457%, Training Loss: 0.5349%\n",
      "Epoch [28/300], Step [123/225], Training Accuracy: 77.9980%, Training Loss: 0.5333%\n",
      "Epoch [28/300], Step [124/225], Training Accuracy: 77.9990%, Training Loss: 0.5332%\n",
      "Epoch [28/300], Step [125/225], Training Accuracy: 77.9625%, Training Loss: 0.5343%\n",
      "Epoch [28/300], Step [126/225], Training Accuracy: 77.9142%, Training Loss: 0.5347%\n",
      "Epoch [28/300], Step [127/225], Training Accuracy: 77.9281%, Training Loss: 0.5347%\n",
      "Epoch [28/300], Step [128/225], Training Accuracy: 77.8809%, Training Loss: 0.5359%\n",
      "Epoch [28/300], Step [129/225], Training Accuracy: 77.8222%, Training Loss: 0.5376%\n",
      "Epoch [28/300], Step [130/225], Training Accuracy: 77.8606%, Training Loss: 0.5368%\n",
      "Epoch [28/300], Step [131/225], Training Accuracy: 77.8626%, Training Loss: 0.5375%\n",
      "Epoch [28/300], Step [132/225], Training Accuracy: 77.9238%, Training Loss: 0.5369%\n",
      "Epoch [28/300], Step [133/225], Training Accuracy: 77.9488%, Training Loss: 0.5357%\n",
      "Epoch [28/300], Step [134/225], Training Accuracy: 77.9268%, Training Loss: 0.5358%\n",
      "Epoch [28/300], Step [135/225], Training Accuracy: 77.9051%, Training Loss: 0.5362%\n",
      "Epoch [28/300], Step [136/225], Training Accuracy: 77.9067%, Training Loss: 0.5359%\n",
      "Epoch [28/300], Step [137/225], Training Accuracy: 77.9653%, Training Loss: 0.5348%\n",
      "Epoch [28/300], Step [138/225], Training Accuracy: 77.9665%, Training Loss: 0.5345%\n",
      "Epoch [28/300], Step [139/225], Training Accuracy: 77.9789%, Training Loss: 0.5345%\n",
      "Epoch [28/300], Step [140/225], Training Accuracy: 77.9799%, Training Loss: 0.5340%\n",
      "Epoch [28/300], Step [141/225], Training Accuracy: 78.0031%, Training Loss: 0.5336%\n",
      "Epoch [28/300], Step [142/225], Training Accuracy: 77.9820%, Training Loss: 0.5334%\n",
      "Epoch [28/300], Step [143/225], Training Accuracy: 78.0048%, Training Loss: 0.5323%\n",
      "Epoch [28/300], Step [144/225], Training Accuracy: 78.0165%, Training Loss: 0.5327%\n",
      "Epoch [28/300], Step [145/225], Training Accuracy: 78.0065%, Training Loss: 0.5328%\n",
      "Epoch [28/300], Step [146/225], Training Accuracy: 78.0501%, Training Loss: 0.5319%\n",
      "Epoch [28/300], Step [147/225], Training Accuracy: 78.0506%, Training Loss: 0.5317%\n",
      "Epoch [28/300], Step [148/225], Training Accuracy: 78.0511%, Training Loss: 0.5312%\n",
      "Epoch [28/300], Step [149/225], Training Accuracy: 78.0411%, Training Loss: 0.5313%\n",
      "Epoch [28/300], Step [150/225], Training Accuracy: 78.0521%, Training Loss: 0.5309%\n",
      "Epoch [28/300], Step [151/225], Training Accuracy: 78.0526%, Training Loss: 0.5310%\n",
      "Epoch [28/300], Step [152/225], Training Accuracy: 78.0222%, Training Loss: 0.5320%\n",
      "Epoch [28/300], Step [153/225], Training Accuracy: 78.0331%, Training Loss: 0.5317%\n",
      "Epoch [28/300], Step [154/225], Training Accuracy: 78.0540%, Training Loss: 0.5314%\n",
      "Epoch [28/300], Step [155/225], Training Accuracy: 77.9839%, Training Loss: 0.5327%\n",
      "Epoch [28/300], Step [156/225], Training Accuracy: 77.9447%, Training Loss: 0.5332%\n",
      "Epoch [28/300], Step [157/225], Training Accuracy: 77.9558%, Training Loss: 0.5336%\n",
      "Epoch [28/300], Step [158/225], Training Accuracy: 77.9371%, Training Loss: 0.5345%\n",
      "Epoch [28/300], Step [159/225], Training Accuracy: 77.9088%, Training Loss: 0.5345%\n",
      "Epoch [28/300], Step [160/225], Training Accuracy: 77.8809%, Training Loss: 0.5347%\n",
      "Epoch [28/300], Step [161/225], Training Accuracy: 77.8533%, Training Loss: 0.5341%\n",
      "Epoch [28/300], Step [162/225], Training Accuracy: 77.8742%, Training Loss: 0.5338%\n",
      "Epoch [28/300], Step [163/225], Training Accuracy: 77.8854%, Training Loss: 0.5336%\n",
      "Epoch [28/300], Step [164/225], Training Accuracy: 77.8868%, Training Loss: 0.5339%\n",
      "Epoch [28/300], Step [165/225], Training Accuracy: 77.9072%, Training Loss: 0.5339%\n",
      "Epoch [28/300], Step [166/225], Training Accuracy: 77.8897%, Training Loss: 0.5345%\n",
      "Epoch [28/300], Step [167/225], Training Accuracy: 77.8817%, Training Loss: 0.5341%\n",
      "Epoch [28/300], Step [168/225], Training Accuracy: 77.7995%, Training Loss: 0.5356%\n",
      "Epoch [28/300], Step [169/225], Training Accuracy: 77.7737%, Training Loss: 0.5363%\n",
      "Epoch [28/300], Step [170/225], Training Accuracy: 77.7482%, Training Loss: 0.5372%\n",
      "Epoch [28/300], Step [171/225], Training Accuracy: 77.7321%, Training Loss: 0.5372%\n",
      "Epoch [28/300], Step [172/225], Training Accuracy: 77.6799%, Training Loss: 0.5380%\n",
      "Epoch [28/300], Step [173/225], Training Accuracy: 77.6102%, Training Loss: 0.5394%\n",
      "Epoch [28/300], Step [174/225], Training Accuracy: 77.6311%, Training Loss: 0.5386%\n",
      "Epoch [28/300], Step [175/225], Training Accuracy: 77.6518%, Training Loss: 0.5379%\n",
      "Epoch [28/300], Step [176/225], Training Accuracy: 77.6190%, Training Loss: 0.5378%\n",
      "Epoch [28/300], Step [177/225], Training Accuracy: 77.6130%, Training Loss: 0.5387%\n",
      "Epoch [28/300], Step [178/225], Training Accuracy: 77.6159%, Training Loss: 0.5389%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/300], Step [179/225], Training Accuracy: 77.6100%, Training Loss: 0.5390%\n",
      "Epoch [28/300], Step [180/225], Training Accuracy: 77.6562%, Training Loss: 0.5383%\n",
      "Epoch [28/300], Step [181/225], Training Accuracy: 77.6416%, Training Loss: 0.5385%\n",
      "Epoch [28/300], Step [182/225], Training Accuracy: 77.5498%, Training Loss: 0.5398%\n",
      "Epoch [28/300], Step [183/225], Training Accuracy: 77.5529%, Training Loss: 0.5404%\n",
      "Epoch [28/300], Step [184/225], Training Accuracy: 77.5645%, Training Loss: 0.5408%\n",
      "Epoch [28/300], Step [185/225], Training Accuracy: 77.5929%, Training Loss: 0.5398%\n",
      "Epoch [28/300], Step [186/225], Training Accuracy: 77.6042%, Training Loss: 0.5392%\n",
      "Epoch [28/300], Step [187/225], Training Accuracy: 77.5902%, Training Loss: 0.5395%\n",
      "Epoch [28/300], Step [188/225], Training Accuracy: 77.6180%, Training Loss: 0.5390%\n",
      "Epoch [28/300], Step [189/225], Training Accuracy: 77.6290%, Training Loss: 0.5386%\n",
      "Epoch [28/300], Step [190/225], Training Accuracy: 77.6234%, Training Loss: 0.5389%\n",
      "Epoch [28/300], Step [191/225], Training Accuracy: 77.6260%, Training Loss: 0.5391%\n",
      "Epoch [28/300], Step [192/225], Training Accuracy: 77.6367%, Training Loss: 0.5391%\n",
      "Epoch [28/300], Step [193/225], Training Accuracy: 77.6392%, Training Loss: 0.5394%\n",
      "Epoch [28/300], Step [194/225], Training Accuracy: 77.5934%, Training Loss: 0.5399%\n",
      "Epoch [28/300], Step [195/225], Training Accuracy: 77.6122%, Training Loss: 0.5396%\n",
      "Epoch [28/300], Step [196/225], Training Accuracy: 77.5670%, Training Loss: 0.5406%\n",
      "Epoch [28/300], Step [197/225], Training Accuracy: 77.5539%, Training Loss: 0.5415%\n",
      "Epoch [28/300], Step [198/225], Training Accuracy: 77.6042%, Training Loss: 0.5402%\n",
      "Epoch [28/300], Step [199/225], Training Accuracy: 77.6539%, Training Loss: 0.5394%\n",
      "Epoch [28/300], Step [200/225], Training Accuracy: 77.6406%, Training Loss: 0.5393%\n",
      "Epoch [28/300], Step [201/225], Training Accuracy: 77.6897%, Training Loss: 0.5384%\n",
      "Epoch [28/300], Step [202/225], Training Accuracy: 77.6609%, Training Loss: 0.5386%\n",
      "Epoch [28/300], Step [203/225], Training Accuracy: 77.6863%, Training Loss: 0.5384%\n",
      "Epoch [28/300], Step [204/225], Training Accuracy: 77.6961%, Training Loss: 0.5382%\n",
      "Epoch [28/300], Step [205/225], Training Accuracy: 77.7134%, Training Loss: 0.5379%\n",
      "Epoch [28/300], Step [206/225], Training Accuracy: 77.7306%, Training Loss: 0.5380%\n",
      "Epoch [28/300], Step [207/225], Training Accuracy: 77.7249%, Training Loss: 0.5378%\n",
      "Epoch [28/300], Step [208/225], Training Accuracy: 77.7569%, Training Loss: 0.5368%\n",
      "Epoch [28/300], Step [209/225], Training Accuracy: 77.7587%, Training Loss: 0.5364%\n",
      "Epoch [28/300], Step [210/225], Training Accuracy: 77.7455%, Training Loss: 0.5370%\n",
      "Epoch [28/300], Step [211/225], Training Accuracy: 77.7621%, Training Loss: 0.5365%\n",
      "Epoch [28/300], Step [212/225], Training Accuracy: 77.7565%, Training Loss: 0.5363%\n",
      "Epoch [28/300], Step [213/225], Training Accuracy: 77.7656%, Training Loss: 0.5366%\n",
      "Epoch [28/300], Step [214/225], Training Accuracy: 77.7891%, Training Loss: 0.5361%\n",
      "Epoch [28/300], Step [215/225], Training Accuracy: 77.8052%, Training Loss: 0.5356%\n",
      "Epoch [28/300], Step [216/225], Training Accuracy: 77.8067%, Training Loss: 0.5357%\n",
      "Epoch [28/300], Step [217/225], Training Accuracy: 77.7938%, Training Loss: 0.5358%\n",
      "Epoch [28/300], Step [218/225], Training Accuracy: 77.7523%, Training Loss: 0.5365%\n",
      "Epoch [28/300], Step [219/225], Training Accuracy: 77.7611%, Training Loss: 0.5362%\n",
      "Epoch [28/300], Step [220/225], Training Accuracy: 77.7699%, Training Loss: 0.5359%\n",
      "Epoch [28/300], Step [221/225], Training Accuracy: 77.8210%, Training Loss: 0.5353%\n",
      "Epoch [28/300], Step [222/225], Training Accuracy: 77.8153%, Training Loss: 0.5351%\n",
      "Epoch [28/300], Step [223/225], Training Accuracy: 77.8167%, Training Loss: 0.5348%\n",
      "Epoch [28/300], Step [224/225], Training Accuracy: 77.8320%, Training Loss: 0.5347%\n",
      "Epoch [28/300], Step [225/225], Training Accuracy: 77.8558%, Training Loss: 0.5338%\n",
      "Epoch [29/300], Step [1/225], Training Accuracy: 82.8125%, Training Loss: 0.4349%\n",
      "Epoch [29/300], Step [2/225], Training Accuracy: 80.4688%, Training Loss: 0.5548%\n",
      "Epoch [29/300], Step [3/225], Training Accuracy: 78.1250%, Training Loss: 0.5780%\n",
      "Epoch [29/300], Step [4/225], Training Accuracy: 77.7344%, Training Loss: 0.5691%\n",
      "Epoch [29/300], Step [5/225], Training Accuracy: 75.9375%, Training Loss: 0.5802%\n",
      "Epoch [29/300], Step [6/225], Training Accuracy: 77.0833%, Training Loss: 0.5670%\n",
      "Epoch [29/300], Step [7/225], Training Accuracy: 77.2321%, Training Loss: 0.5551%\n",
      "Epoch [29/300], Step [8/225], Training Accuracy: 77.5391%, Training Loss: 0.5600%\n",
      "Epoch [29/300], Step [9/225], Training Accuracy: 77.2569%, Training Loss: 0.5673%\n",
      "Epoch [29/300], Step [10/225], Training Accuracy: 76.8750%, Training Loss: 0.5752%\n",
      "Epoch [29/300], Step [11/225], Training Accuracy: 76.8466%, Training Loss: 0.5631%\n",
      "Epoch [29/300], Step [12/225], Training Accuracy: 77.2135%, Training Loss: 0.5536%\n",
      "Epoch [29/300], Step [13/225], Training Accuracy: 77.8846%, Training Loss: 0.5518%\n",
      "Epoch [29/300], Step [14/225], Training Accuracy: 77.5670%, Training Loss: 0.5540%\n",
      "Epoch [29/300], Step [15/225], Training Accuracy: 77.8125%, Training Loss: 0.5453%\n",
      "Epoch [29/300], Step [16/225], Training Accuracy: 77.8320%, Training Loss: 0.5457%\n",
      "Epoch [29/300], Step [17/225], Training Accuracy: 77.2059%, Training Loss: 0.5544%\n",
      "Epoch [29/300], Step [18/225], Training Accuracy: 77.1701%, Training Loss: 0.5593%\n",
      "Epoch [29/300], Step [19/225], Training Accuracy: 77.4671%, Training Loss: 0.5496%\n",
      "Epoch [29/300], Step [20/225], Training Accuracy: 77.7344%, Training Loss: 0.5414%\n",
      "Epoch [29/300], Step [21/225], Training Accuracy: 78.1994%, Training Loss: 0.5342%\n",
      "Epoch [29/300], Step [22/225], Training Accuracy: 78.0540%, Training Loss: 0.5361%\n",
      "Epoch [29/300], Step [23/225], Training Accuracy: 77.8533%, Training Loss: 0.5352%\n",
      "Epoch [29/300], Step [24/225], Training Accuracy: 77.7995%, Training Loss: 0.5343%\n",
      "Epoch [29/300], Step [25/225], Training Accuracy: 78.0000%, Training Loss: 0.5282%\n",
      "Epoch [29/300], Step [26/225], Training Accuracy: 77.8245%, Training Loss: 0.5312%\n",
      "Epoch [29/300], Step [27/225], Training Accuracy: 78.0671%, Training Loss: 0.5235%\n",
      "Epoch [29/300], Step [28/225], Training Accuracy: 78.1250%, Training Loss: 0.5185%\n",
      "Epoch [29/300], Step [29/225], Training Accuracy: 78.2866%, Training Loss: 0.5130%\n",
      "Epoch [29/300], Step [30/225], Training Accuracy: 78.2292%, Training Loss: 0.5133%\n",
      "Epoch [29/300], Step [31/225], Training Accuracy: 78.0746%, Training Loss: 0.5153%\n",
      "Epoch [29/300], Step [32/225], Training Accuracy: 78.2715%, Training Loss: 0.5094%\n",
      "Epoch [29/300], Step [33/225], Training Accuracy: 78.2670%, Training Loss: 0.5107%\n",
      "Epoch [29/300], Step [34/225], Training Accuracy: 78.0790%, Training Loss: 0.5157%\n",
      "Epoch [29/300], Step [35/225], Training Accuracy: 78.1696%, Training Loss: 0.5134%\n",
      "Epoch [29/300], Step [36/225], Training Accuracy: 78.0816%, Training Loss: 0.5143%\n",
      "Epoch [29/300], Step [37/225], Training Accuracy: 78.0828%, Training Loss: 0.5133%\n",
      "Epoch [29/300], Step [38/225], Training Accuracy: 77.9605%, Training Loss: 0.5137%\n",
      "Epoch [29/300], Step [39/225], Training Accuracy: 78.0449%, Training Loss: 0.5148%\n",
      "Epoch [29/300], Step [40/225], Training Accuracy: 78.0469%, Training Loss: 0.5137%\n",
      "Epoch [29/300], Step [41/225], Training Accuracy: 77.8201%, Training Loss: 0.5197%\n",
      "Epoch [29/300], Step [42/225], Training Accuracy: 77.7158%, Training Loss: 0.5209%\n",
      "Epoch [29/300], Step [43/225], Training Accuracy: 77.8343%, Training Loss: 0.5192%\n",
      "Epoch [29/300], Step [44/225], Training Accuracy: 77.9830%, Training Loss: 0.5164%\n",
      "Epoch [29/300], Step [45/225], Training Accuracy: 77.9514%, Training Loss: 0.5163%\n",
      "Epoch [29/300], Step [46/225], Training Accuracy: 78.0231%, Training Loss: 0.5149%\n",
      "Epoch [29/300], Step [47/225], Training Accuracy: 78.0918%, Training Loss: 0.5141%\n",
      "Epoch [29/300], Step [48/225], Training Accuracy: 77.9622%, Training Loss: 0.5163%\n",
      "Epoch [29/300], Step [49/225], Training Accuracy: 77.9337%, Training Loss: 0.5157%\n",
      "Epoch [29/300], Step [50/225], Training Accuracy: 77.9688%, Training Loss: 0.5160%\n",
      "Epoch [29/300], Step [51/225], Training Accuracy: 78.0944%, Training Loss: 0.5145%\n",
      "Epoch [29/300], Step [52/225], Training Accuracy: 78.3353%, Training Loss: 0.5111%\n",
      "Epoch [29/300], Step [53/225], Training Accuracy: 78.3608%, Training Loss: 0.5108%\n",
      "Epoch [29/300], Step [54/225], Training Accuracy: 78.2697%, Training Loss: 0.5124%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/300], Step [55/225], Training Accuracy: 78.2102%, Training Loss: 0.5131%\n",
      "Epoch [29/300], Step [56/225], Training Accuracy: 78.2645%, Training Loss: 0.5105%\n",
      "Epoch [29/300], Step [57/225], Training Accuracy: 78.2072%, Training Loss: 0.5109%\n",
      "Epoch [29/300], Step [58/225], Training Accuracy: 78.2328%, Training Loss: 0.5109%\n",
      "Epoch [29/300], Step [59/225], Training Accuracy: 78.1250%, Training Loss: 0.5118%\n",
      "Epoch [29/300], Step [60/225], Training Accuracy: 78.0208%, Training Loss: 0.5136%\n",
      "Epoch [29/300], Step [61/225], Training Accuracy: 77.9969%, Training Loss: 0.5132%\n",
      "Epoch [29/300], Step [62/225], Training Accuracy: 78.1250%, Training Loss: 0.5123%\n",
      "Epoch [29/300], Step [63/225], Training Accuracy: 78.0754%, Training Loss: 0.5129%\n",
      "Epoch [29/300], Step [64/225], Training Accuracy: 78.1738%, Training Loss: 0.5112%\n",
      "Epoch [29/300], Step [65/225], Training Accuracy: 78.1731%, Training Loss: 0.5129%\n",
      "Epoch [29/300], Step [66/225], Training Accuracy: 78.2907%, Training Loss: 0.5106%\n",
      "Epoch [29/300], Step [67/225], Training Accuracy: 78.1950%, Training Loss: 0.5134%\n",
      "Epoch [29/300], Step [68/225], Training Accuracy: 78.1480%, Training Loss: 0.5139%\n",
      "Epoch [29/300], Step [69/225], Training Accuracy: 78.2382%, Training Loss: 0.5134%\n",
      "Epoch [29/300], Step [70/225], Training Accuracy: 78.3259%, Training Loss: 0.5121%\n",
      "Epoch [29/300], Step [71/225], Training Accuracy: 78.3671%, Training Loss: 0.5119%\n",
      "Epoch [29/300], Step [72/225], Training Accuracy: 78.4071%, Training Loss: 0.5109%\n",
      "Epoch [29/300], Step [73/225], Training Accuracy: 78.4461%, Training Loss: 0.5104%\n",
      "Epoch [29/300], Step [74/225], Training Accuracy: 78.4417%, Training Loss: 0.5087%\n",
      "Epoch [29/300], Step [75/225], Training Accuracy: 78.4375%, Training Loss: 0.5077%\n",
      "Epoch [29/300], Step [76/225], Training Accuracy: 78.3306%, Training Loss: 0.5083%\n",
      "Epoch [29/300], Step [77/225], Training Accuracy: 78.3482%, Training Loss: 0.5103%\n",
      "Epoch [29/300], Step [78/225], Training Accuracy: 78.2252%, Training Loss: 0.5108%\n",
      "Epoch [29/300], Step [79/225], Training Accuracy: 78.3030%, Training Loss: 0.5088%\n",
      "Epoch [29/300], Step [80/225], Training Accuracy: 78.2422%, Training Loss: 0.5094%\n",
      "Epoch [29/300], Step [81/225], Training Accuracy: 78.3372%, Training Loss: 0.5077%\n",
      "Epoch [29/300], Step [82/225], Training Accuracy: 78.4108%, Training Loss: 0.5066%\n",
      "Epoch [29/300], Step [83/225], Training Accuracy: 78.3886%, Training Loss: 0.5051%\n",
      "Epoch [29/300], Step [84/225], Training Accuracy: 78.4040%, Training Loss: 0.5048%\n",
      "Epoch [29/300], Step [85/225], Training Accuracy: 78.4743%, Training Loss: 0.5035%\n",
      "Epoch [29/300], Step [86/225], Training Accuracy: 78.5974%, Training Loss: 0.5015%\n",
      "Epoch [29/300], Step [87/225], Training Accuracy: 78.5201%, Training Loss: 0.5027%\n",
      "Epoch [29/300], Step [88/225], Training Accuracy: 78.4801%, Training Loss: 0.5048%\n",
      "Epoch [29/300], Step [89/225], Training Accuracy: 78.4410%, Training Loss: 0.5052%\n",
      "Epoch [29/300], Step [90/225], Training Accuracy: 78.4028%, Training Loss: 0.5057%\n",
      "Epoch [29/300], Step [91/225], Training Accuracy: 78.3654%, Training Loss: 0.5064%\n",
      "Epoch [29/300], Step [92/225], Training Accuracy: 78.3118%, Training Loss: 0.5080%\n",
      "Epoch [29/300], Step [93/225], Training Accuracy: 78.2258%, Training Loss: 0.5084%\n",
      "Epoch [29/300], Step [94/225], Training Accuracy: 78.2247%, Training Loss: 0.5078%\n",
      "Epoch [29/300], Step [95/225], Training Accuracy: 78.1743%, Training Loss: 0.5096%\n",
      "Epoch [29/300], Step [96/225], Training Accuracy: 78.2064%, Training Loss: 0.5087%\n",
      "Epoch [29/300], Step [97/225], Training Accuracy: 78.2055%, Training Loss: 0.5090%\n",
      "Epoch [29/300], Step [98/225], Training Accuracy: 78.1569%, Training Loss: 0.5097%\n",
      "Epoch [29/300], Step [99/225], Training Accuracy: 78.2355%, Training Loss: 0.5087%\n",
      "Epoch [29/300], Step [100/225], Training Accuracy: 78.1094%, Training Loss: 0.5106%\n",
      "Epoch [29/300], Step [101/225], Training Accuracy: 78.1095%, Training Loss: 0.5112%\n",
      "Epoch [29/300], Step [102/225], Training Accuracy: 78.1403%, Training Loss: 0.5102%\n",
      "Epoch [29/300], Step [103/225], Training Accuracy: 78.1553%, Training Loss: 0.5088%\n",
      "Epoch [29/300], Step [104/225], Training Accuracy: 78.1250%, Training Loss: 0.5084%\n",
      "Epoch [29/300], Step [105/225], Training Accuracy: 78.1845%, Training Loss: 0.5077%\n",
      "Epoch [29/300], Step [106/225], Training Accuracy: 78.2134%, Training Loss: 0.5071%\n",
      "Epoch [29/300], Step [107/225], Training Accuracy: 78.2418%, Training Loss: 0.5072%\n",
      "Epoch [29/300], Step [108/225], Training Accuracy: 78.2263%, Training Loss: 0.5091%\n",
      "Epoch [29/300], Step [109/225], Training Accuracy: 78.2253%, Training Loss: 0.5109%\n",
      "Epoch [29/300], Step [110/225], Training Accuracy: 78.2244%, Training Loss: 0.5120%\n",
      "Epoch [29/300], Step [111/225], Training Accuracy: 78.2939%, Training Loss: 0.5109%\n",
      "Epoch [29/300], Step [112/225], Training Accuracy: 78.2785%, Training Loss: 0.5125%\n",
      "Epoch [29/300], Step [113/225], Training Accuracy: 78.2218%, Training Loss: 0.5133%\n",
      "Epoch [29/300], Step [114/225], Training Accuracy: 78.2209%, Training Loss: 0.5140%\n",
      "Epoch [29/300], Step [115/225], Training Accuracy: 78.2473%, Training Loss: 0.5143%\n",
      "Epoch [29/300], Step [116/225], Training Accuracy: 78.1385%, Training Loss: 0.5163%\n",
      "Epoch [29/300], Step [117/225], Training Accuracy: 78.0849%, Training Loss: 0.5175%\n",
      "Epoch [29/300], Step [118/225], Training Accuracy: 78.0720%, Training Loss: 0.5172%\n",
      "Epoch [29/300], Step [119/225], Training Accuracy: 78.0725%, Training Loss: 0.5167%\n",
      "Epoch [29/300], Step [120/225], Training Accuracy: 78.1120%, Training Loss: 0.5157%\n",
      "Epoch [29/300], Step [121/225], Training Accuracy: 78.0733%, Training Loss: 0.5161%\n",
      "Epoch [29/300], Step [122/225], Training Accuracy: 78.0866%, Training Loss: 0.5156%\n",
      "Epoch [29/300], Step [123/225], Training Accuracy: 78.0488%, Training Loss: 0.5158%\n",
      "Epoch [29/300], Step [124/225], Training Accuracy: 78.0368%, Training Loss: 0.5156%\n",
      "Epoch [29/300], Step [125/225], Training Accuracy: 78.0875%, Training Loss: 0.5148%\n",
      "Epoch [29/300], Step [126/225], Training Accuracy: 78.1126%, Training Loss: 0.5141%\n",
      "Epoch [29/300], Step [127/225], Training Accuracy: 78.1004%, Training Loss: 0.5155%\n",
      "Epoch [29/300], Step [128/225], Training Accuracy: 78.0762%, Training Loss: 0.5155%\n",
      "Epoch [29/300], Step [129/225], Training Accuracy: 78.1492%, Training Loss: 0.5144%\n",
      "Epoch [29/300], Step [130/225], Training Accuracy: 78.0889%, Training Loss: 0.5151%\n",
      "Epoch [29/300], Step [131/225], Training Accuracy: 78.0534%, Training Loss: 0.5154%\n",
      "Epoch [29/300], Step [132/225], Training Accuracy: 78.0185%, Training Loss: 0.5170%\n",
      "Epoch [29/300], Step [133/225], Training Accuracy: 77.9958%, Training Loss: 0.5176%\n",
      "Epoch [29/300], Step [134/225], Training Accuracy: 77.8918%, Training Loss: 0.5193%\n",
      "Epoch [29/300], Step [135/225], Training Accuracy: 77.9167%, Training Loss: 0.5183%\n",
      "Epoch [29/300], Step [136/225], Training Accuracy: 77.9297%, Training Loss: 0.5184%\n",
      "Epoch [29/300], Step [137/225], Training Accuracy: 77.9539%, Training Loss: 0.5182%\n",
      "Epoch [29/300], Step [138/225], Training Accuracy: 78.0231%, Training Loss: 0.5171%\n",
      "Epoch [29/300], Step [139/225], Training Accuracy: 78.0013%, Training Loss: 0.5174%\n",
      "Epoch [29/300], Step [140/225], Training Accuracy: 78.0246%, Training Loss: 0.5173%\n",
      "Epoch [29/300], Step [141/225], Training Accuracy: 77.9477%, Training Loss: 0.5185%\n",
      "Epoch [29/300], Step [142/225], Training Accuracy: 77.9269%, Training Loss: 0.5187%\n",
      "Epoch [29/300], Step [143/225], Training Accuracy: 77.9065%, Training Loss: 0.5185%\n",
      "Epoch [29/300], Step [144/225], Training Accuracy: 77.9080%, Training Loss: 0.5186%\n",
      "Epoch [29/300], Step [145/225], Training Accuracy: 77.8879%, Training Loss: 0.5183%\n",
      "Epoch [29/300], Step [146/225], Training Accuracy: 77.9538%, Training Loss: 0.5173%\n",
      "Epoch [29/300], Step [147/225], Training Accuracy: 77.9868%, Training Loss: 0.5162%\n",
      "Epoch [29/300], Step [148/225], Training Accuracy: 78.0089%, Training Loss: 0.5159%\n",
      "Epoch [29/300], Step [149/225], Training Accuracy: 78.0306%, Training Loss: 0.5157%\n",
      "Epoch [29/300], Step [150/225], Training Accuracy: 78.0521%, Training Loss: 0.5157%\n",
      "Epoch [29/300], Step [151/225], Training Accuracy: 78.0629%, Training Loss: 0.5156%\n",
      "Epoch [29/300], Step [152/225], Training Accuracy: 78.0839%, Training Loss: 0.5155%\n",
      "Epoch [29/300], Step [153/225], Training Accuracy: 78.0944%, Training Loss: 0.5153%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/300], Step [154/225], Training Accuracy: 78.0641%, Training Loss: 0.5154%\n",
      "Epoch [29/300], Step [155/225], Training Accuracy: 78.0343%, Training Loss: 0.5154%\n",
      "Epoch [29/300], Step [156/225], Training Accuracy: 78.0148%, Training Loss: 0.5155%\n",
      "Epoch [29/300], Step [157/225], Training Accuracy: 78.0653%, Training Loss: 0.5149%\n",
      "Epoch [29/300], Step [158/225], Training Accuracy: 78.0459%, Training Loss: 0.5160%\n",
      "Epoch [29/300], Step [159/225], Training Accuracy: 77.9579%, Training Loss: 0.5174%\n",
      "Epoch [29/300], Step [160/225], Training Accuracy: 77.9883%, Training Loss: 0.5170%\n",
      "Epoch [29/300], Step [161/225], Training Accuracy: 77.9988%, Training Loss: 0.5168%\n",
      "Epoch [29/300], Step [162/225], Training Accuracy: 78.0285%, Training Loss: 0.5163%\n",
      "Epoch [29/300], Step [163/225], Training Accuracy: 78.0483%, Training Loss: 0.5159%\n",
      "Epoch [29/300], Step [164/225], Training Accuracy: 78.0488%, Training Loss: 0.5155%\n",
      "Epoch [29/300], Step [165/225], Training Accuracy: 78.0114%, Training Loss: 0.5160%\n",
      "Epoch [29/300], Step [166/225], Training Accuracy: 77.9838%, Training Loss: 0.5163%\n",
      "Epoch [29/300], Step [167/225], Training Accuracy: 77.9847%, Training Loss: 0.5164%\n",
      "Epoch [29/300], Step [168/225], Training Accuracy: 77.9855%, Training Loss: 0.5160%\n",
      "Epoch [29/300], Step [169/225], Training Accuracy: 78.0325%, Training Loss: 0.5152%\n",
      "Epoch [29/300], Step [170/225], Training Accuracy: 78.0423%, Training Loss: 0.5162%\n",
      "Epoch [29/300], Step [171/225], Training Accuracy: 77.9971%, Training Loss: 0.5162%\n",
      "Epoch [29/300], Step [172/225], Training Accuracy: 78.0069%, Training Loss: 0.5159%\n",
      "Epoch [29/300], Step [173/225], Training Accuracy: 78.0527%, Training Loss: 0.5151%\n",
      "Epoch [29/300], Step [174/225], Training Accuracy: 78.0352%, Training Loss: 0.5147%\n",
      "Epoch [29/300], Step [175/225], Training Accuracy: 78.0982%, Training Loss: 0.5135%\n",
      "Epoch [29/300], Step [176/225], Training Accuracy: 78.0717%, Training Loss: 0.5133%\n",
      "Epoch [29/300], Step [177/225], Training Accuracy: 78.1338%, Training Loss: 0.5121%\n",
      "Epoch [29/300], Step [178/225], Training Accuracy: 78.1426%, Training Loss: 0.5122%\n",
      "Epoch [29/300], Step [179/225], Training Accuracy: 78.1337%, Training Loss: 0.5122%\n",
      "Epoch [29/300], Step [180/225], Training Accuracy: 78.1684%, Training Loss: 0.5114%\n",
      "Epoch [29/300], Step [181/225], Training Accuracy: 78.1595%, Training Loss: 0.5119%\n",
      "Epoch [29/300], Step [182/225], Training Accuracy: 78.2023%, Training Loss: 0.5116%\n",
      "Epoch [29/300], Step [183/225], Training Accuracy: 78.1848%, Training Loss: 0.5121%\n",
      "Epoch [29/300], Step [184/225], Training Accuracy: 78.2184%, Training Loss: 0.5117%\n",
      "Epoch [29/300], Step [185/225], Training Accuracy: 78.2348%, Training Loss: 0.5113%\n",
      "Epoch [29/300], Step [186/225], Training Accuracy: 78.3014%, Training Loss: 0.5107%\n",
      "Epoch [29/300], Step [187/225], Training Accuracy: 78.3172%, Training Loss: 0.5106%\n",
      "Epoch [29/300], Step [188/225], Training Accuracy: 78.3162%, Training Loss: 0.5102%\n",
      "Epoch [29/300], Step [189/225], Training Accuracy: 78.3399%, Training Loss: 0.5092%\n",
      "Epoch [29/300], Step [190/225], Training Accuracy: 78.3470%, Training Loss: 0.5088%\n",
      "Epoch [29/300], Step [191/225], Training Accuracy: 78.3377%, Training Loss: 0.5087%\n",
      "Epoch [29/300], Step [192/225], Training Accuracy: 78.3285%, Training Loss: 0.5084%\n",
      "Epoch [29/300], Step [193/225], Training Accuracy: 78.3274%, Training Loss: 0.5089%\n",
      "Epoch [29/300], Step [194/225], Training Accuracy: 78.3425%, Training Loss: 0.5090%\n",
      "Epoch [29/300], Step [195/225], Training Accuracy: 78.3413%, Training Loss: 0.5086%\n",
      "Epoch [29/300], Step [196/225], Training Accuracy: 78.3402%, Training Loss: 0.5087%\n",
      "Epoch [29/300], Step [197/225], Training Accuracy: 78.3074%, Training Loss: 0.5093%\n",
      "Epoch [29/300], Step [198/225], Training Accuracy: 78.3617%, Training Loss: 0.5083%\n",
      "Epoch [29/300], Step [199/225], Training Accuracy: 78.4077%, Training Loss: 0.5075%\n",
      "Epoch [29/300], Step [200/225], Training Accuracy: 78.3750%, Training Loss: 0.5079%\n",
      "Epoch [29/300], Step [201/225], Training Accuracy: 78.3660%, Training Loss: 0.5079%\n",
      "Epoch [29/300], Step [202/225], Training Accuracy: 78.3571%, Training Loss: 0.5083%\n",
      "Epoch [29/300], Step [203/225], Training Accuracy: 78.4175%, Training Loss: 0.5076%\n",
      "Epoch [29/300], Step [204/225], Training Accuracy: 78.4237%, Training Loss: 0.5076%\n",
      "Epoch [29/300], Step [205/225], Training Accuracy: 78.4680%, Training Loss: 0.5066%\n",
      "Epoch [29/300], Step [206/225], Training Accuracy: 78.4967%, Training Loss: 0.5064%\n",
      "Epoch [29/300], Step [207/225], Training Accuracy: 78.5175%, Training Loss: 0.5056%\n",
      "Epoch [29/300], Step [208/225], Training Accuracy: 78.5156%, Training Loss: 0.5052%\n",
      "Epoch [29/300], Step [209/225], Training Accuracy: 78.5063%, Training Loss: 0.5055%\n",
      "Epoch [29/300], Step [210/225], Training Accuracy: 78.5045%, Training Loss: 0.5053%\n",
      "Epoch [29/300], Step [211/225], Training Accuracy: 78.5249%, Training Loss: 0.5049%\n",
      "Epoch [29/300], Step [212/225], Training Accuracy: 78.5156%, Training Loss: 0.5048%\n",
      "Epoch [29/300], Step [213/225], Training Accuracy: 78.5211%, Training Loss: 0.5045%\n",
      "Epoch [29/300], Step [214/225], Training Accuracy: 78.5485%, Training Loss: 0.5038%\n",
      "Epoch [29/300], Step [215/225], Training Accuracy: 78.5465%, Training Loss: 0.5035%\n",
      "Epoch [29/300], Step [216/225], Training Accuracy: 78.5518%, Training Loss: 0.5034%\n",
      "Epoch [29/300], Step [217/225], Training Accuracy: 78.5570%, Training Loss: 0.5036%\n",
      "Epoch [29/300], Step [218/225], Training Accuracy: 78.5049%, Training Loss: 0.5047%\n",
      "Epoch [29/300], Step [219/225], Training Accuracy: 78.5245%, Training Loss: 0.5048%\n",
      "Epoch [29/300], Step [220/225], Training Accuracy: 78.5582%, Training Loss: 0.5041%\n",
      "Epoch [29/300], Step [221/225], Training Accuracy: 78.6058%, Training Loss: 0.5032%\n",
      "Epoch [29/300], Step [222/225], Training Accuracy: 78.6388%, Training Loss: 0.5027%\n",
      "Epoch [29/300], Step [223/225], Training Accuracy: 78.6225%, Training Loss: 0.5027%\n",
      "Epoch [29/300], Step [224/225], Training Accuracy: 78.6203%, Training Loss: 0.5030%\n",
      "Epoch [29/300], Step [225/225], Training Accuracy: 78.6479%, Training Loss: 0.5021%\n",
      "Epoch [30/300], Step [1/225], Training Accuracy: 85.9375%, Training Loss: 0.3568%\n",
      "Epoch [30/300], Step [2/225], Training Accuracy: 85.1562%, Training Loss: 0.3789%\n",
      "Epoch [30/300], Step [3/225], Training Accuracy: 84.3750%, Training Loss: 0.4038%\n",
      "Epoch [30/300], Step [4/225], Training Accuracy: 82.0312%, Training Loss: 0.4340%\n",
      "Epoch [30/300], Step [5/225], Training Accuracy: 81.8750%, Training Loss: 0.4322%\n",
      "Epoch [30/300], Step [6/225], Training Accuracy: 82.2917%, Training Loss: 0.4259%\n",
      "Epoch [30/300], Step [7/225], Training Accuracy: 82.1429%, Training Loss: 0.4278%\n",
      "Epoch [30/300], Step [8/225], Training Accuracy: 80.8594%, Training Loss: 0.4414%\n",
      "Epoch [30/300], Step [9/225], Training Accuracy: 80.5556%, Training Loss: 0.4624%\n",
      "Epoch [30/300], Step [10/225], Training Accuracy: 79.8438%, Training Loss: 0.4782%\n",
      "Epoch [30/300], Step [11/225], Training Accuracy: 79.8295%, Training Loss: 0.4770%\n",
      "Epoch [30/300], Step [12/225], Training Accuracy: 79.9479%, Training Loss: 0.4718%\n",
      "Epoch [30/300], Step [13/225], Training Accuracy: 80.5288%, Training Loss: 0.4603%\n",
      "Epoch [30/300], Step [14/225], Training Accuracy: 80.3571%, Training Loss: 0.4664%\n",
      "Epoch [30/300], Step [15/225], Training Accuracy: 80.3125%, Training Loss: 0.4692%\n",
      "Epoch [30/300], Step [16/225], Training Accuracy: 80.2734%, Training Loss: 0.4748%\n",
      "Epoch [30/300], Step [17/225], Training Accuracy: 79.7794%, Training Loss: 0.4879%\n",
      "Epoch [30/300], Step [18/225], Training Accuracy: 79.8611%, Training Loss: 0.4898%\n",
      "Epoch [30/300], Step [19/225], Training Accuracy: 79.5230%, Training Loss: 0.4900%\n",
      "Epoch [30/300], Step [20/225], Training Accuracy: 79.4531%, Training Loss: 0.4959%\n",
      "Epoch [30/300], Step [21/225], Training Accuracy: 79.8363%, Training Loss: 0.4900%\n",
      "Epoch [30/300], Step [22/225], Training Accuracy: 79.4744%, Training Loss: 0.4953%\n",
      "Epoch [30/300], Step [23/225], Training Accuracy: 79.4837%, Training Loss: 0.4915%\n",
      "Epoch [30/300], Step [24/225], Training Accuracy: 79.0365%, Training Loss: 0.4925%\n",
      "Epoch [30/300], Step [25/225], Training Accuracy: 79.1250%, Training Loss: 0.4909%\n",
      "Epoch [30/300], Step [26/225], Training Accuracy: 79.0865%, Training Loss: 0.4876%\n",
      "Epoch [30/300], Step [27/225], Training Accuracy: 79.2245%, Training Loss: 0.4860%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/300], Step [28/225], Training Accuracy: 79.6317%, Training Loss: 0.4771%\n",
      "Epoch [30/300], Step [29/225], Training Accuracy: 79.7953%, Training Loss: 0.4740%\n",
      "Epoch [30/300], Step [30/225], Training Accuracy: 79.7917%, Training Loss: 0.4754%\n",
      "Epoch [30/300], Step [31/225], Training Accuracy: 79.6875%, Training Loss: 0.4790%\n",
      "Epoch [30/300], Step [32/225], Training Accuracy: 79.4922%, Training Loss: 0.4810%\n",
      "Epoch [30/300], Step [33/225], Training Accuracy: 79.4034%, Training Loss: 0.4858%\n",
      "Epoch [30/300], Step [34/225], Training Accuracy: 79.2739%, Training Loss: 0.4938%\n",
      "Epoch [30/300], Step [35/225], Training Accuracy: 79.2411%, Training Loss: 0.4948%\n",
      "Epoch [30/300], Step [36/225], Training Accuracy: 79.4271%, Training Loss: 0.4908%\n",
      "Epoch [30/300], Step [37/225], Training Accuracy: 79.3919%, Training Loss: 0.4893%\n",
      "Epoch [30/300], Step [38/225], Training Accuracy: 79.4408%, Training Loss: 0.4883%\n",
      "Epoch [30/300], Step [39/225], Training Accuracy: 79.2869%, Training Loss: 0.4905%\n",
      "Epoch [30/300], Step [40/225], Training Accuracy: 79.0234%, Training Loss: 0.4931%\n",
      "Epoch [30/300], Step [41/225], Training Accuracy: 78.8491%, Training Loss: 0.4946%\n",
      "Epoch [30/300], Step [42/225], Training Accuracy: 78.7574%, Training Loss: 0.4967%\n",
      "Epoch [30/300], Step [43/225], Training Accuracy: 79.0334%, Training Loss: 0.4933%\n",
      "Epoch [30/300], Step [44/225], Training Accuracy: 79.1548%, Training Loss: 0.4922%\n",
      "Epoch [30/300], Step [45/225], Training Accuracy: 79.2361%, Training Loss: 0.4904%\n",
      "Epoch [30/300], Step [46/225], Training Accuracy: 79.4158%, Training Loss: 0.4887%\n",
      "Epoch [30/300], Step [47/225], Training Accuracy: 79.4880%, Training Loss: 0.4888%\n",
      "Epoch [30/300], Step [48/225], Training Accuracy: 79.1341%, Training Loss: 0.4933%\n",
      "Epoch [30/300], Step [49/225], Training Accuracy: 79.2411%, Training Loss: 0.4920%\n",
      "Epoch [30/300], Step [50/225], Training Accuracy: 79.2500%, Training Loss: 0.4940%\n",
      "Epoch [30/300], Step [51/225], Training Accuracy: 79.3811%, Training Loss: 0.4922%\n",
      "Epoch [30/300], Step [52/225], Training Accuracy: 79.5072%, Training Loss: 0.4906%\n",
      "Epoch [30/300], Step [53/225], Training Accuracy: 79.5991%, Training Loss: 0.4903%\n",
      "Epoch [30/300], Step [54/225], Training Accuracy: 79.4850%, Training Loss: 0.4918%\n",
      "Epoch [30/300], Step [55/225], Training Accuracy: 79.2330%, Training Loss: 0.4949%\n",
      "Epoch [30/300], Step [56/225], Training Accuracy: 79.2969%, Training Loss: 0.4924%\n",
      "Epoch [30/300], Step [57/225], Training Accuracy: 79.1118%, Training Loss: 0.4943%\n",
      "Epoch [30/300], Step [58/225], Training Accuracy: 79.1487%, Training Loss: 0.4956%\n",
      "Epoch [30/300], Step [59/225], Training Accuracy: 79.0784%, Training Loss: 0.4973%\n",
      "Epoch [30/300], Step [60/225], Training Accuracy: 79.1667%, Training Loss: 0.4957%\n",
      "Epoch [30/300], Step [61/225], Training Accuracy: 79.2008%, Training Loss: 0.4952%\n",
      "Epoch [30/300], Step [62/225], Training Accuracy: 79.2843%, Training Loss: 0.4936%\n",
      "Epoch [30/300], Step [63/225], Training Accuracy: 79.2411%, Training Loss: 0.4934%\n",
      "Epoch [30/300], Step [64/225], Training Accuracy: 79.1016%, Training Loss: 0.4956%\n",
      "Epoch [30/300], Step [65/225], Training Accuracy: 79.0865%, Training Loss: 0.4959%\n",
      "Epoch [30/300], Step [66/225], Training Accuracy: 79.2140%, Training Loss: 0.4964%\n",
      "Epoch [30/300], Step [67/225], Training Accuracy: 79.1978%, Training Loss: 0.4964%\n",
      "Epoch [30/300], Step [68/225], Training Accuracy: 79.1590%, Training Loss: 0.4984%\n",
      "Epoch [30/300], Step [69/225], Training Accuracy: 79.0987%, Training Loss: 0.4998%\n",
      "Epoch [30/300], Step [70/225], Training Accuracy: 79.2411%, Training Loss: 0.4980%\n",
      "Epoch [30/300], Step [71/225], Training Accuracy: 79.2474%, Training Loss: 0.4975%\n",
      "Epoch [30/300], Step [72/225], Training Accuracy: 79.2752%, Training Loss: 0.4977%\n",
      "Epoch [30/300], Step [73/225], Training Accuracy: 79.2808%, Training Loss: 0.4967%\n",
      "Epoch [30/300], Step [74/225], Training Accuracy: 79.3708%, Training Loss: 0.4951%\n",
      "Epoch [30/300], Step [75/225], Training Accuracy: 79.3958%, Training Loss: 0.4943%\n",
      "Epoch [30/300], Step [76/225], Training Accuracy: 79.2763%, Training Loss: 0.4952%\n",
      "Epoch [30/300], Step [77/225], Training Accuracy: 79.2411%, Training Loss: 0.4960%\n",
      "Epoch [30/300], Step [78/225], Training Accuracy: 79.2268%, Training Loss: 0.4971%\n",
      "Epoch [30/300], Step [79/225], Training Accuracy: 79.3908%, Training Loss: 0.4940%\n",
      "Epoch [30/300], Step [80/225], Training Accuracy: 79.3945%, Training Loss: 0.4940%\n",
      "Epoch [30/300], Step [81/225], Training Accuracy: 79.3981%, Training Loss: 0.4945%\n",
      "Epoch [30/300], Step [82/225], Training Accuracy: 79.4588%, Training Loss: 0.4934%\n",
      "Epoch [30/300], Step [83/225], Training Accuracy: 79.4239%, Training Loss: 0.4938%\n",
      "Epoch [30/300], Step [84/225], Training Accuracy: 79.5015%, Training Loss: 0.4923%\n",
      "Epoch [30/300], Step [85/225], Training Accuracy: 79.4669%, Training Loss: 0.4925%\n",
      "Epoch [30/300], Step [86/225], Training Accuracy: 79.5603%, Training Loss: 0.4913%\n",
      "Epoch [30/300], Step [87/225], Training Accuracy: 79.5618%, Training Loss: 0.4916%\n",
      "Epoch [30/300], Step [88/225], Training Accuracy: 79.5099%, Training Loss: 0.4948%\n",
      "Epoch [30/300], Step [89/225], Training Accuracy: 79.5119%, Training Loss: 0.4942%\n",
      "Epoch [30/300], Step [90/225], Training Accuracy: 79.4444%, Training Loss: 0.4950%\n",
      "Epoch [30/300], Step [91/225], Training Accuracy: 79.4643%, Training Loss: 0.4950%\n",
      "Epoch [30/300], Step [92/225], Training Accuracy: 79.5007%, Training Loss: 0.4943%\n",
      "Epoch [30/300], Step [93/225], Training Accuracy: 79.5531%, Training Loss: 0.4931%\n",
      "Epoch [30/300], Step [94/225], Training Accuracy: 79.5213%, Training Loss: 0.4933%\n",
      "Epoch [30/300], Step [95/225], Training Accuracy: 79.5230%, Training Loss: 0.4928%\n",
      "Epoch [30/300], Step [96/225], Training Accuracy: 79.5573%, Training Loss: 0.4912%\n",
      "Epoch [30/300], Step [97/225], Training Accuracy: 79.5103%, Training Loss: 0.4910%\n",
      "Epoch [30/300], Step [98/225], Training Accuracy: 79.5440%, Training Loss: 0.4900%\n",
      "Epoch [30/300], Step [99/225], Training Accuracy: 79.5297%, Training Loss: 0.4895%\n",
      "Epoch [30/300], Step [100/225], Training Accuracy: 79.4531%, Training Loss: 0.4906%\n",
      "Epoch [30/300], Step [101/225], Training Accuracy: 79.4245%, Training Loss: 0.4901%\n",
      "Epoch [30/300], Step [102/225], Training Accuracy: 79.3964%, Training Loss: 0.4906%\n",
      "Epoch [30/300], Step [103/225], Training Accuracy: 79.3083%, Training Loss: 0.4909%\n",
      "Epoch [30/300], Step [104/225], Training Accuracy: 79.2969%, Training Loss: 0.4904%\n",
      "Epoch [30/300], Step [105/225], Training Accuracy: 79.3155%, Training Loss: 0.4905%\n",
      "Epoch [30/300], Step [106/225], Training Accuracy: 79.3337%, Training Loss: 0.4904%\n",
      "Epoch [30/300], Step [107/225], Training Accuracy: 79.3370%, Training Loss: 0.4907%\n",
      "Epoch [30/300], Step [108/225], Training Accuracy: 79.3258%, Training Loss: 0.4910%\n",
      "Epoch [30/300], Step [109/225], Training Accuracy: 79.2718%, Training Loss: 0.4916%\n",
      "Epoch [30/300], Step [110/225], Training Accuracy: 79.3466%, Training Loss: 0.4900%\n",
      "Epoch [30/300], Step [111/225], Training Accuracy: 79.2934%, Training Loss: 0.4909%\n",
      "Epoch [30/300], Step [112/225], Training Accuracy: 79.2690%, Training Loss: 0.4902%\n",
      "Epoch [30/300], Step [113/225], Training Accuracy: 79.2865%, Training Loss: 0.4905%\n",
      "Epoch [30/300], Step [114/225], Training Accuracy: 79.3037%, Training Loss: 0.4902%\n",
      "Epoch [30/300], Step [115/225], Training Accuracy: 79.3478%, Training Loss: 0.4900%\n",
      "Epoch [30/300], Step [116/225], Training Accuracy: 79.2699%, Training Loss: 0.4922%\n",
      "Epoch [30/300], Step [117/225], Training Accuracy: 79.2067%, Training Loss: 0.4938%\n",
      "Epoch [30/300], Step [118/225], Training Accuracy: 79.2108%, Training Loss: 0.4933%\n",
      "Epoch [30/300], Step [119/225], Training Accuracy: 79.2542%, Training Loss: 0.4935%\n",
      "Epoch [30/300], Step [120/225], Training Accuracy: 79.3099%, Training Loss: 0.4930%\n",
      "Epoch [30/300], Step [121/225], Training Accuracy: 79.3259%, Training Loss: 0.4929%\n",
      "Epoch [30/300], Step [122/225], Training Accuracy: 79.3161%, Training Loss: 0.4937%\n",
      "Epoch [30/300], Step [123/225], Training Accuracy: 79.2683%, Training Loss: 0.4957%\n",
      "Epoch [30/300], Step [124/225], Training Accuracy: 79.2717%, Training Loss: 0.4950%\n",
      "Epoch [30/300], Step [125/225], Training Accuracy: 79.2500%, Training Loss: 0.4976%\n",
      "Epoch [30/300], Step [126/225], Training Accuracy: 79.1791%, Training Loss: 0.4989%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/300], Step [127/225], Training Accuracy: 79.2077%, Training Loss: 0.4985%\n",
      "Epoch [30/300], Step [128/225], Training Accuracy: 79.1992%, Training Loss: 0.4987%\n",
      "Epoch [30/300], Step [129/225], Training Accuracy: 79.1182%, Training Loss: 0.4998%\n",
      "Epoch [30/300], Step [130/225], Training Accuracy: 79.0986%, Training Loss: 0.5002%\n",
      "Epoch [30/300], Step [131/225], Training Accuracy: 79.0792%, Training Loss: 0.5007%\n",
      "Epoch [30/300], Step [132/225], Training Accuracy: 79.0246%, Training Loss: 0.5011%\n",
      "Epoch [30/300], Step [133/225], Training Accuracy: 78.9944%, Training Loss: 0.5018%\n",
      "Epoch [30/300], Step [134/225], Training Accuracy: 78.9995%, Training Loss: 0.5027%\n",
      "Epoch [30/300], Step [135/225], Training Accuracy: 79.0162%, Training Loss: 0.5021%\n",
      "Epoch [30/300], Step [136/225], Training Accuracy: 79.0211%, Training Loss: 0.5015%\n",
      "Epoch [30/300], Step [137/225], Training Accuracy: 78.9462%, Training Loss: 0.5025%\n",
      "Epoch [30/300], Step [138/225], Training Accuracy: 78.9742%, Training Loss: 0.5022%\n",
      "Epoch [30/300], Step [139/225], Training Accuracy: 78.9119%, Training Loss: 0.5030%\n",
      "Epoch [30/300], Step [140/225], Training Accuracy: 78.8951%, Training Loss: 0.5031%\n",
      "Epoch [30/300], Step [141/225], Training Accuracy: 78.9450%, Training Loss: 0.5027%\n",
      "Epoch [30/300], Step [142/225], Training Accuracy: 78.9723%, Training Loss: 0.5024%\n",
      "Epoch [30/300], Step [143/225], Training Accuracy: 79.0319%, Training Loss: 0.5015%\n",
      "Epoch [30/300], Step [144/225], Training Accuracy: 79.0365%, Training Loss: 0.5021%\n",
      "Epoch [30/300], Step [145/225], Training Accuracy: 79.0517%, Training Loss: 0.5023%\n",
      "Epoch [30/300], Step [146/225], Training Accuracy: 79.1096%, Training Loss: 0.5014%\n",
      "Epoch [30/300], Step [147/225], Training Accuracy: 79.1454%, Training Loss: 0.5006%\n",
      "Epoch [30/300], Step [148/225], Training Accuracy: 79.1596%, Training Loss: 0.5007%\n",
      "Epoch [30/300], Step [149/225], Training Accuracy: 79.1107%, Training Loss: 0.5013%\n",
      "Epoch [30/300], Step [150/225], Training Accuracy: 79.1667%, Training Loss: 0.4999%\n",
      "Epoch [30/300], Step [151/225], Training Accuracy: 79.2115%, Training Loss: 0.4987%\n",
      "Epoch [30/300], Step [152/225], Training Accuracy: 79.2146%, Training Loss: 0.4987%\n",
      "Epoch [30/300], Step [153/225], Training Accuracy: 79.1871%, Training Loss: 0.4996%\n",
      "Epoch [30/300], Step [154/225], Training Accuracy: 79.2309%, Training Loss: 0.4992%\n",
      "Epoch [30/300], Step [155/225], Training Accuracy: 79.1935%, Training Loss: 0.4993%\n",
      "Epoch [30/300], Step [156/225], Training Accuracy: 79.1867%, Training Loss: 0.4992%\n",
      "Epoch [30/300], Step [157/225], Training Accuracy: 79.1302%, Training Loss: 0.5006%\n",
      "Epoch [30/300], Step [158/225], Training Accuracy: 79.1040%, Training Loss: 0.5013%\n",
      "Epoch [30/300], Step [159/225], Training Accuracy: 79.0979%, Training Loss: 0.5011%\n",
      "Epoch [30/300], Step [160/225], Training Accuracy: 79.0918%, Training Loss: 0.5007%\n",
      "Epoch [30/300], Step [161/225], Training Accuracy: 79.1052%, Training Loss: 0.5007%\n",
      "Epoch [30/300], Step [162/225], Training Accuracy: 79.0895%, Training Loss: 0.5004%\n",
      "Epoch [30/300], Step [163/225], Training Accuracy: 79.0932%, Training Loss: 0.5001%\n",
      "Epoch [30/300], Step [164/225], Training Accuracy: 79.0587%, Training Loss: 0.5005%\n",
      "Epoch [30/300], Step [165/225], Training Accuracy: 79.0436%, Training Loss: 0.5013%\n",
      "Epoch [30/300], Step [166/225], Training Accuracy: 79.0286%, Training Loss: 0.5015%\n",
      "Epoch [30/300], Step [167/225], Training Accuracy: 78.9764%, Training Loss: 0.5023%\n",
      "Epoch [30/300], Step [168/225], Training Accuracy: 78.9807%, Training Loss: 0.5022%\n",
      "Epoch [30/300], Step [169/225], Training Accuracy: 78.9941%, Training Loss: 0.5012%\n",
      "Epoch [30/300], Step [170/225], Training Accuracy: 79.0349%, Training Loss: 0.5006%\n",
      "Epoch [30/300], Step [171/225], Training Accuracy: 79.0296%, Training Loss: 0.5009%\n",
      "Epoch [30/300], Step [172/225], Training Accuracy: 79.0062%, Training Loss: 0.5007%\n",
      "Epoch [30/300], Step [173/225], Training Accuracy: 79.0011%, Training Loss: 0.5006%\n",
      "Epoch [30/300], Step [174/225], Training Accuracy: 79.0230%, Training Loss: 0.5000%\n",
      "Epoch [30/300], Step [175/225], Training Accuracy: 79.0179%, Training Loss: 0.5005%\n",
      "Epoch [30/300], Step [176/225], Training Accuracy: 79.0572%, Training Loss: 0.4997%\n",
      "Epoch [30/300], Step [177/225], Training Accuracy: 79.0784%, Training Loss: 0.4991%\n",
      "Epoch [30/300], Step [178/225], Training Accuracy: 79.1169%, Training Loss: 0.4985%\n",
      "Epoch [30/300], Step [179/225], Training Accuracy: 79.1725%, Training Loss: 0.4975%\n",
      "Epoch [30/300], Step [180/225], Training Accuracy: 79.1840%, Training Loss: 0.4969%\n",
      "Epoch [30/300], Step [181/225], Training Accuracy: 79.1695%, Training Loss: 0.4971%\n",
      "Epoch [30/300], Step [182/225], Training Accuracy: 79.2067%, Training Loss: 0.4967%\n",
      "Epoch [30/300], Step [183/225], Training Accuracy: 79.2094%, Training Loss: 0.4963%\n",
      "Epoch [30/300], Step [184/225], Training Accuracy: 79.2374%, Training Loss: 0.4956%\n",
      "Epoch [30/300], Step [185/225], Training Accuracy: 79.2568%, Training Loss: 0.4949%\n",
      "Epoch [30/300], Step [186/225], Training Accuracy: 79.2927%, Training Loss: 0.4939%\n",
      "Epoch [30/300], Step [187/225], Training Accuracy: 79.2864%, Training Loss: 0.4941%\n",
      "Epoch [30/300], Step [188/225], Training Accuracy: 79.3135%, Training Loss: 0.4935%\n",
      "Epoch [30/300], Step [189/225], Training Accuracy: 79.3320%, Training Loss: 0.4932%\n",
      "Epoch [30/300], Step [190/225], Training Accuracy: 79.3914%, Training Loss: 0.4923%\n",
      "Epoch [30/300], Step [191/225], Training Accuracy: 79.4094%, Training Loss: 0.4920%\n",
      "Epoch [30/300], Step [192/225], Training Accuracy: 79.4189%, Training Loss: 0.4917%\n",
      "Epoch [30/300], Step [193/225], Training Accuracy: 79.4203%, Training Loss: 0.4917%\n",
      "Epoch [30/300], Step [194/225], Training Accuracy: 79.3814%, Training Loss: 0.4921%\n",
      "Epoch [30/300], Step [195/225], Training Accuracy: 79.3990%, Training Loss: 0.4916%\n",
      "Epoch [30/300], Step [196/225], Training Accuracy: 79.4085%, Training Loss: 0.4915%\n",
      "Epoch [30/300], Step [197/225], Training Accuracy: 79.3702%, Training Loss: 0.4925%\n",
      "Epoch [30/300], Step [198/225], Training Accuracy: 79.3876%, Training Loss: 0.4920%\n",
      "Epoch [30/300], Step [199/225], Training Accuracy: 79.4284%, Training Loss: 0.4912%\n",
      "Epoch [30/300], Step [200/225], Training Accuracy: 79.4062%, Training Loss: 0.4921%\n",
      "Epoch [30/300], Step [201/225], Training Accuracy: 79.4232%, Training Loss: 0.4916%\n",
      "Epoch [30/300], Step [202/225], Training Accuracy: 79.3858%, Training Loss: 0.4919%\n",
      "Epoch [30/300], Step [203/225], Training Accuracy: 79.3950%, Training Loss: 0.4918%\n",
      "Epoch [30/300], Step [204/225], Training Accuracy: 79.4041%, Training Loss: 0.4918%\n",
      "Epoch [30/300], Step [205/225], Training Accuracy: 79.4588%, Training Loss: 0.4905%\n",
      "Epoch [30/300], Step [206/225], Training Accuracy: 79.4675%, Training Loss: 0.4905%\n",
      "Epoch [30/300], Step [207/225], Training Accuracy: 79.4384%, Training Loss: 0.4907%\n",
      "Epoch [30/300], Step [208/225], Training Accuracy: 79.3720%, Training Loss: 0.4913%\n",
      "Epoch [30/300], Step [209/225], Training Accuracy: 79.3810%, Training Loss: 0.4911%\n",
      "Epoch [30/300], Step [210/225], Training Accuracy: 79.3824%, Training Loss: 0.4908%\n",
      "Epoch [30/300], Step [211/225], Training Accuracy: 79.3617%, Training Loss: 0.4913%\n",
      "Epoch [30/300], Step [212/225], Training Accuracy: 79.4148%, Training Loss: 0.4904%\n",
      "Epoch [30/300], Step [213/225], Training Accuracy: 79.4014%, Training Loss: 0.4905%\n",
      "Epoch [30/300], Step [214/225], Training Accuracy: 79.4393%, Training Loss: 0.4909%\n",
      "Epoch [30/300], Step [215/225], Training Accuracy: 79.4259%, Training Loss: 0.4909%\n",
      "Epoch [30/300], Step [216/225], Training Accuracy: 79.4416%, Training Loss: 0.4909%\n",
      "Epoch [30/300], Step [217/225], Training Accuracy: 79.4355%, Training Loss: 0.4913%\n",
      "Epoch [30/300], Step [218/225], Training Accuracy: 79.4080%, Training Loss: 0.4921%\n",
      "Epoch [30/300], Step [219/225], Training Accuracy: 79.4307%, Training Loss: 0.4918%\n",
      "Epoch [30/300], Step [220/225], Training Accuracy: 79.4105%, Training Loss: 0.4920%\n",
      "Epoch [30/300], Step [221/225], Training Accuracy: 79.4118%, Training Loss: 0.4921%\n",
      "Epoch [30/300], Step [222/225], Training Accuracy: 79.4130%, Training Loss: 0.4919%\n",
      "Epoch [30/300], Step [223/225], Training Accuracy: 79.4212%, Training Loss: 0.4918%\n",
      "Epoch [30/300], Step [224/225], Training Accuracy: 79.4155%, Training Loss: 0.4919%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/300], Step [225/225], Training Accuracy: 79.4469%, Training Loss: 0.4911%\n",
      "Epoch [31/300], Step [1/225], Training Accuracy: 82.8125%, Training Loss: 0.3733%\n",
      "Epoch [31/300], Step [2/225], Training Accuracy: 80.4688%, Training Loss: 0.4747%\n",
      "Epoch [31/300], Step [3/225], Training Accuracy: 80.7292%, Training Loss: 0.4705%\n",
      "Epoch [31/300], Step [4/225], Training Accuracy: 79.2969%, Training Loss: 0.4727%\n",
      "Epoch [31/300], Step [5/225], Training Accuracy: 78.7500%, Training Loss: 0.4914%\n",
      "Epoch [31/300], Step [6/225], Training Accuracy: 79.9479%, Training Loss: 0.4870%\n",
      "Epoch [31/300], Step [7/225], Training Accuracy: 79.9107%, Training Loss: 0.4832%\n",
      "Epoch [31/300], Step [8/225], Training Accuracy: 80.0781%, Training Loss: 0.4826%\n",
      "Epoch [31/300], Step [9/225], Training Accuracy: 79.8611%, Training Loss: 0.4882%\n",
      "Epoch [31/300], Step [10/225], Training Accuracy: 80.1562%, Training Loss: 0.4922%\n",
      "Epoch [31/300], Step [11/225], Training Accuracy: 80.3977%, Training Loss: 0.4841%\n",
      "Epoch [31/300], Step [12/225], Training Accuracy: 80.5990%, Training Loss: 0.4776%\n",
      "Epoch [31/300], Step [13/225], Training Accuracy: 81.2500%, Training Loss: 0.4638%\n",
      "Epoch [31/300], Step [14/225], Training Accuracy: 81.2500%, Training Loss: 0.4666%\n",
      "Epoch [31/300], Step [15/225], Training Accuracy: 81.3542%, Training Loss: 0.4587%\n",
      "Epoch [31/300], Step [16/225], Training Accuracy: 80.7617%, Training Loss: 0.4695%\n",
      "Epoch [31/300], Step [17/225], Training Accuracy: 80.9743%, Training Loss: 0.4657%\n",
      "Epoch [31/300], Step [18/225], Training Accuracy: 80.3819%, Training Loss: 0.4880%\n",
      "Epoch [31/300], Step [19/225], Training Accuracy: 80.0164%, Training Loss: 0.4960%\n",
      "Epoch [31/300], Step [20/225], Training Accuracy: 80.0781%, Training Loss: 0.4967%\n",
      "Epoch [31/300], Step [21/225], Training Accuracy: 80.4315%, Training Loss: 0.4954%\n",
      "Epoch [31/300], Step [22/225], Training Accuracy: 80.3267%, Training Loss: 0.4952%\n",
      "Epoch [31/300], Step [23/225], Training Accuracy: 79.8913%, Training Loss: 0.4973%\n",
      "Epoch [31/300], Step [24/225], Training Accuracy: 79.7526%, Training Loss: 0.5056%\n",
      "Epoch [31/300], Step [25/225], Training Accuracy: 79.4375%, Training Loss: 0.5138%\n",
      "Epoch [31/300], Step [26/225], Training Accuracy: 79.5072%, Training Loss: 0.5170%\n",
      "Epoch [31/300], Step [27/225], Training Accuracy: 79.2824%, Training Loss: 0.5217%\n",
      "Epoch [31/300], Step [28/225], Training Accuracy: 79.3527%, Training Loss: 0.5185%\n",
      "Epoch [31/300], Step [29/225], Training Accuracy: 79.6875%, Training Loss: 0.5114%\n",
      "Epoch [31/300], Step [30/225], Training Accuracy: 79.6354%, Training Loss: 0.5099%\n",
      "Epoch [31/300], Step [31/225], Training Accuracy: 79.5363%, Training Loss: 0.5210%\n",
      "Epoch [31/300], Step [32/225], Training Accuracy: 79.7363%, Training Loss: 0.5219%\n",
      "Epoch [31/300], Step [33/225], Training Accuracy: 79.9242%, Training Loss: 0.5176%\n",
      "Epoch [31/300], Step [34/225], Training Accuracy: 79.8713%, Training Loss: 0.5179%\n",
      "Epoch [31/300], Step [35/225], Training Accuracy: 80.0893%, Training Loss: 0.5141%\n",
      "Epoch [31/300], Step [36/225], Training Accuracy: 80.0347%, Training Loss: 0.5119%\n",
      "Epoch [31/300], Step [37/225], Training Accuracy: 80.1943%, Training Loss: 0.5064%\n",
      "Epoch [31/300], Step [38/225], Training Accuracy: 80.0987%, Training Loss: 0.5048%\n",
      "Epoch [31/300], Step [39/225], Training Accuracy: 80.0080%, Training Loss: 0.5079%\n",
      "Epoch [31/300], Step [40/225], Training Accuracy: 79.8828%, Training Loss: 0.5073%\n",
      "Epoch [31/300], Step [41/225], Training Accuracy: 79.7256%, Training Loss: 0.5092%\n",
      "Epoch [31/300], Step [42/225], Training Accuracy: 79.6503%, Training Loss: 0.5103%\n",
      "Epoch [31/300], Step [43/225], Training Accuracy: 79.5785%, Training Loss: 0.5091%\n",
      "Epoch [31/300], Step [44/225], Training Accuracy: 79.5455%, Training Loss: 0.5083%\n",
      "Epoch [31/300], Step [45/225], Training Accuracy: 79.2361%, Training Loss: 0.5136%\n",
      "Epoch [31/300], Step [46/225], Training Accuracy: 79.1440%, Training Loss: 0.5156%\n",
      "Epoch [31/300], Step [47/225], Training Accuracy: 79.1888%, Training Loss: 0.5144%\n",
      "Epoch [31/300], Step [48/225], Training Accuracy: 79.1992%, Training Loss: 0.5134%\n",
      "Epoch [31/300], Step [49/225], Training Accuracy: 79.3048%, Training Loss: 0.5116%\n",
      "Epoch [31/300], Step [50/225], Training Accuracy: 79.3125%, Training Loss: 0.5105%\n",
      "Epoch [31/300], Step [51/225], Training Accuracy: 79.4424%, Training Loss: 0.5089%\n",
      "Epoch [31/300], Step [52/225], Training Accuracy: 79.5072%, Training Loss: 0.5058%\n",
      "Epoch [31/300], Step [53/225], Training Accuracy: 79.6875%, Training Loss: 0.5031%\n",
      "Epoch [31/300], Step [54/225], Training Accuracy: 79.5428%, Training Loss: 0.5036%\n",
      "Epoch [31/300], Step [55/225], Training Accuracy: 79.4318%, Training Loss: 0.5047%\n",
      "Epoch [31/300], Step [56/225], Training Accuracy: 79.5480%, Training Loss: 0.5016%\n",
      "Epoch [31/300], Step [57/225], Training Accuracy: 79.5230%, Training Loss: 0.5003%\n",
      "Epoch [31/300], Step [58/225], Training Accuracy: 79.5797%, Training Loss: 0.4986%\n",
      "Epoch [31/300], Step [59/225], Training Accuracy: 79.6610%, Training Loss: 0.4967%\n",
      "Epoch [31/300], Step [60/225], Training Accuracy: 79.6094%, Training Loss: 0.4984%\n",
      "Epoch [31/300], Step [61/225], Training Accuracy: 79.7131%, Training Loss: 0.4979%\n",
      "Epoch [31/300], Step [62/225], Training Accuracy: 79.8639%, Training Loss: 0.4947%\n",
      "Epoch [31/300], Step [63/225], Training Accuracy: 79.8611%, Training Loss: 0.4938%\n",
      "Epoch [31/300], Step [64/225], Training Accuracy: 79.8828%, Training Loss: 0.4927%\n",
      "Epoch [31/300], Step [65/225], Training Accuracy: 79.7115%, Training Loss: 0.4956%\n",
      "Epoch [31/300], Step [66/225], Training Accuracy: 79.8769%, Training Loss: 0.4927%\n",
      "Epoch [31/300], Step [67/225], Training Accuracy: 79.8274%, Training Loss: 0.4932%\n",
      "Epoch [31/300], Step [68/225], Training Accuracy: 79.7335%, Training Loss: 0.4943%\n",
      "Epoch [31/300], Step [69/225], Training Accuracy: 79.6649%, Training Loss: 0.4947%\n",
      "Epoch [31/300], Step [70/225], Training Accuracy: 79.6652%, Training Loss: 0.4959%\n",
      "Epoch [31/300], Step [71/225], Training Accuracy: 79.6875%, Training Loss: 0.4974%\n",
      "Epoch [31/300], Step [72/225], Training Accuracy: 79.8177%, Training Loss: 0.4951%\n",
      "Epoch [31/300], Step [73/225], Training Accuracy: 79.9015%, Training Loss: 0.4930%\n",
      "Epoch [31/300], Step [74/225], Training Accuracy: 79.9409%, Training Loss: 0.4917%\n",
      "Epoch [31/300], Step [75/225], Training Accuracy: 79.9792%, Training Loss: 0.4913%\n",
      "Epoch [31/300], Step [76/225], Training Accuracy: 79.9137%, Training Loss: 0.4921%\n",
      "Epoch [31/300], Step [77/225], Training Accuracy: 79.9310%, Training Loss: 0.4913%\n",
      "Epoch [31/300], Step [78/225], Training Accuracy: 79.9880%, Training Loss: 0.4898%\n",
      "Epoch [31/300], Step [79/225], Training Accuracy: 79.9248%, Training Loss: 0.4893%\n",
      "Epoch [31/300], Step [80/225], Training Accuracy: 79.9023%, Training Loss: 0.4889%\n",
      "Epoch [31/300], Step [81/225], Training Accuracy: 79.9769%, Training Loss: 0.4872%\n",
      "Epoch [31/300], Step [82/225], Training Accuracy: 79.9543%, Training Loss: 0.4875%\n",
      "Epoch [31/300], Step [83/225], Training Accuracy: 79.9134%, Training Loss: 0.4880%\n",
      "Epoch [31/300], Step [84/225], Training Accuracy: 79.9293%, Training Loss: 0.4884%\n",
      "Epoch [31/300], Step [85/225], Training Accuracy: 79.9449%, Training Loss: 0.4869%\n",
      "Epoch [31/300], Step [86/225], Training Accuracy: 80.0690%, Training Loss: 0.4852%\n",
      "Epoch [31/300], Step [87/225], Training Accuracy: 79.9928%, Training Loss: 0.4860%\n",
      "Epoch [31/300], Step [88/225], Training Accuracy: 79.9538%, Training Loss: 0.4859%\n",
      "Epoch [31/300], Step [89/225], Training Accuracy: 80.0211%, Training Loss: 0.4847%\n",
      "Epoch [31/300], Step [90/225], Training Accuracy: 79.9479%, Training Loss: 0.4856%\n",
      "Epoch [31/300], Step [91/225], Training Accuracy: 79.9622%, Training Loss: 0.4851%\n",
      "Epoch [31/300], Step [92/225], Training Accuracy: 79.8743%, Training Loss: 0.4872%\n",
      "Epoch [31/300], Step [93/225], Training Accuracy: 79.9227%, Training Loss: 0.4874%\n",
      "Epoch [31/300], Step [94/225], Training Accuracy: 79.9036%, Training Loss: 0.4870%\n",
      "Epoch [31/300], Step [95/225], Training Accuracy: 79.8849%, Training Loss: 0.4874%\n",
      "Epoch [31/300], Step [96/225], Training Accuracy: 79.8828%, Training Loss: 0.4871%\n",
      "Epoch [31/300], Step [97/225], Training Accuracy: 79.8164%, Training Loss: 0.4888%\n",
      "Epoch [31/300], Step [98/225], Training Accuracy: 79.8469%, Training Loss: 0.4889%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/300], Step [99/225], Training Accuracy: 79.8453%, Training Loss: 0.4893%\n",
      "Epoch [31/300], Step [100/225], Training Accuracy: 79.7969%, Training Loss: 0.4904%\n",
      "Epoch [31/300], Step [101/225], Training Accuracy: 79.8113%, Training Loss: 0.4892%\n",
      "Epoch [31/300], Step [102/225], Training Accuracy: 79.8407%, Training Loss: 0.4888%\n",
      "Epoch [31/300], Step [103/225], Training Accuracy: 79.8392%, Training Loss: 0.4884%\n",
      "Epoch [31/300], Step [104/225], Training Accuracy: 79.8227%, Training Loss: 0.4879%\n",
      "Epoch [31/300], Step [105/225], Training Accuracy: 79.8214%, Training Loss: 0.4871%\n",
      "Epoch [31/300], Step [106/225], Training Accuracy: 79.8939%, Training Loss: 0.4865%\n",
      "Epoch [31/300], Step [107/225], Training Accuracy: 79.8189%, Training Loss: 0.4881%\n",
      "Epoch [31/300], Step [108/225], Training Accuracy: 79.8032%, Training Loss: 0.4893%\n",
      "Epoch [31/300], Step [109/225], Training Accuracy: 79.8165%, Training Loss: 0.4891%\n",
      "Epoch [31/300], Step [110/225], Training Accuracy: 79.8153%, Training Loss: 0.4907%\n",
      "Epoch [31/300], Step [111/225], Training Accuracy: 79.7720%, Training Loss: 0.4907%\n",
      "Epoch [31/300], Step [112/225], Training Accuracy: 79.7712%, Training Loss: 0.4899%\n",
      "Epoch [31/300], Step [113/225], Training Accuracy: 79.7843%, Training Loss: 0.4901%\n",
      "Epoch [31/300], Step [114/225], Training Accuracy: 79.7423%, Training Loss: 0.4914%\n",
      "Epoch [31/300], Step [115/225], Training Accuracy: 79.7147%, Training Loss: 0.4935%\n",
      "Epoch [31/300], Step [116/225], Training Accuracy: 79.7279%, Training Loss: 0.4925%\n",
      "Epoch [31/300], Step [117/225], Training Accuracy: 79.6875%, Training Loss: 0.4930%\n",
      "Epoch [31/300], Step [118/225], Training Accuracy: 79.7007%, Training Loss: 0.4932%\n",
      "Epoch [31/300], Step [119/225], Training Accuracy: 79.7400%, Training Loss: 0.4923%\n",
      "Epoch [31/300], Step [120/225], Training Accuracy: 79.6875%, Training Loss: 0.4929%\n",
      "Epoch [31/300], Step [121/225], Training Accuracy: 79.6746%, Training Loss: 0.4933%\n",
      "Epoch [31/300], Step [122/225], Training Accuracy: 79.6491%, Training Loss: 0.4942%\n",
      "Epoch [31/300], Step [123/225], Training Accuracy: 79.6748%, Training Loss: 0.4934%\n",
      "Epoch [31/300], Step [124/225], Training Accuracy: 79.7505%, Training Loss: 0.4918%\n",
      "Epoch [31/300], Step [125/225], Training Accuracy: 79.7250%, Training Loss: 0.4922%\n",
      "Epoch [31/300], Step [126/225], Training Accuracy: 79.7371%, Training Loss: 0.4915%\n",
      "Epoch [31/300], Step [127/225], Training Accuracy: 79.7367%, Training Loss: 0.4916%\n",
      "Epoch [31/300], Step [128/225], Training Accuracy: 79.6631%, Training Loss: 0.4928%\n",
      "Epoch [31/300], Step [129/225], Training Accuracy: 79.5906%, Training Loss: 0.4935%\n",
      "Epoch [31/300], Step [130/225], Training Accuracy: 79.5312%, Training Loss: 0.4943%\n",
      "Epoch [31/300], Step [131/225], Training Accuracy: 79.4847%, Training Loss: 0.4955%\n",
      "Epoch [31/300], Step [132/225], Training Accuracy: 79.4744%, Training Loss: 0.4955%\n",
      "Epoch [31/300], Step [133/225], Training Accuracy: 79.4878%, Training Loss: 0.4948%\n",
      "Epoch [31/300], Step [134/225], Training Accuracy: 79.4543%, Training Loss: 0.4956%\n",
      "Epoch [31/300], Step [135/225], Training Accuracy: 79.5023%, Training Loss: 0.4950%\n",
      "Epoch [31/300], Step [136/225], Training Accuracy: 79.4807%, Training Loss: 0.4953%\n",
      "Epoch [31/300], Step [137/225], Training Accuracy: 79.5392%, Training Loss: 0.4946%\n",
      "Epoch [31/300], Step [138/225], Training Accuracy: 79.6196%, Training Loss: 0.4930%\n",
      "Epoch [31/300], Step [139/225], Training Accuracy: 79.6425%, Training Loss: 0.4930%\n",
      "Epoch [31/300], Step [140/225], Training Accuracy: 79.6317%, Training Loss: 0.4926%\n",
      "Epoch [31/300], Step [141/225], Training Accuracy: 79.6321%, Training Loss: 0.4923%\n",
      "Epoch [31/300], Step [142/225], Training Accuracy: 79.6545%, Training Loss: 0.4915%\n",
      "Epoch [31/300], Step [143/225], Training Accuracy: 79.6219%, Training Loss: 0.4915%\n",
      "Epoch [31/300], Step [144/225], Training Accuracy: 79.6658%, Training Loss: 0.4902%\n",
      "Epoch [31/300], Step [145/225], Training Accuracy: 79.6228%, Training Loss: 0.4905%\n",
      "Epoch [31/300], Step [146/225], Training Accuracy: 79.6554%, Training Loss: 0.4908%\n",
      "Epoch [31/300], Step [147/225], Training Accuracy: 79.6344%, Training Loss: 0.4910%\n",
      "Epoch [31/300], Step [148/225], Training Accuracy: 79.6875%, Training Loss: 0.4899%\n",
      "Epoch [31/300], Step [149/225], Training Accuracy: 79.6246%, Training Loss: 0.4914%\n",
      "Epoch [31/300], Step [150/225], Training Accuracy: 79.6250%, Training Loss: 0.4912%\n",
      "Epoch [31/300], Step [151/225], Training Accuracy: 79.6565%, Training Loss: 0.4902%\n",
      "Epoch [31/300], Step [152/225], Training Accuracy: 79.6464%, Training Loss: 0.4900%\n",
      "Epoch [31/300], Step [153/225], Training Accuracy: 79.6262%, Training Loss: 0.4899%\n",
      "Epoch [31/300], Step [154/225], Training Accuracy: 79.6469%, Training Loss: 0.4898%\n",
      "Epoch [31/300], Step [155/225], Training Accuracy: 79.6673%, Training Loss: 0.4907%\n",
      "Epoch [31/300], Step [156/225], Training Accuracy: 79.6374%, Training Loss: 0.4913%\n",
      "Epoch [31/300], Step [157/225], Training Accuracy: 79.6676%, Training Loss: 0.4913%\n",
      "Epoch [31/300], Step [158/225], Training Accuracy: 79.6183%, Training Loss: 0.4921%\n",
      "Epoch [31/300], Step [159/225], Training Accuracy: 79.5401%, Training Loss: 0.4930%\n",
      "Epoch [31/300], Step [160/225], Training Accuracy: 79.5801%, Training Loss: 0.4924%\n",
      "Epoch [31/300], Step [161/225], Training Accuracy: 79.5613%, Training Loss: 0.4931%\n",
      "Epoch [31/300], Step [162/225], Training Accuracy: 79.5139%, Training Loss: 0.4938%\n",
      "Epoch [31/300], Step [163/225], Training Accuracy: 79.4862%, Training Loss: 0.4935%\n",
      "Epoch [31/300], Step [164/225], Training Accuracy: 79.5065%, Training Loss: 0.4927%\n",
      "Epoch [31/300], Step [165/225], Training Accuracy: 79.4981%, Training Loss: 0.4933%\n",
      "Epoch [31/300], Step [166/225], Training Accuracy: 79.5087%, Training Loss: 0.4934%\n",
      "Epoch [31/300], Step [167/225], Training Accuracy: 79.4910%, Training Loss: 0.4931%\n",
      "Epoch [31/300], Step [168/225], Training Accuracy: 79.4829%, Training Loss: 0.4934%\n",
      "Epoch [31/300], Step [169/225], Training Accuracy: 79.5396%, Training Loss: 0.4921%\n",
      "Epoch [31/300], Step [170/225], Training Accuracy: 79.5404%, Training Loss: 0.4920%\n",
      "Epoch [31/300], Step [171/225], Training Accuracy: 79.5504%, Training Loss: 0.4917%\n",
      "Epoch [31/300], Step [172/225], Training Accuracy: 79.5149%, Training Loss: 0.4919%\n",
      "Epoch [31/300], Step [173/225], Training Accuracy: 79.4978%, Training Loss: 0.4921%\n",
      "Epoch [31/300], Step [174/225], Training Accuracy: 79.5348%, Training Loss: 0.4915%\n",
      "Epoch [31/300], Step [175/225], Training Accuracy: 79.5536%, Training Loss: 0.4910%\n",
      "Epoch [31/300], Step [176/225], Training Accuracy: 79.5543%, Training Loss: 0.4907%\n",
      "Epoch [31/300], Step [177/225], Training Accuracy: 79.5639%, Training Loss: 0.4899%\n",
      "Epoch [31/300], Step [178/225], Training Accuracy: 79.5646%, Training Loss: 0.4896%\n",
      "Epoch [31/300], Step [179/225], Training Accuracy: 79.6089%, Training Loss: 0.4885%\n",
      "Epoch [31/300], Step [180/225], Training Accuracy: 79.6267%, Training Loss: 0.4882%\n",
      "Epoch [31/300], Step [181/225], Training Accuracy: 79.5925%, Training Loss: 0.4887%\n",
      "Epoch [31/300], Step [182/225], Training Accuracy: 79.6617%, Training Loss: 0.4878%\n",
      "Epoch [31/300], Step [183/225], Training Accuracy: 79.6448%, Training Loss: 0.4882%\n",
      "Epoch [31/300], Step [184/225], Training Accuracy: 79.6620%, Training Loss: 0.4883%\n",
      "Epoch [31/300], Step [185/225], Training Accuracy: 79.6791%, Training Loss: 0.4877%\n",
      "Epoch [31/300], Step [186/225], Training Accuracy: 79.7379%, Training Loss: 0.4863%\n",
      "Epoch [31/300], Step [187/225], Training Accuracy: 79.7209%, Training Loss: 0.4866%\n",
      "Epoch [31/300], Step [188/225], Training Accuracy: 79.7457%, Training Loss: 0.4864%\n",
      "Epoch [31/300], Step [189/225], Training Accuracy: 79.7702%, Training Loss: 0.4856%\n",
      "Epoch [31/300], Step [190/225], Training Accuracy: 79.8026%, Training Loss: 0.4848%\n",
      "Epoch [31/300], Step [191/225], Training Accuracy: 79.8102%, Training Loss: 0.4847%\n",
      "Epoch [31/300], Step [192/225], Training Accuracy: 79.8258%, Training Loss: 0.4841%\n",
      "Epoch [31/300], Step [193/225], Training Accuracy: 79.8413%, Training Loss: 0.4843%\n",
      "Epoch [31/300], Step [194/225], Training Accuracy: 79.8566%, Training Loss: 0.4839%\n",
      "Epoch [31/300], Step [195/225], Training Accuracy: 79.8718%, Training Loss: 0.4832%\n",
      "Epoch [31/300], Step [196/225], Training Accuracy: 79.8469%, Training Loss: 0.4835%\n",
      "Epoch [31/300], Step [197/225], Training Accuracy: 79.8223%, Training Loss: 0.4840%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/300], Step [198/225], Training Accuracy: 79.8848%, Training Loss: 0.4831%\n",
      "Epoch [31/300], Step [199/225], Training Accuracy: 79.9152%, Training Loss: 0.4825%\n",
      "Epoch [31/300], Step [200/225], Training Accuracy: 79.9141%, Training Loss: 0.4822%\n",
      "Epoch [31/300], Step [201/225], Training Accuracy: 79.9285%, Training Loss: 0.4815%\n",
      "Epoch [31/300], Step [202/225], Training Accuracy: 79.9582%, Training Loss: 0.4811%\n",
      "Epoch [31/300], Step [203/225], Training Accuracy: 79.9492%, Training Loss: 0.4812%\n",
      "Epoch [31/300], Step [204/225], Training Accuracy: 79.9326%, Training Loss: 0.4815%\n",
      "Epoch [31/300], Step [205/225], Training Accuracy: 79.9619%, Training Loss: 0.4811%\n",
      "Epoch [31/300], Step [206/225], Training Accuracy: 79.9606%, Training Loss: 0.4813%\n",
      "Epoch [31/300], Step [207/225], Training Accuracy: 80.0121%, Training Loss: 0.4805%\n",
      "Epoch [31/300], Step [208/225], Training Accuracy: 80.0180%, Training Loss: 0.4804%\n",
      "Epoch [31/300], Step [209/225], Training Accuracy: 80.0314%, Training Loss: 0.4799%\n",
      "Epoch [31/300], Step [210/225], Training Accuracy: 80.0521%, Training Loss: 0.4793%\n",
      "Epoch [31/300], Step [211/225], Training Accuracy: 80.0504%, Training Loss: 0.4792%\n",
      "Epoch [31/300], Step [212/225], Training Accuracy: 80.0265%, Training Loss: 0.4801%\n",
      "Epoch [31/300], Step [213/225], Training Accuracy: 79.9663%, Training Loss: 0.4812%\n",
      "Epoch [31/300], Step [214/225], Training Accuracy: 79.9796%, Training Loss: 0.4810%\n",
      "Epoch [31/300], Step [215/225], Training Accuracy: 79.9782%, Training Loss: 0.4817%\n",
      "Epoch [31/300], Step [216/225], Training Accuracy: 79.9769%, Training Loss: 0.4818%\n",
      "Epoch [31/300], Step [217/225], Training Accuracy: 79.9683%, Training Loss: 0.4821%\n",
      "Epoch [31/300], Step [218/225], Training Accuracy: 79.9384%, Training Loss: 0.4827%\n",
      "Epoch [31/300], Step [219/225], Training Accuracy: 79.9515%, Training Loss: 0.4825%\n",
      "Epoch [31/300], Step [220/225], Training Accuracy: 79.9503%, Training Loss: 0.4823%\n",
      "Epoch [31/300], Step [221/225], Training Accuracy: 79.9632%, Training Loss: 0.4826%\n",
      "Epoch [31/300], Step [222/225], Training Accuracy: 79.9479%, Training Loss: 0.4830%\n",
      "Epoch [31/300], Step [223/225], Training Accuracy: 79.9678%, Training Loss: 0.4827%\n",
      "Epoch [31/300], Step [224/225], Training Accuracy: 79.9944%, Training Loss: 0.4827%\n",
      "Epoch [31/300], Step [225/225], Training Accuracy: 80.0097%, Training Loss: 0.4821%\n",
      "Epoch [32/300], Step [1/225], Training Accuracy: 84.3750%, Training Loss: 0.5303%\n",
      "Epoch [32/300], Step [2/225], Training Accuracy: 84.3750%, Training Loss: 0.4549%\n",
      "Epoch [32/300], Step [3/225], Training Accuracy: 80.2083%, Training Loss: 0.5204%\n",
      "Epoch [32/300], Step [4/225], Training Accuracy: 79.2969%, Training Loss: 0.5299%\n",
      "Epoch [32/300], Step [5/225], Training Accuracy: 79.6875%, Training Loss: 0.5327%\n",
      "Epoch [32/300], Step [6/225], Training Accuracy: 79.9479%, Training Loss: 0.5167%\n",
      "Epoch [32/300], Step [7/225], Training Accuracy: 79.4643%, Training Loss: 0.5122%\n",
      "Epoch [32/300], Step [8/225], Training Accuracy: 79.6875%, Training Loss: 0.5010%\n",
      "Epoch [32/300], Step [9/225], Training Accuracy: 79.8611%, Training Loss: 0.5039%\n",
      "Epoch [32/300], Step [10/225], Training Accuracy: 79.3750%, Training Loss: 0.5073%\n",
      "Epoch [32/300], Step [11/225], Training Accuracy: 79.1193%, Training Loss: 0.5135%\n",
      "Epoch [32/300], Step [12/225], Training Accuracy: 79.1667%, Training Loss: 0.5055%\n",
      "Epoch [32/300], Step [13/225], Training Accuracy: 80.2885%, Training Loss: 0.4838%\n",
      "Epoch [32/300], Step [14/225], Training Accuracy: 80.4688%, Training Loss: 0.4759%\n",
      "Epoch [32/300], Step [15/225], Training Accuracy: 80.6250%, Training Loss: 0.4703%\n",
      "Epoch [32/300], Step [16/225], Training Accuracy: 80.8594%, Training Loss: 0.4637%\n",
      "Epoch [32/300], Step [17/225], Training Accuracy: 81.1581%, Training Loss: 0.4592%\n",
      "Epoch [32/300], Step [18/225], Training Accuracy: 80.9896%, Training Loss: 0.4595%\n",
      "Epoch [32/300], Step [19/225], Training Accuracy: 81.0033%, Training Loss: 0.4569%\n",
      "Epoch [32/300], Step [20/225], Training Accuracy: 81.0938%, Training Loss: 0.4565%\n",
      "Epoch [32/300], Step [21/225], Training Accuracy: 81.1756%, Training Loss: 0.4597%\n",
      "Epoch [32/300], Step [22/225], Training Accuracy: 81.0369%, Training Loss: 0.4619%\n",
      "Epoch [32/300], Step [23/225], Training Accuracy: 81.1821%, Training Loss: 0.4625%\n",
      "Epoch [32/300], Step [24/225], Training Accuracy: 81.1198%, Training Loss: 0.4642%\n",
      "Epoch [32/300], Step [25/225], Training Accuracy: 81.4375%, Training Loss: 0.4587%\n",
      "Epoch [32/300], Step [26/225], Training Accuracy: 81.5505%, Training Loss: 0.4617%\n",
      "Epoch [32/300], Step [27/225], Training Accuracy: 81.5394%, Training Loss: 0.4618%\n",
      "Epoch [32/300], Step [28/225], Training Accuracy: 81.6964%, Training Loss: 0.4570%\n",
      "Epoch [32/300], Step [29/225], Training Accuracy: 81.7349%, Training Loss: 0.4535%\n",
      "Epoch [32/300], Step [30/225], Training Accuracy: 81.7188%, Training Loss: 0.4541%\n",
      "Epoch [32/300], Step [31/225], Training Accuracy: 81.4516%, Training Loss: 0.4592%\n",
      "Epoch [32/300], Step [32/225], Training Accuracy: 81.2500%, Training Loss: 0.4591%\n",
      "Epoch [32/300], Step [33/225], Training Accuracy: 81.3447%, Training Loss: 0.4577%\n",
      "Epoch [32/300], Step [34/225], Training Accuracy: 81.2960%, Training Loss: 0.4612%\n",
      "Epoch [32/300], Step [35/225], Training Accuracy: 81.2946%, Training Loss: 0.4653%\n",
      "Epoch [32/300], Step [36/225], Training Accuracy: 81.2934%, Training Loss: 0.4698%\n",
      "Epoch [32/300], Step [37/225], Training Accuracy: 81.1655%, Training Loss: 0.4698%\n",
      "Epoch [32/300], Step [38/225], Training Accuracy: 81.0033%, Training Loss: 0.4717%\n",
      "Epoch [32/300], Step [39/225], Training Accuracy: 80.9696%, Training Loss: 0.4720%\n",
      "Epoch [32/300], Step [40/225], Training Accuracy: 80.7812%, Training Loss: 0.4755%\n",
      "Epoch [32/300], Step [41/225], Training Accuracy: 80.5640%, Training Loss: 0.4789%\n",
      "Epoch [32/300], Step [42/225], Training Accuracy: 80.5060%, Training Loss: 0.4792%\n",
      "Epoch [32/300], Step [43/225], Training Accuracy: 80.4506%, Training Loss: 0.4821%\n",
      "Epoch [32/300], Step [44/225], Training Accuracy: 80.5043%, Training Loss: 0.4805%\n",
      "Epoch [32/300], Step [45/225], Training Accuracy: 80.3819%, Training Loss: 0.4835%\n",
      "Epoch [32/300], Step [46/225], Training Accuracy: 80.3668%, Training Loss: 0.4820%\n",
      "Epoch [32/300], Step [47/225], Training Accuracy: 80.3191%, Training Loss: 0.4822%\n",
      "Epoch [32/300], Step [48/225], Training Accuracy: 80.2734%, Training Loss: 0.4880%\n",
      "Epoch [32/300], Step [49/225], Training Accuracy: 80.2934%, Training Loss: 0.4875%\n",
      "Epoch [32/300], Step [50/225], Training Accuracy: 80.1250%, Training Loss: 0.4880%\n",
      "Epoch [32/300], Step [51/225], Training Accuracy: 80.1777%, Training Loss: 0.4866%\n",
      "Epoch [32/300], Step [52/225], Training Accuracy: 80.3185%, Training Loss: 0.4836%\n",
      "Epoch [32/300], Step [53/225], Training Accuracy: 80.1887%, Training Loss: 0.4877%\n",
      "Epoch [32/300], Step [54/225], Training Accuracy: 80.0926%, Training Loss: 0.4888%\n",
      "Epoch [32/300], Step [55/225], Training Accuracy: 80.0852%, Training Loss: 0.4891%\n",
      "Epoch [32/300], Step [56/225], Training Accuracy: 80.1060%, Training Loss: 0.4873%\n",
      "Epoch [32/300], Step [57/225], Training Accuracy: 80.2357%, Training Loss: 0.4858%\n",
      "Epoch [32/300], Step [58/225], Training Accuracy: 80.3879%, Training Loss: 0.4843%\n",
      "Epoch [32/300], Step [59/225], Training Accuracy: 80.3231%, Training Loss: 0.4867%\n",
      "Epoch [32/300], Step [60/225], Training Accuracy: 80.4427%, Training Loss: 0.4841%\n",
      "Epoch [32/300], Step [61/225], Training Accuracy: 80.4816%, Training Loss: 0.4851%\n",
      "Epoch [32/300], Step [62/225], Training Accuracy: 80.4688%, Training Loss: 0.4844%\n",
      "Epoch [32/300], Step [63/225], Training Accuracy: 80.4563%, Training Loss: 0.4859%\n",
      "Epoch [32/300], Step [64/225], Training Accuracy: 80.4932%, Training Loss: 0.4860%\n",
      "Epoch [32/300], Step [65/225], Training Accuracy: 80.5048%, Training Loss: 0.4849%\n",
      "Epoch [32/300], Step [66/225], Training Accuracy: 80.5161%, Training Loss: 0.4832%\n",
      "Epoch [32/300], Step [67/225], Training Accuracy: 80.2938%, Training Loss: 0.4857%\n",
      "Epoch [32/300], Step [68/225], Training Accuracy: 80.2849%, Training Loss: 0.4873%\n",
      "Epoch [32/300], Step [69/225], Training Accuracy: 80.2536%, Training Loss: 0.4885%\n",
      "Epoch [32/300], Step [70/225], Training Accuracy: 80.3125%, Training Loss: 0.4879%\n",
      "Epoch [32/300], Step [71/225], Training Accuracy: 80.3477%, Training Loss: 0.4870%\n",
      "Epoch [32/300], Step [72/225], Training Accuracy: 80.3168%, Training Loss: 0.4870%\n",
      "Epoch [32/300], Step [73/225], Training Accuracy: 80.3296%, Training Loss: 0.4867%\n",
      "Epoch [32/300], Step [74/225], Training Accuracy: 80.3209%, Training Loss: 0.4865%\n",
      "Epoch [32/300], Step [75/225], Training Accuracy: 80.2708%, Training Loss: 0.4877%\n",
      "Epoch [32/300], Step [76/225], Training Accuracy: 80.1809%, Training Loss: 0.4882%\n",
      "Epoch [32/300], Step [77/225], Training Accuracy: 80.2557%, Training Loss: 0.4877%\n",
      "Epoch [32/300], Step [78/225], Training Accuracy: 80.2885%, Training Loss: 0.4878%\n",
      "Epoch [32/300], Step [79/225], Training Accuracy: 80.3204%, Training Loss: 0.4867%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/300], Step [80/225], Training Accuracy: 80.3125%, Training Loss: 0.4862%\n",
      "Epoch [32/300], Step [81/225], Training Accuracy: 80.3434%, Training Loss: 0.4854%\n",
      "Epoch [32/300], Step [82/225], Training Accuracy: 80.3354%, Training Loss: 0.4851%\n",
      "Epoch [32/300], Step [83/225], Training Accuracy: 80.2899%, Training Loss: 0.4850%\n",
      "Epoch [32/300], Step [84/225], Training Accuracy: 80.3571%, Training Loss: 0.4831%\n",
      "Epoch [32/300], Step [85/225], Training Accuracy: 80.3125%, Training Loss: 0.4832%\n",
      "Epoch [32/300], Step [86/225], Training Accuracy: 80.3597%, Training Loss: 0.4819%\n",
      "Epoch [32/300], Step [87/225], Training Accuracy: 80.3341%, Training Loss: 0.4834%\n",
      "Epoch [32/300], Step [88/225], Training Accuracy: 80.2202%, Training Loss: 0.4845%\n",
      "Epoch [32/300], Step [89/225], Training Accuracy: 80.2142%, Training Loss: 0.4859%\n",
      "Epoch [32/300], Step [90/225], Training Accuracy: 80.2083%, Training Loss: 0.4860%\n",
      "Epoch [32/300], Step [91/225], Training Accuracy: 80.1168%, Training Loss: 0.4866%\n",
      "Epoch [32/300], Step [92/225], Training Accuracy: 80.1461%, Training Loss: 0.4863%\n",
      "Epoch [32/300], Step [93/225], Training Accuracy: 80.2419%, Training Loss: 0.4847%\n",
      "Epoch [32/300], Step [94/225], Training Accuracy: 80.2194%, Training Loss: 0.4839%\n",
      "Epoch [32/300], Step [95/225], Training Accuracy: 80.2796%, Training Loss: 0.4826%\n",
      "Epoch [32/300], Step [96/225], Training Accuracy: 80.3223%, Training Loss: 0.4808%\n",
      "Epoch [32/300], Step [97/225], Training Accuracy: 80.2835%, Training Loss: 0.4823%\n",
      "Epoch [32/300], Step [98/225], Training Accuracy: 80.2615%, Training Loss: 0.4822%\n",
      "Epoch [32/300], Step [99/225], Training Accuracy: 80.2399%, Training Loss: 0.4827%\n",
      "Epoch [32/300], Step [100/225], Training Accuracy: 80.1562%, Training Loss: 0.4844%\n",
      "Epoch [32/300], Step [101/225], Training Accuracy: 80.1361%, Training Loss: 0.4841%\n",
      "Epoch [32/300], Step [102/225], Training Accuracy: 80.1317%, Training Loss: 0.4843%\n",
      "Epoch [32/300], Step [103/225], Training Accuracy: 80.1123%, Training Loss: 0.4842%\n",
      "Epoch [32/300], Step [104/225], Training Accuracy: 80.0481%, Training Loss: 0.4858%\n",
      "Epoch [32/300], Step [105/225], Training Accuracy: 80.1488%, Training Loss: 0.4841%\n",
      "Epoch [32/300], Step [106/225], Training Accuracy: 80.1002%, Training Loss: 0.4855%\n",
      "Epoch [32/300], Step [107/225], Training Accuracy: 80.0818%, Training Loss: 0.4860%\n",
      "Epoch [32/300], Step [108/225], Training Accuracy: 80.1215%, Training Loss: 0.4856%\n",
      "Epoch [32/300], Step [109/225], Training Accuracy: 80.0889%, Training Loss: 0.4860%\n",
      "Epoch [32/300], Step [110/225], Training Accuracy: 80.0426%, Training Loss: 0.4868%\n",
      "Epoch [32/300], Step [111/225], Training Accuracy: 80.0253%, Training Loss: 0.4865%\n",
      "Epoch [32/300], Step [112/225], Training Accuracy: 80.0084%, Training Loss: 0.4862%\n",
      "Epoch [32/300], Step [113/225], Training Accuracy: 79.9917%, Training Loss: 0.4861%\n",
      "Epoch [32/300], Step [114/225], Training Accuracy: 80.0439%, Training Loss: 0.4851%\n",
      "Epoch [32/300], Step [115/225], Training Accuracy: 80.0679%, Training Loss: 0.4844%\n",
      "Epoch [32/300], Step [116/225], Training Accuracy: 80.0377%, Training Loss: 0.4851%\n",
      "Epoch [32/300], Step [117/225], Training Accuracy: 80.0347%, Training Loss: 0.4856%\n",
      "Epoch [32/300], Step [118/225], Training Accuracy: 80.0318%, Training Loss: 0.4841%\n",
      "Epoch [32/300], Step [119/225], Training Accuracy: 80.0289%, Training Loss: 0.4846%\n",
      "Epoch [32/300], Step [120/225], Training Accuracy: 80.0000%, Training Loss: 0.4847%\n",
      "Epoch [32/300], Step [121/225], Training Accuracy: 79.8812%, Training Loss: 0.4871%\n",
      "Epoch [32/300], Step [122/225], Training Accuracy: 79.8284%, Training Loss: 0.4880%\n",
      "Epoch [32/300], Step [123/225], Training Accuracy: 79.8780%, Training Loss: 0.4873%\n",
      "Epoch [32/300], Step [124/225], Training Accuracy: 79.8009%, Training Loss: 0.4887%\n",
      "Epoch [32/300], Step [125/225], Training Accuracy: 79.8750%, Training Loss: 0.4879%\n",
      "Epoch [32/300], Step [126/225], Training Accuracy: 79.8487%, Training Loss: 0.4877%\n",
      "Epoch [32/300], Step [127/225], Training Accuracy: 79.8474%, Training Loss: 0.4880%\n",
      "Epoch [32/300], Step [128/225], Training Accuracy: 79.8584%, Training Loss: 0.4876%\n",
      "Epoch [32/300], Step [129/225], Training Accuracy: 79.7965%, Training Loss: 0.4887%\n",
      "Epoch [32/300], Step [130/225], Training Accuracy: 79.8317%, Training Loss: 0.4880%\n",
      "Epoch [32/300], Step [131/225], Training Accuracy: 79.7948%, Training Loss: 0.4886%\n",
      "Epoch [32/300], Step [132/225], Training Accuracy: 79.7467%, Training Loss: 0.4905%\n",
      "Epoch [32/300], Step [133/225], Training Accuracy: 79.7697%, Training Loss: 0.4898%\n",
      "Epoch [32/300], Step [134/225], Training Accuracy: 79.7575%, Training Loss: 0.4906%\n",
      "Epoch [32/300], Step [135/225], Training Accuracy: 79.7569%, Training Loss: 0.4903%\n",
      "Epoch [32/300], Step [136/225], Training Accuracy: 79.7794%, Training Loss: 0.4897%\n",
      "Epoch [32/300], Step [137/225], Training Accuracy: 79.7787%, Training Loss: 0.4893%\n",
      "Epoch [32/300], Step [138/225], Training Accuracy: 79.7894%, Training Loss: 0.4891%\n",
      "Epoch [32/300], Step [139/225], Training Accuracy: 79.7999%, Training Loss: 0.4885%\n",
      "Epoch [32/300], Step [140/225], Training Accuracy: 79.8326%, Training Loss: 0.4882%\n",
      "Epoch [32/300], Step [141/225], Training Accuracy: 79.8537%, Training Loss: 0.4875%\n",
      "Epoch [32/300], Step [142/225], Training Accuracy: 79.8746%, Training Loss: 0.4869%\n",
      "Epoch [32/300], Step [143/225], Training Accuracy: 79.8951%, Training Loss: 0.4866%\n",
      "Epoch [32/300], Step [144/225], Training Accuracy: 79.9045%, Training Loss: 0.4862%\n",
      "Epoch [32/300], Step [145/225], Training Accuracy: 79.8599%, Training Loss: 0.4864%\n",
      "Epoch [32/300], Step [146/225], Training Accuracy: 79.8908%, Training Loss: 0.4858%\n",
      "Epoch [32/300], Step [147/225], Training Accuracy: 79.8788%, Training Loss: 0.4852%\n",
      "Epoch [32/300], Step [148/225], Training Accuracy: 79.8881%, Training Loss: 0.4845%\n",
      "Epoch [32/300], Step [149/225], Training Accuracy: 79.8867%, Training Loss: 0.4842%\n",
      "Epoch [32/300], Step [150/225], Training Accuracy: 79.9479%, Training Loss: 0.4828%\n",
      "Epoch [32/300], Step [151/225], Training Accuracy: 80.0186%, Training Loss: 0.4811%\n",
      "Epoch [32/300], Step [152/225], Training Accuracy: 79.9959%, Training Loss: 0.4811%\n",
      "Epoch [32/300], Step [153/225], Training Accuracy: 80.0449%, Training Loss: 0.4806%\n",
      "Epoch [32/300], Step [154/225], Training Accuracy: 80.0020%, Training Loss: 0.4806%\n",
      "Epoch [32/300], Step [155/225], Training Accuracy: 80.0202%, Training Loss: 0.4800%\n",
      "Epoch [32/300], Step [156/225], Training Accuracy: 80.0481%, Training Loss: 0.4790%\n",
      "Epoch [32/300], Step [157/225], Training Accuracy: 80.0060%, Training Loss: 0.4797%\n",
      "Epoch [32/300], Step [158/225], Training Accuracy: 80.0534%, Training Loss: 0.4797%\n",
      "Epoch [32/300], Step [159/225], Training Accuracy: 80.0609%, Training Loss: 0.4795%\n",
      "Epoch [32/300], Step [160/225], Training Accuracy: 80.0293%, Training Loss: 0.4805%\n",
      "Epoch [32/300], Step [161/225], Training Accuracy: 80.0563%, Training Loss: 0.4802%\n",
      "Epoch [32/300], Step [162/225], Training Accuracy: 80.0829%, Training Loss: 0.4796%\n",
      "Epoch [32/300], Step [163/225], Training Accuracy: 80.0518%, Training Loss: 0.4795%\n",
      "Epoch [32/300], Step [164/225], Training Accuracy: 80.0686%, Training Loss: 0.4795%\n",
      "Epoch [32/300], Step [165/225], Training Accuracy: 80.0663%, Training Loss: 0.4793%\n",
      "Epoch [32/300], Step [166/225], Training Accuracy: 80.0546%, Training Loss: 0.4795%\n",
      "Epoch [32/300], Step [167/225], Training Accuracy: 80.0898%, Training Loss: 0.4791%\n",
      "Epoch [32/300], Step [168/225], Training Accuracy: 80.1060%, Training Loss: 0.4789%\n",
      "Epoch [32/300], Step [169/225], Training Accuracy: 80.1683%, Training Loss: 0.4779%\n",
      "Epoch [32/300], Step [170/225], Training Accuracy: 80.1011%, Training Loss: 0.4786%\n",
      "Epoch [32/300], Step [171/225], Training Accuracy: 80.0530%, Training Loss: 0.4796%\n",
      "Epoch [32/300], Step [172/225], Training Accuracy: 80.0327%, Training Loss: 0.4801%\n",
      "Epoch [32/300], Step [173/225], Training Accuracy: 80.0217%, Training Loss: 0.4800%\n",
      "Epoch [32/300], Step [174/225], Training Accuracy: 80.0557%, Training Loss: 0.4791%\n",
      "Epoch [32/300], Step [175/225], Training Accuracy: 80.0179%, Training Loss: 0.4793%\n",
      "Epoch [32/300], Step [176/225], Training Accuracy: 80.0426%, Training Loss: 0.4789%\n",
      "Epoch [32/300], Step [177/225], Training Accuracy: 80.0318%, Training Loss: 0.4789%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/300], Step [178/225], Training Accuracy: 80.0650%, Training Loss: 0.4791%\n",
      "Epoch [32/300], Step [179/225], Training Accuracy: 80.0541%, Training Loss: 0.4789%\n",
      "Epoch [32/300], Step [180/225], Training Accuracy: 80.1042%, Training Loss: 0.4781%\n",
      "Epoch [32/300], Step [181/225], Training Accuracy: 80.1105%, Training Loss: 0.4781%\n",
      "Epoch [32/300], Step [182/225], Training Accuracy: 80.1425%, Training Loss: 0.4780%\n",
      "Epoch [32/300], Step [183/225], Training Accuracy: 80.1998%, Training Loss: 0.4776%\n",
      "Epoch [32/300], Step [184/225], Training Accuracy: 80.2395%, Training Loss: 0.4771%\n",
      "Epoch [32/300], Step [185/225], Training Accuracy: 80.2534%, Training Loss: 0.4764%\n",
      "Epoch [32/300], Step [186/225], Training Accuracy: 80.2839%, Training Loss: 0.4755%\n",
      "Epoch [32/300], Step [187/225], Training Accuracy: 80.3058%, Training Loss: 0.4749%\n",
      "Epoch [32/300], Step [188/225], Training Accuracy: 80.2942%, Training Loss: 0.4749%\n",
      "Epoch [32/300], Step [189/225], Training Accuracy: 80.3241%, Training Loss: 0.4744%\n",
      "Epoch [32/300], Step [190/225], Training Accuracy: 80.2796%, Training Loss: 0.4751%\n",
      "Epoch [32/300], Step [191/225], Training Accuracy: 80.2520%, Training Loss: 0.4756%\n",
      "Epoch [32/300], Step [192/225], Training Accuracy: 80.2653%, Training Loss: 0.4753%\n",
      "Epoch [32/300], Step [193/225], Training Accuracy: 80.2866%, Training Loss: 0.4748%\n",
      "Epoch [32/300], Step [194/225], Training Accuracy: 80.2835%, Training Loss: 0.4751%\n",
      "Epoch [32/300], Step [195/225], Training Accuracy: 80.3125%, Training Loss: 0.4743%\n",
      "Epoch [32/300], Step [196/225], Training Accuracy: 80.3173%, Training Loss: 0.4742%\n",
      "Epoch [32/300], Step [197/225], Training Accuracy: 80.3220%, Training Loss: 0.4744%\n",
      "Epoch [32/300], Step [198/225], Training Accuracy: 80.3583%, Training Loss: 0.4738%\n",
      "Epoch [32/300], Step [199/225], Training Accuracy: 80.3235%, Training Loss: 0.4741%\n",
      "Epoch [32/300], Step [200/225], Training Accuracy: 80.3516%, Training Loss: 0.4734%\n",
      "Epoch [32/300], Step [201/225], Training Accuracy: 80.3716%, Training Loss: 0.4731%\n",
      "Epoch [32/300], Step [202/225], Training Accuracy: 80.3682%, Training Loss: 0.4739%\n",
      "Epoch [32/300], Step [203/225], Training Accuracy: 80.4033%, Training Loss: 0.4731%\n",
      "Epoch [32/300], Step [204/225], Training Accuracy: 80.4305%, Training Loss: 0.4732%\n",
      "Epoch [32/300], Step [205/225], Training Accuracy: 80.4345%, Training Loss: 0.4729%\n",
      "Epoch [32/300], Step [206/225], Training Accuracy: 80.4384%, Training Loss: 0.4730%\n",
      "Epoch [32/300], Step [207/225], Training Accuracy: 80.4197%, Training Loss: 0.4738%\n",
      "Epoch [32/300], Step [208/225], Training Accuracy: 80.4162%, Training Loss: 0.4739%\n",
      "Epoch [32/300], Step [209/225], Training Accuracy: 80.3977%, Training Loss: 0.4740%\n",
      "Epoch [32/300], Step [210/225], Training Accuracy: 80.4018%, Training Loss: 0.4740%\n",
      "Epoch [32/300], Step [211/225], Training Accuracy: 80.3984%, Training Loss: 0.4736%\n",
      "Epoch [32/300], Step [212/225], Training Accuracy: 80.4098%, Training Loss: 0.4735%\n",
      "Epoch [32/300], Step [213/225], Training Accuracy: 80.3844%, Training Loss: 0.4739%\n",
      "Epoch [32/300], Step [214/225], Training Accuracy: 80.3957%, Training Loss: 0.4738%\n",
      "Epoch [32/300], Step [215/225], Training Accuracy: 80.3852%, Training Loss: 0.4741%\n",
      "Epoch [32/300], Step [216/225], Training Accuracy: 80.3675%, Training Loss: 0.4744%\n",
      "Epoch [32/300], Step [217/225], Training Accuracy: 80.3571%, Training Loss: 0.4745%\n",
      "Epoch [32/300], Step [218/225], Training Accuracy: 80.3541%, Training Loss: 0.4748%\n",
      "Epoch [32/300], Step [219/225], Training Accuracy: 80.3439%, Training Loss: 0.4750%\n",
      "Epoch [32/300], Step [220/225], Training Accuracy: 80.3409%, Training Loss: 0.4752%\n",
      "Epoch [32/300], Step [221/225], Training Accuracy: 80.3804%, Training Loss: 0.4744%\n",
      "Epoch [32/300], Step [222/225], Training Accuracy: 80.3984%, Training Loss: 0.4742%\n",
      "Epoch [32/300], Step [223/225], Training Accuracy: 80.3952%, Training Loss: 0.4744%\n",
      "Epoch [32/300], Step [224/225], Training Accuracy: 80.3711%, Training Loss: 0.4743%\n",
      "Epoch [32/300], Step [225/225], Training Accuracy: 80.3919%, Training Loss: 0.4735%\n",
      "Epoch [33/300], Step [1/225], Training Accuracy: 85.9375%, Training Loss: 0.3760%\n",
      "Epoch [33/300], Step [2/225], Training Accuracy: 79.6875%, Training Loss: 0.5001%\n",
      "Epoch [33/300], Step [3/225], Training Accuracy: 81.2500%, Training Loss: 0.4483%\n",
      "Epoch [33/300], Step [4/225], Training Accuracy: 78.5156%, Training Loss: 0.4921%\n",
      "Epoch [33/300], Step [5/225], Training Accuracy: 78.4375%, Training Loss: 0.4867%\n",
      "Epoch [33/300], Step [6/225], Training Accuracy: 80.4688%, Training Loss: 0.4808%\n",
      "Epoch [33/300], Step [7/225], Training Accuracy: 80.3571%, Training Loss: 0.4836%\n",
      "Epoch [33/300], Step [8/225], Training Accuracy: 80.0781%, Training Loss: 0.4963%\n",
      "Epoch [33/300], Step [9/225], Training Accuracy: 80.7292%, Training Loss: 0.4815%\n",
      "Epoch [33/300], Step [10/225], Training Accuracy: 80.4688%, Training Loss: 0.5007%\n",
      "Epoch [33/300], Step [11/225], Training Accuracy: 80.9659%, Training Loss: 0.4896%\n",
      "Epoch [33/300], Step [12/225], Training Accuracy: 81.2500%, Training Loss: 0.4840%\n",
      "Epoch [33/300], Step [13/225], Training Accuracy: 81.7308%, Training Loss: 0.4731%\n",
      "Epoch [33/300], Step [14/225], Training Accuracy: 82.2545%, Training Loss: 0.4680%\n",
      "Epoch [33/300], Step [15/225], Training Accuracy: 82.5000%, Training Loss: 0.4605%\n",
      "Epoch [33/300], Step [16/225], Training Accuracy: 82.1289%, Training Loss: 0.4692%\n",
      "Epoch [33/300], Step [17/225], Training Accuracy: 81.8934%, Training Loss: 0.4680%\n",
      "Epoch [33/300], Step [18/225], Training Accuracy: 81.7708%, Training Loss: 0.4731%\n",
      "Epoch [33/300], Step [19/225], Training Accuracy: 81.4967%, Training Loss: 0.4681%\n",
      "Epoch [33/300], Step [20/225], Training Accuracy: 81.5625%, Training Loss: 0.4650%\n",
      "Epoch [33/300], Step [21/225], Training Accuracy: 81.3988%, Training Loss: 0.4647%\n",
      "Epoch [33/300], Step [22/225], Training Accuracy: 80.8949%, Training Loss: 0.4733%\n",
      "Epoch [33/300], Step [23/225], Training Accuracy: 80.9103%, Training Loss: 0.4744%\n",
      "Epoch [33/300], Step [24/225], Training Accuracy: 80.4036%, Training Loss: 0.4777%\n",
      "Epoch [33/300], Step [25/225], Training Accuracy: 80.5625%, Training Loss: 0.4755%\n",
      "Epoch [33/300], Step [26/225], Training Accuracy: 80.5288%, Training Loss: 0.4758%\n",
      "Epoch [33/300], Step [27/225], Training Accuracy: 80.7870%, Training Loss: 0.4701%\n",
      "Epoch [33/300], Step [28/225], Training Accuracy: 81.0268%, Training Loss: 0.4612%\n",
      "Epoch [33/300], Step [29/225], Training Accuracy: 81.1422%, Training Loss: 0.4559%\n",
      "Epoch [33/300], Step [30/225], Training Accuracy: 81.3021%, Training Loss: 0.4517%\n",
      "Epoch [33/300], Step [31/225], Training Accuracy: 81.1492%, Training Loss: 0.4582%\n",
      "Epoch [33/300], Step [32/225], Training Accuracy: 81.1523%, Training Loss: 0.4579%\n",
      "Epoch [33/300], Step [33/225], Training Accuracy: 81.2973%, Training Loss: 0.4572%\n",
      "Epoch [33/300], Step [34/225], Training Accuracy: 81.0662%, Training Loss: 0.4646%\n",
      "Epoch [33/300], Step [35/225], Training Accuracy: 81.3839%, Training Loss: 0.4614%\n",
      "Epoch [33/300], Step [36/225], Training Accuracy: 81.2934%, Training Loss: 0.4635%\n",
      "Epoch [33/300], Step [37/225], Training Accuracy: 81.3767%, Training Loss: 0.4628%\n",
      "Epoch [33/300], Step [38/225], Training Accuracy: 81.3734%, Training Loss: 0.4635%\n",
      "Epoch [33/300], Step [39/225], Training Accuracy: 81.1699%, Training Loss: 0.4689%\n",
      "Epoch [33/300], Step [40/225], Training Accuracy: 81.2500%, Training Loss: 0.4665%\n",
      "Epoch [33/300], Step [41/225], Training Accuracy: 81.1738%, Training Loss: 0.4678%\n",
      "Epoch [33/300], Step [42/225], Training Accuracy: 80.9896%, Training Loss: 0.4680%\n",
      "Epoch [33/300], Step [43/225], Training Accuracy: 80.9593%, Training Loss: 0.4683%\n",
      "Epoch [33/300], Step [44/225], Training Accuracy: 81.0369%, Training Loss: 0.4659%\n",
      "Epoch [33/300], Step [45/225], Training Accuracy: 81.0069%, Training Loss: 0.4666%\n",
      "Epoch [33/300], Step [46/225], Training Accuracy: 81.2500%, Training Loss: 0.4621%\n",
      "Epoch [33/300], Step [47/225], Training Accuracy: 81.0505%, Training Loss: 0.4649%\n",
      "Epoch [33/300], Step [48/225], Training Accuracy: 80.9896%, Training Loss: 0.4638%\n",
      "Epoch [33/300], Step [49/225], Training Accuracy: 80.8992%, Training Loss: 0.4653%\n",
      "Epoch [33/300], Step [50/225], Training Accuracy: 80.8750%, Training Loss: 0.4660%\n",
      "Epoch [33/300], Step [51/225], Training Accuracy: 80.9130%, Training Loss: 0.4647%\n",
      "Epoch [33/300], Step [52/225], Training Accuracy: 81.0096%, Training Loss: 0.4616%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/300], Step [53/225], Training Accuracy: 81.0142%, Training Loss: 0.4625%\n",
      "Epoch [33/300], Step [54/225], Training Accuracy: 80.9606%, Training Loss: 0.4640%\n",
      "Epoch [33/300], Step [55/225], Training Accuracy: 81.0511%, Training Loss: 0.4627%\n",
      "Epoch [33/300], Step [56/225], Training Accuracy: 81.1942%, Training Loss: 0.4603%\n",
      "Epoch [33/300], Step [57/225], Training Accuracy: 81.1678%, Training Loss: 0.4603%\n",
      "Epoch [33/300], Step [58/225], Training Accuracy: 81.1692%, Training Loss: 0.4602%\n",
      "Epoch [33/300], Step [59/225], Training Accuracy: 81.1706%, Training Loss: 0.4598%\n",
      "Epoch [33/300], Step [60/225], Training Accuracy: 81.1719%, Training Loss: 0.4588%\n",
      "Epoch [33/300], Step [61/225], Training Accuracy: 81.2244%, Training Loss: 0.4583%\n",
      "Epoch [33/300], Step [62/225], Training Accuracy: 81.2752%, Training Loss: 0.4560%\n",
      "Epoch [33/300], Step [63/225], Training Accuracy: 81.3244%, Training Loss: 0.4540%\n",
      "Epoch [33/300], Step [64/225], Training Accuracy: 81.1768%, Training Loss: 0.4554%\n",
      "Epoch [33/300], Step [65/225], Training Accuracy: 81.1058%, Training Loss: 0.4580%\n",
      "Epoch [33/300], Step [66/225], Training Accuracy: 81.2027%, Training Loss: 0.4568%\n",
      "Epoch [33/300], Step [67/225], Training Accuracy: 81.1567%, Training Loss: 0.4568%\n",
      "Epoch [33/300], Step [68/225], Training Accuracy: 81.0892%, Training Loss: 0.4579%\n",
      "Epoch [33/300], Step [69/225], Training Accuracy: 81.1141%, Training Loss: 0.4565%\n",
      "Epoch [33/300], Step [70/225], Training Accuracy: 81.1830%, Training Loss: 0.4555%\n",
      "Epoch [33/300], Step [71/225], Training Accuracy: 81.0519%, Training Loss: 0.4576%\n",
      "Epoch [33/300], Step [72/225], Training Accuracy: 80.9896%, Training Loss: 0.4589%\n",
      "Epoch [33/300], Step [73/225], Training Accuracy: 81.0360%, Training Loss: 0.4581%\n",
      "Epoch [33/300], Step [74/225], Training Accuracy: 81.1655%, Training Loss: 0.4558%\n",
      "Epoch [33/300], Step [75/225], Training Accuracy: 81.1875%, Training Loss: 0.4558%\n",
      "Epoch [33/300], Step [76/225], Training Accuracy: 81.0238%, Training Loss: 0.4590%\n",
      "Epoch [33/300], Step [77/225], Training Accuracy: 80.9456%, Training Loss: 0.4617%\n",
      "Epoch [33/300], Step [78/225], Training Accuracy: 80.9495%, Training Loss: 0.4612%\n",
      "Epoch [33/300], Step [79/225], Training Accuracy: 81.0127%, Training Loss: 0.4597%\n",
      "Epoch [33/300], Step [80/225], Training Accuracy: 81.0352%, Training Loss: 0.4596%\n",
      "Epoch [33/300], Step [81/225], Training Accuracy: 81.0378%, Training Loss: 0.4593%\n",
      "Epoch [33/300], Step [82/225], Training Accuracy: 81.0595%, Training Loss: 0.4589%\n",
      "Epoch [33/300], Step [83/225], Training Accuracy: 81.0617%, Training Loss: 0.4589%\n",
      "Epoch [33/300], Step [84/225], Training Accuracy: 81.1198%, Training Loss: 0.4574%\n",
      "Epoch [33/300], Step [85/225], Training Accuracy: 81.1029%, Training Loss: 0.4565%\n",
      "Epoch [33/300], Step [86/225], Training Accuracy: 81.1228%, Training Loss: 0.4564%\n",
      "Epoch [33/300], Step [87/225], Training Accuracy: 81.1063%, Training Loss: 0.4571%\n",
      "Epoch [33/300], Step [88/225], Training Accuracy: 81.0902%, Training Loss: 0.4584%\n",
      "Epoch [33/300], Step [89/225], Training Accuracy: 81.0920%, Training Loss: 0.4583%\n",
      "Epoch [33/300], Step [90/225], Training Accuracy: 81.1458%, Training Loss: 0.4581%\n",
      "Epoch [33/300], Step [91/225], Training Accuracy: 81.1470%, Training Loss: 0.4586%\n",
      "Epoch [33/300], Step [92/225], Training Accuracy: 81.1651%, Training Loss: 0.4594%\n",
      "Epoch [33/300], Step [93/225], Training Accuracy: 81.1492%, Training Loss: 0.4595%\n",
      "Epoch [33/300], Step [94/225], Training Accuracy: 81.1669%, Training Loss: 0.4603%\n",
      "Epoch [33/300], Step [95/225], Training Accuracy: 81.1184%, Training Loss: 0.4621%\n",
      "Epoch [33/300], Step [96/225], Training Accuracy: 81.1361%, Training Loss: 0.4611%\n",
      "Epoch [33/300], Step [97/225], Training Accuracy: 81.0728%, Training Loss: 0.4618%\n",
      "Epoch [33/300], Step [98/225], Training Accuracy: 81.0906%, Training Loss: 0.4613%\n",
      "Epoch [33/300], Step [99/225], Training Accuracy: 81.0133%, Training Loss: 0.4640%\n",
      "Epoch [33/300], Step [100/225], Training Accuracy: 80.8906%, Training Loss: 0.4666%\n",
      "Epoch [33/300], Step [101/225], Training Accuracy: 80.8942%, Training Loss: 0.4670%\n",
      "Epoch [33/300], Step [102/225], Training Accuracy: 80.8517%, Training Loss: 0.4691%\n",
      "Epoch [33/300], Step [103/225], Training Accuracy: 80.8556%, Training Loss: 0.4688%\n",
      "Epoch [33/300], Step [104/225], Training Accuracy: 80.7392%, Training Loss: 0.4708%\n",
      "Epoch [33/300], Step [105/225], Training Accuracy: 80.7292%, Training Loss: 0.4706%\n",
      "Epoch [33/300], Step [106/225], Training Accuracy: 80.7046%, Training Loss: 0.4717%\n",
      "Epoch [33/300], Step [107/225], Training Accuracy: 80.7827%, Training Loss: 0.4706%\n",
      "Epoch [33/300], Step [108/225], Training Accuracy: 80.7870%, Training Loss: 0.4711%\n",
      "Epoch [33/300], Step [109/225], Training Accuracy: 80.7339%, Training Loss: 0.4723%\n",
      "Epoch [33/300], Step [110/225], Training Accuracy: 80.6960%, Training Loss: 0.4721%\n",
      "Epoch [33/300], Step [111/225], Training Accuracy: 80.6588%, Training Loss: 0.4734%\n",
      "Epoch [33/300], Step [112/225], Training Accuracy: 80.6362%, Training Loss: 0.4735%\n",
      "Epoch [33/300], Step [113/225], Training Accuracy: 80.6001%, Training Loss: 0.4748%\n",
      "Epoch [33/300], Step [114/225], Training Accuracy: 80.6195%, Training Loss: 0.4748%\n",
      "Epoch [33/300], Step [115/225], Training Accuracy: 80.6386%, Training Loss: 0.4742%\n",
      "Epoch [33/300], Step [116/225], Training Accuracy: 80.6169%, Training Loss: 0.4750%\n",
      "Epoch [33/300], Step [117/225], Training Accuracy: 80.5823%, Training Loss: 0.4762%\n",
      "Epoch [33/300], Step [118/225], Training Accuracy: 80.6012%, Training Loss: 0.4764%\n",
      "Epoch [33/300], Step [119/225], Training Accuracy: 80.5672%, Training Loss: 0.4758%\n",
      "Epoch [33/300], Step [120/225], Training Accuracy: 80.5469%, Training Loss: 0.4758%\n",
      "Epoch [33/300], Step [121/225], Training Accuracy: 80.4752%, Training Loss: 0.4772%\n",
      "Epoch [33/300], Step [122/225], Training Accuracy: 80.5200%, Training Loss: 0.4763%\n",
      "Epoch [33/300], Step [123/225], Training Accuracy: 80.5132%, Training Loss: 0.4776%\n",
      "Epoch [33/300], Step [124/225], Training Accuracy: 80.5444%, Training Loss: 0.4773%\n",
      "Epoch [33/300], Step [125/225], Training Accuracy: 80.5625%, Training Loss: 0.4776%\n",
      "Epoch [33/300], Step [126/225], Training Accuracy: 80.4688%, Training Loss: 0.4785%\n",
      "Epoch [33/300], Step [127/225], Training Accuracy: 80.4257%, Training Loss: 0.4805%\n",
      "Epoch [33/300], Step [128/225], Training Accuracy: 80.4077%, Training Loss: 0.4806%\n",
      "Epoch [33/300], Step [129/225], Training Accuracy: 80.4506%, Training Loss: 0.4803%\n",
      "Epoch [33/300], Step [130/225], Training Accuracy: 80.3846%, Training Loss: 0.4810%\n",
      "Epoch [33/300], Step [131/225], Training Accuracy: 80.3316%, Training Loss: 0.4819%\n",
      "Epoch [33/300], Step [132/225], Training Accuracy: 80.3741%, Training Loss: 0.4817%\n",
      "Epoch [33/300], Step [133/225], Training Accuracy: 80.4394%, Training Loss: 0.4804%\n",
      "Epoch [33/300], Step [134/225], Training Accuracy: 80.3988%, Training Loss: 0.4813%\n",
      "Epoch [33/300], Step [135/225], Training Accuracy: 80.3704%, Training Loss: 0.4817%\n",
      "Epoch [33/300], Step [136/225], Training Accuracy: 80.3424%, Training Loss: 0.4820%\n",
      "Epoch [33/300], Step [137/225], Training Accuracy: 80.4174%, Training Loss: 0.4806%\n",
      "Epoch [33/300], Step [138/225], Training Accuracy: 80.4914%, Training Loss: 0.4796%\n",
      "Epoch [33/300], Step [139/225], Training Accuracy: 80.5193%, Training Loss: 0.4793%\n",
      "Epoch [33/300], Step [140/225], Training Accuracy: 80.5469%, Training Loss: 0.4784%\n",
      "Epoch [33/300], Step [141/225], Training Accuracy: 80.5519%, Training Loss: 0.4782%\n",
      "Epoch [33/300], Step [142/225], Training Accuracy: 80.5678%, Training Loss: 0.4771%\n",
      "Epoch [33/300], Step [143/225], Training Accuracy: 80.6163%, Training Loss: 0.4760%\n",
      "Epoch [33/300], Step [144/225], Training Accuracy: 80.6532%, Training Loss: 0.4752%\n",
      "Epoch [33/300], Step [145/225], Training Accuracy: 80.6466%, Training Loss: 0.4752%\n",
      "Epoch [33/300], Step [146/225], Training Accuracy: 80.5758%, Training Loss: 0.4766%\n",
      "Epoch [33/300], Step [147/225], Training Accuracy: 80.5697%, Training Loss: 0.4769%\n",
      "Epoch [33/300], Step [148/225], Training Accuracy: 80.5954%, Training Loss: 0.4761%\n",
      "Epoch [33/300], Step [149/225], Training Accuracy: 80.5893%, Training Loss: 0.4756%\n",
      "Epoch [33/300], Step [150/225], Training Accuracy: 80.5833%, Training Loss: 0.4761%\n",
      "Epoch [33/300], Step [151/225], Training Accuracy: 80.6602%, Training Loss: 0.4755%\n",
      "Epoch [33/300], Step [152/225], Training Accuracy: 80.6435%, Training Loss: 0.4750%\n",
      "Epoch [33/300], Step [153/225], Training Accuracy: 80.5556%, Training Loss: 0.4759%\n",
      "Epoch [33/300], Step [154/225], Training Accuracy: 80.5702%, Training Loss: 0.4755%\n",
      "Epoch [33/300], Step [155/225], Training Accuracy: 80.5645%, Training Loss: 0.4755%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/300], Step [156/225], Training Accuracy: 80.5188%, Training Loss: 0.4770%\n",
      "Epoch [33/300], Step [157/225], Training Accuracy: 80.4837%, Training Loss: 0.4781%\n",
      "Epoch [33/300], Step [158/225], Training Accuracy: 80.4490%, Training Loss: 0.4783%\n",
      "Epoch [33/300], Step [159/225], Training Accuracy: 80.4442%, Training Loss: 0.4784%\n",
      "Epoch [33/300], Step [160/225], Training Accuracy: 80.4492%, Training Loss: 0.4781%\n",
      "Epoch [33/300], Step [161/225], Training Accuracy: 80.4445%, Training Loss: 0.4782%\n",
      "Epoch [33/300], Step [162/225], Training Accuracy: 80.4784%, Training Loss: 0.4775%\n",
      "Epoch [33/300], Step [163/225], Training Accuracy: 80.4544%, Training Loss: 0.4771%\n",
      "Epoch [33/300], Step [164/225], Training Accuracy: 80.4783%, Training Loss: 0.4764%\n",
      "Epoch [33/300], Step [165/225], Training Accuracy: 80.4830%, Training Loss: 0.4761%\n",
      "Epoch [33/300], Step [166/225], Training Accuracy: 80.5064%, Training Loss: 0.4754%\n",
      "Epoch [33/300], Step [167/225], Training Accuracy: 80.5109%, Training Loss: 0.4750%\n",
      "Epoch [33/300], Step [168/225], Training Accuracy: 80.5246%, Training Loss: 0.4747%\n",
      "Epoch [33/300], Step [169/225], Training Accuracy: 80.5658%, Training Loss: 0.4734%\n",
      "Epoch [33/300], Step [170/225], Training Accuracy: 80.6066%, Training Loss: 0.4733%\n",
      "Epoch [33/300], Step [171/225], Training Accuracy: 80.5556%, Training Loss: 0.4736%\n",
      "Epoch [33/300], Step [172/225], Training Accuracy: 80.5596%, Training Loss: 0.4733%\n",
      "Epoch [33/300], Step [173/225], Training Accuracy: 80.5546%, Training Loss: 0.4730%\n",
      "Epoch [33/300], Step [174/225], Training Accuracy: 80.5316%, Training Loss: 0.4729%\n",
      "Epoch [33/300], Step [175/225], Training Accuracy: 80.5536%, Training Loss: 0.4721%\n",
      "Epoch [33/300], Step [176/225], Training Accuracy: 80.4599%, Training Loss: 0.4733%\n",
      "Epoch [33/300], Step [177/225], Training Accuracy: 80.4820%, Training Loss: 0.4727%\n",
      "Epoch [33/300], Step [178/225], Training Accuracy: 80.4863%, Training Loss: 0.4727%\n",
      "Epoch [33/300], Step [179/225], Training Accuracy: 80.4644%, Training Loss: 0.4724%\n",
      "Epoch [33/300], Step [180/225], Training Accuracy: 80.4774%, Training Loss: 0.4722%\n",
      "Epoch [33/300], Step [181/225], Training Accuracy: 80.4126%, Training Loss: 0.4729%\n",
      "Epoch [33/300], Step [182/225], Training Accuracy: 80.4258%, Training Loss: 0.4728%\n",
      "Epoch [33/300], Step [183/225], Training Accuracy: 80.4133%, Training Loss: 0.4727%\n",
      "Epoch [33/300], Step [184/225], Training Accuracy: 80.4518%, Training Loss: 0.4723%\n",
      "Epoch [33/300], Step [185/225], Training Accuracy: 80.4645%, Training Loss: 0.4721%\n",
      "Epoch [33/300], Step [186/225], Training Accuracy: 80.4688%, Training Loss: 0.4717%\n",
      "Epoch [33/300], Step [187/225], Training Accuracy: 80.4896%, Training Loss: 0.4714%\n",
      "Epoch [33/300], Step [188/225], Training Accuracy: 80.4771%, Training Loss: 0.4709%\n",
      "Epoch [33/300], Step [189/225], Training Accuracy: 80.4315%, Training Loss: 0.4713%\n",
      "Epoch [33/300], Step [190/225], Training Accuracy: 80.4605%, Training Loss: 0.4709%\n",
      "Epoch [33/300], Step [191/225], Training Accuracy: 80.4401%, Training Loss: 0.4712%\n",
      "Epoch [33/300], Step [192/225], Training Accuracy: 80.4850%, Training Loss: 0.4705%\n",
      "Epoch [33/300], Step [193/225], Training Accuracy: 80.4647%, Training Loss: 0.4708%\n",
      "Epoch [33/300], Step [194/225], Training Accuracy: 80.4688%, Training Loss: 0.4705%\n",
      "Epoch [33/300], Step [195/225], Training Accuracy: 80.4808%, Training Loss: 0.4697%\n",
      "Epoch [33/300], Step [196/225], Training Accuracy: 80.4608%, Training Loss: 0.4702%\n",
      "Epoch [33/300], Step [197/225], Training Accuracy: 80.4569%, Training Loss: 0.4702%\n",
      "Epoch [33/300], Step [198/225], Training Accuracy: 80.5082%, Training Loss: 0.4692%\n",
      "Epoch [33/300], Step [199/225], Training Accuracy: 80.5433%, Training Loss: 0.4684%\n",
      "Epoch [33/300], Step [200/225], Training Accuracy: 80.5781%, Training Loss: 0.4677%\n",
      "Epoch [33/300], Step [201/225], Training Accuracy: 80.6048%, Training Loss: 0.4671%\n",
      "Epoch [33/300], Step [202/225], Training Accuracy: 80.6312%, Training Loss: 0.4668%\n",
      "Epoch [33/300], Step [203/225], Training Accuracy: 80.6573%, Training Loss: 0.4662%\n",
      "Epoch [33/300], Step [204/225], Training Accuracy: 80.6756%, Training Loss: 0.4659%\n",
      "Epoch [33/300], Step [205/225], Training Accuracy: 80.7165%, Training Loss: 0.4655%\n",
      "Epoch [33/300], Step [206/225], Training Accuracy: 80.7342%, Training Loss: 0.4651%\n",
      "Epoch [33/300], Step [207/225], Training Accuracy: 80.7216%, Training Loss: 0.4649%\n",
      "Epoch [33/300], Step [208/225], Training Accuracy: 80.7166%, Training Loss: 0.4647%\n",
      "Epoch [33/300], Step [209/225], Training Accuracy: 80.7117%, Training Loss: 0.4647%\n",
      "Epoch [33/300], Step [210/225], Training Accuracy: 80.7217%, Training Loss: 0.4651%\n",
      "Epoch [33/300], Step [211/225], Training Accuracy: 80.7242%, Training Loss: 0.4645%\n",
      "Epoch [33/300], Step [212/225], Training Accuracy: 80.7193%, Training Loss: 0.4644%\n",
      "Epoch [33/300], Step [213/225], Training Accuracy: 80.7072%, Training Loss: 0.4645%\n",
      "Epoch [33/300], Step [214/225], Training Accuracy: 80.7170%, Training Loss: 0.4643%\n",
      "Epoch [33/300], Step [215/225], Training Accuracy: 80.7485%, Training Loss: 0.4636%\n",
      "Epoch [33/300], Step [216/225], Training Accuracy: 80.7726%, Training Loss: 0.4633%\n",
      "Epoch [33/300], Step [217/225], Training Accuracy: 80.7820%, Training Loss: 0.4637%\n",
      "Epoch [33/300], Step [218/225], Training Accuracy: 80.7626%, Training Loss: 0.4644%\n",
      "Epoch [33/300], Step [219/225], Training Accuracy: 80.7934%, Training Loss: 0.4638%\n",
      "Epoch [33/300], Step [220/225], Training Accuracy: 80.8239%, Training Loss: 0.4632%\n",
      "Epoch [33/300], Step [221/225], Training Accuracy: 80.8329%, Training Loss: 0.4626%\n",
      "Epoch [33/300], Step [222/225], Training Accuracy: 80.8559%, Training Loss: 0.4618%\n",
      "Epoch [33/300], Step [223/225], Training Accuracy: 80.8366%, Training Loss: 0.4620%\n",
      "Epoch [33/300], Step [224/225], Training Accuracy: 80.8315%, Training Loss: 0.4618%\n",
      "Epoch [33/300], Step [225/225], Training Accuracy: 80.8505%, Training Loss: 0.4613%\n",
      "Epoch [34/300], Step [1/225], Training Accuracy: 87.5000%, Training Loss: 0.3583%\n",
      "Epoch [34/300], Step [2/225], Training Accuracy: 83.5938%, Training Loss: 0.3677%\n",
      "Epoch [34/300], Step [3/225], Training Accuracy: 83.3333%, Training Loss: 0.4134%\n",
      "Epoch [34/300], Step [4/225], Training Accuracy: 82.4219%, Training Loss: 0.4310%\n",
      "Epoch [34/300], Step [5/225], Training Accuracy: 81.8750%, Training Loss: 0.4357%\n",
      "Epoch [34/300], Step [6/225], Training Accuracy: 83.0729%, Training Loss: 0.4217%\n",
      "Epoch [34/300], Step [7/225], Training Accuracy: 82.1429%, Training Loss: 0.4307%\n",
      "Epoch [34/300], Step [8/225], Training Accuracy: 81.8359%, Training Loss: 0.4374%\n",
      "Epoch [34/300], Step [9/225], Training Accuracy: 81.7708%, Training Loss: 0.4386%\n",
      "Epoch [34/300], Step [10/225], Training Accuracy: 81.4062%, Training Loss: 0.4520%\n",
      "Epoch [34/300], Step [11/225], Training Accuracy: 81.3920%, Training Loss: 0.4590%\n",
      "Epoch [34/300], Step [12/225], Training Accuracy: 80.9896%, Training Loss: 0.4714%\n",
      "Epoch [34/300], Step [13/225], Training Accuracy: 81.6106%, Training Loss: 0.4612%\n",
      "Epoch [34/300], Step [14/225], Training Accuracy: 81.8080%, Training Loss: 0.4520%\n",
      "Epoch [34/300], Step [15/225], Training Accuracy: 81.4583%, Training Loss: 0.4649%\n",
      "Epoch [34/300], Step [16/225], Training Accuracy: 80.8594%, Training Loss: 0.4753%\n",
      "Epoch [34/300], Step [17/225], Training Accuracy: 80.7904%, Training Loss: 0.4715%\n",
      "Epoch [34/300], Step [18/225], Training Accuracy: 80.9028%, Training Loss: 0.4702%\n",
      "Epoch [34/300], Step [19/225], Training Accuracy: 81.2500%, Training Loss: 0.4622%\n",
      "Epoch [34/300], Step [20/225], Training Accuracy: 81.2500%, Training Loss: 0.4687%\n",
      "Epoch [34/300], Step [21/225], Training Accuracy: 81.5476%, Training Loss: 0.4573%\n",
      "Epoch [34/300], Step [22/225], Training Accuracy: 81.1080%, Training Loss: 0.4632%\n",
      "Epoch [34/300], Step [23/225], Training Accuracy: 81.1821%, Training Loss: 0.4609%\n",
      "Epoch [34/300], Step [24/225], Training Accuracy: 81.2500%, Training Loss: 0.4619%\n",
      "Epoch [34/300], Step [25/225], Training Accuracy: 81.5625%, Training Loss: 0.4527%\n",
      "Epoch [34/300], Step [26/225], Training Accuracy: 81.4303%, Training Loss: 0.4560%\n",
      "Epoch [34/300], Step [27/225], Training Accuracy: 81.4236%, Training Loss: 0.4549%\n",
      "Epoch [34/300], Step [28/225], Training Accuracy: 81.7522%, Training Loss: 0.4487%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/300], Step [29/225], Training Accuracy: 82.0043%, Training Loss: 0.4432%\n",
      "Epoch [34/300], Step [30/225], Training Accuracy: 81.7708%, Training Loss: 0.4471%\n",
      "Epoch [34/300], Step [31/225], Training Accuracy: 81.6532%, Training Loss: 0.4521%\n",
      "Epoch [34/300], Step [32/225], Training Accuracy: 81.5918%, Training Loss: 0.4535%\n",
      "Epoch [34/300], Step [33/225], Training Accuracy: 81.5814%, Training Loss: 0.4533%\n",
      "Epoch [34/300], Step [34/225], Training Accuracy: 81.2960%, Training Loss: 0.4567%\n",
      "Epoch [34/300], Step [35/225], Training Accuracy: 81.2500%, Training Loss: 0.4597%\n",
      "Epoch [34/300], Step [36/225], Training Accuracy: 81.2066%, Training Loss: 0.4600%\n",
      "Epoch [34/300], Step [37/225], Training Accuracy: 81.2078%, Training Loss: 0.4602%\n",
      "Epoch [34/300], Step [38/225], Training Accuracy: 81.2911%, Training Loss: 0.4586%\n",
      "Epoch [34/300], Step [39/225], Training Accuracy: 81.2500%, Training Loss: 0.4631%\n",
      "Epoch [34/300], Step [40/225], Training Accuracy: 81.2109%, Training Loss: 0.4643%\n",
      "Epoch [34/300], Step [41/225], Training Accuracy: 81.1357%, Training Loss: 0.4660%\n",
      "Epoch [34/300], Step [42/225], Training Accuracy: 81.0268%, Training Loss: 0.4662%\n",
      "Epoch [34/300], Step [43/225], Training Accuracy: 81.0320%, Training Loss: 0.4647%\n",
      "Epoch [34/300], Step [44/225], Training Accuracy: 81.2500%, Training Loss: 0.4610%\n",
      "Epoch [34/300], Step [45/225], Training Accuracy: 81.0764%, Training Loss: 0.4628%\n",
      "Epoch [34/300], Step [46/225], Training Accuracy: 81.2160%, Training Loss: 0.4604%\n",
      "Epoch [34/300], Step [47/225], Training Accuracy: 81.2168%, Training Loss: 0.4606%\n",
      "Epoch [34/300], Step [48/225], Training Accuracy: 81.0221%, Training Loss: 0.4635%\n",
      "Epoch [34/300], Step [49/225], Training Accuracy: 81.0906%, Training Loss: 0.4640%\n",
      "Epoch [34/300], Step [50/225], Training Accuracy: 81.1562%, Training Loss: 0.4616%\n",
      "Epoch [34/300], Step [51/225], Training Accuracy: 81.1887%, Training Loss: 0.4614%\n",
      "Epoch [34/300], Step [52/225], Training Accuracy: 81.3702%, Training Loss: 0.4593%\n",
      "Epoch [34/300], Step [53/225], Training Accuracy: 81.3384%, Training Loss: 0.4602%\n",
      "Epoch [34/300], Step [54/225], Training Accuracy: 81.3947%, Training Loss: 0.4587%\n",
      "Epoch [34/300], Step [55/225], Training Accuracy: 81.1932%, Training Loss: 0.4619%\n",
      "Epoch [34/300], Step [56/225], Training Accuracy: 81.1942%, Training Loss: 0.4615%\n",
      "Epoch [34/300], Step [57/225], Training Accuracy: 81.2500%, Training Loss: 0.4609%\n",
      "Epoch [34/300], Step [58/225], Training Accuracy: 81.3039%, Training Loss: 0.4603%\n",
      "Epoch [34/300], Step [59/225], Training Accuracy: 81.1176%, Training Loss: 0.4634%\n",
      "Epoch [34/300], Step [60/225], Training Accuracy: 81.0938%, Training Loss: 0.4641%\n",
      "Epoch [34/300], Step [61/225], Training Accuracy: 81.0451%, Training Loss: 0.4637%\n",
      "Epoch [34/300], Step [62/225], Training Accuracy: 81.1744%, Training Loss: 0.4613%\n",
      "Epoch [34/300], Step [63/225], Training Accuracy: 81.1508%, Training Loss: 0.4623%\n",
      "Epoch [34/300], Step [64/225], Training Accuracy: 81.1768%, Training Loss: 0.4617%\n",
      "Epoch [34/300], Step [65/225], Training Accuracy: 81.2260%, Training Loss: 0.4621%\n",
      "Epoch [34/300], Step [66/225], Training Accuracy: 81.2973%, Training Loss: 0.4603%\n",
      "Epoch [34/300], Step [67/225], Training Accuracy: 81.2733%, Training Loss: 0.4596%\n",
      "Epoch [34/300], Step [68/225], Training Accuracy: 81.2270%, Training Loss: 0.4600%\n",
      "Epoch [34/300], Step [69/225], Training Accuracy: 81.2047%, Training Loss: 0.4605%\n",
      "Epoch [34/300], Step [70/225], Training Accuracy: 81.3170%, Training Loss: 0.4585%\n",
      "Epoch [34/300], Step [71/225], Training Accuracy: 81.3160%, Training Loss: 0.4591%\n",
      "Epoch [34/300], Step [72/225], Training Accuracy: 81.4019%, Training Loss: 0.4573%\n",
      "Epoch [34/300], Step [73/225], Training Accuracy: 81.3784%, Training Loss: 0.4563%\n",
      "Epoch [34/300], Step [74/225], Training Accuracy: 81.5034%, Training Loss: 0.4534%\n",
      "Epoch [34/300], Step [75/225], Training Accuracy: 81.5417%, Training Loss: 0.4517%\n",
      "Epoch [34/300], Step [76/225], Training Accuracy: 81.5789%, Training Loss: 0.4518%\n",
      "Epoch [34/300], Step [77/225], Training Accuracy: 81.6153%, Training Loss: 0.4516%\n",
      "Epoch [34/300], Step [78/225], Training Accuracy: 81.5705%, Training Loss: 0.4520%\n",
      "Epoch [34/300], Step [79/225], Training Accuracy: 81.6653%, Training Loss: 0.4495%\n",
      "Epoch [34/300], Step [80/225], Training Accuracy: 81.6211%, Training Loss: 0.4494%\n",
      "Epoch [34/300], Step [81/225], Training Accuracy: 81.7130%, Training Loss: 0.4472%\n",
      "Epoch [34/300], Step [82/225], Training Accuracy: 81.7645%, Training Loss: 0.4459%\n",
      "Epoch [34/300], Step [83/225], Training Accuracy: 81.7206%, Training Loss: 0.4463%\n",
      "Epoch [34/300], Step [84/225], Training Accuracy: 81.7708%, Training Loss: 0.4452%\n",
      "Epoch [34/300], Step [85/225], Training Accuracy: 81.7463%, Training Loss: 0.4446%\n",
      "Epoch [34/300], Step [86/225], Training Accuracy: 81.7406%, Training Loss: 0.4438%\n",
      "Epoch [34/300], Step [87/225], Training Accuracy: 81.7708%, Training Loss: 0.4432%\n",
      "Epoch [34/300], Step [88/225], Training Accuracy: 81.8004%, Training Loss: 0.4431%\n",
      "Epoch [34/300], Step [89/225], Training Accuracy: 81.8469%, Training Loss: 0.4425%\n",
      "Epoch [34/300], Step [90/225], Training Accuracy: 81.8576%, Training Loss: 0.4429%\n",
      "Epoch [34/300], Step [91/225], Training Accuracy: 81.8166%, Training Loss: 0.4443%\n",
      "Epoch [34/300], Step [92/225], Training Accuracy: 81.8614%, Training Loss: 0.4454%\n",
      "Epoch [34/300], Step [93/225], Training Accuracy: 81.8884%, Training Loss: 0.4446%\n",
      "Epoch [34/300], Step [94/225], Training Accuracy: 81.9149%, Training Loss: 0.4452%\n",
      "Epoch [34/300], Step [95/225], Training Accuracy: 81.9901%, Training Loss: 0.4443%\n",
      "Epoch [34/300], Step [96/225], Training Accuracy: 81.9987%, Training Loss: 0.4438%\n",
      "Epoch [34/300], Step [97/225], Training Accuracy: 82.0071%, Training Loss: 0.4436%\n",
      "Epoch [34/300], Step [98/225], Training Accuracy: 81.9515%, Training Loss: 0.4441%\n",
      "Epoch [34/300], Step [99/225], Training Accuracy: 81.9444%, Training Loss: 0.4437%\n",
      "Epoch [34/300], Step [100/225], Training Accuracy: 81.8125%, Training Loss: 0.4467%\n",
      "Epoch [34/300], Step [101/225], Training Accuracy: 81.7915%, Training Loss: 0.4477%\n",
      "Epoch [34/300], Step [102/225], Training Accuracy: 81.7096%, Training Loss: 0.4516%\n",
      "Epoch [34/300], Step [103/225], Training Accuracy: 81.7354%, Training Loss: 0.4510%\n",
      "Epoch [34/300], Step [104/225], Training Accuracy: 81.7458%, Training Loss: 0.4510%\n",
      "Epoch [34/300], Step [105/225], Training Accuracy: 81.7560%, Training Loss: 0.4505%\n",
      "Epoch [34/300], Step [106/225], Training Accuracy: 81.7954%, Training Loss: 0.4500%\n",
      "Epoch [34/300], Step [107/225], Training Accuracy: 81.7319%, Training Loss: 0.4512%\n",
      "Epoch [34/300], Step [108/225], Training Accuracy: 81.6985%, Training Loss: 0.4527%\n",
      "Epoch [34/300], Step [109/225], Training Accuracy: 81.7087%, Training Loss: 0.4522%\n",
      "Epoch [34/300], Step [110/225], Training Accuracy: 81.7898%, Training Loss: 0.4509%\n",
      "Epoch [34/300], Step [111/225], Training Accuracy: 81.7568%, Training Loss: 0.4518%\n",
      "Epoch [34/300], Step [112/225], Training Accuracy: 81.7662%, Training Loss: 0.4522%\n",
      "Epoch [34/300], Step [113/225], Training Accuracy: 81.7063%, Training Loss: 0.4546%\n",
      "Epoch [34/300], Step [114/225], Training Accuracy: 81.7160%, Training Loss: 0.4542%\n",
      "Epoch [34/300], Step [115/225], Training Accuracy: 81.7663%, Training Loss: 0.4536%\n",
      "Epoch [34/300], Step [116/225], Training Accuracy: 81.7619%, Training Loss: 0.4532%\n",
      "Epoch [34/300], Step [117/225], Training Accuracy: 81.6506%, Training Loss: 0.4546%\n",
      "Epoch [34/300], Step [118/225], Training Accuracy: 81.6605%, Training Loss: 0.4542%\n",
      "Epoch [34/300], Step [119/225], Training Accuracy: 81.6308%, Training Loss: 0.4552%\n",
      "Epoch [34/300], Step [120/225], Training Accuracy: 81.5234%, Training Loss: 0.4569%\n",
      "Epoch [34/300], Step [121/225], Training Accuracy: 81.5341%, Training Loss: 0.4563%\n",
      "Epoch [34/300], Step [122/225], Training Accuracy: 81.5190%, Training Loss: 0.4576%\n",
      "Epoch [34/300], Step [123/225], Training Accuracy: 81.5168%, Training Loss: 0.4592%\n",
      "Epoch [34/300], Step [124/225], Training Accuracy: 81.5398%, Training Loss: 0.4583%\n",
      "Epoch [34/300], Step [125/225], Training Accuracy: 81.5000%, Training Loss: 0.4596%\n",
      "Epoch [34/300], Step [126/225], Training Accuracy: 81.5104%, Training Loss: 0.4597%\n",
      "Epoch [34/300], Step [127/225], Training Accuracy: 81.4715%, Training Loss: 0.4609%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/300], Step [128/225], Training Accuracy: 81.3721%, Training Loss: 0.4620%\n",
      "Epoch [34/300], Step [129/225], Training Accuracy: 81.3469%, Training Loss: 0.4621%\n",
      "Epoch [34/300], Step [130/225], Training Accuracy: 81.2981%, Training Loss: 0.4625%\n",
      "Epoch [34/300], Step [131/225], Training Accuracy: 81.2739%, Training Loss: 0.4624%\n",
      "Epoch [34/300], Step [132/225], Training Accuracy: 81.2737%, Training Loss: 0.4625%\n",
      "Epoch [34/300], Step [133/225], Training Accuracy: 81.2617%, Training Loss: 0.4633%\n",
      "Epoch [34/300], Step [134/225], Training Accuracy: 81.1217%, Training Loss: 0.4655%\n",
      "Epoch [34/300], Step [135/225], Training Accuracy: 81.0995%, Training Loss: 0.4653%\n",
      "Epoch [34/300], Step [136/225], Training Accuracy: 81.0662%, Training Loss: 0.4660%\n",
      "Epoch [34/300], Step [137/225], Training Accuracy: 81.0561%, Training Loss: 0.4658%\n",
      "Epoch [34/300], Step [138/225], Training Accuracy: 81.1028%, Training Loss: 0.4646%\n",
      "Epoch [34/300], Step [139/225], Training Accuracy: 81.0926%, Training Loss: 0.4651%\n",
      "Epoch [34/300], Step [140/225], Training Accuracy: 81.0938%, Training Loss: 0.4655%\n",
      "Epoch [34/300], Step [141/225], Training Accuracy: 81.1059%, Training Loss: 0.4654%\n",
      "Epoch [34/300], Step [142/225], Training Accuracy: 81.0299%, Training Loss: 0.4668%\n",
      "Epoch [34/300], Step [143/225], Training Accuracy: 81.0533%, Training Loss: 0.4667%\n",
      "Epoch [34/300], Step [144/225], Training Accuracy: 81.0330%, Training Loss: 0.4667%\n",
      "Epoch [34/300], Step [145/225], Training Accuracy: 80.9914%, Training Loss: 0.4674%\n",
      "Epoch [34/300], Step [146/225], Training Accuracy: 80.9503%, Training Loss: 0.4680%\n",
      "Epoch [34/300], Step [147/225], Training Accuracy: 80.8992%, Training Loss: 0.4689%\n",
      "Epoch [34/300], Step [148/225], Training Accuracy: 80.9333%, Training Loss: 0.4679%\n",
      "Epoch [34/300], Step [149/225], Training Accuracy: 80.9354%, Training Loss: 0.4677%\n",
      "Epoch [34/300], Step [150/225], Training Accuracy: 80.9792%, Training Loss: 0.4666%\n",
      "Epoch [34/300], Step [151/225], Training Accuracy: 81.0224%, Training Loss: 0.4654%\n",
      "Epoch [34/300], Step [152/225], Training Accuracy: 80.9827%, Training Loss: 0.4667%\n",
      "Epoch [34/300], Step [153/225], Training Accuracy: 80.9436%, Training Loss: 0.4676%\n",
      "Epoch [34/300], Step [154/225], Training Accuracy: 80.9355%, Training Loss: 0.4683%\n",
      "Epoch [34/300], Step [155/225], Training Accuracy: 80.9274%, Training Loss: 0.4686%\n",
      "Epoch [34/300], Step [156/225], Training Accuracy: 80.8594%, Training Loss: 0.4696%\n",
      "Epoch [34/300], Step [157/225], Training Accuracy: 80.8221%, Training Loss: 0.4705%\n",
      "Epoch [34/300], Step [158/225], Training Accuracy: 80.8248%, Training Loss: 0.4711%\n",
      "Epoch [34/300], Step [159/225], Training Accuracy: 80.8176%, Training Loss: 0.4720%\n",
      "Epoch [34/300], Step [160/225], Training Accuracy: 80.8008%, Training Loss: 0.4721%\n",
      "Epoch [34/300], Step [161/225], Training Accuracy: 80.8036%, Training Loss: 0.4726%\n",
      "Epoch [34/300], Step [162/225], Training Accuracy: 80.7967%, Training Loss: 0.4723%\n",
      "Epoch [34/300], Step [163/225], Training Accuracy: 80.8186%, Training Loss: 0.4722%\n",
      "Epoch [34/300], Step [164/225], Training Accuracy: 80.8308%, Training Loss: 0.4715%\n",
      "Epoch [34/300], Step [165/225], Training Accuracy: 80.8712%, Training Loss: 0.4710%\n",
      "Epoch [34/300], Step [166/225], Training Accuracy: 80.8735%, Training Loss: 0.4714%\n",
      "Epoch [34/300], Step [167/225], Training Accuracy: 80.8945%, Training Loss: 0.4709%\n",
      "Epoch [34/300], Step [168/225], Training Accuracy: 80.9338%, Training Loss: 0.4703%\n",
      "Epoch [34/300], Step [169/225], Training Accuracy: 80.9819%, Training Loss: 0.4697%\n",
      "Epoch [34/300], Step [170/225], Training Accuracy: 80.9926%, Training Loss: 0.4693%\n",
      "Epoch [34/300], Step [171/225], Training Accuracy: 80.9211%, Training Loss: 0.4700%\n",
      "Epoch [34/300], Step [172/225], Training Accuracy: 80.9502%, Training Loss: 0.4696%\n",
      "Epoch [34/300], Step [173/225], Training Accuracy: 80.8436%, Training Loss: 0.4709%\n",
      "Epoch [34/300], Step [174/225], Training Accuracy: 80.8908%, Training Loss: 0.4702%\n",
      "Epoch [34/300], Step [175/225], Training Accuracy: 80.8750%, Training Loss: 0.4702%\n",
      "Epoch [34/300], Step [176/225], Training Accuracy: 80.8505%, Training Loss: 0.4699%\n",
      "Epoch [34/300], Step [177/225], Training Accuracy: 80.8616%, Training Loss: 0.4695%\n",
      "Epoch [34/300], Step [178/225], Training Accuracy: 80.8550%, Training Loss: 0.4692%\n",
      "Epoch [34/300], Step [179/225], Training Accuracy: 80.8747%, Training Loss: 0.4686%\n",
      "Epoch [34/300], Step [180/225], Training Accuracy: 80.8941%, Training Loss: 0.4689%\n",
      "Epoch [34/300], Step [181/225], Training Accuracy: 80.9220%, Training Loss: 0.4686%\n",
      "Epoch [34/300], Step [182/225], Training Accuracy: 80.9066%, Training Loss: 0.4685%\n",
      "Epoch [34/300], Step [183/225], Training Accuracy: 80.8743%, Training Loss: 0.4691%\n",
      "Epoch [34/300], Step [184/225], Training Accuracy: 80.8764%, Training Loss: 0.4687%\n",
      "Epoch [34/300], Step [185/225], Training Accuracy: 80.9122%, Training Loss: 0.4678%\n",
      "Epoch [34/300], Step [186/225], Training Accuracy: 80.9224%, Training Loss: 0.4673%\n",
      "Epoch [34/300], Step [187/225], Training Accuracy: 80.9158%, Training Loss: 0.4673%\n",
      "Epoch [34/300], Step [188/225], Training Accuracy: 80.9009%, Training Loss: 0.4670%\n",
      "Epoch [34/300], Step [189/225], Training Accuracy: 80.9193%, Training Loss: 0.4667%\n",
      "Epoch [34/300], Step [190/225], Training Accuracy: 80.9211%, Training Loss: 0.4664%\n",
      "Epoch [34/300], Step [191/225], Training Accuracy: 80.9228%, Training Loss: 0.4668%\n",
      "Epoch [34/300], Step [192/225], Training Accuracy: 80.9652%, Training Loss: 0.4667%\n",
      "Epoch [34/300], Step [193/225], Training Accuracy: 80.9666%, Training Loss: 0.4665%\n",
      "Epoch [34/300], Step [194/225], Training Accuracy: 80.9439%, Training Loss: 0.4668%\n",
      "Epoch [34/300], Step [195/225], Training Accuracy: 81.0016%, Training Loss: 0.4653%\n",
      "Epoch [34/300], Step [196/225], Training Accuracy: 80.9949%, Training Loss: 0.4655%\n",
      "Epoch [34/300], Step [197/225], Training Accuracy: 81.0041%, Training Loss: 0.4652%\n",
      "Epoch [34/300], Step [198/225], Training Accuracy: 81.0290%, Training Loss: 0.4643%\n",
      "Epoch [34/300], Step [199/225], Training Accuracy: 81.0459%, Training Loss: 0.4638%\n",
      "Epoch [34/300], Step [200/225], Training Accuracy: 81.0391%, Training Loss: 0.4639%\n",
      "Epoch [34/300], Step [201/225], Training Accuracy: 81.0479%, Training Loss: 0.4637%\n",
      "Epoch [34/300], Step [202/225], Training Accuracy: 81.0798%, Training Loss: 0.4630%\n",
      "Epoch [34/300], Step [203/225], Training Accuracy: 81.1115%, Training Loss: 0.4624%\n",
      "Epoch [34/300], Step [204/225], Training Accuracy: 81.1198%, Training Loss: 0.4624%\n",
      "Epoch [34/300], Step [205/225], Training Accuracy: 81.1433%, Training Loss: 0.4620%\n",
      "Epoch [34/300], Step [206/225], Training Accuracy: 81.1362%, Training Loss: 0.4622%\n",
      "Epoch [34/300], Step [207/225], Training Accuracy: 81.1594%, Training Loss: 0.4616%\n",
      "Epoch [34/300], Step [208/225], Training Accuracy: 81.1899%, Training Loss: 0.4611%\n",
      "Epoch [34/300], Step [209/225], Training Accuracy: 81.1603%, Training Loss: 0.4612%\n",
      "Epoch [34/300], Step [210/225], Training Accuracy: 81.1384%, Training Loss: 0.4617%\n",
      "Epoch [34/300], Step [211/225], Training Accuracy: 81.1611%, Training Loss: 0.4611%\n",
      "Epoch [34/300], Step [212/225], Training Accuracy: 81.1468%, Training Loss: 0.4612%\n",
      "Epoch [34/300], Step [213/225], Training Accuracy: 81.1693%, Training Loss: 0.4608%\n",
      "Epoch [34/300], Step [214/225], Training Accuracy: 81.1697%, Training Loss: 0.4602%\n",
      "Epoch [34/300], Step [215/225], Training Accuracy: 81.1483%, Training Loss: 0.4606%\n",
      "Epoch [34/300], Step [216/225], Training Accuracy: 81.1487%, Training Loss: 0.4610%\n",
      "Epoch [34/300], Step [217/225], Training Accuracy: 81.1132%, Training Loss: 0.4611%\n",
      "Epoch [34/300], Step [218/225], Training Accuracy: 81.1138%, Training Loss: 0.4613%\n",
      "Epoch [34/300], Step [219/225], Training Accuracy: 81.1358%, Training Loss: 0.4607%\n",
      "Epoch [34/300], Step [220/225], Training Accuracy: 81.1293%, Training Loss: 0.4607%\n",
      "Epoch [34/300], Step [221/225], Training Accuracy: 81.1510%, Training Loss: 0.4599%\n",
      "Epoch [34/300], Step [222/225], Training Accuracy: 81.1867%, Training Loss: 0.4598%\n",
      "Epoch [34/300], Step [223/225], Training Accuracy: 81.1729%, Training Loss: 0.4601%\n",
      "Epoch [34/300], Step [224/225], Training Accuracy: 81.1872%, Training Loss: 0.4593%\n",
      "Epoch [34/300], Step [225/225], Training Accuracy: 81.2048%, Training Loss: 0.4593%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/300], Step [1/225], Training Accuracy: 84.3750%, Training Loss: 0.4041%\n",
      "Epoch [35/300], Step [2/225], Training Accuracy: 83.5938%, Training Loss: 0.4310%\n",
      "Epoch [35/300], Step [3/225], Training Accuracy: 82.2917%, Training Loss: 0.4125%\n",
      "Epoch [35/300], Step [4/225], Training Accuracy: 83.2031%, Training Loss: 0.4070%\n",
      "Epoch [35/300], Step [5/225], Training Accuracy: 83.1250%, Training Loss: 0.4233%\n",
      "Epoch [35/300], Step [6/225], Training Accuracy: 84.3750%, Training Loss: 0.4066%\n",
      "Epoch [35/300], Step [7/225], Training Accuracy: 84.1518%, Training Loss: 0.4120%\n",
      "Epoch [35/300], Step [8/225], Training Accuracy: 82.6172%, Training Loss: 0.4301%\n",
      "Epoch [35/300], Step [9/225], Training Accuracy: 82.6389%, Training Loss: 0.4366%\n",
      "Epoch [35/300], Step [10/225], Training Accuracy: 81.8750%, Training Loss: 0.4542%\n",
      "Epoch [35/300], Step [11/225], Training Accuracy: 81.6761%, Training Loss: 0.4561%\n",
      "Epoch [35/300], Step [12/225], Training Accuracy: 81.5104%, Training Loss: 0.4525%\n",
      "Epoch [35/300], Step [13/225], Training Accuracy: 81.8510%, Training Loss: 0.4402%\n",
      "Epoch [35/300], Step [14/225], Training Accuracy: 82.4777%, Training Loss: 0.4271%\n",
      "Epoch [35/300], Step [15/225], Training Accuracy: 82.2917%, Training Loss: 0.4255%\n",
      "Epoch [35/300], Step [16/225], Training Accuracy: 82.1289%, Training Loss: 0.4240%\n",
      "Epoch [35/300], Step [17/225], Training Accuracy: 82.3529%, Training Loss: 0.4219%\n",
      "Epoch [35/300], Step [18/225], Training Accuracy: 82.0312%, Training Loss: 0.4278%\n",
      "Epoch [35/300], Step [19/225], Training Accuracy: 82.4013%, Training Loss: 0.4216%\n",
      "Epoch [35/300], Step [20/225], Training Accuracy: 82.5781%, Training Loss: 0.4196%\n",
      "Epoch [35/300], Step [21/225], Training Accuracy: 82.8125%, Training Loss: 0.4109%\n",
      "Epoch [35/300], Step [22/225], Training Accuracy: 82.3864%, Training Loss: 0.4172%\n",
      "Epoch [35/300], Step [23/225], Training Accuracy: 82.4728%, Training Loss: 0.4212%\n",
      "Epoch [35/300], Step [24/225], Training Accuracy: 82.2917%, Training Loss: 0.4259%\n",
      "Epoch [35/300], Step [25/225], Training Accuracy: 82.6875%, Training Loss: 0.4221%\n",
      "Epoch [35/300], Step [26/225], Training Accuracy: 82.6923%, Training Loss: 0.4211%\n",
      "Epoch [35/300], Step [27/225], Training Accuracy: 82.5231%, Training Loss: 0.4214%\n",
      "Epoch [35/300], Step [28/225], Training Accuracy: 82.7009%, Training Loss: 0.4158%\n",
      "Epoch [35/300], Step [29/225], Training Accuracy: 82.9203%, Training Loss: 0.4121%\n",
      "Epoch [35/300], Step [30/225], Training Accuracy: 82.8125%, Training Loss: 0.4132%\n",
      "Epoch [35/300], Step [31/225], Training Accuracy: 82.6613%, Training Loss: 0.4168%\n",
      "Epoch [35/300], Step [32/225], Training Accuracy: 83.0566%, Training Loss: 0.4127%\n",
      "Epoch [35/300], Step [33/225], Training Accuracy: 83.1439%, Training Loss: 0.4121%\n",
      "Epoch [35/300], Step [34/225], Training Accuracy: 83.0882%, Training Loss: 0.4196%\n",
      "Epoch [35/300], Step [35/225], Training Accuracy: 83.1696%, Training Loss: 0.4159%\n",
      "Epoch [35/300], Step [36/225], Training Accuracy: 83.2465%, Training Loss: 0.4137%\n",
      "Epoch [35/300], Step [37/225], Training Accuracy: 83.4882%, Training Loss: 0.4101%\n",
      "Epoch [35/300], Step [38/225], Training Accuracy: 83.5938%, Training Loss: 0.4089%\n",
      "Epoch [35/300], Step [39/225], Training Accuracy: 83.4135%, Training Loss: 0.4113%\n",
      "Epoch [35/300], Step [40/225], Training Accuracy: 83.3984%, Training Loss: 0.4151%\n",
      "Epoch [35/300], Step [41/225], Training Accuracy: 83.1555%, Training Loss: 0.4190%\n",
      "Epoch [35/300], Step [42/225], Training Accuracy: 82.9985%, Training Loss: 0.4191%\n",
      "Epoch [35/300], Step [43/225], Training Accuracy: 83.1759%, Training Loss: 0.4145%\n",
      "Epoch [35/300], Step [44/225], Training Accuracy: 83.3452%, Training Loss: 0.4116%\n",
      "Epoch [35/300], Step [45/225], Training Accuracy: 83.0903%, Training Loss: 0.4177%\n",
      "Epoch [35/300], Step [46/225], Training Accuracy: 83.0842%, Training Loss: 0.4207%\n",
      "Epoch [35/300], Step [47/225], Training Accuracy: 82.8790%, Training Loss: 0.4223%\n",
      "Epoch [35/300], Step [48/225], Training Accuracy: 82.7474%, Training Loss: 0.4263%\n",
      "Epoch [35/300], Step [49/225], Training Accuracy: 82.7806%, Training Loss: 0.4260%\n",
      "Epoch [35/300], Step [50/225], Training Accuracy: 82.7812%, Training Loss: 0.4258%\n",
      "Epoch [35/300], Step [51/225], Training Accuracy: 82.9350%, Training Loss: 0.4229%\n",
      "Epoch [35/300], Step [52/225], Training Accuracy: 82.9928%, Training Loss: 0.4206%\n",
      "Epoch [35/300], Step [53/225], Training Accuracy: 83.0189%, Training Loss: 0.4189%\n",
      "Epoch [35/300], Step [54/225], Training Accuracy: 82.8704%, Training Loss: 0.4212%\n",
      "Epoch [35/300], Step [55/225], Training Accuracy: 82.7273%, Training Loss: 0.4252%\n",
      "Epoch [35/300], Step [56/225], Training Accuracy: 82.8404%, Training Loss: 0.4225%\n",
      "Epoch [35/300], Step [57/225], Training Accuracy: 82.8947%, Training Loss: 0.4213%\n",
      "Epoch [35/300], Step [58/225], Training Accuracy: 82.7856%, Training Loss: 0.4226%\n",
      "Epoch [35/300], Step [59/225], Training Accuracy: 82.7066%, Training Loss: 0.4242%\n",
      "Epoch [35/300], Step [60/225], Training Accuracy: 82.7083%, Training Loss: 0.4243%\n",
      "Epoch [35/300], Step [61/225], Training Accuracy: 82.6588%, Training Loss: 0.4248%\n",
      "Epoch [35/300], Step [62/225], Training Accuracy: 82.8629%, Training Loss: 0.4216%\n",
      "Epoch [35/300], Step [63/225], Training Accuracy: 82.9613%, Training Loss: 0.4205%\n",
      "Epoch [35/300], Step [64/225], Training Accuracy: 82.8613%, Training Loss: 0.4236%\n",
      "Epoch [35/300], Step [65/225], Training Accuracy: 82.9808%, Training Loss: 0.4221%\n",
      "Epoch [35/300], Step [66/225], Training Accuracy: 83.0492%, Training Loss: 0.4210%\n",
      "Epoch [35/300], Step [67/225], Training Accuracy: 83.0224%, Training Loss: 0.4210%\n",
      "Epoch [35/300], Step [68/225], Training Accuracy: 82.9044%, Training Loss: 0.4241%\n",
      "Epoch [35/300], Step [69/225], Training Accuracy: 82.8804%, Training Loss: 0.4260%\n",
      "Epoch [35/300], Step [70/225], Training Accuracy: 82.8571%, Training Loss: 0.4266%\n",
      "Epoch [35/300], Step [71/225], Training Accuracy: 82.7905%, Training Loss: 0.4277%\n",
      "Epoch [35/300], Step [72/225], Training Accuracy: 82.6823%, Training Loss: 0.4300%\n",
      "Epoch [35/300], Step [73/225], Training Accuracy: 82.7269%, Training Loss: 0.4289%\n",
      "Epoch [35/300], Step [74/225], Training Accuracy: 82.8125%, Training Loss: 0.4271%\n",
      "Epoch [35/300], Step [75/225], Training Accuracy: 82.7708%, Training Loss: 0.4268%\n",
      "Epoch [35/300], Step [76/225], Training Accuracy: 82.8331%, Training Loss: 0.4263%\n",
      "Epoch [35/300], Step [77/225], Training Accuracy: 82.7719%, Training Loss: 0.4278%\n",
      "Epoch [35/300], Step [78/225], Training Accuracy: 82.7123%, Training Loss: 0.4292%\n",
      "Epoch [35/300], Step [79/225], Training Accuracy: 82.7729%, Training Loss: 0.4274%\n",
      "Epoch [35/300], Step [80/225], Training Accuracy: 82.8320%, Training Loss: 0.4267%\n",
      "Epoch [35/300], Step [81/225], Training Accuracy: 82.8704%, Training Loss: 0.4261%\n",
      "Epoch [35/300], Step [82/225], Training Accuracy: 82.8697%, Training Loss: 0.4252%\n",
      "Epoch [35/300], Step [83/225], Training Accuracy: 82.8313%, Training Loss: 0.4256%\n",
      "Epoch [35/300], Step [84/225], Training Accuracy: 82.9055%, Training Loss: 0.4238%\n",
      "Epoch [35/300], Step [85/225], Training Accuracy: 82.9044%, Training Loss: 0.4246%\n",
      "Epoch [35/300], Step [86/225], Training Accuracy: 82.9033%, Training Loss: 0.4238%\n",
      "Epoch [35/300], Step [87/225], Training Accuracy: 82.8484%, Training Loss: 0.4257%\n",
      "Epoch [35/300], Step [88/225], Training Accuracy: 82.8125%, Training Loss: 0.4265%\n",
      "Epoch [35/300], Step [89/225], Training Accuracy: 82.7423%, Training Loss: 0.4262%\n",
      "Epoch [35/300], Step [90/225], Training Accuracy: 82.6736%, Training Loss: 0.4271%\n",
      "Epoch [35/300], Step [91/225], Training Accuracy: 82.6580%, Training Loss: 0.4280%\n",
      "Epoch [35/300], Step [92/225], Training Accuracy: 82.6596%, Training Loss: 0.4295%\n",
      "Epoch [35/300], Step [93/225], Training Accuracy: 82.6949%, Training Loss: 0.4280%\n",
      "Epoch [35/300], Step [94/225], Training Accuracy: 82.6629%, Training Loss: 0.4279%\n",
      "Epoch [35/300], Step [95/225], Training Accuracy: 82.6809%, Training Loss: 0.4275%\n",
      "Epoch [35/300], Step [96/225], Training Accuracy: 82.6823%, Training Loss: 0.4271%\n",
      "Epoch [35/300], Step [97/225], Training Accuracy: 82.6997%, Training Loss: 0.4268%\n",
      "Epoch [35/300], Step [98/225], Training Accuracy: 82.6690%, Training Loss: 0.4267%\n",
      "Epoch [35/300], Step [99/225], Training Accuracy: 82.6547%, Training Loss: 0.4262%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/300], Step [100/225], Training Accuracy: 82.5469%, Training Loss: 0.4283%\n",
      "Epoch [35/300], Step [101/225], Training Accuracy: 82.4876%, Training Loss: 0.4286%\n",
      "Epoch [35/300], Step [102/225], Training Accuracy: 82.4755%, Training Loss: 0.4284%\n",
      "Epoch [35/300], Step [103/225], Training Accuracy: 82.4636%, Training Loss: 0.4289%\n",
      "Epoch [35/300], Step [104/225], Training Accuracy: 82.4669%, Training Loss: 0.4289%\n",
      "Epoch [35/300], Step [105/225], Training Accuracy: 82.5446%, Training Loss: 0.4273%\n",
      "Epoch [35/300], Step [106/225], Training Accuracy: 82.5619%, Training Loss: 0.4273%\n",
      "Epoch [35/300], Step [107/225], Training Accuracy: 82.6373%, Training Loss: 0.4264%\n",
      "Epoch [35/300], Step [108/225], Training Accuracy: 82.5810%, Training Loss: 0.4271%\n",
      "Epoch [35/300], Step [109/225], Training Accuracy: 82.5258%, Training Loss: 0.4281%\n",
      "Epoch [35/300], Step [110/225], Training Accuracy: 82.5994%, Training Loss: 0.4270%\n",
      "Epoch [35/300], Step [111/225], Training Accuracy: 82.5310%, Training Loss: 0.4289%\n",
      "Epoch [35/300], Step [112/225], Training Accuracy: 82.4916%, Training Loss: 0.4288%\n",
      "Epoch [35/300], Step [113/225], Training Accuracy: 82.4392%, Training Loss: 0.4301%\n",
      "Epoch [35/300], Step [114/225], Training Accuracy: 82.5247%, Training Loss: 0.4290%\n",
      "Epoch [35/300], Step [115/225], Training Accuracy: 82.5136%, Training Loss: 0.4299%\n",
      "Epoch [35/300], Step [116/225], Training Accuracy: 82.3949%, Training Loss: 0.4329%\n",
      "Epoch [35/300], Step [117/225], Training Accuracy: 82.3718%, Training Loss: 0.4334%\n",
      "Epoch [35/300], Step [118/225], Training Accuracy: 82.3490%, Training Loss: 0.4334%\n",
      "Epoch [35/300], Step [119/225], Training Accuracy: 82.3661%, Training Loss: 0.4329%\n",
      "Epoch [35/300], Step [120/225], Training Accuracy: 82.3568%, Training Loss: 0.4328%\n",
      "Epoch [35/300], Step [121/225], Training Accuracy: 82.2960%, Training Loss: 0.4333%\n",
      "Epoch [35/300], Step [122/225], Training Accuracy: 82.2618%, Training Loss: 0.4342%\n",
      "Epoch [35/300], Step [123/225], Training Accuracy: 82.2536%, Training Loss: 0.4348%\n",
      "Epoch [35/300], Step [124/225], Training Accuracy: 82.2959%, Training Loss: 0.4344%\n",
      "Epoch [35/300], Step [125/225], Training Accuracy: 82.2750%, Training Loss: 0.4342%\n",
      "Epoch [35/300], Step [126/225], Training Accuracy: 82.2421%, Training Loss: 0.4349%\n",
      "Epoch [35/300], Step [127/225], Training Accuracy: 82.2219%, Training Loss: 0.4348%\n",
      "Epoch [35/300], Step [128/225], Training Accuracy: 82.2510%, Training Loss: 0.4341%\n",
      "Epoch [35/300], Step [129/225], Training Accuracy: 82.1827%, Training Loss: 0.4352%\n",
      "Epoch [35/300], Step [130/225], Training Accuracy: 82.1154%, Training Loss: 0.4359%\n",
      "Epoch [35/300], Step [131/225], Training Accuracy: 82.0730%, Training Loss: 0.4368%\n",
      "Epoch [35/300], Step [132/225], Training Accuracy: 82.1141%, Training Loss: 0.4365%\n",
      "Epoch [35/300], Step [133/225], Training Accuracy: 82.0606%, Training Loss: 0.4371%\n",
      "Epoch [35/300], Step [134/225], Training Accuracy: 82.0546%, Training Loss: 0.4372%\n",
      "Epoch [35/300], Step [135/225], Training Accuracy: 82.0718%, Training Loss: 0.4369%\n",
      "Epoch [35/300], Step [136/225], Training Accuracy: 82.0887%, Training Loss: 0.4368%\n",
      "Epoch [35/300], Step [137/225], Training Accuracy: 82.0484%, Training Loss: 0.4380%\n",
      "Epoch [35/300], Step [138/225], Training Accuracy: 82.0765%, Training Loss: 0.4372%\n",
      "Epoch [35/300], Step [139/225], Training Accuracy: 82.0931%, Training Loss: 0.4378%\n",
      "Epoch [35/300], Step [140/225], Training Accuracy: 82.1094%, Training Loss: 0.4376%\n",
      "Epoch [35/300], Step [141/225], Training Accuracy: 82.0590%, Training Loss: 0.4383%\n",
      "Epoch [35/300], Step [142/225], Training Accuracy: 82.0423%, Training Loss: 0.4384%\n",
      "Epoch [35/300], Step [143/225], Training Accuracy: 82.0258%, Training Loss: 0.4386%\n",
      "Epoch [35/300], Step [144/225], Training Accuracy: 82.0095%, Training Loss: 0.4395%\n",
      "Epoch [35/300], Step [145/225], Training Accuracy: 81.9935%, Training Loss: 0.4397%\n",
      "Epoch [35/300], Step [146/225], Training Accuracy: 82.0098%, Training Loss: 0.4392%\n",
      "Epoch [35/300], Step [147/225], Training Accuracy: 82.0578%, Training Loss: 0.4383%\n",
      "Epoch [35/300], Step [148/225], Training Accuracy: 82.0735%, Training Loss: 0.4380%\n",
      "Epoch [35/300], Step [149/225], Training Accuracy: 82.0470%, Training Loss: 0.4384%\n",
      "Epoch [35/300], Step [150/225], Training Accuracy: 82.0521%, Training Loss: 0.4384%\n",
      "Epoch [35/300], Step [151/225], Training Accuracy: 82.0882%, Training Loss: 0.4377%\n",
      "Epoch [35/300], Step [152/225], Training Accuracy: 82.1135%, Training Loss: 0.4371%\n",
      "Epoch [35/300], Step [153/225], Training Accuracy: 82.1078%, Training Loss: 0.4381%\n",
      "Epoch [35/300], Step [154/225], Training Accuracy: 82.1530%, Training Loss: 0.4376%\n",
      "Epoch [35/300], Step [155/225], Training Accuracy: 82.1573%, Training Loss: 0.4377%\n",
      "Epoch [35/300], Step [156/225], Training Accuracy: 82.1414%, Training Loss: 0.4381%\n",
      "Epoch [35/300], Step [157/225], Training Accuracy: 82.1557%, Training Loss: 0.4379%\n",
      "Epoch [35/300], Step [158/225], Training Accuracy: 82.1400%, Training Loss: 0.4384%\n",
      "Epoch [35/300], Step [159/225], Training Accuracy: 82.1639%, Training Loss: 0.4382%\n",
      "Epoch [35/300], Step [160/225], Training Accuracy: 82.1582%, Training Loss: 0.4390%\n",
      "Epoch [35/300], Step [161/225], Training Accuracy: 82.1332%, Training Loss: 0.4396%\n",
      "Epoch [35/300], Step [162/225], Training Accuracy: 82.1663%, Training Loss: 0.4391%\n",
      "Epoch [35/300], Step [163/225], Training Accuracy: 82.2086%, Training Loss: 0.4384%\n",
      "Epoch [35/300], Step [164/225], Training Accuracy: 82.2027%, Training Loss: 0.4381%\n",
      "Epoch [35/300], Step [165/225], Training Accuracy: 82.1875%, Training Loss: 0.4389%\n",
      "Epoch [35/300], Step [166/225], Training Accuracy: 82.1724%, Training Loss: 0.4393%\n",
      "Epoch [35/300], Step [167/225], Training Accuracy: 82.1669%, Training Loss: 0.4390%\n",
      "Epoch [35/300], Step [168/225], Training Accuracy: 82.1801%, Training Loss: 0.4385%\n",
      "Epoch [35/300], Step [169/225], Training Accuracy: 82.1746%, Training Loss: 0.4389%\n",
      "Epoch [35/300], Step [170/225], Training Accuracy: 82.2059%, Training Loss: 0.4388%\n",
      "Epoch [35/300], Step [171/225], Training Accuracy: 82.2094%, Training Loss: 0.4387%\n",
      "Epoch [35/300], Step [172/225], Training Accuracy: 82.1948%, Training Loss: 0.4384%\n",
      "Epoch [35/300], Step [173/225], Training Accuracy: 82.1351%, Training Loss: 0.4391%\n",
      "Epoch [35/300], Step [174/225], Training Accuracy: 82.2108%, Training Loss: 0.4379%\n",
      "Epoch [35/300], Step [175/225], Training Accuracy: 82.1875%, Training Loss: 0.4381%\n",
      "Epoch [35/300], Step [176/225], Training Accuracy: 82.1911%, Training Loss: 0.4380%\n",
      "Epoch [35/300], Step [177/225], Training Accuracy: 82.1769%, Training Loss: 0.4380%\n",
      "Epoch [35/300], Step [178/225], Training Accuracy: 82.1893%, Training Loss: 0.4379%\n",
      "Epoch [35/300], Step [179/225], Training Accuracy: 82.2538%, Training Loss: 0.4368%\n",
      "Epoch [35/300], Step [180/225], Training Accuracy: 82.2743%, Training Loss: 0.4365%\n",
      "Epoch [35/300], Step [181/225], Training Accuracy: 82.2169%, Training Loss: 0.4370%\n",
      "Epoch [35/300], Step [182/225], Training Accuracy: 82.2201%, Training Loss: 0.4371%\n",
      "Epoch [35/300], Step [183/225], Training Accuracy: 82.1977%, Training Loss: 0.4372%\n",
      "Epoch [35/300], Step [184/225], Training Accuracy: 82.2011%, Training Loss: 0.4379%\n",
      "Epoch [35/300], Step [185/225], Training Accuracy: 82.1959%, Training Loss: 0.4379%\n",
      "Epoch [35/300], Step [186/225], Training Accuracy: 82.2413%, Training Loss: 0.4368%\n",
      "Epoch [35/300], Step [187/225], Training Accuracy: 82.2443%, Training Loss: 0.4369%\n",
      "Epoch [35/300], Step [188/225], Training Accuracy: 82.2557%, Training Loss: 0.4368%\n",
      "Epoch [35/300], Step [189/225], Training Accuracy: 82.2917%, Training Loss: 0.4362%\n",
      "Epoch [35/300], Step [190/225], Training Accuracy: 82.2615%, Training Loss: 0.4363%\n",
      "Epoch [35/300], Step [191/225], Training Accuracy: 82.2235%, Training Loss: 0.4367%\n",
      "Epoch [35/300], Step [192/225], Training Accuracy: 82.2510%, Training Loss: 0.4364%\n",
      "Epoch [35/300], Step [193/225], Training Accuracy: 82.2215%, Training Loss: 0.4371%\n",
      "Epoch [35/300], Step [194/225], Training Accuracy: 82.2165%, Training Loss: 0.4371%\n",
      "Epoch [35/300], Step [195/225], Training Accuracy: 82.2516%, Training Loss: 0.4367%\n",
      "Epoch [35/300], Step [196/225], Training Accuracy: 82.2465%, Training Loss: 0.4367%\n",
      "Epoch [35/300], Step [197/225], Training Accuracy: 82.2335%, Training Loss: 0.4365%\n",
      "Epoch [35/300], Step [198/225], Training Accuracy: 82.2680%, Training Loss: 0.4357%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/300], Step [199/225], Training Accuracy: 82.2550%, Training Loss: 0.4354%\n",
      "Epoch [35/300], Step [200/225], Training Accuracy: 82.2422%, Training Loss: 0.4360%\n",
      "Epoch [35/300], Step [201/225], Training Accuracy: 82.2761%, Training Loss: 0.4355%\n",
      "Epoch [35/300], Step [202/225], Training Accuracy: 82.2710%, Training Loss: 0.4352%\n",
      "Epoch [35/300], Step [203/225], Training Accuracy: 82.2968%, Training Loss: 0.4349%\n",
      "Epoch [35/300], Step [204/225], Training Accuracy: 82.2763%, Training Loss: 0.4351%\n",
      "Epoch [35/300], Step [205/225], Training Accuracy: 82.3171%, Training Loss: 0.4344%\n",
      "Epoch [35/300], Step [206/225], Training Accuracy: 82.3498%, Training Loss: 0.4336%\n",
      "Epoch [35/300], Step [207/225], Training Accuracy: 82.3143%, Training Loss: 0.4347%\n",
      "Epoch [35/300], Step [208/225], Training Accuracy: 82.3092%, Training Loss: 0.4347%\n",
      "Epoch [35/300], Step [209/225], Training Accuracy: 82.2667%, Training Loss: 0.4356%\n",
      "Epoch [35/300], Step [210/225], Training Accuracy: 82.2693%, Training Loss: 0.4353%\n",
      "Epoch [35/300], Step [211/225], Training Accuracy: 82.2645%, Training Loss: 0.4355%\n",
      "Epoch [35/300], Step [212/225], Training Accuracy: 82.2376%, Training Loss: 0.4360%\n",
      "Epoch [35/300], Step [213/225], Training Accuracy: 82.2550%, Training Loss: 0.4357%\n",
      "Epoch [35/300], Step [214/225], Training Accuracy: 82.2503%, Training Loss: 0.4361%\n",
      "Epoch [35/300], Step [215/225], Training Accuracy: 82.2238%, Training Loss: 0.4365%\n",
      "Epoch [35/300], Step [216/225], Training Accuracy: 82.2193%, Training Loss: 0.4366%\n",
      "Epoch [35/300], Step [217/225], Training Accuracy: 82.2293%, Training Loss: 0.4363%\n",
      "Epoch [35/300], Step [218/225], Training Accuracy: 82.2033%, Training Loss: 0.4369%\n",
      "Epoch [35/300], Step [219/225], Training Accuracy: 82.2203%, Training Loss: 0.4365%\n",
      "Epoch [35/300], Step [220/225], Training Accuracy: 82.2230%, Training Loss: 0.4364%\n",
      "Epoch [35/300], Step [221/225], Training Accuracy: 82.2257%, Training Loss: 0.4372%\n",
      "Epoch [35/300], Step [222/225], Training Accuracy: 82.2142%, Training Loss: 0.4374%\n",
      "Epoch [35/300], Step [223/225], Training Accuracy: 82.2169%, Training Loss: 0.4374%\n",
      "Epoch [35/300], Step [224/225], Training Accuracy: 82.2405%, Training Loss: 0.4371%\n",
      "Epoch [35/300], Step [225/225], Training Accuracy: 82.2679%, Training Loss: 0.4365%\n",
      "Epoch [36/300], Step [1/225], Training Accuracy: 78.1250%, Training Loss: 0.4902%\n",
      "Epoch [36/300], Step [2/225], Training Accuracy: 78.1250%, Training Loss: 0.5036%\n",
      "Epoch [36/300], Step [3/225], Training Accuracy: 77.6042%, Training Loss: 0.4924%\n",
      "Epoch [36/300], Step [4/225], Training Accuracy: 77.3438%, Training Loss: 0.5150%\n",
      "Epoch [36/300], Step [5/225], Training Accuracy: 76.2500%, Training Loss: 0.5743%\n",
      "Epoch [36/300], Step [6/225], Training Accuracy: 77.0833%, Training Loss: 0.5822%\n",
      "Epoch [36/300], Step [7/225], Training Accuracy: 78.3482%, Training Loss: 0.5445%\n",
      "Epoch [36/300], Step [8/225], Training Accuracy: 78.7109%, Training Loss: 0.5370%\n",
      "Epoch [36/300], Step [9/225], Training Accuracy: 78.8194%, Training Loss: 0.5357%\n",
      "Epoch [36/300], Step [10/225], Training Accuracy: 79.2188%, Training Loss: 0.5229%\n",
      "Epoch [36/300], Step [11/225], Training Accuracy: 79.2614%, Training Loss: 0.5114%\n",
      "Epoch [36/300], Step [12/225], Training Accuracy: 78.9062%, Training Loss: 0.5110%\n",
      "Epoch [36/300], Step [13/225], Training Accuracy: 79.3269%, Training Loss: 0.4961%\n",
      "Epoch [36/300], Step [14/225], Training Accuracy: 79.3527%, Training Loss: 0.4878%\n",
      "Epoch [36/300], Step [15/225], Training Accuracy: 79.4792%, Training Loss: 0.4920%\n",
      "Epoch [36/300], Step [16/225], Training Accuracy: 79.2969%, Training Loss: 0.4864%\n",
      "Epoch [36/300], Step [17/225], Training Accuracy: 79.0441%, Training Loss: 0.5015%\n",
      "Epoch [36/300], Step [18/225], Training Accuracy: 78.9931%, Training Loss: 0.4982%\n",
      "Epoch [36/300], Step [19/225], Training Accuracy: 79.5230%, Training Loss: 0.4904%\n",
      "Epoch [36/300], Step [20/225], Training Accuracy: 79.8438%, Training Loss: 0.4816%\n",
      "Epoch [36/300], Step [21/225], Training Accuracy: 80.0595%, Training Loss: 0.4739%\n",
      "Epoch [36/300], Step [22/225], Training Accuracy: 79.5455%, Training Loss: 0.4802%\n",
      "Epoch [36/300], Step [23/225], Training Accuracy: 79.7554%, Training Loss: 0.4809%\n",
      "Epoch [36/300], Step [24/225], Training Accuracy: 79.6875%, Training Loss: 0.4841%\n",
      "Epoch [36/300], Step [25/225], Training Accuracy: 79.6875%, Training Loss: 0.4813%\n",
      "Epoch [36/300], Step [26/225], Training Accuracy: 79.9279%, Training Loss: 0.4777%\n",
      "Epoch [36/300], Step [27/225], Training Accuracy: 80.2662%, Training Loss: 0.4708%\n",
      "Epoch [36/300], Step [28/225], Training Accuracy: 80.4129%, Training Loss: 0.4651%\n",
      "Epoch [36/300], Step [29/225], Training Accuracy: 80.6034%, Training Loss: 0.4597%\n",
      "Epoch [36/300], Step [30/225], Training Accuracy: 80.8333%, Training Loss: 0.4561%\n",
      "Epoch [36/300], Step [31/225], Training Accuracy: 81.1492%, Training Loss: 0.4527%\n",
      "Epoch [36/300], Step [32/225], Training Accuracy: 81.2012%, Training Loss: 0.4528%\n",
      "Epoch [36/300], Step [33/225], Training Accuracy: 81.1553%, Training Loss: 0.4528%\n",
      "Epoch [36/300], Step [34/225], Training Accuracy: 81.2960%, Training Loss: 0.4501%\n",
      "Epoch [36/300], Step [35/225], Training Accuracy: 81.5179%, Training Loss: 0.4447%\n",
      "Epoch [36/300], Step [36/225], Training Accuracy: 81.5104%, Training Loss: 0.4443%\n",
      "Epoch [36/300], Step [37/225], Training Accuracy: 81.7145%, Training Loss: 0.4404%\n",
      "Epoch [36/300], Step [38/225], Training Accuracy: 81.8257%, Training Loss: 0.4360%\n",
      "Epoch [36/300], Step [39/225], Training Accuracy: 81.7708%, Training Loss: 0.4349%\n",
      "Epoch [36/300], Step [40/225], Training Accuracy: 81.8750%, Training Loss: 0.4327%\n",
      "Epoch [36/300], Step [41/225], Training Accuracy: 81.6311%, Training Loss: 0.4429%\n",
      "Epoch [36/300], Step [42/225], Training Accuracy: 81.6592%, Training Loss: 0.4412%\n",
      "Epoch [36/300], Step [43/225], Training Accuracy: 81.6134%, Training Loss: 0.4414%\n",
      "Epoch [36/300], Step [44/225], Training Accuracy: 81.7116%, Training Loss: 0.4401%\n",
      "Epoch [36/300], Step [45/225], Training Accuracy: 81.6667%, Training Loss: 0.4421%\n",
      "Epoch [36/300], Step [46/225], Training Accuracy: 81.6576%, Training Loss: 0.4405%\n",
      "Epoch [36/300], Step [47/225], Training Accuracy: 81.6822%, Training Loss: 0.4389%\n",
      "Epoch [36/300], Step [48/225], Training Accuracy: 81.5430%, Training Loss: 0.4405%\n",
      "Epoch [36/300], Step [49/225], Training Accuracy: 81.5370%, Training Loss: 0.4425%\n",
      "Epoch [36/300], Step [50/225], Training Accuracy: 81.3750%, Training Loss: 0.4452%\n",
      "Epoch [36/300], Step [51/225], Training Accuracy: 81.5257%, Training Loss: 0.4406%\n",
      "Epoch [36/300], Step [52/225], Training Accuracy: 81.6707%, Training Loss: 0.4380%\n",
      "Epoch [36/300], Step [53/225], Training Accuracy: 81.6038%, Training Loss: 0.4392%\n",
      "Epoch [36/300], Step [54/225], Training Accuracy: 81.4525%, Training Loss: 0.4450%\n",
      "Epoch [36/300], Step [55/225], Training Accuracy: 81.3636%, Training Loss: 0.4466%\n",
      "Epoch [36/300], Step [56/225], Training Accuracy: 81.4453%, Training Loss: 0.4436%\n",
      "Epoch [36/300], Step [57/225], Training Accuracy: 81.4419%, Training Loss: 0.4470%\n",
      "Epoch [36/300], Step [58/225], Training Accuracy: 81.3847%, Training Loss: 0.4478%\n",
      "Epoch [36/300], Step [59/225], Training Accuracy: 81.2765%, Training Loss: 0.4486%\n",
      "Epoch [36/300], Step [60/225], Training Accuracy: 81.3021%, Training Loss: 0.4483%\n",
      "Epoch [36/300], Step [61/225], Training Accuracy: 81.3268%, Training Loss: 0.4489%\n",
      "Epoch [36/300], Step [62/225], Training Accuracy: 81.4264%, Training Loss: 0.4479%\n",
      "Epoch [36/300], Step [63/225], Training Accuracy: 81.3492%, Training Loss: 0.4491%\n",
      "Epoch [36/300], Step [64/225], Training Accuracy: 81.2744%, Training Loss: 0.4510%\n",
      "Epoch [36/300], Step [65/225], Training Accuracy: 81.2981%, Training Loss: 0.4530%\n",
      "Epoch [36/300], Step [66/225], Training Accuracy: 81.4157%, Training Loss: 0.4506%\n",
      "Epoch [36/300], Step [67/225], Training Accuracy: 81.4132%, Training Loss: 0.4502%\n",
      "Epoch [36/300], Step [68/225], Training Accuracy: 81.4568%, Training Loss: 0.4481%\n",
      "Epoch [36/300], Step [69/225], Training Accuracy: 81.4538%, Training Loss: 0.4470%\n",
      "Epoch [36/300], Step [70/225], Training Accuracy: 81.5402%, Training Loss: 0.4463%\n",
      "Epoch [36/300], Step [71/225], Training Accuracy: 81.6021%, Training Loss: 0.4458%\n",
      "Epoch [36/300], Step [72/225], Training Accuracy: 81.5755%, Training Loss: 0.4455%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/300], Step [73/225], Training Accuracy: 81.6353%, Training Loss: 0.4446%\n",
      "Epoch [36/300], Step [74/225], Training Accuracy: 81.5878%, Training Loss: 0.4438%\n",
      "Epoch [36/300], Step [75/225], Training Accuracy: 81.6458%, Training Loss: 0.4424%\n",
      "Epoch [36/300], Step [76/225], Training Accuracy: 81.5995%, Training Loss: 0.4429%\n",
      "Epoch [36/300], Step [77/225], Training Accuracy: 81.5544%, Training Loss: 0.4454%\n",
      "Epoch [36/300], Step [78/225], Training Accuracy: 81.5104%, Training Loss: 0.4455%\n",
      "Epoch [36/300], Step [79/225], Training Accuracy: 81.5269%, Training Loss: 0.4453%\n",
      "Epoch [36/300], Step [80/225], Training Accuracy: 81.4844%, Training Loss: 0.4457%\n",
      "Epoch [36/300], Step [81/225], Training Accuracy: 81.5008%, Training Loss: 0.4451%\n",
      "Epoch [36/300], Step [82/225], Training Accuracy: 81.4977%, Training Loss: 0.4452%\n",
      "Epoch [36/300], Step [83/225], Training Accuracy: 81.5324%, Training Loss: 0.4444%\n",
      "Epoch [36/300], Step [84/225], Training Accuracy: 81.6034%, Training Loss: 0.4426%\n",
      "Epoch [36/300], Step [85/225], Training Accuracy: 81.4890%, Training Loss: 0.4444%\n",
      "Epoch [36/300], Step [86/225], Training Accuracy: 81.5589%, Training Loss: 0.4440%\n",
      "Epoch [36/300], Step [87/225], Training Accuracy: 81.5553%, Training Loss: 0.4448%\n",
      "Epoch [36/300], Step [88/225], Training Accuracy: 81.5518%, Training Loss: 0.4458%\n",
      "Epoch [36/300], Step [89/225], Training Accuracy: 81.5660%, Training Loss: 0.4460%\n",
      "Epoch [36/300], Step [90/225], Training Accuracy: 81.5278%, Training Loss: 0.4469%\n",
      "Epoch [36/300], Step [91/225], Training Accuracy: 81.4732%, Training Loss: 0.4479%\n",
      "Epoch [36/300], Step [92/225], Training Accuracy: 81.5217%, Training Loss: 0.4480%\n",
      "Epoch [36/300], Step [93/225], Training Accuracy: 81.5356%, Training Loss: 0.4482%\n",
      "Epoch [36/300], Step [94/225], Training Accuracy: 81.6157%, Training Loss: 0.4473%\n",
      "Epoch [36/300], Step [95/225], Training Accuracy: 81.5954%, Training Loss: 0.4472%\n",
      "Epoch [36/300], Step [96/225], Training Accuracy: 81.6732%, Training Loss: 0.4454%\n",
      "Epoch [36/300], Step [97/225], Training Accuracy: 81.7332%, Training Loss: 0.4442%\n",
      "Epoch [36/300], Step [98/225], Training Accuracy: 81.6486%, Training Loss: 0.4448%\n",
      "Epoch [36/300], Step [99/225], Training Accuracy: 81.6761%, Training Loss: 0.4437%\n",
      "Epoch [36/300], Step [100/225], Training Accuracy: 81.7031%, Training Loss: 0.4435%\n",
      "Epoch [36/300], Step [101/225], Training Accuracy: 81.7141%, Training Loss: 0.4424%\n",
      "Epoch [36/300], Step [102/225], Training Accuracy: 81.7249%, Training Loss: 0.4432%\n",
      "Epoch [36/300], Step [103/225], Training Accuracy: 81.7203%, Training Loss: 0.4427%\n",
      "Epoch [36/300], Step [104/225], Training Accuracy: 81.7007%, Training Loss: 0.4432%\n",
      "Epoch [36/300], Step [105/225], Training Accuracy: 81.7560%, Training Loss: 0.4419%\n",
      "Epoch [36/300], Step [106/225], Training Accuracy: 81.7807%, Training Loss: 0.4411%\n",
      "Epoch [36/300], Step [107/225], Training Accuracy: 81.7757%, Training Loss: 0.4417%\n",
      "Epoch [36/300], Step [108/225], Training Accuracy: 81.7274%, Training Loss: 0.4436%\n",
      "Epoch [36/300], Step [109/225], Training Accuracy: 81.7804%, Training Loss: 0.4428%\n",
      "Epoch [36/300], Step [110/225], Training Accuracy: 81.7614%, Training Loss: 0.4433%\n",
      "Epoch [36/300], Step [111/225], Training Accuracy: 81.7708%, Training Loss: 0.4423%\n",
      "Epoch [36/300], Step [112/225], Training Accuracy: 81.7383%, Training Loss: 0.4433%\n",
      "Epoch [36/300], Step [113/225], Training Accuracy: 81.7340%, Training Loss: 0.4428%\n",
      "Epoch [36/300], Step [114/225], Training Accuracy: 81.7708%, Training Loss: 0.4419%\n",
      "Epoch [36/300], Step [115/225], Training Accuracy: 81.8207%, Training Loss: 0.4404%\n",
      "Epoch [36/300], Step [116/225], Training Accuracy: 81.8157%, Training Loss: 0.4400%\n",
      "Epoch [36/300], Step [117/225], Training Accuracy: 81.7975%, Training Loss: 0.4413%\n",
      "Epoch [36/300], Step [118/225], Training Accuracy: 81.8591%, Training Loss: 0.4402%\n",
      "Epoch [36/300], Step [119/225], Training Accuracy: 81.8540%, Training Loss: 0.4398%\n",
      "Epoch [36/300], Step [120/225], Training Accuracy: 81.8099%, Training Loss: 0.4402%\n",
      "Epoch [36/300], Step [121/225], Training Accuracy: 81.7536%, Training Loss: 0.4408%\n",
      "Epoch [36/300], Step [122/225], Training Accuracy: 81.6598%, Training Loss: 0.4427%\n",
      "Epoch [36/300], Step [123/225], Training Accuracy: 81.6565%, Training Loss: 0.4432%\n",
      "Epoch [36/300], Step [124/225], Training Accuracy: 81.6658%, Training Loss: 0.4423%\n",
      "Epoch [36/300], Step [125/225], Training Accuracy: 81.7000%, Training Loss: 0.4416%\n",
      "Epoch [36/300], Step [126/225], Training Accuracy: 81.6840%, Training Loss: 0.4422%\n",
      "Epoch [36/300], Step [127/225], Training Accuracy: 81.7667%, Training Loss: 0.4413%\n",
      "Epoch [36/300], Step [128/225], Training Accuracy: 81.6895%, Training Loss: 0.4427%\n",
      "Epoch [36/300], Step [129/225], Training Accuracy: 81.6982%, Training Loss: 0.4430%\n",
      "Epoch [36/300], Step [130/225], Training Accuracy: 81.6947%, Training Loss: 0.4432%\n",
      "Epoch [36/300], Step [131/225], Training Accuracy: 81.6078%, Training Loss: 0.4445%\n",
      "Epoch [36/300], Step [132/225], Training Accuracy: 81.5696%, Training Loss: 0.4454%\n",
      "Epoch [36/300], Step [133/225], Training Accuracy: 81.5789%, Training Loss: 0.4452%\n",
      "Epoch [36/300], Step [134/225], Training Accuracy: 81.5065%, Training Loss: 0.4465%\n",
      "Epoch [36/300], Step [135/225], Training Accuracy: 81.4931%, Training Loss: 0.4466%\n",
      "Epoch [36/300], Step [136/225], Training Accuracy: 81.4683%, Training Loss: 0.4474%\n",
      "Epoch [36/300], Step [137/225], Training Accuracy: 81.4667%, Training Loss: 0.4481%\n",
      "Epoch [36/300], Step [138/225], Training Accuracy: 81.5104%, Training Loss: 0.4477%\n",
      "Epoch [36/300], Step [139/225], Training Accuracy: 81.4748%, Training Loss: 0.4483%\n",
      "Epoch [36/300], Step [140/225], Training Accuracy: 81.5067%, Training Loss: 0.4482%\n",
      "Epoch [36/300], Step [141/225], Training Accuracy: 81.5270%, Training Loss: 0.4485%\n",
      "Epoch [36/300], Step [142/225], Training Accuracy: 81.5251%, Training Loss: 0.4482%\n",
      "Epoch [36/300], Step [143/225], Training Accuracy: 81.5778%, Training Loss: 0.4477%\n",
      "Epoch [36/300], Step [144/225], Training Accuracy: 81.5430%, Training Loss: 0.4479%\n",
      "Epoch [36/300], Step [145/225], Training Accuracy: 81.4763%, Training Loss: 0.4489%\n",
      "Epoch [36/300], Step [146/225], Training Accuracy: 81.5068%, Training Loss: 0.4494%\n",
      "Epoch [36/300], Step [147/225], Training Accuracy: 81.4945%, Training Loss: 0.4494%\n",
      "Epoch [36/300], Step [148/225], Training Accuracy: 81.5351%, Training Loss: 0.4481%\n",
      "Epoch [36/300], Step [149/225], Training Accuracy: 81.5122%, Training Loss: 0.4484%\n",
      "Epoch [36/300], Step [150/225], Training Accuracy: 81.5208%, Training Loss: 0.4486%\n",
      "Epoch [36/300], Step [151/225], Training Accuracy: 81.5294%, Training Loss: 0.4488%\n",
      "Epoch [36/300], Step [152/225], Training Accuracy: 81.5481%, Training Loss: 0.4487%\n",
      "Epoch [36/300], Step [153/225], Training Accuracy: 81.5155%, Training Loss: 0.4495%\n",
      "Epoch [36/300], Step [154/225], Training Accuracy: 81.5544%, Training Loss: 0.4495%\n",
      "Epoch [36/300], Step [155/225], Training Accuracy: 81.5222%, Training Loss: 0.4500%\n",
      "Epoch [36/300], Step [156/225], Training Accuracy: 81.5204%, Training Loss: 0.4497%\n",
      "Epoch [36/300], Step [157/225], Training Accuracy: 81.4988%, Training Loss: 0.4503%\n",
      "Epoch [36/300], Step [158/225], Training Accuracy: 81.4676%, Training Loss: 0.4509%\n",
      "Epoch [36/300], Step [159/225], Training Accuracy: 81.4662%, Training Loss: 0.4512%\n",
      "Epoch [36/300], Step [160/225], Training Accuracy: 81.4551%, Training Loss: 0.4513%\n",
      "Epoch [36/300], Step [161/225], Training Accuracy: 81.4538%, Training Loss: 0.4517%\n",
      "Epoch [36/300], Step [162/225], Training Accuracy: 81.4718%, Training Loss: 0.4513%\n",
      "Epoch [36/300], Step [163/225], Training Accuracy: 81.4130%, Training Loss: 0.4521%\n",
      "Epoch [36/300], Step [164/225], Training Accuracy: 81.4405%, Training Loss: 0.4522%\n",
      "Epoch [36/300], Step [165/225], Training Accuracy: 81.4678%, Training Loss: 0.4518%\n",
      "Epoch [36/300], Step [166/225], Training Accuracy: 81.4571%, Training Loss: 0.4526%\n",
      "Epoch [36/300], Step [167/225], Training Accuracy: 81.4652%, Training Loss: 0.4526%\n",
      "Epoch [36/300], Step [168/225], Training Accuracy: 81.3709%, Training Loss: 0.4539%\n",
      "Epoch [36/300], Step [169/225], Training Accuracy: 81.4164%, Training Loss: 0.4526%\n",
      "Epoch [36/300], Step [170/225], Training Accuracy: 81.4246%, Training Loss: 0.4530%\n",
      "Epoch [36/300], Step [171/225], Training Accuracy: 81.3871%, Training Loss: 0.4539%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/300], Step [172/225], Training Accuracy: 81.4135%, Training Loss: 0.4535%\n",
      "Epoch [36/300], Step [173/225], Training Accuracy: 81.4216%, Training Loss: 0.4542%\n",
      "Epoch [36/300], Step [174/225], Training Accuracy: 81.4655%, Training Loss: 0.4538%\n",
      "Epoch [36/300], Step [175/225], Training Accuracy: 81.4554%, Training Loss: 0.4537%\n",
      "Epoch [36/300], Step [176/225], Training Accuracy: 81.4808%, Training Loss: 0.4528%\n",
      "Epoch [36/300], Step [177/225], Training Accuracy: 81.5501%, Training Loss: 0.4514%\n",
      "Epoch [36/300], Step [178/225], Training Accuracy: 81.5572%, Training Loss: 0.4511%\n",
      "Epoch [36/300], Step [179/225], Training Accuracy: 81.5817%, Training Loss: 0.4507%\n",
      "Epoch [36/300], Step [180/225], Training Accuracy: 81.5885%, Training Loss: 0.4515%\n",
      "Epoch [36/300], Step [181/225], Training Accuracy: 81.6126%, Training Loss: 0.4512%\n",
      "Epoch [36/300], Step [182/225], Training Accuracy: 81.6192%, Training Loss: 0.4506%\n",
      "Epoch [36/300], Step [183/225], Training Accuracy: 81.6257%, Training Loss: 0.4514%\n",
      "Epoch [36/300], Step [184/225], Training Accuracy: 81.6831%, Training Loss: 0.4506%\n",
      "Epoch [36/300], Step [185/225], Training Accuracy: 81.6892%, Training Loss: 0.4500%\n",
      "Epoch [36/300], Step [186/225], Training Accuracy: 81.6784%, Training Loss: 0.4496%\n",
      "Epoch [36/300], Step [187/225], Training Accuracy: 81.7179%, Training Loss: 0.4490%\n",
      "Epoch [36/300], Step [188/225], Training Accuracy: 81.7487%, Training Loss: 0.4485%\n",
      "Epoch [36/300], Step [189/225], Training Accuracy: 81.7460%, Training Loss: 0.4486%\n",
      "Epoch [36/300], Step [190/225], Training Accuracy: 81.7516%, Training Loss: 0.4487%\n",
      "Epoch [36/300], Step [191/225], Training Accuracy: 81.7163%, Training Loss: 0.4489%\n",
      "Epoch [36/300], Step [192/225], Training Accuracy: 81.7464%, Training Loss: 0.4486%\n",
      "Epoch [36/300], Step [193/225], Training Accuracy: 81.7277%, Training Loss: 0.4486%\n",
      "Epoch [36/300], Step [194/225], Training Accuracy: 81.7332%, Training Loss: 0.4487%\n",
      "Epoch [36/300], Step [195/225], Training Accuracy: 81.7388%, Training Loss: 0.4483%\n",
      "Epoch [36/300], Step [196/225], Training Accuracy: 81.7203%, Training Loss: 0.4489%\n",
      "Epoch [36/300], Step [197/225], Training Accuracy: 81.6783%, Training Loss: 0.4501%\n",
      "Epoch [36/300], Step [198/225], Training Accuracy: 81.7235%, Training Loss: 0.4493%\n",
      "Epoch [36/300], Step [199/225], Training Accuracy: 81.7682%, Training Loss: 0.4485%\n",
      "Epoch [36/300], Step [200/225], Training Accuracy: 81.7969%, Training Loss: 0.4483%\n",
      "Epoch [36/300], Step [201/225], Training Accuracy: 81.8175%, Training Loss: 0.4478%\n",
      "Epoch [36/300], Step [202/225], Training Accuracy: 81.8456%, Training Loss: 0.4476%\n",
      "Epoch [36/300], Step [203/225], Training Accuracy: 81.8427%, Training Loss: 0.4474%\n",
      "Epoch [36/300], Step [204/225], Training Accuracy: 81.8781%, Training Loss: 0.4468%\n",
      "Epoch [36/300], Step [205/225], Training Accuracy: 81.8979%, Training Loss: 0.4465%\n",
      "Epoch [36/300], Step [206/225], Training Accuracy: 81.8796%, Training Loss: 0.4467%\n",
      "Epoch [36/300], Step [207/225], Training Accuracy: 81.8992%, Training Loss: 0.4465%\n",
      "Epoch [36/300], Step [208/225], Training Accuracy: 81.9111%, Training Loss: 0.4462%\n",
      "Epoch [36/300], Step [209/225], Training Accuracy: 81.9079%, Training Loss: 0.4463%\n",
      "Epoch [36/300], Step [210/225], Training Accuracy: 81.9271%, Training Loss: 0.4458%\n",
      "Epoch [36/300], Step [211/225], Training Accuracy: 81.9017%, Training Loss: 0.4461%\n",
      "Epoch [36/300], Step [212/225], Training Accuracy: 81.8765%, Training Loss: 0.4468%\n",
      "Epoch [36/300], Step [213/225], Training Accuracy: 81.9249%, Training Loss: 0.4461%\n",
      "Epoch [36/300], Step [214/225], Training Accuracy: 81.9217%, Training Loss: 0.4461%\n",
      "Epoch [36/300], Step [215/225], Training Accuracy: 81.9331%, Training Loss: 0.4457%\n",
      "Epoch [36/300], Step [216/225], Training Accuracy: 81.9227%, Training Loss: 0.4458%\n",
      "Epoch [36/300], Step [217/225], Training Accuracy: 81.9196%, Training Loss: 0.4459%\n",
      "Epoch [36/300], Step [218/225], Training Accuracy: 81.8879%, Training Loss: 0.4469%\n",
      "Epoch [36/300], Step [219/225], Training Accuracy: 81.8993%, Training Loss: 0.4466%\n",
      "Epoch [36/300], Step [220/225], Training Accuracy: 81.9105%, Training Loss: 0.4469%\n",
      "Epoch [36/300], Step [221/225], Training Accuracy: 81.9217%, Training Loss: 0.4464%\n",
      "Epoch [36/300], Step [222/225], Training Accuracy: 81.9046%, Training Loss: 0.4468%\n",
      "Epoch [36/300], Step [223/225], Training Accuracy: 81.9226%, Training Loss: 0.4469%\n",
      "Epoch [36/300], Step [224/225], Training Accuracy: 81.9196%, Training Loss: 0.4472%\n",
      "Epoch [36/300], Step [225/225], Training Accuracy: 81.9275%, Training Loss: 0.4465%\n",
      "Epoch [37/300], Step [1/225], Training Accuracy: 75.0000%, Training Loss: 0.5104%\n",
      "Epoch [37/300], Step [2/225], Training Accuracy: 77.3438%, Training Loss: 0.5073%\n",
      "Epoch [37/300], Step [3/225], Training Accuracy: 80.2083%, Training Loss: 0.4602%\n",
      "Epoch [37/300], Step [4/225], Training Accuracy: 82.4219%, Training Loss: 0.4257%\n",
      "Epoch [37/300], Step [5/225], Training Accuracy: 82.1875%, Training Loss: 0.4269%\n",
      "Epoch [37/300], Step [6/225], Training Accuracy: 83.3333%, Training Loss: 0.4255%\n",
      "Epoch [37/300], Step [7/225], Training Accuracy: 82.8125%, Training Loss: 0.4245%\n",
      "Epoch [37/300], Step [8/225], Training Accuracy: 83.0078%, Training Loss: 0.4219%\n",
      "Epoch [37/300], Step [9/225], Training Accuracy: 83.6806%, Training Loss: 0.4147%\n",
      "Epoch [37/300], Step [10/225], Training Accuracy: 83.1250%, Training Loss: 0.4236%\n",
      "Epoch [37/300], Step [11/225], Training Accuracy: 82.3864%, Training Loss: 0.4318%\n",
      "Epoch [37/300], Step [12/225], Training Accuracy: 83.0729%, Training Loss: 0.4209%\n",
      "Epoch [37/300], Step [13/225], Training Accuracy: 83.4135%, Training Loss: 0.4119%\n",
      "Epoch [37/300], Step [14/225], Training Accuracy: 83.5938%, Training Loss: 0.4085%\n",
      "Epoch [37/300], Step [15/225], Training Accuracy: 83.3333%, Training Loss: 0.4076%\n",
      "Epoch [37/300], Step [16/225], Training Accuracy: 83.2031%, Training Loss: 0.4142%\n",
      "Epoch [37/300], Step [17/225], Training Accuracy: 83.3640%, Training Loss: 0.4113%\n",
      "Epoch [37/300], Step [18/225], Training Accuracy: 82.6389%, Training Loss: 0.4297%\n",
      "Epoch [37/300], Step [19/225], Training Accuracy: 82.4013%, Training Loss: 0.4365%\n",
      "Epoch [37/300], Step [20/225], Training Accuracy: 82.6562%, Training Loss: 0.4331%\n",
      "Epoch [37/300], Step [21/225], Training Accuracy: 82.9613%, Training Loss: 0.4262%\n",
      "Epoch [37/300], Step [22/225], Training Accuracy: 82.7415%, Training Loss: 0.4307%\n",
      "Epoch [37/300], Step [23/225], Training Accuracy: 82.5408%, Training Loss: 0.4344%\n",
      "Epoch [37/300], Step [24/225], Training Accuracy: 82.4870%, Training Loss: 0.4362%\n",
      "Epoch [37/300], Step [25/225], Training Accuracy: 82.6250%, Training Loss: 0.4315%\n",
      "Epoch [37/300], Step [26/225], Training Accuracy: 82.5120%, Training Loss: 0.4345%\n",
      "Epoch [37/300], Step [27/225], Training Accuracy: 82.7546%, Training Loss: 0.4312%\n",
      "Epoch [37/300], Step [28/225], Training Accuracy: 82.8683%, Training Loss: 0.4270%\n",
      "Epoch [37/300], Step [29/225], Training Accuracy: 82.9741%, Training Loss: 0.4239%\n",
      "Epoch [37/300], Step [30/225], Training Accuracy: 83.0729%, Training Loss: 0.4271%\n",
      "Epoch [37/300], Step [31/225], Training Accuracy: 82.7117%, Training Loss: 0.4331%\n",
      "Epoch [37/300], Step [32/225], Training Accuracy: 82.4707%, Training Loss: 0.4342%\n",
      "Epoch [37/300], Step [33/225], Training Accuracy: 82.4337%, Training Loss: 0.4337%\n",
      "Epoch [37/300], Step [34/225], Training Accuracy: 82.1691%, Training Loss: 0.4433%\n",
      "Epoch [37/300], Step [35/225], Training Accuracy: 82.3661%, Training Loss: 0.4400%\n",
      "Epoch [37/300], Step [36/225], Training Accuracy: 82.3785%, Training Loss: 0.4387%\n",
      "Epoch [37/300], Step [37/225], Training Accuracy: 82.4324%, Training Loss: 0.4351%\n",
      "Epoch [37/300], Step [38/225], Training Accuracy: 82.4836%, Training Loss: 0.4321%\n",
      "Epoch [37/300], Step [39/225], Training Accuracy: 82.2917%, Training Loss: 0.4338%\n",
      "Epoch [37/300], Step [40/225], Training Accuracy: 82.2656%, Training Loss: 0.4349%\n",
      "Epoch [37/300], Step [41/225], Training Accuracy: 82.0884%, Training Loss: 0.4395%\n",
      "Epoch [37/300], Step [42/225], Training Accuracy: 81.9940%, Training Loss: 0.4420%\n",
      "Epoch [37/300], Step [43/225], Training Accuracy: 82.1221%, Training Loss: 0.4409%\n",
      "Epoch [37/300], Step [44/225], Training Accuracy: 82.2088%, Training Loss: 0.4395%\n",
      "Epoch [37/300], Step [45/225], Training Accuracy: 82.2917%, Training Loss: 0.4374%\n",
      "Epoch [37/300], Step [46/225], Training Accuracy: 82.3030%, Training Loss: 0.4363%\n",
      "Epoch [37/300], Step [47/225], Training Accuracy: 82.3138%, Training Loss: 0.4358%\n",
      "Epoch [37/300], Step [48/225], Training Accuracy: 82.2591%, Training Loss: 0.4401%\n",
      "Epoch [37/300], Step [49/225], Training Accuracy: 82.2704%, Training Loss: 0.4385%\n",
      "Epoch [37/300], Step [50/225], Training Accuracy: 82.2500%, Training Loss: 0.4388%\n",
      "Epoch [37/300], Step [51/225], Training Accuracy: 82.3223%, Training Loss: 0.4359%\n",
      "Epoch [37/300], Step [52/225], Training Accuracy: 82.3618%, Training Loss: 0.4350%\n",
      "Epoch [37/300], Step [53/225], Training Accuracy: 82.2524%, Training Loss: 0.4361%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/300], Step [54/225], Training Accuracy: 82.2917%, Training Loss: 0.4374%\n",
      "Epoch [37/300], Step [55/225], Training Accuracy: 82.2159%, Training Loss: 0.4389%\n",
      "Epoch [37/300], Step [56/225], Training Accuracy: 82.2545%, Training Loss: 0.4391%\n",
      "Epoch [37/300], Step [57/225], Training Accuracy: 82.2094%, Training Loss: 0.4389%\n",
      "Epoch [37/300], Step [58/225], Training Accuracy: 82.1121%, Training Loss: 0.4403%\n",
      "Epoch [37/300], Step [59/225], Training Accuracy: 81.8856%, Training Loss: 0.4423%\n",
      "Epoch [37/300], Step [60/225], Training Accuracy: 81.8229%, Training Loss: 0.4437%\n",
      "Epoch [37/300], Step [61/225], Training Accuracy: 81.7111%, Training Loss: 0.4453%\n",
      "Epoch [37/300], Step [62/225], Training Accuracy: 81.8044%, Training Loss: 0.4421%\n",
      "Epoch [37/300], Step [63/225], Training Accuracy: 81.8948%, Training Loss: 0.4428%\n",
      "Epoch [37/300], Step [64/225], Training Accuracy: 81.9336%, Training Loss: 0.4423%\n",
      "Epoch [37/300], Step [65/225], Training Accuracy: 81.9471%, Training Loss: 0.4427%\n",
      "Epoch [37/300], Step [66/225], Training Accuracy: 81.9839%, Training Loss: 0.4423%\n",
      "Epoch [37/300], Step [67/225], Training Accuracy: 81.9963%, Training Loss: 0.4421%\n",
      "Epoch [37/300], Step [68/225], Training Accuracy: 81.9623%, Training Loss: 0.4431%\n",
      "Epoch [37/300], Step [69/225], Training Accuracy: 81.9746%, Training Loss: 0.4428%\n",
      "Epoch [37/300], Step [70/225], Training Accuracy: 81.8080%, Training Loss: 0.4459%\n",
      "Epoch [37/300], Step [71/225], Training Accuracy: 81.8882%, Training Loss: 0.4445%\n",
      "Epoch [37/300], Step [72/225], Training Accuracy: 81.9010%, Training Loss: 0.4445%\n",
      "Epoch [37/300], Step [73/225], Training Accuracy: 81.9991%, Training Loss: 0.4432%\n",
      "Epoch [37/300], Step [74/225], Training Accuracy: 82.0946%, Training Loss: 0.4405%\n",
      "Epoch [37/300], Step [75/225], Training Accuracy: 82.2083%, Training Loss: 0.4383%\n",
      "Epoch [37/300], Step [76/225], Training Accuracy: 82.1340%, Training Loss: 0.4390%\n",
      "Epoch [37/300], Step [77/225], Training Accuracy: 82.1226%, Training Loss: 0.4384%\n",
      "Epoch [37/300], Step [78/225], Training Accuracy: 82.1514%, Training Loss: 0.4377%\n",
      "Epoch [37/300], Step [79/225], Training Accuracy: 82.1796%, Training Loss: 0.4377%\n",
      "Epoch [37/300], Step [80/225], Training Accuracy: 82.1484%, Training Loss: 0.4382%\n",
      "Epoch [37/300], Step [81/225], Training Accuracy: 82.2338%, Training Loss: 0.4372%\n",
      "Epoch [37/300], Step [82/225], Training Accuracy: 82.2790%, Training Loss: 0.4360%\n",
      "Epoch [37/300], Step [83/225], Training Accuracy: 82.2477%, Training Loss: 0.4363%\n",
      "Epoch [37/300], Step [84/225], Training Accuracy: 82.3103%, Training Loss: 0.4345%\n",
      "Epoch [37/300], Step [85/225], Training Accuracy: 82.4081%, Training Loss: 0.4326%\n",
      "Epoch [37/300], Step [86/225], Training Accuracy: 82.5218%, Training Loss: 0.4303%\n",
      "Epoch [37/300], Step [87/225], Training Accuracy: 82.4713%, Training Loss: 0.4315%\n",
      "Epoch [37/300], Step [88/225], Training Accuracy: 82.4219%, Training Loss: 0.4332%\n",
      "Epoch [37/300], Step [89/225], Training Accuracy: 82.4789%, Training Loss: 0.4321%\n",
      "Epoch [37/300], Step [90/225], Training Accuracy: 82.4653%, Training Loss: 0.4324%\n",
      "Epoch [37/300], Step [91/225], Training Accuracy: 82.3661%, Training Loss: 0.4347%\n",
      "Epoch [37/300], Step [92/225], Training Accuracy: 82.3370%, Training Loss: 0.4346%\n",
      "Epoch [37/300], Step [93/225], Training Accuracy: 82.3925%, Training Loss: 0.4336%\n",
      "Epoch [37/300], Step [94/225], Training Accuracy: 82.4801%, Training Loss: 0.4317%\n",
      "Epoch [37/300], Step [95/225], Training Accuracy: 82.4507%, Training Loss: 0.4316%\n",
      "Epoch [37/300], Step [96/225], Training Accuracy: 82.5195%, Training Loss: 0.4303%\n",
      "Epoch [37/300], Step [97/225], Training Accuracy: 82.4259%, Training Loss: 0.4311%\n",
      "Epoch [37/300], Step [98/225], Training Accuracy: 82.4298%, Training Loss: 0.4318%\n",
      "Epoch [37/300], Step [99/225], Training Accuracy: 82.4495%, Training Loss: 0.4313%\n",
      "Epoch [37/300], Step [100/225], Training Accuracy: 82.2969%, Training Loss: 0.4327%\n",
      "Epoch [37/300], Step [101/225], Training Accuracy: 82.3329%, Training Loss: 0.4316%\n",
      "Epoch [37/300], Step [102/225], Training Accuracy: 82.3529%, Training Loss: 0.4320%\n",
      "Epoch [37/300], Step [103/225], Training Accuracy: 82.3574%, Training Loss: 0.4323%\n",
      "Epoch [37/300], Step [104/225], Training Accuracy: 82.3618%, Training Loss: 0.4321%\n",
      "Epoch [37/300], Step [105/225], Training Accuracy: 82.3512%, Training Loss: 0.4318%\n",
      "Epoch [37/300], Step [106/225], Training Accuracy: 82.3113%, Training Loss: 0.4328%\n",
      "Epoch [37/300], Step [107/225], Training Accuracy: 82.3890%, Training Loss: 0.4320%\n",
      "Epoch [37/300], Step [108/225], Training Accuracy: 82.3351%, Training Loss: 0.4324%\n",
      "Epoch [37/300], Step [109/225], Training Accuracy: 82.3681%, Training Loss: 0.4318%\n",
      "Epoch [37/300], Step [110/225], Training Accuracy: 82.3864%, Training Loss: 0.4313%\n",
      "Epoch [37/300], Step [111/225], Training Accuracy: 82.4043%, Training Loss: 0.4317%\n",
      "Epoch [37/300], Step [112/225], Training Accuracy: 82.4358%, Training Loss: 0.4314%\n",
      "Epoch [37/300], Step [113/225], Training Accuracy: 82.4115%, Training Loss: 0.4317%\n",
      "Epoch [37/300], Step [114/225], Training Accuracy: 82.4287%, Training Loss: 0.4313%\n",
      "Epoch [37/300], Step [115/225], Training Accuracy: 82.4321%, Training Loss: 0.4316%\n",
      "Epoch [37/300], Step [116/225], Training Accuracy: 82.4353%, Training Loss: 0.4310%\n",
      "Epoch [37/300], Step [117/225], Training Accuracy: 82.3851%, Training Loss: 0.4322%\n",
      "Epoch [37/300], Step [118/225], Training Accuracy: 82.4020%, Training Loss: 0.4316%\n",
      "Epoch [37/300], Step [119/225], Training Accuracy: 82.3923%, Training Loss: 0.4320%\n",
      "Epoch [37/300], Step [120/225], Training Accuracy: 82.4349%, Training Loss: 0.4313%\n",
      "Epoch [37/300], Step [121/225], Training Accuracy: 82.3735%, Training Loss: 0.4324%\n",
      "Epoch [37/300], Step [122/225], Training Accuracy: 82.3899%, Training Loss: 0.4317%\n",
      "Epoch [37/300], Step [123/225], Training Accuracy: 82.3679%, Training Loss: 0.4333%\n",
      "Epoch [37/300], Step [124/225], Training Accuracy: 82.3841%, Training Loss: 0.4332%\n",
      "Epoch [37/300], Step [125/225], Training Accuracy: 82.3625%, Training Loss: 0.4335%\n",
      "Epoch [37/300], Step [126/225], Training Accuracy: 82.3909%, Training Loss: 0.4330%\n",
      "Epoch [37/300], Step [127/225], Training Accuracy: 82.4188%, Training Loss: 0.4321%\n",
      "Epoch [37/300], Step [128/225], Training Accuracy: 82.4829%, Training Loss: 0.4318%\n",
      "Epoch [37/300], Step [129/225], Training Accuracy: 82.4734%, Training Loss: 0.4321%\n",
      "Epoch [37/300], Step [130/225], Training Accuracy: 82.4399%, Training Loss: 0.4332%\n",
      "Epoch [37/300], Step [131/225], Training Accuracy: 82.3473%, Training Loss: 0.4353%\n",
      "Epoch [37/300], Step [132/225], Training Accuracy: 82.3627%, Training Loss: 0.4348%\n",
      "Epoch [37/300], Step [133/225], Training Accuracy: 82.3543%, Training Loss: 0.4342%\n",
      "Epoch [37/300], Step [134/225], Training Accuracy: 82.3228%, Training Loss: 0.4346%\n",
      "Epoch [37/300], Step [135/225], Training Accuracy: 82.3264%, Training Loss: 0.4343%\n",
      "Epoch [37/300], Step [136/225], Training Accuracy: 82.3070%, Training Loss: 0.4342%\n",
      "Epoch [37/300], Step [137/225], Training Accuracy: 82.3221%, Training Loss: 0.4340%\n",
      "Epoch [37/300], Step [138/225], Training Accuracy: 82.3483%, Training Loss: 0.4336%\n",
      "Epoch [37/300], Step [139/225], Training Accuracy: 82.3853%, Training Loss: 0.4327%\n",
      "Epoch [37/300], Step [140/225], Training Accuracy: 82.4107%, Training Loss: 0.4322%\n",
      "Epoch [37/300], Step [141/225], Training Accuracy: 82.3692%, Training Loss: 0.4321%\n",
      "Epoch [37/300], Step [142/225], Training Accuracy: 82.3724%, Training Loss: 0.4318%\n",
      "Epoch [37/300], Step [143/225], Training Accuracy: 82.3973%, Training Loss: 0.4314%\n",
      "Epoch [37/300], Step [144/225], Training Accuracy: 82.4219%, Training Loss: 0.4311%\n",
      "Epoch [37/300], Step [145/225], Training Accuracy: 82.4030%, Training Loss: 0.4314%\n",
      "Epoch [37/300], Step [146/225], Training Accuracy: 82.3630%, Training Loss: 0.4321%\n",
      "Epoch [37/300], Step [147/225], Training Accuracy: 82.3767%, Training Loss: 0.4315%\n",
      "Epoch [37/300], Step [148/225], Training Accuracy: 82.3902%, Training Loss: 0.4307%\n",
      "Epoch [37/300], Step [149/225], Training Accuracy: 82.3616%, Training Loss: 0.4313%\n",
      "Epoch [37/300], Step [150/225], Training Accuracy: 82.3854%, Training Loss: 0.4305%\n",
      "Epoch [37/300], Step [151/225], Training Accuracy: 82.4296%, Training Loss: 0.4295%\n",
      "Epoch [37/300], Step [152/225], Training Accuracy: 82.4219%, Training Loss: 0.4295%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/300], Step [153/225], Training Accuracy: 82.4551%, Training Loss: 0.4289%\n",
      "Epoch [37/300], Step [154/225], Training Accuracy: 82.4574%, Training Loss: 0.4286%\n",
      "Epoch [37/300], Step [155/225], Training Accuracy: 82.3992%, Training Loss: 0.4296%\n",
      "Epoch [37/300], Step [156/225], Training Accuracy: 82.4018%, Training Loss: 0.4303%\n",
      "Epoch [37/300], Step [157/225], Training Accuracy: 82.3746%, Training Loss: 0.4307%\n",
      "Epoch [37/300], Step [158/225], Training Accuracy: 82.3477%, Training Loss: 0.4322%\n",
      "Epoch [37/300], Step [159/225], Training Accuracy: 82.3211%, Training Loss: 0.4325%\n",
      "Epoch [37/300], Step [160/225], Training Accuracy: 82.3145%, Training Loss: 0.4327%\n",
      "Epoch [37/300], Step [161/225], Training Accuracy: 82.3467%, Training Loss: 0.4326%\n",
      "Epoch [37/300], Step [162/225], Training Accuracy: 82.3592%, Training Loss: 0.4323%\n",
      "Epoch [37/300], Step [163/225], Training Accuracy: 82.3332%, Training Loss: 0.4324%\n",
      "Epoch [37/300], Step [164/225], Training Accuracy: 82.3742%, Training Loss: 0.4311%\n",
      "Epoch [37/300], Step [165/225], Training Accuracy: 82.3674%, Training Loss: 0.4307%\n",
      "Epoch [37/300], Step [166/225], Training Accuracy: 82.3513%, Training Loss: 0.4308%\n",
      "Epoch [37/300], Step [167/225], Training Accuracy: 82.3540%, Training Loss: 0.4305%\n",
      "Epoch [37/300], Step [168/225], Training Accuracy: 82.3661%, Training Loss: 0.4303%\n",
      "Epoch [37/300], Step [169/225], Training Accuracy: 82.3964%, Training Loss: 0.4299%\n",
      "Epoch [37/300], Step [170/225], Training Accuracy: 82.4265%, Training Loss: 0.4296%\n",
      "Epoch [37/300], Step [171/225], Training Accuracy: 82.4287%, Training Loss: 0.4294%\n",
      "Epoch [37/300], Step [172/225], Training Accuracy: 82.4400%, Training Loss: 0.4291%\n",
      "Epoch [37/300], Step [173/225], Training Accuracy: 82.3970%, Training Loss: 0.4294%\n",
      "Epoch [37/300], Step [174/225], Training Accuracy: 82.4084%, Training Loss: 0.4287%\n",
      "Epoch [37/300], Step [175/225], Training Accuracy: 82.3839%, Training Loss: 0.4287%\n",
      "Epoch [37/300], Step [176/225], Training Accuracy: 82.3952%, Training Loss: 0.4282%\n",
      "Epoch [37/300], Step [177/225], Training Accuracy: 82.4241%, Training Loss: 0.4279%\n",
      "Epoch [37/300], Step [178/225], Training Accuracy: 82.4526%, Training Loss: 0.4274%\n",
      "Epoch [37/300], Step [179/225], Training Accuracy: 82.4633%, Training Loss: 0.4269%\n",
      "Epoch [37/300], Step [180/225], Training Accuracy: 82.4740%, Training Loss: 0.4265%\n",
      "Epoch [37/300], Step [181/225], Training Accuracy: 82.4845%, Training Loss: 0.4272%\n",
      "Epoch [37/300], Step [182/225], Training Accuracy: 82.4948%, Training Loss: 0.4269%\n",
      "Epoch [37/300], Step [183/225], Training Accuracy: 82.5051%, Training Loss: 0.4270%\n",
      "Epoch [37/300], Step [184/225], Training Accuracy: 82.4898%, Training Loss: 0.4276%\n",
      "Epoch [37/300], Step [185/225], Training Accuracy: 82.4831%, Training Loss: 0.4272%\n",
      "Epoch [37/300], Step [186/225], Training Accuracy: 82.4933%, Training Loss: 0.4270%\n",
      "Epoch [37/300], Step [187/225], Training Accuracy: 82.4783%, Training Loss: 0.4272%\n",
      "Epoch [37/300], Step [188/225], Training Accuracy: 82.4884%, Training Loss: 0.4272%\n",
      "Epoch [37/300], Step [189/225], Training Accuracy: 82.5149%, Training Loss: 0.4266%\n",
      "Epoch [37/300], Step [190/225], Training Accuracy: 82.5576%, Training Loss: 0.4256%\n",
      "Epoch [37/300], Step [191/225], Training Accuracy: 82.5507%, Training Loss: 0.4264%\n",
      "Epoch [37/300], Step [192/225], Training Accuracy: 82.5358%, Training Loss: 0.4262%\n",
      "Epoch [37/300], Step [193/225], Training Accuracy: 82.5615%, Training Loss: 0.4257%\n",
      "Epoch [37/300], Step [194/225], Training Accuracy: 82.5387%, Training Loss: 0.4256%\n",
      "Epoch [37/300], Step [195/225], Training Accuracy: 82.5401%, Training Loss: 0.4256%\n",
      "Epoch [37/300], Step [196/225], Training Accuracy: 82.5096%, Training Loss: 0.4263%\n",
      "Epoch [37/300], Step [197/225], Training Accuracy: 82.5032%, Training Loss: 0.4268%\n",
      "Epoch [37/300], Step [198/225], Training Accuracy: 82.4890%, Training Loss: 0.4266%\n",
      "Epoch [37/300], Step [199/225], Training Accuracy: 82.4906%, Training Loss: 0.4266%\n",
      "Epoch [37/300], Step [200/225], Training Accuracy: 82.4922%, Training Loss: 0.4266%\n",
      "Epoch [37/300], Step [201/225], Training Accuracy: 82.4860%, Training Loss: 0.4266%\n",
      "Epoch [37/300], Step [202/225], Training Accuracy: 82.5031%, Training Loss: 0.4263%\n",
      "Epoch [37/300], Step [203/225], Training Accuracy: 82.5123%, Training Loss: 0.4262%\n",
      "Epoch [37/300], Step [204/225], Training Accuracy: 82.5521%, Training Loss: 0.4252%\n",
      "Epoch [37/300], Step [205/225], Training Accuracy: 82.5838%, Training Loss: 0.4245%\n",
      "Epoch [37/300], Step [206/225], Training Accuracy: 82.5470%, Training Loss: 0.4252%\n",
      "Epoch [37/300], Step [207/225], Training Accuracy: 82.5483%, Training Loss: 0.4251%\n",
      "Epoch [37/300], Step [208/225], Training Accuracy: 82.5571%, Training Loss: 0.4252%\n",
      "Epoch [37/300], Step [209/225], Training Accuracy: 82.5733%, Training Loss: 0.4249%\n",
      "Epoch [37/300], Step [210/225], Training Accuracy: 82.5372%, Training Loss: 0.4257%\n",
      "Epoch [37/300], Step [211/225], Training Accuracy: 82.5533%, Training Loss: 0.4258%\n",
      "Epoch [37/300], Step [212/225], Training Accuracy: 82.5398%, Training Loss: 0.4255%\n",
      "Epoch [37/300], Step [213/225], Training Accuracy: 82.5264%, Training Loss: 0.4252%\n",
      "Epoch [37/300], Step [214/225], Training Accuracy: 82.5277%, Training Loss: 0.4248%\n",
      "Epoch [37/300], Step [215/225], Training Accuracy: 82.5218%, Training Loss: 0.4246%\n",
      "Epoch [37/300], Step [216/225], Training Accuracy: 82.4942%, Training Loss: 0.4251%\n",
      "Epoch [37/300], Step [217/225], Training Accuracy: 82.4597%, Training Loss: 0.4256%\n",
      "Epoch [37/300], Step [218/225], Training Accuracy: 82.4183%, Training Loss: 0.4267%\n",
      "Epoch [37/300], Step [219/225], Training Accuracy: 82.4272%, Training Loss: 0.4263%\n",
      "Epoch [37/300], Step [220/225], Training Accuracy: 82.4219%, Training Loss: 0.4265%\n",
      "Epoch [37/300], Step [221/225], Training Accuracy: 82.4590%, Training Loss: 0.4258%\n",
      "Epoch [37/300], Step [222/225], Training Accuracy: 82.4535%, Training Loss: 0.4260%\n",
      "Epoch [37/300], Step [223/225], Training Accuracy: 82.4482%, Training Loss: 0.4270%\n",
      "Epoch [37/300], Step [224/225], Training Accuracy: 82.4637%, Training Loss: 0.4267%\n",
      "Epoch [37/300], Step [225/225], Training Accuracy: 82.4833%, Training Loss: 0.4264%\n",
      "Epoch [38/300], Step [1/225], Training Accuracy: 81.2500%, Training Loss: 0.3950%\n",
      "Epoch [38/300], Step [2/225], Training Accuracy: 81.2500%, Training Loss: 0.4305%\n",
      "Epoch [38/300], Step [3/225], Training Accuracy: 78.1250%, Training Loss: 0.5047%\n",
      "Epoch [38/300], Step [4/225], Training Accuracy: 77.7344%, Training Loss: 0.5029%\n",
      "Epoch [38/300], Step [5/225], Training Accuracy: 78.7500%, Training Loss: 0.4742%\n",
      "Epoch [38/300], Step [6/225], Training Accuracy: 78.6458%, Training Loss: 0.4835%\n",
      "Epoch [38/300], Step [7/225], Training Accuracy: 79.9107%, Training Loss: 0.4793%\n",
      "Epoch [38/300], Step [8/225], Training Accuracy: 80.0781%, Training Loss: 0.4723%\n",
      "Epoch [38/300], Step [9/225], Training Accuracy: 80.3819%, Training Loss: 0.4596%\n",
      "Epoch [38/300], Step [10/225], Training Accuracy: 80.7812%, Training Loss: 0.4537%\n",
      "Epoch [38/300], Step [11/225], Training Accuracy: 81.2500%, Training Loss: 0.4440%\n",
      "Epoch [38/300], Step [12/225], Training Accuracy: 81.3802%, Training Loss: 0.4430%\n",
      "Epoch [38/300], Step [13/225], Training Accuracy: 81.8510%, Training Loss: 0.4311%\n",
      "Epoch [38/300], Step [14/225], Training Accuracy: 81.9196%, Training Loss: 0.4292%\n",
      "Epoch [38/300], Step [15/225], Training Accuracy: 81.7708%, Training Loss: 0.4309%\n",
      "Epoch [38/300], Step [16/225], Training Accuracy: 82.1289%, Training Loss: 0.4255%\n",
      "Epoch [38/300], Step [17/225], Training Accuracy: 81.7096%, Training Loss: 0.4329%\n",
      "Epoch [38/300], Step [18/225], Training Accuracy: 82.0312%, Training Loss: 0.4313%\n",
      "Epoch [38/300], Step [19/225], Training Accuracy: 82.0724%, Training Loss: 0.4292%\n",
      "Epoch [38/300], Step [20/225], Training Accuracy: 82.2656%, Training Loss: 0.4250%\n",
      "Epoch [38/300], Step [21/225], Training Accuracy: 82.6637%, Training Loss: 0.4173%\n",
      "Epoch [38/300], Step [22/225], Training Accuracy: 82.6705%, Training Loss: 0.4210%\n",
      "Epoch [38/300], Step [23/225], Training Accuracy: 82.6087%, Training Loss: 0.4249%\n",
      "Epoch [38/300], Step [24/225], Training Accuracy: 82.7474%, Training Loss: 0.4238%\n",
      "Epoch [38/300], Step [25/225], Training Accuracy: 82.8750%, Training Loss: 0.4229%\n",
      "Epoch [38/300], Step [26/225], Training Accuracy: 82.9327%, Training Loss: 0.4200%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/300], Step [27/225], Training Accuracy: 82.9282%, Training Loss: 0.4200%\n",
      "Epoch [38/300], Step [28/225], Training Accuracy: 83.1473%, Training Loss: 0.4164%\n",
      "Epoch [38/300], Step [29/225], Training Accuracy: 83.3513%, Training Loss: 0.4113%\n",
      "Epoch [38/300], Step [30/225], Training Accuracy: 83.4896%, Training Loss: 0.4087%\n",
      "Epoch [38/300], Step [31/225], Training Accuracy: 83.3669%, Training Loss: 0.4123%\n",
      "Epoch [38/300], Step [32/225], Training Accuracy: 83.3984%, Training Loss: 0.4140%\n",
      "Epoch [38/300], Step [33/225], Training Accuracy: 83.4754%, Training Loss: 0.4115%\n",
      "Epoch [38/300], Step [34/225], Training Accuracy: 83.1801%, Training Loss: 0.4167%\n",
      "Epoch [38/300], Step [35/225], Training Accuracy: 83.3036%, Training Loss: 0.4135%\n",
      "Epoch [38/300], Step [36/225], Training Accuracy: 83.3333%, Training Loss: 0.4130%\n",
      "Epoch [38/300], Step [37/225], Training Accuracy: 83.4459%, Training Loss: 0.4094%\n",
      "Epoch [38/300], Step [38/225], Training Accuracy: 83.3059%, Training Loss: 0.4110%\n",
      "Epoch [38/300], Step [39/225], Training Accuracy: 83.3734%, Training Loss: 0.4089%\n",
      "Epoch [38/300], Step [40/225], Training Accuracy: 83.2031%, Training Loss: 0.4103%\n",
      "Epoch [38/300], Step [41/225], Training Accuracy: 83.0793%, Training Loss: 0.4121%\n",
      "Epoch [38/300], Step [42/225], Training Accuracy: 82.9613%, Training Loss: 0.4136%\n",
      "Epoch [38/300], Step [43/225], Training Accuracy: 83.1032%, Training Loss: 0.4118%\n",
      "Epoch [38/300], Step [44/225], Training Accuracy: 83.2031%, Training Loss: 0.4086%\n",
      "Epoch [38/300], Step [45/225], Training Accuracy: 83.1250%, Training Loss: 0.4132%\n",
      "Epoch [38/300], Step [46/225], Training Accuracy: 83.1182%, Training Loss: 0.4124%\n",
      "Epoch [38/300], Step [47/225], Training Accuracy: 83.0452%, Training Loss: 0.4154%\n",
      "Epoch [38/300], Step [48/225], Training Accuracy: 83.0078%, Training Loss: 0.4178%\n",
      "Epoch [38/300], Step [49/225], Training Accuracy: 83.0038%, Training Loss: 0.4173%\n",
      "Epoch [38/300], Step [50/225], Training Accuracy: 83.0000%, Training Loss: 0.4181%\n",
      "Epoch [38/300], Step [51/225], Training Accuracy: 83.1801%, Training Loss: 0.4152%\n",
      "Epoch [38/300], Step [52/225], Training Accuracy: 83.3233%, Training Loss: 0.4119%\n",
      "Epoch [38/300], Step [53/225], Training Accuracy: 83.3432%, Training Loss: 0.4116%\n",
      "Epoch [38/300], Step [54/225], Training Accuracy: 83.2465%, Training Loss: 0.4123%\n",
      "Epoch [38/300], Step [55/225], Training Accuracy: 83.0114%, Training Loss: 0.4183%\n",
      "Epoch [38/300], Step [56/225], Training Accuracy: 82.9799%, Training Loss: 0.4176%\n",
      "Epoch [38/300], Step [57/225], Training Accuracy: 82.9770%, Training Loss: 0.4170%\n",
      "Epoch [38/300], Step [58/225], Training Accuracy: 82.9741%, Training Loss: 0.4171%\n",
      "Epoch [38/300], Step [59/225], Training Accuracy: 82.9449%, Training Loss: 0.4173%\n",
      "Epoch [38/300], Step [60/225], Training Accuracy: 83.0469%, Training Loss: 0.4168%\n",
      "Epoch [38/300], Step [61/225], Training Accuracy: 83.0174%, Training Loss: 0.4181%\n",
      "Epoch [38/300], Step [62/225], Training Accuracy: 83.0897%, Training Loss: 0.4162%\n",
      "Epoch [38/300], Step [63/225], Training Accuracy: 82.9365%, Training Loss: 0.4178%\n",
      "Epoch [38/300], Step [64/225], Training Accuracy: 82.9346%, Training Loss: 0.4177%\n",
      "Epoch [38/300], Step [65/225], Training Accuracy: 82.8846%, Training Loss: 0.4182%\n",
      "Epoch [38/300], Step [66/225], Training Accuracy: 82.9072%, Training Loss: 0.4187%\n",
      "Epoch [38/300], Step [67/225], Training Accuracy: 82.7659%, Training Loss: 0.4227%\n",
      "Epoch [38/300], Step [68/225], Training Accuracy: 82.7206%, Training Loss: 0.4223%\n",
      "Epoch [38/300], Step [69/225], Training Accuracy: 82.8351%, Training Loss: 0.4195%\n",
      "Epoch [38/300], Step [70/225], Training Accuracy: 82.9464%, Training Loss: 0.4178%\n",
      "Epoch [38/300], Step [71/225], Training Accuracy: 82.8785%, Training Loss: 0.4185%\n",
      "Epoch [38/300], Step [72/225], Training Accuracy: 82.7691%, Training Loss: 0.4199%\n",
      "Epoch [38/300], Step [73/225], Training Accuracy: 82.6627%, Training Loss: 0.4223%\n",
      "Epoch [38/300], Step [74/225], Training Accuracy: 82.7280%, Training Loss: 0.4216%\n",
      "Epoch [38/300], Step [75/225], Training Accuracy: 82.7292%, Training Loss: 0.4212%\n",
      "Epoch [38/300], Step [76/225], Training Accuracy: 82.5863%, Training Loss: 0.4240%\n",
      "Epoch [38/300], Step [77/225], Training Accuracy: 82.5284%, Training Loss: 0.4251%\n",
      "Epoch [38/300], Step [78/225], Training Accuracy: 82.4119%, Training Loss: 0.4258%\n",
      "Epoch [38/300], Step [79/225], Training Accuracy: 82.3774%, Training Loss: 0.4255%\n",
      "Epoch [38/300], Step [80/225], Training Accuracy: 82.3633%, Training Loss: 0.4254%\n",
      "Epoch [38/300], Step [81/225], Training Accuracy: 82.4267%, Training Loss: 0.4232%\n",
      "Epoch [38/300], Step [82/225], Training Accuracy: 82.3361%, Training Loss: 0.4258%\n",
      "Epoch [38/300], Step [83/225], Training Accuracy: 82.2666%, Training Loss: 0.4284%\n",
      "Epoch [38/300], Step [84/225], Training Accuracy: 82.2359%, Training Loss: 0.4296%\n",
      "Epoch [38/300], Step [85/225], Training Accuracy: 82.2059%, Training Loss: 0.4308%\n",
      "Epoch [38/300], Step [86/225], Training Accuracy: 82.2129%, Training Loss: 0.4321%\n",
      "Epoch [38/300], Step [87/225], Training Accuracy: 82.1300%, Training Loss: 0.4351%\n",
      "Epoch [38/300], Step [88/225], Training Accuracy: 82.0490%, Training Loss: 0.4367%\n",
      "Epoch [38/300], Step [89/225], Training Accuracy: 82.0400%, Training Loss: 0.4383%\n",
      "Epoch [38/300], Step [90/225], Training Accuracy: 81.9965%, Training Loss: 0.4395%\n",
      "Epoch [38/300], Step [91/225], Training Accuracy: 81.9712%, Training Loss: 0.4408%\n",
      "Epoch [38/300], Step [92/225], Training Accuracy: 81.8954%, Training Loss: 0.4451%\n",
      "Epoch [38/300], Step [93/225], Training Accuracy: 81.9052%, Training Loss: 0.4460%\n",
      "Epoch [38/300], Step [94/225], Training Accuracy: 81.9149%, Training Loss: 0.4460%\n",
      "Epoch [38/300], Step [95/225], Training Accuracy: 81.8586%, Training Loss: 0.4470%\n",
      "Epoch [38/300], Step [96/225], Training Accuracy: 81.8522%, Training Loss: 0.4469%\n",
      "Epoch [38/300], Step [97/225], Training Accuracy: 81.9104%, Training Loss: 0.4471%\n",
      "Epoch [38/300], Step [98/225], Training Accuracy: 81.9037%, Training Loss: 0.4470%\n",
      "Epoch [38/300], Step [99/225], Training Accuracy: 81.8813%, Training Loss: 0.4472%\n",
      "Epoch [38/300], Step [100/225], Training Accuracy: 81.8125%, Training Loss: 0.4481%\n",
      "Epoch [38/300], Step [101/225], Training Accuracy: 81.8069%, Training Loss: 0.4479%\n",
      "Epoch [38/300], Step [102/225], Training Accuracy: 81.7555%, Training Loss: 0.4501%\n",
      "Epoch [38/300], Step [103/225], Training Accuracy: 81.6899%, Training Loss: 0.4518%\n",
      "Epoch [38/300], Step [104/225], Training Accuracy: 81.7608%, Training Loss: 0.4506%\n",
      "Epoch [38/300], Step [105/225], Training Accuracy: 81.7560%, Training Loss: 0.4498%\n",
      "Epoch [38/300], Step [106/225], Training Accuracy: 81.7807%, Training Loss: 0.4498%\n",
      "Epoch [38/300], Step [107/225], Training Accuracy: 81.8049%, Training Loss: 0.4499%\n",
      "Epoch [38/300], Step [108/225], Training Accuracy: 81.7998%, Training Loss: 0.4501%\n",
      "Epoch [38/300], Step [109/225], Training Accuracy: 81.7947%, Training Loss: 0.4501%\n",
      "Epoch [38/300], Step [110/225], Training Accuracy: 81.8182%, Training Loss: 0.4496%\n",
      "Epoch [38/300], Step [111/225], Training Accuracy: 81.8271%, Training Loss: 0.4495%\n",
      "Epoch [38/300], Step [112/225], Training Accuracy: 81.8359%, Training Loss: 0.4491%\n",
      "Epoch [38/300], Step [113/225], Training Accuracy: 81.8861%, Training Loss: 0.4477%\n",
      "Epoch [38/300], Step [114/225], Training Accuracy: 81.9627%, Training Loss: 0.4473%\n",
      "Epoch [38/300], Step [115/225], Training Accuracy: 81.9837%, Training Loss: 0.4460%\n",
      "Epoch [38/300], Step [116/225], Training Accuracy: 81.9504%, Training Loss: 0.4464%\n",
      "Epoch [38/300], Step [117/225], Training Accuracy: 81.8777%, Training Loss: 0.4477%\n",
      "Epoch [38/300], Step [118/225], Training Accuracy: 81.9121%, Training Loss: 0.4472%\n",
      "Epoch [38/300], Step [119/225], Training Accuracy: 81.9984%, Training Loss: 0.4458%\n",
      "Epoch [38/300], Step [120/225], Training Accuracy: 82.0052%, Training Loss: 0.4449%\n",
      "Epoch [38/300], Step [121/225], Training Accuracy: 81.9861%, Training Loss: 0.4450%\n",
      "Epoch [38/300], Step [122/225], Training Accuracy: 81.9672%, Training Loss: 0.4446%\n",
      "Epoch [38/300], Step [123/225], Training Accuracy: 81.9741%, Training Loss: 0.4445%\n",
      "Epoch [38/300], Step [124/225], Training Accuracy: 81.9682%, Training Loss: 0.4438%\n",
      "Epoch [38/300], Step [125/225], Training Accuracy: 81.9000%, Training Loss: 0.4445%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/300], Step [126/225], Training Accuracy: 81.8824%, Training Loss: 0.4442%\n",
      "Epoch [38/300], Step [127/225], Training Accuracy: 81.9144%, Training Loss: 0.4432%\n",
      "Epoch [38/300], Step [128/225], Training Accuracy: 81.9580%, Training Loss: 0.4424%\n",
      "Epoch [38/300], Step [129/225], Training Accuracy: 81.9404%, Training Loss: 0.4421%\n",
      "Epoch [38/300], Step [130/225], Training Accuracy: 81.9471%, Training Loss: 0.4417%\n",
      "Epoch [38/300], Step [131/225], Training Accuracy: 81.8822%, Training Loss: 0.4428%\n",
      "Epoch [38/300], Step [132/225], Training Accuracy: 81.8537%, Training Loss: 0.4456%\n",
      "Epoch [38/300], Step [133/225], Training Accuracy: 81.8257%, Training Loss: 0.4463%\n",
      "Epoch [38/300], Step [134/225], Training Accuracy: 81.7980%, Training Loss: 0.4473%\n",
      "Epoch [38/300], Step [135/225], Training Accuracy: 81.8056%, Training Loss: 0.4465%\n",
      "Epoch [38/300], Step [136/225], Training Accuracy: 81.7900%, Training Loss: 0.4462%\n",
      "Epoch [38/300], Step [137/225], Training Accuracy: 81.7974%, Training Loss: 0.4465%\n",
      "Epoch [38/300], Step [138/225], Training Accuracy: 81.7935%, Training Loss: 0.4464%\n",
      "Epoch [38/300], Step [139/225], Training Accuracy: 81.7896%, Training Loss: 0.4459%\n",
      "Epoch [38/300], Step [140/225], Training Accuracy: 81.8080%, Training Loss: 0.4454%\n",
      "Epoch [38/300], Step [141/225], Training Accuracy: 81.8041%, Training Loss: 0.4462%\n",
      "Epoch [38/300], Step [142/225], Training Accuracy: 81.7892%, Training Loss: 0.4463%\n",
      "Epoch [38/300], Step [143/225], Training Accuracy: 81.7526%, Training Loss: 0.4471%\n",
      "Epoch [38/300], Step [144/225], Training Accuracy: 81.7817%, Training Loss: 0.4466%\n",
      "Epoch [38/300], Step [145/225], Training Accuracy: 81.7888%, Training Loss: 0.4465%\n",
      "Epoch [38/300], Step [146/225], Training Accuracy: 81.7851%, Training Loss: 0.4459%\n",
      "Epoch [38/300], Step [147/225], Training Accuracy: 81.8027%, Training Loss: 0.4459%\n",
      "Epoch [38/300], Step [148/225], Training Accuracy: 81.7990%, Training Loss: 0.4457%\n",
      "Epoch [38/300], Step [149/225], Training Accuracy: 81.7953%, Training Loss: 0.4451%\n",
      "Epoch [38/300], Step [150/225], Training Accuracy: 81.8542%, Training Loss: 0.4449%\n",
      "Epoch [38/300], Step [151/225], Training Accuracy: 81.8605%, Training Loss: 0.4440%\n",
      "Epoch [38/300], Step [152/225], Training Accuracy: 81.8873%, Training Loss: 0.4435%\n",
      "Epoch [38/300], Step [153/225], Training Accuracy: 81.8423%, Training Loss: 0.4440%\n",
      "Epoch [38/300], Step [154/225], Training Accuracy: 81.8689%, Training Loss: 0.4438%\n",
      "Epoch [38/300], Step [155/225], Training Accuracy: 81.8145%, Training Loss: 0.4447%\n",
      "Epoch [38/300], Step [156/225], Training Accuracy: 81.8209%, Training Loss: 0.4442%\n",
      "Epoch [38/300], Step [157/225], Training Accuracy: 81.7874%, Training Loss: 0.4443%\n",
      "Epoch [38/300], Step [158/225], Training Accuracy: 81.7939%, Training Loss: 0.4440%\n",
      "Epoch [38/300], Step [159/225], Training Accuracy: 81.7414%, Training Loss: 0.4450%\n",
      "Epoch [38/300], Step [160/225], Training Accuracy: 81.7480%, Training Loss: 0.4445%\n",
      "Epoch [38/300], Step [161/225], Training Accuracy: 81.7644%, Training Loss: 0.4441%\n",
      "Epoch [38/300], Step [162/225], Training Accuracy: 81.7805%, Training Loss: 0.4439%\n",
      "Epoch [38/300], Step [163/225], Training Accuracy: 81.8060%, Training Loss: 0.4434%\n",
      "Epoch [38/300], Step [164/225], Training Accuracy: 81.8693%, Training Loss: 0.4423%\n",
      "Epoch [38/300], Step [165/225], Training Accuracy: 81.8750%, Training Loss: 0.4418%\n",
      "Epoch [38/300], Step [166/225], Training Accuracy: 81.9089%, Training Loss: 0.4413%\n",
      "Epoch [38/300], Step [167/225], Training Accuracy: 81.9330%, Training Loss: 0.4407%\n",
      "Epoch [38/300], Step [168/225], Training Accuracy: 81.9568%, Training Loss: 0.4401%\n",
      "Epoch [38/300], Step [169/225], Training Accuracy: 81.9896%, Training Loss: 0.4397%\n",
      "Epoch [38/300], Step [170/225], Training Accuracy: 81.9669%, Training Loss: 0.4401%\n",
      "Epoch [38/300], Step [171/225], Training Accuracy: 81.9627%, Training Loss: 0.4399%\n",
      "Epoch [38/300], Step [172/225], Training Accuracy: 81.9041%, Training Loss: 0.4414%\n",
      "Epoch [38/300], Step [173/225], Training Accuracy: 81.9274%, Training Loss: 0.4409%\n",
      "Epoch [38/300], Step [174/225], Training Accuracy: 81.9864%, Training Loss: 0.4398%\n",
      "Epoch [38/300], Step [175/225], Training Accuracy: 82.0268%, Training Loss: 0.4391%\n",
      "Epoch [38/300], Step [176/225], Training Accuracy: 82.0224%, Training Loss: 0.4392%\n",
      "Epoch [38/300], Step [177/225], Training Accuracy: 82.0533%, Training Loss: 0.4382%\n",
      "Epoch [38/300], Step [178/225], Training Accuracy: 82.0751%, Training Loss: 0.4376%\n",
      "Epoch [38/300], Step [179/225], Training Accuracy: 82.1142%, Training Loss: 0.4369%\n",
      "Epoch [38/300], Step [180/225], Training Accuracy: 82.1615%, Training Loss: 0.4362%\n",
      "Epoch [38/300], Step [181/225], Training Accuracy: 82.1564%, Training Loss: 0.4361%\n",
      "Epoch [38/300], Step [182/225], Training Accuracy: 82.1514%, Training Loss: 0.4360%\n",
      "Epoch [38/300], Step [183/225], Training Accuracy: 82.1380%, Training Loss: 0.4360%\n",
      "Epoch [38/300], Step [184/225], Training Accuracy: 82.1416%, Training Loss: 0.4353%\n",
      "Epoch [38/300], Step [185/225], Training Accuracy: 82.1706%, Training Loss: 0.4348%\n",
      "Epoch [38/300], Step [186/225], Training Accuracy: 82.2245%, Training Loss: 0.4339%\n",
      "Epoch [38/300], Step [187/225], Training Accuracy: 82.2443%, Training Loss: 0.4347%\n",
      "Epoch [38/300], Step [188/225], Training Accuracy: 82.2640%, Training Loss: 0.4349%\n",
      "Epoch [38/300], Step [189/225], Training Accuracy: 82.2421%, Training Loss: 0.4353%\n",
      "Epoch [38/300], Step [190/225], Training Accuracy: 82.2533%, Training Loss: 0.4350%\n",
      "Epoch [38/300], Step [191/225], Training Accuracy: 82.2235%, Training Loss: 0.4352%\n",
      "Epoch [38/300], Step [192/225], Training Accuracy: 82.2266%, Training Loss: 0.4345%\n",
      "Epoch [38/300], Step [193/225], Training Accuracy: 82.2215%, Training Loss: 0.4343%\n",
      "Epoch [38/300], Step [194/225], Training Accuracy: 82.2568%, Training Loss: 0.4337%\n",
      "Epoch [38/300], Step [195/225], Training Accuracy: 82.2596%, Training Loss: 0.4330%\n",
      "Epoch [38/300], Step [196/225], Training Accuracy: 82.2465%, Training Loss: 0.4334%\n",
      "Epoch [38/300], Step [197/225], Training Accuracy: 82.2573%, Training Loss: 0.4333%\n",
      "Epoch [38/300], Step [198/225], Training Accuracy: 82.3074%, Training Loss: 0.4323%\n",
      "Epoch [38/300], Step [199/225], Training Accuracy: 82.3100%, Training Loss: 0.4319%\n",
      "Epoch [38/300], Step [200/225], Training Accuracy: 82.3047%, Training Loss: 0.4319%\n",
      "Epoch [38/300], Step [201/225], Training Accuracy: 82.3150%, Training Loss: 0.4314%\n",
      "Epoch [38/300], Step [202/225], Training Accuracy: 82.3097%, Training Loss: 0.4319%\n",
      "Epoch [38/300], Step [203/225], Training Accuracy: 82.3584%, Training Loss: 0.4311%\n",
      "Epoch [38/300], Step [204/225], Training Accuracy: 82.4066%, Training Loss: 0.4305%\n",
      "Epoch [38/300], Step [205/225], Training Accuracy: 82.4238%, Training Loss: 0.4303%\n",
      "Epoch [38/300], Step [206/225], Training Accuracy: 82.4333%, Training Loss: 0.4301%\n",
      "Epoch [38/300], Step [207/225], Training Accuracy: 82.4351%, Training Loss: 0.4301%\n",
      "Epoch [38/300], Step [208/225], Training Accuracy: 82.4519%, Training Loss: 0.4297%\n",
      "Epoch [38/300], Step [209/225], Training Accuracy: 82.4462%, Training Loss: 0.4297%\n",
      "Epoch [38/300], Step [210/225], Training Accuracy: 82.4628%, Training Loss: 0.4291%\n",
      "Epoch [38/300], Step [211/225], Training Accuracy: 82.4645%, Training Loss: 0.4290%\n",
      "Epoch [38/300], Step [212/225], Training Accuracy: 82.4735%, Training Loss: 0.4285%\n",
      "Epoch [38/300], Step [213/225], Training Accuracy: 82.4677%, Training Loss: 0.4283%\n",
      "Epoch [38/300], Step [214/225], Training Accuracy: 82.4474%, Training Loss: 0.4281%\n",
      "Epoch [38/300], Step [215/225], Training Accuracy: 82.4637%, Training Loss: 0.4277%\n",
      "Epoch [38/300], Step [216/225], Training Accuracy: 82.4725%, Training Loss: 0.4277%\n",
      "Epoch [38/300], Step [217/225], Training Accuracy: 82.4525%, Training Loss: 0.4283%\n",
      "Epoch [38/300], Step [218/225], Training Accuracy: 82.4756%, Training Loss: 0.4282%\n",
      "Epoch [38/300], Step [219/225], Training Accuracy: 82.4700%, Training Loss: 0.4282%\n",
      "Epoch [38/300], Step [220/225], Training Accuracy: 82.5213%, Training Loss: 0.4274%\n",
      "Epoch [38/300], Step [221/225], Training Accuracy: 82.5226%, Training Loss: 0.4273%\n",
      "Epoch [38/300], Step [222/225], Training Accuracy: 82.5099%, Training Loss: 0.4276%\n",
      "Epoch [38/300], Step [223/225], Training Accuracy: 82.5042%, Training Loss: 0.4278%\n",
      "Epoch [38/300], Step [224/225], Training Accuracy: 82.5405%, Training Loss: 0.4272%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/300], Step [225/225], Training Accuracy: 82.5528%, Training Loss: 0.4269%\n",
      "Epoch [39/300], Step [1/225], Training Accuracy: 81.2500%, Training Loss: 0.4503%\n",
      "Epoch [39/300], Step [2/225], Training Accuracy: 82.0312%, Training Loss: 0.3878%\n",
      "Epoch [39/300], Step [3/225], Training Accuracy: 84.3750%, Training Loss: 0.3542%\n",
      "Epoch [39/300], Step [4/225], Training Accuracy: 84.3750%, Training Loss: 0.3582%\n",
      "Epoch [39/300], Step [5/225], Training Accuracy: 84.0625%, Training Loss: 0.3534%\n",
      "Epoch [39/300], Step [6/225], Training Accuracy: 85.1562%, Training Loss: 0.3436%\n",
      "Epoch [39/300], Step [7/225], Training Accuracy: 85.9375%, Training Loss: 0.3396%\n",
      "Epoch [39/300], Step [8/225], Training Accuracy: 85.9375%, Training Loss: 0.3361%\n",
      "Epoch [39/300], Step [9/225], Training Accuracy: 85.4167%, Training Loss: 0.3437%\n",
      "Epoch [39/300], Step [10/225], Training Accuracy: 84.6875%, Training Loss: 0.3679%\n",
      "Epoch [39/300], Step [11/225], Training Accuracy: 84.3750%, Training Loss: 0.3743%\n",
      "Epoch [39/300], Step [12/225], Training Accuracy: 84.6354%, Training Loss: 0.3634%\n",
      "Epoch [39/300], Step [13/225], Training Accuracy: 85.2163%, Training Loss: 0.3532%\n",
      "Epoch [39/300], Step [14/225], Training Accuracy: 85.3795%, Training Loss: 0.3515%\n",
      "Epoch [39/300], Step [15/225], Training Accuracy: 85.0000%, Training Loss: 0.3705%\n",
      "Epoch [39/300], Step [16/225], Training Accuracy: 84.4727%, Training Loss: 0.3801%\n",
      "Epoch [39/300], Step [17/225], Training Accuracy: 84.1912%, Training Loss: 0.3867%\n",
      "Epoch [39/300], Step [18/225], Training Accuracy: 84.0278%, Training Loss: 0.3939%\n",
      "Epoch [39/300], Step [19/225], Training Accuracy: 84.2105%, Training Loss: 0.3922%\n",
      "Epoch [39/300], Step [20/225], Training Accuracy: 84.2969%, Training Loss: 0.3940%\n",
      "Epoch [39/300], Step [21/225], Training Accuracy: 84.3750%, Training Loss: 0.3916%\n",
      "Epoch [39/300], Step [22/225], Training Accuracy: 84.1619%, Training Loss: 0.3972%\n",
      "Epoch [39/300], Step [23/225], Training Accuracy: 83.8315%, Training Loss: 0.3979%\n",
      "Epoch [39/300], Step [24/225], Training Accuracy: 83.6589%, Training Loss: 0.4000%\n",
      "Epoch [39/300], Step [25/225], Training Accuracy: 83.5625%, Training Loss: 0.4075%\n",
      "Epoch [39/300], Step [26/225], Training Accuracy: 83.7139%, Training Loss: 0.4052%\n",
      "Epoch [39/300], Step [27/225], Training Accuracy: 83.9120%, Training Loss: 0.4004%\n",
      "Epoch [39/300], Step [28/225], Training Accuracy: 84.3750%, Training Loss: 0.3922%\n",
      "Epoch [39/300], Step [29/225], Training Accuracy: 84.3211%, Training Loss: 0.3947%\n",
      "Epoch [39/300], Step [30/225], Training Accuracy: 84.4271%, Training Loss: 0.3943%\n",
      "Epoch [39/300], Step [31/225], Training Accuracy: 83.9718%, Training Loss: 0.3983%\n",
      "Epoch [39/300], Step [32/225], Training Accuracy: 83.9844%, Training Loss: 0.3961%\n",
      "Epoch [39/300], Step [33/225], Training Accuracy: 84.0909%, Training Loss: 0.3954%\n",
      "Epoch [39/300], Step [34/225], Training Accuracy: 83.8235%, Training Loss: 0.4014%\n",
      "Epoch [39/300], Step [35/225], Training Accuracy: 83.7946%, Training Loss: 0.3982%\n",
      "Epoch [39/300], Step [36/225], Training Accuracy: 83.8108%, Training Loss: 0.4017%\n",
      "Epoch [39/300], Step [37/225], Training Accuracy: 83.8260%, Training Loss: 0.4018%\n",
      "Epoch [39/300], Step [38/225], Training Accuracy: 83.7993%, Training Loss: 0.4020%\n",
      "Epoch [39/300], Step [39/225], Training Accuracy: 83.7740%, Training Loss: 0.4033%\n",
      "Epoch [39/300], Step [40/225], Training Accuracy: 83.9453%, Training Loss: 0.4016%\n",
      "Epoch [39/300], Step [41/225], Training Accuracy: 83.8034%, Training Loss: 0.4071%\n",
      "Epoch [39/300], Step [42/225], Training Accuracy: 83.7426%, Training Loss: 0.4104%\n",
      "Epoch [39/300], Step [43/225], Training Accuracy: 83.9753%, Training Loss: 0.4076%\n",
      "Epoch [39/300], Step [44/225], Training Accuracy: 84.0199%, Training Loss: 0.4055%\n",
      "Epoch [39/300], Step [45/225], Training Accuracy: 84.0625%, Training Loss: 0.4076%\n",
      "Epoch [39/300], Step [46/225], Training Accuracy: 84.1033%, Training Loss: 0.4058%\n",
      "Epoch [39/300], Step [47/225], Training Accuracy: 83.9428%, Training Loss: 0.4089%\n",
      "Epoch [39/300], Step [48/225], Training Accuracy: 83.7565%, Training Loss: 0.4124%\n",
      "Epoch [39/300], Step [49/225], Training Accuracy: 83.8329%, Training Loss: 0.4114%\n",
      "Epoch [39/300], Step [50/225], Training Accuracy: 83.8438%, Training Loss: 0.4107%\n",
      "Epoch [39/300], Step [51/225], Training Accuracy: 83.9154%, Training Loss: 0.4093%\n",
      "Epoch [39/300], Step [52/225], Training Accuracy: 83.9243%, Training Loss: 0.4088%\n",
      "Epoch [39/300], Step [53/225], Training Accuracy: 83.8443%, Training Loss: 0.4118%\n",
      "Epoch [39/300], Step [54/225], Training Accuracy: 83.7095%, Training Loss: 0.4133%\n",
      "Epoch [39/300], Step [55/225], Training Accuracy: 83.7500%, Training Loss: 0.4126%\n",
      "Epoch [39/300], Step [56/225], Training Accuracy: 83.7891%, Training Loss: 0.4104%\n",
      "Epoch [39/300], Step [57/225], Training Accuracy: 83.6623%, Training Loss: 0.4121%\n",
      "Epoch [39/300], Step [58/225], Training Accuracy: 83.7015%, Training Loss: 0.4121%\n",
      "Epoch [39/300], Step [59/225], Training Accuracy: 83.5540%, Training Loss: 0.4136%\n",
      "Epoch [39/300], Step [60/225], Training Accuracy: 83.4635%, Training Loss: 0.4152%\n",
      "Epoch [39/300], Step [61/225], Training Accuracy: 83.3504%, Training Loss: 0.4160%\n",
      "Epoch [39/300], Step [62/225], Training Accuracy: 83.3669%, Training Loss: 0.4158%\n",
      "Epoch [39/300], Step [63/225], Training Accuracy: 83.2837%, Training Loss: 0.4175%\n",
      "Epoch [39/300], Step [64/225], Training Accuracy: 83.2031%, Training Loss: 0.4181%\n",
      "Epoch [39/300], Step [65/225], Training Accuracy: 83.1731%, Training Loss: 0.4183%\n",
      "Epoch [39/300], Step [66/225], Training Accuracy: 83.2150%, Training Loss: 0.4179%\n",
      "Epoch [39/300], Step [67/225], Training Accuracy: 83.1623%, Training Loss: 0.4188%\n",
      "Epoch [39/300], Step [68/225], Training Accuracy: 83.0653%, Training Loss: 0.4195%\n",
      "Epoch [39/300], Step [69/225], Training Accuracy: 83.0163%, Training Loss: 0.4196%\n",
      "Epoch [39/300], Step [70/225], Training Accuracy: 83.0804%, Training Loss: 0.4179%\n",
      "Epoch [39/300], Step [71/225], Training Accuracy: 82.9445%, Training Loss: 0.4197%\n",
      "Epoch [39/300], Step [72/225], Training Accuracy: 82.8993%, Training Loss: 0.4200%\n",
      "Epoch [39/300], Step [73/225], Training Accuracy: 83.0051%, Training Loss: 0.4186%\n",
      "Epoch [39/300], Step [74/225], Training Accuracy: 83.0659%, Training Loss: 0.4167%\n",
      "Epoch [39/300], Step [75/225], Training Accuracy: 83.0625%, Training Loss: 0.4161%\n",
      "Epoch [39/300], Step [76/225], Training Accuracy: 83.0181%, Training Loss: 0.4178%\n",
      "Epoch [39/300], Step [77/225], Training Accuracy: 83.0357%, Training Loss: 0.4191%\n",
      "Epoch [39/300], Step [78/225], Training Accuracy: 83.0329%, Training Loss: 0.4187%\n",
      "Epoch [39/300], Step [79/225], Training Accuracy: 83.1290%, Training Loss: 0.4170%\n",
      "Epoch [39/300], Step [80/225], Training Accuracy: 83.1445%, Training Loss: 0.4161%\n",
      "Epoch [39/300], Step [81/225], Training Accuracy: 83.1790%, Training Loss: 0.4152%\n",
      "Epoch [39/300], Step [82/225], Training Accuracy: 83.2508%, Training Loss: 0.4133%\n",
      "Epoch [39/300], Step [83/225], Training Accuracy: 83.2643%, Training Loss: 0.4126%\n",
      "Epoch [39/300], Step [84/225], Training Accuracy: 83.2589%, Training Loss: 0.4118%\n",
      "Epoch [39/300], Step [85/225], Training Accuracy: 83.2169%, Training Loss: 0.4117%\n",
      "Epoch [39/300], Step [86/225], Training Accuracy: 83.3212%, Training Loss: 0.4094%\n",
      "Epoch [39/300], Step [87/225], Training Accuracy: 83.3513%, Training Loss: 0.4092%\n",
      "Epoch [39/300], Step [88/225], Training Accuracy: 83.2209%, Training Loss: 0.4113%\n",
      "Epoch [39/300], Step [89/225], Training Accuracy: 83.1812%, Training Loss: 0.4118%\n",
      "Epoch [39/300], Step [90/225], Training Accuracy: 82.9861%, Training Loss: 0.4148%\n",
      "Epoch [39/300], Step [91/225], Training Accuracy: 82.9670%, Training Loss: 0.4152%\n",
      "Epoch [39/300], Step [92/225], Training Accuracy: 82.9823%, Training Loss: 0.4156%\n",
      "Epoch [39/300], Step [93/225], Training Accuracy: 83.0309%, Training Loss: 0.4146%\n",
      "Epoch [39/300], Step [94/225], Training Accuracy: 83.0452%, Training Loss: 0.4136%\n",
      "Epoch [39/300], Step [95/225], Training Accuracy: 83.0263%, Training Loss: 0.4132%\n",
      "Epoch [39/300], Step [96/225], Training Accuracy: 83.0892%, Training Loss: 0.4113%\n",
      "Epoch [39/300], Step [97/225], Training Accuracy: 83.1186%, Training Loss: 0.4116%\n",
      "Epoch [39/300], Step [98/225], Training Accuracy: 83.1154%, Training Loss: 0.4129%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/300], Step [99/225], Training Accuracy: 83.0966%, Training Loss: 0.4142%\n",
      "Epoch [39/300], Step [100/225], Training Accuracy: 83.0781%, Training Loss: 0.4154%\n",
      "Epoch [39/300], Step [101/225], Training Accuracy: 83.0755%, Training Loss: 0.4156%\n",
      "Epoch [39/300], Step [102/225], Training Accuracy: 83.0423%, Training Loss: 0.4177%\n",
      "Epoch [39/300], Step [103/225], Training Accuracy: 83.1311%, Training Loss: 0.4161%\n",
      "Epoch [39/300], Step [104/225], Training Accuracy: 82.9928%, Training Loss: 0.4179%\n",
      "Epoch [39/300], Step [105/225], Training Accuracy: 83.0208%, Training Loss: 0.4175%\n",
      "Epoch [39/300], Step [106/225], Training Accuracy: 83.0631%, Training Loss: 0.4169%\n",
      "Epoch [39/300], Step [107/225], Training Accuracy: 83.0169%, Training Loss: 0.4181%\n",
      "Epoch [39/300], Step [108/225], Training Accuracy: 82.9282%, Training Loss: 0.4194%\n",
      "Epoch [39/300], Step [109/225], Training Accuracy: 82.8698%, Training Loss: 0.4197%\n",
      "Epoch [39/300], Step [110/225], Training Accuracy: 82.8977%, Training Loss: 0.4185%\n",
      "Epoch [39/300], Step [111/225], Training Accuracy: 82.7703%, Training Loss: 0.4208%\n",
      "Epoch [39/300], Step [112/225], Training Accuracy: 82.7706%, Training Loss: 0.4207%\n",
      "Epoch [39/300], Step [113/225], Training Accuracy: 82.7987%, Training Loss: 0.4202%\n",
      "Epoch [39/300], Step [114/225], Training Accuracy: 82.8125%, Training Loss: 0.4205%\n",
      "Epoch [39/300], Step [115/225], Training Accuracy: 82.8940%, Training Loss: 0.4191%\n",
      "Epoch [39/300], Step [116/225], Training Accuracy: 82.7856%, Training Loss: 0.4211%\n",
      "Epoch [39/300], Step [117/225], Training Accuracy: 82.7724%, Training Loss: 0.4218%\n",
      "Epoch [39/300], Step [118/225], Training Accuracy: 82.7728%, Training Loss: 0.4219%\n",
      "Epoch [39/300], Step [119/225], Training Accuracy: 82.8125%, Training Loss: 0.4214%\n",
      "Epoch [39/300], Step [120/225], Training Accuracy: 82.7995%, Training Loss: 0.4220%\n",
      "Epoch [39/300], Step [121/225], Training Accuracy: 82.8383%, Training Loss: 0.4216%\n",
      "Epoch [39/300], Step [122/225], Training Accuracy: 82.7997%, Training Loss: 0.4217%\n",
      "Epoch [39/300], Step [123/225], Training Accuracy: 82.8125%, Training Loss: 0.4216%\n",
      "Epoch [39/300], Step [124/225], Training Accuracy: 82.8251%, Training Loss: 0.4209%\n",
      "Epoch [39/300], Step [125/225], Training Accuracy: 82.8125%, Training Loss: 0.4209%\n",
      "Epoch [39/300], Step [126/225], Training Accuracy: 82.7505%, Training Loss: 0.4220%\n",
      "Epoch [39/300], Step [127/225], Training Accuracy: 82.7756%, Training Loss: 0.4219%\n",
      "Epoch [39/300], Step [128/225], Training Accuracy: 82.7393%, Training Loss: 0.4227%\n",
      "Epoch [39/300], Step [129/225], Training Accuracy: 82.7156%, Training Loss: 0.4235%\n",
      "Epoch [39/300], Step [130/225], Training Accuracy: 82.7043%, Training Loss: 0.4239%\n",
      "Epoch [39/300], Step [131/225], Training Accuracy: 82.7171%, Training Loss: 0.4235%\n",
      "Epoch [39/300], Step [132/225], Training Accuracy: 82.7415%, Training Loss: 0.4227%\n",
      "Epoch [39/300], Step [133/225], Training Accuracy: 82.7420%, Training Loss: 0.4224%\n",
      "Epoch [39/300], Step [134/225], Training Accuracy: 82.7542%, Training Loss: 0.4219%\n",
      "Epoch [39/300], Step [135/225], Training Accuracy: 82.7315%, Training Loss: 0.4217%\n",
      "Epoch [39/300], Step [136/225], Training Accuracy: 82.6861%, Training Loss: 0.4226%\n",
      "Epoch [39/300], Step [137/225], Training Accuracy: 82.6870%, Training Loss: 0.4225%\n",
      "Epoch [39/300], Step [138/225], Training Accuracy: 82.7332%, Training Loss: 0.4212%\n",
      "Epoch [39/300], Step [139/225], Training Accuracy: 82.7451%, Training Loss: 0.4210%\n",
      "Epoch [39/300], Step [140/225], Training Accuracy: 82.7455%, Training Loss: 0.4209%\n",
      "Epoch [39/300], Step [141/225], Training Accuracy: 82.7128%, Training Loss: 0.4211%\n",
      "Epoch [39/300], Step [142/225], Training Accuracy: 82.7465%, Training Loss: 0.4205%\n",
      "Epoch [39/300], Step [143/225], Training Accuracy: 82.7360%, Training Loss: 0.4207%\n",
      "Epoch [39/300], Step [144/225], Training Accuracy: 82.7148%, Training Loss: 0.4209%\n",
      "Epoch [39/300], Step [145/225], Training Accuracy: 82.7371%, Training Loss: 0.4203%\n",
      "Epoch [39/300], Step [146/225], Training Accuracy: 82.7269%, Training Loss: 0.4205%\n",
      "Epoch [39/300], Step [147/225], Training Accuracy: 82.6849%, Training Loss: 0.4206%\n",
      "Epoch [39/300], Step [148/225], Training Accuracy: 82.7175%, Training Loss: 0.4203%\n",
      "Epoch [39/300], Step [149/225], Training Accuracy: 82.6762%, Training Loss: 0.4204%\n",
      "Epoch [39/300], Step [150/225], Training Accuracy: 82.7083%, Training Loss: 0.4194%\n",
      "Epoch [39/300], Step [151/225], Training Accuracy: 82.7608%, Training Loss: 0.4182%\n",
      "Epoch [39/300], Step [152/225], Training Accuracy: 82.7508%, Training Loss: 0.4188%\n",
      "Epoch [39/300], Step [153/225], Training Accuracy: 82.7614%, Training Loss: 0.4190%\n",
      "Epoch [39/300], Step [154/225], Training Accuracy: 82.7719%, Training Loss: 0.4189%\n",
      "Epoch [39/300], Step [155/225], Training Accuracy: 82.7923%, Training Loss: 0.4182%\n",
      "Epoch [39/300], Step [156/225], Training Accuracy: 82.8325%, Training Loss: 0.4176%\n",
      "Epoch [39/300], Step [157/225], Training Accuracy: 82.7826%, Training Loss: 0.4185%\n",
      "Epoch [39/300], Step [158/225], Training Accuracy: 82.8125%, Training Loss: 0.4182%\n",
      "Epoch [39/300], Step [159/225], Training Accuracy: 82.8322%, Training Loss: 0.4180%\n",
      "Epoch [39/300], Step [160/225], Training Accuracy: 82.8711%, Training Loss: 0.4174%\n",
      "Epoch [39/300], Step [161/225], Training Accuracy: 82.8416%, Training Loss: 0.4183%\n",
      "Epoch [39/300], Step [162/225], Training Accuracy: 82.8318%, Training Loss: 0.4182%\n",
      "Epoch [39/300], Step [163/225], Training Accuracy: 82.8700%, Training Loss: 0.4173%\n",
      "Epoch [39/300], Step [164/225], Training Accuracy: 82.9173%, Training Loss: 0.4163%\n",
      "Epoch [39/300], Step [165/225], Training Accuracy: 82.8977%, Training Loss: 0.4162%\n",
      "Epoch [39/300], Step [166/225], Training Accuracy: 82.8878%, Training Loss: 0.4164%\n",
      "Epoch [39/300], Step [167/225], Training Accuracy: 82.9341%, Training Loss: 0.4155%\n",
      "Epoch [39/300], Step [168/225], Training Accuracy: 82.8869%, Training Loss: 0.4163%\n",
      "Epoch [39/300], Step [169/225], Training Accuracy: 82.9419%, Training Loss: 0.4157%\n",
      "Epoch [39/300], Step [170/225], Training Accuracy: 82.9044%, Training Loss: 0.4158%\n",
      "Epoch [39/300], Step [171/225], Training Accuracy: 82.8490%, Training Loss: 0.4163%\n",
      "Epoch [39/300], Step [172/225], Training Accuracy: 82.8488%, Training Loss: 0.4160%\n",
      "Epoch [39/300], Step [173/225], Training Accuracy: 82.8577%, Training Loss: 0.4160%\n",
      "Epoch [39/300], Step [174/225], Training Accuracy: 82.8754%, Training Loss: 0.4152%\n",
      "Epoch [39/300], Step [175/225], Training Accuracy: 82.8839%, Training Loss: 0.4149%\n",
      "Epoch [39/300], Step [176/225], Training Accuracy: 82.8924%, Training Loss: 0.4147%\n",
      "Epoch [39/300], Step [177/225], Training Accuracy: 82.8831%, Training Loss: 0.4144%\n",
      "Epoch [39/300], Step [178/225], Training Accuracy: 82.9003%, Training Loss: 0.4140%\n",
      "Epoch [39/300], Step [179/225], Training Accuracy: 82.9347%, Training Loss: 0.4135%\n",
      "Epoch [39/300], Step [180/225], Training Accuracy: 82.9340%, Training Loss: 0.4145%\n",
      "Epoch [39/300], Step [181/225], Training Accuracy: 82.9161%, Training Loss: 0.4145%\n",
      "Epoch [39/300], Step [182/225], Training Accuracy: 82.9155%, Training Loss: 0.4142%\n",
      "Epoch [39/300], Step [183/225], Training Accuracy: 82.8296%, Training Loss: 0.4152%\n",
      "Epoch [39/300], Step [184/225], Training Accuracy: 82.8380%, Training Loss: 0.4147%\n",
      "Epoch [39/300], Step [185/225], Training Accuracy: 82.8463%, Training Loss: 0.4141%\n",
      "Epoch [39/300], Step [186/225], Training Accuracy: 82.9133%, Training Loss: 0.4131%\n",
      "Epoch [39/300], Step [187/225], Training Accuracy: 82.9044%, Training Loss: 0.4131%\n",
      "Epoch [39/300], Step [188/225], Training Accuracy: 82.9372%, Training Loss: 0.4122%\n",
      "Epoch [39/300], Step [189/225], Training Accuracy: 82.9530%, Training Loss: 0.4120%\n",
      "Epoch [39/300], Step [190/225], Training Accuracy: 82.9441%, Training Loss: 0.4120%\n",
      "Epoch [39/300], Step [191/225], Training Accuracy: 82.9188%, Training Loss: 0.4126%\n",
      "Epoch [39/300], Step [192/225], Training Accuracy: 82.9264%, Training Loss: 0.4127%\n",
      "Epoch [39/300], Step [193/225], Training Accuracy: 82.9097%, Training Loss: 0.4129%\n",
      "Epoch [39/300], Step [194/225], Training Accuracy: 82.9091%, Training Loss: 0.4131%\n",
      "Epoch [39/300], Step [195/225], Training Accuracy: 82.9407%, Training Loss: 0.4126%\n",
      "Epoch [39/300], Step [196/225], Training Accuracy: 82.9560%, Training Loss: 0.4128%\n",
      "Epoch [39/300], Step [197/225], Training Accuracy: 82.9394%, Training Loss: 0.4135%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/300], Step [198/225], Training Accuracy: 82.9624%, Training Loss: 0.4131%\n",
      "Epoch [39/300], Step [199/225], Training Accuracy: 82.9852%, Training Loss: 0.4125%\n",
      "Epoch [39/300], Step [200/225], Training Accuracy: 83.0078%, Training Loss: 0.4118%\n",
      "Epoch [39/300], Step [201/225], Training Accuracy: 83.0068%, Training Loss: 0.4117%\n",
      "Epoch [39/300], Step [202/225], Training Accuracy: 83.0213%, Training Loss: 0.4116%\n",
      "Epoch [39/300], Step [203/225], Training Accuracy: 83.0588%, Training Loss: 0.4112%\n",
      "Epoch [39/300], Step [204/225], Training Accuracy: 83.0806%, Training Loss: 0.4107%\n",
      "Epoch [39/300], Step [205/225], Training Accuracy: 83.0945%, Training Loss: 0.4104%\n",
      "Epoch [39/300], Step [206/225], Training Accuracy: 83.0400%, Training Loss: 0.4116%\n",
      "Epoch [39/300], Step [207/225], Training Accuracy: 83.0163%, Training Loss: 0.4124%\n",
      "Epoch [39/300], Step [208/225], Training Accuracy: 83.0003%, Training Loss: 0.4124%\n",
      "Epoch [39/300], Step [209/225], Training Accuracy: 82.9994%, Training Loss: 0.4123%\n",
      "Epoch [39/300], Step [210/225], Training Accuracy: 82.9985%, Training Loss: 0.4124%\n",
      "Epoch [39/300], Step [211/225], Training Accuracy: 82.9902%, Training Loss: 0.4124%\n",
      "Epoch [39/300], Step [212/225], Training Accuracy: 82.9968%, Training Loss: 0.4126%\n",
      "Epoch [39/300], Step [213/225], Training Accuracy: 82.9739%, Training Loss: 0.4130%\n",
      "Epoch [39/300], Step [214/225], Training Accuracy: 82.9512%, Training Loss: 0.4132%\n",
      "Epoch [39/300], Step [215/225], Training Accuracy: 82.9506%, Training Loss: 0.4133%\n",
      "Epoch [39/300], Step [216/225], Training Accuracy: 82.9499%, Training Loss: 0.4144%\n",
      "Epoch [39/300], Step [217/225], Training Accuracy: 82.9421%, Training Loss: 0.4149%\n",
      "Epoch [39/300], Step [218/225], Training Accuracy: 82.9415%, Training Loss: 0.4152%\n",
      "Epoch [39/300], Step [219/225], Training Accuracy: 82.9552%, Training Loss: 0.4156%\n",
      "Epoch [39/300], Step [220/225], Training Accuracy: 82.9688%, Training Loss: 0.4157%\n",
      "Epoch [39/300], Step [221/225], Training Accuracy: 82.9893%, Training Loss: 0.4156%\n",
      "Epoch [39/300], Step [222/225], Training Accuracy: 82.9955%, Training Loss: 0.4153%\n",
      "Epoch [39/300], Step [223/225], Training Accuracy: 83.0227%, Training Loss: 0.4153%\n",
      "Epoch [39/300], Step [224/225], Training Accuracy: 83.0427%, Training Loss: 0.4151%\n",
      "Epoch [39/300], Step [225/225], Training Accuracy: 83.0600%, Training Loss: 0.4147%\n",
      "Epoch [40/300], Step [1/225], Training Accuracy: 78.1250%, Training Loss: 0.4683%\n",
      "Epoch [40/300], Step [2/225], Training Accuracy: 82.0312%, Training Loss: 0.3859%\n",
      "Epoch [40/300], Step [3/225], Training Accuracy: 82.8125%, Training Loss: 0.4066%\n",
      "Epoch [40/300], Step [4/225], Training Accuracy: 83.9844%, Training Loss: 0.3894%\n",
      "Epoch [40/300], Step [5/225], Training Accuracy: 85.3125%, Training Loss: 0.3766%\n",
      "Epoch [40/300], Step [6/225], Training Accuracy: 84.3750%, Training Loss: 0.3731%\n",
      "Epoch [40/300], Step [7/225], Training Accuracy: 84.3750%, Training Loss: 0.3733%\n",
      "Epoch [40/300], Step [8/225], Training Accuracy: 83.3984%, Training Loss: 0.4123%\n",
      "Epoch [40/300], Step [9/225], Training Accuracy: 83.8542%, Training Loss: 0.4168%\n",
      "Epoch [40/300], Step [10/225], Training Accuracy: 83.9062%, Training Loss: 0.4164%\n",
      "Epoch [40/300], Step [11/225], Training Accuracy: 83.9489%, Training Loss: 0.4071%\n",
      "Epoch [40/300], Step [12/225], Training Accuracy: 83.9844%, Training Loss: 0.4166%\n",
      "Epoch [40/300], Step [13/225], Training Accuracy: 83.8942%, Training Loss: 0.4060%\n",
      "Epoch [40/300], Step [14/225], Training Accuracy: 84.4866%, Training Loss: 0.3909%\n",
      "Epoch [40/300], Step [15/225], Training Accuracy: 83.7500%, Training Loss: 0.4194%\n",
      "Epoch [40/300], Step [16/225], Training Accuracy: 83.3984%, Training Loss: 0.4286%\n",
      "Epoch [40/300], Step [17/225], Training Accuracy: 83.8235%, Training Loss: 0.4221%\n",
      "Epoch [40/300], Step [18/225], Training Accuracy: 83.6806%, Training Loss: 0.4245%\n",
      "Epoch [40/300], Step [19/225], Training Accuracy: 84.0461%, Training Loss: 0.4184%\n",
      "Epoch [40/300], Step [20/225], Training Accuracy: 84.0625%, Training Loss: 0.4175%\n",
      "Epoch [40/300], Step [21/225], Training Accuracy: 84.3006%, Training Loss: 0.4095%\n",
      "Epoch [40/300], Step [22/225], Training Accuracy: 83.8068%, Training Loss: 0.4115%\n",
      "Epoch [40/300], Step [23/225], Training Accuracy: 83.7636%, Training Loss: 0.4114%\n",
      "Epoch [40/300], Step [24/225], Training Accuracy: 83.8542%, Training Loss: 0.4104%\n",
      "Epoch [40/300], Step [25/225], Training Accuracy: 83.8750%, Training Loss: 0.4149%\n",
      "Epoch [40/300], Step [26/225], Training Accuracy: 83.8341%, Training Loss: 0.4192%\n",
      "Epoch [40/300], Step [27/225], Training Accuracy: 83.9120%, Training Loss: 0.4160%\n",
      "Epoch [40/300], Step [28/225], Training Accuracy: 84.0960%, Training Loss: 0.4105%\n",
      "Epoch [40/300], Step [29/225], Training Accuracy: 84.2134%, Training Loss: 0.4064%\n",
      "Epoch [40/300], Step [30/225], Training Accuracy: 84.4271%, Training Loss: 0.4023%\n",
      "Epoch [40/300], Step [31/225], Training Accuracy: 84.1230%, Training Loss: 0.4043%\n",
      "Epoch [40/300], Step [32/225], Training Accuracy: 84.2773%, Training Loss: 0.3987%\n",
      "Epoch [40/300], Step [33/225], Training Accuracy: 84.3277%, Training Loss: 0.3997%\n",
      "Epoch [40/300], Step [34/225], Training Accuracy: 84.2371%, Training Loss: 0.4059%\n",
      "Epoch [40/300], Step [35/225], Training Accuracy: 84.0625%, Training Loss: 0.4098%\n",
      "Epoch [40/300], Step [36/225], Training Accuracy: 84.0278%, Training Loss: 0.4098%\n",
      "Epoch [40/300], Step [37/225], Training Accuracy: 83.7838%, Training Loss: 0.4103%\n",
      "Epoch [40/300], Step [38/225], Training Accuracy: 83.7171%, Training Loss: 0.4090%\n",
      "Epoch [40/300], Step [39/225], Training Accuracy: 83.5337%, Training Loss: 0.4102%\n",
      "Epoch [40/300], Step [40/225], Training Accuracy: 83.4766%, Training Loss: 0.4101%\n",
      "Epoch [40/300], Step [41/225], Training Accuracy: 83.4985%, Training Loss: 0.4096%\n",
      "Epoch [40/300], Step [42/225], Training Accuracy: 83.4449%, Training Loss: 0.4135%\n",
      "Epoch [40/300], Step [43/225], Training Accuracy: 83.4666%, Training Loss: 0.4124%\n",
      "Epoch [40/300], Step [44/225], Training Accuracy: 83.6293%, Training Loss: 0.4100%\n",
      "Epoch [40/300], Step [45/225], Training Accuracy: 83.4722%, Training Loss: 0.4099%\n",
      "Epoch [40/300], Step [46/225], Training Accuracy: 83.6957%, Training Loss: 0.4074%\n",
      "Epoch [40/300], Step [47/225], Training Accuracy: 83.7434%, Training Loss: 0.4061%\n",
      "Epoch [40/300], Step [48/225], Training Accuracy: 83.5938%, Training Loss: 0.4084%\n",
      "Epoch [40/300], Step [49/225], Training Accuracy: 83.6097%, Training Loss: 0.4075%\n",
      "Epoch [40/300], Step [50/225], Training Accuracy: 83.5000%, Training Loss: 0.4094%\n",
      "Epoch [40/300], Step [51/225], Training Accuracy: 83.6091%, Training Loss: 0.4078%\n",
      "Epoch [40/300], Step [52/225], Training Accuracy: 83.5637%, Training Loss: 0.4099%\n",
      "Epoch [40/300], Step [53/225], Training Accuracy: 83.6969%, Training Loss: 0.4076%\n",
      "Epoch [40/300], Step [54/225], Training Accuracy: 83.6806%, Training Loss: 0.4073%\n",
      "Epoch [40/300], Step [55/225], Training Accuracy: 83.6932%, Training Loss: 0.4081%\n",
      "Epoch [40/300], Step [56/225], Training Accuracy: 83.7333%, Training Loss: 0.4074%\n",
      "Epoch [40/300], Step [57/225], Training Accuracy: 83.6349%, Training Loss: 0.4086%\n",
      "Epoch [40/300], Step [58/225], Training Accuracy: 83.5129%, Training Loss: 0.4112%\n",
      "Epoch [40/300], Step [59/225], Training Accuracy: 83.4481%, Training Loss: 0.4118%\n",
      "Epoch [40/300], Step [60/225], Training Accuracy: 83.5417%, Training Loss: 0.4096%\n",
      "Epoch [40/300], Step [61/225], Training Accuracy: 83.5041%, Training Loss: 0.4103%\n",
      "Epoch [40/300], Step [62/225], Training Accuracy: 83.5181%, Training Loss: 0.4103%\n",
      "Epoch [40/300], Step [63/225], Training Accuracy: 83.5813%, Training Loss: 0.4090%\n",
      "Epoch [40/300], Step [64/225], Training Accuracy: 83.6670%, Training Loss: 0.4075%\n",
      "Epoch [40/300], Step [65/225], Training Accuracy: 83.7500%, Training Loss: 0.4071%\n",
      "Epoch [40/300], Step [66/225], Training Accuracy: 83.7831%, Training Loss: 0.4056%\n",
      "Epoch [40/300], Step [67/225], Training Accuracy: 83.7920%, Training Loss: 0.4045%\n",
      "Epoch [40/300], Step [68/225], Training Accuracy: 83.8465%, Training Loss: 0.4035%\n",
      "Epoch [40/300], Step [69/225], Training Accuracy: 83.9221%, Training Loss: 0.4013%\n",
      "Epoch [40/300], Step [70/225], Training Accuracy: 83.9509%, Training Loss: 0.4003%\n",
      "Epoch [40/300], Step [71/225], Training Accuracy: 83.9789%, Training Loss: 0.4012%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/300], Step [72/225], Training Accuracy: 83.8976%, Training Loss: 0.4038%\n",
      "Epoch [40/300], Step [73/225], Training Accuracy: 83.9683%, Training Loss: 0.4019%\n",
      "Epoch [40/300], Step [74/225], Training Accuracy: 83.9738%, Training Loss: 0.4015%\n",
      "Epoch [40/300], Step [75/225], Training Accuracy: 84.0208%, Training Loss: 0.4002%\n",
      "Epoch [40/300], Step [76/225], Training Accuracy: 83.9433%, Training Loss: 0.4015%\n",
      "Epoch [40/300], Step [77/225], Training Accuracy: 83.8880%, Training Loss: 0.4017%\n",
      "Epoch [40/300], Step [78/225], Training Accuracy: 83.8542%, Training Loss: 0.4011%\n",
      "Epoch [40/300], Step [79/225], Training Accuracy: 83.9003%, Training Loss: 0.3999%\n",
      "Epoch [40/300], Step [80/225], Training Accuracy: 83.8672%, Training Loss: 0.4003%\n",
      "Epoch [40/300], Step [81/225], Training Accuracy: 83.9120%, Training Loss: 0.3989%\n",
      "Epoch [40/300], Step [82/225], Training Accuracy: 83.9558%, Training Loss: 0.3978%\n",
      "Epoch [40/300], Step [83/225], Training Accuracy: 83.9608%, Training Loss: 0.3968%\n",
      "Epoch [40/300], Step [84/225], Training Accuracy: 83.9844%, Training Loss: 0.3969%\n",
      "Epoch [40/300], Step [85/225], Training Accuracy: 84.0441%, Training Loss: 0.3971%\n",
      "Epoch [40/300], Step [86/225], Training Accuracy: 84.1206%, Training Loss: 0.3954%\n",
      "Epoch [40/300], Step [87/225], Training Accuracy: 84.0876%, Training Loss: 0.3962%\n",
      "Epoch [40/300], Step [88/225], Training Accuracy: 84.0732%, Training Loss: 0.3960%\n",
      "Epoch [40/300], Step [89/225], Training Accuracy: 84.0590%, Training Loss: 0.3953%\n",
      "Epoch [40/300], Step [90/225], Training Accuracy: 83.9583%, Training Loss: 0.3977%\n",
      "Epoch [40/300], Step [91/225], Training Accuracy: 83.8255%, Training Loss: 0.4006%\n",
      "Epoch [40/300], Step [92/225], Training Accuracy: 83.8485%, Training Loss: 0.3999%\n",
      "Epoch [40/300], Step [93/225], Training Accuracy: 83.8710%, Training Loss: 0.3989%\n",
      "Epoch [40/300], Step [94/225], Training Accuracy: 83.8930%, Training Loss: 0.3983%\n",
      "Epoch [40/300], Step [95/225], Training Accuracy: 83.9474%, Training Loss: 0.3975%\n",
      "Epoch [40/300], Step [96/225], Training Accuracy: 84.0007%, Training Loss: 0.3967%\n",
      "Epoch [40/300], Step [97/225], Training Accuracy: 84.0689%, Training Loss: 0.3965%\n",
      "Epoch [40/300], Step [98/225], Training Accuracy: 84.0083%, Training Loss: 0.3970%\n",
      "Epoch [40/300], Step [99/225], Training Accuracy: 84.0593%, Training Loss: 0.3960%\n",
      "Epoch [40/300], Step [100/225], Training Accuracy: 83.9844%, Training Loss: 0.3972%\n",
      "Epoch [40/300], Step [101/225], Training Accuracy: 83.9728%, Training Loss: 0.3968%\n",
      "Epoch [40/300], Step [102/225], Training Accuracy: 83.9767%, Training Loss: 0.3974%\n",
      "Epoch [40/300], Step [103/225], Training Accuracy: 84.0109%, Training Loss: 0.3967%\n",
      "Epoch [40/300], Step [104/225], Training Accuracy: 84.0595%, Training Loss: 0.3956%\n",
      "Epoch [40/300], Step [105/225], Training Accuracy: 84.0774%, Training Loss: 0.3952%\n",
      "Epoch [40/300], Step [106/225], Training Accuracy: 84.1097%, Training Loss: 0.3958%\n",
      "Epoch [40/300], Step [107/225], Training Accuracy: 84.1268%, Training Loss: 0.3958%\n",
      "Epoch [40/300], Step [108/225], Training Accuracy: 84.1291%, Training Loss: 0.3960%\n",
      "Epoch [40/300], Step [109/225], Training Accuracy: 84.1026%, Training Loss: 0.3972%\n",
      "Epoch [40/300], Step [110/225], Training Accuracy: 84.0483%, Training Loss: 0.3985%\n",
      "Epoch [40/300], Step [111/225], Training Accuracy: 84.0935%, Training Loss: 0.3980%\n",
      "Epoch [40/300], Step [112/225], Training Accuracy: 84.1239%, Training Loss: 0.3971%\n",
      "Epoch [40/300], Step [113/225], Training Accuracy: 84.0985%, Training Loss: 0.3967%\n",
      "Epoch [40/300], Step [114/225], Training Accuracy: 84.1146%, Training Loss: 0.3961%\n",
      "Epoch [40/300], Step [115/225], Training Accuracy: 84.1712%, Training Loss: 0.3951%\n",
      "Epoch [40/300], Step [116/225], Training Accuracy: 84.1460%, Training Loss: 0.3957%\n",
      "Epoch [40/300], Step [117/225], Training Accuracy: 84.1346%, Training Loss: 0.3966%\n",
      "Epoch [40/300], Step [118/225], Training Accuracy: 84.1102%, Training Loss: 0.3971%\n",
      "Epoch [40/300], Step [119/225], Training Accuracy: 84.0861%, Training Loss: 0.3970%\n",
      "Epoch [40/300], Step [120/225], Training Accuracy: 84.0755%, Training Loss: 0.3973%\n",
      "Epoch [40/300], Step [121/225], Training Accuracy: 84.0522%, Training Loss: 0.3986%\n",
      "Epoch [40/300], Step [122/225], Training Accuracy: 84.0804%, Training Loss: 0.3981%\n",
      "Epoch [40/300], Step [123/225], Training Accuracy: 84.0828%, Training Loss: 0.3988%\n",
      "Epoch [40/300], Step [124/225], Training Accuracy: 84.0978%, Training Loss: 0.3984%\n",
      "Epoch [40/300], Step [125/225], Training Accuracy: 84.1625%, Training Loss: 0.3973%\n",
      "Epoch [40/300], Step [126/225], Training Accuracy: 84.1518%, Training Loss: 0.3977%\n",
      "Epoch [40/300], Step [127/225], Training Accuracy: 84.1289%, Training Loss: 0.3983%\n",
      "Epoch [40/300], Step [128/225], Training Accuracy: 84.1309%, Training Loss: 0.3981%\n",
      "Epoch [40/300], Step [129/225], Training Accuracy: 84.0237%, Training Loss: 0.3997%\n",
      "Epoch [40/300], Step [130/225], Training Accuracy: 84.0264%, Training Loss: 0.3999%\n",
      "Epoch [40/300], Step [131/225], Training Accuracy: 83.9933%, Training Loss: 0.4002%\n",
      "Epoch [40/300], Step [132/225], Training Accuracy: 83.9844%, Training Loss: 0.4005%\n",
      "Epoch [40/300], Step [133/225], Training Accuracy: 83.9286%, Training Loss: 0.4011%\n",
      "Epoch [40/300], Step [134/225], Training Accuracy: 83.8969%, Training Loss: 0.4026%\n",
      "Epoch [40/300], Step [135/225], Training Accuracy: 83.8773%, Training Loss: 0.4028%\n",
      "Epoch [40/300], Step [136/225], Training Accuracy: 83.9040%, Training Loss: 0.4026%\n",
      "Epoch [40/300], Step [137/225], Training Accuracy: 83.9188%, Training Loss: 0.4022%\n",
      "Epoch [40/300], Step [138/225], Training Accuracy: 83.9900%, Training Loss: 0.4006%\n",
      "Epoch [40/300], Step [139/225], Training Accuracy: 83.9928%, Training Loss: 0.4004%\n",
      "Epoch [40/300], Step [140/225], Training Accuracy: 83.9844%, Training Loss: 0.4006%\n",
      "Epoch [40/300], Step [141/225], Training Accuracy: 83.9539%, Training Loss: 0.4011%\n",
      "Epoch [40/300], Step [142/225], Training Accuracy: 83.9349%, Training Loss: 0.4015%\n",
      "Epoch [40/300], Step [143/225], Training Accuracy: 83.9489%, Training Loss: 0.4016%\n",
      "Epoch [40/300], Step [144/225], Training Accuracy: 83.9735%, Training Loss: 0.4009%\n",
      "Epoch [40/300], Step [145/225], Training Accuracy: 83.9547%, Training Loss: 0.4007%\n",
      "Epoch [40/300], Step [146/225], Training Accuracy: 83.9576%, Training Loss: 0.4007%\n",
      "Epoch [40/300], Step [147/225], Training Accuracy: 83.9817%, Training Loss: 0.4005%\n",
      "Epoch [40/300], Step [148/225], Training Accuracy: 84.0160%, Training Loss: 0.3991%\n",
      "Epoch [40/300], Step [149/225], Training Accuracy: 84.0080%, Training Loss: 0.3988%\n",
      "Epoch [40/300], Step [150/225], Training Accuracy: 84.0729%, Training Loss: 0.3974%\n",
      "Epoch [40/300], Step [151/225], Training Accuracy: 84.0439%, Training Loss: 0.3980%\n",
      "Epoch [40/300], Step [152/225], Training Accuracy: 84.0563%, Training Loss: 0.3979%\n",
      "Epoch [40/300], Step [153/225], Training Accuracy: 84.0686%, Training Loss: 0.3974%\n",
      "Epoch [40/300], Step [154/225], Training Accuracy: 84.0909%, Training Loss: 0.3969%\n",
      "Epoch [40/300], Step [155/225], Training Accuracy: 84.0524%, Training Loss: 0.3971%\n",
      "Epoch [40/300], Step [156/225], Training Accuracy: 84.0345%, Training Loss: 0.3973%\n",
      "Epoch [40/300], Step [157/225], Training Accuracy: 84.0466%, Training Loss: 0.3984%\n",
      "Epoch [40/300], Step [158/225], Training Accuracy: 84.0091%, Training Loss: 0.3996%\n",
      "Epoch [40/300], Step [159/225], Training Accuracy: 84.0311%, Training Loss: 0.3996%\n",
      "Epoch [40/300], Step [160/225], Training Accuracy: 84.0430%, Training Loss: 0.3997%\n",
      "Epoch [40/300], Step [161/225], Training Accuracy: 84.0256%, Training Loss: 0.3998%\n",
      "Epoch [40/300], Step [162/225], Training Accuracy: 84.0085%, Training Loss: 0.3997%\n",
      "Epoch [40/300], Step [163/225], Training Accuracy: 84.0587%, Training Loss: 0.3990%\n",
      "Epoch [40/300], Step [164/225], Training Accuracy: 84.0796%, Training Loss: 0.3984%\n",
      "Epoch [40/300], Step [165/225], Training Accuracy: 84.0341%, Training Loss: 0.3987%\n",
      "Epoch [40/300], Step [166/225], Training Accuracy: 83.9891%, Training Loss: 0.3997%\n",
      "Epoch [40/300], Step [167/225], Training Accuracy: 83.9446%, Training Loss: 0.4002%\n",
      "Epoch [40/300], Step [168/225], Training Accuracy: 83.9379%, Training Loss: 0.4004%\n",
      "Epoch [40/300], Step [169/225], Training Accuracy: 83.9959%, Training Loss: 0.3990%\n",
      "Epoch [40/300], Step [170/225], Training Accuracy: 83.9706%, Training Loss: 0.3997%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/300], Step [171/225], Training Accuracy: 83.9547%, Training Loss: 0.4002%\n",
      "Epoch [40/300], Step [172/225], Training Accuracy: 83.9390%, Training Loss: 0.4000%\n",
      "Epoch [40/300], Step [173/225], Training Accuracy: 83.9505%, Training Loss: 0.3996%\n",
      "Epoch [40/300], Step [174/225], Training Accuracy: 84.0068%, Training Loss: 0.3987%\n",
      "Epoch [40/300], Step [175/225], Training Accuracy: 84.0179%, Training Loss: 0.3986%\n",
      "Epoch [40/300], Step [176/225], Training Accuracy: 84.0288%, Training Loss: 0.3986%\n",
      "Epoch [40/300], Step [177/225], Training Accuracy: 84.0307%, Training Loss: 0.3984%\n",
      "Epoch [40/300], Step [178/225], Training Accuracy: 84.0327%, Training Loss: 0.3978%\n",
      "Epoch [40/300], Step [179/225], Training Accuracy: 84.0433%, Training Loss: 0.3972%\n",
      "Epoch [40/300], Step [180/225], Training Accuracy: 84.0712%, Training Loss: 0.3972%\n",
      "Epoch [40/300], Step [181/225], Training Accuracy: 84.0642%, Training Loss: 0.3974%\n",
      "Epoch [40/300], Step [182/225], Training Accuracy: 84.1003%, Training Loss: 0.3965%\n",
      "Epoch [40/300], Step [183/225], Training Accuracy: 84.0847%, Training Loss: 0.3970%\n",
      "Epoch [40/300], Step [184/225], Training Accuracy: 84.0608%, Training Loss: 0.3970%\n",
      "Epoch [40/300], Step [185/225], Training Accuracy: 84.0034%, Training Loss: 0.3977%\n",
      "Epoch [40/300], Step [186/225], Training Accuracy: 84.0222%, Training Loss: 0.3973%\n",
      "Epoch [40/300], Step [187/225], Training Accuracy: 83.9906%, Training Loss: 0.3979%\n",
      "Epoch [40/300], Step [188/225], Training Accuracy: 84.0010%, Training Loss: 0.3983%\n",
      "Epoch [40/300], Step [189/225], Training Accuracy: 84.0278%, Training Loss: 0.3977%\n",
      "Epoch [40/300], Step [190/225], Training Accuracy: 84.0707%, Training Loss: 0.3970%\n",
      "Epoch [40/300], Step [191/225], Training Accuracy: 84.0969%, Training Loss: 0.3971%\n",
      "Epoch [40/300], Step [192/225], Training Accuracy: 84.0820%, Training Loss: 0.3969%\n",
      "Epoch [40/300], Step [193/225], Training Accuracy: 84.0835%, Training Loss: 0.3966%\n",
      "Epoch [40/300], Step [194/225], Training Accuracy: 84.0609%, Training Loss: 0.3967%\n",
      "Epoch [40/300], Step [195/225], Training Accuracy: 84.0946%, Training Loss: 0.3962%\n",
      "Epoch [40/300], Step [196/225], Training Accuracy: 84.0721%, Training Loss: 0.3963%\n",
      "Epoch [40/300], Step [197/225], Training Accuracy: 84.0974%, Training Loss: 0.3956%\n",
      "Epoch [40/300], Step [198/225], Training Accuracy: 84.1146%, Training Loss: 0.3959%\n",
      "Epoch [40/300], Step [199/225], Training Accuracy: 84.1080%, Training Loss: 0.3954%\n",
      "Epoch [40/300], Step [200/225], Training Accuracy: 84.1406%, Training Loss: 0.3952%\n",
      "Epoch [40/300], Step [201/225], Training Accuracy: 84.1418%, Training Loss: 0.3947%\n",
      "Epoch [40/300], Step [202/225], Training Accuracy: 84.1275%, Training Loss: 0.3953%\n",
      "Epoch [40/300], Step [203/225], Training Accuracy: 84.1672%, Training Loss: 0.3945%\n",
      "Epoch [40/300], Step [204/225], Training Accuracy: 84.1988%, Training Loss: 0.3938%\n",
      "Epoch [40/300], Step [205/225], Training Accuracy: 84.2149%, Training Loss: 0.3934%\n",
      "Epoch [40/300], Step [206/225], Training Accuracy: 84.2536%, Training Loss: 0.3931%\n",
      "Epoch [40/300], Step [207/225], Training Accuracy: 84.2467%, Training Loss: 0.3927%\n",
      "Epoch [40/300], Step [208/225], Training Accuracy: 84.2323%, Training Loss: 0.3931%\n",
      "Epoch [40/300], Step [209/225], Training Accuracy: 84.2031%, Training Loss: 0.3929%\n",
      "Epoch [40/300], Step [210/225], Training Accuracy: 84.1890%, Training Loss: 0.3929%\n",
      "Epoch [40/300], Step [211/225], Training Accuracy: 84.2047%, Training Loss: 0.3926%\n",
      "Epoch [40/300], Step [212/225], Training Accuracy: 84.2129%, Training Loss: 0.3922%\n",
      "Epoch [40/300], Step [213/225], Training Accuracy: 84.2356%, Training Loss: 0.3917%\n",
      "Epoch [40/300], Step [214/225], Training Accuracy: 84.2436%, Training Loss: 0.3915%\n",
      "Epoch [40/300], Step [215/225], Training Accuracy: 84.2151%, Training Loss: 0.3913%\n",
      "Epoch [40/300], Step [216/225], Training Accuracy: 84.2159%, Training Loss: 0.3914%\n",
      "Epoch [40/300], Step [217/225], Training Accuracy: 84.2166%, Training Loss: 0.3911%\n",
      "Epoch [40/300], Step [218/225], Training Accuracy: 84.1456%, Training Loss: 0.3925%\n",
      "Epoch [40/300], Step [219/225], Training Accuracy: 84.1610%, Training Loss: 0.3925%\n",
      "Epoch [40/300], Step [220/225], Training Accuracy: 84.1264%, Training Loss: 0.3927%\n",
      "Epoch [40/300], Step [221/225], Training Accuracy: 84.1275%, Training Loss: 0.3924%\n",
      "Epoch [40/300], Step [222/225], Training Accuracy: 84.1357%, Training Loss: 0.3921%\n",
      "Epoch [40/300], Step [223/225], Training Accuracy: 84.1298%, Training Loss: 0.3920%\n",
      "Epoch [40/300], Step [224/225], Training Accuracy: 84.1239%, Training Loss: 0.3917%\n",
      "Epoch [40/300], Step [225/225], Training Accuracy: 84.1440%, Training Loss: 0.3911%\n",
      "Epoch [41/300], Step [1/225], Training Accuracy: 78.1250%, Training Loss: 0.4678%\n",
      "Epoch [41/300], Step [2/225], Training Accuracy: 84.3750%, Training Loss: 0.4246%\n",
      "Epoch [41/300], Step [3/225], Training Accuracy: 84.3750%, Training Loss: 0.3963%\n",
      "Epoch [41/300], Step [4/225], Training Accuracy: 83.5938%, Training Loss: 0.4021%\n",
      "Epoch [41/300], Step [5/225], Training Accuracy: 83.4375%, Training Loss: 0.3827%\n",
      "Epoch [41/300], Step [6/225], Training Accuracy: 83.0729%, Training Loss: 0.3864%\n",
      "Epoch [41/300], Step [7/225], Training Accuracy: 83.4821%, Training Loss: 0.3870%\n",
      "Epoch [41/300], Step [8/225], Training Accuracy: 83.5938%, Training Loss: 0.3851%\n",
      "Epoch [41/300], Step [9/225], Training Accuracy: 83.3333%, Training Loss: 0.4005%\n",
      "Epoch [41/300], Step [10/225], Training Accuracy: 82.9688%, Training Loss: 0.4141%\n",
      "Epoch [41/300], Step [11/225], Training Accuracy: 82.5284%, Training Loss: 0.4230%\n",
      "Epoch [41/300], Step [12/225], Training Accuracy: 83.2031%, Training Loss: 0.4082%\n",
      "Epoch [41/300], Step [13/225], Training Accuracy: 83.8942%, Training Loss: 0.4018%\n",
      "Epoch [41/300], Step [14/225], Training Accuracy: 83.7054%, Training Loss: 0.4170%\n",
      "Epoch [41/300], Step [15/225], Training Accuracy: 83.8542%, Training Loss: 0.4133%\n",
      "Epoch [41/300], Step [16/225], Training Accuracy: 83.7891%, Training Loss: 0.4170%\n",
      "Epoch [41/300], Step [17/225], Training Accuracy: 83.5478%, Training Loss: 0.4131%\n",
      "Epoch [41/300], Step [18/225], Training Accuracy: 83.5069%, Training Loss: 0.4145%\n",
      "Epoch [41/300], Step [19/225], Training Accuracy: 83.2237%, Training Loss: 0.4132%\n",
      "Epoch [41/300], Step [20/225], Training Accuracy: 83.2812%, Training Loss: 0.4074%\n",
      "Epoch [41/300], Step [21/225], Training Accuracy: 83.5565%, Training Loss: 0.4006%\n",
      "Epoch [41/300], Step [22/225], Training Accuracy: 83.2386%, Training Loss: 0.4083%\n",
      "Epoch [41/300], Step [23/225], Training Accuracy: 83.2880%, Training Loss: 0.4079%\n",
      "Epoch [41/300], Step [24/225], Training Accuracy: 83.0729%, Training Loss: 0.4148%\n",
      "Epoch [41/300], Step [25/225], Training Accuracy: 83.1250%, Training Loss: 0.4118%\n",
      "Epoch [41/300], Step [26/225], Training Accuracy: 83.1731%, Training Loss: 0.4137%\n",
      "Epoch [41/300], Step [27/225], Training Accuracy: 83.1597%, Training Loss: 0.4136%\n",
      "Epoch [41/300], Step [28/225], Training Accuracy: 83.1473%, Training Loss: 0.4195%\n",
      "Epoch [41/300], Step [29/225], Training Accuracy: 83.4052%, Training Loss: 0.4159%\n",
      "Epoch [41/300], Step [30/225], Training Accuracy: 83.4375%, Training Loss: 0.4156%\n",
      "Epoch [41/300], Step [31/225], Training Accuracy: 83.1149%, Training Loss: 0.4228%\n",
      "Epoch [41/300], Step [32/225], Training Accuracy: 82.9102%, Training Loss: 0.4334%\n",
      "Epoch [41/300], Step [33/225], Training Accuracy: 82.8125%, Training Loss: 0.4365%\n",
      "Epoch [41/300], Step [34/225], Training Accuracy: 82.7206%, Training Loss: 0.4403%\n",
      "Epoch [41/300], Step [35/225], Training Accuracy: 82.9018%, Training Loss: 0.4352%\n",
      "Epoch [41/300], Step [36/225], Training Accuracy: 82.9861%, Training Loss: 0.4337%\n",
      "Epoch [41/300], Step [37/225], Training Accuracy: 83.1503%, Training Loss: 0.4301%\n",
      "Epoch [41/300], Step [38/225], Training Accuracy: 83.1414%, Training Loss: 0.4285%\n",
      "Epoch [41/300], Step [39/225], Training Accuracy: 83.1731%, Training Loss: 0.4292%\n",
      "Epoch [41/300], Step [40/225], Training Accuracy: 83.0859%, Training Loss: 0.4313%\n",
      "Epoch [41/300], Step [41/225], Training Accuracy: 82.8506%, Training Loss: 0.4358%\n",
      "Epoch [41/300], Step [42/225], Training Accuracy: 82.8497%, Training Loss: 0.4346%\n",
      "Epoch [41/300], Step [43/225], Training Accuracy: 82.7035%, Training Loss: 0.4352%\n",
      "Epoch [41/300], Step [44/225], Training Accuracy: 82.5994%, Training Loss: 0.4360%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/300], Step [45/225], Training Accuracy: 82.7083%, Training Loss: 0.4344%\n",
      "Epoch [41/300], Step [46/225], Training Accuracy: 82.7785%, Training Loss: 0.4310%\n",
      "Epoch [41/300], Step [47/225], Training Accuracy: 82.7128%, Training Loss: 0.4304%\n",
      "Epoch [41/300], Step [48/225], Training Accuracy: 82.5521%, Training Loss: 0.4326%\n",
      "Epoch [41/300], Step [49/225], Training Accuracy: 82.5893%, Training Loss: 0.4315%\n",
      "Epoch [41/300], Step [50/225], Training Accuracy: 82.5000%, Training Loss: 0.4339%\n",
      "Epoch [41/300], Step [51/225], Training Accuracy: 82.5061%, Training Loss: 0.4309%\n",
      "Epoch [41/300], Step [52/225], Training Accuracy: 82.6923%, Training Loss: 0.4281%\n",
      "Epoch [41/300], Step [53/225], Training Accuracy: 82.7830%, Training Loss: 0.4271%\n",
      "Epoch [41/300], Step [54/225], Training Accuracy: 82.7836%, Training Loss: 0.4284%\n",
      "Epoch [41/300], Step [55/225], Training Accuracy: 82.6420%, Training Loss: 0.4307%\n",
      "Epoch [41/300], Step [56/225], Training Accuracy: 82.7009%, Training Loss: 0.4292%\n",
      "Epoch [41/300], Step [57/225], Training Accuracy: 82.6206%, Training Loss: 0.4297%\n",
      "Epoch [41/300], Step [58/225], Training Accuracy: 82.6509%, Training Loss: 0.4290%\n",
      "Epoch [41/300], Step [59/225], Training Accuracy: 82.7331%, Training Loss: 0.4271%\n",
      "Epoch [41/300], Step [60/225], Training Accuracy: 82.5781%, Training Loss: 0.4270%\n",
      "Epoch [41/300], Step [61/225], Training Accuracy: 82.5051%, Training Loss: 0.4286%\n",
      "Epoch [41/300], Step [62/225], Training Accuracy: 82.5605%, Training Loss: 0.4276%\n",
      "Epoch [41/300], Step [63/225], Training Accuracy: 82.7133%, Training Loss: 0.4253%\n",
      "Epoch [41/300], Step [64/225], Training Accuracy: 82.7393%, Training Loss: 0.4273%\n",
      "Epoch [41/300], Step [65/225], Training Accuracy: 82.6683%, Training Loss: 0.4304%\n",
      "Epoch [41/300], Step [66/225], Training Accuracy: 82.7178%, Training Loss: 0.4298%\n",
      "Epoch [41/300], Step [67/225], Training Accuracy: 82.7192%, Training Loss: 0.4291%\n",
      "Epoch [41/300], Step [68/225], Training Accuracy: 82.6517%, Training Loss: 0.4298%\n",
      "Epoch [41/300], Step [69/225], Training Accuracy: 82.5861%, Training Loss: 0.4297%\n",
      "Epoch [41/300], Step [70/225], Training Accuracy: 82.5893%, Training Loss: 0.4302%\n",
      "Epoch [41/300], Step [71/225], Training Accuracy: 82.5924%, Training Loss: 0.4301%\n",
      "Epoch [41/300], Step [72/225], Training Accuracy: 82.6823%, Training Loss: 0.4295%\n",
      "Epoch [41/300], Step [73/225], Training Accuracy: 82.8125%, Training Loss: 0.4281%\n",
      "Epoch [41/300], Step [74/225], Training Accuracy: 82.7914%, Training Loss: 0.4262%\n",
      "Epoch [41/300], Step [75/225], Training Accuracy: 82.9167%, Training Loss: 0.4245%\n",
      "Epoch [41/300], Step [76/225], Training Accuracy: 82.9153%, Training Loss: 0.4254%\n",
      "Epoch [41/300], Step [77/225], Training Accuracy: 82.8328%, Training Loss: 0.4269%\n",
      "Epoch [41/300], Step [78/225], Training Accuracy: 82.8726%, Training Loss: 0.4257%\n",
      "Epoch [41/300], Step [79/225], Training Accuracy: 82.8718%, Training Loss: 0.4246%\n",
      "Epoch [41/300], Step [80/225], Training Accuracy: 82.9492%, Training Loss: 0.4233%\n",
      "Epoch [41/300], Step [81/225], Training Accuracy: 83.0247%, Training Loss: 0.4214%\n",
      "Epoch [41/300], Step [82/225], Training Accuracy: 83.0602%, Training Loss: 0.4206%\n",
      "Epoch [41/300], Step [83/225], Training Accuracy: 83.0384%, Training Loss: 0.4209%\n",
      "Epoch [41/300], Step [84/225], Training Accuracy: 83.1101%, Training Loss: 0.4186%\n",
      "Epoch [41/300], Step [85/225], Training Accuracy: 83.1801%, Training Loss: 0.4173%\n",
      "Epoch [41/300], Step [86/225], Training Accuracy: 83.2485%, Training Loss: 0.4163%\n",
      "Epoch [41/300], Step [87/225], Training Accuracy: 83.2076%, Training Loss: 0.4166%\n",
      "Epoch [41/300], Step [88/225], Training Accuracy: 83.3097%, Training Loss: 0.4151%\n",
      "Epoch [41/300], Step [89/225], Training Accuracy: 83.3041%, Training Loss: 0.4149%\n",
      "Epoch [41/300], Step [90/225], Training Accuracy: 83.2812%, Training Loss: 0.4163%\n",
      "Epoch [41/300], Step [91/225], Training Accuracy: 83.2246%, Training Loss: 0.4160%\n",
      "Epoch [41/300], Step [92/225], Training Accuracy: 83.2711%, Training Loss: 0.4158%\n",
      "Epoch [41/300], Step [93/225], Training Accuracy: 83.2997%, Training Loss: 0.4149%\n",
      "Epoch [41/300], Step [94/225], Training Accuracy: 83.3278%, Training Loss: 0.4142%\n",
      "Epoch [41/300], Step [95/225], Training Accuracy: 83.2566%, Training Loss: 0.4160%\n",
      "Epoch [41/300], Step [96/225], Training Accuracy: 83.2682%, Training Loss: 0.4153%\n",
      "Epoch [41/300], Step [97/225], Training Accuracy: 83.1830%, Training Loss: 0.4159%\n",
      "Epoch [41/300], Step [98/225], Training Accuracy: 83.1952%, Training Loss: 0.4154%\n",
      "Epoch [41/300], Step [99/225], Training Accuracy: 83.2386%, Training Loss: 0.4155%\n",
      "Epoch [41/300], Step [100/225], Training Accuracy: 83.1406%, Training Loss: 0.4164%\n",
      "Epoch [41/300], Step [101/225], Training Accuracy: 83.1374%, Training Loss: 0.4168%\n",
      "Epoch [41/300], Step [102/225], Training Accuracy: 83.0576%, Training Loss: 0.4181%\n",
      "Epoch [41/300], Step [103/225], Training Accuracy: 83.1311%, Training Loss: 0.4175%\n",
      "Epoch [41/300], Step [104/225], Training Accuracy: 83.1280%, Training Loss: 0.4168%\n",
      "Epoch [41/300], Step [105/225], Training Accuracy: 83.1994%, Training Loss: 0.4157%\n",
      "Epoch [41/300], Step [106/225], Training Accuracy: 83.1368%, Training Loss: 0.4177%\n",
      "Epoch [41/300], Step [107/225], Training Accuracy: 83.0754%, Training Loss: 0.4186%\n",
      "Epoch [41/300], Step [108/225], Training Accuracy: 82.9572%, Training Loss: 0.4210%\n",
      "Epoch [41/300], Step [109/225], Training Accuracy: 82.9272%, Training Loss: 0.4210%\n",
      "Epoch [41/300], Step [110/225], Training Accuracy: 82.9403%, Training Loss: 0.4207%\n",
      "Epoch [41/300], Step [111/225], Training Accuracy: 82.9392%, Training Loss: 0.4206%\n",
      "Epoch [41/300], Step [112/225], Training Accuracy: 82.9102%, Training Loss: 0.4204%\n",
      "Epoch [41/300], Step [113/225], Training Accuracy: 82.9093%, Training Loss: 0.4204%\n",
      "Epoch [41/300], Step [114/225], Training Accuracy: 82.8947%, Training Loss: 0.4200%\n",
      "Epoch [41/300], Step [115/225], Training Accuracy: 82.9620%, Training Loss: 0.4185%\n",
      "Epoch [41/300], Step [116/225], Training Accuracy: 82.9472%, Training Loss: 0.4185%\n",
      "Epoch [41/300], Step [117/225], Training Accuracy: 82.8659%, Training Loss: 0.4201%\n",
      "Epoch [41/300], Step [118/225], Training Accuracy: 82.9052%, Training Loss: 0.4191%\n",
      "Epoch [41/300], Step [119/225], Training Accuracy: 82.9175%, Training Loss: 0.4186%\n",
      "Epoch [41/300], Step [120/225], Training Accuracy: 82.8646%, Training Loss: 0.4198%\n",
      "Epoch [41/300], Step [121/225], Training Accuracy: 82.8512%, Training Loss: 0.4195%\n",
      "Epoch [41/300], Step [122/225], Training Accuracy: 82.8381%, Training Loss: 0.4195%\n",
      "Epoch [41/300], Step [123/225], Training Accuracy: 82.7998%, Training Loss: 0.4204%\n",
      "Epoch [41/300], Step [124/225], Training Accuracy: 82.8377%, Training Loss: 0.4194%\n",
      "Epoch [41/300], Step [125/225], Training Accuracy: 82.8875%, Training Loss: 0.4183%\n",
      "Epoch [41/300], Step [126/225], Training Accuracy: 82.8993%, Training Loss: 0.4180%\n",
      "Epoch [41/300], Step [127/225], Training Accuracy: 82.9232%, Training Loss: 0.4177%\n",
      "Epoch [41/300], Step [128/225], Training Accuracy: 82.9102%, Training Loss: 0.4185%\n",
      "Epoch [41/300], Step [129/225], Training Accuracy: 82.9457%, Training Loss: 0.4179%\n",
      "Epoch [41/300], Step [130/225], Training Accuracy: 82.8966%, Training Loss: 0.4188%\n",
      "Epoch [41/300], Step [131/225], Training Accuracy: 82.8602%, Training Loss: 0.4197%\n",
      "Epoch [41/300], Step [132/225], Training Accuracy: 82.7888%, Training Loss: 0.4205%\n",
      "Epoch [41/300], Step [133/225], Training Accuracy: 82.7890%, Training Loss: 0.4203%\n",
      "Epoch [41/300], Step [134/225], Training Accuracy: 82.7775%, Training Loss: 0.4207%\n",
      "Epoch [41/300], Step [135/225], Training Accuracy: 82.8009%, Training Loss: 0.4196%\n",
      "Epoch [41/300], Step [136/225], Training Accuracy: 82.7665%, Training Loss: 0.4204%\n",
      "Epoch [41/300], Step [137/225], Training Accuracy: 82.8011%, Training Loss: 0.4195%\n",
      "Epoch [41/300], Step [138/225], Training Accuracy: 82.8238%, Training Loss: 0.4196%\n",
      "Epoch [41/300], Step [139/225], Training Accuracy: 82.8237%, Training Loss: 0.4193%\n",
      "Epoch [41/300], Step [140/225], Training Accuracy: 82.8348%, Training Loss: 0.4193%\n",
      "Epoch [41/300], Step [141/225], Training Accuracy: 82.8457%, Training Loss: 0.4191%\n",
      "Epoch [41/300], Step [142/225], Training Accuracy: 82.8895%, Training Loss: 0.4182%\n",
      "Epoch [41/300], Step [143/225], Training Accuracy: 82.8890%, Training Loss: 0.4179%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/300], Step [144/225], Training Accuracy: 82.9210%, Training Loss: 0.4168%\n",
      "Epoch [41/300], Step [145/225], Training Accuracy: 82.9095%, Training Loss: 0.4164%\n",
      "Epoch [41/300], Step [146/225], Training Accuracy: 82.8874%, Training Loss: 0.4167%\n",
      "Epoch [41/300], Step [147/225], Training Accuracy: 82.9507%, Training Loss: 0.4157%\n",
      "Epoch [41/300], Step [148/225], Training Accuracy: 83.0025%, Training Loss: 0.4144%\n",
      "Epoch [41/300], Step [149/225], Training Accuracy: 82.9279%, Training Loss: 0.4152%\n",
      "Epoch [41/300], Step [150/225], Training Accuracy: 82.9792%, Training Loss: 0.4149%\n",
      "Epoch [41/300], Step [151/225], Training Accuracy: 83.0195%, Training Loss: 0.4136%\n",
      "Epoch [41/300], Step [152/225], Training Accuracy: 83.0284%, Training Loss: 0.4138%\n",
      "Epoch [41/300], Step [153/225], Training Accuracy: 83.0678%, Training Loss: 0.4136%\n",
      "Epoch [41/300], Step [154/225], Training Accuracy: 83.0357%, Training Loss: 0.4155%\n",
      "Epoch [41/300], Step [155/225], Training Accuracy: 83.0444%, Training Loss: 0.4153%\n",
      "Epoch [41/300], Step [156/225], Training Accuracy: 83.0128%, Training Loss: 0.4159%\n",
      "Epoch [41/300], Step [157/225], Training Accuracy: 82.9817%, Training Loss: 0.4164%\n",
      "Epoch [41/300], Step [158/225], Training Accuracy: 83.0301%, Training Loss: 0.4165%\n",
      "Epoch [41/300], Step [159/225], Training Accuracy: 83.0385%, Training Loss: 0.4165%\n",
      "Epoch [41/300], Step [160/225], Training Accuracy: 83.0176%, Training Loss: 0.4166%\n",
      "Epoch [41/300], Step [161/225], Training Accuracy: 83.0357%, Training Loss: 0.4167%\n",
      "Epoch [41/300], Step [162/225], Training Accuracy: 83.0729%, Training Loss: 0.4161%\n",
      "Epoch [41/300], Step [163/225], Training Accuracy: 83.0905%, Training Loss: 0.4160%\n",
      "Epoch [41/300], Step [164/225], Training Accuracy: 83.1079%, Training Loss: 0.4154%\n",
      "Epoch [41/300], Step [165/225], Training Accuracy: 83.1061%, Training Loss: 0.4149%\n",
      "Epoch [41/300], Step [166/225], Training Accuracy: 83.0666%, Training Loss: 0.4148%\n",
      "Epoch [41/300], Step [167/225], Training Accuracy: 83.1025%, Training Loss: 0.4139%\n",
      "Epoch [41/300], Step [168/225], Training Accuracy: 83.1380%, Training Loss: 0.4132%\n",
      "Epoch [41/300], Step [169/225], Training Accuracy: 83.1823%, Training Loss: 0.4129%\n",
      "Epoch [41/300], Step [170/225], Training Accuracy: 83.1893%, Training Loss: 0.4129%\n",
      "Epoch [41/300], Step [171/225], Training Accuracy: 83.1963%, Training Loss: 0.4127%\n",
      "Epoch [41/300], Step [172/225], Training Accuracy: 83.1759%, Training Loss: 0.4131%\n",
      "Epoch [41/300], Step [173/225], Training Accuracy: 83.1647%, Training Loss: 0.4131%\n",
      "Epoch [41/300], Step [174/225], Training Accuracy: 83.1807%, Training Loss: 0.4130%\n",
      "Epoch [41/300], Step [175/225], Training Accuracy: 83.1696%, Training Loss: 0.4130%\n",
      "Epoch [41/300], Step [176/225], Training Accuracy: 83.1854%, Training Loss: 0.4127%\n",
      "Epoch [41/300], Step [177/225], Training Accuracy: 83.1921%, Training Loss: 0.4127%\n",
      "Epoch [41/300], Step [178/225], Training Accuracy: 83.2426%, Training Loss: 0.4124%\n",
      "Epoch [41/300], Step [179/225], Training Accuracy: 83.2490%, Training Loss: 0.4133%\n",
      "Epoch [41/300], Step [180/225], Training Accuracy: 83.2292%, Training Loss: 0.4132%\n",
      "Epoch [41/300], Step [181/225], Training Accuracy: 83.2096%, Training Loss: 0.4134%\n",
      "Epoch [41/300], Step [182/225], Training Accuracy: 83.2246%, Training Loss: 0.4127%\n",
      "Epoch [41/300], Step [183/225], Training Accuracy: 83.2650%, Training Loss: 0.4123%\n",
      "Epoch [41/300], Step [184/225], Training Accuracy: 83.2965%, Training Loss: 0.4115%\n",
      "Epoch [41/300], Step [185/225], Training Accuracy: 83.2939%, Training Loss: 0.4116%\n",
      "Epoch [41/300], Step [186/225], Training Accuracy: 83.3165%, Training Loss: 0.4112%\n",
      "Epoch [41/300], Step [187/225], Training Accuracy: 83.3473%, Training Loss: 0.4107%\n",
      "Epoch [41/300], Step [188/225], Training Accuracy: 83.4026%, Training Loss: 0.4095%\n",
      "Epoch [41/300], Step [189/225], Training Accuracy: 83.3912%, Training Loss: 0.4099%\n",
      "Epoch [41/300], Step [190/225], Training Accuracy: 83.3553%, Training Loss: 0.4104%\n",
      "Epoch [41/300], Step [191/225], Training Accuracy: 83.3033%, Training Loss: 0.4117%\n",
      "Epoch [41/300], Step [192/225], Training Accuracy: 83.3008%, Training Loss: 0.4111%\n",
      "Epoch [41/300], Step [193/225], Training Accuracy: 83.3225%, Training Loss: 0.4107%\n",
      "Epoch [41/300], Step [194/225], Training Accuracy: 83.2635%, Training Loss: 0.4119%\n",
      "Epoch [41/300], Step [195/225], Training Accuracy: 83.2692%, Training Loss: 0.4113%\n",
      "Epoch [41/300], Step [196/225], Training Accuracy: 83.2430%, Training Loss: 0.4117%\n",
      "Epoch [41/300], Step [197/225], Training Accuracy: 83.2011%, Training Loss: 0.4123%\n",
      "Epoch [41/300], Step [198/225], Training Accuracy: 83.2386%, Training Loss: 0.4115%\n",
      "Epoch [41/300], Step [199/225], Training Accuracy: 83.2129%, Training Loss: 0.4130%\n",
      "Epoch [41/300], Step [200/225], Training Accuracy: 83.1797%, Training Loss: 0.4148%\n",
      "Epoch [41/300], Step [201/225], Training Accuracy: 83.1623%, Training Loss: 0.4153%\n",
      "Epoch [41/300], Step [202/225], Training Accuracy: 83.1528%, Training Loss: 0.4154%\n",
      "Epoch [41/300], Step [203/225], Training Accuracy: 83.1204%, Training Loss: 0.4153%\n",
      "Epoch [41/300], Step [204/225], Training Accuracy: 83.0959%, Training Loss: 0.4157%\n",
      "Epoch [41/300], Step [205/225], Training Accuracy: 83.1021%, Training Loss: 0.4152%\n",
      "Epoch [41/300], Step [206/225], Training Accuracy: 83.0780%, Training Loss: 0.4154%\n",
      "Epoch [41/300], Step [207/225], Training Accuracy: 83.1144%, Training Loss: 0.4150%\n",
      "Epoch [41/300], Step [208/225], Training Accuracy: 83.0904%, Training Loss: 0.4155%\n",
      "Epoch [41/300], Step [209/225], Training Accuracy: 83.0742%, Training Loss: 0.4158%\n",
      "Epoch [41/300], Step [210/225], Training Accuracy: 83.0804%, Training Loss: 0.4157%\n",
      "Epoch [41/300], Step [211/225], Training Accuracy: 83.0939%, Training Loss: 0.4154%\n",
      "Epoch [41/300], Step [212/225], Training Accuracy: 83.0852%, Training Loss: 0.4152%\n",
      "Epoch [41/300], Step [213/225], Training Accuracy: 83.0692%, Training Loss: 0.4154%\n",
      "Epoch [41/300], Step [214/225], Training Accuracy: 83.0680%, Training Loss: 0.4156%\n",
      "Epoch [41/300], Step [215/225], Training Accuracy: 83.0814%, Training Loss: 0.4151%\n",
      "Epoch [41/300], Step [216/225], Training Accuracy: 83.1091%, Training Loss: 0.4144%\n",
      "Epoch [41/300], Step [217/225], Training Accuracy: 83.1005%, Training Loss: 0.4141%\n",
      "Epoch [41/300], Step [218/225], Training Accuracy: 83.0562%, Training Loss: 0.4149%\n",
      "Epoch [41/300], Step [219/225], Training Accuracy: 83.0693%, Training Loss: 0.4142%\n",
      "Epoch [41/300], Step [220/225], Training Accuracy: 83.0895%, Training Loss: 0.4139%\n",
      "Epoch [41/300], Step [221/225], Training Accuracy: 83.1165%, Training Loss: 0.4133%\n",
      "Epoch [41/300], Step [222/225], Training Accuracy: 83.1222%, Training Loss: 0.4128%\n",
      "Epoch [41/300], Step [223/225], Training Accuracy: 83.1208%, Training Loss: 0.4128%\n",
      "Epoch [41/300], Step [224/225], Training Accuracy: 83.1334%, Training Loss: 0.4125%\n",
      "Epoch [41/300], Step [225/225], Training Accuracy: 83.1434%, Training Loss: 0.4120%\n",
      "Epoch [42/300], Step [1/225], Training Accuracy: 81.2500%, Training Loss: 0.3355%\n",
      "Epoch [42/300], Step [2/225], Training Accuracy: 87.5000%, Training Loss: 0.3186%\n",
      "Epoch [42/300], Step [3/225], Training Accuracy: 86.4583%, Training Loss: 0.3262%\n",
      "Epoch [42/300], Step [4/225], Training Accuracy: 86.7188%, Training Loss: 0.3491%\n",
      "Epoch [42/300], Step [5/225], Training Accuracy: 86.5625%, Training Loss: 0.3524%\n",
      "Epoch [42/300], Step [6/225], Training Accuracy: 87.5000%, Training Loss: 0.3391%\n",
      "Epoch [42/300], Step [7/225], Training Accuracy: 87.7232%, Training Loss: 0.3410%\n",
      "Epoch [42/300], Step [8/225], Training Accuracy: 87.3047%, Training Loss: 0.3548%\n",
      "Epoch [42/300], Step [9/225], Training Accuracy: 87.3264%, Training Loss: 0.3516%\n",
      "Epoch [42/300], Step [10/225], Training Accuracy: 87.3438%, Training Loss: 0.3561%\n",
      "Epoch [42/300], Step [11/225], Training Accuracy: 86.7898%, Training Loss: 0.3638%\n",
      "Epoch [42/300], Step [12/225], Training Accuracy: 86.7188%, Training Loss: 0.3642%\n",
      "Epoch [42/300], Step [13/225], Training Accuracy: 86.8990%, Training Loss: 0.3576%\n",
      "Epoch [42/300], Step [14/225], Training Accuracy: 87.0536%, Training Loss: 0.3543%\n",
      "Epoch [42/300], Step [15/225], Training Accuracy: 87.0833%, Training Loss: 0.3552%\n",
      "Epoch [42/300], Step [16/225], Training Accuracy: 87.0117%, Training Loss: 0.3496%\n",
      "Epoch [42/300], Step [17/225], Training Accuracy: 86.9485%, Training Loss: 0.3471%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/300], Step [18/225], Training Accuracy: 87.3264%, Training Loss: 0.3515%\n",
      "Epoch [42/300], Step [19/225], Training Accuracy: 87.4178%, Training Loss: 0.3484%\n",
      "Epoch [42/300], Step [20/225], Training Accuracy: 87.3438%, Training Loss: 0.3522%\n",
      "Epoch [42/300], Step [21/225], Training Accuracy: 87.4256%, Training Loss: 0.3478%\n",
      "Epoch [42/300], Step [22/225], Training Accuracy: 87.0739%, Training Loss: 0.3561%\n",
      "Epoch [42/300], Step [23/225], Training Accuracy: 87.2962%, Training Loss: 0.3545%\n",
      "Epoch [42/300], Step [24/225], Training Accuracy: 87.3698%, Training Loss: 0.3602%\n",
      "Epoch [42/300], Step [25/225], Training Accuracy: 87.5000%, Training Loss: 0.3534%\n",
      "Epoch [42/300], Step [26/225], Training Accuracy: 87.3197%, Training Loss: 0.3565%\n",
      "Epoch [42/300], Step [27/225], Training Accuracy: 87.2685%, Training Loss: 0.3573%\n",
      "Epoch [42/300], Step [28/225], Training Accuracy: 87.1652%, Training Loss: 0.3596%\n",
      "Epoch [42/300], Step [29/225], Training Accuracy: 87.1228%, Training Loss: 0.3587%\n",
      "Epoch [42/300], Step [30/225], Training Accuracy: 87.3438%, Training Loss: 0.3556%\n",
      "Epoch [42/300], Step [31/225], Training Accuracy: 86.9456%, Training Loss: 0.3624%\n",
      "Epoch [42/300], Step [32/225], Training Accuracy: 87.0117%, Training Loss: 0.3605%\n",
      "Epoch [42/300], Step [33/225], Training Accuracy: 87.0265%, Training Loss: 0.3592%\n",
      "Epoch [42/300], Step [34/225], Training Accuracy: 86.7188%, Training Loss: 0.3638%\n",
      "Epoch [42/300], Step [35/225], Training Accuracy: 86.7411%, Training Loss: 0.3644%\n",
      "Epoch [42/300], Step [36/225], Training Accuracy: 86.8056%, Training Loss: 0.3624%\n",
      "Epoch [42/300], Step [37/225], Training Accuracy: 86.7399%, Training Loss: 0.3644%\n",
      "Epoch [42/300], Step [38/225], Training Accuracy: 86.6776%, Training Loss: 0.3666%\n",
      "Epoch [42/300], Step [39/225], Training Accuracy: 86.3381%, Training Loss: 0.3738%\n",
      "Epoch [42/300], Step [40/225], Training Accuracy: 86.3672%, Training Loss: 0.3723%\n",
      "Epoch [42/300], Step [41/225], Training Accuracy: 86.0518%, Training Loss: 0.3773%\n",
      "Epoch [42/300], Step [42/225], Training Accuracy: 86.0119%, Training Loss: 0.3769%\n",
      "Epoch [42/300], Step [43/225], Training Accuracy: 86.0465%, Training Loss: 0.3759%\n",
      "Epoch [42/300], Step [44/225], Training Accuracy: 85.9730%, Training Loss: 0.3772%\n",
      "Epoch [42/300], Step [45/225], Training Accuracy: 85.8681%, Training Loss: 0.3783%\n",
      "Epoch [42/300], Step [46/225], Training Accuracy: 86.0054%, Training Loss: 0.3758%\n",
      "Epoch [42/300], Step [47/225], Training Accuracy: 86.0040%, Training Loss: 0.3751%\n",
      "Epoch [42/300], Step [48/225], Training Accuracy: 85.9701%, Training Loss: 0.3755%\n",
      "Epoch [42/300], Step [49/225], Training Accuracy: 85.9056%, Training Loss: 0.3797%\n",
      "Epoch [42/300], Step [50/225], Training Accuracy: 85.7500%, Training Loss: 0.3807%\n",
      "Epoch [42/300], Step [51/225], Training Accuracy: 85.8456%, Training Loss: 0.3789%\n",
      "Epoch [42/300], Step [52/225], Training Accuracy: 85.8774%, Training Loss: 0.3768%\n",
      "Epoch [42/300], Step [53/225], Training Accuracy: 85.8491%, Training Loss: 0.3776%\n",
      "Epoch [42/300], Step [54/225], Training Accuracy: 85.8507%, Training Loss: 0.3768%\n",
      "Epoch [42/300], Step [55/225], Training Accuracy: 85.8239%, Training Loss: 0.3774%\n",
      "Epoch [42/300], Step [56/225], Training Accuracy: 85.7701%, Training Loss: 0.3761%\n",
      "Epoch [42/300], Step [57/225], Training Accuracy: 85.5537%, Training Loss: 0.3808%\n",
      "Epoch [42/300], Step [58/225], Training Accuracy: 85.5334%, Training Loss: 0.3805%\n",
      "Epoch [42/300], Step [59/225], Training Accuracy: 85.3549%, Training Loss: 0.3832%\n",
      "Epoch [42/300], Step [60/225], Training Accuracy: 85.4427%, Training Loss: 0.3819%\n",
      "Epoch [42/300], Step [61/225], Training Accuracy: 85.3484%, Training Loss: 0.3817%\n",
      "Epoch [42/300], Step [62/225], Training Accuracy: 85.3075%, Training Loss: 0.3809%\n",
      "Epoch [42/300], Step [63/225], Training Accuracy: 85.2927%, Training Loss: 0.3831%\n",
      "Epoch [42/300], Step [64/225], Training Accuracy: 85.2295%, Training Loss: 0.3834%\n",
      "Epoch [42/300], Step [65/225], Training Accuracy: 85.1683%, Training Loss: 0.3845%\n",
      "Epoch [42/300], Step [66/225], Training Accuracy: 85.2273%, Training Loss: 0.3822%\n",
      "Epoch [42/300], Step [67/225], Training Accuracy: 85.1446%, Training Loss: 0.3825%\n",
      "Epoch [42/300], Step [68/225], Training Accuracy: 85.1333%, Training Loss: 0.3815%\n",
      "Epoch [42/300], Step [69/225], Training Accuracy: 85.0996%, Training Loss: 0.3817%\n",
      "Epoch [42/300], Step [70/225], Training Accuracy: 85.0893%, Training Loss: 0.3819%\n",
      "Epoch [42/300], Step [71/225], Training Accuracy: 84.9692%, Training Loss: 0.3841%\n",
      "Epoch [42/300], Step [72/225], Training Accuracy: 85.0694%, Training Loss: 0.3824%\n",
      "Epoch [42/300], Step [73/225], Training Accuracy: 85.0813%, Training Loss: 0.3821%\n",
      "Epoch [42/300], Step [74/225], Training Accuracy: 85.0929%, Training Loss: 0.3810%\n",
      "Epoch [42/300], Step [75/225], Training Accuracy: 85.1250%, Training Loss: 0.3807%\n",
      "Epoch [42/300], Step [76/225], Training Accuracy: 85.0946%, Training Loss: 0.3815%\n",
      "Epoch [42/300], Step [77/225], Training Accuracy: 85.0649%, Training Loss: 0.3818%\n",
      "Epoch [42/300], Step [78/225], Training Accuracy: 85.0160%, Training Loss: 0.3820%\n",
      "Epoch [42/300], Step [79/225], Training Accuracy: 85.0870%, Training Loss: 0.3801%\n",
      "Epoch [42/300], Step [80/225], Training Accuracy: 85.0195%, Training Loss: 0.3806%\n",
      "Epoch [42/300], Step [81/225], Training Accuracy: 85.0309%, Training Loss: 0.3837%\n",
      "Epoch [42/300], Step [82/225], Training Accuracy: 85.0800%, Training Loss: 0.3821%\n",
      "Epoch [42/300], Step [83/225], Training Accuracy: 85.1280%, Training Loss: 0.3807%\n",
      "Epoch [42/300], Step [84/225], Training Accuracy: 85.2307%, Training Loss: 0.3788%\n",
      "Epoch [42/300], Step [85/225], Training Accuracy: 85.2574%, Training Loss: 0.3778%\n",
      "Epoch [42/300], Step [86/225], Training Accuracy: 85.3016%, Training Loss: 0.3767%\n",
      "Epoch [42/300], Step [87/225], Training Accuracy: 85.3269%, Training Loss: 0.3767%\n",
      "Epoch [42/300], Step [88/225], Training Accuracy: 85.2273%, Training Loss: 0.3780%\n",
      "Epoch [42/300], Step [89/225], Training Accuracy: 85.2879%, Training Loss: 0.3771%\n",
      "Epoch [42/300], Step [90/225], Training Accuracy: 85.2951%, Training Loss: 0.3783%\n",
      "Epoch [42/300], Step [91/225], Training Accuracy: 85.3537%, Training Loss: 0.3772%\n",
      "Epoch [42/300], Step [92/225], Training Accuracy: 85.3770%, Training Loss: 0.3775%\n",
      "Epoch [42/300], Step [93/225], Training Accuracy: 85.4671%, Training Loss: 0.3756%\n",
      "Epoch [42/300], Step [94/225], Training Accuracy: 85.5219%, Training Loss: 0.3746%\n",
      "Epoch [42/300], Step [95/225], Training Accuracy: 85.5263%, Training Loss: 0.3747%\n",
      "Epoch [42/300], Step [96/225], Training Accuracy: 85.5469%, Training Loss: 0.3747%\n",
      "Epoch [42/300], Step [97/225], Training Accuracy: 85.6153%, Training Loss: 0.3738%\n",
      "Epoch [42/300], Step [98/225], Training Accuracy: 85.5867%, Training Loss: 0.3735%\n",
      "Epoch [42/300], Step [99/225], Training Accuracy: 85.6218%, Training Loss: 0.3724%\n",
      "Epoch [42/300], Step [100/225], Training Accuracy: 85.6406%, Training Loss: 0.3721%\n",
      "Epoch [42/300], Step [101/225], Training Accuracy: 85.5817%, Training Loss: 0.3728%\n",
      "Epoch [42/300], Step [102/225], Training Accuracy: 85.5852%, Training Loss: 0.3743%\n",
      "Epoch [42/300], Step [103/225], Training Accuracy: 85.5886%, Training Loss: 0.3741%\n",
      "Epoch [42/300], Step [104/225], Training Accuracy: 85.6220%, Training Loss: 0.3734%\n",
      "Epoch [42/300], Step [105/225], Training Accuracy: 85.6399%, Training Loss: 0.3731%\n",
      "Epoch [42/300], Step [106/225], Training Accuracy: 85.6427%, Training Loss: 0.3736%\n",
      "Epoch [42/300], Step [107/225], Training Accuracy: 85.6162%, Training Loss: 0.3738%\n",
      "Epoch [42/300], Step [108/225], Training Accuracy: 85.6337%, Training Loss: 0.3732%\n",
      "Epoch [42/300], Step [109/225], Training Accuracy: 85.6365%, Training Loss: 0.3729%\n",
      "Epoch [42/300], Step [110/225], Training Accuracy: 85.6108%, Training Loss: 0.3726%\n",
      "Epoch [42/300], Step [111/225], Training Accuracy: 85.6137%, Training Loss: 0.3728%\n",
      "Epoch [42/300], Step [112/225], Training Accuracy: 85.5887%, Training Loss: 0.3734%\n",
      "Epoch [42/300], Step [113/225], Training Accuracy: 85.5642%, Training Loss: 0.3745%\n",
      "Epoch [42/300], Step [114/225], Training Accuracy: 85.5948%, Training Loss: 0.3740%\n",
      "Epoch [42/300], Step [115/225], Training Accuracy: 85.5707%, Training Loss: 0.3746%\n",
      "Epoch [42/300], Step [116/225], Training Accuracy: 85.5065%, Training Loss: 0.3755%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/300], Step [117/225], Training Accuracy: 85.4701%, Training Loss: 0.3764%\n",
      "Epoch [42/300], Step [118/225], Training Accuracy: 85.4873%, Training Loss: 0.3768%\n",
      "Epoch [42/300], Step [119/225], Training Accuracy: 85.4779%, Training Loss: 0.3762%\n",
      "Epoch [42/300], Step [120/225], Training Accuracy: 85.4427%, Training Loss: 0.3760%\n",
      "Epoch [42/300], Step [121/225], Training Accuracy: 85.4210%, Training Loss: 0.3773%\n",
      "Epoch [42/300], Step [122/225], Training Accuracy: 85.3996%, Training Loss: 0.3781%\n",
      "Epoch [42/300], Step [123/225], Training Accuracy: 85.4167%, Training Loss: 0.3779%\n",
      "Epoch [42/300], Step [124/225], Training Accuracy: 85.4209%, Training Loss: 0.3777%\n",
      "Epoch [42/300], Step [125/225], Training Accuracy: 85.4125%, Training Loss: 0.3789%\n",
      "Epoch [42/300], Step [126/225], Training Accuracy: 85.3547%, Training Loss: 0.3789%\n",
      "Epoch [42/300], Step [127/225], Training Accuracy: 85.3100%, Training Loss: 0.3795%\n",
      "Epoch [42/300], Step [128/225], Training Accuracy: 85.3027%, Training Loss: 0.3795%\n",
      "Epoch [42/300], Step [129/225], Training Accuracy: 85.2955%, Training Loss: 0.3797%\n",
      "Epoch [42/300], Step [130/225], Training Accuracy: 85.3245%, Training Loss: 0.3795%\n",
      "Epoch [42/300], Step [131/225], Training Accuracy: 85.2815%, Training Loss: 0.3798%\n",
      "Epoch [42/300], Step [132/225], Training Accuracy: 85.2983%, Training Loss: 0.3801%\n",
      "Epoch [42/300], Step [133/225], Training Accuracy: 85.3031%, Training Loss: 0.3794%\n",
      "Epoch [42/300], Step [134/225], Training Accuracy: 85.2495%, Training Loss: 0.3809%\n",
      "Epoch [42/300], Step [135/225], Training Accuracy: 85.2894%, Training Loss: 0.3801%\n",
      "Epoch [42/300], Step [136/225], Training Accuracy: 85.2367%, Training Loss: 0.3807%\n",
      "Epoch [42/300], Step [137/225], Training Accuracy: 85.2304%, Training Loss: 0.3809%\n",
      "Epoch [42/300], Step [138/225], Training Accuracy: 85.2582%, Training Loss: 0.3802%\n",
      "Epoch [42/300], Step [139/225], Training Accuracy: 85.2406%, Training Loss: 0.3806%\n",
      "Epoch [42/300], Step [140/225], Training Accuracy: 85.2455%, Training Loss: 0.3819%\n",
      "Epoch [42/300], Step [141/225], Training Accuracy: 85.2394%, Training Loss: 0.3818%\n",
      "Epoch [42/300], Step [142/225], Training Accuracy: 85.2553%, Training Loss: 0.3819%\n",
      "Epoch [42/300], Step [143/225], Training Accuracy: 85.2601%, Training Loss: 0.3815%\n",
      "Epoch [42/300], Step [144/225], Training Accuracy: 85.2322%, Training Loss: 0.3820%\n",
      "Epoch [42/300], Step [145/225], Training Accuracy: 85.2155%, Training Loss: 0.3825%\n",
      "Epoch [42/300], Step [146/225], Training Accuracy: 85.2205%, Training Loss: 0.3824%\n",
      "Epoch [42/300], Step [147/225], Training Accuracy: 85.2360%, Training Loss: 0.3818%\n",
      "Epoch [42/300], Step [148/225], Training Accuracy: 85.2513%, Training Loss: 0.3812%\n",
      "Epoch [42/300], Step [149/225], Training Accuracy: 85.2349%, Training Loss: 0.3819%\n",
      "Epoch [42/300], Step [150/225], Training Accuracy: 85.2708%, Training Loss: 0.3809%\n",
      "Epoch [42/300], Step [151/225], Training Accuracy: 85.3063%, Training Loss: 0.3801%\n",
      "Epoch [42/300], Step [152/225], Training Accuracy: 85.3413%, Training Loss: 0.3792%\n",
      "Epoch [42/300], Step [153/225], Training Accuracy: 85.2737%, Training Loss: 0.3798%\n",
      "Epoch [42/300], Step [154/225], Training Accuracy: 85.2881%, Training Loss: 0.3792%\n",
      "Epoch [42/300], Step [155/225], Training Accuracy: 85.3125%, Training Loss: 0.3793%\n",
      "Epoch [42/300], Step [156/225], Training Accuracy: 85.3065%, Training Loss: 0.3802%\n",
      "Epoch [42/300], Step [157/225], Training Accuracy: 85.2906%, Training Loss: 0.3829%\n",
      "Epoch [42/300], Step [158/225], Training Accuracy: 85.2749%, Training Loss: 0.3839%\n",
      "Epoch [42/300], Step [159/225], Training Accuracy: 85.2889%, Training Loss: 0.3836%\n",
      "Epoch [42/300], Step [160/225], Training Accuracy: 85.2734%, Training Loss: 0.3842%\n",
      "Epoch [42/300], Step [161/225], Training Accuracy: 85.2776%, Training Loss: 0.3842%\n",
      "Epoch [42/300], Step [162/225], Training Accuracy: 85.3009%, Training Loss: 0.3842%\n",
      "Epoch [42/300], Step [163/225], Training Accuracy: 85.2952%, Training Loss: 0.3841%\n",
      "Epoch [42/300], Step [164/225], Training Accuracy: 85.2992%, Training Loss: 0.3834%\n",
      "Epoch [42/300], Step [165/225], Training Accuracy: 85.3314%, Training Loss: 0.3830%\n",
      "Epoch [42/300], Step [166/225], Training Accuracy: 85.2974%, Training Loss: 0.3831%\n",
      "Epoch [42/300], Step [167/225], Training Accuracy: 85.2732%, Training Loss: 0.3834%\n",
      "Epoch [42/300], Step [168/225], Training Accuracy: 85.2307%, Training Loss: 0.3849%\n",
      "Epoch [42/300], Step [169/225], Training Accuracy: 85.2348%, Training Loss: 0.3841%\n",
      "Epoch [42/300], Step [170/225], Training Accuracy: 85.2206%, Training Loss: 0.3846%\n",
      "Epoch [42/300], Step [171/225], Training Accuracy: 85.1882%, Training Loss: 0.3854%\n",
      "Epoch [42/300], Step [172/225], Training Accuracy: 85.1926%, Training Loss: 0.3859%\n",
      "Epoch [42/300], Step [173/225], Training Accuracy: 85.1969%, Training Loss: 0.3860%\n",
      "Epoch [42/300], Step [174/225], Training Accuracy: 85.1832%, Training Loss: 0.3867%\n",
      "Epoch [42/300], Step [175/225], Training Accuracy: 85.1518%, Training Loss: 0.3870%\n",
      "Epoch [42/300], Step [176/225], Training Accuracy: 85.1119%, Training Loss: 0.3873%\n",
      "Epoch [42/300], Step [177/225], Training Accuracy: 85.1342%, Training Loss: 0.3864%\n",
      "Epoch [42/300], Step [178/225], Training Accuracy: 85.1475%, Training Loss: 0.3865%\n",
      "Epoch [42/300], Step [179/225], Training Accuracy: 85.1170%, Training Loss: 0.3864%\n",
      "Epoch [42/300], Step [180/225], Training Accuracy: 85.0955%, Training Loss: 0.3864%\n",
      "Epoch [42/300], Step [181/225], Training Accuracy: 85.0397%, Training Loss: 0.3870%\n",
      "Epoch [42/300], Step [182/225], Training Accuracy: 85.0361%, Training Loss: 0.3869%\n",
      "Epoch [42/300], Step [183/225], Training Accuracy: 85.0666%, Training Loss: 0.3863%\n",
      "Epoch [42/300], Step [184/225], Training Accuracy: 85.0968%, Training Loss: 0.3857%\n",
      "Epoch [42/300], Step [185/225], Training Accuracy: 85.0760%, Training Loss: 0.3860%\n",
      "Epoch [42/300], Step [186/225], Training Accuracy: 85.0806%, Training Loss: 0.3857%\n",
      "Epoch [42/300], Step [187/225], Training Accuracy: 85.1186%, Training Loss: 0.3847%\n",
      "Epoch [42/300], Step [188/225], Training Accuracy: 85.1562%, Training Loss: 0.3839%\n",
      "Epoch [42/300], Step [189/225], Training Accuracy: 85.1687%, Training Loss: 0.3833%\n",
      "Epoch [42/300], Step [190/225], Training Accuracy: 85.1645%, Training Loss: 0.3832%\n",
      "Epoch [42/300], Step [191/225], Training Accuracy: 85.1440%, Training Loss: 0.3832%\n",
      "Epoch [42/300], Step [192/225], Training Accuracy: 85.1237%, Training Loss: 0.3838%\n",
      "Epoch [42/300], Step [193/225], Training Accuracy: 85.1036%, Training Loss: 0.3840%\n",
      "Epoch [42/300], Step [194/225], Training Accuracy: 85.1079%, Training Loss: 0.3835%\n",
      "Epoch [42/300], Step [195/225], Training Accuracy: 85.1362%, Training Loss: 0.3828%\n",
      "Epoch [42/300], Step [196/225], Training Accuracy: 85.0925%, Training Loss: 0.3834%\n",
      "Epoch [42/300], Step [197/225], Training Accuracy: 85.1047%, Training Loss: 0.3833%\n",
      "Epoch [42/300], Step [198/225], Training Accuracy: 85.1010%, Training Loss: 0.3828%\n",
      "Epoch [42/300], Step [199/225], Training Accuracy: 85.0738%, Training Loss: 0.3830%\n",
      "Epoch [42/300], Step [200/225], Training Accuracy: 85.1250%, Training Loss: 0.3821%\n",
      "Epoch [42/300], Step [201/225], Training Accuracy: 85.1368%, Training Loss: 0.3822%\n",
      "Epoch [42/300], Step [202/225], Training Accuracy: 85.1330%, Training Loss: 0.3824%\n",
      "Epoch [42/300], Step [203/225], Training Accuracy: 85.1678%, Training Loss: 0.3817%\n",
      "Epoch [42/300], Step [204/225], Training Accuracy: 85.1716%, Training Loss: 0.3812%\n",
      "Epoch [42/300], Step [205/225], Training Accuracy: 85.1753%, Training Loss: 0.3805%\n",
      "Epoch [42/300], Step [206/225], Training Accuracy: 85.1790%, Training Loss: 0.3806%\n",
      "Epoch [42/300], Step [207/225], Training Accuracy: 85.1902%, Training Loss: 0.3801%\n",
      "Epoch [42/300], Step [208/225], Training Accuracy: 85.1788%, Training Loss: 0.3805%\n",
      "Epoch [42/300], Step [209/225], Training Accuracy: 85.1675%, Training Loss: 0.3810%\n",
      "Epoch [42/300], Step [210/225], Training Accuracy: 85.1637%, Training Loss: 0.3810%\n",
      "Epoch [42/300], Step [211/225], Training Accuracy: 85.1525%, Training Loss: 0.3810%\n",
      "Epoch [42/300], Step [212/225], Training Accuracy: 85.1489%, Training Loss: 0.3810%\n",
      "Epoch [42/300], Step [213/225], Training Accuracy: 85.1086%, Training Loss: 0.3819%\n",
      "Epoch [42/300], Step [214/225], Training Accuracy: 85.1051%, Training Loss: 0.3820%\n",
      "Epoch [42/300], Step [215/225], Training Accuracy: 85.1163%, Training Loss: 0.3818%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/300], Step [216/225], Training Accuracy: 85.0984%, Training Loss: 0.3826%\n",
      "Epoch [42/300], Step [217/225], Training Accuracy: 85.1022%, Training Loss: 0.3820%\n",
      "Epoch [42/300], Step [218/225], Training Accuracy: 85.0989%, Training Loss: 0.3822%\n",
      "Epoch [42/300], Step [219/225], Training Accuracy: 85.1027%, Training Loss: 0.3825%\n",
      "Epoch [42/300], Step [220/225], Training Accuracy: 85.1420%, Training Loss: 0.3817%\n",
      "Epoch [42/300], Step [221/225], Training Accuracy: 85.1669%, Training Loss: 0.3810%\n",
      "Epoch [42/300], Step [222/225], Training Accuracy: 85.1492%, Training Loss: 0.3809%\n",
      "Epoch [42/300], Step [223/225], Training Accuracy: 85.1247%, Training Loss: 0.3806%\n",
      "Epoch [42/300], Step [224/225], Training Accuracy: 85.1214%, Training Loss: 0.3805%\n",
      "Epoch [42/300], Step [225/225], Training Accuracy: 85.1306%, Training Loss: 0.3799%\n",
      "Epoch [43/300], Step [1/225], Training Accuracy: 75.0000%, Training Loss: 0.6372%\n",
      "Epoch [43/300], Step [2/225], Training Accuracy: 78.9062%, Training Loss: 0.5100%\n",
      "Epoch [43/300], Step [3/225], Training Accuracy: 82.2917%, Training Loss: 0.4260%\n",
      "Epoch [43/300], Step [4/225], Training Accuracy: 80.8594%, Training Loss: 0.4258%\n",
      "Epoch [43/300], Step [5/225], Training Accuracy: 80.0000%, Training Loss: 0.4405%\n",
      "Epoch [43/300], Step [6/225], Training Accuracy: 81.5104%, Training Loss: 0.4087%\n",
      "Epoch [43/300], Step [7/225], Training Accuracy: 81.4732%, Training Loss: 0.4086%\n",
      "Epoch [43/300], Step [8/225], Training Accuracy: 82.4219%, Training Loss: 0.4048%\n",
      "Epoch [43/300], Step [9/225], Training Accuracy: 82.4653%, Training Loss: 0.4062%\n",
      "Epoch [43/300], Step [10/225], Training Accuracy: 82.0312%, Training Loss: 0.4117%\n",
      "Epoch [43/300], Step [11/225], Training Accuracy: 81.8182%, Training Loss: 0.4186%\n",
      "Epoch [43/300], Step [12/225], Training Accuracy: 82.4219%, Training Loss: 0.4031%\n",
      "Epoch [43/300], Step [13/225], Training Accuracy: 82.8125%, Training Loss: 0.3998%\n",
      "Epoch [43/300], Step [14/225], Training Accuracy: 82.7009%, Training Loss: 0.4020%\n",
      "Epoch [43/300], Step [15/225], Training Accuracy: 83.5417%, Training Loss: 0.3913%\n",
      "Epoch [43/300], Step [16/225], Training Accuracy: 83.2031%, Training Loss: 0.3984%\n",
      "Epoch [43/300], Step [17/225], Training Accuracy: 83.5478%, Training Loss: 0.3919%\n",
      "Epoch [43/300], Step [18/225], Training Accuracy: 84.0278%, Training Loss: 0.3885%\n",
      "Epoch [43/300], Step [19/225], Training Accuracy: 84.2105%, Training Loss: 0.3868%\n",
      "Epoch [43/300], Step [20/225], Training Accuracy: 84.3750%, Training Loss: 0.3860%\n",
      "Epoch [43/300], Step [21/225], Training Accuracy: 84.7470%, Training Loss: 0.3777%\n",
      "Epoch [43/300], Step [22/225], Training Accuracy: 84.8722%, Training Loss: 0.3763%\n",
      "Epoch [43/300], Step [23/225], Training Accuracy: 84.5788%, Training Loss: 0.3768%\n",
      "Epoch [43/300], Step [24/225], Training Accuracy: 84.3750%, Training Loss: 0.3787%\n",
      "Epoch [43/300], Step [25/225], Training Accuracy: 84.3750%, Training Loss: 0.3756%\n",
      "Epoch [43/300], Step [26/225], Training Accuracy: 84.7356%, Training Loss: 0.3708%\n",
      "Epoch [43/300], Step [27/225], Training Accuracy: 85.0116%, Training Loss: 0.3683%\n",
      "Epoch [43/300], Step [28/225], Training Accuracy: 85.2679%, Training Loss: 0.3632%\n",
      "Epoch [43/300], Step [29/225], Training Accuracy: 85.1832%, Training Loss: 0.3645%\n",
      "Epoch [43/300], Step [30/225], Training Accuracy: 85.2083%, Training Loss: 0.3664%\n",
      "Epoch [43/300], Step [31/225], Training Accuracy: 84.8790%, Training Loss: 0.3744%\n",
      "Epoch [43/300], Step [32/225], Training Accuracy: 84.8145%, Training Loss: 0.3760%\n",
      "Epoch [43/300], Step [33/225], Training Accuracy: 84.9905%, Training Loss: 0.3738%\n",
      "Epoch [43/300], Step [34/225], Training Accuracy: 84.7886%, Training Loss: 0.3800%\n",
      "Epoch [43/300], Step [35/225], Training Accuracy: 84.9107%, Training Loss: 0.3767%\n",
      "Epoch [43/300], Step [36/225], Training Accuracy: 85.0260%, Training Loss: 0.3746%\n",
      "Epoch [43/300], Step [37/225], Training Accuracy: 85.0507%, Training Loss: 0.3756%\n",
      "Epoch [43/300], Step [38/225], Training Accuracy: 85.2385%, Training Loss: 0.3732%\n",
      "Epoch [43/300], Step [39/225], Training Accuracy: 85.0561%, Training Loss: 0.3789%\n",
      "Epoch [43/300], Step [40/225], Training Accuracy: 85.0781%, Training Loss: 0.3823%\n",
      "Epoch [43/300], Step [41/225], Training Accuracy: 84.9848%, Training Loss: 0.3848%\n",
      "Epoch [43/300], Step [42/225], Training Accuracy: 84.8958%, Training Loss: 0.3844%\n",
      "Epoch [43/300], Step [43/225], Training Accuracy: 84.8474%, Training Loss: 0.3855%\n",
      "Epoch [43/300], Step [44/225], Training Accuracy: 84.8011%, Training Loss: 0.3873%\n",
      "Epoch [43/300], Step [45/225], Training Accuracy: 84.7917%, Training Loss: 0.3894%\n",
      "Epoch [43/300], Step [46/225], Training Accuracy: 84.7826%, Training Loss: 0.3887%\n",
      "Epoch [43/300], Step [47/225], Training Accuracy: 84.8072%, Training Loss: 0.3880%\n",
      "Epoch [43/300], Step [48/225], Training Accuracy: 84.7331%, Training Loss: 0.3881%\n",
      "Epoch [43/300], Step [49/225], Training Accuracy: 84.7258%, Training Loss: 0.3916%\n",
      "Epoch [43/300], Step [50/225], Training Accuracy: 84.6562%, Training Loss: 0.3921%\n",
      "Epoch [43/300], Step [51/225], Training Accuracy: 84.8039%, Training Loss: 0.3885%\n",
      "Epoch [43/300], Step [52/225], Training Accuracy: 84.9159%, Training Loss: 0.3868%\n",
      "Epoch [43/300], Step [53/225], Training Accuracy: 84.8762%, Training Loss: 0.3892%\n",
      "Epoch [43/300], Step [54/225], Training Accuracy: 84.9537%, Training Loss: 0.3872%\n",
      "Epoch [43/300], Step [55/225], Training Accuracy: 84.7159%, Training Loss: 0.3921%\n",
      "Epoch [43/300], Step [56/225], Training Accuracy: 84.7935%, Training Loss: 0.3898%\n",
      "Epoch [43/300], Step [57/225], Training Accuracy: 84.6765%, Training Loss: 0.3907%\n",
      "Epoch [43/300], Step [58/225], Training Accuracy: 84.7791%, Training Loss: 0.3885%\n",
      "Epoch [43/300], Step [59/225], Training Accuracy: 84.6928%, Training Loss: 0.3903%\n",
      "Epoch [43/300], Step [60/225], Training Accuracy: 84.6875%, Training Loss: 0.3907%\n",
      "Epoch [43/300], Step [61/225], Training Accuracy: 84.7848%, Training Loss: 0.3886%\n",
      "Epoch [43/300], Step [62/225], Training Accuracy: 84.7782%, Training Loss: 0.3866%\n",
      "Epoch [43/300], Step [63/225], Training Accuracy: 84.7966%, Training Loss: 0.3866%\n",
      "Epoch [43/300], Step [64/225], Training Accuracy: 84.8877%, Training Loss: 0.3848%\n",
      "Epoch [43/300], Step [65/225], Training Accuracy: 84.8317%, Training Loss: 0.3857%\n",
      "Epoch [43/300], Step [66/225], Training Accuracy: 84.9195%, Training Loss: 0.3847%\n",
      "Epoch [43/300], Step [67/225], Training Accuracy: 84.9114%, Training Loss: 0.3840%\n",
      "Epoch [43/300], Step [68/225], Training Accuracy: 84.9035%, Training Loss: 0.3860%\n",
      "Epoch [43/300], Step [69/225], Training Accuracy: 84.7826%, Training Loss: 0.3874%\n",
      "Epoch [43/300], Step [70/225], Training Accuracy: 84.8214%, Training Loss: 0.3861%\n",
      "Epoch [43/300], Step [71/225], Training Accuracy: 84.8151%, Training Loss: 0.3862%\n",
      "Epoch [43/300], Step [72/225], Training Accuracy: 84.7656%, Training Loss: 0.3872%\n",
      "Epoch [43/300], Step [73/225], Training Accuracy: 84.7817%, Training Loss: 0.3870%\n",
      "Epoch [43/300], Step [74/225], Training Accuracy: 84.7128%, Training Loss: 0.3878%\n",
      "Epoch [43/300], Step [75/225], Training Accuracy: 84.6875%, Training Loss: 0.3876%\n",
      "Epoch [43/300], Step [76/225], Training Accuracy: 84.6217%, Training Loss: 0.3880%\n",
      "Epoch [43/300], Step [77/225], Training Accuracy: 84.6388%, Training Loss: 0.3884%\n",
      "Epoch [43/300], Step [78/225], Training Accuracy: 84.5954%, Training Loss: 0.3897%\n",
      "Epoch [43/300], Step [79/225], Training Accuracy: 84.5332%, Training Loss: 0.3898%\n",
      "Epoch [43/300], Step [80/225], Training Accuracy: 84.5508%, Training Loss: 0.3907%\n",
      "Epoch [43/300], Step [81/225], Training Accuracy: 84.5872%, Training Loss: 0.3905%\n",
      "Epoch [43/300], Step [82/225], Training Accuracy: 84.5465%, Training Loss: 0.3910%\n",
      "Epoch [43/300], Step [83/225], Training Accuracy: 84.5068%, Training Loss: 0.3922%\n",
      "Epoch [43/300], Step [84/225], Training Accuracy: 84.4680%, Training Loss: 0.3925%\n",
      "Epoch [43/300], Step [85/225], Training Accuracy: 84.5037%, Training Loss: 0.3914%\n",
      "Epoch [43/300], Step [86/225], Training Accuracy: 84.5022%, Training Loss: 0.3903%\n",
      "Epoch [43/300], Step [87/225], Training Accuracy: 84.5546%, Training Loss: 0.3897%\n",
      "Epoch [43/300], Step [88/225], Training Accuracy: 84.4638%, Training Loss: 0.3926%\n",
      "Epoch [43/300], Step [89/225], Training Accuracy: 84.3399%, Training Loss: 0.3946%\n",
      "Epoch [43/300], Step [90/225], Training Accuracy: 84.3056%, Training Loss: 0.3952%\n",
      "Epoch [43/300], Step [91/225], Training Accuracy: 84.2548%, Training Loss: 0.3966%\n",
      "Epoch [43/300], Step [92/225], Training Accuracy: 84.2221%, Training Loss: 0.3982%\n",
      "Epoch [43/300], Step [93/225], Training Accuracy: 84.2406%, Training Loss: 0.3975%\n",
      "Epoch [43/300], Step [94/225], Training Accuracy: 84.1755%, Training Loss: 0.4002%\n",
      "Epoch [43/300], Step [95/225], Training Accuracy: 84.2105%, Training Loss: 0.3989%\n",
      "Epoch [43/300], Step [96/225], Training Accuracy: 84.2936%, Training Loss: 0.3980%\n",
      "Epoch [43/300], Step [97/225], Training Accuracy: 84.2622%, Training Loss: 0.3985%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/300], Step [98/225], Training Accuracy: 84.2793%, Training Loss: 0.3985%\n",
      "Epoch [43/300], Step [99/225], Training Accuracy: 84.2961%, Training Loss: 0.3990%\n",
      "Epoch [43/300], Step [100/225], Training Accuracy: 84.1719%, Training Loss: 0.4012%\n",
      "Epoch [43/300], Step [101/225], Training Accuracy: 84.1894%, Training Loss: 0.4004%\n",
      "Epoch [43/300], Step [102/225], Training Accuracy: 84.2218%, Training Loss: 0.4006%\n",
      "Epoch [43/300], Step [103/225], Training Accuracy: 84.2840%, Training Loss: 0.3988%\n",
      "Epoch [43/300], Step [104/225], Training Accuracy: 84.1797%, Training Loss: 0.4003%\n",
      "Epoch [43/300], Step [105/225], Training Accuracy: 84.2113%, Training Loss: 0.3998%\n",
      "Epoch [43/300], Step [106/225], Training Accuracy: 84.1834%, Training Loss: 0.4002%\n",
      "Epoch [43/300], Step [107/225], Training Accuracy: 84.1852%, Training Loss: 0.4003%\n",
      "Epoch [43/300], Step [108/225], Training Accuracy: 84.2159%, Training Loss: 0.4000%\n",
      "Epoch [43/300], Step [109/225], Training Accuracy: 84.1743%, Training Loss: 0.4003%\n",
      "Epoch [43/300], Step [110/225], Training Accuracy: 84.2188%, Training Loss: 0.4001%\n",
      "Epoch [43/300], Step [111/225], Training Accuracy: 84.2202%, Training Loss: 0.4007%\n",
      "Epoch [43/300], Step [112/225], Training Accuracy: 84.2355%, Training Loss: 0.3998%\n",
      "Epoch [43/300], Step [113/225], Training Accuracy: 84.2506%, Training Loss: 0.3993%\n",
      "Epoch [43/300], Step [114/225], Training Accuracy: 84.2379%, Training Loss: 0.3992%\n",
      "Epoch [43/300], Step [115/225], Training Accuracy: 84.2391%, Training Loss: 0.3991%\n",
      "Epoch [43/300], Step [116/225], Training Accuracy: 84.1730%, Training Loss: 0.4001%\n",
      "Epoch [43/300], Step [117/225], Training Accuracy: 84.1480%, Training Loss: 0.3998%\n",
      "Epoch [43/300], Step [118/225], Training Accuracy: 84.1499%, Training Loss: 0.4006%\n",
      "Epoch [43/300], Step [119/225], Training Accuracy: 84.1780%, Training Loss: 0.3996%\n",
      "Epoch [43/300], Step [120/225], Training Accuracy: 84.1406%, Training Loss: 0.4001%\n",
      "Epoch [43/300], Step [121/225], Training Accuracy: 84.1296%, Training Loss: 0.4000%\n",
      "Epoch [43/300], Step [122/225], Training Accuracy: 84.0932%, Training Loss: 0.4024%\n",
      "Epoch [43/300], Step [123/225], Training Accuracy: 84.1209%, Training Loss: 0.4018%\n",
      "Epoch [43/300], Step [124/225], Training Accuracy: 84.1608%, Training Loss: 0.4008%\n",
      "Epoch [43/300], Step [125/225], Training Accuracy: 84.1000%, Training Loss: 0.4031%\n",
      "Epoch [43/300], Step [126/225], Training Accuracy: 84.0526%, Training Loss: 0.4042%\n",
      "Epoch [43/300], Step [127/225], Training Accuracy: 84.0182%, Training Loss: 0.4046%\n",
      "Epoch [43/300], Step [128/225], Training Accuracy: 84.0210%, Training Loss: 0.4048%\n",
      "Epoch [43/300], Step [129/225], Training Accuracy: 84.0480%, Training Loss: 0.4047%\n",
      "Epoch [43/300], Step [130/225], Training Accuracy: 84.0625%, Training Loss: 0.4046%\n",
      "Epoch [43/300], Step [131/225], Training Accuracy: 83.9933%, Training Loss: 0.4055%\n",
      "Epoch [43/300], Step [132/225], Training Accuracy: 83.9844%, Training Loss: 0.4064%\n",
      "Epoch [43/300], Step [133/225], Training Accuracy: 83.9873%, Training Loss: 0.4064%\n",
      "Epoch [43/300], Step [134/225], Training Accuracy: 83.9902%, Training Loss: 0.4072%\n",
      "Epoch [43/300], Step [135/225], Training Accuracy: 83.9931%, Training Loss: 0.4079%\n",
      "Epoch [43/300], Step [136/225], Training Accuracy: 83.9269%, Training Loss: 0.4081%\n",
      "Epoch [43/300], Step [137/225], Training Accuracy: 83.8732%, Training Loss: 0.4082%\n",
      "Epoch [43/300], Step [138/225], Training Accuracy: 83.9221%, Training Loss: 0.4071%\n",
      "Epoch [43/300], Step [139/225], Training Accuracy: 83.9029%, Training Loss: 0.4074%\n",
      "Epoch [43/300], Step [140/225], Training Accuracy: 83.8951%, Training Loss: 0.4083%\n",
      "Epoch [43/300], Step [141/225], Training Accuracy: 83.7877%, Training Loss: 0.4096%\n",
      "Epoch [43/300], Step [142/225], Training Accuracy: 83.8028%, Training Loss: 0.4088%\n",
      "Epoch [43/300], Step [143/225], Training Accuracy: 83.8615%, Training Loss: 0.4076%\n",
      "Epoch [43/300], Step [144/225], Training Accuracy: 83.8542%, Training Loss: 0.4066%\n",
      "Epoch [43/300], Step [145/225], Training Accuracy: 83.8685%, Training Loss: 0.4062%\n",
      "Epoch [43/300], Step [146/225], Training Accuracy: 83.8720%, Training Loss: 0.4056%\n",
      "Epoch [43/300], Step [147/225], Training Accuracy: 83.9073%, Training Loss: 0.4050%\n",
      "Epoch [43/300], Step [148/225], Training Accuracy: 83.9527%, Training Loss: 0.4038%\n",
      "Epoch [43/300], Step [149/225], Training Accuracy: 83.8507%, Training Loss: 0.4047%\n",
      "Epoch [43/300], Step [150/225], Training Accuracy: 83.8750%, Training Loss: 0.4040%\n",
      "Epoch [43/300], Step [151/225], Training Accuracy: 83.9094%, Training Loss: 0.4035%\n",
      "Epoch [43/300], Step [152/225], Training Accuracy: 83.9330%, Training Loss: 0.4034%\n",
      "Epoch [43/300], Step [153/225], Training Accuracy: 83.9461%, Training Loss: 0.4030%\n",
      "Epoch [43/300], Step [154/225], Training Accuracy: 83.9793%, Training Loss: 0.4020%\n",
      "Epoch [43/300], Step [155/225], Training Accuracy: 83.9617%, Training Loss: 0.4021%\n",
      "Epoch [43/300], Step [156/225], Training Accuracy: 83.9744%, Training Loss: 0.4021%\n",
      "Epoch [43/300], Step [157/225], Training Accuracy: 84.0167%, Training Loss: 0.4018%\n",
      "Epoch [43/300], Step [158/225], Training Accuracy: 83.9794%, Training Loss: 0.4026%\n",
      "Epoch [43/300], Step [159/225], Training Accuracy: 83.9230%, Training Loss: 0.4036%\n",
      "Epoch [43/300], Step [160/225], Training Accuracy: 83.9355%, Training Loss: 0.4034%\n",
      "Epoch [43/300], Step [161/225], Training Accuracy: 83.9674%, Training Loss: 0.4031%\n",
      "Epoch [43/300], Step [162/225], Training Accuracy: 83.9988%, Training Loss: 0.4025%\n",
      "Epoch [43/300], Step [163/225], Training Accuracy: 83.9916%, Training Loss: 0.4024%\n",
      "Epoch [43/300], Step [164/225], Training Accuracy: 84.0511%, Training Loss: 0.4011%\n",
      "Epoch [43/300], Step [165/225], Training Accuracy: 84.0152%, Training Loss: 0.4016%\n",
      "Epoch [43/300], Step [166/225], Training Accuracy: 84.0079%, Training Loss: 0.4015%\n",
      "Epoch [43/300], Step [167/225], Training Accuracy: 84.0288%, Training Loss: 0.4006%\n",
      "Epoch [43/300], Step [168/225], Training Accuracy: 83.9937%, Training Loss: 0.4014%\n",
      "Epoch [43/300], Step [169/225], Training Accuracy: 84.0514%, Training Loss: 0.3999%\n",
      "Epoch [43/300], Step [170/225], Training Accuracy: 84.0349%, Training Loss: 0.4005%\n",
      "Epoch [43/300], Step [171/225], Training Accuracy: 84.0278%, Training Loss: 0.4004%\n",
      "Epoch [43/300], Step [172/225], Training Accuracy: 83.9935%, Training Loss: 0.4002%\n",
      "Epoch [43/300], Step [173/225], Training Accuracy: 84.0228%, Training Loss: 0.3997%\n",
      "Epoch [43/300], Step [174/225], Training Accuracy: 84.0697%, Training Loss: 0.3987%\n",
      "Epoch [43/300], Step [175/225], Training Accuracy: 84.1161%, Training Loss: 0.3979%\n",
      "Epoch [43/300], Step [176/225], Training Accuracy: 84.0732%, Training Loss: 0.3986%\n",
      "Epoch [43/300], Step [177/225], Training Accuracy: 84.0837%, Training Loss: 0.3980%\n",
      "Epoch [43/300], Step [178/225], Training Accuracy: 84.1117%, Training Loss: 0.3978%\n",
      "Epoch [43/300], Step [179/225], Training Accuracy: 84.1219%, Training Loss: 0.3976%\n",
      "Epoch [43/300], Step [180/225], Training Accuracy: 84.1580%, Training Loss: 0.3973%\n",
      "Epoch [43/300], Step [181/225], Training Accuracy: 84.1851%, Training Loss: 0.3969%\n",
      "Epoch [43/300], Step [182/225], Training Accuracy: 84.2119%, Training Loss: 0.3959%\n",
      "Epoch [43/300], Step [183/225], Training Accuracy: 84.2555%, Training Loss: 0.3951%\n",
      "Epoch [43/300], Step [184/225], Training Accuracy: 84.2816%, Training Loss: 0.3943%\n",
      "Epoch [43/300], Step [185/225], Training Accuracy: 84.2905%, Training Loss: 0.3944%\n",
      "Epoch [43/300], Step [186/225], Training Accuracy: 84.2994%, Training Loss: 0.3945%\n",
      "Epoch [43/300], Step [187/225], Training Accuracy: 84.2831%, Training Loss: 0.3943%\n",
      "Epoch [43/300], Step [188/225], Training Accuracy: 84.3085%, Training Loss: 0.3939%\n",
      "Epoch [43/300], Step [189/225], Training Accuracy: 84.3006%, Training Loss: 0.3938%\n",
      "Epoch [43/300], Step [190/225], Training Accuracy: 84.2845%, Training Loss: 0.3945%\n",
      "Epoch [43/300], Step [191/225], Training Accuracy: 84.2605%, Training Loss: 0.3952%\n",
      "Epoch [43/300], Step [192/225], Training Accuracy: 84.3018%, Training Loss: 0.3944%\n",
      "Epoch [43/300], Step [193/225], Training Accuracy: 84.3264%, Training Loss: 0.3938%\n",
      "Epoch [43/300], Step [194/225], Training Accuracy: 84.3428%, Training Loss: 0.3938%\n",
      "Epoch [43/300], Step [195/225], Training Accuracy: 84.3670%, Training Loss: 0.3930%\n",
      "Epoch [43/300], Step [196/225], Training Accuracy: 84.3670%, Training Loss: 0.3931%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/300], Step [197/225], Training Accuracy: 84.3591%, Training Loss: 0.3935%\n",
      "Epoch [43/300], Step [198/225], Training Accuracy: 84.3513%, Training Loss: 0.3937%\n",
      "Epoch [43/300], Step [199/225], Training Accuracy: 84.3436%, Training Loss: 0.3934%\n",
      "Epoch [43/300], Step [200/225], Training Accuracy: 84.3359%, Training Loss: 0.3935%\n",
      "Epoch [43/300], Step [201/225], Training Accuracy: 84.3439%, Training Loss: 0.3935%\n",
      "Epoch [43/300], Step [202/225], Training Accuracy: 84.3827%, Training Loss: 0.3926%\n",
      "Epoch [43/300], Step [203/225], Training Accuracy: 84.4212%, Training Loss: 0.3922%\n",
      "Epoch [43/300], Step [204/225], Training Accuracy: 84.4669%, Training Loss: 0.3913%\n",
      "Epoch [43/300], Step [205/225], Training Accuracy: 84.4741%, Training Loss: 0.3912%\n",
      "Epoch [43/300], Step [206/225], Training Accuracy: 84.4812%, Training Loss: 0.3906%\n",
      "Epoch [43/300], Step [207/225], Training Accuracy: 84.4807%, Training Loss: 0.3908%\n",
      "Epoch [43/300], Step [208/225], Training Accuracy: 84.4802%, Training Loss: 0.3908%\n",
      "Epoch [43/300], Step [209/225], Training Accuracy: 84.4423%, Training Loss: 0.3912%\n",
      "Epoch [43/300], Step [210/225], Training Accuracy: 84.4643%, Training Loss: 0.3906%\n",
      "Epoch [43/300], Step [211/225], Training Accuracy: 84.4861%, Training Loss: 0.3906%\n",
      "Epoch [43/300], Step [212/225], Training Accuracy: 84.4929%, Training Loss: 0.3908%\n",
      "Epoch [43/300], Step [213/225], Training Accuracy: 84.4630%, Training Loss: 0.3911%\n",
      "Epoch [43/300], Step [214/225], Training Accuracy: 84.4626%, Training Loss: 0.3911%\n",
      "Epoch [43/300], Step [215/225], Training Accuracy: 84.4840%, Training Loss: 0.3906%\n",
      "Epoch [43/300], Step [216/225], Training Accuracy: 84.4546%, Training Loss: 0.3909%\n",
      "Epoch [43/300], Step [217/225], Training Accuracy: 84.4398%, Training Loss: 0.3912%\n",
      "Epoch [43/300], Step [218/225], Training Accuracy: 84.4252%, Training Loss: 0.3915%\n",
      "Epoch [43/300], Step [219/225], Training Accuracy: 84.4178%, Training Loss: 0.3913%\n",
      "Epoch [43/300], Step [220/225], Training Accuracy: 84.4247%, Training Loss: 0.3912%\n",
      "Epoch [43/300], Step [221/225], Training Accuracy: 84.4386%, Training Loss: 0.3910%\n",
      "Epoch [43/300], Step [222/225], Training Accuracy: 84.4595%, Training Loss: 0.3907%\n",
      "Epoch [43/300], Step [223/225], Training Accuracy: 84.4661%, Training Loss: 0.3902%\n",
      "Epoch [43/300], Step [224/225], Training Accuracy: 84.4866%, Training Loss: 0.3899%\n",
      "Epoch [43/300], Step [225/225], Training Accuracy: 84.4844%, Training Loss: 0.3899%\n",
      "Epoch [44/300], Step [1/225], Training Accuracy: 89.0625%, Training Loss: 0.3602%\n",
      "Epoch [44/300], Step [2/225], Training Accuracy: 86.7188%, Training Loss: 0.3608%\n",
      "Epoch [44/300], Step [3/225], Training Accuracy: 86.9792%, Training Loss: 0.3478%\n",
      "Epoch [44/300], Step [4/225], Training Accuracy: 87.1094%, Training Loss: 0.3389%\n",
      "Epoch [44/300], Step [5/225], Training Accuracy: 86.8750%, Training Loss: 0.3451%\n",
      "Epoch [44/300], Step [6/225], Training Accuracy: 87.2396%, Training Loss: 0.3332%\n",
      "Epoch [44/300], Step [7/225], Training Accuracy: 87.2768%, Training Loss: 0.3259%\n",
      "Epoch [44/300], Step [8/225], Training Accuracy: 87.1094%, Training Loss: 0.3369%\n",
      "Epoch [44/300], Step [9/225], Training Accuracy: 87.1528%, Training Loss: 0.3359%\n",
      "Epoch [44/300], Step [10/225], Training Accuracy: 87.0312%, Training Loss: 0.3463%\n",
      "Epoch [44/300], Step [11/225], Training Accuracy: 86.9318%, Training Loss: 0.3539%\n",
      "Epoch [44/300], Step [12/225], Training Accuracy: 86.9792%, Training Loss: 0.3524%\n",
      "Epoch [44/300], Step [13/225], Training Accuracy: 87.6202%, Training Loss: 0.3417%\n",
      "Epoch [44/300], Step [14/225], Training Accuracy: 87.8348%, Training Loss: 0.3395%\n",
      "Epoch [44/300], Step [15/225], Training Accuracy: 87.8125%, Training Loss: 0.3323%\n",
      "Epoch [44/300], Step [16/225], Training Accuracy: 87.8906%, Training Loss: 0.3271%\n",
      "Epoch [44/300], Step [17/225], Training Accuracy: 87.6838%, Training Loss: 0.3272%\n",
      "Epoch [44/300], Step [18/225], Training Accuracy: 87.5868%, Training Loss: 0.3277%\n",
      "Epoch [44/300], Step [19/225], Training Accuracy: 87.3355%, Training Loss: 0.3309%\n",
      "Epoch [44/300], Step [20/225], Training Accuracy: 87.6562%, Training Loss: 0.3242%\n",
      "Epoch [44/300], Step [21/225], Training Accuracy: 87.5000%, Training Loss: 0.3257%\n",
      "Epoch [44/300], Step [22/225], Training Accuracy: 87.1449%, Training Loss: 0.3290%\n",
      "Epoch [44/300], Step [23/225], Training Accuracy: 86.9565%, Training Loss: 0.3315%\n",
      "Epoch [44/300], Step [24/225], Training Accuracy: 86.9792%, Training Loss: 0.3368%\n",
      "Epoch [44/300], Step [25/225], Training Accuracy: 86.8750%, Training Loss: 0.3415%\n",
      "Epoch [44/300], Step [26/225], Training Accuracy: 86.8990%, Training Loss: 0.3407%\n",
      "Epoch [44/300], Step [27/225], Training Accuracy: 86.8634%, Training Loss: 0.3419%\n",
      "Epoch [44/300], Step [28/225], Training Accuracy: 87.0536%, Training Loss: 0.3372%\n",
      "Epoch [44/300], Step [29/225], Training Accuracy: 87.1228%, Training Loss: 0.3353%\n",
      "Epoch [44/300], Step [30/225], Training Accuracy: 87.0312%, Training Loss: 0.3343%\n",
      "Epoch [44/300], Step [31/225], Training Accuracy: 86.8952%, Training Loss: 0.3382%\n",
      "Epoch [44/300], Step [32/225], Training Accuracy: 86.6699%, Training Loss: 0.3419%\n",
      "Epoch [44/300], Step [33/225], Training Accuracy: 86.8371%, Training Loss: 0.3428%\n",
      "Epoch [44/300], Step [34/225], Training Accuracy: 86.6268%, Training Loss: 0.3487%\n",
      "Epoch [44/300], Step [35/225], Training Accuracy: 86.4286%, Training Loss: 0.3528%\n",
      "Epoch [44/300], Step [36/225], Training Accuracy: 86.4583%, Training Loss: 0.3506%\n",
      "Epoch [44/300], Step [37/225], Training Accuracy: 86.5287%, Training Loss: 0.3500%\n",
      "Epoch [44/300], Step [38/225], Training Accuracy: 86.3898%, Training Loss: 0.3548%\n",
      "Epoch [44/300], Step [39/225], Training Accuracy: 86.3782%, Training Loss: 0.3558%\n",
      "Epoch [44/300], Step [40/225], Training Accuracy: 86.1719%, Training Loss: 0.3628%\n",
      "Epoch [44/300], Step [41/225], Training Accuracy: 86.0137%, Training Loss: 0.3696%\n",
      "Epoch [44/300], Step [42/225], Training Accuracy: 85.9375%, Training Loss: 0.3695%\n",
      "Epoch [44/300], Step [43/225], Training Accuracy: 85.9012%, Training Loss: 0.3689%\n",
      "Epoch [44/300], Step [44/225], Training Accuracy: 85.9020%, Training Loss: 0.3686%\n",
      "Epoch [44/300], Step [45/225], Training Accuracy: 85.8681%, Training Loss: 0.3682%\n",
      "Epoch [44/300], Step [46/225], Training Accuracy: 85.8696%, Training Loss: 0.3658%\n",
      "Epoch [44/300], Step [47/225], Training Accuracy: 85.6383%, Training Loss: 0.3705%\n",
      "Epoch [44/300], Step [48/225], Training Accuracy: 85.6120%, Training Loss: 0.3697%\n",
      "Epoch [44/300], Step [49/225], Training Accuracy: 85.6824%, Training Loss: 0.3670%\n",
      "Epoch [44/300], Step [50/225], Training Accuracy: 85.5312%, Training Loss: 0.3706%\n",
      "Epoch [44/300], Step [51/225], Training Accuracy: 85.5392%, Training Loss: 0.3712%\n",
      "Epoch [44/300], Step [52/225], Training Accuracy: 85.5769%, Training Loss: 0.3691%\n",
      "Epoch [44/300], Step [53/225], Training Accuracy: 85.4363%, Training Loss: 0.3733%\n",
      "Epoch [44/300], Step [54/225], Training Accuracy: 85.3877%, Training Loss: 0.3758%\n",
      "Epoch [44/300], Step [55/225], Training Accuracy: 85.2273%, Training Loss: 0.3780%\n",
      "Epoch [44/300], Step [56/225], Training Accuracy: 85.2958%, Training Loss: 0.3770%\n",
      "Epoch [44/300], Step [57/225], Training Accuracy: 85.3618%, Training Loss: 0.3753%\n",
      "Epoch [44/300], Step [58/225], Training Accuracy: 85.2371%, Training Loss: 0.3787%\n",
      "Epoch [44/300], Step [59/225], Training Accuracy: 85.1430%, Training Loss: 0.3807%\n",
      "Epoch [44/300], Step [60/225], Training Accuracy: 85.2604%, Training Loss: 0.3801%\n",
      "Epoch [44/300], Step [61/225], Training Accuracy: 85.2971%, Training Loss: 0.3797%\n",
      "Epoch [44/300], Step [62/225], Training Accuracy: 85.3831%, Training Loss: 0.3769%\n",
      "Epoch [44/300], Step [63/225], Training Accuracy: 85.3671%, Training Loss: 0.3773%\n",
      "Epoch [44/300], Step [64/225], Training Accuracy: 85.2539%, Training Loss: 0.3790%\n",
      "Epoch [44/300], Step [65/225], Training Accuracy: 85.2163%, Training Loss: 0.3789%\n",
      "Epoch [44/300], Step [66/225], Training Accuracy: 85.2746%, Training Loss: 0.3767%\n",
      "Epoch [44/300], Step [67/225], Training Accuracy: 85.2612%, Training Loss: 0.3765%\n",
      "Epoch [44/300], Step [68/225], Training Accuracy: 85.2941%, Training Loss: 0.3755%\n",
      "Epoch [44/300], Step [69/225], Training Accuracy: 85.3034%, Training Loss: 0.3759%\n",
      "Epoch [44/300], Step [70/225], Training Accuracy: 85.3348%, Training Loss: 0.3751%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/300], Step [71/225], Training Accuracy: 85.3213%, Training Loss: 0.3750%\n",
      "Epoch [44/300], Step [72/225], Training Accuracy: 85.3299%, Training Loss: 0.3733%\n",
      "Epoch [44/300], Step [73/225], Training Accuracy: 85.2740%, Training Loss: 0.3756%\n",
      "Epoch [44/300], Step [74/225], Training Accuracy: 85.2407%, Training Loss: 0.3758%\n",
      "Epoch [44/300], Step [75/225], Training Accuracy: 85.2292%, Training Loss: 0.3751%\n",
      "Epoch [44/300], Step [76/225], Training Accuracy: 85.1974%, Training Loss: 0.3758%\n",
      "Epoch [44/300], Step [77/225], Training Accuracy: 85.2273%, Training Loss: 0.3749%\n",
      "Epoch [44/300], Step [78/225], Training Accuracy: 85.2364%, Training Loss: 0.3755%\n",
      "Epoch [44/300], Step [79/225], Training Accuracy: 85.2255%, Training Loss: 0.3759%\n",
      "Epoch [44/300], Step [80/225], Training Accuracy: 85.1562%, Training Loss: 0.3769%\n",
      "Epoch [44/300], Step [81/225], Training Accuracy: 85.1852%, Training Loss: 0.3760%\n",
      "Epoch [44/300], Step [82/225], Training Accuracy: 85.2325%, Training Loss: 0.3746%\n",
      "Epoch [44/300], Step [83/225], Training Accuracy: 85.2221%, Training Loss: 0.3755%\n",
      "Epoch [44/300], Step [84/225], Training Accuracy: 85.2679%, Training Loss: 0.3741%\n",
      "Epoch [44/300], Step [85/225], Training Accuracy: 85.2757%, Training Loss: 0.3755%\n",
      "Epoch [44/300], Step [86/225], Training Accuracy: 85.2289%, Training Loss: 0.3768%\n",
      "Epoch [44/300], Step [87/225], Training Accuracy: 85.1832%, Training Loss: 0.3781%\n",
      "Epoch [44/300], Step [88/225], Training Accuracy: 85.1030%, Training Loss: 0.3785%\n",
      "Epoch [44/300], Step [89/225], Training Accuracy: 85.1475%, Training Loss: 0.3780%\n",
      "Epoch [44/300], Step [90/225], Training Accuracy: 84.9479%, Training Loss: 0.3823%\n",
      "Epoch [44/300], Step [91/225], Training Accuracy: 84.9588%, Training Loss: 0.3832%\n",
      "Epoch [44/300], Step [92/225], Training Accuracy: 84.9015%, Training Loss: 0.3837%\n",
      "Epoch [44/300], Step [93/225], Training Accuracy: 84.9630%, Training Loss: 0.3822%\n",
      "Epoch [44/300], Step [94/225], Training Accuracy: 84.9235%, Training Loss: 0.3821%\n",
      "Epoch [44/300], Step [95/225], Training Accuracy: 84.8355%, Training Loss: 0.3844%\n",
      "Epoch [44/300], Step [96/225], Training Accuracy: 84.8307%, Training Loss: 0.3842%\n",
      "Epoch [44/300], Step [97/225], Training Accuracy: 84.8744%, Training Loss: 0.3831%\n",
      "Epoch [44/300], Step [98/225], Training Accuracy: 84.8533%, Training Loss: 0.3831%\n",
      "Epoch [44/300], Step [99/225], Training Accuracy: 84.8169%, Training Loss: 0.3832%\n",
      "Epoch [44/300], Step [100/225], Training Accuracy: 84.7500%, Training Loss: 0.3840%\n",
      "Epoch [44/300], Step [101/225], Training Accuracy: 84.7618%, Training Loss: 0.3833%\n",
      "Epoch [44/300], Step [102/225], Training Accuracy: 84.7580%, Training Loss: 0.3838%\n",
      "Epoch [44/300], Step [103/225], Training Accuracy: 84.8453%, Training Loss: 0.3823%\n",
      "Epoch [44/300], Step [104/225], Training Accuracy: 84.8558%, Training Loss: 0.3822%\n",
      "Epoch [44/300], Step [105/225], Training Accuracy: 84.8661%, Training Loss: 0.3816%\n",
      "Epoch [44/300], Step [106/225], Training Accuracy: 84.8762%, Training Loss: 0.3811%\n",
      "Epoch [44/300], Step [107/225], Training Accuracy: 84.7693%, Training Loss: 0.3823%\n",
      "Epoch [44/300], Step [108/225], Training Accuracy: 84.6788%, Training Loss: 0.3841%\n",
      "Epoch [44/300], Step [109/225], Training Accuracy: 84.5900%, Training Loss: 0.3846%\n",
      "Epoch [44/300], Step [110/225], Training Accuracy: 84.5312%, Training Loss: 0.3862%\n",
      "Epoch [44/300], Step [111/225], Training Accuracy: 84.5298%, Training Loss: 0.3856%\n",
      "Epoch [44/300], Step [112/225], Training Accuracy: 84.5424%, Training Loss: 0.3850%\n",
      "Epoch [44/300], Step [113/225], Training Accuracy: 84.4994%, Training Loss: 0.3865%\n",
      "Epoch [44/300], Step [114/225], Training Accuracy: 84.5258%, Training Loss: 0.3859%\n",
      "Epoch [44/300], Step [115/225], Training Accuracy: 84.5516%, Training Loss: 0.3854%\n",
      "Epoch [44/300], Step [116/225], Training Accuracy: 84.5232%, Training Loss: 0.3860%\n",
      "Epoch [44/300], Step [117/225], Training Accuracy: 84.5486%, Training Loss: 0.3858%\n",
      "Epoch [44/300], Step [118/225], Training Accuracy: 84.5471%, Training Loss: 0.3858%\n",
      "Epoch [44/300], Step [119/225], Training Accuracy: 84.5720%, Training Loss: 0.3853%\n",
      "Epoch [44/300], Step [120/225], Training Accuracy: 84.5703%, Training Loss: 0.3848%\n",
      "Epoch [44/300], Step [121/225], Training Accuracy: 84.5558%, Training Loss: 0.3851%\n",
      "Epoch [44/300], Step [122/225], Training Accuracy: 84.5671%, Training Loss: 0.3845%\n",
      "Epoch [44/300], Step [123/225], Training Accuracy: 84.5783%, Training Loss: 0.3838%\n",
      "Epoch [44/300], Step [124/225], Training Accuracy: 84.6144%, Training Loss: 0.3831%\n",
      "Epoch [44/300], Step [125/225], Training Accuracy: 84.6125%, Training Loss: 0.3840%\n",
      "Epoch [44/300], Step [126/225], Training Accuracy: 84.6230%, Training Loss: 0.3836%\n",
      "Epoch [44/300], Step [127/225], Training Accuracy: 84.6949%, Training Loss: 0.3827%\n",
      "Epoch [44/300], Step [128/225], Training Accuracy: 84.6802%, Training Loss: 0.3829%\n",
      "Epoch [44/300], Step [129/225], Training Accuracy: 84.6778%, Training Loss: 0.3839%\n",
      "Epoch [44/300], Step [130/225], Training Accuracy: 84.6875%, Training Loss: 0.3841%\n",
      "Epoch [44/300], Step [131/225], Training Accuracy: 84.7090%, Training Loss: 0.3836%\n",
      "Epoch [44/300], Step [132/225], Training Accuracy: 84.6709%, Training Loss: 0.3840%\n",
      "Epoch [44/300], Step [133/225], Training Accuracy: 84.6922%, Training Loss: 0.3834%\n",
      "Epoch [44/300], Step [134/225], Training Accuracy: 84.6432%, Training Loss: 0.3850%\n",
      "Epoch [44/300], Step [135/225], Training Accuracy: 84.6412%, Training Loss: 0.3844%\n",
      "Epoch [44/300], Step [136/225], Training Accuracy: 84.6163%, Training Loss: 0.3846%\n",
      "Epoch [44/300], Step [137/225], Training Accuracy: 84.6259%, Training Loss: 0.3849%\n",
      "Epoch [44/300], Step [138/225], Training Accuracy: 84.6241%, Training Loss: 0.3842%\n",
      "Epoch [44/300], Step [139/225], Training Accuracy: 84.5998%, Training Loss: 0.3849%\n",
      "Epoch [44/300], Step [140/225], Training Accuracy: 84.5647%, Training Loss: 0.3863%\n",
      "Epoch [44/300], Step [141/225], Training Accuracy: 84.5634%, Training Loss: 0.3864%\n",
      "Epoch [44/300], Step [142/225], Training Accuracy: 84.4960%, Training Loss: 0.3874%\n",
      "Epoch [44/300], Step [143/225], Training Accuracy: 84.5061%, Training Loss: 0.3876%\n",
      "Epoch [44/300], Step [144/225], Training Accuracy: 84.5161%, Training Loss: 0.3874%\n",
      "Epoch [44/300], Step [145/225], Training Accuracy: 84.4828%, Training Loss: 0.3880%\n",
      "Epoch [44/300], Step [146/225], Training Accuracy: 84.5248%, Training Loss: 0.3878%\n",
      "Epoch [44/300], Step [147/225], Training Accuracy: 84.5557%, Training Loss: 0.3872%\n",
      "Epoch [44/300], Step [148/225], Training Accuracy: 84.5334%, Training Loss: 0.3872%\n",
      "Epoch [44/300], Step [149/225], Training Accuracy: 84.5323%, Training Loss: 0.3871%\n",
      "Epoch [44/300], Step [150/225], Training Accuracy: 84.5625%, Training Loss: 0.3864%\n",
      "Epoch [44/300], Step [151/225], Training Accuracy: 84.5613%, Training Loss: 0.3859%\n",
      "Epoch [44/300], Step [152/225], Training Accuracy: 84.5600%, Training Loss: 0.3858%\n",
      "Epoch [44/300], Step [153/225], Training Accuracy: 84.5486%, Training Loss: 0.3861%\n",
      "Epoch [44/300], Step [154/225], Training Accuracy: 84.5678%, Training Loss: 0.3862%\n",
      "Epoch [44/300], Step [155/225], Training Accuracy: 84.5464%, Training Loss: 0.3873%\n",
      "Epoch [44/300], Step [156/225], Training Accuracy: 84.5753%, Training Loss: 0.3869%\n",
      "Epoch [44/300], Step [157/225], Training Accuracy: 84.5541%, Training Loss: 0.3880%\n",
      "Epoch [44/300], Step [158/225], Training Accuracy: 84.5728%, Training Loss: 0.3876%\n",
      "Epoch [44/300], Step [159/225], Training Accuracy: 84.5421%, Training Loss: 0.3878%\n",
      "Epoch [44/300], Step [160/225], Training Accuracy: 84.5117%, Training Loss: 0.3882%\n",
      "Epoch [44/300], Step [161/225], Training Accuracy: 84.5400%, Training Loss: 0.3876%\n",
      "Epoch [44/300], Step [162/225], Training Accuracy: 84.4715%, Training Loss: 0.3878%\n",
      "Epoch [44/300], Step [163/225], Training Accuracy: 84.4804%, Training Loss: 0.3871%\n",
      "Epoch [44/300], Step [164/225], Training Accuracy: 84.4607%, Training Loss: 0.3874%\n",
      "Epoch [44/300], Step [165/225], Training Accuracy: 84.4697%, Training Loss: 0.3870%\n",
      "Epoch [44/300], Step [166/225], Training Accuracy: 84.4691%, Training Loss: 0.3870%\n",
      "Epoch [44/300], Step [167/225], Training Accuracy: 84.4592%, Training Loss: 0.3874%\n",
      "Epoch [44/300], Step [168/225], Training Accuracy: 84.4494%, Training Loss: 0.3875%\n",
      "Epoch [44/300], Step [169/225], Training Accuracy: 84.5229%, Training Loss: 0.3860%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/300], Step [170/225], Training Accuracy: 84.5221%, Training Loss: 0.3859%\n",
      "Epoch [44/300], Step [171/225], Training Accuracy: 84.5029%, Training Loss: 0.3860%\n",
      "Epoch [44/300], Step [172/225], Training Accuracy: 84.5022%, Training Loss: 0.3868%\n",
      "Epoch [44/300], Step [173/225], Training Accuracy: 84.5014%, Training Loss: 0.3874%\n",
      "Epoch [44/300], Step [174/225], Training Accuracy: 84.5456%, Training Loss: 0.3871%\n",
      "Epoch [44/300], Step [175/225], Training Accuracy: 84.5625%, Training Loss: 0.3869%\n",
      "Epoch [44/300], Step [176/225], Training Accuracy: 84.5526%, Training Loss: 0.3863%\n",
      "Epoch [44/300], Step [177/225], Training Accuracy: 84.5692%, Training Loss: 0.3855%\n",
      "Epoch [44/300], Step [178/225], Training Accuracy: 84.5593%, Training Loss: 0.3855%\n",
      "Epoch [44/300], Step [179/225], Training Accuracy: 84.5670%, Training Loss: 0.3850%\n",
      "Epoch [44/300], Step [180/225], Training Accuracy: 84.5660%, Training Loss: 0.3853%\n",
      "Epoch [44/300], Step [181/225], Training Accuracy: 84.5477%, Training Loss: 0.3854%\n",
      "Epoch [44/300], Step [182/225], Training Accuracy: 84.5295%, Training Loss: 0.3856%\n",
      "Epoch [44/300], Step [183/225], Training Accuracy: 84.5116%, Training Loss: 0.3862%\n",
      "Epoch [44/300], Step [184/225], Training Accuracy: 84.5448%, Training Loss: 0.3860%\n",
      "Epoch [44/300], Step [185/225], Training Accuracy: 84.5693%, Training Loss: 0.3852%\n",
      "Epoch [44/300], Step [186/225], Training Accuracy: 84.5766%, Training Loss: 0.3852%\n",
      "Epoch [44/300], Step [187/225], Training Accuracy: 84.5755%, Training Loss: 0.3851%\n",
      "Epoch [44/300], Step [188/225], Training Accuracy: 84.5911%, Training Loss: 0.3849%\n",
      "Epoch [44/300], Step [189/225], Training Accuracy: 84.6147%, Training Loss: 0.3844%\n",
      "Epoch [44/300], Step [190/225], Training Accuracy: 84.6217%, Training Loss: 0.3845%\n",
      "Epoch [44/300], Step [191/225], Training Accuracy: 84.5877%, Training Loss: 0.3849%\n",
      "Epoch [44/300], Step [192/225], Training Accuracy: 84.6191%, Training Loss: 0.3842%\n",
      "Epoch [44/300], Step [193/225], Training Accuracy: 84.6422%, Training Loss: 0.3839%\n",
      "Epoch [44/300], Step [194/225], Training Accuracy: 84.6408%, Training Loss: 0.3837%\n",
      "Epoch [44/300], Step [195/225], Training Accuracy: 84.6554%, Training Loss: 0.3830%\n",
      "Epoch [44/300], Step [196/225], Training Accuracy: 84.6301%, Training Loss: 0.3833%\n",
      "Epoch [44/300], Step [197/225], Training Accuracy: 84.6367%, Training Loss: 0.3835%\n",
      "Epoch [44/300], Step [198/225], Training Accuracy: 84.6907%, Training Loss: 0.3826%\n",
      "Epoch [44/300], Step [199/225], Training Accuracy: 84.6969%, Training Loss: 0.3827%\n",
      "Epoch [44/300], Step [200/225], Training Accuracy: 84.6953%, Training Loss: 0.3829%\n",
      "Epoch [44/300], Step [201/225], Training Accuracy: 84.7170%, Training Loss: 0.3823%\n",
      "Epoch [44/300], Step [202/225], Training Accuracy: 84.6689%, Training Loss: 0.3830%\n",
      "Epoch [44/300], Step [203/225], Training Accuracy: 84.6906%, Training Loss: 0.3824%\n",
      "Epoch [44/300], Step [204/225], Training Accuracy: 84.7273%, Training Loss: 0.3820%\n",
      "Epoch [44/300], Step [205/225], Training Accuracy: 84.7332%, Training Loss: 0.3818%\n",
      "Epoch [44/300], Step [206/225], Training Accuracy: 84.7239%, Training Loss: 0.3819%\n",
      "Epoch [44/300], Step [207/225], Training Accuracy: 84.7298%, Training Loss: 0.3817%\n",
      "Epoch [44/300], Step [208/225], Training Accuracy: 84.7581%, Training Loss: 0.3809%\n",
      "Epoch [44/300], Step [209/225], Training Accuracy: 84.7563%, Training Loss: 0.3810%\n",
      "Epoch [44/300], Step [210/225], Training Accuracy: 84.7470%, Training Loss: 0.3809%\n",
      "Epoch [44/300], Step [211/225], Training Accuracy: 84.7305%, Training Loss: 0.3811%\n",
      "Epoch [44/300], Step [212/225], Training Accuracy: 84.7509%, Training Loss: 0.3808%\n",
      "Epoch [44/300], Step [213/225], Training Accuracy: 84.7271%, Training Loss: 0.3809%\n",
      "Epoch [44/300], Step [214/225], Training Accuracy: 84.7255%, Training Loss: 0.3809%\n",
      "Epoch [44/300], Step [215/225], Training Accuracy: 84.7020%, Training Loss: 0.3815%\n",
      "Epoch [44/300], Step [216/225], Training Accuracy: 84.6933%, Training Loss: 0.3822%\n",
      "Epoch [44/300], Step [217/225], Training Accuracy: 84.6846%, Training Loss: 0.3829%\n",
      "Epoch [44/300], Step [218/225], Training Accuracy: 84.6760%, Training Loss: 0.3827%\n",
      "Epoch [44/300], Step [219/225], Training Accuracy: 84.6961%, Training Loss: 0.3822%\n",
      "Epoch [44/300], Step [220/225], Training Accuracy: 84.7088%, Training Loss: 0.3819%\n",
      "Epoch [44/300], Step [221/225], Training Accuracy: 84.7356%, Training Loss: 0.3814%\n",
      "Epoch [44/300], Step [222/225], Training Accuracy: 84.7621%, Training Loss: 0.3811%\n",
      "Epoch [44/300], Step [223/225], Training Accuracy: 84.7393%, Training Loss: 0.3812%\n",
      "Epoch [44/300], Step [224/225], Training Accuracy: 84.7377%, Training Loss: 0.3812%\n",
      "Epoch [44/300], Step [225/225], Training Accuracy: 84.7693%, Training Loss: 0.3805%\n",
      "Epoch [45/300], Step [1/225], Training Accuracy: 84.3750%, Training Loss: 0.4014%\n",
      "Epoch [45/300], Step [2/225], Training Accuracy: 82.8125%, Training Loss: 0.4539%\n",
      "Epoch [45/300], Step [3/225], Training Accuracy: 82.2917%, Training Loss: 0.4735%\n",
      "Epoch [45/300], Step [4/225], Training Accuracy: 82.8125%, Training Loss: 0.5221%\n",
      "Epoch [45/300], Step [5/225], Training Accuracy: 81.8750%, Training Loss: 0.5116%\n",
      "Epoch [45/300], Step [6/225], Training Accuracy: 82.2917%, Training Loss: 0.4758%\n",
      "Epoch [45/300], Step [7/225], Training Accuracy: 83.4821%, Training Loss: 0.4524%\n",
      "Epoch [45/300], Step [8/225], Training Accuracy: 82.2266%, Training Loss: 0.4561%\n",
      "Epoch [45/300], Step [9/225], Training Accuracy: 82.4653%, Training Loss: 0.4492%\n",
      "Epoch [45/300], Step [10/225], Training Accuracy: 82.1875%, Training Loss: 0.4473%\n",
      "Epoch [45/300], Step [11/225], Training Accuracy: 82.5284%, Training Loss: 0.4374%\n",
      "Epoch [45/300], Step [12/225], Training Accuracy: 82.6823%, Training Loss: 0.4250%\n",
      "Epoch [45/300], Step [13/225], Training Accuracy: 83.4135%, Training Loss: 0.4104%\n",
      "Epoch [45/300], Step [14/225], Training Accuracy: 83.8170%, Training Loss: 0.3957%\n",
      "Epoch [45/300], Step [15/225], Training Accuracy: 83.6458%, Training Loss: 0.3984%\n",
      "Epoch [45/300], Step [16/225], Training Accuracy: 83.5938%, Training Loss: 0.3988%\n",
      "Epoch [45/300], Step [17/225], Training Accuracy: 83.8235%, Training Loss: 0.3954%\n",
      "Epoch [45/300], Step [18/225], Training Accuracy: 84.0278%, Training Loss: 0.4003%\n",
      "Epoch [45/300], Step [19/225], Training Accuracy: 84.3750%, Training Loss: 0.3973%\n",
      "Epoch [45/300], Step [20/225], Training Accuracy: 84.5312%, Training Loss: 0.3888%\n",
      "Epoch [45/300], Step [21/225], Training Accuracy: 84.6726%, Training Loss: 0.3847%\n",
      "Epoch [45/300], Step [22/225], Training Accuracy: 84.3750%, Training Loss: 0.3876%\n",
      "Epoch [45/300], Step [23/225], Training Accuracy: 84.5109%, Training Loss: 0.3881%\n",
      "Epoch [45/300], Step [24/225], Training Accuracy: 84.3099%, Training Loss: 0.3917%\n",
      "Epoch [45/300], Step [25/225], Training Accuracy: 84.3125%, Training Loss: 0.3877%\n",
      "Epoch [45/300], Step [26/225], Training Accuracy: 84.6154%, Training Loss: 0.3866%\n",
      "Epoch [45/300], Step [27/225], Training Accuracy: 84.7801%, Training Loss: 0.3822%\n",
      "Epoch [45/300], Step [28/225], Training Accuracy: 84.9330%, Training Loss: 0.3801%\n",
      "Epoch [45/300], Step [29/225], Training Accuracy: 85.2371%, Training Loss: 0.3750%\n",
      "Epoch [45/300], Step [30/225], Training Accuracy: 85.4167%, Training Loss: 0.3694%\n",
      "Epoch [45/300], Step [31/225], Training Accuracy: 85.3831%, Training Loss: 0.3721%\n",
      "Epoch [45/300], Step [32/225], Training Accuracy: 85.4492%, Training Loss: 0.3720%\n",
      "Epoch [45/300], Step [33/225], Training Accuracy: 85.4167%, Training Loss: 0.3709%\n",
      "Epoch [45/300], Step [34/225], Training Accuracy: 85.2482%, Training Loss: 0.3782%\n",
      "Epoch [45/300], Step [35/225], Training Accuracy: 85.0893%, Training Loss: 0.3810%\n",
      "Epoch [45/300], Step [36/225], Training Accuracy: 85.1997%, Training Loss: 0.3765%\n",
      "Epoch [45/300], Step [37/225], Training Accuracy: 85.3041%, Training Loss: 0.3753%\n",
      "Epoch [45/300], Step [38/225], Training Accuracy: 85.1974%, Training Loss: 0.3772%\n",
      "Epoch [45/300], Step [39/225], Training Accuracy: 85.0561%, Training Loss: 0.3806%\n",
      "Epoch [45/300], Step [40/225], Training Accuracy: 84.8828%, Training Loss: 0.3864%\n",
      "Epoch [45/300], Step [41/225], Training Accuracy: 84.7180%, Training Loss: 0.3887%\n",
      "Epoch [45/300], Step [42/225], Training Accuracy: 84.5982%, Training Loss: 0.3887%\n",
      "Epoch [45/300], Step [43/225], Training Accuracy: 84.7020%, Training Loss: 0.3866%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/300], Step [44/225], Training Accuracy: 84.7301%, Training Loss: 0.3886%\n",
      "Epoch [45/300], Step [45/225], Training Accuracy: 84.6875%, Training Loss: 0.3877%\n",
      "Epoch [45/300], Step [46/225], Training Accuracy: 84.7826%, Training Loss: 0.3842%\n",
      "Epoch [45/300], Step [47/225], Training Accuracy: 84.8072%, Training Loss: 0.3829%\n",
      "Epoch [45/300], Step [48/225], Training Accuracy: 84.5378%, Training Loss: 0.3884%\n",
      "Epoch [45/300], Step [49/225], Training Accuracy: 84.6620%, Training Loss: 0.3862%\n",
      "Epoch [45/300], Step [50/225], Training Accuracy: 84.5625%, Training Loss: 0.3865%\n",
      "Epoch [45/300], Step [51/225], Training Accuracy: 84.6201%, Training Loss: 0.3855%\n",
      "Epoch [45/300], Step [52/225], Training Accuracy: 84.7356%, Training Loss: 0.3834%\n",
      "Epoch [45/300], Step [53/225], Training Accuracy: 84.9057%, Training Loss: 0.3801%\n",
      "Epoch [45/300], Step [54/225], Training Accuracy: 84.8958%, Training Loss: 0.3796%\n",
      "Epoch [45/300], Step [55/225], Training Accuracy: 84.8295%, Training Loss: 0.3825%\n",
      "Epoch [45/300], Step [56/225], Training Accuracy: 84.8772%, Training Loss: 0.3812%\n",
      "Epoch [45/300], Step [57/225], Training Accuracy: 84.8136%, Training Loss: 0.3815%\n",
      "Epoch [45/300], Step [58/225], Training Accuracy: 84.8060%, Training Loss: 0.3807%\n",
      "Epoch [45/300], Step [59/225], Training Accuracy: 84.6928%, Training Loss: 0.3818%\n",
      "Epoch [45/300], Step [60/225], Training Accuracy: 84.6094%, Training Loss: 0.3829%\n",
      "Epoch [45/300], Step [61/225], Training Accuracy: 84.5287%, Training Loss: 0.3844%\n",
      "Epoch [45/300], Step [62/225], Training Accuracy: 84.5766%, Training Loss: 0.3831%\n",
      "Epoch [45/300], Step [63/225], Training Accuracy: 84.6230%, Training Loss: 0.3838%\n",
      "Epoch [45/300], Step [64/225], Training Accuracy: 84.6191%, Training Loss: 0.3840%\n",
      "Epoch [45/300], Step [65/225], Training Accuracy: 84.6875%, Training Loss: 0.3843%\n",
      "Epoch [45/300], Step [66/225], Training Accuracy: 84.6354%, Training Loss: 0.3859%\n",
      "Epoch [45/300], Step [67/225], Training Accuracy: 84.5149%, Training Loss: 0.3870%\n",
      "Epoch [45/300], Step [68/225], Training Accuracy: 84.6048%, Training Loss: 0.3866%\n",
      "Epoch [45/300], Step [69/225], Training Accuracy: 84.6694%, Training Loss: 0.3861%\n",
      "Epoch [45/300], Step [70/225], Training Accuracy: 84.7098%, Training Loss: 0.3849%\n",
      "Epoch [45/300], Step [71/225], Training Accuracy: 84.6611%, Training Loss: 0.3851%\n",
      "Epoch [45/300], Step [72/225], Training Accuracy: 84.6354%, Training Loss: 0.3868%\n",
      "Epoch [45/300], Step [73/225], Training Accuracy: 84.6318%, Training Loss: 0.3863%\n",
      "Epoch [45/300], Step [74/225], Training Accuracy: 84.6706%, Training Loss: 0.3848%\n",
      "Epoch [45/300], Step [75/225], Training Accuracy: 84.6458%, Training Loss: 0.3844%\n",
      "Epoch [45/300], Step [76/225], Training Accuracy: 84.5806%, Training Loss: 0.3869%\n",
      "Epoch [45/300], Step [77/225], Training Accuracy: 84.5576%, Training Loss: 0.3886%\n",
      "Epoch [45/300], Step [78/225], Training Accuracy: 84.5152%, Training Loss: 0.3897%\n",
      "Epoch [45/300], Step [79/225], Training Accuracy: 84.6123%, Training Loss: 0.3881%\n",
      "Epoch [45/300], Step [80/225], Training Accuracy: 84.6875%, Training Loss: 0.3863%\n",
      "Epoch [45/300], Step [81/225], Training Accuracy: 84.8573%, Training Loss: 0.3833%\n",
      "Epoch [45/300], Step [82/225], Training Accuracy: 84.7942%, Training Loss: 0.3830%\n",
      "Epoch [45/300], Step [83/225], Training Accuracy: 84.7892%, Training Loss: 0.3828%\n",
      "Epoch [45/300], Step [84/225], Training Accuracy: 84.8028%, Training Loss: 0.3829%\n",
      "Epoch [45/300], Step [85/225], Training Accuracy: 84.8162%, Training Loss: 0.3826%\n",
      "Epoch [45/300], Step [86/225], Training Accuracy: 84.9019%, Training Loss: 0.3806%\n",
      "Epoch [45/300], Step [87/225], Training Accuracy: 84.8958%, Training Loss: 0.3809%\n",
      "Epoch [45/300], Step [88/225], Training Accuracy: 84.8899%, Training Loss: 0.3813%\n",
      "Epoch [45/300], Step [89/225], Training Accuracy: 84.8666%, Training Loss: 0.3816%\n",
      "Epoch [45/300], Step [90/225], Training Accuracy: 84.7396%, Training Loss: 0.3830%\n",
      "Epoch [45/300], Step [91/225], Training Accuracy: 84.7527%, Training Loss: 0.3821%\n",
      "Epoch [45/300], Step [92/225], Training Accuracy: 84.7147%, Training Loss: 0.3829%\n",
      "Epoch [45/300], Step [93/225], Training Accuracy: 84.8286%, Training Loss: 0.3811%\n",
      "Epoch [45/300], Step [94/225], Training Accuracy: 84.8570%, Training Loss: 0.3813%\n",
      "Epoch [45/300], Step [95/225], Training Accuracy: 84.8849%, Training Loss: 0.3816%\n",
      "Epoch [45/300], Step [96/225], Training Accuracy: 84.9284%, Training Loss: 0.3801%\n",
      "Epoch [45/300], Step [97/225], Training Accuracy: 84.8905%, Training Loss: 0.3812%\n",
      "Epoch [45/300], Step [98/225], Training Accuracy: 84.8055%, Training Loss: 0.3827%\n",
      "Epoch [45/300], Step [99/225], Training Accuracy: 84.7854%, Training Loss: 0.3825%\n",
      "Epoch [45/300], Step [100/225], Training Accuracy: 84.7500%, Training Loss: 0.3833%\n",
      "Epoch [45/300], Step [101/225], Training Accuracy: 84.7308%, Training Loss: 0.3836%\n",
      "Epoch [45/300], Step [102/225], Training Accuracy: 84.6661%, Training Loss: 0.3878%\n",
      "Epoch [45/300], Step [103/225], Training Accuracy: 84.6329%, Training Loss: 0.3881%\n",
      "Epoch [45/300], Step [104/225], Training Accuracy: 84.5853%, Training Loss: 0.3904%\n",
      "Epoch [45/300], Step [105/225], Training Accuracy: 84.6131%, Training Loss: 0.3911%\n",
      "Epoch [45/300], Step [106/225], Training Accuracy: 84.6403%, Training Loss: 0.3900%\n",
      "Epoch [45/300], Step [107/225], Training Accuracy: 84.6086%, Training Loss: 0.3912%\n",
      "Epoch [45/300], Step [108/225], Training Accuracy: 84.4763%, Training Loss: 0.3955%\n",
      "Epoch [45/300], Step [109/225], Training Accuracy: 84.4610%, Training Loss: 0.3952%\n",
      "Epoch [45/300], Step [110/225], Training Accuracy: 84.4460%, Training Loss: 0.3976%\n",
      "Epoch [45/300], Step [111/225], Training Accuracy: 84.4454%, Training Loss: 0.3973%\n",
      "Epoch [45/300], Step [112/225], Training Accuracy: 84.5006%, Training Loss: 0.3959%\n",
      "Epoch [45/300], Step [113/225], Training Accuracy: 84.4580%, Training Loss: 0.3971%\n",
      "Epoch [45/300], Step [114/225], Training Accuracy: 84.4846%, Training Loss: 0.3958%\n",
      "Epoch [45/300], Step [115/225], Training Accuracy: 84.5109%, Training Loss: 0.3959%\n",
      "Epoch [45/300], Step [116/225], Training Accuracy: 84.4558%, Training Loss: 0.3981%\n",
      "Epoch [45/300], Step [117/225], Training Accuracy: 84.4151%, Training Loss: 0.3990%\n",
      "Epoch [45/300], Step [118/225], Training Accuracy: 84.3750%, Training Loss: 0.3992%\n",
      "Epoch [45/300], Step [119/225], Training Accuracy: 84.3093%, Training Loss: 0.3999%\n",
      "Epoch [45/300], Step [120/225], Training Accuracy: 84.2708%, Training Loss: 0.4010%\n",
      "Epoch [45/300], Step [121/225], Training Accuracy: 84.2459%, Training Loss: 0.4017%\n",
      "Epoch [45/300], Step [122/225], Training Accuracy: 84.2469%, Training Loss: 0.4025%\n",
      "Epoch [45/300], Step [123/225], Training Accuracy: 84.1972%, Training Loss: 0.4043%\n",
      "Epoch [45/300], Step [124/225], Training Accuracy: 84.2364%, Training Loss: 0.4042%\n",
      "Epoch [45/300], Step [125/225], Training Accuracy: 84.2000%, Training Loss: 0.4047%\n",
      "Epoch [45/300], Step [126/225], Training Accuracy: 84.1766%, Training Loss: 0.4054%\n",
      "Epoch [45/300], Step [127/225], Training Accuracy: 84.1166%, Training Loss: 0.4070%\n",
      "Epoch [45/300], Step [128/225], Training Accuracy: 84.0942%, Training Loss: 0.4073%\n",
      "Epoch [45/300], Step [129/225], Training Accuracy: 84.0480%, Training Loss: 0.4086%\n",
      "Epoch [45/300], Step [130/225], Training Accuracy: 84.0625%, Training Loss: 0.4083%\n",
      "Epoch [45/300], Step [131/225], Training Accuracy: 84.0291%, Training Loss: 0.4102%\n",
      "Epoch [45/300], Step [132/225], Training Accuracy: 83.9844%, Training Loss: 0.4112%\n",
      "Epoch [45/300], Step [133/225], Training Accuracy: 83.9521%, Training Loss: 0.4112%\n",
      "Epoch [45/300], Step [134/225], Training Accuracy: 83.8969%, Training Loss: 0.4137%\n",
      "Epoch [45/300], Step [135/225], Training Accuracy: 83.9005%, Training Loss: 0.4140%\n",
      "Epoch [45/300], Step [136/225], Training Accuracy: 83.8695%, Training Loss: 0.4146%\n",
      "Epoch [45/300], Step [137/225], Training Accuracy: 83.8390%, Training Loss: 0.4172%\n",
      "Epoch [45/300], Step [138/225], Training Accuracy: 83.8542%, Training Loss: 0.4172%\n",
      "Epoch [45/300], Step [139/225], Training Accuracy: 83.8129%, Training Loss: 0.4183%\n",
      "Epoch [45/300], Step [140/225], Training Accuracy: 83.8504%, Training Loss: 0.4182%\n",
      "Epoch [45/300], Step [141/225], Training Accuracy: 83.8542%, Training Loss: 0.4178%\n",
      "Epoch [45/300], Step [142/225], Training Accuracy: 83.8688%, Training Loss: 0.4170%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/300], Step [143/225], Training Accuracy: 83.9270%, Training Loss: 0.4158%\n",
      "Epoch [45/300], Step [144/225], Training Accuracy: 83.9193%, Training Loss: 0.4158%\n",
      "Epoch [45/300], Step [145/225], Training Accuracy: 83.8901%, Training Loss: 0.4165%\n",
      "Epoch [45/300], Step [146/225], Training Accuracy: 83.9148%, Training Loss: 0.4156%\n",
      "Epoch [45/300], Step [147/225], Training Accuracy: 83.9605%, Training Loss: 0.4148%\n",
      "Epoch [45/300], Step [148/225], Training Accuracy: 83.9949%, Training Loss: 0.4147%\n",
      "Epoch [45/300], Step [149/225], Training Accuracy: 83.9765%, Training Loss: 0.4146%\n",
      "Epoch [45/300], Step [150/225], Training Accuracy: 83.9583%, Training Loss: 0.4145%\n",
      "Epoch [45/300], Step [151/225], Training Accuracy: 83.9921%, Training Loss: 0.4139%\n",
      "Epoch [45/300], Step [152/225], Training Accuracy: 84.0255%, Training Loss: 0.4128%\n",
      "Epoch [45/300], Step [153/225], Training Accuracy: 83.9869%, Training Loss: 0.4130%\n",
      "Epoch [45/300], Step [154/225], Training Accuracy: 84.0199%, Training Loss: 0.4122%\n",
      "Epoch [45/300], Step [155/225], Training Accuracy: 84.0020%, Training Loss: 0.4125%\n",
      "Epoch [45/300], Step [156/225], Training Accuracy: 83.9844%, Training Loss: 0.4130%\n",
      "Epoch [45/300], Step [157/225], Training Accuracy: 83.9371%, Training Loss: 0.4133%\n",
      "Epoch [45/300], Step [158/225], Training Accuracy: 83.9102%, Training Loss: 0.4137%\n",
      "Epoch [45/300], Step [159/225], Training Accuracy: 83.8935%, Training Loss: 0.4141%\n",
      "Epoch [45/300], Step [160/225], Training Accuracy: 83.9062%, Training Loss: 0.4143%\n",
      "Epoch [45/300], Step [161/225], Training Accuracy: 83.8898%, Training Loss: 0.4149%\n",
      "Epoch [45/300], Step [162/225], Training Accuracy: 83.9024%, Training Loss: 0.4145%\n",
      "Epoch [45/300], Step [163/225], Training Accuracy: 83.8957%, Training Loss: 0.4147%\n",
      "Epoch [45/300], Step [164/225], Training Accuracy: 83.8891%, Training Loss: 0.4144%\n",
      "Epoch [45/300], Step [165/225], Training Accuracy: 83.8447%, Training Loss: 0.4145%\n",
      "Epoch [45/300], Step [166/225], Training Accuracy: 83.8385%, Training Loss: 0.4140%\n",
      "Epoch [45/300], Step [167/225], Training Accuracy: 83.8510%, Training Loss: 0.4140%\n",
      "Epoch [45/300], Step [168/225], Training Accuracy: 83.8542%, Training Loss: 0.4143%\n",
      "Epoch [45/300], Step [169/225], Training Accuracy: 83.8942%, Training Loss: 0.4132%\n",
      "Epoch [45/300], Step [170/225], Training Accuracy: 83.8879%, Training Loss: 0.4136%\n",
      "Epoch [45/300], Step [171/225], Training Accuracy: 83.8268%, Training Loss: 0.4150%\n",
      "Epoch [45/300], Step [172/225], Training Accuracy: 83.8299%, Training Loss: 0.4148%\n",
      "Epoch [45/300], Step [173/225], Training Accuracy: 83.8512%, Training Loss: 0.4145%\n",
      "Epoch [45/300], Step [174/225], Training Accuracy: 83.8721%, Training Loss: 0.4137%\n",
      "Epoch [45/300], Step [175/225], Training Accuracy: 83.8929%, Training Loss: 0.4133%\n",
      "Epoch [45/300], Step [176/225], Training Accuracy: 83.9134%, Training Loss: 0.4133%\n",
      "Epoch [45/300], Step [177/225], Training Accuracy: 83.9160%, Training Loss: 0.4129%\n",
      "Epoch [45/300], Step [178/225], Training Accuracy: 83.9361%, Training Loss: 0.4127%\n",
      "Epoch [45/300], Step [179/225], Training Accuracy: 83.9211%, Training Loss: 0.4132%\n",
      "Epoch [45/300], Step [180/225], Training Accuracy: 83.9236%, Training Loss: 0.4134%\n",
      "Epoch [45/300], Step [181/225], Training Accuracy: 83.9002%, Training Loss: 0.4146%\n",
      "Epoch [45/300], Step [182/225], Training Accuracy: 83.9114%, Training Loss: 0.4137%\n",
      "Epoch [45/300], Step [183/225], Training Accuracy: 83.9395%, Training Loss: 0.4131%\n",
      "Epoch [45/300], Step [184/225], Training Accuracy: 83.9504%, Training Loss: 0.4127%\n",
      "Epoch [45/300], Step [185/225], Training Accuracy: 83.9443%, Training Loss: 0.4124%\n",
      "Epoch [45/300], Step [186/225], Training Accuracy: 83.9298%, Training Loss: 0.4124%\n",
      "Epoch [45/300], Step [187/225], Training Accuracy: 83.9405%, Training Loss: 0.4124%\n",
      "Epoch [45/300], Step [188/225], Training Accuracy: 83.9511%, Training Loss: 0.4127%\n",
      "Epoch [45/300], Step [189/225], Training Accuracy: 83.9699%, Training Loss: 0.4125%\n",
      "Epoch [45/300], Step [190/225], Training Accuracy: 83.9556%, Training Loss: 0.4125%\n",
      "Epoch [45/300], Step [191/225], Training Accuracy: 83.9251%, Training Loss: 0.4127%\n",
      "Epoch [45/300], Step [192/225], Training Accuracy: 83.9274%, Training Loss: 0.4124%\n",
      "Epoch [45/300], Step [193/225], Training Accuracy: 83.9459%, Training Loss: 0.4124%\n",
      "Epoch [45/300], Step [194/225], Training Accuracy: 83.9723%, Training Loss: 0.4117%\n",
      "Epoch [45/300], Step [195/225], Training Accuracy: 83.9824%, Training Loss: 0.4114%\n",
      "Epoch [45/300], Step [196/225], Training Accuracy: 83.9684%, Training Loss: 0.4117%\n",
      "Epoch [45/300], Step [197/225], Training Accuracy: 83.9546%, Training Loss: 0.4119%\n",
      "Epoch [45/300], Step [198/225], Training Accuracy: 83.9725%, Training Loss: 0.4114%\n",
      "Epoch [45/300], Step [199/225], Training Accuracy: 83.9589%, Training Loss: 0.4118%\n",
      "Epoch [45/300], Step [200/225], Training Accuracy: 83.9609%, Training Loss: 0.4118%\n",
      "Epoch [45/300], Step [201/225], Training Accuracy: 83.9475%, Training Loss: 0.4116%\n",
      "Epoch [45/300], Step [202/225], Training Accuracy: 83.9573%, Training Loss: 0.4115%\n",
      "Epoch [45/300], Step [203/225], Training Accuracy: 83.9825%, Training Loss: 0.4116%\n",
      "Epoch [45/300], Step [204/225], Training Accuracy: 83.9997%, Training Loss: 0.4119%\n",
      "Epoch [45/300], Step [205/225], Training Accuracy: 84.0091%, Training Loss: 0.4119%\n",
      "Epoch [45/300], Step [206/225], Training Accuracy: 83.9882%, Training Loss: 0.4130%\n",
      "Epoch [45/300], Step [207/225], Training Accuracy: 83.9825%, Training Loss: 0.4134%\n",
      "Epoch [45/300], Step [208/225], Training Accuracy: 83.9844%, Training Loss: 0.4130%\n",
      "Epoch [45/300], Step [209/225], Training Accuracy: 83.9414%, Training Loss: 0.4139%\n",
      "Epoch [45/300], Step [210/225], Training Accuracy: 83.9435%, Training Loss: 0.4138%\n",
      "Epoch [45/300], Step [211/225], Training Accuracy: 83.9455%, Training Loss: 0.4136%\n",
      "Epoch [45/300], Step [212/225], Training Accuracy: 83.9402%, Training Loss: 0.4139%\n",
      "Epoch [45/300], Step [213/225], Training Accuracy: 83.9275%, Training Loss: 0.4137%\n",
      "Epoch [45/300], Step [214/225], Training Accuracy: 83.9515%, Training Loss: 0.4129%\n",
      "Epoch [45/300], Step [215/225], Training Accuracy: 83.9317%, Training Loss: 0.4130%\n",
      "Epoch [45/300], Step [216/225], Training Accuracy: 83.9265%, Training Loss: 0.4130%\n",
      "Epoch [45/300], Step [217/225], Training Accuracy: 83.9142%, Training Loss: 0.4129%\n",
      "Epoch [45/300], Step [218/225], Training Accuracy: 83.8804%, Training Loss: 0.4134%\n",
      "Epoch [45/300], Step [219/225], Training Accuracy: 83.9041%, Training Loss: 0.4125%\n",
      "Epoch [45/300], Step [220/225], Training Accuracy: 83.8778%, Training Loss: 0.4123%\n",
      "Epoch [45/300], Step [221/225], Training Accuracy: 83.9013%, Training Loss: 0.4120%\n",
      "Epoch [45/300], Step [222/225], Training Accuracy: 83.9105%, Training Loss: 0.4118%\n",
      "Epoch [45/300], Step [223/225], Training Accuracy: 83.9126%, Training Loss: 0.4121%\n",
      "Epoch [45/300], Step [224/225], Training Accuracy: 83.9355%, Training Loss: 0.4117%\n",
      "Epoch [45/300], Step [225/225], Training Accuracy: 83.9216%, Training Loss: 0.4117%\n",
      "Epoch [46/300], Step [1/225], Training Accuracy: 79.6875%, Training Loss: 0.3930%\n",
      "Epoch [46/300], Step [2/225], Training Accuracy: 80.4688%, Training Loss: 0.4601%\n",
      "Epoch [46/300], Step [3/225], Training Accuracy: 82.8125%, Training Loss: 0.4358%\n",
      "Epoch [46/300], Step [4/225], Training Accuracy: 83.2031%, Training Loss: 0.4319%\n",
      "Epoch [46/300], Step [5/225], Training Accuracy: 83.7500%, Training Loss: 0.4009%\n",
      "Epoch [46/300], Step [6/225], Training Accuracy: 84.3750%, Training Loss: 0.3936%\n",
      "Epoch [46/300], Step [7/225], Training Accuracy: 84.5982%, Training Loss: 0.3924%\n",
      "Epoch [46/300], Step [8/225], Training Accuracy: 84.1797%, Training Loss: 0.4085%\n",
      "Epoch [46/300], Step [9/225], Training Accuracy: 84.3750%, Training Loss: 0.4021%\n",
      "Epoch [46/300], Step [10/225], Training Accuracy: 84.2188%, Training Loss: 0.4080%\n",
      "Epoch [46/300], Step [11/225], Training Accuracy: 83.3807%, Training Loss: 0.4123%\n",
      "Epoch [46/300], Step [12/225], Training Accuracy: 83.9844%, Training Loss: 0.4098%\n",
      "Epoch [46/300], Step [13/225], Training Accuracy: 84.0144%, Training Loss: 0.4023%\n",
      "Epoch [46/300], Step [14/225], Training Accuracy: 84.4866%, Training Loss: 0.3902%\n",
      "Epoch [46/300], Step [15/225], Training Accuracy: 84.4792%, Training Loss: 0.3858%\n",
      "Epoch [46/300], Step [16/225], Training Accuracy: 84.7656%, Training Loss: 0.3781%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/300], Step [17/225], Training Accuracy: 84.8346%, Training Loss: 0.3730%\n",
      "Epoch [46/300], Step [18/225], Training Accuracy: 84.4618%, Training Loss: 0.3820%\n",
      "Epoch [46/300], Step [19/225], Training Accuracy: 84.3750%, Training Loss: 0.3858%\n",
      "Epoch [46/300], Step [20/225], Training Accuracy: 84.8438%, Training Loss: 0.3789%\n",
      "Epoch [46/300], Step [21/225], Training Accuracy: 85.3423%, Training Loss: 0.3690%\n",
      "Epoch [46/300], Step [22/225], Training Accuracy: 84.9432%, Training Loss: 0.3699%\n",
      "Epoch [46/300], Step [23/225], Training Accuracy: 84.9864%, Training Loss: 0.3669%\n",
      "Epoch [46/300], Step [24/225], Training Accuracy: 84.8307%, Training Loss: 0.3647%\n",
      "Epoch [46/300], Step [25/225], Training Accuracy: 84.9375%, Training Loss: 0.3663%\n",
      "Epoch [46/300], Step [26/225], Training Accuracy: 84.9159%, Training Loss: 0.3665%\n",
      "Epoch [46/300], Step [27/225], Training Accuracy: 84.9537%, Training Loss: 0.3647%\n",
      "Epoch [46/300], Step [28/225], Training Accuracy: 84.9888%, Training Loss: 0.3621%\n",
      "Epoch [46/300], Step [29/225], Training Accuracy: 85.0216%, Training Loss: 0.3616%\n",
      "Epoch [46/300], Step [30/225], Training Accuracy: 85.3125%, Training Loss: 0.3640%\n",
      "Epoch [46/300], Step [31/225], Training Accuracy: 85.2319%, Training Loss: 0.3688%\n",
      "Epoch [46/300], Step [32/225], Training Accuracy: 85.4980%, Training Loss: 0.3624%\n",
      "Epoch [46/300], Step [33/225], Training Accuracy: 85.4640%, Training Loss: 0.3625%\n",
      "Epoch [46/300], Step [34/225], Training Accuracy: 85.0643%, Training Loss: 0.3731%\n",
      "Epoch [46/300], Step [35/225], Training Accuracy: 85.0893%, Training Loss: 0.3735%\n",
      "Epoch [46/300], Step [36/225], Training Accuracy: 85.2865%, Training Loss: 0.3724%\n",
      "Epoch [46/300], Step [37/225], Training Accuracy: 85.3463%, Training Loss: 0.3708%\n",
      "Epoch [46/300], Step [38/225], Training Accuracy: 85.4441%, Training Loss: 0.3695%\n",
      "Epoch [46/300], Step [39/225], Training Accuracy: 85.2965%, Training Loss: 0.3728%\n",
      "Epoch [46/300], Step [40/225], Training Accuracy: 85.2344%, Training Loss: 0.3770%\n",
      "Epoch [46/300], Step [41/225], Training Accuracy: 85.0991%, Training Loss: 0.3817%\n",
      "Epoch [46/300], Step [42/225], Training Accuracy: 84.9702%, Training Loss: 0.3810%\n",
      "Epoch [46/300], Step [43/225], Training Accuracy: 85.0654%, Training Loss: 0.3789%\n",
      "Epoch [46/300], Step [44/225], Training Accuracy: 85.0497%, Training Loss: 0.3784%\n",
      "Epoch [46/300], Step [45/225], Training Accuracy: 84.8958%, Training Loss: 0.3803%\n",
      "Epoch [46/300], Step [46/225], Training Accuracy: 85.0543%, Training Loss: 0.3767%\n",
      "Epoch [46/300], Step [47/225], Training Accuracy: 85.0066%, Training Loss: 0.3801%\n",
      "Epoch [46/300], Step [48/225], Training Accuracy: 84.9284%, Training Loss: 0.3798%\n",
      "Epoch [46/300], Step [49/225], Training Accuracy: 84.9809%, Training Loss: 0.3797%\n",
      "Epoch [46/300], Step [50/225], Training Accuracy: 84.9062%, Training Loss: 0.3804%\n",
      "Epoch [46/300], Step [51/225], Training Accuracy: 84.9877%, Training Loss: 0.3780%\n",
      "Epoch [46/300], Step [52/225], Training Accuracy: 85.0962%, Training Loss: 0.3766%\n",
      "Epoch [46/300], Step [53/225], Training Accuracy: 85.0825%, Training Loss: 0.3780%\n",
      "Epoch [46/300], Step [54/225], Training Accuracy: 84.9826%, Training Loss: 0.3822%\n",
      "Epoch [46/300], Step [55/225], Training Accuracy: 84.9148%, Training Loss: 0.3840%\n",
      "Epoch [46/300], Step [56/225], Training Accuracy: 85.0167%, Training Loss: 0.3813%\n",
      "Epoch [46/300], Step [57/225], Training Accuracy: 85.0329%, Training Loss: 0.3814%\n",
      "Epoch [46/300], Step [58/225], Training Accuracy: 84.9407%, Training Loss: 0.3827%\n",
      "Epoch [46/300], Step [59/225], Training Accuracy: 84.8782%, Training Loss: 0.3846%\n",
      "Epoch [46/300], Step [60/225], Training Accuracy: 84.9740%, Training Loss: 0.3831%\n",
      "Epoch [46/300], Step [61/225], Training Accuracy: 84.9641%, Training Loss: 0.3833%\n",
      "Epoch [46/300], Step [62/225], Training Accuracy: 84.9546%, Training Loss: 0.3832%\n",
      "Epoch [46/300], Step [63/225], Training Accuracy: 84.9950%, Training Loss: 0.3835%\n",
      "Epoch [46/300], Step [64/225], Training Accuracy: 84.8633%, Training Loss: 0.3859%\n",
      "Epoch [46/300], Step [65/225], Training Accuracy: 84.9038%, Training Loss: 0.3852%\n",
      "Epoch [46/300], Step [66/225], Training Accuracy: 84.8248%, Training Loss: 0.3854%\n",
      "Epoch [46/300], Step [67/225], Training Accuracy: 84.7481%, Training Loss: 0.3861%\n",
      "Epoch [46/300], Step [68/225], Training Accuracy: 84.8116%, Training Loss: 0.3848%\n",
      "Epoch [46/300], Step [69/225], Training Accuracy: 84.8053%, Training Loss: 0.3837%\n",
      "Epoch [46/300], Step [70/225], Training Accuracy: 84.7768%, Training Loss: 0.3832%\n",
      "Epoch [46/300], Step [71/225], Training Accuracy: 84.8371%, Training Loss: 0.3823%\n",
      "Epoch [46/300], Step [72/225], Training Accuracy: 84.8958%, Training Loss: 0.3800%\n",
      "Epoch [46/300], Step [73/225], Training Accuracy: 84.8245%, Training Loss: 0.3803%\n",
      "Epoch [46/300], Step [74/225], Training Accuracy: 84.7762%, Training Loss: 0.3812%\n",
      "Epoch [46/300], Step [75/225], Training Accuracy: 84.7917%, Training Loss: 0.3801%\n",
      "Epoch [46/300], Step [76/225], Training Accuracy: 84.5189%, Training Loss: 0.3824%\n",
      "Epoch [46/300], Step [77/225], Training Accuracy: 84.5576%, Training Loss: 0.3812%\n",
      "Epoch [46/300], Step [78/225], Training Accuracy: 84.5954%, Training Loss: 0.3801%\n",
      "Epoch [46/300], Step [79/225], Training Accuracy: 84.6123%, Training Loss: 0.3798%\n",
      "Epoch [46/300], Step [80/225], Training Accuracy: 84.6289%, Training Loss: 0.3795%\n",
      "Epoch [46/300], Step [81/225], Training Accuracy: 84.6644%, Training Loss: 0.3782%\n",
      "Epoch [46/300], Step [82/225], Training Accuracy: 84.7180%, Training Loss: 0.3764%\n",
      "Epoch [46/300], Step [83/225], Training Accuracy: 84.7515%, Training Loss: 0.3761%\n",
      "Epoch [46/300], Step [84/225], Training Accuracy: 84.7470%, Training Loss: 0.3752%\n",
      "Epoch [46/300], Step [85/225], Training Accuracy: 84.7794%, Training Loss: 0.3758%\n",
      "Epoch [46/300], Step [86/225], Training Accuracy: 84.8474%, Training Loss: 0.3742%\n",
      "Epoch [46/300], Step [87/225], Training Accuracy: 84.8420%, Training Loss: 0.3747%\n",
      "Epoch [46/300], Step [88/225], Training Accuracy: 84.8899%, Training Loss: 0.3740%\n",
      "Epoch [46/300], Step [89/225], Training Accuracy: 84.9719%, Training Loss: 0.3729%\n",
      "Epoch [46/300], Step [90/225], Training Accuracy: 84.8958%, Training Loss: 0.3744%\n",
      "Epoch [46/300], Step [91/225], Training Accuracy: 84.8729%, Training Loss: 0.3752%\n",
      "Epoch [46/300], Step [92/225], Training Accuracy: 84.9185%, Training Loss: 0.3748%\n",
      "Epoch [46/300], Step [93/225], Training Accuracy: 84.9630%, Training Loss: 0.3737%\n",
      "Epoch [46/300], Step [94/225], Training Accuracy: 85.0233%, Training Loss: 0.3732%\n",
      "Epoch [46/300], Step [95/225], Training Accuracy: 85.0493%, Training Loss: 0.3723%\n",
      "Epoch [46/300], Step [96/225], Training Accuracy: 84.9935%, Training Loss: 0.3729%\n",
      "Epoch [46/300], Step [97/225], Training Accuracy: 84.9388%, Training Loss: 0.3730%\n",
      "Epoch [46/300], Step [98/225], Training Accuracy: 84.9330%, Training Loss: 0.3725%\n",
      "Epoch [46/300], Step [99/225], Training Accuracy: 84.9747%, Training Loss: 0.3712%\n",
      "Epoch [46/300], Step [100/225], Training Accuracy: 84.9062%, Training Loss: 0.3738%\n",
      "Epoch [46/300], Step [101/225], Training Accuracy: 84.9474%, Training Loss: 0.3729%\n",
      "Epoch [46/300], Step [102/225], Training Accuracy: 84.9112%, Training Loss: 0.3740%\n",
      "Epoch [46/300], Step [103/225], Training Accuracy: 84.9818%, Training Loss: 0.3727%\n",
      "Epoch [46/300], Step [104/225], Training Accuracy: 85.0210%, Training Loss: 0.3721%\n",
      "Epoch [46/300], Step [105/225], Training Accuracy: 85.0000%, Training Loss: 0.3725%\n",
      "Epoch [46/300], Step [106/225], Training Accuracy: 84.9646%, Training Loss: 0.3724%\n",
      "Epoch [46/300], Step [107/225], Training Accuracy: 84.9737%, Training Loss: 0.3722%\n",
      "Epoch [46/300], Step [108/225], Training Accuracy: 84.9537%, Training Loss: 0.3731%\n",
      "Epoch [46/300], Step [109/225], Training Accuracy: 84.9341%, Training Loss: 0.3742%\n",
      "Epoch [46/300], Step [110/225], Training Accuracy: 84.9574%, Training Loss: 0.3742%\n",
      "Epoch [46/300], Step [111/225], Training Accuracy: 84.9662%, Training Loss: 0.3751%\n",
      "Epoch [46/300], Step [112/225], Training Accuracy: 84.9470%, Training Loss: 0.3758%\n",
      "Epoch [46/300], Step [113/225], Training Accuracy: 84.8866%, Training Loss: 0.3765%\n",
      "Epoch [46/300], Step [114/225], Training Accuracy: 84.8410%, Training Loss: 0.3778%\n",
      "Epoch [46/300], Step [115/225], Training Accuracy: 84.8505%, Training Loss: 0.3769%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/300], Step [116/225], Training Accuracy: 84.7656%, Training Loss: 0.3796%\n",
      "Epoch [46/300], Step [117/225], Training Accuracy: 84.6554%, Training Loss: 0.3823%\n",
      "Epoch [46/300], Step [118/225], Training Accuracy: 84.6796%, Training Loss: 0.3821%\n",
      "Epoch [46/300], Step [119/225], Training Accuracy: 84.6901%, Training Loss: 0.3817%\n",
      "Epoch [46/300], Step [120/225], Training Accuracy: 84.6875%, Training Loss: 0.3818%\n",
      "Epoch [46/300], Step [121/225], Training Accuracy: 84.6333%, Training Loss: 0.3832%\n",
      "Epoch [46/300], Step [122/225], Training Accuracy: 84.6440%, Training Loss: 0.3830%\n",
      "Epoch [46/300], Step [123/225], Training Accuracy: 84.6672%, Training Loss: 0.3831%\n",
      "Epoch [46/300], Step [124/225], Training Accuracy: 84.6900%, Training Loss: 0.3822%\n",
      "Epoch [46/300], Step [125/225], Training Accuracy: 84.6750%, Training Loss: 0.3823%\n",
      "Epoch [46/300], Step [126/225], Training Accuracy: 84.5734%, Training Loss: 0.3842%\n",
      "Epoch [46/300], Step [127/225], Training Accuracy: 84.5472%, Training Loss: 0.3846%\n",
      "Epoch [46/300], Step [128/225], Training Accuracy: 84.5459%, Training Loss: 0.3854%\n",
      "Epoch [46/300], Step [129/225], Training Accuracy: 84.5567%, Training Loss: 0.3855%\n",
      "Epoch [46/300], Step [130/225], Training Accuracy: 84.5553%, Training Loss: 0.3858%\n",
      "Epoch [46/300], Step [131/225], Training Accuracy: 84.5301%, Training Loss: 0.3861%\n",
      "Epoch [46/300], Step [132/225], Training Accuracy: 84.4815%, Training Loss: 0.3876%\n",
      "Epoch [46/300], Step [133/225], Training Accuracy: 84.5042%, Training Loss: 0.3869%\n",
      "Epoch [46/300], Step [134/225], Training Accuracy: 84.5149%, Training Loss: 0.3868%\n",
      "Epoch [46/300], Step [135/225], Training Accuracy: 84.5370%, Training Loss: 0.3863%\n",
      "Epoch [46/300], Step [136/225], Training Accuracy: 84.5588%, Training Loss: 0.3861%\n",
      "Epoch [46/300], Step [137/225], Training Accuracy: 84.5233%, Training Loss: 0.3875%\n",
      "Epoch [46/300], Step [138/225], Training Accuracy: 84.4995%, Training Loss: 0.3873%\n",
      "Epoch [46/300], Step [139/225], Training Accuracy: 84.4987%, Training Loss: 0.3868%\n",
      "Epoch [46/300], Step [140/225], Training Accuracy: 84.5089%, Training Loss: 0.3869%\n",
      "Epoch [46/300], Step [141/225], Training Accuracy: 84.5080%, Training Loss: 0.3875%\n",
      "Epoch [46/300], Step [142/225], Training Accuracy: 84.5401%, Training Loss: 0.3875%\n",
      "Epoch [46/300], Step [143/225], Training Accuracy: 84.5280%, Training Loss: 0.3869%\n",
      "Epoch [46/300], Step [144/225], Training Accuracy: 84.4944%, Training Loss: 0.3881%\n",
      "Epoch [46/300], Step [145/225], Training Accuracy: 84.5151%, Training Loss: 0.3877%\n",
      "Epoch [46/300], Step [146/225], Training Accuracy: 84.4927%, Training Loss: 0.3882%\n",
      "Epoch [46/300], Step [147/225], Training Accuracy: 84.5026%, Training Loss: 0.3887%\n",
      "Epoch [46/300], Step [148/225], Training Accuracy: 84.5545%, Training Loss: 0.3874%\n",
      "Epoch [46/300], Step [149/225], Training Accuracy: 84.5847%, Training Loss: 0.3870%\n",
      "Epoch [46/300], Step [150/225], Training Accuracy: 84.5938%, Training Loss: 0.3867%\n",
      "Epoch [46/300], Step [151/225], Training Accuracy: 84.6130%, Training Loss: 0.3861%\n",
      "Epoch [46/300], Step [152/225], Training Accuracy: 84.5600%, Training Loss: 0.3871%\n",
      "Epoch [46/300], Step [153/225], Training Accuracy: 84.5588%, Training Loss: 0.3877%\n",
      "Epoch [46/300], Step [154/225], Training Accuracy: 84.5678%, Training Loss: 0.3872%\n",
      "Epoch [46/300], Step [155/225], Training Accuracy: 84.5464%, Training Loss: 0.3874%\n",
      "Epoch [46/300], Step [156/225], Training Accuracy: 84.5353%, Training Loss: 0.3876%\n",
      "Epoch [46/300], Step [157/225], Training Accuracy: 84.5143%, Training Loss: 0.3875%\n",
      "Epoch [46/300], Step [158/225], Training Accuracy: 84.5233%, Training Loss: 0.3872%\n",
      "Epoch [46/300], Step [159/225], Training Accuracy: 84.4634%, Training Loss: 0.3879%\n",
      "Epoch [46/300], Step [160/225], Training Accuracy: 84.5020%, Training Loss: 0.3869%\n",
      "Epoch [46/300], Step [161/225], Training Accuracy: 84.5012%, Training Loss: 0.3865%\n",
      "Epoch [46/300], Step [162/225], Training Accuracy: 84.4618%, Training Loss: 0.3864%\n",
      "Epoch [46/300], Step [163/225], Training Accuracy: 84.4229%, Training Loss: 0.3867%\n",
      "Epoch [46/300], Step [164/225], Training Accuracy: 84.4131%, Training Loss: 0.3870%\n",
      "Epoch [46/300], Step [165/225], Training Accuracy: 84.4223%, Training Loss: 0.3867%\n",
      "Epoch [46/300], Step [166/225], Training Accuracy: 84.4221%, Training Loss: 0.3867%\n",
      "Epoch [46/300], Step [167/225], Training Accuracy: 84.4405%, Training Loss: 0.3863%\n",
      "Epoch [46/300], Step [168/225], Training Accuracy: 84.4029%, Training Loss: 0.3868%\n",
      "Epoch [46/300], Step [169/225], Training Accuracy: 84.4490%, Training Loss: 0.3858%\n",
      "Epoch [46/300], Step [170/225], Training Accuracy: 84.4210%, Training Loss: 0.3861%\n",
      "Epoch [46/300], Step [171/225], Training Accuracy: 84.4298%, Training Loss: 0.3859%\n",
      "Epoch [46/300], Step [172/225], Training Accuracy: 84.3841%, Training Loss: 0.3871%\n",
      "Epoch [46/300], Step [173/225], Training Accuracy: 84.3660%, Training Loss: 0.3876%\n",
      "Epoch [46/300], Step [174/225], Training Accuracy: 84.4019%, Training Loss: 0.3869%\n",
      "Epoch [46/300], Step [175/225], Training Accuracy: 84.4196%, Training Loss: 0.3863%\n",
      "Epoch [46/300], Step [176/225], Training Accuracy: 84.4638%, Training Loss: 0.3854%\n",
      "Epoch [46/300], Step [177/225], Training Accuracy: 84.4368%, Training Loss: 0.3851%\n",
      "Epoch [46/300], Step [178/225], Training Accuracy: 84.4101%, Training Loss: 0.3860%\n",
      "Epoch [46/300], Step [179/225], Training Accuracy: 84.4623%, Training Loss: 0.3847%\n",
      "Epoch [46/300], Step [180/225], Training Accuracy: 84.4878%, Training Loss: 0.3840%\n",
      "Epoch [46/300], Step [181/225], Training Accuracy: 84.5218%, Training Loss: 0.3833%\n",
      "Epoch [46/300], Step [182/225], Training Accuracy: 84.5810%, Training Loss: 0.3824%\n",
      "Epoch [46/300], Step [183/225], Training Accuracy: 84.5628%, Training Loss: 0.3826%\n",
      "Epoch [46/300], Step [184/225], Training Accuracy: 84.5618%, Training Loss: 0.3826%\n",
      "Epoch [46/300], Step [185/225], Training Accuracy: 84.5946%, Training Loss: 0.3824%\n",
      "Epoch [46/300], Step [186/225], Training Accuracy: 84.6186%, Training Loss: 0.3817%\n",
      "Epoch [46/300], Step [187/225], Training Accuracy: 84.6257%, Training Loss: 0.3814%\n",
      "Epoch [46/300], Step [188/225], Training Accuracy: 84.6326%, Training Loss: 0.3815%\n",
      "Epoch [46/300], Step [189/225], Training Accuracy: 84.6644%, Training Loss: 0.3809%\n",
      "Epoch [46/300], Step [190/225], Training Accuracy: 84.6711%, Training Loss: 0.3808%\n",
      "Epoch [46/300], Step [191/225], Training Accuracy: 84.6695%, Training Loss: 0.3806%\n",
      "Epoch [46/300], Step [192/225], Training Accuracy: 84.6436%, Training Loss: 0.3813%\n",
      "Epoch [46/300], Step [193/225], Training Accuracy: 84.6826%, Training Loss: 0.3805%\n",
      "Epoch [46/300], Step [194/225], Training Accuracy: 84.6891%, Training Loss: 0.3808%\n",
      "Epoch [46/300], Step [195/225], Training Accuracy: 84.6875%, Training Loss: 0.3808%\n",
      "Epoch [46/300], Step [196/225], Training Accuracy: 84.6859%, Training Loss: 0.3809%\n",
      "Epoch [46/300], Step [197/225], Training Accuracy: 84.6605%, Training Loss: 0.3816%\n",
      "Epoch [46/300], Step [198/225], Training Accuracy: 84.6749%, Training Loss: 0.3810%\n",
      "Epoch [46/300], Step [199/225], Training Accuracy: 84.6969%, Training Loss: 0.3807%\n",
      "Epoch [46/300], Step [200/225], Training Accuracy: 84.6953%, Training Loss: 0.3808%\n",
      "Epoch [46/300], Step [201/225], Training Accuracy: 84.6704%, Training Loss: 0.3811%\n",
      "Epoch [46/300], Step [202/225], Training Accuracy: 84.6689%, Training Loss: 0.3810%\n",
      "Epoch [46/300], Step [203/225], Training Accuracy: 84.7137%, Training Loss: 0.3813%\n",
      "Epoch [46/300], Step [204/225], Training Accuracy: 84.7350%, Training Loss: 0.3807%\n",
      "Epoch [46/300], Step [205/225], Training Accuracy: 84.7180%, Training Loss: 0.3810%\n",
      "Epoch [46/300], Step [206/225], Training Accuracy: 84.7087%, Training Loss: 0.3813%\n",
      "Epoch [46/300], Step [207/225], Training Accuracy: 84.7147%, Training Loss: 0.3813%\n",
      "Epoch [46/300], Step [208/225], Training Accuracy: 84.7281%, Training Loss: 0.3812%\n",
      "Epoch [46/300], Step [209/225], Training Accuracy: 84.7339%, Training Loss: 0.3809%\n",
      "Epoch [46/300], Step [210/225], Training Accuracy: 84.7619%, Training Loss: 0.3807%\n",
      "Epoch [46/300], Step [211/225], Training Accuracy: 84.7675%, Training Loss: 0.3806%\n",
      "Epoch [46/300], Step [212/225], Training Accuracy: 84.7583%, Training Loss: 0.3807%\n",
      "Epoch [46/300], Step [213/225], Training Accuracy: 84.7491%, Training Loss: 0.3807%\n",
      "Epoch [46/300], Step [214/225], Training Accuracy: 84.7620%, Training Loss: 0.3808%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/300], Step [215/225], Training Accuracy: 84.8038%, Training Loss: 0.3802%\n",
      "Epoch [46/300], Step [216/225], Training Accuracy: 84.8452%, Training Loss: 0.3796%\n",
      "Epoch [46/300], Step [217/225], Training Accuracy: 84.8358%, Training Loss: 0.3794%\n",
      "Epoch [46/300], Step [218/225], Training Accuracy: 84.8337%, Training Loss: 0.3795%\n",
      "Epoch [46/300], Step [219/225], Training Accuracy: 84.8602%, Training Loss: 0.3791%\n",
      "Epoch [46/300], Step [220/225], Training Accuracy: 84.8651%, Training Loss: 0.3795%\n",
      "Epoch [46/300], Step [221/225], Training Accuracy: 84.8840%, Training Loss: 0.3792%\n",
      "Epoch [46/300], Step [222/225], Training Accuracy: 84.9099%, Training Loss: 0.3791%\n",
      "Epoch [46/300], Step [223/225], Training Accuracy: 84.8655%, Training Loss: 0.3800%\n",
      "Epoch [46/300], Step [224/225], Training Accuracy: 84.8703%, Training Loss: 0.3799%\n",
      "Epoch [46/300], Step [225/225], Training Accuracy: 84.8874%, Training Loss: 0.3799%\n",
      "Epoch [47/300], Step [1/225], Training Accuracy: 75.0000%, Training Loss: 0.7142%\n",
      "Epoch [47/300], Step [2/225], Training Accuracy: 80.4688%, Training Loss: 0.5042%\n",
      "Epoch [47/300], Step [3/225], Training Accuracy: 81.2500%, Training Loss: 0.5003%\n",
      "Epoch [47/300], Step [4/225], Training Accuracy: 82.4219%, Training Loss: 0.4884%\n",
      "Epoch [47/300], Step [5/225], Training Accuracy: 83.1250%, Training Loss: 0.4796%\n",
      "Epoch [47/300], Step [6/225], Training Accuracy: 83.8542%, Training Loss: 0.4501%\n",
      "Epoch [47/300], Step [7/225], Training Accuracy: 83.2589%, Training Loss: 0.4430%\n",
      "Epoch [47/300], Step [8/225], Training Accuracy: 83.5938%, Training Loss: 0.4387%\n",
      "Epoch [47/300], Step [9/225], Training Accuracy: 83.5069%, Training Loss: 0.4417%\n",
      "Epoch [47/300], Step [10/225], Training Accuracy: 84.2188%, Training Loss: 0.4254%\n",
      "Epoch [47/300], Step [11/225], Training Accuracy: 84.3750%, Training Loss: 0.4157%\n",
      "Epoch [47/300], Step [12/225], Training Accuracy: 84.1146%, Training Loss: 0.4210%\n",
      "Epoch [47/300], Step [13/225], Training Accuracy: 84.3750%, Training Loss: 0.4081%\n",
      "Epoch [47/300], Step [14/225], Training Accuracy: 84.5982%, Training Loss: 0.3977%\n",
      "Epoch [47/300], Step [15/225], Training Accuracy: 84.8958%, Training Loss: 0.3933%\n",
      "Epoch [47/300], Step [16/225], Training Accuracy: 85.1562%, Training Loss: 0.3883%\n",
      "Epoch [47/300], Step [17/225], Training Accuracy: 85.0184%, Training Loss: 0.3882%\n",
      "Epoch [47/300], Step [18/225], Training Accuracy: 84.8090%, Training Loss: 0.3953%\n",
      "Epoch [47/300], Step [19/225], Training Accuracy: 84.9507%, Training Loss: 0.3933%\n",
      "Epoch [47/300], Step [20/225], Training Accuracy: 84.8438%, Training Loss: 0.3959%\n",
      "Epoch [47/300], Step [21/225], Training Accuracy: 84.8214%, Training Loss: 0.3931%\n",
      "Epoch [47/300], Step [22/225], Training Accuracy: 84.5881%, Training Loss: 0.3974%\n",
      "Epoch [47/300], Step [23/225], Training Accuracy: 84.5788%, Training Loss: 0.3962%\n",
      "Epoch [47/300], Step [24/225], Training Accuracy: 84.7656%, Training Loss: 0.3902%\n",
      "Epoch [47/300], Step [25/225], Training Accuracy: 84.8750%, Training Loss: 0.3870%\n",
      "Epoch [47/300], Step [26/225], Training Accuracy: 85.2163%, Training Loss: 0.3793%\n",
      "Epoch [47/300], Step [27/225], Training Accuracy: 85.1273%, Training Loss: 0.3801%\n",
      "Epoch [47/300], Step [28/225], Training Accuracy: 85.4353%, Training Loss: 0.3728%\n",
      "Epoch [47/300], Step [29/225], Training Accuracy: 85.5065%, Training Loss: 0.3747%\n",
      "Epoch [47/300], Step [30/225], Training Accuracy: 85.5729%, Training Loss: 0.3752%\n",
      "Epoch [47/300], Step [31/225], Training Accuracy: 85.2823%, Training Loss: 0.3881%\n",
      "Epoch [47/300], Step [32/225], Training Accuracy: 85.4492%, Training Loss: 0.3840%\n",
      "Epoch [47/300], Step [33/225], Training Accuracy: 85.3693%, Training Loss: 0.3850%\n",
      "Epoch [47/300], Step [34/225], Training Accuracy: 85.1103%, Training Loss: 0.3883%\n",
      "Epoch [47/300], Step [35/225], Training Accuracy: 85.1786%, Training Loss: 0.3868%\n",
      "Epoch [47/300], Step [36/225], Training Accuracy: 85.0694%, Training Loss: 0.3881%\n",
      "Epoch [47/300], Step [37/225], Training Accuracy: 85.1774%, Training Loss: 0.3839%\n",
      "Epoch [47/300], Step [38/225], Training Accuracy: 85.1151%, Training Loss: 0.3827%\n",
      "Epoch [47/300], Step [39/225], Training Accuracy: 85.2564%, Training Loss: 0.3830%\n",
      "Epoch [47/300], Step [40/225], Training Accuracy: 85.3125%, Training Loss: 0.3817%\n",
      "Epoch [47/300], Step [41/225], Training Accuracy: 85.2515%, Training Loss: 0.3838%\n",
      "Epoch [47/300], Step [42/225], Training Accuracy: 85.1190%, Training Loss: 0.3884%\n",
      "Epoch [47/300], Step [43/225], Training Accuracy: 85.0654%, Training Loss: 0.3883%\n",
      "Epoch [47/300], Step [44/225], Training Accuracy: 85.0142%, Training Loss: 0.3890%\n",
      "Epoch [47/300], Step [45/225], Training Accuracy: 84.8958%, Training Loss: 0.3905%\n",
      "Epoch [47/300], Step [46/225], Training Accuracy: 84.9524%, Training Loss: 0.3906%\n",
      "Epoch [47/300], Step [47/225], Training Accuracy: 84.9069%, Training Loss: 0.3905%\n",
      "Epoch [47/300], Step [48/225], Training Accuracy: 84.8958%, Training Loss: 0.3894%\n",
      "Epoch [47/300], Step [49/225], Training Accuracy: 84.9490%, Training Loss: 0.3889%\n",
      "Epoch [47/300], Step [50/225], Training Accuracy: 85.0938%, Training Loss: 0.3855%\n",
      "Epoch [47/300], Step [51/225], Training Accuracy: 85.1409%, Training Loss: 0.3822%\n",
      "Epoch [47/300], Step [52/225], Training Accuracy: 85.3365%, Training Loss: 0.3784%\n",
      "Epoch [47/300], Step [53/225], Training Accuracy: 85.3184%, Training Loss: 0.3783%\n",
      "Epoch [47/300], Step [54/225], Training Accuracy: 85.2720%, Training Loss: 0.3777%\n",
      "Epoch [47/300], Step [55/225], Training Accuracy: 85.3409%, Training Loss: 0.3767%\n",
      "Epoch [47/300], Step [56/225], Training Accuracy: 85.4353%, Training Loss: 0.3750%\n",
      "Epoch [47/300], Step [57/225], Training Accuracy: 85.4167%, Training Loss: 0.3753%\n",
      "Epoch [47/300], Step [58/225], Training Accuracy: 85.4256%, Training Loss: 0.3751%\n",
      "Epoch [47/300], Step [59/225], Training Accuracy: 85.4873%, Training Loss: 0.3743%\n",
      "Epoch [47/300], Step [60/225], Training Accuracy: 85.5469%, Training Loss: 0.3745%\n",
      "Epoch [47/300], Step [61/225], Training Accuracy: 85.5533%, Training Loss: 0.3747%\n",
      "Epoch [47/300], Step [62/225], Training Accuracy: 85.5343%, Training Loss: 0.3736%\n",
      "Epoch [47/300], Step [63/225], Training Accuracy: 85.5407%, Training Loss: 0.3741%\n",
      "Epoch [47/300], Step [64/225], Training Accuracy: 85.6934%, Training Loss: 0.3709%\n",
      "Epoch [47/300], Step [65/225], Training Accuracy: 85.7212%, Training Loss: 0.3705%\n",
      "Epoch [47/300], Step [66/225], Training Accuracy: 85.7244%, Training Loss: 0.3714%\n",
      "Epoch [47/300], Step [67/225], Training Accuracy: 85.7043%, Training Loss: 0.3707%\n",
      "Epoch [47/300], Step [68/225], Training Accuracy: 85.6847%, Training Loss: 0.3713%\n",
      "Epoch [47/300], Step [69/225], Training Accuracy: 85.6431%, Training Loss: 0.3716%\n",
      "Epoch [47/300], Step [70/225], Training Accuracy: 85.7143%, Training Loss: 0.3700%\n",
      "Epoch [47/300], Step [71/225], Training Accuracy: 85.7835%, Training Loss: 0.3689%\n",
      "Epoch [47/300], Step [72/225], Training Accuracy: 85.7422%, Training Loss: 0.3697%\n",
      "Epoch [47/300], Step [73/225], Training Accuracy: 85.8519%, Training Loss: 0.3673%\n",
      "Epoch [47/300], Step [74/225], Training Accuracy: 85.8319%, Training Loss: 0.3681%\n",
      "Epoch [47/300], Step [75/225], Training Accuracy: 85.7292%, Training Loss: 0.3692%\n",
      "Epoch [47/300], Step [76/225], Training Accuracy: 85.6908%, Training Loss: 0.3695%\n",
      "Epoch [47/300], Step [77/225], Training Accuracy: 85.6940%, Training Loss: 0.3689%\n",
      "Epoch [47/300], Step [78/225], Training Accuracy: 85.7572%, Training Loss: 0.3682%\n",
      "Epoch [47/300], Step [79/225], Training Accuracy: 85.8584%, Training Loss: 0.3674%\n",
      "Epoch [47/300], Step [80/225], Training Accuracy: 85.8789%, Training Loss: 0.3668%\n",
      "Epoch [47/300], Step [81/225], Training Accuracy: 85.8218%, Training Loss: 0.3671%\n",
      "Epoch [47/300], Step [82/225], Training Accuracy: 85.8613%, Training Loss: 0.3658%\n",
      "Epoch [47/300], Step [83/225], Training Accuracy: 85.7681%, Training Loss: 0.3679%\n",
      "Epoch [47/300], Step [84/225], Training Accuracy: 85.7887%, Training Loss: 0.3672%\n",
      "Epoch [47/300], Step [85/225], Training Accuracy: 85.8456%, Training Loss: 0.3664%\n",
      "Epoch [47/300], Step [86/225], Training Accuracy: 85.8648%, Training Loss: 0.3649%\n",
      "Epoch [47/300], Step [87/225], Training Accuracy: 85.8297%, Training Loss: 0.3646%\n",
      "Epoch [47/300], Step [88/225], Training Accuracy: 85.7067%, Training Loss: 0.3664%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/300], Step [89/225], Training Accuracy: 85.6917%, Training Loss: 0.3669%\n",
      "Epoch [47/300], Step [90/225], Training Accuracy: 85.5729%, Training Loss: 0.3693%\n",
      "Epoch [47/300], Step [91/225], Training Accuracy: 85.5941%, Training Loss: 0.3684%\n",
      "Epoch [47/300], Step [92/225], Training Accuracy: 85.5808%, Training Loss: 0.3687%\n",
      "Epoch [47/300], Step [93/225], Training Accuracy: 85.6519%, Training Loss: 0.3676%\n",
      "Epoch [47/300], Step [94/225], Training Accuracy: 85.6549%, Training Loss: 0.3672%\n",
      "Epoch [47/300], Step [95/225], Training Accuracy: 85.6743%, Training Loss: 0.3664%\n",
      "Epoch [47/300], Step [96/225], Training Accuracy: 85.6934%, Training Loss: 0.3647%\n",
      "Epoch [47/300], Step [97/225], Training Accuracy: 85.7603%, Training Loss: 0.3640%\n",
      "Epoch [47/300], Step [98/225], Training Accuracy: 85.7621%, Training Loss: 0.3639%\n",
      "Epoch [47/300], Step [99/225], Training Accuracy: 85.7323%, Training Loss: 0.3654%\n",
      "Epoch [47/300], Step [100/225], Training Accuracy: 85.6562%, Training Loss: 0.3666%\n",
      "Epoch [47/300], Step [101/225], Training Accuracy: 85.6436%, Training Loss: 0.3661%\n",
      "Epoch [47/300], Step [102/225], Training Accuracy: 85.6158%, Training Loss: 0.3668%\n",
      "Epoch [47/300], Step [103/225], Training Accuracy: 85.6189%, Training Loss: 0.3666%\n",
      "Epoch [47/300], Step [104/225], Training Accuracy: 85.6220%, Training Loss: 0.3683%\n",
      "Epoch [47/300], Step [105/225], Training Accuracy: 85.6101%, Training Loss: 0.3682%\n",
      "Epoch [47/300], Step [106/225], Training Accuracy: 85.5837%, Training Loss: 0.3676%\n",
      "Epoch [47/300], Step [107/225], Training Accuracy: 85.5432%, Training Loss: 0.3687%\n",
      "Epoch [47/300], Step [108/225], Training Accuracy: 85.5179%, Training Loss: 0.3688%\n",
      "Epoch [47/300], Step [109/225], Training Accuracy: 85.4931%, Training Loss: 0.3691%\n",
      "Epoch [47/300], Step [110/225], Training Accuracy: 85.4972%, Training Loss: 0.3709%\n",
      "Epoch [47/300], Step [111/225], Training Accuracy: 85.4870%, Training Loss: 0.3717%\n",
      "Epoch [47/300], Step [112/225], Training Accuracy: 85.4911%, Training Loss: 0.3713%\n",
      "Epoch [47/300], Step [113/225], Training Accuracy: 85.4535%, Training Loss: 0.3726%\n",
      "Epoch [47/300], Step [114/225], Training Accuracy: 85.4715%, Training Loss: 0.3723%\n",
      "Epoch [47/300], Step [115/225], Training Accuracy: 85.4620%, Training Loss: 0.3720%\n",
      "Epoch [47/300], Step [116/225], Training Accuracy: 85.3852%, Training Loss: 0.3728%\n",
      "Epoch [47/300], Step [117/225], Training Accuracy: 85.4033%, Training Loss: 0.3721%\n",
      "Epoch [47/300], Step [118/225], Training Accuracy: 85.4211%, Training Loss: 0.3718%\n",
      "Epoch [47/300], Step [119/225], Training Accuracy: 85.4123%, Training Loss: 0.3711%\n",
      "Epoch [47/300], Step [120/225], Training Accuracy: 85.4297%, Training Loss: 0.3708%\n",
      "Epoch [47/300], Step [121/225], Training Accuracy: 85.4081%, Training Loss: 0.3717%\n",
      "Epoch [47/300], Step [122/225], Training Accuracy: 85.4124%, Training Loss: 0.3717%\n",
      "Epoch [47/300], Step [123/225], Training Accuracy: 85.4167%, Training Loss: 0.3711%\n",
      "Epoch [47/300], Step [124/225], Training Accuracy: 85.4083%, Training Loss: 0.3710%\n",
      "Epoch [47/300], Step [125/225], Training Accuracy: 85.3875%, Training Loss: 0.3712%\n",
      "Epoch [47/300], Step [126/225], Training Accuracy: 85.3423%, Training Loss: 0.3717%\n",
      "Epoch [47/300], Step [127/225], Training Accuracy: 85.3346%, Training Loss: 0.3714%\n",
      "Epoch [47/300], Step [128/225], Training Accuracy: 85.3882%, Training Loss: 0.3706%\n",
      "Epoch [47/300], Step [129/225], Training Accuracy: 85.3077%, Training Loss: 0.3719%\n",
      "Epoch [47/300], Step [130/225], Training Accuracy: 85.2764%, Training Loss: 0.3723%\n",
      "Epoch [47/300], Step [131/225], Training Accuracy: 85.2815%, Training Loss: 0.3717%\n",
      "Epoch [47/300], Step [132/225], Training Accuracy: 85.2983%, Training Loss: 0.3720%\n",
      "Epoch [47/300], Step [133/225], Training Accuracy: 85.2914%, Training Loss: 0.3719%\n",
      "Epoch [47/300], Step [134/225], Training Accuracy: 85.2146%, Training Loss: 0.3735%\n",
      "Epoch [47/300], Step [135/225], Training Accuracy: 85.1852%, Training Loss: 0.3742%\n",
      "Epoch [47/300], Step [136/225], Training Accuracy: 85.1448%, Training Loss: 0.3751%\n",
      "Epoch [47/300], Step [137/225], Training Accuracy: 85.1049%, Training Loss: 0.3761%\n",
      "Epoch [47/300], Step [138/225], Training Accuracy: 85.1449%, Training Loss: 0.3750%\n",
      "Epoch [47/300], Step [139/225], Training Accuracy: 85.0832%, Training Loss: 0.3761%\n",
      "Epoch [47/300], Step [140/225], Training Accuracy: 85.1004%, Training Loss: 0.3755%\n",
      "Epoch [47/300], Step [141/225], Training Accuracy: 85.0731%, Training Loss: 0.3759%\n",
      "Epoch [47/300], Step [142/225], Training Accuracy: 85.0902%, Training Loss: 0.3750%\n",
      "Epoch [47/300], Step [143/225], Training Accuracy: 85.0743%, Training Loss: 0.3749%\n",
      "Epoch [47/300], Step [144/225], Training Accuracy: 85.0694%, Training Loss: 0.3752%\n",
      "Epoch [47/300], Step [145/225], Training Accuracy: 85.0970%, Training Loss: 0.3748%\n",
      "Epoch [47/300], Step [146/225], Training Accuracy: 85.1241%, Training Loss: 0.3743%\n",
      "Epoch [47/300], Step [147/225], Training Accuracy: 85.1403%, Training Loss: 0.3734%\n",
      "Epoch [47/300], Step [148/225], Training Accuracy: 85.1457%, Training Loss: 0.3733%\n",
      "Epoch [47/300], Step [149/225], Training Accuracy: 85.1510%, Training Loss: 0.3729%\n",
      "Epoch [47/300], Step [150/225], Training Accuracy: 85.1875%, Training Loss: 0.3720%\n",
      "Epoch [47/300], Step [151/225], Training Accuracy: 85.2339%, Training Loss: 0.3709%\n",
      "Epoch [47/300], Step [152/225], Training Accuracy: 85.2385%, Training Loss: 0.3711%\n",
      "Epoch [47/300], Step [153/225], Training Accuracy: 85.2533%, Training Loss: 0.3709%\n",
      "Epoch [47/300], Step [154/225], Training Accuracy: 85.2476%, Training Loss: 0.3713%\n",
      "Epoch [47/300], Step [155/225], Training Accuracy: 85.1815%, Training Loss: 0.3722%\n",
      "Epoch [47/300], Step [156/225], Training Accuracy: 85.1663%, Training Loss: 0.3730%\n",
      "Epoch [47/300], Step [157/225], Training Accuracy: 85.1712%, Training Loss: 0.3733%\n",
      "Epoch [47/300], Step [158/225], Training Accuracy: 85.1859%, Training Loss: 0.3732%\n",
      "Epoch [47/300], Step [159/225], Training Accuracy: 85.1612%, Training Loss: 0.3736%\n",
      "Epoch [47/300], Step [160/225], Training Accuracy: 85.0879%, Training Loss: 0.3745%\n",
      "Epoch [47/300], Step [161/225], Training Accuracy: 85.1223%, Training Loss: 0.3747%\n",
      "Epoch [47/300], Step [162/225], Training Accuracy: 85.1080%, Training Loss: 0.3745%\n",
      "Epoch [47/300], Step [163/225], Training Accuracy: 85.1419%, Training Loss: 0.3744%\n",
      "Epoch [47/300], Step [164/225], Training Accuracy: 85.1467%, Training Loss: 0.3739%\n",
      "Epoch [47/300], Step [165/225], Training Accuracy: 85.0852%, Training Loss: 0.3755%\n",
      "Epoch [47/300], Step [166/225], Training Accuracy: 85.0904%, Training Loss: 0.3763%\n",
      "Epoch [47/300], Step [167/225], Training Accuracy: 85.0861%, Training Loss: 0.3767%\n",
      "Epoch [47/300], Step [168/225], Training Accuracy: 85.0632%, Training Loss: 0.3771%\n",
      "Epoch [47/300], Step [169/225], Training Accuracy: 85.0777%, Training Loss: 0.3764%\n",
      "Epoch [47/300], Step [170/225], Training Accuracy: 85.0735%, Training Loss: 0.3761%\n",
      "Epoch [47/300], Step [171/225], Training Accuracy: 85.0603%, Training Loss: 0.3759%\n",
      "Epoch [47/300], Step [172/225], Training Accuracy: 85.0836%, Training Loss: 0.3759%\n",
      "Epoch [47/300], Step [173/225], Training Accuracy: 85.1066%, Training Loss: 0.3753%\n",
      "Epoch [47/300], Step [174/225], Training Accuracy: 85.1114%, Training Loss: 0.3755%\n",
      "Epoch [47/300], Step [175/225], Training Accuracy: 85.1607%, Training Loss: 0.3748%\n",
      "Epoch [47/300], Step [176/225], Training Accuracy: 85.1474%, Training Loss: 0.3751%\n",
      "Epoch [47/300], Step [177/225], Training Accuracy: 85.1783%, Training Loss: 0.3746%\n",
      "Epoch [47/300], Step [178/225], Training Accuracy: 85.2177%, Training Loss: 0.3738%\n",
      "Epoch [47/300], Step [179/225], Training Accuracy: 85.2304%, Training Loss: 0.3735%\n",
      "Epoch [47/300], Step [180/225], Training Accuracy: 85.2517%, Training Loss: 0.3730%\n",
      "Epoch [47/300], Step [181/225], Training Accuracy: 85.2383%, Training Loss: 0.3733%\n",
      "Epoch [47/300], Step [182/225], Training Accuracy: 85.2507%, Training Loss: 0.3731%\n",
      "Epoch [47/300], Step [183/225], Training Accuracy: 85.2544%, Training Loss: 0.3727%\n",
      "Epoch [47/300], Step [184/225], Training Accuracy: 85.2412%, Training Loss: 0.3732%\n",
      "Epoch [47/300], Step [185/225], Training Accuracy: 85.2787%, Training Loss: 0.3722%\n",
      "Epoch [47/300], Step [186/225], Training Accuracy: 85.2907%, Training Loss: 0.3724%\n",
      "Epoch [47/300], Step [187/225], Training Accuracy: 85.2941%, Training Loss: 0.3723%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/300], Step [188/225], Training Accuracy: 85.2975%, Training Loss: 0.3723%\n",
      "Epoch [47/300], Step [189/225], Training Accuracy: 85.3257%, Training Loss: 0.3717%\n",
      "Epoch [47/300], Step [190/225], Training Accuracy: 85.3207%, Training Loss: 0.3716%\n",
      "Epoch [47/300], Step [191/225], Training Accuracy: 85.3485%, Training Loss: 0.3713%\n",
      "Epoch [47/300], Step [192/225], Training Accuracy: 85.3678%, Training Loss: 0.3708%\n",
      "Epoch [47/300], Step [193/225], Training Accuracy: 85.3546%, Training Loss: 0.3716%\n",
      "Epoch [47/300], Step [194/225], Training Accuracy: 85.3576%, Training Loss: 0.3718%\n",
      "Epoch [47/300], Step [195/225], Training Accuracy: 85.3686%, Training Loss: 0.3712%\n",
      "Epoch [47/300], Step [196/225], Training Accuracy: 85.3555%, Training Loss: 0.3717%\n",
      "Epoch [47/300], Step [197/225], Training Accuracy: 85.3585%, Training Loss: 0.3720%\n",
      "Epoch [47/300], Step [198/225], Training Accuracy: 85.3851%, Training Loss: 0.3717%\n",
      "Epoch [47/300], Step [199/225], Training Accuracy: 85.4036%, Training Loss: 0.3716%\n",
      "Epoch [47/300], Step [200/225], Training Accuracy: 85.4141%, Training Loss: 0.3717%\n",
      "Epoch [47/300], Step [201/225], Training Accuracy: 85.4244%, Training Loss: 0.3718%\n",
      "Epoch [47/300], Step [202/225], Training Accuracy: 85.4347%, Training Loss: 0.3719%\n",
      "Epoch [47/300], Step [203/225], Training Accuracy: 85.4372%, Training Loss: 0.3715%\n",
      "Epoch [47/300], Step [204/225], Training Accuracy: 85.4396%, Training Loss: 0.3712%\n",
      "Epoch [47/300], Step [205/225], Training Accuracy: 85.4345%, Training Loss: 0.3712%\n",
      "Epoch [47/300], Step [206/225], Training Accuracy: 85.4141%, Training Loss: 0.3714%\n",
      "Epoch [47/300], Step [207/225], Training Accuracy: 85.4091%, Training Loss: 0.3713%\n",
      "Epoch [47/300], Step [208/225], Training Accuracy: 85.4117%, Training Loss: 0.3712%\n",
      "Epoch [47/300], Step [209/225], Training Accuracy: 85.3693%, Training Loss: 0.3720%\n",
      "Epoch [47/300], Step [210/225], Training Accuracy: 85.3571%, Training Loss: 0.3723%\n",
      "Epoch [47/300], Step [211/225], Training Accuracy: 85.3821%, Training Loss: 0.3717%\n",
      "Epoch [47/300], Step [212/225], Training Accuracy: 85.3626%, Training Loss: 0.3717%\n",
      "Epoch [47/300], Step [213/225], Training Accuracy: 85.3360%, Training Loss: 0.3724%\n",
      "Epoch [47/300], Step [214/225], Training Accuracy: 85.3534%, Training Loss: 0.3722%\n",
      "Epoch [47/300], Step [215/225], Training Accuracy: 85.3561%, Training Loss: 0.3720%\n",
      "Epoch [47/300], Step [216/225], Training Accuracy: 85.3371%, Training Loss: 0.3721%\n",
      "Epoch [47/300], Step [217/225], Training Accuracy: 85.3399%, Training Loss: 0.3724%\n",
      "Epoch [47/300], Step [218/225], Training Accuracy: 85.3283%, Training Loss: 0.3724%\n",
      "Epoch [47/300], Step [219/225], Training Accuracy: 85.3096%, Training Loss: 0.3724%\n",
      "Epoch [47/300], Step [220/225], Training Accuracy: 85.3267%, Training Loss: 0.3723%\n",
      "Epoch [47/300], Step [221/225], Training Accuracy: 85.3365%, Training Loss: 0.3722%\n",
      "Epoch [47/300], Step [222/225], Training Accuracy: 85.3392%, Training Loss: 0.3721%\n",
      "Epoch [47/300], Step [223/225], Training Accuracy: 85.3279%, Training Loss: 0.3721%\n",
      "Epoch [47/300], Step [224/225], Training Accuracy: 85.3237%, Training Loss: 0.3721%\n",
      "Epoch [47/300], Step [225/225], Training Accuracy: 85.3321%, Training Loss: 0.3717%\n",
      "Epoch [48/300], Step [1/225], Training Accuracy: 87.5000%, Training Loss: 0.2858%\n",
      "Epoch [48/300], Step [2/225], Training Accuracy: 85.9375%, Training Loss: 0.3530%\n",
      "Epoch [48/300], Step [3/225], Training Accuracy: 85.9375%, Training Loss: 0.3308%\n",
      "Epoch [48/300], Step [4/225], Training Accuracy: 84.7656%, Training Loss: 0.3498%\n",
      "Epoch [48/300], Step [5/225], Training Accuracy: 85.0000%, Training Loss: 0.3533%\n",
      "Epoch [48/300], Step [6/225], Training Accuracy: 85.4167%, Training Loss: 0.3664%\n",
      "Epoch [48/300], Step [7/225], Training Accuracy: 85.7143%, Training Loss: 0.3652%\n",
      "Epoch [48/300], Step [8/225], Training Accuracy: 85.1562%, Training Loss: 0.3624%\n",
      "Epoch [48/300], Step [9/225], Training Accuracy: 84.8958%, Training Loss: 0.3675%\n",
      "Epoch [48/300], Step [10/225], Training Accuracy: 84.6875%, Training Loss: 0.3752%\n",
      "Epoch [48/300], Step [11/225], Training Accuracy: 84.3750%, Training Loss: 0.3864%\n",
      "Epoch [48/300], Step [12/225], Training Accuracy: 84.6354%, Training Loss: 0.3824%\n",
      "Epoch [48/300], Step [13/225], Training Accuracy: 84.8558%, Training Loss: 0.3776%\n",
      "Epoch [48/300], Step [14/225], Training Accuracy: 84.7098%, Training Loss: 0.3829%\n",
      "Epoch [48/300], Step [15/225], Training Accuracy: 85.1042%, Training Loss: 0.3770%\n",
      "Epoch [48/300], Step [16/225], Training Accuracy: 85.7422%, Training Loss: 0.3657%\n",
      "Epoch [48/300], Step [17/225], Training Accuracy: 85.5699%, Training Loss: 0.3699%\n",
      "Epoch [48/300], Step [18/225], Training Accuracy: 85.1562%, Training Loss: 0.3778%\n",
      "Epoch [48/300], Step [19/225], Training Accuracy: 85.0329%, Training Loss: 0.3795%\n",
      "Epoch [48/300], Step [20/225], Training Accuracy: 84.9219%, Training Loss: 0.3751%\n",
      "Epoch [48/300], Step [21/225], Training Accuracy: 85.1935%, Training Loss: 0.3686%\n",
      "Epoch [48/300], Step [22/225], Training Accuracy: 85.0852%, Training Loss: 0.3687%\n",
      "Epoch [48/300], Step [23/225], Training Accuracy: 85.0543%, Training Loss: 0.3689%\n",
      "Epoch [48/300], Step [24/225], Training Accuracy: 84.8958%, Training Loss: 0.3684%\n",
      "Epoch [48/300], Step [25/225], Training Accuracy: 84.9375%, Training Loss: 0.3675%\n",
      "Epoch [48/300], Step [26/225], Training Accuracy: 84.9760%, Training Loss: 0.3655%\n",
      "Epoch [48/300], Step [27/225], Training Accuracy: 85.0694%, Training Loss: 0.3618%\n",
      "Epoch [48/300], Step [28/225], Training Accuracy: 85.2121%, Training Loss: 0.3579%\n",
      "Epoch [48/300], Step [29/225], Training Accuracy: 85.2909%, Training Loss: 0.3542%\n",
      "Epoch [48/300], Step [30/225], Training Accuracy: 85.4167%, Training Loss: 0.3526%\n",
      "Epoch [48/300], Step [31/225], Training Accuracy: 85.2319%, Training Loss: 0.3556%\n",
      "Epoch [48/300], Step [32/225], Training Accuracy: 85.2539%, Training Loss: 0.3558%\n",
      "Epoch [48/300], Step [33/225], Training Accuracy: 85.3220%, Training Loss: 0.3546%\n",
      "Epoch [48/300], Step [34/225], Training Accuracy: 85.1562%, Training Loss: 0.3585%\n",
      "Epoch [48/300], Step [35/225], Training Accuracy: 85.1786%, Training Loss: 0.3567%\n",
      "Epoch [48/300], Step [36/225], Training Accuracy: 85.1997%, Training Loss: 0.3546%\n",
      "Epoch [48/300], Step [37/225], Training Accuracy: 85.3041%, Training Loss: 0.3506%\n",
      "Epoch [48/300], Step [38/225], Training Accuracy: 85.2796%, Training Loss: 0.3515%\n",
      "Epoch [48/300], Step [39/225], Training Accuracy: 85.2163%, Training Loss: 0.3557%\n",
      "Epoch [48/300], Step [40/225], Training Accuracy: 85.2344%, Training Loss: 0.3552%\n",
      "Epoch [48/300], Step [41/225], Training Accuracy: 85.0229%, Training Loss: 0.3609%\n",
      "Epoch [48/300], Step [42/225], Training Accuracy: 85.0818%, Training Loss: 0.3588%\n",
      "Epoch [48/300], Step [43/225], Training Accuracy: 85.1381%, Training Loss: 0.3562%\n",
      "Epoch [48/300], Step [44/225], Training Accuracy: 85.1918%, Training Loss: 0.3553%\n",
      "Epoch [48/300], Step [45/225], Training Accuracy: 85.2083%, Training Loss: 0.3550%\n",
      "Epoch [48/300], Step [46/225], Training Accuracy: 85.2921%, Training Loss: 0.3535%\n",
      "Epoch [48/300], Step [47/225], Training Accuracy: 85.3391%, Training Loss: 0.3548%\n",
      "Epoch [48/300], Step [48/225], Training Accuracy: 85.0911%, Training Loss: 0.3599%\n",
      "Epoch [48/300], Step [49/225], Training Accuracy: 85.1403%, Training Loss: 0.3590%\n",
      "Epoch [48/300], Step [50/225], Training Accuracy: 85.1250%, Training Loss: 0.3600%\n",
      "Epoch [48/300], Step [51/225], Training Accuracy: 85.2941%, Training Loss: 0.3574%\n",
      "Epoch [48/300], Step [52/225], Training Accuracy: 85.3966%, Training Loss: 0.3562%\n",
      "Epoch [48/300], Step [53/225], Training Accuracy: 85.3479%, Training Loss: 0.3559%\n",
      "Epoch [48/300], Step [54/225], Training Accuracy: 85.2720%, Training Loss: 0.3585%\n",
      "Epoch [48/300], Step [55/225], Training Accuracy: 85.1420%, Training Loss: 0.3608%\n",
      "Epoch [48/300], Step [56/225], Training Accuracy: 85.2121%, Training Loss: 0.3584%\n",
      "Epoch [48/300], Step [57/225], Training Accuracy: 85.2248%, Training Loss: 0.3582%\n",
      "Epoch [48/300], Step [58/225], Training Accuracy: 85.2101%, Training Loss: 0.3594%\n",
      "Epoch [48/300], Step [59/225], Training Accuracy: 85.0371%, Training Loss: 0.3618%\n",
      "Epoch [48/300], Step [60/225], Training Accuracy: 84.9479%, Training Loss: 0.3631%\n",
      "Epoch [48/300], Step [61/225], Training Accuracy: 84.9385%, Training Loss: 0.3627%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/300], Step [62/225], Training Accuracy: 85.0050%, Training Loss: 0.3608%\n",
      "Epoch [48/300], Step [63/225], Training Accuracy: 84.9206%, Training Loss: 0.3627%\n",
      "Epoch [48/300], Step [64/225], Training Accuracy: 84.9365%, Training Loss: 0.3619%\n",
      "Epoch [48/300], Step [65/225], Training Accuracy: 84.8798%, Training Loss: 0.3643%\n",
      "Epoch [48/300], Step [66/225], Training Accuracy: 84.8722%, Training Loss: 0.3655%\n",
      "Epoch [48/300], Step [67/225], Training Accuracy: 84.9114%, Training Loss: 0.3654%\n",
      "Epoch [48/300], Step [68/225], Training Accuracy: 84.7886%, Training Loss: 0.3671%\n",
      "Epoch [48/300], Step [69/225], Training Accuracy: 84.8279%, Training Loss: 0.3655%\n",
      "Epoch [48/300], Step [70/225], Training Accuracy: 84.9107%, Training Loss: 0.3645%\n",
      "Epoch [48/300], Step [71/225], Training Accuracy: 84.8371%, Training Loss: 0.3646%\n",
      "Epoch [48/300], Step [72/225], Training Accuracy: 84.7656%, Training Loss: 0.3668%\n",
      "Epoch [48/300], Step [73/225], Training Accuracy: 84.7603%, Training Loss: 0.3671%\n",
      "Epoch [48/300], Step [74/225], Training Accuracy: 84.7340%, Training Loss: 0.3677%\n",
      "Epoch [48/300], Step [75/225], Training Accuracy: 84.8333%, Training Loss: 0.3667%\n",
      "Epoch [48/300], Step [76/225], Training Accuracy: 84.8479%, Training Loss: 0.3666%\n",
      "Epoch [48/300], Step [77/225], Training Accuracy: 84.8823%, Training Loss: 0.3667%\n",
      "Epoch [48/300], Step [78/225], Training Accuracy: 84.9359%, Training Loss: 0.3660%\n",
      "Epoch [48/300], Step [79/225], Training Accuracy: 84.9684%, Training Loss: 0.3653%\n",
      "Epoch [48/300], Step [80/225], Training Accuracy: 85.0391%, Training Loss: 0.3640%\n",
      "Epoch [48/300], Step [81/225], Training Accuracy: 85.1659%, Training Loss: 0.3618%\n",
      "Epoch [48/300], Step [82/225], Training Accuracy: 85.2896%, Training Loss: 0.3602%\n",
      "Epoch [48/300], Step [83/225], Training Accuracy: 85.3351%, Training Loss: 0.3587%\n",
      "Epoch [48/300], Step [84/225], Training Accuracy: 85.3795%, Training Loss: 0.3571%\n",
      "Epoch [48/300], Step [85/225], Training Accuracy: 85.3125%, Training Loss: 0.3567%\n",
      "Epoch [48/300], Step [86/225], Training Accuracy: 85.4651%, Training Loss: 0.3544%\n",
      "Epoch [48/300], Step [87/225], Training Accuracy: 85.4705%, Training Loss: 0.3538%\n",
      "Epoch [48/300], Step [88/225], Training Accuracy: 85.4226%, Training Loss: 0.3550%\n",
      "Epoch [48/300], Step [89/225], Training Accuracy: 85.4108%, Training Loss: 0.3549%\n",
      "Epoch [48/300], Step [90/225], Training Accuracy: 85.3125%, Training Loss: 0.3572%\n",
      "Epoch [48/300], Step [91/225], Training Accuracy: 85.3537%, Training Loss: 0.3569%\n",
      "Epoch [48/300], Step [92/225], Training Accuracy: 85.3770%, Training Loss: 0.3572%\n",
      "Epoch [48/300], Step [93/225], Training Accuracy: 85.4167%, Training Loss: 0.3565%\n",
      "Epoch [48/300], Step [94/225], Training Accuracy: 85.4222%, Training Loss: 0.3582%\n",
      "Epoch [48/300], Step [95/225], Training Accuracy: 85.4112%, Training Loss: 0.3579%\n",
      "Epoch [48/300], Step [96/225], Training Accuracy: 85.5306%, Training Loss: 0.3559%\n",
      "Epoch [48/300], Step [97/225], Training Accuracy: 85.5026%, Training Loss: 0.3561%\n",
      "Epoch [48/300], Step [98/225], Training Accuracy: 85.4432%, Training Loss: 0.3574%\n",
      "Epoch [48/300], Step [99/225], Training Accuracy: 85.4482%, Training Loss: 0.3572%\n",
      "Epoch [48/300], Step [100/225], Training Accuracy: 85.3750%, Training Loss: 0.3588%\n",
      "Epoch [48/300], Step [101/225], Training Accuracy: 85.3651%, Training Loss: 0.3584%\n",
      "Epoch [48/300], Step [102/225], Training Accuracy: 85.3401%, Training Loss: 0.3612%\n",
      "Epoch [48/300], Step [103/225], Training Accuracy: 85.3914%, Training Loss: 0.3602%\n",
      "Epoch [48/300], Step [104/225], Training Accuracy: 85.4117%, Training Loss: 0.3598%\n",
      "Epoch [48/300], Step [105/225], Training Accuracy: 85.5060%, Training Loss: 0.3584%\n",
      "Epoch [48/300], Step [106/225], Training Accuracy: 85.4953%, Training Loss: 0.3583%\n",
      "Epoch [48/300], Step [107/225], Training Accuracy: 85.5286%, Training Loss: 0.3578%\n",
      "Epoch [48/300], Step [108/225], Training Accuracy: 85.5035%, Training Loss: 0.3595%\n",
      "Epoch [48/300], Step [109/225], Training Accuracy: 85.4788%, Training Loss: 0.3592%\n",
      "Epoch [48/300], Step [110/225], Training Accuracy: 85.5256%, Training Loss: 0.3583%\n",
      "Epoch [48/300], Step [111/225], Training Accuracy: 85.5434%, Training Loss: 0.3579%\n",
      "Epoch [48/300], Step [112/225], Training Accuracy: 85.5748%, Training Loss: 0.3575%\n",
      "Epoch [48/300], Step [113/225], Training Accuracy: 85.5642%, Training Loss: 0.3572%\n",
      "Epoch [48/300], Step [114/225], Training Accuracy: 85.5400%, Training Loss: 0.3570%\n",
      "Epoch [48/300], Step [115/225], Training Accuracy: 85.5842%, Training Loss: 0.3553%\n",
      "Epoch [48/300], Step [116/225], Training Accuracy: 85.5199%, Training Loss: 0.3559%\n",
      "Epoch [48/300], Step [117/225], Training Accuracy: 85.5502%, Training Loss: 0.3562%\n",
      "Epoch [48/300], Step [118/225], Training Accuracy: 85.5932%, Training Loss: 0.3553%\n",
      "Epoch [48/300], Step [119/225], Training Accuracy: 85.6092%, Training Loss: 0.3548%\n",
      "Epoch [48/300], Step [120/225], Training Accuracy: 85.5990%, Training Loss: 0.3548%\n",
      "Epoch [48/300], Step [121/225], Training Accuracy: 85.5501%, Training Loss: 0.3552%\n",
      "Epoch [48/300], Step [122/225], Training Accuracy: 85.5789%, Training Loss: 0.3545%\n",
      "Epoch [48/300], Step [123/225], Training Accuracy: 85.5564%, Training Loss: 0.3544%\n",
      "Epoch [48/300], Step [124/225], Training Accuracy: 85.5721%, Training Loss: 0.3532%\n",
      "Epoch [48/300], Step [125/225], Training Accuracy: 85.5625%, Training Loss: 0.3551%\n",
      "Epoch [48/300], Step [126/225], Training Accuracy: 85.5779%, Training Loss: 0.3550%\n",
      "Epoch [48/300], Step [127/225], Training Accuracy: 85.5930%, Training Loss: 0.3550%\n",
      "Epoch [48/300], Step [128/225], Training Accuracy: 85.5713%, Training Loss: 0.3560%\n",
      "Epoch [48/300], Step [129/225], Training Accuracy: 85.5620%, Training Loss: 0.3561%\n",
      "Epoch [48/300], Step [130/225], Training Accuracy: 85.5889%, Training Loss: 0.3564%\n",
      "Epoch [48/300], Step [131/225], Training Accuracy: 85.5200%, Training Loss: 0.3572%\n",
      "Epoch [48/300], Step [132/225], Training Accuracy: 85.5114%, Training Loss: 0.3582%\n",
      "Epoch [48/300], Step [133/225], Training Accuracy: 85.5028%, Training Loss: 0.3590%\n",
      "Epoch [48/300], Step [134/225], Training Accuracy: 85.4244%, Training Loss: 0.3609%\n",
      "Epoch [48/300], Step [135/225], Training Accuracy: 85.3819%, Training Loss: 0.3614%\n",
      "Epoch [48/300], Step [136/225], Training Accuracy: 85.3171%, Training Loss: 0.3623%\n",
      "Epoch [48/300], Step [137/225], Training Accuracy: 85.2874%, Training Loss: 0.3624%\n",
      "Epoch [48/300], Step [138/225], Training Accuracy: 85.3374%, Training Loss: 0.3615%\n",
      "Epoch [48/300], Step [139/225], Training Accuracy: 85.2743%, Training Loss: 0.3644%\n",
      "Epoch [48/300], Step [140/225], Training Accuracy: 85.2567%, Training Loss: 0.3645%\n",
      "Epoch [48/300], Step [141/225], Training Accuracy: 85.2837%, Training Loss: 0.3644%\n",
      "Epoch [48/300], Step [142/225], Training Accuracy: 85.2993%, Training Loss: 0.3637%\n",
      "Epoch [48/300], Step [143/225], Training Accuracy: 85.2819%, Training Loss: 0.3637%\n",
      "Epoch [48/300], Step [144/225], Training Accuracy: 85.2865%, Training Loss: 0.3634%\n",
      "Epoch [48/300], Step [145/225], Training Accuracy: 85.2586%, Training Loss: 0.3636%\n",
      "Epoch [48/300], Step [146/225], Training Accuracy: 85.2419%, Training Loss: 0.3639%\n",
      "Epoch [48/300], Step [147/225], Training Accuracy: 85.2360%, Training Loss: 0.3644%\n",
      "Epoch [48/300], Step [148/225], Training Accuracy: 85.2618%, Training Loss: 0.3637%\n",
      "Epoch [48/300], Step [149/225], Training Accuracy: 85.2873%, Training Loss: 0.3633%\n",
      "Epoch [48/300], Step [150/225], Training Accuracy: 85.3542%, Training Loss: 0.3620%\n",
      "Epoch [48/300], Step [151/225], Training Accuracy: 85.3580%, Training Loss: 0.3619%\n",
      "Epoch [48/300], Step [152/225], Training Accuracy: 85.3721%, Training Loss: 0.3618%\n",
      "Epoch [48/300], Step [153/225], Training Accuracy: 85.3860%, Training Loss: 0.3612%\n",
      "Epoch [48/300], Step [154/225], Training Accuracy: 85.4200%, Training Loss: 0.3606%\n",
      "Epoch [48/300], Step [155/225], Training Accuracy: 85.4032%, Training Loss: 0.3610%\n",
      "Epoch [48/300], Step [156/225], Training Accuracy: 85.3866%, Training Loss: 0.3620%\n",
      "Epoch [48/300], Step [157/225], Training Accuracy: 85.3603%, Training Loss: 0.3629%\n",
      "Epoch [48/300], Step [158/225], Training Accuracy: 85.3540%, Training Loss: 0.3624%\n",
      "Epoch [48/300], Step [159/225], Training Accuracy: 85.3282%, Training Loss: 0.3642%\n",
      "Epoch [48/300], Step [160/225], Training Accuracy: 85.3125%, Training Loss: 0.3642%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/300], Step [161/225], Training Accuracy: 85.3552%, Training Loss: 0.3638%\n",
      "Epoch [48/300], Step [162/225], Training Accuracy: 85.3588%, Training Loss: 0.3639%\n",
      "Epoch [48/300], Step [163/225], Training Accuracy: 85.3623%, Training Loss: 0.3638%\n",
      "Epoch [48/300], Step [164/225], Training Accuracy: 85.3849%, Training Loss: 0.3637%\n",
      "Epoch [48/300], Step [165/225], Training Accuracy: 85.3883%, Training Loss: 0.3635%\n",
      "Epoch [48/300], Step [166/225], Training Accuracy: 85.3727%, Training Loss: 0.3634%\n",
      "Epoch [48/300], Step [167/225], Training Accuracy: 85.3948%, Training Loss: 0.3628%\n",
      "Epoch [48/300], Step [168/225], Training Accuracy: 85.3981%, Training Loss: 0.3637%\n",
      "Epoch [48/300], Step [169/225], Training Accuracy: 85.4290%, Training Loss: 0.3630%\n",
      "Epoch [48/300], Step [170/225], Training Accuracy: 85.4228%, Training Loss: 0.3629%\n",
      "Epoch [48/300], Step [171/225], Training Accuracy: 85.3710%, Training Loss: 0.3639%\n",
      "Epoch [48/300], Step [172/225], Training Accuracy: 85.3834%, Training Loss: 0.3637%\n",
      "Epoch [48/300], Step [173/225], Training Accuracy: 85.3866%, Training Loss: 0.3639%\n",
      "Epoch [48/300], Step [174/225], Training Accuracy: 85.3807%, Training Loss: 0.3639%\n",
      "Epoch [48/300], Step [175/225], Training Accuracy: 85.3661%, Training Loss: 0.3638%\n",
      "Epoch [48/300], Step [176/225], Training Accuracy: 85.3693%, Training Loss: 0.3637%\n",
      "Epoch [48/300], Step [177/225], Training Accuracy: 85.3460%, Training Loss: 0.3640%\n",
      "Epoch [48/300], Step [178/225], Training Accuracy: 85.3318%, Training Loss: 0.3639%\n",
      "Epoch [48/300], Step [179/225], Training Accuracy: 85.3090%, Training Loss: 0.3646%\n",
      "Epoch [48/300], Step [180/225], Training Accuracy: 85.3038%, Training Loss: 0.3647%\n",
      "Epoch [48/300], Step [181/225], Training Accuracy: 85.2642%, Training Loss: 0.3659%\n",
      "Epoch [48/300], Step [182/225], Training Accuracy: 85.3194%, Training Loss: 0.3649%\n",
      "Epoch [48/300], Step [183/225], Training Accuracy: 85.3057%, Training Loss: 0.3652%\n",
      "Epoch [48/300], Step [184/225], Training Accuracy: 85.3091%, Training Loss: 0.3647%\n",
      "Epoch [48/300], Step [185/225], Training Accuracy: 85.3125%, Training Loss: 0.3645%\n",
      "Epoch [48/300], Step [186/225], Training Accuracy: 85.3495%, Training Loss: 0.3634%\n",
      "Epoch [48/300], Step [187/225], Training Accuracy: 85.3777%, Training Loss: 0.3637%\n",
      "Epoch [48/300], Step [188/225], Training Accuracy: 85.4139%, Training Loss: 0.3630%\n",
      "Epoch [48/300], Step [189/225], Training Accuracy: 85.4249%, Training Loss: 0.3631%\n",
      "Epoch [48/300], Step [190/225], Training Accuracy: 85.4030%, Training Loss: 0.3645%\n",
      "Epoch [48/300], Step [191/225], Training Accuracy: 85.3976%, Training Loss: 0.3647%\n",
      "Epoch [48/300], Step [192/225], Training Accuracy: 85.4167%, Training Loss: 0.3643%\n",
      "Epoch [48/300], Step [193/225], Training Accuracy: 85.3951%, Training Loss: 0.3655%\n",
      "Epoch [48/300], Step [194/225], Training Accuracy: 85.4059%, Training Loss: 0.3658%\n",
      "Epoch [48/300], Step [195/225], Training Accuracy: 85.4087%, Training Loss: 0.3657%\n",
      "Epoch [48/300], Step [196/225], Training Accuracy: 85.3715%, Training Loss: 0.3664%\n",
      "Epoch [48/300], Step [197/225], Training Accuracy: 85.3268%, Training Loss: 0.3674%\n",
      "Epoch [48/300], Step [198/225], Training Accuracy: 85.2983%, Training Loss: 0.3674%\n",
      "Epoch [48/300], Step [199/225], Training Accuracy: 85.3015%, Training Loss: 0.3674%\n",
      "Epoch [48/300], Step [200/225], Training Accuracy: 85.2969%, Training Loss: 0.3677%\n",
      "Epoch [48/300], Step [201/225], Training Accuracy: 85.3001%, Training Loss: 0.3676%\n",
      "Epoch [48/300], Step [202/225], Training Accuracy: 85.2877%, Training Loss: 0.3680%\n",
      "Epoch [48/300], Step [203/225], Training Accuracy: 85.2756%, Training Loss: 0.3677%\n",
      "Epoch [48/300], Step [204/225], Training Accuracy: 85.2788%, Training Loss: 0.3679%\n",
      "Epoch [48/300], Step [205/225], Training Accuracy: 85.3125%, Training Loss: 0.3670%\n",
      "Epoch [48/300], Step [206/225], Training Accuracy: 85.2928%, Training Loss: 0.3673%\n",
      "Epoch [48/300], Step [207/225], Training Accuracy: 85.2582%, Training Loss: 0.3677%\n",
      "Epoch [48/300], Step [208/225], Training Accuracy: 85.2464%, Training Loss: 0.3686%\n",
      "Epoch [48/300], Step [209/225], Training Accuracy: 85.2273%, Training Loss: 0.3689%\n",
      "Epoch [48/300], Step [210/225], Training Accuracy: 85.2604%, Training Loss: 0.3686%\n",
      "Epoch [48/300], Step [211/225], Training Accuracy: 85.2710%, Training Loss: 0.3684%\n",
      "Epoch [48/300], Step [212/225], Training Accuracy: 85.2594%, Training Loss: 0.3685%\n",
      "Epoch [48/300], Step [213/225], Training Accuracy: 85.2406%, Training Loss: 0.3685%\n",
      "Epoch [48/300], Step [214/225], Training Accuracy: 85.2366%, Training Loss: 0.3686%\n",
      "Epoch [48/300], Step [215/225], Training Accuracy: 85.2398%, Training Loss: 0.3690%\n",
      "Epoch [48/300], Step [216/225], Training Accuracy: 85.2575%, Training Loss: 0.3691%\n",
      "Epoch [48/300], Step [217/225], Training Accuracy: 85.2463%, Training Loss: 0.3692%\n",
      "Epoch [48/300], Step [218/225], Training Accuracy: 85.2423%, Training Loss: 0.3694%\n",
      "Epoch [48/300], Step [219/225], Training Accuracy: 85.2383%, Training Loss: 0.3696%\n",
      "Epoch [48/300], Step [220/225], Training Accuracy: 85.2486%, Training Loss: 0.3693%\n",
      "Epoch [48/300], Step [221/225], Training Accuracy: 85.2093%, Training Loss: 0.3695%\n",
      "Epoch [48/300], Step [222/225], Training Accuracy: 85.2477%, Training Loss: 0.3690%\n",
      "Epoch [48/300], Step [223/225], Training Accuracy: 85.2649%, Training Loss: 0.3687%\n",
      "Epoch [48/300], Step [224/225], Training Accuracy: 85.2679%, Training Loss: 0.3681%\n",
      "Epoch [48/300], Step [225/225], Training Accuracy: 85.2765%, Training Loss: 0.3676%\n",
      "Epoch [49/300], Step [1/225], Training Accuracy: 92.1875%, Training Loss: 0.2745%\n",
      "Epoch [49/300], Step [2/225], Training Accuracy: 92.9688%, Training Loss: 0.2603%\n",
      "Epoch [49/300], Step [3/225], Training Accuracy: 90.6250%, Training Loss: 0.3150%\n",
      "Epoch [49/300], Step [4/225], Training Accuracy: 89.0625%, Training Loss: 0.3634%\n",
      "Epoch [49/300], Step [5/225], Training Accuracy: 87.8125%, Training Loss: 0.3889%\n",
      "Epoch [49/300], Step [6/225], Training Accuracy: 87.5000%, Training Loss: 0.3923%\n",
      "Epoch [49/300], Step [7/225], Training Accuracy: 88.1696%, Training Loss: 0.3726%\n",
      "Epoch [49/300], Step [8/225], Training Accuracy: 86.9141%, Training Loss: 0.3991%\n",
      "Epoch [49/300], Step [9/225], Training Accuracy: 85.9375%, Training Loss: 0.3941%\n",
      "Epoch [49/300], Step [10/225], Training Accuracy: 85.4688%, Training Loss: 0.4065%\n",
      "Epoch [49/300], Step [11/225], Training Accuracy: 85.7955%, Training Loss: 0.4061%\n",
      "Epoch [49/300], Step [12/225], Training Accuracy: 85.6771%, Training Loss: 0.4003%\n",
      "Epoch [49/300], Step [13/225], Training Accuracy: 86.2981%, Training Loss: 0.3808%\n",
      "Epoch [49/300], Step [14/225], Training Accuracy: 86.4955%, Training Loss: 0.3716%\n",
      "Epoch [49/300], Step [15/225], Training Accuracy: 86.3542%, Training Loss: 0.3747%\n",
      "Epoch [49/300], Step [16/225], Training Accuracy: 85.9375%, Training Loss: 0.3785%\n",
      "Epoch [49/300], Step [17/225], Training Accuracy: 85.6618%, Training Loss: 0.3783%\n",
      "Epoch [49/300], Step [18/225], Training Accuracy: 85.4167%, Training Loss: 0.3809%\n",
      "Epoch [49/300], Step [19/225], Training Accuracy: 85.6086%, Training Loss: 0.3771%\n",
      "Epoch [49/300], Step [20/225], Training Accuracy: 85.7031%, Training Loss: 0.3698%\n",
      "Epoch [49/300], Step [21/225], Training Accuracy: 85.9375%, Training Loss: 0.3653%\n",
      "Epoch [49/300], Step [22/225], Training Accuracy: 85.7955%, Training Loss: 0.3659%\n",
      "Epoch [49/300], Step [23/225], Training Accuracy: 85.8016%, Training Loss: 0.3659%\n",
      "Epoch [49/300], Step [24/225], Training Accuracy: 85.8724%, Training Loss: 0.3612%\n",
      "Epoch [49/300], Step [25/225], Training Accuracy: 86.1250%, Training Loss: 0.3542%\n",
      "Epoch [49/300], Step [26/225], Training Accuracy: 86.2981%, Training Loss: 0.3498%\n",
      "Epoch [49/300], Step [27/225], Training Accuracy: 86.5741%, Training Loss: 0.3468%\n",
      "Epoch [49/300], Step [28/225], Training Accuracy: 86.6071%, Training Loss: 0.3449%\n",
      "Epoch [49/300], Step [29/225], Training Accuracy: 86.3685%, Training Loss: 0.3480%\n",
      "Epoch [49/300], Step [30/225], Training Accuracy: 86.2500%, Training Loss: 0.3474%\n",
      "Epoch [49/300], Step [31/225], Training Accuracy: 86.3407%, Training Loss: 0.3460%\n",
      "Epoch [49/300], Step [32/225], Training Accuracy: 86.5234%, Training Loss: 0.3405%\n",
      "Epoch [49/300], Step [33/225], Training Accuracy: 86.7424%, Training Loss: 0.3359%\n",
      "Epoch [49/300], Step [34/225], Training Accuracy: 86.3511%, Training Loss: 0.3437%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/300], Step [35/225], Training Accuracy: 86.5179%, Training Loss: 0.3409%\n",
      "Epoch [49/300], Step [36/225], Training Accuracy: 86.5451%, Training Loss: 0.3417%\n",
      "Epoch [49/300], Step [37/225], Training Accuracy: 86.5709%, Training Loss: 0.3423%\n",
      "Epoch [49/300], Step [38/225], Training Accuracy: 86.5543%, Training Loss: 0.3412%\n",
      "Epoch [49/300], Step [39/225], Training Accuracy: 86.4183%, Training Loss: 0.3424%\n",
      "Epoch [49/300], Step [40/225], Training Accuracy: 86.4844%, Training Loss: 0.3417%\n",
      "Epoch [49/300], Step [41/225], Training Accuracy: 86.3186%, Training Loss: 0.3465%\n",
      "Epoch [49/300], Step [42/225], Training Accuracy: 86.4583%, Training Loss: 0.3442%\n",
      "Epoch [49/300], Step [43/225], Training Accuracy: 86.4826%, Training Loss: 0.3458%\n",
      "Epoch [49/300], Step [44/225], Training Accuracy: 86.5057%, Training Loss: 0.3461%\n",
      "Epoch [49/300], Step [45/225], Training Accuracy: 86.5278%, Training Loss: 0.3458%\n",
      "Epoch [49/300], Step [46/225], Training Accuracy: 86.6168%, Training Loss: 0.3432%\n",
      "Epoch [49/300], Step [47/225], Training Accuracy: 86.4694%, Training Loss: 0.3485%\n",
      "Epoch [49/300], Step [48/225], Training Accuracy: 86.4909%, Training Loss: 0.3478%\n",
      "Epoch [49/300], Step [49/225], Training Accuracy: 86.4796%, Training Loss: 0.3480%\n",
      "Epoch [49/300], Step [50/225], Training Accuracy: 86.4062%, Training Loss: 0.3487%\n",
      "Epoch [49/300], Step [51/225], Training Accuracy: 86.4890%, Training Loss: 0.3464%\n",
      "Epoch [49/300], Step [52/225], Training Accuracy: 86.6587%, Training Loss: 0.3431%\n",
      "Epoch [49/300], Step [53/225], Training Accuracy: 86.5861%, Training Loss: 0.3442%\n",
      "Epoch [49/300], Step [54/225], Training Accuracy: 86.6319%, Training Loss: 0.3432%\n",
      "Epoch [49/300], Step [55/225], Training Accuracy: 86.5625%, Training Loss: 0.3451%\n",
      "Epoch [49/300], Step [56/225], Training Accuracy: 86.5792%, Training Loss: 0.3445%\n",
      "Epoch [49/300], Step [57/225], Training Accuracy: 86.5680%, Training Loss: 0.3462%\n",
      "Epoch [49/300], Step [58/225], Training Accuracy: 86.4494%, Training Loss: 0.3477%\n",
      "Epoch [49/300], Step [59/225], Training Accuracy: 86.3877%, Training Loss: 0.3490%\n",
      "Epoch [49/300], Step [60/225], Training Accuracy: 86.3802%, Training Loss: 0.3485%\n",
      "Epoch [49/300], Step [61/225], Training Accuracy: 86.3730%, Training Loss: 0.3498%\n",
      "Epoch [49/300], Step [62/225], Training Accuracy: 86.3911%, Training Loss: 0.3487%\n",
      "Epoch [49/300], Step [63/225], Training Accuracy: 86.2847%, Training Loss: 0.3502%\n",
      "Epoch [49/300], Step [64/225], Training Accuracy: 86.2793%, Training Loss: 0.3521%\n",
      "Epoch [49/300], Step [65/225], Training Accuracy: 86.3221%, Training Loss: 0.3519%\n",
      "Epoch [49/300], Step [66/225], Training Accuracy: 86.3873%, Training Loss: 0.3499%\n",
      "Epoch [49/300], Step [67/225], Training Accuracy: 86.3806%, Training Loss: 0.3497%\n",
      "Epoch [49/300], Step [68/225], Training Accuracy: 86.3741%, Training Loss: 0.3515%\n",
      "Epoch [49/300], Step [69/225], Training Accuracy: 86.3451%, Training Loss: 0.3513%\n",
      "Epoch [49/300], Step [70/225], Training Accuracy: 86.3839%, Training Loss: 0.3500%\n",
      "Epoch [49/300], Step [71/225], Training Accuracy: 86.2896%, Training Loss: 0.3517%\n",
      "Epoch [49/300], Step [72/225], Training Accuracy: 86.1545%, Training Loss: 0.3552%\n",
      "Epoch [49/300], Step [73/225], Training Accuracy: 86.1943%, Training Loss: 0.3546%\n",
      "Epoch [49/300], Step [74/225], Training Accuracy: 86.1486%, Training Loss: 0.3546%\n",
      "Epoch [49/300], Step [75/225], Training Accuracy: 86.2500%, Training Loss: 0.3529%\n",
      "Epoch [49/300], Step [76/225], Training Accuracy: 86.2253%, Training Loss: 0.3535%\n",
      "Epoch [49/300], Step [77/225], Training Accuracy: 86.1810%, Training Loss: 0.3548%\n",
      "Epoch [49/300], Step [78/225], Training Accuracy: 86.1779%, Training Loss: 0.3541%\n",
      "Epoch [49/300], Step [79/225], Training Accuracy: 86.1353%, Training Loss: 0.3538%\n",
      "Epoch [49/300], Step [80/225], Training Accuracy: 86.1914%, Training Loss: 0.3527%\n",
      "Epoch [49/300], Step [81/225], Training Accuracy: 86.2654%, Training Loss: 0.3509%\n",
      "Epoch [49/300], Step [82/225], Training Accuracy: 86.2995%, Training Loss: 0.3500%\n",
      "Epoch [49/300], Step [83/225], Training Accuracy: 86.2011%, Training Loss: 0.3522%\n",
      "Epoch [49/300], Step [84/225], Training Accuracy: 86.2351%, Training Loss: 0.3510%\n",
      "Epoch [49/300], Step [85/225], Training Accuracy: 86.3235%, Training Loss: 0.3494%\n",
      "Epoch [49/300], Step [86/225], Training Accuracy: 86.3372%, Training Loss: 0.3489%\n",
      "Epoch [49/300], Step [87/225], Training Accuracy: 86.3865%, Training Loss: 0.3484%\n",
      "Epoch [49/300], Step [88/225], Training Accuracy: 86.2926%, Training Loss: 0.3509%\n",
      "Epoch [49/300], Step [89/225], Training Accuracy: 86.3764%, Training Loss: 0.3500%\n",
      "Epoch [49/300], Step [90/225], Training Accuracy: 86.4236%, Training Loss: 0.3491%\n",
      "Epoch [49/300], Step [91/225], Training Accuracy: 86.4183%, Training Loss: 0.3483%\n",
      "Epoch [49/300], Step [92/225], Training Accuracy: 86.3961%, Training Loss: 0.3496%\n",
      "Epoch [49/300], Step [93/225], Training Accuracy: 86.3911%, Training Loss: 0.3515%\n",
      "Epoch [49/300], Step [94/225], Training Accuracy: 86.3863%, Training Loss: 0.3527%\n",
      "Epoch [49/300], Step [95/225], Training Accuracy: 86.3816%, Training Loss: 0.3524%\n",
      "Epoch [49/300], Step [96/225], Training Accuracy: 86.4095%, Training Loss: 0.3508%\n",
      "Epoch [49/300], Step [97/225], Training Accuracy: 86.4530%, Training Loss: 0.3496%\n",
      "Epoch [49/300], Step [98/225], Training Accuracy: 86.4636%, Training Loss: 0.3494%\n",
      "Epoch [49/300], Step [99/225], Training Accuracy: 86.4899%, Training Loss: 0.3494%\n",
      "Epoch [49/300], Step [100/225], Training Accuracy: 86.4375%, Training Loss: 0.3504%\n",
      "Epoch [49/300], Step [101/225], Training Accuracy: 86.4325%, Training Loss: 0.3503%\n",
      "Epoch [49/300], Step [102/225], Training Accuracy: 86.3664%, Training Loss: 0.3520%\n",
      "Epoch [49/300], Step [103/225], Training Accuracy: 86.3471%, Training Loss: 0.3524%\n",
      "Epoch [49/300], Step [104/225], Training Accuracy: 86.3431%, Training Loss: 0.3523%\n",
      "Epoch [49/300], Step [105/225], Training Accuracy: 86.3839%, Training Loss: 0.3517%\n",
      "Epoch [49/300], Step [106/225], Training Accuracy: 86.3797%, Training Loss: 0.3520%\n",
      "Epoch [49/300], Step [107/225], Training Accuracy: 86.3026%, Training Loss: 0.3527%\n",
      "Epoch [49/300], Step [108/225], Training Accuracy: 86.2847%, Training Loss: 0.3529%\n",
      "Epoch [49/300], Step [109/225], Training Accuracy: 86.2385%, Training Loss: 0.3533%\n",
      "Epoch [49/300], Step [110/225], Training Accuracy: 86.2500%, Training Loss: 0.3533%\n",
      "Epoch [49/300], Step [111/225], Training Accuracy: 86.1768%, Training Loss: 0.3541%\n",
      "Epoch [49/300], Step [112/225], Training Accuracy: 86.1607%, Training Loss: 0.3538%\n",
      "Epoch [49/300], Step [113/225], Training Accuracy: 86.1587%, Training Loss: 0.3542%\n",
      "Epoch [49/300], Step [114/225], Training Accuracy: 86.1705%, Training Loss: 0.3538%\n",
      "Epoch [49/300], Step [115/225], Training Accuracy: 86.1821%, Training Loss: 0.3538%\n",
      "Epoch [49/300], Step [116/225], Training Accuracy: 86.1395%, Training Loss: 0.3550%\n",
      "Epoch [49/300], Step [117/225], Training Accuracy: 86.1245%, Training Loss: 0.3556%\n",
      "Epoch [49/300], Step [118/225], Training Accuracy: 86.1096%, Training Loss: 0.3562%\n",
      "Epoch [49/300], Step [119/225], Training Accuracy: 86.1607%, Training Loss: 0.3553%\n",
      "Epoch [49/300], Step [120/225], Training Accuracy: 86.1068%, Training Loss: 0.3555%\n",
      "Epoch [49/300], Step [121/225], Training Accuracy: 86.0795%, Training Loss: 0.3564%\n",
      "Epoch [49/300], Step [122/225], Training Accuracy: 86.0528%, Training Loss: 0.3567%\n",
      "Epoch [49/300], Step [123/225], Training Accuracy: 86.0772%, Training Loss: 0.3564%\n",
      "Epoch [49/300], Step [124/225], Training Accuracy: 86.1013%, Training Loss: 0.3557%\n",
      "Epoch [49/300], Step [125/225], Training Accuracy: 86.0875%, Training Loss: 0.3553%\n",
      "Epoch [49/300], Step [126/225], Training Accuracy: 86.0615%, Training Loss: 0.3556%\n",
      "Epoch [49/300], Step [127/225], Training Accuracy: 86.0359%, Training Loss: 0.3558%\n",
      "Epoch [49/300], Step [128/225], Training Accuracy: 86.0229%, Training Loss: 0.3554%\n",
      "Epoch [49/300], Step [129/225], Training Accuracy: 86.0223%, Training Loss: 0.3555%\n",
      "Epoch [49/300], Step [130/225], Training Accuracy: 86.0337%, Training Loss: 0.3553%\n",
      "Epoch [49/300], Step [131/225], Training Accuracy: 85.9614%, Training Loss: 0.3564%\n",
      "Epoch [49/300], Step [132/225], Training Accuracy: 85.9493%, Training Loss: 0.3568%\n",
      "Epoch [49/300], Step [133/225], Training Accuracy: 85.9492%, Training Loss: 0.3565%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/300], Step [134/225], Training Accuracy: 85.8559%, Training Loss: 0.3578%\n",
      "Epoch [49/300], Step [135/225], Training Accuracy: 85.8681%, Training Loss: 0.3580%\n",
      "Epoch [49/300], Step [136/225], Training Accuracy: 85.8456%, Training Loss: 0.3588%\n",
      "Epoch [49/300], Step [137/225], Training Accuracy: 85.8349%, Training Loss: 0.3586%\n",
      "Epoch [49/300], Step [138/225], Training Accuracy: 85.9035%, Training Loss: 0.3571%\n",
      "Epoch [49/300], Step [139/225], Training Accuracy: 85.8588%, Training Loss: 0.3590%\n",
      "Epoch [49/300], Step [140/225], Training Accuracy: 85.8482%, Training Loss: 0.3587%\n",
      "Epoch [49/300], Step [141/225], Training Accuracy: 85.8156%, Training Loss: 0.3591%\n",
      "Epoch [49/300], Step [142/225], Training Accuracy: 85.8385%, Training Loss: 0.3585%\n",
      "Epoch [49/300], Step [143/225], Training Accuracy: 85.8282%, Training Loss: 0.3590%\n",
      "Epoch [49/300], Step [144/225], Training Accuracy: 85.8398%, Training Loss: 0.3584%\n",
      "Epoch [49/300], Step [145/225], Training Accuracy: 85.8190%, Training Loss: 0.3583%\n",
      "Epoch [49/300], Step [146/225], Training Accuracy: 85.8519%, Training Loss: 0.3572%\n",
      "Epoch [49/300], Step [147/225], Training Accuracy: 85.8418%, Training Loss: 0.3572%\n",
      "Epoch [49/300], Step [148/225], Training Accuracy: 85.8847%, Training Loss: 0.3559%\n",
      "Epoch [49/300], Step [149/225], Training Accuracy: 85.8641%, Training Loss: 0.3558%\n",
      "Epoch [49/300], Step [150/225], Training Accuracy: 85.8646%, Training Loss: 0.3550%\n",
      "Epoch [49/300], Step [151/225], Training Accuracy: 85.9272%, Training Loss: 0.3539%\n",
      "Epoch [49/300], Step [152/225], Training Accuracy: 85.9581%, Training Loss: 0.3533%\n",
      "Epoch [49/300], Step [153/225], Training Accuracy: 85.9681%, Training Loss: 0.3529%\n",
      "Epoch [49/300], Step [154/225], Training Accuracy: 85.9882%, Training Loss: 0.3524%\n",
      "Epoch [49/300], Step [155/225], Training Accuracy: 85.9778%, Training Loss: 0.3519%\n",
      "Epoch [49/300], Step [156/225], Training Accuracy: 85.9575%, Training Loss: 0.3527%\n",
      "Epoch [49/300], Step [157/225], Training Accuracy: 85.9375%, Training Loss: 0.3539%\n",
      "Epoch [49/300], Step [158/225], Training Accuracy: 85.9573%, Training Loss: 0.3531%\n",
      "Epoch [49/300], Step [159/225], Training Accuracy: 85.9768%, Training Loss: 0.3529%\n",
      "Epoch [49/300], Step [160/225], Training Accuracy: 85.9473%, Training Loss: 0.3537%\n",
      "Epoch [49/300], Step [161/225], Training Accuracy: 85.9569%, Training Loss: 0.3537%\n",
      "Epoch [49/300], Step [162/225], Training Accuracy: 85.9664%, Training Loss: 0.3539%\n",
      "Epoch [49/300], Step [163/225], Training Accuracy: 85.9758%, Training Loss: 0.3542%\n",
      "Epoch [49/300], Step [164/225], Training Accuracy: 86.0232%, Training Loss: 0.3530%\n",
      "Epoch [49/300], Step [165/225], Training Accuracy: 86.0795%, Training Loss: 0.3520%\n",
      "Epoch [49/300], Step [166/225], Training Accuracy: 86.0693%, Training Loss: 0.3526%\n",
      "Epoch [49/300], Step [167/225], Training Accuracy: 86.0778%, Training Loss: 0.3521%\n",
      "Epoch [49/300], Step [168/225], Training Accuracy: 86.1142%, Training Loss: 0.3513%\n",
      "Epoch [49/300], Step [169/225], Training Accuracy: 86.1779%, Training Loss: 0.3502%\n",
      "Epoch [49/300], Step [170/225], Training Accuracy: 86.1581%, Training Loss: 0.3509%\n",
      "Epoch [49/300], Step [171/225], Training Accuracy: 86.1568%, Training Loss: 0.3517%\n",
      "Epoch [49/300], Step [172/225], Training Accuracy: 86.1737%, Training Loss: 0.3513%\n",
      "Epoch [49/300], Step [173/225], Training Accuracy: 86.2175%, Training Loss: 0.3506%\n",
      "Epoch [49/300], Step [174/225], Training Accuracy: 86.2338%, Training Loss: 0.3502%\n",
      "Epoch [49/300], Step [175/225], Training Accuracy: 86.2679%, Training Loss: 0.3493%\n",
      "Epoch [49/300], Step [176/225], Training Accuracy: 86.2749%, Training Loss: 0.3499%\n",
      "Epoch [49/300], Step [177/225], Training Accuracy: 86.2818%, Training Loss: 0.3496%\n",
      "Epoch [49/300], Step [178/225], Training Accuracy: 86.2886%, Training Loss: 0.3494%\n",
      "Epoch [49/300], Step [179/225], Training Accuracy: 86.3128%, Training Loss: 0.3488%\n",
      "Epoch [49/300], Step [180/225], Training Accuracy: 86.3368%, Training Loss: 0.3485%\n",
      "Epoch [49/300], Step [181/225], Training Accuracy: 86.3519%, Training Loss: 0.3482%\n",
      "Epoch [49/300], Step [182/225], Training Accuracy: 86.3496%, Training Loss: 0.3482%\n",
      "Epoch [49/300], Step [183/225], Training Accuracy: 86.3644%, Training Loss: 0.3482%\n",
      "Epoch [49/300], Step [184/225], Training Accuracy: 86.3791%, Training Loss: 0.3480%\n",
      "Epoch [49/300], Step [185/225], Training Accuracy: 86.3767%, Training Loss: 0.3483%\n",
      "Epoch [49/300], Step [186/225], Training Accuracy: 86.3827%, Training Loss: 0.3478%\n",
      "Epoch [49/300], Step [187/225], Training Accuracy: 86.3803%, Training Loss: 0.3477%\n",
      "Epoch [49/300], Step [188/225], Training Accuracy: 86.3697%, Training Loss: 0.3483%\n",
      "Epoch [49/300], Step [189/225], Training Accuracy: 86.3674%, Training Loss: 0.3483%\n",
      "Epoch [49/300], Step [190/225], Training Accuracy: 86.3734%, Training Loss: 0.3487%\n",
      "Epoch [49/300], Step [191/225], Training Accuracy: 86.3711%, Training Loss: 0.3486%\n",
      "Epoch [49/300], Step [192/225], Training Accuracy: 86.3688%, Training Loss: 0.3486%\n",
      "Epoch [49/300], Step [193/225], Training Accuracy: 86.3585%, Training Loss: 0.3490%\n",
      "Epoch [49/300], Step [194/225], Training Accuracy: 86.3241%, Training Loss: 0.3497%\n",
      "Epoch [49/300], Step [195/225], Training Accuracy: 86.3462%, Training Loss: 0.3490%\n",
      "Epoch [49/300], Step [196/225], Training Accuracy: 86.3520%, Training Loss: 0.3486%\n",
      "Epoch [49/300], Step [197/225], Training Accuracy: 86.3341%, Training Loss: 0.3486%\n",
      "Epoch [49/300], Step [198/225], Training Accuracy: 86.3163%, Training Loss: 0.3492%\n",
      "Epoch [49/300], Step [199/225], Training Accuracy: 86.3144%, Training Loss: 0.3490%\n",
      "Epoch [49/300], Step [200/225], Training Accuracy: 86.3281%, Training Loss: 0.3487%\n",
      "Epoch [49/300], Step [201/225], Training Accuracy: 86.3184%, Training Loss: 0.3488%\n",
      "Epoch [49/300], Step [202/225], Training Accuracy: 86.3552%, Training Loss: 0.3479%\n",
      "Epoch [49/300], Step [203/225], Training Accuracy: 86.3685%, Training Loss: 0.3472%\n",
      "Epoch [49/300], Step [204/225], Training Accuracy: 86.3894%, Training Loss: 0.3467%\n",
      "Epoch [49/300], Step [205/225], Training Accuracy: 86.3796%, Training Loss: 0.3481%\n",
      "Epoch [49/300], Step [206/225], Training Accuracy: 86.3698%, Training Loss: 0.3483%\n",
      "Epoch [49/300], Step [207/225], Training Accuracy: 86.3602%, Training Loss: 0.3486%\n",
      "Epoch [49/300], Step [208/225], Training Accuracy: 86.3732%, Training Loss: 0.3482%\n",
      "Epoch [49/300], Step [209/225], Training Accuracy: 86.3188%, Training Loss: 0.3490%\n",
      "Epoch [49/300], Step [210/225], Training Accuracy: 86.3170%, Training Loss: 0.3490%\n",
      "Epoch [49/300], Step [211/225], Training Accuracy: 86.3152%, Training Loss: 0.3487%\n",
      "Epoch [49/300], Step [212/225], Training Accuracy: 86.3355%, Training Loss: 0.3482%\n",
      "Epoch [49/300], Step [213/225], Training Accuracy: 86.3336%, Training Loss: 0.3490%\n",
      "Epoch [49/300], Step [214/225], Training Accuracy: 86.3464%, Training Loss: 0.3486%\n",
      "Epoch [49/300], Step [215/225], Training Accuracy: 86.3299%, Training Loss: 0.3491%\n",
      "Epoch [49/300], Step [216/225], Training Accuracy: 86.3354%, Training Loss: 0.3494%\n",
      "Epoch [49/300], Step [217/225], Training Accuracy: 86.3623%, Training Loss: 0.3490%\n",
      "Epoch [49/300], Step [218/225], Training Accuracy: 86.3604%, Training Loss: 0.3488%\n",
      "Epoch [49/300], Step [219/225], Training Accuracy: 86.3299%, Training Loss: 0.3489%\n",
      "Epoch [49/300], Step [220/225], Training Accuracy: 86.3281%, Training Loss: 0.3490%\n",
      "Epoch [49/300], Step [221/225], Training Accuracy: 86.3334%, Training Loss: 0.3492%\n",
      "Epoch [49/300], Step [222/225], Training Accuracy: 86.3176%, Training Loss: 0.3491%\n",
      "Epoch [49/300], Step [223/225], Training Accuracy: 86.3159%, Training Loss: 0.3489%\n",
      "Epoch [49/300], Step [224/225], Training Accuracy: 86.3281%, Training Loss: 0.3487%\n",
      "Epoch [49/300], Step [225/225], Training Accuracy: 86.3188%, Training Loss: 0.3489%\n",
      "Epoch [50/300], Step [1/225], Training Accuracy: 87.5000%, Training Loss: 0.2781%\n",
      "Epoch [50/300], Step [2/225], Training Accuracy: 84.3750%, Training Loss: 0.3738%\n",
      "Epoch [50/300], Step [3/225], Training Accuracy: 84.8958%, Training Loss: 0.3637%\n",
      "Epoch [50/300], Step [4/225], Training Accuracy: 84.3750%, Training Loss: 0.3735%\n",
      "Epoch [50/300], Step [5/225], Training Accuracy: 84.0625%, Training Loss: 0.4064%\n",
      "Epoch [50/300], Step [6/225], Training Accuracy: 83.5938%, Training Loss: 0.4032%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/300], Step [7/225], Training Accuracy: 83.9286%, Training Loss: 0.3951%\n",
      "Epoch [50/300], Step [8/225], Training Accuracy: 84.1797%, Training Loss: 0.4001%\n",
      "Epoch [50/300], Step [9/225], Training Accuracy: 83.6806%, Training Loss: 0.4067%\n",
      "Epoch [50/300], Step [10/225], Training Accuracy: 83.9062%, Training Loss: 0.4015%\n",
      "Epoch [50/300], Step [11/225], Training Accuracy: 83.8068%, Training Loss: 0.4110%\n",
      "Epoch [50/300], Step [12/225], Training Accuracy: 83.9844%, Training Loss: 0.3995%\n",
      "Epoch [50/300], Step [13/225], Training Accuracy: 84.9760%, Training Loss: 0.3761%\n",
      "Epoch [50/300], Step [14/225], Training Accuracy: 85.7143%, Training Loss: 0.3613%\n",
      "Epoch [50/300], Step [15/225], Training Accuracy: 86.0417%, Training Loss: 0.3517%\n",
      "Epoch [50/300], Step [16/225], Training Accuracy: 86.0352%, Training Loss: 0.3508%\n",
      "Epoch [50/300], Step [17/225], Training Accuracy: 86.0294%, Training Loss: 0.3488%\n",
      "Epoch [50/300], Step [18/225], Training Accuracy: 86.1979%, Training Loss: 0.3444%\n",
      "Epoch [50/300], Step [19/225], Training Accuracy: 86.1842%, Training Loss: 0.3457%\n",
      "Epoch [50/300], Step [20/225], Training Accuracy: 86.0938%, Training Loss: 0.3470%\n",
      "Epoch [50/300], Step [21/225], Training Accuracy: 86.1607%, Training Loss: 0.3473%\n",
      "Epoch [50/300], Step [22/225], Training Accuracy: 86.3636%, Training Loss: 0.3447%\n",
      "Epoch [50/300], Step [23/225], Training Accuracy: 86.5489%, Training Loss: 0.3417%\n",
      "Epoch [50/300], Step [24/225], Training Accuracy: 86.4583%, Training Loss: 0.3435%\n",
      "Epoch [50/300], Step [25/225], Training Accuracy: 86.6875%, Training Loss: 0.3380%\n",
      "Epoch [50/300], Step [26/225], Training Accuracy: 86.5986%, Training Loss: 0.3382%\n",
      "Epoch [50/300], Step [27/225], Training Accuracy: 86.6319%, Training Loss: 0.3404%\n",
      "Epoch [50/300], Step [28/225], Training Accuracy: 86.8304%, Training Loss: 0.3358%\n",
      "Epoch [50/300], Step [29/225], Training Accuracy: 87.1767%, Training Loss: 0.3298%\n",
      "Epoch [50/300], Step [30/225], Training Accuracy: 87.2396%, Training Loss: 0.3290%\n",
      "Epoch [50/300], Step [31/225], Training Accuracy: 87.2984%, Training Loss: 0.3309%\n",
      "Epoch [50/300], Step [32/225], Training Accuracy: 87.3535%, Training Loss: 0.3292%\n",
      "Epoch [50/300], Step [33/225], Training Accuracy: 87.3106%, Training Loss: 0.3290%\n",
      "Epoch [50/300], Step [34/225], Training Accuracy: 87.1783%, Training Loss: 0.3330%\n",
      "Epoch [50/300], Step [35/225], Training Accuracy: 87.0536%, Training Loss: 0.3333%\n",
      "Epoch [50/300], Step [36/225], Training Accuracy: 87.1528%, Training Loss: 0.3334%\n",
      "Epoch [50/300], Step [37/225], Training Accuracy: 87.2889%, Training Loss: 0.3291%\n",
      "Epoch [50/300], Step [38/225], Training Accuracy: 87.2944%, Training Loss: 0.3286%\n",
      "Epoch [50/300], Step [39/225], Training Accuracy: 87.1795%, Training Loss: 0.3300%\n",
      "Epoch [50/300], Step [40/225], Training Accuracy: 87.1094%, Training Loss: 0.3302%\n",
      "Epoch [50/300], Step [41/225], Training Accuracy: 86.7759%, Training Loss: 0.3358%\n",
      "Epoch [50/300], Step [42/225], Training Accuracy: 86.7560%, Training Loss: 0.3368%\n",
      "Epoch [50/300], Step [43/225], Training Accuracy: 86.7733%, Training Loss: 0.3352%\n",
      "Epoch [50/300], Step [44/225], Training Accuracy: 86.8253%, Training Loss: 0.3332%\n",
      "Epoch [50/300], Step [45/225], Training Accuracy: 86.7708%, Training Loss: 0.3341%\n",
      "Epoch [50/300], Step [46/225], Training Accuracy: 86.6168%, Training Loss: 0.3345%\n",
      "Epoch [50/300], Step [47/225], Training Accuracy: 86.6024%, Training Loss: 0.3381%\n",
      "Epoch [50/300], Step [48/225], Training Accuracy: 86.5885%, Training Loss: 0.3387%\n",
      "Epoch [50/300], Step [49/225], Training Accuracy: 86.5753%, Training Loss: 0.3414%\n",
      "Epoch [50/300], Step [50/225], Training Accuracy: 86.5312%, Training Loss: 0.3424%\n",
      "Epoch [50/300], Step [51/225], Training Accuracy: 86.5196%, Training Loss: 0.3416%\n",
      "Epoch [50/300], Step [52/225], Training Accuracy: 86.5685%, Training Loss: 0.3404%\n",
      "Epoch [50/300], Step [53/225], Training Accuracy: 86.4682%, Training Loss: 0.3437%\n",
      "Epoch [50/300], Step [54/225], Training Accuracy: 86.4583%, Training Loss: 0.3434%\n",
      "Epoch [50/300], Step [55/225], Training Accuracy: 86.5057%, Training Loss: 0.3436%\n",
      "Epoch [50/300], Step [56/225], Training Accuracy: 86.5234%, Training Loss: 0.3415%\n",
      "Epoch [50/300], Step [57/225], Training Accuracy: 86.4035%, Training Loss: 0.3473%\n",
      "Epoch [50/300], Step [58/225], Training Accuracy: 86.4224%, Training Loss: 0.3468%\n",
      "Epoch [50/300], Step [59/225], Training Accuracy: 86.4142%, Training Loss: 0.3467%\n",
      "Epoch [50/300], Step [60/225], Training Accuracy: 86.4844%, Training Loss: 0.3451%\n",
      "Epoch [50/300], Step [61/225], Training Accuracy: 86.5523%, Training Loss: 0.3435%\n",
      "Epoch [50/300], Step [62/225], Training Accuracy: 86.5927%, Training Loss: 0.3420%\n",
      "Epoch [50/300], Step [63/225], Training Accuracy: 86.5823%, Training Loss: 0.3423%\n",
      "Epoch [50/300], Step [64/225], Training Accuracy: 86.5723%, Training Loss: 0.3417%\n",
      "Epoch [50/300], Step [65/225], Training Accuracy: 86.5385%, Training Loss: 0.3433%\n",
      "Epoch [50/300], Step [66/225], Training Accuracy: 86.5767%, Training Loss: 0.3419%\n",
      "Epoch [50/300], Step [67/225], Training Accuracy: 86.4039%, Training Loss: 0.3447%\n",
      "Epoch [50/300], Step [68/225], Training Accuracy: 86.3971%, Training Loss: 0.3454%\n",
      "Epoch [50/300], Step [69/225], Training Accuracy: 86.4130%, Training Loss: 0.3457%\n",
      "Epoch [50/300], Step [70/225], Training Accuracy: 86.4062%, Training Loss: 0.3472%\n",
      "Epoch [50/300], Step [71/225], Training Accuracy: 86.3776%, Training Loss: 0.3464%\n",
      "Epoch [50/300], Step [72/225], Training Accuracy: 86.4583%, Training Loss: 0.3450%\n",
      "Epoch [50/300], Step [73/225], Training Accuracy: 86.5154%, Training Loss: 0.3440%\n",
      "Epoch [50/300], Step [74/225], Training Accuracy: 86.3598%, Training Loss: 0.3469%\n",
      "Epoch [50/300], Step [75/225], Training Accuracy: 86.3333%, Training Loss: 0.3479%\n",
      "Epoch [50/300], Step [76/225], Training Accuracy: 86.3076%, Training Loss: 0.3480%\n",
      "Epoch [50/300], Step [77/225], Training Accuracy: 86.2622%, Training Loss: 0.3470%\n",
      "Epoch [50/300], Step [78/225], Training Accuracy: 86.3381%, Training Loss: 0.3470%\n",
      "Epoch [50/300], Step [79/225], Training Accuracy: 86.1946%, Training Loss: 0.3493%\n",
      "Epoch [50/300], Step [80/225], Training Accuracy: 86.2305%, Training Loss: 0.3487%\n",
      "Epoch [50/300], Step [81/225], Training Accuracy: 86.2076%, Training Loss: 0.3484%\n",
      "Epoch [50/300], Step [82/225], Training Accuracy: 86.2424%, Training Loss: 0.3471%\n",
      "Epoch [50/300], Step [83/225], Training Accuracy: 86.2199%, Training Loss: 0.3473%\n",
      "Epoch [50/300], Step [84/225], Training Accuracy: 86.3281%, Training Loss: 0.3458%\n",
      "Epoch [50/300], Step [85/225], Training Accuracy: 86.3787%, Training Loss: 0.3444%\n",
      "Epoch [50/300], Step [86/225], Training Accuracy: 86.4099%, Training Loss: 0.3438%\n",
      "Epoch [50/300], Step [87/225], Training Accuracy: 86.3865%, Training Loss: 0.3437%\n",
      "Epoch [50/300], Step [88/225], Training Accuracy: 86.2926%, Training Loss: 0.3464%\n",
      "Epoch [50/300], Step [89/225], Training Accuracy: 86.3588%, Training Loss: 0.3449%\n",
      "Epoch [50/300], Step [90/225], Training Accuracy: 86.2847%, Training Loss: 0.3471%\n",
      "Epoch [50/300], Step [91/225], Training Accuracy: 86.2809%, Training Loss: 0.3475%\n",
      "Epoch [50/300], Step [92/225], Training Accuracy: 86.2432%, Training Loss: 0.3486%\n",
      "Epoch [50/300], Step [93/225], Training Accuracy: 86.2399%, Training Loss: 0.3492%\n",
      "Epoch [50/300], Step [94/225], Training Accuracy: 86.2699%, Training Loss: 0.3485%\n",
      "Epoch [50/300], Step [95/225], Training Accuracy: 86.2500%, Training Loss: 0.3494%\n",
      "Epoch [50/300], Step [96/225], Training Accuracy: 86.2630%, Training Loss: 0.3495%\n",
      "Epoch [50/300], Step [97/225], Training Accuracy: 86.2436%, Training Loss: 0.3500%\n",
      "Epoch [50/300], Step [98/225], Training Accuracy: 86.2723%, Training Loss: 0.3497%\n",
      "Epoch [50/300], Step [99/225], Training Accuracy: 86.3163%, Training Loss: 0.3493%\n",
      "Epoch [50/300], Step [100/225], Training Accuracy: 86.2656%, Training Loss: 0.3512%\n",
      "Epoch [50/300], Step [101/225], Training Accuracy: 86.2624%, Training Loss: 0.3509%\n",
      "Epoch [50/300], Step [102/225], Training Accuracy: 86.2286%, Training Loss: 0.3524%\n",
      "Epoch [50/300], Step [103/225], Training Accuracy: 86.1802%, Training Loss: 0.3525%\n",
      "Epoch [50/300], Step [104/225], Training Accuracy: 86.1929%, Training Loss: 0.3521%\n",
      "Epoch [50/300], Step [105/225], Training Accuracy: 86.2202%, Training Loss: 0.3514%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/300], Step [106/225], Training Accuracy: 86.2323%, Training Loss: 0.3512%\n",
      "Epoch [50/300], Step [107/225], Training Accuracy: 86.2880%, Training Loss: 0.3513%\n",
      "Epoch [50/300], Step [108/225], Training Accuracy: 86.2847%, Training Loss: 0.3511%\n",
      "Epoch [50/300], Step [109/225], Training Accuracy: 86.2242%, Training Loss: 0.3517%\n",
      "Epoch [50/300], Step [110/225], Training Accuracy: 86.2358%, Training Loss: 0.3519%\n",
      "Epoch [50/300], Step [111/225], Training Accuracy: 86.2613%, Training Loss: 0.3522%\n",
      "Epoch [50/300], Step [112/225], Training Accuracy: 86.3002%, Training Loss: 0.3514%\n",
      "Epoch [50/300], Step [113/225], Training Accuracy: 86.2970%, Training Loss: 0.3508%\n",
      "Epoch [50/300], Step [114/225], Training Accuracy: 86.3213%, Training Loss: 0.3506%\n",
      "Epoch [50/300], Step [115/225], Training Accuracy: 86.2908%, Training Loss: 0.3501%\n",
      "Epoch [50/300], Step [116/225], Training Accuracy: 86.2204%, Training Loss: 0.3525%\n",
      "Epoch [50/300], Step [117/225], Training Accuracy: 86.1378%, Training Loss: 0.3557%\n",
      "Epoch [50/300], Step [118/225], Training Accuracy: 86.1626%, Training Loss: 0.3554%\n",
      "Epoch [50/300], Step [119/225], Training Accuracy: 86.1607%, Training Loss: 0.3551%\n",
      "Epoch [50/300], Step [120/225], Training Accuracy: 86.1458%, Training Loss: 0.3548%\n",
      "Epoch [50/300], Step [121/225], Training Accuracy: 86.1829%, Training Loss: 0.3538%\n",
      "Epoch [50/300], Step [122/225], Training Accuracy: 86.2065%, Training Loss: 0.3533%\n",
      "Epoch [50/300], Step [123/225], Training Accuracy: 86.2424%, Training Loss: 0.3525%\n",
      "Epoch [50/300], Step [124/225], Training Accuracy: 86.2777%, Training Loss: 0.3523%\n",
      "Epoch [50/300], Step [125/225], Training Accuracy: 86.2125%, Training Loss: 0.3529%\n",
      "Epoch [50/300], Step [126/225], Training Accuracy: 86.1731%, Training Loss: 0.3536%\n",
      "Epoch [50/300], Step [127/225], Training Accuracy: 86.1836%, Training Loss: 0.3533%\n",
      "Epoch [50/300], Step [128/225], Training Accuracy: 86.1694%, Training Loss: 0.3536%\n",
      "Epoch [50/300], Step [129/225], Training Accuracy: 86.1313%, Training Loss: 0.3542%\n",
      "Epoch [50/300], Step [130/225], Training Accuracy: 86.1418%, Training Loss: 0.3544%\n",
      "Epoch [50/300], Step [131/225], Training Accuracy: 86.1045%, Training Loss: 0.3551%\n",
      "Epoch [50/300], Step [132/225], Training Accuracy: 86.1269%, Training Loss: 0.3550%\n",
      "Epoch [50/300], Step [133/225], Training Accuracy: 86.1725%, Training Loss: 0.3538%\n",
      "Epoch [50/300], Step [134/225], Training Accuracy: 86.1357%, Training Loss: 0.3550%\n",
      "Epoch [50/300], Step [135/225], Training Accuracy: 86.1574%, Training Loss: 0.3543%\n",
      "Epoch [50/300], Step [136/225], Training Accuracy: 86.1213%, Training Loss: 0.3545%\n",
      "Epoch [50/300], Step [137/225], Training Accuracy: 86.1770%, Training Loss: 0.3534%\n",
      "Epoch [50/300], Step [138/225], Training Accuracy: 86.1979%, Training Loss: 0.3528%\n",
      "Epoch [50/300], Step [139/225], Training Accuracy: 86.1848%, Training Loss: 0.3533%\n",
      "Epoch [50/300], Step [140/225], Training Accuracy: 86.1607%, Training Loss: 0.3536%\n",
      "Epoch [50/300], Step [141/225], Training Accuracy: 86.1591%, Training Loss: 0.3533%\n",
      "Epoch [50/300], Step [142/225], Training Accuracy: 86.1576%, Training Loss: 0.3529%\n",
      "Epoch [50/300], Step [143/225], Training Accuracy: 86.1451%, Training Loss: 0.3531%\n",
      "Epoch [50/300], Step [144/225], Training Accuracy: 86.1654%, Training Loss: 0.3527%\n",
      "Epoch [50/300], Step [145/225], Training Accuracy: 86.1315%, Training Loss: 0.3545%\n",
      "Epoch [50/300], Step [146/225], Training Accuracy: 86.1194%, Training Loss: 0.3544%\n",
      "Epoch [50/300], Step [147/225], Training Accuracy: 86.1607%, Training Loss: 0.3534%\n",
      "Epoch [50/300], Step [148/225], Training Accuracy: 86.1803%, Training Loss: 0.3535%\n",
      "Epoch [50/300], Step [149/225], Training Accuracy: 86.1787%, Training Loss: 0.3532%\n",
      "Epoch [50/300], Step [150/225], Training Accuracy: 86.2188%, Training Loss: 0.3522%\n",
      "Epoch [50/300], Step [151/225], Training Accuracy: 86.2479%, Training Loss: 0.3522%\n",
      "Epoch [50/300], Step [152/225], Training Accuracy: 86.2356%, Training Loss: 0.3519%\n",
      "Epoch [50/300], Step [153/225], Training Accuracy: 86.2337%, Training Loss: 0.3514%\n",
      "Epoch [50/300], Step [154/225], Training Accuracy: 86.2317%, Training Loss: 0.3509%\n",
      "Epoch [50/300], Step [155/225], Training Accuracy: 86.2500%, Training Loss: 0.3506%\n",
      "Epoch [50/300], Step [156/225], Training Accuracy: 86.2480%, Training Loss: 0.3511%\n",
      "Epoch [50/300], Step [157/225], Training Accuracy: 86.2460%, Training Loss: 0.3505%\n",
      "Epoch [50/300], Step [158/225], Training Accuracy: 86.2243%, Training Loss: 0.3507%\n",
      "Epoch [50/300], Step [159/225], Training Accuracy: 86.1537%, Training Loss: 0.3515%\n",
      "Epoch [50/300], Step [160/225], Training Accuracy: 86.1719%, Training Loss: 0.3513%\n",
      "Epoch [50/300], Step [161/225], Training Accuracy: 86.1316%, Training Loss: 0.3526%\n",
      "Epoch [50/300], Step [162/225], Training Accuracy: 86.0918%, Training Loss: 0.3532%\n",
      "Epoch [50/300], Step [163/225], Training Accuracy: 86.1005%, Training Loss: 0.3529%\n",
      "Epoch [50/300], Step [164/225], Training Accuracy: 86.1185%, Training Loss: 0.3523%\n",
      "Epoch [50/300], Step [165/225], Training Accuracy: 86.1269%, Training Loss: 0.3523%\n",
      "Epoch [50/300], Step [166/225], Training Accuracy: 86.1069%, Training Loss: 0.3528%\n",
      "Epoch [50/300], Step [167/225], Training Accuracy: 86.1340%, Training Loss: 0.3521%\n",
      "Epoch [50/300], Step [168/225], Training Accuracy: 86.1142%, Training Loss: 0.3533%\n",
      "Epoch [50/300], Step [169/225], Training Accuracy: 86.1594%, Training Loss: 0.3522%\n",
      "Epoch [50/300], Step [170/225], Training Accuracy: 86.1397%, Training Loss: 0.3532%\n",
      "Epoch [50/300], Step [171/225], Training Accuracy: 86.1294%, Training Loss: 0.3535%\n",
      "Epoch [50/300], Step [172/225], Training Accuracy: 86.1374%, Training Loss: 0.3533%\n",
      "Epoch [50/300], Step [173/225], Training Accuracy: 86.1362%, Training Loss: 0.3534%\n",
      "Epoch [50/300], Step [174/225], Training Accuracy: 86.1530%, Training Loss: 0.3532%\n",
      "Epoch [50/300], Step [175/225], Training Accuracy: 86.1607%, Training Loss: 0.3526%\n",
      "Epoch [50/300], Step [176/225], Training Accuracy: 86.1772%, Training Loss: 0.3521%\n",
      "Epoch [50/300], Step [177/225], Training Accuracy: 86.1935%, Training Loss: 0.3513%\n",
      "Epoch [50/300], Step [178/225], Training Accuracy: 86.1921%, Training Loss: 0.3509%\n",
      "Epoch [50/300], Step [179/225], Training Accuracy: 86.1819%, Training Loss: 0.3505%\n",
      "Epoch [50/300], Step [180/225], Training Accuracy: 86.2153%, Training Loss: 0.3496%\n",
      "Epoch [50/300], Step [181/225], Training Accuracy: 86.2310%, Training Loss: 0.3494%\n",
      "Epoch [50/300], Step [182/225], Training Accuracy: 86.2466%, Training Loss: 0.3488%\n",
      "Epoch [50/300], Step [183/225], Training Accuracy: 86.2790%, Training Loss: 0.3485%\n",
      "Epoch [50/300], Step [184/225], Training Accuracy: 86.2942%, Training Loss: 0.3483%\n",
      "Epoch [50/300], Step [185/225], Training Accuracy: 86.3176%, Training Loss: 0.3482%\n",
      "Epoch [50/300], Step [186/225], Training Accuracy: 86.2987%, Training Loss: 0.3481%\n",
      "Epoch [50/300], Step [187/225], Training Accuracy: 86.2884%, Training Loss: 0.3481%\n",
      "Epoch [50/300], Step [188/225], Training Accuracy: 86.3032%, Training Loss: 0.3478%\n",
      "Epoch [50/300], Step [189/225], Training Accuracy: 86.3509%, Training Loss: 0.3469%\n",
      "Epoch [50/300], Step [190/225], Training Accuracy: 86.3569%, Training Loss: 0.3467%\n",
      "Epoch [50/300], Step [191/225], Training Accuracy: 86.3711%, Training Loss: 0.3466%\n",
      "Epoch [50/300], Step [192/225], Training Accuracy: 86.3607%, Training Loss: 0.3470%\n",
      "Epoch [50/300], Step [193/225], Training Accuracy: 86.3342%, Training Loss: 0.3478%\n",
      "Epoch [50/300], Step [194/225], Training Accuracy: 86.3241%, Training Loss: 0.3482%\n",
      "Epoch [50/300], Step [195/225], Training Accuracy: 86.3381%, Training Loss: 0.3476%\n",
      "Epoch [50/300], Step [196/225], Training Accuracy: 86.3520%, Training Loss: 0.3472%\n",
      "Epoch [50/300], Step [197/225], Training Accuracy: 86.3499%, Training Loss: 0.3467%\n",
      "Epoch [50/300], Step [198/225], Training Accuracy: 86.3321%, Training Loss: 0.3463%\n",
      "Epoch [50/300], Step [199/225], Training Accuracy: 86.2594%, Training Loss: 0.3475%\n",
      "Epoch [50/300], Step [200/225], Training Accuracy: 86.2891%, Training Loss: 0.3469%\n",
      "Epoch [50/300], Step [201/225], Training Accuracy: 86.2718%, Training Loss: 0.3472%\n",
      "Epoch [50/300], Step [202/225], Training Accuracy: 86.2624%, Training Loss: 0.3473%\n",
      "Epoch [50/300], Step [203/225], Training Accuracy: 86.3070%, Training Loss: 0.3467%\n",
      "Epoch [50/300], Step [204/225], Training Accuracy: 86.3128%, Training Loss: 0.3466%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/300], Step [205/225], Training Accuracy: 86.2881%, Training Loss: 0.3467%\n",
      "Epoch [50/300], Step [206/225], Training Accuracy: 86.2940%, Training Loss: 0.3467%\n",
      "Epoch [50/300], Step [207/225], Training Accuracy: 86.2621%, Training Loss: 0.3474%\n",
      "Epoch [50/300], Step [208/225], Training Accuracy: 86.2605%, Training Loss: 0.3475%\n",
      "Epoch [50/300], Step [209/225], Training Accuracy: 86.2515%, Training Loss: 0.3476%\n",
      "Epoch [50/300], Step [210/225], Training Accuracy: 86.2574%, Training Loss: 0.3471%\n",
      "Epoch [50/300], Step [211/225], Training Accuracy: 86.2633%, Training Loss: 0.3471%\n",
      "Epoch [50/300], Step [212/225], Training Accuracy: 86.2544%, Training Loss: 0.3470%\n",
      "Epoch [50/300], Step [213/225], Training Accuracy: 86.2823%, Training Loss: 0.3465%\n",
      "Epoch [50/300], Step [214/225], Training Accuracy: 86.2953%, Training Loss: 0.3462%\n",
      "Epoch [50/300], Step [215/225], Training Accuracy: 86.2791%, Training Loss: 0.3461%\n",
      "Epoch [50/300], Step [216/225], Training Accuracy: 86.2775%, Training Loss: 0.3465%\n",
      "Epoch [50/300], Step [217/225], Training Accuracy: 86.2831%, Training Loss: 0.3463%\n",
      "Epoch [50/300], Step [218/225], Training Accuracy: 86.2529%, Training Loss: 0.3468%\n",
      "Epoch [50/300], Step [219/225], Training Accuracy: 86.2657%, Training Loss: 0.3463%\n",
      "Epoch [50/300], Step [220/225], Training Accuracy: 86.2713%, Training Loss: 0.3462%\n",
      "Epoch [50/300], Step [221/225], Training Accuracy: 86.2981%, Training Loss: 0.3455%\n",
      "Epoch [50/300], Step [222/225], Training Accuracy: 86.3035%, Training Loss: 0.3453%\n",
      "Epoch [50/300], Step [223/225], Training Accuracy: 86.3229%, Training Loss: 0.3453%\n",
      "Epoch [50/300], Step [224/225], Training Accuracy: 86.3491%, Training Loss: 0.3448%\n",
      "Epoch [50/300], Step [225/225], Training Accuracy: 86.3257%, Training Loss: 0.3453%\n",
      "Epoch [51/300], Step [1/225], Training Accuracy: 84.3750%, Training Loss: 0.2758%\n",
      "Epoch [51/300], Step [2/225], Training Accuracy: 85.9375%, Training Loss: 0.3566%\n",
      "Epoch [51/300], Step [3/225], Training Accuracy: 84.8958%, Training Loss: 0.3878%\n",
      "Epoch [51/300], Step [4/225], Training Accuracy: 85.1562%, Training Loss: 0.3675%\n",
      "Epoch [51/300], Step [5/225], Training Accuracy: 85.3125%, Training Loss: 0.3496%\n",
      "Epoch [51/300], Step [6/225], Training Accuracy: 85.6771%, Training Loss: 0.3394%\n",
      "Epoch [51/300], Step [7/225], Training Accuracy: 85.9375%, Training Loss: 0.3348%\n",
      "Epoch [51/300], Step [8/225], Training Accuracy: 86.3281%, Training Loss: 0.3265%\n",
      "Epoch [51/300], Step [9/225], Training Accuracy: 86.4583%, Training Loss: 0.3266%\n",
      "Epoch [51/300], Step [10/225], Training Accuracy: 85.9375%, Training Loss: 0.3324%\n",
      "Epoch [51/300], Step [11/225], Training Accuracy: 85.6534%, Training Loss: 0.3373%\n",
      "Epoch [51/300], Step [12/225], Training Accuracy: 86.1979%, Training Loss: 0.3298%\n",
      "Epoch [51/300], Step [13/225], Training Accuracy: 87.0192%, Training Loss: 0.3125%\n",
      "Epoch [51/300], Step [14/225], Training Accuracy: 86.6071%, Training Loss: 0.3211%\n",
      "Epoch [51/300], Step [15/225], Training Accuracy: 86.4583%, Training Loss: 0.3297%\n",
      "Epoch [51/300], Step [16/225], Training Accuracy: 86.1328%, Training Loss: 0.3392%\n",
      "Epoch [51/300], Step [17/225], Training Accuracy: 86.1213%, Training Loss: 0.3360%\n",
      "Epoch [51/300], Step [18/225], Training Accuracy: 85.8507%, Training Loss: 0.3399%\n",
      "Epoch [51/300], Step [19/225], Training Accuracy: 86.2664%, Training Loss: 0.3319%\n",
      "Epoch [51/300], Step [20/225], Training Accuracy: 86.4062%, Training Loss: 0.3323%\n",
      "Epoch [51/300], Step [21/225], Training Accuracy: 86.3839%, Training Loss: 0.3317%\n",
      "Epoch [51/300], Step [22/225], Training Accuracy: 86.0085%, Training Loss: 0.3413%\n",
      "Epoch [51/300], Step [23/225], Training Accuracy: 85.9375%, Training Loss: 0.3431%\n",
      "Epoch [51/300], Step [24/225], Training Accuracy: 85.7422%, Training Loss: 0.3498%\n",
      "Epoch [51/300], Step [25/225], Training Accuracy: 86.0625%, Training Loss: 0.3425%\n",
      "Epoch [51/300], Step [26/225], Training Accuracy: 86.2380%, Training Loss: 0.3385%\n",
      "Epoch [51/300], Step [27/225], Training Accuracy: 86.3426%, Training Loss: 0.3372%\n",
      "Epoch [51/300], Step [28/225], Training Accuracy: 86.6629%, Training Loss: 0.3299%\n",
      "Epoch [51/300], Step [29/225], Training Accuracy: 86.2608%, Training Loss: 0.3377%\n",
      "Epoch [51/300], Step [30/225], Training Accuracy: 86.6146%, Training Loss: 0.3339%\n",
      "Epoch [51/300], Step [31/225], Training Accuracy: 86.4415%, Training Loss: 0.3367%\n",
      "Epoch [51/300], Step [32/225], Training Accuracy: 86.5723%, Training Loss: 0.3329%\n",
      "Epoch [51/300], Step [33/225], Training Accuracy: 86.6477%, Training Loss: 0.3313%\n",
      "Epoch [51/300], Step [34/225], Training Accuracy: 86.5349%, Training Loss: 0.3318%\n",
      "Epoch [51/300], Step [35/225], Training Accuracy: 86.4732%, Training Loss: 0.3300%\n",
      "Epoch [51/300], Step [36/225], Training Accuracy: 86.5885%, Training Loss: 0.3267%\n",
      "Epoch [51/300], Step [37/225], Training Accuracy: 86.5709%, Training Loss: 0.3254%\n",
      "Epoch [51/300], Step [38/225], Training Accuracy: 86.6365%, Training Loss: 0.3231%\n",
      "Epoch [51/300], Step [39/225], Training Accuracy: 86.6987%, Training Loss: 0.3232%\n",
      "Epoch [51/300], Step [40/225], Training Accuracy: 86.7188%, Training Loss: 0.3259%\n",
      "Epoch [51/300], Step [41/225], Training Accuracy: 86.6616%, Training Loss: 0.3285%\n",
      "Epoch [51/300], Step [42/225], Training Accuracy: 86.5327%, Training Loss: 0.3312%\n",
      "Epoch [51/300], Step [43/225], Training Accuracy: 86.5552%, Training Loss: 0.3309%\n",
      "Epoch [51/300], Step [44/225], Training Accuracy: 86.6122%, Training Loss: 0.3294%\n",
      "Epoch [51/300], Step [45/225], Training Accuracy: 86.7014%, Training Loss: 0.3269%\n",
      "Epoch [51/300], Step [46/225], Training Accuracy: 86.8207%, Training Loss: 0.3255%\n",
      "Epoch [51/300], Step [47/225], Training Accuracy: 86.8351%, Training Loss: 0.3253%\n",
      "Epoch [51/300], Step [48/225], Training Accuracy: 86.8164%, Training Loss: 0.3269%\n",
      "Epoch [51/300], Step [49/225], Training Accuracy: 86.8304%, Training Loss: 0.3258%\n",
      "Epoch [51/300], Step [50/225], Training Accuracy: 86.7188%, Training Loss: 0.3292%\n",
      "Epoch [51/300], Step [51/225], Training Accuracy: 86.7034%, Training Loss: 0.3282%\n",
      "Epoch [51/300], Step [52/225], Training Accuracy: 86.8389%, Training Loss: 0.3260%\n",
      "Epoch [51/300], Step [53/225], Training Accuracy: 86.9693%, Training Loss: 0.3233%\n",
      "Epoch [51/300], Step [54/225], Training Accuracy: 87.0370%, Training Loss: 0.3216%\n",
      "Epoch [51/300], Step [55/225], Training Accuracy: 87.0455%, Training Loss: 0.3215%\n",
      "Epoch [51/300], Step [56/225], Training Accuracy: 87.1931%, Training Loss: 0.3199%\n",
      "Epoch [51/300], Step [57/225], Training Accuracy: 87.1162%, Training Loss: 0.3199%\n",
      "Epoch [51/300], Step [58/225], Training Accuracy: 87.0959%, Training Loss: 0.3215%\n",
      "Epoch [51/300], Step [59/225], Training Accuracy: 87.1557%, Training Loss: 0.3204%\n",
      "Epoch [51/300], Step [60/225], Training Accuracy: 87.2135%, Training Loss: 0.3195%\n",
      "Epoch [51/300], Step [61/225], Training Accuracy: 87.1926%, Training Loss: 0.3202%\n",
      "Epoch [51/300], Step [62/225], Training Accuracy: 87.1724%, Training Loss: 0.3195%\n",
      "Epoch [51/300], Step [63/225], Training Accuracy: 87.1280%, Training Loss: 0.3188%\n",
      "Epoch [51/300], Step [64/225], Training Accuracy: 87.2070%, Training Loss: 0.3168%\n",
      "Epoch [51/300], Step [65/225], Training Accuracy: 87.2596%, Training Loss: 0.3158%\n",
      "Epoch [51/300], Step [66/225], Training Accuracy: 87.3343%, Training Loss: 0.3145%\n",
      "Epoch [51/300], Step [67/225], Training Accuracy: 87.4067%, Training Loss: 0.3129%\n",
      "Epoch [51/300], Step [68/225], Training Accuracy: 87.3621%, Training Loss: 0.3125%\n",
      "Epoch [51/300], Step [69/225], Training Accuracy: 87.4094%, Training Loss: 0.3115%\n",
      "Epoch [51/300], Step [70/225], Training Accuracy: 87.4330%, Training Loss: 0.3101%\n",
      "Epoch [51/300], Step [71/225], Training Accuracy: 87.4780%, Training Loss: 0.3084%\n",
      "Epoch [51/300], Step [72/225], Training Accuracy: 87.4566%, Training Loss: 0.3080%\n",
      "Epoch [51/300], Step [73/225], Training Accuracy: 87.4572%, Training Loss: 0.3077%\n",
      "Epoch [51/300], Step [74/225], Training Accuracy: 87.5211%, Training Loss: 0.3071%\n",
      "Epoch [51/300], Step [75/225], Training Accuracy: 87.6042%, Training Loss: 0.3058%\n",
      "Epoch [51/300], Step [76/225], Training Accuracy: 87.6645%, Training Loss: 0.3055%\n",
      "Epoch [51/300], Step [77/225], Training Accuracy: 87.7029%, Training Loss: 0.3044%\n",
      "Epoch [51/300], Step [78/225], Training Accuracy: 87.7204%, Training Loss: 0.3040%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/300], Step [79/225], Training Accuracy: 87.7769%, Training Loss: 0.3032%\n",
      "Epoch [51/300], Step [80/225], Training Accuracy: 87.7734%, Training Loss: 0.3032%\n",
      "Epoch [51/300], Step [81/225], Training Accuracy: 87.8086%, Training Loss: 0.3025%\n",
      "Epoch [51/300], Step [82/225], Training Accuracy: 87.8811%, Training Loss: 0.3011%\n",
      "Epoch [51/300], Step [83/225], Training Accuracy: 87.9330%, Training Loss: 0.3001%\n",
      "Epoch [51/300], Step [84/225], Training Accuracy: 87.9278%, Training Loss: 0.3003%\n",
      "Epoch [51/300], Step [85/225], Training Accuracy: 87.9596%, Training Loss: 0.2991%\n",
      "Epoch [51/300], Step [86/225], Training Accuracy: 88.0087%, Training Loss: 0.2981%\n",
      "Epoch [51/300], Step [87/225], Training Accuracy: 87.9310%, Training Loss: 0.2995%\n",
      "Epoch [51/300], Step [88/225], Training Accuracy: 87.8906%, Training Loss: 0.3000%\n",
      "Epoch [51/300], Step [89/225], Training Accuracy: 87.9213%, Training Loss: 0.2993%\n",
      "Epoch [51/300], Step [90/225], Training Accuracy: 87.8299%, Training Loss: 0.3010%\n",
      "Epoch [51/300], Step [91/225], Training Accuracy: 87.8434%, Training Loss: 0.3008%\n",
      "Epoch [51/300], Step [92/225], Training Accuracy: 87.8057%, Training Loss: 0.3009%\n",
      "Epoch [51/300], Step [93/225], Training Accuracy: 87.8696%, Training Loss: 0.2994%\n",
      "Epoch [51/300], Step [94/225], Training Accuracy: 87.8823%, Training Loss: 0.2988%\n",
      "Epoch [51/300], Step [95/225], Training Accuracy: 87.9112%, Training Loss: 0.2977%\n",
      "Epoch [51/300], Step [96/225], Training Accuracy: 87.9883%, Training Loss: 0.2960%\n",
      "Epoch [51/300], Step [97/225], Training Accuracy: 87.9349%, Training Loss: 0.2962%\n",
      "Epoch [51/300], Step [98/225], Training Accuracy: 87.9464%, Training Loss: 0.2953%\n",
      "Epoch [51/300], Step [99/225], Training Accuracy: 87.9104%, Training Loss: 0.2960%\n",
      "Epoch [51/300], Step [100/225], Training Accuracy: 87.9062%, Training Loss: 0.2959%\n",
      "Epoch [51/300], Step [101/225], Training Accuracy: 87.9332%, Training Loss: 0.2954%\n",
      "Epoch [51/300], Step [102/225], Training Accuracy: 87.9442%, Training Loss: 0.2955%\n",
      "Epoch [51/300], Step [103/225], Training Accuracy: 88.0158%, Training Loss: 0.2947%\n",
      "Epoch [51/300], Step [104/225], Training Accuracy: 88.0258%, Training Loss: 0.2943%\n",
      "Epoch [51/300], Step [105/225], Training Accuracy: 88.0208%, Training Loss: 0.2949%\n",
      "Epoch [51/300], Step [106/225], Training Accuracy: 88.0896%, Training Loss: 0.2934%\n",
      "Epoch [51/300], Step [107/225], Training Accuracy: 88.0841%, Training Loss: 0.2936%\n",
      "Epoch [51/300], Step [108/225], Training Accuracy: 88.1510%, Training Loss: 0.2926%\n",
      "Epoch [51/300], Step [109/225], Training Accuracy: 88.1737%, Training Loss: 0.2919%\n",
      "Epoch [51/300], Step [110/225], Training Accuracy: 88.1818%, Training Loss: 0.2918%\n",
      "Epoch [51/300], Step [111/225], Training Accuracy: 88.2038%, Training Loss: 0.2907%\n",
      "Epoch [51/300], Step [112/225], Training Accuracy: 88.1975%, Training Loss: 0.2907%\n",
      "Epoch [51/300], Step [113/225], Training Accuracy: 88.2605%, Training Loss: 0.2894%\n",
      "Epoch [51/300], Step [114/225], Training Accuracy: 88.2264%, Training Loss: 0.2896%\n",
      "Epoch [51/300], Step [115/225], Training Accuracy: 88.2065%, Training Loss: 0.2893%\n",
      "Epoch [51/300], Step [116/225], Training Accuracy: 88.2408%, Training Loss: 0.2885%\n",
      "Epoch [51/300], Step [117/225], Training Accuracy: 88.3146%, Training Loss: 0.2874%\n",
      "Epoch [51/300], Step [118/225], Training Accuracy: 88.2945%, Training Loss: 0.2881%\n",
      "Epoch [51/300], Step [119/225], Training Accuracy: 88.2878%, Training Loss: 0.2878%\n",
      "Epoch [51/300], Step [120/225], Training Accuracy: 88.3073%, Training Loss: 0.2876%\n",
      "Epoch [51/300], Step [121/225], Training Accuracy: 88.3394%, Training Loss: 0.2869%\n",
      "Epoch [51/300], Step [122/225], Training Accuracy: 88.3453%, Training Loss: 0.2873%\n",
      "Epoch [51/300], Step [123/225], Training Accuracy: 88.3892%, Training Loss: 0.2867%\n",
      "Epoch [51/300], Step [124/225], Training Accuracy: 88.4199%, Training Loss: 0.2859%\n",
      "Epoch [51/300], Step [125/225], Training Accuracy: 88.4250%, Training Loss: 0.2856%\n",
      "Epoch [51/300], Step [126/225], Training Accuracy: 88.4549%, Training Loss: 0.2855%\n",
      "Epoch [51/300], Step [127/225], Training Accuracy: 88.4719%, Training Loss: 0.2851%\n",
      "Epoch [51/300], Step [128/225], Training Accuracy: 88.4399%, Training Loss: 0.2854%\n",
      "Epoch [51/300], Step [129/225], Training Accuracy: 88.4327%, Training Loss: 0.2854%\n",
      "Epoch [51/300], Step [130/225], Training Accuracy: 88.4495%, Training Loss: 0.2852%\n",
      "Epoch [51/300], Step [131/225], Training Accuracy: 88.4303%, Training Loss: 0.2858%\n",
      "Epoch [51/300], Step [132/225], Training Accuracy: 88.4351%, Training Loss: 0.2855%\n",
      "Epoch [51/300], Step [133/225], Training Accuracy: 88.4751%, Training Loss: 0.2848%\n",
      "Epoch [51/300], Step [134/225], Training Accuracy: 88.4328%, Training Loss: 0.2855%\n",
      "Epoch [51/300], Step [135/225], Training Accuracy: 88.4722%, Training Loss: 0.2847%\n",
      "Epoch [51/300], Step [136/225], Training Accuracy: 88.4421%, Training Loss: 0.2854%\n",
      "Epoch [51/300], Step [137/225], Training Accuracy: 88.4694%, Training Loss: 0.2846%\n",
      "Epoch [51/300], Step [138/225], Training Accuracy: 88.4737%, Training Loss: 0.2842%\n",
      "Epoch [51/300], Step [139/225], Training Accuracy: 88.5454%, Training Loss: 0.2833%\n",
      "Epoch [51/300], Step [140/225], Training Accuracy: 88.5379%, Training Loss: 0.2837%\n",
      "Epoch [51/300], Step [141/225], Training Accuracy: 88.5195%, Training Loss: 0.2838%\n",
      "Epoch [51/300], Step [142/225], Training Accuracy: 88.5453%, Training Loss: 0.2843%\n",
      "Epoch [51/300], Step [143/225], Training Accuracy: 88.5817%, Training Loss: 0.2845%\n",
      "Epoch [51/300], Step [144/225], Training Accuracy: 88.6176%, Training Loss: 0.2839%\n",
      "Epoch [51/300], Step [145/225], Training Accuracy: 88.6315%, Training Loss: 0.2837%\n",
      "Epoch [51/300], Step [146/225], Training Accuracy: 88.6772%, Training Loss: 0.2827%\n",
      "Epoch [51/300], Step [147/225], Training Accuracy: 88.7011%, Training Loss: 0.2818%\n",
      "Epoch [51/300], Step [148/225], Training Accuracy: 88.7458%, Training Loss: 0.2808%\n",
      "Epoch [51/300], Step [149/225], Training Accuracy: 88.7269%, Training Loss: 0.2804%\n",
      "Epoch [51/300], Step [150/225], Training Accuracy: 88.7500%, Training Loss: 0.2802%\n",
      "Epoch [51/300], Step [151/225], Training Accuracy: 88.7935%, Training Loss: 0.2792%\n",
      "Epoch [51/300], Step [152/225], Training Accuracy: 88.8363%, Training Loss: 0.2782%\n",
      "Epoch [51/300], Step [153/225], Training Accuracy: 88.8174%, Training Loss: 0.2782%\n",
      "Epoch [51/300], Step [154/225], Training Accuracy: 88.8494%, Training Loss: 0.2776%\n",
      "Epoch [51/300], Step [155/225], Training Accuracy: 88.8105%, Training Loss: 0.2785%\n",
      "Epoch [51/300], Step [156/225], Training Accuracy: 88.8321%, Training Loss: 0.2781%\n",
      "Epoch [51/300], Step [157/225], Training Accuracy: 88.8436%, Training Loss: 0.2780%\n",
      "Epoch [51/300], Step [158/225], Training Accuracy: 88.8845%, Training Loss: 0.2774%\n",
      "Epoch [51/300], Step [159/225], Training Accuracy: 88.8954%, Training Loss: 0.2772%\n",
      "Epoch [51/300], Step [160/225], Training Accuracy: 88.9258%, Training Loss: 0.2763%\n",
      "Epoch [51/300], Step [161/225], Training Accuracy: 88.9363%, Training Loss: 0.2765%\n",
      "Epoch [51/300], Step [162/225], Training Accuracy: 88.9178%, Training Loss: 0.2766%\n",
      "Epoch [51/300], Step [163/225], Training Accuracy: 88.9283%, Training Loss: 0.2762%\n",
      "Epoch [51/300], Step [164/225], Training Accuracy: 88.9863%, Training Loss: 0.2752%\n",
      "Epoch [51/300], Step [165/225], Training Accuracy: 89.0057%, Training Loss: 0.2747%\n",
      "Epoch [51/300], Step [166/225], Training Accuracy: 88.9966%, Training Loss: 0.2749%\n",
      "Epoch [51/300], Step [167/225], Training Accuracy: 89.0064%, Training Loss: 0.2745%\n",
      "Epoch [51/300], Step [168/225], Training Accuracy: 88.9602%, Training Loss: 0.2750%\n",
      "Epoch [51/300], Step [169/225], Training Accuracy: 88.9793%, Training Loss: 0.2743%\n",
      "Epoch [51/300], Step [170/225], Training Accuracy: 88.9798%, Training Loss: 0.2744%\n",
      "Epoch [51/300], Step [171/225], Training Accuracy: 88.9894%, Training Loss: 0.2742%\n",
      "Epoch [51/300], Step [172/225], Training Accuracy: 88.9989%, Training Loss: 0.2738%\n",
      "Epoch [51/300], Step [173/225], Training Accuracy: 89.0444%, Training Loss: 0.2735%\n",
      "Epoch [51/300], Step [174/225], Training Accuracy: 89.0805%, Training Loss: 0.2730%\n",
      "Epoch [51/300], Step [175/225], Training Accuracy: 89.0893%, Training Loss: 0.2727%\n",
      "Epoch [51/300], Step [176/225], Training Accuracy: 89.0980%, Training Loss: 0.2723%\n",
      "Epoch [51/300], Step [177/225], Training Accuracy: 89.1331%, Training Loss: 0.2716%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/300], Step [178/225], Training Accuracy: 89.1591%, Training Loss: 0.2712%\n",
      "Epoch [51/300], Step [179/225], Training Accuracy: 89.1760%, Training Loss: 0.2706%\n",
      "Epoch [51/300], Step [180/225], Training Accuracy: 89.2014%, Training Loss: 0.2702%\n",
      "Epoch [51/300], Step [181/225], Training Accuracy: 89.1920%, Training Loss: 0.2702%\n",
      "Epoch [51/300], Step [182/225], Training Accuracy: 89.2170%, Training Loss: 0.2702%\n",
      "Epoch [51/300], Step [183/225], Training Accuracy: 89.2333%, Training Loss: 0.2699%\n",
      "Epoch [51/300], Step [184/225], Training Accuracy: 89.2323%, Training Loss: 0.2698%\n",
      "Epoch [51/300], Step [185/225], Training Accuracy: 89.2821%, Training Loss: 0.2687%\n",
      "Epoch [51/300], Step [186/225], Training Accuracy: 89.3313%, Training Loss: 0.2677%\n",
      "Epoch [51/300], Step [187/225], Training Accuracy: 89.3717%, Training Loss: 0.2668%\n",
      "Epoch [51/300], Step [188/225], Training Accuracy: 89.3949%, Training Loss: 0.2665%\n",
      "Epoch [51/300], Step [189/225], Training Accuracy: 89.3932%, Training Loss: 0.2668%\n",
      "Epoch [51/300], Step [190/225], Training Accuracy: 89.3914%, Training Loss: 0.2666%\n",
      "Epoch [51/300], Step [191/225], Training Accuracy: 89.3815%, Training Loss: 0.2671%\n",
      "Epoch [51/300], Step [192/225], Training Accuracy: 89.4043%, Training Loss: 0.2664%\n",
      "Epoch [51/300], Step [193/225], Training Accuracy: 89.3782%, Training Loss: 0.2670%\n",
      "Epoch [51/300], Step [194/225], Training Accuracy: 89.4008%, Training Loss: 0.2664%\n",
      "Epoch [51/300], Step [195/225], Training Accuracy: 89.4471%, Training Loss: 0.2657%\n",
      "Epoch [51/300], Step [196/225], Training Accuracy: 89.4691%, Training Loss: 0.2652%\n",
      "Epoch [51/300], Step [197/225], Training Accuracy: 89.4591%, Training Loss: 0.2651%\n",
      "Epoch [51/300], Step [198/225], Training Accuracy: 89.5044%, Training Loss: 0.2643%\n",
      "Epoch [51/300], Step [199/225], Training Accuracy: 89.5258%, Training Loss: 0.2640%\n",
      "Epoch [51/300], Step [200/225], Training Accuracy: 89.5547%, Training Loss: 0.2634%\n",
      "Epoch [51/300], Step [201/225], Training Accuracy: 89.5289%, Training Loss: 0.2641%\n",
      "Epoch [51/300], Step [202/225], Training Accuracy: 89.5575%, Training Loss: 0.2637%\n",
      "Epoch [51/300], Step [203/225], Training Accuracy: 89.5936%, Training Loss: 0.2631%\n",
      "Epoch [51/300], Step [204/225], Training Accuracy: 89.5910%, Training Loss: 0.2635%\n",
      "Epoch [51/300], Step [205/225], Training Accuracy: 89.6265%, Training Loss: 0.2626%\n",
      "Epoch [51/300], Step [206/225], Training Accuracy: 89.6238%, Training Loss: 0.2627%\n",
      "Epoch [51/300], Step [207/225], Training Accuracy: 89.6211%, Training Loss: 0.2626%\n",
      "Epoch [51/300], Step [208/225], Training Accuracy: 89.6409%, Training Loss: 0.2621%\n",
      "Epoch [51/300], Step [209/225], Training Accuracy: 89.6157%, Training Loss: 0.2625%\n",
      "Epoch [51/300], Step [210/225], Training Accuracy: 89.6280%, Training Loss: 0.2623%\n",
      "Epoch [51/300], Step [211/225], Training Accuracy: 89.6327%, Training Loss: 0.2620%\n",
      "Epoch [51/300], Step [212/225], Training Accuracy: 89.6521%, Training Loss: 0.2619%\n",
      "Epoch [51/300], Step [213/225], Training Accuracy: 89.6640%, Training Loss: 0.2616%\n",
      "Epoch [51/300], Step [214/225], Training Accuracy: 89.6831%, Training Loss: 0.2612%\n",
      "Epoch [51/300], Step [215/225], Training Accuracy: 89.6948%, Training Loss: 0.2609%\n",
      "Epoch [51/300], Step [216/225], Training Accuracy: 89.7063%, Training Loss: 0.2611%\n",
      "Epoch [51/300], Step [217/225], Training Accuracy: 89.7033%, Training Loss: 0.2611%\n",
      "Epoch [51/300], Step [218/225], Training Accuracy: 89.6789%, Training Loss: 0.2616%\n",
      "Epoch [51/300], Step [219/225], Training Accuracy: 89.6975%, Training Loss: 0.2612%\n",
      "Epoch [51/300], Step [220/225], Training Accuracy: 89.7159%, Training Loss: 0.2609%\n",
      "Epoch [51/300], Step [221/225], Training Accuracy: 89.7412%, Training Loss: 0.2605%\n",
      "Epoch [51/300], Step [222/225], Training Accuracy: 89.7734%, Training Loss: 0.2600%\n",
      "Epoch [51/300], Step [223/225], Training Accuracy: 89.8122%, Training Loss: 0.2593%\n",
      "Epoch [51/300], Step [224/225], Training Accuracy: 89.8298%, Training Loss: 0.2590%\n",
      "Epoch [51/300], Step [225/225], Training Accuracy: 89.8207%, Training Loss: 0.2590%\n",
      "Epoch [52/300], Step [1/225], Training Accuracy: 90.6250%, Training Loss: 0.3060%\n",
      "Epoch [52/300], Step [2/225], Training Accuracy: 87.5000%, Training Loss: 0.3009%\n",
      "Epoch [52/300], Step [3/225], Training Accuracy: 89.0625%, Training Loss: 0.2965%\n",
      "Epoch [52/300], Step [4/225], Training Accuracy: 89.8438%, Training Loss: 0.2785%\n",
      "Epoch [52/300], Step [5/225], Training Accuracy: 90.6250%, Training Loss: 0.2554%\n",
      "Epoch [52/300], Step [6/225], Training Accuracy: 90.6250%, Training Loss: 0.2377%\n",
      "Epoch [52/300], Step [7/225], Training Accuracy: 90.8482%, Training Loss: 0.2371%\n",
      "Epoch [52/300], Step [8/225], Training Accuracy: 90.4297%, Training Loss: 0.2520%\n",
      "Epoch [52/300], Step [9/225], Training Accuracy: 90.2778%, Training Loss: 0.2565%\n",
      "Epoch [52/300], Step [10/225], Training Accuracy: 89.6875%, Training Loss: 0.2661%\n",
      "Epoch [52/300], Step [11/225], Training Accuracy: 89.9148%, Training Loss: 0.2634%\n",
      "Epoch [52/300], Step [12/225], Training Accuracy: 90.1042%, Training Loss: 0.2581%\n",
      "Epoch [52/300], Step [13/225], Training Accuracy: 90.5048%, Training Loss: 0.2489%\n",
      "Epoch [52/300], Step [14/225], Training Accuracy: 90.7366%, Training Loss: 0.2420%\n",
      "Epoch [52/300], Step [15/225], Training Accuracy: 90.9375%, Training Loss: 0.2444%\n",
      "Epoch [52/300], Step [16/225], Training Accuracy: 90.7227%, Training Loss: 0.2556%\n",
      "Epoch [52/300], Step [17/225], Training Accuracy: 90.7169%, Training Loss: 0.2572%\n",
      "Epoch [52/300], Step [18/225], Training Accuracy: 90.9722%, Training Loss: 0.2535%\n",
      "Epoch [52/300], Step [19/225], Training Accuracy: 90.9539%, Training Loss: 0.2530%\n",
      "Epoch [52/300], Step [20/225], Training Accuracy: 90.7031%, Training Loss: 0.2562%\n",
      "Epoch [52/300], Step [21/225], Training Accuracy: 90.7738%, Training Loss: 0.2499%\n",
      "Epoch [52/300], Step [22/225], Training Accuracy: 90.8381%, Training Loss: 0.2470%\n",
      "Epoch [52/300], Step [23/225], Training Accuracy: 90.8967%, Training Loss: 0.2442%\n",
      "Epoch [52/300], Step [24/225], Training Accuracy: 90.6901%, Training Loss: 0.2491%\n",
      "Epoch [52/300], Step [25/225], Training Accuracy: 91.0000%, Training Loss: 0.2432%\n",
      "Epoch [52/300], Step [26/225], Training Accuracy: 90.8053%, Training Loss: 0.2456%\n",
      "Epoch [52/300], Step [27/225], Training Accuracy: 90.6829%, Training Loss: 0.2436%\n",
      "Epoch [52/300], Step [28/225], Training Accuracy: 90.8482%, Training Loss: 0.2391%\n",
      "Epoch [52/300], Step [29/225], Training Accuracy: 90.8944%, Training Loss: 0.2356%\n",
      "Epoch [52/300], Step [30/225], Training Accuracy: 90.9375%, Training Loss: 0.2372%\n",
      "Epoch [52/300], Step [31/225], Training Accuracy: 90.8266%, Training Loss: 0.2401%\n",
      "Epoch [52/300], Step [32/225], Training Accuracy: 90.9668%, Training Loss: 0.2359%\n",
      "Epoch [52/300], Step [33/225], Training Accuracy: 91.0511%, Training Loss: 0.2354%\n",
      "Epoch [52/300], Step [34/225], Training Accuracy: 90.9926%, Training Loss: 0.2373%\n",
      "Epoch [52/300], Step [35/225], Training Accuracy: 90.9821%, Training Loss: 0.2359%\n",
      "Epoch [52/300], Step [36/225], Training Accuracy: 91.0156%, Training Loss: 0.2348%\n",
      "Epoch [52/300], Step [37/225], Training Accuracy: 90.9628%, Training Loss: 0.2349%\n",
      "Epoch [52/300], Step [38/225], Training Accuracy: 90.7895%, Training Loss: 0.2369%\n",
      "Epoch [52/300], Step [39/225], Training Accuracy: 90.7452%, Training Loss: 0.2389%\n",
      "Epoch [52/300], Step [40/225], Training Accuracy: 90.8203%, Training Loss: 0.2371%\n",
      "Epoch [52/300], Step [41/225], Training Accuracy: 90.7012%, Training Loss: 0.2401%\n",
      "Epoch [52/300], Step [42/225], Training Accuracy: 90.7366%, Training Loss: 0.2391%\n",
      "Epoch [52/300], Step [43/225], Training Accuracy: 90.8067%, Training Loss: 0.2374%\n",
      "Epoch [52/300], Step [44/225], Training Accuracy: 90.8026%, Training Loss: 0.2376%\n",
      "Epoch [52/300], Step [45/225], Training Accuracy: 90.7986%, Training Loss: 0.2369%\n",
      "Epoch [52/300], Step [46/225], Training Accuracy: 90.8967%, Training Loss: 0.2344%\n",
      "Epoch [52/300], Step [47/225], Training Accuracy: 90.8245%, Training Loss: 0.2354%\n",
      "Epoch [52/300], Step [48/225], Training Accuracy: 90.8203%, Training Loss: 0.2356%\n",
      "Epoch [52/300], Step [49/225], Training Accuracy: 90.8482%, Training Loss: 0.2349%\n",
      "Epoch [52/300], Step [50/225], Training Accuracy: 90.7500%, Training Loss: 0.2367%\n",
      "Epoch [52/300], Step [51/225], Training Accuracy: 90.7169%, Training Loss: 0.2363%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/300], Step [52/225], Training Accuracy: 90.8353%, Training Loss: 0.2343%\n",
      "Epoch [52/300], Step [53/225], Training Accuracy: 90.7429%, Training Loss: 0.2339%\n",
      "Epoch [52/300], Step [54/225], Training Accuracy: 90.7697%, Training Loss: 0.2329%\n",
      "Epoch [52/300], Step [55/225], Training Accuracy: 90.6818%, Training Loss: 0.2334%\n",
      "Epoch [52/300], Step [56/225], Training Accuracy: 90.6808%, Training Loss: 0.2332%\n",
      "Epoch [52/300], Step [57/225], Training Accuracy: 90.5428%, Training Loss: 0.2353%\n",
      "Epoch [52/300], Step [58/225], Training Accuracy: 90.5711%, Training Loss: 0.2350%\n",
      "Epoch [52/300], Step [59/225], Training Accuracy: 90.6515%, Training Loss: 0.2343%\n",
      "Epoch [52/300], Step [60/225], Training Accuracy: 90.6250%, Training Loss: 0.2343%\n",
      "Epoch [52/300], Step [61/225], Training Accuracy: 90.6762%, Training Loss: 0.2343%\n",
      "Epoch [52/300], Step [62/225], Training Accuracy: 90.7762%, Training Loss: 0.2325%\n",
      "Epoch [52/300], Step [63/225], Training Accuracy: 90.8234%, Training Loss: 0.2314%\n",
      "Epoch [52/300], Step [64/225], Training Accuracy: 90.7715%, Training Loss: 0.2310%\n",
      "Epoch [52/300], Step [65/225], Training Accuracy: 90.7692%, Training Loss: 0.2306%\n",
      "Epoch [52/300], Step [66/225], Training Accuracy: 90.7434%, Training Loss: 0.2308%\n",
      "Epoch [52/300], Step [67/225], Training Accuracy: 90.7649%, Training Loss: 0.2312%\n",
      "Epoch [52/300], Step [68/225], Training Accuracy: 90.7399%, Training Loss: 0.2318%\n",
      "Epoch [52/300], Step [69/225], Training Accuracy: 90.7382%, Training Loss: 0.2317%\n",
      "Epoch [52/300], Step [70/225], Training Accuracy: 90.7366%, Training Loss: 0.2315%\n",
      "Epoch [52/300], Step [71/225], Training Accuracy: 90.7790%, Training Loss: 0.2309%\n",
      "Epoch [52/300], Step [72/225], Training Accuracy: 90.7769%, Training Loss: 0.2317%\n",
      "Epoch [52/300], Step [73/225], Training Accuracy: 90.7962%, Training Loss: 0.2311%\n",
      "Epoch [52/300], Step [74/225], Training Accuracy: 90.8573%, Training Loss: 0.2304%\n",
      "Epoch [52/300], Step [75/225], Training Accuracy: 90.9167%, Training Loss: 0.2297%\n",
      "Epoch [52/300], Step [76/225], Training Accuracy: 90.9334%, Training Loss: 0.2301%\n",
      "Epoch [52/300], Step [77/225], Training Accuracy: 90.9091%, Training Loss: 0.2299%\n",
      "Epoch [52/300], Step [78/225], Training Accuracy: 90.8454%, Training Loss: 0.2314%\n",
      "Epoch [52/300], Step [79/225], Training Accuracy: 90.8821%, Training Loss: 0.2301%\n",
      "Epoch [52/300], Step [80/225], Training Accuracy: 90.8398%, Training Loss: 0.2299%\n",
      "Epoch [52/300], Step [81/225], Training Accuracy: 90.9336%, Training Loss: 0.2284%\n",
      "Epoch [52/300], Step [82/225], Training Accuracy: 90.9680%, Training Loss: 0.2268%\n",
      "Epoch [52/300], Step [83/225], Training Accuracy: 91.0580%, Training Loss: 0.2256%\n",
      "Epoch [52/300], Step [84/225], Training Accuracy: 91.1086%, Training Loss: 0.2249%\n",
      "Epoch [52/300], Step [85/225], Training Accuracy: 91.0478%, Training Loss: 0.2255%\n",
      "Epoch [52/300], Step [86/225], Training Accuracy: 91.1519%, Training Loss: 0.2239%\n",
      "Epoch [52/300], Step [87/225], Training Accuracy: 91.1638%, Training Loss: 0.2236%\n",
      "Epoch [52/300], Step [88/225], Training Accuracy: 91.0866%, Training Loss: 0.2252%\n",
      "Epoch [52/300], Step [89/225], Training Accuracy: 91.0990%, Training Loss: 0.2248%\n",
      "Epoch [52/300], Step [90/225], Training Accuracy: 90.9896%, Training Loss: 0.2265%\n",
      "Epoch [52/300], Step [91/225], Training Accuracy: 90.9856%, Training Loss: 0.2264%\n",
      "Epoch [52/300], Step [92/225], Training Accuracy: 90.9307%, Training Loss: 0.2284%\n",
      "Epoch [52/300], Step [93/225], Training Accuracy: 90.9442%, Training Loss: 0.2285%\n",
      "Epoch [52/300], Step [94/225], Training Accuracy: 90.9741%, Training Loss: 0.2278%\n",
      "Epoch [52/300], Step [95/225], Training Accuracy: 90.9868%, Training Loss: 0.2270%\n",
      "Epoch [52/300], Step [96/225], Training Accuracy: 90.9831%, Training Loss: 0.2276%\n",
      "Epoch [52/300], Step [97/225], Training Accuracy: 90.9472%, Training Loss: 0.2283%\n",
      "Epoch [52/300], Step [98/225], Training Accuracy: 90.9758%, Training Loss: 0.2283%\n",
      "Epoch [52/300], Step [99/225], Training Accuracy: 91.0354%, Training Loss: 0.2276%\n",
      "Epoch [52/300], Step [100/225], Training Accuracy: 91.0781%, Training Loss: 0.2268%\n",
      "Epoch [52/300], Step [101/225], Training Accuracy: 91.1046%, Training Loss: 0.2261%\n",
      "Epoch [52/300], Step [102/225], Training Accuracy: 91.1458%, Training Loss: 0.2254%\n",
      "Epoch [52/300], Step [103/225], Training Accuracy: 91.1863%, Training Loss: 0.2244%\n",
      "Epoch [52/300], Step [104/225], Training Accuracy: 91.1959%, Training Loss: 0.2239%\n",
      "Epoch [52/300], Step [105/225], Training Accuracy: 91.1161%, Training Loss: 0.2246%\n",
      "Epoch [52/300], Step [106/225], Training Accuracy: 91.1704%, Training Loss: 0.2237%\n",
      "Epoch [52/300], Step [107/225], Training Accuracy: 91.1653%, Training Loss: 0.2246%\n",
      "Epoch [52/300], Step [108/225], Training Accuracy: 91.1314%, Training Loss: 0.2248%\n",
      "Epoch [52/300], Step [109/225], Training Accuracy: 91.1267%, Training Loss: 0.2250%\n",
      "Epoch [52/300], Step [110/225], Training Accuracy: 91.1790%, Training Loss: 0.2243%\n",
      "Epoch [52/300], Step [111/225], Training Accuracy: 91.1599%, Training Loss: 0.2242%\n",
      "Epoch [52/300], Step [112/225], Training Accuracy: 91.1412%, Training Loss: 0.2243%\n",
      "Epoch [52/300], Step [113/225], Training Accuracy: 91.1504%, Training Loss: 0.2240%\n",
      "Epoch [52/300], Step [114/225], Training Accuracy: 91.1321%, Training Loss: 0.2238%\n",
      "Epoch [52/300], Step [115/225], Training Accuracy: 91.1549%, Training Loss: 0.2232%\n",
      "Epoch [52/300], Step [116/225], Training Accuracy: 91.1369%, Training Loss: 0.2233%\n",
      "Epoch [52/300], Step [117/225], Training Accuracy: 91.1592%, Training Loss: 0.2227%\n",
      "Epoch [52/300], Step [118/225], Training Accuracy: 91.1414%, Training Loss: 0.2231%\n",
      "Epoch [52/300], Step [119/225], Training Accuracy: 91.1633%, Training Loss: 0.2232%\n",
      "Epoch [52/300], Step [120/225], Training Accuracy: 91.1849%, Training Loss: 0.2232%\n",
      "Epoch [52/300], Step [121/225], Training Accuracy: 91.1932%, Training Loss: 0.2228%\n",
      "Epoch [52/300], Step [122/225], Training Accuracy: 91.1757%, Training Loss: 0.2236%\n",
      "Epoch [52/300], Step [123/225], Training Accuracy: 91.1966%, Training Loss: 0.2231%\n",
      "Epoch [52/300], Step [124/225], Training Accuracy: 91.1920%, Training Loss: 0.2232%\n",
      "Epoch [52/300], Step [125/225], Training Accuracy: 91.2250%, Training Loss: 0.2228%\n",
      "Epoch [52/300], Step [126/225], Training Accuracy: 91.2078%, Training Loss: 0.2225%\n",
      "Epoch [52/300], Step [127/225], Training Accuracy: 91.2032%, Training Loss: 0.2226%\n",
      "Epoch [52/300], Step [128/225], Training Accuracy: 91.2109%, Training Loss: 0.2226%\n",
      "Epoch [52/300], Step [129/225], Training Accuracy: 91.1701%, Training Loss: 0.2228%\n",
      "Epoch [52/300], Step [130/225], Training Accuracy: 91.0817%, Training Loss: 0.2237%\n",
      "Epoch [52/300], Step [131/225], Training Accuracy: 91.0425%, Training Loss: 0.2243%\n",
      "Epoch [52/300], Step [132/225], Training Accuracy: 91.0630%, Training Loss: 0.2239%\n",
      "Epoch [52/300], Step [133/225], Training Accuracy: 91.0479%, Training Loss: 0.2240%\n",
      "Epoch [52/300], Step [134/225], Training Accuracy: 91.0448%, Training Loss: 0.2240%\n",
      "Epoch [52/300], Step [135/225], Training Accuracy: 91.0764%, Training Loss: 0.2234%\n",
      "Epoch [52/300], Step [136/225], Training Accuracy: 91.0501%, Training Loss: 0.2236%\n",
      "Epoch [52/300], Step [137/225], Training Accuracy: 91.1040%, Training Loss: 0.2227%\n",
      "Epoch [52/300], Step [138/225], Training Accuracy: 91.1458%, Training Loss: 0.2220%\n",
      "Epoch [52/300], Step [139/225], Training Accuracy: 91.1758%, Training Loss: 0.2214%\n",
      "Epoch [52/300], Step [140/225], Training Accuracy: 91.1719%, Training Loss: 0.2214%\n",
      "Epoch [52/300], Step [141/225], Training Accuracy: 91.1791%, Training Loss: 0.2214%\n",
      "Epoch [52/300], Step [142/225], Training Accuracy: 91.2082%, Training Loss: 0.2209%\n",
      "Epoch [52/300], Step [143/225], Training Accuracy: 91.2369%, Training Loss: 0.2204%\n",
      "Epoch [52/300], Step [144/225], Training Accuracy: 91.2001%, Training Loss: 0.2209%\n",
      "Epoch [52/300], Step [145/225], Training Accuracy: 91.1638%, Training Loss: 0.2213%\n",
      "Epoch [52/300], Step [146/225], Training Accuracy: 91.1708%, Training Loss: 0.2209%\n",
      "Epoch [52/300], Step [147/225], Training Accuracy: 91.1565%, Training Loss: 0.2212%\n",
      "Epoch [52/300], Step [148/225], Training Accuracy: 91.1740%, Training Loss: 0.2208%\n",
      "Epoch [52/300], Step [149/225], Training Accuracy: 91.1703%, Training Loss: 0.2206%\n",
      "Epoch [52/300], Step [150/225], Training Accuracy: 91.1875%, Training Loss: 0.2199%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/300], Step [151/225], Training Accuracy: 91.2148%, Training Loss: 0.2193%\n",
      "Epoch [52/300], Step [152/225], Training Accuracy: 91.2212%, Training Loss: 0.2195%\n",
      "Epoch [52/300], Step [153/225], Training Accuracy: 91.2071%, Training Loss: 0.2194%\n",
      "Epoch [52/300], Step [154/225], Training Accuracy: 91.2135%, Training Loss: 0.2194%\n",
      "Epoch [52/300], Step [155/225], Training Accuracy: 91.2097%, Training Loss: 0.2195%\n",
      "Epoch [52/300], Step [156/225], Training Accuracy: 91.2059%, Training Loss: 0.2195%\n",
      "Epoch [52/300], Step [157/225], Training Accuracy: 91.2221%, Training Loss: 0.2193%\n",
      "Epoch [52/300], Step [158/225], Training Accuracy: 91.2678%, Training Loss: 0.2186%\n",
      "Epoch [52/300], Step [159/225], Training Accuracy: 91.2539%, Training Loss: 0.2186%\n",
      "Epoch [52/300], Step [160/225], Training Accuracy: 91.2207%, Training Loss: 0.2186%\n",
      "Epoch [52/300], Step [161/225], Training Accuracy: 91.2170%, Training Loss: 0.2190%\n",
      "Epoch [52/300], Step [162/225], Training Accuracy: 91.2326%, Training Loss: 0.2186%\n",
      "Epoch [52/300], Step [163/225], Training Accuracy: 91.2289%, Training Loss: 0.2187%\n",
      "Epoch [52/300], Step [164/225], Training Accuracy: 91.2348%, Training Loss: 0.2181%\n",
      "Epoch [52/300], Step [165/225], Training Accuracy: 91.2500%, Training Loss: 0.2179%\n",
      "Epoch [52/300], Step [166/225], Training Accuracy: 91.2556%, Training Loss: 0.2180%\n",
      "Epoch [52/300], Step [167/225], Training Accuracy: 91.2987%, Training Loss: 0.2173%\n",
      "Epoch [52/300], Step [168/225], Training Accuracy: 91.2853%, Training Loss: 0.2175%\n",
      "Epoch [52/300], Step [169/225], Training Accuracy: 91.2814%, Training Loss: 0.2175%\n",
      "Epoch [52/300], Step [170/225], Training Accuracy: 91.2684%, Training Loss: 0.2179%\n",
      "Epoch [52/300], Step [171/225], Training Accuracy: 91.2189%, Training Loss: 0.2186%\n",
      "Epoch [52/300], Step [172/225], Training Accuracy: 91.2336%, Training Loss: 0.2184%\n",
      "Epoch [52/300], Step [173/225], Training Accuracy: 91.2121%, Training Loss: 0.2186%\n",
      "Epoch [52/300], Step [174/225], Training Accuracy: 91.2536%, Training Loss: 0.2179%\n",
      "Epoch [52/300], Step [175/225], Training Accuracy: 91.2411%, Training Loss: 0.2183%\n",
      "Epoch [52/300], Step [176/225], Training Accuracy: 91.2731%, Training Loss: 0.2176%\n",
      "Epoch [52/300], Step [177/225], Training Accuracy: 91.2606%, Training Loss: 0.2175%\n",
      "Epoch [52/300], Step [178/225], Training Accuracy: 91.2658%, Training Loss: 0.2172%\n",
      "Epoch [52/300], Step [179/225], Training Accuracy: 91.2622%, Training Loss: 0.2173%\n",
      "Epoch [52/300], Step [180/225], Training Accuracy: 91.3021%, Training Loss: 0.2166%\n",
      "Epoch [52/300], Step [181/225], Training Accuracy: 91.3156%, Training Loss: 0.2164%\n",
      "Epoch [52/300], Step [182/225], Training Accuracy: 91.3376%, Training Loss: 0.2160%\n",
      "Epoch [52/300], Step [183/225], Training Accuracy: 91.3337%, Training Loss: 0.2158%\n",
      "Epoch [52/300], Step [184/225], Training Accuracy: 91.3298%, Training Loss: 0.2159%\n",
      "Epoch [52/300], Step [185/225], Training Accuracy: 91.3682%, Training Loss: 0.2150%\n",
      "Epoch [52/300], Step [186/225], Training Accuracy: 91.3978%, Training Loss: 0.2144%\n",
      "Epoch [52/300], Step [187/225], Training Accuracy: 91.4188%, Training Loss: 0.2138%\n",
      "Epoch [52/300], Step [188/225], Training Accuracy: 91.4395%, Training Loss: 0.2133%\n",
      "Epoch [52/300], Step [189/225], Training Accuracy: 91.4352%, Training Loss: 0.2132%\n",
      "Epoch [52/300], Step [190/225], Training Accuracy: 91.4556%, Training Loss: 0.2128%\n",
      "Epoch [52/300], Step [191/225], Training Accuracy: 91.4512%, Training Loss: 0.2127%\n",
      "Epoch [52/300], Step [192/225], Training Accuracy: 91.4225%, Training Loss: 0.2132%\n",
      "Epoch [52/300], Step [193/225], Training Accuracy: 91.4427%, Training Loss: 0.2129%\n",
      "Epoch [52/300], Step [194/225], Training Accuracy: 91.4304%, Training Loss: 0.2132%\n",
      "Epoch [52/300], Step [195/225], Training Accuracy: 91.4423%, Training Loss: 0.2132%\n",
      "Epoch [52/300], Step [196/225], Training Accuracy: 91.4222%, Training Loss: 0.2133%\n",
      "Epoch [52/300], Step [197/225], Training Accuracy: 91.4499%, Training Loss: 0.2128%\n",
      "Epoch [52/300], Step [198/225], Training Accuracy: 91.4773%, Training Loss: 0.2121%\n",
      "Epoch [52/300], Step [199/225], Training Accuracy: 91.4651%, Training Loss: 0.2123%\n",
      "Epoch [52/300], Step [200/225], Training Accuracy: 91.4453%, Training Loss: 0.2128%\n",
      "Epoch [52/300], Step [201/225], Training Accuracy: 91.4179%, Training Loss: 0.2134%\n",
      "Epoch [52/300], Step [202/225], Training Accuracy: 91.3908%, Training Loss: 0.2134%\n",
      "Epoch [52/300], Step [203/225], Training Accuracy: 91.4101%, Training Loss: 0.2130%\n",
      "Epoch [52/300], Step [204/225], Training Accuracy: 91.4216%, Training Loss: 0.2129%\n",
      "Epoch [52/300], Step [205/225], Training Accuracy: 91.4405%, Training Loss: 0.2123%\n",
      "Epoch [52/300], Step [206/225], Training Accuracy: 91.4214%, Training Loss: 0.2129%\n",
      "Epoch [52/300], Step [207/225], Training Accuracy: 91.4327%, Training Loss: 0.2128%\n",
      "Epoch [52/300], Step [208/225], Training Accuracy: 91.4438%, Training Loss: 0.2131%\n",
      "Epoch [52/300], Step [209/225], Training Accuracy: 91.4100%, Training Loss: 0.2139%\n",
      "Epoch [52/300], Step [210/225], Training Accuracy: 91.3988%, Training Loss: 0.2141%\n",
      "Epoch [52/300], Step [211/225], Training Accuracy: 91.3951%, Training Loss: 0.2144%\n",
      "Epoch [52/300], Step [212/225], Training Accuracy: 91.3841%, Training Loss: 0.2145%\n",
      "Epoch [52/300], Step [213/225], Training Accuracy: 91.3806%, Training Loss: 0.2145%\n",
      "Epoch [52/300], Step [214/225], Training Accuracy: 91.3989%, Training Loss: 0.2144%\n",
      "Epoch [52/300], Step [215/225], Training Accuracy: 91.4099%, Training Loss: 0.2141%\n",
      "Epoch [52/300], Step [216/225], Training Accuracy: 91.4280%, Training Loss: 0.2136%\n",
      "Epoch [52/300], Step [217/225], Training Accuracy: 91.4171%, Training Loss: 0.2142%\n",
      "Epoch [52/300], Step [218/225], Training Accuracy: 91.4278%, Training Loss: 0.2142%\n",
      "Epoch [52/300], Step [219/225], Training Accuracy: 91.4455%, Training Loss: 0.2140%\n",
      "Epoch [52/300], Step [220/225], Training Accuracy: 91.4631%, Training Loss: 0.2139%\n",
      "Epoch [52/300], Step [221/225], Training Accuracy: 91.4734%, Training Loss: 0.2136%\n",
      "Epoch [52/300], Step [222/225], Training Accuracy: 91.4837%, Training Loss: 0.2136%\n",
      "Epoch [52/300], Step [223/225], Training Accuracy: 91.4798%, Training Loss: 0.2137%\n",
      "Epoch [52/300], Step [224/225], Training Accuracy: 91.4760%, Training Loss: 0.2137%\n",
      "Epoch [52/300], Step [225/225], Training Accuracy: 91.4605%, Training Loss: 0.2143%\n",
      "Epoch [53/300], Step [1/225], Training Accuracy: 82.8125%, Training Loss: 0.3291%\n",
      "Epoch [53/300], Step [2/225], Training Accuracy: 85.1562%, Training Loss: 0.3520%\n",
      "Epoch [53/300], Step [3/225], Training Accuracy: 86.4583%, Training Loss: 0.3172%\n",
      "Epoch [53/300], Step [4/225], Training Accuracy: 87.5000%, Training Loss: 0.3124%\n",
      "Epoch [53/300], Step [5/225], Training Accuracy: 88.7500%, Training Loss: 0.2878%\n",
      "Epoch [53/300], Step [6/225], Training Accuracy: 89.3229%, Training Loss: 0.2765%\n",
      "Epoch [53/300], Step [7/225], Training Accuracy: 88.8393%, Training Loss: 0.2973%\n",
      "Epoch [53/300], Step [8/225], Training Accuracy: 89.0625%, Training Loss: 0.2946%\n",
      "Epoch [53/300], Step [9/225], Training Accuracy: 88.5417%, Training Loss: 0.2993%\n",
      "Epoch [53/300], Step [10/225], Training Accuracy: 88.5938%, Training Loss: 0.2960%\n",
      "Epoch [53/300], Step [11/225], Training Accuracy: 88.4943%, Training Loss: 0.2972%\n",
      "Epoch [53/300], Step [12/225], Training Accuracy: 89.0625%, Training Loss: 0.2886%\n",
      "Epoch [53/300], Step [13/225], Training Accuracy: 89.4231%, Training Loss: 0.2780%\n",
      "Epoch [53/300], Step [14/225], Training Accuracy: 89.6205%, Training Loss: 0.2767%\n",
      "Epoch [53/300], Step [15/225], Training Accuracy: 89.3750%, Training Loss: 0.2780%\n",
      "Epoch [53/300], Step [16/225], Training Accuracy: 89.0625%, Training Loss: 0.2822%\n",
      "Epoch [53/300], Step [17/225], Training Accuracy: 89.4301%, Training Loss: 0.2747%\n",
      "Epoch [53/300], Step [18/225], Training Accuracy: 89.6701%, Training Loss: 0.2710%\n",
      "Epoch [53/300], Step [19/225], Training Accuracy: 89.8849%, Training Loss: 0.2671%\n",
      "Epoch [53/300], Step [20/225], Training Accuracy: 90.3125%, Training Loss: 0.2596%\n",
      "Epoch [53/300], Step [21/225], Training Accuracy: 90.3274%, Training Loss: 0.2554%\n",
      "Epoch [53/300], Step [22/225], Training Accuracy: 90.1278%, Training Loss: 0.2573%\n",
      "Epoch [53/300], Step [23/225], Training Accuracy: 90.2853%, Training Loss: 0.2523%\n",
      "Epoch [53/300], Step [24/225], Training Accuracy: 90.1693%, Training Loss: 0.2557%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/300], Step [25/225], Training Accuracy: 90.3750%, Training Loss: 0.2502%\n",
      "Epoch [53/300], Step [26/225], Training Accuracy: 90.5048%, Training Loss: 0.2454%\n",
      "Epoch [53/300], Step [27/225], Training Accuracy: 90.6250%, Training Loss: 0.2424%\n",
      "Epoch [53/300], Step [28/225], Training Accuracy: 90.8482%, Training Loss: 0.2372%\n",
      "Epoch [53/300], Step [29/225], Training Accuracy: 90.8405%, Training Loss: 0.2358%\n",
      "Epoch [53/300], Step [30/225], Training Accuracy: 90.9896%, Training Loss: 0.2338%\n",
      "Epoch [53/300], Step [31/225], Training Accuracy: 90.8266%, Training Loss: 0.2435%\n",
      "Epoch [53/300], Step [32/225], Training Accuracy: 90.9180%, Training Loss: 0.2418%\n",
      "Epoch [53/300], Step [33/225], Training Accuracy: 90.9091%, Training Loss: 0.2435%\n",
      "Epoch [53/300], Step [34/225], Training Accuracy: 90.9007%, Training Loss: 0.2433%\n",
      "Epoch [53/300], Step [35/225], Training Accuracy: 91.0268%, Training Loss: 0.2404%\n",
      "Epoch [53/300], Step [36/225], Training Accuracy: 91.1458%, Training Loss: 0.2376%\n",
      "Epoch [53/300], Step [37/225], Training Accuracy: 91.2162%, Training Loss: 0.2377%\n",
      "Epoch [53/300], Step [38/225], Training Accuracy: 91.0362%, Training Loss: 0.2378%\n",
      "Epoch [53/300], Step [39/225], Training Accuracy: 90.8654%, Training Loss: 0.2405%\n",
      "Epoch [53/300], Step [40/225], Training Accuracy: 90.8203%, Training Loss: 0.2415%\n",
      "Epoch [53/300], Step [41/225], Training Accuracy: 90.6250%, Training Loss: 0.2431%\n",
      "Epoch [53/300], Step [42/225], Training Accuracy: 90.5878%, Training Loss: 0.2435%\n",
      "Epoch [53/300], Step [43/225], Training Accuracy: 90.6977%, Training Loss: 0.2407%\n",
      "Epoch [53/300], Step [44/225], Training Accuracy: 90.7315%, Training Loss: 0.2397%\n",
      "Epoch [53/300], Step [45/225], Training Accuracy: 90.7639%, Training Loss: 0.2387%\n",
      "Epoch [53/300], Step [46/225], Training Accuracy: 90.8288%, Training Loss: 0.2373%\n",
      "Epoch [53/300], Step [47/225], Training Accuracy: 90.8910%, Training Loss: 0.2376%\n",
      "Epoch [53/300], Step [48/225], Training Accuracy: 90.7878%, Training Loss: 0.2412%\n",
      "Epoch [53/300], Step [49/225], Training Accuracy: 90.8482%, Training Loss: 0.2399%\n",
      "Epoch [53/300], Step [50/225], Training Accuracy: 90.7500%, Training Loss: 0.2404%\n",
      "Epoch [53/300], Step [51/225], Training Accuracy: 90.7475%, Training Loss: 0.2402%\n",
      "Epoch [53/300], Step [52/225], Training Accuracy: 90.8654%, Training Loss: 0.2382%\n",
      "Epoch [53/300], Step [53/225], Training Accuracy: 90.9493%, Training Loss: 0.2360%\n",
      "Epoch [53/300], Step [54/225], Training Accuracy: 90.9722%, Training Loss: 0.2352%\n",
      "Epoch [53/300], Step [55/225], Training Accuracy: 91.0227%, Training Loss: 0.2347%\n",
      "Epoch [53/300], Step [56/225], Training Accuracy: 91.0993%, Training Loss: 0.2346%\n",
      "Epoch [53/300], Step [57/225], Training Accuracy: 90.9814%, Training Loss: 0.2354%\n",
      "Epoch [53/300], Step [58/225], Training Accuracy: 91.0560%, Training Loss: 0.2341%\n",
      "Epoch [53/300], Step [59/225], Training Accuracy: 91.0487%, Training Loss: 0.2348%\n",
      "Epoch [53/300], Step [60/225], Training Accuracy: 91.0938%, Training Loss: 0.2340%\n",
      "Epoch [53/300], Step [61/225], Training Accuracy: 91.0605%, Training Loss: 0.2341%\n",
      "Epoch [53/300], Step [62/225], Training Accuracy: 91.0786%, Training Loss: 0.2335%\n",
      "Epoch [53/300], Step [63/225], Training Accuracy: 90.9970%, Training Loss: 0.2343%\n",
      "Epoch [53/300], Step [64/225], Training Accuracy: 91.0889%, Training Loss: 0.2324%\n",
      "Epoch [53/300], Step [65/225], Training Accuracy: 91.0337%, Training Loss: 0.2333%\n",
      "Epoch [53/300], Step [66/225], Training Accuracy: 90.9801%, Training Loss: 0.2333%\n",
      "Epoch [53/300], Step [67/225], Training Accuracy: 90.9981%, Training Loss: 0.2328%\n",
      "Epoch [53/300], Step [68/225], Training Accuracy: 90.9697%, Training Loss: 0.2343%\n",
      "Epoch [53/300], Step [69/225], Training Accuracy: 91.0326%, Training Loss: 0.2328%\n",
      "Epoch [53/300], Step [70/225], Training Accuracy: 90.9598%, Training Loss: 0.2342%\n",
      "Epoch [53/300], Step [71/225], Training Accuracy: 90.8671%, Training Loss: 0.2349%\n",
      "Epoch [53/300], Step [72/225], Training Accuracy: 90.7552%, Training Loss: 0.2375%\n",
      "Epoch [53/300], Step [73/225], Training Accuracy: 90.7106%, Training Loss: 0.2382%\n",
      "Epoch [53/300], Step [74/225], Training Accuracy: 90.6672%, Training Loss: 0.2389%\n",
      "Epoch [53/300], Step [75/225], Training Accuracy: 90.6667%, Training Loss: 0.2382%\n",
      "Epoch [53/300], Step [76/225], Training Accuracy: 90.6250%, Training Loss: 0.2386%\n",
      "Epoch [53/300], Step [77/225], Training Accuracy: 90.6250%, Training Loss: 0.2382%\n",
      "Epoch [53/300], Step [78/225], Training Accuracy: 90.6851%, Training Loss: 0.2375%\n",
      "Epoch [53/300], Step [79/225], Training Accuracy: 90.7041%, Training Loss: 0.2363%\n",
      "Epoch [53/300], Step [80/225], Training Accuracy: 90.7031%, Training Loss: 0.2360%\n",
      "Epoch [53/300], Step [81/225], Training Accuracy: 90.7407%, Training Loss: 0.2349%\n",
      "Epoch [53/300], Step [82/225], Training Accuracy: 90.8346%, Training Loss: 0.2329%\n",
      "Epoch [53/300], Step [83/225], Training Accuracy: 90.8321%, Training Loss: 0.2324%\n",
      "Epoch [53/300], Step [84/225], Training Accuracy: 90.8854%, Training Loss: 0.2312%\n",
      "Epoch [53/300], Step [85/225], Training Accuracy: 90.8824%, Training Loss: 0.2309%\n",
      "Epoch [53/300], Step [86/225], Training Accuracy: 90.8794%, Training Loss: 0.2300%\n",
      "Epoch [53/300], Step [87/225], Training Accuracy: 90.8944%, Training Loss: 0.2299%\n",
      "Epoch [53/300], Step [88/225], Training Accuracy: 90.8203%, Training Loss: 0.2311%\n",
      "Epoch [53/300], Step [89/225], Training Accuracy: 90.8532%, Training Loss: 0.2307%\n",
      "Epoch [53/300], Step [90/225], Training Accuracy: 90.7986%, Training Loss: 0.2319%\n",
      "Epoch [53/300], Step [91/225], Training Accuracy: 90.7967%, Training Loss: 0.2325%\n",
      "Epoch [53/300], Step [92/225], Training Accuracy: 90.7439%, Training Loss: 0.2336%\n",
      "Epoch [53/300], Step [93/225], Training Accuracy: 90.8098%, Training Loss: 0.2329%\n",
      "Epoch [53/300], Step [94/225], Training Accuracy: 90.8411%, Training Loss: 0.2327%\n",
      "Epoch [53/300], Step [95/225], Training Accuracy: 90.8717%, Training Loss: 0.2319%\n",
      "Epoch [53/300], Step [96/225], Training Accuracy: 90.9180%, Training Loss: 0.2313%\n",
      "Epoch [53/300], Step [97/225], Training Accuracy: 90.8666%, Training Loss: 0.2320%\n",
      "Epoch [53/300], Step [98/225], Training Accuracy: 90.8163%, Training Loss: 0.2335%\n",
      "Epoch [53/300], Step [99/225], Training Accuracy: 90.8460%, Training Loss: 0.2329%\n",
      "Epoch [53/300], Step [100/225], Training Accuracy: 90.8594%, Training Loss: 0.2328%\n",
      "Epoch [53/300], Step [101/225], Training Accuracy: 90.8880%, Training Loss: 0.2329%\n",
      "Epoch [53/300], Step [102/225], Training Accuracy: 90.9007%, Training Loss: 0.2329%\n",
      "Epoch [53/300], Step [103/225], Training Accuracy: 90.9284%, Training Loss: 0.2322%\n",
      "Epoch [53/300], Step [104/225], Training Accuracy: 90.9555%, Training Loss: 0.2318%\n",
      "Epoch [53/300], Step [105/225], Training Accuracy: 90.9375%, Training Loss: 0.2323%\n",
      "Epoch [53/300], Step [106/225], Training Accuracy: 90.9051%, Training Loss: 0.2325%\n",
      "Epoch [53/300], Step [107/225], Training Accuracy: 90.8732%, Training Loss: 0.2326%\n",
      "Epoch [53/300], Step [108/225], Training Accuracy: 90.8420%, Training Loss: 0.2326%\n",
      "Epoch [53/300], Step [109/225], Training Accuracy: 90.7827%, Training Loss: 0.2332%\n",
      "Epoch [53/300], Step [110/225], Training Accuracy: 90.7670%, Training Loss: 0.2327%\n",
      "Epoch [53/300], Step [111/225], Training Accuracy: 90.7658%, Training Loss: 0.2322%\n",
      "Epoch [53/300], Step [112/225], Training Accuracy: 90.7227%, Training Loss: 0.2326%\n",
      "Epoch [53/300], Step [113/225], Training Accuracy: 90.7080%, Training Loss: 0.2328%\n",
      "Epoch [53/300], Step [114/225], Training Accuracy: 90.7072%, Training Loss: 0.2329%\n",
      "Epoch [53/300], Step [115/225], Training Accuracy: 90.7201%, Training Loss: 0.2324%\n",
      "Epoch [53/300], Step [116/225], Training Accuracy: 90.7328%, Training Loss: 0.2323%\n",
      "Epoch [53/300], Step [117/225], Training Accuracy: 90.7853%, Training Loss: 0.2317%\n",
      "Epoch [53/300], Step [118/225], Training Accuracy: 90.7971%, Training Loss: 0.2320%\n",
      "Epoch [53/300], Step [119/225], Training Accuracy: 90.7826%, Training Loss: 0.2323%\n",
      "Epoch [53/300], Step [120/225], Training Accuracy: 90.7943%, Training Loss: 0.2319%\n",
      "Epoch [53/300], Step [121/225], Training Accuracy: 90.7541%, Training Loss: 0.2320%\n",
      "Epoch [53/300], Step [122/225], Training Accuracy: 90.7659%, Training Loss: 0.2315%\n",
      "Epoch [53/300], Step [123/225], Training Accuracy: 90.7647%, Training Loss: 0.2313%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/300], Step [124/225], Training Accuracy: 90.7888%, Training Loss: 0.2310%\n",
      "Epoch [53/300], Step [125/225], Training Accuracy: 90.8000%, Training Loss: 0.2304%\n",
      "Epoch [53/300], Step [126/225], Training Accuracy: 90.8110%, Training Loss: 0.2303%\n",
      "Epoch [53/300], Step [127/225], Training Accuracy: 90.8095%, Training Loss: 0.2303%\n",
      "Epoch [53/300], Step [128/225], Training Accuracy: 90.8447%, Training Loss: 0.2297%\n",
      "Epoch [53/300], Step [129/225], Training Accuracy: 90.8672%, Training Loss: 0.2296%\n",
      "Epoch [53/300], Step [130/225], Training Accuracy: 90.8774%, Training Loss: 0.2298%\n",
      "Epoch [53/300], Step [131/225], Training Accuracy: 90.8397%, Training Loss: 0.2308%\n",
      "Epoch [53/300], Step [132/225], Training Accuracy: 90.8736%, Training Loss: 0.2304%\n",
      "Epoch [53/300], Step [133/225], Training Accuracy: 90.8365%, Training Loss: 0.2307%\n",
      "Epoch [53/300], Step [134/225], Training Accuracy: 90.8582%, Training Loss: 0.2304%\n",
      "Epoch [53/300], Step [135/225], Training Accuracy: 90.8449%, Training Loss: 0.2303%\n",
      "Epoch [53/300], Step [136/225], Training Accuracy: 90.7858%, Training Loss: 0.2307%\n",
      "Epoch [53/300], Step [137/225], Training Accuracy: 90.8303%, Training Loss: 0.2301%\n",
      "Epoch [53/300], Step [138/225], Training Accuracy: 90.8514%, Training Loss: 0.2296%\n",
      "Epoch [53/300], Step [139/225], Training Accuracy: 90.8386%, Training Loss: 0.2295%\n",
      "Epoch [53/300], Step [140/225], Training Accuracy: 90.8147%, Training Loss: 0.2296%\n",
      "Epoch [53/300], Step [141/225], Training Accuracy: 90.8023%, Training Loss: 0.2297%\n",
      "Epoch [53/300], Step [142/225], Training Accuracy: 90.8121%, Training Loss: 0.2295%\n",
      "Epoch [53/300], Step [143/225], Training Accuracy: 90.8435%, Training Loss: 0.2291%\n",
      "Epoch [53/300], Step [144/225], Training Accuracy: 90.8529%, Training Loss: 0.2287%\n",
      "Epoch [53/300], Step [145/225], Training Accuracy: 90.8728%, Training Loss: 0.2284%\n",
      "Epoch [53/300], Step [146/225], Training Accuracy: 90.8711%, Training Loss: 0.2287%\n",
      "Epoch [53/300], Step [147/225], Training Accuracy: 90.8695%, Training Loss: 0.2287%\n",
      "Epoch [53/300], Step [148/225], Training Accuracy: 90.9101%, Training Loss: 0.2283%\n",
      "Epoch [53/300], Step [149/225], Training Accuracy: 90.9186%, Training Loss: 0.2279%\n",
      "Epoch [53/300], Step [150/225], Training Accuracy: 90.9688%, Training Loss: 0.2267%\n",
      "Epoch [53/300], Step [151/225], Training Accuracy: 91.0182%, Training Loss: 0.2259%\n",
      "Epoch [53/300], Step [152/225], Training Accuracy: 91.0053%, Training Loss: 0.2259%\n",
      "Epoch [53/300], Step [153/225], Training Accuracy: 91.0437%, Training Loss: 0.2253%\n",
      "Epoch [53/300], Step [154/225], Training Accuracy: 91.0714%, Training Loss: 0.2246%\n",
      "Epoch [53/300], Step [155/225], Training Accuracy: 91.0685%, Training Loss: 0.2250%\n",
      "Epoch [53/300], Step [156/225], Training Accuracy: 91.1058%, Training Loss: 0.2243%\n",
      "Epoch [53/300], Step [157/225], Training Accuracy: 91.1425%, Training Loss: 0.2238%\n",
      "Epoch [53/300], Step [158/225], Training Accuracy: 91.1986%, Training Loss: 0.2229%\n",
      "Epoch [53/300], Step [159/225], Training Accuracy: 91.1950%, Training Loss: 0.2231%\n",
      "Epoch [53/300], Step [160/225], Training Accuracy: 91.1914%, Training Loss: 0.2232%\n",
      "Epoch [53/300], Step [161/225], Training Accuracy: 91.1782%, Training Loss: 0.2230%\n",
      "Epoch [53/300], Step [162/225], Training Accuracy: 91.1844%, Training Loss: 0.2229%\n",
      "Epoch [53/300], Step [163/225], Training Accuracy: 91.1810%, Training Loss: 0.2228%\n",
      "Epoch [53/300], Step [164/225], Training Accuracy: 91.2157%, Training Loss: 0.2219%\n",
      "Epoch [53/300], Step [165/225], Training Accuracy: 91.2405%, Training Loss: 0.2216%\n",
      "Epoch [53/300], Step [166/225], Training Accuracy: 91.2274%, Training Loss: 0.2219%\n",
      "Epoch [53/300], Step [167/225], Training Accuracy: 91.2519%, Training Loss: 0.2215%\n",
      "Epoch [53/300], Step [168/225], Training Accuracy: 91.2574%, Training Loss: 0.2213%\n",
      "Epoch [53/300], Step [169/225], Training Accuracy: 91.2629%, Training Loss: 0.2209%\n",
      "Epoch [53/300], Step [170/225], Training Accuracy: 91.2684%, Training Loss: 0.2204%\n",
      "Epoch [53/300], Step [171/225], Training Accuracy: 91.2646%, Training Loss: 0.2206%\n",
      "Epoch [53/300], Step [172/225], Training Accuracy: 91.2882%, Training Loss: 0.2204%\n",
      "Epoch [53/300], Step [173/225], Training Accuracy: 91.2934%, Training Loss: 0.2203%\n",
      "Epoch [53/300], Step [174/225], Training Accuracy: 91.2985%, Training Loss: 0.2200%\n",
      "Epoch [53/300], Step [175/225], Training Accuracy: 91.3214%, Training Loss: 0.2195%\n",
      "Epoch [53/300], Step [176/225], Training Accuracy: 91.3441%, Training Loss: 0.2191%\n",
      "Epoch [53/300], Step [177/225], Training Accuracy: 91.3312%, Training Loss: 0.2194%\n",
      "Epoch [53/300], Step [178/225], Training Accuracy: 91.3536%, Training Loss: 0.2190%\n",
      "Epoch [53/300], Step [179/225], Training Accuracy: 91.3844%, Training Loss: 0.2185%\n",
      "Epoch [53/300], Step [180/225], Training Accuracy: 91.3715%, Training Loss: 0.2186%\n",
      "Epoch [53/300], Step [181/225], Training Accuracy: 91.3501%, Training Loss: 0.2191%\n",
      "Epoch [53/300], Step [182/225], Training Accuracy: 91.3462%, Training Loss: 0.2192%\n",
      "Epoch [53/300], Step [183/225], Training Accuracy: 91.3081%, Training Loss: 0.2202%\n",
      "Epoch [53/300], Step [184/225], Training Accuracy: 91.3213%, Training Loss: 0.2197%\n",
      "Epoch [53/300], Step [185/225], Training Accuracy: 91.3514%, Training Loss: 0.2190%\n",
      "Epoch [53/300], Step [186/225], Training Accuracy: 91.3894%, Training Loss: 0.2181%\n",
      "Epoch [53/300], Step [187/225], Training Accuracy: 91.3937%, Training Loss: 0.2180%\n",
      "Epoch [53/300], Step [188/225], Training Accuracy: 91.4146%, Training Loss: 0.2174%\n",
      "Epoch [53/300], Step [189/225], Training Accuracy: 91.4269%, Training Loss: 0.2170%\n",
      "Epoch [53/300], Step [190/225], Training Accuracy: 91.4391%, Training Loss: 0.2168%\n",
      "Epoch [53/300], Step [191/225], Training Accuracy: 91.4512%, Training Loss: 0.2168%\n",
      "Epoch [53/300], Step [192/225], Training Accuracy: 91.4307%, Training Loss: 0.2169%\n",
      "Epoch [53/300], Step [193/225], Training Accuracy: 91.3941%, Training Loss: 0.2175%\n",
      "Epoch [53/300], Step [194/225], Training Accuracy: 91.3982%, Training Loss: 0.2177%\n",
      "Epoch [53/300], Step [195/225], Training Accuracy: 91.4263%, Training Loss: 0.2170%\n",
      "Epoch [53/300], Step [196/225], Training Accuracy: 91.4302%, Training Loss: 0.2170%\n",
      "Epoch [53/300], Step [197/225], Training Accuracy: 91.4499%, Training Loss: 0.2165%\n",
      "Epoch [53/300], Step [198/225], Training Accuracy: 91.4694%, Training Loss: 0.2158%\n",
      "Epoch [53/300], Step [199/225], Training Accuracy: 91.4651%, Training Loss: 0.2158%\n",
      "Epoch [53/300], Step [200/225], Training Accuracy: 91.4922%, Training Loss: 0.2155%\n",
      "Epoch [53/300], Step [201/225], Training Accuracy: 91.4723%, Training Loss: 0.2156%\n",
      "Epoch [53/300], Step [202/225], Training Accuracy: 91.4759%, Training Loss: 0.2154%\n",
      "Epoch [53/300], Step [203/225], Training Accuracy: 91.5102%, Training Loss: 0.2148%\n",
      "Epoch [53/300], Step [204/225], Training Accuracy: 91.5365%, Training Loss: 0.2142%\n",
      "Epoch [53/300], Step [205/225], Training Accuracy: 91.5625%, Training Loss: 0.2138%\n",
      "Epoch [53/300], Step [206/225], Training Accuracy: 91.5731%, Training Loss: 0.2138%\n",
      "Epoch [53/300], Step [207/225], Training Accuracy: 91.5836%, Training Loss: 0.2138%\n",
      "Epoch [53/300], Step [208/225], Training Accuracy: 91.5865%, Training Loss: 0.2135%\n",
      "Epoch [53/300], Step [209/225], Training Accuracy: 91.5595%, Training Loss: 0.2138%\n",
      "Epoch [53/300], Step [210/225], Training Accuracy: 91.5551%, Training Loss: 0.2140%\n",
      "Epoch [53/300], Step [211/225], Training Accuracy: 91.5581%, Training Loss: 0.2140%\n",
      "Epoch [53/300], Step [212/225], Training Accuracy: 91.5537%, Training Loss: 0.2140%\n",
      "Epoch [53/300], Step [213/225], Training Accuracy: 91.5713%, Training Loss: 0.2136%\n",
      "Epoch [53/300], Step [214/225], Training Accuracy: 91.5596%, Training Loss: 0.2139%\n",
      "Epoch [53/300], Step [215/225], Training Accuracy: 91.5698%, Training Loss: 0.2136%\n",
      "Epoch [53/300], Step [216/225], Training Accuracy: 91.5726%, Training Loss: 0.2136%\n",
      "Epoch [53/300], Step [217/225], Training Accuracy: 91.5755%, Training Loss: 0.2140%\n",
      "Epoch [53/300], Step [218/225], Training Accuracy: 91.5496%, Training Loss: 0.2140%\n",
      "Epoch [53/300], Step [219/225], Training Accuracy: 91.5525%, Training Loss: 0.2139%\n",
      "Epoch [53/300], Step [220/225], Training Accuracy: 91.5483%, Training Loss: 0.2138%\n",
      "Epoch [53/300], Step [221/225], Training Accuracy: 91.5724%, Training Loss: 0.2133%\n",
      "Epoch [53/300], Step [222/225], Training Accuracy: 91.5611%, Training Loss: 0.2134%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/300], Step [223/225], Training Accuracy: 91.5779%, Training Loss: 0.2132%\n",
      "Epoch [53/300], Step [224/225], Training Accuracy: 91.5876%, Training Loss: 0.2130%\n",
      "Epoch [53/300], Step [225/225], Training Accuracy: 91.5717%, Training Loss: 0.2134%\n",
      "Epoch [54/300], Step [1/225], Training Accuracy: 90.6250%, Training Loss: 0.2466%\n",
      "Epoch [54/300], Step [2/225], Training Accuracy: 89.0625%, Training Loss: 0.2698%\n",
      "Epoch [54/300], Step [3/225], Training Accuracy: 89.5833%, Training Loss: 0.2821%\n",
      "Epoch [54/300], Step [4/225], Training Accuracy: 89.8438%, Training Loss: 0.2891%\n",
      "Epoch [54/300], Step [5/225], Training Accuracy: 90.3125%, Training Loss: 0.2685%\n",
      "Epoch [54/300], Step [6/225], Training Accuracy: 90.8854%, Training Loss: 0.2524%\n",
      "Epoch [54/300], Step [7/225], Training Accuracy: 90.8482%, Training Loss: 0.2461%\n",
      "Epoch [54/300], Step [8/225], Training Accuracy: 90.4297%, Training Loss: 0.2489%\n",
      "Epoch [54/300], Step [9/225], Training Accuracy: 90.6250%, Training Loss: 0.2466%\n",
      "Epoch [54/300], Step [10/225], Training Accuracy: 90.1562%, Training Loss: 0.2558%\n",
      "Epoch [54/300], Step [11/225], Training Accuracy: 90.4830%, Training Loss: 0.2483%\n",
      "Epoch [54/300], Step [12/225], Training Accuracy: 90.8854%, Training Loss: 0.2446%\n",
      "Epoch [54/300], Step [13/225], Training Accuracy: 91.2260%, Training Loss: 0.2409%\n",
      "Epoch [54/300], Step [14/225], Training Accuracy: 91.6295%, Training Loss: 0.2296%\n",
      "Epoch [54/300], Step [15/225], Training Accuracy: 91.8750%, Training Loss: 0.2236%\n",
      "Epoch [54/300], Step [16/225], Training Accuracy: 91.8945%, Training Loss: 0.2229%\n",
      "Epoch [54/300], Step [17/225], Training Accuracy: 91.9118%, Training Loss: 0.2186%\n",
      "Epoch [54/300], Step [18/225], Training Accuracy: 91.4931%, Training Loss: 0.2255%\n",
      "Epoch [54/300], Step [19/225], Training Accuracy: 91.6941%, Training Loss: 0.2203%\n",
      "Epoch [54/300], Step [20/225], Training Accuracy: 91.8750%, Training Loss: 0.2161%\n",
      "Epoch [54/300], Step [21/225], Training Accuracy: 91.9643%, Training Loss: 0.2116%\n",
      "Epoch [54/300], Step [22/225], Training Accuracy: 91.7614%, Training Loss: 0.2135%\n",
      "Epoch [54/300], Step [23/225], Training Accuracy: 91.9158%, Training Loss: 0.2120%\n",
      "Epoch [54/300], Step [24/225], Training Accuracy: 91.9271%, Training Loss: 0.2132%\n",
      "Epoch [54/300], Step [25/225], Training Accuracy: 92.1250%, Training Loss: 0.2093%\n",
      "Epoch [54/300], Step [26/225], Training Accuracy: 92.0673%, Training Loss: 0.2077%\n",
      "Epoch [54/300], Step [27/225], Training Accuracy: 92.1296%, Training Loss: 0.2048%\n",
      "Epoch [54/300], Step [28/225], Training Accuracy: 92.3549%, Training Loss: 0.2004%\n",
      "Epoch [54/300], Step [29/225], Training Accuracy: 92.3491%, Training Loss: 0.2010%\n",
      "Epoch [54/300], Step [30/225], Training Accuracy: 92.4479%, Training Loss: 0.1982%\n",
      "Epoch [54/300], Step [31/225], Training Accuracy: 92.4395%, Training Loss: 0.1982%\n",
      "Epoch [54/300], Step [32/225], Training Accuracy: 92.5781%, Training Loss: 0.1951%\n",
      "Epoch [54/300], Step [33/225], Training Accuracy: 92.5189%, Training Loss: 0.1957%\n",
      "Epoch [54/300], Step [34/225], Training Accuracy: 92.4632%, Training Loss: 0.1967%\n",
      "Epoch [54/300], Step [35/225], Training Accuracy: 92.5000%, Training Loss: 0.1947%\n",
      "Epoch [54/300], Step [36/225], Training Accuracy: 92.6649%, Training Loss: 0.1922%\n",
      "Epoch [54/300], Step [37/225], Training Accuracy: 92.6943%, Training Loss: 0.1909%\n",
      "Epoch [54/300], Step [38/225], Training Accuracy: 92.6398%, Training Loss: 0.1920%\n",
      "Epoch [54/300], Step [39/225], Training Accuracy: 92.5481%, Training Loss: 0.1936%\n",
      "Epoch [54/300], Step [40/225], Training Accuracy: 92.6172%, Training Loss: 0.1924%\n",
      "Epoch [54/300], Step [41/225], Training Accuracy: 92.3780%, Training Loss: 0.1970%\n",
      "Epoch [54/300], Step [42/225], Training Accuracy: 92.3363%, Training Loss: 0.1963%\n",
      "Epoch [54/300], Step [43/225], Training Accuracy: 92.3328%, Training Loss: 0.1989%\n",
      "Epoch [54/300], Step [44/225], Training Accuracy: 92.3651%, Training Loss: 0.1980%\n",
      "Epoch [54/300], Step [45/225], Training Accuracy: 92.3958%, Training Loss: 0.1971%\n",
      "Epoch [54/300], Step [46/225], Training Accuracy: 92.3234%, Training Loss: 0.1976%\n",
      "Epoch [54/300], Step [47/225], Training Accuracy: 92.4202%, Training Loss: 0.1961%\n",
      "Epoch [54/300], Step [48/225], Training Accuracy: 92.3828%, Training Loss: 0.1957%\n",
      "Epoch [54/300], Step [49/225], Training Accuracy: 92.4426%, Training Loss: 0.1955%\n",
      "Epoch [54/300], Step [50/225], Training Accuracy: 92.3438%, Training Loss: 0.1961%\n",
      "Epoch [54/300], Step [51/225], Training Accuracy: 92.3100%, Training Loss: 0.1965%\n",
      "Epoch [54/300], Step [52/225], Training Accuracy: 92.2776%, Training Loss: 0.1957%\n",
      "Epoch [54/300], Step [53/225], Training Accuracy: 92.3349%, Training Loss: 0.1953%\n",
      "Epoch [54/300], Step [54/225], Training Accuracy: 92.3611%, Training Loss: 0.1945%\n",
      "Epoch [54/300], Step [55/225], Training Accuracy: 92.3864%, Training Loss: 0.1947%\n",
      "Epoch [54/300], Step [56/225], Training Accuracy: 92.4107%, Training Loss: 0.1946%\n",
      "Epoch [54/300], Step [57/225], Training Accuracy: 92.3246%, Training Loss: 0.1980%\n",
      "Epoch [54/300], Step [58/225], Training Accuracy: 92.2683%, Training Loss: 0.1984%\n",
      "Epoch [54/300], Step [59/225], Training Accuracy: 92.2934%, Training Loss: 0.1976%\n",
      "Epoch [54/300], Step [60/225], Training Accuracy: 92.3177%, Training Loss: 0.1975%\n",
      "Epoch [54/300], Step [61/225], Training Accuracy: 92.2900%, Training Loss: 0.1981%\n",
      "Epoch [54/300], Step [62/225], Training Accuracy: 92.3135%, Training Loss: 0.1971%\n",
      "Epoch [54/300], Step [63/225], Training Accuracy: 92.3115%, Training Loss: 0.1974%\n",
      "Epoch [54/300], Step [64/225], Training Accuracy: 92.3828%, Training Loss: 0.1971%\n",
      "Epoch [54/300], Step [65/225], Training Accuracy: 92.3077%, Training Loss: 0.1980%\n",
      "Epoch [54/300], Step [66/225], Training Accuracy: 92.3532%, Training Loss: 0.1969%\n",
      "Epoch [54/300], Step [67/225], Training Accuracy: 92.3507%, Training Loss: 0.1970%\n",
      "Epoch [54/300], Step [68/225], Training Accuracy: 92.3024%, Training Loss: 0.1975%\n",
      "Epoch [54/300], Step [69/225], Training Accuracy: 92.2781%, Training Loss: 0.1979%\n",
      "Epoch [54/300], Step [70/225], Training Accuracy: 92.2321%, Training Loss: 0.1986%\n",
      "Epoch [54/300], Step [71/225], Training Accuracy: 92.2535%, Training Loss: 0.1982%\n",
      "Epoch [54/300], Step [72/225], Training Accuracy: 92.2092%, Training Loss: 0.1987%\n",
      "Epoch [54/300], Step [73/225], Training Accuracy: 92.2517%, Training Loss: 0.1980%\n",
      "Epoch [54/300], Step [74/225], Training Accuracy: 92.3142%, Training Loss: 0.1978%\n",
      "Epoch [54/300], Step [75/225], Training Accuracy: 92.3333%, Training Loss: 0.1977%\n",
      "Epoch [54/300], Step [76/225], Training Accuracy: 92.2492%, Training Loss: 0.1986%\n",
      "Epoch [54/300], Step [77/225], Training Accuracy: 92.3093%, Training Loss: 0.1974%\n",
      "Epoch [54/300], Step [78/225], Training Accuracy: 92.3678%, Training Loss: 0.1970%\n",
      "Epoch [54/300], Step [79/225], Training Accuracy: 92.4248%, Training Loss: 0.1961%\n",
      "Epoch [54/300], Step [80/225], Training Accuracy: 92.4609%, Training Loss: 0.1952%\n",
      "Epoch [54/300], Step [81/225], Training Accuracy: 92.5154%, Training Loss: 0.1939%\n",
      "Epoch [54/300], Step [82/225], Training Accuracy: 92.4924%, Training Loss: 0.1940%\n",
      "Epoch [54/300], Step [83/225], Training Accuracy: 92.5075%, Training Loss: 0.1935%\n",
      "Epoch [54/300], Step [84/225], Training Accuracy: 92.5409%, Training Loss: 0.1929%\n",
      "Epoch [54/300], Step [85/225], Training Accuracy: 92.5000%, Training Loss: 0.1927%\n",
      "Epoch [54/300], Step [86/225], Training Accuracy: 92.5327%, Training Loss: 0.1919%\n",
      "Epoch [54/300], Step [87/225], Training Accuracy: 92.5287%, Training Loss: 0.1919%\n",
      "Epoch [54/300], Step [88/225], Training Accuracy: 92.4893%, Training Loss: 0.1940%\n",
      "Epoch [54/300], Step [89/225], Training Accuracy: 92.5035%, Training Loss: 0.1939%\n",
      "Epoch [54/300], Step [90/225], Training Accuracy: 92.4479%, Training Loss: 0.1955%\n",
      "Epoch [54/300], Step [91/225], Training Accuracy: 92.4622%, Training Loss: 0.1952%\n",
      "Epoch [54/300], Step [92/225], Training Accuracy: 92.4592%, Training Loss: 0.1952%\n",
      "Epoch [54/300], Step [93/225], Training Accuracy: 92.4899%, Training Loss: 0.1947%\n",
      "Epoch [54/300], Step [94/225], Training Accuracy: 92.4701%, Training Loss: 0.1951%\n",
      "Epoch [54/300], Step [95/225], Training Accuracy: 92.5000%, Training Loss: 0.1945%\n",
      "Epoch [54/300], Step [96/225], Training Accuracy: 92.5130%, Training Loss: 0.1948%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/300], Step [97/225], Training Accuracy: 92.5258%, Training Loss: 0.1947%\n",
      "Epoch [54/300], Step [98/225], Training Accuracy: 92.5383%, Training Loss: 0.1938%\n",
      "Epoch [54/300], Step [99/225], Training Accuracy: 92.5663%, Training Loss: 0.1933%\n",
      "Epoch [54/300], Step [100/225], Training Accuracy: 92.5000%, Training Loss: 0.1945%\n",
      "Epoch [54/300], Step [101/225], Training Accuracy: 92.4660%, Training Loss: 0.1952%\n",
      "Epoch [54/300], Step [102/225], Training Accuracy: 92.4020%, Training Loss: 0.1958%\n",
      "Epoch [54/300], Step [103/225], Training Accuracy: 92.4302%, Training Loss: 0.1953%\n",
      "Epoch [54/300], Step [104/225], Training Accuracy: 92.4429%, Training Loss: 0.1953%\n",
      "Epoch [54/300], Step [105/225], Training Accuracy: 92.4405%, Training Loss: 0.1954%\n",
      "Epoch [54/300], Step [106/225], Training Accuracy: 92.4381%, Training Loss: 0.1957%\n",
      "Epoch [54/300], Step [107/225], Training Accuracy: 92.4650%, Training Loss: 0.1955%\n",
      "Epoch [54/300], Step [108/225], Training Accuracy: 92.4479%, Training Loss: 0.1959%\n",
      "Epoch [54/300], Step [109/225], Training Accuracy: 92.4312%, Training Loss: 0.1961%\n",
      "Epoch [54/300], Step [110/225], Training Accuracy: 92.4290%, Training Loss: 0.1962%\n",
      "Epoch [54/300], Step [111/225], Training Accuracy: 92.3986%, Training Loss: 0.1972%\n",
      "Epoch [54/300], Step [112/225], Training Accuracy: 92.3689%, Training Loss: 0.1978%\n",
      "Epoch [54/300], Step [113/225], Training Accuracy: 92.3119%, Training Loss: 0.1988%\n",
      "Epoch [54/300], Step [114/225], Training Accuracy: 92.3246%, Training Loss: 0.1989%\n",
      "Epoch [54/300], Step [115/225], Training Accuracy: 92.3234%, Training Loss: 0.1987%\n",
      "Epoch [54/300], Step [116/225], Training Accuracy: 92.2953%, Training Loss: 0.1997%\n",
      "Epoch [54/300], Step [117/225], Training Accuracy: 92.2943%, Training Loss: 0.1996%\n",
      "Epoch [54/300], Step [118/225], Training Accuracy: 92.3067%, Training Loss: 0.1995%\n",
      "Epoch [54/300], Step [119/225], Training Accuracy: 92.2794%, Training Loss: 0.1996%\n",
      "Epoch [54/300], Step [120/225], Training Accuracy: 92.2656%, Training Loss: 0.1998%\n",
      "Epoch [54/300], Step [121/225], Training Accuracy: 92.3037%, Training Loss: 0.1991%\n",
      "Epoch [54/300], Step [122/225], Training Accuracy: 92.3028%, Training Loss: 0.1990%\n",
      "Epoch [54/300], Step [123/225], Training Accuracy: 92.3272%, Training Loss: 0.1983%\n",
      "Epoch [54/300], Step [124/225], Training Accuracy: 92.3639%, Training Loss: 0.1982%\n",
      "Epoch [54/300], Step [125/225], Training Accuracy: 92.4000%, Training Loss: 0.1975%\n",
      "Epoch [54/300], Step [126/225], Training Accuracy: 92.4107%, Training Loss: 0.1977%\n",
      "Epoch [54/300], Step [127/225], Training Accuracy: 92.4459%, Training Loss: 0.1974%\n",
      "Epoch [54/300], Step [128/225], Training Accuracy: 92.4805%, Training Loss: 0.1972%\n",
      "Epoch [54/300], Step [129/225], Training Accuracy: 92.4176%, Training Loss: 0.1982%\n",
      "Epoch [54/300], Step [130/225], Training Accuracy: 92.3798%, Training Loss: 0.1985%\n",
      "Epoch [54/300], Step [131/225], Training Accuracy: 92.3306%, Training Loss: 0.1990%\n",
      "Epoch [54/300], Step [132/225], Training Accuracy: 92.3295%, Training Loss: 0.1988%\n",
      "Epoch [54/300], Step [133/225], Training Accuracy: 92.3285%, Training Loss: 0.1990%\n",
      "Epoch [54/300], Step [134/225], Training Accuracy: 92.3041%, Training Loss: 0.2001%\n",
      "Epoch [54/300], Step [135/225], Training Accuracy: 92.3032%, Training Loss: 0.2001%\n",
      "Epoch [54/300], Step [136/225], Training Accuracy: 92.3139%, Training Loss: 0.2000%\n",
      "Epoch [54/300], Step [137/225], Training Accuracy: 92.3130%, Training Loss: 0.1997%\n",
      "Epoch [54/300], Step [138/225], Training Accuracy: 92.3460%, Training Loss: 0.1990%\n",
      "Epoch [54/300], Step [139/225], Training Accuracy: 92.3449%, Training Loss: 0.1984%\n",
      "Epoch [54/300], Step [140/225], Training Accuracy: 92.3326%, Training Loss: 0.1985%\n",
      "Epoch [54/300], Step [141/225], Training Accuracy: 92.3094%, Training Loss: 0.1990%\n",
      "Epoch [54/300], Step [142/225], Training Accuracy: 92.3305%, Training Loss: 0.1989%\n",
      "Epoch [54/300], Step [143/225], Training Accuracy: 92.3405%, Training Loss: 0.1989%\n",
      "Epoch [54/300], Step [144/225], Training Accuracy: 92.3286%, Training Loss: 0.1991%\n",
      "Epoch [54/300], Step [145/225], Training Accuracy: 92.2845%, Training Loss: 0.1994%\n",
      "Epoch [54/300], Step [146/225], Training Accuracy: 92.2517%, Training Loss: 0.1996%\n",
      "Epoch [54/300], Step [147/225], Training Accuracy: 92.2832%, Training Loss: 0.1992%\n",
      "Epoch [54/300], Step [148/225], Training Accuracy: 92.3142%, Training Loss: 0.1987%\n",
      "Epoch [54/300], Step [149/225], Training Accuracy: 92.3029%, Training Loss: 0.1988%\n",
      "Epoch [54/300], Step [150/225], Training Accuracy: 92.3438%, Training Loss: 0.1979%\n",
      "Epoch [54/300], Step [151/225], Training Accuracy: 92.3531%, Training Loss: 0.1977%\n",
      "Epoch [54/300], Step [152/225], Training Accuracy: 92.3623%, Training Loss: 0.1976%\n",
      "Epoch [54/300], Step [153/225], Training Accuracy: 92.3611%, Training Loss: 0.1977%\n",
      "Epoch [54/300], Step [154/225], Training Accuracy: 92.3701%, Training Loss: 0.1975%\n",
      "Epoch [54/300], Step [155/225], Training Accuracy: 92.3690%, Training Loss: 0.1975%\n",
      "Epoch [54/300], Step [156/225], Training Accuracy: 92.3778%, Training Loss: 0.1972%\n",
      "Epoch [54/300], Step [157/225], Training Accuracy: 92.3268%, Training Loss: 0.1981%\n",
      "Epoch [54/300], Step [158/225], Training Accuracy: 92.3358%, Training Loss: 0.1980%\n",
      "Epoch [54/300], Step [159/225], Training Accuracy: 92.3153%, Training Loss: 0.1984%\n",
      "Epoch [54/300], Step [160/225], Training Accuracy: 92.3145%, Training Loss: 0.1983%\n",
      "Epoch [54/300], Step [161/225], Training Accuracy: 92.2748%, Training Loss: 0.1998%\n",
      "Epoch [54/300], Step [162/225], Training Accuracy: 92.2550%, Training Loss: 0.2000%\n",
      "Epoch [54/300], Step [163/225], Training Accuracy: 92.2354%, Training Loss: 0.2002%\n",
      "Epoch [54/300], Step [164/225], Training Accuracy: 92.2637%, Training Loss: 0.1998%\n",
      "Epoch [54/300], Step [165/225], Training Accuracy: 92.2822%, Training Loss: 0.1995%\n",
      "Epoch [54/300], Step [166/225], Training Accuracy: 92.2628%, Training Loss: 0.1996%\n",
      "Epoch [54/300], Step [167/225], Training Accuracy: 92.2904%, Training Loss: 0.1993%\n",
      "Epoch [54/300], Step [168/225], Training Accuracy: 92.2526%, Training Loss: 0.2003%\n",
      "Epoch [54/300], Step [169/225], Training Accuracy: 92.2245%, Training Loss: 0.2007%\n",
      "Epoch [54/300], Step [170/225], Training Accuracy: 92.2151%, Training Loss: 0.2008%\n",
      "Epoch [54/300], Step [171/225], Training Accuracy: 92.1875%, Training Loss: 0.2016%\n",
      "Epoch [54/300], Step [172/225], Training Accuracy: 92.1875%, Training Loss: 0.2017%\n",
      "Epoch [54/300], Step [173/225], Training Accuracy: 92.2146%, Training Loss: 0.2013%\n",
      "Epoch [54/300], Step [174/225], Training Accuracy: 92.2144%, Training Loss: 0.2009%\n",
      "Epoch [54/300], Step [175/225], Training Accuracy: 92.2143%, Training Loss: 0.2008%\n",
      "Epoch [54/300], Step [176/225], Training Accuracy: 92.2141%, Training Loss: 0.2008%\n",
      "Epoch [54/300], Step [177/225], Training Accuracy: 92.2140%, Training Loss: 0.2005%\n",
      "Epoch [54/300], Step [178/225], Training Accuracy: 92.2226%, Training Loss: 0.2003%\n",
      "Epoch [54/300], Step [179/225], Training Accuracy: 92.2137%, Training Loss: 0.2001%\n",
      "Epoch [54/300], Step [180/225], Training Accuracy: 92.2135%, Training Loss: 0.2004%\n",
      "Epoch [54/300], Step [181/225], Training Accuracy: 92.2220%, Training Loss: 0.2005%\n",
      "Epoch [54/300], Step [182/225], Training Accuracy: 92.2304%, Training Loss: 0.2004%\n",
      "Epoch [54/300], Step [183/225], Training Accuracy: 92.2217%, Training Loss: 0.2004%\n",
      "Epoch [54/300], Step [184/225], Training Accuracy: 92.2215%, Training Loss: 0.2005%\n",
      "Epoch [54/300], Step [185/225], Training Accuracy: 92.2382%, Training Loss: 0.2003%\n",
      "Epoch [54/300], Step [186/225], Training Accuracy: 92.2211%, Training Loss: 0.2003%\n",
      "Epoch [54/300], Step [187/225], Training Accuracy: 92.2209%, Training Loss: 0.2002%\n",
      "Epoch [54/300], Step [188/225], Training Accuracy: 92.2291%, Training Loss: 0.1998%\n",
      "Epoch [54/300], Step [189/225], Training Accuracy: 92.2206%, Training Loss: 0.1998%\n",
      "Epoch [54/300], Step [190/225], Training Accuracy: 92.2368%, Training Loss: 0.1995%\n",
      "Epoch [54/300], Step [191/225], Training Accuracy: 92.2366%, Training Loss: 0.2001%\n",
      "Epoch [54/300], Step [192/225], Training Accuracy: 92.2445%, Training Loss: 0.2000%\n",
      "Epoch [54/300], Step [193/225], Training Accuracy: 92.2361%, Training Loss: 0.2000%\n",
      "Epoch [54/300], Step [194/225], Training Accuracy: 92.2036%, Training Loss: 0.2005%\n",
      "Epoch [54/300], Step [195/225], Training Accuracy: 92.2035%, Training Loss: 0.2008%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/300], Step [196/225], Training Accuracy: 92.2114%, Training Loss: 0.2007%\n",
      "Epoch [54/300], Step [197/225], Training Accuracy: 92.2272%, Training Loss: 0.2003%\n",
      "Epoch [54/300], Step [198/225], Training Accuracy: 92.2506%, Training Loss: 0.1997%\n",
      "Epoch [54/300], Step [199/225], Training Accuracy: 92.2346%, Training Loss: 0.2000%\n",
      "Epoch [54/300], Step [200/225], Training Accuracy: 92.2656%, Training Loss: 0.1995%\n",
      "Epoch [54/300], Step [201/225], Training Accuracy: 92.2886%, Training Loss: 0.1993%\n",
      "Epoch [54/300], Step [202/225], Training Accuracy: 92.2881%, Training Loss: 0.1993%\n",
      "Epoch [54/300], Step [203/225], Training Accuracy: 92.3183%, Training Loss: 0.1988%\n",
      "Epoch [54/300], Step [204/225], Training Accuracy: 92.3330%, Training Loss: 0.1986%\n",
      "Epoch [54/300], Step [205/225], Training Accuracy: 92.3476%, Training Loss: 0.1983%\n",
      "Epoch [54/300], Step [206/225], Training Accuracy: 92.3544%, Training Loss: 0.1985%\n",
      "Epoch [54/300], Step [207/225], Training Accuracy: 92.3385%, Training Loss: 0.1989%\n",
      "Epoch [54/300], Step [208/225], Training Accuracy: 92.3453%, Training Loss: 0.1991%\n",
      "Epoch [54/300], Step [209/225], Training Accuracy: 92.3146%, Training Loss: 0.1998%\n",
      "Epoch [54/300], Step [210/225], Training Accuracy: 92.3140%, Training Loss: 0.1997%\n",
      "Epoch [54/300], Step [211/225], Training Accuracy: 92.3208%, Training Loss: 0.1997%\n",
      "Epoch [54/300], Step [212/225], Training Accuracy: 92.2907%, Training Loss: 0.1998%\n",
      "Epoch [54/300], Step [213/225], Training Accuracy: 92.3122%, Training Loss: 0.1994%\n",
      "Epoch [54/300], Step [214/225], Training Accuracy: 92.3116%, Training Loss: 0.1996%\n",
      "Epoch [54/300], Step [215/225], Training Accuracy: 92.3256%, Training Loss: 0.1991%\n",
      "Epoch [54/300], Step [216/225], Training Accuracy: 92.3394%, Training Loss: 0.1987%\n",
      "Epoch [54/300], Step [217/225], Training Accuracy: 92.3387%, Training Loss: 0.1989%\n",
      "Epoch [54/300], Step [218/225], Training Accuracy: 92.3452%, Training Loss: 0.1987%\n",
      "Epoch [54/300], Step [219/225], Training Accuracy: 92.3445%, Training Loss: 0.1986%\n",
      "Epoch [54/300], Step [220/225], Training Accuracy: 92.3509%, Training Loss: 0.1987%\n",
      "Epoch [54/300], Step [221/225], Training Accuracy: 92.3713%, Training Loss: 0.1983%\n",
      "Epoch [54/300], Step [222/225], Training Accuracy: 92.3846%, Training Loss: 0.1981%\n",
      "Epoch [54/300], Step [223/225], Training Accuracy: 92.3767%, Training Loss: 0.1981%\n",
      "Epoch [54/300], Step [224/225], Training Accuracy: 92.3410%, Training Loss: 0.1986%\n",
      "Epoch [54/300], Step [225/225], Training Accuracy: 92.3499%, Training Loss: 0.1982%\n",
      "Epoch [55/300], Step [1/225], Training Accuracy: 90.6250%, Training Loss: 0.2141%\n",
      "Epoch [55/300], Step [2/225], Training Accuracy: 89.0625%, Training Loss: 0.2497%\n",
      "Epoch [55/300], Step [3/225], Training Accuracy: 91.1458%, Training Loss: 0.2232%\n",
      "Epoch [55/300], Step [4/225], Training Accuracy: 91.0156%, Training Loss: 0.2280%\n",
      "Epoch [55/300], Step [5/225], Training Accuracy: 91.5625%, Training Loss: 0.2165%\n",
      "Epoch [55/300], Step [6/225], Training Accuracy: 91.6667%, Training Loss: 0.2160%\n",
      "Epoch [55/300], Step [7/225], Training Accuracy: 91.7411%, Training Loss: 0.2126%\n",
      "Epoch [55/300], Step [8/225], Training Accuracy: 90.2344%, Training Loss: 0.2467%\n",
      "Epoch [55/300], Step [9/225], Training Accuracy: 90.4514%, Training Loss: 0.2409%\n",
      "Epoch [55/300], Step [10/225], Training Accuracy: 90.1562%, Training Loss: 0.2501%\n",
      "Epoch [55/300], Step [11/225], Training Accuracy: 90.1989%, Training Loss: 0.2448%\n",
      "Epoch [55/300], Step [12/225], Training Accuracy: 90.7552%, Training Loss: 0.2321%\n",
      "Epoch [55/300], Step [13/225], Training Accuracy: 91.1058%, Training Loss: 0.2244%\n",
      "Epoch [55/300], Step [14/225], Training Accuracy: 91.4062%, Training Loss: 0.2163%\n",
      "Epoch [55/300], Step [15/225], Training Accuracy: 91.5625%, Training Loss: 0.2130%\n",
      "Epoch [55/300], Step [16/225], Training Accuracy: 91.5039%, Training Loss: 0.2125%\n",
      "Epoch [55/300], Step [17/225], Training Accuracy: 91.5441%, Training Loss: 0.2117%\n",
      "Epoch [55/300], Step [18/225], Training Accuracy: 91.6667%, Training Loss: 0.2110%\n",
      "Epoch [55/300], Step [19/225], Training Accuracy: 91.5296%, Training Loss: 0.2134%\n",
      "Epoch [55/300], Step [20/225], Training Accuracy: 91.7969%, Training Loss: 0.2094%\n",
      "Epoch [55/300], Step [21/225], Training Accuracy: 92.1131%, Training Loss: 0.2049%\n",
      "Epoch [55/300], Step [22/225], Training Accuracy: 92.3295%, Training Loss: 0.2033%\n",
      "Epoch [55/300], Step [23/225], Training Accuracy: 92.4592%, Training Loss: 0.1998%\n",
      "Epoch [55/300], Step [24/225], Training Accuracy: 92.4479%, Training Loss: 0.2000%\n",
      "Epoch [55/300], Step [25/225], Training Accuracy: 92.6250%, Training Loss: 0.1962%\n",
      "Epoch [55/300], Step [26/225], Training Accuracy: 92.7885%, Training Loss: 0.1911%\n",
      "Epoch [55/300], Step [27/225], Training Accuracy: 92.9398%, Training Loss: 0.1889%\n",
      "Epoch [55/300], Step [28/225], Training Accuracy: 92.9688%, Training Loss: 0.1869%\n",
      "Epoch [55/300], Step [29/225], Training Accuracy: 93.0496%, Training Loss: 0.1879%\n",
      "Epoch [55/300], Step [30/225], Training Accuracy: 93.0729%, Training Loss: 0.1856%\n",
      "Epoch [55/300], Step [31/225], Training Accuracy: 92.9435%, Training Loss: 0.1870%\n",
      "Epoch [55/300], Step [32/225], Training Accuracy: 93.0664%, Training Loss: 0.1838%\n",
      "Epoch [55/300], Step [33/225], Training Accuracy: 92.9924%, Training Loss: 0.1844%\n",
      "Epoch [55/300], Step [34/225], Training Accuracy: 92.8768%, Training Loss: 0.1860%\n",
      "Epoch [55/300], Step [35/225], Training Accuracy: 92.9018%, Training Loss: 0.1841%\n",
      "Epoch [55/300], Step [36/225], Training Accuracy: 92.7951%, Training Loss: 0.1847%\n",
      "Epoch [55/300], Step [37/225], Training Accuracy: 92.7365%, Training Loss: 0.1868%\n",
      "Epoch [55/300], Step [38/225], Training Accuracy: 92.5987%, Training Loss: 0.1885%\n",
      "Epoch [55/300], Step [39/225], Training Accuracy: 92.5080%, Training Loss: 0.1895%\n",
      "Epoch [55/300], Step [40/225], Training Accuracy: 92.4609%, Training Loss: 0.1895%\n",
      "Epoch [55/300], Step [41/225], Training Accuracy: 92.3399%, Training Loss: 0.1940%\n",
      "Epoch [55/300], Step [42/225], Training Accuracy: 92.2619%, Training Loss: 0.1972%\n",
      "Epoch [55/300], Step [43/225], Training Accuracy: 92.2238%, Training Loss: 0.1983%\n",
      "Epoch [55/300], Step [44/225], Training Accuracy: 92.2940%, Training Loss: 0.1970%\n",
      "Epoch [55/300], Step [45/225], Training Accuracy: 92.3264%, Training Loss: 0.1952%\n",
      "Epoch [55/300], Step [46/225], Training Accuracy: 92.3573%, Training Loss: 0.1939%\n",
      "Epoch [55/300], Step [47/225], Training Accuracy: 92.3537%, Training Loss: 0.1956%\n",
      "Epoch [55/300], Step [48/225], Training Accuracy: 92.1875%, Training Loss: 0.1983%\n",
      "Epoch [55/300], Step [49/225], Training Accuracy: 92.0599%, Training Loss: 0.2000%\n",
      "Epoch [55/300], Step [50/225], Training Accuracy: 92.0312%, Training Loss: 0.2008%\n",
      "Epoch [55/300], Step [51/225], Training Accuracy: 92.0650%, Training Loss: 0.1998%\n",
      "Epoch [55/300], Step [52/225], Training Accuracy: 92.1575%, Training Loss: 0.1977%\n",
      "Epoch [55/300], Step [53/225], Training Accuracy: 92.2170%, Training Loss: 0.1967%\n",
      "Epoch [55/300], Step [54/225], Training Accuracy: 92.2164%, Training Loss: 0.1964%\n",
      "Epoch [55/300], Step [55/225], Training Accuracy: 92.3011%, Training Loss: 0.1966%\n",
      "Epoch [55/300], Step [56/225], Training Accuracy: 92.2991%, Training Loss: 0.1962%\n",
      "Epoch [55/300], Step [57/225], Training Accuracy: 92.2149%, Training Loss: 0.1980%\n",
      "Epoch [55/300], Step [58/225], Training Accuracy: 92.2144%, Training Loss: 0.1976%\n",
      "Epoch [55/300], Step [59/225], Training Accuracy: 92.1875%, Training Loss: 0.1978%\n",
      "Epoch [55/300], Step [60/225], Training Accuracy: 92.1094%, Training Loss: 0.1990%\n",
      "Epoch [55/300], Step [61/225], Training Accuracy: 92.1107%, Training Loss: 0.1991%\n",
      "Epoch [55/300], Step [62/225], Training Accuracy: 92.1623%, Training Loss: 0.1984%\n",
      "Epoch [55/300], Step [63/225], Training Accuracy: 92.1627%, Training Loss: 0.1978%\n",
      "Epoch [55/300], Step [64/225], Training Accuracy: 92.2363%, Training Loss: 0.1980%\n",
      "Epoch [55/300], Step [65/225], Training Accuracy: 92.3077%, Training Loss: 0.1970%\n",
      "Epoch [55/300], Step [66/225], Training Accuracy: 92.3532%, Training Loss: 0.1957%\n",
      "Epoch [55/300], Step [67/225], Training Accuracy: 92.3974%, Training Loss: 0.1946%\n",
      "Epoch [55/300], Step [68/225], Training Accuracy: 92.3483%, Training Loss: 0.1963%\n",
      "Epoch [55/300], Step [69/225], Training Accuracy: 92.3913%, Training Loss: 0.1948%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/300], Step [70/225], Training Accuracy: 92.4107%, Training Loss: 0.1951%\n",
      "Epoch [55/300], Step [71/225], Training Accuracy: 92.3856%, Training Loss: 0.1946%\n",
      "Epoch [55/300], Step [72/225], Training Accuracy: 92.3394%, Training Loss: 0.1945%\n",
      "Epoch [55/300], Step [73/225], Training Accuracy: 92.3801%, Training Loss: 0.1942%\n",
      "Epoch [55/300], Step [74/225], Training Accuracy: 92.3353%, Training Loss: 0.1949%\n",
      "Epoch [55/300], Step [75/225], Training Accuracy: 92.3958%, Training Loss: 0.1941%\n",
      "Epoch [55/300], Step [76/225], Training Accuracy: 92.3520%, Training Loss: 0.1950%\n",
      "Epoch [55/300], Step [77/225], Training Accuracy: 92.4107%, Training Loss: 0.1939%\n",
      "Epoch [55/300], Step [78/225], Training Accuracy: 92.4279%, Training Loss: 0.1943%\n",
      "Epoch [55/300], Step [79/225], Training Accuracy: 92.4842%, Training Loss: 0.1929%\n",
      "Epoch [55/300], Step [80/225], Training Accuracy: 92.4414%, Training Loss: 0.1935%\n",
      "Epoch [55/300], Step [81/225], Training Accuracy: 92.4576%, Training Loss: 0.1928%\n",
      "Epoch [55/300], Step [82/225], Training Accuracy: 92.4352%, Training Loss: 0.1924%\n",
      "Epoch [55/300], Step [83/225], Training Accuracy: 92.4322%, Training Loss: 0.1922%\n",
      "Epoch [55/300], Step [84/225], Training Accuracy: 92.4293%, Training Loss: 0.1922%\n",
      "Epoch [55/300], Step [85/225], Training Accuracy: 92.4449%, Training Loss: 0.1913%\n",
      "Epoch [55/300], Step [86/225], Training Accuracy: 92.5145%, Training Loss: 0.1903%\n",
      "Epoch [55/300], Step [87/225], Training Accuracy: 92.5287%, Training Loss: 0.1908%\n",
      "Epoch [55/300], Step [88/225], Training Accuracy: 92.4716%, Training Loss: 0.1919%\n",
      "Epoch [55/300], Step [89/225], Training Accuracy: 92.4860%, Training Loss: 0.1915%\n",
      "Epoch [55/300], Step [90/225], Training Accuracy: 92.4653%, Training Loss: 0.1920%\n",
      "Epoch [55/300], Step [91/225], Training Accuracy: 92.4966%, Training Loss: 0.1913%\n",
      "Epoch [55/300], Step [92/225], Training Accuracy: 92.4592%, Training Loss: 0.1921%\n",
      "Epoch [55/300], Step [93/225], Training Accuracy: 92.4899%, Training Loss: 0.1910%\n",
      "Epoch [55/300], Step [94/225], Training Accuracy: 92.5033%, Training Loss: 0.1908%\n",
      "Epoch [55/300], Step [95/225], Training Accuracy: 92.5329%, Training Loss: 0.1900%\n",
      "Epoch [55/300], Step [96/225], Training Accuracy: 92.5293%, Training Loss: 0.1899%\n",
      "Epoch [55/300], Step [97/225], Training Accuracy: 92.5258%, Training Loss: 0.1903%\n",
      "Epoch [55/300], Step [98/225], Training Accuracy: 92.5542%, Training Loss: 0.1903%\n",
      "Epoch [55/300], Step [99/225], Training Accuracy: 92.5821%, Training Loss: 0.1900%\n",
      "Epoch [55/300], Step [100/225], Training Accuracy: 92.5469%, Training Loss: 0.1909%\n",
      "Epoch [55/300], Step [101/225], Training Accuracy: 92.5588%, Training Loss: 0.1901%\n",
      "Epoch [55/300], Step [102/225], Training Accuracy: 92.5705%, Training Loss: 0.1906%\n",
      "Epoch [55/300], Step [103/225], Training Accuracy: 92.5971%, Training Loss: 0.1901%\n",
      "Epoch [55/300], Step [104/225], Training Accuracy: 92.6232%, Training Loss: 0.1895%\n",
      "Epoch [55/300], Step [105/225], Training Accuracy: 92.6190%, Training Loss: 0.1892%\n",
      "Epoch [55/300], Step [106/225], Training Accuracy: 92.5855%, Training Loss: 0.1899%\n",
      "Epoch [55/300], Step [107/225], Training Accuracy: 92.5672%, Training Loss: 0.1902%\n",
      "Epoch [55/300], Step [108/225], Training Accuracy: 92.5347%, Training Loss: 0.1906%\n",
      "Epoch [55/300], Step [109/225], Training Accuracy: 92.5315%, Training Loss: 0.1910%\n",
      "Epoch [55/300], Step [110/225], Training Accuracy: 92.5284%, Training Loss: 0.1913%\n",
      "Epoch [55/300], Step [111/225], Training Accuracy: 92.5816%, Training Loss: 0.1907%\n",
      "Epoch [55/300], Step [112/225], Training Accuracy: 92.5781%, Training Loss: 0.1905%\n",
      "Epoch [55/300], Step [113/225], Training Accuracy: 92.6023%, Training Loss: 0.1902%\n",
      "Epoch [55/300], Step [114/225], Training Accuracy: 92.6261%, Training Loss: 0.1899%\n",
      "Epoch [55/300], Step [115/225], Training Accuracy: 92.6495%, Training Loss: 0.1895%\n",
      "Epoch [55/300], Step [116/225], Training Accuracy: 92.6320%, Training Loss: 0.1899%\n",
      "Epoch [55/300], Step [117/225], Training Accuracy: 92.6416%, Training Loss: 0.1899%\n",
      "Epoch [55/300], Step [118/225], Training Accuracy: 92.6377%, Training Loss: 0.1903%\n",
      "Epoch [55/300], Step [119/225], Training Accuracy: 92.6339%, Training Loss: 0.1899%\n",
      "Epoch [55/300], Step [120/225], Training Accuracy: 92.6042%, Training Loss: 0.1907%\n",
      "Epoch [55/300], Step [121/225], Training Accuracy: 92.6007%, Training Loss: 0.1903%\n",
      "Epoch [55/300], Step [122/225], Training Accuracy: 92.6230%, Training Loss: 0.1905%\n",
      "Epoch [55/300], Step [123/225], Training Accuracy: 92.6448%, Training Loss: 0.1898%\n",
      "Epoch [55/300], Step [124/225], Training Accuracy: 92.6537%, Training Loss: 0.1893%\n",
      "Epoch [55/300], Step [125/225], Training Accuracy: 92.6625%, Training Loss: 0.1890%\n",
      "Epoch [55/300], Step [126/225], Training Accuracy: 92.6587%, Training Loss: 0.1891%\n",
      "Epoch [55/300], Step [127/225], Training Accuracy: 92.6550%, Training Loss: 0.1892%\n",
      "Epoch [55/300], Step [128/225], Training Accuracy: 92.6880%, Training Loss: 0.1885%\n",
      "Epoch [55/300], Step [129/225], Training Accuracy: 92.6599%, Training Loss: 0.1889%\n",
      "Epoch [55/300], Step [130/225], Training Accuracy: 92.6562%, Training Loss: 0.1892%\n",
      "Epoch [55/300], Step [131/225], Training Accuracy: 92.6169%, Training Loss: 0.1902%\n",
      "Epoch [55/300], Step [132/225], Training Accuracy: 92.6136%, Training Loss: 0.1906%\n",
      "Epoch [55/300], Step [133/225], Training Accuracy: 92.6339%, Training Loss: 0.1901%\n",
      "Epoch [55/300], Step [134/225], Training Accuracy: 92.5840%, Training Loss: 0.1910%\n",
      "Epoch [55/300], Step [135/225], Training Accuracy: 92.6157%, Training Loss: 0.1903%\n",
      "Epoch [55/300], Step [136/225], Training Accuracy: 92.6126%, Training Loss: 0.1907%\n",
      "Epoch [55/300], Step [137/225], Training Accuracy: 92.5981%, Training Loss: 0.1910%\n",
      "Epoch [55/300], Step [138/225], Training Accuracy: 92.5611%, Training Loss: 0.1911%\n",
      "Epoch [55/300], Step [139/225], Training Accuracy: 92.5922%, Training Loss: 0.1906%\n",
      "Epoch [55/300], Step [140/225], Training Accuracy: 92.5670%, Training Loss: 0.1911%\n",
      "Epoch [55/300], Step [141/225], Training Accuracy: 92.5975%, Training Loss: 0.1905%\n",
      "Epoch [55/300], Step [142/225], Training Accuracy: 92.5946%, Training Loss: 0.1906%\n",
      "Epoch [55/300], Step [143/225], Training Accuracy: 92.5809%, Training Loss: 0.1906%\n",
      "Epoch [55/300], Step [144/225], Training Accuracy: 92.5890%, Training Loss: 0.1905%\n",
      "Epoch [55/300], Step [145/225], Training Accuracy: 92.5647%, Training Loss: 0.1909%\n",
      "Epoch [55/300], Step [146/225], Training Accuracy: 92.5300%, Training Loss: 0.1912%\n",
      "Epoch [55/300], Step [147/225], Training Accuracy: 92.5064%, Training Loss: 0.1915%\n",
      "Epoch [55/300], Step [148/225], Training Accuracy: 92.5359%, Training Loss: 0.1912%\n",
      "Epoch [55/300], Step [149/225], Training Accuracy: 92.5650%, Training Loss: 0.1910%\n",
      "Epoch [55/300], Step [150/225], Training Accuracy: 92.5729%, Training Loss: 0.1906%\n",
      "Epoch [55/300], Step [151/225], Training Accuracy: 92.5704%, Training Loss: 0.1905%\n",
      "Epoch [55/300], Step [152/225], Training Accuracy: 92.5884%, Training Loss: 0.1902%\n",
      "Epoch [55/300], Step [153/225], Training Accuracy: 92.5756%, Training Loss: 0.1908%\n",
      "Epoch [55/300], Step [154/225], Training Accuracy: 92.5629%, Training Loss: 0.1908%\n",
      "Epoch [55/300], Step [155/225], Training Accuracy: 92.5302%, Training Loss: 0.1911%\n",
      "Epoch [55/300], Step [156/225], Training Accuracy: 92.5481%, Training Loss: 0.1907%\n",
      "Epoch [55/300], Step [157/225], Training Accuracy: 92.5458%, Training Loss: 0.1910%\n",
      "Epoch [55/300], Step [158/225], Training Accuracy: 92.5732%, Training Loss: 0.1907%\n",
      "Epoch [55/300], Step [159/225], Training Accuracy: 92.5609%, Training Loss: 0.1909%\n",
      "Epoch [55/300], Step [160/225], Training Accuracy: 92.5391%, Training Loss: 0.1910%\n",
      "Epoch [55/300], Step [161/225], Training Accuracy: 92.5369%, Training Loss: 0.1911%\n",
      "Epoch [55/300], Step [162/225], Training Accuracy: 92.5154%, Training Loss: 0.1916%\n",
      "Epoch [55/300], Step [163/225], Training Accuracy: 92.5134%, Training Loss: 0.1914%\n",
      "Epoch [55/300], Step [164/225], Training Accuracy: 92.5210%, Training Loss: 0.1908%\n",
      "Epoch [55/300], Step [165/225], Training Accuracy: 92.4811%, Training Loss: 0.1913%\n",
      "Epoch [55/300], Step [166/225], Training Accuracy: 92.4416%, Training Loss: 0.1916%\n",
      "Epoch [55/300], Step [167/225], Training Accuracy: 92.4495%, Training Loss: 0.1920%\n",
      "Epoch [55/300], Step [168/225], Training Accuracy: 92.4572%, Training Loss: 0.1924%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/300], Step [169/225], Training Accuracy: 92.4649%, Training Loss: 0.1920%\n",
      "Epoch [55/300], Step [170/225], Training Accuracy: 92.4449%, Training Loss: 0.1921%\n",
      "Epoch [55/300], Step [171/225], Training Accuracy: 92.4159%, Training Loss: 0.1926%\n",
      "Epoch [55/300], Step [172/225], Training Accuracy: 92.3874%, Training Loss: 0.1932%\n",
      "Epoch [55/300], Step [173/225], Training Accuracy: 92.4043%, Training Loss: 0.1928%\n",
      "Epoch [55/300], Step [174/225], Training Accuracy: 92.3940%, Training Loss: 0.1927%\n",
      "Epoch [55/300], Step [175/225], Training Accuracy: 92.3929%, Training Loss: 0.1927%\n",
      "Epoch [55/300], Step [176/225], Training Accuracy: 92.4183%, Training Loss: 0.1920%\n",
      "Epoch [55/300], Step [177/225], Training Accuracy: 92.4258%, Training Loss: 0.1919%\n",
      "Epoch [55/300], Step [178/225], Training Accuracy: 92.4421%, Training Loss: 0.1916%\n",
      "Epoch [55/300], Step [179/225], Training Accuracy: 92.3883%, Training Loss: 0.1921%\n",
      "Epoch [55/300], Step [180/225], Training Accuracy: 92.3872%, Training Loss: 0.1918%\n",
      "Epoch [55/300], Step [181/225], Training Accuracy: 92.3947%, Training Loss: 0.1919%\n",
      "Epoch [55/300], Step [182/225], Training Accuracy: 92.4193%, Training Loss: 0.1914%\n",
      "Epoch [55/300], Step [183/225], Training Accuracy: 92.3924%, Training Loss: 0.1917%\n",
      "Epoch [55/300], Step [184/225], Training Accuracy: 92.3828%, Training Loss: 0.1917%\n",
      "Epoch [55/300], Step [185/225], Training Accuracy: 92.3818%, Training Loss: 0.1918%\n",
      "Epoch [55/300], Step [186/225], Training Accuracy: 92.4059%, Training Loss: 0.1912%\n",
      "Epoch [55/300], Step [187/225], Training Accuracy: 92.4131%, Training Loss: 0.1909%\n",
      "Epoch [55/300], Step [188/225], Training Accuracy: 92.4036%, Training Loss: 0.1910%\n",
      "Epoch [55/300], Step [189/225], Training Accuracy: 92.4107%, Training Loss: 0.1908%\n",
      "Epoch [55/300], Step [190/225], Training Accuracy: 92.4424%, Training Loss: 0.1903%\n",
      "Epoch [55/300], Step [191/225], Training Accuracy: 92.4738%, Training Loss: 0.1901%\n",
      "Epoch [55/300], Step [192/225], Training Accuracy: 92.4805%, Training Loss: 0.1899%\n",
      "Epoch [55/300], Step [193/225], Training Accuracy: 92.4709%, Training Loss: 0.1900%\n",
      "Epoch [55/300], Step [194/225], Training Accuracy: 92.4211%, Training Loss: 0.1909%\n",
      "Epoch [55/300], Step [195/225], Training Accuracy: 92.4359%, Training Loss: 0.1907%\n",
      "Epoch [55/300], Step [196/225], Training Accuracy: 92.4267%, Training Loss: 0.1909%\n",
      "Epoch [55/300], Step [197/225], Training Accuracy: 92.4254%, Training Loss: 0.1907%\n",
      "Epoch [55/300], Step [198/225], Training Accuracy: 92.4321%, Training Loss: 0.1906%\n",
      "Epoch [55/300], Step [199/225], Training Accuracy: 92.4309%, Training Loss: 0.1912%\n",
      "Epoch [55/300], Step [200/225], Training Accuracy: 92.4297%, Training Loss: 0.1913%\n",
      "Epoch [55/300], Step [201/225], Training Accuracy: 92.4052%, Training Loss: 0.1915%\n",
      "Epoch [55/300], Step [202/225], Training Accuracy: 92.4041%, Training Loss: 0.1916%\n",
      "Epoch [55/300], Step [203/225], Training Accuracy: 92.4107%, Training Loss: 0.1917%\n",
      "Epoch [55/300], Step [204/225], Training Accuracy: 92.4096%, Training Loss: 0.1922%\n",
      "Epoch [55/300], Step [205/225], Training Accuracy: 92.4314%, Training Loss: 0.1919%\n",
      "Epoch [55/300], Step [206/225], Training Accuracy: 92.4226%, Training Loss: 0.1924%\n",
      "Epoch [55/300], Step [207/225], Training Accuracy: 92.4215%, Training Loss: 0.1924%\n",
      "Epoch [55/300], Step [208/225], Training Accuracy: 92.4504%, Training Loss: 0.1918%\n",
      "Epoch [55/300], Step [209/225], Training Accuracy: 92.4342%, Training Loss: 0.1922%\n",
      "Epoch [55/300], Step [210/225], Training Accuracy: 92.4256%, Training Loss: 0.1925%\n",
      "Epoch [55/300], Step [211/225], Training Accuracy: 92.4393%, Training Loss: 0.1924%\n",
      "Epoch [55/300], Step [212/225], Training Accuracy: 92.4307%, Training Loss: 0.1925%\n",
      "Epoch [55/300], Step [213/225], Training Accuracy: 92.4296%, Training Loss: 0.1924%\n",
      "Epoch [55/300], Step [214/225], Training Accuracy: 92.4357%, Training Loss: 0.1923%\n",
      "Epoch [55/300], Step [215/225], Training Accuracy: 92.4491%, Training Loss: 0.1920%\n",
      "Epoch [55/300], Step [216/225], Training Accuracy: 92.4696%, Training Loss: 0.1918%\n",
      "Epoch [55/300], Step [217/225], Training Accuracy: 92.4683%, Training Loss: 0.1916%\n",
      "Epoch [55/300], Step [218/225], Training Accuracy: 92.4312%, Training Loss: 0.1919%\n",
      "Epoch [55/300], Step [219/225], Training Accuracy: 92.4443%, Training Loss: 0.1915%\n",
      "Epoch [55/300], Step [220/225], Training Accuracy: 92.4432%, Training Loss: 0.1918%\n",
      "Epoch [55/300], Step [221/225], Training Accuracy: 92.4703%, Training Loss: 0.1913%\n",
      "Epoch [55/300], Step [222/225], Training Accuracy: 92.4761%, Training Loss: 0.1911%\n",
      "Epoch [55/300], Step [223/225], Training Accuracy: 92.4888%, Training Loss: 0.1909%\n",
      "Epoch [55/300], Step [224/225], Training Accuracy: 92.5084%, Training Loss: 0.1907%\n",
      "Epoch [55/300], Step [225/225], Training Accuracy: 92.5167%, Training Loss: 0.1906%\n",
      "Epoch [56/300], Step [1/225], Training Accuracy: 89.0625%, Training Loss: 0.2459%\n",
      "Epoch [56/300], Step [2/225], Training Accuracy: 89.0625%, Training Loss: 0.2659%\n",
      "Epoch [56/300], Step [3/225], Training Accuracy: 89.0625%, Training Loss: 0.2600%\n",
      "Epoch [56/300], Step [4/225], Training Accuracy: 89.0625%, Training Loss: 0.2457%\n",
      "Epoch [56/300], Step [5/225], Training Accuracy: 89.3750%, Training Loss: 0.2301%\n",
      "Epoch [56/300], Step [6/225], Training Accuracy: 90.6250%, Training Loss: 0.2203%\n",
      "Epoch [56/300], Step [7/225], Training Accuracy: 90.6250%, Training Loss: 0.2245%\n",
      "Epoch [56/300], Step [8/225], Training Accuracy: 90.0391%, Training Loss: 0.2402%\n",
      "Epoch [56/300], Step [9/225], Training Accuracy: 89.7569%, Training Loss: 0.2601%\n",
      "Epoch [56/300], Step [10/225], Training Accuracy: 89.6875%, Training Loss: 0.2637%\n",
      "Epoch [56/300], Step [11/225], Training Accuracy: 89.7727%, Training Loss: 0.2551%\n",
      "Epoch [56/300], Step [12/225], Training Accuracy: 90.2344%, Training Loss: 0.2455%\n",
      "Epoch [56/300], Step [13/225], Training Accuracy: 90.5048%, Training Loss: 0.2366%\n",
      "Epoch [56/300], Step [14/225], Training Accuracy: 90.7366%, Training Loss: 0.2324%\n",
      "Epoch [56/300], Step [15/225], Training Accuracy: 90.8333%, Training Loss: 0.2357%\n",
      "Epoch [56/300], Step [16/225], Training Accuracy: 90.7227%, Training Loss: 0.2387%\n",
      "Epoch [56/300], Step [17/225], Training Accuracy: 90.9007%, Training Loss: 0.2325%\n",
      "Epoch [56/300], Step [18/225], Training Accuracy: 91.1458%, Training Loss: 0.2257%\n",
      "Epoch [56/300], Step [19/225], Training Accuracy: 91.3651%, Training Loss: 0.2233%\n",
      "Epoch [56/300], Step [20/225], Training Accuracy: 91.5625%, Training Loss: 0.2186%\n",
      "Epoch [56/300], Step [21/225], Training Accuracy: 91.7411%, Training Loss: 0.2149%\n",
      "Epoch [56/300], Step [22/225], Training Accuracy: 91.5483%, Training Loss: 0.2192%\n",
      "Epoch [56/300], Step [23/225], Training Accuracy: 91.5082%, Training Loss: 0.2174%\n",
      "Epoch [56/300], Step [24/225], Training Accuracy: 91.4062%, Training Loss: 0.2199%\n",
      "Epoch [56/300], Step [25/225], Training Accuracy: 91.5625%, Training Loss: 0.2156%\n",
      "Epoch [56/300], Step [26/225], Training Accuracy: 91.8269%, Training Loss: 0.2110%\n",
      "Epoch [56/300], Step [27/225], Training Accuracy: 91.8981%, Training Loss: 0.2075%\n",
      "Epoch [56/300], Step [28/225], Training Accuracy: 92.0759%, Training Loss: 0.2030%\n",
      "Epoch [56/300], Step [29/225], Training Accuracy: 92.0259%, Training Loss: 0.2025%\n",
      "Epoch [56/300], Step [30/225], Training Accuracy: 92.1354%, Training Loss: 0.2002%\n",
      "Epoch [56/300], Step [31/225], Training Accuracy: 92.1371%, Training Loss: 0.2020%\n",
      "Epoch [56/300], Step [32/225], Training Accuracy: 92.2852%, Training Loss: 0.1992%\n",
      "Epoch [56/300], Step [33/225], Training Accuracy: 92.1402%, Training Loss: 0.2003%\n",
      "Epoch [56/300], Step [34/225], Training Accuracy: 92.1415%, Training Loss: 0.2007%\n",
      "Epoch [56/300], Step [35/225], Training Accuracy: 92.2321%, Training Loss: 0.1987%\n",
      "Epoch [56/300], Step [36/225], Training Accuracy: 92.4479%, Training Loss: 0.1950%\n",
      "Epoch [56/300], Step [37/225], Training Accuracy: 92.4831%, Training Loss: 0.1938%\n",
      "Epoch [56/300], Step [38/225], Training Accuracy: 92.5164%, Training Loss: 0.1935%\n",
      "Epoch [56/300], Step [39/225], Training Accuracy: 92.4679%, Training Loss: 0.1945%\n",
      "Epoch [56/300], Step [40/225], Training Accuracy: 92.4609%, Training Loss: 0.1952%\n",
      "Epoch [56/300], Step [41/225], Training Accuracy: 92.4162%, Training Loss: 0.1996%\n",
      "Epoch [56/300], Step [42/225], Training Accuracy: 92.4479%, Training Loss: 0.1979%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/300], Step [43/225], Training Accuracy: 92.3328%, Training Loss: 0.1989%\n",
      "Epoch [56/300], Step [44/225], Training Accuracy: 92.2940%, Training Loss: 0.1988%\n",
      "Epoch [56/300], Step [45/225], Training Accuracy: 92.3264%, Training Loss: 0.1971%\n",
      "Epoch [56/300], Step [46/225], Training Accuracy: 92.4253%, Training Loss: 0.1959%\n",
      "Epoch [56/300], Step [47/225], Training Accuracy: 92.4535%, Training Loss: 0.1950%\n",
      "Epoch [56/300], Step [48/225], Training Accuracy: 92.3503%, Training Loss: 0.1954%\n",
      "Epoch [56/300], Step [49/225], Training Accuracy: 92.4426%, Training Loss: 0.1942%\n",
      "Epoch [56/300], Step [50/225], Training Accuracy: 92.5000%, Training Loss: 0.1932%\n",
      "Epoch [56/300], Step [51/225], Training Accuracy: 92.4632%, Training Loss: 0.1936%\n",
      "Epoch [56/300], Step [52/225], Training Accuracy: 92.4880%, Training Loss: 0.1928%\n",
      "Epoch [56/300], Step [53/225], Training Accuracy: 92.4528%, Training Loss: 0.1930%\n",
      "Epoch [56/300], Step [54/225], Training Accuracy: 92.5347%, Training Loss: 0.1923%\n",
      "Epoch [56/300], Step [55/225], Training Accuracy: 92.4432%, Training Loss: 0.1946%\n",
      "Epoch [56/300], Step [56/225], Training Accuracy: 92.4944%, Training Loss: 0.1938%\n",
      "Epoch [56/300], Step [57/225], Training Accuracy: 92.4890%, Training Loss: 0.1937%\n",
      "Epoch [56/300], Step [58/225], Training Accuracy: 92.4300%, Training Loss: 0.1947%\n",
      "Epoch [56/300], Step [59/225], Training Accuracy: 92.4258%, Training Loss: 0.1942%\n",
      "Epoch [56/300], Step [60/225], Training Accuracy: 92.3958%, Training Loss: 0.1949%\n",
      "Epoch [56/300], Step [61/225], Training Accuracy: 92.3924%, Training Loss: 0.1944%\n",
      "Epoch [56/300], Step [62/225], Training Accuracy: 92.4395%, Training Loss: 0.1929%\n",
      "Epoch [56/300], Step [63/225], Training Accuracy: 92.4851%, Training Loss: 0.1916%\n",
      "Epoch [56/300], Step [64/225], Training Accuracy: 92.5293%, Training Loss: 0.1913%\n",
      "Epoch [56/300], Step [65/225], Training Accuracy: 92.5240%, Training Loss: 0.1919%\n",
      "Epoch [56/300], Step [66/225], Training Accuracy: 92.5663%, Training Loss: 0.1911%\n",
      "Epoch [56/300], Step [67/225], Training Accuracy: 92.6073%, Training Loss: 0.1909%\n",
      "Epoch [56/300], Step [68/225], Training Accuracy: 92.5551%, Training Loss: 0.1922%\n",
      "Epoch [56/300], Step [69/225], Training Accuracy: 92.5498%, Training Loss: 0.1919%\n",
      "Epoch [56/300], Step [70/225], Training Accuracy: 92.5893%, Training Loss: 0.1912%\n",
      "Epoch [56/300], Step [71/225], Training Accuracy: 92.6717%, Training Loss: 0.1903%\n",
      "Epoch [56/300], Step [72/225], Training Accuracy: 92.6649%, Training Loss: 0.1900%\n",
      "Epoch [56/300], Step [73/225], Training Accuracy: 92.7226%, Training Loss: 0.1889%\n",
      "Epoch [56/300], Step [74/225], Training Accuracy: 92.7154%, Training Loss: 0.1890%\n",
      "Epoch [56/300], Step [75/225], Training Accuracy: 92.7500%, Training Loss: 0.1880%\n",
      "Epoch [56/300], Step [76/225], Training Accuracy: 92.7426%, Training Loss: 0.1886%\n",
      "Epoch [56/300], Step [77/225], Training Accuracy: 92.7151%, Training Loss: 0.1893%\n",
      "Epoch [56/300], Step [78/225], Training Accuracy: 92.7284%, Training Loss: 0.1887%\n",
      "Epoch [56/300], Step [79/225], Training Accuracy: 92.7809%, Training Loss: 0.1876%\n",
      "Epoch [56/300], Step [80/225], Training Accuracy: 92.7930%, Training Loss: 0.1877%\n",
      "Epoch [56/300], Step [81/225], Training Accuracy: 92.8241%, Training Loss: 0.1872%\n",
      "Epoch [56/300], Step [82/225], Training Accuracy: 92.8163%, Training Loss: 0.1873%\n",
      "Epoch [56/300], Step [83/225], Training Accuracy: 92.8087%, Training Loss: 0.1875%\n",
      "Epoch [56/300], Step [84/225], Training Accuracy: 92.8571%, Training Loss: 0.1871%\n",
      "Epoch [56/300], Step [85/225], Training Accuracy: 92.8860%, Training Loss: 0.1870%\n",
      "Epoch [56/300], Step [86/225], Training Accuracy: 92.9142%, Training Loss: 0.1863%\n",
      "Epoch [56/300], Step [87/225], Training Accuracy: 92.9059%, Training Loss: 0.1858%\n",
      "Epoch [56/300], Step [88/225], Training Accuracy: 92.9155%, Training Loss: 0.1859%\n",
      "Epoch [56/300], Step [89/225], Training Accuracy: 92.9073%, Training Loss: 0.1861%\n",
      "Epoch [56/300], Step [90/225], Training Accuracy: 92.8819%, Training Loss: 0.1863%\n",
      "Epoch [56/300], Step [91/225], Training Accuracy: 92.8571%, Training Loss: 0.1867%\n",
      "Epoch [56/300], Step [92/225], Training Accuracy: 92.8159%, Training Loss: 0.1878%\n",
      "Epoch [56/300], Step [93/225], Training Accuracy: 92.8427%, Training Loss: 0.1876%\n",
      "Epoch [56/300], Step [94/225], Training Accuracy: 92.8690%, Training Loss: 0.1868%\n",
      "Epoch [56/300], Step [95/225], Training Accuracy: 92.8783%, Training Loss: 0.1865%\n",
      "Epoch [56/300], Step [96/225], Training Accuracy: 92.9036%, Training Loss: 0.1858%\n",
      "Epoch [56/300], Step [97/225], Training Accuracy: 92.9285%, Training Loss: 0.1854%\n",
      "Epoch [56/300], Step [98/225], Training Accuracy: 92.9528%, Training Loss: 0.1852%\n",
      "Epoch [56/300], Step [99/225], Training Accuracy: 92.8977%, Training Loss: 0.1862%\n",
      "Epoch [56/300], Step [100/225], Training Accuracy: 92.8281%, Training Loss: 0.1875%\n",
      "Epoch [56/300], Step [101/225], Training Accuracy: 92.8218%, Training Loss: 0.1870%\n",
      "Epoch [56/300], Step [102/225], Training Accuracy: 92.8002%, Training Loss: 0.1876%\n",
      "Epoch [56/300], Step [103/225], Training Accuracy: 92.7943%, Training Loss: 0.1876%\n",
      "Epoch [56/300], Step [104/225], Training Accuracy: 92.8035%, Training Loss: 0.1874%\n",
      "Epoch [56/300], Step [105/225], Training Accuracy: 92.7976%, Training Loss: 0.1877%\n",
      "Epoch [56/300], Step [106/225], Training Accuracy: 92.8361%, Training Loss: 0.1869%\n",
      "Epoch [56/300], Step [107/225], Training Accuracy: 92.8008%, Training Loss: 0.1875%\n",
      "Epoch [56/300], Step [108/225], Training Accuracy: 92.7951%, Training Loss: 0.1878%\n",
      "Epoch [56/300], Step [109/225], Training Accuracy: 92.7752%, Training Loss: 0.1889%\n",
      "Epoch [56/300], Step [110/225], Training Accuracy: 92.6847%, Training Loss: 0.1906%\n",
      "Epoch [56/300], Step [111/225], Training Accuracy: 92.7224%, Training Loss: 0.1906%\n",
      "Epoch [56/300], Step [112/225], Training Accuracy: 92.7455%, Training Loss: 0.1901%\n",
      "Epoch [56/300], Step [113/225], Training Accuracy: 92.7544%, Training Loss: 0.1897%\n",
      "Epoch [56/300], Step [114/225], Training Accuracy: 92.7495%, Training Loss: 0.1891%\n",
      "Epoch [56/300], Step [115/225], Training Accuracy: 92.7038%, Training Loss: 0.1899%\n",
      "Epoch [56/300], Step [116/225], Training Accuracy: 92.6724%, Training Loss: 0.1907%\n",
      "Epoch [56/300], Step [117/225], Training Accuracy: 92.6683%, Training Loss: 0.1905%\n",
      "Epoch [56/300], Step [118/225], Training Accuracy: 92.6377%, Training Loss: 0.1911%\n",
      "Epoch [56/300], Step [119/225], Training Accuracy: 92.6471%, Training Loss: 0.1913%\n",
      "Epoch [56/300], Step [120/225], Training Accuracy: 92.6042%, Training Loss: 0.1919%\n",
      "Epoch [56/300], Step [121/225], Training Accuracy: 92.5749%, Training Loss: 0.1923%\n",
      "Epoch [56/300], Step [122/225], Training Accuracy: 92.6230%, Training Loss: 0.1922%\n",
      "Epoch [56/300], Step [123/225], Training Accuracy: 92.6448%, Training Loss: 0.1916%\n",
      "Epoch [56/300], Step [124/225], Training Accuracy: 92.6285%, Training Loss: 0.1917%\n",
      "Epoch [56/300], Step [125/225], Training Accuracy: 92.6375%, Training Loss: 0.1914%\n",
      "Epoch [56/300], Step [126/225], Training Accuracy: 92.5843%, Training Loss: 0.1924%\n",
      "Epoch [56/300], Step [127/225], Training Accuracy: 92.6058%, Training Loss: 0.1919%\n",
      "Epoch [56/300], Step [128/225], Training Accuracy: 92.5781%, Training Loss: 0.1920%\n",
      "Epoch [56/300], Step [129/225], Training Accuracy: 92.5993%, Training Loss: 0.1918%\n",
      "Epoch [56/300], Step [130/225], Training Accuracy: 92.5841%, Training Loss: 0.1918%\n",
      "Epoch [56/300], Step [131/225], Training Accuracy: 92.5573%, Training Loss: 0.1926%\n",
      "Epoch [56/300], Step [132/225], Training Accuracy: 92.5663%, Training Loss: 0.1923%\n",
      "Epoch [56/300], Step [133/225], Training Accuracy: 92.5752%, Training Loss: 0.1920%\n",
      "Epoch [56/300], Step [134/225], Training Accuracy: 92.5723%, Training Loss: 0.1920%\n",
      "Epoch [56/300], Step [135/225], Training Accuracy: 92.5926%, Training Loss: 0.1917%\n",
      "Epoch [56/300], Step [136/225], Training Accuracy: 92.5896%, Training Loss: 0.1919%\n",
      "Epoch [56/300], Step [137/225], Training Accuracy: 92.5981%, Training Loss: 0.1918%\n",
      "Epoch [56/300], Step [138/225], Training Accuracy: 92.6291%, Training Loss: 0.1911%\n",
      "Epoch [56/300], Step [139/225], Training Accuracy: 92.6709%, Training Loss: 0.1904%\n",
      "Epoch [56/300], Step [140/225], Training Accuracy: 92.6897%, Training Loss: 0.1903%\n",
      "Epoch [56/300], Step [141/225], Training Accuracy: 92.6973%, Training Loss: 0.1898%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/300], Step [142/225], Training Accuracy: 92.6937%, Training Loss: 0.1901%\n",
      "Epoch [56/300], Step [143/225], Training Accuracy: 92.7120%, Training Loss: 0.1900%\n",
      "Epoch [56/300], Step [144/225], Training Accuracy: 92.7300%, Training Loss: 0.1908%\n",
      "Epoch [56/300], Step [145/225], Training Accuracy: 92.7371%, Training Loss: 0.1906%\n",
      "Epoch [56/300], Step [146/225], Training Accuracy: 92.7654%, Training Loss: 0.1902%\n",
      "Epoch [56/300], Step [147/225], Training Accuracy: 92.7721%, Training Loss: 0.1901%\n",
      "Epoch [56/300], Step [148/225], Training Accuracy: 92.7682%, Training Loss: 0.1899%\n",
      "Epoch [56/300], Step [149/225], Training Accuracy: 92.7328%, Training Loss: 0.1905%\n",
      "Epoch [56/300], Step [150/225], Training Accuracy: 92.7708%, Training Loss: 0.1896%\n",
      "Epoch [56/300], Step [151/225], Training Accuracy: 92.7877%, Training Loss: 0.1891%\n",
      "Epoch [56/300], Step [152/225], Training Accuracy: 92.8043%, Training Loss: 0.1887%\n",
      "Epoch [56/300], Step [153/225], Training Accuracy: 92.8105%, Training Loss: 0.1884%\n",
      "Epoch [56/300], Step [154/225], Training Accuracy: 92.7963%, Training Loss: 0.1882%\n",
      "Epoch [56/300], Step [155/225], Training Accuracy: 92.8226%, Training Loss: 0.1877%\n",
      "Epoch [56/300], Step [156/225], Training Accuracy: 92.8185%, Training Loss: 0.1876%\n",
      "Epoch [56/300], Step [157/225], Training Accuracy: 92.7747%, Training Loss: 0.1885%\n",
      "Epoch [56/300], Step [158/225], Training Accuracy: 92.7710%, Training Loss: 0.1888%\n",
      "Epoch [56/300], Step [159/225], Training Accuracy: 92.7575%, Training Loss: 0.1888%\n",
      "Epoch [56/300], Step [160/225], Training Accuracy: 92.7441%, Training Loss: 0.1889%\n",
      "Epoch [56/300], Step [161/225], Training Accuracy: 92.7601%, Training Loss: 0.1888%\n",
      "Epoch [56/300], Step [162/225], Training Accuracy: 92.7469%, Training Loss: 0.1889%\n",
      "Epoch [56/300], Step [163/225], Training Accuracy: 92.7243%, Training Loss: 0.1894%\n",
      "Epoch [56/300], Step [164/225], Training Accuracy: 92.7591%, Training Loss: 0.1890%\n",
      "Epoch [56/300], Step [165/225], Training Accuracy: 92.7462%, Training Loss: 0.1891%\n",
      "Epoch [56/300], Step [166/225], Training Accuracy: 92.7146%, Training Loss: 0.1894%\n",
      "Epoch [56/300], Step [167/225], Training Accuracy: 92.7302%, Training Loss: 0.1890%\n",
      "Epoch [56/300], Step [168/225], Training Accuracy: 92.6897%, Training Loss: 0.1892%\n",
      "Epoch [56/300], Step [169/225], Training Accuracy: 92.7053%, Training Loss: 0.1892%\n",
      "Epoch [56/300], Step [170/225], Training Accuracy: 92.7114%, Training Loss: 0.1892%\n",
      "Epoch [56/300], Step [171/225], Training Accuracy: 92.6809%, Training Loss: 0.1898%\n",
      "Epoch [56/300], Step [172/225], Training Accuracy: 92.6690%, Training Loss: 0.1903%\n",
      "Epoch [56/300], Step [173/225], Training Accuracy: 92.6842%, Training Loss: 0.1903%\n",
      "Epoch [56/300], Step [174/225], Training Accuracy: 92.6994%, Training Loss: 0.1903%\n",
      "Epoch [56/300], Step [175/225], Training Accuracy: 92.7232%, Training Loss: 0.1898%\n",
      "Epoch [56/300], Step [176/225], Training Accuracy: 92.7379%, Training Loss: 0.1893%\n",
      "Epoch [56/300], Step [177/225], Training Accuracy: 92.7436%, Training Loss: 0.1895%\n",
      "Epoch [56/300], Step [178/225], Training Accuracy: 92.7142%, Training Loss: 0.1895%\n",
      "Epoch [56/300], Step [179/225], Training Accuracy: 92.7374%, Training Loss: 0.1891%\n",
      "Epoch [56/300], Step [180/225], Training Accuracy: 92.7431%, Training Loss: 0.1890%\n",
      "Epoch [56/300], Step [181/225], Training Accuracy: 92.7486%, Training Loss: 0.1889%\n",
      "Epoch [56/300], Step [182/225], Training Accuracy: 92.7112%, Training Loss: 0.1891%\n",
      "Epoch [56/300], Step [183/225], Training Accuracy: 92.6913%, Training Loss: 0.1893%\n",
      "Epoch [56/300], Step [184/225], Training Accuracy: 92.7140%, Training Loss: 0.1891%\n",
      "Epoch [56/300], Step [185/225], Training Accuracy: 92.7365%, Training Loss: 0.1888%\n",
      "Epoch [56/300], Step [186/225], Training Accuracy: 92.7587%, Training Loss: 0.1882%\n",
      "Epoch [56/300], Step [187/225], Training Accuracy: 92.7807%, Training Loss: 0.1881%\n",
      "Epoch [56/300], Step [188/225], Training Accuracy: 92.8025%, Training Loss: 0.1877%\n",
      "Epoch [56/300], Step [189/225], Training Accuracy: 92.7910%, Training Loss: 0.1875%\n",
      "Epoch [56/300], Step [190/225], Training Accuracy: 92.8043%, Training Loss: 0.1873%\n",
      "Epoch [56/300], Step [191/225], Training Accuracy: 92.7847%, Training Loss: 0.1879%\n",
      "Epoch [56/300], Step [192/225], Training Accuracy: 92.7979%, Training Loss: 0.1877%\n",
      "Epoch [56/300], Step [193/225], Training Accuracy: 92.8028%, Training Loss: 0.1874%\n",
      "Epoch [56/300], Step [194/225], Training Accuracy: 92.7916%, Training Loss: 0.1874%\n",
      "Epoch [56/300], Step [195/225], Training Accuracy: 92.8285%, Training Loss: 0.1867%\n",
      "Epoch [56/300], Step [196/225], Training Accuracy: 92.8412%, Training Loss: 0.1865%\n",
      "Epoch [56/300], Step [197/225], Training Accuracy: 92.8617%, Training Loss: 0.1861%\n",
      "Epoch [56/300], Step [198/225], Training Accuracy: 92.8898%, Training Loss: 0.1856%\n",
      "Epoch [56/300], Step [199/225], Training Accuracy: 92.8706%, Training Loss: 0.1859%\n",
      "Epoch [56/300], Step [200/225], Training Accuracy: 92.8906%, Training Loss: 0.1856%\n",
      "Epoch [56/300], Step [201/225], Training Accuracy: 92.8949%, Training Loss: 0.1858%\n",
      "Epoch [56/300], Step [202/225], Training Accuracy: 92.9069%, Training Loss: 0.1854%\n",
      "Epoch [56/300], Step [203/225], Training Accuracy: 92.9033%, Training Loss: 0.1850%\n",
      "Epoch [56/300], Step [204/225], Training Accuracy: 92.9075%, Training Loss: 0.1849%\n",
      "Epoch [56/300], Step [205/225], Training Accuracy: 92.9192%, Training Loss: 0.1845%\n",
      "Epoch [56/300], Step [206/225], Training Accuracy: 92.9308%, Training Loss: 0.1844%\n",
      "Epoch [56/300], Step [207/225], Training Accuracy: 92.9197%, Training Loss: 0.1844%\n",
      "Epoch [56/300], Step [208/225], Training Accuracy: 92.9312%, Training Loss: 0.1843%\n",
      "Epoch [56/300], Step [209/225], Training Accuracy: 92.9351%, Training Loss: 0.1846%\n",
      "Epoch [56/300], Step [210/225], Training Accuracy: 92.9390%, Training Loss: 0.1844%\n",
      "Epoch [56/300], Step [211/225], Training Accuracy: 92.9428%, Training Loss: 0.1841%\n",
      "Epoch [56/300], Step [212/225], Training Accuracy: 92.9245%, Training Loss: 0.1843%\n",
      "Epoch [56/300], Step [213/225], Training Accuracy: 92.9431%, Training Loss: 0.1840%\n",
      "Epoch [56/300], Step [214/225], Training Accuracy: 92.9395%, Training Loss: 0.1841%\n",
      "Epoch [56/300], Step [215/225], Training Accuracy: 92.9433%, Training Loss: 0.1842%\n",
      "Epoch [56/300], Step [216/225], Training Accuracy: 92.9543%, Training Loss: 0.1840%\n",
      "Epoch [56/300], Step [217/225], Training Accuracy: 92.9363%, Training Loss: 0.1844%\n",
      "Epoch [56/300], Step [218/225], Training Accuracy: 92.9401%, Training Loss: 0.1844%\n",
      "Epoch [56/300], Step [219/225], Training Accuracy: 92.9295%, Training Loss: 0.1847%\n",
      "Epoch [56/300], Step [220/225], Training Accuracy: 92.9190%, Training Loss: 0.1848%\n",
      "Epoch [56/300], Step [221/225], Training Accuracy: 92.9299%, Training Loss: 0.1844%\n",
      "Epoch [56/300], Step [222/225], Training Accuracy: 92.9265%, Training Loss: 0.1844%\n",
      "Epoch [56/300], Step [223/225], Training Accuracy: 92.9302%, Training Loss: 0.1843%\n",
      "Epoch [56/300], Step [224/225], Training Accuracy: 92.9269%, Training Loss: 0.1846%\n",
      "Epoch [56/300], Step [225/225], Training Accuracy: 92.9266%, Training Loss: 0.1845%\n",
      "Epoch [57/300], Step [1/225], Training Accuracy: 92.1875%, Training Loss: 0.2468%\n",
      "Epoch [57/300], Step [2/225], Training Accuracy: 93.7500%, Training Loss: 0.2032%\n",
      "Epoch [57/300], Step [3/225], Training Accuracy: 92.7083%, Training Loss: 0.2346%\n",
      "Epoch [57/300], Step [4/225], Training Accuracy: 93.3594%, Training Loss: 0.2127%\n",
      "Epoch [57/300], Step [5/225], Training Accuracy: 93.1250%, Training Loss: 0.2167%\n",
      "Epoch [57/300], Step [6/225], Training Accuracy: 93.4896%, Training Loss: 0.2062%\n",
      "Epoch [57/300], Step [7/225], Training Accuracy: 93.0804%, Training Loss: 0.2111%\n",
      "Epoch [57/300], Step [8/225], Training Accuracy: 92.9688%, Training Loss: 0.2103%\n",
      "Epoch [57/300], Step [9/225], Training Accuracy: 93.2292%, Training Loss: 0.2016%\n",
      "Epoch [57/300], Step [10/225], Training Accuracy: 92.9688%, Training Loss: 0.2032%\n",
      "Epoch [57/300], Step [11/225], Training Accuracy: 92.7557%, Training Loss: 0.2064%\n",
      "Epoch [57/300], Step [12/225], Training Accuracy: 92.7083%, Training Loss: 0.2079%\n",
      "Epoch [57/300], Step [13/225], Training Accuracy: 92.9087%, Training Loss: 0.2011%\n",
      "Epoch [57/300], Step [14/225], Training Accuracy: 93.1920%, Training Loss: 0.1999%\n",
      "Epoch [57/300], Step [15/225], Training Accuracy: 93.0208%, Training Loss: 0.1984%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/300], Step [16/225], Training Accuracy: 92.9688%, Training Loss: 0.1975%\n",
      "Epoch [57/300], Step [17/225], Training Accuracy: 92.8309%, Training Loss: 0.2008%\n",
      "Epoch [57/300], Step [18/225], Training Accuracy: 92.6215%, Training Loss: 0.2049%\n",
      "Epoch [57/300], Step [19/225], Training Accuracy: 92.6809%, Training Loss: 0.2022%\n",
      "Epoch [57/300], Step [20/225], Training Accuracy: 92.7344%, Training Loss: 0.1997%\n",
      "Epoch [57/300], Step [21/225], Training Accuracy: 92.7083%, Training Loss: 0.1991%\n",
      "Epoch [57/300], Step [22/225], Training Accuracy: 92.5426%, Training Loss: 0.2039%\n",
      "Epoch [57/300], Step [23/225], Training Accuracy: 92.5272%, Training Loss: 0.2015%\n",
      "Epoch [57/300], Step [24/225], Training Accuracy: 92.4479%, Training Loss: 0.2033%\n",
      "Epoch [57/300], Step [25/225], Training Accuracy: 92.3125%, Training Loss: 0.2031%\n",
      "Epoch [57/300], Step [26/225], Training Accuracy: 92.4279%, Training Loss: 0.2023%\n",
      "Epoch [57/300], Step [27/225], Training Accuracy: 92.5347%, Training Loss: 0.2005%\n",
      "Epoch [57/300], Step [28/225], Training Accuracy: 92.8013%, Training Loss: 0.1948%\n",
      "Epoch [57/300], Step [29/225], Training Accuracy: 92.8879%, Training Loss: 0.1917%\n",
      "Epoch [57/300], Step [30/225], Training Accuracy: 92.8125%, Training Loss: 0.1916%\n",
      "Epoch [57/300], Step [31/225], Training Accuracy: 92.6411%, Training Loss: 0.1968%\n",
      "Epoch [57/300], Step [32/225], Training Accuracy: 92.7734%, Training Loss: 0.1940%\n",
      "Epoch [57/300], Step [33/225], Training Accuracy: 92.8504%, Training Loss: 0.1930%\n",
      "Epoch [57/300], Step [34/225], Training Accuracy: 92.7390%, Training Loss: 0.1942%\n",
      "Epoch [57/300], Step [35/225], Training Accuracy: 92.8125%, Training Loss: 0.1930%\n",
      "Epoch [57/300], Step [36/225], Training Accuracy: 92.9253%, Training Loss: 0.1899%\n",
      "Epoch [57/300], Step [37/225], Training Accuracy: 92.9899%, Training Loss: 0.1894%\n",
      "Epoch [57/300], Step [38/225], Training Accuracy: 92.9688%, Training Loss: 0.1901%\n",
      "Epoch [57/300], Step [39/225], Training Accuracy: 92.7484%, Training Loss: 0.1941%\n",
      "Epoch [57/300], Step [40/225], Training Accuracy: 92.6172%, Training Loss: 0.1952%\n",
      "Epoch [57/300], Step [41/225], Training Accuracy: 92.3399%, Training Loss: 0.1984%\n",
      "Epoch [57/300], Step [42/225], Training Accuracy: 92.3735%, Training Loss: 0.1982%\n",
      "Epoch [57/300], Step [43/225], Training Accuracy: 92.4055%, Training Loss: 0.2005%\n",
      "Epoch [57/300], Step [44/225], Training Accuracy: 92.3651%, Training Loss: 0.2020%\n",
      "Epoch [57/300], Step [45/225], Training Accuracy: 92.3958%, Training Loss: 0.2012%\n",
      "Epoch [57/300], Step [46/225], Training Accuracy: 92.4253%, Training Loss: 0.2010%\n",
      "Epoch [57/300], Step [47/225], Training Accuracy: 92.4535%, Training Loss: 0.2000%\n",
      "Epoch [57/300], Step [48/225], Training Accuracy: 92.5130%, Training Loss: 0.1990%\n",
      "Epoch [57/300], Step [49/225], Training Accuracy: 92.5383%, Training Loss: 0.1990%\n",
      "Epoch [57/300], Step [50/225], Training Accuracy: 92.6250%, Training Loss: 0.1976%\n",
      "Epoch [57/300], Step [51/225], Training Accuracy: 92.6164%, Training Loss: 0.1980%\n",
      "Epoch [57/300], Step [52/225], Training Accuracy: 92.6683%, Training Loss: 0.1970%\n",
      "Epoch [57/300], Step [53/225], Training Accuracy: 92.6592%, Training Loss: 0.1964%\n",
      "Epoch [57/300], Step [54/225], Training Accuracy: 92.7373%, Training Loss: 0.1955%\n",
      "Epoch [57/300], Step [55/225], Training Accuracy: 92.6136%, Training Loss: 0.1971%\n",
      "Epoch [57/300], Step [56/225], Training Accuracy: 92.6618%, Training Loss: 0.1958%\n",
      "Epoch [57/300], Step [57/225], Training Accuracy: 92.6535%, Training Loss: 0.1962%\n",
      "Epoch [57/300], Step [58/225], Training Accuracy: 92.6455%, Training Loss: 0.1967%\n",
      "Epoch [57/300], Step [59/225], Training Accuracy: 92.6642%, Training Loss: 0.1965%\n",
      "Epoch [57/300], Step [60/225], Training Accuracy: 92.6562%, Training Loss: 0.1970%\n",
      "Epoch [57/300], Step [61/225], Training Accuracy: 92.5205%, Training Loss: 0.1983%\n",
      "Epoch [57/300], Step [62/225], Training Accuracy: 92.5655%, Training Loss: 0.1968%\n",
      "Epoch [57/300], Step [63/225], Training Accuracy: 92.6091%, Training Loss: 0.1962%\n",
      "Epoch [57/300], Step [64/225], Training Accuracy: 92.5781%, Training Loss: 0.1962%\n",
      "Epoch [57/300], Step [65/225], Training Accuracy: 92.6202%, Training Loss: 0.1959%\n",
      "Epoch [57/300], Step [66/225], Training Accuracy: 92.6373%, Training Loss: 0.1959%\n",
      "Epoch [57/300], Step [67/225], Training Accuracy: 92.6772%, Training Loss: 0.1952%\n",
      "Epoch [57/300], Step [68/225], Training Accuracy: 92.6241%, Training Loss: 0.1959%\n",
      "Epoch [57/300], Step [69/225], Training Accuracy: 92.6630%, Training Loss: 0.1953%\n",
      "Epoch [57/300], Step [70/225], Training Accuracy: 92.7009%, Training Loss: 0.1946%\n",
      "Epoch [57/300], Step [71/225], Training Accuracy: 92.6496%, Training Loss: 0.1951%\n",
      "Epoch [57/300], Step [72/225], Training Accuracy: 92.6866%, Training Loss: 0.1944%\n",
      "Epoch [57/300], Step [73/225], Training Accuracy: 92.6798%, Training Loss: 0.1942%\n",
      "Epoch [57/300], Step [74/225], Training Accuracy: 92.6731%, Training Loss: 0.1943%\n",
      "Epoch [57/300], Step [75/225], Training Accuracy: 92.6875%, Training Loss: 0.1943%\n",
      "Epoch [57/300], Step [76/225], Training Accuracy: 92.7015%, Training Loss: 0.1947%\n",
      "Epoch [57/300], Step [77/225], Training Accuracy: 92.7354%, Training Loss: 0.1944%\n",
      "Epoch [57/300], Step [78/225], Training Accuracy: 92.7484%, Training Loss: 0.1945%\n",
      "Epoch [57/300], Step [79/225], Training Accuracy: 92.7809%, Training Loss: 0.1938%\n",
      "Epoch [57/300], Step [80/225], Training Accuracy: 92.7734%, Training Loss: 0.1935%\n",
      "Epoch [57/300], Step [81/225], Training Accuracy: 92.6890%, Training Loss: 0.1951%\n",
      "Epoch [57/300], Step [82/225], Training Accuracy: 92.7210%, Training Loss: 0.1946%\n",
      "Epoch [57/300], Step [83/225], Training Accuracy: 92.7146%, Training Loss: 0.1948%\n",
      "Epoch [57/300], Step [84/225], Training Accuracy: 92.7269%, Training Loss: 0.1946%\n",
      "Epoch [57/300], Step [85/225], Training Accuracy: 92.7574%, Training Loss: 0.1939%\n",
      "Epoch [57/300], Step [86/225], Training Accuracy: 92.8052%, Training Loss: 0.1927%\n",
      "Epoch [57/300], Step [87/225], Training Accuracy: 92.8341%, Training Loss: 0.1921%\n",
      "Epoch [57/300], Step [88/225], Training Accuracy: 92.8267%, Training Loss: 0.1932%\n",
      "Epoch [57/300], Step [89/225], Training Accuracy: 92.8195%, Training Loss: 0.1931%\n",
      "Epoch [57/300], Step [90/225], Training Accuracy: 92.7083%, Training Loss: 0.1956%\n",
      "Epoch [57/300], Step [91/225], Training Accuracy: 92.7026%, Training Loss: 0.1957%\n",
      "Epoch [57/300], Step [92/225], Training Accuracy: 92.6121%, Training Loss: 0.1980%\n",
      "Epoch [57/300], Step [93/225], Training Accuracy: 92.6411%, Training Loss: 0.1975%\n",
      "Epoch [57/300], Step [94/225], Training Accuracy: 92.6031%, Training Loss: 0.1985%\n",
      "Epoch [57/300], Step [95/225], Training Accuracy: 92.6316%, Training Loss: 0.1976%\n",
      "Epoch [57/300], Step [96/225], Training Accuracy: 92.5781%, Training Loss: 0.1977%\n",
      "Epoch [57/300], Step [97/225], Training Accuracy: 92.5580%, Training Loss: 0.1975%\n",
      "Epoch [57/300], Step [98/225], Training Accuracy: 92.5383%, Training Loss: 0.1975%\n",
      "Epoch [57/300], Step [99/225], Training Accuracy: 92.5505%, Training Loss: 0.1974%\n",
      "Epoch [57/300], Step [100/225], Training Accuracy: 92.5469%, Training Loss: 0.1976%\n",
      "Epoch [57/300], Step [101/225], Training Accuracy: 92.5897%, Training Loss: 0.1966%\n",
      "Epoch [57/300], Step [102/225], Training Accuracy: 92.5398%, Training Loss: 0.1978%\n",
      "Epoch [57/300], Step [103/225], Training Accuracy: 92.5971%, Training Loss: 0.1969%\n",
      "Epoch [57/300], Step [104/225], Training Accuracy: 92.6232%, Training Loss: 0.1966%\n",
      "Epoch [57/300], Step [105/225], Training Accuracy: 92.5893%, Training Loss: 0.1979%\n",
      "Epoch [57/300], Step [106/225], Training Accuracy: 92.6150%, Training Loss: 0.1977%\n",
      "Epoch [57/300], Step [107/225], Training Accuracy: 92.6110%, Training Loss: 0.1979%\n",
      "Epoch [57/300], Step [108/225], Training Accuracy: 92.6360%, Training Loss: 0.1973%\n",
      "Epoch [57/300], Step [109/225], Training Accuracy: 92.6032%, Training Loss: 0.1971%\n",
      "Epoch [57/300], Step [110/225], Training Accuracy: 92.5994%, Training Loss: 0.1968%\n",
      "Epoch [57/300], Step [111/225], Training Accuracy: 92.5816%, Training Loss: 0.1972%\n",
      "Epoch [57/300], Step [112/225], Training Accuracy: 92.5781%, Training Loss: 0.1978%\n",
      "Epoch [57/300], Step [113/225], Training Accuracy: 92.5747%, Training Loss: 0.1973%\n",
      "Epoch [57/300], Step [114/225], Training Accuracy: 92.5576%, Training Loss: 0.1974%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/300], Step [115/225], Training Accuracy: 92.5679%, Training Loss: 0.1971%\n",
      "Epoch [57/300], Step [116/225], Training Accuracy: 92.5377%, Training Loss: 0.1976%\n",
      "Epoch [57/300], Step [117/225], Training Accuracy: 92.5481%, Training Loss: 0.1977%\n",
      "Epoch [57/300], Step [118/225], Training Accuracy: 92.5450%, Training Loss: 0.1979%\n",
      "Epoch [57/300], Step [119/225], Training Accuracy: 92.5551%, Training Loss: 0.1978%\n",
      "Epoch [57/300], Step [120/225], Training Accuracy: 92.5781%, Training Loss: 0.1979%\n",
      "Epoch [57/300], Step [121/225], Training Accuracy: 92.5878%, Training Loss: 0.1976%\n",
      "Epoch [57/300], Step [122/225], Training Accuracy: 92.5717%, Training Loss: 0.1977%\n",
      "Epoch [57/300], Step [123/225], Training Accuracy: 92.6067%, Training Loss: 0.1973%\n",
      "Epoch [57/300], Step [124/225], Training Accuracy: 92.6411%, Training Loss: 0.1969%\n",
      "Epoch [57/300], Step [125/225], Training Accuracy: 92.6750%, Training Loss: 0.1963%\n",
      "Epoch [57/300], Step [126/225], Training Accuracy: 92.6711%, Training Loss: 0.1960%\n",
      "Epoch [57/300], Step [127/225], Training Accuracy: 92.6796%, Training Loss: 0.1967%\n",
      "Epoch [57/300], Step [128/225], Training Accuracy: 92.6392%, Training Loss: 0.1989%\n",
      "Epoch [57/300], Step [129/225], Training Accuracy: 92.5993%, Training Loss: 0.1994%\n",
      "Epoch [57/300], Step [130/225], Training Accuracy: 92.5962%, Training Loss: 0.1991%\n",
      "Epoch [57/300], Step [131/225], Training Accuracy: 92.5811%, Training Loss: 0.1994%\n",
      "Epoch [57/300], Step [132/225], Training Accuracy: 92.6018%, Training Loss: 0.1988%\n",
      "Epoch [57/300], Step [133/225], Training Accuracy: 92.6104%, Training Loss: 0.1994%\n",
      "Epoch [57/300], Step [134/225], Training Accuracy: 92.6306%, Training Loss: 0.1992%\n",
      "Epoch [57/300], Step [135/225], Training Accuracy: 92.6042%, Training Loss: 0.1994%\n",
      "Epoch [57/300], Step [136/225], Training Accuracy: 92.5781%, Training Loss: 0.2002%\n",
      "Epoch [57/300], Step [137/225], Training Accuracy: 92.5639%, Training Loss: 0.2001%\n",
      "Epoch [57/300], Step [138/225], Training Accuracy: 92.5725%, Training Loss: 0.1999%\n",
      "Epoch [57/300], Step [139/225], Training Accuracy: 92.5922%, Training Loss: 0.1991%\n",
      "Epoch [57/300], Step [140/225], Training Accuracy: 92.6004%, Training Loss: 0.1988%\n",
      "Epoch [57/300], Step [141/225], Training Accuracy: 92.6086%, Training Loss: 0.1987%\n",
      "Epoch [57/300], Step [142/225], Training Accuracy: 92.6276%, Training Loss: 0.1982%\n",
      "Epoch [57/300], Step [143/225], Training Accuracy: 92.6683%, Training Loss: 0.1976%\n",
      "Epoch [57/300], Step [144/225], Training Accuracy: 92.6758%, Training Loss: 0.1971%\n",
      "Epoch [57/300], Step [145/225], Training Accuracy: 92.6832%, Training Loss: 0.1972%\n",
      "Epoch [57/300], Step [146/225], Training Accuracy: 92.6905%, Training Loss: 0.1968%\n",
      "Epoch [57/300], Step [147/225], Training Accuracy: 92.6977%, Training Loss: 0.1971%\n",
      "Epoch [57/300], Step [148/225], Training Accuracy: 92.7154%, Training Loss: 0.1966%\n",
      "Epoch [57/300], Step [149/225], Training Accuracy: 92.7118%, Training Loss: 0.1968%\n",
      "Epoch [57/300], Step [150/225], Training Accuracy: 92.7396%, Training Loss: 0.1961%\n",
      "Epoch [57/300], Step [151/225], Training Accuracy: 92.7773%, Training Loss: 0.1955%\n",
      "Epoch [57/300], Step [152/225], Training Accuracy: 92.7837%, Training Loss: 0.1955%\n",
      "Epoch [57/300], Step [153/225], Training Accuracy: 92.7798%, Training Loss: 0.1961%\n",
      "Epoch [57/300], Step [154/225], Training Accuracy: 92.7760%, Training Loss: 0.1958%\n",
      "Epoch [57/300], Step [155/225], Training Accuracy: 92.7520%, Training Loss: 0.1963%\n",
      "Epoch [57/300], Step [156/225], Training Accuracy: 92.7484%, Training Loss: 0.1963%\n",
      "Epoch [57/300], Step [157/225], Training Accuracy: 92.7349%, Training Loss: 0.1965%\n",
      "Epoch [57/300], Step [158/225], Training Accuracy: 92.7710%, Training Loss: 0.1958%\n",
      "Epoch [57/300], Step [159/225], Training Accuracy: 92.7869%, Training Loss: 0.1961%\n",
      "Epoch [57/300], Step [160/225], Training Accuracy: 92.7734%, Training Loss: 0.1960%\n",
      "Epoch [57/300], Step [161/225], Training Accuracy: 92.7407%, Training Loss: 0.1968%\n",
      "Epoch [57/300], Step [162/225], Training Accuracy: 92.7276%, Training Loss: 0.1970%\n",
      "Epoch [57/300], Step [163/225], Training Accuracy: 92.7051%, Training Loss: 0.1970%\n",
      "Epoch [57/300], Step [164/225], Training Accuracy: 92.7210%, Training Loss: 0.1965%\n",
      "Epoch [57/300], Step [165/225], Training Accuracy: 92.7273%, Training Loss: 0.1962%\n",
      "Epoch [57/300], Step [166/225], Training Accuracy: 92.7052%, Training Loss: 0.1967%\n",
      "Epoch [57/300], Step [167/225], Training Accuracy: 92.7208%, Training Loss: 0.1966%\n",
      "Epoch [57/300], Step [168/225], Training Accuracy: 92.6990%, Training Loss: 0.1967%\n",
      "Epoch [57/300], Step [169/225], Training Accuracy: 92.7330%, Training Loss: 0.1961%\n",
      "Epoch [57/300], Step [170/225], Training Accuracy: 92.7390%, Training Loss: 0.1960%\n",
      "Epoch [57/300], Step [171/225], Training Accuracy: 92.7083%, Training Loss: 0.1965%\n",
      "Epoch [57/300], Step [172/225], Training Accuracy: 92.6962%, Training Loss: 0.1965%\n",
      "Epoch [57/300], Step [173/225], Training Accuracy: 92.7023%, Training Loss: 0.1961%\n",
      "Epoch [57/300], Step [174/225], Training Accuracy: 92.7083%, Training Loss: 0.1961%\n",
      "Epoch [57/300], Step [175/225], Training Accuracy: 92.7321%, Training Loss: 0.1955%\n",
      "Epoch [57/300], Step [176/225], Training Accuracy: 92.7202%, Training Loss: 0.1953%\n",
      "Epoch [57/300], Step [177/225], Training Accuracy: 92.6907%, Training Loss: 0.1959%\n",
      "Epoch [57/300], Step [178/225], Training Accuracy: 92.6791%, Training Loss: 0.1959%\n",
      "Epoch [57/300], Step [179/225], Training Accuracy: 92.6589%, Training Loss: 0.1962%\n",
      "Epoch [57/300], Step [180/225], Training Accuracy: 92.6389%, Training Loss: 0.1962%\n",
      "Epoch [57/300], Step [181/225], Training Accuracy: 92.6278%, Training Loss: 0.1962%\n",
      "Epoch [57/300], Step [182/225], Training Accuracy: 92.6168%, Training Loss: 0.1963%\n",
      "Epoch [57/300], Step [183/225], Training Accuracy: 92.6315%, Training Loss: 0.1961%\n",
      "Epoch [57/300], Step [184/225], Training Accuracy: 92.6291%, Training Loss: 0.1962%\n",
      "Epoch [57/300], Step [185/225], Training Accuracy: 92.6520%, Training Loss: 0.1959%\n",
      "Epoch [57/300], Step [186/225], Training Accuracy: 92.6663%, Training Loss: 0.1957%\n",
      "Epoch [57/300], Step [187/225], Training Accuracy: 92.6721%, Training Loss: 0.1955%\n",
      "Epoch [57/300], Step [188/225], Training Accuracy: 92.6779%, Training Loss: 0.1953%\n",
      "Epoch [57/300], Step [189/225], Training Accuracy: 92.6670%, Training Loss: 0.1958%\n",
      "Epoch [57/300], Step [190/225], Training Accuracy: 92.6398%, Training Loss: 0.1964%\n",
      "Epoch [57/300], Step [191/225], Training Accuracy: 92.6047%, Training Loss: 0.1966%\n",
      "Epoch [57/300], Step [192/225], Training Accuracy: 92.6351%, Training Loss: 0.1963%\n",
      "Epoch [57/300], Step [193/225], Training Accuracy: 92.6409%, Training Loss: 0.1962%\n",
      "Epoch [57/300], Step [194/225], Training Accuracy: 92.6224%, Training Loss: 0.1970%\n",
      "Epoch [57/300], Step [195/225], Training Accuracy: 92.6042%, Training Loss: 0.1974%\n",
      "Epoch [57/300], Step [196/225], Training Accuracy: 92.5622%, Training Loss: 0.1980%\n",
      "Epoch [57/300], Step [197/225], Training Accuracy: 92.5523%, Training Loss: 0.1981%\n",
      "Epoch [57/300], Step [198/225], Training Accuracy: 92.5821%, Training Loss: 0.1976%\n",
      "Epoch [57/300], Step [199/225], Training Accuracy: 92.5801%, Training Loss: 0.1976%\n",
      "Epoch [57/300], Step [200/225], Training Accuracy: 92.6094%, Training Loss: 0.1972%\n",
      "Epoch [57/300], Step [201/225], Training Accuracy: 92.5840%, Training Loss: 0.1975%\n",
      "Epoch [57/300], Step [202/225], Training Accuracy: 92.5743%, Training Loss: 0.1974%\n",
      "Epoch [57/300], Step [203/225], Training Accuracy: 92.5800%, Training Loss: 0.1972%\n",
      "Epoch [57/300], Step [204/225], Training Accuracy: 92.5705%, Training Loss: 0.1973%\n",
      "Epoch [57/300], Step [205/225], Training Accuracy: 92.5915%, Training Loss: 0.1967%\n",
      "Epoch [57/300], Step [206/225], Training Accuracy: 92.5971%, Training Loss: 0.1966%\n",
      "Epoch [57/300], Step [207/225], Training Accuracy: 92.5876%, Training Loss: 0.1966%\n",
      "Epoch [57/300], Step [208/225], Training Accuracy: 92.5931%, Training Loss: 0.1963%\n",
      "Epoch [57/300], Step [209/225], Training Accuracy: 92.5912%, Training Loss: 0.1963%\n",
      "Epoch [57/300], Step [210/225], Training Accuracy: 92.5818%, Training Loss: 0.1963%\n",
      "Epoch [57/300], Step [211/225], Training Accuracy: 92.5726%, Training Loss: 0.1964%\n",
      "Epoch [57/300], Step [212/225], Training Accuracy: 92.5708%, Training Loss: 0.1964%\n",
      "Epoch [57/300], Step [213/225], Training Accuracy: 92.5763%, Training Loss: 0.1962%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/300], Step [214/225], Training Accuracy: 92.5672%, Training Loss: 0.1963%\n",
      "Epoch [57/300], Step [215/225], Training Accuracy: 92.5945%, Training Loss: 0.1958%\n",
      "Epoch [57/300], Step [216/225], Training Accuracy: 92.6071%, Training Loss: 0.1957%\n",
      "Epoch [57/300], Step [217/225], Training Accuracy: 92.6339%, Training Loss: 0.1954%\n",
      "Epoch [57/300], Step [218/225], Training Accuracy: 92.6319%, Training Loss: 0.1956%\n",
      "Epoch [57/300], Step [219/225], Training Accuracy: 92.6370%, Training Loss: 0.1954%\n",
      "Epoch [57/300], Step [220/225], Training Accuracy: 92.6634%, Training Loss: 0.1950%\n",
      "Epoch [57/300], Step [221/225], Training Accuracy: 92.6541%, Training Loss: 0.1947%\n",
      "Epoch [57/300], Step [222/225], Training Accuracy: 92.6309%, Training Loss: 0.1952%\n",
      "Epoch [57/300], Step [223/225], Training Accuracy: 92.6079%, Training Loss: 0.1958%\n",
      "Epoch [57/300], Step [224/225], Training Accuracy: 92.6130%, Training Loss: 0.1957%\n",
      "Epoch [57/300], Step [225/225], Training Accuracy: 92.6140%, Training Loss: 0.1955%\n",
      "Epoch [58/300], Step [1/225], Training Accuracy: 95.3125%, Training Loss: 0.2149%\n",
      "Epoch [58/300], Step [2/225], Training Accuracy: 92.1875%, Training Loss: 0.2204%\n",
      "Epoch [58/300], Step [3/225], Training Accuracy: 91.6667%, Training Loss: 0.2562%\n",
      "Epoch [58/300], Step [4/225], Training Accuracy: 91.0156%, Training Loss: 0.2496%\n",
      "Epoch [58/300], Step [5/225], Training Accuracy: 91.5625%, Training Loss: 0.2384%\n",
      "Epoch [58/300], Step [6/225], Training Accuracy: 91.6667%, Training Loss: 0.2254%\n",
      "Epoch [58/300], Step [7/225], Training Accuracy: 91.5179%, Training Loss: 0.2288%\n",
      "Epoch [58/300], Step [8/225], Training Accuracy: 90.8203%, Training Loss: 0.2498%\n",
      "Epoch [58/300], Step [9/225], Training Accuracy: 90.7986%, Training Loss: 0.2441%\n",
      "Epoch [58/300], Step [10/225], Training Accuracy: 90.7812%, Training Loss: 0.2456%\n",
      "Epoch [58/300], Step [11/225], Training Accuracy: 90.9091%, Training Loss: 0.2453%\n",
      "Epoch [58/300], Step [12/225], Training Accuracy: 91.2760%, Training Loss: 0.2358%\n",
      "Epoch [58/300], Step [13/225], Training Accuracy: 91.3462%, Training Loss: 0.2313%\n",
      "Epoch [58/300], Step [14/225], Training Accuracy: 91.2946%, Training Loss: 0.2291%\n",
      "Epoch [58/300], Step [15/225], Training Accuracy: 91.6667%, Training Loss: 0.2221%\n",
      "Epoch [58/300], Step [16/225], Training Accuracy: 91.5039%, Training Loss: 0.2236%\n",
      "Epoch [58/300], Step [17/225], Training Accuracy: 91.7279%, Training Loss: 0.2183%\n",
      "Epoch [58/300], Step [18/225], Training Accuracy: 92.1007%, Training Loss: 0.2131%\n",
      "Epoch [58/300], Step [19/225], Training Accuracy: 92.1875%, Training Loss: 0.2102%\n",
      "Epoch [58/300], Step [20/225], Training Accuracy: 92.5000%, Training Loss: 0.2033%\n",
      "Epoch [58/300], Step [21/225], Training Accuracy: 92.6339%, Training Loss: 0.2021%\n",
      "Epoch [58/300], Step [22/225], Training Accuracy: 92.5426%, Training Loss: 0.2047%\n",
      "Epoch [58/300], Step [23/225], Training Accuracy: 92.5272%, Training Loss: 0.2065%\n",
      "Epoch [58/300], Step [24/225], Training Accuracy: 92.5781%, Training Loss: 0.2058%\n",
      "Epoch [58/300], Step [25/225], Training Accuracy: 92.3750%, Training Loss: 0.2073%\n",
      "Epoch [58/300], Step [26/225], Training Accuracy: 92.4279%, Training Loss: 0.2076%\n",
      "Epoch [58/300], Step [27/225], Training Accuracy: 92.3611%, Training Loss: 0.2134%\n",
      "Epoch [58/300], Step [28/225], Training Accuracy: 92.5223%, Training Loss: 0.2108%\n",
      "Epoch [58/300], Step [29/225], Training Accuracy: 92.6185%, Training Loss: 0.2100%\n",
      "Epoch [58/300], Step [30/225], Training Accuracy: 92.6562%, Training Loss: 0.2110%\n",
      "Epoch [58/300], Step [31/225], Training Accuracy: 92.4395%, Training Loss: 0.2160%\n",
      "Epoch [58/300], Step [32/225], Training Accuracy: 92.4316%, Training Loss: 0.2139%\n",
      "Epoch [58/300], Step [33/225], Training Accuracy: 92.4242%, Training Loss: 0.2127%\n",
      "Epoch [58/300], Step [34/225], Training Accuracy: 92.2794%, Training Loss: 0.2147%\n",
      "Epoch [58/300], Step [35/225], Training Accuracy: 92.2768%, Training Loss: 0.2129%\n",
      "Epoch [58/300], Step [36/225], Training Accuracy: 92.4045%, Training Loss: 0.2104%\n",
      "Epoch [58/300], Step [37/225], Training Accuracy: 92.5253%, Training Loss: 0.2090%\n",
      "Epoch [58/300], Step [38/225], Training Accuracy: 92.4342%, Training Loss: 0.2112%\n",
      "Epoch [58/300], Step [39/225], Training Accuracy: 92.3478%, Training Loss: 0.2109%\n",
      "Epoch [58/300], Step [40/225], Training Accuracy: 92.2266%, Training Loss: 0.2121%\n",
      "Epoch [58/300], Step [41/225], Training Accuracy: 92.1494%, Training Loss: 0.2144%\n",
      "Epoch [58/300], Step [42/225], Training Accuracy: 92.0387%, Training Loss: 0.2168%\n",
      "Epoch [58/300], Step [43/225], Training Accuracy: 92.0785%, Training Loss: 0.2152%\n",
      "Epoch [58/300], Step [44/225], Training Accuracy: 92.0455%, Training Loss: 0.2152%\n",
      "Epoch [58/300], Step [45/225], Training Accuracy: 91.9792%, Training Loss: 0.2157%\n",
      "Epoch [58/300], Step [46/225], Training Accuracy: 92.0856%, Training Loss: 0.2142%\n",
      "Epoch [58/300], Step [47/225], Training Accuracy: 92.0213%, Training Loss: 0.2139%\n",
      "Epoch [58/300], Step [48/225], Training Accuracy: 92.1224%, Training Loss: 0.2118%\n",
      "Epoch [58/300], Step [49/225], Training Accuracy: 92.1556%, Training Loss: 0.2099%\n",
      "Epoch [58/300], Step [50/225], Training Accuracy: 92.0938%, Training Loss: 0.2108%\n",
      "Epoch [58/300], Step [51/225], Training Accuracy: 92.2181%, Training Loss: 0.2084%\n",
      "Epoch [58/300], Step [52/225], Training Accuracy: 92.2476%, Training Loss: 0.2075%\n",
      "Epoch [58/300], Step [53/225], Training Accuracy: 92.2465%, Training Loss: 0.2068%\n",
      "Epoch [58/300], Step [54/225], Training Accuracy: 92.2743%, Training Loss: 0.2064%\n",
      "Epoch [58/300], Step [55/225], Training Accuracy: 92.3295%, Training Loss: 0.2060%\n",
      "Epoch [58/300], Step [56/225], Training Accuracy: 92.3828%, Training Loss: 0.2056%\n",
      "Epoch [58/300], Step [57/225], Training Accuracy: 92.3246%, Training Loss: 0.2069%\n",
      "Epoch [58/300], Step [58/225], Training Accuracy: 92.2144%, Training Loss: 0.2076%\n",
      "Epoch [58/300], Step [59/225], Training Accuracy: 92.1345%, Training Loss: 0.2107%\n",
      "Epoch [58/300], Step [60/225], Training Accuracy: 92.1875%, Training Loss: 0.2094%\n",
      "Epoch [58/300], Step [61/225], Training Accuracy: 92.0850%, Training Loss: 0.2117%\n",
      "Epoch [58/300], Step [62/225], Training Accuracy: 92.1371%, Training Loss: 0.2098%\n",
      "Epoch [58/300], Step [63/225], Training Accuracy: 92.0387%, Training Loss: 0.2101%\n",
      "Epoch [58/300], Step [64/225], Training Accuracy: 91.9922%, Training Loss: 0.2099%\n",
      "Epoch [58/300], Step [65/225], Training Accuracy: 92.0192%, Training Loss: 0.2093%\n",
      "Epoch [58/300], Step [66/225], Training Accuracy: 91.9271%, Training Loss: 0.2116%\n",
      "Epoch [58/300], Step [67/225], Training Accuracy: 92.0243%, Training Loss: 0.2100%\n",
      "Epoch [58/300], Step [68/225], Training Accuracy: 92.0267%, Training Loss: 0.2094%\n",
      "Epoch [58/300], Step [69/225], Training Accuracy: 91.9837%, Training Loss: 0.2101%\n",
      "Epoch [58/300], Step [70/225], Training Accuracy: 92.0536%, Training Loss: 0.2096%\n",
      "Epoch [58/300], Step [71/225], Training Accuracy: 92.0775%, Training Loss: 0.2099%\n",
      "Epoch [58/300], Step [72/225], Training Accuracy: 92.1007%, Training Loss: 0.2094%\n",
      "Epoch [58/300], Step [73/225], Training Accuracy: 92.1019%, Training Loss: 0.2096%\n",
      "Epoch [58/300], Step [74/225], Training Accuracy: 92.1030%, Training Loss: 0.2114%\n",
      "Epoch [58/300], Step [75/225], Training Accuracy: 92.0833%, Training Loss: 0.2114%\n",
      "Epoch [58/300], Step [76/225], Training Accuracy: 92.0847%, Training Loss: 0.2108%\n",
      "Epoch [58/300], Step [77/225], Training Accuracy: 92.0455%, Training Loss: 0.2111%\n",
      "Epoch [58/300], Step [78/225], Training Accuracy: 92.0873%, Training Loss: 0.2103%\n",
      "Epoch [58/300], Step [79/225], Training Accuracy: 92.0688%, Training Loss: 0.2102%\n",
      "Epoch [58/300], Step [80/225], Training Accuracy: 92.0898%, Training Loss: 0.2102%\n",
      "Epoch [58/300], Step [81/225], Training Accuracy: 92.1489%, Training Loss: 0.2088%\n",
      "Epoch [58/300], Step [82/225], Training Accuracy: 92.1113%, Training Loss: 0.2084%\n",
      "Epoch [58/300], Step [83/225], Training Accuracy: 92.0934%, Training Loss: 0.2085%\n",
      "Epoch [58/300], Step [84/225], Training Accuracy: 92.0759%, Training Loss: 0.2090%\n",
      "Epoch [58/300], Step [85/225], Training Accuracy: 92.0772%, Training Loss: 0.2084%\n",
      "Epoch [58/300], Step [86/225], Training Accuracy: 92.0967%, Training Loss: 0.2077%\n",
      "Epoch [58/300], Step [87/225], Training Accuracy: 92.1157%, Training Loss: 0.2071%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/300], Step [88/225], Training Accuracy: 92.0277%, Training Loss: 0.2088%\n",
      "Epoch [58/300], Step [89/225], Training Accuracy: 92.0646%, Training Loss: 0.2085%\n",
      "Epoch [58/300], Step [90/225], Training Accuracy: 92.0312%, Training Loss: 0.2084%\n",
      "Epoch [58/300], Step [91/225], Training Accuracy: 92.0158%, Training Loss: 0.2083%\n",
      "Epoch [58/300], Step [92/225], Training Accuracy: 92.0177%, Training Loss: 0.2091%\n",
      "Epoch [58/300], Step [93/225], Training Accuracy: 92.0363%, Training Loss: 0.2089%\n",
      "Epoch [58/300], Step [94/225], Training Accuracy: 91.9548%, Training Loss: 0.2099%\n",
      "Epoch [58/300], Step [95/225], Training Accuracy: 91.9408%, Training Loss: 0.2097%\n",
      "Epoch [58/300], Step [96/225], Training Accuracy: 91.9596%, Training Loss: 0.2092%\n",
      "Epoch [58/300], Step [97/225], Training Accuracy: 91.9620%, Training Loss: 0.2095%\n",
      "Epoch [58/300], Step [98/225], Training Accuracy: 91.8846%, Training Loss: 0.2100%\n",
      "Epoch [58/300], Step [99/225], Training Accuracy: 91.9034%, Training Loss: 0.2099%\n",
      "Epoch [58/300], Step [100/225], Training Accuracy: 91.9219%, Training Loss: 0.2098%\n",
      "Epoch [58/300], Step [101/225], Training Accuracy: 91.9245%, Training Loss: 0.2092%\n",
      "Epoch [58/300], Step [102/225], Training Accuracy: 91.9271%, Training Loss: 0.2095%\n",
      "Epoch [58/300], Step [103/225], Training Accuracy: 91.9144%, Training Loss: 0.2095%\n",
      "Epoch [58/300], Step [104/225], Training Accuracy: 91.8570%, Training Loss: 0.2106%\n",
      "Epoch [58/300], Step [105/225], Training Accuracy: 91.8750%, Training Loss: 0.2097%\n",
      "Epoch [58/300], Step [106/225], Training Accuracy: 91.8779%, Training Loss: 0.2097%\n",
      "Epoch [58/300], Step [107/225], Training Accuracy: 91.8224%, Training Loss: 0.2109%\n",
      "Epoch [58/300], Step [108/225], Training Accuracy: 91.8113%, Training Loss: 0.2110%\n",
      "Epoch [58/300], Step [109/225], Training Accuracy: 91.8291%, Training Loss: 0.2109%\n",
      "Epoch [58/300], Step [110/225], Training Accuracy: 91.8040%, Training Loss: 0.2110%\n",
      "Epoch [58/300], Step [111/225], Training Accuracy: 91.7793%, Training Loss: 0.2115%\n",
      "Epoch [58/300], Step [112/225], Training Accuracy: 91.7969%, Training Loss: 0.2114%\n",
      "Epoch [58/300], Step [113/225], Training Accuracy: 91.8280%, Training Loss: 0.2110%\n",
      "Epoch [58/300], Step [114/225], Training Accuracy: 91.7626%, Training Loss: 0.2115%\n",
      "Epoch [58/300], Step [115/225], Training Accuracy: 91.7663%, Training Loss: 0.2107%\n",
      "Epoch [58/300], Step [116/225], Training Accuracy: 91.7969%, Training Loss: 0.2102%\n",
      "Epoch [58/300], Step [117/225], Training Accuracy: 91.8269%, Training Loss: 0.2095%\n",
      "Epoch [58/300], Step [118/225], Training Accuracy: 91.8697%, Training Loss: 0.2088%\n",
      "Epoch [58/300], Step [119/225], Training Accuracy: 91.8724%, Training Loss: 0.2084%\n",
      "Epoch [58/300], Step [120/225], Training Accuracy: 91.9010%, Training Loss: 0.2080%\n",
      "Epoch [58/300], Step [121/225], Training Accuracy: 91.8905%, Training Loss: 0.2079%\n",
      "Epoch [58/300], Step [122/225], Training Accuracy: 91.9057%, Training Loss: 0.2074%\n",
      "Epoch [58/300], Step [123/225], Training Accuracy: 91.9080%, Training Loss: 0.2070%\n",
      "Epoch [58/300], Step [124/225], Training Accuracy: 91.9229%, Training Loss: 0.2065%\n",
      "Epoch [58/300], Step [125/225], Training Accuracy: 91.9125%, Training Loss: 0.2068%\n",
      "Epoch [58/300], Step [126/225], Training Accuracy: 91.8899%, Training Loss: 0.2074%\n",
      "Epoch [58/300], Step [127/225], Training Accuracy: 91.8676%, Training Loss: 0.2074%\n",
      "Epoch [58/300], Step [128/225], Training Accuracy: 91.9067%, Training Loss: 0.2067%\n",
      "Epoch [58/300], Step [129/225], Training Accuracy: 91.9089%, Training Loss: 0.2065%\n",
      "Epoch [58/300], Step [130/225], Training Accuracy: 91.8630%, Training Loss: 0.2081%\n",
      "Epoch [58/300], Step [131/225], Training Accuracy: 91.7939%, Training Loss: 0.2093%\n",
      "Epoch [58/300], Step [132/225], Training Accuracy: 91.8087%, Training Loss: 0.2093%\n",
      "Epoch [58/300], Step [133/225], Training Accuracy: 91.7881%, Training Loss: 0.2097%\n",
      "Epoch [58/300], Step [134/225], Training Accuracy: 91.8027%, Training Loss: 0.2099%\n",
      "Epoch [58/300], Step [135/225], Training Accuracy: 91.8519%, Training Loss: 0.2090%\n",
      "Epoch [58/300], Step [136/225], Training Accuracy: 91.7969%, Training Loss: 0.2105%\n",
      "Epoch [58/300], Step [137/225], Training Accuracy: 91.7655%, Training Loss: 0.2107%\n",
      "Epoch [58/300], Step [138/225], Training Accuracy: 91.7912%, Training Loss: 0.2099%\n",
      "Epoch [58/300], Step [139/225], Training Accuracy: 91.7491%, Training Loss: 0.2108%\n",
      "Epoch [58/300], Step [140/225], Training Accuracy: 91.7522%, Training Loss: 0.2104%\n",
      "Epoch [58/300], Step [141/225], Training Accuracy: 91.7664%, Training Loss: 0.2103%\n",
      "Epoch [58/300], Step [142/225], Training Accuracy: 91.7804%, Training Loss: 0.2099%\n",
      "Epoch [58/300], Step [143/225], Training Accuracy: 91.8160%, Training Loss: 0.2091%\n",
      "Epoch [58/300], Step [144/225], Training Accuracy: 91.8077%, Training Loss: 0.2090%\n",
      "Epoch [58/300], Step [145/225], Training Accuracy: 91.8211%, Training Loss: 0.2086%\n",
      "Epoch [58/300], Step [146/225], Training Accuracy: 91.8022%, Training Loss: 0.2088%\n",
      "Epoch [58/300], Step [147/225], Training Accuracy: 91.8155%, Training Loss: 0.2085%\n",
      "Epoch [58/300], Step [148/225], Training Accuracy: 91.8285%, Training Loss: 0.2088%\n",
      "Epoch [58/300], Step [149/225], Training Accuracy: 91.8310%, Training Loss: 0.2085%\n",
      "Epoch [58/300], Step [150/225], Training Accuracy: 91.8646%, Training Loss: 0.2075%\n",
      "Epoch [58/300], Step [151/225], Training Accuracy: 91.8771%, Training Loss: 0.2072%\n",
      "Epoch [58/300], Step [152/225], Training Accuracy: 91.8586%, Training Loss: 0.2072%\n",
      "Epoch [58/300], Step [153/225], Training Accuracy: 91.8403%, Training Loss: 0.2074%\n",
      "Epoch [58/300], Step [154/225], Training Accuracy: 91.8222%, Training Loss: 0.2072%\n",
      "Epoch [58/300], Step [155/225], Training Accuracy: 91.8246%, Training Loss: 0.2071%\n",
      "Epoch [58/300], Step [156/225], Training Accuracy: 91.8269%, Training Loss: 0.2070%\n",
      "Epoch [58/300], Step [157/225], Training Accuracy: 91.8093%, Training Loss: 0.2073%\n",
      "Epoch [58/300], Step [158/225], Training Accuracy: 91.8117%, Training Loss: 0.2076%\n",
      "Epoch [58/300], Step [159/225], Training Accuracy: 91.8337%, Training Loss: 0.2075%\n",
      "Epoch [58/300], Step [160/225], Training Accuracy: 91.8555%, Training Loss: 0.2072%\n",
      "Epoch [58/300], Step [161/225], Training Accuracy: 91.8769%, Training Loss: 0.2071%\n",
      "Epoch [58/300], Step [162/225], Training Accuracy: 91.8692%, Training Loss: 0.2070%\n",
      "Epoch [58/300], Step [163/225], Training Accuracy: 91.8808%, Training Loss: 0.2067%\n",
      "Epoch [58/300], Step [164/225], Training Accuracy: 91.9017%, Training Loss: 0.2061%\n",
      "Epoch [58/300], Step [165/225], Training Accuracy: 91.9223%, Training Loss: 0.2062%\n",
      "Epoch [58/300], Step [166/225], Training Accuracy: 91.9239%, Training Loss: 0.2066%\n",
      "Epoch [58/300], Step [167/225], Training Accuracy: 91.9068%, Training Loss: 0.2069%\n",
      "Epoch [58/300], Step [168/225], Training Accuracy: 91.9178%, Training Loss: 0.2069%\n",
      "Epoch [58/300], Step [169/225], Training Accuracy: 91.9286%, Training Loss: 0.2065%\n",
      "Epoch [58/300], Step [170/225], Training Accuracy: 91.9301%, Training Loss: 0.2065%\n",
      "Epoch [58/300], Step [171/225], Training Accuracy: 91.9134%, Training Loss: 0.2065%\n",
      "Epoch [58/300], Step [172/225], Training Accuracy: 91.9150%, Training Loss: 0.2065%\n",
      "Epoch [58/300], Step [173/225], Training Accuracy: 91.8985%, Training Loss: 0.2071%\n",
      "Epoch [58/300], Step [174/225], Training Accuracy: 91.8912%, Training Loss: 0.2071%\n",
      "Epoch [58/300], Step [175/225], Training Accuracy: 91.9107%, Training Loss: 0.2066%\n",
      "Epoch [58/300], Step [176/225], Training Accuracy: 91.9123%, Training Loss: 0.2066%\n",
      "Epoch [58/300], Step [177/225], Training Accuracy: 91.8962%, Training Loss: 0.2069%\n",
      "Epoch [58/300], Step [178/225], Training Accuracy: 91.8890%, Training Loss: 0.2068%\n",
      "Epoch [58/300], Step [179/225], Training Accuracy: 91.8645%, Training Loss: 0.2071%\n",
      "Epoch [58/300], Step [180/225], Training Accuracy: 91.8837%, Training Loss: 0.2069%\n",
      "Epoch [58/300], Step [181/225], Training Accuracy: 91.8767%, Training Loss: 0.2070%\n",
      "Epoch [58/300], Step [182/225], Training Accuracy: 91.8956%, Training Loss: 0.2065%\n",
      "Epoch [58/300], Step [183/225], Training Accuracy: 91.8887%, Training Loss: 0.2067%\n",
      "Epoch [58/300], Step [184/225], Training Accuracy: 91.9158%, Training Loss: 0.2063%\n",
      "Epoch [58/300], Step [185/225], Training Accuracy: 91.9172%, Training Loss: 0.2061%\n",
      "Epoch [58/300], Step [186/225], Training Accuracy: 91.9523%, Training Loss: 0.2057%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/300], Step [187/225], Training Accuracy: 91.9786%, Training Loss: 0.2054%\n",
      "Epoch [58/300], Step [188/225], Training Accuracy: 92.0047%, Training Loss: 0.2051%\n",
      "Epoch [58/300], Step [189/225], Training Accuracy: 92.0304%, Training Loss: 0.2046%\n",
      "Epoch [58/300], Step [190/225], Training Accuracy: 92.0148%, Training Loss: 0.2046%\n",
      "Epoch [58/300], Step [191/225], Training Accuracy: 91.9912%, Training Loss: 0.2048%\n",
      "Epoch [58/300], Step [192/225], Training Accuracy: 92.0166%, Training Loss: 0.2043%\n",
      "Epoch [58/300], Step [193/225], Training Accuracy: 92.0256%, Training Loss: 0.2041%\n",
      "Epoch [58/300], Step [194/225], Training Accuracy: 92.0184%, Training Loss: 0.2043%\n",
      "Epoch [58/300], Step [195/225], Training Accuracy: 92.0433%, Training Loss: 0.2038%\n",
      "Epoch [58/300], Step [196/225], Training Accuracy: 92.0360%, Training Loss: 0.2037%\n",
      "Epoch [58/300], Step [197/225], Training Accuracy: 92.0606%, Training Loss: 0.2030%\n",
      "Epoch [58/300], Step [198/225], Training Accuracy: 92.0770%, Training Loss: 0.2026%\n",
      "Epoch [58/300], Step [199/225], Training Accuracy: 92.0619%, Training Loss: 0.2026%\n",
      "Epoch [58/300], Step [200/225], Training Accuracy: 92.0781%, Training Loss: 0.2024%\n",
      "Epoch [58/300], Step [201/225], Training Accuracy: 92.1020%, Training Loss: 0.2020%\n",
      "Epoch [58/300], Step [202/225], Training Accuracy: 92.1024%, Training Loss: 0.2018%\n",
      "Epoch [58/300], Step [203/225], Training Accuracy: 92.1259%, Training Loss: 0.2014%\n",
      "Epoch [58/300], Step [204/225], Training Accuracy: 92.1415%, Training Loss: 0.2013%\n",
      "Epoch [58/300], Step [205/225], Training Accuracy: 92.1265%, Training Loss: 0.2015%\n",
      "Epoch [58/300], Step [206/225], Training Accuracy: 92.1192%, Training Loss: 0.2018%\n",
      "Epoch [58/300], Step [207/225], Training Accuracy: 92.1120%, Training Loss: 0.2017%\n",
      "Epoch [58/300], Step [208/225], Training Accuracy: 92.1424%, Training Loss: 0.2011%\n",
      "Epoch [58/300], Step [209/225], Training Accuracy: 92.1277%, Training Loss: 0.2014%\n",
      "Epoch [58/300], Step [210/225], Training Accuracy: 92.1503%, Training Loss: 0.2009%\n",
      "Epoch [58/300], Step [211/225], Training Accuracy: 92.1431%, Training Loss: 0.2010%\n",
      "Epoch [58/300], Step [212/225], Training Accuracy: 92.1506%, Training Loss: 0.2009%\n",
      "Epoch [58/300], Step [213/225], Training Accuracy: 92.1215%, Training Loss: 0.2015%\n",
      "Epoch [58/300], Step [214/225], Training Accuracy: 92.1291%, Training Loss: 0.2013%\n",
      "Epoch [58/300], Step [215/225], Training Accuracy: 92.1366%, Training Loss: 0.2011%\n",
      "Epoch [58/300], Step [216/225], Training Accuracy: 92.1586%, Training Loss: 0.2008%\n",
      "Epoch [58/300], Step [217/225], Training Accuracy: 92.1371%, Training Loss: 0.2010%\n",
      "Epoch [58/300], Step [218/225], Training Accuracy: 92.1230%, Training Loss: 0.2012%\n",
      "Epoch [58/300], Step [219/225], Training Accuracy: 92.1162%, Training Loss: 0.2012%\n",
      "Epoch [58/300], Step [220/225], Training Accuracy: 92.1094%, Training Loss: 0.2010%\n",
      "Epoch [58/300], Step [221/225], Training Accuracy: 92.1309%, Training Loss: 0.2006%\n",
      "Epoch [58/300], Step [222/225], Training Accuracy: 92.1242%, Training Loss: 0.2009%\n",
      "Epoch [58/300], Step [223/225], Training Accuracy: 92.1314%, Training Loss: 0.2008%\n",
      "Epoch [58/300], Step [224/225], Training Accuracy: 92.1596%, Training Loss: 0.2003%\n",
      "Epoch [58/300], Step [225/225], Training Accuracy: 92.1762%, Training Loss: 0.2000%\n",
      "Epoch [59/300], Step [1/225], Training Accuracy: 98.4375%, Training Loss: 0.1059%\n",
      "Epoch [59/300], Step [2/225], Training Accuracy: 93.7500%, Training Loss: 0.2181%\n",
      "Epoch [59/300], Step [3/225], Training Accuracy: 93.2292%, Training Loss: 0.2072%\n",
      "Epoch [59/300], Step [4/225], Training Accuracy: 91.4062%, Training Loss: 0.2197%\n",
      "Epoch [59/300], Step [5/225], Training Accuracy: 92.1875%, Training Loss: 0.2125%\n",
      "Epoch [59/300], Step [6/225], Training Accuracy: 92.1875%, Training Loss: 0.2133%\n",
      "Epoch [59/300], Step [7/225], Training Accuracy: 92.4107%, Training Loss: 0.2078%\n",
      "Epoch [59/300], Step [8/225], Training Accuracy: 91.7969%, Training Loss: 0.2164%\n",
      "Epoch [59/300], Step [9/225], Training Accuracy: 92.1875%, Training Loss: 0.2130%\n",
      "Epoch [59/300], Step [10/225], Training Accuracy: 92.3438%, Training Loss: 0.2067%\n",
      "Epoch [59/300], Step [11/225], Training Accuracy: 91.7614%, Training Loss: 0.2112%\n",
      "Epoch [59/300], Step [12/225], Training Accuracy: 91.6667%, Training Loss: 0.2121%\n",
      "Epoch [59/300], Step [13/225], Training Accuracy: 92.0673%, Training Loss: 0.2039%\n",
      "Epoch [59/300], Step [14/225], Training Accuracy: 92.2991%, Training Loss: 0.2003%\n",
      "Epoch [59/300], Step [15/225], Training Accuracy: 92.3958%, Training Loss: 0.1993%\n",
      "Epoch [59/300], Step [16/225], Training Accuracy: 91.7969%, Training Loss: 0.2153%\n",
      "Epoch [59/300], Step [17/225], Training Accuracy: 91.8199%, Training Loss: 0.2130%\n",
      "Epoch [59/300], Step [18/225], Training Accuracy: 92.1875%, Training Loss: 0.2066%\n",
      "Epoch [59/300], Step [19/225], Training Accuracy: 92.3520%, Training Loss: 0.2028%\n",
      "Epoch [59/300], Step [20/225], Training Accuracy: 92.7344%, Training Loss: 0.1950%\n",
      "Epoch [59/300], Step [21/225], Training Accuracy: 92.9315%, Training Loss: 0.1914%\n",
      "Epoch [59/300], Step [22/225], Training Accuracy: 92.6847%, Training Loss: 0.1970%\n",
      "Epoch [59/300], Step [23/225], Training Accuracy: 92.8668%, Training Loss: 0.1931%\n",
      "Epoch [59/300], Step [24/225], Training Accuracy: 92.7734%, Training Loss: 0.1972%\n",
      "Epoch [59/300], Step [25/225], Training Accuracy: 92.9375%, Training Loss: 0.1925%\n",
      "Epoch [59/300], Step [26/225], Training Accuracy: 93.0288%, Training Loss: 0.1916%\n",
      "Epoch [59/300], Step [27/225], Training Accuracy: 93.1134%, Training Loss: 0.1878%\n",
      "Epoch [59/300], Step [28/225], Training Accuracy: 93.1362%, Training Loss: 0.1859%\n",
      "Epoch [59/300], Step [29/225], Training Accuracy: 93.0496%, Training Loss: 0.1896%\n",
      "Epoch [59/300], Step [30/225], Training Accuracy: 93.0729%, Training Loss: 0.1871%\n",
      "Epoch [59/300], Step [31/225], Training Accuracy: 93.0444%, Training Loss: 0.1880%\n",
      "Epoch [59/300], Step [32/225], Training Accuracy: 93.1641%, Training Loss: 0.1841%\n",
      "Epoch [59/300], Step [33/225], Training Accuracy: 93.0871%, Training Loss: 0.1853%\n",
      "Epoch [59/300], Step [34/225], Training Accuracy: 93.0607%, Training Loss: 0.1865%\n",
      "Epoch [59/300], Step [35/225], Training Accuracy: 92.9911%, Training Loss: 0.1874%\n",
      "Epoch [59/300], Step [36/225], Training Accuracy: 93.0122%, Training Loss: 0.1910%\n",
      "Epoch [59/300], Step [37/225], Training Accuracy: 92.9899%, Training Loss: 0.1904%\n",
      "Epoch [59/300], Step [38/225], Training Accuracy: 92.8865%, Training Loss: 0.1908%\n",
      "Epoch [59/300], Step [39/225], Training Accuracy: 92.8285%, Training Loss: 0.1918%\n",
      "Epoch [59/300], Step [40/225], Training Accuracy: 92.6562%, Training Loss: 0.1959%\n",
      "Epoch [59/300], Step [41/225], Training Accuracy: 92.4543%, Training Loss: 0.1990%\n",
      "Epoch [59/300], Step [42/225], Training Accuracy: 92.3363%, Training Loss: 0.1997%\n",
      "Epoch [59/300], Step [43/225], Training Accuracy: 92.3328%, Training Loss: 0.2002%\n",
      "Epoch [59/300], Step [44/225], Training Accuracy: 92.3651%, Training Loss: 0.1997%\n",
      "Epoch [59/300], Step [45/225], Training Accuracy: 92.3958%, Training Loss: 0.1997%\n",
      "Epoch [59/300], Step [46/225], Training Accuracy: 92.4253%, Training Loss: 0.1993%\n",
      "Epoch [59/300], Step [47/225], Training Accuracy: 92.3205%, Training Loss: 0.2016%\n",
      "Epoch [59/300], Step [48/225], Training Accuracy: 92.2201%, Training Loss: 0.2033%\n",
      "Epoch [59/300], Step [49/225], Training Accuracy: 92.2832%, Training Loss: 0.2016%\n",
      "Epoch [59/300], Step [50/225], Training Accuracy: 92.3125%, Training Loss: 0.2023%\n",
      "Epoch [59/300], Step [51/225], Training Accuracy: 92.2794%, Training Loss: 0.2030%\n",
      "Epoch [59/300], Step [52/225], Training Accuracy: 92.2776%, Training Loss: 0.2027%\n",
      "Epoch [59/300], Step [53/225], Training Accuracy: 92.2465%, Training Loss: 0.2021%\n",
      "Epoch [59/300], Step [54/225], Training Accuracy: 92.2164%, Training Loss: 0.2028%\n",
      "Epoch [59/300], Step [55/225], Training Accuracy: 92.2727%, Training Loss: 0.2020%\n",
      "Epoch [59/300], Step [56/225], Training Accuracy: 92.2433%, Training Loss: 0.2020%\n",
      "Epoch [59/300], Step [57/225], Training Accuracy: 92.1875%, Training Loss: 0.2027%\n",
      "Epoch [59/300], Step [58/225], Training Accuracy: 92.2414%, Training Loss: 0.2033%\n",
      "Epoch [59/300], Step [59/225], Training Accuracy: 92.2934%, Training Loss: 0.2040%\n",
      "Epoch [59/300], Step [60/225], Training Accuracy: 92.2917%, Training Loss: 0.2037%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/300], Step [61/225], Training Accuracy: 92.2643%, Training Loss: 0.2045%\n",
      "Epoch [59/300], Step [62/225], Training Accuracy: 92.2883%, Training Loss: 0.2056%\n",
      "Epoch [59/300], Step [63/225], Training Accuracy: 92.3115%, Training Loss: 0.2052%\n",
      "Epoch [59/300], Step [64/225], Training Accuracy: 92.3828%, Training Loss: 0.2040%\n",
      "Epoch [59/300], Step [65/225], Training Accuracy: 92.2596%, Training Loss: 0.2075%\n",
      "Epoch [59/300], Step [66/225], Training Accuracy: 92.2348%, Training Loss: 0.2071%\n",
      "Epoch [59/300], Step [67/225], Training Accuracy: 92.0709%, Training Loss: 0.2091%\n",
      "Epoch [59/300], Step [68/225], Training Accuracy: 92.0037%, Training Loss: 0.2098%\n",
      "Epoch [59/300], Step [69/225], Training Accuracy: 92.0516%, Training Loss: 0.2094%\n",
      "Epoch [59/300], Step [70/225], Training Accuracy: 92.0759%, Training Loss: 0.2091%\n",
      "Epoch [59/300], Step [71/225], Training Accuracy: 92.0775%, Training Loss: 0.2089%\n",
      "Epoch [59/300], Step [72/225], Training Accuracy: 92.1007%, Training Loss: 0.2083%\n",
      "Epoch [59/300], Step [73/225], Training Accuracy: 92.1233%, Training Loss: 0.2077%\n",
      "Epoch [59/300], Step [74/225], Training Accuracy: 92.1453%, Training Loss: 0.2093%\n",
      "Epoch [59/300], Step [75/225], Training Accuracy: 92.1250%, Training Loss: 0.2101%\n",
      "Epoch [59/300], Step [76/225], Training Accuracy: 92.0847%, Training Loss: 0.2103%\n",
      "Epoch [59/300], Step [77/225], Training Accuracy: 92.0657%, Training Loss: 0.2104%\n",
      "Epoch [59/300], Step [78/225], Training Accuracy: 92.0873%, Training Loss: 0.2100%\n",
      "Epoch [59/300], Step [79/225], Training Accuracy: 92.0293%, Training Loss: 0.2104%\n",
      "Epoch [59/300], Step [80/225], Training Accuracy: 91.9727%, Training Loss: 0.2104%\n",
      "Epoch [59/300], Step [81/225], Training Accuracy: 91.9946%, Training Loss: 0.2099%\n",
      "Epoch [59/300], Step [82/225], Training Accuracy: 92.0351%, Training Loss: 0.2085%\n",
      "Epoch [59/300], Step [83/225], Training Accuracy: 91.9992%, Training Loss: 0.2083%\n",
      "Epoch [59/300], Step [84/225], Training Accuracy: 92.0573%, Training Loss: 0.2069%\n",
      "Epoch [59/300], Step [85/225], Training Accuracy: 92.0221%, Training Loss: 0.2079%\n",
      "Epoch [59/300], Step [86/225], Training Accuracy: 92.0240%, Training Loss: 0.2085%\n",
      "Epoch [59/300], Step [87/225], Training Accuracy: 91.9899%, Training Loss: 0.2089%\n",
      "Epoch [59/300], Step [88/225], Training Accuracy: 91.9212%, Training Loss: 0.2097%\n",
      "Epoch [59/300], Step [89/225], Training Accuracy: 91.9066%, Training Loss: 0.2097%\n",
      "Epoch [59/300], Step [90/225], Training Accuracy: 91.9097%, Training Loss: 0.2105%\n",
      "Epoch [59/300], Step [91/225], Training Accuracy: 91.9299%, Training Loss: 0.2097%\n",
      "Epoch [59/300], Step [92/225], Training Accuracy: 91.8988%, Training Loss: 0.2109%\n",
      "Epoch [59/300], Step [93/225], Training Accuracy: 91.9187%, Training Loss: 0.2102%\n",
      "Epoch [59/300], Step [94/225], Training Accuracy: 91.9049%, Training Loss: 0.2107%\n",
      "Epoch [59/300], Step [95/225], Training Accuracy: 91.8750%, Training Loss: 0.2103%\n",
      "Epoch [59/300], Step [96/225], Training Accuracy: 91.8620%, Training Loss: 0.2101%\n",
      "Epoch [59/300], Step [97/225], Training Accuracy: 91.8653%, Training Loss: 0.2099%\n",
      "Epoch [59/300], Step [98/225], Training Accuracy: 91.9324%, Training Loss: 0.2088%\n",
      "Epoch [59/300], Step [99/225], Training Accuracy: 91.9665%, Training Loss: 0.2078%\n",
      "Epoch [59/300], Step [100/225], Training Accuracy: 91.9375%, Training Loss: 0.2085%\n",
      "Epoch [59/300], Step [101/225], Training Accuracy: 91.9864%, Training Loss: 0.2078%\n",
      "Epoch [59/300], Step [102/225], Training Accuracy: 92.0190%, Training Loss: 0.2071%\n",
      "Epoch [59/300], Step [103/225], Training Accuracy: 92.0206%, Training Loss: 0.2066%\n",
      "Epoch [59/300], Step [104/225], Training Accuracy: 92.0523%, Training Loss: 0.2059%\n",
      "Epoch [59/300], Step [105/225], Training Accuracy: 92.0833%, Training Loss: 0.2052%\n",
      "Epoch [59/300], Step [106/225], Training Accuracy: 92.1138%, Training Loss: 0.2047%\n",
      "Epoch [59/300], Step [107/225], Training Accuracy: 92.1583%, Training Loss: 0.2045%\n",
      "Epoch [59/300], Step [108/225], Training Accuracy: 92.1296%, Training Loss: 0.2045%\n",
      "Epoch [59/300], Step [109/225], Training Accuracy: 92.0728%, Training Loss: 0.2049%\n",
      "Epoch [59/300], Step [110/225], Training Accuracy: 92.0881%, Training Loss: 0.2046%\n",
      "Epoch [59/300], Step [111/225], Training Accuracy: 92.1171%, Training Loss: 0.2040%\n",
      "Epoch [59/300], Step [112/225], Training Accuracy: 92.0898%, Training Loss: 0.2044%\n",
      "Epoch [59/300], Step [113/225], Training Accuracy: 92.0631%, Training Loss: 0.2050%\n",
      "Epoch [59/300], Step [114/225], Training Accuracy: 92.0504%, Training Loss: 0.2049%\n",
      "Epoch [59/300], Step [115/225], Training Accuracy: 92.0380%, Training Loss: 0.2052%\n",
      "Epoch [59/300], Step [116/225], Training Accuracy: 92.0124%, Training Loss: 0.2055%\n",
      "Epoch [59/300], Step [117/225], Training Accuracy: 91.9738%, Training Loss: 0.2064%\n",
      "Epoch [59/300], Step [118/225], Training Accuracy: 92.0021%, Training Loss: 0.2065%\n",
      "Epoch [59/300], Step [119/225], Training Accuracy: 92.0168%, Training Loss: 0.2059%\n",
      "Epoch [59/300], Step [120/225], Training Accuracy: 92.0443%, Training Loss: 0.2063%\n",
      "Epoch [59/300], Step [121/225], Training Accuracy: 92.0842%, Training Loss: 0.2054%\n",
      "Epoch [59/300], Step [122/225], Training Accuracy: 92.0850%, Training Loss: 0.2053%\n",
      "Epoch [59/300], Step [123/225], Training Accuracy: 92.0859%, Training Loss: 0.2052%\n",
      "Epoch [59/300], Step [124/225], Training Accuracy: 92.0867%, Training Loss: 0.2052%\n",
      "Epoch [59/300], Step [125/225], Training Accuracy: 92.0500%, Training Loss: 0.2060%\n",
      "Epoch [59/300], Step [126/225], Training Accuracy: 92.0263%, Training Loss: 0.2061%\n",
      "Epoch [59/300], Step [127/225], Training Accuracy: 92.0399%, Training Loss: 0.2060%\n",
      "Epoch [59/300], Step [128/225], Training Accuracy: 92.0288%, Training Loss: 0.2066%\n",
      "Epoch [59/300], Step [129/225], Training Accuracy: 92.0058%, Training Loss: 0.2069%\n",
      "Epoch [59/300], Step [130/225], Training Accuracy: 92.0192%, Training Loss: 0.2065%\n",
      "Epoch [59/300], Step [131/225], Training Accuracy: 92.0324%, Training Loss: 0.2063%\n",
      "Epoch [59/300], Step [132/225], Training Accuracy: 92.0099%, Training Loss: 0.2065%\n",
      "Epoch [59/300], Step [133/225], Training Accuracy: 92.0113%, Training Loss: 0.2062%\n",
      "Epoch [59/300], Step [134/225], Training Accuracy: 92.0126%, Training Loss: 0.2062%\n",
      "Epoch [59/300], Step [135/225], Training Accuracy: 92.0255%, Training Loss: 0.2058%\n",
      "Epoch [59/300], Step [136/225], Training Accuracy: 91.9807%, Training Loss: 0.2066%\n",
      "Epoch [59/300], Step [137/225], Training Accuracy: 91.9822%, Training Loss: 0.2064%\n",
      "Epoch [59/300], Step [138/225], Training Accuracy: 91.9611%, Training Loss: 0.2063%\n",
      "Epoch [59/300], Step [139/225], Training Accuracy: 91.9514%, Training Loss: 0.2063%\n",
      "Epoch [59/300], Step [140/225], Training Accuracy: 91.9531%, Training Loss: 0.2062%\n",
      "Epoch [59/300], Step [141/225], Training Accuracy: 91.9548%, Training Loss: 0.2064%\n",
      "Epoch [59/300], Step [142/225], Training Accuracy: 91.9894%, Training Loss: 0.2055%\n",
      "Epoch [59/300], Step [143/225], Training Accuracy: 91.9471%, Training Loss: 0.2058%\n",
      "Epoch [59/300], Step [144/225], Training Accuracy: 91.9922%, Training Loss: 0.2050%\n",
      "Epoch [59/300], Step [145/225], Training Accuracy: 91.9935%, Training Loss: 0.2050%\n",
      "Epoch [59/300], Step [146/225], Training Accuracy: 92.0377%, Training Loss: 0.2042%\n",
      "Epoch [59/300], Step [147/225], Training Accuracy: 92.0599%, Training Loss: 0.2038%\n",
      "Epoch [59/300], Step [148/225], Training Accuracy: 92.0925%, Training Loss: 0.2032%\n",
      "Epoch [59/300], Step [149/225], Training Accuracy: 92.1246%, Training Loss: 0.2026%\n",
      "Epoch [59/300], Step [150/225], Training Accuracy: 92.1458%, Training Loss: 0.2021%\n",
      "Epoch [59/300], Step [151/225], Training Accuracy: 92.1772%, Training Loss: 0.2017%\n",
      "Epoch [59/300], Step [152/225], Training Accuracy: 92.1875%, Training Loss: 0.2012%\n",
      "Epoch [59/300], Step [153/225], Training Accuracy: 92.1671%, Training Loss: 0.2013%\n",
      "Epoch [59/300], Step [154/225], Training Accuracy: 92.1875%, Training Loss: 0.2008%\n",
      "Epoch [59/300], Step [155/225], Training Accuracy: 92.1976%, Training Loss: 0.2007%\n",
      "Epoch [59/300], Step [156/225], Training Accuracy: 92.1675%, Training Loss: 0.2009%\n",
      "Epoch [59/300], Step [157/225], Training Accuracy: 92.1775%, Training Loss: 0.2008%\n",
      "Epoch [59/300], Step [158/225], Training Accuracy: 92.1974%, Training Loss: 0.2002%\n",
      "Epoch [59/300], Step [159/225], Training Accuracy: 92.1678%, Training Loss: 0.2008%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/300], Step [160/225], Training Accuracy: 92.1582%, Training Loss: 0.2012%\n",
      "Epoch [59/300], Step [161/225], Training Accuracy: 92.1293%, Training Loss: 0.2018%\n",
      "Epoch [59/300], Step [162/225], Training Accuracy: 92.1296%, Training Loss: 0.2016%\n",
      "Epoch [59/300], Step [163/225], Training Accuracy: 92.1300%, Training Loss: 0.2015%\n",
      "Epoch [59/300], Step [164/225], Training Accuracy: 92.1589%, Training Loss: 0.2012%\n",
      "Epoch [59/300], Step [165/225], Training Accuracy: 92.1875%, Training Loss: 0.2008%\n",
      "Epoch [59/300], Step [166/225], Training Accuracy: 92.1969%, Training Loss: 0.2008%\n",
      "Epoch [59/300], Step [167/225], Training Accuracy: 92.2062%, Training Loss: 0.2006%\n",
      "Epoch [59/300], Step [168/225], Training Accuracy: 92.1410%, Training Loss: 0.2018%\n",
      "Epoch [59/300], Step [169/225], Training Accuracy: 92.1690%, Training Loss: 0.2013%\n",
      "Epoch [59/300], Step [170/225], Training Accuracy: 92.1324%, Training Loss: 0.2020%\n",
      "Epoch [59/300], Step [171/225], Training Accuracy: 92.1235%, Training Loss: 0.2021%\n",
      "Epoch [59/300], Step [172/225], Training Accuracy: 92.0876%, Training Loss: 0.2030%\n",
      "Epoch [59/300], Step [173/225], Training Accuracy: 92.1062%, Training Loss: 0.2026%\n",
      "Epoch [59/300], Step [174/225], Training Accuracy: 92.1336%, Training Loss: 0.2019%\n",
      "Epoch [59/300], Step [175/225], Training Accuracy: 92.1250%, Training Loss: 0.2024%\n",
      "Epoch [59/300], Step [176/225], Training Accuracy: 92.1165%, Training Loss: 0.2022%\n",
      "Epoch [59/300], Step [177/225], Training Accuracy: 92.1434%, Training Loss: 0.2017%\n",
      "Epoch [59/300], Step [178/225], Training Accuracy: 92.1612%, Training Loss: 0.2013%\n",
      "Epoch [59/300], Step [179/225], Training Accuracy: 92.1875%, Training Loss: 0.2009%\n",
      "Epoch [59/300], Step [180/225], Training Accuracy: 92.1788%, Training Loss: 0.2010%\n",
      "Epoch [59/300], Step [181/225], Training Accuracy: 92.1875%, Training Loss: 0.2009%\n",
      "Epoch [59/300], Step [182/225], Training Accuracy: 92.2047%, Training Loss: 0.2008%\n",
      "Epoch [59/300], Step [183/225], Training Accuracy: 92.2046%, Training Loss: 0.2012%\n",
      "Epoch [59/300], Step [184/225], Training Accuracy: 92.2130%, Training Loss: 0.2007%\n",
      "Epoch [59/300], Step [185/225], Training Accuracy: 92.2213%, Training Loss: 0.2005%\n",
      "Epoch [59/300], Step [186/225], Training Accuracy: 92.2463%, Training Loss: 0.1997%\n",
      "Epoch [59/300], Step [187/225], Training Accuracy: 92.2460%, Training Loss: 0.1996%\n",
      "Epoch [59/300], Step [188/225], Training Accuracy: 92.2706%, Training Loss: 0.1994%\n",
      "Epoch [59/300], Step [189/225], Training Accuracy: 92.2784%, Training Loss: 0.1992%\n",
      "Epoch [59/300], Step [190/225], Training Accuracy: 92.3026%, Training Loss: 0.1987%\n",
      "Epoch [59/300], Step [191/225], Training Accuracy: 92.2938%, Training Loss: 0.1993%\n",
      "Epoch [59/300], Step [192/225], Training Accuracy: 92.3096%, Training Loss: 0.1990%\n",
      "Epoch [59/300], Step [193/225], Training Accuracy: 92.3170%, Training Loss: 0.1990%\n",
      "Epoch [59/300], Step [194/225], Training Accuracy: 92.3164%, Training Loss: 0.1990%\n",
      "Epoch [59/300], Step [195/225], Training Accuracy: 92.3317%, Training Loss: 0.1988%\n",
      "Epoch [59/300], Step [196/225], Training Accuracy: 92.3310%, Training Loss: 0.1990%\n",
      "Epoch [59/300], Step [197/225], Training Accuracy: 92.3541%, Training Loss: 0.1987%\n",
      "Epoch [59/300], Step [198/225], Training Accuracy: 92.3532%, Training Loss: 0.1986%\n",
      "Epoch [59/300], Step [199/225], Training Accuracy: 92.3602%, Training Loss: 0.1987%\n",
      "Epoch [59/300], Step [200/225], Training Accuracy: 92.3594%, Training Loss: 0.1987%\n",
      "Epoch [59/300], Step [201/225], Training Accuracy: 92.3430%, Training Loss: 0.1986%\n",
      "Epoch [59/300], Step [202/225], Training Accuracy: 92.3577%, Training Loss: 0.1983%\n",
      "Epoch [59/300], Step [203/225], Training Accuracy: 92.3645%, Training Loss: 0.1982%\n",
      "Epoch [59/300], Step [204/225], Training Accuracy: 92.4020%, Training Loss: 0.1975%\n",
      "Epoch [59/300], Step [205/225], Training Accuracy: 92.4238%, Training Loss: 0.1973%\n",
      "Epoch [59/300], Step [206/225], Training Accuracy: 92.4226%, Training Loss: 0.1977%\n",
      "Epoch [59/300], Step [207/225], Training Accuracy: 92.4290%, Training Loss: 0.1978%\n",
      "Epoch [59/300], Step [208/225], Training Accuracy: 92.4654%, Training Loss: 0.1973%\n",
      "Epoch [59/300], Step [209/225], Training Accuracy: 92.4566%, Training Loss: 0.1978%\n",
      "Epoch [59/300], Step [210/225], Training Accuracy: 92.4479%, Training Loss: 0.1979%\n",
      "Epoch [59/300], Step [211/225], Training Accuracy: 92.4541%, Training Loss: 0.1981%\n",
      "Epoch [59/300], Step [212/225], Training Accuracy: 92.4676%, Training Loss: 0.1979%\n",
      "Epoch [59/300], Step [213/225], Training Accuracy: 92.4663%, Training Loss: 0.1978%\n",
      "Epoch [59/300], Step [214/225], Training Accuracy: 92.4796%, Training Loss: 0.1978%\n",
      "Epoch [59/300], Step [215/225], Training Accuracy: 92.4927%, Training Loss: 0.1974%\n",
      "Epoch [59/300], Step [216/225], Training Accuracy: 92.5058%, Training Loss: 0.1972%\n",
      "Epoch [59/300], Step [217/225], Training Accuracy: 92.5187%, Training Loss: 0.1971%\n",
      "Epoch [59/300], Step [218/225], Training Accuracy: 92.4957%, Training Loss: 0.1973%\n",
      "Epoch [59/300], Step [219/225], Training Accuracy: 92.5228%, Training Loss: 0.1967%\n",
      "Epoch [59/300], Step [220/225], Training Accuracy: 92.5284%, Training Loss: 0.1965%\n",
      "Epoch [59/300], Step [221/225], Training Accuracy: 92.5269%, Training Loss: 0.1963%\n",
      "Epoch [59/300], Step [222/225], Training Accuracy: 92.5394%, Training Loss: 0.1961%\n",
      "Epoch [59/300], Step [223/225], Training Accuracy: 92.5378%, Training Loss: 0.1963%\n",
      "Epoch [59/300], Step [224/225], Training Accuracy: 92.5502%, Training Loss: 0.1960%\n",
      "Epoch [59/300], Step [225/225], Training Accuracy: 92.5375%, Training Loss: 0.1964%\n",
      "Epoch [60/300], Step [1/225], Training Accuracy: 90.6250%, Training Loss: 0.2145%\n",
      "Epoch [60/300], Step [2/225], Training Accuracy: 88.2812%, Training Loss: 0.2513%\n",
      "Epoch [60/300], Step [3/225], Training Accuracy: 91.1458%, Training Loss: 0.2109%\n",
      "Epoch [60/300], Step [4/225], Training Accuracy: 89.8438%, Training Loss: 0.2330%\n",
      "Epoch [60/300], Step [5/225], Training Accuracy: 88.7500%, Training Loss: 0.2338%\n",
      "Epoch [60/300], Step [6/225], Training Accuracy: 89.5833%, Training Loss: 0.2347%\n",
      "Epoch [60/300], Step [7/225], Training Accuracy: 89.0625%, Training Loss: 0.2430%\n",
      "Epoch [60/300], Step [8/225], Training Accuracy: 89.4531%, Training Loss: 0.2369%\n",
      "Epoch [60/300], Step [9/225], Training Accuracy: 89.0625%, Training Loss: 0.2423%\n",
      "Epoch [60/300], Step [10/225], Training Accuracy: 89.6875%, Training Loss: 0.2326%\n",
      "Epoch [60/300], Step [11/225], Training Accuracy: 89.6307%, Training Loss: 0.2351%\n",
      "Epoch [60/300], Step [12/225], Training Accuracy: 89.5833%, Training Loss: 0.2378%\n",
      "Epoch [60/300], Step [13/225], Training Accuracy: 89.7837%, Training Loss: 0.2280%\n",
      "Epoch [60/300], Step [14/225], Training Accuracy: 89.6205%, Training Loss: 0.2309%\n",
      "Epoch [60/300], Step [15/225], Training Accuracy: 89.8958%, Training Loss: 0.2289%\n",
      "Epoch [60/300], Step [16/225], Training Accuracy: 90.2344%, Training Loss: 0.2232%\n",
      "Epoch [60/300], Step [17/225], Training Accuracy: 90.3493%, Training Loss: 0.2196%\n",
      "Epoch [60/300], Step [18/225], Training Accuracy: 90.5382%, Training Loss: 0.2160%\n",
      "Epoch [60/300], Step [19/225], Training Accuracy: 90.3783%, Training Loss: 0.2160%\n",
      "Epoch [60/300], Step [20/225], Training Accuracy: 90.3906%, Training Loss: 0.2126%\n",
      "Epoch [60/300], Step [21/225], Training Accuracy: 90.1786%, Training Loss: 0.2134%\n",
      "Epoch [60/300], Step [22/225], Training Accuracy: 90.1989%, Training Loss: 0.2129%\n",
      "Epoch [60/300], Step [23/225], Training Accuracy: 90.0815%, Training Loss: 0.2155%\n",
      "Epoch [60/300], Step [24/225], Training Accuracy: 89.9740%, Training Loss: 0.2164%\n",
      "Epoch [60/300], Step [25/225], Training Accuracy: 90.1875%, Training Loss: 0.2121%\n",
      "Epoch [60/300], Step [26/225], Training Accuracy: 90.2644%, Training Loss: 0.2115%\n",
      "Epoch [60/300], Step [27/225], Training Accuracy: 90.4514%, Training Loss: 0.2075%\n",
      "Epoch [60/300], Step [28/225], Training Accuracy: 90.4576%, Training Loss: 0.2077%\n",
      "Epoch [60/300], Step [29/225], Training Accuracy: 90.5711%, Training Loss: 0.2092%\n",
      "Epoch [60/300], Step [30/225], Training Accuracy: 90.6250%, Training Loss: 0.2095%\n",
      "Epoch [60/300], Step [31/225], Training Accuracy: 90.5746%, Training Loss: 0.2114%\n",
      "Epoch [60/300], Step [32/225], Training Accuracy: 90.6250%, Training Loss: 0.2107%\n",
      "Epoch [60/300], Step [33/225], Training Accuracy: 90.7197%, Training Loss: 0.2106%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/300], Step [34/225], Training Accuracy: 90.6250%, Training Loss: 0.2157%\n",
      "Epoch [60/300], Step [35/225], Training Accuracy: 90.8036%, Training Loss: 0.2149%\n",
      "Epoch [60/300], Step [36/225], Training Accuracy: 90.9722%, Training Loss: 0.2107%\n",
      "Epoch [60/300], Step [37/225], Training Accuracy: 91.1318%, Training Loss: 0.2076%\n",
      "Epoch [60/300], Step [38/225], Training Accuracy: 91.0773%, Training Loss: 0.2096%\n",
      "Epoch [60/300], Step [39/225], Training Accuracy: 91.2260%, Training Loss: 0.2098%\n",
      "Epoch [60/300], Step [40/225], Training Accuracy: 91.2891%, Training Loss: 0.2090%\n",
      "Epoch [60/300], Step [41/225], Training Accuracy: 91.1966%, Training Loss: 0.2100%\n",
      "Epoch [60/300], Step [42/225], Training Accuracy: 91.2946%, Training Loss: 0.2081%\n",
      "Epoch [60/300], Step [43/225], Training Accuracy: 91.3517%, Training Loss: 0.2086%\n",
      "Epoch [60/300], Step [44/225], Training Accuracy: 91.4418%, Training Loss: 0.2074%\n",
      "Epoch [60/300], Step [45/225], Training Accuracy: 91.4931%, Training Loss: 0.2060%\n",
      "Epoch [60/300], Step [46/225], Training Accuracy: 91.6440%, Training Loss: 0.2031%\n",
      "Epoch [60/300], Step [47/225], Training Accuracy: 91.6223%, Training Loss: 0.2035%\n",
      "Epoch [60/300], Step [48/225], Training Accuracy: 91.6016%, Training Loss: 0.2035%\n",
      "Epoch [60/300], Step [49/225], Training Accuracy: 91.5816%, Training Loss: 0.2054%\n",
      "Epoch [60/300], Step [50/225], Training Accuracy: 91.6562%, Training Loss: 0.2048%\n",
      "Epoch [60/300], Step [51/225], Training Accuracy: 91.6667%, Training Loss: 0.2048%\n",
      "Epoch [60/300], Step [52/225], Training Accuracy: 91.7067%, Training Loss: 0.2039%\n",
      "Epoch [60/300], Step [53/225], Training Accuracy: 91.7158%, Training Loss: 0.2040%\n",
      "Epoch [60/300], Step [54/225], Training Accuracy: 91.8113%, Training Loss: 0.2027%\n",
      "Epoch [60/300], Step [55/225], Training Accuracy: 91.8182%, Training Loss: 0.2027%\n",
      "Epoch [60/300], Step [56/225], Training Accuracy: 91.7969%, Training Loss: 0.2036%\n",
      "Epoch [60/300], Step [57/225], Training Accuracy: 91.8037%, Training Loss: 0.2032%\n",
      "Epoch [60/300], Step [58/225], Training Accuracy: 91.8373%, Training Loss: 0.2023%\n",
      "Epoch [60/300], Step [59/225], Training Accuracy: 91.8167%, Training Loss: 0.2042%\n",
      "Epoch [60/300], Step [60/225], Training Accuracy: 91.7448%, Training Loss: 0.2065%\n",
      "Epoch [60/300], Step [61/225], Training Accuracy: 91.7264%, Training Loss: 0.2088%\n",
      "Epoch [60/300], Step [62/225], Training Accuracy: 91.7339%, Training Loss: 0.2085%\n",
      "Epoch [60/300], Step [63/225], Training Accuracy: 91.7411%, Training Loss: 0.2079%\n",
      "Epoch [60/300], Step [64/225], Training Accuracy: 91.7236%, Training Loss: 0.2075%\n",
      "Epoch [60/300], Step [65/225], Training Accuracy: 91.7067%, Training Loss: 0.2077%\n",
      "Epoch [60/300], Step [66/225], Training Accuracy: 91.7850%, Training Loss: 0.2062%\n",
      "Epoch [60/300], Step [67/225], Training Accuracy: 91.7910%, Training Loss: 0.2064%\n",
      "Epoch [60/300], Step [68/225], Training Accuracy: 91.7279%, Training Loss: 0.2074%\n",
      "Epoch [60/300], Step [69/225], Training Accuracy: 91.7572%, Training Loss: 0.2065%\n",
      "Epoch [60/300], Step [70/225], Training Accuracy: 91.8080%, Training Loss: 0.2058%\n",
      "Epoch [60/300], Step [71/225], Training Accuracy: 91.7474%, Training Loss: 0.2070%\n",
      "Epoch [60/300], Step [72/225], Training Accuracy: 91.7535%, Training Loss: 0.2064%\n",
      "Epoch [60/300], Step [73/225], Training Accuracy: 91.8022%, Training Loss: 0.2054%\n",
      "Epoch [60/300], Step [74/225], Training Accuracy: 91.8708%, Training Loss: 0.2047%\n",
      "Epoch [60/300], Step [75/225], Training Accuracy: 91.8125%, Training Loss: 0.2067%\n",
      "Epoch [60/300], Step [76/225], Training Accuracy: 91.7969%, Training Loss: 0.2083%\n",
      "Epoch [60/300], Step [77/225], Training Accuracy: 91.8222%, Training Loss: 0.2082%\n",
      "Epoch [60/300], Step [78/225], Training Accuracy: 91.8470%, Training Loss: 0.2075%\n",
      "Epoch [60/300], Step [79/225], Training Accuracy: 91.8710%, Training Loss: 0.2063%\n",
      "Epoch [60/300], Step [80/225], Training Accuracy: 91.8164%, Training Loss: 0.2074%\n",
      "Epoch [60/300], Step [81/225], Training Accuracy: 91.8210%, Training Loss: 0.2068%\n",
      "Epoch [60/300], Step [82/225], Training Accuracy: 91.8255%, Training Loss: 0.2066%\n",
      "Epoch [60/300], Step [83/225], Training Accuracy: 91.8110%, Training Loss: 0.2069%\n",
      "Epoch [60/300], Step [84/225], Training Accuracy: 91.7783%, Training Loss: 0.2071%\n",
      "Epoch [60/300], Step [85/225], Training Accuracy: 91.8199%, Training Loss: 0.2060%\n",
      "Epoch [60/300], Step [86/225], Training Accuracy: 91.8060%, Training Loss: 0.2058%\n",
      "Epoch [60/300], Step [87/225], Training Accuracy: 91.8283%, Training Loss: 0.2051%\n",
      "Epoch [60/300], Step [88/225], Training Accuracy: 91.7436%, Training Loss: 0.2067%\n",
      "Epoch [60/300], Step [89/225], Training Accuracy: 91.6784%, Training Loss: 0.2082%\n",
      "Epoch [60/300], Step [90/225], Training Accuracy: 91.6667%, Training Loss: 0.2086%\n",
      "Epoch [60/300], Step [91/225], Training Accuracy: 91.7067%, Training Loss: 0.2077%\n",
      "Epoch [60/300], Step [92/225], Training Accuracy: 91.6950%, Training Loss: 0.2079%\n",
      "Epoch [60/300], Step [93/225], Training Accuracy: 91.6499%, Training Loss: 0.2078%\n",
      "Epoch [60/300], Step [94/225], Training Accuracy: 91.5891%, Training Loss: 0.2079%\n",
      "Epoch [60/300], Step [95/225], Training Accuracy: 91.5625%, Training Loss: 0.2079%\n",
      "Epoch [60/300], Step [96/225], Training Accuracy: 91.6016%, Training Loss: 0.2071%\n",
      "Epoch [60/300], Step [97/225], Training Accuracy: 91.6076%, Training Loss: 0.2069%\n",
      "Epoch [60/300], Step [98/225], Training Accuracy: 91.5976%, Training Loss: 0.2083%\n",
      "Epoch [60/300], Step [99/225], Training Accuracy: 91.6351%, Training Loss: 0.2082%\n",
      "Epoch [60/300], Step [100/225], Training Accuracy: 91.5156%, Training Loss: 0.2113%\n",
      "Epoch [60/300], Step [101/225], Training Accuracy: 91.5068%, Training Loss: 0.2117%\n",
      "Epoch [60/300], Step [102/225], Training Accuracy: 91.4828%, Training Loss: 0.2122%\n",
      "Epoch [60/300], Step [103/225], Training Accuracy: 91.5352%, Training Loss: 0.2114%\n",
      "Epoch [60/300], Step [104/225], Training Accuracy: 91.5415%, Training Loss: 0.2113%\n",
      "Epoch [60/300], Step [105/225], Training Accuracy: 91.5476%, Training Loss: 0.2106%\n",
      "Epoch [60/300], Step [106/225], Training Accuracy: 91.6126%, Training Loss: 0.2094%\n",
      "Epoch [60/300], Step [107/225], Training Accuracy: 91.6472%, Training Loss: 0.2092%\n",
      "Epoch [60/300], Step [108/225], Training Accuracy: 91.6233%, Training Loss: 0.2093%\n",
      "Epoch [60/300], Step [109/225], Training Accuracy: 91.5998%, Training Loss: 0.2100%\n",
      "Epoch [60/300], Step [110/225], Training Accuracy: 91.6051%, Training Loss: 0.2094%\n",
      "Epoch [60/300], Step [111/225], Training Accuracy: 91.6104%, Training Loss: 0.2092%\n",
      "Epoch [60/300], Step [112/225], Training Accuracy: 91.6434%, Training Loss: 0.2086%\n",
      "Epoch [60/300], Step [113/225], Training Accuracy: 91.6759%, Training Loss: 0.2079%\n",
      "Epoch [60/300], Step [114/225], Training Accuracy: 91.6667%, Training Loss: 0.2084%\n",
      "Epoch [60/300], Step [115/225], Training Accuracy: 91.6440%, Training Loss: 0.2086%\n",
      "Epoch [60/300], Step [116/225], Training Accuracy: 91.6487%, Training Loss: 0.2094%\n",
      "Epoch [60/300], Step [117/225], Training Accuracy: 91.6667%, Training Loss: 0.2086%\n",
      "Epoch [60/300], Step [118/225], Training Accuracy: 91.6446%, Training Loss: 0.2090%\n",
      "Epoch [60/300], Step [119/225], Training Accuracy: 91.6492%, Training Loss: 0.2089%\n",
      "Epoch [60/300], Step [120/225], Training Accuracy: 91.6536%, Training Loss: 0.2089%\n",
      "Epoch [60/300], Step [121/225], Training Accuracy: 91.6710%, Training Loss: 0.2082%\n",
      "Epoch [60/300], Step [122/225], Training Accuracy: 91.6624%, Training Loss: 0.2085%\n",
      "Epoch [60/300], Step [123/225], Training Accuracy: 91.6921%, Training Loss: 0.2079%\n",
      "Epoch [60/300], Step [124/225], Training Accuracy: 91.7339%, Training Loss: 0.2073%\n",
      "Epoch [60/300], Step [125/225], Training Accuracy: 91.7750%, Training Loss: 0.2066%\n",
      "Epoch [60/300], Step [126/225], Training Accuracy: 91.7783%, Training Loss: 0.2067%\n",
      "Epoch [60/300], Step [127/225], Training Accuracy: 91.8307%, Training Loss: 0.2059%\n",
      "Epoch [60/300], Step [128/225], Training Accuracy: 91.8091%, Training Loss: 0.2062%\n",
      "Epoch [60/300], Step [129/225], Training Accuracy: 91.8241%, Training Loss: 0.2058%\n",
      "Epoch [60/300], Step [130/225], Training Accuracy: 91.8029%, Training Loss: 0.2070%\n",
      "Epoch [60/300], Step [131/225], Training Accuracy: 91.7820%, Training Loss: 0.2079%\n",
      "Epoch [60/300], Step [132/225], Training Accuracy: 91.8087%, Training Loss: 0.2077%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/300], Step [133/225], Training Accuracy: 91.8233%, Training Loss: 0.2075%\n",
      "Epoch [60/300], Step [134/225], Training Accuracy: 91.8027%, Training Loss: 0.2077%\n",
      "Epoch [60/300], Step [135/225], Training Accuracy: 91.8171%, Training Loss: 0.2075%\n",
      "Epoch [60/300], Step [136/225], Training Accuracy: 91.7969%, Training Loss: 0.2076%\n",
      "Epoch [60/300], Step [137/225], Training Accuracy: 91.8339%, Training Loss: 0.2072%\n",
      "Epoch [60/300], Step [138/225], Training Accuracy: 91.8478%, Training Loss: 0.2066%\n",
      "Epoch [60/300], Step [139/225], Training Accuracy: 91.8952%, Training Loss: 0.2059%\n",
      "Epoch [60/300], Step [140/225], Training Accuracy: 91.8973%, Training Loss: 0.2061%\n",
      "Epoch [60/300], Step [141/225], Training Accuracy: 91.9215%, Training Loss: 0.2059%\n",
      "Epoch [60/300], Step [142/225], Training Accuracy: 91.9344%, Training Loss: 0.2055%\n",
      "Epoch [60/300], Step [143/225], Training Accuracy: 91.9471%, Training Loss: 0.2050%\n",
      "Epoch [60/300], Step [144/225], Training Accuracy: 91.9705%, Training Loss: 0.2046%\n",
      "Epoch [60/300], Step [145/225], Training Accuracy: 91.9935%, Training Loss: 0.2043%\n",
      "Epoch [60/300], Step [146/225], Training Accuracy: 91.9949%, Training Loss: 0.2041%\n",
      "Epoch [60/300], Step [147/225], Training Accuracy: 92.0174%, Training Loss: 0.2036%\n",
      "Epoch [60/300], Step [148/225], Training Accuracy: 92.0397%, Training Loss: 0.2028%\n",
      "Epoch [60/300], Step [149/225], Training Accuracy: 92.0407%, Training Loss: 0.2027%\n",
      "Epoch [60/300], Step [150/225], Training Accuracy: 92.0729%, Training Loss: 0.2021%\n",
      "Epoch [60/300], Step [151/225], Training Accuracy: 92.0737%, Training Loss: 0.2018%\n",
      "Epoch [60/300], Step [152/225], Training Accuracy: 92.0847%, Training Loss: 0.2018%\n",
      "Epoch [60/300], Step [153/225], Training Accuracy: 92.0752%, Training Loss: 0.2018%\n",
      "Epoch [60/300], Step [154/225], Training Accuracy: 92.0860%, Training Loss: 0.2013%\n",
      "Epoch [60/300], Step [155/225], Training Accuracy: 92.1069%, Training Loss: 0.2011%\n",
      "Epoch [60/300], Step [156/225], Training Accuracy: 92.1174%, Training Loss: 0.2020%\n",
      "Epoch [60/300], Step [157/225], Training Accuracy: 92.1178%, Training Loss: 0.2018%\n",
      "Epoch [60/300], Step [158/225], Training Accuracy: 92.1578%, Training Loss: 0.2011%\n",
      "Epoch [60/300], Step [159/225], Training Accuracy: 92.1777%, Training Loss: 0.2009%\n",
      "Epoch [60/300], Step [160/225], Training Accuracy: 92.1680%, Training Loss: 0.2008%\n",
      "Epoch [60/300], Step [161/225], Training Accuracy: 92.1681%, Training Loss: 0.2009%\n",
      "Epoch [60/300], Step [162/225], Training Accuracy: 92.1779%, Training Loss: 0.2006%\n",
      "Epoch [60/300], Step [163/225], Training Accuracy: 92.1971%, Training Loss: 0.2003%\n",
      "Epoch [60/300], Step [164/225], Training Accuracy: 92.2351%, Training Loss: 0.1995%\n",
      "Epoch [60/300], Step [165/225], Training Accuracy: 92.2443%, Training Loss: 0.1995%\n",
      "Epoch [60/300], Step [166/225], Training Accuracy: 92.2628%, Training Loss: 0.1992%\n",
      "Epoch [60/300], Step [167/225], Training Accuracy: 92.2811%, Training Loss: 0.1991%\n",
      "Epoch [60/300], Step [168/225], Training Accuracy: 92.2433%, Training Loss: 0.1998%\n",
      "Epoch [60/300], Step [169/225], Training Accuracy: 92.2707%, Training Loss: 0.1992%\n",
      "Epoch [60/300], Step [170/225], Training Accuracy: 92.2886%, Training Loss: 0.1991%\n",
      "Epoch [60/300], Step [171/225], Training Accuracy: 92.2606%, Training Loss: 0.2004%\n",
      "Epoch [60/300], Step [172/225], Training Accuracy: 92.2602%, Training Loss: 0.2007%\n",
      "Epoch [60/300], Step [173/225], Training Accuracy: 92.2417%, Training Loss: 0.2010%\n",
      "Epoch [60/300], Step [174/225], Training Accuracy: 92.2414%, Training Loss: 0.2013%\n",
      "Epoch [60/300], Step [175/225], Training Accuracy: 92.2768%, Training Loss: 0.2006%\n",
      "Epoch [60/300], Step [176/225], Training Accuracy: 92.3029%, Training Loss: 0.2002%\n",
      "Epoch [60/300], Step [177/225], Training Accuracy: 92.2846%, Training Loss: 0.2006%\n",
      "Epoch [60/300], Step [178/225], Training Accuracy: 92.2928%, Training Loss: 0.2006%\n",
      "Epoch [60/300], Step [179/225], Training Accuracy: 92.2922%, Training Loss: 0.2004%\n",
      "Epoch [60/300], Step [180/225], Training Accuracy: 92.3090%, Training Loss: 0.2000%\n",
      "Epoch [60/300], Step [181/225], Training Accuracy: 92.2825%, Training Loss: 0.2006%\n",
      "Epoch [60/300], Step [182/225], Training Accuracy: 92.2648%, Training Loss: 0.2008%\n",
      "Epoch [60/300], Step [183/225], Training Accuracy: 92.2558%, Training Loss: 0.2010%\n",
      "Epoch [60/300], Step [184/225], Training Accuracy: 92.2639%, Training Loss: 0.2006%\n",
      "Epoch [60/300], Step [185/225], Training Accuracy: 92.2889%, Training Loss: 0.2000%\n",
      "Epoch [60/300], Step [186/225], Training Accuracy: 92.2799%, Training Loss: 0.2002%\n",
      "Epoch [60/300], Step [187/225], Training Accuracy: 92.3212%, Training Loss: 0.1995%\n",
      "Epoch [60/300], Step [188/225], Training Accuracy: 92.3205%, Training Loss: 0.1997%\n",
      "Epoch [60/300], Step [189/225], Training Accuracy: 92.3280%, Training Loss: 0.1999%\n",
      "Epoch [60/300], Step [190/225], Training Accuracy: 92.3273%, Training Loss: 0.2000%\n",
      "Epoch [60/300], Step [191/225], Training Accuracy: 92.3020%, Training Loss: 0.2005%\n",
      "Epoch [60/300], Step [192/225], Training Accuracy: 92.2852%, Training Loss: 0.2006%\n",
      "Epoch [60/300], Step [193/225], Training Accuracy: 92.2847%, Training Loss: 0.2006%\n",
      "Epoch [60/300], Step [194/225], Training Accuracy: 92.3083%, Training Loss: 0.2005%\n",
      "Epoch [60/300], Step [195/225], Training Accuracy: 92.3317%, Training Loss: 0.1999%\n",
      "Epoch [60/300], Step [196/225], Training Accuracy: 92.3390%, Training Loss: 0.1998%\n",
      "Epoch [60/300], Step [197/225], Training Accuracy: 92.3144%, Training Loss: 0.2005%\n",
      "Epoch [60/300], Step [198/225], Training Accuracy: 92.3295%, Training Loss: 0.2001%\n",
      "Epoch [60/300], Step [199/225], Training Accuracy: 92.3288%, Training Loss: 0.2001%\n",
      "Epoch [60/300], Step [200/225], Training Accuracy: 92.3125%, Training Loss: 0.2005%\n",
      "Epoch [60/300], Step [201/225], Training Accuracy: 92.2963%, Training Loss: 0.2010%\n",
      "Epoch [60/300], Step [202/225], Training Accuracy: 92.3345%, Training Loss: 0.2001%\n",
      "Epoch [60/300], Step [203/225], Training Accuracy: 92.3491%, Training Loss: 0.1998%\n",
      "Epoch [60/300], Step [204/225], Training Accuracy: 92.3637%, Training Loss: 0.1995%\n",
      "Epoch [60/300], Step [205/225], Training Accuracy: 92.3628%, Training Loss: 0.1993%\n",
      "Epoch [60/300], Step [206/225], Training Accuracy: 92.3620%, Training Loss: 0.1993%\n",
      "Epoch [60/300], Step [207/225], Training Accuracy: 92.3762%, Training Loss: 0.1992%\n",
      "Epoch [60/300], Step [208/225], Training Accuracy: 92.3753%, Training Loss: 0.1991%\n",
      "Epoch [60/300], Step [209/225], Training Accuracy: 92.3594%, Training Loss: 0.1995%\n",
      "Epoch [60/300], Step [210/225], Training Accuracy: 92.3363%, Training Loss: 0.1997%\n",
      "Epoch [60/300], Step [211/225], Training Accuracy: 92.3134%, Training Loss: 0.1998%\n",
      "Epoch [60/300], Step [212/225], Training Accuracy: 92.3054%, Training Loss: 0.2000%\n",
      "Epoch [60/300], Step [213/225], Training Accuracy: 92.2975%, Training Loss: 0.2000%\n",
      "Epoch [60/300], Step [214/225], Training Accuracy: 92.3043%, Training Loss: 0.1998%\n",
      "Epoch [60/300], Step [215/225], Training Accuracy: 92.3183%, Training Loss: 0.1997%\n",
      "Epoch [60/300], Step [216/225], Training Accuracy: 92.3177%, Training Loss: 0.1998%\n",
      "Epoch [60/300], Step [217/225], Training Accuracy: 92.3027%, Training Loss: 0.2004%\n",
      "Epoch [60/300], Step [218/225], Training Accuracy: 92.2950%, Training Loss: 0.2003%\n",
      "Epoch [60/300], Step [219/225], Training Accuracy: 92.3159%, Training Loss: 0.1999%\n",
      "Epoch [60/300], Step [220/225], Training Accuracy: 92.3224%, Training Loss: 0.1997%\n",
      "Epoch [60/300], Step [221/225], Training Accuracy: 92.3289%, Training Loss: 0.1994%\n",
      "Epoch [60/300], Step [222/225], Training Accuracy: 92.3564%, Training Loss: 0.1989%\n",
      "Epoch [60/300], Step [223/225], Training Accuracy: 92.3767%, Training Loss: 0.1987%\n",
      "Epoch [60/300], Step [224/225], Training Accuracy: 92.3898%, Training Loss: 0.1983%\n",
      "Epoch [60/300], Step [225/225], Training Accuracy: 92.4055%, Training Loss: 0.1981%\n",
      "Epoch [61/300], Step [1/225], Training Accuracy: 95.3125%, Training Loss: 0.1774%\n",
      "Epoch [61/300], Step [2/225], Training Accuracy: 94.5312%, Training Loss: 0.1847%\n",
      "Epoch [61/300], Step [3/225], Training Accuracy: 94.2708%, Training Loss: 0.1814%\n",
      "Epoch [61/300], Step [4/225], Training Accuracy: 93.3594%, Training Loss: 0.1966%\n",
      "Epoch [61/300], Step [5/225], Training Accuracy: 93.4375%, Training Loss: 0.2059%\n",
      "Epoch [61/300], Step [6/225], Training Accuracy: 93.7500%, Training Loss: 0.1942%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/300], Step [7/225], Training Accuracy: 93.0804%, Training Loss: 0.1967%\n",
      "Epoch [61/300], Step [8/225], Training Accuracy: 93.1641%, Training Loss: 0.1937%\n",
      "Epoch [61/300], Step [9/225], Training Accuracy: 93.0556%, Training Loss: 0.1960%\n",
      "Epoch [61/300], Step [10/225], Training Accuracy: 93.2812%, Training Loss: 0.1946%\n",
      "Epoch [61/300], Step [11/225], Training Accuracy: 92.8977%, Training Loss: 0.2032%\n",
      "Epoch [61/300], Step [12/225], Training Accuracy: 92.9688%, Training Loss: 0.1979%\n",
      "Epoch [61/300], Step [13/225], Training Accuracy: 93.1490%, Training Loss: 0.1952%\n",
      "Epoch [61/300], Step [14/225], Training Accuracy: 93.0804%, Training Loss: 0.1936%\n",
      "Epoch [61/300], Step [15/225], Training Accuracy: 93.0208%, Training Loss: 0.1987%\n",
      "Epoch [61/300], Step [16/225], Training Accuracy: 92.6758%, Training Loss: 0.2089%\n",
      "Epoch [61/300], Step [17/225], Training Accuracy: 92.9228%, Training Loss: 0.2027%\n",
      "Epoch [61/300], Step [18/225], Training Accuracy: 92.7083%, Training Loss: 0.2087%\n",
      "Epoch [61/300], Step [19/225], Training Accuracy: 92.6809%, Training Loss: 0.2097%\n",
      "Epoch [61/300], Step [20/225], Training Accuracy: 92.3438%, Training Loss: 0.2117%\n",
      "Epoch [61/300], Step [21/225], Training Accuracy: 92.4107%, Training Loss: 0.2089%\n",
      "Epoch [61/300], Step [22/225], Training Accuracy: 92.4716%, Training Loss: 0.2092%\n",
      "Epoch [61/300], Step [23/225], Training Accuracy: 92.4592%, Training Loss: 0.2081%\n",
      "Epoch [61/300], Step [24/225], Training Accuracy: 92.3828%, Training Loss: 0.2094%\n",
      "Epoch [61/300], Step [25/225], Training Accuracy: 92.5625%, Training Loss: 0.2051%\n",
      "Epoch [61/300], Step [26/225], Training Accuracy: 92.7885%, Training Loss: 0.2013%\n",
      "Epoch [61/300], Step [27/225], Training Accuracy: 92.7662%, Training Loss: 0.1994%\n",
      "Epoch [61/300], Step [28/225], Training Accuracy: 92.6897%, Training Loss: 0.1981%\n",
      "Epoch [61/300], Step [29/225], Training Accuracy: 92.6185%, Training Loss: 0.1981%\n",
      "Epoch [61/300], Step [30/225], Training Accuracy: 92.7083%, Training Loss: 0.1965%\n",
      "Epoch [61/300], Step [31/225], Training Accuracy: 92.4899%, Training Loss: 0.2004%\n",
      "Epoch [61/300], Step [32/225], Training Accuracy: 92.4805%, Training Loss: 0.1998%\n",
      "Epoch [61/300], Step [33/225], Training Accuracy: 92.3295%, Training Loss: 0.2024%\n",
      "Epoch [61/300], Step [34/225], Training Accuracy: 92.2335%, Training Loss: 0.2036%\n",
      "Epoch [61/300], Step [35/225], Training Accuracy: 92.3214%, Training Loss: 0.2019%\n",
      "Epoch [61/300], Step [36/225], Training Accuracy: 92.4045%, Training Loss: 0.1991%\n",
      "Epoch [61/300], Step [37/225], Training Accuracy: 92.4831%, Training Loss: 0.1979%\n",
      "Epoch [61/300], Step [38/225], Training Accuracy: 92.3520%, Training Loss: 0.2016%\n",
      "Epoch [61/300], Step [39/225], Training Accuracy: 92.4679%, Training Loss: 0.2000%\n",
      "Epoch [61/300], Step [40/225], Training Accuracy: 92.6562%, Training Loss: 0.1971%\n",
      "Epoch [61/300], Step [41/225], Training Accuracy: 92.4924%, Training Loss: 0.1996%\n",
      "Epoch [61/300], Step [42/225], Training Accuracy: 92.5223%, Training Loss: 0.1983%\n",
      "Epoch [61/300], Step [43/225], Training Accuracy: 92.4419%, Training Loss: 0.2006%\n",
      "Epoch [61/300], Step [44/225], Training Accuracy: 92.5781%, Training Loss: 0.1985%\n",
      "Epoch [61/300], Step [45/225], Training Accuracy: 92.5694%, Training Loss: 0.1981%\n",
      "Epoch [61/300], Step [46/225], Training Accuracy: 92.5951%, Training Loss: 0.1975%\n",
      "Epoch [61/300], Step [47/225], Training Accuracy: 92.5864%, Training Loss: 0.1966%\n",
      "Epoch [61/300], Step [48/225], Training Accuracy: 92.6758%, Training Loss: 0.1943%\n",
      "Epoch [61/300], Step [49/225], Training Accuracy: 92.6977%, Training Loss: 0.1940%\n",
      "Epoch [61/300], Step [50/225], Training Accuracy: 92.7188%, Training Loss: 0.1933%\n",
      "Epoch [61/300], Step [51/225], Training Accuracy: 92.8615%, Training Loss: 0.1910%\n",
      "Epoch [61/300], Step [52/225], Training Accuracy: 92.9387%, Training Loss: 0.1886%\n",
      "Epoch [61/300], Step [53/225], Training Accuracy: 92.9540%, Training Loss: 0.1884%\n",
      "Epoch [61/300], Step [54/225], Training Accuracy: 93.0556%, Training Loss: 0.1868%\n",
      "Epoch [61/300], Step [55/225], Training Accuracy: 93.0682%, Training Loss: 0.1866%\n",
      "Epoch [61/300], Step [56/225], Training Accuracy: 93.1083%, Training Loss: 0.1858%\n",
      "Epoch [61/300], Step [57/225], Training Accuracy: 93.0373%, Training Loss: 0.1926%\n",
      "Epoch [61/300], Step [58/225], Training Accuracy: 93.0496%, Training Loss: 0.1935%\n",
      "Epoch [61/300], Step [59/225], Training Accuracy: 93.0350%, Training Loss: 0.1936%\n",
      "Epoch [61/300], Step [60/225], Training Accuracy: 93.0208%, Training Loss: 0.1934%\n",
      "Epoch [61/300], Step [61/225], Training Accuracy: 92.9303%, Training Loss: 0.1933%\n",
      "Epoch [61/300], Step [62/225], Training Accuracy: 92.9183%, Training Loss: 0.1930%\n",
      "Epoch [61/300], Step [63/225], Training Accuracy: 92.9812%, Training Loss: 0.1913%\n",
      "Epoch [61/300], Step [64/225], Training Accuracy: 93.0420%, Training Loss: 0.1905%\n",
      "Epoch [61/300], Step [65/225], Training Accuracy: 93.0288%, Training Loss: 0.1907%\n",
      "Epoch [61/300], Step [66/225], Training Accuracy: 93.0161%, Training Loss: 0.1910%\n",
      "Epoch [61/300], Step [67/225], Training Accuracy: 92.9338%, Training Loss: 0.1931%\n",
      "Epoch [61/300], Step [68/225], Training Accuracy: 92.9688%, Training Loss: 0.1922%\n",
      "Epoch [61/300], Step [69/225], Training Accuracy: 92.9801%, Training Loss: 0.1914%\n",
      "Epoch [61/300], Step [70/225], Training Accuracy: 92.9911%, Training Loss: 0.1911%\n",
      "Epoch [61/300], Step [71/225], Training Accuracy: 93.0238%, Training Loss: 0.1909%\n",
      "Epoch [61/300], Step [72/225], Training Accuracy: 92.9688%, Training Loss: 0.1917%\n",
      "Epoch [61/300], Step [73/225], Training Accuracy: 92.9366%, Training Loss: 0.1921%\n",
      "Epoch [61/300], Step [74/225], Training Accuracy: 92.9688%, Training Loss: 0.1916%\n",
      "Epoch [61/300], Step [75/225], Training Accuracy: 92.9792%, Training Loss: 0.1917%\n",
      "Epoch [61/300], Step [76/225], Training Accuracy: 93.0099%, Training Loss: 0.1908%\n",
      "Epoch [61/300], Step [77/225], Training Accuracy: 93.0804%, Training Loss: 0.1899%\n",
      "Epoch [61/300], Step [78/225], Training Accuracy: 93.0489%, Training Loss: 0.1902%\n",
      "Epoch [61/300], Step [79/225], Training Accuracy: 93.0775%, Training Loss: 0.1902%\n",
      "Epoch [61/300], Step [80/225], Training Accuracy: 93.1055%, Training Loss: 0.1897%\n",
      "Epoch [61/300], Step [81/225], Training Accuracy: 93.1327%, Training Loss: 0.1885%\n",
      "Epoch [61/300], Step [82/225], Training Accuracy: 93.1212%, Training Loss: 0.1885%\n",
      "Epoch [61/300], Step [83/225], Training Accuracy: 93.1099%, Training Loss: 0.1882%\n",
      "Epoch [61/300], Step [84/225], Training Accuracy: 93.1362%, Training Loss: 0.1871%\n",
      "Epoch [61/300], Step [85/225], Training Accuracy: 93.1434%, Training Loss: 0.1870%\n",
      "Epoch [61/300], Step [86/225], Training Accuracy: 93.1504%, Training Loss: 0.1869%\n",
      "Epoch [61/300], Step [87/225], Training Accuracy: 93.1394%, Training Loss: 0.1879%\n",
      "Epoch [61/300], Step [88/225], Training Accuracy: 93.1463%, Training Loss: 0.1882%\n",
      "Epoch [61/300], Step [89/225], Training Accuracy: 93.1355%, Training Loss: 0.1881%\n",
      "Epoch [61/300], Step [90/225], Training Accuracy: 93.1076%, Training Loss: 0.1883%\n",
      "Epoch [61/300], Step [91/225], Training Accuracy: 93.0975%, Training Loss: 0.1883%\n",
      "Epoch [61/300], Step [92/225], Training Accuracy: 93.0537%, Training Loss: 0.1897%\n",
      "Epoch [61/300], Step [93/225], Training Accuracy: 93.1116%, Training Loss: 0.1884%\n",
      "Epoch [61/300], Step [94/225], Training Accuracy: 93.1184%, Training Loss: 0.1883%\n",
      "Epoch [61/300], Step [95/225], Training Accuracy: 93.0757%, Training Loss: 0.1894%\n",
      "Epoch [61/300], Step [96/225], Training Accuracy: 93.0501%, Training Loss: 0.1893%\n",
      "Epoch [61/300], Step [97/225], Training Accuracy: 92.9929%, Training Loss: 0.1906%\n",
      "Epoch [61/300], Step [98/225], Training Accuracy: 92.9209%, Training Loss: 0.1916%\n",
      "Epoch [61/300], Step [99/225], Training Accuracy: 92.9135%, Training Loss: 0.1918%\n",
      "Epoch [61/300], Step [100/225], Training Accuracy: 92.8906%, Training Loss: 0.1921%\n",
      "Epoch [61/300], Step [101/225], Training Accuracy: 92.8373%, Training Loss: 0.1928%\n",
      "Epoch [61/300], Step [102/225], Training Accuracy: 92.8309%, Training Loss: 0.1929%\n",
      "Epoch [61/300], Step [103/225], Training Accuracy: 92.8246%, Training Loss: 0.1939%\n",
      "Epoch [61/300], Step [104/225], Training Accuracy: 92.8335%, Training Loss: 0.1937%\n",
      "Epoch [61/300], Step [105/225], Training Accuracy: 92.8423%, Training Loss: 0.1937%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/300], Step [106/225], Training Accuracy: 92.9098%, Training Loss: 0.1926%\n",
      "Epoch [61/300], Step [107/225], Training Accuracy: 92.8592%, Training Loss: 0.1932%\n",
      "Epoch [61/300], Step [108/225], Training Accuracy: 92.8675%, Training Loss: 0.1931%\n",
      "Epoch [61/300], Step [109/225], Training Accuracy: 92.8756%, Training Loss: 0.1937%\n",
      "Epoch [61/300], Step [110/225], Training Accuracy: 92.9119%, Training Loss: 0.1933%\n",
      "Epoch [61/300], Step [111/225], Training Accuracy: 92.9054%, Training Loss: 0.1937%\n",
      "Epoch [61/300], Step [112/225], Training Accuracy: 92.9129%, Training Loss: 0.1931%\n",
      "Epoch [61/300], Step [113/225], Training Accuracy: 92.8650%, Training Loss: 0.1933%\n",
      "Epoch [61/300], Step [114/225], Training Accuracy: 92.8865%, Training Loss: 0.1931%\n",
      "Epoch [61/300], Step [115/225], Training Accuracy: 92.9348%, Training Loss: 0.1926%\n",
      "Epoch [61/300], Step [116/225], Training Accuracy: 92.9014%, Training Loss: 0.1935%\n",
      "Epoch [61/300], Step [117/225], Training Accuracy: 92.9087%, Training Loss: 0.1927%\n",
      "Epoch [61/300], Step [118/225], Training Accuracy: 92.9290%, Training Loss: 0.1921%\n",
      "Epoch [61/300], Step [119/225], Training Accuracy: 92.9491%, Training Loss: 0.1919%\n",
      "Epoch [61/300], Step [120/225], Training Accuracy: 92.9557%, Training Loss: 0.1918%\n",
      "Epoch [61/300], Step [121/225], Training Accuracy: 92.9365%, Training Loss: 0.1919%\n",
      "Epoch [61/300], Step [122/225], Training Accuracy: 92.9047%, Training Loss: 0.1920%\n",
      "Epoch [61/300], Step [123/225], Training Accuracy: 92.8989%, Training Loss: 0.1916%\n",
      "Epoch [61/300], Step [124/225], Training Accuracy: 92.8805%, Training Loss: 0.1924%\n",
      "Epoch [61/300], Step [125/225], Training Accuracy: 92.9125%, Training Loss: 0.1915%\n",
      "Epoch [61/300], Step [126/225], Training Accuracy: 92.8695%, Training Loss: 0.1922%\n",
      "Epoch [61/300], Step [127/225], Training Accuracy: 92.8642%, Training Loss: 0.1919%\n",
      "Epoch [61/300], Step [128/225], Training Accuracy: 92.8833%, Training Loss: 0.1922%\n",
      "Epoch [61/300], Step [129/225], Training Accuracy: 92.8779%, Training Loss: 0.1921%\n",
      "Epoch [61/300], Step [130/225], Training Accuracy: 92.8726%, Training Loss: 0.1920%\n",
      "Epoch [61/300], Step [131/225], Training Accuracy: 92.8554%, Training Loss: 0.1926%\n",
      "Epoch [61/300], Step [132/225], Training Accuracy: 92.8385%, Training Loss: 0.1927%\n",
      "Epoch [61/300], Step [133/225], Training Accuracy: 92.7867%, Training Loss: 0.1934%\n",
      "Epoch [61/300], Step [134/225], Training Accuracy: 92.7355%, Training Loss: 0.1944%\n",
      "Epoch [61/300], Step [135/225], Training Accuracy: 92.7431%, Training Loss: 0.1939%\n",
      "Epoch [61/300], Step [136/225], Training Accuracy: 92.7045%, Training Loss: 0.1944%\n",
      "Epoch [61/300], Step [137/225], Training Accuracy: 92.6893%, Training Loss: 0.1952%\n",
      "Epoch [61/300], Step [138/225], Training Accuracy: 92.6970%, Training Loss: 0.1947%\n",
      "Epoch [61/300], Step [139/225], Training Accuracy: 92.6596%, Training Loss: 0.1947%\n",
      "Epoch [61/300], Step [140/225], Training Accuracy: 92.6786%, Training Loss: 0.1943%\n",
      "Epoch [61/300], Step [141/225], Training Accuracy: 92.6640%, Training Loss: 0.1946%\n",
      "Epoch [61/300], Step [142/225], Training Accuracy: 92.6607%, Training Loss: 0.1948%\n",
      "Epoch [61/300], Step [143/225], Training Accuracy: 92.6792%, Training Loss: 0.1942%\n",
      "Epoch [61/300], Step [144/225], Training Accuracy: 92.6866%, Training Loss: 0.1941%\n",
      "Epoch [61/300], Step [145/225], Training Accuracy: 92.6616%, Training Loss: 0.1943%\n",
      "Epoch [61/300], Step [146/225], Training Accuracy: 92.6798%, Training Loss: 0.1937%\n",
      "Epoch [61/300], Step [147/225], Training Accuracy: 92.6552%, Training Loss: 0.1939%\n",
      "Epoch [61/300], Step [148/225], Training Accuracy: 92.6731%, Training Loss: 0.1931%\n",
      "Epoch [61/300], Step [149/225], Training Accuracy: 92.6804%, Training Loss: 0.1927%\n",
      "Epoch [61/300], Step [150/225], Training Accuracy: 92.6771%, Training Loss: 0.1925%\n",
      "Epoch [61/300], Step [151/225], Training Accuracy: 92.6531%, Training Loss: 0.1929%\n",
      "Epoch [61/300], Step [152/225], Training Accuracy: 92.6398%, Training Loss: 0.1929%\n",
      "Epoch [61/300], Step [153/225], Training Accuracy: 92.6471%, Training Loss: 0.1930%\n",
      "Epoch [61/300], Step [154/225], Training Accuracy: 92.6948%, Training Loss: 0.1922%\n",
      "Epoch [61/300], Step [155/225], Training Accuracy: 92.6815%, Training Loss: 0.1925%\n",
      "Epoch [61/300], Step [156/225], Training Accuracy: 92.6983%, Training Loss: 0.1924%\n",
      "Epoch [61/300], Step [157/225], Training Accuracy: 92.6851%, Training Loss: 0.1927%\n",
      "Epoch [61/300], Step [158/225], Training Accuracy: 92.6721%, Training Loss: 0.1928%\n",
      "Epoch [61/300], Step [159/225], Training Accuracy: 92.6395%, Training Loss: 0.1938%\n",
      "Epoch [61/300], Step [160/225], Training Accuracy: 92.6562%, Training Loss: 0.1936%\n",
      "Epoch [61/300], Step [161/225], Training Accuracy: 92.6533%, Training Loss: 0.1938%\n",
      "Epoch [61/300], Step [162/225], Training Accuracy: 92.6601%, Training Loss: 0.1936%\n",
      "Epoch [61/300], Step [163/225], Training Accuracy: 92.6860%, Training Loss: 0.1928%\n",
      "Epoch [61/300], Step [164/225], Training Accuracy: 92.7020%, Training Loss: 0.1925%\n",
      "Epoch [61/300], Step [165/225], Training Accuracy: 92.6610%, Training Loss: 0.1936%\n",
      "Epoch [61/300], Step [166/225], Training Accuracy: 92.6393%, Training Loss: 0.1939%\n",
      "Epoch [61/300], Step [167/225], Training Accuracy: 92.6366%, Training Loss: 0.1937%\n",
      "Epoch [61/300], Step [168/225], Training Accuracy: 92.6339%, Training Loss: 0.1938%\n",
      "Epoch [61/300], Step [169/225], Training Accuracy: 92.6405%, Training Loss: 0.1938%\n",
      "Epoch [61/300], Step [170/225], Training Accuracy: 92.6287%, Training Loss: 0.1941%\n",
      "Epoch [61/300], Step [171/225], Training Accuracy: 92.6261%, Training Loss: 0.1939%\n",
      "Epoch [61/300], Step [172/225], Training Accuracy: 92.6326%, Training Loss: 0.1937%\n",
      "Epoch [61/300], Step [173/225], Training Accuracy: 92.6301%, Training Loss: 0.1940%\n",
      "Epoch [61/300], Step [174/225], Training Accuracy: 92.6365%, Training Loss: 0.1942%\n",
      "Epoch [61/300], Step [175/225], Training Accuracy: 92.6429%, Training Loss: 0.1941%\n",
      "Epoch [61/300], Step [176/225], Training Accuracy: 92.6580%, Training Loss: 0.1935%\n",
      "Epoch [61/300], Step [177/225], Training Accuracy: 92.6819%, Training Loss: 0.1931%\n",
      "Epoch [61/300], Step [178/225], Training Accuracy: 92.6791%, Training Loss: 0.1932%\n",
      "Epoch [61/300], Step [179/225], Training Accuracy: 92.6676%, Training Loss: 0.1936%\n",
      "Epoch [61/300], Step [180/225], Training Accuracy: 92.6649%, Training Loss: 0.1939%\n",
      "Epoch [61/300], Step [181/225], Training Accuracy: 92.6796%, Training Loss: 0.1935%\n",
      "Epoch [61/300], Step [182/225], Training Accuracy: 92.7112%, Training Loss: 0.1930%\n",
      "Epoch [61/300], Step [183/225], Training Accuracy: 92.7339%, Training Loss: 0.1929%\n",
      "Epoch [61/300], Step [184/225], Training Accuracy: 92.7395%, Training Loss: 0.1923%\n",
      "Epoch [61/300], Step [185/225], Training Accuracy: 92.7618%, Training Loss: 0.1919%\n",
      "Epoch [61/300], Step [186/225], Training Accuracy: 92.7671%, Training Loss: 0.1914%\n",
      "Epoch [61/300], Step [187/225], Training Accuracy: 92.7975%, Training Loss: 0.1909%\n",
      "Epoch [61/300], Step [188/225], Training Accuracy: 92.7859%, Training Loss: 0.1910%\n",
      "Epoch [61/300], Step [189/225], Training Accuracy: 92.8158%, Training Loss: 0.1905%\n",
      "Epoch [61/300], Step [190/225], Training Accuracy: 92.8289%, Training Loss: 0.1900%\n",
      "Epoch [61/300], Step [191/225], Training Accuracy: 92.8174%, Training Loss: 0.1907%\n",
      "Epoch [61/300], Step [192/225], Training Accuracy: 92.8223%, Training Loss: 0.1905%\n",
      "Epoch [61/300], Step [193/225], Training Accuracy: 92.8190%, Training Loss: 0.1906%\n",
      "Epoch [61/300], Step [194/225], Training Accuracy: 92.8157%, Training Loss: 0.1909%\n",
      "Epoch [61/300], Step [195/225], Training Accuracy: 92.8125%, Training Loss: 0.1909%\n",
      "Epoch [61/300], Step [196/225], Training Accuracy: 92.8173%, Training Loss: 0.1909%\n",
      "Epoch [61/300], Step [197/225], Training Accuracy: 92.8299%, Training Loss: 0.1906%\n",
      "Epoch [61/300], Step [198/225], Training Accuracy: 92.8425%, Training Loss: 0.1903%\n",
      "Epoch [61/300], Step [199/225], Training Accuracy: 92.8470%, Training Loss: 0.1903%\n",
      "Epoch [61/300], Step [200/225], Training Accuracy: 92.8672%, Training Loss: 0.1899%\n",
      "Epoch [61/300], Step [201/225], Training Accuracy: 92.8560%, Training Loss: 0.1899%\n",
      "Epoch [61/300], Step [202/225], Training Accuracy: 92.8682%, Training Loss: 0.1896%\n",
      "Epoch [61/300], Step [203/225], Training Accuracy: 92.9033%, Training Loss: 0.1889%\n",
      "Epoch [61/300], Step [204/225], Training Accuracy: 92.9228%, Training Loss: 0.1887%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/300], Step [205/225], Training Accuracy: 92.9192%, Training Loss: 0.1892%\n",
      "Epoch [61/300], Step [206/225], Training Accuracy: 92.9005%, Training Loss: 0.1893%\n",
      "Epoch [61/300], Step [207/225], Training Accuracy: 92.8895%, Training Loss: 0.1892%\n",
      "Epoch [61/300], Step [208/225], Training Accuracy: 92.9087%, Training Loss: 0.1890%\n",
      "Epoch [61/300], Step [209/225], Training Accuracy: 92.8977%, Training Loss: 0.1891%\n",
      "Epoch [61/300], Step [210/225], Training Accuracy: 92.8869%, Training Loss: 0.1892%\n",
      "Epoch [61/300], Step [211/225], Training Accuracy: 92.8614%, Training Loss: 0.1895%\n",
      "Epoch [61/300], Step [212/225], Training Accuracy: 92.8435%, Training Loss: 0.1898%\n",
      "Epoch [61/300], Step [213/225], Training Accuracy: 92.8330%, Training Loss: 0.1905%\n",
      "Epoch [61/300], Step [214/225], Training Accuracy: 92.8300%, Training Loss: 0.1905%\n",
      "Epoch [61/300], Step [215/225], Training Accuracy: 92.8416%, Training Loss: 0.1900%\n",
      "Epoch [61/300], Step [216/225], Training Accuracy: 92.8530%, Training Loss: 0.1899%\n",
      "Epoch [61/300], Step [217/225], Training Accuracy: 92.8355%, Training Loss: 0.1908%\n",
      "Epoch [61/300], Step [218/225], Training Accuracy: 92.8326%, Training Loss: 0.1908%\n",
      "Epoch [61/300], Step [219/225], Training Accuracy: 92.8296%, Training Loss: 0.1907%\n",
      "Epoch [61/300], Step [220/225], Training Accuracy: 92.8480%, Training Loss: 0.1904%\n",
      "Epoch [61/300], Step [221/225], Training Accuracy: 92.8592%, Training Loss: 0.1900%\n",
      "Epoch [61/300], Step [222/225], Training Accuracy: 92.8632%, Training Loss: 0.1898%\n",
      "Epoch [61/300], Step [223/225], Training Accuracy: 92.8742%, Training Loss: 0.1898%\n",
      "Epoch [61/300], Step [224/225], Training Accuracy: 92.8781%, Training Loss: 0.1895%\n",
      "Epoch [61/300], Step [225/225], Training Accuracy: 92.8780%, Training Loss: 0.1894%\n",
      "Epoch [62/300], Step [1/225], Training Accuracy: 90.6250%, Training Loss: 0.2750%\n",
      "Epoch [62/300], Step [2/225], Training Accuracy: 91.4062%, Training Loss: 0.2096%\n",
      "Epoch [62/300], Step [3/225], Training Accuracy: 91.1458%, Training Loss: 0.2046%\n",
      "Epoch [62/300], Step [4/225], Training Accuracy: 91.0156%, Training Loss: 0.2017%\n",
      "Epoch [62/300], Step [5/225], Training Accuracy: 91.5625%, Training Loss: 0.2114%\n",
      "Epoch [62/300], Step [6/225], Training Accuracy: 91.6667%, Training Loss: 0.2190%\n",
      "Epoch [62/300], Step [7/225], Training Accuracy: 91.5179%, Training Loss: 0.2290%\n",
      "Epoch [62/300], Step [8/225], Training Accuracy: 91.6016%, Training Loss: 0.2274%\n",
      "Epoch [62/300], Step [9/225], Training Accuracy: 91.8403%, Training Loss: 0.2243%\n",
      "Epoch [62/300], Step [10/225], Training Accuracy: 91.7188%, Training Loss: 0.2236%\n",
      "Epoch [62/300], Step [11/225], Training Accuracy: 91.4773%, Training Loss: 0.2304%\n",
      "Epoch [62/300], Step [12/225], Training Accuracy: 91.7969%, Training Loss: 0.2208%\n",
      "Epoch [62/300], Step [13/225], Training Accuracy: 92.0673%, Training Loss: 0.2141%\n",
      "Epoch [62/300], Step [14/225], Training Accuracy: 91.8527%, Training Loss: 0.2183%\n",
      "Epoch [62/300], Step [15/225], Training Accuracy: 92.3958%, Training Loss: 0.2079%\n",
      "Epoch [62/300], Step [16/225], Training Accuracy: 92.0898%, Training Loss: 0.2150%\n",
      "Epoch [62/300], Step [17/225], Training Accuracy: 92.1875%, Training Loss: 0.2107%\n",
      "Epoch [62/300], Step [18/225], Training Accuracy: 92.1007%, Training Loss: 0.2101%\n",
      "Epoch [62/300], Step [19/225], Training Accuracy: 92.2697%, Training Loss: 0.2051%\n",
      "Epoch [62/300], Step [20/225], Training Accuracy: 92.5000%, Training Loss: 0.1993%\n",
      "Epoch [62/300], Step [21/225], Training Accuracy: 92.6339%, Training Loss: 0.1955%\n",
      "Epoch [62/300], Step [22/225], Training Accuracy: 92.7557%, Training Loss: 0.1921%\n",
      "Epoch [62/300], Step [23/225], Training Accuracy: 92.7310%, Training Loss: 0.1939%\n",
      "Epoch [62/300], Step [24/225], Training Accuracy: 92.3828%, Training Loss: 0.2027%\n",
      "Epoch [62/300], Step [25/225], Training Accuracy: 92.5625%, Training Loss: 0.1978%\n",
      "Epoch [62/300], Step [26/225], Training Accuracy: 92.6683%, Training Loss: 0.1961%\n",
      "Epoch [62/300], Step [27/225], Training Accuracy: 92.7083%, Training Loss: 0.1942%\n",
      "Epoch [62/300], Step [28/225], Training Accuracy: 92.9129%, Training Loss: 0.1897%\n",
      "Epoch [62/300], Step [29/225], Training Accuracy: 92.9957%, Training Loss: 0.1891%\n",
      "Epoch [62/300], Step [30/225], Training Accuracy: 93.2292%, Training Loss: 0.1851%\n",
      "Epoch [62/300], Step [31/225], Training Accuracy: 93.2460%, Training Loss: 0.1848%\n",
      "Epoch [62/300], Step [32/225], Training Accuracy: 93.3105%, Training Loss: 0.1840%\n",
      "Epoch [62/300], Step [33/225], Training Accuracy: 93.2765%, Training Loss: 0.1858%\n",
      "Epoch [62/300], Step [34/225], Training Accuracy: 93.2445%, Training Loss: 0.1859%\n",
      "Epoch [62/300], Step [35/225], Training Accuracy: 93.2143%, Training Loss: 0.1862%\n",
      "Epoch [62/300], Step [36/225], Training Accuracy: 93.2292%, Training Loss: 0.1909%\n",
      "Epoch [62/300], Step [37/225], Training Accuracy: 93.2010%, Training Loss: 0.1904%\n",
      "Epoch [62/300], Step [38/225], Training Accuracy: 93.2155%, Training Loss: 0.1904%\n",
      "Epoch [62/300], Step [39/225], Training Accuracy: 93.1891%, Training Loss: 0.1944%\n",
      "Epoch [62/300], Step [40/225], Training Accuracy: 93.2812%, Training Loss: 0.1929%\n",
      "Epoch [62/300], Step [41/225], Training Accuracy: 93.1402%, Training Loss: 0.1968%\n",
      "Epoch [62/300], Step [42/225], Training Accuracy: 93.1920%, Training Loss: 0.1966%\n",
      "Epoch [62/300], Step [43/225], Training Accuracy: 93.2413%, Training Loss: 0.1952%\n",
      "Epoch [62/300], Step [44/225], Training Accuracy: 93.2173%, Training Loss: 0.1971%\n",
      "Epoch [62/300], Step [45/225], Training Accuracy: 93.3333%, Training Loss: 0.1955%\n",
      "Epoch [62/300], Step [46/225], Training Accuracy: 93.4103%, Training Loss: 0.1943%\n",
      "Epoch [62/300], Step [47/225], Training Accuracy: 93.4508%, Training Loss: 0.1932%\n",
      "Epoch [62/300], Step [48/225], Training Accuracy: 93.3919%, Training Loss: 0.1944%\n",
      "Epoch [62/300], Step [49/225], Training Accuracy: 93.4311%, Training Loss: 0.1929%\n",
      "Epoch [62/300], Step [50/225], Training Accuracy: 93.3750%, Training Loss: 0.1923%\n",
      "Epoch [62/300], Step [51/225], Training Accuracy: 93.2904%, Training Loss: 0.1920%\n",
      "Epoch [62/300], Step [52/225], Training Accuracy: 93.3594%, Training Loss: 0.1902%\n",
      "Epoch [62/300], Step [53/225], Training Accuracy: 93.4257%, Training Loss: 0.1883%\n",
      "Epoch [62/300], Step [54/225], Training Accuracy: 93.4317%, Training Loss: 0.1868%\n",
      "Epoch [62/300], Step [55/225], Training Accuracy: 93.3239%, Training Loss: 0.1887%\n",
      "Epoch [62/300], Step [56/225], Training Accuracy: 93.3873%, Training Loss: 0.1873%\n",
      "Epoch [62/300], Step [57/225], Training Accuracy: 93.2566%, Training Loss: 0.1894%\n",
      "Epoch [62/300], Step [58/225], Training Accuracy: 93.2920%, Training Loss: 0.1883%\n",
      "Epoch [62/300], Step [59/225], Training Accuracy: 93.1674%, Training Loss: 0.1889%\n",
      "Epoch [62/300], Step [60/225], Training Accuracy: 93.1250%, Training Loss: 0.1888%\n",
      "Epoch [62/300], Step [61/225], Training Accuracy: 93.1096%, Training Loss: 0.1894%\n",
      "Epoch [62/300], Step [62/225], Training Accuracy: 93.0948%, Training Loss: 0.1886%\n",
      "Epoch [62/300], Step [63/225], Training Accuracy: 93.0804%, Training Loss: 0.1882%\n",
      "Epoch [62/300], Step [64/225], Training Accuracy: 93.1396%, Training Loss: 0.1867%\n",
      "Epoch [62/300], Step [65/225], Training Accuracy: 93.1490%, Training Loss: 0.1868%\n",
      "Epoch [62/300], Step [66/225], Training Accuracy: 93.1345%, Training Loss: 0.1866%\n",
      "Epoch [62/300], Step [67/225], Training Accuracy: 93.2136%, Training Loss: 0.1855%\n",
      "Epoch [62/300], Step [68/225], Training Accuracy: 93.1296%, Training Loss: 0.1869%\n",
      "Epoch [62/300], Step [69/225], Training Accuracy: 93.1386%, Training Loss: 0.1864%\n",
      "Epoch [62/300], Step [70/225], Training Accuracy: 93.0134%, Training Loss: 0.1886%\n",
      "Epoch [62/300], Step [71/225], Training Accuracy: 93.0238%, Training Loss: 0.1883%\n",
      "Epoch [62/300], Step [72/225], Training Accuracy: 93.0122%, Training Loss: 0.1878%\n",
      "Epoch [62/300], Step [73/225], Training Accuracy: 93.0223%, Training Loss: 0.1876%\n",
      "Epoch [62/300], Step [74/225], Training Accuracy: 92.9688%, Training Loss: 0.1881%\n",
      "Epoch [62/300], Step [75/225], Training Accuracy: 93.0208%, Training Loss: 0.1868%\n",
      "Epoch [62/300], Step [76/225], Training Accuracy: 92.9688%, Training Loss: 0.1884%\n",
      "Epoch [62/300], Step [77/225], Training Accuracy: 92.9789%, Training Loss: 0.1876%\n",
      "Epoch [62/300], Step [78/225], Training Accuracy: 92.9487%, Training Loss: 0.1881%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/300], Step [79/225], Training Accuracy: 92.9786%, Training Loss: 0.1877%\n",
      "Epoch [62/300], Step [80/225], Training Accuracy: 92.9883%, Training Loss: 0.1872%\n",
      "Epoch [62/300], Step [81/225], Training Accuracy: 93.0363%, Training Loss: 0.1864%\n",
      "Epoch [62/300], Step [82/225], Training Accuracy: 93.1021%, Training Loss: 0.1847%\n",
      "Epoch [62/300], Step [83/225], Training Accuracy: 93.0723%, Training Loss: 0.1851%\n",
      "Epoch [62/300], Step [84/225], Training Accuracy: 93.0990%, Training Loss: 0.1845%\n",
      "Epoch [62/300], Step [85/225], Training Accuracy: 93.1066%, Training Loss: 0.1841%\n",
      "Epoch [62/300], Step [86/225], Training Accuracy: 93.1868%, Training Loss: 0.1829%\n",
      "Epoch [62/300], Step [87/225], Training Accuracy: 93.0855%, Training Loss: 0.1841%\n",
      "Epoch [62/300], Step [88/225], Training Accuracy: 93.0220%, Training Loss: 0.1849%\n",
      "Epoch [62/300], Step [89/225], Training Accuracy: 93.0478%, Training Loss: 0.1840%\n",
      "Epoch [62/300], Step [90/225], Training Accuracy: 93.0556%, Training Loss: 0.1837%\n",
      "Epoch [62/300], Step [91/225], Training Accuracy: 93.0804%, Training Loss: 0.1831%\n",
      "Epoch [62/300], Step [92/225], Training Accuracy: 93.0537%, Training Loss: 0.1838%\n",
      "Epoch [62/300], Step [93/225], Training Accuracy: 93.1116%, Training Loss: 0.1826%\n",
      "Epoch [62/300], Step [94/225], Training Accuracy: 93.1017%, Training Loss: 0.1830%\n",
      "Epoch [62/300], Step [95/225], Training Accuracy: 93.0921%, Training Loss: 0.1833%\n",
      "Epoch [62/300], Step [96/225], Training Accuracy: 93.0990%, Training Loss: 0.1836%\n",
      "Epoch [62/300], Step [97/225], Training Accuracy: 93.0735%, Training Loss: 0.1848%\n",
      "Epoch [62/300], Step [98/225], Training Accuracy: 93.0963%, Training Loss: 0.1842%\n",
      "Epoch [62/300], Step [99/225], Training Accuracy: 93.0871%, Training Loss: 0.1849%\n",
      "Epoch [62/300], Step [100/225], Training Accuracy: 93.1094%, Training Loss: 0.1845%\n",
      "Epoch [62/300], Step [101/225], Training Accuracy: 93.1002%, Training Loss: 0.1848%\n",
      "Epoch [62/300], Step [102/225], Training Accuracy: 93.1066%, Training Loss: 0.1846%\n",
      "Epoch [62/300], Step [103/225], Training Accuracy: 93.1432%, Training Loss: 0.1834%\n",
      "Epoch [62/300], Step [104/225], Training Accuracy: 93.1941%, Training Loss: 0.1831%\n",
      "Epoch [62/300], Step [105/225], Training Accuracy: 93.1548%, Training Loss: 0.1838%\n",
      "Epoch [62/300], Step [106/225], Training Accuracy: 93.1162%, Training Loss: 0.1852%\n",
      "Epoch [62/300], Step [107/225], Training Accuracy: 93.0929%, Training Loss: 0.1853%\n",
      "Epoch [62/300], Step [108/225], Training Accuracy: 93.0990%, Training Loss: 0.1851%\n",
      "Epoch [62/300], Step [109/225], Training Accuracy: 93.0763%, Training Loss: 0.1868%\n",
      "Epoch [62/300], Step [110/225], Training Accuracy: 93.0398%, Training Loss: 0.1873%\n",
      "Epoch [62/300], Step [111/225], Training Accuracy: 92.9899%, Training Loss: 0.1881%\n",
      "Epoch [62/300], Step [112/225], Training Accuracy: 92.9688%, Training Loss: 0.1884%\n",
      "Epoch [62/300], Step [113/225], Training Accuracy: 92.9342%, Training Loss: 0.1886%\n",
      "Epoch [62/300], Step [114/225], Training Accuracy: 92.9688%, Training Loss: 0.1882%\n",
      "Epoch [62/300], Step [115/225], Training Accuracy: 92.9891%, Training Loss: 0.1877%\n",
      "Epoch [62/300], Step [116/225], Training Accuracy: 92.9822%, Training Loss: 0.1875%\n",
      "Epoch [62/300], Step [117/225], Training Accuracy: 93.0021%, Training Loss: 0.1870%\n",
      "Epoch [62/300], Step [118/225], Training Accuracy: 92.9952%, Training Loss: 0.1870%\n",
      "Epoch [62/300], Step [119/225], Training Accuracy: 92.9753%, Training Loss: 0.1871%\n",
      "Epoch [62/300], Step [120/225], Training Accuracy: 92.9557%, Training Loss: 0.1879%\n",
      "Epoch [62/300], Step [121/225], Training Accuracy: 92.9881%, Training Loss: 0.1872%\n",
      "Epoch [62/300], Step [122/225], Training Accuracy: 92.9816%, Training Loss: 0.1874%\n",
      "Epoch [62/300], Step [123/225], Training Accuracy: 92.9751%, Training Loss: 0.1875%\n",
      "Epoch [62/300], Step [124/225], Training Accuracy: 92.9814%, Training Loss: 0.1878%\n",
      "Epoch [62/300], Step [125/225], Training Accuracy: 92.9750%, Training Loss: 0.1886%\n",
      "Epoch [62/300], Step [126/225], Training Accuracy: 92.9563%, Training Loss: 0.1887%\n",
      "Epoch [62/300], Step [127/225], Training Accuracy: 92.9749%, Training Loss: 0.1886%\n",
      "Epoch [62/300], Step [128/225], Training Accuracy: 92.9565%, Training Loss: 0.1889%\n",
      "Epoch [62/300], Step [129/225], Training Accuracy: 92.9021%, Training Loss: 0.1893%\n",
      "Epoch [62/300], Step [130/225], Training Accuracy: 92.8966%, Training Loss: 0.1892%\n",
      "Epoch [62/300], Step [131/225], Training Accuracy: 92.8554%, Training Loss: 0.1908%\n",
      "Epoch [62/300], Step [132/225], Training Accuracy: 92.8149%, Training Loss: 0.1918%\n",
      "Epoch [62/300], Step [133/225], Training Accuracy: 92.8219%, Training Loss: 0.1918%\n",
      "Epoch [62/300], Step [134/225], Training Accuracy: 92.8172%, Training Loss: 0.1917%\n",
      "Epoch [62/300], Step [135/225], Training Accuracy: 92.7778%, Training Loss: 0.1927%\n",
      "Epoch [62/300], Step [136/225], Training Accuracy: 92.7505%, Training Loss: 0.1931%\n",
      "Epoch [62/300], Step [137/225], Training Accuracy: 92.7121%, Training Loss: 0.1939%\n",
      "Epoch [62/300], Step [138/225], Training Accuracy: 92.7536%, Training Loss: 0.1929%\n",
      "Epoch [62/300], Step [139/225], Training Accuracy: 92.7496%, Training Loss: 0.1931%\n",
      "Epoch [62/300], Step [140/225], Training Accuracy: 92.7679%, Training Loss: 0.1932%\n",
      "Epoch [62/300], Step [141/225], Training Accuracy: 92.7637%, Training Loss: 0.1932%\n",
      "Epoch [62/300], Step [142/225], Training Accuracy: 92.7487%, Training Loss: 0.1934%\n",
      "Epoch [62/300], Step [143/225], Training Accuracy: 92.7557%, Training Loss: 0.1930%\n",
      "Epoch [62/300], Step [144/225], Training Accuracy: 92.6975%, Training Loss: 0.1940%\n",
      "Epoch [62/300], Step [145/225], Training Accuracy: 92.6940%, Training Loss: 0.1944%\n",
      "Epoch [62/300], Step [146/225], Training Accuracy: 92.6798%, Training Loss: 0.1945%\n",
      "Epoch [62/300], Step [147/225], Training Accuracy: 92.6764%, Training Loss: 0.1944%\n",
      "Epoch [62/300], Step [148/225], Training Accuracy: 92.6837%, Training Loss: 0.1946%\n",
      "Epoch [62/300], Step [149/225], Training Accuracy: 92.6804%, Training Loss: 0.1947%\n",
      "Epoch [62/300], Step [150/225], Training Accuracy: 92.6979%, Training Loss: 0.1941%\n",
      "Epoch [62/300], Step [151/225], Training Accuracy: 92.7152%, Training Loss: 0.1934%\n",
      "Epoch [62/300], Step [152/225], Training Accuracy: 92.7529%, Training Loss: 0.1925%\n",
      "Epoch [62/300], Step [153/225], Training Accuracy: 92.7390%, Training Loss: 0.1927%\n",
      "Epoch [62/300], Step [154/225], Training Accuracy: 92.7557%, Training Loss: 0.1925%\n",
      "Epoch [62/300], Step [155/225], Training Accuracy: 92.7218%, Training Loss: 0.1938%\n",
      "Epoch [62/300], Step [156/225], Training Accuracy: 92.7484%, Training Loss: 0.1931%\n",
      "Epoch [62/300], Step [157/225], Training Accuracy: 92.7150%, Training Loss: 0.1937%\n",
      "Epoch [62/300], Step [158/225], Training Accuracy: 92.7215%, Training Loss: 0.1931%\n",
      "Epoch [62/300], Step [159/225], Training Accuracy: 92.7476%, Training Loss: 0.1926%\n",
      "Epoch [62/300], Step [160/225], Training Accuracy: 92.7344%, Training Loss: 0.1930%\n",
      "Epoch [62/300], Step [161/225], Training Accuracy: 92.7019%, Training Loss: 0.1933%\n",
      "Epoch [62/300], Step [162/225], Training Accuracy: 92.6794%, Training Loss: 0.1934%\n",
      "Epoch [62/300], Step [163/225], Training Accuracy: 92.7051%, Training Loss: 0.1930%\n",
      "Epoch [62/300], Step [164/225], Training Accuracy: 92.7306%, Training Loss: 0.1922%\n",
      "Epoch [62/300], Step [165/225], Training Accuracy: 92.7178%, Training Loss: 0.1922%\n",
      "Epoch [62/300], Step [166/225], Training Accuracy: 92.6487%, Training Loss: 0.1929%\n",
      "Epoch [62/300], Step [167/225], Training Accuracy: 92.6272%, Training Loss: 0.1930%\n",
      "Epoch [62/300], Step [168/225], Training Accuracy: 92.5874%, Training Loss: 0.1936%\n",
      "Epoch [62/300], Step [169/225], Training Accuracy: 92.6128%, Training Loss: 0.1929%\n",
      "Epoch [62/300], Step [170/225], Training Accuracy: 92.5919%, Training Loss: 0.1932%\n",
      "Epoch [62/300], Step [171/225], Training Accuracy: 92.5621%, Training Loss: 0.1938%\n",
      "Epoch [62/300], Step [172/225], Training Accuracy: 92.5600%, Training Loss: 0.1941%\n",
      "Epoch [62/300], Step [173/225], Training Accuracy: 92.5759%, Training Loss: 0.1936%\n",
      "Epoch [62/300], Step [174/225], Training Accuracy: 92.6006%, Training Loss: 0.1933%\n",
      "Epoch [62/300], Step [175/225], Training Accuracy: 92.6071%, Training Loss: 0.1933%\n",
      "Epoch [62/300], Step [176/225], Training Accuracy: 92.6225%, Training Loss: 0.1926%\n",
      "Epoch [62/300], Step [177/225], Training Accuracy: 92.6554%, Training Loss: 0.1923%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/300], Step [178/225], Training Accuracy: 92.6615%, Training Loss: 0.1921%\n",
      "Epoch [62/300], Step [179/225], Training Accuracy: 92.6414%, Training Loss: 0.1925%\n",
      "Epoch [62/300], Step [180/225], Training Accuracy: 92.6302%, Training Loss: 0.1927%\n",
      "Epoch [62/300], Step [181/225], Training Accuracy: 92.5932%, Training Loss: 0.1934%\n",
      "Epoch [62/300], Step [182/225], Training Accuracy: 92.5996%, Training Loss: 0.1933%\n",
      "Epoch [62/300], Step [183/225], Training Accuracy: 92.6059%, Training Loss: 0.1934%\n",
      "Epoch [62/300], Step [184/225], Training Accuracy: 92.6461%, Training Loss: 0.1926%\n",
      "Epoch [62/300], Step [185/225], Training Accuracy: 92.6689%, Training Loss: 0.1922%\n",
      "Epoch [62/300], Step [186/225], Training Accuracy: 92.6831%, Training Loss: 0.1916%\n",
      "Epoch [62/300], Step [187/225], Training Accuracy: 92.6721%, Training Loss: 0.1917%\n",
      "Epoch [62/300], Step [188/225], Training Accuracy: 92.6695%, Training Loss: 0.1916%\n",
      "Epoch [62/300], Step [189/225], Training Accuracy: 92.6670%, Training Loss: 0.1912%\n",
      "Epoch [62/300], Step [190/225], Training Accuracy: 92.6809%, Training Loss: 0.1910%\n",
      "Epoch [62/300], Step [191/225], Training Accuracy: 92.6620%, Training Loss: 0.1915%\n",
      "Epoch [62/300], Step [192/225], Training Accuracy: 92.6514%, Training Loss: 0.1919%\n",
      "Epoch [62/300], Step [193/225], Training Accuracy: 92.6490%, Training Loss: 0.1920%\n",
      "Epoch [62/300], Step [194/225], Training Accuracy: 92.6466%, Training Loss: 0.1922%\n",
      "Epoch [62/300], Step [195/225], Training Accuracy: 92.6683%, Training Loss: 0.1918%\n",
      "Epoch [62/300], Step [196/225], Training Accuracy: 92.6419%, Training Loss: 0.1920%\n",
      "Epoch [62/300], Step [197/225], Training Accuracy: 92.6396%, Training Loss: 0.1919%\n",
      "Epoch [62/300], Step [198/225], Training Accuracy: 92.6610%, Training Loss: 0.1914%\n",
      "Epoch [62/300], Step [199/225], Training Accuracy: 92.6743%, Training Loss: 0.1912%\n",
      "Epoch [62/300], Step [200/225], Training Accuracy: 92.6562%, Training Loss: 0.1913%\n",
      "Epoch [62/300], Step [201/225], Training Accuracy: 92.6772%, Training Loss: 0.1912%\n",
      "Epoch [62/300], Step [202/225], Training Accuracy: 92.7135%, Training Loss: 0.1905%\n",
      "Epoch [62/300], Step [203/225], Training Accuracy: 92.7109%, Training Loss: 0.1903%\n",
      "Epoch [62/300], Step [204/225], Training Accuracy: 92.7313%, Training Loss: 0.1899%\n",
      "Epoch [62/300], Step [205/225], Training Accuracy: 92.7439%, Training Loss: 0.1898%\n",
      "Epoch [62/300], Step [206/225], Training Accuracy: 92.7564%, Training Loss: 0.1896%\n",
      "Epoch [62/300], Step [207/225], Training Accuracy: 92.7536%, Training Loss: 0.1898%\n",
      "Epoch [62/300], Step [208/225], Training Accuracy: 92.7509%, Training Loss: 0.1896%\n",
      "Epoch [62/300], Step [209/225], Training Accuracy: 92.7407%, Training Loss: 0.1898%\n",
      "Epoch [62/300], Step [210/225], Training Accuracy: 92.7455%, Training Loss: 0.1900%\n",
      "Epoch [62/300], Step [211/225], Training Accuracy: 92.7577%, Training Loss: 0.1901%\n",
      "Epoch [62/300], Step [212/225], Training Accuracy: 92.7255%, Training Loss: 0.1904%\n",
      "Epoch [62/300], Step [213/225], Training Accuracy: 92.7377%, Training Loss: 0.1900%\n",
      "Epoch [62/300], Step [214/225], Training Accuracy: 92.7278%, Training Loss: 0.1907%\n",
      "Epoch [62/300], Step [215/225], Training Accuracy: 92.7253%, Training Loss: 0.1912%\n",
      "Epoch [62/300], Step [216/225], Training Accuracy: 92.7373%, Training Loss: 0.1911%\n",
      "Epoch [62/300], Step [217/225], Training Accuracy: 92.7275%, Training Loss: 0.1911%\n",
      "Epoch [62/300], Step [218/225], Training Accuracy: 92.7251%, Training Loss: 0.1912%\n",
      "Epoch [62/300], Step [219/225], Training Accuracy: 92.7297%, Training Loss: 0.1915%\n",
      "Epoch [62/300], Step [220/225], Training Accuracy: 92.7415%, Training Loss: 0.1913%\n",
      "Epoch [62/300], Step [221/225], Training Accuracy: 92.7460%, Training Loss: 0.1912%\n",
      "Epoch [62/300], Step [222/225], Training Accuracy: 92.7294%, Training Loss: 0.1916%\n",
      "Epoch [62/300], Step [223/225], Training Accuracy: 92.7270%, Training Loss: 0.1916%\n",
      "Epoch [62/300], Step [224/225], Training Accuracy: 92.7525%, Training Loss: 0.1913%\n",
      "Epoch [62/300], Step [225/225], Training Accuracy: 92.7529%, Training Loss: 0.1911%\n",
      "Epoch [63/300], Step [1/225], Training Accuracy: 89.0625%, Training Loss: 0.2903%\n",
      "Epoch [63/300], Step [2/225], Training Accuracy: 91.4062%, Training Loss: 0.2204%\n",
      "Epoch [63/300], Step [3/225], Training Accuracy: 92.1875%, Training Loss: 0.2350%\n",
      "Epoch [63/300], Step [4/225], Training Accuracy: 92.1875%, Training Loss: 0.2159%\n",
      "Epoch [63/300], Step [5/225], Training Accuracy: 92.1875%, Training Loss: 0.2112%\n",
      "Epoch [63/300], Step [6/225], Training Accuracy: 92.4479%, Training Loss: 0.2055%\n",
      "Epoch [63/300], Step [7/225], Training Accuracy: 92.8571%, Training Loss: 0.1936%\n",
      "Epoch [63/300], Step [8/225], Training Accuracy: 92.1875%, Training Loss: 0.1998%\n",
      "Epoch [63/300], Step [9/225], Training Accuracy: 92.1875%, Training Loss: 0.2006%\n",
      "Epoch [63/300], Step [10/225], Training Accuracy: 92.3438%, Training Loss: 0.1937%\n",
      "Epoch [63/300], Step [11/225], Training Accuracy: 92.0455%, Training Loss: 0.1969%\n",
      "Epoch [63/300], Step [12/225], Training Accuracy: 92.3177%, Training Loss: 0.1894%\n",
      "Epoch [63/300], Step [13/225], Training Accuracy: 92.6683%, Training Loss: 0.1825%\n",
      "Epoch [63/300], Step [14/225], Training Accuracy: 92.8571%, Training Loss: 0.1829%\n",
      "Epoch [63/300], Step [15/225], Training Accuracy: 93.0208%, Training Loss: 0.1793%\n",
      "Epoch [63/300], Step [16/225], Training Accuracy: 93.0664%, Training Loss: 0.1801%\n",
      "Epoch [63/300], Step [17/225], Training Accuracy: 93.1985%, Training Loss: 0.1774%\n",
      "Epoch [63/300], Step [18/225], Training Accuracy: 93.0556%, Training Loss: 0.1785%\n",
      "Epoch [63/300], Step [19/225], Training Accuracy: 93.2566%, Training Loss: 0.1753%\n",
      "Epoch [63/300], Step [20/225], Training Accuracy: 93.2031%, Training Loss: 0.1771%\n",
      "Epoch [63/300], Step [21/225], Training Accuracy: 93.3036%, Training Loss: 0.1752%\n",
      "Epoch [63/300], Step [22/225], Training Accuracy: 93.1108%, Training Loss: 0.1797%\n",
      "Epoch [63/300], Step [23/225], Training Accuracy: 92.9348%, Training Loss: 0.1815%\n",
      "Epoch [63/300], Step [24/225], Training Accuracy: 92.9036%, Training Loss: 0.1832%\n",
      "Epoch [63/300], Step [25/225], Training Accuracy: 93.0000%, Training Loss: 0.1793%\n",
      "Epoch [63/300], Step [26/225], Training Accuracy: 93.0288%, Training Loss: 0.1791%\n",
      "Epoch [63/300], Step [27/225], Training Accuracy: 93.1134%, Training Loss: 0.1768%\n",
      "Epoch [63/300], Step [28/225], Training Accuracy: 93.3036%, Training Loss: 0.1735%\n",
      "Epoch [63/300], Step [29/225], Training Accuracy: 93.3190%, Training Loss: 0.1731%\n",
      "Epoch [63/300], Step [30/225], Training Accuracy: 93.3854%, Training Loss: 0.1714%\n",
      "Epoch [63/300], Step [31/225], Training Accuracy: 93.2964%, Training Loss: 0.1722%\n",
      "Epoch [63/300], Step [32/225], Training Accuracy: 93.4082%, Training Loss: 0.1715%\n",
      "Epoch [63/300], Step [33/225], Training Accuracy: 93.3712%, Training Loss: 0.1709%\n",
      "Epoch [63/300], Step [34/225], Training Accuracy: 93.1985%, Training Loss: 0.1728%\n",
      "Epoch [63/300], Step [35/225], Training Accuracy: 93.1696%, Training Loss: 0.1722%\n",
      "Epoch [63/300], Step [36/225], Training Accuracy: 93.1858%, Training Loss: 0.1730%\n",
      "Epoch [63/300], Step [37/225], Training Accuracy: 93.2855%, Training Loss: 0.1714%\n",
      "Epoch [63/300], Step [38/225], Training Accuracy: 93.2155%, Training Loss: 0.1760%\n",
      "Epoch [63/300], Step [39/225], Training Accuracy: 93.2692%, Training Loss: 0.1758%\n",
      "Epoch [63/300], Step [40/225], Training Accuracy: 93.3594%, Training Loss: 0.1750%\n",
      "Epoch [63/300], Step [41/225], Training Accuracy: 93.3689%, Training Loss: 0.1757%\n",
      "Epoch [63/300], Step [42/225], Training Accuracy: 93.3408%, Training Loss: 0.1763%\n",
      "Epoch [63/300], Step [43/225], Training Accuracy: 93.3866%, Training Loss: 0.1771%\n",
      "Epoch [63/300], Step [44/225], Training Accuracy: 93.3239%, Training Loss: 0.1778%\n",
      "Epoch [63/300], Step [45/225], Training Accuracy: 93.3681%, Training Loss: 0.1759%\n",
      "Epoch [63/300], Step [46/225], Training Accuracy: 93.3424%, Training Loss: 0.1761%\n",
      "Epoch [63/300], Step [47/225], Training Accuracy: 93.2846%, Training Loss: 0.1762%\n",
      "Epoch [63/300], Step [48/225], Training Accuracy: 93.2943%, Training Loss: 0.1753%\n",
      "Epoch [63/300], Step [49/225], Training Accuracy: 93.3355%, Training Loss: 0.1745%\n",
      "Epoch [63/300], Step [50/225], Training Accuracy: 93.2812%, Training Loss: 0.1746%\n",
      "Epoch [63/300], Step [51/225], Training Accuracy: 93.2904%, Training Loss: 0.1747%\n",
      "Epoch [63/300], Step [52/225], Training Accuracy: 93.3894%, Training Loss: 0.1728%\n",
      "Epoch [63/300], Step [53/225], Training Accuracy: 93.2783%, Training Loss: 0.1748%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/300], Step [54/225], Training Accuracy: 93.2870%, Training Loss: 0.1748%\n",
      "Epoch [63/300], Step [55/225], Training Accuracy: 93.2670%, Training Loss: 0.1749%\n",
      "Epoch [63/300], Step [56/225], Training Accuracy: 93.3036%, Training Loss: 0.1742%\n",
      "Epoch [63/300], Step [57/225], Training Accuracy: 93.2566%, Training Loss: 0.1751%\n",
      "Epoch [63/300], Step [58/225], Training Accuracy: 93.2920%, Training Loss: 0.1748%\n",
      "Epoch [63/300], Step [59/225], Training Accuracy: 93.1144%, Training Loss: 0.1784%\n",
      "Epoch [63/300], Step [60/225], Training Accuracy: 93.1771%, Training Loss: 0.1779%\n",
      "Epoch [63/300], Step [61/225], Training Accuracy: 93.1352%, Training Loss: 0.1786%\n",
      "Epoch [63/300], Step [62/225], Training Accuracy: 93.1452%, Training Loss: 0.1795%\n",
      "Epoch [63/300], Step [63/225], Training Accuracy: 93.1548%, Training Loss: 0.1791%\n",
      "Epoch [63/300], Step [64/225], Training Accuracy: 93.1641%, Training Loss: 0.1785%\n",
      "Epoch [63/300], Step [65/225], Training Accuracy: 93.2212%, Training Loss: 0.1782%\n",
      "Epoch [63/300], Step [66/225], Training Accuracy: 93.1818%, Training Loss: 0.1792%\n",
      "Epoch [63/300], Step [67/225], Training Accuracy: 93.1670%, Training Loss: 0.1798%\n",
      "Epoch [63/300], Step [68/225], Training Accuracy: 93.1066%, Training Loss: 0.1809%\n",
      "Epoch [63/300], Step [69/225], Training Accuracy: 93.0707%, Training Loss: 0.1815%\n",
      "Epoch [63/300], Step [70/225], Training Accuracy: 93.0357%, Training Loss: 0.1820%\n",
      "Epoch [63/300], Step [71/225], Training Accuracy: 93.0458%, Training Loss: 0.1814%\n",
      "Epoch [63/300], Step [72/225], Training Accuracy: 92.9905%, Training Loss: 0.1834%\n",
      "Epoch [63/300], Step [73/225], Training Accuracy: 93.0223%, Training Loss: 0.1825%\n",
      "Epoch [63/300], Step [74/225], Training Accuracy: 93.0321%, Training Loss: 0.1826%\n",
      "Epoch [63/300], Step [75/225], Training Accuracy: 93.0208%, Training Loss: 0.1821%\n",
      "Epoch [63/300], Step [76/225], Training Accuracy: 93.0510%, Training Loss: 0.1816%\n",
      "Epoch [63/300], Step [77/225], Training Accuracy: 93.0398%, Training Loss: 0.1813%\n",
      "Epoch [63/300], Step [78/225], Training Accuracy: 93.0889%, Training Loss: 0.1807%\n",
      "Epoch [63/300], Step [79/225], Training Accuracy: 93.1566%, Training Loss: 0.1793%\n",
      "Epoch [63/300], Step [80/225], Training Accuracy: 93.2031%, Training Loss: 0.1789%\n",
      "Epoch [63/300], Step [81/225], Training Accuracy: 93.2292%, Training Loss: 0.1784%\n",
      "Epoch [63/300], Step [82/225], Training Accuracy: 93.2546%, Training Loss: 0.1776%\n",
      "Epoch [63/300], Step [83/225], Training Accuracy: 93.2605%, Training Loss: 0.1774%\n",
      "Epoch [63/300], Step [84/225], Training Accuracy: 93.2664%, Training Loss: 0.1765%\n",
      "Epoch [63/300], Step [85/225], Training Accuracy: 93.2169%, Training Loss: 0.1769%\n",
      "Epoch [63/300], Step [86/225], Training Accuracy: 93.2049%, Training Loss: 0.1765%\n",
      "Epoch [63/300], Step [87/225], Training Accuracy: 93.2471%, Training Loss: 0.1761%\n",
      "Epoch [63/300], Step [88/225], Training Accuracy: 93.2173%, Training Loss: 0.1767%\n",
      "Epoch [63/300], Step [89/225], Training Accuracy: 93.2584%, Training Loss: 0.1759%\n",
      "Epoch [63/300], Step [90/225], Training Accuracy: 93.2465%, Training Loss: 0.1764%\n",
      "Epoch [63/300], Step [91/225], Training Accuracy: 93.2864%, Training Loss: 0.1755%\n",
      "Epoch [63/300], Step [92/225], Training Accuracy: 93.2065%, Training Loss: 0.1760%\n",
      "Epoch [63/300], Step [93/225], Training Accuracy: 93.2124%, Training Loss: 0.1761%\n",
      "Epoch [63/300], Step [94/225], Training Accuracy: 93.1682%, Training Loss: 0.1761%\n",
      "Epoch [63/300], Step [95/225], Training Accuracy: 93.1414%, Training Loss: 0.1761%\n",
      "Epoch [63/300], Step [96/225], Training Accuracy: 93.1315%, Training Loss: 0.1764%\n",
      "Epoch [63/300], Step [97/225], Training Accuracy: 93.1057%, Training Loss: 0.1765%\n",
      "Epoch [63/300], Step [98/225], Training Accuracy: 93.1282%, Training Loss: 0.1759%\n",
      "Epoch [63/300], Step [99/225], Training Accuracy: 93.1187%, Training Loss: 0.1763%\n",
      "Epoch [63/300], Step [100/225], Training Accuracy: 93.0781%, Training Loss: 0.1773%\n",
      "Epoch [63/300], Step [101/225], Training Accuracy: 93.0693%, Training Loss: 0.1769%\n",
      "Epoch [63/300], Step [102/225], Training Accuracy: 93.0913%, Training Loss: 0.1766%\n",
      "Epoch [63/300], Step [103/225], Training Accuracy: 93.0825%, Training Loss: 0.1773%\n",
      "Epoch [63/300], Step [104/225], Training Accuracy: 93.0739%, Training Loss: 0.1776%\n",
      "Epoch [63/300], Step [105/225], Training Accuracy: 93.0655%, Training Loss: 0.1779%\n",
      "Epoch [63/300], Step [106/225], Training Accuracy: 93.0867%, Training Loss: 0.1778%\n",
      "Epoch [63/300], Step [107/225], Training Accuracy: 93.0637%, Training Loss: 0.1777%\n",
      "Epoch [63/300], Step [108/225], Training Accuracy: 92.9832%, Training Loss: 0.1791%\n",
      "Epoch [63/300], Step [109/225], Training Accuracy: 92.9472%, Training Loss: 0.1796%\n",
      "Epoch [63/300], Step [110/225], Training Accuracy: 92.9545%, Training Loss: 0.1795%\n",
      "Epoch [63/300], Step [111/225], Training Accuracy: 92.9617%, Training Loss: 0.1793%\n",
      "Epoch [63/300], Step [112/225], Training Accuracy: 92.9688%, Training Loss: 0.1792%\n",
      "Epoch [63/300], Step [113/225], Training Accuracy: 92.9065%, Training Loss: 0.1798%\n",
      "Epoch [63/300], Step [114/225], Training Accuracy: 92.8317%, Training Loss: 0.1811%\n",
      "Epoch [63/300], Step [115/225], Training Accuracy: 92.7989%, Training Loss: 0.1816%\n",
      "Epoch [63/300], Step [116/225], Training Accuracy: 92.8071%, Training Loss: 0.1814%\n",
      "Epoch [63/300], Step [117/225], Training Accuracy: 92.7885%, Training Loss: 0.1837%\n",
      "Epoch [63/300], Step [118/225], Training Accuracy: 92.8099%, Training Loss: 0.1834%\n",
      "Epoch [63/300], Step [119/225], Training Accuracy: 92.8440%, Training Loss: 0.1831%\n",
      "Epoch [63/300], Step [120/225], Training Accuracy: 92.8776%, Training Loss: 0.1825%\n",
      "Epoch [63/300], Step [121/225], Training Accuracy: 92.9106%, Training Loss: 0.1817%\n",
      "Epoch [63/300], Step [122/225], Training Accuracy: 92.9047%, Training Loss: 0.1816%\n",
      "Epoch [63/300], Step [123/225], Training Accuracy: 92.9243%, Training Loss: 0.1819%\n",
      "Epoch [63/300], Step [124/225], Training Accuracy: 92.9561%, Training Loss: 0.1812%\n",
      "Epoch [63/300], Step [125/225], Training Accuracy: 92.9250%, Training Loss: 0.1818%\n",
      "Epoch [63/300], Step [126/225], Training Accuracy: 92.9191%, Training Loss: 0.1818%\n",
      "Epoch [63/300], Step [127/225], Training Accuracy: 92.8888%, Training Loss: 0.1818%\n",
      "Epoch [63/300], Step [128/225], Training Accuracy: 92.9199%, Training Loss: 0.1817%\n",
      "Epoch [63/300], Step [129/225], Training Accuracy: 92.9142%, Training Loss: 0.1817%\n",
      "Epoch [63/300], Step [130/225], Training Accuracy: 92.8846%, Training Loss: 0.1819%\n",
      "Epoch [63/300], Step [131/225], Training Accuracy: 92.8674%, Training Loss: 0.1823%\n",
      "Epoch [63/300], Step [132/225], Training Accuracy: 92.8977%, Training Loss: 0.1820%\n",
      "Epoch [63/300], Step [133/225], Training Accuracy: 92.8924%, Training Loss: 0.1822%\n",
      "Epoch [63/300], Step [134/225], Training Accuracy: 92.8988%, Training Loss: 0.1821%\n",
      "Epoch [63/300], Step [135/225], Training Accuracy: 92.9167%, Training Loss: 0.1818%\n",
      "Epoch [63/300], Step [136/225], Training Accuracy: 92.8539%, Training Loss: 0.1833%\n",
      "Epoch [63/300], Step [137/225], Training Accuracy: 92.8832%, Training Loss: 0.1831%\n",
      "Epoch [63/300], Step [138/225], Training Accuracy: 92.8895%, Training Loss: 0.1829%\n",
      "Epoch [63/300], Step [139/225], Training Accuracy: 92.8732%, Training Loss: 0.1826%\n",
      "Epoch [63/300], Step [140/225], Training Accuracy: 92.9018%, Training Loss: 0.1819%\n",
      "Epoch [63/300], Step [141/225], Training Accuracy: 92.8746%, Training Loss: 0.1822%\n",
      "Epoch [63/300], Step [142/225], Training Accuracy: 92.9027%, Training Loss: 0.1818%\n",
      "Epoch [63/300], Step [143/225], Training Accuracy: 92.8977%, Training Loss: 0.1822%\n",
      "Epoch [63/300], Step [144/225], Training Accuracy: 92.9145%, Training Loss: 0.1816%\n",
      "Epoch [63/300], Step [145/225], Training Accuracy: 92.9095%, Training Loss: 0.1816%\n",
      "Epoch [63/300], Step [146/225], Training Accuracy: 92.8724%, Training Loss: 0.1823%\n",
      "Epoch [63/300], Step [147/225], Training Accuracy: 92.8890%, Training Loss: 0.1821%\n",
      "Epoch [63/300], Step [148/225], Training Accuracy: 92.9160%, Training Loss: 0.1818%\n",
      "Epoch [63/300], Step [149/225], Training Accuracy: 92.9006%, Training Loss: 0.1823%\n",
      "Epoch [63/300], Step [150/225], Training Accuracy: 92.9375%, Training Loss: 0.1816%\n",
      "Epoch [63/300], Step [151/225], Training Accuracy: 92.9325%, Training Loss: 0.1817%\n",
      "Epoch [63/300], Step [152/225], Training Accuracy: 92.9482%, Training Loss: 0.1816%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/300], Step [153/225], Training Accuracy: 92.9432%, Training Loss: 0.1822%\n",
      "Epoch [63/300], Step [154/225], Training Accuracy: 92.9485%, Training Loss: 0.1822%\n",
      "Epoch [63/300], Step [155/225], Training Accuracy: 92.9435%, Training Loss: 0.1820%\n",
      "Epoch [63/300], Step [156/225], Training Accuracy: 92.9387%, Training Loss: 0.1819%\n",
      "Epoch [63/300], Step [157/225], Training Accuracy: 92.9339%, Training Loss: 0.1822%\n",
      "Epoch [63/300], Step [158/225], Training Accuracy: 92.9292%, Training Loss: 0.1819%\n",
      "Epoch [63/300], Step [159/225], Training Accuracy: 92.8950%, Training Loss: 0.1823%\n",
      "Epoch [63/300], Step [160/225], Training Accuracy: 92.8711%, Training Loss: 0.1827%\n",
      "Epoch [63/300], Step [161/225], Training Accuracy: 92.8960%, Training Loss: 0.1822%\n",
      "Epoch [63/300], Step [162/225], Training Accuracy: 92.9205%, Training Loss: 0.1817%\n",
      "Epoch [63/300], Step [163/225], Training Accuracy: 92.9160%, Training Loss: 0.1821%\n",
      "Epoch [63/300], Step [164/225], Training Accuracy: 92.9402%, Training Loss: 0.1818%\n",
      "Epoch [63/300], Step [165/225], Training Accuracy: 92.9545%, Training Loss: 0.1815%\n",
      "Epoch [63/300], Step [166/225], Training Accuracy: 92.9217%, Training Loss: 0.1821%\n",
      "Epoch [63/300], Step [167/225], Training Accuracy: 92.9454%, Training Loss: 0.1818%\n",
      "Epoch [63/300], Step [168/225], Training Accuracy: 92.9222%, Training Loss: 0.1819%\n",
      "Epoch [63/300], Step [169/225], Training Accuracy: 92.9456%, Training Loss: 0.1813%\n",
      "Epoch [63/300], Step [170/225], Training Accuracy: 92.9688%, Training Loss: 0.1810%\n",
      "Epoch [63/300], Step [171/225], Training Accuracy: 92.9733%, Training Loss: 0.1813%\n",
      "Epoch [63/300], Step [172/225], Training Accuracy: 92.9597%, Training Loss: 0.1819%\n",
      "Epoch [63/300], Step [173/225], Training Accuracy: 92.9462%, Training Loss: 0.1822%\n",
      "Epoch [63/300], Step [174/225], Training Accuracy: 92.9688%, Training Loss: 0.1817%\n",
      "Epoch [63/300], Step [175/225], Training Accuracy: 92.9821%, Training Loss: 0.1815%\n",
      "Epoch [63/300], Step [176/225], Training Accuracy: 92.9954%, Training Loss: 0.1811%\n",
      "Epoch [63/300], Step [177/225], Training Accuracy: 93.0085%, Training Loss: 0.1808%\n",
      "Epoch [63/300], Step [178/225], Training Accuracy: 93.0214%, Training Loss: 0.1809%\n",
      "Epoch [63/300], Step [179/225], Training Accuracy: 93.0255%, Training Loss: 0.1817%\n",
      "Epoch [63/300], Step [180/225], Training Accuracy: 93.0208%, Training Loss: 0.1820%\n",
      "Epoch [63/300], Step [181/225], Training Accuracy: 93.0249%, Training Loss: 0.1821%\n",
      "Epoch [63/300], Step [182/225], Training Accuracy: 93.0203%, Training Loss: 0.1819%\n",
      "Epoch [63/300], Step [183/225], Training Accuracy: 93.0413%, Training Loss: 0.1813%\n",
      "Epoch [63/300], Step [184/225], Training Accuracy: 93.0622%, Training Loss: 0.1813%\n",
      "Epoch [63/300], Step [185/225], Training Accuracy: 93.0743%, Training Loss: 0.1810%\n",
      "Epoch [63/300], Step [186/225], Training Accuracy: 93.0696%, Training Loss: 0.1810%\n",
      "Epoch [63/300], Step [187/225], Training Accuracy: 93.0816%, Training Loss: 0.1806%\n",
      "Epoch [63/300], Step [188/225], Training Accuracy: 93.0851%, Training Loss: 0.1804%\n",
      "Epoch [63/300], Step [189/225], Training Accuracy: 93.0804%, Training Loss: 0.1802%\n",
      "Epoch [63/300], Step [190/225], Training Accuracy: 93.0921%, Training Loss: 0.1801%\n",
      "Epoch [63/300], Step [191/225], Training Accuracy: 93.0874%, Training Loss: 0.1801%\n",
      "Epoch [63/300], Step [192/225], Training Accuracy: 93.1071%, Training Loss: 0.1797%\n",
      "Epoch [63/300], Step [193/225], Training Accuracy: 93.1104%, Training Loss: 0.1799%\n",
      "Epoch [63/300], Step [194/225], Training Accuracy: 93.0735%, Training Loss: 0.1805%\n",
      "Epoch [63/300], Step [195/225], Training Accuracy: 93.0689%, Training Loss: 0.1803%\n",
      "Epoch [63/300], Step [196/225], Training Accuracy: 93.0405%, Training Loss: 0.1806%\n",
      "Epoch [63/300], Step [197/225], Training Accuracy: 93.0520%, Training Loss: 0.1804%\n",
      "Epoch [63/300], Step [198/225], Training Accuracy: 93.0713%, Training Loss: 0.1800%\n",
      "Epoch [63/300], Step [199/225], Training Accuracy: 93.0590%, Training Loss: 0.1803%\n",
      "Epoch [63/300], Step [200/225], Training Accuracy: 93.0703%, Training Loss: 0.1800%\n",
      "Epoch [63/300], Step [201/225], Training Accuracy: 93.0659%, Training Loss: 0.1802%\n",
      "Epoch [63/300], Step [202/225], Training Accuracy: 93.0770%, Training Loss: 0.1803%\n",
      "Epoch [63/300], Step [203/225], Training Accuracy: 93.0727%, Training Loss: 0.1804%\n",
      "Epoch [63/300], Step [204/225], Training Accuracy: 93.0836%, Training Loss: 0.1802%\n",
      "Epoch [63/300], Step [205/225], Training Accuracy: 93.1174%, Training Loss: 0.1796%\n",
      "Epoch [63/300], Step [206/225], Training Accuracy: 93.1129%, Training Loss: 0.1798%\n",
      "Epoch [63/300], Step [207/225], Training Accuracy: 93.1310%, Training Loss: 0.1796%\n",
      "Epoch [63/300], Step [208/225], Training Accuracy: 93.1265%, Training Loss: 0.1797%\n",
      "Epoch [63/300], Step [209/225], Training Accuracy: 93.0846%, Training Loss: 0.1802%\n",
      "Epoch [63/300], Step [210/225], Training Accuracy: 93.0655%, Training Loss: 0.1806%\n",
      "Epoch [63/300], Step [211/225], Training Accuracy: 93.0613%, Training Loss: 0.1807%\n",
      "Epoch [63/300], Step [212/225], Training Accuracy: 93.0646%, Training Loss: 0.1807%\n",
      "Epoch [63/300], Step [213/225], Training Accuracy: 93.0898%, Training Loss: 0.1805%\n",
      "Epoch [63/300], Step [214/225], Training Accuracy: 93.1075%, Training Loss: 0.1801%\n",
      "Epoch [63/300], Step [215/225], Training Accuracy: 93.1323%, Training Loss: 0.1795%\n",
      "Epoch [63/300], Step [216/225], Training Accuracy: 93.1279%, Training Loss: 0.1794%\n",
      "Epoch [63/300], Step [217/225], Training Accuracy: 93.1164%, Training Loss: 0.1802%\n",
      "Epoch [63/300], Step [218/225], Training Accuracy: 93.1049%, Training Loss: 0.1802%\n",
      "Epoch [63/300], Step [219/225], Training Accuracy: 93.1150%, Training Loss: 0.1798%\n",
      "Epoch [63/300], Step [220/225], Training Accuracy: 93.1108%, Training Loss: 0.1800%\n",
      "Epoch [63/300], Step [221/225], Training Accuracy: 93.1278%, Training Loss: 0.1797%\n",
      "Epoch [63/300], Step [222/225], Training Accuracy: 93.1377%, Training Loss: 0.1796%\n",
      "Epoch [63/300], Step [223/225], Training Accuracy: 93.1194%, Training Loss: 0.1799%\n",
      "Epoch [63/300], Step [224/225], Training Accuracy: 93.1292%, Training Loss: 0.1797%\n",
      "Epoch [63/300], Step [225/225], Training Accuracy: 93.1073%, Training Loss: 0.1802%\n",
      "Epoch [64/300], Step [1/225], Training Accuracy: 89.0625%, Training Loss: 0.3208%\n",
      "Epoch [64/300], Step [2/225], Training Accuracy: 88.2812%, Training Loss: 0.3268%\n",
      "Epoch [64/300], Step [3/225], Training Accuracy: 89.0625%, Training Loss: 0.3005%\n",
      "Epoch [64/300], Step [4/225], Training Accuracy: 89.8438%, Training Loss: 0.2918%\n",
      "Epoch [64/300], Step [5/225], Training Accuracy: 90.6250%, Training Loss: 0.2686%\n",
      "Epoch [64/300], Step [6/225], Training Accuracy: 91.9271%, Training Loss: 0.2415%\n",
      "Epoch [64/300], Step [7/225], Training Accuracy: 91.2946%, Training Loss: 0.2522%\n",
      "Epoch [64/300], Step [8/225], Training Accuracy: 91.2109%, Training Loss: 0.2459%\n",
      "Epoch [64/300], Step [9/225], Training Accuracy: 91.3194%, Training Loss: 0.2373%\n",
      "Epoch [64/300], Step [10/225], Training Accuracy: 91.0938%, Training Loss: 0.2512%\n",
      "Epoch [64/300], Step [11/225], Training Accuracy: 90.9091%, Training Loss: 0.2544%\n",
      "Epoch [64/300], Step [12/225], Training Accuracy: 91.0156%, Training Loss: 0.2516%\n",
      "Epoch [64/300], Step [13/225], Training Accuracy: 91.4663%, Training Loss: 0.2388%\n",
      "Epoch [64/300], Step [14/225], Training Accuracy: 91.5179%, Training Loss: 0.2336%\n",
      "Epoch [64/300], Step [15/225], Training Accuracy: 91.6667%, Training Loss: 0.2310%\n",
      "Epoch [64/300], Step [16/225], Training Accuracy: 91.8945%, Training Loss: 0.2269%\n",
      "Epoch [64/300], Step [17/225], Training Accuracy: 91.8199%, Training Loss: 0.2230%\n",
      "Epoch [64/300], Step [18/225], Training Accuracy: 91.6667%, Training Loss: 0.2263%\n",
      "Epoch [64/300], Step [19/225], Training Accuracy: 91.7763%, Training Loss: 0.2279%\n",
      "Epoch [64/300], Step [20/225], Training Accuracy: 91.9531%, Training Loss: 0.2214%\n",
      "Epoch [64/300], Step [21/225], Training Accuracy: 91.7411%, Training Loss: 0.2194%\n",
      "Epoch [64/300], Step [22/225], Training Accuracy: 91.4062%, Training Loss: 0.2249%\n",
      "Epoch [64/300], Step [23/225], Training Accuracy: 91.6440%, Training Loss: 0.2207%\n",
      "Epoch [64/300], Step [24/225], Training Accuracy: 91.7318%, Training Loss: 0.2205%\n",
      "Epoch [64/300], Step [25/225], Training Accuracy: 91.6875%, Training Loss: 0.2211%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/300], Step [26/225], Training Accuracy: 91.6466%, Training Loss: 0.2184%\n",
      "Epoch [64/300], Step [27/225], Training Accuracy: 91.6667%, Training Loss: 0.2174%\n",
      "Epoch [64/300], Step [28/225], Training Accuracy: 91.7411%, Training Loss: 0.2129%\n",
      "Epoch [64/300], Step [29/225], Training Accuracy: 91.8642%, Training Loss: 0.2088%\n",
      "Epoch [64/300], Step [30/225], Training Accuracy: 91.9792%, Training Loss: 0.2116%\n",
      "Epoch [64/300], Step [31/225], Training Accuracy: 91.9355%, Training Loss: 0.2121%\n",
      "Epoch [64/300], Step [32/225], Training Accuracy: 91.9434%, Training Loss: 0.2127%\n",
      "Epoch [64/300], Step [33/225], Training Accuracy: 92.0928%, Training Loss: 0.2103%\n",
      "Epoch [64/300], Step [34/225], Training Accuracy: 92.0496%, Training Loss: 0.2114%\n",
      "Epoch [64/300], Step [35/225], Training Accuracy: 92.0536%, Training Loss: 0.2104%\n",
      "Epoch [64/300], Step [36/225], Training Accuracy: 92.1441%, Training Loss: 0.2074%\n",
      "Epoch [64/300], Step [37/225], Training Accuracy: 92.1030%, Training Loss: 0.2059%\n",
      "Epoch [64/300], Step [38/225], Training Accuracy: 92.1464%, Training Loss: 0.2051%\n",
      "Epoch [64/300], Step [39/225], Training Accuracy: 92.0272%, Training Loss: 0.2078%\n",
      "Epoch [64/300], Step [40/225], Training Accuracy: 92.0312%, Training Loss: 0.2067%\n",
      "Epoch [64/300], Step [41/225], Training Accuracy: 91.9588%, Training Loss: 0.2082%\n",
      "Epoch [64/300], Step [42/225], Training Accuracy: 92.0387%, Training Loss: 0.2058%\n",
      "Epoch [64/300], Step [43/225], Training Accuracy: 91.9331%, Training Loss: 0.2084%\n",
      "Epoch [64/300], Step [44/225], Training Accuracy: 92.0099%, Training Loss: 0.2072%\n",
      "Epoch [64/300], Step [45/225], Training Accuracy: 91.9792%, Training Loss: 0.2064%\n",
      "Epoch [64/300], Step [46/225], Training Accuracy: 92.0516%, Training Loss: 0.2059%\n",
      "Epoch [64/300], Step [47/225], Training Accuracy: 92.1210%, Training Loss: 0.2052%\n",
      "Epoch [64/300], Step [48/225], Training Accuracy: 92.1549%, Training Loss: 0.2029%\n",
      "Epoch [64/300], Step [49/225], Training Accuracy: 92.0918%, Training Loss: 0.2029%\n",
      "Epoch [64/300], Step [50/225], Training Accuracy: 92.1562%, Training Loss: 0.2015%\n",
      "Epoch [64/300], Step [51/225], Training Accuracy: 92.1875%, Training Loss: 0.2008%\n",
      "Epoch [64/300], Step [52/225], Training Accuracy: 92.1575%, Training Loss: 0.2008%\n",
      "Epoch [64/300], Step [53/225], Training Accuracy: 92.1875%, Training Loss: 0.2000%\n",
      "Epoch [64/300], Step [54/225], Training Accuracy: 92.2164%, Training Loss: 0.2004%\n",
      "Epoch [64/300], Step [55/225], Training Accuracy: 92.2443%, Training Loss: 0.1992%\n",
      "Epoch [64/300], Step [56/225], Training Accuracy: 92.2433%, Training Loss: 0.1995%\n",
      "Epoch [64/300], Step [57/225], Training Accuracy: 92.1053%, Training Loss: 0.2011%\n",
      "Epoch [64/300], Step [58/225], Training Accuracy: 92.0259%, Training Loss: 0.2023%\n",
      "Epoch [64/300], Step [59/225], Training Accuracy: 92.0551%, Training Loss: 0.2013%\n",
      "Epoch [64/300], Step [60/225], Training Accuracy: 91.9792%, Training Loss: 0.2028%\n",
      "Epoch [64/300], Step [61/225], Training Accuracy: 91.9826%, Training Loss: 0.2027%\n",
      "Epoch [64/300], Step [62/225], Training Accuracy: 92.0363%, Training Loss: 0.2012%\n",
      "Epoch [64/300], Step [63/225], Training Accuracy: 92.0387%, Training Loss: 0.2005%\n",
      "Epoch [64/300], Step [64/225], Training Accuracy: 92.0166%, Training Loss: 0.2000%\n",
      "Epoch [64/300], Step [65/225], Training Accuracy: 92.0192%, Training Loss: 0.1990%\n",
      "Epoch [64/300], Step [66/225], Training Accuracy: 92.0455%, Training Loss: 0.1979%\n",
      "Epoch [64/300], Step [67/225], Training Accuracy: 92.1409%, Training Loss: 0.1962%\n",
      "Epoch [64/300], Step [68/225], Training Accuracy: 92.2105%, Training Loss: 0.1946%\n",
      "Epoch [64/300], Step [69/225], Training Accuracy: 92.2328%, Training Loss: 0.1937%\n",
      "Epoch [64/300], Step [70/225], Training Accuracy: 92.2545%, Training Loss: 0.1933%\n",
      "Epoch [64/300], Step [71/225], Training Accuracy: 92.3195%, Training Loss: 0.1920%\n",
      "Epoch [64/300], Step [72/225], Training Accuracy: 92.3611%, Training Loss: 0.1915%\n",
      "Epoch [64/300], Step [73/225], Training Accuracy: 92.3159%, Training Loss: 0.1917%\n",
      "Epoch [64/300], Step [74/225], Training Accuracy: 92.3564%, Training Loss: 0.1909%\n",
      "Epoch [64/300], Step [75/225], Training Accuracy: 92.3750%, Training Loss: 0.1903%\n",
      "Epoch [64/300], Step [76/225], Training Accuracy: 92.4342%, Training Loss: 0.1894%\n",
      "Epoch [64/300], Step [77/225], Training Accuracy: 92.5122%, Training Loss: 0.1880%\n",
      "Epoch [64/300], Step [78/225], Training Accuracy: 92.5681%, Training Loss: 0.1876%\n",
      "Epoch [64/300], Step [79/225], Training Accuracy: 92.6622%, Training Loss: 0.1862%\n",
      "Epoch [64/300], Step [80/225], Training Accuracy: 92.6758%, Training Loss: 0.1859%\n",
      "Epoch [64/300], Step [81/225], Training Accuracy: 92.7083%, Training Loss: 0.1851%\n",
      "Epoch [64/300], Step [82/225], Training Accuracy: 92.7210%, Training Loss: 0.1849%\n",
      "Epoch [64/300], Step [83/225], Training Accuracy: 92.7334%, Training Loss: 0.1853%\n",
      "Epoch [64/300], Step [84/225], Training Accuracy: 92.7827%, Training Loss: 0.1845%\n",
      "Epoch [64/300], Step [85/225], Training Accuracy: 92.7390%, Training Loss: 0.1845%\n",
      "Epoch [64/300], Step [86/225], Training Accuracy: 92.8234%, Training Loss: 0.1831%\n",
      "Epoch [64/300], Step [87/225], Training Accuracy: 92.7802%, Training Loss: 0.1840%\n",
      "Epoch [64/300], Step [88/225], Training Accuracy: 92.7202%, Training Loss: 0.1851%\n",
      "Epoch [64/300], Step [89/225], Training Accuracy: 92.7669%, Training Loss: 0.1842%\n",
      "Epoch [64/300], Step [90/225], Training Accuracy: 92.8125%, Training Loss: 0.1831%\n",
      "Epoch [64/300], Step [91/225], Training Accuracy: 92.8056%, Training Loss: 0.1830%\n",
      "Epoch [64/300], Step [92/225], Training Accuracy: 92.7819%, Training Loss: 0.1834%\n",
      "Epoch [64/300], Step [93/225], Training Accuracy: 92.8259%, Training Loss: 0.1823%\n",
      "Epoch [64/300], Step [94/225], Training Accuracy: 92.8524%, Training Loss: 0.1827%\n",
      "Epoch [64/300], Step [95/225], Training Accuracy: 92.8289%, Training Loss: 0.1830%\n",
      "Epoch [64/300], Step [96/225], Training Accuracy: 92.8223%, Training Loss: 0.1825%\n",
      "Epoch [64/300], Step [97/225], Training Accuracy: 92.8157%, Training Loss: 0.1832%\n",
      "Epoch [64/300], Step [98/225], Training Accuracy: 92.8093%, Training Loss: 0.1831%\n",
      "Epoch [64/300], Step [99/225], Training Accuracy: 92.8030%, Training Loss: 0.1837%\n",
      "Epoch [64/300], Step [100/225], Training Accuracy: 92.7812%, Training Loss: 0.1850%\n",
      "Epoch [64/300], Step [101/225], Training Accuracy: 92.7754%, Training Loss: 0.1861%\n",
      "Epoch [64/300], Step [102/225], Training Accuracy: 92.7696%, Training Loss: 0.1866%\n",
      "Epoch [64/300], Step [103/225], Training Accuracy: 92.8246%, Training Loss: 0.1855%\n",
      "Epoch [64/300], Step [104/225], Training Accuracy: 92.8335%, Training Loss: 0.1853%\n",
      "Epoch [64/300], Step [105/225], Training Accuracy: 92.8571%, Training Loss: 0.1849%\n",
      "Epoch [64/300], Step [106/225], Training Accuracy: 92.8508%, Training Loss: 0.1847%\n",
      "Epoch [64/300], Step [107/225], Training Accuracy: 92.8884%, Training Loss: 0.1848%\n",
      "Epoch [64/300], Step [108/225], Training Accuracy: 92.8675%, Training Loss: 0.1847%\n",
      "Epoch [64/300], Step [109/225], Training Accuracy: 92.8612%, Training Loss: 0.1850%\n",
      "Epoch [64/300], Step [110/225], Training Accuracy: 92.8409%, Training Loss: 0.1863%\n",
      "Epoch [64/300], Step [111/225], Training Accuracy: 92.8069%, Training Loss: 0.1867%\n",
      "Epoch [64/300], Step [112/225], Training Accuracy: 92.8013%, Training Loss: 0.1865%\n",
      "Epoch [64/300], Step [113/225], Training Accuracy: 92.7959%, Training Loss: 0.1861%\n",
      "Epoch [64/300], Step [114/225], Training Accuracy: 92.8043%, Training Loss: 0.1859%\n",
      "Epoch [64/300], Step [115/225], Training Accuracy: 92.7989%, Training Loss: 0.1871%\n",
      "Epoch [64/300], Step [116/225], Training Accuracy: 92.8071%, Training Loss: 0.1875%\n",
      "Epoch [64/300], Step [117/225], Training Accuracy: 92.8018%, Training Loss: 0.1876%\n",
      "Epoch [64/300], Step [118/225], Training Accuracy: 92.8099%, Training Loss: 0.1873%\n",
      "Epoch [64/300], Step [119/225], Training Accuracy: 92.7915%, Training Loss: 0.1874%\n",
      "Epoch [64/300], Step [120/225], Training Accuracy: 92.7995%, Training Loss: 0.1875%\n",
      "Epoch [64/300], Step [121/225], Training Accuracy: 92.7815%, Training Loss: 0.1888%\n",
      "Epoch [64/300], Step [122/225], Training Accuracy: 92.7766%, Training Loss: 0.1887%\n",
      "Epoch [64/300], Step [123/225], Training Accuracy: 92.8100%, Training Loss: 0.1878%\n",
      "Epoch [64/300], Step [124/225], Training Accuracy: 92.8175%, Training Loss: 0.1876%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/300], Step [125/225], Training Accuracy: 92.8250%, Training Loss: 0.1877%\n",
      "Epoch [64/300], Step [126/225], Training Accuracy: 92.8075%, Training Loss: 0.1879%\n",
      "Epoch [64/300], Step [127/225], Training Accuracy: 92.7781%, Training Loss: 0.1882%\n",
      "Epoch [64/300], Step [128/225], Training Accuracy: 92.7856%, Training Loss: 0.1881%\n",
      "Epoch [64/300], Step [129/225], Training Accuracy: 92.7568%, Training Loss: 0.1891%\n",
      "Epoch [64/300], Step [130/225], Training Accuracy: 92.8005%, Training Loss: 0.1886%\n",
      "Epoch [64/300], Step [131/225], Training Accuracy: 92.7958%, Training Loss: 0.1890%\n",
      "Epoch [64/300], Step [132/225], Training Accuracy: 92.8149%, Training Loss: 0.1888%\n",
      "Epoch [64/300], Step [133/225], Training Accuracy: 92.8102%, Training Loss: 0.1886%\n",
      "Epoch [64/300], Step [134/225], Training Accuracy: 92.7705%, Training Loss: 0.1899%\n",
      "Epoch [64/300], Step [135/225], Training Accuracy: 92.7662%, Training Loss: 0.1898%\n",
      "Epoch [64/300], Step [136/225], Training Accuracy: 92.7619%, Training Loss: 0.1898%\n",
      "Epoch [64/300], Step [137/225], Training Accuracy: 92.6893%, Training Loss: 0.1914%\n",
      "Epoch [64/300], Step [138/225], Training Accuracy: 92.7197%, Training Loss: 0.1905%\n",
      "Epoch [64/300], Step [139/225], Training Accuracy: 92.7271%, Training Loss: 0.1903%\n",
      "Epoch [64/300], Step [140/225], Training Accuracy: 92.7121%, Training Loss: 0.1905%\n",
      "Epoch [64/300], Step [141/225], Training Accuracy: 92.6973%, Training Loss: 0.1902%\n",
      "Epoch [64/300], Step [142/225], Training Accuracy: 92.6717%, Training Loss: 0.1905%\n",
      "Epoch [64/300], Step [143/225], Training Accuracy: 92.6573%, Training Loss: 0.1909%\n",
      "Epoch [64/300], Step [144/225], Training Accuracy: 92.6758%, Training Loss: 0.1901%\n",
      "Epoch [64/300], Step [145/225], Training Accuracy: 92.6401%, Training Loss: 0.1906%\n",
      "Epoch [64/300], Step [146/225], Training Accuracy: 92.6370%, Training Loss: 0.1905%\n",
      "Epoch [64/300], Step [147/225], Training Accuracy: 92.6446%, Training Loss: 0.1903%\n",
      "Epoch [64/300], Step [148/225], Training Accuracy: 92.6626%, Training Loss: 0.1900%\n",
      "Epoch [64/300], Step [149/225], Training Accuracy: 92.6594%, Training Loss: 0.1911%\n",
      "Epoch [64/300], Step [150/225], Training Accuracy: 92.6667%, Training Loss: 0.1910%\n",
      "Epoch [64/300], Step [151/225], Training Accuracy: 92.6945%, Training Loss: 0.1905%\n",
      "Epoch [64/300], Step [152/225], Training Accuracy: 92.7015%, Training Loss: 0.1905%\n",
      "Epoch [64/300], Step [153/225], Training Accuracy: 92.7083%, Training Loss: 0.1899%\n",
      "Epoch [64/300], Step [154/225], Training Accuracy: 92.7354%, Training Loss: 0.1893%\n",
      "Epoch [64/300], Step [155/225], Training Accuracy: 92.7117%, Training Loss: 0.1897%\n",
      "Epoch [64/300], Step [156/225], Training Accuracy: 92.7083%, Training Loss: 0.1905%\n",
      "Epoch [64/300], Step [157/225], Training Accuracy: 92.6752%, Training Loss: 0.1908%\n",
      "Epoch [64/300], Step [158/225], Training Accuracy: 92.7017%, Training Loss: 0.1899%\n",
      "Epoch [64/300], Step [159/225], Training Accuracy: 92.6592%, Training Loss: 0.1904%\n",
      "Epoch [64/300], Step [160/225], Training Accuracy: 92.6367%, Training Loss: 0.1907%\n",
      "Epoch [64/300], Step [161/225], Training Accuracy: 92.6242%, Training Loss: 0.1911%\n",
      "Epoch [64/300], Step [162/225], Training Accuracy: 92.6215%, Training Loss: 0.1913%\n",
      "Epoch [64/300], Step [163/225], Training Accuracy: 92.6093%, Training Loss: 0.1912%\n",
      "Epoch [64/300], Step [164/225], Training Accuracy: 92.6258%, Training Loss: 0.1908%\n",
      "Epoch [64/300], Step [165/225], Training Accuracy: 92.6136%, Training Loss: 0.1910%\n",
      "Epoch [64/300], Step [166/225], Training Accuracy: 92.6017%, Training Loss: 0.1912%\n",
      "Epoch [64/300], Step [167/225], Training Accuracy: 92.5898%, Training Loss: 0.1914%\n",
      "Epoch [64/300], Step [168/225], Training Accuracy: 92.5967%, Training Loss: 0.1912%\n",
      "Epoch [64/300], Step [169/225], Training Accuracy: 92.6220%, Training Loss: 0.1906%\n",
      "Epoch [64/300], Step [170/225], Training Accuracy: 92.6287%, Training Loss: 0.1904%\n",
      "Epoch [64/300], Step [171/225], Training Accuracy: 92.5987%, Training Loss: 0.1907%\n",
      "Epoch [64/300], Step [172/225], Training Accuracy: 92.5872%, Training Loss: 0.1907%\n",
      "Epoch [64/300], Step [173/225], Training Accuracy: 92.5939%, Training Loss: 0.1904%\n",
      "Epoch [64/300], Step [174/225], Training Accuracy: 92.5916%, Training Loss: 0.1903%\n",
      "Epoch [64/300], Step [175/225], Training Accuracy: 92.5714%, Training Loss: 0.1906%\n",
      "Epoch [64/300], Step [176/225], Training Accuracy: 92.5781%, Training Loss: 0.1903%\n",
      "Epoch [64/300], Step [177/225], Training Accuracy: 92.6024%, Training Loss: 0.1897%\n",
      "Epoch [64/300], Step [178/225], Training Accuracy: 92.5825%, Training Loss: 0.1897%\n",
      "Epoch [64/300], Step [179/225], Training Accuracy: 92.6065%, Training Loss: 0.1895%\n",
      "Epoch [64/300], Step [180/225], Training Accuracy: 92.6215%, Training Loss: 0.1891%\n",
      "Epoch [64/300], Step [181/225], Training Accuracy: 92.6537%, Training Loss: 0.1888%\n",
      "Epoch [64/300], Step [182/225], Training Accuracy: 92.6339%, Training Loss: 0.1894%\n",
      "Epoch [64/300], Step [183/225], Training Accuracy: 92.6571%, Training Loss: 0.1889%\n",
      "Epoch [64/300], Step [184/225], Training Accuracy: 92.6715%, Training Loss: 0.1890%\n",
      "Epoch [64/300], Step [185/225], Training Accuracy: 92.6858%, Training Loss: 0.1892%\n",
      "Epoch [64/300], Step [186/225], Training Accuracy: 92.7167%, Training Loss: 0.1886%\n",
      "Epoch [64/300], Step [187/225], Training Accuracy: 92.7055%, Training Loss: 0.1883%\n",
      "Epoch [64/300], Step [188/225], Training Accuracy: 92.7194%, Training Loss: 0.1881%\n",
      "Epoch [64/300], Step [189/225], Training Accuracy: 92.7249%, Training Loss: 0.1877%\n",
      "Epoch [64/300], Step [190/225], Training Accuracy: 92.7549%, Training Loss: 0.1873%\n",
      "Epoch [64/300], Step [191/225], Training Accuracy: 92.7601%, Training Loss: 0.1874%\n",
      "Epoch [64/300], Step [192/225], Training Accuracy: 92.7653%, Training Loss: 0.1875%\n",
      "Epoch [64/300], Step [193/225], Training Accuracy: 92.7785%, Training Loss: 0.1877%\n",
      "Epoch [64/300], Step [194/225], Training Accuracy: 92.7674%, Training Loss: 0.1882%\n",
      "Epoch [64/300], Step [195/225], Training Accuracy: 92.7644%, Training Loss: 0.1881%\n",
      "Epoch [64/300], Step [196/225], Training Accuracy: 92.7695%, Training Loss: 0.1878%\n",
      "Epoch [64/300], Step [197/225], Training Accuracy: 92.7982%, Training Loss: 0.1873%\n",
      "Epoch [64/300], Step [198/225], Training Accuracy: 92.8267%, Training Loss: 0.1866%\n",
      "Epoch [64/300], Step [199/225], Training Accuracy: 92.8313%, Training Loss: 0.1866%\n",
      "Epoch [64/300], Step [200/225], Training Accuracy: 92.8281%, Training Loss: 0.1868%\n",
      "Epoch [64/300], Step [201/225], Training Accuracy: 92.8094%, Training Loss: 0.1867%\n",
      "Epoch [64/300], Step [202/225], Training Accuracy: 92.8295%, Training Loss: 0.1864%\n",
      "Epoch [64/300], Step [203/225], Training Accuracy: 92.8648%, Training Loss: 0.1856%\n",
      "Epoch [64/300], Step [204/225], Training Accuracy: 92.8615%, Training Loss: 0.1856%\n",
      "Epoch [64/300], Step [205/225], Training Accuracy: 92.8963%, Training Loss: 0.1850%\n",
      "Epoch [64/300], Step [206/225], Training Accuracy: 92.9157%, Training Loss: 0.1846%\n",
      "Epoch [64/300], Step [207/225], Training Accuracy: 92.9197%, Training Loss: 0.1843%\n",
      "Epoch [64/300], Step [208/225], Training Accuracy: 92.8936%, Training Loss: 0.1846%\n",
      "Epoch [64/300], Step [209/225], Training Accuracy: 92.9052%, Training Loss: 0.1844%\n",
      "Epoch [64/300], Step [210/225], Training Accuracy: 92.9092%, Training Loss: 0.1844%\n",
      "Epoch [64/300], Step [211/225], Training Accuracy: 92.9058%, Training Loss: 0.1844%\n",
      "Epoch [64/300], Step [212/225], Training Accuracy: 92.9172%, Training Loss: 0.1843%\n",
      "Epoch [64/300], Step [213/225], Training Accuracy: 92.8991%, Training Loss: 0.1850%\n",
      "Epoch [64/300], Step [214/225], Training Accuracy: 92.9249%, Training Loss: 0.1847%\n",
      "Epoch [64/300], Step [215/225], Training Accuracy: 92.9433%, Training Loss: 0.1844%\n",
      "Epoch [64/300], Step [216/225], Training Accuracy: 92.9398%, Training Loss: 0.1848%\n",
      "Epoch [64/300], Step [217/225], Training Accuracy: 92.9435%, Training Loss: 0.1847%\n",
      "Epoch [64/300], Step [218/225], Training Accuracy: 92.9472%, Training Loss: 0.1845%\n",
      "Epoch [64/300], Step [219/225], Training Accuracy: 92.9366%, Training Loss: 0.1846%\n",
      "Epoch [64/300], Step [220/225], Training Accuracy: 92.8906%, Training Loss: 0.1853%\n",
      "Epoch [64/300], Step [221/225], Training Accuracy: 92.8945%, Training Loss: 0.1855%\n",
      "Epoch [64/300], Step [222/225], Training Accuracy: 92.9054%, Training Loss: 0.1852%\n",
      "Epoch [64/300], Step [223/225], Training Accuracy: 92.9022%, Training Loss: 0.1852%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/300], Step [224/225], Training Accuracy: 92.8990%, Training Loss: 0.1852%\n",
      "Epoch [64/300], Step [225/225], Training Accuracy: 92.9127%, Training Loss: 0.1848%\n",
      "Epoch [65/300], Step [1/225], Training Accuracy: 92.1875%, Training Loss: 0.1767%\n",
      "Epoch [65/300], Step [2/225], Training Accuracy: 94.5312%, Training Loss: 0.1781%\n",
      "Epoch [65/300], Step [3/225], Training Accuracy: 95.3125%, Training Loss: 0.1588%\n",
      "Epoch [65/300], Step [4/225], Training Accuracy: 94.5312%, Training Loss: 0.1929%\n",
      "Epoch [65/300], Step [5/225], Training Accuracy: 92.8125%, Training Loss: 0.2239%\n",
      "Epoch [65/300], Step [6/225], Training Accuracy: 92.9688%, Training Loss: 0.2137%\n",
      "Epoch [65/300], Step [7/225], Training Accuracy: 92.8571%, Training Loss: 0.2062%\n",
      "Epoch [65/300], Step [8/225], Training Accuracy: 93.3594%, Training Loss: 0.1919%\n",
      "Epoch [65/300], Step [9/225], Training Accuracy: 93.0556%, Training Loss: 0.1990%\n",
      "Epoch [65/300], Step [10/225], Training Accuracy: 92.9688%, Training Loss: 0.1986%\n",
      "Epoch [65/300], Step [11/225], Training Accuracy: 92.6136%, Training Loss: 0.2003%\n",
      "Epoch [65/300], Step [12/225], Training Accuracy: 92.7083%, Training Loss: 0.1966%\n",
      "Epoch [65/300], Step [13/225], Training Accuracy: 93.1490%, Training Loss: 0.1853%\n",
      "Epoch [65/300], Step [14/225], Training Accuracy: 93.5268%, Training Loss: 0.1777%\n",
      "Epoch [65/300], Step [15/225], Training Accuracy: 93.0208%, Training Loss: 0.1831%\n",
      "Epoch [65/300], Step [16/225], Training Accuracy: 92.9688%, Training Loss: 0.1830%\n",
      "Epoch [65/300], Step [17/225], Training Accuracy: 93.1985%, Training Loss: 0.1817%\n",
      "Epoch [65/300], Step [18/225], Training Accuracy: 93.0556%, Training Loss: 0.1824%\n",
      "Epoch [65/300], Step [19/225], Training Accuracy: 93.0921%, Training Loss: 0.1825%\n",
      "Epoch [65/300], Step [20/225], Training Accuracy: 92.9688%, Training Loss: 0.1821%\n",
      "Epoch [65/300], Step [21/225], Training Accuracy: 93.0804%, Training Loss: 0.1772%\n",
      "Epoch [65/300], Step [22/225], Training Accuracy: 93.1108%, Training Loss: 0.1778%\n",
      "Epoch [65/300], Step [23/225], Training Accuracy: 93.2745%, Training Loss: 0.1753%\n",
      "Epoch [65/300], Step [24/225], Training Accuracy: 93.0990%, Training Loss: 0.1780%\n",
      "Epoch [65/300], Step [25/225], Training Accuracy: 93.0625%, Training Loss: 0.1796%\n",
      "Epoch [65/300], Step [26/225], Training Accuracy: 92.7885%, Training Loss: 0.1843%\n",
      "Epoch [65/300], Step [27/225], Training Accuracy: 92.6505%, Training Loss: 0.1827%\n",
      "Epoch [65/300], Step [28/225], Training Accuracy: 92.7455%, Training Loss: 0.1816%\n",
      "Epoch [65/300], Step [29/225], Training Accuracy: 92.7263%, Training Loss: 0.1830%\n",
      "Epoch [65/300], Step [30/225], Training Accuracy: 92.8646%, Training Loss: 0.1801%\n",
      "Epoch [65/300], Step [31/225], Training Accuracy: 92.6915%, Training Loss: 0.1856%\n",
      "Epoch [65/300], Step [32/225], Training Accuracy: 92.8711%, Training Loss: 0.1818%\n",
      "Epoch [65/300], Step [33/225], Training Accuracy: 92.8977%, Training Loss: 0.1829%\n",
      "Epoch [65/300], Step [34/225], Training Accuracy: 92.9688%, Training Loss: 0.1812%\n",
      "Epoch [65/300], Step [35/225], Training Accuracy: 93.0357%, Training Loss: 0.1788%\n",
      "Epoch [65/300], Step [36/225], Training Accuracy: 93.0556%, Training Loss: 0.1775%\n",
      "Epoch [65/300], Step [37/225], Training Accuracy: 93.1166%, Training Loss: 0.1773%\n",
      "Epoch [65/300], Step [38/225], Training Accuracy: 93.1332%, Training Loss: 0.1782%\n",
      "Epoch [65/300], Step [39/225], Training Accuracy: 93.2292%, Training Loss: 0.1772%\n",
      "Epoch [65/300], Step [40/225], Training Accuracy: 93.2422%, Training Loss: 0.1767%\n",
      "Epoch [65/300], Step [41/225], Training Accuracy: 93.1784%, Training Loss: 0.1780%\n",
      "Epoch [65/300], Step [42/225], Training Accuracy: 93.1920%, Training Loss: 0.1781%\n",
      "Epoch [65/300], Step [43/225], Training Accuracy: 93.0959%, Training Loss: 0.1781%\n",
      "Epoch [65/300], Step [44/225], Training Accuracy: 93.1108%, Training Loss: 0.1778%\n",
      "Epoch [65/300], Step [45/225], Training Accuracy: 93.2292%, Training Loss: 0.1765%\n",
      "Epoch [65/300], Step [46/225], Training Accuracy: 93.2405%, Training Loss: 0.1749%\n",
      "Epoch [65/300], Step [47/225], Training Accuracy: 93.2846%, Training Loss: 0.1748%\n",
      "Epoch [65/300], Step [48/225], Training Accuracy: 93.1966%, Training Loss: 0.1766%\n",
      "Epoch [65/300], Step [49/225], Training Accuracy: 93.2398%, Training Loss: 0.1750%\n",
      "Epoch [65/300], Step [50/225], Training Accuracy: 93.3750%, Training Loss: 0.1729%\n",
      "Epoch [65/300], Step [51/225], Training Accuracy: 93.3517%, Training Loss: 0.1731%\n",
      "Epoch [65/300], Step [52/225], Training Accuracy: 93.4495%, Training Loss: 0.1715%\n",
      "Epoch [65/300], Step [53/225], Training Accuracy: 93.3962%, Training Loss: 0.1717%\n",
      "Epoch [65/300], Step [54/225], Training Accuracy: 93.3738%, Training Loss: 0.1716%\n",
      "Epoch [65/300], Step [55/225], Training Accuracy: 93.4375%, Training Loss: 0.1707%\n",
      "Epoch [65/300], Step [56/225], Training Accuracy: 93.5268%, Training Loss: 0.1691%\n",
      "Epoch [65/300], Step [57/225], Training Accuracy: 93.3936%, Training Loss: 0.1704%\n",
      "Epoch [65/300], Step [58/225], Training Accuracy: 93.3998%, Training Loss: 0.1705%\n",
      "Epoch [65/300], Step [59/225], Training Accuracy: 93.3528%, Training Loss: 0.1711%\n",
      "Epoch [65/300], Step [60/225], Training Accuracy: 93.3594%, Training Loss: 0.1711%\n",
      "Epoch [65/300], Step [61/225], Training Accuracy: 93.4170%, Training Loss: 0.1709%\n",
      "Epoch [65/300], Step [62/225], Training Accuracy: 93.4224%, Training Loss: 0.1704%\n",
      "Epoch [65/300], Step [63/225], Training Accuracy: 93.4276%, Training Loss: 0.1707%\n",
      "Epoch [65/300], Step [64/225], Training Accuracy: 93.4814%, Training Loss: 0.1694%\n",
      "Epoch [65/300], Step [65/225], Training Accuracy: 93.4615%, Training Loss: 0.1687%\n",
      "Epoch [65/300], Step [66/225], Training Accuracy: 93.3949%, Training Loss: 0.1698%\n",
      "Epoch [65/300], Step [67/225], Training Accuracy: 93.3302%, Training Loss: 0.1711%\n",
      "Epoch [65/300], Step [68/225], Training Accuracy: 93.3134%, Training Loss: 0.1711%\n",
      "Epoch [65/300], Step [69/225], Training Accuracy: 93.2518%, Training Loss: 0.1728%\n",
      "Epoch [65/300], Step [70/225], Training Accuracy: 93.2812%, Training Loss: 0.1721%\n",
      "Epoch [65/300], Step [71/225], Training Accuracy: 93.2218%, Training Loss: 0.1728%\n",
      "Epoch [65/300], Step [72/225], Training Accuracy: 93.1424%, Training Loss: 0.1741%\n",
      "Epoch [65/300], Step [73/225], Training Accuracy: 93.1293%, Training Loss: 0.1738%\n",
      "Epoch [65/300], Step [74/225], Training Accuracy: 93.0954%, Training Loss: 0.1742%\n",
      "Epoch [65/300], Step [75/225], Training Accuracy: 93.0208%, Training Loss: 0.1751%\n",
      "Epoch [65/300], Step [76/225], Training Accuracy: 93.0099%, Training Loss: 0.1762%\n",
      "Epoch [65/300], Step [77/225], Training Accuracy: 93.0398%, Training Loss: 0.1756%\n",
      "Epoch [65/300], Step [78/225], Training Accuracy: 93.0689%, Training Loss: 0.1756%\n",
      "Epoch [65/300], Step [79/225], Training Accuracy: 93.0973%, Training Loss: 0.1749%\n",
      "Epoch [65/300], Step [80/225], Training Accuracy: 93.1055%, Training Loss: 0.1751%\n",
      "Epoch [65/300], Step [81/225], Training Accuracy: 93.0941%, Training Loss: 0.1750%\n",
      "Epoch [65/300], Step [82/225], Training Accuracy: 93.1593%, Training Loss: 0.1738%\n",
      "Epoch [65/300], Step [83/225], Training Accuracy: 93.1288%, Training Loss: 0.1745%\n",
      "Epoch [65/300], Step [84/225], Training Accuracy: 93.1734%, Training Loss: 0.1735%\n",
      "Epoch [65/300], Step [85/225], Training Accuracy: 93.1434%, Training Loss: 0.1734%\n",
      "Epoch [65/300], Step [86/225], Training Accuracy: 93.1504%, Training Loss: 0.1739%\n",
      "Epoch [65/300], Step [87/225], Training Accuracy: 93.2112%, Training Loss: 0.1730%\n",
      "Epoch [65/300], Step [88/225], Training Accuracy: 93.2173%, Training Loss: 0.1738%\n",
      "Epoch [65/300], Step [89/225], Training Accuracy: 93.1531%, Training Loss: 0.1752%\n",
      "Epoch [65/300], Step [90/225], Training Accuracy: 93.1250%, Training Loss: 0.1758%\n",
      "Epoch [65/300], Step [91/225], Training Accuracy: 93.1490%, Training Loss: 0.1751%\n",
      "Epoch [65/300], Step [92/225], Training Accuracy: 93.0197%, Training Loss: 0.1786%\n",
      "Epoch [65/300], Step [93/225], Training Accuracy: 93.0276%, Training Loss: 0.1781%\n",
      "Epoch [65/300], Step [94/225], Training Accuracy: 93.0186%, Training Loss: 0.1784%\n",
      "Epoch [65/300], Step [95/225], Training Accuracy: 93.0428%, Training Loss: 0.1781%\n",
      "Epoch [65/300], Step [96/225], Training Accuracy: 93.0501%, Training Loss: 0.1778%\n",
      "Epoch [65/300], Step [97/225], Training Accuracy: 93.0735%, Training Loss: 0.1776%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/300], Step [98/225], Training Accuracy: 93.0325%, Training Loss: 0.1780%\n",
      "Epoch [65/300], Step [99/225], Training Accuracy: 93.0398%, Training Loss: 0.1778%\n",
      "Epoch [65/300], Step [100/225], Training Accuracy: 93.0000%, Training Loss: 0.1784%\n",
      "Epoch [65/300], Step [101/225], Training Accuracy: 92.9920%, Training Loss: 0.1783%\n",
      "Epoch [65/300], Step [102/225], Training Accuracy: 92.9534%, Training Loss: 0.1796%\n",
      "Epoch [65/300], Step [103/225], Training Accuracy: 92.8701%, Training Loss: 0.1819%\n",
      "Epoch [65/300], Step [104/225], Training Accuracy: 92.8185%, Training Loss: 0.1835%\n",
      "Epoch [65/300], Step [105/225], Training Accuracy: 92.8720%, Training Loss: 0.1827%\n",
      "Epoch [65/300], Step [106/225], Training Accuracy: 92.8656%, Training Loss: 0.1828%\n",
      "Epoch [65/300], Step [107/225], Training Accuracy: 92.8884%, Training Loss: 0.1823%\n",
      "Epoch [65/300], Step [108/225], Training Accuracy: 92.9543%, Training Loss: 0.1816%\n",
      "Epoch [65/300], Step [109/225], Training Accuracy: 92.9616%, Training Loss: 0.1814%\n",
      "Epoch [65/300], Step [110/225], Training Accuracy: 92.9119%, Training Loss: 0.1818%\n",
      "Epoch [65/300], Step [111/225], Training Accuracy: 92.8632%, Training Loss: 0.1823%\n",
      "Epoch [65/300], Step [112/225], Training Accuracy: 92.8153%, Training Loss: 0.1826%\n",
      "Epoch [65/300], Step [113/225], Training Accuracy: 92.7821%, Training Loss: 0.1835%\n",
      "Epoch [65/300], Step [114/225], Training Accuracy: 92.8043%, Training Loss: 0.1830%\n",
      "Epoch [65/300], Step [115/225], Training Accuracy: 92.8397%, Training Loss: 0.1824%\n",
      "Epoch [65/300], Step [116/225], Training Accuracy: 92.8341%, Training Loss: 0.1832%\n",
      "Epoch [65/300], Step [117/225], Training Accuracy: 92.8285%, Training Loss: 0.1830%\n",
      "Epoch [65/300], Step [118/225], Training Accuracy: 92.8496%, Training Loss: 0.1825%\n",
      "Epoch [65/300], Step [119/225], Training Accuracy: 92.8440%, Training Loss: 0.1824%\n",
      "Epoch [65/300], Step [120/225], Training Accuracy: 92.8516%, Training Loss: 0.1821%\n",
      "Epoch [65/300], Step [121/225], Training Accuracy: 92.8848%, Training Loss: 0.1817%\n",
      "Epoch [65/300], Step [122/225], Training Accuracy: 92.8535%, Training Loss: 0.1820%\n",
      "Epoch [65/300], Step [123/225], Training Accuracy: 92.8608%, Training Loss: 0.1822%\n",
      "Epoch [65/300], Step [124/225], Training Accuracy: 92.8931%, Training Loss: 0.1816%\n",
      "Epoch [65/300], Step [125/225], Training Accuracy: 92.8625%, Training Loss: 0.1815%\n",
      "Epoch [65/300], Step [126/225], Training Accuracy: 92.8447%, Training Loss: 0.1817%\n",
      "Epoch [65/300], Step [127/225], Training Accuracy: 92.8642%, Training Loss: 0.1811%\n",
      "Epoch [65/300], Step [128/225], Training Accuracy: 92.8833%, Training Loss: 0.1805%\n",
      "Epoch [65/300], Step [129/225], Training Accuracy: 92.8900%, Training Loss: 0.1806%\n",
      "Epoch [65/300], Step [130/225], Training Accuracy: 92.9207%, Training Loss: 0.1800%\n",
      "Epoch [65/300], Step [131/225], Training Accuracy: 92.9270%, Training Loss: 0.1801%\n",
      "Epoch [65/300], Step [132/225], Training Accuracy: 92.9688%, Training Loss: 0.1795%\n",
      "Epoch [65/300], Step [133/225], Training Accuracy: 92.9981%, Training Loss: 0.1792%\n",
      "Epoch [65/300], Step [134/225], Training Accuracy: 93.0504%, Training Loss: 0.1786%\n",
      "Epoch [65/300], Step [135/225], Training Accuracy: 93.0440%, Training Loss: 0.1783%\n",
      "Epoch [65/300], Step [136/225], Training Accuracy: 93.0262%, Training Loss: 0.1789%\n",
      "Epoch [65/300], Step [137/225], Training Accuracy: 93.0315%, Training Loss: 0.1786%\n",
      "Epoch [65/300], Step [138/225], Training Accuracy: 93.0367%, Training Loss: 0.1784%\n",
      "Epoch [65/300], Step [139/225], Training Accuracy: 93.0643%, Training Loss: 0.1782%\n",
      "Epoch [65/300], Step [140/225], Training Accuracy: 93.0804%, Training Loss: 0.1781%\n",
      "Epoch [65/300], Step [141/225], Training Accuracy: 93.0851%, Training Loss: 0.1779%\n",
      "Epoch [65/300], Step [142/225], Training Accuracy: 93.0898%, Training Loss: 0.1776%\n",
      "Epoch [65/300], Step [143/225], Training Accuracy: 93.1053%, Training Loss: 0.1777%\n",
      "Epoch [65/300], Step [144/225], Training Accuracy: 93.1532%, Training Loss: 0.1769%\n",
      "Epoch [65/300], Step [145/225], Training Accuracy: 93.1466%, Training Loss: 0.1772%\n",
      "Epoch [65/300], Step [146/225], Training Accuracy: 93.1400%, Training Loss: 0.1777%\n",
      "Epoch [65/300], Step [147/225], Training Accuracy: 93.1441%, Training Loss: 0.1776%\n",
      "Epoch [65/300], Step [148/225], Training Accuracy: 93.1166%, Training Loss: 0.1784%\n",
      "Epoch [65/300], Step [149/225], Training Accuracy: 93.1103%, Training Loss: 0.1788%\n",
      "Epoch [65/300], Step [150/225], Training Accuracy: 93.1458%, Training Loss: 0.1783%\n",
      "Epoch [65/300], Step [151/225], Training Accuracy: 93.1602%, Training Loss: 0.1780%\n",
      "Epoch [65/300], Step [152/225], Training Accuracy: 93.1538%, Training Loss: 0.1783%\n",
      "Epoch [65/300], Step [153/225], Training Accuracy: 93.1475%, Training Loss: 0.1782%\n",
      "Epoch [65/300], Step [154/225], Training Accuracy: 93.1615%, Training Loss: 0.1777%\n",
      "Epoch [65/300], Step [155/225], Training Accuracy: 93.1552%, Training Loss: 0.1777%\n",
      "Epoch [65/300], Step [156/225], Training Accuracy: 93.1490%, Training Loss: 0.1779%\n",
      "Epoch [65/300], Step [157/225], Training Accuracy: 93.1330%, Training Loss: 0.1781%\n",
      "Epoch [65/300], Step [158/225], Training Accuracy: 93.1566%, Training Loss: 0.1776%\n",
      "Epoch [65/300], Step [159/225], Training Accuracy: 93.1800%, Training Loss: 0.1773%\n",
      "Epoch [65/300], Step [160/225], Training Accuracy: 93.2031%, Training Loss: 0.1769%\n",
      "Epoch [65/300], Step [161/225], Training Accuracy: 93.1677%, Training Loss: 0.1778%\n",
      "Epoch [65/300], Step [162/225], Training Accuracy: 93.1327%, Training Loss: 0.1786%\n",
      "Epoch [65/300], Step [163/225], Training Accuracy: 93.0982%, Training Loss: 0.1788%\n",
      "Epoch [65/300], Step [164/225], Training Accuracy: 93.1117%, Training Loss: 0.1784%\n",
      "Epoch [65/300], Step [165/225], Training Accuracy: 93.0871%, Training Loss: 0.1786%\n",
      "Epoch [65/300], Step [166/225], Training Accuracy: 93.0911%, Training Loss: 0.1785%\n",
      "Epoch [65/300], Step [167/225], Training Accuracy: 93.0951%, Training Loss: 0.1782%\n",
      "Epoch [65/300], Step [168/225], Training Accuracy: 93.0990%, Training Loss: 0.1783%\n",
      "Epoch [65/300], Step [169/225], Training Accuracy: 93.1028%, Training Loss: 0.1781%\n",
      "Epoch [65/300], Step [170/225], Training Accuracy: 93.1158%, Training Loss: 0.1781%\n",
      "Epoch [65/300], Step [171/225], Training Accuracy: 93.1104%, Training Loss: 0.1782%\n",
      "Epoch [65/300], Step [172/225], Training Accuracy: 93.1141%, Training Loss: 0.1778%\n",
      "Epoch [65/300], Step [173/225], Training Accuracy: 93.1178%, Training Loss: 0.1780%\n",
      "Epoch [65/300], Step [174/225], Training Accuracy: 93.1483%, Training Loss: 0.1775%\n",
      "Epoch [65/300], Step [175/225], Training Accuracy: 93.1518%, Training Loss: 0.1774%\n",
      "Epoch [65/300], Step [176/225], Training Accuracy: 93.1818%, Training Loss: 0.1768%\n",
      "Epoch [65/300], Step [177/225], Training Accuracy: 93.1850%, Training Loss: 0.1765%\n",
      "Epoch [65/300], Step [178/225], Training Accuracy: 93.1882%, Training Loss: 0.1764%\n",
      "Epoch [65/300], Step [179/225], Training Accuracy: 93.1826%, Training Loss: 0.1763%\n",
      "Epoch [65/300], Step [180/225], Training Accuracy: 93.1771%, Training Loss: 0.1764%\n",
      "Epoch [65/300], Step [181/225], Training Accuracy: 93.1802%, Training Loss: 0.1761%\n",
      "Epoch [65/300], Step [182/225], Training Accuracy: 93.2091%, Training Loss: 0.1757%\n",
      "Epoch [65/300], Step [183/225], Training Accuracy: 93.2121%, Training Loss: 0.1756%\n",
      "Epoch [65/300], Step [184/225], Training Accuracy: 93.2235%, Training Loss: 0.1757%\n",
      "Epoch [65/300], Step [185/225], Training Accuracy: 93.2264%, Training Loss: 0.1756%\n",
      "Epoch [65/300], Step [186/225], Training Accuracy: 93.2208%, Training Loss: 0.1761%\n",
      "Epoch [65/300], Step [187/225], Training Accuracy: 93.2487%, Training Loss: 0.1755%\n",
      "Epoch [65/300], Step [188/225], Training Accuracy: 93.2596%, Training Loss: 0.1753%\n",
      "Epoch [65/300], Step [189/225], Training Accuracy: 93.2457%, Training Loss: 0.1758%\n",
      "Epoch [65/300], Step [190/225], Training Accuracy: 93.2484%, Training Loss: 0.1754%\n",
      "Epoch [65/300], Step [191/225], Training Accuracy: 93.2510%, Training Loss: 0.1753%\n",
      "Epoch [65/300], Step [192/225], Training Accuracy: 93.2536%, Training Loss: 0.1751%\n",
      "Epoch [65/300], Step [193/225], Training Accuracy: 93.2642%, Training Loss: 0.1749%\n",
      "Epoch [65/300], Step [194/225], Training Accuracy: 93.2748%, Training Loss: 0.1746%\n",
      "Epoch [65/300], Step [195/225], Training Accuracy: 93.2933%, Training Loss: 0.1741%\n",
      "Epoch [65/300], Step [196/225], Training Accuracy: 93.3036%, Training Loss: 0.1741%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/300], Step [197/225], Training Accuracy: 93.3058%, Training Loss: 0.1744%\n",
      "Epoch [65/300], Step [198/225], Training Accuracy: 93.3160%, Training Loss: 0.1742%\n",
      "Epoch [65/300], Step [199/225], Training Accuracy: 93.3182%, Training Loss: 0.1741%\n",
      "Epoch [65/300], Step [200/225], Training Accuracy: 93.3047%, Training Loss: 0.1740%\n",
      "Epoch [65/300], Step [201/225], Training Accuracy: 93.2836%, Training Loss: 0.1745%\n",
      "Epoch [65/300], Step [202/225], Training Accuracy: 93.2782%, Training Loss: 0.1745%\n",
      "Epoch [65/300], Step [203/225], Training Accuracy: 93.2959%, Training Loss: 0.1741%\n",
      "Epoch [65/300], Step [204/225], Training Accuracy: 93.2981%, Training Loss: 0.1739%\n",
      "Epoch [65/300], Step [205/225], Training Accuracy: 93.3232%, Training Loss: 0.1733%\n",
      "Epoch [65/300], Step [206/225], Training Accuracy: 93.3177%, Training Loss: 0.1734%\n",
      "Epoch [65/300], Step [207/225], Training Accuracy: 93.2971%, Training Loss: 0.1736%\n",
      "Epoch [65/300], Step [208/225], Training Accuracy: 93.2918%, Training Loss: 0.1737%\n",
      "Epoch [65/300], Step [209/225], Training Accuracy: 93.3014%, Training Loss: 0.1738%\n",
      "Epoch [65/300], Step [210/225], Training Accuracy: 93.3036%, Training Loss: 0.1735%\n",
      "Epoch [65/300], Step [211/225], Training Accuracy: 93.3131%, Training Loss: 0.1731%\n",
      "Epoch [65/300], Step [212/225], Training Accuracy: 93.2857%, Training Loss: 0.1738%\n",
      "Epoch [65/300], Step [213/225], Training Accuracy: 93.2805%, Training Loss: 0.1739%\n",
      "Epoch [65/300], Step [214/225], Training Accuracy: 93.2900%, Training Loss: 0.1738%\n",
      "Epoch [65/300], Step [215/225], Training Accuracy: 93.2922%, Training Loss: 0.1735%\n",
      "Epoch [65/300], Step [216/225], Training Accuracy: 93.2870%, Training Loss: 0.1738%\n",
      "Epoch [65/300], Step [217/225], Training Accuracy: 93.2892%, Training Loss: 0.1737%\n",
      "Epoch [65/300], Step [218/225], Training Accuracy: 93.3056%, Training Loss: 0.1735%\n",
      "Epoch [65/300], Step [219/225], Training Accuracy: 93.3076%, Training Loss: 0.1733%\n",
      "Epoch [65/300], Step [220/225], Training Accuracy: 93.2955%, Training Loss: 0.1735%\n",
      "Epoch [65/300], Step [221/225], Training Accuracy: 93.2904%, Training Loss: 0.1739%\n",
      "Epoch [65/300], Step [222/225], Training Accuracy: 93.2714%, Training Loss: 0.1742%\n",
      "Epoch [65/300], Step [223/225], Training Accuracy: 93.2665%, Training Loss: 0.1743%\n",
      "Epoch [65/300], Step [224/225], Training Accuracy: 93.2687%, Training Loss: 0.1740%\n",
      "Epoch [65/300], Step [225/225], Training Accuracy: 93.2532%, Training Loss: 0.1740%\n",
      "Epoch [66/300], Step [1/225], Training Accuracy: 92.1875%, Training Loss: 0.2133%\n",
      "Epoch [66/300], Step [2/225], Training Accuracy: 90.6250%, Training Loss: 0.2140%\n",
      "Epoch [66/300], Step [3/225], Training Accuracy: 91.1458%, Training Loss: 0.1957%\n",
      "Epoch [66/300], Step [4/225], Training Accuracy: 91.4062%, Training Loss: 0.2011%\n",
      "Epoch [66/300], Step [5/225], Training Accuracy: 92.8125%, Training Loss: 0.1816%\n",
      "Epoch [66/300], Step [6/225], Training Accuracy: 92.9688%, Training Loss: 0.1731%\n",
      "Epoch [66/300], Step [7/225], Training Accuracy: 92.6339%, Training Loss: 0.1772%\n",
      "Epoch [66/300], Step [8/225], Training Accuracy: 92.3828%, Training Loss: 0.1840%\n",
      "Epoch [66/300], Step [9/225], Training Accuracy: 92.3611%, Training Loss: 0.1865%\n",
      "Epoch [66/300], Step [10/225], Training Accuracy: 92.5000%, Training Loss: 0.1890%\n",
      "Epoch [66/300], Step [11/225], Training Accuracy: 92.6136%, Training Loss: 0.1864%\n",
      "Epoch [66/300], Step [12/225], Training Accuracy: 92.9688%, Training Loss: 0.1834%\n",
      "Epoch [66/300], Step [13/225], Training Accuracy: 93.1490%, Training Loss: 0.1841%\n",
      "Epoch [66/300], Step [14/225], Training Accuracy: 93.1920%, Training Loss: 0.1819%\n",
      "Epoch [66/300], Step [15/225], Training Accuracy: 93.3333%, Training Loss: 0.1790%\n",
      "Epoch [66/300], Step [16/225], Training Accuracy: 93.2617%, Training Loss: 0.1823%\n",
      "Epoch [66/300], Step [17/225], Training Accuracy: 93.6581%, Training Loss: 0.1747%\n",
      "Epoch [66/300], Step [18/225], Training Accuracy: 93.9236%, Training Loss: 0.1694%\n",
      "Epoch [66/300], Step [19/225], Training Accuracy: 93.8322%, Training Loss: 0.1716%\n",
      "Epoch [66/300], Step [20/225], Training Accuracy: 94.0625%, Training Loss: 0.1668%\n",
      "Epoch [66/300], Step [21/225], Training Accuracy: 94.0476%, Training Loss: 0.1662%\n",
      "Epoch [66/300], Step [22/225], Training Accuracy: 93.8920%, Training Loss: 0.1695%\n",
      "Epoch [66/300], Step [23/225], Training Accuracy: 93.7500%, Training Loss: 0.1748%\n",
      "Epoch [66/300], Step [24/225], Training Accuracy: 93.6849%, Training Loss: 0.1747%\n",
      "Epoch [66/300], Step [25/225], Training Accuracy: 93.7500%, Training Loss: 0.1727%\n",
      "Epoch [66/300], Step [26/225], Training Accuracy: 93.9303%, Training Loss: 0.1689%\n",
      "Epoch [66/300], Step [27/225], Training Accuracy: 94.0394%, Training Loss: 0.1669%\n",
      "Epoch [66/300], Step [28/225], Training Accuracy: 94.1964%, Training Loss: 0.1634%\n",
      "Epoch [66/300], Step [29/225], Training Accuracy: 94.1272%, Training Loss: 0.1666%\n",
      "Epoch [66/300], Step [30/225], Training Accuracy: 94.2188%, Training Loss: 0.1662%\n",
      "Epoch [66/300], Step [31/225], Training Accuracy: 94.1532%, Training Loss: 0.1675%\n",
      "Epoch [66/300], Step [32/225], Training Accuracy: 94.2871%, Training Loss: 0.1645%\n",
      "Epoch [66/300], Step [33/225], Training Accuracy: 94.2708%, Training Loss: 0.1652%\n",
      "Epoch [66/300], Step [34/225], Training Accuracy: 94.0717%, Training Loss: 0.1679%\n",
      "Epoch [66/300], Step [35/225], Training Accuracy: 94.1071%, Training Loss: 0.1686%\n",
      "Epoch [66/300], Step [36/225], Training Accuracy: 94.1406%, Training Loss: 0.1678%\n",
      "Epoch [66/300], Step [37/225], Training Accuracy: 94.1301%, Training Loss: 0.1663%\n",
      "Epoch [66/300], Step [38/225], Training Accuracy: 93.9145%, Training Loss: 0.1704%\n",
      "Epoch [66/300], Step [39/225], Training Accuracy: 93.9904%, Training Loss: 0.1694%\n",
      "Epoch [66/300], Step [40/225], Training Accuracy: 94.0234%, Training Loss: 0.1682%\n",
      "Epoch [66/300], Step [41/225], Training Accuracy: 94.0168%, Training Loss: 0.1685%\n",
      "Epoch [66/300], Step [42/225], Training Accuracy: 93.9360%, Training Loss: 0.1693%\n",
      "Epoch [66/300], Step [43/225], Training Accuracy: 93.9680%, Training Loss: 0.1696%\n",
      "Epoch [66/300], Step [44/225], Training Accuracy: 93.9986%, Training Loss: 0.1700%\n",
      "Epoch [66/300], Step [45/225], Training Accuracy: 94.0278%, Training Loss: 0.1695%\n",
      "Epoch [66/300], Step [46/225], Training Accuracy: 94.0217%, Training Loss: 0.1698%\n",
      "Epoch [66/300], Step [47/225], Training Accuracy: 93.9495%, Training Loss: 0.1720%\n",
      "Epoch [66/300], Step [48/225], Training Accuracy: 93.9453%, Training Loss: 0.1717%\n",
      "Epoch [66/300], Step [49/225], Training Accuracy: 93.9413%, Training Loss: 0.1709%\n",
      "Epoch [66/300], Step [50/225], Training Accuracy: 93.8750%, Training Loss: 0.1732%\n",
      "Epoch [66/300], Step [51/225], Training Accuracy: 93.8419%, Training Loss: 0.1731%\n",
      "Epoch [66/300], Step [52/225], Training Accuracy: 93.8702%, Training Loss: 0.1757%\n",
      "Epoch [66/300], Step [53/225], Training Accuracy: 93.8384%, Training Loss: 0.1752%\n",
      "Epoch [66/300], Step [54/225], Training Accuracy: 93.8657%, Training Loss: 0.1740%\n",
      "Epoch [66/300], Step [55/225], Training Accuracy: 93.8920%, Training Loss: 0.1742%\n",
      "Epoch [66/300], Step [56/225], Training Accuracy: 93.8895%, Training Loss: 0.1727%\n",
      "Epoch [66/300], Step [57/225], Training Accuracy: 93.8322%, Training Loss: 0.1736%\n",
      "Epoch [66/300], Step [58/225], Training Accuracy: 93.8039%, Training Loss: 0.1736%\n",
      "Epoch [66/300], Step [59/225], Training Accuracy: 93.8030%, Training Loss: 0.1731%\n",
      "Epoch [66/300], Step [60/225], Training Accuracy: 93.8021%, Training Loss: 0.1727%\n",
      "Epoch [66/300], Step [61/225], Training Accuracy: 93.8268%, Training Loss: 0.1717%\n",
      "Epoch [66/300], Step [62/225], Training Accuracy: 93.8760%, Training Loss: 0.1707%\n",
      "Epoch [66/300], Step [63/225], Training Accuracy: 93.9236%, Training Loss: 0.1696%\n",
      "Epoch [66/300], Step [64/225], Training Accuracy: 93.9209%, Training Loss: 0.1699%\n",
      "Epoch [66/300], Step [65/225], Training Accuracy: 93.8942%, Training Loss: 0.1691%\n",
      "Epoch [66/300], Step [66/225], Training Accuracy: 93.9631%, Training Loss: 0.1675%\n",
      "Epoch [66/300], Step [67/225], Training Accuracy: 94.0065%, Training Loss: 0.1669%\n",
      "Epoch [66/300], Step [68/225], Training Accuracy: 94.0028%, Training Loss: 0.1667%\n",
      "Epoch [66/300], Step [69/225], Training Accuracy: 93.9312%, Training Loss: 0.1671%\n",
      "Epoch [66/300], Step [70/225], Training Accuracy: 93.9062%, Training Loss: 0.1673%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/300], Step [71/225], Training Accuracy: 93.8820%, Training Loss: 0.1684%\n",
      "Epoch [66/300], Step [72/225], Training Accuracy: 93.7717%, Training Loss: 0.1708%\n",
      "Epoch [66/300], Step [73/225], Training Accuracy: 93.7286%, Training Loss: 0.1709%\n",
      "Epoch [66/300], Step [74/225], Training Accuracy: 93.7078%, Training Loss: 0.1708%\n",
      "Epoch [66/300], Step [75/225], Training Accuracy: 93.7500%, Training Loss: 0.1699%\n",
      "Epoch [66/300], Step [76/225], Training Accuracy: 93.7706%, Training Loss: 0.1701%\n",
      "Epoch [66/300], Step [77/225], Training Accuracy: 93.7297%, Training Loss: 0.1709%\n",
      "Epoch [66/300], Step [78/225], Training Accuracy: 93.6699%, Training Loss: 0.1719%\n",
      "Epoch [66/300], Step [79/225], Training Accuracy: 93.7302%, Training Loss: 0.1705%\n",
      "Epoch [66/300], Step [80/225], Training Accuracy: 93.6719%, Training Loss: 0.1713%\n",
      "Epoch [66/300], Step [81/225], Training Accuracy: 93.6535%, Training Loss: 0.1710%\n",
      "Epoch [66/300], Step [82/225], Training Accuracy: 93.6738%, Training Loss: 0.1703%\n",
      "Epoch [66/300], Step [83/225], Training Accuracy: 93.6182%, Training Loss: 0.1706%\n",
      "Epoch [66/300], Step [84/225], Training Accuracy: 93.6012%, Training Loss: 0.1702%\n",
      "Epoch [66/300], Step [85/225], Training Accuracy: 93.6397%, Training Loss: 0.1696%\n",
      "Epoch [66/300], Step [86/225], Training Accuracy: 93.6955%, Training Loss: 0.1687%\n",
      "Epoch [66/300], Step [87/225], Training Accuracy: 93.6961%, Training Loss: 0.1683%\n",
      "Epoch [66/300], Step [88/225], Training Accuracy: 93.6967%, Training Loss: 0.1687%\n",
      "Epoch [66/300], Step [89/225], Training Accuracy: 93.6798%, Training Loss: 0.1692%\n",
      "Epoch [66/300], Step [90/225], Training Accuracy: 93.6458%, Training Loss: 0.1699%\n",
      "Epoch [66/300], Step [91/225], Training Accuracy: 93.6641%, Training Loss: 0.1696%\n",
      "Epoch [66/300], Step [92/225], Training Accuracy: 93.6311%, Training Loss: 0.1708%\n",
      "Epoch [66/300], Step [93/225], Training Accuracy: 93.6492%, Training Loss: 0.1700%\n",
      "Epoch [66/300], Step [94/225], Training Accuracy: 93.5505%, Training Loss: 0.1726%\n",
      "Epoch [66/300], Step [95/225], Training Accuracy: 93.5362%, Training Loss: 0.1726%\n",
      "Epoch [66/300], Step [96/225], Training Accuracy: 93.5059%, Training Loss: 0.1727%\n",
      "Epoch [66/300], Step [97/225], Training Accuracy: 93.4117%, Training Loss: 0.1741%\n",
      "Epoch [66/300], Step [98/225], Training Accuracy: 93.3992%, Training Loss: 0.1740%\n",
      "Epoch [66/300], Step [99/225], Training Accuracy: 93.3870%, Training Loss: 0.1747%\n",
      "Epoch [66/300], Step [100/225], Training Accuracy: 93.4375%, Training Loss: 0.1747%\n",
      "Epoch [66/300], Step [101/225], Training Accuracy: 93.4406%, Training Loss: 0.1746%\n",
      "Epoch [66/300], Step [102/225], Training Accuracy: 93.3670%, Training Loss: 0.1754%\n",
      "Epoch [66/300], Step [103/225], Training Accuracy: 93.3708%, Training Loss: 0.1752%\n",
      "Epoch [66/300], Step [104/225], Training Accuracy: 93.4195%, Training Loss: 0.1742%\n",
      "Epoch [66/300], Step [105/225], Training Accuracy: 93.4226%, Training Loss: 0.1743%\n",
      "Epoch [66/300], Step [106/225], Training Accuracy: 93.3962%, Training Loss: 0.1744%\n",
      "Epoch [66/300], Step [107/225], Training Accuracy: 93.3557%, Training Loss: 0.1749%\n",
      "Epoch [66/300], Step [108/225], Training Accuracy: 93.3304%, Training Loss: 0.1762%\n",
      "Epoch [66/300], Step [109/225], Training Accuracy: 93.3056%, Training Loss: 0.1765%\n",
      "Epoch [66/300], Step [110/225], Training Accuracy: 93.3097%, Training Loss: 0.1766%\n",
      "Epoch [66/300], Step [111/225], Training Accuracy: 93.2855%, Training Loss: 0.1763%\n",
      "Epoch [66/300], Step [112/225], Training Accuracy: 93.2617%, Training Loss: 0.1760%\n",
      "Epoch [66/300], Step [113/225], Training Accuracy: 93.3075%, Training Loss: 0.1752%\n",
      "Epoch [66/300], Step [114/225], Training Accuracy: 93.2977%, Training Loss: 0.1756%\n",
      "Epoch [66/300], Step [115/225], Training Accuracy: 93.2880%, Training Loss: 0.1761%\n",
      "Epoch [66/300], Step [116/225], Training Accuracy: 93.3055%, Training Loss: 0.1759%\n",
      "Epoch [66/300], Step [117/225], Training Accuracy: 93.3226%, Training Loss: 0.1759%\n",
      "Epoch [66/300], Step [118/225], Training Accuracy: 93.3395%, Training Loss: 0.1753%\n",
      "Epoch [66/300], Step [119/225], Training Accuracy: 93.3430%, Training Loss: 0.1752%\n",
      "Epoch [66/300], Step [120/225], Training Accuracy: 93.3594%, Training Loss: 0.1750%\n",
      "Epoch [66/300], Step [121/225], Training Accuracy: 93.3110%, Training Loss: 0.1757%\n",
      "Epoch [66/300], Step [122/225], Training Accuracy: 93.3145%, Training Loss: 0.1756%\n",
      "Epoch [66/300], Step [123/225], Training Accuracy: 93.3054%, Training Loss: 0.1760%\n",
      "Epoch [66/300], Step [124/225], Training Accuracy: 93.3342%, Training Loss: 0.1754%\n",
      "Epoch [66/300], Step [125/225], Training Accuracy: 93.3375%, Training Loss: 0.1753%\n",
      "Epoch [66/300], Step [126/225], Training Accuracy: 93.3036%, Training Loss: 0.1756%\n",
      "Epoch [66/300], Step [127/225], Training Accuracy: 93.3317%, Training Loss: 0.1753%\n",
      "Epoch [66/300], Step [128/225], Training Accuracy: 93.3594%, Training Loss: 0.1748%\n",
      "Epoch [66/300], Step [129/225], Training Accuracy: 93.3261%, Training Loss: 0.1759%\n",
      "Epoch [66/300], Step [130/225], Training Accuracy: 93.3293%, Training Loss: 0.1761%\n",
      "Epoch [66/300], Step [131/225], Training Accuracy: 93.3087%, Training Loss: 0.1771%\n",
      "Epoch [66/300], Step [132/225], Training Accuracy: 93.3120%, Training Loss: 0.1774%\n",
      "Epoch [66/300], Step [133/225], Training Accuracy: 93.2801%, Training Loss: 0.1775%\n",
      "Epoch [66/300], Step [134/225], Training Accuracy: 93.2369%, Training Loss: 0.1781%\n",
      "Epoch [66/300], Step [135/225], Training Accuracy: 93.2176%, Training Loss: 0.1786%\n",
      "Epoch [66/300], Step [136/225], Training Accuracy: 93.1870%, Training Loss: 0.1789%\n",
      "Epoch [66/300], Step [137/225], Training Accuracy: 93.1797%, Training Loss: 0.1792%\n",
      "Epoch [66/300], Step [138/225], Training Accuracy: 93.2178%, Training Loss: 0.1783%\n",
      "Epoch [66/300], Step [139/225], Training Accuracy: 93.1879%, Training Loss: 0.1791%\n",
      "Epoch [66/300], Step [140/225], Training Accuracy: 93.1473%, Training Loss: 0.1804%\n",
      "Epoch [66/300], Step [141/225], Training Accuracy: 93.1738%, Training Loss: 0.1799%\n",
      "Epoch [66/300], Step [142/225], Training Accuracy: 93.1558%, Training Loss: 0.1800%\n",
      "Epoch [66/300], Step [143/225], Training Accuracy: 93.1600%, Training Loss: 0.1796%\n",
      "Epoch [66/300], Step [144/225], Training Accuracy: 93.1641%, Training Loss: 0.1796%\n",
      "Epoch [66/300], Step [145/225], Training Accuracy: 93.1573%, Training Loss: 0.1798%\n",
      "Epoch [66/300], Step [146/225], Training Accuracy: 93.1614%, Training Loss: 0.1796%\n",
      "Epoch [66/300], Step [147/225], Training Accuracy: 93.1441%, Training Loss: 0.1805%\n",
      "Epoch [66/300], Step [148/225], Training Accuracy: 93.1482%, Training Loss: 0.1801%\n",
      "Epoch [66/300], Step [149/225], Training Accuracy: 93.1418%, Training Loss: 0.1801%\n",
      "Epoch [66/300], Step [150/225], Training Accuracy: 93.1771%, Training Loss: 0.1794%\n",
      "Epoch [66/300], Step [151/225], Training Accuracy: 93.1912%, Training Loss: 0.1793%\n",
      "Epoch [66/300], Step [152/225], Training Accuracy: 93.2052%, Training Loss: 0.1791%\n",
      "Epoch [66/300], Step [153/225], Training Accuracy: 93.1883%, Training Loss: 0.1798%\n",
      "Epoch [66/300], Step [154/225], Training Accuracy: 93.2123%, Training Loss: 0.1794%\n",
      "Epoch [66/300], Step [155/225], Training Accuracy: 93.1956%, Training Loss: 0.1801%\n",
      "Epoch [66/300], Step [156/225], Training Accuracy: 93.2091%, Training Loss: 0.1797%\n",
      "Epoch [66/300], Step [157/225], Training Accuracy: 93.1628%, Training Loss: 0.1815%\n",
      "Epoch [66/300], Step [158/225], Training Accuracy: 93.1665%, Training Loss: 0.1814%\n",
      "Epoch [66/300], Step [159/225], Training Accuracy: 93.1407%, Training Loss: 0.1816%\n",
      "Epoch [66/300], Step [160/225], Training Accuracy: 93.1641%, Training Loss: 0.1811%\n",
      "Epoch [66/300], Step [161/225], Training Accuracy: 93.1580%, Training Loss: 0.1810%\n",
      "Epoch [66/300], Step [162/225], Training Accuracy: 93.1809%, Training Loss: 0.1806%\n",
      "Epoch [66/300], Step [163/225], Training Accuracy: 93.1844%, Training Loss: 0.1807%\n",
      "Epoch [66/300], Step [164/225], Training Accuracy: 93.1688%, Training Loss: 0.1814%\n",
      "Epoch [66/300], Step [165/225], Training Accuracy: 93.1723%, Training Loss: 0.1814%\n",
      "Epoch [66/300], Step [166/225], Training Accuracy: 93.1570%, Training Loss: 0.1815%\n",
      "Epoch [66/300], Step [167/225], Training Accuracy: 93.1699%, Training Loss: 0.1810%\n",
      "Epoch [66/300], Step [168/225], Training Accuracy: 93.1734%, Training Loss: 0.1818%\n",
      "Epoch [66/300], Step [169/225], Training Accuracy: 93.1768%, Training Loss: 0.1815%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/300], Step [170/225], Training Accuracy: 93.1618%, Training Loss: 0.1817%\n",
      "Epoch [66/300], Step [171/225], Training Accuracy: 93.1743%, Training Loss: 0.1815%\n",
      "Epoch [66/300], Step [172/225], Training Accuracy: 93.1686%, Training Loss: 0.1817%\n",
      "Epoch [66/300], Step [173/225], Training Accuracy: 93.1629%, Training Loss: 0.1815%\n",
      "Epoch [66/300], Step [174/225], Training Accuracy: 93.1573%, Training Loss: 0.1818%\n",
      "Epoch [66/300], Step [175/225], Training Accuracy: 93.1339%, Training Loss: 0.1819%\n",
      "Epoch [66/300], Step [176/225], Training Accuracy: 93.1374%, Training Loss: 0.1818%\n",
      "Epoch [66/300], Step [177/225], Training Accuracy: 93.1585%, Training Loss: 0.1812%\n",
      "Epoch [66/300], Step [178/225], Training Accuracy: 93.1970%, Training Loss: 0.1807%\n",
      "Epoch [66/300], Step [179/225], Training Accuracy: 93.1652%, Training Loss: 0.1811%\n",
      "Epoch [66/300], Step [180/225], Training Accuracy: 93.1510%, Training Loss: 0.1817%\n",
      "Epoch [66/300], Step [181/225], Training Accuracy: 93.1371%, Training Loss: 0.1814%\n",
      "Epoch [66/300], Step [182/225], Training Accuracy: 93.1490%, Training Loss: 0.1812%\n",
      "Epoch [66/300], Step [183/225], Training Accuracy: 93.1523%, Training Loss: 0.1817%\n",
      "Epoch [66/300], Step [184/225], Training Accuracy: 93.1726%, Training Loss: 0.1813%\n",
      "Epoch [66/300], Step [185/225], Training Accuracy: 93.1841%, Training Loss: 0.1812%\n",
      "Epoch [66/300], Step [186/225], Training Accuracy: 93.2040%, Training Loss: 0.1806%\n",
      "Epoch [66/300], Step [187/225], Training Accuracy: 93.1818%, Training Loss: 0.1810%\n",
      "Epoch [66/300], Step [188/225], Training Accuracy: 93.1765%, Training Loss: 0.1809%\n",
      "Epoch [66/300], Step [189/225], Training Accuracy: 93.1878%, Training Loss: 0.1805%\n",
      "Epoch [66/300], Step [190/225], Training Accuracy: 93.1826%, Training Loss: 0.1806%\n",
      "Epoch [66/300], Step [191/225], Training Accuracy: 93.1774%, Training Loss: 0.1810%\n",
      "Epoch [66/300], Step [192/225], Training Accuracy: 93.1803%, Training Loss: 0.1810%\n",
      "Epoch [66/300], Step [193/225], Training Accuracy: 93.1833%, Training Loss: 0.1808%\n",
      "Epoch [66/300], Step [194/225], Training Accuracy: 93.1862%, Training Loss: 0.1807%\n",
      "Epoch [66/300], Step [195/225], Training Accuracy: 93.1811%, Training Loss: 0.1806%\n",
      "Epoch [66/300], Step [196/225], Training Accuracy: 93.1920%, Training Loss: 0.1805%\n",
      "Epoch [66/300], Step [197/225], Training Accuracy: 93.2027%, Training Loss: 0.1803%\n",
      "Epoch [66/300], Step [198/225], Training Accuracy: 93.2055%, Training Loss: 0.1803%\n",
      "Epoch [66/300], Step [199/225], Training Accuracy: 93.2082%, Training Loss: 0.1802%\n",
      "Epoch [66/300], Step [200/225], Training Accuracy: 93.2266%, Training Loss: 0.1798%\n",
      "Epoch [66/300], Step [201/225], Training Accuracy: 93.2058%, Training Loss: 0.1799%\n",
      "Epoch [66/300], Step [202/225], Training Accuracy: 93.2085%, Training Loss: 0.1799%\n",
      "Epoch [66/300], Step [203/225], Training Accuracy: 93.2266%, Training Loss: 0.1797%\n",
      "Epoch [66/300], Step [204/225], Training Accuracy: 93.2215%, Training Loss: 0.1798%\n",
      "Epoch [66/300], Step [205/225], Training Accuracy: 93.2317%, Training Loss: 0.1797%\n",
      "Epoch [66/300], Step [206/225], Training Accuracy: 93.2115%, Training Loss: 0.1798%\n",
      "Epoch [66/300], Step [207/225], Training Accuracy: 93.2065%, Training Loss: 0.1802%\n",
      "Epoch [66/300], Step [208/225], Training Accuracy: 93.2392%, Training Loss: 0.1796%\n",
      "Epoch [66/300], Step [209/225], Training Accuracy: 93.2491%, Training Loss: 0.1797%\n",
      "Epoch [66/300], Step [210/225], Training Accuracy: 93.2515%, Training Loss: 0.1797%\n",
      "Epoch [66/300], Step [211/225], Training Accuracy: 93.2390%, Training Loss: 0.1799%\n",
      "Epoch [66/300], Step [212/225], Training Accuracy: 93.2562%, Training Loss: 0.1796%\n",
      "Epoch [66/300], Step [213/225], Training Accuracy: 93.2512%, Training Loss: 0.1799%\n",
      "Epoch [66/300], Step [214/225], Training Accuracy: 93.2389%, Training Loss: 0.1799%\n",
      "Epoch [66/300], Step [215/225], Training Accuracy: 93.2485%, Training Loss: 0.1797%\n",
      "Epoch [66/300], Step [216/225], Training Accuracy: 93.2509%, Training Loss: 0.1799%\n",
      "Epoch [66/300], Step [217/225], Training Accuracy: 93.2388%, Training Loss: 0.1802%\n",
      "Epoch [66/300], Step [218/225], Training Accuracy: 93.2483%, Training Loss: 0.1801%\n",
      "Epoch [66/300], Step [219/225], Training Accuracy: 93.2506%, Training Loss: 0.1801%\n",
      "Epoch [66/300], Step [220/225], Training Accuracy: 93.2741%, Training Loss: 0.1798%\n",
      "Epoch [66/300], Step [221/225], Training Accuracy: 93.2904%, Training Loss: 0.1794%\n",
      "Epoch [66/300], Step [222/225], Training Accuracy: 93.2925%, Training Loss: 0.1792%\n",
      "Epoch [66/300], Step [223/225], Training Accuracy: 93.2665%, Training Loss: 0.1796%\n",
      "Epoch [66/300], Step [224/225], Training Accuracy: 93.2896%, Training Loss: 0.1792%\n",
      "Epoch [66/300], Step [225/225], Training Accuracy: 93.3157%, Training Loss: 0.1787%\n",
      "Epoch [67/300], Step [1/225], Training Accuracy: 92.1875%, Training Loss: 0.1694%\n",
      "Epoch [67/300], Step [2/225], Training Accuracy: 94.5312%, Training Loss: 0.1619%\n",
      "Epoch [67/300], Step [3/225], Training Accuracy: 92.7083%, Training Loss: 0.1906%\n",
      "Epoch [67/300], Step [4/225], Training Accuracy: 91.4062%, Training Loss: 0.2048%\n",
      "Epoch [67/300], Step [5/225], Training Accuracy: 91.2500%, Training Loss: 0.2119%\n",
      "Epoch [67/300], Step [6/225], Training Accuracy: 91.4062%, Training Loss: 0.2095%\n",
      "Epoch [67/300], Step [7/225], Training Accuracy: 92.4107%, Training Loss: 0.1912%\n",
      "Epoch [67/300], Step [8/225], Training Accuracy: 92.3828%, Training Loss: 0.1921%\n",
      "Epoch [67/300], Step [9/225], Training Accuracy: 92.5347%, Training Loss: 0.1856%\n",
      "Epoch [67/300], Step [10/225], Training Accuracy: 92.3438%, Training Loss: 0.1875%\n",
      "Epoch [67/300], Step [11/225], Training Accuracy: 92.1875%, Training Loss: 0.1942%\n",
      "Epoch [67/300], Step [12/225], Training Accuracy: 92.1875%, Training Loss: 0.1910%\n",
      "Epoch [67/300], Step [13/225], Training Accuracy: 92.3077%, Training Loss: 0.1892%\n",
      "Epoch [67/300], Step [14/225], Training Accuracy: 92.5223%, Training Loss: 0.1848%\n",
      "Epoch [67/300], Step [15/225], Training Accuracy: 92.3958%, Training Loss: 0.1846%\n",
      "Epoch [67/300], Step [16/225], Training Accuracy: 92.6758%, Training Loss: 0.1791%\n",
      "Epoch [67/300], Step [17/225], Training Accuracy: 93.0147%, Training Loss: 0.1727%\n",
      "Epoch [67/300], Step [18/225], Training Accuracy: 92.9688%, Training Loss: 0.1736%\n",
      "Epoch [67/300], Step [19/225], Training Accuracy: 92.7632%, Training Loss: 0.1776%\n",
      "Epoch [67/300], Step [20/225], Training Accuracy: 92.7344%, Training Loss: 0.1812%\n",
      "Epoch [67/300], Step [21/225], Training Accuracy: 92.8571%, Training Loss: 0.1833%\n",
      "Epoch [67/300], Step [22/225], Training Accuracy: 92.8267%, Training Loss: 0.1856%\n",
      "Epoch [67/300], Step [23/225], Training Accuracy: 92.8668%, Training Loss: 0.1863%\n",
      "Epoch [67/300], Step [24/225], Training Accuracy: 92.8385%, Training Loss: 0.1854%\n",
      "Epoch [67/300], Step [25/225], Training Accuracy: 92.8750%, Training Loss: 0.1859%\n",
      "Epoch [67/300], Step [26/225], Training Accuracy: 92.8486%, Training Loss: 0.1864%\n",
      "Epoch [67/300], Step [27/225], Training Accuracy: 92.7662%, Training Loss: 0.1846%\n",
      "Epoch [67/300], Step [28/225], Training Accuracy: 92.9129%, Training Loss: 0.1803%\n",
      "Epoch [67/300], Step [29/225], Training Accuracy: 93.0496%, Training Loss: 0.1779%\n",
      "Epoch [67/300], Step [30/225], Training Accuracy: 93.1771%, Training Loss: 0.1750%\n",
      "Epoch [67/300], Step [31/225], Training Accuracy: 93.1452%, Training Loss: 0.1768%\n",
      "Epoch [67/300], Step [32/225], Training Accuracy: 93.3105%, Training Loss: 0.1732%\n",
      "Epoch [67/300], Step [33/225], Training Accuracy: 93.3239%, Training Loss: 0.1726%\n",
      "Epoch [67/300], Step [34/225], Training Accuracy: 93.2904%, Training Loss: 0.1747%\n",
      "Epoch [67/300], Step [35/225], Training Accuracy: 93.3482%, Training Loss: 0.1731%\n",
      "Epoch [67/300], Step [36/225], Training Accuracy: 93.4028%, Training Loss: 0.1720%\n",
      "Epoch [67/300], Step [37/225], Training Accuracy: 93.4966%, Training Loss: 0.1700%\n",
      "Epoch [67/300], Step [38/225], Training Accuracy: 93.5033%, Training Loss: 0.1693%\n",
      "Epoch [67/300], Step [39/225], Training Accuracy: 93.5497%, Training Loss: 0.1691%\n",
      "Epoch [67/300], Step [40/225], Training Accuracy: 93.5938%, Training Loss: 0.1685%\n",
      "Epoch [67/300], Step [41/225], Training Accuracy: 93.4832%, Training Loss: 0.1692%\n",
      "Epoch [67/300], Step [42/225], Training Accuracy: 93.5268%, Training Loss: 0.1690%\n",
      "Epoch [67/300], Step [43/225], Training Accuracy: 93.4956%, Training Loss: 0.1698%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/300], Step [44/225], Training Accuracy: 93.5014%, Training Loss: 0.1705%\n",
      "Epoch [67/300], Step [45/225], Training Accuracy: 93.5069%, Training Loss: 0.1709%\n",
      "Epoch [67/300], Step [46/225], Training Accuracy: 93.4783%, Training Loss: 0.1701%\n",
      "Epoch [67/300], Step [47/225], Training Accuracy: 93.4508%, Training Loss: 0.1719%\n",
      "Epoch [67/300], Step [48/225], Training Accuracy: 93.5221%, Training Loss: 0.1714%\n",
      "Epoch [67/300], Step [49/225], Training Accuracy: 93.5906%, Training Loss: 0.1700%\n",
      "Epoch [67/300], Step [50/225], Training Accuracy: 93.6562%, Training Loss: 0.1693%\n",
      "Epoch [67/300], Step [51/225], Training Accuracy: 93.7194%, Training Loss: 0.1679%\n",
      "Epoch [67/300], Step [52/225], Training Accuracy: 93.7500%, Training Loss: 0.1667%\n",
      "Epoch [67/300], Step [53/225], Training Accuracy: 93.8090%, Training Loss: 0.1657%\n",
      "Epoch [67/300], Step [54/225], Training Accuracy: 93.7211%, Training Loss: 0.1669%\n",
      "Epoch [67/300], Step [55/225], Training Accuracy: 93.7216%, Training Loss: 0.1665%\n",
      "Epoch [67/300], Step [56/225], Training Accuracy: 93.7500%, Training Loss: 0.1682%\n",
      "Epoch [67/300], Step [57/225], Training Accuracy: 93.6404%, Training Loss: 0.1698%\n",
      "Epoch [67/300], Step [58/225], Training Accuracy: 93.5614%, Training Loss: 0.1710%\n",
      "Epoch [67/300], Step [59/225], Training Accuracy: 93.6176%, Training Loss: 0.1700%\n",
      "Epoch [67/300], Step [60/225], Training Accuracy: 93.6458%, Training Loss: 0.1691%\n",
      "Epoch [67/300], Step [61/225], Training Accuracy: 93.6475%, Training Loss: 0.1688%\n",
      "Epoch [67/300], Step [62/225], Training Accuracy: 93.6996%, Training Loss: 0.1677%\n",
      "Epoch [67/300], Step [63/225], Training Accuracy: 93.7252%, Training Loss: 0.1671%\n",
      "Epoch [67/300], Step [64/225], Training Accuracy: 93.8232%, Training Loss: 0.1652%\n",
      "Epoch [67/300], Step [65/225], Training Accuracy: 93.8221%, Training Loss: 0.1659%\n",
      "Epoch [67/300], Step [66/225], Training Accuracy: 93.8447%, Training Loss: 0.1653%\n",
      "Epoch [67/300], Step [67/225], Training Accuracy: 93.8666%, Training Loss: 0.1640%\n",
      "Epoch [67/300], Step [68/225], Training Accuracy: 93.8419%, Training Loss: 0.1691%\n",
      "Epoch [67/300], Step [69/225], Training Accuracy: 93.8632%, Training Loss: 0.1680%\n",
      "Epoch [67/300], Step [70/225], Training Accuracy: 93.8839%, Training Loss: 0.1672%\n",
      "Epoch [67/300], Step [71/225], Training Accuracy: 93.8820%, Training Loss: 0.1677%\n",
      "Epoch [67/300], Step [72/225], Training Accuracy: 93.9453%, Training Loss: 0.1666%\n",
      "Epoch [67/300], Step [73/225], Training Accuracy: 94.0068%, Training Loss: 0.1652%\n",
      "Epoch [67/300], Step [74/225], Training Accuracy: 93.9611%, Training Loss: 0.1653%\n",
      "Epoch [67/300], Step [75/225], Training Accuracy: 94.0208%, Training Loss: 0.1639%\n",
      "Epoch [67/300], Step [76/225], Training Accuracy: 93.9556%, Training Loss: 0.1663%\n",
      "Epoch [67/300], Step [77/225], Training Accuracy: 93.9326%, Training Loss: 0.1665%\n",
      "Epoch [67/300], Step [78/225], Training Accuracy: 93.8902%, Training Loss: 0.1670%\n",
      "Epoch [67/300], Step [79/225], Training Accuracy: 93.8489%, Training Loss: 0.1675%\n",
      "Epoch [67/300], Step [80/225], Training Accuracy: 93.8867%, Training Loss: 0.1668%\n",
      "Epoch [67/300], Step [81/225], Training Accuracy: 93.9429%, Training Loss: 0.1657%\n",
      "Epoch [67/300], Step [82/225], Training Accuracy: 93.9596%, Training Loss: 0.1649%\n",
      "Epoch [67/300], Step [83/225], Training Accuracy: 93.9571%, Training Loss: 0.1651%\n",
      "Epoch [67/300], Step [84/225], Training Accuracy: 93.9546%, Training Loss: 0.1650%\n",
      "Epoch [67/300], Step [85/225], Training Accuracy: 93.9338%, Training Loss: 0.1654%\n",
      "Epoch [67/300], Step [86/225], Training Accuracy: 93.9680%, Training Loss: 0.1645%\n",
      "Epoch [67/300], Step [87/225], Training Accuracy: 93.9835%, Training Loss: 0.1642%\n",
      "Epoch [67/300], Step [88/225], Training Accuracy: 93.9631%, Training Loss: 0.1650%\n",
      "Epoch [67/300], Step [89/225], Training Accuracy: 93.9782%, Training Loss: 0.1651%\n",
      "Epoch [67/300], Step [90/225], Training Accuracy: 93.8889%, Training Loss: 0.1661%\n",
      "Epoch [67/300], Step [91/225], Training Accuracy: 93.9045%, Training Loss: 0.1660%\n",
      "Epoch [67/300], Step [92/225], Training Accuracy: 93.9198%, Training Loss: 0.1657%\n",
      "Epoch [67/300], Step [93/225], Training Accuracy: 93.9852%, Training Loss: 0.1649%\n",
      "Epoch [67/300], Step [94/225], Training Accuracy: 93.9661%, Training Loss: 0.1660%\n",
      "Epoch [67/300], Step [95/225], Training Accuracy: 94.0132%, Training Loss: 0.1648%\n",
      "Epoch [67/300], Step [96/225], Training Accuracy: 94.0267%, Training Loss: 0.1648%\n",
      "Epoch [67/300], Step [97/225], Training Accuracy: 94.0077%, Training Loss: 0.1653%\n",
      "Epoch [67/300], Step [98/225], Training Accuracy: 93.9892%, Training Loss: 0.1656%\n",
      "Epoch [67/300], Step [99/225], Training Accuracy: 93.9867%, Training Loss: 0.1654%\n",
      "Epoch [67/300], Step [100/225], Training Accuracy: 93.9531%, Training Loss: 0.1660%\n",
      "Epoch [67/300], Step [101/225], Training Accuracy: 93.9511%, Training Loss: 0.1662%\n",
      "Epoch [67/300], Step [102/225], Training Accuracy: 93.9185%, Training Loss: 0.1662%\n",
      "Epoch [67/300], Step [103/225], Training Accuracy: 93.9017%, Training Loss: 0.1660%\n",
      "Epoch [67/300], Step [104/225], Training Accuracy: 93.8552%, Training Loss: 0.1664%\n",
      "Epoch [67/300], Step [105/225], Training Accuracy: 93.8690%, Training Loss: 0.1660%\n",
      "Epoch [67/300], Step [106/225], Training Accuracy: 93.8974%, Training Loss: 0.1657%\n",
      "Epoch [67/300], Step [107/225], Training Accuracy: 93.9106%, Training Loss: 0.1656%\n",
      "Epoch [67/300], Step [108/225], Training Accuracy: 93.8657%, Training Loss: 0.1660%\n",
      "Epoch [67/300], Step [109/225], Training Accuracy: 93.8647%, Training Loss: 0.1660%\n",
      "Epoch [67/300], Step [110/225], Training Accuracy: 93.8352%, Training Loss: 0.1663%\n",
      "Epoch [67/300], Step [111/225], Training Accuracy: 93.8485%, Training Loss: 0.1663%\n",
      "Epoch [67/300], Step [112/225], Training Accuracy: 93.8756%, Training Loss: 0.1661%\n",
      "Epoch [67/300], Step [113/225], Training Accuracy: 93.9021%, Training Loss: 0.1660%\n",
      "Epoch [67/300], Step [114/225], Training Accuracy: 93.9145%, Training Loss: 0.1657%\n",
      "Epoch [67/300], Step [115/225], Training Accuracy: 93.9266%, Training Loss: 0.1649%\n",
      "Epoch [67/300], Step [116/225], Training Accuracy: 93.9520%, Training Loss: 0.1644%\n",
      "Epoch [67/300], Step [117/225], Training Accuracy: 93.9370%, Training Loss: 0.1652%\n",
      "Epoch [67/300], Step [118/225], Training Accuracy: 93.8957%, Training Loss: 0.1660%\n",
      "Epoch [67/300], Step [119/225], Training Accuracy: 93.9076%, Training Loss: 0.1654%\n",
      "Epoch [67/300], Step [120/225], Training Accuracy: 93.8932%, Training Loss: 0.1659%\n",
      "Epoch [67/300], Step [121/225], Training Accuracy: 93.8791%, Training Loss: 0.1659%\n",
      "Epoch [67/300], Step [122/225], Training Accuracy: 93.8525%, Training Loss: 0.1658%\n",
      "Epoch [67/300], Step [123/225], Training Accuracy: 93.8770%, Training Loss: 0.1654%\n",
      "Epoch [67/300], Step [124/225], Training Accuracy: 93.8886%, Training Loss: 0.1650%\n",
      "Epoch [67/300], Step [125/225], Training Accuracy: 93.8750%, Training Loss: 0.1649%\n",
      "Epoch [67/300], Step [126/225], Training Accuracy: 93.8368%, Training Loss: 0.1653%\n",
      "Epoch [67/300], Step [127/225], Training Accuracy: 93.7746%, Training Loss: 0.1658%\n",
      "Epoch [67/300], Step [128/225], Training Accuracy: 93.7622%, Training Loss: 0.1659%\n",
      "Epoch [67/300], Step [129/225], Training Accuracy: 93.7863%, Training Loss: 0.1655%\n",
      "Epoch [67/300], Step [130/225], Training Accuracy: 93.7861%, Training Loss: 0.1661%\n",
      "Epoch [67/300], Step [131/225], Training Accuracy: 93.7977%, Training Loss: 0.1664%\n",
      "Epoch [67/300], Step [132/225], Training Accuracy: 93.7855%, Training Loss: 0.1674%\n",
      "Epoch [67/300], Step [133/225], Training Accuracy: 93.7617%, Training Loss: 0.1678%\n",
      "Epoch [67/300], Step [134/225], Training Accuracy: 93.7500%, Training Loss: 0.1680%\n",
      "Epoch [67/300], Step [135/225], Training Accuracy: 93.7616%, Training Loss: 0.1676%\n",
      "Epoch [67/300], Step [136/225], Training Accuracy: 93.7270%, Training Loss: 0.1685%\n",
      "Epoch [67/300], Step [137/225], Training Accuracy: 93.7386%, Training Loss: 0.1684%\n",
      "Epoch [67/300], Step [138/225], Training Accuracy: 93.7387%, Training Loss: 0.1679%\n",
      "Epoch [67/300], Step [139/225], Training Accuracy: 93.6826%, Training Loss: 0.1685%\n",
      "Epoch [67/300], Step [140/225], Training Accuracy: 93.6384%, Training Loss: 0.1689%\n",
      "Epoch [67/300], Step [141/225], Training Accuracy: 93.6503%, Training Loss: 0.1687%\n",
      "Epoch [67/300], Step [142/225], Training Accuracy: 93.6510%, Training Loss: 0.1688%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/300], Step [143/225], Training Accuracy: 93.6517%, Training Loss: 0.1687%\n",
      "Epoch [67/300], Step [144/225], Training Accuracy: 93.6632%, Training Loss: 0.1686%\n",
      "Epoch [67/300], Step [145/225], Training Accuracy: 93.6315%, Training Loss: 0.1693%\n",
      "Epoch [67/300], Step [146/225], Training Accuracy: 93.6644%, Training Loss: 0.1686%\n",
      "Epoch [67/300], Step [147/225], Training Accuracy: 93.6437%, Training Loss: 0.1688%\n",
      "Epoch [67/300], Step [148/225], Training Accuracy: 93.6444%, Training Loss: 0.1685%\n",
      "Epoch [67/300], Step [149/225], Training Accuracy: 93.6346%, Training Loss: 0.1684%\n",
      "Epoch [67/300], Step [150/225], Training Accuracy: 93.6354%, Training Loss: 0.1682%\n",
      "Epoch [67/300], Step [151/225], Training Accuracy: 93.6569%, Training Loss: 0.1677%\n",
      "Epoch [67/300], Step [152/225], Training Accuracy: 93.6472%, Training Loss: 0.1682%\n",
      "Epoch [67/300], Step [153/225], Training Accuracy: 93.6377%, Training Loss: 0.1684%\n",
      "Epoch [67/300], Step [154/225], Training Accuracy: 93.6485%, Training Loss: 0.1685%\n",
      "Epoch [67/300], Step [155/225], Training Accuracy: 93.6089%, Training Loss: 0.1692%\n",
      "Epoch [67/300], Step [156/225], Training Accuracy: 93.6098%, Training Loss: 0.1693%\n",
      "Epoch [67/300], Step [157/225], Training Accuracy: 93.6007%, Training Loss: 0.1695%\n",
      "Epoch [67/300], Step [158/225], Training Accuracy: 93.5918%, Training Loss: 0.1695%\n",
      "Epoch [67/300], Step [159/225], Training Accuracy: 93.5928%, Training Loss: 0.1694%\n",
      "Epoch [67/300], Step [160/225], Training Accuracy: 93.6035%, Training Loss: 0.1693%\n",
      "Epoch [67/300], Step [161/225], Training Accuracy: 93.6141%, Training Loss: 0.1691%\n",
      "Epoch [67/300], Step [162/225], Training Accuracy: 93.6150%, Training Loss: 0.1690%\n",
      "Epoch [67/300], Step [163/225], Training Accuracy: 93.6062%, Training Loss: 0.1694%\n",
      "Epoch [67/300], Step [164/225], Training Accuracy: 93.6071%, Training Loss: 0.1690%\n",
      "Epoch [67/300], Step [165/225], Training Accuracy: 93.5701%, Training Loss: 0.1698%\n",
      "Epoch [67/300], Step [166/225], Training Accuracy: 93.5617%, Training Loss: 0.1698%\n",
      "Epoch [67/300], Step [167/225], Training Accuracy: 93.5535%, Training Loss: 0.1697%\n",
      "Epoch [67/300], Step [168/225], Training Accuracy: 93.5733%, Training Loss: 0.1695%\n",
      "Epoch [67/300], Step [169/225], Training Accuracy: 93.6021%, Training Loss: 0.1689%\n",
      "Epoch [67/300], Step [170/225], Training Accuracy: 93.5938%, Training Loss: 0.1691%\n",
      "Epoch [67/300], Step [171/225], Training Accuracy: 93.5764%, Training Loss: 0.1694%\n",
      "Epoch [67/300], Step [172/225], Training Accuracy: 93.5865%, Training Loss: 0.1695%\n",
      "Epoch [67/300], Step [173/225], Training Accuracy: 93.5965%, Training Loss: 0.1692%\n",
      "Epoch [67/300], Step [174/225], Training Accuracy: 93.6063%, Training Loss: 0.1693%\n",
      "Epoch [67/300], Step [175/225], Training Accuracy: 93.6161%, Training Loss: 0.1694%\n",
      "Epoch [67/300], Step [176/225], Training Accuracy: 93.6435%, Training Loss: 0.1691%\n",
      "Epoch [67/300], Step [177/225], Training Accuracy: 93.6617%, Training Loss: 0.1686%\n",
      "Epoch [67/300], Step [178/225], Training Accuracy: 93.6710%, Training Loss: 0.1683%\n",
      "Epoch [67/300], Step [179/225], Training Accuracy: 93.6453%, Training Loss: 0.1683%\n",
      "Epoch [67/300], Step [180/225], Training Accuracy: 93.6719%, Training Loss: 0.1677%\n",
      "Epoch [67/300], Step [181/225], Training Accuracy: 93.6723%, Training Loss: 0.1676%\n",
      "Epoch [67/300], Step [182/225], Training Accuracy: 93.6727%, Training Loss: 0.1676%\n",
      "Epoch [67/300], Step [183/225], Training Accuracy: 93.6732%, Training Loss: 0.1675%\n",
      "Epoch [67/300], Step [184/225], Training Accuracy: 93.6906%, Training Loss: 0.1673%\n",
      "Epoch [67/300], Step [185/225], Training Accuracy: 93.6824%, Training Loss: 0.1672%\n",
      "Epoch [67/300], Step [186/225], Training Accuracy: 93.6744%, Training Loss: 0.1670%\n",
      "Epoch [67/300], Step [187/225], Training Accuracy: 93.6832%, Training Loss: 0.1666%\n",
      "Epoch [67/300], Step [188/225], Training Accuracy: 93.7084%, Training Loss: 0.1660%\n",
      "Epoch [67/300], Step [189/225], Training Accuracy: 93.7087%, Training Loss: 0.1660%\n",
      "Epoch [67/300], Step [190/225], Training Accuracy: 93.7171%, Training Loss: 0.1658%\n",
      "Epoch [67/300], Step [191/225], Training Accuracy: 93.6927%, Training Loss: 0.1663%\n",
      "Epoch [67/300], Step [192/225], Training Accuracy: 93.6849%, Training Loss: 0.1665%\n",
      "Epoch [67/300], Step [193/225], Training Accuracy: 93.6771%, Training Loss: 0.1668%\n",
      "Epoch [67/300], Step [194/225], Training Accuracy: 93.6775%, Training Loss: 0.1668%\n",
      "Epoch [67/300], Step [195/225], Training Accuracy: 93.6939%, Training Loss: 0.1664%\n",
      "Epoch [67/300], Step [196/225], Training Accuracy: 93.6942%, Training Loss: 0.1664%\n",
      "Epoch [67/300], Step [197/225], Training Accuracy: 93.6865%, Training Loss: 0.1663%\n",
      "Epoch [67/300], Step [198/225], Training Accuracy: 93.6869%, Training Loss: 0.1662%\n",
      "Epoch [67/300], Step [199/225], Training Accuracy: 93.6950%, Training Loss: 0.1658%\n",
      "Epoch [67/300], Step [200/225], Training Accuracy: 93.6719%, Training Loss: 0.1661%\n",
      "Epoch [67/300], Step [201/225], Training Accuracy: 93.6800%, Training Loss: 0.1658%\n",
      "Epoch [67/300], Step [202/225], Training Accuracy: 93.7036%, Training Loss: 0.1653%\n",
      "Epoch [67/300], Step [203/225], Training Accuracy: 93.7346%, Training Loss: 0.1646%\n",
      "Epoch [67/300], Step [204/225], Training Accuracy: 93.7500%, Training Loss: 0.1643%\n",
      "Epoch [67/300], Step [205/225], Training Accuracy: 93.7729%, Training Loss: 0.1638%\n",
      "Epoch [67/300], Step [206/225], Training Accuracy: 93.7955%, Training Loss: 0.1635%\n",
      "Epoch [67/300], Step [207/225], Training Accuracy: 93.7953%, Training Loss: 0.1636%\n",
      "Epoch [67/300], Step [208/225], Training Accuracy: 93.8026%, Training Loss: 0.1634%\n",
      "Epoch [67/300], Step [209/225], Training Accuracy: 93.8173%, Training Loss: 0.1631%\n",
      "Epoch [67/300], Step [210/225], Training Accuracy: 93.8467%, Training Loss: 0.1627%\n",
      "Epoch [67/300], Step [211/225], Training Accuracy: 93.8463%, Training Loss: 0.1629%\n",
      "Epoch [67/300], Step [212/225], Training Accuracy: 93.8163%, Training Loss: 0.1632%\n",
      "Epoch [67/300], Step [213/225], Training Accuracy: 93.8087%, Training Loss: 0.1631%\n",
      "Epoch [67/300], Step [214/225], Training Accuracy: 93.8011%, Training Loss: 0.1632%\n",
      "Epoch [67/300], Step [215/225], Training Accuracy: 93.8154%, Training Loss: 0.1629%\n",
      "Epoch [67/300], Step [216/225], Training Accuracy: 93.8006%, Training Loss: 0.1634%\n",
      "Epoch [67/300], Step [217/225], Training Accuracy: 93.8148%, Training Loss: 0.1632%\n",
      "Epoch [67/300], Step [218/225], Training Accuracy: 93.7858%, Training Loss: 0.1635%\n",
      "Epoch [67/300], Step [219/225], Training Accuracy: 93.7857%, Training Loss: 0.1633%\n",
      "Epoch [67/300], Step [220/225], Training Accuracy: 93.7926%, Training Loss: 0.1633%\n",
      "Epoch [67/300], Step [221/225], Training Accuracy: 93.8066%, Training Loss: 0.1629%\n",
      "Epoch [67/300], Step [222/225], Training Accuracy: 93.7993%, Training Loss: 0.1630%\n",
      "Epoch [67/300], Step [223/225], Training Accuracy: 93.8061%, Training Loss: 0.1628%\n",
      "Epoch [67/300], Step [224/225], Training Accuracy: 93.7779%, Training Loss: 0.1631%\n",
      "Epoch [67/300], Step [225/225], Training Accuracy: 93.7813%, Training Loss: 0.1632%\n",
      "Epoch [68/300], Step [1/225], Training Accuracy: 87.5000%, Training Loss: 0.2161%\n",
      "Epoch [68/300], Step [2/225], Training Accuracy: 89.0625%, Training Loss: 0.2201%\n",
      "Epoch [68/300], Step [3/225], Training Accuracy: 91.1458%, Training Loss: 0.1862%\n",
      "Epoch [68/300], Step [4/225], Training Accuracy: 91.7969%, Training Loss: 0.1784%\n",
      "Epoch [68/300], Step [5/225], Training Accuracy: 91.8750%, Training Loss: 0.1881%\n",
      "Epoch [68/300], Step [6/225], Training Accuracy: 92.1875%, Training Loss: 0.1828%\n",
      "Epoch [68/300], Step [7/225], Training Accuracy: 91.9643%, Training Loss: 0.1836%\n",
      "Epoch [68/300], Step [8/225], Training Accuracy: 91.7969%, Training Loss: 0.1899%\n",
      "Epoch [68/300], Step [9/225], Training Accuracy: 91.6667%, Training Loss: 0.1907%\n",
      "Epoch [68/300], Step [10/225], Training Accuracy: 91.8750%, Training Loss: 0.1867%\n",
      "Epoch [68/300], Step [11/225], Training Accuracy: 91.7614%, Training Loss: 0.1904%\n",
      "Epoch [68/300], Step [12/225], Training Accuracy: 91.7969%, Training Loss: 0.1888%\n",
      "Epoch [68/300], Step [13/225], Training Accuracy: 91.8269%, Training Loss: 0.1921%\n",
      "Epoch [68/300], Step [14/225], Training Accuracy: 92.2991%, Training Loss: 0.1861%\n",
      "Epoch [68/300], Step [15/225], Training Accuracy: 92.2917%, Training Loss: 0.1837%\n",
      "Epoch [68/300], Step [16/225], Training Accuracy: 92.2852%, Training Loss: 0.1839%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/300], Step [17/225], Training Accuracy: 92.0956%, Training Loss: 0.1895%\n",
      "Epoch [68/300], Step [18/225], Training Accuracy: 92.3611%, Training Loss: 0.1892%\n",
      "Epoch [68/300], Step [19/225], Training Accuracy: 92.4342%, Training Loss: 0.1906%\n",
      "Epoch [68/300], Step [20/225], Training Accuracy: 92.4219%, Training Loss: 0.1875%\n",
      "Epoch [68/300], Step [21/225], Training Accuracy: 92.6339%, Training Loss: 0.1815%\n",
      "Epoch [68/300], Step [22/225], Training Accuracy: 92.5426%, Training Loss: 0.1872%\n",
      "Epoch [68/300], Step [23/225], Training Accuracy: 92.5272%, Training Loss: 0.1885%\n",
      "Epoch [68/300], Step [24/225], Training Accuracy: 92.5130%, Training Loss: 0.1883%\n",
      "Epoch [68/300], Step [25/225], Training Accuracy: 92.6875%, Training Loss: 0.1833%\n",
      "Epoch [68/300], Step [26/225], Training Accuracy: 92.7885%, Training Loss: 0.1803%\n",
      "Epoch [68/300], Step [27/225], Training Accuracy: 92.8241%, Training Loss: 0.1782%\n",
      "Epoch [68/300], Step [28/225], Training Accuracy: 92.8571%, Training Loss: 0.1755%\n",
      "Epoch [68/300], Step [29/225], Training Accuracy: 92.6724%, Training Loss: 0.1795%\n",
      "Epoch [68/300], Step [30/225], Training Accuracy: 92.8125%, Training Loss: 0.1767%\n",
      "Epoch [68/300], Step [31/225], Training Accuracy: 92.6915%, Training Loss: 0.1856%\n",
      "Epoch [68/300], Step [32/225], Training Accuracy: 92.7734%, Training Loss: 0.1837%\n",
      "Epoch [68/300], Step [33/225], Training Accuracy: 92.9451%, Training Loss: 0.1811%\n",
      "Epoch [68/300], Step [34/225], Training Accuracy: 92.9688%, Training Loss: 0.1810%\n",
      "Epoch [68/300], Step [35/225], Training Accuracy: 92.8125%, Training Loss: 0.1830%\n",
      "Epoch [68/300], Step [36/225], Training Accuracy: 92.8385%, Training Loss: 0.1809%\n",
      "Epoch [68/300], Step [37/225], Training Accuracy: 92.9476%, Training Loss: 0.1794%\n",
      "Epoch [68/300], Step [38/225], Training Accuracy: 92.8043%, Training Loss: 0.1814%\n",
      "Epoch [68/300], Step [39/225], Training Accuracy: 92.7083%, Training Loss: 0.1823%\n",
      "Epoch [68/300], Step [40/225], Training Accuracy: 92.7734%, Training Loss: 0.1810%\n",
      "Epoch [68/300], Step [41/225], Training Accuracy: 92.7973%, Training Loss: 0.1809%\n",
      "Epoch [68/300], Step [42/225], Training Accuracy: 92.7827%, Training Loss: 0.1807%\n",
      "Epoch [68/300], Step [43/225], Training Accuracy: 92.8779%, Training Loss: 0.1797%\n",
      "Epoch [68/300], Step [44/225], Training Accuracy: 92.8267%, Training Loss: 0.1792%\n",
      "Epoch [68/300], Step [45/225], Training Accuracy: 92.9167%, Training Loss: 0.1779%\n",
      "Epoch [68/300], Step [46/225], Training Accuracy: 93.0027%, Training Loss: 0.1766%\n",
      "Epoch [68/300], Step [47/225], Training Accuracy: 92.9854%, Training Loss: 0.1769%\n",
      "Epoch [68/300], Step [48/225], Training Accuracy: 92.9036%, Training Loss: 0.1797%\n",
      "Epoch [68/300], Step [49/225], Training Accuracy: 93.0166%, Training Loss: 0.1775%\n",
      "Epoch [68/300], Step [50/225], Training Accuracy: 92.9688%, Training Loss: 0.1793%\n",
      "Epoch [68/300], Step [51/225], Training Accuracy: 93.0147%, Training Loss: 0.1783%\n",
      "Epoch [68/300], Step [52/225], Training Accuracy: 93.0589%, Training Loss: 0.1777%\n",
      "Epoch [68/300], Step [53/225], Training Accuracy: 93.1014%, Training Loss: 0.1771%\n",
      "Epoch [68/300], Step [54/225], Training Accuracy: 93.0556%, Training Loss: 0.1770%\n",
      "Epoch [68/300], Step [55/225], Training Accuracy: 92.9830%, Training Loss: 0.1801%\n",
      "Epoch [68/300], Step [56/225], Training Accuracy: 92.9967%, Training Loss: 0.1795%\n",
      "Epoch [68/300], Step [57/225], Training Accuracy: 92.8728%, Training Loss: 0.1806%\n",
      "Epoch [68/300], Step [58/225], Training Accuracy: 92.8071%, Training Loss: 0.1807%\n",
      "Epoch [68/300], Step [59/225], Training Accuracy: 92.7172%, Training Loss: 0.1823%\n",
      "Epoch [68/300], Step [60/225], Training Accuracy: 92.7604%, Training Loss: 0.1817%\n",
      "Epoch [68/300], Step [61/225], Training Accuracy: 92.8279%, Training Loss: 0.1804%\n",
      "Epoch [68/300], Step [62/225], Training Accuracy: 92.8679%, Training Loss: 0.1808%\n",
      "Epoch [68/300], Step [63/225], Training Accuracy: 92.9067%, Training Loss: 0.1806%\n",
      "Epoch [68/300], Step [64/225], Training Accuracy: 92.9443%, Training Loss: 0.1797%\n",
      "Epoch [68/300], Step [65/225], Training Accuracy: 92.9567%, Training Loss: 0.1813%\n",
      "Epoch [68/300], Step [66/225], Training Accuracy: 93.0161%, Training Loss: 0.1804%\n",
      "Epoch [68/300], Step [67/225], Training Accuracy: 92.9338%, Training Loss: 0.1829%\n",
      "Epoch [68/300], Step [68/225], Training Accuracy: 92.9458%, Training Loss: 0.1825%\n",
      "Epoch [68/300], Step [69/225], Training Accuracy: 92.9574%, Training Loss: 0.1830%\n",
      "Epoch [68/300], Step [70/225], Training Accuracy: 93.0134%, Training Loss: 0.1820%\n",
      "Epoch [68/300], Step [71/225], Training Accuracy: 93.0678%, Training Loss: 0.1809%\n",
      "Epoch [68/300], Step [72/225], Training Accuracy: 93.0990%, Training Loss: 0.1807%\n",
      "Epoch [68/300], Step [73/225], Training Accuracy: 93.1293%, Training Loss: 0.1804%\n",
      "Epoch [68/300], Step [74/225], Training Accuracy: 93.1588%, Training Loss: 0.1801%\n",
      "Epoch [68/300], Step [75/225], Training Accuracy: 93.1042%, Training Loss: 0.1826%\n",
      "Epoch [68/300], Step [76/225], Training Accuracy: 93.1332%, Training Loss: 0.1823%\n",
      "Epoch [68/300], Step [77/225], Training Accuracy: 93.1615%, Training Loss: 0.1814%\n",
      "Epoch [68/300], Step [78/225], Training Accuracy: 93.1691%, Training Loss: 0.1821%\n",
      "Epoch [68/300], Step [79/225], Training Accuracy: 93.1764%, Training Loss: 0.1815%\n",
      "Epoch [68/300], Step [80/225], Training Accuracy: 93.1641%, Training Loss: 0.1814%\n",
      "Epoch [68/300], Step [81/225], Training Accuracy: 93.1134%, Training Loss: 0.1832%\n",
      "Epoch [68/300], Step [82/225], Training Accuracy: 93.1212%, Training Loss: 0.1825%\n",
      "Epoch [68/300], Step [83/225], Training Accuracy: 93.1852%, Training Loss: 0.1816%\n",
      "Epoch [68/300], Step [84/225], Training Accuracy: 93.2478%, Training Loss: 0.1806%\n",
      "Epoch [68/300], Step [85/225], Training Accuracy: 93.2721%, Training Loss: 0.1799%\n",
      "Epoch [68/300], Step [86/225], Training Accuracy: 93.2958%, Training Loss: 0.1795%\n",
      "Epoch [68/300], Step [87/225], Training Accuracy: 93.2651%, Training Loss: 0.1802%\n",
      "Epoch [68/300], Step [88/225], Training Accuracy: 93.1996%, Training Loss: 0.1813%\n",
      "Epoch [68/300], Step [89/225], Training Accuracy: 93.2409%, Training Loss: 0.1804%\n",
      "Epoch [68/300], Step [90/225], Training Accuracy: 93.2292%, Training Loss: 0.1807%\n",
      "Epoch [68/300], Step [91/225], Training Accuracy: 93.2692%, Training Loss: 0.1802%\n",
      "Epoch [68/300], Step [92/225], Training Accuracy: 93.2235%, Training Loss: 0.1812%\n",
      "Epoch [68/300], Step [93/225], Training Accuracy: 93.2628%, Training Loss: 0.1802%\n",
      "Epoch [68/300], Step [94/225], Training Accuracy: 93.2680%, Training Loss: 0.1801%\n",
      "Epoch [68/300], Step [95/225], Training Accuracy: 93.2730%, Training Loss: 0.1795%\n",
      "Epoch [68/300], Step [96/225], Training Accuracy: 93.3268%, Training Loss: 0.1788%\n",
      "Epoch [68/300], Step [97/225], Training Accuracy: 93.2668%, Training Loss: 0.1815%\n",
      "Epoch [68/300], Step [98/225], Training Accuracy: 93.2876%, Training Loss: 0.1819%\n",
      "Epoch [68/300], Step [99/225], Training Accuracy: 93.3081%, Training Loss: 0.1816%\n",
      "Epoch [68/300], Step [100/225], Training Accuracy: 93.3125%, Training Loss: 0.1815%\n",
      "Epoch [68/300], Step [101/225], Training Accuracy: 93.3787%, Training Loss: 0.1804%\n",
      "Epoch [68/300], Step [102/225], Training Accuracy: 93.3670%, Training Loss: 0.1806%\n",
      "Epoch [68/300], Step [103/225], Training Accuracy: 93.4011%, Training Loss: 0.1798%\n",
      "Epoch [68/300], Step [104/225], Training Accuracy: 93.3744%, Training Loss: 0.1802%\n",
      "Epoch [68/300], Step [105/225], Training Accuracy: 93.2887%, Training Loss: 0.1826%\n",
      "Epoch [68/300], Step [106/225], Training Accuracy: 93.2930%, Training Loss: 0.1838%\n",
      "Epoch [68/300], Step [107/225], Training Accuracy: 93.2097%, Training Loss: 0.1862%\n",
      "Epoch [68/300], Step [108/225], Training Accuracy: 93.1858%, Training Loss: 0.1871%\n",
      "Epoch [68/300], Step [109/225], Training Accuracy: 93.1623%, Training Loss: 0.1891%\n",
      "Epoch [68/300], Step [110/225], Training Accuracy: 93.1534%, Training Loss: 0.1894%\n",
      "Epoch [68/300], Step [111/225], Training Accuracy: 93.1729%, Training Loss: 0.1889%\n",
      "Epoch [68/300], Step [112/225], Training Accuracy: 93.1362%, Training Loss: 0.1912%\n",
      "Epoch [68/300], Step [113/225], Training Accuracy: 93.1416%, Training Loss: 0.1912%\n",
      "Epoch [68/300], Step [114/225], Training Accuracy: 93.1195%, Training Loss: 0.1920%\n",
      "Epoch [68/300], Step [115/225], Training Accuracy: 93.1250%, Training Loss: 0.1923%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/300], Step [116/225], Training Accuracy: 93.0765%, Training Loss: 0.1939%\n",
      "Epoch [68/300], Step [117/225], Training Accuracy: 93.1357%, Training Loss: 0.1928%\n",
      "Epoch [68/300], Step [118/225], Training Accuracy: 93.1144%, Training Loss: 0.1933%\n",
      "Epoch [68/300], Step [119/225], Training Accuracy: 93.1329%, Training Loss: 0.1928%\n",
      "Epoch [68/300], Step [120/225], Training Accuracy: 93.0729%, Training Loss: 0.1935%\n",
      "Epoch [68/300], Step [121/225], Training Accuracy: 93.1043%, Training Loss: 0.1932%\n",
      "Epoch [68/300], Step [122/225], Training Accuracy: 93.1096%, Training Loss: 0.1929%\n",
      "Epoch [68/300], Step [123/225], Training Accuracy: 93.1021%, Training Loss: 0.1929%\n",
      "Epoch [68/300], Step [124/225], Training Accuracy: 93.0570%, Training Loss: 0.1943%\n",
      "Epoch [68/300], Step [125/225], Training Accuracy: 93.1000%, Training Loss: 0.1936%\n",
      "Epoch [68/300], Step [126/225], Training Accuracy: 93.0804%, Training Loss: 0.1938%\n",
      "Epoch [68/300], Step [127/225], Training Accuracy: 93.0487%, Training Loss: 0.1940%\n",
      "Epoch [68/300], Step [128/225], Training Accuracy: 93.0420%, Training Loss: 0.1939%\n",
      "Epoch [68/300], Step [129/225], Training Accuracy: 93.0596%, Training Loss: 0.1934%\n",
      "Epoch [68/300], Step [130/225], Training Accuracy: 93.0168%, Training Loss: 0.1938%\n",
      "Epoch [68/300], Step [131/225], Training Accuracy: 92.9747%, Training Loss: 0.1948%\n",
      "Epoch [68/300], Step [132/225], Training Accuracy: 92.9688%, Training Loss: 0.1951%\n",
      "Epoch [68/300], Step [133/225], Training Accuracy: 92.9629%, Training Loss: 0.1953%\n",
      "Epoch [68/300], Step [134/225], Training Accuracy: 92.9454%, Training Loss: 0.1959%\n",
      "Epoch [68/300], Step [135/225], Training Accuracy: 92.9514%, Training Loss: 0.1955%\n",
      "Epoch [68/300], Step [136/225], Training Accuracy: 92.9458%, Training Loss: 0.1957%\n",
      "Epoch [68/300], Step [137/225], Training Accuracy: 92.9288%, Training Loss: 0.1962%\n",
      "Epoch [68/300], Step [138/225], Training Accuracy: 92.9235%, Training Loss: 0.1960%\n",
      "Epoch [68/300], Step [139/225], Training Accuracy: 92.9182%, Training Loss: 0.1958%\n",
      "Epoch [68/300], Step [140/225], Training Accuracy: 92.9129%, Training Loss: 0.1954%\n",
      "Epoch [68/300], Step [141/225], Training Accuracy: 92.9410%, Training Loss: 0.1956%\n",
      "Epoch [68/300], Step [142/225], Training Accuracy: 92.9357%, Training Loss: 0.1960%\n",
      "Epoch [68/300], Step [143/225], Training Accuracy: 92.9196%, Training Loss: 0.1969%\n",
      "Epoch [68/300], Step [144/225], Training Accuracy: 92.9253%, Training Loss: 0.1970%\n",
      "Epoch [68/300], Step [145/225], Training Accuracy: 92.9418%, Training Loss: 0.1967%\n",
      "Epoch [68/300], Step [146/225], Training Accuracy: 92.9152%, Training Loss: 0.1976%\n",
      "Epoch [68/300], Step [147/225], Training Accuracy: 92.9103%, Training Loss: 0.1976%\n",
      "Epoch [68/300], Step [148/225], Training Accuracy: 92.9371%, Training Loss: 0.1968%\n",
      "Epoch [68/300], Step [149/225], Training Accuracy: 92.9320%, Training Loss: 0.1970%\n",
      "Epoch [68/300], Step [150/225], Training Accuracy: 92.9688%, Training Loss: 0.1960%\n",
      "Epoch [68/300], Step [151/225], Training Accuracy: 93.0050%, Training Loss: 0.1954%\n",
      "Epoch [68/300], Step [152/225], Training Accuracy: 93.0099%, Training Loss: 0.1953%\n",
      "Epoch [68/300], Step [153/225], Training Accuracy: 93.0147%, Training Loss: 0.1953%\n",
      "Epoch [68/300], Step [154/225], Training Accuracy: 93.0398%, Training Loss: 0.1947%\n",
      "Epoch [68/300], Step [155/225], Training Accuracy: 93.0544%, Training Loss: 0.1940%\n",
      "Epoch [68/300], Step [156/225], Training Accuracy: 93.0789%, Training Loss: 0.1935%\n",
      "Epoch [68/300], Step [157/225], Training Accuracy: 93.0832%, Training Loss: 0.1934%\n",
      "Epoch [68/300], Step [158/225], Training Accuracy: 93.1072%, Training Loss: 0.1928%\n",
      "Epoch [68/300], Step [159/225], Training Accuracy: 93.0916%, Training Loss: 0.1927%\n",
      "Epoch [68/300], Step [160/225], Training Accuracy: 93.0957%, Training Loss: 0.1925%\n",
      "Epoch [68/300], Step [161/225], Training Accuracy: 93.0901%, Training Loss: 0.1925%\n",
      "Epoch [68/300], Step [162/225], Training Accuracy: 93.0845%, Training Loss: 0.1925%\n",
      "Epoch [68/300], Step [163/225], Training Accuracy: 93.0886%, Training Loss: 0.1926%\n",
      "Epoch [68/300], Step [164/225], Training Accuracy: 93.1212%, Training Loss: 0.1919%\n",
      "Epoch [68/300], Step [165/225], Training Accuracy: 93.1155%, Training Loss: 0.1921%\n",
      "Epoch [68/300], Step [166/225], Training Accuracy: 93.1005%, Training Loss: 0.1922%\n",
      "Epoch [68/300], Step [167/225], Training Accuracy: 93.0951%, Training Loss: 0.1924%\n",
      "Epoch [68/300], Step [168/225], Training Accuracy: 93.0339%, Training Loss: 0.1930%\n",
      "Epoch [68/300], Step [169/225], Training Accuracy: 92.9919%, Training Loss: 0.1940%\n",
      "Epoch [68/300], Step [170/225], Training Accuracy: 92.9963%, Training Loss: 0.1941%\n",
      "Epoch [68/300], Step [171/225], Training Accuracy: 92.9916%, Training Loss: 0.1944%\n",
      "Epoch [68/300], Step [172/225], Training Accuracy: 92.9869%, Training Loss: 0.1943%\n",
      "Epoch [68/300], Step [173/225], Training Accuracy: 93.0004%, Training Loss: 0.1938%\n",
      "Epoch [68/300], Step [174/225], Training Accuracy: 93.0226%, Training Loss: 0.1933%\n",
      "Epoch [68/300], Step [175/225], Training Accuracy: 93.0268%, Training Loss: 0.1930%\n",
      "Epoch [68/300], Step [176/225], Training Accuracy: 93.0220%, Training Loss: 0.1931%\n",
      "Epoch [68/300], Step [177/225], Training Accuracy: 93.0173%, Training Loss: 0.1931%\n",
      "Epoch [68/300], Step [178/225], Training Accuracy: 93.0126%, Training Loss: 0.1929%\n",
      "Epoch [68/300], Step [179/225], Training Accuracy: 92.9993%, Training Loss: 0.1928%\n",
      "Epoch [68/300], Step [180/225], Training Accuracy: 92.9948%, Training Loss: 0.1930%\n",
      "Epoch [68/300], Step [181/225], Training Accuracy: 92.9817%, Training Loss: 0.1933%\n",
      "Epoch [68/300], Step [182/225], Training Accuracy: 93.0031%, Training Loss: 0.1928%\n",
      "Epoch [68/300], Step [183/225], Training Accuracy: 92.9986%, Training Loss: 0.1927%\n",
      "Epoch [68/300], Step [184/225], Training Accuracy: 93.0027%, Training Loss: 0.1925%\n",
      "Epoch [68/300], Step [185/225], Training Accuracy: 92.9814%, Training Loss: 0.1926%\n",
      "Epoch [68/300], Step [186/225], Training Accuracy: 92.9940%, Training Loss: 0.1921%\n",
      "Epoch [68/300], Step [187/225], Training Accuracy: 92.9980%, Training Loss: 0.1921%\n",
      "Epoch [68/300], Step [188/225], Training Accuracy: 92.9854%, Training Loss: 0.1924%\n",
      "Epoch [68/300], Step [189/225], Training Accuracy: 92.9977%, Training Loss: 0.1920%\n",
      "Epoch [68/300], Step [190/225], Training Accuracy: 92.9934%, Training Loss: 0.1923%\n",
      "Epoch [68/300], Step [191/225], Training Accuracy: 92.9974%, Training Loss: 0.1923%\n",
      "Epoch [68/300], Step [192/225], Training Accuracy: 93.0094%, Training Loss: 0.1919%\n",
      "Epoch [68/300], Step [193/225], Training Accuracy: 93.0133%, Training Loss: 0.1918%\n",
      "Epoch [68/300], Step [194/225], Training Accuracy: 93.0010%, Training Loss: 0.1926%\n",
      "Epoch [68/300], Step [195/225], Training Accuracy: 93.0048%, Training Loss: 0.1931%\n",
      "Epoch [68/300], Step [196/225], Training Accuracy: 93.0006%, Training Loss: 0.1936%\n",
      "Epoch [68/300], Step [197/225], Training Accuracy: 93.0124%, Training Loss: 0.1935%\n",
      "Epoch [68/300], Step [198/225], Training Accuracy: 93.0398%, Training Loss: 0.1929%\n",
      "Epoch [68/300], Step [199/225], Training Accuracy: 92.9884%, Training Loss: 0.1937%\n",
      "Epoch [68/300], Step [200/225], Training Accuracy: 92.9922%, Training Loss: 0.1936%\n",
      "Epoch [68/300], Step [201/225], Training Accuracy: 92.9649%, Training Loss: 0.1943%\n",
      "Epoch [68/300], Step [202/225], Training Accuracy: 92.9842%, Training Loss: 0.1937%\n",
      "Epoch [68/300], Step [203/225], Training Accuracy: 92.9880%, Training Loss: 0.1935%\n",
      "Epoch [68/300], Step [204/225], Training Accuracy: 92.9917%, Training Loss: 0.1937%\n",
      "Epoch [68/300], Step [205/225], Training Accuracy: 93.0030%, Training Loss: 0.1935%\n",
      "Epoch [68/300], Step [206/225], Training Accuracy: 92.9991%, Training Loss: 0.1936%\n",
      "Epoch [68/300], Step [207/225], Training Accuracy: 92.9725%, Training Loss: 0.1938%\n",
      "Epoch [68/300], Step [208/225], Training Accuracy: 92.9688%, Training Loss: 0.1941%\n",
      "Epoch [68/300], Step [209/225], Training Accuracy: 92.9575%, Training Loss: 0.1942%\n",
      "Epoch [68/300], Step [210/225], Training Accuracy: 92.9613%, Training Loss: 0.1941%\n",
      "Epoch [68/300], Step [211/225], Training Accuracy: 92.9428%, Training Loss: 0.1942%\n",
      "Epoch [68/300], Step [212/225], Training Accuracy: 92.9393%, Training Loss: 0.1940%\n",
      "Epoch [68/300], Step [213/225], Training Accuracy: 92.9357%, Training Loss: 0.1940%\n",
      "Epoch [68/300], Step [214/225], Training Accuracy: 92.9541%, Training Loss: 0.1937%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/300], Step [215/225], Training Accuracy: 92.9651%, Training Loss: 0.1935%\n",
      "Epoch [68/300], Step [216/225], Training Accuracy: 92.9832%, Training Loss: 0.1930%\n",
      "Epoch [68/300], Step [217/225], Training Accuracy: 92.9724%, Training Loss: 0.1931%\n",
      "Epoch [68/300], Step [218/225], Training Accuracy: 92.9544%, Training Loss: 0.1935%\n",
      "Epoch [68/300], Step [219/225], Training Accuracy: 92.9580%, Training Loss: 0.1936%\n",
      "Epoch [68/300], Step [220/225], Training Accuracy: 92.9616%, Training Loss: 0.1934%\n",
      "Epoch [68/300], Step [221/225], Training Accuracy: 92.9794%, Training Loss: 0.1928%\n",
      "Epoch [68/300], Step [222/225], Training Accuracy: 92.9617%, Training Loss: 0.1934%\n",
      "Epoch [68/300], Step [223/225], Training Accuracy: 92.9442%, Training Loss: 0.1936%\n",
      "Epoch [68/300], Step [224/225], Training Accuracy: 92.9060%, Training Loss: 0.1944%\n",
      "Epoch [68/300], Step [225/225], Training Accuracy: 92.9266%, Training Loss: 0.1942%\n",
      "Epoch [69/300], Step [1/225], Training Accuracy: 90.6250%, Training Loss: 0.1499%\n",
      "Epoch [69/300], Step [2/225], Training Accuracy: 91.4062%, Training Loss: 0.1863%\n",
      "Epoch [69/300], Step [3/225], Training Accuracy: 90.6250%, Training Loss: 0.2827%\n",
      "Epoch [69/300], Step [4/225], Training Accuracy: 91.0156%, Training Loss: 0.2761%\n",
      "Epoch [69/300], Step [5/225], Training Accuracy: 92.1875%, Training Loss: 0.2641%\n",
      "Epoch [69/300], Step [6/225], Training Accuracy: 92.1875%, Training Loss: 0.2408%\n",
      "Epoch [69/300], Step [7/225], Training Accuracy: 93.0804%, Training Loss: 0.2191%\n",
      "Epoch [69/300], Step [8/225], Training Accuracy: 92.5781%, Training Loss: 0.2174%\n",
      "Epoch [69/300], Step [9/225], Training Accuracy: 92.3611%, Training Loss: 0.2181%\n",
      "Epoch [69/300], Step [10/225], Training Accuracy: 92.5000%, Training Loss: 0.2116%\n",
      "Epoch [69/300], Step [11/225], Training Accuracy: 92.3295%, Training Loss: 0.2102%\n",
      "Epoch [69/300], Step [12/225], Training Accuracy: 91.9271%, Training Loss: 0.2144%\n",
      "Epoch [69/300], Step [13/225], Training Accuracy: 92.1875%, Training Loss: 0.2055%\n",
      "Epoch [69/300], Step [14/225], Training Accuracy: 92.4107%, Training Loss: 0.1963%\n",
      "Epoch [69/300], Step [15/225], Training Accuracy: 92.2917%, Training Loss: 0.1941%\n",
      "Epoch [69/300], Step [16/225], Training Accuracy: 92.1875%, Training Loss: 0.1951%\n",
      "Epoch [69/300], Step [17/225], Training Accuracy: 92.3713%, Training Loss: 0.1924%\n",
      "Epoch [69/300], Step [18/225], Training Accuracy: 92.4479%, Training Loss: 0.1929%\n",
      "Epoch [69/300], Step [19/225], Training Accuracy: 92.5987%, Training Loss: 0.1928%\n",
      "Epoch [69/300], Step [20/225], Training Accuracy: 92.8125%, Training Loss: 0.1881%\n",
      "Epoch [69/300], Step [21/225], Training Accuracy: 92.7827%, Training Loss: 0.1892%\n",
      "Epoch [69/300], Step [22/225], Training Accuracy: 92.4716%, Training Loss: 0.1946%\n",
      "Epoch [69/300], Step [23/225], Training Accuracy: 92.4592%, Training Loss: 0.1933%\n",
      "Epoch [69/300], Step [24/225], Training Accuracy: 92.3828%, Training Loss: 0.1947%\n",
      "Epoch [69/300], Step [25/225], Training Accuracy: 92.4375%, Training Loss: 0.1941%\n",
      "Epoch [69/300], Step [26/225], Training Accuracy: 92.5481%, Training Loss: 0.1904%\n",
      "Epoch [69/300], Step [27/225], Training Accuracy: 92.8241%, Training Loss: 0.1850%\n",
      "Epoch [69/300], Step [28/225], Training Accuracy: 92.9129%, Training Loss: 0.1841%\n",
      "Epoch [69/300], Step [29/225], Training Accuracy: 92.7263%, Training Loss: 0.1847%\n",
      "Epoch [69/300], Step [30/225], Training Accuracy: 92.7604%, Training Loss: 0.1871%\n",
      "Epoch [69/300], Step [31/225], Training Accuracy: 92.7419%, Training Loss: 0.1885%\n",
      "Epoch [69/300], Step [32/225], Training Accuracy: 92.7734%, Training Loss: 0.1874%\n",
      "Epoch [69/300], Step [33/225], Training Accuracy: 92.8977%, Training Loss: 0.1849%\n",
      "Epoch [69/300], Step [34/225], Training Accuracy: 92.7390%, Training Loss: 0.1869%\n",
      "Epoch [69/300], Step [35/225], Training Accuracy: 92.8571%, Training Loss: 0.1846%\n",
      "Epoch [69/300], Step [36/225], Training Accuracy: 92.9253%, Training Loss: 0.1846%\n",
      "Epoch [69/300], Step [37/225], Training Accuracy: 92.9054%, Training Loss: 0.1851%\n",
      "Epoch [69/300], Step [38/225], Training Accuracy: 93.0099%, Training Loss: 0.1833%\n",
      "Epoch [69/300], Step [39/225], Training Accuracy: 93.0288%, Training Loss: 0.1828%\n",
      "Epoch [69/300], Step [40/225], Training Accuracy: 93.0469%, Training Loss: 0.1851%\n",
      "Epoch [69/300], Step [41/225], Training Accuracy: 92.9878%, Training Loss: 0.1859%\n",
      "Epoch [69/300], Step [42/225], Training Accuracy: 93.1548%, Training Loss: 0.1826%\n",
      "Epoch [69/300], Step [43/225], Training Accuracy: 93.1323%, Training Loss: 0.1825%\n",
      "Epoch [69/300], Step [44/225], Training Accuracy: 93.1818%, Training Loss: 0.1808%\n",
      "Epoch [69/300], Step [45/225], Training Accuracy: 93.2986%, Training Loss: 0.1781%\n",
      "Epoch [69/300], Step [46/225], Training Accuracy: 93.2745%, Training Loss: 0.1769%\n",
      "Epoch [69/300], Step [47/225], Training Accuracy: 93.1848%, Training Loss: 0.1785%\n",
      "Epoch [69/300], Step [48/225], Training Accuracy: 93.0990%, Training Loss: 0.1802%\n",
      "Epoch [69/300], Step [49/225], Training Accuracy: 93.1122%, Training Loss: 0.1795%\n",
      "Epoch [69/300], Step [50/225], Training Accuracy: 93.0000%, Training Loss: 0.1809%\n",
      "Epoch [69/300], Step [51/225], Training Accuracy: 92.9228%, Training Loss: 0.1822%\n",
      "Epoch [69/300], Step [52/225], Training Accuracy: 92.9387%, Training Loss: 0.1823%\n",
      "Epoch [69/300], Step [53/225], Training Accuracy: 92.9835%, Training Loss: 0.1812%\n",
      "Epoch [69/300], Step [54/225], Training Accuracy: 92.9977%, Training Loss: 0.1819%\n",
      "Epoch [69/300], Step [55/225], Training Accuracy: 93.0114%, Training Loss: 0.1818%\n",
      "Epoch [69/300], Step [56/225], Training Accuracy: 93.0246%, Training Loss: 0.1821%\n",
      "Epoch [69/300], Step [57/225], Training Accuracy: 92.9550%, Training Loss: 0.1842%\n",
      "Epoch [69/300], Step [58/225], Training Accuracy: 92.9688%, Training Loss: 0.1842%\n",
      "Epoch [69/300], Step [59/225], Training Accuracy: 92.9290%, Training Loss: 0.1847%\n",
      "Epoch [69/300], Step [60/225], Training Accuracy: 92.9427%, Training Loss: 0.1837%\n",
      "Epoch [69/300], Step [61/225], Training Accuracy: 92.9559%, Training Loss: 0.1836%\n",
      "Epoch [69/300], Step [62/225], Training Accuracy: 92.9435%, Training Loss: 0.1841%\n",
      "Epoch [69/300], Step [63/225], Training Accuracy: 92.9812%, Training Loss: 0.1835%\n",
      "Epoch [69/300], Step [64/225], Training Accuracy: 92.9688%, Training Loss: 0.1834%\n",
      "Epoch [69/300], Step [65/225], Training Accuracy: 93.0288%, Training Loss: 0.1828%\n",
      "Epoch [69/300], Step [66/225], Training Accuracy: 93.0634%, Training Loss: 0.1823%\n",
      "Epoch [69/300], Step [67/225], Training Accuracy: 93.0970%, Training Loss: 0.1813%\n",
      "Epoch [69/300], Step [68/225], Training Accuracy: 93.1066%, Training Loss: 0.1808%\n",
      "Epoch [69/300], Step [69/225], Training Accuracy: 93.0933%, Training Loss: 0.1812%\n",
      "Epoch [69/300], Step [70/225], Training Accuracy: 93.1027%, Training Loss: 0.1808%\n",
      "Epoch [69/300], Step [71/225], Training Accuracy: 93.1118%, Training Loss: 0.1804%\n",
      "Epoch [69/300], Step [72/225], Training Accuracy: 93.0773%, Training Loss: 0.1806%\n",
      "Epoch [69/300], Step [73/225], Training Accuracy: 93.1079%, Training Loss: 0.1804%\n",
      "Epoch [69/300], Step [74/225], Training Accuracy: 93.0743%, Training Loss: 0.1810%\n",
      "Epoch [69/300], Step [75/225], Training Accuracy: 93.0625%, Training Loss: 0.1818%\n",
      "Epoch [69/300], Step [76/225], Training Accuracy: 93.0715%, Training Loss: 0.1827%\n",
      "Epoch [69/300], Step [77/225], Training Accuracy: 93.0601%, Training Loss: 0.1835%\n",
      "Epoch [69/300], Step [78/225], Training Accuracy: 93.0889%, Training Loss: 0.1832%\n",
      "Epoch [69/300], Step [79/225], Training Accuracy: 93.1369%, Training Loss: 0.1823%\n",
      "Epoch [69/300], Step [80/225], Training Accuracy: 93.1641%, Training Loss: 0.1814%\n",
      "Epoch [69/300], Step [81/225], Training Accuracy: 93.1327%, Training Loss: 0.1822%\n",
      "Epoch [69/300], Step [82/225], Training Accuracy: 93.1402%, Training Loss: 0.1819%\n",
      "Epoch [69/300], Step [83/225], Training Accuracy: 93.1664%, Training Loss: 0.1820%\n",
      "Epoch [69/300], Step [84/225], Training Accuracy: 93.1362%, Training Loss: 0.1817%\n",
      "Epoch [69/300], Step [85/225], Training Accuracy: 93.1801%, Training Loss: 0.1807%\n",
      "Epoch [69/300], Step [86/225], Training Accuracy: 93.2049%, Training Loss: 0.1800%\n",
      "Epoch [69/300], Step [87/225], Training Accuracy: 93.1932%, Training Loss: 0.1808%\n",
      "Epoch [69/300], Step [88/225], Training Accuracy: 93.1818%, Training Loss: 0.1811%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/300], Step [89/225], Training Accuracy: 93.1706%, Training Loss: 0.1808%\n",
      "Epoch [69/300], Step [90/225], Training Accuracy: 93.1771%, Training Loss: 0.1803%\n",
      "Epoch [69/300], Step [91/225], Training Accuracy: 93.2005%, Training Loss: 0.1793%\n",
      "Epoch [69/300], Step [92/225], Training Accuracy: 93.1895%, Training Loss: 0.1793%\n",
      "Epoch [69/300], Step [93/225], Training Accuracy: 93.2292%, Training Loss: 0.1783%\n",
      "Epoch [69/300], Step [94/225], Training Accuracy: 93.2181%, Training Loss: 0.1779%\n",
      "Epoch [69/300], Step [95/225], Training Accuracy: 93.2401%, Training Loss: 0.1772%\n",
      "Epoch [69/300], Step [96/225], Training Accuracy: 93.2943%, Training Loss: 0.1761%\n",
      "Epoch [69/300], Step [97/225], Training Accuracy: 93.2990%, Training Loss: 0.1760%\n",
      "Epoch [69/300], Step [98/225], Training Accuracy: 93.2876%, Training Loss: 0.1771%\n",
      "Epoch [69/300], Step [99/225], Training Accuracy: 93.2765%, Training Loss: 0.1775%\n",
      "Epoch [69/300], Step [100/225], Training Accuracy: 93.2500%, Training Loss: 0.1785%\n",
      "Epoch [69/300], Step [101/225], Training Accuracy: 93.3014%, Training Loss: 0.1773%\n",
      "Epoch [69/300], Step [102/225], Training Accuracy: 93.2445%, Training Loss: 0.1780%\n",
      "Epoch [69/300], Step [103/225], Training Accuracy: 93.2797%, Training Loss: 0.1777%\n",
      "Epoch [69/300], Step [104/225], Training Accuracy: 93.2993%, Training Loss: 0.1774%\n",
      "Epoch [69/300], Step [105/225], Training Accuracy: 93.2738%, Training Loss: 0.1774%\n",
      "Epoch [69/300], Step [106/225], Training Accuracy: 93.3373%, Training Loss: 0.1766%\n",
      "Epoch [69/300], Step [107/225], Training Accuracy: 93.3265%, Training Loss: 0.1765%\n",
      "Epoch [69/300], Step [108/225], Training Accuracy: 93.3015%, Training Loss: 0.1762%\n",
      "Epoch [69/300], Step [109/225], Training Accuracy: 93.2483%, Training Loss: 0.1769%\n",
      "Epoch [69/300], Step [110/225], Training Accuracy: 93.2812%, Training Loss: 0.1763%\n",
      "Epoch [69/300], Step [111/225], Training Accuracy: 93.2714%, Training Loss: 0.1762%\n",
      "Epoch [69/300], Step [112/225], Training Accuracy: 93.2199%, Training Loss: 0.1769%\n",
      "Epoch [69/300], Step [113/225], Training Accuracy: 93.2384%, Training Loss: 0.1765%\n",
      "Epoch [69/300], Step [114/225], Training Accuracy: 93.2155%, Training Loss: 0.1769%\n",
      "Epoch [69/300], Step [115/225], Training Accuracy: 93.2065%, Training Loss: 0.1779%\n",
      "Epoch [69/300], Step [116/225], Training Accuracy: 93.2112%, Training Loss: 0.1780%\n",
      "Epoch [69/300], Step [117/225], Training Accuracy: 93.2559%, Training Loss: 0.1772%\n",
      "Epoch [69/300], Step [118/225], Training Accuracy: 93.2468%, Training Loss: 0.1769%\n",
      "Epoch [69/300], Step [119/225], Training Accuracy: 93.2511%, Training Loss: 0.1761%\n",
      "Epoch [69/300], Step [120/225], Training Accuracy: 93.2422%, Training Loss: 0.1760%\n",
      "Epoch [69/300], Step [121/225], Training Accuracy: 93.2464%, Training Loss: 0.1758%\n",
      "Epoch [69/300], Step [122/225], Training Accuracy: 93.2377%, Training Loss: 0.1772%\n",
      "Epoch [69/300], Step [123/225], Training Accuracy: 93.2419%, Training Loss: 0.1771%\n",
      "Epoch [69/300], Step [124/225], Training Accuracy: 93.2334%, Training Loss: 0.1772%\n",
      "Epoch [69/300], Step [125/225], Training Accuracy: 93.2125%, Training Loss: 0.1782%\n",
      "Epoch [69/300], Step [126/225], Training Accuracy: 93.1920%, Training Loss: 0.1780%\n",
      "Epoch [69/300], Step [127/225], Training Accuracy: 93.1964%, Training Loss: 0.1773%\n",
      "Epoch [69/300], Step [128/225], Training Accuracy: 93.2007%, Training Loss: 0.1769%\n",
      "Epoch [69/300], Step [129/225], Training Accuracy: 93.2413%, Training Loss: 0.1764%\n",
      "Epoch [69/300], Step [130/225], Training Accuracy: 93.2332%, Training Loss: 0.1766%\n",
      "Epoch [69/300], Step [131/225], Training Accuracy: 93.1775%, Training Loss: 0.1777%\n",
      "Epoch [69/300], Step [132/225], Training Accuracy: 93.1463%, Training Loss: 0.1795%\n",
      "Epoch [69/300], Step [133/225], Training Accuracy: 93.1391%, Training Loss: 0.1792%\n",
      "Epoch [69/300], Step [134/225], Training Accuracy: 93.1437%, Training Loss: 0.1789%\n",
      "Epoch [69/300], Step [135/225], Training Accuracy: 93.1366%, Training Loss: 0.1792%\n",
      "Epoch [69/300], Step [136/225], Training Accuracy: 93.1181%, Training Loss: 0.1803%\n",
      "Epoch [69/300], Step [137/225], Training Accuracy: 93.0999%, Training Loss: 0.1808%\n",
      "Epoch [69/300], Step [138/225], Training Accuracy: 93.1273%, Training Loss: 0.1802%\n",
      "Epoch [69/300], Step [139/225], Training Accuracy: 93.1430%, Training Loss: 0.1796%\n",
      "Epoch [69/300], Step [140/225], Training Accuracy: 93.1585%, Training Loss: 0.1799%\n",
      "Epoch [69/300], Step [141/225], Training Accuracy: 93.1738%, Training Loss: 0.1796%\n",
      "Epoch [69/300], Step [142/225], Training Accuracy: 93.1998%, Training Loss: 0.1791%\n",
      "Epoch [69/300], Step [143/225], Training Accuracy: 93.2037%, Training Loss: 0.1788%\n",
      "Epoch [69/300], Step [144/225], Training Accuracy: 93.1858%, Training Loss: 0.1786%\n",
      "Epoch [69/300], Step [145/225], Training Accuracy: 93.1466%, Training Loss: 0.1793%\n",
      "Epoch [69/300], Step [146/225], Training Accuracy: 93.1079%, Training Loss: 0.1796%\n",
      "Epoch [69/300], Step [147/225], Training Accuracy: 93.1229%, Training Loss: 0.1797%\n",
      "Epoch [69/300], Step [148/225], Training Accuracy: 93.1693%, Training Loss: 0.1787%\n",
      "Epoch [69/300], Step [149/225], Training Accuracy: 93.1732%, Training Loss: 0.1787%\n",
      "Epoch [69/300], Step [150/225], Training Accuracy: 93.1667%, Training Loss: 0.1788%\n",
      "Epoch [69/300], Step [151/225], Training Accuracy: 93.1809%, Training Loss: 0.1789%\n",
      "Epoch [69/300], Step [152/225], Training Accuracy: 93.1949%, Training Loss: 0.1788%\n",
      "Epoch [69/300], Step [153/225], Training Accuracy: 93.1577%, Training Loss: 0.1791%\n",
      "Epoch [69/300], Step [154/225], Training Accuracy: 93.1818%, Training Loss: 0.1786%\n",
      "Epoch [69/300], Step [155/225], Training Accuracy: 93.1855%, Training Loss: 0.1784%\n",
      "Epoch [69/300], Step [156/225], Training Accuracy: 93.1991%, Training Loss: 0.1781%\n",
      "Epoch [69/300], Step [157/225], Training Accuracy: 93.1628%, Training Loss: 0.1826%\n",
      "Epoch [69/300], Step [158/225], Training Accuracy: 93.1468%, Training Loss: 0.1827%\n",
      "Epoch [69/300], Step [159/225], Training Accuracy: 93.1407%, Training Loss: 0.1828%\n",
      "Epoch [69/300], Step [160/225], Training Accuracy: 93.0957%, Training Loss: 0.1840%\n",
      "Epoch [69/300], Step [161/225], Training Accuracy: 93.0707%, Training Loss: 0.1847%\n",
      "Epoch [69/300], Step [162/225], Training Accuracy: 93.0941%, Training Loss: 0.1841%\n",
      "Epoch [69/300], Step [163/225], Training Accuracy: 93.0886%, Training Loss: 0.1843%\n",
      "Epoch [69/300], Step [164/225], Training Accuracy: 93.0926%, Training Loss: 0.1838%\n",
      "Epoch [69/300], Step [165/225], Training Accuracy: 93.0966%, Training Loss: 0.1835%\n",
      "Epoch [69/300], Step [166/225], Training Accuracy: 93.0723%, Training Loss: 0.1838%\n",
      "Epoch [69/300], Step [167/225], Training Accuracy: 93.0670%, Training Loss: 0.1838%\n",
      "Epoch [69/300], Step [168/225], Training Accuracy: 93.0246%, Training Loss: 0.1842%\n",
      "Epoch [69/300], Step [169/225], Training Accuracy: 93.0288%, Training Loss: 0.1839%\n",
      "Epoch [69/300], Step [170/225], Training Accuracy: 93.0331%, Training Loss: 0.1837%\n",
      "Epoch [69/300], Step [171/225], Training Accuracy: 93.0373%, Training Loss: 0.1836%\n",
      "Epoch [69/300], Step [172/225], Training Accuracy: 93.0596%, Training Loss: 0.1834%\n",
      "Epoch [69/300], Step [173/225], Training Accuracy: 93.0365%, Training Loss: 0.1834%\n",
      "Epoch [69/300], Step [174/225], Training Accuracy: 93.0496%, Training Loss: 0.1830%\n",
      "Epoch [69/300], Step [175/225], Training Accuracy: 93.0446%, Training Loss: 0.1827%\n",
      "Epoch [69/300], Step [176/225], Training Accuracy: 93.0309%, Training Loss: 0.1825%\n",
      "Epoch [69/300], Step [177/225], Training Accuracy: 93.0261%, Training Loss: 0.1826%\n",
      "Epoch [69/300], Step [178/225], Training Accuracy: 93.0214%, Training Loss: 0.1826%\n",
      "Epoch [69/300], Step [179/225], Training Accuracy: 93.0342%, Training Loss: 0.1821%\n",
      "Epoch [69/300], Step [180/225], Training Accuracy: 93.0295%, Training Loss: 0.1825%\n",
      "Epoch [69/300], Step [181/225], Training Accuracy: 93.0076%, Training Loss: 0.1833%\n",
      "Epoch [69/300], Step [182/225], Training Accuracy: 92.9859%, Training Loss: 0.1834%\n",
      "Epoch [69/300], Step [183/225], Training Accuracy: 92.9816%, Training Loss: 0.1832%\n",
      "Epoch [69/300], Step [184/225], Training Accuracy: 92.9942%, Training Loss: 0.1829%\n",
      "Epoch [69/300], Step [185/225], Training Accuracy: 93.0152%, Training Loss: 0.1826%\n",
      "Epoch [69/300], Step [186/225], Training Accuracy: 93.0108%, Training Loss: 0.1828%\n",
      "Epoch [69/300], Step [187/225], Training Accuracy: 93.0064%, Training Loss: 0.1828%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/300], Step [188/225], Training Accuracy: 92.9937%, Training Loss: 0.1828%\n",
      "Epoch [69/300], Step [189/225], Training Accuracy: 92.9894%, Training Loss: 0.1830%\n",
      "Epoch [69/300], Step [190/225], Training Accuracy: 92.9770%, Training Loss: 0.1833%\n",
      "Epoch [69/300], Step [191/225], Training Accuracy: 92.9647%, Training Loss: 0.1836%\n",
      "Epoch [69/300], Step [192/225], Training Accuracy: 92.9606%, Training Loss: 0.1834%\n",
      "Epoch [69/300], Step [193/225], Training Accuracy: 92.9809%, Training Loss: 0.1832%\n",
      "Epoch [69/300], Step [194/225], Training Accuracy: 92.9849%, Training Loss: 0.1832%\n",
      "Epoch [69/300], Step [195/225], Training Accuracy: 93.0048%, Training Loss: 0.1829%\n",
      "Epoch [69/300], Step [196/225], Training Accuracy: 93.0006%, Training Loss: 0.1832%\n",
      "Epoch [69/300], Step [197/225], Training Accuracy: 92.9965%, Training Loss: 0.1833%\n",
      "Epoch [69/300], Step [198/225], Training Accuracy: 93.0003%, Training Loss: 0.1833%\n",
      "Epoch [69/300], Step [199/225], Training Accuracy: 92.9884%, Training Loss: 0.1836%\n",
      "Epoch [69/300], Step [200/225], Training Accuracy: 93.0078%, Training Loss: 0.1831%\n",
      "Epoch [69/300], Step [201/225], Training Accuracy: 93.0115%, Training Loss: 0.1830%\n",
      "Epoch [69/300], Step [202/225], Training Accuracy: 93.0384%, Training Loss: 0.1826%\n",
      "Epoch [69/300], Step [203/225], Training Accuracy: 93.0573%, Training Loss: 0.1823%\n",
      "Epoch [69/300], Step [204/225], Training Accuracy: 93.0836%, Training Loss: 0.1816%\n",
      "Epoch [69/300], Step [205/225], Training Accuracy: 93.0716%, Training Loss: 0.1818%\n",
      "Epoch [69/300], Step [206/225], Training Accuracy: 93.0901%, Training Loss: 0.1817%\n",
      "Epoch [69/300], Step [207/225], Training Accuracy: 93.0707%, Training Loss: 0.1816%\n",
      "Epoch [69/300], Step [208/225], Training Accuracy: 93.0814%, Training Loss: 0.1814%\n",
      "Epoch [69/300], Step [209/225], Training Accuracy: 93.0697%, Training Loss: 0.1813%\n",
      "Epoch [69/300], Step [210/225], Training Accuracy: 93.0729%, Training Loss: 0.1811%\n",
      "Epoch [69/300], Step [211/225], Training Accuracy: 93.0613%, Training Loss: 0.1813%\n",
      "Epoch [69/300], Step [212/225], Training Accuracy: 93.0572%, Training Loss: 0.1813%\n",
      "Epoch [69/300], Step [213/225], Training Accuracy: 93.0678%, Training Loss: 0.1810%\n",
      "Epoch [69/300], Step [214/225], Training Accuracy: 93.0783%, Training Loss: 0.1807%\n",
      "Epoch [69/300], Step [215/225], Training Accuracy: 93.0887%, Training Loss: 0.1804%\n",
      "Epoch [69/300], Step [216/225], Training Accuracy: 93.0700%, Training Loss: 0.1807%\n",
      "Epoch [69/300], Step [217/225], Training Accuracy: 93.0660%, Training Loss: 0.1808%\n",
      "Epoch [69/300], Step [218/225], Training Accuracy: 93.0548%, Training Loss: 0.1808%\n",
      "Epoch [69/300], Step [219/225], Training Accuracy: 93.0579%, Training Loss: 0.1808%\n",
      "Epoch [69/300], Step [220/225], Training Accuracy: 93.0682%, Training Loss: 0.1803%\n",
      "Epoch [69/300], Step [221/225], Training Accuracy: 93.0925%, Training Loss: 0.1798%\n",
      "Epoch [69/300], Step [222/225], Training Accuracy: 93.1025%, Training Loss: 0.1796%\n",
      "Epoch [69/300], Step [223/225], Training Accuracy: 93.1194%, Training Loss: 0.1793%\n",
      "Epoch [69/300], Step [224/225], Training Accuracy: 93.1292%, Training Loss: 0.1790%\n",
      "Epoch [69/300], Step [225/225], Training Accuracy: 93.1212%, Training Loss: 0.1789%\n",
      "Epoch [70/300], Step [1/225], Training Accuracy: 92.1875%, Training Loss: 0.1556%\n",
      "Epoch [70/300], Step [2/225], Training Accuracy: 91.4062%, Training Loss: 0.1931%\n",
      "Epoch [70/300], Step [3/225], Training Accuracy: 91.6667%, Training Loss: 0.1782%\n",
      "Epoch [70/300], Step [4/225], Training Accuracy: 91.4062%, Training Loss: 0.1927%\n",
      "Epoch [70/300], Step [5/225], Training Accuracy: 91.5625%, Training Loss: 0.1895%\n",
      "Epoch [70/300], Step [6/225], Training Accuracy: 91.6667%, Training Loss: 0.1921%\n",
      "Epoch [70/300], Step [7/225], Training Accuracy: 91.5179%, Training Loss: 0.1892%\n",
      "Epoch [70/300], Step [8/225], Training Accuracy: 91.4062%, Training Loss: 0.2020%\n",
      "Epoch [70/300], Step [9/225], Training Accuracy: 91.3194%, Training Loss: 0.2009%\n",
      "Epoch [70/300], Step [10/225], Training Accuracy: 91.4062%, Training Loss: 0.1984%\n",
      "Epoch [70/300], Step [11/225], Training Accuracy: 91.3352%, Training Loss: 0.1983%\n",
      "Epoch [70/300], Step [12/225], Training Accuracy: 91.7969%, Training Loss: 0.1923%\n",
      "Epoch [70/300], Step [13/225], Training Accuracy: 92.3077%, Training Loss: 0.1811%\n",
      "Epoch [70/300], Step [14/225], Training Accuracy: 92.5223%, Training Loss: 0.1763%\n",
      "Epoch [70/300], Step [15/225], Training Accuracy: 92.6042%, Training Loss: 0.1774%\n",
      "Epoch [70/300], Step [16/225], Training Accuracy: 92.7734%, Training Loss: 0.1778%\n",
      "Epoch [70/300], Step [17/225], Training Accuracy: 93.0147%, Training Loss: 0.1728%\n",
      "Epoch [70/300], Step [18/225], Training Accuracy: 93.0556%, Training Loss: 0.1726%\n",
      "Epoch [70/300], Step [19/225], Training Accuracy: 93.1743%, Training Loss: 0.1703%\n",
      "Epoch [70/300], Step [20/225], Training Accuracy: 93.4375%, Training Loss: 0.1668%\n",
      "Epoch [70/300], Step [21/225], Training Accuracy: 93.4524%, Training Loss: 0.1663%\n",
      "Epoch [70/300], Step [22/225], Training Accuracy: 93.6080%, Training Loss: 0.1642%\n",
      "Epoch [70/300], Step [23/225], Training Accuracy: 93.7500%, Training Loss: 0.1652%\n",
      "Epoch [70/300], Step [24/225], Training Accuracy: 93.6198%, Training Loss: 0.1688%\n",
      "Epoch [70/300], Step [25/225], Training Accuracy: 93.5000%, Training Loss: 0.1739%\n",
      "Epoch [70/300], Step [26/225], Training Accuracy: 93.5096%, Training Loss: 0.1708%\n",
      "Epoch [70/300], Step [27/225], Training Accuracy: 93.6921%, Training Loss: 0.1669%\n",
      "Epoch [70/300], Step [28/225], Training Accuracy: 93.7500%, Training Loss: 0.1647%\n",
      "Epoch [70/300], Step [29/225], Training Accuracy: 93.6422%, Training Loss: 0.1658%\n",
      "Epoch [70/300], Step [30/225], Training Accuracy: 93.7500%, Training Loss: 0.1640%\n",
      "Epoch [70/300], Step [31/225], Training Accuracy: 93.5988%, Training Loss: 0.1676%\n",
      "Epoch [70/300], Step [32/225], Training Accuracy: 93.5547%, Training Loss: 0.1684%\n",
      "Epoch [70/300], Step [33/225], Training Accuracy: 93.6080%, Training Loss: 0.1685%\n",
      "Epoch [70/300], Step [34/225], Training Accuracy: 93.5202%, Training Loss: 0.1717%\n",
      "Epoch [70/300], Step [35/225], Training Accuracy: 93.6161%, Training Loss: 0.1704%\n",
      "Epoch [70/300], Step [36/225], Training Accuracy: 93.5764%, Training Loss: 0.1714%\n",
      "Epoch [70/300], Step [37/225], Training Accuracy: 93.6233%, Training Loss: 0.1697%\n",
      "Epoch [70/300], Step [38/225], Training Accuracy: 93.5033%, Training Loss: 0.1719%\n",
      "Epoch [70/300], Step [39/225], Training Accuracy: 93.4696%, Training Loss: 0.1722%\n",
      "Epoch [70/300], Step [40/225], Training Accuracy: 93.5156%, Training Loss: 0.1716%\n",
      "Epoch [70/300], Step [41/225], Training Accuracy: 93.4070%, Training Loss: 0.1729%\n",
      "Epoch [70/300], Step [42/225], Training Accuracy: 93.5268%, Training Loss: 0.1704%\n",
      "Epoch [70/300], Step [43/225], Training Accuracy: 93.5683%, Training Loss: 0.1695%\n",
      "Epoch [70/300], Step [44/225], Training Accuracy: 93.6080%, Training Loss: 0.1685%\n",
      "Epoch [70/300], Step [45/225], Training Accuracy: 93.5764%, Training Loss: 0.1681%\n",
      "Epoch [70/300], Step [46/225], Training Accuracy: 93.5122%, Training Loss: 0.1679%\n",
      "Epoch [70/300], Step [47/225], Training Accuracy: 93.5505%, Training Loss: 0.1687%\n",
      "Epoch [70/300], Step [48/225], Training Accuracy: 93.5547%, Training Loss: 0.1686%\n",
      "Epoch [70/300], Step [49/225], Training Accuracy: 93.5268%, Training Loss: 0.1684%\n",
      "Epoch [70/300], Step [50/225], Training Accuracy: 93.5000%, Training Loss: 0.1681%\n",
      "Epoch [70/300], Step [51/225], Training Accuracy: 93.5662%, Training Loss: 0.1670%\n",
      "Epoch [70/300], Step [52/225], Training Accuracy: 93.5397%, Training Loss: 0.1676%\n",
      "Epoch [70/300], Step [53/225], Training Accuracy: 93.5436%, Training Loss: 0.1678%\n",
      "Epoch [70/300], Step [54/225], Training Accuracy: 93.6053%, Training Loss: 0.1665%\n",
      "Epoch [70/300], Step [55/225], Training Accuracy: 93.5795%, Training Loss: 0.1677%\n",
      "Epoch [70/300], Step [56/225], Training Accuracy: 93.6105%, Training Loss: 0.1673%\n",
      "Epoch [70/300], Step [57/225], Training Accuracy: 93.5307%, Training Loss: 0.1696%\n",
      "Epoch [70/300], Step [58/225], Training Accuracy: 93.5345%, Training Loss: 0.1704%\n",
      "Epoch [70/300], Step [59/225], Training Accuracy: 93.5646%, Training Loss: 0.1695%\n",
      "Epoch [70/300], Step [60/225], Training Accuracy: 93.5417%, Training Loss: 0.1692%\n",
      "Epoch [70/300], Step [61/225], Training Accuracy: 93.5451%, Training Loss: 0.1690%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/300], Step [62/225], Training Accuracy: 93.6240%, Training Loss: 0.1671%\n",
      "Epoch [70/300], Step [63/225], Training Accuracy: 93.6260%, Training Loss: 0.1673%\n",
      "Epoch [70/300], Step [64/225], Training Accuracy: 93.6523%, Training Loss: 0.1665%\n",
      "Epoch [70/300], Step [65/225], Training Accuracy: 93.5817%, Training Loss: 0.1674%\n",
      "Epoch [70/300], Step [66/225], Training Accuracy: 93.6316%, Training Loss: 0.1674%\n",
      "Epoch [70/300], Step [67/225], Training Accuracy: 93.6567%, Training Loss: 0.1670%\n",
      "Epoch [70/300], Step [68/225], Training Accuracy: 93.6811%, Training Loss: 0.1673%\n",
      "Epoch [70/300], Step [69/225], Training Accuracy: 93.6594%, Training Loss: 0.1672%\n",
      "Epoch [70/300], Step [70/225], Training Accuracy: 93.6830%, Training Loss: 0.1661%\n",
      "Epoch [70/300], Step [71/225], Training Accuracy: 93.7060%, Training Loss: 0.1661%\n",
      "Epoch [70/300], Step [72/225], Training Accuracy: 93.7066%, Training Loss: 0.1663%\n",
      "Epoch [70/300], Step [73/225], Training Accuracy: 93.7286%, Training Loss: 0.1662%\n",
      "Epoch [70/300], Step [74/225], Training Accuracy: 93.7078%, Training Loss: 0.1660%\n",
      "Epoch [70/300], Step [75/225], Training Accuracy: 93.6875%, Training Loss: 0.1676%\n",
      "Epoch [70/300], Step [76/225], Training Accuracy: 93.6061%, Training Loss: 0.1693%\n",
      "Epoch [70/300], Step [77/225], Training Accuracy: 93.6485%, Training Loss: 0.1684%\n",
      "Epoch [70/300], Step [78/225], Training Accuracy: 93.5697%, Training Loss: 0.1701%\n",
      "Epoch [70/300], Step [79/225], Training Accuracy: 93.5918%, Training Loss: 0.1692%\n",
      "Epoch [70/300], Step [80/225], Training Accuracy: 93.5938%, Training Loss: 0.1685%\n",
      "Epoch [70/300], Step [81/225], Training Accuracy: 93.5957%, Training Loss: 0.1683%\n",
      "Epoch [70/300], Step [82/225], Training Accuracy: 93.6357%, Training Loss: 0.1675%\n",
      "Epoch [70/300], Step [83/225], Training Accuracy: 93.6747%, Training Loss: 0.1671%\n",
      "Epoch [70/300], Step [84/225], Training Accuracy: 93.6198%, Training Loss: 0.1683%\n",
      "Epoch [70/300], Step [85/225], Training Accuracy: 93.6213%, Training Loss: 0.1676%\n",
      "Epoch [70/300], Step [86/225], Training Accuracy: 93.6228%, Training Loss: 0.1678%\n",
      "Epoch [70/300], Step [87/225], Training Accuracy: 93.6063%, Training Loss: 0.1681%\n",
      "Epoch [70/300], Step [88/225], Training Accuracy: 93.4837%, Training Loss: 0.1699%\n",
      "Epoch [70/300], Step [89/225], Training Accuracy: 93.5218%, Training Loss: 0.1693%\n",
      "Epoch [70/300], Step [90/225], Training Accuracy: 93.5417%, Training Loss: 0.1689%\n",
      "Epoch [70/300], Step [91/225], Training Accuracy: 93.5096%, Training Loss: 0.1693%\n",
      "Epoch [70/300], Step [92/225], Training Accuracy: 93.4952%, Training Loss: 0.1692%\n",
      "Epoch [70/300], Step [93/225], Training Accuracy: 93.4980%, Training Loss: 0.1687%\n",
      "Epoch [70/300], Step [94/225], Training Accuracy: 93.5505%, Training Loss: 0.1683%\n",
      "Epoch [70/300], Step [95/225], Training Accuracy: 93.5362%, Training Loss: 0.1690%\n",
      "Epoch [70/300], Step [96/225], Training Accuracy: 93.5059%, Training Loss: 0.1691%\n",
      "Epoch [70/300], Step [97/225], Training Accuracy: 93.5084%, Training Loss: 0.1690%\n",
      "Epoch [70/300], Step [98/225], Training Accuracy: 93.4949%, Training Loss: 0.1695%\n",
      "Epoch [70/300], Step [99/225], Training Accuracy: 93.5133%, Training Loss: 0.1702%\n",
      "Epoch [70/300], Step [100/225], Training Accuracy: 93.4375%, Training Loss: 0.1708%\n",
      "Epoch [70/300], Step [101/225], Training Accuracy: 93.4251%, Training Loss: 0.1711%\n",
      "Epoch [70/300], Step [102/225], Training Accuracy: 93.4130%, Training Loss: 0.1723%\n",
      "Epoch [70/300], Step [103/225], Training Accuracy: 93.4314%, Training Loss: 0.1715%\n",
      "Epoch [70/300], Step [104/225], Training Accuracy: 93.3894%, Training Loss: 0.1723%\n",
      "Epoch [70/300], Step [105/225], Training Accuracy: 93.4077%, Training Loss: 0.1716%\n",
      "Epoch [70/300], Step [106/225], Training Accuracy: 93.4110%, Training Loss: 0.1716%\n",
      "Epoch [70/300], Step [107/225], Training Accuracy: 93.3995%, Training Loss: 0.1724%\n",
      "Epoch [70/300], Step [108/225], Training Accuracy: 93.4317%, Training Loss: 0.1721%\n",
      "Epoch [70/300], Step [109/225], Training Accuracy: 93.4203%, Training Loss: 0.1723%\n",
      "Epoch [70/300], Step [110/225], Training Accuracy: 93.4801%, Training Loss: 0.1715%\n",
      "Epoch [70/300], Step [111/225], Training Accuracy: 93.5248%, Training Loss: 0.1708%\n",
      "Epoch [70/300], Step [112/225], Training Accuracy: 93.5407%, Training Loss: 0.1710%\n",
      "Epoch [70/300], Step [113/225], Training Accuracy: 93.5426%, Training Loss: 0.1705%\n",
      "Epoch [70/300], Step [114/225], Training Accuracy: 93.5581%, Training Loss: 0.1700%\n",
      "Epoch [70/300], Step [115/225], Training Accuracy: 93.5598%, Training Loss: 0.1697%\n",
      "Epoch [70/300], Step [116/225], Training Accuracy: 93.5614%, Training Loss: 0.1695%\n",
      "Epoch [70/300], Step [117/225], Training Accuracy: 93.5897%, Training Loss: 0.1690%\n",
      "Epoch [70/300], Step [118/225], Training Accuracy: 93.6176%, Training Loss: 0.1686%\n",
      "Epoch [70/300], Step [119/225], Training Accuracy: 93.6056%, Training Loss: 0.1691%\n",
      "Epoch [70/300], Step [120/225], Training Accuracy: 93.6198%, Training Loss: 0.1689%\n",
      "Epoch [70/300], Step [121/225], Training Accuracy: 93.6080%, Training Loss: 0.1689%\n",
      "Epoch [70/300], Step [122/225], Training Accuracy: 93.6475%, Training Loss: 0.1684%\n",
      "Epoch [70/300], Step [123/225], Training Accuracy: 93.6357%, Training Loss: 0.1684%\n",
      "Epoch [70/300], Step [124/225], Training Accuracy: 93.6114%, Training Loss: 0.1686%\n",
      "Epoch [70/300], Step [125/225], Training Accuracy: 93.6250%, Training Loss: 0.1683%\n",
      "Epoch [70/300], Step [126/225], Training Accuracy: 93.6136%, Training Loss: 0.1683%\n",
      "Epoch [70/300], Step [127/225], Training Accuracy: 93.6147%, Training Loss: 0.1688%\n",
      "Epoch [70/300], Step [128/225], Training Accuracy: 93.6035%, Training Loss: 0.1690%\n",
      "Epoch [70/300], Step [129/225], Training Accuracy: 93.6289%, Training Loss: 0.1685%\n",
      "Epoch [70/300], Step [130/225], Training Accuracy: 93.6418%, Training Loss: 0.1681%\n",
      "Epoch [70/300], Step [131/225], Training Accuracy: 93.6188%, Training Loss: 0.1693%\n",
      "Epoch [70/300], Step [132/225], Training Accuracy: 93.6080%, Training Loss: 0.1692%\n",
      "Epoch [70/300], Step [133/225], Training Accuracy: 93.6090%, Training Loss: 0.1692%\n",
      "Epoch [70/300], Step [134/225], Training Accuracy: 93.5518%, Training Loss: 0.1703%\n",
      "Epoch [70/300], Step [135/225], Training Accuracy: 93.5648%, Training Loss: 0.1698%\n",
      "Epoch [70/300], Step [136/225], Training Accuracy: 93.5432%, Training Loss: 0.1701%\n",
      "Epoch [70/300], Step [137/225], Training Accuracy: 93.5105%, Training Loss: 0.1702%\n",
      "Epoch [70/300], Step [138/225], Training Accuracy: 93.5236%, Training Loss: 0.1700%\n",
      "Epoch [70/300], Step [139/225], Training Accuracy: 93.5252%, Training Loss: 0.1696%\n",
      "Epoch [70/300], Step [140/225], Training Accuracy: 93.5268%, Training Loss: 0.1697%\n",
      "Epoch [70/300], Step [141/225], Training Accuracy: 93.5284%, Training Loss: 0.1695%\n",
      "Epoch [70/300], Step [142/225], Training Accuracy: 93.5629%, Training Loss: 0.1690%\n",
      "Epoch [70/300], Step [143/225], Training Accuracy: 93.5642%, Training Loss: 0.1691%\n",
      "Epoch [70/300], Step [144/225], Training Accuracy: 93.5764%, Training Loss: 0.1686%\n",
      "Epoch [70/300], Step [145/225], Training Accuracy: 93.5668%, Training Loss: 0.1687%\n",
      "Epoch [70/300], Step [146/225], Training Accuracy: 93.5788%, Training Loss: 0.1683%\n",
      "Epoch [70/300], Step [147/225], Training Accuracy: 93.5587%, Training Loss: 0.1683%\n",
      "Epoch [70/300], Step [148/225], Training Accuracy: 93.5916%, Training Loss: 0.1676%\n",
      "Epoch [70/300], Step [149/225], Training Accuracy: 93.5927%, Training Loss: 0.1678%\n",
      "Epoch [70/300], Step [150/225], Training Accuracy: 93.6250%, Training Loss: 0.1673%\n",
      "Epoch [70/300], Step [151/225], Training Accuracy: 93.6569%, Training Loss: 0.1665%\n",
      "Epoch [70/300], Step [152/225], Training Accuracy: 93.6575%, Training Loss: 0.1664%\n",
      "Epoch [70/300], Step [153/225], Training Accuracy: 93.6172%, Training Loss: 0.1667%\n",
      "Epoch [70/300], Step [154/225], Training Accuracy: 93.6181%, Training Loss: 0.1664%\n",
      "Epoch [70/300], Step [155/225], Training Accuracy: 93.6190%, Training Loss: 0.1665%\n",
      "Epoch [70/300], Step [156/225], Training Accuracy: 93.6398%, Training Loss: 0.1662%\n",
      "Epoch [70/300], Step [157/225], Training Accuracy: 93.6107%, Training Loss: 0.1669%\n",
      "Epoch [70/300], Step [158/225], Training Accuracy: 93.6313%, Training Loss: 0.1666%\n",
      "Epoch [70/300], Step [159/225], Training Accuracy: 93.6616%, Training Loss: 0.1661%\n",
      "Epoch [70/300], Step [160/225], Training Accuracy: 93.6621%, Training Loss: 0.1664%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/300], Step [161/225], Training Accuracy: 93.6530%, Training Loss: 0.1667%\n",
      "Epoch [70/300], Step [162/225], Training Accuracy: 93.6535%, Training Loss: 0.1667%\n",
      "Epoch [70/300], Step [163/225], Training Accuracy: 93.6541%, Training Loss: 0.1665%\n",
      "Epoch [70/300], Step [164/225], Training Accuracy: 93.6738%, Training Loss: 0.1659%\n",
      "Epoch [70/300], Step [165/225], Training Accuracy: 93.6458%, Training Loss: 0.1661%\n",
      "Epoch [70/300], Step [166/225], Training Accuracy: 93.6653%, Training Loss: 0.1661%\n",
      "Epoch [70/300], Step [167/225], Training Accuracy: 93.6845%, Training Loss: 0.1656%\n",
      "Epoch [70/300], Step [168/225], Training Accuracy: 93.7035%, Training Loss: 0.1652%\n",
      "Epoch [70/300], Step [169/225], Training Accuracy: 93.7130%, Training Loss: 0.1648%\n",
      "Epoch [70/300], Step [170/225], Training Accuracy: 93.7224%, Training Loss: 0.1646%\n",
      "Epoch [70/300], Step [171/225], Training Accuracy: 93.7500%, Training Loss: 0.1642%\n",
      "Epoch [70/300], Step [172/225], Training Accuracy: 93.7227%, Training Loss: 0.1648%\n",
      "Epoch [70/300], Step [173/225], Training Accuracy: 93.7048%, Training Loss: 0.1650%\n",
      "Epoch [70/300], Step [174/225], Training Accuracy: 93.7051%, Training Loss: 0.1652%\n",
      "Epoch [70/300], Step [175/225], Training Accuracy: 93.7232%, Training Loss: 0.1647%\n",
      "Epoch [70/300], Step [176/225], Training Accuracy: 93.7322%, Training Loss: 0.1645%\n",
      "Epoch [70/300], Step [177/225], Training Accuracy: 93.7412%, Training Loss: 0.1646%\n",
      "Epoch [70/300], Step [178/225], Training Accuracy: 93.7237%, Training Loss: 0.1652%\n",
      "Epoch [70/300], Step [179/225], Training Accuracy: 93.7325%, Training Loss: 0.1648%\n",
      "Epoch [70/300], Step [180/225], Training Accuracy: 93.7413%, Training Loss: 0.1648%\n",
      "Epoch [70/300], Step [181/225], Training Accuracy: 93.7327%, Training Loss: 0.1646%\n",
      "Epoch [70/300], Step [182/225], Training Accuracy: 93.7071%, Training Loss: 0.1652%\n",
      "Epoch [70/300], Step [183/225], Training Accuracy: 93.7244%, Training Loss: 0.1648%\n",
      "Epoch [70/300], Step [184/225], Training Accuracy: 93.7415%, Training Loss: 0.1644%\n",
      "Epoch [70/300], Step [185/225], Training Accuracy: 93.7500%, Training Loss: 0.1648%\n",
      "Epoch [70/300], Step [186/225], Training Accuracy: 93.7668%, Training Loss: 0.1643%\n",
      "Epoch [70/300], Step [187/225], Training Accuracy: 93.7751%, Training Loss: 0.1640%\n",
      "Epoch [70/300], Step [188/225], Training Accuracy: 93.7666%, Training Loss: 0.1639%\n",
      "Epoch [70/300], Step [189/225], Training Accuracy: 93.7913%, Training Loss: 0.1634%\n",
      "Epoch [70/300], Step [190/225], Training Accuracy: 93.7829%, Training Loss: 0.1636%\n",
      "Epoch [70/300], Step [191/225], Training Accuracy: 93.7664%, Training Loss: 0.1637%\n",
      "Epoch [70/300], Step [192/225], Training Accuracy: 93.7744%, Training Loss: 0.1637%\n",
      "Epoch [70/300], Step [193/225], Training Accuracy: 93.7662%, Training Loss: 0.1636%\n",
      "Epoch [70/300], Step [194/225], Training Accuracy: 93.7339%, Training Loss: 0.1641%\n",
      "Epoch [70/300], Step [195/225], Training Accuracy: 93.7260%, Training Loss: 0.1642%\n",
      "Epoch [70/300], Step [196/225], Training Accuracy: 93.7101%, Training Loss: 0.1643%\n",
      "Epoch [70/300], Step [197/225], Training Accuracy: 93.7103%, Training Loss: 0.1642%\n",
      "Epoch [70/300], Step [198/225], Training Accuracy: 93.7184%, Training Loss: 0.1641%\n",
      "Epoch [70/300], Step [199/225], Training Accuracy: 93.7029%, Training Loss: 0.1642%\n",
      "Epoch [70/300], Step [200/225], Training Accuracy: 93.7031%, Training Loss: 0.1640%\n",
      "Epoch [70/300], Step [201/225], Training Accuracy: 93.6800%, Training Loss: 0.1649%\n",
      "Epoch [70/300], Step [202/225], Training Accuracy: 93.6804%, Training Loss: 0.1649%\n",
      "Epoch [70/300], Step [203/225], Training Accuracy: 93.6807%, Training Loss: 0.1650%\n",
      "Epoch [70/300], Step [204/225], Training Accuracy: 93.7040%, Training Loss: 0.1646%\n",
      "Epoch [70/300], Step [205/225], Training Accuracy: 93.7271%, Training Loss: 0.1641%\n",
      "Epoch [70/300], Step [206/225], Training Accuracy: 93.7272%, Training Loss: 0.1643%\n",
      "Epoch [70/300], Step [207/225], Training Accuracy: 93.7425%, Training Loss: 0.1642%\n",
      "Epoch [70/300], Step [208/225], Training Accuracy: 93.7500%, Training Loss: 0.1640%\n",
      "Epoch [70/300], Step [209/225], Training Accuracy: 93.7350%, Training Loss: 0.1641%\n",
      "Epoch [70/300], Step [210/225], Training Accuracy: 93.7351%, Training Loss: 0.1642%\n",
      "Epoch [70/300], Step [211/225], Training Accuracy: 93.7278%, Training Loss: 0.1644%\n",
      "Epoch [70/300], Step [212/225], Training Accuracy: 93.7353%, Training Loss: 0.1643%\n",
      "Epoch [70/300], Step [213/225], Training Accuracy: 93.7573%, Training Loss: 0.1639%\n",
      "Epoch [70/300], Step [214/225], Training Accuracy: 93.7500%, Training Loss: 0.1644%\n",
      "Epoch [70/300], Step [215/225], Training Accuracy: 93.7791%, Training Loss: 0.1639%\n",
      "Epoch [70/300], Step [216/225], Training Accuracy: 93.7789%, Training Loss: 0.1638%\n",
      "Epoch [70/300], Step [217/225], Training Accuracy: 93.7716%, Training Loss: 0.1638%\n",
      "Epoch [70/300], Step [218/225], Training Accuracy: 93.7787%, Training Loss: 0.1639%\n",
      "Epoch [70/300], Step [219/225], Training Accuracy: 93.7785%, Training Loss: 0.1636%\n",
      "Epoch [70/300], Step [220/225], Training Accuracy: 93.7926%, Training Loss: 0.1635%\n",
      "Epoch [70/300], Step [221/225], Training Accuracy: 93.7924%, Training Loss: 0.1633%\n",
      "Epoch [70/300], Step [222/225], Training Accuracy: 93.8133%, Training Loss: 0.1630%\n",
      "Epoch [70/300], Step [223/225], Training Accuracy: 93.8271%, Training Loss: 0.1629%\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    correct=0\n",
    "    total=0\n",
    "    running_loss = 0\n",
    "    for i, (X, Y) in enumerate(train_loader):\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, Y)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        #scheduler.step() \n",
    "        #print(scheduler.get_last_lr()[0])\n",
    "      \n",
    "        optimizer.step()\n",
    "        scheduler.step() \n",
    "        #print(optimizer.param_groups[0][\"lr\"])\n",
    "        \n",
    "        _, predicted = outputs.max(1)\n",
    "        total += Y.size(0)\n",
    "        correct += predicted.eq(Y).sum().item()\n",
    "        running_loss += loss.item()\n",
    "        accu=100.*correct/total\n",
    "        train_loss = running_loss/(i+1)\n",
    "        print ('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.4f}%, Training Loss: {:.4f}%'.format(epoch+1, num_epochs, i+1, total_step, accu, train_loss))\n",
    "    \n",
    "   \n",
    "        #writer.add_scalar(f'train/accuracy', accu, epoch)\n",
    "        #writer.add_scalar(f'train/loss', train_loss, epoch)\n",
    "        writer.add_scalars(f'train/accuracy_loss', {\n",
    "            'accuracy': accu,\n",
    "            'loss': train_loss,\n",
    "        }, epoch)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d5f4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for X, Y in test_loader:\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += Y.size(0)\n",
    "        correct += (predicted == Y).sum().item()\n",
    "\n",
    "    print('Test Accuracy : {} %'.format(100 * correct / total))\n",
    "\n",
    "# Save the model checkpoint\n",
    "#torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce71586",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
