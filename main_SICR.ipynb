{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce5e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a57cd07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "f7d5557b",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c0bd2f",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa75f0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"data/64_640data/train_set.csv\",header=None).to_numpy()\n",
    "train_label = pd.read_csv(\"data/64_640data/train_label.csv\",header=None).to_numpy()\n",
    "test_set = pd.read_csv(\"data/64_640data/test_set.csv\",header=None).to_numpy()\n",
    "test_label = pd.read_csv(\"data/64_640data/test_label.csv\",header=None).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b59e7337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1439, 40960) (1439, 1) (360, 40960) (360, 1)\n"
     ]
    }
   ],
   "source": [
    "#delet first row data\n",
    "train_set = train_set[1:]\n",
    "train_label = train_label[1:]\n",
    "test_set = test_set[1:]\n",
    "test_label = test_label[1:]\n",
    "print(train_set.shape, train_label.shape, test_set.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46a572a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.reshape((-1,1,64,640))\n",
    "test_set = test_set.reshape((-1,1,64,640))\n",
    "train_label = train_label.reshape(-1)\n",
    "test_label = test_label.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "241affd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1439, 1, 64, 640) (1439,) (360, 1, 64, 640) (360,)\n"
     ]
    }
   ],
   "source": [
    "print(train_set.shape, train_label.shape, test_set.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e578922",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_tensor = Tensor(train_set) \n",
    "train_label_tensor = Tensor(train_label).type(torch.LongTensor)\n",
    "\n",
    "train_dataset = TensorDataset(train_set_tensor,train_label_tensor) \n",
    "train_loader = DataLoader(train_dataset, batch_size=64) \n",
    "\n",
    "test_set_tensor = Tensor(test_set) \n",
    "test_label_tensor = Tensor(test_label).type(torch.LongTensor)\n",
    "\n",
    "test_dataset = TensorDataset(test_set_tensor,test_label_tensor) \n",
    "test_loader = DataLoader(test_dataset, batch_size=64) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb6fb04",
   "metadata": {},
   "source": [
    "# construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cad89f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "F1 = 8\n",
    "D = 2\n",
    "F2 = 16\n",
    "drop_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cf0da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dWithConstraint(nn.Conv2d):\n",
    "    def __init__(self, *args, max_norm=1, **kwargs):\n",
    "        self.max_norm = max_norm\n",
    "        super(Conv2dWithConstraint, self).__init__(*args, **kwargs)\n",
    "    def forward(self, x):\n",
    "        self.weight.data = torch.renorm(self.weight.data, p=2, dim=0, maxnorm=self.max_norm)\n",
    "        return super(Conv2dWithConstraint, self).forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8210abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalEncoder_EEGNet(nn.Module):\n",
    "    def __init__(self, fs, num_ch, num_time):\n",
    "        super(LocalEncoder_EEGNet, self).__init__()\n",
    "        self.c1 = nn.Conv2d(in_channels=1, out_channels=F1, kernel_size=(1, int(fs / 2)), stride=1, bias=False,\n",
    "                            padding=(0, (int(fs / 2) // 2) - 1))  # []\n",
    "        self.b1 = nn.BatchNorm2d(F1)\n",
    "        self.c2 = Conv2dWithConstraint(in_channels=F1, out_channels=F1 * D, kernel_size=(num_ch, 1), stride=1,\n",
    "                                       bias=False, groups=F1, padding=(0, 0), max_norm=1)\n",
    "        self.b2 = nn.BatchNorm2d(F1 * D)\n",
    "        self.p2 = nn.AvgPool2d(kernel_size=(1, 4), stride=(1, 4))\n",
    "        self.d2 = nn.Dropout(drop_prob)\n",
    "\n",
    "    def forward(self, input):\n",
    "        h1 = self.b1(self.c1(input))\n",
    "        h2 = self.d2(self.p2(F.elu(self.b2(self.c2(h1)))))\n",
    "        return h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd22a138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_enc = LocalEncoder_EEGNet(fs=160, num_ch=64, num_time = 640)\n",
    "# a = torch.randn((10,1,64,640))\n",
    "# b = local_enc(a)\n",
    "# b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b969b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decomposer(nn.Module):\n",
    "    def __init__(self, nfeat):\n",
    "        super(Decomposer, self).__init__()\n",
    "        self.nfeat = nfeat\n",
    "        self.embed_layer = nn.Sequential(nn.Conv2d(nfeat, nfeat*2, kernel_size=1, bias=False),\n",
    "                                         nn.BatchNorm2d(nfeat*2), nn.ELU(), nn.Dropout())\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embed_layer(x)\n",
    "        #print(embedded.shape)\n",
    "        rele, irre = torch.split(embedded, [int(self.nfeat), int(self.nfeat)], dim=1)\n",
    "\n",
    "        return rele, irre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb63db7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decomposer = Decomposer(16)\n",
    "# c, d = decomposer(b)\n",
    "# print(c.shape,d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57348d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalEncoder_EEGNet(nn.Module):\n",
    "    def __init__(self, num_ch, num_time, nfeatl):\n",
    "        super(GlobalEncoder_EEGNet, self).__init__()\n",
    "        self.c3 = nn.Conv2d(in_channels=nfeatl, out_channels=F1 * D, kernel_size=(1, 16), stride=1, bias=False,\n",
    "                            groups=(nfeatl), padding=(0, 16 // 2))\n",
    "        self.b3 = nn.BatchNorm2d(F1 * D)\n",
    "        self.p3 = nn.AvgPool2d(kernel_size=(1, 8), stride=(1, 8))\n",
    "        self.d3 = nn.Dropout(drop_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h3 = self.d3(self.p3(F.elu(self.b3(self.c3(x)))))\n",
    "        h3_ = torch.flatten(h3, start_dim=1)\n",
    "        return h3_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33d1ac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_enc = GlobalEncoder_EEGNet(64,640,16)\n",
    "# e = global_enc(c)\n",
    "# e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1da9ff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, nfeatr):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.dense1 = nn.Linear(nfeatr, 4)\n",
    "\n",
    "    def forward(self, latent):\n",
    "        out = self.dense1(latent)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e1e4973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = Classifier(320)\n",
    "# f = classifier(e)\n",
    "# f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69145031",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradReverse(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Extension of grad reverse layer\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, constant):\n",
    "        ctx.constant = constant\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        grad_output = grad_output.neg() * ctx.constant\n",
    "        return grad_output, None\n",
    "\n",
    "    def grad_reverse(x, constant):\n",
    "        return GradReverse.apply(x, constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36476248",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MINE(nn.Module):\n",
    "    def __init__(self, nfeatr, nfeati):\n",
    "        super(MINE, self).__init__()\n",
    "        self.fc1_x = nn.Linear(nfeatr, int(nfeatr/16))\n",
    "        self.bn1_x = nn.BatchNorm1d(int(nfeatr/16))\n",
    "        self.fc1_y = nn.Linear(nfeati, int(nfeati/16))\n",
    "        self.bn1_y = nn.BatchNorm1d(int(nfeati/16))\n",
    "\n",
    "        self.fc2 = nn.Linear(int(nfeati/16) + int(nfeatr/16),int(nfeati/16) + int(nfeatr/16))\n",
    "        self.bn2 = nn.BatchNorm1d(int(nfeati/16) + int(nfeatr/16))\n",
    "\n",
    "        self.fc3 = nn.Linear(int(nfeati/16) + int(nfeatr/16), 1)\n",
    "\n",
    "    def forward(self, x, y, lambd=1):\n",
    "        # GRL\n",
    "        x = GradReverse.grad_reverse(x, lambd)\n",
    "        y = GradReverse.grad_reverse(y, lambd)\n",
    "        #print(x.shape,y.shape)\n",
    "        #x = x.reshape(10,-1)\n",
    "        #y = y.reshape(10,-1)\n",
    "        x = F.dropout(self.bn1_x(self.fc1_x(x)))\n",
    "        y = F.dropout(self.bn1_y(self.fc1_y(y)))\n",
    "\n",
    "        h = F.elu(torch.cat((x,y), dim=-1))\n",
    "        h = F.elu(self.bn2(self.fc2(h)))\n",
    "        h = self.fc3(h)\n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd2e30b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mine = MINE(nfeatr=int(16 * 15), nfeati=int(16 * 15))\n",
    "# g = mine(c,d)\n",
    "# g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6c10b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Global_disc_EEGNet(nn.Module):\n",
    "    def __init__(self, nfeatl, nfeatg, num_ch):\n",
    "        super(Global_disc_EEGNet, self).__init__()\n",
    "        self.local_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=nfeatl, out_channels=F1 * D, kernel_size=(1, 16), stride=1, bias=False,\n",
    "                      groups=(nfeatl), padding=(0, 16 // 2)),\n",
    "            nn.BatchNorm2d(F1 * D),\n",
    "            nn.AvgPool2d(kernel_size=(1, 8), stride=(1, 8)),\n",
    "            nn.Dropout(drop_prob)\n",
    "        )\n",
    "        self.dense1 = nn.Linear(int(nfeatg*2), 1)\n",
    "        self.drop1 = nn.Dropout()\n",
    "\n",
    "    def forward(self, localf, globalf):\n",
    "        localff = self.local_conv(localf)\n",
    "        localff = localff.view(localf.shape[0], -1)\n",
    "\n",
    "        concat = torch.cat((localff, globalf), dim=-1)\n",
    "        #print(concat.shape)\n",
    "        out = self.drop1(self.dense1(concat))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e03a89c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_disc = Global_disc_EEGNet(nfeatl=16, nfeatg=32, num_ch=64)\n",
    "# h = global_disc(c,e)\n",
    "# h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54248a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Local_disc_EEGNet(nn.Module):\n",
    "    def __init__(self, nfeatl, nfeatg, nfeatl2, num_ch):\n",
    "        super(Local_disc_EEGNet, self).__init__()\n",
    "        self.num_ch = num_ch\n",
    "        self.nfeatl = nfeatl\n",
    "        self.nfeatl2 = nfeatl2\n",
    "        self.nfeatg = nfeatg\n",
    "\n",
    "        self.drop1 = nn.Dropout()\n",
    "        self.conv = nn.Conv2d(int(self.nfeatg+self.nfeatl), 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, localf, globalf):\n",
    "        #print(localf.shape,globalf.shape)\n",
    "        # Concat-and-convolve architecture\n",
    "        globalff = globalf.unsqueeze(2).unsqueeze(3)\n",
    "        #print(globalff.shape)\n",
    "        globalff = globalff.repeat(1,1,1,self.nfeatl2)\n",
    "        concat = torch.cat((localf, globalff), dim=1)\n",
    "        out = self.drop1(self.conv(concat))\n",
    "        out = out.view(out.shape[0],-1)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e4d365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_disc = Local_disc_EEGNet(nfeatl=16, nfeatg=32, nfeatl2=15, num_ch=64)\n",
    "# i = local_disc(c,e)\n",
    "# i.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f553f3",
   "metadata": {},
   "source": [
    "# function and model define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8205512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Hyperparameter \"\"\"\n",
    "lr = 1e-3\n",
    "n_class = 4\n",
    "drop = 0.5\n",
    "total_epoch = 300\n",
    "w_decay = 0.05\n",
    "alpha = 0.5\n",
    "beta = 0.3\n",
    "gamma = 0.5\n",
    "bs = 40\n",
    "fs = 160\n",
    "num_ch = 64\n",
    "num_time = 64\n",
    "nfeatl = 16\n",
    "nfeatg = 320\n",
    "nfeatl2 = 159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24272d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_enc = LocalEncoder_EEGNet(fs=fs, num_ch=num_ch, num_time=num_time).to(device)\n",
    "global_enc = GlobalEncoder_EEGNet(num_ch=num_ch, num_time=num_time, nfeatl=nfeatl).to(device)\n",
    "local_disc = Local_disc_EEGNet(nfeatl=nfeatl, nfeatg=nfeatg, nfeatl2=nfeatl2, num_ch=num_ch).to(device)\n",
    "global_disc = Global_disc_EEGNet(nfeatl=nfeatl, nfeatg=nfeatg, num_ch=num_ch).to(device)\n",
    "decomposer = Decomposer(nfeatl).to(device)\n",
    "mine = MINE(nfeatr=int(nfeatl * nfeatl2), nfeati=int(nfeatl * nfeatl2)).to(device)\n",
    "classifier = Classifier(nfeatg).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fbf3ea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_criterion = nn.CrossEntropyLoss().cuda()\n",
    "parameters = list(local_enc.parameters()) + list(global_enc.parameters()) + list(local_disc.parameters()) + list(\n",
    "    global_disc.parameters()) + list(classifier.parameters()) + list(mine.parameters()) + list(decomposer.parameters())\n",
    "opt = torch.optim.RAdam(parameters, lr=lr, weight_decay=w_decay)\n",
    "scheduler = lr_scheduler.ExponentialLR(opt, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9462c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_JSD_MI(joint, marginal, mean=False):\n",
    "    joint = (torch.log(torch.tensor(2.0)) - F.softplus(-joint))\n",
    "    marginal = (F.softplus(-marginal)+marginal - torch.log(torch.tensor(2.0)))\n",
    "\n",
    "    out = joint - marginal\n",
    "    if mean:\n",
    "        out = out.mean()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8525ecd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Step [1/23], Training Accuracy: 28.1250%, Training Loss: 0.7802%\n",
      "Epoch [1/300], Step [2/23], Training Accuracy: 28.1250%, Training Loss: 0.7511%\n",
      "Epoch [1/300], Step [3/23], Training Accuracy: 26.5625%, Training Loss: 0.7630%\n",
      "Epoch [1/300], Step [4/23], Training Accuracy: 24.2188%, Training Loss: 0.7591%\n",
      "Epoch [1/300], Step [5/23], Training Accuracy: 25.3125%, Training Loss: 0.7602%\n",
      "Epoch [1/300], Step [6/23], Training Accuracy: 25.2604%, Training Loss: 0.7703%\n",
      "Epoch [1/300], Step [7/23], Training Accuracy: 25.2232%, Training Loss: 0.7727%\n",
      "Epoch [1/300], Step [8/23], Training Accuracy: 25.9766%, Training Loss: 0.7701%\n",
      "Epoch [1/300], Step [9/23], Training Accuracy: 26.9097%, Training Loss: 0.7727%\n",
      "Epoch [1/300], Step [10/23], Training Accuracy: 25.7812%, Training Loss: 0.7754%\n",
      "Epoch [1/300], Step [11/23], Training Accuracy: 25.1420%, Training Loss: 0.7753%\n",
      "Epoch [1/300], Step [12/23], Training Accuracy: 24.4792%, Training Loss: 0.7750%\n",
      "Epoch [1/300], Step [13/23], Training Accuracy: 24.3990%, Training Loss: 0.7793%\n",
      "Epoch [1/300], Step [14/23], Training Accuracy: 24.4420%, Training Loss: 0.7774%\n",
      "Epoch [1/300], Step [15/23], Training Accuracy: 24.5833%, Training Loss: 0.7781%\n",
      "Epoch [1/300], Step [16/23], Training Accuracy: 24.6094%, Training Loss: 0.7762%\n",
      "Epoch [1/300], Step [17/23], Training Accuracy: 24.7243%, Training Loss: 0.7763%\n",
      "Epoch [1/300], Step [18/23], Training Accuracy: 24.3924%, Training Loss: 0.7754%\n",
      "Epoch [1/300], Step [19/23], Training Accuracy: 24.8355%, Training Loss: 0.7734%\n",
      "Epoch [1/300], Step [20/23], Training Accuracy: 24.7656%, Training Loss: 0.7726%\n",
      "Epoch [1/300], Step [21/23], Training Accuracy: 24.4792%, Training Loss: 0.7737%\n",
      "Epoch [1/300], Step [22/23], Training Accuracy: 24.6449%, Training Loss: 0.7742%\n",
      "Epoch [1/300], Step [23/23], Training Accuracy: 24.2530%, Training Loss: 0.7756%\n",
      "Epoch [2/300], Step [1/23], Training Accuracy: 32.8125%, Training Loss: 0.7769%\n",
      "Epoch [2/300], Step [2/23], Training Accuracy: 32.0312%, Training Loss: 0.7562%\n",
      "Epoch [2/300], Step [3/23], Training Accuracy: 28.6458%, Training Loss: 0.7608%\n",
      "Epoch [2/300], Step [4/23], Training Accuracy: 28.1250%, Training Loss: 0.7569%\n",
      "Epoch [2/300], Step [5/23], Training Accuracy: 26.5625%, Training Loss: 0.7642%\n",
      "Epoch [2/300], Step [6/23], Training Accuracy: 25.2604%, Training Loss: 0.7610%\n",
      "Epoch [2/300], Step [7/23], Training Accuracy: 25.0000%, Training Loss: 0.7651%\n",
      "Epoch [2/300], Step [8/23], Training Accuracy: 25.1953%, Training Loss: 0.7616%\n",
      "Epoch [2/300], Step [9/23], Training Accuracy: 26.3889%, Training Loss: 0.7614%\n",
      "Epoch [2/300], Step [10/23], Training Accuracy: 25.6250%, Training Loss: 0.7674%\n",
      "Epoch [2/300], Step [11/23], Training Accuracy: 25.4261%, Training Loss: 0.7670%\n",
      "Epoch [2/300], Step [12/23], Training Accuracy: 25.9115%, Training Loss: 0.7649%\n",
      "Epoch [2/300], Step [13/23], Training Accuracy: 25.4808%, Training Loss: 0.7686%\n",
      "Epoch [2/300], Step [14/23], Training Accuracy: 25.1116%, Training Loss: 0.7678%\n",
      "Epoch [2/300], Step [15/23], Training Accuracy: 24.5833%, Training Loss: 0.7699%\n",
      "Epoch [2/300], Step [16/23], Training Accuracy: 24.6094%, Training Loss: 0.7696%\n",
      "Epoch [2/300], Step [17/23], Training Accuracy: 25.2757%, Training Loss: 0.7669%\n",
      "Epoch [2/300], Step [18/23], Training Accuracy: 25.5208%, Training Loss: 0.7684%\n",
      "Epoch [2/300], Step [19/23], Training Accuracy: 25.4934%, Training Loss: 0.7668%\n",
      "Epoch [2/300], Step [20/23], Training Accuracy: 25.6250%, Training Loss: 0.7651%\n",
      "Epoch [2/300], Step [21/23], Training Accuracy: 25.9673%, Training Loss: 0.7631%\n",
      "Epoch [2/300], Step [22/23], Training Accuracy: 25.4261%, Training Loss: 0.7643%\n",
      "Epoch [2/300], Step [23/23], Training Accuracy: 25.3648%, Training Loss: 0.7637%\n",
      "Epoch [3/300], Step [1/23], Training Accuracy: 21.8750%, Training Loss: 0.7202%\n",
      "Epoch [3/300], Step [2/23], Training Accuracy: 23.4375%, Training Loss: 0.7402%\n",
      "Epoch [3/300], Step [3/23], Training Accuracy: 25.5208%, Training Loss: 0.7401%\n",
      "Epoch [3/300], Step [4/23], Training Accuracy: 25.3906%, Training Loss: 0.7424%\n",
      "Epoch [3/300], Step [5/23], Training Accuracy: 25.6250%, Training Loss: 0.7428%\n",
      "Epoch [3/300], Step [6/23], Training Accuracy: 26.0417%, Training Loss: 0.7418%\n",
      "Epoch [3/300], Step [7/23], Training Accuracy: 26.5625%, Training Loss: 0.7433%\n",
      "Epoch [3/300], Step [8/23], Training Accuracy: 26.5625%, Training Loss: 0.7428%\n",
      "Epoch [3/300], Step [9/23], Training Accuracy: 26.7361%, Training Loss: 0.7442%\n",
      "Epoch [3/300], Step [10/23], Training Accuracy: 26.8750%, Training Loss: 0.7445%\n",
      "Epoch [3/300], Step [11/23], Training Accuracy: 26.8466%, Training Loss: 0.7422%\n",
      "Epoch [3/300], Step [12/23], Training Accuracy: 27.2135%, Training Loss: 0.7410%\n",
      "Epoch [3/300], Step [13/23], Training Accuracy: 26.4423%, Training Loss: 0.7447%\n",
      "Epoch [3/300], Step [14/23], Training Accuracy: 26.4509%, Training Loss: 0.7442%\n",
      "Epoch [3/300], Step [15/23], Training Accuracy: 26.1458%, Training Loss: 0.7455%\n",
      "Epoch [3/300], Step [16/23], Training Accuracy: 25.9766%, Training Loss: 0.7467%\n",
      "Epoch [3/300], Step [17/23], Training Accuracy: 26.1029%, Training Loss: 0.7479%\n",
      "Epoch [3/300], Step [18/23], Training Accuracy: 25.8681%, Training Loss: 0.7488%\n",
      "Epoch [3/300], Step [19/23], Training Accuracy: 25.9868%, Training Loss: 0.7471%\n",
      "Epoch [3/300], Step [20/23], Training Accuracy: 26.0938%, Training Loss: 0.7468%\n",
      "Epoch [3/300], Step [21/23], Training Accuracy: 25.5952%, Training Loss: 0.7472%\n",
      "Epoch [3/300], Step [22/23], Training Accuracy: 25.6392%, Training Loss: 0.7471%\n",
      "Epoch [3/300], Step [23/23], Training Accuracy: 25.7123%, Training Loss: 0.7473%\n",
      "Epoch [4/300], Step [1/23], Training Accuracy: 32.8125%, Training Loss: 0.7665%\n",
      "Epoch [4/300], Step [2/23], Training Accuracy: 26.5625%, Training Loss: 0.7668%\n",
      "Epoch [4/300], Step [3/23], Training Accuracy: 29.1667%, Training Loss: 0.7567%\n",
      "Epoch [4/300], Step [4/23], Training Accuracy: 29.6875%, Training Loss: 0.7545%\n",
      "Epoch [4/300], Step [5/23], Training Accuracy: 32.1875%, Training Loss: 0.7449%\n",
      "Epoch [4/300], Step [6/23], Training Accuracy: 30.7292%, Training Loss: 0.7456%\n",
      "Epoch [4/300], Step [7/23], Training Accuracy: 29.4643%, Training Loss: 0.7470%\n",
      "Epoch [4/300], Step [8/23], Training Accuracy: 28.7109%, Training Loss: 0.7470%\n",
      "Epoch [4/300], Step [9/23], Training Accuracy: 28.9931%, Training Loss: 0.7441%\n",
      "Epoch [4/300], Step [10/23], Training Accuracy: 27.8125%, Training Loss: 0.7461%\n",
      "Epoch [4/300], Step [11/23], Training Accuracy: 28.1250%, Training Loss: 0.7452%\n",
      "Epoch [4/300], Step [12/23], Training Accuracy: 28.2552%, Training Loss: 0.7443%\n",
      "Epoch [4/300], Step [13/23], Training Accuracy: 27.5240%, Training Loss: 0.7466%\n",
      "Epoch [4/300], Step [14/23], Training Accuracy: 27.5670%, Training Loss: 0.7472%\n",
      "Epoch [4/300], Step [15/23], Training Accuracy: 27.2917%, Training Loss: 0.7488%\n",
      "Epoch [4/300], Step [16/23], Training Accuracy: 27.0508%, Training Loss: 0.7505%\n",
      "Epoch [4/300], Step [17/23], Training Accuracy: 27.3897%, Training Loss: 0.7519%\n",
      "Epoch [4/300], Step [18/23], Training Accuracy: 27.0833%, Training Loss: 0.7534%\n",
      "Epoch [4/300], Step [19/23], Training Accuracy: 27.5493%, Training Loss: 0.7518%\n",
      "Epoch [4/300], Step [20/23], Training Accuracy: 27.7344%, Training Loss: 0.7517%\n",
      "Epoch [4/300], Step [21/23], Training Accuracy: 27.6786%, Training Loss: 0.7492%\n",
      "Epoch [4/300], Step [22/23], Training Accuracy: 27.6989%, Training Loss: 0.7490%\n",
      "Epoch [4/300], Step [23/23], Training Accuracy: 27.5191%, Training Loss: 0.7471%\n",
      "Epoch [5/300], Step [1/23], Training Accuracy: 34.3750%, Training Loss: 0.7062%\n",
      "Epoch [5/300], Step [2/23], Training Accuracy: 28.1250%, Training Loss: 0.7116%\n",
      "Epoch [5/300], Step [3/23], Training Accuracy: 27.0833%, Training Loss: 0.7291%\n",
      "Epoch [5/300], Step [4/23], Training Accuracy: 28.1250%, Training Loss: 0.7240%\n",
      "Epoch [5/300], Step [5/23], Training Accuracy: 26.5625%, Training Loss: 0.7275%\n",
      "Epoch [5/300], Step [6/23], Training Accuracy: 26.3021%, Training Loss: 0.7315%\n",
      "Epoch [5/300], Step [7/23], Training Accuracy: 26.1161%, Training Loss: 0.7302%\n",
      "Epoch [5/300], Step [8/23], Training Accuracy: 25.5859%, Training Loss: 0.7334%\n",
      "Epoch [5/300], Step [9/23], Training Accuracy: 25.6944%, Training Loss: 0.7354%\n",
      "Epoch [5/300], Step [10/23], Training Accuracy: 25.9375%, Training Loss: 0.7351%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/300], Step [11/23], Training Accuracy: 26.2784%, Training Loss: 0.7341%\n",
      "Epoch [5/300], Step [12/23], Training Accuracy: 26.9531%, Training Loss: 0.7353%\n",
      "Epoch [5/300], Step [13/23], Training Accuracy: 27.2837%, Training Loss: 0.7368%\n",
      "Epoch [5/300], Step [14/23], Training Accuracy: 27.6786%, Training Loss: 0.7350%\n",
      "Epoch [5/300], Step [15/23], Training Accuracy: 27.3958%, Training Loss: 0.7366%\n",
      "Epoch [5/300], Step [16/23], Training Accuracy: 27.9297%, Training Loss: 0.7348%\n",
      "Epoch [5/300], Step [17/23], Training Accuracy: 27.8493%, Training Loss: 0.7343%\n",
      "Epoch [5/300], Step [18/23], Training Accuracy: 27.6042%, Training Loss: 0.7350%\n",
      "Epoch [5/300], Step [19/23], Training Accuracy: 27.6316%, Training Loss: 0.7329%\n",
      "Epoch [5/300], Step [20/23], Training Accuracy: 27.5000%, Training Loss: 0.7322%\n",
      "Epoch [5/300], Step [21/23], Training Accuracy: 27.4554%, Training Loss: 0.7341%\n",
      "Epoch [5/300], Step [22/23], Training Accuracy: 27.6989%, Training Loss: 0.7328%\n",
      "Epoch [5/300], Step [23/23], Training Accuracy: 27.4496%, Training Loss: 0.7327%\n",
      "Epoch [6/300], Step [1/23], Training Accuracy: 28.1250%, Training Loss: 0.7182%\n",
      "Epoch [6/300], Step [2/23], Training Accuracy: 32.8125%, Training Loss: 0.7172%\n",
      "Epoch [6/300], Step [3/23], Training Accuracy: 31.7708%, Training Loss: 0.7252%\n",
      "Epoch [6/300], Step [4/23], Training Accuracy: 30.8594%, Training Loss: 0.7213%\n",
      "Epoch [6/300], Step [5/23], Training Accuracy: 30.0000%, Training Loss: 0.7224%\n",
      "Epoch [6/300], Step [6/23], Training Accuracy: 30.2083%, Training Loss: 0.7268%\n",
      "Epoch [6/300], Step [7/23], Training Accuracy: 30.3571%, Training Loss: 0.7302%\n",
      "Epoch [6/300], Step [8/23], Training Accuracy: 30.0781%, Training Loss: 0.7283%\n",
      "Epoch [6/300], Step [9/23], Training Accuracy: 30.0347%, Training Loss: 0.7260%\n",
      "Epoch [6/300], Step [10/23], Training Accuracy: 29.8438%, Training Loss: 0.7272%\n",
      "Epoch [6/300], Step [11/23], Training Accuracy: 30.3977%, Training Loss: 0.7251%\n",
      "Epoch [6/300], Step [12/23], Training Accuracy: 30.7292%, Training Loss: 0.7263%\n",
      "Epoch [6/300], Step [13/23], Training Accuracy: 31.1298%, Training Loss: 0.7240%\n",
      "Epoch [6/300], Step [14/23], Training Accuracy: 30.8036%, Training Loss: 0.7225%\n",
      "Epoch [6/300], Step [15/23], Training Accuracy: 29.7917%, Training Loss: 0.7231%\n",
      "Epoch [6/300], Step [16/23], Training Accuracy: 29.8828%, Training Loss: 0.7237%\n",
      "Epoch [6/300], Step [17/23], Training Accuracy: 30.0551%, Training Loss: 0.7236%\n",
      "Epoch [6/300], Step [18/23], Training Accuracy: 29.9479%, Training Loss: 0.7245%\n",
      "Epoch [6/300], Step [19/23], Training Accuracy: 30.0987%, Training Loss: 0.7235%\n",
      "Epoch [6/300], Step [20/23], Training Accuracy: 29.9219%, Training Loss: 0.7220%\n",
      "Epoch [6/300], Step [21/23], Training Accuracy: 30.2827%, Training Loss: 0.7212%\n",
      "Epoch [6/300], Step [22/23], Training Accuracy: 29.6875%, Training Loss: 0.7216%\n",
      "Epoch [6/300], Step [23/23], Training Accuracy: 29.4649%, Training Loss: 0.7224%\n",
      "Epoch [7/300], Step [1/23], Training Accuracy: 23.4375%, Training Loss: 0.7112%\n",
      "Epoch [7/300], Step [2/23], Training Accuracy: 29.6875%, Training Loss: 0.7114%\n",
      "Epoch [7/300], Step [3/23], Training Accuracy: 29.1667%, Training Loss: 0.7037%\n",
      "Epoch [7/300], Step [4/23], Training Accuracy: 28.9062%, Training Loss: 0.6962%\n",
      "Epoch [7/300], Step [5/23], Training Accuracy: 29.6875%, Training Loss: 0.6986%\n",
      "Epoch [7/300], Step [6/23], Training Accuracy: 30.4688%, Training Loss: 0.7027%\n",
      "Epoch [7/300], Step [7/23], Training Accuracy: 30.5804%, Training Loss: 0.7044%\n",
      "Epoch [7/300], Step [8/23], Training Accuracy: 30.4688%, Training Loss: 0.7030%\n",
      "Epoch [7/300], Step [9/23], Training Accuracy: 31.0764%, Training Loss: 0.7012%\n",
      "Epoch [7/300], Step [10/23], Training Accuracy: 32.1875%, Training Loss: 0.7052%\n",
      "Epoch [7/300], Step [11/23], Training Accuracy: 33.0966%, Training Loss: 0.7059%\n",
      "Epoch [7/300], Step [12/23], Training Accuracy: 33.3333%, Training Loss: 0.7046%\n",
      "Epoch [7/300], Step [13/23], Training Accuracy: 33.2933%, Training Loss: 0.7033%\n",
      "Epoch [7/300], Step [14/23], Training Accuracy: 33.3705%, Training Loss: 0.7035%\n",
      "Epoch [7/300], Step [15/23], Training Accuracy: 33.2292%, Training Loss: 0.7052%\n",
      "Epoch [7/300], Step [16/23], Training Accuracy: 33.1055%, Training Loss: 0.7066%\n",
      "Epoch [7/300], Step [17/23], Training Accuracy: 32.8125%, Training Loss: 0.7065%\n",
      "Epoch [7/300], Step [18/23], Training Accuracy: 32.3785%, Training Loss: 0.7070%\n",
      "Epoch [7/300], Step [19/23], Training Accuracy: 32.4013%, Training Loss: 0.7064%\n",
      "Epoch [7/300], Step [20/23], Training Accuracy: 32.6562%, Training Loss: 0.7060%\n",
      "Epoch [7/300], Step [21/23], Training Accuracy: 32.5893%, Training Loss: 0.7070%\n",
      "Epoch [7/300], Step [22/23], Training Accuracy: 32.5284%, Training Loss: 0.7066%\n",
      "Epoch [7/300], Step [23/23], Training Accuracy: 32.4531%, Training Loss: 0.7056%\n",
      "Epoch [8/300], Step [1/23], Training Accuracy: 25.0000%, Training Loss: 0.6934%\n",
      "Epoch [8/300], Step [2/23], Training Accuracy: 25.7812%, Training Loss: 0.6969%\n",
      "Epoch [8/300], Step [3/23], Training Accuracy: 30.2083%, Training Loss: 0.6969%\n",
      "Epoch [8/300], Step [4/23], Training Accuracy: 30.0781%, Training Loss: 0.6956%\n",
      "Epoch [8/300], Step [5/23], Training Accuracy: 33.7500%, Training Loss: 0.6900%\n",
      "Epoch [8/300], Step [6/23], Training Accuracy: 33.5938%, Training Loss: 0.6978%\n",
      "Epoch [8/300], Step [7/23], Training Accuracy: 31.6964%, Training Loss: 0.7034%\n",
      "Epoch [8/300], Step [8/23], Training Accuracy: 31.8359%, Training Loss: 0.7019%\n",
      "Epoch [8/300], Step [9/23], Training Accuracy: 32.2917%, Training Loss: 0.7012%\n",
      "Epoch [8/300], Step [10/23], Training Accuracy: 30.9375%, Training Loss: 0.7048%\n",
      "Epoch [8/300], Step [11/23], Training Accuracy: 31.6761%, Training Loss: 0.7038%\n",
      "Epoch [8/300], Step [12/23], Training Accuracy: 31.5104%, Training Loss: 0.7035%\n",
      "Epoch [8/300], Step [13/23], Training Accuracy: 31.4904%, Training Loss: 0.7049%\n",
      "Epoch [8/300], Step [14/23], Training Accuracy: 31.3616%, Training Loss: 0.7058%\n",
      "Epoch [8/300], Step [15/23], Training Accuracy: 31.6667%, Training Loss: 0.7044%\n",
      "Epoch [8/300], Step [16/23], Training Accuracy: 31.8359%, Training Loss: 0.7050%\n",
      "Epoch [8/300], Step [17/23], Training Accuracy: 32.2610%, Training Loss: 0.7043%\n",
      "Epoch [8/300], Step [18/23], Training Accuracy: 32.4653%, Training Loss: 0.7032%\n",
      "Epoch [8/300], Step [19/23], Training Accuracy: 31.9079%, Training Loss: 0.7042%\n",
      "Epoch [8/300], Step [20/23], Training Accuracy: 32.4219%, Training Loss: 0.7028%\n",
      "Epoch [8/300], Step [21/23], Training Accuracy: 32.4405%, Training Loss: 0.7023%\n",
      "Epoch [8/300], Step [22/23], Training Accuracy: 32.5994%, Training Loss: 0.7026%\n",
      "Epoch [8/300], Step [23/23], Training Accuracy: 32.4531%, Training Loss: 0.7025%\n",
      "Epoch [9/300], Step [1/23], Training Accuracy: 28.1250%, Training Loss: 0.6875%\n",
      "Epoch [9/300], Step [2/23], Training Accuracy: 32.8125%, Training Loss: 0.6864%\n",
      "Epoch [9/300], Step [3/23], Training Accuracy: 35.9375%, Training Loss: 0.6831%\n",
      "Epoch [9/300], Step [4/23], Training Accuracy: 34.7656%, Training Loss: 0.6869%\n",
      "Epoch [9/300], Step [5/23], Training Accuracy: 36.8750%, Training Loss: 0.6822%\n",
      "Epoch [9/300], Step [6/23], Training Accuracy: 35.9375%, Training Loss: 0.6850%\n",
      "Epoch [9/300], Step [7/23], Training Accuracy: 35.0446%, Training Loss: 0.6853%\n",
      "Epoch [9/300], Step [8/23], Training Accuracy: 35.7422%, Training Loss: 0.6837%\n",
      "Epoch [9/300], Step [9/23], Training Accuracy: 36.6319%, Training Loss: 0.6842%\n",
      "Epoch [9/300], Step [10/23], Training Accuracy: 37.8125%, Training Loss: 0.6852%\n",
      "Epoch [9/300], Step [11/23], Training Accuracy: 37.3580%, Training Loss: 0.6872%\n",
      "Epoch [9/300], Step [12/23], Training Accuracy: 36.4583%, Training Loss: 0.6898%\n",
      "Epoch [9/300], Step [13/23], Training Accuracy: 36.4183%, Training Loss: 0.6901%\n",
      "Epoch [9/300], Step [14/23], Training Accuracy: 36.7188%, Training Loss: 0.6905%\n",
      "Epoch [9/300], Step [15/23], Training Accuracy: 37.5000%, Training Loss: 0.6899%\n",
      "Epoch [9/300], Step [16/23], Training Accuracy: 36.8164%, Training Loss: 0.6912%\n",
      "Epoch [9/300], Step [17/23], Training Accuracy: 36.4890%, Training Loss: 0.6909%\n",
      "Epoch [9/300], Step [18/23], Training Accuracy: 36.4583%, Training Loss: 0.6912%\n",
      "Epoch [9/300], Step [19/23], Training Accuracy: 36.5132%, Training Loss: 0.6891%\n",
      "Epoch [9/300], Step [20/23], Training Accuracy: 36.7969%, Training Loss: 0.6888%\n",
      "Epoch [9/300], Step [21/23], Training Accuracy: 36.9048%, Training Loss: 0.6880%\n",
      "Epoch [9/300], Step [22/23], Training Accuracy: 36.3636%, Training Loss: 0.6890%\n",
      "Epoch [9/300], Step [23/23], Training Accuracy: 36.1362%, Training Loss: 0.6903%\n",
      "Epoch [10/300], Step [1/23], Training Accuracy: 39.0625%, Training Loss: 0.6906%\n",
      "Epoch [10/300], Step [2/23], Training Accuracy: 34.3750%, Training Loss: 0.6949%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/300], Step [3/23], Training Accuracy: 36.9792%, Training Loss: 0.6828%\n",
      "Epoch [10/300], Step [4/23], Training Accuracy: 35.9375%, Training Loss: 0.6794%\n",
      "Epoch [10/300], Step [5/23], Training Accuracy: 38.1250%, Training Loss: 0.6753%\n",
      "Epoch [10/300], Step [6/23], Training Accuracy: 38.5417%, Training Loss: 0.6825%\n",
      "Epoch [10/300], Step [7/23], Training Accuracy: 37.5000%, Training Loss: 0.6833%\n",
      "Epoch [10/300], Step [8/23], Training Accuracy: 37.5000%, Training Loss: 0.6835%\n",
      "Epoch [10/300], Step [9/23], Training Accuracy: 37.5000%, Training Loss: 0.6830%\n",
      "Epoch [10/300], Step [10/23], Training Accuracy: 37.8125%, Training Loss: 0.6820%\n",
      "Epoch [10/300], Step [11/23], Training Accuracy: 37.0739%, Training Loss: 0.6825%\n",
      "Epoch [10/300], Step [12/23], Training Accuracy: 36.5885%, Training Loss: 0.6851%\n",
      "Epoch [10/300], Step [13/23], Training Accuracy: 36.2981%, Training Loss: 0.6851%\n",
      "Epoch [10/300], Step [14/23], Training Accuracy: 36.1607%, Training Loss: 0.6867%\n",
      "Epoch [10/300], Step [15/23], Training Accuracy: 35.8333%, Training Loss: 0.6879%\n",
      "Epoch [10/300], Step [16/23], Training Accuracy: 36.0352%, Training Loss: 0.6881%\n",
      "Epoch [10/300], Step [17/23], Training Accuracy: 36.2132%, Training Loss: 0.6865%\n",
      "Epoch [10/300], Step [18/23], Training Accuracy: 36.4583%, Training Loss: 0.6859%\n",
      "Epoch [10/300], Step [19/23], Training Accuracy: 36.3487%, Training Loss: 0.6855%\n",
      "Epoch [10/300], Step [20/23], Training Accuracy: 36.6406%, Training Loss: 0.6846%\n",
      "Epoch [10/300], Step [21/23], Training Accuracy: 36.8304%, Training Loss: 0.6855%\n",
      "Epoch [10/300], Step [22/23], Training Accuracy: 36.2216%, Training Loss: 0.6857%\n",
      "Epoch [10/300], Step [23/23], Training Accuracy: 36.2057%, Training Loss: 0.6853%\n",
      "Epoch [11/300], Step [1/23], Training Accuracy: 37.5000%, Training Loss: 0.6419%\n",
      "Epoch [11/300], Step [2/23], Training Accuracy: 37.5000%, Training Loss: 0.6532%\n",
      "Epoch [11/300], Step [3/23], Training Accuracy: 37.5000%, Training Loss: 0.6596%\n",
      "Epoch [11/300], Step [4/23], Training Accuracy: 36.7188%, Training Loss: 0.6620%\n",
      "Epoch [11/300], Step [5/23], Training Accuracy: 39.0625%, Training Loss: 0.6593%\n",
      "Epoch [11/300], Step [6/23], Training Accuracy: 38.2812%, Training Loss: 0.6687%\n",
      "Epoch [11/300], Step [7/23], Training Accuracy: 38.8393%, Training Loss: 0.6669%\n",
      "Epoch [11/300], Step [8/23], Training Accuracy: 39.2578%, Training Loss: 0.6653%\n",
      "Epoch [11/300], Step [9/23], Training Accuracy: 39.7569%, Training Loss: 0.6673%\n",
      "Epoch [11/300], Step [10/23], Training Accuracy: 38.7500%, Training Loss: 0.6691%\n",
      "Epoch [11/300], Step [11/23], Training Accuracy: 38.0682%, Training Loss: 0.6707%\n",
      "Epoch [11/300], Step [12/23], Training Accuracy: 38.2812%, Training Loss: 0.6707%\n",
      "Epoch [11/300], Step [13/23], Training Accuracy: 38.3413%, Training Loss: 0.6713%\n",
      "Epoch [11/300], Step [14/23], Training Accuracy: 38.2812%, Training Loss: 0.6728%\n",
      "Epoch [11/300], Step [15/23], Training Accuracy: 37.6042%, Training Loss: 0.6748%\n",
      "Epoch [11/300], Step [16/23], Training Accuracy: 37.5977%, Training Loss: 0.6740%\n",
      "Epoch [11/300], Step [17/23], Training Accuracy: 38.1434%, Training Loss: 0.6725%\n",
      "Epoch [11/300], Step [18/23], Training Accuracy: 38.2812%, Training Loss: 0.6733%\n",
      "Epoch [11/300], Step [19/23], Training Accuracy: 38.4868%, Training Loss: 0.6721%\n",
      "Epoch [11/300], Step [20/23], Training Accuracy: 39.2188%, Training Loss: 0.6706%\n",
      "Epoch [11/300], Step [21/23], Training Accuracy: 39.2113%, Training Loss: 0.6703%\n",
      "Epoch [11/300], Step [22/23], Training Accuracy: 39.2756%, Training Loss: 0.6705%\n",
      "Epoch [11/300], Step [23/23], Training Accuracy: 39.4024%, Training Loss: 0.6699%\n",
      "Epoch [12/300], Step [1/23], Training Accuracy: 46.8750%, Training Loss: 0.6715%\n",
      "Epoch [12/300], Step [2/23], Training Accuracy: 45.3125%, Training Loss: 0.6715%\n",
      "Epoch [12/300], Step [3/23], Training Accuracy: 40.6250%, Training Loss: 0.6722%\n",
      "Epoch [12/300], Step [4/23], Training Accuracy: 41.7969%, Training Loss: 0.6663%\n",
      "Epoch [12/300], Step [5/23], Training Accuracy: 40.3125%, Training Loss: 0.6596%\n",
      "Epoch [12/300], Step [6/23], Training Accuracy: 39.5833%, Training Loss: 0.6640%\n",
      "Epoch [12/300], Step [7/23], Training Accuracy: 40.6250%, Training Loss: 0.6641%\n",
      "Epoch [12/300], Step [8/23], Training Accuracy: 41.2109%, Training Loss: 0.6643%\n",
      "Epoch [12/300], Step [9/23], Training Accuracy: 41.3194%, Training Loss: 0.6617%\n",
      "Epoch [12/300], Step [10/23], Training Accuracy: 40.7812%, Training Loss: 0.6628%\n",
      "Epoch [12/300], Step [11/23], Training Accuracy: 40.1989%, Training Loss: 0.6629%\n",
      "Epoch [12/300], Step [12/23], Training Accuracy: 40.1042%, Training Loss: 0.6648%\n",
      "Epoch [12/300], Step [13/23], Training Accuracy: 39.4231%, Training Loss: 0.6654%\n",
      "Epoch [12/300], Step [14/23], Training Accuracy: 39.5089%, Training Loss: 0.6669%\n",
      "Epoch [12/300], Step [15/23], Training Accuracy: 39.0625%, Training Loss: 0.6679%\n",
      "Epoch [12/300], Step [16/23], Training Accuracy: 38.8672%, Training Loss: 0.6687%\n",
      "Epoch [12/300], Step [17/23], Training Accuracy: 39.5221%, Training Loss: 0.6677%\n",
      "Epoch [12/300], Step [18/23], Training Accuracy: 39.1493%, Training Loss: 0.6678%\n",
      "Epoch [12/300], Step [19/23], Training Accuracy: 38.8158%, Training Loss: 0.6674%\n",
      "Epoch [12/300], Step [20/23], Training Accuracy: 39.4531%, Training Loss: 0.6654%\n",
      "Epoch [12/300], Step [21/23], Training Accuracy: 39.2113%, Training Loss: 0.6658%\n",
      "Epoch [12/300], Step [22/23], Training Accuracy: 38.9205%, Training Loss: 0.6648%\n",
      "Epoch [12/300], Step [23/23], Training Accuracy: 38.7074%, Training Loss: 0.6651%\n",
      "Epoch [13/300], Step [1/23], Training Accuracy: 37.5000%, Training Loss: 0.6522%\n",
      "Epoch [13/300], Step [2/23], Training Accuracy: 39.8438%, Training Loss: 0.6653%\n",
      "Epoch [13/300], Step [3/23], Training Accuracy: 38.5417%, Training Loss: 0.6666%\n",
      "Epoch [13/300], Step [4/23], Training Accuracy: 39.8438%, Training Loss: 0.6568%\n",
      "Epoch [13/300], Step [5/23], Training Accuracy: 38.4375%, Training Loss: 0.6557%\n",
      "Epoch [13/300], Step [6/23], Training Accuracy: 40.3646%, Training Loss: 0.6592%\n",
      "Epoch [13/300], Step [7/23], Training Accuracy: 41.2946%, Training Loss: 0.6618%\n",
      "Epoch [13/300], Step [8/23], Training Accuracy: 42.3828%, Training Loss: 0.6567%\n",
      "Epoch [13/300], Step [9/23], Training Accuracy: 42.3611%, Training Loss: 0.6534%\n",
      "Epoch [13/300], Step [10/23], Training Accuracy: 40.7812%, Training Loss: 0.6552%\n",
      "Epoch [13/300], Step [11/23], Training Accuracy: 40.4830%, Training Loss: 0.6543%\n",
      "Epoch [13/300], Step [12/23], Training Accuracy: 39.8438%, Training Loss: 0.6541%\n",
      "Epoch [13/300], Step [13/23], Training Accuracy: 39.7837%, Training Loss: 0.6549%\n",
      "Epoch [13/300], Step [14/23], Training Accuracy: 39.2857%, Training Loss: 0.6575%\n",
      "Epoch [13/300], Step [15/23], Training Accuracy: 39.2708%, Training Loss: 0.6578%\n",
      "Epoch [13/300], Step [16/23], Training Accuracy: 39.2578%, Training Loss: 0.6562%\n",
      "Epoch [13/300], Step [17/23], Training Accuracy: 39.9816%, Training Loss: 0.6549%\n",
      "Epoch [13/300], Step [18/23], Training Accuracy: 40.1910%, Training Loss: 0.6540%\n",
      "Epoch [13/300], Step [19/23], Training Accuracy: 39.9671%, Training Loss: 0.6546%\n",
      "Epoch [13/300], Step [20/23], Training Accuracy: 40.6250%, Training Loss: 0.6526%\n",
      "Epoch [13/300], Step [21/23], Training Accuracy: 40.3274%, Training Loss: 0.6524%\n",
      "Epoch [13/300], Step [22/23], Training Accuracy: 40.3409%, Training Loss: 0.6510%\n",
      "Epoch [13/300], Step [23/23], Training Accuracy: 40.0973%, Training Loss: 0.6515%\n",
      "Epoch [14/300], Step [1/23], Training Accuracy: 40.6250%, Training Loss: 0.6558%\n",
      "Epoch [14/300], Step [2/23], Training Accuracy: 39.0625%, Training Loss: 0.6640%\n",
      "Epoch [14/300], Step [3/23], Training Accuracy: 40.6250%, Training Loss: 0.6580%\n",
      "Epoch [14/300], Step [4/23], Training Accuracy: 40.2344%, Training Loss: 0.6505%\n",
      "Epoch [14/300], Step [5/23], Training Accuracy: 41.2500%, Training Loss: 0.6496%\n",
      "Epoch [14/300], Step [6/23], Training Accuracy: 42.9688%, Training Loss: 0.6516%\n",
      "Epoch [14/300], Step [7/23], Training Accuracy: 43.3036%, Training Loss: 0.6498%\n",
      "Epoch [14/300], Step [8/23], Training Accuracy: 42.7734%, Training Loss: 0.6489%\n",
      "Epoch [14/300], Step [9/23], Training Accuracy: 42.8819%, Training Loss: 0.6459%\n",
      "Epoch [14/300], Step [10/23], Training Accuracy: 43.4375%, Training Loss: 0.6445%\n",
      "Epoch [14/300], Step [11/23], Training Accuracy: 42.6136%, Training Loss: 0.6469%\n",
      "Epoch [14/300], Step [12/23], Training Accuracy: 42.5781%, Training Loss: 0.6467%\n",
      "Epoch [14/300], Step [13/23], Training Accuracy: 42.6683%, Training Loss: 0.6456%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/300], Step [14/23], Training Accuracy: 42.7455%, Training Loss: 0.6463%\n",
      "Epoch [14/300], Step [15/23], Training Accuracy: 42.2917%, Training Loss: 0.6474%\n",
      "Epoch [14/300], Step [16/23], Training Accuracy: 42.8711%, Training Loss: 0.6445%\n",
      "Epoch [14/300], Step [17/23], Training Accuracy: 43.3824%, Training Loss: 0.6448%\n",
      "Epoch [14/300], Step [18/23], Training Accuracy: 43.6632%, Training Loss: 0.6436%\n",
      "Epoch [14/300], Step [19/23], Training Accuracy: 44.2434%, Training Loss: 0.6427%\n",
      "Epoch [14/300], Step [20/23], Training Accuracy: 44.5312%, Training Loss: 0.6414%\n",
      "Epoch [14/300], Step [21/23], Training Accuracy: 44.4940%, Training Loss: 0.6416%\n",
      "Epoch [14/300], Step [22/23], Training Accuracy: 44.3182%, Training Loss: 0.6413%\n",
      "Epoch [14/300], Step [23/23], Training Accuracy: 44.4058%, Training Loss: 0.6390%\n",
      "Epoch [15/300], Step [1/23], Training Accuracy: 46.8750%, Training Loss: 0.5968%\n",
      "Epoch [15/300], Step [2/23], Training Accuracy: 46.0938%, Training Loss: 0.6170%\n",
      "Epoch [15/300], Step [3/23], Training Accuracy: 47.3958%, Training Loss: 0.6184%\n",
      "Epoch [15/300], Step [4/23], Training Accuracy: 49.6094%, Training Loss: 0.6121%\n",
      "Epoch [15/300], Step [5/23], Training Accuracy: 50.9375%, Training Loss: 0.6109%\n",
      "Epoch [15/300], Step [6/23], Training Accuracy: 49.7396%, Training Loss: 0.6121%\n",
      "Epoch [15/300], Step [7/23], Training Accuracy: 48.4375%, Training Loss: 0.6149%\n",
      "Epoch [15/300], Step [8/23], Training Accuracy: 48.6328%, Training Loss: 0.6124%\n",
      "Epoch [15/300], Step [9/23], Training Accuracy: 48.2639%, Training Loss: 0.6139%\n",
      "Epoch [15/300], Step [10/23], Training Accuracy: 47.0312%, Training Loss: 0.6166%\n",
      "Epoch [15/300], Step [11/23], Training Accuracy: 47.0170%, Training Loss: 0.6169%\n",
      "Epoch [15/300], Step [12/23], Training Accuracy: 46.6146%, Training Loss: 0.6165%\n",
      "Epoch [15/300], Step [13/23], Training Accuracy: 45.9135%, Training Loss: 0.6181%\n",
      "Epoch [15/300], Step [14/23], Training Accuracy: 45.4241%, Training Loss: 0.6212%\n",
      "Epoch [15/300], Step [15/23], Training Accuracy: 44.7917%, Training Loss: 0.6228%\n",
      "Epoch [15/300], Step [16/23], Training Accuracy: 44.9219%, Training Loss: 0.6213%\n",
      "Epoch [15/300], Step [17/23], Training Accuracy: 45.4963%, Training Loss: 0.6203%\n",
      "Epoch [15/300], Step [18/23], Training Accuracy: 45.5729%, Training Loss: 0.6204%\n",
      "Epoch [15/300], Step [19/23], Training Accuracy: 46.1349%, Training Loss: 0.6178%\n",
      "Epoch [15/300], Step [20/23], Training Accuracy: 46.6406%, Training Loss: 0.6168%\n",
      "Epoch [15/300], Step [21/23], Training Accuracy: 46.6518%, Training Loss: 0.6174%\n",
      "Epoch [15/300], Step [22/23], Training Accuracy: 46.9460%, Training Loss: 0.6158%\n",
      "Epoch [15/300], Step [23/23], Training Accuracy: 46.9771%, Training Loss: 0.6153%\n",
      "Epoch [16/300], Step [1/23], Training Accuracy: 45.3125%, Training Loss: 0.5962%\n",
      "Epoch [16/300], Step [2/23], Training Accuracy: 42.9688%, Training Loss: 0.6153%\n",
      "Epoch [16/300], Step [3/23], Training Accuracy: 41.6667%, Training Loss: 0.6191%\n",
      "Epoch [16/300], Step [4/23], Training Accuracy: 44.5312%, Training Loss: 0.6055%\n",
      "Epoch [16/300], Step [5/23], Training Accuracy: 45.9375%, Training Loss: 0.6033%\n",
      "Epoch [16/300], Step [6/23], Training Accuracy: 46.6146%, Training Loss: 0.6049%\n",
      "Epoch [16/300], Step [7/23], Training Accuracy: 46.2054%, Training Loss: 0.6059%\n",
      "Epoch [16/300], Step [8/23], Training Accuracy: 47.2656%, Training Loss: 0.6039%\n",
      "Epoch [16/300], Step [9/23], Training Accuracy: 47.9167%, Training Loss: 0.6051%\n",
      "Epoch [16/300], Step [10/23], Training Accuracy: 47.6562%, Training Loss: 0.6045%\n",
      "Epoch [16/300], Step [11/23], Training Accuracy: 48.2955%, Training Loss: 0.6037%\n",
      "Epoch [16/300], Step [12/23], Training Accuracy: 47.7865%, Training Loss: 0.6030%\n",
      "Epoch [16/300], Step [13/23], Training Accuracy: 48.0769%, Training Loss: 0.6046%\n",
      "Epoch [16/300], Step [14/23], Training Accuracy: 47.4330%, Training Loss: 0.6078%\n",
      "Epoch [16/300], Step [15/23], Training Accuracy: 46.8750%, Training Loss: 0.6101%\n",
      "Epoch [16/300], Step [16/23], Training Accuracy: 47.3633%, Training Loss: 0.6070%\n",
      "Epoch [16/300], Step [17/23], Training Accuracy: 47.7022%, Training Loss: 0.6064%\n",
      "Epoch [16/300], Step [18/23], Training Accuracy: 47.9167%, Training Loss: 0.6058%\n",
      "Epoch [16/300], Step [19/23], Training Accuracy: 48.1086%, Training Loss: 0.6051%\n",
      "Epoch [16/300], Step [20/23], Training Accuracy: 48.4375%, Training Loss: 0.6021%\n",
      "Epoch [16/300], Step [21/23], Training Accuracy: 48.4375%, Training Loss: 0.6008%\n",
      "Epoch [16/300], Step [22/23], Training Accuracy: 48.7216%, Training Loss: 0.6002%\n",
      "Epoch [16/300], Step [23/23], Training Accuracy: 48.6449%, Training Loss: 0.5984%\n",
      "Epoch [17/300], Step [1/23], Training Accuracy: 51.5625%, Training Loss: 0.5797%\n",
      "Epoch [17/300], Step [2/23], Training Accuracy: 46.0938%, Training Loss: 0.6051%\n",
      "Epoch [17/300], Step [3/23], Training Accuracy: 46.3542%, Training Loss: 0.6105%\n",
      "Epoch [17/300], Step [4/23], Training Accuracy: 49.6094%, Training Loss: 0.5956%\n",
      "Epoch [17/300], Step [5/23], Training Accuracy: 50.6250%, Training Loss: 0.5950%\n",
      "Epoch [17/300], Step [6/23], Training Accuracy: 50.5208%, Training Loss: 0.5960%\n",
      "Epoch [17/300], Step [7/23], Training Accuracy: 51.1161%, Training Loss: 0.5944%\n",
      "Epoch [17/300], Step [8/23], Training Accuracy: 50.1953%, Training Loss: 0.5972%\n",
      "Epoch [17/300], Step [9/23], Training Accuracy: 51.0417%, Training Loss: 0.5981%\n",
      "Epoch [17/300], Step [10/23], Training Accuracy: 50.9375%, Training Loss: 0.5954%\n",
      "Epoch [17/300], Step [11/23], Training Accuracy: 50.5682%, Training Loss: 0.5932%\n",
      "Epoch [17/300], Step [12/23], Training Accuracy: 50.3906%, Training Loss: 0.5923%\n",
      "Epoch [17/300], Step [13/23], Training Accuracy: 50.2404%, Training Loss: 0.5914%\n",
      "Epoch [17/300], Step [14/23], Training Accuracy: 50.0000%, Training Loss: 0.5957%\n",
      "Epoch [17/300], Step [15/23], Training Accuracy: 49.4792%, Training Loss: 0.5964%\n",
      "Epoch [17/300], Step [16/23], Training Accuracy: 49.4141%, Training Loss: 0.5945%\n",
      "Epoch [17/300], Step [17/23], Training Accuracy: 49.3566%, Training Loss: 0.5943%\n",
      "Epoch [17/300], Step [18/23], Training Accuracy: 49.1319%, Training Loss: 0.5935%\n",
      "Epoch [17/300], Step [19/23], Training Accuracy: 48.9309%, Training Loss: 0.5942%\n",
      "Epoch [17/300], Step [20/23], Training Accuracy: 49.5312%, Training Loss: 0.5920%\n",
      "Epoch [17/300], Step [21/23], Training Accuracy: 49.6280%, Training Loss: 0.5918%\n",
      "Epoch [17/300], Step [22/23], Training Accuracy: 49.5028%, Training Loss: 0.5905%\n",
      "Epoch [17/300], Step [23/23], Training Accuracy: 49.4788%, Training Loss: 0.5875%\n",
      "Epoch [18/300], Step [1/23], Training Accuracy: 51.5625%, Training Loss: 0.5845%\n",
      "Epoch [18/300], Step [2/23], Training Accuracy: 49.2188%, Training Loss: 0.5982%\n",
      "Epoch [18/300], Step [3/23], Training Accuracy: 46.3542%, Training Loss: 0.6073%\n",
      "Epoch [18/300], Step [4/23], Training Accuracy: 50.7812%, Training Loss: 0.5890%\n",
      "Epoch [18/300], Step [5/23], Training Accuracy: 51.2500%, Training Loss: 0.5887%\n",
      "Epoch [18/300], Step [6/23], Training Accuracy: 50.7812%, Training Loss: 0.5912%\n",
      "Epoch [18/300], Step [7/23], Training Accuracy: 50.4464%, Training Loss: 0.5885%\n",
      "Epoch [18/300], Step [8/23], Training Accuracy: 51.9531%, Training Loss: 0.5869%\n",
      "Epoch [18/300], Step [9/23], Training Accuracy: 51.5625%, Training Loss: 0.5882%\n",
      "Epoch [18/300], Step [10/23], Training Accuracy: 51.8750%, Training Loss: 0.5848%\n",
      "Epoch [18/300], Step [11/23], Training Accuracy: 52.1307%, Training Loss: 0.5837%\n",
      "Epoch [18/300], Step [12/23], Training Accuracy: 51.4323%, Training Loss: 0.5827%\n",
      "Epoch [18/300], Step [13/23], Training Accuracy: 51.4423%, Training Loss: 0.5802%\n",
      "Epoch [18/300], Step [14/23], Training Accuracy: 51.3393%, Training Loss: 0.5814%\n",
      "Epoch [18/300], Step [15/23], Training Accuracy: 50.7292%, Training Loss: 0.5846%\n",
      "Epoch [18/300], Step [16/23], Training Accuracy: 51.3672%, Training Loss: 0.5810%\n",
      "Epoch [18/300], Step [17/23], Training Accuracy: 51.1029%, Training Loss: 0.5810%\n",
      "Epoch [18/300], Step [18/23], Training Accuracy: 51.0417%, Training Loss: 0.5806%\n",
      "Epoch [18/300], Step [19/23], Training Accuracy: 51.4803%, Training Loss: 0.5782%\n",
      "Epoch [18/300], Step [20/23], Training Accuracy: 51.9531%, Training Loss: 0.5771%\n",
      "Epoch [18/300], Step [21/23], Training Accuracy: 52.2321%, Training Loss: 0.5757%\n",
      "Epoch [18/300], Step [22/23], Training Accuracy: 52.2727%, Training Loss: 0.5753%\n",
      "Epoch [18/300], Step [23/23], Training Accuracy: 52.1195%, Training Loss: 0.5725%\n",
      "Epoch [19/300], Step [1/23], Training Accuracy: 56.2500%, Training Loss: 0.5512%\n",
      "Epoch [19/300], Step [2/23], Training Accuracy: 49.2188%, Training Loss: 0.5758%\n",
      "Epoch [19/300], Step [3/23], Training Accuracy: 48.9583%, Training Loss: 0.5803%\n",
      "Epoch [19/300], Step [4/23], Training Accuracy: 51.5625%, Training Loss: 0.5725%\n",
      "Epoch [19/300], Step [5/23], Training Accuracy: 52.8125%, Training Loss: 0.5711%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/300], Step [6/23], Training Accuracy: 53.1250%, Training Loss: 0.5685%\n",
      "Epoch [19/300], Step [7/23], Training Accuracy: 54.0179%, Training Loss: 0.5638%\n",
      "Epoch [19/300], Step [8/23], Training Accuracy: 54.1016%, Training Loss: 0.5639%\n",
      "Epoch [19/300], Step [9/23], Training Accuracy: 52.9514%, Training Loss: 0.5679%\n",
      "Epoch [19/300], Step [10/23], Training Accuracy: 52.5000%, Training Loss: 0.5665%\n",
      "Epoch [19/300], Step [11/23], Training Accuracy: 52.2727%, Training Loss: 0.5640%\n",
      "Epoch [19/300], Step [12/23], Training Accuracy: 52.7344%, Training Loss: 0.5642%\n",
      "Epoch [19/300], Step [13/23], Training Accuracy: 52.6442%, Training Loss: 0.5644%\n",
      "Epoch [19/300], Step [14/23], Training Accuracy: 52.1205%, Training Loss: 0.5660%\n",
      "Epoch [19/300], Step [15/23], Training Accuracy: 51.4583%, Training Loss: 0.5705%\n",
      "Epoch [19/300], Step [16/23], Training Accuracy: 52.1484%, Training Loss: 0.5658%\n",
      "Epoch [19/300], Step [17/23], Training Accuracy: 52.2059%, Training Loss: 0.5647%\n",
      "Epoch [19/300], Step [18/23], Training Accuracy: 51.9965%, Training Loss: 0.5656%\n",
      "Epoch [19/300], Step [19/23], Training Accuracy: 52.3026%, Training Loss: 0.5648%\n",
      "Epoch [19/300], Step [20/23], Training Accuracy: 52.8125%, Training Loss: 0.5633%\n",
      "Epoch [19/300], Step [21/23], Training Accuracy: 52.6786%, Training Loss: 0.5643%\n",
      "Epoch [19/300], Step [22/23], Training Accuracy: 52.9830%, Training Loss: 0.5621%\n",
      "Epoch [19/300], Step [23/23], Training Accuracy: 52.9534%, Training Loss: 0.5590%\n",
      "Epoch [20/300], Step [1/23], Training Accuracy: 54.6875%, Training Loss: 0.5263%\n",
      "Epoch [20/300], Step [2/23], Training Accuracy: 51.5625%, Training Loss: 0.5799%\n",
      "Epoch [20/300], Step [3/23], Training Accuracy: 49.4792%, Training Loss: 0.5815%\n",
      "Epoch [20/300], Step [4/23], Training Accuracy: 51.9531%, Training Loss: 0.5644%\n",
      "Epoch [20/300], Step [5/23], Training Accuracy: 53.4375%, Training Loss: 0.5644%\n",
      "Epoch [20/300], Step [6/23], Training Accuracy: 54.4271%, Training Loss: 0.5597%\n",
      "Epoch [20/300], Step [7/23], Training Accuracy: 54.2411%, Training Loss: 0.5626%\n",
      "Epoch [20/300], Step [8/23], Training Accuracy: 54.6875%, Training Loss: 0.5624%\n",
      "Epoch [20/300], Step [9/23], Training Accuracy: 54.3403%, Training Loss: 0.5638%\n",
      "Epoch [20/300], Step [10/23], Training Accuracy: 54.5312%, Training Loss: 0.5596%\n",
      "Epoch [20/300], Step [11/23], Training Accuracy: 54.8295%, Training Loss: 0.5568%\n",
      "Epoch [20/300], Step [12/23], Training Accuracy: 54.9479%, Training Loss: 0.5570%\n",
      "Epoch [20/300], Step [13/23], Training Accuracy: 55.0481%, Training Loss: 0.5559%\n",
      "Epoch [20/300], Step [14/23], Training Accuracy: 54.5759%, Training Loss: 0.5580%\n",
      "Epoch [20/300], Step [15/23], Training Accuracy: 53.6458%, Training Loss: 0.5632%\n",
      "Epoch [20/300], Step [16/23], Training Accuracy: 54.0039%, Training Loss: 0.5603%\n",
      "Epoch [20/300], Step [17/23], Training Accuracy: 54.2279%, Training Loss: 0.5608%\n",
      "Epoch [20/300], Step [18/23], Training Accuracy: 53.9062%, Training Loss: 0.5614%\n",
      "Epoch [20/300], Step [19/23], Training Accuracy: 53.7829%, Training Loss: 0.5599%\n",
      "Epoch [20/300], Step [20/23], Training Accuracy: 54.0625%, Training Loss: 0.5572%\n",
      "Epoch [20/300], Step [21/23], Training Accuracy: 54.3155%, Training Loss: 0.5562%\n",
      "Epoch [20/300], Step [22/23], Training Accuracy: 54.8295%, Training Loss: 0.5551%\n",
      "Epoch [20/300], Step [23/23], Training Accuracy: 54.7603%, Training Loss: 0.5527%\n",
      "Epoch [21/300], Step [1/23], Training Accuracy: 57.8125%, Training Loss: 0.5214%\n",
      "Epoch [21/300], Step [2/23], Training Accuracy: 54.6875%, Training Loss: 0.5455%\n",
      "Epoch [21/300], Step [3/23], Training Accuracy: 50.0000%, Training Loss: 0.5607%\n",
      "Epoch [21/300], Step [4/23], Training Accuracy: 53.5156%, Training Loss: 0.5452%\n",
      "Epoch [21/300], Step [5/23], Training Accuracy: 54.6875%, Training Loss: 0.5374%\n",
      "Epoch [21/300], Step [6/23], Training Accuracy: 55.4688%, Training Loss: 0.5342%\n",
      "Epoch [21/300], Step [7/23], Training Accuracy: 56.6964%, Training Loss: 0.5330%\n",
      "Epoch [21/300], Step [8/23], Training Accuracy: 57.4219%, Training Loss: 0.5331%\n",
      "Epoch [21/300], Step [9/23], Training Accuracy: 58.1597%, Training Loss: 0.5341%\n",
      "Epoch [21/300], Step [10/23], Training Accuracy: 58.4375%, Training Loss: 0.5315%\n",
      "Epoch [21/300], Step [11/23], Training Accuracy: 58.5227%, Training Loss: 0.5325%\n",
      "Epoch [21/300], Step [12/23], Training Accuracy: 58.3333%, Training Loss: 0.5337%\n",
      "Epoch [21/300], Step [13/23], Training Accuracy: 58.2933%, Training Loss: 0.5368%\n",
      "Epoch [21/300], Step [14/23], Training Accuracy: 57.1429%, Training Loss: 0.5424%\n",
      "Epoch [21/300], Step [15/23], Training Accuracy: 56.0417%, Training Loss: 0.5475%\n",
      "Epoch [21/300], Step [16/23], Training Accuracy: 56.1523%, Training Loss: 0.5436%\n",
      "Epoch [21/300], Step [17/23], Training Accuracy: 56.1581%, Training Loss: 0.5441%\n",
      "Epoch [21/300], Step [18/23], Training Accuracy: 55.8160%, Training Loss: 0.5438%\n",
      "Epoch [21/300], Step [19/23], Training Accuracy: 56.2500%, Training Loss: 0.5427%\n",
      "Epoch [21/300], Step [20/23], Training Accuracy: 56.2500%, Training Loss: 0.5425%\n",
      "Epoch [21/300], Step [21/23], Training Accuracy: 55.9524%, Training Loss: 0.5418%\n",
      "Epoch [21/300], Step [22/23], Training Accuracy: 56.2500%, Training Loss: 0.5400%\n",
      "Epoch [21/300], Step [23/23], Training Accuracy: 56.2196%, Training Loss: 0.5359%\n",
      "Epoch [22/300], Step [1/23], Training Accuracy: 56.2500%, Training Loss: 0.5047%\n",
      "Epoch [22/300], Step [2/23], Training Accuracy: 55.4688%, Training Loss: 0.5399%\n",
      "Epoch [22/300], Step [3/23], Training Accuracy: 54.1667%, Training Loss: 0.5517%\n",
      "Epoch [22/300], Step [4/23], Training Accuracy: 57.0312%, Training Loss: 0.5269%\n",
      "Epoch [22/300], Step [5/23], Training Accuracy: 56.2500%, Training Loss: 0.5234%\n",
      "Epoch [22/300], Step [6/23], Training Accuracy: 56.7708%, Training Loss: 0.5252%\n",
      "Epoch [22/300], Step [7/23], Training Accuracy: 56.2500%, Training Loss: 0.5297%\n",
      "Epoch [22/300], Step [8/23], Training Accuracy: 57.0312%, Training Loss: 0.5320%\n",
      "Epoch [22/300], Step [9/23], Training Accuracy: 56.7708%, Training Loss: 0.5350%\n",
      "Epoch [22/300], Step [10/23], Training Accuracy: 57.0312%, Training Loss: 0.5323%\n",
      "Epoch [22/300], Step [11/23], Training Accuracy: 57.6705%, Training Loss: 0.5294%\n",
      "Epoch [22/300], Step [12/23], Training Accuracy: 57.9427%, Training Loss: 0.5305%\n",
      "Epoch [22/300], Step [13/23], Training Accuracy: 58.1731%, Training Loss: 0.5290%\n",
      "Epoch [22/300], Step [14/23], Training Accuracy: 57.5893%, Training Loss: 0.5312%\n",
      "Epoch [22/300], Step [15/23], Training Accuracy: 56.8750%, Training Loss: 0.5364%\n",
      "Epoch [22/300], Step [16/23], Training Accuracy: 57.2266%, Training Loss: 0.5343%\n",
      "Epoch [22/300], Step [17/23], Training Accuracy: 57.4449%, Training Loss: 0.5332%\n",
      "Epoch [22/300], Step [18/23], Training Accuracy: 57.0312%, Training Loss: 0.5345%\n",
      "Epoch [22/300], Step [19/23], Training Accuracy: 57.1546%, Training Loss: 0.5339%\n",
      "Epoch [22/300], Step [20/23], Training Accuracy: 57.1875%, Training Loss: 0.5319%\n",
      "Epoch [22/300], Step [21/23], Training Accuracy: 57.2917%, Training Loss: 0.5294%\n",
      "Epoch [22/300], Step [22/23], Training Accuracy: 57.3153%, Training Loss: 0.5285%\n",
      "Epoch [22/300], Step [23/23], Training Accuracy: 57.4705%, Training Loss: 0.5253%\n",
      "Epoch [23/300], Step [1/23], Training Accuracy: 57.8125%, Training Loss: 0.4892%\n",
      "Epoch [23/300], Step [2/23], Training Accuracy: 57.0312%, Training Loss: 0.5281%\n",
      "Epoch [23/300], Step [3/23], Training Accuracy: 54.6875%, Training Loss: 0.5334%\n",
      "Epoch [23/300], Step [4/23], Training Accuracy: 57.4219%, Training Loss: 0.5185%\n",
      "Epoch [23/300], Step [5/23], Training Accuracy: 58.1250%, Training Loss: 0.5105%\n",
      "Epoch [23/300], Step [6/23], Training Accuracy: 58.3333%, Training Loss: 0.5142%\n",
      "Epoch [23/300], Step [7/23], Training Accuracy: 58.7054%, Training Loss: 0.5156%\n",
      "Epoch [23/300], Step [8/23], Training Accuracy: 58.9844%, Training Loss: 0.5165%\n",
      "Epoch [23/300], Step [9/23], Training Accuracy: 58.1597%, Training Loss: 0.5185%\n",
      "Epoch [23/300], Step [10/23], Training Accuracy: 58.2812%, Training Loss: 0.5163%\n",
      "Epoch [23/300], Step [11/23], Training Accuracy: 58.8068%, Training Loss: 0.5144%\n",
      "Epoch [23/300], Step [12/23], Training Accuracy: 58.5938%, Training Loss: 0.5179%\n",
      "Epoch [23/300], Step [13/23], Training Accuracy: 58.4135%, Training Loss: 0.5163%\n",
      "Epoch [23/300], Step [14/23], Training Accuracy: 58.2589%, Training Loss: 0.5175%\n",
      "Epoch [23/300], Step [15/23], Training Accuracy: 57.2917%, Training Loss: 0.5216%\n",
      "Epoch [23/300], Step [16/23], Training Accuracy: 58.0078%, Training Loss: 0.5190%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/300], Step [17/23], Training Accuracy: 58.3640%, Training Loss: 0.5178%\n",
      "Epoch [23/300], Step [18/23], Training Accuracy: 58.1597%, Training Loss: 0.5186%\n",
      "Epoch [23/300], Step [19/23], Training Accuracy: 58.4704%, Training Loss: 0.5184%\n",
      "Epoch [23/300], Step [20/23], Training Accuracy: 58.4375%, Training Loss: 0.5175%\n",
      "Epoch [23/300], Step [21/23], Training Accuracy: 58.4821%, Training Loss: 0.5181%\n",
      "Epoch [23/300], Step [22/23], Training Accuracy: 58.5227%, Training Loss: 0.5180%\n",
      "Epoch [23/300], Step [23/23], Training Accuracy: 58.5129%, Training Loss: 0.5180%\n",
      "Epoch [24/300], Step [1/23], Training Accuracy: 67.1875%, Training Loss: 0.4723%\n",
      "Epoch [24/300], Step [2/23], Training Accuracy: 58.5938%, Training Loss: 0.5434%\n",
      "Epoch [24/300], Step [3/23], Training Accuracy: 56.2500%, Training Loss: 0.5561%\n",
      "Epoch [24/300], Step [4/23], Training Accuracy: 57.4219%, Training Loss: 0.5365%\n",
      "Epoch [24/300], Step [5/23], Training Accuracy: 57.1875%, Training Loss: 0.5292%\n",
      "Epoch [24/300], Step [6/23], Training Accuracy: 58.5938%, Training Loss: 0.5216%\n",
      "Epoch [24/300], Step [7/23], Training Accuracy: 58.7054%, Training Loss: 0.5206%\n",
      "Epoch [24/300], Step [8/23], Training Accuracy: 59.1797%, Training Loss: 0.5185%\n",
      "Epoch [24/300], Step [9/23], Training Accuracy: 58.3333%, Training Loss: 0.5210%\n",
      "Epoch [24/300], Step [10/23], Training Accuracy: 59.3750%, Training Loss: 0.5175%\n",
      "Epoch [24/300], Step [11/23], Training Accuracy: 59.3750%, Training Loss: 0.5168%\n",
      "Epoch [24/300], Step [12/23], Training Accuracy: 59.7656%, Training Loss: 0.5187%\n",
      "Epoch [24/300], Step [13/23], Training Accuracy: 59.9760%, Training Loss: 0.5156%\n",
      "Epoch [24/300], Step [14/23], Training Accuracy: 59.4866%, Training Loss: 0.5193%\n",
      "Epoch [24/300], Step [15/23], Training Accuracy: 58.5417%, Training Loss: 0.5249%\n",
      "Epoch [24/300], Step [16/23], Training Accuracy: 58.3984%, Training Loss: 0.5208%\n",
      "Epoch [24/300], Step [17/23], Training Accuracy: 58.4559%, Training Loss: 0.5210%\n",
      "Epoch [24/300], Step [18/23], Training Accuracy: 58.1597%, Training Loss: 0.5220%\n",
      "Epoch [24/300], Step [19/23], Training Accuracy: 58.3059%, Training Loss: 0.5206%\n",
      "Epoch [24/300], Step [20/23], Training Accuracy: 58.4375%, Training Loss: 0.5180%\n",
      "Epoch [24/300], Step [21/23], Training Accuracy: 58.5565%, Training Loss: 0.5174%\n",
      "Epoch [24/300], Step [22/23], Training Accuracy: 58.8778%, Training Loss: 0.5142%\n",
      "Epoch [24/300], Step [23/23], Training Accuracy: 58.8603%, Training Loss: 0.5114%\n",
      "Epoch [25/300], Step [1/23], Training Accuracy: 62.5000%, Training Loss: 0.4622%\n",
      "Epoch [25/300], Step [2/23], Training Accuracy: 56.2500%, Training Loss: 0.5224%\n",
      "Epoch [25/300], Step [3/23], Training Accuracy: 54.6875%, Training Loss: 0.5257%\n",
      "Epoch [25/300], Step [4/23], Training Accuracy: 59.3750%, Training Loss: 0.5050%\n",
      "Epoch [25/300], Step [5/23], Training Accuracy: 58.4375%, Training Loss: 0.5077%\n",
      "Epoch [25/300], Step [6/23], Training Accuracy: 59.6354%, Training Loss: 0.5091%\n",
      "Epoch [25/300], Step [7/23], Training Accuracy: 59.5982%, Training Loss: 0.5144%\n",
      "Epoch [25/300], Step [8/23], Training Accuracy: 59.7656%, Training Loss: 0.5109%\n",
      "Epoch [25/300], Step [9/23], Training Accuracy: 59.5486%, Training Loss: 0.5147%\n",
      "Epoch [25/300], Step [10/23], Training Accuracy: 59.5312%, Training Loss: 0.5143%\n",
      "Epoch [25/300], Step [11/23], Training Accuracy: 60.0852%, Training Loss: 0.5122%\n",
      "Epoch [25/300], Step [12/23], Training Accuracy: 59.6354%, Training Loss: 0.5170%\n",
      "Epoch [25/300], Step [13/23], Training Accuracy: 59.9760%, Training Loss: 0.5159%\n",
      "Epoch [25/300], Step [14/23], Training Accuracy: 59.9330%, Training Loss: 0.5182%\n",
      "Epoch [25/300], Step [15/23], Training Accuracy: 58.5417%, Training Loss: 0.5234%\n",
      "Epoch [25/300], Step [16/23], Training Accuracy: 59.0820%, Training Loss: 0.5205%\n",
      "Epoch [25/300], Step [17/23], Training Accuracy: 59.0074%, Training Loss: 0.5192%\n",
      "Epoch [25/300], Step [18/23], Training Accuracy: 58.8542%, Training Loss: 0.5177%\n",
      "Epoch [25/300], Step [19/23], Training Accuracy: 59.1283%, Training Loss: 0.5152%\n",
      "Epoch [25/300], Step [20/23], Training Accuracy: 59.1406%, Training Loss: 0.5131%\n",
      "Epoch [25/300], Step [21/23], Training Accuracy: 59.3750%, Training Loss: 0.5107%\n",
      "Epoch [25/300], Step [22/23], Training Accuracy: 59.2330%, Training Loss: 0.5095%\n",
      "Epoch [25/300], Step [23/23], Training Accuracy: 59.4163%, Training Loss: 0.5047%\n",
      "Epoch [26/300], Step [1/23], Training Accuracy: 60.9375%, Training Loss: 0.4639%\n",
      "Epoch [26/300], Step [2/23], Training Accuracy: 59.3750%, Training Loss: 0.4954%\n",
      "Epoch [26/300], Step [3/23], Training Accuracy: 58.3333%, Training Loss: 0.5031%\n",
      "Epoch [26/300], Step [4/23], Training Accuracy: 59.7656%, Training Loss: 0.4857%\n",
      "Epoch [26/300], Step [5/23], Training Accuracy: 60.6250%, Training Loss: 0.4854%\n",
      "Epoch [26/300], Step [6/23], Training Accuracy: 61.7188%, Training Loss: 0.4846%\n",
      "Epoch [26/300], Step [7/23], Training Accuracy: 61.8304%, Training Loss: 0.4882%\n",
      "Epoch [26/300], Step [8/23], Training Accuracy: 61.9141%, Training Loss: 0.4886%\n",
      "Epoch [26/300], Step [9/23], Training Accuracy: 60.7639%, Training Loss: 0.4925%\n",
      "Epoch [26/300], Step [10/23], Training Accuracy: 60.7812%, Training Loss: 0.4928%\n",
      "Epoch [26/300], Step [11/23], Training Accuracy: 61.0795%, Training Loss: 0.4925%\n",
      "Epoch [26/300], Step [12/23], Training Accuracy: 60.6771%, Training Loss: 0.4956%\n",
      "Epoch [26/300], Step [13/23], Training Accuracy: 60.4567%, Training Loss: 0.4955%\n",
      "Epoch [26/300], Step [14/23], Training Accuracy: 60.1562%, Training Loss: 0.5014%\n",
      "Epoch [26/300], Step [15/23], Training Accuracy: 59.8958%, Training Loss: 0.5074%\n",
      "Epoch [26/300], Step [16/23], Training Accuracy: 60.2539%, Training Loss: 0.5045%\n",
      "Epoch [26/300], Step [17/23], Training Accuracy: 60.0184%, Training Loss: 0.5054%\n",
      "Epoch [26/300], Step [18/23], Training Accuracy: 59.4618%, Training Loss: 0.5073%\n",
      "Epoch [26/300], Step [19/23], Training Accuracy: 59.7862%, Training Loss: 0.5055%\n",
      "Epoch [26/300], Step [20/23], Training Accuracy: 59.9219%, Training Loss: 0.5037%\n",
      "Epoch [26/300], Step [21/23], Training Accuracy: 60.1935%, Training Loss: 0.5014%\n",
      "Epoch [26/300], Step [22/23], Training Accuracy: 60.0852%, Training Loss: 0.4997%\n",
      "Epoch [26/300], Step [23/23], Training Accuracy: 60.1807%, Training Loss: 0.4970%\n",
      "Epoch [27/300], Step [1/23], Training Accuracy: 64.0625%, Training Loss: 0.4523%\n",
      "Epoch [27/300], Step [2/23], Training Accuracy: 57.0312%, Training Loss: 0.4993%\n",
      "Epoch [27/300], Step [3/23], Training Accuracy: 56.2500%, Training Loss: 0.5123%\n",
      "Epoch [27/300], Step [4/23], Training Accuracy: 58.9844%, Training Loss: 0.4919%\n",
      "Epoch [27/300], Step [5/23], Training Accuracy: 59.0625%, Training Loss: 0.4919%\n",
      "Epoch [27/300], Step [6/23], Training Accuracy: 59.8958%, Training Loss: 0.4918%\n",
      "Epoch [27/300], Step [7/23], Training Accuracy: 60.9375%, Training Loss: 0.4918%\n",
      "Epoch [27/300], Step [8/23], Training Accuracy: 61.7188%, Training Loss: 0.4882%\n",
      "Epoch [27/300], Step [9/23], Training Accuracy: 60.9375%, Training Loss: 0.4912%\n",
      "Epoch [27/300], Step [10/23], Training Accuracy: 60.6250%, Training Loss: 0.4889%\n",
      "Epoch [27/300], Step [11/23], Training Accuracy: 60.9375%, Training Loss: 0.4899%\n",
      "Epoch [27/300], Step [12/23], Training Accuracy: 60.9375%, Training Loss: 0.4902%\n",
      "Epoch [27/300], Step [13/23], Training Accuracy: 61.4183%, Training Loss: 0.4881%\n",
      "Epoch [27/300], Step [14/23], Training Accuracy: 60.7143%, Training Loss: 0.4922%\n",
      "Epoch [27/300], Step [15/23], Training Accuracy: 60.2083%, Training Loss: 0.4963%\n",
      "Epoch [27/300], Step [16/23], Training Accuracy: 60.6445%, Training Loss: 0.4940%\n",
      "Epoch [27/300], Step [17/23], Training Accuracy: 60.7537%, Training Loss: 0.4916%\n",
      "Epoch [27/300], Step [18/23], Training Accuracy: 60.7639%, Training Loss: 0.4905%\n",
      "Epoch [27/300], Step [19/23], Training Accuracy: 60.8553%, Training Loss: 0.4891%\n",
      "Epoch [27/300], Step [20/23], Training Accuracy: 60.9375%, Training Loss: 0.4866%\n",
      "Epoch [27/300], Step [21/23], Training Accuracy: 60.9375%, Training Loss: 0.4849%\n",
      "Epoch [27/300], Step [22/23], Training Accuracy: 61.0795%, Training Loss: 0.4849%\n",
      "Epoch [27/300], Step [23/23], Training Accuracy: 61.1536%, Training Loss: 0.4843%\n",
      "Epoch [28/300], Step [1/23], Training Accuracy: 68.7500%, Training Loss: 0.4344%\n",
      "Epoch [28/300], Step [2/23], Training Accuracy: 63.2812%, Training Loss: 0.4767%\n",
      "Epoch [28/300], Step [3/23], Training Accuracy: 63.5417%, Training Loss: 0.4854%\n",
      "Epoch [28/300], Step [4/23], Training Accuracy: 63.2812%, Training Loss: 0.4699%\n",
      "Epoch [28/300], Step [5/23], Training Accuracy: 62.5000%, Training Loss: 0.4658%\n",
      "Epoch [28/300], Step [6/23], Training Accuracy: 61.9792%, Training Loss: 0.4706%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/300], Step [7/23], Training Accuracy: 62.7232%, Training Loss: 0.4723%\n",
      "Epoch [28/300], Step [8/23], Training Accuracy: 62.5000%, Training Loss: 0.4747%\n",
      "Epoch [28/300], Step [9/23], Training Accuracy: 61.8056%, Training Loss: 0.4809%\n",
      "Epoch [28/300], Step [10/23], Training Accuracy: 61.7188%, Training Loss: 0.4757%\n",
      "Epoch [28/300], Step [11/23], Training Accuracy: 62.2159%, Training Loss: 0.4744%\n",
      "Epoch [28/300], Step [12/23], Training Accuracy: 62.5000%, Training Loss: 0.4761%\n",
      "Epoch [28/300], Step [13/23], Training Accuracy: 62.3798%, Training Loss: 0.4758%\n",
      "Epoch [28/300], Step [14/23], Training Accuracy: 62.1652%, Training Loss: 0.4794%\n",
      "Epoch [28/300], Step [15/23], Training Accuracy: 61.6667%, Training Loss: 0.4845%\n",
      "Epoch [28/300], Step [16/23], Training Accuracy: 61.8164%, Training Loss: 0.4811%\n",
      "Epoch [28/300], Step [17/23], Training Accuracy: 61.9485%, Training Loss: 0.4798%\n",
      "Epoch [28/300], Step [18/23], Training Accuracy: 61.5451%, Training Loss: 0.4804%\n",
      "Epoch [28/300], Step [19/23], Training Accuracy: 61.5132%, Training Loss: 0.4798%\n",
      "Epoch [28/300], Step [20/23], Training Accuracy: 61.8750%, Training Loss: 0.4781%\n",
      "Epoch [28/300], Step [21/23], Training Accuracy: 61.6815%, Training Loss: 0.4779%\n",
      "Epoch [28/300], Step [22/23], Training Accuracy: 61.7188%, Training Loss: 0.4770%\n",
      "Epoch [28/300], Step [23/23], Training Accuracy: 61.7790%, Training Loss: 0.4732%\n",
      "Epoch [29/300], Step [1/23], Training Accuracy: 67.1875%, Training Loss: 0.4752%\n",
      "Epoch [29/300], Step [2/23], Training Accuracy: 63.2812%, Training Loss: 0.4901%\n",
      "Epoch [29/300], Step [3/23], Training Accuracy: 60.9375%, Training Loss: 0.4923%\n",
      "Epoch [29/300], Step [4/23], Training Accuracy: 63.2812%, Training Loss: 0.4691%\n",
      "Epoch [29/300], Step [5/23], Training Accuracy: 62.8125%, Training Loss: 0.4693%\n",
      "Epoch [29/300], Step [6/23], Training Accuracy: 62.7604%, Training Loss: 0.4749%\n",
      "Epoch [29/300], Step [7/23], Training Accuracy: 63.1696%, Training Loss: 0.4763%\n",
      "Epoch [29/300], Step [8/23], Training Accuracy: 63.2812%, Training Loss: 0.4775%\n",
      "Epoch [29/300], Step [9/23], Training Accuracy: 63.0208%, Training Loss: 0.4803%\n",
      "Epoch [29/300], Step [10/23], Training Accuracy: 62.9688%, Training Loss: 0.4769%\n",
      "Epoch [29/300], Step [11/23], Training Accuracy: 63.4943%, Training Loss: 0.4750%\n",
      "Epoch [29/300], Step [12/23], Training Accuracy: 63.6719%, Training Loss: 0.4753%\n",
      "Epoch [29/300], Step [13/23], Training Accuracy: 63.8221%, Training Loss: 0.4754%\n",
      "Epoch [29/300], Step [14/23], Training Accuracy: 63.5045%, Training Loss: 0.4787%\n",
      "Epoch [29/300], Step [15/23], Training Accuracy: 62.5000%, Training Loss: 0.4852%\n",
      "Epoch [29/300], Step [16/23], Training Accuracy: 63.3789%, Training Loss: 0.4816%\n",
      "Epoch [29/300], Step [17/23], Training Accuracy: 63.4191%, Training Loss: 0.4815%\n",
      "Epoch [29/300], Step [18/23], Training Accuracy: 63.1944%, Training Loss: 0.4824%\n",
      "Epoch [29/300], Step [19/23], Training Accuracy: 63.4868%, Training Loss: 0.4817%\n",
      "Epoch [29/300], Step [20/23], Training Accuracy: 63.5938%, Training Loss: 0.4783%\n",
      "Epoch [29/300], Step [21/23], Training Accuracy: 63.8393%, Training Loss: 0.4763%\n",
      "Epoch [29/300], Step [22/23], Training Accuracy: 63.8494%, Training Loss: 0.4758%\n",
      "Epoch [29/300], Step [23/23], Training Accuracy: 64.0723%, Training Loss: 0.4705%\n",
      "Epoch [30/300], Step [1/23], Training Accuracy: 59.3750%, Training Loss: 0.4448%\n",
      "Epoch [30/300], Step [2/23], Training Accuracy: 57.8125%, Training Loss: 0.4754%\n",
      "Epoch [30/300], Step [3/23], Training Accuracy: 57.8125%, Training Loss: 0.4988%\n",
      "Epoch [30/300], Step [4/23], Training Accuracy: 60.9375%, Training Loss: 0.4828%\n",
      "Epoch [30/300], Step [5/23], Training Accuracy: 60.3125%, Training Loss: 0.4776%\n",
      "Epoch [30/300], Step [6/23], Training Accuracy: 60.4167%, Training Loss: 0.4845%\n",
      "Epoch [30/300], Step [7/23], Training Accuracy: 60.7143%, Training Loss: 0.4849%\n",
      "Epoch [30/300], Step [8/23], Training Accuracy: 61.7188%, Training Loss: 0.4787%\n",
      "Epoch [30/300], Step [9/23], Training Accuracy: 61.4583%, Training Loss: 0.4778%\n",
      "Epoch [30/300], Step [10/23], Training Accuracy: 62.0312%, Training Loss: 0.4719%\n",
      "Epoch [30/300], Step [11/23], Training Accuracy: 62.9261%, Training Loss: 0.4707%\n",
      "Epoch [30/300], Step [12/23], Training Accuracy: 63.0208%, Training Loss: 0.4721%\n",
      "Epoch [30/300], Step [13/23], Training Accuracy: 62.6202%, Training Loss: 0.4724%\n",
      "Epoch [30/300], Step [14/23], Training Accuracy: 62.2768%, Training Loss: 0.4736%\n",
      "Epoch [30/300], Step [15/23], Training Accuracy: 61.6667%, Training Loss: 0.4788%\n",
      "Epoch [30/300], Step [16/23], Training Accuracy: 62.2070%, Training Loss: 0.4766%\n",
      "Epoch [30/300], Step [17/23], Training Accuracy: 62.2243%, Training Loss: 0.4756%\n",
      "Epoch [30/300], Step [18/23], Training Accuracy: 62.2396%, Training Loss: 0.4754%\n",
      "Epoch [30/300], Step [19/23], Training Accuracy: 62.5000%, Training Loss: 0.4745%\n",
      "Epoch [30/300], Step [20/23], Training Accuracy: 62.8125%, Training Loss: 0.4713%\n",
      "Epoch [30/300], Step [21/23], Training Accuracy: 62.7232%, Training Loss: 0.4697%\n",
      "Epoch [30/300], Step [22/23], Training Accuracy: 63.2102%, Training Loss: 0.4677%\n",
      "Epoch [30/300], Step [23/23], Training Accuracy: 63.3079%, Training Loss: 0.4654%\n",
      "Epoch [31/300], Step [1/23], Training Accuracy: 65.6250%, Training Loss: 0.4543%\n",
      "Epoch [31/300], Step [2/23], Training Accuracy: 60.9375%, Training Loss: 0.4780%\n",
      "Epoch [31/300], Step [3/23], Training Accuracy: 59.8958%, Training Loss: 0.4830%\n",
      "Epoch [31/300], Step [4/23], Training Accuracy: 63.6719%, Training Loss: 0.4624%\n",
      "Epoch [31/300], Step [5/23], Training Accuracy: 63.7500%, Training Loss: 0.4603%\n",
      "Epoch [31/300], Step [6/23], Training Accuracy: 64.5833%, Training Loss: 0.4623%\n",
      "Epoch [31/300], Step [7/23], Training Accuracy: 64.9554%, Training Loss: 0.4655%\n",
      "Epoch [31/300], Step [8/23], Training Accuracy: 64.6484%, Training Loss: 0.4661%\n",
      "Epoch [31/300], Step [9/23], Training Accuracy: 63.5417%, Training Loss: 0.4710%\n",
      "Epoch [31/300], Step [10/23], Training Accuracy: 64.2188%, Training Loss: 0.4641%\n",
      "Epoch [31/300], Step [11/23], Training Accuracy: 65.0568%, Training Loss: 0.4618%\n",
      "Epoch [31/300], Step [12/23], Training Accuracy: 64.7135%, Training Loss: 0.4632%\n",
      "Epoch [31/300], Step [13/23], Training Accuracy: 65.0240%, Training Loss: 0.4612%\n",
      "Epoch [31/300], Step [14/23], Training Accuracy: 64.9554%, Training Loss: 0.4620%\n",
      "Epoch [31/300], Step [15/23], Training Accuracy: 64.4792%, Training Loss: 0.4693%\n",
      "Epoch [31/300], Step [16/23], Training Accuracy: 64.8438%, Training Loss: 0.4661%\n",
      "Epoch [31/300], Step [17/23], Training Accuracy: 65.3493%, Training Loss: 0.4649%\n",
      "Epoch [31/300], Step [18/23], Training Accuracy: 65.2778%, Training Loss: 0.4643%\n",
      "Epoch [31/300], Step [19/23], Training Accuracy: 65.2961%, Training Loss: 0.4634%\n",
      "Epoch [31/300], Step [20/23], Training Accuracy: 65.3906%, Training Loss: 0.4619%\n",
      "Epoch [31/300], Step [21/23], Training Accuracy: 65.1786%, Training Loss: 0.4612%\n",
      "Epoch [31/300], Step [22/23], Training Accuracy: 65.1989%, Training Loss: 0.4611%\n",
      "Epoch [31/300], Step [23/23], Training Accuracy: 65.1842%, Training Loss: 0.4573%\n",
      "Epoch [32/300], Step [1/23], Training Accuracy: 64.0625%, Training Loss: 0.4518%\n",
      "Epoch [32/300], Step [2/23], Training Accuracy: 61.7188%, Training Loss: 0.4922%\n",
      "Epoch [32/300], Step [3/23], Training Accuracy: 59.8958%, Training Loss: 0.4899%\n",
      "Epoch [32/300], Step [4/23], Training Accuracy: 62.8906%, Training Loss: 0.4683%\n",
      "Epoch [32/300], Step [5/23], Training Accuracy: 62.1875%, Training Loss: 0.4720%\n",
      "Epoch [32/300], Step [6/23], Training Accuracy: 63.2812%, Training Loss: 0.4669%\n",
      "Epoch [32/300], Step [7/23], Training Accuracy: 64.2857%, Training Loss: 0.4647%\n",
      "Epoch [32/300], Step [8/23], Training Accuracy: 64.2578%, Training Loss: 0.4671%\n",
      "Epoch [32/300], Step [9/23], Training Accuracy: 64.0625%, Training Loss: 0.4700%\n",
      "Epoch [32/300], Step [10/23], Training Accuracy: 64.3750%, Training Loss: 0.4646%\n",
      "Epoch [32/300], Step [11/23], Training Accuracy: 65.1989%, Training Loss: 0.4601%\n",
      "Epoch [32/300], Step [12/23], Training Accuracy: 65.2344%, Training Loss: 0.4645%\n",
      "Epoch [32/300], Step [13/23], Training Accuracy: 65.2644%, Training Loss: 0.4612%\n",
      "Epoch [32/300], Step [14/23], Training Accuracy: 64.9554%, Training Loss: 0.4626%\n",
      "Epoch [32/300], Step [15/23], Training Accuracy: 64.3750%, Training Loss: 0.4677%\n",
      "Epoch [32/300], Step [16/23], Training Accuracy: 64.7461%, Training Loss: 0.4644%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/300], Step [17/23], Training Accuracy: 64.9816%, Training Loss: 0.4644%\n",
      "Epoch [32/300], Step [18/23], Training Accuracy: 64.9306%, Training Loss: 0.4639%\n",
      "Epoch [32/300], Step [19/23], Training Accuracy: 65.2961%, Training Loss: 0.4616%\n",
      "Epoch [32/300], Step [20/23], Training Accuracy: 65.4688%, Training Loss: 0.4591%\n",
      "Epoch [32/300], Step [21/23], Training Accuracy: 65.6250%, Training Loss: 0.4576%\n",
      "Epoch [32/300], Step [22/23], Training Accuracy: 65.8381%, Training Loss: 0.4573%\n",
      "Epoch [32/300], Step [23/23], Training Accuracy: 66.0181%, Training Loss: 0.4539%\n",
      "Epoch [33/300], Step [1/23], Training Accuracy: 64.0625%, Training Loss: 0.4576%\n",
      "Epoch [33/300], Step [2/23], Training Accuracy: 64.0625%, Training Loss: 0.4712%\n",
      "Epoch [33/300], Step [3/23], Training Accuracy: 61.9792%, Training Loss: 0.4838%\n",
      "Epoch [33/300], Step [4/23], Training Accuracy: 62.8906%, Training Loss: 0.4705%\n",
      "Epoch [33/300], Step [5/23], Training Accuracy: 64.0625%, Training Loss: 0.4647%\n",
      "Epoch [33/300], Step [6/23], Training Accuracy: 65.6250%, Training Loss: 0.4618%\n",
      "Epoch [33/300], Step [7/23], Training Accuracy: 66.7411%, Training Loss: 0.4638%\n",
      "Epoch [33/300], Step [8/23], Training Accuracy: 67.1875%, Training Loss: 0.4588%\n",
      "Epoch [33/300], Step [9/23], Training Accuracy: 66.6667%, Training Loss: 0.4640%\n",
      "Epoch [33/300], Step [10/23], Training Accuracy: 66.4062%, Training Loss: 0.4586%\n",
      "Epoch [33/300], Step [11/23], Training Accuracy: 66.7614%, Training Loss: 0.4549%\n",
      "Epoch [33/300], Step [12/23], Training Accuracy: 66.7969%, Training Loss: 0.4556%\n",
      "Epoch [33/300], Step [13/23], Training Accuracy: 66.5865%, Training Loss: 0.4562%\n",
      "Epoch [33/300], Step [14/23], Training Accuracy: 65.9598%, Training Loss: 0.4609%\n",
      "Epoch [33/300], Step [15/23], Training Accuracy: 65.0000%, Training Loss: 0.4662%\n",
      "Epoch [33/300], Step [16/23], Training Accuracy: 64.9414%, Training Loss: 0.4641%\n",
      "Epoch [33/300], Step [17/23], Training Accuracy: 65.2574%, Training Loss: 0.4598%\n",
      "Epoch [33/300], Step [18/23], Training Accuracy: 64.9306%, Training Loss: 0.4604%\n",
      "Epoch [33/300], Step [19/23], Training Accuracy: 65.3783%, Training Loss: 0.4566%\n",
      "Epoch [33/300], Step [20/23], Training Accuracy: 65.8594%, Training Loss: 0.4538%\n",
      "Epoch [33/300], Step [21/23], Training Accuracy: 66.0714%, Training Loss: 0.4518%\n",
      "Epoch [33/300], Step [22/23], Training Accuracy: 66.2642%, Training Loss: 0.4501%\n",
      "Epoch [33/300], Step [23/23], Training Accuracy: 66.4350%, Training Loss: 0.4473%\n",
      "Epoch [34/300], Step [1/23], Training Accuracy: 67.1875%, Training Loss: 0.4334%\n",
      "Epoch [34/300], Step [2/23], Training Accuracy: 67.1875%, Training Loss: 0.4428%\n",
      "Epoch [34/300], Step [3/23], Training Accuracy: 64.5833%, Training Loss: 0.4471%\n",
      "Epoch [34/300], Step [4/23], Training Accuracy: 65.6250%, Training Loss: 0.4366%\n",
      "Epoch [34/300], Step [5/23], Training Accuracy: 64.0625%, Training Loss: 0.4425%\n",
      "Epoch [34/300], Step [6/23], Training Accuracy: 64.8438%, Training Loss: 0.4428%\n",
      "Epoch [34/300], Step [7/23], Training Accuracy: 65.1786%, Training Loss: 0.4438%\n",
      "Epoch [34/300], Step [8/23], Training Accuracy: 65.8203%, Training Loss: 0.4422%\n",
      "Epoch [34/300], Step [9/23], Training Accuracy: 64.9306%, Training Loss: 0.4479%\n",
      "Epoch [34/300], Step [10/23], Training Accuracy: 65.4688%, Training Loss: 0.4424%\n",
      "Epoch [34/300], Step [11/23], Training Accuracy: 65.7670%, Training Loss: 0.4417%\n",
      "Epoch [34/300], Step [12/23], Training Accuracy: 65.6250%, Training Loss: 0.4429%\n",
      "Epoch [34/300], Step [13/23], Training Accuracy: 65.3846%, Training Loss: 0.4444%\n",
      "Epoch [34/300], Step [14/23], Training Accuracy: 65.5134%, Training Loss: 0.4460%\n",
      "Epoch [34/300], Step [15/23], Training Accuracy: 64.6875%, Training Loss: 0.4530%\n",
      "Epoch [34/300], Step [16/23], Training Accuracy: 65.0391%, Training Loss: 0.4519%\n",
      "Epoch [34/300], Step [17/23], Training Accuracy: 65.3493%, Training Loss: 0.4499%\n",
      "Epoch [34/300], Step [18/23], Training Accuracy: 65.1910%, Training Loss: 0.4504%\n",
      "Epoch [34/300], Step [19/23], Training Accuracy: 65.7072%, Training Loss: 0.4490%\n",
      "Epoch [34/300], Step [20/23], Training Accuracy: 66.0156%, Training Loss: 0.4466%\n",
      "Epoch [34/300], Step [21/23], Training Accuracy: 65.9970%, Training Loss: 0.4446%\n",
      "Epoch [34/300], Step [22/23], Training Accuracy: 66.2642%, Training Loss: 0.4439%\n",
      "Epoch [34/300], Step [23/23], Training Accuracy: 66.3655%, Training Loss: 0.4401%\n",
      "Epoch [35/300], Step [1/23], Training Accuracy: 70.3125%, Training Loss: 0.4313%\n",
      "Epoch [35/300], Step [2/23], Training Accuracy: 66.4062%, Training Loss: 0.4606%\n",
      "Epoch [35/300], Step [3/23], Training Accuracy: 61.9792%, Training Loss: 0.4637%\n",
      "Epoch [35/300], Step [4/23], Training Accuracy: 64.0625%, Training Loss: 0.4504%\n",
      "Epoch [35/300], Step [5/23], Training Accuracy: 63.4375%, Training Loss: 0.4506%\n",
      "Epoch [35/300], Step [6/23], Training Accuracy: 64.3229%, Training Loss: 0.4533%\n",
      "Epoch [35/300], Step [7/23], Training Accuracy: 64.9554%, Training Loss: 0.4555%\n",
      "Epoch [35/300], Step [8/23], Training Accuracy: 65.6250%, Training Loss: 0.4461%\n",
      "Epoch [35/300], Step [9/23], Training Accuracy: 64.9306%, Training Loss: 0.4474%\n",
      "Epoch [35/300], Step [10/23], Training Accuracy: 65.3125%, Training Loss: 0.4443%\n",
      "Epoch [35/300], Step [11/23], Training Accuracy: 66.1932%, Training Loss: 0.4397%\n",
      "Epoch [35/300], Step [12/23], Training Accuracy: 66.1458%, Training Loss: 0.4423%\n",
      "Epoch [35/300], Step [13/23], Training Accuracy: 66.3462%, Training Loss: 0.4430%\n",
      "Epoch [35/300], Step [14/23], Training Accuracy: 66.2946%, Training Loss: 0.4459%\n",
      "Epoch [35/300], Step [15/23], Training Accuracy: 65.6250%, Training Loss: 0.4522%\n",
      "Epoch [35/300], Step [16/23], Training Accuracy: 65.6250%, Training Loss: 0.4499%\n",
      "Epoch [35/300], Step [17/23], Training Accuracy: 65.8088%, Training Loss: 0.4486%\n",
      "Epoch [35/300], Step [18/23], Training Accuracy: 65.7118%, Training Loss: 0.4476%\n",
      "Epoch [35/300], Step [19/23], Training Accuracy: 65.9539%, Training Loss: 0.4477%\n",
      "Epoch [35/300], Step [20/23], Training Accuracy: 66.1719%, Training Loss: 0.4464%\n",
      "Epoch [35/300], Step [21/23], Training Accuracy: 66.2202%, Training Loss: 0.4451%\n",
      "Epoch [35/300], Step [22/23], Training Accuracy: 66.6903%, Training Loss: 0.4429%\n",
      "Epoch [35/300], Step [23/23], Training Accuracy: 66.7825%, Training Loss: 0.4402%\n",
      "Epoch [36/300], Step [1/23], Training Accuracy: 70.3125%, Training Loss: 0.4143%\n",
      "Epoch [36/300], Step [2/23], Training Accuracy: 64.8438%, Training Loss: 0.4430%\n",
      "Epoch [36/300], Step [3/23], Training Accuracy: 64.0625%, Training Loss: 0.4487%\n",
      "Epoch [36/300], Step [4/23], Training Accuracy: 66.4062%, Training Loss: 0.4324%\n",
      "Epoch [36/300], Step [5/23], Training Accuracy: 65.9375%, Training Loss: 0.4392%\n",
      "Epoch [36/300], Step [6/23], Training Accuracy: 66.4062%, Training Loss: 0.4381%\n",
      "Epoch [36/300], Step [7/23], Training Accuracy: 66.5179%, Training Loss: 0.4398%\n",
      "Epoch [36/300], Step [8/23], Training Accuracy: 67.3828%, Training Loss: 0.4341%\n",
      "Epoch [36/300], Step [9/23], Training Accuracy: 66.8403%, Training Loss: 0.4398%\n",
      "Epoch [36/300], Step [10/23], Training Accuracy: 66.5625%, Training Loss: 0.4367%\n",
      "Epoch [36/300], Step [11/23], Training Accuracy: 66.9034%, Training Loss: 0.4351%\n",
      "Epoch [36/300], Step [12/23], Training Accuracy: 67.0573%, Training Loss: 0.4388%\n",
      "Epoch [36/300], Step [13/23], Training Accuracy: 67.3077%, Training Loss: 0.4378%\n",
      "Epoch [36/300], Step [14/23], Training Accuracy: 66.8527%, Training Loss: 0.4395%\n",
      "Epoch [36/300], Step [15/23], Training Accuracy: 66.2500%, Training Loss: 0.4462%\n",
      "Epoch [36/300], Step [16/23], Training Accuracy: 66.5039%, Training Loss: 0.4433%\n",
      "Epoch [36/300], Step [17/23], Training Accuracy: 66.4522%, Training Loss: 0.4430%\n",
      "Epoch [36/300], Step [18/23], Training Accuracy: 66.4062%, Training Loss: 0.4417%\n",
      "Epoch [36/300], Step [19/23], Training Accuracy: 66.6118%, Training Loss: 0.4393%\n",
      "Epoch [36/300], Step [20/23], Training Accuracy: 66.8750%, Training Loss: 0.4373%\n",
      "Epoch [36/300], Step [21/23], Training Accuracy: 66.9643%, Training Loss: 0.4349%\n",
      "Epoch [36/300], Step [22/23], Training Accuracy: 67.0455%, Training Loss: 0.4344%\n",
      "Epoch [36/300], Step [23/23], Training Accuracy: 67.2689%, Training Loss: 0.4311%\n",
      "Epoch [37/300], Step [1/23], Training Accuracy: 70.3125%, Training Loss: 0.4183%\n",
      "Epoch [37/300], Step [2/23], Training Accuracy: 70.3125%, Training Loss: 0.4414%\n",
      "Epoch [37/300], Step [3/23], Training Accuracy: 67.1875%, Training Loss: 0.4452%\n",
      "Epoch [37/300], Step [4/23], Training Accuracy: 68.7500%, Training Loss: 0.4269%\n",
      "Epoch [37/300], Step [5/23], Training Accuracy: 67.8125%, Training Loss: 0.4301%\n",
      "Epoch [37/300], Step [6/23], Training Accuracy: 68.2292%, Training Loss: 0.4303%\n",
      "Epoch [37/300], Step [7/23], Training Accuracy: 67.8571%, Training Loss: 0.4324%\n",
      "Epoch [37/300], Step [8/23], Training Accuracy: 68.5547%, Training Loss: 0.4253%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/300], Step [9/23], Training Accuracy: 68.0556%, Training Loss: 0.4295%\n",
      "Epoch [37/300], Step [10/23], Training Accuracy: 68.2812%, Training Loss: 0.4266%\n",
      "Epoch [37/300], Step [11/23], Training Accuracy: 68.3239%, Training Loss: 0.4243%\n",
      "Epoch [37/300], Step [12/23], Training Accuracy: 67.8385%, Training Loss: 0.4268%\n",
      "Epoch [37/300], Step [13/23], Training Accuracy: 67.3077%, Training Loss: 0.4280%\n",
      "Epoch [37/300], Step [14/23], Training Accuracy: 66.9643%, Training Loss: 0.4302%\n",
      "Epoch [37/300], Step [15/23], Training Accuracy: 66.3542%, Training Loss: 0.4370%\n",
      "Epoch [37/300], Step [16/23], Training Accuracy: 66.2109%, Training Loss: 0.4361%\n",
      "Epoch [37/300], Step [17/23], Training Accuracy: 66.5441%, Training Loss: 0.4357%\n",
      "Epoch [37/300], Step [18/23], Training Accuracy: 66.8403%, Training Loss: 0.4341%\n",
      "Epoch [37/300], Step [19/23], Training Accuracy: 67.2697%, Training Loss: 0.4323%\n",
      "Epoch [37/300], Step [20/23], Training Accuracy: 67.7344%, Training Loss: 0.4299%\n",
      "Epoch [37/300], Step [21/23], Training Accuracy: 67.4851%, Training Loss: 0.4298%\n",
      "Epoch [37/300], Step [22/23], Training Accuracy: 67.6847%, Training Loss: 0.4282%\n",
      "Epoch [37/300], Step [23/23], Training Accuracy: 67.8944%, Training Loss: 0.4256%\n",
      "Epoch [38/300], Step [1/23], Training Accuracy: 71.8750%, Training Loss: 0.4208%\n",
      "Epoch [38/300], Step [2/23], Training Accuracy: 67.9688%, Training Loss: 0.4362%\n",
      "Epoch [38/300], Step [3/23], Training Accuracy: 66.1458%, Training Loss: 0.4383%\n",
      "Epoch [38/300], Step [4/23], Training Accuracy: 67.5781%, Training Loss: 0.4255%\n",
      "Epoch [38/300], Step [5/23], Training Accuracy: 67.1875%, Training Loss: 0.4284%\n",
      "Epoch [38/300], Step [6/23], Training Accuracy: 66.9271%, Training Loss: 0.4261%\n",
      "Epoch [38/300], Step [7/23], Training Accuracy: 68.0804%, Training Loss: 0.4278%\n",
      "Epoch [38/300], Step [8/23], Training Accuracy: 68.5547%, Training Loss: 0.4256%\n",
      "Epoch [38/300], Step [9/23], Training Accuracy: 67.8819%, Training Loss: 0.4278%\n",
      "Epoch [38/300], Step [10/23], Training Accuracy: 67.6562%, Training Loss: 0.4285%\n",
      "Epoch [38/300], Step [11/23], Training Accuracy: 68.7500%, Training Loss: 0.4254%\n",
      "Epoch [38/300], Step [12/23], Training Accuracy: 68.0990%, Training Loss: 0.4281%\n",
      "Epoch [38/300], Step [13/23], Training Accuracy: 68.0288%, Training Loss: 0.4291%\n",
      "Epoch [38/300], Step [14/23], Training Accuracy: 67.6339%, Training Loss: 0.4288%\n",
      "Epoch [38/300], Step [15/23], Training Accuracy: 67.0833%, Training Loss: 0.4327%\n",
      "Epoch [38/300], Step [16/23], Training Accuracy: 67.2852%, Training Loss: 0.4312%\n",
      "Epoch [38/300], Step [17/23], Training Accuracy: 67.5551%, Training Loss: 0.4302%\n",
      "Epoch [38/300], Step [18/23], Training Accuracy: 67.7083%, Training Loss: 0.4300%\n",
      "Epoch [38/300], Step [19/23], Training Accuracy: 67.9276%, Training Loss: 0.4291%\n",
      "Epoch [38/300], Step [20/23], Training Accuracy: 68.3594%, Training Loss: 0.4266%\n",
      "Epoch [38/300], Step [21/23], Training Accuracy: 68.6756%, Training Loss: 0.4241%\n",
      "Epoch [38/300], Step [22/23], Training Accuracy: 68.8210%, Training Loss: 0.4231%\n",
      "Epoch [38/300], Step [23/23], Training Accuracy: 68.7978%, Training Loss: 0.4206%\n",
      "Epoch [39/300], Step [1/23], Training Accuracy: 64.0625%, Training Loss: 0.4210%\n",
      "Epoch [39/300], Step [2/23], Training Accuracy: 63.2812%, Training Loss: 0.4357%\n",
      "Epoch [39/300], Step [3/23], Training Accuracy: 61.4583%, Training Loss: 0.4355%\n",
      "Epoch [39/300], Step [4/23], Training Accuracy: 66.0156%, Training Loss: 0.4150%\n",
      "Epoch [39/300], Step [5/23], Training Accuracy: 65.9375%, Training Loss: 0.4160%\n",
      "Epoch [39/300], Step [6/23], Training Accuracy: 66.1458%, Training Loss: 0.4198%\n",
      "Epoch [39/300], Step [7/23], Training Accuracy: 66.5179%, Training Loss: 0.4256%\n",
      "Epoch [39/300], Step [8/23], Training Accuracy: 67.3828%, Training Loss: 0.4203%\n",
      "Epoch [39/300], Step [9/23], Training Accuracy: 67.1875%, Training Loss: 0.4243%\n",
      "Epoch [39/300], Step [10/23], Training Accuracy: 67.1875%, Training Loss: 0.4197%\n",
      "Epoch [39/300], Step [11/23], Training Accuracy: 67.4716%, Training Loss: 0.4231%\n",
      "Epoch [39/300], Step [12/23], Training Accuracy: 67.5781%, Training Loss: 0.4249%\n",
      "Epoch [39/300], Step [13/23], Training Accuracy: 67.1875%, Training Loss: 0.4239%\n",
      "Epoch [39/300], Step [14/23], Training Accuracy: 67.2991%, Training Loss: 0.4256%\n",
      "Epoch [39/300], Step [15/23], Training Accuracy: 67.0833%, Training Loss: 0.4310%\n",
      "Epoch [39/300], Step [16/23], Training Accuracy: 67.4805%, Training Loss: 0.4304%\n",
      "Epoch [39/300], Step [17/23], Training Accuracy: 67.7390%, Training Loss: 0.4293%\n",
      "Epoch [39/300], Step [18/23], Training Accuracy: 67.7083%, Training Loss: 0.4281%\n",
      "Epoch [39/300], Step [19/23], Training Accuracy: 68.0921%, Training Loss: 0.4251%\n",
      "Epoch [39/300], Step [20/23], Training Accuracy: 68.2031%, Training Loss: 0.4248%\n",
      "Epoch [39/300], Step [21/23], Training Accuracy: 68.4524%, Training Loss: 0.4222%\n",
      "Epoch [39/300], Step [22/23], Training Accuracy: 68.4659%, Training Loss: 0.4214%\n",
      "Epoch [39/300], Step [23/23], Training Accuracy: 68.5893%, Training Loss: 0.4185%\n",
      "Epoch [40/300], Step [1/23], Training Accuracy: 71.8750%, Training Loss: 0.4015%\n",
      "Epoch [40/300], Step [2/23], Training Accuracy: 66.4062%, Training Loss: 0.4279%\n",
      "Epoch [40/300], Step [3/23], Training Accuracy: 63.5417%, Training Loss: 0.4421%\n",
      "Epoch [40/300], Step [4/23], Training Accuracy: 66.4062%, Training Loss: 0.4290%\n",
      "Epoch [40/300], Step [5/23], Training Accuracy: 66.5625%, Training Loss: 0.4226%\n",
      "Epoch [40/300], Step [6/23], Training Accuracy: 67.4479%, Training Loss: 0.4239%\n",
      "Epoch [40/300], Step [7/23], Training Accuracy: 68.0804%, Training Loss: 0.4213%\n",
      "Epoch [40/300], Step [8/23], Training Accuracy: 68.7500%, Training Loss: 0.4179%\n",
      "Epoch [40/300], Step [9/23], Training Accuracy: 68.4028%, Training Loss: 0.4177%\n",
      "Epoch [40/300], Step [10/23], Training Accuracy: 68.4375%, Training Loss: 0.4166%\n",
      "Epoch [40/300], Step [11/23], Training Accuracy: 68.8920%, Training Loss: 0.4168%\n",
      "Epoch [40/300], Step [12/23], Training Accuracy: 68.7500%, Training Loss: 0.4179%\n",
      "Epoch [40/300], Step [13/23], Training Accuracy: 68.3894%, Training Loss: 0.4199%\n",
      "Epoch [40/300], Step [14/23], Training Accuracy: 68.3036%, Training Loss: 0.4221%\n",
      "Epoch [40/300], Step [15/23], Training Accuracy: 67.6042%, Training Loss: 0.4276%\n",
      "Epoch [40/300], Step [16/23], Training Accuracy: 67.8711%, Training Loss: 0.4253%\n",
      "Epoch [40/300], Step [17/23], Training Accuracy: 67.8309%, Training Loss: 0.4256%\n",
      "Epoch [40/300], Step [18/23], Training Accuracy: 67.8819%, Training Loss: 0.4257%\n",
      "Epoch [40/300], Step [19/23], Training Accuracy: 68.2566%, Training Loss: 0.4257%\n",
      "Epoch [40/300], Step [20/23], Training Accuracy: 68.5156%, Training Loss: 0.4227%\n",
      "Epoch [40/300], Step [21/23], Training Accuracy: 68.6012%, Training Loss: 0.4217%\n",
      "Epoch [40/300], Step [22/23], Training Accuracy: 68.5369%, Training Loss: 0.4208%\n",
      "Epoch [40/300], Step [23/23], Training Accuracy: 68.7283%, Training Loss: 0.4175%\n",
      "Epoch [41/300], Step [1/23], Training Accuracy: 64.0625%, Training Loss: 0.4100%\n",
      "Epoch [41/300], Step [2/23], Training Accuracy: 60.1562%, Training Loss: 0.4373%\n",
      "Epoch [41/300], Step [3/23], Training Accuracy: 60.4167%, Training Loss: 0.4349%\n",
      "Epoch [41/300], Step [4/23], Training Accuracy: 66.0156%, Training Loss: 0.4125%\n",
      "Epoch [41/300], Step [5/23], Training Accuracy: 66.8750%, Training Loss: 0.4075%\n",
      "Epoch [41/300], Step [6/23], Training Accuracy: 67.9688%, Training Loss: 0.4047%\n",
      "Epoch [41/300], Step [7/23], Training Accuracy: 68.9732%, Training Loss: 0.4094%\n",
      "Epoch [41/300], Step [8/23], Training Accuracy: 68.5547%, Training Loss: 0.4107%\n",
      "Epoch [41/300], Step [9/23], Training Accuracy: 67.5347%, Training Loss: 0.4136%\n",
      "Epoch [41/300], Step [10/23], Training Accuracy: 68.1250%, Training Loss: 0.4099%\n",
      "Epoch [41/300], Step [11/23], Training Accuracy: 68.6080%, Training Loss: 0.4097%\n",
      "Epoch [41/300], Step [12/23], Training Accuracy: 69.0104%, Training Loss: 0.4086%\n",
      "Epoch [41/300], Step [13/23], Training Accuracy: 68.7500%, Training Loss: 0.4098%\n",
      "Epoch [41/300], Step [14/23], Training Accuracy: 67.7455%, Training Loss: 0.4163%\n",
      "Epoch [41/300], Step [15/23], Training Accuracy: 67.3958%, Training Loss: 0.4222%\n",
      "Epoch [41/300], Step [16/23], Training Accuracy: 67.4805%, Training Loss: 0.4199%\n",
      "Epoch [41/300], Step [17/23], Training Accuracy: 67.5551%, Training Loss: 0.4198%\n",
      "Epoch [41/300], Step [18/23], Training Accuracy: 67.5347%, Training Loss: 0.4209%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/300], Step [19/23], Training Accuracy: 67.7632%, Training Loss: 0.4193%\n",
      "Epoch [41/300], Step [20/23], Training Accuracy: 68.0469%, Training Loss: 0.4164%\n",
      "Epoch [41/300], Step [21/23], Training Accuracy: 68.5268%, Training Loss: 0.4152%\n",
      "Epoch [41/300], Step [22/23], Training Accuracy: 68.8210%, Training Loss: 0.4138%\n",
      "Epoch [41/300], Step [23/23], Training Accuracy: 68.9368%, Training Loss: 0.4097%\n",
      "Epoch [42/300], Step [1/23], Training Accuracy: 65.6250%, Training Loss: 0.3988%\n",
      "Epoch [42/300], Step [2/23], Training Accuracy: 61.7188%, Training Loss: 0.4244%\n",
      "Epoch [42/300], Step [3/23], Training Accuracy: 63.5417%, Training Loss: 0.4213%\n",
      "Epoch [42/300], Step [4/23], Training Accuracy: 67.5781%, Training Loss: 0.4021%\n",
      "Epoch [42/300], Step [5/23], Training Accuracy: 65.6250%, Training Loss: 0.4091%\n",
      "Epoch [42/300], Step [6/23], Training Accuracy: 67.4479%, Training Loss: 0.4084%\n",
      "Epoch [42/300], Step [7/23], Training Accuracy: 68.5268%, Training Loss: 0.4113%\n",
      "Epoch [42/300], Step [8/23], Training Accuracy: 68.7500%, Training Loss: 0.4078%\n",
      "Epoch [42/300], Step [9/23], Training Accuracy: 68.0556%, Training Loss: 0.4116%\n",
      "Epoch [42/300], Step [10/23], Training Accuracy: 67.8125%, Training Loss: 0.4086%\n",
      "Epoch [42/300], Step [11/23], Training Accuracy: 67.8977%, Training Loss: 0.4088%\n",
      "Epoch [42/300], Step [12/23], Training Accuracy: 68.0990%, Training Loss: 0.4103%\n",
      "Epoch [42/300], Step [13/23], Training Accuracy: 68.1490%, Training Loss: 0.4102%\n",
      "Epoch [42/300], Step [14/23], Training Accuracy: 68.1920%, Training Loss: 0.4123%\n",
      "Epoch [42/300], Step [15/23], Training Accuracy: 67.6042%, Training Loss: 0.4172%\n",
      "Epoch [42/300], Step [16/23], Training Accuracy: 67.8711%, Training Loss: 0.4162%\n",
      "Epoch [42/300], Step [17/23], Training Accuracy: 68.1066%, Training Loss: 0.4149%\n",
      "Epoch [42/300], Step [18/23], Training Accuracy: 68.0556%, Training Loss: 0.4154%\n",
      "Epoch [42/300], Step [19/23], Training Accuracy: 68.2566%, Training Loss: 0.4137%\n",
      "Epoch [42/300], Step [20/23], Training Accuracy: 68.5938%, Training Loss: 0.4111%\n",
      "Epoch [42/300], Step [21/23], Training Accuracy: 68.8988%, Training Loss: 0.4101%\n",
      "Epoch [42/300], Step [22/23], Training Accuracy: 68.8210%, Training Loss: 0.4108%\n",
      "Epoch [42/300], Step [23/23], Training Accuracy: 69.0063%, Training Loss: 0.4076%\n",
      "Epoch [43/300], Step [1/23], Training Accuracy: 71.8750%, Training Loss: 0.3952%\n",
      "Epoch [43/300], Step [2/23], Training Accuracy: 67.1875%, Training Loss: 0.4298%\n",
      "Epoch [43/300], Step [3/23], Training Accuracy: 65.1042%, Training Loss: 0.4307%\n",
      "Epoch [43/300], Step [4/23], Training Accuracy: 67.9688%, Training Loss: 0.4154%\n",
      "Epoch [43/300], Step [5/23], Training Accuracy: 67.5000%, Training Loss: 0.4126%\n",
      "Epoch [43/300], Step [6/23], Training Accuracy: 68.2292%, Training Loss: 0.4071%\n",
      "Epoch [43/300], Step [7/23], Training Accuracy: 69.4196%, Training Loss: 0.4078%\n",
      "Epoch [43/300], Step [8/23], Training Accuracy: 69.9219%, Training Loss: 0.4056%\n",
      "Epoch [43/300], Step [9/23], Training Accuracy: 69.6181%, Training Loss: 0.4084%\n",
      "Epoch [43/300], Step [10/23], Training Accuracy: 69.6875%, Training Loss: 0.4060%\n",
      "Epoch [43/300], Step [11/23], Training Accuracy: 70.4545%, Training Loss: 0.4017%\n",
      "Epoch [43/300], Step [12/23], Training Accuracy: 70.5729%, Training Loss: 0.4032%\n",
      "Epoch [43/300], Step [13/23], Training Accuracy: 70.3125%, Training Loss: 0.4061%\n",
      "Epoch [43/300], Step [14/23], Training Accuracy: 70.5357%, Training Loss: 0.4073%\n",
      "Epoch [43/300], Step [15/23], Training Accuracy: 69.8958%, Training Loss: 0.4128%\n",
      "Epoch [43/300], Step [16/23], Training Accuracy: 69.7266%, Training Loss: 0.4128%\n",
      "Epoch [43/300], Step [17/23], Training Accuracy: 69.4853%, Training Loss: 0.4137%\n",
      "Epoch [43/300], Step [18/23], Training Accuracy: 69.7917%, Training Loss: 0.4129%\n",
      "Epoch [43/300], Step [19/23], Training Accuracy: 70.3125%, Training Loss: 0.4107%\n",
      "Epoch [43/300], Step [20/23], Training Accuracy: 70.7812%, Training Loss: 0.4075%\n",
      "Epoch [43/300], Step [21/23], Training Accuracy: 71.0565%, Training Loss: 0.4063%\n",
      "Epoch [43/300], Step [22/23], Training Accuracy: 70.8807%, Training Loss: 0.4056%\n",
      "Epoch [43/300], Step [23/23], Training Accuracy: 71.0215%, Training Loss: 0.4021%\n",
      "Epoch [44/300], Step [1/23], Training Accuracy: 71.8750%, Training Loss: 0.4073%\n",
      "Epoch [44/300], Step [2/23], Training Accuracy: 69.5312%, Training Loss: 0.4240%\n",
      "Epoch [44/300], Step [3/23], Training Accuracy: 66.1458%, Training Loss: 0.4368%\n",
      "Epoch [44/300], Step [4/23], Training Accuracy: 69.1406%, Training Loss: 0.4123%\n",
      "Epoch [44/300], Step [5/23], Training Accuracy: 68.1250%, Training Loss: 0.4153%\n",
      "Epoch [44/300], Step [6/23], Training Accuracy: 68.2292%, Training Loss: 0.4128%\n",
      "Epoch [44/300], Step [7/23], Training Accuracy: 68.0804%, Training Loss: 0.4184%\n",
      "Epoch [44/300], Step [8/23], Training Accuracy: 68.9453%, Training Loss: 0.4158%\n",
      "Epoch [44/300], Step [9/23], Training Accuracy: 68.5764%, Training Loss: 0.4180%\n",
      "Epoch [44/300], Step [10/23], Training Accuracy: 69.0625%, Training Loss: 0.4118%\n",
      "Epoch [44/300], Step [11/23], Training Accuracy: 69.8864%, Training Loss: 0.4088%\n",
      "Epoch [44/300], Step [12/23], Training Accuracy: 69.5312%, Training Loss: 0.4143%\n",
      "Epoch [44/300], Step [13/23], Training Accuracy: 69.1106%, Training Loss: 0.4156%\n",
      "Epoch [44/300], Step [14/23], Training Accuracy: 68.9732%, Training Loss: 0.4178%\n",
      "Epoch [44/300], Step [15/23], Training Accuracy: 68.6458%, Training Loss: 0.4220%\n",
      "Epoch [44/300], Step [16/23], Training Accuracy: 68.4570%, Training Loss: 0.4195%\n",
      "Epoch [44/300], Step [17/23], Training Accuracy: 68.4743%, Training Loss: 0.4214%\n",
      "Epoch [44/300], Step [18/23], Training Accuracy: 68.5764%, Training Loss: 0.4202%\n",
      "Epoch [44/300], Step [19/23], Training Accuracy: 68.8322%, Training Loss: 0.4169%\n",
      "Epoch [44/300], Step [20/23], Training Accuracy: 69.0625%, Training Loss: 0.4145%\n",
      "Epoch [44/300], Step [21/23], Training Accuracy: 69.3452%, Training Loss: 0.4125%\n",
      "Epoch [44/300], Step [22/23], Training Accuracy: 69.5312%, Training Loss: 0.4100%\n",
      "Epoch [44/300], Step [23/23], Training Accuracy: 69.7012%, Training Loss: 0.4074%\n",
      "Epoch [45/300], Step [1/23], Training Accuracy: 65.6250%, Training Loss: 0.4141%\n",
      "Epoch [45/300], Step [2/23], Training Accuracy: 64.0625%, Training Loss: 0.4403%\n",
      "Epoch [45/300], Step [3/23], Training Accuracy: 63.0208%, Training Loss: 0.4386%\n",
      "Epoch [45/300], Step [4/23], Training Accuracy: 66.4062%, Training Loss: 0.4182%\n",
      "Epoch [45/300], Step [5/23], Training Accuracy: 65.6250%, Training Loss: 0.4184%\n",
      "Epoch [45/300], Step [6/23], Training Accuracy: 65.6250%, Training Loss: 0.4175%\n",
      "Epoch [45/300], Step [7/23], Training Accuracy: 67.1875%, Training Loss: 0.4161%\n",
      "Epoch [45/300], Step [8/23], Training Accuracy: 68.3594%, Training Loss: 0.4123%\n",
      "Epoch [45/300], Step [9/23], Training Accuracy: 68.0556%, Training Loss: 0.4132%\n",
      "Epoch [45/300], Step [10/23], Training Accuracy: 68.5938%, Training Loss: 0.4101%\n",
      "Epoch [45/300], Step [11/23], Training Accuracy: 69.3182%, Training Loss: 0.4062%\n",
      "Epoch [45/300], Step [12/23], Training Accuracy: 69.1406%, Training Loss: 0.4108%\n",
      "Epoch [45/300], Step [13/23], Training Accuracy: 69.2308%, Training Loss: 0.4099%\n",
      "Epoch [45/300], Step [14/23], Training Accuracy: 68.9732%, Training Loss: 0.4111%\n",
      "Epoch [45/300], Step [15/23], Training Accuracy: 68.4375%, Training Loss: 0.4152%\n",
      "Epoch [45/300], Step [16/23], Training Accuracy: 68.4570%, Training Loss: 0.4137%\n",
      "Epoch [45/300], Step [17/23], Training Accuracy: 69.0257%, Training Loss: 0.4128%\n",
      "Epoch [45/300], Step [18/23], Training Accuracy: 69.2708%, Training Loss: 0.4117%\n",
      "Epoch [45/300], Step [19/23], Training Accuracy: 69.1612%, Training Loss: 0.4122%\n",
      "Epoch [45/300], Step [20/23], Training Accuracy: 69.4531%, Training Loss: 0.4093%\n",
      "Epoch [45/300], Step [21/23], Training Accuracy: 69.6429%, Training Loss: 0.4078%\n",
      "Epoch [45/300], Step [22/23], Training Accuracy: 69.6733%, Training Loss: 0.4065%\n",
      "Epoch [45/300], Step [23/23], Training Accuracy: 69.7012%, Training Loss: 0.4045%\n",
      "Epoch [46/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3438%\n",
      "Epoch [46/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.4037%\n",
      "Epoch [46/300], Step [3/23], Training Accuracy: 68.2292%, Training Loss: 0.4179%\n",
      "Epoch [46/300], Step [4/23], Training Accuracy: 70.7031%, Training Loss: 0.3961%\n",
      "Epoch [46/300], Step [5/23], Training Accuracy: 69.6875%, Training Loss: 0.3957%\n",
      "Epoch [46/300], Step [6/23], Training Accuracy: 70.3125%, Training Loss: 0.4017%\n",
      "Epoch [46/300], Step [7/23], Training Accuracy: 70.0893%, Training Loss: 0.4031%\n",
      "Epoch [46/300], Step [8/23], Training Accuracy: 70.5078%, Training Loss: 0.4005%\n",
      "Epoch [46/300], Step [9/23], Training Accuracy: 70.4861%, Training Loss: 0.4065%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/300], Step [10/23], Training Accuracy: 70.6250%, Training Loss: 0.4039%\n",
      "Epoch [46/300], Step [11/23], Training Accuracy: 71.5909%, Training Loss: 0.4010%\n",
      "Epoch [46/300], Step [12/23], Training Accuracy: 71.3542%, Training Loss: 0.4034%\n",
      "Epoch [46/300], Step [13/23], Training Accuracy: 71.6346%, Training Loss: 0.4016%\n",
      "Epoch [46/300], Step [14/23], Training Accuracy: 71.3170%, Training Loss: 0.4045%\n",
      "Epoch [46/300], Step [15/23], Training Accuracy: 70.5208%, Training Loss: 0.4112%\n",
      "Epoch [46/300], Step [16/23], Training Accuracy: 70.4102%, Training Loss: 0.4102%\n",
      "Epoch [46/300], Step [17/23], Training Accuracy: 70.4044%, Training Loss: 0.4090%\n",
      "Epoch [46/300], Step [18/23], Training Accuracy: 70.3125%, Training Loss: 0.4078%\n",
      "Epoch [46/300], Step [19/23], Training Accuracy: 70.5592%, Training Loss: 0.4068%\n",
      "Epoch [46/300], Step [20/23], Training Accuracy: 70.6250%, Training Loss: 0.4055%\n",
      "Epoch [46/300], Step [21/23], Training Accuracy: 70.9077%, Training Loss: 0.4034%\n",
      "Epoch [46/300], Step [22/23], Training Accuracy: 70.8097%, Training Loss: 0.4038%\n",
      "Epoch [46/300], Step [23/23], Training Accuracy: 70.8826%, Training Loss: 0.4018%\n",
      "Epoch [47/300], Step [1/23], Training Accuracy: 68.7500%, Training Loss: 0.4147%\n",
      "Epoch [47/300], Step [2/23], Training Accuracy: 67.1875%, Training Loss: 0.4251%\n",
      "Epoch [47/300], Step [3/23], Training Accuracy: 66.1458%, Training Loss: 0.4283%\n",
      "Epoch [47/300], Step [4/23], Training Accuracy: 69.1406%, Training Loss: 0.4116%\n",
      "Epoch [47/300], Step [5/23], Training Accuracy: 67.8125%, Training Loss: 0.4150%\n",
      "Epoch [47/300], Step [6/23], Training Accuracy: 67.7083%, Training Loss: 0.4136%\n",
      "Epoch [47/300], Step [7/23], Training Accuracy: 68.3036%, Training Loss: 0.4154%\n",
      "Epoch [47/300], Step [8/23], Training Accuracy: 68.3594%, Training Loss: 0.4116%\n",
      "Epoch [47/300], Step [9/23], Training Accuracy: 67.7083%, Training Loss: 0.4121%\n",
      "Epoch [47/300], Step [10/23], Training Accuracy: 68.1250%, Training Loss: 0.4087%\n",
      "Epoch [47/300], Step [11/23], Training Accuracy: 68.6080%, Training Loss: 0.4052%\n",
      "Epoch [47/300], Step [12/23], Training Accuracy: 68.2292%, Training Loss: 0.4082%\n",
      "Epoch [47/300], Step [13/23], Training Accuracy: 68.3894%, Training Loss: 0.4085%\n",
      "Epoch [47/300], Step [14/23], Training Accuracy: 67.9688%, Training Loss: 0.4110%\n",
      "Epoch [47/300], Step [15/23], Training Accuracy: 67.5000%, Training Loss: 0.4151%\n",
      "Epoch [47/300], Step [16/23], Training Accuracy: 67.5781%, Training Loss: 0.4134%\n",
      "Epoch [47/300], Step [17/23], Training Accuracy: 67.7390%, Training Loss: 0.4131%\n",
      "Epoch [47/300], Step [18/23], Training Accuracy: 68.2292%, Training Loss: 0.4117%\n",
      "Epoch [47/300], Step [19/23], Training Accuracy: 68.5033%, Training Loss: 0.4112%\n",
      "Epoch [47/300], Step [20/23], Training Accuracy: 68.9062%, Training Loss: 0.4086%\n",
      "Epoch [47/300], Step [21/23], Training Accuracy: 69.3452%, Training Loss: 0.4059%\n",
      "Epoch [47/300], Step [22/23], Training Accuracy: 69.4602%, Training Loss: 0.4056%\n",
      "Epoch [47/300], Step [23/23], Training Accuracy: 69.7012%, Training Loss: 0.4015%\n",
      "Epoch [48/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3851%\n",
      "Epoch [48/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.3939%\n",
      "Epoch [48/300], Step [3/23], Training Accuracy: 71.3542%, Training Loss: 0.3953%\n",
      "Epoch [48/300], Step [4/23], Training Accuracy: 71.8750%, Training Loss: 0.3875%\n",
      "Epoch [48/300], Step [5/23], Training Accuracy: 71.5625%, Training Loss: 0.3923%\n",
      "Epoch [48/300], Step [6/23], Training Accuracy: 71.6146%, Training Loss: 0.3942%\n",
      "Epoch [48/300], Step [7/23], Training Accuracy: 71.2054%, Training Loss: 0.3970%\n",
      "Epoch [48/300], Step [8/23], Training Accuracy: 71.4844%, Training Loss: 0.3965%\n",
      "Epoch [48/300], Step [9/23], Training Accuracy: 71.0069%, Training Loss: 0.4007%\n",
      "Epoch [48/300], Step [10/23], Training Accuracy: 70.6250%, Training Loss: 0.3986%\n",
      "Epoch [48/300], Step [11/23], Training Accuracy: 71.8750%, Training Loss: 0.3962%\n",
      "Epoch [48/300], Step [12/23], Training Accuracy: 72.1354%, Training Loss: 0.3984%\n",
      "Epoch [48/300], Step [13/23], Training Accuracy: 71.5144%, Training Loss: 0.3990%\n",
      "Epoch [48/300], Step [14/23], Training Accuracy: 71.0938%, Training Loss: 0.4003%\n",
      "Epoch [48/300], Step [15/23], Training Accuracy: 70.6250%, Training Loss: 0.4044%\n",
      "Epoch [48/300], Step [16/23], Training Accuracy: 70.4102%, Training Loss: 0.4042%\n",
      "Epoch [48/300], Step [17/23], Training Accuracy: 70.3125%, Training Loss: 0.4038%\n",
      "Epoch [48/300], Step [18/23], Training Accuracy: 70.3993%, Training Loss: 0.4038%\n",
      "Epoch [48/300], Step [19/23], Training Accuracy: 70.5592%, Training Loss: 0.4024%\n",
      "Epoch [48/300], Step [20/23], Training Accuracy: 70.7031%, Training Loss: 0.4015%\n",
      "Epoch [48/300], Step [21/23], Training Accuracy: 71.1310%, Training Loss: 0.3992%\n",
      "Epoch [48/300], Step [22/23], Training Accuracy: 71.5909%, Training Loss: 0.3973%\n",
      "Epoch [48/300], Step [23/23], Training Accuracy: 71.7165%, Training Loss: 0.3934%\n",
      "Epoch [49/300], Step [1/23], Training Accuracy: 73.4375%, Training Loss: 0.3804%\n",
      "Epoch [49/300], Step [2/23], Training Accuracy: 71.0938%, Training Loss: 0.4121%\n",
      "Epoch [49/300], Step [3/23], Training Accuracy: 68.2292%, Training Loss: 0.4190%\n",
      "Epoch [49/300], Step [4/23], Training Accuracy: 70.7031%, Training Loss: 0.4021%\n",
      "Epoch [49/300], Step [5/23], Training Accuracy: 69.6875%, Training Loss: 0.4033%\n",
      "Epoch [49/300], Step [6/23], Training Accuracy: 69.5312%, Training Loss: 0.4097%\n",
      "Epoch [49/300], Step [7/23], Training Accuracy: 70.0893%, Training Loss: 0.4100%\n",
      "Epoch [49/300], Step [8/23], Training Accuracy: 70.5078%, Training Loss: 0.4076%\n",
      "Epoch [49/300], Step [9/23], Training Accuracy: 69.7917%, Training Loss: 0.4104%\n",
      "Epoch [49/300], Step [10/23], Training Accuracy: 70.3125%, Training Loss: 0.4048%\n",
      "Epoch [49/300], Step [11/23], Training Accuracy: 71.4489%, Training Loss: 0.3993%\n",
      "Epoch [49/300], Step [12/23], Training Accuracy: 71.6146%, Training Loss: 0.4029%\n",
      "Epoch [49/300], Step [13/23], Training Accuracy: 71.7548%, Training Loss: 0.4018%\n",
      "Epoch [49/300], Step [14/23], Training Accuracy: 71.0938%, Training Loss: 0.4039%\n",
      "Epoch [49/300], Step [15/23], Training Accuracy: 70.5208%, Training Loss: 0.4105%\n",
      "Epoch [49/300], Step [16/23], Training Accuracy: 70.4102%, Training Loss: 0.4081%\n",
      "Epoch [49/300], Step [17/23], Training Accuracy: 70.4044%, Training Loss: 0.4092%\n",
      "Epoch [49/300], Step [18/23], Training Accuracy: 70.4861%, Training Loss: 0.4069%\n",
      "Epoch [49/300], Step [19/23], Training Accuracy: 70.5592%, Training Loss: 0.4060%\n",
      "Epoch [49/300], Step [20/23], Training Accuracy: 70.9375%, Training Loss: 0.4034%\n",
      "Epoch [49/300], Step [21/23], Training Accuracy: 71.2798%, Training Loss: 0.4015%\n",
      "Epoch [49/300], Step [22/23], Training Accuracy: 70.9517%, Training Loss: 0.4016%\n",
      "Epoch [49/300], Step [23/23], Training Accuracy: 71.0215%, Training Loss: 0.3986%\n",
      "Epoch [50/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3911%\n",
      "Epoch [50/300], Step [2/23], Training Accuracy: 71.8750%, Training Loss: 0.4099%\n",
      "Epoch [50/300], Step [3/23], Training Accuracy: 69.2708%, Training Loss: 0.4212%\n",
      "Epoch [50/300], Step [4/23], Training Accuracy: 71.0938%, Training Loss: 0.4021%\n",
      "Epoch [50/300], Step [5/23], Training Accuracy: 69.6875%, Training Loss: 0.4016%\n",
      "Epoch [50/300], Step [6/23], Training Accuracy: 70.3125%, Training Loss: 0.3963%\n",
      "Epoch [50/300], Step [7/23], Training Accuracy: 70.5357%, Training Loss: 0.3975%\n",
      "Epoch [50/300], Step [8/23], Training Accuracy: 72.2656%, Training Loss: 0.3926%\n",
      "Epoch [50/300], Step [9/23], Training Accuracy: 71.3542%, Training Loss: 0.4003%\n",
      "Epoch [50/300], Step [10/23], Training Accuracy: 71.4062%, Training Loss: 0.3982%\n",
      "Epoch [50/300], Step [11/23], Training Accuracy: 71.3068%, Training Loss: 0.3971%\n",
      "Epoch [50/300], Step [12/23], Training Accuracy: 70.9635%, Training Loss: 0.3996%\n",
      "Epoch [50/300], Step [13/23], Training Accuracy: 70.6731%, Training Loss: 0.4002%\n",
      "Epoch [50/300], Step [14/23], Training Accuracy: 70.0893%, Training Loss: 0.4018%\n",
      "Epoch [50/300], Step [15/23], Training Accuracy: 70.1042%, Training Loss: 0.4054%\n",
      "Epoch [50/300], Step [16/23], Training Accuracy: 70.2148%, Training Loss: 0.4031%\n",
      "Epoch [50/300], Step [17/23], Training Accuracy: 70.6801%, Training Loss: 0.4020%\n",
      "Epoch [50/300], Step [18/23], Training Accuracy: 70.8333%, Training Loss: 0.4032%\n",
      "Epoch [50/300], Step [19/23], Training Accuracy: 70.8059%, Training Loss: 0.4036%\n",
      "Epoch [50/300], Step [20/23], Training Accuracy: 71.1719%, Training Loss: 0.4010%\n",
      "Epoch [50/300], Step [21/23], Training Accuracy: 71.3542%, Training Loss: 0.3988%\n",
      "Epoch [50/300], Step [22/23], Training Accuracy: 71.3778%, Training Loss: 0.3979%\n",
      "Epoch [50/300], Step [23/23], Training Accuracy: 71.5775%, Training Loss: 0.3941%\n",
      "Epoch [51/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3590%\n",
      "Epoch [51/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.3917%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/300], Step [3/23], Training Accuracy: 73.9583%, Training Loss: 0.3958%\n",
      "Epoch [51/300], Step [4/23], Training Accuracy: 75.0000%, Training Loss: 0.3804%\n",
      "Epoch [51/300], Step [5/23], Training Accuracy: 72.5000%, Training Loss: 0.3909%\n",
      "Epoch [51/300], Step [6/23], Training Accuracy: 72.3958%, Training Loss: 0.3946%\n",
      "Epoch [51/300], Step [7/23], Training Accuracy: 72.5446%, Training Loss: 0.3992%\n",
      "Epoch [51/300], Step [8/23], Training Accuracy: 72.2656%, Training Loss: 0.3941%\n",
      "Epoch [51/300], Step [9/23], Training Accuracy: 71.3542%, Training Loss: 0.3987%\n",
      "Epoch [51/300], Step [10/23], Training Accuracy: 70.9375%, Training Loss: 0.3962%\n",
      "Epoch [51/300], Step [11/23], Training Accuracy: 71.4489%, Training Loss: 0.3941%\n",
      "Epoch [51/300], Step [12/23], Training Accuracy: 71.3542%, Training Loss: 0.3959%\n",
      "Epoch [51/300], Step [13/23], Training Accuracy: 71.3942%, Training Loss: 0.3955%\n",
      "Epoch [51/300], Step [14/23], Training Accuracy: 70.8705%, Training Loss: 0.3963%\n",
      "Epoch [51/300], Step [15/23], Training Accuracy: 70.3125%, Training Loss: 0.3980%\n",
      "Epoch [51/300], Step [16/23], Training Accuracy: 70.3125%, Training Loss: 0.3987%\n",
      "Epoch [51/300], Step [17/23], Training Accuracy: 70.3125%, Training Loss: 0.3981%\n",
      "Epoch [51/300], Step [18/23], Training Accuracy: 70.4861%, Training Loss: 0.3964%\n",
      "Epoch [51/300], Step [19/23], Training Accuracy: 70.4770%, Training Loss: 0.3962%\n",
      "Epoch [51/300], Step [20/23], Training Accuracy: 70.6250%, Training Loss: 0.3946%\n",
      "Epoch [51/300], Step [21/23], Training Accuracy: 70.9077%, Training Loss: 0.3938%\n",
      "Epoch [51/300], Step [22/23], Training Accuracy: 70.7386%, Training Loss: 0.3931%\n",
      "Epoch [51/300], Step [23/23], Training Accuracy: 70.7436%, Training Loss: 0.3912%\n",
      "Epoch [52/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3686%\n",
      "Epoch [52/300], Step [2/23], Training Accuracy: 71.0938%, Training Loss: 0.3988%\n",
      "Epoch [52/300], Step [3/23], Training Accuracy: 68.7500%, Training Loss: 0.4111%\n",
      "Epoch [52/300], Step [4/23], Training Accuracy: 70.3125%, Training Loss: 0.3916%\n",
      "Epoch [52/300], Step [5/23], Training Accuracy: 69.0625%, Training Loss: 0.3965%\n",
      "Epoch [52/300], Step [6/23], Training Accuracy: 69.7917%, Training Loss: 0.3979%\n",
      "Epoch [52/300], Step [7/23], Training Accuracy: 70.5357%, Training Loss: 0.3998%\n",
      "Epoch [52/300], Step [8/23], Training Accuracy: 71.4844%, Training Loss: 0.3956%\n",
      "Epoch [52/300], Step [9/23], Training Accuracy: 70.6597%, Training Loss: 0.3989%\n",
      "Epoch [52/300], Step [10/23], Training Accuracy: 71.8750%, Training Loss: 0.3958%\n",
      "Epoch [52/300], Step [11/23], Training Accuracy: 72.3011%, Training Loss: 0.3941%\n",
      "Epoch [52/300], Step [12/23], Training Accuracy: 72.1354%, Training Loss: 0.3973%\n",
      "Epoch [52/300], Step [13/23], Training Accuracy: 71.2740%, Training Loss: 0.4008%\n",
      "Epoch [52/300], Step [14/23], Training Accuracy: 71.0938%, Training Loss: 0.4008%\n",
      "Epoch [52/300], Step [15/23], Training Accuracy: 70.8333%, Training Loss: 0.4040%\n",
      "Epoch [52/300], Step [16/23], Training Accuracy: 70.7031%, Training Loss: 0.4033%\n",
      "Epoch [52/300], Step [17/23], Training Accuracy: 70.7721%, Training Loss: 0.4031%\n",
      "Epoch [52/300], Step [18/23], Training Accuracy: 70.7465%, Training Loss: 0.4021%\n",
      "Epoch [52/300], Step [19/23], Training Accuracy: 70.8882%, Training Loss: 0.3999%\n",
      "Epoch [52/300], Step [20/23], Training Accuracy: 70.7812%, Training Loss: 0.3986%\n",
      "Epoch [52/300], Step [21/23], Training Accuracy: 71.1310%, Training Loss: 0.3970%\n",
      "Epoch [52/300], Step [22/23], Training Accuracy: 70.9517%, Training Loss: 0.3963%\n",
      "Epoch [52/300], Step [23/23], Training Accuracy: 71.0215%, Training Loss: 0.3923%\n",
      "Epoch [53/300], Step [1/23], Training Accuracy: 73.4375%, Training Loss: 0.3953%\n",
      "Epoch [53/300], Step [2/23], Training Accuracy: 70.3125%, Training Loss: 0.4171%\n",
      "Epoch [53/300], Step [3/23], Training Accuracy: 69.7917%, Training Loss: 0.4165%\n",
      "Epoch [53/300], Step [4/23], Training Accuracy: 71.4844%, Training Loss: 0.3961%\n",
      "Epoch [53/300], Step [5/23], Training Accuracy: 70.9375%, Training Loss: 0.3951%\n",
      "Epoch [53/300], Step [6/23], Training Accuracy: 71.0938%, Training Loss: 0.3927%\n",
      "Epoch [53/300], Step [7/23], Training Accuracy: 71.2054%, Training Loss: 0.3960%\n",
      "Epoch [53/300], Step [8/23], Training Accuracy: 71.4844%, Training Loss: 0.3960%\n",
      "Epoch [53/300], Step [9/23], Training Accuracy: 70.3125%, Training Loss: 0.3985%\n",
      "Epoch [53/300], Step [10/23], Training Accuracy: 70.9375%, Training Loss: 0.3941%\n",
      "Epoch [53/300], Step [11/23], Training Accuracy: 71.7330%, Training Loss: 0.3907%\n",
      "Epoch [53/300], Step [12/23], Training Accuracy: 71.8750%, Training Loss: 0.3922%\n",
      "Epoch [53/300], Step [13/23], Training Accuracy: 71.3942%, Training Loss: 0.3940%\n",
      "Epoch [53/300], Step [14/23], Training Accuracy: 71.2054%, Training Loss: 0.3957%\n",
      "Epoch [53/300], Step [15/23], Training Accuracy: 71.2500%, Training Loss: 0.3993%\n",
      "Epoch [53/300], Step [16/23], Training Accuracy: 70.9961%, Training Loss: 0.3984%\n",
      "Epoch [53/300], Step [17/23], Training Accuracy: 71.3235%, Training Loss: 0.3961%\n",
      "Epoch [53/300], Step [18/23], Training Accuracy: 71.3542%, Training Loss: 0.3957%\n",
      "Epoch [53/300], Step [19/23], Training Accuracy: 71.2171%, Training Loss: 0.3945%\n",
      "Epoch [53/300], Step [20/23], Training Accuracy: 71.4844%, Training Loss: 0.3926%\n",
      "Epoch [53/300], Step [21/23], Training Accuracy: 71.7262%, Training Loss: 0.3910%\n",
      "Epoch [53/300], Step [22/23], Training Accuracy: 71.6619%, Training Loss: 0.3902%\n",
      "Epoch [53/300], Step [23/23], Training Accuracy: 71.8555%, Training Loss: 0.3867%\n",
      "Epoch [54/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3707%\n",
      "Epoch [54/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.3998%\n",
      "Epoch [54/300], Step [3/23], Training Accuracy: 70.8333%, Training Loss: 0.3950%\n",
      "Epoch [54/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.3757%\n",
      "Epoch [54/300], Step [5/23], Training Accuracy: 74.0625%, Training Loss: 0.3781%\n",
      "Epoch [54/300], Step [6/23], Training Accuracy: 73.1771%, Training Loss: 0.3804%\n",
      "Epoch [54/300], Step [7/23], Training Accuracy: 73.4375%, Training Loss: 0.3848%\n",
      "Epoch [54/300], Step [8/23], Training Accuracy: 73.4375%, Training Loss: 0.3862%\n",
      "Epoch [54/300], Step [9/23], Training Accuracy: 72.0486%, Training Loss: 0.3926%\n",
      "Epoch [54/300], Step [10/23], Training Accuracy: 71.5625%, Training Loss: 0.3930%\n",
      "Epoch [54/300], Step [11/23], Training Accuracy: 72.3011%, Training Loss: 0.3881%\n",
      "Epoch [54/300], Step [12/23], Training Accuracy: 71.7448%, Training Loss: 0.3942%\n",
      "Epoch [54/300], Step [13/23], Training Accuracy: 71.7548%, Training Loss: 0.3951%\n",
      "Epoch [54/300], Step [14/23], Training Accuracy: 71.9866%, Training Loss: 0.3953%\n",
      "Epoch [54/300], Step [15/23], Training Accuracy: 71.5625%, Training Loss: 0.4022%\n",
      "Epoch [54/300], Step [16/23], Training Accuracy: 71.7773%, Training Loss: 0.4006%\n",
      "Epoch [54/300], Step [17/23], Training Accuracy: 71.6912%, Training Loss: 0.4012%\n",
      "Epoch [54/300], Step [18/23], Training Accuracy: 71.7882%, Training Loss: 0.4006%\n",
      "Epoch [54/300], Step [19/23], Training Accuracy: 72.2039%, Training Loss: 0.3980%\n",
      "Epoch [54/300], Step [20/23], Training Accuracy: 72.5000%, Training Loss: 0.3948%\n",
      "Epoch [54/300], Step [21/23], Training Accuracy: 72.5446%, Training Loss: 0.3944%\n",
      "Epoch [54/300], Step [22/23], Training Accuracy: 72.7983%, Training Loss: 0.3919%\n",
      "Epoch [54/300], Step [23/23], Training Accuracy: 72.7589%, Training Loss: 0.3885%\n",
      "Epoch [55/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3574%\n",
      "Epoch [55/300], Step [2/23], Training Accuracy: 71.8750%, Training Loss: 0.4085%\n",
      "Epoch [55/300], Step [3/23], Training Accuracy: 67.7083%, Training Loss: 0.4161%\n",
      "Epoch [55/300], Step [4/23], Training Accuracy: 69.9219%, Training Loss: 0.4007%\n",
      "Epoch [55/300], Step [5/23], Training Accuracy: 69.0625%, Training Loss: 0.4021%\n",
      "Epoch [55/300], Step [6/23], Training Accuracy: 70.5729%, Training Loss: 0.4034%\n",
      "Epoch [55/300], Step [7/23], Training Accuracy: 70.9821%, Training Loss: 0.4057%\n",
      "Epoch [55/300], Step [8/23], Training Accuracy: 71.8750%, Training Loss: 0.4012%\n",
      "Epoch [55/300], Step [9/23], Training Accuracy: 70.8333%, Training Loss: 0.4038%\n",
      "Epoch [55/300], Step [10/23], Training Accuracy: 70.9375%, Training Loss: 0.4020%\n",
      "Epoch [55/300], Step [11/23], Training Accuracy: 71.4489%, Training Loss: 0.3983%\n",
      "Epoch [55/300], Step [12/23], Training Accuracy: 71.4844%, Training Loss: 0.3975%\n",
      "Epoch [55/300], Step [13/23], Training Accuracy: 71.2740%, Training Loss: 0.3974%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/300], Step [14/23], Training Accuracy: 70.7589%, Training Loss: 0.3988%\n",
      "Epoch [55/300], Step [15/23], Training Accuracy: 70.4167%, Training Loss: 0.4034%\n",
      "Epoch [55/300], Step [16/23], Training Accuracy: 70.3125%, Training Loss: 0.4041%\n",
      "Epoch [55/300], Step [17/23], Training Accuracy: 70.5882%, Training Loss: 0.4027%\n",
      "Epoch [55/300], Step [18/23], Training Accuracy: 70.7465%, Training Loss: 0.4007%\n",
      "Epoch [55/300], Step [19/23], Training Accuracy: 70.8059%, Training Loss: 0.4015%\n",
      "Epoch [55/300], Step [20/23], Training Accuracy: 70.9375%, Training Loss: 0.4000%\n",
      "Epoch [55/300], Step [21/23], Training Accuracy: 71.0565%, Training Loss: 0.3981%\n",
      "Epoch [55/300], Step [22/23], Training Accuracy: 71.1648%, Training Loss: 0.3977%\n",
      "Epoch [55/300], Step [23/23], Training Accuracy: 71.1605%, Training Loss: 0.3948%\n",
      "Epoch [56/300], Step [1/23], Training Accuracy: 70.3125%, Training Loss: 0.3653%\n",
      "Epoch [56/300], Step [2/23], Training Accuracy: 71.8750%, Training Loss: 0.3946%\n",
      "Epoch [56/300], Step [3/23], Training Accuracy: 68.7500%, Training Loss: 0.4030%\n",
      "Epoch [56/300], Step [4/23], Training Accuracy: 70.7031%, Training Loss: 0.3867%\n",
      "Epoch [56/300], Step [5/23], Training Accuracy: 70.0000%, Training Loss: 0.3880%\n",
      "Epoch [56/300], Step [6/23], Training Accuracy: 70.5729%, Training Loss: 0.3889%\n",
      "Epoch [56/300], Step [7/23], Training Accuracy: 70.7589%, Training Loss: 0.3918%\n",
      "Epoch [56/300], Step [8/23], Training Accuracy: 71.8750%, Training Loss: 0.3916%\n",
      "Epoch [56/300], Step [9/23], Training Accuracy: 71.0069%, Training Loss: 0.3966%\n",
      "Epoch [56/300], Step [10/23], Training Accuracy: 71.4062%, Training Loss: 0.3914%\n",
      "Epoch [56/300], Step [11/23], Training Accuracy: 72.1591%, Training Loss: 0.3899%\n",
      "Epoch [56/300], Step [12/23], Training Accuracy: 72.7865%, Training Loss: 0.3925%\n",
      "Epoch [56/300], Step [13/23], Training Accuracy: 72.4760%, Training Loss: 0.3920%\n",
      "Epoch [56/300], Step [14/23], Training Accuracy: 72.3214%, Training Loss: 0.3925%\n",
      "Epoch [56/300], Step [15/23], Training Accuracy: 72.1875%, Training Loss: 0.3957%\n",
      "Epoch [56/300], Step [16/23], Training Accuracy: 71.9727%, Training Loss: 0.3949%\n",
      "Epoch [56/300], Step [17/23], Training Accuracy: 72.2426%, Training Loss: 0.3936%\n",
      "Epoch [56/300], Step [18/23], Training Accuracy: 72.1354%, Training Loss: 0.3926%\n",
      "Epoch [56/300], Step [19/23], Training Accuracy: 72.1217%, Training Loss: 0.3931%\n",
      "Epoch [56/300], Step [20/23], Training Accuracy: 72.3438%, Training Loss: 0.3915%\n",
      "Epoch [56/300], Step [21/23], Training Accuracy: 72.6190%, Training Loss: 0.3896%\n",
      "Epoch [56/300], Step [22/23], Training Accuracy: 72.5142%, Training Loss: 0.3890%\n",
      "Epoch [56/300], Step [23/23], Training Accuracy: 72.7589%, Training Loss: 0.3867%\n",
      "Epoch [57/300], Step [1/23], Training Accuracy: 82.8125%, Training Loss: 0.3663%\n",
      "Epoch [57/300], Step [2/23], Training Accuracy: 72.6562%, Training Loss: 0.4220%\n",
      "Epoch [57/300], Step [3/23], Training Accuracy: 70.3125%, Training Loss: 0.4231%\n",
      "Epoch [57/300], Step [4/23], Training Accuracy: 72.6562%, Training Loss: 0.3974%\n",
      "Epoch [57/300], Step [5/23], Training Accuracy: 71.2500%, Training Loss: 0.3967%\n",
      "Epoch [57/300], Step [6/23], Training Accuracy: 71.6146%, Training Loss: 0.3977%\n",
      "Epoch [57/300], Step [7/23], Training Accuracy: 71.6518%, Training Loss: 0.4041%\n",
      "Epoch [57/300], Step [8/23], Training Accuracy: 73.0469%, Training Loss: 0.4006%\n",
      "Epoch [57/300], Step [9/23], Training Accuracy: 71.5278%, Training Loss: 0.4096%\n",
      "Epoch [57/300], Step [10/23], Training Accuracy: 71.7188%, Training Loss: 0.4056%\n",
      "Epoch [57/300], Step [11/23], Training Accuracy: 72.3011%, Training Loss: 0.4040%\n",
      "Epoch [57/300], Step [12/23], Training Accuracy: 72.1354%, Training Loss: 0.4045%\n",
      "Epoch [57/300], Step [13/23], Training Accuracy: 71.5144%, Training Loss: 0.4051%\n",
      "Epoch [57/300], Step [14/23], Training Accuracy: 71.2054%, Training Loss: 0.4061%\n",
      "Epoch [57/300], Step [15/23], Training Accuracy: 70.9375%, Training Loss: 0.4090%\n",
      "Epoch [57/300], Step [16/23], Training Accuracy: 70.9961%, Training Loss: 0.4074%\n",
      "Epoch [57/300], Step [17/23], Training Accuracy: 71.2316%, Training Loss: 0.4070%\n",
      "Epoch [57/300], Step [18/23], Training Accuracy: 71.0938%, Training Loss: 0.4058%\n",
      "Epoch [57/300], Step [19/23], Training Accuracy: 71.2993%, Training Loss: 0.4043%\n",
      "Epoch [57/300], Step [20/23], Training Accuracy: 71.4062%, Training Loss: 0.4031%\n",
      "Epoch [57/300], Step [21/23], Training Accuracy: 71.5030%, Training Loss: 0.4013%\n",
      "Epoch [57/300], Step [22/23], Training Accuracy: 71.8750%, Training Loss: 0.3995%\n",
      "Epoch [57/300], Step [23/23], Training Accuracy: 72.0639%, Training Loss: 0.3959%\n",
      "Epoch [58/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3818%\n",
      "Epoch [58/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.4138%\n",
      "Epoch [58/300], Step [3/23], Training Accuracy: 70.8333%, Training Loss: 0.4057%\n",
      "Epoch [58/300], Step [4/23], Training Accuracy: 73.4375%, Training Loss: 0.3849%\n",
      "Epoch [58/300], Step [5/23], Training Accuracy: 71.8750%, Training Loss: 0.3869%\n",
      "Epoch [58/300], Step [6/23], Training Accuracy: 72.1354%, Training Loss: 0.3857%\n",
      "Epoch [58/300], Step [7/23], Training Accuracy: 72.3214%, Training Loss: 0.3909%\n",
      "Epoch [58/300], Step [8/23], Training Accuracy: 73.0469%, Training Loss: 0.3847%\n",
      "Epoch [58/300], Step [9/23], Training Accuracy: 73.2639%, Training Loss: 0.3846%\n",
      "Epoch [58/300], Step [10/23], Training Accuracy: 73.7500%, Training Loss: 0.3811%\n",
      "Epoch [58/300], Step [11/23], Training Accuracy: 73.5795%, Training Loss: 0.3818%\n",
      "Epoch [58/300], Step [12/23], Training Accuracy: 73.6979%, Training Loss: 0.3835%\n",
      "Epoch [58/300], Step [13/23], Training Accuracy: 73.0769%, Training Loss: 0.3845%\n",
      "Epoch [58/300], Step [14/23], Training Accuracy: 72.9911%, Training Loss: 0.3843%\n",
      "Epoch [58/300], Step [15/23], Training Accuracy: 72.8125%, Training Loss: 0.3883%\n",
      "Epoch [58/300], Step [16/23], Training Accuracy: 72.8516%, Training Loss: 0.3880%\n",
      "Epoch [58/300], Step [17/23], Training Accuracy: 72.7941%, Training Loss: 0.3874%\n",
      "Epoch [58/300], Step [18/23], Training Accuracy: 73.0035%, Training Loss: 0.3866%\n",
      "Epoch [58/300], Step [19/23], Training Accuracy: 73.1086%, Training Loss: 0.3856%\n",
      "Epoch [58/300], Step [20/23], Training Accuracy: 73.1250%, Training Loss: 0.3848%\n",
      "Epoch [58/300], Step [21/23], Training Accuracy: 73.5119%, Training Loss: 0.3830%\n",
      "Epoch [58/300], Step [22/23], Training Accuracy: 73.5795%, Training Loss: 0.3815%\n",
      "Epoch [58/300], Step [23/23], Training Accuracy: 73.6623%, Training Loss: 0.3787%\n",
      "Epoch [59/300], Step [1/23], Training Accuracy: 82.8125%, Training Loss: 0.3553%\n",
      "Epoch [59/300], Step [2/23], Training Accuracy: 72.6562%, Training Loss: 0.4010%\n",
      "Epoch [59/300], Step [3/23], Training Accuracy: 70.3125%, Training Loss: 0.4027%\n",
      "Epoch [59/300], Step [4/23], Training Accuracy: 73.4375%, Training Loss: 0.3792%\n",
      "Epoch [59/300], Step [5/23], Training Accuracy: 71.5625%, Training Loss: 0.3823%\n",
      "Epoch [59/300], Step [6/23], Training Accuracy: 72.1354%, Training Loss: 0.3791%\n",
      "Epoch [59/300], Step [7/23], Training Accuracy: 73.2143%, Training Loss: 0.3788%\n",
      "Epoch [59/300], Step [8/23], Training Accuracy: 73.8281%, Training Loss: 0.3760%\n",
      "Epoch [59/300], Step [9/23], Training Accuracy: 72.5694%, Training Loss: 0.3832%\n",
      "Epoch [59/300], Step [10/23], Training Accuracy: 72.3438%, Training Loss: 0.3807%\n",
      "Epoch [59/300], Step [11/23], Training Accuracy: 72.5852%, Training Loss: 0.3794%\n",
      "Epoch [59/300], Step [12/23], Training Accuracy: 72.6562%, Training Loss: 0.3790%\n",
      "Epoch [59/300], Step [13/23], Training Accuracy: 72.5962%, Training Loss: 0.3804%\n",
      "Epoch [59/300], Step [14/23], Training Accuracy: 72.5446%, Training Loss: 0.3796%\n",
      "Epoch [59/300], Step [15/23], Training Accuracy: 71.9792%, Training Loss: 0.3843%\n",
      "Epoch [59/300], Step [16/23], Training Accuracy: 71.8750%, Training Loss: 0.3829%\n",
      "Epoch [59/300], Step [17/23], Training Accuracy: 71.6912%, Training Loss: 0.3846%\n",
      "Epoch [59/300], Step [18/23], Training Accuracy: 71.6146%, Training Loss: 0.3850%\n",
      "Epoch [59/300], Step [19/23], Training Accuracy: 71.9572%, Training Loss: 0.3840%\n",
      "Epoch [59/300], Step [20/23], Training Accuracy: 72.3438%, Training Loss: 0.3835%\n",
      "Epoch [59/300], Step [21/23], Training Accuracy: 72.3214%, Training Loss: 0.3832%\n",
      "Epoch [59/300], Step [22/23], Training Accuracy: 72.5142%, Training Loss: 0.3831%\n",
      "Epoch [59/300], Step [23/23], Training Accuracy: 72.6894%, Training Loss: 0.3797%\n",
      "Epoch [60/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3759%\n",
      "Epoch [60/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.4076%\n",
      "Epoch [60/300], Step [3/23], Training Accuracy: 70.8333%, Training Loss: 0.4181%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/300], Step [4/23], Training Accuracy: 72.6562%, Training Loss: 0.3990%\n",
      "Epoch [60/300], Step [5/23], Training Accuracy: 71.2500%, Training Loss: 0.4001%\n",
      "Epoch [60/300], Step [6/23], Training Accuracy: 72.1354%, Training Loss: 0.3938%\n",
      "Epoch [60/300], Step [7/23], Training Accuracy: 73.2143%, Training Loss: 0.3935%\n",
      "Epoch [60/300], Step [8/23], Training Accuracy: 73.2422%, Training Loss: 0.3942%\n",
      "Epoch [60/300], Step [9/23], Training Accuracy: 72.7431%, Training Loss: 0.3966%\n",
      "Epoch [60/300], Step [10/23], Training Accuracy: 72.5000%, Training Loss: 0.3919%\n",
      "Epoch [60/300], Step [11/23], Training Accuracy: 72.4432%, Training Loss: 0.3942%\n",
      "Epoch [60/300], Step [12/23], Training Accuracy: 72.6562%, Training Loss: 0.3967%\n",
      "Epoch [60/300], Step [13/23], Training Accuracy: 72.1154%, Training Loss: 0.3982%\n",
      "Epoch [60/300], Step [14/23], Training Accuracy: 72.3214%, Training Loss: 0.3978%\n",
      "Epoch [60/300], Step [15/23], Training Accuracy: 72.2917%, Training Loss: 0.4016%\n",
      "Epoch [60/300], Step [16/23], Training Accuracy: 72.2656%, Training Loss: 0.3997%\n",
      "Epoch [60/300], Step [17/23], Training Accuracy: 72.0588%, Training Loss: 0.3998%\n",
      "Epoch [60/300], Step [18/23], Training Accuracy: 72.1354%, Training Loss: 0.3988%\n",
      "Epoch [60/300], Step [19/23], Training Accuracy: 72.3684%, Training Loss: 0.3979%\n",
      "Epoch [60/300], Step [20/23], Training Accuracy: 72.5781%, Training Loss: 0.3961%\n",
      "Epoch [60/300], Step [21/23], Training Accuracy: 72.7679%, Training Loss: 0.3948%\n",
      "Epoch [60/300], Step [22/23], Training Accuracy: 73.1534%, Training Loss: 0.3935%\n",
      "Epoch [60/300], Step [23/23], Training Accuracy: 73.2453%, Training Loss: 0.3911%\n",
      "Epoch [61/300], Step [1/23], Training Accuracy: 81.2500%, Training Loss: 0.3282%\n",
      "Epoch [61/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.3716%\n",
      "Epoch [61/300], Step [3/23], Training Accuracy: 71.3542%, Training Loss: 0.3876%\n",
      "Epoch [61/300], Step [4/23], Training Accuracy: 73.4375%, Training Loss: 0.3780%\n",
      "Epoch [61/300], Step [5/23], Training Accuracy: 71.2500%, Training Loss: 0.3797%\n",
      "Epoch [61/300], Step [6/23], Training Accuracy: 71.3542%, Training Loss: 0.3776%\n",
      "Epoch [61/300], Step [7/23], Training Accuracy: 71.8750%, Training Loss: 0.3824%\n",
      "Epoch [61/300], Step [8/23], Training Accuracy: 73.0469%, Training Loss: 0.3799%\n",
      "Epoch [61/300], Step [9/23], Training Accuracy: 72.2222%, Training Loss: 0.3850%\n",
      "Epoch [61/300], Step [10/23], Training Accuracy: 72.6562%, Training Loss: 0.3834%\n",
      "Epoch [61/300], Step [11/23], Training Accuracy: 73.7216%, Training Loss: 0.3789%\n",
      "Epoch [61/300], Step [12/23], Training Accuracy: 73.1771%, Training Loss: 0.3842%\n",
      "Epoch [61/300], Step [13/23], Training Accuracy: 72.2356%, Training Loss: 0.3856%\n",
      "Epoch [61/300], Step [14/23], Training Accuracy: 72.3214%, Training Loss: 0.3866%\n",
      "Epoch [61/300], Step [15/23], Training Accuracy: 71.9792%, Training Loss: 0.3913%\n",
      "Epoch [61/300], Step [16/23], Training Accuracy: 72.4609%, Training Loss: 0.3901%\n",
      "Epoch [61/300], Step [17/23], Training Accuracy: 72.8860%, Training Loss: 0.3898%\n",
      "Epoch [61/300], Step [18/23], Training Accuracy: 72.7431%, Training Loss: 0.3896%\n",
      "Epoch [61/300], Step [19/23], Training Accuracy: 73.1908%, Training Loss: 0.3884%\n",
      "Epoch [61/300], Step [20/23], Training Accuracy: 73.5938%, Training Loss: 0.3859%\n",
      "Epoch [61/300], Step [21/23], Training Accuracy: 73.5119%, Training Loss: 0.3857%\n",
      "Epoch [61/300], Step [22/23], Training Accuracy: 73.6506%, Training Loss: 0.3850%\n",
      "Epoch [61/300], Step [23/23], Training Accuracy: 73.7318%, Training Loss: 0.3823%\n",
      "Epoch [62/300], Step [1/23], Training Accuracy: 71.8750%, Training Loss: 0.3571%\n",
      "Epoch [62/300], Step [2/23], Training Accuracy: 71.0938%, Training Loss: 0.3901%\n",
      "Epoch [62/300], Step [3/23], Training Accuracy: 68.7500%, Training Loss: 0.4042%\n",
      "Epoch [62/300], Step [4/23], Training Accuracy: 70.7031%, Training Loss: 0.3807%\n",
      "Epoch [62/300], Step [5/23], Training Accuracy: 69.3750%, Training Loss: 0.3851%\n",
      "Epoch [62/300], Step [6/23], Training Accuracy: 70.0521%, Training Loss: 0.3841%\n",
      "Epoch [62/300], Step [7/23], Training Accuracy: 69.6429%, Training Loss: 0.3894%\n",
      "Epoch [62/300], Step [8/23], Training Accuracy: 70.3125%, Training Loss: 0.3899%\n",
      "Epoch [62/300], Step [9/23], Training Accuracy: 69.9653%, Training Loss: 0.3916%\n",
      "Epoch [62/300], Step [10/23], Training Accuracy: 70.1562%, Training Loss: 0.3892%\n",
      "Epoch [62/300], Step [11/23], Training Accuracy: 70.7386%, Training Loss: 0.3858%\n",
      "Epoch [62/300], Step [12/23], Training Accuracy: 70.8333%, Training Loss: 0.3886%\n",
      "Epoch [62/300], Step [13/23], Training Accuracy: 70.4327%, Training Loss: 0.3920%\n",
      "Epoch [62/300], Step [14/23], Training Accuracy: 70.7589%, Training Loss: 0.3908%\n",
      "Epoch [62/300], Step [15/23], Training Accuracy: 70.3125%, Training Loss: 0.3949%\n",
      "Epoch [62/300], Step [16/23], Training Accuracy: 70.2148%, Training Loss: 0.3940%\n",
      "Epoch [62/300], Step [17/23], Training Accuracy: 70.8640%, Training Loss: 0.3904%\n",
      "Epoch [62/300], Step [18/23], Training Accuracy: 71.0938%, Training Loss: 0.3899%\n",
      "Epoch [62/300], Step [19/23], Training Accuracy: 71.1349%, Training Loss: 0.3901%\n",
      "Epoch [62/300], Step [20/23], Training Accuracy: 71.7969%, Training Loss: 0.3872%\n",
      "Epoch [62/300], Step [21/23], Training Accuracy: 71.9494%, Training Loss: 0.3869%\n",
      "Epoch [62/300], Step [22/23], Training Accuracy: 72.1591%, Training Loss: 0.3853%\n",
      "Epoch [62/300], Step [23/23], Training Accuracy: 72.2029%, Training Loss: 0.3835%\n",
      "Epoch [63/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3488%\n",
      "Epoch [63/300], Step [2/23], Training Accuracy: 77.3438%, Training Loss: 0.3772%\n",
      "Epoch [63/300], Step [3/23], Training Accuracy: 72.3958%, Training Loss: 0.3875%\n",
      "Epoch [63/300], Step [4/23], Training Accuracy: 72.2656%, Training Loss: 0.3785%\n",
      "Epoch [63/300], Step [5/23], Training Accuracy: 72.1875%, Training Loss: 0.3813%\n",
      "Epoch [63/300], Step [6/23], Training Accuracy: 73.4375%, Training Loss: 0.3816%\n",
      "Epoch [63/300], Step [7/23], Training Accuracy: 73.4375%, Training Loss: 0.3847%\n",
      "Epoch [63/300], Step [8/23], Training Accuracy: 73.8281%, Training Loss: 0.3842%\n",
      "Epoch [63/300], Step [9/23], Training Accuracy: 72.5694%, Training Loss: 0.3886%\n",
      "Epoch [63/300], Step [10/23], Training Accuracy: 72.5000%, Training Loss: 0.3859%\n",
      "Epoch [63/300], Step [11/23], Training Accuracy: 73.0114%, Training Loss: 0.3829%\n",
      "Epoch [63/300], Step [12/23], Training Accuracy: 72.9167%, Training Loss: 0.3854%\n",
      "Epoch [63/300], Step [13/23], Training Accuracy: 72.4760%, Training Loss: 0.3855%\n",
      "Epoch [63/300], Step [14/23], Training Accuracy: 72.2098%, Training Loss: 0.3869%\n",
      "Epoch [63/300], Step [15/23], Training Accuracy: 72.1875%, Training Loss: 0.3899%\n",
      "Epoch [63/300], Step [16/23], Training Accuracy: 71.8750%, Training Loss: 0.3905%\n",
      "Epoch [63/300], Step [17/23], Training Accuracy: 71.6912%, Training Loss: 0.3898%\n",
      "Epoch [63/300], Step [18/23], Training Accuracy: 71.9618%, Training Loss: 0.3884%\n",
      "Epoch [63/300], Step [19/23], Training Accuracy: 72.0395%, Training Loss: 0.3883%\n",
      "Epoch [63/300], Step [20/23], Training Accuracy: 71.9531%, Training Loss: 0.3866%\n",
      "Epoch [63/300], Step [21/23], Training Accuracy: 72.3958%, Training Loss: 0.3852%\n",
      "Epoch [63/300], Step [22/23], Training Accuracy: 72.5852%, Training Loss: 0.3858%\n",
      "Epoch [63/300], Step [23/23], Training Accuracy: 72.5504%, Training Loss: 0.3833%\n",
      "Epoch [64/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3590%\n",
      "Epoch [64/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.3924%\n",
      "Epoch [64/300], Step [3/23], Training Accuracy: 71.3542%, Training Loss: 0.4003%\n",
      "Epoch [64/300], Step [4/23], Training Accuracy: 71.4844%, Training Loss: 0.3784%\n",
      "Epoch [64/300], Step [5/23], Training Accuracy: 69.3750%, Training Loss: 0.3819%\n",
      "Epoch [64/300], Step [6/23], Training Accuracy: 70.8333%, Training Loss: 0.3819%\n",
      "Epoch [64/300], Step [7/23], Training Accuracy: 71.4286%, Training Loss: 0.3886%\n",
      "Epoch [64/300], Step [8/23], Training Accuracy: 72.0703%, Training Loss: 0.3879%\n",
      "Epoch [64/300], Step [9/23], Training Accuracy: 71.3542%, Training Loss: 0.3933%\n",
      "Epoch [64/300], Step [10/23], Training Accuracy: 71.5625%, Training Loss: 0.3906%\n",
      "Epoch [64/300], Step [11/23], Training Accuracy: 72.4432%, Training Loss: 0.3891%\n",
      "Epoch [64/300], Step [12/23], Training Accuracy: 71.7448%, Training Loss: 0.3939%\n",
      "Epoch [64/300], Step [13/23], Training Accuracy: 71.0337%, Training Loss: 0.3965%\n",
      "Epoch [64/300], Step [14/23], Training Accuracy: 71.0938%, Training Loss: 0.3949%\n",
      "Epoch [64/300], Step [15/23], Training Accuracy: 71.0417%, Training Loss: 0.3956%\n",
      "Epoch [64/300], Step [16/23], Training Accuracy: 70.8984%, Training Loss: 0.3953%\n",
      "Epoch [64/300], Step [17/23], Training Accuracy: 71.2316%, Training Loss: 0.3937%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/300], Step [18/23], Training Accuracy: 71.4410%, Training Loss: 0.3926%\n",
      "Epoch [64/300], Step [19/23], Training Accuracy: 71.7105%, Training Loss: 0.3909%\n",
      "Epoch [64/300], Step [20/23], Training Accuracy: 71.7188%, Training Loss: 0.3901%\n",
      "Epoch [64/300], Step [21/23], Training Accuracy: 71.9494%, Training Loss: 0.3883%\n",
      "Epoch [64/300], Step [22/23], Training Accuracy: 72.0170%, Training Loss: 0.3853%\n",
      "Epoch [64/300], Step [23/23], Training Accuracy: 72.1334%, Training Loss: 0.3836%\n",
      "Epoch [65/300], Step [1/23], Training Accuracy: 73.4375%, Training Loss: 0.3507%\n",
      "Epoch [65/300], Step [2/23], Training Accuracy: 69.5312%, Training Loss: 0.3842%\n",
      "Epoch [65/300], Step [3/23], Training Accuracy: 68.2292%, Training Loss: 0.3905%\n",
      "Epoch [65/300], Step [4/23], Training Accuracy: 69.9219%, Training Loss: 0.3820%\n",
      "Epoch [65/300], Step [5/23], Training Accuracy: 69.6875%, Training Loss: 0.3808%\n",
      "Epoch [65/300], Step [6/23], Training Accuracy: 71.3542%, Training Loss: 0.3789%\n",
      "Epoch [65/300], Step [7/23], Training Accuracy: 71.4286%, Training Loss: 0.3841%\n",
      "Epoch [65/300], Step [8/23], Training Accuracy: 72.2656%, Training Loss: 0.3791%\n",
      "Epoch [65/300], Step [9/23], Training Accuracy: 71.7014%, Training Loss: 0.3845%\n",
      "Epoch [65/300], Step [10/23], Training Accuracy: 71.5625%, Training Loss: 0.3819%\n",
      "Epoch [65/300], Step [11/23], Training Accuracy: 72.3011%, Training Loss: 0.3803%\n",
      "Epoch [65/300], Step [12/23], Training Accuracy: 72.1354%, Training Loss: 0.3825%\n",
      "Epoch [65/300], Step [13/23], Training Accuracy: 72.3558%, Training Loss: 0.3832%\n",
      "Epoch [65/300], Step [14/23], Training Accuracy: 72.2098%, Training Loss: 0.3841%\n",
      "Epoch [65/300], Step [15/23], Training Accuracy: 72.1875%, Training Loss: 0.3870%\n",
      "Epoch [65/300], Step [16/23], Training Accuracy: 71.7773%, Training Loss: 0.3876%\n",
      "Epoch [65/300], Step [17/23], Training Accuracy: 72.0588%, Training Loss: 0.3863%\n",
      "Epoch [65/300], Step [18/23], Training Accuracy: 72.2222%, Training Loss: 0.3863%\n",
      "Epoch [65/300], Step [19/23], Training Accuracy: 72.3684%, Training Loss: 0.3857%\n",
      "Epoch [65/300], Step [20/23], Training Accuracy: 72.4219%, Training Loss: 0.3849%\n",
      "Epoch [65/300], Step [21/23], Training Accuracy: 72.4702%, Training Loss: 0.3842%\n",
      "Epoch [65/300], Step [22/23], Training Accuracy: 72.3011%, Training Loss: 0.3829%\n",
      "Epoch [65/300], Step [23/23], Training Accuracy: 72.4114%, Training Loss: 0.3793%\n",
      "Epoch [66/300], Step [1/23], Training Accuracy: 84.3750%, Training Loss: 0.3364%\n",
      "Epoch [66/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3795%\n",
      "Epoch [66/300], Step [3/23], Training Accuracy: 72.9167%, Training Loss: 0.3996%\n",
      "Epoch [66/300], Step [4/23], Training Accuracy: 74.2188%, Training Loss: 0.3783%\n",
      "Epoch [66/300], Step [5/23], Training Accuracy: 73.4375%, Training Loss: 0.3738%\n",
      "Epoch [66/300], Step [6/23], Training Accuracy: 74.2188%, Training Loss: 0.3748%\n",
      "Epoch [66/300], Step [7/23], Training Accuracy: 73.6607%, Training Loss: 0.3824%\n",
      "Epoch [66/300], Step [8/23], Training Accuracy: 73.8281%, Training Loss: 0.3832%\n",
      "Epoch [66/300], Step [9/23], Training Accuracy: 72.5694%, Training Loss: 0.3879%\n",
      "Epoch [66/300], Step [10/23], Training Accuracy: 72.3438%, Training Loss: 0.3863%\n",
      "Epoch [66/300], Step [11/23], Training Accuracy: 72.1591%, Training Loss: 0.3842%\n",
      "Epoch [66/300], Step [12/23], Training Accuracy: 72.5260%, Training Loss: 0.3863%\n",
      "Epoch [66/300], Step [13/23], Training Accuracy: 72.5962%, Training Loss: 0.3883%\n",
      "Epoch [66/300], Step [14/23], Training Accuracy: 72.6562%, Training Loss: 0.3873%\n",
      "Epoch [66/300], Step [15/23], Training Accuracy: 72.6042%, Training Loss: 0.3890%\n",
      "Epoch [66/300], Step [16/23], Training Accuracy: 72.3633%, Training Loss: 0.3892%\n",
      "Epoch [66/300], Step [17/23], Training Accuracy: 72.1507%, Training Loss: 0.3891%\n",
      "Epoch [66/300], Step [18/23], Training Accuracy: 72.3958%, Training Loss: 0.3883%\n",
      "Epoch [66/300], Step [19/23], Training Accuracy: 72.6151%, Training Loss: 0.3884%\n",
      "Epoch [66/300], Step [20/23], Training Accuracy: 72.8125%, Training Loss: 0.3868%\n",
      "Epoch [66/300], Step [21/23], Training Accuracy: 72.9167%, Training Loss: 0.3867%\n",
      "Epoch [66/300], Step [22/23], Training Accuracy: 73.0824%, Training Loss: 0.3852%\n",
      "Epoch [66/300], Step [23/23], Training Accuracy: 73.1063%, Training Loss: 0.3827%\n",
      "Epoch [67/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3774%\n",
      "Epoch [67/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.4122%\n",
      "Epoch [67/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.4086%\n",
      "Epoch [67/300], Step [4/23], Training Accuracy: 74.6094%, Training Loss: 0.3825%\n",
      "Epoch [67/300], Step [5/23], Training Accuracy: 74.6875%, Training Loss: 0.3822%\n",
      "Epoch [67/300], Step [6/23], Training Accuracy: 75.0000%, Training Loss: 0.3823%\n",
      "Epoch [67/300], Step [7/23], Training Accuracy: 75.0000%, Training Loss: 0.3859%\n",
      "Epoch [67/300], Step [8/23], Training Accuracy: 75.0000%, Training Loss: 0.3823%\n",
      "Epoch [67/300], Step [9/23], Training Accuracy: 73.2639%, Training Loss: 0.3888%\n",
      "Epoch [67/300], Step [10/23], Training Accuracy: 73.4375%, Training Loss: 0.3853%\n",
      "Epoch [67/300], Step [11/23], Training Accuracy: 73.4375%, Training Loss: 0.3858%\n",
      "Epoch [67/300], Step [12/23], Training Accuracy: 73.3073%, Training Loss: 0.3888%\n",
      "Epoch [67/300], Step [13/23], Training Accuracy: 73.4375%, Training Loss: 0.3893%\n",
      "Epoch [67/300], Step [14/23], Training Accuracy: 73.7723%, Training Loss: 0.3881%\n",
      "Epoch [67/300], Step [15/23], Training Accuracy: 73.3333%, Training Loss: 0.3926%\n",
      "Epoch [67/300], Step [16/23], Training Accuracy: 73.0469%, Training Loss: 0.3929%\n",
      "Epoch [67/300], Step [17/23], Training Accuracy: 73.2537%, Training Loss: 0.3924%\n",
      "Epoch [67/300], Step [18/23], Training Accuracy: 73.4375%, Training Loss: 0.3923%\n",
      "Epoch [67/300], Step [19/23], Training Accuracy: 73.6020%, Training Loss: 0.3910%\n",
      "Epoch [67/300], Step [20/23], Training Accuracy: 73.6719%, Training Loss: 0.3900%\n",
      "Epoch [67/300], Step [21/23], Training Accuracy: 73.8839%, Training Loss: 0.3885%\n",
      "Epoch [67/300], Step [22/23], Training Accuracy: 74.0767%, Training Loss: 0.3866%\n",
      "Epoch [67/300], Step [23/23], Training Accuracy: 74.0097%, Training Loss: 0.3839%\n",
      "Epoch [68/300], Step [1/23], Training Accuracy: 73.4375%, Training Loss: 0.3724%\n",
      "Epoch [68/300], Step [2/23], Training Accuracy: 71.8750%, Training Loss: 0.3933%\n",
      "Epoch [68/300], Step [3/23], Training Accuracy: 70.8333%, Training Loss: 0.3961%\n",
      "Epoch [68/300], Step [4/23], Training Accuracy: 72.6562%, Training Loss: 0.3849%\n",
      "Epoch [68/300], Step [5/23], Training Accuracy: 72.1875%, Training Loss: 0.3807%\n",
      "Epoch [68/300], Step [6/23], Training Accuracy: 71.3542%, Training Loss: 0.3844%\n",
      "Epoch [68/300], Step [7/23], Training Accuracy: 71.6518%, Training Loss: 0.3888%\n",
      "Epoch [68/300], Step [8/23], Training Accuracy: 72.6562%, Training Loss: 0.3897%\n",
      "Epoch [68/300], Step [9/23], Training Accuracy: 72.0486%, Training Loss: 0.3923%\n",
      "Epoch [68/300], Step [10/23], Training Accuracy: 72.5000%, Training Loss: 0.3884%\n",
      "Epoch [68/300], Step [11/23], Training Accuracy: 73.0114%, Training Loss: 0.3859%\n",
      "Epoch [68/300], Step [12/23], Training Accuracy: 73.0469%, Training Loss: 0.3885%\n",
      "Epoch [68/300], Step [13/23], Training Accuracy: 72.9567%, Training Loss: 0.3895%\n",
      "Epoch [68/300], Step [14/23], Training Accuracy: 72.9911%, Training Loss: 0.3891%\n",
      "Epoch [68/300], Step [15/23], Training Accuracy: 72.8125%, Training Loss: 0.3916%\n",
      "Epoch [68/300], Step [16/23], Training Accuracy: 72.5586%, Training Loss: 0.3907%\n",
      "Epoch [68/300], Step [17/23], Training Accuracy: 72.9779%, Training Loss: 0.3873%\n",
      "Epoch [68/300], Step [18/23], Training Accuracy: 72.9167%, Training Loss: 0.3860%\n",
      "Epoch [68/300], Step [19/23], Training Accuracy: 73.0263%, Training Loss: 0.3860%\n",
      "Epoch [68/300], Step [20/23], Training Accuracy: 73.2031%, Training Loss: 0.3842%\n",
      "Epoch [68/300], Step [21/23], Training Accuracy: 73.5119%, Training Loss: 0.3829%\n",
      "Epoch [68/300], Step [22/23], Training Accuracy: 73.5085%, Training Loss: 0.3814%\n",
      "Epoch [68/300], Step [23/23], Training Accuracy: 73.5928%, Training Loss: 0.3786%\n",
      "Epoch [69/300], Step [1/23], Training Accuracy: 81.2500%, Training Loss: 0.3492%\n",
      "Epoch [69/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3872%\n",
      "Epoch [69/300], Step [3/23], Training Accuracy: 72.3958%, Training Loss: 0.3991%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/300], Step [4/23], Training Accuracy: 74.2188%, Training Loss: 0.3813%\n",
      "Epoch [69/300], Step [5/23], Training Accuracy: 73.7500%, Training Loss: 0.3818%\n",
      "Epoch [69/300], Step [6/23], Training Accuracy: 73.9583%, Training Loss: 0.3815%\n",
      "Epoch [69/300], Step [7/23], Training Accuracy: 74.1071%, Training Loss: 0.3902%\n",
      "Epoch [69/300], Step [8/23], Training Accuracy: 75.1953%, Training Loss: 0.3883%\n",
      "Epoch [69/300], Step [9/23], Training Accuracy: 74.3056%, Training Loss: 0.3935%\n",
      "Epoch [69/300], Step [10/23], Training Accuracy: 74.2188%, Training Loss: 0.3887%\n",
      "Epoch [69/300], Step [11/23], Training Accuracy: 74.5739%, Training Loss: 0.3878%\n",
      "Epoch [69/300], Step [12/23], Training Accuracy: 74.2188%, Training Loss: 0.3897%\n",
      "Epoch [69/300], Step [13/23], Training Accuracy: 73.6779%, Training Loss: 0.3896%\n",
      "Epoch [69/300], Step [14/23], Training Accuracy: 73.8839%, Training Loss: 0.3890%\n",
      "Epoch [69/300], Step [15/23], Training Accuracy: 73.5417%, Training Loss: 0.3936%\n",
      "Epoch [69/300], Step [16/23], Training Accuracy: 73.6328%, Training Loss: 0.3922%\n",
      "Epoch [69/300], Step [17/23], Training Accuracy: 73.7132%, Training Loss: 0.3906%\n",
      "Epoch [69/300], Step [18/23], Training Accuracy: 73.9583%, Training Loss: 0.3896%\n",
      "Epoch [69/300], Step [19/23], Training Accuracy: 74.0954%, Training Loss: 0.3881%\n",
      "Epoch [69/300], Step [20/23], Training Accuracy: 74.2188%, Training Loss: 0.3880%\n",
      "Epoch [69/300], Step [21/23], Training Accuracy: 74.5536%, Training Loss: 0.3867%\n",
      "Epoch [69/300], Step [22/23], Training Accuracy: 74.5028%, Training Loss: 0.3863%\n",
      "Epoch [69/300], Step [23/23], Training Accuracy: 74.7047%, Training Loss: 0.3826%\n",
      "Epoch [70/300], Step [1/23], Training Accuracy: 70.3125%, Training Loss: 0.3800%\n",
      "Epoch [70/300], Step [2/23], Training Accuracy: 71.0938%, Training Loss: 0.3976%\n",
      "Epoch [70/300], Step [3/23], Training Accuracy: 70.8333%, Training Loss: 0.4038%\n",
      "Epoch [70/300], Step [4/23], Training Accuracy: 73.0469%, Training Loss: 0.3870%\n",
      "Epoch [70/300], Step [5/23], Training Accuracy: 71.8750%, Training Loss: 0.3893%\n",
      "Epoch [70/300], Step [6/23], Training Accuracy: 72.9167%, Training Loss: 0.3903%\n",
      "Epoch [70/300], Step [7/23], Training Accuracy: 72.5446%, Training Loss: 0.3933%\n",
      "Epoch [70/300], Step [8/23], Training Accuracy: 73.2422%, Training Loss: 0.3916%\n",
      "Epoch [70/300], Step [9/23], Training Accuracy: 73.0903%, Training Loss: 0.3942%\n",
      "Epoch [70/300], Step [10/23], Training Accuracy: 72.8125%, Training Loss: 0.3935%\n",
      "Epoch [70/300], Step [11/23], Training Accuracy: 73.2955%, Training Loss: 0.3901%\n",
      "Epoch [70/300], Step [12/23], Training Accuracy: 73.4375%, Training Loss: 0.3914%\n",
      "Epoch [70/300], Step [13/23], Training Accuracy: 73.0769%, Training Loss: 0.3911%\n",
      "Epoch [70/300], Step [14/23], Training Accuracy: 73.1027%, Training Loss: 0.3922%\n",
      "Epoch [70/300], Step [15/23], Training Accuracy: 72.9167%, Training Loss: 0.3969%\n",
      "Epoch [70/300], Step [16/23], Training Accuracy: 72.7539%, Training Loss: 0.3962%\n",
      "Epoch [70/300], Step [17/23], Training Accuracy: 72.6103%, Training Loss: 0.3941%\n",
      "Epoch [70/300], Step [18/23], Training Accuracy: 72.7431%, Training Loss: 0.3930%\n",
      "Epoch [70/300], Step [19/23], Training Accuracy: 73.0263%, Training Loss: 0.3918%\n",
      "Epoch [70/300], Step [20/23], Training Accuracy: 73.0469%, Training Loss: 0.3913%\n",
      "Epoch [70/300], Step [21/23], Training Accuracy: 73.3631%, Training Loss: 0.3896%\n",
      "Epoch [70/300], Step [22/23], Training Accuracy: 73.3665%, Training Loss: 0.3877%\n",
      "Epoch [70/300], Step [23/23], Training Accuracy: 73.2453%, Training Loss: 0.3856%\n",
      "Epoch [71/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3584%\n",
      "Epoch [71/300], Step [2/23], Training Accuracy: 71.0938%, Training Loss: 0.3866%\n",
      "Epoch [71/300], Step [3/23], Training Accuracy: 70.3125%, Training Loss: 0.4028%\n",
      "Epoch [71/300], Step [4/23], Training Accuracy: 73.0469%, Training Loss: 0.3778%\n",
      "Epoch [71/300], Step [5/23], Training Accuracy: 72.8125%, Training Loss: 0.3736%\n",
      "Epoch [71/300], Step [6/23], Training Accuracy: 72.9167%, Training Loss: 0.3728%\n",
      "Epoch [71/300], Step [7/23], Training Accuracy: 72.0982%, Training Loss: 0.3804%\n",
      "Epoch [71/300], Step [8/23], Training Accuracy: 72.4609%, Training Loss: 0.3811%\n",
      "Epoch [71/300], Step [9/23], Training Accuracy: 71.7014%, Training Loss: 0.3868%\n",
      "Epoch [71/300], Step [10/23], Training Accuracy: 71.7188%, Training Loss: 0.3843%\n",
      "Epoch [71/300], Step [11/23], Training Accuracy: 71.8750%, Training Loss: 0.3839%\n",
      "Epoch [71/300], Step [12/23], Training Accuracy: 72.0052%, Training Loss: 0.3869%\n",
      "Epoch [71/300], Step [13/23], Training Accuracy: 71.3942%, Training Loss: 0.3884%\n",
      "Epoch [71/300], Step [14/23], Training Accuracy: 71.3170%, Training Loss: 0.3867%\n",
      "Epoch [71/300], Step [15/23], Training Accuracy: 71.1458%, Training Loss: 0.3900%\n",
      "Epoch [71/300], Step [16/23], Training Accuracy: 71.5820%, Training Loss: 0.3890%\n",
      "Epoch [71/300], Step [17/23], Training Accuracy: 71.8750%, Training Loss: 0.3891%\n",
      "Epoch [71/300], Step [18/23], Training Accuracy: 71.9618%, Training Loss: 0.3887%\n",
      "Epoch [71/300], Step [19/23], Training Accuracy: 72.0395%, Training Loss: 0.3877%\n",
      "Epoch [71/300], Step [20/23], Training Accuracy: 72.3438%, Training Loss: 0.3847%\n",
      "Epoch [71/300], Step [21/23], Training Accuracy: 72.6190%, Training Loss: 0.3837%\n",
      "Epoch [71/300], Step [22/23], Training Accuracy: 72.7273%, Training Loss: 0.3824%\n",
      "Epoch [71/300], Step [23/23], Training Accuracy: 72.8284%, Training Loss: 0.3803%\n",
      "Epoch [72/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3568%\n",
      "Epoch [72/300], Step [2/23], Training Accuracy: 71.8750%, Training Loss: 0.3859%\n",
      "Epoch [72/300], Step [3/23], Training Accuracy: 70.3125%, Training Loss: 0.3915%\n",
      "Epoch [72/300], Step [4/23], Training Accuracy: 71.8750%, Training Loss: 0.3821%\n",
      "Epoch [72/300], Step [5/23], Training Accuracy: 70.3125%, Training Loss: 0.3820%\n",
      "Epoch [72/300], Step [6/23], Training Accuracy: 71.0938%, Training Loss: 0.3810%\n",
      "Epoch [72/300], Step [7/23], Training Accuracy: 71.8750%, Training Loss: 0.3844%\n",
      "Epoch [72/300], Step [8/23], Training Accuracy: 72.2656%, Training Loss: 0.3831%\n",
      "Epoch [72/300], Step [9/23], Training Accuracy: 72.3958%, Training Loss: 0.3879%\n",
      "Epoch [72/300], Step [10/23], Training Accuracy: 72.5000%, Training Loss: 0.3851%\n",
      "Epoch [72/300], Step [11/23], Training Accuracy: 72.8693%, Training Loss: 0.3837%\n",
      "Epoch [72/300], Step [12/23], Training Accuracy: 72.7865%, Training Loss: 0.3842%\n",
      "Epoch [72/300], Step [13/23], Training Accuracy: 72.7163%, Training Loss: 0.3854%\n",
      "Epoch [72/300], Step [14/23], Training Accuracy: 72.5446%, Training Loss: 0.3838%\n",
      "Epoch [72/300], Step [15/23], Training Accuracy: 72.2917%, Training Loss: 0.3876%\n",
      "Epoch [72/300], Step [16/23], Training Accuracy: 72.4609%, Training Loss: 0.3878%\n",
      "Epoch [72/300], Step [17/23], Training Accuracy: 72.1507%, Training Loss: 0.3878%\n",
      "Epoch [72/300], Step [18/23], Training Accuracy: 72.2222%, Training Loss: 0.3878%\n",
      "Epoch [72/300], Step [19/23], Training Accuracy: 72.5329%, Training Loss: 0.3864%\n",
      "Epoch [72/300], Step [20/23], Training Accuracy: 72.8125%, Training Loss: 0.3849%\n",
      "Epoch [72/300], Step [21/23], Training Accuracy: 72.6935%, Training Loss: 0.3856%\n",
      "Epoch [72/300], Step [22/23], Training Accuracy: 73.0824%, Training Loss: 0.3840%\n",
      "Epoch [72/300], Step [23/23], Training Accuracy: 73.1758%, Training Loss: 0.3805%\n",
      "Epoch [73/300], Step [1/23], Training Accuracy: 82.8125%, Training Loss: 0.3288%\n",
      "Epoch [73/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3799%\n",
      "Epoch [73/300], Step [3/23], Training Accuracy: 74.4792%, Training Loss: 0.3887%\n",
      "Epoch [73/300], Step [4/23], Training Accuracy: 74.6094%, Training Loss: 0.3766%\n",
      "Epoch [73/300], Step [5/23], Training Accuracy: 73.4375%, Training Loss: 0.3719%\n",
      "Epoch [73/300], Step [6/23], Training Accuracy: 73.6979%, Training Loss: 0.3707%\n",
      "Epoch [73/300], Step [7/23], Training Accuracy: 74.1071%, Training Loss: 0.3732%\n",
      "Epoch [73/300], Step [8/23], Training Accuracy: 74.6094%, Training Loss: 0.3725%\n",
      "Epoch [73/300], Step [9/23], Training Accuracy: 73.4375%, Training Loss: 0.3808%\n",
      "Epoch [73/300], Step [10/23], Training Accuracy: 73.7500%, Training Loss: 0.3793%\n",
      "Epoch [73/300], Step [11/23], Training Accuracy: 74.1477%, Training Loss: 0.3786%\n",
      "Epoch [73/300], Step [12/23], Training Accuracy: 73.5677%, Training Loss: 0.3807%\n",
      "Epoch [73/300], Step [13/23], Training Accuracy: 72.8365%, Training Loss: 0.3845%\n",
      "Epoch [73/300], Step [14/23], Training Accuracy: 73.2143%, Training Loss: 0.3812%\n",
      "Epoch [73/300], Step [15/23], Training Accuracy: 72.9167%, Training Loss: 0.3845%\n",
      "Epoch [73/300], Step [16/23], Training Accuracy: 72.8516%, Training Loss: 0.3845%\n",
      "Epoch [73/300], Step [17/23], Training Accuracy: 72.8860%, Training Loss: 0.3833%\n",
      "Epoch [73/300], Step [18/23], Training Accuracy: 73.0903%, Training Loss: 0.3844%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/300], Step [19/23], Training Accuracy: 73.3553%, Training Loss: 0.3831%\n",
      "Epoch [73/300], Step [20/23], Training Accuracy: 73.8281%, Training Loss: 0.3811%\n",
      "Epoch [73/300], Step [21/23], Training Accuracy: 73.6607%, Training Loss: 0.3805%\n",
      "Epoch [73/300], Step [22/23], Training Accuracy: 73.7926%, Training Loss: 0.3805%\n",
      "Epoch [73/300], Step [23/23], Training Accuracy: 73.9402%, Training Loss: 0.3773%\n",
      "Epoch [74/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3646%\n",
      "Epoch [74/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.3939%\n",
      "Epoch [74/300], Step [3/23], Training Accuracy: 74.4792%, Training Loss: 0.3877%\n",
      "Epoch [74/300], Step [4/23], Training Accuracy: 76.5625%, Training Loss: 0.3667%\n",
      "Epoch [74/300], Step [5/23], Training Accuracy: 75.6250%, Training Loss: 0.3684%\n",
      "Epoch [74/300], Step [6/23], Training Accuracy: 75.7812%, Training Loss: 0.3672%\n",
      "Epoch [74/300], Step [7/23], Training Accuracy: 75.4464%, Training Loss: 0.3702%\n",
      "Epoch [74/300], Step [8/23], Training Accuracy: 76.1719%, Training Loss: 0.3695%\n",
      "Epoch [74/300], Step [9/23], Training Accuracy: 75.0000%, Training Loss: 0.3745%\n",
      "Epoch [74/300], Step [10/23], Training Accuracy: 75.1562%, Training Loss: 0.3720%\n",
      "Epoch [74/300], Step [11/23], Training Accuracy: 75.5682%, Training Loss: 0.3706%\n",
      "Epoch [74/300], Step [12/23], Training Accuracy: 75.6510%, Training Loss: 0.3748%\n",
      "Epoch [74/300], Step [13/23], Training Accuracy: 74.8798%, Training Loss: 0.3761%\n",
      "Epoch [74/300], Step [14/23], Training Accuracy: 74.5536%, Training Loss: 0.3782%\n",
      "Epoch [74/300], Step [15/23], Training Accuracy: 73.8542%, Training Loss: 0.3821%\n",
      "Epoch [74/300], Step [16/23], Training Accuracy: 73.3398%, Training Loss: 0.3835%\n",
      "Epoch [74/300], Step [17/23], Training Accuracy: 73.3456%, Training Loss: 0.3825%\n",
      "Epoch [74/300], Step [18/23], Training Accuracy: 73.3507%, Training Loss: 0.3825%\n",
      "Epoch [74/300], Step [19/23], Training Accuracy: 73.4375%, Training Loss: 0.3829%\n",
      "Epoch [74/300], Step [20/23], Training Accuracy: 73.6719%, Training Loss: 0.3817%\n",
      "Epoch [74/300], Step [21/23], Training Accuracy: 73.8095%, Training Loss: 0.3811%\n",
      "Epoch [74/300], Step [22/23], Training Accuracy: 73.7216%, Training Loss: 0.3805%\n",
      "Epoch [74/300], Step [23/23], Training Accuracy: 73.8013%, Training Loss: 0.3781%\n",
      "Epoch [75/300], Step [1/23], Training Accuracy: 82.8125%, Training Loss: 0.3358%\n",
      "Epoch [75/300], Step [2/23], Training Accuracy: 77.3438%, Training Loss: 0.3752%\n",
      "Epoch [75/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.3898%\n",
      "Epoch [75/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.3771%\n",
      "Epoch [75/300], Step [5/23], Training Accuracy: 74.3750%, Training Loss: 0.3753%\n",
      "Epoch [75/300], Step [6/23], Training Accuracy: 75.7812%, Training Loss: 0.3765%\n",
      "Epoch [75/300], Step [7/23], Training Accuracy: 75.0000%, Training Loss: 0.3815%\n",
      "Epoch [75/300], Step [8/23], Training Accuracy: 75.1953%, Training Loss: 0.3790%\n",
      "Epoch [75/300], Step [9/23], Training Accuracy: 74.6528%, Training Loss: 0.3820%\n",
      "Epoch [75/300], Step [10/23], Training Accuracy: 75.3125%, Training Loss: 0.3787%\n",
      "Epoch [75/300], Step [11/23], Training Accuracy: 75.4261%, Training Loss: 0.3767%\n",
      "Epoch [75/300], Step [12/23], Training Accuracy: 75.2604%, Training Loss: 0.3784%\n",
      "Epoch [75/300], Step [13/23], Training Accuracy: 75.6010%, Training Loss: 0.3809%\n",
      "Epoch [75/300], Step [14/23], Training Accuracy: 74.8884%, Training Loss: 0.3837%\n",
      "Epoch [75/300], Step [15/23], Training Accuracy: 74.6875%, Training Loss: 0.3863%\n",
      "Epoch [75/300], Step [16/23], Training Accuracy: 74.7070%, Training Loss: 0.3848%\n",
      "Epoch [75/300], Step [17/23], Training Accuracy: 74.8162%, Training Loss: 0.3848%\n",
      "Epoch [75/300], Step [18/23], Training Accuracy: 74.9132%, Training Loss: 0.3847%\n",
      "Epoch [75/300], Step [19/23], Training Accuracy: 75.1645%, Training Loss: 0.3829%\n",
      "Epoch [75/300], Step [20/23], Training Accuracy: 75.0781%, Training Loss: 0.3817%\n",
      "Epoch [75/300], Step [21/23], Training Accuracy: 75.0000%, Training Loss: 0.3810%\n",
      "Epoch [75/300], Step [22/23], Training Accuracy: 74.6449%, Training Loss: 0.3811%\n",
      "Epoch [75/300], Step [23/23], Training Accuracy: 74.8436%, Training Loss: 0.3783%\n",
      "Epoch [76/300], Step [1/23], Training Accuracy: 82.8125%, Training Loss: 0.3533%\n",
      "Epoch [76/300], Step [2/23], Training Accuracy: 75.7812%, Training Loss: 0.3863%\n",
      "Epoch [76/300], Step [3/23], Training Accuracy: 73.4375%, Training Loss: 0.3888%\n",
      "Epoch [76/300], Step [4/23], Training Accuracy: 74.2188%, Training Loss: 0.3730%\n",
      "Epoch [76/300], Step [5/23], Training Accuracy: 73.4375%, Training Loss: 0.3786%\n",
      "Epoch [76/300], Step [6/23], Training Accuracy: 74.4792%, Training Loss: 0.3768%\n",
      "Epoch [76/300], Step [7/23], Training Accuracy: 74.5536%, Training Loss: 0.3820%\n",
      "Epoch [76/300], Step [8/23], Training Accuracy: 74.6094%, Training Loss: 0.3815%\n",
      "Epoch [76/300], Step [9/23], Training Accuracy: 74.3056%, Training Loss: 0.3835%\n",
      "Epoch [76/300], Step [10/23], Training Accuracy: 74.0625%, Training Loss: 0.3805%\n",
      "Epoch [76/300], Step [11/23], Training Accuracy: 74.0057%, Training Loss: 0.3803%\n",
      "Epoch [76/300], Step [12/23], Training Accuracy: 74.0885%, Training Loss: 0.3801%\n",
      "Epoch [76/300], Step [13/23], Training Accuracy: 73.0769%, Training Loss: 0.3842%\n",
      "Epoch [76/300], Step [14/23], Training Accuracy: 73.3259%, Training Loss: 0.3845%\n",
      "Epoch [76/300], Step [15/23], Training Accuracy: 72.7083%, Training Loss: 0.3889%\n",
      "Epoch [76/300], Step [16/23], Training Accuracy: 72.5586%, Training Loss: 0.3895%\n",
      "Epoch [76/300], Step [17/23], Training Accuracy: 72.7941%, Training Loss: 0.3885%\n",
      "Epoch [76/300], Step [18/23], Training Accuracy: 72.7431%, Training Loss: 0.3887%\n",
      "Epoch [76/300], Step [19/23], Training Accuracy: 72.6974%, Training Loss: 0.3890%\n",
      "Epoch [76/300], Step [20/23], Training Accuracy: 72.9688%, Training Loss: 0.3861%\n",
      "Epoch [76/300], Step [21/23], Training Accuracy: 73.2887%, Training Loss: 0.3856%\n",
      "Epoch [76/300], Step [22/23], Training Accuracy: 73.4375%, Training Loss: 0.3851%\n",
      "Epoch [76/300], Step [23/23], Training Accuracy: 73.6623%, Training Loss: 0.3815%\n",
      "Epoch [77/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3371%\n",
      "Epoch [77/300], Step [2/23], Training Accuracy: 75.7812%, Training Loss: 0.3836%\n",
      "Epoch [77/300], Step [3/23], Training Accuracy: 73.4375%, Training Loss: 0.3855%\n",
      "Epoch [77/300], Step [4/23], Training Accuracy: 74.2188%, Training Loss: 0.3707%\n",
      "Epoch [77/300], Step [5/23], Training Accuracy: 72.5000%, Training Loss: 0.3782%\n",
      "Epoch [77/300], Step [6/23], Training Accuracy: 72.9167%, Training Loss: 0.3793%\n",
      "Epoch [77/300], Step [7/23], Training Accuracy: 72.7679%, Training Loss: 0.3831%\n",
      "Epoch [77/300], Step [8/23], Training Accuracy: 72.8516%, Training Loss: 0.3852%\n",
      "Epoch [77/300], Step [9/23], Training Accuracy: 71.3542%, Training Loss: 0.3939%\n",
      "Epoch [77/300], Step [10/23], Training Accuracy: 71.2500%, Training Loss: 0.3902%\n",
      "Epoch [77/300], Step [11/23], Training Accuracy: 72.0170%, Training Loss: 0.3857%\n",
      "Epoch [77/300], Step [12/23], Training Accuracy: 71.8750%, Training Loss: 0.3860%\n",
      "Epoch [77/300], Step [13/23], Training Accuracy: 72.4760%, Training Loss: 0.3853%\n",
      "Epoch [77/300], Step [14/23], Training Accuracy: 72.8795%, Training Loss: 0.3827%\n",
      "Epoch [77/300], Step [15/23], Training Accuracy: 73.1250%, Training Loss: 0.3850%\n",
      "Epoch [77/300], Step [16/23], Training Accuracy: 73.0469%, Training Loss: 0.3858%\n",
      "Epoch [77/300], Step [17/23], Training Accuracy: 73.2537%, Training Loss: 0.3851%\n",
      "Epoch [77/300], Step [18/23], Training Accuracy: 73.5243%, Training Loss: 0.3849%\n",
      "Epoch [77/300], Step [19/23], Training Accuracy: 73.6020%, Training Loss: 0.3835%\n",
      "Epoch [77/300], Step [20/23], Training Accuracy: 73.7500%, Training Loss: 0.3820%\n",
      "Epoch [77/300], Step [21/23], Training Accuracy: 73.9583%, Training Loss: 0.3807%\n",
      "Epoch [77/300], Step [22/23], Training Accuracy: 74.0767%, Training Loss: 0.3800%\n",
      "Epoch [77/300], Step [23/23], Training Accuracy: 74.2182%, Training Loss: 0.3773%\n",
      "Epoch [78/300], Step [1/23], Training Accuracy: 73.4375%, Training Loss: 0.3568%\n",
      "Epoch [78/300], Step [2/23], Training Accuracy: 71.0938%, Training Loss: 0.3907%\n",
      "Epoch [78/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.3893%\n",
      "Epoch [78/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.3766%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/300], Step [5/23], Training Accuracy: 74.0625%, Training Loss: 0.3725%\n",
      "Epoch [78/300], Step [6/23], Training Accuracy: 73.9583%, Training Loss: 0.3733%\n",
      "Epoch [78/300], Step [7/23], Training Accuracy: 74.3304%, Training Loss: 0.3789%\n",
      "Epoch [78/300], Step [8/23], Training Accuracy: 75.0000%, Training Loss: 0.3776%\n",
      "Epoch [78/300], Step [9/23], Training Accuracy: 73.7847%, Training Loss: 0.3884%\n",
      "Epoch [78/300], Step [10/23], Training Accuracy: 73.2812%, Training Loss: 0.3872%\n",
      "Epoch [78/300], Step [11/23], Training Accuracy: 74.1477%, Training Loss: 0.3829%\n",
      "Epoch [78/300], Step [12/23], Training Accuracy: 73.6979%, Training Loss: 0.3847%\n",
      "Epoch [78/300], Step [13/23], Training Accuracy: 73.1971%, Training Loss: 0.3859%\n",
      "Epoch [78/300], Step [14/23], Training Accuracy: 73.5491%, Training Loss: 0.3841%\n",
      "Epoch [78/300], Step [15/23], Training Accuracy: 73.2292%, Training Loss: 0.3872%\n",
      "Epoch [78/300], Step [16/23], Training Accuracy: 72.8516%, Training Loss: 0.3878%\n",
      "Epoch [78/300], Step [17/23], Training Accuracy: 72.5184%, Training Loss: 0.3879%\n",
      "Epoch [78/300], Step [18/23], Training Accuracy: 72.7431%, Training Loss: 0.3882%\n",
      "Epoch [78/300], Step [19/23], Training Accuracy: 72.9441%, Training Loss: 0.3873%\n",
      "Epoch [78/300], Step [20/23], Training Accuracy: 73.0469%, Training Loss: 0.3855%\n",
      "Epoch [78/300], Step [21/23], Training Accuracy: 73.3631%, Training Loss: 0.3851%\n",
      "Epoch [78/300], Step [22/23], Training Accuracy: 73.5085%, Training Loss: 0.3842%\n",
      "Epoch [78/300], Step [23/23], Training Accuracy: 73.8013%, Training Loss: 0.3808%\n",
      "Epoch [79/300], Step [1/23], Training Accuracy: 81.2500%, Training Loss: 0.3640%\n",
      "Epoch [79/300], Step [2/23], Training Accuracy: 78.1250%, Training Loss: 0.3895%\n",
      "Epoch [79/300], Step [3/23], Training Accuracy: 76.0417%, Training Loss: 0.3861%\n",
      "Epoch [79/300], Step [4/23], Training Accuracy: 76.9531%, Training Loss: 0.3712%\n",
      "Epoch [79/300], Step [5/23], Training Accuracy: 75.9375%, Training Loss: 0.3744%\n",
      "Epoch [79/300], Step [6/23], Training Accuracy: 76.3021%, Training Loss: 0.3692%\n",
      "Epoch [79/300], Step [7/23], Training Accuracy: 75.6696%, Training Loss: 0.3739%\n",
      "Epoch [79/300], Step [8/23], Training Accuracy: 76.3672%, Training Loss: 0.3720%\n",
      "Epoch [79/300], Step [9/23], Training Accuracy: 75.0000%, Training Loss: 0.3801%\n",
      "Epoch [79/300], Step [10/23], Training Accuracy: 75.1562%, Training Loss: 0.3796%\n",
      "Epoch [79/300], Step [11/23], Training Accuracy: 75.1420%, Training Loss: 0.3791%\n",
      "Epoch [79/300], Step [12/23], Training Accuracy: 74.7396%, Training Loss: 0.3824%\n",
      "Epoch [79/300], Step [13/23], Training Accuracy: 73.9183%, Training Loss: 0.3856%\n",
      "Epoch [79/300], Step [14/23], Training Accuracy: 73.9955%, Training Loss: 0.3836%\n",
      "Epoch [79/300], Step [15/23], Training Accuracy: 73.5417%, Training Loss: 0.3853%\n",
      "Epoch [79/300], Step [16/23], Training Accuracy: 73.6328%, Training Loss: 0.3845%\n",
      "Epoch [79/300], Step [17/23], Training Accuracy: 73.7132%, Training Loss: 0.3844%\n",
      "Epoch [79/300], Step [18/23], Training Accuracy: 73.6979%, Training Loss: 0.3840%\n",
      "Epoch [79/300], Step [19/23], Training Accuracy: 73.8487%, Training Loss: 0.3833%\n",
      "Epoch [79/300], Step [20/23], Training Accuracy: 73.9062%, Training Loss: 0.3824%\n",
      "Epoch [79/300], Step [21/23], Training Accuracy: 74.1815%, Training Loss: 0.3815%\n",
      "Epoch [79/300], Step [22/23], Training Accuracy: 74.2188%, Training Loss: 0.3805%\n",
      "Epoch [79/300], Step [23/23], Training Accuracy: 74.4267%, Training Loss: 0.3777%\n",
      "Epoch [80/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3845%\n",
      "Epoch [80/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.4100%\n",
      "Epoch [80/300], Step [3/23], Training Accuracy: 71.3542%, Training Loss: 0.4176%\n",
      "Epoch [80/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.3952%\n",
      "Epoch [80/300], Step [5/23], Training Accuracy: 73.4375%, Training Loss: 0.3919%\n",
      "Epoch [80/300], Step [6/23], Training Accuracy: 74.7396%, Training Loss: 0.3886%\n",
      "Epoch [80/300], Step [7/23], Training Accuracy: 75.2232%, Training Loss: 0.3934%\n",
      "Epoch [80/300], Step [8/23], Training Accuracy: 75.5859%, Training Loss: 0.3901%\n",
      "Epoch [80/300], Step [9/23], Training Accuracy: 74.1319%, Training Loss: 0.3945%\n",
      "Epoch [80/300], Step [10/23], Training Accuracy: 74.2188%, Training Loss: 0.3923%\n",
      "Epoch [80/300], Step [11/23], Training Accuracy: 74.4318%, Training Loss: 0.3880%\n",
      "Epoch [80/300], Step [12/23], Training Accuracy: 74.3490%, Training Loss: 0.3891%\n",
      "Epoch [80/300], Step [13/23], Training Accuracy: 74.6394%, Training Loss: 0.3865%\n",
      "Epoch [80/300], Step [14/23], Training Accuracy: 74.5536%, Training Loss: 0.3855%\n",
      "Epoch [80/300], Step [15/23], Training Accuracy: 74.2708%, Training Loss: 0.3870%\n",
      "Epoch [80/300], Step [16/23], Training Accuracy: 74.1211%, Training Loss: 0.3874%\n",
      "Epoch [80/300], Step [17/23], Training Accuracy: 73.8971%, Training Loss: 0.3864%\n",
      "Epoch [80/300], Step [18/23], Training Accuracy: 73.5243%, Training Loss: 0.3877%\n",
      "Epoch [80/300], Step [19/23], Training Accuracy: 73.4375%, Training Loss: 0.3888%\n",
      "Epoch [80/300], Step [20/23], Training Accuracy: 73.5156%, Training Loss: 0.3868%\n",
      "Epoch [80/300], Step [21/23], Training Accuracy: 73.1399%, Training Loss: 0.3882%\n",
      "Epoch [80/300], Step [22/23], Training Accuracy: 73.3665%, Training Loss: 0.3873%\n",
      "Epoch [80/300], Step [23/23], Training Accuracy: 73.4538%, Training Loss: 0.3844%\n",
      "Epoch [81/300], Step [1/23], Training Accuracy: 71.8750%, Training Loss: 0.3510%\n",
      "Epoch [81/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.3819%\n",
      "Epoch [81/300], Step [3/23], Training Accuracy: 72.9167%, Training Loss: 0.3872%\n",
      "Epoch [81/300], Step [4/23], Training Accuracy: 75.7812%, Training Loss: 0.3728%\n",
      "Epoch [81/300], Step [5/23], Training Accuracy: 75.0000%, Training Loss: 0.3767%\n",
      "Epoch [81/300], Step [6/23], Training Accuracy: 75.7812%, Training Loss: 0.3764%\n",
      "Epoch [81/300], Step [7/23], Training Accuracy: 74.7768%, Training Loss: 0.3815%\n",
      "Epoch [81/300], Step [8/23], Training Accuracy: 74.8047%, Training Loss: 0.3825%\n",
      "Epoch [81/300], Step [9/23], Training Accuracy: 73.7847%, Training Loss: 0.3887%\n",
      "Epoch [81/300], Step [10/23], Training Accuracy: 73.1250%, Training Loss: 0.3879%\n",
      "Epoch [81/300], Step [11/23], Training Accuracy: 73.0114%, Training Loss: 0.3862%\n",
      "Epoch [81/300], Step [12/23], Training Accuracy: 72.9167%, Training Loss: 0.3854%\n",
      "Epoch [81/300], Step [13/23], Training Accuracy: 72.5962%, Training Loss: 0.3850%\n",
      "Epoch [81/300], Step [14/23], Training Accuracy: 73.1027%, Training Loss: 0.3844%\n",
      "Epoch [81/300], Step [15/23], Training Accuracy: 72.5000%, Training Loss: 0.3888%\n",
      "Epoch [81/300], Step [16/23], Training Accuracy: 72.3633%, Training Loss: 0.3895%\n",
      "Epoch [81/300], Step [17/23], Training Accuracy: 72.5184%, Training Loss: 0.3895%\n",
      "Epoch [81/300], Step [18/23], Training Accuracy: 72.3090%, Training Loss: 0.3909%\n",
      "Epoch [81/300], Step [19/23], Training Accuracy: 72.5329%, Training Loss: 0.3886%\n",
      "Epoch [81/300], Step [20/23], Training Accuracy: 72.5781%, Training Loss: 0.3875%\n",
      "Epoch [81/300], Step [21/23], Training Accuracy: 72.9167%, Training Loss: 0.3848%\n",
      "Epoch [81/300], Step [22/23], Training Accuracy: 73.2244%, Training Loss: 0.3833%\n",
      "Epoch [81/300], Step [23/23], Training Accuracy: 73.3148%, Training Loss: 0.3809%\n",
      "Epoch [82/300], Step [1/23], Training Accuracy: 81.2500%, Training Loss: 0.3379%\n",
      "Epoch [82/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3834%\n",
      "Epoch [82/300], Step [3/23], Training Accuracy: 73.9583%, Training Loss: 0.3864%\n",
      "Epoch [82/300], Step [4/23], Training Accuracy: 75.0000%, Training Loss: 0.3660%\n",
      "Epoch [82/300], Step [5/23], Training Accuracy: 73.7500%, Training Loss: 0.3732%\n",
      "Epoch [82/300], Step [6/23], Training Accuracy: 75.7812%, Training Loss: 0.3717%\n",
      "Epoch [82/300], Step [7/23], Training Accuracy: 75.8929%, Training Loss: 0.3747%\n",
      "Epoch [82/300], Step [8/23], Training Accuracy: 75.7812%, Training Loss: 0.3778%\n",
      "Epoch [82/300], Step [9/23], Training Accuracy: 74.6528%, Training Loss: 0.3805%\n",
      "Epoch [82/300], Step [10/23], Training Accuracy: 74.2188%, Training Loss: 0.3799%\n",
      "Epoch [82/300], Step [11/23], Training Accuracy: 74.4318%, Training Loss: 0.3804%\n",
      "Epoch [82/300], Step [12/23], Training Accuracy: 73.8281%, Training Loss: 0.3821%\n",
      "Epoch [82/300], Step [13/23], Training Accuracy: 73.9183%, Training Loss: 0.3828%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/300], Step [14/23], Training Accuracy: 73.8839%, Training Loss: 0.3821%\n",
      "Epoch [82/300], Step [15/23], Training Accuracy: 73.9583%, Training Loss: 0.3844%\n",
      "Epoch [82/300], Step [16/23], Training Accuracy: 73.6328%, Training Loss: 0.3843%\n",
      "Epoch [82/300], Step [17/23], Training Accuracy: 73.3456%, Training Loss: 0.3845%\n",
      "Epoch [82/300], Step [18/23], Training Accuracy: 73.7847%, Training Loss: 0.3840%\n",
      "Epoch [82/300], Step [19/23], Training Accuracy: 74.0954%, Training Loss: 0.3826%\n",
      "Epoch [82/300], Step [20/23], Training Accuracy: 74.1406%, Training Loss: 0.3830%\n",
      "Epoch [82/300], Step [21/23], Training Accuracy: 73.9583%, Training Loss: 0.3827%\n",
      "Epoch [82/300], Step [22/23], Training Accuracy: 74.0057%, Training Loss: 0.3817%\n",
      "Epoch [82/300], Step [23/23], Training Accuracy: 74.2182%, Training Loss: 0.3776%\n",
      "Epoch [83/300], Step [1/23], Training Accuracy: 71.8750%, Training Loss: 0.3640%\n",
      "Epoch [83/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.3866%\n",
      "Epoch [83/300], Step [3/23], Training Accuracy: 70.8333%, Training Loss: 0.3845%\n",
      "Epoch [83/300], Step [4/23], Training Accuracy: 73.4375%, Training Loss: 0.3626%\n",
      "Epoch [83/300], Step [5/23], Training Accuracy: 73.7500%, Training Loss: 0.3589%\n",
      "Epoch [83/300], Step [6/23], Training Accuracy: 73.4375%, Training Loss: 0.3659%\n",
      "Epoch [83/300], Step [7/23], Training Accuracy: 73.6607%, Training Loss: 0.3685%\n",
      "Epoch [83/300], Step [8/23], Training Accuracy: 74.8047%, Training Loss: 0.3709%\n",
      "Epoch [83/300], Step [9/23], Training Accuracy: 74.3056%, Training Loss: 0.3780%\n",
      "Epoch [83/300], Step [10/23], Training Accuracy: 74.5312%, Training Loss: 0.3747%\n",
      "Epoch [83/300], Step [11/23], Training Accuracy: 75.1420%, Training Loss: 0.3728%\n",
      "Epoch [83/300], Step [12/23], Training Accuracy: 74.6094%, Training Loss: 0.3747%\n",
      "Epoch [83/300], Step [13/23], Training Accuracy: 74.2788%, Training Loss: 0.3774%\n",
      "Epoch [83/300], Step [14/23], Training Accuracy: 74.2188%, Training Loss: 0.3780%\n",
      "Epoch [83/300], Step [15/23], Training Accuracy: 73.5417%, Training Loss: 0.3831%\n",
      "Epoch [83/300], Step [16/23], Training Accuracy: 73.3398%, Training Loss: 0.3837%\n",
      "Epoch [83/300], Step [17/23], Training Accuracy: 72.9779%, Training Loss: 0.3857%\n",
      "Epoch [83/300], Step [18/23], Training Accuracy: 73.1771%, Training Loss: 0.3874%\n",
      "Epoch [83/300], Step [19/23], Training Accuracy: 73.3553%, Training Loss: 0.3864%\n",
      "Epoch [83/300], Step [20/23], Training Accuracy: 73.2812%, Training Loss: 0.3859%\n",
      "Epoch [83/300], Step [21/23], Training Accuracy: 73.5119%, Training Loss: 0.3849%\n",
      "Epoch [83/300], Step [22/23], Training Accuracy: 73.7216%, Training Loss: 0.3840%\n",
      "Epoch [83/300], Step [23/23], Training Accuracy: 74.0097%, Training Loss: 0.3796%\n",
      "Epoch [84/300], Step [1/23], Training Accuracy: 81.2500%, Training Loss: 0.3730%\n",
      "Epoch [84/300], Step [2/23], Training Accuracy: 75.7812%, Training Loss: 0.3923%\n",
      "Epoch [84/300], Step [3/23], Training Accuracy: 72.9167%, Training Loss: 0.4007%\n",
      "Epoch [84/300], Step [4/23], Training Accuracy: 75.7812%, Training Loss: 0.3804%\n",
      "Epoch [84/300], Step [5/23], Training Accuracy: 75.6250%, Training Loss: 0.3790%\n",
      "Epoch [84/300], Step [6/23], Training Accuracy: 77.6042%, Training Loss: 0.3773%\n",
      "Epoch [84/300], Step [7/23], Training Accuracy: 77.2321%, Training Loss: 0.3817%\n",
      "Epoch [84/300], Step [8/23], Training Accuracy: 76.9531%, Training Loss: 0.3837%\n",
      "Epoch [84/300], Step [9/23], Training Accuracy: 75.6944%, Training Loss: 0.3855%\n",
      "Epoch [84/300], Step [10/23], Training Accuracy: 75.6250%, Training Loss: 0.3820%\n",
      "Epoch [84/300], Step [11/23], Training Accuracy: 75.0000%, Training Loss: 0.3832%\n",
      "Epoch [84/300], Step [12/23], Training Accuracy: 74.6094%, Training Loss: 0.3873%\n",
      "Epoch [84/300], Step [13/23], Training Accuracy: 74.3990%, Training Loss: 0.3890%\n",
      "Epoch [84/300], Step [14/23], Training Accuracy: 74.8884%, Training Loss: 0.3865%\n",
      "Epoch [84/300], Step [15/23], Training Accuracy: 74.4792%, Training Loss: 0.3896%\n",
      "Epoch [84/300], Step [16/23], Training Accuracy: 74.0234%, Training Loss: 0.3919%\n",
      "Epoch [84/300], Step [17/23], Training Accuracy: 74.4485%, Training Loss: 0.3884%\n",
      "Epoch [84/300], Step [18/23], Training Accuracy: 74.5660%, Training Loss: 0.3883%\n",
      "Epoch [84/300], Step [19/23], Training Accuracy: 74.6711%, Training Loss: 0.3881%\n",
      "Epoch [84/300], Step [20/23], Training Accuracy: 74.6094%, Training Loss: 0.3871%\n",
      "Epoch [84/300], Step [21/23], Training Accuracy: 74.2560%, Training Loss: 0.3867%\n",
      "Epoch [84/300], Step [22/23], Training Accuracy: 74.2898%, Training Loss: 0.3844%\n",
      "Epoch [84/300], Step [23/23], Training Accuracy: 74.3572%, Training Loss: 0.3814%\n",
      "Epoch [85/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3643%\n",
      "Epoch [85/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3790%\n",
      "Epoch [85/300], Step [3/23], Training Accuracy: 73.4375%, Training Loss: 0.3829%\n",
      "Epoch [85/300], Step [4/23], Training Accuracy: 75.7812%, Training Loss: 0.3702%\n",
      "Epoch [85/300], Step [5/23], Training Accuracy: 75.9375%, Training Loss: 0.3708%\n",
      "Epoch [85/300], Step [6/23], Training Accuracy: 75.2604%, Training Loss: 0.3702%\n",
      "Epoch [85/300], Step [7/23], Training Accuracy: 75.0000%, Training Loss: 0.3763%\n",
      "Epoch [85/300], Step [8/23], Training Accuracy: 75.3906%, Training Loss: 0.3746%\n",
      "Epoch [85/300], Step [9/23], Training Accuracy: 74.1319%, Training Loss: 0.3824%\n",
      "Epoch [85/300], Step [10/23], Training Accuracy: 73.9062%, Training Loss: 0.3821%\n",
      "Epoch [85/300], Step [11/23], Training Accuracy: 73.8636%, Training Loss: 0.3853%\n",
      "Epoch [85/300], Step [12/23], Training Accuracy: 73.6979%, Training Loss: 0.3882%\n",
      "Epoch [85/300], Step [13/23], Training Accuracy: 73.3173%, Training Loss: 0.3900%\n",
      "Epoch [85/300], Step [14/23], Training Accuracy: 72.7679%, Training Loss: 0.3911%\n",
      "Epoch [85/300], Step [15/23], Training Accuracy: 72.5000%, Training Loss: 0.3938%\n",
      "Epoch [85/300], Step [16/23], Training Accuracy: 72.5586%, Training Loss: 0.3926%\n",
      "Epoch [85/300], Step [17/23], Training Accuracy: 72.7022%, Training Loss: 0.3922%\n",
      "Epoch [85/300], Step [18/23], Training Accuracy: 73.1771%, Training Loss: 0.3920%\n",
      "Epoch [85/300], Step [19/23], Training Accuracy: 73.2730%, Training Loss: 0.3911%\n",
      "Epoch [85/300], Step [20/23], Training Accuracy: 73.3594%, Training Loss: 0.3899%\n",
      "Epoch [85/300], Step [21/23], Training Accuracy: 73.5863%, Training Loss: 0.3899%\n",
      "Epoch [85/300], Step [22/23], Training Accuracy: 73.7216%, Training Loss: 0.3896%\n",
      "Epoch [85/300], Step [23/23], Training Accuracy: 73.8707%, Training Loss: 0.3868%\n",
      "Epoch [86/300], Step [1/23], Training Accuracy: 81.2500%, Training Loss: 0.3550%\n",
      "Epoch [86/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3859%\n",
      "Epoch [86/300], Step [3/23], Training Accuracy: 73.9583%, Training Loss: 0.3806%\n",
      "Epoch [86/300], Step [4/23], Training Accuracy: 75.7812%, Training Loss: 0.3740%\n",
      "Epoch [86/300], Step [5/23], Training Accuracy: 75.0000%, Training Loss: 0.3747%\n",
      "Epoch [86/300], Step [6/23], Training Accuracy: 74.7396%, Training Loss: 0.3725%\n",
      "Epoch [86/300], Step [7/23], Training Accuracy: 74.5536%, Training Loss: 0.3781%\n",
      "Epoch [86/300], Step [8/23], Training Accuracy: 75.0000%, Training Loss: 0.3761%\n",
      "Epoch [86/300], Step [9/23], Training Accuracy: 73.9583%, Training Loss: 0.3786%\n",
      "Epoch [86/300], Step [10/23], Training Accuracy: 74.3750%, Training Loss: 0.3782%\n",
      "Epoch [86/300], Step [11/23], Training Accuracy: 74.5739%, Training Loss: 0.3788%\n",
      "Epoch [86/300], Step [12/23], Training Accuracy: 74.2188%, Training Loss: 0.3810%\n",
      "Epoch [86/300], Step [13/23], Training Accuracy: 73.7981%, Training Loss: 0.3819%\n",
      "Epoch [86/300], Step [14/23], Training Accuracy: 73.8839%, Training Loss: 0.3819%\n",
      "Epoch [86/300], Step [15/23], Training Accuracy: 72.9167%, Training Loss: 0.3863%\n",
      "Epoch [86/300], Step [16/23], Training Accuracy: 72.8516%, Training Loss: 0.3865%\n",
      "Epoch [86/300], Step [17/23], Training Accuracy: 72.8860%, Training Loss: 0.3879%\n",
      "Epoch [86/300], Step [18/23], Training Accuracy: 72.9167%, Training Loss: 0.3869%\n",
      "Epoch [86/300], Step [19/23], Training Accuracy: 73.1908%, Training Loss: 0.3850%\n",
      "Epoch [86/300], Step [20/23], Training Accuracy: 73.2812%, Training Loss: 0.3834%\n",
      "Epoch [86/300], Step [21/23], Training Accuracy: 73.4375%, Training Loss: 0.3832%\n",
      "Epoch [86/300], Step [22/23], Training Accuracy: 73.2955%, Training Loss: 0.3832%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/300], Step [23/23], Training Accuracy: 73.1758%, Training Loss: 0.3806%\n",
      "Epoch [87/300], Step [1/23], Training Accuracy: 71.8750%, Training Loss: 0.3736%\n",
      "Epoch [87/300], Step [2/23], Training Accuracy: 71.8750%, Training Loss: 0.3897%\n",
      "Epoch [87/300], Step [3/23], Training Accuracy: 69.7917%, Training Loss: 0.4003%\n",
      "Epoch [87/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.3800%\n",
      "Epoch [87/300], Step [5/23], Training Accuracy: 73.1250%, Training Loss: 0.3795%\n",
      "Epoch [87/300], Step [6/23], Training Accuracy: 74.2188%, Training Loss: 0.3780%\n",
      "Epoch [87/300], Step [7/23], Training Accuracy: 73.8839%, Training Loss: 0.3840%\n",
      "Epoch [87/300], Step [8/23], Training Accuracy: 74.2188%, Training Loss: 0.3853%\n",
      "Epoch [87/300], Step [9/23], Training Accuracy: 72.5694%, Training Loss: 0.3927%\n",
      "Epoch [87/300], Step [10/23], Training Accuracy: 72.1875%, Training Loss: 0.3909%\n",
      "Epoch [87/300], Step [11/23], Training Accuracy: 72.0170%, Training Loss: 0.3868%\n",
      "Epoch [87/300], Step [12/23], Training Accuracy: 71.8750%, Training Loss: 0.3889%\n",
      "Epoch [87/300], Step [13/23], Training Accuracy: 71.8750%, Training Loss: 0.3906%\n",
      "Epoch [87/300], Step [14/23], Training Accuracy: 72.2098%, Training Loss: 0.3893%\n",
      "Epoch [87/300], Step [15/23], Training Accuracy: 72.1875%, Training Loss: 0.3921%\n",
      "Epoch [87/300], Step [16/23], Training Accuracy: 72.4609%, Training Loss: 0.3903%\n",
      "Epoch [87/300], Step [17/23], Training Accuracy: 72.7022%, Training Loss: 0.3880%\n",
      "Epoch [87/300], Step [18/23], Training Accuracy: 73.0035%, Training Loss: 0.3880%\n",
      "Epoch [87/300], Step [19/23], Training Accuracy: 73.1908%, Training Loss: 0.3865%\n",
      "Epoch [87/300], Step [20/23], Training Accuracy: 73.4375%, Training Loss: 0.3847%\n",
      "Epoch [87/300], Step [21/23], Training Accuracy: 73.4375%, Training Loss: 0.3841%\n",
      "Epoch [87/300], Step [22/23], Training Accuracy: 73.5085%, Training Loss: 0.3830%\n",
      "Epoch [87/300], Step [23/23], Training Accuracy: 73.8013%, Training Loss: 0.3815%\n",
      "Epoch [88/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.4037%\n",
      "Epoch [88/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3998%\n",
      "Epoch [88/300], Step [3/23], Training Accuracy: 70.8333%, Training Loss: 0.4182%\n",
      "Epoch [88/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.4012%\n",
      "Epoch [88/300], Step [5/23], Training Accuracy: 75.0000%, Training Loss: 0.3889%\n",
      "Epoch [88/300], Step [6/23], Training Accuracy: 76.0417%, Training Loss: 0.3888%\n",
      "Epoch [88/300], Step [7/23], Training Accuracy: 75.6696%, Training Loss: 0.3917%\n",
      "Epoch [88/300], Step [8/23], Training Accuracy: 76.9531%, Training Loss: 0.3842%\n",
      "Epoch [88/300], Step [9/23], Training Accuracy: 75.1736%, Training Loss: 0.3939%\n",
      "Epoch [88/300], Step [10/23], Training Accuracy: 74.8438%, Training Loss: 0.3903%\n",
      "Epoch [88/300], Step [11/23], Training Accuracy: 74.8580%, Training Loss: 0.3895%\n",
      "Epoch [88/300], Step [12/23], Training Accuracy: 74.8698%, Training Loss: 0.3901%\n",
      "Epoch [88/300], Step [13/23], Training Accuracy: 74.6394%, Training Loss: 0.3922%\n",
      "Epoch [88/300], Step [14/23], Training Accuracy: 74.4420%, Training Loss: 0.3919%\n",
      "Epoch [88/300], Step [15/23], Training Accuracy: 73.8542%, Training Loss: 0.3952%\n",
      "Epoch [88/300], Step [16/23], Training Accuracy: 73.7305%, Training Loss: 0.3951%\n",
      "Epoch [88/300], Step [17/23], Training Accuracy: 74.0809%, Training Loss: 0.3931%\n",
      "Epoch [88/300], Step [18/23], Training Accuracy: 74.1319%, Training Loss: 0.3925%\n",
      "Epoch [88/300], Step [19/23], Training Accuracy: 74.4243%, Training Loss: 0.3912%\n",
      "Epoch [88/300], Step [20/23], Training Accuracy: 74.2969%, Training Loss: 0.3906%\n",
      "Epoch [88/300], Step [21/23], Training Accuracy: 74.4792%, Training Loss: 0.3894%\n",
      "Epoch [88/300], Step [22/23], Training Accuracy: 74.5739%, Training Loss: 0.3886%\n",
      "Epoch [88/300], Step [23/23], Training Accuracy: 74.6352%, Training Loss: 0.3850%\n",
      "Epoch [89/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3678%\n",
      "Epoch [89/300], Step [2/23], Training Accuracy: 77.3438%, Training Loss: 0.3814%\n",
      "Epoch [89/300], Step [3/23], Training Accuracy: 75.5208%, Training Loss: 0.3887%\n",
      "Epoch [89/300], Step [4/23], Training Accuracy: 77.3438%, Training Loss: 0.3690%\n",
      "Epoch [89/300], Step [5/23], Training Accuracy: 75.0000%, Training Loss: 0.3758%\n",
      "Epoch [89/300], Step [6/23], Training Accuracy: 75.2604%, Training Loss: 0.3732%\n",
      "Epoch [89/300], Step [7/23], Training Accuracy: 74.7768%, Training Loss: 0.3784%\n",
      "Epoch [89/300], Step [8/23], Training Accuracy: 75.5859%, Training Loss: 0.3782%\n",
      "Epoch [89/300], Step [9/23], Training Accuracy: 74.8264%, Training Loss: 0.3800%\n",
      "Epoch [89/300], Step [10/23], Training Accuracy: 74.6875%, Training Loss: 0.3789%\n",
      "Epoch [89/300], Step [11/23], Training Accuracy: 75.5682%, Training Loss: 0.3773%\n",
      "Epoch [89/300], Step [12/23], Training Accuracy: 75.0000%, Training Loss: 0.3792%\n",
      "Epoch [89/300], Step [13/23], Training Accuracy: 74.7596%, Training Loss: 0.3797%\n",
      "Epoch [89/300], Step [14/23], Training Accuracy: 74.6652%, Training Loss: 0.3779%\n",
      "Epoch [89/300], Step [15/23], Training Accuracy: 74.1667%, Training Loss: 0.3812%\n",
      "Epoch [89/300], Step [16/23], Training Accuracy: 73.9258%, Training Loss: 0.3820%\n",
      "Epoch [89/300], Step [17/23], Training Accuracy: 74.1728%, Training Loss: 0.3797%\n",
      "Epoch [89/300], Step [18/23], Training Accuracy: 74.4792%, Training Loss: 0.3794%\n",
      "Epoch [89/300], Step [19/23], Training Accuracy: 74.4243%, Training Loss: 0.3793%\n",
      "Epoch [89/300], Step [20/23], Training Accuracy: 74.7656%, Training Loss: 0.3789%\n",
      "Epoch [89/300], Step [21/23], Training Accuracy: 75.0744%, Training Loss: 0.3775%\n",
      "Epoch [89/300], Step [22/23], Training Accuracy: 75.0000%, Training Loss: 0.3779%\n",
      "Epoch [89/300], Step [23/23], Training Accuracy: 75.1216%, Training Loss: 0.3758%\n",
      "Epoch [90/300], Step [1/23], Training Accuracy: 73.4375%, Training Loss: 0.3781%\n",
      "Epoch [90/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3948%\n",
      "Epoch [90/300], Step [3/23], Training Accuracy: 71.3542%, Training Loss: 0.4001%\n",
      "Epoch [90/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.3813%\n",
      "Epoch [90/300], Step [5/23], Training Accuracy: 73.7500%, Training Loss: 0.3812%\n",
      "Epoch [90/300], Step [6/23], Training Accuracy: 74.2188%, Training Loss: 0.3831%\n",
      "Epoch [90/300], Step [7/23], Training Accuracy: 74.7768%, Training Loss: 0.3830%\n",
      "Epoch [90/300], Step [8/23], Training Accuracy: 74.8047%, Training Loss: 0.3820%\n",
      "Epoch [90/300], Step [9/23], Training Accuracy: 73.9583%, Training Loss: 0.3877%\n",
      "Epoch [90/300], Step [10/23], Training Accuracy: 74.0625%, Training Loss: 0.3833%\n",
      "Epoch [90/300], Step [11/23], Training Accuracy: 74.1477%, Training Loss: 0.3854%\n",
      "Epoch [90/300], Step [12/23], Training Accuracy: 73.6979%, Training Loss: 0.3877%\n",
      "Epoch [90/300], Step [13/23], Training Accuracy: 73.3173%, Training Loss: 0.3887%\n",
      "Epoch [90/300], Step [14/23], Training Accuracy: 73.5491%, Training Loss: 0.3873%\n",
      "Epoch [90/300], Step [15/23], Training Accuracy: 73.3333%, Training Loss: 0.3909%\n",
      "Epoch [90/300], Step [16/23], Training Accuracy: 73.0469%, Training Loss: 0.3914%\n",
      "Epoch [90/300], Step [17/23], Training Accuracy: 73.2537%, Training Loss: 0.3896%\n",
      "Epoch [90/300], Step [18/23], Training Accuracy: 73.3507%, Training Loss: 0.3897%\n",
      "Epoch [90/300], Step [19/23], Training Accuracy: 73.6842%, Training Loss: 0.3881%\n",
      "Epoch [90/300], Step [20/23], Training Accuracy: 74.0625%, Training Loss: 0.3862%\n",
      "Epoch [90/300], Step [21/23], Training Accuracy: 74.3304%, Training Loss: 0.3846%\n",
      "Epoch [90/300], Step [22/23], Training Accuracy: 74.3608%, Training Loss: 0.3829%\n",
      "Epoch [90/300], Step [23/23], Training Accuracy: 74.5657%, Training Loss: 0.3798%\n",
      "Epoch [91/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3386%\n",
      "Epoch [91/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.3681%\n",
      "Epoch [91/300], Step [3/23], Training Accuracy: 70.3125%, Training Loss: 0.3803%\n",
      "Epoch [91/300], Step [4/23], Training Accuracy: 74.6094%, Training Loss: 0.3692%\n",
      "Epoch [91/300], Step [5/23], Training Accuracy: 75.3125%, Training Loss: 0.3662%\n",
      "Epoch [91/300], Step [6/23], Training Accuracy: 76.3021%, Training Loss: 0.3630%\n",
      "Epoch [91/300], Step [7/23], Training Accuracy: 75.8929%, Training Loss: 0.3697%\n",
      "Epoch [91/300], Step [8/23], Training Accuracy: 76.5625%, Training Loss: 0.3702%\n",
      "Epoch [91/300], Step [9/23], Training Accuracy: 75.5208%, Training Loss: 0.3738%\n",
      "Epoch [91/300], Step [10/23], Training Accuracy: 75.7812%, Training Loss: 0.3727%\n",
      "Epoch [91/300], Step [11/23], Training Accuracy: 76.5625%, Training Loss: 0.3689%\n",
      "Epoch [91/300], Step [12/23], Training Accuracy: 76.0417%, Training Loss: 0.3721%\n",
      "Epoch [91/300], Step [13/23], Training Accuracy: 75.6010%, Training Loss: 0.3739%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/300], Step [14/23], Training Accuracy: 75.6696%, Training Loss: 0.3730%\n",
      "Epoch [91/300], Step [15/23], Training Accuracy: 75.2083%, Training Loss: 0.3771%\n",
      "Epoch [91/300], Step [16/23], Training Accuracy: 75.1953%, Training Loss: 0.3778%\n",
      "Epoch [91/300], Step [17/23], Training Accuracy: 75.0919%, Training Loss: 0.3768%\n",
      "Epoch [91/300], Step [18/23], Training Accuracy: 74.9132%, Training Loss: 0.3775%\n",
      "Epoch [91/300], Step [19/23], Training Accuracy: 74.8355%, Training Loss: 0.3772%\n",
      "Epoch [91/300], Step [20/23], Training Accuracy: 75.0000%, Training Loss: 0.3761%\n",
      "Epoch [91/300], Step [21/23], Training Accuracy: 74.9256%, Training Loss: 0.3768%\n",
      "Epoch [91/300], Step [22/23], Training Accuracy: 74.9290%, Training Loss: 0.3765%\n",
      "Epoch [91/300], Step [23/23], Training Accuracy: 74.9131%, Training Loss: 0.3751%\n",
      "Epoch [92/300], Step [1/23], Training Accuracy: 73.4375%, Training Loss: 0.3537%\n",
      "Epoch [92/300], Step [2/23], Training Accuracy: 71.0938%, Training Loss: 0.3944%\n",
      "Epoch [92/300], Step [3/23], Training Accuracy: 70.3125%, Training Loss: 0.4047%\n",
      "Epoch [92/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.3858%\n",
      "Epoch [92/300], Step [5/23], Training Accuracy: 72.5000%, Training Loss: 0.3801%\n",
      "Epoch [92/300], Step [6/23], Training Accuracy: 73.6979%, Training Loss: 0.3775%\n",
      "Epoch [92/300], Step [7/23], Training Accuracy: 74.1071%, Training Loss: 0.3825%\n",
      "Epoch [92/300], Step [8/23], Training Accuracy: 74.8047%, Training Loss: 0.3793%\n",
      "Epoch [92/300], Step [9/23], Training Accuracy: 73.4375%, Training Loss: 0.3872%\n",
      "Epoch [92/300], Step [10/23], Training Accuracy: 73.9062%, Training Loss: 0.3829%\n",
      "Epoch [92/300], Step [11/23], Training Accuracy: 74.4318%, Training Loss: 0.3804%\n",
      "Epoch [92/300], Step [12/23], Training Accuracy: 74.6094%, Training Loss: 0.3824%\n",
      "Epoch [92/300], Step [13/23], Training Accuracy: 74.2788%, Training Loss: 0.3845%\n",
      "Epoch [92/300], Step [14/23], Training Accuracy: 74.7768%, Training Loss: 0.3820%\n",
      "Epoch [92/300], Step [15/23], Training Accuracy: 74.4792%, Training Loss: 0.3863%\n",
      "Epoch [92/300], Step [16/23], Training Accuracy: 74.0234%, Training Loss: 0.3871%\n",
      "Epoch [92/300], Step [17/23], Training Accuracy: 74.0809%, Training Loss: 0.3854%\n",
      "Epoch [92/300], Step [18/23], Training Accuracy: 74.2188%, Training Loss: 0.3853%\n",
      "Epoch [92/300], Step [19/23], Training Accuracy: 74.4243%, Training Loss: 0.3838%\n",
      "Epoch [92/300], Step [20/23], Training Accuracy: 74.3750%, Training Loss: 0.3824%\n",
      "Epoch [92/300], Step [21/23], Training Accuracy: 74.5536%, Training Loss: 0.3817%\n",
      "Epoch [92/300], Step [22/23], Training Accuracy: 74.4318%, Training Loss: 0.3822%\n",
      "Epoch [92/300], Step [23/23], Training Accuracy: 74.4962%, Training Loss: 0.3791%\n",
      "Epoch [93/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3410%\n",
      "Epoch [93/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.3821%\n",
      "Epoch [93/300], Step [3/23], Training Accuracy: 72.9167%, Training Loss: 0.3943%\n",
      "Epoch [93/300], Step [4/23], Training Accuracy: 75.0000%, Training Loss: 0.3766%\n",
      "Epoch [93/300], Step [5/23], Training Accuracy: 74.3750%, Training Loss: 0.3764%\n",
      "Epoch [93/300], Step [6/23], Training Accuracy: 75.5208%, Training Loss: 0.3772%\n",
      "Epoch [93/300], Step [7/23], Training Accuracy: 75.0000%, Training Loss: 0.3823%\n",
      "Epoch [93/300], Step [8/23], Training Accuracy: 75.1953%, Training Loss: 0.3821%\n",
      "Epoch [93/300], Step [9/23], Training Accuracy: 74.3056%, Training Loss: 0.3858%\n",
      "Epoch [93/300], Step [10/23], Training Accuracy: 74.2188%, Training Loss: 0.3862%\n",
      "Epoch [93/300], Step [11/23], Training Accuracy: 74.1477%, Training Loss: 0.3858%\n",
      "Epoch [93/300], Step [12/23], Training Accuracy: 74.3490%, Training Loss: 0.3850%\n",
      "Epoch [93/300], Step [13/23], Training Accuracy: 74.5192%, Training Loss: 0.3846%\n",
      "Epoch [93/300], Step [14/23], Training Accuracy: 74.4420%, Training Loss: 0.3838%\n",
      "Epoch [93/300], Step [15/23], Training Accuracy: 73.7500%, Training Loss: 0.3865%\n",
      "Epoch [93/300], Step [16/23], Training Accuracy: 73.9258%, Training Loss: 0.3846%\n",
      "Epoch [93/300], Step [17/23], Training Accuracy: 74.3566%, Training Loss: 0.3833%\n",
      "Epoch [93/300], Step [18/23], Training Accuracy: 74.5660%, Training Loss: 0.3827%\n",
      "Epoch [93/300], Step [19/23], Training Accuracy: 74.5066%, Training Loss: 0.3809%\n",
      "Epoch [93/300], Step [20/23], Training Accuracy: 74.6094%, Training Loss: 0.3800%\n",
      "Epoch [93/300], Step [21/23], Training Accuracy: 74.9256%, Training Loss: 0.3786%\n",
      "Epoch [93/300], Step [22/23], Training Accuracy: 74.9290%, Training Loss: 0.3777%\n",
      "Epoch [93/300], Step [23/23], Training Accuracy: 74.9826%, Training Loss: 0.3749%\n",
      "Epoch [94/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3550%\n",
      "Epoch [94/300], Step [2/23], Training Accuracy: 77.3438%, Training Loss: 0.3836%\n",
      "Epoch [94/300], Step [3/23], Training Accuracy: 74.4792%, Training Loss: 0.3966%\n",
      "Epoch [94/300], Step [4/23], Training Accuracy: 76.1719%, Training Loss: 0.3771%\n",
      "Epoch [94/300], Step [5/23], Training Accuracy: 74.6875%, Training Loss: 0.3785%\n",
      "Epoch [94/300], Step [6/23], Training Accuracy: 74.7396%, Training Loss: 0.3803%\n",
      "Epoch [94/300], Step [7/23], Training Accuracy: 74.7768%, Training Loss: 0.3857%\n",
      "Epoch [94/300], Step [8/23], Training Accuracy: 75.5859%, Training Loss: 0.3837%\n",
      "Epoch [94/300], Step [9/23], Training Accuracy: 74.6528%, Training Loss: 0.3860%\n",
      "Epoch [94/300], Step [10/23], Training Accuracy: 75.0000%, Training Loss: 0.3835%\n",
      "Epoch [94/300], Step [11/23], Training Accuracy: 75.1420%, Training Loss: 0.3827%\n",
      "Epoch [94/300], Step [12/23], Training Accuracy: 75.5208%, Training Loss: 0.3815%\n",
      "Epoch [94/300], Step [13/23], Training Accuracy: 75.2404%, Training Loss: 0.3830%\n",
      "Epoch [94/300], Step [14/23], Training Accuracy: 75.5580%, Training Loss: 0.3808%\n",
      "Epoch [94/300], Step [15/23], Training Accuracy: 75.2083%, Training Loss: 0.3826%\n",
      "Epoch [94/300], Step [16/23], Training Accuracy: 75.1953%, Training Loss: 0.3835%\n",
      "Epoch [94/300], Step [17/23], Training Accuracy: 75.3676%, Training Loss: 0.3820%\n",
      "Epoch [94/300], Step [18/23], Training Accuracy: 75.2604%, Training Loss: 0.3832%\n",
      "Epoch [94/300], Step [19/23], Training Accuracy: 75.1645%, Training Loss: 0.3833%\n",
      "Epoch [94/300], Step [20/23], Training Accuracy: 75.3125%, Training Loss: 0.3811%\n",
      "Epoch [94/300], Step [21/23], Training Accuracy: 75.2232%, Training Loss: 0.3804%\n",
      "Epoch [94/300], Step [22/23], Training Accuracy: 75.2841%, Training Loss: 0.3799%\n",
      "Epoch [94/300], Step [23/23], Training Accuracy: 75.4691%, Training Loss: 0.3761%\n",
      "Epoch [95/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3548%\n",
      "Epoch [95/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.3991%\n",
      "Epoch [95/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.3968%\n",
      "Epoch [95/300], Step [4/23], Training Accuracy: 72.2656%, Training Loss: 0.3841%\n",
      "Epoch [95/300], Step [5/23], Training Accuracy: 73.7500%, Training Loss: 0.3842%\n",
      "Epoch [95/300], Step [6/23], Training Accuracy: 73.6979%, Training Loss: 0.3826%\n",
      "Epoch [95/300], Step [7/23], Training Accuracy: 73.6607%, Training Loss: 0.3875%\n",
      "Epoch [95/300], Step [8/23], Training Accuracy: 74.2188%, Training Loss: 0.3867%\n",
      "Epoch [95/300], Step [9/23], Training Accuracy: 73.4375%, Training Loss: 0.3924%\n",
      "Epoch [95/300], Step [10/23], Training Accuracy: 73.1250%, Training Loss: 0.3913%\n",
      "Epoch [95/300], Step [11/23], Training Accuracy: 73.2955%, Training Loss: 0.3904%\n",
      "Epoch [95/300], Step [12/23], Training Accuracy: 73.5677%, Training Loss: 0.3905%\n",
      "Epoch [95/300], Step [13/23], Training Accuracy: 73.0769%, Training Loss: 0.3914%\n",
      "Epoch [95/300], Step [14/23], Training Accuracy: 73.3259%, Training Loss: 0.3908%\n",
      "Epoch [95/300], Step [15/23], Training Accuracy: 72.9167%, Training Loss: 0.3938%\n",
      "Epoch [95/300], Step [16/23], Training Accuracy: 72.9492%, Training Loss: 0.3945%\n",
      "Epoch [95/300], Step [17/23], Training Accuracy: 73.1618%, Training Loss: 0.3930%\n",
      "Epoch [95/300], Step [18/23], Training Accuracy: 73.1771%, Training Loss: 0.3930%\n",
      "Epoch [95/300], Step [19/23], Training Accuracy: 73.5197%, Training Loss: 0.3925%\n",
      "Epoch [95/300], Step [20/23], Training Accuracy: 73.5156%, Training Loss: 0.3925%\n",
      "Epoch [95/300], Step [21/23], Training Accuracy: 73.3631%, Training Loss: 0.3922%\n",
      "Epoch [95/300], Step [22/23], Training Accuracy: 73.5085%, Training Loss: 0.3907%\n",
      "Epoch [95/300], Step [23/23], Training Accuracy: 73.4538%, Training Loss: 0.3873%\n",
      "Epoch [96/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3714%\n",
      "Epoch [96/300], Step [2/23], Training Accuracy: 75.7812%, Training Loss: 0.3817%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/300], Step [3/23], Training Accuracy: 74.4792%, Training Loss: 0.3934%\n",
      "Epoch [96/300], Step [4/23], Training Accuracy: 76.9531%, Training Loss: 0.3734%\n",
      "Epoch [96/300], Step [5/23], Training Accuracy: 75.9375%, Training Loss: 0.3769%\n",
      "Epoch [96/300], Step [6/23], Training Accuracy: 76.8229%, Training Loss: 0.3799%\n",
      "Epoch [96/300], Step [7/23], Training Accuracy: 77.0089%, Training Loss: 0.3829%\n",
      "Epoch [96/300], Step [8/23], Training Accuracy: 77.3438%, Training Loss: 0.3809%\n",
      "Epoch [96/300], Step [9/23], Training Accuracy: 76.3889%, Training Loss: 0.3853%\n",
      "Epoch [96/300], Step [10/23], Training Accuracy: 75.7812%, Training Loss: 0.3842%\n",
      "Epoch [96/300], Step [11/23], Training Accuracy: 75.9943%, Training Loss: 0.3814%\n",
      "Epoch [96/300], Step [12/23], Training Accuracy: 75.7812%, Training Loss: 0.3805%\n",
      "Epoch [96/300], Step [13/23], Training Accuracy: 75.6010%, Training Loss: 0.3802%\n",
      "Epoch [96/300], Step [14/23], Training Accuracy: 75.7812%, Training Loss: 0.3783%\n",
      "Epoch [96/300], Step [15/23], Training Accuracy: 75.4167%, Training Loss: 0.3826%\n",
      "Epoch [96/300], Step [16/23], Training Accuracy: 75.1953%, Training Loss: 0.3839%\n",
      "Epoch [96/300], Step [17/23], Training Accuracy: 75.2757%, Training Loss: 0.3828%\n",
      "Epoch [96/300], Step [18/23], Training Accuracy: 75.2604%, Training Loss: 0.3829%\n",
      "Epoch [96/300], Step [19/23], Training Accuracy: 75.0000%, Training Loss: 0.3838%\n",
      "Epoch [96/300], Step [20/23], Training Accuracy: 75.2344%, Training Loss: 0.3820%\n",
      "Epoch [96/300], Step [21/23], Training Accuracy: 75.0744%, Training Loss: 0.3821%\n",
      "Epoch [96/300], Step [22/23], Training Accuracy: 74.9290%, Training Loss: 0.3814%\n",
      "Epoch [96/300], Step [23/23], Training Accuracy: 75.0521%, Training Loss: 0.3781%\n",
      "Epoch [97/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3616%\n",
      "Epoch [97/300], Step [2/23], Training Accuracy: 72.6562%, Training Loss: 0.3939%\n",
      "Epoch [97/300], Step [3/23], Training Accuracy: 71.3542%, Training Loss: 0.3948%\n",
      "Epoch [97/300], Step [4/23], Training Accuracy: 73.0469%, Training Loss: 0.3795%\n",
      "Epoch [97/300], Step [5/23], Training Accuracy: 72.8125%, Training Loss: 0.3827%\n",
      "Epoch [97/300], Step [6/23], Training Accuracy: 73.9583%, Training Loss: 0.3794%\n",
      "Epoch [97/300], Step [7/23], Training Accuracy: 74.1071%, Training Loss: 0.3815%\n",
      "Epoch [97/300], Step [8/23], Training Accuracy: 75.5859%, Training Loss: 0.3793%\n",
      "Epoch [97/300], Step [9/23], Training Accuracy: 74.6528%, Training Loss: 0.3850%\n",
      "Epoch [97/300], Step [10/23], Training Accuracy: 74.8438%, Training Loss: 0.3849%\n",
      "Epoch [97/300], Step [11/23], Training Accuracy: 75.1420%, Training Loss: 0.3841%\n",
      "Epoch [97/300], Step [12/23], Training Accuracy: 75.1302%, Training Loss: 0.3854%\n",
      "Epoch [97/300], Step [13/23], Training Accuracy: 75.1202%, Training Loss: 0.3869%\n",
      "Epoch [97/300], Step [14/23], Training Accuracy: 75.3348%, Training Loss: 0.3852%\n",
      "Epoch [97/300], Step [15/23], Training Accuracy: 75.0000%, Training Loss: 0.3871%\n",
      "Epoch [97/300], Step [16/23], Training Accuracy: 74.5117%, Training Loss: 0.3872%\n",
      "Epoch [97/300], Step [17/23], Training Accuracy: 74.2647%, Training Loss: 0.3868%\n",
      "Epoch [97/300], Step [18/23], Training Accuracy: 74.0451%, Training Loss: 0.3876%\n",
      "Epoch [97/300], Step [19/23], Training Accuracy: 74.1776%, Training Loss: 0.3876%\n",
      "Epoch [97/300], Step [20/23], Training Accuracy: 74.2969%, Training Loss: 0.3853%\n",
      "Epoch [97/300], Step [21/23], Training Accuracy: 74.1815%, Training Loss: 0.3846%\n",
      "Epoch [97/300], Step [22/23], Training Accuracy: 74.3608%, Training Loss: 0.3833%\n",
      "Epoch [97/300], Step [23/23], Training Accuracy: 74.5657%, Training Loss: 0.3802%\n",
      "Epoch [98/300], Step [1/23], Training Accuracy: 82.8125%, Training Loss: 0.3395%\n",
      "Epoch [98/300], Step [2/23], Training Accuracy: 80.4688%, Training Loss: 0.3813%\n",
      "Epoch [98/300], Step [3/23], Training Accuracy: 76.5625%, Training Loss: 0.3939%\n",
      "Epoch [98/300], Step [4/23], Training Accuracy: 77.3438%, Training Loss: 0.3785%\n",
      "Epoch [98/300], Step [5/23], Training Accuracy: 75.9375%, Training Loss: 0.3810%\n",
      "Epoch [98/300], Step [6/23], Training Accuracy: 76.5625%, Training Loss: 0.3786%\n",
      "Epoch [98/300], Step [7/23], Training Accuracy: 76.3393%, Training Loss: 0.3818%\n",
      "Epoch [98/300], Step [8/23], Training Accuracy: 76.7578%, Training Loss: 0.3792%\n",
      "Epoch [98/300], Step [9/23], Training Accuracy: 75.6944%, Training Loss: 0.3831%\n",
      "Epoch [98/300], Step [10/23], Training Accuracy: 75.7812%, Training Loss: 0.3808%\n",
      "Epoch [98/300], Step [11/23], Training Accuracy: 75.9943%, Training Loss: 0.3810%\n",
      "Epoch [98/300], Step [12/23], Training Accuracy: 75.9115%, Training Loss: 0.3818%\n",
      "Epoch [98/300], Step [13/23], Training Accuracy: 75.6010%, Training Loss: 0.3854%\n",
      "Epoch [98/300], Step [14/23], Training Accuracy: 75.8929%, Training Loss: 0.3850%\n",
      "Epoch [98/300], Step [15/23], Training Accuracy: 75.3125%, Training Loss: 0.3869%\n",
      "Epoch [98/300], Step [16/23], Training Accuracy: 75.2930%, Training Loss: 0.3858%\n",
      "Epoch [98/300], Step [17/23], Training Accuracy: 75.4596%, Training Loss: 0.3838%\n",
      "Epoch [98/300], Step [18/23], Training Accuracy: 75.5208%, Training Loss: 0.3830%\n",
      "Epoch [98/300], Step [19/23], Training Accuracy: 75.6579%, Training Loss: 0.3817%\n",
      "Epoch [98/300], Step [20/23], Training Accuracy: 75.7812%, Training Loss: 0.3806%\n",
      "Epoch [98/300], Step [21/23], Training Accuracy: 75.8185%, Training Loss: 0.3796%\n",
      "Epoch [98/300], Step [22/23], Training Accuracy: 75.4972%, Training Loss: 0.3792%\n",
      "Epoch [98/300], Step [23/23], Training Accuracy: 75.5386%, Training Loss: 0.3767%\n",
      "Epoch [99/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3500%\n",
      "Epoch [99/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.3738%\n",
      "Epoch [99/300], Step [3/23], Training Accuracy: 73.4375%, Training Loss: 0.3815%\n",
      "Epoch [99/300], Step [4/23], Training Accuracy: 76.5625%, Training Loss: 0.3653%\n",
      "Epoch [99/300], Step [5/23], Training Accuracy: 76.5625%, Training Loss: 0.3680%\n",
      "Epoch [99/300], Step [6/23], Training Accuracy: 77.3438%, Training Loss: 0.3678%\n",
      "Epoch [99/300], Step [7/23], Training Accuracy: 77.4554%, Training Loss: 0.3704%\n",
      "Epoch [99/300], Step [8/23], Training Accuracy: 77.9297%, Training Loss: 0.3681%\n",
      "Epoch [99/300], Step [9/23], Training Accuracy: 76.2153%, Training Loss: 0.3749%\n",
      "Epoch [99/300], Step [10/23], Training Accuracy: 75.7812%, Training Loss: 0.3746%\n",
      "Epoch [99/300], Step [11/23], Training Accuracy: 75.9943%, Training Loss: 0.3733%\n",
      "Epoch [99/300], Step [12/23], Training Accuracy: 76.0417%, Training Loss: 0.3748%\n",
      "Epoch [99/300], Step [13/23], Training Accuracy: 75.4808%, Training Loss: 0.3776%\n",
      "Epoch [99/300], Step [14/23], Training Accuracy: 75.6696%, Training Loss: 0.3771%\n",
      "Epoch [99/300], Step [15/23], Training Accuracy: 74.8958%, Training Loss: 0.3801%\n",
      "Epoch [99/300], Step [16/23], Training Accuracy: 74.6094%, Training Loss: 0.3826%\n",
      "Epoch [99/300], Step [17/23], Training Accuracy: 74.5404%, Training Loss: 0.3819%\n",
      "Epoch [99/300], Step [18/23], Training Accuracy: 74.0451%, Training Loss: 0.3828%\n",
      "Epoch [99/300], Step [19/23], Training Accuracy: 74.1776%, Training Loss: 0.3828%\n",
      "Epoch [99/300], Step [20/23], Training Accuracy: 74.1406%, Training Loss: 0.3827%\n",
      "Epoch [99/300], Step [21/23], Training Accuracy: 74.1071%, Training Loss: 0.3825%\n",
      "Epoch [99/300], Step [22/23], Training Accuracy: 74.2898%, Training Loss: 0.3812%\n",
      "Epoch [99/300], Step [23/23], Training Accuracy: 74.4962%, Training Loss: 0.3781%\n",
      "Epoch [100/300], Step [1/23], Training Accuracy: 84.3750%, Training Loss: 0.3526%\n",
      "Epoch [100/300], Step [2/23], Training Accuracy: 77.3438%, Training Loss: 0.3834%\n",
      "Epoch [100/300], Step [3/23], Training Accuracy: 73.9583%, Training Loss: 0.3966%\n",
      "Epoch [100/300], Step [4/23], Training Accuracy: 75.7812%, Training Loss: 0.3826%\n",
      "Epoch [100/300], Step [5/23], Training Accuracy: 74.6875%, Training Loss: 0.3831%\n",
      "Epoch [100/300], Step [6/23], Training Accuracy: 75.5208%, Training Loss: 0.3788%\n",
      "Epoch [100/300], Step [7/23], Training Accuracy: 75.2232%, Training Loss: 0.3852%\n",
      "Epoch [100/300], Step [8/23], Training Accuracy: 75.7812%, Training Loss: 0.3839%\n",
      "Epoch [100/300], Step [9/23], Training Accuracy: 73.9583%, Training Loss: 0.3895%\n",
      "Epoch [100/300], Step [10/23], Training Accuracy: 74.5312%, Training Loss: 0.3841%\n",
      "Epoch [100/300], Step [11/23], Training Accuracy: 74.8580%, Training Loss: 0.3833%\n",
      "Epoch [100/300], Step [12/23], Training Accuracy: 74.8698%, Training Loss: 0.3849%\n",
      "Epoch [100/300], Step [13/23], Training Accuracy: 74.8798%, Training Loss: 0.3872%\n",
      "Epoch [100/300], Step [14/23], Training Accuracy: 75.1116%, Training Loss: 0.3850%\n",
      "Epoch [100/300], Step [15/23], Training Accuracy: 74.7917%, Training Loss: 0.3901%\n",
      "Epoch [100/300], Step [16/23], Training Accuracy: 74.6094%, Training Loss: 0.3906%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/300], Step [17/23], Training Accuracy: 74.7243%, Training Loss: 0.3894%\n",
      "Epoch [100/300], Step [18/23], Training Accuracy: 74.8264%, Training Loss: 0.3896%\n",
      "Epoch [100/300], Step [19/23], Training Accuracy: 74.8355%, Training Loss: 0.3901%\n",
      "Epoch [100/300], Step [20/23], Training Accuracy: 75.1562%, Training Loss: 0.3877%\n",
      "Epoch [100/300], Step [21/23], Training Accuracy: 75.0000%, Training Loss: 0.3872%\n",
      "Epoch [100/300], Step [22/23], Training Accuracy: 74.9290%, Training Loss: 0.3863%\n",
      "Epoch [100/300], Step [23/23], Training Accuracy: 74.9826%, Training Loss: 0.3825%\n",
      "Epoch [101/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3614%\n",
      "Epoch [101/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.3954%\n",
      "Epoch [101/300], Step [3/23], Training Accuracy: 71.3542%, Training Loss: 0.4021%\n",
      "Epoch [101/300], Step [4/23], Training Accuracy: 75.3906%, Training Loss: 0.3804%\n",
      "Epoch [101/300], Step [5/23], Training Accuracy: 75.0000%, Training Loss: 0.3754%\n",
      "Epoch [101/300], Step [6/23], Training Accuracy: 75.7812%, Training Loss: 0.3762%\n",
      "Epoch [101/300], Step [7/23], Training Accuracy: 75.2232%, Training Loss: 0.3799%\n",
      "Epoch [101/300], Step [8/23], Training Accuracy: 75.3906%, Training Loss: 0.3806%\n",
      "Epoch [101/300], Step [9/23], Training Accuracy: 73.9583%, Training Loss: 0.3893%\n",
      "Epoch [101/300], Step [10/23], Training Accuracy: 74.0625%, Training Loss: 0.3874%\n",
      "Epoch [101/300], Step [11/23], Training Accuracy: 74.1477%, Training Loss: 0.3880%\n",
      "Epoch [101/300], Step [12/23], Training Accuracy: 74.3490%, Training Loss: 0.3879%\n",
      "Epoch [101/300], Step [13/23], Training Accuracy: 74.5192%, Training Loss: 0.3881%\n",
      "Epoch [101/300], Step [14/23], Training Accuracy: 74.6652%, Training Loss: 0.3850%\n",
      "Epoch [101/300], Step [15/23], Training Accuracy: 74.6875%, Training Loss: 0.3863%\n",
      "Epoch [101/300], Step [16/23], Training Accuracy: 74.3164%, Training Loss: 0.3871%\n",
      "Epoch [101/300], Step [17/23], Training Accuracy: 74.6324%, Training Loss: 0.3860%\n",
      "Epoch [101/300], Step [18/23], Training Accuracy: 74.3056%, Training Loss: 0.3875%\n",
      "Epoch [101/300], Step [19/23], Training Accuracy: 74.1776%, Training Loss: 0.3884%\n",
      "Epoch [101/300], Step [20/23], Training Accuracy: 74.3750%, Training Loss: 0.3866%\n",
      "Epoch [101/300], Step [21/23], Training Accuracy: 74.5536%, Training Loss: 0.3849%\n",
      "Epoch [101/300], Step [22/23], Training Accuracy: 74.5739%, Training Loss: 0.3838%\n",
      "Epoch [101/300], Step [23/23], Training Accuracy: 74.7741%, Training Loss: 0.3798%\n",
      "Epoch [102/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3394%\n",
      "Epoch [102/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.3761%\n",
      "Epoch [102/300], Step [3/23], Training Accuracy: 74.4792%, Training Loss: 0.3826%\n",
      "Epoch [102/300], Step [4/23], Training Accuracy: 76.5625%, Training Loss: 0.3683%\n",
      "Epoch [102/300], Step [5/23], Training Accuracy: 75.6250%, Training Loss: 0.3710%\n",
      "Epoch [102/300], Step [6/23], Training Accuracy: 75.7812%, Training Loss: 0.3707%\n",
      "Epoch [102/300], Step [7/23], Training Accuracy: 75.4464%, Training Loss: 0.3768%\n",
      "Epoch [102/300], Step [8/23], Training Accuracy: 75.7812%, Training Loss: 0.3745%\n",
      "Epoch [102/300], Step [9/23], Training Accuracy: 74.6528%, Training Loss: 0.3778%\n",
      "Epoch [102/300], Step [10/23], Training Accuracy: 75.0000%, Training Loss: 0.3761%\n",
      "Epoch [102/300], Step [11/23], Training Accuracy: 75.8523%, Training Loss: 0.3742%\n",
      "Epoch [102/300], Step [12/23], Training Accuracy: 75.6510%, Training Loss: 0.3747%\n",
      "Epoch [102/300], Step [13/23], Training Accuracy: 75.4808%, Training Loss: 0.3754%\n",
      "Epoch [102/300], Step [14/23], Training Accuracy: 75.2232%, Training Loss: 0.3763%\n",
      "Epoch [102/300], Step [15/23], Training Accuracy: 74.6875%, Training Loss: 0.3796%\n",
      "Epoch [102/300], Step [16/23], Training Accuracy: 74.7070%, Training Loss: 0.3800%\n",
      "Epoch [102/300], Step [17/23], Training Accuracy: 74.6324%, Training Loss: 0.3795%\n",
      "Epoch [102/300], Step [18/23], Training Accuracy: 74.3924%, Training Loss: 0.3808%\n",
      "Epoch [102/300], Step [19/23], Training Accuracy: 74.8355%, Training Loss: 0.3806%\n",
      "Epoch [102/300], Step [20/23], Training Accuracy: 74.7656%, Training Loss: 0.3800%\n",
      "Epoch [102/300], Step [21/23], Training Accuracy: 74.7768%, Training Loss: 0.3797%\n",
      "Epoch [102/300], Step [22/23], Training Accuracy: 74.6449%, Training Loss: 0.3794%\n",
      "Epoch [102/300], Step [23/23], Training Accuracy: 74.9131%, Training Loss: 0.3753%\n",
      "Epoch [103/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3543%\n",
      "Epoch [103/300], Step [2/23], Training Accuracy: 72.6562%, Training Loss: 0.3832%\n",
      "Epoch [103/300], Step [3/23], Training Accuracy: 69.2708%, Training Loss: 0.3890%\n",
      "Epoch [103/300], Step [4/23], Training Accuracy: 71.8750%, Training Loss: 0.3726%\n",
      "Epoch [103/300], Step [5/23], Training Accuracy: 71.5625%, Training Loss: 0.3739%\n",
      "Epoch [103/300], Step [6/23], Training Accuracy: 72.3958%, Training Loss: 0.3764%\n",
      "Epoch [103/300], Step [7/23], Training Accuracy: 72.7679%, Training Loss: 0.3811%\n",
      "Epoch [103/300], Step [8/23], Training Accuracy: 73.6328%, Training Loss: 0.3779%\n",
      "Epoch [103/300], Step [9/23], Training Accuracy: 72.5694%, Training Loss: 0.3846%\n",
      "Epoch [103/300], Step [10/23], Training Accuracy: 72.8125%, Training Loss: 0.3817%\n",
      "Epoch [103/300], Step [11/23], Training Accuracy: 73.0114%, Training Loss: 0.3797%\n",
      "Epoch [103/300], Step [12/23], Training Accuracy: 73.1771%, Training Loss: 0.3804%\n",
      "Epoch [103/300], Step [13/23], Training Accuracy: 73.1971%, Training Loss: 0.3820%\n",
      "Epoch [103/300], Step [14/23], Training Accuracy: 73.3259%, Training Loss: 0.3816%\n",
      "Epoch [103/300], Step [15/23], Training Accuracy: 73.0208%, Training Loss: 0.3850%\n",
      "Epoch [103/300], Step [16/23], Training Accuracy: 72.8516%, Training Loss: 0.3871%\n",
      "Epoch [103/300], Step [17/23], Training Accuracy: 73.1618%, Training Loss: 0.3852%\n",
      "Epoch [103/300], Step [18/23], Training Accuracy: 73.2639%, Training Loss: 0.3850%\n",
      "Epoch [103/300], Step [19/23], Training Accuracy: 73.5197%, Training Loss: 0.3842%\n",
      "Epoch [103/300], Step [20/23], Training Accuracy: 73.9844%, Training Loss: 0.3819%\n",
      "Epoch [103/300], Step [21/23], Training Accuracy: 73.8839%, Training Loss: 0.3822%\n",
      "Epoch [103/300], Step [22/23], Training Accuracy: 73.8636%, Training Loss: 0.3826%\n",
      "Epoch [103/300], Step [23/23], Training Accuracy: 74.0097%, Training Loss: 0.3791%\n",
      "Epoch [104/300], Step [1/23], Training Accuracy: 84.3750%, Training Loss: 0.3424%\n",
      "Epoch [104/300], Step [2/23], Training Accuracy: 78.1250%, Training Loss: 0.3817%\n",
      "Epoch [104/300], Step [3/23], Training Accuracy: 72.9167%, Training Loss: 0.3952%\n",
      "Epoch [104/300], Step [4/23], Training Accuracy: 74.2188%, Training Loss: 0.3812%\n",
      "Epoch [104/300], Step [5/23], Training Accuracy: 75.0000%, Training Loss: 0.3757%\n",
      "Epoch [104/300], Step [6/23], Training Accuracy: 75.2604%, Training Loss: 0.3772%\n",
      "Epoch [104/300], Step [7/23], Training Accuracy: 75.4464%, Training Loss: 0.3825%\n",
      "Epoch [104/300], Step [8/23], Training Accuracy: 76.1719%, Training Loss: 0.3831%\n",
      "Epoch [104/300], Step [9/23], Training Accuracy: 74.3056%, Training Loss: 0.3916%\n",
      "Epoch [104/300], Step [10/23], Training Accuracy: 74.3750%, Training Loss: 0.3881%\n",
      "Epoch [104/300], Step [11/23], Training Accuracy: 73.8636%, Training Loss: 0.3867%\n",
      "Epoch [104/300], Step [12/23], Training Accuracy: 73.4375%, Training Loss: 0.3882%\n",
      "Epoch [104/300], Step [13/23], Training Accuracy: 73.3173%, Training Loss: 0.3909%\n",
      "Epoch [104/300], Step [14/23], Training Accuracy: 73.5491%, Training Loss: 0.3910%\n",
      "Epoch [104/300], Step [15/23], Training Accuracy: 73.2292%, Training Loss: 0.3926%\n",
      "Epoch [104/300], Step [16/23], Training Accuracy: 73.5352%, Training Loss: 0.3913%\n",
      "Epoch [104/300], Step [17/23], Training Accuracy: 73.6213%, Training Loss: 0.3910%\n",
      "Epoch [104/300], Step [18/23], Training Accuracy: 73.6111%, Training Loss: 0.3918%\n",
      "Epoch [104/300], Step [19/23], Training Accuracy: 73.6020%, Training Loss: 0.3912%\n",
      "Epoch [104/300], Step [20/23], Training Accuracy: 73.9062%, Training Loss: 0.3890%\n",
      "Epoch [104/300], Step [21/23], Training Accuracy: 73.7351%, Training Loss: 0.3890%\n",
      "Epoch [104/300], Step [22/23], Training Accuracy: 73.6506%, Training Loss: 0.3881%\n",
      "Epoch [104/300], Step [23/23], Training Accuracy: 73.7318%, Training Loss: 0.3844%\n",
      "Epoch [105/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3547%\n",
      "Epoch [105/300], Step [2/23], Training Accuracy: 77.3438%, Training Loss: 0.3751%\n",
      "Epoch [105/300], Step [3/23], Training Accuracy: 72.9167%, Training Loss: 0.3847%\n",
      "Epoch [105/300], Step [4/23], Training Accuracy: 74.6094%, Training Loss: 0.3724%\n",
      "Epoch [105/300], Step [5/23], Training Accuracy: 73.1250%, Training Loss: 0.3778%\n",
      "Epoch [105/300], Step [6/23], Training Accuracy: 74.4792%, Training Loss: 0.3767%\n",
      "Epoch [105/300], Step [7/23], Training Accuracy: 75.2232%, Training Loss: 0.3765%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [105/300], Step [8/23], Training Accuracy: 75.5859%, Training Loss: 0.3766%\n",
      "Epoch [105/300], Step [9/23], Training Accuracy: 73.9583%, Training Loss: 0.3824%\n",
      "Epoch [105/300], Step [10/23], Training Accuracy: 73.7500%, Training Loss: 0.3818%\n",
      "Epoch [105/300], Step [11/23], Training Accuracy: 74.1477%, Training Loss: 0.3835%\n",
      "Epoch [105/300], Step [12/23], Training Accuracy: 74.2188%, Training Loss: 0.3837%\n",
      "Epoch [105/300], Step [13/23], Training Accuracy: 74.2788%, Training Loss: 0.3854%\n",
      "Epoch [105/300], Step [14/23], Training Accuracy: 74.6652%, Training Loss: 0.3845%\n",
      "Epoch [105/300], Step [15/23], Training Accuracy: 74.1667%, Training Loss: 0.3871%\n",
      "Epoch [105/300], Step [16/23], Training Accuracy: 74.4141%, Training Loss: 0.3871%\n",
      "Epoch [105/300], Step [17/23], Training Accuracy: 74.4485%, Training Loss: 0.3861%\n",
      "Epoch [105/300], Step [18/23], Training Accuracy: 74.2188%, Training Loss: 0.3872%\n",
      "Epoch [105/300], Step [19/23], Training Accuracy: 74.0954%, Training Loss: 0.3874%\n",
      "Epoch [105/300], Step [20/23], Training Accuracy: 74.2188%, Training Loss: 0.3872%\n",
      "Epoch [105/300], Step [21/23], Training Accuracy: 74.3304%, Training Loss: 0.3868%\n",
      "Epoch [105/300], Step [22/23], Training Accuracy: 74.5739%, Training Loss: 0.3856%\n",
      "Epoch [105/300], Step [23/23], Training Accuracy: 74.6352%, Training Loss: 0.3831%\n",
      "Epoch [106/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3605%\n",
      "Epoch [106/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.3896%\n",
      "Epoch [106/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.3920%\n",
      "Epoch [106/300], Step [4/23], Training Accuracy: 73.0469%, Training Loss: 0.3825%\n",
      "Epoch [106/300], Step [5/23], Training Accuracy: 73.4375%, Training Loss: 0.3834%\n",
      "Epoch [106/300], Step [6/23], Training Accuracy: 74.4792%, Training Loss: 0.3799%\n",
      "Epoch [106/300], Step [7/23], Training Accuracy: 74.7768%, Training Loss: 0.3819%\n",
      "Epoch [106/300], Step [8/23], Training Accuracy: 75.3906%, Training Loss: 0.3813%\n",
      "Epoch [106/300], Step [9/23], Training Accuracy: 74.4792%, Training Loss: 0.3863%\n",
      "Epoch [106/300], Step [10/23], Training Accuracy: 75.3125%, Training Loss: 0.3840%\n",
      "Epoch [106/300], Step [11/23], Training Accuracy: 75.1420%, Training Loss: 0.3836%\n",
      "Epoch [106/300], Step [12/23], Training Accuracy: 74.4792%, Training Loss: 0.3849%\n",
      "Epoch [106/300], Step [13/23], Training Accuracy: 74.1587%, Training Loss: 0.3855%\n",
      "Epoch [106/300], Step [14/23], Training Accuracy: 74.3304%, Training Loss: 0.3850%\n",
      "Epoch [106/300], Step [15/23], Training Accuracy: 73.7500%, Training Loss: 0.3889%\n",
      "Epoch [106/300], Step [16/23], Training Accuracy: 73.2422%, Training Loss: 0.3906%\n",
      "Epoch [106/300], Step [17/23], Training Accuracy: 73.3456%, Training Loss: 0.3906%\n",
      "Epoch [106/300], Step [18/23], Training Accuracy: 73.6111%, Training Loss: 0.3910%\n",
      "Epoch [106/300], Step [19/23], Training Accuracy: 73.6842%, Training Loss: 0.3905%\n",
      "Epoch [106/300], Step [20/23], Training Accuracy: 73.9062%, Training Loss: 0.3898%\n",
      "Epoch [106/300], Step [21/23], Training Accuracy: 74.0327%, Training Loss: 0.3894%\n",
      "Epoch [106/300], Step [22/23], Training Accuracy: 74.2188%, Training Loss: 0.3885%\n",
      "Epoch [106/300], Step [23/23], Training Accuracy: 74.3572%, Training Loss: 0.3854%\n",
      "Epoch [107/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3560%\n",
      "Epoch [107/300], Step [2/23], Training Accuracy: 77.3438%, Training Loss: 0.3927%\n",
      "Epoch [107/300], Step [3/23], Training Accuracy: 75.5208%, Training Loss: 0.3887%\n",
      "Epoch [107/300], Step [4/23], Training Accuracy: 78.1250%, Training Loss: 0.3693%\n",
      "Epoch [107/300], Step [5/23], Training Accuracy: 76.5625%, Training Loss: 0.3723%\n",
      "Epoch [107/300], Step [6/23], Training Accuracy: 77.3438%, Training Loss: 0.3729%\n",
      "Epoch [107/300], Step [7/23], Training Accuracy: 76.3393%, Training Loss: 0.3813%\n",
      "Epoch [107/300], Step [8/23], Training Accuracy: 75.9766%, Training Loss: 0.3830%\n",
      "Epoch [107/300], Step [9/23], Training Accuracy: 74.3056%, Training Loss: 0.3904%\n",
      "Epoch [107/300], Step [10/23], Training Accuracy: 73.9062%, Training Loss: 0.3874%\n",
      "Epoch [107/300], Step [11/23], Training Accuracy: 74.2898%, Training Loss: 0.3871%\n",
      "Epoch [107/300], Step [12/23], Training Accuracy: 74.3490%, Training Loss: 0.3866%\n",
      "Epoch [107/300], Step [13/23], Training Accuracy: 74.1587%, Training Loss: 0.3865%\n",
      "Epoch [107/300], Step [14/23], Training Accuracy: 74.1071%, Training Loss: 0.3839%\n",
      "Epoch [107/300], Step [15/23], Training Accuracy: 73.6458%, Training Loss: 0.3857%\n",
      "Epoch [107/300], Step [16/23], Training Accuracy: 73.8281%, Training Loss: 0.3868%\n",
      "Epoch [107/300], Step [17/23], Training Accuracy: 74.0809%, Training Loss: 0.3849%\n",
      "Epoch [107/300], Step [18/23], Training Accuracy: 73.6111%, Training Loss: 0.3867%\n",
      "Epoch [107/300], Step [19/23], Training Accuracy: 74.0132%, Training Loss: 0.3850%\n",
      "Epoch [107/300], Step [20/23], Training Accuracy: 73.9844%, Training Loss: 0.3846%\n",
      "Epoch [107/300], Step [21/23], Training Accuracy: 73.8839%, Training Loss: 0.3849%\n",
      "Epoch [107/300], Step [22/23], Training Accuracy: 73.7926%, Training Loss: 0.3845%\n",
      "Epoch [107/300], Step [23/23], Training Accuracy: 73.9402%, Training Loss: 0.3810%\n",
      "Epoch [108/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3942%\n",
      "Epoch [108/300], Step [2/23], Training Accuracy: 71.8750%, Training Loss: 0.4038%\n",
      "Epoch [108/300], Step [3/23], Training Accuracy: 68.7500%, Training Loss: 0.4095%\n",
      "Epoch [108/300], Step [4/23], Training Accuracy: 71.4844%, Training Loss: 0.3871%\n",
      "Epoch [108/300], Step [5/23], Training Accuracy: 71.5625%, Training Loss: 0.3818%\n",
      "Epoch [108/300], Step [6/23], Training Accuracy: 72.3958%, Training Loss: 0.3808%\n",
      "Epoch [108/300], Step [7/23], Training Accuracy: 71.8750%, Training Loss: 0.3867%\n",
      "Epoch [108/300], Step [8/23], Training Accuracy: 73.0469%, Training Loss: 0.3831%\n",
      "Epoch [108/300], Step [9/23], Training Accuracy: 72.0486%, Training Loss: 0.3895%\n",
      "Epoch [108/300], Step [10/23], Training Accuracy: 72.6562%, Training Loss: 0.3863%\n",
      "Epoch [108/300], Step [11/23], Training Accuracy: 72.7273%, Training Loss: 0.3859%\n",
      "Epoch [108/300], Step [12/23], Training Accuracy: 72.7865%, Training Loss: 0.3870%\n",
      "Epoch [108/300], Step [13/23], Training Accuracy: 72.2356%, Training Loss: 0.3870%\n",
      "Epoch [108/300], Step [14/23], Training Accuracy: 72.5446%, Training Loss: 0.3856%\n",
      "Epoch [108/300], Step [15/23], Training Accuracy: 72.3958%, Training Loss: 0.3880%\n",
      "Epoch [108/300], Step [16/23], Training Accuracy: 72.2656%, Training Loss: 0.3886%\n",
      "Epoch [108/300], Step [17/23], Training Accuracy: 72.5184%, Training Loss: 0.3878%\n",
      "Epoch [108/300], Step [18/23], Training Accuracy: 72.7431%, Training Loss: 0.3891%\n",
      "Epoch [108/300], Step [19/23], Training Accuracy: 72.9441%, Training Loss: 0.3882%\n",
      "Epoch [108/300], Step [20/23], Training Accuracy: 73.3594%, Training Loss: 0.3871%\n",
      "Epoch [108/300], Step [21/23], Training Accuracy: 73.4375%, Training Loss: 0.3863%\n",
      "Epoch [108/300], Step [22/23], Training Accuracy: 73.5085%, Training Loss: 0.3862%\n",
      "Epoch [108/300], Step [23/23], Training Accuracy: 73.6623%, Training Loss: 0.3828%\n",
      "Epoch [109/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3830%\n",
      "Epoch [109/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.4041%\n",
      "Epoch [109/300], Step [3/23], Training Accuracy: 75.0000%, Training Loss: 0.3998%\n",
      "Epoch [109/300], Step [4/23], Training Accuracy: 76.9531%, Training Loss: 0.3792%\n",
      "Epoch [109/300], Step [5/23], Training Accuracy: 76.8750%, Training Loss: 0.3786%\n",
      "Epoch [109/300], Step [6/23], Training Accuracy: 76.8229%, Training Loss: 0.3765%\n",
      "Epoch [109/300], Step [7/23], Training Accuracy: 76.3393%, Training Loss: 0.3811%\n",
      "Epoch [109/300], Step [8/23], Training Accuracy: 76.7578%, Training Loss: 0.3805%\n",
      "Epoch [109/300], Step [9/23], Training Accuracy: 76.0417%, Training Loss: 0.3834%\n",
      "Epoch [109/300], Step [10/23], Training Accuracy: 76.0938%, Training Loss: 0.3802%\n",
      "Epoch [109/300], Step [11/23], Training Accuracy: 76.1364%, Training Loss: 0.3798%\n",
      "Epoch [109/300], Step [12/23], Training Accuracy: 76.0417%, Training Loss: 0.3806%\n",
      "Epoch [109/300], Step [13/23], Training Accuracy: 75.2404%, Training Loss: 0.3842%\n",
      "Epoch [109/300], Step [14/23], Training Accuracy: 75.0000%, Training Loss: 0.3825%\n",
      "Epoch [109/300], Step [15/23], Training Accuracy: 74.8958%, Training Loss: 0.3854%\n",
      "Epoch [109/300], Step [16/23], Training Accuracy: 74.7070%, Training Loss: 0.3857%\n",
      "Epoch [109/300], Step [17/23], Training Accuracy: 75.0919%, Training Loss: 0.3850%\n",
      "Epoch [109/300], Step [18/23], Training Accuracy: 75.4340%, Training Loss: 0.3847%\n",
      "Epoch [109/300], Step [19/23], Training Accuracy: 75.3289%, Training Loss: 0.3852%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [109/300], Step [20/23], Training Accuracy: 75.4688%, Training Loss: 0.3835%\n",
      "Epoch [109/300], Step [21/23], Training Accuracy: 75.6696%, Training Loss: 0.3824%\n",
      "Epoch [109/300], Step [22/23], Training Accuracy: 75.5682%, Training Loss: 0.3824%\n",
      "Epoch [109/300], Step [23/23], Training Accuracy: 75.5386%, Training Loss: 0.3801%\n",
      "Epoch [110/300], Step [1/23], Training Accuracy: 82.8125%, Training Loss: 0.3850%\n",
      "Epoch [110/300], Step [2/23], Training Accuracy: 75.7812%, Training Loss: 0.4072%\n",
      "Epoch [110/300], Step [3/23], Training Accuracy: 75.0000%, Training Loss: 0.3982%\n",
      "Epoch [110/300], Step [4/23], Training Accuracy: 77.7344%, Training Loss: 0.3771%\n",
      "Epoch [110/300], Step [5/23], Training Accuracy: 75.6250%, Training Loss: 0.3773%\n",
      "Epoch [110/300], Step [6/23], Training Accuracy: 76.5625%, Training Loss: 0.3747%\n",
      "Epoch [110/300], Step [7/23], Training Accuracy: 76.1161%, Training Loss: 0.3804%\n",
      "Epoch [110/300], Step [8/23], Training Accuracy: 76.1719%, Training Loss: 0.3810%\n",
      "Epoch [110/300], Step [9/23], Training Accuracy: 74.6528%, Training Loss: 0.3878%\n",
      "Epoch [110/300], Step [10/23], Training Accuracy: 74.2188%, Training Loss: 0.3853%\n",
      "Epoch [110/300], Step [11/23], Training Accuracy: 74.7159%, Training Loss: 0.3835%\n",
      "Epoch [110/300], Step [12/23], Training Accuracy: 74.4792%, Training Loss: 0.3842%\n",
      "Epoch [110/300], Step [13/23], Training Accuracy: 74.6394%, Training Loss: 0.3855%\n",
      "Epoch [110/300], Step [14/23], Training Accuracy: 74.6652%, Training Loss: 0.3842%\n",
      "Epoch [110/300], Step [15/23], Training Accuracy: 74.2708%, Training Loss: 0.3890%\n",
      "Epoch [110/300], Step [16/23], Training Accuracy: 74.5117%, Training Loss: 0.3880%\n",
      "Epoch [110/300], Step [17/23], Training Accuracy: 74.6324%, Training Loss: 0.3866%\n",
      "Epoch [110/300], Step [18/23], Training Accuracy: 74.6528%, Training Loss: 0.3862%\n",
      "Epoch [110/300], Step [19/23], Training Accuracy: 75.0822%, Training Loss: 0.3844%\n",
      "Epoch [110/300], Step [20/23], Training Accuracy: 75.3125%, Training Loss: 0.3826%\n",
      "Epoch [110/300], Step [21/23], Training Accuracy: 75.3720%, Training Loss: 0.3825%\n",
      "Epoch [110/300], Step [22/23], Training Accuracy: 75.2131%, Training Loss: 0.3834%\n",
      "Epoch [110/300], Step [23/23], Training Accuracy: 75.4691%, Training Loss: 0.3805%\n",
      "Epoch [111/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3624%\n",
      "Epoch [111/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.3845%\n",
      "Epoch [111/300], Step [3/23], Training Accuracy: 72.9167%, Training Loss: 0.3849%\n",
      "Epoch [111/300], Step [4/23], Training Accuracy: 75.7812%, Training Loss: 0.3711%\n",
      "Epoch [111/300], Step [5/23], Training Accuracy: 75.6250%, Training Loss: 0.3709%\n",
      "Epoch [111/300], Step [6/23], Training Accuracy: 75.7812%, Training Loss: 0.3713%\n",
      "Epoch [111/300], Step [7/23], Training Accuracy: 75.2232%, Training Loss: 0.3783%\n",
      "Epoch [111/300], Step [8/23], Training Accuracy: 76.5625%, Training Loss: 0.3742%\n",
      "Epoch [111/300], Step [9/23], Training Accuracy: 74.6528%, Training Loss: 0.3812%\n",
      "Epoch [111/300], Step [10/23], Training Accuracy: 75.1562%, Training Loss: 0.3801%\n",
      "Epoch [111/300], Step [11/23], Training Accuracy: 74.7159%, Training Loss: 0.3816%\n",
      "Epoch [111/300], Step [12/23], Training Accuracy: 74.8698%, Training Loss: 0.3827%\n",
      "Epoch [111/300], Step [13/23], Training Accuracy: 74.2788%, Training Loss: 0.3864%\n",
      "Epoch [111/300], Step [14/23], Training Accuracy: 74.3304%, Training Loss: 0.3838%\n",
      "Epoch [111/300], Step [15/23], Training Accuracy: 74.2708%, Training Loss: 0.3872%\n",
      "Epoch [111/300], Step [16/23], Training Accuracy: 74.5117%, Training Loss: 0.3871%\n",
      "Epoch [111/300], Step [17/23], Training Accuracy: 74.8162%, Training Loss: 0.3860%\n",
      "Epoch [111/300], Step [18/23], Training Accuracy: 74.6528%, Training Loss: 0.3863%\n",
      "Epoch [111/300], Step [19/23], Training Accuracy: 74.5888%, Training Loss: 0.3862%\n",
      "Epoch [111/300], Step [20/23], Training Accuracy: 74.7656%, Training Loss: 0.3850%\n",
      "Epoch [111/300], Step [21/23], Training Accuracy: 74.3304%, Training Loss: 0.3868%\n",
      "Epoch [111/300], Step [22/23], Training Accuracy: 74.7159%, Training Loss: 0.3853%\n",
      "Epoch [111/300], Step [23/23], Training Accuracy: 74.9826%, Training Loss: 0.3818%\n",
      "Epoch [112/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3543%\n",
      "Epoch [112/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.3929%\n",
      "Epoch [112/300], Step [3/23], Training Accuracy: 73.4375%, Training Loss: 0.3978%\n",
      "Epoch [112/300], Step [4/23], Training Accuracy: 75.3906%, Training Loss: 0.3839%\n",
      "Epoch [112/300], Step [5/23], Training Accuracy: 76.5625%, Training Loss: 0.3808%\n",
      "Epoch [112/300], Step [6/23], Training Accuracy: 77.3438%, Training Loss: 0.3766%\n",
      "Epoch [112/300], Step [7/23], Training Accuracy: 76.5625%, Training Loss: 0.3823%\n",
      "Epoch [112/300], Step [8/23], Training Accuracy: 77.7344%, Training Loss: 0.3791%\n",
      "Epoch [112/300], Step [9/23], Training Accuracy: 76.0417%, Training Loss: 0.3828%\n",
      "Epoch [112/300], Step [10/23], Training Accuracy: 75.9375%, Training Loss: 0.3820%\n",
      "Epoch [112/300], Step [11/23], Training Accuracy: 75.4261%, Training Loss: 0.3841%\n",
      "Epoch [112/300], Step [12/23], Training Accuracy: 75.5208%, Training Loss: 0.3855%\n",
      "Epoch [112/300], Step [13/23], Training Accuracy: 75.0000%, Training Loss: 0.3874%\n",
      "Epoch [112/300], Step [14/23], Training Accuracy: 74.8884%, Training Loss: 0.3872%\n",
      "Epoch [112/300], Step [15/23], Training Accuracy: 74.4792%, Training Loss: 0.3915%\n",
      "Epoch [112/300], Step [16/23], Training Accuracy: 74.4141%, Training Loss: 0.3926%\n",
      "Epoch [112/300], Step [17/23], Training Accuracy: 74.3566%, Training Loss: 0.3932%\n",
      "Epoch [112/300], Step [18/23], Training Accuracy: 74.2188%, Training Loss: 0.3953%\n",
      "Epoch [112/300], Step [19/23], Training Accuracy: 74.0954%, Training Loss: 0.3959%\n",
      "Epoch [112/300], Step [20/23], Training Accuracy: 73.9844%, Training Loss: 0.3956%\n",
      "Epoch [112/300], Step [21/23], Training Accuracy: 73.8095%, Training Loss: 0.3958%\n",
      "Epoch [112/300], Step [22/23], Training Accuracy: 74.2898%, Training Loss: 0.3936%\n",
      "Epoch [112/300], Step [23/23], Training Accuracy: 74.3572%, Training Loss: 0.3912%\n",
      "Epoch [113/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3738%\n",
      "Epoch [113/300], Step [2/23], Training Accuracy: 75.7812%, Training Loss: 0.3943%\n",
      "Epoch [113/300], Step [3/23], Training Accuracy: 73.9583%, Training Loss: 0.3931%\n",
      "Epoch [113/300], Step [4/23], Training Accuracy: 76.1719%, Training Loss: 0.3779%\n",
      "Epoch [113/300], Step [5/23], Training Accuracy: 75.3125%, Training Loss: 0.3790%\n",
      "Epoch [113/300], Step [6/23], Training Accuracy: 74.7396%, Training Loss: 0.3782%\n",
      "Epoch [113/300], Step [7/23], Training Accuracy: 74.7768%, Training Loss: 0.3857%\n",
      "Epoch [113/300], Step [8/23], Training Accuracy: 75.7812%, Training Loss: 0.3841%\n",
      "Epoch [113/300], Step [9/23], Training Accuracy: 74.3056%, Training Loss: 0.3919%\n",
      "Epoch [113/300], Step [10/23], Training Accuracy: 74.3750%, Training Loss: 0.3907%\n",
      "Epoch [113/300], Step [11/23], Training Accuracy: 74.7159%, Training Loss: 0.3895%\n",
      "Epoch [113/300], Step [12/23], Training Accuracy: 74.2188%, Training Loss: 0.3919%\n",
      "Epoch [113/300], Step [13/23], Training Accuracy: 73.7981%, Training Loss: 0.3932%\n",
      "Epoch [113/300], Step [14/23], Training Accuracy: 73.6607%, Training Loss: 0.3921%\n",
      "Epoch [113/300], Step [15/23], Training Accuracy: 73.1250%, Training Loss: 0.3963%\n",
      "Epoch [113/300], Step [16/23], Training Accuracy: 72.7539%, Training Loss: 0.3956%\n",
      "Epoch [113/300], Step [17/23], Training Accuracy: 73.0699%, Training Loss: 0.3945%\n",
      "Epoch [113/300], Step [18/23], Training Accuracy: 73.0903%, Training Loss: 0.3942%\n",
      "Epoch [113/300], Step [19/23], Training Accuracy: 73.5197%, Training Loss: 0.3928%\n",
      "Epoch [113/300], Step [20/23], Training Accuracy: 73.7500%, Training Loss: 0.3904%\n",
      "Epoch [113/300], Step [21/23], Training Accuracy: 73.5119%, Training Loss: 0.3899%\n",
      "Epoch [113/300], Step [22/23], Training Accuracy: 73.5795%, Training Loss: 0.3875%\n",
      "Epoch [113/300], Step [23/23], Training Accuracy: 73.7318%, Training Loss: 0.3836%\n",
      "Epoch [114/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3701%\n",
      "Epoch [114/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.3919%\n",
      "Epoch [114/300], Step [3/23], Training Accuracy: 71.3542%, Training Loss: 0.3929%\n",
      "Epoch [114/300], Step [4/23], Training Accuracy: 73.4375%, Training Loss: 0.3762%\n",
      "Epoch [114/300], Step [5/23], Training Accuracy: 72.8125%, Training Loss: 0.3770%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [114/300], Step [6/23], Training Accuracy: 73.9583%, Training Loss: 0.3803%\n",
      "Epoch [114/300], Step [7/23], Training Accuracy: 73.6607%, Training Loss: 0.3879%\n",
      "Epoch [114/300], Step [8/23], Training Accuracy: 75.0000%, Training Loss: 0.3834%\n",
      "Epoch [114/300], Step [9/23], Training Accuracy: 74.1319%, Training Loss: 0.3904%\n",
      "Epoch [114/300], Step [10/23], Training Accuracy: 73.7500%, Training Loss: 0.3888%\n",
      "Epoch [114/300], Step [11/23], Training Accuracy: 74.2898%, Training Loss: 0.3876%\n",
      "Epoch [114/300], Step [12/23], Training Accuracy: 73.8281%, Training Loss: 0.3886%\n",
      "Epoch [114/300], Step [13/23], Training Accuracy: 73.1971%, Training Loss: 0.3916%\n",
      "Epoch [114/300], Step [14/23], Training Accuracy: 73.2143%, Training Loss: 0.3921%\n",
      "Epoch [114/300], Step [15/23], Training Accuracy: 72.3958%, Training Loss: 0.3968%\n",
      "Epoch [114/300], Step [16/23], Training Accuracy: 72.3633%, Training Loss: 0.3955%\n",
      "Epoch [114/300], Step [17/23], Training Accuracy: 72.2426%, Training Loss: 0.3950%\n",
      "Epoch [114/300], Step [18/23], Training Accuracy: 72.4826%, Training Loss: 0.3939%\n",
      "Epoch [114/300], Step [19/23], Training Accuracy: 72.6974%, Training Loss: 0.3936%\n",
      "Epoch [114/300], Step [20/23], Training Accuracy: 72.8906%, Training Loss: 0.3925%\n",
      "Epoch [114/300], Step [21/23], Training Accuracy: 73.0655%, Training Loss: 0.3920%\n",
      "Epoch [114/300], Step [22/23], Training Accuracy: 73.0824%, Training Loss: 0.3910%\n",
      "Epoch [114/300], Step [23/23], Training Accuracy: 73.1758%, Training Loss: 0.3870%\n",
      "Epoch [115/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3564%\n",
      "Epoch [115/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.3985%\n",
      "Epoch [115/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.4069%\n",
      "Epoch [115/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.3922%\n",
      "Epoch [115/300], Step [5/23], Training Accuracy: 72.5000%, Training Loss: 0.3899%\n",
      "Epoch [115/300], Step [6/23], Training Accuracy: 74.4792%, Training Loss: 0.3856%\n",
      "Epoch [115/300], Step [7/23], Training Accuracy: 75.0000%, Training Loss: 0.3877%\n",
      "Epoch [115/300], Step [8/23], Training Accuracy: 75.3906%, Training Loss: 0.3856%\n",
      "Epoch [115/300], Step [9/23], Training Accuracy: 74.3056%, Training Loss: 0.3918%\n",
      "Epoch [115/300], Step [10/23], Training Accuracy: 74.5312%, Training Loss: 0.3889%\n",
      "Epoch [115/300], Step [11/23], Training Accuracy: 75.0000%, Training Loss: 0.3863%\n",
      "Epoch [115/300], Step [12/23], Training Accuracy: 75.2604%, Training Loss: 0.3850%\n",
      "Epoch [115/300], Step [13/23], Training Accuracy: 74.7596%, Training Loss: 0.3877%\n",
      "Epoch [115/300], Step [14/23], Training Accuracy: 74.7768%, Training Loss: 0.3880%\n",
      "Epoch [115/300], Step [15/23], Training Accuracy: 74.5833%, Training Loss: 0.3895%\n",
      "Epoch [115/300], Step [16/23], Training Accuracy: 74.4141%, Training Loss: 0.3906%\n",
      "Epoch [115/300], Step [17/23], Training Accuracy: 74.5404%, Training Loss: 0.3888%\n",
      "Epoch [115/300], Step [18/23], Training Accuracy: 74.5660%, Training Loss: 0.3882%\n",
      "Epoch [115/300], Step [19/23], Training Accuracy: 74.5888%, Training Loss: 0.3872%\n",
      "Epoch [115/300], Step [20/23], Training Accuracy: 74.6094%, Training Loss: 0.3858%\n",
      "Epoch [115/300], Step [21/23], Training Accuracy: 74.9256%, Training Loss: 0.3850%\n",
      "Epoch [115/300], Step [22/23], Training Accuracy: 74.7159%, Training Loss: 0.3860%\n",
      "Epoch [115/300], Step [23/23], Training Accuracy: 74.8436%, Training Loss: 0.3830%\n",
      "Epoch [116/300], Step [1/23], Training Accuracy: 71.8750%, Training Loss: 0.4032%\n",
      "Epoch [116/300], Step [2/23], Training Accuracy: 71.8750%, Training Loss: 0.4052%\n",
      "Epoch [116/300], Step [3/23], Training Accuracy: 71.3542%, Training Loss: 0.4069%\n",
      "Epoch [116/300], Step [4/23], Training Accuracy: 73.4375%, Training Loss: 0.3909%\n",
      "Epoch [116/300], Step [5/23], Training Accuracy: 73.7500%, Training Loss: 0.3861%\n",
      "Epoch [116/300], Step [6/23], Training Accuracy: 74.7396%, Training Loss: 0.3843%\n",
      "Epoch [116/300], Step [7/23], Training Accuracy: 73.8839%, Training Loss: 0.3929%\n",
      "Epoch [116/300], Step [8/23], Training Accuracy: 74.4141%, Training Loss: 0.3931%\n",
      "Epoch [116/300], Step [9/23], Training Accuracy: 73.4375%, Training Loss: 0.3959%\n",
      "Epoch [116/300], Step [10/23], Training Accuracy: 73.5938%, Training Loss: 0.3940%\n",
      "Epoch [116/300], Step [11/23], Training Accuracy: 74.0057%, Training Loss: 0.3924%\n",
      "Epoch [116/300], Step [12/23], Training Accuracy: 73.6979%, Training Loss: 0.3919%\n",
      "Epoch [116/300], Step [13/23], Training Accuracy: 73.9183%, Training Loss: 0.3941%\n",
      "Epoch [116/300], Step [14/23], Training Accuracy: 74.2188%, Training Loss: 0.3931%\n",
      "Epoch [116/300], Step [15/23], Training Accuracy: 73.6458%, Training Loss: 0.3980%\n",
      "Epoch [116/300], Step [16/23], Training Accuracy: 73.2422%, Training Loss: 0.3985%\n",
      "Epoch [116/300], Step [17/23], Training Accuracy: 72.9779%, Training Loss: 0.3975%\n",
      "Epoch [116/300], Step [18/23], Training Accuracy: 72.7431%, Training Loss: 0.3977%\n",
      "Epoch [116/300], Step [19/23], Training Accuracy: 72.9441%, Training Loss: 0.3963%\n",
      "Epoch [116/300], Step [20/23], Training Accuracy: 73.3594%, Training Loss: 0.3960%\n",
      "Epoch [116/300], Step [21/23], Training Accuracy: 73.2887%, Training Loss: 0.3960%\n",
      "Epoch [116/300], Step [22/23], Training Accuracy: 73.5085%, Training Loss: 0.3944%\n",
      "Epoch [116/300], Step [23/23], Training Accuracy: 73.6623%, Training Loss: 0.3914%\n",
      "Epoch [117/300], Step [1/23], Training Accuracy: 81.2500%, Training Loss: 0.3580%\n",
      "Epoch [117/300], Step [2/23], Training Accuracy: 79.6875%, Training Loss: 0.3831%\n",
      "Epoch [117/300], Step [3/23], Training Accuracy: 76.5625%, Training Loss: 0.3871%\n",
      "Epoch [117/300], Step [4/23], Training Accuracy: 79.6875%, Training Loss: 0.3680%\n",
      "Epoch [117/300], Step [5/23], Training Accuracy: 78.7500%, Training Loss: 0.3687%\n",
      "Epoch [117/300], Step [6/23], Training Accuracy: 79.4271%, Training Loss: 0.3683%\n",
      "Epoch [117/300], Step [7/23], Training Accuracy: 78.5714%, Training Loss: 0.3762%\n",
      "Epoch [117/300], Step [8/23], Training Accuracy: 78.3203%, Training Loss: 0.3790%\n",
      "Epoch [117/300], Step [9/23], Training Accuracy: 76.9097%, Training Loss: 0.3865%\n",
      "Epoch [117/300], Step [10/23], Training Accuracy: 76.7188%, Training Loss: 0.3877%\n",
      "Epoch [117/300], Step [11/23], Training Accuracy: 76.7045%, Training Loss: 0.3875%\n",
      "Epoch [117/300], Step [12/23], Training Accuracy: 76.4323%, Training Loss: 0.3875%\n",
      "Epoch [117/300], Step [13/23], Training Accuracy: 75.2404%, Training Loss: 0.3901%\n",
      "Epoch [117/300], Step [14/23], Training Accuracy: 75.5580%, Training Loss: 0.3878%\n",
      "Epoch [117/300], Step [15/23], Training Accuracy: 75.3125%, Training Loss: 0.3902%\n",
      "Epoch [117/300], Step [16/23], Training Accuracy: 74.9023%, Training Loss: 0.3916%\n",
      "Epoch [117/300], Step [17/23], Training Accuracy: 75.0000%, Training Loss: 0.3911%\n",
      "Epoch [117/300], Step [18/23], Training Accuracy: 75.0000%, Training Loss: 0.3905%\n",
      "Epoch [117/300], Step [19/23], Training Accuracy: 75.2467%, Training Loss: 0.3881%\n",
      "Epoch [117/300], Step [20/23], Training Accuracy: 75.3906%, Training Loss: 0.3874%\n",
      "Epoch [117/300], Step [21/23], Training Accuracy: 75.4464%, Training Loss: 0.3877%\n",
      "Epoch [117/300], Step [22/23], Training Accuracy: 75.6392%, Training Loss: 0.3868%\n",
      "Epoch [117/300], Step [23/23], Training Accuracy: 75.7470%, Training Loss: 0.3833%\n",
      "Epoch [118/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3544%\n",
      "Epoch [118/300], Step [2/23], Training Accuracy: 75.7812%, Training Loss: 0.3828%\n",
      "Epoch [118/300], Step [3/23], Training Accuracy: 73.4375%, Training Loss: 0.3927%\n",
      "Epoch [118/300], Step [4/23], Training Accuracy: 75.0000%, Training Loss: 0.3772%\n",
      "Epoch [118/300], Step [5/23], Training Accuracy: 74.3750%, Training Loss: 0.3778%\n",
      "Epoch [118/300], Step [6/23], Training Accuracy: 75.2604%, Training Loss: 0.3789%\n",
      "Epoch [118/300], Step [7/23], Training Accuracy: 75.0000%, Training Loss: 0.3820%\n",
      "Epoch [118/300], Step [8/23], Training Accuracy: 75.3906%, Training Loss: 0.3846%\n",
      "Epoch [118/300], Step [9/23], Training Accuracy: 74.1319%, Training Loss: 0.3912%\n",
      "Epoch [118/300], Step [10/23], Training Accuracy: 74.2188%, Training Loss: 0.3899%\n",
      "Epoch [118/300], Step [11/23], Training Accuracy: 74.8580%, Training Loss: 0.3873%\n",
      "Epoch [118/300], Step [12/23], Training Accuracy: 74.3490%, Training Loss: 0.3880%\n",
      "Epoch [118/300], Step [13/23], Training Accuracy: 74.2788%, Training Loss: 0.3902%\n",
      "Epoch [118/300], Step [14/23], Training Accuracy: 74.4420%, Training Loss: 0.3884%\n",
      "Epoch [118/300], Step [15/23], Training Accuracy: 73.9583%, Training Loss: 0.3915%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [118/300], Step [16/23], Training Accuracy: 73.1445%, Training Loss: 0.3913%\n",
      "Epoch [118/300], Step [17/23], Training Accuracy: 73.4375%, Training Loss: 0.3902%\n",
      "Epoch [118/300], Step [18/23], Training Accuracy: 73.6979%, Training Loss: 0.3906%\n",
      "Epoch [118/300], Step [19/23], Training Accuracy: 73.8487%, Training Loss: 0.3910%\n",
      "Epoch [118/300], Step [20/23], Training Accuracy: 74.2188%, Training Loss: 0.3887%\n",
      "Epoch [118/300], Step [21/23], Training Accuracy: 74.4048%, Training Loss: 0.3888%\n",
      "Epoch [118/300], Step [22/23], Training Accuracy: 74.2188%, Training Loss: 0.3886%\n",
      "Epoch [118/300], Step [23/23], Training Accuracy: 74.2182%, Training Loss: 0.3869%\n",
      "Epoch [119/300], Step [1/23], Training Accuracy: 71.8750%, Training Loss: 0.3697%\n",
      "Epoch [119/300], Step [2/23], Training Accuracy: 71.8750%, Training Loss: 0.4039%\n",
      "Epoch [119/300], Step [3/23], Training Accuracy: 70.8333%, Training Loss: 0.4061%\n",
      "Epoch [119/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.3826%\n",
      "Epoch [119/300], Step [5/23], Training Accuracy: 73.1250%, Training Loss: 0.3821%\n",
      "Epoch [119/300], Step [6/23], Training Accuracy: 73.6979%, Training Loss: 0.3813%\n",
      "Epoch [119/300], Step [7/23], Training Accuracy: 73.4375%, Training Loss: 0.3871%\n",
      "Epoch [119/300], Step [8/23], Training Accuracy: 73.8281%, Training Loss: 0.3865%\n",
      "Epoch [119/300], Step [9/23], Training Accuracy: 72.9167%, Training Loss: 0.3909%\n",
      "Epoch [119/300], Step [10/23], Training Accuracy: 73.9062%, Training Loss: 0.3891%\n",
      "Epoch [119/300], Step [11/23], Training Accuracy: 74.7159%, Training Loss: 0.3883%\n",
      "Epoch [119/300], Step [12/23], Training Accuracy: 74.7396%, Training Loss: 0.3893%\n",
      "Epoch [119/300], Step [13/23], Training Accuracy: 74.3990%, Training Loss: 0.3915%\n",
      "Epoch [119/300], Step [14/23], Training Accuracy: 74.8884%, Training Loss: 0.3889%\n",
      "Epoch [119/300], Step [15/23], Training Accuracy: 75.1042%, Training Loss: 0.3900%\n",
      "Epoch [119/300], Step [16/23], Training Accuracy: 75.0000%, Training Loss: 0.3902%\n",
      "Epoch [119/300], Step [17/23], Training Accuracy: 74.9081%, Training Loss: 0.3907%\n",
      "Epoch [119/300], Step [18/23], Training Accuracy: 75.0000%, Training Loss: 0.3910%\n",
      "Epoch [119/300], Step [19/23], Training Accuracy: 75.0822%, Training Loss: 0.3908%\n",
      "Epoch [119/300], Step [20/23], Training Accuracy: 75.0000%, Training Loss: 0.3886%\n",
      "Epoch [119/300], Step [21/23], Training Accuracy: 75.1488%, Training Loss: 0.3888%\n",
      "Epoch [119/300], Step [22/23], Training Accuracy: 75.1420%, Training Loss: 0.3884%\n",
      "Epoch [119/300], Step [23/23], Training Accuracy: 75.2606%, Training Loss: 0.3852%\n",
      "Epoch [120/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3887%\n",
      "Epoch [120/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.4044%\n",
      "Epoch [120/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.4091%\n",
      "Epoch [120/300], Step [4/23], Training Accuracy: 74.6094%, Training Loss: 0.3890%\n",
      "Epoch [120/300], Step [5/23], Training Accuracy: 74.0625%, Training Loss: 0.3862%\n",
      "Epoch [120/300], Step [6/23], Training Accuracy: 75.0000%, Training Loss: 0.3795%\n",
      "Epoch [120/300], Step [7/23], Training Accuracy: 74.1071%, Training Loss: 0.3879%\n",
      "Epoch [120/300], Step [8/23], Training Accuracy: 74.4141%, Training Loss: 0.3896%\n",
      "Epoch [120/300], Step [9/23], Training Accuracy: 72.9167%, Training Loss: 0.3975%\n",
      "Epoch [120/300], Step [10/23], Training Accuracy: 73.5938%, Training Loss: 0.3931%\n",
      "Epoch [120/300], Step [11/23], Training Accuracy: 73.8636%, Training Loss: 0.3921%\n",
      "Epoch [120/300], Step [12/23], Training Accuracy: 74.0885%, Training Loss: 0.3901%\n",
      "Epoch [120/300], Step [13/23], Training Accuracy: 73.9183%, Training Loss: 0.3908%\n",
      "Epoch [120/300], Step [14/23], Training Accuracy: 73.7723%, Training Loss: 0.3911%\n",
      "Epoch [120/300], Step [15/23], Training Accuracy: 73.8542%, Training Loss: 0.3943%\n",
      "Epoch [120/300], Step [16/23], Training Accuracy: 73.7305%, Training Loss: 0.3938%\n",
      "Epoch [120/300], Step [17/23], Training Accuracy: 73.8051%, Training Loss: 0.3926%\n",
      "Epoch [120/300], Step [18/23], Training Accuracy: 74.3056%, Training Loss: 0.3915%\n",
      "Epoch [120/300], Step [19/23], Training Accuracy: 74.3421%, Training Loss: 0.3908%\n",
      "Epoch [120/300], Step [20/23], Training Accuracy: 74.3750%, Training Loss: 0.3894%\n",
      "Epoch [120/300], Step [21/23], Training Accuracy: 74.3304%, Training Loss: 0.3892%\n",
      "Epoch [120/300], Step [22/23], Training Accuracy: 74.5739%, Training Loss: 0.3866%\n",
      "Epoch [120/300], Step [23/23], Training Accuracy: 74.7047%, Training Loss: 0.3834%\n",
      "Epoch [121/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3636%\n",
      "Epoch [121/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.3912%\n",
      "Epoch [121/300], Step [3/23], Training Accuracy: 73.4375%, Training Loss: 0.4000%\n",
      "Epoch [121/300], Step [4/23], Training Accuracy: 76.1719%, Training Loss: 0.3842%\n",
      "Epoch [121/300], Step [5/23], Training Accuracy: 75.0000%, Training Loss: 0.3843%\n",
      "Epoch [121/300], Step [6/23], Training Accuracy: 75.5208%, Training Loss: 0.3811%\n",
      "Epoch [121/300], Step [7/23], Training Accuracy: 75.6696%, Training Loss: 0.3874%\n",
      "Epoch [121/300], Step [8/23], Training Accuracy: 76.1719%, Training Loss: 0.3888%\n",
      "Epoch [121/300], Step [9/23], Training Accuracy: 75.0000%, Training Loss: 0.3917%\n",
      "Epoch [121/300], Step [10/23], Training Accuracy: 74.5312%, Training Loss: 0.3902%\n",
      "Epoch [121/300], Step [11/23], Training Accuracy: 74.7159%, Training Loss: 0.3889%\n",
      "Epoch [121/300], Step [12/23], Training Accuracy: 75.1302%, Training Loss: 0.3897%\n",
      "Epoch [121/300], Step [13/23], Training Accuracy: 74.5192%, Training Loss: 0.3916%\n",
      "Epoch [121/300], Step [14/23], Training Accuracy: 75.1116%, Training Loss: 0.3894%\n",
      "Epoch [121/300], Step [15/23], Training Accuracy: 74.7917%, Training Loss: 0.3938%\n",
      "Epoch [121/300], Step [16/23], Training Accuracy: 74.3164%, Training Loss: 0.3947%\n",
      "Epoch [121/300], Step [17/23], Training Accuracy: 74.1728%, Training Loss: 0.3950%\n",
      "Epoch [121/300], Step [18/23], Training Accuracy: 73.9583%, Training Loss: 0.3950%\n",
      "Epoch [121/300], Step [19/23], Training Accuracy: 74.0954%, Training Loss: 0.3945%\n",
      "Epoch [121/300], Step [20/23], Training Accuracy: 74.4531%, Training Loss: 0.3928%\n",
      "Epoch [121/300], Step [21/23], Training Accuracy: 74.3304%, Training Loss: 0.3920%\n",
      "Epoch [121/300], Step [22/23], Training Accuracy: 74.5739%, Training Loss: 0.3912%\n",
      "Epoch [121/300], Step [23/23], Training Accuracy: 74.6352%, Training Loss: 0.3882%\n",
      "Epoch [122/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3717%\n",
      "Epoch [122/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3978%\n",
      "Epoch [122/300], Step [3/23], Training Accuracy: 73.9583%, Training Loss: 0.3976%\n",
      "Epoch [122/300], Step [4/23], Training Accuracy: 75.7812%, Training Loss: 0.3797%\n",
      "Epoch [122/300], Step [5/23], Training Accuracy: 74.0625%, Training Loss: 0.3809%\n",
      "Epoch [122/300], Step [6/23], Training Accuracy: 73.9583%, Training Loss: 0.3807%\n",
      "Epoch [122/300], Step [7/23], Training Accuracy: 74.1071%, Training Loss: 0.3843%\n",
      "Epoch [122/300], Step [8/23], Training Accuracy: 74.4141%, Training Loss: 0.3830%\n",
      "Epoch [122/300], Step [9/23], Training Accuracy: 73.4375%, Training Loss: 0.3880%\n",
      "Epoch [122/300], Step [10/23], Training Accuracy: 73.1250%, Training Loss: 0.3895%\n",
      "Epoch [122/300], Step [11/23], Training Accuracy: 73.4375%, Training Loss: 0.3887%\n",
      "Epoch [122/300], Step [12/23], Training Accuracy: 73.8281%, Training Loss: 0.3882%\n",
      "Epoch [122/300], Step [13/23], Training Accuracy: 73.5577%, Training Loss: 0.3892%\n",
      "Epoch [122/300], Step [14/23], Training Accuracy: 73.4375%, Training Loss: 0.3894%\n",
      "Epoch [122/300], Step [15/23], Training Accuracy: 73.1250%, Training Loss: 0.3928%\n",
      "Epoch [122/300], Step [16/23], Training Accuracy: 72.9492%, Training Loss: 0.3935%\n",
      "Epoch [122/300], Step [17/23], Training Accuracy: 72.9779%, Training Loss: 0.3935%\n",
      "Epoch [122/300], Step [18/23], Training Accuracy: 73.0903%, Training Loss: 0.3931%\n",
      "Epoch [122/300], Step [19/23], Training Accuracy: 73.3553%, Training Loss: 0.3927%\n",
      "Epoch [122/300], Step [20/23], Training Accuracy: 73.4375%, Training Loss: 0.3906%\n",
      "Epoch [122/300], Step [21/23], Training Accuracy: 73.5119%, Training Loss: 0.3903%\n",
      "Epoch [122/300], Step [22/23], Training Accuracy: 73.4375%, Training Loss: 0.3887%\n",
      "Epoch [122/300], Step [23/23], Training Accuracy: 73.4538%, Training Loss: 0.3858%\n",
      "Epoch [123/300], Step [1/23], Training Accuracy: 70.3125%, Training Loss: 0.3658%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [123/300], Step [2/23], Training Accuracy: 70.3125%, Training Loss: 0.3916%\n",
      "Epoch [123/300], Step [3/23], Training Accuracy: 69.2708%, Training Loss: 0.3955%\n",
      "Epoch [123/300], Step [4/23], Training Accuracy: 71.8750%, Training Loss: 0.3828%\n",
      "Epoch [123/300], Step [5/23], Training Accuracy: 73.1250%, Training Loss: 0.3767%\n",
      "Epoch [123/300], Step [6/23], Training Accuracy: 73.6979%, Training Loss: 0.3791%\n",
      "Epoch [123/300], Step [7/23], Training Accuracy: 72.7679%, Training Loss: 0.3848%\n",
      "Epoch [123/300], Step [8/23], Training Accuracy: 73.6328%, Training Loss: 0.3829%\n",
      "Epoch [123/300], Step [9/23], Training Accuracy: 71.8750%, Training Loss: 0.3931%\n",
      "Epoch [123/300], Step [10/23], Training Accuracy: 72.1875%, Training Loss: 0.3917%\n",
      "Epoch [123/300], Step [11/23], Training Accuracy: 72.3011%, Training Loss: 0.3925%\n",
      "Epoch [123/300], Step [12/23], Training Accuracy: 72.5260%, Training Loss: 0.3923%\n",
      "Epoch [123/300], Step [13/23], Training Accuracy: 73.1971%, Training Loss: 0.3905%\n",
      "Epoch [123/300], Step [14/23], Training Accuracy: 73.3259%, Training Loss: 0.3894%\n",
      "Epoch [123/300], Step [15/23], Training Accuracy: 73.1250%, Training Loss: 0.3944%\n",
      "Epoch [123/300], Step [16/23], Training Accuracy: 72.9492%, Training Loss: 0.3941%\n",
      "Epoch [123/300], Step [17/23], Training Accuracy: 73.2537%, Training Loss: 0.3920%\n",
      "Epoch [123/300], Step [18/23], Training Accuracy: 73.6111%, Training Loss: 0.3916%\n",
      "Epoch [123/300], Step [19/23], Training Accuracy: 73.7664%, Training Loss: 0.3906%\n",
      "Epoch [123/300], Step [20/23], Training Accuracy: 74.2188%, Training Loss: 0.3890%\n",
      "Epoch [123/300], Step [21/23], Training Accuracy: 74.0327%, Training Loss: 0.3893%\n",
      "Epoch [123/300], Step [22/23], Training Accuracy: 74.3608%, Training Loss: 0.3886%\n",
      "Epoch [123/300], Step [23/23], Training Accuracy: 74.4267%, Training Loss: 0.3854%\n",
      "Epoch [124/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3802%\n",
      "Epoch [124/300], Step [2/23], Training Accuracy: 78.1250%, Training Loss: 0.3902%\n",
      "Epoch [124/300], Step [3/23], Training Accuracy: 75.5208%, Training Loss: 0.3940%\n",
      "Epoch [124/300], Step [4/23], Training Accuracy: 78.9062%, Training Loss: 0.3755%\n",
      "Epoch [124/300], Step [5/23], Training Accuracy: 78.7500%, Training Loss: 0.3735%\n",
      "Epoch [124/300], Step [6/23], Training Accuracy: 78.9062%, Training Loss: 0.3757%\n",
      "Epoch [124/300], Step [7/23], Training Accuracy: 78.7946%, Training Loss: 0.3840%\n",
      "Epoch [124/300], Step [8/23], Training Accuracy: 78.9062%, Training Loss: 0.3836%\n",
      "Epoch [124/300], Step [9/23], Training Accuracy: 77.6042%, Training Loss: 0.3906%\n",
      "Epoch [124/300], Step [10/23], Training Accuracy: 77.3438%, Training Loss: 0.3893%\n",
      "Epoch [124/300], Step [11/23], Training Accuracy: 77.4148%, Training Loss: 0.3862%\n",
      "Epoch [124/300], Step [12/23], Training Accuracy: 76.8229%, Training Loss: 0.3874%\n",
      "Epoch [124/300], Step [13/23], Training Accuracy: 76.8029%, Training Loss: 0.3877%\n",
      "Epoch [124/300], Step [14/23], Training Accuracy: 77.0089%, Training Loss: 0.3845%\n",
      "Epoch [124/300], Step [15/23], Training Accuracy: 76.5625%, Training Loss: 0.3866%\n",
      "Epoch [124/300], Step [16/23], Training Accuracy: 76.4648%, Training Loss: 0.3873%\n",
      "Epoch [124/300], Step [17/23], Training Accuracy: 76.4706%, Training Loss: 0.3851%\n",
      "Epoch [124/300], Step [18/23], Training Accuracy: 76.1285%, Training Loss: 0.3863%\n",
      "Epoch [124/300], Step [19/23], Training Accuracy: 75.9868%, Training Loss: 0.3868%\n",
      "Epoch [124/300], Step [20/23], Training Accuracy: 76.2500%, Training Loss: 0.3852%\n",
      "Epoch [124/300], Step [21/23], Training Accuracy: 76.3393%, Training Loss: 0.3855%\n",
      "Epoch [124/300], Step [22/23], Training Accuracy: 76.3494%, Training Loss: 0.3855%\n",
      "Epoch [124/300], Step [23/23], Training Accuracy: 76.4420%, Training Loss: 0.3814%\n",
      "Epoch [125/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3907%\n",
      "Epoch [125/300], Step [2/23], Training Accuracy: 77.3438%, Training Loss: 0.3873%\n",
      "Epoch [125/300], Step [3/23], Training Accuracy: 74.4792%, Training Loss: 0.3893%\n",
      "Epoch [125/300], Step [4/23], Training Accuracy: 77.3438%, Training Loss: 0.3729%\n",
      "Epoch [125/300], Step [5/23], Training Accuracy: 75.9375%, Training Loss: 0.3766%\n",
      "Epoch [125/300], Step [6/23], Training Accuracy: 76.8229%, Training Loss: 0.3768%\n",
      "Epoch [125/300], Step [7/23], Training Accuracy: 75.8929%, Training Loss: 0.3819%\n",
      "Epoch [125/300], Step [8/23], Training Accuracy: 76.1719%, Training Loss: 0.3841%\n",
      "Epoch [125/300], Step [9/23], Training Accuracy: 75.0000%, Training Loss: 0.3885%\n",
      "Epoch [125/300], Step [10/23], Training Accuracy: 75.3125%, Training Loss: 0.3854%\n",
      "Epoch [125/300], Step [11/23], Training Accuracy: 75.8523%, Training Loss: 0.3850%\n",
      "Epoch [125/300], Step [12/23], Training Accuracy: 75.3906%, Training Loss: 0.3862%\n",
      "Epoch [125/300], Step [13/23], Training Accuracy: 75.3606%, Training Loss: 0.3854%\n",
      "Epoch [125/300], Step [14/23], Training Accuracy: 75.4464%, Training Loss: 0.3839%\n",
      "Epoch [125/300], Step [15/23], Training Accuracy: 74.7917%, Training Loss: 0.3881%\n",
      "Epoch [125/300], Step [16/23], Training Accuracy: 74.9023%, Training Loss: 0.3884%\n",
      "Epoch [125/300], Step [17/23], Training Accuracy: 75.3676%, Training Loss: 0.3881%\n",
      "Epoch [125/300], Step [18/23], Training Accuracy: 75.3472%, Training Loss: 0.3879%\n",
      "Epoch [125/300], Step [19/23], Training Accuracy: 75.3289%, Training Loss: 0.3877%\n",
      "Epoch [125/300], Step [20/23], Training Accuracy: 75.4688%, Training Loss: 0.3865%\n",
      "Epoch [125/300], Step [21/23], Training Accuracy: 75.5208%, Training Loss: 0.3871%\n",
      "Epoch [125/300], Step [22/23], Training Accuracy: 75.4261%, Training Loss: 0.3870%\n",
      "Epoch [125/300], Step [23/23], Training Accuracy: 75.6081%, Training Loss: 0.3843%\n",
      "Epoch [126/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3356%\n",
      "Epoch [126/300], Step [2/23], Training Accuracy: 77.3438%, Training Loss: 0.3674%\n",
      "Epoch [126/300], Step [3/23], Training Accuracy: 73.4375%, Training Loss: 0.3779%\n",
      "Epoch [126/300], Step [4/23], Training Accuracy: 75.0000%, Training Loss: 0.3692%\n",
      "Epoch [126/300], Step [5/23], Training Accuracy: 74.3750%, Training Loss: 0.3713%\n",
      "Epoch [126/300], Step [6/23], Training Accuracy: 75.2604%, Training Loss: 0.3726%\n",
      "Epoch [126/300], Step [7/23], Training Accuracy: 74.7768%, Training Loss: 0.3808%\n",
      "Epoch [126/300], Step [8/23], Training Accuracy: 74.8047%, Training Loss: 0.3821%\n",
      "Epoch [126/300], Step [9/23], Training Accuracy: 73.9583%, Training Loss: 0.3871%\n",
      "Epoch [126/300], Step [10/23], Training Accuracy: 74.2188%, Training Loss: 0.3889%\n",
      "Epoch [126/300], Step [11/23], Training Accuracy: 73.8636%, Training Loss: 0.3888%\n",
      "Epoch [126/300], Step [12/23], Training Accuracy: 73.9583%, Training Loss: 0.3900%\n",
      "Epoch [126/300], Step [13/23], Training Accuracy: 73.9183%, Training Loss: 0.3915%\n",
      "Epoch [126/300], Step [14/23], Training Accuracy: 74.1071%, Training Loss: 0.3889%\n",
      "Epoch [126/300], Step [15/23], Training Accuracy: 73.9583%, Training Loss: 0.3915%\n",
      "Epoch [126/300], Step [16/23], Training Accuracy: 73.6328%, Training Loss: 0.3924%\n",
      "Epoch [126/300], Step [17/23], Training Accuracy: 73.7132%, Training Loss: 0.3923%\n",
      "Epoch [126/300], Step [18/23], Training Accuracy: 73.7847%, Training Loss: 0.3933%\n",
      "Epoch [126/300], Step [19/23], Training Accuracy: 73.9309%, Training Loss: 0.3932%\n",
      "Epoch [126/300], Step [20/23], Training Accuracy: 74.2188%, Training Loss: 0.3917%\n",
      "Epoch [126/300], Step [21/23], Training Accuracy: 74.1815%, Training Loss: 0.3921%\n",
      "Epoch [126/300], Step [22/23], Training Accuracy: 74.3608%, Training Loss: 0.3907%\n",
      "Epoch [126/300], Step [23/23], Training Accuracy: 74.5657%, Training Loss: 0.3868%\n",
      "Epoch [127/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3678%\n",
      "Epoch [127/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3952%\n",
      "Epoch [127/300], Step [3/23], Training Accuracy: 74.4792%, Training Loss: 0.3997%\n",
      "Epoch [127/300], Step [4/23], Training Accuracy: 77.3438%, Training Loss: 0.3855%\n",
      "Epoch [127/300], Step [5/23], Training Accuracy: 75.6250%, Training Loss: 0.3854%\n",
      "Epoch [127/300], Step [6/23], Training Accuracy: 76.5625%, Training Loss: 0.3869%\n",
      "Epoch [127/300], Step [7/23], Training Accuracy: 76.1161%, Training Loss: 0.3934%\n",
      "Epoch [127/300], Step [8/23], Training Accuracy: 75.9766%, Training Loss: 0.3929%\n",
      "Epoch [127/300], Step [9/23], Training Accuracy: 74.6528%, Training Loss: 0.3993%\n",
      "Epoch [127/300], Step [10/23], Training Accuracy: 74.6875%, Training Loss: 0.3985%\n",
      "Epoch [127/300], Step [11/23], Training Accuracy: 74.8580%, Training Loss: 0.3972%\n",
      "Epoch [127/300], Step [12/23], Training Accuracy: 74.7396%, Training Loss: 0.3963%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [127/300], Step [13/23], Training Accuracy: 74.8798%, Training Loss: 0.3963%\n",
      "Epoch [127/300], Step [14/23], Training Accuracy: 74.6652%, Training Loss: 0.3952%\n",
      "Epoch [127/300], Step [15/23], Training Accuracy: 74.4792%, Training Loss: 0.3971%\n",
      "Epoch [127/300], Step [16/23], Training Accuracy: 74.4141%, Training Loss: 0.3964%\n",
      "Epoch [127/300], Step [17/23], Training Accuracy: 74.4485%, Training Loss: 0.3955%\n",
      "Epoch [127/300], Step [18/23], Training Accuracy: 74.6528%, Training Loss: 0.3945%\n",
      "Epoch [127/300], Step [19/23], Training Accuracy: 74.2599%, Training Loss: 0.3934%\n",
      "Epoch [127/300], Step [20/23], Training Accuracy: 74.6094%, Training Loss: 0.3924%\n",
      "Epoch [127/300], Step [21/23], Training Accuracy: 74.8512%, Training Loss: 0.3912%\n",
      "Epoch [127/300], Step [22/23], Training Accuracy: 75.0000%, Training Loss: 0.3899%\n",
      "Epoch [127/300], Step [23/23], Training Accuracy: 75.1216%, Training Loss: 0.3873%\n",
      "Epoch [128/300], Step [1/23], Training Accuracy: 73.4375%, Training Loss: 0.3636%\n",
      "Epoch [128/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.3880%\n",
      "Epoch [128/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.3920%\n",
      "Epoch [128/300], Step [4/23], Training Accuracy: 73.4375%, Training Loss: 0.3775%\n",
      "Epoch [128/300], Step [5/23], Training Accuracy: 73.4375%, Training Loss: 0.3767%\n",
      "Epoch [128/300], Step [6/23], Training Accuracy: 74.7396%, Training Loss: 0.3764%\n",
      "Epoch [128/300], Step [7/23], Training Accuracy: 73.6607%, Training Loss: 0.3847%\n",
      "Epoch [128/300], Step [8/23], Training Accuracy: 74.2188%, Training Loss: 0.3832%\n",
      "Epoch [128/300], Step [9/23], Training Accuracy: 72.3958%, Training Loss: 0.3929%\n",
      "Epoch [128/300], Step [10/23], Training Accuracy: 72.6562%, Training Loss: 0.3909%\n",
      "Epoch [128/300], Step [11/23], Training Accuracy: 73.2955%, Training Loss: 0.3882%\n",
      "Epoch [128/300], Step [12/23], Training Accuracy: 73.6979%, Training Loss: 0.3884%\n",
      "Epoch [128/300], Step [13/23], Training Accuracy: 72.9567%, Training Loss: 0.3891%\n",
      "Epoch [128/300], Step [14/23], Training Accuracy: 73.6607%, Training Loss: 0.3873%\n",
      "Epoch [128/300], Step [15/23], Training Accuracy: 73.2292%, Training Loss: 0.3916%\n",
      "Epoch [128/300], Step [16/23], Training Accuracy: 73.0469%, Training Loss: 0.3920%\n",
      "Epoch [128/300], Step [17/23], Training Accuracy: 73.4375%, Training Loss: 0.3916%\n",
      "Epoch [128/300], Step [18/23], Training Accuracy: 73.5243%, Training Loss: 0.3913%\n",
      "Epoch [128/300], Step [19/23], Training Accuracy: 73.5197%, Training Loss: 0.3926%\n",
      "Epoch [128/300], Step [20/23], Training Accuracy: 73.8281%, Training Loss: 0.3915%\n",
      "Epoch [128/300], Step [21/23], Training Accuracy: 74.0327%, Training Loss: 0.3922%\n",
      "Epoch [128/300], Step [22/23], Training Accuracy: 74.2898%, Training Loss: 0.3914%\n",
      "Epoch [128/300], Step [23/23], Training Accuracy: 74.4962%, Training Loss: 0.3876%\n",
      "Epoch [129/300], Step [1/23], Training Accuracy: 73.4375%, Training Loss: 0.3937%\n",
      "Epoch [129/300], Step [2/23], Training Accuracy: 70.3125%, Training Loss: 0.4090%\n",
      "Epoch [129/300], Step [3/23], Training Accuracy: 69.7917%, Training Loss: 0.4106%\n",
      "Epoch [129/300], Step [4/23], Training Accuracy: 72.6562%, Training Loss: 0.3896%\n",
      "Epoch [129/300], Step [5/23], Training Accuracy: 74.6875%, Training Loss: 0.3824%\n",
      "Epoch [129/300], Step [6/23], Training Accuracy: 74.7396%, Training Loss: 0.3829%\n",
      "Epoch [129/300], Step [7/23], Training Accuracy: 74.3304%, Training Loss: 0.3884%\n",
      "Epoch [129/300], Step [8/23], Training Accuracy: 75.1953%, Training Loss: 0.3877%\n",
      "Epoch [129/300], Step [9/23], Training Accuracy: 74.4792%, Training Loss: 0.3905%\n",
      "Epoch [129/300], Step [10/23], Training Accuracy: 74.5312%, Training Loss: 0.3889%\n",
      "Epoch [129/300], Step [11/23], Training Accuracy: 75.1420%, Training Loss: 0.3876%\n",
      "Epoch [129/300], Step [12/23], Training Accuracy: 74.8698%, Training Loss: 0.3898%\n",
      "Epoch [129/300], Step [13/23], Training Accuracy: 73.9183%, Training Loss: 0.3927%\n",
      "Epoch [129/300], Step [14/23], Training Accuracy: 74.3304%, Training Loss: 0.3894%\n",
      "Epoch [129/300], Step [15/23], Training Accuracy: 73.8542%, Training Loss: 0.3929%\n",
      "Epoch [129/300], Step [16/23], Training Accuracy: 73.8281%, Training Loss: 0.3928%\n",
      "Epoch [129/300], Step [17/23], Training Accuracy: 74.2647%, Training Loss: 0.3917%\n",
      "Epoch [129/300], Step [18/23], Training Accuracy: 74.0451%, Training Loss: 0.3928%\n",
      "Epoch [129/300], Step [19/23], Training Accuracy: 74.0132%, Training Loss: 0.3916%\n",
      "Epoch [129/300], Step [20/23], Training Accuracy: 74.5312%, Training Loss: 0.3893%\n",
      "Epoch [129/300], Step [21/23], Training Accuracy: 74.7768%, Training Loss: 0.3887%\n",
      "Epoch [129/300], Step [22/23], Training Accuracy: 74.7869%, Training Loss: 0.3885%\n",
      "Epoch [129/300], Step [23/23], Training Accuracy: 74.6352%, Training Loss: 0.3843%\n",
      "Epoch [130/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3617%\n",
      "Epoch [130/300], Step [2/23], Training Accuracy: 78.1250%, Training Loss: 0.3810%\n",
      "Epoch [130/300], Step [3/23], Training Accuracy: 76.5625%, Training Loss: 0.3838%\n",
      "Epoch [130/300], Step [4/23], Training Accuracy: 79.2969%, Training Loss: 0.3670%\n",
      "Epoch [130/300], Step [5/23], Training Accuracy: 78.1250%, Training Loss: 0.3670%\n",
      "Epoch [130/300], Step [6/23], Training Accuracy: 78.3854%, Training Loss: 0.3679%\n",
      "Epoch [130/300], Step [7/23], Training Accuracy: 77.2321%, Training Loss: 0.3769%\n",
      "Epoch [130/300], Step [8/23], Training Accuracy: 77.5391%, Training Loss: 0.3763%\n",
      "Epoch [130/300], Step [9/23], Training Accuracy: 75.8681%, Training Loss: 0.3854%\n",
      "Epoch [130/300], Step [10/23], Training Accuracy: 76.2500%, Training Loss: 0.3826%\n",
      "Epoch [130/300], Step [11/23], Training Accuracy: 76.1364%, Training Loss: 0.3816%\n",
      "Epoch [130/300], Step [12/23], Training Accuracy: 75.7812%, Training Loss: 0.3836%\n",
      "Epoch [130/300], Step [13/23], Training Accuracy: 75.0000%, Training Loss: 0.3864%\n",
      "Epoch [130/300], Step [14/23], Training Accuracy: 75.1116%, Training Loss: 0.3849%\n",
      "Epoch [130/300], Step [15/23], Training Accuracy: 74.2708%, Training Loss: 0.3902%\n",
      "Epoch [130/300], Step [16/23], Training Accuracy: 74.1211%, Training Loss: 0.3908%\n",
      "Epoch [130/300], Step [17/23], Training Accuracy: 74.3566%, Training Loss: 0.3892%\n",
      "Epoch [130/300], Step [18/23], Training Accuracy: 74.4792%, Training Loss: 0.3886%\n",
      "Epoch [130/300], Step [19/23], Training Accuracy: 74.7533%, Training Loss: 0.3882%\n",
      "Epoch [130/300], Step [20/23], Training Accuracy: 75.0000%, Training Loss: 0.3874%\n",
      "Epoch [130/300], Step [21/23], Training Accuracy: 75.1488%, Training Loss: 0.3864%\n",
      "Epoch [130/300], Step [22/23], Training Accuracy: 75.0000%, Training Loss: 0.3852%\n",
      "Epoch [130/300], Step [23/23], Training Accuracy: 74.9826%, Training Loss: 0.3821%\n",
      "Epoch [131/300], Step [1/23], Training Accuracy: 81.2500%, Training Loss: 0.3955%\n",
      "Epoch [131/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.4067%\n",
      "Epoch [131/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.4053%\n",
      "Epoch [131/300], Step [4/23], Training Accuracy: 74.2188%, Training Loss: 0.3902%\n",
      "Epoch [131/300], Step [5/23], Training Accuracy: 73.7500%, Training Loss: 0.3864%\n",
      "Epoch [131/300], Step [6/23], Training Accuracy: 75.0000%, Training Loss: 0.3845%\n",
      "Epoch [131/300], Step [7/23], Training Accuracy: 75.0000%, Training Loss: 0.3888%\n",
      "Epoch [131/300], Step [8/23], Training Accuracy: 75.3906%, Training Loss: 0.3868%\n",
      "Epoch [131/300], Step [9/23], Training Accuracy: 73.7847%, Training Loss: 0.3918%\n",
      "Epoch [131/300], Step [10/23], Training Accuracy: 73.5938%, Training Loss: 0.3901%\n",
      "Epoch [131/300], Step [11/23], Training Accuracy: 74.1477%, Training Loss: 0.3869%\n",
      "Epoch [131/300], Step [12/23], Training Accuracy: 74.2188%, Training Loss: 0.3866%\n",
      "Epoch [131/300], Step [13/23], Training Accuracy: 74.2788%, Training Loss: 0.3897%\n",
      "Epoch [131/300], Step [14/23], Training Accuracy: 74.4420%, Training Loss: 0.3875%\n",
      "Epoch [131/300], Step [15/23], Training Accuracy: 73.8542%, Training Loss: 0.3916%\n",
      "Epoch [131/300], Step [16/23], Training Accuracy: 73.7305%, Training Loss: 0.3934%\n",
      "Epoch [131/300], Step [17/23], Training Accuracy: 74.2647%, Training Loss: 0.3928%\n",
      "Epoch [131/300], Step [18/23], Training Accuracy: 74.3056%, Training Loss: 0.3934%\n",
      "Epoch [131/300], Step [19/23], Training Accuracy: 74.0132%, Training Loss: 0.3934%\n",
      "Epoch [131/300], Step [20/23], Training Accuracy: 74.0625%, Training Loss: 0.3921%\n",
      "Epoch [131/300], Step [21/23], Training Accuracy: 74.3304%, Training Loss: 0.3913%\n",
      "Epoch [131/300], Step [22/23], Training Accuracy: 74.5028%, Training Loss: 0.3899%\n",
      "Epoch [131/300], Step [23/23], Training Accuracy: 74.5657%, Training Loss: 0.3864%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [132/300], Step [1/23], Training Accuracy: 73.4375%, Training Loss: 0.3824%\n",
      "Epoch [132/300], Step [2/23], Training Accuracy: 72.6562%, Training Loss: 0.3909%\n",
      "Epoch [132/300], Step [3/23], Training Accuracy: 70.8333%, Training Loss: 0.4011%\n",
      "Epoch [132/300], Step [4/23], Training Accuracy: 73.4375%, Training Loss: 0.3847%\n",
      "Epoch [132/300], Step [5/23], Training Accuracy: 73.4375%, Training Loss: 0.3860%\n",
      "Epoch [132/300], Step [6/23], Training Accuracy: 74.4792%, Training Loss: 0.3869%\n",
      "Epoch [132/300], Step [7/23], Training Accuracy: 74.3304%, Training Loss: 0.3911%\n",
      "Epoch [132/300], Step [8/23], Training Accuracy: 74.8047%, Training Loss: 0.3898%\n",
      "Epoch [132/300], Step [9/23], Training Accuracy: 74.1319%, Training Loss: 0.3917%\n",
      "Epoch [132/300], Step [10/23], Training Accuracy: 74.5312%, Training Loss: 0.3877%\n",
      "Epoch [132/300], Step [11/23], Training Accuracy: 74.2898%, Training Loss: 0.3879%\n",
      "Epoch [132/300], Step [12/23], Training Accuracy: 73.5677%, Training Loss: 0.3920%\n",
      "Epoch [132/300], Step [13/23], Training Accuracy: 73.5577%, Training Loss: 0.3927%\n",
      "Epoch [132/300], Step [14/23], Training Accuracy: 73.4375%, Training Loss: 0.3927%\n",
      "Epoch [132/300], Step [15/23], Training Accuracy: 73.1250%, Training Loss: 0.3982%\n",
      "Epoch [132/300], Step [16/23], Training Accuracy: 73.0469%, Training Loss: 0.3988%\n",
      "Epoch [132/300], Step [17/23], Training Accuracy: 73.1618%, Training Loss: 0.3970%\n",
      "Epoch [132/300], Step [18/23], Training Accuracy: 73.2639%, Training Loss: 0.3977%\n",
      "Epoch [132/300], Step [19/23], Training Accuracy: 73.6020%, Training Loss: 0.3961%\n",
      "Epoch [132/300], Step [20/23], Training Accuracy: 73.7500%, Training Loss: 0.3949%\n",
      "Epoch [132/300], Step [21/23], Training Accuracy: 73.3631%, Training Loss: 0.3951%\n",
      "Epoch [132/300], Step [22/23], Training Accuracy: 73.5795%, Training Loss: 0.3940%\n",
      "Epoch [132/300], Step [23/23], Training Accuracy: 73.6623%, Training Loss: 0.3913%\n",
      "Epoch [133/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3631%\n",
      "Epoch [133/300], Step [2/23], Training Accuracy: 75.7812%, Training Loss: 0.4005%\n",
      "Epoch [133/300], Step [3/23], Training Accuracy: 70.8333%, Training Loss: 0.4066%\n",
      "Epoch [133/300], Step [4/23], Training Accuracy: 73.4375%, Training Loss: 0.3867%\n",
      "Epoch [133/300], Step [5/23], Training Accuracy: 71.8750%, Training Loss: 0.3858%\n",
      "Epoch [133/300], Step [6/23], Training Accuracy: 72.9167%, Training Loss: 0.3863%\n",
      "Epoch [133/300], Step [7/23], Training Accuracy: 73.4375%, Training Loss: 0.3885%\n",
      "Epoch [133/300], Step [8/23], Training Accuracy: 74.0234%, Training Loss: 0.3872%\n",
      "Epoch [133/300], Step [9/23], Training Accuracy: 73.0903%, Training Loss: 0.3930%\n",
      "Epoch [133/300], Step [10/23], Training Accuracy: 73.4375%, Training Loss: 0.3911%\n",
      "Epoch [133/300], Step [11/23], Training Accuracy: 73.7216%, Training Loss: 0.3915%\n",
      "Epoch [133/300], Step [12/23], Training Accuracy: 74.2188%, Training Loss: 0.3896%\n",
      "Epoch [133/300], Step [13/23], Training Accuracy: 73.6779%, Training Loss: 0.3918%\n",
      "Epoch [133/300], Step [14/23], Training Accuracy: 74.2188%, Training Loss: 0.3889%\n",
      "Epoch [133/300], Step [15/23], Training Accuracy: 74.1667%, Training Loss: 0.3899%\n",
      "Epoch [133/300], Step [16/23], Training Accuracy: 73.8281%, Training Loss: 0.3915%\n",
      "Epoch [133/300], Step [17/23], Training Accuracy: 73.7132%, Training Loss: 0.3918%\n",
      "Epoch [133/300], Step [18/23], Training Accuracy: 74.2188%, Training Loss: 0.3902%\n",
      "Epoch [133/300], Step [19/23], Training Accuracy: 74.4243%, Training Loss: 0.3902%\n",
      "Epoch [133/300], Step [20/23], Training Accuracy: 74.6875%, Training Loss: 0.3885%\n",
      "Epoch [133/300], Step [21/23], Training Accuracy: 74.4048%, Training Loss: 0.3883%\n",
      "Epoch [133/300], Step [22/23], Training Accuracy: 74.2898%, Training Loss: 0.3876%\n",
      "Epoch [133/300], Step [23/23], Training Accuracy: 74.3572%, Training Loss: 0.3844%\n",
      "Epoch [134/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3611%\n",
      "Epoch [134/300], Step [2/23], Training Accuracy: 75.7812%, Training Loss: 0.3863%\n",
      "Epoch [134/300], Step [3/23], Training Accuracy: 73.4375%, Training Loss: 0.3895%\n",
      "Epoch [134/300], Step [4/23], Training Accuracy: 76.1719%, Training Loss: 0.3748%\n",
      "Epoch [134/300], Step [5/23], Training Accuracy: 75.6250%, Training Loss: 0.3750%\n",
      "Epoch [134/300], Step [6/23], Training Accuracy: 75.5208%, Training Loss: 0.3730%\n",
      "Epoch [134/300], Step [7/23], Training Accuracy: 75.4464%, Training Loss: 0.3789%\n",
      "Epoch [134/300], Step [8/23], Training Accuracy: 75.9766%, Training Loss: 0.3821%\n",
      "Epoch [134/300], Step [9/23], Training Accuracy: 74.3056%, Training Loss: 0.3875%\n",
      "Epoch [134/300], Step [10/23], Training Accuracy: 73.7500%, Training Loss: 0.3867%\n",
      "Epoch [134/300], Step [11/23], Training Accuracy: 74.1477%, Training Loss: 0.3867%\n",
      "Epoch [134/300], Step [12/23], Training Accuracy: 74.4792%, Training Loss: 0.3860%\n",
      "Epoch [134/300], Step [13/23], Training Accuracy: 74.5192%, Training Loss: 0.3871%\n",
      "Epoch [134/300], Step [14/23], Training Accuracy: 74.7768%, Training Loss: 0.3867%\n",
      "Epoch [134/300], Step [15/23], Training Accuracy: 74.1667%, Training Loss: 0.3882%\n",
      "Epoch [134/300], Step [16/23], Training Accuracy: 74.2188%, Training Loss: 0.3900%\n",
      "Epoch [134/300], Step [17/23], Training Accuracy: 74.2647%, Training Loss: 0.3906%\n",
      "Epoch [134/300], Step [18/23], Training Accuracy: 73.9583%, Training Loss: 0.3915%\n",
      "Epoch [134/300], Step [19/23], Training Accuracy: 73.9309%, Training Loss: 0.3908%\n",
      "Epoch [134/300], Step [20/23], Training Accuracy: 74.2969%, Training Loss: 0.3887%\n",
      "Epoch [134/300], Step [21/23], Training Accuracy: 74.4048%, Training Loss: 0.3882%\n",
      "Epoch [134/300], Step [22/23], Training Accuracy: 74.4318%, Training Loss: 0.3882%\n",
      "Epoch [134/300], Step [23/23], Training Accuracy: 74.4267%, Training Loss: 0.3857%\n",
      "Epoch [135/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3718%\n",
      "Epoch [135/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.3991%\n",
      "Epoch [135/300], Step [3/23], Training Accuracy: 72.3958%, Training Loss: 0.3947%\n",
      "Epoch [135/300], Step [4/23], Training Accuracy: 75.0000%, Training Loss: 0.3773%\n",
      "Epoch [135/300], Step [5/23], Training Accuracy: 74.3750%, Training Loss: 0.3811%\n",
      "Epoch [135/300], Step [6/23], Training Accuracy: 75.2604%, Training Loss: 0.3831%\n",
      "Epoch [135/300], Step [7/23], Training Accuracy: 75.0000%, Training Loss: 0.3901%\n",
      "Epoch [135/300], Step [8/23], Training Accuracy: 75.3906%, Training Loss: 0.3897%\n",
      "Epoch [135/300], Step [9/23], Training Accuracy: 74.1319%, Training Loss: 0.3956%\n",
      "Epoch [135/300], Step [10/23], Training Accuracy: 73.9062%, Training Loss: 0.3926%\n",
      "Epoch [135/300], Step [11/23], Training Accuracy: 74.1477%, Training Loss: 0.3911%\n",
      "Epoch [135/300], Step [12/23], Training Accuracy: 74.4792%, Training Loss: 0.3900%\n",
      "Epoch [135/300], Step [13/23], Training Accuracy: 74.5192%, Training Loss: 0.3900%\n",
      "Epoch [135/300], Step [14/23], Training Accuracy: 74.8884%, Training Loss: 0.3868%\n",
      "Epoch [135/300], Step [15/23], Training Accuracy: 74.2708%, Training Loss: 0.3902%\n",
      "Epoch [135/300], Step [16/23], Training Accuracy: 74.5117%, Training Loss: 0.3886%\n",
      "Epoch [135/300], Step [17/23], Training Accuracy: 74.6324%, Training Loss: 0.3875%\n",
      "Epoch [135/300], Step [18/23], Training Accuracy: 74.3924%, Training Loss: 0.3885%\n",
      "Epoch [135/300], Step [19/23], Training Accuracy: 74.2599%, Training Loss: 0.3881%\n",
      "Epoch [135/300], Step [20/23], Training Accuracy: 74.5312%, Training Loss: 0.3875%\n",
      "Epoch [135/300], Step [21/23], Training Accuracy: 74.6280%, Training Loss: 0.3870%\n",
      "Epoch [135/300], Step [22/23], Training Accuracy: 74.8580%, Training Loss: 0.3860%\n",
      "Epoch [135/300], Step [23/23], Training Accuracy: 74.8436%, Training Loss: 0.3828%\n",
      "Epoch [136/300], Step [1/23], Training Accuracy: 82.8125%, Training Loss: 0.3638%\n",
      "Epoch [136/300], Step [2/23], Training Accuracy: 72.6562%, Training Loss: 0.4018%\n",
      "Epoch [136/300], Step [3/23], Training Accuracy: 72.3958%, Training Loss: 0.4089%\n",
      "Epoch [136/300], Step [4/23], Training Accuracy: 75.0000%, Training Loss: 0.3908%\n",
      "Epoch [136/300], Step [5/23], Training Accuracy: 74.6875%, Training Loss: 0.3875%\n",
      "Epoch [136/300], Step [6/23], Training Accuracy: 75.2604%, Training Loss: 0.3878%\n",
      "Epoch [136/300], Step [7/23], Training Accuracy: 74.7768%, Training Loss: 0.3932%\n",
      "Epoch [136/300], Step [8/23], Training Accuracy: 75.9766%, Training Loss: 0.3914%\n",
      "Epoch [136/300], Step [9/23], Training Accuracy: 75.3472%, Training Loss: 0.3960%\n",
      "Epoch [136/300], Step [10/23], Training Accuracy: 75.4688%, Training Loss: 0.3943%\n",
      "Epoch [136/300], Step [11/23], Training Accuracy: 75.8523%, Training Loss: 0.3924%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [136/300], Step [12/23], Training Accuracy: 75.5208%, Training Loss: 0.3926%\n",
      "Epoch [136/300], Step [13/23], Training Accuracy: 75.4808%, Training Loss: 0.3935%\n",
      "Epoch [136/300], Step [14/23], Training Accuracy: 75.6696%, Training Loss: 0.3907%\n",
      "Epoch [136/300], Step [15/23], Training Accuracy: 75.5208%, Training Loss: 0.3926%\n",
      "Epoch [136/300], Step [16/23], Training Accuracy: 75.0977%, Training Loss: 0.3936%\n",
      "Epoch [136/300], Step [17/23], Training Accuracy: 74.8162%, Training Loss: 0.3936%\n",
      "Epoch [136/300], Step [18/23], Training Accuracy: 75.0868%, Training Loss: 0.3928%\n",
      "Epoch [136/300], Step [19/23], Training Accuracy: 75.0822%, Training Loss: 0.3923%\n",
      "Epoch [136/300], Step [20/23], Training Accuracy: 75.3906%, Training Loss: 0.3891%\n",
      "Epoch [136/300], Step [21/23], Training Accuracy: 75.4464%, Training Loss: 0.3887%\n",
      "Epoch [136/300], Step [22/23], Training Accuracy: 75.4261%, Training Loss: 0.3888%\n",
      "Epoch [136/300], Step [23/23], Training Accuracy: 75.5386%, Training Loss: 0.3860%\n",
      "Epoch [137/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3659%\n",
      "Epoch [137/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.4000%\n",
      "Epoch [137/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.4062%\n",
      "Epoch [137/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.3954%\n",
      "Epoch [137/300], Step [5/23], Training Accuracy: 73.1250%, Training Loss: 0.3895%\n",
      "Epoch [137/300], Step [6/23], Training Accuracy: 74.4792%, Training Loss: 0.3902%\n",
      "Epoch [137/300], Step [7/23], Training Accuracy: 75.0000%, Training Loss: 0.3926%\n",
      "Epoch [137/300], Step [8/23], Training Accuracy: 75.3906%, Training Loss: 0.3927%\n",
      "Epoch [137/300], Step [9/23], Training Accuracy: 73.7847%, Training Loss: 0.3993%\n",
      "Epoch [137/300], Step [10/23], Training Accuracy: 73.4375%, Training Loss: 0.3970%\n",
      "Epoch [137/300], Step [11/23], Training Accuracy: 73.5795%, Training Loss: 0.3967%\n",
      "Epoch [137/300], Step [12/23], Training Accuracy: 73.3073%, Training Loss: 0.3984%\n",
      "Epoch [137/300], Step [13/23], Training Accuracy: 72.9567%, Training Loss: 0.4001%\n",
      "Epoch [137/300], Step [14/23], Training Accuracy: 73.4375%, Training Loss: 0.3984%\n",
      "Epoch [137/300], Step [15/23], Training Accuracy: 72.9167%, Training Loss: 0.4027%\n",
      "Epoch [137/300], Step [16/23], Training Accuracy: 72.8516%, Training Loss: 0.4035%\n",
      "Epoch [137/300], Step [17/23], Training Accuracy: 73.2537%, Training Loss: 0.4021%\n",
      "Epoch [137/300], Step [18/23], Training Accuracy: 73.5243%, Training Loss: 0.4012%\n",
      "Epoch [137/300], Step [19/23], Training Accuracy: 73.4375%, Training Loss: 0.4016%\n",
      "Epoch [137/300], Step [20/23], Training Accuracy: 73.6719%, Training Loss: 0.4000%\n",
      "Epoch [137/300], Step [21/23], Training Accuracy: 73.7351%, Training Loss: 0.3989%\n",
      "Epoch [137/300], Step [22/23], Training Accuracy: 73.9347%, Training Loss: 0.3962%\n",
      "Epoch [137/300], Step [23/23], Training Accuracy: 74.0792%, Training Loss: 0.3924%\n",
      "Epoch [138/300], Step [1/23], Training Accuracy: 81.2500%, Training Loss: 0.3626%\n",
      "Epoch [138/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3929%\n",
      "Epoch [138/300], Step [3/23], Training Accuracy: 76.5625%, Training Loss: 0.3944%\n",
      "Epoch [138/300], Step [4/23], Training Accuracy: 78.5156%, Training Loss: 0.3791%\n",
      "Epoch [138/300], Step [5/23], Training Accuracy: 77.8125%, Training Loss: 0.3782%\n",
      "Epoch [138/300], Step [6/23], Training Accuracy: 77.8646%, Training Loss: 0.3798%\n",
      "Epoch [138/300], Step [7/23], Training Accuracy: 77.4554%, Training Loss: 0.3851%\n",
      "Epoch [138/300], Step [8/23], Training Accuracy: 77.3438%, Training Loss: 0.3836%\n",
      "Epoch [138/300], Step [9/23], Training Accuracy: 76.2153%, Training Loss: 0.3875%\n",
      "Epoch [138/300], Step [10/23], Training Accuracy: 75.9375%, Training Loss: 0.3851%\n",
      "Epoch [138/300], Step [11/23], Training Accuracy: 75.8523%, Training Loss: 0.3860%\n",
      "Epoch [138/300], Step [12/23], Training Accuracy: 74.7396%, Training Loss: 0.3902%\n",
      "Epoch [138/300], Step [13/23], Training Accuracy: 74.6394%, Training Loss: 0.3914%\n",
      "Epoch [138/300], Step [14/23], Training Accuracy: 74.7768%, Training Loss: 0.3921%\n",
      "Epoch [138/300], Step [15/23], Training Accuracy: 73.5417%, Training Loss: 0.3974%\n",
      "Epoch [138/300], Step [16/23], Training Accuracy: 73.4375%, Training Loss: 0.3976%\n",
      "Epoch [138/300], Step [17/23], Training Accuracy: 73.3456%, Training Loss: 0.3976%\n",
      "Epoch [138/300], Step [18/23], Training Accuracy: 73.2639%, Training Loss: 0.3985%\n",
      "Epoch [138/300], Step [19/23], Training Accuracy: 73.3553%, Training Loss: 0.3980%\n",
      "Epoch [138/300], Step [20/23], Training Accuracy: 73.3594%, Training Loss: 0.3966%\n",
      "Epoch [138/300], Step [21/23], Training Accuracy: 73.3631%, Training Loss: 0.3970%\n",
      "Epoch [138/300], Step [22/23], Training Accuracy: 73.5085%, Training Loss: 0.3960%\n",
      "Epoch [138/300], Step [23/23], Training Accuracy: 73.5928%, Training Loss: 0.3933%\n",
      "Epoch [139/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3699%\n",
      "Epoch [139/300], Step [2/23], Training Accuracy: 75.7812%, Training Loss: 0.3944%\n",
      "Epoch [139/300], Step [3/23], Training Accuracy: 75.0000%, Training Loss: 0.3907%\n",
      "Epoch [139/300], Step [4/23], Training Accuracy: 77.7344%, Training Loss: 0.3720%\n",
      "Epoch [139/300], Step [5/23], Training Accuracy: 75.9375%, Training Loss: 0.3731%\n",
      "Epoch [139/300], Step [6/23], Training Accuracy: 76.5625%, Training Loss: 0.3744%\n",
      "Epoch [139/300], Step [7/23], Training Accuracy: 76.3393%, Training Loss: 0.3819%\n",
      "Epoch [139/300], Step [8/23], Training Accuracy: 77.1484%, Training Loss: 0.3840%\n",
      "Epoch [139/300], Step [9/23], Training Accuracy: 75.5208%, Training Loss: 0.3916%\n",
      "Epoch [139/300], Step [10/23], Training Accuracy: 75.4688%, Training Loss: 0.3909%\n",
      "Epoch [139/300], Step [11/23], Training Accuracy: 75.2841%, Training Loss: 0.3909%\n",
      "Epoch [139/300], Step [12/23], Training Accuracy: 74.4792%, Training Loss: 0.3934%\n",
      "Epoch [139/300], Step [13/23], Training Accuracy: 74.6394%, Training Loss: 0.3969%\n",
      "Epoch [139/300], Step [14/23], Training Accuracy: 74.4420%, Training Loss: 0.3943%\n",
      "Epoch [139/300], Step [15/23], Training Accuracy: 73.9583%, Training Loss: 0.3959%\n",
      "Epoch [139/300], Step [16/23], Training Accuracy: 73.4375%, Training Loss: 0.3968%\n",
      "Epoch [139/300], Step [17/23], Training Accuracy: 73.7132%, Training Loss: 0.3972%\n",
      "Epoch [139/300], Step [18/23], Training Accuracy: 73.9583%, Training Loss: 0.3961%\n",
      "Epoch [139/300], Step [19/23], Training Accuracy: 73.9309%, Training Loss: 0.3954%\n",
      "Epoch [139/300], Step [20/23], Training Accuracy: 74.1406%, Training Loss: 0.3943%\n",
      "Epoch [139/300], Step [21/23], Training Accuracy: 74.1815%, Training Loss: 0.3933%\n",
      "Epoch [139/300], Step [22/23], Training Accuracy: 74.3608%, Training Loss: 0.3919%\n",
      "Epoch [139/300], Step [23/23], Training Accuracy: 74.7047%, Training Loss: 0.3873%\n",
      "Epoch [140/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3781%\n",
      "Epoch [140/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.3850%\n",
      "Epoch [140/300], Step [3/23], Training Accuracy: 73.4375%, Training Loss: 0.3876%\n",
      "Epoch [140/300], Step [4/23], Training Accuracy: 75.0000%, Training Loss: 0.3749%\n",
      "Epoch [140/300], Step [5/23], Training Accuracy: 73.7500%, Training Loss: 0.3774%\n",
      "Epoch [140/300], Step [6/23], Training Accuracy: 73.9583%, Training Loss: 0.3807%\n",
      "Epoch [140/300], Step [7/23], Training Accuracy: 73.6607%, Training Loss: 0.3867%\n",
      "Epoch [140/300], Step [8/23], Training Accuracy: 74.2188%, Training Loss: 0.3867%\n",
      "Epoch [140/300], Step [9/23], Training Accuracy: 73.2639%, Training Loss: 0.3905%\n",
      "Epoch [140/300], Step [10/23], Training Accuracy: 73.7500%, Training Loss: 0.3882%\n",
      "Epoch [140/300], Step [11/23], Training Accuracy: 74.4318%, Training Loss: 0.3865%\n",
      "Epoch [140/300], Step [12/23], Training Accuracy: 74.3490%, Training Loss: 0.3889%\n",
      "Epoch [140/300], Step [13/23], Training Accuracy: 73.7981%, Training Loss: 0.3903%\n",
      "Epoch [140/300], Step [14/23], Training Accuracy: 73.7723%, Training Loss: 0.3902%\n",
      "Epoch [140/300], Step [15/23], Training Accuracy: 73.4375%, Training Loss: 0.3932%\n",
      "Epoch [140/300], Step [16/23], Training Accuracy: 73.1445%, Training Loss: 0.3941%\n",
      "Epoch [140/300], Step [17/23], Training Accuracy: 73.4375%, Training Loss: 0.3940%\n",
      "Epoch [140/300], Step [18/23], Training Accuracy: 73.7847%, Training Loss: 0.3942%\n",
      "Epoch [140/300], Step [19/23], Training Accuracy: 73.6020%, Training Loss: 0.3946%\n",
      "Epoch [140/300], Step [20/23], Training Accuracy: 74.0625%, Training Loss: 0.3938%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [140/300], Step [21/23], Training Accuracy: 73.7351%, Training Loss: 0.3943%\n",
      "Epoch [140/300], Step [22/23], Training Accuracy: 73.7926%, Training Loss: 0.3936%\n",
      "Epoch [140/300], Step [23/23], Training Accuracy: 73.8013%, Training Loss: 0.3904%\n",
      "Epoch [141/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3570%\n",
      "Epoch [141/300], Step [2/23], Training Accuracy: 72.6562%, Training Loss: 0.3925%\n",
      "Epoch [141/300], Step [3/23], Training Accuracy: 72.3958%, Training Loss: 0.3943%\n",
      "Epoch [141/300], Step [4/23], Training Accuracy: 75.0000%, Training Loss: 0.3754%\n",
      "Epoch [141/300], Step [5/23], Training Accuracy: 74.6875%, Training Loss: 0.3757%\n",
      "Epoch [141/300], Step [6/23], Training Accuracy: 75.7812%, Training Loss: 0.3741%\n",
      "Epoch [141/300], Step [7/23], Training Accuracy: 76.1161%, Training Loss: 0.3788%\n",
      "Epoch [141/300], Step [8/23], Training Accuracy: 77.1484%, Training Loss: 0.3743%\n",
      "Epoch [141/300], Step [9/23], Training Accuracy: 76.2153%, Training Loss: 0.3803%\n",
      "Epoch [141/300], Step [10/23], Training Accuracy: 76.4062%, Training Loss: 0.3800%\n",
      "Epoch [141/300], Step [11/23], Training Accuracy: 75.7102%, Training Loss: 0.3822%\n",
      "Epoch [141/300], Step [12/23], Training Accuracy: 76.0417%, Training Loss: 0.3812%\n",
      "Epoch [141/300], Step [13/23], Training Accuracy: 75.9615%, Training Loss: 0.3823%\n",
      "Epoch [141/300], Step [14/23], Training Accuracy: 75.7812%, Training Loss: 0.3818%\n",
      "Epoch [141/300], Step [15/23], Training Accuracy: 75.4167%, Training Loss: 0.3840%\n",
      "Epoch [141/300], Step [16/23], Training Accuracy: 75.1953%, Training Loss: 0.3846%\n",
      "Epoch [141/300], Step [17/23], Training Accuracy: 74.8162%, Training Loss: 0.3863%\n",
      "Epoch [141/300], Step [18/23], Training Accuracy: 75.0000%, Training Loss: 0.3854%\n",
      "Epoch [141/300], Step [19/23], Training Accuracy: 75.1645%, Training Loss: 0.3848%\n",
      "Epoch [141/300], Step [20/23], Training Accuracy: 75.3906%, Training Loss: 0.3841%\n",
      "Epoch [141/300], Step [21/23], Training Accuracy: 75.5952%, Training Loss: 0.3839%\n",
      "Epoch [141/300], Step [22/23], Training Accuracy: 75.6392%, Training Loss: 0.3836%\n",
      "Epoch [141/300], Step [23/23], Training Accuracy: 75.8165%, Training Loss: 0.3809%\n",
      "Epoch [142/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3753%\n",
      "Epoch [142/300], Step [2/23], Training Accuracy: 72.6562%, Training Loss: 0.3989%\n",
      "Epoch [142/300], Step [3/23], Training Accuracy: 72.9167%, Training Loss: 0.3925%\n",
      "Epoch [142/300], Step [4/23], Training Accuracy: 74.2188%, Training Loss: 0.3795%\n",
      "Epoch [142/300], Step [5/23], Training Accuracy: 73.7500%, Training Loss: 0.3843%\n",
      "Epoch [142/300], Step [6/23], Training Accuracy: 74.7396%, Training Loss: 0.3813%\n",
      "Epoch [142/300], Step [7/23], Training Accuracy: 74.7768%, Training Loss: 0.3868%\n",
      "Epoch [142/300], Step [8/23], Training Accuracy: 75.5859%, Training Loss: 0.3872%\n",
      "Epoch [142/300], Step [9/23], Training Accuracy: 73.7847%, Training Loss: 0.3962%\n",
      "Epoch [142/300], Step [10/23], Training Accuracy: 73.5938%, Training Loss: 0.3942%\n",
      "Epoch [142/300], Step [11/23], Training Accuracy: 73.8636%, Training Loss: 0.3932%\n",
      "Epoch [142/300], Step [12/23], Training Accuracy: 73.9583%, Training Loss: 0.3944%\n",
      "Epoch [142/300], Step [13/23], Training Accuracy: 73.3173%, Training Loss: 0.3983%\n",
      "Epoch [142/300], Step [14/23], Training Accuracy: 73.8839%, Training Loss: 0.3967%\n",
      "Epoch [142/300], Step [15/23], Training Accuracy: 73.4375%, Training Loss: 0.3997%\n",
      "Epoch [142/300], Step [16/23], Training Accuracy: 73.1445%, Training Loss: 0.3992%\n",
      "Epoch [142/300], Step [17/23], Training Accuracy: 73.4375%, Training Loss: 0.3990%\n",
      "Epoch [142/300], Step [18/23], Training Accuracy: 73.4375%, Training Loss: 0.4000%\n",
      "Epoch [142/300], Step [19/23], Training Accuracy: 73.6020%, Training Loss: 0.3987%\n",
      "Epoch [142/300], Step [20/23], Training Accuracy: 74.0625%, Training Loss: 0.3960%\n",
      "Epoch [142/300], Step [21/23], Training Accuracy: 74.2560%, Training Loss: 0.3960%\n",
      "Epoch [142/300], Step [22/23], Training Accuracy: 74.5028%, Training Loss: 0.3946%\n",
      "Epoch [142/300], Step [23/23], Training Accuracy: 74.5657%, Training Loss: 0.3912%\n",
      "Epoch [143/300], Step [1/23], Training Accuracy: 81.2500%, Training Loss: 0.3710%\n",
      "Epoch [143/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.3927%\n",
      "Epoch [143/300], Step [3/23], Training Accuracy: 70.8333%, Training Loss: 0.4043%\n",
      "Epoch [143/300], Step [4/23], Training Accuracy: 74.2188%, Training Loss: 0.3857%\n",
      "Epoch [143/300], Step [5/23], Training Accuracy: 73.1250%, Training Loss: 0.3907%\n",
      "Epoch [143/300], Step [6/23], Training Accuracy: 73.6979%, Training Loss: 0.3898%\n",
      "Epoch [143/300], Step [7/23], Training Accuracy: 73.6607%, Training Loss: 0.3964%\n",
      "Epoch [143/300], Step [8/23], Training Accuracy: 73.8281%, Training Loss: 0.3950%\n",
      "Epoch [143/300], Step [9/23], Training Accuracy: 72.9167%, Training Loss: 0.4009%\n",
      "Epoch [143/300], Step [10/23], Training Accuracy: 72.6562%, Training Loss: 0.4015%\n",
      "Epoch [143/300], Step [11/23], Training Accuracy: 72.7273%, Training Loss: 0.4004%\n",
      "Epoch [143/300], Step [12/23], Training Accuracy: 72.6562%, Training Loss: 0.4022%\n",
      "Epoch [143/300], Step [13/23], Training Accuracy: 71.9952%, Training Loss: 0.4056%\n",
      "Epoch [143/300], Step [14/23], Training Accuracy: 72.5446%, Training Loss: 0.4020%\n",
      "Epoch [143/300], Step [15/23], Training Accuracy: 72.3958%, Training Loss: 0.4046%\n",
      "Epoch [143/300], Step [16/23], Training Accuracy: 72.5586%, Training Loss: 0.4038%\n",
      "Epoch [143/300], Step [17/23], Training Accuracy: 72.8860%, Training Loss: 0.4017%\n",
      "Epoch [143/300], Step [18/23], Training Accuracy: 73.0903%, Training Loss: 0.4008%\n",
      "Epoch [143/300], Step [19/23], Training Accuracy: 72.9441%, Training Loss: 0.3994%\n",
      "Epoch [143/300], Step [20/23], Training Accuracy: 73.2812%, Training Loss: 0.3967%\n",
      "Epoch [143/300], Step [21/23], Training Accuracy: 73.3631%, Training Loss: 0.3955%\n",
      "Epoch [143/300], Step [22/23], Training Accuracy: 73.7216%, Training Loss: 0.3940%\n",
      "Epoch [143/300], Step [23/23], Training Accuracy: 73.9402%, Training Loss: 0.3902%\n",
      "Epoch [144/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3760%\n",
      "Epoch [144/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.3953%\n",
      "Epoch [144/300], Step [3/23], Training Accuracy: 73.4375%, Training Loss: 0.3933%\n",
      "Epoch [144/300], Step [4/23], Training Accuracy: 75.7812%, Training Loss: 0.3811%\n",
      "Epoch [144/300], Step [5/23], Training Accuracy: 75.6250%, Training Loss: 0.3859%\n",
      "Epoch [144/300], Step [6/23], Training Accuracy: 76.3021%, Training Loss: 0.3894%\n",
      "Epoch [144/300], Step [7/23], Training Accuracy: 75.6696%, Training Loss: 0.3953%\n",
      "Epoch [144/300], Step [8/23], Training Accuracy: 75.5859%, Training Loss: 0.3969%\n",
      "Epoch [144/300], Step [9/23], Training Accuracy: 74.3056%, Training Loss: 0.4013%\n",
      "Epoch [144/300], Step [10/23], Training Accuracy: 73.5938%, Training Loss: 0.4008%\n",
      "Epoch [144/300], Step [11/23], Training Accuracy: 73.4375%, Training Loss: 0.4000%\n",
      "Epoch [144/300], Step [12/23], Training Accuracy: 73.3073%, Training Loss: 0.4019%\n",
      "Epoch [144/300], Step [13/23], Training Accuracy: 73.4375%, Training Loss: 0.4028%\n",
      "Epoch [144/300], Step [14/23], Training Accuracy: 73.6607%, Training Loss: 0.4015%\n",
      "Epoch [144/300], Step [15/23], Training Accuracy: 73.9583%, Training Loss: 0.4021%\n",
      "Epoch [144/300], Step [16/23], Training Accuracy: 73.9258%, Training Loss: 0.4018%\n",
      "Epoch [144/300], Step [17/23], Training Accuracy: 73.8051%, Training Loss: 0.4013%\n",
      "Epoch [144/300], Step [18/23], Training Accuracy: 73.5243%, Training Loss: 0.4014%\n",
      "Epoch [144/300], Step [19/23], Training Accuracy: 73.6020%, Training Loss: 0.4012%\n",
      "Epoch [144/300], Step [20/23], Training Accuracy: 74.0625%, Training Loss: 0.3984%\n",
      "Epoch [144/300], Step [21/23], Training Accuracy: 73.9583%, Training Loss: 0.3982%\n",
      "Epoch [144/300], Step [22/23], Training Accuracy: 74.0767%, Training Loss: 0.3969%\n",
      "Epoch [144/300], Step [23/23], Training Accuracy: 74.1487%, Training Loss: 0.3939%\n",
      "Epoch [145/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3699%\n",
      "Epoch [145/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3962%\n",
      "Epoch [145/300], Step [3/23], Training Accuracy: 73.9583%, Training Loss: 0.3963%\n",
      "Epoch [145/300], Step [4/23], Training Accuracy: 76.1719%, Training Loss: 0.3792%\n",
      "Epoch [145/300], Step [5/23], Training Accuracy: 75.9375%, Training Loss: 0.3787%\n",
      "Epoch [145/300], Step [6/23], Training Accuracy: 76.8229%, Training Loss: 0.3783%\n",
      "Epoch [145/300], Step [7/23], Training Accuracy: 76.7857%, Training Loss: 0.3861%\n",
      "Epoch [145/300], Step [8/23], Training Accuracy: 77.5391%, Training Loss: 0.3852%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [145/300], Step [9/23], Training Accuracy: 75.6944%, Training Loss: 0.3940%\n",
      "Epoch [145/300], Step [10/23], Training Accuracy: 75.7812%, Training Loss: 0.3906%\n",
      "Epoch [145/300], Step [11/23], Training Accuracy: 76.1364%, Training Loss: 0.3901%\n",
      "Epoch [145/300], Step [12/23], Training Accuracy: 75.9115%, Training Loss: 0.3904%\n",
      "Epoch [145/300], Step [13/23], Training Accuracy: 75.4808%, Training Loss: 0.3922%\n",
      "Epoch [145/300], Step [14/23], Training Accuracy: 75.8929%, Training Loss: 0.3895%\n",
      "Epoch [145/300], Step [15/23], Training Accuracy: 75.1042%, Training Loss: 0.3920%\n",
      "Epoch [145/300], Step [16/23], Training Accuracy: 75.0000%, Training Loss: 0.3929%\n",
      "Epoch [145/300], Step [17/23], Training Accuracy: 75.0919%, Training Loss: 0.3928%\n",
      "Epoch [145/300], Step [18/23], Training Accuracy: 74.9132%, Training Loss: 0.3939%\n",
      "Epoch [145/300], Step [19/23], Training Accuracy: 74.9178%, Training Loss: 0.3941%\n",
      "Epoch [145/300], Step [20/23], Training Accuracy: 75.1562%, Training Loss: 0.3935%\n",
      "Epoch [145/300], Step [21/23], Training Accuracy: 75.0744%, Training Loss: 0.3936%\n",
      "Epoch [145/300], Step [22/23], Training Accuracy: 75.4261%, Training Loss: 0.3921%\n",
      "Epoch [145/300], Step [23/23], Training Accuracy: 75.5386%, Training Loss: 0.3885%\n",
      "Epoch [146/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3742%\n",
      "Epoch [146/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.3992%\n",
      "Epoch [146/300], Step [3/23], Training Accuracy: 72.9167%, Training Loss: 0.4088%\n",
      "Epoch [146/300], Step [4/23], Training Accuracy: 75.0000%, Training Loss: 0.3976%\n",
      "Epoch [146/300], Step [5/23], Training Accuracy: 74.3750%, Training Loss: 0.3962%\n",
      "Epoch [146/300], Step [6/23], Training Accuracy: 75.2604%, Training Loss: 0.3939%\n",
      "Epoch [146/300], Step [7/23], Training Accuracy: 75.0000%, Training Loss: 0.3999%\n",
      "Epoch [146/300], Step [8/23], Training Accuracy: 75.7812%, Training Loss: 0.3989%\n",
      "Epoch [146/300], Step [9/23], Training Accuracy: 74.3056%, Training Loss: 0.4010%\n",
      "Epoch [146/300], Step [10/23], Training Accuracy: 73.9062%, Training Loss: 0.4005%\n",
      "Epoch [146/300], Step [11/23], Training Accuracy: 73.7216%, Training Loss: 0.3989%\n",
      "Epoch [146/300], Step [12/23], Training Accuracy: 73.6979%, Training Loss: 0.3992%\n",
      "Epoch [146/300], Step [13/23], Training Accuracy: 73.5577%, Training Loss: 0.3999%\n",
      "Epoch [146/300], Step [14/23], Training Accuracy: 73.7723%, Training Loss: 0.3969%\n",
      "Epoch [146/300], Step [15/23], Training Accuracy: 73.0208%, Training Loss: 0.3991%\n",
      "Epoch [146/300], Step [16/23], Training Accuracy: 73.2422%, Training Loss: 0.3984%\n",
      "Epoch [146/300], Step [17/23], Training Accuracy: 73.4375%, Training Loss: 0.3987%\n",
      "Epoch [146/300], Step [18/23], Training Accuracy: 73.6111%, Training Loss: 0.3987%\n",
      "Epoch [146/300], Step [19/23], Training Accuracy: 74.0954%, Training Loss: 0.3963%\n",
      "Epoch [146/300], Step [20/23], Training Accuracy: 74.2188%, Training Loss: 0.3942%\n",
      "Epoch [146/300], Step [21/23], Training Accuracy: 74.2560%, Training Loss: 0.3935%\n",
      "Epoch [146/300], Step [22/23], Training Accuracy: 74.2898%, Training Loss: 0.3930%\n",
      "Epoch [146/300], Step [23/23], Training Accuracy: 74.3572%, Training Loss: 0.3903%\n",
      "Epoch [147/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3590%\n",
      "Epoch [147/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3873%\n",
      "Epoch [147/300], Step [3/23], Training Accuracy: 72.3958%, Training Loss: 0.3970%\n",
      "Epoch [147/300], Step [4/23], Training Accuracy: 75.0000%, Training Loss: 0.3831%\n",
      "Epoch [147/300], Step [5/23], Training Accuracy: 74.3750%, Training Loss: 0.3850%\n",
      "Epoch [147/300], Step [6/23], Training Accuracy: 74.7396%, Training Loss: 0.3862%\n",
      "Epoch [147/300], Step [7/23], Training Accuracy: 75.8929%, Training Loss: 0.3881%\n",
      "Epoch [147/300], Step [8/23], Training Accuracy: 75.9766%, Training Loss: 0.3894%\n",
      "Epoch [147/300], Step [9/23], Training Accuracy: 74.8264%, Training Loss: 0.3983%\n",
      "Epoch [147/300], Step [10/23], Training Accuracy: 74.6875%, Training Loss: 0.3959%\n",
      "Epoch [147/300], Step [11/23], Training Accuracy: 74.7159%, Training Loss: 0.3971%\n",
      "Epoch [147/300], Step [12/23], Training Accuracy: 74.7396%, Training Loss: 0.3968%\n",
      "Epoch [147/300], Step [13/23], Training Accuracy: 74.2788%, Training Loss: 0.3992%\n",
      "Epoch [147/300], Step [14/23], Training Accuracy: 74.4420%, Training Loss: 0.3981%\n",
      "Epoch [147/300], Step [15/23], Training Accuracy: 74.0625%, Training Loss: 0.4015%\n",
      "Epoch [147/300], Step [16/23], Training Accuracy: 73.7305%, Training Loss: 0.4027%\n",
      "Epoch [147/300], Step [17/23], Training Accuracy: 73.7132%, Training Loss: 0.4023%\n",
      "Epoch [147/300], Step [18/23], Training Accuracy: 74.0451%, Training Loss: 0.4018%\n",
      "Epoch [147/300], Step [19/23], Training Accuracy: 73.8487%, Training Loss: 0.4019%\n",
      "Epoch [147/300], Step [20/23], Training Accuracy: 74.3750%, Training Loss: 0.3987%\n",
      "Epoch [147/300], Step [21/23], Training Accuracy: 74.1071%, Training Loss: 0.3983%\n",
      "Epoch [147/300], Step [22/23], Training Accuracy: 74.2898%, Training Loss: 0.3965%\n",
      "Epoch [147/300], Step [23/23], Training Accuracy: 74.2182%, Training Loss: 0.3933%\n",
      "Epoch [148/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3827%\n",
      "Epoch [148/300], Step [2/23], Training Accuracy: 78.1250%, Training Loss: 0.4016%\n",
      "Epoch [148/300], Step [3/23], Training Accuracy: 72.9167%, Training Loss: 0.4140%\n",
      "Epoch [148/300], Step [4/23], Training Accuracy: 75.7812%, Training Loss: 0.3909%\n",
      "Epoch [148/300], Step [5/23], Training Accuracy: 75.9375%, Training Loss: 0.3866%\n",
      "Epoch [148/300], Step [6/23], Training Accuracy: 76.0417%, Training Loss: 0.3869%\n",
      "Epoch [148/300], Step [7/23], Training Accuracy: 76.3393%, Training Loss: 0.3901%\n",
      "Epoch [148/300], Step [8/23], Training Accuracy: 76.3672%, Training Loss: 0.3913%\n",
      "Epoch [148/300], Step [9/23], Training Accuracy: 75.6944%, Training Loss: 0.3940%\n",
      "Epoch [148/300], Step [10/23], Training Accuracy: 75.9375%, Training Loss: 0.3937%\n",
      "Epoch [148/300], Step [11/23], Training Accuracy: 75.9943%, Training Loss: 0.3937%\n",
      "Epoch [148/300], Step [12/23], Training Accuracy: 75.7812%, Training Loss: 0.3944%\n",
      "Epoch [148/300], Step [13/23], Training Accuracy: 75.7212%, Training Loss: 0.3961%\n",
      "Epoch [148/300], Step [14/23], Training Accuracy: 75.7812%, Training Loss: 0.3963%\n",
      "Epoch [148/300], Step [15/23], Training Accuracy: 75.3125%, Training Loss: 0.4001%\n",
      "Epoch [148/300], Step [16/23], Training Accuracy: 75.0000%, Training Loss: 0.4004%\n",
      "Epoch [148/300], Step [17/23], Training Accuracy: 75.1838%, Training Loss: 0.3985%\n",
      "Epoch [148/300], Step [18/23], Training Accuracy: 74.7396%, Training Loss: 0.3977%\n",
      "Epoch [148/300], Step [19/23], Training Accuracy: 74.2599%, Training Loss: 0.3971%\n",
      "Epoch [148/300], Step [20/23], Training Accuracy: 74.4531%, Training Loss: 0.3956%\n",
      "Epoch [148/300], Step [21/23], Training Accuracy: 74.4048%, Training Loss: 0.3955%\n",
      "Epoch [148/300], Step [22/23], Training Accuracy: 74.5739%, Training Loss: 0.3943%\n",
      "Epoch [148/300], Step [23/23], Training Accuracy: 74.8436%, Training Loss: 0.3899%\n",
      "Epoch [149/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3456%\n",
      "Epoch [149/300], Step [2/23], Training Accuracy: 79.6875%, Training Loss: 0.3671%\n",
      "Epoch [149/300], Step [3/23], Training Accuracy: 77.6042%, Training Loss: 0.3794%\n",
      "Epoch [149/300], Step [4/23], Training Accuracy: 77.7344%, Training Loss: 0.3721%\n",
      "Epoch [149/300], Step [5/23], Training Accuracy: 74.3750%, Training Loss: 0.3784%\n",
      "Epoch [149/300], Step [6/23], Training Accuracy: 74.7396%, Training Loss: 0.3862%\n",
      "Epoch [149/300], Step [7/23], Training Accuracy: 75.2232%, Training Loss: 0.3895%\n",
      "Epoch [149/300], Step [8/23], Training Accuracy: 76.3672%, Training Loss: 0.3865%\n",
      "Epoch [149/300], Step [9/23], Training Accuracy: 75.6944%, Training Loss: 0.3916%\n",
      "Epoch [149/300], Step [10/23], Training Accuracy: 76.0938%, Training Loss: 0.3879%\n",
      "Epoch [149/300], Step [11/23], Training Accuracy: 75.2841%, Training Loss: 0.3909%\n",
      "Epoch [149/300], Step [12/23], Training Accuracy: 75.0000%, Training Loss: 0.3921%\n",
      "Epoch [149/300], Step [13/23], Training Accuracy: 74.3990%, Training Loss: 0.3948%\n",
      "Epoch [149/300], Step [14/23], Training Accuracy: 74.5536%, Training Loss: 0.3920%\n",
      "Epoch [149/300], Step [15/23], Training Accuracy: 74.2708%, Training Loss: 0.3950%\n",
      "Epoch [149/300], Step [16/23], Training Accuracy: 74.1211%, Training Loss: 0.3941%\n",
      "Epoch [149/300], Step [17/23], Training Accuracy: 74.0809%, Training Loss: 0.3935%\n",
      "Epoch [149/300], Step [18/23], Training Accuracy: 74.2188%, Training Loss: 0.3930%\n",
      "Epoch [149/300], Step [19/23], Training Accuracy: 74.0132%, Training Loss: 0.3938%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [149/300], Step [20/23], Training Accuracy: 73.9062%, Training Loss: 0.3934%\n",
      "Epoch [149/300], Step [21/23], Training Accuracy: 73.9583%, Training Loss: 0.3923%\n",
      "Epoch [149/300], Step [22/23], Training Accuracy: 74.0057%, Training Loss: 0.3920%\n",
      "Epoch [149/300], Step [23/23], Training Accuracy: 74.2877%, Training Loss: 0.3874%\n",
      "Epoch [150/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3855%\n",
      "Epoch [150/300], Step [2/23], Training Accuracy: 75.7812%, Training Loss: 0.4020%\n",
      "Epoch [150/300], Step [3/23], Training Accuracy: 72.9167%, Training Loss: 0.4080%\n",
      "Epoch [150/300], Step [4/23], Training Accuracy: 76.5625%, Training Loss: 0.3825%\n",
      "Epoch [150/300], Step [5/23], Training Accuracy: 75.0000%, Training Loss: 0.3833%\n",
      "Epoch [150/300], Step [6/23], Training Accuracy: 76.0417%, Training Loss: 0.3853%\n",
      "Epoch [150/300], Step [7/23], Training Accuracy: 75.4464%, Training Loss: 0.3927%\n",
      "Epoch [150/300], Step [8/23], Training Accuracy: 75.5859%, Training Loss: 0.3938%\n",
      "Epoch [150/300], Step [9/23], Training Accuracy: 74.1319%, Training Loss: 0.4007%\n",
      "Epoch [150/300], Step [10/23], Training Accuracy: 74.2188%, Training Loss: 0.3996%\n",
      "Epoch [150/300], Step [11/23], Training Accuracy: 74.2898%, Training Loss: 0.3970%\n",
      "Epoch [150/300], Step [12/23], Training Accuracy: 74.2188%, Training Loss: 0.3971%\n",
      "Epoch [150/300], Step [13/23], Training Accuracy: 74.0385%, Training Loss: 0.3975%\n",
      "Epoch [150/300], Step [14/23], Training Accuracy: 74.5536%, Training Loss: 0.3952%\n",
      "Epoch [150/300], Step [15/23], Training Accuracy: 74.2708%, Training Loss: 0.3974%\n",
      "Epoch [150/300], Step [16/23], Training Accuracy: 74.5117%, Training Loss: 0.3973%\n",
      "Epoch [150/300], Step [17/23], Training Accuracy: 74.2647%, Training Loss: 0.3971%\n",
      "Epoch [150/300], Step [18/23], Training Accuracy: 74.4792%, Training Loss: 0.3971%\n",
      "Epoch [150/300], Step [19/23], Training Accuracy: 74.9178%, Training Loss: 0.3955%\n",
      "Epoch [150/300], Step [20/23], Training Accuracy: 75.0000%, Training Loss: 0.3939%\n",
      "Epoch [150/300], Step [21/23], Training Accuracy: 74.7024%, Training Loss: 0.3933%\n",
      "Epoch [150/300], Step [22/23], Training Accuracy: 74.7869%, Training Loss: 0.3924%\n",
      "Epoch [150/300], Step [23/23], Training Accuracy: 74.7741%, Training Loss: 0.3889%\n",
      "Epoch [151/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3948%\n",
      "Epoch [151/300], Step [2/23], Training Accuracy: 71.8750%, Training Loss: 0.4134%\n",
      "Epoch [151/300], Step [3/23], Training Accuracy: 70.3125%, Training Loss: 0.4138%\n",
      "Epoch [151/300], Step [4/23], Training Accuracy: 71.0938%, Training Loss: 0.3982%\n",
      "Epoch [151/300], Step [5/23], Training Accuracy: 71.8750%, Training Loss: 0.3931%\n",
      "Epoch [151/300], Step [6/23], Training Accuracy: 73.1771%, Training Loss: 0.3940%\n",
      "Epoch [151/300], Step [7/23], Training Accuracy: 73.2143%, Training Loss: 0.3987%\n",
      "Epoch [151/300], Step [8/23], Training Accuracy: 74.6094%, Training Loss: 0.3967%\n",
      "Epoch [151/300], Step [9/23], Training Accuracy: 73.6111%, Training Loss: 0.4013%\n",
      "Epoch [151/300], Step [10/23], Training Accuracy: 73.9062%, Training Loss: 0.4005%\n",
      "Epoch [151/300], Step [11/23], Training Accuracy: 74.4318%, Training Loss: 0.3981%\n",
      "Epoch [151/300], Step [12/23], Training Accuracy: 74.2188%, Training Loss: 0.3974%\n",
      "Epoch [151/300], Step [13/23], Training Accuracy: 73.7981%, Training Loss: 0.3988%\n",
      "Epoch [151/300], Step [14/23], Training Accuracy: 74.5536%, Training Loss: 0.3955%\n",
      "Epoch [151/300], Step [15/23], Training Accuracy: 74.3750%, Training Loss: 0.3972%\n",
      "Epoch [151/300], Step [16/23], Training Accuracy: 74.6094%, Training Loss: 0.3973%\n",
      "Epoch [151/300], Step [17/23], Training Accuracy: 74.5404%, Training Loss: 0.3985%\n",
      "Epoch [151/300], Step [18/23], Training Accuracy: 74.8264%, Training Loss: 0.3980%\n",
      "Epoch [151/300], Step [19/23], Training Accuracy: 75.0822%, Training Loss: 0.3979%\n",
      "Epoch [151/300], Step [20/23], Training Accuracy: 75.3125%, Training Loss: 0.3970%\n",
      "Epoch [151/300], Step [21/23], Training Accuracy: 75.0744%, Training Loss: 0.3971%\n",
      "Epoch [151/300], Step [22/23], Training Accuracy: 75.1420%, Training Loss: 0.3960%\n",
      "Epoch [151/300], Step [23/23], Training Accuracy: 75.3996%, Training Loss: 0.3914%\n",
      "Epoch [152/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3790%\n",
      "Epoch [152/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.4074%\n",
      "Epoch [152/300], Step [3/23], Training Accuracy: 73.4375%, Training Loss: 0.4154%\n",
      "Epoch [152/300], Step [4/23], Training Accuracy: 75.7812%, Training Loss: 0.3991%\n",
      "Epoch [152/300], Step [5/23], Training Accuracy: 74.3750%, Training Loss: 0.3983%\n",
      "Epoch [152/300], Step [6/23], Training Accuracy: 74.4792%, Training Loss: 0.3988%\n",
      "Epoch [152/300], Step [7/23], Training Accuracy: 75.2232%, Training Loss: 0.4017%\n",
      "Epoch [152/300], Step [8/23], Training Accuracy: 75.1953%, Training Loss: 0.4000%\n",
      "Epoch [152/300], Step [9/23], Training Accuracy: 73.6111%, Training Loss: 0.4063%\n",
      "Epoch [152/300], Step [10/23], Training Accuracy: 74.0625%, Training Loss: 0.4031%\n",
      "Epoch [152/300], Step [11/23], Training Accuracy: 74.0057%, Training Loss: 0.4021%\n",
      "Epoch [152/300], Step [12/23], Training Accuracy: 73.9583%, Training Loss: 0.4029%\n",
      "Epoch [152/300], Step [13/23], Training Accuracy: 74.0385%, Training Loss: 0.4034%\n",
      "Epoch [152/300], Step [14/23], Training Accuracy: 74.1071%, Training Loss: 0.3998%\n",
      "Epoch [152/300], Step [15/23], Training Accuracy: 73.7500%, Training Loss: 0.4023%\n",
      "Epoch [152/300], Step [16/23], Training Accuracy: 73.7305%, Training Loss: 0.4023%\n",
      "Epoch [152/300], Step [17/23], Training Accuracy: 73.9890%, Training Loss: 0.4003%\n",
      "Epoch [152/300], Step [18/23], Training Accuracy: 73.6111%, Training Loss: 0.4007%\n",
      "Epoch [152/300], Step [19/23], Training Accuracy: 73.4375%, Training Loss: 0.4008%\n",
      "Epoch [152/300], Step [20/23], Training Accuracy: 73.3594%, Training Loss: 0.3995%\n",
      "Epoch [152/300], Step [21/23], Training Accuracy: 73.5863%, Training Loss: 0.3987%\n",
      "Epoch [152/300], Step [22/23], Training Accuracy: 73.8636%, Training Loss: 0.3974%\n",
      "Epoch [152/300], Step [23/23], Training Accuracy: 73.9402%, Training Loss: 0.3935%\n",
      "Epoch [153/300], Step [1/23], Training Accuracy: 82.8125%, Training Loss: 0.3523%\n",
      "Epoch [153/300], Step [2/23], Training Accuracy: 78.1250%, Training Loss: 0.3837%\n",
      "Epoch [153/300], Step [3/23], Training Accuracy: 73.9583%, Training Loss: 0.3943%\n",
      "Epoch [153/300], Step [4/23], Training Accuracy: 75.3906%, Training Loss: 0.3836%\n",
      "Epoch [153/300], Step [5/23], Training Accuracy: 74.3750%, Training Loss: 0.3862%\n",
      "Epoch [153/300], Step [6/23], Training Accuracy: 75.0000%, Training Loss: 0.3845%\n",
      "Epoch [153/300], Step [7/23], Training Accuracy: 74.5536%, Training Loss: 0.3924%\n",
      "Epoch [153/300], Step [8/23], Training Accuracy: 75.1953%, Training Loss: 0.3874%\n",
      "Epoch [153/300], Step [9/23], Training Accuracy: 74.1319%, Training Loss: 0.3932%\n",
      "Epoch [153/300], Step [10/23], Training Accuracy: 74.5312%, Training Loss: 0.3905%\n",
      "Epoch [153/300], Step [11/23], Training Accuracy: 74.8580%, Training Loss: 0.3905%\n",
      "Epoch [153/300], Step [12/23], Training Accuracy: 74.4792%, Training Loss: 0.3933%\n",
      "Epoch [153/300], Step [13/23], Training Accuracy: 74.1587%, Training Loss: 0.3953%\n",
      "Epoch [153/300], Step [14/23], Training Accuracy: 74.3304%, Training Loss: 0.3928%\n",
      "Epoch [153/300], Step [15/23], Training Accuracy: 74.2708%, Training Loss: 0.3952%\n",
      "Epoch [153/300], Step [16/23], Training Accuracy: 74.2188%, Training Loss: 0.3951%\n",
      "Epoch [153/300], Step [17/23], Training Accuracy: 74.0809%, Training Loss: 0.3950%\n",
      "Epoch [153/300], Step [18/23], Training Accuracy: 73.9583%, Training Loss: 0.3955%\n",
      "Epoch [153/300], Step [19/23], Training Accuracy: 73.9309%, Training Loss: 0.3952%\n",
      "Epoch [153/300], Step [20/23], Training Accuracy: 74.0625%, Training Loss: 0.3936%\n",
      "Epoch [153/300], Step [21/23], Training Accuracy: 74.0327%, Training Loss: 0.3937%\n",
      "Epoch [153/300], Step [22/23], Training Accuracy: 74.0767%, Training Loss: 0.3929%\n",
      "Epoch [153/300], Step [23/23], Training Accuracy: 74.0792%, Training Loss: 0.3896%\n",
      "Epoch [154/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3787%\n",
      "Epoch [154/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.3959%\n",
      "Epoch [154/300], Step [3/23], Training Accuracy: 72.3958%, Training Loss: 0.3982%\n",
      "Epoch [154/300], Step [4/23], Training Accuracy: 75.3906%, Training Loss: 0.3843%\n",
      "Epoch [154/300], Step [5/23], Training Accuracy: 73.4375%, Training Loss: 0.3886%\n",
      "Epoch [154/300], Step [6/23], Training Accuracy: 73.4375%, Training Loss: 0.3881%\n",
      "Epoch [154/300], Step [7/23], Training Accuracy: 72.7679%, Training Loss: 0.3963%\n",
      "Epoch [154/300], Step [8/23], Training Accuracy: 72.4609%, Training Loss: 0.3958%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [154/300], Step [9/23], Training Accuracy: 71.5278%, Training Loss: 0.4009%\n",
      "Epoch [154/300], Step [10/23], Training Accuracy: 71.4062%, Training Loss: 0.3993%\n",
      "Epoch [154/300], Step [11/23], Training Accuracy: 72.0170%, Training Loss: 0.3986%\n",
      "Epoch [154/300], Step [12/23], Training Accuracy: 72.0052%, Training Loss: 0.3984%\n",
      "Epoch [154/300], Step [13/23], Training Accuracy: 71.8750%, Training Loss: 0.4002%\n",
      "Epoch [154/300], Step [14/23], Training Accuracy: 72.0982%, Training Loss: 0.3974%\n",
      "Epoch [154/300], Step [15/23], Training Accuracy: 71.7708%, Training Loss: 0.4014%\n",
      "Epoch [154/300], Step [16/23], Training Accuracy: 72.0703%, Training Loss: 0.4004%\n",
      "Epoch [154/300], Step [17/23], Training Accuracy: 72.1507%, Training Loss: 0.3999%\n",
      "Epoch [154/300], Step [18/23], Training Accuracy: 72.3090%, Training Loss: 0.3998%\n",
      "Epoch [154/300], Step [19/23], Training Accuracy: 72.3684%, Training Loss: 0.3984%\n",
      "Epoch [154/300], Step [20/23], Training Accuracy: 72.7344%, Training Loss: 0.3965%\n",
      "Epoch [154/300], Step [21/23], Training Accuracy: 72.8423%, Training Loss: 0.3966%\n",
      "Epoch [154/300], Step [22/23], Training Accuracy: 73.1534%, Training Loss: 0.3959%\n",
      "Epoch [154/300], Step [23/23], Training Accuracy: 73.2453%, Training Loss: 0.3920%\n",
      "Epoch [155/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3834%\n",
      "Epoch [155/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.4023%\n",
      "Epoch [155/300], Step [3/23], Training Accuracy: 71.3542%, Training Loss: 0.4139%\n",
      "Epoch [155/300], Step [4/23], Training Accuracy: 71.8750%, Training Loss: 0.4013%\n",
      "Epoch [155/300], Step [5/23], Training Accuracy: 72.1875%, Training Loss: 0.3955%\n",
      "Epoch [155/300], Step [6/23], Training Accuracy: 73.9583%, Training Loss: 0.3923%\n",
      "Epoch [155/300], Step [7/23], Training Accuracy: 74.3304%, Training Loss: 0.3932%\n",
      "Epoch [155/300], Step [8/23], Training Accuracy: 75.0000%, Training Loss: 0.3932%\n",
      "Epoch [155/300], Step [9/23], Training Accuracy: 74.1319%, Training Loss: 0.4005%\n",
      "Epoch [155/300], Step [10/23], Training Accuracy: 74.2188%, Training Loss: 0.3964%\n",
      "Epoch [155/300], Step [11/23], Training Accuracy: 74.4318%, Training Loss: 0.3961%\n",
      "Epoch [155/300], Step [12/23], Training Accuracy: 74.3490%, Training Loss: 0.3975%\n",
      "Epoch [155/300], Step [13/23], Training Accuracy: 73.6779%, Training Loss: 0.3991%\n",
      "Epoch [155/300], Step [14/23], Training Accuracy: 74.1071%, Training Loss: 0.3962%\n",
      "Epoch [155/300], Step [15/23], Training Accuracy: 73.5417%, Training Loss: 0.4000%\n",
      "Epoch [155/300], Step [16/23], Training Accuracy: 73.4375%, Training Loss: 0.4001%\n",
      "Epoch [155/300], Step [17/23], Training Accuracy: 73.8051%, Training Loss: 0.3991%\n",
      "Epoch [155/300], Step [18/23], Training Accuracy: 73.6979%, Training Loss: 0.3984%\n",
      "Epoch [155/300], Step [19/23], Training Accuracy: 74.0132%, Training Loss: 0.3971%\n",
      "Epoch [155/300], Step [20/23], Training Accuracy: 74.2188%, Training Loss: 0.3959%\n",
      "Epoch [155/300], Step [21/23], Training Accuracy: 73.8095%, Training Loss: 0.3978%\n",
      "Epoch [155/300], Step [22/23], Training Accuracy: 73.7216%, Training Loss: 0.3971%\n",
      "Epoch [155/300], Step [23/23], Training Accuracy: 73.9402%, Training Loss: 0.3946%\n",
      "Epoch [156/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3736%\n",
      "Epoch [156/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.4132%\n",
      "Epoch [156/300], Step [3/23], Training Accuracy: 73.9583%, Training Loss: 0.4131%\n",
      "Epoch [156/300], Step [4/23], Training Accuracy: 75.7812%, Training Loss: 0.3947%\n",
      "Epoch [156/300], Step [5/23], Training Accuracy: 73.4375%, Training Loss: 0.3897%\n",
      "Epoch [156/300], Step [6/23], Training Accuracy: 73.9583%, Training Loss: 0.3874%\n",
      "Epoch [156/300], Step [7/23], Training Accuracy: 74.1071%, Training Loss: 0.3926%\n",
      "Epoch [156/300], Step [8/23], Training Accuracy: 74.6094%, Training Loss: 0.3928%\n",
      "Epoch [156/300], Step [9/23], Training Accuracy: 74.3056%, Training Loss: 0.3982%\n",
      "Epoch [156/300], Step [10/23], Training Accuracy: 75.0000%, Training Loss: 0.3933%\n",
      "Epoch [156/300], Step [11/23], Training Accuracy: 75.5682%, Training Loss: 0.3942%\n",
      "Epoch [156/300], Step [12/23], Training Accuracy: 75.0000%, Training Loss: 0.3956%\n",
      "Epoch [156/300], Step [13/23], Training Accuracy: 74.6394%, Training Loss: 0.3980%\n",
      "Epoch [156/300], Step [14/23], Training Accuracy: 74.5536%, Training Loss: 0.3954%\n",
      "Epoch [156/300], Step [15/23], Training Accuracy: 74.1667%, Training Loss: 0.3974%\n",
      "Epoch [156/300], Step [16/23], Training Accuracy: 73.7305%, Training Loss: 0.3976%\n",
      "Epoch [156/300], Step [17/23], Training Accuracy: 73.9890%, Training Loss: 0.3971%\n",
      "Epoch [156/300], Step [18/23], Training Accuracy: 73.8715%, Training Loss: 0.3987%\n",
      "Epoch [156/300], Step [19/23], Training Accuracy: 73.7664%, Training Loss: 0.3995%\n",
      "Epoch [156/300], Step [20/23], Training Accuracy: 74.1406%, Training Loss: 0.3970%\n",
      "Epoch [156/300], Step [21/23], Training Accuracy: 74.4792%, Training Loss: 0.3966%\n",
      "Epoch [156/300], Step [22/23], Training Accuracy: 74.8580%, Training Loss: 0.3949%\n",
      "Epoch [156/300], Step [23/23], Training Accuracy: 74.9131%, Training Loss: 0.3921%\n",
      "Epoch [157/300], Step [1/23], Training Accuracy: 71.8750%, Training Loss: 0.3948%\n",
      "Epoch [157/300], Step [2/23], Training Accuracy: 70.3125%, Training Loss: 0.4140%\n",
      "Epoch [157/300], Step [3/23], Training Accuracy: 72.9167%, Training Loss: 0.4063%\n",
      "Epoch [157/300], Step [4/23], Training Accuracy: 75.3906%, Training Loss: 0.3917%\n",
      "Epoch [157/300], Step [5/23], Training Accuracy: 74.6875%, Training Loss: 0.3878%\n",
      "Epoch [157/300], Step [6/23], Training Accuracy: 75.7812%, Training Loss: 0.3944%\n",
      "Epoch [157/300], Step [7/23], Training Accuracy: 75.2232%, Training Loss: 0.4017%\n",
      "Epoch [157/300], Step [8/23], Training Accuracy: 75.0000%, Training Loss: 0.4009%\n",
      "Epoch [157/300], Step [9/23], Training Accuracy: 74.4792%, Training Loss: 0.4019%\n",
      "Epoch [157/300], Step [10/23], Training Accuracy: 74.2188%, Training Loss: 0.4001%\n",
      "Epoch [157/300], Step [11/23], Training Accuracy: 74.0057%, Training Loss: 0.4003%\n",
      "Epoch [157/300], Step [12/23], Training Accuracy: 73.9583%, Training Loss: 0.3995%\n",
      "Epoch [157/300], Step [13/23], Training Accuracy: 73.4375%, Training Loss: 0.4009%\n",
      "Epoch [157/300], Step [14/23], Training Accuracy: 73.4375%, Training Loss: 0.4000%\n",
      "Epoch [157/300], Step [15/23], Training Accuracy: 72.7083%, Training Loss: 0.4046%\n",
      "Epoch [157/300], Step [16/23], Training Accuracy: 72.7539%, Training Loss: 0.4045%\n",
      "Epoch [157/300], Step [17/23], Training Accuracy: 72.8860%, Training Loss: 0.4032%\n",
      "Epoch [157/300], Step [18/23], Training Accuracy: 72.7431%, Training Loss: 0.4036%\n",
      "Epoch [157/300], Step [19/23], Training Accuracy: 72.9441%, Training Loss: 0.4016%\n",
      "Epoch [157/300], Step [20/23], Training Accuracy: 73.2031%, Training Loss: 0.3992%\n",
      "Epoch [157/300], Step [21/23], Training Accuracy: 73.0655%, Training Loss: 0.4004%\n",
      "Epoch [157/300], Step [22/23], Training Accuracy: 73.2955%, Training Loss: 0.3987%\n",
      "Epoch [157/300], Step [23/23], Training Accuracy: 73.3148%, Training Loss: 0.3955%\n",
      "Epoch [158/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3817%\n",
      "Epoch [158/300], Step [2/23], Training Accuracy: 72.6562%, Training Loss: 0.3937%\n",
      "Epoch [158/300], Step [3/23], Training Accuracy: 68.7500%, Training Loss: 0.4061%\n",
      "Epoch [158/300], Step [4/23], Training Accuracy: 71.0938%, Training Loss: 0.3911%\n",
      "Epoch [158/300], Step [5/23], Training Accuracy: 69.6875%, Training Loss: 0.3969%\n",
      "Epoch [158/300], Step [6/23], Training Accuracy: 71.3542%, Training Loss: 0.3948%\n",
      "Epoch [158/300], Step [7/23], Training Accuracy: 72.0982%, Training Loss: 0.4006%\n",
      "Epoch [158/300], Step [8/23], Training Accuracy: 73.2422%, Training Loss: 0.4008%\n",
      "Epoch [158/300], Step [9/23], Training Accuracy: 72.9167%, Training Loss: 0.4016%\n",
      "Epoch [158/300], Step [10/23], Training Accuracy: 73.2812%, Training Loss: 0.4004%\n",
      "Epoch [158/300], Step [11/23], Training Accuracy: 73.0114%, Training Loss: 0.4000%\n",
      "Epoch [158/300], Step [12/23], Training Accuracy: 73.0469%, Training Loss: 0.4010%\n",
      "Epoch [158/300], Step [13/23], Training Accuracy: 72.8365%, Training Loss: 0.4012%\n",
      "Epoch [158/300], Step [14/23], Training Accuracy: 73.3259%, Training Loss: 0.3996%\n",
      "Epoch [158/300], Step [15/23], Training Accuracy: 73.0208%, Training Loss: 0.4002%\n",
      "Epoch [158/300], Step [16/23], Training Accuracy: 73.1445%, Training Loss: 0.3988%\n",
      "Epoch [158/300], Step [17/23], Training Accuracy: 73.1618%, Training Loss: 0.3991%\n",
      "Epoch [158/300], Step [18/23], Training Accuracy: 73.4375%, Training Loss: 0.3993%\n",
      "Epoch [158/300], Step [19/23], Training Accuracy: 73.1086%, Training Loss: 0.3995%\n",
      "Epoch [158/300], Step [20/23], Training Accuracy: 73.5938%, Training Loss: 0.3970%\n",
      "Epoch [158/300], Step [21/23], Training Accuracy: 73.5119%, Training Loss: 0.3971%\n",
      "Epoch [158/300], Step [22/23], Training Accuracy: 73.5795%, Training Loss: 0.3956%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [158/300], Step [23/23], Training Accuracy: 73.8013%, Training Loss: 0.3921%\n",
      "Epoch [159/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3871%\n",
      "Epoch [159/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3969%\n",
      "Epoch [159/300], Step [3/23], Training Accuracy: 73.9583%, Training Loss: 0.4011%\n",
      "Epoch [159/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.3858%\n",
      "Epoch [159/300], Step [5/23], Training Accuracy: 72.1875%, Training Loss: 0.3892%\n",
      "Epoch [159/300], Step [6/23], Training Accuracy: 71.8750%, Training Loss: 0.3898%\n",
      "Epoch [159/300], Step [7/23], Training Accuracy: 72.5446%, Training Loss: 0.3935%\n",
      "Epoch [159/300], Step [8/23], Training Accuracy: 73.6328%, Training Loss: 0.3928%\n",
      "Epoch [159/300], Step [9/23], Training Accuracy: 72.5694%, Training Loss: 0.3989%\n",
      "Epoch [159/300], Step [10/23], Training Accuracy: 73.1250%, Training Loss: 0.3952%\n",
      "Epoch [159/300], Step [11/23], Training Accuracy: 73.8636%, Training Loss: 0.3928%\n",
      "Epoch [159/300], Step [12/23], Training Accuracy: 73.9583%, Training Loss: 0.3926%\n",
      "Epoch [159/300], Step [13/23], Training Accuracy: 74.0385%, Training Loss: 0.3944%\n",
      "Epoch [159/300], Step [14/23], Training Accuracy: 74.2188%, Training Loss: 0.3934%\n",
      "Epoch [159/300], Step [15/23], Training Accuracy: 73.6458%, Training Loss: 0.3962%\n",
      "Epoch [159/300], Step [16/23], Training Accuracy: 73.6328%, Training Loss: 0.3966%\n",
      "Epoch [159/300], Step [17/23], Training Accuracy: 73.7132%, Training Loss: 0.3969%\n",
      "Epoch [159/300], Step [18/23], Training Accuracy: 73.8715%, Training Loss: 0.3975%\n",
      "Epoch [159/300], Step [19/23], Training Accuracy: 73.8487%, Training Loss: 0.3981%\n",
      "Epoch [159/300], Step [20/23], Training Accuracy: 74.2969%, Training Loss: 0.3952%\n",
      "Epoch [159/300], Step [21/23], Training Accuracy: 74.3304%, Training Loss: 0.3952%\n",
      "Epoch [159/300], Step [22/23], Training Accuracy: 74.3608%, Training Loss: 0.3946%\n",
      "Epoch [159/300], Step [23/23], Training Accuracy: 74.4962%, Training Loss: 0.3919%\n",
      "Epoch [160/300], Step [1/23], Training Accuracy: 73.4375%, Training Loss: 0.3595%\n",
      "Epoch [160/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.3830%\n",
      "Epoch [160/300], Step [3/23], Training Accuracy: 73.9583%, Training Loss: 0.3899%\n",
      "Epoch [160/300], Step [4/23], Training Accuracy: 75.7812%, Training Loss: 0.3804%\n",
      "Epoch [160/300], Step [5/23], Training Accuracy: 76.5625%, Training Loss: 0.3726%\n",
      "Epoch [160/300], Step [6/23], Training Accuracy: 76.5625%, Training Loss: 0.3734%\n",
      "Epoch [160/300], Step [7/23], Training Accuracy: 75.8929%, Training Loss: 0.3806%\n",
      "Epoch [160/300], Step [8/23], Training Accuracy: 75.5859%, Training Loss: 0.3812%\n",
      "Epoch [160/300], Step [9/23], Training Accuracy: 73.6111%, Training Loss: 0.3903%\n",
      "Epoch [160/300], Step [10/23], Training Accuracy: 73.7500%, Training Loss: 0.3900%\n",
      "Epoch [160/300], Step [11/23], Training Accuracy: 74.1477%, Training Loss: 0.3902%\n",
      "Epoch [160/300], Step [12/23], Training Accuracy: 74.4792%, Training Loss: 0.3876%\n",
      "Epoch [160/300], Step [13/23], Training Accuracy: 73.7981%, Training Loss: 0.3906%\n",
      "Epoch [160/300], Step [14/23], Training Accuracy: 73.9955%, Training Loss: 0.3890%\n",
      "Epoch [160/300], Step [15/23], Training Accuracy: 73.6458%, Training Loss: 0.3927%\n",
      "Epoch [160/300], Step [16/23], Training Accuracy: 73.3398%, Training Loss: 0.3927%\n",
      "Epoch [160/300], Step [17/23], Training Accuracy: 73.4375%, Training Loss: 0.3937%\n",
      "Epoch [160/300], Step [18/23], Training Accuracy: 73.3507%, Training Loss: 0.3943%\n",
      "Epoch [160/300], Step [19/23], Training Accuracy: 73.5197%, Training Loss: 0.3923%\n",
      "Epoch [160/300], Step [20/23], Training Accuracy: 73.6719%, Training Loss: 0.3911%\n",
      "Epoch [160/300], Step [21/23], Training Accuracy: 73.6607%, Training Loss: 0.3919%\n",
      "Epoch [160/300], Step [22/23], Training Accuracy: 73.5085%, Training Loss: 0.3912%\n",
      "Epoch [160/300], Step [23/23], Training Accuracy: 73.7318%, Training Loss: 0.3881%\n",
      "Epoch [161/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3815%\n",
      "Epoch [161/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.4098%\n",
      "Epoch [161/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.4105%\n",
      "Epoch [161/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.3951%\n",
      "Epoch [161/300], Step [5/23], Training Accuracy: 73.1250%, Training Loss: 0.3945%\n",
      "Epoch [161/300], Step [6/23], Training Accuracy: 74.7396%, Training Loss: 0.3915%\n",
      "Epoch [161/300], Step [7/23], Training Accuracy: 74.7768%, Training Loss: 0.3948%\n",
      "Epoch [161/300], Step [8/23], Training Accuracy: 75.1953%, Training Loss: 0.3967%\n",
      "Epoch [161/300], Step [9/23], Training Accuracy: 74.3056%, Training Loss: 0.4031%\n",
      "Epoch [161/300], Step [10/23], Training Accuracy: 74.3750%, Training Loss: 0.4015%\n",
      "Epoch [161/300], Step [11/23], Training Accuracy: 74.1477%, Training Loss: 0.4024%\n",
      "Epoch [161/300], Step [12/23], Training Accuracy: 74.0885%, Training Loss: 0.4030%\n",
      "Epoch [161/300], Step [13/23], Training Accuracy: 74.1587%, Training Loss: 0.4045%\n",
      "Epoch [161/300], Step [14/23], Training Accuracy: 74.1071%, Training Loss: 0.4016%\n",
      "Epoch [161/300], Step [15/23], Training Accuracy: 73.8542%, Training Loss: 0.4032%\n",
      "Epoch [161/300], Step [16/23], Training Accuracy: 73.2422%, Training Loss: 0.4052%\n",
      "Epoch [161/300], Step [17/23], Training Accuracy: 73.4375%, Training Loss: 0.4035%\n",
      "Epoch [161/300], Step [18/23], Training Accuracy: 73.3507%, Training Loss: 0.4023%\n",
      "Epoch [161/300], Step [19/23], Training Accuracy: 73.2730%, Training Loss: 0.4014%\n",
      "Epoch [161/300], Step [20/23], Training Accuracy: 73.6719%, Training Loss: 0.3983%\n",
      "Epoch [161/300], Step [21/23], Training Accuracy: 73.2887%, Training Loss: 0.3984%\n",
      "Epoch [161/300], Step [22/23], Training Accuracy: 73.4375%, Training Loss: 0.3975%\n",
      "Epoch [161/300], Step [23/23], Training Accuracy: 73.5928%, Training Loss: 0.3941%\n",
      "Epoch [162/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3796%\n",
      "Epoch [162/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3834%\n",
      "Epoch [162/300], Step [3/23], Training Accuracy: 72.9167%, Training Loss: 0.3959%\n",
      "Epoch [162/300], Step [4/23], Training Accuracy: 75.3906%, Training Loss: 0.3806%\n",
      "Epoch [162/300], Step [5/23], Training Accuracy: 75.0000%, Training Loss: 0.3796%\n",
      "Epoch [162/300], Step [6/23], Training Accuracy: 75.7812%, Training Loss: 0.3831%\n",
      "Epoch [162/300], Step [7/23], Training Accuracy: 75.4464%, Training Loss: 0.3894%\n",
      "Epoch [162/300], Step [8/23], Training Accuracy: 75.7812%, Training Loss: 0.3865%\n",
      "Epoch [162/300], Step [9/23], Training Accuracy: 74.3056%, Training Loss: 0.3951%\n",
      "Epoch [162/300], Step [10/23], Training Accuracy: 74.0625%, Training Loss: 0.3950%\n",
      "Epoch [162/300], Step [11/23], Training Accuracy: 74.4318%, Training Loss: 0.3969%\n",
      "Epoch [162/300], Step [12/23], Training Accuracy: 74.6094%, Training Loss: 0.3972%\n",
      "Epoch [162/300], Step [13/23], Training Accuracy: 74.1587%, Training Loss: 0.4014%\n",
      "Epoch [162/300], Step [14/23], Training Accuracy: 74.3304%, Training Loss: 0.3980%\n",
      "Epoch [162/300], Step [15/23], Training Accuracy: 73.7500%, Training Loss: 0.4014%\n",
      "Epoch [162/300], Step [16/23], Training Accuracy: 73.6328%, Training Loss: 0.4009%\n",
      "Epoch [162/300], Step [17/23], Training Accuracy: 73.7132%, Training Loss: 0.3997%\n",
      "Epoch [162/300], Step [18/23], Training Accuracy: 73.8715%, Training Loss: 0.3994%\n",
      "Epoch [162/300], Step [19/23], Training Accuracy: 74.0954%, Training Loss: 0.3984%\n",
      "Epoch [162/300], Step [20/23], Training Accuracy: 74.2969%, Training Loss: 0.3966%\n",
      "Epoch [162/300], Step [21/23], Training Accuracy: 74.1815%, Training Loss: 0.3969%\n",
      "Epoch [162/300], Step [22/23], Training Accuracy: 74.2898%, Training Loss: 0.3974%\n",
      "Epoch [162/300], Step [23/23], Training Accuracy: 74.4267%, Training Loss: 0.3927%\n",
      "Epoch [163/300], Step [1/23], Training Accuracy: 81.2500%, Training Loss: 0.3783%\n",
      "Epoch [163/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3961%\n",
      "Epoch [163/300], Step [3/23], Training Accuracy: 73.9583%, Training Loss: 0.4048%\n",
      "Epoch [163/300], Step [4/23], Training Accuracy: 75.0000%, Training Loss: 0.3943%\n",
      "Epoch [163/300], Step [5/23], Training Accuracy: 73.7500%, Training Loss: 0.3945%\n",
      "Epoch [163/300], Step [6/23], Training Accuracy: 74.7396%, Training Loss: 0.3940%\n",
      "Epoch [163/300], Step [7/23], Training Accuracy: 75.2232%, Training Loss: 0.3940%\n",
      "Epoch [163/300], Step [8/23], Training Accuracy: 75.9766%, Training Loss: 0.3937%\n",
      "Epoch [163/300], Step [9/23], Training Accuracy: 75.6944%, Training Loss: 0.3959%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [163/300], Step [10/23], Training Accuracy: 76.0938%, Training Loss: 0.3958%\n",
      "Epoch [163/300], Step [11/23], Training Accuracy: 76.5625%, Training Loss: 0.3929%\n",
      "Epoch [163/300], Step [12/23], Training Accuracy: 76.0417%, Training Loss: 0.3922%\n",
      "Epoch [163/300], Step [13/23], Training Accuracy: 75.8413%, Training Loss: 0.3926%\n",
      "Epoch [163/300], Step [14/23], Training Accuracy: 76.2277%, Training Loss: 0.3916%\n",
      "Epoch [163/300], Step [15/23], Training Accuracy: 75.8333%, Training Loss: 0.3950%\n",
      "Epoch [163/300], Step [16/23], Training Accuracy: 75.2930%, Training Loss: 0.3956%\n",
      "Epoch [163/300], Step [17/23], Training Accuracy: 75.0919%, Training Loss: 0.3958%\n",
      "Epoch [163/300], Step [18/23], Training Accuracy: 75.0000%, Training Loss: 0.3961%\n",
      "Epoch [163/300], Step [19/23], Training Accuracy: 74.8355%, Training Loss: 0.3955%\n",
      "Epoch [163/300], Step [20/23], Training Accuracy: 75.1562%, Training Loss: 0.3931%\n",
      "Epoch [163/300], Step [21/23], Training Accuracy: 75.0744%, Training Loss: 0.3918%\n",
      "Epoch [163/300], Step [22/23], Training Accuracy: 75.2131%, Training Loss: 0.3909%\n",
      "Epoch [163/300], Step [23/23], Training Accuracy: 75.1216%, Training Loss: 0.3882%\n",
      "Epoch [164/300], Step [1/23], Training Accuracy: 70.3125%, Training Loss: 0.3850%\n",
      "Epoch [164/300], Step [2/23], Training Accuracy: 67.9688%, Training Loss: 0.4142%\n",
      "Epoch [164/300], Step [3/23], Training Accuracy: 69.2708%, Training Loss: 0.4162%\n",
      "Epoch [164/300], Step [4/23], Training Accuracy: 71.8750%, Training Loss: 0.4015%\n",
      "Epoch [164/300], Step [5/23], Training Accuracy: 72.8125%, Training Loss: 0.3954%\n",
      "Epoch [164/300], Step [6/23], Training Accuracy: 72.9167%, Training Loss: 0.3961%\n",
      "Epoch [164/300], Step [7/23], Training Accuracy: 73.6607%, Training Loss: 0.3994%\n",
      "Epoch [164/300], Step [8/23], Training Accuracy: 74.2188%, Training Loss: 0.3969%\n",
      "Epoch [164/300], Step [9/23], Training Accuracy: 72.5694%, Training Loss: 0.4035%\n",
      "Epoch [164/300], Step [10/23], Training Accuracy: 72.6562%, Training Loss: 0.4023%\n",
      "Epoch [164/300], Step [11/23], Training Accuracy: 72.7273%, Training Loss: 0.4001%\n",
      "Epoch [164/300], Step [12/23], Training Accuracy: 72.5260%, Training Loss: 0.4013%\n",
      "Epoch [164/300], Step [13/23], Training Accuracy: 72.9567%, Training Loss: 0.4005%\n",
      "Epoch [164/300], Step [14/23], Training Accuracy: 73.5491%, Training Loss: 0.3980%\n",
      "Epoch [164/300], Step [15/23], Training Accuracy: 72.7083%, Training Loss: 0.4015%\n",
      "Epoch [164/300], Step [16/23], Training Accuracy: 72.5586%, Training Loss: 0.4016%\n",
      "Epoch [164/300], Step [17/23], Training Accuracy: 72.5184%, Training Loss: 0.4010%\n",
      "Epoch [164/300], Step [18/23], Training Accuracy: 72.3958%, Training Loss: 0.4019%\n",
      "Epoch [164/300], Step [19/23], Training Accuracy: 72.7796%, Training Loss: 0.4009%\n",
      "Epoch [164/300], Step [20/23], Training Accuracy: 73.0469%, Training Loss: 0.3990%\n",
      "Epoch [164/300], Step [21/23], Training Accuracy: 72.9911%, Training Loss: 0.3996%\n",
      "Epoch [164/300], Step [22/23], Training Accuracy: 73.3665%, Training Loss: 0.3973%\n",
      "Epoch [164/300], Step [23/23], Training Accuracy: 73.3843%, Training Loss: 0.3948%\n",
      "Epoch [165/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3638%\n",
      "Epoch [165/300], Step [2/23], Training Accuracy: 72.6562%, Training Loss: 0.3965%\n",
      "Epoch [165/300], Step [3/23], Training Accuracy: 72.3958%, Training Loss: 0.4033%\n",
      "Epoch [165/300], Step [4/23], Training Accuracy: 74.6094%, Training Loss: 0.3915%\n",
      "Epoch [165/300], Step [5/23], Training Accuracy: 73.4375%, Training Loss: 0.3909%\n",
      "Epoch [165/300], Step [6/23], Training Accuracy: 74.4792%, Training Loss: 0.3841%\n",
      "Epoch [165/300], Step [7/23], Training Accuracy: 74.3304%, Training Loss: 0.3887%\n",
      "Epoch [165/300], Step [8/23], Training Accuracy: 75.0000%, Training Loss: 0.3901%\n",
      "Epoch [165/300], Step [9/23], Training Accuracy: 73.7847%, Training Loss: 0.3965%\n",
      "Epoch [165/300], Step [10/23], Training Accuracy: 73.4375%, Training Loss: 0.3969%\n",
      "Epoch [165/300], Step [11/23], Training Accuracy: 73.7216%, Training Loss: 0.3974%\n",
      "Epoch [165/300], Step [12/23], Training Accuracy: 73.5677%, Training Loss: 0.3974%\n",
      "Epoch [165/300], Step [13/23], Training Accuracy: 73.1971%, Training Loss: 0.3993%\n",
      "Epoch [165/300], Step [14/23], Training Accuracy: 73.2143%, Training Loss: 0.3975%\n",
      "Epoch [165/300], Step [15/23], Training Accuracy: 73.2292%, Training Loss: 0.3977%\n",
      "Epoch [165/300], Step [16/23], Training Accuracy: 73.0469%, Training Loss: 0.3980%\n",
      "Epoch [165/300], Step [17/23], Training Accuracy: 72.9779%, Training Loss: 0.3969%\n",
      "Epoch [165/300], Step [18/23], Training Accuracy: 73.1771%, Training Loss: 0.3972%\n",
      "Epoch [165/300], Step [19/23], Training Accuracy: 73.3553%, Training Loss: 0.3978%\n",
      "Epoch [165/300], Step [20/23], Training Accuracy: 73.5938%, Training Loss: 0.3969%\n",
      "Epoch [165/300], Step [21/23], Training Accuracy: 73.4375%, Training Loss: 0.3970%\n",
      "Epoch [165/300], Step [22/23], Training Accuracy: 73.5085%, Training Loss: 0.3962%\n",
      "Epoch [165/300], Step [23/23], Training Accuracy: 73.5233%, Training Loss: 0.3927%\n",
      "Epoch [166/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3649%\n",
      "Epoch [166/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3885%\n",
      "Epoch [166/300], Step [3/23], Training Accuracy: 73.4375%, Training Loss: 0.3912%\n",
      "Epoch [166/300], Step [4/23], Training Accuracy: 76.1719%, Training Loss: 0.3800%\n",
      "Epoch [166/300], Step [5/23], Training Accuracy: 75.3125%, Training Loss: 0.3813%\n",
      "Epoch [166/300], Step [6/23], Training Accuracy: 77.0833%, Training Loss: 0.3807%\n",
      "Epoch [166/300], Step [7/23], Training Accuracy: 76.7857%, Training Loss: 0.3891%\n",
      "Epoch [166/300], Step [8/23], Training Accuracy: 76.7578%, Training Loss: 0.3881%\n",
      "Epoch [166/300], Step [9/23], Training Accuracy: 75.6944%, Training Loss: 0.3931%\n",
      "Epoch [166/300], Step [10/23], Training Accuracy: 75.6250%, Training Loss: 0.3927%\n",
      "Epoch [166/300], Step [11/23], Training Accuracy: 75.8523%, Training Loss: 0.3938%\n",
      "Epoch [166/300], Step [12/23], Training Accuracy: 75.6510%, Training Loss: 0.3958%\n",
      "Epoch [166/300], Step [13/23], Training Accuracy: 74.6394%, Training Loss: 0.4006%\n",
      "Epoch [166/300], Step [14/23], Training Accuracy: 75.3348%, Training Loss: 0.3978%\n",
      "Epoch [166/300], Step [15/23], Training Accuracy: 74.8958%, Training Loss: 0.3993%\n",
      "Epoch [166/300], Step [16/23], Training Accuracy: 74.3164%, Training Loss: 0.4001%\n",
      "Epoch [166/300], Step [17/23], Training Accuracy: 74.3566%, Training Loss: 0.3995%\n",
      "Epoch [166/300], Step [18/23], Training Accuracy: 74.0451%, Training Loss: 0.4002%\n",
      "Epoch [166/300], Step [19/23], Training Accuracy: 74.2599%, Training Loss: 0.3987%\n",
      "Epoch [166/300], Step [20/23], Training Accuracy: 74.1406%, Training Loss: 0.3978%\n",
      "Epoch [166/300], Step [21/23], Training Accuracy: 74.4792%, Training Loss: 0.3971%\n",
      "Epoch [166/300], Step [22/23], Training Accuracy: 74.6449%, Training Loss: 0.3952%\n",
      "Epoch [166/300], Step [23/23], Training Accuracy: 74.4962%, Training Loss: 0.3920%\n",
      "Epoch [167/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3858%\n",
      "Epoch [167/300], Step [2/23], Training Accuracy: 71.8750%, Training Loss: 0.4075%\n",
      "Epoch [167/300], Step [3/23], Training Accuracy: 68.2292%, Training Loss: 0.4223%\n",
      "Epoch [167/300], Step [4/23], Training Accuracy: 72.2656%, Training Loss: 0.4101%\n",
      "Epoch [167/300], Step [5/23], Training Accuracy: 71.5625%, Training Loss: 0.4087%\n",
      "Epoch [167/300], Step [6/23], Training Accuracy: 72.6562%, Training Loss: 0.4020%\n",
      "Epoch [167/300], Step [7/23], Training Accuracy: 73.4375%, Training Loss: 0.4048%\n",
      "Epoch [167/300], Step [8/23], Training Accuracy: 74.2188%, Training Loss: 0.4030%\n",
      "Epoch [167/300], Step [9/23], Training Accuracy: 73.9583%, Training Loss: 0.4058%\n",
      "Epoch [167/300], Step [10/23], Training Accuracy: 73.4375%, Training Loss: 0.4014%\n",
      "Epoch [167/300], Step [11/23], Training Accuracy: 73.7216%, Training Loss: 0.4003%\n",
      "Epoch [167/300], Step [12/23], Training Accuracy: 74.0885%, Training Loss: 0.4020%\n",
      "Epoch [167/300], Step [13/23], Training Accuracy: 74.0385%, Training Loss: 0.4050%\n",
      "Epoch [167/300], Step [14/23], Training Accuracy: 74.1071%, Training Loss: 0.4027%\n",
      "Epoch [167/300], Step [15/23], Training Accuracy: 73.6458%, Training Loss: 0.4047%\n",
      "Epoch [167/300], Step [16/23], Training Accuracy: 73.4375%, Training Loss: 0.4056%\n",
      "Epoch [167/300], Step [17/23], Training Accuracy: 73.4375%, Training Loss: 0.4070%\n",
      "Epoch [167/300], Step [18/23], Training Accuracy: 73.7847%, Training Loss: 0.4050%\n",
      "Epoch [167/300], Step [19/23], Training Accuracy: 73.6020%, Training Loss: 0.4060%\n",
      "Epoch [167/300], Step [20/23], Training Accuracy: 73.6719%, Training Loss: 0.4041%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [167/300], Step [21/23], Training Accuracy: 73.3631%, Training Loss: 0.4041%\n",
      "Epoch [167/300], Step [22/23], Training Accuracy: 73.5795%, Training Loss: 0.4022%\n",
      "Epoch [167/300], Step [23/23], Training Accuracy: 73.7318%, Training Loss: 0.4001%\n",
      "Epoch [168/300], Step [1/23], Training Accuracy: 71.8750%, Training Loss: 0.3817%\n",
      "Epoch [168/300], Step [2/23], Training Accuracy: 69.5312%, Training Loss: 0.4223%\n",
      "Epoch [168/300], Step [3/23], Training Accuracy: 70.8333%, Training Loss: 0.4122%\n",
      "Epoch [168/300], Step [4/23], Training Accuracy: 75.0000%, Training Loss: 0.3946%\n",
      "Epoch [168/300], Step [5/23], Training Accuracy: 75.0000%, Training Loss: 0.3935%\n",
      "Epoch [168/300], Step [6/23], Training Accuracy: 75.2604%, Training Loss: 0.3919%\n",
      "Epoch [168/300], Step [7/23], Training Accuracy: 75.4464%, Training Loss: 0.3955%\n",
      "Epoch [168/300], Step [8/23], Training Accuracy: 75.5859%, Training Loss: 0.3965%\n",
      "Epoch [168/300], Step [9/23], Training Accuracy: 74.4792%, Training Loss: 0.3997%\n",
      "Epoch [168/300], Step [10/23], Training Accuracy: 75.0000%, Training Loss: 0.3964%\n",
      "Epoch [168/300], Step [11/23], Training Accuracy: 74.2898%, Training Loss: 0.3974%\n",
      "Epoch [168/300], Step [12/23], Training Accuracy: 74.0885%, Training Loss: 0.3969%\n",
      "Epoch [168/300], Step [13/23], Training Accuracy: 74.5192%, Training Loss: 0.3975%\n",
      "Epoch [168/300], Step [14/23], Training Accuracy: 75.0000%, Training Loss: 0.3953%\n",
      "Epoch [168/300], Step [15/23], Training Accuracy: 74.7917%, Training Loss: 0.3977%\n",
      "Epoch [168/300], Step [16/23], Training Accuracy: 74.7070%, Training Loss: 0.3986%\n",
      "Epoch [168/300], Step [17/23], Training Accuracy: 74.3566%, Training Loss: 0.4009%\n",
      "Epoch [168/300], Step [18/23], Training Accuracy: 74.4792%, Training Loss: 0.4007%\n",
      "Epoch [168/300], Step [19/23], Training Accuracy: 74.7533%, Training Loss: 0.3987%\n",
      "Epoch [168/300], Step [20/23], Training Accuracy: 75.0000%, Training Loss: 0.3971%\n",
      "Epoch [168/300], Step [21/23], Training Accuracy: 74.7768%, Training Loss: 0.3971%\n",
      "Epoch [168/300], Step [22/23], Training Accuracy: 75.2131%, Training Loss: 0.3964%\n",
      "Epoch [168/300], Step [23/23], Training Accuracy: 75.1216%, Training Loss: 0.3934%\n",
      "Epoch [169/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3762%\n",
      "Epoch [169/300], Step [2/23], Training Accuracy: 77.3438%, Training Loss: 0.4044%\n",
      "Epoch [169/300], Step [3/23], Training Accuracy: 74.4792%, Training Loss: 0.4063%\n",
      "Epoch [169/300], Step [4/23], Training Accuracy: 75.3906%, Training Loss: 0.3913%\n",
      "Epoch [169/300], Step [5/23], Training Accuracy: 74.0625%, Training Loss: 0.3945%\n",
      "Epoch [169/300], Step [6/23], Training Accuracy: 74.2188%, Training Loss: 0.3944%\n",
      "Epoch [169/300], Step [7/23], Training Accuracy: 75.0000%, Training Loss: 0.3979%\n",
      "Epoch [169/300], Step [8/23], Training Accuracy: 75.7812%, Training Loss: 0.3980%\n",
      "Epoch [169/300], Step [9/23], Training Accuracy: 75.0000%, Training Loss: 0.4036%\n",
      "Epoch [169/300], Step [10/23], Training Accuracy: 75.3125%, Training Loss: 0.3993%\n",
      "Epoch [169/300], Step [11/23], Training Accuracy: 75.0000%, Training Loss: 0.3994%\n",
      "Epoch [169/300], Step [12/23], Training Accuracy: 75.0000%, Training Loss: 0.3991%\n",
      "Epoch [169/300], Step [13/23], Training Accuracy: 74.2788%, Training Loss: 0.4016%\n",
      "Epoch [169/300], Step [14/23], Training Accuracy: 74.1071%, Training Loss: 0.3998%\n",
      "Epoch [169/300], Step [15/23], Training Accuracy: 73.8542%, Training Loss: 0.4021%\n",
      "Epoch [169/300], Step [16/23], Training Accuracy: 73.7305%, Training Loss: 0.4021%\n",
      "Epoch [169/300], Step [17/23], Training Accuracy: 73.6213%, Training Loss: 0.4017%\n",
      "Epoch [169/300], Step [18/23], Training Accuracy: 73.3507%, Training Loss: 0.4020%\n",
      "Epoch [169/300], Step [19/23], Training Accuracy: 73.1086%, Training Loss: 0.4020%\n",
      "Epoch [169/300], Step [20/23], Training Accuracy: 73.4375%, Training Loss: 0.3990%\n",
      "Epoch [169/300], Step [21/23], Training Accuracy: 73.2887%, Training Loss: 0.3987%\n",
      "Epoch [169/300], Step [22/23], Training Accuracy: 73.5795%, Training Loss: 0.3975%\n",
      "Epoch [169/300], Step [23/23], Training Accuracy: 73.7318%, Training Loss: 0.3941%\n",
      "Epoch [170/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3722%\n",
      "Epoch [170/300], Step [2/23], Training Accuracy: 78.9062%, Training Loss: 0.3866%\n",
      "Epoch [170/300], Step [3/23], Training Accuracy: 75.5208%, Training Loss: 0.3957%\n",
      "Epoch [170/300], Step [4/23], Training Accuracy: 77.7344%, Training Loss: 0.3800%\n",
      "Epoch [170/300], Step [5/23], Training Accuracy: 75.9375%, Training Loss: 0.3846%\n",
      "Epoch [170/300], Step [6/23], Training Accuracy: 77.3438%, Training Loss: 0.3823%\n",
      "Epoch [170/300], Step [7/23], Training Accuracy: 77.6786%, Training Loss: 0.3877%\n",
      "Epoch [170/300], Step [8/23], Training Accuracy: 78.1250%, Training Loss: 0.3898%\n",
      "Epoch [170/300], Step [9/23], Training Accuracy: 76.9097%, Training Loss: 0.3944%\n",
      "Epoch [170/300], Step [10/23], Training Accuracy: 77.3438%, Training Loss: 0.3916%\n",
      "Epoch [170/300], Step [11/23], Training Accuracy: 76.5625%, Training Loss: 0.3933%\n",
      "Epoch [170/300], Step [12/23], Training Accuracy: 76.0417%, Training Loss: 0.3938%\n",
      "Epoch [170/300], Step [13/23], Training Accuracy: 75.6010%, Training Loss: 0.3957%\n",
      "Epoch [170/300], Step [14/23], Training Accuracy: 75.5580%, Training Loss: 0.3929%\n",
      "Epoch [170/300], Step [15/23], Training Accuracy: 74.8958%, Training Loss: 0.3961%\n",
      "Epoch [170/300], Step [16/23], Training Accuracy: 74.9023%, Training Loss: 0.3962%\n",
      "Epoch [170/300], Step [17/23], Training Accuracy: 74.8162%, Training Loss: 0.3964%\n",
      "Epoch [170/300], Step [18/23], Training Accuracy: 75.2604%, Training Loss: 0.3953%\n",
      "Epoch [170/300], Step [19/23], Training Accuracy: 75.1645%, Training Loss: 0.3954%\n",
      "Epoch [170/300], Step [20/23], Training Accuracy: 75.3125%, Training Loss: 0.3926%\n",
      "Epoch [170/300], Step [21/23], Training Accuracy: 75.3720%, Training Loss: 0.3928%\n",
      "Epoch [170/300], Step [22/23], Training Accuracy: 75.4261%, Training Loss: 0.3926%\n",
      "Epoch [170/300], Step [23/23], Training Accuracy: 75.3996%, Training Loss: 0.3893%\n",
      "Epoch [171/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.4056%\n",
      "Epoch [171/300], Step [2/23], Training Accuracy: 77.3438%, Training Loss: 0.4037%\n",
      "Epoch [171/300], Step [3/23], Training Accuracy: 72.9167%, Training Loss: 0.4073%\n",
      "Epoch [171/300], Step [4/23], Training Accuracy: 75.0000%, Training Loss: 0.3927%\n",
      "Epoch [171/300], Step [5/23], Training Accuracy: 73.7500%, Training Loss: 0.3944%\n",
      "Epoch [171/300], Step [6/23], Training Accuracy: 74.7396%, Training Loss: 0.3971%\n",
      "Epoch [171/300], Step [7/23], Training Accuracy: 74.3304%, Training Loss: 0.4002%\n",
      "Epoch [171/300], Step [8/23], Training Accuracy: 74.8047%, Training Loss: 0.3995%\n",
      "Epoch [171/300], Step [9/23], Training Accuracy: 74.3056%, Training Loss: 0.4020%\n",
      "Epoch [171/300], Step [10/23], Training Accuracy: 74.0625%, Training Loss: 0.3996%\n",
      "Epoch [171/300], Step [11/23], Training Accuracy: 74.8580%, Training Loss: 0.3965%\n",
      "Epoch [171/300], Step [12/23], Training Accuracy: 74.3490%, Training Loss: 0.3974%\n",
      "Epoch [171/300], Step [13/23], Training Accuracy: 73.9183%, Training Loss: 0.4003%\n",
      "Epoch [171/300], Step [14/23], Training Accuracy: 73.9955%, Training Loss: 0.3981%\n",
      "Epoch [171/300], Step [15/23], Training Accuracy: 73.3333%, Training Loss: 0.4016%\n",
      "Epoch [171/300], Step [16/23], Training Accuracy: 73.3398%, Training Loss: 0.4008%\n",
      "Epoch [171/300], Step [17/23], Training Accuracy: 73.1618%, Training Loss: 0.4001%\n",
      "Epoch [171/300], Step [18/23], Training Accuracy: 73.2639%, Training Loss: 0.3997%\n",
      "Epoch [171/300], Step [19/23], Training Accuracy: 73.3553%, Training Loss: 0.4005%\n",
      "Epoch [171/300], Step [20/23], Training Accuracy: 73.9844%, Training Loss: 0.3981%\n",
      "Epoch [171/300], Step [21/23], Training Accuracy: 73.8839%, Training Loss: 0.3983%\n",
      "Epoch [171/300], Step [22/23], Training Accuracy: 74.0057%, Training Loss: 0.3976%\n",
      "Epoch [171/300], Step [23/23], Training Accuracy: 74.3572%, Training Loss: 0.3935%\n",
      "Epoch [172/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3665%\n",
      "Epoch [172/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.3824%\n",
      "Epoch [172/300], Step [3/23], Training Accuracy: 72.9167%, Training Loss: 0.3873%\n",
      "Epoch [172/300], Step [4/23], Training Accuracy: 76.5625%, Training Loss: 0.3783%\n",
      "Epoch [172/300], Step [5/23], Training Accuracy: 74.0625%, Training Loss: 0.3823%\n",
      "Epoch [172/300], Step [6/23], Training Accuracy: 75.0000%, Training Loss: 0.3855%\n",
      "Epoch [172/300], Step [7/23], Training Accuracy: 73.8839%, Training Loss: 0.3905%\n",
      "Epoch [172/300], Step [8/23], Training Accuracy: 74.4141%, Training Loss: 0.3913%\n",
      "Epoch [172/300], Step [9/23], Training Accuracy: 73.4375%, Training Loss: 0.3952%\n",
      "Epoch [172/300], Step [10/23], Training Accuracy: 73.2812%, Training Loss: 0.3964%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [172/300], Step [11/23], Training Accuracy: 74.1477%, Training Loss: 0.3935%\n",
      "Epoch [172/300], Step [12/23], Training Accuracy: 73.8281%, Training Loss: 0.3958%\n",
      "Epoch [172/300], Step [13/23], Training Accuracy: 73.5577%, Training Loss: 0.3963%\n",
      "Epoch [172/300], Step [14/23], Training Accuracy: 73.7723%, Training Loss: 0.3936%\n",
      "Epoch [172/300], Step [15/23], Training Accuracy: 73.4375%, Training Loss: 0.3953%\n",
      "Epoch [172/300], Step [16/23], Training Accuracy: 73.3398%, Training Loss: 0.3964%\n",
      "Epoch [172/300], Step [17/23], Training Accuracy: 73.6213%, Training Loss: 0.3957%\n",
      "Epoch [172/300], Step [18/23], Training Accuracy: 73.6979%, Training Loss: 0.3971%\n",
      "Epoch [172/300], Step [19/23], Training Accuracy: 74.1776%, Training Loss: 0.3951%\n",
      "Epoch [172/300], Step [20/23], Training Accuracy: 74.4531%, Training Loss: 0.3942%\n",
      "Epoch [172/300], Step [21/23], Training Accuracy: 74.6280%, Training Loss: 0.3941%\n",
      "Epoch [172/300], Step [22/23], Training Accuracy: 74.5739%, Training Loss: 0.3936%\n",
      "Epoch [172/300], Step [23/23], Training Accuracy: 74.7741%, Training Loss: 0.3900%\n",
      "Epoch [173/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3781%\n",
      "Epoch [173/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.3999%\n",
      "Epoch [173/300], Step [3/23], Training Accuracy: 74.4792%, Training Loss: 0.3966%\n",
      "Epoch [173/300], Step [4/23], Training Accuracy: 76.1719%, Training Loss: 0.3832%\n",
      "Epoch [173/300], Step [5/23], Training Accuracy: 75.6250%, Training Loss: 0.3822%\n",
      "Epoch [173/300], Step [6/23], Training Accuracy: 76.0417%, Training Loss: 0.3796%\n",
      "Epoch [173/300], Step [7/23], Training Accuracy: 75.8929%, Training Loss: 0.3866%\n",
      "Epoch [173/300], Step [8/23], Training Accuracy: 76.3672%, Training Loss: 0.3863%\n",
      "Epoch [173/300], Step [9/23], Training Accuracy: 75.3472%, Training Loss: 0.3959%\n",
      "Epoch [173/300], Step [10/23], Training Accuracy: 74.8438%, Training Loss: 0.3954%\n",
      "Epoch [173/300], Step [11/23], Training Accuracy: 75.2841%, Training Loss: 0.3935%\n",
      "Epoch [173/300], Step [12/23], Training Accuracy: 75.3906%, Training Loss: 0.3929%\n",
      "Epoch [173/300], Step [13/23], Training Accuracy: 74.6394%, Training Loss: 0.3956%\n",
      "Epoch [173/300], Step [14/23], Training Accuracy: 74.7768%, Training Loss: 0.3948%\n",
      "Epoch [173/300], Step [15/23], Training Accuracy: 74.4792%, Training Loss: 0.3970%\n",
      "Epoch [173/300], Step [16/23], Training Accuracy: 74.2188%, Training Loss: 0.3972%\n",
      "Epoch [173/300], Step [17/23], Training Accuracy: 74.1728%, Training Loss: 0.3969%\n",
      "Epoch [173/300], Step [18/23], Training Accuracy: 74.2188%, Training Loss: 0.3957%\n",
      "Epoch [173/300], Step [19/23], Training Accuracy: 74.0954%, Training Loss: 0.3954%\n",
      "Epoch [173/300], Step [20/23], Training Accuracy: 74.1406%, Training Loss: 0.3956%\n",
      "Epoch [173/300], Step [21/23], Training Accuracy: 73.9583%, Training Loss: 0.3961%\n",
      "Epoch [173/300], Step [22/23], Training Accuracy: 74.0767%, Training Loss: 0.3949%\n",
      "Epoch [173/300], Step [23/23], Training Accuracy: 74.1487%, Training Loss: 0.3909%\n",
      "Epoch [174/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3728%\n",
      "Epoch [174/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.4005%\n",
      "Epoch [174/300], Step [3/23], Training Accuracy: 71.3542%, Training Loss: 0.4118%\n",
      "Epoch [174/300], Step [4/23], Training Accuracy: 73.4375%, Training Loss: 0.3985%\n",
      "Epoch [174/300], Step [5/23], Training Accuracy: 73.4375%, Training Loss: 0.3965%\n",
      "Epoch [174/300], Step [6/23], Training Accuracy: 74.2188%, Training Loss: 0.3951%\n",
      "Epoch [174/300], Step [7/23], Training Accuracy: 73.8839%, Training Loss: 0.3974%\n",
      "Epoch [174/300], Step [8/23], Training Accuracy: 75.1953%, Training Loss: 0.3933%\n",
      "Epoch [174/300], Step [9/23], Training Accuracy: 73.7847%, Training Loss: 0.4002%\n",
      "Epoch [174/300], Step [10/23], Training Accuracy: 73.5938%, Training Loss: 0.3990%\n",
      "Epoch [174/300], Step [11/23], Training Accuracy: 74.2898%, Training Loss: 0.3974%\n",
      "Epoch [174/300], Step [12/23], Training Accuracy: 74.0885%, Training Loss: 0.3990%\n",
      "Epoch [174/300], Step [13/23], Training Accuracy: 74.2788%, Training Loss: 0.3999%\n",
      "Epoch [174/300], Step [14/23], Training Accuracy: 74.5536%, Training Loss: 0.3973%\n",
      "Epoch [174/300], Step [15/23], Training Accuracy: 73.4375%, Training Loss: 0.4041%\n",
      "Epoch [174/300], Step [16/23], Training Accuracy: 73.4375%, Training Loss: 0.4045%\n",
      "Epoch [174/300], Step [17/23], Training Accuracy: 73.8971%, Training Loss: 0.4030%\n",
      "Epoch [174/300], Step [18/23], Training Accuracy: 74.1319%, Training Loss: 0.4018%\n",
      "Epoch [174/300], Step [19/23], Training Accuracy: 74.0954%, Training Loss: 0.3995%\n",
      "Epoch [174/300], Step [20/23], Training Accuracy: 74.2969%, Training Loss: 0.3972%\n",
      "Epoch [174/300], Step [21/23], Training Accuracy: 74.1815%, Training Loss: 0.3961%\n",
      "Epoch [174/300], Step [22/23], Training Accuracy: 74.5028%, Training Loss: 0.3944%\n",
      "Epoch [174/300], Step [23/23], Training Accuracy: 74.6352%, Training Loss: 0.3909%\n",
      "Epoch [175/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.4032%\n",
      "Epoch [175/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.4093%\n",
      "Epoch [175/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.4087%\n",
      "Epoch [175/300], Step [4/23], Training Accuracy: 73.4375%, Training Loss: 0.3892%\n",
      "Epoch [175/300], Step [5/23], Training Accuracy: 72.5000%, Training Loss: 0.3892%\n",
      "Epoch [175/300], Step [6/23], Training Accuracy: 73.6979%, Training Loss: 0.3892%\n",
      "Epoch [175/300], Step [7/23], Training Accuracy: 74.5536%, Training Loss: 0.3910%\n",
      "Epoch [175/300], Step [8/23], Training Accuracy: 75.1953%, Training Loss: 0.3935%\n",
      "Epoch [175/300], Step [9/23], Training Accuracy: 73.9583%, Training Loss: 0.3968%\n",
      "Epoch [175/300], Step [10/23], Training Accuracy: 73.9062%, Training Loss: 0.3949%\n",
      "Epoch [175/300], Step [11/23], Training Accuracy: 74.1477%, Training Loss: 0.3937%\n",
      "Epoch [175/300], Step [12/23], Training Accuracy: 74.2188%, Training Loss: 0.3947%\n",
      "Epoch [175/300], Step [13/23], Training Accuracy: 74.1587%, Training Loss: 0.3975%\n",
      "Epoch [175/300], Step [14/23], Training Accuracy: 74.8884%, Training Loss: 0.3944%\n",
      "Epoch [175/300], Step [15/23], Training Accuracy: 74.5833%, Training Loss: 0.3975%\n",
      "Epoch [175/300], Step [16/23], Training Accuracy: 74.3164%, Training Loss: 0.3986%\n",
      "Epoch [175/300], Step [17/23], Training Accuracy: 74.1728%, Training Loss: 0.3991%\n",
      "Epoch [175/300], Step [18/23], Training Accuracy: 74.3056%, Training Loss: 0.3987%\n",
      "Epoch [175/300], Step [19/23], Training Accuracy: 74.2599%, Training Loss: 0.3985%\n",
      "Epoch [175/300], Step [20/23], Training Accuracy: 74.6094%, Training Loss: 0.3969%\n",
      "Epoch [175/300], Step [21/23], Training Accuracy: 74.3304%, Training Loss: 0.3981%\n",
      "Epoch [175/300], Step [22/23], Training Accuracy: 74.3608%, Training Loss: 0.3964%\n",
      "Epoch [175/300], Step [23/23], Training Accuracy: 74.5657%, Training Loss: 0.3924%\n",
      "Epoch [176/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3706%\n",
      "Epoch [176/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.3885%\n",
      "Epoch [176/300], Step [3/23], Training Accuracy: 72.3958%, Training Loss: 0.3942%\n",
      "Epoch [176/300], Step [4/23], Training Accuracy: 74.6094%, Training Loss: 0.3798%\n",
      "Epoch [176/300], Step [5/23], Training Accuracy: 73.4375%, Training Loss: 0.3815%\n",
      "Epoch [176/300], Step [6/23], Training Accuracy: 74.2188%, Training Loss: 0.3872%\n",
      "Epoch [176/300], Step [7/23], Training Accuracy: 74.3304%, Training Loss: 0.3929%\n",
      "Epoch [176/300], Step [8/23], Training Accuracy: 74.6094%, Training Loss: 0.3942%\n",
      "Epoch [176/300], Step [9/23], Training Accuracy: 73.2639%, Training Loss: 0.3998%\n",
      "Epoch [176/300], Step [10/23], Training Accuracy: 73.7500%, Training Loss: 0.3972%\n",
      "Epoch [176/300], Step [11/23], Training Accuracy: 74.0057%, Training Loss: 0.3977%\n",
      "Epoch [176/300], Step [12/23], Training Accuracy: 74.3490%, Training Loss: 0.3983%\n",
      "Epoch [176/300], Step [13/23], Training Accuracy: 73.7981%, Training Loss: 0.4004%\n",
      "Epoch [176/300], Step [14/23], Training Accuracy: 74.2188%, Training Loss: 0.3981%\n",
      "Epoch [176/300], Step [15/23], Training Accuracy: 73.7500%, Training Loss: 0.3990%\n",
      "Epoch [176/300], Step [16/23], Training Accuracy: 73.6328%, Training Loss: 0.3991%\n",
      "Epoch [176/300], Step [17/23], Training Accuracy: 73.7132%, Training Loss: 0.3977%\n",
      "Epoch [176/300], Step [18/23], Training Accuracy: 73.6111%, Training Loss: 0.3987%\n",
      "Epoch [176/300], Step [19/23], Training Accuracy: 73.5197%, Training Loss: 0.3981%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [176/300], Step [20/23], Training Accuracy: 73.9844%, Training Loss: 0.3950%\n",
      "Epoch [176/300], Step [21/23], Training Accuracy: 73.6607%, Training Loss: 0.3954%\n",
      "Epoch [176/300], Step [22/23], Training Accuracy: 73.4375%, Training Loss: 0.3949%\n",
      "Epoch [176/300], Step [23/23], Training Accuracy: 73.5928%, Training Loss: 0.3918%\n",
      "Epoch [177/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3851%\n",
      "Epoch [177/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.4090%\n",
      "Epoch [177/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.4089%\n",
      "Epoch [177/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.3921%\n",
      "Epoch [177/300], Step [5/23], Training Accuracy: 72.8125%, Training Loss: 0.3912%\n",
      "Epoch [177/300], Step [6/23], Training Accuracy: 74.2188%, Training Loss: 0.3899%\n",
      "Epoch [177/300], Step [7/23], Training Accuracy: 73.2143%, Training Loss: 0.3982%\n",
      "Epoch [177/300], Step [8/23], Training Accuracy: 73.8281%, Training Loss: 0.3987%\n",
      "Epoch [177/300], Step [9/23], Training Accuracy: 73.2639%, Training Loss: 0.4013%\n",
      "Epoch [177/300], Step [10/23], Training Accuracy: 73.5938%, Training Loss: 0.3983%\n",
      "Epoch [177/300], Step [11/23], Training Accuracy: 74.0057%, Training Loss: 0.3970%\n",
      "Epoch [177/300], Step [12/23], Training Accuracy: 73.5677%, Training Loss: 0.3993%\n",
      "Epoch [177/300], Step [13/23], Training Accuracy: 73.1971%, Training Loss: 0.4019%\n",
      "Epoch [177/300], Step [14/23], Training Accuracy: 73.7723%, Training Loss: 0.3986%\n",
      "Epoch [177/300], Step [15/23], Training Accuracy: 73.7500%, Training Loss: 0.3989%\n",
      "Epoch [177/300], Step [16/23], Training Accuracy: 73.5352%, Training Loss: 0.3994%\n",
      "Epoch [177/300], Step [17/23], Training Accuracy: 73.6213%, Training Loss: 0.3987%\n",
      "Epoch [177/300], Step [18/23], Training Accuracy: 73.4375%, Training Loss: 0.3996%\n",
      "Epoch [177/300], Step [19/23], Training Accuracy: 73.8487%, Training Loss: 0.3984%\n",
      "Epoch [177/300], Step [20/23], Training Accuracy: 74.1406%, Training Loss: 0.3965%\n",
      "Epoch [177/300], Step [21/23], Training Accuracy: 74.1815%, Training Loss: 0.3957%\n",
      "Epoch [177/300], Step [22/23], Training Accuracy: 74.3608%, Training Loss: 0.3939%\n",
      "Epoch [177/300], Step [23/23], Training Accuracy: 74.5657%, Training Loss: 0.3910%\n",
      "Epoch [178/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3562%\n",
      "Epoch [178/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.3844%\n",
      "Epoch [178/300], Step [3/23], Training Accuracy: 72.3958%, Training Loss: 0.3916%\n",
      "Epoch [178/300], Step [4/23], Training Accuracy: 74.2188%, Training Loss: 0.3808%\n",
      "Epoch [178/300], Step [5/23], Training Accuracy: 73.7500%, Training Loss: 0.3807%\n",
      "Epoch [178/300], Step [6/23], Training Accuracy: 75.0000%, Training Loss: 0.3775%\n",
      "Epoch [178/300], Step [7/23], Training Accuracy: 75.0000%, Training Loss: 0.3866%\n",
      "Epoch [178/300], Step [8/23], Training Accuracy: 75.5859%, Training Loss: 0.3831%\n",
      "Epoch [178/300], Step [9/23], Training Accuracy: 75.0000%, Training Loss: 0.3889%\n",
      "Epoch [178/300], Step [10/23], Training Accuracy: 75.0000%, Training Loss: 0.3893%\n",
      "Epoch [178/300], Step [11/23], Training Accuracy: 75.4261%, Training Loss: 0.3891%\n",
      "Epoch [178/300], Step [12/23], Training Accuracy: 75.0000%, Training Loss: 0.3922%\n",
      "Epoch [178/300], Step [13/23], Training Accuracy: 74.7596%, Training Loss: 0.3955%\n",
      "Epoch [178/300], Step [14/23], Training Accuracy: 75.4464%, Training Loss: 0.3922%\n",
      "Epoch [178/300], Step [15/23], Training Accuracy: 75.1042%, Training Loss: 0.3950%\n",
      "Epoch [178/300], Step [16/23], Training Accuracy: 74.8047%, Training Loss: 0.3950%\n",
      "Epoch [178/300], Step [17/23], Training Accuracy: 74.4485%, Training Loss: 0.3953%\n",
      "Epoch [178/300], Step [18/23], Training Accuracy: 74.0451%, Training Loss: 0.3959%\n",
      "Epoch [178/300], Step [19/23], Training Accuracy: 74.0954%, Training Loss: 0.3962%\n",
      "Epoch [178/300], Step [20/23], Training Accuracy: 74.3750%, Training Loss: 0.3939%\n",
      "Epoch [178/300], Step [21/23], Training Accuracy: 74.4048%, Training Loss: 0.3941%\n",
      "Epoch [178/300], Step [22/23], Training Accuracy: 74.5028%, Training Loss: 0.3933%\n",
      "Epoch [178/300], Step [23/23], Training Accuracy: 74.4267%, Training Loss: 0.3903%\n",
      "Epoch [179/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3736%\n",
      "Epoch [179/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.3932%\n",
      "Epoch [179/300], Step [3/23], Training Accuracy: 72.9167%, Training Loss: 0.3965%\n",
      "Epoch [179/300], Step [4/23], Training Accuracy: 75.3906%, Training Loss: 0.3859%\n",
      "Epoch [179/300], Step [5/23], Training Accuracy: 75.6250%, Training Loss: 0.3919%\n",
      "Epoch [179/300], Step [6/23], Training Accuracy: 76.0417%, Training Loss: 0.3933%\n",
      "Epoch [179/300], Step [7/23], Training Accuracy: 75.8929%, Training Loss: 0.3983%\n",
      "Epoch [179/300], Step [8/23], Training Accuracy: 76.3672%, Training Loss: 0.3983%\n",
      "Epoch [179/300], Step [9/23], Training Accuracy: 74.6528%, Training Loss: 0.4025%\n",
      "Epoch [179/300], Step [10/23], Training Accuracy: 75.3125%, Training Loss: 0.3997%\n",
      "Epoch [179/300], Step [11/23], Training Accuracy: 75.2841%, Training Loss: 0.3974%\n",
      "Epoch [179/300], Step [12/23], Training Accuracy: 74.6094%, Training Loss: 0.3999%\n",
      "Epoch [179/300], Step [13/23], Training Accuracy: 74.2788%, Training Loss: 0.4013%\n",
      "Epoch [179/300], Step [14/23], Training Accuracy: 74.4420%, Training Loss: 0.3982%\n",
      "Epoch [179/300], Step [15/23], Training Accuracy: 74.2708%, Training Loss: 0.4012%\n",
      "Epoch [179/300], Step [16/23], Training Accuracy: 73.8281%, Training Loss: 0.4007%\n",
      "Epoch [179/300], Step [17/23], Training Accuracy: 73.8051%, Training Loss: 0.4000%\n",
      "Epoch [179/300], Step [18/23], Training Accuracy: 73.7847%, Training Loss: 0.3999%\n",
      "Epoch [179/300], Step [19/23], Training Accuracy: 73.8487%, Training Loss: 0.3983%\n",
      "Epoch [179/300], Step [20/23], Training Accuracy: 74.0625%, Training Loss: 0.3967%\n",
      "Epoch [179/300], Step [21/23], Training Accuracy: 73.8839%, Training Loss: 0.3975%\n",
      "Epoch [179/300], Step [22/23], Training Accuracy: 73.9347%, Training Loss: 0.3963%\n",
      "Epoch [179/300], Step [23/23], Training Accuracy: 73.9402%, Training Loss: 0.3935%\n",
      "Epoch [180/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3862%\n",
      "Epoch [180/300], Step [2/23], Training Accuracy: 78.1250%, Training Loss: 0.3881%\n",
      "Epoch [180/300], Step [3/23], Training Accuracy: 74.4792%, Training Loss: 0.4038%\n",
      "Epoch [180/300], Step [4/23], Training Accuracy: 75.3906%, Training Loss: 0.3875%\n",
      "Epoch [180/300], Step [5/23], Training Accuracy: 75.9375%, Training Loss: 0.3850%\n",
      "Epoch [180/300], Step [6/23], Training Accuracy: 75.7812%, Training Loss: 0.3851%\n",
      "Epoch [180/300], Step [7/23], Training Accuracy: 75.8929%, Training Loss: 0.3881%\n",
      "Epoch [180/300], Step [8/23], Training Accuracy: 76.5625%, Training Loss: 0.3849%\n",
      "Epoch [180/300], Step [9/23], Training Accuracy: 74.8264%, Training Loss: 0.3959%\n",
      "Epoch [180/300], Step [10/23], Training Accuracy: 74.6875%, Training Loss: 0.3967%\n",
      "Epoch [180/300], Step [11/23], Training Accuracy: 74.8580%, Training Loss: 0.3951%\n",
      "Epoch [180/300], Step [12/23], Training Accuracy: 74.8698%, Training Loss: 0.3950%\n",
      "Epoch [180/300], Step [13/23], Training Accuracy: 75.0000%, Training Loss: 0.3973%\n",
      "Epoch [180/300], Step [14/23], Training Accuracy: 74.8884%, Training Loss: 0.3962%\n",
      "Epoch [180/300], Step [15/23], Training Accuracy: 74.3750%, Training Loss: 0.3991%\n",
      "Epoch [180/300], Step [16/23], Training Accuracy: 73.9258%, Training Loss: 0.3999%\n",
      "Epoch [180/300], Step [17/23], Training Accuracy: 73.8971%, Training Loss: 0.3991%\n",
      "Epoch [180/300], Step [18/23], Training Accuracy: 73.9583%, Training Loss: 0.3980%\n",
      "Epoch [180/300], Step [19/23], Training Accuracy: 73.7664%, Training Loss: 0.3991%\n",
      "Epoch [180/300], Step [20/23], Training Accuracy: 74.2188%, Training Loss: 0.3974%\n",
      "Epoch [180/300], Step [21/23], Training Accuracy: 74.1815%, Training Loss: 0.3965%\n",
      "Epoch [180/300], Step [22/23], Training Accuracy: 74.2188%, Training Loss: 0.3955%\n",
      "Epoch [180/300], Step [23/23], Training Accuracy: 74.3572%, Training Loss: 0.3919%\n",
      "Epoch [181/300], Step [1/23], Training Accuracy: 73.4375%, Training Loss: 0.3771%\n",
      "Epoch [181/300], Step [2/23], Training Accuracy: 69.5312%, Training Loss: 0.4096%\n",
      "Epoch [181/300], Step [3/23], Training Accuracy: 69.7917%, Training Loss: 0.4091%\n",
      "Epoch [181/300], Step [4/23], Training Accuracy: 73.4375%, Training Loss: 0.3908%\n",
      "Epoch [181/300], Step [5/23], Training Accuracy: 72.5000%, Training Loss: 0.3933%\n",
      "Epoch [181/300], Step [6/23], Training Accuracy: 72.9167%, Training Loss: 0.3932%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [181/300], Step [7/23], Training Accuracy: 72.9911%, Training Loss: 0.3979%\n",
      "Epoch [181/300], Step [8/23], Training Accuracy: 74.0234%, Training Loss: 0.3965%\n",
      "Epoch [181/300], Step [9/23], Training Accuracy: 73.2639%, Training Loss: 0.4020%\n",
      "Epoch [181/300], Step [10/23], Training Accuracy: 73.1250%, Training Loss: 0.4015%\n",
      "Epoch [181/300], Step [11/23], Training Accuracy: 73.2955%, Training Loss: 0.4014%\n",
      "Epoch [181/300], Step [12/23], Training Accuracy: 73.1771%, Training Loss: 0.4033%\n",
      "Epoch [181/300], Step [13/23], Training Accuracy: 73.0769%, Training Loss: 0.4036%\n",
      "Epoch [181/300], Step [14/23], Training Accuracy: 72.9911%, Training Loss: 0.4018%\n",
      "Epoch [181/300], Step [15/23], Training Accuracy: 73.2292%, Training Loss: 0.4034%\n",
      "Epoch [181/300], Step [16/23], Training Accuracy: 73.2422%, Training Loss: 0.4036%\n",
      "Epoch [181/300], Step [17/23], Training Accuracy: 73.1618%, Training Loss: 0.4045%\n",
      "Epoch [181/300], Step [18/23], Training Accuracy: 73.3507%, Training Loss: 0.4040%\n",
      "Epoch [181/300], Step [19/23], Training Accuracy: 73.2730%, Training Loss: 0.4036%\n",
      "Epoch [181/300], Step [20/23], Training Accuracy: 73.5938%, Training Loss: 0.4016%\n",
      "Epoch [181/300], Step [21/23], Training Accuracy: 73.7351%, Training Loss: 0.4009%\n",
      "Epoch [181/300], Step [22/23], Training Accuracy: 73.8636%, Training Loss: 0.4003%\n",
      "Epoch [181/300], Step [23/23], Training Accuracy: 74.0792%, Training Loss: 0.3961%\n",
      "Epoch [182/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3705%\n",
      "Epoch [182/300], Step [2/23], Training Accuracy: 77.3438%, Training Loss: 0.3832%\n",
      "Epoch [182/300], Step [3/23], Training Accuracy: 72.9167%, Training Loss: 0.4007%\n",
      "Epoch [182/300], Step [4/23], Training Accuracy: 75.7812%, Training Loss: 0.3826%\n",
      "Epoch [182/300], Step [5/23], Training Accuracy: 74.0625%, Training Loss: 0.3823%\n",
      "Epoch [182/300], Step [6/23], Training Accuracy: 74.7396%, Training Loss: 0.3848%\n",
      "Epoch [182/300], Step [7/23], Training Accuracy: 74.3304%, Training Loss: 0.3896%\n",
      "Epoch [182/300], Step [8/23], Training Accuracy: 74.2188%, Training Loss: 0.3921%\n",
      "Epoch [182/300], Step [9/23], Training Accuracy: 73.0903%, Training Loss: 0.3986%\n",
      "Epoch [182/300], Step [10/23], Training Accuracy: 73.1250%, Training Loss: 0.3982%\n",
      "Epoch [182/300], Step [11/23], Training Accuracy: 73.4375%, Training Loss: 0.3976%\n",
      "Epoch [182/300], Step [12/23], Training Accuracy: 73.4375%, Training Loss: 0.3978%\n",
      "Epoch [182/300], Step [13/23], Training Accuracy: 73.4375%, Training Loss: 0.3992%\n",
      "Epoch [182/300], Step [14/23], Training Accuracy: 73.7723%, Training Loss: 0.3957%\n",
      "Epoch [182/300], Step [15/23], Training Accuracy: 73.7500%, Training Loss: 0.3987%\n",
      "Epoch [182/300], Step [16/23], Training Accuracy: 73.3398%, Training Loss: 0.3988%\n",
      "Epoch [182/300], Step [17/23], Training Accuracy: 73.1618%, Training Loss: 0.4001%\n",
      "Epoch [182/300], Step [18/23], Training Accuracy: 72.9167%, Training Loss: 0.4006%\n",
      "Epoch [182/300], Step [19/23], Training Accuracy: 73.1908%, Training Loss: 0.3999%\n",
      "Epoch [182/300], Step [20/23], Training Accuracy: 73.5156%, Training Loss: 0.3983%\n",
      "Epoch [182/300], Step [21/23], Training Accuracy: 73.2887%, Training Loss: 0.3988%\n",
      "Epoch [182/300], Step [22/23], Training Accuracy: 73.4375%, Training Loss: 0.3976%\n",
      "Epoch [182/300], Step [23/23], Training Accuracy: 73.4538%, Training Loss: 0.3944%\n",
      "Epoch [183/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3804%\n",
      "Epoch [183/300], Step [2/23], Training Accuracy: 72.6562%, Training Loss: 0.3967%\n",
      "Epoch [183/300], Step [3/23], Training Accuracy: 69.7917%, Training Loss: 0.4016%\n",
      "Epoch [183/300], Step [4/23], Training Accuracy: 70.7031%, Training Loss: 0.3978%\n",
      "Epoch [183/300], Step [5/23], Training Accuracy: 71.2500%, Training Loss: 0.3930%\n",
      "Epoch [183/300], Step [6/23], Training Accuracy: 73.1771%, Training Loss: 0.3869%\n",
      "Epoch [183/300], Step [7/23], Training Accuracy: 73.4375%, Training Loss: 0.3928%\n",
      "Epoch [183/300], Step [8/23], Training Accuracy: 73.6328%, Training Loss: 0.3949%\n",
      "Epoch [183/300], Step [9/23], Training Accuracy: 72.9167%, Training Loss: 0.4005%\n",
      "Epoch [183/300], Step [10/23], Training Accuracy: 73.7500%, Training Loss: 0.3969%\n",
      "Epoch [183/300], Step [11/23], Training Accuracy: 74.4318%, Training Loss: 0.3948%\n",
      "Epoch [183/300], Step [12/23], Training Accuracy: 74.0885%, Training Loss: 0.3972%\n",
      "Epoch [183/300], Step [13/23], Training Accuracy: 73.6779%, Training Loss: 0.3996%\n",
      "Epoch [183/300], Step [14/23], Training Accuracy: 73.5491%, Training Loss: 0.3967%\n",
      "Epoch [183/300], Step [15/23], Training Accuracy: 72.9167%, Training Loss: 0.3997%\n",
      "Epoch [183/300], Step [16/23], Training Accuracy: 73.0469%, Training Loss: 0.4005%\n",
      "Epoch [183/300], Step [17/23], Training Accuracy: 73.0699%, Training Loss: 0.4013%\n",
      "Epoch [183/300], Step [18/23], Training Accuracy: 73.3507%, Training Loss: 0.4013%\n",
      "Epoch [183/300], Step [19/23], Training Accuracy: 73.4375%, Training Loss: 0.4010%\n",
      "Epoch [183/300], Step [20/23], Training Accuracy: 73.5938%, Training Loss: 0.3993%\n",
      "Epoch [183/300], Step [21/23], Training Accuracy: 73.5119%, Training Loss: 0.3998%\n",
      "Epoch [183/300], Step [22/23], Training Accuracy: 73.5795%, Training Loss: 0.3996%\n",
      "Epoch [183/300], Step [23/23], Training Accuracy: 73.7318%, Training Loss: 0.3951%\n",
      "Epoch [184/300], Step [1/23], Training Accuracy: 73.4375%, Training Loss: 0.3983%\n",
      "Epoch [184/300], Step [2/23], Training Accuracy: 68.7500%, Training Loss: 0.4176%\n",
      "Epoch [184/300], Step [3/23], Training Accuracy: 69.2708%, Training Loss: 0.4123%\n",
      "Epoch [184/300], Step [4/23], Training Accuracy: 72.6562%, Training Loss: 0.3951%\n",
      "Epoch [184/300], Step [5/23], Training Accuracy: 72.1875%, Training Loss: 0.3918%\n",
      "Epoch [184/300], Step [6/23], Training Accuracy: 73.9583%, Training Loss: 0.3897%\n",
      "Epoch [184/300], Step [7/23], Training Accuracy: 74.1071%, Training Loss: 0.3941%\n",
      "Epoch [184/300], Step [8/23], Training Accuracy: 74.8047%, Training Loss: 0.3943%\n",
      "Epoch [184/300], Step [9/23], Training Accuracy: 73.6111%, Training Loss: 0.3994%\n",
      "Epoch [184/300], Step [10/23], Training Accuracy: 73.5938%, Training Loss: 0.3980%\n",
      "Epoch [184/300], Step [11/23], Training Accuracy: 73.1534%, Training Loss: 0.3991%\n",
      "Epoch [184/300], Step [12/23], Training Accuracy: 73.0469%, Training Loss: 0.4001%\n",
      "Epoch [184/300], Step [13/23], Training Accuracy: 72.9567%, Training Loss: 0.4021%\n",
      "Epoch [184/300], Step [14/23], Training Accuracy: 73.7723%, Training Loss: 0.3989%\n",
      "Epoch [184/300], Step [15/23], Training Accuracy: 73.4375%, Training Loss: 0.4012%\n",
      "Epoch [184/300], Step [16/23], Training Accuracy: 73.3398%, Training Loss: 0.4018%\n",
      "Epoch [184/300], Step [17/23], Training Accuracy: 73.2537%, Training Loss: 0.4026%\n",
      "Epoch [184/300], Step [18/23], Training Accuracy: 73.2639%, Training Loss: 0.4026%\n",
      "Epoch [184/300], Step [19/23], Training Accuracy: 73.2730%, Training Loss: 0.4015%\n",
      "Epoch [184/300], Step [20/23], Training Accuracy: 73.5156%, Training Loss: 0.3993%\n",
      "Epoch [184/300], Step [21/23], Training Accuracy: 73.6607%, Training Loss: 0.3989%\n",
      "Epoch [184/300], Step [22/23], Training Accuracy: 73.5795%, Training Loss: 0.3985%\n",
      "Epoch [184/300], Step [23/23], Training Accuracy: 73.8707%, Training Loss: 0.3928%\n",
      "Epoch [185/300], Step [1/23], Training Accuracy: 81.2500%, Training Loss: 0.3667%\n",
      "Epoch [185/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.3870%\n",
      "Epoch [185/300], Step [3/23], Training Accuracy: 72.9167%, Training Loss: 0.3936%\n",
      "Epoch [185/300], Step [4/23], Training Accuracy: 75.0000%, Training Loss: 0.3786%\n",
      "Epoch [185/300], Step [5/23], Training Accuracy: 73.7500%, Training Loss: 0.3836%\n",
      "Epoch [185/300], Step [6/23], Training Accuracy: 75.2604%, Training Loss: 0.3838%\n",
      "Epoch [185/300], Step [7/23], Training Accuracy: 76.1161%, Training Loss: 0.3870%\n",
      "Epoch [185/300], Step [8/23], Training Accuracy: 75.9766%, Training Loss: 0.3866%\n",
      "Epoch [185/300], Step [9/23], Training Accuracy: 74.6528%, Training Loss: 0.3949%\n",
      "Epoch [185/300], Step [10/23], Training Accuracy: 74.3750%, Training Loss: 0.3921%\n",
      "Epoch [185/300], Step [11/23], Training Accuracy: 73.7216%, Training Loss: 0.3941%\n",
      "Epoch [185/300], Step [12/23], Training Accuracy: 73.8281%, Training Loss: 0.3937%\n",
      "Epoch [185/300], Step [13/23], Training Accuracy: 73.4375%, Training Loss: 0.3950%\n",
      "Epoch [185/300], Step [14/23], Training Accuracy: 73.8839%, Training Loss: 0.3931%\n",
      "Epoch [185/300], Step [15/23], Training Accuracy: 73.5417%, Training Loss: 0.3958%\n",
      "Epoch [185/300], Step [16/23], Training Accuracy: 73.4375%, Training Loss: 0.3975%\n",
      "Epoch [185/300], Step [17/23], Training Accuracy: 73.2537%, Training Loss: 0.3978%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [185/300], Step [18/23], Training Accuracy: 73.4375%, Training Loss: 0.3976%\n",
      "Epoch [185/300], Step [19/23], Training Accuracy: 73.2730%, Training Loss: 0.3974%\n",
      "Epoch [185/300], Step [20/23], Training Accuracy: 73.6719%, Training Loss: 0.3944%\n",
      "Epoch [185/300], Step [21/23], Training Accuracy: 73.5863%, Training Loss: 0.3940%\n",
      "Epoch [185/300], Step [22/23], Training Accuracy: 73.7926%, Training Loss: 0.3934%\n",
      "Epoch [185/300], Step [23/23], Training Accuracy: 74.0097%, Training Loss: 0.3889%\n",
      "Epoch [186/300], Step [1/23], Training Accuracy: 70.3125%, Training Loss: 0.3734%\n",
      "Epoch [186/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.3920%\n",
      "Epoch [186/300], Step [3/23], Training Accuracy: 72.9167%, Training Loss: 0.4045%\n",
      "Epoch [186/300], Step [4/23], Training Accuracy: 73.4375%, Training Loss: 0.3910%\n",
      "Epoch [186/300], Step [5/23], Training Accuracy: 72.5000%, Training Loss: 0.3906%\n",
      "Epoch [186/300], Step [6/23], Training Accuracy: 73.1771%, Training Loss: 0.3914%\n",
      "Epoch [186/300], Step [7/23], Training Accuracy: 72.7679%, Training Loss: 0.3964%\n",
      "Epoch [186/300], Step [8/23], Training Accuracy: 74.4141%, Training Loss: 0.3956%\n",
      "Epoch [186/300], Step [9/23], Training Accuracy: 73.0903%, Training Loss: 0.3993%\n",
      "Epoch [186/300], Step [10/23], Training Accuracy: 72.9688%, Training Loss: 0.3985%\n",
      "Epoch [186/300], Step [11/23], Training Accuracy: 73.0114%, Training Loss: 0.3981%\n",
      "Epoch [186/300], Step [12/23], Training Accuracy: 73.0469%, Training Loss: 0.3989%\n",
      "Epoch [186/300], Step [13/23], Training Accuracy: 72.7163%, Training Loss: 0.4014%\n",
      "Epoch [186/300], Step [14/23], Training Accuracy: 73.1027%, Training Loss: 0.3997%\n",
      "Epoch [186/300], Step [15/23], Training Accuracy: 72.9167%, Training Loss: 0.4017%\n",
      "Epoch [186/300], Step [16/23], Training Accuracy: 72.9492%, Training Loss: 0.4008%\n",
      "Epoch [186/300], Step [17/23], Training Accuracy: 73.1618%, Training Loss: 0.4002%\n",
      "Epoch [186/300], Step [18/23], Training Accuracy: 73.2639%, Training Loss: 0.3995%\n",
      "Epoch [186/300], Step [19/23], Training Accuracy: 73.6020%, Training Loss: 0.3981%\n",
      "Epoch [186/300], Step [20/23], Training Accuracy: 73.9062%, Training Loss: 0.3956%\n",
      "Epoch [186/300], Step [21/23], Training Accuracy: 73.8095%, Training Loss: 0.3951%\n",
      "Epoch [186/300], Step [22/23], Training Accuracy: 73.7216%, Training Loss: 0.3952%\n",
      "Epoch [186/300], Step [23/23], Training Accuracy: 73.9402%, Training Loss: 0.3922%\n",
      "Epoch [187/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3868%\n",
      "Epoch [187/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.4065%\n",
      "Epoch [187/300], Step [3/23], Training Accuracy: 71.3542%, Training Loss: 0.4143%\n",
      "Epoch [187/300], Step [4/23], Training Accuracy: 74.2188%, Training Loss: 0.3939%\n",
      "Epoch [187/300], Step [5/23], Training Accuracy: 72.8125%, Training Loss: 0.3927%\n",
      "Epoch [187/300], Step [6/23], Training Accuracy: 74.4792%, Training Loss: 0.3911%\n",
      "Epoch [187/300], Step [7/23], Training Accuracy: 75.4464%, Training Loss: 0.3924%\n",
      "Epoch [187/300], Step [8/23], Training Accuracy: 75.0000%, Training Loss: 0.3950%\n",
      "Epoch [187/300], Step [9/23], Training Accuracy: 74.1319%, Training Loss: 0.4001%\n",
      "Epoch [187/300], Step [10/23], Training Accuracy: 73.5938%, Training Loss: 0.3999%\n",
      "Epoch [187/300], Step [11/23], Training Accuracy: 73.7216%, Training Loss: 0.4003%\n",
      "Epoch [187/300], Step [12/23], Training Accuracy: 73.4375%, Training Loss: 0.4024%\n",
      "Epoch [187/300], Step [13/23], Training Accuracy: 73.4375%, Training Loss: 0.4051%\n",
      "Epoch [187/300], Step [14/23], Training Accuracy: 73.3259%, Training Loss: 0.4028%\n",
      "Epoch [187/300], Step [15/23], Training Accuracy: 73.0208%, Training Loss: 0.4068%\n",
      "Epoch [187/300], Step [16/23], Training Accuracy: 72.9492%, Training Loss: 0.4073%\n",
      "Epoch [187/300], Step [17/23], Training Accuracy: 73.1618%, Training Loss: 0.4069%\n",
      "Epoch [187/300], Step [18/23], Training Accuracy: 73.0903%, Training Loss: 0.4069%\n",
      "Epoch [187/300], Step [19/23], Training Accuracy: 73.1908%, Training Loss: 0.4064%\n",
      "Epoch [187/300], Step [20/23], Training Accuracy: 73.3594%, Training Loss: 0.4058%\n",
      "Epoch [187/300], Step [21/23], Training Accuracy: 73.5119%, Training Loss: 0.4051%\n",
      "Epoch [187/300], Step [22/23], Training Accuracy: 73.8636%, Training Loss: 0.4031%\n",
      "Epoch [187/300], Step [23/23], Training Accuracy: 73.8707%, Training Loss: 0.3999%\n",
      "Epoch [188/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3683%\n",
      "Epoch [188/300], Step [2/23], Training Accuracy: 72.6562%, Training Loss: 0.3971%\n",
      "Epoch [188/300], Step [3/23], Training Accuracy: 72.3958%, Training Loss: 0.3994%\n",
      "Epoch [188/300], Step [4/23], Training Accuracy: 76.1719%, Training Loss: 0.3846%\n",
      "Epoch [188/300], Step [5/23], Training Accuracy: 75.0000%, Training Loss: 0.3851%\n",
      "Epoch [188/300], Step [6/23], Training Accuracy: 75.5208%, Training Loss: 0.3847%\n",
      "Epoch [188/300], Step [7/23], Training Accuracy: 75.6696%, Training Loss: 0.3889%\n",
      "Epoch [188/300], Step [8/23], Training Accuracy: 76.1719%, Training Loss: 0.3870%\n",
      "Epoch [188/300], Step [9/23], Training Accuracy: 75.3472%, Training Loss: 0.3927%\n",
      "Epoch [188/300], Step [10/23], Training Accuracy: 75.3125%, Training Loss: 0.3911%\n",
      "Epoch [188/300], Step [11/23], Training Accuracy: 75.8523%, Training Loss: 0.3892%\n",
      "Epoch [188/300], Step [12/23], Training Accuracy: 75.1302%, Training Loss: 0.3901%\n",
      "Epoch [188/300], Step [13/23], Training Accuracy: 74.2788%, Training Loss: 0.3934%\n",
      "Epoch [188/300], Step [14/23], Training Accuracy: 74.7768%, Training Loss: 0.3907%\n",
      "Epoch [188/300], Step [15/23], Training Accuracy: 74.1667%, Training Loss: 0.3930%\n",
      "Epoch [188/300], Step [16/23], Training Accuracy: 74.0234%, Training Loss: 0.3935%\n",
      "Epoch [188/300], Step [17/23], Training Accuracy: 74.3566%, Training Loss: 0.3942%\n",
      "Epoch [188/300], Step [18/23], Training Accuracy: 74.1319%, Training Loss: 0.3947%\n",
      "Epoch [188/300], Step [19/23], Training Accuracy: 74.1776%, Training Loss: 0.3952%\n",
      "Epoch [188/300], Step [20/23], Training Accuracy: 74.1406%, Training Loss: 0.3938%\n",
      "Epoch [188/300], Step [21/23], Training Accuracy: 73.8095%, Training Loss: 0.3954%\n",
      "Epoch [188/300], Step [22/23], Training Accuracy: 73.7926%, Training Loss: 0.3940%\n",
      "Epoch [188/300], Step [23/23], Training Accuracy: 73.8707%, Training Loss: 0.3918%\n",
      "Epoch [189/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3867%\n",
      "Epoch [189/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.4013%\n",
      "Epoch [189/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.4060%\n",
      "Epoch [189/300], Step [4/23], Training Accuracy: 74.2188%, Training Loss: 0.3889%\n",
      "Epoch [189/300], Step [5/23], Training Accuracy: 72.1875%, Training Loss: 0.3928%\n",
      "Epoch [189/300], Step [6/23], Training Accuracy: 73.4375%, Training Loss: 0.3932%\n",
      "Epoch [189/300], Step [7/23], Training Accuracy: 73.4375%, Training Loss: 0.3973%\n",
      "Epoch [189/300], Step [8/23], Training Accuracy: 74.2188%, Training Loss: 0.3963%\n",
      "Epoch [189/300], Step [9/23], Training Accuracy: 73.4375%, Training Loss: 0.3987%\n",
      "Epoch [189/300], Step [10/23], Training Accuracy: 73.9062%, Training Loss: 0.3953%\n",
      "Epoch [189/300], Step [11/23], Training Accuracy: 74.2898%, Training Loss: 0.3950%\n",
      "Epoch [189/300], Step [12/23], Training Accuracy: 73.8281%, Training Loss: 0.3960%\n",
      "Epoch [189/300], Step [13/23], Training Accuracy: 73.5577%, Training Loss: 0.3968%\n",
      "Epoch [189/300], Step [14/23], Training Accuracy: 73.6607%, Training Loss: 0.3944%\n",
      "Epoch [189/300], Step [15/23], Training Accuracy: 73.0208%, Training Loss: 0.3978%\n",
      "Epoch [189/300], Step [16/23], Training Accuracy: 72.7539%, Training Loss: 0.3989%\n",
      "Epoch [189/300], Step [17/23], Training Accuracy: 72.9779%, Training Loss: 0.3981%\n",
      "Epoch [189/300], Step [18/23], Training Accuracy: 72.8299%, Training Loss: 0.3992%\n",
      "Epoch [189/300], Step [19/23], Training Accuracy: 73.1086%, Training Loss: 0.3973%\n",
      "Epoch [189/300], Step [20/23], Training Accuracy: 73.1250%, Training Loss: 0.3961%\n",
      "Epoch [189/300], Step [21/23], Training Accuracy: 73.1399%, Training Loss: 0.3961%\n",
      "Epoch [189/300], Step [22/23], Training Accuracy: 72.9403%, Training Loss: 0.3959%\n",
      "Epoch [189/300], Step [23/23], Training Accuracy: 73.1063%, Training Loss: 0.3930%\n",
      "Epoch [190/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3738%\n",
      "Epoch [190/300], Step [2/23], Training Accuracy: 75.7812%, Training Loss: 0.3952%\n",
      "Epoch [190/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.4044%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [190/300], Step [4/23], Training Accuracy: 74.2188%, Training Loss: 0.3911%\n",
      "Epoch [190/300], Step [5/23], Training Accuracy: 73.4375%, Training Loss: 0.3910%\n",
      "Epoch [190/300], Step [6/23], Training Accuracy: 74.7396%, Training Loss: 0.3909%\n",
      "Epoch [190/300], Step [7/23], Training Accuracy: 75.4464%, Training Loss: 0.3936%\n",
      "Epoch [190/300], Step [8/23], Training Accuracy: 75.5859%, Training Loss: 0.3906%\n",
      "Epoch [190/300], Step [9/23], Training Accuracy: 74.4792%, Training Loss: 0.3950%\n",
      "Epoch [190/300], Step [10/23], Training Accuracy: 74.5312%, Training Loss: 0.3923%\n",
      "Epoch [190/300], Step [11/23], Training Accuracy: 74.1477%, Training Loss: 0.3932%\n",
      "Epoch [190/300], Step [12/23], Training Accuracy: 74.3490%, Training Loss: 0.3948%\n",
      "Epoch [190/300], Step [13/23], Training Accuracy: 73.9183%, Training Loss: 0.3970%\n",
      "Epoch [190/300], Step [14/23], Training Accuracy: 74.2188%, Training Loss: 0.3935%\n",
      "Epoch [190/300], Step [15/23], Training Accuracy: 73.7500%, Training Loss: 0.3951%\n",
      "Epoch [190/300], Step [16/23], Training Accuracy: 74.1211%, Training Loss: 0.3943%\n",
      "Epoch [190/300], Step [17/23], Training Accuracy: 73.9890%, Training Loss: 0.3953%\n",
      "Epoch [190/300], Step [18/23], Training Accuracy: 74.0451%, Training Loss: 0.3952%\n",
      "Epoch [190/300], Step [19/23], Training Accuracy: 74.0954%, Training Loss: 0.3949%\n",
      "Epoch [190/300], Step [20/23], Training Accuracy: 74.1406%, Training Loss: 0.3946%\n",
      "Epoch [190/300], Step [21/23], Training Accuracy: 74.3304%, Training Loss: 0.3941%\n",
      "Epoch [190/300], Step [22/23], Training Accuracy: 74.5739%, Training Loss: 0.3933%\n",
      "Epoch [190/300], Step [23/23], Training Accuracy: 74.5657%, Training Loss: 0.3898%\n",
      "Epoch [191/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3695%\n",
      "Epoch [191/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.3949%\n",
      "Epoch [191/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.4041%\n",
      "Epoch [191/300], Step [4/23], Training Accuracy: 71.8750%, Training Loss: 0.3899%\n",
      "Epoch [191/300], Step [5/23], Training Accuracy: 70.6250%, Training Loss: 0.3933%\n",
      "Epoch [191/300], Step [6/23], Training Accuracy: 72.1354%, Training Loss: 0.3904%\n",
      "Epoch [191/300], Step [7/23], Training Accuracy: 72.7679%, Training Loss: 0.3953%\n",
      "Epoch [191/300], Step [8/23], Training Accuracy: 73.4375%, Training Loss: 0.3966%\n",
      "Epoch [191/300], Step [9/23], Training Accuracy: 72.0486%, Training Loss: 0.4003%\n",
      "Epoch [191/300], Step [10/23], Training Accuracy: 72.1875%, Training Loss: 0.3991%\n",
      "Epoch [191/300], Step [11/23], Training Accuracy: 72.8693%, Training Loss: 0.3966%\n",
      "Epoch [191/300], Step [12/23], Training Accuracy: 72.9167%, Training Loss: 0.3972%\n",
      "Epoch [191/300], Step [13/23], Training Accuracy: 72.7163%, Training Loss: 0.3989%\n",
      "Epoch [191/300], Step [14/23], Training Accuracy: 73.1027%, Training Loss: 0.3983%\n",
      "Epoch [191/300], Step [15/23], Training Accuracy: 72.8125%, Training Loss: 0.3999%\n",
      "Epoch [191/300], Step [16/23], Training Accuracy: 72.8516%, Training Loss: 0.3989%\n",
      "Epoch [191/300], Step [17/23], Training Accuracy: 73.1618%, Training Loss: 0.3983%\n",
      "Epoch [191/300], Step [18/23], Training Accuracy: 73.4375%, Training Loss: 0.3981%\n",
      "Epoch [191/300], Step [19/23], Training Accuracy: 73.6842%, Training Loss: 0.3979%\n",
      "Epoch [191/300], Step [20/23], Training Accuracy: 73.7500%, Training Loss: 0.3965%\n",
      "Epoch [191/300], Step [21/23], Training Accuracy: 73.5863%, Training Loss: 0.3955%\n",
      "Epoch [191/300], Step [22/23], Training Accuracy: 73.6506%, Training Loss: 0.3950%\n",
      "Epoch [191/300], Step [23/23], Training Accuracy: 73.7318%, Training Loss: 0.3917%\n",
      "Epoch [192/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3683%\n",
      "Epoch [192/300], Step [2/23], Training Accuracy: 71.8750%, Training Loss: 0.4006%\n",
      "Epoch [192/300], Step [3/23], Training Accuracy: 71.3542%, Training Loss: 0.4015%\n",
      "Epoch [192/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.3851%\n",
      "Epoch [192/300], Step [5/23], Training Accuracy: 72.1875%, Training Loss: 0.3892%\n",
      "Epoch [192/300], Step [6/23], Training Accuracy: 72.1354%, Training Loss: 0.3935%\n",
      "Epoch [192/300], Step [7/23], Training Accuracy: 72.9911%, Training Loss: 0.3969%\n",
      "Epoch [192/300], Step [8/23], Training Accuracy: 73.6328%, Training Loss: 0.3959%\n",
      "Epoch [192/300], Step [9/23], Training Accuracy: 72.7431%, Training Loss: 0.4033%\n",
      "Epoch [192/300], Step [10/23], Training Accuracy: 73.5938%, Training Loss: 0.4010%\n",
      "Epoch [192/300], Step [11/23], Training Accuracy: 73.7216%, Training Loss: 0.4000%\n",
      "Epoch [192/300], Step [12/23], Training Accuracy: 73.5677%, Training Loss: 0.4008%\n",
      "Epoch [192/300], Step [13/23], Training Accuracy: 73.5577%, Training Loss: 0.4008%\n",
      "Epoch [192/300], Step [14/23], Training Accuracy: 74.2188%, Training Loss: 0.3976%\n",
      "Epoch [192/300], Step [15/23], Training Accuracy: 73.8542%, Training Loss: 0.3994%\n",
      "Epoch [192/300], Step [16/23], Training Accuracy: 73.1445%, Training Loss: 0.4014%\n",
      "Epoch [192/300], Step [17/23], Training Accuracy: 73.4375%, Training Loss: 0.4021%\n",
      "Epoch [192/300], Step [18/23], Training Accuracy: 73.4375%, Training Loss: 0.4029%\n",
      "Epoch [192/300], Step [19/23], Training Accuracy: 73.6842%, Training Loss: 0.4010%\n",
      "Epoch [192/300], Step [20/23], Training Accuracy: 73.8281%, Training Loss: 0.4000%\n",
      "Epoch [192/300], Step [21/23], Training Accuracy: 73.8095%, Training Loss: 0.4001%\n",
      "Epoch [192/300], Step [22/23], Training Accuracy: 73.9347%, Training Loss: 0.3992%\n",
      "Epoch [192/300], Step [23/23], Training Accuracy: 74.0097%, Training Loss: 0.3965%\n",
      "Epoch [193/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3747%\n",
      "Epoch [193/300], Step [2/23], Training Accuracy: 78.1250%, Training Loss: 0.3908%\n",
      "Epoch [193/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.4078%\n",
      "Epoch [193/300], Step [4/23], Training Accuracy: 75.7812%, Training Loss: 0.3879%\n",
      "Epoch [193/300], Step [5/23], Training Accuracy: 74.3750%, Training Loss: 0.3873%\n",
      "Epoch [193/300], Step [6/23], Training Accuracy: 74.4792%, Training Loss: 0.3884%\n",
      "Epoch [193/300], Step [7/23], Training Accuracy: 73.8839%, Training Loss: 0.3932%\n",
      "Epoch [193/300], Step [8/23], Training Accuracy: 74.6094%, Training Loss: 0.3923%\n",
      "Epoch [193/300], Step [9/23], Training Accuracy: 73.2639%, Training Loss: 0.3992%\n",
      "Epoch [193/300], Step [10/23], Training Accuracy: 73.7500%, Training Loss: 0.3968%\n",
      "Epoch [193/300], Step [11/23], Training Accuracy: 74.0057%, Training Loss: 0.3956%\n",
      "Epoch [193/300], Step [12/23], Training Accuracy: 74.2188%, Training Loss: 0.3956%\n",
      "Epoch [193/300], Step [13/23], Training Accuracy: 74.1587%, Training Loss: 0.3961%\n",
      "Epoch [193/300], Step [14/23], Training Accuracy: 74.2188%, Training Loss: 0.3952%\n",
      "Epoch [193/300], Step [15/23], Training Accuracy: 74.6875%, Training Loss: 0.3962%\n",
      "Epoch [193/300], Step [16/23], Training Accuracy: 74.5117%, Training Loss: 0.3960%\n",
      "Epoch [193/300], Step [17/23], Training Accuracy: 74.4485%, Training Loss: 0.3965%\n",
      "Epoch [193/300], Step [18/23], Training Accuracy: 73.9583%, Training Loss: 0.3980%\n",
      "Epoch [193/300], Step [19/23], Training Accuracy: 74.1776%, Training Loss: 0.3967%\n",
      "Epoch [193/300], Step [20/23], Training Accuracy: 74.2969%, Training Loss: 0.3950%\n",
      "Epoch [193/300], Step [21/23], Training Accuracy: 74.0327%, Training Loss: 0.3957%\n",
      "Epoch [193/300], Step [22/23], Training Accuracy: 74.0767%, Training Loss: 0.3943%\n",
      "Epoch [193/300], Step [23/23], Training Accuracy: 74.2182%, Training Loss: 0.3906%\n",
      "Epoch [194/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3857%\n",
      "Epoch [194/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.4015%\n",
      "Epoch [194/300], Step [3/23], Training Accuracy: 74.4792%, Training Loss: 0.4064%\n",
      "Epoch [194/300], Step [4/23], Training Accuracy: 77.3438%, Training Loss: 0.3930%\n",
      "Epoch [194/300], Step [5/23], Training Accuracy: 75.6250%, Training Loss: 0.3910%\n",
      "Epoch [194/300], Step [6/23], Training Accuracy: 76.5625%, Training Loss: 0.3889%\n",
      "Epoch [194/300], Step [7/23], Training Accuracy: 75.8929%, Training Loss: 0.3954%\n",
      "Epoch [194/300], Step [8/23], Training Accuracy: 75.7812%, Training Loss: 0.3975%\n",
      "Epoch [194/300], Step [9/23], Training Accuracy: 74.6528%, Training Loss: 0.4022%\n",
      "Epoch [194/300], Step [10/23], Training Accuracy: 73.7500%, Training Loss: 0.4014%\n",
      "Epoch [194/300], Step [11/23], Training Accuracy: 73.7216%, Training Loss: 0.4011%\n",
      "Epoch [194/300], Step [12/23], Training Accuracy: 74.2188%, Training Loss: 0.4006%\n",
      "Epoch [194/300], Step [13/23], Training Accuracy: 73.9183%, Training Loss: 0.4028%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [194/300], Step [14/23], Training Accuracy: 74.4420%, Training Loss: 0.3988%\n",
      "Epoch [194/300], Step [15/23], Training Accuracy: 73.7500%, Training Loss: 0.4037%\n",
      "Epoch [194/300], Step [16/23], Training Accuracy: 73.7305%, Training Loss: 0.4032%\n",
      "Epoch [194/300], Step [17/23], Training Accuracy: 73.9890%, Training Loss: 0.4012%\n",
      "Epoch [194/300], Step [18/23], Training Accuracy: 74.0451%, Training Loss: 0.4010%\n",
      "Epoch [194/300], Step [19/23], Training Accuracy: 73.8487%, Training Loss: 0.4016%\n",
      "Epoch [194/300], Step [20/23], Training Accuracy: 74.1406%, Training Loss: 0.3992%\n",
      "Epoch [194/300], Step [21/23], Training Accuracy: 73.9583%, Training Loss: 0.3994%\n",
      "Epoch [194/300], Step [22/23], Training Accuracy: 74.1477%, Training Loss: 0.3977%\n",
      "Epoch [194/300], Step [23/23], Training Accuracy: 74.1487%, Training Loss: 0.3944%\n",
      "Epoch [195/300], Step [1/23], Training Accuracy: 81.2500%, Training Loss: 0.3719%\n",
      "Epoch [195/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3931%\n",
      "Epoch [195/300], Step [3/23], Training Accuracy: 74.4792%, Training Loss: 0.3930%\n",
      "Epoch [195/300], Step [4/23], Training Accuracy: 76.1719%, Training Loss: 0.3779%\n",
      "Epoch [195/300], Step [5/23], Training Accuracy: 75.0000%, Training Loss: 0.3801%\n",
      "Epoch [195/300], Step [6/23], Training Accuracy: 75.5208%, Training Loss: 0.3829%\n",
      "Epoch [195/300], Step [7/23], Training Accuracy: 75.2232%, Training Loss: 0.3878%\n",
      "Epoch [195/300], Step [8/23], Training Accuracy: 76.1719%, Training Loss: 0.3878%\n",
      "Epoch [195/300], Step [9/23], Training Accuracy: 74.8264%, Training Loss: 0.3946%\n",
      "Epoch [195/300], Step [10/23], Training Accuracy: 75.3125%, Training Loss: 0.3932%\n",
      "Epoch [195/300], Step [11/23], Training Accuracy: 74.7159%, Training Loss: 0.3950%\n",
      "Epoch [195/300], Step [12/23], Training Accuracy: 75.2604%, Training Loss: 0.3962%\n",
      "Epoch [195/300], Step [13/23], Training Accuracy: 74.5192%, Training Loss: 0.3996%\n",
      "Epoch [195/300], Step [14/23], Training Accuracy: 75.1116%, Training Loss: 0.3956%\n",
      "Epoch [195/300], Step [15/23], Training Accuracy: 75.3125%, Training Loss: 0.3968%\n",
      "Epoch [195/300], Step [16/23], Training Accuracy: 74.9023%, Training Loss: 0.3972%\n",
      "Epoch [195/300], Step [17/23], Training Accuracy: 75.0919%, Training Loss: 0.3972%\n",
      "Epoch [195/300], Step [18/23], Training Accuracy: 75.0868%, Training Loss: 0.3964%\n",
      "Epoch [195/300], Step [19/23], Training Accuracy: 75.3289%, Training Loss: 0.3959%\n",
      "Epoch [195/300], Step [20/23], Training Accuracy: 75.3906%, Training Loss: 0.3939%\n",
      "Epoch [195/300], Step [21/23], Training Accuracy: 75.1488%, Training Loss: 0.3946%\n",
      "Epoch [195/300], Step [22/23], Training Accuracy: 75.3551%, Training Loss: 0.3935%\n",
      "Epoch [195/300], Step [23/23], Training Accuracy: 75.3301%, Training Loss: 0.3912%\n",
      "Epoch [196/300], Step [1/23], Training Accuracy: 71.8750%, Training Loss: 0.3859%\n",
      "Epoch [196/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.4003%\n",
      "Epoch [196/300], Step [3/23], Training Accuracy: 72.3958%, Training Loss: 0.4062%\n",
      "Epoch [196/300], Step [4/23], Training Accuracy: 75.3906%, Training Loss: 0.3867%\n",
      "Epoch [196/300], Step [5/23], Training Accuracy: 74.6875%, Training Loss: 0.3951%\n",
      "Epoch [196/300], Step [6/23], Training Accuracy: 75.5208%, Training Loss: 0.3926%\n",
      "Epoch [196/300], Step [7/23], Training Accuracy: 75.0000%, Training Loss: 0.3991%\n",
      "Epoch [196/300], Step [8/23], Training Accuracy: 74.8047%, Training Loss: 0.3981%\n",
      "Epoch [196/300], Step [9/23], Training Accuracy: 74.1319%, Training Loss: 0.4013%\n",
      "Epoch [196/300], Step [10/23], Training Accuracy: 74.3750%, Training Loss: 0.3993%\n",
      "Epoch [196/300], Step [11/23], Training Accuracy: 74.2898%, Training Loss: 0.3986%\n",
      "Epoch [196/300], Step [12/23], Training Accuracy: 74.3490%, Training Loss: 0.3999%\n",
      "Epoch [196/300], Step [13/23], Training Accuracy: 73.4375%, Training Loss: 0.4020%\n",
      "Epoch [196/300], Step [14/23], Training Accuracy: 73.7723%, Training Loss: 0.4008%\n",
      "Epoch [196/300], Step [15/23], Training Accuracy: 73.1250%, Training Loss: 0.4053%\n",
      "Epoch [196/300], Step [16/23], Training Accuracy: 73.0469%, Training Loss: 0.4053%\n",
      "Epoch [196/300], Step [17/23], Training Accuracy: 73.1618%, Training Loss: 0.4042%\n",
      "Epoch [196/300], Step [18/23], Training Accuracy: 73.3507%, Training Loss: 0.4041%\n",
      "Epoch [196/300], Step [19/23], Training Accuracy: 73.6020%, Training Loss: 0.4021%\n",
      "Epoch [196/300], Step [20/23], Training Accuracy: 74.0625%, Training Loss: 0.4000%\n",
      "Epoch [196/300], Step [21/23], Training Accuracy: 73.8839%, Training Loss: 0.4000%\n",
      "Epoch [196/300], Step [22/23], Training Accuracy: 74.1477%, Training Loss: 0.3988%\n",
      "Epoch [196/300], Step [23/23], Training Accuracy: 74.2877%, Training Loss: 0.3953%\n",
      "Epoch [197/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3595%\n",
      "Epoch [197/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3859%\n",
      "Epoch [197/300], Step [3/23], Training Accuracy: 73.4375%, Training Loss: 0.3975%\n",
      "Epoch [197/300], Step [4/23], Training Accuracy: 75.7812%, Training Loss: 0.3856%\n",
      "Epoch [197/300], Step [5/23], Training Accuracy: 75.6250%, Training Loss: 0.3860%\n",
      "Epoch [197/300], Step [6/23], Training Accuracy: 75.7812%, Training Loss: 0.3888%\n",
      "Epoch [197/300], Step [7/23], Training Accuracy: 74.7768%, Training Loss: 0.3986%\n",
      "Epoch [197/300], Step [8/23], Training Accuracy: 75.5859%, Training Loss: 0.3950%\n",
      "Epoch [197/300], Step [9/23], Training Accuracy: 73.7847%, Training Loss: 0.4028%\n",
      "Epoch [197/300], Step [10/23], Training Accuracy: 74.5312%, Training Loss: 0.3984%\n",
      "Epoch [197/300], Step [11/23], Training Accuracy: 74.8580%, Training Loss: 0.3968%\n",
      "Epoch [197/300], Step [12/23], Training Accuracy: 74.2188%, Training Loss: 0.4001%\n",
      "Epoch [197/300], Step [13/23], Training Accuracy: 73.9183%, Training Loss: 0.4024%\n",
      "Epoch [197/300], Step [14/23], Training Accuracy: 74.3304%, Training Loss: 0.4006%\n",
      "Epoch [197/300], Step [15/23], Training Accuracy: 74.1667%, Training Loss: 0.4004%\n",
      "Epoch [197/300], Step [16/23], Training Accuracy: 74.0234%, Training Loss: 0.4000%\n",
      "Epoch [197/300], Step [17/23], Training Accuracy: 73.9890%, Training Loss: 0.3997%\n",
      "Epoch [197/300], Step [18/23], Training Accuracy: 74.2188%, Training Loss: 0.3993%\n",
      "Epoch [197/300], Step [19/23], Training Accuracy: 74.2599%, Training Loss: 0.3994%\n",
      "Epoch [197/300], Step [20/23], Training Accuracy: 74.5312%, Training Loss: 0.3983%\n",
      "Epoch [197/300], Step [21/23], Training Accuracy: 74.3304%, Training Loss: 0.3991%\n",
      "Epoch [197/300], Step [22/23], Training Accuracy: 74.4318%, Training Loss: 0.3980%\n",
      "Epoch [197/300], Step [23/23], Training Accuracy: 74.5657%, Training Loss: 0.3945%\n",
      "Epoch [198/300], Step [1/23], Training Accuracy: 73.4375%, Training Loss: 0.3858%\n",
      "Epoch [198/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.3963%\n",
      "Epoch [198/300], Step [3/23], Training Accuracy: 70.3125%, Training Loss: 0.4078%\n",
      "Epoch [198/300], Step [4/23], Training Accuracy: 73.4375%, Training Loss: 0.3895%\n",
      "Epoch [198/300], Step [5/23], Training Accuracy: 73.1250%, Training Loss: 0.3903%\n",
      "Epoch [198/300], Step [6/23], Training Accuracy: 73.9583%, Training Loss: 0.3944%\n",
      "Epoch [198/300], Step [7/23], Training Accuracy: 74.5536%, Training Loss: 0.3970%\n",
      "Epoch [198/300], Step [8/23], Training Accuracy: 75.1953%, Training Loss: 0.3963%\n",
      "Epoch [198/300], Step [9/23], Training Accuracy: 74.6528%, Training Loss: 0.3997%\n",
      "Epoch [198/300], Step [10/23], Training Accuracy: 74.2188%, Training Loss: 0.3982%\n",
      "Epoch [198/300], Step [11/23], Training Accuracy: 74.5739%, Training Loss: 0.3975%\n",
      "Epoch [198/300], Step [12/23], Training Accuracy: 74.0885%, Training Loss: 0.4003%\n",
      "Epoch [198/300], Step [13/23], Training Accuracy: 73.6779%, Training Loss: 0.4028%\n",
      "Epoch [198/300], Step [14/23], Training Accuracy: 73.9955%, Training Loss: 0.4016%\n",
      "Epoch [198/300], Step [15/23], Training Accuracy: 73.3333%, Training Loss: 0.4052%\n",
      "Epoch [198/300], Step [16/23], Training Accuracy: 73.3398%, Training Loss: 0.4038%\n",
      "Epoch [198/300], Step [17/23], Training Accuracy: 73.3456%, Training Loss: 0.4048%\n",
      "Epoch [198/300], Step [18/23], Training Accuracy: 73.2639%, Training Loss: 0.4059%\n",
      "Epoch [198/300], Step [19/23], Training Accuracy: 73.5197%, Training Loss: 0.4056%\n",
      "Epoch [198/300], Step [20/23], Training Accuracy: 73.9062%, Training Loss: 0.4034%\n",
      "Epoch [198/300], Step [21/23], Training Accuracy: 73.9583%, Training Loss: 0.4021%\n",
      "Epoch [198/300], Step [22/23], Training Accuracy: 74.0057%, Training Loss: 0.3998%\n",
      "Epoch [198/300], Step [23/23], Training Accuracy: 74.2182%, Training Loss: 0.3950%\n",
      "Epoch [199/300], Step [1/23], Training Accuracy: 81.2500%, Training Loss: 0.3589%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [199/300], Step [2/23], Training Accuracy: 78.9062%, Training Loss: 0.3845%\n",
      "Epoch [199/300], Step [3/23], Training Accuracy: 75.0000%, Training Loss: 0.3929%\n",
      "Epoch [199/300], Step [4/23], Training Accuracy: 77.3438%, Training Loss: 0.3797%\n",
      "Epoch [199/300], Step [5/23], Training Accuracy: 76.2500%, Training Loss: 0.3846%\n",
      "Epoch [199/300], Step [6/23], Training Accuracy: 76.8229%, Training Loss: 0.3826%\n",
      "Epoch [199/300], Step [7/23], Training Accuracy: 76.3393%, Training Loss: 0.3886%\n",
      "Epoch [199/300], Step [8/23], Training Accuracy: 76.7578%, Training Loss: 0.3894%\n",
      "Epoch [199/300], Step [9/23], Training Accuracy: 75.5208%, Training Loss: 0.3916%\n",
      "Epoch [199/300], Step [10/23], Training Accuracy: 75.3125%, Training Loss: 0.3909%\n",
      "Epoch [199/300], Step [11/23], Training Accuracy: 75.7102%, Training Loss: 0.3893%\n",
      "Epoch [199/300], Step [12/23], Training Accuracy: 75.9115%, Training Loss: 0.3898%\n",
      "Epoch [199/300], Step [13/23], Training Accuracy: 75.9615%, Training Loss: 0.3911%\n",
      "Epoch [199/300], Step [14/23], Training Accuracy: 76.4509%, Training Loss: 0.3901%\n",
      "Epoch [199/300], Step [15/23], Training Accuracy: 76.5625%, Training Loss: 0.3932%\n",
      "Epoch [199/300], Step [16/23], Training Accuracy: 76.2695%, Training Loss: 0.3931%\n",
      "Epoch [199/300], Step [17/23], Training Accuracy: 76.1029%, Training Loss: 0.3939%\n",
      "Epoch [199/300], Step [18/23], Training Accuracy: 76.2153%, Training Loss: 0.3927%\n",
      "Epoch [199/300], Step [19/23], Training Accuracy: 76.4803%, Training Loss: 0.3909%\n",
      "Epoch [199/300], Step [20/23], Training Accuracy: 76.3281%, Training Loss: 0.3903%\n",
      "Epoch [199/300], Step [21/23], Training Accuracy: 75.9673%, Training Loss: 0.3898%\n",
      "Epoch [199/300], Step [22/23], Training Accuracy: 75.9943%, Training Loss: 0.3899%\n",
      "Epoch [199/300], Step [23/23], Training Accuracy: 75.9555%, Training Loss: 0.3872%\n",
      "Epoch [200/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3454%\n",
      "Epoch [200/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.3699%\n",
      "Epoch [200/300], Step [3/23], Training Accuracy: 73.4375%, Training Loss: 0.3871%\n",
      "Epoch [200/300], Step [4/23], Training Accuracy: 75.0000%, Training Loss: 0.3820%\n",
      "Epoch [200/300], Step [5/23], Training Accuracy: 74.0625%, Training Loss: 0.3812%\n",
      "Epoch [200/300], Step [6/23], Training Accuracy: 75.2604%, Training Loss: 0.3794%\n",
      "Epoch [200/300], Step [7/23], Training Accuracy: 75.6696%, Training Loss: 0.3846%\n",
      "Epoch [200/300], Step [8/23], Training Accuracy: 75.9766%, Training Loss: 0.3850%\n",
      "Epoch [200/300], Step [9/23], Training Accuracy: 75.0000%, Training Loss: 0.3912%\n",
      "Epoch [200/300], Step [10/23], Training Accuracy: 74.3750%, Training Loss: 0.3930%\n",
      "Epoch [200/300], Step [11/23], Training Accuracy: 74.1477%, Training Loss: 0.3920%\n",
      "Epoch [200/300], Step [12/23], Training Accuracy: 74.0885%, Training Loss: 0.3951%\n",
      "Epoch [200/300], Step [13/23], Training Accuracy: 74.1587%, Training Loss: 0.3968%\n",
      "Epoch [200/300], Step [14/23], Training Accuracy: 74.2188%, Training Loss: 0.3949%\n",
      "Epoch [200/300], Step [15/23], Training Accuracy: 74.1667%, Training Loss: 0.3955%\n",
      "Epoch [200/300], Step [16/23], Training Accuracy: 74.0234%, Training Loss: 0.3969%\n",
      "Epoch [200/300], Step [17/23], Training Accuracy: 73.9890%, Training Loss: 0.3959%\n",
      "Epoch [200/300], Step [18/23], Training Accuracy: 73.7847%, Training Loss: 0.3958%\n",
      "Epoch [200/300], Step [19/23], Training Accuracy: 73.8487%, Training Loss: 0.3959%\n",
      "Epoch [200/300], Step [20/23], Training Accuracy: 74.2969%, Training Loss: 0.3938%\n",
      "Epoch [200/300], Step [21/23], Training Accuracy: 73.8839%, Training Loss: 0.3953%\n",
      "Epoch [200/300], Step [22/23], Training Accuracy: 73.7926%, Training Loss: 0.3953%\n",
      "Epoch [200/300], Step [23/23], Training Accuracy: 73.8707%, Training Loss: 0.3913%\n",
      "Epoch [201/300], Step [1/23], Training Accuracy: 81.2500%, Training Loss: 0.3635%\n",
      "Epoch [201/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.3942%\n",
      "Epoch [201/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.4048%\n",
      "Epoch [201/300], Step [4/23], Training Accuracy: 74.2188%, Training Loss: 0.3910%\n",
      "Epoch [201/300], Step [5/23], Training Accuracy: 73.1250%, Training Loss: 0.3947%\n",
      "Epoch [201/300], Step [6/23], Training Accuracy: 74.4792%, Training Loss: 0.3967%\n",
      "Epoch [201/300], Step [7/23], Training Accuracy: 74.1071%, Training Loss: 0.4020%\n",
      "Epoch [201/300], Step [8/23], Training Accuracy: 74.2188%, Training Loss: 0.3981%\n",
      "Epoch [201/300], Step [9/23], Training Accuracy: 73.6111%, Training Loss: 0.4015%\n",
      "Epoch [201/300], Step [10/23], Training Accuracy: 73.7500%, Training Loss: 0.4011%\n",
      "Epoch [201/300], Step [11/23], Training Accuracy: 74.2898%, Training Loss: 0.4004%\n",
      "Epoch [201/300], Step [12/23], Training Accuracy: 73.9583%, Training Loss: 0.4019%\n",
      "Epoch [201/300], Step [13/23], Training Accuracy: 73.9183%, Training Loss: 0.4016%\n",
      "Epoch [201/300], Step [14/23], Training Accuracy: 74.4420%, Training Loss: 0.3987%\n",
      "Epoch [201/300], Step [15/23], Training Accuracy: 74.0625%, Training Loss: 0.4005%\n",
      "Epoch [201/300], Step [16/23], Training Accuracy: 73.8281%, Training Loss: 0.4005%\n",
      "Epoch [201/300], Step [17/23], Training Accuracy: 74.0809%, Training Loss: 0.3995%\n",
      "Epoch [201/300], Step [18/23], Training Accuracy: 73.9583%, Training Loss: 0.4001%\n",
      "Epoch [201/300], Step [19/23], Training Accuracy: 73.9309%, Training Loss: 0.4001%\n",
      "Epoch [201/300], Step [20/23], Training Accuracy: 74.3750%, Training Loss: 0.3977%\n",
      "Epoch [201/300], Step [21/23], Training Accuracy: 74.4792%, Training Loss: 0.3971%\n",
      "Epoch [201/300], Step [22/23], Training Accuracy: 74.2898%, Training Loss: 0.3967%\n",
      "Epoch [201/300], Step [23/23], Training Accuracy: 74.4962%, Training Loss: 0.3932%\n",
      "Epoch [202/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.4013%\n",
      "Epoch [202/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.4115%\n",
      "Epoch [202/300], Step [3/23], Training Accuracy: 69.2708%, Training Loss: 0.4188%\n",
      "Epoch [202/300], Step [4/23], Training Accuracy: 73.0469%, Training Loss: 0.4006%\n",
      "Epoch [202/300], Step [5/23], Training Accuracy: 71.8750%, Training Loss: 0.4047%\n",
      "Epoch [202/300], Step [6/23], Training Accuracy: 72.6562%, Training Loss: 0.3992%\n",
      "Epoch [202/300], Step [7/23], Training Accuracy: 73.8839%, Training Loss: 0.4026%\n",
      "Epoch [202/300], Step [8/23], Training Accuracy: 74.4141%, Training Loss: 0.4018%\n",
      "Epoch [202/300], Step [9/23], Training Accuracy: 74.3056%, Training Loss: 0.4047%\n",
      "Epoch [202/300], Step [10/23], Training Accuracy: 74.5312%, Training Loss: 0.4028%\n",
      "Epoch [202/300], Step [11/23], Training Accuracy: 75.0000%, Training Loss: 0.3996%\n",
      "Epoch [202/300], Step [12/23], Training Accuracy: 74.6094%, Training Loss: 0.3996%\n",
      "Epoch [202/300], Step [13/23], Training Accuracy: 73.5577%, Training Loss: 0.4019%\n",
      "Epoch [202/300], Step [14/23], Training Accuracy: 73.7723%, Training Loss: 0.3989%\n",
      "Epoch [202/300], Step [15/23], Training Accuracy: 74.0625%, Training Loss: 0.4004%\n",
      "Epoch [202/300], Step [16/23], Training Accuracy: 74.4141%, Training Loss: 0.4001%\n",
      "Epoch [202/300], Step [17/23], Training Accuracy: 74.4485%, Training Loss: 0.3991%\n",
      "Epoch [202/300], Step [18/23], Training Accuracy: 74.3056%, Training Loss: 0.3994%\n",
      "Epoch [202/300], Step [19/23], Training Accuracy: 74.5066%, Training Loss: 0.3976%\n",
      "Epoch [202/300], Step [20/23], Training Accuracy: 74.8438%, Training Loss: 0.3953%\n",
      "Epoch [202/300], Step [21/23], Training Accuracy: 74.7024%, Training Loss: 0.3948%\n",
      "Epoch [202/300], Step [22/23], Training Accuracy: 75.0000%, Training Loss: 0.3939%\n",
      "Epoch [202/300], Step [23/23], Training Accuracy: 75.1911%, Training Loss: 0.3905%\n",
      "Epoch [203/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3848%\n",
      "Epoch [203/300], Step [2/23], Training Accuracy: 75.7812%, Training Loss: 0.3977%\n",
      "Epoch [203/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.3979%\n",
      "Epoch [203/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.3879%\n",
      "Epoch [203/300], Step [5/23], Training Accuracy: 73.4375%, Training Loss: 0.3893%\n",
      "Epoch [203/300], Step [6/23], Training Accuracy: 74.2188%, Training Loss: 0.3900%\n",
      "Epoch [203/300], Step [7/23], Training Accuracy: 74.7768%, Training Loss: 0.3938%\n",
      "Epoch [203/300], Step [8/23], Training Accuracy: 75.3906%, Training Loss: 0.3965%\n",
      "Epoch [203/300], Step [9/23], Training Accuracy: 74.3056%, Training Loss: 0.4021%\n",
      "Epoch [203/300], Step [10/23], Training Accuracy: 74.8438%, Training Loss: 0.3986%\n",
      "Epoch [203/300], Step [11/23], Training Accuracy: 74.8580%, Training Loss: 0.3969%\n",
      "Epoch [203/300], Step [12/23], Training Accuracy: 74.4792%, Training Loss: 0.3976%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [203/300], Step [13/23], Training Accuracy: 74.3990%, Training Loss: 0.4008%\n",
      "Epoch [203/300], Step [14/23], Training Accuracy: 74.6652%, Training Loss: 0.3996%\n",
      "Epoch [203/300], Step [15/23], Training Accuracy: 74.0625%, Training Loss: 0.4015%\n",
      "Epoch [203/300], Step [16/23], Training Accuracy: 73.8281%, Training Loss: 0.4006%\n",
      "Epoch [203/300], Step [17/23], Training Accuracy: 74.0809%, Training Loss: 0.4003%\n",
      "Epoch [203/300], Step [18/23], Training Accuracy: 74.1319%, Training Loss: 0.4011%\n",
      "Epoch [203/300], Step [19/23], Training Accuracy: 74.2599%, Training Loss: 0.3997%\n",
      "Epoch [203/300], Step [20/23], Training Accuracy: 74.3750%, Training Loss: 0.3978%\n",
      "Epoch [203/300], Step [21/23], Training Accuracy: 74.1815%, Training Loss: 0.3982%\n",
      "Epoch [203/300], Step [22/23], Training Accuracy: 74.2188%, Training Loss: 0.3976%\n",
      "Epoch [203/300], Step [23/23], Training Accuracy: 74.4962%, Training Loss: 0.3942%\n",
      "Epoch [204/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3841%\n",
      "Epoch [204/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.4055%\n",
      "Epoch [204/300], Step [3/23], Training Accuracy: 74.4792%, Training Loss: 0.4060%\n",
      "Epoch [204/300], Step [4/23], Training Accuracy: 76.1719%, Training Loss: 0.3931%\n",
      "Epoch [204/300], Step [5/23], Training Accuracy: 76.5625%, Training Loss: 0.3928%\n",
      "Epoch [204/300], Step [6/23], Training Accuracy: 76.8229%, Training Loss: 0.3927%\n",
      "Epoch [204/300], Step [7/23], Training Accuracy: 76.1161%, Training Loss: 0.3959%\n",
      "Epoch [204/300], Step [8/23], Training Accuracy: 76.1719%, Training Loss: 0.3976%\n",
      "Epoch [204/300], Step [9/23], Training Accuracy: 75.5208%, Training Loss: 0.4020%\n",
      "Epoch [204/300], Step [10/23], Training Accuracy: 75.7812%, Training Loss: 0.3998%\n",
      "Epoch [204/300], Step [11/23], Training Accuracy: 76.1364%, Training Loss: 0.3995%\n",
      "Epoch [204/300], Step [12/23], Training Accuracy: 75.9115%, Training Loss: 0.3974%\n",
      "Epoch [204/300], Step [13/23], Training Accuracy: 75.8413%, Training Loss: 0.3993%\n",
      "Epoch [204/300], Step [14/23], Training Accuracy: 76.2277%, Training Loss: 0.3946%\n",
      "Epoch [204/300], Step [15/23], Training Accuracy: 75.7292%, Training Loss: 0.3981%\n",
      "Epoch [204/300], Step [16/23], Training Accuracy: 75.4883%, Training Loss: 0.3977%\n",
      "Epoch [204/300], Step [17/23], Training Accuracy: 75.7353%, Training Loss: 0.3973%\n",
      "Epoch [204/300], Step [18/23], Training Accuracy: 75.6944%, Training Loss: 0.3967%\n",
      "Epoch [204/300], Step [19/23], Training Accuracy: 75.4934%, Training Loss: 0.3955%\n",
      "Epoch [204/300], Step [20/23], Training Accuracy: 75.3906%, Training Loss: 0.3941%\n",
      "Epoch [204/300], Step [21/23], Training Accuracy: 75.4464%, Training Loss: 0.3946%\n",
      "Epoch [204/300], Step [22/23], Training Accuracy: 75.4972%, Training Loss: 0.3942%\n",
      "Epoch [204/300], Step [23/23], Training Accuracy: 75.6776%, Training Loss: 0.3904%\n",
      "Epoch [205/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3729%\n",
      "Epoch [205/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.4052%\n",
      "Epoch [205/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.4160%\n",
      "Epoch [205/300], Step [4/23], Training Accuracy: 76.1719%, Training Loss: 0.3940%\n",
      "Epoch [205/300], Step [5/23], Training Accuracy: 76.2500%, Training Loss: 0.3912%\n",
      "Epoch [205/300], Step [6/23], Training Accuracy: 77.3438%, Training Loss: 0.3857%\n",
      "Epoch [205/300], Step [7/23], Training Accuracy: 76.7857%, Training Loss: 0.3889%\n",
      "Epoch [205/300], Step [8/23], Training Accuracy: 77.1484%, Training Loss: 0.3886%\n",
      "Epoch [205/300], Step [9/23], Training Accuracy: 76.0417%, Training Loss: 0.3935%\n",
      "Epoch [205/300], Step [10/23], Training Accuracy: 75.7812%, Training Loss: 0.3928%\n",
      "Epoch [205/300], Step [11/23], Training Accuracy: 75.5682%, Training Loss: 0.3941%\n",
      "Epoch [205/300], Step [12/23], Training Accuracy: 75.1302%, Training Loss: 0.3973%\n",
      "Epoch [205/300], Step [13/23], Training Accuracy: 74.7596%, Training Loss: 0.3991%\n",
      "Epoch [205/300], Step [14/23], Training Accuracy: 74.4420%, Training Loss: 0.3982%\n",
      "Epoch [205/300], Step [15/23], Training Accuracy: 74.1667%, Training Loss: 0.4006%\n",
      "Epoch [205/300], Step [16/23], Training Accuracy: 74.0234%, Training Loss: 0.4014%\n",
      "Epoch [205/300], Step [17/23], Training Accuracy: 74.3566%, Training Loss: 0.3998%\n",
      "Epoch [205/300], Step [18/23], Training Accuracy: 74.5660%, Training Loss: 0.3997%\n",
      "Epoch [205/300], Step [19/23], Training Accuracy: 74.6711%, Training Loss: 0.3992%\n",
      "Epoch [205/300], Step [20/23], Training Accuracy: 74.8438%, Training Loss: 0.3973%\n",
      "Epoch [205/300], Step [21/23], Training Accuracy: 75.0000%, Training Loss: 0.3982%\n",
      "Epoch [205/300], Step [22/23], Training Accuracy: 75.2841%, Training Loss: 0.3976%\n",
      "Epoch [205/300], Step [23/23], Training Accuracy: 75.3996%, Training Loss: 0.3940%\n",
      "Epoch [206/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3534%\n",
      "Epoch [206/300], Step [2/23], Training Accuracy: 75.7812%, Training Loss: 0.3933%\n",
      "Epoch [206/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.4060%\n",
      "Epoch [206/300], Step [4/23], Training Accuracy: 75.0000%, Training Loss: 0.3906%\n",
      "Epoch [206/300], Step [5/23], Training Accuracy: 74.0625%, Training Loss: 0.3899%\n",
      "Epoch [206/300], Step [6/23], Training Accuracy: 74.7396%, Training Loss: 0.3912%\n",
      "Epoch [206/300], Step [7/23], Training Accuracy: 74.5536%, Training Loss: 0.3935%\n",
      "Epoch [206/300], Step [8/23], Training Accuracy: 75.5859%, Training Loss: 0.3922%\n",
      "Epoch [206/300], Step [9/23], Training Accuracy: 73.9583%, Training Loss: 0.3986%\n",
      "Epoch [206/300], Step [10/23], Training Accuracy: 73.5938%, Training Loss: 0.3970%\n",
      "Epoch [206/300], Step [11/23], Training Accuracy: 73.7216%, Training Loss: 0.3965%\n",
      "Epoch [206/300], Step [12/23], Training Accuracy: 73.5677%, Training Loss: 0.3977%\n",
      "Epoch [206/300], Step [13/23], Training Accuracy: 73.0769%, Training Loss: 0.3993%\n",
      "Epoch [206/300], Step [14/23], Training Accuracy: 73.2143%, Training Loss: 0.3960%\n",
      "Epoch [206/300], Step [15/23], Training Accuracy: 72.9167%, Training Loss: 0.3990%\n",
      "Epoch [206/300], Step [16/23], Training Accuracy: 72.9492%, Training Loss: 0.3988%\n",
      "Epoch [206/300], Step [17/23], Training Accuracy: 73.1618%, Training Loss: 0.3988%\n",
      "Epoch [206/300], Step [18/23], Training Accuracy: 73.1771%, Training Loss: 0.3990%\n",
      "Epoch [206/300], Step [19/23], Training Accuracy: 73.3553%, Training Loss: 0.3978%\n",
      "Epoch [206/300], Step [20/23], Training Accuracy: 73.5938%, Training Loss: 0.3965%\n",
      "Epoch [206/300], Step [21/23], Training Accuracy: 73.6607%, Training Loss: 0.3968%\n",
      "Epoch [206/300], Step [22/23], Training Accuracy: 74.0767%, Training Loss: 0.3953%\n",
      "Epoch [206/300], Step [23/23], Training Accuracy: 74.2182%, Training Loss: 0.3921%\n",
      "Epoch [207/300], Step [1/23], Training Accuracy: 81.2500%, Training Loss: 0.3823%\n",
      "Epoch [207/300], Step [2/23], Training Accuracy: 78.9062%, Training Loss: 0.3964%\n",
      "Epoch [207/300], Step [3/23], Training Accuracy: 74.4792%, Training Loss: 0.4072%\n",
      "Epoch [207/300], Step [4/23], Training Accuracy: 76.1719%, Training Loss: 0.3841%\n",
      "Epoch [207/300], Step [5/23], Training Accuracy: 75.9375%, Training Loss: 0.3821%\n",
      "Epoch [207/300], Step [6/23], Training Accuracy: 76.5625%, Training Loss: 0.3858%\n",
      "Epoch [207/300], Step [7/23], Training Accuracy: 76.1161%, Training Loss: 0.3903%\n",
      "Epoch [207/300], Step [8/23], Training Accuracy: 76.5625%, Training Loss: 0.3901%\n",
      "Epoch [207/300], Step [9/23], Training Accuracy: 75.3472%, Training Loss: 0.3967%\n",
      "Epoch [207/300], Step [10/23], Training Accuracy: 75.3125%, Training Loss: 0.3967%\n",
      "Epoch [207/300], Step [11/23], Training Accuracy: 75.4261%, Training Loss: 0.3965%\n",
      "Epoch [207/300], Step [12/23], Training Accuracy: 75.3906%, Training Loss: 0.3960%\n",
      "Epoch [207/300], Step [13/23], Training Accuracy: 74.8798%, Training Loss: 0.3995%\n",
      "Epoch [207/300], Step [14/23], Training Accuracy: 75.0000%, Training Loss: 0.3983%\n",
      "Epoch [207/300], Step [15/23], Training Accuracy: 74.3750%, Training Loss: 0.3991%\n",
      "Epoch [207/300], Step [16/23], Training Accuracy: 74.0234%, Training Loss: 0.4003%\n",
      "Epoch [207/300], Step [17/23], Training Accuracy: 73.8971%, Training Loss: 0.3995%\n",
      "Epoch [207/300], Step [18/23], Training Accuracy: 74.1319%, Training Loss: 0.3997%\n",
      "Epoch [207/300], Step [19/23], Training Accuracy: 73.9309%, Training Loss: 0.3989%\n",
      "Epoch [207/300], Step [20/23], Training Accuracy: 74.2188%, Training Loss: 0.3973%\n",
      "Epoch [207/300], Step [21/23], Training Accuracy: 74.1815%, Training Loss: 0.3970%\n",
      "Epoch [207/300], Step [22/23], Training Accuracy: 74.1477%, Training Loss: 0.3965%\n",
      "Epoch [207/300], Step [23/23], Training Accuracy: 74.3572%, Training Loss: 0.3933%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [208/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3660%\n",
      "Epoch [208/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.3941%\n",
      "Epoch [208/300], Step [3/23], Training Accuracy: 70.8333%, Training Loss: 0.4021%\n",
      "Epoch [208/300], Step [4/23], Training Accuracy: 73.4375%, Training Loss: 0.3890%\n",
      "Epoch [208/300], Step [5/23], Training Accuracy: 71.8750%, Training Loss: 0.3870%\n",
      "Epoch [208/300], Step [6/23], Training Accuracy: 72.1354%, Training Loss: 0.3842%\n",
      "Epoch [208/300], Step [7/23], Training Accuracy: 72.0982%, Training Loss: 0.3891%\n",
      "Epoch [208/300], Step [8/23], Training Accuracy: 73.0469%, Training Loss: 0.3889%\n",
      "Epoch [208/300], Step [9/23], Training Accuracy: 72.0486%, Training Loss: 0.3942%\n",
      "Epoch [208/300], Step [10/23], Training Accuracy: 72.3438%, Training Loss: 0.3948%\n",
      "Epoch [208/300], Step [11/23], Training Accuracy: 72.1591%, Training Loss: 0.3949%\n",
      "Epoch [208/300], Step [12/23], Training Accuracy: 71.8750%, Training Loss: 0.3946%\n",
      "Epoch [208/300], Step [13/23], Training Accuracy: 71.0337%, Training Loss: 0.3980%\n",
      "Epoch [208/300], Step [14/23], Training Accuracy: 71.4286%, Training Loss: 0.3959%\n",
      "Epoch [208/300], Step [15/23], Training Accuracy: 71.4583%, Training Loss: 0.3985%\n",
      "Epoch [208/300], Step [16/23], Training Accuracy: 71.3867%, Training Loss: 0.4000%\n",
      "Epoch [208/300], Step [17/23], Training Accuracy: 71.4154%, Training Loss: 0.3992%\n",
      "Epoch [208/300], Step [18/23], Training Accuracy: 71.4410%, Training Loss: 0.3987%\n",
      "Epoch [208/300], Step [19/23], Training Accuracy: 71.6283%, Training Loss: 0.3978%\n",
      "Epoch [208/300], Step [20/23], Training Accuracy: 72.1875%, Training Loss: 0.3957%\n",
      "Epoch [208/300], Step [21/23], Training Accuracy: 72.2470%, Training Loss: 0.3954%\n",
      "Epoch [208/300], Step [22/23], Training Accuracy: 72.4432%, Training Loss: 0.3960%\n",
      "Epoch [208/300], Step [23/23], Training Accuracy: 72.4114%, Training Loss: 0.3932%\n",
      "Epoch [209/300], Step [1/23], Training Accuracy: 71.8750%, Training Loss: 0.3776%\n",
      "Epoch [209/300], Step [2/23], Training Accuracy: 71.8750%, Training Loss: 0.4011%\n",
      "Epoch [209/300], Step [3/23], Training Accuracy: 69.7917%, Training Loss: 0.4140%\n",
      "Epoch [209/300], Step [4/23], Training Accuracy: 73.4375%, Training Loss: 0.4005%\n",
      "Epoch [209/300], Step [5/23], Training Accuracy: 72.1875%, Training Loss: 0.4017%\n",
      "Epoch [209/300], Step [6/23], Training Accuracy: 73.6979%, Training Loss: 0.4010%\n",
      "Epoch [209/300], Step [7/23], Training Accuracy: 73.4375%, Training Loss: 0.4034%\n",
      "Epoch [209/300], Step [8/23], Training Accuracy: 73.8281%, Training Loss: 0.4003%\n",
      "Epoch [209/300], Step [9/23], Training Accuracy: 73.0903%, Training Loss: 0.4045%\n",
      "Epoch [209/300], Step [10/23], Training Accuracy: 73.5938%, Training Loss: 0.4006%\n",
      "Epoch [209/300], Step [11/23], Training Accuracy: 74.1477%, Training Loss: 0.3980%\n",
      "Epoch [209/300], Step [12/23], Training Accuracy: 74.6094%, Training Loss: 0.3973%\n",
      "Epoch [209/300], Step [13/23], Training Accuracy: 74.6394%, Training Loss: 0.3993%\n",
      "Epoch [209/300], Step [14/23], Training Accuracy: 75.0000%, Training Loss: 0.3972%\n",
      "Epoch [209/300], Step [15/23], Training Accuracy: 74.5833%, Training Loss: 0.3998%\n",
      "Epoch [209/300], Step [16/23], Training Accuracy: 74.5117%, Training Loss: 0.4000%\n",
      "Epoch [209/300], Step [17/23], Training Accuracy: 74.4485%, Training Loss: 0.4000%\n",
      "Epoch [209/300], Step [18/23], Training Accuracy: 74.5660%, Training Loss: 0.4000%\n",
      "Epoch [209/300], Step [19/23], Training Accuracy: 74.6711%, Training Loss: 0.3990%\n",
      "Epoch [209/300], Step [20/23], Training Accuracy: 74.6875%, Training Loss: 0.3976%\n",
      "Epoch [209/300], Step [21/23], Training Accuracy: 74.5536%, Training Loss: 0.3975%\n",
      "Epoch [209/300], Step [22/23], Training Accuracy: 74.5739%, Training Loss: 0.3956%\n",
      "Epoch [209/300], Step [23/23], Training Accuracy: 74.5657%, Training Loss: 0.3933%\n",
      "Epoch [210/300], Step [1/23], Training Accuracy: 73.4375%, Training Loss: 0.3789%\n",
      "Epoch [210/300], Step [2/23], Training Accuracy: 72.6562%, Training Loss: 0.4003%\n",
      "Epoch [210/300], Step [3/23], Training Accuracy: 71.3542%, Training Loss: 0.4061%\n",
      "Epoch [210/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.3881%\n",
      "Epoch [210/300], Step [5/23], Training Accuracy: 73.4375%, Training Loss: 0.3901%\n",
      "Epoch [210/300], Step [6/23], Training Accuracy: 74.2188%, Training Loss: 0.3893%\n",
      "Epoch [210/300], Step [7/23], Training Accuracy: 74.1071%, Training Loss: 0.3976%\n",
      "Epoch [210/300], Step [8/23], Training Accuracy: 74.8047%, Training Loss: 0.3930%\n",
      "Epoch [210/300], Step [9/23], Training Accuracy: 74.4792%, Training Loss: 0.3976%\n",
      "Epoch [210/300], Step [10/23], Training Accuracy: 74.6875%, Training Loss: 0.3965%\n",
      "Epoch [210/300], Step [11/23], Training Accuracy: 74.5739%, Training Loss: 0.3947%\n",
      "Epoch [210/300], Step [12/23], Training Accuracy: 74.4792%, Training Loss: 0.3976%\n",
      "Epoch [210/300], Step [13/23], Training Accuracy: 74.1587%, Training Loss: 0.3996%\n",
      "Epoch [210/300], Step [14/23], Training Accuracy: 73.8839%, Training Loss: 0.3998%\n",
      "Epoch [210/300], Step [15/23], Training Accuracy: 73.2292%, Training Loss: 0.4032%\n",
      "Epoch [210/300], Step [16/23], Training Accuracy: 72.9492%, Training Loss: 0.4032%\n",
      "Epoch [210/300], Step [17/23], Training Accuracy: 73.3456%, Training Loss: 0.4020%\n",
      "Epoch [210/300], Step [18/23], Training Accuracy: 73.4375%, Training Loss: 0.4019%\n",
      "Epoch [210/300], Step [19/23], Training Accuracy: 73.4375%, Training Loss: 0.4030%\n",
      "Epoch [210/300], Step [20/23], Training Accuracy: 73.6719%, Training Loss: 0.4017%\n",
      "Epoch [210/300], Step [21/23], Training Accuracy: 73.4375%, Training Loss: 0.4006%\n",
      "Epoch [210/300], Step [22/23], Training Accuracy: 73.5085%, Training Loss: 0.3991%\n",
      "Epoch [210/300], Step [23/23], Training Accuracy: 73.6623%, Training Loss: 0.3960%\n",
      "Epoch [211/300], Step [1/23], Training Accuracy: 73.4375%, Training Loss: 0.3668%\n",
      "Epoch [211/300], Step [2/23], Training Accuracy: 75.7812%, Training Loss: 0.3794%\n",
      "Epoch [211/300], Step [3/23], Training Accuracy: 72.9167%, Training Loss: 0.3902%\n",
      "Epoch [211/300], Step [4/23], Training Accuracy: 75.3906%, Training Loss: 0.3817%\n",
      "Epoch [211/300], Step [5/23], Training Accuracy: 75.3125%, Training Loss: 0.3831%\n",
      "Epoch [211/300], Step [6/23], Training Accuracy: 76.0417%, Training Loss: 0.3808%\n",
      "Epoch [211/300], Step [7/23], Training Accuracy: 75.4464%, Training Loss: 0.3879%\n",
      "Epoch [211/300], Step [8/23], Training Accuracy: 76.3672%, Training Loss: 0.3900%\n",
      "Epoch [211/300], Step [9/23], Training Accuracy: 76.2153%, Training Loss: 0.3957%\n",
      "Epoch [211/300], Step [10/23], Training Accuracy: 75.4688%, Training Loss: 0.3952%\n",
      "Epoch [211/300], Step [11/23], Training Accuracy: 75.8523%, Training Loss: 0.3931%\n",
      "Epoch [211/300], Step [12/23], Training Accuracy: 76.0417%, Training Loss: 0.3936%\n",
      "Epoch [211/300], Step [13/23], Training Accuracy: 75.9615%, Training Loss: 0.3972%\n",
      "Epoch [211/300], Step [14/23], Training Accuracy: 76.2277%, Training Loss: 0.3944%\n",
      "Epoch [211/300], Step [15/23], Training Accuracy: 75.8333%, Training Loss: 0.3959%\n",
      "Epoch [211/300], Step [16/23], Training Accuracy: 75.2930%, Training Loss: 0.3966%\n",
      "Epoch [211/300], Step [17/23], Training Accuracy: 75.0000%, Training Loss: 0.3970%\n",
      "Epoch [211/300], Step [18/23], Training Accuracy: 75.1736%, Training Loss: 0.3965%\n",
      "Epoch [211/300], Step [19/23], Training Accuracy: 75.1645%, Training Loss: 0.3972%\n",
      "Epoch [211/300], Step [20/23], Training Accuracy: 75.2344%, Training Loss: 0.3959%\n",
      "Epoch [211/300], Step [21/23], Training Accuracy: 74.8512%, Training Loss: 0.3968%\n",
      "Epoch [211/300], Step [22/23], Training Accuracy: 74.7869%, Training Loss: 0.3968%\n",
      "Epoch [211/300], Step [23/23], Training Accuracy: 74.9131%, Training Loss: 0.3937%\n",
      "Epoch [212/300], Step [1/23], Training Accuracy: 73.4375%, Training Loss: 0.3918%\n",
      "Epoch [212/300], Step [2/23], Training Accuracy: 72.6562%, Training Loss: 0.4097%\n",
      "Epoch [212/300], Step [3/23], Training Accuracy: 70.8333%, Training Loss: 0.4250%\n",
      "Epoch [212/300], Step [4/23], Training Accuracy: 73.4375%, Training Loss: 0.4060%\n",
      "Epoch [212/300], Step [5/23], Training Accuracy: 72.8125%, Training Loss: 0.4011%\n",
      "Epoch [212/300], Step [6/23], Training Accuracy: 73.9583%, Training Loss: 0.3970%\n",
      "Epoch [212/300], Step [7/23], Training Accuracy: 73.8839%, Training Loss: 0.4005%\n",
      "Epoch [212/300], Step [8/23], Training Accuracy: 74.4141%, Training Loss: 0.3988%\n",
      "Epoch [212/300], Step [9/23], Training Accuracy: 74.1319%, Training Loss: 0.4036%\n",
      "Epoch [212/300], Step [10/23], Training Accuracy: 75.1562%, Training Loss: 0.4007%\n",
      "Epoch [212/300], Step [11/23], Training Accuracy: 75.1420%, Training Loss: 0.4010%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [212/300], Step [12/23], Training Accuracy: 75.1302%, Training Loss: 0.4009%\n",
      "Epoch [212/300], Step [13/23], Training Accuracy: 75.1202%, Training Loss: 0.4005%\n",
      "Epoch [212/300], Step [14/23], Training Accuracy: 75.4464%, Training Loss: 0.3995%\n",
      "Epoch [212/300], Step [15/23], Training Accuracy: 75.1042%, Training Loss: 0.4029%\n",
      "Epoch [212/300], Step [16/23], Training Accuracy: 75.0000%, Training Loss: 0.4025%\n",
      "Epoch [212/300], Step [17/23], Training Accuracy: 75.0000%, Training Loss: 0.4033%\n",
      "Epoch [212/300], Step [18/23], Training Accuracy: 75.2604%, Training Loss: 0.4029%\n",
      "Epoch [212/300], Step [19/23], Training Accuracy: 75.0000%, Training Loss: 0.4020%\n",
      "Epoch [212/300], Step [20/23], Training Accuracy: 75.2344%, Training Loss: 0.3997%\n",
      "Epoch [212/300], Step [21/23], Training Accuracy: 75.0744%, Training Loss: 0.3989%\n",
      "Epoch [212/300], Step [22/23], Training Accuracy: 74.9290%, Training Loss: 0.3981%\n",
      "Epoch [212/300], Step [23/23], Training Accuracy: 75.0521%, Training Loss: 0.3941%\n",
      "Epoch [213/300], Step [1/23], Training Accuracy: 81.2500%, Training Loss: 0.3796%\n",
      "Epoch [213/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.4022%\n",
      "Epoch [213/300], Step [3/23], Training Accuracy: 72.9167%, Training Loss: 0.4065%\n",
      "Epoch [213/300], Step [4/23], Training Accuracy: 75.0000%, Training Loss: 0.3974%\n",
      "Epoch [213/300], Step [5/23], Training Accuracy: 73.4375%, Training Loss: 0.3981%\n",
      "Epoch [213/300], Step [6/23], Training Accuracy: 73.9583%, Training Loss: 0.3943%\n",
      "Epoch [213/300], Step [7/23], Training Accuracy: 74.7768%, Training Loss: 0.3953%\n",
      "Epoch [213/300], Step [8/23], Training Accuracy: 75.7812%, Training Loss: 0.3941%\n",
      "Epoch [213/300], Step [9/23], Training Accuracy: 75.1736%, Training Loss: 0.3997%\n",
      "Epoch [213/300], Step [10/23], Training Accuracy: 74.8438%, Training Loss: 0.3989%\n",
      "Epoch [213/300], Step [11/23], Training Accuracy: 75.0000%, Training Loss: 0.3949%\n",
      "Epoch [213/300], Step [12/23], Training Accuracy: 75.0000%, Training Loss: 0.3950%\n",
      "Epoch [213/300], Step [13/23], Training Accuracy: 75.0000%, Training Loss: 0.3969%\n",
      "Epoch [213/300], Step [14/23], Training Accuracy: 75.4464%, Training Loss: 0.3934%\n",
      "Epoch [213/300], Step [15/23], Training Accuracy: 75.1042%, Training Loss: 0.3956%\n",
      "Epoch [213/300], Step [16/23], Training Accuracy: 74.9023%, Training Loss: 0.3960%\n",
      "Epoch [213/300], Step [17/23], Training Accuracy: 74.8162%, Training Loss: 0.3952%\n",
      "Epoch [213/300], Step [18/23], Training Accuracy: 74.3056%, Training Loss: 0.3966%\n",
      "Epoch [213/300], Step [19/23], Training Accuracy: 74.5066%, Training Loss: 0.3955%\n",
      "Epoch [213/300], Step [20/23], Training Accuracy: 74.9219%, Training Loss: 0.3931%\n",
      "Epoch [213/300], Step [21/23], Training Accuracy: 74.5536%, Training Loss: 0.3934%\n",
      "Epoch [213/300], Step [22/23], Training Accuracy: 74.7159%, Training Loss: 0.3923%\n",
      "Epoch [213/300], Step [23/23], Training Accuracy: 74.7047%, Training Loss: 0.3899%\n",
      "Epoch [214/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3699%\n",
      "Epoch [214/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.3969%\n",
      "Epoch [214/300], Step [3/23], Training Accuracy: 69.7917%, Training Loss: 0.4048%\n",
      "Epoch [214/300], Step [4/23], Training Accuracy: 74.2188%, Training Loss: 0.3828%\n",
      "Epoch [214/300], Step [5/23], Training Accuracy: 73.7500%, Training Loss: 0.3844%\n",
      "Epoch [214/300], Step [6/23], Training Accuracy: 74.7396%, Training Loss: 0.3809%\n",
      "Epoch [214/300], Step [7/23], Training Accuracy: 74.7768%, Training Loss: 0.3864%\n",
      "Epoch [214/300], Step [8/23], Training Accuracy: 75.1953%, Training Loss: 0.3844%\n",
      "Epoch [214/300], Step [9/23], Training Accuracy: 74.4792%, Training Loss: 0.3888%\n",
      "Epoch [214/300], Step [10/23], Training Accuracy: 74.5312%, Training Loss: 0.3881%\n",
      "Epoch [214/300], Step [11/23], Training Accuracy: 74.4318%, Training Loss: 0.3875%\n",
      "Epoch [214/300], Step [12/23], Training Accuracy: 74.3490%, Training Loss: 0.3911%\n",
      "Epoch [214/300], Step [13/23], Training Accuracy: 74.0385%, Training Loss: 0.3930%\n",
      "Epoch [214/300], Step [14/23], Training Accuracy: 74.5536%, Training Loss: 0.3908%\n",
      "Epoch [214/300], Step [15/23], Training Accuracy: 73.8542%, Training Loss: 0.3939%\n",
      "Epoch [214/300], Step [16/23], Training Accuracy: 73.5352%, Training Loss: 0.3955%\n",
      "Epoch [214/300], Step [17/23], Training Accuracy: 73.8971%, Training Loss: 0.3938%\n",
      "Epoch [214/300], Step [18/23], Training Accuracy: 73.7847%, Training Loss: 0.3943%\n",
      "Epoch [214/300], Step [19/23], Training Accuracy: 74.1776%, Training Loss: 0.3932%\n",
      "Epoch [214/300], Step [20/23], Training Accuracy: 74.4531%, Training Loss: 0.3925%\n",
      "Epoch [214/300], Step [21/23], Training Accuracy: 74.4792%, Training Loss: 0.3924%\n",
      "Epoch [214/300], Step [22/23], Training Accuracy: 74.6449%, Training Loss: 0.3918%\n",
      "Epoch [214/300], Step [23/23], Training Accuracy: 74.8436%, Training Loss: 0.3884%\n",
      "Epoch [215/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3516%\n",
      "Epoch [215/300], Step [2/23], Training Accuracy: 75.7812%, Training Loss: 0.4039%\n",
      "Epoch [215/300], Step [3/23], Training Accuracy: 73.4375%, Training Loss: 0.4060%\n",
      "Epoch [215/300], Step [4/23], Training Accuracy: 75.7812%, Training Loss: 0.3876%\n",
      "Epoch [215/300], Step [5/23], Training Accuracy: 75.6250%, Training Loss: 0.3862%\n",
      "Epoch [215/300], Step [6/23], Training Accuracy: 76.8229%, Training Loss: 0.3836%\n",
      "Epoch [215/300], Step [7/23], Training Accuracy: 76.7857%, Training Loss: 0.3890%\n",
      "Epoch [215/300], Step [8/23], Training Accuracy: 75.9766%, Training Loss: 0.3892%\n",
      "Epoch [215/300], Step [9/23], Training Accuracy: 74.8264%, Training Loss: 0.3943%\n",
      "Epoch [215/300], Step [10/23], Training Accuracy: 74.3750%, Training Loss: 0.3930%\n",
      "Epoch [215/300], Step [11/23], Training Accuracy: 74.4318%, Training Loss: 0.3917%\n",
      "Epoch [215/300], Step [12/23], Training Accuracy: 74.6094%, Training Loss: 0.3932%\n",
      "Epoch [215/300], Step [13/23], Training Accuracy: 74.1587%, Training Loss: 0.3950%\n",
      "Epoch [215/300], Step [14/23], Training Accuracy: 74.6652%, Training Loss: 0.3936%\n",
      "Epoch [215/300], Step [15/23], Training Accuracy: 74.5833%, Training Loss: 0.3941%\n",
      "Epoch [215/300], Step [16/23], Training Accuracy: 74.1211%, Training Loss: 0.3948%\n",
      "Epoch [215/300], Step [17/23], Training Accuracy: 74.3566%, Training Loss: 0.3951%\n",
      "Epoch [215/300], Step [18/23], Training Accuracy: 74.0451%, Training Loss: 0.3959%\n",
      "Epoch [215/300], Step [19/23], Training Accuracy: 74.1776%, Training Loss: 0.3963%\n",
      "Epoch [215/300], Step [20/23], Training Accuracy: 74.3750%, Training Loss: 0.3948%\n",
      "Epoch [215/300], Step [21/23], Training Accuracy: 74.7024%, Training Loss: 0.3940%\n",
      "Epoch [215/300], Step [22/23], Training Accuracy: 74.8580%, Training Loss: 0.3926%\n",
      "Epoch [215/300], Step [23/23], Training Accuracy: 74.9826%, Training Loss: 0.3887%\n",
      "Epoch [216/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3935%\n",
      "Epoch [216/300], Step [2/23], Training Accuracy: 70.3125%, Training Loss: 0.4109%\n",
      "Epoch [216/300], Step [3/23], Training Accuracy: 70.3125%, Training Loss: 0.4121%\n",
      "Epoch [216/300], Step [4/23], Training Accuracy: 72.6562%, Training Loss: 0.3951%\n",
      "Epoch [216/300], Step [5/23], Training Accuracy: 71.5625%, Training Loss: 0.3925%\n",
      "Epoch [216/300], Step [6/23], Training Accuracy: 72.9167%, Training Loss: 0.3908%\n",
      "Epoch [216/300], Step [7/23], Training Accuracy: 72.5446%, Training Loss: 0.3964%\n",
      "Epoch [216/300], Step [8/23], Training Accuracy: 73.4375%, Training Loss: 0.3969%\n",
      "Epoch [216/300], Step [9/23], Training Accuracy: 72.9167%, Training Loss: 0.4001%\n",
      "Epoch [216/300], Step [10/23], Training Accuracy: 73.1250%, Training Loss: 0.3989%\n",
      "Epoch [216/300], Step [11/23], Training Accuracy: 73.1534%, Training Loss: 0.3979%\n",
      "Epoch [216/300], Step [12/23], Training Accuracy: 73.1771%, Training Loss: 0.4005%\n",
      "Epoch [216/300], Step [13/23], Training Accuracy: 73.0769%, Training Loss: 0.4015%\n",
      "Epoch [216/300], Step [14/23], Training Accuracy: 72.9911%, Training Loss: 0.4012%\n",
      "Epoch [216/300], Step [15/23], Training Accuracy: 72.2917%, Training Loss: 0.4039%\n",
      "Epoch [216/300], Step [16/23], Training Accuracy: 72.1680%, Training Loss: 0.4045%\n",
      "Epoch [216/300], Step [17/23], Training Accuracy: 71.8750%, Training Loss: 0.4054%\n",
      "Epoch [216/300], Step [18/23], Training Accuracy: 71.8750%, Training Loss: 0.4049%\n",
      "Epoch [216/300], Step [19/23], Training Accuracy: 72.2862%, Training Loss: 0.4035%\n",
      "Epoch [216/300], Step [20/23], Training Accuracy: 72.5000%, Training Loss: 0.4010%\n",
      "Epoch [216/300], Step [21/23], Training Accuracy: 72.5446%, Training Loss: 0.4014%\n",
      "Epoch [216/300], Step [22/23], Training Accuracy: 72.7273%, Training Loss: 0.4007%\n",
      "Epoch [216/300], Step [23/23], Training Accuracy: 72.8284%, Training Loss: 0.3972%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [217/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3817%\n",
      "Epoch [217/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.4051%\n",
      "Epoch [217/300], Step [3/23], Training Accuracy: 72.9167%, Training Loss: 0.4052%\n",
      "Epoch [217/300], Step [4/23], Training Accuracy: 76.5625%, Training Loss: 0.3861%\n",
      "Epoch [217/300], Step [5/23], Training Accuracy: 75.0000%, Training Loss: 0.3824%\n",
      "Epoch [217/300], Step [6/23], Training Accuracy: 75.2604%, Training Loss: 0.3833%\n",
      "Epoch [217/300], Step [7/23], Training Accuracy: 75.2232%, Training Loss: 0.3887%\n",
      "Epoch [217/300], Step [8/23], Training Accuracy: 75.7812%, Training Loss: 0.3878%\n",
      "Epoch [217/300], Step [9/23], Training Accuracy: 75.3472%, Training Loss: 0.3923%\n",
      "Epoch [217/300], Step [10/23], Training Accuracy: 75.6250%, Training Loss: 0.3905%\n",
      "Epoch [217/300], Step [11/23], Training Accuracy: 76.4205%, Training Loss: 0.3876%\n",
      "Epoch [217/300], Step [12/23], Training Accuracy: 76.5625%, Training Loss: 0.3873%\n",
      "Epoch [217/300], Step [13/23], Training Accuracy: 76.4423%, Training Loss: 0.3883%\n",
      "Epoch [217/300], Step [14/23], Training Accuracy: 77.0089%, Training Loss: 0.3854%\n",
      "Epoch [217/300], Step [15/23], Training Accuracy: 76.1458%, Training Loss: 0.3901%\n",
      "Epoch [217/300], Step [16/23], Training Accuracy: 75.5859%, Training Loss: 0.3917%\n",
      "Epoch [217/300], Step [17/23], Training Accuracy: 75.3676%, Training Loss: 0.3929%\n",
      "Epoch [217/300], Step [18/23], Training Accuracy: 75.4340%, Training Loss: 0.3944%\n",
      "Epoch [217/300], Step [19/23], Training Accuracy: 75.1645%, Training Loss: 0.3946%\n",
      "Epoch [217/300], Step [20/23], Training Accuracy: 75.3906%, Training Loss: 0.3932%\n",
      "Epoch [217/300], Step [21/23], Training Accuracy: 75.2976%, Training Loss: 0.3935%\n",
      "Epoch [217/300], Step [22/23], Training Accuracy: 75.5682%, Training Loss: 0.3925%\n",
      "Epoch [217/300], Step [23/23], Training Accuracy: 75.8165%, Training Loss: 0.3890%\n",
      "Epoch [218/300], Step [1/23], Training Accuracy: 73.4375%, Training Loss: 0.3817%\n",
      "Epoch [218/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3958%\n",
      "Epoch [218/300], Step [3/23], Training Accuracy: 72.3958%, Training Loss: 0.4085%\n",
      "Epoch [218/300], Step [4/23], Training Accuracy: 74.6094%, Training Loss: 0.3938%\n",
      "Epoch [218/300], Step [5/23], Training Accuracy: 74.0625%, Training Loss: 0.3918%\n",
      "Epoch [218/300], Step [6/23], Training Accuracy: 75.0000%, Training Loss: 0.3851%\n",
      "Epoch [218/300], Step [7/23], Training Accuracy: 75.2232%, Training Loss: 0.3912%\n",
      "Epoch [218/300], Step [8/23], Training Accuracy: 76.3672%, Training Loss: 0.3878%\n",
      "Epoch [218/300], Step [9/23], Training Accuracy: 75.8681%, Training Loss: 0.3906%\n",
      "Epoch [218/300], Step [10/23], Training Accuracy: 75.4688%, Training Loss: 0.3905%\n",
      "Epoch [218/300], Step [11/23], Training Accuracy: 75.4261%, Training Loss: 0.3895%\n",
      "Epoch [218/300], Step [12/23], Training Accuracy: 75.2604%, Training Loss: 0.3916%\n",
      "Epoch [218/300], Step [13/23], Training Accuracy: 74.2788%, Training Loss: 0.3936%\n",
      "Epoch [218/300], Step [14/23], Training Accuracy: 74.6652%, Training Loss: 0.3905%\n",
      "Epoch [218/300], Step [15/23], Training Accuracy: 74.4792%, Training Loss: 0.3932%\n",
      "Epoch [218/300], Step [16/23], Training Accuracy: 73.9258%, Training Loss: 0.3927%\n",
      "Epoch [218/300], Step [17/23], Training Accuracy: 73.7132%, Training Loss: 0.3923%\n",
      "Epoch [218/300], Step [18/23], Training Accuracy: 73.6979%, Training Loss: 0.3941%\n",
      "Epoch [218/300], Step [19/23], Training Accuracy: 73.9309%, Training Loss: 0.3936%\n",
      "Epoch [218/300], Step [20/23], Training Accuracy: 74.1406%, Training Loss: 0.3913%\n",
      "Epoch [218/300], Step [21/23], Training Accuracy: 73.9583%, Training Loss: 0.3917%\n",
      "Epoch [218/300], Step [22/23], Training Accuracy: 74.0767%, Training Loss: 0.3906%\n",
      "Epoch [218/300], Step [23/23], Training Accuracy: 74.2877%, Training Loss: 0.3875%\n",
      "Epoch [219/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3692%\n",
      "Epoch [219/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.4149%\n",
      "Epoch [219/300], Step [3/23], Training Accuracy: 73.9583%, Training Loss: 0.4087%\n",
      "Epoch [219/300], Step [4/23], Training Accuracy: 75.0000%, Training Loss: 0.3912%\n",
      "Epoch [219/300], Step [5/23], Training Accuracy: 74.6875%, Training Loss: 0.3892%\n",
      "Epoch [219/300], Step [6/23], Training Accuracy: 73.9583%, Training Loss: 0.3893%\n",
      "Epoch [219/300], Step [7/23], Training Accuracy: 73.8839%, Training Loss: 0.3971%\n",
      "Epoch [219/300], Step [8/23], Training Accuracy: 75.1953%, Training Loss: 0.3929%\n",
      "Epoch [219/300], Step [9/23], Training Accuracy: 74.1319%, Training Loss: 0.3966%\n",
      "Epoch [219/300], Step [10/23], Training Accuracy: 74.2188%, Training Loss: 0.3956%\n",
      "Epoch [219/300], Step [11/23], Training Accuracy: 74.2898%, Training Loss: 0.3950%\n",
      "Epoch [219/300], Step [12/23], Training Accuracy: 74.0885%, Training Loss: 0.3963%\n",
      "Epoch [219/300], Step [13/23], Training Accuracy: 73.6779%, Training Loss: 0.4004%\n",
      "Epoch [219/300], Step [14/23], Training Accuracy: 73.8839%, Training Loss: 0.3980%\n",
      "Epoch [219/300], Step [15/23], Training Accuracy: 73.4375%, Training Loss: 0.4019%\n",
      "Epoch [219/300], Step [16/23], Training Accuracy: 73.5352%, Training Loss: 0.4022%\n",
      "Epoch [219/300], Step [17/23], Training Accuracy: 73.8051%, Training Loss: 0.4019%\n",
      "Epoch [219/300], Step [18/23], Training Accuracy: 73.6111%, Training Loss: 0.4019%\n",
      "Epoch [219/300], Step [19/23], Training Accuracy: 73.7664%, Training Loss: 0.4016%\n",
      "Epoch [219/300], Step [20/23], Training Accuracy: 73.6719%, Training Loss: 0.4012%\n",
      "Epoch [219/300], Step [21/23], Training Accuracy: 73.5119%, Training Loss: 0.4017%\n",
      "Epoch [219/300], Step [22/23], Training Accuracy: 73.7926%, Training Loss: 0.4000%\n",
      "Epoch [219/300], Step [23/23], Training Accuracy: 73.7318%, Training Loss: 0.3969%\n",
      "Epoch [220/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3922%\n",
      "Epoch [220/300], Step [2/23], Training Accuracy: 70.3125%, Training Loss: 0.4138%\n",
      "Epoch [220/300], Step [3/23], Training Accuracy: 69.2708%, Training Loss: 0.4117%\n",
      "Epoch [220/300], Step [4/23], Training Accuracy: 71.0938%, Training Loss: 0.3975%\n",
      "Epoch [220/300], Step [5/23], Training Accuracy: 70.3125%, Training Loss: 0.4033%\n",
      "Epoch [220/300], Step [6/23], Training Accuracy: 71.6146%, Training Loss: 0.4024%\n",
      "Epoch [220/300], Step [7/23], Training Accuracy: 72.0982%, Training Loss: 0.4022%\n",
      "Epoch [220/300], Step [8/23], Training Accuracy: 72.0703%, Training Loss: 0.4008%\n",
      "Epoch [220/300], Step [9/23], Training Accuracy: 71.1806%, Training Loss: 0.4058%\n",
      "Epoch [220/300], Step [10/23], Training Accuracy: 72.1875%, Training Loss: 0.4014%\n",
      "Epoch [220/300], Step [11/23], Training Accuracy: 72.3011%, Training Loss: 0.4007%\n",
      "Epoch [220/300], Step [12/23], Training Accuracy: 73.1771%, Training Loss: 0.3988%\n",
      "Epoch [220/300], Step [13/23], Training Accuracy: 73.3173%, Training Loss: 0.4007%\n",
      "Epoch [220/300], Step [14/23], Training Accuracy: 73.7723%, Training Loss: 0.3978%\n",
      "Epoch [220/300], Step [15/23], Training Accuracy: 73.3333%, Training Loss: 0.4008%\n",
      "Epoch [220/300], Step [16/23], Training Accuracy: 73.3398%, Training Loss: 0.3995%\n",
      "Epoch [220/300], Step [17/23], Training Accuracy: 73.4375%, Training Loss: 0.3988%\n",
      "Epoch [220/300], Step [18/23], Training Accuracy: 73.4375%, Training Loss: 0.3998%\n",
      "Epoch [220/300], Step [19/23], Training Accuracy: 73.6842%, Training Loss: 0.3995%\n",
      "Epoch [220/300], Step [20/23], Training Accuracy: 73.9844%, Training Loss: 0.3987%\n",
      "Epoch [220/300], Step [21/23], Training Accuracy: 73.8839%, Training Loss: 0.3988%\n",
      "Epoch [220/300], Step [22/23], Training Accuracy: 73.7926%, Training Loss: 0.3983%\n",
      "Epoch [220/300], Step [23/23], Training Accuracy: 74.0097%, Training Loss: 0.3956%\n",
      "Epoch [221/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3930%\n",
      "Epoch [221/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.4044%\n",
      "Epoch [221/300], Step [3/23], Training Accuracy: 72.3958%, Training Loss: 0.4115%\n",
      "Epoch [221/300], Step [4/23], Training Accuracy: 75.7812%, Training Loss: 0.3964%\n",
      "Epoch [221/300], Step [5/23], Training Accuracy: 75.3125%, Training Loss: 0.3945%\n",
      "Epoch [221/300], Step [6/23], Training Accuracy: 75.7812%, Training Loss: 0.3960%\n",
      "Epoch [221/300], Step [7/23], Training Accuracy: 75.6696%, Training Loss: 0.4023%\n",
      "Epoch [221/300], Step [8/23], Training Accuracy: 76.1719%, Training Loss: 0.4019%\n",
      "Epoch [221/300], Step [9/23], Training Accuracy: 74.6528%, Training Loss: 0.4051%\n",
      "Epoch [221/300], Step [10/23], Training Accuracy: 75.0000%, Training Loss: 0.4017%\n",
      "Epoch [221/300], Step [11/23], Training Accuracy: 74.8580%, Training Loss: 0.4038%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [221/300], Step [12/23], Training Accuracy: 74.6094%, Training Loss: 0.4049%\n",
      "Epoch [221/300], Step [13/23], Training Accuracy: 74.2788%, Training Loss: 0.4062%\n",
      "Epoch [221/300], Step [14/23], Training Accuracy: 74.5536%, Training Loss: 0.4024%\n",
      "Epoch [221/300], Step [15/23], Training Accuracy: 74.3750%, Training Loss: 0.4057%\n",
      "Epoch [221/300], Step [16/23], Training Accuracy: 73.7305%, Training Loss: 0.4072%\n",
      "Epoch [221/300], Step [17/23], Training Accuracy: 74.0809%, Training Loss: 0.4060%\n",
      "Epoch [221/300], Step [18/23], Training Accuracy: 73.8715%, Training Loss: 0.4057%\n",
      "Epoch [221/300], Step [19/23], Training Accuracy: 74.0132%, Training Loss: 0.4055%\n",
      "Epoch [221/300], Step [20/23], Training Accuracy: 74.1406%, Training Loss: 0.4041%\n",
      "Epoch [221/300], Step [21/23], Training Accuracy: 73.4375%, Training Loss: 0.4051%\n",
      "Epoch [221/300], Step [22/23], Training Accuracy: 73.2955%, Training Loss: 0.4046%\n",
      "Epoch [221/300], Step [23/23], Training Accuracy: 73.3843%, Training Loss: 0.4012%\n",
      "Epoch [222/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3554%\n",
      "Epoch [222/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.3864%\n",
      "Epoch [222/300], Step [3/23], Training Accuracy: 72.9167%, Training Loss: 0.3893%\n",
      "Epoch [222/300], Step [4/23], Training Accuracy: 75.7812%, Training Loss: 0.3761%\n",
      "Epoch [222/300], Step [5/23], Training Accuracy: 73.1250%, Training Loss: 0.3822%\n",
      "Epoch [222/300], Step [6/23], Training Accuracy: 73.1771%, Training Loss: 0.3850%\n",
      "Epoch [222/300], Step [7/23], Training Accuracy: 72.0982%, Training Loss: 0.3912%\n",
      "Epoch [222/300], Step [8/23], Training Accuracy: 72.6562%, Training Loss: 0.3907%\n",
      "Epoch [222/300], Step [9/23], Training Accuracy: 71.3542%, Training Loss: 0.3960%\n",
      "Epoch [222/300], Step [10/23], Training Accuracy: 72.3438%, Training Loss: 0.3924%\n",
      "Epoch [222/300], Step [11/23], Training Accuracy: 72.5852%, Training Loss: 0.3918%\n",
      "Epoch [222/300], Step [12/23], Training Accuracy: 73.1771%, Training Loss: 0.3933%\n",
      "Epoch [222/300], Step [13/23], Training Accuracy: 72.4760%, Training Loss: 0.3966%\n",
      "Epoch [222/300], Step [14/23], Training Accuracy: 72.8795%, Training Loss: 0.3947%\n",
      "Epoch [222/300], Step [15/23], Training Accuracy: 72.6042%, Training Loss: 0.3962%\n",
      "Epoch [222/300], Step [16/23], Training Accuracy: 72.2656%, Training Loss: 0.3960%\n",
      "Epoch [222/300], Step [17/23], Training Accuracy: 72.5184%, Training Loss: 0.3963%\n",
      "Epoch [222/300], Step [18/23], Training Accuracy: 72.6562%, Training Loss: 0.3961%\n",
      "Epoch [222/300], Step [19/23], Training Accuracy: 72.9441%, Training Loss: 0.3964%\n",
      "Epoch [222/300], Step [20/23], Training Accuracy: 73.2812%, Training Loss: 0.3947%\n",
      "Epoch [222/300], Step [21/23], Training Accuracy: 73.1399%, Training Loss: 0.3953%\n",
      "Epoch [222/300], Step [22/23], Training Accuracy: 73.0824%, Training Loss: 0.3948%\n",
      "Epoch [222/300], Step [23/23], Training Accuracy: 73.2453%, Training Loss: 0.3912%\n",
      "Epoch [223/300], Step [1/23], Training Accuracy: 71.8750%, Training Loss: 0.3769%\n",
      "Epoch [223/300], Step [2/23], Training Accuracy: 71.0938%, Training Loss: 0.4082%\n",
      "Epoch [223/300], Step [3/23], Training Accuracy: 70.3125%, Training Loss: 0.4093%\n",
      "Epoch [223/300], Step [4/23], Training Accuracy: 72.2656%, Training Loss: 0.3957%\n",
      "Epoch [223/300], Step [5/23], Training Accuracy: 71.2500%, Training Loss: 0.3992%\n",
      "Epoch [223/300], Step [6/23], Training Accuracy: 72.6562%, Training Loss: 0.3919%\n",
      "Epoch [223/300], Step [7/23], Training Accuracy: 73.4375%, Training Loss: 0.3951%\n",
      "Epoch [223/300], Step [8/23], Training Accuracy: 73.6328%, Training Loss: 0.3967%\n",
      "Epoch [223/300], Step [9/23], Training Accuracy: 72.9167%, Training Loss: 0.4017%\n",
      "Epoch [223/300], Step [10/23], Training Accuracy: 72.9688%, Training Loss: 0.4001%\n",
      "Epoch [223/300], Step [11/23], Training Accuracy: 73.8636%, Training Loss: 0.3975%\n",
      "Epoch [223/300], Step [12/23], Training Accuracy: 73.6979%, Training Loss: 0.3985%\n",
      "Epoch [223/300], Step [13/23], Training Accuracy: 73.1971%, Training Loss: 0.4019%\n",
      "Epoch [223/300], Step [14/23], Training Accuracy: 73.4375%, Training Loss: 0.4001%\n",
      "Epoch [223/300], Step [15/23], Training Accuracy: 73.6458%, Training Loss: 0.3993%\n",
      "Epoch [223/300], Step [16/23], Training Accuracy: 73.9258%, Training Loss: 0.3976%\n",
      "Epoch [223/300], Step [17/23], Training Accuracy: 74.0809%, Training Loss: 0.3976%\n",
      "Epoch [223/300], Step [18/23], Training Accuracy: 73.7847%, Training Loss: 0.3989%\n",
      "Epoch [223/300], Step [19/23], Training Accuracy: 73.6842%, Training Loss: 0.3997%\n",
      "Epoch [223/300], Step [20/23], Training Accuracy: 73.5938%, Training Loss: 0.3979%\n",
      "Epoch [223/300], Step [21/23], Training Accuracy: 73.4375%, Training Loss: 0.3989%\n",
      "Epoch [223/300], Step [22/23], Training Accuracy: 73.5795%, Training Loss: 0.3978%\n",
      "Epoch [223/300], Step [23/23], Training Accuracy: 73.6623%, Training Loss: 0.3935%\n",
      "Epoch [224/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3796%\n",
      "Epoch [224/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3987%\n",
      "Epoch [224/300], Step [3/23], Training Accuracy: 72.3958%, Training Loss: 0.4054%\n",
      "Epoch [224/300], Step [4/23], Training Accuracy: 74.2188%, Training Loss: 0.3938%\n",
      "Epoch [224/300], Step [5/23], Training Accuracy: 74.3750%, Training Loss: 0.3874%\n",
      "Epoch [224/300], Step [6/23], Training Accuracy: 74.7396%, Training Loss: 0.3859%\n",
      "Epoch [224/300], Step [7/23], Training Accuracy: 73.8839%, Training Loss: 0.3922%\n",
      "Epoch [224/300], Step [8/23], Training Accuracy: 74.4141%, Training Loss: 0.3907%\n",
      "Epoch [224/300], Step [9/23], Training Accuracy: 72.7431%, Training Loss: 0.3989%\n",
      "Epoch [224/300], Step [10/23], Training Accuracy: 72.6562%, Training Loss: 0.3982%\n",
      "Epoch [224/300], Step [11/23], Training Accuracy: 73.1534%, Training Loss: 0.3966%\n",
      "Epoch [224/300], Step [12/23], Training Accuracy: 73.1771%, Training Loss: 0.3964%\n",
      "Epoch [224/300], Step [13/23], Training Accuracy: 72.4760%, Training Loss: 0.3985%\n",
      "Epoch [224/300], Step [14/23], Training Accuracy: 72.5446%, Training Loss: 0.3971%\n",
      "Epoch [224/300], Step [15/23], Training Accuracy: 72.3958%, Training Loss: 0.3982%\n",
      "Epoch [224/300], Step [16/23], Training Accuracy: 72.2656%, Training Loss: 0.3990%\n",
      "Epoch [224/300], Step [17/23], Training Accuracy: 72.3346%, Training Loss: 0.3976%\n",
      "Epoch [224/300], Step [18/23], Training Accuracy: 72.3958%, Training Loss: 0.3981%\n",
      "Epoch [224/300], Step [19/23], Training Accuracy: 72.2039%, Training Loss: 0.3992%\n",
      "Epoch [224/300], Step [20/23], Training Accuracy: 72.1875%, Training Loss: 0.3974%\n",
      "Epoch [224/300], Step [21/23], Training Accuracy: 72.1726%, Training Loss: 0.3974%\n",
      "Epoch [224/300], Step [22/23], Training Accuracy: 72.2301%, Training Loss: 0.3971%\n",
      "Epoch [224/300], Step [23/23], Training Accuracy: 72.3419%, Training Loss: 0.3936%\n",
      "Epoch [225/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3841%\n",
      "Epoch [225/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.4033%\n",
      "Epoch [225/300], Step [3/23], Training Accuracy: 73.9583%, Training Loss: 0.4088%\n",
      "Epoch [225/300], Step [4/23], Training Accuracy: 74.6094%, Training Loss: 0.3945%\n",
      "Epoch [225/300], Step [5/23], Training Accuracy: 75.0000%, Training Loss: 0.3919%\n",
      "Epoch [225/300], Step [6/23], Training Accuracy: 75.2604%, Training Loss: 0.3955%\n",
      "Epoch [225/300], Step [7/23], Training Accuracy: 75.4464%, Training Loss: 0.4006%\n",
      "Epoch [225/300], Step [8/23], Training Accuracy: 75.7812%, Training Loss: 0.4000%\n",
      "Epoch [225/300], Step [9/23], Training Accuracy: 75.0000%, Training Loss: 0.4037%\n",
      "Epoch [225/300], Step [10/23], Training Accuracy: 74.8438%, Training Loss: 0.4039%\n",
      "Epoch [225/300], Step [11/23], Training Accuracy: 75.4261%, Training Loss: 0.4033%\n",
      "Epoch [225/300], Step [12/23], Training Accuracy: 75.2604%, Training Loss: 0.4039%\n",
      "Epoch [225/300], Step [13/23], Training Accuracy: 75.1202%, Training Loss: 0.4053%\n",
      "Epoch [225/300], Step [14/23], Training Accuracy: 75.3348%, Training Loss: 0.4010%\n",
      "Epoch [225/300], Step [15/23], Training Accuracy: 74.8958%, Training Loss: 0.4032%\n",
      "Epoch [225/300], Step [16/23], Training Accuracy: 74.7070%, Training Loss: 0.4032%\n",
      "Epoch [225/300], Step [17/23], Training Accuracy: 74.7243%, Training Loss: 0.4033%\n",
      "Epoch [225/300], Step [18/23], Training Accuracy: 74.5660%, Training Loss: 0.4040%\n",
      "Epoch [225/300], Step [19/23], Training Accuracy: 74.5888%, Training Loss: 0.4027%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [225/300], Step [20/23], Training Accuracy: 75.0781%, Training Loss: 0.3991%\n",
      "Epoch [225/300], Step [21/23], Training Accuracy: 74.6280%, Training Loss: 0.3996%\n",
      "Epoch [225/300], Step [22/23], Training Accuracy: 74.7869%, Training Loss: 0.3982%\n",
      "Epoch [225/300], Step [23/23], Training Accuracy: 74.8436%, Training Loss: 0.3949%\n",
      "Epoch [226/300], Step [1/23], Training Accuracy: 73.4375%, Training Loss: 0.3633%\n",
      "Epoch [226/300], Step [2/23], Training Accuracy: 71.8750%, Training Loss: 0.3901%\n",
      "Epoch [226/300], Step [3/23], Training Accuracy: 69.2708%, Training Loss: 0.3929%\n",
      "Epoch [226/300], Step [4/23], Training Accuracy: 72.6562%, Training Loss: 0.3785%\n",
      "Epoch [226/300], Step [5/23], Training Accuracy: 72.5000%, Training Loss: 0.3837%\n",
      "Epoch [226/300], Step [6/23], Training Accuracy: 72.6562%, Training Loss: 0.3849%\n",
      "Epoch [226/300], Step [7/23], Training Accuracy: 72.9911%, Training Loss: 0.3868%\n",
      "Epoch [226/300], Step [8/23], Training Accuracy: 73.2422%, Training Loss: 0.3888%\n",
      "Epoch [226/300], Step [9/23], Training Accuracy: 72.3958%, Training Loss: 0.3947%\n",
      "Epoch [226/300], Step [10/23], Training Accuracy: 72.6562%, Training Loss: 0.3940%\n",
      "Epoch [226/300], Step [11/23], Training Accuracy: 72.3011%, Training Loss: 0.3940%\n",
      "Epoch [226/300], Step [12/23], Training Accuracy: 72.6562%, Training Loss: 0.3934%\n",
      "Epoch [226/300], Step [13/23], Training Accuracy: 72.3558%, Training Loss: 0.3982%\n",
      "Epoch [226/300], Step [14/23], Training Accuracy: 73.1027%, Training Loss: 0.3953%\n",
      "Epoch [226/300], Step [15/23], Training Accuracy: 73.0208%, Training Loss: 0.3989%\n",
      "Epoch [226/300], Step [16/23], Training Accuracy: 72.8516%, Training Loss: 0.4007%\n",
      "Epoch [226/300], Step [17/23], Training Accuracy: 73.2537%, Training Loss: 0.3990%\n",
      "Epoch [226/300], Step [18/23], Training Accuracy: 73.0903%, Training Loss: 0.4006%\n",
      "Epoch [226/300], Step [19/23], Training Accuracy: 73.4375%, Training Loss: 0.3988%\n",
      "Epoch [226/300], Step [20/23], Training Accuracy: 73.5156%, Training Loss: 0.3979%\n",
      "Epoch [226/300], Step [21/23], Training Accuracy: 72.9911%, Training Loss: 0.3993%\n",
      "Epoch [226/300], Step [22/23], Training Accuracy: 72.9403%, Training Loss: 0.3989%\n",
      "Epoch [226/300], Step [23/23], Training Accuracy: 72.9673%, Training Loss: 0.3948%\n",
      "Epoch [227/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3784%\n",
      "Epoch [227/300], Step [2/23], Training Accuracy: 72.6562%, Training Loss: 0.4128%\n",
      "Epoch [227/300], Step [3/23], Training Accuracy: 73.4375%, Training Loss: 0.4075%\n",
      "Epoch [227/300], Step [4/23], Training Accuracy: 73.4375%, Training Loss: 0.3935%\n",
      "Epoch [227/300], Step [5/23], Training Accuracy: 71.8750%, Training Loss: 0.3964%\n",
      "Epoch [227/300], Step [6/23], Training Accuracy: 73.9583%, Training Loss: 0.3981%\n",
      "Epoch [227/300], Step [7/23], Training Accuracy: 74.3304%, Training Loss: 0.4008%\n",
      "Epoch [227/300], Step [8/23], Training Accuracy: 74.6094%, Training Loss: 0.4004%\n",
      "Epoch [227/300], Step [9/23], Training Accuracy: 74.1319%, Training Loss: 0.4025%\n",
      "Epoch [227/300], Step [10/23], Training Accuracy: 73.7500%, Training Loss: 0.4020%\n",
      "Epoch [227/300], Step [11/23], Training Accuracy: 73.7216%, Training Loss: 0.4027%\n",
      "Epoch [227/300], Step [12/23], Training Accuracy: 73.6979%, Training Loss: 0.4043%\n",
      "Epoch [227/300], Step [13/23], Training Accuracy: 73.9183%, Training Loss: 0.4036%\n",
      "Epoch [227/300], Step [14/23], Training Accuracy: 74.2188%, Training Loss: 0.4002%\n",
      "Epoch [227/300], Step [15/23], Training Accuracy: 74.1667%, Training Loss: 0.4021%\n",
      "Epoch [227/300], Step [16/23], Training Accuracy: 74.1211%, Training Loss: 0.4025%\n",
      "Epoch [227/300], Step [17/23], Training Accuracy: 74.0809%, Training Loss: 0.4021%\n",
      "Epoch [227/300], Step [18/23], Training Accuracy: 74.1319%, Training Loss: 0.4024%\n",
      "Epoch [227/300], Step [19/23], Training Accuracy: 74.4243%, Training Loss: 0.4005%\n",
      "Epoch [227/300], Step [20/23], Training Accuracy: 74.7656%, Training Loss: 0.3983%\n",
      "Epoch [227/300], Step [21/23], Training Accuracy: 75.0000%, Training Loss: 0.3974%\n",
      "Epoch [227/300], Step [22/23], Training Accuracy: 75.0710%, Training Loss: 0.3962%\n",
      "Epoch [227/300], Step [23/23], Training Accuracy: 75.1911%, Training Loss: 0.3923%\n",
      "Epoch [228/300], Step [1/23], Training Accuracy: 81.2500%, Training Loss: 0.3842%\n",
      "Epoch [228/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.4133%\n",
      "Epoch [228/300], Step [3/23], Training Accuracy: 70.8333%, Training Loss: 0.4170%\n",
      "Epoch [228/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.3969%\n",
      "Epoch [228/300], Step [5/23], Training Accuracy: 73.1250%, Training Loss: 0.3978%\n",
      "Epoch [228/300], Step [6/23], Training Accuracy: 73.9583%, Training Loss: 0.3959%\n",
      "Epoch [228/300], Step [7/23], Training Accuracy: 74.3304%, Training Loss: 0.3980%\n",
      "Epoch [228/300], Step [8/23], Training Accuracy: 75.0000%, Training Loss: 0.3993%\n",
      "Epoch [228/300], Step [9/23], Training Accuracy: 74.3056%, Training Loss: 0.4014%\n",
      "Epoch [228/300], Step [10/23], Training Accuracy: 74.6875%, Training Loss: 0.3983%\n",
      "Epoch [228/300], Step [11/23], Training Accuracy: 75.4261%, Training Loss: 0.3950%\n",
      "Epoch [228/300], Step [12/23], Training Accuracy: 75.1302%, Training Loss: 0.3958%\n",
      "Epoch [228/300], Step [13/23], Training Accuracy: 74.6394%, Training Loss: 0.3983%\n",
      "Epoch [228/300], Step [14/23], Training Accuracy: 74.6652%, Training Loss: 0.3972%\n",
      "Epoch [228/300], Step [15/23], Training Accuracy: 74.0625%, Training Loss: 0.3996%\n",
      "Epoch [228/300], Step [16/23], Training Accuracy: 74.1211%, Training Loss: 0.3987%\n",
      "Epoch [228/300], Step [17/23], Training Accuracy: 73.9890%, Training Loss: 0.3988%\n",
      "Epoch [228/300], Step [18/23], Training Accuracy: 73.9583%, Training Loss: 0.3990%\n",
      "Epoch [228/300], Step [19/23], Training Accuracy: 74.1776%, Training Loss: 0.3984%\n",
      "Epoch [228/300], Step [20/23], Training Accuracy: 74.3750%, Training Loss: 0.3952%\n",
      "Epoch [228/300], Step [21/23], Training Accuracy: 74.3304%, Training Loss: 0.3952%\n",
      "Epoch [228/300], Step [22/23], Training Accuracy: 74.2898%, Training Loss: 0.3939%\n",
      "Epoch [228/300], Step [23/23], Training Accuracy: 74.7047%, Training Loss: 0.3893%\n",
      "Epoch [229/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3524%\n",
      "Epoch [229/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.3908%\n",
      "Epoch [229/300], Step [3/23], Training Accuracy: 73.9583%, Training Loss: 0.3938%\n",
      "Epoch [229/300], Step [4/23], Training Accuracy: 76.9531%, Training Loss: 0.3800%\n",
      "Epoch [229/300], Step [5/23], Training Accuracy: 75.6250%, Training Loss: 0.3828%\n",
      "Epoch [229/300], Step [6/23], Training Accuracy: 76.5625%, Training Loss: 0.3822%\n",
      "Epoch [229/300], Step [7/23], Training Accuracy: 76.5625%, Training Loss: 0.3873%\n",
      "Epoch [229/300], Step [8/23], Training Accuracy: 76.5625%, Training Loss: 0.3872%\n",
      "Epoch [229/300], Step [9/23], Training Accuracy: 75.5208%, Training Loss: 0.3928%\n",
      "Epoch [229/300], Step [10/23], Training Accuracy: 75.9375%, Training Loss: 0.3929%\n",
      "Epoch [229/300], Step [11/23], Training Accuracy: 75.9943%, Training Loss: 0.3911%\n",
      "Epoch [229/300], Step [12/23], Training Accuracy: 75.6510%, Training Loss: 0.3911%\n",
      "Epoch [229/300], Step [13/23], Training Accuracy: 75.0000%, Training Loss: 0.3934%\n",
      "Epoch [229/300], Step [14/23], Training Accuracy: 75.0000%, Training Loss: 0.3925%\n",
      "Epoch [229/300], Step [15/23], Training Accuracy: 74.3750%, Training Loss: 0.3952%\n",
      "Epoch [229/300], Step [16/23], Training Accuracy: 74.3164%, Training Loss: 0.3953%\n",
      "Epoch [229/300], Step [17/23], Training Accuracy: 73.9890%, Training Loss: 0.3947%\n",
      "Epoch [229/300], Step [18/23], Training Accuracy: 74.2188%, Training Loss: 0.3959%\n",
      "Epoch [229/300], Step [19/23], Training Accuracy: 74.5066%, Training Loss: 0.3949%\n",
      "Epoch [229/300], Step [20/23], Training Accuracy: 74.6094%, Training Loss: 0.3942%\n",
      "Epoch [229/300], Step [21/23], Training Accuracy: 74.4048%, Training Loss: 0.3940%\n",
      "Epoch [229/300], Step [22/23], Training Accuracy: 74.3608%, Training Loss: 0.3921%\n",
      "Epoch [229/300], Step [23/23], Training Accuracy: 74.5657%, Training Loss: 0.3886%\n",
      "Epoch [230/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3653%\n",
      "Epoch [230/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3889%\n",
      "Epoch [230/300], Step [3/23], Training Accuracy: 72.3958%, Training Loss: 0.3992%\n",
      "Epoch [230/300], Step [4/23], Training Accuracy: 75.7812%, Training Loss: 0.3852%\n",
      "Epoch [230/300], Step [5/23], Training Accuracy: 73.7500%, Training Loss: 0.3863%\n",
      "Epoch [230/300], Step [6/23], Training Accuracy: 74.2188%, Training Loss: 0.3885%\n",
      "Epoch [230/300], Step [7/23], Training Accuracy: 74.3304%, Training Loss: 0.3929%\n",
      "Epoch [230/300], Step [8/23], Training Accuracy: 74.8047%, Training Loss: 0.3918%\n",
      "Epoch [230/300], Step [9/23], Training Accuracy: 73.2639%, Training Loss: 0.3981%\n",
      "Epoch [230/300], Step [10/23], Training Accuracy: 72.6562%, Training Loss: 0.3974%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [230/300], Step [11/23], Training Accuracy: 72.4432%, Training Loss: 0.3972%\n",
      "Epoch [230/300], Step [12/23], Training Accuracy: 72.1354%, Training Loss: 0.3973%\n",
      "Epoch [230/300], Step [13/23], Training Accuracy: 71.5144%, Training Loss: 0.4000%\n",
      "Epoch [230/300], Step [14/23], Training Accuracy: 71.9866%, Training Loss: 0.3976%\n",
      "Epoch [230/300], Step [15/23], Training Accuracy: 71.6667%, Training Loss: 0.3987%\n",
      "Epoch [230/300], Step [16/23], Training Accuracy: 71.2891%, Training Loss: 0.3984%\n",
      "Epoch [230/300], Step [17/23], Training Accuracy: 71.1397%, Training Loss: 0.3996%\n",
      "Epoch [230/300], Step [18/23], Training Accuracy: 71.4410%, Training Loss: 0.3999%\n",
      "Epoch [230/300], Step [19/23], Training Accuracy: 71.4638%, Training Loss: 0.4005%\n",
      "Epoch [230/300], Step [20/23], Training Accuracy: 71.7969%, Training Loss: 0.3992%\n",
      "Epoch [230/300], Step [21/23], Training Accuracy: 71.4286%, Training Loss: 0.4006%\n",
      "Epoch [230/300], Step [22/23], Training Accuracy: 71.5909%, Training Loss: 0.3995%\n",
      "Epoch [230/300], Step [23/23], Training Accuracy: 71.5775%, Training Loss: 0.3967%\n",
      "Epoch [231/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3831%\n",
      "Epoch [231/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.3950%\n",
      "Epoch [231/300], Step [3/23], Training Accuracy: 70.3125%, Training Loss: 0.4087%\n",
      "Epoch [231/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.3979%\n",
      "Epoch [231/300], Step [5/23], Training Accuracy: 73.4375%, Training Loss: 0.4010%\n",
      "Epoch [231/300], Step [6/23], Training Accuracy: 73.6979%, Training Loss: 0.4019%\n",
      "Epoch [231/300], Step [7/23], Training Accuracy: 73.8839%, Training Loss: 0.4036%\n",
      "Epoch [231/300], Step [8/23], Training Accuracy: 73.8281%, Training Loss: 0.4020%\n",
      "Epoch [231/300], Step [9/23], Training Accuracy: 72.9167%, Training Loss: 0.4082%\n",
      "Epoch [231/300], Step [10/23], Training Accuracy: 73.4375%, Training Loss: 0.4060%\n",
      "Epoch [231/300], Step [11/23], Training Accuracy: 73.2955%, Training Loss: 0.4031%\n",
      "Epoch [231/300], Step [12/23], Training Accuracy: 73.4375%, Training Loss: 0.4039%\n",
      "Epoch [231/300], Step [13/23], Training Accuracy: 73.1971%, Training Loss: 0.4046%\n",
      "Epoch [231/300], Step [14/23], Training Accuracy: 73.2143%, Training Loss: 0.4021%\n",
      "Epoch [231/300], Step [15/23], Training Accuracy: 72.5000%, Training Loss: 0.4055%\n",
      "Epoch [231/300], Step [16/23], Training Accuracy: 71.9727%, Training Loss: 0.4067%\n",
      "Epoch [231/300], Step [17/23], Training Accuracy: 72.0588%, Training Loss: 0.4052%\n",
      "Epoch [231/300], Step [18/23], Training Accuracy: 71.9618%, Training Loss: 0.4064%\n",
      "Epoch [231/300], Step [19/23], Training Accuracy: 72.2862%, Training Loss: 0.4041%\n",
      "Epoch [231/300], Step [20/23], Training Accuracy: 72.5000%, Training Loss: 0.4019%\n",
      "Epoch [231/300], Step [21/23], Training Accuracy: 72.5446%, Training Loss: 0.4013%\n",
      "Epoch [231/300], Step [22/23], Training Accuracy: 72.5852%, Training Loss: 0.3993%\n",
      "Epoch [231/300], Step [23/23], Training Accuracy: 72.6894%, Training Loss: 0.3951%\n",
      "Epoch [232/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3646%\n",
      "Epoch [232/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3827%\n",
      "Epoch [232/300], Step [3/23], Training Accuracy: 74.4792%, Training Loss: 0.3936%\n",
      "Epoch [232/300], Step [4/23], Training Accuracy: 76.1719%, Training Loss: 0.3814%\n",
      "Epoch [232/300], Step [5/23], Training Accuracy: 74.0625%, Training Loss: 0.3852%\n",
      "Epoch [232/300], Step [6/23], Training Accuracy: 75.2604%, Training Loss: 0.3887%\n",
      "Epoch [232/300], Step [7/23], Training Accuracy: 75.0000%, Training Loss: 0.3948%\n",
      "Epoch [232/300], Step [8/23], Training Accuracy: 75.5859%, Training Loss: 0.3967%\n",
      "Epoch [232/300], Step [9/23], Training Accuracy: 74.4792%, Training Loss: 0.4006%\n",
      "Epoch [232/300], Step [10/23], Training Accuracy: 74.3750%, Training Loss: 0.3988%\n",
      "Epoch [232/300], Step [11/23], Training Accuracy: 75.1420%, Training Loss: 0.3982%\n",
      "Epoch [232/300], Step [12/23], Training Accuracy: 75.1302%, Training Loss: 0.3986%\n",
      "Epoch [232/300], Step [13/23], Training Accuracy: 75.1202%, Training Loss: 0.4013%\n",
      "Epoch [232/300], Step [14/23], Training Accuracy: 75.0000%, Training Loss: 0.3995%\n",
      "Epoch [232/300], Step [15/23], Training Accuracy: 74.5833%, Training Loss: 0.4016%\n",
      "Epoch [232/300], Step [16/23], Training Accuracy: 74.4141%, Training Loss: 0.4015%\n",
      "Epoch [232/300], Step [17/23], Training Accuracy: 74.4485%, Training Loss: 0.4005%\n",
      "Epoch [232/300], Step [18/23], Training Accuracy: 74.3924%, Training Loss: 0.4017%\n",
      "Epoch [232/300], Step [19/23], Training Accuracy: 74.5888%, Training Loss: 0.4002%\n",
      "Epoch [232/300], Step [20/23], Training Accuracy: 74.9219%, Training Loss: 0.3982%\n",
      "Epoch [232/300], Step [21/23], Training Accuracy: 74.4792%, Training Loss: 0.3982%\n",
      "Epoch [232/300], Step [22/23], Training Accuracy: 74.5028%, Training Loss: 0.3976%\n",
      "Epoch [232/300], Step [23/23], Training Accuracy: 74.6352%, Training Loss: 0.3943%\n",
      "Epoch [233/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3732%\n",
      "Epoch [233/300], Step [2/23], Training Accuracy: 72.6562%, Training Loss: 0.4088%\n",
      "Epoch [233/300], Step [3/23], Training Accuracy: 69.7917%, Training Loss: 0.4192%\n",
      "Epoch [233/300], Step [4/23], Training Accuracy: 72.2656%, Training Loss: 0.4017%\n",
      "Epoch [233/300], Step [5/23], Training Accuracy: 71.8750%, Training Loss: 0.4000%\n",
      "Epoch [233/300], Step [6/23], Training Accuracy: 72.9167%, Training Loss: 0.3959%\n",
      "Epoch [233/300], Step [7/23], Training Accuracy: 72.9911%, Training Loss: 0.4005%\n",
      "Epoch [233/300], Step [8/23], Training Accuracy: 73.8281%, Training Loss: 0.3992%\n",
      "Epoch [233/300], Step [9/23], Training Accuracy: 72.0486%, Training Loss: 0.4038%\n",
      "Epoch [233/300], Step [10/23], Training Accuracy: 72.0312%, Training Loss: 0.4025%\n",
      "Epoch [233/300], Step [11/23], Training Accuracy: 72.7273%, Training Loss: 0.4027%\n",
      "Epoch [233/300], Step [12/23], Training Accuracy: 72.3958%, Training Loss: 0.4019%\n",
      "Epoch [233/300], Step [13/23], Training Accuracy: 72.2356%, Training Loss: 0.4038%\n",
      "Epoch [233/300], Step [14/23], Training Accuracy: 72.2098%, Training Loss: 0.4026%\n",
      "Epoch [233/300], Step [15/23], Training Accuracy: 71.7708%, Training Loss: 0.4051%\n",
      "Epoch [233/300], Step [16/23], Training Accuracy: 71.7773%, Training Loss: 0.4057%\n",
      "Epoch [233/300], Step [17/23], Training Accuracy: 72.0588%, Training Loss: 0.4044%\n",
      "Epoch [233/300], Step [18/23], Training Accuracy: 72.3090%, Training Loss: 0.4044%\n",
      "Epoch [233/300], Step [19/23], Training Accuracy: 72.5329%, Training Loss: 0.4027%\n",
      "Epoch [233/300], Step [20/23], Training Accuracy: 72.8906%, Training Loss: 0.4012%\n",
      "Epoch [233/300], Step [21/23], Training Accuracy: 72.6935%, Training Loss: 0.4020%\n",
      "Epoch [233/300], Step [22/23], Training Accuracy: 73.2955%, Training Loss: 0.3997%\n",
      "Epoch [233/300], Step [23/23], Training Accuracy: 73.3843%, Training Loss: 0.3967%\n",
      "Epoch [234/300], Step [1/23], Training Accuracy: 73.4375%, Training Loss: 0.3831%\n",
      "Epoch [234/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.3922%\n",
      "Epoch [234/300], Step [3/23], Training Accuracy: 71.3542%, Training Loss: 0.4092%\n",
      "Epoch [234/300], Step [4/23], Training Accuracy: 74.6094%, Training Loss: 0.3943%\n",
      "Epoch [234/300], Step [5/23], Training Accuracy: 74.0625%, Training Loss: 0.3938%\n",
      "Epoch [234/300], Step [6/23], Training Accuracy: 74.4792%, Training Loss: 0.3892%\n",
      "Epoch [234/300], Step [7/23], Training Accuracy: 75.2232%, Training Loss: 0.3901%\n",
      "Epoch [234/300], Step [8/23], Training Accuracy: 75.1953%, Training Loss: 0.3922%\n",
      "Epoch [234/300], Step [9/23], Training Accuracy: 74.4792%, Training Loss: 0.3975%\n",
      "Epoch [234/300], Step [10/23], Training Accuracy: 74.2188%, Training Loss: 0.3963%\n",
      "Epoch [234/300], Step [11/23], Training Accuracy: 74.7159%, Training Loss: 0.3940%\n",
      "Epoch [234/300], Step [12/23], Training Accuracy: 74.8698%, Training Loss: 0.3945%\n",
      "Epoch [234/300], Step [13/23], Training Accuracy: 74.6394%, Training Loss: 0.3962%\n",
      "Epoch [234/300], Step [14/23], Training Accuracy: 74.7768%, Training Loss: 0.3942%\n",
      "Epoch [234/300], Step [15/23], Training Accuracy: 74.6875%, Training Loss: 0.3971%\n",
      "Epoch [234/300], Step [16/23], Training Accuracy: 74.6094%, Training Loss: 0.3970%\n",
      "Epoch [234/300], Step [17/23], Training Accuracy: 74.5404%, Training Loss: 0.3963%\n",
      "Epoch [234/300], Step [18/23], Training Accuracy: 74.5660%, Training Loss: 0.3958%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [234/300], Step [19/23], Training Accuracy: 74.4243%, Training Loss: 0.3955%\n",
      "Epoch [234/300], Step [20/23], Training Accuracy: 74.6094%, Training Loss: 0.3942%\n",
      "Epoch [234/300], Step [21/23], Training Accuracy: 74.3304%, Training Loss: 0.3943%\n",
      "Epoch [234/300], Step [22/23], Training Accuracy: 74.5028%, Training Loss: 0.3929%\n",
      "Epoch [234/300], Step [23/23], Training Accuracy: 74.6352%, Training Loss: 0.3891%\n",
      "Epoch [235/300], Step [1/23], Training Accuracy: 70.3125%, Training Loss: 0.3955%\n",
      "Epoch [235/300], Step [2/23], Training Accuracy: 70.3125%, Training Loss: 0.4124%\n",
      "Epoch [235/300], Step [3/23], Training Accuracy: 69.7917%, Training Loss: 0.4080%\n",
      "Epoch [235/300], Step [4/23], Training Accuracy: 74.2188%, Training Loss: 0.3871%\n",
      "Epoch [235/300], Step [5/23], Training Accuracy: 74.6875%, Training Loss: 0.3875%\n",
      "Epoch [235/300], Step [6/23], Training Accuracy: 74.4792%, Training Loss: 0.3934%\n",
      "Epoch [235/300], Step [7/23], Training Accuracy: 74.5536%, Training Loss: 0.3965%\n",
      "Epoch [235/300], Step [8/23], Training Accuracy: 74.6094%, Training Loss: 0.4027%\n",
      "Epoch [235/300], Step [9/23], Training Accuracy: 73.4375%, Training Loss: 0.4074%\n",
      "Epoch [235/300], Step [10/23], Training Accuracy: 74.0625%, Training Loss: 0.4035%\n",
      "Epoch [235/300], Step [11/23], Training Accuracy: 74.1477%, Training Loss: 0.4028%\n",
      "Epoch [235/300], Step [12/23], Training Accuracy: 74.2188%, Training Loss: 0.4018%\n",
      "Epoch [235/300], Step [13/23], Training Accuracy: 74.3990%, Training Loss: 0.4028%\n",
      "Epoch [235/300], Step [14/23], Training Accuracy: 74.7768%, Training Loss: 0.4001%\n",
      "Epoch [235/300], Step [15/23], Training Accuracy: 74.4792%, Training Loss: 0.4029%\n",
      "Epoch [235/300], Step [16/23], Training Accuracy: 74.2188%, Training Loss: 0.4027%\n",
      "Epoch [235/300], Step [17/23], Training Accuracy: 74.5404%, Training Loss: 0.4016%\n",
      "Epoch [235/300], Step [18/23], Training Accuracy: 74.4792%, Training Loss: 0.4018%\n",
      "Epoch [235/300], Step [19/23], Training Accuracy: 74.7533%, Training Loss: 0.4003%\n",
      "Epoch [235/300], Step [20/23], Training Accuracy: 75.1562%, Training Loss: 0.3971%\n",
      "Epoch [235/300], Step [21/23], Training Accuracy: 75.0744%, Training Loss: 0.3970%\n",
      "Epoch [235/300], Step [22/23], Training Accuracy: 74.8580%, Training Loss: 0.3977%\n",
      "Epoch [235/300], Step [23/23], Training Accuracy: 75.0521%, Training Loss: 0.3950%\n",
      "Epoch [236/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3801%\n",
      "Epoch [236/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.3971%\n",
      "Epoch [236/300], Step [3/23], Training Accuracy: 73.4375%, Training Loss: 0.4028%\n",
      "Epoch [236/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.3925%\n",
      "Epoch [236/300], Step [5/23], Training Accuracy: 72.8125%, Training Loss: 0.3929%\n",
      "Epoch [236/300], Step [6/23], Training Accuracy: 73.1771%, Training Loss: 0.3970%\n",
      "Epoch [236/300], Step [7/23], Training Accuracy: 73.6607%, Training Loss: 0.3992%\n",
      "Epoch [236/300], Step [8/23], Training Accuracy: 74.0234%, Training Loss: 0.3992%\n",
      "Epoch [236/300], Step [9/23], Training Accuracy: 73.0903%, Training Loss: 0.4018%\n",
      "Epoch [236/300], Step [10/23], Training Accuracy: 72.8125%, Training Loss: 0.3998%\n",
      "Epoch [236/300], Step [11/23], Training Accuracy: 72.5852%, Training Loss: 0.4003%\n",
      "Epoch [236/300], Step [12/23], Training Accuracy: 72.3958%, Training Loss: 0.4021%\n",
      "Epoch [236/300], Step [13/23], Training Accuracy: 72.5962%, Training Loss: 0.4020%\n",
      "Epoch [236/300], Step [14/23], Training Accuracy: 73.1027%, Training Loss: 0.3994%\n",
      "Epoch [236/300], Step [15/23], Training Accuracy: 72.6042%, Training Loss: 0.4018%\n",
      "Epoch [236/300], Step [16/23], Training Accuracy: 72.2656%, Training Loss: 0.4033%\n",
      "Epoch [236/300], Step [17/23], Training Accuracy: 72.3346%, Training Loss: 0.4027%\n",
      "Epoch [236/300], Step [18/23], Training Accuracy: 72.5694%, Training Loss: 0.4040%\n",
      "Epoch [236/300], Step [19/23], Training Accuracy: 72.8618%, Training Loss: 0.4029%\n",
      "Epoch [236/300], Step [20/23], Training Accuracy: 73.1250%, Training Loss: 0.4017%\n",
      "Epoch [236/300], Step [21/23], Training Accuracy: 72.9911%, Training Loss: 0.4013%\n",
      "Epoch [236/300], Step [22/23], Training Accuracy: 73.2244%, Training Loss: 0.3997%\n",
      "Epoch [236/300], Step [23/23], Training Accuracy: 73.4538%, Training Loss: 0.3965%\n",
      "Epoch [237/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3920%\n",
      "Epoch [237/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.3939%\n",
      "Epoch [237/300], Step [3/23], Training Accuracy: 70.3125%, Training Loss: 0.4019%\n",
      "Epoch [237/300], Step [4/23], Training Accuracy: 71.0938%, Training Loss: 0.3919%\n",
      "Epoch [237/300], Step [5/23], Training Accuracy: 71.5625%, Training Loss: 0.3894%\n",
      "Epoch [237/300], Step [6/23], Training Accuracy: 72.3958%, Training Loss: 0.3901%\n",
      "Epoch [237/300], Step [7/23], Training Accuracy: 72.0982%, Training Loss: 0.3960%\n",
      "Epoch [237/300], Step [8/23], Training Accuracy: 72.6562%, Training Loss: 0.3971%\n",
      "Epoch [237/300], Step [9/23], Training Accuracy: 72.0486%, Training Loss: 0.4028%\n",
      "Epoch [237/300], Step [10/23], Training Accuracy: 72.0312%, Training Loss: 0.4027%\n",
      "Epoch [237/300], Step [11/23], Training Accuracy: 72.8693%, Training Loss: 0.4016%\n",
      "Epoch [237/300], Step [12/23], Training Accuracy: 72.9167%, Training Loss: 0.4010%\n",
      "Epoch [237/300], Step [13/23], Training Accuracy: 72.5962%, Training Loss: 0.4023%\n",
      "Epoch [237/300], Step [14/23], Training Accuracy: 72.6562%, Training Loss: 0.4006%\n",
      "Epoch [237/300], Step [15/23], Training Accuracy: 72.2917%, Training Loss: 0.4022%\n",
      "Epoch [237/300], Step [16/23], Training Accuracy: 72.0703%, Training Loss: 0.4030%\n",
      "Epoch [237/300], Step [17/23], Training Accuracy: 72.6103%, Training Loss: 0.4016%\n",
      "Epoch [237/300], Step [18/23], Training Accuracy: 72.5694%, Training Loss: 0.4018%\n",
      "Epoch [237/300], Step [19/23], Training Accuracy: 72.6151%, Training Loss: 0.4003%\n",
      "Epoch [237/300], Step [20/23], Training Accuracy: 72.9688%, Training Loss: 0.3982%\n",
      "Epoch [237/300], Step [21/23], Training Accuracy: 73.0655%, Training Loss: 0.3987%\n",
      "Epoch [237/300], Step [22/23], Training Accuracy: 72.9403%, Training Loss: 0.3976%\n",
      "Epoch [237/300], Step [23/23], Training Accuracy: 73.0368%, Training Loss: 0.3930%\n",
      "Epoch [238/300], Step [1/23], Training Accuracy: 81.2500%, Training Loss: 0.3614%\n",
      "Epoch [238/300], Step [2/23], Training Accuracy: 78.1250%, Training Loss: 0.3921%\n",
      "Epoch [238/300], Step [3/23], Training Accuracy: 75.0000%, Training Loss: 0.3929%\n",
      "Epoch [238/300], Step [4/23], Training Accuracy: 78.5156%, Training Loss: 0.3770%\n",
      "Epoch [238/300], Step [5/23], Training Accuracy: 75.3125%, Training Loss: 0.3837%\n",
      "Epoch [238/300], Step [6/23], Training Accuracy: 75.7812%, Training Loss: 0.3857%\n",
      "Epoch [238/300], Step [7/23], Training Accuracy: 76.5625%, Training Loss: 0.3888%\n",
      "Epoch [238/300], Step [8/23], Training Accuracy: 77.3438%, Training Loss: 0.3906%\n",
      "Epoch [238/300], Step [9/23], Training Accuracy: 76.5625%, Training Loss: 0.3966%\n",
      "Epoch [238/300], Step [10/23], Training Accuracy: 76.7188%, Training Loss: 0.3943%\n",
      "Epoch [238/300], Step [11/23], Training Accuracy: 76.5625%, Training Loss: 0.3946%\n",
      "Epoch [238/300], Step [12/23], Training Accuracy: 76.3021%, Training Loss: 0.3963%\n",
      "Epoch [238/300], Step [13/23], Training Accuracy: 76.4423%, Training Loss: 0.3960%\n",
      "Epoch [238/300], Step [14/23], Training Accuracy: 76.4509%, Training Loss: 0.3944%\n",
      "Epoch [238/300], Step [15/23], Training Accuracy: 75.9375%, Training Loss: 0.3976%\n",
      "Epoch [238/300], Step [16/23], Training Accuracy: 75.6836%, Training Loss: 0.3984%\n",
      "Epoch [238/300], Step [17/23], Training Accuracy: 75.5515%, Training Loss: 0.3990%\n",
      "Epoch [238/300], Step [18/23], Training Accuracy: 75.3472%, Training Loss: 0.3996%\n",
      "Epoch [238/300], Step [19/23], Training Accuracy: 75.3289%, Training Loss: 0.4000%\n",
      "Epoch [238/300], Step [20/23], Training Accuracy: 75.4688%, Training Loss: 0.3982%\n",
      "Epoch [238/300], Step [21/23], Training Accuracy: 75.3720%, Training Loss: 0.3977%\n",
      "Epoch [238/300], Step [22/23], Training Accuracy: 75.4261%, Training Loss: 0.3973%\n",
      "Epoch [238/300], Step [23/23], Training Accuracy: 75.4691%, Training Loss: 0.3946%\n",
      "Epoch [239/300], Step [1/23], Training Accuracy: 81.2500%, Training Loss: 0.3594%\n",
      "Epoch [239/300], Step [2/23], Training Accuracy: 75.7812%, Training Loss: 0.3854%\n",
      "Epoch [239/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.3923%\n",
      "Epoch [239/300], Step [4/23], Training Accuracy: 74.6094%, Training Loss: 0.3821%\n",
      "Epoch [239/300], Step [5/23], Training Accuracy: 73.7500%, Training Loss: 0.3852%\n",
      "Epoch [239/300], Step [6/23], Training Accuracy: 74.7396%, Training Loss: 0.3835%\n",
      "Epoch [239/300], Step [7/23], Training Accuracy: 74.7768%, Training Loss: 0.3892%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [239/300], Step [8/23], Training Accuracy: 75.5859%, Training Loss: 0.3878%\n",
      "Epoch [239/300], Step [9/23], Training Accuracy: 74.3056%, Training Loss: 0.3939%\n",
      "Epoch [239/300], Step [10/23], Training Accuracy: 74.3750%, Training Loss: 0.3930%\n",
      "Epoch [239/300], Step [11/23], Training Accuracy: 74.2898%, Training Loss: 0.3914%\n",
      "Epoch [239/300], Step [12/23], Training Accuracy: 74.2188%, Training Loss: 0.3906%\n",
      "Epoch [239/300], Step [13/23], Training Accuracy: 74.1587%, Training Loss: 0.3921%\n",
      "Epoch [239/300], Step [14/23], Training Accuracy: 74.5536%, Training Loss: 0.3899%\n",
      "Epoch [239/300], Step [15/23], Training Accuracy: 74.4792%, Training Loss: 0.3931%\n",
      "Epoch [239/300], Step [16/23], Training Accuracy: 74.4141%, Training Loss: 0.3930%\n",
      "Epoch [239/300], Step [17/23], Training Accuracy: 74.3566%, Training Loss: 0.3933%\n",
      "Epoch [239/300], Step [18/23], Training Accuracy: 74.3924%, Training Loss: 0.3928%\n",
      "Epoch [239/300], Step [19/23], Training Accuracy: 74.5066%, Training Loss: 0.3928%\n",
      "Epoch [239/300], Step [20/23], Training Accuracy: 74.7656%, Training Loss: 0.3908%\n",
      "Epoch [239/300], Step [21/23], Training Accuracy: 74.8512%, Training Loss: 0.3909%\n",
      "Epoch [239/300], Step [22/23], Training Accuracy: 74.8580%, Training Loss: 0.3898%\n",
      "Epoch [239/300], Step [23/23], Training Accuracy: 74.9826%, Training Loss: 0.3867%\n",
      "Epoch [240/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3577%\n",
      "Epoch [240/300], Step [2/23], Training Accuracy: 71.8750%, Training Loss: 0.3960%\n",
      "Epoch [240/300], Step [3/23], Training Accuracy: 69.7917%, Training Loss: 0.4064%\n",
      "Epoch [240/300], Step [4/23], Training Accuracy: 73.0469%, Training Loss: 0.3889%\n",
      "Epoch [240/300], Step [5/23], Training Accuracy: 72.5000%, Training Loss: 0.3911%\n",
      "Epoch [240/300], Step [6/23], Training Accuracy: 73.1771%, Training Loss: 0.3899%\n",
      "Epoch [240/300], Step [7/23], Training Accuracy: 73.2143%, Training Loss: 0.3931%\n",
      "Epoch [240/300], Step [8/23], Training Accuracy: 74.0234%, Training Loss: 0.3933%\n",
      "Epoch [240/300], Step [9/23], Training Accuracy: 73.6111%, Training Loss: 0.3967%\n",
      "Epoch [240/300], Step [10/23], Training Accuracy: 73.4375%, Training Loss: 0.3952%\n",
      "Epoch [240/300], Step [11/23], Training Accuracy: 73.8636%, Training Loss: 0.3950%\n",
      "Epoch [240/300], Step [12/23], Training Accuracy: 74.0885%, Training Loss: 0.3961%\n",
      "Epoch [240/300], Step [13/23], Training Accuracy: 74.0385%, Training Loss: 0.3973%\n",
      "Epoch [240/300], Step [14/23], Training Accuracy: 74.2188%, Training Loss: 0.3951%\n",
      "Epoch [240/300], Step [15/23], Training Accuracy: 73.8542%, Training Loss: 0.3967%\n",
      "Epoch [240/300], Step [16/23], Training Accuracy: 74.2188%, Training Loss: 0.3964%\n",
      "Epoch [240/300], Step [17/23], Training Accuracy: 74.2647%, Training Loss: 0.3952%\n",
      "Epoch [240/300], Step [18/23], Training Accuracy: 74.3056%, Training Loss: 0.3950%\n",
      "Epoch [240/300], Step [19/23], Training Accuracy: 74.5066%, Training Loss: 0.3940%\n",
      "Epoch [240/300], Step [20/23], Training Accuracy: 74.6875%, Training Loss: 0.3929%\n",
      "Epoch [240/300], Step [21/23], Training Accuracy: 74.0327%, Training Loss: 0.3929%\n",
      "Epoch [240/300], Step [22/23], Training Accuracy: 74.1477%, Training Loss: 0.3925%\n",
      "Epoch [240/300], Step [23/23], Training Accuracy: 74.2877%, Training Loss: 0.3889%\n",
      "Epoch [241/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3733%\n",
      "Epoch [241/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.3953%\n",
      "Epoch [241/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.4083%\n",
      "Epoch [241/300], Step [4/23], Training Accuracy: 75.0000%, Training Loss: 0.3933%\n",
      "Epoch [241/300], Step [5/23], Training Accuracy: 73.7500%, Training Loss: 0.3936%\n",
      "Epoch [241/300], Step [6/23], Training Accuracy: 75.2604%, Training Loss: 0.3929%\n",
      "Epoch [241/300], Step [7/23], Training Accuracy: 75.2232%, Training Loss: 0.3948%\n",
      "Epoch [241/300], Step [8/23], Training Accuracy: 75.1953%, Training Loss: 0.3942%\n",
      "Epoch [241/300], Step [9/23], Training Accuracy: 73.9583%, Training Loss: 0.4008%\n",
      "Epoch [241/300], Step [10/23], Training Accuracy: 74.0625%, Training Loss: 0.4006%\n",
      "Epoch [241/300], Step [11/23], Training Accuracy: 74.0057%, Training Loss: 0.3996%\n",
      "Epoch [241/300], Step [12/23], Training Accuracy: 73.4375%, Training Loss: 0.4020%\n",
      "Epoch [241/300], Step [13/23], Training Accuracy: 73.4375%, Training Loss: 0.4024%\n",
      "Epoch [241/300], Step [14/23], Training Accuracy: 73.4375%, Training Loss: 0.4006%\n",
      "Epoch [241/300], Step [15/23], Training Accuracy: 73.1250%, Training Loss: 0.4021%\n",
      "Epoch [241/300], Step [16/23], Training Accuracy: 73.2422%, Training Loss: 0.4017%\n",
      "Epoch [241/300], Step [17/23], Training Accuracy: 73.0699%, Training Loss: 0.4026%\n",
      "Epoch [241/300], Step [18/23], Training Accuracy: 73.3507%, Training Loss: 0.4024%\n",
      "Epoch [241/300], Step [19/23], Training Accuracy: 73.2730%, Training Loss: 0.4034%\n",
      "Epoch [241/300], Step [20/23], Training Accuracy: 73.5156%, Training Loss: 0.4007%\n",
      "Epoch [241/300], Step [21/23], Training Accuracy: 73.3631%, Training Loss: 0.4008%\n",
      "Epoch [241/300], Step [22/23], Training Accuracy: 73.4375%, Training Loss: 0.3998%\n",
      "Epoch [241/300], Step [23/23], Training Accuracy: 73.5928%, Training Loss: 0.3956%\n",
      "Epoch [242/300], Step [1/23], Training Accuracy: 68.7500%, Training Loss: 0.3671%\n",
      "Epoch [242/300], Step [2/23], Training Accuracy: 71.8750%, Training Loss: 0.3915%\n",
      "Epoch [242/300], Step [3/23], Training Accuracy: 70.8333%, Training Loss: 0.4013%\n",
      "Epoch [242/300], Step [4/23], Training Accuracy: 74.6094%, Training Loss: 0.3856%\n",
      "Epoch [242/300], Step [5/23], Training Accuracy: 73.7500%, Training Loss: 0.3907%\n",
      "Epoch [242/300], Step [6/23], Training Accuracy: 74.2188%, Training Loss: 0.3886%\n",
      "Epoch [242/300], Step [7/23], Training Accuracy: 75.0000%, Training Loss: 0.3935%\n",
      "Epoch [242/300], Step [8/23], Training Accuracy: 75.5859%, Training Loss: 0.3915%\n",
      "Epoch [242/300], Step [9/23], Training Accuracy: 74.6528%, Training Loss: 0.3964%\n",
      "Epoch [242/300], Step [10/23], Training Accuracy: 74.3750%, Training Loss: 0.3968%\n",
      "Epoch [242/300], Step [11/23], Training Accuracy: 74.7159%, Training Loss: 0.3967%\n",
      "Epoch [242/300], Step [12/23], Training Accuracy: 74.3490%, Training Loss: 0.4003%\n",
      "Epoch [242/300], Step [13/23], Training Accuracy: 73.9183%, Training Loss: 0.4015%\n",
      "Epoch [242/300], Step [14/23], Training Accuracy: 74.2188%, Training Loss: 0.3992%\n",
      "Epoch [242/300], Step [15/23], Training Accuracy: 73.8542%, Training Loss: 0.4020%\n",
      "Epoch [242/300], Step [16/23], Training Accuracy: 73.7305%, Training Loss: 0.4021%\n",
      "Epoch [242/300], Step [17/23], Training Accuracy: 73.6213%, Training Loss: 0.4003%\n",
      "Epoch [242/300], Step [18/23], Training Accuracy: 73.7847%, Training Loss: 0.3998%\n",
      "Epoch [242/300], Step [19/23], Training Accuracy: 74.0132%, Training Loss: 0.3983%\n",
      "Epoch [242/300], Step [20/23], Training Accuracy: 74.4531%, Training Loss: 0.3955%\n",
      "Epoch [242/300], Step [21/23], Training Accuracy: 74.3304%, Training Loss: 0.3956%\n",
      "Epoch [242/300], Step [22/23], Training Accuracy: 74.2898%, Training Loss: 0.3956%\n",
      "Epoch [242/300], Step [23/23], Training Accuracy: 74.3572%, Training Loss: 0.3926%\n",
      "Epoch [243/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3797%\n",
      "Epoch [243/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.3985%\n",
      "Epoch [243/300], Step [3/23], Training Accuracy: 71.3542%, Training Loss: 0.4146%\n",
      "Epoch [243/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.3962%\n",
      "Epoch [243/300], Step [5/23], Training Accuracy: 73.1250%, Training Loss: 0.3954%\n",
      "Epoch [243/300], Step [6/23], Training Accuracy: 72.9167%, Training Loss: 0.3946%\n",
      "Epoch [243/300], Step [7/23], Training Accuracy: 73.2143%, Training Loss: 0.3968%\n",
      "Epoch [243/300], Step [8/23], Training Accuracy: 73.0469%, Training Loss: 0.3997%\n",
      "Epoch [243/300], Step [9/23], Training Accuracy: 72.2222%, Training Loss: 0.4045%\n",
      "Epoch [243/300], Step [10/23], Training Accuracy: 72.8125%, Training Loss: 0.4013%\n",
      "Epoch [243/300], Step [11/23], Training Accuracy: 73.2955%, Training Loss: 0.3985%\n",
      "Epoch [243/300], Step [12/23], Training Accuracy: 73.3073%, Training Loss: 0.3985%\n",
      "Epoch [243/300], Step [13/23], Training Accuracy: 73.1971%, Training Loss: 0.3999%\n",
      "Epoch [243/300], Step [14/23], Training Accuracy: 73.5491%, Training Loss: 0.3971%\n",
      "Epoch [243/300], Step [15/23], Training Accuracy: 73.6458%, Training Loss: 0.3985%\n",
      "Epoch [243/300], Step [16/23], Training Accuracy: 73.5352%, Training Loss: 0.4003%\n",
      "Epoch [243/300], Step [17/23], Training Accuracy: 73.7132%, Training Loss: 0.4001%\n",
      "Epoch [243/300], Step [18/23], Training Accuracy: 73.6111%, Training Loss: 0.3993%\n",
      "Epoch [243/300], Step [19/23], Training Accuracy: 73.7664%, Training Loss: 0.3984%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [243/300], Step [20/23], Training Accuracy: 73.9844%, Training Loss: 0.3972%\n",
      "Epoch [243/300], Step [21/23], Training Accuracy: 73.6607%, Training Loss: 0.3971%\n",
      "Epoch [243/300], Step [22/23], Training Accuracy: 73.7926%, Training Loss: 0.3962%\n",
      "Epoch [243/300], Step [23/23], Training Accuracy: 74.0097%, Training Loss: 0.3927%\n",
      "Epoch [244/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3864%\n",
      "Epoch [244/300], Step [2/23], Training Accuracy: 72.6562%, Training Loss: 0.4105%\n",
      "Epoch [244/300], Step [3/23], Training Accuracy: 71.3542%, Training Loss: 0.4126%\n",
      "Epoch [244/300], Step [4/23], Training Accuracy: 73.4375%, Training Loss: 0.3960%\n",
      "Epoch [244/300], Step [5/23], Training Accuracy: 72.5000%, Training Loss: 0.3968%\n",
      "Epoch [244/300], Step [6/23], Training Accuracy: 73.6979%, Training Loss: 0.3976%\n",
      "Epoch [244/300], Step [7/23], Training Accuracy: 73.6607%, Training Loss: 0.3999%\n",
      "Epoch [244/300], Step [8/23], Training Accuracy: 74.6094%, Training Loss: 0.3967%\n",
      "Epoch [244/300], Step [9/23], Training Accuracy: 74.1319%, Training Loss: 0.4001%\n",
      "Epoch [244/300], Step [10/23], Training Accuracy: 74.2188%, Training Loss: 0.3984%\n",
      "Epoch [244/300], Step [11/23], Training Accuracy: 74.2898%, Training Loss: 0.3971%\n",
      "Epoch [244/300], Step [12/23], Training Accuracy: 74.6094%, Training Loss: 0.4001%\n",
      "Epoch [244/300], Step [13/23], Training Accuracy: 74.7596%, Training Loss: 0.4010%\n",
      "Epoch [244/300], Step [14/23], Training Accuracy: 74.5536%, Training Loss: 0.3980%\n",
      "Epoch [244/300], Step [15/23], Training Accuracy: 74.3750%, Training Loss: 0.4025%\n",
      "Epoch [244/300], Step [16/23], Training Accuracy: 74.0234%, Training Loss: 0.4029%\n",
      "Epoch [244/300], Step [17/23], Training Accuracy: 73.9890%, Training Loss: 0.4023%\n",
      "Epoch [244/300], Step [18/23], Training Accuracy: 73.6111%, Training Loss: 0.4036%\n",
      "Epoch [244/300], Step [19/23], Training Accuracy: 73.7664%, Training Loss: 0.4033%\n",
      "Epoch [244/300], Step [20/23], Training Accuracy: 73.7500%, Training Loss: 0.4018%\n",
      "Epoch [244/300], Step [21/23], Training Accuracy: 73.5863%, Training Loss: 0.4017%\n",
      "Epoch [244/300], Step [22/23], Training Accuracy: 73.6506%, Training Loss: 0.4006%\n",
      "Epoch [244/300], Step [23/23], Training Accuracy: 73.7318%, Training Loss: 0.3962%\n",
      "Epoch [245/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3601%\n",
      "Epoch [245/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3889%\n",
      "Epoch [245/300], Step [3/23], Training Accuracy: 72.9167%, Training Loss: 0.4040%\n",
      "Epoch [245/300], Step [4/23], Training Accuracy: 74.2188%, Training Loss: 0.3914%\n",
      "Epoch [245/300], Step [5/23], Training Accuracy: 73.7500%, Training Loss: 0.3944%\n",
      "Epoch [245/300], Step [6/23], Training Accuracy: 74.7396%, Training Loss: 0.3952%\n",
      "Epoch [245/300], Step [7/23], Training Accuracy: 75.2232%, Training Loss: 0.3944%\n",
      "Epoch [245/300], Step [8/23], Training Accuracy: 75.7812%, Training Loss: 0.3926%\n",
      "Epoch [245/300], Step [9/23], Training Accuracy: 73.9583%, Training Loss: 0.3999%\n",
      "Epoch [245/300], Step [10/23], Training Accuracy: 73.2812%, Training Loss: 0.3995%\n",
      "Epoch [245/300], Step [11/23], Training Accuracy: 73.4375%, Training Loss: 0.3989%\n",
      "Epoch [245/300], Step [12/23], Training Accuracy: 73.4375%, Training Loss: 0.3972%\n",
      "Epoch [245/300], Step [13/23], Training Accuracy: 73.1971%, Training Loss: 0.3981%\n",
      "Epoch [245/300], Step [14/23], Training Accuracy: 73.6607%, Training Loss: 0.3968%\n",
      "Epoch [245/300], Step [15/23], Training Accuracy: 73.7500%, Training Loss: 0.3969%\n",
      "Epoch [245/300], Step [16/23], Training Accuracy: 73.3398%, Training Loss: 0.3974%\n",
      "Epoch [245/300], Step [17/23], Training Accuracy: 73.3456%, Training Loss: 0.3971%\n",
      "Epoch [245/300], Step [18/23], Training Accuracy: 73.3507%, Training Loss: 0.3972%\n",
      "Epoch [245/300], Step [19/23], Training Accuracy: 73.5197%, Training Loss: 0.3964%\n",
      "Epoch [245/300], Step [20/23], Training Accuracy: 73.9062%, Training Loss: 0.3948%\n",
      "Epoch [245/300], Step [21/23], Training Accuracy: 73.7351%, Training Loss: 0.3946%\n",
      "Epoch [245/300], Step [22/23], Training Accuracy: 73.7926%, Training Loss: 0.3949%\n",
      "Epoch [245/300], Step [23/23], Training Accuracy: 73.9402%, Training Loss: 0.3911%\n",
      "Epoch [246/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3793%\n",
      "Epoch [246/300], Step [2/23], Training Accuracy: 75.7812%, Training Loss: 0.3976%\n",
      "Epoch [246/300], Step [3/23], Training Accuracy: 71.3542%, Training Loss: 0.4092%\n",
      "Epoch [246/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.3973%\n",
      "Epoch [246/300], Step [5/23], Training Accuracy: 74.6875%, Training Loss: 0.3903%\n",
      "Epoch [246/300], Step [6/23], Training Accuracy: 75.0000%, Training Loss: 0.3927%\n",
      "Epoch [246/300], Step [7/23], Training Accuracy: 75.0000%, Training Loss: 0.3962%\n",
      "Epoch [246/300], Step [8/23], Training Accuracy: 75.5859%, Training Loss: 0.3941%\n",
      "Epoch [246/300], Step [9/23], Training Accuracy: 75.0000%, Training Loss: 0.3977%\n",
      "Epoch [246/300], Step [10/23], Training Accuracy: 74.8438%, Training Loss: 0.3963%\n",
      "Epoch [246/300], Step [11/23], Training Accuracy: 75.5682%, Training Loss: 0.3951%\n",
      "Epoch [246/300], Step [12/23], Training Accuracy: 75.5208%, Training Loss: 0.3950%\n",
      "Epoch [246/300], Step [13/23], Training Accuracy: 75.6010%, Training Loss: 0.3967%\n",
      "Epoch [246/300], Step [14/23], Training Accuracy: 76.0045%, Training Loss: 0.3924%\n",
      "Epoch [246/300], Step [15/23], Training Accuracy: 75.8333%, Training Loss: 0.3931%\n",
      "Epoch [246/300], Step [16/23], Training Accuracy: 75.4883%, Training Loss: 0.3939%\n",
      "Epoch [246/300], Step [17/23], Training Accuracy: 75.3676%, Training Loss: 0.3939%\n",
      "Epoch [246/300], Step [18/23], Training Accuracy: 75.5208%, Training Loss: 0.3942%\n",
      "Epoch [246/300], Step [19/23], Training Accuracy: 75.8224%, Training Loss: 0.3928%\n",
      "Epoch [246/300], Step [20/23], Training Accuracy: 75.9375%, Training Loss: 0.3905%\n",
      "Epoch [246/300], Step [21/23], Training Accuracy: 75.5952%, Training Loss: 0.3913%\n",
      "Epoch [246/300], Step [22/23], Training Accuracy: 75.5682%, Training Loss: 0.3916%\n",
      "Epoch [246/300], Step [23/23], Training Accuracy: 75.8165%, Training Loss: 0.3871%\n",
      "Epoch [247/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3683%\n",
      "Epoch [247/300], Step [2/23], Training Accuracy: 75.7812%, Training Loss: 0.3782%\n",
      "Epoch [247/300], Step [3/23], Training Accuracy: 73.4375%, Training Loss: 0.3909%\n",
      "Epoch [247/300], Step [4/23], Training Accuracy: 76.9531%, Training Loss: 0.3806%\n",
      "Epoch [247/300], Step [5/23], Training Accuracy: 75.6250%, Training Loss: 0.3827%\n",
      "Epoch [247/300], Step [6/23], Training Accuracy: 76.3021%, Training Loss: 0.3801%\n",
      "Epoch [247/300], Step [7/23], Training Accuracy: 76.7857%, Training Loss: 0.3839%\n",
      "Epoch [247/300], Step [8/23], Training Accuracy: 76.3672%, Training Loss: 0.3866%\n",
      "Epoch [247/300], Step [9/23], Training Accuracy: 75.1736%, Training Loss: 0.3918%\n",
      "Epoch [247/300], Step [10/23], Training Accuracy: 74.6875%, Training Loss: 0.3923%\n",
      "Epoch [247/300], Step [11/23], Training Accuracy: 74.5739%, Training Loss: 0.3915%\n",
      "Epoch [247/300], Step [12/23], Training Accuracy: 74.8698%, Training Loss: 0.3912%\n",
      "Epoch [247/300], Step [13/23], Training Accuracy: 74.5192%, Training Loss: 0.3942%\n",
      "Epoch [247/300], Step [14/23], Training Accuracy: 75.4464%, Training Loss: 0.3904%\n",
      "Epoch [247/300], Step [15/23], Training Accuracy: 74.8958%, Training Loss: 0.3928%\n",
      "Epoch [247/300], Step [16/23], Training Accuracy: 74.6094%, Training Loss: 0.3929%\n",
      "Epoch [247/300], Step [17/23], Training Accuracy: 74.7243%, Training Loss: 0.3943%\n",
      "Epoch [247/300], Step [18/23], Training Accuracy: 74.5660%, Training Loss: 0.3950%\n",
      "Epoch [247/300], Step [19/23], Training Accuracy: 74.7533%, Training Loss: 0.3937%\n",
      "Epoch [247/300], Step [20/23], Training Accuracy: 74.9219%, Training Loss: 0.3919%\n",
      "Epoch [247/300], Step [21/23], Training Accuracy: 75.0000%, Training Loss: 0.3930%\n",
      "Epoch [247/300], Step [22/23], Training Accuracy: 75.1420%, Training Loss: 0.3915%\n",
      "Epoch [247/300], Step [23/23], Training Accuracy: 75.3301%, Training Loss: 0.3877%\n",
      "Epoch [248/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3734%\n",
      "Epoch [248/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.4114%\n",
      "Epoch [248/300], Step [3/23], Training Accuracy: 73.4375%, Training Loss: 0.4079%\n",
      "Epoch [248/300], Step [4/23], Training Accuracy: 76.1719%, Training Loss: 0.3899%\n",
      "Epoch [248/300], Step [5/23], Training Accuracy: 74.6875%, Training Loss: 0.3942%\n",
      "Epoch [248/300], Step [6/23], Training Accuracy: 74.7396%, Training Loss: 0.3963%\n",
      "Epoch [248/300], Step [7/23], Training Accuracy: 74.3304%, Training Loss: 0.3996%\n",
      "Epoch [248/300], Step [8/23], Training Accuracy: 74.2188%, Training Loss: 0.3990%\n",
      "Epoch [248/300], Step [9/23], Training Accuracy: 72.9167%, Training Loss: 0.4049%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [248/300], Step [10/23], Training Accuracy: 73.4375%, Training Loss: 0.4044%\n",
      "Epoch [248/300], Step [11/23], Training Accuracy: 73.8636%, Training Loss: 0.4033%\n",
      "Epoch [248/300], Step [12/23], Training Accuracy: 73.9583%, Training Loss: 0.4032%\n",
      "Epoch [248/300], Step [13/23], Training Accuracy: 73.7981%, Training Loss: 0.4046%\n",
      "Epoch [248/300], Step [14/23], Training Accuracy: 74.1071%, Training Loss: 0.4009%\n",
      "Epoch [248/300], Step [15/23], Training Accuracy: 73.8542%, Training Loss: 0.4034%\n",
      "Epoch [248/300], Step [16/23], Training Accuracy: 73.7305%, Training Loss: 0.4025%\n",
      "Epoch [248/300], Step [17/23], Training Accuracy: 73.1618%, Training Loss: 0.4023%\n",
      "Epoch [248/300], Step [18/23], Training Accuracy: 73.5243%, Training Loss: 0.4025%\n",
      "Epoch [248/300], Step [19/23], Training Accuracy: 73.4375%, Training Loss: 0.4023%\n",
      "Epoch [248/300], Step [20/23], Training Accuracy: 73.7500%, Training Loss: 0.4003%\n",
      "Epoch [248/300], Step [21/23], Training Accuracy: 74.0327%, Training Loss: 0.3986%\n",
      "Epoch [248/300], Step [22/23], Training Accuracy: 74.0767%, Training Loss: 0.3984%\n",
      "Epoch [248/300], Step [23/23], Training Accuracy: 74.2877%, Training Loss: 0.3942%\n",
      "Epoch [249/300], Step [1/23], Training Accuracy: 68.7500%, Training Loss: 0.3775%\n",
      "Epoch [249/300], Step [2/23], Training Accuracy: 67.1875%, Training Loss: 0.4123%\n",
      "Epoch [249/300], Step [3/23], Training Accuracy: 65.6250%, Training Loss: 0.4177%\n",
      "Epoch [249/300], Step [4/23], Training Accuracy: 67.1875%, Training Loss: 0.4033%\n",
      "Epoch [249/300], Step [5/23], Training Accuracy: 67.5000%, Training Loss: 0.3985%\n",
      "Epoch [249/300], Step [6/23], Training Accuracy: 69.5312%, Training Loss: 0.3956%\n",
      "Epoch [249/300], Step [7/23], Training Accuracy: 70.5357%, Training Loss: 0.3980%\n",
      "Epoch [249/300], Step [8/23], Training Accuracy: 71.2891%, Training Loss: 0.3990%\n",
      "Epoch [249/300], Step [9/23], Training Accuracy: 70.8333%, Training Loss: 0.4064%\n",
      "Epoch [249/300], Step [10/23], Training Accuracy: 71.7188%, Training Loss: 0.4048%\n",
      "Epoch [249/300], Step [11/23], Training Accuracy: 71.5909%, Training Loss: 0.4016%\n",
      "Epoch [249/300], Step [12/23], Training Accuracy: 72.0052%, Training Loss: 0.3993%\n",
      "Epoch [249/300], Step [13/23], Training Accuracy: 71.6346%, Training Loss: 0.4026%\n",
      "Epoch [249/300], Step [14/23], Training Accuracy: 72.0982%, Training Loss: 0.3999%\n",
      "Epoch [249/300], Step [15/23], Training Accuracy: 72.0833%, Training Loss: 0.4006%\n",
      "Epoch [249/300], Step [16/23], Training Accuracy: 72.4609%, Training Loss: 0.3990%\n",
      "Epoch [249/300], Step [17/23], Training Accuracy: 72.2426%, Training Loss: 0.3992%\n",
      "Epoch [249/300], Step [18/23], Training Accuracy: 71.7014%, Training Loss: 0.4000%\n",
      "Epoch [249/300], Step [19/23], Training Accuracy: 71.9572%, Training Loss: 0.3987%\n",
      "Epoch [249/300], Step [20/23], Training Accuracy: 72.1875%, Training Loss: 0.3982%\n",
      "Epoch [249/300], Step [21/23], Training Accuracy: 71.9494%, Training Loss: 0.3979%\n",
      "Epoch [249/300], Step [22/23], Training Accuracy: 72.0881%, Training Loss: 0.3974%\n",
      "Epoch [249/300], Step [23/23], Training Accuracy: 72.3419%, Training Loss: 0.3932%\n",
      "Epoch [250/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3794%\n",
      "Epoch [250/300], Step [2/23], Training Accuracy: 75.7812%, Training Loss: 0.3983%\n",
      "Epoch [250/300], Step [3/23], Training Accuracy: 75.0000%, Training Loss: 0.4056%\n",
      "Epoch [250/300], Step [4/23], Training Accuracy: 77.3438%, Training Loss: 0.3887%\n",
      "Epoch [250/300], Step [5/23], Training Accuracy: 75.3125%, Training Loss: 0.3947%\n",
      "Epoch [250/300], Step [6/23], Training Accuracy: 75.7812%, Training Loss: 0.3965%\n",
      "Epoch [250/300], Step [7/23], Training Accuracy: 75.2232%, Training Loss: 0.4020%\n",
      "Epoch [250/300], Step [8/23], Training Accuracy: 75.3906%, Training Loss: 0.4069%\n",
      "Epoch [250/300], Step [9/23], Training Accuracy: 74.4792%, Training Loss: 0.4091%\n",
      "Epoch [250/300], Step [10/23], Training Accuracy: 74.8438%, Training Loss: 0.4062%\n",
      "Epoch [250/300], Step [11/23], Training Accuracy: 75.0000%, Training Loss: 0.4029%\n",
      "Epoch [250/300], Step [12/23], Training Accuracy: 74.8698%, Training Loss: 0.4036%\n",
      "Epoch [250/300], Step [13/23], Training Accuracy: 74.5192%, Training Loss: 0.4046%\n",
      "Epoch [250/300], Step [14/23], Training Accuracy: 75.1116%, Training Loss: 0.4010%\n",
      "Epoch [250/300], Step [15/23], Training Accuracy: 74.5833%, Training Loss: 0.4038%\n",
      "Epoch [250/300], Step [16/23], Training Accuracy: 74.7070%, Training Loss: 0.4026%\n",
      "Epoch [250/300], Step [17/23], Training Accuracy: 74.4485%, Training Loss: 0.4024%\n",
      "Epoch [250/300], Step [18/23], Training Accuracy: 74.5660%, Training Loss: 0.4016%\n",
      "Epoch [250/300], Step [19/23], Training Accuracy: 74.5066%, Training Loss: 0.4006%\n",
      "Epoch [250/300], Step [20/23], Training Accuracy: 74.7656%, Training Loss: 0.3981%\n",
      "Epoch [250/300], Step [21/23], Training Accuracy: 74.7024%, Training Loss: 0.3978%\n",
      "Epoch [250/300], Step [22/23], Training Accuracy: 74.8580%, Training Loss: 0.3960%\n",
      "Epoch [250/300], Step [23/23], Training Accuracy: 74.9131%, Training Loss: 0.3938%\n",
      "Epoch [251/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3507%\n",
      "Epoch [251/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.3788%\n",
      "Epoch [251/300], Step [3/23], Training Accuracy: 74.4792%, Training Loss: 0.3843%\n",
      "Epoch [251/300], Step [4/23], Training Accuracy: 75.7812%, Training Loss: 0.3751%\n",
      "Epoch [251/300], Step [5/23], Training Accuracy: 76.2500%, Training Loss: 0.3740%\n",
      "Epoch [251/300], Step [6/23], Training Accuracy: 76.3021%, Training Loss: 0.3771%\n",
      "Epoch [251/300], Step [7/23], Training Accuracy: 76.1161%, Training Loss: 0.3841%\n",
      "Epoch [251/300], Step [8/23], Training Accuracy: 76.5625%, Training Loss: 0.3870%\n",
      "Epoch [251/300], Step [9/23], Training Accuracy: 75.1736%, Training Loss: 0.3924%\n",
      "Epoch [251/300], Step [10/23], Training Accuracy: 74.8438%, Training Loss: 0.3903%\n",
      "Epoch [251/300], Step [11/23], Training Accuracy: 74.7159%, Training Loss: 0.3904%\n",
      "Epoch [251/300], Step [12/23], Training Accuracy: 75.0000%, Training Loss: 0.3911%\n",
      "Epoch [251/300], Step [13/23], Training Accuracy: 74.7596%, Training Loss: 0.3941%\n",
      "Epoch [251/300], Step [14/23], Training Accuracy: 75.1116%, Training Loss: 0.3932%\n",
      "Epoch [251/300], Step [15/23], Training Accuracy: 74.7917%, Training Loss: 0.3975%\n",
      "Epoch [251/300], Step [16/23], Training Accuracy: 74.6094%, Training Loss: 0.3973%\n",
      "Epoch [251/300], Step [17/23], Training Accuracy: 74.4485%, Training Loss: 0.3976%\n",
      "Epoch [251/300], Step [18/23], Training Accuracy: 74.4792%, Training Loss: 0.3983%\n",
      "Epoch [251/300], Step [19/23], Training Accuracy: 74.6711%, Training Loss: 0.3976%\n",
      "Epoch [251/300], Step [20/23], Training Accuracy: 74.8438%, Training Loss: 0.3960%\n",
      "Epoch [251/300], Step [21/23], Training Accuracy: 74.5536%, Training Loss: 0.3961%\n",
      "Epoch [251/300], Step [22/23], Training Accuracy: 74.5739%, Training Loss: 0.3953%\n",
      "Epoch [251/300], Step [23/23], Training Accuracy: 74.6352%, Training Loss: 0.3916%\n",
      "Epoch [252/300], Step [1/23], Training Accuracy: 73.4375%, Training Loss: 0.3722%\n",
      "Epoch [252/300], Step [2/23], Training Accuracy: 71.8750%, Training Loss: 0.4040%\n",
      "Epoch [252/300], Step [3/23], Training Accuracy: 69.7917%, Training Loss: 0.4040%\n",
      "Epoch [252/300], Step [4/23], Training Accuracy: 72.2656%, Training Loss: 0.3886%\n",
      "Epoch [252/300], Step [5/23], Training Accuracy: 70.9375%, Training Loss: 0.3913%\n",
      "Epoch [252/300], Step [6/23], Training Accuracy: 71.8750%, Training Loss: 0.3967%\n",
      "Epoch [252/300], Step [7/23], Training Accuracy: 72.9911%, Training Loss: 0.4000%\n",
      "Epoch [252/300], Step [8/23], Training Accuracy: 72.8516%, Training Loss: 0.4027%\n",
      "Epoch [252/300], Step [9/23], Training Accuracy: 72.2222%, Training Loss: 0.4078%\n",
      "Epoch [252/300], Step [10/23], Training Accuracy: 72.9688%, Training Loss: 0.4049%\n",
      "Epoch [252/300], Step [11/23], Training Accuracy: 73.5795%, Training Loss: 0.4017%\n",
      "Epoch [252/300], Step [12/23], Training Accuracy: 73.4375%, Training Loss: 0.4014%\n",
      "Epoch [252/300], Step [13/23], Training Accuracy: 73.1971%, Training Loss: 0.4027%\n",
      "Epoch [252/300], Step [14/23], Training Accuracy: 73.8839%, Training Loss: 0.3996%\n",
      "Epoch [252/300], Step [15/23], Training Accuracy: 73.4375%, Training Loss: 0.4014%\n",
      "Epoch [252/300], Step [16/23], Training Accuracy: 73.2422%, Training Loss: 0.4030%\n",
      "Epoch [252/300], Step [17/23], Training Accuracy: 73.1618%, Training Loss: 0.4023%\n",
      "Epoch [252/300], Step [18/23], Training Accuracy: 73.4375%, Training Loss: 0.4018%\n",
      "Epoch [252/300], Step [19/23], Training Accuracy: 73.5197%, Training Loss: 0.4019%\n",
      "Epoch [252/300], Step [20/23], Training Accuracy: 73.8281%, Training Loss: 0.4000%\n",
      "Epoch [252/300], Step [21/23], Training Accuracy: 73.7351%, Training Loss: 0.3998%\n",
      "Epoch [252/300], Step [22/23], Training Accuracy: 74.0767%, Training Loss: 0.3976%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [252/300], Step [23/23], Training Accuracy: 74.1487%, Training Loss: 0.3943%\n",
      "Epoch [253/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3776%\n",
      "Epoch [253/300], Step [2/23], Training Accuracy: 75.7812%, Training Loss: 0.3975%\n",
      "Epoch [253/300], Step [3/23], Training Accuracy: 71.3542%, Training Loss: 0.4027%\n",
      "Epoch [253/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.3888%\n",
      "Epoch [253/300], Step [5/23], Training Accuracy: 72.5000%, Training Loss: 0.3921%\n",
      "Epoch [253/300], Step [6/23], Training Accuracy: 73.9583%, Training Loss: 0.3888%\n",
      "Epoch [253/300], Step [7/23], Training Accuracy: 74.1071%, Training Loss: 0.3922%\n",
      "Epoch [253/300], Step [8/23], Training Accuracy: 75.0000%, Training Loss: 0.3888%\n",
      "Epoch [253/300], Step [9/23], Training Accuracy: 74.3056%, Training Loss: 0.3926%\n",
      "Epoch [253/300], Step [10/23], Training Accuracy: 74.6875%, Training Loss: 0.3896%\n",
      "Epoch [253/300], Step [11/23], Training Accuracy: 75.2841%, Training Loss: 0.3891%\n",
      "Epoch [253/300], Step [12/23], Training Accuracy: 75.7812%, Training Loss: 0.3883%\n",
      "Epoch [253/300], Step [13/23], Training Accuracy: 75.7212%, Training Loss: 0.3906%\n",
      "Epoch [253/300], Step [14/23], Training Accuracy: 75.6696%, Training Loss: 0.3899%\n",
      "Epoch [253/300], Step [15/23], Training Accuracy: 75.2083%, Training Loss: 0.3917%\n",
      "Epoch [253/300], Step [16/23], Training Accuracy: 74.9023%, Training Loss: 0.3925%\n",
      "Epoch [253/300], Step [17/23], Training Accuracy: 75.1838%, Training Loss: 0.3924%\n",
      "Epoch [253/300], Step [18/23], Training Accuracy: 75.2604%, Training Loss: 0.3934%\n",
      "Epoch [253/300], Step [19/23], Training Accuracy: 75.1645%, Training Loss: 0.3932%\n",
      "Epoch [253/300], Step [20/23], Training Accuracy: 74.9219%, Training Loss: 0.3919%\n",
      "Epoch [253/300], Step [21/23], Training Accuracy: 74.6280%, Training Loss: 0.3930%\n",
      "Epoch [253/300], Step [22/23], Training Accuracy: 74.5028%, Training Loss: 0.3925%\n",
      "Epoch [253/300], Step [23/23], Training Accuracy: 74.4267%, Training Loss: 0.3902%\n",
      "Epoch [254/300], Step [1/23], Training Accuracy: 68.7500%, Training Loss: 0.3888%\n",
      "Epoch [254/300], Step [2/23], Training Accuracy: 71.8750%, Training Loss: 0.3936%\n",
      "Epoch [254/300], Step [3/23], Training Accuracy: 71.3542%, Training Loss: 0.4034%\n",
      "Epoch [254/300], Step [4/23], Training Accuracy: 74.2188%, Training Loss: 0.3905%\n",
      "Epoch [254/300], Step [5/23], Training Accuracy: 73.4375%, Training Loss: 0.3918%\n",
      "Epoch [254/300], Step [6/23], Training Accuracy: 73.6979%, Training Loss: 0.3943%\n",
      "Epoch [254/300], Step [7/23], Training Accuracy: 74.1071%, Training Loss: 0.3969%\n",
      "Epoch [254/300], Step [8/23], Training Accuracy: 74.4141%, Training Loss: 0.3992%\n",
      "Epoch [254/300], Step [9/23], Training Accuracy: 73.6111%, Training Loss: 0.4016%\n",
      "Epoch [254/300], Step [10/23], Training Accuracy: 74.0625%, Training Loss: 0.3984%\n",
      "Epoch [254/300], Step [11/23], Training Accuracy: 74.5739%, Training Loss: 0.3957%\n",
      "Epoch [254/300], Step [12/23], Training Accuracy: 74.7396%, Training Loss: 0.3954%\n",
      "Epoch [254/300], Step [13/23], Training Accuracy: 74.7596%, Training Loss: 0.3973%\n",
      "Epoch [254/300], Step [14/23], Training Accuracy: 75.1116%, Training Loss: 0.3963%\n",
      "Epoch [254/300], Step [15/23], Training Accuracy: 74.6875%, Training Loss: 0.3981%\n",
      "Epoch [254/300], Step [16/23], Training Accuracy: 74.5117%, Training Loss: 0.3983%\n",
      "Epoch [254/300], Step [17/23], Training Accuracy: 73.9890%, Training Loss: 0.3999%\n",
      "Epoch [254/300], Step [18/23], Training Accuracy: 74.0451%, Training Loss: 0.3998%\n",
      "Epoch [254/300], Step [19/23], Training Accuracy: 74.3421%, Training Loss: 0.3989%\n",
      "Epoch [254/300], Step [20/23], Training Accuracy: 74.6094%, Training Loss: 0.3971%\n",
      "Epoch [254/300], Step [21/23], Training Accuracy: 74.4792%, Training Loss: 0.3971%\n",
      "Epoch [254/300], Step [22/23], Training Accuracy: 74.4318%, Training Loss: 0.3963%\n",
      "Epoch [254/300], Step [23/23], Training Accuracy: 74.5657%, Training Loss: 0.3922%\n",
      "Epoch [255/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3680%\n",
      "Epoch [255/300], Step [2/23], Training Accuracy: 72.6562%, Training Loss: 0.4003%\n",
      "Epoch [255/300], Step [3/23], Training Accuracy: 70.3125%, Training Loss: 0.4061%\n",
      "Epoch [255/300], Step [4/23], Training Accuracy: 74.6094%, Training Loss: 0.3868%\n",
      "Epoch [255/300], Step [5/23], Training Accuracy: 74.0625%, Training Loss: 0.3845%\n",
      "Epoch [255/300], Step [6/23], Training Accuracy: 75.0000%, Training Loss: 0.3873%\n",
      "Epoch [255/300], Step [7/23], Training Accuracy: 75.0000%, Training Loss: 0.3920%\n",
      "Epoch [255/300], Step [8/23], Training Accuracy: 75.1953%, Training Loss: 0.3917%\n",
      "Epoch [255/300], Step [9/23], Training Accuracy: 74.3056%, Training Loss: 0.3960%\n",
      "Epoch [255/300], Step [10/23], Training Accuracy: 74.5312%, Training Loss: 0.3941%\n",
      "Epoch [255/300], Step [11/23], Training Accuracy: 74.1477%, Training Loss: 0.3949%\n",
      "Epoch [255/300], Step [12/23], Training Accuracy: 74.4792%, Training Loss: 0.3945%\n",
      "Epoch [255/300], Step [13/23], Training Accuracy: 74.1587%, Training Loss: 0.3961%\n",
      "Epoch [255/300], Step [14/23], Training Accuracy: 74.6652%, Training Loss: 0.3946%\n",
      "Epoch [255/300], Step [15/23], Training Accuracy: 74.6875%, Training Loss: 0.3962%\n",
      "Epoch [255/300], Step [16/23], Training Accuracy: 74.3164%, Training Loss: 0.3987%\n",
      "Epoch [255/300], Step [17/23], Training Accuracy: 74.4485%, Training Loss: 0.3977%\n",
      "Epoch [255/300], Step [18/23], Training Accuracy: 74.6528%, Training Loss: 0.3973%\n",
      "Epoch [255/300], Step [19/23], Training Accuracy: 74.5066%, Training Loss: 0.3977%\n",
      "Epoch [255/300], Step [20/23], Training Accuracy: 74.7656%, Training Loss: 0.3969%\n",
      "Epoch [255/300], Step [21/23], Training Accuracy: 75.0000%, Training Loss: 0.3959%\n",
      "Epoch [255/300], Step [22/23], Training Accuracy: 75.2131%, Training Loss: 0.3933%\n",
      "Epoch [255/300], Step [23/23], Training Accuracy: 75.1911%, Training Loss: 0.3902%\n",
      "Epoch [256/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3900%\n",
      "Epoch [256/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.4068%\n",
      "Epoch [256/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.4102%\n",
      "Epoch [256/300], Step [4/23], Training Accuracy: 74.6094%, Training Loss: 0.3943%\n",
      "Epoch [256/300], Step [5/23], Training Accuracy: 72.1875%, Training Loss: 0.3933%\n",
      "Epoch [256/300], Step [6/23], Training Accuracy: 73.6979%, Training Loss: 0.3907%\n",
      "Epoch [256/300], Step [7/23], Training Accuracy: 73.6607%, Training Loss: 0.3946%\n",
      "Epoch [256/300], Step [8/23], Training Accuracy: 73.8281%, Training Loss: 0.3937%\n",
      "Epoch [256/300], Step [9/23], Training Accuracy: 73.2639%, Training Loss: 0.3962%\n",
      "Epoch [256/300], Step [10/23], Training Accuracy: 73.2812%, Training Loss: 0.3945%\n",
      "Epoch [256/300], Step [11/23], Training Accuracy: 73.0114%, Training Loss: 0.3962%\n",
      "Epoch [256/300], Step [12/23], Training Accuracy: 73.0469%, Training Loss: 0.3977%\n",
      "Epoch [256/300], Step [13/23], Training Accuracy: 73.1971%, Training Loss: 0.3981%\n",
      "Epoch [256/300], Step [14/23], Training Accuracy: 73.6607%, Training Loss: 0.3961%\n",
      "Epoch [256/300], Step [15/23], Training Accuracy: 73.2292%, Training Loss: 0.3990%\n",
      "Epoch [256/300], Step [16/23], Training Accuracy: 72.9492%, Training Loss: 0.3987%\n",
      "Epoch [256/300], Step [17/23], Training Accuracy: 73.2537%, Training Loss: 0.3985%\n",
      "Epoch [256/300], Step [18/23], Training Accuracy: 73.2639%, Training Loss: 0.3990%\n",
      "Epoch [256/300], Step [19/23], Training Accuracy: 73.1086%, Training Loss: 0.3991%\n",
      "Epoch [256/300], Step [20/23], Training Accuracy: 73.3594%, Training Loss: 0.3975%\n",
      "Epoch [256/300], Step [21/23], Training Accuracy: 73.2143%, Training Loss: 0.3973%\n",
      "Epoch [256/300], Step [22/23], Training Accuracy: 73.5795%, Training Loss: 0.3957%\n",
      "Epoch [256/300], Step [23/23], Training Accuracy: 73.6623%, Training Loss: 0.3924%\n",
      "Epoch [257/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3700%\n",
      "Epoch [257/300], Step [2/23], Training Accuracy: 71.0938%, Training Loss: 0.3933%\n",
      "Epoch [257/300], Step [3/23], Training Accuracy: 69.2708%, Training Loss: 0.4044%\n",
      "Epoch [257/300], Step [4/23], Training Accuracy: 74.2188%, Training Loss: 0.3856%\n",
      "Epoch [257/300], Step [5/23], Training Accuracy: 73.7500%, Training Loss: 0.3859%\n",
      "Epoch [257/300], Step [6/23], Training Accuracy: 74.7396%, Training Loss: 0.3860%\n",
      "Epoch [257/300], Step [7/23], Training Accuracy: 75.0000%, Training Loss: 0.3872%\n",
      "Epoch [257/300], Step [8/23], Training Accuracy: 75.7812%, Training Loss: 0.3857%\n",
      "Epoch [257/300], Step [9/23], Training Accuracy: 75.0000%, Training Loss: 0.3905%\n",
      "Epoch [257/300], Step [10/23], Training Accuracy: 75.1562%, Training Loss: 0.3908%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [257/300], Step [11/23], Training Accuracy: 75.5682%, Training Loss: 0.3898%\n",
      "Epoch [257/300], Step [12/23], Training Accuracy: 75.2604%, Training Loss: 0.3928%\n",
      "Epoch [257/300], Step [13/23], Training Accuracy: 75.3606%, Training Loss: 0.3931%\n",
      "Epoch [257/300], Step [14/23], Training Accuracy: 75.5580%, Training Loss: 0.3929%\n",
      "Epoch [257/300], Step [15/23], Training Accuracy: 74.6875%, Training Loss: 0.3984%\n",
      "Epoch [257/300], Step [16/23], Training Accuracy: 74.3164%, Training Loss: 0.4000%\n",
      "Epoch [257/300], Step [17/23], Training Accuracy: 74.4485%, Training Loss: 0.4002%\n",
      "Epoch [257/300], Step [18/23], Training Accuracy: 74.4792%, Training Loss: 0.4007%\n",
      "Epoch [257/300], Step [19/23], Training Accuracy: 74.5888%, Training Loss: 0.3998%\n",
      "Epoch [257/300], Step [20/23], Training Accuracy: 74.9219%, Training Loss: 0.3974%\n",
      "Epoch [257/300], Step [21/23], Training Accuracy: 74.9256%, Training Loss: 0.3971%\n",
      "Epoch [257/300], Step [22/23], Training Accuracy: 75.2131%, Training Loss: 0.3963%\n",
      "Epoch [257/300], Step [23/23], Training Accuracy: 75.1911%, Training Loss: 0.3930%\n",
      "Epoch [258/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3612%\n",
      "Epoch [258/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.3958%\n",
      "Epoch [258/300], Step [3/23], Training Accuracy: 72.3958%, Training Loss: 0.4027%\n",
      "Epoch [258/300], Step [4/23], Training Accuracy: 74.6094%, Training Loss: 0.3888%\n",
      "Epoch [258/300], Step [5/23], Training Accuracy: 73.4375%, Training Loss: 0.3909%\n",
      "Epoch [258/300], Step [6/23], Training Accuracy: 73.6979%, Training Loss: 0.3919%\n",
      "Epoch [258/300], Step [7/23], Training Accuracy: 74.1071%, Training Loss: 0.3986%\n",
      "Epoch [258/300], Step [8/23], Training Accuracy: 74.6094%, Training Loss: 0.3946%\n",
      "Epoch [258/300], Step [9/23], Training Accuracy: 73.7847%, Training Loss: 0.4001%\n",
      "Epoch [258/300], Step [10/23], Training Accuracy: 73.7500%, Training Loss: 0.3979%\n",
      "Epoch [258/300], Step [11/23], Training Accuracy: 74.1477%, Training Loss: 0.3950%\n",
      "Epoch [258/300], Step [12/23], Training Accuracy: 74.0885%, Training Loss: 0.3964%\n",
      "Epoch [258/300], Step [13/23], Training Accuracy: 73.0769%, Training Loss: 0.4004%\n",
      "Epoch [258/300], Step [14/23], Training Accuracy: 73.6607%, Training Loss: 0.3984%\n",
      "Epoch [258/300], Step [15/23], Training Accuracy: 73.3333%, Training Loss: 0.4007%\n",
      "Epoch [258/300], Step [16/23], Training Accuracy: 73.2422%, Training Loss: 0.4003%\n",
      "Epoch [258/300], Step [17/23], Training Accuracy: 73.0699%, Training Loss: 0.4008%\n",
      "Epoch [258/300], Step [18/23], Training Accuracy: 73.4375%, Training Loss: 0.3993%\n",
      "Epoch [258/300], Step [19/23], Training Accuracy: 73.3553%, Training Loss: 0.3990%\n",
      "Epoch [258/300], Step [20/23], Training Accuracy: 73.6719%, Training Loss: 0.3967%\n",
      "Epoch [258/300], Step [21/23], Training Accuracy: 73.7351%, Training Loss: 0.3968%\n",
      "Epoch [258/300], Step [22/23], Training Accuracy: 73.9347%, Training Loss: 0.3965%\n",
      "Epoch [258/300], Step [23/23], Training Accuracy: 74.2182%, Training Loss: 0.3928%\n",
      "Epoch [259/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3669%\n",
      "Epoch [259/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3980%\n",
      "Epoch [259/300], Step [3/23], Training Accuracy: 71.3542%, Training Loss: 0.4024%\n",
      "Epoch [259/300], Step [4/23], Training Accuracy: 74.2188%, Training Loss: 0.3875%\n",
      "Epoch [259/300], Step [5/23], Training Accuracy: 73.1250%, Training Loss: 0.3892%\n",
      "Epoch [259/300], Step [6/23], Training Accuracy: 75.0000%, Training Loss: 0.3854%\n",
      "Epoch [259/300], Step [7/23], Training Accuracy: 75.2232%, Training Loss: 0.3884%\n",
      "Epoch [259/300], Step [8/23], Training Accuracy: 75.5859%, Training Loss: 0.3884%\n",
      "Epoch [259/300], Step [9/23], Training Accuracy: 74.3056%, Training Loss: 0.3959%\n",
      "Epoch [259/300], Step [10/23], Training Accuracy: 73.9062%, Training Loss: 0.3954%\n",
      "Epoch [259/300], Step [11/23], Training Accuracy: 74.2898%, Training Loss: 0.3949%\n",
      "Epoch [259/300], Step [12/23], Training Accuracy: 74.3490%, Training Loss: 0.3954%\n",
      "Epoch [259/300], Step [13/23], Training Accuracy: 74.2788%, Training Loss: 0.3956%\n",
      "Epoch [259/300], Step [14/23], Training Accuracy: 74.4420%, Training Loss: 0.3953%\n",
      "Epoch [259/300], Step [15/23], Training Accuracy: 74.0625%, Training Loss: 0.3980%\n",
      "Epoch [259/300], Step [16/23], Training Accuracy: 73.7305%, Training Loss: 0.3978%\n",
      "Epoch [259/300], Step [17/23], Training Accuracy: 73.7132%, Training Loss: 0.3973%\n",
      "Epoch [259/300], Step [18/23], Training Accuracy: 73.6111%, Training Loss: 0.3979%\n",
      "Epoch [259/300], Step [19/23], Training Accuracy: 73.9309%, Training Loss: 0.3968%\n",
      "Epoch [259/300], Step [20/23], Training Accuracy: 74.6094%, Training Loss: 0.3941%\n",
      "Epoch [259/300], Step [21/23], Training Accuracy: 74.4792%, Training Loss: 0.3941%\n",
      "Epoch [259/300], Step [22/23], Training Accuracy: 74.5739%, Training Loss: 0.3925%\n",
      "Epoch [259/300], Step [23/23], Training Accuracy: 74.7741%, Training Loss: 0.3883%\n",
      "Epoch [260/300], Step [1/23], Training Accuracy: 82.8125%, Training Loss: 0.3503%\n",
      "Epoch [260/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3857%\n",
      "Epoch [260/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.3989%\n",
      "Epoch [260/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.3923%\n",
      "Epoch [260/300], Step [5/23], Training Accuracy: 73.4375%, Training Loss: 0.3907%\n",
      "Epoch [260/300], Step [6/23], Training Accuracy: 73.6979%, Training Loss: 0.3926%\n",
      "Epoch [260/300], Step [7/23], Training Accuracy: 73.4375%, Training Loss: 0.3974%\n",
      "Epoch [260/300], Step [8/23], Training Accuracy: 74.4141%, Training Loss: 0.3983%\n",
      "Epoch [260/300], Step [9/23], Training Accuracy: 73.9583%, Training Loss: 0.3998%\n",
      "Epoch [260/300], Step [10/23], Training Accuracy: 73.2812%, Training Loss: 0.4000%\n",
      "Epoch [260/300], Step [11/23], Training Accuracy: 73.0114%, Training Loss: 0.3989%\n",
      "Epoch [260/300], Step [12/23], Training Accuracy: 73.5677%, Training Loss: 0.3990%\n",
      "Epoch [260/300], Step [13/23], Training Accuracy: 73.5577%, Training Loss: 0.4006%\n",
      "Epoch [260/300], Step [14/23], Training Accuracy: 73.6607%, Training Loss: 0.4000%\n",
      "Epoch [260/300], Step [15/23], Training Accuracy: 73.5417%, Training Loss: 0.4038%\n",
      "Epoch [260/300], Step [16/23], Training Accuracy: 73.5352%, Training Loss: 0.4027%\n",
      "Epoch [260/300], Step [17/23], Training Accuracy: 73.6213%, Training Loss: 0.4016%\n",
      "Epoch [260/300], Step [18/23], Training Accuracy: 73.7847%, Training Loss: 0.4003%\n",
      "Epoch [260/300], Step [19/23], Training Accuracy: 73.6020%, Training Loss: 0.4005%\n",
      "Epoch [260/300], Step [20/23], Training Accuracy: 74.0625%, Training Loss: 0.3979%\n",
      "Epoch [260/300], Step [21/23], Training Accuracy: 73.9583%, Training Loss: 0.3988%\n",
      "Epoch [260/300], Step [22/23], Training Accuracy: 74.1477%, Training Loss: 0.3982%\n",
      "Epoch [260/300], Step [23/23], Training Accuracy: 74.1487%, Training Loss: 0.3947%\n",
      "Epoch [261/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3807%\n",
      "Epoch [261/300], Step [2/23], Training Accuracy: 77.3438%, Training Loss: 0.3932%\n",
      "Epoch [261/300], Step [3/23], Training Accuracy: 73.4375%, Training Loss: 0.3952%\n",
      "Epoch [261/300], Step [4/23], Training Accuracy: 76.1719%, Training Loss: 0.3810%\n",
      "Epoch [261/300], Step [5/23], Training Accuracy: 75.0000%, Training Loss: 0.3839%\n",
      "Epoch [261/300], Step [6/23], Training Accuracy: 76.0417%, Training Loss: 0.3857%\n",
      "Epoch [261/300], Step [7/23], Training Accuracy: 76.3393%, Training Loss: 0.3903%\n",
      "Epoch [261/300], Step [8/23], Training Accuracy: 75.7812%, Training Loss: 0.3919%\n",
      "Epoch [261/300], Step [9/23], Training Accuracy: 75.0000%, Training Loss: 0.3991%\n",
      "Epoch [261/300], Step [10/23], Training Accuracy: 74.2188%, Training Loss: 0.3987%\n",
      "Epoch [261/300], Step [11/23], Training Accuracy: 74.7159%, Training Loss: 0.3967%\n",
      "Epoch [261/300], Step [12/23], Training Accuracy: 74.3490%, Training Loss: 0.3986%\n",
      "Epoch [261/300], Step [13/23], Training Accuracy: 74.2788%, Training Loss: 0.3993%\n",
      "Epoch [261/300], Step [14/23], Training Accuracy: 74.7768%, Training Loss: 0.3971%\n",
      "Epoch [261/300], Step [15/23], Training Accuracy: 74.4792%, Training Loss: 0.3997%\n",
      "Epoch [261/300], Step [16/23], Training Accuracy: 74.5117%, Training Loss: 0.3988%\n",
      "Epoch [261/300], Step [17/23], Training Accuracy: 74.6324%, Training Loss: 0.3987%\n",
      "Epoch [261/300], Step [18/23], Training Accuracy: 74.8264%, Training Loss: 0.3988%\n",
      "Epoch [261/300], Step [19/23], Training Accuracy: 74.6711%, Training Loss: 0.3983%\n",
      "Epoch [261/300], Step [20/23], Training Accuracy: 75.0000%, Training Loss: 0.3965%\n",
      "Epoch [261/300], Step [21/23], Training Accuracy: 75.0000%, Training Loss: 0.3965%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [261/300], Step [22/23], Training Accuracy: 74.7869%, Training Loss: 0.3967%\n",
      "Epoch [261/300], Step [23/23], Training Accuracy: 74.8436%, Training Loss: 0.3939%\n",
      "Epoch [262/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3625%\n",
      "Epoch [262/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.3822%\n",
      "Epoch [262/300], Step [3/23], Training Accuracy: 72.9167%, Training Loss: 0.3947%\n",
      "Epoch [262/300], Step [4/23], Training Accuracy: 75.7812%, Training Loss: 0.3802%\n",
      "Epoch [262/300], Step [5/23], Training Accuracy: 73.7500%, Training Loss: 0.3812%\n",
      "Epoch [262/300], Step [6/23], Training Accuracy: 74.7396%, Training Loss: 0.3820%\n",
      "Epoch [262/300], Step [7/23], Training Accuracy: 75.2232%, Training Loss: 0.3876%\n",
      "Epoch [262/300], Step [8/23], Training Accuracy: 75.7812%, Training Loss: 0.3876%\n",
      "Epoch [262/300], Step [9/23], Training Accuracy: 74.3056%, Training Loss: 0.3937%\n",
      "Epoch [262/300], Step [10/23], Training Accuracy: 74.5312%, Training Loss: 0.3926%\n",
      "Epoch [262/300], Step [11/23], Training Accuracy: 75.2841%, Training Loss: 0.3903%\n",
      "Epoch [262/300], Step [12/23], Training Accuracy: 75.0000%, Training Loss: 0.3904%\n",
      "Epoch [262/300], Step [13/23], Training Accuracy: 75.2404%, Training Loss: 0.3929%\n",
      "Epoch [262/300], Step [14/23], Training Accuracy: 75.0000%, Training Loss: 0.3923%\n",
      "Epoch [262/300], Step [15/23], Training Accuracy: 75.0000%, Training Loss: 0.3940%\n",
      "Epoch [262/300], Step [16/23], Training Accuracy: 74.8047%, Training Loss: 0.3941%\n",
      "Epoch [262/300], Step [17/23], Training Accuracy: 74.6324%, Training Loss: 0.3937%\n",
      "Epoch [262/300], Step [18/23], Training Accuracy: 74.5660%, Training Loss: 0.3938%\n",
      "Epoch [262/300], Step [19/23], Training Accuracy: 74.5888%, Training Loss: 0.3949%\n",
      "Epoch [262/300], Step [20/23], Training Accuracy: 74.7656%, Training Loss: 0.3934%\n",
      "Epoch [262/300], Step [21/23], Training Accuracy: 74.5536%, Training Loss: 0.3929%\n",
      "Epoch [262/300], Step [22/23], Training Accuracy: 74.6449%, Training Loss: 0.3917%\n",
      "Epoch [262/300], Step [23/23], Training Accuracy: 74.9131%, Training Loss: 0.3881%\n",
      "Epoch [263/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3749%\n",
      "Epoch [263/300], Step [2/23], Training Accuracy: 75.7812%, Training Loss: 0.3856%\n",
      "Epoch [263/300], Step [3/23], Training Accuracy: 73.4375%, Training Loss: 0.3948%\n",
      "Epoch [263/300], Step [4/23], Training Accuracy: 77.3438%, Training Loss: 0.3770%\n",
      "Epoch [263/300], Step [5/23], Training Accuracy: 75.9375%, Training Loss: 0.3781%\n",
      "Epoch [263/300], Step [6/23], Training Accuracy: 75.7812%, Training Loss: 0.3801%\n",
      "Epoch [263/300], Step [7/23], Training Accuracy: 75.8929%, Training Loss: 0.3855%\n",
      "Epoch [263/300], Step [8/23], Training Accuracy: 76.1719%, Training Loss: 0.3847%\n",
      "Epoch [263/300], Step [9/23], Training Accuracy: 75.3472%, Training Loss: 0.3880%\n",
      "Epoch [263/300], Step [10/23], Training Accuracy: 74.8438%, Training Loss: 0.3862%\n",
      "Epoch [263/300], Step [11/23], Training Accuracy: 74.7159%, Training Loss: 0.3849%\n",
      "Epoch [263/300], Step [12/23], Training Accuracy: 74.6094%, Training Loss: 0.3871%\n",
      "Epoch [263/300], Step [13/23], Training Accuracy: 74.6394%, Training Loss: 0.3880%\n",
      "Epoch [263/300], Step [14/23], Training Accuracy: 75.1116%, Training Loss: 0.3850%\n",
      "Epoch [263/300], Step [15/23], Training Accuracy: 74.5833%, Training Loss: 0.3865%\n",
      "Epoch [263/300], Step [16/23], Training Accuracy: 74.3164%, Training Loss: 0.3878%\n",
      "Epoch [263/300], Step [17/23], Training Accuracy: 73.9890%, Training Loss: 0.3892%\n",
      "Epoch [263/300], Step [18/23], Training Accuracy: 73.7847%, Training Loss: 0.3891%\n",
      "Epoch [263/300], Step [19/23], Training Accuracy: 73.6842%, Training Loss: 0.3891%\n",
      "Epoch [263/300], Step [20/23], Training Accuracy: 74.1406%, Training Loss: 0.3870%\n",
      "Epoch [263/300], Step [21/23], Training Accuracy: 74.1071%, Training Loss: 0.3871%\n",
      "Epoch [263/300], Step [22/23], Training Accuracy: 74.2188%, Training Loss: 0.3858%\n",
      "Epoch [263/300], Step [23/23], Training Accuracy: 74.3572%, Training Loss: 0.3826%\n",
      "Epoch [264/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3755%\n",
      "Epoch [264/300], Step [2/23], Training Accuracy: 77.3438%, Training Loss: 0.3995%\n",
      "Epoch [264/300], Step [3/23], Training Accuracy: 75.0000%, Training Loss: 0.3962%\n",
      "Epoch [264/300], Step [4/23], Training Accuracy: 76.9531%, Training Loss: 0.3822%\n",
      "Epoch [264/300], Step [5/23], Training Accuracy: 76.2500%, Training Loss: 0.3820%\n",
      "Epoch [264/300], Step [6/23], Training Accuracy: 77.3438%, Training Loss: 0.3793%\n",
      "Epoch [264/300], Step [7/23], Training Accuracy: 77.0089%, Training Loss: 0.3843%\n",
      "Epoch [264/300], Step [8/23], Training Accuracy: 76.9531%, Training Loss: 0.3867%\n",
      "Epoch [264/300], Step [9/23], Training Accuracy: 75.6944%, Training Loss: 0.3914%\n",
      "Epoch [264/300], Step [10/23], Training Accuracy: 75.4688%, Training Loss: 0.3902%\n",
      "Epoch [264/300], Step [11/23], Training Accuracy: 75.7102%, Training Loss: 0.3902%\n",
      "Epoch [264/300], Step [12/23], Training Accuracy: 75.5208%, Training Loss: 0.3926%\n",
      "Epoch [264/300], Step [13/23], Training Accuracy: 75.0000%, Training Loss: 0.3941%\n",
      "Epoch [264/300], Step [14/23], Training Accuracy: 75.2232%, Training Loss: 0.3928%\n",
      "Epoch [264/300], Step [15/23], Training Accuracy: 74.8958%, Training Loss: 0.3946%\n",
      "Epoch [264/300], Step [16/23], Training Accuracy: 74.5117%, Training Loss: 0.3965%\n",
      "Epoch [264/300], Step [17/23], Training Accuracy: 74.4485%, Training Loss: 0.3960%\n",
      "Epoch [264/300], Step [18/23], Training Accuracy: 74.3924%, Training Loss: 0.3958%\n",
      "Epoch [264/300], Step [19/23], Training Accuracy: 74.5066%, Training Loss: 0.3953%\n",
      "Epoch [264/300], Step [20/23], Training Accuracy: 74.9219%, Training Loss: 0.3935%\n",
      "Epoch [264/300], Step [21/23], Training Accuracy: 74.6280%, Training Loss: 0.3933%\n",
      "Epoch [264/300], Step [22/23], Training Accuracy: 74.7159%, Training Loss: 0.3927%\n",
      "Epoch [264/300], Step [23/23], Training Accuracy: 74.8436%, Training Loss: 0.3894%\n",
      "Epoch [265/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3677%\n",
      "Epoch [265/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.4029%\n",
      "Epoch [265/300], Step [3/23], Training Accuracy: 70.8333%, Training Loss: 0.4142%\n",
      "Epoch [265/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.3986%\n",
      "Epoch [265/300], Step [5/23], Training Accuracy: 73.7500%, Training Loss: 0.3936%\n",
      "Epoch [265/300], Step [6/23], Training Accuracy: 74.7396%, Training Loss: 0.3930%\n",
      "Epoch [265/300], Step [7/23], Training Accuracy: 74.3304%, Training Loss: 0.3991%\n",
      "Epoch [265/300], Step [8/23], Training Accuracy: 74.6094%, Training Loss: 0.3978%\n",
      "Epoch [265/300], Step [9/23], Training Accuracy: 73.9583%, Training Loss: 0.3989%\n",
      "Epoch [265/300], Step [10/23], Training Accuracy: 73.7500%, Training Loss: 0.3972%\n",
      "Epoch [265/300], Step [11/23], Training Accuracy: 73.8636%, Training Loss: 0.3980%\n",
      "Epoch [265/300], Step [12/23], Training Accuracy: 73.9583%, Training Loss: 0.3991%\n",
      "Epoch [265/300], Step [13/23], Training Accuracy: 74.1587%, Training Loss: 0.3991%\n",
      "Epoch [265/300], Step [14/23], Training Accuracy: 74.5536%, Training Loss: 0.3976%\n",
      "Epoch [265/300], Step [15/23], Training Accuracy: 74.4792%, Training Loss: 0.4006%\n",
      "Epoch [265/300], Step [16/23], Training Accuracy: 74.1211%, Training Loss: 0.3999%\n",
      "Epoch [265/300], Step [17/23], Training Accuracy: 74.1728%, Training Loss: 0.3999%\n",
      "Epoch [265/300], Step [18/23], Training Accuracy: 74.3056%, Training Loss: 0.4002%\n",
      "Epoch [265/300], Step [19/23], Training Accuracy: 74.5888%, Training Loss: 0.3996%\n",
      "Epoch [265/300], Step [20/23], Training Accuracy: 74.8438%, Training Loss: 0.3985%\n",
      "Epoch [265/300], Step [21/23], Training Accuracy: 74.8512%, Training Loss: 0.3985%\n",
      "Epoch [265/300], Step [22/23], Training Accuracy: 75.1420%, Training Loss: 0.3976%\n",
      "Epoch [265/300], Step [23/23], Training Accuracy: 75.1216%, Training Loss: 0.3942%\n",
      "Epoch [266/300], Step [1/23], Training Accuracy: 73.4375%, Training Loss: 0.3844%\n",
      "Epoch [266/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.4003%\n",
      "Epoch [266/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.3973%\n",
      "Epoch [266/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.3816%\n",
      "Epoch [266/300], Step [5/23], Training Accuracy: 72.8125%, Training Loss: 0.3852%\n",
      "Epoch [266/300], Step [6/23], Training Accuracy: 74.2188%, Training Loss: 0.3845%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [266/300], Step [7/23], Training Accuracy: 74.3304%, Training Loss: 0.3923%\n",
      "Epoch [266/300], Step [8/23], Training Accuracy: 74.4141%, Training Loss: 0.3927%\n",
      "Epoch [266/300], Step [9/23], Training Accuracy: 73.4375%, Training Loss: 0.3954%\n",
      "Epoch [266/300], Step [10/23], Training Accuracy: 74.2188%, Training Loss: 0.3957%\n",
      "Epoch [266/300], Step [11/23], Training Accuracy: 74.2898%, Training Loss: 0.3938%\n",
      "Epoch [266/300], Step [12/23], Training Accuracy: 74.3490%, Training Loss: 0.3940%\n",
      "Epoch [266/300], Step [13/23], Training Accuracy: 74.5192%, Training Loss: 0.3962%\n",
      "Epoch [266/300], Step [14/23], Training Accuracy: 74.7768%, Training Loss: 0.3938%\n",
      "Epoch [266/300], Step [15/23], Training Accuracy: 74.3750%, Training Loss: 0.3966%\n",
      "Epoch [266/300], Step [16/23], Training Accuracy: 74.3164%, Training Loss: 0.3960%\n",
      "Epoch [266/300], Step [17/23], Training Accuracy: 74.2647%, Training Loss: 0.3970%\n",
      "Epoch [266/300], Step [18/23], Training Accuracy: 74.3924%, Training Loss: 0.3970%\n",
      "Epoch [266/300], Step [19/23], Training Accuracy: 74.5066%, Training Loss: 0.3964%\n",
      "Epoch [266/300], Step [20/23], Training Accuracy: 74.7656%, Training Loss: 0.3947%\n",
      "Epoch [266/300], Step [21/23], Training Accuracy: 74.7768%, Training Loss: 0.3957%\n",
      "Epoch [266/300], Step [22/23], Training Accuracy: 75.0000%, Training Loss: 0.3953%\n",
      "Epoch [266/300], Step [23/23], Training Accuracy: 75.1216%, Training Loss: 0.3923%\n",
      "Epoch [267/300], Step [1/23], Training Accuracy: 81.2500%, Training Loss: 0.3798%\n",
      "Epoch [267/300], Step [2/23], Training Accuracy: 80.4688%, Training Loss: 0.4017%\n",
      "Epoch [267/300], Step [3/23], Training Accuracy: 75.0000%, Training Loss: 0.4101%\n",
      "Epoch [267/300], Step [4/23], Training Accuracy: 76.5625%, Training Loss: 0.3907%\n",
      "Epoch [267/300], Step [5/23], Training Accuracy: 75.9375%, Training Loss: 0.3891%\n",
      "Epoch [267/300], Step [6/23], Training Accuracy: 75.7812%, Training Loss: 0.3924%\n",
      "Epoch [267/300], Step [7/23], Training Accuracy: 75.8929%, Training Loss: 0.3965%\n",
      "Epoch [267/300], Step [8/23], Training Accuracy: 75.7812%, Training Loss: 0.3971%\n",
      "Epoch [267/300], Step [9/23], Training Accuracy: 75.0000%, Training Loss: 0.3986%\n",
      "Epoch [267/300], Step [10/23], Training Accuracy: 75.3125%, Training Loss: 0.3965%\n",
      "Epoch [267/300], Step [11/23], Training Accuracy: 75.2841%, Training Loss: 0.3962%\n",
      "Epoch [267/300], Step [12/23], Training Accuracy: 75.7812%, Training Loss: 0.3949%\n",
      "Epoch [267/300], Step [13/23], Training Accuracy: 75.0000%, Training Loss: 0.3990%\n",
      "Epoch [267/300], Step [14/23], Training Accuracy: 75.3348%, Training Loss: 0.3967%\n",
      "Epoch [267/300], Step [15/23], Training Accuracy: 74.8958%, Training Loss: 0.3993%\n",
      "Epoch [267/300], Step [16/23], Training Accuracy: 74.8047%, Training Loss: 0.3997%\n",
      "Epoch [267/300], Step [17/23], Training Accuracy: 74.6324%, Training Loss: 0.3984%\n",
      "Epoch [267/300], Step [18/23], Training Accuracy: 74.7396%, Training Loss: 0.3979%\n",
      "Epoch [267/300], Step [19/23], Training Accuracy: 74.6711%, Training Loss: 0.3975%\n",
      "Epoch [267/300], Step [20/23], Training Accuracy: 74.8438%, Training Loss: 0.3959%\n",
      "Epoch [267/300], Step [21/23], Training Accuracy: 74.8512%, Training Loss: 0.3963%\n",
      "Epoch [267/300], Step [22/23], Training Accuracy: 74.9290%, Training Loss: 0.3963%\n",
      "Epoch [267/300], Step [23/23], Training Accuracy: 74.9826%, Training Loss: 0.3924%\n",
      "Epoch [268/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3708%\n",
      "Epoch [268/300], Step [2/23], Training Accuracy: 75.7812%, Training Loss: 0.3988%\n",
      "Epoch [268/300], Step [3/23], Training Accuracy: 72.3958%, Training Loss: 0.4045%\n",
      "Epoch [268/300], Step [4/23], Training Accuracy: 75.3906%, Training Loss: 0.3910%\n",
      "Epoch [268/300], Step [5/23], Training Accuracy: 74.3750%, Training Loss: 0.3958%\n",
      "Epoch [268/300], Step [6/23], Training Accuracy: 75.0000%, Training Loss: 0.3922%\n",
      "Epoch [268/300], Step [7/23], Training Accuracy: 74.1071%, Training Loss: 0.3992%\n",
      "Epoch [268/300], Step [8/23], Training Accuracy: 75.0000%, Training Loss: 0.3991%\n",
      "Epoch [268/300], Step [9/23], Training Accuracy: 73.6111%, Training Loss: 0.4053%\n",
      "Epoch [268/300], Step [10/23], Training Accuracy: 72.9688%, Training Loss: 0.4052%\n",
      "Epoch [268/300], Step [11/23], Training Accuracy: 73.7216%, Training Loss: 0.4057%\n",
      "Epoch [268/300], Step [12/23], Training Accuracy: 73.9583%, Training Loss: 0.4050%\n",
      "Epoch [268/300], Step [13/23], Training Accuracy: 73.5577%, Training Loss: 0.4064%\n",
      "Epoch [268/300], Step [14/23], Training Accuracy: 73.4375%, Training Loss: 0.4052%\n",
      "Epoch [268/300], Step [15/23], Training Accuracy: 72.8125%, Training Loss: 0.4083%\n",
      "Epoch [268/300], Step [16/23], Training Accuracy: 72.7539%, Training Loss: 0.4075%\n",
      "Epoch [268/300], Step [17/23], Training Accuracy: 72.8860%, Training Loss: 0.4067%\n",
      "Epoch [268/300], Step [18/23], Training Accuracy: 72.8299%, Training Loss: 0.4066%\n",
      "Epoch [268/300], Step [19/23], Training Accuracy: 73.1086%, Training Loss: 0.4047%\n",
      "Epoch [268/300], Step [20/23], Training Accuracy: 73.4375%, Training Loss: 0.4022%\n",
      "Epoch [268/300], Step [21/23], Training Accuracy: 73.4375%, Training Loss: 0.4015%\n",
      "Epoch [268/300], Step [22/23], Training Accuracy: 73.3665%, Training Loss: 0.4003%\n",
      "Epoch [268/300], Step [23/23], Training Accuracy: 73.3843%, Training Loss: 0.3974%\n",
      "Epoch [269/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3929%\n",
      "Epoch [269/300], Step [2/23], Training Accuracy: 78.1250%, Training Loss: 0.3854%\n",
      "Epoch [269/300], Step [3/23], Training Accuracy: 75.0000%, Training Loss: 0.3989%\n",
      "Epoch [269/300], Step [4/23], Training Accuracy: 77.3438%, Training Loss: 0.3871%\n",
      "Epoch [269/300], Step [5/23], Training Accuracy: 76.5625%, Training Loss: 0.3861%\n",
      "Epoch [269/300], Step [6/23], Training Accuracy: 78.6458%, Training Loss: 0.3823%\n",
      "Epoch [269/300], Step [7/23], Training Accuracy: 77.9018%, Training Loss: 0.3885%\n",
      "Epoch [269/300], Step [8/23], Training Accuracy: 78.5156%, Training Loss: 0.3846%\n",
      "Epoch [269/300], Step [9/23], Training Accuracy: 77.0833%, Training Loss: 0.3929%\n",
      "Epoch [269/300], Step [10/23], Training Accuracy: 76.7188%, Training Loss: 0.3912%\n",
      "Epoch [269/300], Step [11/23], Training Accuracy: 76.7045%, Training Loss: 0.3885%\n",
      "Epoch [269/300], Step [12/23], Training Accuracy: 76.3021%, Training Loss: 0.3898%\n",
      "Epoch [269/300], Step [13/23], Training Accuracy: 75.7212%, Training Loss: 0.3919%\n",
      "Epoch [269/300], Step [14/23], Training Accuracy: 76.0045%, Training Loss: 0.3907%\n",
      "Epoch [269/300], Step [15/23], Training Accuracy: 75.8333%, Training Loss: 0.3936%\n",
      "Epoch [269/300], Step [16/23], Training Accuracy: 75.5859%, Training Loss: 0.3946%\n",
      "Epoch [269/300], Step [17/23], Training Accuracy: 75.4596%, Training Loss: 0.3942%\n",
      "Epoch [269/300], Step [18/23], Training Accuracy: 75.3472%, Training Loss: 0.3951%\n",
      "Epoch [269/300], Step [19/23], Training Accuracy: 75.8224%, Training Loss: 0.3933%\n",
      "Epoch [269/300], Step [20/23], Training Accuracy: 75.8594%, Training Loss: 0.3923%\n",
      "Epoch [269/300], Step [21/23], Training Accuracy: 75.4464%, Training Loss: 0.3925%\n",
      "Epoch [269/300], Step [22/23], Training Accuracy: 75.4261%, Training Loss: 0.3924%\n",
      "Epoch [269/300], Step [23/23], Training Accuracy: 75.6081%, Training Loss: 0.3891%\n",
      "Epoch [270/300], Step [1/23], Training Accuracy: 68.7500%, Training Loss: 0.4064%\n",
      "Epoch [270/300], Step [2/23], Training Accuracy: 71.8750%, Training Loss: 0.3999%\n",
      "Epoch [270/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.3986%\n",
      "Epoch [270/300], Step [4/23], Training Accuracy: 76.1719%, Training Loss: 0.3810%\n",
      "Epoch [270/300], Step [5/23], Training Accuracy: 74.6875%, Training Loss: 0.3821%\n",
      "Epoch [270/300], Step [6/23], Training Accuracy: 75.7812%, Training Loss: 0.3830%\n",
      "Epoch [270/300], Step [7/23], Training Accuracy: 75.4464%, Training Loss: 0.3899%\n",
      "Epoch [270/300], Step [8/23], Training Accuracy: 75.1953%, Training Loss: 0.3916%\n",
      "Epoch [270/300], Step [9/23], Training Accuracy: 73.7847%, Training Loss: 0.3954%\n",
      "Epoch [270/300], Step [10/23], Training Accuracy: 73.7500%, Training Loss: 0.3942%\n",
      "Epoch [270/300], Step [11/23], Training Accuracy: 74.0057%, Training Loss: 0.3928%\n",
      "Epoch [270/300], Step [12/23], Training Accuracy: 74.2188%, Training Loss: 0.3934%\n",
      "Epoch [270/300], Step [13/23], Training Accuracy: 74.2788%, Training Loss: 0.3945%\n",
      "Epoch [270/300], Step [14/23], Training Accuracy: 74.2188%, Training Loss: 0.3939%\n",
      "Epoch [270/300], Step [15/23], Training Accuracy: 73.6458%, Training Loss: 0.3982%\n",
      "Epoch [270/300], Step [16/23], Training Accuracy: 73.4375%, Training Loss: 0.3992%\n",
      "Epoch [270/300], Step [17/23], Training Accuracy: 73.4375%, Training Loss: 0.3980%\n",
      "Epoch [270/300], Step [18/23], Training Accuracy: 73.6979%, Training Loss: 0.3968%\n",
      "Epoch [270/300], Step [19/23], Training Accuracy: 73.6020%, Training Loss: 0.3954%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [270/300], Step [20/23], Training Accuracy: 73.8281%, Training Loss: 0.3939%\n",
      "Epoch [270/300], Step [21/23], Training Accuracy: 73.5863%, Training Loss: 0.3945%\n",
      "Epoch [270/300], Step [22/23], Training Accuracy: 73.3665%, Training Loss: 0.3940%\n",
      "Epoch [270/300], Step [23/23], Training Accuracy: 73.4538%, Training Loss: 0.3907%\n",
      "Epoch [271/300], Step [1/23], Training Accuracy: 71.8750%, Training Loss: 0.3949%\n",
      "Epoch [271/300], Step [2/23], Training Accuracy: 70.3125%, Training Loss: 0.4145%\n",
      "Epoch [271/300], Step [3/23], Training Accuracy: 70.8333%, Training Loss: 0.4057%\n",
      "Epoch [271/300], Step [4/23], Training Accuracy: 73.4375%, Training Loss: 0.3917%\n",
      "Epoch [271/300], Step [5/23], Training Accuracy: 71.5625%, Training Loss: 0.3949%\n",
      "Epoch [271/300], Step [6/23], Training Accuracy: 72.9167%, Training Loss: 0.3948%\n",
      "Epoch [271/300], Step [7/23], Training Accuracy: 72.7679%, Training Loss: 0.3998%\n",
      "Epoch [271/300], Step [8/23], Training Accuracy: 72.8516%, Training Loss: 0.3982%\n",
      "Epoch [271/300], Step [9/23], Training Accuracy: 72.2222%, Training Loss: 0.4006%\n",
      "Epoch [271/300], Step [10/23], Training Accuracy: 72.9688%, Training Loss: 0.3984%\n",
      "Epoch [271/300], Step [11/23], Training Accuracy: 73.2955%, Training Loss: 0.3974%\n",
      "Epoch [271/300], Step [12/23], Training Accuracy: 73.3073%, Training Loss: 0.3991%\n",
      "Epoch [271/300], Step [13/23], Training Accuracy: 73.3173%, Training Loss: 0.4004%\n",
      "Epoch [271/300], Step [14/23], Training Accuracy: 73.6607%, Training Loss: 0.3969%\n",
      "Epoch [271/300], Step [15/23], Training Accuracy: 72.7083%, Training Loss: 0.4010%\n",
      "Epoch [271/300], Step [16/23], Training Accuracy: 72.5586%, Training Loss: 0.4013%\n",
      "Epoch [271/300], Step [17/23], Training Accuracy: 72.8860%, Training Loss: 0.3997%\n",
      "Epoch [271/300], Step [18/23], Training Accuracy: 72.8299%, Training Loss: 0.3990%\n",
      "Epoch [271/300], Step [19/23], Training Accuracy: 72.9441%, Training Loss: 0.3989%\n",
      "Epoch [271/300], Step [20/23], Training Accuracy: 73.2031%, Training Loss: 0.3970%\n",
      "Epoch [271/300], Step [21/23], Training Accuracy: 73.1399%, Training Loss: 0.3970%\n",
      "Epoch [271/300], Step [22/23], Training Accuracy: 73.3665%, Training Loss: 0.3961%\n",
      "Epoch [271/300], Step [23/23], Training Accuracy: 73.6623%, Training Loss: 0.3923%\n",
      "Epoch [272/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3555%\n",
      "Epoch [272/300], Step [2/23], Training Accuracy: 72.6562%, Training Loss: 0.3857%\n",
      "Epoch [272/300], Step [3/23], Training Accuracy: 70.3125%, Training Loss: 0.4007%\n",
      "Epoch [272/300], Step [4/23], Training Accuracy: 71.8750%, Training Loss: 0.3868%\n",
      "Epoch [272/300], Step [5/23], Training Accuracy: 72.8125%, Training Loss: 0.3852%\n",
      "Epoch [272/300], Step [6/23], Training Accuracy: 74.7396%, Training Loss: 0.3823%\n",
      "Epoch [272/300], Step [7/23], Training Accuracy: 75.2232%, Training Loss: 0.3871%\n",
      "Epoch [272/300], Step [8/23], Training Accuracy: 75.1953%, Training Loss: 0.3913%\n",
      "Epoch [272/300], Step [9/23], Training Accuracy: 73.6111%, Training Loss: 0.3981%\n",
      "Epoch [272/300], Step [10/23], Training Accuracy: 73.9062%, Training Loss: 0.3977%\n",
      "Epoch [272/300], Step [11/23], Training Accuracy: 73.8636%, Training Loss: 0.3980%\n",
      "Epoch [272/300], Step [12/23], Training Accuracy: 74.3490%, Training Loss: 0.3977%\n",
      "Epoch [272/300], Step [13/23], Training Accuracy: 74.3990%, Training Loss: 0.3978%\n",
      "Epoch [272/300], Step [14/23], Training Accuracy: 74.7768%, Training Loss: 0.3958%\n",
      "Epoch [272/300], Step [15/23], Training Accuracy: 74.5833%, Training Loss: 0.3974%\n",
      "Epoch [272/300], Step [16/23], Training Accuracy: 74.7070%, Training Loss: 0.3969%\n",
      "Epoch [272/300], Step [17/23], Training Accuracy: 74.7243%, Training Loss: 0.3958%\n",
      "Epoch [272/300], Step [18/23], Training Accuracy: 74.9132%, Training Loss: 0.3950%\n",
      "Epoch [272/300], Step [19/23], Training Accuracy: 75.1645%, Training Loss: 0.3947%\n",
      "Epoch [272/300], Step [20/23], Training Accuracy: 75.0781%, Training Loss: 0.3939%\n",
      "Epoch [272/300], Step [21/23], Training Accuracy: 74.7024%, Training Loss: 0.3933%\n",
      "Epoch [272/300], Step [22/23], Training Accuracy: 74.8580%, Training Loss: 0.3920%\n",
      "Epoch [272/300], Step [23/23], Training Accuracy: 74.8436%, Training Loss: 0.3887%\n",
      "Epoch [273/300], Step [1/23], Training Accuracy: 84.3750%, Training Loss: 0.3616%\n",
      "Epoch [273/300], Step [2/23], Training Accuracy: 79.6875%, Training Loss: 0.3885%\n",
      "Epoch [273/300], Step [3/23], Training Accuracy: 77.0833%, Training Loss: 0.3940%\n",
      "Epoch [273/300], Step [4/23], Training Accuracy: 78.9062%, Training Loss: 0.3826%\n",
      "Epoch [273/300], Step [5/23], Training Accuracy: 77.5000%, Training Loss: 0.3835%\n",
      "Epoch [273/300], Step [6/23], Training Accuracy: 77.3438%, Training Loss: 0.3820%\n",
      "Epoch [273/300], Step [7/23], Training Accuracy: 77.2321%, Training Loss: 0.3895%\n",
      "Epoch [273/300], Step [8/23], Training Accuracy: 76.7578%, Training Loss: 0.3900%\n",
      "Epoch [273/300], Step [9/23], Training Accuracy: 76.0417%, Training Loss: 0.3949%\n",
      "Epoch [273/300], Step [10/23], Training Accuracy: 76.4062%, Training Loss: 0.3950%\n",
      "Epoch [273/300], Step [11/23], Training Accuracy: 75.8523%, Training Loss: 0.3936%\n",
      "Epoch [273/300], Step [12/23], Training Accuracy: 76.0417%, Training Loss: 0.3941%\n",
      "Epoch [273/300], Step [13/23], Training Accuracy: 75.8413%, Training Loss: 0.3981%\n",
      "Epoch [273/300], Step [14/23], Training Accuracy: 76.6741%, Training Loss: 0.3955%\n",
      "Epoch [273/300], Step [15/23], Training Accuracy: 76.4583%, Training Loss: 0.3979%\n",
      "Epoch [273/300], Step [16/23], Training Accuracy: 76.2695%, Training Loss: 0.3984%\n",
      "Epoch [273/300], Step [17/23], Training Accuracy: 76.1029%, Training Loss: 0.3988%\n",
      "Epoch [273/300], Step [18/23], Training Accuracy: 75.9549%, Training Loss: 0.3994%\n",
      "Epoch [273/300], Step [19/23], Training Accuracy: 76.0691%, Training Loss: 0.3989%\n",
      "Epoch [273/300], Step [20/23], Training Accuracy: 76.4062%, Training Loss: 0.3976%\n",
      "Epoch [273/300], Step [21/23], Training Accuracy: 76.3393%, Training Loss: 0.3968%\n",
      "Epoch [273/300], Step [22/23], Training Accuracy: 76.2784%, Training Loss: 0.3967%\n",
      "Epoch [273/300], Step [23/23], Training Accuracy: 76.1640%, Training Loss: 0.3935%\n",
      "Epoch [274/300], Step [1/23], Training Accuracy: 81.2500%, Training Loss: 0.3858%\n",
      "Epoch [274/300], Step [2/23], Training Accuracy: 78.1250%, Training Loss: 0.3996%\n",
      "Epoch [274/300], Step [3/23], Training Accuracy: 73.4375%, Training Loss: 0.4088%\n",
      "Epoch [274/300], Step [4/23], Training Accuracy: 76.1719%, Training Loss: 0.3943%\n",
      "Epoch [274/300], Step [5/23], Training Accuracy: 74.3750%, Training Loss: 0.3985%\n",
      "Epoch [274/300], Step [6/23], Training Accuracy: 75.0000%, Training Loss: 0.3967%\n",
      "Epoch [274/300], Step [7/23], Training Accuracy: 74.5536%, Training Loss: 0.3996%\n",
      "Epoch [274/300], Step [8/23], Training Accuracy: 75.0000%, Training Loss: 0.4010%\n",
      "Epoch [274/300], Step [9/23], Training Accuracy: 74.1319%, Training Loss: 0.4036%\n",
      "Epoch [274/300], Step [10/23], Training Accuracy: 73.2812%, Training Loss: 0.4024%\n",
      "Epoch [274/300], Step [11/23], Training Accuracy: 73.0114%, Training Loss: 0.4012%\n",
      "Epoch [274/300], Step [12/23], Training Accuracy: 73.5677%, Training Loss: 0.4000%\n",
      "Epoch [274/300], Step [13/23], Training Accuracy: 73.5577%, Training Loss: 0.4002%\n",
      "Epoch [274/300], Step [14/23], Training Accuracy: 73.6607%, Training Loss: 0.3961%\n",
      "Epoch [274/300], Step [15/23], Training Accuracy: 73.0208%, Training Loss: 0.4013%\n",
      "Epoch [274/300], Step [16/23], Training Accuracy: 72.5586%, Training Loss: 0.4020%\n",
      "Epoch [274/300], Step [17/23], Training Accuracy: 72.5184%, Training Loss: 0.4015%\n",
      "Epoch [274/300], Step [18/23], Training Accuracy: 72.5694%, Training Loss: 0.4011%\n",
      "Epoch [274/300], Step [19/23], Training Accuracy: 72.5329%, Training Loss: 0.3999%\n",
      "Epoch [274/300], Step [20/23], Training Accuracy: 72.6562%, Training Loss: 0.3990%\n",
      "Epoch [274/300], Step [21/23], Training Accuracy: 72.8423%, Training Loss: 0.3983%\n",
      "Epoch [274/300], Step [22/23], Training Accuracy: 73.0824%, Training Loss: 0.3965%\n",
      "Epoch [274/300], Step [23/23], Training Accuracy: 73.1063%, Training Loss: 0.3928%\n",
      "Epoch [275/300], Step [1/23], Training Accuracy: 82.8125%, Training Loss: 0.3626%\n",
      "Epoch [275/300], Step [2/23], Training Accuracy: 78.1250%, Training Loss: 0.3872%\n",
      "Epoch [275/300], Step [3/23], Training Accuracy: 74.4792%, Training Loss: 0.4000%\n",
      "Epoch [275/300], Step [4/23], Training Accuracy: 75.7812%, Training Loss: 0.3909%\n",
      "Epoch [275/300], Step [5/23], Training Accuracy: 74.6875%, Training Loss: 0.3879%\n",
      "Epoch [275/300], Step [6/23], Training Accuracy: 75.7812%, Training Loss: 0.3911%\n",
      "Epoch [275/300], Step [7/23], Training Accuracy: 76.1161%, Training Loss: 0.3940%\n",
      "Epoch [275/300], Step [8/23], Training Accuracy: 75.1953%, Training Loss: 0.3979%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [275/300], Step [9/23], Training Accuracy: 74.1319%, Training Loss: 0.4051%\n",
      "Epoch [275/300], Step [10/23], Training Accuracy: 73.7500%, Training Loss: 0.4015%\n",
      "Epoch [275/300], Step [11/23], Training Accuracy: 73.4375%, Training Loss: 0.4000%\n",
      "Epoch [275/300], Step [12/23], Training Accuracy: 73.3073%, Training Loss: 0.4000%\n",
      "Epoch [275/300], Step [13/23], Training Accuracy: 73.1971%, Training Loss: 0.4002%\n",
      "Epoch [275/300], Step [14/23], Training Accuracy: 73.7723%, Training Loss: 0.3967%\n",
      "Epoch [275/300], Step [15/23], Training Accuracy: 73.6458%, Training Loss: 0.3983%\n",
      "Epoch [275/300], Step [16/23], Training Accuracy: 73.2422%, Training Loss: 0.4009%\n",
      "Epoch [275/300], Step [17/23], Training Accuracy: 73.2537%, Training Loss: 0.3997%\n",
      "Epoch [275/300], Step [18/23], Training Accuracy: 73.5243%, Training Loss: 0.4005%\n",
      "Epoch [275/300], Step [19/23], Training Accuracy: 73.2730%, Training Loss: 0.3999%\n",
      "Epoch [275/300], Step [20/23], Training Accuracy: 73.3594%, Training Loss: 0.3983%\n",
      "Epoch [275/300], Step [21/23], Training Accuracy: 73.1399%, Training Loss: 0.3984%\n",
      "Epoch [275/300], Step [22/23], Training Accuracy: 73.3665%, Training Loss: 0.3971%\n",
      "Epoch [275/300], Step [23/23], Training Accuracy: 73.5233%, Training Loss: 0.3934%\n",
      "Epoch [276/300], Step [1/23], Training Accuracy: 81.2500%, Training Loss: 0.3571%\n",
      "Epoch [276/300], Step [2/23], Training Accuracy: 78.9062%, Training Loss: 0.3770%\n",
      "Epoch [276/300], Step [3/23], Training Accuracy: 75.5208%, Training Loss: 0.3872%\n",
      "Epoch [276/300], Step [4/23], Training Accuracy: 78.1250%, Training Loss: 0.3722%\n",
      "Epoch [276/300], Step [5/23], Training Accuracy: 77.1875%, Training Loss: 0.3733%\n",
      "Epoch [276/300], Step [6/23], Training Accuracy: 77.3438%, Training Loss: 0.3734%\n",
      "Epoch [276/300], Step [7/23], Training Accuracy: 77.6786%, Training Loss: 0.3773%\n",
      "Epoch [276/300], Step [8/23], Training Accuracy: 76.9531%, Training Loss: 0.3810%\n",
      "Epoch [276/300], Step [9/23], Training Accuracy: 76.0417%, Training Loss: 0.3898%\n",
      "Epoch [276/300], Step [10/23], Training Accuracy: 76.4062%, Training Loss: 0.3874%\n",
      "Epoch [276/300], Step [11/23], Training Accuracy: 76.5625%, Training Loss: 0.3868%\n",
      "Epoch [276/300], Step [12/23], Training Accuracy: 76.1719%, Training Loss: 0.3865%\n",
      "Epoch [276/300], Step [13/23], Training Accuracy: 75.6010%, Training Loss: 0.3880%\n",
      "Epoch [276/300], Step [14/23], Training Accuracy: 76.1161%, Training Loss: 0.3859%\n",
      "Epoch [276/300], Step [15/23], Training Accuracy: 75.6250%, Training Loss: 0.3895%\n",
      "Epoch [276/300], Step [16/23], Training Accuracy: 75.2930%, Training Loss: 0.3897%\n",
      "Epoch [276/300], Step [17/23], Training Accuracy: 74.8162%, Training Loss: 0.3916%\n",
      "Epoch [276/300], Step [18/23], Training Accuracy: 74.4792%, Training Loss: 0.3925%\n",
      "Epoch [276/300], Step [19/23], Training Accuracy: 74.5888%, Training Loss: 0.3928%\n",
      "Epoch [276/300], Step [20/23], Training Accuracy: 74.6875%, Training Loss: 0.3915%\n",
      "Epoch [276/300], Step [21/23], Training Accuracy: 74.4048%, Training Loss: 0.3915%\n",
      "Epoch [276/300], Step [22/23], Training Accuracy: 74.6449%, Training Loss: 0.3905%\n",
      "Epoch [276/300], Step [23/23], Training Accuracy: 74.8436%, Training Loss: 0.3879%\n",
      "Epoch [277/300], Step [1/23], Training Accuracy: 84.3750%, Training Loss: 0.3585%\n",
      "Epoch [277/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3860%\n",
      "Epoch [277/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.3933%\n",
      "Epoch [277/300], Step [4/23], Training Accuracy: 74.2188%, Training Loss: 0.3832%\n",
      "Epoch [277/300], Step [5/23], Training Accuracy: 74.0625%, Training Loss: 0.3824%\n",
      "Epoch [277/300], Step [6/23], Training Accuracy: 73.6979%, Training Loss: 0.3877%\n",
      "Epoch [277/300], Step [7/23], Training Accuracy: 74.7768%, Training Loss: 0.3932%\n",
      "Epoch [277/300], Step [8/23], Training Accuracy: 75.3906%, Training Loss: 0.3916%\n",
      "Epoch [277/300], Step [9/23], Training Accuracy: 74.1319%, Training Loss: 0.3954%\n",
      "Epoch [277/300], Step [10/23], Training Accuracy: 74.0625%, Training Loss: 0.3960%\n",
      "Epoch [277/300], Step [11/23], Training Accuracy: 73.8636%, Training Loss: 0.3956%\n",
      "Epoch [277/300], Step [12/23], Training Accuracy: 73.8281%, Training Loss: 0.3956%\n",
      "Epoch [277/300], Step [13/23], Training Accuracy: 73.4375%, Training Loss: 0.3972%\n",
      "Epoch [277/300], Step [14/23], Training Accuracy: 73.6607%, Training Loss: 0.3953%\n",
      "Epoch [277/300], Step [15/23], Training Accuracy: 73.2292%, Training Loss: 0.3975%\n",
      "Epoch [277/300], Step [16/23], Training Accuracy: 73.2422%, Training Loss: 0.3992%\n",
      "Epoch [277/300], Step [17/23], Training Accuracy: 73.4375%, Training Loss: 0.3996%\n",
      "Epoch [277/300], Step [18/23], Training Accuracy: 73.7847%, Training Loss: 0.3990%\n",
      "Epoch [277/300], Step [19/23], Training Accuracy: 73.7664%, Training Loss: 0.3972%\n",
      "Epoch [277/300], Step [20/23], Training Accuracy: 73.9062%, Training Loss: 0.3950%\n",
      "Epoch [277/300], Step [21/23], Training Accuracy: 74.1815%, Training Loss: 0.3942%\n",
      "Epoch [277/300], Step [22/23], Training Accuracy: 74.0767%, Training Loss: 0.3939%\n",
      "Epoch [277/300], Step [23/23], Training Accuracy: 74.3572%, Training Loss: 0.3904%\n",
      "Epoch [278/300], Step [1/23], Training Accuracy: 67.1875%, Training Loss: 0.4054%\n",
      "Epoch [278/300], Step [2/23], Training Accuracy: 69.5312%, Training Loss: 0.4147%\n",
      "Epoch [278/300], Step [3/23], Training Accuracy: 69.7917%, Training Loss: 0.4103%\n",
      "Epoch [278/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.3917%\n",
      "Epoch [278/300], Step [5/23], Training Accuracy: 72.1875%, Training Loss: 0.3932%\n",
      "Epoch [278/300], Step [6/23], Training Accuracy: 72.9167%, Training Loss: 0.4003%\n",
      "Epoch [278/300], Step [7/23], Training Accuracy: 73.2143%, Training Loss: 0.4010%\n",
      "Epoch [278/300], Step [8/23], Training Accuracy: 74.0234%, Training Loss: 0.4017%\n",
      "Epoch [278/300], Step [9/23], Training Accuracy: 73.2639%, Training Loss: 0.4058%\n",
      "Epoch [278/300], Step [10/23], Training Accuracy: 73.1250%, Training Loss: 0.4059%\n",
      "Epoch [278/300], Step [11/23], Training Accuracy: 73.8636%, Training Loss: 0.4044%\n",
      "Epoch [278/300], Step [12/23], Training Accuracy: 74.0885%, Training Loss: 0.4031%\n",
      "Epoch [278/300], Step [13/23], Training Accuracy: 73.7981%, Training Loss: 0.4055%\n",
      "Epoch [278/300], Step [14/23], Training Accuracy: 74.1071%, Training Loss: 0.4028%\n",
      "Epoch [278/300], Step [15/23], Training Accuracy: 73.6458%, Training Loss: 0.4064%\n",
      "Epoch [278/300], Step [16/23], Training Accuracy: 73.2422%, Training Loss: 0.4073%\n",
      "Epoch [278/300], Step [17/23], Training Accuracy: 73.4375%, Training Loss: 0.4061%\n",
      "Epoch [278/300], Step [18/23], Training Accuracy: 73.7847%, Training Loss: 0.4054%\n",
      "Epoch [278/300], Step [19/23], Training Accuracy: 73.8487%, Training Loss: 0.4046%\n",
      "Epoch [278/300], Step [20/23], Training Accuracy: 73.9062%, Training Loss: 0.4032%\n",
      "Epoch [278/300], Step [21/23], Training Accuracy: 73.5863%, Training Loss: 0.4040%\n",
      "Epoch [278/300], Step [22/23], Training Accuracy: 73.6506%, Training Loss: 0.4031%\n",
      "Epoch [278/300], Step [23/23], Training Accuracy: 73.6623%, Training Loss: 0.3999%\n",
      "Epoch [279/300], Step [1/23], Training Accuracy: 79.6875%, Training Loss: 0.3769%\n",
      "Epoch [279/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.4019%\n",
      "Epoch [279/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.4080%\n",
      "Epoch [279/300], Step [4/23], Training Accuracy: 74.6094%, Training Loss: 0.3933%\n",
      "Epoch [279/300], Step [5/23], Training Accuracy: 73.1250%, Training Loss: 0.3947%\n",
      "Epoch [279/300], Step [6/23], Training Accuracy: 74.2188%, Training Loss: 0.3926%\n",
      "Epoch [279/300], Step [7/23], Training Accuracy: 74.5536%, Training Loss: 0.3995%\n",
      "Epoch [279/300], Step [8/23], Training Accuracy: 75.0000%, Training Loss: 0.3993%\n",
      "Epoch [279/300], Step [9/23], Training Accuracy: 74.4792%, Training Loss: 0.4019%\n",
      "Epoch [279/300], Step [10/23], Training Accuracy: 74.0625%, Training Loss: 0.3999%\n",
      "Epoch [279/300], Step [11/23], Training Accuracy: 74.4318%, Training Loss: 0.3982%\n",
      "Epoch [279/300], Step [12/23], Training Accuracy: 74.3490%, Training Loss: 0.3987%\n",
      "Epoch [279/300], Step [13/23], Training Accuracy: 73.5577%, Training Loss: 0.4016%\n",
      "Epoch [279/300], Step [14/23], Training Accuracy: 73.4375%, Training Loss: 0.4011%\n",
      "Epoch [279/300], Step [15/23], Training Accuracy: 73.2292%, Training Loss: 0.4027%\n",
      "Epoch [279/300], Step [16/23], Training Accuracy: 73.2422%, Training Loss: 0.4037%\n",
      "Epoch [279/300], Step [17/23], Training Accuracy: 73.4375%, Training Loss: 0.4026%\n",
      "Epoch [279/300], Step [18/23], Training Accuracy: 73.1771%, Training Loss: 0.4028%\n",
      "Epoch [279/300], Step [19/23], Training Accuracy: 73.2730%, Training Loss: 0.4020%\n",
      "Epoch [279/300], Step [20/23], Training Accuracy: 73.7500%, Training Loss: 0.3994%\n",
      "Epoch [279/300], Step [21/23], Training Accuracy: 74.1071%, Training Loss: 0.3985%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [279/300], Step [22/23], Training Accuracy: 74.0767%, Training Loss: 0.3981%\n",
      "Epoch [279/300], Step [23/23], Training Accuracy: 74.0792%, Training Loss: 0.3944%\n",
      "Epoch [280/300], Step [1/23], Training Accuracy: 71.8750%, Training Loss: 0.3828%\n",
      "Epoch [280/300], Step [2/23], Training Accuracy: 72.6562%, Training Loss: 0.3962%\n",
      "Epoch [280/300], Step [3/23], Training Accuracy: 72.3958%, Training Loss: 0.3980%\n",
      "Epoch [280/300], Step [4/23], Training Accuracy: 74.2188%, Training Loss: 0.3820%\n",
      "Epoch [280/300], Step [5/23], Training Accuracy: 73.7500%, Training Loss: 0.3856%\n",
      "Epoch [280/300], Step [6/23], Training Accuracy: 73.6979%, Training Loss: 0.3877%\n",
      "Epoch [280/300], Step [7/23], Training Accuracy: 73.4375%, Training Loss: 0.3921%\n",
      "Epoch [280/300], Step [8/23], Training Accuracy: 74.4141%, Training Loss: 0.3906%\n",
      "Epoch [280/300], Step [9/23], Training Accuracy: 74.1319%, Training Loss: 0.3956%\n",
      "Epoch [280/300], Step [10/23], Training Accuracy: 74.0625%, Training Loss: 0.3940%\n",
      "Epoch [280/300], Step [11/23], Training Accuracy: 74.1477%, Training Loss: 0.3943%\n",
      "Epoch [280/300], Step [12/23], Training Accuracy: 74.3490%, Training Loss: 0.3938%\n",
      "Epoch [280/300], Step [13/23], Training Accuracy: 73.7981%, Training Loss: 0.3965%\n",
      "Epoch [280/300], Step [14/23], Training Accuracy: 74.4420%, Training Loss: 0.3935%\n",
      "Epoch [280/300], Step [15/23], Training Accuracy: 74.4792%, Training Loss: 0.3957%\n",
      "Epoch [280/300], Step [16/23], Training Accuracy: 73.9258%, Training Loss: 0.3968%\n",
      "Epoch [280/300], Step [17/23], Training Accuracy: 73.8051%, Training Loss: 0.3966%\n",
      "Epoch [280/300], Step [18/23], Training Accuracy: 74.1319%, Training Loss: 0.3957%\n",
      "Epoch [280/300], Step [19/23], Training Accuracy: 74.2599%, Training Loss: 0.3954%\n",
      "Epoch [280/300], Step [20/23], Training Accuracy: 74.2188%, Training Loss: 0.3942%\n",
      "Epoch [280/300], Step [21/23], Training Accuracy: 74.0327%, Training Loss: 0.3944%\n",
      "Epoch [280/300], Step [22/23], Training Accuracy: 74.0767%, Training Loss: 0.3935%\n",
      "Epoch [280/300], Step [23/23], Training Accuracy: 74.2877%, Training Loss: 0.3902%\n",
      "Epoch [281/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3594%\n",
      "Epoch [281/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3851%\n",
      "Epoch [281/300], Step [3/23], Training Accuracy: 73.9583%, Training Loss: 0.3931%\n",
      "Epoch [281/300], Step [4/23], Training Accuracy: 76.5625%, Training Loss: 0.3765%\n",
      "Epoch [281/300], Step [5/23], Training Accuracy: 74.6875%, Training Loss: 0.3825%\n",
      "Epoch [281/300], Step [6/23], Training Accuracy: 76.3021%, Training Loss: 0.3815%\n",
      "Epoch [281/300], Step [7/23], Training Accuracy: 77.0089%, Training Loss: 0.3853%\n",
      "Epoch [281/300], Step [8/23], Training Accuracy: 77.5391%, Training Loss: 0.3822%\n",
      "Epoch [281/300], Step [9/23], Training Accuracy: 76.0417%, Training Loss: 0.3888%\n",
      "Epoch [281/300], Step [10/23], Training Accuracy: 76.2500%, Training Loss: 0.3870%\n",
      "Epoch [281/300], Step [11/23], Training Accuracy: 75.9943%, Training Loss: 0.3886%\n",
      "Epoch [281/300], Step [12/23], Training Accuracy: 75.5208%, Training Loss: 0.3887%\n",
      "Epoch [281/300], Step [13/23], Training Accuracy: 75.3606%, Training Loss: 0.3921%\n",
      "Epoch [281/300], Step [14/23], Training Accuracy: 75.4464%, Training Loss: 0.3905%\n",
      "Epoch [281/300], Step [15/23], Training Accuracy: 75.2083%, Training Loss: 0.3927%\n",
      "Epoch [281/300], Step [16/23], Training Accuracy: 75.2930%, Training Loss: 0.3916%\n",
      "Epoch [281/300], Step [17/23], Training Accuracy: 74.9081%, Training Loss: 0.3923%\n",
      "Epoch [281/300], Step [18/23], Training Accuracy: 75.0000%, Training Loss: 0.3927%\n",
      "Epoch [281/300], Step [19/23], Training Accuracy: 75.0822%, Training Loss: 0.3924%\n",
      "Epoch [281/300], Step [20/23], Training Accuracy: 75.3125%, Training Loss: 0.3907%\n",
      "Epoch [281/300], Step [21/23], Training Accuracy: 75.2976%, Training Loss: 0.3902%\n",
      "Epoch [281/300], Step [22/23], Training Accuracy: 75.1420%, Training Loss: 0.3901%\n",
      "Epoch [281/300], Step [23/23], Training Accuracy: 75.3301%, Training Loss: 0.3868%\n",
      "Epoch [282/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3787%\n",
      "Epoch [282/300], Step [2/23], Training Accuracy: 71.8750%, Training Loss: 0.4150%\n",
      "Epoch [282/300], Step [3/23], Training Accuracy: 69.7917%, Training Loss: 0.4213%\n",
      "Epoch [282/300], Step [4/23], Training Accuracy: 73.4375%, Training Loss: 0.4012%\n",
      "Epoch [282/300], Step [5/23], Training Accuracy: 71.8750%, Training Loss: 0.4018%\n",
      "Epoch [282/300], Step [6/23], Training Accuracy: 72.9167%, Training Loss: 0.4034%\n",
      "Epoch [282/300], Step [7/23], Training Accuracy: 72.7679%, Training Loss: 0.4071%\n",
      "Epoch [282/300], Step [8/23], Training Accuracy: 73.8281%, Training Loss: 0.4084%\n",
      "Epoch [282/300], Step [9/23], Training Accuracy: 72.2222%, Training Loss: 0.4166%\n",
      "Epoch [282/300], Step [10/23], Training Accuracy: 72.3438%, Training Loss: 0.4129%\n",
      "Epoch [282/300], Step [11/23], Training Accuracy: 72.5852%, Training Loss: 0.4108%\n",
      "Epoch [282/300], Step [12/23], Training Accuracy: 72.7865%, Training Loss: 0.4097%\n",
      "Epoch [282/300], Step [13/23], Training Accuracy: 72.8365%, Training Loss: 0.4105%\n",
      "Epoch [282/300], Step [14/23], Training Accuracy: 73.2143%, Training Loss: 0.4058%\n",
      "Epoch [282/300], Step [15/23], Training Accuracy: 72.8125%, Training Loss: 0.4074%\n",
      "Epoch [282/300], Step [16/23], Training Accuracy: 72.5586%, Training Loss: 0.4078%\n",
      "Epoch [282/300], Step [17/23], Training Accuracy: 72.8860%, Training Loss: 0.4071%\n",
      "Epoch [282/300], Step [18/23], Training Accuracy: 73.0903%, Training Loss: 0.4063%\n",
      "Epoch [282/300], Step [19/23], Training Accuracy: 72.9441%, Training Loss: 0.4067%\n",
      "Epoch [282/300], Step [20/23], Training Accuracy: 73.3594%, Training Loss: 0.4042%\n",
      "Epoch [282/300], Step [21/23], Training Accuracy: 73.3631%, Training Loss: 0.4041%\n",
      "Epoch [282/300], Step [22/23], Training Accuracy: 73.5085%, Training Loss: 0.4028%\n",
      "Epoch [282/300], Step [23/23], Training Accuracy: 73.5928%, Training Loss: 0.3996%\n",
      "Epoch [283/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3901%\n",
      "Epoch [283/300], Step [2/23], Training Accuracy: 77.3438%, Training Loss: 0.4062%\n",
      "Epoch [283/300], Step [3/23], Training Accuracy: 72.9167%, Training Loss: 0.4108%\n",
      "Epoch [283/300], Step [4/23], Training Accuracy: 76.1719%, Training Loss: 0.3906%\n",
      "Epoch [283/300], Step [5/23], Training Accuracy: 75.3125%, Training Loss: 0.3877%\n",
      "Epoch [283/300], Step [6/23], Training Accuracy: 75.0000%, Training Loss: 0.3900%\n",
      "Epoch [283/300], Step [7/23], Training Accuracy: 74.3304%, Training Loss: 0.3983%\n",
      "Epoch [283/300], Step [8/23], Training Accuracy: 75.0000%, Training Loss: 0.3973%\n",
      "Epoch [283/300], Step [9/23], Training Accuracy: 74.6528%, Training Loss: 0.3999%\n",
      "Epoch [283/300], Step [10/23], Training Accuracy: 75.3125%, Training Loss: 0.3973%\n",
      "Epoch [283/300], Step [11/23], Training Accuracy: 75.9943%, Training Loss: 0.3955%\n",
      "Epoch [283/300], Step [12/23], Training Accuracy: 75.6510%, Training Loss: 0.3944%\n",
      "Epoch [283/300], Step [13/23], Training Accuracy: 74.6394%, Training Loss: 0.3964%\n",
      "Epoch [283/300], Step [14/23], Training Accuracy: 74.6652%, Training Loss: 0.3954%\n",
      "Epoch [283/300], Step [15/23], Training Accuracy: 74.1667%, Training Loss: 0.3980%\n",
      "Epoch [283/300], Step [16/23], Training Accuracy: 74.1211%, Training Loss: 0.3982%\n",
      "Epoch [283/300], Step [17/23], Training Accuracy: 74.0809%, Training Loss: 0.3981%\n",
      "Epoch [283/300], Step [18/23], Training Accuracy: 73.8715%, Training Loss: 0.3986%\n",
      "Epoch [283/300], Step [19/23], Training Accuracy: 73.9309%, Training Loss: 0.3992%\n",
      "Epoch [283/300], Step [20/23], Training Accuracy: 74.2188%, Training Loss: 0.3975%\n",
      "Epoch [283/300], Step [21/23], Training Accuracy: 73.9583%, Training Loss: 0.3979%\n",
      "Epoch [283/300], Step [22/23], Training Accuracy: 73.7216%, Training Loss: 0.3968%\n",
      "Epoch [283/300], Step [23/23], Training Accuracy: 73.8013%, Training Loss: 0.3940%\n",
      "Epoch [284/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3750%\n",
      "Epoch [284/300], Step [2/23], Training Accuracy: 77.3438%, Training Loss: 0.3878%\n",
      "Epoch [284/300], Step [3/23], Training Accuracy: 73.9583%, Training Loss: 0.4025%\n",
      "Epoch [284/300], Step [4/23], Training Accuracy: 75.7812%, Training Loss: 0.3881%\n",
      "Epoch [284/300], Step [5/23], Training Accuracy: 73.7500%, Training Loss: 0.3918%\n",
      "Epoch [284/300], Step [6/23], Training Accuracy: 74.2188%, Training Loss: 0.3890%\n",
      "Epoch [284/300], Step [7/23], Training Accuracy: 73.8839%, Training Loss: 0.3939%\n",
      "Epoch [284/300], Step [8/23], Training Accuracy: 74.4141%, Training Loss: 0.3947%\n",
      "Epoch [284/300], Step [9/23], Training Accuracy: 73.7847%, Training Loss: 0.3983%\n",
      "Epoch [284/300], Step [10/23], Training Accuracy: 73.7500%, Training Loss: 0.3957%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [284/300], Step [11/23], Training Accuracy: 73.8636%, Training Loss: 0.3939%\n",
      "Epoch [284/300], Step [12/23], Training Accuracy: 74.0885%, Training Loss: 0.3933%\n",
      "Epoch [284/300], Step [13/23], Training Accuracy: 74.5192%, Training Loss: 0.3942%\n",
      "Epoch [284/300], Step [14/23], Training Accuracy: 75.0000%, Training Loss: 0.3908%\n",
      "Epoch [284/300], Step [15/23], Training Accuracy: 74.0625%, Training Loss: 0.3967%\n",
      "Epoch [284/300], Step [16/23], Training Accuracy: 73.8281%, Training Loss: 0.3964%\n",
      "Epoch [284/300], Step [17/23], Training Accuracy: 74.1728%, Training Loss: 0.3951%\n",
      "Epoch [284/300], Step [18/23], Training Accuracy: 74.0451%, Training Loss: 0.3962%\n",
      "Epoch [284/300], Step [19/23], Training Accuracy: 74.2599%, Training Loss: 0.3956%\n",
      "Epoch [284/300], Step [20/23], Training Accuracy: 74.6094%, Training Loss: 0.3936%\n",
      "Epoch [284/300], Step [21/23], Training Accuracy: 74.7768%, Training Loss: 0.3929%\n",
      "Epoch [284/300], Step [22/23], Training Accuracy: 75.0710%, Training Loss: 0.3924%\n",
      "Epoch [284/300], Step [23/23], Training Accuracy: 75.0521%, Training Loss: 0.3902%\n",
      "Epoch [285/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3647%\n",
      "Epoch [285/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.3902%\n",
      "Epoch [285/300], Step [3/23], Training Accuracy: 73.4375%, Training Loss: 0.3909%\n",
      "Epoch [285/300], Step [4/23], Training Accuracy: 74.2188%, Training Loss: 0.3763%\n",
      "Epoch [285/300], Step [5/23], Training Accuracy: 73.1250%, Training Loss: 0.3803%\n",
      "Epoch [285/300], Step [6/23], Training Accuracy: 74.4792%, Training Loss: 0.3760%\n",
      "Epoch [285/300], Step [7/23], Training Accuracy: 74.1071%, Training Loss: 0.3826%\n",
      "Epoch [285/300], Step [8/23], Training Accuracy: 73.6328%, Training Loss: 0.3857%\n",
      "Epoch [285/300], Step [9/23], Training Accuracy: 73.4375%, Training Loss: 0.3922%\n",
      "Epoch [285/300], Step [10/23], Training Accuracy: 73.7500%, Training Loss: 0.3919%\n",
      "Epoch [285/300], Step [11/23], Training Accuracy: 73.8636%, Training Loss: 0.3937%\n",
      "Epoch [285/300], Step [12/23], Training Accuracy: 73.1771%, Training Loss: 0.3961%\n",
      "Epoch [285/300], Step [13/23], Training Accuracy: 73.0769%, Training Loss: 0.3979%\n",
      "Epoch [285/300], Step [14/23], Training Accuracy: 73.4375%, Training Loss: 0.3957%\n",
      "Epoch [285/300], Step [15/23], Training Accuracy: 73.4375%, Training Loss: 0.3999%\n",
      "Epoch [285/300], Step [16/23], Training Accuracy: 73.2422%, Training Loss: 0.3996%\n",
      "Epoch [285/300], Step [17/23], Training Accuracy: 73.2537%, Training Loss: 0.4003%\n",
      "Epoch [285/300], Step [18/23], Training Accuracy: 73.0903%, Training Loss: 0.4015%\n",
      "Epoch [285/300], Step [19/23], Training Accuracy: 73.2730%, Training Loss: 0.4009%\n",
      "Epoch [285/300], Step [20/23], Training Accuracy: 73.5938%, Training Loss: 0.3988%\n",
      "Epoch [285/300], Step [21/23], Training Accuracy: 73.4375%, Training Loss: 0.3986%\n",
      "Epoch [285/300], Step [22/23], Training Accuracy: 73.4375%, Training Loss: 0.3976%\n",
      "Epoch [285/300], Step [23/23], Training Accuracy: 73.5233%, Training Loss: 0.3935%\n",
      "Epoch [286/300], Step [1/23], Training Accuracy: 71.8750%, Training Loss: 0.3775%\n",
      "Epoch [286/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.3855%\n",
      "Epoch [286/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.3994%\n",
      "Epoch [286/300], Step [4/23], Training Accuracy: 74.2188%, Training Loss: 0.3867%\n",
      "Epoch [286/300], Step [5/23], Training Accuracy: 74.0625%, Training Loss: 0.3905%\n",
      "Epoch [286/300], Step [6/23], Training Accuracy: 75.0000%, Training Loss: 0.3876%\n",
      "Epoch [286/300], Step [7/23], Training Accuracy: 75.0000%, Training Loss: 0.3919%\n",
      "Epoch [286/300], Step [8/23], Training Accuracy: 75.1953%, Training Loss: 0.3918%\n",
      "Epoch [286/300], Step [9/23], Training Accuracy: 74.6528%, Training Loss: 0.3953%\n",
      "Epoch [286/300], Step [10/23], Training Accuracy: 75.3125%, Training Loss: 0.3936%\n",
      "Epoch [286/300], Step [11/23], Training Accuracy: 75.7102%, Training Loss: 0.3931%\n",
      "Epoch [286/300], Step [12/23], Training Accuracy: 74.8698%, Training Loss: 0.3953%\n",
      "Epoch [286/300], Step [13/23], Training Accuracy: 74.3990%, Training Loss: 0.3982%\n",
      "Epoch [286/300], Step [14/23], Training Accuracy: 74.6652%, Training Loss: 0.3961%\n",
      "Epoch [286/300], Step [15/23], Training Accuracy: 74.2708%, Training Loss: 0.3991%\n",
      "Epoch [286/300], Step [16/23], Training Accuracy: 74.1211%, Training Loss: 0.3999%\n",
      "Epoch [286/300], Step [17/23], Training Accuracy: 74.3566%, Training Loss: 0.3999%\n",
      "Epoch [286/300], Step [18/23], Training Accuracy: 74.3924%, Training Loss: 0.3991%\n",
      "Epoch [286/300], Step [19/23], Training Accuracy: 74.4243%, Training Loss: 0.3982%\n",
      "Epoch [286/300], Step [20/23], Training Accuracy: 74.5312%, Training Loss: 0.3973%\n",
      "Epoch [286/300], Step [21/23], Training Accuracy: 74.2560%, Training Loss: 0.3963%\n",
      "Epoch [286/300], Step [22/23], Training Accuracy: 74.2188%, Training Loss: 0.3958%\n",
      "Epoch [286/300], Step [23/23], Training Accuracy: 74.3572%, Training Loss: 0.3922%\n",
      "Epoch [287/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3566%\n",
      "Epoch [287/300], Step [2/23], Training Accuracy: 72.6562%, Training Loss: 0.3950%\n",
      "Epoch [287/300], Step [3/23], Training Accuracy: 70.3125%, Training Loss: 0.3976%\n",
      "Epoch [287/300], Step [4/23], Training Accuracy: 72.2656%, Training Loss: 0.3817%\n",
      "Epoch [287/300], Step [5/23], Training Accuracy: 72.1875%, Training Loss: 0.3815%\n",
      "Epoch [287/300], Step [6/23], Training Accuracy: 73.4375%, Training Loss: 0.3834%\n",
      "Epoch [287/300], Step [7/23], Training Accuracy: 74.5536%, Training Loss: 0.3866%\n",
      "Epoch [287/300], Step [8/23], Training Accuracy: 74.6094%, Training Loss: 0.3914%\n",
      "Epoch [287/300], Step [9/23], Training Accuracy: 73.6111%, Training Loss: 0.3973%\n",
      "Epoch [287/300], Step [10/23], Training Accuracy: 73.4375%, Training Loss: 0.3965%\n",
      "Epoch [287/300], Step [11/23], Training Accuracy: 73.7216%, Training Loss: 0.3955%\n",
      "Epoch [287/300], Step [12/23], Training Accuracy: 73.6979%, Training Loss: 0.3971%\n",
      "Epoch [287/300], Step [13/23], Training Accuracy: 73.4375%, Training Loss: 0.4004%\n",
      "Epoch [287/300], Step [14/23], Training Accuracy: 73.6607%, Training Loss: 0.3977%\n",
      "Epoch [287/300], Step [15/23], Training Accuracy: 73.5417%, Training Loss: 0.3987%\n",
      "Epoch [287/300], Step [16/23], Training Accuracy: 72.9492%, Training Loss: 0.3987%\n",
      "Epoch [287/300], Step [17/23], Training Accuracy: 73.1618%, Training Loss: 0.3973%\n",
      "Epoch [287/300], Step [18/23], Training Accuracy: 73.2639%, Training Loss: 0.3976%\n",
      "Epoch [287/300], Step [19/23], Training Accuracy: 73.1086%, Training Loss: 0.3987%\n",
      "Epoch [287/300], Step [20/23], Training Accuracy: 73.3594%, Training Loss: 0.3974%\n",
      "Epoch [287/300], Step [21/23], Training Accuracy: 73.3631%, Training Loss: 0.3979%\n",
      "Epoch [287/300], Step [22/23], Training Accuracy: 73.5085%, Training Loss: 0.3970%\n",
      "Epoch [287/300], Step [23/23], Training Accuracy: 73.5928%, Training Loss: 0.3927%\n",
      "Epoch [288/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3721%\n",
      "Epoch [288/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.3822%\n",
      "Epoch [288/300], Step [3/23], Training Accuracy: 72.3958%, Training Loss: 0.3968%\n",
      "Epoch [288/300], Step [4/23], Training Accuracy: 74.6094%, Training Loss: 0.3854%\n",
      "Epoch [288/300], Step [5/23], Training Accuracy: 74.0625%, Training Loss: 0.3859%\n",
      "Epoch [288/300], Step [6/23], Training Accuracy: 75.0000%, Training Loss: 0.3886%\n",
      "Epoch [288/300], Step [7/23], Training Accuracy: 75.4464%, Training Loss: 0.3922%\n",
      "Epoch [288/300], Step [8/23], Training Accuracy: 75.5859%, Training Loss: 0.3953%\n",
      "Epoch [288/300], Step [9/23], Training Accuracy: 74.8264%, Training Loss: 0.3987%\n",
      "Epoch [288/300], Step [10/23], Training Accuracy: 74.8438%, Training Loss: 0.3979%\n",
      "Epoch [288/300], Step [11/23], Training Accuracy: 74.5739%, Training Loss: 0.3970%\n",
      "Epoch [288/300], Step [12/23], Training Accuracy: 74.7396%, Training Loss: 0.3989%\n",
      "Epoch [288/300], Step [13/23], Training Accuracy: 75.1202%, Training Loss: 0.3999%\n",
      "Epoch [288/300], Step [14/23], Training Accuracy: 75.3348%, Training Loss: 0.3973%\n",
      "Epoch [288/300], Step [15/23], Training Accuracy: 74.6875%, Training Loss: 0.4001%\n",
      "Epoch [288/300], Step [16/23], Training Accuracy: 75.0000%, Training Loss: 0.3997%\n",
      "Epoch [288/300], Step [17/23], Training Accuracy: 75.3676%, Training Loss: 0.3975%\n",
      "Epoch [288/300], Step [18/23], Training Accuracy: 75.2604%, Training Loss: 0.3994%\n",
      "Epoch [288/300], Step [19/23], Training Accuracy: 75.4112%, Training Loss: 0.3984%\n",
      "Epoch [288/300], Step [20/23], Training Accuracy: 75.5469%, Training Loss: 0.3964%\n",
      "Epoch [288/300], Step [21/23], Training Accuracy: 75.2976%, Training Loss: 0.3969%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [288/300], Step [22/23], Training Accuracy: 75.4972%, Training Loss: 0.3954%\n",
      "Epoch [288/300], Step [23/23], Training Accuracy: 75.4691%, Training Loss: 0.3911%\n",
      "Epoch [289/300], Step [1/23], Training Accuracy: 73.4375%, Training Loss: 0.3732%\n",
      "Epoch [289/300], Step [2/23], Training Accuracy: 74.2188%, Training Loss: 0.3931%\n",
      "Epoch [289/300], Step [3/23], Training Accuracy: 73.4375%, Training Loss: 0.4025%\n",
      "Epoch [289/300], Step [4/23], Training Accuracy: 75.7812%, Training Loss: 0.3817%\n",
      "Epoch [289/300], Step [5/23], Training Accuracy: 75.3125%, Training Loss: 0.3812%\n",
      "Epoch [289/300], Step [6/23], Training Accuracy: 76.0417%, Training Loss: 0.3820%\n",
      "Epoch [289/300], Step [7/23], Training Accuracy: 76.1161%, Training Loss: 0.3845%\n",
      "Epoch [289/300], Step [8/23], Training Accuracy: 76.5625%, Training Loss: 0.3860%\n",
      "Epoch [289/300], Step [9/23], Training Accuracy: 75.6944%, Training Loss: 0.3902%\n",
      "Epoch [289/300], Step [10/23], Training Accuracy: 75.1562%, Training Loss: 0.3892%\n",
      "Epoch [289/300], Step [11/23], Training Accuracy: 75.5682%, Training Loss: 0.3875%\n",
      "Epoch [289/300], Step [12/23], Training Accuracy: 75.7812%, Training Loss: 0.3881%\n",
      "Epoch [289/300], Step [13/23], Training Accuracy: 75.7212%, Training Loss: 0.3911%\n",
      "Epoch [289/300], Step [14/23], Training Accuracy: 75.7812%, Training Loss: 0.3900%\n",
      "Epoch [289/300], Step [15/23], Training Accuracy: 75.0000%, Training Loss: 0.3940%\n",
      "Epoch [289/300], Step [16/23], Training Accuracy: 74.8047%, Training Loss: 0.3943%\n",
      "Epoch [289/300], Step [17/23], Training Accuracy: 75.1838%, Training Loss: 0.3938%\n",
      "Epoch [289/300], Step [18/23], Training Accuracy: 74.8264%, Training Loss: 0.3945%\n",
      "Epoch [289/300], Step [19/23], Training Accuracy: 74.8355%, Training Loss: 0.3951%\n",
      "Epoch [289/300], Step [20/23], Training Accuracy: 74.8438%, Training Loss: 0.3945%\n",
      "Epoch [289/300], Step [21/23], Training Accuracy: 74.6280%, Training Loss: 0.3945%\n",
      "Epoch [289/300], Step [22/23], Training Accuracy: 74.6449%, Training Loss: 0.3937%\n",
      "Epoch [289/300], Step [23/23], Training Accuracy: 74.8436%, Training Loss: 0.3898%\n",
      "Epoch [290/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3717%\n",
      "Epoch [290/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.3957%\n",
      "Epoch [290/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.4036%\n",
      "Epoch [290/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.3938%\n",
      "Epoch [290/300], Step [5/23], Training Accuracy: 72.8125%, Training Loss: 0.3929%\n",
      "Epoch [290/300], Step [6/23], Training Accuracy: 73.9583%, Training Loss: 0.3910%\n",
      "Epoch [290/300], Step [7/23], Training Accuracy: 73.4375%, Training Loss: 0.3966%\n",
      "Epoch [290/300], Step [8/23], Training Accuracy: 73.4375%, Training Loss: 0.3979%\n",
      "Epoch [290/300], Step [9/23], Training Accuracy: 72.9167%, Training Loss: 0.3997%\n",
      "Epoch [290/300], Step [10/23], Training Accuracy: 73.2812%, Training Loss: 0.3963%\n",
      "Epoch [290/300], Step [11/23], Training Accuracy: 73.8636%, Training Loss: 0.3958%\n",
      "Epoch [290/300], Step [12/23], Training Accuracy: 73.9583%, Training Loss: 0.3964%\n",
      "Epoch [290/300], Step [13/23], Training Accuracy: 73.3173%, Training Loss: 0.3995%\n",
      "Epoch [290/300], Step [14/23], Training Accuracy: 73.7723%, Training Loss: 0.3979%\n",
      "Epoch [290/300], Step [15/23], Training Accuracy: 72.8125%, Training Loss: 0.4020%\n",
      "Epoch [290/300], Step [16/23], Training Accuracy: 72.4609%, Training Loss: 0.4022%\n",
      "Epoch [290/300], Step [17/23], Training Accuracy: 72.6103%, Training Loss: 0.4020%\n",
      "Epoch [290/300], Step [18/23], Training Accuracy: 72.7431%, Training Loss: 0.4006%\n",
      "Epoch [290/300], Step [19/23], Training Accuracy: 73.1908%, Training Loss: 0.3998%\n",
      "Epoch [290/300], Step [20/23], Training Accuracy: 73.3594%, Training Loss: 0.3980%\n",
      "Epoch [290/300], Step [21/23], Training Accuracy: 73.5863%, Training Loss: 0.3973%\n",
      "Epoch [290/300], Step [22/23], Training Accuracy: 73.8636%, Training Loss: 0.3966%\n",
      "Epoch [290/300], Step [23/23], Training Accuracy: 74.0097%, Training Loss: 0.3929%\n",
      "Epoch [291/300], Step [1/23], Training Accuracy: 71.8750%, Training Loss: 0.3666%\n",
      "Epoch [291/300], Step [2/23], Training Accuracy: 71.8750%, Training Loss: 0.3930%\n",
      "Epoch [291/300], Step [3/23], Training Accuracy: 70.8333%, Training Loss: 0.3996%\n",
      "Epoch [291/300], Step [4/23], Training Accuracy: 73.4375%, Training Loss: 0.3864%\n",
      "Epoch [291/300], Step [5/23], Training Accuracy: 74.0625%, Training Loss: 0.3866%\n",
      "Epoch [291/300], Step [6/23], Training Accuracy: 75.7812%, Training Loss: 0.3845%\n",
      "Epoch [291/300], Step [7/23], Training Accuracy: 76.1161%, Training Loss: 0.3877%\n",
      "Epoch [291/300], Step [8/23], Training Accuracy: 75.7812%, Training Loss: 0.3911%\n",
      "Epoch [291/300], Step [9/23], Training Accuracy: 74.6528%, Training Loss: 0.3953%\n",
      "Epoch [291/300], Step [10/23], Training Accuracy: 75.3125%, Training Loss: 0.3931%\n",
      "Epoch [291/300], Step [11/23], Training Accuracy: 75.0000%, Training Loss: 0.3928%\n",
      "Epoch [291/300], Step [12/23], Training Accuracy: 74.7396%, Training Loss: 0.3927%\n",
      "Epoch [291/300], Step [13/23], Training Accuracy: 74.5192%, Training Loss: 0.3939%\n",
      "Epoch [291/300], Step [14/23], Training Accuracy: 74.6652%, Training Loss: 0.3927%\n",
      "Epoch [291/300], Step [15/23], Training Accuracy: 73.6458%, Training Loss: 0.4005%\n",
      "Epoch [291/300], Step [16/23], Training Accuracy: 73.3398%, Training Loss: 0.4013%\n",
      "Epoch [291/300], Step [17/23], Training Accuracy: 73.2537%, Training Loss: 0.4010%\n",
      "Epoch [291/300], Step [18/23], Training Accuracy: 73.4375%, Training Loss: 0.4005%\n",
      "Epoch [291/300], Step [19/23], Training Accuracy: 73.4375%, Training Loss: 0.4003%\n",
      "Epoch [291/300], Step [20/23], Training Accuracy: 73.5156%, Training Loss: 0.3988%\n",
      "Epoch [291/300], Step [21/23], Training Accuracy: 72.9167%, Training Loss: 0.3984%\n",
      "Epoch [291/300], Step [22/23], Training Accuracy: 72.9403%, Training Loss: 0.3983%\n",
      "Epoch [291/300], Step [23/23], Training Accuracy: 73.1063%, Training Loss: 0.3944%\n",
      "Epoch [292/300], Step [1/23], Training Accuracy: 78.1250%, Training Loss: 0.3727%\n",
      "Epoch [292/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.3983%\n",
      "Epoch [292/300], Step [3/23], Training Accuracy: 68.7500%, Training Loss: 0.4036%\n",
      "Epoch [292/300], Step [4/23], Training Accuracy: 73.0469%, Training Loss: 0.3882%\n",
      "Epoch [292/300], Step [5/23], Training Accuracy: 73.4375%, Training Loss: 0.3848%\n",
      "Epoch [292/300], Step [6/23], Training Accuracy: 74.2188%, Training Loss: 0.3874%\n",
      "Epoch [292/300], Step [7/23], Training Accuracy: 73.8839%, Training Loss: 0.3926%\n",
      "Epoch [292/300], Step [8/23], Training Accuracy: 75.0000%, Training Loss: 0.3900%\n",
      "Epoch [292/300], Step [9/23], Training Accuracy: 74.4792%, Training Loss: 0.3962%\n",
      "Epoch [292/300], Step [10/23], Training Accuracy: 74.5312%, Training Loss: 0.3956%\n",
      "Epoch [292/300], Step [11/23], Training Accuracy: 74.5739%, Training Loss: 0.3953%\n",
      "Epoch [292/300], Step [12/23], Training Accuracy: 75.1302%, Training Loss: 0.3940%\n",
      "Epoch [292/300], Step [13/23], Training Accuracy: 75.2404%, Training Loss: 0.3957%\n",
      "Epoch [292/300], Step [14/23], Training Accuracy: 75.7812%, Training Loss: 0.3935%\n",
      "Epoch [292/300], Step [15/23], Training Accuracy: 75.3125%, Training Loss: 0.3955%\n",
      "Epoch [292/300], Step [16/23], Training Accuracy: 75.0000%, Training Loss: 0.3968%\n",
      "Epoch [292/300], Step [17/23], Training Accuracy: 75.2757%, Training Loss: 0.3973%\n",
      "Epoch [292/300], Step [18/23], Training Accuracy: 75.0868%, Training Loss: 0.3988%\n",
      "Epoch [292/300], Step [19/23], Training Accuracy: 75.0000%, Training Loss: 0.3999%\n",
      "Epoch [292/300], Step [20/23], Training Accuracy: 75.3125%, Training Loss: 0.3983%\n",
      "Epoch [292/300], Step [21/23], Training Accuracy: 75.2976%, Training Loss: 0.3981%\n",
      "Epoch [292/300], Step [22/23], Training Accuracy: 75.2131%, Training Loss: 0.3972%\n",
      "Epoch [292/300], Step [23/23], Training Accuracy: 75.2606%, Training Loss: 0.3941%\n",
      "Epoch [293/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3679%\n",
      "Epoch [293/300], Step [2/23], Training Accuracy: 72.6562%, Training Loss: 0.3923%\n",
      "Epoch [293/300], Step [3/23], Training Accuracy: 70.3125%, Training Loss: 0.4101%\n",
      "Epoch [293/300], Step [4/23], Training Accuracy: 73.8281%, Training Loss: 0.3943%\n",
      "Epoch [293/300], Step [5/23], Training Accuracy: 73.1250%, Training Loss: 0.3949%\n",
      "Epoch [293/300], Step [6/23], Training Accuracy: 73.4375%, Training Loss: 0.3966%\n",
      "Epoch [293/300], Step [7/23], Training Accuracy: 73.2143%, Training Loss: 0.4033%\n",
      "Epoch [293/300], Step [8/23], Training Accuracy: 73.4375%, Training Loss: 0.4030%\n",
      "Epoch [293/300], Step [9/23], Training Accuracy: 72.7431%, Training Loss: 0.4066%\n",
      "Epoch [293/300], Step [10/23], Training Accuracy: 72.9688%, Training Loss: 0.4051%\n",
      "Epoch [293/300], Step [11/23], Training Accuracy: 73.4375%, Training Loss: 0.4035%\n",
      "Epoch [293/300], Step [12/23], Training Accuracy: 73.6979%, Training Loss: 0.4013%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [293/300], Step [13/23], Training Accuracy: 72.9567%, Training Loss: 0.4022%\n",
      "Epoch [293/300], Step [14/23], Training Accuracy: 73.6607%, Training Loss: 0.3988%\n",
      "Epoch [293/300], Step [15/23], Training Accuracy: 73.6458%, Training Loss: 0.3986%\n",
      "Epoch [293/300], Step [16/23], Training Accuracy: 73.6328%, Training Loss: 0.3987%\n",
      "Epoch [293/300], Step [17/23], Training Accuracy: 73.8971%, Training Loss: 0.3969%\n",
      "Epoch [293/300], Step [18/23], Training Accuracy: 74.0451%, Training Loss: 0.3963%\n",
      "Epoch [293/300], Step [19/23], Training Accuracy: 73.8487%, Training Loss: 0.3964%\n",
      "Epoch [293/300], Step [20/23], Training Accuracy: 74.1406%, Training Loss: 0.3953%\n",
      "Epoch [293/300], Step [21/23], Training Accuracy: 74.1071%, Training Loss: 0.3945%\n",
      "Epoch [293/300], Step [22/23], Training Accuracy: 74.2898%, Training Loss: 0.3938%\n",
      "Epoch [293/300], Step [23/23], Training Accuracy: 74.4267%, Training Loss: 0.3905%\n",
      "Epoch [294/300], Step [1/23], Training Accuracy: 73.4375%, Training Loss: 0.3599%\n",
      "Epoch [294/300], Step [2/23], Training Accuracy: 72.6562%, Training Loss: 0.3887%\n",
      "Epoch [294/300], Step [3/23], Training Accuracy: 70.8333%, Training Loss: 0.3902%\n",
      "Epoch [294/300], Step [4/23], Training Accuracy: 74.6094%, Training Loss: 0.3739%\n",
      "Epoch [294/300], Step [5/23], Training Accuracy: 73.4375%, Training Loss: 0.3793%\n",
      "Epoch [294/300], Step [6/23], Training Accuracy: 74.2188%, Training Loss: 0.3813%\n",
      "Epoch [294/300], Step [7/23], Training Accuracy: 74.1071%, Training Loss: 0.3865%\n",
      "Epoch [294/300], Step [8/23], Training Accuracy: 75.0000%, Training Loss: 0.3869%\n",
      "Epoch [294/300], Step [9/23], Training Accuracy: 73.6111%, Training Loss: 0.3938%\n",
      "Epoch [294/300], Step [10/23], Training Accuracy: 73.9062%, Training Loss: 0.3913%\n",
      "Epoch [294/300], Step [11/23], Training Accuracy: 74.4318%, Training Loss: 0.3888%\n",
      "Epoch [294/300], Step [12/23], Training Accuracy: 74.2188%, Training Loss: 0.3914%\n",
      "Epoch [294/300], Step [13/23], Training Accuracy: 73.7981%, Training Loss: 0.3930%\n",
      "Epoch [294/300], Step [14/23], Training Accuracy: 74.1071%, Training Loss: 0.3915%\n",
      "Epoch [294/300], Step [15/23], Training Accuracy: 73.9583%, Training Loss: 0.3932%\n",
      "Epoch [294/300], Step [16/23], Training Accuracy: 74.0234%, Training Loss: 0.3925%\n",
      "Epoch [294/300], Step [17/23], Training Accuracy: 74.3566%, Training Loss: 0.3924%\n",
      "Epoch [294/300], Step [18/23], Training Accuracy: 74.5660%, Training Loss: 0.3931%\n",
      "Epoch [294/300], Step [19/23], Training Accuracy: 74.5066%, Training Loss: 0.3928%\n",
      "Epoch [294/300], Step [20/23], Training Accuracy: 74.6875%, Training Loss: 0.3918%\n",
      "Epoch [294/300], Step [21/23], Training Accuracy: 74.3304%, Training Loss: 0.3930%\n",
      "Epoch [294/300], Step [22/23], Training Accuracy: 74.5028%, Training Loss: 0.3916%\n",
      "Epoch [294/300], Step [23/23], Training Accuracy: 74.6352%, Training Loss: 0.3880%\n",
      "Epoch [295/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3725%\n",
      "Epoch [295/300], Step [2/23], Training Accuracy: 73.4375%, Training Loss: 0.4014%\n",
      "Epoch [295/300], Step [3/23], Training Accuracy: 71.8750%, Training Loss: 0.4140%\n",
      "Epoch [295/300], Step [4/23], Training Accuracy: 74.2188%, Training Loss: 0.4029%\n",
      "Epoch [295/300], Step [5/23], Training Accuracy: 73.1250%, Training Loss: 0.4050%\n",
      "Epoch [295/300], Step [6/23], Training Accuracy: 74.2188%, Training Loss: 0.4001%\n",
      "Epoch [295/300], Step [7/23], Training Accuracy: 74.5536%, Training Loss: 0.4027%\n",
      "Epoch [295/300], Step [8/23], Training Accuracy: 75.1953%, Training Loss: 0.3988%\n",
      "Epoch [295/300], Step [9/23], Training Accuracy: 73.2639%, Training Loss: 0.4050%\n",
      "Epoch [295/300], Step [10/23], Training Accuracy: 73.2812%, Training Loss: 0.4029%\n",
      "Epoch [295/300], Step [11/23], Training Accuracy: 73.7216%, Training Loss: 0.4010%\n",
      "Epoch [295/300], Step [12/23], Training Accuracy: 73.6979%, Training Loss: 0.4003%\n",
      "Epoch [295/300], Step [13/23], Training Accuracy: 73.3173%, Training Loss: 0.4028%\n",
      "Epoch [295/300], Step [14/23], Training Accuracy: 73.6607%, Training Loss: 0.3985%\n",
      "Epoch [295/300], Step [15/23], Training Accuracy: 73.2292%, Training Loss: 0.4007%\n",
      "Epoch [295/300], Step [16/23], Training Accuracy: 73.1445%, Training Loss: 0.3994%\n",
      "Epoch [295/300], Step [17/23], Training Accuracy: 73.0699%, Training Loss: 0.3989%\n",
      "Epoch [295/300], Step [18/23], Training Accuracy: 73.6111%, Training Loss: 0.3977%\n",
      "Epoch [295/300], Step [19/23], Training Accuracy: 73.8487%, Training Loss: 0.3968%\n",
      "Epoch [295/300], Step [20/23], Training Accuracy: 74.2969%, Training Loss: 0.3946%\n",
      "Epoch [295/300], Step [21/23], Training Accuracy: 73.7351%, Training Loss: 0.3965%\n",
      "Epoch [295/300], Step [22/23], Training Accuracy: 74.0057%, Training Loss: 0.3960%\n",
      "Epoch [295/300], Step [23/23], Training Accuracy: 74.2182%, Training Loss: 0.3923%\n",
      "Epoch [296/300], Step [1/23], Training Accuracy: 71.8750%, Training Loss: 0.3707%\n",
      "Epoch [296/300], Step [2/23], Training Accuracy: 71.8750%, Training Loss: 0.3875%\n",
      "Epoch [296/300], Step [3/23], Training Accuracy: 72.3958%, Training Loss: 0.3938%\n",
      "Epoch [296/300], Step [4/23], Training Accuracy: 75.0000%, Training Loss: 0.3789%\n",
      "Epoch [296/300], Step [5/23], Training Accuracy: 74.0625%, Training Loss: 0.3781%\n",
      "Epoch [296/300], Step [6/23], Training Accuracy: 75.2604%, Training Loss: 0.3765%\n",
      "Epoch [296/300], Step [7/23], Training Accuracy: 75.4464%, Training Loss: 0.3810%\n",
      "Epoch [296/300], Step [8/23], Training Accuracy: 75.5859%, Training Loss: 0.3829%\n",
      "Epoch [296/300], Step [9/23], Training Accuracy: 74.1319%, Training Loss: 0.3892%\n",
      "Epoch [296/300], Step [10/23], Training Accuracy: 74.0625%, Training Loss: 0.3886%\n",
      "Epoch [296/300], Step [11/23], Training Accuracy: 74.1477%, Training Loss: 0.3885%\n",
      "Epoch [296/300], Step [12/23], Training Accuracy: 74.4792%, Training Loss: 0.3891%\n",
      "Epoch [296/300], Step [13/23], Training Accuracy: 74.2788%, Training Loss: 0.3899%\n",
      "Epoch [296/300], Step [14/23], Training Accuracy: 74.3304%, Training Loss: 0.3872%\n",
      "Epoch [296/300], Step [15/23], Training Accuracy: 73.6458%, Training Loss: 0.3917%\n",
      "Epoch [296/300], Step [16/23], Training Accuracy: 73.4375%, Training Loss: 0.3934%\n",
      "Epoch [296/300], Step [17/23], Training Accuracy: 73.6213%, Training Loss: 0.3931%\n",
      "Epoch [296/300], Step [18/23], Training Accuracy: 73.7847%, Training Loss: 0.3930%\n",
      "Epoch [296/300], Step [19/23], Training Accuracy: 74.0954%, Training Loss: 0.3932%\n",
      "Epoch [296/300], Step [20/23], Training Accuracy: 74.2969%, Training Loss: 0.3918%\n",
      "Epoch [296/300], Step [21/23], Training Accuracy: 74.1815%, Training Loss: 0.3924%\n",
      "Epoch [296/300], Step [22/23], Training Accuracy: 74.2188%, Training Loss: 0.3919%\n",
      "Epoch [296/300], Step [23/23], Training Accuracy: 74.2877%, Training Loss: 0.3878%\n",
      "Epoch [297/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3546%\n",
      "Epoch [297/300], Step [2/23], Training Accuracy: 75.0000%, Training Loss: 0.3831%\n",
      "Epoch [297/300], Step [3/23], Training Accuracy: 74.4792%, Training Loss: 0.3891%\n",
      "Epoch [297/300], Step [4/23], Training Accuracy: 77.7344%, Training Loss: 0.3776%\n",
      "Epoch [297/300], Step [5/23], Training Accuracy: 75.6250%, Training Loss: 0.3775%\n",
      "Epoch [297/300], Step [6/23], Training Accuracy: 75.7812%, Training Loss: 0.3781%\n",
      "Epoch [297/300], Step [7/23], Training Accuracy: 76.3393%, Training Loss: 0.3850%\n",
      "Epoch [297/300], Step [8/23], Training Accuracy: 76.7578%, Training Loss: 0.3830%\n",
      "Epoch [297/300], Step [9/23], Training Accuracy: 76.0417%, Training Loss: 0.3897%\n",
      "Epoch [297/300], Step [10/23], Training Accuracy: 76.0938%, Training Loss: 0.3874%\n",
      "Epoch [297/300], Step [11/23], Training Accuracy: 75.8523%, Training Loss: 0.3883%\n",
      "Epoch [297/300], Step [12/23], Training Accuracy: 75.5208%, Training Loss: 0.3901%\n",
      "Epoch [297/300], Step [13/23], Training Accuracy: 75.6010%, Training Loss: 0.3916%\n",
      "Epoch [297/300], Step [14/23], Training Accuracy: 75.8929%, Training Loss: 0.3900%\n",
      "Epoch [297/300], Step [15/23], Training Accuracy: 75.5208%, Training Loss: 0.3917%\n",
      "Epoch [297/300], Step [16/23], Training Accuracy: 75.1953%, Training Loss: 0.3928%\n",
      "Epoch [297/300], Step [17/23], Training Accuracy: 75.2757%, Training Loss: 0.3928%\n",
      "Epoch [297/300], Step [18/23], Training Accuracy: 75.6944%, Training Loss: 0.3923%\n",
      "Epoch [297/300], Step [19/23], Training Accuracy: 75.7401%, Training Loss: 0.3919%\n",
      "Epoch [297/300], Step [20/23], Training Accuracy: 75.7812%, Training Loss: 0.3900%\n",
      "Epoch [297/300], Step [21/23], Training Accuracy: 75.6696%, Training Loss: 0.3901%\n",
      "Epoch [297/300], Step [22/23], Training Accuracy: 75.9233%, Training Loss: 0.3887%\n",
      "Epoch [297/300], Step [23/23], Training Accuracy: 75.8860%, Training Loss: 0.3861%\n",
      "Epoch [298/300], Step [1/23], Training Accuracy: 75.0000%, Training Loss: 0.3673%\n",
      "Epoch [298/300], Step [2/23], Training Accuracy: 75.7812%, Training Loss: 0.4020%\n",
      "Epoch [298/300], Step [3/23], Training Accuracy: 73.4375%, Training Loss: 0.4082%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [298/300], Step [4/23], Training Accuracy: 77.3438%, Training Loss: 0.3925%\n",
      "Epoch [298/300], Step [5/23], Training Accuracy: 76.2500%, Training Loss: 0.3882%\n",
      "Epoch [298/300], Step [6/23], Training Accuracy: 76.8229%, Training Loss: 0.3889%\n",
      "Epoch [298/300], Step [7/23], Training Accuracy: 77.2321%, Training Loss: 0.3948%\n",
      "Epoch [298/300], Step [8/23], Training Accuracy: 77.9297%, Training Loss: 0.3926%\n",
      "Epoch [298/300], Step [9/23], Training Accuracy: 77.2569%, Training Loss: 0.3961%\n",
      "Epoch [298/300], Step [10/23], Training Accuracy: 77.1875%, Training Loss: 0.3936%\n",
      "Epoch [298/300], Step [11/23], Training Accuracy: 77.1307%, Training Loss: 0.3940%\n",
      "Epoch [298/300], Step [12/23], Training Accuracy: 77.0833%, Training Loss: 0.3964%\n",
      "Epoch [298/300], Step [13/23], Training Accuracy: 76.8029%, Training Loss: 0.3973%\n",
      "Epoch [298/300], Step [14/23], Training Accuracy: 76.7857%, Training Loss: 0.3959%\n",
      "Epoch [298/300], Step [15/23], Training Accuracy: 76.2500%, Training Loss: 0.3988%\n",
      "Epoch [298/300], Step [16/23], Training Accuracy: 76.0742%, Training Loss: 0.3998%\n",
      "Epoch [298/300], Step [17/23], Training Accuracy: 75.9191%, Training Loss: 0.3986%\n",
      "Epoch [298/300], Step [18/23], Training Accuracy: 75.9549%, Training Loss: 0.3986%\n",
      "Epoch [298/300], Step [19/23], Training Accuracy: 75.5757%, Training Loss: 0.3995%\n",
      "Epoch [298/300], Step [20/23], Training Accuracy: 75.6250%, Training Loss: 0.3979%\n",
      "Epoch [298/300], Step [21/23], Training Accuracy: 75.4464%, Training Loss: 0.3981%\n",
      "Epoch [298/300], Step [22/23], Training Accuracy: 75.3551%, Training Loss: 0.3965%\n",
      "Epoch [298/300], Step [23/23], Training Accuracy: 75.4691%, Training Loss: 0.3932%\n",
      "Epoch [299/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3706%\n",
      "Epoch [299/300], Step [2/23], Training Accuracy: 76.5625%, Training Loss: 0.3832%\n",
      "Epoch [299/300], Step [3/23], Training Accuracy: 72.3958%, Training Loss: 0.3939%\n",
      "Epoch [299/300], Step [4/23], Training Accuracy: 75.7812%, Training Loss: 0.3788%\n",
      "Epoch [299/300], Step [5/23], Training Accuracy: 75.0000%, Training Loss: 0.3781%\n",
      "Epoch [299/300], Step [6/23], Training Accuracy: 75.0000%, Training Loss: 0.3792%\n",
      "Epoch [299/300], Step [7/23], Training Accuracy: 75.4464%, Training Loss: 0.3837%\n",
      "Epoch [299/300], Step [8/23], Training Accuracy: 75.7812%, Training Loss: 0.3837%\n",
      "Epoch [299/300], Step [9/23], Training Accuracy: 74.4792%, Training Loss: 0.3909%\n",
      "Epoch [299/300], Step [10/23], Training Accuracy: 74.3750%, Training Loss: 0.3888%\n",
      "Epoch [299/300], Step [11/23], Training Accuracy: 74.4318%, Training Loss: 0.3889%\n",
      "Epoch [299/300], Step [12/23], Training Accuracy: 74.2188%, Training Loss: 0.3914%\n",
      "Epoch [299/300], Step [13/23], Training Accuracy: 73.9183%, Training Loss: 0.3943%\n",
      "Epoch [299/300], Step [14/23], Training Accuracy: 74.6652%, Training Loss: 0.3910%\n",
      "Epoch [299/300], Step [15/23], Training Accuracy: 74.4792%, Training Loss: 0.3931%\n",
      "Epoch [299/300], Step [16/23], Training Accuracy: 74.3164%, Training Loss: 0.3950%\n",
      "Epoch [299/300], Step [17/23], Training Accuracy: 74.7243%, Training Loss: 0.3948%\n",
      "Epoch [299/300], Step [18/23], Training Accuracy: 74.5660%, Training Loss: 0.3951%\n",
      "Epoch [299/300], Step [19/23], Training Accuracy: 74.6711%, Training Loss: 0.3945%\n",
      "Epoch [299/300], Step [20/23], Training Accuracy: 74.8438%, Training Loss: 0.3935%\n",
      "Epoch [299/300], Step [21/23], Training Accuracy: 74.8512%, Training Loss: 0.3929%\n",
      "Epoch [299/300], Step [22/23], Training Accuracy: 74.9290%, Training Loss: 0.3926%\n",
      "Epoch [299/300], Step [23/23], Training Accuracy: 75.1911%, Training Loss: 0.3886%\n",
      "Epoch [300/300], Step [1/23], Training Accuracy: 76.5625%, Training Loss: 0.3813%\n",
      "Epoch [300/300], Step [2/23], Training Accuracy: 78.1250%, Training Loss: 0.3914%\n",
      "Epoch [300/300], Step [3/23], Training Accuracy: 74.4792%, Training Loss: 0.4059%\n",
      "Epoch [300/300], Step [4/23], Training Accuracy: 75.7812%, Training Loss: 0.3885%\n",
      "Epoch [300/300], Step [5/23], Training Accuracy: 74.6875%, Training Loss: 0.3901%\n",
      "Epoch [300/300], Step [6/23], Training Accuracy: 74.7396%, Training Loss: 0.3903%\n",
      "Epoch [300/300], Step [7/23], Training Accuracy: 75.0000%, Training Loss: 0.3958%\n",
      "Epoch [300/300], Step [8/23], Training Accuracy: 75.1953%, Training Loss: 0.3950%\n",
      "Epoch [300/300], Step [9/23], Training Accuracy: 74.8264%, Training Loss: 0.3973%\n",
      "Epoch [300/300], Step [10/23], Training Accuracy: 74.0625%, Training Loss: 0.3961%\n",
      "Epoch [300/300], Step [11/23], Training Accuracy: 74.5739%, Training Loss: 0.3970%\n",
      "Epoch [300/300], Step [12/23], Training Accuracy: 74.7396%, Training Loss: 0.3964%\n",
      "Epoch [300/300], Step [13/23], Training Accuracy: 74.3990%, Training Loss: 0.3984%\n",
      "Epoch [300/300], Step [14/23], Training Accuracy: 74.5536%, Training Loss: 0.3956%\n",
      "Epoch [300/300], Step [15/23], Training Accuracy: 74.3750%, Training Loss: 0.3968%\n",
      "Epoch [300/300], Step [16/23], Training Accuracy: 74.3164%, Training Loss: 0.3976%\n",
      "Epoch [300/300], Step [17/23], Training Accuracy: 74.2647%, Training Loss: 0.3983%\n",
      "Epoch [300/300], Step [18/23], Training Accuracy: 74.3056%, Training Loss: 0.3980%\n",
      "Epoch [300/300], Step [19/23], Training Accuracy: 74.1776%, Training Loss: 0.3980%\n",
      "Epoch [300/300], Step [20/23], Training Accuracy: 74.4531%, Training Loss: 0.3959%\n",
      "Epoch [300/300], Step [21/23], Training Accuracy: 73.7351%, Training Loss: 0.3970%\n",
      "Epoch [300/300], Step [22/23], Training Accuracy: 73.7216%, Training Loss: 0.3971%\n",
      "Epoch [300/300], Step [23/23], Training Accuracy: 73.8013%, Training Loss: 0.3929%\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "total_step = len(train_loader)\n",
    "for ep in range(total_epoch):\n",
    "    global_enc.train(), local_enc.train(), local_disc.train(), global_disc.train(), mine.train(), decomposer.train(), classifier.train()\n",
    "    correct=0\n",
    "    total=0\n",
    "    running_loss = 0\n",
    "    for bidx, (batchx, batchy) in enumerate(train_loader):\n",
    "        batchx = batchx.to(device)\n",
    "        batchy = batchy.to(device)\n",
    "        # Reset gradient\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # Feed input to enocders and then obtain local feature (relevant, irrelevant) and global feature\n",
    "        localf = local_enc(batchx) #[batch, d1, 1, t1]\n",
    "        rele, irre = decomposer(localf) #[batch, d1, 1, t1], #[batch, depth, 1, t1]\n",
    "        globalf = global_enc(rele) #[batch, d2]\n",
    "\n",
    "        # Feed the relevant feature to classifier\n",
    "        logits = classifier(globalf) #[batch, 4]\n",
    "        loss_class = cls_criterion(logits, batchy)\n",
    "\n",
    "        # To ensure good decomposition, estimate MI between relevant feature and irrelevant feature\n",
    "        rele_ = torch.reshape(rele, (rele.shape[0], -1)) #[batch, d1*t1]\n",
    "        irre_ = torch.reshape(irre, (irre.shape[0], -1)) #[batch, d1*t1]\n",
    "        ishuffle = torch.index_select(irre_, 0, torch.randperm(irre_.shape[0]).to(device))\n",
    "        djoint = mine(rele_, irre_) #[batch, 1]\n",
    "        dmarginal = mine(rele_, ishuffle) #[batch, 1]\n",
    "        loss_decomposition = - estimate_JSD_MI(djoint, dmarginal, True)\n",
    "\n",
    "        # Estimate global MI\n",
    "        gshuffle = torch.index_select(globalf, 0, torch.randperm(globalf.shape[0]).to(device)) #[batch, d2]\n",
    "        gjoint = global_disc(rele, globalf) #[batch, 1]\n",
    "        gmarginal = global_disc(rele, gshuffle) #[batch, 1]\n",
    "        loss_global_mi = estimate_JSD_MI(gjoint, gmarginal, True)\n",
    "\n",
    "        # Estimate local MI\n",
    "        ljoint = local_disc(rele, globalf)\n",
    "        lmarginal = local_disc(rele, gshuffle)\n",
    "        temp = estimate_JSD_MI(ljoint, lmarginal, False)\n",
    "        loss_local_mi = temp.mean()\n",
    "\n",
    "        loss_dim = - (loss_global_mi + loss_local_mi)\n",
    "\n",
    "        # All objective function\n",
    "        loss_all = alpha * loss_class + beta * loss_decomposition + gamma * loss_dim\n",
    "\n",
    "        loss_all.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        _, predicted = logits.max(1)\n",
    "        total += batchy.size(0)\n",
    "        correct += predicted.eq(batchy).sum().item()\n",
    "        running_loss += loss_all.item()\n",
    "        accu=100.*correct/total\n",
    "        train_loss = running_loss/(bidx+1)\n",
    "        print ('Epoch [{}/{}], Step [{}/{}], Training Accuracy: {:.4f}%, Training Loss: {:.4f}%'.format(ep+1, total_epoch, bidx+1, total_step, accu, train_loss))\n",
    "\n",
    "    scheduler.step()  # learning rate decay\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cda1d108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 62.77777777777778 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    global_enc.eval(), global_disc.eval(), local_enc.eval(), local_disc.eval(), mine.eval(), classifier.eval(), decomposer.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for X, Y in test_loader:\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        localf = local_enc(X)\n",
    "        rele, irre = decomposer(localf) \n",
    "        globalf = global_enc(rele)\n",
    "        logits = classifier(globalf) \n",
    "        \n",
    "        _, predicted = torch.max(logits.data, 1)\n",
    "        total += Y.size(0)\n",
    "        correct += (predicted == Y).sum().item()\n",
    "\n",
    "    print('Test Accuracy : {} %'.format(100 * correct / total))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feadc1ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6febe9de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826d4e44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce71586",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
