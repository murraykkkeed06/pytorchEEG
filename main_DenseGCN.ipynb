{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce5e4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murray\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\murray\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\murray\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\murray\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\murray\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\murray\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from gcn_scripts import DenseGCN_Model, graph, coarsening\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8a3116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"data/final_format/train_set.csv\",header=None).to_numpy()\n",
    "train_label = pd.read_csv(\"data/final_format/train_label.csv\",header=None).to_numpy()\n",
    "test_set = pd.read_csv(\"data/final_format/test_set.csv\",header=None).to_numpy()\n",
    "test_label = pd.read_csv(\"data/final_format/test_label.csv\",header=None).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37f64e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14393, 4096) (14393, 1) (3599, 4096) (3599, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_set.shape, train_label.shape, test_set.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27d522cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14392, 4096) (14392, 1) (3598, 4096) (3598, 1)\n"
     ]
    }
   ],
   "source": [
    "#delet first row data\n",
    "train_set = train_set[1:]\n",
    "train_label = train_label[1:]\n",
    "test_set = test_set[1:]\n",
    "test_label = test_label[1:]\n",
    "print(train_set.shape, train_label.shape, test_set.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65794c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14392, 64, 64) (14392,) (3598, 64, 64) (3598,)\n"
     ]
    }
   ],
   "source": [
    "train_set = train_set.reshape((-1,64,64))\n",
    "train_set = np.transpose(train_set, (0, 2, 1))\n",
    "test_set = test_set.reshape((-1,64,64))\n",
    "test_set = np.transpose(test_set, (0, 2, 1))\n",
    "train_label = train_label.reshape(-1)\n",
    "test_label = test_label.reshape(-1)\n",
    "print(train_set.shape, train_label.shape, test_set.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94ecca77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(921088, 64) (921088,) (230272, 64) (230272,)\n"
     ]
    }
   ],
   "source": [
    "#set data for gcn model\n",
    "train_label_holder = np.ones((0))\n",
    "test_label_holder = np.ones((0))\n",
    "\n",
    "for i in range(train_set.shape[0]):\n",
    "    temp = np.full((64), train_label[i])\n",
    "    train_label_holder = np.concatenate((train_label_holder, temp), axis=0)\n",
    "    \n",
    "for i in range(test_set.shape[0]):\n",
    "    temp = np.full((64), test_label[i])\n",
    "    test_label_holder = np.concatenate((test_label_holder, temp), axis=0)\n",
    "\n",
    "train_set = train_set.reshape((-1,64))\n",
    "test_set = test_set.reshape((-1,64))\n",
    "train_label = train_label_holder\n",
    "test_label = test_label_holder\n",
    "print(train_set.shape, train_label.shape, test_set.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fb5d3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist, idx = graph.distance_scipy_spatial(train_set.T, k=10, metric='euclidean')\n",
    "A = graph.adjacency(dist, idx).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "763ec0f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.spy(A, markersize=2, color='black');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb21e36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: M_0 = |V| = 96 nodes (32 added),|E| = 401 edges\n",
      "Layer 1: M_1 = |V| = 48 nodes (15 added),|E| = 167 edges\n",
      "Layer 2: M_2 = |V| = 24 nodes (7 added),|E| = 60 edges\n",
      "Layer 3: M_3 = |V| = 12 nodes (3 added),|E| = 24 edges\n",
      "Layer 4: M_4 = |V| = 6 nodes (1 added),|E| = 9 edges\n",
      "Layer 5: M_5 = |V| = 3 nodes (0 added),|E| = 3 edges\n"
     ]
    }
   ],
   "source": [
    "graphs, perm = coarsening.coarsen(A, levels=5, self_connections=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9ed3538",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = coarsening.perm_data(train_set, perm)\n",
    "X_test  = coarsening.perm_data(test_set,  perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "402afeac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "L = [graph.laplacian(A, normalized=True) for A in graphs]\n",
    "graph.plot_spectrum(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e28efe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict()\n",
    "params['dir_name']       = 'DenseGCN'\n",
    "params['num_epochs']     = 300\n",
    "params['batch_size']     = 1024\n",
    "params['eval_frequency'] = 100\n",
    "\n",
    "# Building blocks.\n",
    "params['filter'] = 'chebyshev5'\n",
    "params['brelu']  = 'b2relu'\n",
    "params['pool']   = 'mpool1'\n",
    "\n",
    "# Architecture.\n",
    "params['F'] = [16, 32, 64, 128, 256, 512]         # Number of graph convolutional filters.\n",
    "params['K'] = [2, 2, 2, 2, 2, 2]                  # Polynomial orders.\n",
    "params['p'] = [1, 1, 1, 1, 1, 1]                  # Pooling sizes.\n",
    "params['M'] = [4]                                 # Output dimensionality of fully connected layers.\n",
    "\n",
    "# Optimization.\n",
    "params['regularization'] = 0.001     # L2 regularization\n",
    "params['dropout']        = 0.50      # Dropout rate\n",
    "params['learning_rate']  = 0.01      # Learning rate\n",
    "params['decay_rate']     = 1         # Learning rate Decay == 1 means no Decay\n",
    "params['momentum']       = 0         # momentum == 0 means Use Adam Optimizer\n",
    "params['decay_steps']    = np.shape(train_set)[0] / params['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84927873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN architecture\n",
      "input: M_0 = 96\n",
      "layer 1: cgconv1\n",
      "representation: M_0 * F_1 / p_1 = 96 * 16 / 1 = 1536\n",
      "weights: F_0 * F_1 * K_1 = 1 * 16 * 2 = 32\n",
      "biases: M_1 * F_1 = 96 * 16 = 1536\n",
      "layer 2: cgconv2\n",
      "representation: M_1 * F_2 / p_2 = 96 * 32 / 1 = 3072\n",
      "weights: F_1 * F_2 * K_2 = 16 * 32 * 2 = 1024\n",
      "biases: M_2 * F_2 = 96 * 32 = 3072\n",
      "layer 3: cgconv3\n",
      "representation: M_2 * F_3 / p_3 = 96 * 64 / 1 = 6144\n",
      "weights: F_2 * F_3 * K_3 = 32 * 64 * 2 = 4096\n",
      "biases: M_3 * F_3 = 96 * 64 = 6144\n",
      "layer 4: cgconv4\n",
      "representation: M_3 * F_4 / p_4 = 96 * 128 / 1 = 12288\n",
      "weights: F_3 * F_4 * K_4 = 64 * 128 * 2 = 16384\n",
      "biases: M_4 * F_4 = 96 * 128 = 12288\n",
      "layer 5: cgconv5\n",
      "representation: M_4 * F_5 / p_5 = 96 * 256 / 1 = 24576\n",
      "weights: F_4 * F_5 * K_5 = 128 * 256 * 2 = 65536\n",
      "biases: M_5 * F_5 = 96 * 256 = 24576\n",
      "layer 6: cgconv6\n",
      "representation: M_5 * F_6 / p_6 = 96 * 512 / 1 = 49152\n",
      "weights: F_5 * F_6 * K_6 = 256 * 512 * 2 = 262144\n",
      "biases: M_6 * F_6 = 96 * 512 = 49152\n",
      "layer 7: logits (softmax)\n",
      "representation: M_7 = 4\n",
      "weights: M_6 * M_7 = 49152 * 4 = 196608\n",
      "biases: M_7 = 4\n",
      "WARNING:tensorflow:From C:\\Users\\murray\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\murray\\pytorchEEG\\gcn_scripts\\DenseGCN_Model.py:590: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From C:\\Users\\murray\\pytorchEEG\\gcn_scripts\\DenseGCN_Model.py:212: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\murray\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "warning: logits/batch_normalization/gamma has no gradient\n",
      "warning: logits/batch_normalization/beta has no gradient\n",
      "step 100 / 269850 (epoch 0.11 / 300):\n",
      "learning_rate = 0.010000, loss_average = 1.517309\n",
      "Training   accuracy: 30.175781 (309 / 1024), f1 (weighted): 24.051307, loss: 1.470002\n",
      "validation accuracy: 29.602818 (68167 / 230272), f1 (weighted): 22.079421, loss: 1.477351\n",
      "time: 58s (wall 40s)\n",
      "\n",
      "\n",
      "step 200 / 269850 (epoch 0.22 / 300):\n",
      "learning_rate = 0.010000, loss_average = 1.323800\n",
      "Training   accuracy: 38.476562 (394 / 1024), f1 (weighted): 34.964069, loss: 1.289062\n",
      "validation accuracy: 34.173933 (78693 / 230272), f1 (weighted): 30.229900, loss: 1.331541\n",
      "time: 115s (wall 79s)\n",
      "\n",
      "\n",
      "step 300 / 269850 (epoch 0.33 / 300):\n",
      "learning_rate = 0.010000, loss_average = 1.281403\n",
      "Training   accuracy: 38.085938 (390 / 1024), f1 (weighted): 32.907605, loss: 1.261159\n",
      "validation accuracy: 35.946620 (82775 / 230272), f1 (weighted): 31.558959, loss: 1.308094\n",
      "time: 173s (wall 118s)\n",
      "\n",
      "\n",
      "step 400 / 269850 (epoch 0.44 / 300):\n",
      "learning_rate = 0.010000, loss_average = 1.276582\n",
      "Training   accuracy: 40.527344 (415 / 1024), f1 (weighted): 35.595271, loss: 1.258575\n",
      "validation accuracy: 37.168653 (85589 / 230272), f1 (weighted): 31.819528, loss: 1.308301\n",
      "time: 231s (wall 158s)\n",
      "\n",
      "\n",
      "step 500 / 269850 (epoch 0.56 / 300):\n",
      "learning_rate = 0.010000, loss_average = 1.244224\n",
      "Training   accuracy: 42.773438 (438 / 1024), f1 (weighted): 40.889287, loss: 1.237980\n",
      "validation accuracy: 39.314810 (90531 / 230272), f1 (weighted): 36.766741, loss: 1.280393\n",
      "time: 288s (wall 197s)\n",
      "\n",
      "\n",
      "step 600 / 269850 (epoch 0.67 / 300):\n",
      "learning_rate = 0.010000, loss_average = 1.215002\n",
      "Training   accuracy: 41.992188 (430 / 1024), f1 (weighted): 40.448087, loss: 1.216657\n",
      "validation accuracy: 39.610113 (91211 / 230272), f1 (weighted): 38.329629, loss: 1.278977\n",
      "time: 346s (wall 236s)\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\murray\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "step 700 / 269850 (epoch 0.78 / 300):\n",
      "learning_rate = 0.010000, loss_average = 1.204670\n",
      "Training   accuracy: 44.726562 (458 / 1024), f1 (weighted): 41.113251, loss: 1.198807\n",
      "validation accuracy: 38.850577 (89462 / 230272), f1 (weighted): 36.339874, loss: 1.287824\n",
      "time: 403s (wall 275s)\n",
      "\n",
      "\n",
      "step 800 / 269850 (epoch 0.89 / 300):\n",
      "learning_rate = 0.010000, loss_average = 1.180728\n",
      "Training   accuracy: 51.562500 (528 / 1024), f1 (weighted): 51.189964, loss: 1.130456\n",
      "validation accuracy: 42.304753 (97416 / 230272), f1 (weighted): 41.750957, loss: 1.245541\n",
      "time: 460s (wall 314s)\n",
      "\n",
      "\n",
      "step 900 / 269850 (epoch 1.00 / 300):\n",
      "learning_rate = 0.010000, loss_average = 1.173541\n",
      "Training   accuracy: 46.972656 (481 / 1024), f1 (weighted): 45.785824, loss: 1.161132\n",
      "validation accuracy: 42.690384 (98304 / 230272), f1 (weighted): 41.672669, loss: 1.245609\n",
      "time: 520s (wall 354s)\n",
      "\n",
      "\n",
      "step 1000 / 269850 (epoch 1.11 / 300):\n",
      "learning_rate = 0.010000, loss_average = 1.151136\n",
      "Training   accuracy: 47.070312 (482 / 1024), f1 (weighted): 42.079250, loss: 1.155328\n",
      "validation accuracy: 42.445456 (97740 / 230272), f1 (weighted): 38.219529, loss: 1.270638\n",
      "time: 586s (wall 399s)\n",
      "\n",
      "\n",
      "step 1100 / 269850 (epoch 1.22 / 300):\n",
      "learning_rate = 0.010000, loss_average = 1.120271\n",
      "Training   accuracy: 53.320312 (546 / 1024), f1 (weighted): 51.590869, loss: 1.076958\n",
      "validation accuracy: 44.276768 (101957 / 230272), f1 (weighted): 42.901664, loss: 1.229460\n",
      "time: 650s (wall 443s)\n",
      "\n",
      "\n",
      "step 1200 / 269850 (epoch 1.33 / 300):\n",
      "learning_rate = 0.010000, loss_average = 1.118733\n",
      "Training   accuracy: 49.609375 (508 / 1024), f1 (weighted): 49.818054, loss: 1.107435\n",
      "validation accuracy: 45.487945 (104746 / 230272), f1 (weighted): 45.701341, loss: 1.215458\n",
      "time: 713s (wall 486s)\n",
      "\n",
      "\n",
      "step 1300 / 269850 (epoch 1.45 / 300):\n",
      "learning_rate = 0.010000, loss_average = 1.099105\n",
      "Training   accuracy: 53.125000 (544 / 1024), f1 (weighted): 52.732917, loss: 1.084347\n",
      "validation accuracy: 45.284273 (104277 / 230272), f1 (weighted): 45.264888, loss: 1.223771\n",
      "time: 774s (wall 529s)\n",
      "\n",
      "\n",
      "step 1400 / 269850 (epoch 1.56 / 300):\n",
      "learning_rate = 0.010000, loss_average = 1.071966\n",
      "Training   accuracy: 52.734375 (540 / 1024), f1 (weighted): 51.483363, loss: 1.056322\n",
      "validation accuracy: 45.521818 (104824 / 230272), f1 (weighted): 45.195581, loss: 1.210595\n",
      "time: 832s (wall 569s)\n",
      "\n",
      "\n",
      "step 1500 / 269850 (epoch 1.67 / 300):\n",
      "learning_rate = 0.010000, loss_average = 1.059779\n",
      "Training   accuracy: 55.078125 (564 / 1024), f1 (weighted): 54.671619, loss: 1.047649\n",
      "validation accuracy: 47.668844 (109768 / 230272), f1 (weighted): 46.958524, loss: 1.180163\n",
      "time: 890s (wall 608s)\n",
      "\n",
      "\n",
      "step 1600 / 269850 (epoch 1.78 / 300):\n",
      "learning_rate = 0.010000, loss_average = 1.049547\n",
      "Training   accuracy: 55.273438 (566 / 1024), f1 (weighted): 54.757932, loss: 1.032340\n",
      "validation accuracy: 46.546693 (107184 / 230272), f1 (weighted): 45.535050, loss: 1.206269\n",
      "time: 951s (wall 650s)\n",
      "\n",
      "\n",
      "step 1700 / 269850 (epoch 1.89 / 300):\n",
      "learning_rate = 0.010000, loss_average = 1.021393\n",
      "Training   accuracy: 58.300781 (597 / 1024), f1 (weighted): 57.886776, loss: 0.979819\n",
      "validation accuracy: 49.124948 (113121 / 230272), f1 (weighted): 48.147243, loss: 1.164992\n",
      "time: 1010s (wall 692s)\n",
      "\n",
      "\n",
      "step 1800 / 269850 (epoch 2.00 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.998172\n",
      "Training   accuracy: 58.496094 (599 / 1024), f1 (weighted): 57.330096, loss: 0.985057\n",
      "validation accuracy: 48.812274 (112401 / 230272), f1 (weighted): 47.386919, loss: 1.176976\n",
      "time: 1069s (wall 732s)\n",
      "\n",
      "\n",
      "step 1900 / 269850 (epoch 2.11 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.982633\n",
      "Training   accuracy: 61.132812 (626 / 1024), f1 (weighted): 60.374926, loss: 0.943070\n",
      "validation accuracy: 50.201501 (115600 / 230272), f1 (weighted): 49.179198, loss: 1.154949\n",
      "time: 1130s (wall 774s)\n",
      "\n",
      "\n",
      "step 2000 / 269850 (epoch 2.22 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.965647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training   accuracy: 58.691406 (601 / 1024), f1 (weighted): 58.562140, loss: 0.964029\n",
      "validation accuracy: 50.931507 (117281 / 230272), f1 (weighted): 50.347762, loss: 1.145522\n",
      "time: 1190s (wall 815s)\n",
      "\n",
      "\n",
      "step 2100 / 269850 (epoch 2.33 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.937116\n",
      "Training   accuracy: 62.011719 (635 / 1024), f1 (weighted): 61.647694, loss: 0.912085\n",
      "validation accuracy: 50.650101 (116633 / 230272), f1 (weighted): 49.649193, loss: 1.155773\n",
      "time: 1249s (wall 856s)\n",
      "\n",
      "\n",
      "step 2200 / 269850 (epoch 2.45 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.932010\n",
      "Training   accuracy: 61.816406 (633 / 1024), f1 (weighted): 61.575114, loss: 0.905276\n",
      "validation accuracy: 50.693093 (116732 / 230272), f1 (weighted): 49.810609, loss: 1.158803\n",
      "time: 1307s (wall 896s)\n",
      "\n",
      "\n",
      "step 2300 / 269850 (epoch 2.56 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.907928\n",
      "Training   accuracy: 62.011719 (635 / 1024), f1 (weighted): 61.625991, loss: 0.913522\n",
      "validation accuracy: 52.490967 (120872 / 230272), f1 (weighted): 51.773248, loss: 1.118726\n",
      "time: 1365s (wall 935s)\n",
      "\n",
      "\n",
      "step 2400 / 269850 (epoch 2.67 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.902397\n",
      "Training   accuracy: 63.378906 (649 / 1024), f1 (weighted): 63.179803, loss: 0.894564\n",
      "validation accuracy: 52.211298 (120228 / 230272), f1 (weighted): 51.812945, loss: 1.128056\n",
      "time: 1423s (wall 975s)\n",
      "\n",
      "\n",
      "step 2500 / 269850 (epoch 2.78 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.895415\n",
      "Training   accuracy: 64.941406 (665 / 1024), f1 (weighted): 65.266280, loss: 0.880285\n",
      "validation accuracy: 50.167628 (115522 / 230272), f1 (weighted): 50.396944, loss: 1.166028\n",
      "time: 1484s (wall 1016s)\n",
      "\n",
      "\n",
      "step 2600 / 269850 (epoch 2.89 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.859284\n",
      "Training   accuracy: 67.187500 (688 / 1024), f1 (weighted): 66.711309, loss: 0.825962\n",
      "validation accuracy: 53.864560 (124035 / 230272), f1 (weighted): 53.218401, loss: 1.099738\n",
      "time: 1546s (wall 1059s)\n",
      "\n",
      "\n",
      "step 2700 / 269850 (epoch 3.00 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.857653\n",
      "Training   accuracy: 67.285156 (689 / 1024), f1 (weighted): 67.048466, loss: 0.814751\n",
      "validation accuracy: 54.058244 (124481 / 230272), f1 (weighted): 53.963405, loss: 1.091146\n",
      "time: 1606s (wall 1100s)\n",
      "\n",
      "\n",
      "step 2800 / 269850 (epoch 3.11 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.833024\n",
      "Training   accuracy: 67.871094 (695 / 1024), f1 (weighted): 67.161481, loss: 0.802093\n",
      "validation accuracy: 54.498159 (125494 / 230272), f1 (weighted): 53.259374, loss: 1.103839\n",
      "time: 1666s (wall 1141s)\n",
      "\n",
      "\n",
      "step 2900 / 269850 (epoch 3.22 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.808560\n",
      "Training   accuracy: 66.699219 (683 / 1024), f1 (weighted): 66.694142, loss: 0.806293\n",
      "validation accuracy: 54.976723 (126596 / 230272), f1 (weighted): 55.088941, loss: 1.074588\n",
      "time: 1725s (wall 1182s)\n",
      "\n",
      "\n",
      "step 3000 / 269850 (epoch 3.34 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.808307\n",
      "Training   accuracy: 70.800781 (725 / 1024), f1 (weighted): 70.716625, loss: 0.762182\n",
      "validation accuracy: 55.687187 (128232 / 230272), f1 (weighted): 55.551852, loss: 1.068280\n",
      "time: 1783s (wall 1222s)\n",
      "\n",
      "\n",
      "step 3100 / 269850 (epoch 3.45 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.789327\n",
      "Training   accuracy: 69.824219 (715 / 1024), f1 (weighted): 69.712032, loss: 0.747443\n",
      "validation accuracy: 56.123193 (129236 / 230272), f1 (weighted): 55.474886, loss: 1.067172\n",
      "time: 1840s (wall 1261s)\n",
      "\n",
      "\n",
      "step 3200 / 269850 (epoch 3.56 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.783861\n",
      "Training   accuracy: 67.382812 (690 / 1024), f1 (weighted): 66.909914, loss: 0.781703\n",
      "validation accuracy: 55.110912 (126905 / 230272), f1 (weighted): 54.231136, loss: 1.097799\n",
      "time: 1897s (wall 1300s)\n",
      "\n",
      "\n",
      "step 3300 / 269850 (epoch 3.67 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.772586\n",
      "Training   accuracy: 70.117188 (718 / 1024), f1 (weighted): 70.021423, loss: 0.765983\n",
      "validation accuracy: 55.557341 (127933 / 230272), f1 (weighted): 55.549084, loss: 1.074665\n",
      "time: 1955s (wall 1339s)\n",
      "\n",
      "\n",
      "step 3400 / 269850 (epoch 3.78 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.763277\n",
      "Training   accuracy: 71.289062 (730 / 1024), f1 (weighted): 71.165733, loss: 0.720942\n",
      "validation accuracy: 56.656476 (130464 / 230272), f1 (weighted): 56.150280, loss: 1.063711\n",
      "time: 2012s (wall 1378s)\n",
      "\n",
      "\n",
      "step 3500 / 269850 (epoch 3.89 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.748229\n",
      "Training   accuracy: 71.582031 (733 / 1024), f1 (weighted): 71.560468, loss: 0.743882\n",
      "validation accuracy: 56.606101 (130348 / 230272), f1 (weighted): 56.460792, loss: 1.047275\n",
      "time: 2070s (wall 1418s)\n",
      "\n",
      "\n",
      "step 3600 / 269850 (epoch 4.00 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.736637\n",
      "Training   accuracy: 72.753906 (745 / 1024), f1 (weighted): 72.700787, loss: 0.710493\n",
      "validation accuracy: 57.307879 (131964 / 230272), f1 (weighted): 57.352262, loss: 1.036987\n",
      "time: 2129s (wall 1458s)\n",
      "\n",
      "\n",
      "step 3700 / 269850 (epoch 4.11 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.725306\n",
      "Training   accuracy: 70.996094 (727 / 1024), f1 (weighted): 71.266038, loss: 0.708416\n",
      "validation accuracy: 56.557462 (130236 / 230272), f1 (weighted): 56.988139, loss: 1.054957\n",
      "time: 2187s (wall 1498s)\n",
      "\n",
      "\n",
      "step 3800 / 269850 (epoch 4.22 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.723115\n",
      "Training   accuracy: 74.902344 (767 / 1024), f1 (weighted): 74.583245, loss: 0.663791\n",
      "validation accuracy: 57.561927 (132549 / 230272), f1 (weighted): 56.751241, loss: 1.053051\n",
      "time: 2245s (wall 1538s)\n",
      "\n",
      "\n",
      "step 3900 / 269850 (epoch 4.34 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.732257\n",
      "Training   accuracy: 72.949219 (747 / 1024), f1 (weighted): 73.445411, loss: 0.669927\n",
      "validation accuracy: 56.392440 (129856 / 230272), f1 (weighted): 57.185406, loss: 1.083132\n",
      "time: 2303s (wall 1577s)\n",
      "\n",
      "\n",
      "step 4000 / 269850 (epoch 4.45 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.697694\n",
      "Training   accuracy: 73.730469 (755 / 1024), f1 (weighted): 73.339715, loss: 0.664270\n",
      "validation accuracy: 57.400813 (132178 / 230272), f1 (weighted): 56.302670, loss: 1.086185\n",
      "time: 2362s (wall 1617s)\n",
      "\n",
      "\n",
      "step 4100 / 269850 (epoch 4.56 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.687673\n",
      "Training   accuracy: 74.707031 (765 / 1024), f1 (weighted): 74.309568, loss: 0.658679\n",
      "validation accuracy: 57.279218 (131898 / 230272), f1 (weighted): 56.310500, loss: 1.091275\n",
      "time: 2419s (wall 1657s)\n",
      "\n",
      "\n",
      "step 4200 / 269850 (epoch 4.67 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.678721\n",
      "Training   accuracy: 76.269531 (781 / 1024), f1 (weighted): 76.140040, loss: 0.648216\n",
      "validation accuracy: 57.973614 (133497 / 230272), f1 (weighted): 57.508019, loss: 1.058808\n",
      "time: 2477s (wall 1696s)\n",
      "\n",
      "\n",
      "step 4300 / 269850 (epoch 4.78 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.664080\n",
      "Training   accuracy: 77.539062 (794 / 1024), f1 (weighted): 77.691692, loss: 0.585091\n",
      "validation accuracy: 59.166985 (136245 / 230272), f1 (weighted): 59.119084, loss: 1.019226\n",
      "time: 2534s (wall 1735s)\n",
      "\n",
      "\n",
      "step 4400 / 269850 (epoch 4.89 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.668270\n",
      "Training   accuracy: 76.757812 (786 / 1024), f1 (weighted): 76.430833, loss: 0.642701\n",
      "validation accuracy: 58.298013 (134244 / 230272), f1 (weighted): 57.444260, loss: 1.064772\n",
      "time: 2592s (wall 1774s)\n",
      "\n",
      "\n",
      "step 4500 / 269850 (epoch 5.00 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.662244\n",
      "Training   accuracy: 76.660156 (785 / 1024), f1 (weighted): 76.370375, loss: 0.624150\n",
      "validation accuracy: 59.650761 (137359 / 230272), f1 (weighted): 59.214109, loss: 1.023532\n",
      "time: 2649s (wall 1813s)\n",
      "\n",
      "\n",
      "step 4600 / 269850 (epoch 5.11 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.656022\n",
      "Training   accuracy: 74.902344 (767 / 1024), f1 (weighted): 74.578654, loss: 0.628640\n",
      "validation accuracy: 58.383130 (134440 / 230272), f1 (weighted): 57.511268, loss: 1.047651\n",
      "time: 2706s (wall 1852s)\n",
      "\n",
      "\n",
      "step 4700 / 269850 (epoch 5.23 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.642998\n",
      "Training   accuracy: 75.878906 (777 / 1024), f1 (weighted): 75.684507, loss: 0.582901\n",
      "validation accuracy: 59.573027 (137180 / 230272), f1 (weighted): 59.427755, loss: 1.016282\n",
      "time: 2764s (wall 1891s)\n",
      "\n",
      "\n",
      "step 4800 / 269850 (epoch 5.34 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.638306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training   accuracy: 78.125000 (800 / 1024), f1 (weighted): 77.930978, loss: 0.588588\n",
      "validation accuracy: 58.998054 (135856 / 230272), f1 (weighted): 58.246184, loss: 1.037694\n",
      "time: 2821s (wall 1930s)\n",
      "\n",
      "\n",
      "step 4900 / 269850 (epoch 5.45 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.650986\n",
      "Training   accuracy: 74.804688 (766 / 1024), f1 (weighted): 74.698132, loss: 0.611653\n",
      "validation accuracy: 58.704054 (135179 / 230272), f1 (weighted): 58.510271, loss: 1.045938\n",
      "time: 2879s (wall 1969s)\n",
      "\n",
      "\n",
      "step 5000 / 269850 (epoch 5.56 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.646994\n",
      "Training   accuracy: 76.953125 (788 / 1024), f1 (weighted): 76.759669, loss: 0.607047\n",
      "validation accuracy: 59.120084 (136137 / 230272), f1 (weighted): 58.963745, loss: 1.027933\n",
      "time: 2936s (wall 2008s)\n",
      "\n",
      "\n",
      "step 5100 / 269850 (epoch 5.67 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.621348\n",
      "Training   accuracy: 77.636719 (795 / 1024), f1 (weighted): 77.488473, loss: 0.584651\n",
      "validation accuracy: 60.435485 (139166 / 230272), f1 (weighted): 60.266909, loss: 1.003177\n",
      "time: 2993s (wall 2047s)\n",
      "\n",
      "\n",
      "step 5200 / 269850 (epoch 5.78 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.629434\n",
      "Training   accuracy: 76.855469 (787 / 1024), f1 (weighted): 76.839574, loss: 0.577109\n",
      "validation accuracy: 59.450563 (136898 / 230272), f1 (weighted): 59.142644, loss: 1.032104\n",
      "time: 3051s (wall 2086s)\n",
      "\n",
      "\n",
      "step 5300 / 269850 (epoch 5.89 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.640408\n",
      "Training   accuracy: 77.246094 (791 / 1024), f1 (weighted): 77.184738, loss: 0.604829\n",
      "validation accuracy: 59.669434 (137402 / 230272), f1 (weighted): 59.452346, loss: 1.016490\n",
      "time: 3108s (wall 2125s)\n",
      "\n",
      "\n",
      "step 5400 / 269850 (epoch 6.00 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.753412\n",
      "Training   accuracy: 76.953125 (788 / 1024), f1 (weighted): 76.959695, loss: 0.637898\n",
      "validation accuracy: 58.697106 (135163 / 230272), f1 (weighted): 58.604182, loss: 1.116255\n",
      "time: 3165s (wall 2164s)\n",
      "\n",
      "\n",
      "step 5500 / 269850 (epoch 6.11 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.594145\n",
      "Training   accuracy: 79.589844 (815 / 1024), f1 (weighted): 79.665336, loss: 0.556697\n",
      "validation accuracy: 60.715154 (139810 / 230272), f1 (weighted): 60.666283, loss: 1.014972\n",
      "time: 3223s (wall 2203s)\n",
      "\n",
      "\n",
      "step 5600 / 269850 (epoch 6.23 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.598010\n",
      "Training   accuracy: 79.785156 (817 / 1024), f1 (weighted): 79.705148, loss: 0.543795\n",
      "validation accuracy: 60.091110 (138373 / 230272), f1 (weighted): 59.521354, loss: 1.035626\n",
      "time: 3280s (wall 2242s)\n",
      "\n",
      "\n",
      "step 5700 / 269850 (epoch 6.34 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.605541\n",
      "Training   accuracy: 79.687500 (816 / 1024), f1 (weighted): 79.573583, loss: 0.553431\n",
      "validation accuracy: 59.691148 (137452 / 230272), f1 (weighted): 59.484126, loss: 1.025877\n",
      "time: 3337s (wall 2281s)\n",
      "\n",
      "\n",
      "step 5800 / 269850 (epoch 6.45 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.595826\n",
      "Training   accuracy: 77.929688 (798 / 1024), f1 (weighted): 77.896473, loss: 0.560748\n",
      "validation accuracy: 60.160593 (138533 / 230272), f1 (weighted): 59.735944, loss: 1.024067\n",
      "time: 3395s (wall 2320s)\n",
      "\n",
      "\n",
      "step 5900 / 269850 (epoch 6.56 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.608034\n",
      "Training   accuracy: 76.660156 (785 / 1024), f1 (weighted): 76.551326, loss: 0.588636\n",
      "validation accuracy: 59.929562 (138001 / 230272), f1 (weighted): 59.555145, loss: 1.035834\n",
      "time: 3452s (wall 2359s)\n",
      "\n",
      "\n",
      "step 6000 / 269850 (epoch 6.67 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.596156\n",
      "Training   accuracy: 79.492188 (814 / 1024), f1 (weighted): 79.312799, loss: 0.544259\n",
      "validation accuracy: 60.947922 (140346 / 230272), f1 (weighted): 60.504276, loss: 0.998682\n",
      "time: 3510s (wall 2398s)\n",
      "\n",
      "\n",
      "step 6100 / 269850 (epoch 6.78 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.604875\n",
      "Training   accuracy: 79.882812 (818 / 1024), f1 (weighted): 79.814596, loss: 0.525101\n",
      "validation accuracy: 60.457198 (139216 / 230272), f1 (weighted): 60.088063, loss: 1.024046\n",
      "time: 3567s (wall 2437s)\n",
      "\n",
      "\n",
      "step 6200 / 269850 (epoch 6.89 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.594454\n",
      "Training   accuracy: 80.468750 (824 / 1024), f1 (weighted): 80.367681, loss: 0.535776\n",
      "validation accuracy: 60.070265 (138325 / 230272), f1 (weighted): 59.964395, loss: 1.014816\n",
      "time: 3625s (wall 2476s)\n",
      "\n",
      "\n",
      "step 6300 / 269850 (epoch 7.00 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.590379\n",
      "Training   accuracy: 79.394531 (813 / 1024), f1 (weighted): 79.155520, loss: 0.539954\n",
      "validation accuracy: 60.617878 (139586 / 230272), f1 (weighted): 59.875421, loss: 1.020738\n",
      "time: 3683s (wall 2516s)\n",
      "\n",
      "\n",
      "step 6400 / 269850 (epoch 7.12 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.576520\n",
      "Training   accuracy: 78.710938 (806 / 1024), f1 (weighted): 78.542527, loss: 0.552930\n",
      "validation accuracy: 60.956174 (140365 / 230272), f1 (weighted): 60.783537, loss: 1.004177\n",
      "time: 3741s (wall 2555s)\n",
      "\n",
      "\n",
      "step 6500 / 269850 (epoch 7.23 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.582295\n",
      "Training   accuracy: 80.957031 (829 / 1024), f1 (weighted): 80.711283, loss: 0.536272\n",
      "validation accuracy: 60.649145 (139658 / 230272), f1 (weighted): 60.129074, loss: 1.019349\n",
      "time: 3799s (wall 2595s)\n",
      "\n",
      "\n",
      "step 6600 / 269850 (epoch 7.34 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.576230\n",
      "Training   accuracy: 82.812500 (848 / 1024), f1 (weighted): 82.729330, loss: 0.529446\n",
      "validation accuracy: 60.759015 (139911 / 230272), f1 (weighted): 60.756310, loss: 1.015072\n",
      "time: 3856s (wall 2634s)\n",
      "\n",
      "\n",
      "step 6700 / 269850 (epoch 7.45 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.565130\n",
      "Training   accuracy: 80.664062 (826 / 1024), f1 (weighted): 80.611677, loss: 0.533350\n",
      "validation accuracy: 60.935329 (140317 / 230272), f1 (weighted): 60.864874, loss: 1.007674\n",
      "time: 3913s (wall 2673s)\n",
      "\n",
      "\n",
      "step 6800 / 269850 (epoch 7.56 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.572804\n",
      "Training   accuracy: 79.492188 (814 / 1024), f1 (weighted): 79.492725, loss: 0.537983\n",
      "validation accuracy: 60.305639 (138867 / 230272), f1 (weighted): 60.150135, loss: 1.025979\n",
      "time: 3971s (wall 2712s)\n",
      "\n",
      "\n",
      "step 6900 / 269850 (epoch 7.67 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.582700\n",
      "Training   accuracy: 78.222656 (801 / 1024), f1 (weighted): 78.055771, loss: 0.572833\n",
      "validation accuracy: 61.171137 (140860 / 230272), f1 (weighted): 60.788069, loss: 1.010664\n",
      "time: 4028s (wall 2751s)\n",
      "\n",
      "\n",
      "step 7000 / 269850 (epoch 7.78 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.595445\n",
      "Training   accuracy: 79.101562 (810 / 1024), f1 (weighted): 79.190718, loss: 0.559089\n",
      "validation accuracy: 61.012194 (140494 / 230272), f1 (weighted): 61.243861, loss: 0.993226\n",
      "time: 4086s (wall 2790s)\n",
      "\n",
      "\n",
      "step 7100 / 269850 (epoch 7.89 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.580723\n",
      "Training   accuracy: 80.175781 (821 / 1024), f1 (weighted): 80.282943, loss: 0.527903\n",
      "validation accuracy: 60.752501 (139896 / 230272), f1 (weighted): 60.777953, loss: 1.011091\n",
      "time: 4145s (wall 2831s)\n",
      "\n",
      "\n",
      "step 7200 / 269850 (epoch 8.00 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.569516\n",
      "Training   accuracy: 77.929688 (798 / 1024), f1 (weighted): 77.832049, loss: 0.573043\n",
      "validation accuracy: 60.159290 (138530 / 230272), f1 (weighted): 59.774973, loss: 1.052300\n",
      "time: 4204s (wall 2871s)\n",
      "\n",
      "\n",
      "step 7300 / 269850 (epoch 8.12 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.573015\n",
      "Training   accuracy: 80.761719 (827 / 1024), f1 (weighted): 80.610491, loss: 0.512390\n",
      "validation accuracy: 61.199798 (140926 / 230272), f1 (weighted): 60.761668, loss: 1.012558\n",
      "time: 4265s (wall 2912s)\n",
      "\n",
      "\n",
      "step 7400 / 269850 (epoch 8.23 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.565278\n",
      "Training   accuracy: 78.320312 (802 / 1024), f1 (weighted): 78.318245, loss: 0.533543\n",
      "validation accuracy: 61.054753 (140592 / 230272), f1 (weighted): 60.727151, loss: 1.020826\n",
      "time: 4326s (wall 2954s)\n",
      "\n",
      "\n",
      "step 7500 / 269850 (epoch 8.34 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.563318\n",
      "Training   accuracy: 79.003906 (809 / 1024), f1 (weighted): 78.806465, loss: 0.561564\n",
      "validation accuracy: 60.549698 (139429 / 230272), f1 (weighted): 60.196818, loss: 1.040978\n",
      "time: 4385s (wall 2995s)\n",
      "\n",
      "\n",
      "step 7600 / 269850 (epoch 8.45 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.554841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training   accuracy: 79.687500 (816 / 1024), f1 (weighted): 79.611114, loss: 0.543811\n",
      "validation accuracy: 60.618747 (139588 / 230272), f1 (weighted): 60.175969, loss: 1.042265\n",
      "time: 4446s (wall 3036s)\n",
      "\n",
      "\n",
      "step 7700 / 269850 (epoch 8.56 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.568992\n",
      "Training   accuracy: 77.246094 (791 / 1024), f1 (weighted): 77.218824, loss: 0.568792\n",
      "validation accuracy: 60.744250 (139877 / 230272), f1 (weighted): 60.629423, loss: 1.030832\n",
      "time: 4515s (wall 3084s)\n",
      "\n",
      "\n",
      "step 7800 / 269850 (epoch 8.67 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.569594\n",
      "Training   accuracy: 80.468750 (824 / 1024), f1 (weighted): 80.398422, loss: 0.533541\n",
      "validation accuracy: 60.682584 (139735 / 230272), f1 (weighted): 60.494185, loss: 1.025727\n",
      "time: 4575s (wall 3125s)\n",
      "\n",
      "\n",
      "step 7900 / 269850 (epoch 8.78 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.563033\n",
      "Training   accuracy: 78.613281 (805 / 1024), f1 (weighted): 78.690513, loss: 0.547785\n",
      "validation accuracy: 61.158109 (140830 / 230272), f1 (weighted): 61.135513, loss: 1.018024\n",
      "time: 4633s (wall 3164s)\n",
      "\n",
      "\n",
      "step 8000 / 269850 (epoch 8.89 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.557080\n",
      "Training   accuracy: 77.636719 (795 / 1024), f1 (weighted): 77.748511, loss: 0.561529\n",
      "validation accuracy: 61.595418 (141837 / 230272), f1 (weighted): 61.758925, loss: 0.988976\n",
      "time: 4691s (wall 3204s)\n",
      "\n",
      "\n",
      "step 8100 / 269850 (epoch 9.01 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.546142\n",
      "Training   accuracy: 81.835938 (838 / 1024), f1 (weighted): 81.886900, loss: 0.498044\n",
      "validation accuracy: 61.415630 (141423 / 230272), f1 (weighted): 61.207412, loss: 1.018606\n",
      "time: 4748s (wall 3243s)\n",
      "\n",
      "\n",
      "step 8200 / 269850 (epoch 9.12 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.540820\n",
      "Training   accuracy: 80.175781 (821 / 1024), f1 (weighted): 80.134162, loss: 0.513791\n",
      "validation accuracy: 61.336593 (141241 / 230272), f1 (weighted): 61.442996, loss: 1.027210\n",
      "time: 4806s (wall 3282s)\n",
      "\n",
      "\n",
      "step 8300 / 269850 (epoch 9.23 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.547425\n",
      "Training   accuracy: 81.640625 (836 / 1024), f1 (weighted): 81.559692, loss: 0.493764\n",
      "validation accuracy: 61.587601 (141819 / 230272), f1 (weighted): 61.382559, loss: 1.016971\n",
      "time: 4863s (wall 3321s)\n",
      "\n",
      "\n",
      "step 8400 / 269850 (epoch 9.34 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.555173\n",
      "Training   accuracy: 78.906250 (808 / 1024), f1 (weighted): 78.999893, loss: 0.544875\n",
      "validation accuracy: 60.917958 (140277 / 230272), f1 (weighted): 61.181385, loss: 1.020814\n",
      "time: 4920s (wall 3360s)\n",
      "\n",
      "\n",
      "step 8500 / 269850 (epoch 9.45 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.557053\n",
      "Training   accuracy: 81.054688 (830 / 1024), f1 (weighted): 81.113199, loss: 0.498769\n",
      "validation accuracy: 60.689532 (139751 / 230272), f1 (weighted): 60.580430, loss: 1.060368\n",
      "time: 4978s (wall 3399s)\n",
      "\n",
      "\n",
      "step 8600 / 269850 (epoch 9.56 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.557188\n",
      "Training   accuracy: 81.054688 (830 / 1024), f1 (weighted): 80.926667, loss: 0.511937\n",
      "validation accuracy: 61.134224 (140775 / 230272), f1 (weighted): 60.500678, loss: 1.036121\n",
      "time: 5035s (wall 3438s)\n",
      "\n",
      "\n",
      "step 8700 / 269850 (epoch 9.67 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.547341\n",
      "Training   accuracy: 80.761719 (827 / 1024), f1 (weighted): 80.794113, loss: 0.506742\n",
      "validation accuracy: 60.974847 (140408 / 230272), f1 (weighted): 61.016180, loss: 1.034437\n",
      "time: 5093s (wall 3477s)\n",
      "\n",
      "\n",
      "step 8800 / 269850 (epoch 9.78 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.549492\n",
      "Training   accuracy: 79.199219 (811 / 1024), f1 (weighted): 79.152736, loss: 0.538114\n",
      "validation accuracy: 61.217169 (140966 / 230272), f1 (weighted): 61.516422, loss: 1.024606\n",
      "time: 5150s (wall 3516s)\n",
      "\n",
      "\n",
      "step 8900 / 269850 (epoch 9.89 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.543445\n",
      "Training   accuracy: 78.808594 (807 / 1024), f1 (weighted): 78.846492, loss: 0.530747\n",
      "validation accuracy: 61.649701 (141962 / 230272), f1 (weighted): 61.678722, loss: 1.016357\n",
      "time: 5208s (wall 3555s)\n",
      "\n",
      "\n",
      "step 9000 / 269850 (epoch 10.01 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.529077\n",
      "Training   accuracy: 79.589844 (815 / 1024), f1 (weighted): 79.663678, loss: 0.492195\n",
      "validation accuracy: 61.667072 (142002 / 230272), f1 (weighted): 61.692130, loss: 1.010553\n",
      "time: 5265s (wall 3594s)\n",
      "\n",
      "\n",
      "step 9100 / 269850 (epoch 10.12 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.525456\n",
      "Training   accuracy: 79.589844 (815 / 1024), f1 (weighted): 79.547158, loss: 0.532733\n",
      "validation accuracy: 61.428658 (141453 / 230272), f1 (weighted): 61.704941, loss: 1.030240\n",
      "time: 5323s (wall 3633s)\n",
      "\n",
      "\n",
      "step 9200 / 269850 (epoch 10.23 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.530433\n",
      "Training   accuracy: 80.566406 (825 / 1024), f1 (weighted): 80.361073, loss: 0.509497\n",
      "validation accuracy: 61.169400 (140856 / 230272), f1 (weighted): 60.900456, loss: 1.042415\n",
      "time: 5380s (wall 3672s)\n",
      "\n",
      "\n",
      "step 9300 / 269850 (epoch 10.34 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.524235\n",
      "Training   accuracy: 80.175781 (821 / 1024), f1 (weighted): 80.075776, loss: 0.493458\n",
      "validation accuracy: 61.868573 (142466 / 230272), f1 (weighted): 61.609077, loss: 1.017601\n",
      "time: 5437s (wall 3711s)\n",
      "\n",
      "\n",
      "step 9400 / 269850 (epoch 10.45 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.527141\n",
      "Training   accuracy: 81.933594 (839 / 1024), f1 (weighted): 81.893684, loss: 0.485427\n",
      "validation accuracy: 61.212392 (140955 / 230272), f1 (weighted): 61.321687, loss: 1.026232\n",
      "time: 5496s (wall 3751s)\n",
      "\n",
      "\n",
      "step 9500 / 269850 (epoch 10.56 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.528480\n",
      "Training   accuracy: 82.910156 (849 / 1024), f1 (weighted): 82.901606, loss: 0.486351\n",
      "validation accuracy: 60.633077 (139621 / 230272), f1 (weighted): 60.706546, loss: 1.079201\n",
      "time: 5555s (wall 3791s)\n",
      "\n",
      "\n",
      "step 9600 / 269850 (epoch 10.67 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.538703\n",
      "Training   accuracy: 81.738281 (837 / 1024), f1 (weighted): 81.681190, loss: 0.489740\n",
      "validation accuracy: 61.162886 (140841 / 230272), f1 (weighted): 61.219300, loss: 1.033882\n",
      "time: 5619s (wall 3835s)\n",
      "\n",
      "\n",
      "step 9700 / 269850 (epoch 10.78 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.532349\n",
      "Training   accuracy: 80.468750 (824 / 1024), f1 (weighted): 80.254299, loss: 0.508355\n",
      "validation accuracy: 60.671293 (139709 / 230272), f1 (weighted): 60.200716, loss: 1.071564\n",
      "time: 5683s (wall 3879s)\n",
      "\n",
      "\n",
      "step 9800 / 269850 (epoch 10.89 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.549207\n",
      "Training   accuracy: 81.152344 (831 / 1024), f1 (weighted): 81.029278, loss: 0.505333\n",
      "validation accuracy: 61.837305 (142394 / 230272), f1 (weighted): 61.246293, loss: 1.023825\n",
      "time: 5747s (wall 3922s)\n",
      "\n",
      "\n",
      "step 9900 / 269850 (epoch 11.01 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.526938\n",
      "Training   accuracy: 83.496094 (855 / 1024), f1 (weighted): 83.373896, loss: 0.457349\n",
      "validation accuracy: 62.345834 (143565 / 230272), f1 (weighted): 61.952449, loss: 1.004873\n",
      "time: 5811s (wall 3967s)\n",
      "\n",
      "\n",
      "step 10000 / 269850 (epoch 11.12 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.521502\n",
      "Training   accuracy: 80.664062 (826 / 1024), f1 (weighted): 80.605637, loss: 0.481825\n",
      "validation accuracy: 61.654044 (141972 / 230272), f1 (weighted): 61.326349, loss: 1.036579\n",
      "time: 5875s (wall 4011s)\n",
      "\n",
      "\n",
      "step 10100 / 269850 (epoch 11.23 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.521860\n",
      "Training   accuracy: 83.007812 (850 / 1024), f1 (weighted): 82.964112, loss: 0.488750\n",
      "validation accuracy: 61.585429 (141814 / 230272), f1 (weighted): 61.446564, loss: 1.038672\n",
      "time: 5939s (wall 4055s)\n",
      "\n",
      "\n",
      "step 10200 / 269850 (epoch 11.34 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.517615\n",
      "Training   accuracy: 82.226562 (842 / 1024), f1 (weighted): 82.229510, loss: 0.475751\n",
      "validation accuracy: 62.248124 (143340 / 230272), f1 (weighted): 62.183136, loss: 1.013725\n",
      "time: 6004s (wall 4099s)\n",
      "\n",
      "\n",
      "step 10300 / 269850 (epoch 11.45 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.531922\n",
      "Training   accuracy: 79.980469 (819 / 1024), f1 (weighted): 79.965658, loss: 0.505297\n",
      "validation accuracy: 60.143222 (138493 / 230272), f1 (weighted): 60.548663, loss: 1.065322\n",
      "time: 6068s (wall 4143s)\n",
      "\n",
      "\n",
      "step 10400 / 269850 (epoch 11.56 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.506271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training   accuracy: 81.933594 (839 / 1024), f1 (weighted): 81.845944, loss: 0.483084\n",
      "validation accuracy: 61.248437 (141038 / 230272), f1 (weighted): 61.136532, loss: 1.068427\n",
      "time: 6132s (wall 4187s)\n",
      "\n",
      "\n",
      "step 10500 / 269850 (epoch 11.67 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.524587\n",
      "Training   accuracy: 81.542969 (835 / 1024), f1 (weighted): 81.746032, loss: 0.517129\n",
      "validation accuracy: 60.656094 (139674 / 230272), f1 (weighted): 60.944821, loss: 1.075193\n",
      "time: 6190s (wall 4227s)\n",
      "\n",
      "\n",
      "step 10600 / 269850 (epoch 11.78 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.509188\n",
      "Training   accuracy: 83.105469 (851 / 1024), f1 (weighted): 83.031541, loss: 0.459056\n",
      "validation accuracy: 62.166916 (143153 / 230272), f1 (weighted): 62.093746, loss: 1.019460\n",
      "time: 6248s (wall 4267s)\n",
      "\n",
      "\n",
      "step 10700 / 269850 (epoch 11.90 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.509723\n",
      "Training   accuracy: 85.058594 (871 / 1024), f1 (weighted): 85.025335, loss: 0.438709\n",
      "validation accuracy: 62.162573 (143143 / 230272), f1 (weighted): 61.699426, loss: 1.035294\n",
      "time: 6306s (wall 4307s)\n",
      "\n",
      "\n",
      "step 10800 / 269850 (epoch 12.01 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.503908\n",
      "Training   accuracy: 83.398438 (854 / 1024), f1 (weighted): 83.401723, loss: 0.455655\n",
      "validation accuracy: 62.156059 (143128 / 230272), f1 (weighted): 61.976777, loss: 1.019230\n",
      "time: 6365s (wall 4347s)\n",
      "\n",
      "\n",
      "step 10900 / 269850 (epoch 12.12 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.500728\n",
      "Training   accuracy: 83.496094 (855 / 1024), f1 (weighted): 83.520992, loss: 0.462383\n",
      "validation accuracy: 61.426921 (141449 / 230272), f1 (weighted): 61.163930, loss: 1.053556\n",
      "time: 6423s (wall 4386s)\n",
      "\n",
      "\n",
      "step 11000 / 269850 (epoch 12.23 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.490181\n",
      "Training   accuracy: 83.300781 (853 / 1024), f1 (weighted): 83.169229, loss: 0.431618\n",
      "validation accuracy: 62.071811 (142934 / 230272), f1 (weighted): 62.076080, loss: 1.022354\n",
      "time: 6481s (wall 4426s)\n",
      "\n",
      "\n",
      "step 11100 / 269850 (epoch 12.34 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.491452\n",
      "Training   accuracy: 81.152344 (831 / 1024), f1 (weighted): 81.168618, loss: 0.483221\n",
      "validation accuracy: 62.080062 (142953 / 230272), f1 (weighted): 61.858784, loss: 1.039634\n",
      "time: 6540s (wall 4466s)\n",
      "\n",
      "\n",
      "step 11200 / 269850 (epoch 12.45 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.503899\n",
      "Training   accuracy: 83.105469 (851 / 1024), f1 (weighted): 83.092225, loss: 0.482856\n",
      "validation accuracy: 61.638410 (141936 / 230272), f1 (weighted): 61.596540, loss: 1.034793\n",
      "time: 6599s (wall 4507s)\n",
      "\n",
      "\n",
      "step 11300 / 269850 (epoch 12.56 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.507913\n",
      "Training   accuracy: 79.687500 (816 / 1024), f1 (weighted): 79.615037, loss: 0.490287\n",
      "validation accuracy: 61.941530 (142634 / 230272), f1 (weighted): 61.600152, loss: 1.036144\n",
      "time: 6662s (wall 4550s)\n",
      "\n",
      "\n",
      "step 11400 / 269850 (epoch 12.67 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.492120\n",
      "Training   accuracy: 83.593750 (856 / 1024), f1 (weighted): 83.559048, loss: 0.437597\n",
      "validation accuracy: 62.169956 (143160 / 230272), f1 (weighted): 62.264722, loss: 1.022494\n",
      "time: 6727s (wall 4595s)\n",
      "\n",
      "\n",
      "step 11500 / 269850 (epoch 12.78 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.488435\n",
      "Training   accuracy: 83.105469 (851 / 1024), f1 (weighted): 83.057364, loss: 0.447576\n",
      "validation accuracy: 62.190800 (143208 / 230272), f1 (weighted): 61.626517, loss: 1.038938\n",
      "time: 6787s (wall 4637s)\n",
      "\n",
      "\n",
      "step 11600 / 269850 (epoch 12.90 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.487550\n",
      "Training   accuracy: 83.691406 (857 / 1024), f1 (weighted): 83.538328, loss: 0.447197\n",
      "validation accuracy: 62.467864 (143846 / 230272), f1 (weighted): 62.441920, loss: 1.023924\n",
      "time: 6845s (wall 4677s)\n",
      "\n",
      "\n",
      "step 11700 / 269850 (epoch 13.01 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.507504\n",
      "Training   accuracy: 82.128906 (841 / 1024), f1 (weighted): 82.140443, loss: 0.475619\n",
      "validation accuracy: 62.085707 (142966 / 230272), f1 (weighted): 62.098991, loss: 1.031371\n",
      "time: 6910s (wall 4721s)\n",
      "\n",
      "\n",
      "step 11800 / 269850 (epoch 13.12 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.494934\n",
      "Training   accuracy: 83.105469 (851 / 1024), f1 (weighted): 83.060942, loss: 0.473489\n",
      "validation accuracy: 62.391867 (143671 / 230272), f1 (weighted): 62.409932, loss: 1.015340\n",
      "time: 6977s (wall 4767s)\n",
      "\n",
      "\n",
      "step 11900 / 269850 (epoch 13.23 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.485749\n",
      "Training   accuracy: 81.738281 (837 / 1024), f1 (weighted): 81.635064, loss: 0.459967\n",
      "validation accuracy: 62.044886 (142872 / 230272), f1 (weighted): 61.510401, loss: 1.079058\n",
      "time: 7041s (wall 4812s)\n",
      "\n",
      "\n",
      "step 12000 / 269850 (epoch 13.34 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.489407\n",
      "Training   accuracy: 83.300781 (853 / 1024), f1 (weighted): 83.182616, loss: 0.440969\n",
      "validation accuracy: 62.186023 (143197 / 230272), f1 (weighted): 61.973468, loss: 1.047226\n",
      "time: 7102s (wall 4854s)\n",
      "\n",
      "\n",
      "step 12100 / 269850 (epoch 13.45 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.488415\n",
      "Training   accuracy: 83.203125 (852 / 1024), f1 (weighted): 83.144607, loss: 0.462040\n",
      "validation accuracy: 62.421397 (143739 / 230272), f1 (weighted): 62.047795, loss: 1.042252\n",
      "time: 7163s (wall 4897s)\n",
      "\n",
      "\n",
      "step 12200 / 269850 (epoch 13.56 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.476520\n",
      "Training   accuracy: 86.230469 (883 / 1024), f1 (weighted): 86.180621, loss: 0.408262\n",
      "validation accuracy: 62.353217 (143582 / 230272), f1 (weighted): 62.343631, loss: 1.038054\n",
      "time: 7222s (wall 4938s)\n",
      "\n",
      "\n",
      "step 12300 / 269850 (epoch 13.67 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.496245\n",
      "Training   accuracy: 80.761719 (827 / 1024), f1 (weighted): 80.755370, loss: 0.502966\n",
      "validation accuracy: 62.481761 (143878 / 230272), f1 (weighted): 62.265163, loss: 1.018864\n",
      "time: 7281s (wall 4978s)\n",
      "\n",
      "\n",
      "step 12400 / 269850 (epoch 13.79 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.485536\n",
      "Training   accuracy: 82.128906 (841 / 1024), f1 (weighted): 82.024810, loss: 0.484429\n",
      "validation accuracy: 62.546033 (144026 / 230272), f1 (weighted): 62.583235, loss: 1.018964\n",
      "time: 7341s (wall 5019s)\n",
      "\n",
      "\n",
      "step 12500 / 269850 (epoch 13.90 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.474251\n",
      "Training   accuracy: 84.960938 (870 / 1024), f1 (weighted): 84.911768, loss: 0.407363\n",
      "validation accuracy: 62.743625 (144481 / 230272), f1 (weighted): 62.767977, loss: 1.015202\n",
      "time: 7402s (wall 5061s)\n",
      "\n",
      "\n",
      "step 12600 / 269850 (epoch 14.01 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.475564\n",
      "Training   accuracy: 83.007812 (850 / 1024), f1 (weighted): 83.090573, loss: 0.459491\n",
      "validation accuracy: 62.178641 (143180 / 230272), f1 (weighted): 62.336165, loss: 1.029565\n",
      "time: 7459s (wall 5100s)\n",
      "\n",
      "\n",
      "step 12700 / 269850 (epoch 14.12 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.477141\n",
      "Training   accuracy: 86.230469 (883 / 1024), f1 (weighted): 86.282045, loss: 0.416592\n",
      "validation accuracy: 62.203394 (143237 / 230272), f1 (weighted): 62.559516, loss: 1.048211\n",
      "time: 7516s (wall 5139s)\n",
      "\n",
      "\n",
      "step 12800 / 269850 (epoch 14.23 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.466854\n",
      "Training   accuracy: 84.667969 (867 / 1024), f1 (weighted): 84.653683, loss: 0.433384\n",
      "validation accuracy: 62.748402 (144492 / 230272), f1 (weighted): 62.603655, loss: 1.025073\n",
      "time: 7574s (wall 5178s)\n",
      "\n",
      "\n",
      "step 12900 / 269850 (epoch 14.34 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.482036\n",
      "Training   accuracy: 83.593750 (856 / 1024), f1 (weighted): 83.621241, loss: 0.453861\n",
      "validation accuracy: 61.870310 (142470 / 230272), f1 (weighted): 61.930578, loss: 1.043131\n",
      "time: 7632s (wall 5218s)\n",
      "\n",
      "\n",
      "step 13000 / 269850 (epoch 14.45 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.488708\n",
      "Training   accuracy: 82.617188 (846 / 1024), f1 (weighted): 82.434938, loss: 0.444790\n",
      "validation accuracy: 61.417367 (141427 / 230272), f1 (weighted): 60.817994, loss: 1.109121\n",
      "time: 7691s (wall 5259s)\n",
      "\n",
      "\n",
      "step 13100 / 269850 (epoch 14.56 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.485404\n",
      "Training   accuracy: 82.714844 (847 / 1024), f1 (weighted): 82.711219, loss: 0.453420\n",
      "validation accuracy: 62.227713 (143293 / 230272), f1 (weighted): 62.310117, loss: 1.048708\n",
      "time: 7749s (wall 5299s)\n",
      "\n",
      "\n",
      "step 13200 / 269850 (epoch 14.67 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.476157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training   accuracy: 83.300781 (853 / 1024), f1 (weighted): 83.288911, loss: 0.464838\n",
      "validation accuracy: 62.793566 (144596 / 230272), f1 (weighted): 62.592712, loss: 1.026907\n",
      "time: 7807s (wall 5338s)\n",
      "\n",
      "\n",
      "step 13300 / 269850 (epoch 14.79 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.473534\n",
      "Training   accuracy: 85.351562 (874 / 1024), f1 (weighted): 85.257766, loss: 0.419402\n",
      "validation accuracy: 62.306316 (143474 / 230272), f1 (weighted): 62.303778, loss: 1.040858\n",
      "time: 7867s (wall 5380s)\n",
      "\n",
      "\n",
      "step 13400 / 269850 (epoch 14.90 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.476884\n",
      "Training   accuracy: 83.691406 (857 / 1024), f1 (weighted): 83.676235, loss: 0.442371\n",
      "validation accuracy: 63.050653 (145188 / 230272), f1 (weighted): 62.934161, loss: 1.010153\n",
      "time: 7926s (wall 5421s)\n",
      "\n",
      "\n",
      "step 13500 / 269850 (epoch 15.01 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.463021\n",
      "Training   accuracy: 83.886719 (859 / 1024), f1 (weighted): 83.831508, loss: 0.437072\n",
      "validation accuracy: 62.366679 (143613 / 230272), f1 (weighted): 62.168221, loss: 1.050287\n",
      "time: 7985s (wall 5461s)\n",
      "\n",
      "\n",
      "step 13600 / 269850 (epoch 15.12 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.470194\n",
      "Training   accuracy: 82.519531 (845 / 1024), f1 (weighted): 82.479020, loss: 0.447224\n",
      "validation accuracy: 62.275483 (143403 / 230272), f1 (weighted): 62.241821, loss: 1.049218\n",
      "time: 8043s (wall 5501s)\n",
      "\n",
      "\n",
      "step 13700 / 269850 (epoch 15.23 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.470170\n",
      "Training   accuracy: 81.933594 (839 / 1024), f1 (weighted): 81.946882, loss: 0.463887\n",
      "validation accuracy: 60.971807 (140401 / 230272), f1 (weighted): 61.401350, loss: 1.106143\n",
      "time: 8102s (wall 5540s)\n",
      "\n",
      "\n",
      "step 13800 / 269850 (epoch 15.34 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.468352\n",
      "Training   accuracy: 83.691406 (857 / 1024), f1 (weighted): 83.783928, loss: 0.440198\n",
      "validation accuracy: 62.626807 (144212 / 230272), f1 (weighted): 62.798026, loss: 1.039394\n",
      "time: 8160s (wall 5580s)\n",
      "\n",
      "\n",
      "step 13900 / 269850 (epoch 15.45 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.477238\n",
      "Training   accuracy: 84.472656 (865 / 1024), f1 (weighted): 84.450794, loss: 0.449217\n",
      "validation accuracy: 62.695855 (144371 / 230272), f1 (weighted): 62.773311, loss: 1.034793\n",
      "time: 8218s (wall 5620s)\n",
      "\n",
      "\n",
      "step 14000 / 269850 (epoch 15.56 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.485852\n",
      "Training   accuracy: 83.203125 (852 / 1024), f1 (weighted): 83.198923, loss: 0.466908\n",
      "validation accuracy: 62.291551 (143440 / 230272), f1 (weighted): 62.331717, loss: 1.034924\n",
      "time: 8277s (wall 5660s)\n",
      "\n",
      "\n",
      "step 14100 / 269850 (epoch 15.68 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.479403\n",
      "Training   accuracy: 82.617188 (846 / 1024), f1 (weighted): 82.643057, loss: 0.463225\n",
      "validation accuracy: 62.737111 (144466 / 230272), f1 (weighted): 62.670294, loss: 1.027896\n",
      "time: 8338s (wall 5702s)\n",
      "\n",
      "\n",
      "step 14200 / 269850 (epoch 15.79 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.477159\n",
      "Training   accuracy: 83.300781 (853 / 1024), f1 (weighted): 83.246747, loss: 0.439038\n",
      "validation accuracy: 61.888983 (142513 / 230272), f1 (weighted): 62.040971, loss: 1.066083\n",
      "time: 8398s (wall 5743s)\n",
      "\n",
      "\n",
      "step 14300 / 269850 (epoch 15.90 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.485110\n",
      "Training   accuracy: 84.082031 (861 / 1024), f1 (weighted): 84.116020, loss: 0.435505\n",
      "validation accuracy: 61.795181 (142297 / 230272), f1 (weighted): 62.008825, loss: 1.067845\n",
      "time: 8460s (wall 5785s)\n",
      "\n",
      "\n",
      "step 14400 / 269850 (epoch 16.01 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.479224\n",
      "Training   accuracy: 83.007812 (850 / 1024), f1 (weighted): 83.104987, loss: 0.456440\n",
      "validation accuracy: 61.243225 (141026 / 230272), f1 (weighted): 60.989662, loss: 1.106372\n",
      "time: 8520s (wall 5826s)\n",
      "\n",
      "\n",
      "step 14500 / 269850 (epoch 16.12 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.465217\n",
      "Training   accuracy: 83.300781 (853 / 1024), f1 (weighted): 83.331512, loss: 0.451263\n",
      "validation accuracy: 62.736242 (144464 / 230272), f1 (weighted): 62.654873, loss: 1.037411\n",
      "time: 8580s (wall 5867s)\n",
      "\n",
      "\n",
      "step 14600 / 269850 (epoch 16.23 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.462215\n",
      "Training   accuracy: 85.839844 (879 / 1024), f1 (weighted): 85.769598, loss: 0.390331\n",
      "validation accuracy: 62.494789 (143908 / 230272), f1 (weighted): 61.927301, loss: 1.047464\n",
      "time: 8638s (wall 5907s)\n",
      "\n",
      "\n",
      "step 14700 / 269850 (epoch 16.34 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.475480\n",
      "Training   accuracy: 85.546875 (876 / 1024), f1 (weighted): 85.509383, loss: 0.422316\n",
      "validation accuracy: 62.456139 (143819 / 230272), f1 (weighted): 62.540871, loss: 1.029637\n",
      "time: 8696s (wall 5947s)\n",
      "\n",
      "\n",
      "step 14800 / 269850 (epoch 16.45 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.467989\n",
      "Training   accuracy: 84.082031 (861 / 1024), f1 (weighted): 84.223860, loss: 0.433526\n",
      "validation accuracy: 61.825146 (142366 / 230272), f1 (weighted): 62.308481, loss: 1.062398\n",
      "time: 8755s (wall 5988s)\n",
      "\n",
      "\n",
      "step 14900 / 269850 (epoch 16.56 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.478464\n",
      "Training   accuracy: 86.035156 (881 / 1024), f1 (weighted): 86.036221, loss: 0.414147\n",
      "validation accuracy: 62.684564 (144345 / 230272), f1 (weighted): 62.640358, loss: 1.053432\n",
      "time: 8816s (wall 6029s)\n",
      "\n",
      "\n",
      "step 15000 / 269850 (epoch 16.68 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.487198\n",
      "Training   accuracy: 82.910156 (849 / 1024), f1 (weighted): 82.851657, loss: 0.475895\n",
      "validation accuracy: 62.420094 (143736 / 230272), f1 (weighted): 62.530974, loss: 1.055880\n",
      "time: 8876s (wall 6070s)\n",
      "\n",
      "\n",
      "step 15100 / 269850 (epoch 16.79 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.470130\n",
      "Training   accuracy: 82.031250 (840 / 1024), f1 (weighted): 81.959116, loss: 0.449202\n",
      "validation accuracy: 63.222189 (145583 / 230272), f1 (weighted): 63.117186, loss: 1.030865\n",
      "time: 8935s (wall 6111s)\n",
      "\n",
      "\n",
      "step 15200 / 269850 (epoch 16.90 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.461140\n",
      "Training   accuracy: 84.375000 (864 / 1024), f1 (weighted): 84.344565, loss: 0.417871\n",
      "validation accuracy: 62.695421 (144370 / 230272), f1 (weighted): 62.350792, loss: 1.046921\n",
      "time: 8994s (wall 6151s)\n",
      "\n",
      "\n",
      "step 15300 / 269850 (epoch 17.01 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.441395\n",
      "Training   accuracy: 85.839844 (879 / 1024), f1 (weighted): 85.795387, loss: 0.403742\n",
      "validation accuracy: 63.033282 (145148 / 230272), f1 (weighted): 62.775838, loss: 1.044751\n",
      "time: 9054s (wall 6192s)\n",
      "\n",
      "\n",
      "step 15400 / 269850 (epoch 17.12 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.475752\n",
      "Training   accuracy: 82.519531 (845 / 1024), f1 (weighted): 82.373788, loss: 0.470927\n",
      "validation accuracy: 62.089616 (142975 / 230272), f1 (weighted): 61.545191, loss: 1.124808\n",
      "time: 9113s (wall 6233s)\n",
      "\n",
      "\n",
      "step 15500 / 269850 (epoch 17.23 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.455373\n",
      "Training   accuracy: 83.496094 (855 / 1024), f1 (weighted): 83.490718, loss: 0.434124\n",
      "validation accuracy: 62.896922 (144834 / 230272), f1 (weighted): 62.724149, loss: 1.054944\n",
      "time: 9174s (wall 6275s)\n",
      "\n",
      "\n",
      "step 15600 / 269850 (epoch 17.34 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.493215\n",
      "Training   accuracy: 81.445312 (834 / 1024), f1 (weighted): 81.453403, loss: 0.478606\n",
      "validation accuracy: 61.926765 (142600 / 230272), f1 (weighted): 61.634163, loss: 1.087713\n",
      "time: 9234s (wall 6316s)\n",
      "\n",
      "\n",
      "step 15700 / 269850 (epoch 17.45 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.475569\n",
      "Training   accuracy: 82.617188 (846 / 1024), f1 (weighted): 82.606353, loss: 0.481449\n",
      "validation accuracy: 61.827317 (142371 / 230272), f1 (weighted): 61.444475, loss: 1.090886\n",
      "time: 9294s (wall 6357s)\n",
      "\n",
      "\n",
      "step 15800 / 269850 (epoch 17.57 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.460980\n",
      "Training   accuracy: 83.593750 (856 / 1024), f1 (weighted): 83.481957, loss: 0.451580\n",
      "validation accuracy: 62.898225 (144837 / 230272), f1 (weighted): 62.524764, loss: 1.037239\n",
      "time: 9355s (wall 6399s)\n",
      "\n",
      "\n",
      "step 15900 / 269850 (epoch 17.68 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.456470\n",
      "Training   accuracy: 84.667969 (867 / 1024), f1 (weighted): 84.683465, loss: 0.419503\n",
      "validation accuracy: 62.877380 (144789 / 230272), f1 (weighted): 62.785882, loss: 1.047500\n",
      "time: 9419s (wall 6442s)\n",
      "\n",
      "\n",
      "step 16000 / 269850 (epoch 17.79 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.458729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training   accuracy: 85.253906 (873 / 1024), f1 (weighted): 85.279145, loss: 0.405551\n",
      "validation accuracy: 62.587722 (144122 / 230272), f1 (weighted): 62.589410, loss: 1.054989\n",
      "time: 9483s (wall 6486s)\n",
      "\n",
      "\n",
      "step 16100 / 269850 (epoch 17.90 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.483621\n",
      "Training   accuracy: 84.570312 (866 / 1024), f1 (weighted): 84.509921, loss: 0.430334\n",
      "validation accuracy: 62.608133 (144169 / 230272), f1 (weighted): 62.179092, loss: 1.055236\n",
      "time: 9546s (wall 6530s)\n",
      "\n",
      "\n",
      "step 16200 / 269850 (epoch 18.01 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.446680\n",
      "Training   accuracy: 84.570312 (866 / 1024), f1 (weighted): 84.630971, loss: 0.427866\n",
      "validation accuracy: 63.213070 (145562 / 230272), f1 (weighted): 63.101290, loss: 1.046285\n",
      "time: 9606s (wall 6572s)\n",
      "\n",
      "\n",
      "step 16300 / 269850 (epoch 18.12 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.450147\n",
      "Training   accuracy: 83.300781 (853 / 1024), f1 (weighted): 83.356827, loss: 0.442868\n",
      "validation accuracy: 62.909516 (144863 / 230272), f1 (weighted): 63.043682, loss: 1.040553\n",
      "time: 9664s (wall 6611s)\n",
      "\n",
      "\n",
      "step 16400 / 269850 (epoch 18.23 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.451705\n",
      "Training   accuracy: 84.472656 (865 / 1024), f1 (weighted): 84.484215, loss: 0.424282\n",
      "validation accuracy: 62.934703 (144921 / 230272), f1 (weighted): 63.076349, loss: 1.054543\n",
      "time: 9721s (wall 6650s)\n",
      "\n",
      "\n",
      "step 16500 / 269850 (epoch 18.34 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.449853\n",
      "Training   accuracy: 84.472656 (865 / 1024), f1 (weighted): 84.520357, loss: 0.426287\n",
      "validation accuracy: 63.060207 (145210 / 230272), f1 (weighted): 62.950605, loss: 1.049246\n",
      "time: 9778s (wall 6689s)\n",
      "\n",
      "\n",
      "step 16600 / 269850 (epoch 18.45 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.458502\n",
      "Training   accuracy: 85.839844 (879 / 1024), f1 (weighted): 85.857506, loss: 0.421656\n",
      "validation accuracy: 62.427477 (143753 / 230272), f1 (weighted): 62.463720, loss: 1.047706\n",
      "time: 9836s (wall 6728s)\n",
      "\n",
      "\n",
      "step 16700 / 269850 (epoch 18.57 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.452541\n",
      "Training   accuracy: 84.277344 (863 / 1024), f1 (weighted): 84.272797, loss: 0.408889\n",
      "validation accuracy: 62.633321 (144227 / 230272), f1 (weighted): 62.517473, loss: 1.056138\n",
      "time: 9894s (wall 6767s)\n",
      "\n",
      "\n",
      "step 16800 / 269850 (epoch 18.68 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.441148\n",
      "Training   accuracy: 85.351562 (874 / 1024), f1 (weighted): 85.282051, loss: 0.418371\n",
      "validation accuracy: 63.238692 (145621 / 230272), f1 (weighted): 62.948803, loss: 1.051413\n",
      "time: 9951s (wall 6806s)\n",
      "\n",
      "\n",
      "step 16900 / 269850 (epoch 18.79 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.453672\n",
      "Training   accuracy: 82.617188 (846 / 1024), f1 (weighted): 82.559304, loss: 0.446306\n",
      "validation accuracy: 62.611173 (144176 / 230272), f1 (weighted): 62.304235, loss: 1.058468\n",
      "time: 10009s (wall 6845s)\n",
      "\n",
      "\n",
      "step 17000 / 269850 (epoch 18.90 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.446785\n",
      "Training   accuracy: 85.253906 (873 / 1024), f1 (weighted): 85.235475, loss: 0.416788\n",
      "validation accuracy: 62.770115 (144542 / 230272), f1 (weighted): 63.009982, loss: 1.048210\n",
      "time: 10066s (wall 6884s)\n",
      "\n",
      "\n",
      "step 17100 / 269850 (epoch 19.01 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.432628\n",
      "Training   accuracy: 87.207031 (893 / 1024), f1 (weighted): 87.193718, loss: 0.361902\n",
      "validation accuracy: 62.658942 (144286 / 230272), f1 (weighted): 62.636292, loss: 1.069480\n",
      "time: 10123s (wall 6923s)\n",
      "\n",
      "\n",
      "step 17200 / 269850 (epoch 19.12 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.434945\n",
      "Training   accuracy: 84.863281 (869 / 1024), f1 (weighted): 84.741365, loss: 0.431934\n",
      "validation accuracy: 62.646349 (144257 / 230272), f1 (weighted): 62.080018, loss: 1.079614\n",
      "time: 10181s (wall 6962s)\n",
      "\n",
      "\n",
      "step 17300 / 269850 (epoch 19.23 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.472263\n",
      "Training   accuracy: 85.546875 (876 / 1024), f1 (weighted): 85.491068, loss: 0.447360\n",
      "validation accuracy: 62.263758 (143376 / 230272), f1 (weighted): 62.085887, loss: 1.066848\n",
      "time: 10238s (wall 7001s)\n",
      "\n",
      "\n",
      "step 17400 / 269850 (epoch 19.34 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.448113\n",
      "Training   accuracy: 83.007812 (850 / 1024), f1 (weighted): 83.061557, loss: 0.423028\n",
      "validation accuracy: 62.769681 (144541 / 230272), f1 (weighted): 62.818149, loss: 1.057535\n",
      "time: 10295s (wall 7040s)\n",
      "\n",
      "\n",
      "step 17500 / 269850 (epoch 19.46 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.451967\n",
      "Training   accuracy: 84.863281 (869 / 1024), f1 (weighted): 84.849812, loss: 0.424105\n",
      "validation accuracy: 62.788355 (144584 / 230272), f1 (weighted): 62.699074, loss: 1.062249\n",
      "time: 10352s (wall 7079s)\n",
      "\n",
      "\n",
      "step 17600 / 269850 (epoch 19.57 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.442234\n",
      "Training   accuracy: 86.230469 (883 / 1024), f1 (weighted): 86.208928, loss: 0.399030\n",
      "validation accuracy: 62.741454 (144476 / 230272), f1 (weighted): 62.647003, loss: 1.057859\n",
      "time: 10410s (wall 7118s)\n",
      "\n",
      "\n",
      "step 17700 / 269850 (epoch 19.68 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.469454\n",
      "Training   accuracy: 81.835938 (838 / 1024), f1 (weighted): 81.951061, loss: 0.468279\n",
      "validation accuracy: 62.580774 (144106 / 230272), f1 (weighted): 62.724338, loss: 1.069060\n",
      "time: 10468s (wall 7158s)\n",
      "\n",
      "\n",
      "step 17800 / 269850 (epoch 19.79 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.448584\n",
      "Training   accuracy: 84.472656 (865 / 1024), f1 (weighted): 84.473680, loss: 0.419684\n",
      "validation accuracy: 62.658508 (144285 / 230272), f1 (weighted): 62.549275, loss: 1.074217\n",
      "time: 10525s (wall 7196s)\n",
      "\n",
      "\n",
      "step 17900 / 269850 (epoch 19.90 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.442028\n",
      "Training   accuracy: 87.109375 (892 / 1024), f1 (weighted): 87.086771, loss: 0.383028\n",
      "validation accuracy: 63.407188 (146009 / 230272), f1 (weighted): 63.266783, loss: 1.042436\n",
      "time: 10582s (wall 7235s)\n",
      "\n",
      "\n",
      "step 18000 / 269850 (epoch 20.01 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.438300\n",
      "Training   accuracy: 85.058594 (871 / 1024), f1 (weighted): 84.994366, loss: 0.414046\n",
      "validation accuracy: 63.317729 (145803 / 230272), f1 (weighted): 63.206639, loss: 1.065251\n",
      "time: 10640s (wall 7275s)\n",
      "\n",
      "\n",
      "step 18100 / 269850 (epoch 20.12 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.448892\n",
      "Training   accuracy: 82.519531 (845 / 1024), f1 (weighted): 82.572383, loss: 0.458953\n",
      "validation accuracy: 61.499010 (141615 / 230272), f1 (weighted): 61.396304, loss: 1.123120\n",
      "time: 10697s (wall 7314s)\n",
      "\n",
      "\n",
      "step 18200 / 269850 (epoch 20.23 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.446392\n",
      "Training   accuracy: 84.472656 (865 / 1024), f1 (weighted): 84.445009, loss: 0.414422\n",
      "validation accuracy: 63.340745 (145856 / 230272), f1 (weighted): 63.548704, loss: 1.031161\n",
      "time: 10754s (wall 7353s)\n",
      "\n",
      "\n",
      "step 18300 / 269850 (epoch 20.34 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.441270\n",
      "Training   accuracy: 82.421875 (844 / 1024), f1 (weighted): 82.411364, loss: 0.453098\n",
      "validation accuracy: 61.904617 (142549 / 230272), f1 (weighted): 61.888116, loss: 1.109120\n",
      "time: 10812s (wall 7392s)\n",
      "\n",
      "\n",
      "step 18400 / 269850 (epoch 20.46 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.434377\n",
      "Training   accuracy: 84.960938 (870 / 1024), f1 (weighted): 84.998104, loss: 0.409245\n",
      "validation accuracy: 62.718437 (144423 / 230272), f1 (weighted): 62.844910, loss: 1.057194\n",
      "time: 10869s (wall 7431s)\n",
      "\n",
      "\n",
      "step 18500 / 269850 (epoch 20.57 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.445090\n",
      "Training   accuracy: 85.058594 (871 / 1024), f1 (weighted): 85.082893, loss: 0.416989\n",
      "validation accuracy: 63.104503 (145312 / 230272), f1 (weighted): 62.810896, loss: 1.055268\n",
      "time: 10927s (wall 7470s)\n",
      "\n",
      "\n",
      "step 18600 / 269850 (epoch 20.68 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.442520\n",
      "Training   accuracy: 85.839844 (879 / 1024), f1 (weighted): 85.782180, loss: 0.389047\n",
      "validation accuracy: 62.839598 (144702 / 230272), f1 (weighted): 62.651498, loss: 1.066340\n",
      "time: 10984s (wall 7509s)\n",
      "\n",
      "\n",
      "step 18700 / 269850 (epoch 20.79 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.436091\n",
      "Training   accuracy: 86.523438 (886 / 1024), f1 (weighted): 86.320458, loss: 0.413506\n",
      "validation accuracy: 62.466127 (143842 / 230272), f1 (weighted): 61.804421, loss: 1.115373\n",
      "time: 11041s (wall 7548s)\n",
      "\n",
      "\n",
      "step 18800 / 269850 (epoch 20.90 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.456129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training   accuracy: 83.105469 (851 / 1024), f1 (weighted): 83.050889, loss: 0.425912\n",
      "validation accuracy: 62.332372 (143534 / 230272), f1 (weighted): 61.990543, loss: 1.082469\n",
      "time: 11099s (wall 7587s)\n",
      "\n",
      "\n",
      "step 18900 / 269850 (epoch 21.01 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.439179\n",
      "Training   accuracy: 84.472656 (865 / 1024), f1 (weighted): 84.474193, loss: 0.402164\n",
      "validation accuracy: 63.064984 (145221 / 230272), f1 (weighted): 62.821759, loss: 1.057988\n",
      "time: 11156s (wall 7626s)\n",
      "\n",
      "\n",
      "step 19000 / 269850 (epoch 21.12 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.437261\n",
      "Training   accuracy: 84.960938 (870 / 1024), f1 (weighted): 84.921694, loss: 0.411302\n",
      "validation accuracy: 62.991158 (145051 / 230272), f1 (weighted): 62.585731, loss: 1.071166\n",
      "time: 11214s (wall 7665s)\n",
      "\n",
      "\n",
      "step 19100 / 269850 (epoch 21.23 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.422652\n",
      "Training   accuracy: 84.375000 (864 / 1024), f1 (weighted): 84.297800, loss: 0.413932\n",
      "validation accuracy: 63.281684 (145720 / 230272), f1 (weighted): 62.854754, loss: 1.088683\n",
      "time: 11271s (wall 7704s)\n",
      "\n",
      "\n",
      "step 19200 / 269850 (epoch 21.35 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.432095\n",
      "Training   accuracy: 83.886719 (859 / 1024), f1 (weighted): 83.918519, loss: 0.411700\n",
      "validation accuracy: 62.816582 (144649 / 230272), f1 (weighted): 62.937548, loss: 1.061455\n",
      "time: 11328s (wall 7743s)\n",
      "\n",
      "\n",
      "step 19300 / 269850 (epoch 21.46 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.432972\n",
      "Training   accuracy: 86.816406 (889 / 1024), f1 (weighted): 86.828142, loss: 0.372646\n",
      "validation accuracy: 62.761430 (144522 / 230272), f1 (weighted): 62.868876, loss: 1.055763\n",
      "time: 11386s (wall 7782s)\n",
      "\n",
      "\n",
      "step 19400 / 269850 (epoch 21.57 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.443224\n",
      "Training   accuracy: 84.472656 (865 / 1024), f1 (weighted): 84.462036, loss: 0.408230\n",
      "validation accuracy: 63.430639 (146063 / 230272), f1 (weighted): 63.573171, loss: 1.035953\n",
      "time: 11443s (wall 7821s)\n",
      "\n",
      "\n",
      "step 19500 / 269850 (epoch 21.68 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.435190\n",
      "Training   accuracy: 84.082031 (861 / 1024), f1 (weighted): 84.092045, loss: 0.429996\n",
      "validation accuracy: 62.607699 (144168 / 230272), f1 (weighted): 62.617897, loss: 1.064914\n",
      "time: 11500s (wall 7860s)\n",
      "\n",
      "\n",
      "step 19600 / 269850 (epoch 21.79 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.421956\n",
      "Training   accuracy: 86.523438 (886 / 1024), f1 (weighted): 86.485904, loss: 0.380216\n",
      "validation accuracy: 63.706399 (146698 / 230272), f1 (weighted): 63.580852, loss: 1.041814\n",
      "time: 11558s (wall 7899s)\n",
      "\n",
      "\n",
      "step 19700 / 269850 (epoch 21.90 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.448683\n",
      "Training   accuracy: 84.082031 (861 / 1024), f1 (weighted): 84.090880, loss: 0.432159\n",
      "validation accuracy: 63.144021 (145403 / 230272), f1 (weighted): 62.832680, loss: 1.077385\n",
      "time: 11615s (wall 7938s)\n",
      "\n",
      "\n",
      "step 19800 / 269850 (epoch 22.01 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.433794\n",
      "Training   accuracy: 85.644531 (877 / 1024), f1 (weighted): 85.562422, loss: 0.396492\n",
      "validation accuracy: 62.481761 (143878 / 230272), f1 (weighted): 62.227115, loss: 1.087376\n",
      "time: 11673s (wall 7977s)\n",
      "\n",
      "\n",
      "step 19900 / 269850 (epoch 22.12 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.424728\n",
      "Training   accuracy: 84.570312 (866 / 1024), f1 (weighted): 84.639177, loss: 0.422401\n",
      "validation accuracy: 63.286461 (145731 / 230272), f1 (weighted): 63.225815, loss: 1.057592\n",
      "time: 11730s (wall 8016s)\n",
      "\n",
      "\n",
      "step 20000 / 269850 (epoch 22.23 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.429453\n",
      "Training   accuracy: 84.570312 (866 / 1024), f1 (weighted): 84.591719, loss: 0.421301\n",
      "validation accuracy: 62.773589 (144550 / 230272), f1 (weighted): 62.482915, loss: 1.074544\n",
      "time: 11787s (wall 8055s)\n",
      "\n",
      "\n",
      "step 20100 / 269850 (epoch 22.35 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.444073\n",
      "Training   accuracy: 85.644531 (877 / 1024), f1 (weighted): 85.622346, loss: 0.397386\n",
      "validation accuracy: 63.341613 (145858 / 230272), f1 (weighted): 63.068721, loss: 1.032303\n",
      "time: 11845s (wall 8094s)\n",
      "\n",
      "\n",
      "step 20200 / 269850 (epoch 22.46 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.422000\n",
      "Training   accuracy: 86.621094 (887 / 1024), f1 (weighted): 86.664932, loss: 0.387104\n",
      "validation accuracy: 63.513150 (146253 / 230272), f1 (weighted): 63.639118, loss: 1.041118\n",
      "time: 11902s (wall 8133s)\n",
      "\n",
      "\n",
      "step 20300 / 269850 (epoch 22.57 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.416115\n",
      "Training   accuracy: 86.914062 (890 / 1024), f1 (weighted): 86.869490, loss: 0.380002\n",
      "validation accuracy: 63.226098 (145592 / 230272), f1 (weighted): 62.724249, loss: 1.084382\n",
      "time: 11960s (wall 8172s)\n",
      "\n",
      "\n",
      "step 20400 / 269850 (epoch 22.68 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.439381\n",
      "Training   accuracy: 85.839844 (879 / 1024), f1 (weighted): 85.824941, loss: 0.413588\n",
      "validation accuracy: 63.689897 (146660 / 230272), f1 (weighted): 63.644280, loss: 1.026635\n",
      "time: 12017s (wall 8211s)\n",
      "\n",
      "\n",
      "step 20500 / 269850 (epoch 22.79 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.425989\n",
      "Training   accuracy: 84.375000 (864 / 1024), f1 (weighted): 84.388815, loss: 0.413912\n",
      "validation accuracy: 63.442798 (146091 / 230272), f1 (weighted): 63.424078, loss: 1.057746\n",
      "time: 12074s (wall 8250s)\n",
      "\n",
      "\n",
      "step 20600 / 269850 (epoch 22.90 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.436737\n",
      "Training   accuracy: 85.839844 (879 / 1024), f1 (weighted): 85.818723, loss: 0.403915\n",
      "validation accuracy: 63.275605 (145706 / 230272), f1 (weighted): 63.184082, loss: 1.034670\n",
      "time: 12132s (wall 8289s)\n",
      "\n",
      "\n",
      "step 20700 / 269850 (epoch 23.01 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.411218\n",
      "Training   accuracy: 86.230469 (883 / 1024), f1 (weighted): 86.211080, loss: 0.369703\n",
      "validation accuracy: 63.380698 (145948 / 230272), f1 (weighted): 63.280207, loss: 1.046336\n",
      "time: 12189s (wall 8328s)\n",
      "\n",
      "\n",
      "step 20800 / 269850 (epoch 23.12 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.425628\n",
      "Training   accuracy: 86.523438 (886 / 1024), f1 (weighted): 86.513135, loss: 0.396232\n",
      "validation accuracy: 63.290370 (145740 / 230272), f1 (weighted): 63.172621, loss: 1.057523\n",
      "time: 12246s (wall 8367s)\n",
      "\n",
      "\n",
      "step 20900 / 269850 (epoch 23.24 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.415433\n",
      "Training   accuracy: 87.207031 (893 / 1024), f1 (weighted): 87.230637, loss: 0.366117\n",
      "validation accuracy: 62.515634 (143956 / 230272), f1 (weighted): 62.683234, loss: 1.116699\n",
      "time: 12304s (wall 8406s)\n",
      "\n",
      "\n",
      "step 21000 / 269850 (epoch 23.35 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.408552\n",
      "Training   accuracy: 86.328125 (884 / 1024), f1 (weighted): 86.326694, loss: 0.388707\n",
      "validation accuracy: 63.491436 (146203 / 230272), f1 (weighted): 63.130638, loss: 1.064006\n",
      "time: 12361s (wall 8445s)\n",
      "\n",
      "\n",
      "step 21100 / 269850 (epoch 23.46 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.420283\n",
      "Training   accuracy: 86.035156 (881 / 1024), f1 (weighted): 85.992730, loss: 0.392291\n",
      "validation accuracy: 63.485791 (146190 / 230272), f1 (weighted): 63.217868, loss: 1.065748\n",
      "time: 12418s (wall 8484s)\n",
      "\n",
      "\n",
      "step 21200 / 269850 (epoch 23.57 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.427677\n",
      "Training   accuracy: 83.984375 (860 / 1024), f1 (weighted): 83.899975, loss: 0.422229\n",
      "validation accuracy: 63.489699 (146199 / 230272), f1 (weighted): 63.159222, loss: 1.069590\n",
      "time: 12475s (wall 8523s)\n",
      "\n",
      "\n",
      "step 21300 / 269850 (epoch 23.68 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.423757\n",
      "Training   accuracy: 84.863281 (869 / 1024), f1 (weighted): 84.718127, loss: 0.386242\n",
      "validation accuracy: 63.596964 (146446 / 230272), f1 (weighted): 63.369937, loss: 1.046746\n",
      "time: 12533s (wall 8562s)\n",
      "\n",
      "\n",
      "step 21400 / 269850 (epoch 23.79 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.429974\n",
      "Training   accuracy: 84.667969 (867 / 1024), f1 (weighted): 84.546797, loss: 0.409175\n",
      "validation accuracy: 63.421519 (146042 / 230272), f1 (weighted): 63.349013, loss: 1.020476\n",
      "time: 12590s (wall 8601s)\n",
      "\n",
      "\n",
      "step 21500 / 269850 (epoch 23.90 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.435488\n",
      "Training   accuracy: 85.546875 (876 / 1024), f1 (weighted): 85.527365, loss: 0.390630\n",
      "validation accuracy: 63.363761 (145909 / 230272), f1 (weighted): 63.295143, loss: 1.047327\n",
      "time: 12647s (wall 8640s)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 21600 / 269850 (epoch 24.01 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.422974\n",
      "Training   accuracy: 85.351562 (874 / 1024), f1 (weighted): 85.292504, loss: 0.401918\n",
      "validation accuracy: 63.417176 (146032 / 230272), f1 (weighted): 63.423312, loss: 1.021862\n",
      "time: 12705s (wall 8678s)\n",
      "\n",
      "\n",
      "step 21700 / 269850 (epoch 24.12 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.447986\n",
      "Training   accuracy: 86.132812 (882 / 1024), f1 (weighted): 85.989067, loss: 0.393831\n",
      "validation accuracy: 62.678919 (144332 / 230272), f1 (weighted): 62.434396, loss: 1.128415\n",
      "time: 12762s (wall 8717s)\n",
      "\n",
      "\n",
      "step 21800 / 269850 (epoch 24.24 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.416785\n",
      "Training   accuracy: 86.230469 (883 / 1024), f1 (weighted): 86.087197, loss: 0.388279\n",
      "validation accuracy: 63.557879 (146356 / 230272), f1 (weighted): 62.972017, loss: 1.082810\n",
      "time: 12819s (wall 8756s)\n",
      "\n",
      "\n",
      "step 21900 / 269850 (epoch 24.35 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.443005\n",
      "Training   accuracy: 85.937500 (880 / 1024), f1 (weighted): 85.959729, loss: 0.389592\n",
      "validation accuracy: 62.753179 (144503 / 230272), f1 (weighted): 63.084959, loss: 1.084196\n",
      "time: 12876s (wall 8795s)\n",
      "\n",
      "\n",
      "step 22000 / 269850 (epoch 24.46 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.421843\n",
      "Training   accuracy: 85.449219 (875 / 1024), f1 (weighted): 85.510991, loss: 0.407525\n",
      "validation accuracy: 62.827005 (144673 / 230272), f1 (weighted): 63.029654, loss: 1.071749\n",
      "time: 12934s (wall 8834s)\n",
      "\n",
      "\n",
      "step 22100 / 269850 (epoch 24.57 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.416369\n",
      "Training   accuracy: 87.500000 (896 / 1024), f1 (weighted): 87.515153, loss: 0.360391\n",
      "validation accuracy: 63.222624 (145584 / 230272), f1 (weighted): 63.561379, loss: 1.061380\n",
      "time: 12991s (wall 8873s)\n",
      "\n",
      "\n",
      "step 22200 / 269850 (epoch 24.68 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.423771\n",
      "Training   accuracy: 87.011719 (891 / 1024), f1 (weighted): 86.957989, loss: 0.371958\n",
      "validation accuracy: 63.403280 (146000 / 230272), f1 (weighted): 63.107747, loss: 1.077296\n",
      "time: 13048s (wall 8912s)\n",
      "\n",
      "\n",
      "step 22300 / 269850 (epoch 24.79 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.424489\n",
      "Training   accuracy: 85.449219 (875 / 1024), f1 (weighted): 85.518741, loss: 0.404639\n",
      "validation accuracy: 63.170946 (145465 / 230272), f1 (weighted): 63.197409, loss: 1.057411\n",
      "time: 13105s (wall 8951s)\n",
      "\n",
      "\n",
      "step 22400 / 269850 (epoch 24.90 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.427694\n",
      "Training   accuracy: 84.179688 (862 / 1024), f1 (weighted): 84.194932, loss: 0.406310\n",
      "validation accuracy: 63.651247 (146571 / 230272), f1 (weighted): 63.494834, loss: 1.053172\n",
      "time: 13162s (wall 8990s)\n",
      "\n",
      "\n",
      "step 22500 / 269850 (epoch 25.01 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.402112\n",
      "Training   accuracy: 86.035156 (881 / 1024), f1 (weighted): 86.048053, loss: 0.409667\n",
      "validation accuracy: 63.583501 (146415 / 230272), f1 (weighted): 63.708797, loss: 1.076894\n",
      "time: 13220s (wall 9028s)\n",
      "\n",
      "\n",
      "step 22600 / 269850 (epoch 25.13 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.423547\n",
      "Training   accuracy: 84.082031 (861 / 1024), f1 (weighted): 84.215628, loss: 0.416718\n",
      "validation accuracy: 62.006236 (142783 / 230272), f1 (weighted): 62.075755, loss: 1.128653\n",
      "time: 13277s (wall 9067s)\n",
      "\n",
      "\n",
      "step 22700 / 269850 (epoch 25.24 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.412919\n",
      "Training   accuracy: 87.109375 (892 / 1024), f1 (weighted): 87.105046, loss: 0.374216\n",
      "validation accuracy: 63.423690 (146047 / 230272), f1 (weighted): 63.371810, loss: 1.061932\n",
      "time: 13334s (wall 9106s)\n",
      "\n",
      "\n",
      "step 22800 / 269850 (epoch 25.35 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.435524\n",
      "Training   accuracy: 85.253906 (873 / 1024), f1 (weighted): 85.238694, loss: 0.411942\n",
      "validation accuracy: 62.574260 (144091 / 230272), f1 (weighted): 62.605916, loss: 1.094404\n",
      "time: 13391s (wall 9145s)\n",
      "\n",
      "\n",
      "step 22900 / 269850 (epoch 25.46 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.408783\n",
      "Training   accuracy: 85.839844 (879 / 1024), f1 (weighted): 85.733343, loss: 0.371801\n",
      "validation accuracy: 63.785871 (146881 / 230272), f1 (weighted): 63.465611, loss: 1.052897\n",
      "time: 13449s (wall 9184s)\n",
      "\n",
      "\n",
      "step 23000 / 269850 (epoch 25.57 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.414962\n",
      "Training   accuracy: 84.863281 (869 / 1024), f1 (weighted): 84.764427, loss: 0.390187\n",
      "validation accuracy: 63.148364 (145413 / 230272), f1 (weighted): 63.197759, loss: 1.080656\n",
      "time: 13506s (wall 9223s)\n",
      "\n",
      "\n",
      "step 23100 / 269850 (epoch 25.68 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.403785\n",
      "Training   accuracy: 86.523438 (886 / 1024), f1 (weighted): 86.503826, loss: 0.377964\n",
      "validation accuracy: 63.508373 (146242 / 230272), f1 (weighted): 63.374458, loss: 1.070537\n",
      "time: 13563s (wall 9262s)\n",
      "\n",
      "\n",
      "step 23200 / 269850 (epoch 25.79 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.424539\n",
      "Training   accuracy: 84.570312 (866 / 1024), f1 (weighted): 84.701225, loss: 0.418000\n",
      "validation accuracy: 62.746665 (144488 / 230272), f1 (weighted): 62.824901, loss: 1.098808\n",
      "time: 13620s (wall 9301s)\n",
      "\n",
      "\n",
      "step 23300 / 269850 (epoch 25.90 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.406760\n",
      "Training   accuracy: 84.863281 (869 / 1024), f1 (weighted): 84.939805, loss: 0.392454\n",
      "validation accuracy: 63.003318 (145079 / 230272), f1 (weighted): 63.361903, loss: 1.078621\n",
      "time: 13678s (wall 9340s)\n",
      "\n",
      "\n",
      "step 23400 / 269850 (epoch 26.01 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.394850\n",
      "Training   accuracy: 86.914062 (890 / 1024), f1 (weighted): 86.915746, loss: 0.358840\n",
      "validation accuracy: 62.749270 (144494 / 230272), f1 (weighted): 62.789939, loss: 1.091679\n",
      "time: 13735s (wall 9379s)\n",
      "\n",
      "\n",
      "step 23500 / 269850 (epoch 26.13 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.401137\n",
      "Training   accuracy: 85.156250 (872 / 1024), f1 (weighted): 85.138384, loss: 0.390141\n",
      "validation accuracy: 63.792385 (146896 / 230272), f1 (weighted): 63.474674, loss: 1.084096\n",
      "time: 13792s (wall 9418s)\n",
      "\n",
      "\n",
      "step 23600 / 269850 (epoch 26.24 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.405777\n",
      "Training   accuracy: 86.621094 (887 / 1024), f1 (weighted): 86.622459, loss: 0.376513\n",
      "validation accuracy: 63.391989 (145974 / 230272), f1 (weighted): 63.623197, loss: 1.069923\n",
      "time: 13850s (wall 9457s)\n",
      "\n",
      "\n",
      "step 23700 / 269850 (epoch 26.35 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.408566\n",
      "Training   accuracy: 86.914062 (890 / 1024), f1 (weighted): 86.798618, loss: 0.371378\n",
      "validation accuracy: 63.078446 (145252 / 230272), f1 (weighted): 62.626037, loss: 1.115779\n",
      "time: 13907s (wall 9495s)\n",
      "\n",
      "\n",
      "step 23800 / 269850 (epoch 26.46 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.412889\n",
      "Training   accuracy: 87.792969 (899 / 1024), f1 (weighted): 87.791303, loss: 0.359292\n",
      "validation accuracy: 63.713782 (146715 / 230272), f1 (weighted): 63.453872, loss: 1.073243\n",
      "time: 13964s (wall 9534s)\n",
      "\n",
      "\n",
      "step 23900 / 269850 (epoch 26.57 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.416526\n",
      "Training   accuracy: 88.281250 (904 / 1024), f1 (weighted): 88.224710, loss: 0.344007\n",
      "validation accuracy: 63.565696 (146374 / 230272), f1 (weighted): 63.410054, loss: 1.061990\n",
      "time: 14021s (wall 9573s)\n",
      "\n",
      "\n",
      "step 24000 / 269850 (epoch 26.68 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.424342\n",
      "Training   accuracy: 86.816406 (889 / 1024), f1 (weighted): 86.843332, loss: 0.391476\n",
      "validation accuracy: 63.243469 (145632 / 230272), f1 (weighted): 63.366787, loss: 1.081212\n",
      "time: 14078s (wall 9612s)\n",
      "\n",
      "\n",
      "step 24100 / 269850 (epoch 26.79 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.419450\n",
      "Training   accuracy: 86.035156 (881 / 1024), f1 (weighted): 86.033280, loss: 0.412124\n",
      "validation accuracy: 63.427164 (146055 / 230272), f1 (weighted): 63.488358, loss: 1.073201\n",
      "time: 14135s (wall 9651s)\n",
      "\n",
      "\n",
      "step 24200 / 269850 (epoch 26.90 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.410179\n",
      "Training   accuracy: 87.109375 (892 / 1024), f1 (weighted): 87.146779, loss: 0.352345\n",
      "validation accuracy: 63.460603 (146132 / 230272), f1 (weighted): 63.497926, loss: 1.059454\n",
      "time: 14192s (wall 9690s)\n",
      "\n",
      "\n",
      "step 24300 / 269850 (epoch 27.02 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.397535\n",
      "Training   accuracy: 85.742188 (878 / 1024), f1 (weighted): 85.715442, loss: 0.401686\n",
      "validation accuracy: 62.737111 (144466 / 230272), f1 (weighted): 62.612546, loss: 1.107777\n",
      "time: 14250s (wall 9729s)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 24400 / 269850 (epoch 27.13 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.395511\n",
      "Training   accuracy: 87.011719 (891 / 1024), f1 (weighted): 86.989944, loss: 0.369551\n",
      "validation accuracy: 63.767631 (146839 / 230272), f1 (weighted): 63.494035, loss: 1.070915\n",
      "time: 14307s (wall 9768s)\n",
      "\n",
      "\n",
      "step 24500 / 269850 (epoch 27.24 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.402242\n",
      "Training   accuracy: 85.839844 (879 / 1024), f1 (weighted): 85.816510, loss: 0.384892\n",
      "validation accuracy: 63.396766 (145985 / 230272), f1 (weighted): 63.559930, loss: 1.083506\n",
      "time: 14364s (wall 9807s)\n",
      "\n",
      "\n",
      "step 24600 / 269850 (epoch 27.35 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.409160\n",
      "Training   accuracy: 88.378906 (905 / 1024), f1 (weighted): 88.209574, loss: 0.355796\n",
      "validation accuracy: 63.104937 (145313 / 230272), f1 (weighted): 62.483224, loss: 1.132849\n",
      "time: 14421s (wall 9846s)\n",
      "\n",
      "\n",
      "step 24700 / 269850 (epoch 27.46 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.412641\n",
      "Training   accuracy: 86.425781 (885 / 1024), f1 (weighted): 86.537018, loss: 0.375559\n",
      "validation accuracy: 63.434113 (146071 / 230272), f1 (weighted): 63.311906, loss: 1.089257\n",
      "time: 14479s (wall 9884s)\n",
      "\n",
      "\n",
      "step 24800 / 269850 (epoch 27.57 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.407122\n",
      "Training   accuracy: 82.910156 (849 / 1024), f1 (weighted): 82.989037, loss: 0.436032\n",
      "validation accuracy: 62.468733 (143848 / 230272), f1 (weighted): 62.331935, loss: 1.113761\n",
      "time: 14536s (wall 9923s)\n",
      "\n",
      "\n",
      "step 24900 / 269850 (epoch 27.68 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.400129\n",
      "Training   accuracy: 85.546875 (876 / 1024), f1 (weighted): 85.549737, loss: 0.377915\n",
      "validation accuracy: 63.552234 (146343 / 230272), f1 (weighted): 63.408406, loss: 1.078546\n",
      "time: 14593s (wall 9962s)\n",
      "\n",
      "\n",
      "step 25000 / 269850 (epoch 27.79 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.402270\n",
      "Training   accuracy: 86.132812 (882 / 1024), f1 (weighted): 86.140131, loss: 0.377887\n",
      "validation accuracy: 63.459735 (146130 / 230272), f1 (weighted): 63.676325, loss: 1.063230\n",
      "time: 14650s (wall 10001s)\n",
      "\n",
      "\n",
      "step 25100 / 269850 (epoch 27.90 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.398610\n",
      "Training   accuracy: 87.402344 (895 / 1024), f1 (weighted): 87.375941, loss: 0.360140\n",
      "validation accuracy: 63.570473 (146385 / 230272), f1 (weighted): 63.369869, loss: 1.082968\n",
      "time: 14707s (wall 10040s)\n",
      "\n",
      "\n",
      "step 25200 / 269850 (epoch 28.02 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.392943\n",
      "Training   accuracy: 87.792969 (899 / 1024), f1 (weighted): 87.745953, loss: 0.352097\n",
      "validation accuracy: 63.699885 (146683 / 230272), f1 (weighted): 63.585616, loss: 1.081802\n",
      "time: 14765s (wall 10079s)\n",
      "\n",
      "\n",
      "step 25300 / 269850 (epoch 28.13 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.394317\n",
      "Training   accuracy: 88.378906 (905 / 1024), f1 (weighted): 88.375763, loss: 0.340919\n",
      "validation accuracy: 63.342482 (145860 / 230272), f1 (weighted): 63.289440, loss: 1.100821\n",
      "time: 14822s (wall 10118s)\n",
      "\n",
      "\n",
      "step 25400 / 269850 (epoch 28.24 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.414143\n",
      "Training   accuracy: 86.132812 (882 / 1024), f1 (weighted): 86.097486, loss: 0.384084\n",
      "validation accuracy: 62.709318 (144402 / 230272), f1 (weighted): 62.137188, loss: 1.154688\n",
      "time: 14880s (wall 10157s)\n",
      "\n",
      "\n",
      "step 25500 / 269850 (epoch 28.35 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.394654\n",
      "Training   accuracy: 89.257812 (914 / 1024), f1 (weighted): 89.236387, loss: 0.329479\n",
      "validation accuracy: 63.465380 (146143 / 230272), f1 (weighted): 63.395572, loss: 1.094435\n",
      "time: 14937s (wall 10196s)\n",
      "\n",
      "\n",
      "step 25600 / 269850 (epoch 28.46 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.405423\n",
      "Training   accuracy: 86.425781 (885 / 1024), f1 (weighted): 86.409290, loss: 0.368967\n",
      "validation accuracy: 63.223926 (145587 / 230272), f1 (weighted): 63.089449, loss: 1.106380\n",
      "time: 14994s (wall 10235s)\n",
      "\n",
      "\n",
      "step 25700 / 269850 (epoch 28.57 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.409029\n",
      "Training   accuracy: 85.351562 (874 / 1024), f1 (weighted): 85.319424, loss: 0.406148\n",
      "validation accuracy: 63.621283 (146502 / 230272), f1 (weighted): 63.278582, loss: 1.090900\n",
      "time: 15051s (wall 10274s)\n",
      "\n",
      "\n",
      "step 25800 / 269850 (epoch 28.68 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.408461\n",
      "Training   accuracy: 87.011719 (891 / 1024), f1 (weighted): 87.112252, loss: 0.367387\n",
      "validation accuracy: 62.642440 (144248 / 230272), f1 (weighted): 63.019471, loss: 1.108011\n",
      "time: 15108s (wall 10312s)\n",
      "\n",
      "\n",
      "step 25900 / 269850 (epoch 28.79 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.421491\n",
      "Training   accuracy: 85.937500 (880 / 1024), f1 (weighted): 86.019530, loss: 0.389694\n",
      "validation accuracy: 62.302842 (143466 / 230272), f1 (weighted): 62.654730, loss: 1.109206\n",
      "time: 15166s (wall 10351s)\n",
      "\n",
      "\n",
      "step 26000 / 269850 (epoch 28.90 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.396028\n",
      "Training   accuracy: 86.816406 (889 / 1024), f1 (weighted): 86.828752, loss: 0.374333\n",
      "validation accuracy: 63.252588 (145653 / 230272), f1 (weighted): 63.364157, loss: 1.086228\n",
      "time: 15223s (wall 10390s)\n",
      "\n",
      "\n",
      "step 26100 / 269850 (epoch 29.02 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.390620\n",
      "Training   accuracy: 87.207031 (893 / 1024), f1 (weighted): 87.164730, loss: 0.352073\n",
      "validation accuracy: 64.294400 (148052 / 230272), f1 (weighted): 64.164826, loss: 1.053778\n",
      "time: 15280s (wall 10429s)\n",
      "\n",
      "\n",
      "step 26200 / 269850 (epoch 29.13 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.393923\n",
      "Training   accuracy: 88.671875 (908 / 1024), f1 (weighted): 88.655549, loss: 0.336545\n",
      "validation accuracy: 63.129256 (145369 / 230272), f1 (weighted): 63.109397, loss: 1.088946\n",
      "time: 15337s (wall 10468s)\n",
      "\n",
      "\n",
      "step 26300 / 269850 (epoch 29.24 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.397586\n",
      "Training   accuracy: 88.378906 (905 / 1024), f1 (weighted): 88.377634, loss: 0.329816\n",
      "validation accuracy: 63.844497 (147016 / 230272), f1 (weighted): 63.703122, loss: 1.089895\n",
      "time: 15394s (wall 10507s)\n",
      "\n",
      "\n",
      "step 26400 / 269850 (epoch 29.35 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.391096\n",
      "Training   accuracy: 86.914062 (890 / 1024), f1 (weighted): 86.852734, loss: 0.371222\n",
      "validation accuracy: 63.946116 (147250 / 230272), f1 (weighted): 63.699895, loss: 1.074547\n",
      "time: 15452s (wall 10546s)\n",
      "\n",
      "\n",
      "step 26500 / 269850 (epoch 29.46 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.395828\n",
      "Training   accuracy: 88.085938 (902 / 1024), f1 (weighted): 88.075261, loss: 0.339626\n",
      "validation accuracy: 63.993451 (147359 / 230272), f1 (weighted): 63.864364, loss: 1.057910\n",
      "time: 15509s (wall 10585s)\n",
      "\n",
      "\n",
      "step 26600 / 269850 (epoch 29.57 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.395274\n",
      "Training   accuracy: 87.890625 (900 / 1024), f1 (weighted): 87.874022, loss: 0.344156\n",
      "validation accuracy: 63.699885 (146683 / 230272), f1 (weighted): 63.231498, loss: 1.086692\n",
      "time: 15566s (wall 10623s)\n",
      "\n",
      "\n",
      "step 26700 / 269850 (epoch 29.68 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.388405\n",
      "Training   accuracy: 86.621094 (887 / 1024), f1 (weighted): 86.560507, loss: 0.362706\n",
      "validation accuracy: 63.922231 (147195 / 230272), f1 (weighted): 63.767454, loss: 1.078563\n",
      "time: 15623s (wall 10662s)\n",
      "\n",
      "\n",
      "step 26800 / 269850 (epoch 29.79 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.389217\n",
      "Training   accuracy: 87.109375 (892 / 1024), f1 (weighted): 87.090388, loss: 0.366762\n",
      "validation accuracy: 64.181055 (147791 / 230272), f1 (weighted): 64.053220, loss: 1.068235\n",
      "time: 15680s (wall 10701s)\n",
      "\n",
      "\n",
      "step 26900 / 269850 (epoch 29.91 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.402469\n",
      "Training   accuracy: 86.621094 (887 / 1024), f1 (weighted): 86.604555, loss: 0.377722\n",
      "validation accuracy: 63.556142 (146352 / 230272), f1 (weighted): 63.617752, loss: 1.083943\n",
      "time: 15738s (wall 10740s)\n",
      "\n",
      "\n",
      "step 27000 / 269850 (epoch 30.02 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.378655\n",
      "Training   accuracy: 87.792969 (899 / 1024), f1 (weighted): 87.758515, loss: 0.348767\n",
      "validation accuracy: 64.035141 (147455 / 230272), f1 (weighted): 64.122890, loss: 1.079968\n",
      "time: 15795s (wall 10779s)\n",
      "\n",
      "\n",
      "step 27100 / 269850 (epoch 30.13 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.395240\n",
      "Training   accuracy: 87.890625 (900 / 1024), f1 (weighted): 87.887360, loss: 0.352123\n",
      "validation accuracy: 63.751563 (146802 / 230272), f1 (weighted): 63.852549, loss: 1.073858\n",
      "time: 15852s (wall 10818s)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 27200 / 269850 (epoch 30.24 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.379906\n",
      "Training   accuracy: 87.890625 (900 / 1024), f1 (weighted): 87.846495, loss: 0.343617\n",
      "validation accuracy: 63.603912 (146462 / 230272), f1 (weighted): 63.611773, loss: 1.096634\n",
      "time: 15909s (wall 10857s)\n",
      "\n",
      "\n",
      "step 27300 / 269850 (epoch 30.35 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.387378\n",
      "Training   accuracy: 86.230469 (883 / 1024), f1 (weighted): 86.150305, loss: 0.366814\n",
      "validation accuracy: 63.680778 (146639 / 230272), f1 (weighted): 63.716689, loss: 1.080801\n",
      "time: 15966s (wall 10896s)\n",
      "\n",
      "\n",
      "step 27400 / 269850 (epoch 30.46 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.392347\n",
      "Training   accuracy: 86.914062 (890 / 1024), f1 (weighted): 86.901237, loss: 0.366091\n",
      "validation accuracy: 62.899093 (144839 / 230272), f1 (weighted): 63.078333, loss: 1.112947\n",
      "time: 16024s (wall 10935s)\n",
      "\n",
      "\n",
      "step 27500 / 269850 (epoch 30.57 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.410534\n",
      "Training   accuracy: 84.960938 (870 / 1024), f1 (weighted): 84.978335, loss: 0.386780\n",
      "validation accuracy: 62.400987 (143692 / 230272), f1 (weighted): 62.667500, loss: 1.133724\n",
      "time: 16081s (wall 10973s)\n",
      "\n",
      "\n",
      "step 27600 / 269850 (epoch 30.68 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.407859\n",
      "Training   accuracy: 85.253906 (873 / 1024), f1 (weighted): 85.120120, loss: 0.404403\n",
      "validation accuracy: 62.894316 (144828 / 230272), f1 (weighted): 62.483217, loss: 1.136769\n",
      "time: 16138s (wall 11012s)\n",
      "\n",
      "\n",
      "step 27700 / 269850 (epoch 30.79 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.389073\n",
      "Training   accuracy: 85.253906 (873 / 1024), f1 (weighted): 85.230393, loss: 0.376881\n",
      "validation accuracy: 63.564828 (146372 / 230272), f1 (weighted): 63.605181, loss: 1.084796\n",
      "time: 16195s (wall 11051s)\n",
      "\n",
      "\n",
      "step 27800 / 269850 (epoch 30.91 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.409148\n",
      "Training   accuracy: 87.109375 (892 / 1024), f1 (weighted): 87.107945, loss: 0.380347\n",
      "validation accuracy: 63.298621 (145759 / 230272), f1 (weighted): 62.953755, loss: 1.113418\n",
      "time: 16253s (wall 11090s)\n",
      "\n",
      "\n",
      "step 27900 / 269850 (epoch 31.02 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.383335\n",
      "Training   accuracy: 89.160156 (913 / 1024), f1 (weighted): 89.175114, loss: 0.348774\n",
      "validation accuracy: 63.826258 (146974 / 230272), f1 (weighted): 63.479595, loss: 1.115100\n",
      "time: 16310s (wall 11129s)\n",
      "\n",
      "\n",
      "step 28000 / 269850 (epoch 31.13 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.381446\n",
      "Training   accuracy: 87.988281 (901 / 1024), f1 (weighted): 87.981130, loss: 0.356638\n",
      "validation accuracy: 63.793687 (146899 / 230272), f1 (weighted): 63.742955, loss: 1.089105\n",
      "time: 16367s (wall 11168s)\n",
      "\n",
      "\n",
      "step 28100 / 269850 (epoch 31.24 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.382795\n",
      "Training   accuracy: 87.402344 (895 / 1024), f1 (weighted): 87.327551, loss: 0.353043\n",
      "validation accuracy: 64.162382 (147748 / 230272), f1 (weighted): 64.101284, loss: 1.077709\n",
      "time: 16424s (wall 11207s)\n",
      "\n",
      "\n",
      "step 28200 / 269850 (epoch 31.35 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.394545\n",
      "Training   accuracy: 86.621094 (887 / 1024), f1 (weighted): 86.618271, loss: 0.366180\n",
      "validation accuracy: 63.395028 (145981 / 230272), f1 (weighted): 63.132256, loss: 1.115910\n",
      "time: 16482s (wall 11246s)\n",
      "\n",
      "\n",
      "step 28300 / 269850 (epoch 31.46 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.393484\n",
      "Training   accuracy: 84.960938 (870 / 1024), f1 (weighted): 84.976179, loss: 0.387570\n",
      "validation accuracy: 63.682080 (146642 / 230272), f1 (weighted): 63.575525, loss: 1.086828\n",
      "time: 16539s (wall 11284s)\n",
      "\n",
      "\n",
      "step 28400 / 269850 (epoch 31.57 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.403525\n",
      "Training   accuracy: 87.402344 (895 / 1024), f1 (weighted): 87.349238, loss: 0.365490\n",
      "validation accuracy: 62.975959 (145016 / 230272), f1 (weighted): 62.974355, loss: 1.115703\n",
      "time: 16596s (wall 11323s)\n",
      "\n",
      "\n",
      "step 28500 / 269850 (epoch 31.68 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.404748\n",
      "Training   accuracy: 84.765625 (868 / 1024), f1 (weighted): 84.797782, loss: 0.382839\n",
      "validation accuracy: 63.419348 (146037 / 230272), f1 (weighted): 63.710789, loss: 1.098316\n",
      "time: 16654s (wall 11362s)\n",
      "\n",
      "\n",
      "step 28600 / 269850 (epoch 31.80 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.388748\n",
      "Training   accuracy: 87.402344 (895 / 1024), f1 (weighted): 87.391312, loss: 0.347044\n",
      "validation accuracy: 64.005611 (147387 / 230272), f1 (weighted): 63.844196, loss: 1.089218\n",
      "time: 16711s (wall 11401s)\n",
      "\n",
      "\n",
      "step 28700 / 269850 (epoch 31.91 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.393879\n",
      "Training   accuracy: 86.035156 (881 / 1024), f1 (weighted): 85.972991, loss: 0.378393\n",
      "validation accuracy: 64.033404 (147451 / 230272), f1 (weighted): 64.014682, loss: 1.063370\n",
      "time: 16768s (wall 11440s)\n",
      "\n",
      "\n",
      "step 28800 / 269850 (epoch 32.02 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.380948\n",
      "Training   accuracy: 87.207031 (893 / 1024), f1 (weighted): 87.197722, loss: 0.354709\n",
      "validation accuracy: 63.539640 (146314 / 230272), f1 (weighted): 63.595935, loss: 1.115564\n",
      "time: 16825s (wall 11479s)\n",
      "\n",
      "\n",
      "step 28900 / 269850 (epoch 32.13 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.395884\n",
      "Training   accuracy: 86.718750 (888 / 1024), f1 (weighted): 86.758160, loss: 0.372261\n",
      "validation accuracy: 63.671658 (146618 / 230272), f1 (weighted): 63.311830, loss: 1.101866\n",
      "time: 16882s (wall 11518s)\n",
      "\n",
      "\n",
      "step 29000 / 269850 (epoch 32.24 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.397250\n",
      "Training   accuracy: 85.156250 (872 / 1024), f1 (weighted): 85.236472, loss: 0.406853\n",
      "validation accuracy: 62.792263 (144593 / 230272), f1 (weighted): 62.806757, loss: 1.135061\n",
      "time: 16939s (wall 11557s)\n",
      "\n",
      "\n",
      "step 29100 / 269850 (epoch 32.35 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.384278\n",
      "Training   accuracy: 89.160156 (913 / 1024), f1 (weighted): 89.111596, loss: 0.353562\n",
      "validation accuracy: 63.399371 (145991 / 230272), f1 (weighted): 63.228259, loss: 1.099773\n",
      "time: 16996s (wall 11595s)\n",
      "\n",
      "\n",
      "step 29200 / 269850 (epoch 32.46 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.388107\n",
      "Training   accuracy: 86.816406 (889 / 1024), f1 (weighted): 86.781732, loss: 0.365470\n",
      "validation accuracy: 63.706399 (146698 / 230272), f1 (weighted): 63.593466, loss: 1.100018\n",
      "time: 17054s (wall 11634s)\n",
      "\n",
      "\n",
      "step 29300 / 269850 (epoch 32.57 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.380665\n",
      "Training   accuracy: 88.476562 (906 / 1024), f1 (weighted): 88.497402, loss: 0.324922\n",
      "validation accuracy: 63.742878 (146782 / 230272), f1 (weighted): 63.634326, loss: 1.101312\n",
      "time: 17111s (wall 11673s)\n",
      "\n",
      "\n",
      "step 29400 / 269850 (epoch 32.68 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.397137\n",
      "Training   accuracy: 86.621094 (887 / 1024), f1 (weighted): 86.638034, loss: 0.371137\n",
      "validation accuracy: 64.236642 (147919 / 230272), f1 (weighted): 64.139217, loss: 1.073424\n",
      "time: 17168s (wall 11712s)\n",
      "\n",
      "\n",
      "step 29500 / 269850 (epoch 32.80 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.387957\n",
      "Training   accuracy: 89.550781 (917 / 1024), f1 (weighted): 89.513425, loss: 0.333449\n",
      "validation accuracy: 64.155868 (147733 / 230272), f1 (weighted): 63.796356, loss: 1.087011\n",
      "time: 17225s (wall 11751s)\n",
      "\n",
      "\n",
      "step 29600 / 269850 (epoch 32.91 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.405080\n",
      "Training   accuracy: 86.328125 (884 / 1024), f1 (weighted): 86.291623, loss: 0.374288\n",
      "validation accuracy: 63.787608 (146885 / 230272), f1 (weighted): 63.523210, loss: 1.093517\n",
      "time: 17283s (wall 11790s)\n",
      "\n",
      "\n",
      "step 29700 / 269850 (epoch 33.02 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.393497\n",
      "Training   accuracy: 85.742188 (878 / 1024), f1 (weighted): 85.808111, loss: 0.399710\n",
      "validation accuracy: 62.916898 (144880 / 230272), f1 (weighted): 62.884511, loss: 1.130726\n",
      "time: 17340s (wall 11829s)\n",
      "\n",
      "\n",
      "step 29800 / 269850 (epoch 33.13 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.378378\n",
      "Training   accuracy: 88.867188 (910 / 1024), f1 (weighted): 88.814874, loss: 0.331265\n",
      "validation accuracy: 63.484054 (146186 / 230272), f1 (weighted): 62.949083, loss: 1.132017\n",
      "time: 17397s (wall 11868s)\n",
      "\n",
      "\n",
      "step 29900 / 269850 (epoch 33.24 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.387334\n",
      "Training   accuracy: 86.035156 (881 / 1024), f1 (weighted): 86.020033, loss: 0.367753\n",
      "validation accuracy: 63.862302 (147057 / 230272), f1 (weighted): 63.810960, loss: 1.086414\n",
      "time: 17454s (wall 11907s)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 30000 / 269850 (epoch 33.35 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.384373\n",
      "Training   accuracy: 86.816406 (889 / 1024), f1 (weighted): 86.890362, loss: 0.346661\n",
      "validation accuracy: 63.401543 (145996 / 230272), f1 (weighted): 63.477046, loss: 1.104294\n",
      "time: 17511s (wall 11945s)\n",
      "\n",
      "\n",
      "step 30100 / 269850 (epoch 33.46 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.373466\n",
      "Training   accuracy: 87.988281 (901 / 1024), f1 (weighted): 87.902076, loss: 0.346194\n",
      "validation accuracy: 63.850577 (147030 / 230272), f1 (weighted): 63.566148, loss: 1.102317\n",
      "time: 17569s (wall 11984s)\n",
      "\n",
      "\n",
      "step 30200 / 269850 (epoch 33.57 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.380490\n",
      "Training   accuracy: 87.597656 (897 / 1024), f1 (weighted): 87.478138, loss: 0.349946\n",
      "validation accuracy: 64.015599 (147410 / 230272), f1 (weighted): 63.548278, loss: 1.096760\n",
      "time: 17626s (wall 12023s)\n",
      "\n",
      "\n",
      "step 30300 / 269850 (epoch 33.69 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.404811\n",
      "Training   accuracy: 85.449219 (875 / 1024), f1 (weighted): 85.480722, loss: 0.375193\n",
      "validation accuracy: 63.666012 (146605 / 230272), f1 (weighted): 63.595318, loss: 1.072125\n",
      "time: 17683s (wall 12062s)\n",
      "\n",
      "\n",
      "step 30400 / 269850 (epoch 33.80 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.382177\n",
      "Training   accuracy: 87.695312 (898 / 1024), f1 (weighted): 87.706485, loss: 0.345587\n",
      "validation accuracy: 63.945247 (147248 / 230272), f1 (weighted): 63.771168, loss: 1.110427\n",
      "time: 17741s (wall 12101s)\n",
      "\n",
      "\n",
      "step 30500 / 269850 (epoch 33.91 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.389165\n",
      "Training   accuracy: 87.500000 (896 / 1024), f1 (weighted): 87.480893, loss: 0.364403\n",
      "validation accuracy: 63.809755 (146936 / 230272), f1 (weighted): 63.871901, loss: 1.082558\n",
      "time: 17798s (wall 12140s)\n",
      "\n",
      "\n",
      "step 30600 / 269850 (epoch 34.02 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.377307\n",
      "Training   accuracy: 88.574219 (907 / 1024), f1 (weighted): 88.585182, loss: 0.334384\n",
      "validation accuracy: 63.879238 (147096 / 230272), f1 (weighted): 63.790452, loss: 1.117006\n",
      "time: 17855s (wall 12179s)\n",
      "\n",
      "\n",
      "step 30700 / 269850 (epoch 34.13 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.379743\n",
      "Training   accuracy: 87.597656 (897 / 1024), f1 (weighted): 87.572694, loss: 0.346715\n",
      "validation accuracy: 64.120692 (147652 / 230272), f1 (weighted): 63.969884, loss: 1.086437\n",
      "time: 17912s (wall 12218s)\n",
      "\n",
      "\n",
      "step 30800 / 269850 (epoch 34.24 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.371080\n",
      "Training   accuracy: 88.378906 (905 / 1024), f1 (weighted): 88.353261, loss: 0.333033\n",
      "validation accuracy: 63.848840 (147026 / 230272), f1 (weighted): 63.448054, loss: 1.125393\n",
      "time: 17969s (wall 12257s)\n",
      "\n",
      "\n",
      "step 30900 / 269850 (epoch 34.35 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.396325\n",
      "Training   accuracy: 87.597656 (897 / 1024), f1 (weighted): 87.633515, loss: 0.362780\n",
      "validation accuracy: 63.276039 (145707 / 230272), f1 (weighted): 63.427512, loss: 1.114621\n",
      "time: 18026s (wall 12296s)\n",
      "\n",
      "\n",
      "step 31000 / 269850 (epoch 34.46 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.386772\n",
      "Training   accuracy: 87.207031 (893 / 1024), f1 (weighted): 87.156494, loss: 0.351234\n",
      "validation accuracy: 63.720296 (146730 / 230272), f1 (weighted): 63.589549, loss: 1.106813\n",
      "time: 18083s (wall 12334s)\n",
      "\n",
      "\n",
      "step 31100 / 269850 (epoch 34.57 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.397799\n",
      "Training   accuracy: 85.351562 (874 / 1024), f1 (weighted): 85.441449, loss: 0.400284\n",
      "validation accuracy: 63.263445 (145678 / 230272), f1 (weighted): 63.348008, loss: 1.110970\n",
      "time: 18140s (wall 12373s)\n",
      "\n",
      "\n",
      "step 31200 / 269850 (epoch 34.69 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.399343\n",
      "Training   accuracy: 86.718750 (888 / 1024), f1 (weighted): 86.673883, loss: 0.354439\n",
      "validation accuracy: 63.411531 (146019 / 230272), f1 (weighted): 63.268405, loss: 1.091694\n",
      "time: 18198s (wall 12412s)\n",
      "\n",
      "\n",
      "step 31300 / 269850 (epoch 34.80 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.397995\n",
      "Training   accuracy: 85.937500 (880 / 1024), f1 (weighted): 85.878062, loss: 0.387713\n",
      "validation accuracy: 63.455392 (146120 / 230272), f1 (weighted): 62.732390, loss: 1.139490\n",
      "time: 18255s (wall 12451s)\n",
      "\n",
      "\n",
      "step 31400 / 269850 (epoch 34.91 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.388539\n",
      "Training   accuracy: 87.207031 (893 / 1024), f1 (weighted): 87.145884, loss: 0.353037\n",
      "validation accuracy: 64.169764 (147765 / 230272), f1 (weighted): 63.902516, loss: 1.082393\n",
      "time: 18312s (wall 12490s)\n",
      "\n",
      "\n",
      "step 31500 / 269850 (epoch 35.02 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.368413\n",
      "Training   accuracy: 87.402344 (895 / 1024), f1 (weighted): 87.342327, loss: 0.346509\n",
      "validation accuracy: 64.372568 (148232 / 230272), f1 (weighted): 64.225010, loss: 1.084065\n",
      "time: 18370s (wall 12529s)\n",
      "\n",
      "\n",
      "step 31600 / 269850 (epoch 35.13 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.376875\n",
      "Training   accuracy: 88.476562 (906 / 1024), f1 (weighted): 88.503456, loss: 0.342826\n",
      "validation accuracy: 63.510110 (146246 / 230272), f1 (weighted): 63.440634, loss: 1.110597\n",
      "time: 18427s (wall 12568s)\n",
      "\n",
      "\n",
      "step 31700 / 269850 (epoch 35.24 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.377340\n",
      "Training   accuracy: 87.500000 (896 / 1024), f1 (weighted): 87.453276, loss: 0.367337\n",
      "validation accuracy: 63.715519 (146719 / 230272), f1 (weighted): 63.452424, loss: 1.121814\n",
      "time: 18484s (wall 12607s)\n",
      "\n",
      "\n",
      "step 31800 / 269850 (epoch 35.35 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.384384\n",
      "Training   accuracy: 88.867188 (910 / 1024), f1 (weighted): 88.833532, loss: 0.338409\n",
      "validation accuracy: 64.262698 (147979 / 230272), f1 (weighted): 64.103777, loss: 1.073469\n",
      "time: 18541s (wall 12646s)\n",
      "\n",
      "\n",
      "step 31900 / 269850 (epoch 35.46 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.377198\n",
      "Training   accuracy: 87.695312 (898 / 1024), f1 (weighted): 87.690748, loss: 0.351056\n",
      "validation accuracy: 64.217100 (147874 / 230272), f1 (weighted): 64.095982, loss: 1.106174\n",
      "time: 18598s (wall 12685s)\n",
      "\n",
      "\n",
      "step 32000 / 269850 (epoch 35.58 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.394567\n",
      "Training   accuracy: 86.718750 (888 / 1024), f1 (weighted): 86.629315, loss: 0.370045\n",
      "validation accuracy: 64.107664 (147622 / 230272), f1 (weighted): 63.886077, loss: 1.091626\n",
      "time: 18656s (wall 12724s)\n",
      "\n",
      "\n",
      "step 32100 / 269850 (epoch 35.69 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.393436\n",
      "Training   accuracy: 85.742188 (878 / 1024), f1 (weighted): 85.595348, loss: 0.388766\n",
      "validation accuracy: 63.390252 (145970 / 230272), f1 (weighted): 62.919974, loss: 1.118223\n",
      "time: 18712s (wall 12762s)\n",
      "\n",
      "\n",
      "step 32200 / 269850 (epoch 35.80 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.392267\n",
      "Training   accuracy: 86.328125 (884 / 1024), f1 (weighted): 86.322066, loss: 0.382777\n",
      "validation accuracy: 62.733202 (144457 / 230272), f1 (weighted): 62.879055, loss: 1.156448\n",
      "time: 18770s (wall 12801s)\n",
      "\n",
      "\n",
      "step 32300 / 269850 (epoch 35.91 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.389267\n",
      "Training   accuracy: 85.644531 (877 / 1024), f1 (weighted): 85.659364, loss: 0.380500\n",
      "validation accuracy: 63.475803 (146167 / 230272), f1 (weighted): 63.451747, loss: 1.118484\n",
      "time: 18827s (wall 12840s)\n",
      "\n",
      "\n",
      "step 32400 / 269850 (epoch 36.02 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.373243\n",
      "Training   accuracy: 87.402344 (895 / 1024), f1 (weighted): 87.392527, loss: 0.354760\n",
      "validation accuracy: 64.098544 (147601 / 230272), f1 (weighted): 64.082635, loss: 1.108921\n",
      "time: 18885s (wall 12879s)\n",
      "\n",
      "\n",
      "step 32500 / 269850 (epoch 36.13 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.381013\n",
      "Training   accuracy: 86.718750 (888 / 1024), f1 (weighted): 86.690021, loss: 0.375210\n",
      "validation accuracy: 64.347380 (148174 / 230272), f1 (weighted): 64.392018, loss: 1.094893\n",
      "time: 18942s (wall 12918s)\n",
      "\n",
      "\n",
      "step 32600 / 269850 (epoch 36.24 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.374264\n",
      "Training   accuracy: 88.574219 (907 / 1024), f1 (weighted): 88.534321, loss: 0.332504\n",
      "validation accuracy: 64.152828 (147726 / 230272), f1 (weighted): 63.812165, loss: 1.108394\n",
      "time: 18999s (wall 12957s)\n",
      "\n",
      "\n",
      "step 32700 / 269850 (epoch 36.35 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.391664\n",
      "Training   accuracy: 87.597656 (897 / 1024), f1 (weighted): 87.621861, loss: 0.362150\n",
      "validation accuracy: 62.742756 (144479 / 230272), f1 (weighted): 62.817972, loss: 1.140159\n",
      "time: 19056s (wall 12996s)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 32800 / 269850 (epoch 36.46 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.378243\n",
      "Training   accuracy: 90.039062 (922 / 1024), f1 (weighted): 90.018086, loss: 0.306844\n",
      "validation accuracy: 64.049906 (147489 / 230272), f1 (weighted): 63.970144, loss: 1.083817\n",
      "time: 19114s (wall 13035s)\n",
      "\n",
      "\n",
      "step 32900 / 269850 (epoch 36.58 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.380080\n",
      "Training   accuracy: 87.402344 (895 / 1024), f1 (weighted): 87.379628, loss: 0.361747\n",
      "validation accuracy: 64.299611 (148064 / 230272), f1 (weighted): 64.165259, loss: 1.084580\n",
      "time: 19171s (wall 13074s)\n",
      "\n",
      "\n",
      "step 33000 / 269850 (epoch 36.69 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.379090\n",
      "Training   accuracy: 88.085938 (902 / 1024), f1 (weighted): 88.081036, loss: 0.357869\n",
      "validation accuracy: 64.423378 (148349 / 230272), f1 (weighted): 64.391242, loss: 1.057642\n",
      "time: 19228s (wall 13113s)\n",
      "\n",
      "\n",
      "step 33100 / 269850 (epoch 36.80 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.365749\n",
      "Training   accuracy: 87.304688 (894 / 1024), f1 (weighted): 87.296190, loss: 0.358691\n",
      "validation accuracy: 63.648642 (146565 / 230272), f1 (weighted): 63.752858, loss: 1.105463\n",
      "time: 19285s (wall 13152s)\n",
      "\n",
      "\n",
      "step 33200 / 269850 (epoch 36.91 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.378644\n",
      "Training   accuracy: 86.816406 (889 / 1024), f1 (weighted): 86.807492, loss: 0.366687\n",
      "validation accuracy: 63.898346 (147140 / 230272), f1 (weighted): 63.673300, loss: 1.109430\n",
      "time: 19343s (wall 13191s)\n",
      "\n",
      "\n",
      "step 33300 / 269850 (epoch 37.02 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.357654\n",
      "Training   accuracy: 89.257812 (914 / 1024), f1 (weighted): 89.201488, loss: 0.320624\n",
      "validation accuracy: 64.073791 (147544 / 230272), f1 (weighted): 63.667914, loss: 1.105516\n",
      "time: 19400s (wall 13229s)\n",
      "\n",
      "\n",
      "step 33400 / 269850 (epoch 37.13 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.361025\n",
      "Training   accuracy: 86.132812 (882 / 1024), f1 (weighted): 86.103927, loss: 0.353227\n",
      "validation accuracy: 63.930048 (147213 / 230272), f1 (weighted): 63.941774, loss: 1.081782\n",
      "time: 19457s (wall 13268s)\n",
      "\n",
      "\n",
      "step 33500 / 269850 (epoch 37.24 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.369823\n",
      "Training   accuracy: 87.695312 (898 / 1024), f1 (weighted): 87.665510, loss: 0.356042\n",
      "validation accuracy: 63.566999 (146377 / 230272), f1 (weighted): 63.635699, loss: 1.123599\n",
      "time: 19514s (wall 13307s)\n",
      "\n",
      "\n",
      "step 33600 / 269850 (epoch 37.35 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.369029\n",
      "Training   accuracy: 89.257812 (914 / 1024), f1 (weighted): 89.215493, loss: 0.320059\n",
      "validation accuracy: 63.827560 (146977 / 230272), f1 (weighted): 63.570452, loss: 1.108464\n",
      "time: 19572s (wall 13346s)\n",
      "\n",
      "\n",
      "step 33700 / 269850 (epoch 37.47 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.382490\n",
      "Training   accuracy: 87.109375 (892 / 1024), f1 (weighted): 87.098459, loss: 0.364149\n",
      "validation accuracy: 63.714651 (146717 / 230272), f1 (weighted): 63.710450, loss: 1.125589\n",
      "time: 19629s (wall 13385s)\n",
      "\n",
      "\n",
      "step 33800 / 269850 (epoch 37.58 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.374419\n",
      "Training   accuracy: 89.160156 (913 / 1024), f1 (weighted): 89.200426, loss: 0.337474\n",
      "validation accuracy: 63.038059 (145159 / 230272), f1 (weighted): 63.255679, loss: 1.151806\n",
      "time: 19686s (wall 13424s)\n",
      "\n",
      "\n",
      "step 33900 / 269850 (epoch 37.69 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.372084\n",
      "Training   accuracy: 87.695312 (898 / 1024), f1 (weighted): 87.700829, loss: 0.342614\n",
      "validation accuracy: 63.514887 (146257 / 230272), f1 (weighted): 63.533080, loss: 1.131562\n",
      "time: 19743s (wall 13463s)\n",
      "\n",
      "\n",
      "step 34000 / 269850 (epoch 37.80 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.373813\n",
      "Training   accuracy: 86.425781 (885 / 1024), f1 (weighted): 86.411387, loss: 0.371017\n",
      "validation accuracy: 63.875764 (147088 / 230272), f1 (weighted): 63.464262, loss: 1.126900\n",
      "time: 19800s (wall 13502s)\n",
      "\n",
      "\n",
      "step 34100 / 269850 (epoch 37.91 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.374480\n",
      "Training   accuracy: 88.574219 (907 / 1024), f1 (weighted): 88.495164, loss: 0.320010\n",
      "validation accuracy: 64.321759 (148115 / 230272), f1 (weighted): 64.318252, loss: 1.079292\n",
      "time: 19858s (wall 13541s)\n",
      "\n",
      "\n",
      "step 34200 / 269850 (epoch 38.02 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.356178\n",
      "Training   accuracy: 88.769531 (909 / 1024), f1 (weighted): 88.751352, loss: 0.336184\n",
      "validation accuracy: 64.139366 (147695 / 230272), f1 (weighted): 64.264288, loss: 1.115844\n",
      "time: 19915s (wall 13580s)\n",
      "\n",
      "\n",
      "step 34300 / 269850 (epoch 38.13 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.363640\n",
      "Training   accuracy: 88.964844 (911 / 1024), f1 (weighted): 88.950047, loss: 0.342426\n",
      "validation accuracy: 64.281372 (148022 / 230272), f1 (weighted): 64.306128, loss: 1.104167\n",
      "time: 19972s (wall 13618s)\n",
      "\n",
      "\n",
      "step 34400 / 269850 (epoch 38.24 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.363941\n",
      "Training   accuracy: 88.183594 (903 / 1024), f1 (weighted): 88.107801, loss: 0.341791\n",
      "validation accuracy: 64.296137 (148056 / 230272), f1 (weighted): 64.160576, loss: 1.095308\n",
      "time: 20029s (wall 13657s)\n",
      "\n",
      "\n",
      "step 34500 / 269850 (epoch 38.35 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.377541\n",
      "Training   accuracy: 87.207031 (893 / 1024), f1 (weighted): 87.215428, loss: 0.362042\n",
      "validation accuracy: 63.963487 (147290 / 230272), f1 (weighted): 64.092023, loss: 1.087876\n",
      "time: 20086s (wall 13696s)\n",
      "\n",
      "\n",
      "step 34600 / 269850 (epoch 38.47 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.366266\n",
      "Training   accuracy: 87.792969 (899 / 1024), f1 (weighted): 87.815671, loss: 0.334050\n",
      "validation accuracy: 63.841891 (147010 / 230272), f1 (weighted): 63.563346, loss: 1.117003\n",
      "time: 20144s (wall 13735s)\n",
      "\n",
      "\n",
      "step 34700 / 269850 (epoch 38.58 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.367962\n",
      "Training   accuracy: 87.695312 (898 / 1024), f1 (weighted): 87.636718, loss: 0.351475\n",
      "validation accuracy: 64.204072 (147844 / 230272), f1 (weighted): 63.673066, loss: 1.134750\n",
      "time: 20201s (wall 13774s)\n",
      "\n",
      "\n",
      "step 34800 / 269850 (epoch 38.69 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.373670\n",
      "Training   accuracy: 87.695312 (898 / 1024), f1 (weighted): 87.668528, loss: 0.340686\n",
      "validation accuracy: 64.066408 (147527 / 230272), f1 (weighted): 63.980195, loss: 1.101495\n",
      "time: 20258s (wall 13813s)\n",
      "\n",
      "\n",
      "step 34900 / 269850 (epoch 38.80 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.382714\n",
      "Training   accuracy: 87.695312 (898 / 1024), f1 (weighted): 87.621139, loss: 0.344392\n",
      "validation accuracy: 63.764157 (146831 / 230272), f1 (weighted): 63.487871, loss: 1.125704\n",
      "time: 20315s (wall 13852s)\n",
      "\n",
      "\n",
      "step 35000 / 269850 (epoch 38.91 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.386830\n",
      "Training   accuracy: 87.597656 (897 / 1024), f1 (weighted): 87.599150, loss: 0.344397\n",
      "validation accuracy: 63.854919 (147040 / 230272), f1 (weighted): 63.683055, loss: 1.132793\n",
      "time: 20372s (wall 13891s)\n",
      "\n",
      "\n",
      "step 35100 / 269850 (epoch 39.02 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.362566\n",
      "Training   accuracy: 88.476562 (906 / 1024), f1 (weighted): 88.494476, loss: 0.323163\n",
      "validation accuracy: 63.989109 (147349 / 230272), f1 (weighted): 64.076434, loss: 1.113759\n",
      "time: 20430s (wall 13929s)\n",
      "\n",
      "\n",
      "step 35200 / 269850 (epoch 39.13 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.368148\n",
      "Training   accuracy: 88.378906 (905 / 1024), f1 (weighted): 88.411789, loss: 0.329395\n",
      "validation accuracy: 63.710742 (146708 / 230272), f1 (weighted): 63.923597, loss: 1.119484\n",
      "time: 20487s (wall 13968s)\n",
      "\n",
      "\n",
      "step 35300 / 269850 (epoch 39.24 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.374810\n",
      "Training   accuracy: 87.207031 (893 / 1024), f1 (weighted): 87.237221, loss: 0.354595\n",
      "validation accuracy: 64.011691 (147401 / 230272), f1 (weighted): 64.051771, loss: 1.088880\n",
      "time: 20545s (wall 14007s)\n",
      "\n",
      "\n",
      "step 35400 / 269850 (epoch 39.36 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.369828\n",
      "Training   accuracy: 86.328125 (884 / 1024), f1 (weighted): 86.288185, loss: 0.357840\n",
      "validation accuracy: 63.972606 (147311 / 230272), f1 (weighted): 63.907783, loss: 1.098367\n",
      "time: 20602s (wall 14046s)\n",
      "\n",
      "\n",
      "step 35500 / 269850 (epoch 39.47 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.366003\n",
      "Training   accuracy: 88.769531 (909 / 1024), f1 (weighted): 88.772954, loss: 0.324584\n",
      "validation accuracy: 64.187569 (147806 / 230272), f1 (weighted): 64.264680, loss: 1.095385\n",
      "time: 20659s (wall 14085s)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 35600 / 269850 (epoch 39.58 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.363627\n",
      "Training   accuracy: 88.476562 (906 / 1024), f1 (weighted): 88.460467, loss: 0.331395\n",
      "validation accuracy: 64.343472 (148165 / 230272), f1 (weighted): 63.984722, loss: 1.105952\n",
      "time: 20716s (wall 14124s)\n",
      "\n",
      "\n",
      "step 35700 / 269850 (epoch 39.69 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.366383\n",
      "Training   accuracy: 88.085938 (902 / 1024), f1 (weighted): 88.048450, loss: 0.359995\n",
      "validation accuracy: 64.138931 (147694 / 230272), f1 (weighted): 64.142102, loss: 1.110792\n",
      "time: 20773s (wall 14163s)\n",
      "\n",
      "\n",
      "step 35800 / 269850 (epoch 39.80 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.369330\n",
      "Training   accuracy: 86.914062 (890 / 1024), f1 (weighted): 86.883273, loss: 0.349345\n",
      "validation accuracy: 64.045564 (147479 / 230272), f1 (weighted): 63.740618, loss: 1.124231\n",
      "time: 20830s (wall 14201s)\n",
      "\n",
      "\n",
      "step 35900 / 269850 (epoch 39.91 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.368659\n",
      "Training   accuracy: 87.988281 (901 / 1024), f1 (weighted): 87.981862, loss: 0.341535\n",
      "validation accuracy: 64.095070 (147593 / 230272), f1 (weighted): 63.956750, loss: 1.123341\n",
      "time: 20887s (wall 14240s)\n",
      "\n",
      "\n",
      "step 36000 / 269850 (epoch 40.02 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.355223\n",
      "Training   accuracy: 89.062500 (912 / 1024), f1 (weighted): 89.109914, loss: 0.313474\n",
      "validation accuracy: 63.798899 (146911 / 230272), f1 (weighted): 63.689826, loss: 1.116379\n",
      "time: 20945s (wall 14279s)\n",
      "\n",
      "\n",
      "step 36100 / 269850 (epoch 40.13 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.365585\n",
      "Training   accuracy: 87.792969 (899 / 1024), f1 (weighted): 87.741905, loss: 0.336818\n",
      "validation accuracy: 64.290491 (148043 / 230272), f1 (weighted): 64.060451, loss: 1.106973\n",
      "time: 21002s (wall 14318s)\n",
      "\n",
      "\n",
      "step 36200 / 269850 (epoch 40.24 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.355565\n",
      "Training   accuracy: 89.843750 (920 / 1024), f1 (weighted): 89.807665, loss: 0.321658\n",
      "validation accuracy: 63.985634 (147341 / 230272), f1 (weighted): 63.914196, loss: 1.114203\n",
      "time: 21060s (wall 14357s)\n",
      "\n",
      "\n",
      "step 36300 / 269850 (epoch 40.36 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.363411\n",
      "Training   accuracy: 88.281250 (904 / 1024), f1 (weighted): 88.307452, loss: 0.329292\n",
      "validation accuracy: 63.964355 (147292 / 230272), f1 (weighted): 63.870875, loss: 1.103672\n",
      "time: 21117s (wall 14396s)\n",
      "\n",
      "\n",
      "step 36400 / 269850 (epoch 40.47 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.362460\n",
      "Training   accuracy: 88.964844 (911 / 1024), f1 (weighted): 89.045355, loss: 0.328009\n",
      "validation accuracy: 62.953811 (144965 / 230272), f1 (weighted): 63.342358, loss: 1.162938\n",
      "time: 21174s (wall 14435s)\n",
      "\n",
      "\n",
      "step 36500 / 269850 (epoch 40.58 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.370795\n",
      "Training   accuracy: 88.281250 (904 / 1024), f1 (weighted): 88.326694, loss: 0.345183\n",
      "validation accuracy: 64.262698 (147979 / 230272), f1 (weighted): 64.350692, loss: 1.072523\n",
      "time: 21231s (wall 14474s)\n",
      "\n",
      "\n",
      "step 36600 / 269850 (epoch 40.69 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.365913\n",
      "Training   accuracy: 87.890625 (900 / 1024), f1 (weighted): 87.801727, loss: 0.342182\n",
      "validation accuracy: 63.695977 (146674 / 230272), f1 (weighted): 63.213888, loss: 1.149334\n",
      "time: 21289s (wall 14513s)\n",
      "\n",
      "\n",
      "step 36700 / 269850 (epoch 40.80 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.363145\n",
      "Training   accuracy: 88.476562 (906 / 1024), f1 (weighted): 88.478550, loss: 0.337559\n",
      "validation accuracy: 63.782831 (146874 / 230272), f1 (weighted): 63.810985, loss: 1.121998\n",
      "time: 21346s (wall 14552s)\n",
      "\n",
      "\n",
      "step 36800 / 269850 (epoch 40.91 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.363420\n",
      "Training   accuracy: 87.500000 (896 / 1024), f1 (weighted): 87.507777, loss: 0.338028\n",
      "validation accuracy: 63.947419 (147253 / 230272), f1 (weighted): 63.813832, loss: 1.104735\n",
      "time: 21403s (wall 14591s)\n",
      "\n",
      "\n",
      "step 36900 / 269850 (epoch 41.02 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.342423\n",
      "Training   accuracy: 88.574219 (907 / 1024), f1 (weighted): 88.590189, loss: 0.326422\n",
      "validation accuracy: 64.305691 (148078 / 230272), f1 (weighted): 64.390982, loss: 1.101030\n",
      "time: 21460s (wall 14630s)\n",
      "\n",
      "\n",
      "step 37000 / 269850 (epoch 41.13 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.348796\n",
      "Training   accuracy: 90.234375 (924 / 1024), f1 (weighted): 90.285649, loss: 0.302038\n",
      "validation accuracy: 64.058592 (147509 / 230272), f1 (weighted): 64.168798, loss: 1.134283\n",
      "time: 21517s (wall 14669s)\n",
      "\n",
      "\n",
      "step 37100 / 269850 (epoch 41.25 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.356434\n",
      "Training   accuracy: 88.867188 (910 / 1024), f1 (weighted): 88.922934, loss: 0.325720\n",
      "validation accuracy: 63.187882 (145504 / 230272), f1 (weighted): 63.416737, loss: 1.144944\n",
      "time: 21575s (wall 14707s)\n",
      "\n",
      "\n",
      "step 37200 / 269850 (epoch 41.36 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.361438\n",
      "Training   accuracy: 88.085938 (902 / 1024), f1 (weighted): 88.114322, loss: 0.334895\n",
      "validation accuracy: 63.378961 (145944 / 230272), f1 (weighted): 63.318603, loss: 1.151846\n",
      "time: 21632s (wall 14746s)\n",
      "\n",
      "\n",
      "step 37300 / 269850 (epoch 41.47 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.356302\n",
      "Training   accuracy: 88.769531 (909 / 1024), f1 (weighted): 88.749017, loss: 0.333955\n",
      "validation accuracy: 63.900518 (147145 / 230272), f1 (weighted): 63.805095, loss: 1.137861\n",
      "time: 21689s (wall 14785s)\n",
      "\n",
      "\n",
      "step 37400 / 269850 (epoch 41.58 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.383514\n",
      "Training   accuracy: 87.402344 (895 / 1024), f1 (weighted): 87.330271, loss: 0.359151\n",
      "validation accuracy: 63.836246 (146997 / 230272), f1 (weighted): 63.535994, loss: 1.093235\n",
      "time: 21746s (wall 14824s)\n",
      "\n",
      "\n",
      "step 37500 / 269850 (epoch 41.69 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.387877\n",
      "Training   accuracy: 87.402344 (895 / 1024), f1 (weighted): 87.403423, loss: 0.369707\n",
      "validation accuracy: 62.382313 (143649 / 230272), f1 (weighted): 62.298323, loss: 1.189504\n",
      "time: 21803s (wall 14863s)\n",
      "\n",
      "\n",
      "step 37600 / 269850 (epoch 41.80 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.370821\n",
      "Training   accuracy: 87.695312 (898 / 1024), f1 (weighted): 87.705471, loss: 0.342474\n",
      "validation accuracy: 63.788911 (146888 / 230272), f1 (weighted): 63.629853, loss: 1.119101\n",
      "time: 21861s (wall 14902s)\n",
      "\n",
      "\n",
      "step 37700 / 269850 (epoch 41.91 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.384415\n",
      "Training   accuracy: 85.937500 (880 / 1024), f1 (weighted): 85.925380, loss: 0.376913\n",
      "validation accuracy: 63.411096 (146018 / 230272), f1 (weighted): 63.335366, loss: 1.143268\n",
      "time: 21918s (wall 14941s)\n",
      "\n",
      "\n",
      "step 37800 / 269850 (epoch 42.02 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.358602\n",
      "Training   accuracy: 90.917969 (931 / 1024), f1 (weighted): 90.901042, loss: 0.286917\n",
      "validation accuracy: 63.785002 (146879 / 230272), f1 (weighted): 63.401291, loss: 1.166623\n",
      "time: 21975s (wall 14980s)\n",
      "\n",
      "\n",
      "step 37900 / 269850 (epoch 42.13 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.392913\n",
      "Training   accuracy: 87.500000 (896 / 1024), f1 (weighted): 87.535373, loss: 0.374762\n",
      "validation accuracy: 62.829176 (144678 / 230272), f1 (weighted): 62.988149, loss: 1.181096\n",
      "time: 22033s (wall 15018s)\n",
      "\n",
      "\n",
      "step 38000 / 269850 (epoch 42.25 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.436808\n",
      "Training   accuracy: 83.984375 (860 / 1024), f1 (weighted): 84.006248, loss: 0.424516\n",
      "validation accuracy: 60.906667 (140251 / 230272), f1 (weighted): 60.795019, loss: 1.259355\n",
      "time: 22090s (wall 15057s)\n",
      "\n",
      "\n",
      "step 38100 / 269850 (epoch 42.36 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.387516\n",
      "Training   accuracy: 87.988281 (901 / 1024), f1 (weighted): 87.935574, loss: 0.351880\n",
      "validation accuracy: 63.668618 (146611 / 230272), f1 (weighted): 63.315916, loss: 1.155195\n",
      "time: 22147s (wall 15096s)\n",
      "\n",
      "\n",
      "step 38200 / 269850 (epoch 42.47 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.369589\n",
      "Training   accuracy: 88.867188 (910 / 1024), f1 (weighted): 88.824728, loss: 0.320246\n",
      "validation accuracy: 64.234036 (147913 / 230272), f1 (weighted): 64.198539, loss: 1.118230\n",
      "time: 22204s (wall 15135s)\n",
      "\n",
      "\n",
      "step 38300 / 269850 (epoch 42.58 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.357196\n",
      "Training   accuracy: 87.304688 (894 / 1024), f1 (weighted): 87.259256, loss: 0.346223\n",
      "validation accuracy: 64.130680 (147675 / 230272), f1 (weighted): 64.005028, loss: 1.106530\n",
      "time: 22261s (wall 15174s)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 38400 / 269850 (epoch 42.69 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.360103\n",
      "Training   accuracy: 88.867188 (910 / 1024), f1 (weighted): 88.914143, loss: 0.316379\n",
      "validation accuracy: 63.988674 (147348 / 230272), f1 (weighted): 63.976143, loss: 1.136003\n",
      "time: 22319s (wall 15213s)\n",
      "\n",
      "\n",
      "step 38500 / 269850 (epoch 42.80 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.370781\n",
      "Training   accuracy: 86.914062 (890 / 1024), f1 (weighted): 86.952077, loss: 0.357959\n",
      "validation accuracy: 64.511100 (148551 / 230272), f1 (weighted): 64.468782, loss: 1.106245\n",
      "time: 22376s (wall 15252s)\n",
      "\n",
      "\n",
      "step 38600 / 269850 (epoch 42.91 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.362600\n",
      "Training   accuracy: 87.988281 (901 / 1024), f1 (weighted): 88.037540, loss: 0.335783\n",
      "validation accuracy: 64.078134 (147554 / 230272), f1 (weighted): 64.266333, loss: 1.111343\n",
      "time: 22433s (wall 15291s)\n",
      "\n",
      "\n",
      "step 38700 / 269850 (epoch 43.02 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.354459\n",
      "Training   accuracy: 90.136719 (923 / 1024), f1 (weighted): 90.114849, loss: 0.318901\n",
      "validation accuracy: 64.012993 (147404 / 230272), f1 (weighted): 63.659976, loss: 1.152558\n",
      "time: 22490s (wall 15329s)\n",
      "\n",
      "\n",
      "step 38800 / 269850 (epoch 43.14 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.357201\n",
      "Training   accuracy: 88.671875 (908 / 1024), f1 (weighted): 88.614073, loss: 0.346450\n",
      "validation accuracy: 64.234905 (147915 / 230272), f1 (weighted): 64.040200, loss: 1.105876\n",
      "time: 22547s (wall 15368s)\n",
      "\n",
      "\n",
      "step 38900 / 269850 (epoch 43.25 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.352858\n",
      "Training   accuracy: 88.574219 (907 / 1024), f1 (weighted): 88.537191, loss: 0.307779\n",
      "validation accuracy: 64.185398 (147801 / 230272), f1 (weighted): 63.800922, loss: 1.140432\n",
      "time: 22605s (wall 15407s)\n",
      "\n",
      "\n",
      "step 39000 / 269850 (epoch 43.36 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.353457\n",
      "Training   accuracy: 86.914062 (890 / 1024), f1 (weighted): 86.967954, loss: 0.365570\n",
      "validation accuracy: 64.045564 (147479 / 230272), f1 (weighted): 63.651918, loss: 1.167501\n",
      "time: 22662s (wall 15446s)\n",
      "\n",
      "\n",
      "step 39100 / 269850 (epoch 43.47 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.360249\n",
      "Training   accuracy: 89.062500 (912 / 1024), f1 (weighted): 89.059846, loss: 0.333205\n",
      "validation accuracy: 64.178884 (147786 / 230272), f1 (weighted): 64.045590, loss: 1.107390\n",
      "time: 22719s (wall 15485s)\n",
      "\n",
      "\n",
      "step 39200 / 269850 (epoch 43.58 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.352991\n",
      "Training   accuracy: 89.062500 (912 / 1024), f1 (weighted): 89.064847, loss: 0.326322\n",
      "validation accuracy: 64.280069 (148019 / 230272), f1 (weighted): 64.150893, loss: 1.131471\n",
      "time: 22776s (wall 15524s)\n",
      "\n",
      "\n",
      "step 39300 / 269850 (epoch 43.69 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.364145\n",
      "Training   accuracy: 89.453125 (916 / 1024), f1 (weighted): 89.461740, loss: 0.310527\n",
      "validation accuracy: 64.275292 (148008 / 230272), f1 (weighted): 64.371817, loss: 1.077424\n",
      "time: 22833s (wall 15563s)\n",
      "\n",
      "\n",
      "step 39400 / 269850 (epoch 43.80 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.369379\n",
      "Training   accuracy: 87.695312 (898 / 1024), f1 (weighted): 87.751072, loss: 0.338752\n",
      "validation accuracy: 63.857525 (147046 / 230272), f1 (weighted): 63.931536, loss: 1.126178\n",
      "time: 22891s (wall 15602s)\n",
      "\n",
      "\n",
      "step 39500 / 269850 (epoch 43.91 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.352483\n",
      "Training   accuracy: 88.574219 (907 / 1024), f1 (weighted): 88.596257, loss: 0.318821\n",
      "validation accuracy: 64.221008 (147883 / 230272), f1 (weighted): 64.178613, loss: 1.118894\n",
      "time: 22948s (wall 15641s)\n",
      "\n",
      "\n",
      "step 39600 / 269850 (epoch 44.02 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.354149\n",
      "Training   accuracy: 88.476562 (906 / 1024), f1 (weighted): 88.565043, loss: 0.321463\n",
      "validation accuracy: 63.481014 (146179 / 230272), f1 (weighted): 63.436805, loss: 1.166744\n",
      "time: 23005s (wall 15680s)\n",
      "\n",
      "\n",
      "step 39700 / 269850 (epoch 44.14 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.348342\n",
      "Training   accuracy: 89.843750 (920 / 1024), f1 (weighted): 89.878051, loss: 0.304888\n",
      "validation accuracy: 63.720730 (146731 / 230272), f1 (weighted): 63.964464, loss: 1.141553\n",
      "time: 23062s (wall 15719s)\n",
      "\n",
      "\n",
      "step 39800 / 269850 (epoch 44.25 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.347296\n",
      "Training   accuracy: 88.281250 (904 / 1024), f1 (weighted): 88.248274, loss: 0.340212\n",
      "validation accuracy: 64.216666 (147873 / 230272), f1 (weighted): 64.055958, loss: 1.151293\n",
      "time: 23120s (wall 15758s)\n",
      "\n",
      "\n",
      "step 39900 / 269850 (epoch 44.36 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.374607\n",
      "Training   accuracy: 87.011719 (891 / 1024), f1 (weighted): 86.901563, loss: 0.354087\n",
      "validation accuracy: 63.372012 (145928 / 230272), f1 (weighted): 62.788696, loss: 1.195170\n",
      "time: 23177s (wall 15796s)\n",
      "\n",
      "\n",
      "step 40000 / 269850 (epoch 44.47 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.361932\n",
      "Training   accuracy: 86.718750 (888 / 1024), f1 (weighted): 86.761537, loss: 0.357098\n",
      "validation accuracy: 63.467117 (146147 / 230272), f1 (weighted): 63.651543, loss: 1.137549\n",
      "time: 23235s (wall 15835s)\n",
      "\n",
      "\n",
      "step 40100 / 269850 (epoch 44.58 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.360472\n",
      "Training   accuracy: 88.671875 (908 / 1024), f1 (weighted): 88.660979, loss: 0.317575\n",
      "validation accuracy: 64.138497 (147693 / 230272), f1 (weighted): 64.104824, loss: 1.113922\n",
      "time: 23292s (wall 15874s)\n",
      "\n",
      "\n",
      "step 40200 / 269850 (epoch 44.69 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.358492\n",
      "Training   accuracy: 88.476562 (906 / 1024), f1 (weighted): 88.469727, loss: 0.322284\n",
      "validation accuracy: 64.826814 (149278 / 230272), f1 (weighted): 64.777560, loss: 1.087862\n",
      "time: 23349s (wall 15913s)\n",
      "\n",
      "\n",
      "step 40300 / 269850 (epoch 44.80 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.371729\n",
      "Training   accuracy: 87.304688 (894 / 1024), f1 (weighted): 87.334568, loss: 0.354376\n",
      "validation accuracy: 63.996057 (147365 / 230272), f1 (weighted): 63.950657, loss: 1.111824\n",
      "time: 23406s (wall 15952s)\n",
      "\n",
      "\n",
      "step 40400 / 269850 (epoch 44.91 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.373287\n",
      "Training   accuracy: 87.792969 (899 / 1024), f1 (weighted): 87.760992, loss: 0.333604\n",
      "validation accuracy: 64.316982 (148104 / 230272), f1 (weighted): 64.172211, loss: 1.106450\n",
      "time: 23463s (wall 15991s)\n",
      "\n",
      "\n",
      "step 40500 / 269850 (epoch 45.03 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.340682\n",
      "Training   accuracy: 90.332031 (925 / 1024), f1 (weighted): 90.307854, loss: 0.304287\n",
      "validation accuracy: 64.412087 (148323 / 230272), f1 (weighted): 64.351566, loss: 1.136353\n",
      "time: 23521s (wall 16030s)\n",
      "\n",
      "\n",
      "step 40600 / 269850 (epoch 45.14 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.360620\n",
      "Training   accuracy: 89.062500 (912 / 1024), f1 (weighted): 89.020887, loss: 0.315561\n",
      "validation accuracy: 64.381688 (148253 / 230272), f1 (weighted): 64.242413, loss: 1.100257\n",
      "time: 23578s (wall 16069s)\n",
      "\n",
      "\n",
      "step 40700 / 269850 (epoch 45.25 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.358063\n",
      "Training   accuracy: 90.625000 (928 / 1024), f1 (weighted): 90.618578, loss: 0.305593\n",
      "validation accuracy: 64.089425 (147580 / 230272), f1 (weighted): 64.092632, loss: 1.134250\n",
      "time: 23635s (wall 16107s)\n",
      "\n",
      "\n",
      "step 40800 / 269850 (epoch 45.36 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.362623\n",
      "Training   accuracy: 89.746094 (919 / 1024), f1 (weighted): 89.748230, loss: 0.316499\n",
      "validation accuracy: 64.299611 (148064 / 230272), f1 (weighted): 64.225423, loss: 1.121435\n",
      "time: 23692s (wall 16146s)\n",
      "\n",
      "\n",
      "step 40900 / 269850 (epoch 45.47 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.366517\n",
      "Training   accuracy: 87.402344 (895 / 1024), f1 (weighted): 87.326397, loss: 0.343284\n",
      "validation accuracy: 63.238692 (145621 / 230272), f1 (weighted): 62.561955, loss: 1.186122\n",
      "time: 23749s (wall 16185s)\n",
      "\n",
      "\n",
      "step 41000 / 269850 (epoch 45.58 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.372948\n",
      "Training   accuracy: 88.378906 (905 / 1024), f1 (weighted): 88.310794, loss: 0.341796\n",
      "validation accuracy: 64.173673 (147774 / 230272), f1 (weighted): 64.079016, loss: 1.143308\n",
      "time: 23806s (wall 16224s)\n",
      "\n",
      "\n",
      "step 41100 / 269850 (epoch 45.69 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.371615\n",
      "Training   accuracy: 88.281250 (904 / 1024), f1 (weighted): 88.231427, loss: 0.364476\n",
      "validation accuracy: 64.046432 (147481 / 230272), f1 (weighted): 64.019835, loss: 1.122851\n",
      "time: 23863s (wall 16263s)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 41200 / 269850 (epoch 45.80 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.353067\n",
      "Training   accuracy: 88.769531 (909 / 1024), f1 (weighted): 88.721979, loss: 0.299346\n",
      "validation accuracy: 64.564081 (148673 / 230272), f1 (weighted): 64.441342, loss: 1.103012\n",
      "time: 23921s (wall 16302s)\n",
      "\n",
      "\n",
      "step 41300 / 269850 (epoch 45.91 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.398069\n",
      "Training   accuracy: 87.402344 (895 / 1024), f1 (weighted): 87.346541, loss: 0.354016\n",
      "validation accuracy: 63.593489 (146438 / 230272), f1 (weighted): 63.320300, loss: 1.138179\n",
      "time: 23978s (wall 16341s)\n",
      "\n",
      "\n",
      "step 41400 / 269850 (epoch 46.03 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.346132\n",
      "Training   accuracy: 87.109375 (892 / 1024), f1 (weighted): 87.119301, loss: 0.363073\n",
      "validation accuracy: 64.314376 (148098 / 230272), f1 (weighted): 64.305725, loss: 1.105990\n",
      "time: 24035s (wall 16380s)\n",
      "\n",
      "\n",
      "step 41500 / 269850 (epoch 46.14 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.358808\n",
      "Training   accuracy: 88.769531 (909 / 1024), f1 (weighted): 88.758364, loss: 0.315217\n",
      "validation accuracy: 64.044261 (147476 / 230272), f1 (weighted): 64.023836, loss: 1.117831\n",
      "time: 24092s (wall 16419s)\n",
      "\n",
      "\n",
      "step 41600 / 269850 (epoch 46.25 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.355841\n",
      "Training   accuracy: 87.890625 (900 / 1024), f1 (weighted): 87.845806, loss: 0.345132\n",
      "validation accuracy: 64.125903 (147664 / 230272), f1 (weighted): 63.835798, loss: 1.155705\n",
      "time: 24149s (wall 16457s)\n",
      "\n",
      "\n",
      "step 41700 / 269850 (epoch 46.36 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.351161\n",
      "Training   accuracy: 87.207031 (893 / 1024), f1 (weighted): 87.126514, loss: 0.341695\n",
      "validation accuracy: 64.234036 (147913 / 230272), f1 (weighted): 64.101779, loss: 1.130220\n",
      "time: 24206s (wall 16496s)\n",
      "\n",
      "\n",
      "step 41800 / 269850 (epoch 46.47 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.374184\n",
      "Training   accuracy: 88.574219 (907 / 1024), f1 (weighted): 88.566158, loss: 0.345579\n",
      "validation accuracy: 63.646905 (146561 / 230272), f1 (weighted): 63.514627, loss: 1.135708\n",
      "time: 24264s (wall 16535s)\n",
      "\n",
      "\n",
      "step 41900 / 269850 (epoch 46.58 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.375481\n",
      "Training   accuracy: 88.671875 (908 / 1024), f1 (weighted): 88.685068, loss: 0.338108\n",
      "validation accuracy: 63.378526 (145943 / 230272), f1 (weighted): 63.374387, loss: 1.146124\n",
      "time: 24321s (wall 16574s)\n",
      "\n",
      "\n",
      "step 42000 / 269850 (epoch 46.69 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.353065\n",
      "Training   accuracy: 88.574219 (907 / 1024), f1 (weighted): 88.565613, loss: 0.327280\n",
      "validation accuracy: 64.359974 (148203 / 230272), f1 (weighted): 64.507561, loss: 1.118464\n",
      "time: 24378s (wall 16613s)\n",
      "\n",
      "\n",
      "step 42100 / 269850 (epoch 46.80 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.365575\n",
      "Training   accuracy: 87.695312 (898 / 1024), f1 (weighted): 87.698812, loss: 0.335394\n",
      "validation accuracy: 64.613153 (148786 / 230272), f1 (weighted): 64.475764, loss: 1.101544\n",
      "time: 24435s (wall 16652s)\n",
      "\n",
      "\n",
      "step 42200 / 269850 (epoch 46.91 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.346959\n",
      "Training   accuracy: 87.890625 (900 / 1024), f1 (weighted): 87.827826, loss: 0.326382\n",
      "validation accuracy: 64.422075 (148346 / 230272), f1 (weighted): 63.903994, loss: 1.132232\n",
      "time: 24493s (wall 16691s)\n",
      "\n",
      "\n",
      "step 42300 / 269850 (epoch 47.03 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.345427\n",
      "Training   accuracy: 90.625000 (928 / 1024), f1 (weighted): 90.611087, loss: 0.301698\n",
      "validation accuracy: 63.956104 (147273 / 230272), f1 (weighted): 63.727591, loss: 1.162215\n",
      "time: 24550s (wall 16730s)\n",
      "\n",
      "\n",
      "step 42400 / 269850 (epoch 47.14 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.338695\n",
      "Training   accuracy: 90.332031 (925 / 1024), f1 (weighted): 90.321168, loss: 0.305098\n",
      "validation accuracy: 64.703481 (148994 / 230272), f1 (weighted): 64.774182, loss: 1.101916\n",
      "time: 24607s (wall 16769s)\n",
      "\n",
      "\n",
      "step 42500 / 269850 (epoch 47.25 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.346749\n",
      "Training   accuracy: 88.964844 (911 / 1024), f1 (weighted): 88.981239, loss: 0.325642\n",
      "validation accuracy: 64.458553 (148430 / 230272), f1 (weighted): 64.557691, loss: 1.114690\n",
      "time: 24664s (wall 16808s)\n",
      "\n",
      "\n",
      "step 42600 / 269850 (epoch 47.36 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.341032\n",
      "Training   accuracy: 88.964844 (911 / 1024), f1 (weighted): 88.981988, loss: 0.324683\n",
      "validation accuracy: 64.265304 (147985 / 230272), f1 (weighted): 64.017315, loss: 1.156762\n",
      "time: 24722s (wall 16846s)\n",
      "\n",
      "\n",
      "step 42700 / 269850 (epoch 47.47 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.355169\n",
      "Training   accuracy: 87.890625 (900 / 1024), f1 (weighted): 87.893155, loss: 0.316577\n",
      "validation accuracy: 64.240116 (147927 / 230272), f1 (weighted): 64.097883, loss: 1.130722\n",
      "time: 24779s (wall 16885s)\n",
      "\n",
      "\n",
      "step 42800 / 269850 (epoch 47.58 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.346965\n",
      "Training   accuracy: 89.453125 (916 / 1024), f1 (weighted): 89.431264, loss: 0.312647\n",
      "validation accuracy: 64.256184 (147964 / 230272), f1 (weighted): 64.238091, loss: 1.104670\n",
      "time: 24836s (wall 16924s)\n",
      "\n",
      "\n",
      "step 42900 / 269850 (epoch 47.69 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.342328\n",
      "Training   accuracy: 88.769531 (909 / 1024), f1 (weighted): 88.675783, loss: 0.311561\n",
      "validation accuracy: 64.534116 (148604 / 230272), f1 (weighted): 64.150133, loss: 1.106832\n",
      "time: 24893s (wall 16963s)\n",
      "\n",
      "\n",
      "step 43000 / 269850 (epoch 47.80 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.349056\n",
      "Training   accuracy: 89.941406 (921 / 1024), f1 (weighted): 89.906580, loss: 0.293162\n",
      "validation accuracy: 64.079871 (147558 / 230272), f1 (weighted): 64.006329, loss: 1.139385\n",
      "time: 24950s (wall 17002s)\n",
      "\n",
      "\n",
      "step 43100 / 269850 (epoch 47.92 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.349447\n",
      "Training   accuracy: 91.406250 (936 / 1024), f1 (weighted): 91.407584, loss: 0.292632\n",
      "validation accuracy: 64.482872 (148486 / 230272), f1 (weighted): 64.053821, loss: 1.143489\n",
      "time: 25007s (wall 17041s)\n",
      "\n",
      "\n",
      "step 43200 / 269850 (epoch 48.03 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.349017\n",
      "Training   accuracy: 89.062500 (912 / 1024), f1 (weighted): 89.030454, loss: 0.321470\n",
      "validation accuracy: 64.373002 (148233 / 230272), f1 (weighted): 64.393070, loss: 1.137877\n",
      "time: 25064s (wall 17080s)\n",
      "\n",
      "\n",
      "step 43300 / 269850 (epoch 48.14 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.345310\n",
      "Training   accuracy: 88.281250 (904 / 1024), f1 (weighted): 88.240481, loss: 0.331286\n",
      "validation accuracy: 64.364751 (148214 / 230272), f1 (weighted): 63.830872, loss: 1.144665\n",
      "time: 25122s (wall 17119s)\n",
      "\n",
      "\n",
      "step 43400 / 269850 (epoch 48.25 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.345299\n",
      "Training   accuracy: 89.062500 (912 / 1024), f1 (weighted): 89.090854, loss: 0.304013\n",
      "validation accuracy: 64.885874 (149414 / 230272), f1 (weighted): 64.921493, loss: 1.095221\n",
      "time: 25179s (wall 17158s)\n",
      "\n",
      "\n",
      "step 43500 / 269850 (epoch 48.36 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.341747\n",
      "Training   accuracy: 88.085938 (902 / 1024), f1 (weighted): 88.093156, loss: 0.335878\n",
      "validation accuracy: 63.936562 (147228 / 230272), f1 (weighted): 63.859249, loss: 1.143616\n",
      "time: 25236s (wall 17197s)\n",
      "\n",
      "\n",
      "step 43600 / 269850 (epoch 48.47 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.352086\n",
      "Training   accuracy: 90.625000 (928 / 1024), f1 (weighted): 90.619931, loss: 0.282462\n",
      "validation accuracy: 64.582320 (148715 / 230272), f1 (weighted): 64.444281, loss: 1.131124\n",
      "time: 25294s (wall 17235s)\n",
      "\n",
      "\n",
      "step 43700 / 269850 (epoch 48.58 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.354043\n",
      "Training   accuracy: 87.988281 (901 / 1024), f1 (weighted): 87.949357, loss: 0.328067\n",
      "validation accuracy: 64.077265 (147552 / 230272), f1 (weighted): 63.811408, loss: 1.170823\n",
      "time: 25351s (wall 17274s)\n",
      "\n",
      "\n",
      "step 43800 / 269850 (epoch 48.69 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.357062\n",
      "Training   accuracy: 89.160156 (913 / 1024), f1 (weighted): 89.124080, loss: 0.315163\n",
      "validation accuracy: 64.244024 (147936 / 230272), f1 (weighted): 64.197323, loss: 1.136478\n",
      "time: 25408s (wall 17313s)\n",
      "\n",
      "\n",
      "step 43900 / 269850 (epoch 48.80 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.364208\n",
      "Training   accuracy: 87.890625 (900 / 1024), f1 (weighted): 87.882663, loss: 0.353285\n",
      "validation accuracy: 64.293965 (148051 / 230272), f1 (weighted): 64.326558, loss: 1.121163\n",
      "time: 25465s (wall 17352s)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 44000 / 269850 (epoch 48.92 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.352002\n",
      "Training   accuracy: 89.941406 (921 / 1024), f1 (weighted): 89.960953, loss: 0.296755\n",
      "validation accuracy: 64.015599 (147410 / 230272), f1 (weighted): 64.167776, loss: 1.157998\n",
      "time: 25522s (wall 17391s)\n",
      "\n",
      "\n",
      "step 44100 / 269850 (epoch 49.03 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.348133\n",
      "Training   accuracy: 89.257812 (914 / 1024), f1 (weighted): 89.224119, loss: 0.312046\n",
      "validation accuracy: 64.246630 (147942 / 230272), f1 (weighted): 64.043134, loss: 1.134015\n",
      "time: 25580s (wall 17430s)\n",
      "\n",
      "\n",
      "step 44200 / 269850 (epoch 49.14 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.347332\n",
      "Training   accuracy: 89.355469 (915 / 1024), f1 (weighted): 89.311622, loss: 0.308726\n",
      "validation accuracy: 63.665144 (146603 / 230272), f1 (weighted): 63.429531, loss: 1.160986\n",
      "time: 25637s (wall 17469s)\n",
      "\n",
      "\n",
      "step 44300 / 269850 (epoch 49.25 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.341033\n",
      "Training   accuracy: 89.941406 (921 / 1024), f1 (weighted): 89.900679, loss: 0.312883\n",
      "validation accuracy: 64.592742 (148739 / 230272), f1 (weighted): 64.352953, loss: 1.135312\n",
      "time: 25694s (wall 17508s)\n",
      "\n",
      "\n",
      "step 44400 / 269850 (epoch 49.36 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.340882\n",
      "Training   accuracy: 88.769531 (909 / 1024), f1 (weighted): 88.734285, loss: 0.318663\n",
      "validation accuracy: 64.897599 (149441 / 230272), f1 (weighted): 64.783686, loss: 1.102117\n",
      "time: 25751s (wall 17546s)\n",
      "\n",
      "\n",
      "step 44500 / 269850 (epoch 49.47 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.399470\n",
      "Training   accuracy: 87.011719 (891 / 1024), f1 (weighted): 86.958374, loss: 0.357538\n",
      "validation accuracy: 62.337583 (143546 / 230272), f1 (weighted): 62.324304, loss: 1.164481\n",
      "time: 25808s (wall 17585s)\n",
      "\n",
      "\n",
      "step 44600 / 269850 (epoch 49.58 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.369577\n",
      "Training   accuracy: 87.988281 (901 / 1024), f1 (weighted): 87.977054, loss: 0.351558\n",
      "validation accuracy: 64.136326 (147688 / 230272), f1 (weighted): 63.821714, loss: 1.143409\n",
      "time: 25866s (wall 17624s)\n",
      "\n",
      "\n",
      "step 44700 / 269850 (epoch 49.69 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.349689\n",
      "Training   accuracy: 91.015625 (932 / 1024), f1 (weighted): 91.026817, loss: 0.285222\n",
      "validation accuracy: 64.160211 (147743 / 230272), f1 (weighted): 64.131401, loss: 1.132023\n",
      "time: 25923s (wall 17663s)\n",
      "\n",
      "\n",
      "step 44800 / 269850 (epoch 49.81 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.367037\n",
      "Training   accuracy: 88.281250 (904 / 1024), f1 (weighted): 88.290789, loss: 0.349982\n",
      "validation accuracy: 63.962184 (147287 / 230272), f1 (weighted): 63.722013, loss: 1.135743\n",
      "time: 25980s (wall 17702s)\n",
      "\n",
      "\n",
      "step 44900 / 269850 (epoch 49.92 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.355401\n",
      "Training   accuracy: 89.550781 (917 / 1024), f1 (weighted): 89.499895, loss: 0.319689\n",
      "validation accuracy: 64.077699 (147553 / 230272), f1 (weighted): 63.809159, loss: 1.151328\n",
      "time: 26037s (wall 17741s)\n",
      "\n",
      "\n",
      "step 45000 / 269850 (epoch 50.03 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.335264\n",
      "Training   accuracy: 88.476562 (906 / 1024), f1 (weighted): 88.418229, loss: 0.318448\n",
      "validation accuracy: 64.226219 (147895 / 230272), f1 (weighted): 63.931488, loss: 1.143650\n",
      "time: 26095s (wall 17780s)\n",
      "\n",
      "\n",
      "step 45100 / 269850 (epoch 50.14 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.345134\n",
      "Training   accuracy: 89.746094 (919 / 1024), f1 (weighted): 89.761990, loss: 0.306897\n",
      "validation accuracy: 63.508373 (146242 / 230272), f1 (weighted): 63.873466, loss: 1.163888\n",
      "time: 26152s (wall 17819s)\n",
      "\n",
      "\n",
      "step 45200 / 269850 (epoch 50.25 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.335199\n",
      "Training   accuracy: 89.550781 (917 / 1024), f1 (weighted): 89.487440, loss: 0.295052\n",
      "validation accuracy: 64.181490 (147792 / 230272), f1 (weighted): 63.977000, loss: 1.146423\n",
      "time: 26210s (wall 17858s)\n",
      "\n",
      "\n",
      "step 45300 / 269850 (epoch 50.36 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.347752\n",
      "Training   accuracy: 89.257812 (914 / 1024), f1 (weighted): 89.207635, loss: 0.318024\n",
      "validation accuracy: 63.874462 (147085 / 230272), f1 (weighted): 63.743024, loss: 1.169856\n",
      "time: 26267s (wall 17897s)\n",
      "\n",
      "\n",
      "step 45400 / 269850 (epoch 50.47 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.356738\n",
      "Training   accuracy: 89.355469 (915 / 1024), f1 (weighted): 89.312945, loss: 0.330992\n",
      "validation accuracy: 63.765460 (146834 / 230272), f1 (weighted): 63.274063, loss: 1.176331\n",
      "time: 26324s (wall 17936s)\n",
      "\n",
      "\n",
      "step 45500 / 269850 (epoch 50.58 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.333179\n",
      "Training   accuracy: 89.941406 (921 / 1024), f1 (weighted): 89.932118, loss: 0.297630\n",
      "validation accuracy: 64.343906 (148166 / 230272), f1 (weighted): 64.229071, loss: 1.136532\n",
      "time: 26381s (wall 17975s)\n",
      "\n",
      "\n",
      "step 45600 / 269850 (epoch 50.69 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.340892\n",
      "Training   accuracy: 89.843750 (920 / 1024), f1 (weighted): 89.844466, loss: 0.298842\n",
      "validation accuracy: 64.828551 (149282 / 230272), f1 (weighted): 64.702227, loss: 1.127117\n",
      "time: 26438s (wall 18013s)\n",
      "\n",
      "\n",
      "step 45700 / 269850 (epoch 50.81 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.352330\n",
      "Training   accuracy: 88.378906 (905 / 1024), f1 (weighted): 88.304122, loss: 0.326921\n",
      "validation accuracy: 64.019073 (147418 / 230272), f1 (weighted): 63.474017, loss: 1.155894\n",
      "time: 26496s (wall 18052s)\n",
      "\n",
      "\n",
      "step 45800 / 269850 (epoch 50.92 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.339872\n",
      "Training   accuracy: 89.843750 (920 / 1024), f1 (weighted): 89.819971, loss: 0.300581\n",
      "validation accuracy: 65.069570 (149837 / 230272), f1 (weighted): 64.877942, loss: 1.098437\n",
      "time: 26553s (wall 18091s)\n",
      "\n",
      "\n",
      "step 45900 / 269850 (epoch 51.03 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.338483\n",
      "Training   accuracy: 87.500000 (896 / 1024), f1 (weighted): 87.512288, loss: 0.342269\n",
      "validation accuracy: 64.028193 (147439 / 230272), f1 (weighted): 64.044932, loss: 1.170152\n",
      "time: 26610s (wall 18130s)\n",
      "\n",
      "\n",
      "step 46000 / 269850 (epoch 51.14 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.350187\n",
      "Training   accuracy: 88.085938 (902 / 1024), f1 (weighted): 88.038921, loss: 0.336751\n",
      "validation accuracy: 64.032101 (147448 / 230272), f1 (weighted): 63.832340, loss: 1.161644\n",
      "time: 26667s (wall 18169s)\n",
      "\n",
      "\n",
      "step 46100 / 269850 (epoch 51.25 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.332578\n",
      "Training   accuracy: 87.890625 (900 / 1024), f1 (weighted): 87.910451, loss: 0.336256\n",
      "validation accuracy: 64.353895 (148189 / 230272), f1 (weighted): 64.102251, loss: 1.176545\n",
      "time: 26724s (wall 18208s)\n",
      "\n",
      "\n",
      "step 46200 / 269850 (epoch 51.36 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.332585\n",
      "Training   accuracy: 89.453125 (916 / 1024), f1 (weighted): 89.418741, loss: 0.307944\n",
      "validation accuracy: 64.696099 (148977 / 230272), f1 (weighted): 64.706848, loss: 1.117635\n",
      "time: 26782s (wall 18247s)\n",
      "\n",
      "\n",
      "step 46300 / 269850 (epoch 51.47 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.333552\n",
      "Training   accuracy: 90.234375 (924 / 1024), f1 (weighted): 90.218060, loss: 0.295702\n",
      "validation accuracy: 63.941339 (147239 / 230272), f1 (weighted): 63.576191, loss: 1.172318\n",
      "time: 26839s (wall 18286s)\n",
      "\n",
      "\n",
      "step 46400 / 269850 (epoch 51.58 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.346330\n",
      "Training   accuracy: 87.890625 (900 / 1024), f1 (weighted): 87.845644, loss: 0.328003\n",
      "validation accuracy: 64.158039 (147738 / 230272), f1 (weighted): 64.088721, loss: 1.155292\n",
      "time: 26896s (wall 18325s)\n",
      "\n",
      "\n",
      "step 46500 / 269850 (epoch 51.70 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.359898\n",
      "Training   accuracy: 90.234375 (924 / 1024), f1 (weighted): 90.222658, loss: 0.300656\n",
      "validation accuracy: 63.625191 (146511 / 230272), f1 (weighted): 63.460998, loss: 1.188971\n",
      "time: 26953s (wall 18364s)\n",
      "\n",
      "\n",
      "step 46600 / 269850 (epoch 51.81 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.364958\n",
      "Training   accuracy: 87.597656 (897 / 1024), f1 (weighted): 87.559270, loss: 0.344528\n",
      "validation accuracy: 64.079002 (147556 / 230272), f1 (weighted): 63.821100, loss: 1.164121\n",
      "time: 27010s (wall 18402s)\n",
      "\n",
      "\n",
      "step 46700 / 269850 (epoch 51.92 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.361286\n",
      "Training   accuracy: 89.160156 (913 / 1024), f1 (weighted): 89.122970, loss: 0.335870\n",
      "validation accuracy: 63.754169 (146808 / 230272), f1 (weighted): 63.463963, loss: 1.174730\n",
      "time: 27067s (wall 18441s)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 46800 / 269850 (epoch 52.03 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.339227\n",
      "Training   accuracy: 89.355469 (915 / 1024), f1 (weighted): 89.353673, loss: 0.307304\n",
      "validation accuracy: 63.853182 (147036 / 230272), f1 (weighted): 63.680713, loss: 1.156986\n",
      "time: 27125s (wall 18480s)\n",
      "\n",
      "\n",
      "step 46900 / 269850 (epoch 52.14 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.344267\n",
      "Training   accuracy: 87.207031 (893 / 1024), f1 (weighted): 87.208662, loss: 0.354252\n",
      "validation accuracy: 63.032414 (145146 / 230272), f1 (weighted): 62.973953, loss: 1.210608\n",
      "time: 27182s (wall 18519s)\n",
      "\n",
      "\n",
      "step 47000 / 269850 (epoch 52.25 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.358821\n",
      "Training   accuracy: 88.769531 (909 / 1024), f1 (weighted): 88.780743, loss: 0.321437\n",
      "validation accuracy: 63.904426 (147154 / 230272), f1 (weighted): 63.846091, loss: 1.154847\n",
      "time: 27239s (wall 18558s)\n",
      "\n",
      "\n",
      "step 47100 / 269850 (epoch 52.36 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.356867\n",
      "Training   accuracy: 87.890625 (900 / 1024), f1 (weighted): 87.868076, loss: 0.332458\n",
      "validation accuracy: 64.319587 (148110 / 230272), f1 (weighted): 64.097966, loss: 1.132864\n",
      "time: 27296s (wall 18597s)\n",
      "\n",
      "\n",
      "step 47200 / 269850 (epoch 52.47 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.347077\n",
      "Training   accuracy: 88.085938 (902 / 1024), f1 (weighted): 88.101396, loss: 0.331041\n",
      "validation accuracy: 64.067277 (147529 / 230272), f1 (weighted): 63.857911, loss: 1.161122\n",
      "time: 27354s (wall 18636s)\n",
      "\n",
      "\n",
      "step 47300 / 269850 (epoch 52.58 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.369569\n",
      "Training   accuracy: 88.574219 (907 / 1024), f1 (weighted): 88.661836, loss: 0.328547\n",
      "validation accuracy: 63.479711 (146176 / 230272), f1 (weighted): 63.813179, loss: 1.167461\n",
      "time: 27411s (wall 18675s)\n",
      "\n",
      "\n",
      "step 47400 / 269850 (epoch 52.70 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.363006\n",
      "Training   accuracy: 86.816406 (889 / 1024), f1 (weighted): 86.728759, loss: 0.348777\n",
      "validation accuracy: 63.588712 (146427 / 230272), f1 (weighted): 63.482654, loss: 1.172976\n",
      "time: 27468s (wall 18714s)\n",
      "\n",
      "\n",
      "step 47500 / 269850 (epoch 52.81 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.350184\n",
      "Training   accuracy: 88.671875 (908 / 1024), f1 (weighted): 88.672887, loss: 0.319663\n",
      "validation accuracy: 64.655712 (148884 / 230272), f1 (weighted): 64.600417, loss: 1.140303\n",
      "time: 27526s (wall 18752s)\n",
      "\n",
      "\n",
      "step 47600 / 269850 (epoch 52.92 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.343439\n",
      "Training   accuracy: 88.769531 (909 / 1024), f1 (weighted): 88.750089, loss: 0.318758\n",
      "validation accuracy: 64.469844 (148456 / 230272), f1 (weighted): 64.403473, loss: 1.128416\n",
      "time: 27583s (wall 18791s)\n",
      "\n",
      "\n",
      "step 47700 / 269850 (epoch 53.03 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.334010\n",
      "Training   accuracy: 90.136719 (923 / 1024), f1 (weighted): 90.171390, loss: 0.290551\n",
      "validation accuracy: 64.085516 (147571 / 230272), f1 (weighted): 64.057961, loss: 1.153803\n",
      "time: 27640s (wall 18830s)\n",
      "\n",
      "\n",
      "step 47800 / 269850 (epoch 53.14 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.329471\n",
      "Training   accuracy: 89.355469 (915 / 1024), f1 (weighted): 89.380414, loss: 0.321560\n",
      "validation accuracy: 64.757330 (149118 / 230272), f1 (weighted): 64.575943, loss: 1.144260\n",
      "time: 27697s (wall 18869s)\n",
      "\n",
      "\n",
      "step 47900 / 269850 (epoch 53.25 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.332508\n",
      "Training   accuracy: 88.281250 (904 / 1024), f1 (weighted): 88.307098, loss: 0.314038\n",
      "validation accuracy: 64.487649 (148497 / 230272), f1 (weighted): 64.654839, loss: 1.131600\n",
      "time: 27755s (wall 18908s)\n",
      "\n",
      "\n",
      "step 48000 / 269850 (epoch 53.36 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.336984\n",
      "Training   accuracy: 87.597656 (897 / 1024), f1 (weighted): 87.589482, loss: 0.344329\n",
      "validation accuracy: 64.291794 (148046 / 230272), f1 (weighted): 64.112291, loss: 1.146389\n",
      "time: 27812s (wall 18947s)\n",
      "\n",
      "\n",
      "step 48100 / 269850 (epoch 53.47 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.349388\n",
      "Training   accuracy: 89.160156 (913 / 1024), f1 (weighted): 89.144424, loss: 0.300543\n",
      "validation accuracy: 64.357803 (148198 / 230272), f1 (weighted): 64.273331, loss: 1.141288\n",
      "time: 27869s (wall 18986s)\n",
      "\n",
      "\n",
      "step 48200 / 269850 (epoch 53.59 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.348540\n",
      "Training   accuracy: 88.085938 (902 / 1024), f1 (weighted): 88.146679, loss: 0.316194\n",
      "validation accuracy: 63.726376 (146744 / 230272), f1 (weighted): 63.607384, loss: 1.165915\n",
      "time: 27926s (wall 19025s)\n",
      "\n",
      "\n",
      "step 48300 / 269850 (epoch 53.70 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.343552\n",
      "Training   accuracy: 89.062500 (912 / 1024), f1 (weighted): 89.028688, loss: 0.322382\n",
      "validation accuracy: 64.686545 (148955 / 230272), f1 (weighted): 64.536564, loss: 1.135083\n",
      "time: 27983s (wall 19063s)\n",
      "\n",
      "\n",
      "step 48400 / 269850 (epoch 53.81 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.346435\n",
      "Training   accuracy: 88.378906 (905 / 1024), f1 (weighted): 88.329664, loss: 0.325690\n",
      "validation accuracy: 64.379516 (148248 / 230272), f1 (weighted): 64.073136, loss: 1.135785\n",
      "time: 28040s (wall 19102s)\n",
      "\n",
      "\n",
      "step 48500 / 269850 (epoch 53.92 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.367533\n",
      "Training   accuracy: 87.597656 (897 / 1024), f1 (weighted): 87.588693, loss: 0.333032\n",
      "validation accuracy: 64.260961 (147975 / 230272), f1 (weighted): 63.945404, loss: 1.151298\n",
      "time: 28098s (wall 19141s)\n",
      "\n",
      "\n",
      "step 48600 / 269850 (epoch 54.03 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.327075\n",
      "Training   accuracy: 89.648438 (918 / 1024), f1 (weighted): 89.635545, loss: 0.307569\n",
      "validation accuracy: 64.453342 (148418 / 230272), f1 (weighted): 64.250980, loss: 1.151461\n",
      "time: 28155s (wall 19180s)\n",
      "\n",
      "\n",
      "step 48700 / 269850 (epoch 54.14 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.354101\n",
      "Training   accuracy: 89.062500 (912 / 1024), f1 (weighted): 89.049421, loss: 0.330887\n",
      "validation accuracy: 63.754169 (146808 / 230272), f1 (weighted): 63.946745, loss: 1.162025\n",
      "time: 28212s (wall 19219s)\n",
      "\n",
      "\n",
      "step 48800 / 269850 (epoch 54.25 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.344767\n",
      "Training   accuracy: 88.281250 (904 / 1024), f1 (weighted): 88.270178, loss: 0.337615\n",
      "validation accuracy: 64.001268 (147377 / 230272), f1 (weighted): 64.150711, loss: 1.166211\n",
      "time: 28269s (wall 19258s)\n",
      "\n",
      "\n",
      "step 48900 / 269850 (epoch 54.36 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.333328\n",
      "Training   accuracy: 88.378906 (905 / 1024), f1 (weighted): 88.332809, loss: 0.321913\n",
      "validation accuracy: 64.141537 (147700 / 230272), f1 (weighted): 63.936199, loss: 1.142111\n",
      "time: 28327s (wall 19297s)\n",
      "\n",
      "\n",
      "step 49000 / 269850 (epoch 54.47 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.332119\n",
      "Training   accuracy: 89.746094 (919 / 1024), f1 (weighted): 89.756117, loss: 0.301372\n",
      "validation accuracy: 64.648763 (148868 / 230272), f1 (weighted): 64.694448, loss: 1.117625\n",
      "time: 28384s (wall 19335s)\n",
      "\n",
      "\n",
      "step 49100 / 269850 (epoch 54.59 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.332015\n",
      "Training   accuracy: 88.085938 (902 / 1024), f1 (weighted): 88.066709, loss: 0.321633\n",
      "validation accuracy: 64.639644 (148847 / 230272), f1 (weighted): 64.408491, loss: 1.139103\n",
      "time: 28441s (wall 19374s)\n",
      "\n",
      "\n",
      "step 49200 / 269850 (epoch 54.70 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.338688\n",
      "Training   accuracy: 90.917969 (931 / 1024), f1 (weighted): 90.888398, loss: 0.279662\n",
      "validation accuracy: 64.622273 (148807 / 230272), f1 (weighted): 64.521306, loss: 1.124079\n",
      "time: 28498s (wall 19413s)\n",
      "\n",
      "\n",
      "step 49300 / 269850 (epoch 54.81 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.333960\n",
      "Training   accuracy: 88.281250 (904 / 1024), f1 (weighted): 88.233361, loss: 0.312524\n",
      "validation accuracy: 64.673951 (148926 / 230272), f1 (weighted): 64.474265, loss: 1.129315\n",
      "time: 28555s (wall 19452s)\n",
      "\n",
      "\n",
      "step 49400 / 269850 (epoch 54.92 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.327199\n",
      "Training   accuracy: 89.941406 (921 / 1024), f1 (weighted): 89.956315, loss: 0.292644\n",
      "validation accuracy: 64.595782 (148746 / 230272), f1 (weighted): 64.675650, loss: 1.149660\n",
      "time: 28613s (wall 19491s)\n",
      "\n",
      "\n",
      "step 49500 / 269850 (epoch 55.03 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.330434\n",
      "Training   accuracy: 90.039062 (922 / 1024), f1 (weighted): 90.044021, loss: 0.302002\n",
      "validation accuracy: 64.223614 (147889 / 230272), f1 (weighted): 64.120556, loss: 1.154379\n",
      "time: 28670s (wall 19530s)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 49600 / 269850 (epoch 55.14 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.329219\n",
      "Training   accuracy: 89.941406 (921 / 1024), f1 (weighted): 89.911308, loss: 0.301984\n",
      "validation accuracy: 64.528036 (148590 / 230272), f1 (weighted): 64.344944, loss: 1.140713\n",
      "time: 28727s (wall 19569s)\n",
      "\n",
      "\n",
      "step 49700 / 269850 (epoch 55.25 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.346358\n",
      "Training   accuracy: 88.378906 (905 / 1024), f1 (weighted): 88.376964, loss: 0.333028\n",
      "validation accuracy: 64.223614 (147889 / 230272), f1 (weighted): 64.034562, loss: 1.145063\n",
      "time: 28784s (wall 19608s)\n",
      "\n",
      "\n",
      "step 49800 / 269850 (epoch 55.36 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.332478\n",
      "Training   accuracy: 89.550781 (917 / 1024), f1 (weighted): 89.536326, loss: 0.295192\n",
      "validation accuracy: 64.640946 (148850 / 230272), f1 (weighted): 64.622869, loss: 1.145955\n",
      "time: 28841s (wall 19647s)\n",
      "\n",
      "\n",
      "step 49900 / 269850 (epoch 55.48 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.331268\n",
      "Training   accuracy: 88.183594 (903 / 1024), f1 (weighted): 88.136286, loss: 0.325937\n",
      "validation accuracy: 64.253578 (147958 / 230272), f1 (weighted): 63.838461, loss: 1.168473\n",
      "time: 28898s (wall 19686s)\n",
      "\n",
      "\n",
      "step 50000 / 269850 (epoch 55.59 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.323101\n",
      "Training   accuracy: 89.453125 (916 / 1024), f1 (weighted): 89.444381, loss: 0.295851\n",
      "validation accuracy: 64.361711 (148207 / 230272), f1 (weighted): 64.006943, loss: 1.178336\n",
      "time: 28955s (wall 19725s)\n",
      "\n",
      "\n",
      "step 50100 / 269850 (epoch 55.70 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.349999\n",
      "Training   accuracy: 88.476562 (906 / 1024), f1 (weighted): 88.448203, loss: 0.331760\n",
      "validation accuracy: 63.870987 (147077 / 230272), f1 (weighted): 63.540354, loss: 1.154021\n",
      "time: 29012s (wall 19763s)\n",
      "\n",
      "\n",
      "step 50200 / 269850 (epoch 55.81 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.333688\n",
      "Training   accuracy: 90.136719 (923 / 1024), f1 (weighted): 90.105682, loss: 0.306886\n",
      "validation accuracy: 64.796415 (149208 / 230272), f1 (weighted): 64.563717, loss: 1.165897\n",
      "time: 29070s (wall 19802s)\n",
      "\n",
      "\n",
      "step 50300 / 269850 (epoch 55.92 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.343121\n",
      "Training   accuracy: 88.671875 (908 / 1024), f1 (weighted): 88.695860, loss: 0.315664\n",
      "validation accuracy: 64.321759 (148115 / 230272), f1 (weighted): 64.533512, loss: 1.132651\n",
      "time: 29127s (wall 19841s)\n",
      "\n",
      "\n",
      "step 50400 / 269850 (epoch 56.03 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.334451\n",
      "Training   accuracy: 88.867188 (910 / 1024), f1 (weighted): 88.842959, loss: 0.308152\n",
      "validation accuracy: 64.666568 (148909 / 230272), f1 (weighted): 64.696799, loss: 1.152641\n",
      "time: 29184s (wall 19880s)\n",
      "\n",
      "\n",
      "step 50500 / 269850 (epoch 56.14 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.341202\n",
      "Training   accuracy: 89.355469 (915 / 1024), f1 (weighted): 89.390816, loss: 0.319144\n",
      "validation accuracy: 63.195699 (145522 / 230272), f1 (weighted): 63.282563, loss: 1.203926\n",
      "time: 29242s (wall 19919s)\n",
      "\n",
      "\n",
      "step 50600 / 269850 (epoch 56.25 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.340524\n",
      "Training   accuracy: 91.210938 (934 / 1024), f1 (weighted): 91.171338, loss: 0.295740\n",
      "validation accuracy: 63.809755 (146936 / 230272), f1 (weighted): 63.355281, loss: 1.183179\n",
      "time: 29299s (wall 19958s)\n",
      "\n",
      "\n",
      "step 50700 / 269850 (epoch 56.36 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.360418\n",
      "Training   accuracy: 88.378906 (905 / 1024), f1 (weighted): 88.375743, loss: 0.343597\n",
      "validation accuracy: 61.855545 (142436 / 230272), f1 (weighted): 61.253327, loss: 1.283457\n",
      "time: 29356s (wall 19997s)\n",
      "\n",
      "\n",
      "step 50800 / 269850 (epoch 56.48 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.342674\n",
      "Training   accuracy: 88.964844 (911 / 1024), f1 (weighted): 88.978235, loss: 0.309133\n",
      "validation accuracy: 63.801504 (146917 / 230272), f1 (weighted): 63.878609, loss: 1.172693\n",
      "time: 29414s (wall 20036s)\n",
      "\n",
      "\n",
      "step 50900 / 269850 (epoch 56.59 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.344510\n",
      "Training   accuracy: 87.304688 (894 / 1024), f1 (weighted): 87.266857, loss: 0.347245\n",
      "validation accuracy: 64.180621 (147790 / 230272), f1 (weighted): 63.964828, loss: 1.177749\n",
      "time: 29471s (wall 20075s)\n",
      "\n",
      "\n",
      "step 51000 / 269850 (epoch 56.70 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.341936\n",
      "Training   accuracy: 89.160156 (913 / 1024), f1 (weighted): 89.170401, loss: 0.301309\n",
      "validation accuracy: 64.637472 (148842 / 230272), f1 (weighted): 64.448760, loss: 1.144907\n",
      "time: 29528s (wall 20114s)\n",
      "\n",
      "\n",
      "step 51100 / 269850 (epoch 56.81 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.342707\n",
      "Training   accuracy: 89.257812 (914 / 1024), f1 (weighted): 89.258097, loss: 0.313826\n",
      "validation accuracy: 64.683070 (148947 / 230272), f1 (weighted): 64.465933, loss: 1.138654\n",
      "time: 29586s (wall 20153s)\n",
      "\n",
      "\n",
      "step 51200 / 269850 (epoch 56.92 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.338577\n",
      "Training   accuracy: 89.648438 (918 / 1024), f1 (weighted): 89.654288, loss: 0.297002\n",
      "validation accuracy: 64.118521 (147647 / 230272), f1 (weighted): 64.015562, loss: 1.173081\n",
      "time: 29643s (wall 20192s)\n",
      "\n",
      "\n",
      "step 51300 / 269850 (epoch 57.03 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.335625\n",
      "Training   accuracy: 88.769531 (909 / 1024), f1 (weighted): 88.809277, loss: 0.308183\n",
      "validation accuracy: 63.883581 (147106 / 230272), f1 (weighted): 63.685545, loss: 1.200097\n",
      "time: 29700s (wall 20230s)\n",
      "\n",
      "\n",
      "step 51400 / 269850 (epoch 57.14 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.330089\n",
      "Training   accuracy: 90.722656 (929 / 1024), f1 (weighted): 90.714607, loss: 0.286525\n",
      "validation accuracy: 64.529339 (148593 / 230272), f1 (weighted): 64.249142, loss: 1.174370\n",
      "time: 29757s (wall 20269s)\n",
      "\n",
      "\n",
      "step 51500 / 269850 (epoch 57.25 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.349136\n",
      "Training   accuracy: 88.476562 (906 / 1024), f1 (weighted): 88.520263, loss: 0.321714\n",
      "validation accuracy: 63.880976 (147100 / 230272), f1 (weighted): 63.754777, loss: 1.210612\n",
      "time: 29815s (wall 20308s)\n",
      "\n",
      "\n",
      "step 51600 / 269850 (epoch 57.37 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.340195\n",
      "Training   accuracy: 88.574219 (907 / 1024), f1 (weighted): 88.614786, loss: 0.324956\n",
      "validation accuracy: 64.600559 (148757 / 230272), f1 (weighted): 64.448357, loss: 1.142571\n",
      "time: 29872s (wall 20347s)\n",
      "\n",
      "\n",
      "step 51700 / 269850 (epoch 57.48 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.323852\n",
      "Training   accuracy: 89.746094 (919 / 1024), f1 (weighted): 89.723408, loss: 0.292401\n",
      "validation accuracy: 64.245762 (147940 / 230272), f1 (weighted): 63.878601, loss: 1.182035\n",
      "time: 29929s (wall 20386s)\n",
      "\n",
      "\n",
      "step 51800 / 269850 (epoch 57.59 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.339817\n",
      "Training   accuracy: 88.964844 (911 / 1024), f1 (weighted): 88.941930, loss: 0.321478\n",
      "validation accuracy: 64.299177 (148063 / 230272), f1 (weighted): 64.037472, loss: 1.160161\n",
      "time: 29986s (wall 20425s)\n",
      "\n",
      "\n",
      "step 51900 / 269850 (epoch 57.70 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.323805\n",
      "Training   accuracy: 89.941406 (921 / 1024), f1 (weighted): 89.925122, loss: 0.302153\n",
      "validation accuracy: 64.334787 (148145 / 230272), f1 (weighted): 64.477283, loss: 1.160001\n",
      "time: 30044s (wall 20464s)\n",
      "\n",
      "\n",
      "step 52000 / 269850 (epoch 57.81 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.330229\n",
      "Training   accuracy: 88.671875 (908 / 1024), f1 (weighted): 88.652482, loss: 0.326269\n",
      "validation accuracy: 64.781650 (149174 / 230272), f1 (weighted): 64.549144, loss: 1.148602\n",
      "time: 30101s (wall 20503s)\n",
      "\n",
      "\n",
      "step 52100 / 269850 (epoch 57.92 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.338005\n",
      "Training   accuracy: 89.550781 (917 / 1024), f1 (weighted): 89.522799, loss: 0.305469\n",
      "validation accuracy: 64.412087 (148323 / 230272), f1 (weighted): 64.345439, loss: 1.152269\n",
      "time: 30158s (wall 20542s)\n",
      "\n",
      "\n",
      "step 52200 / 269850 (epoch 58.03 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.318508\n",
      "Training   accuracy: 89.453125 (916 / 1024), f1 (weighted): 89.440258, loss: 0.289197\n",
      "validation accuracy: 64.527168 (148588 / 230272), f1 (weighted): 64.246737, loss: 1.183817\n",
      "time: 30215s (wall 20581s)\n",
      "\n",
      "\n",
      "step 52300 / 269850 (epoch 58.14 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.316710\n",
      "Training   accuracy: 90.136719 (923 / 1024), f1 (weighted): 90.135851, loss: 0.289198\n",
      "validation accuracy: 64.608810 (148776 / 230272), f1 (weighted): 64.398853, loss: 1.161343\n",
      "time: 30273s (wall 20620s)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 52400 / 269850 (epoch 58.25 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.325280\n",
      "Training   accuracy: 89.453125 (916 / 1024), f1 (weighted): 89.409236, loss: 0.308169\n",
      "validation accuracy: 64.295702 (148055 / 230272), f1 (weighted): 64.021715, loss: 1.196014\n",
      "time: 30330s (wall 20659s)\n",
      "\n",
      "\n",
      "step 52500 / 269850 (epoch 58.37 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.320387\n",
      "Training   accuracy: 91.113281 (933 / 1024), f1 (weighted): 91.130331, loss: 0.296541\n",
      "validation accuracy: 64.555395 (148653 / 230272), f1 (weighted): 64.335060, loss: 1.178797\n",
      "time: 30387s (wall 20697s)\n",
      "\n",
      "\n",
      "step 52600 / 269850 (epoch 58.48 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.330365\n",
      "Training   accuracy: 89.257812 (914 / 1024), f1 (weighted): 89.230359, loss: 0.300133\n",
      "validation accuracy: 64.165422 (147755 / 230272), f1 (weighted): 63.872931, loss: 1.184735\n",
      "time: 30444s (wall 20736s)\n",
      "\n",
      "\n",
      "step 52700 / 269850 (epoch 58.59 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.409680\n",
      "Training   accuracy: 87.695312 (898 / 1024), f1 (weighted): 87.732583, loss: 0.383390\n",
      "validation accuracy: 62.831782 (144684 / 230272), f1 (weighted): 62.903350, loss: 1.164218\n",
      "time: 30502s (wall 20775s)\n",
      "\n",
      "\n",
      "step 52800 / 269850 (epoch 58.70 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.334469\n",
      "Training   accuracy: 89.746094 (919 / 1024), f1 (weighted): 89.657738, loss: 0.298710\n",
      "validation accuracy: 64.180187 (147789 / 230272), f1 (weighted): 63.762978, loss: 1.177301\n",
      "time: 30559s (wall 20814s)\n",
      "\n",
      "\n",
      "step 52900 / 269850 (epoch 58.81 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.347709\n",
      "Training   accuracy: 87.988281 (901 / 1024), f1 (weighted): 87.955531, loss: 0.325115\n",
      "validation accuracy: 64.078568 (147555 / 230272), f1 (weighted): 63.653020, loss: 1.164296\n",
      "time: 30616s (wall 20853s)\n",
      "\n",
      "\n",
      "step 53000 / 269850 (epoch 58.92 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.332469\n",
      "Training   accuracy: 89.843750 (920 / 1024), f1 (weighted): 89.810439, loss: 0.300135\n",
      "validation accuracy: 64.556698 (148656 / 230272), f1 (weighted): 64.580079, loss: 1.146374\n",
      "time: 30673s (wall 20892s)\n",
      "\n",
      "\n",
      "step 53100 / 269850 (epoch 59.03 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.326204\n",
      "Training   accuracy: 89.550781 (917 / 1024), f1 (weighted): 89.551601, loss: 0.306400\n",
      "validation accuracy: 64.063369 (147520 / 230272), f1 (weighted): 64.251900, loss: 1.176839\n",
      "time: 30731s (wall 20930s)\n",
      "\n",
      "\n",
      "step 53200 / 269850 (epoch 59.14 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.334085\n",
      "Training   accuracy: 89.550781 (917 / 1024), f1 (weighted): 89.496978, loss: 0.314266\n",
      "validation accuracy: 64.370397 (148227 / 230272), f1 (weighted): 63.741225, loss: 1.196079\n",
      "time: 30788s (wall 20969s)\n",
      "\n",
      "\n",
      "step 53300 / 269850 (epoch 59.26 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.328446\n",
      "Training   accuracy: 91.308594 (935 / 1024), f1 (weighted): 91.255438, loss: 0.286796\n",
      "validation accuracy: 64.653540 (148879 / 230272), f1 (weighted): 64.274068, loss: 1.189013\n",
      "time: 30845s (wall 21008s)\n",
      "\n",
      "\n",
      "step 53400 / 269850 (epoch 59.37 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.330746\n",
      "Training   accuracy: 92.187500 (944 / 1024), f1 (weighted): 92.190811, loss: 0.290269\n",
      "validation accuracy: 64.257921 (147968 / 230272), f1 (weighted): 64.234604, loss: 1.175426\n",
      "time: 30902s (wall 21047s)\n",
      "\n",
      "\n",
      "step 53500 / 269850 (epoch 59.48 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.362180\n",
      "Training   accuracy: 87.402344 (895 / 1024), f1 (weighted): 87.402632, loss: 0.368959\n",
      "validation accuracy: 64.584491 (148720 / 230272), f1 (weighted): 64.635340, loss: 1.157670\n",
      "time: 30960s (wall 21086s)\n",
      "\n",
      "\n",
      "step 53600 / 269850 (epoch 59.59 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.328139\n",
      "Training   accuracy: 89.941406 (921 / 1024), f1 (weighted): 89.943784, loss: 0.299403\n",
      "validation accuracy: 64.659186 (148892 / 230272), f1 (weighted): 64.668467, loss: 1.136373\n",
      "time: 31017s (wall 21125s)\n",
      "\n",
      "\n",
      "step 53700 / 269850 (epoch 59.70 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.321372\n",
      "Training   accuracy: 91.308594 (935 / 1024), f1 (weighted): 91.274017, loss: 0.283400\n",
      "validation accuracy: 64.562344 (148669 / 230272), f1 (weighted): 64.445075, loss: 1.140827\n",
      "time: 31074s (wall 21164s)\n",
      "\n",
      "\n",
      "step 53800 / 269850 (epoch 59.81 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.332150\n",
      "Training   accuracy: 88.769531 (909 / 1024), f1 (weighted): 88.740862, loss: 0.327992\n",
      "validation accuracy: 64.886743 (149416 / 230272), f1 (weighted): 64.589379, loss: 1.137831\n",
      "time: 31131s (wall 21203s)\n",
      "\n",
      "\n",
      "step 53900 / 269850 (epoch 59.92 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.331586\n",
      "Training   accuracy: 87.988281 (901 / 1024), f1 (weighted): 88.009377, loss: 0.340772\n",
      "validation accuracy: 64.501546 (148529 / 230272), f1 (weighted): 64.532197, loss: 1.138155\n",
      "time: 31188s (wall 21242s)\n",
      "\n",
      "\n",
      "step 54000 / 269850 (epoch 60.03 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.311011\n",
      "Training   accuracy: 89.062500 (912 / 1024), f1 (weighted): 89.121265, loss: 0.305642\n",
      "validation accuracy: 64.832459 (149291 / 230272), f1 (weighted): 64.585238, loss: 1.158638\n",
      "time: 31246s (wall 21281s)\n",
      "\n",
      "\n",
      "step 54100 / 269850 (epoch 60.14 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.318258\n",
      "Training   accuracy: 88.964844 (911 / 1024), f1 (weighted): 88.920525, loss: 0.306353\n",
      "validation accuracy: 64.591874 (148737 / 230272), f1 (weighted): 64.287668, loss: 1.182109\n",
      "time: 31303s (wall 21319s)\n",
      "\n",
      "\n",
      "step 54200 / 269850 (epoch 60.26 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.326567\n",
      "Training   accuracy: 89.355469 (915 / 1024), f1 (weighted): 89.417928, loss: 0.296297\n",
      "validation accuracy: 64.117652 (147645 / 230272), f1 (weighted): 63.854244, loss: 1.173362\n",
      "time: 31361s (wall 21358s)\n",
      "\n",
      "\n",
      "step 54300 / 269850 (epoch 60.37 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.310887\n",
      "Training   accuracy: 90.820312 (930 / 1024), f1 (weighted): 90.792997, loss: 0.263814\n",
      "validation accuracy: 64.713469 (149017 / 230272), f1 (weighted): 64.463313, loss: 1.170268\n",
      "time: 31418s (wall 21397s)\n",
      "\n",
      "\n",
      "step 54400 / 269850 (epoch 60.48 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.321987\n",
      "Training   accuracy: 89.648438 (918 / 1024), f1 (weighted): 89.613414, loss: 0.283430\n",
      "validation accuracy: 64.790769 (149195 / 230272), f1 (weighted): 64.718495, loss: 1.169280\n",
      "time: 31475s (wall 21436s)\n",
      "\n",
      "\n",
      "step 54500 / 269850 (epoch 60.59 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.321826\n",
      "Training   accuracy: 90.234375 (924 / 1024), f1 (weighted): 90.216417, loss: 0.284430\n",
      "validation accuracy: 64.634432 (148835 / 230272), f1 (weighted): 64.556663, loss: 1.157424\n",
      "time: 31532s (wall 21475s)\n",
      "\n",
      "\n",
      "step 54600 / 269850 (epoch 60.70 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.316867\n",
      "Training   accuracy: 90.234375 (924 / 1024), f1 (weighted): 90.265602, loss: 0.279852\n",
      "validation accuracy: 64.548013 (148636 / 230272), f1 (weighted): 64.490864, loss: 1.165985\n",
      "time: 31589s (wall 21514s)\n",
      "\n",
      "\n",
      "step 54700 / 269850 (epoch 60.81 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.323839\n",
      "Training   accuracy: 88.964844 (911 / 1024), f1 (weighted): 88.970412, loss: 0.308772\n",
      "validation accuracy: 64.548881 (148638 / 230272), f1 (weighted): 64.636048, loss: 1.124561\n",
      "time: 31646s (wall 21553s)\n",
      "\n",
      "\n",
      "step 54800 / 269850 (epoch 60.92 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.331623\n",
      "Training   accuracy: 89.160156 (913 / 1024), f1 (weighted): 89.153766, loss: 0.306539\n",
      "validation accuracy: 64.339129 (148155 / 230272), f1 (weighted): 64.368132, loss: 1.169626\n",
      "time: 31704s (wall 21592s)\n",
      "\n",
      "\n",
      "step 54900 / 269850 (epoch 61.03 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.309327\n",
      "Training   accuracy: 89.550781 (917 / 1024), f1 (weighted): 89.488625, loss: 0.288792\n",
      "validation accuracy: 64.505889 (148539 / 230272), f1 (weighted): 63.819053, loss: 1.218508\n",
      "time: 31761s (wall 21631s)\n",
      "\n",
      "\n",
      "step 55000 / 269850 (epoch 61.15 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.310568\n",
      "Training   accuracy: 90.039062 (922 / 1024), f1 (weighted): 90.048000, loss: 0.286243\n",
      "validation accuracy: 64.364751 (148214 / 230272), f1 (weighted): 64.552819, loss: 1.181146\n",
      "time: 31818s (wall 21670s)\n",
      "\n",
      "\n",
      "step 55100 / 269850 (epoch 61.26 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.319894\n",
      "Training   accuracy: 90.039062 (922 / 1024), f1 (weighted): 90.075323, loss: 0.295521\n",
      "validation accuracy: 64.648763 (148868 / 230272), f1 (weighted): 64.618480, loss: 1.157663\n",
      "time: 31875s (wall 21708s)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 55200 / 269850 (epoch 61.37 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.312096\n",
      "Training   accuracy: 89.843750 (920 / 1024), f1 (weighted): 89.832352, loss: 0.312720\n",
      "validation accuracy: 64.581886 (148714 / 230272), f1 (weighted): 64.412193, loss: 1.178282\n",
      "time: 31933s (wall 21747s)\n",
      "\n",
      "\n",
      "step 55300 / 269850 (epoch 61.48 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.329865\n",
      "Training   accuracy: 89.257812 (914 / 1024), f1 (weighted): 89.254259, loss: 0.296358\n",
      "validation accuracy: 64.033838 (147452 / 230272), f1 (weighted): 63.745847, loss: 1.191459\n",
      "time: 31990s (wall 21786s)\n",
      "\n",
      "\n",
      "step 55400 / 269850 (epoch 61.59 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.333957\n",
      "Training   accuracy: 89.257812 (914 / 1024), f1 (weighted): 89.260225, loss: 0.328180\n",
      "validation accuracy: 63.718993 (146727 / 230272), f1 (weighted): 63.741057, loss: 1.192084\n",
      "time: 32047s (wall 21825s)\n",
      "\n",
      "\n",
      "step 55500 / 269850 (epoch 61.70 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.336526\n",
      "Training   accuracy: 90.332031 (925 / 1024), f1 (weighted): 90.337042, loss: 0.294413\n",
      "validation accuracy: 64.640946 (148850 / 230272), f1 (weighted): 64.667477, loss: 1.142418\n",
      "time: 32104s (wall 21864s)\n",
      "\n",
      "\n",
      "step 55600 / 269850 (epoch 61.81 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.324294\n",
      "Training   accuracy: 90.625000 (928 / 1024), f1 (weighted): 90.654659, loss: 0.283191\n",
      "validation accuracy: 64.683505 (148948 / 230272), f1 (weighted): 64.684685, loss: 1.150704\n",
      "time: 32161s (wall 21903s)\n",
      "\n",
      "\n",
      "step 55700 / 269850 (epoch 61.92 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.330948\n",
      "Training   accuracy: 89.746094 (919 / 1024), f1 (weighted): 89.773094, loss: 0.310488\n",
      "validation accuracy: 64.500243 (148526 / 230272), f1 (weighted): 64.500357, loss: 1.141935\n",
      "time: 32219s (wall 21942s)\n",
      "\n",
      "\n",
      "step 55800 / 269850 (epoch 62.03 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.320572\n",
      "Training   accuracy: 90.820312 (930 / 1024), f1 (weighted): 90.796876, loss: 0.288902\n",
      "validation accuracy: 65.158161 (150041 / 230272), f1 (weighted): 64.909307, loss: 1.152068\n",
      "time: 32276s (wall 21981s)\n",
      "\n",
      "\n",
      "step 55900 / 269850 (epoch 62.15 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.332557\n",
      "Training   accuracy: 90.136719 (923 / 1024), f1 (weighted): 90.128714, loss: 0.305818\n",
      "validation accuracy: 64.504152 (148535 / 230272), f1 (weighted): 64.399055, loss: 1.149926\n",
      "time: 32333s (wall 22020s)\n",
      "\n",
      "\n",
      "step 56000 / 269850 (epoch 62.26 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.329907\n",
      "Training   accuracy: 89.941406 (921 / 1024), f1 (weighted): 89.933025, loss: 0.293813\n",
      "validation accuracy: 63.187882 (145504 / 230272), f1 (weighted): 62.775205, loss: 1.241546\n",
      "time: 32391s (wall 22059s)\n",
      "\n",
      "\n",
      "step 56100 / 269850 (epoch 62.37 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.322068\n",
      "Training   accuracy: 89.746094 (919 / 1024), f1 (weighted): 89.774549, loss: 0.300313\n",
      "validation accuracy: 63.857959 (147047 / 230272), f1 (weighted): 64.245467, loss: 1.165625\n",
      "time: 32448s (wall 22097s)\n",
      "\n",
      "\n",
      "step 56200 / 269850 (epoch 62.48 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.330482\n",
      "Training   accuracy: 90.820312 (930 / 1024), f1 (weighted): 90.774456, loss: 0.287228\n",
      "validation accuracy: 64.161079 (147745 / 230272), f1 (weighted): 63.850271, loss: 1.175454\n",
      "time: 32505s (wall 22136s)\n",
      "\n",
      "\n",
      "step 56300 / 269850 (epoch 62.59 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.337222\n",
      "Training   accuracy: 88.671875 (908 / 1024), f1 (weighted): 88.686213, loss: 0.316257\n",
      "validation accuracy: 64.672648 (148923 / 230272), f1 (weighted): 64.754694, loss: 1.129526\n",
      "time: 32562s (wall 22175s)\n",
      "\n",
      "\n",
      "step 56400 / 269850 (epoch 62.70 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.327607\n",
      "Training   accuracy: 89.941406 (921 / 1024), f1 (weighted): 89.948021, loss: 0.305799\n",
      "validation accuracy: 64.442051 (148392 / 230272), f1 (weighted): 64.069733, loss: 1.173386\n",
      "time: 32620s (wall 22214s)\n",
      "\n",
      "\n",
      "step 56500 / 269850 (epoch 62.81 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.326046\n",
      "Training   accuracy: 90.917969 (931 / 1024), f1 (weighted): 90.902751, loss: 0.284420\n",
      "validation accuracy: 64.401664 (148299 / 230272), f1 (weighted): 64.375175, loss: 1.179072\n",
      "time: 32677s (wall 22253s)\n",
      "\n",
      "\n",
      "step 56600 / 269850 (epoch 62.92 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.328604\n",
      "Training   accuracy: 88.867188 (910 / 1024), f1 (weighted): 88.848511, loss: 0.314922\n",
      "validation accuracy: 64.333484 (148142 / 230272), f1 (weighted): 64.027975, loss: 1.158033\n",
      "time: 32734s (wall 22292s)\n",
      "\n",
      "\n",
      "step 56700 / 269850 (epoch 63.04 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.315335\n",
      "Training   accuracy: 89.648438 (918 / 1024), f1 (weighted): 89.627121, loss: 0.282633\n",
      "validation accuracy: 64.610113 (148779 / 230272), f1 (weighted): 64.521161, loss: 1.198272\n",
      "time: 32792s (wall 22331s)\n",
      "\n",
      "\n",
      "step 56800 / 269850 (epoch 63.15 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.320477\n",
      "Training   accuracy: 90.136719 (923 / 1024), f1 (weighted): 90.128559, loss: 0.288828\n",
      "validation accuracy: 64.396887 (148288 / 230272), f1 (weighted): 64.064110, loss: 1.193591\n",
      "time: 32849s (wall 22370s)\n",
      "\n",
      "\n",
      "step 56900 / 269850 (epoch 63.26 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.324461\n",
      "Training   accuracy: 88.085938 (902 / 1024), f1 (weighted): 88.159565, loss: 0.325836\n",
      "validation accuracy: 64.108098 (147623 / 230272), f1 (weighted): 64.275182, loss: 1.174400\n",
      "time: 32906s (wall 22408s)\n",
      "\n",
      "\n",
      "step 57000 / 269850 (epoch 63.37 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.312397\n",
      "Training   accuracy: 91.015625 (932 / 1024), f1 (weighted): 91.028012, loss: 0.280472\n",
      "validation accuracy: 64.500243 (148526 / 230272), f1 (weighted): 64.296535, loss: 1.185003\n",
      "time: 32963s (wall 22447s)\n",
      "\n",
      "\n",
      "step 57100 / 269850 (epoch 63.48 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.321792\n",
      "Training   accuracy: 88.964844 (911 / 1024), f1 (weighted): 88.970563, loss: 0.312802\n",
      "validation accuracy: 64.386899 (148265 / 230272), f1 (weighted): 64.262653, loss: 1.182948\n",
      "time: 33020s (wall 22486s)\n",
      "\n",
      "\n",
      "step 57200 / 269850 (epoch 63.59 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.324037\n",
      "Training   accuracy: 89.355469 (915 / 1024), f1 (weighted): 89.331359, loss: 0.296622\n",
      "validation accuracy: 64.391242 (148275 / 230272), f1 (weighted): 64.203874, loss: 1.161372\n",
      "time: 33078s (wall 22525s)\n",
      "\n",
      "\n",
      "step 57300 / 269850 (epoch 63.70 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.313519\n",
      "Training   accuracy: 91.113281 (933 / 1024), f1 (weighted): 91.094505, loss: 0.268769\n",
      "validation accuracy: 64.952317 (149567 / 230272), f1 (weighted): 64.564820, loss: 1.144548\n",
      "time: 33135s (wall 22564s)\n",
      "\n",
      "\n",
      "step 57400 / 269850 (epoch 63.81 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.333259\n",
      "Training   accuracy: 91.308594 (935 / 1024), f1 (weighted): 91.318216, loss: 0.286077\n",
      "validation accuracy: 63.785002 (146879 / 230272), f1 (weighted): 63.670137, loss: 1.173866\n",
      "time: 33192s (wall 22603s)\n",
      "\n",
      "\n",
      "step 57500 / 269850 (epoch 63.92 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.336875\n",
      "Training   accuracy: 90.527344 (927 / 1024), f1 (weighted): 90.530297, loss: 0.288593\n",
      "validation accuracy: 64.181490 (147792 / 230272), f1 (weighted): 64.176868, loss: 1.159662\n",
      "time: 33249s (wall 22642s)\n",
      "\n",
      "\n",
      "step 57600 / 269850 (epoch 64.04 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.305029\n",
      "Training   accuracy: 91.015625 (932 / 1024), f1 (weighted): 91.044304, loss: 0.266017\n",
      "validation accuracy: 63.975212 (147317 / 230272), f1 (weighted): 63.731924, loss: 1.217712\n",
      "time: 33306s (wall 22681s)\n",
      "\n",
      "\n",
      "step 57700 / 269850 (epoch 64.15 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.327163\n",
      "Training   accuracy: 91.113281 (933 / 1024), f1 (weighted): 91.099410, loss: 0.292480\n",
      "validation accuracy: 63.858394 (147048 / 230272), f1 (weighted): 63.723722, loss: 1.183178\n",
      "time: 33364s (wall 22719s)\n",
      "\n",
      "\n",
      "step 57800 / 269850 (epoch 64.26 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.317702\n",
      "Training   accuracy: 91.601562 (938 / 1024), f1 (weighted): 91.569655, loss: 0.275826\n",
      "validation accuracy: 64.164987 (147754 / 230272), f1 (weighted): 64.012387, loss: 1.186384\n",
      "time: 33421s (wall 22758s)\n",
      "\n",
      "\n",
      "step 57900 / 269850 (epoch 64.37 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.321454\n",
      "Training   accuracy: 90.625000 (928 / 1024), f1 (weighted): 90.608646, loss: 0.281590\n",
      "validation accuracy: 64.592742 (148739 / 230272), f1 (weighted): 64.526982, loss: 1.182122\n",
      "time: 33478s (wall 22797s)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 58000 / 269850 (epoch 64.48 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.328198\n",
      "Training   accuracy: 90.917969 (931 / 1024), f1 (weighted): 90.938019, loss: 0.282202\n",
      "validation accuracy: 64.383859 (148258 / 230272), f1 (weighted): 64.051978, loss: 1.179108\n",
      "time: 33535s (wall 22836s)\n",
      "\n",
      "\n",
      "step 58100 / 269850 (epoch 64.59 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.332477\n",
      "Training   accuracy: 88.574219 (907 / 1024), f1 (weighted): 88.595609, loss: 0.314498\n",
      "validation accuracy: 64.201466 (147838 / 230272), f1 (weighted): 64.201632, loss: 1.170734\n",
      "time: 33593s (wall 22875s)\n",
      "\n",
      "\n",
      "step 58200 / 269850 (epoch 64.70 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.316545\n",
      "Training   accuracy: 90.917969 (931 / 1024), f1 (weighted): 90.837196, loss: 0.284865\n",
      "validation accuracy: 64.578846 (148707 / 230272), f1 (weighted): 64.177507, loss: 1.167907\n",
      "time: 33650s (wall 22914s)\n",
      "\n",
      "\n",
      "step 58300 / 269850 (epoch 64.81 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.324476\n",
      "Training   accuracy: 90.136719 (923 / 1024), f1 (weighted): 90.091732, loss: 0.282761\n",
      "validation accuracy: 64.580149 (148710 / 230272), f1 (weighted): 64.318329, loss: 1.180443\n",
      "time: 33708s (wall 22953s)\n",
      "\n",
      "\n",
      "step 58400 / 269850 (epoch 64.92 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.307700\n",
      "Training   accuracy: 89.550781 (917 / 1024), f1 (weighted): 89.555677, loss: 0.290533\n",
      "validation accuracy: 64.720418 (149033 / 230272), f1 (weighted): 64.582523, loss: 1.172145\n",
      "time: 33765s (wall 22992s)\n",
      "\n",
      "\n",
      "step 58500 / 269850 (epoch 65.04 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.296932\n",
      "Training   accuracy: 90.722656 (929 / 1024), f1 (weighted): 90.718821, loss: 0.281858\n",
      "validation accuracy: 65.038303 (149765 / 230272), f1 (weighted): 64.904378, loss: 1.177060\n",
      "time: 33822s (wall 23031s)\n",
      "\n",
      "\n",
      "step 58600 / 269850 (epoch 65.15 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.305040\n",
      "Training   accuracy: 91.210938 (934 / 1024), f1 (weighted): 91.215357, loss: 0.273138\n",
      "validation accuracy: 64.660054 (148894 / 230272), f1 (weighted): 64.425979, loss: 1.172476\n",
      "time: 33879s (wall 23070s)\n",
      "\n",
      "\n",
      "step 58700 / 269850 (epoch 65.26 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.316028\n",
      "Training   accuracy: 89.746094 (919 / 1024), f1 (weighted): 89.674226, loss: 0.290959\n",
      "validation accuracy: 64.271818 (148000 / 230272), f1 (weighted): 64.261087, loss: 1.204344\n",
      "time: 33936s (wall 23109s)\n",
      "\n",
      "\n",
      "step 58800 / 269850 (epoch 65.37 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.331835\n",
      "Training   accuracy: 90.332031 (925 / 1024), f1 (weighted): 90.332942, loss: 0.296175\n",
      "validation accuracy: 63.826692 (146975 / 230272), f1 (weighted): 63.336492, loss: 1.220112\n",
      "time: 33993s (wall 23148s)\n",
      "\n",
      "\n",
      "step 58900 / 269850 (epoch 65.48 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.334442\n",
      "Training   accuracy: 89.062500 (912 / 1024), f1 (weighted): 89.070809, loss: 0.324390\n",
      "validation accuracy: 64.241419 (147930 / 230272), f1 (weighted): 64.176762, loss: 1.180716\n",
      "time: 34050s (wall 23187s)\n",
      "\n",
      "\n",
      "step 59000 / 269850 (epoch 65.59 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.321140\n",
      "Training   accuracy: 90.136719 (923 / 1024), f1 (weighted): 90.108277, loss: 0.287959\n",
      "validation accuracy: 64.007348 (147391 / 230272), f1 (weighted): 63.970949, loss: 1.207723\n",
      "time: 34107s (wall 23225s)\n",
      "\n",
      "\n",
      "step 59100 / 269850 (epoch 65.70 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.310571\n",
      "Training   accuracy: 92.480469 (947 / 1024), f1 (weighted): 92.459418, loss: 0.254679\n",
      "validation accuracy: 64.704784 (148997 / 230272), f1 (weighted): 64.469428, loss: 1.188867\n",
      "time: 34164s (wall 23264s)\n",
      "\n",
      "\n",
      "step 59200 / 269850 (epoch 65.81 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.316957\n",
      "Training   accuracy: 90.917969 (931 / 1024), f1 (weighted): 90.910540, loss: 0.271169\n",
      "validation accuracy: 64.667871 (148912 / 230272), f1 (weighted): 64.469840, loss: 1.171160\n",
      "time: 34221s (wall 23303s)\n",
      "\n",
      "\n",
      "step 59300 / 269850 (epoch 65.93 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.318275\n",
      "Training   accuracy: 90.332031 (925 / 1024), f1 (weighted): 90.350837, loss: 0.302450\n",
      "validation accuracy: 64.503717 (148534 / 230272), f1 (weighted): 64.591607, loss: 1.153463\n",
      "time: 34279s (wall 23342s)\n",
      "\n",
      "\n",
      "step 59400 / 269850 (epoch 66.04 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.296863\n",
      "Training   accuracy: 91.992188 (942 / 1024), f1 (weighted): 91.955546, loss: 0.242917\n",
      "validation accuracy: 64.798586 (149213 / 230272), f1 (weighted): 64.633372, loss: 1.192785\n",
      "time: 34336s (wall 23381s)\n",
      "\n",
      "\n",
      "step 59500 / 269850 (epoch 66.15 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.306457\n",
      "Training   accuracy: 91.503906 (937 / 1024), f1 (weighted): 91.485743, loss: 0.273734\n",
      "validation accuracy: 64.402098 (148300 / 230272), f1 (weighted): 64.144484, loss: 1.194845\n",
      "time: 34393s (wall 23420s)\n",
      "\n",
      "\n",
      "step 59600 / 269850 (epoch 66.26 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.307927\n",
      "Training   accuracy: 89.843750 (920 / 1024), f1 (weighted): 89.833749, loss: 0.287470\n",
      "validation accuracy: 64.752119 (149106 / 230272), f1 (weighted): 64.532198, loss: 1.159205\n",
      "time: 34450s (wall 23459s)\n",
      "\n",
      "\n",
      "step 59700 / 269850 (epoch 66.37 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.302845\n",
      "Training   accuracy: 91.503906 (937 / 1024), f1 (weighted): 91.490948, loss: 0.264647\n",
      "validation accuracy: 64.754291 (149111 / 230272), f1 (weighted): 64.482605, loss: 1.184724\n",
      "time: 34507s (wall 23498s)\n",
      "\n",
      "\n",
      "step 59800 / 269850 (epoch 66.48 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.316450\n",
      "Training   accuracy: 88.574219 (907 / 1024), f1 (weighted): 88.542491, loss: 0.331431\n",
      "validation accuracy: 64.553658 (148649 / 230272), f1 (weighted): 64.407016, loss: 1.146974\n",
      "time: 34565s (wall 23536s)\n",
      "\n",
      "\n",
      "step 59900 / 269850 (epoch 66.59 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.317361\n",
      "Training   accuracy: 90.722656 (929 / 1024), f1 (weighted): 90.761183, loss: 0.275746\n",
      "validation accuracy: 64.424680 (148352 / 230272), f1 (weighted): 64.597221, loss: 1.175239\n",
      "time: 34622s (wall 23575s)\n",
      "\n",
      "\n",
      "step 60000 / 269850 (epoch 66.70 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.315710\n",
      "Training   accuracy: 91.113281 (933 / 1024), f1 (weighted): 91.123415, loss: 0.264625\n",
      "validation accuracy: 64.589268 (148731 / 230272), f1 (weighted): 64.031216, loss: 1.186470\n",
      "time: 34679s (wall 23614s)\n",
      "\n",
      "\n",
      "step 60100 / 269850 (epoch 66.81 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.315865\n",
      "Training   accuracy: 90.136719 (923 / 1024), f1 (weighted): 90.142806, loss: 0.289627\n",
      "validation accuracy: 64.840710 (149310 / 230272), f1 (weighted): 64.769961, loss: 1.156486\n",
      "time: 34736s (wall 23653s)\n",
      "\n",
      "\n",
      "step 60200 / 269850 (epoch 66.93 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.319692\n",
      "Training   accuracy: 91.015625 (932 / 1024), f1 (weighted): 91.034274, loss: 0.287275\n",
      "validation accuracy: 64.677859 (148935 / 230272), f1 (weighted): 64.710724, loss: 1.151206\n",
      "time: 34793s (wall 23692s)\n",
      "\n",
      "\n",
      "step 60300 / 269850 (epoch 67.04 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.320615\n",
      "Training   accuracy: 89.453125 (916 / 1024), f1 (weighted): 89.405210, loss: 0.304094\n",
      "validation accuracy: 64.335221 (148146 / 230272), f1 (weighted): 63.905500, loss: 1.198394\n",
      "time: 34850s (wall 23731s)\n",
      "\n",
      "\n",
      "step 60400 / 269850 (epoch 67.15 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.305915\n",
      "Training   accuracy: 90.820312 (930 / 1024), f1 (weighted): 90.770615, loss: 0.267497\n",
      "validation accuracy: 64.355632 (148193 / 230272), f1 (weighted): 63.987200, loss: 1.213938\n",
      "time: 34907s (wall 23770s)\n",
      "\n",
      "\n",
      "step 60500 / 269850 (epoch 67.26 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.323570\n",
      "Training   accuracy: 89.941406 (921 / 1024), f1 (weighted): 89.960081, loss: 0.304095\n",
      "validation accuracy: 64.217968 (147876 / 230272), f1 (weighted): 64.070984, loss: 1.191880\n",
      "time: 34964s (wall 23808s)\n",
      "\n",
      "\n",
      "step 60600 / 269850 (epoch 67.37 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.321249\n",
      "Training   accuracy: 91.308594 (935 / 1024), f1 (weighted): 91.274914, loss: 0.287245\n",
      "validation accuracy: 64.450302 (148411 / 230272), f1 (weighted): 64.343305, loss: 1.168605\n",
      "time: 35022s (wall 23847s)\n",
      "\n",
      "\n",
      "step 60700 / 269850 (epoch 67.48 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.331248\n",
      "Training   accuracy: 88.769531 (909 / 1024), f1 (weighted): 88.803808, loss: 0.309512\n",
      "validation accuracy: 64.253144 (147957 / 230272), f1 (weighted): 64.298181, loss: 1.160650\n",
      "time: 35079s (wall 23886s)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 60800 / 269850 (epoch 67.59 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.322938\n",
      "Training   accuracy: 90.234375 (924 / 1024), f1 (weighted): 90.223121, loss: 0.310159\n",
      "validation accuracy: 64.337392 (148151 / 230272), f1 (weighted): 63.932770, loss: 1.192992\n",
      "time: 35137s (wall 23925s)\n",
      "\n",
      "\n",
      "step 60900 / 269850 (epoch 67.70 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.330196\n",
      "Training   accuracy: 89.453125 (916 / 1024), f1 (weighted): 89.419410, loss: 0.310984\n",
      "validation accuracy: 64.264435 (147983 / 230272), f1 (weighted): 64.065952, loss: 1.188115\n",
      "time: 35194s (wall 23964s)\n",
      "\n",
      "\n",
      "step 61000 / 269850 (epoch 67.82 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.315707\n",
      "Training   accuracy: 89.160156 (913 / 1024), f1 (weighted): 89.125950, loss: 0.307911\n",
      "validation accuracy: 64.270515 (147997 / 230272), f1 (weighted): 64.235073, loss: 1.201901\n",
      "time: 35251s (wall 24003s)\n",
      "\n",
      "\n",
      "step 61100 / 269850 (epoch 67.93 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.338242\n",
      "Training   accuracy: 89.062500 (912 / 1024), f1 (weighted): 89.065621, loss: 0.315494\n",
      "validation accuracy: 63.779791 (146867 / 230272), f1 (weighted): 63.310047, loss: 1.210927\n",
      "time: 35309s (wall 24042s)\n",
      "\n",
      "\n",
      "step 61200 / 269850 (epoch 68.04 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.307616\n",
      "Training   accuracy: 89.941406 (921 / 1024), f1 (weighted): 89.927767, loss: 0.304533\n",
      "validation accuracy: 64.363883 (148212 / 230272), f1 (weighted): 64.099566, loss: 1.191110\n",
      "time: 35366s (wall 24081s)\n",
      "\n",
      "\n",
      "step 61300 / 269850 (epoch 68.15 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.314126\n",
      "Training   accuracy: 91.601562 (938 / 1024), f1 (weighted): 91.595959, loss: 0.267787\n",
      "validation accuracy: 64.552355 (148646 / 230272), f1 (weighted): 64.266550, loss: 1.190888\n",
      "time: 35423s (wall 24120s)\n",
      "\n",
      "\n",
      "step 61400 / 269850 (epoch 68.26 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.320286\n",
      "Training   accuracy: 90.429688 (926 / 1024), f1 (weighted): 90.397659, loss: 0.299264\n",
      "validation accuracy: 64.411218 (148321 / 230272), f1 (weighted): 64.014471, loss: 1.198351\n",
      "time: 35481s (wall 24159s)\n",
      "\n",
      "\n",
      "step 61500 / 269850 (epoch 68.37 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.324577\n",
      "Training   accuracy: 90.332031 (925 / 1024), f1 (weighted): 90.313811, loss: 0.289320\n",
      "validation accuracy: 64.310033 (148088 / 230272), f1 (weighted): 64.323603, loss: 1.181708\n",
      "time: 35538s (wall 24198s)\n",
      "\n",
      "\n",
      "step 61600 / 269850 (epoch 68.48 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.321024\n",
      "Training   accuracy: 90.820312 (930 / 1024), f1 (weighted): 90.812342, loss: 0.278251\n",
      "validation accuracy: 63.553971 (146347 / 230272), f1 (weighted): 63.445407, loss: 1.213842\n",
      "time: 35596s (wall 24238s)\n",
      "\n",
      "\n",
      "step 61700 / 269850 (epoch 68.59 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.328596\n",
      "Training   accuracy: 88.964844 (911 / 1024), f1 (weighted): 88.936848, loss: 0.309738\n",
      "validation accuracy: 64.586228 (148724 / 230272), f1 (weighted): 64.483481, loss: 1.194643\n",
      "time: 35654s (wall 24277s)\n",
      "\n",
      "\n",
      "step 61800 / 269850 (epoch 68.70 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.318280\n",
      "Training   accuracy: 90.527344 (927 / 1024), f1 (weighted): 90.558467, loss: 0.290609\n",
      "validation accuracy: 64.313508 (148096 / 230272), f1 (weighted): 64.576157, loss: 1.181734\n",
      "time: 35713s (wall 24319s)\n",
      "\n",
      "\n",
      "step 61900 / 269850 (epoch 68.82 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.320455\n",
      "Training   accuracy: 88.964844 (911 / 1024), f1 (weighted): 88.964426, loss: 0.313854\n",
      "validation accuracy: 64.854607 (149342 / 230272), f1 (weighted): 64.752202, loss: 1.176997\n",
      "time: 35771s (wall 24358s)\n",
      "\n",
      "\n",
      "step 62000 / 269850 (epoch 68.93 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.323967\n",
      "Training   accuracy: 91.406250 (936 / 1024), f1 (weighted): 91.394693, loss: 0.275769\n",
      "validation accuracy: 64.437708 (148382 / 230272), f1 (weighted): 64.193111, loss: 1.192636\n",
      "time: 35829s (wall 24397s)\n",
      "\n",
      "\n",
      "step 62100 / 269850 (epoch 69.04 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.300485\n",
      "Training   accuracy: 91.015625 (932 / 1024), f1 (weighted): 91.002388, loss: 0.260656\n",
      "validation accuracy: 64.456382 (148425 / 230272), f1 (weighted): 64.350865, loss: 1.209893\n",
      "time: 35887s (wall 24436s)\n",
      "\n",
      "\n",
      "step 62200 / 269850 (epoch 69.15 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.310568\n",
      "Training   accuracy: 91.210938 (934 / 1024), f1 (weighted): 91.222936, loss: 0.287950\n",
      "validation accuracy: 64.809443 (149238 / 230272), f1 (weighted): 64.696039, loss: 1.177060\n",
      "time: 35946s (wall 24478s)\n",
      "\n",
      "\n",
      "step 62300 / 269850 (epoch 69.26 / 300):\n",
      "learning_rate = 0.010000, loss_average = 0.312259\n"
     ]
    }
   ],
   "source": [
    "model = DenseGCN_Model.cgcnn(L, **params)\n",
    "accuracy, loss, t_step = model.fit(X_train, train_label, X_test, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8525ecd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826d4e44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce71586",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
